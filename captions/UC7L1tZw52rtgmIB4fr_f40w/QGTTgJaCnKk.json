[
  {
    "text": "hello",
    "start": "5240",
    "end": "7559"
  },
  {
    "text": "everyone hello everyone my name is",
    "start": "10799",
    "end": "13440"
  },
  {
    "text": "freedy I work as a principal machine",
    "start": "13440",
    "end": "15839"
  },
  {
    "text": "learning engineer at best Farmers 1",
    "start": "15839",
    "end": "18520"
  },
  {
    "text": "digital and today I'm here to talk about",
    "start": "18520",
    "end": "21000"
  },
  {
    "text": "the machine learning platform that we",
    "start": "21000",
    "end": "22519"
  },
  {
    "text": "have built at best Farmers 1",
    "start": "22519",
    "end": "25880"
  },
  {
    "text": "digital so before I begin my talk for",
    "start": "26359",
    "end": "28960"
  },
  {
    "text": "today I just want to take a moment to",
    "start": "28960",
    "end": "31480"
  },
  {
    "text": "talk about the company that I work for",
    "start": "31480",
    "end": "34200"
  },
  {
    "text": "so West Farmers is one of the leading",
    "start": "34200",
    "end": "36320"
  },
  {
    "text": "conglomerates in",
    "start": "36320",
    "end": "38399"
  },
  {
    "text": "Australia as of financial year 2023 West",
    "start": "38399",
    "end": "41520"
  },
  {
    "text": "Farmers is valued at 43.6 billion",
    "start": "41520",
    "end": "44239"
  },
  {
    "text": "Australian dollars West Farmers own some",
    "start": "44239",
    "end": "46600"
  },
  {
    "text": "of the most trusted B brands in",
    "start": "46600",
    "end": "49280"
  },
  {
    "text": "Australia like Kmart Target Bunnings",
    "start": "49280",
    "end": "53039"
  },
  {
    "text": "Office Works and many",
    "start": "53039",
    "end": "55399"
  },
  {
    "text": "others recently West Farmers formed a",
    "start": "55399",
    "end": "58160"
  },
  {
    "text": "new data and digital division called one",
    "start": "58160",
    "end": "60680"
  },
  {
    "text": "digital and I work in the data science",
    "start": "60680",
    "end": "62680"
  },
  {
    "text": "team at one",
    "start": "62680",
    "end": "64040"
  },
  {
    "text": "digital so as you can imagine the kind",
    "start": "64040",
    "end": "66400"
  },
  {
    "text": "of use cases and machine learning",
    "start": "66400",
    "end": "68400"
  },
  {
    "text": "problems that we work on are generally",
    "start": "68400",
    "end": "70520"
  },
  {
    "text": "around customer preferences",
    "start": "70520",
    "end": "73320"
  },
  {
    "text": "understanding customer Journeys creating",
    "start": "73320",
    "end": "75640"
  },
  {
    "text": "customer segments and so",
    "start": "75640",
    "end": "78840"
  },
  {
    "text": "forth so today I want to talk about the",
    "start": "78840",
    "end": "82159"
  },
  {
    "text": "machine learning platform that we have",
    "start": "82159",
    "end": "83960"
  },
  {
    "text": "built at one digital so I'll start with",
    "start": "83960",
    "end": "86759"
  },
  {
    "text": "sharing my journey of creating this new",
    "start": "86759",
    "end": "89360"
  },
  {
    "text": "platform",
    "start": "89360",
    "end": "90960"
  },
  {
    "text": "then I'll talk about the platform",
    "start": "90960",
    "end": "93040"
  },
  {
    "text": "architecture and how we have built this",
    "start": "93040",
    "end": "95320"
  },
  {
    "text": "platform after that I'll talk about the",
    "start": "95320",
    "end": "97920"
  },
  {
    "text": "migration Journey we had of migrating a",
    "start": "97920",
    "end": "100439"
  },
  {
    "text": "few workloads in production from the",
    "start": "100439",
    "end": "102240"
  },
  {
    "text": "previous platform to the new one and",
    "start": "102240",
    "end": "104520"
  },
  {
    "text": "finally I'll share a use case of how we",
    "start": "104520",
    "end": "106960"
  },
  {
    "text": "have used Ray remote distribution",
    "start": "106960",
    "end": "109640"
  },
  {
    "text": "distributed Paradigm to make one of our",
    "start": "109640",
    "end": "113759"
  },
  {
    "text": "use cases",
    "start": "113759",
    "end": "116520"
  },
  {
    "text": "simpler so beginning with the journey",
    "start": "118840",
    "end": "121880"
  },
  {
    "text": "that we had so back in",
    "start": "121880",
    "end": "123960"
  },
  {
    "text": "2020 we wrote the first version of our",
    "start": "123960",
    "end": "126719"
  },
  {
    "text": "platform this platform was based on",
    "start": "126719",
    "end": "129239"
  },
  {
    "text": "cities which we selfhosted we also chose",
    "start": "129239",
    "end": "133000"
  },
  {
    "text": "mlflow as the model monitoring and",
    "start": "133000",
    "end": "135760"
  },
  {
    "text": "storage solution at that time for the",
    "start": "135760",
    "end": "139080"
  },
  {
    "text": "next 2 and half years we would use this",
    "start": "139080",
    "end": "142200"
  },
  {
    "text": "platform to create our model pipelines",
    "start": "142200",
    "end": "145280"
  },
  {
    "text": "and for the day-to-day workbench that",
    "start": "145280",
    "end": "147800"
  },
  {
    "text": "the data science would need for the ad",
    "start": "147800",
    "end": "149519"
  },
  {
    "text": "hoc",
    "start": "149519",
    "end": "151080"
  },
  {
    "text": "experimentation in the last 2 and a half",
    "start": "151080",
    "end": "153280"
  },
  {
    "text": "years what we observed was this platform",
    "start": "153280",
    "end": "156760"
  },
  {
    "text": "continued to build a lot of tech debt so",
    "start": "156760",
    "end": "160040"
  },
  {
    "text": "we would face operational inefficiencies",
    "start": "160040",
    "end": "163000"
  },
  {
    "text": "in the platform there would be very long",
    "start": "163000",
    "end": "166000"
  },
  {
    "text": "model training and scoring run times we",
    "start": "166000",
    "end": "169680"
  },
  {
    "text": "would also face memory issues and we",
    "start": "169680",
    "end": "173000"
  },
  {
    "text": "would face some very specific",
    "start": "173000",
    "end": "175040"
  },
  {
    "text": "operational constraint around cities",
    "start": "175040",
    "end": "178360"
  },
  {
    "text": "management so last year we decided to",
    "start": "178360",
    "end": "181519"
  },
  {
    "text": "uplift our",
    "start": "181519",
    "end": "183840"
  },
  {
    "text": "platform and we wanted to move away from",
    "start": "183840",
    "end": "187400"
  },
  {
    "text": "cuetes being a small team we had limited",
    "start": "187400",
    "end": "190280"
  },
  {
    "text": "resources and limited time to manage the",
    "start": "190280",
    "end": "193840"
  },
  {
    "text": "kubernetes so we decided to move away",
    "start": "193840",
    "end": "196280"
  },
  {
    "text": "from cuberes and adopt Ray and any scale",
    "start": "196280",
    "end": "199480"
  },
  {
    "text": "at the same time we replaced mlflow with",
    "start": "199480",
    "end": "203040"
  },
  {
    "text": "weights and biases at as a model storage",
    "start": "203040",
    "end": "206879"
  },
  {
    "text": "solution so as you can see on the screen",
    "start": "206879",
    "end": "209799"
  },
  {
    "text": "in last June we made the decision by",
    "start": "209799",
    "end": "212080"
  },
  {
    "text": "July we had successfully completed proof",
    "start": "212080",
    "end": "215560"
  },
  {
    "text": "of concept with the vendors Ray and",
    "start": "215560",
    "end": "217599"
  },
  {
    "text": "scale and weights and biases and in",
    "start": "217599",
    "end": "219799"
  },
  {
    "text": "September we kicked off the production",
    "start": "219799",
    "end": "223200"
  },
  {
    "text": "build this March we released the first",
    "start": "223200",
    "end": "225799"
  },
  {
    "text": "version of our platform and by this may",
    "start": "225799",
    "end": "228480"
  },
  {
    "text": "we had migrated all our production",
    "start": "228480",
    "end": "230319"
  },
  {
    "text": "workloads from the previous platform to",
    "start": "230319",
    "end": "232239"
  },
  {
    "text": "the new",
    "start": "232239",
    "end": "234640"
  },
  {
    "text": "platform as we had been using this",
    "start": "235360",
    "end": "237720"
  },
  {
    "text": "platform for over 3 years our our data",
    "start": "237720",
    "end": "240079"
  },
  {
    "text": "science team had a pretty good idea what",
    "start": "240079",
    "end": "242159"
  },
  {
    "text": "they wanted out of the new",
    "start": "242159",
    "end": "244120"
  },
  {
    "text": "platform so what we wanted for our data",
    "start": "244120",
    "end": "247720"
  },
  {
    "text": "scientists was that they would be able",
    "start": "247720",
    "end": "250319"
  },
  {
    "text": "to build deploy maintain and monitor",
    "start": "250319",
    "end": "253200"
  },
  {
    "text": "machine learning models in production",
    "start": "253200",
    "end": "255319"
  },
  {
    "text": "with minimal inuring",
    "start": "255319",
    "end": "257120"
  },
  {
    "text": "efforts so that was what our vision was",
    "start": "257120",
    "end": "260840"
  },
  {
    "text": "so based on that we came up with a few",
    "start": "260840",
    "end": "263199"
  },
  {
    "text": "guiding principles so like I said we",
    "start": "263199",
    "end": "266160"
  },
  {
    "text": "wanted to maximize the DS ownership in",
    "start": "266160",
    "end": "269000"
  },
  {
    "text": "the new platform form we also did not",
    "start": "269000",
    "end": "271759"
  },
  {
    "text": "want to reinvent the",
    "start": "271759",
    "end": "274280"
  },
  {
    "text": "wheel unlike the last time this time",
    "start": "274280",
    "end": "276960"
  },
  {
    "text": "what we wanted was to have more vendors",
    "start": "276960",
    "end": "279479"
  },
  {
    "text": "come in and Outsource some of the",
    "start": "279479",
    "end": "281400"
  },
  {
    "text": "problematic areas and components of our",
    "start": "281400",
    "end": "283400"
  },
  {
    "text": "platform rather than hosting our own",
    "start": "283400",
    "end": "286479"
  },
  {
    "text": "services and writing our own software",
    "start": "286479",
    "end": "288520"
  },
  {
    "text": "for",
    "start": "288520",
    "end": "289280"
  },
  {
    "text": "that we also wanted to reuse the",
    "start": "289280",
    "end": "291880"
  },
  {
    "text": "existing",
    "start": "291880",
    "end": "292919"
  },
  {
    "text": "infrastructure as we were all based on",
    "start": "292919",
    "end": "295080"
  },
  {
    "text": "AWS we wanted to keep the infrastructure",
    "start": "295080",
    "end": "299080"
  },
  {
    "text": "as is but rather do a more of a plug-and",
    "start": "299080",
    "end": "301479"
  },
  {
    "text": "playay kind of approach rather than",
    "start": "301479",
    "end": "304440"
  },
  {
    "text": "writing everything from scratch and",
    "start": "304440",
    "end": "307280"
  },
  {
    "text": "lastly we were a",
    "start": "307280",
    "end": "309639"
  },
  {
    "text": "bit risky in our approach in the sense",
    "start": "309639",
    "end": "312160"
  },
  {
    "text": "that we wanted to try out the latest",
    "start": "312160",
    "end": "313840"
  },
  {
    "text": "state of our technologies that were out",
    "start": "313840",
    "end": "315759"
  },
  {
    "text": "there so we we were bold in the choice",
    "start": "315759",
    "end": "318479"
  },
  {
    "text": "of the vendor that we",
    "start": "318479",
    "end": "322000"
  },
  {
    "text": "made now let's talk about the platform",
    "start": "322000",
    "end": "324479"
  },
  {
    "text": "architecture and",
    "start": "324479",
    "end": "326560"
  },
  {
    "text": "build so what you see on the screen is",
    "start": "326560",
    "end": "329199"
  },
  {
    "text": "our Tex",
    "start": "329199",
    "end": "331280"
  },
  {
    "text": "stack so in the Ed and experimentation",
    "start": "331280",
    "end": "334880"
  },
  {
    "text": "stage we have got any scale weights and",
    "start": "334880",
    "end": "337919"
  },
  {
    "text": "biases which are now the new components",
    "start": "337919",
    "end": "340039"
  },
  {
    "text": "along with the previous component like",
    "start": "340039",
    "end": "341880"
  },
  {
    "text": "Gyer Hub and python which we",
    "start": "341880",
    "end": "344280"
  },
  {
    "text": "use for our um data science use cases",
    "start": "344280",
    "end": "348360"
  },
  {
    "text": "similarly for model training we have",
    "start": "348360",
    "end": "350199"
  },
  {
    "text": "been using and integrated now any scale",
    "start": "350199",
    "end": "352960"
  },
  {
    "text": "and weights and biases for our cicd",
    "start": "352960",
    "end": "355240"
  },
  {
    "text": "pipeline we use gitlab so our model",
    "start": "355240",
    "end": "357560"
  },
  {
    "text": "pipeline is actually written in gitlab",
    "start": "357560",
    "end": "360360"
  },
  {
    "text": "similarly for model monitoring and",
    "start": "360360",
    "end": "363000"
  },
  {
    "text": "monitoring of the pipelines in general",
    "start": "363000",
    "end": "365440"
  },
  {
    "text": "we used to have grafana and Cloud watch",
    "start": "365440",
    "end": "367440"
  },
  {
    "text": "so now we have replaced that with any",
    "start": "367440",
    "end": "369160"
  },
  {
    "text": "scales version of grafana and what we",
    "start": "369160",
    "end": "371960"
  },
  {
    "text": "have done is we have integrated any",
    "start": "371960",
    "end": "373960"
  },
  {
    "text": "scale jobs with slack so that's how we",
    "start": "373960",
    "end": "376960"
  },
  {
    "text": "have created our alerting",
    "start": "376960",
    "end": "379000"
  },
  {
    "text": "mechanism our storage and data store is",
    "start": "379000",
    "end": "381840"
  },
  {
    "text": "based in Snowflake and we also use J",
    "start": "381840",
    "end": "384919"
  },
  {
    "text": "jrog",
    "start": "384919",
    "end": "386039"
  },
  {
    "text": "artifactory um for storing our Docker",
    "start": "386039",
    "end": "388520"
  },
  {
    "text": "images and scanning the",
    "start": "388520",
    "end": "390240"
  },
  {
    "text": "images and for compute we have got ec2",
    "start": "390240",
    "end": "394039"
  },
  {
    "text": "machines which are now managed",
    "start": "394039",
    "end": "396680"
  },
  {
    "text": "completely by any scale previously we",
    "start": "396680",
    "end": "399080"
  },
  {
    "text": "used to manage it ourselves using",
    "start": "399080",
    "end": "401479"
  },
  {
    "text": "selfhosted kubernetes",
    "start": "401479",
    "end": "403280"
  },
  {
    "text": "cluster also we work with our data",
    "start": "403280",
    "end": "405960"
  },
  {
    "text": "engineering team and they use airflow to",
    "start": "405960",
    "end": "408199"
  },
  {
    "text": "run Dax which we use to create our uh",
    "start": "408199",
    "end": "411639"
  },
  {
    "text": "data",
    "start": "411639",
    "end": "413240"
  },
  {
    "text": "pipelines and we also use terraform as",
    "start": "413240",
    "end": "416080"
  },
  {
    "text": "our infrastructure",
    "start": "416080",
    "end": "417800"
  },
  {
    "text": "scode so these Stars show how we have",
    "start": "417800",
    "end": "421720"
  },
  {
    "text": "implemented any scale in all those",
    "start": "421720",
    "end": "423479"
  },
  {
    "text": "different areas of our text tack",
    "start": "423479",
    "end": "427080"
  },
  {
    "text": "similarly how we have integrated weights",
    "start": "427080",
    "end": "429400"
  },
  {
    "text": "and biases also in those different text",
    "start": "429400",
    "end": "431560"
  },
  {
    "text": "areas of the text",
    "start": "431560",
    "end": "433720"
  },
  {
    "text": "stack the next thing I want to talk",
    "start": "433720",
    "end": "435919"
  },
  {
    "text": "about is how we have implemented our",
    "start": "435919",
    "end": "437800"
  },
  {
    "text": "production pipelines using any scale",
    "start": "437800",
    "end": "440479"
  },
  {
    "text": "jobs so like I said before we use gitlab",
    "start": "440479",
    "end": "444039"
  },
  {
    "text": "as our cicd solution so what we have",
    "start": "444039",
    "end": "446599"
  },
  {
    "text": "done is we have written our gitlab",
    "start": "446599",
    "end": "449960"
  },
  {
    "text": "machine learning pipelines it's there",
    "start": "449960",
    "end": "452520"
  },
  {
    "text": "where we create any scale production",
    "start": "452520",
    "end": "455280"
  },
  {
    "text": "jobs now any scale production job they",
    "start": "455280",
    "end": "457800"
  },
  {
    "text": "talk to weights and bies and they also",
    "start": "457800",
    "end": "459599"
  },
  {
    "text": "interact with snowflake to get in the",
    "start": "459599",
    "end": "461199"
  },
  {
    "text": "data and to store upload and download",
    "start": "461199",
    "end": "463560"
  },
  {
    "text": "the models as well on the bottom of",
    "start": "463560",
    "end": "466000"
  },
  {
    "text": "screen what you see is just a code",
    "start": "466000",
    "end": "467520"
  },
  {
    "text": "snippet of how our standard machine",
    "start": "467520",
    "end": "469720"
  },
  {
    "text": "learning pipeline would look like so we",
    "start": "469720",
    "end": "472000"
  },
  {
    "text": "use API from four weights and biases and",
    "start": "472000",
    "end": "475120"
  },
  {
    "text": "Ray um to let's say um write some Ray",
    "start": "475120",
    "end": "478759"
  },
  {
    "text": "remote function",
    "start": "478759",
    "end": "479960"
  },
  {
    "text": "uh to log into weights and biases and",
    "start": "479960",
    "end": "482280"
  },
  {
    "text": "start a ray cluster on the right side",
    "start": "482280",
    "end": "485440"
  },
  {
    "text": "what you see is is a snippet for a",
    "start": "485440",
    "end": "487960"
  },
  {
    "text": "sample job so this is how we have",
    "start": "487960",
    "end": "490560"
  },
  {
    "text": "defined our production jobs so we've got",
    "start": "490560",
    "end": "493280"
  },
  {
    "text": "a project ID we create our own compute",
    "start": "493280",
    "end": "495280"
  },
  {
    "text": "configs we have our own cluster",
    "start": "495280",
    "end": "498120"
  },
  {
    "text": "environment uh and then uh we have got",
    "start": "498120",
    "end": "500879"
  },
  {
    "text": "an entry point from which it connects to",
    "start": "500879",
    "end": "502840"
  },
  {
    "text": "the python application code to run a",
    "start": "502840",
    "end": "505120"
  },
  {
    "text": "particular any scale",
    "start": "505120",
    "end": "507400"
  },
  {
    "text": "job I also want to highlight something",
    "start": "507400",
    "end": "510120"
  },
  {
    "text": "else here which is really helpful for us",
    "start": "510120",
    "end": "513399"
  },
  {
    "text": "is the partnership between any scale and",
    "start": "513399",
    "end": "515080"
  },
  {
    "text": "weights and biases as we have integrated",
    "start": "515080",
    "end": "517560"
  },
  {
    "text": "both of these separate technology into",
    "start": "517560",
    "end": "520000"
  },
  {
    "text": "our platform it made sense for us to",
    "start": "520000",
    "end": "523399"
  },
  {
    "text": "just um uh explore ways in which they",
    "start": "523399",
    "end": "526040"
  },
  {
    "text": "work better so what you see on the",
    "start": "526040",
    "end": "528360"
  },
  {
    "text": "screen uh in this red circle is how any",
    "start": "528360",
    "end": "532800"
  },
  {
    "text": "scale and weights and biases are working",
    "start": "532800",
    "end": "535560"
  },
  {
    "text": "together so the the screen shows the",
    "start": "535560",
    "end": "537600"
  },
  {
    "text": "console of any scale so this is a job",
    "start": "537600",
    "end": "541320"
  },
  {
    "text": "from an any scale job you can integrate",
    "start": "541320",
    "end": "543959"
  },
  {
    "text": "a weights and biases run so that's the",
    "start": "543959",
    "end": "546360"
  },
  {
    "text": "red circle uh will take you directly to",
    "start": "546360",
    "end": "548680"
  },
  {
    "text": "weights and bies run which I'll show in",
    "start": "548680",
    "end": "550320"
  },
  {
    "text": "the next screen so this is a weights and",
    "start": "550320",
    "end": "552640"
  },
  {
    "text": "biases console and what you see in the",
    "start": "552640",
    "end": "554640"
  },
  {
    "text": "circle is a connection from where you",
    "start": "554640",
    "end": "556760"
  },
  {
    "text": "can go from a w and biis run back to an",
    "start": "556760",
    "end": "559320"
  },
  {
    "text": "any scale",
    "start": "559320",
    "end": "561000"
  },
  {
    "text": "job this is pretty handy for us as we",
    "start": "561000",
    "end": "563839"
  },
  {
    "text": "have both these Technologies and there",
    "start": "563839",
    "end": "566680"
  },
  {
    "text": "at every stage of the pipeline we use",
    "start": "566680",
    "end": "568880"
  },
  {
    "text": "both any scale and weights and",
    "start": "568880",
    "end": "571959"
  },
  {
    "text": "bues so the next thing I want to talk",
    "start": "571959",
    "end": "574360"
  },
  {
    "text": "about is the production workload and the",
    "start": "574360",
    "end": "576480"
  },
  {
    "text": "migration exercise that we did to move",
    "start": "576480",
    "end": "578480"
  },
  {
    "text": "our existing workloads from the previous",
    "start": "578480",
    "end": "580959"
  },
  {
    "text": "platform to the new",
    "start": "580959",
    "end": "583800"
  },
  {
    "text": "one so just to set some context in the",
    "start": "584440",
    "end": "588160"
  },
  {
    "text": "previous platform where our models were",
    "start": "588160",
    "end": "590240"
  },
  {
    "text": "previously running we had quite a few",
    "start": "590240",
    "end": "592720"
  },
  {
    "text": "problems so our model pipelines would",
    "start": "592720",
    "end": "595200"
  },
  {
    "text": "take sometimes too long to finish either",
    "start": "595200",
    "end": "597600"
  },
  {
    "text": "the training or the school",
    "start": "597600",
    "end": "600440"
  },
  {
    "text": "scoring as we experience more and more",
    "start": "600440",
    "end": "604000"
  },
  {
    "text": "data uh as we as for the some of the use",
    "start": "604000",
    "end": "606760"
  },
  {
    "text": "cases which would be on a store level on",
    "start": "606760",
    "end": "609760"
  },
  {
    "text": "a regional level and sometimes we would",
    "start": "609760",
    "end": "611640"
  },
  {
    "text": "work on use cases in which we we would",
    "start": "611640",
    "end": "613760"
  },
  {
    "text": "work with multiple West Farmers Division",
    "start": "613760",
    "end": "615920"
  },
  {
    "text": "and we need to combine the data from all",
    "start": "615920",
    "end": "617560"
  },
  {
    "text": "the division we would see the problem of",
    "start": "617560",
    "end": "621720"
  },
  {
    "text": "scaling getting more and",
    "start": "621720",
    "end": "624160"
  },
  {
    "text": "more and that what that meant for us is",
    "start": "624160",
    "end": "627279"
  },
  {
    "text": "we would start experiences models which",
    "start": "627279",
    "end": "629880"
  },
  {
    "text": "would not fit in memory of one machine",
    "start": "629880",
    "end": "633480"
  },
  {
    "text": "so either the size of data would get too",
    "start": "633480",
    "end": "635240"
  },
  {
    "text": "large or the size of model itself still",
    "start": "635240",
    "end": "637440"
  },
  {
    "text": "some sometimes would get too",
    "start": "637440",
    "end": "639480"
  },
  {
    "text": "large we also experienced low",
    "start": "639480",
    "end": "642040"
  },
  {
    "text": "observability of production models so in",
    "start": "642040",
    "end": "644880"
  },
  {
    "text": "the last version of our platform what we",
    "start": "644880",
    "end": "646800"
  },
  {
    "text": "did was we had kubernetes sometimes we",
    "start": "646800",
    "end": "649519"
  },
  {
    "text": "would send some logs from kubernetes to",
    "start": "649519",
    "end": "652680"
  },
  {
    "text": "cloudwatch but most of the times what we",
    "start": "652680",
    "end": "655000"
  },
  {
    "text": "ended up doing was like literally",
    "start": "655000",
    "end": "656839"
  },
  {
    "text": "logging into Cube Running P and would",
    "start": "656839",
    "end": "659639"
  },
  {
    "text": "would have to sssh into the cluster we'd",
    "start": "659639",
    "end": "661760"
  },
  {
    "text": "have to grab the logs pull it out that",
    "start": "661760",
    "end": "664680"
  },
  {
    "text": "used to be not so ideal way of looking",
    "start": "664680",
    "end": "667320"
  },
  {
    "text": "at logs of observing the production",
    "start": "667320",
    "end": "670560"
  },
  {
    "text": "models so the debugging was really",
    "start": "670560",
    "end": "673920"
  },
  {
    "text": "hard and lastly we would experience some",
    "start": "673920",
    "end": "678200"
  },
  {
    "text": "very specific inefficiencies around",
    "start": "678200",
    "end": "680320"
  },
  {
    "text": "cubity Stacks so people who have been",
    "start": "680320",
    "end": "682560"
  },
  {
    "text": "used uh you have used uh cuberes before",
    "start": "682560",
    "end": "685000"
  },
  {
    "text": "would know very well that cuberes is a",
    "start": "685000",
    "end": "686800"
  },
  {
    "text": "fantastic technology but at the same",
    "start": "686800",
    "end": "689120"
  },
  {
    "text": "time managing a cube cluster is not",
    "start": "689120",
    "end": "694480"
  },
  {
    "text": "easy so as part of migrating to any",
    "start": "695279",
    "end": "697839"
  },
  {
    "text": "scale and Ray we had a few Focus areas",
    "start": "697839",
    "end": "701680"
  },
  {
    "text": "the first one was Cod reite so what it",
    "start": "701680",
    "end": "703839"
  },
  {
    "text": "meant for us was the code that was",
    "start": "703839",
    "end": "705360"
  },
  {
    "text": "already written and in production we had",
    "start": "705360",
    "end": "707240"
  },
  {
    "text": "to write certain section of the codes",
    "start": "707240",
    "end": "709120"
  },
  {
    "text": "specifically the wrappers in the way",
    "start": "709120",
    "end": "711440"
  },
  {
    "text": "that the code and the model would",
    "start": "711440",
    "end": "713519"
  },
  {
    "text": "interact with the data store because",
    "start": "713519",
    "end": "715600"
  },
  {
    "text": "previously we would directly uh connect",
    "start": "715600",
    "end": "718959"
  },
  {
    "text": "Cube cluster with the snowflake now with",
    "start": "718959",
    "end": "721560"
  },
  {
    "text": "the new platform we had to connect any",
    "start": "721560",
    "end": "723800"
  },
  {
    "text": "scale with snowflake so what that meant",
    "start": "723800",
    "end": "725480"
  },
  {
    "text": "for us we we had new problems to solve",
    "start": "725480",
    "end": "728560"
  },
  {
    "text": "in the sense we we wrote new API",
    "start": "728560",
    "end": "730760"
  },
  {
    "text": "management solution to connect from any",
    "start": "730760",
    "end": "732560"
  },
  {
    "text": "scale to snowflake so we wrote some",
    "start": "732560",
    "end": "734600"
  },
  {
    "text": "datab based utility wrappers which took",
    "start": "734600",
    "end": "736399"
  },
  {
    "text": "us some time similarly as we integrated",
    "start": "736399",
    "end": "738600"
  },
  {
    "text": "weights and bies into the new platform",
    "start": "738600",
    "end": "741160"
  },
  {
    "text": "we had to write wrapper around the",
    "start": "741160",
    "end": "742680"
  },
  {
    "text": "weights and byes API as well another",
    "start": "742680",
    "end": "745959"
  },
  {
    "text": "Focus area that we had was exploring the",
    "start": "745959",
    "end": "748160"
  },
  {
    "text": "improvements",
    "start": "748160",
    "end": "750279"
  },
  {
    "text": "what we wanted to do with the new",
    "start": "750279",
    "end": "752240"
  },
  {
    "text": "platform was explore the opportunities",
    "start": "752240",
    "end": "754680"
  },
  {
    "text": "of making our models better so for",
    "start": "754680",
    "end": "757440"
  },
  {
    "text": "scalable data loading we wanted to use",
    "start": "757440",
    "end": "760040"
  },
  {
    "text": "Ray data set we got the opportunities in",
    "start": "760040",
    "end": "762760"
  },
  {
    "text": "one of the models to explore that and we",
    "start": "762760",
    "end": "765320"
  },
  {
    "text": "were quite successful in doing that for",
    "start": "765320",
    "end": "767680"
  },
  {
    "text": "one of the use cases we also",
    "start": "767680",
    "end": "770639"
  },
  {
    "text": "successfully implemented live GBM",
    "start": "770639",
    "end": "772560"
  },
  {
    "text": "trainer in one of our use cases we also",
    "start": "772560",
    "end": "776480"
  },
  {
    "text": "played around a bit with Ray tune for",
    "start": "776480",
    "end": "779360"
  },
  {
    "text": "hyper parameter",
    "start": "779360",
    "end": "781519"
  },
  {
    "text": "optimization finally we explored",
    "start": "781519",
    "end": "784279"
  },
  {
    "text": "improvements by paralyzing our pipelines",
    "start": "784279",
    "end": "787000"
  },
  {
    "text": "by using fre",
    "start": "787000",
    "end": "789560"
  },
  {
    "text": "remote as with any new technologies it",
    "start": "789560",
    "end": "792360"
  },
  {
    "text": "comes with its own set of challenges for",
    "start": "792360",
    "end": "795600"
  },
  {
    "text": "us it was a few of the teeing pains that",
    "start": "795600",
    "end": "797880"
  },
  {
    "text": "we had because of the decision that we",
    "start": "797880",
    "end": "800120"
  },
  {
    "text": "made that we would migrate the models",
    "start": "800120",
    "end": "802920"
  },
  {
    "text": "before we release the first version of",
    "start": "802920",
    "end": "804600"
  },
  {
    "text": "that platform what that meant for us was",
    "start": "804600",
    "end": "807279"
  },
  {
    "text": "our data science team would experience",
    "start": "807279",
    "end": "810279"
  },
  {
    "text": "very frequent down times so frequent",
    "start": "810279",
    "end": "812320"
  },
  {
    "text": "changes in the platform before even the",
    "start": "812320",
    "end": "814360"
  },
  {
    "text": "first version was released so the",
    "start": "814360",
    "end": "816279"
  },
  {
    "text": "initial few weeks of this migration",
    "start": "816279",
    "end": "817920"
  },
  {
    "text": "exercise had parallel development so the",
    "start": "817920",
    "end": "819920"
  },
  {
    "text": "data science team and the platform team",
    "start": "819920",
    "end": "822399"
  },
  {
    "text": "would work really",
    "start": "822399",
    "end": "824720"
  },
  {
    "text": "close at the same time what that meant",
    "start": "824720",
    "end": "827040"
  },
  {
    "text": "for us is we would we were able to",
    "start": "827040",
    "end": "829079"
  },
  {
    "text": "identify issues early on in this",
    "start": "829079",
    "end": "831519"
  },
  {
    "text": "platform that helped us in hardening the",
    "start": "831519",
    "end": "834160"
  },
  {
    "text": "platform by the time the platform was",
    "start": "834160",
    "end": "837759"
  },
  {
    "text": "released and with the new set of",
    "start": "837759",
    "end": "840199"
  },
  {
    "text": "Technologies we had to work on a",
    "start": "840199",
    "end": "843680"
  },
  {
    "text": "completely new coding Paradigm so what",
    "start": "843680",
    "end": "845639"
  },
  {
    "text": "that meant for us was um uh taking our",
    "start": "845639",
    "end": "849560"
  },
  {
    "text": "data science stream to multiple training",
    "start": "849560",
    "end": "852079"
  },
  {
    "text": "sessions so we had regular catch-ups",
    "start": "852079",
    "end": "854440"
  },
  {
    "text": "with our any scale team and a weights",
    "start": "854440",
    "end": "856199"
  },
  {
    "text": "and bis team and we also had internal",
    "start": "856199",
    "end": "858839"
  },
  {
    "text": "knowledge sharing sessions to upskill",
    "start": "858839",
    "end": "861480"
  },
  {
    "text": "the team member to use the new",
    "start": "861480",
    "end": "865040"
  },
  {
    "text": "platform next I want to share some key",
    "start": "866279",
    "end": "868959"
  },
  {
    "text": "results of the migration exercise that",
    "start": "868959",
    "end": "871440"
  },
  {
    "text": "we did so we migrated a few models so",
    "start": "871440",
    "end": "874040"
  },
  {
    "text": "the first model that we migrated it took",
    "start": "874040",
    "end": "876920"
  },
  {
    "text": "us roughly two",
    "start": "876920",
    "end": "880320"
  },
  {
    "text": "months the training and tuning time",
    "start": "880320",
    "end": "882480"
  },
  {
    "text": "reduction in this first model was around",
    "start": "882480",
    "end": "885040"
  },
  {
    "text": "from 2 hours it got down to 1 and a half",
    "start": "885040",
    "end": "887399"
  },
  {
    "text": "hours the data science team",
    "start": "887399",
    "end": "890040"
  },
  {
    "text": "experienced improved developer",
    "start": "890040",
    "end": "892800"
  },
  {
    "text": "productivity so previously the data",
    "start": "892800",
    "end": "895000"
  },
  {
    "text": "scientists would just use jerub which",
    "start": "895000",
    "end": "897320"
  },
  {
    "text": "was self fored on cubity which was very",
    "start": "897320",
    "end": "900680"
  },
  {
    "text": "clunky now we were using jup Jupiter Hub",
    "start": "900680",
    "end": "904040"
  },
  {
    "text": "that came out of the box from any scale",
    "start": "904040",
    "end": "906680"
  },
  {
    "text": "which was a significant Improvement so",
    "start": "906680",
    "end": "908839"
  },
  {
    "text": "the now data scientists were using any",
    "start": "908839",
    "end": "910519"
  },
  {
    "text": "scale workspaces as part of that they",
    "start": "910519",
    "end": "912600"
  },
  {
    "text": "were also able to use vs code so",
    "start": "912600",
    "end": "916120"
  },
  {
    "text": "previously we had no separate",
    "start": "916120",
    "end": "918000"
  },
  {
    "text": "productivity or an IDE for our data",
    "start": "918000",
    "end": "921399"
  },
  {
    "text": "science team now we had vs code if which",
    "start": "921399",
    "end": "924240"
  },
  {
    "text": "was in two different um uh ways that we",
    "start": "924240",
    "end": "927800"
  },
  {
    "text": "could use one was a browser version one",
    "start": "927800",
    "end": "929319"
  },
  {
    "text": "was a local version so those were",
    "start": "929319",
    "end": "931160"
  },
  {
    "text": "significant Improvement in the new",
    "start": "931160",
    "end": "933079"
  },
  {
    "text": "platform similarly we had improved",
    "start": "933079",
    "end": "935399"
  },
  {
    "text": "logging so like I mentioned before",
    "start": "935399",
    "end": "936959"
  },
  {
    "text": "previously we had to log into cloudwatch",
    "start": "936959",
    "end": "939440"
  },
  {
    "text": "or log into Cube cluster to get the logs",
    "start": "939440",
    "end": "941759"
  },
  {
    "text": "out this time around it was so much",
    "start": "941759",
    "end": "944279"
  },
  {
    "text": "easier and simpler to just see the logs",
    "start": "944279",
    "end": "946560"
  },
  {
    "text": "by logging into any scale workspaces or",
    "start": "946560",
    "end": "949000"
  },
  {
    "text": "by going uh to weights and bies platform",
    "start": "949000",
    "end": "951279"
  },
  {
    "text": "and looking at the logs right over there",
    "start": "951279",
    "end": "953600"
  },
  {
    "text": "similarly in another model migration the",
    "start": "953600",
    "end": "956199"
  },
  {
    "text": "next one which is model B we we",
    "start": "956199",
    "end": "958839"
  },
  {
    "text": "experienced the monthly scoring pipeline",
    "start": "958839",
    "end": "961279"
  },
  {
    "text": "runtime being reduced from 2 and 1/2",
    "start": "961279",
    "end": "963560"
  },
  {
    "text": "hours to 16 minutes which was a",
    "start": "963560",
    "end": "966120"
  },
  {
    "text": "significant Improvement at the same time",
    "start": "966120",
    "end": "969199"
  },
  {
    "text": "what we experienced",
    "start": "969199",
    "end": "970920"
  },
  {
    "text": "was reduce AWS instant cost because the",
    "start": "970920",
    "end": "975759"
  },
  {
    "text": "training Pipeline and the scoring",
    "start": "975759",
    "end": "977399"
  },
  {
    "text": "pipeline were running for lesser time",
    "start": "977399",
    "end": "979440"
  },
  {
    "text": "now what it meant for us we experienced",
    "start": "979440",
    "end": "983240"
  },
  {
    "text": "48% reduction in the use case running",
    "start": "983240",
    "end": "986480"
  },
  {
    "text": "the use case training and scoring",
    "start": "986480",
    "end": "988199"
  },
  {
    "text": "pipeline L at the same time we also",
    "start": "988199",
    "end": "991880"
  },
  {
    "text": "added some cost control measure so in",
    "start": "991880",
    "end": "994240"
  },
  {
    "text": "any scale workspaces you have a way in",
    "start": "994240",
    "end": "996120"
  },
  {
    "text": "which you can set up the maximum number",
    "start": "996120",
    "end": "997839"
  },
  {
    "text": "of workload which you can spin up as",
    "start": "997839",
    "end": "999880"
  },
  {
    "text": "part of the cluster similarly the third",
    "start": "999880",
    "end": "1002839"
  },
  {
    "text": "model that we migrated we saw a",
    "start": "1002839",
    "end": "1006279"
  },
  {
    "text": "massive reduction in the runtime for",
    "start": "1006279",
    "end": "1009120"
  },
  {
    "text": "scoring pipeline from 9 hours to 1 and",
    "start": "1009120",
    "end": "1011000"
  },
  {
    "text": "1/ half",
    "start": "1011000",
    "end": "1011959"
  },
  {
    "text": "hours similarly we also experience AWS",
    "start": "1011959",
    "end": "1016440"
  },
  {
    "text": "cost and any scale cost combined cost of",
    "start": "1016440",
    "end": "1018639"
  },
  {
    "text": "the use case reduced by",
    "start": "1018639",
    "end": "1021720"
  },
  {
    "text": "52% and in this model also we had sent",
    "start": "1021720",
    "end": "1024558"
  },
  {
    "text": "some set some cost control",
    "start": "1024559",
    "end": "1027918"
  },
  {
    "text": "measures in the last section what I want",
    "start": "1028760",
    "end": "1031199"
  },
  {
    "text": "to do is just share one of very specific",
    "start": "1031199",
    "end": "1033880"
  },
  {
    "text": "use case and just demonstrate how we",
    "start": "1033880",
    "end": "1036678"
  },
  {
    "text": "have used Ray remote by just change",
    "start": "1036679",
    "end": "1038520"
  },
  {
    "text": "tweaking a few lines of code and",
    "start": "1038520",
    "end": "1040798"
  },
  {
    "text": "parallelizing our",
    "start": "1040799",
    "end": "1042760"
  },
  {
    "text": "code so what you see on this screen is a",
    "start": "1042760",
    "end": "1045438"
  },
  {
    "text": "code snippet so this is a very standard",
    "start": "1045439",
    "end": "1047240"
  },
  {
    "text": "function for the this use case we were",
    "start": "1047240",
    "end": "1049600"
  },
  {
    "text": "building a k means model and we were",
    "start": "1049600",
    "end": "1052480"
  },
  {
    "text": "scoring uh over this K means model so we",
    "start": "1052480",
    "end": "1055360"
  },
  {
    "text": "would get the project configs we would",
    "start": "1055360",
    "end": "1057559"
  },
  {
    "text": "download the model from weights and bies",
    "start": "1057559",
    "end": "1059799"
  },
  {
    "text": "we'll get the features from a feature",
    "start": "1059799",
    "end": "1061400"
  },
  {
    "text": "store and finally we would call this c",
    "start": "1061400",
    "end": "1063960"
  },
  {
    "text": "means scoring function which will input",
    "start": "1063960",
    "end": "1065960"
  },
  {
    "text": "all this data in and then give the model",
    "start": "1065960",
    "end": "1068360"
  },
  {
    "text": "output the model output will be uploaded",
    "start": "1068360",
    "end": "1070960"
  },
  {
    "text": "back to the database and is was a batch",
    "start": "1070960",
    "end": "1074000"
  },
  {
    "text": "service so previously we had this score",
    "start": "1074000",
    "end": "1078039"
  },
  {
    "text": "function that would be called from the",
    "start": "1078039",
    "end": "1079480"
  },
  {
    "text": "scoring",
    "start": "1079480",
    "end": "1081159"
  },
  {
    "text": "pipeline so how it would work with in",
    "start": "1081159",
    "end": "1084400"
  },
  {
    "text": "the first line it would create the",
    "start": "1084400",
    "end": "1086600"
  },
  {
    "text": "scoring data set and in the second line",
    "start": "1086600",
    "end": "1089120"
  },
  {
    "text": "it would pass this the entire scoring",
    "start": "1089120",
    "end": "1091720"
  },
  {
    "text": "data set and call the cing score upload",
    "start": "1091720",
    "end": "1094880"
  },
  {
    "text": "function",
    "start": "1094880",
    "end": "1097360"
  },
  {
    "text": "once when we replaced this code and",
    "start": "1097919",
    "end": "1100919"
  },
  {
    "text": "started using r. remote we made a very",
    "start": "1100919",
    "end": "1104799"
  },
  {
    "text": "small change in this code so what we did",
    "start": "1104799",
    "end": "1107559"
  },
  {
    "text": "was we removed those two lines of code",
    "start": "1107559",
    "end": "1110400"
  },
  {
    "text": "and replace that with these two lines of",
    "start": "1110400",
    "end": "1112919"
  },
  {
    "text": "code so the changes were we were we had",
    "start": "1112919",
    "end": "1115720"
  },
  {
    "text": "a function called great chunk loader",
    "start": "1115720",
    "end": "1117480"
  },
  {
    "text": "which would just split the entire",
    "start": "1117480",
    "end": "1119200"
  },
  {
    "text": "scoring data set into multiple chunks so",
    "start": "1119200",
    "end": "1122120"
  },
  {
    "text": "in this case it was 14 chunks and then",
    "start": "1122120",
    "end": "1125240"
  },
  {
    "text": "instead of calling the",
    "start": "1125240",
    "end": "1127840"
  },
  {
    "text": "function one time we would call the",
    "start": "1127840",
    "end": "1130360"
  },
  {
    "text": "function 14 times by going over all the",
    "start": "1130360",
    "end": "1133280"
  },
  {
    "text": "chunks that were individually created",
    "start": "1133280",
    "end": "1135600"
  },
  {
    "text": "and we were using R.G and remote",
    "start": "1135600",
    "end": "1138360"
  },
  {
    "text": "function and would passing these chunks",
    "start": "1138360",
    "end": "1140280"
  },
  {
    "text": "instead of passing the entire data set",
    "start": "1140280",
    "end": "1142640"
  },
  {
    "text": "we also made one minor change was we",
    "start": "1142640",
    "end": "1145120"
  },
  {
    "text": "added this decorative r. remote to the",
    "start": "1145120",
    "end": "1148400"
  },
  {
    "text": "called",
    "start": "1148400",
    "end": "1150679"
  },
  {
    "text": "function so next thing I want to show is",
    "start": "1152640",
    "end": "1155720"
  },
  {
    "text": "how it look like from the grafana",
    "start": "1155720",
    "end": "1157240"
  },
  {
    "text": "dashboard so this is the grafana",
    "start": "1157240",
    "end": "1159919"
  },
  {
    "text": "dashboard screen um snippet that comes",
    "start": "1159919",
    "end": "1164000"
  },
  {
    "text": "out of the box with any scale so what",
    "start": "1164000",
    "end": "1165559"
  },
  {
    "text": "you see on the screen right now is that",
    "start": "1165559",
    "end": "1167400"
  },
  {
    "text": "first 5 minutes of of the running the",
    "start": "1167400",
    "end": "1168919"
  },
  {
    "text": "code uh that I just showed so as you can",
    "start": "1168919",
    "end": "1172520"
  },
  {
    "text": "see on the screen uh in the",
    "start": "1172520",
    "end": "1175520"
  },
  {
    "text": "red the number of tasks quickly gets",
    "start": "1175520",
    "end": "1178320"
  },
  {
    "text": "spun up and from zero it goes to",
    "start": "1178320",
    "end": "1180840"
  },
  {
    "text": "14 so does the active number of task on",
    "start": "1180840",
    "end": "1183760"
  },
  {
    "text": "the right side which you see see in",
    "start": "1183760",
    "end": "1187159"
  },
  {
    "text": "green after approximately 10 minutes of",
    "start": "1187159",
    "end": "1190200"
  },
  {
    "text": "running the code the screen would look",
    "start": "1190200",
    "end": "1192760"
  },
  {
    "text": "like what you see at the bottom so as",
    "start": "1192760",
    "end": "1195120"
  },
  {
    "text": "the task would finish you would see that",
    "start": "1195120",
    "end": "1197360"
  },
  {
    "text": "tapering over time time so the task",
    "start": "1197360",
    "end": "1199200"
  },
  {
    "text": "would finish and eventually around in 15",
    "start": "1199200",
    "end": "1201679"
  },
  {
    "text": "minutes the whole pipeline would run",
    "start": "1201679",
    "end": "1204960"
  },
  {
    "text": "another way to look at it is using array",
    "start": "1204960",
    "end": "1207280"
  },
  {
    "text": "dashboard so the first row that you see",
    "start": "1207280",
    "end": "1209440"
  },
  {
    "text": "on the screen is the head node and all",
    "start": "1209440",
    "end": "1211919"
  },
  {
    "text": "the rows that you see at the bottom are",
    "start": "1211919",
    "end": "1213679"
  },
  {
    "text": "those individual functions that were",
    "start": "1213679",
    "end": "1216280"
  },
  {
    "text": "called which are like separate tasks",
    "start": "1216280",
    "end": "1218360"
  },
  {
    "text": "that are created by Ray",
    "start": "1218360",
    "end": "1221600"
  },
  {
    "text": "parall to process all the data in the",
    "start": "1221600",
    "end": "1224360"
  },
  {
    "text": "scoring",
    "start": "1224360",
    "end": "1226200"
  },
  {
    "text": "pipeline so let's have a look at the",
    "start": "1226200",
    "end": "1229000"
  },
  {
    "text": "results",
    "start": "1229000",
    "end": "1231480"
  },
  {
    "text": "now so the scoring pipeline for use case",
    "start": "1231640",
    "end": "1234799"
  },
  {
    "text": "a without using three took us 2 and 1",
    "start": "1234799",
    "end": "1237960"
  },
  {
    "text": "half hours when it would ingest",
    "start": "1237960",
    "end": "1239960"
  },
  {
    "text": "approximately 13.2 million",
    "start": "1239960",
    "end": "1242600"
  },
  {
    "text": "rows after making the code",
    "start": "1242600",
    "end": "1245159"
  },
  {
    "text": "changes and implementing r.",
    "start": "1245159",
    "end": "1249000"
  },
  {
    "text": "remote it took us around 16 minutes to",
    "start": "1249000",
    "end": "1253120"
  },
  {
    "text": "in just exactly the same amount of data",
    "start": "1253120",
    "end": "1255840"
  },
  {
    "text": "with using",
    "start": "1255840",
    "end": "1257120"
  },
  {
    "text": "Gray so the efficiency Improvement that",
    "start": "1257120",
    "end": "1260400"
  },
  {
    "text": "we observed with this particular use",
    "start": "1260400",
    "end": "1262440"
  },
  {
    "text": "case was over 90% which is",
    "start": "1262440",
    "end": "1267360"
  },
  {
    "text": "amazing",
    "start": "1268960",
    "end": "1270679"
  },
  {
    "text": "finally a few key",
    "start": "1270679",
    "end": "1274679"
  },
  {
    "text": "takeaways N scale has stabilized our",
    "start": "1274919",
    "end": "1277559"
  },
  {
    "text": "platform it has added numerous features",
    "start": "1277559",
    "end": "1279919"
  },
  {
    "text": "for data science team weights and bues",
    "start": "1279919",
    "end": "1283120"
  },
  {
    "text": "has boosted our data science teams",
    "start": "1283120",
    "end": "1285000"
  },
  {
    "text": "productivity to a large extent and",
    "start": "1285000",
    "end": "1287640"
  },
  {
    "text": "access to Distributing Computing has",
    "start": "1287640",
    "end": "1289799"
  },
  {
    "text": "provided ability to service more complex",
    "start": "1289799",
    "end": "1292159"
  },
  {
    "text": "requirement for us so we are able to",
    "start": "1292159",
    "end": "1294919"
  },
  {
    "text": "work on new use cases which were not",
    "start": "1294919",
    "end": "1297000"
  },
  {
    "text": "possible before for",
    "start": "1297000",
    "end": "1299000"
  },
  {
    "text": "us so what's next for one digital",
    "start": "1299000",
    "end": "1302080"
  },
  {
    "text": "machine learning platform we want to",
    "start": "1302080",
    "end": "1304000"
  },
  {
    "text": "continue using and exploring rate tune",
    "start": "1304000",
    "end": "1307880"
  },
  {
    "text": "Library what we want to do next uh is",
    "start": "1307880",
    "end": "1311880"
  },
  {
    "text": "explore automl as part of the L Ludwig",
    "start": "1311880",
    "end": "1315159"
  },
  {
    "text": "integration uh that any scale provides",
    "start": "1315159",
    "end": "1318600"
  },
  {
    "text": "we also have res serve integration in",
    "start": "1318600",
    "end": "1321120"
  },
  {
    "text": "our road",
    "start": "1321120",
    "end": "1322720"
  },
  {
    "text": "map we explored a bit of the llm",
    "start": "1322720",
    "end": "1327039"
  },
  {
    "text": "technology that any scale provides so we",
    "start": "1327039",
    "end": "1329200"
  },
  {
    "text": "had a mini hackathon recently in the",
    "start": "1329200",
    "end": "1331799"
  },
  {
    "text": "last one month in which we were able to",
    "start": "1331799",
    "end": "1334080"
  },
  {
    "text": "test the stable diffusion model that any",
    "start": "1334080",
    "end": "1337960"
  },
  {
    "text": "scale provides so now we are looking",
    "start": "1337960",
    "end": "1340159"
  },
  {
    "text": "forward to exploring any scale private",
    "start": "1340159",
    "end": "1343600"
  },
  {
    "text": "endpoints and any scale finetune API",
    "start": "1343600",
    "end": "1346320"
  },
  {
    "text": "which was released and announced earlier",
    "start": "1346320",
    "end": "1348480"
  },
  {
    "text": "today and lastly we also want to explore",
    "start": "1348480",
    "end": "1352400"
  },
  {
    "text": "model registry of weights and",
    "start": "1352400",
    "end": "1355679"
  },
  {
    "text": "biases so that's it that's the end of my",
    "start": "1355679",
    "end": "1359440"
  },
  {
    "text": "talk thank",
    "start": "1359440",
    "end": "1361060"
  },
  {
    "text": "[Applause]",
    "start": "1361060",
    "end": "1367240"
  },
  {
    "text": "you yes can you talk a little bit about",
    "start": "1367360",
    "end": "1371159"
  },
  {
    "text": "oh sorry can you talk a little bit more",
    "start": "1371159",
    "end": "1373760"
  },
  {
    "text": "about weights and biases and like just",
    "start": "1373760",
    "end": "1376679"
  },
  {
    "text": "like I guess guess just at a more",
    "start": "1376679",
    "end": "1379760"
  },
  {
    "text": "conceptual level like how it I guess how",
    "start": "1379760",
    "end": "1382919"
  },
  {
    "text": "it influences your ml Pipeline and stuff",
    "start": "1382919",
    "end": "1386279"
  },
  {
    "text": "like that and how you guys tune things",
    "start": "1386279",
    "end": "1388360"
  },
  {
    "text": "with it",
    "start": "1388360",
    "end": "1391279"
  },
  {
    "text": "yeah um so the question is to explain a",
    "start": "1391279",
    "end": "1394960"
  },
  {
    "text": "little more about weights and biases on",
    "start": "1394960",
    "end": "1396880"
  },
  {
    "text": "a conceptual level and how we have",
    "start": "1396880",
    "end": "1398480"
  },
  {
    "text": "integrated and using it so what we have",
    "start": "1398480",
    "end": "1400840"
  },
  {
    "text": "seen is uh since we have replaced ml",
    "start": "1400840",
    "end": "1402880"
  },
  {
    "text": "flow with weight and biases and the",
    "start": "1402880",
    "end": "1404760"
  },
  {
    "text": "version of the ml flow that we were",
    "start": "1404760",
    "end": "1406080"
  },
  {
    "text": "using were actually open source so it",
    "start": "1406080",
    "end": "1408400"
  },
  {
    "text": "limited features now we see with b and",
    "start": "1408400",
    "end": "1411440"
  },
  {
    "text": "buses it has really boosted our data",
    "start": "1411440",
    "end": "1414360"
  },
  {
    "text": "science team's productivity so at",
    "start": "1414360",
    "end": "1416679"
  },
  {
    "text": "conceptual level what we have done is we",
    "start": "1416679",
    "end": "1418760"
  },
  {
    "text": "are using that in our pipeline for our",
    "start": "1418760",
    "end": "1420919"
  },
  {
    "text": "model storage solution so every training",
    "start": "1420919",
    "end": "1423640"
  },
  {
    "text": "pipeline completes by pushing the train",
    "start": "1423640",
    "end": "1425880"
  },
  {
    "text": "model to weights and bias storage it",
    "start": "1425880",
    "end": "1428480"
  },
  {
    "text": "takes care of the",
    "start": "1428480",
    "end": "1429720"
  },
  {
    "text": "versioning uh it takes care of for",
    "start": "1429720",
    "end": "1432559"
  },
  {
    "text": "multiple models that we may want to",
    "start": "1432559",
    "end": "1434520"
  },
  {
    "text": "deploy using the same use case uh it",
    "start": "1434520",
    "end": "1437559"
  },
  {
    "text": "also Al helps us to download the model",
    "start": "1437559",
    "end": "1441240"
  },
  {
    "text": "with each scoring pipeline that it",
    "start": "1441240",
    "end": "1443520"
  },
  {
    "text": "starts um so that's how we have",
    "start": "1443520",
    "end": "1445919"
  },
  {
    "text": "basically using uh we've been using",
    "start": "1445919",
    "end": "1448240"
  },
  {
    "text": "weights and bies but at the same time",
    "start": "1448240",
    "end": "1450000"
  },
  {
    "text": "there are so many other features of",
    "start": "1450000",
    "end": "1451240"
  },
  {
    "text": "weight and bies that we use so this",
    "start": "1451240",
    "end": "1453679"
  },
  {
    "text": "feature called we and bases reports with",
    "start": "1453679",
    "end": "1455520"
  },
  {
    "text": "the data science team is now using to",
    "start": "1455520",
    "end": "1457760"
  },
  {
    "text": "have better conversation with the",
    "start": "1457760",
    "end": "1459600"
  },
  {
    "text": "stakeholders so um you can pull in all",
    "start": "1459600",
    "end": "1462240"
  },
  {
    "text": "the metrics for a particular use case",
    "start": "1462240",
    "end": "1463799"
  },
  {
    "text": "whether it's in production or it's an ad",
    "start": "1463799",
    "end": "1465480"
  },
  {
    "text": "hoc experimentation and then you can",
    "start": "1465480",
    "end": "1467440"
  },
  {
    "text": "quickly create a report uh and you can",
    "start": "1467440",
    "end": "1470279"
  },
  {
    "text": "automatically push in all your metrics",
    "start": "1470279",
    "end": "1472440"
  },
  {
    "text": "charts that you have and share that with",
    "start": "1472440",
    "end": "1475159"
  },
  {
    "text": "your stakeholders um we are also using W",
    "start": "1475159",
    "end": "1478279"
  },
  {
    "text": "and biases model metric throughout the",
    "start": "1478279",
    "end": "1480880"
  },
  {
    "text": "training and scoring process so we and",
    "start": "1480880",
    "end": "1483559"
  },
  {
    "text": "basis API are really intuitive and easy",
    "start": "1483559",
    "end": "1485559"
  },
  {
    "text": "to use and we write the code using those",
    "start": "1485559",
    "end": "1488320"
  },
  {
    "text": "apis and the data scientists they don't",
    "start": "1488320",
    "end": "1491120"
  },
  {
    "text": "have to do a lot of um work uh to make",
    "start": "1491120",
    "end": "1495440"
  },
  {
    "text": "this work all they have to do is use",
    "start": "1495440",
    "end": "1497480"
  },
  {
    "text": "those API that uh quickly propagates all",
    "start": "1497480",
    "end": "1500080"
  },
  {
    "text": "the values while running the model uh to",
    "start": "1500080",
    "end": "1502919"
  },
  {
    "text": "weights and bi it gets stored easily and",
    "start": "1502919",
    "end": "1504880"
  },
  {
    "text": "you can pull off that data anytime that",
    "start": "1504880",
    "end": "1506480"
  },
  {
    "text": "you want for experiment",
    "start": "1506480",
    "end": "1509799"
  },
  {
    "text": "tracking hey uh when you think of like",
    "start": "1514320",
    "end": "1518520"
  },
  {
    "text": "Ray",
    "start": "1518520",
    "end": "1519360"
  },
  {
    "text": "internally and you think of the theme",
    "start": "1519360",
    "end": "1521520"
  },
  {
    "text": "Ray brings to the table and when someone",
    "start": "1521520",
    "end": "1523960"
  },
  {
    "text": "asks you internally is it is it scale is",
    "start": "1523960",
    "end": "1526080"
  },
  {
    "text": "it performance is it ease use is it",
    "start": "1526080",
    "end": "1528320"
  },
  {
    "text": "flexibility like what's like the main",
    "start": "1528320",
    "end": "1530240"
  },
  {
    "text": "theme I know all them kind of apply to",
    "start": "1530240",
    "end": "1532360"
  },
  {
    "text": "your use case but like what's like the",
    "start": "1532360",
    "end": "1533760"
  },
  {
    "text": "main theme that sticks out for like",
    "start": "1533760",
    "end": "1535279"
  },
  {
    "text": "everyone internally given your",
    "start": "1535279",
    "end": "1537480"
  },
  {
    "text": "experience so",
    "start": "1537480",
    "end": "1539559"
  },
  {
    "text": "far um so the question is in the ray",
    "start": "1539559",
    "end": "1542279"
  },
  {
    "text": "earning what exactly is like is the",
    "start": "1542279",
    "end": "1544919"
  },
  {
    "text": "scale is it deficiency yeah I guess what",
    "start": "1544919",
    "end": "1546960"
  },
  {
    "text": "what stands what stands out the most to",
    "start": "1546960",
    "end": "1549200"
  },
  {
    "text": "like you and maybe the team is it the",
    "start": "1549200",
    "end": "1550679"
  },
  {
    "text": "flexibility of Ray is it the scale is",
    "start": "1550679",
    "end": "1552840"
  },
  {
    "text": "the performance is it the cost Savings",
    "start": "1552840",
    "end": "1554520"
  },
  {
    "text": "of what Ray brings to the table I'm just",
    "start": "1554520",
    "end": "1556000"
  },
  {
    "text": "curious like which which one one like is",
    "start": "1556000",
    "end": "1558240"
  },
  {
    "text": "the most important what's the one thing",
    "start": "1558240",
    "end": "1561520"
  },
  {
    "text": "um so for us uh I would say if I had to",
    "start": "1561520",
    "end": "1565279"
  },
  {
    "text": "choose one thing it's actually",
    "start": "1565279",
    "end": "1567080"
  },
  {
    "text": "enablement so scale yes but we don't we",
    "start": "1567080",
    "end": "1570640"
  },
  {
    "text": "are not at that level of scale with the",
    "start": "1570640",
    "end": "1572520"
  },
  {
    "text": "scale is the only problem that we have",
    "start": "1572520",
    "end": "1574120"
  },
  {
    "text": "got but rather it's enablement so when",
    "start": "1574120",
    "end": "1576840"
  },
  {
    "text": "we started using R in any",
    "start": "1576840",
    "end": "1578960"
  },
  {
    "text": "scale um we got access to a lot of",
    "start": "1578960",
    "end": "1581840"
  },
  {
    "text": "things that our data scientists were",
    "start": "1581840",
    "end": "1583480"
  },
  {
    "text": "never able to do uh which just included",
    "start": "1583480",
    "end": "1586360"
  },
  {
    "text": "all these features that comes out the",
    "start": "1586360",
    "end": "1587880"
  },
  {
    "text": "box of any scale so um uh you know",
    "start": "1587880",
    "end": "1591000"
  },
  {
    "text": "spinning up jupter hub using workspaces",
    "start": "1591000",
    "end": "1593880"
  },
  {
    "text": "creating production jobs easily so all",
    "start": "1593880",
    "end": "1596399"
  },
  {
    "text": "these numerous standard features of any",
    "start": "1596399",
    "end": "1598799"
  },
  {
    "text": "scale and Ray and yes um an extension to",
    "start": "1598799",
    "end": "1602120"
  },
  {
    "text": "that would be distributed computing so",
    "start": "1602120",
    "end": "1603760"
  },
  {
    "text": "we never had access to a good",
    "start": "1603760",
    "end": "1605720"
  },
  {
    "text": "distributed computing solution which we",
    "start": "1605720",
    "end": "1608279"
  },
  {
    "text": "now do because of ray. remote and then",
    "start": "1608279",
    "end": "1611039"
  },
  {
    "text": "there's this whole Suite of apis that",
    "start": "1611039",
    "end": "1614360"
  },
  {
    "text": "that is under Ray air and we are really",
    "start": "1614360",
    "end": "1616159"
  },
  {
    "text": "excited to use that in the future as",
    "start": "1616159",
    "end": "1619840"
  },
  {
    "text": "well guess that's it thank you everyone",
    "start": "1622480",
    "end": "1627039"
  },
  {
    "text": "yes",
    "start": "1629399",
    "end": "1632399"
  }
]
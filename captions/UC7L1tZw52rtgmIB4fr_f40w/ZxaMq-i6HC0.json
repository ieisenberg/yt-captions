[
  {
    "text": "I'll update that but I am the same person uh and I'm psych to be presenting here and talking about model training",
    "start": "399",
    "end": "6520"
  },
  {
    "text": "with pytorch in any scales so before I even get into the schedule of what we'll be doing today uh I want to give a",
    "start": "6520",
    "end": "12840"
  },
  {
    "text": "really really high level of what is Ray what is any scale because I understand there may be people who have you know",
    "start": "12840",
    "end": "19160"
  },
  {
    "text": "never heard of these tools but thought oh well maybe I'll check this out or maybe you've heard of these uh or maybe",
    "start": "19160",
    "end": "24519"
  },
  {
    "text": "even looked at them in the past but you're not sure where things have gotten to here in 2024",
    "start": "24519",
    "end": "30359"
  },
  {
    "text": "or just uh want to get a little bit more orientation so before we go anywhere else what is Reay Ray is an open source",
    "start": "30359",
    "end": "36879"
  },
  {
    "text": "project which represents the simplest fastest way to build and deploy scalable computation you can do all kinds of",
    "start": "36879",
    "end": "43680"
  },
  {
    "text": "scalable computation with Ray uh we're going to be focusing today on uh AI model training and in general these days",
    "start": "43680",
    "end": "51640"
  },
  {
    "text": "we're focusing on any scale as a as a firm is focusing on customers that are interested in life cycle for AI",
    "start": "51640",
    "end": "58519"
  },
  {
    "text": "applications so data process for AI you know things like um featurization vectorization ingestion pre-processing",
    "start": "58519",
    "end": "66640"
  },
  {
    "text": "uh model training itself um so probably the most famous um uh model in the world",
    "start": "66640",
    "end": "73720"
  },
  {
    "text": "that's been trained with Ray is um gpt3 GPT 4 so uh if you are at Ray Summit uh",
    "start": "73720",
    "end": "81680"
  },
  {
    "text": "a year or two back you may uh remember hearing about how open AI uses Ray to",
    "start": "81680",
    "end": "86880"
  },
  {
    "text": "train their biggest language models uh of course you can also use Ray for lots of smaller things that you know are not",
    "start": "86880",
    "end": "94000"
  },
  {
    "text": "at that same scale uh and then model serving so that's what we're focused on for the most part today but you can do",
    "start": "94000",
    "end": "100000"
  },
  {
    "text": "all kinds of scalable compute with Ray uh where does any scale fit into the picture so Ray is open source uh any",
    "start": "100000",
    "end": "106680"
  },
  {
    "text": "scale we'll talk more about any scale in just a minute but at a high level uh is an organization um created by the um",
    "start": "106680",
    "end": "113240"
  },
  {
    "text": "founded by the creators of Ray and it's all about extending Ray uh in a number of Dimensions so uh even better",
    "start": "113240",
    "end": "120200"
  },
  {
    "text": "performance uh we think Ray is actually really really highly performing by itself but it's nice to have some um",
    "start": "120200",
    "end": "126439"
  },
  {
    "text": "funding that can go towards R&D towards really really pushing the limits uh adding more functionality right just",
    "start": "126439",
    "end": "132160"
  },
  {
    "text": "making making uh the framework able to do more things uh usability making it easier to do stuff uh and then",
    "start": "132160",
    "end": "138840"
  },
  {
    "text": "operations best practices so all of those things that you need to do in between using a great open source",
    "start": "138840",
    "end": "144920"
  },
  {
    "text": "library and deploying something in production uh in an Enterprise uh if you've been doing this for while you",
    "start": "144920",
    "end": "150280"
  },
  {
    "text": "know that there's a lot of complexity in between those things right the um if if",
    "start": "150280",
    "end": "155760"
  },
  {
    "text": "we could just go from an open source library to putting stuff in production and have it work that would be a nice world but in reality it's a little more",
    "start": "155760",
    "end": "162360"
  },
  {
    "text": "complex and so we need some more infrastructure there and so all of those areas are places where any scale is",
    "start": "162360",
    "end": "168000"
  },
  {
    "text": "adding a ton on top of Ray I also want to make sure that I mentioned Ray Summit",
    "start": "168000",
    "end": "173720"
  },
  {
    "text": "in San Francisco this fall uh September 30th to October 2 uh if you want to learn more about Ray more about any",
    "start": "173720",
    "end": "180080"
  },
  {
    "text": "scale if you want to meet the team uh if you want to see all kinds of companies from around the world that are using the platform to do interesting things uh",
    "start": "180080",
    "end": "187360"
  },
  {
    "text": "that would be a place to uh check out and I think those tickets are already on sale uh okay so uh with that really",
    "start": "187360",
    "end": "194879"
  },
  {
    "text": "quick kind of intro uh let's talk a little more about what we're doing here in this tutorial today and a little more",
    "start": "194879",
    "end": "201480"
  },
  {
    "text": "about um any scale and then we'll get into some code uh so the the virtual AI",
    "start": "201480",
    "end": "206760"
  },
  {
    "text": "tutorial format is basically you know webinar format we've got about one hour together here today I'm going to be",
    "start": "206760",
    "end": "212879"
  },
  {
    "text": "demonstrating um you know running actual code so the code I'm running will be in Jupiter lab notebooks so not slides and",
    "start": "212879",
    "end": "219840"
  },
  {
    "text": "I'll be actually running it live on array cluster on any scale um you can try this workload yourself not kind of",
    "start": "219840",
    "end": "227519"
  },
  {
    "text": "synchronously as I do it unless you're already set up but you can um you know definitely do it on your own because",
    "start": "227519",
    "end": "233120"
  },
  {
    "text": "we've got a selfservice uh version of any scale you can sign up for directly today uh and",
    "start": "233120",
    "end": "239480"
  },
  {
    "text": "start using it right away without a credit card or anything uh there's some compute credits built in there uh so if",
    "start": "239480",
    "end": "245120"
  },
  {
    "text": "it's interesting you can start um running uh code like this um and testing",
    "start": "245120",
    "end": "250319"
  },
  {
    "text": "stuff out uh you know right away so 100% runnable code uh we're going to look today at some model training workloads",
    "start": "250319",
    "end": "257600"
  },
  {
    "text": "and then maybe in other sessions we'll look at some other ones uh and in some sessions we'll talk about fundamentals",
    "start": "257600",
    "end": "263560"
  },
  {
    "text": "of scalable compute for AI so that'll come in from time to time but I don't want to get too academic on that stuff",
    "start": "263560",
    "end": "270000"
  },
  {
    "text": "uh and then live Q&A so any kind of uh questions um so it looks like uh",
    "start": "270000",
    "end": "276600"
  },
  {
    "text": "somebody has their hand raised and for this kind of a format because we're a little tight on time uh I would say just",
    "start": "276600",
    "end": "282199"
  },
  {
    "text": "go ahead and put uh questions into the uh Q&A and we'll kind of address those",
    "start": "282199",
    "end": "288720"
  },
  {
    "text": "there um just because with a lot of people on and kind of a lot of stuff that we want to look at we necessarily",
    "start": "288720",
    "end": "294560"
  },
  {
    "text": "be able to do as much uh synchronous interaction so",
    "start": "294560",
    "end": "300080"
  },
  {
    "text": "all right uh so uh the agenda here so we'll talk a little bit about Ray a little bit about any scale we'll try and",
    "start": "300080",
    "end": "306520"
  },
  {
    "text": "keep that to like the next 10 minutes or so like not too much time then we're going to get down into some actual codes",
    "start": "306520",
    "end": "313440"
  },
  {
    "text": "So today we're going to focus on Ray train uh which if that doesn't mean anything to you it will I promise it'll",
    "start": "313440",
    "end": "319560"
  },
  {
    "text": "mean something to you in about five minutes um but it is a library that is part of the ray ecosystem and it's",
    "start": "319560",
    "end": "325400"
  },
  {
    "text": "focused like it sounds on model training so we're going to look at two actual examples with that one uh training a a a",
    "start": "325400",
    "end": "333199"
  },
  {
    "text": "kind of a simple deep learning model but doing it with pie torch lightning so kind of looking at what is the same as",
    "start": "333199",
    "end": "339880"
  },
  {
    "text": "your regular pytorch lightning workflow and then what has to change um in order",
    "start": "339880",
    "end": "345280"
  },
  {
    "text": "to uh run this stuff with Ray uh and then we'll look at another example with just straight pie torch uh so I would",
    "start": "345280",
    "end": "351919"
  },
  {
    "text": "say these days most people that are doing stuff with pytorch or doing it with lightning for for various reasons",
    "start": "351919",
    "end": "357479"
  },
  {
    "text": "or you maybe even something higher level like more abstract like hugging face um but sometimes to get a good",
    "start": "357479",
    "end": "363560"
  },
  {
    "text": "understanding of what's going on uh it's also handy to get kind of a little bit closer to what's going on underneath the",
    "start": "363560",
    "end": "370560"
  },
  {
    "text": "hood uh so doing an example with just pure pie torch so you can see that there's no magic there and we'll also",
    "start": "370560",
    "end": "376400"
  },
  {
    "text": "introduce into that example a little bit of a library called Ray data um and like",
    "start": "376400",
    "end": "381759"
  },
  {
    "text": "it sounds Ray data is about data ingestion and processing we'll talk more about that uh in a couple of",
    "start": "381759",
    "end": "388440"
  },
  {
    "text": "minutes um um so I see there are a couple of great questions about one about training one about Ray Summit so",
    "start": "388440",
    "end": "394160"
  },
  {
    "text": "we'll definitely Circle back on those I'm going to hold most of the questions till till the end so you can see there's",
    "start": "394160",
    "end": "399199"
  },
  {
    "text": "a little entry on the agenda for Q&A so we'll definitely get to that um so what",
    "start": "399199",
    "end": "404479"
  },
  {
    "text": "is Reay I said something earlier about Ray being an easy and fast uh platform",
    "start": "404479",
    "end": "409960"
  },
  {
    "text": "for doing distributed computation so that's kind of like the one level uh sort of oneline elevator pitch kind of",
    "start": "409960",
    "end": "416800"
  },
  {
    "text": "uh description uh here's a little bit more information so we can separate the ray platform at first into a couple",
    "start": "416800",
    "end": "423840"
  },
  {
    "text": "layers there's kind of a bottom layer which is sometimes called Ray core and in the picture on the right hand side of",
    "start": "423840",
    "end": "430199"
  },
  {
    "text": "this slide uh you can see that there is a kind of a blue box called Ray cor so",
    "start": "430199",
    "end": "435280"
  },
  {
    "text": "Raye was the original kind of Kernel or central part of the open source project it was built out um by a graduate team",
    "start": "435280",
    "end": "442120"
  },
  {
    "text": "at UC Berkeley uh starting several years ago and the idea for Ray core is to",
    "start": "442120",
    "end": "447599"
  },
  {
    "text": "create a really high performance uh but simple infrastructure for doing scale",
    "start": "447599",
    "end": "453080"
  },
  {
    "text": "out distributed computation um if you've been in the industry for a while you may think wait a second I think I've heard",
    "start": "453080",
    "end": "458520"
  },
  {
    "text": "the story before aren't there lots of these Frameworks for doing high performance distributed computation uh",
    "start": "458520",
    "end": "464080"
  },
  {
    "text": "and the answer is yes uh and what makes Ray core interesting is that it's designed to be more flexible than some",
    "start": "464080",
    "end": "470159"
  },
  {
    "text": "of those other ones so it basically can do any kind of a program not just certain specific patterns uh and it's",
    "start": "470159",
    "end": "476039"
  },
  {
    "text": "designed to accommodate uh certain requirements like stateful actors uh and things that some of the other platforms",
    "start": "476039",
    "end": "482800"
  },
  {
    "text": "uh were not designed uh to handle uh it's also designed from the beginning to support heterogeneous Hardware so the",
    "start": "482800",
    "end": "488840"
  },
  {
    "text": "folks working on this had some pretty good uh intuition that uh sooner or later we'd all be using CPUs gpus tpus",
    "start": "488840",
    "end": "497000"
  },
  {
    "text": "ipus you know different kinds of processors that were not the same hardware and so we would need a way to",
    "start": "497000",
    "end": "503479"
  },
  {
    "text": "build systems that didn't assume you had a symmetric cluster right so a lot of Frameworks assume that every piece of",
    "start": "503479",
    "end": "509560"
  },
  {
    "text": "your cluster has the same hardware and configuration and everything works but as soon as that's not true things get",
    "start": "509560",
    "end": "514880"
  },
  {
    "text": "really complicated uh Ray was designed from the beginning to uh support heterogeneous hardware and uh",
    "start": "514880",
    "end": "520919"
  },
  {
    "text": "specifically these days things like gpus that turns out to have been a really good uh design decision uh above the ray",
    "start": "520919",
    "end": "527880"
  },
  {
    "text": "core there's another layer uh that's this teal colored box in the picture on the right hand side of the slide that",
    "start": "527880",
    "end": "534600"
  },
  {
    "text": "says Ray AI libraries so this is a collection of higher level AP apis uh for simplifying",
    "start": "534600",
    "end": "541760"
  },
  {
    "text": "common use cases so Ray core you can do anything with but um you know it might",
    "start": "541760",
    "end": "546839"
  },
  {
    "text": "take a lot of work uh because uh it's a very simple set of um uh computation",
    "start": "546839",
    "end": "552480"
  },
  {
    "text": "Primitives if you just want to do something like grab a chunk of data off disk and train a model with it you don't",
    "start": "552480",
    "end": "558519"
  },
  {
    "text": "want to have to reinvent that wheel from low-level Ray cor code you want to be able to do this in a few lines just like",
    "start": "558519",
    "end": "564360"
  },
  {
    "text": "you're used to doing with things like uh torch lightning or before that things",
    "start": "564360",
    "end": "569440"
  },
  {
    "text": "like scit learn uh so Ray AI libraries gives you a high level API so literally",
    "start": "569440",
    "end": "574959"
  },
  {
    "text": "in a lot of cases just a few lines of code for common use cases like ingesting data transforming data um training a",
    "start": "574959",
    "end": "582519"
  },
  {
    "text": "model um and the idea is that they are implemented internally using all of the",
    "start": "582519",
    "end": "587600"
  },
  {
    "text": "ray cor best practices to give you the best scaling and performance uh the four",
    "start": "587600",
    "end": "592839"
  },
  {
    "text": "that are listed in the picture on the right here Ray data uh for data processing Ray train for training models",
    "start": "592839",
    "end": "599160"
  },
  {
    "text": "uh Ray tune for hyper pram optimization and Ray serve for serving",
    "start": "599160",
    "end": "604480"
  },
  {
    "text": "models there's also a couple of other libraries like RL lib you might have heard about uh for doing reinforcement",
    "start": "604480",
    "end": "610600"
  },
  {
    "text": "learning but the four main ones are on this picture",
    "start": "610600",
    "end": "615440"
  },
  {
    "text": "here uh okay so why would we be interested in Ray I think I've talked about that a little bit already right so",
    "start": "617519",
    "end": "623079"
  },
  {
    "text": "Ray strengths uh seem to align really really well with exactly what we need for uh high performance training",
    "start": "623079",
    "end": "629800"
  },
  {
    "text": "inference and and data proc for large AI models uh and it's interesting because that was not exactly the original idea",
    "start": "629800",
    "end": "637800"
  },
  {
    "text": "um you know six seven years ago when the team first created Ray core they just thought well it would be really great to build something kind of super scalable",
    "start": "637800",
    "end": "645160"
  },
  {
    "text": "uh super high performance that handles all these features and it turns out that as the industry evolved um towards the",
    "start": "645160",
    "end": "651240"
  },
  {
    "text": "kind of AI models we're working on today that that's a really really good fit uh so it's kind of being uh you know a",
    "start": "651240",
    "end": "656560"
  },
  {
    "text": "little bit of luck of being in the right place at the at the right time with these uh capabilities in engineering uh",
    "start": "656560",
    "end": "662279"
  },
  {
    "text": "over on the right so why any scale so if Ray is so great why do we need something else why don't we just download Ray",
    "start": "662279",
    "end": "668720"
  },
  {
    "text": "which you can do you can just do a um pip install Ray and and get ray completely for free and run it locally",
    "start": "668720",
    "end": "674800"
  },
  {
    "text": "on your own laptop uh it runs great on even a single machine as well as on on big clusters um and and the thing is",
    "start": "674800",
    "end": "681440"
  },
  {
    "text": "this Ray is great open source software it does lots of cool stuff um but it's",
    "start": "681440",
    "end": "686600"
  },
  {
    "text": "focused more on performance and simplic and capabilities so being able to do",
    "start": "686600",
    "end": "691959"
  },
  {
    "text": "things uh you know from the point of view of like AI engineering um and um",
    "start": "691959",
    "end": "698079"
  },
  {
    "text": "you know AI training but not necessarily from the point of view of Enterprise infrastructure so once we've got this",
    "start": "698079",
    "end": "704440"
  },
  {
    "text": "cool project running on our local cluster or on our uh you know on our kind of private Amazon cluster wherever",
    "start": "704440",
    "end": "710120"
  },
  {
    "text": "we happen to be running it and we convince our bosses that hey this is actually the solution we want we want to go put this thing into production and",
    "start": "710120",
    "end": "716240"
  },
  {
    "text": "run it on like you know at at scale where the whole business depends on it there's just other stuff that we need",
    "start": "716240",
    "end": "721920"
  },
  {
    "text": "that lives outside of the core Ray Library so you know all of that operation stuff um and that's where any",
    "start": "721920",
    "end": "727920"
  },
  {
    "text": "scale fits in so we'll talk a little bit more about what is in any scale um uh I",
    "start": "727920",
    "end": "733839"
  },
  {
    "text": "kind of think about it as four layers I don't know if that's kind of the official way to break down the platform but it makes it you know I come from a",
    "start": "733839",
    "end": "739720"
  },
  {
    "text": "kind of a software engineering background and for me this is kind of a a good way to think about it uh there's",
    "start": "739720",
    "end": "745040"
  },
  {
    "text": "the infrastructure layer uh the service layer some Enterprise featur featur es and then kind of bonus stuff technical",
    "start": "745040",
    "end": "751839"
  },
  {
    "text": "features and extensions to Ray uh the infrastructure layer uh are",
    "start": "751839",
    "end": "757480"
  },
  {
    "text": "things like managing your clouds right like you might say hey I want to have a cluster that's got 32 nodes and it has",
    "start": "757480",
    "end": "765880"
  },
  {
    "text": "uh 24 of them have got eight gpus and eight of them just have like CPUs and I want them to have certain kind of",
    "start": "765880",
    "end": "771399"
  },
  {
    "text": "performance characteristics uh well we're going to need something to actually go and acquire those nodes from",
    "start": "771399",
    "end": "776839"
  },
  {
    "text": "Amazon or gcp or whatever uh make sure all the networking is set up all that kind of just boring stuff",
    "start": "776839",
    "end": "782880"
  },
  {
    "text": "but it has to happen um managing these Hardware environments if you build a hardware environment that's configured",
    "start": "782880",
    "end": "788920"
  },
  {
    "text": "for your application uh you may want to reuse this like for development for other systems so we'd like to be able to",
    "start": "788920",
    "end": "795160"
  },
  {
    "text": "record this we'd like to be able to version it and not be doing things by hand or having to like throw a lot of",
    "start": "795160",
    "end": "800440"
  },
  {
    "text": "scripts around uh so any scale manages these and calls them uh compute configs",
    "start": "800440",
    "end": "806040"
  },
  {
    "text": "uh cluster environments basically this is your software environment so uh you're going to be using Ray you're",
    "start": "806040",
    "end": "811720"
  },
  {
    "text": "going to be using any scale but you're probably also using a ton of other libraries open source things like torch and uh lightning and hugging face um but",
    "start": "811720",
    "end": "820399"
  },
  {
    "text": "also stuff that's coming from inside your company and you're going to have specific collections of those libraries",
    "start": "820399",
    "end": "826160"
  },
  {
    "text": "that work together maybe other assets that you're depending on and again you want to be able to manage those things",
    "start": "826160",
    "end": "831199"
  },
  {
    "text": "and version them so there's infrastructure for that uh if you create a cluster you want",
    "start": "831199",
    "end": "836920"
  },
  {
    "text": "to be able to kind of manage this cluster uh over a long lifespan u meaning uh configure it and get the",
    "start": "836920",
    "end": "844440"
  },
  {
    "text": "right um assets onto that cluster in terms of storage and then be able to stop it say when you don't want to spend",
    "start": "844440",
    "end": "850199"
  },
  {
    "text": "money on those gpus you go home for the night if you're doing development come in the next day and turn it back on and",
    "start": "850199",
    "end": "855279"
  },
  {
    "text": "have everything where it's supposed to be so different kinds of storage Scopes uh and having an identity associated",
    "start": "855279",
    "end": "861320"
  },
  {
    "text": "with with clusters especially for for development purposes uh and so one of the things any scale gives you is a set",
    "start": "861320",
    "end": "866959"
  },
  {
    "text": "of scoped uh storage systems that kind of have different lifespans so a really",
    "start": "866959",
    "end": "873160"
  },
  {
    "text": "fast local only storage scope that's handy for caching things so you're not always getting them from other systems",
    "start": "873160",
    "end": "878839"
  },
  {
    "text": "or from the internet uh a cluster scope so as long as a cluster exists within the any scale system as long as it has",
    "start": "878839",
    "end": "885199"
  },
  {
    "text": "an identity even if it's not turned on uh you get automatically a posx compatible shared storage that's visible",
    "start": "885199",
    "end": "891680"
  },
  {
    "text": "just within that cluster this is extremely extremely useful because a lot of times in any kind of distributed",
    "start": "891680",
    "end": "897440"
  },
  {
    "text": "compute we need some file system that everyone can see kind of looks the same way um you can always use things like",
    "start": "897440",
    "end": "903839"
  },
  {
    "text": "you know S3 buckets stuff like that but that's not quite the same as a posix file system it doesn't perform the same",
    "start": "903839",
    "end": "909600"
  },
  {
    "text": "way and it doesn't really have the same features uh so it's nice to have that uh there's also storage scoped to the user",
    "start": "909600",
    "end": "916160"
  },
  {
    "text": "so you as an individual user across anything you're doing within any scale you've got a file system and then your",
    "start": "916160",
    "end": "921880"
  },
  {
    "text": "organization which could be your whole company or a business unit within your company uh can also segment a file",
    "start": "921880",
    "end": "928120"
  },
  {
    "text": "system that way uh the next layer we've got the service layer so these are services that any",
    "start": "928120",
    "end": "935199"
  },
  {
    "text": "scale offers kind of in addition to you know and Beyond what's just basically in Ray so one of them is workspaces uh",
    "start": "935199",
    "end": "942360"
  },
  {
    "text": "these are a collection of a hardware cluster a software config and then a development uh experience that includes",
    "start": "942360",
    "end": "949160"
  },
  {
    "text": "things like Jupiter lab notebooks or vs code uh a dashboard where you can see",
    "start": "949160",
    "end": "954519"
  },
  {
    "text": "what's going on and we'll actually do the um code later in the session today using a workspace so you'll see that uh",
    "start": "954519",
    "end": "961440"
  },
  {
    "text": "live uh jobs job management is basically a way to uh schedule and run things that",
    "start": "961440",
    "end": "967920"
  },
  {
    "text": "are not interactive right so a lot of your production workloads you you you it's nice to have interactive when",
    "start": "967920",
    "end": "973880"
  },
  {
    "text": "you're developing them but in production right you don't want to be like running a notebook in production we've all had that kind of debate before you want to",
    "start": "973880",
    "end": "980560"
  },
  {
    "text": "be able to take a script that you've built in tested and then be able to schedule it uh run it and so when we",
    "start": "980560",
    "end": "986880"
  },
  {
    "text": "kick off an any scale job it's associate iated with resources and software and it kind of builds up its cluster and sets",
    "start": "986880",
    "end": "992720"
  },
  {
    "text": "up an environment runs uh Records all of its results reports back to you uh so we",
    "start": "992720",
    "end": "998920"
  },
  {
    "text": "can do productionizing uh of workloads that way uh and then any scale services so Ray",
    "start": "998920",
    "end": "1005240"
  },
  {
    "text": "serve which is the component of Ray for serving uh models or other uh chunks of",
    "start": "1005240",
    "end": "1011720"
  },
  {
    "text": "compute logic uh we can actually use Ray serve to create services that are exposed to other uh software or even",
    "start": "1011720",
    "end": "1019079"
  },
  {
    "text": "onto the internet um but any scale Services adds even more uh production capabilities on top of that so things",
    "start": "1019079",
    "end": "1025839"
  },
  {
    "text": "like versioning and uh like Canary rollouts green blue rollouts for routing",
    "start": "1025839",
    "end": "1031640"
  },
  {
    "text": "traffic between evolving versions of of systems and things that are a little more sophisticated for uh actual um",
    "start": "1031640",
    "end": "1038400"
  },
  {
    "text": "production scenarios uh then we have Enterprise features so um these you know",
    "start": "1038400",
    "end": "1044600"
  },
  {
    "text": "are maybe not the most exciting from a software engineering point of view but they're really really important for successful system deployment so admin",
    "start": "1044600",
    "end": "1051880"
  },
  {
    "text": "stuff operations and security uh things like keeping track of Who's Who so",
    "start": "1051880",
    "end": "1057000"
  },
  {
    "text": "single sign on support granular access controls uh audit logs if you need to be able to know who did what when uh these",
    "start": "1057000",
    "end": "1064200"
  },
  {
    "text": "are all really really important things uh and then the last piece are um",
    "start": "1064200",
    "end": "1069880"
  },
  {
    "text": "additional technical features and extensions uh kind of Beyond Ray so some of these things may end up in open",
    "start": "1069880",
    "end": "1075720"
  },
  {
    "text": "source Ray sooner or later um but uh right away they're available through any",
    "start": "1075720",
    "end": "1081240"
  },
  {
    "text": "scale and these are things like enhanced data processing support for video and audio access to data bricks if you've",
    "start": "1081240",
    "end": "1088440"
  },
  {
    "text": "got stuff in the data bricks Unity catalog access to snowflake your company's probably using snowflake for",
    "start": "1088440",
    "end": "1094080"
  },
  {
    "text": "something um uh and some other Integrations things uh things like faster local storage so that we can uh",
    "start": "1094080",
    "end": "1101799"
  },
  {
    "text": "kind of use some really fast local storage um in place of you know having more RAM or pushing stuff to a more",
    "start": "1101799",
    "end": "1107760"
  },
  {
    "text": "distant uh storage stage uh things like that uh and like I said you can try this",
    "start": "1107760",
    "end": "1113960"
  },
  {
    "text": "right away so if you go to NYSC scale.com you can sign up and start without a credit card or anything you",
    "start": "1113960",
    "end": "1120280"
  },
  {
    "text": "can just start there there's a chunk of compute credits uh you'll get right away and there's some templates you can try",
    "start": "1120280",
    "end": "1126080"
  },
  {
    "text": "which I think are on this next slide here so if you get started and you're thinking well okay this is cool but I",
    "start": "1126080",
    "end": "1131720"
  },
  {
    "text": "have no idea what the heck I'm doing you can literally click one of these buttons and start with an example like deploying",
    "start": "1131720",
    "end": "1137320"
  },
  {
    "text": "a language model uh fine-tuning a language model um deploying stable diffusion that's one of my favorites",
    "start": "1137320",
    "end": "1143600"
  },
  {
    "text": "that's kind of fun because you get to generate pictures right away um fine-tuning stable diffusion so that's",
    "start": "1143600",
    "end": "1149520"
  },
  {
    "text": "kind of an interesting project so there's a bunch of templates you can start with or you know lots of other stuff um",
    "start": "1149520",
    "end": "1155640"
  },
  {
    "text": "online so I'm gonna dive into the actual live coding section here in a moment you",
    "start": "1155640",
    "end": "1162000"
  },
  {
    "text": "can see I hidden behind here on my desktop uh this web browser which is",
    "start": "1162000",
    "end": "1167240"
  },
  {
    "text": "pointing at an any any scale workspace so in this tab I'm looking at the any",
    "start": "1167240",
    "end": "1172320"
  },
  {
    "text": "scale workspaces list for one of my accounts here you can see I've got three",
    "start": "1172320",
    "end": "1178919"
  },
  {
    "text": "workspaces I'm not using right now that are for different development projects so one that says Dev May one that says",
    "start": "1178919",
    "end": "1184760"
  },
  {
    "text": "Dev June another Dev June 2 those are turned off right now and then I have this one that's active right now that",
    "start": "1184760",
    "end": "1190720"
  },
  {
    "text": "says fast and scalable model training so uh I can create different workspaces for different things I'm working on and I've",
    "start": "1190720",
    "end": "1197919"
  },
  {
    "text": "got a Jupiter lab view into the uh training one right now uh before I jump into this though I want to take a quick",
    "start": "1197919",
    "end": "1204559"
  },
  {
    "text": "look at some of the questions uh let's see there's a question uh does any scale offer online training um uh we do have a",
    "start": "1204559",
    "end": "1212120"
  },
  {
    "text": "combination of uh some in-person training and uh live training and if you",
    "start": "1212120",
    "end": "1218200"
  },
  {
    "text": "um contact me so Adam",
    "start": "1218200",
    "end": "1222360"
  },
  {
    "text": "bale.in or if you look on the uh any scale website and contact anyone in sales there with your uh interest there",
    "start": "1223600",
    "end": "1231120"
  },
  {
    "text": "uh we'll definitely get back to you um grants for attending race Summit that's a great question I don't know the answer",
    "start": "1231120",
    "end": "1237159"
  },
  {
    "text": "to that actually so I would say that would be something we need to follow up on um uh building end to end ml",
    "start": "1237159",
    "end": "1245120"
  },
  {
    "text": "pipelines uh kind of like with sage maker um so short answer like yes you can do very very similar things um we're",
    "start": "1245120",
    "end": "1252799"
  },
  {
    "text": "not going to do a complete end to end today but yeah there's some stuff about that on our website there's also tons of",
    "start": "1252799",
    "end": "1259080"
  },
  {
    "text": "examples in some of our other online sessions uh and at Ray Summit but yeah you can absolutely uh use Ray and any",
    "start": "1259080",
    "end": "1266679"
  },
  {
    "text": "scale as an endtoend platform um let's see another question if I use any scale in Google Cloud uh does that enable fast",
    "start": "1266679",
    "end": "1273559"
  },
  {
    "text": "multi-node trainings do any setup uh so the short answer is yes and yes so we'll see some of that here today right so um",
    "start": "1273559",
    "end": "1281720"
  },
  {
    "text": "um we'll get into more of the details but yeah the the whole um one of the whole benefits of Ray is that we can do",
    "start": "1281720",
    "end": "1288200"
  },
  {
    "text": "arbit scale out so if you think about how you scale model training right you start out with like a GPU and then you",
    "start": "1288200",
    "end": "1294600"
  },
  {
    "text": "can scale to a node with a bunch of gpus but like in this particular question at some point you're going to want to go to",
    "start": "1294600",
    "end": "1300240"
  },
  {
    "text": "multi node where you've got lots of nodes with one GPU each or maybe lots of nodes with lots of gpus each and getting",
    "start": "1300240",
    "end": "1308120"
  },
  {
    "text": "everything running for that can be and and kind of maintaining that can be a little bit tricky that's exactly the use",
    "start": "1308120",
    "end": "1313440"
  },
  {
    "text": "case that uh Ray train was designed for to make that really simple so uh so",
    "start": "1313440",
    "end": "1319960"
  },
  {
    "text": "yes uh let's see there's another question about syncing the posix file system or loading data into it and can",
    "start": "1319960",
    "end": "1326000"
  },
  {
    "text": "you sync with buckets um yeah it's just there for your convenience so you can absolutely do anything that you you like",
    "start": "1326000",
    "end": "1331840"
  },
  {
    "text": "with it you can write scripts that load data in there um you can also U Move",
    "start": "1331840",
    "end": "1337400"
  },
  {
    "text": "data to and from buckets U maybe a better way to say this because this question's come up before is Ray is and",
    "start": "1337400",
    "end": "1343360"
  },
  {
    "text": "any scale are not constrained to that file system it's just there as like a free bonus that's nice to have so if",
    "start": "1343360",
    "end": "1350559"
  },
  {
    "text": "your current training scripts load things from uh Google cloud or from a S3",
    "start": "1350559",
    "end": "1356559"
  },
  {
    "text": "or from someplace else in your company that will all still work so none of that goes away it's just that sometimes it's",
    "start": "1356559",
    "end": "1362720"
  },
  {
    "text": "also nice to have these other file systems so it's kind of a bonus it you don't have to actually change anything",
    "start": "1362720",
    "end": "1368559"
  },
  {
    "text": "um but you you can totally do that if you want uh let's see a few examples for",
    "start": "1368559",
    "end": "1373640"
  },
  {
    "text": "endtoend pipeline we're not going to have that today just for time reasons um",
    "start": "1373640",
    "end": "1378720"
  },
  {
    "text": "but we'll try to get to that in a future session uh let's see some of these are",
    "start": "1378720",
    "end": "1384679"
  },
  {
    "text": "more technical we'll save for the end just looking at uh some of I think",
    "start": "1384679",
    "end": "1392919"
  },
  {
    "text": "we'll say save the rest of these guys for the end because they get into more technical",
    "start": "1392919",
    "end": "1398520"
  },
  {
    "text": "things um okay so let's take a look we've got two examples you can see on my screen here there's kind of two",
    "start": "1398520",
    "end": "1404080"
  },
  {
    "text": "notebooks and I mentioned that earlier we're going to do a lightning one and then we're going to do a data and",
    "start": "1404080",
    "end": "1409640"
  },
  {
    "text": "pytorch one so the scenario we're looking at in this first uh example is",
    "start": "1409640",
    "end": "1415960"
  },
  {
    "text": "you know imagine that you've been developing with Ray lightning so you've got a lightning data module maybe that wraps your data ingestion and you've got",
    "start": "1415960",
    "end": "1424039"
  },
  {
    "text": "a lightning module like a classic lightning module that wraps your module your model structure and then the",
    "start": "1424039",
    "end": "1429960"
  },
  {
    "text": "training Hooks and your challenge is okay I want to scale this out I want to use it with Ray how do I do it so we",
    "start": "1429960",
    "end": "1436919"
  },
  {
    "text": "want to look at migrating this um from lightning to uh Ray train now in this",
    "start": "1436919",
    "end": "1443240"
  },
  {
    "text": "example we're just using Ray train so it says here without Ray data and I want to",
    "start": "1443240",
    "end": "1448799"
  },
  {
    "text": "make that distinction because in the other example we're going to add Ray data as like another uh useful piece but",
    "start": "1448799",
    "end": "1454840"
  },
  {
    "text": "here we want to keep it kind of as simple uh as possible uh to keep this really small",
    "start": "1454840",
    "end": "1460840"
  },
  {
    "text": "and fast for training you can see we're just doing mest here in terms of a data set uh it just keeps things nice and",
    "start": "1460840",
    "end": "1467000"
  },
  {
    "text": "simple everyone knows what it is is uh and it um you know will will run really",
    "start": "1467000",
    "end": "1472919"
  },
  {
    "text": "quickly the mnus data set that we're using is actually just the one that you",
    "start": "1472919",
    "end": "1478360"
  },
  {
    "text": "would grab from torch so you can see up here I've got my torch Vision data sets",
    "start": "1478360",
    "end": "1483840"
  },
  {
    "text": "mest that's where the actual data is going to come from and it's implemented as a lightning data",
    "start": "1483840",
    "end": "1491000"
  },
  {
    "text": "module and there's nothing that's Ray or any scale specific in this data module",
    "start": "1491000",
    "end": "1497159"
  },
  {
    "text": "so this is completely compatible with whatever module you're currently or data",
    "start": "1497159",
    "end": "1502520"
  },
  {
    "text": "modules you're currently using there's no you can see there's no aray in here anywhere there's no any scale in here at",
    "start": "1502520",
    "end": "1508039"
  },
  {
    "text": "all uh this is just a classic um lightning module here so we've got some",
    "start": "1508039",
    "end": "1513279"
  },
  {
    "text": "uh initializer uh we've got some setup uh we can produce train validation and",
    "start": "1513279",
    "end": "1519880"
  },
  {
    "text": "test data loaders on these calls and that's pretty much it so we'll go and",
    "start": "1519880",
    "end": "1525240"
  },
  {
    "text": "evaluate that cell here uh then then we're going to do our model which is our lightning module",
    "start": "1525240",
    "end": "1532559"
  },
  {
    "text": "subass so this will encapsulate our model itself as well as the training",
    "start": "1532559",
    "end": "1538520"
  },
  {
    "text": "steps so for the model itself we're just going to use something really simple",
    "start": "1538520",
    "end": "1544720"
  },
  {
    "text": "again just to keep it kind of minimal um but if you're wondering like is it what happens when this gets more complicated",
    "start": "1544720",
    "end": "1551120"
  },
  {
    "text": "the same basic structure works so one of our uh big projects that we worked on with a a customer uh that you may have",
    "start": "1551120",
    "end": "1557039"
  },
  {
    "text": "heard of named canva uh was training stable diffusion from scratch and that is done using lightning",
    "start": "1557039",
    "end": "1563000"
  },
  {
    "text": "modules and uh hugging face and it's basically just a slightly more complicated version of what we're seeing",
    "start": "1563000",
    "end": "1568960"
  },
  {
    "text": "here today and they're using it to train stable diffusion in production from scratch so much much bigger more complex",
    "start": "1568960",
    "end": "1576240"
  },
  {
    "text": "model a lot more data involved but the structure is you know almost the same as what we're demoing here today so we've",
    "start": "1576240",
    "end": "1582200"
  },
  {
    "text": "got a little model here um we've got a couple of config things for keeping",
    "start": "1582200",
    "end": "1587440"
  },
  {
    "text": "setting up things like learning rate keeping track of uh losses accuracy uh",
    "start": "1587440",
    "end": "1592600"
  },
  {
    "text": "we've got our training Hooks and this is just regular lightning stuff so again there's nothing that is Ray specific",
    "start": "1592600",
    "end": "1598520"
  },
  {
    "text": "here so this is your usual lightning code you have to define a forward you're going to define a training step um if",
    "start": "1598520",
    "end": "1606360"
  },
  {
    "text": "you're going to do validation steps and or test steps you're going to define",
    "start": "1606360",
    "end": "1611480"
  },
  {
    "text": "those usually there's some shared logic there so you probably come across this yourself en lightning that you're going",
    "start": "1611480",
    "end": "1617200"
  },
  {
    "text": "to write some kind of shared uh logic that's used in um more than one of these",
    "start": "1617200",
    "end": "1622480"
  },
  {
    "text": "steps so you don't have to repeat yourself uh and then we can put hooks for things like on uh validation Epoch",
    "start": "1622480",
    "end": "1629200"
  },
  {
    "text": "and for collecting statistics uh and then of course configure optimizers",
    "start": "1629200",
    "end": "1634279"
  },
  {
    "text": "optimizers so that's like an essential part of lightning and how you tell the framework uh what Optimizer you're",
    "start": "1634279",
    "end": "1640159"
  },
  {
    "text": "actually trying to to use here so that's going to be our lightning module so so far we haven't done",
    "start": "1640159",
    "end": "1647279"
  },
  {
    "text": "anything that had r in it so let's get to the ray part so what has to change uh",
    "start": "1647279",
    "end": "1653120"
  },
  {
    "text": "what has to happen here in order to use this with Ray so the biggest thing that has to happen",
    "start": "1653120",
    "end": "1659960"
  },
  {
    "text": "is we're going to take the code that normally would instantiate our models",
    "start": "1659960",
    "end": "1665279"
  },
  {
    "text": "and our data modules and our lightning trainer and then do our lightning",
    "start": "1665279",
    "end": "1670440"
  },
  {
    "text": "trainer. fit we're going to take that logic and that's going to have to run on every single worker so what we're going",
    "start": "1670440",
    "end": "1676720"
  },
  {
    "text": "to do is we're going to put that into a function that's called the per worker training Loop or per worker training",
    "start": "1676720",
    "end": "1684120"
  },
  {
    "text": "function and that happens in this cell in the notebook right here so we Define",
    "start": "1684120",
    "end": "1690799"
  },
  {
    "text": "a python function this one's called train Funk per worker maybe not the best name but uh the idea is this is the",
    "start": "1690799",
    "end": "1697799"
  },
  {
    "text": "logic that's going to end up getting started on every single worker so uh in the distri in the torch distributed",
    "start": "1697799",
    "end": "1704679"
  },
  {
    "text": "world that's usually uh going to be a worker process a associated with each GPU somewhere in the cluster that there",
    "start": "1704679",
    "end": "1710760"
  },
  {
    "text": "are some other patterns that can happen but that's the most common and what's going to happen in here so inside of",
    "start": "1710760",
    "end": "1716519"
  },
  {
    "text": "here is almost just the regular lightning code so we get our um model",
    "start": "1716519",
    "end": "1722720"
  },
  {
    "text": "our lightning module right here we get our data right here uh we configure our",
    "start": "1722720",
    "end": "1727880"
  },
  {
    "text": "lightning trainer so the lightning trainer is mostly standard there's a couple of little adjustments so some",
    "start": "1727880",
    "end": "1733840"
  },
  {
    "text": "things are normal like CSV logger or weights and biases if you're doing things like that that uh",
    "start": "1733840",
    "end": "1739840"
  },
  {
    "text": "accelerator um you know configuring Epoch okay so what is different so",
    "start": "1739840",
    "end": "1745120"
  },
  {
    "text": "what's different are these three guys here so there is a strategy we're going",
    "start": "1745120",
    "end": "1750200"
  },
  {
    "text": "to specify called Ray DDP strategy and that stands for distributed data",
    "start": "1750200",
    "end": "1756120"
  },
  {
    "text": "parallel so this is going to help integrate lightning with Ray there's a plugin Ray lightning environment so we",
    "start": "1756120",
    "end": "1763000"
  },
  {
    "text": "also need that that's also for uh completing the Ray and Light integration",
    "start": "1763000",
    "end": "1769360"
  },
  {
    "text": "uh and then there's a call back Ray train report call back and that's just for synchronizing the metrics and data",
    "start": "1769360",
    "end": "1776760"
  },
  {
    "text": "that's coming out of those worker processes back into the kind of main Ray",
    "start": "1776760",
    "end": "1782159"
  },
  {
    "text": "process uh so that we can do things like keep track of Statistics in case we want to do like say early stopping or we want",
    "start": "1782159",
    "end": "1789000"
  },
  {
    "text": "to do checkpointing right we need to get some communication back into the kind of host process so we're going to plug",
    "start": "1789000",
    "end": "1795080"
  },
  {
    "text": "these three lines in here uh then we're going to make this is call prepare trainer and this is going to give the",
    "start": "1795080",
    "end": "1802039"
  },
  {
    "text": "framework an opportunity to adjust this trainer uh if it's needed uh to get it",
    "start": "1802039",
    "end": "1807679"
  },
  {
    "text": "to work with Reay uh in some cases there's there's some adjustments here in other versions and for other Frameworks",
    "start": "1807679",
    "end": "1814720"
  },
  {
    "text": "not too much happens in the prepare trainer uh but it's a pattern we follow so it's a best practice to always call",
    "start": "1814720",
    "end": "1819919"
  },
  {
    "text": "prepare trainer uh and then we just do our trainer. fit and we're passing our",
    "start": "1819919",
    "end": "1825000"
  },
  {
    "text": "regular so just to be clear this is your standard code so lightning trainer. fit",
    "start": "1825000",
    "end": "1830120"
  },
  {
    "text": "lightning module here lightning data module here and then the same thing here with test so nothing else",
    "start": "1830120",
    "end": "1836960"
  },
  {
    "text": "changes and let's see let's go and evaluate this cell here we're going to do two workers with used GPU set to tr",
    "start": "1836960",
    "end": "1844600"
  },
  {
    "text": "we'll evaluate our train Funk per worker uh and now we're ready to uh go and get",
    "start": "1844600",
    "end": "1852519"
  },
  {
    "text": "everything ready to do our training so to do that we're going to orchestrate everything using a uh torch trainer",
    "start": "1852519",
    "end": "1862039"
  },
  {
    "text": "which is a class in the ray framework that handles training for all of the P torch related tools so if you're using",
    "start": "1862039",
    "end": "1868440"
  },
  {
    "text": "pytorch directly if you're using lightning if you're using hugging face with py torch models in all those cases",
    "start": "1868440",
    "end": "1874480"
  },
  {
    "text": "you're going to use a ray torch trainer and the API for this isn't too complicated you have to tell it what to",
    "start": "1874480",
    "end": "1881200"
  },
  {
    "text": "run on all the workers so we're going to put that train Funk per worker in here we have to tell it how big to scale the",
    "start": "1881200",
    "end": "1887919"
  },
  {
    "text": "clusters so we're going to pass in a scaling config here uh and you can see that has to have at least how many",
    "start": "1887919",
    "end": "1893440"
  },
  {
    "text": "workers you know whether we want to use a GPU uh and then we're going to pass in a run config uh the most important thing",
    "start": "1893440",
    "end": "1901399"
  },
  {
    "text": "in the Run config and the only thing you really really need is a piece of shared storage where all of the workers can uh",
    "start": "1901399",
    "end": "1909440"
  },
  {
    "text": "see each other's uh storage in case they need to write checkpoints and statistics and things like that uh and that's the",
    "start": "1909440",
    "end": "1916519"
  },
  {
    "text": "storage path here uh in order to show off a couple of other features this particular run config has a couple of",
    "start": "1916519",
    "end": "1922639"
  },
  {
    "text": "other things it has this name uh which is going to end up in the statistical reports uh experiment reports that come",
    "start": "1922639",
    "end": "1929919"
  },
  {
    "text": "out of the training it's also got a checkpoint config so we can tell uh lightning to do things like hey we or",
    "start": "1929919",
    "end": "1936519"
  },
  {
    "text": "really we're telling Ry to do things like let's keep checkpoints but don't keep all of them just keep the three",
    "start": "1936519",
    "end": "1942279"
  },
  {
    "text": "that have the highest score in the validation accuracy statistic uh so you",
    "start": "1942279",
    "end": "1947600"
  },
  {
    "text": "can kind of customize how your checkpointing works so we'll get that set",
    "start": "1947600",
    "end": "1952919"
  },
  {
    "text": "up and then we're going to do a trainer. fit on the ray trainer uh the ray torch",
    "start": "1952919",
    "end": "1960320"
  },
  {
    "text": "trainer so let's kick this off and we should see some distributed training",
    "start": "1960320",
    "end": "1965960"
  },
  {
    "text": "happening so we've identified our resources and now we're starting to use",
    "start": "1967120",
    "end": "1972200"
  },
  {
    "text": "them so we're using one CPU and two gpus you can see here that we've got A10 GS",
    "start": "1972200",
    "end": "1978799"
  },
  {
    "text": "that we're using we're getting some updates uh printing out here I would show you the ray dashboard I can go to",
    "start": "1978799",
    "end": "1985960"
  },
  {
    "text": "open it although I think what's going to happen is that this this training is going to finish so fast that before we",
    "start": "1985960",
    "end": "1992039"
  },
  {
    "text": "really get to see anything on there it'll probably be over uh yeah so I think this thing is",
    "start": "1992039",
    "end": "1997679"
  },
  {
    "text": "finished already maybe see if I can get the dashboard set up for the next demo um but the idea here is we've now run a",
    "start": "1997679",
    "end": "2005760"
  },
  {
    "text": "uh training using P torch using lightning using distributed data",
    "start": "2005760",
    "end": "2011159"
  },
  {
    "text": "parallel across two physically separate machines so going to that question earlier that we had in the Q&A about",
    "start": "2011159",
    "end": "2017240"
  },
  {
    "text": "does Ray help uh do any setup you can see that we didn't I didn't personally have to set up anything uh for this Ray",
    "start": "2017240",
    "end": "2024440"
  },
  {
    "text": "set up all the communication well it uses you know pytorch to do some of that work but Ray and pytorch together uh set",
    "start": "2024440",
    "end": "2030880"
  },
  {
    "text": "up all the communication we're running across two physically separate machines that that each have an a1g uh and we're",
    "start": "2030880",
    "end": "2037159"
  },
  {
    "text": "working together and producing a single model output uh here we can see the stats on that and we",
    "start": "2037159",
    "end": "2043919"
  },
  {
    "text": "can see where it physically is so in this path here it's another reason why",
    "start": "2043919",
    "end": "2049878"
  },
  {
    "text": "having some shared storage here is nice so in this path is going to be a regular old lightning model which is really a",
    "start": "2049879",
    "end": "2056079"
  },
  {
    "text": "torch model uh that represents the result of our training there's also you know other checkpoints saved as",
    "start": "2056079",
    "end": "2061919"
  },
  {
    "text": "well and just to show that we can load this up so let's say I've been using Ray to do some massive training project and",
    "start": "2061919",
    "end": "2069280"
  },
  {
    "text": "now let's say you're working on a project where you don't care about the training and the model is not that big you just want to load up the model and",
    "start": "2069280",
    "end": "2075280"
  },
  {
    "text": "use it for some use case for your job so it's a regular old lightning module uh",
    "start": "2075280",
    "end": "2081000"
  },
  {
    "text": "model so you can just take the lightning module class and do a regular lightning",
    "start": "2081000",
    "end": "2086760"
  },
  {
    "text": "load from checkpoint and point at that file and you've got your you've got your regular old model so there's nothing Ray",
    "start": "2086760",
    "end": "2094040"
  },
  {
    "text": "specific about the model either you're not like you you can you can work in the ray ecosystem but you can also just take",
    "start": "2094040",
    "end": "2100160"
  },
  {
    "text": "these things and work with them elsewhere as well it's just a regular you regular torch and lightning model So",
    "start": "2100160",
    "end": "2107640"
  },
  {
    "text": "Okay cool so that hopefully made some sense uh hopefully it was a little boring because you're like hey that",
    "start": "2107640",
    "end": "2112720"
  },
  {
    "text": "wasn't very exciting where's the magical Ray stuff and if you're thinking that that's the whole point so the idea is to",
    "start": "2112720",
    "end": "2118200"
  },
  {
    "text": "make this as straightforward as possible based on the tools you're already using not to create a whole new system uh you",
    "start": "2118200",
    "end": "2125400"
  },
  {
    "text": "know with tons of new apis that you have to learn uh let me take another quick look at the Q&A and just see if there's anything",
    "start": "2125400",
    "end": "2132280"
  },
  {
    "text": "that we want to specifically uh talk about with respect to this and again the other questions we",
    "start": "2132280",
    "end": "2137839"
  },
  {
    "text": "will answer but we'll hold for the the end of the session",
    "start": "2137839",
    "end": "2143560"
  },
  {
    "text": "um uh let's let's just see if there's anything specific for",
    "start": "2143720",
    "end": "2150599"
  },
  {
    "text": "this uh okay so probably not anything very specific to this lightning piece there",
    "start": "2152839",
    "end": "2159079"
  },
  {
    "text": "are lots of great questions and I will talk to them I just I'm going to hold those because they're generally useful",
    "start": "2159079",
    "end": "2164560"
  },
  {
    "text": "uh for the end there so we have one other demo notebook",
    "start": "2164560",
    "end": "2170680"
  },
  {
    "text": "that we want to look at so this is also a very simple model using a very simple data set so we're",
    "start": "2170680",
    "end": "2177640"
  },
  {
    "text": "not going to see any exciting AI here we're not we're not doing stable diffusion just yet this is a simple",
    "start": "2177640",
    "end": "2183079"
  },
  {
    "text": "tabular processing kind of perceptron model and the data is some of the New York City Taxi Cab data which you may",
    "start": "2183079",
    "end": "2190040"
  },
  {
    "text": "have seen before in some other you know demos or blog posts it's just some tabular data um what we want to",
    "start": "2190040",
    "end": "2196119"
  },
  {
    "text": "demonstrate here are two things one using Ray train just with pytorch so",
    "start": "2196119",
    "end": "2202079"
  },
  {
    "text": "maybe you've never used lightning or for whatever reason you'd like to see this without the lightning layer involved we can see a little bit more U maybe what's",
    "start": "2202079",
    "end": "2209280"
  },
  {
    "text": "going on just looking at uh Ray and torch and we're also going to introduce Ray data just a tiny bit to show um",
    "start": "2209280",
    "end": "2216920"
  },
  {
    "text": "where that might come in right so in the previous example we saw that if you're using lightning data modules or torch",
    "start": "2216920",
    "end": "2223640"
  },
  {
    "text": "data sets torch data loaders all that stuff works but it may not be the fastest way uh to do this stuff at",
    "start": "2223640",
    "end": "2230640"
  },
  {
    "text": "really large scale uh because you know you may be you may run into situations where you want to do like some",
    "start": "2230640",
    "end": "2236560"
  },
  {
    "text": "Transformations on say your torch your batches of torch data and you want to distribute those transformations in like",
    "start": "2236560",
    "end": "2243280"
  },
  {
    "text": "an intelligent way like using specific resources or using other models to do those trans Transformations things that",
    "start": "2243280",
    "end": "2248440"
  },
  {
    "text": "get a little more you know complicated than maybe just like a torch Vision um you know normalizing an image kind of",
    "start": "2248440",
    "end": "2254760"
  },
  {
    "text": "transform uh so for situations like that where we want to ingest and do some processing on data at scale and then",
    "start": "2254760",
    "end": "2261240"
  },
  {
    "text": "feed that into training uh we have Ray data a really common example of this",
    "start": "2261240",
    "end": "2266760"
  },
  {
    "text": "right now is uh generating embeddings so there's lots of applications today",
    "start": "2266760",
    "end": "2271800"
  },
  {
    "text": "they're generating embeddings for text for llm based applications uh or embeddings of images for doing you know",
    "start": "2271800",
    "end": "2279079"
  },
  {
    "text": "things like image fingerprinting or multimodal stuff where we want to you want to create these vectorized uh",
    "start": "2279079",
    "end": "2285520"
  },
  {
    "text": "representations of um images or text and so that counts as pre-processing right",
    "start": "2285520",
    "end": "2291680"
  },
  {
    "text": "that that's not super super hard we've got kind of pre-trained models for those but it can be kind of heavyweight we",
    "start": "2291680",
    "end": "2297119"
  },
  {
    "text": "want to you know keep those models running and you know um associate them",
    "start": "2297119",
    "end": "2302599"
  },
  {
    "text": "with uh suitably performant Hardware so maybe a GPU but not our fanciest gpus",
    "start": "2302599",
    "end": "2308040"
  },
  {
    "text": "because maybe the fanciest gpus we actually want to use for the main model training or inference so um they they",
    "start": "2308040",
    "end": "2314319"
  },
  {
    "text": "kind of you know represent a real world example that gets a little bit more sophisticated so uh we won't see that in",
    "start": "2314319",
    "end": "2319880"
  },
  {
    "text": "this example here today but Ray data works really well with that pattern okay so let's run some code here uh how do I",
    "start": "2319880",
    "end": "2327000"
  },
  {
    "text": "get some uh taxi cab data so I'm going to go ray. data uh and then we've got uh",
    "start": "2327000",
    "end": "2333520"
  },
  {
    "text": "read apis for lots of different formats so you know all all of your common data",
    "start": "2333520",
    "end": "2338599"
  },
  {
    "text": "formats are supported here paret generally is one of the you know best performing ones for especially tabular",
    "start": "2338599",
    "end": "2345760"
  },
  {
    "text": "data but even tabular data with embedded binary data it works really well uh we're loading it from an S3 bucket so",
    "start": "2345760",
    "end": "2352000"
  },
  {
    "text": "this is an example of something I mentioned before that local posx file system those extensions are nice but",
    "start": "2352000",
    "end": "2357599"
  },
  {
    "text": "you're not everything doesn't have to be in there here we're just loading from",
    "start": "2357599",
    "end": "2362680"
  },
  {
    "text": "S3 uh oh I'm missing some imports let's do the import at the top and then we'll do this read parquet again and this time",
    "start": "2363359",
    "end": "2369800"
  },
  {
    "text": "I think it'll be a little bit happier so like in some other large scale data processing Frameworks that",
    "start": "2369800",
    "end": "2376599"
  },
  {
    "text": "you may have seen things like Apache spark the raid data abstraction is designed to handle arbitrarily large",
    "start": "2376599",
    "end": "2383400"
  },
  {
    "text": "sets of data and to process them in a lazy way so uh we're not going to go and",
    "start": "2383400",
    "end": "2388440"
  },
  {
    "text": "like read all this data into memory and then start poking around on it like we might with pandas instead we're going to",
    "start": "2388440",
    "end": "2393880"
  },
  {
    "text": "create a recipe for kind of flowing this data or streaming it from a source doing",
    "start": "2393880",
    "end": "2399200"
  },
  {
    "text": "things with it and sending it somewhere because that's the trick that allows us to optimize uh and to work on really",
    "start": "2399200",
    "end": "2404920"
  },
  {
    "text": "really large data sets so what are we going to do with this data what's interesting here well",
    "start": "2404920",
    "end": "2411119"
  },
  {
    "text": "the main thing we have to do is just convert all of these values into uh kind of vectors from the individual columns",
    "start": "2411119",
    "end": "2418720"
  },
  {
    "text": "uh and then stack them together into matrices for training so we'll just look at some code that that does that so here",
    "start": "2418720",
    "end": "2425400"
  },
  {
    "text": "we're going to take a batch of Records from this data set and kind of look at it so you can see we've got some columns",
    "start": "2425400",
    "end": "2431680"
  },
  {
    "text": "and they're each associated with some Vector of values uh there's some different types here um what we want to",
    "start": "2431680",
    "end": "2437800"
  },
  {
    "text": "do is rearrange these and kind of stack them up into a matrix for uh deep",
    "start": "2437800",
    "end": "2443040"
  },
  {
    "text": "learning training uh so we're going to go and grab the uh values we're going to",
    "start": "2443040",
    "end": "2448079"
  },
  {
    "text": "go and convert these to lists stack them up so this is just a little bit of numpy",
    "start": "2448079",
    "end": "2453440"
  },
  {
    "text": "kind of playing around uh and then if we do a transpose will get them in the right orientation where we have the",
    "start": "2453440",
    "end": "2460280"
  },
  {
    "text": "records or batch axis and the zero axis and then the features uh in the next",
    "start": "2460280",
    "end": "2465880"
  },
  {
    "text": "axis so where does this connect to Ray data well if we have a program this is a",
    "start": "2465880",
    "end": "2471800"
  },
  {
    "text": "very small program but it's a little program that does some data transformation we can run that over our",
    "start": "2471800",
    "end": "2477920"
  },
  {
    "text": "large data set by putting this into a function and then calling map batches",
    "start": "2477920",
    "end": "2483800"
  },
  {
    "text": "with our data set and providing that function so now what we can do is we can run",
    "start": "2483800",
    "end": "2490280"
  },
  {
    "text": "batches of data from our data set through this transformation and the cool thing that",
    "start": "2490280",
    "end": "2495560"
  },
  {
    "text": "we can do with Ray data is if we have a transformation like this that is stateful like let's say it loads up a",
    "start": "2495560",
    "end": "2502079"
  },
  {
    "text": "big expensive model and we want to keep that model around to do lots of processing uh there's a version of this",
    "start": "2502079",
    "end": "2508400"
  },
  {
    "text": "that looks a tiny bit different where we can use a whole python class that is allowed to have kind of arbitrary State",
    "start": "2508400",
    "end": "2514359"
  },
  {
    "text": "like loading a model and doing other things and we can route our data through that and we can have multiple instances",
    "start": "2514359",
    "end": "2521119"
  },
  {
    "text": "of that um it's called an actor we can have multiple instances of that actor uh",
    "start": "2521119",
    "end": "2526359"
  },
  {
    "text": "and we can spread our data processing across those instances across our cluster uh and you can you can see how",
    "start": "2526359",
    "end": "2533079"
  },
  {
    "text": "those couple of things working together give us a lot of scalability and efficiency this the statefulness being",
    "start": "2533079",
    "end": "2538760"
  },
  {
    "text": "able to allocate you know Hardware like gpus for this processing being able to run lots of these across the cluster so",
    "start": "2538760",
    "end": "2545800"
  },
  {
    "text": "um that's that's kind of the pattern that looks like this this map batches that we're seeing right here uh is kind",
    "start": "2545800",
    "end": "2551400"
  },
  {
    "text": "of the maybe one of the the simpler flavors of data transformation okay so let's go and do",
    "start": "2551400",
    "end": "2558760"
  },
  {
    "text": "our training right that's all we've got our data prepared uh if we want to do our training once again we're going to",
    "start": "2558760",
    "end": "2565319"
  },
  {
    "text": "write a per worker training function and this is going to be the process that gets started on every",
    "start": "2565319",
    "end": "2571720"
  },
  {
    "text": "worker and in this example it's called train Funk so it doesn't really matter what we call it you could see the other",
    "start": "2571720",
    "end": "2577319"
  },
  {
    "text": "notebook had a different name uh and it's going to get this config variable so anything that we want to pass small",
    "start": "2577319",
    "end": "2584240"
  },
  {
    "text": "values not big data sets but small values like hyper prams for example that we want to pass from our main Control",
    "start": "2584240",
    "end": "2591160"
  },
  {
    "text": "process into the per worker training Loop uh is going to show up in this config so that is another kind of",
    "start": "2591160",
    "end": "2597920"
  },
  {
    "text": "convenience mechanism for getting uh things that we decide in our main program automatically distributed into",
    "start": "2597920",
    "end": "2604119"
  },
  {
    "text": "the right workers so we don't have to come up with ways to like get all that stuff into to the right",
    "start": "2604119",
    "end": "2609400"
  },
  {
    "text": "place uh so what are we going to have in this per worker training function so",
    "start": "2609400",
    "end": "2614720"
  },
  {
    "text": "first we're going to set up a model and here you can see it's just very basic torch NN sequential with some",
    "start": "2614720",
    "end": "2621160"
  },
  {
    "text": "layers I'm doing some of those layers um shape based on values that are coming in",
    "start": "2621160",
    "end": "2628760"
  },
  {
    "text": "from this config uh so you don't have to do that but here I'm just demonstrating how we could have maybe make some decisions",
    "start": "2628760",
    "end": "2635640"
  },
  {
    "text": "about the shape of our Network in our main process and then have that get propagated so that it automatically",
    "start": "2635640",
    "end": "2642079"
  },
  {
    "text": "comes up in the right place and our individual models are configured correctly uh we've got our loss function",
    "start": "2642079",
    "end": "2648640"
  },
  {
    "text": "our Optimizer uh we're going to do a prepare model on our model so when we're working",
    "start": "2648640",
    "end": "2654839"
  },
  {
    "text": "with a model directly like this in in uh torch and we use it with train we're",
    "start": "2654839",
    "end": "2659920"
  },
  {
    "text": "going to pass it through a call to Ray Trin torch prepare model so this is",
    "start": "2659920",
    "end": "2664960"
  },
  {
    "text": "similar to what we saw with the trainer in the notebook uh it's a best practice to pass this model in it gives Ry a",
    "start": "2664960",
    "end": "2671640"
  },
  {
    "text": "chance to put hooks in or make other adjustments that need to happen um if you've used uh torch data parallel",
    "start": "2671640",
    "end": "2677920"
  },
  {
    "text": "before you may remember that there's a a similar call you have to pass where you take your torch model and pass it to",
    "start": "2677920",
    "end": "2683599"
  },
  {
    "text": "torch to to DDP to generate the data parallel wrapping that's kind of what's going on here if that doesn't mean",
    "start": "2683599",
    "end": "2689599"
  },
  {
    "text": "anything to you don't worry about it uh then we're going to go and grab the data set so I said the config is good for",
    "start": "2689599",
    "end": "2696200"
  },
  {
    "text": "small Valu like say the H1 width which is what it's like 10 or something like that in here",
    "start": "2696200",
    "end": "2703359"
  },
  {
    "text": "some single number what about a big data set so the way we're going to do that is we're going to use a couple of helpers",
    "start": "2703359",
    "end": "2709119"
  },
  {
    "text": "from Ray we're going to call get data set Shard which will get us a disjoint",
    "start": "2709119",
    "end": "2714400"
  },
  {
    "text": "slice of our big data set just for this worker so if you have lots of workers they not all using the same data and",
    "start": "2714400",
    "end": "2720559"
  },
  {
    "text": "then we're going to call iter torch batches to pull chunks of data off of that Shard convert them to P torch",
    "start": "2720559",
    "end": "2727599"
  },
  {
    "text": "tensors of a particular type and a particular batch size and then we can",
    "start": "2727599",
    "end": "2732880"
  },
  {
    "text": "just walk this training iterator right here and pull off batches and do regular",
    "start": "2732880",
    "end": "2738240"
  },
  {
    "text": "old training so here is a simple pytorch training loop we're going to do five epochs we'll get our batches from this",
    "start": "2738240",
    "end": "2745760"
  },
  {
    "text": "training iterator here we're going to slice up our features and our labels we'll calculate our outputs our loss",
    "start": "2745760",
    "end": "2753000"
  },
  {
    "text": "we'll do our zero grad we'll back propagate will update our um weights",
    "start": "2753000",
    "end": "2760400"
  },
  {
    "text": "with the optimizer and that's just your usual Pi torch Loop uh then we have a little bit of code specific to reporting",
    "start": "2760400",
    "end": "2767960"
  },
  {
    "text": "checkpoints um so if we want to record checkpoints what we're going to do here is figure out which is our number zero",
    "start": "2767960",
    "end": "2776680"
  },
  {
    "text": "worker and for that worker we're going to record the current model using a regular torch. saave uh why we're using",
    "start": "2776680",
    "end": "2784319"
  },
  {
    "text": "just the one worker because in DDP training the model is the same on every worker so if we have like 30 workers it",
    "start": "2784319",
    "end": "2790839"
  },
  {
    "text": "doesn't make sense to record 30 copies of the same model we just just record the one uh we're also going to report",
    "start": "2790839",
    "end": "2796640"
  },
  {
    "text": "our metrics back to Ray so we'll go and get this running then we're going to set",
    "start": "2796640",
    "end": "2802880"
  },
  {
    "text": "up our scaling config and our torch trainer kind of like what we saw in the last",
    "start": "2802880",
    "end": "2808680"
  },
  {
    "text": "example and then we're going to do a trainer. fit before I do the trainer. fit though I want to call attention to",
    "start": "2808680",
    "end": "2815760"
  },
  {
    "text": "let's see two things that are new in this example so before we saw this per worker training code we saw scaling",
    "start": "2815760",
    "end": "2822040"
  },
  {
    "text": "config before uh we saw run config before that's the thing with the shared",
    "start": "2822040",
    "end": "2827119"
  },
  {
    "text": "storage um here we're passing Ray data sets so we could pass as many as we want",
    "start": "2827119",
    "end": "2833240"
  },
  {
    "text": "train test validation extra data however it doesn't matter we can pass as many as",
    "start": "2833240",
    "end": "2838319"
  },
  {
    "text": "we want we put the handles to those Ray data sets in this dictionary and then we",
    "start": "2838319",
    "end": "2844160"
  },
  {
    "text": "can access them using this call inside of the per worker training Loop",
    "start": "2844160",
    "end": "2849480"
  },
  {
    "text": "so by name we can get a Shard of any of those data sets so that's relatively straightforward and then for the small",
    "start": "2849480",
    "end": "2856359"
  },
  {
    "text": "values I talked about that config this is where that config uh dictionary comes",
    "start": "2856359",
    "end": "2861880"
  },
  {
    "text": "from so this allows me to specify values in my main code here that will propagate",
    "start": "2861880",
    "end": "2867000"
  },
  {
    "text": "into my workers so let's go and get this running and see if it wants to train",
    "start": "2867000",
    "end": "2875319"
  },
  {
    "text": "and this is you know not a super complicated problem so it'll probably finish in about 20 seconds looks like",
    "start": "2889200",
    "end": "2895040"
  },
  {
    "text": "it's already done and if we look at this result so here is our output so we had a a loss of you know this score here uh",
    "start": "2895040",
    "end": "2902800"
  },
  {
    "text": "this is where our last um model is stored",
    "start": "2902800",
    "end": "2908160"
  },
  {
    "text": "and we've got a checkpoint object that wraps that um model snapshot so we've",
    "start": "2908160",
    "end": "2914160"
  },
  {
    "text": "successfully trained that using our cluster so yeah it's so it's so challenging to do these examples in like",
    "start": "2914160",
    "end": "2921000"
  },
  {
    "text": "a onh hour setting here because we're almost out of time but we've got a few minutes left for the questions and I",
    "start": "2921000",
    "end": "2926480"
  },
  {
    "text": "know I've been promising that we'd talk about these questions so let's do some of that uh before we wrap up here so let",
    "start": "2926480",
    "end": "2933200"
  },
  {
    "text": "me take a look at which questions we haven't uh answered",
    "start": "2933200",
    "end": "2938319"
  },
  {
    "text": "I'm just going to go back to the beginning and take a",
    "start": "2938319",
    "end": "2942798"
  },
  {
    "text": "look uh okay so I think the first one that we haven't talked about yet so uh if I have a large the question is if I",
    "start": "2945240",
    "end": "2951720"
  },
  {
    "text": "have a large data set hundreds of terabytes or pedabytes in S3 what's the fastest way to load my data uh into AR",
    "start": "2951720",
    "end": "2958400"
  },
  {
    "text": "Ray data set and iterate it through it in batches uh great question and the the",
    "start": "2958400",
    "end": "2963599"
  },
  {
    "text": "answer is something very much like what we saw in here here um so the simplest",
    "start": "2963599",
    "end": "2969079"
  },
  {
    "text": "way is create array data set that looks like this and Define whatever Transformations",
    "start": "2969079",
    "end": "2976480"
  },
  {
    "text": "you may need to do using either actors or functions so you can do things like map batches but in terms of iterating",
    "start": "2976480",
    "end": "2982680"
  },
  {
    "text": "through it in batches um you can if you want to just process it in batches kind",
    "start": "2982680",
    "end": "2988720"
  },
  {
    "text": "of without training you can do it like this so you can do things like map batches which will you know process it",
    "start": "2988720",
    "end": "2995640"
  },
  {
    "text": "you know process it a bat at a time and you can configure things like how big the batches are and you know the resources associated with that and all",
    "start": "2995640",
    "end": "3002119"
  },
  {
    "text": "of that if you want to get those batches specifically for training like maybe you",
    "start": "3002119",
    "end": "3007160"
  },
  {
    "text": "you don't need to do any transformation or you're already done with that it's going to look like this pattern right",
    "start": "3007160",
    "end": "3013240"
  },
  {
    "text": "here so you're going to get a data set Shard on the worker and then you're going to do an itter batches if you just",
    "start": "3013240",
    "end": "3019799"
  },
  {
    "text": "want raw batches as like whatever the original data uh flavor is or it or",
    "start": "3019799",
    "end": "3024920"
  },
  {
    "text": "torch batches if you want uh torch tensors and this this does work at scale",
    "start": "3024920",
    "end": "3030559"
  },
  {
    "text": "so like this is what we use for stable diffusion on a much much bigger data set it's the exact same code well I mean not",
    "start": "3030559",
    "end": "3036520"
  },
  {
    "text": "literally the exact same code it's the exact same pattern uh and that works pretty nicely uh let's see what else do",
    "start": "3036520",
    "end": "3042119"
  },
  {
    "text": "we have here um let's see uh how do we virtualize the compute resources for",
    "start": "3042119",
    "end": "3048440"
  },
  {
    "text": "each node okay so yeah so in the N scale and Ray system there's two um there's kind of three three flavors of that so",
    "start": "3048440",
    "end": "3055480"
  },
  {
    "text": "mainly we're going to have individual worker machines that are going to be you know like if we're in AWS they're going",
    "start": "3055480",
    "end": "3061319"
  },
  {
    "text": "to be specific AWS like ec2 node types so those are um there's some",
    "start": "3061319",
    "end": "3067160"
  },
  {
    "text": "virtualization going on on the Amazon side but we treat them as like physical servers basically so that's one layer uh",
    "start": "3067160",
    "end": "3073319"
  },
  {
    "text": "there's another layer in terms of let's say you've got one of these instances and it has two gpus on it but I've got",
    "start": "3073319",
    "end": "3078920"
  },
  {
    "text": "some code here in Ray that is you know needing different numbers of gpus how does that work so the way that works is",
    "start": "3078920",
    "end": "3085079"
  },
  {
    "text": "Ray has its own uh capability for accounting uh CPUs gpus other kinds of",
    "start": "3085079",
    "end": "3091000"
  },
  {
    "text": "accelerators or custom resources so you can uh in in this example today the only",
    "start": "3091000",
    "end": "3097520"
  },
  {
    "text": "thing we did that involved something like that is where we said scaling config numb workers equals two but",
    "start": "3097520",
    "end": "3104520"
  },
  {
    "text": "there's a lot more fancy things you can do you can write individual pieces of your code that say things like I need",
    "start": "3104520",
    "end": "3110559"
  },
  {
    "text": "one GPU and you know this many CPUs or I need a GPU but I don't really need much",
    "start": "3110559",
    "end": "3116280"
  },
  {
    "text": "of it so I'll take a tenth of a GPU because I really what I really need is the compute capability there but not",
    "start": "3116280",
    "end": "3121440"
  },
  {
    "text": "much of the memory uh you can also Define custom resources and other kinds of things and Ry will do the accounting",
    "start": "3121440",
    "end": "3127720"
  },
  {
    "text": "for that and make sure that stuff gets scheduled in the place where those resources are present uh if those",
    "start": "3127720",
    "end": "3133079"
  },
  {
    "text": "resources don't exist in the cluster but autoscaling is available then uh Ray and",
    "start": "3133079",
    "end": "3138799"
  },
  {
    "text": "any scale can scale up to acquire those resources uh there's one more level of virtualization that's used for certain",
    "start": "3138799",
    "end": "3145640"
  },
  {
    "text": "edge cases where where we need like different software environments for different pieces of code um but I don't",
    "start": "3145640",
    "end": "3151119"
  },
  {
    "text": "want to get into that today it's it's a capability that is really cool but um it's just maybe a little bit too much time for for",
    "start": "3151119",
    "end": "3157839"
  },
  {
    "text": "today uh let's see what else do we have here in terms of questions um there's a",
    "start": "3157839",
    "end": "3163079"
  },
  {
    "text": "question about a Bastion server with slurm I don't have an answer for that today so I don't wanna I don't want to",
    "start": "3163079",
    "end": "3169760"
  },
  {
    "text": "talk out of turn and maybe take up anybody's time with my my bad guessing of that we'd have to get some other",
    "start": "3169760",
    "end": "3175760"
  },
  {
    "text": "input on that integrating Ray jobs with Kafka for large scale testing um so yeah you could",
    "start": "3175760",
    "end": "3181960"
  },
  {
    "text": "certainly integrate Ray with other you know it's just python I mean that's um I mean the the deep deep engine of of Ray",
    "start": "3181960",
    "end": "3189240"
  },
  {
    "text": "involves C++ but all the programming of Ray um that you're going to be doing involves python so it's pretty",
    "start": "3189240",
    "end": "3194680"
  },
  {
    "text": "straightforward to integrate it with with other systems and you can absolutely do that um can Ray work efficiently with Triton and other",
    "start": "3194680",
    "end": "3200760"
  },
  {
    "text": "inference servers uh yes so there's a few different I think there are implementations of that um I think any",
    "start": "3200760",
    "end": "3206520"
  },
  {
    "text": "scale has one but I'm not 100% sure whether that's the current one that we're deploying but it's been built and",
    "start": "3206520",
    "end": "3212200"
  },
  {
    "text": "those things are around um uh let's see what else do we have",
    "start": "3212200",
    "end": "3217799"
  },
  {
    "text": "here some great questions uh how do you define the storage path for shared",
    "start": "3217799",
    "end": "3222839"
  },
  {
    "text": "memory in a cloud environment for example um so those the the storage pads",
    "start": "3222839",
    "end": "3228000"
  },
  {
    "text": "that are built in they're like they they are basically at fixed paths um I can",
    "start": "3228000",
    "end": "3233319"
  },
  {
    "text": "show you what that looks like so um so you get",
    "start": "3233319",
    "end": "3238799"
  },
  {
    "text": "um so for like cluster so for like cluster scope storage it's going to look",
    "start": "3238799",
    "end": "3243960"
  },
  {
    "text": "like this so SL Mount cluster storage and you can put whatever you want underneath there so that would be for",
    "start": "3243960",
    "end": "3250079"
  },
  {
    "text": "cluster storage if you wanted something that's for your entire um organization",
    "start": "3250079",
    "end": "3255400"
  },
  {
    "text": "but scoped to you as a user that's going to be under like user storage so here is anything I've put in um on any of my",
    "start": "3255400",
    "end": "3262760"
  },
  {
    "text": "work I can see in here so there's a bunch of um so there's a bunch of different",
    "start": "3262760",
    "end": "3269480"
  },
  {
    "text": "amounts that are kind of built in that way and of course you can always add more but uh that's how the built-in ones work uh is it possible to Define your",
    "start": "3269480",
    "end": "3276400"
  },
  {
    "text": "own scheduling algorithms so if you mean for like the core Ray scheduler um I",
    "start": "3276400",
    "end": "3282079"
  },
  {
    "text": "mean in theory yes it's open source and there's a lot of stuff you can configure in practice most people that are using",
    "start": "3282079",
    "end": "3287520"
  },
  {
    "text": "Ray are using it because they already want to use the scheduling system that's",
    "start": "3287520",
    "end": "3293040"
  },
  {
    "text": "been developed for Ray because that that's kind of a major investment in like research and and development over",
    "start": "3293040",
    "end": "3298280"
  },
  {
    "text": "the years um so typically they want to use that but you can customize it um if you want to totally change its Behavior",
    "start": "3298280",
    "end": "3304599"
  },
  {
    "text": "you can do that um it's maybe less popular to do it uh let's see how does",
    "start": "3304599",
    "end": "3309680"
  },
  {
    "text": "Auto how does Resource Auto scaling work with Ray train um like if you run R kubernetes can scale from 1 to 16 gpus",
    "start": "3309680",
    "end": "3316160"
  },
  {
    "text": "will train automatically scale up um so usually for so the short answer",
    "start": "3316160",
    "end": "3323160"
  },
  {
    "text": "is we can yes we can scale up the available resources like the number of um uh nodes in say a cloud environment",
    "start": "3323160",
    "end": "3331039"
  },
  {
    "text": "or number of gpus in the cloud environment for the train task itself we usually start with a set number of gpus",
    "start": "3331039",
    "end": "3339400"
  },
  {
    "text": "so we want to have a certain number like 32 we can scale the cluster up to get 32",
    "start": "3339400",
    "end": "3344480"
  },
  {
    "text": "but we usually don't change the number of gpus involved in the training just because the way the training algorithms",
    "start": "3344480",
    "end": "3349880"
  },
  {
    "text": "work they they're usually um they they're usually expecting to have a a set number of",
    "start": "3349880",
    "end": "3356599"
  },
  {
    "text": "resources for the duration of the training so if that makes sense like there's scaling of the resources that are supplied to the training the",
    "start": "3356599",
    "end": "3363160"
  },
  {
    "text": "training itself usually uh grabs a hold of a fixed pool and then what Ray will",
    "start": "3363160",
    "end": "3368359"
  },
  {
    "text": "do is if we lose nodes from that pool um we can get them back but we're not going to say like during training we wouldn't",
    "start": "3368359",
    "end": "3374880"
  },
  {
    "text": "typically scale from say 32 to 64 gpus in the middle of a training cycle just because the algorithms aren't really uh",
    "start": "3374880",
    "end": "3381000"
  },
  {
    "text": "designed for that uh let's see we're just about out of time I'm looking to see if we have any more questions can",
    "start": "3381000",
    "end": "3386400"
  },
  {
    "text": "you use Ray data and py Spark together uh the short answer is yes but is a little bit tricky um I know that's maybe",
    "start": "3386400",
    "end": "3392960"
  },
  {
    "text": "not a great answer but it's it's uh tough and the very last one I'm going to answer is what do we mean by worker in Ray train so throughout Ray when we talk",
    "start": "3392960",
    "end": "3400200"
  },
  {
    "text": "about a worker what we mean is a process that can run code and has some resources",
    "start": "3400200",
    "end": "3406520"
  },
  {
    "text": "so it can run your own python functions it can participate in a multi-worker",
    "start": "3406520",
    "end": "3412000"
  },
  {
    "text": "distributed training process it can participate in a distributed data process processing application um but",
    "start": "3412000",
    "end": "3418079"
  },
  {
    "text": "it's it's it's a process running somewhere in your cluster that has some resources and is running some of your",
    "start": "3418079",
    "end": "3423839"
  },
  {
    "text": "code that's kind of the definition for that uh and with that we're pretty much out of time so I want to thank everybody",
    "start": "3423839",
    "end": "3429440"
  },
  {
    "text": "for joining here today uh remind you to uh take a look we'll send out um the slides and the notebooks after this",
    "start": "3429440",
    "end": "3436599"
  },
  {
    "text": "session so there were questions about that you'll get all that stuff in the mail uh definitely check out Ray Summit it' be really cool to uh meet up in",
    "start": "3436599",
    "end": "3443480"
  },
  {
    "text": "person and uh we'll all be learning more about Ray together at that time this fall thanks so much",
    "start": "3443480",
    "end": "3451799"
  }
]
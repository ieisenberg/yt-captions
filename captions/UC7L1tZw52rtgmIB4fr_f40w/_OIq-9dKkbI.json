[
  {
    "text": "[Applause]",
    "start": "3530",
    "end": "6919"
  },
  {
    "text": "hello everyone can you guys hear me yeah",
    "start": "6919",
    "end": "10920"
  },
  {
    "text": "um Welcome to our talk my name is kurosh",
    "start": "10920",
    "end": "13559"
  },
  {
    "text": "I'm a tech lead in the AI team here at",
    "start": "13559",
    "end": "16260"
  },
  {
    "text": "any scale and together with Arthur we're",
    "start": "16260",
    "end": "18900"
  },
  {
    "text": "going to be talking about some of the",
    "start": "18900",
    "end": "20520"
  },
  {
    "text": "lessons we learned from fine-tuning",
    "start": "20520",
    "end": "22080"
  },
  {
    "text": "llama 2. I hope these insights that we",
    "start": "22080",
    "end": "25260"
  },
  {
    "text": "uncover in this talk will be of help to",
    "start": "25260",
    "end": "27900"
  },
  {
    "text": "you as well",
    "start": "27900",
    "end": "29460"
  },
  {
    "text": "so here's the outline of the talk",
    "start": "29460",
    "end": "32220"
  },
  {
    "text": "um I'm going to start by motivating the",
    "start": "32220",
    "end": "34739"
  },
  {
    "text": "promise behind open source L Ms and why",
    "start": "34739",
    "end": "38280"
  },
  {
    "text": "especially we need to fine-tune them I'm",
    "start": "38280",
    "end": "40800"
  },
  {
    "text": "going to briefly talk about how raytrain",
    "start": "40800",
    "end": "42780"
  },
  {
    "text": "fits into picture when it comes to llm",
    "start": "42780",
    "end": "45899"
  },
  {
    "text": "distributed training and then we're",
    "start": "45899",
    "end": "48300"
  },
  {
    "text": "going to cover some learnings around",
    "start": "48300",
    "end": "49800"
  },
  {
    "text": "fine tuning problem set up and parameter",
    "start": "49800",
    "end": "52320"
  },
  {
    "text": "efficient fine tuning",
    "start": "52320",
    "end": "54780"
  },
  {
    "text": "so since the emergence of chat GPT we've",
    "start": "54780",
    "end": "58920"
  },
  {
    "text": "seen two major separations in the street",
    "start": "58920",
    "end": "61800"
  },
  {
    "text": "Trends on one hand we have closed Source",
    "start": "61800",
    "end": "64500"
  },
  {
    "text": "language models this includes models",
    "start": "64500",
    "end": "67020"
  },
  {
    "text": "like gpd4 or Cloud V2 from anthropic",
    "start": "67020",
    "end": "70979"
  },
  {
    "text": "um these kind of serve as a very",
    "start": "70979",
    "end": "73140"
  },
  {
    "text": "powerful general purpose assistant model",
    "start": "73140",
    "end": "75240"
  },
  {
    "text": "that is capable of solving a wide",
    "start": "75240",
    "end": "78060"
  },
  {
    "text": "variety of tasks but",
    "start": "78060",
    "end": "80759"
  },
  {
    "text": "one of the kind of like things that are",
    "start": "80759",
    "end": "83880"
  },
  {
    "text": "on top of Mind of people is that they're",
    "start": "83880",
    "end": "86159"
  },
  {
    "text": "prohibitively expensive to run in",
    "start": "86159",
    "end": "88140"
  },
  {
    "text": "production and also more importantly",
    "start": "88140",
    "end": "90840"
  },
  {
    "text": "there's a lot of ambiguity around data",
    "start": "90840",
    "end": "94080"
  },
  {
    "text": "governance and how your data is get",
    "start": "94080",
    "end": "95939"
  },
  {
    "text": "getting used when you're using these",
    "start": "95939",
    "end": "97560"
  },
  {
    "text": "systems",
    "start": "97560",
    "end": "99479"
  },
  {
    "text": "um at the same time we have open",
    "start": "99479",
    "end": "101759"
  },
  {
    "text": "language models",
    "start": "101759",
    "end": "103500"
  },
  {
    "text": "this includes models like llama 2 from",
    "start": "103500",
    "end": "105840"
  },
  {
    "text": "meta or Falcon models or mosaic MPT",
    "start": "105840",
    "end": "109020"
  },
  {
    "text": "models",
    "start": "109020",
    "end": "110420"
  },
  {
    "text": "they kind of have promises on the other",
    "start": "110420",
    "end": "113159"
  },
  {
    "text": "side of this spectrum which is they're",
    "start": "113159",
    "end": "115799"
  },
  {
    "text": "often smaller and cheaper to run and",
    "start": "115799",
    "end": "119159"
  },
  {
    "text": "they more importantly they give you more",
    "start": "119159",
    "end": "121200"
  },
  {
    "text": "control to over your data and your",
    "start": "121200",
    "end": "125219"
  },
  {
    "text": "technology stack in serving them",
    "start": "125219",
    "end": "127799"
  },
  {
    "text": "what is more interesting is that in",
    "start": "127799",
    "end": "130860"
  },
  {
    "text": "recent months we've seen an immense",
    "start": "130860",
    "end": "133440"
  },
  {
    "text": "progress on the open language models",
    "start": "133440",
    "end": "136400"
  },
  {
    "text": "closing the Gap compared to proprietary",
    "start": "136400",
    "end": "139980"
  },
  {
    "text": "models like gpd4 this is a leaderboard",
    "start": "139980",
    "end": "142379"
  },
  {
    "text": "from lmsys kind of an organization UC",
    "start": "142379",
    "end": "146459"
  },
  {
    "text": "Berkeley which kind of keeps track of",
    "start": "146459",
    "end": "148560"
  },
  {
    "text": "the the progress that is made on",
    "start": "148560",
    "end": "151440"
  },
  {
    "text": "language models by evaluating these",
    "start": "151440",
    "end": "153300"
  },
  {
    "text": "models on across a wide range of kind of",
    "start": "153300",
    "end": "156660"
  },
  {
    "text": "tasks and then puts them on this",
    "start": "156660",
    "end": "158700"
  },
  {
    "text": "leaderboard",
    "start": "158700",
    "end": "159959"
  },
  {
    "text": "llama2 models have come very close to",
    "start": "159959",
    "end": "162780"
  },
  {
    "text": "kind of like GPD 3.5 and other property",
    "start": "162780",
    "end": "167280"
  },
  {
    "text": "models",
    "start": "167280",
    "end": "169760"
  },
  {
    "text": "um but one of the kind of problems that",
    "start": "169860",
    "end": "173160"
  },
  {
    "text": "exists like in these language models you",
    "start": "173160",
    "end": "175379"
  },
  {
    "text": "can categorize them into two subsets",
    "start": "175379",
    "end": "177680"
  },
  {
    "text": "they're often like when these models",
    "start": "177680",
    "end": "180360"
  },
  {
    "text": "produce like completions what they",
    "start": "180360",
    "end": "184680"
  },
  {
    "text": "output is oftentimes not factually",
    "start": "184680",
    "end": "187440"
  },
  {
    "text": "grounded they often hallucinate and make",
    "start": "187440",
    "end": "190080"
  },
  {
    "text": "things up",
    "start": "190080",
    "end": "191459"
  },
  {
    "text": "and there's another category of problems",
    "start": "191459",
    "end": "194040"
  },
  {
    "text": "which is they often don't follow the",
    "start": "194040",
    "end": "196739"
  },
  {
    "text": "format that you have in your mind or",
    "start": "196739",
    "end": "198900"
  },
  {
    "text": "like in intent and to use these language",
    "start": "198900",
    "end": "201540"
  },
  {
    "text": "models for this figure kind of shows a",
    "start": "201540",
    "end": "205200"
  },
  {
    "text": "spectrum of techniques that kind of try",
    "start": "205200",
    "end": "207420"
  },
  {
    "text": "to address these two types of problems",
    "start": "207420",
    "end": "210239"
  },
  {
    "text": "on the bottom we've got prompt tuning or",
    "start": "210239",
    "end": "213420"
  },
  {
    "text": "prompt engineering and then few shot",
    "start": "213420",
    "end": "214920"
  },
  {
    "text": "prompting we have fine tuning which",
    "start": "214920",
    "end": "217739"
  },
  {
    "text": "addresses following a form problem",
    "start": "217739",
    "end": "221640"
  },
  {
    "text": "um and then we've got retrieval",
    "start": "221640",
    "end": "223140"
  },
  {
    "text": "assistant generation which explicitly",
    "start": "223140",
    "end": "225060"
  },
  {
    "text": "addresses the hallucination and on top",
    "start": "225060",
    "end": "227459"
  },
  {
    "text": "we've got reinforcement learning and",
    "start": "227459",
    "end": "228959"
  },
  {
    "text": "training from scratch which are kind of",
    "start": "228959",
    "end": "231060"
  },
  {
    "text": "like more complex and only available to",
    "start": "231060",
    "end": "233819"
  },
  {
    "text": "a few companies today we're going to",
    "start": "233819",
    "end": "236040"
  },
  {
    "text": "talk about fine-tuning and how it",
    "start": "236040",
    "end": "238560"
  },
  {
    "text": "addresses the form problems with these",
    "start": "238560",
    "end": "240780"
  },
  {
    "text": "language models",
    "start": "240780",
    "end": "243060"
  },
  {
    "text": "so why fine-tune language models in the",
    "start": "243060",
    "end": "247080"
  },
  {
    "text": "next few slides I'm going to cover a few",
    "start": "247080",
    "end": "249480"
  },
  {
    "text": "reasons that show that highlights that",
    "start": "249480",
    "end": "252239"
  },
  {
    "text": "shows the benefits of fine-tune language",
    "start": "252239",
    "end": "254400"
  },
  {
    "text": "models",
    "start": "254400",
    "end": "255900"
  },
  {
    "text": "first thing to point out is few shot",
    "start": "255900",
    "end": "258780"
  },
  {
    "text": "prompting is a technique that enables in",
    "start": "258780",
    "end": "261840"
  },
  {
    "text": "context learning meaning that we found",
    "start": "261840",
    "end": "264960"
  },
  {
    "text": "that like you can in language models you",
    "start": "264960",
    "end": "268440"
  },
  {
    "text": "can provide a few examples of desired",
    "start": "268440",
    "end": "270600"
  },
  {
    "text": "input outputs and fit them into the",
    "start": "270600",
    "end": "273000"
  },
  {
    "text": "context of these language models as",
    "start": "273000",
    "end": "275340"
  },
  {
    "text": "input and have them model generalize",
    "start": "275340",
    "end": "277860"
  },
  {
    "text": "that same pattern matching to unseen",
    "start": "277860",
    "end": "281180"
  },
  {
    "text": "data points",
    "start": "281180",
    "end": "283259"
  },
  {
    "text": "but there are often many times that your",
    "start": "283259",
    "end": "285780"
  },
  {
    "text": "data is huge and doesn't fit The Limited",
    "start": "285780",
    "end": "289080"
  },
  {
    "text": "context window that these language",
    "start": "289080",
    "end": "290699"
  },
  {
    "text": "models provide",
    "start": "290699",
    "end": "292320"
  },
  {
    "text": "so in this case in these scenarios what",
    "start": "292320",
    "end": "295139"
  },
  {
    "text": "you can do is instead of putting these",
    "start": "295139",
    "end": "298680"
  },
  {
    "text": "examples into the context bake them into",
    "start": "298680",
    "end": "301020"
  },
  {
    "text": "the neural network rates that",
    "start": "301020",
    "end": "303780"
  },
  {
    "text": "essentially present the internal",
    "start": "303780",
    "end": "305699"
  },
  {
    "text": "knowledge of these language models",
    "start": "305699",
    "end": "309259"
  },
  {
    "text": "um another reason to think about",
    "start": "309600",
    "end": "311220"
  },
  {
    "text": "fine-tuning is there are a lot of tasks",
    "start": "311220",
    "end": "314220"
  },
  {
    "text": "that are hard to describe in words some",
    "start": "314220",
    "end": "317820"
  },
  {
    "text": "of these like subtleties go around like",
    "start": "317820",
    "end": "320820"
  },
  {
    "text": "formatting out the output is a specific",
    "start": "320820",
    "end": "323100"
  },
  {
    "text": "output format that you have in mind or",
    "start": "323100",
    "end": "325740"
  },
  {
    "text": "having the model generate something in a",
    "start": "325740",
    "end": "328259"
  },
  {
    "text": "specific tone you may attempt to fix",
    "start": "328259",
    "end": "330720"
  },
  {
    "text": "these by prompting with phrases like",
    "start": "330720",
    "end": "333600"
  },
  {
    "text": "output this thing in this Json format or",
    "start": "333600",
    "end": "336500"
  },
  {
    "text": "like put something like the final answer",
    "start": "336500",
    "end": "339000"
  },
  {
    "text": "in this integer format that I want to",
    "start": "339000",
    "end": "341039"
  },
  {
    "text": "parse later in my software",
    "start": "341039",
    "end": "343340"
  },
  {
    "text": "but there are often many times that",
    "start": "343340",
    "end": "346620"
  },
  {
    "text": "language models don't respect these kind",
    "start": "346620",
    "end": "349139"
  },
  {
    "text": "of like phrases and you may need to",
    "start": "349139",
    "end": "351180"
  },
  {
    "text": "provide several examples to kind of",
    "start": "351180",
    "end": "353580"
  },
  {
    "text": "reinforce what you mean",
    "start": "353580",
    "end": "355800"
  },
  {
    "text": "um in the following a specific tone",
    "start": "355800",
    "end": "358440"
  },
  {
    "text": "another example is like you may say",
    "start": "358440",
    "end": "360300"
  },
  {
    "text": "something like hey write this in a",
    "start": "360300",
    "end": "362460"
  },
  {
    "text": "concise respectful or helpful manual",
    "start": "362460",
    "end": "364440"
  },
  {
    "text": "manner without being explicit what these",
    "start": "364440",
    "end": "367680"
  },
  {
    "text": "kind of words mean and you may need to",
    "start": "367680",
    "end": "370259"
  },
  {
    "text": "again provide some examples what these",
    "start": "370259",
    "end": "373020"
  },
  {
    "text": "words mean for the model",
    "start": "373020",
    "end": "375539"
  },
  {
    "text": "so with fine tuning we can actually",
    "start": "375539",
    "end": "377400"
  },
  {
    "text": "leverage a lot of illustrations and bake",
    "start": "377400",
    "end": "380580"
  },
  {
    "text": "that into the internal knowledge of the",
    "start": "380580",
    "end": "382560"
  },
  {
    "text": "model",
    "start": "382560",
    "end": "384060"
  },
  {
    "text": "it can also save you tokens",
    "start": "384060",
    "end": "386460"
  },
  {
    "text": "um there are many applications that you",
    "start": "386460",
    "end": "388259"
  },
  {
    "text": "can get away with prompt engineering but",
    "start": "388259",
    "end": "390780"
  },
  {
    "text": "oftentimes this prompt end up being too",
    "start": "390780",
    "end": "393419"
  },
  {
    "text": "wordy or verbose with many examples",
    "start": "393419",
    "end": "396180"
  },
  {
    "text": "but what what thing the thing that you",
    "start": "396180",
    "end": "398520"
  },
  {
    "text": "have to keep in mind",
    "start": "398520",
    "end": "399900"
  },
  {
    "text": "is if you want to run this in production",
    "start": "399900",
    "end": "402860"
  },
  {
    "text": "for every single request and every input",
    "start": "402860",
    "end": "405900"
  },
  {
    "text": "token output token that you want to",
    "start": "405900",
    "end": "407520"
  },
  {
    "text": "generate you have to fit in the scene",
    "start": "407520",
    "end": "409680"
  },
  {
    "text": "the same context scene and you're going",
    "start": "409680",
    "end": "411780"
  },
  {
    "text": "to have to perform computation on it so",
    "start": "411780",
    "end": "414479"
  },
  {
    "text": "if you have cases where this is too",
    "start": "414479",
    "end": "417660"
  },
  {
    "text": "verbose it's going to actually incur a",
    "start": "417660",
    "end": "419759"
  },
  {
    "text": "lot of cost during deployment with fine",
    "start": "419759",
    "end": "422160"
  },
  {
    "text": "tuning you can kind of implicitly bake",
    "start": "422160",
    "end": "425160"
  },
  {
    "text": "that this prompt again into the",
    "start": "425160",
    "end": "426780"
  },
  {
    "text": "knowledge of the network and get away",
    "start": "426780",
    "end": "428580"
  },
  {
    "text": "with like a cheaper serving cost",
    "start": "428580",
    "end": "431580"
  },
  {
    "text": "and last but not least as we show later",
    "start": "431580",
    "end": "434880"
  },
  {
    "text": "in the talk",
    "start": "434880",
    "end": "436139"
  },
  {
    "text": "with fine tuning you can oftentimes get",
    "start": "436139",
    "end": "439080"
  },
  {
    "text": "a faster cheaper model",
    "start": "439080",
    "end": "441300"
  },
  {
    "text": "at the same quality for some of the",
    "start": "441300",
    "end": "443520"
  },
  {
    "text": "niche tasks compared to let's say larger",
    "start": "443520",
    "end": "446880"
  },
  {
    "text": "models or even gpd4 in some cases",
    "start": "446880",
    "end": "450120"
  },
  {
    "text": "um so this is a plot that I think you",
    "start": "450120",
    "end": "452759"
  },
  {
    "text": "guys have seen already in the Keynotes",
    "start": "452759",
    "end": "455099"
  },
  {
    "text": "and other talks here which kind of",
    "start": "455099",
    "end": "457560"
  },
  {
    "text": "demonstrates an example of what we mean",
    "start": "457560",
    "end": "459840"
  },
  {
    "text": "by Niche test like a SQL data generation",
    "start": "459840",
    "end": "462780"
  },
  {
    "text": "how we can",
    "start": "462780",
    "end": "464300"
  },
  {
    "text": "fine-tune these small models to kind of",
    "start": "464300",
    "end": "466860"
  },
  {
    "text": "outperform other powerful models for",
    "start": "466860",
    "end": "469139"
  },
  {
    "text": "this specific task",
    "start": "469139",
    "end": "471180"
  },
  {
    "text": "we're gonna cover more about like more",
    "start": "471180",
    "end": "473580"
  },
  {
    "text": "of the experimentation side later in the",
    "start": "473580",
    "end": "475500"
  },
  {
    "text": "top",
    "start": "475500",
    "end": "477440"
  },
  {
    "text": "now I want to just highlight and briefly",
    "start": "477440",
    "end": "480360"
  },
  {
    "text": "talk about how Rey kind of fits into",
    "start": "480360",
    "end": "482940"
  },
  {
    "text": "this picture",
    "start": "482940",
    "end": "484020"
  },
  {
    "text": "and there's a great talk that was",
    "start": "484020",
    "end": "487160"
  },
  {
    "text": "presented by June Sean yesterday that",
    "start": "487160",
    "end": "490020"
  },
  {
    "text": "dives deeper into how raytrain is a",
    "start": "490020",
    "end": "493199"
  },
  {
    "text": "production ready library for distributed",
    "start": "493199",
    "end": "495060"
  },
  {
    "text": "deep learning I'm not gonna cover",
    "start": "495060",
    "end": "498180"
  },
  {
    "text": "um as much details but I'm gonna just",
    "start": "498180",
    "end": "500099"
  },
  {
    "text": "highlight some of the features that",
    "start": "500099",
    "end": "502440"
  },
  {
    "text": "makes raytrain great for this type of",
    "start": "502440",
    "end": "505680"
  },
  {
    "text": "workload",
    "start": "505680",
    "end": "507780"
  },
  {
    "text": "um so what is rate train rate train in",
    "start": "507780",
    "end": "509819"
  },
  {
    "text": "my opinion is the best framework for",
    "start": "509819",
    "end": "511500"
  },
  {
    "text": "orchestrating multi-process training",
    "start": "511500",
    "end": "514140"
  },
  {
    "text": "workload and here is why",
    "start": "514140",
    "end": "516919"
  },
  {
    "text": "first of all it provides a very simple",
    "start": "516919",
    "end": "519779"
  },
  {
    "text": "API 100 pythonic that you can take",
    "start": "519779",
    "end": "523860"
  },
  {
    "text": "existing python code in your favorite",
    "start": "523860",
    "end": "525839"
  },
  {
    "text": "framework and just integrate it with",
    "start": "525839",
    "end": "527640"
  },
  {
    "text": "great train to distribute it across your",
    "start": "527640",
    "end": "529260"
  },
  {
    "text": "cluster",
    "start": "529260",
    "end": "531180"
  },
  {
    "text": "um plus it has also seamless integration",
    "start": "531180",
    "end": "533779"
  },
  {
    "text": "with other libraries in the repo system",
    "start": "533779",
    "end": "536700"
  },
  {
    "text": "like Ray data that provides distributed",
    "start": "536700",
    "end": "540240"
  },
  {
    "text": "data ingestion which can be very helpful",
    "start": "540240",
    "end": "542160"
  },
  {
    "text": "when you have when you're dealing with",
    "start": "542160",
    "end": "543660"
  },
  {
    "text": "large data sets",
    "start": "543660",
    "end": "546120"
  },
  {
    "text": "it provides Tools around faster",
    "start": "546120",
    "end": "548640"
  },
  {
    "text": "development",
    "start": "548640",
    "end": "550200"
  },
  {
    "text": "um for example it automatically sets up",
    "start": "550200",
    "end": "552180"
  },
  {
    "text": "distributed environments so that these",
    "start": "552180",
    "end": "555120"
  },
  {
    "text": "lower level libraries like Cuda Nico",
    "start": "555120",
    "end": "557459"
  },
  {
    "text": "these things can communicate to each",
    "start": "557459",
    "end": "559140"
  },
  {
    "text": "other and as an ml developer you have",
    "start": "559140",
    "end": "561540"
  },
  {
    "text": "you don't have to think about them and",
    "start": "561540",
    "end": "563399"
  },
  {
    "text": "just can focus on your model training",
    "start": "563399",
    "end": "565860"
  },
  {
    "text": "and you know lost scares and things like",
    "start": "565860",
    "end": "568560"
  },
  {
    "text": "that",
    "start": "568560",
    "end": "570240"
  },
  {
    "text": "um",
    "start": "570240",
    "end": "571140"
  },
  {
    "text": "another way to look at raytrain is that",
    "start": "571140",
    "end": "573540"
  },
  {
    "text": "it is a simple and elegant Java",
    "start": "573540",
    "end": "575760"
  },
  {
    "text": "scheduling with features like Auto",
    "start": "575760",
    "end": "577440"
  },
  {
    "text": "scaling or support for heterogeneous",
    "start": "577440",
    "end": "580320"
  },
  {
    "text": "resources you can actually survive in",
    "start": "580320",
    "end": "584640"
  },
  {
    "text": "today's world where like gpus are very",
    "start": "584640",
    "end": "586860"
  },
  {
    "text": "scarce and there's like capacity issues",
    "start": "586860",
    "end": "590100"
  },
  {
    "text": "at reservation you can put together",
    "start": "590100",
    "end": "592339"
  },
  {
    "text": "heterogeneous clusters and get unblocked",
    "start": "592339",
    "end": "595740"
  },
  {
    "text": "when you're training something in",
    "start": "595740",
    "end": "597000"
  },
  {
    "text": "development",
    "start": "597000",
    "end": "598200"
  },
  {
    "text": "and last but not least there is a lot of",
    "start": "598200",
    "end": "600660"
  },
  {
    "text": "observability tools built around gray",
    "start": "600660",
    "end": "603480"
  },
  {
    "text": "that helps us like easily debug",
    "start": "603480",
    "end": "606420"
  },
  {
    "text": "distributed applications and unblock",
    "start": "606420",
    "end": "608399"
  },
  {
    "text": "ourselves",
    "start": "608399",
    "end": "610820"
  },
  {
    "text": "um yeah so now that we talked about",
    "start": "611100",
    "end": "614459"
  },
  {
    "text": "um kind of the infrastructure side and",
    "start": "614459",
    "end": "616320"
  },
  {
    "text": "why we should do fine tuning let's talk",
    "start": "616320",
    "end": "619380"
  },
  {
    "text": "about what it takes to do fine tuning",
    "start": "619380",
    "end": "621540"
  },
  {
    "text": "how do we set up problems for",
    "start": "621540",
    "end": "623399"
  },
  {
    "text": "fine-tuning language models",
    "start": "623399",
    "end": "625320"
  },
  {
    "text": "so there are two main pillars that you",
    "start": "625320",
    "end": "628200"
  },
  {
    "text": "have to think about very carefully when",
    "start": "628200",
    "end": "630420"
  },
  {
    "text": "you want to set up a fine tuning problem",
    "start": "630420",
    "end": "632899"
  },
  {
    "text": "obviously there is data collection and",
    "start": "632899",
    "end": "635160"
  },
  {
    "text": "formatting and I want to really",
    "start": "635160",
    "end": "637320"
  },
  {
    "text": "highlight the importance of evaluation",
    "start": "637320",
    "end": "641040"
  },
  {
    "text": "so to concrete to crystallize these",
    "start": "641040",
    "end": "644640"
  },
  {
    "text": "things into concrete examples we're",
    "start": "644640",
    "end": "646500"
  },
  {
    "text": "going to use this natural language to",
    "start": "646500",
    "end": "647940"
  },
  {
    "text": "SQL query generation",
    "start": "647940",
    "end": "650839"
  },
  {
    "text": "so data set quality is crucial I think",
    "start": "650839",
    "end": "654839"
  },
  {
    "text": "you've heard it already from even Adobe",
    "start": "654839",
    "end": "657480"
  },
  {
    "text": "stock here",
    "start": "657480",
    "end": "658800"
  },
  {
    "text": "um in generative AI data set is kind of",
    "start": "658800",
    "end": "662100"
  },
  {
    "text": "the king and you have to invest a lot of",
    "start": "662100",
    "end": "664260"
  },
  {
    "text": "time in it to make sure you've got high",
    "start": "664260",
    "end": "666420"
  },
  {
    "text": "quality curated data that captures your",
    "start": "666420",
    "end": "669060"
  },
  {
    "text": "intention of how these language models",
    "start": "669060",
    "end": "670980"
  },
  {
    "text": "should behave",
    "start": "670980",
    "end": "672360"
  },
  {
    "text": "so in SQL generation",
    "start": "672360",
    "end": "675360"
  },
  {
    "text": "um we've the examples are formatted like",
    "start": "675360",
    "end": "677940"
  },
  {
    "text": "this you have like a natural language",
    "start": "677940",
    "end": "679380"
  },
  {
    "text": "statement that poses a question about a",
    "start": "679380",
    "end": "682860"
  },
  {
    "text": "data set and there is like a table",
    "start": "682860",
    "end": "684899"
  },
  {
    "text": "schema presented by a bunch of tables",
    "start": "684899",
    "end": "687540"
  },
  {
    "text": "and then",
    "start": "687540",
    "end": "688560"
  },
  {
    "text": "um like variable names and what data",
    "start": "688560",
    "end": "691440"
  },
  {
    "text": "type they have and then at the end a",
    "start": "691440",
    "end": "693720"
  },
  {
    "text": "desired query that you want these models",
    "start": "693720",
    "end": "695820"
  },
  {
    "text": "to generate",
    "start": "695820",
    "end": "697079"
  },
  {
    "text": "it's very important to make sure these",
    "start": "697079",
    "end": "700200"
  },
  {
    "text": "data sets are clean V for this type of",
    "start": "700200",
    "end": "702420"
  },
  {
    "text": "study we did a lot of data curation",
    "start": "702420",
    "end": "705000"
  },
  {
    "text": "manually went through all these data",
    "start": "705000",
    "end": "707519"
  },
  {
    "text": "sets make sure kind of understood what",
    "start": "707519",
    "end": "710220"
  },
  {
    "text": "are the common errors in the data set",
    "start": "710220",
    "end": "712560"
  },
  {
    "text": "fixed them filter them to make sure for",
    "start": "712560",
    "end": "715500"
  },
  {
    "text": "example table names makes sense they",
    "start": "715500",
    "end": "717779"
  },
  {
    "text": "represent what the underlying data is",
    "start": "717779",
    "end": "721320"
  },
  {
    "text": "um data types match for example the",
    "start": "721320",
    "end": "724200"
  },
  {
    "text": "query that is generated so to get these",
    "start": "724200",
    "end": "727680"
  },
  {
    "text": "good results you gotta curate your data",
    "start": "727680",
    "end": "730440"
  },
  {
    "text": "and I can emphasize it enough just by",
    "start": "730440",
    "end": "733320"
  },
  {
    "text": "one like slides",
    "start": "733320",
    "end": "735140"
  },
  {
    "text": "next",
    "start": "735140",
    "end": "736680"
  },
  {
    "text": "thing that you have to think about the",
    "start": "736680",
    "end": "738360"
  },
  {
    "text": "data is",
    "start": "738360",
    "end": "740700"
  },
  {
    "text": "um and this is kind of an important one",
    "start": "740700",
    "end": "742500"
  },
  {
    "text": "is the way that you kind of format them",
    "start": "742500",
    "end": "744959"
  },
  {
    "text": "during training is going to impact how",
    "start": "744959",
    "end": "747060"
  },
  {
    "text": "you want to use them like ask the model",
    "start": "747060",
    "end": "750180"
  },
  {
    "text": "to do something so training and",
    "start": "750180",
    "end": "752880"
  },
  {
    "text": "inference data format should be very",
    "start": "752880",
    "end": "755279"
  },
  {
    "text": "consistent with each other",
    "start": "755279",
    "end": "756959"
  },
  {
    "text": "so I'm going to give you an example in",
    "start": "756959",
    "end": "758640"
  },
  {
    "text": "this SQL generation imagine my training",
    "start": "758640",
    "end": "761100"
  },
  {
    "text": "data set I structure all my examples",
    "start": "761100",
    "end": "763860"
  },
  {
    "text": "like this write a SQL query to answer",
    "start": "763860",
    "end": "766079"
  },
  {
    "text": "this question based on a table schema",
    "start": "766079",
    "end": "767940"
  },
  {
    "text": "followed by two new line symbols context",
    "start": "767940",
    "end": "771120"
  },
  {
    "text": "two new line against symbols and then",
    "start": "771120",
    "end": "773220"
  },
  {
    "text": "the question",
    "start": "773220",
    "end": "774300"
  },
  {
    "text": "and then have the model learn how to",
    "start": "774300",
    "end": "776100"
  },
  {
    "text": "Output the kind of corresponding query",
    "start": "776100",
    "end": "779760"
  },
  {
    "text": "I go ahead and train a model with this",
    "start": "779760",
    "end": "782040"
  },
  {
    "text": "but at inference time I come back and",
    "start": "782040",
    "end": "784139"
  },
  {
    "text": "ask the model the same question but in a",
    "start": "784139",
    "end": "786180"
  },
  {
    "text": "different format like here is a database",
    "start": "786180",
    "end": "789000"
  },
  {
    "text": "maybe I don't specify the schema",
    "start": "789000",
    "end": "792120"
  },
  {
    "text": "and then I ask it hey convert the",
    "start": "792120",
    "end": "794160"
  },
  {
    "text": "following to a SQL command like show",
    "start": "794160",
    "end": "796920"
  },
  {
    "text": "names blah blah and then when I see what",
    "start": "796920",
    "end": "799920"
  },
  {
    "text": "the model produces it's kind of like",
    "start": "799920",
    "end": "801720"
  },
  {
    "text": "wrong in subtle senses like it doesn't",
    "start": "801720",
    "end": "804720"
  },
  {
    "text": "it for example forgets the name of the",
    "start": "804720",
    "end": "807540"
  },
  {
    "text": "the schema or it doesn't do this order",
    "start": "807540",
    "end": "809940"
  },
  {
    "text": "by like descending",
    "start": "809940",
    "end": "811760"
  },
  {
    "text": "but",
    "start": "811760",
    "end": "813300"
  },
  {
    "text": "the reason behind like this thing is",
    "start": "813300",
    "end": "816240"
  },
  {
    "text": "that you have to think about how the",
    "start": "816240",
    "end": "817980"
  },
  {
    "text": "model has seen the data before it has",
    "start": "817980",
    "end": "819899"
  },
  {
    "text": "only seen the data in this particular",
    "start": "819899",
    "end": "822540"
  },
  {
    "text": "format and then you're throwing it at it",
    "start": "822540",
    "end": "825240"
  },
  {
    "text": "like a new kind of format of data which",
    "start": "825240",
    "end": "827820"
  },
  {
    "text": "kind of gets to converted to new symbols",
    "start": "827820",
    "end": "830279"
  },
  {
    "text": "that this model may not even recognize",
    "start": "830279",
    "end": "832680"
  },
  {
    "text": "and may generalize may not generalize",
    "start": "832680",
    "end": "835200"
  },
  {
    "text": "very well too",
    "start": "835200",
    "end": "836639"
  },
  {
    "text": "so it's very important",
    "start": "836639",
    "end": "839700"
  },
  {
    "text": "um to kind of have a consistent format",
    "start": "839700",
    "end": "842579"
  },
  {
    "text": "when you're actually running inference",
    "start": "842579",
    "end": "844260"
  },
  {
    "text": "on training on these models or if you",
    "start": "844260",
    "end": "847320"
  },
  {
    "text": "want to have variations in the type of",
    "start": "847320",
    "end": "849240"
  },
  {
    "text": "like data that goes into inference you",
    "start": "849240",
    "end": "851220"
  },
  {
    "text": "have to have the same type of variation",
    "start": "851220",
    "end": "852899"
  },
  {
    "text": "in your data as well so these models",
    "start": "852899",
    "end": "854940"
  },
  {
    "text": "learn to be robust to those type of",
    "start": "854940",
    "end": "856800"
  },
  {
    "text": "variations",
    "start": "856800",
    "end": "859279"
  },
  {
    "text": "and now I want to talk about a little",
    "start": "859380",
    "end": "861420"
  },
  {
    "text": "bit about setting up evaluation",
    "start": "861420",
    "end": "863700"
  },
  {
    "text": "Pipelines",
    "start": "863700",
    "end": "865079"
  },
  {
    "text": "this example is kind of very specific to",
    "start": "865079",
    "end": "867420"
  },
  {
    "text": "the SQL generation but it kind of",
    "start": "867420",
    "end": "870680"
  },
  {
    "text": "inspires other ways to think about it so",
    "start": "870680",
    "end": "874620"
  },
  {
    "text": "for see let's talk about SQL so SQL like",
    "start": "874620",
    "end": "877500"
  },
  {
    "text": "you your model output something like",
    "start": "877500",
    "end": "879600"
  },
  {
    "text": "select block and then you have a",
    "start": "879600",
    "end": "881579"
  },
  {
    "text": "reference output that you want to check",
    "start": "881579",
    "end": "883019"
  },
  {
    "text": "whether the model what model generated",
    "start": "883019",
    "end": "884820"
  },
  {
    "text": "is equivalent to",
    "start": "884820",
    "end": "886440"
  },
  {
    "text": "there are cases there are like this is a",
    "start": "886440",
    "end": "888899"
  },
  {
    "text": "contrived example but this kind of",
    "start": "888899",
    "end": "890579"
  },
  {
    "text": "greatly captures the nuances behind this",
    "start": "890579",
    "end": "893220"
  },
  {
    "text": "task it's very complicated to ensure",
    "start": "893220",
    "end": "895139"
  },
  {
    "text": "whether what the model outputted is",
    "start": "895139",
    "end": "897540"
  },
  {
    "text": "consistent or the same as the reference",
    "start": "897540",
    "end": "900360"
  },
  {
    "text": "output you cannot do character for",
    "start": "900360",
    "end": "902639"
  },
  {
    "text": "character matching you cannot do more",
    "start": "902639",
    "end": "906120"
  },
  {
    "text": "complex methods like abstract syntax",
    "start": "906120",
    "end": "908339"
  },
  {
    "text": "stream matching maybe you have like",
    "start": "908339",
    "end": "909839"
  },
  {
    "text": "expressions Math Expressions that are",
    "start": "909839",
    "end": "912000"
  },
  {
    "text": "equivalent but look different than this",
    "start": "912000",
    "end": "915060"
  },
  {
    "text": "a steam matching method would also not",
    "start": "915060",
    "end": "916980"
  },
  {
    "text": "work out well",
    "start": "916980",
    "end": "918300"
  },
  {
    "text": "uh what we did here was to use gpt4",
    "start": "918300",
    "end": "921899"
  },
  {
    "text": "actually a powerful model",
    "start": "921899",
    "end": "924000"
  },
  {
    "text": "although it costs you can cost and it",
    "start": "924000",
    "end": "927360"
  },
  {
    "text": "can become expensive you're doing an",
    "start": "927360",
    "end": "928980"
  },
  {
    "text": "evaluation pipeline so it's like a",
    "start": "928980",
    "end": "930600"
  },
  {
    "text": "one-time cost that you can pay up front",
    "start": "930600",
    "end": "932220"
  },
  {
    "text": "to set up evaluation pipelines that are",
    "start": "932220",
    "end": "934680"
  },
  {
    "text": "that you kind of keep consistent",
    "start": "934680",
    "end": "936600"
  },
  {
    "text": "throughout your experimentation",
    "start": "936600",
    "end": "939300"
  },
  {
    "text": "so what we did here was we asked chat",
    "start": "939300",
    "end": "942440"
  },
  {
    "text": "gpt4 to create a bunch of mock tables",
    "start": "942440",
    "end": "946680"
  },
  {
    "text": "their like conditioned on for example",
    "start": "946680",
    "end": "948959"
  },
  {
    "text": "the the reference output and the table",
    "start": "948959",
    "end": "951060"
  },
  {
    "text": "schema where if we ran the reference",
    "start": "951060",
    "end": "954839"
  },
  {
    "text": "output against we could check what got",
    "start": "954839",
    "end": "957660"
  },
  {
    "text": "um as a as what came out as a result of",
    "start": "957660",
    "end": "960000"
  },
  {
    "text": "running that query would match the same",
    "start": "960000",
    "end": "962399"
  },
  {
    "text": "thing that would come out as there is",
    "start": "962399",
    "end": "965220"
  },
  {
    "text": "running the like the model output",
    "start": "965220",
    "end": "967199"
  },
  {
    "text": "against the same mod table so by doing",
    "start": "967199",
    "end": "969899"
  },
  {
    "text": "so we kind of curated and handcrafted",
    "start": "969899",
    "end": "973260"
  },
  {
    "text": "maybe like 200 300 examples of such unit",
    "start": "973260",
    "end": "976680"
  },
  {
    "text": "tests where we could like run all of our",
    "start": "976680",
    "end": "979680"
  },
  {
    "text": "experimentations against and make sure",
    "start": "979680",
    "end": "981540"
  },
  {
    "text": "we've got like consistent evaluation",
    "start": "981540",
    "end": "983279"
  },
  {
    "text": "pipeline in a scalable way when we are",
    "start": "983279",
    "end": "986220"
  },
  {
    "text": "experimenting with this like fine tuning",
    "start": "986220",
    "end": "988440"
  },
  {
    "text": "tasks",
    "start": "988440",
    "end": "989579"
  },
  {
    "text": "so",
    "start": "989579",
    "end": "991199"
  },
  {
    "text": "um the takeaway from this is that there",
    "start": "991199",
    "end": "994260"
  },
  {
    "text": "are tasks out there that you may want to",
    "start": "994260",
    "end": "996300"
  },
  {
    "text": "apply fine-tuning to that",
    "start": "996300",
    "end": "999680"
  },
  {
    "text": "evacuating and evaluation may be a hard",
    "start": "999680",
    "end": "1002180"
  },
  {
    "text": "thing to do but you can leverage these",
    "start": "1002180",
    "end": "1005480"
  },
  {
    "text": "like more powerful models to kind of",
    "start": "1005480",
    "end": "1007459"
  },
  {
    "text": "automate that part and take some of the",
    "start": "1007459",
    "end": "1009620"
  },
  {
    "text": "human effort out of the the loop",
    "start": "1009620",
    "end": "1013720"
  },
  {
    "text": "now let's talk about some of the",
    "start": "1013940",
    "end": "1016339"
  },
  {
    "text": "learnings we had from running these",
    "start": "1016339",
    "end": "1018800"
  },
  {
    "text": "experiments on llama2 models",
    "start": "1018800",
    "end": "1022220"
  },
  {
    "text": "so",
    "start": "1022220",
    "end": "1023779"
  },
  {
    "text": "um this spot was kind of shown in the",
    "start": "1023779",
    "end": "1026660"
  },
  {
    "text": "keynote as well",
    "start": "1026660",
    "end": "1027980"
  },
  {
    "text": "um we have",
    "start": "1027980",
    "end": "1030199"
  },
  {
    "text": "applied fine tuning to kind of several",
    "start": "1030199",
    "end": "1033079"
  },
  {
    "text": "tasks that we thought might be relevant",
    "start": "1033079",
    "end": "1035360"
  },
  {
    "text": "to what other people might want to do",
    "start": "1035360",
    "end": "1038418"
  },
  {
    "text": "with these language models I already",
    "start": "1038419",
    "end": "1041360"
  },
  {
    "text": "talked about the SQL generation task in",
    "start": "1041360",
    "end": "1043579"
  },
  {
    "text": "the in details in the middle that's",
    "start": "1043579",
    "end": "1045860"
  },
  {
    "text": "that's what's shown in the middle",
    "start": "1045860",
    "end": "1047480"
  },
  {
    "text": "on the left side we have functional",
    "start": "1047480",
    "end": "1049760"
  },
  {
    "text": "representation which is just a task",
    "start": "1049760",
    "end": "1052760"
  },
  {
    "text": "where you have a",
    "start": "1052760",
    "end": "1054740"
  },
  {
    "text": "like a honestructured text",
    "start": "1054740",
    "end": "1057520"
  },
  {
    "text": "asking a question or like have a comment",
    "start": "1057520",
    "end": "1060440"
  },
  {
    "text": "about something and then your task is to",
    "start": "1060440",
    "end": "1063380"
  },
  {
    "text": "read that text and convert it to a",
    "start": "1063380",
    "end": "1065960"
  },
  {
    "text": "structured data this is a very common",
    "start": "1065960",
    "end": "1068360"
  },
  {
    "text": "tasks that in like Health space where",
    "start": "1068360",
    "end": "1071120"
  },
  {
    "text": "for example doctors write a lot of notes",
    "start": "1071120",
    "end": "1073640"
  },
  {
    "text": "and you have to kind of parse that and",
    "start": "1073640",
    "end": "1075799"
  },
  {
    "text": "extract it in a structured format",
    "start": "1075799",
    "end": "1079039"
  },
  {
    "text": "um and so that's that's basically what",
    "start": "1079039",
    "end": "1081320"
  },
  {
    "text": "is shown here and we've got another task",
    "start": "1081320",
    "end": "1083240"
  },
  {
    "text": "which is more more geared toward",
    "start": "1083240",
    "end": "1086360"
  },
  {
    "text": "um mathematical reasoning and logical",
    "start": "1086360",
    "end": "1087919"
  },
  {
    "text": "reasoning GSM 8K is a data set of around",
    "start": "1087919",
    "end": "1091340"
  },
  {
    "text": "8 000 examples of basic math questions",
    "start": "1091340",
    "end": "1094419"
  },
  {
    "text": "followed by some answer and you want to",
    "start": "1094419",
    "end": "1096559"
  },
  {
    "text": "evaluate better language models can",
    "start": "1096559",
    "end": "1098299"
  },
  {
    "text": "solve this type of task",
    "start": "1098299",
    "end": "1100520"
  },
  {
    "text": "so what is shown here is that these",
    "start": "1100520",
    "end": "1103580"
  },
  {
    "text": "darker bars are",
    "start": "1103580",
    "end": "1106360"
  },
  {
    "text": "the performance and success rate of",
    "start": "1106360",
    "end": "1110780"
  },
  {
    "text": "these like models then fine tune the",
    "start": "1110780",
    "end": "1113840"
  },
  {
    "text": "chat fine-tune models right out of the",
    "start": "1113840",
    "end": "1115820"
  },
  {
    "text": "box so you don't do any specialized fine",
    "start": "1115820",
    "end": "1118760"
  },
  {
    "text": "tuning on them and they compare to gpt4",
    "start": "1118760",
    "end": "1122059"
  },
  {
    "text": "for example they do very poorly",
    "start": "1122059",
    "end": "1124820"
  },
  {
    "text": "they they're not even close to the",
    "start": "1124820",
    "end": "1127160"
  },
  {
    "text": "performance",
    "start": "1127160",
    "end": "1128179"
  },
  {
    "text": "but if you kind of use the training data",
    "start": "1128179",
    "end": "1130700"
  },
  {
    "text": "that is curated for these tasks and then",
    "start": "1130700",
    "end": "1133400"
  },
  {
    "text": "fine-tune these models and then do the",
    "start": "1133400",
    "end": "1135740"
  },
  {
    "text": "evaluation again you'll see that the",
    "start": "1135740",
    "end": "1138679"
  },
  {
    "text": "performance gets boosted so much that it",
    "start": "1138679",
    "end": "1141260"
  },
  {
    "text": "can actually beat gpd4 in these two kind",
    "start": "1141260",
    "end": "1145160"
  },
  {
    "text": "of",
    "start": "1145160",
    "end": "1145880"
  },
  {
    "text": "tasks however",
    "start": "1145880",
    "end": "1147919"
  },
  {
    "text": "in some of the tasks that involve more",
    "start": "1147919",
    "end": "1150740"
  },
  {
    "text": "things than just following a format",
    "start": "1150740",
    "end": "1152360"
  },
  {
    "text": "right math involved requires",
    "start": "1152360",
    "end": "1156080"
  },
  {
    "text": "um more understanding of like reasoning",
    "start": "1156080",
    "end": "1158179"
  },
  {
    "text": "and logic piecing together different",
    "start": "1158179",
    "end": "1161120"
  },
  {
    "text": "piece things about the logic behind the",
    "start": "1161120",
    "end": "1163640"
  },
  {
    "text": "question and although fine-tuning can",
    "start": "1163640",
    "end": "1166700"
  },
  {
    "text": "help get you from let's say I don't know",
    "start": "1166700",
    "end": "1168919"
  },
  {
    "text": "40 to 50 it is still far behind",
    "start": "1168919",
    "end": "1173419"
  },
  {
    "text": "um kind of performance of more powerful",
    "start": "1173419",
    "end": "1175760"
  },
  {
    "text": "and general purpose models like gpt4",
    "start": "1175760",
    "end": "1178760"
  },
  {
    "text": "what this kind of presents is the",
    "start": "1178760",
    "end": "1181700"
  },
  {
    "text": "opportunity for applying fine tuning on",
    "start": "1181700",
    "end": "1185179"
  },
  {
    "text": "these four and following fact tasks like",
    "start": "1185179",
    "end": "1188120"
  },
  {
    "text": "dysfunctional representation or SQL",
    "start": "1188120",
    "end": "1190280"
  },
  {
    "text": "generation are the kind of task that the",
    "start": "1190280",
    "end": "1193100"
  },
  {
    "text": "model does not have to really kind of",
    "start": "1193100",
    "end": "1196100"
  },
  {
    "text": "understand the world or how the work",
    "start": "1196100",
    "end": "1198080"
  },
  {
    "text": "functions they just have to learn how to",
    "start": "1198080",
    "end": "1200299"
  },
  {
    "text": "map like a certain format of input to",
    "start": "1200299",
    "end": "1202760"
  },
  {
    "text": "assert another format in the output and",
    "start": "1202760",
    "end": "1205400"
  },
  {
    "text": "this is where like fine tuning can",
    "start": "1205400",
    "end": "1206900"
  },
  {
    "text": "really help",
    "start": "1206900",
    "end": "1208820"
  },
  {
    "text": "um now I'm gonna hand it off to Archer",
    "start": "1208820",
    "end": "1210980"
  },
  {
    "text": "to talk about learnings from parameter",
    "start": "1210980",
    "end": "1213020"
  },
  {
    "text": "efficient fine tuning right thanks",
    "start": "1213020",
    "end": "1215360"
  },
  {
    "text": "karosh uh hello everyone all right so",
    "start": "1215360",
    "end": "1218120"
  },
  {
    "text": "another we have seen the the value of",
    "start": "1218120",
    "end": "1220460"
  },
  {
    "text": "these models let's talk about parameter",
    "start": "1220460",
    "end": "1223400"
  },
  {
    "text": "for tuning so first first of all what is",
    "start": "1223400",
    "end": "1226160"
  },
  {
    "text": "parameter efficient fine tuning um in in",
    "start": "1226160",
    "end": "1228980"
  },
  {
    "text": "full parameter fine tuning what you do",
    "start": "1228980",
    "end": "1230480"
  },
  {
    "text": "is just a continuation of the training",
    "start": "1230480",
    "end": "1232160"
  },
  {
    "text": "but on Specialized data and parameter",
    "start": "1232160",
    "end": "1235039"
  },
  {
    "text": "efficient fine tuning is the same the",
    "start": "1235039",
    "end": "1236960"
  },
  {
    "text": "same thing but uh your only fine-tuning",
    "start": "1236960",
    "end": "1240679"
  },
  {
    "text": "a small number of parameters so this",
    "start": "1240679",
    "end": "1242240"
  },
  {
    "text": "could be a subset of the parameters of",
    "start": "1242240",
    "end": "1244580"
  },
  {
    "text": "the original model or it could be some",
    "start": "1244580",
    "end": "1246679"
  },
  {
    "text": "additional parameters",
    "start": "1246679",
    "end": "1248179"
  },
  {
    "text": "the point being that it has to be very",
    "start": "1248179",
    "end": "1249799"
  },
  {
    "text": "few parameters and there's a couple of",
    "start": "1249799",
    "end": "1251960"
  },
  {
    "text": "techniques that exist out there to do",
    "start": "1251960",
    "end": "1253760"
  },
  {
    "text": "this and one of these techniques is",
    "start": "1253760",
    "end": "1255740"
  },
  {
    "text": "Laura",
    "start": "1255740",
    "end": "1257360"
  },
  {
    "text": "so Laura means low rank adaptation of",
    "start": "1257360",
    "end": "1259580"
  },
  {
    "text": "LMS and you see here on the left side a",
    "start": "1259580",
    "end": "1262160"
  },
  {
    "text": "kind of schematic of the internals of a",
    "start": "1262160",
    "end": "1265820"
  },
  {
    "text": "transformer and on the right side here",
    "start": "1265820",
    "end": "1267620"
  },
  {
    "text": "you see how Laura works in principle",
    "start": "1267620",
    "end": "1270200"
  },
  {
    "text": "so for any given layer for from the",
    "start": "1270200",
    "end": "1272419"
  },
  {
    "text": "Transformer that is dense so for example",
    "start": "1272419",
    "end": "1274880"
  },
  {
    "text": "like a feed forward layer you can grab",
    "start": "1274880",
    "end": "1276919"
  },
  {
    "text": "that layer and you can apply Laura to it",
    "start": "1276919",
    "end": "1278720"
  },
  {
    "text": "so what does that mean",
    "start": "1278720",
    "end": "1280580"
  },
  {
    "text": "um",
    "start": "1280580",
    "end": "1281179"
  },
  {
    "text": "well you have these pre-trained weights",
    "start": "1281179",
    "end": "1282980"
  },
  {
    "text": "and what you do during training with",
    "start": "1282980",
    "end": "1285020"
  },
  {
    "text": "Laura is you freeze them and you set",
    "start": "1285020",
    "end": "1287179"
  },
  {
    "text": "them aside and this will become quite",
    "start": "1287179",
    "end": "1289220"
  },
  {
    "text": "important later so you set those pre you",
    "start": "1289220",
    "end": "1291440"
  },
  {
    "text": "freeze them and you set them aside and",
    "start": "1291440",
    "end": "1293240"
  },
  {
    "text": "then you add an additional Matrix a",
    "start": "1293240",
    "end": "1296240"
  },
  {
    "text": "times B that can be decomposed into two",
    "start": "1296240",
    "end": "1300679"
  },
  {
    "text": "low rank matrices A and B",
    "start": "1300679",
    "end": "1303020"
  },
  {
    "text": "and these two matrices combined have",
    "start": "1303020",
    "end": "1306440"
  },
  {
    "text": "very few parameters compared to the",
    "start": "1306440",
    "end": "1308780"
  },
  {
    "text": "original parameters the pre-trained",
    "start": "1308780",
    "end": "1310580"
  },
  {
    "text": "weights that you would normally be",
    "start": "1310580",
    "end": "1311900"
  },
  {
    "text": "fine-tuning so this is really where the",
    "start": "1311900",
    "end": "1314059"
  },
  {
    "text": "where the trick is here and this can",
    "start": "1314059",
    "end": "1315440"
  },
  {
    "text": "bring you two things",
    "start": "1315440",
    "end": "1317480"
  },
  {
    "text": "um first of all during training",
    "start": "1317480",
    "end": "1318799"
  },
  {
    "text": "obviously there's a a much smaller",
    "start": "1318799",
    "end": "1321260"
  },
  {
    "text": "Optimizer state to be kept in memory and",
    "start": "1321260",
    "end": "1324140"
  },
  {
    "text": "then second of all you're left with much",
    "start": "1324140",
    "end": "1327080"
  },
  {
    "text": "smaller checkpoints and we'll talk more",
    "start": "1327080",
    "end": "1330020"
  },
  {
    "text": "about this later but let's first talk a",
    "start": "1330020",
    "end": "1332120"
  },
  {
    "text": "little bit more about the quality of the",
    "start": "1332120",
    "end": "1334820"
  },
  {
    "text": "models that we gained out of fine tuning",
    "start": "1334820",
    "end": "1336799"
  },
  {
    "text": "with Laura",
    "start": "1336799",
    "end": "1338419"
  },
  {
    "text": "right so this should look somewhat",
    "start": "1338419",
    "end": "1340159"
  },
  {
    "text": "familiar these are the same tasks that",
    "start": "1340159",
    "end": "1341900"
  },
  {
    "text": "Crush talked about earlier so we have",
    "start": "1341900",
    "end": "1343400"
  },
  {
    "text": "the functional representation test SQL",
    "start": "1343400",
    "end": "1345080"
  },
  {
    "text": "generation and the math task",
    "start": "1345080",
    "end": "1347600"
  },
  {
    "text": "and we added another shade here a medium",
    "start": "1347600",
    "end": "1350299"
  },
  {
    "text": "shade to the to the dark shade that",
    "start": "1350299",
    "end": "1352520"
  },
  {
    "text": "signifies the Baseline and the Light",
    "start": "1352520",
    "end": "1354080"
  },
  {
    "text": "trade that signifies how well full",
    "start": "1354080",
    "end": "1356000"
  },
  {
    "text": "parameter fine-tuning does so we added",
    "start": "1356000",
    "end": "1358520"
  },
  {
    "text": "the medium shade here to signify how",
    "start": "1358520",
    "end": "1360320"
  },
  {
    "text": "well Laura does and you can see for the",
    "start": "1360320",
    "end": "1362360"
  },
  {
    "text": "left two tests for functional",
    "start": "1362360",
    "end": "1363620"
  },
  {
    "text": "representation and SQL generation that",
    "start": "1363620",
    "end": "1365900"
  },
  {
    "text": "Laura did basically almost as well as",
    "start": "1365900",
    "end": "1368240"
  },
  {
    "text": "full parameter fine tuning so the",
    "start": "1368240",
    "end": "1370460"
  },
  {
    "text": "relative difference in accuracy here is",
    "start": "1370460",
    "end": "1372080"
  },
  {
    "text": "like one or two percent",
    "start": "1372080",
    "end": "1373760"
  },
  {
    "text": "and we can learn from this already that",
    "start": "1373760",
    "end": "1376580"
  },
  {
    "text": "with Laura we're able to solve some like",
    "start": "1376580",
    "end": "1379280"
  },
  {
    "text": "real world problems uh very well",
    "start": "1379280",
    "end": "1381740"
  },
  {
    "text": "actually better than uh what we got out",
    "start": "1381740",
    "end": "1383480"
  },
  {
    "text": "of gpt4",
    "start": "1383480",
    "end": "1384860"
  },
  {
    "text": "and",
    "start": "1384860",
    "end": "1386179"
  },
  {
    "text": "um but on the right side you see the",
    "start": "1386179",
    "end": "1388159"
  },
  {
    "text": "math test again where Laura is lacking a",
    "start": "1388159",
    "end": "1390140"
  },
  {
    "text": "little bit behind so for the 13 and 70b",
    "start": "1390140",
    "end": "1392120"
  },
  {
    "text": "parameter models um we're seeing",
    "start": "1392120",
    "end": "1394039"
  },
  {
    "text": "differences of like two or three percent",
    "start": "1394039",
    "end": "1395539"
  },
  {
    "text": "and for the seven billion parameter",
    "start": "1395539",
    "end": "1397640"
  },
  {
    "text": "model",
    "start": "1397640",
    "end": "1398419"
  },
  {
    "text": "um the lack and quality was even greater",
    "start": "1398419",
    "end": "1400820"
  },
  {
    "text": "and our hypothesis around why this might",
    "start": "1400820",
    "end": "1403820"
  },
  {
    "text": "be is that you know like math is",
    "start": "1403820",
    "end": "1406580"
  },
  {
    "text": "generally hard for LMS to do as we know",
    "start": "1406580",
    "end": "1409280"
  },
  {
    "text": "and then Laura is also a more difficult",
    "start": "1409280",
    "end": "1412039"
  },
  {
    "text": "optimization task so since you have much",
    "start": "1412039",
    "end": "1413840"
  },
  {
    "text": "fewer parameters to play with the the",
    "start": "1413840",
    "end": "1416179"
  },
  {
    "text": "optimization landscape is a little more",
    "start": "1416179",
    "end": "1418880"
  },
  {
    "text": "more tricky and this might just add up",
    "start": "1418880",
    "end": "1421580"
  },
  {
    "text": "so something we can maybe learn from",
    "start": "1421580",
    "end": "1423260"
  },
  {
    "text": "this and this has to be seen like in",
    "start": "1423260",
    "end": "1425480"
  },
  {
    "text": "future tasks that we look at is that the",
    "start": "1425480",
    "end": "1427880"
  },
  {
    "text": "performance of Laura might depend a",
    "start": "1427880",
    "end": "1429860"
  },
  {
    "text": "little bit on the type of task that",
    "start": "1429860",
    "end": "1431840"
  },
  {
    "text": "you're looking at",
    "start": "1431840",
    "end": "1433820"
  },
  {
    "text": "right so another thing that we learned",
    "start": "1433820",
    "end": "1435919"
  },
  {
    "text": "with Laura was that it's sensitive to",
    "start": "1435919",
    "end": "1438740"
  },
  {
    "text": "the learning rate so with full parameter",
    "start": "1438740",
    "end": "1441020"
  },
  {
    "text": "fine tuning what you'll find generally",
    "start": "1441020",
    "end": "1442280"
  },
  {
    "text": "is that it's very stable across a wide",
    "start": "1442280",
    "end": "1443840"
  },
  {
    "text": "range of of learning rates",
    "start": "1443840",
    "end": "1445820"
  },
  {
    "text": "and when we use Laura we encountered",
    "start": "1445820",
    "end": "1448760"
  },
  {
    "text": "some instabilities here so a learning",
    "start": "1448760",
    "end": "1450799"
  },
  {
    "text": "rate that you'll see widely used on the",
    "start": "1450799",
    "end": "1452360"
  },
  {
    "text": "Internet is 1e minus four and we use",
    "start": "1452360",
    "end": "1454039"
  },
  {
    "text": "that at first as well and then ran to",
    "start": "1454039",
    "end": "1456080"
  },
  {
    "text": "some of these instabilities and you can",
    "start": "1456080",
    "end": "1457580"
  },
  {
    "text": "see here how just by tweaking they're",
    "start": "1457580",
    "end": "1459679"
  },
  {
    "text": "learning right a little bit we got a",
    "start": "1459679",
    "end": "1461659"
  },
  {
    "text": "much smoother learning curve here in",
    "start": "1461659",
    "end": "1464000"
  },
  {
    "text": "this purple one",
    "start": "1464000",
    "end": "1466340"
  },
  {
    "text": "yeah and then another thing that we did",
    "start": "1466340",
    "end": "1468559"
  },
  {
    "text": "to improve stability was interestingly",
    "start": "1468559",
    "end": "1471640"
  },
  {
    "text": "prompting so what you can do during",
    "start": "1471640",
    "end": "1475280"
  },
  {
    "text": "training and obviously you have to do",
    "start": "1475280",
    "end": "1476900"
  },
  {
    "text": "the same thing during evaluation as",
    "start": "1476900",
    "end": "1478520"
  },
  {
    "text": "career said is you can apply some prompt",
    "start": "1478520",
    "end": "1481159"
  },
  {
    "text": "engineering basically during fine tuning",
    "start": "1481159",
    "end": "1482960"
  },
  {
    "text": "so you you create some helpful context",
    "start": "1482960",
    "end": "1485240"
  },
  {
    "text": "for the model like for example you know",
    "start": "1485240",
    "end": "1487280"
  },
  {
    "text": "you're a helpful assistant this is like",
    "start": "1487280",
    "end": "1490280"
  },
  {
    "text": "a SQL table in the query and stuff like",
    "start": "1490280",
    "end": "1493159"
  },
  {
    "text": "that and then you prepend that to what",
    "start": "1493159",
    "end": "1496880"
  },
  {
    "text": "you're normally inputting to your model",
    "start": "1496880",
    "end": "1499580"
  },
  {
    "text": "and what that leaves you with if you",
    "start": "1499580",
    "end": "1502520"
  },
  {
    "text": "like we fixed everything else here like",
    "start": "1502520",
    "end": "1504980"
  },
  {
    "text": "a seating and learning rate and",
    "start": "1504980",
    "end": "1506840"
  },
  {
    "text": "everything right but what that left us",
    "start": "1506840",
    "end": "1508580"
  },
  {
    "text": "with was",
    "start": "1508580",
    "end": "1509900"
  },
  {
    "text": "um even even smoother",
    "start": "1509900",
    "end": "1511760"
  },
  {
    "text": "um learning curve here the the orange",
    "start": "1511760",
    "end": "1514400"
  },
  {
    "text": "one",
    "start": "1514400",
    "end": "1515659"
  },
  {
    "text": "yeah",
    "start": "1515659",
    "end": "1517220"
  },
  {
    "text": "cool so now um that we've talked about",
    "start": "1517220",
    "end": "1520700"
  },
  {
    "text": "like how well Laura does on these on",
    "start": "1520700",
    "end": "1522919"
  },
  {
    "text": "these problems and that we just might",
    "start": "1522919",
    "end": "1525200"
  },
  {
    "text": "have to tweak it a little bit here and",
    "start": "1525200",
    "end": "1526580"
  },
  {
    "text": "there let's look at the upsides of Laura",
    "start": "1526580",
    "end": "1529279"
  },
  {
    "text": "so first of all as I said in the",
    "start": "1529279",
    "end": "1531740"
  },
  {
    "text": "beginning",
    "start": "1531740",
    "end": "1532520"
  },
  {
    "text": "um the the optimizer state is much",
    "start": "1532520",
    "end": "1535279"
  },
  {
    "text": "smaller right so for the 7 billion",
    "start": "1535279",
    "end": "1537080"
  },
  {
    "text": "parameter model for example that we",
    "start": "1537080",
    "end": "1538460"
  },
  {
    "text": "fine-tuned we were able to fine tune the",
    "start": "1538460",
    "end": "1540559"
  },
  {
    "text": "seven billion parameter model",
    "start": "1540559",
    "end": "1542059"
  },
  {
    "text": "um",
    "start": "1542059",
    "end": "1542720"
  },
  {
    "text": "on a single AWS",
    "start": "1542720",
    "end": "1545140"
  },
  {
    "text": "p4de 24x large instance and we were",
    "start": "1545140",
    "end": "1548120"
  },
  {
    "text": "simply not able to do the same thing",
    "start": "1548120",
    "end": "1549799"
  },
  {
    "text": "with full parameter fine tuning and the",
    "start": "1549799",
    "end": "1552380"
  },
  {
    "text": "other thing is as you can see here the",
    "start": "1552380",
    "end": "1554360"
  },
  {
    "text": "the checkpoint sizes are much smaller so",
    "start": "1554360",
    "end": "1556700"
  },
  {
    "text": "with our Laura settings we were left",
    "start": "1556700",
    "end": "1558440"
  },
  {
    "text": "we're left with checkpoints that are",
    "start": "1558440",
    "end": "1560840"
  },
  {
    "text": "like 40 megabytes for the 7 billion",
    "start": "1560840",
    "end": "1562880"
  },
  {
    "text": "parameter model and 12.6 gigabytes for",
    "start": "1562880",
    "end": "1566539"
  },
  {
    "text": "the full parameter fine tuning",
    "start": "1566539",
    "end": "1569120"
  },
  {
    "text": "so obviously with full parameter",
    "start": "1569120",
    "end": "1571340"
  },
  {
    "text": "fine-tuning every time you checkpoint",
    "start": "1571340",
    "end": "1572659"
  },
  {
    "text": "you have to check one the entire thing",
    "start": "1572659",
    "end": "1574159"
  },
  {
    "text": "right with Laura you're just",
    "start": "1574159",
    "end": "1575480"
  },
  {
    "text": "checkpointing these two matrices A and B",
    "start": "1575480",
    "end": "1579679"
  },
  {
    "text": "cool so this brings us to our sixth",
    "start": "1579679",
    "end": "1582740"
  },
  {
    "text": "learning",
    "start": "1582740",
    "end": "1584120"
  },
  {
    "text": "um so as I said in the beginning you",
    "start": "1584120",
    "end": "1586159"
  },
  {
    "text": "during training you freeze these weights",
    "start": "1586159",
    "end": "1588020"
  },
  {
    "text": "right and you set them aside and you add",
    "start": "1588020",
    "end": "1590000"
  },
  {
    "text": "these two matrices A and B that are your",
    "start": "1590000",
    "end": "1592400"
  },
  {
    "text": "your Laura weights and what this means",
    "start": "1592400",
    "end": "1595340"
  },
  {
    "text": "during during serving is that you you",
    "start": "1595340",
    "end": "1598159"
  },
  {
    "text": "take those frozen weights like the",
    "start": "1598159",
    "end": "1599900"
  },
  {
    "text": "original model and you put it in memory",
    "start": "1599900",
    "end": "1601580"
  },
  {
    "text": "and then along with that you have an",
    "start": "1601580",
    "end": "1603980"
  },
  {
    "text": "array of uh Laura whites that are tasks",
    "start": "1603980",
    "end": "1606679"
  },
  {
    "text": "task specific",
    "start": "1606679",
    "end": "1609260"
  },
  {
    "text": "so this ties in very well with what",
    "start": "1609260",
    "end": "1611360"
  },
  {
    "text": "kurosh said initially about",
    "start": "1611360",
    "end": "1613820"
  },
  {
    "text": "um in order to beat these these open and",
    "start": "1613820",
    "end": "1616039"
  },
  {
    "text": "large and general purpose and very",
    "start": "1616039",
    "end": "1618559"
  },
  {
    "text": "expensive models we need to find small",
    "start": "1618559",
    "end": "1621500"
  },
  {
    "text": "models that we fine-tune and like a",
    "start": "1621500",
    "end": "1624080"
  },
  {
    "text": "niche specific tasks so you can imagine",
    "start": "1624080",
    "end": "1626480"
  },
  {
    "text": "like one Laura one set of lower weights",
    "start": "1626480",
    "end": "1629179"
  },
  {
    "text": "per task here",
    "start": "1629179",
    "end": "1631720"
  },
  {
    "text": "right so",
    "start": "1632539",
    "end": "1634700"
  },
  {
    "text": "what have we learned about Laura now in",
    "start": "1634700",
    "end": "1637039"
  },
  {
    "text": "terms of a trade-off",
    "start": "1637039",
    "end": "1638840"
  },
  {
    "text": "first of all if your sole concern is",
    "start": "1638840",
    "end": "1640820"
  },
  {
    "text": "model quality there's no way around full",
    "start": "1640820",
    "end": "1643220"
  },
  {
    "text": "parameter fine tuning still you'll still",
    "start": "1643220",
    "end": "1644720"
  },
  {
    "text": "have this edge of one or two or three",
    "start": "1644720",
    "end": "1646520"
  },
  {
    "text": "percent of relative accuracy",
    "start": "1646520",
    "end": "1648679"
  },
  {
    "text": "um and um the the training time between",
    "start": "1648679",
    "end": "1651620"
  },
  {
    "text": "the between the two the difference in",
    "start": "1651620",
    "end": "1653900"
  },
  {
    "text": "training time is is really not there so",
    "start": "1653900",
    "end": "1656659"
  },
  {
    "text": "initially we thought like Laura must be",
    "start": "1656659",
    "end": "1659000"
  },
  {
    "text": "much quicker in like fewer parameters",
    "start": "1659000",
    "end": "1660500"
  },
  {
    "text": "fewer things to checkpoint stuff like",
    "start": "1660500",
    "end": "1662000"
  },
  {
    "text": "that but it turns out that if you look",
    "start": "1662000",
    "end": "1664520"
  },
  {
    "text": "at the time it takes the model to",
    "start": "1664520",
    "end": "1666200"
  },
  {
    "text": "converge um as in like wall clock time",
    "start": "1666200",
    "end": "1668720"
  },
  {
    "text": "to a given perplexity it's roughly the",
    "start": "1668720",
    "end": "1671000"
  },
  {
    "text": "same between the two methods and then",
    "start": "1671000",
    "end": "1673760"
  },
  {
    "text": "what we really gained from Laura is",
    "start": "1673760",
    "end": "1675140"
  },
  {
    "text": "first of all the memory footprint that",
    "start": "1675140",
    "end": "1676760"
  },
  {
    "text": "can really unblock you on using smaller",
    "start": "1676760",
    "end": "1678860"
  },
  {
    "text": "instance types in training and second of",
    "start": "1678860",
    "end": "1681860"
  },
  {
    "text": "all the the serving efficiency that's",
    "start": "1681860",
    "end": "1683539"
  },
  {
    "text": "just greatly enhanced",
    "start": "1683539",
    "end": "1685760"
  },
  {
    "text": "right so here are all the learnings that",
    "start": "1685760",
    "end": "1688640"
  },
  {
    "text": "we mentioned today first of all data set",
    "start": "1688640",
    "end": "1690620"
  },
  {
    "text": "quality is crucial",
    "start": "1690620",
    "end": "1692120"
  },
  {
    "text": "training and inference data form and",
    "start": "1692120",
    "end": "1693620"
  },
  {
    "text": "consistency is crucial and we use gpd4",
    "start": "1693620",
    "end": "1696980"
  },
  {
    "text": "to set up a reliable evaluation pipeline",
    "start": "1696980",
    "end": "1699860"
  },
  {
    "text": "then Laura being sensitive to the",
    "start": "1699860",
    "end": "1702919"
  },
  {
    "text": "learning rate and prompting data sets",
    "start": "1702919",
    "end": "1705980"
  },
  {
    "text": "help with training stability",
    "start": "1705980",
    "end": "1708440"
  },
  {
    "text": "and lastly the large big Advantage is",
    "start": "1708440",
    "end": "1711140"
  },
  {
    "text": "really the serving efficiency",
    "start": "1711140",
    "end": "1714340"
  },
  {
    "text": "yeah so one more thing here there's",
    "start": "1714380",
    "end": "1717500"
  },
  {
    "text": "another talk about these LMS in",
    "start": "1717500",
    "end": "1719900"
  },
  {
    "text": "production by our chief scientist Walid",
    "start": "1719900",
    "end": "1723140"
  },
  {
    "text": "and that's going to be at 3 15 PM in",
    "start": "1723140",
    "end": "1725900"
  },
  {
    "text": "Gate Ballroom B",
    "start": "1725900",
    "end": "1727580"
  },
  {
    "text": "cool thanks everyone for attending",
    "start": "1727580",
    "end": "1730520"
  },
  {
    "text": "thank you",
    "start": "1730520",
    "end": "1732640"
  }
]
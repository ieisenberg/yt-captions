[
  {
    "start": "0",
    "end": "37000"
  },
  {
    "text": "[Music]",
    "start": "170",
    "end": "14960"
  },
  {
    "text": "hi everyone thanks for coming out to my",
    "start": "14960",
    "end": "17039"
  },
  {
    "text": "presentation today",
    "start": "17039",
    "end": "18480"
  },
  {
    "text": "my name is travis adair i'm the lead",
    "start": "18480",
    "end": "21279"
  },
  {
    "text": "maintainer of an open source project",
    "start": "21279",
    "end": "23119"
  },
  {
    "text": "called horvad",
    "start": "23119",
    "end": "24320"
  },
  {
    "text": "and a co-maintainer of the open source",
    "start": "24320",
    "end": "26320"
  },
  {
    "text": "project ludwig that i'm here to talk to",
    "start": "26320",
    "end": "28000"
  },
  {
    "text": "you about today",
    "start": "28000",
    "end": "29359"
  },
  {
    "text": "i also used to work as the tech lead for",
    "start": "29359",
    "end": "31760"
  },
  {
    "text": "the deep learning training team at uber",
    "start": "31760",
    "end": "33520"
  },
  {
    "text": "as part of the michelangelo machine",
    "start": "33520",
    "end": "35120"
  },
  {
    "text": "learning platform",
    "start": "35120",
    "end": "36559"
  },
  {
    "text": "and i'm now the co-founder of a company",
    "start": "36559",
    "end": "38239"
  },
  {
    "start": "37000",
    "end": "37000"
  },
  {
    "text": "called predabase",
    "start": "38239",
    "end": "39600"
  },
  {
    "text": "uh which i'll tell you a little bit",
    "start": "39600",
    "end": "41120"
  },
  {
    "text": "about today but we're still in stealth",
    "start": "41120",
    "end": "43200"
  },
  {
    "text": "so",
    "start": "43200",
    "end": "43760"
  },
  {
    "text": "you know don't tell anyone too much but",
    "start": "43760",
    "end": "45680"
  },
  {
    "text": "between you and me we'll we'll",
    "start": "45680",
    "end": "46800"
  },
  {
    "text": "definitely tell you a little bit about",
    "start": "46800",
    "end": "48000"
  },
  {
    "text": "what we're up to",
    "start": "48000",
    "end": "50640"
  },
  {
    "text": "so to start things off um what is the",
    "start": "50879",
    "end": "54239"
  },
  {
    "text": "problem",
    "start": "54239",
    "end": "55120"
  },
  {
    "text": "that you know we on the ludwig team",
    "start": "55120",
    "end": "57520"
  },
  {
    "text": "observed",
    "start": "57520",
    "end": "58640"
  },
  {
    "text": "uh in the industry going on today the",
    "start": "58640",
    "end": "60719"
  },
  {
    "text": "biggest thing",
    "start": "60719",
    "end": "62000"
  },
  {
    "text": "um that i want to emphasize is that",
    "start": "62000",
    "end": "65360"
  },
  {
    "text": "machine learning today is fundamentally",
    "start": "65360",
    "end": "67200"
  },
  {
    "text": "very limited and slow by",
    "start": "67200",
    "end": "69200"
  },
  {
    "text": "a number of factors which mostly have to",
    "start": "69200",
    "end": "71040"
  },
  {
    "text": "do with",
    "start": "71040",
    "end": "72240"
  },
  {
    "text": "the uh cost of creating models",
    "start": "72240",
    "end": "75920"
  },
  {
    "text": "and also which is largely driven by the",
    "start": "75920",
    "end": "78560"
  },
  {
    "text": "fact that",
    "start": "78560",
    "end": "80080"
  },
  {
    "text": "you know these projects are driven by",
    "start": "80080",
    "end": "81759"
  },
  {
    "text": "data scientists who are a very limited",
    "start": "81759",
    "end": "83600"
  },
  {
    "text": "resource in most organizations and",
    "start": "83600",
    "end": "86320"
  },
  {
    "text": "there's very limited amount of attention",
    "start": "86320",
    "end": "87920"
  },
  {
    "text": "that they can spend on any given problem",
    "start": "87920",
    "end": "90159"
  },
  {
    "text": "right so",
    "start": "90159",
    "end": "90720"
  },
  {
    "text": "what tends to happen is that most of the",
    "start": "90720",
    "end": "92320"
  },
  {
    "text": "resources within an organization are",
    "start": "92320",
    "end": "94079"
  },
  {
    "text": "diverted to",
    "start": "94079",
    "end": "95439"
  },
  {
    "text": "a very limited set of high priority use",
    "start": "95439",
    "end": "97840"
  },
  {
    "text": "cases right",
    "start": "97840",
    "end": "99759"
  },
  {
    "text": "and so to solve this problem in",
    "start": "99759",
    "end": "102000"
  },
  {
    "text": "organizations that have a lot of machine",
    "start": "102000",
    "end": "103920"
  },
  {
    "text": "learning",
    "start": "103920",
    "end": "104479"
  },
  {
    "text": "uh problems and not as many uh data",
    "start": "104479",
    "end": "107280"
  },
  {
    "text": "scientists and machine learning",
    "start": "107280",
    "end": "108799"
  },
  {
    "text": "experts to solve them typically what",
    "start": "108799",
    "end": "111439"
  },
  {
    "text": "organizations do",
    "start": "111439",
    "end": "112399"
  },
  {
    "text": "is turn to these sort of black box",
    "start": "112399",
    "end": "114720"
  },
  {
    "text": "automl solutions",
    "start": "114720",
    "end": "116560"
  },
  {
    "text": "out there in the industry but these also",
    "start": "116560",
    "end": "118880"
  },
  {
    "text": "come with their own set of trade-offs",
    "start": "118880",
    "end": "121040"
  },
  {
    "text": "typically what we find is that you know",
    "start": "121040",
    "end": "124719"
  },
  {
    "text": "while these solutions kind of get you",
    "start": "124719",
    "end": "126320"
  },
  {
    "text": "off the ground very quickly they also",
    "start": "126320",
    "end": "128399"
  },
  {
    "text": "have what we would call this dead end",
    "start": "128399",
    "end": "129920"
  },
  {
    "text": "problem where",
    "start": "129920",
    "end": "131680"
  },
  {
    "text": "if you try it and it doesn't work for",
    "start": "131680",
    "end": "134239"
  },
  {
    "text": "you there's very limited course in terms",
    "start": "134239",
    "end": "136239"
  },
  {
    "text": "of what you can do",
    "start": "136239",
    "end": "137280"
  },
  {
    "text": "to further refine",
    "start": "137280",
    "end": "140640"
  },
  {
    "text": "or customize the solution to your to",
    "start": "140640",
    "end": "142879"
  },
  {
    "text": "your requirements",
    "start": "142879",
    "end": "144319"
  },
  {
    "text": "and so we kind of end up in this dilemma",
    "start": "144319",
    "end": "146239"
  },
  {
    "text": "where we need things that are",
    "start": "146239",
    "end": "147680"
  },
  {
    "text": "simple in order to make them uh",
    "start": "147680",
    "end": "150560"
  },
  {
    "text": "accessible to organizations that don't",
    "start": "150560",
    "end": "152480"
  },
  {
    "text": "have like an infinite number of data",
    "start": "152480",
    "end": "153920"
  },
  {
    "text": "scientists",
    "start": "153920",
    "end": "154720"
  },
  {
    "text": "but they also need to be flexible in the",
    "start": "154720",
    "end": "156400"
  },
  {
    "text": "sense that",
    "start": "156400",
    "end": "158000"
  },
  {
    "start": "158000",
    "end": "158000"
  },
  {
    "text": "if you try it and it doesn't work just",
    "start": "158000",
    "end": "160959"
  },
  {
    "text": "out of the box with the first thing you",
    "start": "160959",
    "end": "162400"
  },
  {
    "text": "do you need to be able to",
    "start": "162400",
    "end": "163760"
  },
  {
    "text": "customize and extend it in ways that can",
    "start": "163760",
    "end": "166239"
  },
  {
    "text": "adapt",
    "start": "166239",
    "end": "166800"
  },
  {
    "text": "to solve your your specific business",
    "start": "166800",
    "end": "168840"
  },
  {
    "text": "need",
    "start": "168840",
    "end": "170000"
  },
  {
    "text": "and so when we start to think about what",
    "start": "170000",
    "end": "172160"
  },
  {
    "text": "a solution would look like that kind of",
    "start": "172160",
    "end": "173680"
  },
  {
    "text": "gives us this best of both worlds",
    "start": "173680",
    "end": "175760"
  },
  {
    "text": "um the analogy that i'd like to start",
    "start": "175760",
    "end": "177360"
  },
  {
    "text": "with is to think about",
    "start": "177360",
    "end": "179200"
  },
  {
    "text": "the how things have progressed in the",
    "start": "179200",
    "end": "181599"
  },
  {
    "text": "data management data infrastructure",
    "start": "181599",
    "end": "183280"
  },
  {
    "text": "space",
    "start": "183280",
    "end": "184159"
  },
  {
    "text": "so as a little bit of a history lesson",
    "start": "184159",
    "end": "186000"
  },
  {
    "text": "if we go back to",
    "start": "186000",
    "end": "187440"
  },
  {
    "text": "sort of the pre-2000s to early 2000s",
    "start": "187440",
    "end": "190800"
  },
  {
    "text": "time period",
    "start": "190800",
    "end": "192000"
  },
  {
    "text": "sql was kind of the lingua franca for",
    "start": "192000",
    "end": "194080"
  },
  {
    "text": "all data engineering data infrastructure",
    "start": "194080",
    "end": "195840"
  },
  {
    "text": "work that was going on",
    "start": "195840",
    "end": "197280"
  },
  {
    "text": "but of course we had this moment in the",
    "start": "197280",
    "end": "199280"
  },
  {
    "text": "early 2000s",
    "start": "199280",
    "end": "200480"
  },
  {
    "text": "where google released the seminal",
    "start": "200480",
    "end": "202560"
  },
  {
    "text": "mapreduce paper",
    "start": "202560",
    "end": "203840"
  },
  {
    "text": "where suddenly we entered this new era",
    "start": "203840",
    "end": "205519"
  },
  {
    "text": "of big data and nosql",
    "start": "205519",
    "end": "208000"
  },
  {
    "text": "and as a result the tooling kind of had",
    "start": "208000",
    "end": "209920"
  },
  {
    "text": "to go back to the beginning in some ways",
    "start": "209920",
    "end": "212480"
  },
  {
    "text": "where we're doing much more low level uh",
    "start": "212480",
    "end": "215519"
  },
  {
    "text": "code writing things directly in c plus",
    "start": "215519",
    "end": "217360"
  },
  {
    "text": "plus in java",
    "start": "217360",
    "end": "218640"
  },
  {
    "text": "to do this sort of data processing and",
    "start": "218640",
    "end": "221280"
  },
  {
    "text": "we lost a lot of the benefits of a",
    "start": "221280",
    "end": "222720"
  },
  {
    "text": "higher level language like sql because",
    "start": "222720",
    "end": "224480"
  },
  {
    "text": "the tooling hadn't yet caught up to",
    "start": "224480",
    "end": "226720"
  },
  {
    "text": "the new state of the world the new kind",
    "start": "226720",
    "end": "228239"
  },
  {
    "text": "of requirements that we had",
    "start": "228239",
    "end": "230080"
  },
  {
    "text": "fast forward a few years you had a",
    "start": "230080",
    "end": "231599"
  },
  {
    "text": "framework like hive come in provided",
    "start": "231599",
    "end": "233519"
  },
  {
    "text": "like a much needed sql layer over a lot",
    "start": "233519",
    "end": "236000"
  },
  {
    "text": "of the mapreduce abstractions",
    "start": "236000",
    "end": "238239"
  },
  {
    "text": "and then apache spark which of course is",
    "start": "238239",
    "end": "240480"
  },
  {
    "text": "now to this day a very",
    "start": "240480",
    "end": "242159"
  },
  {
    "text": "prominent uh piece of technology and",
    "start": "242159",
    "end": "244080"
  },
  {
    "text": "data engineering",
    "start": "244080",
    "end": "245519"
  },
  {
    "text": "um that sort of introduced a lower level",
    "start": "245519",
    "end": "248400"
  },
  {
    "text": "api but with a lot of like nice bells",
    "start": "248400",
    "end": "250239"
  },
  {
    "text": "and whistles attached",
    "start": "250239",
    "end": "251599"
  },
  {
    "text": "but then the really interesting thing i",
    "start": "251599",
    "end": "253120"
  },
  {
    "text": "think has started to occur in the past",
    "start": "253120",
    "end": "254720"
  },
  {
    "text": "few years when you see this kind of",
    "start": "254720",
    "end": "256720"
  },
  {
    "text": "snowflake trend occurring in the",
    "start": "256720",
    "end": "258239"
  },
  {
    "text": "industry where things are kind of moving",
    "start": "258239",
    "end": "259759"
  },
  {
    "text": "back to the structured",
    "start": "259759",
    "end": "261519"
  },
  {
    "text": "data warehouse as opposed to data lake",
    "start": "261519",
    "end": "264400"
  },
  {
    "text": "sql and schema driven workflow",
    "start": "264400",
    "end": "266800"
  },
  {
    "text": "and as a result you see a lot of",
    "start": "266800",
    "end": "268720"
  },
  {
    "text": "frameworks like dbt",
    "start": "268720",
    "end": "270080"
  },
  {
    "text": "that kind of move from this let's write",
    "start": "270080",
    "end": "272400"
  },
  {
    "text": "spark",
    "start": "272400",
    "end": "273360"
  },
  {
    "text": "etls to do our ingestion of the data to",
    "start": "273360",
    "end": "277520"
  },
  {
    "text": "let's write sql to do elt and similarly",
    "start": "277520",
    "end": "280960"
  },
  {
    "text": "frameworks like arrow",
    "start": "280960",
    "end": "282720"
  },
  {
    "text": "and das that are unifying the data",
    "start": "282720",
    "end": "284960"
  },
  {
    "text": "transformation",
    "start": "284960",
    "end": "285840"
  },
  {
    "text": "and data representation process that",
    "start": "285840",
    "end": "288720"
  },
  {
    "start": "288000",
    "end": "288000"
  },
  {
    "text": "then enable frameworks like fugue to sit",
    "start": "288720",
    "end": "290880"
  },
  {
    "text": "on top of this that",
    "start": "290880",
    "end": "292240"
  },
  {
    "text": "can build these sorts of high-level sql",
    "start": "292240",
    "end": "294240"
  },
  {
    "text": "abstractions",
    "start": "294240",
    "end": "295360"
  },
  {
    "text": "over top advanced data processing",
    "start": "295360",
    "end": "297199"
  },
  {
    "text": "pipelines as well",
    "start": "297199",
    "end": "300080"
  },
  {
    "text": "similarly if you look at how things are",
    "start": "300240",
    "end": "301840"
  },
  {
    "text": "progressing in the machine learning",
    "start": "301840",
    "end": "303280"
  },
  {
    "text": "ecosystem",
    "start": "303280",
    "end": "304479"
  },
  {
    "text": "what you see is a very similar kind of",
    "start": "304479",
    "end": "306720"
  },
  {
    "text": "pattern where",
    "start": "306720",
    "end": "307919"
  },
  {
    "text": "before the in this case early 2010s you",
    "start": "307919",
    "end": "310960"
  },
  {
    "text": "had traditional machine learning",
    "start": "310960",
    "end": "312800"
  },
  {
    "text": "and frameworks like sk learn that made",
    "start": "312800",
    "end": "314720"
  },
  {
    "text": "it very high level and accessible for",
    "start": "314720",
    "end": "316320"
  },
  {
    "text": "people",
    "start": "316320",
    "end": "317199"
  },
  {
    "text": "but then when the deep learning",
    "start": "317199",
    "end": "318400"
  },
  {
    "text": "revolution hit largely driven by",
    "start": "318400",
    "end": "320400"
  },
  {
    "text": "the alex ned paper what we saw was that",
    "start": "320400",
    "end": "324320"
  },
  {
    "text": "things once again kind of went back to",
    "start": "324320",
    "end": "326560"
  },
  {
    "text": "lower level tools lower level frameworks",
    "start": "326560",
    "end": "328960"
  },
  {
    "text": "writing a lot more code in this case in",
    "start": "328960",
    "end": "330880"
  },
  {
    "text": "python",
    "start": "330880",
    "end": "331840"
  },
  {
    "text": "using tools like tensorflow and pytorch",
    "start": "331840",
    "end": "334400"
  },
  {
    "text": "and then once again there was kind of",
    "start": "334400",
    "end": "335600"
  },
  {
    "text": "this interesting kind of trend",
    "start": "335600",
    "end": "337120"
  },
  {
    "text": "back to higher level frameworks that",
    "start": "337120",
    "end": "338720"
  },
  {
    "text": "occurred and i would call out kind of",
    "start": "338720",
    "end": "340720"
  },
  {
    "text": "two moments in particular that that had",
    "start": "340720",
    "end": "342800"
  },
  {
    "text": "a lot to do with this one",
    "start": "342800",
    "end": "344400"
  },
  {
    "text": "we had uh frameworks like horovod come",
    "start": "344400",
    "end": "346960"
  },
  {
    "text": "along that sort of",
    "start": "346960",
    "end": "348479"
  },
  {
    "text": "standardized the abstraction for how you",
    "start": "348479",
    "end": "350639"
  },
  {
    "text": "can scale the training of deep neural",
    "start": "350639",
    "end": "352560"
  },
  {
    "text": "networks",
    "start": "352560",
    "end": "353600"
  },
  {
    "text": "so you know most of these systems are",
    "start": "353600",
    "end": "355680"
  },
  {
    "text": "using stochastic gradient descent",
    "start": "355680",
    "end": "357680"
  },
  {
    "text": "with horovide you have a very common",
    "start": "357680",
    "end": "359360"
  },
  {
    "text": "interface that allows you to express",
    "start": "359360",
    "end": "361440"
  },
  {
    "text": "distributing training for stochastic",
    "start": "361440",
    "end": "363280"
  },
  {
    "text": "gradient descent",
    "start": "363280",
    "end": "364639"
  },
  {
    "text": "and then you also have the paper",
    "start": "364639",
    "end": "365919"
  },
  {
    "text": "attention is all you need",
    "start": "365919",
    "end": "367759"
  },
  {
    "text": "which introduced this kind of",
    "start": "367759",
    "end": "369199"
  },
  {
    "text": "transformer architecture this attention",
    "start": "369199",
    "end": "371120"
  },
  {
    "text": "mechanism",
    "start": "371120",
    "end": "372160"
  },
  {
    "text": "which has now become a very core piece",
    "start": "372160",
    "end": "374639"
  },
  {
    "text": "of technology that underlies state of",
    "start": "374639",
    "end": "376319"
  },
  {
    "text": "the art",
    "start": "376319",
    "end": "376880"
  },
  {
    "text": "nlp models tabular models and vision",
    "start": "376880",
    "end": "379759"
  },
  {
    "text": "models",
    "start": "379759",
    "end": "380639"
  },
  {
    "text": "and so you had you know frameworks like",
    "start": "380639",
    "end": "382319"
  },
  {
    "text": "hugging phase come out that",
    "start": "382319",
    "end": "384479"
  },
  {
    "text": "packaged up these sorts of transformer",
    "start": "384479",
    "end": "386319"
  },
  {
    "text": "architectures into a very",
    "start": "386319",
    "end": "388240"
  },
  {
    "text": "high level user friendly api and then",
    "start": "388240",
    "end": "390639"
  },
  {
    "text": "you have frameworks modern like",
    "start": "390639",
    "end": "392639"
  },
  {
    "text": "modern uh training frameworks like",
    "start": "392639",
    "end": "394240"
  },
  {
    "text": "pytorch lightning and fastai",
    "start": "394240",
    "end": "396319"
  },
  {
    "text": "that provide very good abstractions over",
    "start": "396319",
    "end": "398479"
  },
  {
    "text": "training loops and distributed training",
    "start": "398479",
    "end": "400240"
  },
  {
    "text": "and all these other sorts of things that",
    "start": "400240",
    "end": "401680"
  },
  {
    "text": "are very",
    "start": "401680",
    "end": "402479"
  },
  {
    "text": "repeatable in general about doing",
    "start": "402479",
    "end": "404800"
  },
  {
    "text": "machine learning training",
    "start": "404800",
    "end": "407759"
  },
  {
    "text": "and so the way that we think about how",
    "start": "407759",
    "end": "409919"
  },
  {
    "text": "ludwig and specifically ludwig and ray",
    "start": "409919",
    "end": "412000"
  },
  {
    "text": "fits into this model this sort of",
    "start": "412000",
    "end": "413680"
  },
  {
    "text": "ecosystem",
    "start": "413680",
    "end": "415039"
  },
  {
    "text": "is that when you have the combination of",
    "start": "415039",
    "end": "417280"
  },
  {
    "text": "these two trends together of structured",
    "start": "417280",
    "end": "419680"
  },
  {
    "text": "data",
    "start": "419680",
    "end": "420560"
  },
  {
    "text": "driven by a move from lake uh data lakes",
    "start": "420560",
    "end": "422880"
  },
  {
    "text": "to data warehouses",
    "start": "422880",
    "end": "424160"
  },
  {
    "text": "etl to elt unified schema and",
    "start": "424160",
    "end": "426960"
  },
  {
    "text": "representation",
    "start": "426960",
    "end": "428400"
  },
  {
    "text": "and combine that with these general",
    "start": "428400",
    "end": "430080"
  },
  {
    "text": "model architectures so",
    "start": "430080",
    "end": "431680"
  },
  {
    "text": "standardized processes for distributing",
    "start": "431680",
    "end": "433919"
  },
  {
    "text": "the training with stochastic gradient",
    "start": "433919",
    "end": "435199"
  },
  {
    "text": "descent",
    "start": "435199",
    "end": "436240"
  },
  {
    "text": "state-of-the-art model architectures",
    "start": "436240",
    "end": "437759"
  },
  {
    "text": "that are very reusable to lots of",
    "start": "437759",
    "end": "439440"
  },
  {
    "text": "different",
    "start": "439440",
    "end": "439840"
  },
  {
    "text": "domains that's where you have the",
    "start": "439840",
    "end": "442000"
  },
  {
    "start": "441000",
    "end": "441000"
  },
  {
    "text": "potential to create this sort of",
    "start": "442000",
    "end": "444080"
  },
  {
    "text": "declarative or high-level framework",
    "start": "444080",
    "end": "446400"
  },
  {
    "text": "that's very flexible",
    "start": "446400",
    "end": "448000"
  },
  {
    "text": "similar to sql for machine learning and",
    "start": "448000",
    "end": "450800"
  },
  {
    "text": "that's fundamentally what ludwig is all",
    "start": "450800",
    "end": "452880"
  },
  {
    "text": "about",
    "start": "452880",
    "end": "454639"
  },
  {
    "text": "so what is ludwig ludwig is what we call",
    "start": "454639",
    "end": "457599"
  },
  {
    "text": "a low code declarative framework to",
    "start": "457599",
    "end": "459599"
  },
  {
    "text": "build deep neural networks",
    "start": "459599",
    "end": "461199"
  },
  {
    "text": "it's open source popular framework out",
    "start": "461199",
    "end": "464479"
  },
  {
    "text": "of over seven",
    "start": "464479",
    "end": "465440"
  },
  {
    "text": "seven thousand stars at this time on",
    "start": "465440",
    "end": "467039"
  },
  {
    "text": "github um",
    "start": "467039",
    "end": "468479"
  },
  {
    "text": "60 plus contributors from across the",
    "start": "468479",
    "end": "470639"
  },
  {
    "text": "industry",
    "start": "470639",
    "end": "471919"
  },
  {
    "text": "and one thing that we think is really",
    "start": "471919",
    "end": "473520"
  },
  {
    "text": "unique about ludwig is that",
    "start": "473520",
    "end": "475520"
  },
  {
    "text": "it's focused on a mixed modality style",
    "start": "475520",
    "end": "478800"
  },
  {
    "text": "of training so we don't just focus on",
    "start": "478800",
    "end": "480560"
  },
  {
    "text": "nlp or tabular or computer vision etc",
    "start": "480560",
    "end": "485280"
  },
  {
    "text": "we like to think of the training in",
    "start": "485280",
    "end": "487759"
  },
  {
    "text": "terms of these abstract data types as",
    "start": "487759",
    "end": "489759"
  },
  {
    "text": "you'll see in the slides to follow",
    "start": "489759",
    "end": "492160"
  },
  {
    "text": "that allow us to mix these different",
    "start": "492160",
    "end": "493840"
  },
  {
    "text": "data types together into single models",
    "start": "493840",
    "end": "496000"
  },
  {
    "text": "and perform multi-task learning where we",
    "start": "496000",
    "end": "497840"
  },
  {
    "text": "can do binary prediction",
    "start": "497840",
    "end": "499599"
  },
  {
    "start": "499000",
    "end": "499000"
  },
  {
    "text": "regression text generation all these",
    "start": "499599",
    "end": "501840"
  },
  {
    "text": "things together in one framework",
    "start": "501840",
    "end": "504240"
  },
  {
    "text": "ludwig has been battle tested used in",
    "start": "504240",
    "end": "506400"
  },
  {
    "text": "production at uber",
    "start": "506400",
    "end": "508000"
  },
  {
    "text": "and is now a member of the linux",
    "start": "508000",
    "end": "510240"
  },
  {
    "text": "foundation ai and data foundation",
    "start": "510240",
    "end": "513919"
  },
  {
    "text": "and at the heart of ludwig is what we",
    "start": "513919",
    "end": "515760"
  },
  {
    "text": "call the encoder decoder decoder",
    "start": "515760",
    "end": "518000"
  },
  {
    "text": "architecture ecd and the way that this",
    "start": "518000",
    "end": "520719"
  },
  {
    "text": "works",
    "start": "520719",
    "end": "521200"
  },
  {
    "text": "is that instead of thinking about",
    "start": "521200",
    "end": "522800"
  },
  {
    "text": "writing your model in terms of like",
    "start": "522800",
    "end": "524720"
  },
  {
    "text": "different layers and",
    "start": "524720",
    "end": "526160"
  },
  {
    "text": "you know having like different",
    "start": "526160",
    "end": "528240"
  },
  {
    "text": "dimensionalities to different",
    "start": "528240",
    "end": "529920"
  },
  {
    "text": "heads and tails in the model and",
    "start": "529920",
    "end": "531760"
  },
  {
    "text": "different stacks of convolutional layers",
    "start": "531760",
    "end": "533680"
  },
  {
    "text": "etc",
    "start": "533680",
    "end": "534720"
  },
  {
    "text": "what we do is we just think about data",
    "start": "534720",
    "end": "536320"
  },
  {
    "text": "inputs and data outputs",
    "start": "536320",
    "end": "538080"
  },
  {
    "text": "so with ludwig you might say okay this",
    "start": "538080",
    "end": "540080"
  },
  {
    "text": "particular column in my data set is a",
    "start": "540080",
    "end": "542000"
  },
  {
    "text": "categorical column",
    "start": "542000",
    "end": "543279"
  },
  {
    "text": "or this is a text column etc and then",
    "start": "543279",
    "end": "546240"
  },
  {
    "text": "what ludwig will do is it will",
    "start": "546240",
    "end": "547680"
  },
  {
    "text": "pre-process that data",
    "start": "547680",
    "end": "549600"
  },
  {
    "text": "encode it into a representation that is",
    "start": "549600",
    "end": "551920"
  },
  {
    "start": "551000",
    "end": "551000"
  },
  {
    "text": "understandable by the deep learning",
    "start": "551920",
    "end": "553839"
  },
  {
    "text": "framework",
    "start": "553839",
    "end": "554800"
  },
  {
    "text": "and then it will combine all these",
    "start": "554800",
    "end": "556480"
  },
  {
    "text": "different inputs together using this",
    "start": "556480",
    "end": "558080"
  },
  {
    "text": "combiner layer",
    "start": "558080",
    "end": "559680"
  },
  {
    "text": "do some processing of it and then decode",
    "start": "559680",
    "end": "562000"
  },
  {
    "text": "them into the outputs of the model that",
    "start": "562000",
    "end": "563839"
  },
  {
    "text": "you want to predict",
    "start": "563839",
    "end": "565760"
  },
  {
    "text": "and this ends up being a very flexible",
    "start": "565760",
    "end": "567600"
  },
  {
    "text": "architecture",
    "start": "567600",
    "end": "568800"
  },
  {
    "text": "that is extensible to a wide variety of",
    "start": "568800",
    "end": "571040"
  },
  {
    "text": "problems so for example",
    "start": "571040",
    "end": "572560"
  },
  {
    "text": "if you have some textual inputs and you",
    "start": "572560",
    "end": "574640"
  },
  {
    "text": "want to predict some numerical value",
    "start": "574640",
    "end": "577040"
  },
  {
    "text": "that's a classic regression problem",
    "start": "577040",
    "end": "579279"
  },
  {
    "text": "if you have some text data and you want",
    "start": "579279",
    "end": "581279"
  },
  {
    "text": "to predict a category that would be like",
    "start": "581279",
    "end": "582800"
  },
  {
    "text": "a text classification problem",
    "start": "582800",
    "end": "584880"
  },
  {
    "text": "similarly if you have like two different",
    "start": "584880",
    "end": "586640"
  },
  {
    "text": "audio signals coming in you want to",
    "start": "586640",
    "end": "588320"
  },
  {
    "text": "determine",
    "start": "588320",
    "end": "589120"
  },
  {
    "text": "if the if the two signals are the same",
    "start": "589120",
    "end": "591040"
  },
  {
    "text": "that could be a speech verification",
    "start": "591040",
    "end": "592720"
  },
  {
    "text": "problem",
    "start": "592720",
    "end": "593600"
  },
  {
    "text": "and so on you can imagine extrapolating",
    "start": "593600",
    "end": "595360"
  },
  {
    "text": "this out to all different types of",
    "start": "595360",
    "end": "597600"
  },
  {
    "text": "problems that you might want to solve",
    "start": "597600",
    "end": "600800"
  },
  {
    "text": "and so fundamentally this gets back to",
    "start": "600800",
    "end": "603839"
  },
  {
    "text": "the heart of our original problem",
    "start": "603839",
    "end": "605839"
  },
  {
    "text": "that that idea that machine learning is",
    "start": "605839",
    "end": "608800"
  },
  {
    "text": "both",
    "start": "608800",
    "end": "609279"
  },
  {
    "text": "slow and also these black box solutions",
    "start": "609279",
    "end": "612640"
  },
  {
    "text": "are not very extensible",
    "start": "612640",
    "end": "614640"
  },
  {
    "text": "by bringing this to this declarative",
    "start": "614640",
    "end": "617120"
  },
  {
    "text": "model where instead",
    "start": "617120",
    "end": "618079"
  },
  {
    "text": "we combine the best of both worlds in",
    "start": "618079",
    "end": "619839"
  },
  {
    "text": "terms of the flexibility",
    "start": "619839",
    "end": "621600"
  },
  {
    "text": "of a framework like tensorflow and pi",
    "start": "621600",
    "end": "623360"
  },
  {
    "text": "torch with the simplicity of an automl",
    "start": "623360",
    "end": "625920"
  },
  {
    "text": "solution and this is what we call a",
    "start": "625920",
    "end": "627519"
  },
  {
    "start": "626000",
    "end": "626000"
  },
  {
    "text": "declarative ml",
    "start": "627519",
    "end": "629360"
  },
  {
    "text": "and to give you a better understanding",
    "start": "629360",
    "end": "630880"
  },
  {
    "text": "of why this is",
    "start": "630880",
    "end": "632480"
  },
  {
    "text": "we feel that this is a very valuable",
    "start": "632480",
    "end": "634160"
  },
  {
    "text": "contribution",
    "start": "634160",
    "end": "636399"
  },
  {
    "text": "you know here's a quick example so with",
    "start": "636399",
    "end": "639440"
  },
  {
    "text": "ludwig you abstract away the complexity",
    "start": "639440",
    "end": "642000"
  },
  {
    "text": "of how you scale your model with",
    "start": "642000",
    "end": "643680"
  },
  {
    "text": "something like horovod",
    "start": "643680",
    "end": "645200"
  },
  {
    "text": "how you optimize it with something like",
    "start": "645200",
    "end": "647040"
  },
  {
    "text": "hyperparameter search",
    "start": "647040",
    "end": "648720"
  },
  {
    "text": "how you productionize it using something",
    "start": "648720",
    "end": "651200"
  },
  {
    "text": "like uh you know model serving",
    "start": "651200",
    "end": "653680"
  },
  {
    "text": "and instead you just express your intent",
    "start": "653680",
    "end": "656720"
  },
  {
    "text": "in terms of what you want",
    "start": "656720",
    "end": "658399"
  },
  {
    "text": "and then ludwig does the hard work of",
    "start": "658399",
    "end": "660160"
  },
  {
    "text": "figuring out how to achieve it right",
    "start": "660160",
    "end": "662640"
  },
  {
    "text": "and so the nice thing about this is that",
    "start": "662640",
    "end": "665200"
  },
  {
    "text": "if you do want to provide a lot of",
    "start": "665200",
    "end": "666880"
  },
  {
    "text": "specificity in terms of say what the",
    "start": "666880",
    "end": "668800"
  },
  {
    "text": "learning rate is or what the optimizer",
    "start": "668800",
    "end": "670640"
  },
  {
    "text": "is",
    "start": "670640",
    "end": "671360"
  },
  {
    "text": "all of those features are available to",
    "start": "671360",
    "end": "673120"
  },
  {
    "text": "you but if you just want to say here's",
    "start": "673120",
    "end": "675120"
  },
  {
    "text": "my data",
    "start": "675120",
    "end": "676079"
  },
  {
    "text": "train a model that's also a possibility",
    "start": "676079",
    "end": "678560"
  },
  {
    "start": "677000",
    "end": "677000"
  },
  {
    "text": "and so we give you the full spread",
    "start": "678560",
    "end": "680160"
  },
  {
    "text": "spectrum of going from low code to high",
    "start": "680160",
    "end": "683760"
  },
  {
    "text": "code depending on",
    "start": "683760",
    "end": "684959"
  },
  {
    "text": "what your requirements are and what your",
    "start": "684959",
    "end": "686320"
  },
  {
    "text": "level of sophistication is with deep",
    "start": "686320",
    "end": "688079"
  },
  {
    "text": "learning",
    "start": "688079",
    "end": "690240"
  },
  {
    "text": "and the nice thing about this is also",
    "start": "690240",
    "end": "692560"
  },
  {
    "text": "that you know because",
    "start": "692560",
    "end": "693839"
  },
  {
    "text": "ludwig packages up all these",
    "start": "693839",
    "end": "695519"
  },
  {
    "text": "state-of-the-art techniques into one",
    "start": "695519",
    "end": "696959"
  },
  {
    "text": "system",
    "start": "696959",
    "end": "697839"
  },
  {
    "text": "you get all this for free without having",
    "start": "697839",
    "end": "699839"
  },
  {
    "text": "to re-implement yourself like say",
    "start": "699839",
    "end": "702800"
  },
  {
    "text": "the latest uh nlp model or the latest",
    "start": "702800",
    "end": "705519"
  },
  {
    "text": "you know tabular model",
    "start": "705519",
    "end": "707120"
  },
  {
    "text": "so with ludwig for instance we have um",
    "start": "707120",
    "end": "710320"
  },
  {
    "text": "tabnet as a recent contribution to to",
    "start": "710320",
    "end": "713120"
  },
  {
    "text": "the framework that achieves",
    "start": "713120",
    "end": "714240"
  },
  {
    "text": "state-of-the-art accuracy",
    "start": "714240",
    "end": "716160"
  },
  {
    "text": "on a number of different previously",
    "start": "716160",
    "end": "719519"
  },
  {
    "text": "very difficult for neural networks",
    "start": "719519",
    "end": "721279"
  },
  {
    "text": "problems like force tree cover higgs",
    "start": "721279",
    "end": "723040"
  },
  {
    "text": "boson",
    "start": "723040",
    "end": "723920"
  },
  {
    "text": "and as you can see we achieve parity",
    "start": "723920",
    "end": "725920"
  },
  {
    "text": "with the the",
    "start": "725920",
    "end": "726959"
  },
  {
    "text": "accuracies reported in the original",
    "start": "726959",
    "end": "728720"
  },
  {
    "text": "tabnet paper",
    "start": "728720",
    "end": "730079"
  },
  {
    "text": "but that's also extensible to nlp",
    "start": "730079",
    "end": "732160"
  },
  {
    "text": "problems as well so we package up",
    "start": "732160",
    "end": "734399"
  },
  {
    "text": "hugging face transformers for example as",
    "start": "734399",
    "end": "736959"
  },
  {
    "text": "optional encoders you can use for text",
    "start": "736959",
    "end": "738880"
  },
  {
    "text": "features",
    "start": "738880",
    "end": "739839"
  },
  {
    "text": "and with these you get all these",
    "start": "739839",
    "end": "741120"
  },
  {
    "start": "741000",
    "end": "741000"
  },
  {
    "text": "different model architectures which",
    "start": "741120",
    "end": "742639"
  },
  {
    "text": "achieve state of the art results on a",
    "start": "742639",
    "end": "744079"
  },
  {
    "text": "variety of data sets",
    "start": "744079",
    "end": "745600"
  },
  {
    "text": "and this is all available to you for",
    "start": "745600",
    "end": "747040"
  },
  {
    "text": "free with ludwig so instead of having to",
    "start": "747040",
    "end": "749040"
  },
  {
    "text": "rewrite this yourself",
    "start": "749040",
    "end": "750480"
  },
  {
    "text": "you just pull the latest version of",
    "start": "750480",
    "end": "752000"
  },
  {
    "text": "ludwig and you get all these new models",
    "start": "752000",
    "end": "754000"
  },
  {
    "text": "for free",
    "start": "754000",
    "end": "756320"
  },
  {
    "text": "so this transitions into a little bit",
    "start": "756320",
    "end": "759040"
  },
  {
    "text": "more about",
    "start": "759040",
    "end": "760079"
  },
  {
    "text": "uh the benefits of declarative not just",
    "start": "760079",
    "end": "762079"
  },
  {
    "text": "for uh being able to use new model",
    "start": "762079",
    "end": "764160"
  },
  {
    "text": "architectures but also for being able to",
    "start": "764160",
    "end": "766079"
  },
  {
    "text": "scale in ways that were previously not",
    "start": "766079",
    "end": "767839"
  },
  {
    "text": "possible",
    "start": "767839",
    "end": "768800"
  },
  {
    "text": "and that's what fundamentally ludwig on",
    "start": "768800",
    "end": "770639"
  },
  {
    "text": "ray is all about so in the original",
    "start": "770639",
    "end": "772720"
  },
  {
    "text": "implementation of ludwig",
    "start": "772720",
    "end": "774959"
  },
  {
    "text": "we were very much focused on kind of the",
    "start": "774959",
    "end": "776639"
  },
  {
    "text": "single machine",
    "start": "776639",
    "end": "778399"
  },
  {
    "text": "like development on your local laptop",
    "start": "778399",
    "end": "780079"
  },
  {
    "text": "way of doing training right",
    "start": "780079",
    "end": "781920"
  },
  {
    "text": "so what we would do is we would take",
    "start": "781920",
    "end": "783360"
  },
  {
    "text": "your data set which resided on local",
    "start": "783360",
    "end": "785440"
  },
  {
    "text": "disks somewhere",
    "start": "785440",
    "end": "786720"
  },
  {
    "text": "the configuration that we showed before",
    "start": "786720",
    "end": "788880"
  },
  {
    "text": "and then we would read the data into",
    "start": "788880",
    "end": "790560"
  },
  {
    "text": "memory",
    "start": "790560",
    "end": "791360"
  },
  {
    "text": "using pandas transform it into numpy",
    "start": "791360",
    "end": "794480"
  },
  {
    "text": "arrays",
    "start": "794480",
    "end": "795200"
  },
  {
    "text": "do training on tensorflow and then",
    "start": "795200",
    "end": "796800"
  },
  {
    "text": "evaluation and tensorflow",
    "start": "796800",
    "end": "798959"
  },
  {
    "text": "and this had a few limitations one of",
    "start": "798959",
    "end": "801200"
  },
  {
    "text": "which is that the data",
    "start": "801200",
    "end": "802639"
  },
  {
    "text": "and pandas has to fit inside memory it",
    "start": "802639",
    "end": "804480"
  },
  {
    "text": "doesn't do any out of core processing or",
    "start": "804480",
    "end": "806240"
  },
  {
    "text": "anything like that",
    "start": "806240",
    "end": "807519"
  },
  {
    "text": "and with tensorflow by itself you don't",
    "start": "807519",
    "end": "809200"
  },
  {
    "text": "get any distributed training so we're",
    "start": "809200",
    "end": "810800"
  },
  {
    "text": "processing on a single machine and",
    "start": "810800",
    "end": "812240"
  },
  {
    "text": "similarly",
    "start": "812240",
    "end": "813200"
  },
  {
    "text": "all the evaluation was happening on a",
    "start": "813200",
    "end": "814880"
  },
  {
    "text": "single machine which was running locally",
    "start": "814880",
    "end": "818480"
  },
  {
    "text": "now with ludwig on ray recently",
    "start": "818480",
    "end": "820480"
  },
  {
    "text": "introduced in v0.4 of ludwig",
    "start": "820480",
    "end": "823040"
  },
  {
    "text": "what we've been able to do is given the",
    "start": "823040",
    "end": "824639"
  },
  {
    "text": "same config so making zero code changes",
    "start": "824639",
    "end": "827760"
  },
  {
    "text": "to your to your application what you can",
    "start": "827760",
    "end": "830320"
  },
  {
    "text": "now do",
    "start": "830320",
    "end": "831040"
  },
  {
    "text": "is use ludwig on ray which provides das",
    "start": "831040",
    "end": "834079"
  },
  {
    "text": "for doing pre-processing horvat on ray",
    "start": "834079",
    "end": "837040"
  },
  {
    "text": "for doing",
    "start": "837040",
    "end": "838000"
  },
  {
    "text": "distributed training and then dasgun ray",
    "start": "838000",
    "end": "839920"
  },
  {
    "text": "for doing evaluation",
    "start": "839920",
    "end": "841760"
  },
  {
    "text": "and as a result what we're able to do is",
    "start": "841760",
    "end": "845120"
  },
  {
    "text": "process very large data sets using out",
    "start": "845120",
    "end": "847279"
  },
  {
    "text": "of core execution",
    "start": "847279",
    "end": "848480"
  },
  {
    "text": "parallel execution all on top of ray",
    "start": "848480",
    "end": "851519"
  },
  {
    "text": "we're able to ingest data directly from",
    "start": "851519",
    "end": "853680"
  },
  {
    "text": "remote data sources like",
    "start": "853680",
    "end": "855199"
  },
  {
    "text": "s3 or from warehouses like snowflake",
    "start": "855199",
    "end": "858959"
  },
  {
    "text": "do the data processing transform it into",
    "start": "858959",
    "end": "861920"
  },
  {
    "text": "transform data and store it as part k",
    "start": "861920",
    "end": "864720"
  },
  {
    "text": "where we then do horvath for doing",
    "start": "864720",
    "end": "867040"
  },
  {
    "text": "distributed training so horebot on ray",
    "start": "867040",
    "end": "869360"
  },
  {
    "text": "and finally we do distributed tensorflow",
    "start": "869360",
    "end": "872480"
  },
  {
    "start": "872000",
    "end": "872000"
  },
  {
    "text": "using dask to do a parallel batch",
    "start": "872480",
    "end": "874959"
  },
  {
    "text": "prediction as well",
    "start": "874959",
    "end": "876320"
  },
  {
    "text": "and all of this can be initialized from",
    "start": "876320",
    "end": "878800"
  },
  {
    "text": "your local machine and then executed",
    "start": "878800",
    "end": "880399"
  },
  {
    "text": "remotely on ray",
    "start": "880399",
    "end": "881760"
  },
  {
    "text": "using the kind of infinite laptop",
    "start": "881760",
    "end": "883440"
  },
  {
    "text": "abstraction that ray",
    "start": "883440",
    "end": "885440"
  },
  {
    "text": "provides and so",
    "start": "885440",
    "end": "888880"
  },
  {
    "text": "configuring ray to use ludwig is is also",
    "start": "888880",
    "end": "891279"
  },
  {
    "text": "very simple",
    "start": "891279",
    "end": "892560"
  },
  {
    "text": "it's nothing special for ludwig but this",
    "start": "892560",
    "end": "895440"
  },
  {
    "text": "is an example of a configuration that",
    "start": "895440",
    "end": "897199"
  },
  {
    "text": "you might typically",
    "start": "897199",
    "end": "898079"
  },
  {
    "text": "see when running a distributed load wave",
    "start": "898079",
    "end": "900480"
  },
  {
    "text": "on top of ray",
    "start": "900480",
    "end": "901600"
  },
  {
    "text": "so here i define my cluster i specify my",
    "start": "901600",
    "end": "904000"
  },
  {
    "text": "cluster name",
    "start": "904000",
    "end": "905360"
  },
  {
    "text": "i have how many workers i want to use in",
    "start": "905360",
    "end": "907279"
  },
  {
    "text": "this case for",
    "start": "907279",
    "end": "909120"
  },
  {
    "text": "i specify the docker image and in this",
    "start": "909120",
    "end": "911519"
  },
  {
    "text": "case",
    "start": "911519",
    "end": "912240"
  },
  {
    "text": "what we do is we actually publish uh gpu",
    "start": "912240",
    "end": "914720"
  },
  {
    "text": "ray images",
    "start": "914720",
    "end": "915519"
  },
  {
    "text": "for ludwig every night and every release",
    "start": "915519",
    "end": "917920"
  },
  {
    "text": "which you can",
    "start": "917920",
    "end": "918720"
  },
  {
    "text": "download from docker hub and typically",
    "start": "918720",
    "end": "921120"
  },
  {
    "text": "what i'll do is i'll",
    "start": "921120",
    "end": "922079"
  },
  {
    "text": "use a cpu instance here these are ec2",
    "start": "922079",
    "end": "924880"
  },
  {
    "start": "923000",
    "end": "923000"
  },
  {
    "text": "instances of course on aws",
    "start": "924880",
    "end": "927040"
  },
  {
    "text": "and this will be a cpu instance for the",
    "start": "927040",
    "end": "929360"
  },
  {
    "text": "head node and then my worker nodes will",
    "start": "929360",
    "end": "931040"
  },
  {
    "text": "be",
    "start": "931040",
    "end": "931279"
  },
  {
    "text": "gpu instances here that are using one t4",
    "start": "931279",
    "end": "935199"
  },
  {
    "text": "gpu right and running ludwig and",
    "start": "935199",
    "end": "939440"
  },
  {
    "text": "versus running ludwig on ray is not all",
    "start": "939440",
    "end": "941839"
  },
  {
    "text": "that different",
    "start": "941839",
    "end": "942560"
  },
  {
    "text": "uh running ludwig you just say ludwig",
    "start": "942560",
    "end": "944480"
  },
  {
    "text": "train you give it your configuration",
    "start": "944480",
    "end": "946000"
  },
  {
    "text": "file",
    "start": "946000",
    "end": "946399"
  },
  {
    "text": "and you point it to a data set and then",
    "start": "946399",
    "end": "948560"
  },
  {
    "text": "similarly if you want to run ludwig on",
    "start": "948560",
    "end": "950320"
  },
  {
    "text": "range you do the exact same thing",
    "start": "950320",
    "end": "952240"
  },
  {
    "text": "but with two extra two additional",
    "start": "952240",
    "end": "954399"
  },
  {
    "text": "modifications you first need to",
    "start": "954399",
    "end": "956800"
  },
  {
    "text": "instantiate your ray cluster of course",
    "start": "956800",
    "end": "959040"
  },
  {
    "text": "and then you need to",
    "start": "959040",
    "end": "960160"
  },
  {
    "text": "submit the raid training function to the",
    "start": "960160",
    "end": "962480"
  },
  {
    "text": "ray cluster for execution",
    "start": "962480",
    "end": "966079"
  },
  {
    "text": "another feature that we added to ludwig",
    "start": "966480",
    "end": "969160"
  },
  {
    "text": "4v0.4",
    "start": "969160",
    "end": "970320"
  },
  {
    "text": "is a hyperparameter search using raytune",
    "start": "970320",
    "end": "973519"
  },
  {
    "text": "and with this you can take the same",
    "start": "973519",
    "end": "976399"
  },
  {
    "text": "configuration that",
    "start": "976399",
    "end": "977519"
  },
  {
    "text": "we saw before and then explore different",
    "start": "977519",
    "end": "979839"
  },
  {
    "text": "hyperparameters in parallel",
    "start": "979839",
    "end": "981360"
  },
  {
    "text": "using the state of the art raytune",
    "start": "981360",
    "end": "983920"
  },
  {
    "text": "library which provides lots of different",
    "start": "983920",
    "end": "986079"
  },
  {
    "text": "algorithms out of the box and all these",
    "start": "986079",
    "end": "988880"
  },
  {
    "text": "are made available to you",
    "start": "988880",
    "end": "990160"
  },
  {
    "text": "using ludwig with just a few simple",
    "start": "990160",
    "end": "991920"
  },
  {
    "text": "changes to the config as we'll see here",
    "start": "991920",
    "end": "994800"
  },
  {
    "text": "so if you want to do hyper parameter",
    "start": "994800",
    "end": "996320"
  },
  {
    "text": "search with ludwig using ray tune",
    "start": "996320",
    "end": "998560"
  },
  {
    "text": "uh you just specify the parameters you",
    "start": "998560",
    "end": "1000240"
  },
  {
    "text": "want to tune and then you can optionally",
    "start": "1000240",
    "end": "1001920"
  },
  {
    "text": "provide some constraints over that the",
    "start": "1001920",
    "end": "1003839"
  },
  {
    "text": "space to explore",
    "start": "1003839",
    "end": "1005279"
  },
  {
    "text": "you specify what your goal is in this",
    "start": "1005279",
    "end": "1007120"
  },
  {
    "text": "case i want to minimize",
    "start": "1007120",
    "end": "1008959"
  },
  {
    "text": "the the training and then you also are",
    "start": "1008959",
    "end": "1011759"
  },
  {
    "text": "the the loss",
    "start": "1011759",
    "end": "1012720"
  },
  {
    "text": "and then you just specify the executor",
    "start": "1012720",
    "end": "1014720"
  },
  {
    "text": "and sampler that you want to use in this",
    "start": "1014720",
    "end": "1016079"
  },
  {
    "text": "case both",
    "start": "1016079",
    "end": "1016880"
  },
  {
    "text": "the standard defaults for ray",
    "start": "1016880",
    "end": "1020000"
  },
  {
    "text": "but this of course like anything in this",
    "start": "1020000",
    "end": "1021839"
  },
  {
    "text": "declarative ludwig",
    "start": "1021839",
    "end": "1023120"
  },
  {
    "text": "style that we've discussed can be",
    "start": "1023120",
    "end": "1025438"
  },
  {
    "text": "customized as well so",
    "start": "1025439",
    "end": "1026798"
  },
  {
    "text": "if you want to use a specific search",
    "start": "1026799",
    "end": "1028160"
  },
  {
    "text": "algorithm in this case",
    "start": "1028160",
    "end": "1030079"
  },
  {
    "text": "bohb a specific scheduler",
    "start": "1030079",
    "end": "1033600"
  },
  {
    "text": "specify how many samples you want to use",
    "start": "1033600",
    "end": "1035678"
  },
  {
    "text": "anything that you can do",
    "start": "1035679",
    "end": "1036880"
  },
  {
    "text": "using raytune in the config you can",
    "start": "1036880",
    "end": "1039678"
  },
  {
    "text": "specify it here in the hyperparameter",
    "start": "1039679",
    "end": "1041760"
  },
  {
    "text": "search or hyperopt config portion of",
    "start": "1041760",
    "end": "1043760"
  },
  {
    "text": "ludwig",
    "start": "1043760",
    "end": "1046160"
  },
  {
    "text": "and finally i also want to call out some",
    "start": "1046160",
    "end": "1048319"
  },
  {
    "text": "automotive work that we're doing",
    "start": "1048319",
    "end": "1050160"
  },
  {
    "text": "this is a bit experimental at the moment",
    "start": "1050160",
    "end": "1052000"
  },
  {
    "text": "um so some of these apis are subject to",
    "start": "1052000",
    "end": "1054000"
  },
  {
    "text": "change",
    "start": "1054000",
    "end": "1054880"
  },
  {
    "text": "but what we're doing is taking the same",
    "start": "1054880",
    "end": "1057039"
  },
  {
    "text": "idea of building on top of this idea of",
    "start": "1057039",
    "end": "1059200"
  },
  {
    "text": "hyper parameter search",
    "start": "1059200",
    "end": "1060640"
  },
  {
    "text": "using ray tune and doing distributed",
    "start": "1060640",
    "end": "1062880"
  },
  {
    "text": "training with horovat on ray with das",
    "start": "1062880",
    "end": "1066960"
  },
  {
    "text": "and what we're doing is providing this",
    "start": "1068960",
    "end": "1071039"
  },
  {
    "text": "auto train api",
    "start": "1071039",
    "end": "1072240"
  },
  {
    "text": "on top of all these things that will",
    "start": "1072240",
    "end": "1074240"
  },
  {
    "text": "allow you to instead of specifying the",
    "start": "1074240",
    "end": "1076240"
  },
  {
    "text": "complete config",
    "start": "1076240",
    "end": "1077120"
  },
  {
    "text": "just specify the target that you want to",
    "start": "1077120",
    "end": "1078799"
  },
  {
    "text": "predict and then",
    "start": "1078799",
    "end": "1080400"
  },
  {
    "text": "ludwig will do the hard work of running",
    "start": "1080400",
    "end": "1082160"
  },
  {
    "text": "the hyper parameter search and figuring",
    "start": "1082160",
    "end": "1083840"
  },
  {
    "text": "out",
    "start": "1083840",
    "end": "1084480"
  },
  {
    "text": "what the best uh what the best",
    "start": "1084480",
    "end": "1086799"
  },
  {
    "text": "parameters are in order to",
    "start": "1086799",
    "end": "1088559"
  },
  {
    "text": "achieve the results you're looking for",
    "start": "1088559",
    "end": "1090720"
  },
  {
    "text": "and there's some",
    "start": "1090720",
    "end": "1092240"
  },
  {
    "text": "work going on in conjunct in conjunction",
    "start": "1092240",
    "end": "1094080"
  },
  {
    "text": "with some folks at stanford right now",
    "start": "1094080",
    "end": "1096320"
  },
  {
    "text": "in order to uh that will be exploring",
    "start": "1096320",
    "end": "1098640"
  },
  {
    "text": "exactly the techniques that we're we're",
    "start": "1098640",
    "end": "1100400"
  },
  {
    "text": "going to be using for doing auto",
    "start": "1100400",
    "end": "1101840"
  },
  {
    "text": "training and",
    "start": "1101840",
    "end": "1102799"
  },
  {
    "text": "benchmarking the different uh hyper",
    "start": "1102799",
    "end": "1104799"
  },
  {
    "text": "parameter search strategies on different",
    "start": "1104799",
    "end": "1106320"
  },
  {
    "text": "model types and data sets",
    "start": "1106320",
    "end": "1108080"
  },
  {
    "text": "so look for that later this summer as",
    "start": "1108080",
    "end": "1109840"
  },
  {
    "text": "well",
    "start": "1109840",
    "end": "1112080"
  },
  {
    "text": "and last but not least i want to briefly",
    "start": "1112160",
    "end": "1114640"
  },
  {
    "text": "talk a little bit about",
    "start": "1114640",
    "end": "1116080"
  },
  {
    "text": "the future of ludwig and",
    "start": "1116080",
    "end": "1119280"
  },
  {
    "text": "what we're doing with our new company",
    "start": "1119280",
    "end": "1121360"
  },
  {
    "start": "1120000",
    "end": "1120000"
  },
  {
    "text": "called prettybase so",
    "start": "1121360",
    "end": "1123039"
  },
  {
    "text": "prettybase is started by um the uh",
    "start": "1123039",
    "end": "1126960"
  },
  {
    "text": "two people from from uber ai myself and",
    "start": "1126960",
    "end": "1129280"
  },
  {
    "text": "piero molina who's the original author",
    "start": "1129280",
    "end": "1131039"
  },
  {
    "text": "of ludwig",
    "start": "1131039",
    "end": "1132400"
  },
  {
    "text": "as well as um some other folks uh",
    "start": "1132400",
    "end": "1135280"
  },
  {
    "text": "deborah rishi from",
    "start": "1135280",
    "end": "1136400"
  },
  {
    "text": "previously a product manager google and",
    "start": "1136400",
    "end": "1138080"
  },
  {
    "text": "chris wray from from stanford",
    "start": "1138080",
    "end": "1140400"
  },
  {
    "text": "and the idea behind preda base is that",
    "start": "1140400",
    "end": "1142799"
  },
  {
    "text": "we want to take",
    "start": "1142799",
    "end": "1143760"
  },
  {
    "text": "these ideas uh at the heart of lubricant",
    "start": "1143760",
    "end": "1146160"
  },
  {
    "text": "ray",
    "start": "1146160",
    "end": "1147039"
  },
  {
    "text": "and sort of find a way to bring them to",
    "start": "1147039",
    "end": "1149440"
  },
  {
    "text": "the enterprise with a focus on",
    "start": "1149440",
    "end": "1152880"
  },
  {
    "text": "quick productionization and getting",
    "start": "1152880",
    "end": "1155760"
  },
  {
    "text": "models to derive value for your",
    "start": "1155760",
    "end": "1157440"
  },
  {
    "text": "organization with very minimal overhead",
    "start": "1157440",
    "end": "1159840"
  },
  {
    "text": "so specifically we want to bring the",
    "start": "1159840",
    "end": "1161919"
  },
  {
    "text": "simplicity and flexibility of the",
    "start": "1161919",
    "end": "1163440"
  },
  {
    "text": "declarative",
    "start": "1163440",
    "end": "1164000"
  },
  {
    "text": "ml that ludwig provides with the",
    "start": "1164000",
    "end": "1165679"
  },
  {
    "text": "scalability of horvat on ray",
    "start": "1165679",
    "end": "1168080"
  },
  {
    "text": "and combine that with your existing data",
    "start": "1168080",
    "end": "1170640"
  },
  {
    "text": "infrastructure",
    "start": "1170640",
    "end": "1171679"
  },
  {
    "text": "to create this new type of abstraction",
    "start": "1171679",
    "end": "1173520"
  },
  {
    "text": "that we call the predictive database",
    "start": "1173520",
    "end": "1176080"
  },
  {
    "text": "and so as i said we're still in stealth",
    "start": "1176080",
    "end": "1177919"
  },
  {
    "text": "so i don't have",
    "start": "1177919",
    "end": "1179440"
  },
  {
    "text": "too much to show you yet about what",
    "start": "1179440",
    "end": "1180960"
  },
  {
    "text": "exactly this means but to give you a",
    "start": "1180960",
    "end": "1183039"
  },
  {
    "text": "very quick sneak peek",
    "start": "1183039",
    "end": "1184640"
  },
  {
    "text": "um what you can do is you can imagine um",
    "start": "1184640",
    "end": "1188720"
  },
  {
    "text": "that we fundamentally want to make",
    "start": "1188720",
    "end": "1192240"
  },
  {
    "text": "the machine learning process as simple",
    "start": "1192240",
    "end": "1194320"
  },
  {
    "text": "and fast as writing any query",
    "start": "1194320",
    "end": "1196960"
  },
  {
    "text": "in a language like sql and to do that we",
    "start": "1196960",
    "end": "1199919"
  },
  {
    "text": "provide",
    "start": "1199919",
    "end": "1201039"
  },
  {
    "text": "some tools that sit on top of your",
    "start": "1201039",
    "end": "1202559"
  },
  {
    "text": "database",
    "start": "1202559",
    "end": "1204080"
  },
  {
    "text": "that integrate very directly with ludwig",
    "start": "1204080",
    "end": "1206159"
  },
  {
    "text": "and horvath",
    "start": "1206159",
    "end": "1207679"
  },
  {
    "text": "and allow you to express the intent of",
    "start": "1207679",
    "end": "1210240"
  },
  {
    "text": "what it is you want to predict",
    "start": "1210240",
    "end": "1212320"
  },
  {
    "text": "uh using a dialect that should be very",
    "start": "1212320",
    "end": "1214640"
  },
  {
    "text": "familiar to anyone who's ever worked",
    "start": "1214640",
    "end": "1216000"
  },
  {
    "text": "with sql so for example",
    "start": "1216000",
    "end": "1217919"
  },
  {
    "text": "in this example here if you want to if",
    "start": "1217919",
    "end": "1220640"
  },
  {
    "text": "you have a customer table in your",
    "start": "1220640",
    "end": "1221919"
  },
  {
    "text": "database",
    "start": "1221919",
    "end": "1222640"
  },
  {
    "text": "and you want to predict which of your",
    "start": "1222640",
    "end": "1223840"
  },
  {
    "text": "customers are going to churn instead of",
    "start": "1223840",
    "end": "1225919"
  },
  {
    "text": "having to think about some",
    "start": "1225919",
    "end": "1227840"
  },
  {
    "text": "elaborate process to pull the data out",
    "start": "1227840",
    "end": "1230240"
  },
  {
    "text": "train a model",
    "start": "1230240",
    "end": "1231679"
  },
  {
    "text": "figure out how you're going to scale the",
    "start": "1231679",
    "end": "1232960"
  },
  {
    "text": "training using the resources you have",
    "start": "1232960",
    "end": "1235280"
  },
  {
    "text": "how to productionize it how to serve it",
    "start": "1235280",
    "end": "1237600"
  },
  {
    "text": "you just simply say",
    "start": "1237600",
    "end": "1239120"
  },
  {
    "text": "given the data for my customer table",
    "start": "1239120",
    "end": "1241360"
  },
  {
    "text": "filter it by some",
    "start": "1241360",
    "end": "1242799"
  },
  {
    "text": "standard sql predicates and predict the",
    "start": "1242799",
    "end": "1245600"
  },
  {
    "text": "target that i want to predict in this",
    "start": "1245600",
    "end": "1247039"
  },
  {
    "text": "case churn",
    "start": "1247039",
    "end": "1248559"
  },
  {
    "text": "and so we'll have a lot more to say",
    "start": "1248559",
    "end": "1250000"
  },
  {
    "text": "about this in the coming months",
    "start": "1250000",
    "end": "1252000"
  },
  {
    "text": "but you know please reach out to me",
    "start": "1252000",
    "end": "1254000"
  },
  {
    "text": "travis prettybase.com if you're",
    "start": "1254000",
    "end": "1255600"
  },
  {
    "text": "interested in hearing more about this",
    "start": "1255600",
    "end": "1257679"
  },
  {
    "text": "and definitely for anyone out there who",
    "start": "1257679",
    "end": "1260320"
  },
  {
    "text": "is really interested we are hiring so",
    "start": "1260320",
    "end": "1262080"
  },
  {
    "text": "please",
    "start": "1262080",
    "end": "1262880"
  },
  {
    "text": "reach out to me if you're looking for a",
    "start": "1262880",
    "end": "1264559"
  },
  {
    "text": "new job as well",
    "start": "1264559",
    "end": "1266159"
  },
  {
    "text": "and with that i want to thank you all",
    "start": "1266159",
    "end": "1268400"
  },
  {
    "text": "for taking the time to",
    "start": "1268400",
    "end": "1269919"
  },
  {
    "text": "come out and listen to my presentation",
    "start": "1269919",
    "end": "1271360"
  },
  {
    "text": "today i hope that you'll go and check",
    "start": "1271360",
    "end": "1273520"
  },
  {
    "text": "out ludwig",
    "start": "1273520",
    "end": "1274720"
  },
  {
    "text": "and tell me all about what you think",
    "start": "1274720",
    "end": "1276559"
  },
  {
    "text": "about it feel free to reach out",
    "start": "1276559",
    "end": "1278559"
  },
  {
    "text": "anytime and thanks again",
    "start": "1278559",
    "end": "1286000"
  }
]
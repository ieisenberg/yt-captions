[
  {
    "text": "good afternoon everyone uh thanks for coming uh I'm Lim ma from by Dance I'm",
    "start": "3179",
    "end": "8639"
  },
  {
    "text": "very happy to be here to share some of our ongoing effort in building a serverless resilient graph analysis",
    "start": "8639",
    "end": "15000"
  },
  {
    "text": "framework with the hierarchical Precision storage by leveraging the powerful capability of Rey so typically",
    "start": "15000",
    "end": "22080"
  },
  {
    "text": "this is a ray use case as well in the graph domain so before uh I'm going to",
    "start": "22080",
    "end": "28560"
  },
  {
    "text": "elaborate how we use the array I would like to firstly recap how the existing",
    "start": "28560",
    "end": "33920"
  },
  {
    "text": "graph Computing system looks like so graphs are relational data structures",
    "start": "33920",
    "end": "39899"
  },
  {
    "text": "that can Define information collectively by using the node and Edge structures in",
    "start": "39899",
    "end": "46620"
  },
  {
    "text": "a non-linear way we can store a lot of information for example now there's a lot of",
    "start": "46620",
    "end": "52399"
  },
  {
    "text": "real world applications for example the interest or the behavior based research",
    "start": "52399",
    "end": "59640"
  },
  {
    "text": "or recommendations like your Twitter her accounts social networks your Netflix",
    "start": "59640",
    "end": "66380"
  },
  {
    "text": "movie movies deck as well as the biological networks iot devices networks",
    "start": "66380",
    "end": "72659"
  },
  {
    "text": "all these are real application that can be represented by graphs so this we also",
    "start": "72659",
    "end": "79439"
  },
  {
    "text": "have a wide adoption in our company as well so we have a thousands of graph Computing jobs every day a whole bunch",
    "start": "79439",
    "end": "86280"
  },
  {
    "text": "of algorithms for example we use the page rank to identify the top content creators in Tick Tock and also we have a",
    "start": "86280",
    "end": "94380"
  },
  {
    "text": "connected components to capture the cluster for bad accounts better behaviors and also like between as a",
    "start": "94380",
    "end": "101820"
  },
  {
    "text": "centrality where we use it to extract the features for Downstream application as well and all these algorithms rise on",
    "start": "101820",
    "end": "109200"
  },
  {
    "text": "super large scale graphs say like tens of billions of nodes and hundreds of",
    "start": "109200",
    "end": "115680"
  },
  {
    "text": "trillion of edges so super large gigantic number of nose and and edges",
    "start": "115680",
    "end": "122360"
  },
  {
    "text": "we started with Plato So which is actually a open source Prego lag system",
    "start": "122360",
    "end": "128220"
  },
  {
    "text": "it's built by a Vertex Centric methodology so what the the what is the",
    "start": "128220",
    "end": "136080"
  },
  {
    "text": "vertex entry so basically for every iteration you update every vertex by",
    "start": "136080",
    "end": "142560"
  },
  {
    "text": "fetching the enabled data and this is every iteration there's a clear vertex",
    "start": "142560",
    "end": "148620"
  },
  {
    "text": "intricate barrier so which means this computation happens for every vertex before it's done you cannot move on to",
    "start": "148620",
    "end": "155760"
  },
  {
    "text": "the next iteration so we can see it's clearly a bsp model using the MPI for",
    "start": "155760",
    "end": "161519"
  },
  {
    "text": "data passing right so in our effort we to meet the production requirements we",
    "start": "161519",
    "end": "167459"
  },
  {
    "text": "did a lot of you know enhancement to that this includes we adapt more implement or more algorithms of graph on",
    "start": "167459",
    "end": "174900"
  },
  {
    "text": "that and also we extend the data ranges we fixed a bunch of bugs especially the",
    "start": "174900",
    "end": "180000"
  },
  {
    "text": "NPI related so here's something that really had it so um when the when the graph becomes really large the socket",
    "start": "180000",
    "end": "186780"
  },
  {
    "text": "issue becomes available and the negative lens issue becomes available and also",
    "start": "186780",
    "end": "192360"
  },
  {
    "text": "the MPI randomly fail because of the the system-wise assertions so this happens",
    "start": "192360",
    "end": "199200"
  },
  {
    "text": "quite frequently like a certain times a day so all this comes to our headache",
    "start": "199200",
    "end": "204360"
  },
  {
    "text": "that what's the problem of it right so firstly it has a high cost because the",
    "start": "204360",
    "end": "209519"
  },
  {
    "text": "plateau loads the entire graph into the in memory so in order to host this really big graph in our real production",
    "start": "209519",
    "end": "216540"
  },
  {
    "text": "case we would have too large a large number of nodes so which means it's very",
    "start": "216540",
    "end": "222299"
  },
  {
    "text": "nose consuming and also It suffers with high maintenance cost because as I",
    "start": "222299",
    "end": "228360"
  },
  {
    "text": "mentioned it's frequently failure with MPI and there's no checkpointing for that so which means you can use trainer",
    "start": "228360",
    "end": "234540"
  },
  {
    "text": "if you even if you do a Computing job for 10 days and at the very last second",
    "start": "234540",
    "end": "241080"
  },
  {
    "text": "if it failed you would have to restart from the very beginning so that's very time consuming and resource consuming",
    "start": "241080",
    "end": "246540"
  },
  {
    "text": "and also although it is work eccentric but it is a mix of poo and push Lambda",
    "start": "246540",
    "end": "252659"
  },
  {
    "text": "functions which make the program really not friendly and hard to program",
    "start": "252659",
    "end": "258419"
  },
  {
    "text": "so to deal with these three issues um what we are thinking about is that maybe",
    "start": "258419",
    "end": "263639"
  },
  {
    "text": "the hierarchical storage can help right if we leverage the nvme SSD we can",
    "start": "263639",
    "end": "270120"
  },
  {
    "text": "offload the large amount of data off to the out of core memories uh in this case",
    "start": "270120",
    "end": "275940"
  },
  {
    "text": "we can reduce the uh the the Computing nodes scale for example uh normally many",
    "start": "275940",
    "end": "283020"
  },
  {
    "text": "use Southern nodes now probably you can just use tense of that right or even",
    "start": "283020",
    "end": "288060"
  },
  {
    "text": "smaller number of that and also the for tolerant part we want to cover the",
    "start": "288060",
    "end": "293639"
  },
  {
    "text": "fourth tolerant part we don't want any recomputer in an unnecessary way and we",
    "start": "293639",
    "end": "299460"
  },
  {
    "text": "want to have the end-to-end failure recovery for the super large graph for",
    "start": "299460",
    "end": "305280"
  },
  {
    "text": "the graph Computing job and lately um we wanted this one to be very",
    "start": "305280",
    "end": "311100"
  },
  {
    "text": "friendly for for graph scientists to write their own algorithm to implement their algorithms so that's why we try to",
    "start": "311100",
    "end": "317820"
  },
  {
    "text": "define a Udi UDF with python apis since this greatly simplifies the apis so here",
    "start": "317820",
    "end": "325440"
  },
  {
    "text": "is some of the motivation that we do this work um So based on the analysis we try to",
    "start": "325440",
    "end": "334020"
  },
  {
    "text": "build our internal bed Gap solution which is uh the bad the the binance",
    "start": "334020",
    "end": "341520"
  },
  {
    "text": "graph and Analysis platform the Gap is for the short acronym for graph",
    "start": "341520",
    "end": "346639"
  },
  {
    "text": "analytics platform um so how the system looks like we can see from this figure we have a several",
    "start": "346639",
    "end": "354080"
  },
  {
    "text": "components in this system overview so in the middle there's a workers workers are",
    "start": "354080",
    "end": "360479"
  },
  {
    "text": "the major components of this system so the worker is the place where we really",
    "start": "360479",
    "end": "366360"
  },
  {
    "text": "implement the compute operators that implement the different graph algorithms for example graph mining workers logic",
    "start": "366360",
    "end": "375360"
  },
  {
    "text": "and graphic Computing logic they all Implement in this part and they communicate with each other through the",
    "start": "375360",
    "end": "381120"
  },
  {
    "text": "mpis and below the workers they're persistent volume percent storage in which it is",
    "start": "381120",
    "end": "389400"
  },
  {
    "text": "actually um a hierarchical storage of different layers it could be dram it could be pmam",
    "start": "389400",
    "end": "396060"
  },
  {
    "text": "could be SSD or combination of those um so the progester volume actually uh",
    "start": "396060",
    "end": "401580"
  },
  {
    "text": "fetched the partition the graph data from remote file systems in addition to that during the computation during the",
    "start": "401580",
    "end": "409020"
  },
  {
    "text": "entire worker computation the intermediate States will also be recorded will be saved into the",
    "start": "409020",
    "end": "414419"
  },
  {
    "text": "persistent volume for example the checkpoints the messages and that's the persistent volume part",
    "start": "414419",
    "end": "421620"
  },
  {
    "text": "and at the very top the red part is the job server and the cost scheduler which is actually a a serverless engine built",
    "start": "421620",
    "end": "428940"
  },
  {
    "text": "on top of the kubernetes to provide several important capabilities the first",
    "start": "428940",
    "end": "434220"
  },
  {
    "text": "it provides a flexible cluster Resource Management so by using this is the",
    "start": "434220",
    "end": "440460"
  },
  {
    "text": "resource management management can be are purely transparent to the users and also automatic deployment capabilities",
    "start": "440460",
    "end": "447240"
  },
  {
    "text": "we use a large graph Computing job is normally with a lot of workers right so",
    "start": "447240",
    "end": "454199"
  },
  {
    "text": "all this handling work can be can be covered by this service engine to finish",
    "start": "454199",
    "end": "460620"
  },
  {
    "text": "the automatic deployment and also we decoupled the through this architecture",
    "start": "460620",
    "end": "466139"
  },
  {
    "text": "we do a couple of compute and storage and provide the end-to-end for tolerant",
    "start": "466139",
    "end": "471360"
  },
  {
    "text": "so we can see the workers are purely stateless so the workers are getting the data from persistent volume by this",
    "start": "471360",
    "end": "479520"
  },
  {
    "text": "means whenever workers failed we can have this engine automatically relax the",
    "start": "479520",
    "end": "485099"
  },
  {
    "text": "worker and hooked with the correct volume data stories previous States and resume the work resume the graph",
    "start": "485099",
    "end": "492180"
  },
  {
    "text": "Computing job moving forward and um and the last day is the hydrogenous stories uh story support by",
    "start": "492180",
    "end": "499199"
  },
  {
    "text": "this engine which I already mentioned so how do we implement this we Implement",
    "start": "499199",
    "end": "504539"
  },
  {
    "text": "and deploy it on a cloud using the kuberate as well as Ray elastic Ray elastic is uh originally built uh",
    "start": "504539",
    "end": "511740"
  },
  {
    "text": "in-house a infrastructure components which I will talk about that after after",
    "start": "511740",
    "end": "518459"
  },
  {
    "text": "uh like two slides later um so why we used to rate because we can",
    "start": "518459",
    "end": "524159"
  },
  {
    "text": "easily have this distribute abstraction and programming model to scale our workload from single node to any skill",
    "start": "524159",
    "end": "531120"
  },
  {
    "text": "right and also it has Rich ecosystem for libraries that we can easily hook on and",
    "start": "531120",
    "end": "536580"
  },
  {
    "text": "use Autobox we even build our own Ray platform",
    "start": "536580",
    "end": "541740"
  },
  {
    "text": "within a company on top of the ray operator and auto scalers if you can see",
    "start": "541740",
    "end": "546959"
  },
  {
    "text": "from this figure we even we also built our quota management job management",
    "start": "546959",
    "end": "552500"
  },
  {
    "text": "dashboard workspace and so on so forth all the orchestrations and we also",
    "start": "552500",
    "end": "557700"
  },
  {
    "text": "provide services within a company based on this real platform for example automl service or different services",
    "start": "557700",
    "end": "565200"
  },
  {
    "text": "um so how this graph Computing system looks like on the cloud so basically from this figure I want to show that",
    "start": "565200",
    "end": "572160"
  },
  {
    "text": "when a request comes the kuberate controller will create a resource for",
    "start": "572160",
    "end": "577800"
  },
  {
    "text": "this particular cluster so it's a job cluster job-based cluster that when a",
    "start": "577800",
    "end": "583140"
  },
  {
    "text": "job is done the cluster can be reclaimed so it is the corporate controller to",
    "start": "583140",
    "end": "588240"
  },
  {
    "text": "create the resources for this job so in this job cluster as as normal other re",
    "start": "588240",
    "end": "595140"
  },
  {
    "text": "cluster as well there's a have there's a banner workers the Hat will keep the states of entire working group for",
    "start": "595140",
    "end": "603959"
  },
  {
    "text": "example individual worker and its Rank and also the global the word size of all",
    "start": "603959",
    "end": "609720"
  },
  {
    "text": "the ranks as well as the relationship mapping between the workers with the",
    "start": "609720",
    "end": "614940"
  },
  {
    "text": "volume which is the persistent volume through the Pod and for the rest of the working worker part so basically we have",
    "start": "614940",
    "end": "623519"
  },
  {
    "text": "a in each of the part that we have an agent the the driver of this program will launch the agent to each of this",
    "start": "623519",
    "end": "630660"
  },
  {
    "text": "part and in each of the part the agent will serve the role to large the worker",
    "start": "630660",
    "end": "636420"
  },
  {
    "text": "large the real graph Computing workers and cover the full life cycle of the",
    "start": "636420",
    "end": "641580"
  },
  {
    "text": "worker and have the worker interact you with the p-man with their data stored in",
    "start": "641580",
    "end": "647640"
  },
  {
    "text": "the in the p-man president storage um so why we have this layer of agent so",
    "start": "647640",
    "end": "654480"
  },
  {
    "text": "that comes with the our internal build infrastructure we call it real elastic so it's actually a agent or a ray agent",
    "start": "654480",
    "end": "662519"
  },
  {
    "text": "based for tolerant control plan to cover the entire end-to-end for tolerant",
    "start": "662519",
    "end": "668640"
  },
  {
    "text": "so um again it's an agent-based control plan build array for the presets and stable",
    "start": "668640",
    "end": "675899"
  },
  {
    "text": "rank management and and for tolerant for example I hear listening example",
    "start": "675899",
    "end": "682560"
  },
  {
    "text": "um for arbitrary worker pod right we have an agent in it for example the",
    "start": "682560",
    "end": "687959"
  },
  {
    "text": "agency with the rank K so the rank K agent will large a worker and assign the",
    "start": "687959",
    "end": "693779"
  },
  {
    "text": "rank to it as well um another the worker of rank K will",
    "start": "693779",
    "end": "698940"
  },
  {
    "text": "talk with the pmam volume of Rand K as well to retrieve exactly what it used to",
    "start": "698940",
    "end": "704940"
  },
  {
    "text": "be or what what's the previous States it used to be so we see in this complex interaction",
    "start": "704940",
    "end": "710940"
  },
  {
    "text": "the container May Fail and the agent May Fail and the worker itself May Fail as",
    "start": "710940",
    "end": "716640"
  },
  {
    "text": "well right so um here by using the array elastic we can actually handle the",
    "start": "716640",
    "end": "723300"
  },
  {
    "text": "failure From end-to-end perspective in different three layers from container level from agent level from worker level",
    "start": "723300",
    "end": "729660"
  },
  {
    "text": "that's actually a Synergy that MPI simply cannot fully cover and for the",
    "start": "729660",
    "end": "735959"
  },
  {
    "text": "for the container level whenever the container fails we use the group array to relax the Pod to recreate the pot",
    "start": "735959",
    "end": "742980"
  },
  {
    "text": "right and when the agent is failed the agent actually tried to negotiate we",
    "start": "742980",
    "end": "748560"
  },
  {
    "text": "call Rendezvous to negotiate and assign and also match the ranks for workers and",
    "start": "748560",
    "end": "755160"
  },
  {
    "text": "the Precision volumes and when it's fail it's easily can detect which rank is",
    "start": "755160",
    "end": "760620"
  },
  {
    "text": "wrong and which of the new workers that I need to schedule two um and the the work at the worker level",
    "start": "760620",
    "end": "767820"
  },
  {
    "text": "when the worker is failed we don't want to start from scratch right so the worker has the checkpointing and the",
    "start": "767820",
    "end": "774120"
  },
  {
    "text": "recovery capability at which um you can start from where you were right whether you got field so with all",
    "start": "774120",
    "end": "781680"
  },
  {
    "text": "of this together we can ensure the automatic recovery for any iteration of any worker and with any of the arbitrary",
    "start": "781680",
    "end": "790019"
  },
  {
    "text": "rank um so that's actually an end-to-end perspective for the thought tolerance based on the realistic",
    "start": "790019",
    "end": "797100"
  },
  {
    "text": "um so um to be more detailed we defined this as a as a as a general spmd control plan",
    "start": "797100",
    "end": "804540"
  },
  {
    "text": "because it works for all the MPI related finer green controlled",
    "start": "804540",
    "end": "810120"
  },
  {
    "text": "um this system so we call it the uh spmd it's a single program multiple data so",
    "start": "810120",
    "end": "815339"
  },
  {
    "text": "this can apply to this kind of system realistic as the infrastructure component can be easily adapted to this",
    "start": "815339",
    "end": "822060"
  },
  {
    "text": "kind of computation a based on rate so in this figure we show how it looks like in detail so basically a user have a",
    "start": "822060",
    "end": "828899"
  },
  {
    "text": "driver program and and the driver will launch the elastic agent in each of the part so what does the elastic agent does",
    "start": "828899",
    "end": "836040"
  },
  {
    "text": "it actually Rendezvous among all the agents negotiate and provide a stable",
    "start": "836040",
    "end": "841380"
  },
  {
    "text": "rank they can they can associate the rank of the worker with the persistent",
    "start": "841380",
    "end": "847019"
  },
  {
    "text": "volume that hooked or marked with the computation part",
    "start": "847019",
    "end": "852060"
  },
  {
    "text": "um so the agent another role is to manage large and manage the entire work cycle a life cycle of all the work",
    "start": "852060",
    "end": "858360"
  },
  {
    "text": "occurs it can be single it can be multiple and the worker can be even different languages for example in our",
    "start": "858360",
    "end": "864600"
  },
  {
    "text": "case the graph Computing worker is actually written in C plus plus so basically the elastic elastic agent is",
    "start": "864600",
    "end": "871139"
  },
  {
    "text": "covering the C plus part worker from the process level and the amount of elastic agent we see",
    "start": "871139",
    "end": "877680"
  },
  {
    "text": "another module called the Rendezvous registry so this is actually the real place where we keep the states we keep",
    "start": "877680",
    "end": "883199"
  },
  {
    "text": "the states of every agent for example the ranks of every worker and the mapping with the worker with the mapping",
    "start": "883199",
    "end": "889980"
  },
  {
    "text": "of the worker with the persistent volumes through the parts so here is the um like a little bit",
    "start": "889980",
    "end": "896820"
  },
  {
    "text": "detail about how the realistic implemented by the by using Ray",
    "start": "896820",
    "end": "902279"
  },
  {
    "text": "um we have some experiments again so this is also a ongoing work so it's not on a",
    "start": "902279",
    "end": "910320"
  },
  {
    "text": "super large scale of data but we do it in a and two data sets a smaller one and",
    "start": "910320",
    "end": "915600"
  },
  {
    "text": "the middle middle skill but still we can show some of the effectiveness so",
    "start": "915600",
    "end": "920760"
  },
  {
    "text": "basically we play this experiment in a small cluster which has the knife",
    "start": "920760",
    "end": "927300"
  },
  {
    "text": "physical machines and a kubri cluster we play with two data sets two algorithms",
    "start": "927300",
    "end": "933000"
  },
  {
    "text": "and also two trials so Twitter datasets will have 41 million nodes for the UK",
    "start": "933000",
    "end": "939000"
  },
  {
    "text": "Union data set which is larger we have a 133 million nodes we have a 5.4 billion",
    "start": "939000",
    "end": "945720"
  },
  {
    "text": "agents so two algorithms we have a playlist in this experiment is paid Rank",
    "start": "945720",
    "end": "950940"
  },
  {
    "text": "and the kinetic component and we do two sets of experiments the first is the",
    "start": "950940",
    "end": "956820"
  },
  {
    "text": "pmap plus the DRM version so we use the pure we use the pmam to store the graph",
    "start": "956820",
    "end": "962880"
  },
  {
    "text": "the checkpoints the messages all the intermediate intermediate States and for the dram only we only use the dram to",
    "start": "962880",
    "end": "969839"
  },
  {
    "text": "store the graph to store the the graph the checkpoints also messages so um so first I would like to show the",
    "start": "969839",
    "end": "978300"
  },
  {
    "text": "um the the the the pmm offloading right so uh we see two sets of uh figures on",
    "start": "978300",
    "end": "985199"
  },
  {
    "text": "the left side is the uh runtime and on the right side is the total uh dram",
    "start": "985199",
    "end": "991500"
  },
  {
    "text": "memory footprint so what do we do here we we um scale the number of parts for",
    "start": "991500",
    "end": "997019"
  },
  {
    "text": "the same problem same graph we scale the different number of parts so um that's",
    "start": "997019",
    "end": "1002720"
  },
  {
    "text": "first the focus on the uh the runtime so we can see as we scale the scale up the",
    "start": "1002720",
    "end": "1008899"
  },
  {
    "text": "number pause actually we got some linear speed up of the runtime",
    "start": "1008899",
    "end": "1014959"
  },
  {
    "text": "and also at the same time it will compare the blue bar with the orange bar so the orange bar is the dram only",
    "start": "1014959",
    "end": "1021259"
  },
  {
    "text": "version and the blue bar is the Pima and plus the dram version we can see there are some of the degradation the",
    "start": "1021259",
    "end": "1027980"
  },
  {
    "text": "degradation from the data seems like a 10 or 20 less than that but it's almost",
    "start": "1027980",
    "end": "1033260"
  },
  {
    "text": "a comparable when you use the uh the pmap because uh pmem it has a um because",
    "start": "1033260",
    "end": "1042140"
  },
  {
    "text": "the the reader red pattern is a hybrid so we keep reading keep writing in a kind of random way so that's why using p",
    "start": "1042140",
    "end": "1049040"
  },
  {
    "text": "Ram we got a performance degradation and a 10 to 20 is a purely acceptable and",
    "start": "1049040",
    "end": "1054200"
  },
  {
    "text": "comparable on the right side figure we can see is the the total memory footprint that in",
    "start": "1054200",
    "end": "1060919"
  },
  {
    "text": "memory and obviously we can see using the the dram plus the pmem the blue bar",
    "start": "1060919",
    "end": "1067760"
  },
  {
    "text": "drops to like one third of the orange of the orange bar which means",
    "start": "1067760",
    "end": "1073100"
  },
  {
    "text": "um the peak dram usage drops to a great extent to one cert and this is also both",
    "start": "1073100",
    "end": "1079940"
  },
  {
    "text": "of this this observation actually true for both the small data set and the",
    "start": "1079940",
    "end": "1085580"
  },
  {
    "text": "middle size data set of the UK unit so that's for the dram offloading",
    "start": "1085580",
    "end": "1092539"
  },
  {
    "text": "um and another set of experiment is interesting as well so we try to show how we use this method to save the",
    "start": "1092539",
    "end": "1099860"
  },
  {
    "text": "resource and also the thought tolerance time so um we we lowered the number of",
    "start": "1099860",
    "end": "1106160"
  },
  {
    "text": "we will lower the number of machines and the memory consumption by using this approach so from this figure we can see",
    "start": "1106160",
    "end": "1112600"
  },
  {
    "text": "use the p-man plus dram version we can show the minimum number of parts that",
    "start": "1112600",
    "end": "1119179"
  },
  {
    "text": "can hold the graph for the for the for the Twitter one we can see we can drop",
    "start": "1119179",
    "end": "1124340"
  },
  {
    "text": "the Pod usage from three to one for holding the Twitter data",
    "start": "1124340",
    "end": "1129980"
  },
  {
    "text": "um and and finish the Computing job for the UK Union we actually can reduce the",
    "start": "1129980",
    "end": "1136100"
  },
  {
    "text": "total pod usage from six to two so all job to a one third",
    "start": "1136100",
    "end": "1142400"
  },
  {
    "text": "so this from a different perspective means that um given the fixed size of the Computing",
    "start": "1142400",
    "end": "1150260"
  },
  {
    "text": "resources uh given the uh given the fixed number of parts we can fit the",
    "start": "1150260",
    "end": "1156320"
  },
  {
    "text": "bigger models actually for for the problem-sized perspective",
    "start": "1156320",
    "end": "1161720"
  },
  {
    "text": "and another interesting experiment on observation is that we try to show",
    "start": "1161720",
    "end": "1168740"
  },
  {
    "text": "how much overhead we ran into when we have a fault tolerant recover so",
    "start": "1168740",
    "end": "1174919"
  },
  {
    "text": "basically from the observation when there's no failure we run the Twitter and the page rank on the eight Port",
    "start": "1174919",
    "end": "1182960"
  },
  {
    "text": "experimental settings so when there's no failure the Computing job can finish in",
    "start": "1182960",
    "end": "1189559"
  },
  {
    "text": "about 600 seconds however when we inject something to make",
    "start": "1189559",
    "end": "1194600"
  },
  {
    "text": "it fail at some point and get it recovered so the overall time including",
    "start": "1194600",
    "end": "1200539"
  },
  {
    "text": "the recovery time will will be like 6 660 seconds which introduces about the",
    "start": "1200539",
    "end": "1207919"
  },
  {
    "text": "uh 70 60 to 70 seconds which is like a 10 overhead for recovering so this is a",
    "start": "1207919",
    "end": "1214900"
  },
  {
    "text": "also accept acceptable because if without such a recovery mechanism you",
    "start": "1214900",
    "end": "1221360"
  },
  {
    "text": "would have to rerun the whole thing so you will have another five or six hundred to start from scratch so from",
    "start": "1221360",
    "end": "1229039"
  },
  {
    "text": "this perspective we believe this is really helpful for computing a super",
    "start": "1229039",
    "end": "1234260"
  },
  {
    "text": "large compute jobs um yeah so um",
    "start": "1234260",
    "end": "1240140"
  },
  {
    "text": "here is a summary of how the uh Huawei design and use the bed Gap so basically",
    "start": "1240140",
    "end": "1247280"
  },
  {
    "text": "we aim to use this bed Gap to process really large real world applications",
    "start": "1247280",
    "end": "1252820"
  },
  {
    "text": "with a gigantic number of edges and nodes 100 trillion level at a cheaper",
    "start": "1252820",
    "end": "1258980"
  },
  {
    "text": "cost resources use as as much as little Resource as possible we'll still get no",
    "start": "1258980",
    "end": "1265160"
  },
  {
    "text": "unnecessary recomputes as possible so the beta Gap actually features several",
    "start": "1265160",
    "end": "1270799"
  },
  {
    "text": "important features which actually I put all this in the in the title so the first is the",
    "start": "1270799",
    "end": "1277220"
  },
  {
    "text": "serverless we make it the flexible in a cluster to make it really transparent to",
    "start": "1277220",
    "end": "1284480"
  },
  {
    "text": "the to the users and also it's resilient it provides end-to-end for tolerance and",
    "start": "1284480",
    "end": "1291020"
  },
  {
    "text": "by using this framework there's no need to rewrite the entire job you just need",
    "start": "1291020",
    "end": "1297440"
  },
  {
    "text": "to start from the latest the checkpoints for all the workers Years also it hires the hierarchical Precision storage so we",
    "start": "1297440",
    "end": "1305840"
  },
  {
    "text": "heavily Leverage The Art of core storage and we are also in the effort to build this hierarchical storage more uh more",
    "start": "1305840",
    "end": "1314659"
  },
  {
    "text": "automatically more smartly and lately and also I think this most",
    "start": "1314659",
    "end": "1319820"
  },
  {
    "text": "important for the for the resubmit which is the use case that we use the real",
    "start": "1319820",
    "end": "1325340"
  },
  {
    "text": "elastic plus the Kube array to build a general purpose for tolerant control",
    "start": "1325340",
    "end": "1330799"
  },
  {
    "text": "plan for spmd programs so that's not only for graph you can use it for big",
    "start": "1330799",
    "end": "1335960"
  },
  {
    "text": "data for for AI applications as long as it's satisfied the SNP Computing",
    "start": "1335960",
    "end": "1342799"
  },
  {
    "text": "computation computation patterns um yeah so I think that's uh for for for",
    "start": "1342799",
    "end": "1349059"
  },
  {
    "text": "our work that I want to share here at this moment um I would like to take any questions if",
    "start": "1349059",
    "end": "1354740"
  },
  {
    "text": "you have [Applause]",
    "start": "1354740",
    "end": "1363839"
  },
  {
    "text": "a very nice presentation thank you I was curious given the background of using",
    "start": "1364159",
    "end": "1369679"
  },
  {
    "text": "MPI for for message packs passing have you looked at using actors uh in lieu of",
    "start": "1369679",
    "end": "1375799"
  },
  {
    "text": "message passing or maybe I may have missed that part oh which one is what using reactors for the message yeah yeah",
    "start": "1375799",
    "end": "1382580"
  },
  {
    "text": "right it's a different way right using reactor is actually RPC transferring right but uh um and then for normally",
    "start": "1382580",
    "end": "1389659"
  },
  {
    "text": "for graph Computing the MPI also has a very wide adoption for HPC jobs right",
    "start": "1389659",
    "end": "1395960"
  },
  {
    "text": "so yeah",
    "start": "1395960",
    "end": "1399340"
  },
  {
    "text": "hey uh so uh are you planning to open sources or like make it available to the",
    "start": "1403280",
    "end": "1408740"
  },
  {
    "text": "public which part we're actually really elastic and also equivalent copyright is is already open source so we start with",
    "start": "1408740",
    "end": "1415340"
  },
  {
    "text": "real Community to build a corporate from uh by dance ever as well we have another talk uh single 330 also this room",
    "start": "1415340",
    "end": "1422900"
  },
  {
    "text": "talking about the the copyright uh I think with IBM people together yeah I",
    "start": "1422900",
    "end": "1428419"
  },
  {
    "text": "was wondering more about the graph processing framework because you're promising that you'll support 100 trillion nodes so that's something like",
    "start": "1428419",
    "end": "1436820"
  },
  {
    "text": "I would be wow that yeah that's literally in edges sorry we we hope to yeah but that actually",
    "start": "1436820",
    "end": "1443600"
  },
  {
    "text": "um we also have some uh to be uh things wanna you know have a complication",
    "start": "1443600",
    "end": "1449360"
  },
  {
    "text": "between the you know open source and also application to be so I think I'm",
    "start": "1449360",
    "end": "1454460"
  },
  {
    "text": "not the right person to at this moment but not something like that but we would like to but it needs some time and this",
    "start": "1454460",
    "end": "1461720"
  },
  {
    "text": "is still ongoing effort yeah okay and uh have you compared this with uh spark and",
    "start": "1461720",
    "end": "1467480"
  },
  {
    "text": "graphics uh not yet we mostly compare that with our in-house existing solution which is",
    "start": "1467480",
    "end": "1475400"
  },
  {
    "text": "a plateau so we didn't compare that with the spark that you mentioned okay yeah okay this will be very interesting to",
    "start": "1475400",
    "end": "1482600"
  },
  {
    "text": "compare as well but I guess again this is an ongoing effort I think it's subject to a lot of optimization as well",
    "start": "1482600",
    "end": "1488900"
  },
  {
    "text": "so after we apply a bunch of optimization I think it would be great to compare with the spark with other",
    "start": "1488900",
    "end": "1495919"
  },
  {
    "text": "um appear Frameworks yeah okay okay thank you sure",
    "start": "1495919",
    "end": "1501640"
  },
  {
    "text": "hi um two questions so could you reiterate the importance of rank and",
    "start": "1501980",
    "end": "1507740"
  },
  {
    "text": "also is Ray elastic using some consensus algorithm to resolve the ranks across",
    "start": "1507740",
    "end": "1513559"
  },
  {
    "text": "agents that's a great question so um because the graph is super large we need",
    "start": "1513559",
    "end": "1519080"
  },
  {
    "text": "to partition that right so each workers cover a individual subsection of the graph",
    "start": "1519080",
    "end": "1524840"
  },
  {
    "text": "when we load the data a large amount of data into the persistent volume you don't want to reload it again right",
    "start": "1524840",
    "end": "1531320"
  },
  {
    "text": "so that's why the run there where the rank is important when the worker match the rank the worker will fetch the data",
    "start": "1531320",
    "end": "1538400"
  },
  {
    "text": "directly to that Rank and get the part of the correct part of the data from the persistent volume when it fail I mean",
    "start": "1538400",
    "end": "1546380"
  },
  {
    "text": "the corporate will larger worker but the worker doesn't know where to find the correct the persistent volume and then",
    "start": "1546380",
    "end": "1553580"
  },
  {
    "text": "the agent will tell agents through the random rule will say that okay random K",
    "start": "1553580",
    "end": "1559039"
  },
  {
    "text": "field and the new worker I'm the Renegade so when I schedule that I schedule the Pod to the place that",
    "start": "1559039",
    "end": "1566779"
  },
  {
    "text": "hooked with the model is the purchase volume that is ranked k such that you can get the correct data",
    "start": "1566779",
    "end": "1574039"
  },
  {
    "text": "yeah if you scheduled to a different node which means you have to fetch the entire partition data to that new node",
    "start": "1574039",
    "end": "1580279"
  },
  {
    "text": "which is unacceptable because loading the data I didn't show the time for loading the graph actually it's very",
    "start": "1580279",
    "end": "1587000"
  },
  {
    "text": "large amount of time for loading the 600 mil a second is excluding the the",
    "start": "1587000",
    "end": "1593240"
  },
  {
    "text": "loading time for the graph that that does that answer your question for the rank",
    "start": "1593240",
    "end": "1599240"
  },
  {
    "text": "yeah but there is like some master agent that keeps track of the state or is it",
    "start": "1599240",
    "end": "1605179"
  },
  {
    "text": "like yes that's the Rendezvous the Rendezvous actually in the in the master in the driver um yeah so all the agents talk with the",
    "start": "1605179",
    "end": "1612140"
  },
  {
    "text": "driver so they they negotiate which is amazing who is the next yeah who I am",
    "start": "1612140",
    "end": "1620140"
  },
  {
    "text": "one of the concerns with rank based approaches is that the graph is dynamic right you",
    "start": "1626860",
    "end": "1633679"
  },
  {
    "text": "might end up with hot nodes you might end up with more nodes being added to a particular subgraph and so the question of repartitioning comes up and it seems",
    "start": "1633679",
    "end": "1640820"
  },
  {
    "text": "in this particular setup the cost of repartitioning is going to be very high how do you think about that and how do",
    "start": "1640820",
    "end": "1648320"
  },
  {
    "text": "you think about things like hot nodes and other issues that can occur when you make a fixed static distribution of sub",
    "start": "1648320",
    "end": "1654559"
  },
  {
    "text": "graphs across the different nodes oh yeah that's a great question so in",
    "start": "1654559",
    "end": "1659720"
  },
  {
    "text": "any cases real partition will incur a lot of uh overhead that's that's for sure so even",
    "start": "1659720",
    "end": "1665720"
  },
  {
    "text": "in this case in other cases as well so we also thought about how to do their resharding to do the like uh",
    "start": "1665720",
    "end": "1672700"
  },
  {
    "text": "scale agnostic framework that we can you know for",
    "start": "1672700",
    "end": "1678320"
  },
  {
    "text": "example Knight partitions we do it in a 10 partition right so we thought about that way for example by leveraging the",
    "start": "1678320",
    "end": "1685900"
  },
  {
    "text": "consistent hashing and in the prefetching way things like that but",
    "start": "1685900",
    "end": "1692000"
  },
  {
    "text": "that's actually not in this road map at this moment yeah we thought about that",
    "start": "1692000",
    "end": "1698960"
  },
  {
    "text": "I'm here with you um that's a hard problem though",
    "start": "1698960",
    "end": "1704440"
  },
  {
    "text": "so maybe again on the partitioning I mean does your graph fall apart naturally into partitions or is there",
    "start": "1707059",
    "end": "1712700"
  },
  {
    "text": "let's say this overlap problem I mean graph partitioning of course is NP hard problem and do you think about",
    "start": "1712700",
    "end": "1717799"
  },
  {
    "text": "strategies like not doing a strict partitioning but maybe keeping Parts across several partitions yeah so that",
    "start": "1717799",
    "end": "1724220"
  },
  {
    "text": "you basically have a shadow of your petition on other nodes to avoid let's say the the problems of strict",
    "start": "1724220",
    "end": "1730400"
  },
  {
    "text": "partitioning and maybe another question with regards to that as we can see the the runtime behavior of the algorithms",
    "start": "1730400",
    "end": "1737299"
  },
  {
    "text": "run on the graph um let's say optimizing the partitioning",
    "start": "1737299",
    "end": "1742400"
  },
  {
    "text": "scheme to the application or to the algorithm applied um and let's say when to do a",
    "start": "1742400",
    "end": "1748580"
  },
  {
    "text": "repetitioning and let's say when to keep it do you implement strategies like that or maybe learn even what would be the",
    "start": "1748580",
    "end": "1754880"
  },
  {
    "text": "the optimal partition scheme for a graph of that size yeah that's a hard question actually",
    "start": "1754880",
    "end": "1762799"
  },
  {
    "text": "um again we want to do the scale but the scale in graph can be a really hard problem because you need to reach",
    "start": "1762799",
    "end": "1768679"
  },
  {
    "text": "restarting shifting part of the data there could be some smart way Optimizer to you know planning the shift you know",
    "start": "1768679",
    "end": "1776240"
  },
  {
    "text": "minimize the shifting of data as much as possible right so that's one of the direction and the earlier question you",
    "start": "1776240",
    "end": "1782419"
  },
  {
    "text": "mentioned is how to partition the data with some of the hot hot nodes right we",
    "start": "1782419",
    "end": "1787580"
  },
  {
    "text": "actually that's a good question actually um we had some investigation by a graph",
    "start": "1787580",
    "end": "1793039"
  },
  {
    "text": "partition algorithms we use some of them I think [Music] by from by observing some of this hot",
    "start": "1793039",
    "end": "1802279"
  },
  {
    "text": "part of the sub graph we're saying we can further increase the efficiency",
    "start": "1802279",
    "end": "1808120"
  },
  {
    "text": "especially when we do the partitioning but yeah that's definitely",
    "start": "1808120",
    "end": "1814100"
  },
  {
    "text": "part with overlapping structure so that we don't use Quick partitioning what you keep let's say certain parts that you",
    "start": "1814100",
    "end": "1820159"
  },
  {
    "text": "visit right on both sides",
    "start": "1820159",
    "end": "1825278"
  },
  {
    "text": "right and also that's really helpful for reducing the message passing because if",
    "start": "1827360",
    "end": "1833299"
  },
  {
    "text": "we partition in a really efficient way you can greatly reduce the message",
    "start": "1833299",
    "end": "1838340"
  },
  {
    "text": "passing between each of the nodes because by vertex Centric actually every node needs to send a message uh actually",
    "start": "1838340",
    "end": "1844760"
  },
  {
    "text": "fetch the message from all the neighbors that update every node so a lot of message passing among the individual",
    "start": "1844760",
    "end": "1851480"
  },
  {
    "text": "nodes so a great partition will reduce reduce that upsell yeah",
    "start": "1851480",
    "end": "1856940"
  },
  {
    "text": "this video so we're just going to take one more question",
    "start": "1856940",
    "end": "1861700"
  },
  {
    "text": "hello sure just a follow-up question to the spark",
    "start": "1866120",
    "end": "1872000"
  },
  {
    "text": "Graphics question is there a particular reason why you chose Rey versus testing",
    "start": "1872000",
    "end": "1877100"
  },
  {
    "text": "uh using Graphics by default I mean that's like a very standard uh yeah",
    "start": "1877100",
    "end": "1882860"
  },
  {
    "text": "distributed computing way of doing it and you talked about uh what's the",
    "start": "1882860",
    "end": "1888320"
  },
  {
    "text": "largest graph that you have tried and have you seen with Ray the convergence",
    "start": "1888320",
    "end": "1894559"
  },
  {
    "text": "time to be much smaller for some of these uh Algos the point point",
    "start": "1894559",
    "end": "1899899"
  },
  {
    "text": "convergence Algos that you talked about uh yeah can you talk a little bit about that yeah yeah so the the data size that",
    "start": "1899899",
    "end": "1907039"
  },
  {
    "text": "we play with uh showing here is uh in a small middle side but in the real production we have super large scale",
    "start": "1907039",
    "end": "1913039"
  },
  {
    "text": "data set so that's the second question so for the first question why we usually because um is um we have a first in the cloud",
    "start": "1913039",
    "end": "1921200"
  },
  {
    "text": "environment we adopt the kubrey which can provide a service management of all",
    "start": "1921200",
    "end": "1927260"
  },
  {
    "text": "the real workload right another thing is that Ray has a very powerful states and also the programming model",
    "start": "1927260",
    "end": "1934220"
  },
  {
    "text": "such that we can play with it and compose any logic that we want for",
    "start": "1934220",
    "end": "1939799"
  },
  {
    "text": "example the law the rank based logic is easy to to represent using the ray apis",
    "start": "1939799",
    "end": "1946279"
  },
  {
    "text": "using array of patterns actually to come up with this rank based array elastic",
    "start": "1946279",
    "end": "1953380"
  },
  {
    "text": "components that's only for fault tolerance aspect right like if some of",
    "start": "1953380",
    "end": "1958520"
  },
  {
    "text": "the workers or some nodes go down let's assume for a second that you don't have the a problem do you still see a any",
    "start": "1958520",
    "end": "1965539"
  },
  {
    "text": "advantage over other distributed processing Frameworks with Ray",
    "start": "1965539",
    "end": "1971840"
  },
  {
    "text": "what's the question second please no I'm saying so the the state and let's assume the",
    "start": "1971840",
    "end": "1979460"
  },
  {
    "text": "fault tolerance aspect is taken care of for a second do you see any other Advantage compared to other distributed processing",
    "start": "1979460",
    "end": "1985640"
  },
  {
    "text": "framework in terms of really for example uh the shared memory I can access some a",
    "start": "1985640",
    "end": "1991220"
  },
  {
    "text": "state of another node in a graph much more efficiently is that an advantage that you see",
    "start": "1991220",
    "end": "1997059"
  },
  {
    "text": "versus uh other things maybe that that might speed up some of the Algos that",
    "start": "1997059",
    "end": "2003399"
  },
  {
    "text": "you're writing yeah I think um the adoption why would adopt a ray and I",
    "start": "2003399",
    "end": "2011019"
  },
  {
    "text": "think one of the reasons as I mentioned uh we use copyright for the serverless we have real platform and the workload",
    "start": "2011019",
    "end": "2017740"
  },
  {
    "text": "can be easily migrated adapted to to this part as well um and uh",
    "start": "2017740",
    "end": "2025320"
  },
  {
    "text": "yeah so uh did I ask our questions happen we can talk about more about that later",
    "start": "2026740",
    "end": "2034799"
  }
]
[
  {
    "text": "good afternoon folks myself on Indo from Lyft and my",
    "start": "3560",
    "end": "9059"
  },
  {
    "text": "colleague hanwa he is also a lift software engineer a senior staff engineer so we'll be talking about Ray",
    "start": "9059",
    "end": "16080"
  },
  {
    "text": "on kubernetes today especially Ray is a new framework and Lyft is a kubernetes",
    "start": "16080",
    "end": "22380"
  },
  {
    "text": "house so we try to merge both of these Technologies and how we work on it so",
    "start": "22380",
    "end": "27420"
  },
  {
    "text": "Han will take talk about the first half and then I will take about take care about the demo sessions",
    "start": "27420",
    "end": "33899"
  },
  {
    "text": "uh hun",
    "start": "33899",
    "end": "36679"
  },
  {
    "text": "hello everyone welcome today onindo and I will talk about the",
    "start": "41520",
    "end": "47820"
  },
  {
    "text": "distributed machine learning with Ray and kubernetes inside lift both of us work in the machine learning",
    "start": "47820",
    "end": "55199"
  },
  {
    "text": "platform team of Lyft our focus is on the large-scale distributed systems for",
    "start": "55199",
    "end": "61379"
  },
  {
    "text": "machine learning here is today's agenda I will talk about",
    "start": "61379",
    "end": "66600"
  },
  {
    "text": "the pain points and the design principles of the machine learning platform of Lyft",
    "start": "66600",
    "end": "73080"
  },
  {
    "text": "and then aningdo is going to dive deep into the ray integration",
    "start": "73080",
    "end": "79100"
  },
  {
    "text": "so inside lift most of our business decisions",
    "start": "80520",
    "end": "86759"
  },
  {
    "text": "are empowered by Machine learning models as the machine learning platform team we",
    "start": "86759",
    "end": "93420"
  },
  {
    "text": "work with all the practitioners inside the company",
    "start": "93420",
    "end": "98520"
  },
  {
    "text": "and here are the things common things that we learned from the practitioners",
    "start": "98520",
    "end": "104939"
  },
  {
    "text": "first of all we notice we have very good engineers and",
    "start": "104939",
    "end": "110040"
  },
  {
    "text": "scientists they write nice code but most of the code is just to run locally",
    "start": "110040",
    "end": "117600"
  },
  {
    "text": "they don't know how to scale out we see another group of people who has",
    "start": "117600",
    "end": "123720"
  },
  {
    "text": "some knowledge of a certain distributed framework and then they try to scale out",
    "start": "123720",
    "end": "130259"
  },
  {
    "text": "but it's not very successful their code becomes convoluted and unmanageable very quickly and the",
    "start": "130259",
    "end": "137760"
  },
  {
    "text": "scalability is not really very good and another problem is single vendor",
    "start": "137760",
    "end": "144599"
  },
  {
    "text": "locking this is not only a technical problem but also a mindset problem think",
    "start": "144599",
    "end": "150060"
  },
  {
    "text": "about that we use spark widely inside the company so a lot of people their mindset is on",
    "start": "150060",
    "end": "157500"
  },
  {
    "text": "spark they try to build the end-to-end machine learning pipeline or on spark",
    "start": "157500",
    "end": "163200"
  },
  {
    "text": "fairly speaking spark is pretty good on most parts of a machine learning pipeline but",
    "start": "163200",
    "end": "169019"
  },
  {
    "text": "for example one thing cannot do very well that is the training step so the problem is",
    "start": "169019",
    "end": "176160"
  },
  {
    "text": "they have very scalable pre-processing post-processing but they don't know how to scale out their training process",
    "start": "176160",
    "end": "184519"
  },
  {
    "text": "and the cost of iteration is another big pain points so as the data size increase",
    "start": "185700",
    "end": "192360"
  },
  {
    "text": "as the model complexity increase the time and cost",
    "start": "192360",
    "end": "197580"
  },
  {
    "text": "will increase drastically how do they handle that how do they do multi-step iterations",
    "start": "197580",
    "end": "206099"
  },
  {
    "text": "the last but not the least we notice that following good practices sometimes",
    "start": "206099",
    "end": "211319"
  },
  {
    "text": "are penalized for example if I want to add unit test to the pipeline what if I want to do",
    "start": "211319",
    "end": "218700"
  },
  {
    "text": "hyper parameter tuning what if I want to do data validation",
    "start": "218700",
    "end": "224459"
  },
  {
    "text": "all of those good practices they will require huge amount of effort",
    "start": "224459",
    "end": "229860"
  },
  {
    "text": "and by doing so sometimes it's very hard to justify from the business perspective so practically speaking we notice people",
    "start": "229860",
    "end": "237299"
  },
  {
    "text": "tend to skip those steps and to ship models directly which is obviously very risky",
    "start": "237299",
    "end": "244319"
  },
  {
    "text": "So based on these pain points here are our design principles for our machine learning platform",
    "start": "244319",
    "end": "252120"
  },
  {
    "text": "first of all it must be very easy to use and it must be very seamless to use no",
    "start": "252120",
    "end": "259500"
  },
  {
    "text": "matter which kind of solution you are using we take the layered cake approach",
    "start": "259500",
    "end": "265620"
  },
  {
    "text": "so instead of one layer of abstraction we have multiple layers of abstractions",
    "start": "265620",
    "end": "272400"
  },
  {
    "text": "so for common use cases and common users they always they commonly just need to access the",
    "start": "272400",
    "end": "280320"
  },
  {
    "text": "top level abstraction which is mostly one liner which you will see in our demo",
    "start": "280320",
    "end": "286440"
  },
  {
    "text": "in the later sections and for advanced use cases",
    "start": "286440",
    "end": "291840"
  },
  {
    "text": "they will be able to access the full feature of the Frameworks provide",
    "start": "291840",
    "end": "299300"
  },
  {
    "text": "the second thing we want to abstract away the concern of scale and vendor",
    "start": "299340",
    "end": "305220"
  },
  {
    "text": "locking we want users to focus on their Core Business logic and Computing logic",
    "start": "305220",
    "end": "311699"
  },
  {
    "text": "without too much concern about scalability and how to adapt to a",
    "start": "311699",
    "end": "318120"
  },
  {
    "text": "certain Computing framework we will handle that through our abstraction layers",
    "start": "318120",
    "end": "324860"
  },
  {
    "text": "enabling faster iteration I think this is very important because enabling faster iteration it will save a lot of",
    "start": "326100",
    "end": "333060"
  },
  {
    "text": "time and also it will save huge amount of cost for the company",
    "start": "333060",
    "end": "339000"
  },
  {
    "text": "so in order to do that we must provide a collection of utility functions that is",
    "start": "339000",
    "end": "344880"
  },
  {
    "text": "very easy to use but under the hood it will fully utilize the distributed system that we have",
    "start": "344880",
    "end": "351600"
  },
  {
    "text": "so actually increasing the utilization of the whole cluster",
    "start": "351600",
    "end": "356940"
  },
  {
    "text": "is a very effective way to accelerate the iterations",
    "start": "356940",
    "end": "362660"
  },
  {
    "text": "and the last but not least we want make following good practices to be rewarding",
    "start": "363120",
    "end": "370919"
  },
  {
    "text": "right so what do we do is we try to again we try to provide the most",
    "start": "370919",
    "end": "376919"
  },
  {
    "text": "reasonable interfaces and components that people can use directly to do their",
    "start": "376919",
    "end": "382620"
  },
  {
    "text": "job for example for hyper parameter tuning we have very simple interfaces",
    "start": "382620",
    "end": "387960"
  },
  {
    "text": "for them to interact with any type of distributed systems for data validation we have the um the well-defined",
    "start": "387960",
    "end": "396360"
  },
  {
    "text": "interface for them to directly um invoke the validation steps",
    "start": "396360",
    "end": "403160"
  },
  {
    "text": "so here is an overview of the lifter distributed environment the ecosystem as",
    "start": "403919",
    "end": "408960"
  },
  {
    "text": "you can see in each stack there are competing Solutions",
    "start": "408960",
    "end": "414060"
  },
  {
    "text": "right but for us we don't see them to compete with each other instead we think",
    "start": "414060",
    "end": "419819"
  },
  {
    "text": "they are complementary to each other the key is that the abstraction must be",
    "start": "419819",
    "end": "425699"
  },
  {
    "text": "right we must Define the most reasonable abstraction so that people can use them",
    "start": "425699",
    "end": "432300"
  },
  {
    "text": "freely people can switch between them freely so in that way",
    "start": "432300",
    "end": "438000"
  },
  {
    "text": "people can have more options without a lot of frictions",
    "start": "438000",
    "end": "444080"
  },
  {
    "text": "so now I will hand it off to anindo to dive deep into the ray integration thank",
    "start": "445500",
    "end": "450599"
  },
  {
    "text": "you",
    "start": "450599",
    "end": "452780"
  },
  {
    "text": "thank you hon so to start with uh lift is uh relief",
    "start": "455880",
    "end": "463139"
  },
  {
    "text": "runs on AWS and we do not use ec2 directly we use all Kate's instances on",
    "start": "463139",
    "end": "469319"
  },
  {
    "text": "top of ec2 so lifts is a AWS on EC Kate's house so how does it work so let's it's a",
    "start": "469319",
    "end": "476099"
  },
  {
    "text": "schematic diagram due to the brevity of time I will keep it short we I I can take questions later after this talk so",
    "start": "476099",
    "end": "483900"
  },
  {
    "text": "how does it work so we have uh we we have a function called with case Ray",
    "start": "483900",
    "end": "489960"
  },
  {
    "text": "we use that function and I will demo it in a bit so we submit a ray clustered",
    "start": "489960",
    "end": "495060"
  },
  {
    "text": "job to the kubernetes API using the ray cluster operators and we also have the",
    "start": "495060",
    "end": "502139"
  },
  {
    "text": "EFS mounted on each of the operators so that we can have a shared volumes shared",
    "start": "502139",
    "end": "507960"
  },
  {
    "text": "across all the workers or reactor nodes ah this is the same principle you follow",
    "start": "507960",
    "end": "513180"
  },
  {
    "text": "its spark we just extended spark on kubernetes to Ray on kubernetes and we have the",
    "start": "513180",
    "end": "519300"
  },
  {
    "text": "same infrastructure API for spark as well I will show you in a bit so how does a scientist create array",
    "start": "519300",
    "end": "527700"
  },
  {
    "text": "cluster is just this one line of code with K8 that's it and then you uh the he they have to",
    "start": "527700",
    "end": "535320"
  },
  {
    "text": "mention two parameters the configuration instances and whether I want the dashboard or not",
    "start": "535320",
    "end": "541740"
  },
  {
    "text": "so what does this number four eight one eight G stand for 4 means I want four notes eight means I",
    "start": "541740",
    "end": "549180"
  },
  {
    "text": "want eight CPUs per node and one means I want one GPU per node and 8G means I",
    "start": "549180",
    "end": "556920"
  },
  {
    "text": "want 8 GB of RAM per CPU in a node",
    "start": "556920",
    "end": "562800"
  },
  {
    "text": "so four letters and one cluster and inside that you do the entire",
    "start": "562800",
    "end": "569880"
  },
  {
    "text": "processing some method dot remote that's it done so how can I monitor we have a ray",
    "start": "569880",
    "end": "577080"
  },
  {
    "text": "dashboard we also create a dashboard on the Fly we create the Ingress the dashboard is already created we create",
    "start": "577080",
    "end": "583560"
  },
  {
    "text": "the Ingress to that service and expose it how did he come to this idea so in our",
    "start": "583560",
    "end": "591000"
  },
  {
    "text": "last data break stock we had a talk in database also so for any machine learning workflow they are primarily",
    "start": "591000",
    "end": "597360"
  },
  {
    "text": "four steps pre-processing training saving the model and then post",
    "start": "597360",
    "end": "603060"
  },
  {
    "text": "processing which is most likely inference so how we do that in lift as Han was",
    "start": "603060",
    "end": "610620"
  },
  {
    "text": "mentioning that here we are not competing against each other Ray is powerful from for something",
    "start": "610620",
    "end": "616080"
  },
  {
    "text": "spark is powerful for something we want to take the advantage of both of them",
    "start": "616080",
    "end": "621240"
  },
  {
    "text": "so the abstraction is from lift distributed so in the first cell you can",
    "start": "621240",
    "end": "626580"
  },
  {
    "text": "see pre-processing we are using a spark cluster we want a 16 nodes 16 CPU",
    "start": "626580",
    "end": "632220"
  },
  {
    "text": "machines with 4GB Rams for each executor we read from a certain data set and",
    "start": "632220",
    "end": "637740"
  },
  {
    "text": "apply a transform function once the pre-processing is done what's next we want training so spark doesn't",
    "start": "637740",
    "end": "644940"
  },
  {
    "text": "support light GBM distributed training that well so Ray has a good support for that so we introduce Ray here on the",
    "start": "644940",
    "end": "652680"
  },
  {
    "text": "Second Step do the training on Ray Once the preprocessing is done do the training on Ray",
    "start": "652680",
    "end": "658560"
  },
  {
    "text": "so we call the light GBM remote method on the S3 data set and call the live GBM",
    "start": "658560",
    "end": "664140"
  },
  {
    "text": "training third step pretty simple and straightforward save the model once you save it what do you do we do",
    "start": "664140",
    "end": "671040"
  },
  {
    "text": "post processing do you want to scale up the post processing if yes you spark again so load the model from that",
    "start": "671040",
    "end": "679040"
  },
  {
    "text": "shift path load your test data and do again a transform the third line",
    "start": "679040",
    "end": "684180"
  },
  {
    "text": "transform test data and run the predict method on top of it so there are many more technical details we do not have",
    "start": "684180",
    "end": "690360"
  },
  {
    "text": "time to go into too much of it but this is a gist and synopsis that four steps",
    "start": "690360",
    "end": "696899"
  },
  {
    "text": "in the entire machine learning workflow being abstracted with kids functions and",
    "start": "696899",
    "end": "703620"
  },
  {
    "text": "everything is running on kubernetes and this leap distributed is our own",
    "start": "703620",
    "end": "708800"
  },
  {
    "text": "framework that we have built in-house and it comes from a few figures open",
    "start": "708800",
    "end": "714839"
  },
  {
    "text": "source framework Han is the creator of that framework and live distributes is heavily inspired by if you can use this",
    "start": "714839",
    "end": "723000"
  },
  {
    "text": "Fugue directly and we have some more extra wrappers specifically for Lyft but the main driving engine in is the fugue",
    "start": "723000",
    "end": "731760"
  },
  {
    "text": "okay so we talked a lot talked about Theory top showed some codes nice",
    "start": "731760",
    "end": "738420"
  },
  {
    "text": "looking great blue color green green slides does it really work so let's have a look at the demo and how we do it",
    "start": "738420",
    "end": "747019"
  },
  {
    "text": "so this is a demo of the first example I want to talk of a pytorch lightning job",
    "start": "747180",
    "end": "753779"
  },
  {
    "text": "that we want to use Ray to distribute it and I will show another notebook later",
    "start": "753779",
    "end": "759959"
  },
  {
    "text": "after this demo so let's focus on this pytorch lightning Demo First and see how",
    "start": "759959",
    "end": "765779"
  },
  {
    "text": "it works",
    "start": "765779",
    "end": "768260"
  },
  {
    "text": "is an inference example this is a typical piece of code",
    "start": "771600",
    "end": "777720"
  },
  {
    "text": "to make an inference of a local data frame the question is how can we scale",
    "start": "777720",
    "end": "783779"
  },
  {
    "text": "out this inference logic inside the left machine learning practitioners often use the field",
    "start": "783779",
    "end": "791279"
  },
  {
    "text": "transform to do this type of job the transform function can taking a path",
    "start": "791279",
    "end": "797160"
  },
  {
    "text": "or data frame as the input and then we can specify the Computing",
    "start": "797160",
    "end": "802560"
  },
  {
    "text": "logic info infer and optionally we can specify the same path",
    "start": "802560",
    "end": "808740"
  },
  {
    "text": "if this is specified the output will be directly written into this file location",
    "start": "808740",
    "end": "814800"
  },
  {
    "text": "the interesting part is engine and engine curve This is highly customized inside lifter",
    "start": "814800",
    "end": "823019"
  },
  {
    "text": "machine learning platform if you specify this to be Ray that will respond an ephemeral Ray cluster on top",
    "start": "823019",
    "end": "831120"
  },
  {
    "text": "of kubernetes just for this transformation before or after this transform that cluster does not exist",
    "start": "831120",
    "end": "838860"
  },
  {
    "text": "and the size is specified by the simplified expression we want 16",
    "start": "838860",
    "end": "844279"
  },
  {
    "text": "instances eight CPUs for each instance and the 4 Gig for each CPU so that is 32",
    "start": "844279",
    "end": "852180"
  },
  {
    "text": "gig of memory for each instance this design totally separates the",
    "start": "852180",
    "end": "858839"
  },
  {
    "text": "concern of the distributed system and the co-competing logic we want users",
    "start": "858839",
    "end": "865320"
  },
  {
    "text": "Computing logic to be framework agnostic and scale agnostic",
    "start": "865320",
    "end": "872459"
  },
  {
    "text": "so actually in this example if we want to change the Computing",
    "start": "872459",
    "end": "878279"
  },
  {
    "text": "backend from red to spark the only thing we need to change is this engine",
    "start": "878279",
    "end": "884240"
  },
  {
    "text": "parameter if we change this to spark and then the whole transformation logic will",
    "start": "884240",
    "end": "890100"
  },
  {
    "text": "happen on an ephemeral spark cluster",
    "start": "890100",
    "end": "894740"
  },
  {
    "text": "the second example I want to talk about is training so look at this piece of",
    "start": "895440",
    "end": "901139"
  },
  {
    "text": "code which is the standard way to train a pie Tosh lengthening model the",
    "start": "901139",
    "end": "907800"
  },
  {
    "text": "question is how can we scale out this training process",
    "start": "907800",
    "end": "912959"
  },
  {
    "text": "so Rey has made it very simple and inside the left we have made it even",
    "start": "912959",
    "end": "920519"
  },
  {
    "text": "simpler let's take a look take a look at the example so what do we need to do is just to use",
    "start": "920519",
    "end": "927060"
  },
  {
    "text": "this utility function to create an ephemeral Ray cluster",
    "start": "927060",
    "end": "933120"
  },
  {
    "text": "the expression is the same as before and within this context we're just",
    "start": "933120",
    "end": "939300"
  },
  {
    "text": "moving these two lines of code the only thing we add is this strategy",
    "start": "939300",
    "end": "945720"
  },
  {
    "text": "equal to ring this will tell the system that we will use raised by dodge lightening strategy and we will also",
    "start": "945720",
    "end": "953279"
  },
  {
    "text": "pick up the cluster information from the context so users don't have to manually",
    "start": "953279",
    "end": "961399"
  },
  {
    "text": "instantiate that rate strategy",
    "start": "961399",
    "end": "965720"
  },
  {
    "text": "so with this setting this training process can fully utilize",
    "start": "967199",
    "end": "972839"
  },
  {
    "text": "all the CPUs of the SAFE Federal rent cluster",
    "start": "972839",
    "end": "978360"
  },
  {
    "text": "now the question is what if we want to use gpus so actually the only thing we need to",
    "start": "978360",
    "end": "984899"
  },
  {
    "text": "change is from 8 to 8 and 1. that is to tell the system for each instance we",
    "start": "984899",
    "end": "992579"
  },
  {
    "text": "want eight CPUs and one GPU so with this setting this strategy will",
    "start": "992579",
    "end": "999420"
  },
  {
    "text": "be able to pick up the GPU information and to move the whole training onto the 16 gpus",
    "start": "999420",
    "end": "1007300"
  },
  {
    "text": "okay so this okay so this was a short demo like how",
    "start": "1012860",
    "end": "1018860"
  },
  {
    "text": "we integrate pythorch lightning with tray and that is also it's abstracted so",
    "start": "1018860",
    "end": "1024020"
  },
  {
    "text": "the integration is happening under the under the hood and also you can switch between spark and um spark and Ray just",
    "start": "1024020",
    "end": "1032660"
  },
  {
    "text": "with the configuration so we saw a video of the demo but we",
    "start": "1032660",
    "end": "1038959"
  },
  {
    "text": "actually want to get into the real meat how it works in kubernetes so how how do",
    "start": "1038959",
    "end": "1044058"
  },
  {
    "text": "you spawn up clusters so I have created a notebook here for",
    "start": "1044059",
    "end": "1051440"
  },
  {
    "text": "Ray Summit and I will try to attempt a more riskier",
    "start": "1051440",
    "end": "1057500"
  },
  {
    "text": "demo now it's alive oh it's it's alive",
    "start": "1057500",
    "end": "1063460"
  },
  {
    "text": "cluster creation demo let's see if the demo gods are with me ok so I have",
    "start": "1063740",
    "end": "1072100"
  },
  {
    "text": "I have my command cell up so I will start watching for the parts so what we",
    "start": "1072620",
    "end": "1078860"
  },
  {
    "text": "are trying to do as I mentioned uh it's a one line step for us to create",
    "start": "1078860",
    "end": "1084559"
  },
  {
    "text": "clusters this cluster is doing nothing just sleeping so I want to create a two",
    "start": "1084559",
    "end": "1090200"
  },
  {
    "text": "nodes two CPUs cluster can I do that so let's go back to the ray dashboard sorry",
    "start": "1090200",
    "end": "1096320"
  },
  {
    "text": "the kubernetes dashboard so there is only one part The Notebook which I'm running nothing is there",
    "start": "1096320",
    "end": "1103100"
  },
  {
    "text": "so I try to attempt to create a cluster so you can see as I",
    "start": "1103100",
    "end": "1110419"
  },
  {
    "text": "try to spinning a spin of a cluster so I saw you see that the ray head has come up",
    "start": "1110419",
    "end": "1117080"
  },
  {
    "text": "and I'm staying waiting for the work and as I speak the workers are also coming up so I asked for two two extra two",
    "start": "1117080",
    "end": "1123140"
  },
  {
    "text": "workers so I am getting two nodes and then also I'm I'm really actually",
    "start": "1123140",
    "end": "1129380"
  },
  {
    "text": "spawning up the cluster so I have watched it and I can see the state has transitioned so this cluster did nothing but just to",
    "start": "1129380",
    "end": "1137059"
  },
  {
    "text": "sleep so the whole point of showing this script was to show how easy for the",
    "start": "1137059",
    "end": "1144440"
  },
  {
    "text": "scientists and researchers to work with the cluster they just don't need to know anything underlying what's going on with",
    "start": "1144440",
    "end": "1152480"
  },
  {
    "text": "kubernetes and things like that we also have some other way of creating",
    "start": "1152480",
    "end": "1159140"
  },
  {
    "text": "the cluster where some some people are some Engineers want to mention it explicitly",
    "start": "1159140",
    "end": "1164900"
  },
  {
    "text": "we can do that does it work on real later",
    "start": "1164900",
    "end": "1170720"
  },
  {
    "text": "let's let's again try it live",
    "start": "1170720",
    "end": "1176780"
  },
  {
    "text": "so there was a computation in kaggle going on some months back so I'm not going into details of the competition",
    "start": "1176780",
    "end": "1182840"
  },
  {
    "text": "it's a regression problem and it has a bunch of numerical features and there is a target column to be predicted so",
    "start": "1182840",
    "end": "1189500"
  },
  {
    "text": "what's the goal of this presentation today what I want to",
    "start": "1189500",
    "end": "1194600"
  },
  {
    "text": "show is like in this ah in this demo I will be",
    "start": "1194600",
    "end": "1199700"
  },
  {
    "text": "showing that spark fugan Ray are working together as I mentioned in the one of the slides",
    "start": "1199700",
    "end": "1204860"
  },
  {
    "text": "that there are four steps so this notebook is a demo of that and then how we can train a distributed",
    "start": "1204860",
    "end": "1210980"
  },
  {
    "text": "light GBM using Ray on this data set and this data set was 18 GB so it is",
    "start": "1210980",
    "end": "1217460"
  },
  {
    "text": "a pretty large reasonably large enough to do some distributed training it's not too small",
    "start": "1217460",
    "end": "1223539"
  },
  {
    "text": "and I will show you how things work so let's look at the data set its uh",
    "start": "1223539",
    "end": "1230900"
  },
  {
    "text": "it's a kaggle data sets standard format training CSV is there and there is some sample summation",
    "start": "1230900",
    "end": "1237860"
  },
  {
    "text": "and so what we do is so this data set came",
    "start": "1237860",
    "end": "1242900"
  },
  {
    "text": "ah and then we loaded that data set and what I found is like when I read it when I'm doing the",
    "start": "1242900",
    "end": "1249799"
  },
  {
    "text": "preprocessing I'm using spark to read that data set and I find that most of the columns are string which is kind of",
    "start": "1249799",
    "end": "1255980"
  },
  {
    "text": "weird for a numerical challenge but when I actually see the data cities",
    "start": "1255980",
    "end": "1261980"
  },
  {
    "text": "numbers so what we can do we can pre-process so",
    "start": "1261980",
    "end": "1267980"
  },
  {
    "text": "there is no array here still so that's why I am not executing this cell this this talk is all about Ray so these are",
    "start": "1267980",
    "end": "1274520"
  },
  {
    "text": "these are all pre-executed ah so what we do is we just simple pre-processing ah",
    "start": "1274520",
    "end": "1280400"
  },
  {
    "text": "change all the features to float and drop some of the ID columns which",
    "start": "1280400",
    "end": "1285799"
  },
  {
    "text": "are redundant we again use spark to read the data set",
    "start": "1285799",
    "end": "1292460"
  },
  {
    "text": "and use the transform function and then pre-process and after that we persist it as a",
    "start": "1292460",
    "end": "1298880"
  },
  {
    "text": "parquet so as you can see that data set is already distributed why we do that because Ray works very well in a",
    "start": "1298880",
    "end": "1305360"
  },
  {
    "text": "distributed manner so you we need a distributed data set if I have only one",
    "start": "1305360",
    "end": "1310640"
  },
  {
    "text": "CV a CSV then it does not work well with it it it it gives you no benefit at all",
    "start": "1310640",
    "end": "1318559"
  },
  {
    "text": "so we have a part we we we pre-processed so now comes",
    "start": "1318559",
    "end": "1324679"
  },
  {
    "text": "the array part the light GBM part so in Ray what we need to do is we have",
    "start": "1324679",
    "end": "1330200"
  },
  {
    "text": "to create a function we have to create a remote function which will execute on remote machines",
    "start": "1330200",
    "end": "1335240"
  },
  {
    "text": "and how does that function look like so this function should look like this",
    "start": "1335240",
    "end": "1341120"
  },
  {
    "text": "it should we should be annotating with array remote and it's the training function which is taking the training",
    "start": "1341120",
    "end": "1346220"
  },
  {
    "text": "files as input and what does it do as I mentioned we read it from parquet file",
    "start": "1346220",
    "end": "1351860"
  },
  {
    "text": "shuffling splitting training and validations normal stuff and then we re-partition based on the number of",
    "start": "1351860",
    "end": "1358400"
  },
  {
    "text": "processes we want to spawn on Ray and I would like to mention contribution of Anthony from rating he helped us a",
    "start": "1358400",
    "end": "1366200"
  },
  {
    "text": "lot in giving this into shape so we repartition the data so we load it",
    "start": "1366200",
    "end": "1372799"
  },
  {
    "text": "from parquet they were 139 files but then we repartitioned into four actors or four processes",
    "start": "1372799",
    "end": "1377900"
  },
  {
    "text": "foreign we create ready Matrix because in order",
    "start": "1377900",
    "end": "1382940"
  },
  {
    "text": "to distribute we have to use a ratey matrix the rest of the part is like normal like",
    "start": "1382940",
    "end": "1388640"
  },
  {
    "text": "GBM we have a light GBM we have objective regression or MSE and any any other many more parameters but what is",
    "start": "1388640",
    "end": "1396260"
  },
  {
    "text": "different the difference is this this block this is the only difference so we have to use like GBM Ray dot train",
    "start": "1396260",
    "end": "1402740"
  },
  {
    "text": "not light gbm.train it takes the same things as inputs",
    "start": "1402740",
    "end": "1409460"
  },
  {
    "text": "parameters training set validation sets and names no difference the only difference is this",
    "start": "1409460",
    "end": "1416780"
  },
  {
    "text": "we have to pass an extra parameter a params and how many actors I want and",
    "start": "1416780",
    "end": "1422360"
  },
  {
    "text": "how many CPUs I want to give per actor or per process so actor is equal to a",
    "start": "1422360",
    "end": "1428419"
  },
  {
    "text": "process so let's um create this method",
    "start": "1428419",
    "end": "1434299"
  },
  {
    "text": "and then I will take I will try to run it live",
    "start": "1434299",
    "end": "1440840"
  },
  {
    "text": "so we have actually 139 files I ran it yesterday so today I'm spawning a four",
    "start": "1440840",
    "end": "1448159"
  },
  {
    "text": "node cluster with six CPUs and 4 GB RAM on each CPU and I also want to wait",
    "start": "1448159",
    "end": "1455600"
  },
  {
    "text": "on the cluster until it dies so that I do not come out of this cell last time I showed when I created the",
    "start": "1455600",
    "end": "1462380"
  },
  {
    "text": "cluster I just checked how it spawned a cluster and it came out but this time I won't want to do that",
    "start": "1462380",
    "end": "1469100"
  },
  {
    "text": "so I'm just trying to run it on the fly live and see the cluster is nothing is still there I",
    "start": "1469100",
    "end": "1477080"
  },
  {
    "text": "have only one Ray head node coming up but I ask for four",
    "start": "1477080",
    "end": "1483100"
  },
  {
    "text": "let's see I get yes I got it so I got four nodes on the Fly and they are",
    "start": "1483860",
    "end": "1488960"
  },
  {
    "text": "running and since I was fetching the data and then I was doing shuffling in",
    "start": "1488960",
    "end": "1495020"
  },
  {
    "text": "between so all those things are happening in place right now so it will be four partitions okay",
    "start": "1495020",
    "end": "1500840"
  },
  {
    "text": "but just looking at this console output is not very",
    "start": "1500840",
    "end": "1506419"
  },
  {
    "text": "informative so what we can do we can go to the red dashboard",
    "start": "1506419",
    "end": "1512299"
  },
  {
    "text": "and we can really see that am I getting all the ray workers and am I getting the",
    "start": "1512299",
    "end": "1519380"
  },
  {
    "text": "shuffling across so I can see there are some reduce operations happening so red dashboard is so critical in monitoring",
    "start": "1519380",
    "end": "1525620"
  },
  {
    "text": "your applications and then also to figure out that are your CPUs being well used and your Rams are being well used",
    "start": "1525620",
    "end": "1530900"
  },
  {
    "text": "or not based on that we tweak the size of this cluster that how much RAM and CPUs we",
    "start": "1530900",
    "end": "1537620"
  },
  {
    "text": "need so let me see what we are going so we are we are we have spawned four",
    "start": "1537620",
    "end": "1543320"
  },
  {
    "text": "machines and there are four ranks zero one zero to three and everyone is connected good and the dread training is",
    "start": "1543320",
    "end": "1550340"
  },
  {
    "text": "also happening it is happening so fast I have to catch up uh so okay so here is an example so the",
    "start": "1550340",
    "end": "1558320"
  },
  {
    "text": "executor is actually spawning up as a process in one of the nodes and you can verify it live and see that",
    "start": "1558320",
    "end": "1567080"
  },
  {
    "text": "the shuffling you did do you need four partitions eight partitions twelve partitions based on the number of actors everything you can figure out from this",
    "start": "1567080",
    "end": "1573740"
  },
  {
    "text": "dashboard so once this uh training is done so what happens see this cell is still",
    "start": "1573740",
    "end": "1580520"
  },
  {
    "text": "Mark star the training is done it has reached the end of its life but still it's there why is it there",
    "start": "1580520",
    "end": "1588020"
  },
  {
    "text": "the the reason it is there because I have said I want to wait on the cluster to die I don't want to come out of the",
    "start": "1588020",
    "end": "1593960"
  },
  {
    "text": "cell so that's why nodes are still terminating and it's it's still uh the sale is still running",
    "start": "1593960",
    "end": "1602240"
  },
  {
    "text": "um so while that is happening let me show you another ah quick we do not have time",
    "start": "1602240",
    "end": "1608360"
  },
  {
    "text": "to do demo for that so but let me uh we did a benchmark study so we ran the same thing uh Andre",
    "start": "1608360",
    "end": "1615860"
  },
  {
    "text": "online GBM and we ran the same program on non-ray just a normal like GBM so this",
    "start": "1615860",
    "end": "1623000"
  },
  {
    "text": "is a Training Method and there is no remote function exact same parameters",
    "start": "1623000",
    "end": "1628159"
  },
  {
    "text": "except to use the light GBM chain except to use the light GM train call",
    "start": "1628159",
    "end": "1634159"
  },
  {
    "text": "the rest of the things are remaining same and we train it it takes some time to train",
    "start": "1634159",
    "end": "1639260"
  },
  {
    "text": "so what's the goal of this study so let's go back to the okay the cluster",
    "start": "1639260",
    "end": "1645380"
  },
  {
    "text": "is gone everything is gone so this sale should have come out of its life let's go back",
    "start": "1645380",
    "end": "1651980"
  },
  {
    "text": "yes it is done ok so we have so this shows that we have a",
    "start": "1651980",
    "end": "1657559"
  },
  {
    "text": "clean cluster shutdown also we just keep don't keep on head note hit pause and hit uh worker pods hanging around",
    "start": "1657559",
    "end": "1665539"
  },
  {
    "text": "so we did a benchmark study between this approach and the local light GBM",
    "start": "1665539",
    "end": "1671360"
  },
  {
    "text": "approach we persisted two serialized models and we loaded it and then we did the predictions on the same data set so",
    "start": "1671360",
    "end": "1677900"
  },
  {
    "text": "what we did so generally uh we use usually plot residuals of uh two kinds",
    "start": "1677900",
    "end": "1684980"
  },
  {
    "text": "of models and on we see that they are almost pretty similar and then if we do a distribution of the",
    "start": "1684980",
    "end": "1692299"
  },
  {
    "text": "errors given by these two models they're almost all almost similar so we were",
    "start": "1692299",
    "end": "1698600"
  },
  {
    "text": "apprehensive that since Ray is working on a partition data set to model would not be as good as a if it",
    "start": "1698600",
    "end": "1707059"
  },
  {
    "text": "was trained on a single machine so here are some Matrix comparisons uh I",
    "start": "1707059",
    "end": "1712760"
  },
  {
    "text": "will quickly touch the ray accuracy is a little bit lower than the normalizing which is obvious because the data is",
    "start": "1712760",
    "end": "1718100"
  },
  {
    "text": "already partitioned and they are using all ring reduce to collect the gradients",
    "start": "1718100",
    "end": "1723260"
  },
  {
    "text": "but the most important part is like normal training takes 205 seconds but",
    "start": "1723260",
    "end": "1730520"
  },
  {
    "text": "the ray training takes 50 seconds and remember this 50 seconds includes the time to",
    "start": "1730520",
    "end": "1737900"
  },
  {
    "text": "spawn up the cluster and kill the cluster the actual training uh",
    "start": "1737900",
    "end": "1743840"
  },
  {
    "text": "actual training code is even lesser is very small as compared to the this 50",
    "start": "1743840",
    "end": "1752360"
  },
  {
    "text": "seconds and we can also calculate the cost so I will just quickly touch on like",
    "start": "1752360",
    "end": "1760159"
  },
  {
    "text": "okay we showed some methods it works seamlessly but what goes underneath",
    "start": "1760159",
    "end": "1766120"
  },
  {
    "text": "we are all Engineers we love to see some codes so I am not an exception to that",
    "start": "1766120",
    "end": "1771799"
  },
  {
    "text": "so this is array cluster so you must have seen this this example in the ray",
    "start": "1771799",
    "end": "1777320"
  },
  {
    "text": "GitHub and everyone uses that as a starting point we have some Maximum workers and we have",
    "start": "1777320",
    "end": "1783980"
  },
  {
    "text": "head parts and a Dimitri from rating helped us a lot some with some cluster queries and we are we had some",
    "start": "1783980",
    "end": "1790700"
  },
  {
    "text": "we are not able to spawn our clusters he helped us a lot but the bottom line is",
    "start": "1790700",
    "end": "1795740"
  },
  {
    "text": "like we want some worker nodes and I am one three workers and this is the yaml",
    "start": "1795740",
    "end": "1801440"
  },
  {
    "text": "you would typically apply if you want to create a cluster and then you will get the pods and check",
    "start": "1801440",
    "end": "1807919"
  },
  {
    "text": "how the parts are up and then do array in it check the available resources and submit the job and shut down of course",
    "start": "1807919",
    "end": "1813799"
  },
  {
    "text": "we can do it but no data scientist would want to do it why why why they would want to spawn ah some kubernetes",
    "start": "1813799",
    "end": "1820580"
  },
  {
    "text": "clusters on the fly so what can we do so that's why with case Ray comes up so let",
    "start": "1820580",
    "end": "1825919"
  },
  {
    "text": "us look at this code a little bit ah more so here is a python file",
    "start": "1825919",
    "end": "1835220"
  },
  {
    "text": "where unfortunately its not rendering but we",
    "start": "1835220",
    "end": "1840260"
  },
  {
    "text": "have used in a kubernetes clients to use ginger templates to apply these",
    "start": "1840260",
    "end": "1846500"
  },
  {
    "text": "yamls on the cluster so it is the same thing this is just as",
    "start": "1846500",
    "end": "1852020"
  },
  {
    "text": "simple as that use some ginger templates inject your parameters how many workers",
    "start": "1852020",
    "end": "1857240"
  },
  {
    "text": "you want that's done and we also inject S3 credentials to connect to S3 buckets",
    "start": "1857240",
    "end": "1862580"
  },
  {
    "text": "create confident credentials EFS mounts many more things stains and tolerations",
    "start": "1862580",
    "end": "1868159"
  },
  {
    "text": "for gpus ok so that ends uh I will quickly",
    "start": "1868159",
    "end": "1875770"
  },
  {
    "text": "[Music] um that ends our talk mostly and we have",
    "start": "1875770",
    "end": "1883640"
  },
  {
    "text": "some engineering blogs and if you want anyone wants to connect with us please feel free to do so thank you so much for",
    "start": "1883640",
    "end": "1889220"
  },
  {
    "text": "your attention [Applause]",
    "start": "1889220",
    "end": "1895850"
  }
]
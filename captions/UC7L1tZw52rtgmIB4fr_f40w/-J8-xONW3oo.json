[
  {
    "text": "welcome everyone to this talk I'm eating and this is my teammate Roy we are from",
    "start": "3620",
    "end": "9780"
  },
  {
    "text": "instabase uh so today we will discuss about uh deploying uh Ray on airgapped",
    "start": "9780",
    "end": "16080"
  },
  {
    "text": "kubernetes cluster with Enterprise security uh",
    "start": "16080",
    "end": "22400"
  },
  {
    "text": "so this is today's agenda so in the first section we will do an introduction what is instabase and we want to do a",
    "start": "23520",
    "end": "31439"
  },
  {
    "text": "quick recap of race key features uh that for our business also we want to talk",
    "start": "31439",
    "end": "36480"
  },
  {
    "text": "about how we use Ray add instabase and in the next section we want to talk about some unique challenges of air gap",
    "start": "36480",
    "end": "44160"
  },
  {
    "text": "Ray deployment in with tight security control and in the third part I will hand over",
    "start": "44160",
    "end": "50460"
  },
  {
    "text": "to royu to discuss some architecture and implementation details how we make this happen",
    "start": "50460",
    "end": "55680"
  },
  {
    "text": "and at the last section I will do a live demo directly into our environment and",
    "start": "55680",
    "end": "62219"
  },
  {
    "text": "show how we train the model and how we serve the model and if time allows we will do a q a",
    "start": "62219",
    "end": "70400"
  },
  {
    "text": "so okay so here is the first section uh what is things to base",
    "start": "70439",
    "end": "75540"
  },
  {
    "text": "so instabase provides a platform for building running and distribute elect",
    "start": "75540",
    "end": "80580"
  },
  {
    "text": "intelligent solutions that can process any type of input execute some custom",
    "start": "80580",
    "end": "86040"
  },
  {
    "text": "business logic facilit humor review at every step and integrate with industry",
    "start": "86040",
    "end": "91080"
  },
  {
    "text": "specific system to support some business decisions so one of the use case for us as we can",
    "start": "91080",
    "end": "97259"
  },
  {
    "text": "show from as we can see from here is the mortgage lending so traditionally mortgage lending is a very very time",
    "start": "97259",
    "end": "103619"
  },
  {
    "text": "consuming process so there are many many steps in the middle for example we need",
    "start": "103619",
    "end": "108840"
  },
  {
    "text": "some officer officer to review each cases and there are a lot of documents",
    "start": "108840",
    "end": "114119"
  },
  {
    "text": "we need like human to classify and validate these documents right so one of our use case",
    "start": "114119",
    "end": "122119"
  },
  {
    "text": "basically we allow the customer to build an automation workflow for the",
    "start": "122119",
    "end": "127259"
  },
  {
    "text": "unstructured data with many Advanced machine learning model to do these tasks for humans for example classification",
    "start": "127259",
    "end": "134520"
  },
  {
    "text": "extraction and this helps reduce the human effort dramatically",
    "start": "134520",
    "end": "140900"
  },
  {
    "text": "so as we discussed before or as we can sing from that diagram right so ml",
    "start": "141900",
    "end": "148140"
  },
  {
    "text": "really uh like plays a very very important role adding space so we",
    "start": "148140",
    "end": "153180"
  },
  {
    "text": "provide the capability to the non-technical user to fine-tune the model uh to based on their specific type",
    "start": "153180",
    "end": "160200"
  },
  {
    "text": "of document no matter it has structure or unstructured data so usually like the",
    "start": "160200",
    "end": "165540"
  },
  {
    "text": "people work for all those like Banks or some firms they don't know technology",
    "start": "165540",
    "end": "171420"
  },
  {
    "text": "they don't write code right so we really need to like make this machine learning technique to be accessible to these",
    "start": "171420",
    "end": "178260"
  },
  {
    "text": "non-technical users yeah so with that we basically built",
    "start": "178260",
    "end": "183720"
  },
  {
    "text": "some model training and solution Builder apps these help the user to create a",
    "start": "183720",
    "end": "188879"
  },
  {
    "text": "scaled model to like solve their unique business problems and the infra for the",
    "start": "188879",
    "end": "194940"
  },
  {
    "text": "model training service is powered by Ray which I will cover in the next later",
    "start": "194940",
    "end": "201319"
  },
  {
    "text": "so now let's talk about some key features that Ray brings to the table so",
    "start": "202680",
    "end": "207720"
  },
  {
    "text": "first of all it has distributed execution these allow us to execute tasks seamlessly across a cluster of",
    "start": "207720",
    "end": "214560"
  },
  {
    "text": "machines so once we train a model we can really scale it we can really scale the",
    "start": "214560",
    "end": "219959"
  },
  {
    "text": "model training workload like across multiple GPU nodes",
    "start": "219959",
    "end": "225140"
  },
  {
    "text": "and secondly Ray managed cluster resource like CPU memory and gpus with",
    "start": "225140",
    "end": "230700"
  },
  {
    "text": "efficiency and precision also it's very important to mention that it brings us visibility it has building",
    "start": "230700",
    "end": "238200"
  },
  {
    "text": "support to have the really good metrics about all the hardware resources and even for",
    "start": "238200",
    "end": "244319"
  },
  {
    "text": "the gpus and thirdly it's provide for tolerance if a worker node died we can easily",
    "start": "244319",
    "end": "250680"
  },
  {
    "text": "recover that worker node and Rey is able to schedule tasks to the worker node based on their specific",
    "start": "250680",
    "end": "257459"
  },
  {
    "text": "resource requirement and even customer resource and later my colleague Roy will talk about how we really optimize the",
    "start": "257459",
    "end": "264840"
  },
  {
    "text": "task scheduling use the customer resource and these give us a lot of a lot of flexibility to schedule the task",
    "start": "264840",
    "end": "273560"
  },
  {
    "text": "so now I want to introduce how we use Ray so as we can see from the diagram",
    "start": "274020",
    "end": "280860"
  },
  {
    "text": "data on the right side usually the the user like use the ml Studio to submit a",
    "start": "280860",
    "end": "287820"
  },
  {
    "text": "model training task and that one talk to the API server at instabase through HTTP and the API",
    "start": "287820",
    "end": "294960"
  },
  {
    "text": "server used the range of submission client to submit that job to the ray hat",
    "start": "294960",
    "end": "301259"
  },
  {
    "text": "rayhead itself has a CPU node and it also can in the ray cluster we also have",
    "start": "301259",
    "end": "308160"
  },
  {
    "text": "multiple GPU node so the ray hat will schedule the task to the ray worker",
    "start": "308160",
    "end": "314820"
  },
  {
    "text": "based on the specific like Hardware resource for the or customer resource definition for this for this job and",
    "start": "314820",
    "end": "322199"
  },
  {
    "text": "also the ray hat and the ray worker like keep exporting all those like metrics",
    "start": "322199",
    "end": "327600"
  },
  {
    "text": "Hardware metrics usage like logging to our internal monitoring login service",
    "start": "327600",
    "end": "333680"
  },
  {
    "text": "also the real worker during the model training I try to like upload and",
    "start": "333680",
    "end": "338940"
  },
  {
    "text": "download the model artifacts from the file service and all those like communication between service and within",
    "start": "338940",
    "end": "346440"
  },
  {
    "text": "Ray cluster we do have it like encrypted and also one of the use cases how to",
    "start": "346440",
    "end": "353039"
  },
  {
    "text": "authorize those GPU chip like efficiently right because GPU are really very expensive",
    "start": "353039",
    "end": "358199"
  },
  {
    "text": "so we do have like internal uh like library to squeeze two models into one",
    "start": "358199",
    "end": "365340"
  },
  {
    "text": "GPU to like this is especially useful for those small models and we use the",
    "start": "365340",
    "end": "371940"
  },
  {
    "text": "ray torch trainer and Ray tune to like train large model across multiple gpus",
    "start": "371940",
    "end": "378600"
  },
  {
    "text": "and this uh it's really easy it's already handled by uh Ray uh Air library",
    "start": "378600",
    "end": "384600"
  },
  {
    "text": "so uh this is basically how we make good use of these gpus",
    "start": "384600",
    "end": "390419"
  },
  {
    "text": "and also for the training observability part we raise support to export all",
    "start": "390419",
    "end": "395580"
  },
  {
    "text": "those metrics to the grafana and to the Prometheus so we basically take",
    "start": "395580",
    "end": "401220"
  },
  {
    "text": "advantage of that feature and also we do some like internal optimization to",
    "start": "401220",
    "end": "407280"
  },
  {
    "text": "export all those logs to the low key so we can easily keep track of those model",
    "start": "407280",
    "end": "412740"
  },
  {
    "text": "training logs and also we surface that log to the ml studio so the non-technical user really know what",
    "start": "412740",
    "end": "419160"
  },
  {
    "text": "happened in each step so this is how we use Ray so in the next section I want to talk",
    "start": "419160",
    "end": "426300"
  },
  {
    "text": "about some unique challenges so as we navigate the involving",
    "start": "426300",
    "end": "431400"
  },
  {
    "text": "landscape of distributed computing one of the challenge we often encounter",
    "start": "431400",
    "end": "437280"
  },
  {
    "text": "is the limitation imposed by the air gap system so now what do I mean by air gapped these are the system isolated",
    "start": "437280",
    "end": "444720"
  },
  {
    "text": "from the public internet right and while this isolation indeed",
    "start": "444720",
    "end": "449940"
  },
  {
    "text": "serve a purpose it brings some unique challenges with it",
    "start": "449940",
    "end": "454819"
  },
  {
    "text": "so if you work with or within a large Enterprise you're the probably no stranger to all those uh like long list",
    "start": "454979",
    "end": "462419"
  },
  {
    "text": "of security protocols and compliance checks and these rules are just guidelines they are often legal",
    "start": "462419",
    "end": "468300"
  },
  {
    "text": "requirements and system in such a secure environment usually have access to an internal Network and Docker registry but",
    "start": "468300",
    "end": "475680"
  },
  {
    "text": "these are tightly controlled and isolated from the unsecured like public internet",
    "start": "475680",
    "end": "481680"
  },
  {
    "text": "right and in addition the customer have tight permission control for the distributed",
    "start": "481680",
    "end": "488639"
  },
  {
    "text": "system and for example the official way that we like browse from the ray website",
    "start": "488639",
    "end": "495479"
  },
  {
    "text": "is to use kubre to deploy Ray on a kubernetes cluster but here is comes with a challenge",
    "start": "495479",
    "end": "503720"
  },
  {
    "text": "because deploying rate in kubernetes with Coupe Ray which is the official way",
    "start": "503720",
    "end": "509520"
  },
  {
    "text": "needs a customer resource definition crd so this one requires cluster-wide",
    "start": "509520",
    "end": "515880"
  },
  {
    "text": "permission but however usually the Enterprise customer will not give the platform",
    "start": "515880",
    "end": "521399"
  },
  {
    "text": "permission to in-store crd so with this we basically cannot use kubray Auto scaling and some other kubrey features",
    "start": "521399",
    "end": "528300"
  },
  {
    "text": "because we can now use kubrey so we have another approach to duato scouting which we will cover later in this talk",
    "start": "528300",
    "end": "536660"
  },
  {
    "text": "so most notably this air gap system have limited access to those cloud-based",
    "start": "540300",
    "end": "546680"
  },
  {
    "text": "debugging and monitoring tools and these tools are crucial for quickly and",
    "start": "546680",
    "end": "552720"
  },
  {
    "text": "effective debugging so these lack of access can make the debugging really challenging so in addition this",
    "start": "552720",
    "end": "559860"
  },
  {
    "text": "application are often composed of multiple components and each one running in a separate environment",
    "start": "559860",
    "end": "565920"
  },
  {
    "text": "and the traditional debugging tool is really hard to understand the data flow between the components",
    "start": "565920",
    "end": "572519"
  },
  {
    "text": "so between the resource limitation of air gap systems and the inherent complexity of distributed applications",
    "start": "572519",
    "end": "580040"
  },
  {
    "text": "debugging becomes a considerably like challenging task and in the coming slides we will explore",
    "start": "580040",
    "end": "586440"
  },
  {
    "text": "some strategies that we did to mitigate these challenges so with that I will",
    "start": "586440",
    "end": "591779"
  },
  {
    "text": "hand over to my colleague Roy to Deep dive into Ray integration settings the base",
    "start": "591779",
    "end": "598040"
  },
  {
    "text": "okay next I will walk through some implementation detail as iching mentioned air-gapped",
    "start": "600420",
    "end": "608720"
  },
  {
    "text": "environments have a lot of challenge to deploy um so first of all result equally to",
    "start": "608720",
    "end": "616980"
  },
  {
    "text": "manage the cluster we have to rely on some native kubernetes features to",
    "start": "616980",
    "end": "623640"
  },
  {
    "text": "manage the cluster we deploy re-head and reworker using different deployment but",
    "start": "623640",
    "end": "631200"
  },
  {
    "text": "the deployment sequence matters so what we did is we used innate container",
    "start": "631200",
    "end": "636300"
  },
  {
    "text": "inside the reworker and the innate container will always wait for the rehab",
    "start": "636300",
    "end": "641880"
  },
  {
    "text": "to start and then it starts a reworker so that the worker can register itself",
    "start": "641880",
    "end": "647399"
  },
  {
    "text": "correctly with the rehab and if anything goes wrong with the rear",
    "start": "647399",
    "end": "653940"
  },
  {
    "text": "head and reworker we rely on the kubernetes Readiness and the liveness",
    "start": "653940",
    "end": "659339"
  },
  {
    "text": "health check to detect those failures in rehab we use the real health check it",
    "start": "659339",
    "end": "666000"
  },
  {
    "text": "it checks the GCS server whether it's apple or down and in the worker we use a",
    "start": "666000",
    "end": "673740"
  },
  {
    "text": "really health check API so really it will continuously communicate with the rehead",
    "start": "673740",
    "end": "680579"
  },
  {
    "text": "and if the communication lost for a certain timeout the health check",
    "start": "680579",
    "end": "686399"
  },
  {
    "text": "will fail and kubernetes were detected and restart the real worker until it it",
    "start": "686399",
    "end": "692399"
  },
  {
    "text": "is able to reconnect with the head also we Implement Auto scaling we use a",
    "start": "692399",
    "end": "699600"
  },
  {
    "text": "combination of permissive stats and some in-house Auto scalar controller",
    "start": "699600",
    "end": "707100"
  },
  {
    "text": "to to implement this so as show as shown in the diagram below we have a matrix",
    "start": "707100",
    "end": "713700"
  },
  {
    "text": "that defined over 30 minutes like for last 30 minutes is there any jobs",
    "start": "713700",
    "end": "719880"
  },
  {
    "text": "running in the recluster if it's not we scale down as shown in the in the",
    "start": "719880",
    "end": "725940"
  },
  {
    "text": "diagram in in the graph and when there's new jobs submitted we can scale back up the",
    "start": "725940",
    "end": "733680"
  },
  {
    "text": "worker and next I will talk about how do we run",
    "start": "733680",
    "end": "739800"
  },
  {
    "text": "the training jobs by the way what we are training is not large language models",
    "start": "739800",
    "end": "745560"
  },
  {
    "text": "like pre-gpt it's mostly bird fan tuning jobs",
    "start": "745560",
    "end": "751920"
  },
  {
    "text": "yeah because it's a air gapped environment we have to build",
    "start": "751920",
    "end": "757980"
  },
  {
    "text": "all the dependencies into the container and ship it to the customer and when we run the job we submitted the",
    "start": "757980",
    "end": "767399"
  },
  {
    "text": "training script as a real job into in the rehab and the rehab will have a main",
    "start": "767399",
    "end": "774060"
  },
  {
    "text": "process that runs the job and use the real API to distribute these",
    "start": "774060",
    "end": "780060"
  },
  {
    "text": "computations to the different reworkers and we have a very interesting feature",
    "start": "780060",
    "end": "786899"
  },
  {
    "text": "called customer resources we use it very smart way we used to use it to define a",
    "start": "786899",
    "end": "793920"
  },
  {
    "text": "customer resource called queue size so usually for the computation cluster",
    "start": "793920",
    "end": "799639"
  },
  {
    "text": "is you cannot just let people submit all kind of job it will easily get overloaded and we don't want to build a",
    "start": "799639",
    "end": "807480"
  },
  {
    "text": "custom queue in front of Ray so we use a customer resource we Define customer resource based on the amount of memory",
    "start": "807480",
    "end": "815040"
  },
  {
    "text": "in the rehead and set a number like how many jobs we can accept and for each job",
    "start": "815040",
    "end": "820740"
  },
  {
    "text": "we submit to rehab it will consume one token from the total queue size",
    "start": "820740",
    "end": "826560"
  },
  {
    "text": "um also in our platform we have a different platform service for example",
    "start": "826560",
    "end": "832320"
  },
  {
    "text": "the observability we have a set of service Jagger Prometheus lucky those",
    "start": "832320",
    "end": "838139"
  },
  {
    "text": "are for logs and the and traces and we have as a database and file",
    "start": "838139",
    "end": "844260"
  },
  {
    "text": "system so in the real job we we have a script on the functions to integrate with all",
    "start": "844260",
    "end": "851519"
  },
  {
    "text": "the platform level services so this offers a fully observability into the",
    "start": "851519",
    "end": "856920"
  },
  {
    "text": "real training jobs so each training job we have a trace ID and using that Trace",
    "start": "856920",
    "end": "862800"
  },
  {
    "text": "ID we can draw on an aggregate all the traces from J Edgar permissions and logs",
    "start": "862800",
    "end": "868860"
  },
  {
    "text": "from looky and the metadata from the database and and artifacts from the file",
    "start": "868860",
    "end": "874380"
  },
  {
    "text": "system so this all these aggregate information will also surface to the",
    "start": "874380",
    "end": "879839"
  },
  {
    "text": "customer so when they run the job in the UI they can have a holistic view of what",
    "start": "879839",
    "end": "886880"
  },
  {
    "text": "what their job is doing also really helps us a lot to handle",
    "start": "886880",
    "end": "892620"
  },
  {
    "text": "failures when we run the training job there are many many times depend on the",
    "start": "892620",
    "end": "900779"
  },
  {
    "text": "size of the model or the size of input it will run auto memory or crash in certain ways and really help us a lot to",
    "start": "900779",
    "end": "909420"
  },
  {
    "text": "monitor those process in our Lexis system it was very painful to to debug",
    "start": "909420",
    "end": "916199"
  },
  {
    "text": "of all the other process crash we have to log into the machine and exam the log",
    "start": "916199",
    "end": "923100"
  },
  {
    "text": "and examine the uh the process Trace but with Ray it consists",
    "start": "923100",
    "end": "929959"
  },
  {
    "text": "continuously monitor the memory through footprint and if there's any error like",
    "start": "929959",
    "end": "936180"
  },
  {
    "text": "a lot of memory error the rear detect catch that and the surface it into the",
    "start": "936180",
    "end": "941279"
  },
  {
    "text": "driver driver's script and in the JavaScript we will store all the",
    "start": "941279",
    "end": "946500"
  },
  {
    "text": "information into the into the database and the user can see it immediately like",
    "start": "946500",
    "end": "952620"
  },
  {
    "text": "I show in the bottom they can immediately know the job failed due to out of memory",
    "start": "952620",
    "end": "960740"
  },
  {
    "text": "and at instabase we also have a surface service mesh implemented using",
    "start": "961740",
    "end": "969360"
  },
  {
    "text": "Envoy so it helps us to configure the network also to for network security",
    "start": "969360",
    "end": "976560"
  },
  {
    "text": "encrypted traffic and also do some smart load balancing inside the inside the",
    "start": "976560",
    "end": "983339"
  },
  {
    "text": "whole cluster and our recluster also integrate into this service mesh and all",
    "start": "983339",
    "end": "991440"
  },
  {
    "text": "the traffic between Ray and other platform service is fully encrypted also with the the writing is like",
    "start": "991440",
    "end": "998160"
  },
  {
    "text": "configurable using some smart algorithm to further tighten down the security",
    "start": "998160",
    "end": "1004720"
  },
  {
    "text": "within a recluster we also Implement TLS connections between rehab and reworker a",
    "start": "1004720",
    "end": "1013399"
  },
  {
    "text": "challenging here is that we had and reworker often communicate using the Pod",
    "start": "1013399",
    "end": "1018860"
  },
  {
    "text": "IP and to send a certificate for dynamic product IPS pretty",
    "start": "1018860",
    "end": "1025640"
  },
  {
    "text": "hard to manage so what we came up with is is that we use a innate container to",
    "start": "1025640",
    "end": "1032480"
  },
  {
    "text": "sign a self-cent certificate every time before the re cluster starts",
    "start": "1032480",
    "end": "1039740"
  },
  {
    "text": "and the sales and certificate will use the Pod IPS dynamically generated by the",
    "start": "1039740",
    "end": "1046400"
  },
  {
    "text": "kubernetes and with that certificate the rehab and reworker can establish TLS connection",
    "start": "1046400",
    "end": "1055580"
  },
  {
    "text": "and all this work we have documented very thoroughly and we also contribute to the re-document as well",
    "start": "1055580",
    "end": "1063940"
  },
  {
    "text": "okay I will hand back to itching 12 of end-to-end demo",
    "start": "1064940",
    "end": "1070539"
  },
  {
    "text": "uh yes so now let's do a live demo into our environment",
    "start": "1071000",
    "end": "1077360"
  },
  {
    "text": "uh so first of all this is uh basically what instabase looks like this is the UI",
    "start": "1077360",
    "end": "1083480"
  },
  {
    "text": "for instabase and let's head over to uh the app that we were used today which we",
    "start": "1083480",
    "end": "1089480"
  },
  {
    "text": "called solution Builder so first of all let me give you some",
    "start": "1089480",
    "end": "1095780"
  },
  {
    "text": "some high level about this demo so basically we will use uh uh the ray as",
    "start": "1095780",
    "end": "1104299"
  },
  {
    "text": "the infrastructure to train a model right then also we want to show that we",
    "start": "1104299",
    "end": "1110299"
  },
  {
    "text": "have some in-house like annotation too so how these work with the ray cluster",
    "start": "1110299",
    "end": "1115760"
  },
  {
    "text": "and during the process the rayware service like a lot of logs or metrics to",
    "start": "1115760",
    "end": "1121580"
  },
  {
    "text": "the observability tool then in the end we basically want to run the train model",
    "start": "1121580",
    "end": "1127720"
  },
  {
    "text": "and to really get some predictions so first of all I already created this",
    "start": "1127720",
    "end": "1134360"
  },
  {
    "text": "project but this is really easy to create just like create a folder",
    "start": "1134360",
    "end": "1141100"
  },
  {
    "text": "um just to save some time I already upload these pay stubs so first of all",
    "start": "1141380",
    "end": "1146900"
  },
  {
    "text": "let's take a look at the pay stub um so as we can see it's uh pretty like",
    "start": "1146900",
    "end": "1155059"
  },
  {
    "text": "unstructured uh let's also take a look at this one",
    "start": "1155059",
    "end": "1162580"
  },
  {
    "text": "and this one is just a scan copy of a pay stub from Intuit",
    "start": "1165500",
    "end": "1171260"
  },
  {
    "text": "by the way all these PDFs are like generated not not a real document",
    "start": "1171260",
    "end": "1178820"
  },
  {
    "text": "so as we consider these as unstructured data",
    "start": "1178820",
    "end": "1183980"
  },
  {
    "text": "so now let's use this file to create an",
    "start": "1183980",
    "end": "1189020"
  },
  {
    "text": "annotation set so to do that I just need to click this button so I pre-created",
    "start": "1189020",
    "end": "1195160"
  },
  {
    "text": "these two annotation set based on the labels for this document one is Intuit",
    "start": "1195160",
    "end": "1201559"
  },
  {
    "text": "one is from ADP so let's open up the ADP one",
    "start": "1201559",
    "end": "1210100"
  },
  {
    "text": "so as we can see from here all the documents with the green dots are",
    "start": "1214059",
    "end": "1219080"
  },
  {
    "text": "already annotated but I like leave two uh so I can annotate it here Lively",
    "start": "1219080",
    "end": "1227539"
  },
  {
    "text": "so all we need to do is uh like just select this name field and I can mark",
    "start": "1227539",
    "end": "1234320"
  },
  {
    "text": "this as annotated and same as this one all we need to do is just select this",
    "start": "1234320",
    "end": "1241059"
  },
  {
    "text": "name and Mark as annotated okay so we have all the like documents annotated",
    "start": "1241059",
    "end": "1247880"
  },
  {
    "text": "here so what to do next let's go back to the solution Builder project",
    "start": "1247880",
    "end": "1255820"
  },
  {
    "text": "um let's go back here let's go to the models the model is pretty easy to adjusting to",
    "start": "1256460",
    "end": "1265039"
  },
  {
    "text": "create new to create a new model project but just to save some time here I already created a model so let's open it",
    "start": "1265039",
    "end": "1272299"
  },
  {
    "text": "up",
    "start": "1272299",
    "end": "1274480"
  },
  {
    "text": "so this one uh this app is a new app we call it machine Learning Studio this is",
    "start": "1277400",
    "end": "1283460"
  },
  {
    "text": "the app that we use to train a model so behind this app the infrastructure is",
    "start": "1283460",
    "end": "1288559"
  },
  {
    "text": "array so we use Ray job to train a job so let's click the train button this is",
    "start": "1288559",
    "end": "1296059"
  },
  {
    "text": "a brand new model we haven't tried anything yet um so here we can select different base",
    "start": "1296059",
    "end": "1302240"
  },
  {
    "text": "models so for now let's just use the default one we basically have some uh",
    "start": "1302240",
    "end": "1308000"
  },
  {
    "text": "how to like suggestion for the user and we also have like Auto suggestions for all the parameters uh so since I'm a",
    "start": "1308000",
    "end": "1315740"
  },
  {
    "text": "non-technical user I act as a non-technical user so I just train the model with the default value",
    "start": "1315740",
    "end": "1323559"
  },
  {
    "text": "and also I want to showcase that uh here",
    "start": "1326539",
    "end": "1332620"
  },
  {
    "text": "in the advanced hyper parameters the user can choose different GPU allocation mode so as I introduced earlier the",
    "start": "1333080",
    "end": "1340940"
  },
  {
    "text": "partial one basically we can squeeze multiple model training jobs into one GPU if the model is relatively small",
    "start": "1340940",
    "end": "1348080"
  },
  {
    "text": "and the multi-gpu one we use the rate or trainer and the Ray tune to like",
    "start": "1348080",
    "end": "1353299"
  },
  {
    "text": "distributed the model training job across multiple gpus",
    "start": "1353299",
    "end": "1358940"
  },
  {
    "text": "so here we can see the job is started so maybe we can head over to the",
    "start": "1358940",
    "end": "1367299"
  },
  {
    "text": "Tudor grafana",
    "start": "1369140",
    "end": "1372280"
  },
  {
    "text": "so here is the uh the dashboard for the ray training job so as we can see from",
    "start": "1379700",
    "end": "1387799"
  },
  {
    "text": "here there is new tasks comes in uh we use this to scale uh to scale the GPU",
    "start": "1387799",
    "end": "1394820"
  },
  {
    "text": "node actually we can take a look at maybe a",
    "start": "1394820",
    "end": "1400520"
  },
  {
    "text": "longer time so we can really tell that so here really a small friction of time",
    "start": "1400520",
    "end": "1408200"
  },
  {
    "text": "we have GPU deployed because there is tasks coming",
    "start": "1408200",
    "end": "1415100"
  },
  {
    "text": "as I show from here so one task coming we scale the GPU up",
    "start": "1415100",
    "end": "1420520"
  },
  {
    "text": "then there's some node to process this GPU training job then after 30 minutes",
    "start": "1420520",
    "end": "1426320"
  },
  {
    "text": "if there's no jobs coming we scale down the GPU node",
    "start": "1426320",
    "end": "1431980"
  },
  {
    "text": "so things the model where train training will take some time so maybe I can just",
    "start": "1432700",
    "end": "1438080"
  },
  {
    "text": "use show you guys what is the trained model looks like uh so let's take a look",
    "start": "1438080",
    "end": "1444980"
  },
  {
    "text": "at this one I have multiple training jobs",
    "start": "1444980",
    "end": "1450919"
  },
  {
    "text": "uh if we build a detail it will have all the metrics show in this app and we also",
    "start": "1450919",
    "end": "1457700"
  },
  {
    "text": "have locks the user can use this to track like each step of the model training status and in the grafana in",
    "start": "1457700",
    "end": "1467059"
  },
  {
    "text": "the grafana tool we have this integrate with Loki the user can use the low-key",
    "start": "1467059",
    "end": "1476120"
  },
  {
    "text": "low-key service to track there will be a trace ID so they can",
    "start": "1476120",
    "end": "1481880"
  },
  {
    "text": "also link to the Jaeger to trace each like request",
    "start": "1481880",
    "end": "1488659"
  },
  {
    "text": "so I won't show here but okay so so let's take a look if the",
    "start": "1488659",
    "end": "1493700"
  },
  {
    "text": "model training is finished",
    "start": "1493700",
    "end": "1496960"
  },
  {
    "text": "I think it's still got trained so maybe let's just take a look at the trained",
    "start": "1503840",
    "end": "1508940"
  },
  {
    "text": "model for example we have like three version of the Intuit model right so let's just",
    "start": "1508940",
    "end": "1516200"
  },
  {
    "text": "randomly choose one",
    "start": "1516200",
    "end": "1519220"
  },
  {
    "text": "so let's run maybe two document we can take a look",
    "start": "1521360",
    "end": "1527200"
  },
  {
    "text": "yeah I don't think the during the demo the the note will be scaled down because we don't have like 30 minutes uh time to",
    "start": "1551299",
    "end": "1558380"
  },
  {
    "text": "wait for it to scale down but based on the historical uh data we can really see",
    "start": "1558380",
    "end": "1563720"
  },
  {
    "text": "that the node will be scale down so we can take a look at the refiner",
    "start": "1563720",
    "end": "1572020"
  },
  {
    "text": "so once the job finished uh the the model influencing it will generate some",
    "start": "1573020",
    "end": "1579559"
  },
  {
    "text": "document so we can really the user can just open it up in this",
    "start": "1579559",
    "end": "1587120"
  },
  {
    "text": "in this app uh maybe let's just wait until the the",
    "start": "1587120",
    "end": "1594140"
  },
  {
    "text": "job finished training usually this one",
    "start": "1594140",
    "end": "1599480"
  },
  {
    "text": "um probably will take some time because there are some other users also use the platform right now",
    "start": "1599480",
    "end": "1606580"
  },
  {
    "text": "uh and one more thing I want to show up is here so once we finish like check the",
    "start": "1644659",
    "end": "1651740"
  },
  {
    "text": "result for this document we have a Flow app in this solution Builder with this",
    "start": "1651740",
    "end": "1659600"
  },
  {
    "text": "we can basically generate some new workflows and also we can build from",
    "start": "1659600",
    "end": "1665960"
  },
  {
    "text": "scratch so this can let the user to build the workflow to process this kind of document",
    "start": "1665960",
    "end": "1672500"
  },
  {
    "text": "and as we can see from here we can create for example",
    "start": "1672500",
    "end": "1678080"
  },
  {
    "text": "let's select these two annotation sets it looks like our job is running right",
    "start": "1678080",
    "end": "1684200"
  },
  {
    "text": "now so we have also classification model so with this we can really build like a",
    "start": "1684200",
    "end": "1691039"
  },
  {
    "text": "workflow so usually the first step is the user uploads a huge amount of document right first of all we want to",
    "start": "1691039",
    "end": "1697640"
  },
  {
    "text": "train a relatively large classification model so we know like which ma which",
    "start": "1697640",
    "end": "1703400"
  },
  {
    "text": "document is most likely which form then we use the extraction model so",
    "start": "1703400",
    "end": "1708440"
  },
  {
    "text": "extraction model we can make a lot of annotations so it can train and extract",
    "start": "1708440",
    "end": "1713960"
  },
  {
    "text": "the like corresponding field to the user and let's take a look at the output set",
    "start": "1713960",
    "end": "1724179"
  },
  {
    "text": "so these are the two documents that being generated so let's take a look at the models",
    "start": "1733039",
    "end": "1741340"
  },
  {
    "text": "so here is basically the model that we just run",
    "start": "1746020",
    "end": "1751279"
  },
  {
    "text": "yeah so I think the time is over that's the demo",
    "start": "1751279",
    "end": "1756799"
  },
  {
    "text": "also uh so here let me give just one more minutes so this is our new product uh",
    "start": "1756799",
    "end": "1766279"
  },
  {
    "text": "we call it AI hub so this air Hub used some Advantage",
    "start": "1766279",
    "end": "1774140"
  },
  {
    "text": "Advanced large language model to analyze your document and it offers immediate",
    "start": "1774140",
    "end": "1779600"
  },
  {
    "text": "data interpretation content summarization and even more you can build a workflow just like I showed",
    "start": "1779600",
    "end": "1784940"
  },
  {
    "text": "before to optimize the entire process the AI Hardware converts like static and",
    "start": "1784940",
    "end": "1790820"
  },
  {
    "text": "unstructured data into actionable insight and it also can like enhance efficiency and decision making during",
    "start": "1790820",
    "end": "1797360"
  },
  {
    "text": "the like the business process and we are currently working on use Razer to serve",
    "start": "1797360",
    "end": "1802460"
  },
  {
    "text": "the large language model for this product uh yeah so so that's it for the talk",
    "start": "1802460",
    "end": "1811340"
  },
  {
    "text": "um yeah that's it thank you thank you guys",
    "start": "1811340",
    "end": "1815980"
  }
]
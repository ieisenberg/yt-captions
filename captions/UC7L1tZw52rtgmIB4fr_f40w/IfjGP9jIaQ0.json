[
  {
    "text": "all right",
    "start": "5480",
    "end": "7220"
  },
  {
    "text": "so Jan just highlighted some of the new",
    "start": "7220",
    "end": "10139"
  },
  {
    "text": "any scale features and I'm going to give",
    "start": "10139",
    "end": "11940"
  },
  {
    "text": "a quick demo of how you can use any",
    "start": "11940",
    "end": "14280"
  },
  {
    "text": "scale and the ray AI runtime to build an",
    "start": "14280",
    "end": "17220"
  },
  {
    "text": "end-to-end machine learning application",
    "start": "17220",
    "end": "18900"
  },
  {
    "text": "and before I dive into the actual coding",
    "start": "18900",
    "end": "21900"
  },
  {
    "text": "I want to mention there are a few",
    "start": "21900",
    "end": "23340"
  },
  {
    "text": "different ways to use Ray air the first",
    "start": "23340",
    "end": "26760"
  },
  {
    "text": "and the simplest is to use Ray air as",
    "start": "26760",
    "end": "29099"
  },
  {
    "text": "part of an existing machine learning",
    "start": "29099",
    "end": "31019"
  },
  {
    "text": "pipeline to scale just one component",
    "start": "31019",
    "end": "34079"
  },
  {
    "text": "so imagine this is your machine learning",
    "start": "34079",
    "end": "36000"
  },
  {
    "text": "pipeline you're doing everything you've",
    "start": "36000",
    "end": "37559"
  },
  {
    "text": "already gotten it working you're doing",
    "start": "37559",
    "end": "39180"
  },
  {
    "text": "everything from loading your data",
    "start": "39180",
    "end": "40739"
  },
  {
    "text": "processing your data training your",
    "start": "40739",
    "end": "42360"
  },
  {
    "text": "models deploying your models but as you",
    "start": "42360",
    "end": "44940"
  },
  {
    "text": "scale one of these components turns out",
    "start": "44940",
    "end": "47100"
  },
  {
    "text": "to be a bottleneck the bottleneck could",
    "start": "47100",
    "end": "49320"
  },
  {
    "text": "be anywhere but imagine it's hyper",
    "start": "49320",
    "end": "51000"
  },
  {
    "text": "parameter tuning hyper parameter tuning",
    "start": "51000",
    "end": "53280"
  },
  {
    "text": "refers to training many models so you",
    "start": "53280",
    "end": "55620"
  },
  {
    "text": "can find the best one",
    "start": "55620",
    "end": "57180"
  },
  {
    "text": "and what you can do in this case is you",
    "start": "57180",
    "end": "59399"
  },
  {
    "text": "can introduce Ray you can use Rey change",
    "start": "59399",
    "end": "61860"
  },
  {
    "text": "a few lines of code and scale just that",
    "start": "61860",
    "end": "64320"
  },
  {
    "text": "one component leaving everything else in",
    "start": "64320",
    "end": "66720"
  },
  {
    "text": "place",
    "start": "66720",
    "end": "67439"
  },
  {
    "text": "and this is important because you may",
    "start": "67439",
    "end": "69479"
  },
  {
    "text": "already be using a number of different",
    "start": "69479",
    "end": "70860"
  },
  {
    "text": "tools you may have ml platforms like",
    "start": "70860",
    "end": "72840"
  },
  {
    "text": "sagemaker or vertex you may have data",
    "start": "72840",
    "end": "75060"
  },
  {
    "text": "platforms you may be using a variety of",
    "start": "75060",
    "end": "76979"
  },
  {
    "text": "mlops Frameworks Ray integrates with",
    "start": "76979",
    "end": "79500"
  },
  {
    "text": "everything and so you can leave",
    "start": "79500",
    "end": "80880"
  },
  {
    "text": "everything in place and scale just that",
    "start": "80880",
    "end": "83040"
  },
  {
    "text": "one component with Rey",
    "start": "83040",
    "end": "85740"
  },
  {
    "text": "the second way to use Rey is to not just",
    "start": "85740",
    "end": "88560"
  },
  {
    "text": "scale a single part of your application",
    "start": "88560",
    "end": "90299"
  },
  {
    "text": "but actually scale the end-to-end thing",
    "start": "90299",
    "end": "92820"
  },
  {
    "text": "with Ray air and so here's the same ml",
    "start": "92820",
    "end": "96540"
  },
  {
    "text": "application we have we're showing before",
    "start": "96540",
    "end": "98040"
  },
  {
    "text": "everything from data ingest to model",
    "start": "98040",
    "end": "100380"
  },
  {
    "text": "deployment what you can do is you can",
    "start": "100380",
    "end": "102360"
  },
  {
    "text": "actually build and scale this entire",
    "start": "102360",
    "end": "104240"
  },
  {
    "text": "application and pipeline using Ray air",
    "start": "104240",
    "end": "107220"
  },
  {
    "text": "and that's actually what I'm going to",
    "start": "107220",
    "end": "109020"
  },
  {
    "text": "demo here today",
    "start": "109020",
    "end": "110759"
  },
  {
    "text": "but before I dive into the code and",
    "start": "110759",
    "end": "112860"
  },
  {
    "text": "actually implement this I want to",
    "start": "112860",
    "end": "114720"
  },
  {
    "text": "mention there's a third way you can use",
    "start": "114720",
    "end": "116100"
  },
  {
    "text": "Rey which is to build not only a single",
    "start": "116100",
    "end": "118680"
  },
  {
    "text": "machine learning application but an",
    "start": "118680",
    "end": "120960"
  },
  {
    "text": "entire machine learning platform on top",
    "start": "120960",
    "end": "123420"
  },
  {
    "text": "of Ray air and this is what companies",
    "start": "123420",
    "end": "125460"
  },
  {
    "text": "like uber and Shopify have done and so I",
    "start": "125460",
    "end": "128280"
  },
  {
    "text": "if you're interested in learning more",
    "start": "128280",
    "end": "129479"
  },
  {
    "text": "about these kinds of use cases I'd",
    "start": "129479",
    "end": "131459"
  },
  {
    "text": "encourage you to check out their talks",
    "start": "131459",
    "end": "132840"
  },
  {
    "text": "today and tomorrow",
    "start": "132840",
    "end": "134520"
  },
  {
    "text": "okay so let's actually zoom in on how to",
    "start": "134520",
    "end": "137580"
  },
  {
    "text": "build the end-to-end machine learning",
    "start": "137580",
    "end": "139440"
  },
  {
    "text": "application",
    "start": "139440",
    "end": "140640"
  },
  {
    "text": "so our running example for this",
    "start": "140640",
    "end": "142560"
  },
  {
    "text": "presentation is going to be building a",
    "start": "142560",
    "end": "144180"
  },
  {
    "text": "movie recommendation system very simple",
    "start": "144180",
    "end": "146160"
  },
  {
    "text": "on the surface but there's a lot of",
    "start": "146160",
    "end": "148020"
  },
  {
    "text": "complexity to make it work well",
    "start": "148020",
    "end": "150959"
  },
  {
    "text": "and the structure of our of our demo of",
    "start": "150959",
    "end": "153420"
  },
  {
    "text": "our application will follow the same",
    "start": "153420",
    "end": "155280"
  },
  {
    "text": "pattern we're going to be ingesting data",
    "start": "155280",
    "end": "157440"
  },
  {
    "text": "and pre-processing that data that data",
    "start": "157440",
    "end": "159660"
  },
  {
    "text": "is going to be historical examples of",
    "start": "159660",
    "end": "161819"
  },
  {
    "text": "which users liked which movies",
    "start": "161819",
    "end": "163980"
  },
  {
    "text": "we're going to do machine learning",
    "start": "163980",
    "end": "165900"
  },
  {
    "text": "training we're going to train a deep",
    "start": "165900",
    "end": "167040"
  },
  {
    "text": "learning model a pytorch model to uh to",
    "start": "167040",
    "end": "169980"
  },
  {
    "text": "generate recommendations and actually",
    "start": "169980",
    "end": "171360"
  },
  {
    "text": "predict which users will like which",
    "start": "171360",
    "end": "172920"
  },
  {
    "text": "movies",
    "start": "172920",
    "end": "174239"
  },
  {
    "text": "and then we're going to take that model",
    "start": "174239",
    "end": "175500"
  },
  {
    "text": "and deploy it and we're going to use",
    "start": "175500",
    "end": "177300"
  },
  {
    "text": "that deployed model to power the actual",
    "start": "177300",
    "end": "180239"
  },
  {
    "text": "website the web app that we're going to",
    "start": "180239",
    "end": "182040"
  },
  {
    "text": "show to generate recommendations",
    "start": "182040",
    "end": "185459"
  },
  {
    "text": "and what we're going to build with Ray",
    "start": "185459",
    "end": "187080"
  },
  {
    "text": "air is everything in blue all of the",
    "start": "187080",
    "end": "189540"
  },
  {
    "text": "compute pieces and it's we're going to",
    "start": "189540",
    "end": "191580"
  },
  {
    "text": "show the advantages of having common",
    "start": "191580",
    "end": "193140"
  },
  {
    "text": "infrastructure for scaling all of these",
    "start": "193140",
    "end": "195300"
  },
  {
    "text": "different workloads",
    "start": "195300",
    "end": "196739"
  },
  {
    "text": "and as a bonus this is already a lot but",
    "start": "196739",
    "end": "199680"
  },
  {
    "text": "as a bonus we are going to show how to",
    "start": "199680",
    "end": "201540"
  },
  {
    "text": "do continual retraining so as new data",
    "start": "201540",
    "end": "204180"
  },
  {
    "text": "comes in closing the loop to",
    "start": "204180",
    "end": "206040"
  },
  {
    "text": "continuously update the model to train",
    "start": "206040",
    "end": "207959"
  },
  {
    "text": "on the latest data and that's actually",
    "start": "207959",
    "end": "209700"
  },
  {
    "text": "turns out to be important for a lot of",
    "start": "209700",
    "end": "211319"
  },
  {
    "text": "recommendation systems the fresher the",
    "start": "211319",
    "end": "213599"
  },
  {
    "text": "data the more relevant the",
    "start": "213599",
    "end": "215340"
  },
  {
    "text": "recommendations can be",
    "start": "215340",
    "end": "217319"
  },
  {
    "text": "okay so let's actually dive in I want to",
    "start": "217319",
    "end": "220319"
  },
  {
    "text": "start by implementing everything in the",
    "start": "220319",
    "end": "222480"
  },
  {
    "text": "red box everything from data ingestion",
    "start": "222480",
    "end": "224280"
  },
  {
    "text": "to training to hyper parameter tuning",
    "start": "224280",
    "end": "226200"
  },
  {
    "text": "and then we'll get to the next part and",
    "start": "226200",
    "end": "227940"
  },
  {
    "text": "so to implement this I'm going to switch",
    "start": "227940",
    "end": "230819"
  },
  {
    "text": "over to the any scale UI to show you",
    "start": "230819",
    "end": "233099"
  },
  {
    "text": "what I'm doing",
    "start": "233099",
    "end": "234720"
  },
  {
    "text": "okay so here I have an any scale",
    "start": "234720",
    "end": "237239"
  },
  {
    "text": "workspace started up you don't have to",
    "start": "237239",
    "end": "238680"
  },
  {
    "text": "read the text I know it's small the",
    "start": "238680",
    "end": "240480"
  },
  {
    "text": "details that are not super important but",
    "start": "240480",
    "end": "242640"
  },
  {
    "text": "the point to mention like Jan said this",
    "start": "242640",
    "end": "245519"
  },
  {
    "text": "is a tool for managing the entire",
    "start": "245519",
    "end": "248040"
  },
  {
    "text": "machine entire application life cycle",
    "start": "248040",
    "end": "250200"
  },
  {
    "text": "from development to deploying it",
    "start": "250200",
    "end": "252780"
  },
  {
    "text": "and you can think of any scale the any",
    "start": "252780",
    "end": "255840"
  },
  {
    "text": "scale workspace as a box in the cloud",
    "start": "255840",
    "end": "258239"
  },
  {
    "text": "where I can do local development except",
    "start": "258239",
    "end": "260579"
  },
  {
    "text": "it's not just a single box in this case",
    "start": "260579",
    "end": "262740"
  },
  {
    "text": "I have nearly a thousand CPU cores 16",
    "start": "262740",
    "end": "265199"
  },
  {
    "text": "gpus and a ton of ram as well",
    "start": "265199",
    "end": "268080"
  },
  {
    "text": "so I've already cloned my my project I'm",
    "start": "268080",
    "end": "270780"
  },
  {
    "text": "going to be editing the project to",
    "start": "270780",
    "end": "271919"
  },
  {
    "text": "actually develop this application and",
    "start": "271919",
    "end": "274199"
  },
  {
    "text": "I'm going to start by opening an IDE so",
    "start": "274199",
    "end": "276960"
  },
  {
    "text": "I'm through any scale I'm opening up a",
    "start": "276960",
    "end": "279000"
  },
  {
    "text": "vs code okay so that's the editor I'll",
    "start": "279000",
    "end": "281340"
  },
  {
    "text": "be using",
    "start": "281340",
    "end": "282540"
  },
  {
    "text": "and this is vs code is running running",
    "start": "282540",
    "end": "286979"
  },
  {
    "text": "on my laptop but the code that we're",
    "start": "286979",
    "end": "289020"
  },
  {
    "text": "editing actually lives in the cloud on",
    "start": "289020",
    "end": "290759"
  },
  {
    "text": "any scale so vs code is connected",
    "start": "290759",
    "end": "292320"
  },
  {
    "text": "through remote SSH to any scale",
    "start": "292320",
    "end": "295560"
  },
  {
    "text": "and I'm going to open up this file",
    "start": "295560",
    "end": "297380"
  },
  {
    "text": "train.pi so as we edit this code it's",
    "start": "297380",
    "end": "299699"
  },
  {
    "text": "it's changing in the cloud on any scale",
    "start": "299699",
    "end": "302580"
  },
  {
    "text": "um this is the skeleton of the",
    "start": "302580",
    "end": "304080"
  },
  {
    "text": "application that we're going to be",
    "start": "304080",
    "end": "305460"
  },
  {
    "text": "building",
    "start": "305460",
    "end": "306300"
  },
  {
    "text": "so I have a few import statements I'll",
    "start": "306300",
    "end": "308280"
  },
  {
    "text": "explain them when I when I use them and",
    "start": "308280",
    "end": "310080"
  },
  {
    "text": "we have a few hard-coded URLs that we're",
    "start": "310080",
    "end": "312540"
  },
  {
    "text": "going to use for fetching our data and",
    "start": "312540",
    "end": "314220"
  },
  {
    "text": "checkpointing the model okay so I'm",
    "start": "314220",
    "end": "317220"
  },
  {
    "text": "going to scroll up a little bit just so",
    "start": "317220",
    "end": "318540"
  },
  {
    "text": "we can focus on the actual uh meat of",
    "start": "318540",
    "end": "321660"
  },
  {
    "text": "the application",
    "start": "321660",
    "end": "323100"
  },
  {
    "text": "so as a reminder of what we're building",
    "start": "323100",
    "end": "325759"
  },
  {
    "text": "there are three there are three parts",
    "start": "325759",
    "end": "328020"
  },
  {
    "text": "that we're building there's the data",
    "start": "328020",
    "end": "329699"
  },
  {
    "text": "ingest and pre-processing then we're",
    "start": "329699",
    "end": "331440"
  },
  {
    "text": "going to train the model then we're",
    "start": "331440",
    "end": "332940"
  },
  {
    "text": "going to do hyper parameter tuning okay",
    "start": "332940",
    "end": "335340"
  },
  {
    "text": "and part of what I'm trying to",
    "start": "335340",
    "end": "336539"
  },
  {
    "text": "illustrate here is the Simplicity of Ray",
    "start": "336539",
    "end": "338639"
  },
  {
    "text": "air which lets us do this in relatively",
    "start": "338639",
    "end": "341160"
  },
  {
    "text": "few lines of code",
    "start": "341160",
    "end": "342660"
  },
  {
    "text": "so to start off with let's fetch the",
    "start": "342660",
    "end": "344880"
  },
  {
    "text": "data I'm going to use I'm going to",
    "start": "344880",
    "end": "346740"
  },
  {
    "text": "create a data set using Ray data this is",
    "start": "346740",
    "end": "349259"
  },
  {
    "text": "one of the ray air libraries and we're",
    "start": "349259",
    "end": "351300"
  },
  {
    "text": "going to read a parquet file from uh",
    "start": "351300",
    "end": "353759"
  },
  {
    "text": "from S3 okay so this is scaling data in",
    "start": "353759",
    "end": "356280"
  },
  {
    "text": "just about 100 gigabytes across",
    "start": "356280",
    "end": "358259"
  },
  {
    "text": "potentially up to a thousand CPU cores",
    "start": "358259",
    "end": "361259"
  },
  {
    "text": "then we're going to transform the data",
    "start": "361259",
    "end": "363180"
  },
  {
    "text": "set so I'm going to create a processed",
    "start": "363180",
    "end": "365460"
  },
  {
    "text": "data set",
    "start": "365460",
    "end": "366780"
  },
  {
    "text": "and this is going to use a process",
    "start": "366780",
    "end": "369180"
  },
  {
    "text": "preprocessor that I'm importing and",
    "start": "369180",
    "end": "371639"
  },
  {
    "text": "we're going to use that to transform the",
    "start": "371639",
    "end": "374039"
  },
  {
    "text": "data set",
    "start": "374039",
    "end": "375120"
  },
  {
    "text": "okay so I didn't Define the preprocessor",
    "start": "375120",
    "end": "377280"
  },
  {
    "text": "that's something I imported but you it",
    "start": "377280",
    "end": "379020"
  },
  {
    "text": "uses Ray data and you can think of it as",
    "start": "379020",
    "end": "381180"
  },
  {
    "text": "doing some maps and reduces and filters",
    "start": "381180",
    "end": "383759"
  },
  {
    "text": "to compute the features that we want to",
    "start": "383759",
    "end": "386160"
  },
  {
    "text": "use for uh for training",
    "start": "386160",
    "end": "388620"
  },
  {
    "text": "and so that's everything we have to do",
    "start": "388620",
    "end": "389880"
  },
  {
    "text": "for the data ingest and pre-processing",
    "start": "389880",
    "end": "392100"
  },
  {
    "text": "what we're doing in a couple lines of",
    "start": "392100",
    "end": "393780"
  },
  {
    "text": "code here is something you would",
    "start": "393780",
    "end": "395340"
  },
  {
    "text": "normally use an entire distributed",
    "start": "395340",
    "end": "396900"
  },
  {
    "text": "system like spark to accomplish",
    "start": "396900",
    "end": "399900"
  },
  {
    "text": "so now that we have our data let's",
    "start": "399900",
    "end": "402060"
  },
  {
    "text": "actually scale training on a bunch of",
    "start": "402060",
    "end": "404100"
  },
  {
    "text": "gpus",
    "start": "404100",
    "end": "405120"
  },
  {
    "text": "so here we're going to create a trainer",
    "start": "405120",
    "end": "406740"
  },
  {
    "text": "we're going to use raytrain and we're",
    "start": "406740",
    "end": "408720"
  },
  {
    "text": "going to create a train a pie torch",
    "start": "408720",
    "end": "410280"
  },
  {
    "text": "model",
    "start": "410280",
    "end": "411539"
  },
  {
    "text": "um",
    "start": "411539",
    "end": "412199"
  },
  {
    "text": "and um and we're going to pass in train",
    "start": "412199",
    "end": "415380"
  },
  {
    "text": "function so train func what this is",
    "start": "415380",
    "end": "417419"
  },
  {
    "text": "doing this is essentially that's another",
    "start": "417419",
    "end": "419819"
  },
  {
    "text": "thing I imported it's single machine",
    "start": "419819",
    "end": "422520"
  },
  {
    "text": "code for training pytorch okay so this",
    "start": "422520",
    "end": "424740"
  },
  {
    "text": "is what you would do if you're just",
    "start": "424740",
    "end": "425819"
  },
  {
    "text": "using pytorch on your laptop raytrain",
    "start": "425819",
    "end": "428460"
  },
  {
    "text": "lets you take the pytorch code on your",
    "start": "428460",
    "end": "430620"
  },
  {
    "text": "laptop and scale it across many gpus or",
    "start": "430620",
    "end": "433319"
  },
  {
    "text": "many machines",
    "start": "433319",
    "end": "434460"
  },
  {
    "text": "okay there are a few more parameters I",
    "start": "434460",
    "end": "436500"
  },
  {
    "text": "need to fill in to make this actually",
    "start": "436500",
    "end": "437759"
  },
  {
    "text": "work but um but I'll come back to that",
    "start": "437759",
    "end": "440460"
  },
  {
    "text": "after in a little bit",
    "start": "440460",
    "end": "442199"
  },
  {
    "text": "and one thing I want to point out",
    "start": "442199",
    "end": "443880"
  },
  {
    "text": "quickly is that I'm showing that in this",
    "start": "443880",
    "end": "445979"
  },
  {
    "text": "demo we're showing how to scale Pi torch",
    "start": "445979",
    "end": "447479"
  },
  {
    "text": "but if you wanted to use tensorflow or",
    "start": "447479",
    "end": "450060"
  },
  {
    "text": "if you wanted to use xgboost these are",
    "start": "450060",
    "end": "452340"
  },
  {
    "text": "all options right you could use hugging",
    "start": "452340",
    "end": "453720"
  },
  {
    "text": "face to scale Transformers or natural",
    "start": "453720",
    "end": "456120"
  },
  {
    "text": "language processing you could use",
    "start": "456120",
    "end": "457860"
  },
  {
    "text": "scikit-learn there are a number of",
    "start": "457860",
    "end": "459599"
  },
  {
    "text": "different options there and Ray train",
    "start": "459599",
    "end": "461220"
  },
  {
    "text": "provides and Ray air provides plugable",
    "start": "461220",
    "end": "463440"
  },
  {
    "text": "interfaces for scaling the entire",
    "start": "463440",
    "end": "465419"
  },
  {
    "text": "machine learning ecosystem",
    "start": "465419",
    "end": "467160"
  },
  {
    "text": "okay and but for the purposes of this",
    "start": "467160",
    "end": "469740"
  },
  {
    "text": "demo we are showing how to scale pytorch",
    "start": "469740",
    "end": "472979"
  },
  {
    "text": "training",
    "start": "472979",
    "end": "474180"
  },
  {
    "text": "and the last thing I want to show is",
    "start": "474180",
    "end": "475620"
  },
  {
    "text": "hyper parameter tuning so again hyper",
    "start": "475620",
    "end": "478259"
  },
  {
    "text": "parameter tuning refers to training many",
    "start": "478259",
    "end": "480780"
  },
  {
    "text": "models so you can find the best one",
    "start": "480780",
    "end": "483300"
  },
  {
    "text": "we're going to create a tuner using Ray",
    "start": "483300",
    "end": "485039"
  },
  {
    "text": "tune and we're going to pass in uh the",
    "start": "485039",
    "end": "488460"
  },
  {
    "text": "trainer okay so again there are a few",
    "start": "488460",
    "end": "490199"
  },
  {
    "text": "more arguments I need to pass in but",
    "start": "490199",
    "end": "493319"
  },
  {
    "text": "what I want to emphasize here is that",
    "start": "493319",
    "end": "495300"
  },
  {
    "text": "and you know this is still just the",
    "start": "495300",
    "end": "497039"
  },
  {
    "text": "skeleton it's not actually going to run",
    "start": "497039",
    "end": "498419"
  },
  {
    "text": "yet but what we've done in about 23",
    "start": "498419",
    "end": "501840"
  },
  {
    "text": "lines of code is something that would",
    "start": "501840",
    "end": "503940"
  },
  {
    "text": "normally require three separate",
    "start": "503940",
    "end": "505860"
  },
  {
    "text": "distributed systems one for loading and",
    "start": "505860",
    "end": "509160"
  },
  {
    "text": "processing your data like spark one for",
    "start": "509160",
    "end": "511860"
  },
  {
    "text": "training and scaling training across a",
    "start": "511860",
    "end": "513659"
  },
  {
    "text": "bunch of gpus that could be distributed",
    "start": "513659",
    "end": "515399"
  },
  {
    "text": "tensorflow or horovod or a number of",
    "start": "515399",
    "end": "517740"
  },
  {
    "text": "different systems and a separate system",
    "start": "517740",
    "end": "520080"
  },
  {
    "text": "for hyper parameter tuning okay and the",
    "start": "520080",
    "end": "523140"
  },
  {
    "text": "fact that Ray provides common",
    "start": "523140",
    "end": "525000"
  },
  {
    "text": "infrastructure for scaling all of these",
    "start": "525000",
    "end": "527160"
  },
  {
    "text": "workloads means that I can implement",
    "start": "527160",
    "end": "529140"
  },
  {
    "text": "this in just a simple python application",
    "start": "529140",
    "end": "531779"
  },
  {
    "text": "in a handful of lines of code",
    "start": "531779",
    "end": "534480"
  },
  {
    "text": "so let's actually you know finish the",
    "start": "534480",
    "end": "537660"
  },
  {
    "text": "application and make this run",
    "start": "537660",
    "end": "539640"
  },
  {
    "text": "so in order to scale training we already",
    "start": "539640",
    "end": "542040"
  },
  {
    "text": "have our pytorch code I need to specify",
    "start": "542040",
    "end": "544260"
  },
  {
    "text": "how we want to scale so I'm going to",
    "start": "544260",
    "end": "546240"
  },
  {
    "text": "pass in a scaling config and",
    "start": "546240",
    "end": "549660"
  },
  {
    "text": "we're going to tell it to use four",
    "start": "549660",
    "end": "551700"
  },
  {
    "text": "different four gpus",
    "start": "551700",
    "end": "554899"
  },
  {
    "text": "okay so we could tell it to use 100 gpus",
    "start": "555480",
    "end": "557580"
  },
  {
    "text": "or whatever but for this demo we're",
    "start": "557580",
    "end": "559680"
  },
  {
    "text": "using four gpus each model is going to",
    "start": "559680",
    "end": "561660"
  },
  {
    "text": "use four gpus we're going to train a",
    "start": "561660",
    "end": "563160"
  },
  {
    "text": "bunch of models",
    "start": "563160",
    "end": "564540"
  },
  {
    "text": "we also have to tell it what data to",
    "start": "564540",
    "end": "566160"
  },
  {
    "text": "train on",
    "start": "566160",
    "end": "567240"
  },
  {
    "text": "so we're going to tell it to use for the",
    "start": "567240",
    "end": "569580"
  },
  {
    "text": "training data to use this process data",
    "start": "569580",
    "end": "572040"
  },
  {
    "text": "set that we defined above okay",
    "start": "572040",
    "end": "575720"
  },
  {
    "text": "and that's really all we have to do for",
    "start": "575720",
    "end": "577920"
  },
  {
    "text": "training I want to mention one more",
    "start": "577920",
    "end": "580279"
  },
  {
    "text": "optimization that you can do",
    "start": "580279",
    "end": "582660"
  },
  {
    "text": "which is that here we're doing things in",
    "start": "582660",
    "end": "585420"
  },
  {
    "text": "two stages first we're ingesting and",
    "start": "585420",
    "end": "587399"
  },
  {
    "text": "processing our data up at the top",
    "start": "587399",
    "end": "589500"
  },
  {
    "text": "and then we are training the model after",
    "start": "589500",
    "end": "592380"
  },
  {
    "text": "that",
    "start": "592380",
    "end": "593160"
  },
  {
    "text": "in practice it's often valuable as a",
    "start": "593160",
    "end": "596040"
  },
  {
    "text": "performance optimization to be able to",
    "start": "596040",
    "end": "598380"
  },
  {
    "text": "overlap these two stages so as the data",
    "start": "598380",
    "end": "601320"
  },
  {
    "text": "is coming in and being processed it's",
    "start": "601320",
    "end": "603480"
  },
  {
    "text": "being fed into training while the next",
    "start": "603480",
    "end": "605580"
  },
  {
    "text": "data is coming in and being processed",
    "start": "605580",
    "end": "607320"
  },
  {
    "text": "and that's an important performance",
    "start": "607320",
    "end": "608760"
  },
  {
    "text": "optimization",
    "start": "608760",
    "end": "609959"
  },
  {
    "text": "so and it's difficult to do without",
    "start": "609959",
    "end": "612120"
  },
  {
    "text": "having common infrastructure for both",
    "start": "612120",
    "end": "614100"
  },
  {
    "text": "data processing and training",
    "start": "614100",
    "end": "616080"
  },
  {
    "text": "so the way we can achieve that is by",
    "start": "616080",
    "end": "618959"
  },
  {
    "text": "passing a preprocessor uh into we'll",
    "start": "618959",
    "end": "621899"
  },
  {
    "text": "just pass the movie preprocessor Into",
    "start": "621899",
    "end": "624000"
  },
  {
    "text": "the trainer okay and then we don't need",
    "start": "624000",
    "end": "625560"
  },
  {
    "text": "to do the pre-processing up front",
    "start": "625560",
    "end": "626760"
  },
  {
    "text": "anymore so I can I can get rid of this",
    "start": "626760",
    "end": "628800"
  },
  {
    "text": "line",
    "start": "628800",
    "end": "629820"
  },
  {
    "text": "okay so now the two stages are being",
    "start": "629820",
    "end": "631980"
  },
  {
    "text": "overlapped",
    "start": "631980",
    "end": "633480"
  },
  {
    "text": "okay",
    "start": "633480",
    "end": "634440"
  },
  {
    "text": "so let's fill in the details for hyper",
    "start": "634440",
    "end": "636540"
  },
  {
    "text": "parameter tuning the only remaining",
    "start": "636540",
    "end": "638459"
  },
  {
    "text": "thing I need to show here is we need to",
    "start": "638459",
    "end": "642120"
  },
  {
    "text": "tell it what hyper parameters to search",
    "start": "642120",
    "end": "643860"
  },
  {
    "text": "over",
    "start": "643860",
    "end": "644880"
  },
  {
    "text": "so",
    "start": "644880",
    "end": "646200"
  },
  {
    "text": "we're going to configure the training",
    "start": "646200",
    "end": "647760"
  },
  {
    "text": "Loop",
    "start": "647760",
    "end": "648660"
  },
  {
    "text": "and",
    "start": "648660",
    "end": "649980"
  },
  {
    "text": "we're going to search over two different",
    "start": "649980",
    "end": "651660"
  },
  {
    "text": "hyper parameters the first is going to",
    "start": "651660",
    "end": "653760"
  },
  {
    "text": "be the learning rate we're going to use",
    "start": "653760",
    "end": "656279"
  },
  {
    "text": "Ray tune to do a grid search over a",
    "start": "656279",
    "end": "658440"
  },
  {
    "text": "couple possible values",
    "start": "658440",
    "end": "660600"
  },
  {
    "text": "and we're also going to use do a search",
    "start": "660600",
    "end": "662700"
  },
  {
    "text": "over the batch size for training so",
    "start": "662700",
    "end": "664980"
  },
  {
    "text": "again we're going to do a grid search",
    "start": "664980",
    "end": "668459"
  },
  {
    "text": "using two possible values 8 and 16. okay",
    "start": "668459",
    "end": "672060"
  },
  {
    "text": "so that's going to run to try out two",
    "start": "672060",
    "end": "675000"
  },
  {
    "text": "different values of two different hyper",
    "start": "675000",
    "end": "676560"
  },
  {
    "text": "parameters so we're going to do four",
    "start": "676560",
    "end": "677640"
  },
  {
    "text": "experiments in total so training four",
    "start": "677640",
    "end": "679500"
  },
  {
    "text": "models each on four gpus",
    "start": "679500",
    "end": "682680"
  },
  {
    "text": "and the last thing I have to run is to",
    "start": "682680",
    "end": "685320"
  },
  {
    "text": "say to actually just run it so I'll say",
    "start": "685320",
    "end": "688030"
  },
  {
    "text": "[Music]",
    "start": "688030",
    "end": "688560"
  },
  {
    "text": "um",
    "start": "688560",
    "end": "689360"
  },
  {
    "text": "tuner.fit to get the results and then we",
    "start": "689360",
    "end": "692940"
  },
  {
    "text": "have to save the results the best model",
    "start": "692940",
    "end": "694320"
  },
  {
    "text": "to a checkpoint and so the you know the",
    "start": "694320",
    "end": "696000"
  },
  {
    "text": "details of this line are not not super",
    "start": "696000",
    "end": "698220"
  },
  {
    "text": "important but we need to get the best",
    "start": "698220",
    "end": "699959"
  },
  {
    "text": "results",
    "start": "699959",
    "end": "701220"
  },
  {
    "text": "um we're getting the best results",
    "start": "701220",
    "end": "702120"
  },
  {
    "text": "according to the training loss metric",
    "start": "702120",
    "end": "703920"
  },
  {
    "text": "and we are using the uh getting the",
    "start": "703920",
    "end": "707339"
  },
  {
    "text": "model that minimizes the training loss",
    "start": "707339",
    "end": "708839"
  },
  {
    "text": "so then we find the checkpoints and we",
    "start": "708839",
    "end": "711180"
  },
  {
    "text": "store it to S3 so we're going to pass in",
    "start": "711180",
    "end": "713399"
  },
  {
    "text": "our checkpoint URL the checkpoint URL we",
    "start": "713399",
    "end": "715500"
  },
  {
    "text": "we defined at the top so the details of",
    "start": "715500",
    "end": "717420"
  },
  {
    "text": "this line don't matter we are just",
    "start": "717420",
    "end": "720060"
  },
  {
    "text": "um getting the best model and saving the",
    "start": "720060",
    "end": "722100"
  },
  {
    "text": "result in S3",
    "start": "722100",
    "end": "723959"
  },
  {
    "text": "so that actually completes the",
    "start": "723959",
    "end": "726240"
  },
  {
    "text": "application everything from data ingest",
    "start": "726240",
    "end": "728100"
  },
  {
    "text": "to pre-processing to training to hyper",
    "start": "728100",
    "end": "730740"
  },
  {
    "text": "parameter tuning okay and so now let's",
    "start": "730740",
    "end": "733980"
  },
  {
    "text": "actually run it",
    "start": "733980",
    "end": "735779"
  },
  {
    "text": "all right so I'm going to open up a",
    "start": "735779",
    "end": "737040"
  },
  {
    "text": "terminal",
    "start": "737040",
    "end": "739260"
  },
  {
    "text": "line 15 is incorrect yeah okay so I have",
    "start": "739260",
    "end": "741779"
  },
  {
    "text": "a bug here",
    "start": "741779",
    "end": "743399"
  },
  {
    "text": "um well let's just let's just keep that",
    "start": "743399",
    "end": "745079"
  },
  {
    "text": "anyway",
    "start": "745079",
    "end": "746519"
  },
  {
    "text": "um and and run pythontrain.pi because",
    "start": "746519",
    "end": "749880"
  },
  {
    "text": "then I can show you what the debugging",
    "start": "749880",
    "end": "751200"
  },
  {
    "text": "experience looks like",
    "start": "751200",
    "end": "752940"
  },
  {
    "text": "um so",
    "start": "752940",
    "end": "754260"
  },
  {
    "text": "we are um thanks for pointing that out",
    "start": "754260",
    "end": "757800"
  },
  {
    "text": "um",
    "start": "757800",
    "end": "758459"
  },
  {
    "text": "so it's telling us the error that the",
    "start": "758459",
    "end": "760860"
  },
  {
    "text": "audience was calling out so this process",
    "start": "760860",
    "end": "762480"
  },
  {
    "text": "data set",
    "start": "762480",
    "end": "763800"
  },
  {
    "text": "um is still you know we we deleted that",
    "start": "763800",
    "end": "766440"
  },
  {
    "text": "variable",
    "start": "766440",
    "end": "767519"
  },
  {
    "text": "um so we're going to to remove the we're",
    "start": "767519",
    "end": "770399"
  },
  {
    "text": "going to just use the regular data set",
    "start": "770399",
    "end": "771959"
  },
  {
    "text": "okay and re-save that and run it again",
    "start": "771959",
    "end": "774480"
  },
  {
    "text": "so",
    "start": "774480",
    "end": "775920"
  },
  {
    "text": "um actually the you know the interesting",
    "start": "775920",
    "end": "777600"
  },
  {
    "text": "thing to point out there is that the",
    "start": "777600",
    "end": "779760"
  },
  {
    "text": "flow that we're going through right now",
    "start": "779760",
    "end": "781139"
  },
  {
    "text": "right editing our code running the",
    "start": "781139",
    "end": "783600"
  },
  {
    "text": "application seeing the bug",
    "start": "783600",
    "end": "786120"
  },
  {
    "text": "um rerun it you know fixing the bug and",
    "start": "786120",
    "end": "787500"
  },
  {
    "text": "then re-running it it feels very much",
    "start": "787500",
    "end": "789060"
  },
  {
    "text": "like how you would develop on your",
    "start": "789060",
    "end": "790920"
  },
  {
    "text": "laptop",
    "start": "790920",
    "end": "792060"
  },
  {
    "text": "but the difference is that we are",
    "start": "792060",
    "end": "793740"
  },
  {
    "text": "developing and debugging at scale right",
    "start": "793740",
    "end": "795959"
  },
  {
    "text": "on thousands of CPU cores tons of gpus",
    "start": "795959",
    "end": "799260"
  },
  {
    "text": "and but with the developer velocity or",
    "start": "799260",
    "end": "802440"
  },
  {
    "text": "the productivity that you might expect",
    "start": "802440",
    "end": "803760"
  },
  {
    "text": "on your laptop",
    "start": "803760",
    "end": "805560"
  },
  {
    "text": "Okay so",
    "start": "805560",
    "end": "807660"
  },
  {
    "text": "while that's running I'm going to show",
    "start": "807660",
    "end": "809940"
  },
  {
    "text": "the next part of the application that",
    "start": "809940",
    "end": "811800"
  },
  {
    "text": "we're going to uh you know to show so we",
    "start": "811800",
    "end": "814800"
  },
  {
    "text": "just built everything from data ingest",
    "start": "814800",
    "end": "816360"
  },
  {
    "text": "to training to hyper parameter tuning",
    "start": "816360",
    "end": "819120"
  },
  {
    "text": "the next part so that's producing this",
    "start": "819120",
    "end": "821220"
  },
  {
    "text": "Pi torch model and the next thing we",
    "start": "821220",
    "end": "823200"
  },
  {
    "text": "want to do is to actually take that",
    "start": "823200",
    "end": "824940"
  },
  {
    "text": "model and deploy it in production and",
    "start": "824940",
    "end": "827579"
  },
  {
    "text": "then show the actual web application",
    "start": "827579",
    "end": "829800"
  },
  {
    "text": "powered by that uh you know by that",
    "start": "829800",
    "end": "832139"
  },
  {
    "text": "model",
    "start": "832139",
    "end": "833040"
  },
  {
    "text": "okay so for the next part",
    "start": "833040",
    "end": "835740"
  },
  {
    "text": "um I'm not actually going to I'm just",
    "start": "835740",
    "end": "838079"
  },
  {
    "text": "going to walk through the code I'm not",
    "start": "838079",
    "end": "839220"
  },
  {
    "text": "actually going to implement it this time",
    "start": "839220",
    "end": "840540"
  },
  {
    "text": "but um",
    "start": "840540",
    "end": "842700"
  },
  {
    "text": "looking at let's see looking at the code",
    "start": "842700",
    "end": "844560"
  },
  {
    "text": "here we have",
    "start": "844560",
    "end": "846600"
  },
  {
    "text": "so there's some code below for creating",
    "start": "846600",
    "end": "848160"
  },
  {
    "text": "the UI I just want to focus on on the uh",
    "start": "848160",
    "end": "851459"
  },
  {
    "text": "the code at the top so this is using",
    "start": "851459",
    "end": "853079"
  },
  {
    "text": "race serve which is one of the ray air",
    "start": "853079",
    "end": "855060"
  },
  {
    "text": "libraries for model deployment we're",
    "start": "855060",
    "end": "857700"
  },
  {
    "text": "starting race serve",
    "start": "857700",
    "end": "859320"
  },
  {
    "text": "we're creating a race serve deployments",
    "start": "859320",
    "end": "861720"
  },
  {
    "text": "and we are specifying a number of",
    "start": "861720",
    "end": "864480"
  },
  {
    "text": "replicas so here we're doing two",
    "start": "864480",
    "end": "865740"
  },
  {
    "text": "replicas but if you were serving a lot",
    "start": "865740",
    "end": "868740"
  },
  {
    "text": "of traffic then you would you would use",
    "start": "868740",
    "end": "870540"
  },
  {
    "text": "more replicas",
    "start": "870540",
    "end": "871860"
  },
  {
    "text": "and then we are deploying the model and",
    "start": "871860",
    "end": "874620"
  },
  {
    "text": "we're telling it to load the model from",
    "start": "874620",
    "end": "876600"
  },
  {
    "text": "the checkpoint where we we just saved",
    "start": "876600",
    "end": "878519"
  },
  {
    "text": "the trained model in the in the previous",
    "start": "878519",
    "end": "880320"
  },
  {
    "text": "uh section",
    "start": "880320",
    "end": "882180"
  },
  {
    "text": "okay so training has finished now it was",
    "start": "882180",
    "end": "884880"
  },
  {
    "text": "just a short run because we want to",
    "start": "884880",
    "end": "886199"
  },
  {
    "text": "actually uh because it's a short demo",
    "start": "886199",
    "end": "887760"
  },
  {
    "text": "and we want to have it run in time so",
    "start": "887760",
    "end": "889980"
  },
  {
    "text": "now I'm going to run Python deploy.pi",
    "start": "889980",
    "end": "892680"
  },
  {
    "text": "and I know this is at the bottom of the",
    "start": "892680",
    "end": "894120"
  },
  {
    "text": "screen so it's not easy for everyone to",
    "start": "894120",
    "end": "896040"
  },
  {
    "text": "see but I'm running that over here",
    "start": "896040",
    "end": "898740"
  },
  {
    "text": "and by the way this terminal lives uh",
    "start": "898740",
    "end": "901980"
  },
  {
    "text": "I'm running vs code on my laptop but the",
    "start": "901980",
    "end": "904440"
  },
  {
    "text": "terminal is really in the cloud it's",
    "start": "904440",
    "end": "905880"
  },
  {
    "text": "connected via remote SSH so everything",
    "start": "905880",
    "end": "907680"
  },
  {
    "text": "we're doing the code the terminal",
    "start": "907680",
    "end": "910500"
  },
  {
    "text": "um are on any scale",
    "start": "910500",
    "end": "912779"
  },
  {
    "text": "so this just printed out two things it",
    "start": "912779",
    "end": "914699"
  },
  {
    "text": "printed out a URL for us to look at",
    "start": "914699",
    "end": "916980"
  },
  {
    "text": "metrics",
    "start": "916980",
    "end": "918060"
  },
  {
    "text": "so I'm going to go back to",
    "start": "918060",
    "end": "920160"
  },
  {
    "text": "um",
    "start": "920160",
    "end": "921180"
  },
  {
    "text": "the uh any scale UI and just go to this",
    "start": "921180",
    "end": "924360"
  },
  {
    "text": "URL and show grafana okay nothing's",
    "start": "924360",
    "end": "926699"
  },
  {
    "text": "happening yet because",
    "start": "926699",
    "end": "928500"
  },
  {
    "text": "um because we haven't started querying",
    "start": "928500",
    "end": "930240"
  },
  {
    "text": "the model yet but I'll tell it to update",
    "start": "930240",
    "end": "931860"
  },
  {
    "text": "every every five seconds so we can once",
    "start": "931860",
    "end": "933839"
  },
  {
    "text": "we start querying the model we'll see",
    "start": "933839",
    "end": "935519"
  },
  {
    "text": "some activity here",
    "start": "935519",
    "end": "938279"
  },
  {
    "text": "um the other URL that was printed out",
    "start": "938279",
    "end": "940139"
  },
  {
    "text": "was the actual movie recommendation",
    "start": "940139",
    "end": "942000"
  },
  {
    "text": "website that we're going to go to to get",
    "start": "942000",
    "end": "944459"
  },
  {
    "text": "movie recommendations and which we'll",
    "start": "944459",
    "end": "945899"
  },
  {
    "text": "talk to the uh you know to the model",
    "start": "945899",
    "end": "948540"
  },
  {
    "text": "that we just deployed to actually get",
    "start": "948540",
    "end": "949920"
  },
  {
    "text": "the recommendations",
    "start": "949920",
    "end": "952199"
  },
  {
    "text": "so I'm going to open up that URL and",
    "start": "952199",
    "end": "954720"
  },
  {
    "text": "this is showing you know it's a simple",
    "start": "954720",
    "end": "956820"
  },
  {
    "text": "web app We Built For This demo showing",
    "start": "956820",
    "end": "958860"
  },
  {
    "text": "different movies that you might want to",
    "start": "958860",
    "end": "960660"
  },
  {
    "text": "watch and we can tell it a little bit",
    "start": "960660",
    "end": "963000"
  },
  {
    "text": "about ourselves so as we tell it more",
    "start": "963000",
    "end": "965100"
  },
  {
    "text": "about our interests or things we like it",
    "start": "965100",
    "end": "968220"
  },
  {
    "text": "will query the model with those values",
    "start": "968220",
    "end": "970440"
  },
  {
    "text": "and and produce recommendations for us",
    "start": "970440",
    "end": "972540"
  },
  {
    "text": "so if I tell it that I'm interested in",
    "start": "972540",
    "end": "974220"
  },
  {
    "text": "sports for instance I might see movies",
    "start": "974220",
    "end": "976560"
  },
  {
    "text": "about basketball right or if I tell it",
    "start": "976560",
    "end": "978720"
  },
  {
    "text": "that I'm interested in action then I may",
    "start": "978720",
    "end": "981899"
  },
  {
    "text": "see",
    "start": "981899",
    "end": "983160"
  },
  {
    "text": "um you know start to see some action",
    "start": "983160",
    "end": "984420"
  },
  {
    "text": "movies Okay",
    "start": "984420",
    "end": "986279"
  },
  {
    "text": "um or you know perhaps I'm interested in",
    "start": "986279",
    "end": "988440"
  },
  {
    "text": "in uh animals right and then there might",
    "start": "988440",
    "end": "991380"
  },
  {
    "text": "be movies about about uh killer whales",
    "start": "991380",
    "end": "994199"
  },
  {
    "text": "and stuff like that",
    "start": "994199",
    "end": "995399"
  },
  {
    "text": "so",
    "start": "995399",
    "end": "996420"
  },
  {
    "text": "the point is uh if we go back to grafana",
    "start": "996420",
    "end": "999060"
  },
  {
    "text": "now you can see that the queries per",
    "start": "999060",
    "end": "1001040"
  },
  {
    "text": "second has increased right and this is",
    "start": "1001040",
    "end": "1002540"
  },
  {
    "text": "it's at a relatively coarse granularity",
    "start": "1002540",
    "end": "1004459"
  },
  {
    "text": "but um over time if we if we wait a",
    "start": "1004459",
    "end": "1007639"
  },
  {
    "text": "little bile uh then that will level off",
    "start": "1007639",
    "end": "1009440"
  },
  {
    "text": "because we're no longer querying the",
    "start": "1009440",
    "end": "1010759"
  },
  {
    "text": "model but the point is to see that this",
    "start": "1010759",
    "end": "1013040"
  },
  {
    "text": "is the the model is being queried it's",
    "start": "1013040",
    "end": "1015139"
  },
  {
    "text": "running in production we can we can sort",
    "start": "1015139",
    "end": "1017180"
  },
  {
    "text": "of track how it's doing",
    "start": "1017180",
    "end": "1019699"
  },
  {
    "text": "okay so what we just showed was how to",
    "start": "1019699",
    "end": "1022459"
  },
  {
    "text": "take the model we trained deploy it and",
    "start": "1022459",
    "end": "1025220"
  },
  {
    "text": "use it to actually power",
    "start": "1025220",
    "end": "1026449"
  },
  {
    "text": "[Music]",
    "start": "1026450",
    "end": "1026959"
  },
  {
    "text": "um",
    "start": "1026959",
    "end": "1027740"
  },
  {
    "text": "power our application",
    "start": "1027740",
    "end": "1029780"
  },
  {
    "text": "so the last thing I want to show is",
    "start": "1029780",
    "end": "1031760"
  },
  {
    "text": "closing the loop with continuous",
    "start": "1031760",
    "end": "1033740"
  },
  {
    "text": "retraining as new data comes in how can",
    "start": "1033740",
    "end": "1036980"
  },
  {
    "text": "we update and retrain our models and the",
    "start": "1036980",
    "end": "1039558"
  },
  {
    "text": "reason you would want to do this is that",
    "start": "1039559",
    "end": "1040880"
  },
  {
    "text": "a lot of companies have seen for",
    "start": "1040880",
    "end": "1042500"
  },
  {
    "text": "recommendation systems that as the world",
    "start": "1042500",
    "end": "1045020"
  },
  {
    "text": "changes around you the you know your",
    "start": "1045020",
    "end": "1047839"
  },
  {
    "text": "recommendation performance gets worse",
    "start": "1047839",
    "end": "1049700"
  },
  {
    "text": "over time and as and so being able to",
    "start": "1049700",
    "end": "1052580"
  },
  {
    "text": "train and update your recommendation",
    "start": "1052580",
    "end": "1053960"
  },
  {
    "text": "models on the latest data can lead to",
    "start": "1053960",
    "end": "1056840"
  },
  {
    "text": "improved recommendations and more",
    "start": "1056840",
    "end": "1058340"
  },
  {
    "text": "relevant recommendations",
    "start": "1058340",
    "end": "1060740"
  },
  {
    "text": "um so there are two parts to this one is",
    "start": "1060740",
    "end": "1063020"
  },
  {
    "text": "we're going to need some kind of trigger",
    "start": "1063020",
    "end": "1064580"
  },
  {
    "text": "for the retraining whether it is a timer",
    "start": "1064580",
    "end": "1066620"
  },
  {
    "text": "right retrain every one hour or one",
    "start": "1066620",
    "end": "1068780"
  },
  {
    "text": "minute uh or something that our model",
    "start": "1068780",
    "end": "1071360"
  },
  {
    "text": "model monitoring system is telling us as",
    "start": "1071360",
    "end": "1073280"
  },
  {
    "text": "model performance degrades kickoff",
    "start": "1073280",
    "end": "1075500"
  },
  {
    "text": "retraining",
    "start": "1075500",
    "end": "1076700"
  },
  {
    "text": "the other thing we'll need is we don't",
    "start": "1076700",
    "end": "1078740"
  },
  {
    "text": "want to when we do retraining we don't",
    "start": "1078740",
    "end": "1081679"
  },
  {
    "text": "necessarily want to start over from",
    "start": "1081679",
    "end": "1083179"
  },
  {
    "text": "scratch and train from the beginning we",
    "start": "1083179",
    "end": "1085280"
  },
  {
    "text": "often want to pick up where we left off",
    "start": "1085280",
    "end": "1087080"
  },
  {
    "text": "with our previously trained model so",
    "start": "1087080",
    "end": "1089299"
  },
  {
    "text": "we're going to need to resume from a",
    "start": "1089299",
    "end": "1090620"
  },
  {
    "text": "checkpoint",
    "start": "1090620",
    "end": "1091580"
  },
  {
    "text": "so let me show both of those things",
    "start": "1091580",
    "end": "1093919"
  },
  {
    "text": "so",
    "start": "1093919",
    "end": "1095299"
  },
  {
    "text": "um for resuming from a checkpoint",
    "start": "1095299",
    "end": "1098919"
  },
  {
    "text": "we only have to change one line of code",
    "start": "1098960",
    "end": "1101240"
  },
  {
    "text": "we have to change the trainer",
    "start": "1101240",
    "end": "1103280"
  },
  {
    "text": "to tell it to resume from a checkpoint",
    "start": "1103280",
    "end": "1107240"
  },
  {
    "text": "and we're going to tell it to get uh get",
    "start": "1107240",
    "end": "1109460"
  },
  {
    "text": "the checkpoint from",
    "start": "1109460",
    "end": "1111980"
  },
  {
    "text": "the URL that we where we stored our our",
    "start": "1111980",
    "end": "1114140"
  },
  {
    "text": "model Okay so",
    "start": "1114140",
    "end": "1115880"
  },
  {
    "text": "using Ray air to get the to read the",
    "start": "1115880",
    "end": "1118340"
  },
  {
    "text": "checkpoint from S3 this is the same URL",
    "start": "1118340",
    "end": "1120020"
  },
  {
    "text": "where we're storing the checkpoint and",
    "start": "1120020",
    "end": "1121880"
  },
  {
    "text": "we're going to pick up training where we",
    "start": "1121880",
    "end": "1123020"
  },
  {
    "text": "left off using the the current best",
    "start": "1123020",
    "end": "1124940"
  },
  {
    "text": "model",
    "start": "1124940",
    "end": "1126020"
  },
  {
    "text": "okay that's the only line we need to",
    "start": "1126020",
    "end": "1127700"
  },
  {
    "text": "change to make that happen",
    "start": "1127700",
    "end": "1130039"
  },
  {
    "text": "and the next part we've mentioned is",
    "start": "1130039",
    "end": "1132200"
  },
  {
    "text": "some kind of trigger for uh kicking off",
    "start": "1132200",
    "end": "1135080"
  },
  {
    "text": "retraining and I'll show any scale",
    "start": "1135080",
    "end": "1137179"
  },
  {
    "text": "scheduled jobs for how you can do that",
    "start": "1137179",
    "end": "1139940"
  },
  {
    "text": "okay so going back to so you can see",
    "start": "1139940",
    "end": "1141679"
  },
  {
    "text": "from grafana nobody's querying the model",
    "start": "1141679",
    "end": "1143780"
  },
  {
    "text": "anymore",
    "start": "1143780",
    "end": "1145280"
  },
  {
    "text": "um and if we go to the any scale UI it's",
    "start": "1145280",
    "end": "1147559"
  },
  {
    "text": "just a simple feature for running this",
    "start": "1147559",
    "end": "1149480"
  },
  {
    "text": "as a scheduled job we can call it um you",
    "start": "1149480",
    "end": "1152360"
  },
  {
    "text": "know our retraining job",
    "start": "1152360",
    "end": "1154400"
  },
  {
    "text": "and we can tell it to run",
    "start": "1154400",
    "end": "1156400"
  },
  {
    "text": "pythontrain.pi so train.pi is our",
    "start": "1156400",
    "end": "1158600"
  },
  {
    "text": "training application",
    "start": "1158600",
    "end": "1160100"
  },
  {
    "text": "and we can have it do that once every",
    "start": "1160100",
    "end": "1162860"
  },
  {
    "text": "hour for instance okay so we're going to",
    "start": "1162860",
    "end": "1165559"
  },
  {
    "text": "submit that and that's all there is to",
    "start": "1165559",
    "end": "1167660"
  },
  {
    "text": "it now we are doing every hour We're",
    "start": "1167660",
    "end": "1170919"
  },
  {
    "text": "redoing training with the latest data",
    "start": "1170919",
    "end": "1173600"
  },
  {
    "text": "updating the model and saving the",
    "start": "1173600",
    "end": "1175700"
  },
  {
    "text": "updated model",
    "start": "1175700",
    "end": "1177500"
  },
  {
    "text": "so just to recap everything we've seen",
    "start": "1177500",
    "end": "1180980"
  },
  {
    "text": "we've demoed Ray air how to use Ray air",
    "start": "1180980",
    "end": "1184340"
  },
  {
    "text": "to scale everything from data ingest to",
    "start": "1184340",
    "end": "1187400"
  },
  {
    "text": "deep learning training on gpus to hyper",
    "start": "1187400",
    "end": "1189799"
  },
  {
    "text": "parameter search to model deployments",
    "start": "1189799",
    "end": "1191840"
  },
  {
    "text": "and then continuous retraining and",
    "start": "1191840",
    "end": "1194419"
  },
  {
    "text": "hopefully you can see the advantage you",
    "start": "1194419",
    "end": "1196039"
  },
  {
    "text": "know we were able to do this in around",
    "start": "1196039",
    "end": "1197480"
  },
  {
    "text": "30 to 50 lines of code of course it's a",
    "start": "1197480",
    "end": "1200120"
  },
  {
    "text": "you know it's a toy example you would",
    "start": "1200120",
    "end": "1201799"
  },
  {
    "text": "the the real world thing would be much",
    "start": "1201799",
    "end": "1203480"
  },
  {
    "text": "more complex but this can give you a",
    "start": "1203480",
    "end": "1206240"
  },
  {
    "text": "taste of what you can accomplish with",
    "start": "1206240",
    "end": "1208100"
  },
  {
    "text": "Ray air",
    "start": "1208100",
    "end": "1209419"
  },
  {
    "text": "the second thing we showed was how to",
    "start": "1209419",
    "end": "1211580"
  },
  {
    "text": "use any scale how to use workspaces for",
    "start": "1211580",
    "end": "1214220"
  },
  {
    "text": "interactive development and debugging at",
    "start": "1214220",
    "end": "1217220"
  },
  {
    "text": "scale how to deploy Production Services",
    "start": "1217220",
    "end": "1219620"
  },
  {
    "text": "and do monitoring and how to use",
    "start": "1219620",
    "end": "1222200"
  },
  {
    "text": "schedule jobs for continuous retraining",
    "start": "1222200",
    "end": "1225200"
  },
  {
    "text": "so if you're interested in learning more",
    "start": "1225200",
    "end": "1226940"
  },
  {
    "text": "we'll be demoing these in much more",
    "start": "1226940",
    "end": "1228620"
  },
  {
    "text": "depth at the any scale Booth throughout",
    "start": "1228620",
    "end": "1230600"
  },
  {
    "text": "the conference and there will be more",
    "start": "1230600",
    "end": "1232640"
  },
  {
    "text": "deep Dives and talks on each of these",
    "start": "1232640",
    "end": "1234679"
  },
  {
    "text": "topics so thank you so much that",
    "start": "1234679",
    "end": "1237740"
  },
  {
    "text": "concludes the demo and next up I'd like",
    "start": "1237740",
    "end": "1241160"
  },
  {
    "text": "to welcome Greg Brockman to the stage",
    "start": "1241160",
    "end": "1243500"
  },
  {
    "text": "we'll be he'll be talking with us Greg",
    "start": "1243500",
    "end": "1245600"
  },
  {
    "text": "Brockman is the former CTO at stripe and",
    "start": "1245600",
    "end": "1248840"
  },
  {
    "text": "one of the co-founders and president of",
    "start": "1248840",
    "end": "1250460"
  },
  {
    "text": "openai so openai does the most Cutting",
    "start": "1250460",
    "end": "1252919"
  },
  {
    "text": "Edge work out there in Ai and he'll be",
    "start": "1252919",
    "end": "1255200"
  },
  {
    "text": "talking to us about Ai and",
    "start": "1255200",
    "end": "1257539"
  },
  {
    "text": "infrastructure at openai so welcome Greg",
    "start": "1257539",
    "end": "1262460"
  },
  {
    "text": "foreign",
    "start": "1262460",
    "end": "1265460"
  }
]
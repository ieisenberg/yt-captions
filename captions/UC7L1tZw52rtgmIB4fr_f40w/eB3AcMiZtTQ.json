[
  {
    "start": "0",
    "end": "19000"
  },
  {
    "text": "i'm a member of the rlo team yeah nice to meet you so i'm eddie um",
    "start": "1040",
    "end": "8400"
  },
  {
    "text": "i'm actually working using ray for our own application uh and for the reinforcement learning problem",
    "start": "8400",
    "end": "15759"
  },
  {
    "text": "so the first thing um the first thing and that i wanted to ask is you know there are two ways to",
    "start": "15759",
    "end": "22800"
  },
  {
    "start": "19000",
    "end": "63000"
  },
  {
    "text": "train a model in ray one is using the ray trainer and the other one is raytune",
    "start": "22800",
    "end": "29519"
  },
  {
    "text": "yeah okay yeah so i wanted to uh you know have a replicable model that",
    "start": "29519",
    "end": "36320"
  },
  {
    "text": "i can you know like the one that we set the seed number and",
    "start": "36320",
    "end": "41440"
  },
  {
    "text": "we are able to achieve the exact same result so i was able to achieve the exact same",
    "start": "41440",
    "end": "46800"
  },
  {
    "text": "result with while using great tune but once i use ray trainer i",
    "start": "46800",
    "end": "53039"
  },
  {
    "text": "um you know get different results and any time that i use it actually i get uh",
    "start": "53039",
    "end": "58480"
  },
  {
    "text": "different results so that was my first question sure okay i can i can i guess yeah so",
    "start": "58480",
    "end": "64960"
  },
  {
    "start": "63000",
    "end": "289000"
  },
  {
    "text": "we offer the standalone api which you've used and you've also used like the way in which you tune models via ray",
    "start": "64960",
    "end": "71200"
  },
  {
    "text": "tune truthfully because of the distributed nature of rey it's actually not quite fully seed reproducible",
    "start": "71200",
    "end": "77600"
  },
  {
    "text": "unfortunately yeah it's something that we've been trying to tackle ourselves but like unfortunately",
    "start": "77600",
    "end": "84240"
  },
  {
    "text": "with some of the algorithms um you can't get seed reproducibility so so which algorithm are you using first of",
    "start": "84240",
    "end": "90159"
  },
  {
    "text": "all so we're using sac i'm with uh it's",
    "start": "90159",
    "end": "95920"
  },
  {
    "text": "sac it's soft active yeah okay um",
    "start": "96079",
    "end": "102399"
  },
  {
    "text": "yeah tru truthfully like the we we do have like a seed reproducibility bug right now which like",
    "start": "102399",
    "end": "107840"
  },
  {
    "text": "we have enabled we haven't been able to exactly pin down where it is uh",
    "start": "107840",
    "end": "113520"
  },
  {
    "text": "we spend quite a bit of time trying to find it so we can't really put more time into it at the moment",
    "start": "113520",
    "end": "120399"
  },
  {
    "text": "yeah uh do you recommend the best way to use it right now the more stable",
    "start": "120399",
    "end": "126079"
  },
  {
    "text": "way of using gray for the purpose of model training in reinforcement learning is it through the trainer or to the",
    "start": "126079",
    "end": "132720"
  },
  {
    "text": "through the radio our team would almost always prefer that you use ray tune wrapping",
    "start": "132720",
    "end": "138879"
  },
  {
    "text": "wrapping your experiment yeah just because there are so many benefits that you get from it",
    "start": "138879",
    "end": "144480"
  },
  {
    "text": "okay i see uh the other question is about the the production side so let's say",
    "start": "144480",
    "end": "151599"
  },
  {
    "text": "we train a model for the purpose of reinforcement learning and then we want to use it",
    "start": "151599",
    "end": "157680"
  },
  {
    "text": "during the production time so let's say specifically about this sac algorithm what is the best way to to use it for",
    "start": "157680",
    "end": "164239"
  },
  {
    "text": "the production is it just to there is a config you know parameter which is exploration so we",
    "start": "164239",
    "end": "171280"
  },
  {
    "text": "know we can turn it off and it it just takes informative decision and then we",
    "start": "171280",
    "end": "176400"
  },
  {
    "text": "just do the same thing ray.train or tune that",
    "start": "176400",
    "end": "181440"
  },
  {
    "text": "is it the only way to to do it for the purpose of production or there's another sort of method",
    "start": "181599",
    "end": "186640"
  },
  {
    "text": "uh yeah so the first thing is like there is a way to like essentially like after you do a radar",
    "start": "186640",
    "end": "192400"
  },
  {
    "text": "tune like a ray tune dot run call like uh your whole experiment will be collected like",
    "start": "192400",
    "end": "198480"
  },
  {
    "text": "there's a checkpoint file which like you can find under uh if you haven't changed like your array results directory you'll",
    "start": "198480",
    "end": "204159"
  },
  {
    "text": "be found under like home results yeah so then",
    "start": "204159",
    "end": "209360"
  },
  {
    "text": "there's examples in the repo which i'm going to share with you right now that show you like you can",
    "start": "209360",
    "end": "215920"
  },
  {
    "text": "on you can you can restore it you can restore your entire experiment from checkpoint and then change like say the",
    "start": "215920",
    "end": "221280"
  },
  {
    "text": "configuration of it so that exploration is disabled and then once you've",
    "start": "221280",
    "end": "226720"
  },
  {
    "text": "restored the entire experiment you can get the policy you can recover the policy from your experiment",
    "start": "226720",
    "end": "232400"
  },
  {
    "text": "and that policy you can call functions like compute actions on it and so i",
    "start": "232400",
    "end": "237840"
  },
  {
    "text": "would say like that that's probably the best way right now",
    "start": "237840",
    "end": "242959"
  },
  {
    "text": "now um we do have like a model serving library called reserve and",
    "start": "242959",
    "end": "248000"
  },
  {
    "text": "we're in the process of like building a tighter integration with it so you can like directly go and use your",
    "start": "248000",
    "end": "254640"
  },
  {
    "text": "model with reserve oh that's awesome yeah it's like we're we're close to",
    "start": "254640",
    "end": "262000"
  },
  {
    "text": "getting it done but like we uh yeah we're close to getting it done but like we haven't really exactly had the",
    "start": "262000",
    "end": "267360"
  },
  {
    "text": "bandwidth to get it done yeah so apologies for that but like i could see so ray2 ray 2.0 you",
    "start": "267360",
    "end": "273680"
  },
  {
    "text": "guys will see by the end of august and i can see that coming in 2.1 which would be sometime in september but now like in",
    "start": "273680",
    "end": "279520"
  },
  {
    "text": "the meantime to get you guys unblocked i'm going to share this uh scripted to you guys let's say there you go",
    "start": "279520",
    "end": "285840"
  },
  {
    "text": "yeah sebastian did you have some questions about uh uh",
    "start": "285840",
    "end": "291199"
  },
  {
    "start": "289000",
    "end": "543000"
  },
  {
    "text": "mostly so my questions again sac so uh i'm in the same team as media working on the",
    "start": "291759",
    "end": "297120"
  },
  {
    "text": "same agent and uh i've been so we have a",
    "start": "297120",
    "end": "302320"
  },
  {
    "text": "a 5d uh our sac agent has a 5d action space and",
    "start": "302320",
    "end": "308840"
  },
  {
    "text": "a uh 19d uh observation space",
    "start": "308840",
    "end": "314000"
  },
  {
    "text": "okay uh both are normalized so actions uh go from negative one to one and",
    "start": "314000",
    "end": "319759"
  },
  {
    "text": "observations because they have a varying scale uh they go from negative one to one",
    "start": "319759",
    "end": "326080"
  },
  {
    "text": "and um i was wondering mainly during the reward function i know sccs and rl agents in",
    "start": "326080",
    "end": "332560"
  },
  {
    "text": "general like to have a continuous uh reward function they like something",
    "start": "332560",
    "end": "337680"
  },
  {
    "text": "with a nice gradient and so what i was wondering about is the scale like what should be like the maximum",
    "start": "337680",
    "end": "343440"
  },
  {
    "text": "reward points that my uh yes this is a great question okay yeah so this one actually i can answer",
    "start": "343440",
    "end": "349039"
  },
  {
    "text": "because i've written a lot of reward functions before um yeah okay in order to like get oh okay",
    "start": "349039",
    "end": "356000"
  },
  {
    "text": "i'm gonna have to get a little bit more knowledge here and i know you guys are probably working on something that you don't really want to share",
    "start": "356000",
    "end": "361840"
  },
  {
    "text": "so like stop me whenever like you feel for youtube like i i sort of need to get an understanding",
    "start": "361840",
    "end": "367440"
  },
  {
    "text": "of like what tasks you guys are trying to solve so there's a vehicle",
    "start": "367440",
    "end": "372560"
  },
  {
    "text": "and we're trying to get it to travel in a straight line as fast as possible",
    "start": "372560",
    "end": "379360"
  },
  {
    "text": "okay and the way i reward it uh i guess if you want more uh details and reward",
    "start": "379360",
    "end": "385680"
  },
  {
    "text": "function is uh i look at its relative angle to the course and if it's",
    "start": "385680",
    "end": "391520"
  },
  {
    "text": "within threshold then i give it points and then i look at",
    "start": "391520",
    "end": "398880"
  },
  {
    "text": "another state variable of said vehicle and i give it uh points and the reward",
    "start": "399120",
    "end": "404160"
  },
  {
    "text": "function i'm sorry the reward shape uh if you can picture it's kind of like a",
    "start": "404160",
    "end": "409280"
  },
  {
    "text": "it's a gaussian but with the top uh made into a plateau so that we don't bias it to a certain angle or uh other state",
    "start": "409280",
    "end": "416160"
  },
  {
    "text": "variable it's okay is if it's plateaued is there",
    "start": "416160",
    "end": "422639"
  },
  {
    "text": "it's uh yeah the one i'm working on is exponential uh",
    "start": "422639",
    "end": "428240"
  },
  {
    "text": "so exponential side so it's like a gaussian but you know take off the top uh and the the maximum height of that",
    "start": "428240",
    "end": "434960"
  },
  {
    "text": "plateau is say uh two points for my two uh reward functions that have that uh",
    "start": "434960",
    "end": "440800"
  },
  {
    "text": "flat gaussian got yeah okay and then what what does",
    "start": "440800",
    "end": "446479"
  },
  {
    "text": "what's like the peak of like what is the scale of the peak of the gaussian what's the maximum reward",
    "start": "446479",
    "end": "453039"
  },
  {
    "text": "is uh two for both and i add them so uh if my agent uh for in for an immediate",
    "start": "453039",
    "end": "459440"
  },
  {
    "text": "reward if it nails both those state variables then it's gonna get four points",
    "start": "459440",
    "end": "464720"
  },
  {
    "text": "i see okay so if it if it's going fast and it's within like the correct",
    "start": "464720",
    "end": "469759"
  },
  {
    "text": "steering angle or the correct angle angle with respect to the track well you know the okay so this is the scale you",
    "start": "469759",
    "end": "475440"
  },
  {
    "text": "can immediately report maybe it's it's important to consider the intermediate reward piece that we have so",
    "start": "475440",
    "end": "481840"
  },
  {
    "text": "let's say we we give it a huge number of points once it reaches a",
    "start": "481840",
    "end": "487039"
  },
  {
    "text": "certain you know it passed a certain level during the course of moving so let's say",
    "start": "487039",
    "end": "492560"
  },
  {
    "text": "it's moving through this you know uh road and the aim is you know to to reach to the",
    "start": "492560",
    "end": "499520"
  },
  {
    "text": "end mark as soon as possible so we have some a step-by-step intermediate reward",
    "start": "499520",
    "end": "505039"
  },
  {
    "text": "so we divide the whole pass into let's say 10 segments and as soon as it patches as as soon as the vehicle passed",
    "start": "505039",
    "end": "511759"
  },
  {
    "text": "each segment we give it a whole bunch of revolver which is on this scale of 10 to 20 000",
    "start": "511759",
    "end": "518959"
  },
  {
    "text": "right now and so the other so if we call these different pieces different",
    "start": "518959",
    "end": "524240"
  },
  {
    "text": "components of the reward function so the piece related to the relative angle",
    "start": "524240",
    "end": "529600"
  },
  {
    "text": "is on the scale of two to four and that the piece related to the intermediate revolt which is",
    "start": "529600",
    "end": "536000"
  },
  {
    "text": "discrete revolves is on the scale of 10 000 or 20 000",
    "start": "536000",
    "end": "542399"
  },
  {
    "text": "ah i see okay well yeah that's that okay okay maybe that actually pretty much answers the whole question as a whole",
    "start": "542399",
    "end": "548800"
  },
  {
    "start": "543000",
    "end": "696000"
  },
  {
    "text": "yeah so your agent's gonna bias towards just like reaching reaching these checkpoints but",
    "start": "548800",
    "end": "555440"
  },
  {
    "text": "like comparatively two with respect to ten thousand means that like it's it's going",
    "start": "555440",
    "end": "561040"
  },
  {
    "text": "to bias towards any possible any possible actions that get at these intermediate rewards and the",
    "start": "561040",
    "end": "566160"
  },
  {
    "text": "intermediate rewards are sparse from my understanding yeah because there are ten segments and then what it's like",
    "start": "566160",
    "end": "572000"
  },
  {
    "text": "you get like one thousand two thousand three thousand four thousand yeah five thousand yeah",
    "start": "572000",
    "end": "577600"
  },
  {
    "text": "yeah you probably don't want to do that just because yeah that's like the difference between",
    "start": "577600",
    "end": "584080"
  },
  {
    "text": "two and ten thousand essentially means that like your agent can essentially throw out the window anything about like",
    "start": "584080",
    "end": "590160"
  },
  {
    "text": "you know having good essentially like steering angle or something like that whatever whatever it was called my bed yeah um",
    "start": "590160",
    "end": "596000"
  },
  {
    "text": "so okay actually what you're going to want to do here is you're on the track you get rewards for",
    "start": "596000",
    "end": "603680"
  },
  {
    "text": "throwing down the track like in the most if i elaborate on the other idea that we",
    "start": "603680",
    "end": "609360"
  },
  {
    "text": "implemented so the other idea is like delta x over delta t",
    "start": "609360",
    "end": "614959"
  },
  {
    "text": "to my reward function real quick thank you uh so throughout the ladders you said",
    "start": "614959",
    "end": "620720"
  },
  {
    "text": "it's not just it's just it's not just a matter of throwing out the ladders though because like the ladders actually are a good idea",
    "start": "620720",
    "end": "626560"
  },
  {
    "text": "but the ladders actually are a good idea it's just that the ladders with respect to your steering angle reward aren't",
    "start": "626560",
    "end": "632320"
  },
  {
    "text": "great that's the issue yeah because like",
    "start": "632320",
    "end": "637760"
  },
  {
    "text": "like so imagine you get to 1000 right right the difference between 1000 and 1002 is like not",
    "start": "637760",
    "end": "643760"
  },
  {
    "text": "great enough like with respect to like the gradients that you're going to be computing in your backwards class the other thing also is that like by default",
    "start": "643760",
    "end": "650480"
  },
  {
    "text": "we clip the gradients we clip the gradients that you'll see like inside of your inside of your policy so that you like you can avoid",
    "start": "650480",
    "end": "657120"
  },
  {
    "text": "like these crazy instabilities that like can occur so",
    "start": "657120",
    "end": "662959"
  },
  {
    "text": "having large scale rewards anyways is like not a great idea i would say like any reward function that you write it's",
    "start": "662959",
    "end": "668800"
  },
  {
    "text": "a good like it's a good practice to keep it like okay typically you would keep it between",
    "start": "668800",
    "end": "674320"
  },
  {
    "text": "zero and one but then like that really that can sometimes lead to like uh",
    "start": "674320",
    "end": "679519"
  },
  {
    "text": "issues because like your rewards can be too small like definitely so like you can make it between zero and ten or zero and a hundred that'll work fine you",
    "start": "679519",
    "end": "685839"
  },
  {
    "text": "wanna still advise having good steering that's the thing",
    "start": "685839",
    "end": "691600"
  },
  {
    "text": "throughout the course you want to learn that behavior uh one thing i should mention too uh if",
    "start": "691600",
    "end": "697920"
  },
  {
    "start": "696000",
    "end": "778000"
  },
  {
    "text": "the agent is not driving the vehicle at a certain speed or uh rather yeah its meet speed is",
    "start": "697920",
    "end": "704560"
  },
  {
    "text": "below a threshold then it's not going to get the points for that ladder so let's say so that's that's actually",
    "start": "704560",
    "end": "710639"
  },
  {
    "text": "also so what you've created here is like a non-differentiable reward function actually",
    "start": "710639",
    "end": "717440"
  },
  {
    "text": "yeah so okay writing guys writing word functions is actually pretty much the same as writing a loss function like in deep",
    "start": "717440",
    "end": "723120"
  },
  {
    "text": "learning yeah so i'd say that like if you if you do something like this",
    "start": "723120",
    "end": "728959"
  },
  {
    "text": "your like reward function is not going to be smooth smooth and continuous and differentiable at all points",
    "start": "728959",
    "end": "735040"
  },
  {
    "text": "when i when i say that it's differentiable like also when you're analytically computing gradients which is like how most of these networks work",
    "start": "735040",
    "end": "741279"
  },
  {
    "text": "like if your slope is like if your slope is really high right if your slope on your reward curve is really high that's",
    "start": "741279",
    "end": "746880"
  },
  {
    "text": "going to lead to like really really large gradients that could almost be like computed as infinity you know",
    "start": "746880",
    "end": "754000"
  },
  {
    "text": "so like you can pretty much you can pretty much forget about like those actually like being useful in terms of",
    "start": "754000",
    "end": "759440"
  },
  {
    "text": "signal okay this is like a repo that i worked on a while ago before i was working on ray",
    "start": "759440",
    "end": "765439"
  },
  {
    "text": "it's called meta world it was like these set of like uh robotic manipulation environments",
    "start": "765760",
    "end": "771360"
  },
  {
    "text": "cool um so let's see let me let me find the piece of code that i'm trying to share with you so essentially like for",
    "start": "771360",
    "end": "777360"
  },
  {
    "text": "every single task that you have you're probably going to want to like have some normalized reward for",
    "start": "777360",
    "end": "783360"
  },
  {
    "start": "778000",
    "end": "1100000"
  },
  {
    "text": "completing that task and then you'll have to combine those rewards okay and like the combination of those rewards is",
    "start": "783360",
    "end": "788959"
  },
  {
    "text": "like where things get a little bit complicated because you want to essentially like",
    "start": "788959",
    "end": "795360"
  },
  {
    "text": "have some way of saying like or in hand uh it's like i am driving at like a certain",
    "start": "795360",
    "end": "801839"
  },
  {
    "text": "velocity and this i'm driving at a certain you know steering angle and this but",
    "start": "801839",
    "end": "807360"
  },
  {
    "text": "like the and operation is like a non-differentiable operation so essentially we need something that looks like a soft hand",
    "start": "807360",
    "end": "814880"
  },
  {
    "text": "yeah you need something that looks like a soft and so there actually is something and it works pretty well",
    "start": "815040",
    "end": "820480"
  },
  {
    "text": "it's not like very well researched but we use it to make like 50 robotic manipulation environments",
    "start": "820480",
    "end": "826240"
  },
  {
    "text": "for some metal learning research and it works pretty well uh",
    "start": "826240",
    "end": "831680"
  },
  {
    "text": "so i'm going to share this with you guys this is my first time hearing of a soft",
    "start": "831680",
    "end": "837120"
  },
  {
    "text": "hand yeah i mean like most people don't really discuss",
    "start": "837120",
    "end": "842800"
  },
  {
    "text": "writing writing reward functions right so okay so like or or is pretty easy to do",
    "start": "842800",
    "end": "849199"
  },
  {
    "text": "right because or is just like a plus b divided by a times b it's like a normalized a normalized product or you",
    "start": "849199",
    "end": "856160"
  },
  {
    "text": "could just do a plus b but saying and is different and is like something that you can",
    "start": "856160",
    "end": "862399"
  },
  {
    "text": "compute using this thing called a hamaker product so you say just simply adding the two",
    "start": "862399",
    "end": "869519"
  },
  {
    "text": "different components of the reward is not a kind of hand operation",
    "start": "869519",
    "end": "875199"
  },
  {
    "text": "it's not i mean it's an or operation essentially because like your agent can bias towards one term versus the other",
    "start": "875199",
    "end": "881279"
  },
  {
    "text": "in that case but what you really want is that like either like either both are happening or",
    "start": "881279",
    "end": "886880"
  },
  {
    "text": "none are happening yeah so that's that's this is like the first thing that i recommend but the second thing is like is there a way for",
    "start": "886880",
    "end": "893120"
  },
  {
    "text": "you to write some sort of scripted policy of the actions that like your agent should take her on this track",
    "start": "893120",
    "end": "898639"
  },
  {
    "text": "scripted policy yeah something where it's like i literally hard code like for like maybe one or two tracks like what",
    "start": "898639",
    "end": "905839"
  },
  {
    "text": "is the course like what what is the policy so that's like the agent is doing the correct thing on the track",
    "start": "905839",
    "end": "911440"
  },
  {
    "text": "if you do that the nice thing is that when you do that you can also like plot your reward function over time to like",
    "start": "911440",
    "end": "918959"
  },
  {
    "text": "see what actually the shape of your reward function is yeah and if your reward function like",
    "start": "918959",
    "end": "925600"
  },
  {
    "text": "you know is having like weird plateaus uh weird plateaus or like weird spikes",
    "start": "925600",
    "end": "931440"
  },
  {
    "text": "you know things that would otherwise be very non-differentiable then it's like a good chance that your agent's like not",
    "start": "931440",
    "end": "936720"
  },
  {
    "text": "going to learn your learning reward okay gotcha essentially and then and then the other thing is like you want your terms",
    "start": "936720",
    "end": "942800"
  },
  {
    "text": "to be normalized which i think you guys have done so it's like steering angle is a reward that ranges between zero and two",
    "start": "942800",
    "end": "948560"
  },
  {
    "text": "uh and velocity is a term that ranges between zero and two and then after that",
    "start": "948560",
    "end": "954480"
  },
  {
    "text": "you'll want to bias them so like if steering angle is like if if like velocity is something that's",
    "start": "954480",
    "end": "961440"
  },
  {
    "text": "easier to achieve than steering angle then like uh i mean you can you can",
    "start": "961440",
    "end": "967600"
  },
  {
    "text": "hammock or product them together or like you can essentially like do a normalization on the terms such that like",
    "start": "967600",
    "end": "974160"
  },
  {
    "text": "uh the steering angle one is worth like three times more than like the",
    "start": "974160",
    "end": "979759"
  },
  {
    "text": "velocity one because we really care about like steering angle uh compared to velocity yeah",
    "start": "979759",
    "end": "986639"
  },
  {
    "text": "okay so if you look at like line 76 uh you don't have to change like this uh",
    "start": "986639",
    "end": "992399"
  },
  {
    "text": "sigmoid parameter you should just like that should just be fine but um essentially like what this will",
    "start": "992399",
    "end": "997440"
  },
  {
    "text": "do is you have to write",
    "start": "997440",
    "end": "1002480"
  },
  {
    "text": "the bounds like the target interval for um for for your sigmoid itself",
    "start": "1002959",
    "end": "1009680"
  },
  {
    "text": "yeah there's i i essentially like actually copied this code from uh deepmind like wrote this",
    "start": "1009680",
    "end": "1015440"
  },
  {
    "text": "uh deepmind like wrote these reward utilities yeah so like i'm gonna like share this paper with you and like it on",
    "start": "1015440",
    "end": "1020560"
  },
  {
    "text": "a a very specific page it essentially teaches you how to use this tolerance and inverse tolerance",
    "start": "1020560",
    "end": "1026319"
  },
  {
    "text": "functions and then the the hamaker product uh that one's like a little bit more explainable but i",
    "start": "1026319",
    "end": "1031678"
  },
  {
    "text": "think you guys can google that one go here to this paper and then you go to",
    "start": "1031679",
    "end": "1038480"
  },
  {
    "text": "page four page four there's a diagram at the top",
    "start": "1038480",
    "end": "1045199"
  },
  {
    "text": "that explains how to tune the tolerance function",
    "start": "1045199",
    "end": "1051679"
  },
  {
    "text": "essentially it allows you to create these reward curves yeah this will allow you to create like normalized reward curves in such a way",
    "start": "1051679",
    "end": "1057919"
  },
  {
    "text": "that you can change the shape of the curve that is so damn rap thank you yeah this",
    "start": "1057919",
    "end": "1064480"
  },
  {
    "text": "is this was this like really saved my ass when i was in grad school yeah so i'm guessing uh like rl stuff was",
    "start": "1064480",
    "end": "1070880"
  },
  {
    "text": "your thesis project yeah i did i did like rl for i did rl like for manipulation control",
    "start": "1070880",
    "end": "1077600"
  },
  {
    "text": "yeah when i was a master's you guys are based in berkeley right",
    "start": "1077600",
    "end": "1083039"
  },
  {
    "text": "uh we're based we're missing san francisco now actually okay yeah i don't do any robotics anymore but",
    "start": "1083039",
    "end": "1089440"
  },
  {
    "text": "okay it's always fun to like work on these things yeah gone man that was my first",
    "start": "1089440",
    "end": "1095120"
  },
  {
    "text": "time using rl i mean it's a bit overwhelming but it's a badass i mean",
    "start": "1095120",
    "end": "1100240"
  },
  {
    "start": "1100000",
    "end": "1239000"
  },
  {
    "text": "so so there's a there's another thing that i wanted to discuss with you guys since you guys are saying you guys are first time rl users it's just like",
    "start": "1100240",
    "end": "1106160"
  },
  {
    "text": "uh so there's this like concept called mark object decision process okay",
    "start": "1106160",
    "end": "1111440"
  },
  {
    "text": "which i think you guys might have read up on at this point yeah yeah so there's this thing called a",
    "start": "1111440",
    "end": "1117679"
  },
  {
    "text": "partially observable markov decision process which essentially says that like if like i have like",
    "start": "1117679",
    "end": "1123760"
  },
  {
    "text": "some if i have some action that i need so typically like the actions that you take at any given time step are dependent on",
    "start": "1123760",
    "end": "1130960"
  },
  {
    "text": "like the current observation okay like that's the whole point of like the markov decision process which is like",
    "start": "1130960",
    "end": "1137840"
  },
  {
    "text": "whatever i can observe right now is like what i can use to act but like uh if there's some quantity that i need",
    "start": "1137840",
    "end": "1144400"
  },
  {
    "text": "to like essentially be inside my observation then if that quantity isn't in there then",
    "start": "1144400",
    "end": "1151039"
  },
  {
    "text": "like this markov decision process becomes a partially observable crop decision process so like i'll give you",
    "start": "1151039",
    "end": "1156400"
  },
  {
    "text": "an example okay to make this like a little bit easier to cement just like so say like you're doing like this driving",
    "start": "1156400",
    "end": "1162080"
  },
  {
    "text": "project and like you have to drive on the track okay well um",
    "start": "1162080",
    "end": "1167280"
  },
  {
    "text": "what if uh the the the friction the friction of the the friction of the road at any moment",
    "start": "1167280",
    "end": "1173600"
  },
  {
    "text": "like how much slippage is going on is like actually really important to your problem but like you don't actually",
    "start": "1173600",
    "end": "1180080"
  },
  {
    "text": "include that inside your observation okay yeah so i don't really know exactly how we measure that i guess like",
    "start": "1180080",
    "end": "1186080"
  },
  {
    "text": "friction of the road is like one of them or like i don't know like percentage of tire patch contact on the road i'm not",
    "start": "1186080",
    "end": "1191120"
  },
  {
    "text": "entirely sure uh yeah well anyways like if that's not included inside the observation but it's really important it makes your problem a",
    "start": "1191120",
    "end": "1197760"
  },
  {
    "text": "particularly observable markov decision process and uh that can actually make your life really",
    "start": "1197760",
    "end": "1203360"
  },
  {
    "text": "hard when you're using some of these off policy or our algorithms so like when you're using sac stack is really nice",
    "start": "1203360",
    "end": "1209039"
  },
  {
    "text": "just because like it has less tunable parameters in general try also try like using ppo with",
    "start": "1209039",
    "end": "1214559"
  },
  {
    "text": "whatever reward function you write just because like harder to solve reward functions",
    "start": "1214559",
    "end": "1220000"
  },
  {
    "text": "partially observable markov decision processes like all of that should be like much easier to solve via ppo than",
    "start": "1220000",
    "end": "1226320"
  },
  {
    "text": "sac and since you're using a simulator like there's actually really no point in like going for sample efficiency",
    "start": "1226320",
    "end": "1233360"
  },
  {
    "text": "sounds good do i answer you ask your questions yeah yeah maybe for five minutes i will",
    "start": "1233360",
    "end": "1239440"
  },
  {
    "start": "1239000",
    "end": "1345000"
  },
  {
    "text": "try to wrap up so one thing is is overtraining detrimental for the performance of the model like",
    "start": "1239440",
    "end": "1246000"
  },
  {
    "text": "oh that's a good question but it's difficult to characterize",
    "start": "1246000",
    "end": "1251679"
  },
  {
    "text": "exactly like how general your policy is i'd say that um",
    "start": "1251679",
    "end": "1257200"
  },
  {
    "text": "if your reward function allows for like multiple uh trajectories to like have like to",
    "start": "1257200",
    "end": "1263760"
  },
  {
    "text": "achieve the optimal reward uh then",
    "start": "1263760",
    "end": "1268559"
  },
  {
    "text": "it's just really a matter of like having really good uh really good initialization of your",
    "start": "1269600",
    "end": "1276000"
  },
  {
    "text": "environment okay so like if your environment itself like uh it changes the starting the starting",
    "start": "1276000",
    "end": "1283520"
  },
  {
    "text": "criteria like the initialization criteria then you probably won't end up in a situation where you're over fitting",
    "start": "1283520",
    "end": "1291520"
  },
  {
    "text": "i see yeah does that yeah so it's not it's not like supervised learning in that sense because like",
    "start": "1291520",
    "end": "1296880"
  },
  {
    "text": "supervised learning you'll have that issue like were you over fit to uh you overfit to like futures in your",
    "start": "1296880",
    "end": "1303280"
  },
  {
    "text": "data set but reinforcing learning you bootstrap right you bootstrap on your environment",
    "start": "1303280",
    "end": "1308640"
  },
  {
    "text": "essentially so your environment itself like has to express",
    "start": "1308640",
    "end": "1313679"
  },
  {
    "text": "express the ability to like have diverse behaviors yeah and then so long as you like",
    "start": "1313679",
    "end": "1319760"
  },
  {
    "text": "do a good job of randomization randomization of your initialization criteria then you should be fine i don't really know",
    "start": "1319760",
    "end": "1326080"
  },
  {
    "text": "what that looks like in your environment today but i can tell you like in a robotic manipulation environment we're like we're doing this picking and",
    "start": "1326080",
    "end": "1331360"
  },
  {
    "text": "placing it's like okay we might like move the starting of the position of the cube quite a bit and then move the",
    "start": "1331360",
    "end": "1336880"
  },
  {
    "text": "starting position of the arm quite a bit you know and then how to try to complete how the robot try",
    "start": "1336880",
    "end": "1342720"
  },
  {
    "text": "to complete the task from there so which method you kind of show us that we are having over training issue",
    "start": "1342720",
    "end": "1349520"
  },
  {
    "start": "1345000",
    "end": "1493000"
  },
  {
    "text": "overfitting issues okay let's see okay so actually but yeah this is another good question um i haven't",
    "start": "1349520",
    "end": "1355440"
  },
  {
    "text": "looked at like the parameters that are reported in sac but okay essentially like",
    "start": "1355440",
    "end": "1362240"
  },
  {
    "text": "essentially what you want is like uh so there's this concept of like an entropy of a policy okay especially like with",
    "start": "1362240",
    "end": "1368159"
  },
  {
    "text": "sac it like it's like a your guys's action space is continuous right so your policy is essentially",
    "start": "1368159",
    "end": "1374480"
  },
  {
    "text": "represented by like this thing that outputs logics to adoption so like this gaussian distribution has an entropy to",
    "start": "1374480",
    "end": "1380000"
  },
  {
    "text": "it which um essentially you want the entropy to like remain relatively high you don't want it",
    "start": "1380000",
    "end": "1386559"
  },
  {
    "text": "to like drop this entropy essentially says that like the the higher the higher your entropy",
    "start": "1386559",
    "end": "1393200"
  },
  {
    "text": "of your policy is like the more it is likely to like not biased to",
    "start": "1393200",
    "end": "1398640"
  },
  {
    "text": "like one one or like a small subset of actions yeah so entropy is like nothing more",
    "start": "1398640",
    "end": "1405520"
  },
  {
    "text": "than like actually before i go and dive into what",
    "start": "1405520",
    "end": "1410880"
  },
  {
    "text": "entropy is like do you guys actually understand the concept of it i can like point at a high level",
    "start": "1410880",
    "end": "1417120"
  },
  {
    "text": "okay yeah yeah oh you're sad okay",
    "start": "1417120",
    "end": "1423520"
  },
  {
    "text": "yeah so i would i would keep track of the policy entropy or like the policy standard deviation which probably is reported",
    "start": "1423520",
    "end": "1430640"
  },
  {
    "text": "yeah i mean naturally over time your entropy is going to start out like relatively high and then drop a little",
    "start": "1430640",
    "end": "1435760"
  },
  {
    "text": "bit but when you don't want us to like continue training the policy to the point that the entropy like",
    "start": "1435760",
    "end": "1440880"
  },
  {
    "text": "absolutely drops to zero that's that's like something that you don't want",
    "start": "1440880",
    "end": "1446159"
  },
  {
    "text": "yeah because like low interview policy essentially means like we're spamming the same action pretty much all the time",
    "start": "1446159",
    "end": "1453679"
  },
  {
    "text": "okay okay sounds good yeah so actually like that's why stack works really well right",
    "start": "1454799",
    "end": "1460799"
  },
  {
    "text": "because like they have this automatic entropy reward uh automatically to an",
    "start": "1460799",
    "end": "1465919"
  },
  {
    "text": "entropy reward yeah and like that helps quite a bit with the exploration i mean yeah big thing for you guys is",
    "start": "1465919",
    "end": "1471600"
  },
  {
    "text": "like going to be um write a reward function that's like smooth and continuous yeah and got it",
    "start": "1471600",
    "end": "1478240"
  },
  {
    "text": "yeah and use a scripted policy to help you do that all right yeah okay cool thank you sebastian yeah",
    "start": "1478240",
    "end": "1486080"
  },
  {
    "text": "thank you guys so much for joining yeah yeah okay thank you very much yeah it was great",
    "start": "1486080",
    "end": "1491600"
  },
  {
    "text": "i see yeah and the other one was about evaluation uh config that we have for",
    "start": "1491600",
    "end": "1497279"
  },
  {
    "start": "1493000",
    "end": "1554000"
  },
  {
    "text": "this as sac so is it do you recommend like frequently turning the evaluation mode on and off",
    "start": "1497279",
    "end": "1505039"
  },
  {
    "text": "to see the the to track the bot's performance for example for sac we can turn the exploration",
    "start": "1505039",
    "end": "1510799"
  },
  {
    "text": "on and off during training because i did try this approach um i wanted to see for example",
    "start": "1510799",
    "end": "1517520"
  },
  {
    "text": "at which stage the bot is fully trained and beyond which probably i'm gonna have over training",
    "start": "1517520",
    "end": "1523120"
  },
  {
    "text": "issue or overfitting um but i i found that once i'm restoring",
    "start": "1523120",
    "end": "1529039"
  },
  {
    "text": "the the bot from some you know some save points",
    "start": "1529039",
    "end": "1534559"
  },
  {
    "text": "uh i again don't see a consistent behavior so if i just continue training let's say for 500 iteration rather than i you know",
    "start": "1534559",
    "end": "1542640"
  },
  {
    "text": "stop uh change the evaluation and training mode frequently i see",
    "start": "1542640",
    "end": "1548720"
  },
  {
    "text": "it's kind of different behavior yeah okay i see really",
    "start": "1548720",
    "end": "1555200"
  },
  {
    "start": "1554000",
    "end": "1678000"
  },
  {
    "text": "i'm not sure what would be the best way to to figure out yeah so you're definitely you're definitely gonna be",
    "start": "1555200",
    "end": "1561200"
  },
  {
    "text": "needing to run your evaluation uh as frequently as you can within your compute budget",
    "start": "1561200",
    "end": "1567600"
  },
  {
    "text": "yeah so like what's the what's the setup that you guys run your experiments on is it just like a desktop tower yeah i'm",
    "start": "1567600",
    "end": "1572880"
  },
  {
    "text": "running it on my gaming pc right now you're getting pc okay all right so like how many quarters do",
    "start": "1572880",
    "end": "1578720"
  },
  {
    "text": "you have on your gaming pc uh i got 12 course of course okay and then",
    "start": "1578720",
    "end": "1585120"
  },
  {
    "text": "for work do you have access to any other computers uh we just got uh our office just got a",
    "start": "1585120",
    "end": "1591120"
  },
  {
    "text": "uh what does it mean like an eight uh 24 core machine okay red specs but yeah it's a",
    "start": "1591120",
    "end": "1598159"
  },
  {
    "text": "server processor yeah so the really cool thing actually is like",
    "start": "1598159",
    "end": "1603679"
  },
  {
    "text": "if you like so this is something that i did a lot in grad school but it's like you know in my lab we had like 10 pcs",
    "start": "1604000",
    "end": "1609840"
  },
  {
    "text": "lying around all from the last decade but like that doesn't necessarily make them all useless right so i actually",
    "start": "1609840",
    "end": "1615039"
  },
  {
    "text": "chained them together and like made one ray cluster out of those 10 pcs that's dope",
    "start": "1615039",
    "end": "1620400"
  },
  {
    "text": "yeah because it's really easy to set up like a ray cluster just using a couple of pcs assuming that you can",
    "start": "1620400",
    "end": "1626799"
  },
  {
    "text": "get access to like some public ip address if you're on different networks or if you're on the same network then",
    "start": "1626799",
    "end": "1632080"
  },
  {
    "text": "you just have to know that the network ip address essentially yeah",
    "start": "1632080",
    "end": "1637440"
  },
  {
    "text": "yeah so i'd say like set up a bigger ray cluster um and then",
    "start": "1637760",
    "end": "1643520"
  },
  {
    "text": "if your evaluation is really slow if your simulator is pretty slow then increase the number of workers in general for like training and then but",
    "start": "1643520",
    "end": "1650720"
  },
  {
    "text": "also like you can also specify a number of evaluation workers and you can run your evaluation in parallel to your training",
    "start": "1650720",
    "end": "1657360"
  },
  {
    "text": "yeah but maybe answering your first question run your evaluation as frequently as you possibly can yeah and",
    "start": "1657360",
    "end": "1663200"
  },
  {
    "text": "then train your policy and like see how it rolls out yeah",
    "start": "1663200",
    "end": "1669840"
  },
  {
    "text": "okay does that does that answer your question yeah yeah yeah that makes sense",
    "start": "1670640",
    "end": "1677679"
  },
  {
    "text": "cool yeah is there a tutorial on how to set up multiple array clusters",
    "start": "1677679",
    "end": "1683039"
  },
  {
    "start": "1678000",
    "end": "1698000"
  },
  {
    "text": "uh yeah okay let's let's see if i can find this we don't support this as much nowadays just because like the bulk of",
    "start": "1683039",
    "end": "1688159"
  },
  {
    "text": "our customers were achieving scale um gonna use the cloud um so like we have a ray cluster",
    "start": "1688159",
    "end": "1694799"
  },
  {
    "text": "launcher for that but okay let me see simon i see your question we're going to try to answer it but i'm not a",
    "start": "1694799",
    "end": "1700640"
  },
  {
    "start": "1698000",
    "end": "2033000"
  },
  {
    "text": "tensorflow expert so let's let's see what we can do all right all right um yeah i'm trying to figure out this",
    "start": "1700640",
    "end": "1707520"
  },
  {
    "text": "for a while now i've tried a lot um i don't know if i should uh share my",
    "start": "1707520",
    "end": "1713919"
  },
  {
    "text": "screen or if yeah you could yeah so actually um you go ahead and share your screen first",
    "start": "1713919",
    "end": "1720000"
  },
  {
    "text": "this is the link oh yeah yeah you can get there um so what i've implemented is like an r",
    "start": "1720000",
    "end": "1727600"
  },
  {
    "text": "d algorithm that uses a couple of like variables and um when it runs with tensorflow",
    "start": "1727600",
    "end": "1734960"
  },
  {
    "text": "tensorflow one so always like static graph i have a problem to actually get the",
    "start": "1734960",
    "end": "1741360"
  },
  {
    "text": "variables and and i want to get them actually like here at this at the states such that i",
    "start": "1741360",
    "end": "1746880"
  },
  {
    "text": "can um give them for example to a matrix callback or something like that",
    "start": "1746880",
    "end": "1752880"
  },
  {
    "text": "yeah so i actually did a little bit of digging into this this morning sorry that i didn't pick this up a little bit earlier i'm gonna",
    "start": "1752880",
    "end": "1759360"
  },
  {
    "text": "come up with something more comprehensive for you uh but like my best guess at the moment right now is",
    "start": "1759360",
    "end": "1765360"
  },
  {
    "text": "like so first of all like any anywhere that i am inside the code base um",
    "start": "1765360",
    "end": "1770399"
  },
  {
    "text": "i don't see people call like you know uh variable.eval",
    "start": "1770399",
    "end": "1776640"
  },
  {
    "text": "and then and then pass the session to it i definitely see the the former which is like",
    "start": "1776640",
    "end": "1781840"
  },
  {
    "text": "self dot pdf dot yeah i see that yeah but like my",
    "start": "1781840",
    "end": "1787039"
  },
  {
    "text": "question to you then is like so i dug into like the self dot vf intrinsic loss inside your code base",
    "start": "1787039",
    "end": "1793440"
  },
  {
    "text": "and i'm just wondering like is this a tf variable uh yes this is a um because everything",
    "start": "1793440",
    "end": "1800799"
  },
  {
    "text": "like in the loss function here say everything inside of here",
    "start": "1800799",
    "end": "1807360"
  },
  {
    "text": "is is all like given as tensor are as tensors so the sample batch holds",
    "start": "1807360",
    "end": "1815039"
  },
  {
    "text": "tensors and so everything else which i compute here then these are all like tensors",
    "start": "1815039",
    "end": "1821679"
  },
  {
    "text": "and um if i'm like in an eager tracing something like that then it's easy to",
    "start": "1821679",
    "end": "1827760"
  },
  {
    "text": "use the numpy and i get what i want but in the other case i can't also like as",
    "start": "1827760",
    "end": "1833600"
  },
  {
    "text": "you see here i tried it here it it does work and say yeah",
    "start": "1833600",
    "end": "1839600"
  },
  {
    "text": "um i i have no clue where maybe there is like i i see that a very similar thing",
    "start": "1839600",
    "end": "1845520"
  },
  {
    "text": "is done with the the f loss in the ppo and that's given somehow to the stats",
    "start": "1845520",
    "end": "1851520"
  },
  {
    "text": "function and that's somewhere yeah yeah yeah create it so i'm i'm like a little bit concerned",
    "start": "1851520",
    "end": "1858240"
  },
  {
    "text": "right now that uh the issue is that like this this uh this graph operation like",
    "start": "1858240",
    "end": "1864960"
  },
  {
    "text": "actually hasn't been built before you actually pass it to the to the to the um",
    "start": "1864960",
    "end": "1871600"
  },
  {
    "text": "inside of get state so i like was reading up in the code base and i noticed that like there was like this relatively common",
    "start": "1871600",
    "end": "1877679"
  },
  {
    "text": "pattern where like i'll i'll try to i'll try to show you right now actually so like this um okay",
    "start": "1877679",
    "end": "1884559"
  },
  {
    "text": "can you read this by the way or do you need me to make this bigger for you i'll just switch to the other screen and that becomes way better",
    "start": "1884559",
    "end": "1892480"
  },
  {
    "text": "okay so you can read this perfectly cool yeah so if we look inside this get state",
    "start": "1892480",
    "end": "1897600"
  },
  {
    "text": "of this um of this uh ou noise of this ou noise uh",
    "start": "1897600",
    "end": "1903840"
  },
  {
    "text": "exploration policy it's like what it looks like it actually does is like",
    "start": "1903840",
    "end": "1909279"
  },
  {
    "text": "so if you call getstate and you have not specified a session then you",
    "start": "1909279",
    "end": "1916559"
  },
  {
    "text": "actually return this first okay and then if you've specified a session",
    "start": "1916640",
    "end": "1922000"
  },
  {
    "text": "then you would respect then you would return this but like where is it actually called without a session actually so it's like if you go like",
    "start": "1922000",
    "end": "1928080"
  },
  {
    "text": "looking inside this uh we go looking like for self dot get",
    "start": "1928080",
    "end": "1935840"
  },
  {
    "text": "state okay one second it's down here it's inside cash noise",
    "start": "1935840",
    "end": "1942880"
  },
  {
    "text": "oh here we go yeah so if we actually look at at this file like this gaussian noise one which is",
    "start": "1942960",
    "end": "1948000"
  },
  {
    "text": "like also pretty much same callback it's like give session return session of self.tf",
    "start": "1948000",
    "end": "1954000"
  },
  {
    "text": "state off okay well like what is tf's data well it's actually like",
    "start": "1954000",
    "end": "1959039"
  },
  {
    "text": "built over here inside of dunder in it",
    "start": "1959039",
    "end": "1963840"
  },
  {
    "text": "so like what they do is like inside of a knit first they build the the get state up and then",
    "start": "1964480",
    "end": "1969600"
  },
  {
    "text": "when you've passed the session then you can like run it on the state off",
    "start": "1969600",
    "end": "1975360"
  },
  {
    "text": "in essence",
    "start": "1975360",
    "end": "1978000"
  },
  {
    "text": "so my my yeah so again like like in in summary like my concern is that like the state op for you is like not being built",
    "start": "1982320",
    "end": "1988720"
  },
  {
    "text": "before you actually run it through the set.run call and so we just need to build we just need to build the",
    "start": "1988720",
    "end": "1995440"
  },
  {
    "text": "operation first before hand and then we can",
    "start": "1995440",
    "end": "2000720"
  },
  {
    "text": "we can make this call and it'll work properly yeah also is there a reason why you're using tensorflow one",
    "start": "2000720",
    "end": "2007519"
  },
  {
    "text": "uh yes it's way faster it's way faster okay yeah like if i run like um",
    "start": "2007519",
    "end": "2016080"
  },
  {
    "text": "one iteration tensorflow is like at four point something seconds and uh",
    "start": "2016080",
    "end": "2023200"
  },
  {
    "text": "uh torch is the next fastest at seven point something",
    "start": "2023200",
    "end": "2028480"
  },
  {
    "text": "something okay that's um no arguments there",
    "start": "2028480",
    "end": "2033600"
  },
  {
    "start": "2033000",
    "end": "2513000"
  },
  {
    "text": "but like not even using tensorflow 2 with eager tracing yes like if you install tensorflow 2",
    "start": "2033600",
    "end": "2038640"
  },
  {
    "text": "right there's like a way to run it like in graph mode and there's a way to run it with uh eager execution",
    "start": "2038640",
    "end": "2044640"
  },
  {
    "text": "yeah so like different things that we can do here if you're using tensorflow 2 but with",
    "start": "2044640",
    "end": "2052079"
  },
  {
    "text": "with that execution would like that um and you're still doing graph tracing and you're still going to graph racing yeah",
    "start": "2052079",
    "end": "2060398"
  },
  {
    "text": "yeah i i actually like implement this like for for all like versions",
    "start": "2060399",
    "end": "2065679"
  },
  {
    "text": "like tfe tft with eager tracing and so on okay um because i want to to have that",
    "start": "2065679",
    "end": "2072079"
  },
  {
    "text": "algorithm like be usable for all kinds of uh frameworks",
    "start": "2072079",
    "end": "2078320"
  },
  {
    "text": "and um [Music] if you look into into the code i think um the operation",
    "start": "2078320",
    "end": "2085280"
  },
  {
    "text": "does get initialized it does get initialized okay because",
    "start": "2085280",
    "end": "2090638"
  },
  {
    "text": "can you give me an example like something something on which i can run your on your code or example it's like",
    "start": "2090639",
    "end": "2097359"
  },
  {
    "text": "i think that would help me quite a bit here i can give you um just what i use",
    "start": "2097359",
    "end": "2104079"
  },
  {
    "text": "and um [Music] that's actually",
    "start": "2104079",
    "end": "2109200"
  },
  {
    "text": "where should i copy it uh actually one is it on here is it on your branch",
    "start": "2109200",
    "end": "2116079"
  },
  {
    "text": "it on my branch no um this is a file i have like just in my",
    "start": "2116079",
    "end": "2121200"
  },
  {
    "text": "uh in my editor which i uh that's um i can make it",
    "start": "2121200",
    "end": "2128240"
  },
  {
    "text": "okay but your your branch um that itself like it's available on github right",
    "start": "2128240",
    "end": "2134160"
  },
  {
    "text": "yes that's available at you know uh did you open a pr out of it by chance at any point",
    "start": "2134160",
    "end": "2140240"
  },
  {
    "text": "uh no not yet i didn't want to like fill up your uh your queue even more i can do it if you want to",
    "start": "2140240",
    "end": "2147040"
  },
  {
    "text": "yeah so can you actually can you actually do that because then i can actually open i can actually check out your pr right",
    "start": "2147040",
    "end": "2153359"
  },
  {
    "text": "now all right it looks like there's nobody else here so we can actually spend some time trying to figure this out",
    "start": "2153359",
    "end": "2159280"
  },
  {
    "text": "yeah say say you want me to do this right now yeah i want you to like if you can if",
    "start": "2159280",
    "end": "2166240"
  },
  {
    "text": "it's possible yeah so we can actually just check this pr out",
    "start": "2166240",
    "end": "2172400"
  },
  {
    "text": "get status so is this is this uh is your branch",
    "start": "2172400",
    "end": "2178960"
  },
  {
    "text": "level with master or is it level with something else you have master that's on this because",
    "start": "2178960",
    "end": "2184880"
  },
  {
    "text": "like that's the only thing that's going to stop me from running this right now okay july 12. oh okay all right so this",
    "start": "2184880",
    "end": "2191680"
  },
  {
    "text": "shouldn't be too bad they shouldn't be too bad i mean let's just like try to like run something that's not",
    "start": "2191680",
    "end": "2197280"
  },
  {
    "text": "um i mean if it is the case we'll just take an extra five minutes and then i'll um",
    "start": "2197280",
    "end": "2202880"
  },
  {
    "text": "install whatever the version of ray is on this",
    "start": "2202880",
    "end": "2207640"
  },
  {
    "text": "oh",
    "start": "2214800",
    "end": "2217040"
  },
  {
    "text": "yeah kind of just hoping it's not the case because",
    "start": "2223599",
    "end": "2228760"
  },
  {
    "text": "we change the okay wait hold on this looks like it's gonna be fine let me just",
    "start": "2230560",
    "end": "2236320"
  },
  {
    "text": "copy this and put it on paste bin that's i think the quickest solution right now",
    "start": "2236320",
    "end": "2243310"
  },
  {
    "text": "[Music]",
    "start": "2243310",
    "end": "2246480"
  },
  {
    "text": "okay here's the link",
    "start": "2255839",
    "end": "2258880"
  },
  {
    "text": "yeah so actually let's do it like this okay uh i'm removing it from tune just makes",
    "start": "2262480",
    "end": "2268880"
  },
  {
    "text": "it so that like i can it's it's like a little bit easier to debug because then like your errors don't get wrapped up inside two dot run",
    "start": "2268880",
    "end": "2275200"
  },
  {
    "text": "calls okay like ray tune calls yeah which like like then like the errors will start getting like propagated to like this",
    "start": "2275200",
    "end": "2281680"
  },
  {
    "text": "file and you know that always becomes kind of annoying and so you can actually like get with a new config builder it's",
    "start": "2281680",
    "end": "2288400"
  },
  {
    "text": "like you can do config.dick to get this right but then also like you can literally just create the algorithm like via config.build",
    "start": "2288400",
    "end": "2296079"
  },
  {
    "text": "it's really nice yeah it's like very very nice i'm very much a fan",
    "start": "2296079",
    "end": "2302000"
  },
  {
    "text": "yeah they're nice yeah let's see if this works",
    "start": "2302000",
    "end": "2308240"
  },
  {
    "text": "python reproduce high that it doesn't throw any extra errors",
    "start": "2308240",
    "end": "2313920"
  },
  {
    "text": "because otherwise you're gonna get stuck rnd object has no attribute sets",
    "start": "2313920",
    "end": "2320000"
  },
  {
    "text": "actually i might have tensorflow just joking because i installed the viaconda tensorflow",
    "start": "2320000",
    "end": "2327560"
  },
  {
    "text": "so i have two point nine yeah that should work it seems to be it should work fine let's see",
    "start": "2330480",
    "end": "2338520"
  },
  {
    "text": "let's take a break point over here what happens oh no that's not what i want to do",
    "start": "2342560",
    "end": "2350119"
  },
  {
    "text": "okay so right here in the code and then",
    "start": "2354640",
    "end": "2359760"
  },
  {
    "text": "what do you want to do now it's like self dot says self enter self",
    "start": "2359760",
    "end": "2366240"
  },
  {
    "text": "we have why do we not have sex we're assess initialized",
    "start": "2366240",
    "end": "2373359"
  },
  {
    "text": "self dot success equals the session comes actually via the the",
    "start": "2373359",
    "end": "2378880"
  },
  {
    "text": "constructor",
    "start": "2378880",
    "end": "2381599"
  },
  {
    "text": "okay but this is assigned this is a sign inside of forward though right now",
    "start": "2386800",
    "end": "2392480"
  },
  {
    "text": "or one second this is assigned at line 310 which is what function is inside",
    "start": "2392480",
    "end": "2399520"
  },
  {
    "text": "inside a net it is inside of a head but",
    "start": "2399520",
    "end": "2406640"
  },
  {
    "text": "what's inside this but it's inside this forward function is it no no it's not no it's not",
    "start": "2409280",
    "end": "2416319"
  },
  {
    "text": "okay it's it's outside of that okay yeah yeah so",
    "start": "2416319",
    "end": "2421359"
  },
  {
    "text": "let's see here probably being that um just write none instead of self session into this",
    "start": "2422319",
    "end": "2428720"
  },
  {
    "text": "um into this function below i think that's usually fine",
    "start": "2428720",
    "end": "2434400"
  },
  {
    "text": "yes because um the variables are later on just used um",
    "start": "2434400",
    "end": "2441040"
  },
  {
    "text": "uh with another session i guess and and then let's work out",
    "start": "2441200",
    "end": "2446640"
  },
  {
    "text": "okay but like you don't need a session to create the this thing i can just try this right now i can just",
    "start": "2446640",
    "end": "2453200"
  },
  {
    "text": "write like instead of self session we can just write known okay",
    "start": "2453200",
    "end": "2459119"
  },
  {
    "text": "that should i think like run let's just try this and see what happens",
    "start": "2459119",
    "end": "2464319"
  },
  {
    "text": "okay so this this works all right so let's just get rid of this for now",
    "start": "2464319",
    "end": "2470799"
  },
  {
    "text": "yeah but this is this is like when i'm doing like algorithm development itself like this is almost 90 of the way that i would do it just like",
    "start": "2473040",
    "end": "2480319"
  },
  {
    "text": "a little more convenient nun type is not callable",
    "start": "2480319",
    "end": "2487200"
  },
  {
    "text": "where is that actually no this this might be fine like it looks like this ran actually fully",
    "start": "2487200",
    "end": "2492800"
  },
  {
    "text": "through this isn't an error",
    "start": "2492800",
    "end": "2496480"
  },
  {
    "text": "like i think i think it ran like one iteration of trade and we were fine if i say like",
    "start": "2498319",
    "end": "2504960"
  },
  {
    "text": "okay yeah so i think for i range 10",
    "start": "2504960",
    "end": "2510319"
  },
  {
    "text": "run this and then important i",
    "start": "2510319",
    "end": "2513760"
  },
  {
    "start": "2513000",
    "end": "2937000"
  },
  {
    "text": "i do something like",
    "start": "2515839",
    "end": "2519720"
  },
  {
    "text": "make sure this actually ran yeah this this exception at the end might just be from rey",
    "start": "2531119",
    "end": "2537760"
  },
  {
    "text": "being dumb about something or the other",
    "start": "2537760",
    "end": "2542400"
  },
  {
    "text": "yeah it looks like it's doing fine nice all right yeah it's running at",
    "start": "2543680",
    "end": "2549119"
  },
  {
    "text": "least it's running in local modes i don't know at least that's good it should also run in parallel",
    "start": "2549119",
    "end": "2555359"
  },
  {
    "text": "um but i think yeah we just i i'm just saying like we you know because we have local mode set",
    "start": "2555359",
    "end": "2561599"
  },
  {
    "text": "to true we could do this really quickly you do that always like if you debug",
    "start": "2561599",
    "end": "2569839"
  },
  {
    "text": "yeah i do but the core team is for actually trying to get rid of local mode but i'm fighting with them about that",
    "start": "2569839",
    "end": "2575520"
  },
  {
    "text": "right now so uh yeah if you actually just want to drop a message and be like i don't know how i",
    "start": "2575520",
    "end": "2580640"
  },
  {
    "text": "would i would do ro of debugging without robo mode like just inside the rlub channel then i can like actually just",
    "start": "2580640",
    "end": "2586319"
  },
  {
    "text": "use that with chen and like tell them hey we have users who use this too for their debugging yeah yeah it came do you",
    "start": "2586319",
    "end": "2592240"
  },
  {
    "text": "say i i definitely like used on multiple workers and then debugging and",
    "start": "2592240",
    "end": "2597839"
  },
  {
    "text": "that was always like problem problematic okay so this looks like it's running",
    "start": "2597839",
    "end": "2603359"
  },
  {
    "text": "actually let's let's go ahead and like just actually turn around and see what happens if i do if i run what you got here",
    "start": "2603359",
    "end": "2610880"
  },
  {
    "text": "do you need this radar timeline by the way do we not uncomment that or just this that was something i i used because in",
    "start": "2610880",
    "end": "2618160"
  },
  {
    "text": "between i had actually um a problem with tensorflow it was super",
    "start": "2618160",
    "end": "2623760"
  },
  {
    "text": "super slow used like 137 like um",
    "start": "2623760",
    "end": "2629520"
  },
  {
    "text": "milliseconds for uh executing the model",
    "start": "2629520",
    "end": "2635760"
  },
  {
    "text": "and so that i i used profiling oh okay we used that before but that's cool",
    "start": "2635760",
    "end": "2644000"
  },
  {
    "text": "this is this is yeah hold on all right none of us use this over here we should we should go and actually explore using",
    "start": "2644480",
    "end": "2650079"
  },
  {
    "text": "this did it help you at all is sorry did this help you at all this radar",
    "start": "2650079",
    "end": "2655599"
  },
  {
    "text": "timeline you're doing profiling via this uh it helped me but at the end i have to",
    "start": "2655599",
    "end": "2661119"
  },
  {
    "text": "say um there's something like line profiler it's called",
    "start": "2661119",
    "end": "2666880"
  },
  {
    "text": "oh you use you're using prop you you're using a lot yeah i've used line profiler before yeah but how do you use line",
    "start": "2666880",
    "end": "2673040"
  },
  {
    "text": "profiler when you're inside of rey does that work you just use the the decorator profile and",
    "start": "2673040",
    "end": "2679839"
  },
  {
    "text": "then you run it and that's so nice you run it and then it gives you really like for all calls you make",
    "start": "2679839",
    "end": "2687119"
  },
  {
    "text": "um yeah i've used it before i i know but i've not used it with ray so it's like",
    "start": "2687119",
    "end": "2692319"
  },
  {
    "text": "do you have to use it via use it with local mode yeah i use it with a locomotive uh okay",
    "start": "2692319",
    "end": "2698880"
  },
  {
    "text": "you can't use it like without locomotor right i have not i've never tried that okay",
    "start": "2698880",
    "end": "2704160"
  },
  {
    "text": "because if you ever if you ever get the chance could you like let me know how it goes actually it's like yeah yeah i can",
    "start": "2704160",
    "end": "2709680"
  },
  {
    "text": "do that yeah because i love using line profiler but like i've been i've been having to use pi spy more recently than line",
    "start": "2709680",
    "end": "2715359"
  },
  {
    "text": "profiler for because because like otherwise i can't get it to run but then like the pi spy",
    "start": "2715359",
    "end": "2721440"
  },
  {
    "text": "it's like it's too many ray tracing calls that are actually wrapping like my actual code so",
    "start": "2721440",
    "end": "2727119"
  },
  {
    "text": "i can't even use that properly yeah yeah yeah that's annoying using c profile is",
    "start": "2727119",
    "end": "2733440"
  },
  {
    "text": "sometimes also not giving you like um the right location for us",
    "start": "2733440",
    "end": "2739920"
  },
  {
    "text": "yeah but when i used to first use this thing like actually",
    "start": "2739920",
    "end": "2745119"
  },
  {
    "text": "here we go let's see it's running yeah",
    "start": "2745119",
    "end": "2750480"
  },
  {
    "text": "all right well let's see oh wait where is the logging directory it's test route 2 so",
    "start": "2750480",
    "end": "2758160"
  },
  {
    "text": "is",
    "start": "2762560",
    "end": "2765560"
  },
  {
    "text": "so we're not getting any errors right now but do you see like you just don't have the metric inside tensorboard is",
    "start": "2776480",
    "end": "2781680"
  },
  {
    "text": "that what it is i actually haven't like here i think i don't use even the",
    "start": "2781680",
    "end": "2786800"
  },
  {
    "text": "the metric otherwise it would like uh error out because it tells me then uh i can't run the seven",
    "start": "2786800",
    "end": "2793920"
  },
  {
    "text": "oh okay okay you won't see the like the matrix i want to show",
    "start": "2793920",
    "end": "2800839"
  },
  {
    "text": "um yeah so there's like this cat state in here right",
    "start": "2800839",
    "end": "2805760"
  },
  {
    "text": "yeah exactly say it it actually like um hear it errors out",
    "start": "2806160",
    "end": "2812800"
  },
  {
    "text": "here errors out if you say self.non episodic returns yeah exactly if like if you like uh",
    "start": "2812800",
    "end": "2818720"
  },
  {
    "text": "scroll a little up in the um in the file um uh file tab on the on the left",
    "start": "2818720",
    "end": "2825920"
  },
  {
    "text": "you see up there on callbacks and if you look into this",
    "start": "2825920",
    "end": "2831119"
  },
  {
    "text": "you see there an r d matrix callback and this is where i like actually like catch this",
    "start": "2831119",
    "end": "2837200"
  },
  {
    "text": "like this via intrinsic loss [Music] um",
    "start": "2837200",
    "end": "2843119"
  },
  {
    "text": "and on episode step i think i call uh get state",
    "start": "2843119",
    "end": "2848480"
  },
  {
    "text": "from from the exploration there it is and this is where the errors aren't so if you want you can also like put a put",
    "start": "2848480",
    "end": "2855599"
  },
  {
    "text": "a um a breakdown here yeah okay yeah but we're not",
    "start": "2855599",
    "end": "2861440"
  },
  {
    "text": "getting an error right now so how do i enable this actually uh you have to enable it when you go into the python",
    "start": "2861440",
    "end": "2869119"
  },
  {
    "text": "script which you run and then um there should be i implemented out and",
    "start": "2869119",
    "end": "2876960"
  },
  {
    "text": "upwards um when i built the config",
    "start": "2876960",
    "end": "2882480"
  },
  {
    "text": "there is something [Music] um",
    "start": "2882720",
    "end": "2887838"
  },
  {
    "text": "actually yeah this line below the the exploration there's the callbacks",
    "start": "2888480",
    "end": "2894160"
  },
  {
    "text": "um [Music] oh here here this line commented out yet",
    "start": "2894160",
    "end": "2899440"
  },
  {
    "text": "and and then these callbacks that that's actually like the first line that's",
    "start": "2899440",
    "end": "2905280"
  },
  {
    "text": "uh what uh no not not the exploration below that",
    "start": "2905280",
    "end": "2910559"
  },
  {
    "text": "was just to test out if curiosity is running in the same way",
    "start": "2910559",
    "end": "2916318"
  },
  {
    "text": "and that's yeah see",
    "start": "2917200",
    "end": "2923319"
  },
  {
    "start": "2937000",
    "end": "4567000"
  },
  {
    "text": "okay we're in here that's cool let's see what the type of this is",
    "start": "2951359",
    "end": "2956960"
  },
  {
    "text": "ah well here's your issue this doesn't exist to begin with",
    "start": "2956960",
    "end": "2963440"
  },
  {
    "text": "oh this is awesome okay um oh so this is paul it's actually one second let's see oh yes",
    "start": "2963440",
    "end": "2971760"
  },
  {
    "text": "this is automatically set to false so we have to put that on true um",
    "start": "2971760",
    "end": "2977010"
  },
  {
    "text": "[Music] yeah exactly i i just switch that up where do",
    "start": "2977010",
    "end": "2982800"
  },
  {
    "text": "you want me to stick this oh here yes yeah there it is okay",
    "start": "2982800",
    "end": "2989280"
  },
  {
    "text": "that's it from it's a little slightly slower but um",
    "start": "2989280",
    "end": "2997440"
  },
  {
    "text": "[Music]",
    "start": "2998770",
    "end": "3005760"
  },
  {
    "text": "i'm quite excited okay here we go we got a we have a tensor",
    "start": "3007520",
    "end": "3013760"
  },
  {
    "text": "yeah so we just need to evaluate said tensor okay so if we step into this",
    "start": "3013760",
    "end": "3020240"
  },
  {
    "text": "it's like what happens if i wait so what is sets first of all so that says none",
    "start": "3021359",
    "end": "3028000"
  },
  {
    "text": "uh but i usually say that's not okay",
    "start": "3028000",
    "end": "3033839"
  },
  {
    "text": "can you can you use dots underscore s",
    "start": "3033839",
    "end": "3038880"
  },
  {
    "text": "yeah i'm sure let me try that once with this yeah",
    "start": "3038880",
    "end": "3044480"
  },
  {
    "text": "here we go okay now this looks like something intense that would have happened to you yeah",
    "start": "3044480",
    "end": "3050640"
  },
  {
    "text": "now is this the area that you were getting yes exactly say there's one thing i need actually a feed stick i don't",
    "start": "3050640",
    "end": "3057920"
  },
  {
    "text": "have that oh how do we because that's actually like in the sample batch",
    "start": "3057920",
    "end": "3064000"
  },
  {
    "text": "but uh so but we could do the same actually",
    "start": "3064000",
    "end": "3071359"
  },
  {
    "text": "down in the compute loss and update function yeah so let's do that",
    "start": "3071359",
    "end": "3078240"
  },
  {
    "text": "and then we have the sample batch but we get the same problem and um maybe you have a clue um",
    "start": "3078240",
    "end": "3086480"
  },
  {
    "text": "where does it compute lies yeah well i set up it here we go um and then first part is torch and then",
    "start": "3086480",
    "end": "3092720"
  },
  {
    "text": "comes the tensorflow let's remove that this is tensorflow all right and then we um call in self",
    "start": "3092720",
    "end": "3100720"
  },
  {
    "text": "non-episodic returns in this condition we call actually the speed of intrinsic loss to uh assign it",
    "start": "3100720",
    "end": "3108400"
  },
  {
    "text": "uh down there uh there it is like self-compute",
    "start": "3108400",
    "end": "3113480"
  },
  {
    "text": "non-episodically loss yeah yeah i saw this line before yeah and you see there is also like commented out already the",
    "start": "3113480",
    "end": "3120319"
  },
  {
    "text": "session run but here we actually have the sample batch",
    "start": "3120319",
    "end": "3126240"
  },
  {
    "text": "so we could like try to feed it in but so what i tried out didn't work",
    "start": "3126240",
    "end": "3133359"
  },
  {
    "text": "and i think it's because uh yeah you're returning it's also a challenge so you can't feed it in",
    "start": "3134480",
    "end": "3140319"
  },
  {
    "text": "what what we actually need is a numpy to feed it",
    "start": "3140319",
    "end": "3145920"
  },
  {
    "text": "the sample that you mean as a tensor so okay yeah so let's actually take a look at like",
    "start": "3145920",
    "end": "3152000"
  },
  {
    "text": "something i don't know like ppo tensorflow policy really quickly let's look at that those are like always good",
    "start": "3152000",
    "end": "3157040"
  },
  {
    "text": "i mean i'm not a tensorflow expert so like it's probably a good start like yeah who's expensive",
    "start": "3157040",
    "end": "3163760"
  },
  {
    "text": "yeah uh i mean and sven and june both have like pretty significant experience with tensorflow but",
    "start": "3163760",
    "end": "3169359"
  },
  {
    "text": "me and cruz coming out of grad school it's like tensorflow wasn't as common but it wasn't common at that point so so",
    "start": "3169359",
    "end": "3175359"
  },
  {
    "text": "you weren't using it yeah we use more torch for sure but",
    "start": "3175359",
    "end": "3181680"
  },
  {
    "text": "it's so much easier to code i'm intensified fan i've started with tensorflow",
    "start": "3181680",
    "end": "3187839"
  },
  {
    "text": "way before i used ulcer torch and see that so beautiful it's really easy",
    "start": "3187839",
    "end": "3196559"
  },
  {
    "text": "yeah i mean when i started using when i started doing deep learning probably in like 2016 it's like torch was just",
    "start": "3196559",
    "end": "3202319"
  },
  {
    "text": "becoming a thing and all the grad students were using it when i was in undergrad so i was just using it",
    "start": "3202319",
    "end": "3207440"
  },
  {
    "text": "and then also like in addition i'd use like keras yeah it's down there it's down here here we go here we go so",
    "start": "3207440",
    "end": "3213760"
  },
  {
    "text": "they assign it here and then comes the stats function",
    "start": "3213760",
    "end": "3218799"
  },
  {
    "text": "and the stats from these",
    "start": "3219040",
    "end": "3223800"
  },
  {
    "text": "so i can even tell you how how this is then evaluated it's evaluated in the in",
    "start": "3229040",
    "end": "3234240"
  },
  {
    "text": "the main session run that is done by the uh by the run builder",
    "start": "3234240",
    "end": "3239760"
  },
  {
    "text": "i see but is there a reason like we can't throw your stats inside the stats function it has to be inside get state",
    "start": "3239760",
    "end": "3246160"
  },
  {
    "text": "no it would be fine um it'd be fine if it worked",
    "start": "3246160",
    "end": "3251359"
  },
  {
    "text": "how do i get it good question okay so",
    "start": "3251359",
    "end": "3256400"
  },
  {
    "text": "yeah do something like um um very different because i've actually",
    "start": "3257920",
    "end": "3264319"
  },
  {
    "text": "like rewritten also the loss function in the dynamic tf policy and the egotis",
    "start": "3264319",
    "end": "3270640"
  },
  {
    "text": "policy in such a way that we do not only",
    "start": "3270640",
    "end": "3275680"
  },
  {
    "text": "add an exploration optimizer but we also add like an optimizer for",
    "start": "3275680",
    "end": "3282240"
  },
  {
    "text": "the product okay oh sorry i'd like um another part of the loss function",
    "start": "3282240",
    "end": "3289440"
  },
  {
    "text": "and we overwrite actually the last function right okay so we we add this this term to your",
    "start": "3289440",
    "end": "3296799"
  },
  {
    "text": "log we add this term to your last term and then yeah if you take a look into into dynamic",
    "start": "3296799",
    "end": "3303520"
  },
  {
    "text": "policy uh you see what's uh what's happening there",
    "start": "3303520",
    "end": "3308559"
  },
  {
    "text": "it's inside dynamic tf policy v2 rv2 yes yeah yeah okay okay that's that's true",
    "start": "3308559",
    "end": "3314480"
  },
  {
    "text": "that's mine maybe initialize optimizer loss yes exactly that was the one and um",
    "start": "3314480",
    "end": "3321920"
  },
  {
    "text": "down there is actually like called um and it optimizes or something like that",
    "start": "3321920",
    "end": "3330160"
  },
  {
    "text": "here we go this let's see if this is starting to look great exactly and there's self-exploration",
    "start": "3331280",
    "end": "3336559"
  },
  {
    "text": "if you if if we want to make a global update there we add exploration laws and updates and this function at exploration",
    "start": "3336559",
    "end": "3343760"
  },
  {
    "text": "laws and updates that's actually where it's it's happening",
    "start": "3343760",
    "end": "3349920"
  },
  {
    "text": "so if you look at this function below it's it's right defined below",
    "start": "3349920",
    "end": "3355200"
  },
  {
    "text": "um [Music] there the old loss the original loss is like taken",
    "start": "3355200",
    "end": "3361200"
  },
  {
    "text": "on the lines below like seven six seven one",
    "start": "3361200",
    "end": "3367440"
  },
  {
    "text": "yeah there so i take the the loss which is there and i define a new one",
    "start": "3368720",
    "end": "3375440"
  },
  {
    "text": "we're called the policy laws and also call them",
    "start": "3375440",
    "end": "3380559"
  },
  {
    "text": "um exploration last year and does this does this return a new will this end up returning a new",
    "start": "3380559",
    "end": "3387040"
  },
  {
    "text": "not place a word but like a graph up have you been able to check that",
    "start": "3387040",
    "end": "3392799"
  },
  {
    "text": "um when the dummy batch is created right yeah let's let's actually figure that",
    "start": "3392799",
    "end": "3398880"
  },
  {
    "text": "out right now if it does that",
    "start": "3398880",
    "end": "3402000"
  },
  {
    "text": "i've checked that for a lot of other variables i haven't checked it for the vehicle transitions",
    "start": "3405680",
    "end": "3412400"
  },
  {
    "text": "it's a bound method of this is it supposed to be a method",
    "start": "3417599",
    "end": "3422799"
  },
  {
    "text": "yes it's supposed to be that's the way you've written it yeah that's but it's not supposed to be like a",
    "start": "3422799",
    "end": "3429200"
  },
  {
    "text": "ad exploration loss and updates start locals with loss of ppo tf policy so is this fine",
    "start": "3430559",
    "end": "3436480"
  },
  {
    "text": "actually",
    "start": "3436480",
    "end": "3438880"
  },
  {
    "text": "why don't we add actually inside here let's add it in here only",
    "start": "3441920",
    "end": "3447520"
  },
  {
    "text": "yeah see where this is called first",
    "start": "3447520",
    "end": "3452440"
  },
  {
    "text": "okay so we we get like a we have one we get a loss we yeah we get a loss",
    "start": "3470160",
    "end": "3476640"
  },
  {
    "text": "we don't know its shape though but we do get a loss and it is a tensorflow tensor",
    "start": "3476640",
    "end": "3481839"
  },
  {
    "text": "should shape usually be like the shape of the batch for the loss or is it a scalar",
    "start": "3481839",
    "end": "3488319"
  },
  {
    "text": "um no it should be like it's a normal let's see what train matches it's yeah it's usually the norm",
    "start": "3488319",
    "end": "3495359"
  },
  {
    "text": "so it should be like a scalar okay and we are fine i think",
    "start": "3495359",
    "end": "3501320"
  },
  {
    "text": "[Music] yeah this is a dummy batch yeah",
    "start": "3501320",
    "end": "3507480"
  },
  {
    "text": "[Music]",
    "start": "3507790",
    "end": "3510969"
  },
  {
    "text": "yeah shape is listen to 16 yeah okay perfect okay",
    "start": "3517280",
    "end": "3523119"
  },
  {
    "text": "i'm assuming this is the observation space of the of this thing",
    "start": "3523440",
    "end": "3531318"
  },
  {
    "text": "yes dude this frozen lake yeah so this looks fine to me for now i mean",
    "start": "3531440",
    "end": "3539359"
  },
  {
    "text": "not saying that it's correct but it looks fine if we come back here",
    "start": "3539760",
    "end": "3547040"
  },
  {
    "text": "and close this out we're back here inside of this and we need to",
    "start": "3547680",
    "end": "3554559"
  },
  {
    "text": "do this vf intrinsic loss does this get called",
    "start": "3554559",
    "end": "3559680"
  },
  {
    "text": "okay so the question is does this get called before get state gets called",
    "start": "3559680",
    "end": "3566079"
  },
  {
    "text": "so this gets called called before i'm checking checking to make sure you know",
    "start": "3568640",
    "end": "3574160"
  },
  {
    "text": "it's always good to like not make any good any assumptions right it actually arrows out because",
    "start": "3574160",
    "end": "3581359"
  },
  {
    "text": "and it doesn't doesn't get this feedback with the self.test.run",
    "start": "3581359",
    "end": "3587040"
  },
  {
    "text": "yes it just gets this at the point where the model is updated",
    "start": "3587040",
    "end": "3592720"
  },
  {
    "text": "the policy model because as this is added to the policy loss",
    "start": "3592720",
    "end": "3599119"
  },
  {
    "text": "it's like also like used in the update so the parameters coming from this",
    "start": "3599119",
    "end": "3605920"
  },
  {
    "text": "or define this are actually a second value head on the policy model",
    "start": "3605920",
    "end": "3612640"
  },
  {
    "text": "um at the point where the policy model is updated",
    "start": "3612640",
    "end": "3617680"
  },
  {
    "text": "it gets this feedback and then everything is there but here this feedback is not",
    "start": "3617680",
    "end": "3624640"
  },
  {
    "text": "here so i think this is the reason why i can't evaluate it",
    "start": "3624640",
    "end": "3629838"
  },
  {
    "text": "gotcha okay so i have one question which is like if you have tensorflow 2 enabled then like",
    "start": "3630240",
    "end": "3637520"
  },
  {
    "text": "you're going to run through this code anyways so like why not start out by being an eager execution mode and then",
    "start": "3637520",
    "end": "3645119"
  },
  {
    "text": "making sure that these evaluate properly and then moving over to the tracing mode",
    "start": "3645119",
    "end": "3651760"
  },
  {
    "text": "i actually like um did that already and i see that that the values are are good it's also like",
    "start": "3651760",
    "end": "3659280"
  },
  {
    "text": "the glass so if i if i use like tens of your eager mode",
    "start": "3659280",
    "end": "3665200"
  },
  {
    "text": "then i actually see like vf intrinsic class has a has a value that makes sense and it's also like minimized over the",
    "start": "3665200",
    "end": "3671359"
  },
  {
    "text": "time of the course of the run uh i got you okay and i also like get the uh get the value",
    "start": "3671359",
    "end": "3678880"
  },
  {
    "text": "of it um when i just call below numpy on the on the vector",
    "start": "3678880",
    "end": "3687119"
  },
  {
    "text": "the thief one and i was wondering how okay i'm just just making sure",
    "start": "3687599",
    "end": "3694079"
  },
  {
    "text": "i'm just making sure not i like i thought i thought like it could have been possibly like an issue with your",
    "start": "3694160",
    "end": "3700000"
  },
  {
    "text": "actual computation but it's definitely not the way you're describing it so we can scratch that for now",
    "start": "3700000",
    "end": "3706240"
  },
  {
    "text": "um okay let's try i don't want to run via self that says i",
    "start": "3706240",
    "end": "3712400"
  },
  {
    "text": "want to run via the session that's passed okay let's do it yeah so like i like there should be at",
    "start": "3712400",
    "end": "3719359"
  },
  {
    "text": "some point like a session that's past this right like that's i don't want to run via self that sets because i'm like not sure",
    "start": "3719359",
    "end": "3726640"
  },
  {
    "text": "why like a self-doubt sets wouldn't be passed unless this just has something to do with like this initialization",
    "start": "3726640",
    "end": "3733039"
  },
  {
    "text": "so let's just say in this and assess",
    "start": "3733039",
    "end": "3738680"
  },
  {
    "text": "yeah let's just do that and then",
    "start": "3743119",
    "end": "3746400"
  },
  {
    "text": "yeah if we if we don't get this sorted out then if we don't get this sorted out like the next 50 minutes or so then",
    "start": "3753280",
    "end": "3759760"
  },
  {
    "text": "um there's not much we can do to help you",
    "start": "3759760",
    "end": "3765359"
  },
  {
    "text": "right now just because like santa's actually out on vacation unfortunately",
    "start": "3765359",
    "end": "3770319"
  },
  {
    "text": "it's not line 452 [Music]",
    "start": "3770960",
    "end": "3776149"
  },
  {
    "text": "yeah so this doesn't exist apparently [Applause] could you shed some light here actually",
    "start": "3777760",
    "end": "3784720"
  },
  {
    "text": "it's like what do you i should come out of the um",
    "start": "3784720",
    "end": "3790240"
  },
  {
    "text": "uh with it process",
    "start": "3790240",
    "end": "3793920"
  },
  {
    "text": "browser trajectory okay yeah this is where it should be assigned",
    "start": "3795280",
    "end": "3800480"
  },
  {
    "text": "okay can i just comment these out for now and we'll just use this for now it should probably be fine",
    "start": "3800480",
    "end": "3806000"
  },
  {
    "text": "yeah sure let's try that just because probably other issues going on here",
    "start": "3806000",
    "end": "3814160"
  },
  {
    "text": "okay here we go and we have s no we don't have sex oh wait i need i",
    "start": "3817839",
    "end": "3823039"
  },
  {
    "text": "need session",
    "start": "3823039",
    "end": "3826160"
  },
  {
    "text": "i think here you were in the get state right and you wanted to do it like in the compute on",
    "start": "3830880",
    "end": "3837039"
  },
  {
    "text": "computer loss and update function here yeah",
    "start": "3837039",
    "end": "3844480"
  },
  {
    "text": "you're saying like you want me to okay well i see what you're saying but",
    "start": "3845359",
    "end": "3851720"
  },
  {
    "text": "i guess yeah i mean first we should just be able to like actually evaluate this loss inside the get loss this function we should it shouldn't",
    "start": "3852000",
    "end": "3858400"
  },
  {
    "text": "matter like whether or not we're able to do this inside of get state if we can't do it even inside of get lost right",
    "start": "3858400",
    "end": "3866000"
  },
  {
    "text": "so let's do that first actually the get lost so what's it called oh no",
    "start": "3866000",
    "end": "3871520"
  },
  {
    "text": "it's like computer compute loss and update yeah compute loss and update here we go yeah we so enough the session",
    "start": "3871520",
    "end": "3878640"
  },
  {
    "text": "actually sorry here we have the session actually and um",
    "start": "3878640",
    "end": "3885200"
  },
  {
    "text": "yeah okay say it's almost like at the end of the of the function",
    "start": "3885200",
    "end": "3892480"
  },
  {
    "text": "it's like here's the bf intrinsic loss and below um there is this line where actually",
    "start": "3892480",
    "end": "3899280"
  },
  {
    "text": "self session one is called this is where what yet it's high marked uh highlighted",
    "start": "3899280",
    "end": "3904960"
  },
  {
    "text": "oh right here okay yeah so let's do that",
    "start": "3904960",
    "end": "3909720"
  },
  {
    "text": "[Music]",
    "start": "3925880",
    "end": "3929089"
  },
  {
    "text": "by the way is there actually like a form or way how we can when we want to contribute make your life easier",
    "start": "3935680",
    "end": "3943920"
  },
  {
    "text": "because i think you have a lot of contribution on the queue right a form",
    "start": "3943920",
    "end": "3949440"
  },
  {
    "text": "a form in which you can contribute sorry i'm not oh wait here we go one second",
    "start": "3949440",
    "end": "3955039"
  },
  {
    "text": "initialize optimizer and loss make it maybe initialize initialize from dummy back",
    "start": "3955039",
    "end": "3961760"
  },
  {
    "text": "here we go okay so your issue is like actually in here initialize for lots from watch well not",
    "start": "3961920",
    "end": "3968640"
  },
  {
    "text": "here but here maybe initialize do you you wrote this too right you",
    "start": "3968640",
    "end": "3974640"
  },
  {
    "text": "wrote this function over here or is it something that we wrote that's original yeah that's original okay",
    "start": "3974640",
    "end": "3982480"
  },
  {
    "text": "okay so it actually doesn't like it when we try to initialize this your law something to begin with is the issue",
    "start": "3982480",
    "end": "3988960"
  },
  {
    "text": "so it has nothing to do with get state it actually has something to do with the way that we initialize your loss function",
    "start": "3988960",
    "end": "3996079"
  },
  {
    "text": "we can get here and then it says return tfo on",
    "start": "3996079",
    "end": "4001839"
  },
  {
    "text": "placeholder and then it says solar this",
    "start": "4001839",
    "end": "4007520"
  },
  {
    "text": "okay so this is the part that it's starting to like it's like",
    "start": "4007520",
    "end": "4012839"
  },
  {
    "text": "but what is the night like about this [Music] so while creating the policy it looks",
    "start": "4022400",
    "end": "4028160"
  },
  {
    "text": "like this is gonna execute and be just fine",
    "start": "4028160",
    "end": "4033079"
  },
  {
    "text": "whoa what okay we're on this using pdb and all of a sudden we're getting a different different issue",
    "start": "4051039",
    "end": "4057280"
  },
  {
    "text": "strange attribute r d has no this thing called",
    "start": "4057280",
    "end": "4063599"
  },
  {
    "text": "vf intrinsic class np okay so there doesn't exist anything like when you run this",
    "start": "4063599",
    "end": "4069760"
  },
  {
    "text": "it's possible that this error is not actually from tensorflow but it's from something like this and it's like",
    "start": "4069760",
    "end": "4074799"
  },
  {
    "text": "getting covered up right now so if i run this and this doesn't exist",
    "start": "4074799",
    "end": "4080799"
  },
  {
    "text": "then what am i supposed to do here i'm supposed to just like return in theory the",
    "start": "4080799",
    "end": "4086078"
  },
  {
    "text": "the um oh wait hold on let's do one thing let's do one thing it's like actually let's",
    "start": "4086160",
    "end": "4092559"
  },
  {
    "text": "comment all of this out for now and then let's just return like",
    "start": "4092559",
    "end": "4100798"
  },
  {
    "text": "yeah because we're in here and we actually want to run where is it that we ran your loss",
    "start": "4102799",
    "end": "4108400"
  },
  {
    "text": "function inside the loss again is that inside dynamic tf policy it's in here right",
    "start": "4108400",
    "end": "4113679"
  },
  {
    "text": "yeah yeah yeah so where where is that call again",
    "start": "4113679",
    "end": "4119120"
  },
  {
    "text": "compute loss where is that compute loss",
    "start": "4119120",
    "end": "4124159"
  },
  {
    "text": "it's not in dynamic like here it is yeah yeah",
    "start": "4124159",
    "end": "4129600"
  },
  {
    "text": "update okay so i actually want to hit this i want to",
    "start": "4129600",
    "end": "4134960"
  },
  {
    "text": "hit this branch of code in here instead of inside getstate make life a little bit easier",
    "start": "4134960",
    "end": "4141520"
  },
  {
    "text": "there's something going on here",
    "start": "4142319",
    "end": "4147839"
  },
  {
    "text": "something just tells me that this is not going to work but all right let's just i mean i know it's not going to work but",
    "start": "4153679",
    "end": "4158719"
  },
  {
    "text": "let's just see what happens and then if i go back to",
    "start": "4158719",
    "end": "4164798"
  },
  {
    "text": "get state yeah i want to just comment",
    "start": "4164799",
    "end": "4171440"
  },
  {
    "text": "all this out if i can where is uh get state called in here",
    "start": "4171440",
    "end": "4176960"
  },
  {
    "text": "does it call anyone here or is it just called elsewhere no it's called uh in callbacks",
    "start": "4176960",
    "end": "4182480"
  },
  {
    "text": "and callbacks oh that's right yeah okay but we need to just make sure that the loss is being computed properly first",
    "start": "4182480",
    "end": "4189359"
  },
  {
    "text": "so okay i'm hoping that like can avoid this branch of code for the",
    "start": "4189359",
    "end": "4194960"
  },
  {
    "text": "time being",
    "start": "4194960",
    "end": "4198198"
  },
  {
    "text": "here we go perfect okay we have vf and drinks of loss",
    "start": "4206719",
    "end": "4212320"
  },
  {
    "text": "but have the loss has been initialized first that is the question to ask right now",
    "start": "4213600",
    "end": "4220880"
  },
  {
    "text": "so i have this tensor but then like this is the one that's obviously gonna fail right yeah",
    "start": "4221199",
    "end": "4227760"
  },
  {
    "text": "it's actually this is called inside of the um maybe initialize um",
    "start": "4229040",
    "end": "4235440"
  },
  {
    "text": "uh optimizer and loss in in what's called the lsb2 pi",
    "start": "4235440",
    "end": "4241760"
  },
  {
    "text": "you're saying this function is called inside dynamic tf4cv2 yeah",
    "start": "4241760",
    "end": "4246880"
  },
  {
    "text": "so if we go into the dynamic df policy p2 there actually we see that this compute",
    "start": "4246880",
    "end": "4253440"
  },
  {
    "text": "loss and update is called by this by this loss function",
    "start": "4253440",
    "end": "4260480"
  },
  {
    "text": "function is actually replacing the original one",
    "start": "4260640",
    "end": "4266480"
  },
  {
    "text": "but just adding a term to it yes fans on location maybe we can give",
    "start": "4266480",
    "end": "4272159"
  },
  {
    "text": "him this one to chew on because he's still checking in every now and then so we can just ask him",
    "start": "4272159",
    "end": "4277440"
  },
  {
    "text": "for a little bit of help here i think at the end the solution is probably quite simple",
    "start": "4277440",
    "end": "4283679"
  },
  {
    "text": "oh it probably is you don't know where exactly this has to be done because i think this initializing um",
    "start": "4283679",
    "end": "4291679"
  },
  {
    "text": "point you give that is somehow the right direction",
    "start": "4291679",
    "end": "4296800"
  },
  {
    "text": "um yeah it's like when you run when you run this from the session it's like it shouldn't",
    "start": "4296800",
    "end": "4302960"
  },
  {
    "text": "that it should have already been initialized but it was not which is why i'm sussed okay so let's actually try",
    "start": "4302960",
    "end": "4309520"
  },
  {
    "text": "one thing let's try yeah let's try one thing which is like this colon here",
    "start": "4309520",
    "end": "4316320"
  },
  {
    "text": "uh self dot uh compute loss with sample batch it's",
    "start": "4316320",
    "end": "4323040"
  },
  {
    "text": "like if i google this let's see what happens um",
    "start": "4323040",
    "end": "4329840"
  },
  {
    "text": "okay hold on i'm gonna i'm gonna have to pause over here just because i have to get to my next meeting unfortunately",
    "start": "4330080",
    "end": "4335679"
  },
  {
    "text": "i'm really sorry that we couldn't get to the bottom of this yeah but we tried a lot so we tried a lot i think",
    "start": "4335679",
    "end": "4342560"
  },
  {
    "text": "i think like there's some i mean like as a diva as a general debugging strategy it's probably good if",
    "start": "4342560",
    "end": "4348159"
  },
  {
    "text": "you did this first you know so like i can take this and then copy it back and give it to you",
    "start": "4348159",
    "end": "4354800"
  },
  {
    "text": "oh yeah if you could just like at least look at me on slag yeah let me just yeah let me just hit you on slack with this one",
    "start": "4354800",
    "end": "4361679"
  },
  {
    "text": "i mean this is the issue with using tensorflow one yes it is but i don't know like if if we",
    "start": "4361679",
    "end": "4368800"
  },
  {
    "text": "develop something like for foray for example should it work with tf1",
    "start": "4368800",
    "end": "4376400"
  },
  {
    "text": "because i mean you you oh oh if you if you merge something in the code path no no you can merge",
    "start": "4376400",
    "end": "4382400"
  },
  {
    "text": "something that like if if you make me something that like doesn't work with tf1 but it does work with like",
    "start": "4382400",
    "end": "4388480"
  },
  {
    "text": "tf2 and it works with torch then like we just call it there that's fine because like",
    "start": "4388480",
    "end": "4394320"
  },
  {
    "text": "we have already we've already said that like we don't want to support tf1 to begin",
    "start": "4394320",
    "end": "4401199"
  },
  {
    "text": "with just because it's such a pain in the ass to support anyways yeah yeah",
    "start": "4401199",
    "end": "4407199"
  },
  {
    "text": "yeah we've actually already made that opinionated decision all right then i know",
    "start": "4407199",
    "end": "4413040"
  },
  {
    "text": "there's a uh there's a light at the tunnel so i try i'm gonna try it out a little more to figure it out",
    "start": "4413040",
    "end": "4419600"
  },
  {
    "text": "if not i might just uh give it for tft on torch so",
    "start": "4419600",
    "end": "4427840"
  },
  {
    "text": "okay cool yeah i mean it's totally fine if you just merge like tf2 and torch like i i don't want you to like be",
    "start": "4428000",
    "end": "4434159"
  },
  {
    "text": "blocked on this if this is just for the sake of like merging into rlib then yeah i mean have you modified dyna tf policy",
    "start": "4434159",
    "end": "4442239"
  },
  {
    "text": "v2 in the process though in order to make your code work um i just had this problem that i",
    "start": "4442239",
    "end": "4449199"
  },
  {
    "text": "actually have to add a certain lost term",
    "start": "4449199",
    "end": "4455840"
  },
  {
    "text": "and i was like how can i figure this out uh okay so that's actually that's actually a bigger problem than this one",
    "start": "4456239",
    "end": "4462400"
  },
  {
    "text": "just because like yeah if you're going to emerge actually yeah and then i did this actually in a",
    "start": "4462400",
    "end": "4469360"
  },
  {
    "text": "separate branch and this one is built on top on this other branch such that this part which",
    "start": "4469360",
    "end": "4475760"
  },
  {
    "text": "is like changing actually like dynamic tf policy to version two",
    "start": "4475760",
    "end": "4481360"
  },
  {
    "text": "is somewhere else and and this one is just holding building on top of it",
    "start": "4481360",
    "end": "4488719"
  },
  {
    "text": "okay yeah i see all right well that's actually like a little bit more in depth of the discussion but i i'm actually really",
    "start": "4492239",
    "end": "4498159"
  },
  {
    "text": "late to my next week so i really gotta get going yeah really really sorry about that",
    "start": "4498159",
    "end": "4503520"
  },
  {
    "text": "yeah no problem i'm very thankful for uh for your long help um",
    "start": "4503520",
    "end": "4508640"
  },
  {
    "text": "enjoy your day and uh i would say that's uh at last until this summer",
    "start": "4508640",
    "end": "4514560"
  },
  {
    "text": "yeah yeah yeah yeah i'd be really excited to see you at the summit yeah like voicemail",
    "start": "4514560",
    "end": "4520080"
  },
  {
    "text": "okay yeah do me a favor like take your question just tag us veteran and i'll text him and be like hey can you take a look at this like",
    "start": "4520080",
    "end": "4526320"
  },
  {
    "text": "nasty tensorflow issue yeah on on your branch though um",
    "start": "4526320",
    "end": "4532080"
  },
  {
    "text": "can you like make the updates that like it's somewhat runnable you know like you you",
    "start": "4532080",
    "end": "4538239"
  },
  {
    "text": "like set that variable to none you know initially etc oh yeah yeah",
    "start": "4538239",
    "end": "4543679"
  },
  {
    "text": "yeah yeah yeah yeah okay i'll make that and um yeah and then you have to include your",
    "start": "4543679",
    "end": "4549679"
  },
  {
    "text": "repro you have to yeah i mean i'll text fan to like take a look at it but also just tag him in the",
    "start": "4549679",
    "end": "4555600"
  },
  {
    "text": "in the contributor's channel too you know for you for you because he likes you he'll take a look",
    "start": "4555600",
    "end": "4562239"
  },
  {
    "text": "yeah all right take care yes take care",
    "start": "4562239",
    "end": "4567840"
  }
]
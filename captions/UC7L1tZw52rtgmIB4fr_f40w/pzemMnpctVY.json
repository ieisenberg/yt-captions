[
  {
    "start": "0",
    "end": "266000"
  },
  {
    "text": "hello everybody I'm swarup",
    "start": "4940",
    "end": "9259"
  },
  {
    "text": "and we're going to start with a story a story about forecasting so we work at a",
    "start": "10559",
    "end": "16859"
  },
  {
    "text": "company called dodash if you haven't heard of us or used our service recently",
    "start": "16859",
    "end": "22080"
  },
  {
    "text": "we are a local Commerce company collecting the local Merchant to the local customer via the local Dasher who",
    "start": "22080",
    "end": "29880"
  },
  {
    "text": "does the delivery so why is forecasting important in our context as you can",
    "start": "29880",
    "end": "36480"
  },
  {
    "text": "imagine because for real people are involved here balancing supply and demand is crucial so if you are",
    "start": "36480",
    "end": "43140"
  },
  {
    "text": "expecting more orders this weekend then we need to make sure we have enough Dashers who can deliver those orders on",
    "start": "43140",
    "end": "50520"
  },
  {
    "text": "our behalf and so we need to make sure they are recruited ahead of time these",
    "start": "50520",
    "end": "57239"
  },
  {
    "text": "are not AWS instances which we can bring up and on any any moment right similarly if we are expecting more orders next",
    "start": "57239",
    "end": "63480"
  },
  {
    "text": "weekend you can kind of imagine that we would need have more customer support tickets which means you need to have",
    "start": "63480",
    "end": "68880"
  },
  {
    "text": "more customer support agent which means we would need to tell our vendors hey we need more folks managing our answering",
    "start": "68880",
    "end": "75900"
  },
  {
    "text": "our customer support ticket so these are the reasons why forecasting is critical to us at doordash",
    "start": "75900",
    "end": "81600"
  },
  {
    "text": "now take the case of the ATS algorithm that one of the algorithms that we use when",
    "start": "81600",
    "end": "88920"
  },
  {
    "text": "there is a single time series there's just only so much data so you cannot iterate on data so what do you do you",
    "start": "88920",
    "end": "95520"
  },
  {
    "text": "need to find use a grid search to find the best model that works for the given data range that we have so the code you",
    "start": "95520",
    "end": "102119"
  },
  {
    "text": "was paralyzed using joblib and distributed across machines using joblip spark and it worked fine in terms of",
    "start": "102119",
    "end": "109619"
  },
  {
    "text": "accuracy but we had some challenges most importantly was scale given the grid",
    "start": "109619",
    "end": "116280"
  },
  {
    "text": "search that we were doing we could expect a on a one of our larger forecasts we could expect like 1.6",
    "start": "116280",
    "end": "123119"
  },
  {
    "text": "million uh model trainings now that's a lot of model training that is happening and it",
    "start": "123119",
    "end": "129660"
  },
  {
    "text": "was paralyzed using spark and the cost was super high given the value that we",
    "start": "129660",
    "end": "135000"
  },
  {
    "text": "get from it the jobs would run for several hours it would break have random error messages so it was kind of a issue",
    "start": "135000",
    "end": "143580"
  },
  {
    "text": "and that's when uh uh me and a couple of others from the machine learning platform team got",
    "start": "143580",
    "end": "149099"
  },
  {
    "text": "involved so my question was like why is this so slow like I don't understand why",
    "start": "149099",
    "end": "155160"
  },
  {
    "text": "if it is so parallelizable why is this running slow um and how can I inspect or debug what",
    "start": "155160",
    "end": "162060"
  },
  {
    "text": "happened and that's when uh I heard about Ray um and I was like oh this Ray dashboard",
    "start": "162060",
    "end": "168780"
  },
  {
    "text": "looks really cool can I make use of this uh to understand what's happening inside so in our team we have something called",
    "start": "168780",
    "end": "177120"
  },
  {
    "text": "a yak day which is kind of like a hack day where we take one day in a month to either pick up a backlog task or learn",
    "start": "177120",
    "end": "184379"
  },
  {
    "text": "about something that you've been wanting to learn so I took the yak day opportunity to learn about Ray and",
    "start": "184379",
    "end": "191280"
  },
  {
    "text": "it was a very simple hack I just took the job lines and replaced that with a ray dot",
    "start": "191280",
    "end": "198840"
  },
  {
    "text": "remote right and just literally this is the this is the actual diff this is not a made up example this is the actual",
    "start": "198840",
    "end": "204959"
  },
  {
    "text": "diff right and it was running on my laptop uh the things that I loved was you know Simplicity for a data scientist",
    "start": "204959",
    "end": "212220"
  },
  {
    "text": "or a machine learning engineer they don't have to think oh is this running on my machine is this running on several machines which was the problem with the",
    "start": "212220",
    "end": "217620"
  },
  {
    "text": "earlier code that we have you just use Ray dot remote and the ray cluster knows where to send it off to",
    "start": "217620",
    "end": "224220"
  },
  {
    "text": "um and the debugging monitoring was great I could go down to a specific task and see the log specifically for that",
    "start": "224220",
    "end": "229799"
  },
  {
    "text": "which was a far better experience than looking up a log log file of everything",
    "start": "229799",
    "end": "235080"
  },
  {
    "text": "jammed in in one log file and it was actually faster too which was surprising so",
    "start": "235080",
    "end": "241319"
  },
  {
    "text": "then we decided to actually Benchmark this like you know running on the laptop is fine but how does it actually uh mean",
    "start": "241319",
    "end": "249239"
  },
  {
    "text": "if you do a proper benchmarking and to our surprise it was 35 to 45 faster and",
    "start": "249239",
    "end": "255659"
  },
  {
    "text": "45 to 55 percent cheaper and that was really exciting for us so uh so we took",
    "start": "255659",
    "end": "261780"
  },
  {
    "text": "a decision that hey we want to double down on Ray for forecasting and that was when the story switches to distributed",
    "start": "261780",
    "end": "269520"
  },
  {
    "start": "266000",
    "end": "553000"
  },
  {
    "text": "training thanks swarup so let me first explain why we train",
    "start": "269520",
    "end": "275940"
  },
  {
    "text": "machine learning models at doordash like we have a variety of use cases and let me do that in the context of an order",
    "start": "275940",
    "end": "282419"
  },
  {
    "text": "delivery process so first we have the step of creating your order so this is",
    "start": "282419",
    "end": "287699"
  },
  {
    "text": "where you are browsing through the doordash home page and search ranking and recommendation models they play a",
    "start": "287699",
    "end": "294419"
  },
  {
    "text": "huge role here next step is the order checkout so this is where the ETA model is that is expected time of arrival they",
    "start": "294419",
    "end": "302160"
  },
  {
    "text": "try to estimate when you will receive your order and one of the most challenging things is an ETA model is",
    "start": "302160",
    "end": "308400"
  },
  {
    "text": "actually not that simple because not only the aftertake historically how long has this restaurant taken to prepare a",
    "start": "308400",
    "end": "314759"
  },
  {
    "text": "dish but you also need to know how are they are they backlogged in real time or",
    "start": "314759",
    "end": "321000"
  },
  {
    "text": "you know are they slower than usual are they faster than usual so the ETA model is actually not as simple as it sounds",
    "start": "321000",
    "end": "327539"
  },
  {
    "text": "yes and after that like we also have certain fraud detection models because when you are actually making the payment",
    "start": "327539",
    "end": "333900"
  },
  {
    "text": "we need to identify fraudulent transactions and flag them as needed next is dispatching the order so this is",
    "start": "333900",
    "end": "340919"
  },
  {
    "text": "where our Logistics team leverages several ml models like swarup mentioned",
    "start": "340919",
    "end": "346020"
  },
  {
    "text": "they compute like how much time the restaurant will take to prepare the order how much time will the Dasher take",
    "start": "346020",
    "end": "351419"
  },
  {
    "text": "to arrive at the restaurant and arrive at your place to deliver the order yeah and another example of complexity there",
    "start": "351419",
    "end": "357840"
  },
  {
    "text": "is you don't want to send the Dasher to ahead of time because if you send them 10 minutes before to the restaurant",
    "start": "357840",
    "end": "363300"
  },
  {
    "text": "they're just standing there and waiting the restaurant doesn't like it the Dasher doesn't like it but if you have",
    "start": "363300",
    "end": "368520"
  },
  {
    "text": "to dispatch them at the right time and at the same time at the right time when the order is ready for pickup not not",
    "start": "368520",
    "end": "375000"
  },
  {
    "text": "when we estimated uh it to be ready right so if the restaurants are if restaurant we detect is actually slower",
    "start": "375000",
    "end": "381360"
  },
  {
    "text": "than usual we need to dispatch the Dasher later than usual in which case the the Dasher might even change based",
    "start": "381360",
    "end": "388860"
  },
  {
    "text": "on the expected time of dispatch right so you might pick up different person to go farther and a different person to",
    "start": "388860",
    "end": "396120"
  },
  {
    "text": "go nearer depending on when is the time the time of the order to be ready yeah",
    "start": "396120",
    "end": "401340"
  },
  {
    "text": "and there are like several factors like traffic or weather conditions and which are like out of our control so we need",
    "start": "401340",
    "end": "407520"
  },
  {
    "text": "to take into account all of that as well and the final step is delivering your order so this is where we leverage ml",
    "start": "407520",
    "end": "414720"
  },
  {
    "text": "models to identify like what channels we should invest in to acquire more and more dashes on our platform and what's",
    "start": "414720",
    "end": "421620"
  },
  {
    "text": "the right time to mobilize them and we also use like image recognition deep",
    "start": "421620",
    "end": "426660"
  },
  {
    "text": "learning models to identify if the order was delivered correctly and this was particularly helpful during covet times",
    "start": "426660",
    "end": "433560"
  },
  {
    "text": "when the interaction between the customer and the Dasher was limited so in the last one and a half year or two",
    "start": "433560",
    "end": "440220"
  },
  {
    "text": "if you are about to pick up your door Dash order and you see your Dasher clicking a picture of it this is why",
    "start": "440220",
    "end": "448400"
  },
  {
    "text": "so like I said we have several use cases at dodash that we train ml models for but we have traditionally used tree",
    "start": "448440",
    "end": "455759"
  },
  {
    "text": "based or simple Pi torch models for oh okay we have used like tree based or",
    "start": "455759",
    "end": "462240"
  },
  {
    "text": "Simple Pie torch models for most of these use cases but what we were noticing now is that there was an",
    "start": "462240",
    "end": "467340"
  },
  {
    "text": "increasing number of deep learning use cases at doordash like users wanted to train larger models on larger data sets",
    "start": "467340",
    "end": "474120"
  },
  {
    "text": "in less time so we did develop a framework for distributed GPU training using",
    "start": "474120",
    "end": "480360"
  },
  {
    "text": "databricks horowat and Peta storm this was an extremely painful process it took",
    "start": "480360",
    "end": "485819"
  },
  {
    "text": "us weeks and Cornell in the audience can vouch for this it took us weeks to set this up for just one model training",
    "start": "485819",
    "end": "492360"
  },
  {
    "text": "script and even though the results were encouraging this was not easily",
    "start": "492360",
    "end": "497780"
  },
  {
    "text": "generalized across all the use cases and on the other hand ray provided easy",
    "start": "497780",
    "end": "503099"
  },
  {
    "text": "to use apis with solid documentation so this is one reason why we decided to",
    "start": "503099",
    "end": "508379"
  },
  {
    "text": "conduct a POC of sorts on Ray in Q4 2022",
    "start": "508379",
    "end": "514219"
  },
  {
    "text": "so before we dived into the POC we also ran some benchmarking uh experiments",
    "start": "514380",
    "end": "519419"
  },
  {
    "text": "like forecasting team did and the idea here was to Benchmark several model training Frameworks uh mainly on two",
    "start": "519419",
    "end": "526500"
  },
  {
    "text": "pillars cost and velocity so as you can see we benchmarked uh array data sets uh",
    "start": "526500",
    "end": "532860"
  },
  {
    "text": "Ray data sets with horowad and horowad and Peta storm as well and you can see that we saw a 46 reduction in training",
    "start": "532860",
    "end": "540600"
  },
  {
    "text": "time for two epochs and as for as far as cost is concerned we saw a 42 percent",
    "start": "540600",
    "end": "545760"
  },
  {
    "text": "reduction when we were hosting these applications on kubernetes rather than on database",
    "start": "545760",
    "end": "552500"
  },
  {
    "start": "553000",
    "end": "615000"
  },
  {
    "text": "okay I let swaroop talk about the next chapter in our story so funnily enough around this time is when we attended Ray",
    "start": "553080",
    "end": "559260"
  },
  {
    "text": "Summit last year uh and it's funny that we are actually on stage this year",
    "start": "559260",
    "end": "565200"
  },
  {
    "text": "um so one of the things that we learned at uh the first day Summit last year was uh before our training and serving",
    "start": "565200",
    "end": "571800"
  },
  {
    "text": "required a lot of integration like you want to add a new library okay you have to actually integrate it into our serving or training stack now with Ray",
    "start": "571800",
    "end": "579180"
  },
  {
    "text": "all of that came built in for free at least the most popular libraries so we didn't have to reinvent that so that",
    "start": "579180",
    "end": "585600"
  },
  {
    "text": "single point of integration was very attractive for us and this was actually uh some of the notes that we shared with",
    "start": "585600",
    "end": "591420"
  },
  {
    "text": "the team and this is actually a screenshot from the takeaway section two things resonated for us one is the spark",
    "start": "591420",
    "end": "599220"
  },
  {
    "text": "for data Ray for compute idea that seemed to be my take away from all the ray Summit talks last year so the",
    "start": "599220",
    "end": "605700"
  },
  {
    "text": "question I post to the team was just like kubernetes standardized compute infra can raise standardized ml compute",
    "start": "605700",
    "end": "611880"
  },
  {
    "text": "infra that was kind of the question we had at that time and that's when the team decided to take",
    "start": "611880",
    "end": "618660"
  },
  {
    "start": "615000",
    "end": "965000"
  },
  {
    "text": "a bet on Ray and that's when project Lucent is born so yeah like uh coupled with all the",
    "start": "618660",
    "end": "625800"
  },
  {
    "text": "interesting and encouraging benchmarking results that we just showed and all the learnings from the ray Summit as well uh",
    "start": "625800",
    "end": "632160"
  },
  {
    "text": "the ml platform team decided to make a bet on Ray for our next generation of training and inference Frameworks and",
    "start": "632160",
    "end": "638700"
  },
  {
    "text": "Lucent is the training framework that's built on top of array at doordash",
    "start": "638700",
    "end": "643800"
  },
  {
    "text": "initially we had two different uh Frameworks for forecasting and training so with Lucent we took the opportunity",
    "start": "643800",
    "end": "650399"
  },
  {
    "text": "to like unify them under one common training platform yeah the reality is I was just looking for an excuse to work",
    "start": "650399",
    "end": "655800"
  },
  {
    "text": "with double yeah because we thought forecasting is just another type of model training so",
    "start": "655800",
    "end": "661260"
  },
  {
    "text": "why have our users onboard to two different services and this greatly helped us reduce uh like duplication of",
    "start": "661260",
    "end": "667680"
  },
  {
    "text": "effort code and speed up the velocity like development velocity so Lucent is built on top of Ray and",
    "start": "667680",
    "end": "674339"
  },
  {
    "text": "Daxter while Ray is the compute backend Daxter is our orchestration engine and",
    "start": "674339",
    "end": "679920"
  },
  {
    "text": "it enables us to implement several things like continuous training which could be schedule based or if the",
    "start": "679920",
    "end": "686100"
  },
  {
    "text": "Upstream data becomes available how do I automatically trigger my training job uh Dynamic creation and tearing down of",
    "start": "686100",
    "end": "692760"
  },
  {
    "text": "clusters and all of those nice things so now I will go through some of the",
    "start": "692760",
    "end": "698459"
  },
  {
    "text": "challenges that we encountered uh during our POC uh process and these are long",
    "start": "698459",
    "end": "704040"
  },
  {
    "text": "three slides so please bear with me here uh first was of course understanding Ray",
    "start": "704040",
    "end": "709140"
  },
  {
    "text": "uh this was a completely new technology for most of us so we had to understand",
    "start": "709140",
    "end": "714240"
  },
  {
    "text": "its Concepts the apis and all the bells and whistles that it came with right but",
    "start": "714240",
    "end": "719760"
  },
  {
    "text": "the any scale team has been of great help here they are super responsive in answering all of our questions and even",
    "start": "719760",
    "end": "726120"
  },
  {
    "text": "jumping on Zoom calls if and when required so huge shout out to them here ah next was several infrastructure",
    "start": "726120",
    "end": "732600"
  },
  {
    "text": "challenges so we were setting up Ray on the existing kubernetes uh setup at",
    "start": "732600",
    "end": "738420"
  },
  {
    "text": "doordash and the kubernetes Clusters at dodash were not designed for these type of workloads they are uh technically",
    "start": "738420",
    "end": "745440"
  },
  {
    "text": "designed to host microservices at the company so we needed a lot of help from several infra teams at doordash we had",
    "start": "745440",
    "end": "753240"
  },
  {
    "text": "to make sure the Clusters got created with the right permissions to access all of our internal resources and libraries",
    "start": "753240",
    "end": "759560"
  },
  {
    "text": "next was the dynamic cluster creation so idle clusters lying around simply incur",
    "start": "759560",
    "end": "765180"
  },
  {
    "text": "a lot of cost and we noticed it would also block other clusters from getting created when limited resources were",
    "start": "765180",
    "end": "771360"
  },
  {
    "text": "available so we had to identify how do we dynamically click create clusters when needed and tear them down once the",
    "start": "771360",
    "end": "778200"
  },
  {
    "text": "job has completed so we also looked at Rays Auto scaling here so one thing we",
    "start": "778200",
    "end": "783779"
  },
  {
    "text": "would do is we would set the main worker count to zero so whenever the job is not running the workers would scale down but",
    "start": "783779",
    "end": "790860"
  },
  {
    "text": "there was a trade-off here because next time whenever the users would start a new job they would have to wait for",
    "start": "790860",
    "end": "796260"
  },
  {
    "text": "these worker nodes to come up again so we had to deal with all of these trade-offs and find a sweet spot there",
    "start": "796260",
    "end": "803360"
  },
  {
    "text": "uh next and I would say the most the biggest challenge we faced was uh",
    "start": "804240",
    "end": "809940"
  },
  {
    "text": "providing stable GPU support to our customers and some of the challenges here where we were noticing that the",
    "start": "809940",
    "end": "816480"
  },
  {
    "text": "containers would lose access to gpus after a random amount of time uh there were several incompatibility",
    "start": "816480",
    "end": "823100"
  },
  {
    "text": "incompatibilities between the Cuda and the Nvidia driver versions and on top of that we were experimenting with several",
    "start": "823100",
    "end": "829800"
  },
  {
    "text": "instance and GPU types so the Nvidia team here was of great help they would try to explain why something is",
    "start": "829800",
    "end": "836940"
  },
  {
    "text": "happening or what is happening and unblock us wherever possible and the infra teams and MLP also joined",
    "start": "836940",
    "end": "844980"
  },
  {
    "text": "hands here and made sure that Lucent reaches a stage where we can claim that our users have stable GPU support on the",
    "start": "844980",
    "end": "851639"
  },
  {
    "text": "ray clusters but after doing that the next challenge was GPU availability like",
    "start": "851639",
    "end": "856800"
  },
  {
    "text": "as we all know there's a shortage of gpus in the industry so this made us carefully estimate uh how many gpus we",
    "start": "856800",
    "end": "863940"
  },
  {
    "text": "would be needing in the near future and it helped us secure some dedicated instances which has proven really really",
    "start": "863940",
    "end": "870360"
  },
  {
    "text": "helpful to unlock some critical model training use cases at doordash",
    "start": "870360",
    "end": "875880"
  },
  {
    "text": "this is the final one I promise uh so we also had certain unforeseen customer",
    "start": "875880",
    "end": "881160"
  },
  {
    "text": "requests like we were so focused on building the infrastructure uh on making",
    "start": "881160",
    "end": "886620"
  },
  {
    "text": "sure that all the pieces align we forgot that our customers might need something totally different right uh so one common",
    "start": "886620",
    "end": "894839"
  },
  {
    "text": "uh ask there was how can we get more observability into our training jobs so",
    "start": "894839",
    "end": "900060"
  },
  {
    "text": "for that we had to build support for pi torch profiler and tensorboard we will be going over these uh in the later",
    "start": "900060",
    "end": "906779"
  },
  {
    "text": "slides and the next one was uh sometimes the underlying instance on which we are",
    "start": "906779",
    "end": "912480"
  },
  {
    "text": "hosting Ray clusters would be scheduled for maintenance or the node might restart because of disk pressure and",
    "start": "912480",
    "end": "919079"
  },
  {
    "text": "this would lead to our users losing all of their files that they had stored on the ray clusters so this was a very",
    "start": "919079",
    "end": "924959"
  },
  {
    "text": "critical ask and we had to implement support for persistent volume uh to make sure this doesn't happen again and we",
    "start": "924959",
    "end": "931800"
  },
  {
    "text": "also started exporting pod logs so whenever there would be a no no restart we could look at the logs to identify",
    "start": "931800",
    "end": "938760"
  },
  {
    "text": "what went wrong and last but not the least we completely did not estimate the huge support",
    "start": "938760",
    "end": "945180"
  },
  {
    "text": "overhead that came with this as I said understanding Ray was a big challenge for us but it was an even bigger",
    "start": "945180",
    "end": "952139"
  },
  {
    "text": "challenge to educate our customers about tree so there were so many questions so",
    "start": "952139",
    "end": "957839"
  },
  {
    "text": "many doubts and there are so many nuances today that each and every question required like a different type",
    "start": "957839",
    "end": "963300"
  },
  {
    "text": "of investigation on our part okay we are done with the challenges uh",
    "start": "963300",
    "end": "969899"
  },
  {
    "start": "965000",
    "end": "1217000"
  },
  {
    "text": "now what did we build with Lucent so at a high level we built two different workflows for development and production",
    "start": "969899",
    "end": "976560"
  },
  {
    "text": "and these are like some important differences between the two so the dev",
    "start": "976560",
    "end": "981720"
  },
  {
    "text": "workflow was intended to provide our users with a notebooking environment for faster iterations so they can try out",
    "start": "981720",
    "end": "988139"
  },
  {
    "text": "different model architectures really quickly but once they are happy with their model",
    "start": "988139",
    "end": "993779"
  },
  {
    "text": "architecture or their training script they need to commit this code to a centralized GitHub repository",
    "start": "993779",
    "end": "999860"
  },
  {
    "text": "this way we ensure reproducibility and we also make sure that every model in",
    "start": "999860",
    "end": "1005180"
  },
  {
    "text": "production has gone through code reviews surprisingly these two things were really really important to our customers",
    "start": "1005180",
    "end": "1011000"
  },
  {
    "text": "yeah if you ever had the challenge like where's the training script for this model then this is how we solved for it yeah fun story we were actually looking",
    "start": "1011000",
    "end": "1018680"
  },
  {
    "text": "at implementing direct deployment from the dev environment itself but our customers were the ones who said no we",
    "start": "1018680",
    "end": "1025280"
  },
  {
    "text": "are fine with uh lesser development velocity but we do want our code to be checked in so that was a fun learning",
    "start": "1025280",
    "end": "1031938"
  },
  {
    "text": "there okay so let's do a quick walkthrough of these two uh environments so this is our",
    "start": "1031939",
    "end": "1039438"
  },
  {
    "text": "code repository so uh basically they clone this uh repo and they create a new",
    "start": "1039439",
    "end": "1045500"
  },
  {
    "text": "project directory within it as you can see we have a project directory here called Ray Summit demo uh this directory",
    "start": "1045500",
    "end": "1052280"
  },
  {
    "text": "must have the job config yaml that you see here",
    "start": "1052280",
    "end": "1057220"
  },
  {
    "text": "and this job config file is where the users can Define exactly what resources they want for example here we are",
    "start": "1057320",
    "end": "1064100"
  },
  {
    "text": "creating a ray cluster with four worker nodes actually two worker nodes with four gpus on each and it can also",
    "start": "1064100",
    "end": "1071660"
  },
  {
    "text": "contain a list of all the libraries that they want us to install on their clusters and some metadata like uh slack",
    "start": "1071660",
    "end": "1079160"
  },
  {
    "text": "IDs for notifications and timely updates once the project directory is ready they",
    "start": "1079160",
    "end": "1086480"
  },
  {
    "text": "need to run this one command which will create the ray cluster for them as per this job spec that I just showed you and",
    "start": "1086480",
    "end": "1093620"
  },
  {
    "text": "it will also transfer all the files in their project directory to the remote Ray cluster",
    "start": "1093620",
    "end": "1098780"
  },
  {
    "text": "now in the end they just need to visit this URL that you see in the end to get to the notebooking environment",
    "start": "1098780",
    "end": "1106160"
  },
  {
    "text": "so this is the ray dashboard as you can see the cluster is created two worker nodes with four gpus on each",
    "start": "1106160",
    "end": "1112880"
  },
  {
    "text": "and this is the notebooking environment that I was talking about so on the left if you see the ray Summit demo project",
    "start": "1112880",
    "end": "1118820"
  },
  {
    "text": "directory has been copied over for them on top of that we also provide a simple",
    "start": "1118820",
    "end": "1124640"
  },
  {
    "text": "starter onboarding notebook for them they only need to update the command and",
    "start": "1124640",
    "end": "1130039"
  },
  {
    "text": "the working directory to Kickstart a new Ray job so we have this Lucent library that",
    "start": "1130039",
    "end": "1136100"
  },
  {
    "text": "tries to abstract away a lot of boilerplate array code for them so just by running the submit command they would",
    "start": "1136100",
    "end": "1142400"
  },
  {
    "text": "have kickstarted array job and in response they get certain URLs like where is the job running uh what are the",
    "start": "1142400",
    "end": "1149600"
  },
  {
    "text": "metrics and the tensorboard and Pi torch profiler Pages as well",
    "start": "1149600",
    "end": "1154899"
  },
  {
    "text": "so as you can see this is the tensorboard page for the job that got started",
    "start": "1155059",
    "end": "1160640"
  },
  {
    "text": "this is the ray cluster metrics page so we don't want them navigating through these different pages we are providing",
    "start": "1160640",
    "end": "1167179"
  },
  {
    "text": "them the required URLs then and there over here they can have a look at certain metrics like what's the GPU",
    "start": "1167179",
    "end": "1173120"
  },
  {
    "text": "usage like or what's the disk pressure and things like that and finally when they are done",
    "start": "1173120",
    "end": "1179539"
  },
  {
    "text": "experimenting on the notebooking environment they will merge that code in and the CD process will handle creating",
    "start": "1179539",
    "end": "1186200"
  },
  {
    "text": "a new dagster job for them now once they can now they can come to the dagget UI play with the job config",
    "start": "1186200",
    "end": "1193160"
  },
  {
    "text": "here and use the command line arguments to run the same job multiple times with different parameters if needed",
    "start": "1193160",
    "end": "1200240"
  },
  {
    "text": "so as you can see here all of these three jobs were kickstarted at the same time just with different parameters so",
    "start": "1200240",
    "end": "1206600"
  },
  {
    "text": "essentially you could Kickstart a llama 7B 13B 70b fine tuning job at the same",
    "start": "1206600",
    "end": "1212539"
  },
  {
    "text": "time once you know what the architecture and the data is so along with leveraging Ray for model",
    "start": "1212539",
    "end": "1221000"
  },
  {
    "start": "1217000",
    "end": "1244000"
  },
  {
    "text": "training we also built our next generation of inference platform on top of it and that is called argil now I am",
    "start": "1221000",
    "end": "1227360"
  },
  {
    "text": "not going to go into much details here because Sid and Cornell from Double Dash are presenting exactly this tomorrow but",
    "start": "1227360",
    "end": "1233900"
  },
  {
    "text": "at a high level argil is focused on extensibility flexibility and GPU",
    "start": "1233900",
    "end": "1239059"
  },
  {
    "text": "inference so do attend their talk tomorrow if you are interested to learn more",
    "start": "1239059",
    "end": "1244940"
  },
  {
    "start": "1244000",
    "end": "1319000"
  },
  {
    "text": "and I hand it back to swarook yeah and so this is what Roger Lucent was so how",
    "start": "1244940",
    "end": "1250760"
  },
  {
    "text": "did we benefit from it right and I would say the BET paid off because as I'm sure you're away from the keynote today llms",
    "start": "1250760",
    "end": "1257059"
  },
  {
    "text": "happened now the question was how do we support it right and we it took us all by surprise but uh folks were interested",
    "start": "1257059",
    "end": "1264919"
  },
  {
    "text": "in fine-tuning open source models like Falcon and now as of the last few months it's Lama so how do we support that and",
    "start": "1264919",
    "end": "1273320"
  },
  {
    "text": "the challenges was that there were things like data parallelism model parallelism uh multiple GPU support all",
    "start": "1273320",
    "end": "1280340"
  },
  {
    "text": "of these things that we needed to figure out and uh luckily for us the any scale",
    "start": "1280340",
    "end": "1285440"
  },
  {
    "text": "team was providing support for this on top of Ray and that's how we were able to support llms uh fast uh now in the",
    "start": "1285440",
    "end": "1292760"
  },
  {
    "text": "process we had to figure out what is an A10 what is 800 what is 800 what is V100 I'm sure many of you have learned these",
    "start": "1292760",
    "end": "1298580"
  },
  {
    "text": "in the past year along with us as well my takeaway is that if you are not bad",
    "start": "1298580",
    "end": "1303919"
  },
  {
    "text": "on Rave would have easily lost six months in trying to figure out our llm story and because we already had a ray",
    "start": "1303919",
    "end": "1310039"
  },
  {
    "text": "train Ray training and Ray serving in place and any scale kept adding llm support we were able to move fast on",
    "start": "1310039",
    "end": "1317240"
  },
  {
    "text": "llms um so what do we use Lucent for the we have training dnns or deep neural",
    "start": "1317240",
    "end": "1325460"
  },
  {
    "text": "networks uh data parallelism via Ray data sets model parallelism via deep speed all of these things again was",
    "start": "1325460",
    "end": "1333200"
  },
  {
    "text": "possible because of the single point of integration which is Ray fine-tuning llms and GPU training so",
    "start": "1333200",
    "end": "1339860"
  },
  {
    "text": "these are all the new functionality that we added in the past one year thanks to building on top of Ray",
    "start": "1339860",
    "end": "1345700"
  },
  {
    "start": "1345000",
    "end": "1482000"
  },
  {
    "text": "so what's next as you noticed the GPU stability",
    "start": "1345700",
    "end": "1352419"
  },
  {
    "text": "challenges that we had one of the things was we wanted to one of the advice that",
    "start": "1352419",
    "end": "1357559"
  },
  {
    "text": "we got from Nvidia was to switch to their GPU operator and we had some other challenges as well because of which our",
    "start": "1357559",
    "end": "1364640"
  },
  {
    "text": "infra our compute team decided that migrating to AWS elastic kubernetes was",
    "start": "1364640",
    "end": "1369919"
  },
  {
    "text": "a better path so we have just started on that Journey um getting started for machine learning",
    "start": "1369919",
    "end": "1377000"
  },
  {
    "text": "Engineers need to be much faster so we are thinking of adding templates um so hey you want to do a llama llama",
    "start": "1377000",
    "end": "1382580"
  },
  {
    "text": "training template here you go like here here's your template you can just punch in your data and get started all right",
    "start": "1382580",
    "end": "1388400"
  },
  {
    "text": "uh easy saving and loading of checkpoints a lot of times we get the request from saying Hey I want to save",
    "start": "1388400",
    "end": "1394039"
  },
  {
    "text": "this checkpoint and continue training epochs later how do I do that right now it's a it's a manual process and we are",
    "start": "1394039",
    "end": "1400580"
  },
  {
    "text": "hoping to streamline that uh and who here hasn't faced dependency held in Python",
    "start": "1400580",
    "end": "1406299"
  },
  {
    "text": "so one of the major problems in stability for our mlas is like hey it's",
    "start": "1406299",
    "end": "1412460"
  },
  {
    "text": "just not working what's this magic combination of Library versions that works and we are trying to figure out a",
    "start": "1412460",
    "end": "1418580"
  },
  {
    "text": "story there hopefully have some standard package combinations available and ready",
    "start": "1418580",
    "end": "1423679"
  },
  {
    "text": "for our mlas to use and so that they don't have to figure this out on their own",
    "start": "1423679",
    "end": "1429020"
  },
  {
    "text": "um and one of the interesting challenges we faced recently was the node the GPU runs out of memory and",
    "start": "1429020",
    "end": "1437539"
  },
  {
    "text": "the node dies and all that the user sees this actor died because node died and they're like oh Ray is not working uh",
    "start": "1437539",
    "end": "1443720"
  },
  {
    "text": "and when we dig into the logs it's like oh actually we ran out of memory or you have ran out of disk so we want to",
    "start": "1443720",
    "end": "1449059"
  },
  {
    "text": "preempt that discussion by proactively sending slack alerts to the user saying hey your cluster is running out of",
    "start": "1449059",
    "end": "1454520"
  },
  {
    "text": "memory or running out of GPU and so and I've often also seen the case where they",
    "start": "1454520",
    "end": "1460100"
  },
  {
    "text": "use four out of the eight available gpus on that single machine and then run out of GPU memory right like oh no use all",
    "start": "1460100",
    "end": "1467360"
  },
  {
    "text": "the eight gpus right and similarly the dev clusters are running all all the time now so we we are depending on good",
    "start": "1467360",
    "end": "1474620"
  },
  {
    "text": "faith of MLS to shut down when they are not using it so obviously that's not a long term solution so we want to",
    "start": "1474620",
    "end": "1480380"
  },
  {
    "text": "introduce idle shutdown as well um so yeah with that closing thoughts uh",
    "start": "1480380",
    "end": "1486620"
  },
  {
    "start": "1482000",
    "end": "1573000"
  },
  {
    "text": "velocity and efficiency are evergreen we were looking at Dev velocity and that's why we started looking at Ray and",
    "start": "1486620",
    "end": "1493340"
  },
  {
    "text": "it turns out we got efficiency as well by Ray reducing costs for us so because",
    "start": "1493340",
    "end": "1498679"
  },
  {
    "text": "of velocity and efficiency or not focused it was an easy sell within our platform team uh bet on open source",
    "start": "1498679",
    "end": "1505280"
  },
  {
    "text": "projects like Ray all of us are here because Ray is open source um some of the do's and don'ts is",
    "start": "1505280",
    "end": "1512360"
  },
  {
    "text": "um have sample benchmarks for mles they are always constantly asking us Hey what how much have you benchmarked this for",
    "start": "1512360",
    "end": "1518720"
  },
  {
    "text": "can I train a billion data points right and they expect answers to uh to these questions which we are",
    "start": "1518720",
    "end": "1524900"
  },
  {
    "text": "working towards have sample projects like the cookie cutter templates any scale office hours was very helpful",
    "start": "1524900",
    "end": "1531200"
  },
  {
    "text": "because we are not the experts on Ray any scale is so getting them in and getting them directly to answer",
    "start": "1531200",
    "end": "1536299"
  },
  {
    "text": "questions was super helpful some don'ts don't assume Emily is understand Ray they understand pie torch",
    "start": "1536299",
    "end": "1542539"
  },
  {
    "text": "they understand ml but they do not understand Ray and Bridging the Gap is something that we are working towards uh",
    "start": "1542539",
    "end": "1548419"
  },
  {
    "text": "don't position Ray as a replacement for pi torch it's just different part of the stack Ray is",
    "start": "1548419",
    "end": "1555159"
  },
  {
    "text": "at a much lower level in the stack than by torch or Koda issues so there are",
    "start": "1555159",
    "end": "1560419"
  },
  {
    "text": "different parts of the stack often we ran into the issue where folks thought the ray should have solved the Cuda",
    "start": "1560419",
    "end": "1566840"
  },
  {
    "text": "issues which is not at all the case because there are different parts of the stack so with that yeah we are hiring so if",
    "start": "1566840",
    "end": "1575900"
  },
  {
    "start": "1573000",
    "end": "1861000"
  },
  {
    "text": "folks are interested in working on things like this please let us know and we have three and a half minutes left so",
    "start": "1575900",
    "end": "1581360"
  },
  {
    "text": "if there are any questions would love to take them yeah hi uh hi um so I have two questions the",
    "start": "1581360",
    "end": "1589100"
  },
  {
    "text": "first is you mentioned that you have any skill office hours like how does that work like do do you it's a support",
    "start": "1589100",
    "end": "1595880"
  },
  {
    "text": "contract uh with them so so do you use manage rate by any scale no we do not we",
    "start": "1595880",
    "end": "1602480"
  },
  {
    "text": "are running in-house uh as of now uh managed uh any scale hosting is an option for us in the future uh but right",
    "start": "1602480",
    "end": "1609559"
  },
  {
    "text": "now we are running Ray in-house using the cube Ray operator uh but any scale officers is more for answering questions",
    "start": "1609559",
    "end": "1616220"
  },
  {
    "text": "ah if mlas have questions about how do I do this how do I checkpoint in Ray we",
    "start": "1616220",
    "end": "1621260"
  },
  {
    "text": "may not be the experts on that so we have folks from any scale coming in and answering questions call it that's awesome so it's only for support yes",
    "start": "1621260",
    "end": "1628159"
  },
  {
    "text": "okay that's awesome the second question I have is uh for project Evolution and and upcoming projects like how big is a",
    "start": "1628159",
    "end": "1636020"
  },
  {
    "text": "team behind it so Lucent itself was built by I would say two two and a half Engineers",
    "start": "1636020",
    "end": "1641919"
  },
  {
    "text": "uh depending on you know how long you count someone's contributions so yeah two two and a half Engineers over the",
    "start": "1641919",
    "end": "1648020"
  },
  {
    "text": "past year is what I would say God thank you so much",
    "start": "1648020",
    "end": "1652778"
  },
  {
    "text": "so you mentioned that for last year's takeaway you use spark for the data",
    "start": "1660620",
    "end": "1666159"
  },
  {
    "text": "processing and use array for the training and inference so for today are",
    "start": "1666159",
    "end": "1671480"
  },
  {
    "text": "you still using the spark for the data preprocessing or you use you plan to use array data for pre-processing part",
    "start": "1671480",
    "end": "1678320"
  },
  {
    "text": "great question so are we still using spark or we're using the ray data right",
    "start": "1678320",
    "end": "1683720"
  },
  {
    "text": "um our experience has been and we have uh benchmarked on prototyped task and",
    "start": "1683720",
    "end": "1690980"
  },
  {
    "text": "what's the other one modern model along with Ray the the truth is those projects",
    "start": "1690980",
    "end": "1697100"
  },
  {
    "text": "are still early uh they they are useful if you are already on Ray but since we",
    "start": "1697100",
    "end": "1702380"
  },
  {
    "text": "already have a spark setup nothing I mean spark is like just way ahead right now I still think spark for data a for",
    "start": "1702380",
    "end": "1709039"
  },
  {
    "text": "compute is is the best way to go for now uh where Ray data is super helpful is",
    "start": "1709039",
    "end": "1714799"
  },
  {
    "text": "for loading the data for training right and Ray data is still the best option there",
    "start": "1714799",
    "end": "1720620"
  },
  {
    "text": "yeah and how do you resolve the currently the transition between smart",
    "start": "1720620",
    "end": "1726500"
  },
  {
    "text": "data and then use Ray so we use uh so we have a dodash data Lake that acts as the",
    "start": "1726500",
    "end": "1733880"
  },
  {
    "text": "Gateway across so we have a we have a blog post on this called uh on doordash",
    "start": "1733880",
    "end": "1739580"
  },
  {
    "text": "uh it's a system called fabricator so our mle's come in right fabricator code",
    "start": "1739580",
    "end": "1744799"
  },
  {
    "text": "check in the script and again we use Daxter to run the data generation on a daily hourly whenever they need it and",
    "start": "1744799",
    "end": "1751279"
  },
  {
    "text": "it writes to the data Lake and you can use the same fabricator IPA apis in the",
    "start": "1751279",
    "end": "1757159"
  },
  {
    "text": "training to load back the same data for training and again we are using radiator",
    "start": "1757159",
    "end": "1762380"
  },
  {
    "text": "to read that in but it's written in a standardized like parquet you know the standard data Lake stuff and then read",
    "start": "1762380",
    "end": "1768740"
  },
  {
    "text": "back with easy to use apis that were provided internally does that answer your question yeah so any like a pension",
    "start": "1768740",
    "end": "1775640"
  },
  {
    "text": "Market you guys had done or any performance bottlenecks sorry sorry any Benchmark you guys had done by like you",
    "start": "1775640",
    "end": "1781220"
  },
  {
    "text": "know use in the reading and write out data reading and writing benchmarking are you talking about the data lake or",
    "start": "1781220",
    "end": "1787159"
  },
  {
    "text": "the data about the data Lake because you know you're using spark and then you spark to Output the data then you ready",
    "start": "1787159",
    "end": "1793940"
  },
  {
    "text": "to read in the data right so those are the extra step and also just curious about you know what's like a performance",
    "start": "1793940",
    "end": "1799580"
  },
  {
    "text": "look like I'm not sure if you've done any benchmarks yeah something we have done",
    "start": "1799580",
    "end": "1804679"
  },
  {
    "text": "benchmarking for this there are two totally different services like even the data that's written on data Lake it's",
    "start": "1804679",
    "end": "1811340"
  },
  {
    "text": "not just being consumed for model training I I know we did a benchmark to decide on the format like are we going",
    "start": "1811340",
    "end": "1817100"
  },
  {
    "text": "with Iceberg are we going with parquet or with something else I believe there was a whole host of considerations and",
    "start": "1817100",
    "end": "1822919"
  },
  {
    "text": "our data platform Tech Steering group decided on uh what was it Delta Delta as",
    "start": "1822919",
    "end": "1829940"
  },
  {
    "text": "our final format so I believe there was benchmarking for that but not the radiation side of",
    "start": "1829940",
    "end": "1836779"
  },
  {
    "text": "things yeah yeah okay no problem thank you sure",
    "start": "1836779",
    "end": "1841240"
  },
  {
    "text": "maybe uh there's one more question here get offline okay sure sure yeah looks",
    "start": "1844480",
    "end": "1851720"
  },
  {
    "text": "like we're out of time uh thank you everybody thanks for listening thank you",
    "start": "1851720",
    "end": "1857260"
  }
]
[
  {
    "text": "oh yeah that's right thank you hey hi",
    "start": "3419",
    "end": "6180"
  },
  {
    "text": "everyone a lot of familiar faces uh",
    "start": "6180",
    "end": "8519"
  },
  {
    "text": "thanks all for coming I'm Carlos Costa",
    "start": "8519",
    "end": "10620"
  },
  {
    "text": "from IBM research I'm the tech lead the",
    "start": "10620",
    "end": "12660"
  },
  {
    "text": "foundation model platforms at research",
    "start": "12660",
    "end": "14700"
  },
  {
    "text": "worked very close with a red hat our",
    "start": "14700",
    "end": "16920"
  },
  {
    "text": "friends and I have my co-speaker here at",
    "start": "16920",
    "end": "18840"
  },
  {
    "text": "the name hi everyone thank you all for",
    "start": "18840",
    "end": "20699"
  },
  {
    "text": "coming I'm tanim Ibrahim I am an",
    "start": "20699",
    "end": "22800"
  },
  {
    "text": "engineering leader at openshift I",
    "start": "22800",
    "end": "24660"
  },
  {
    "text": "practically focus on openshift AI",
    "start": "24660",
    "end": "26720"
  },
  {
    "text": "inferencing workload as well as",
    "start": "26720",
    "end": "29039"
  },
  {
    "text": "trustworthy Ai and model registry",
    "start": "29039",
    "end": "31500"
  },
  {
    "text": "Solutions",
    "start": "31500",
    "end": "33920"
  },
  {
    "text": "let's take you through our effort to",
    "start": "33920",
    "end": "37200"
  },
  {
    "text": "build an end-to-end platform for",
    "start": "37200",
    "end": "38940"
  },
  {
    "text": "foundational models we don't have our",
    "start": "38940",
    "end": "41700"
  },
  {
    "text": "third speaker here Nick Hill he couldn't",
    "start": "41700",
    "end": "43260"
  },
  {
    "text": "make it so our effort is all about how",
    "start": "43260",
    "end": "45600"
  },
  {
    "text": "we can simplify again the end-to-end",
    "start": "45600",
    "end": "47640"
  },
  {
    "text": "lifecycle Foundation mode from data",
    "start": "47640",
    "end": "49320"
  },
  {
    "text": "pre-processing training fine tuning and",
    "start": "49320",
    "end": "51899"
  },
  {
    "text": "serving right I want to kind of",
    "start": "51899",
    "end": "54360"
  },
  {
    "text": "highlight some of the emerging",
    "start": "54360",
    "end": "55440"
  },
  {
    "text": "challenges right I've been talking about",
    "start": "55440",
    "end": "56640"
  },
  {
    "text": "this during the summit but I want to",
    "start": "56640",
    "end": "58920"
  },
  {
    "text": "kind of use this to really anchor what",
    "start": "58920",
    "end": "61320"
  },
  {
    "text": "are like the new things that you've seen",
    "start": "61320",
    "end": "63000"
  },
  {
    "text": "why Foundation model is different from a",
    "start": "63000",
    "end": "64619"
  },
  {
    "text": "platform perspective right and how we",
    "start": "64619",
    "end": "66600"
  },
  {
    "text": "can build a fully integrated open",
    "start": "66600",
    "end": "68580"
  },
  {
    "text": "sources stack for this right we've seen",
    "start": "68580",
    "end": "71939"
  },
  {
    "text": "this inflection point right there is no",
    "start": "71939",
    "end": "73560"
  },
  {
    "text": "doubt about this so what is really",
    "start": "73560",
    "end": "75180"
  },
  {
    "text": "changes like the economy of bringing AI",
    "start": "75180",
    "end": "77939"
  },
  {
    "text": "to the Enterprise right we all know that",
    "start": "77939",
    "end": "80520"
  },
  {
    "text": "for a long time doing AI Enterprise",
    "start": "80520",
    "end": "83100"
  },
  {
    "text": "would mean that you go to a use case you",
    "start": "83100",
    "end": "85740"
  },
  {
    "text": "do all the hard work of finding the data",
    "start": "85740",
    "end": "88500"
  },
  {
    "text": "labeling the data right",
    "start": "88500",
    "end": "91140"
  },
  {
    "text": "picking a model or an architectural",
    "start": "91140",
    "end": "93659"
  },
  {
    "text": "model training this model validating and",
    "start": "93659",
    "end": "96420"
  },
  {
    "text": "finally deployment deploying in",
    "start": "96420",
    "end": "98939"
  },
  {
    "text": "practices you take like at least a year",
    "start": "98939",
    "end": "101460"
  },
  {
    "text": "right and this is for one use case you",
    "start": "101460",
    "end": "103799"
  },
  {
    "text": "need to basically go through this the",
    "start": "103799",
    "end": "105299"
  },
  {
    "text": "same process right for Second Use case a",
    "start": "105299",
    "end": "108180"
  },
  {
    "text": "third use case right very costly very",
    "start": "108180",
    "end": "110280"
  },
  {
    "text": "very prohibitively I'm sorry what",
    "start": "110280",
    "end": "113880"
  },
  {
    "text": "happens here is that this is the reason",
    "start": "113880",
    "end": "116340"
  },
  {
    "text": "why we haven't seen adoption of AI in",
    "start": "116340",
    "end": "118740"
  },
  {
    "text": "the Enterprise living up to the",
    "start": "118740",
    "end": "120780"
  },
  {
    "text": "expectation that you all had right it",
    "start": "120780",
    "end": "122880"
  },
  {
    "text": "was very cost costly what changed here",
    "start": "122880",
    "end": "125340"
  },
  {
    "text": "is that with the foundation models now",
    "start": "125340",
    "end": "127799"
  },
  {
    "text": "you can start with a pre-trained model",
    "start": "127799",
    "end": "129239"
  },
  {
    "text": "right it's much less investment or some",
    "start": "129239",
    "end": "132060"
  },
  {
    "text": "investment upfront you can start with",
    "start": "132060",
    "end": "133739"
  },
  {
    "text": "something that's precaine and then you",
    "start": "133739",
    "end": "136080"
  },
  {
    "text": "can fine tune this model heard this many",
    "start": "136080",
    "end": "137520"
  },
  {
    "text": "times what happens now is that you can",
    "start": "137520",
    "end": "139860"
  },
  {
    "text": "apply the same model to different use",
    "start": "139860",
    "end": "141840"
  },
  {
    "text": "cases right fine-tuning this model is",
    "start": "141840",
    "end": "144120"
  },
  {
    "text": "much less costly right you can use much",
    "start": "144120",
    "end": "147000"
  },
  {
    "text": "less labeling data labeling right and",
    "start": "147000",
    "end": "149580"
  },
  {
    "text": "then now you can go to more that's why",
    "start": "149580",
    "end": "151920"
  },
  {
    "text": "the Enterprise got so much about",
    "start": "151920",
    "end": "153540"
  },
  {
    "text": "foundational models these days right so",
    "start": "153540",
    "end": "155819"
  },
  {
    "text": "if you go to the next step the next",
    "start": "155819",
    "end": "157260"
  },
  {
    "text": "lighting standing uh this is again that",
    "start": "157260",
    "end": "159840"
  },
  {
    "text": "means a workflow meaning that you have",
    "start": "159840",
    "end": "162420"
  },
  {
    "text": "to go through these steps and the uh the",
    "start": "162420",
    "end": "164879"
  },
  {
    "text": "difference is that these Tabs are very",
    "start": "164879",
    "end": "166379"
  },
  {
    "text": "much heterogeneous right when you talk",
    "start": "166379",
    "end": "168000"
  },
  {
    "text": "about their pre-processing for example",
    "start": "168000",
    "end": "169519"
  },
  {
    "text": "uh uh for data print processing many",
    "start": "169519",
    "end": "171959"
  },
  {
    "text": "times you just need like say CPUs right",
    "start": "171959",
    "end": "174060"
  },
  {
    "text": "it's kind of scale out a very simple",
    "start": "174060",
    "end": "176220"
  },
  {
    "text": "filtering type of computation right when",
    "start": "176220",
    "end": "178860"
  },
  {
    "text": "it comes to training uh this is way more",
    "start": "178860",
    "end": "182099"
  },
  {
    "text": "like a hard specific you need a network",
    "start": "182099",
    "end": "184019"
  },
  {
    "text": "and so on right and of course when you",
    "start": "184019",
    "end": "186180"
  },
  {
    "text": "go to like all the way to inference",
    "start": "186180",
    "end": "187500"
  },
  {
    "text": "you're talking about throughput right",
    "start": "187500",
    "end": "189480"
  },
  {
    "text": "latency uh inference closer to the data",
    "start": "189480",
    "end": "192840"
  },
  {
    "text": "right we all know this but the point is",
    "start": "192840",
    "end": "195360"
  },
  {
    "text": "that how you put together a platform",
    "start": "195360",
    "end": "197819"
  },
  {
    "text": "that can cover the whole spectrum of",
    "start": "197819",
    "end": "199980"
  },
  {
    "text": "these workflows right what are these",
    "start": "199980",
    "end": "202019"
  },
  {
    "text": "standards how you can simplify the life",
    "start": "202019",
    "end": "203700"
  },
  {
    "text": "of the user as I go through this",
    "start": "203700",
    "end": "205640"
  },
  {
    "text": "workflow when you talk about the",
    "start": "205640",
    "end": "208920"
  },
  {
    "text": "challenges uh we talk a lot about the",
    "start": "208920",
    "end": "211080"
  },
  {
    "text": "scale and of course training is hard",
    "start": "211080",
    "end": "214800"
  },
  {
    "text": "when you go to billions of parameters",
    "start": "214800",
    "end": "217280"
  },
  {
    "text": "the problem is also is on the",
    "start": "217280",
    "end": "220319"
  },
  {
    "text": "integration right if you look at this",
    "start": "220319",
    "end": "222780"
  },
  {
    "text": "environment is very fragmented one of",
    "start": "222780",
    "end": "225000"
  },
  {
    "text": "the key pain points and you keep hearing",
    "start": "225000",
    "end": "226620"
  },
  {
    "text": "this across most of the talks in the",
    "start": "226620",
    "end": "228959"
  },
  {
    "text": "Summit is the fact now that you have to",
    "start": "228959",
    "end": "230819"
  },
  {
    "text": "combine different tools right and how we",
    "start": "230819",
    "end": "235019"
  },
  {
    "text": "put them together is one of the biggest",
    "start": "235019",
    "end": "236819"
  },
  {
    "text": "challenges right so what do you do for",
    "start": "236819",
    "end": "239280"
  },
  {
    "text": "now is basically take you through our",
    "start": "239280",
    "end": "241739"
  },
  {
    "text": "point of view how we're putting this",
    "start": "241739",
    "end": "243720"
  },
  {
    "text": "together of course leverage array but",
    "start": "243720",
    "end": "246000"
  },
  {
    "text": "also other open source tools that we",
    "start": "246000",
    "end": "248459"
  },
  {
    "text": "also contributing and how we all",
    "start": "248459",
    "end": "250920"
  },
  {
    "text": "bringing this together Enterprise ready",
    "start": "250920",
    "end": "252659"
  },
  {
    "text": "application in some of the use cases as",
    "start": "252659",
    "end": "254640"
  },
  {
    "text": "well thank you Carlos",
    "start": "254640",
    "end": "257220"
  },
  {
    "text": "so",
    "start": "257220",
    "end": "259079"
  },
  {
    "text": "one key theme in all the talks at this",
    "start": "259079",
    "end": "262500"
  },
  {
    "text": "Summit so far has been around",
    "start": "262500",
    "end": "264120"
  },
  {
    "text": "collaborating in open source various",
    "start": "264120",
    "end": "266400"
  },
  {
    "text": "open store Upstream communities for llm",
    "start": "266400",
    "end": "269040"
  },
  {
    "text": "training fine-tuning prompting",
    "start": "269040",
    "end": "270840"
  },
  {
    "text": "inferencing all the primary workloads",
    "start": "270840",
    "end": "273840"
  },
  {
    "text": "they're all built around open source",
    "start": "273840",
    "end": "275160"
  },
  {
    "text": "that's where we're at race Summit so so",
    "start": "275160",
    "end": "277199"
  },
  {
    "text": "AI is clearly driven by open source it's",
    "start": "277199",
    "end": "279840"
  },
  {
    "text": "the new model of innovation everything",
    "start": "279840",
    "end": "281940"
  },
  {
    "text": "from pytarch to code to Ray to",
    "start": "281940",
    "end": "285240"
  },
  {
    "text": "tensorflow they're all advancing at",
    "start": "285240",
    "end": "287699"
  },
  {
    "text": "lightning speed due to the power of Open",
    "start": "287699",
    "end": "289979"
  },
  {
    "text": "Source and collaborative nature across",
    "start": "289979",
    "end": "291780"
  },
  {
    "text": "various communities so red hat has",
    "start": "291780",
    "end": "294360"
  },
  {
    "text": "always been historically been a trusted",
    "start": "294360",
    "end": "296040"
  },
  {
    "text": "advisor in open source and we're doing",
    "start": "296040",
    "end": "298259"
  },
  {
    "text": "the same we're helping guide our",
    "start": "298259",
    "end": "300300"
  },
  {
    "text": "customers through this ever-changing AI",
    "start": "300300",
    "end": "302940"
  },
  {
    "text": "landscape and this is why we established",
    "start": "302940",
    "end": "305280"
  },
  {
    "text": "open data Hub community so open data Hub",
    "start": "305280",
    "end": "308040"
  },
  {
    "text": "is a project that allows that brings",
    "start": "308040",
    "end": "310139"
  },
  {
    "text": "best of breed High AIML tools from",
    "start": "310139",
    "end": "314160"
  },
  {
    "text": "labeling through partner ecosystem",
    "start": "314160",
    "end": "316400"
  },
  {
    "text": "through open pytorch with various",
    "start": "316400",
    "end": "320280"
  },
  {
    "text": "notebooks support in various inferencing",
    "start": "320280",
    "end": "323340"
  },
  {
    "text": "technology through k-serv and model mesh",
    "start": "323340",
    "end": "325380"
  },
  {
    "text": "all of that comes towards in one open",
    "start": "325380",
    "end": "327960"
  },
  {
    "text": "one Community where you can easily",
    "start": "327960",
    "end": "330360"
  },
  {
    "text": "deploy that platform and and enable",
    "start": "330360",
    "end": "333120"
  },
  {
    "text": "organizations to run the AI workload so",
    "start": "333120",
    "end": "336360"
  },
  {
    "text": "if you look at historically what red hat",
    "start": "336360",
    "end": "337800"
  },
  {
    "text": "has done with various other open source",
    "start": "337800",
    "end": "340139"
  },
  {
    "text": "projects so from Fedora to Enterprise",
    "start": "340139",
    "end": "341940"
  },
  {
    "text": "Linux or from kubernetes to openshift we",
    "start": "341940",
    "end": "345720"
  },
  {
    "text": "are doing the same with open data Hub",
    "start": "345720",
    "end": "347580"
  },
  {
    "text": "and we're taking open data hub learnings",
    "start": "347580",
    "end": "349620"
  },
  {
    "text": "from it and we're building openshift AI",
    "start": "349620",
    "end": "353780"
  },
  {
    "text": "now how can we actually apply the same",
    "start": "353880",
    "end": "357660"
  },
  {
    "text": "open source first mindset to building a",
    "start": "357660",
    "end": "361020"
  },
  {
    "text": "foundation model",
    "start": "361020",
    "end": "362360"
  },
  {
    "text": "workload for the Enterprise right so",
    "start": "362360",
    "end": "364680"
  },
  {
    "text": "with open data Hub we have open source",
    "start": "364680",
    "end": "366360"
  },
  {
    "text": "based Frameworks for training fine and",
    "start": "366360",
    "end": "368280"
  },
  {
    "text": "fine-tuning and prompting and also",
    "start": "368280",
    "end": "370380"
  },
  {
    "text": "serving Foundation models these projects",
    "start": "370380",
    "end": "372660"
  },
  {
    "text": "all of them reside in their own Upstream",
    "start": "372660",
    "end": "374940"
  },
  {
    "text": "communities and then we take them and we",
    "start": "374940",
    "end": "378660"
  },
  {
    "text": "use the open data Hub operator",
    "start": "378660",
    "end": "380039"
  },
  {
    "text": "orchestrator do you provide an",
    "start": "380039",
    "end": "382680"
  },
  {
    "text": "end-to-end deployment stack for",
    "start": "382680",
    "end": "384840"
  },
  {
    "text": "e-customers to easily prescriptively",
    "start": "384840",
    "end": "387060"
  },
  {
    "text": "deploy a stack for trading tuning models",
    "start": "387060",
    "end": "390060"
  },
  {
    "text": "inferencing with models trustworthy AI",
    "start": "390060",
    "end": "392520"
  },
  {
    "text": "having a model registry integrated and",
    "start": "392520",
    "end": "395340"
  },
  {
    "text": "also be able to do metrics",
    "start": "395340",
    "end": "397220"
  },
  {
    "text": "modeling monitoring everything that an",
    "start": "397220",
    "end": "399600"
  },
  {
    "text": "Enterprise great foundational model",
    "start": "399600",
    "end": "401340"
  },
  {
    "text": "workload would require",
    "start": "401340",
    "end": "403620"
  },
  {
    "text": "um and and then once the incubation is",
    "start": "403620",
    "end": "406020"
  },
  {
    "text": "done in this Midstream open GitHub",
    "start": "406020",
    "end": "407520"
  },
  {
    "text": "Community we take them to openshift AI",
    "start": "407520",
    "end": "410220"
  },
  {
    "text": "as an Enterprise offering",
    "start": "410220",
    "end": "413360"
  },
  {
    "text": "um so let's dive further let's dive a",
    "start": "413819",
    "end": "416460"
  },
  {
    "text": "little bit more into the actual training",
    "start": "416460",
    "end": "418319"
  },
  {
    "text": "and validation stack uh so uh for on the",
    "start": "418319",
    "end": "421860"
  },
  {
    "text": "left hand side of this diagram you'll",
    "start": "421860",
    "end": "423780"
  },
  {
    "text": "see the stack that represents how an",
    "start": "423780",
    "end": "426120"
  },
  {
    "text": "open data Hub and openshift AI a user",
    "start": "426120",
    "end": "429060"
  },
  {
    "text": "would run their training and fine-tuning",
    "start": "429060",
    "end": "431220"
  },
  {
    "text": "and prompt tuning workload so code flare",
    "start": "431220",
    "end": "433919"
  },
  {
    "text": "at the top that provides data scientists",
    "start": "433919",
    "end": "436080"
  },
  {
    "text": "enamel Engineers a very simple pythonic",
    "start": "436080",
    "end": "438780"
  },
  {
    "text": "way of starts burning up any large",
    "start": "438780",
    "end": "442860"
  },
  {
    "text": "training cluster so let's say you have a",
    "start": "442860",
    "end": "445319"
  },
  {
    "text": "ray job and you have to run a ray train",
    "start": "445319",
    "end": "446819"
  },
  {
    "text": "job you can literally do that from your",
    "start": "446819",
    "end": "448620"
  },
  {
    "text": "laptop with the code for SDK and submit",
    "start": "448620",
    "end": "451919"
  },
  {
    "text": "jobs that will spawn up large-scale rate",
    "start": "451919",
    "end": "454740"
  },
  {
    "text": "clusters depending on the type of number",
    "start": "454740",
    "end": "457620"
  },
  {
    "text": "of gpus you need number of nodes you",
    "start": "457620",
    "end": "459599"
  },
  {
    "text": "need across across across your AWS cloud",
    "start": "459599",
    "end": "462780"
  },
  {
    "text": "or other Cloud providers also",
    "start": "462780",
    "end": "466259"
  },
  {
    "text": "under the hood with cold flare we have",
    "start": "466259",
    "end": "469020"
  },
  {
    "text": "um MCAT which stands for multi-cluster",
    "start": "469020",
    "end": "471000"
  },
  {
    "text": "app dispatcher that is essentially a",
    "start": "471000",
    "end": "473280"
  },
  {
    "text": "batch scheduler that works with the",
    "start": "473280",
    "end": "475800"
  },
  {
    "text": "actual underlying provider be its",
    "start": "475800",
    "end": "478259"
  },
  {
    "text": "on-prem or in the cloud to instantiate",
    "start": "478259",
    "end": "480660"
  },
  {
    "text": "all those jobs it could be a pytorch job",
    "start": "480660",
    "end": "483780"
  },
  {
    "text": "could be a raindrop could be a spark job",
    "start": "483780",
    "end": "485400"
  },
  {
    "text": "as long as the job type is defined it",
    "start": "485400",
    "end": "487860"
  },
  {
    "text": "goes and stashes that for you and not",
    "start": "487860",
    "end": "490080"
  },
  {
    "text": "only that it instantiates the cluster",
    "start": "490080",
    "end": "491819"
  },
  {
    "text": "for you it also looks at when your",
    "start": "491819",
    "end": "495240"
  },
  {
    "text": "workload is no longer needed it actually",
    "start": "495240",
    "end": "497280"
  },
  {
    "text": "shrinks down the cluster so you save on",
    "start": "497280",
    "end": "499139"
  },
  {
    "text": "your GPU cost you save on your overall",
    "start": "499139",
    "end": "501539"
  },
  {
    "text": "AWS quota or any other cloud provider",
    "start": "501539",
    "end": "503699"
  },
  {
    "text": "quota cost now you need something that",
    "start": "503699",
    "end": "507060"
  },
  {
    "text": "will actually guarantee that you can go",
    "start": "507060",
    "end": "509220"
  },
  {
    "text": "and scale right so how would how would",
    "start": "509220",
    "end": "511919"
  },
  {
    "text": "MCAT know that you need your AWS cluster",
    "start": "511919",
    "end": "514800"
  },
  {
    "text": "and you actually have the coda to be",
    "start": "514800",
    "end": "517500"
  },
  {
    "text": "able to spawn that and make that large",
    "start": "517500",
    "end": "520200"
  },
  {
    "text": "cluster and that's where instascale",
    "start": "520200",
    "end": "522419"
  },
  {
    "text": "comes into play so instascale works with",
    "start": "522419",
    "end": "524940"
  },
  {
    "text": "your native quota management system and",
    "start": "524940",
    "end": "528180"
  },
  {
    "text": "knows that okay how much Coda do you",
    "start": "528180",
    "end": "529920"
  },
  {
    "text": "have in this provider for you to how",
    "start": "529920",
    "end": "532140"
  },
  {
    "text": "much scaling up you can do with number",
    "start": "532140",
    "end": "534000"
  },
  {
    "text": "of gpus number of nodes number of let's",
    "start": "534000",
    "end": "535980"
  },
  {
    "text": "say ec2 instances with FBS or openshift",
    "start": "535980",
    "end": "539339"
  },
  {
    "text": "and nodes underneath the hood so and it",
    "start": "539339",
    "end": "542760"
  },
  {
    "text": "also allows you to do priority queuing",
    "start": "542760",
    "end": "544800"
  },
  {
    "text": "so let's say you have jobs that are",
    "start": "544800",
    "end": "546360"
  },
  {
    "text": "higher priority and you have multiple",
    "start": "546360",
    "end": "548339"
  },
  {
    "text": "tenants within your cluster they all are",
    "start": "548339",
    "end": "550440"
  },
  {
    "text": "fighting for the same GPU workload to do",
    "start": "550440",
    "end": "553019"
  },
  {
    "text": "their training jobs or training jobs it",
    "start": "553019",
    "end": "554820"
  },
  {
    "text": "will actually can assign a priority to",
    "start": "554820",
    "end": "556380"
  },
  {
    "text": "those jobs and it will actually go and",
    "start": "556380",
    "end": "557940"
  },
  {
    "text": "share the resources in a fair fair and",
    "start": "557940",
    "end": "560640"
  },
  {
    "text": "Fair Way",
    "start": "560640",
    "end": "563060"
  },
  {
    "text": "now moving on to the inference side of",
    "start": "563279",
    "end": "566760"
  },
  {
    "text": "the stack so everything's for the LNF",
    "start": "566760",
    "end": "570060"
  },
  {
    "text": "mops Journey for our users starts with",
    "start": "570060",
    "end": "572940"
  },
  {
    "text": "k-serv at the at the top so K services",
    "start": "572940",
    "end": "576300"
  },
  {
    "text": "are controller uh we work with the case",
    "start": "576300",
    "end": "578519"
  },
  {
    "text": "of community very closely that actually",
    "start": "578519",
    "end": "580940"
  },
  {
    "text": "takes all the different stack that we",
    "start": "580940",
    "end": "583680"
  },
  {
    "text": "have with kkit compositional AI kit and",
    "start": "583680",
    "end": "586860"
  },
  {
    "text": "text generation inference service and",
    "start": "586860",
    "end": "589260"
  },
  {
    "text": "I'm going to dive a little bit deeper",
    "start": "589260",
    "end": "590339"
  },
  {
    "text": "into those two stack so",
    "start": "590339",
    "end": "593399"
  },
  {
    "text": "um cake it essentially is is a is an",
    "start": "593399",
    "end": "597300"
  },
  {
    "text": "abstraction layer which is a python",
    "start": "597300",
    "end": "599880"
  },
  {
    "text": "based API so that a data scientist or an",
    "start": "599880",
    "end": "602940"
  },
  {
    "text": "app developer doesn't necessarily need",
    "start": "602940",
    "end": "604800"
  },
  {
    "text": "to know about the intricate details",
    "start": "604800",
    "end": "606600"
  },
  {
    "text": "behind kubernetes crds or how how do you",
    "start": "606600",
    "end": "609899"
  },
  {
    "text": "work with the cube API it essentially",
    "start": "609899",
    "end": "611899"
  },
  {
    "text": "abstracts all of that out into a simple",
    "start": "611899",
    "end": "615180"
  },
  {
    "text": "set of apis that allows an app developer",
    "start": "615180",
    "end": "617700"
  },
  {
    "text": "to take a model and apply different",
    "start": "617700",
    "end": "620459"
  },
  {
    "text": "operations to a model so it could be get",
    "start": "620459",
    "end": "622080"
  },
  {
    "text": "a model that's deployed in the class",
    "start": "622080",
    "end": "623279"
  },
  {
    "text": "today or you could register that model",
    "start": "623279",
    "end": "626339"
  },
  {
    "text": "you could do run prompt tuning jobs with",
    "start": "626339",
    "end": "628560"
  },
  {
    "text": "that model but you don't necessarily",
    "start": "628560",
    "end": "630000"
  },
  {
    "text": "have to know all the details behind how",
    "start": "630000",
    "end": "633480"
  },
  {
    "text": "to do that because a lot of app",
    "start": "633480",
    "end": "634620"
  },
  {
    "text": "developers are not machine learning",
    "start": "634620",
    "end": "636060"
  },
  {
    "text": "Engineers they may not know all this",
    "start": "636060",
    "end": "637860"
  },
  {
    "text": "workflow right so that's where we have",
    "start": "637860",
    "end": "639959"
  },
  {
    "text": "developed kkit to provide that",
    "start": "639959",
    "end": "642720"
  },
  {
    "text": "orchestration behind the scene and not",
    "start": "642720",
    "end": "644640"
  },
  {
    "text": "only that it also kind of organizes",
    "start": "644640",
    "end": "646860"
  },
  {
    "text": "different model formats into one single",
    "start": "646860",
    "end": "648899"
  },
  {
    "text": "formatted API so your model could be a",
    "start": "648899",
    "end": "651360"
  },
  {
    "text": "foundation model with pytorch but it",
    "start": "651360",
    "end": "653040"
  },
  {
    "text": "could also be a SK learn model for",
    "start": "653040",
    "end": "654839"
  },
  {
    "text": "example for a classification type of use",
    "start": "654839",
    "end": "657240"
  },
  {
    "text": "case it will it will the API do not",
    "start": "657240",
    "end": "659220"
  },
  {
    "text": "change based on your model type it",
    "start": "659220",
    "end": "660660"
  },
  {
    "text": "provides the same abstraction layer for",
    "start": "660660",
    "end": "662880"
  },
  {
    "text": "you",
    "start": "662880",
    "end": "664260"
  },
  {
    "text": "um another important part of this",
    "start": "664260",
    "end": "665940"
  },
  {
    "text": "component stack is the tjs so which",
    "start": "665940",
    "end": "668040"
  },
  {
    "text": "stands for a text Generation Um",
    "start": "668040",
    "end": "669959"
  },
  {
    "text": "inference service so sex generation",
    "start": "669959",
    "end": "671760"
  },
  {
    "text": "inference service is a very early Fork",
    "start": "671760",
    "end": "675360"
  },
  {
    "text": "of hugging face text generation in",
    "start": "675360",
    "end": "677399"
  },
  {
    "text": "France project so those of you who have",
    "start": "677399",
    "end": "679500"
  },
  {
    "text": "worked in llm serving space probably",
    "start": "679500",
    "end": "681300"
  },
  {
    "text": "have heard of TGI so we forked a hugging",
    "start": "681300",
    "end": "686160"
  },
  {
    "text": "phase one dot some version of it from",
    "start": "686160",
    "end": "689100"
  },
  {
    "text": "the community into a tg's sections",
    "start": "689100",
    "end": "691200"
  },
  {
    "text": "reference service and the primary reason",
    "start": "691200",
    "end": "693360"
  },
  {
    "text": "um we did that was essentially around",
    "start": "693360",
    "end": "696060"
  },
  {
    "text": "adding a lot of enhancements for the",
    "start": "696060",
    "end": "699300"
  },
  {
    "text": "inferencing side so one of the",
    "start": "699300",
    "end": "700740"
  },
  {
    "text": "enhancements we added working with",
    "start": "700740",
    "end": "702480"
  },
  {
    "text": "hugging Place Community is around",
    "start": "702480",
    "end": "703680"
  },
  {
    "text": "continuous batching so that multiple",
    "start": "703680",
    "end": "706740"
  },
  {
    "text": "different type of workloads inference",
    "start": "706740",
    "end": "708240"
  },
  {
    "text": "workloads which are similar in nature",
    "start": "708240",
    "end": "711000"
  },
  {
    "text": "could be batched and could be run and",
    "start": "711000",
    "end": "713339"
  },
  {
    "text": "scheduled in GPU very efficiently since",
    "start": "713339",
    "end": "715320"
  },
  {
    "text": "you know fighting for GPU continues it's",
    "start": "715320",
    "end": "717600"
  },
  {
    "text": "hard to get gpus it makes it very",
    "start": "717600",
    "end": "719579"
  },
  {
    "text": "efficient we also looked at options like",
    "start": "719579",
    "end": "722700"
  },
  {
    "text": "um",
    "start": "722700",
    "end": "723480"
  },
  {
    "text": "wow we also work with meta and and the",
    "start": "723480",
    "end": "726540"
  },
  {
    "text": "pytorch community to contribute to the",
    "start": "726540",
    "end": "728880"
  },
  {
    "text": "pytorch 2.0 compilation of those models",
    "start": "728880",
    "end": "731399"
  },
  {
    "text": "which have provided amazing speed ups",
    "start": "731399",
    "end": "733800"
  },
  {
    "text": "for models that are like llama 2 or 70",
    "start": "733800",
    "end": "736980"
  },
  {
    "text": "billion plus level parameter models",
    "start": "736980",
    "end": "739680"
  },
  {
    "text": "and um and then we also uh work with the",
    "start": "739680",
    "end": "742860"
  },
  {
    "text": "tensorflow community to uh for the",
    "start": "742860",
    "end": "744779"
  },
  {
    "text": "tensor parallel nature so that we can do",
    "start": "744779",
    "end": "746820"
  },
  {
    "text": "sharding for the large uh large language",
    "start": "746820",
    "end": "748800"
  },
  {
    "text": "models across multiple GPU which",
    "start": "748800",
    "end": "751500"
  },
  {
    "text": "essentially allows you to have reduced",
    "start": "751500",
    "end": "754320"
  },
  {
    "text": "latency around it",
    "start": "754320",
    "end": "757260"
  },
  {
    "text": "um going to hand it back over to Carlos",
    "start": "757260",
    "end": "759899"
  },
  {
    "text": "thanks Tony and be on top of all this",
    "start": "759899",
    "end": "762899"
  },
  {
    "text": "great open source innovations that we're",
    "start": "762899",
    "end": "764940"
  },
  {
    "text": "building uh we have launched the Watson",
    "start": "764940",
    "end": "768000"
  },
  {
    "text": "X platform uh this is one of the most",
    "start": "768000",
    "end": "770940"
  },
  {
    "text": "important offerings IBM has right now",
    "start": "770940",
    "end": "772980"
  },
  {
    "text": "this is a of course a response to all",
    "start": "772980",
    "end": "775560"
  },
  {
    "text": "like the demand and challenge that we",
    "start": "775560",
    "end": "777180"
  },
  {
    "text": "see in the industry to go after",
    "start": "777180",
    "end": "778380"
  },
  {
    "text": "foundational models as you can see again",
    "start": "778380",
    "end": "780959"
  },
  {
    "text": "it goes across all the like life cycle",
    "start": "780959",
    "end": "784380"
  },
  {
    "text": "that I mentioned before it has three",
    "start": "784380",
    "end": "786360"
  },
  {
    "text": "components Watson x dot AI which is for",
    "start": "786360",
    "end": "789480"
  },
  {
    "text": "like the training validation and",
    "start": "789480",
    "end": "791220"
  },
  {
    "text": "fine-tuning this includes some of the",
    "start": "791220",
    "end": "793200"
  },
  {
    "text": "recipes UI studio safeguards all of that",
    "start": "793200",
    "end": "797579"
  },
  {
    "text": "right to train these models to fine-tune",
    "start": "797579",
    "end": "800279"
  },
  {
    "text": "them into inference then what's an extra",
    "start": "800279",
    "end": "802440"
  },
  {
    "text": "data this is a very important piece we",
    "start": "802440",
    "end": "804540"
  },
  {
    "text": "all know that data is the most important",
    "start": "804540",
    "end": "806820"
  },
  {
    "text": "component when you train your model what",
    "start": "806820",
    "end": "808920"
  },
  {
    "text": "we've seen the industry today is pretty",
    "start": "808920",
    "end": "810779"
  },
  {
    "text": "much like wild west where you're",
    "start": "810779",
    "end": "812279"
  },
  {
    "text": "training data I'm sorry training models",
    "start": "812279",
    "end": "814260"
  },
  {
    "text": "across data that you might not have full",
    "start": "814260",
    "end": "816420"
  },
  {
    "text": "control or for permission right and",
    "start": "816420",
    "end": "819540"
  },
  {
    "text": "there are many issues with the models",
    "start": "819540",
    "end": "821279"
  },
  {
    "text": "getting like legal troubles because of",
    "start": "821279",
    "end": "823620"
  },
  {
    "text": "the data what's an extra data is our",
    "start": "823620",
    "end": "826339"
  },
  {
    "text": "approach to have a curated data set not",
    "start": "826339",
    "end": "829800"
  },
  {
    "text": "only like the data set itself but the",
    "start": "829800",
    "end": "831720"
  },
  {
    "text": "tooling to do things like filtering have",
    "start": "831720",
    "end": "834779"
  },
  {
    "text": "removal hating abuse speech removal",
    "start": "834779",
    "end": "836880"
  },
  {
    "text": "right license identification language",
    "start": "836880",
    "end": "840180"
  },
  {
    "text": "identification also no way to bring",
    "start": "840180",
    "end": "842399"
  },
  {
    "text": "Enterprise data right so if you want to",
    "start": "842399",
    "end": "844260"
  },
  {
    "text": "want to bring your own data as well so",
    "start": "844260",
    "end": "847139"
  },
  {
    "text": "it's a created data set to train our own",
    "start": "847139",
    "end": "850019"
  },
  {
    "text": "models but also engage with clients and",
    "start": "850019",
    "end": "852240"
  },
  {
    "text": "what's an x.governance these models are",
    "start": "852240",
    "end": "855000"
  },
  {
    "text": "only good uh based on like the output",
    "start": "855000",
    "end": "857519"
  },
  {
    "text": "they provide in the field meaning that",
    "start": "857519",
    "end": "859500"
  },
  {
    "text": "you have to be very careful with the",
    "start": "859500",
    "end": "861480"
  },
  {
    "text": "things like Thrift or even like hate and",
    "start": "861480",
    "end": "864480"
  },
  {
    "text": "abuse speech in the model output right",
    "start": "864480",
    "end": "866760"
  },
  {
    "text": "or things like a change in regulation",
    "start": "866760",
    "end": "870440"
  },
  {
    "text": "for example you have like a user a given",
    "start": "870440",
    "end": "874019"
  },
  {
    "text": "data set with a given license to train",
    "start": "874019",
    "end": "875639"
  },
  {
    "text": "your model but there was some change",
    "start": "875639",
    "end": "876959"
  },
  {
    "text": "you're not allowed to have that data set",
    "start": "876959",
    "end": "878880"
  },
  {
    "text": "in the mix anymore how you track these",
    "start": "878880",
    "end": "881040"
  },
  {
    "text": "things triggering like a retraining",
    "start": "881040",
    "end": "882779"
  },
  {
    "text": "replacement of the model right so dot",
    "start": "882779",
    "end": "885180"
  },
  {
    "text": "coven is all about the safeguards around",
    "start": "885180",
    "end": "887100"
  },
  {
    "text": "using these models in the field so this",
    "start": "887100",
    "end": "889500"
  },
  {
    "text": "is a solution for the Enterprise right",
    "start": "889500",
    "end": "891899"
  },
  {
    "text": "uh if you go to the next one uh just to",
    "start": "891899",
    "end": "894959"
  },
  {
    "text": "position",
    "start": "894959",
    "end": "896339"
  },
  {
    "text": "um what's an ax across what we just",
    "start": "896339",
    "end": "898560"
  },
  {
    "text": "discussed right so at the bottom we have",
    "start": "898560",
    "end": "900660"
  },
  {
    "text": "openshift ai as the platform as the",
    "start": "900660",
    "end": "903240"
  },
  {
    "text": "building block this is the open source",
    "start": "903240",
    "end": "905399"
  },
  {
    "text": "integrated stack that they described and",
    "start": "905399",
    "end": "907380"
  },
  {
    "text": "then on top of it we add in this kind of",
    "start": "907380",
    "end": "909480"
  },
  {
    "text": "value add right things like again the",
    "start": "909480",
    "end": "912600"
  },
  {
    "text": "models themselves the IBM is producing",
    "start": "912600",
    "end": "915620"
  },
  {
    "text": "things like a studio",
    "start": "915620",
    "end": "917899"
  },
  {
    "text": "safeguards",
    "start": "917899",
    "end": "919579"
  },
  {
    "text": "and so on right so this is how you kind",
    "start": "919579",
    "end": "922680"
  },
  {
    "text": "of look at the across the stack what I",
    "start": "922680",
    "end": "924540"
  },
  {
    "text": "want to do now is to take you through",
    "start": "924540",
    "end": "926399"
  },
  {
    "text": "some use cases and deployments right we",
    "start": "926399",
    "end": "929880"
  },
  {
    "text": "have some very significant interesting",
    "start": "929880",
    "end": "932339"
  },
  {
    "text": "validation for this uh stack so if you",
    "start": "932339",
    "end": "934800"
  },
  {
    "text": "move to the next one the first of is",
    "start": "934800",
    "end": "936899"
  },
  {
    "text": "actually deploying this at scale right",
    "start": "936899",
    "end": "938480"
  },
  {
    "text": "we all know that when it comes to",
    "start": "938480",
    "end": "941160"
  },
  {
    "text": "training large models you need very",
    "start": "941160",
    "end": "943440"
  },
  {
    "text": "specialized infrastructure so what I",
    "start": "943440",
    "end": "945600"
  },
  {
    "text": "showed here is that this stack it's",
    "start": "945600",
    "end": "948600"
  },
  {
    "text": "pretty much portable meaning that you",
    "start": "948600",
    "end": "950519"
  },
  {
    "text": "can run this on commodity variable but",
    "start": "950519",
    "end": "952380"
  },
  {
    "text": "also on very specialized ones so what",
    "start": "952380",
    "end": "954600"
  },
  {
    "text": "I'm showing here is a develop",
    "start": "954600",
    "end": "957000"
  },
  {
    "text": "supercomputer so this is something that",
    "start": "957000",
    "end": "958740"
  },
  {
    "text": "IBM put together using a",
    "start": "958740",
    "end": "960959"
  },
  {
    "text": "state-of-the-art infrastructure things",
    "start": "960959",
    "end": "963360"
  },
  {
    "text": "like a 100 gpus with nodes with eight",
    "start": "963360",
    "end": "967320"
  },
  {
    "text": "a100s per node A specialized networking",
    "start": "967320",
    "end": "970680"
  },
  {
    "text": "but we're doing the all of this with the",
    "start": "970680",
    "end": "973139"
  },
  {
    "text": "cloud control plane meaning that to",
    "start": "973139",
    "end": "975120"
  },
  {
    "text": "visualizing these nodes right and he",
    "start": "975120",
    "end": "977519"
  },
  {
    "text": "made some very interesting decisions",
    "start": "977519",
    "end": "978660"
  },
  {
    "text": "here for like the network for example",
    "start": "978660",
    "end": "980279"
  },
  {
    "text": "everybody goes with infinity band for",
    "start": "980279",
    "end": "982019"
  },
  {
    "text": "many reasons we demonstrate that you can",
    "start": "982019",
    "end": "984360"
  },
  {
    "text": "actually save a network you can do",
    "start": "984360",
    "end": "986279"
  },
  {
    "text": "ethernet with some of the tricks at the",
    "start": "986279",
    "end": "988680"
  },
  {
    "text": "stack to do a better computation and",
    "start": "988680",
    "end": "991980"
  },
  {
    "text": "communication",
    "start": "991980",
    "end": "993139"
  },
  {
    "text": "collocation right in placement and",
    "start": "993139",
    "end": "995519"
  },
  {
    "text": "ensure that you can actually these to",
    "start": "995519",
    "end": "997259"
  },
  {
    "text": "very large models more important message",
    "start": "997259",
    "end": "999779"
  },
  {
    "text": "is that with these environment we can do",
    "start": "999779",
    "end": "1003320"
  },
  {
    "text": "like the whole life cycle with one",
    "start": "1003320",
    "end": "1004759"
  },
  {
    "text": "single stack users don't have to",
    "start": "1004759",
    "end": "1006800"
  },
  {
    "text": "actually worry about the underlying face",
    "start": "1006800",
    "end": "1009139"
  },
  {
    "text": "structure itself right all of this is",
    "start": "1009139",
    "end": "1010940"
  },
  {
    "text": "kind of abstracted you start with your",
    "start": "1010940",
    "end": "1012800"
  },
  {
    "text": "SDK you say uh you provide like inputs",
    "start": "1012800",
    "end": "1016579"
  },
  {
    "text": "for resource utilization and so on and",
    "start": "1016579",
    "end": "1018800"
  },
  {
    "text": "the stack takes care of actually placing",
    "start": "1018800",
    "end": "1020660"
  },
  {
    "text": "this uh what we have running these uh",
    "start": "1020660",
    "end": "1023420"
  },
  {
    "text": "environment today anything from like a",
    "start": "1023420",
    "end": "1026178"
  },
  {
    "text": "single GPU job all the way to a job that",
    "start": "1026179",
    "end": "1029058"
  },
  {
    "text": "takes like five to six hundred gpus per",
    "start": "1029059",
    "end": "1032660"
  },
  {
    "text": "single job right",
    "start": "1032660",
    "end": "1034120"
  },
  {
    "text": "these environment supports preemption",
    "start": "1034120",
    "end": "1036980"
  },
  {
    "text": "right meaning that you can have like a",
    "start": "1036980",
    "end": "1039438"
  },
  {
    "text": "low product jobs that can be preempted",
    "start": "1039439",
    "end": "1041839"
  },
  {
    "text": "by like some production runs that you",
    "start": "1041839",
    "end": "1044298"
  },
  {
    "text": "need to kind of take precedence right",
    "start": "1044299",
    "end": "1046640"
  },
  {
    "text": "and all of this again on the same",
    "start": "1046640",
    "end": "1048199"
  },
  {
    "text": "platform so this is not aspirational",
    "start": "1048199",
    "end": "1050120"
  },
  {
    "text": "we're running actually this internet for",
    "start": "1050120",
    "end": "1052160"
  },
  {
    "text": "production for models but we're also",
    "start": "1052160",
    "end": "1054559"
  },
  {
    "text": "taking these to other environments uh on",
    "start": "1054559",
    "end": "1057080"
  },
  {
    "text": "this slide that shows someone like the",
    "start": "1057080",
    "end": "1059179"
  },
  {
    "text": "speeds and feeds the benefits that",
    "start": "1059179",
    "end": "1060740"
  },
  {
    "text": "you're getting with the with this stack",
    "start": "1060740",
    "end": "1062240"
  },
  {
    "text": "on the left hand side with Ray something",
    "start": "1062240",
    "end": "1065179"
  },
  {
    "text": "that we're doing is really kind of",
    "start": "1065179",
    "end": "1066799"
  },
  {
    "text": "unifying the pipeline across one single",
    "start": "1066799",
    "end": "1069500"
  },
  {
    "text": "runtime right I talked about the",
    "start": "1069500",
    "end": "1071720"
  },
  {
    "text": "fragmentation how hard sometimes it is",
    "start": "1071720",
    "end": "1073820"
  },
  {
    "text": "to combine different things right we had",
    "start": "1073820",
    "end": "1076460"
  },
  {
    "text": "this internally at IBM as well meaning",
    "start": "1076460",
    "end": "1078860"
  },
  {
    "text": "that some of the teams would be using",
    "start": "1078860",
    "end": "1080419"
  },
  {
    "text": "spark or they write in their own kind of",
    "start": "1080419",
    "end": "1082340"
  },
  {
    "text": "ad hoc python code to scale bringing all",
    "start": "1082340",
    "end": "1086240"
  },
  {
    "text": "together around the ray API allowed us",
    "start": "1086240",
    "end": "1088400"
  },
  {
    "text": "to run this as a pipeline meaning that",
    "start": "1088400",
    "end": "1090919"
  },
  {
    "text": "now any of my user can actually submit",
    "start": "1090919",
    "end": "1093260"
  },
  {
    "text": "this without a specific knowledge about",
    "start": "1093260",
    "end": "1095960"
  },
  {
    "text": "the implementation right it's more like",
    "start": "1095960",
    "end": "1098059"
  },
  {
    "text": "a unified",
    "start": "1098059",
    "end": "1099580"
  },
  {
    "text": "in all our steps to pre-process are",
    "start": "1099580",
    "end": "1102380"
  },
  {
    "text": "mostly now running with Ray what we saw",
    "start": "1102380",
    "end": "1104660"
  },
  {
    "text": "in the field was that we went from like",
    "start": "1104660",
    "end": "1106700"
  },
  {
    "text": "a days mostly to coordinate across",
    "start": "1106700",
    "end": "1109400"
  },
  {
    "text": "different runs to something that now",
    "start": "1109400",
    "end": "1111380"
  },
  {
    "text": "runs in minutes to hours right just",
    "start": "1111380",
    "end": "1114020"
  },
  {
    "text": "because we're able to do like better",
    "start": "1114020",
    "end": "1115400"
  },
  {
    "text": "coordination because across these steps",
    "start": "1115400",
    "end": "1117460"
  },
  {
    "text": "on the right hand side as the animation",
    "start": "1117460",
    "end": "1120320"
  },
  {
    "text": "we have a very close collaboration with",
    "start": "1120320",
    "end": "1121940"
  },
  {
    "text": "pathological mint as well if you have a",
    "start": "1121940",
    "end": "1123980"
  },
  {
    "text": "scene we made some big announcements",
    "start": "1123980",
    "end": "1125360"
  },
  {
    "text": "around this one of them is around the",
    "start": "1125360",
    "end": "1128000"
  },
  {
    "text": "API for training we are one of the",
    "start": "1128000",
    "end": "1130820"
  },
  {
    "text": "contributors to fstp fully charged data",
    "start": "1130820",
    "end": "1133580"
  },
  {
    "text": "parallel the super training approach",
    "start": "1133580",
    "end": "1135799"
  },
  {
    "text": "which is part of my thoughts and we can",
    "start": "1135799",
    "end": "1137720"
  },
  {
    "text": "run this on top of Ray as well when you",
    "start": "1137720",
    "end": "1140000"
  },
  {
    "text": "do this you get some very very good uh",
    "start": "1140000",
    "end": "1143419"
  },
  {
    "text": "parallel efficiency in fact able to",
    "start": "1143419",
    "end": "1146000"
  },
  {
    "text": "train models up to 11 billion parameters",
    "start": "1146000",
    "end": "1147919"
  },
  {
    "text": "with up to 90 percent parallel",
    "start": "1147919",
    "end": "1149900"
  },
  {
    "text": "efficiency which is state of the art in",
    "start": "1149900",
    "end": "1151580"
  },
  {
    "text": "the industry again all of this is",
    "start": "1151580",
    "end": "1153919"
  },
  {
    "text": "absolutely abstracted in terms of like",
    "start": "1153919",
    "end": "1156440"
  },
  {
    "text": "access to infrastructure right so if you",
    "start": "1156440",
    "end": "1158600"
  },
  {
    "text": "bring your pytorch fsdp code here you",
    "start": "1158600",
    "end": "1161840"
  },
  {
    "text": "can run on this platform without any",
    "start": "1161840",
    "end": "1163460"
  },
  {
    "text": "change we use Rave orchestration gpus",
    "start": "1163460",
    "end": "1166220"
  },
  {
    "text": "and discussion underneath everything's",
    "start": "1166220",
    "end": "1168620"
  },
  {
    "text": "kind of integrated and you don't have to",
    "start": "1168620",
    "end": "1170120"
  },
  {
    "text": "worry right you don't need to write DML",
    "start": "1170120",
    "end": "1172100"
  },
  {
    "text": "files you don't need to to do all like",
    "start": "1172100",
    "end": "1173720"
  },
  {
    "text": "the plumbing typically needed to do",
    "start": "1173720",
    "end": "1176120"
  },
  {
    "text": "these type of platforms",
    "start": "1176120",
    "end": "1178179"
  },
  {
    "text": "if you go to the next one I think I",
    "start": "1178179",
    "end": "1181039"
  },
  {
    "text": "convinced you like how we use this and",
    "start": "1181039",
    "end": "1183200"
  },
  {
    "text": "why it's great I want to show a little",
    "start": "1183200",
    "end": "1185240"
  },
  {
    "text": "bit some of like the validation that",
    "start": "1185240",
    "end": "1187580"
  },
  {
    "text": "we'll be doing with the community there",
    "start": "1187580",
    "end": "1189320"
  },
  {
    "text": "is one in particular that you're very",
    "start": "1189320",
    "end": "1190640"
  },
  {
    "text": "proud about you might have heard about",
    "start": "1190640",
    "end": "1192140"
  },
  {
    "text": "this we partnered with NASA",
    "start": "1192140",
    "end": "1195260"
  },
  {
    "text": "to build the very first geospatial",
    "start": "1195260",
    "end": "1198140"
  },
  {
    "text": "Foundation model so this is basically",
    "start": "1198140",
    "end": "1200059"
  },
  {
    "text": "showing that Transformer technology is",
    "start": "1200059",
    "end": "1202340"
  },
  {
    "text": "applicable Beyond language this is very",
    "start": "1202340",
    "end": "1204140"
  },
  {
    "text": "exciting right to see the same type of",
    "start": "1204140",
    "end": "1206440"
  },
  {
    "text": "benefits and generality in Foundation",
    "start": "1206440",
    "end": "1209059"
  },
  {
    "text": "models going again Beyond language so",
    "start": "1209059",
    "end": "1211039"
  },
  {
    "text": "what we did with NASA was to do again I",
    "start": "1211039",
    "end": "1213919"
  },
  {
    "text": "mean to do the whole life cycle meaning",
    "start": "1213919",
    "end": "1215900"
  },
  {
    "text": "that these guys they have tons of",
    "start": "1215900",
    "end": "1218960"
  },
  {
    "text": "geospatial data when I say tons this is",
    "start": "1218960",
    "end": "1222500"
  },
  {
    "text": "like a compared to language it's like",
    "start": "1222500",
    "end": "1224120"
  },
  {
    "text": "orders of magnitude right talking about",
    "start": "1224120",
    "end": "1226220"
  },
  {
    "text": "petabytes of satellite data we set about",
    "start": "1226220",
    "end": "1229220"
  },
  {
    "text": "to actually train a model there applying",
    "start": "1229220",
    "end": "1231200"
  },
  {
    "text": "again transform technology we can talk",
    "start": "1231200",
    "end": "1233480"
  },
  {
    "text": "about like the actual architecture that",
    "start": "1233480",
    "end": "1235039"
  },
  {
    "text": "you use and so on for this talk I'll",
    "start": "1235039",
    "end": "1236720"
  },
  {
    "text": "kind of give you like the summary we",
    "start": "1236720",
    "end": "1238760"
  },
  {
    "text": "train a model and uh within this is",
    "start": "1238760",
    "end": "1241460"
  },
  {
    "text": "using the IBM Fellowship computer that I",
    "start": "1241460",
    "end": "1244220"
  },
  {
    "text": "mentioned right the model was trained",
    "start": "1244220",
    "end": "1246380"
  },
  {
    "text": "there and can you I think can you play",
    "start": "1246380",
    "end": "1248660"
  },
  {
    "text": "the there is a video yeah I feel uh in a",
    "start": "1248660",
    "end": "1251660"
  },
  {
    "text": "video like you see like the thing",
    "start": "1251660",
    "end": "1253760"
  },
  {
    "text": "actually happening right so we can use",
    "start": "1253760",
    "end": "1255200"
  },
  {
    "text": "music softly the type of interface that",
    "start": "1255200",
    "end": "1257360"
  },
  {
    "text": "you describe so what you see in the",
    "start": "1257360",
    "end": "1258799"
  },
  {
    "text": "right hand side is what the NASA data",
    "start": "1258799",
    "end": "1260960"
  },
  {
    "text": "scientist sees right a Jupiter notebook",
    "start": "1260960",
    "end": "1263179"
  },
  {
    "text": "an SDK where you can Define resources",
    "start": "1263179",
    "end": "1265280"
  },
  {
    "text": "then we train this model on IBM Cloud",
    "start": "1265280",
    "end": "1268039"
  },
  {
    "text": "this takes like hundreds of thousands of",
    "start": "1268039",
    "end": "1270200"
  },
  {
    "text": "gpus as you can imagine and the beauty",
    "start": "1270200",
    "end": "1272240"
  },
  {
    "text": "is that once you train the model now we",
    "start": "1272240",
    "end": "1274820"
  },
  {
    "text": "can actually move the mod and fine tune",
    "start": "1274820",
    "end": "1276620"
  },
  {
    "text": "it on another's environment and that's",
    "start": "1276620",
    "end": "1278780"
  },
  {
    "text": "exactly what we did so this stack is",
    "start": "1278780",
    "end": "1280460"
  },
  {
    "text": "very much portable meaning that we ran",
    "start": "1280460",
    "end": "1282679"
  },
  {
    "text": "for training on one Cloud IBM Cloud but",
    "start": "1282679",
    "end": "1285740"
  },
  {
    "text": "for fine-tuning you brought this stack",
    "start": "1285740",
    "end": "1287419"
  },
  {
    "text": "on others uh managed science environment",
    "start": "1287419",
    "end": "1290240"
  },
  {
    "text": "right that runs on AWS uh there the data",
    "start": "1290240",
    "end": "1294440"
  },
  {
    "text": "scientist has the same experience they",
    "start": "1294440",
    "end": "1295760"
  },
  {
    "text": "start with the Jupiter notebook we can",
    "start": "1295760",
    "end": "1297679"
  },
  {
    "text": "package the whole experience in terms of",
    "start": "1297679",
    "end": "1299900"
  },
  {
    "text": "some of like the profiles so do fine",
    "start": "1299900",
    "end": "1302539"
  },
  {
    "text": "tuning they can run this without any",
    "start": "1302539",
    "end": "1305659"
  },
  {
    "text": "kind of knowledge of how you actually",
    "start": "1305659",
    "end": "1307039"
  },
  {
    "text": "deploy VMS on AWS or how you deal with",
    "start": "1307039",
    "end": "1309740"
  },
  {
    "text": "actual kubernetes and so on of course",
    "start": "1309740",
    "end": "1311960"
  },
  {
    "text": "you run this with openshift on Rosa",
    "start": "1311960",
    "end": "1314600"
  },
  {
    "text": "right with them and we got very very",
    "start": "1314600",
    "end": "1317419"
  },
  {
    "text": "good feedback with this we're able to",
    "start": "1317419",
    "end": "1319100"
  },
  {
    "text": "enable very quickly a lot of scientists",
    "start": "1319100",
    "end": "1321080"
  },
  {
    "text": "to start with this very general",
    "start": "1321080",
    "end": "1323480"
  },
  {
    "text": "just special Foundation model and go",
    "start": "1323480",
    "end": "1325700"
  },
  {
    "text": "thing and go to things like let me",
    "start": "1325700",
    "end": "1327500"
  },
  {
    "text": "fine-tune this for burns cars or flood",
    "start": "1327500",
    "end": "1331100"
  },
  {
    "text": "mapping right things that like I was",
    "start": "1331100",
    "end": "1332960"
  },
  {
    "text": "saying before would take like its own",
    "start": "1332960",
    "end": "1335179"
  },
  {
    "text": "pipeline together so before they're",
    "start": "1335179",
    "end": "1336860"
  },
  {
    "text": "doing like a single model to detect like",
    "start": "1336860",
    "end": "1339559"
  },
  {
    "text": "bonus cars a satellite image and then",
    "start": "1339559",
    "end": "1341960"
  },
  {
    "text": "another model for anomaly and an",
    "start": "1341960",
    "end": "1344419"
  },
  {
    "text": "anomalies for like a flooding and so on",
    "start": "1344419",
    "end": "1346820"
  },
  {
    "text": "with this Foundation model they can",
    "start": "1346820",
    "end": "1348260"
  },
  {
    "text": "start with something very generous just",
    "start": "1348260",
    "end": "1349820"
  },
  {
    "text": "fine tune for that specific use case",
    "start": "1349820",
    "end": "1351679"
  },
  {
    "text": "it's much much faster so we've seen like",
    "start": "1351679",
    "end": "1354080"
  },
  {
    "text": "a lot of like new use case enabling and",
    "start": "1354080",
    "end": "1356600"
  },
  {
    "text": "given that now that we have this very",
    "start": "1356600",
    "end": "1358520"
  },
  {
    "text": "general foundational model and that we",
    "start": "1358520",
    "end": "1360320"
  },
  {
    "text": "prove that you can do fine tuning we",
    "start": "1360320",
    "end": "1362900"
  },
  {
    "text": "release this mode as well in hugging",
    "start": "1362900",
    "end": "1365240"
  },
  {
    "text": "phase uh it was the very first model uh",
    "start": "1365240",
    "end": "1368780"
  },
  {
    "text": "into your spatial uh science domain uh",
    "start": "1368780",
    "end": "1371780"
  },
  {
    "text": "there was a lot of traction the",
    "start": "1371780",
    "end": "1373159"
  },
  {
    "text": "community might have heard about this uh",
    "start": "1373159",
    "end": "1375080"
  },
  {
    "text": "it's available in Phase as I said before",
    "start": "1375080",
    "end": "1376700"
  },
  {
    "text": "we have blogs around these and NASA has",
    "start": "1376700",
    "end": "1379100"
  },
  {
    "text": "been talking about this not only in us",
    "start": "1379100",
    "end": "1380840"
  },
  {
    "text": "we're very proud to see like a lot of",
    "start": "1380840",
    "end": "1382880"
  },
  {
    "text": "the other players in the industry now",
    "start": "1382880",
    "end": "1384799"
  },
  {
    "text": "also using this model for its generality",
    "start": "1384799",
    "end": "1387679"
  },
  {
    "text": "right and ease of use in terms of fine",
    "start": "1387679",
    "end": "1389539"
  },
  {
    "text": "tuning if you go to the next one let me",
    "start": "1389539",
    "end": "1393559"
  },
  {
    "text": "try to wrap up so you can save some time",
    "start": "1393559",
    "end": "1395360"
  },
  {
    "text": "for questions uh just a little bit on",
    "start": "1395360",
    "end": "1398299"
  },
  {
    "text": "what is next for us right",
    "start": "1398299",
    "end": "1400100"
  },
  {
    "text": "I showed you that there is a way to kind",
    "start": "1400100",
    "end": "1402020"
  },
  {
    "text": "of abstract these layers right in a way",
    "start": "1402020",
    "end": "1404960"
  },
  {
    "text": "that becomes very simple for the user to",
    "start": "1404960",
    "end": "1406880"
  },
  {
    "text": "basically get going with the stack uh",
    "start": "1406880",
    "end": "1409520"
  },
  {
    "text": "the next step is to create more like uh",
    "start": "1409520",
    "end": "1411640"
  },
  {
    "text": "profiles or automation end-to-end",
    "start": "1411640",
    "end": "1414260"
  },
  {
    "text": "recipes right so you can actually get",
    "start": "1414260",
    "end": "1416480"
  },
  {
    "text": "going even uh more easily right",
    "start": "1416480",
    "end": "1419299"
  },
  {
    "text": "so this is one of the things that you're",
    "start": "1419299",
    "end": "1420500"
  },
  {
    "text": "doing so like how you can package the",
    "start": "1420500",
    "end": "1422179"
  },
  {
    "text": "whole fine tuning of the special model",
    "start": "1422179",
    "end": "1424159"
  },
  {
    "text": "for example uh Cube Ray uh it's a big",
    "start": "1424159",
    "end": "1427220"
  },
  {
    "text": "piece for us meaning the integration of",
    "start": "1427220",
    "end": "1428900"
  },
  {
    "text": "Ray with kubernetes so we have been very",
    "start": "1428900",
    "end": "1430940"
  },
  {
    "text": "active in this community there is an",
    "start": "1430940",
    "end": "1433159"
  },
  {
    "text": "integration that you've been working on",
    "start": "1433159",
    "end": "1434720"
  },
  {
    "text": "uh mcad that drops cash and kubrade is",
    "start": "1434720",
    "end": "1437240"
  },
  {
    "text": "in place but we want to make this even",
    "start": "1437240",
    "end": "1438500"
  },
  {
    "text": "better right there's a lot of tuning at",
    "start": "1438500",
    "end": "1441020"
  },
  {
    "text": "the kubernetes layer right I described",
    "start": "1441020",
    "end": "1442880"
  },
  {
    "text": "something to you that sounds great but",
    "start": "1442880",
    "end": "1445039"
  },
  {
    "text": "again I mean there was a lot of like uh",
    "start": "1445039",
    "end": "1447620"
  },
  {
    "text": "learning and expertise at like a tuning",
    "start": "1447620",
    "end": "1450740"
  },
  {
    "text": "kubernetes for this a lot of these",
    "start": "1450740",
    "end": "1452419"
  },
  {
    "text": "things can be actually embedded as",
    "start": "1452419",
    "end": "1453980"
  },
  {
    "text": "profile that can be delivered to this uh",
    "start": "1453980",
    "end": "1456440"
  },
  {
    "text": "open sources stack uh on the right hand",
    "start": "1456440",
    "end": "1458840"
  },
  {
    "text": "side uh pythosh right as I said there's",
    "start": "1458840",
    "end": "1462020"
  },
  {
    "text": "a lot of room to continue improve in",
    "start": "1462020",
    "end": "1464120"
  },
  {
    "text": "terms of the apis for the super training",
    "start": "1464120",
    "end": "1465799"
  },
  {
    "text": "fstp is a big one for us we want to go",
    "start": "1465799",
    "end": "1468200"
  },
  {
    "text": "to something more like hybrid now fsdp",
    "start": "1468200",
    "end": "1470539"
  },
  {
    "text": "but tensor parallel right on the cake",
    "start": "1470539",
    "end": "1473360"
  },
  {
    "text": "heat side this is for the fine tuning",
    "start": "1473360",
    "end": "1475460"
  },
  {
    "text": "piece right there is a lot we can do",
    "start": "1475460",
    "end": "1478039"
  },
  {
    "text": "including pluggable python apis for",
    "start": "1478039",
    "end": "1480620"
  },
  {
    "text": "tuning inference we continue to evolve",
    "start": "1480620",
    "end": "1482659"
  },
  {
    "text": "kit rag is another one that's big for us",
    "start": "1482659",
    "end": "1485539"
  },
  {
    "text": "we also bringing rags to this platform",
    "start": "1485539",
    "end": "1487400"
  },
  {
    "text": "and finally when you deal with gpus",
    "start": "1487400",
    "end": "1490039"
  },
  {
    "text": "anybody in the industry doing anything",
    "start": "1490039",
    "end": "1492679"
  },
  {
    "text": "uh landscape with the gpus you know that",
    "start": "1492679",
    "end": "1494659"
  },
  {
    "text": "they fail this is not very reliable",
    "start": "1494659",
    "end": "1496400"
  },
  {
    "text": "right it's a very complicated Infinity",
    "start": "1496400",
    "end": "1498559"
  },
  {
    "text": "environment so there's a lot of",
    "start": "1498559",
    "end": "1500539"
  },
  {
    "text": "opportunity for us to make a photo",
    "start": "1500539",
    "end": "1503059"
  },
  {
    "text": "awareness in kubernetes better and we're",
    "start": "1503059",
    "end": "1505039"
  },
  {
    "text": "bringing some of these learnings at that",
    "start": "1505039",
    "end": "1506659"
  },
  {
    "text": "layer as well so that's what is next for",
    "start": "1506659",
    "end": "1508820"
  },
  {
    "text": "us I hope this resonated with you",
    "start": "1508820",
    "end": "1511419"
  },
  {
    "text": "we really can encourage you to try out",
    "start": "1511419",
    "end": "1513919"
  },
  {
    "text": "everything that you described but it's",
    "start": "1513919",
    "end": "1515659"
  },
  {
    "text": "open source right around the open data",
    "start": "1515659",
    "end": "1518120"
  },
  {
    "text": "Hub community so we encourage you to",
    "start": "1518120",
    "end": "1520400"
  },
  {
    "text": "check the QR code go see read our blogs",
    "start": "1520400",
    "end": "1523640"
  },
  {
    "text": "and give it a try and share feedback",
    "start": "1523640",
    "end": "1525740"
  },
  {
    "text": "with us and you're here to build",
    "start": "1525740",
    "end": "1527240"
  },
  {
    "text": "together",
    "start": "1527240",
    "end": "1528140"
  },
  {
    "text": "and that's all thank you thank you",
    "start": "1528140",
    "end": "1532240"
  },
  {
    "text": "so",
    "start": "1538220",
    "end": "1540820"
  },
  {
    "text": "okay",
    "start": "1542360",
    "end": "1544039"
  },
  {
    "text": "all right you mentioned the IBM building",
    "start": "1544039",
    "end": "1546799"
  },
  {
    "text": "the computer was very large was the NASA",
    "start": "1546799",
    "end": "1549440"
  },
  {
    "text": "computer similar or smaller yeah very",
    "start": "1549440",
    "end": "1552500"
  },
  {
    "text": "good question so the NASA model was",
    "start": "1552500",
    "end": "1554539"
  },
  {
    "text": "trained Novella right uh because we're",
    "start": "1554539",
    "end": "1557480"
  },
  {
    "text": "growing these systems we typically don't",
    "start": "1557480",
    "end": "1558860"
  },
  {
    "text": "say like the actual number of GPU so",
    "start": "1558860",
    "end": "1560600"
  },
  {
    "text": "what you say typical public is like over",
    "start": "1560600",
    "end": "1562159"
  },
  {
    "text": "thousands of gpus right this is",
    "start": "1562159",
    "end": "1564620"
  },
  {
    "text": "I mean the scale when we train uh the",
    "start": "1564620",
    "end": "1567919"
  },
  {
    "text": "geospatial model right uh it's growing",
    "start": "1567919",
    "end": "1570380"
  },
  {
    "text": "this environment",
    "start": "1570380",
    "end": "1571820"
  },
  {
    "text": "um on the NASA side right they have an",
    "start": "1571820",
    "end": "1573620"
  },
  {
    "text": "AWS account where they could actually",
    "start": "1573620",
    "end": "1575179"
  },
  {
    "text": "grow too many gpus but these are like",
    "start": "1575179",
    "end": "1577820"
  },
  {
    "text": "many fine-tuning jobs right meaning that",
    "start": "1577820",
    "end": "1580039"
  },
  {
    "text": "it's more like throughput its job was",
    "start": "1580039",
    "end": "1581720"
  },
  {
    "text": "like four to six gpus and then it had",
    "start": "1581720",
    "end": "1583940"
  },
  {
    "text": "many users run at the same time so it's",
    "start": "1583940",
    "end": "1586520"
  },
  {
    "text": "like a one big job for training versus",
    "start": "1586520",
    "end": "1588679"
  },
  {
    "text": "many smaller jobs but many concurrent",
    "start": "1588679",
    "end": "1591740"
  },
  {
    "text": "jobs right uh there is another side of",
    "start": "1591740",
    "end": "1594679"
  },
  {
    "text": "this which is on-prem with NASA where",
    "start": "1594679",
    "end": "1596720"
  },
  {
    "text": "they have like a much larger pool and",
    "start": "1596720",
    "end": "1598400"
  },
  {
    "text": "can also not comment on like the actual",
    "start": "1598400",
    "end": "1601100"
  },
  {
    "text": "number but it's also the same order of",
    "start": "1601100",
    "end": "1603020"
  },
  {
    "text": "magnitude right we're talking about like",
    "start": "1603020",
    "end": "1604279"
  },
  {
    "text": "thousands of gpus running this stack",
    "start": "1604279",
    "end": "1608500"
  },
  {
    "text": "I hope this answered",
    "start": "1608900",
    "end": "1610760"
  },
  {
    "text": "any other questions oh yes",
    "start": "1610760",
    "end": "1614480"
  },
  {
    "text": "um so I'm very curious about the the use",
    "start": "1614480",
    "end": "1617480"
  },
  {
    "text": "of um this generative models for",
    "start": "1617480",
    "end": "1619760"
  },
  {
    "text": "geospatial tasks",
    "start": "1619760",
    "end": "1621679"
  },
  {
    "text": "um is this something you have Liberty to",
    "start": "1621679",
    "end": "1623299"
  },
  {
    "text": "discuss or do we need to talk to people",
    "start": "1623299",
    "end": "1625220"
  },
  {
    "text": "at Nasa just to get the intuition behind",
    "start": "1625220",
    "end": "1627620"
  },
  {
    "text": "the tasks and and right yeah so here's",
    "start": "1627620",
    "end": "1630620"
  },
  {
    "text": "the good news right so this is an area",
    "start": "1630620",
    "end": "1632900"
  },
  {
    "text": "with nas which is all about like open",
    "start": "1632900",
    "end": "1634640"
  },
  {
    "text": "data like open source right so they're",
    "start": "1634640",
    "end": "1637279"
  },
  {
    "text": "very open about what we're doing in fact",
    "start": "1637279",
    "end": "1639140"
  },
  {
    "text": "like they release the mod itself there's",
    "start": "1639140",
    "end": "1641299"
  },
  {
    "text": "a lot of like literature around this so",
    "start": "1641299",
    "end": "1643100"
  },
  {
    "text": "we've been publishing papers blogs even",
    "start": "1643100",
    "end": "1645860"
  },
  {
    "text": "some of the tooling so what I'll do is",
    "start": "1645860",
    "end": "1647779"
  },
  {
    "text": "kind of connect with you give you some",
    "start": "1647779",
    "end": "1649100"
  },
  {
    "text": "some of these pointers and there's a lot",
    "start": "1649100",
    "end": "1651080"
  },
  {
    "text": "of information around this in the mod",
    "start": "1651080",
    "end": "1652520"
  },
  {
    "text": "itself right of course we have not only",
    "start": "1652520",
    "end": "1654260"
  },
  {
    "text": "published the mod but on some of the",
    "start": "1654260",
    "end": "1655580"
  },
  {
    "text": "recipes for you to get go and get",
    "start": "1655580",
    "end": "1657440"
  },
  {
    "text": "started with the model as well",
    "start": "1657440",
    "end": "1660580"
  },
  {
    "text": "good",
    "start": "1662299",
    "end": "1664840"
  },
  {
    "text": "any more questions",
    "start": "1667340",
    "end": "1670000"
  },
  {
    "text": "well I guess if that is if there's any",
    "start": "1671659",
    "end": "1674360"
  },
  {
    "text": "more questions",
    "start": "1674360",
    "end": "1674930"
  },
  {
    "text": "[Music]",
    "start": "1674930",
    "end": "1676039"
  },
  {
    "text": "can we give a round of applause for a",
    "start": "1676039",
    "end": "1677720"
  },
  {
    "text": "class Center thank you thank you",
    "start": "1677720",
    "end": "1679100"
  },
  {
    "text": "everyone for joining us",
    "start": "1679100",
    "end": "1682120"
  }
]
[
  {
    "text": "with that I'm very very excited to welcome John schan to the stage John is one of the co-founders of open Ai and",
    "start": "199",
    "end": "5960"
  },
  {
    "text": "the creator of chat GPT please welcome [Applause]",
    "start": "5960",
    "end": "14480"
  },
  {
    "text": "John John thank you so much for being here pleasure to be",
    "start": "14480",
    "end": "19759"
  },
  {
    "text": "here so there are a bunch of questions I'd love to ask you about your work at open AI but uh before we dive into that",
    "start": "20920",
    "end": "29720"
  },
  {
    "text": "can you tell us a little bit about how you got excited about AI in the first place I used to read a lot of sci-fi as",
    "start": "29720",
    "end": "36520"
  },
  {
    "text": "a kid I liked Isaac azimoff's books and verer vinge yeah and uh I remember",
    "start": "36520",
    "end": "42960"
  },
  {
    "text": "picking up the singularity is near by Ray curtz at a garage sale once and uh",
    "start": "42960",
    "end": "48760"
  },
  {
    "text": "looking at all the nice um scaling flots uh like how um mors law and all of its",
    "start": "48760",
    "end": "55640"
  },
  {
    "text": "uh variations so uh and then I did some projects um as an",
    "start": "55640",
    "end": "62160"
  },
  {
    "text": "undergrad in um doing things with machine learning like I worked on uh",
    "start": "62160",
    "end": "67200"
  },
  {
    "text": "transcribing uh handwriting into latch uh for some project for some class and that was uh that was exciting to me you",
    "start": "67200",
    "end": "75360"
  },
  {
    "text": "also did some Physics projects right oh yeah I did an undergrad in physics okay nice and so that led you to do a PhD in",
    "start": "75360",
    "end": "83200"
  },
  {
    "text": "machine learning right yeah you weren't always working on language models right can you tell us about the kind of work",
    "start": "83200",
    "end": "89439"
  },
  {
    "text": "you did in in grad school yeah I started out actually I started grad school in Neuroscience uh but then I ended up",
    "start": "89439",
    "end": "96119"
  },
  {
    "text": "switching to Robotics and to um a machine learning group uh Peter ral's",
    "start": "96119",
    "end": "101439"
  },
  {
    "text": "group that worked on Robotics and uh so I I worked a bit with uh with the robots",
    "start": "101439",
    "end": "107000"
  },
  {
    "text": "of the time like there's the the PR2 personal robot 2 uh and uh we were doing",
    "start": "107000",
    "end": "113719"
  },
  {
    "text": "things like uh using it to fold laundry uh in a very uh very slow and deliver",
    "start": "113719",
    "end": "120119"
  },
  {
    "text": "way and uh tying I was working on tying knots getting it to tie knots I remember",
    "start": "120119",
    "end": "125399"
  },
  {
    "text": "that um as a kind of simulation of um doing uh robot surgery that was the",
    "start": "125399",
    "end": "131000"
  },
  {
    "text": "motivating application like having suturing with a robot so yeah I worked",
    "start": "131000",
    "end": "136239"
  },
  {
    "text": "on robotics a bit for a while and then halfway through the PHD switched over to uh to reinforcement",
    "start": "136239",
    "end": "142280"
  },
  {
    "text": "learning if you look back on your PhD work I'm curious which projects do you",
    "start": "142280",
    "end": "147599"
  },
  {
    "text": "think stood the test of time the most I'd say the work on reinforcement",
    "start": "147599",
    "end": "152920"
  },
  {
    "text": "learning and uh specifically uh applying it to neuron Nets uh definitely that was",
    "start": "152920",
    "end": "159680"
  },
  {
    "text": "the stuff that that ended up uh uh making a difference in the long run uh some of the earlier work on robotics uh",
    "start": "159680",
    "end": "167120"
  },
  {
    "text": "definitely produced some nice demos at the time but I don't think the methods are that General yeah cool so we all",
    "start": "167120",
    "end": "174120"
  },
  {
    "text": "know that open AI does great research and builds great products um but opening",
    "start": "174120",
    "end": "180080"
  },
  {
    "text": "I didn't start out that way right it started out purely focused on Research right um can you tell us about that",
    "start": "180080",
    "end": "186280"
  },
  {
    "text": "transition what led to the decision to um do both well we we were interested in um",
    "start": "186280",
    "end": "195120"
  },
  {
    "text": "releasing some kind of product or releasing something to the world uh from the beginning but we also didn't uh want",
    "start": "195120",
    "end": "200799"
  },
  {
    "text": "to go too far out of our way uh to to build a product so we um um we had some",
    "start": "200799",
    "end": "208319"
  },
  {
    "text": "there were some ideas uh being tossed around um but um nothing quite nothing",
    "start": "208319",
    "end": "214840"
  },
  {
    "text": "quite came together and uh we wanted to we wanted to raise more money and it it was kind of um even",
    "start": "214840",
    "end": "222640"
  },
  {
    "text": "though um our structure didn't require us to um make money immediately or be um",
    "start": "222640",
    "end": "229680"
  },
  {
    "text": "profitable uh it seemed like we were going to be able to raise more money if we actually had uh some kind of um some",
    "start": "229680",
    "end": "236640"
  },
  {
    "text": "kind of product out there and also we felt like it was uh it's nice if your research actually",
    "start": "236640",
    "end": "242480"
  },
  {
    "text": "connects to the real world instead of just uh being kind of uh I don't know",
    "start": "242480",
    "end": "249319"
  },
  {
    "text": "just having um uh just being like publishing things",
    "start": "249319",
    "end": "254799"
  },
  {
    "text": "and putting together demos yeah and so your first product was the API product",
    "start": "254799",
    "end": "261639"
  },
  {
    "text": "right how long you know once you guys decided to start building products and shipping that um how long did it take to",
    "start": "261639",
    "end": "269400"
  },
  {
    "text": "decide on building an API were there other ideas you you considered yeah we",
    "start": "269400",
    "end": "274680"
  },
  {
    "text": "had some other ideas uh a lot of them were more like domain specific applications like doing translation so",
    "start": "274680",
    "end": "281440"
  },
  {
    "text": "after gbd3 we we knew that um these models were uh impressively smart and",
    "start": "281440",
    "end": "286840"
  },
  {
    "text": "there must be something you can do with them uh so we we ended up thinking about a bunch of natural language processing",
    "start": "286840",
    "end": "292720"
  },
  {
    "text": "applications but at the time we were thinking that the model wasn't quite good enough at anything to be useful uh",
    "start": "292720",
    "end": "300320"
  },
  {
    "text": "by itself so we would probably need to fine-tune it and build it make it really good for a specific application but I",
    "start": "300320",
    "end": "306400"
  },
  {
    "text": "think uh then there was the other um well um I actually don't think we could",
    "start": "306400",
    "end": "311880"
  },
  {
    "text": "have succeeded with one of those products because it would have required um building up a ton of uh domain",
    "start": "311880",
    "end": "317960"
  },
  {
    "text": "expertise and really digging into that domain and it would have been um it would have required a lot of work that's",
    "start": "317960",
    "end": "324440"
  },
  {
    "text": "separate from our main research so the nice thing about an API is it's just basically taking the thing that the",
    "start": "324440",
    "end": "330199"
  },
  {
    "text": "research team has built and commercializing it directly as opposed to going and building this whole other",
    "start": "330199",
    "end": "335960"
  },
  {
    "text": "product that's separate from what the research team is doing were you deterred At All by the fact that there were other",
    "start": "335960",
    "end": "343600"
  },
  {
    "text": "AI apis out there other companies have tried building AI apis but none of them had been a huge success a little bit",
    "start": "343600",
    "end": "351000"
  },
  {
    "text": "that was definitely a concern that there were some there there were some other apis like for object recognition and",
    "start": "351000",
    "end": "356919"
  },
  {
    "text": "vision and um I think some of them were moderately well-used but they weren't uh",
    "start": "356919",
    "end": "362880"
  },
  {
    "text": "like uh spectacular products so we were defin we had some concerns about that",
    "start": "362880",
    "end": "368080"
  },
  {
    "text": "and I think um in retrospect those concerns were warranted because I'd say",
    "start": "368080",
    "end": "373240"
  },
  {
    "text": "the original model we released the API with wasn't good enough um for most",
    "start": "373240",
    "end": "379000"
  },
  {
    "text": "people I mean it was a pretty small business for a while and um I think it only um the model started to get good",
    "start": "379000",
    "end": "386120"
  },
  {
    "text": "enough um only in the last year and a half or so so it wasn't an overnight success when did you when did you",
    "start": "386120",
    "end": "393720"
  },
  {
    "text": "realize that it was going to work out that the API was you know the right choice or that it was going to work",
    "start": "393720",
    "end": "399960"
  },
  {
    "text": "out well I think you you could have um looked at the trends and uh and",
    "start": "399960",
    "end": "406280"
  },
  {
    "text": "predicted what I just described that maybe the initial model wasn't good enough but uh some uh future models",
    "start": "406280",
    "end": "412520"
  },
  {
    "text": "would be and uh like serving uh models seemed like a generally useful thing to",
    "start": "412520",
    "end": "418960"
  },
  {
    "text": "do so I I would say that um the API uh only like saw a lot of growth in uh 2022",
    "start": "418960",
    "end": "428400"
  },
  {
    "text": "uh just after um we had the 3 gbd 3.5 base models coming out and then we sort",
    "start": "428400",
    "end": "434720"
  },
  {
    "text": "of had a pretty steep growth curve um and then chat gbt itself made the API a",
    "start": "434720",
    "end": "440400"
  },
  {
    "text": "lot more popular because a lot more people got excited about language models in general yeah",
    "start": "440400",
    "end": "446680"
  },
  {
    "text": "now before we talk about chat GPT let's talk about scaling this is a you",
    "start": "446680",
    "end": "452680"
  },
  {
    "text": "know distributed systems event in some extent um we all know open AI uses a huge amount of compute and actually I",
    "start": "452680",
    "end": "460400"
  },
  {
    "text": "think open AI was perhaps the first to really go all in on",
    "start": "460400",
    "end": "466520"
  },
  {
    "text": "scaling where did that belief in the importance of scaling models and compute come",
    "start": "466520",
    "end": "472400"
  },
  {
    "text": "from the idea that bigger models are better was a bit in the Zeitgeist that",
    "start": "472400",
    "end": "478360"
  },
  {
    "text": "um people had um produce the best Benchmark results with fairly big models",
    "start": "478360",
    "end": "483720"
  },
  {
    "text": "and uh but I guess it wasn't um so and I I would say the uh founding team of open",
    "start": "483720",
    "end": "490720"
  },
  {
    "text": "AI was uh more uh leaned more towards this uh aesthetic of uh scale up simple",
    "start": "490720",
    "end": "497759"
  },
  {
    "text": "things rather than trying to build uh some complicated clever thing like we definitely believed that uh simple",
    "start": "497759",
    "end": "503960"
  },
  {
    "text": "things that are uh doing the simple thing right was uh uh tended to win when",
    "start": "503960",
    "end": "510479"
  },
  {
    "text": "in machine learning but I would say for scaling um it's not um scaling uh looks",
    "start": "510479",
    "end": "517959"
  },
  {
    "text": "easy when you see the final result or it looks obvious when you see the final result that uh like curve goes up and to",
    "start": "517959",
    "end": "523919"
  },
  {
    "text": "the right but often there's a lot of complexity in getting there and you have to yeah say I mean there's all the",
    "start": "523919",
    "end": "531399"
  },
  {
    "text": "systems uh just doing the engineering is very difficult uh to get something that's actually performing that scale",
    "start": "531399",
    "end": "536800"
  },
  {
    "text": "and then there's usually all these little details like you have to to scale your learning rates just right otherwise",
    "start": "536800",
    "end": "541959"
  },
  {
    "text": "you get worse results with big models and you have to scale your data up along with the model size so I'd say that it",
    "start": "541959",
    "end": "547920"
  },
  {
    "text": "took several years to figure out what were the right recipes for scaling things yeah now we talk about scaling as",
    "start": "547920",
    "end": "554399"
  },
  {
    "text": "if it's one thing but there are many different dimensions you could scale right the amount of data size of the",
    "start": "554399",
    "end": "559920"
  },
  {
    "text": "model just the amount of compute you put into it maybe other things as well is it",
    "start": "559920",
    "end": "565160"
  },
  {
    "text": "obvious which ones matter and which ones don't well it's usually not completely",
    "start": "565160",
    "end": "570720"
  },
  {
    "text": "obvious I mean model size and data are the two biggest ones but then you usually have a lot of hyperparameters",
    "start": "570720",
    "end": "577079"
  },
  {
    "text": "that have to be scaled properly and it's uh you have to do a lot of science to figure out how to scale them yeah so can",
    "start": "577079",
    "end": "584360"
  },
  {
    "text": "you share some intuition about why scaling is hard like why aren't we using",
    "start": "584360",
    "end": "589839"
  },
  {
    "text": "much what's stopping us from using you know 70 trillion parameter models today or or even",
    "start": "589839",
    "end": "595279"
  },
  {
    "text": "bigger yeah I think um a lot of that is about um well it's about compute efficiency",
    "start": "595279",
    "end": "602360"
  },
  {
    "text": "like you can so now we know you can train a small model for really long or a",
    "start": "602360",
    "end": "607560"
  },
  {
    "text": "big model for short and um there's some uh there's some trade-off and it turns",
    "start": "607560",
    "end": "612920"
  },
  {
    "text": "out that um somewhere in the middle you get the best compute efficiency so if you put the flops on the x-axis you have",
    "start": "612920",
    "end": "619519"
  },
  {
    "text": "a bunch of Curves of uh and you you draw your learning curves of loss versus flops uh there's some optimal model size",
    "start": "619519",
    "end": "626800"
  },
  {
    "text": "for getting the best performance so I think what we have now is just uh using Transformers and using the",
    "start": "626800",
    "end": "633959"
  },
  {
    "text": "training recipe we have it turns out um certain model sizes are the most",
    "start": "633959",
    "end": "639079"
  },
  {
    "text": "efficient uh given the amount of Computer Resources we're putting into it but that that's probably going to change",
    "start": "639079",
    "end": "645440"
  },
  {
    "text": "as we uh start putting more compute into the training runs and also maybe as we start to change the training",
    "start": "645440",
    "end": "652120"
  },
  {
    "text": "methodologies and the types of data we use we also might end find that uh",
    "start": "652120",
    "end": "657519"
  },
  {
    "text": "different size models end up working working the best do you have a sense of whether this is something with",
    "start": "657519",
    "end": "662600"
  },
  {
    "text": "diminishing returns or or not like how far this will take us yeah I'd say often",
    "start": "662600",
    "end": "669079"
  },
  {
    "text": "the um often the returns diminish as you uh scale the current thing and but then",
    "start": "669079",
    "end": "675519"
  },
  {
    "text": "there are other uh innovations that like you continue uh so I guess I don't see I",
    "start": "675519",
    "end": "682000"
  },
  {
    "text": "don't see deep learning in general uh like uh reaching a plateau or anything or hitting diminishing returns uh maybe",
    "start": "682000",
    "end": "689519"
  },
  {
    "text": "um just doing the most basic thing uh reaches some diminishing returns yeah",
    "start": "689519",
    "end": "696120"
  },
  {
    "text": "makes sense since this is Ray Summit uh let's talk a little bit about distributed systems and infrastructure",
    "start": "696120",
    "end": "703560"
  },
  {
    "text": "so I'm sure almost no one in this audience knows this but early on or or",
    "start": "703560",
    "end": "709720"
  },
  {
    "text": "maybe partway through your PhD you actually built your own deep learning framework called computational",
    "start": "709720",
    "end": "715000"
  },
  {
    "text": "computation graph toolkit can you share a little bit about why you built that that and and what you were trying to",
    "start": "715000",
    "end": "721120"
  },
  {
    "text": "achieve yeah um back uh some people might remember theano that was this uh",
    "start": "721120",
    "end": "728040"
  },
  {
    "text": "absolutely that was the uh Auto diff framework from before tensor flow and P torch uh so the was amazing uh and but",
    "start": "728040",
    "end": "736600"
  },
  {
    "text": "it also uh was starting to hit its limitations like uh it would sometimes",
    "start": "736600",
    "end": "741880"
  },
  {
    "text": "take half an hour to compile your your graph before you could do a single step",
    "start": "741880",
    "end": "747199"
  },
  {
    "text": "so uh and I want to do some things like um I wanted to do some things with",
    "start": "747199",
    "end": "752320"
  },
  {
    "text": "recurrent networks and theano wasn't wasn't that great for it so uh so I",
    "start": "752320",
    "end": "757800"
  },
  {
    "text": "ended up uh working on building building one of these things and actually I think it was a great learning experience I",
    "start": "757800",
    "end": "764399"
  },
  {
    "text": "mean uh it turned out that uh um Google yeah there was tensor flow and P torch",
    "start": "764399",
    "end": "770720"
  },
  {
    "text": "right after that and those ended up I think you were working on the or working on cgt this was 2015 um in the fall and",
    "start": "770720",
    "end": "779480"
  },
  {
    "text": "then tensor Flow came out right after that yeah I started working on it before I knew about tensor flow and then I found out about it and uh maybe part of",
    "start": "779480",
    "end": "786320"
  },
  {
    "text": "me was disappointed but uh I was getting um upstaged by Google but it was it's",
    "start": "786320",
    "end": "793279"
  },
  {
    "text": "fine yeah I think uh I think everyone should write their own um Auto diff uh",
    "start": "793279",
    "end": "798600"
  },
  {
    "text": "everyone should at least write their own little autoi library at one point to learn get a really good intuition for",
    "start": "798600",
    "end": "804639"
  },
  {
    "text": "back propop it's a great idea yeah but this is all yeah but slow compile times",
    "start": "804639",
    "end": "810480"
  },
  {
    "text": "yeah for neural network for recurrent neural networks this is uh I had forgotten about that that was a long time ago um but if I remember correctly",
    "start": "810480",
    "end": "817600"
  },
  {
    "text": "it was quite fast it was actually you know quite well architected um and you actually were an",
    "start": "817600",
    "end": "824000"
  },
  {
    "text": "early Ray user or maybe an you attempted to use Ray uh you used Ray quite a long",
    "start": "824000",
    "end": "829440"
  },
  {
    "text": "time ago before it was really ready can you share do you remember what you were trying it for and what your experience",
    "start": "829440",
    "end": "835240"
  },
  {
    "text": "was like yeah this was back in 2016 2017 when you guys were just getting started",
    "start": "835240",
    "end": "841199"
  },
  {
    "text": "on it and I at the time I was doing something in the realm of architecture search um and uh I remember ra creating",
    "start": "841199",
    "end": "850040"
  },
  {
    "text": "some issues on GitHub about the schedule or not doing the right thing which you guys have fixed since then uh but",
    "start": "850040",
    "end": "858519"
  },
  {
    "text": "yeah yeah it's it's come a long way um there's still GitHub issues so probably",
    "start": "858519",
    "end": "864480"
  },
  {
    "text": "you closed that issue at some point so I remember seeing a about it yes nice um",
    "start": "864480",
    "end": "872320"
  },
  {
    "text": "can you share a little bit about you know you guys are pushing the limits at open AI of scale in a lot of different",
    "start": "872320",
    "end": "879279"
  },
  {
    "text": "dimensions um and so you may encounter challenges that um a lot of other people",
    "start": "879279",
    "end": "884839"
  },
  {
    "text": "don't encounter can you share a little bit about you know what makes infrastructure hard for the kind of AI",
    "start": "884839",
    "end": "891480"
  },
  {
    "text": "work you guys do at open AI yeah we have a library for doing distributed training and it does model",
    "start": "891480",
    "end": "897680"
  },
  {
    "text": "parallelism uh so so you're sending around weights and gradients and activations and",
    "start": "897680",
    "end": "905279"
  },
  {
    "text": "um yeah Ray and we use Ray as a big part of that for uh for doing all the",
    "start": "905279",
    "end": "910560"
  },
  {
    "text": "communication and it's um yeah it it's been very useful having this uh solid",
    "start": "910560",
    "end": "915920"
  },
  {
    "text": "component that we can build on um we've had various I mean open AI has a lot of the type of people who like writing",
    "start": "915920",
    "end": "922079"
  },
  {
    "text": "their own distributed systems code so we we've had our own uh yeah Everyone likes writing their own thing we've had our",
    "start": "922079",
    "end": "927880"
  },
  {
    "text": "own internal Library um often when you develop something internally it ends up it works great for",
    "start": "927880",
    "end": "934959"
  },
  {
    "text": "the person who wrote it but uh that person usually doesn't want to maintain it for years and uh it it's not very",
    "start": "934959",
    "end": "940959"
  },
  {
    "text": "well documented or general so um yeah we've had our own um like internal",
    "start": "940959",
    "end": "946240"
  },
  {
    "text": "systems but then uh I'd say it's been nice uh switching over to Ray so we have",
    "start": "946240",
    "end": "951440"
  },
  {
    "text": "this uh solid component that is uh very well documented and supported that we can build on yeah so if you weren't",
    "start": "951440",
    "end": "959000"
  },
  {
    "text": "using Ray what would you be using yeah we'd probably uh have our we'd probably",
    "start": "959000",
    "end": "964360"
  },
  {
    "text": "roll our own thing and use uh tools we'd use the other um lower level tools out",
    "start": "964360",
    "end": "970120"
  },
  {
    "text": "there like uh redus and MPI and so forth and just uh glue those together yeah",
    "start": "970120",
    "end": "976480"
  },
  {
    "text": "lots of MPI lots of red makes sense nice um",
    "start": "976480",
    "end": "982440"
  },
  {
    "text": "so tell us about Chachi PT how did you get the idea when did you start working",
    "start": "982440",
    "end": "987839"
  },
  {
    "text": "on it yeah re uh so I'd say it started off uh",
    "start": "987839",
    "end": "995519"
  },
  {
    "text": "well well I personally was uh working on um a project called uh well web GPT",
    "start": "995519",
    "end": "1002360"
  },
  {
    "text": "before this which is like uh a questioning question answering system that does retrieval and it uh so it'll",
    "start": "1002360",
    "end": "1009199"
  },
  {
    "text": "um you ask a question and then uh it'll go and find a bunch of relevant sources by uh doing a web search and uh browsing",
    "start": "1009199",
    "end": "1016839"
  },
  {
    "text": "some of the pages it finds and then write an one or two paragraph answer with citations and this was what we were",
    "start": "1016839",
    "end": "1024400"
  },
  {
    "text": "trying to get get at with that project was uh getting language models to use tools and uh and like trying to we were",
    "start": "1024400",
    "end": "1031959"
  },
  {
    "text": "trying to um work on this problem of truthfulness like how can you get models that uh don't make stuff up they just uh",
    "start": "1031959",
    "end": "1038959"
  },
  {
    "text": "say things that are true and based on has that one been solved I'd say we made progress on it it's not completely",
    "start": "1038959",
    "end": "1044520"
  },
  {
    "text": "solved but uh yeah we've come a long way so yeah we were really interested in",
    "start": "1044520",
    "end": "1050320"
  },
  {
    "text": "truthfulness so that project we had worked on this project and uh done our",
    "start": "1050320",
    "end": "1055720"
  },
  {
    "text": "first we had published a paper about it and um we're trying to figure out what was the next uh version of it and um for",
    "start": "1055720",
    "end": "1063360"
  },
  {
    "text": "question answering I'd say uh chat starts to make a lot of sense because you need to do things like uh follow-up",
    "start": "1063360",
    "end": "1069039"
  },
  {
    "text": "questions and clarifying questions and um uh so and there were some internal uh",
    "start": "1069039",
    "end": "1076360"
  },
  {
    "text": "we had been playing with uh Chad internally a bit B uh like at open Ai and it seemed like the models were quite",
    "start": "1076360",
    "end": "1082600"
  },
  {
    "text": "good at it so um yeah we decided to um use di like have a dialogue based system",
    "start": "1082600",
    "end": "1089480"
  },
  {
    "text": "for the next iteration of uh our our system uh so we started collecting data",
    "start": "1089480",
    "end": "1096240"
  },
  {
    "text": "in um like early 2022 um that was like specific for chat",
    "start": "1096240",
    "end": "1103840"
  },
  {
    "text": "um and uh we were originally was going to be a successor to this web GPT system M and eventually we we really ended up",
    "start": "1103840",
    "end": "1111919"
  },
  {
    "text": "liking the uh chat models and the the whole retrieval part end being a little",
    "start": "1111919",
    "end": "1117559"
  },
  {
    "text": "complicated so we temporarily dropped that and we just decided to focus on the chat",
    "start": "1117559",
    "end": "1122840"
  },
  {
    "text": "models um and uh and I'd say we were surprised by how um like how good the",
    "start": "1122840",
    "end": "1130400"
  },
  {
    "text": "models were um or how how useful they were so we had an internal demo and um I",
    "start": "1130400",
    "end": "1136880"
  },
  {
    "text": "definitely use the demo a lot for uh coding help um because the models are really good at answering questions about",
    "start": "1136880",
    "end": "1143320"
  },
  {
    "text": "code especially when you're trying to use new libraries so um yeah it became uh well",
    "start": "1143320",
    "end": "1151280"
  },
  {
    "text": "um we started to think that it was a good idea to release uh to like do a",
    "start": "1151280",
    "end": "1156320"
  },
  {
    "text": "public release and uh just let other people try out the model and that that",
    "start": "1156320",
    "end": "1163360"
  },
  {
    "text": "um ended up getting delayed a bit because we had uh gbd4 finish training",
    "start": "1163360",
    "end": "1168440"
  },
  {
    "text": "and uh everyone got excited about that about that model and uh the the chat model we",
    "start": "1168440",
    "end": "1175039"
  },
  {
    "text": "had trained that was based on gbd 3.5 was uh that kind of got sidelined for a while but uh anyway we we ended up",
    "start": "1175039",
    "end": "1183320"
  },
  {
    "text": "deciding to uh do a release anyway and worked with the um worked with the product team who put together the UI and",
    "start": "1183320",
    "end": "1190280"
  },
  {
    "text": "everything for it and then ended up launching it late uh in",
    "start": "1190280",
    "end": "1195480"
  },
  {
    "text": "November that year that's a was a great decision yeah that turned out were you",
    "start": "1195480",
    "end": "1201000"
  },
  {
    "text": "surprised by the just the world's reaction to chat GPT or you know given that you had a lot of experience using",
    "start": "1201000",
    "end": "1207080"
  },
  {
    "text": "it internally did you kind of see that coming um yeah we were very surprised I mean we did have beta testers so we had",
    "start": "1207080",
    "end": "1214360"
  },
  {
    "text": "friends and family using it for a few months beforehand and uh there were definitely some enthusiastic users",
    "start": "1214360",
    "end": "1221960"
  },
  {
    "text": "especially people using it for code but um it didn't really uh like um I don't",
    "start": "1221960",
    "end": "1228280"
  },
  {
    "text": "know people weren't that excited about it and they um not everyone uh ended up",
    "start": "1228280",
    "end": "1234080"
  },
  {
    "text": "um not all the users ended up uh coming back to it a lot so um only a few of the",
    "start": "1234080",
    "end": "1240280"
  },
  {
    "text": "people who who we gave access ended up using it regularly so I think what happened was when everyone got access",
    "start": "1240280",
    "end": "1246320"
  },
  {
    "text": "people um sort of uh taught each other how to use it and what what use cases",
    "start": "1246320",
    "end": "1251559"
  },
  {
    "text": "ended up working so was kind of the social aspect of it was pretty important like people teach each other how to",
    "start": "1251559",
    "end": "1257320"
  },
  {
    "text": "prompt it and what kind of tasks is good at so I I think it really uh just the fact that it was really easy to use and",
    "start": "1257320",
    "end": "1263600"
  },
  {
    "text": "people could U share uh their use cases with each other um got caused it to",
    "start": "1263600",
    "end": "1270400"
  },
  {
    "text": "cause this this uh Mass excitement yeah so you mentioned using it for help",
    "start": "1270400",
    "end": "1277679"
  },
  {
    "text": "coding what about today what do you use Chachi BT for today I'd say that's still",
    "start": "1277679",
    "end": "1284000"
  },
  {
    "text": "my uh biggest use case personally uh uh I I also just use it here and there as",
    "start": "1284000",
    "end": "1290279"
  },
  {
    "text": "uh just to ask questions if I have if I have random questions about history or science or whatever I'll I'll just ask",
    "start": "1290279",
    "end": "1296960"
  },
  {
    "text": "it um but um I'd say uh the one I get the most utility out of is coding yeah",
    "start": "1296960",
    "end": "1305080"
  },
  {
    "text": "so you've been in AI for quite a long time if you look back on your time in AI",
    "start": "1305080",
    "end": "1311960"
  },
  {
    "text": "you know more than a decade what do you think of as the biggest advances or",
    "start": "1311960",
    "end": "1317640"
  },
  {
    "text": "conceptual breakthrough that have happened during that period well yeah I guess I started grad",
    "start": "1317640",
    "end": "1325480"
  },
  {
    "text": "school in 2010 so that's when I was sort of seriously in the field um and I'd say",
    "start": "1325480",
    "end": "1332720"
  },
  {
    "text": "um back back then well uh deep learning hadn't really taken off yeah so uh it",
    "start": "1332720",
    "end": "1339760"
  },
  {
    "text": "wasn't even clear um I remember thinking that",
    "start": "1339760",
    "end": "1344799"
  },
  {
    "text": "um it wasn't clear what um you would use uh um neuron nets for like if it it",
    "start": "1344799",
    "end": "1352799"
  },
  {
    "text": "wasn't clear that the making the model uh that we would even know what to do if",
    "start": "1352799",
    "end": "1358600"
  },
  {
    "text": "we had a model that had like a a model that was um more powerful um it wasn't even clear exactly what we would do with",
    "start": "1358600",
    "end": "1364960"
  },
  {
    "text": "it um so so I would say there are a few there were a lot of things that were less obvious than like we were um we",
    "start": "1364960",
    "end": "1371960"
  },
  {
    "text": "didn't know deep learning worked really well uh we didn't know um exactly what you would what training objective you",
    "start": "1371960",
    "end": "1378679"
  },
  {
    "text": "use if you did if we did know that neur neural Nets could be trained it wasn't clear exactly what to do with them and",
    "start": "1378679",
    "end": "1384760"
  },
  {
    "text": "uh like so I guess the the answer there ended up being fairly simple like",
    "start": "1384760",
    "end": "1390159"
  },
  {
    "text": "whatever uh like you can do reinforcement learning with neuron Nets you can train classifiers you can do uh",
    "start": "1390159",
    "end": "1396279"
  },
  {
    "text": "you can do maximum likelihood on sequences um and all these things work pretty well I mean some things that were",
    "start": "1396279",
    "end": "1403000"
  },
  {
    "text": "popular back then didn't end up working that well or didn't scale as well um so",
    "start": "1403000",
    "end": "1409360"
  },
  {
    "text": "yeah it's kind of uh the set of things that ended up scaling wasn't easily",
    "start": "1409360",
    "end": "1415880"
  },
  {
    "text": "foreseeable at that time but yeah and certainly the importance of scaling oh yeah and definitely scaling yeah the",
    "start": "1415880",
    "end": "1422640"
  },
  {
    "text": "fact that scaling was so important and the whole Paradigm of scaling laws yeah yeah I'm sure you you probably took an",
    "start": "1422640",
    "end": "1429240"
  },
  {
    "text": "introductory machine learning class at some point right and at least I don't know about now but a decade ago when",
    "start": "1429240",
    "end": "1435799"
  },
  {
    "text": "they were teaching introductory machine learning courses the the course would often start by Framing different areas",
    "start": "1435799",
    "end": "1441360"
  },
  {
    "text": "of of machine learning they say there's supervised learning which is like classification and regression and",
    "start": "1441360",
    "end": "1446880"
  },
  {
    "text": "there's unsupervised learning and when we talked about unsupervised learning at least when I took machine learning it",
    "start": "1446880",
    "end": "1453120"
  },
  {
    "text": "was mostly about clustering like K means clustering and and things like that I feel like I'm curious if you would agree",
    "start": "1453120",
    "end": "1460039"
  },
  {
    "text": "that our perspective on unsupervised learning is uh has changed quite a bit",
    "start": "1460039",
    "end": "1466279"
  },
  {
    "text": "over the past decade oh yeah defin I mean now it's not even clear what",
    "start": "1466279",
    "end": "1471799"
  },
  {
    "text": "unsupervised learning means uh like uh sequence modeling um is is uh like the",
    "start": "1471799",
    "end": "1478960"
  },
  {
    "text": "way the language models are trained is that unsupervised learning it's kind of supervised by predicting the future",
    "start": "1478960",
    "end": "1484720"
  },
  {
    "text": "given the past it's you know it still fits into the regression framework but or classification framework but uh you",
    "start": "1484720",
    "end": "1491159"
  },
  {
    "text": "don't have to spend a lot of energy labeling data and things like that yeah U but yeah it's not K means clustering",
    "start": "1491159",
    "end": "1497679"
  },
  {
    "text": "that's for sure I mean you can say that supervised learning is a special case of uh unsupervised learning or or doing",
    "start": "1497679",
    "end": "1503520"
  },
  {
    "text": "maximum likelihood uh so I think you know looking back a decade ago problems",
    "start": "1503520",
    "end": "1510480"
  },
  {
    "text": "like unsupervised learning were not that well understood or perhaps we didn't know how to conceptualize the problem",
    "start": "1510480",
    "end": "1518120"
  },
  {
    "text": "what do you think are the problems today that we're still figuring out how to",
    "start": "1518120",
    "end": "1524480"
  },
  {
    "text": "formulate I'd say there's a lot of problems around uh",
    "start": "1524480",
    "end": "1530279"
  },
  {
    "text": "well I'd say one problem I ended up thinking about a lot is data quality and um like how to um how to get really good",
    "start": "1530279",
    "end": "1537840"
  },
  {
    "text": "supervision uh for so like gbd4 is really good at a lot of things and it has a lot of breadth of knowledge and",
    "start": "1537840",
    "end": "1544279"
  },
  {
    "text": "it's often hard to even uh collect good labels to uh make it better like if you",
    "start": "1544279",
    "end": "1549640"
  },
  {
    "text": "like people um ask questions about um Al like they ask about all sorts of um",
    "start": "1549640",
    "end": "1556240"
  },
  {
    "text": "obscure topics or very technical topics and it's hard to find people who can label this like who can provide good",
    "start": "1556240",
    "end": "1563720"
  },
  {
    "text": "labels so um so so this um so there's this problem of how do you um how do you",
    "start": "1563720",
    "end": "1571000"
  },
  {
    "text": "uh supervise a model that's kind of superhuman and uh I would say this is so sometimes this",
    "start": "1571000",
    "end": "1577720"
  },
  {
    "text": "is called scalable oversight or scalable supervision uh people first got interested in this from the standpoint",
    "start": "1577720",
    "end": "1583320"
  },
  {
    "text": "of alignment and how how do you make uh yeah concern but with uh like the um",
    "start": "1583320",
    "end": "1589360"
  },
  {
    "text": "very smart models and how do we make sure they're doing what like doing what humans want so I'd say uh I'd say in",
    "start": "1589360",
    "end": "1597120"
  },
  {
    "text": "this area like some of the problems haven't even been formulated uh precisely yet yeah so you have good",
    "start": "1597120",
    "end": "1604440"
  },
  {
    "text": "taste in problems and what to work on how do you decide what problems to work",
    "start": "1604440",
    "end": "1611159"
  },
  {
    "text": "on yeah I don't think I have a really General uh uh framework for doing this I",
    "start": "1611159",
    "end": "1617200"
  },
  {
    "text": "I try to think about what but uh think about some uh some real world use cases",
    "start": "1617200",
    "end": "1623000"
  },
  {
    "text": "and what are some uh common uh like what are some Comon like limitations of our",
    "start": "1623000",
    "end": "1629200"
  },
  {
    "text": "existing methods uh that that would unlock a lot of uh opportunities um and I try to try to not",
    "start": "1629200",
    "end": "1636919"
  },
  {
    "text": "yeah try to think of the the advances that would feed into a lot of uh that would have a lot of Downstream",
    "start": "1636919",
    "end": "1643200"
  },
  {
    "text": "implications and are you thinking about how we get to human level intelligence and kind of work backwards from there or",
    "start": "1643200",
    "end": "1649600"
  },
  {
    "text": "thinking more about products that could be built or applications I'd say I do a little bit",
    "start": "1649600",
    "end": "1655279"
  },
  {
    "text": "of all of those I mean I I I thinking about what humans can do and how the human mind can works works and like",
    "start": "1655279",
    "end": "1662519"
  },
  {
    "text": "trying to introspect is useful but it doesn't it can also be misleading so I think it's useful to think about where",
    "start": "1662519",
    "end": "1668720"
  },
  {
    "text": "are humans much better than our models and uh where we might be missing something uh but it also um it's hard to",
    "start": "1668720",
    "end": "1675120"
  },
  {
    "text": "predict uh what order we're going to get AI to solve different problems and if something is uh how hard something is",
    "start": "1675120",
    "end": "1683039"
  },
  {
    "text": "for humans doesn't necessarily correlate that well with how hard it is for AI so you well math is hard for both of us",
    "start": "1683039",
    "end": "1689559"
  },
  {
    "text": "right definitely yeah so that's one yeah yeah so when you think about the path to",
    "start": "1689559",
    "end": "1696880"
  },
  {
    "text": "say human level intelligence do you think of it as more of a research challenge an engineering",
    "start": "1696880",
    "end": "1702559"
  },
  {
    "text": "challenge both or does the distinction not make sense yeah I'd say it's a it's",
    "start": "1702559",
    "end": "1709519"
  },
  {
    "text": "both it's a little of both and the the boundar is a little bit blurry like uh",
    "start": "1709519",
    "end": "1715080"
  },
  {
    "text": "definitely um you need to do a lot of engineering to get more data and train",
    "start": "1715080",
    "end": "1721200"
  },
  {
    "text": "bigger models on that data and then there's a lot of research for um like",
    "start": "1721200",
    "end": "1726799"
  },
  {
    "text": "how you can uh to just make that scaling work you need to uh figure out the",
    "start": "1726799",
    "end": "1732960"
  },
  {
    "text": "recipe of how all your hyperparameters scale and then there but then there's a lot of there's open question about",
    "start": "1732960",
    "end": "1739000"
  },
  {
    "text": "things like data quality and supervision that I just mentioned and you mentioned",
    "start": "1739000",
    "end": "1744519"
  },
  {
    "text": "high quality data in your view when a human is learning right how much high quality",
    "start": "1744519",
    "end": "1751120"
  },
  {
    "text": "data do we have access to like in a normal educational experience",
    "start": "1751120",
    "end": "1757120"
  },
  {
    "text": "um like how much do um like when humans are learning uh like learning from their",
    "start": "1757120",
    "end": "1763159"
  },
  {
    "text": "parents or schools and so forth like yeah I mean we have we have access to tons of data right both",
    "start": "1763159",
    "end": "1768559"
  },
  {
    "text": "things like textbooks as well as just all the you know sensory input that we we get in do you consider some of that",
    "start": "1768559",
    "end": "1776320"
  },
  {
    "text": "high quality and some of that low quality oh yeah well I guess human learning um humans are extremely um I",
    "start": "1776320",
    "end": "1783960"
  },
  {
    "text": "guess humans are able to learn from very undiverse data uh like so I think one of the most remarkable things is that a",
    "start": "1783960",
    "end": "1790679"
  },
  {
    "text": "human can grow up um in like spending most of their time in one household and",
    "start": "1790679",
    "end": "1796519"
  },
  {
    "text": "talking to a small number of people uh maybe going going to school so there's",
    "start": "1796519",
    "end": "1802159"
  },
  {
    "text": "not a lot of um data diversity compared to what we train our systems deep learning systems with and but still you",
    "start": "1802159",
    "end": "1809000"
  },
  {
    "text": "get an extremely robust model like a extremely robust Vision system even though you you've only seen this one",
    "start": "1809000",
    "end": "1814960"
  },
  {
    "text": "house uh so that's pretty crazy and I think we're nowhere near there are limits to that though right if you if",
    "start": "1814960",
    "end": "1820760"
  },
  {
    "text": "you you know never see vertical lines or something like that you know yeah um this has been fascinating are there",
    "start": "1820760",
    "end": "1828120"
  },
  {
    "text": "any common misconceptions that people have about open AI that um you'd like to clarify",
    "start": "1828120",
    "end": "1834200"
  },
  {
    "text": "for us yeah I'd say um sometimes I read Twitter and people are talking about chat gbt and they uh form they have some",
    "start": "1834200",
    "end": "1842440"
  },
  {
    "text": "speculations about what we're doing and sometimes I I think uh well sometimes um",
    "start": "1842440",
    "end": "1848720"
  },
  {
    "text": "people have some uh uh well people often think we're doing a lot more than we're",
    "start": "1848720",
    "end": "1854360"
  },
  {
    "text": "actually doing like they think we're monitoring uh everything like monitoring Twitter and usage in real time and",
    "start": "1854360",
    "end": "1860120"
  },
  {
    "text": "fixing the model uh like fine-tuning uh all the time and fixing all these problems and uh yeah I'd love to do like",
    "start": "1860120",
    "end": "1867000"
  },
  {
    "text": "the jailbreaks oh yeah fixing jailbreaks and uh like finding uh when the model gets a riddle wrong and we're going to",
    "start": "1867000",
    "end": "1873320"
  },
  {
    "text": "go and fix that uh so yeah it's more like we uh we love to fix things faster",
    "start": "1873320",
    "end": "1879919"
  },
  {
    "text": "but uh it's it's often hard like you can't um you don't want to just and you",
    "start": "1879919",
    "end": "1885279"
  },
  {
    "text": "don't want to just play whack-a-mole and uh fix these little problems um it's I'd",
    "start": "1885279",
    "end": "1890360"
  },
  {
    "text": "rather uh like look at the bulk of use cases and make every every um everyone's",
    "start": "1890360",
    "end": "1895679"
  },
  {
    "text": "experience better so it's more like we uh when we get feedback from people like they give thumbs down we use that as",
    "start": "1895679",
    "end": "1903240"
  },
  {
    "text": "part of our data labeling effort and we we try to collect some labels to to fix those examples but um yeah it's I'd say",
    "start": "1903240",
    "end": "1911760"
  },
  {
    "text": "that's um yeah people also um yeah people I think we're doing all",
    "start": "1911760",
    "end": "1918519"
  },
  {
    "text": "sorts of uh crazy things that we're not doing but glad to hear it yeah um John",
    "start": "1918519",
    "end": "1924799"
  },
  {
    "text": "it's been a pleasure this is thank you so much for for being here uh really",
    "start": "1924799",
    "end": "1929880"
  },
  {
    "text": "enjoyed the conversation uh everyone please join me and thanking John",
    "start": "1929880",
    "end": "1936200"
  },
  {
    "text": "schan I guess I will thanks for having me yeah",
    "start": "1936200",
    "end": "1942519"
  }
]
[
  {
    "text": "[Applause] good morning welcome to race Summit",
    "start": "2610",
    "end": "8360"
  },
  {
    "text": "thank you so much for being here what a great year for AI over the past year",
    "start": "8360",
    "end": "15400"
  },
  {
    "text": "billions of people have encountered Ai and so many of us here have put AI at",
    "start": "15400",
    "end": "20880"
  },
  {
    "text": "the heart of our products over the next couple of days you'll hear how Runway",
    "start": "20880",
    "end": "27240"
  },
  {
    "text": "and canva are transforming creativity what Netflix and bite dance are doing in",
    "start": "27240",
    "end": "33399"
  },
  {
    "text": "entertainment what Ford and zukes are doing in autonomous driving Tower",
    "start": "33399",
    "end": "38600"
  },
  {
    "text": "research in finance recursion in drug Discovery roadblocks in gaming and so",
    "start": "38600",
    "end": "43760"
  },
  {
    "text": "many more over the past year every business on Earth has realized that AI",
    "start": "43760",
    "end": "50039"
  },
  {
    "text": "is Central to its strategy and this community here building with Ray has had",
    "start": "50039",
    "end": "55879"
  },
  {
    "text": "a front row seat to that how cool is that [Applause]",
    "start": "55879",
    "end": "61760"
  },
  {
    "text": "Ray now thank you Ray now sees around 1 million unique",
    "start": "61760",
    "end": "67680"
  },
  {
    "text": "clusters launched every single month and my favorite stat Ry recently crossed the",
    "start": "67680",
    "end": "73080"
  },
  {
    "text": "1,000 contributor Mark to the open source project many of you are here with us today thank you so much for all of",
    "start": "73080",
    "end": "79200"
  },
  {
    "text": "your help building this project it's just been a massive collaborative",
    "start": "79200",
    "end": "84479"
  },
  {
    "text": "effort now many of you here are building AI platforms for your companies so you",
    "start": "85479",
    "end": "92759"
  },
  {
    "text": "know how powerful it can be when you can truly enable the latest AI capabilities",
    "start": "92759",
    "end": "99240"
  },
  {
    "text": "throughout your organization right capabilities ranging from Rapid iteration to massive scale spanning",
    "start": "99240",
    "end": "106040"
  },
  {
    "text": "classical machine learning and generative AI right if you do your job well you can enable every team",
    "start": "106040",
    "end": "113360"
  },
  {
    "text": "internally to be an AI team but you also know how hard it is to",
    "start": "113360",
    "end": "120320"
  },
  {
    "text": "actually do that over the past 6 months I've chatted with around 100 of you and",
    "start": "120320",
    "end": "127880"
  },
  {
    "text": "one message stood out very clearly complexity is blocking us we're",
    "start": "127880",
    "end": "134440"
  },
  {
    "text": "all clear on the potential we all want to do this but we're held back by complexity of AI and my co-founder Yan",
    "start": "134440",
    "end": "142000"
  },
  {
    "text": "will go into far more detail about the underlying Trends driving that driving this but this is the complexity",
    "start": "142000",
    "end": "148959"
  },
  {
    "text": "generated by scaling data not just more data but new data modalities text images video",
    "start": "148959",
    "end": "156959"
  },
  {
    "text": "scaling compute the pro the proliferation of Hardware accelerators of AI Frameworks",
    "start": "156959",
    "end": "162840"
  },
  {
    "text": "more and more AI being used for data processing itself and growing complexity",
    "start": "162840",
    "end": "168879"
  },
  {
    "text": "around post training and inference time compute none of this is going anywhere",
    "start": "168879",
    "end": "174840"
  },
  {
    "text": "and actually it's going to get a lot worse of course the potential is getting a lot bigger bigger but in parallel the",
    "start": "174840",
    "end": "181800"
  },
  {
    "text": "complexity is getting far worse and this complexity is actually why we set out to",
    "start": "181800",
    "end": "187519"
  },
  {
    "text": "build Ray in the first place 2016 the aha moment for Yan Philip",
    "start": "187519",
    "end": "195560"
  },
  {
    "text": "myself and those of us who originally built Ray was just a similar version of",
    "start": "195560",
    "end": "200920"
  },
  {
    "text": "exactly the same problem that we're seeing today we were researching deep learning and reinforcement learning",
    "start": "200920",
    "end": "207200"
  },
  {
    "text": "algorithms for our PhD at Berkeley and the funny thing is we weren't",
    "start": "207200",
    "end": "212400"
  },
  {
    "text": "actually doing research we were spending our time managing clusters or cobbling",
    "start": "212400",
    "end": "217519"
  },
  {
    "text": "together distributed systems or wrangling data we weren't setting out to",
    "start": "217519",
    "end": "223400"
  },
  {
    "text": "to change AI infrastructure and revolutionize AI infrastructure we were just trying to solve practical issues",
    "start": "223400",
    "end": "229439"
  },
  {
    "text": "that were driving us nuts but what we ended up building this",
    "start": "229439",
    "end": "234920"
  },
  {
    "text": "python first flexible seamless scaling approach everyone we talked to who was",
    "start": "234920",
    "end": "241040"
  },
  {
    "text": "serious about AI at the time needed to solve that problem and so it caught on slowly at",
    "start": "241040",
    "end": "250400"
  },
  {
    "text": "first the first serious Ray user was ants group they contributed a ton to",
    "start": "250400",
    "end": "256440"
  },
  {
    "text": "hardening Ray in production and today they use Ray on millions of CPU cores tens of thousands of gpus for use cases",
    "start": "256440",
    "end": "263840"
  },
  {
    "text": "ranging from batch inference to online learning to model serving and more",
    "start": "263840",
    "end": "270360"
  },
  {
    "text": "Uber was one of the next major Ray users and Pinterest those two contributed to fleshing out the data ingest and",
    "start": "270360",
    "end": "277080"
  },
  {
    "text": "pre-processing story for training which so many of us use today and is so important for uh how we think about",
    "start": "277080",
    "end": "283360"
  },
  {
    "text": "Ray's use cases today they run tens of thousands of batch jobs training jobs",
    "start": "283360",
    "end": "289360"
  },
  {
    "text": "every month but these were early adopters Ry was still very young the",
    "start": "289360",
    "end": "295960"
  },
  {
    "text": "real inflection point for Ray came with chat gbt and generative AI generative AI",
    "start": "295960",
    "end": "302320"
  },
  {
    "text": "took the complexity problem and made it 10 times worse it also made the potential and the promise 10 times",
    "start": "302320",
    "end": "308000"
  },
  {
    "text": "bigger or more but it made the complexity far worse and as a consequence Reay is now powering AI",
    "start": "308000",
    "end": "315160"
  },
  {
    "text": "workloads around the world the work this community is doing is truly bringing AI",
    "start": "315160",
    "end": "322120"
  },
  {
    "text": "to Life Next I'd like to welcome my co-founder Yan stoa co-founder and",
    "start": "322120",
    "end": "328000"
  },
  {
    "text": "chairman of any scale and data brick professor at UC Berkeley to the stage to",
    "start": "328000",
    "end": "333160"
  },
  {
    "text": "talk about the underlying Trends driving this complexity and why Ray has become the underpinning of so many AI platforms",
    "start": "333160",
    "end": "339680"
  },
  {
    "text": "please welcome [Applause]",
    "start": "339680",
    "end": "344520"
  },
  {
    "text": "[Music] Yan I'm thrilled to be here this is",
    "start": "349920",
    "end": "358199"
  },
  {
    "text": "really a historical moment for AI which means the need for Ray is only",
    "start": "358199",
    "end": "364840"
  },
  {
    "text": "growing the complexity that leading researchers like philli and Robert were",
    "start": "364840",
    "end": "370720"
  },
  {
    "text": "facing in our lab almost one decade ago has become the norm for AI developers at",
    "start": "370720",
    "end": "377759"
  },
  {
    "text": "every Enterprise today I know you all feel this the",
    "start": "377759",
    "end": "383479"
  },
  {
    "text": "complexity has become overwhelming so how did we get here",
    "start": "383479",
    "end": "389680"
  },
  {
    "text": "let's do a quick run through the modern computer history as you know I'm a",
    "start": "389680",
    "end": "395160"
  },
  {
    "text": "professor so I cannot help myself two decades ago we saw the rise",
    "start": "395160",
    "end": "401560"
  },
  {
    "text": "of big data in classic machine learning workloads these workloads require large",
    "start": "401560",
    "end": "407039"
  },
  {
    "text": "clusters to scale data and machine learning processing however these clusters are",
    "start": "407039",
    "end": "413280"
  },
  {
    "text": "homogenous consisting of more or less identical machines this is a had doop and Spark",
    "start": "413280",
    "end": "419240"
  },
  {
    "text": "store you all know well one decade ago we saw the rise of",
    "start": "419240",
    "end": "424960"
  },
  {
    "text": "deep learning and reinforcement learning workloads machine learning platforms came to the",
    "start": "424960",
    "end": "431039"
  },
  {
    "text": "four gpus started to become",
    "start": "431039",
    "end": "435840"
  },
  {
    "text": "indispensable then 5 years ago gen I'll go into more details on this",
    "start": "436840",
    "end": "443639"
  },
  {
    "text": "one but there are five Trends to keep in mind first scale",
    "start": "443639",
    "end": "450759"
  },
  {
    "text": "the computer requirements to train state-ofthe-art model has grown over five times every",
    "start": "450759",
    "end": "458120"
  },
  {
    "text": "year this has been driven by the SC scaling law which simply says that more",
    "start": "458120",
    "end": "464199"
  },
  {
    "text": "data and more compute equates better models correspondingly the cost of",
    "start": "464199",
    "end": "471599"
  },
  {
    "text": "training as you can see here with with GPT has increased more than one order of",
    "start": "471599",
    "end": "477840"
  },
  {
    "text": "magnitude every two year and it's not only the large language models the smaller models themselves are",
    "start": "477840",
    "end": "485080"
  },
  {
    "text": "much larger than their predecessors and it's not only",
    "start": "485080",
    "end": "491120"
  },
  {
    "text": "training also inference recently open AI released a one the most advanced",
    "start": "491120",
    "end": "497240"
  },
  {
    "text": "reasoning model where the context can be orders of magnitude larger than before",
    "start": "497240",
    "end": "503000"
  },
  {
    "text": "it may takes tens of seconds just to answer a single",
    "start": "503000",
    "end": "508039"
  },
  {
    "text": "question this is a beginning of a new scaling a era for model",
    "start": "508039",
    "end": "514479"
  },
  {
    "text": "inference second massive unstructured data text audio images video These data",
    "start": "516519",
    "end": "524519"
  },
  {
    "text": "modalities which are inherently much bigger than structured data have become increasingly",
    "start": "524519",
    "end": "530440"
  },
  {
    "text": "critical video companies building Foundation models like open AI with s or",
    "start": "530440",
    "end": "536480"
  },
  {
    "text": "genmo or and Runway are processing millions of images and videos every",
    "start": "536480",
    "end": "543000"
  },
  {
    "text": "day and Pinterest and apple who you will be here from later today are processing",
    "start": "543000",
    "end": "548440"
  },
  {
    "text": "petabytes of multimodal data to power their J applications and it's not just large",
    "start": "548440",
    "end": "554920"
  },
  {
    "text": "language models the unstructured data story also applies to tradition traditional",
    "start": "554920",
    "end": "561000"
  },
  {
    "text": "models third sophisticated posttraining training no longer means just",
    "start": "561000",
    "end": "567880"
  },
  {
    "text": "pre-training and fine-tuning but model pruning distillation merging",
    "start": "567880",
    "end": "573680"
  },
  {
    "text": "reinforcement learning and more fource AI it's used to build AI by that",
    "start": "573680",
    "end": "583800"
  },
  {
    "text": "I mean that AI is being increasingly used to optimize every aspect of model development from data preprocessing to",
    "start": "583800",
    "end": "590800"
  },
  {
    "text": "synthetic data generation to automatically partition models across multiple",
    "start": "590800",
    "end": "597000"
  },
  {
    "text": "gpus each part of the AI stack is it cell becoming AI",
    "start": "597000",
    "end": "602760"
  },
  {
    "text": "powered fifth in actual Enterprises we are not talking about just one model we",
    "start": "602760",
    "end": "609760"
  },
  {
    "text": "are talking now about compound Ai and agentic systems that involves tens even",
    "start": "609760",
    "end": "614959"
  },
  {
    "text": "hundreds of models including not only large language models but also traditional predictive models and more",
    "start": "614959",
    "end": "622760"
  },
  {
    "text": "compound AI systems only increase a pressure on the underly underlying AI infrastructure",
    "start": "622760",
    "end": "629560"
  },
  {
    "text": "to summarize the trends are scale multimodal data sophisticated post",
    "start": "629560",
    "end": "637279"
  },
  {
    "text": "trining AI powering AI stack and compound Ai and agentic",
    "start": "637279",
    "end": "644680"
  },
  {
    "text": "systems these developments put enormous pressure on the underlying",
    "start": "644880",
    "end": "650320"
  },
  {
    "text": "infrastructure to evolve the result innovation of",
    "start": "650320",
    "end": "656560"
  },
  {
    "text": "course above all Hardware accelerators just 5 years ago if I said",
    "start": "656560",
    "end": "663560"
  },
  {
    "text": "GPU we would be largely talking about a single GPU model from",
    "start": "663560",
    "end": "668720"
  },
  {
    "text": "Nvidia now one will be talking about W GPU we have not only Nvidia but MD Intel",
    "start": "668720",
    "end": "676800"
  },
  {
    "text": "and every Super scalar with its own accelerators and even when it comes to",
    "start": "676800",
    "end": "682000"
  },
  {
    "text": "Nvidia now we have h100 a100 A10 L4 and",
    "start": "682000",
    "end": "687200"
  },
  {
    "text": "much more moreover to support bigger and bigger",
    "start": "687200",
    "end": "692680"
  },
  {
    "text": "models we are rapid rapidly moving from single server gpus to Ports with",
    "start": "692680",
    "end": "698279"
  },
  {
    "text": "hundreds or thousands of tightly connected gpus and when it comes to using the",
    "start": "698279",
    "end": "703480"
  },
  {
    "text": "resource efficiently we need to decouple the CPU and GPU allocation to best fit",
    "start": "703480",
    "end": "709440"
  },
  {
    "text": "each application demands in summary we are witnessing a",
    "start": "709440",
    "end": "716560"
  },
  {
    "text": "historic transition from a CPU Centric to an accelerator Centric",
    "start": "716560",
    "end": "723440"
  },
  {
    "text": "World in addition we are seeing the emergence of AI Focus clouds like cor wave and Lambda lamps dozen of new",
    "start": "723440",
    "end": "731440"
  },
  {
    "text": "libraries Frameworks and tool for training and inference on llm inference alone we have",
    "start": "731440",
    "end": "737839"
  },
  {
    "text": "not only VM but trt llm and AG Lang as as well as a myriad of proprietary",
    "start": "737839",
    "end": "745959"
  },
  {
    "text": "Frameworks finally there in there is an explos ion of models over 1 million models are now",
    "start": "746160",
    "end": "754079"
  },
  {
    "text": "available on hugging face over three times more since our last",
    "start": "754079",
    "end": "760079"
  },
  {
    "text": "Summit so really the story is simple the huge changes in the compute",
    "start": "760079",
    "end": "767399"
  },
  {
    "text": "needs for machine learning and AI workloads led to very rapid innovation",
    "start": "767399",
    "end": "774199"
  },
  {
    "text": "in the infrastructure and tooling which led to enormous",
    "start": "774199",
    "end": "781480"
  },
  {
    "text": "complexity which in turn led to huge obstacles to AI",
    "start": "781480",
    "end": "788120"
  },
  {
    "text": "progress I know everyone who is trying to build an AI platforms knows the story by",
    "start": "788120",
    "end": "794480"
  },
  {
    "text": "heart we call this the AI complexity wall you hire the best Minds in Ai and",
    "start": "794480",
    "end": "803639"
  },
  {
    "text": "they spend their days writing yaml files and trou troubleshooting",
    "start": "803639",
    "end": "811120"
  },
  {
    "text": "kubernetes so the ey complexity wall leads to wasted resources skyrocketing cost and endless",
    "start": "812880",
    "end": "821519"
  },
  {
    "text": "timelines to get to production as Robert outlines we",
    "start": "821519",
    "end": "827399"
  },
  {
    "text": "originally created Ray to break this complexity wall a complexity wall that is growing",
    "start": "827399",
    "end": "833240"
  },
  {
    "text": "bigger and bigger every day and over the last eight years we've had so many conversations",
    "start": "833240",
    "end": "840320"
  },
  {
    "text": "with people in the growing R Community about this complexity wall and over and over again what we've",
    "start": "840320",
    "end": "847600"
  },
  {
    "text": "been hearing from you is that we need a unifying layer that sits between the",
    "start": "847600",
    "end": "853560"
  },
  {
    "text": "bare metal and the exploding AI ecosystem we need a softer engine you've",
    "start": "853560",
    "end": "859120"
  },
  {
    "text": "told us that can support any Ai and machine learning",
    "start": "859120",
    "end": "864360"
  },
  {
    "text": "workload any data types and model architecture the couples the allocation",
    "start": "864360",
    "end": "870120"
  },
  {
    "text": "of different resource types fully utilizes every",
    "start": "870120",
    "end": "875399"
  },
  {
    "text": "accelerators and scale from your laptop to thousand of gpus and do all this while being able to",
    "start": "875399",
    "end": "884160"
  },
  {
    "text": "abstract away the complexity of this infrastructure from the end developer and serve as a flexible and",
    "start": "884160",
    "end": "891560"
  },
  {
    "text": "unifying platform for the entire AI",
    "start": "891560",
    "end": "896399"
  },
  {
    "text": "ecosystem the rise of the AI era has made such an engine indispensable to the",
    "start": "896800",
    "end": "902399"
  },
  {
    "text": "progress of AI we are calling it an AI compute",
    "start": "902399",
    "end": "908759"
  },
  {
    "text": "engine an AI compute engine is critical technology for every company that wants to build a future prooof AI",
    "start": "908759",
    "end": "916519"
  },
  {
    "text": "platform thei compute engine we are here to talk about today is of course",
    "start": "916519",
    "end": "923240"
  },
  {
    "text": "Ray Ray has become the AI computer engine of choice for the world most experienced Engineers who are trying to",
    "start": "923240",
    "end": "929639"
  },
  {
    "text": "unlock AI in their companies now I like to welcome Robert",
    "start": "929639",
    "end": "935920"
  },
  {
    "text": "back on stage to walk us through the main elements of an AI compute engine",
    "start": "935920",
    "end": "941079"
  },
  {
    "text": "using gray as our prime example thank you all right",
    "start": "941079",
    "end": "949519"
  },
  {
    "text": "so I'm going to walk through a blueprint of this AI compute engine and this is a",
    "start": "949519",
    "end": "954720"
  },
  {
    "text": "picture we've formed from talking with hundreds of teams who are actually building AI platforms okay so I'll walk",
    "start": "954720",
    "end": "962240"
  },
  {
    "text": "through the individual components that make up this engine there are three core problems that the AI compute engine has",
    "start": "962240",
    "end": "969279"
  },
  {
    "text": "to solve managing compute resources managing data and executing",
    "start": "969279",
    "end": "974839"
  },
  {
    "text": "workloads so compute Resource Management what is this this is about managing the underlying diversity of cloud providers",
    "start": "974839",
    "end": "981959"
  },
  {
    "text": "Hardware accelerators that Yan talked about what kind of problems do you have to solve things like autoscaling",
    "start": "981959",
    "end": "987759"
  },
  {
    "text": "selecting the right instance types CPUs and gpus handling Hardware failures",
    "start": "987759",
    "end": "992839"
  },
  {
    "text": "which are increasingly common at scale right this this goes very deep data",
    "start": "992839",
    "end": "998319"
  },
  {
    "text": "management Yan mentioned that AI is becoming increasingly data intensive",
    "start": "998319",
    "end": "1003519"
  },
  {
    "text": "especially as multimodal models become commonplace right so handling data",
    "start": "1003519",
    "end": "1009199"
  },
  {
    "text": "effectively within this AI compute engine means handling large data it means leveraging shared memory it means",
    "start": "1009199",
    "end": "1015720"
  },
  {
    "text": "optimizing data movement through Frameworks communication framework like nickel and RDMA workload execution this is the core",
    "start": "1015720",
    "end": "1023880"
  },
  {
    "text": "scheduling and execution of the actual tasks that make up the AI workload",
    "start": "1023880",
    "end": "1029360"
  },
  {
    "text": "scheduling has to be fa tolerant it has to leverage accelerators right it has to be highly flexible to be able to support",
    "start": "1029360",
    "end": "1036400"
  },
  {
    "text": "the variety of AI workloads that are running on top otherwise you'll end up with different engines for different",
    "start": "1036400",
    "end": "1042720"
  },
  {
    "text": "workloads right so within the core compute engine you also have workload specific optimizations for the most",
    "start": "1042720",
    "end": "1049360"
  },
  {
    "text": "important Ai workloads and you have essential observability support because",
    "start": "1049360",
    "end": "1054440"
  },
  {
    "text": "people are going to spend all their time debugging and debugging performance so",
    "start": "1054440",
    "end": "1059799"
  },
  {
    "text": "this is the AI compute engine and the entire compute engine Powers the most",
    "start": "1059799",
    "end": "1065600"
  },
  {
    "text": "important AI workloads that we see reoccurring across so many different companies from data ingest and",
    "start": "1065600",
    "end": "1071360"
  },
  {
    "text": "pre-processing to training to inference but of course for those of you",
    "start": "1071360",
    "end": "1076640"
  },
  {
    "text": "building AI platforms you know that the compute engine is not the whole picture it sits within a vast ecosystem of",
    "start": "1076640",
    "end": "1084840"
  },
  {
    "text": "tools now without an AI compute engine AI teams can suffer from serious",
    "start": "1084840",
    "end": "1091159"
  },
  {
    "text": "fragmentation think different Tech stacks for classical ML and generative AI think segregated pools of compute for",
    "start": "1091159",
    "end": "1099159"
  },
  {
    "text": "different workloads or complex development to production handoffs or delays supporting new AI Frameworks or",
    "start": "1099159",
    "end": "1106640"
  },
  {
    "text": "models so this AI computer engine is needed to re in the growing complexity",
    "start": "1106640",
    "end": "1112480"
  },
  {
    "text": "of AI and that's why we're building Ray now the result of adding an AI",
    "start": "1112480",
    "end": "1117799"
  },
  {
    "text": "compute engine to your Tech stack can be dramatic after moving to Ray instacart",
    "start": "1117799",
    "end": "1124080"
  },
  {
    "text": "is training on a 100 times more data Niantic cut reduced lines of Code",
    "start": "1124080",
    "end": "1130120"
  },
  {
    "text": "by 85% and canva cut costs Cloud costs in",
    "start": "1130120",
    "end": "1136280"
  },
  {
    "text": "half these are just a few examples you'll hear dozens more today and",
    "start": "1136280",
    "end": "1141440"
  },
  {
    "text": "tomorrow so with the AI compute engine blueprint laid out I'd like to hand it",
    "start": "1141440",
    "end": "1146760"
  },
  {
    "text": "back to Yan to share our first Ray [Music]",
    "start": "1146760",
    "end": "1156520"
  },
  {
    "text": "announcement we have been building Ray for nearly a decade now we started with",
    "start": "1161600",
    "end": "1167200"
  },
  {
    "text": "the assumption that The Innovation AI will be relentless so we try to design a",
    "start": "1167200",
    "end": "1174360"
  },
  {
    "text": "platform that is flexible enough that is General enough to easily handle constant",
    "start": "1174360",
    "end": "1180320"
  },
  {
    "text": "advancement in AI this year we took a hard look at the",
    "start": "1180320",
    "end": "1186520"
  },
  {
    "text": "rapid changes in the AI or and asked a fresh what is needed for Ray to remain",
    "start": "1186520",
    "end": "1194200"
  },
  {
    "text": "the corei Platforms in every company we we talked to many of you",
    "start": "1194200",
    "end": "1200480"
  },
  {
    "text": "about the top problems you are facing about what challenges the next 5 years",
    "start": "1200480",
    "end": "1205720"
  },
  {
    "text": "will bring and based on what we learn from you we have a number of significant",
    "start": "1205720",
    "end": "1211440"
  },
  {
    "text": "announcement about how Ray continues to evolve let's start talking about",
    "start": "1211440",
    "end": "1218720"
  },
  {
    "text": "performance an necessity in a GPU first word where models are getting larger and",
    "start": "1218720",
    "end": "1225880"
  },
  {
    "text": "more complex consider the simple example of serving a",
    "start": "1225880",
    "end": "1231240"
  },
  {
    "text": "large language model with a mo where the model is so big that in order to serve",
    "start": "1231240",
    "end": "1236440"
  },
  {
    "text": "it we need to split it across multiple",
    "start": "1236440",
    "end": "1241360"
  },
  {
    "text": "gpus now while Ray is super flexible in general the pr the price it pays it's a",
    "start": "1242320",
    "end": "1250440"
  },
  {
    "text": "non-trivial overhead at runtime for tasks which are smaller smaller than a",
    "start": "1250440",
    "end": "1255480"
  },
  {
    "text": "few H tens of milliseconds and this can be the case here when we",
    "start": "1255480",
    "end": "1261400"
  },
  {
    "text": "generate a new token now here is everything gray does",
    "start": "1261400",
    "end": "1267400"
  },
  {
    "text": "to generate a single token quite a",
    "start": "1267400",
    "end": "1273200"
  },
  {
    "text": "lot so let me desect this for",
    "start": "1273200",
    "end": "1277760"
  },
  {
    "text": "you first Ray needs to allocate the memory dynamically every time it passes",
    "start": "1279880",
    "end": "1286720"
  },
  {
    "text": "an argument or a result between different nodes then to transfer the data between",
    "start": "1286720",
    "end": "1295159"
  },
  {
    "text": "gpus on different nodes Ray has first to copy the data from the GPU memory to CPU memory a slow",
    "start": "1295159",
    "end": "1303600"
  },
  {
    "text": "operation especially for large data items then it needs to transfer this",
    "start": "1303600",
    "end": "1309120"
  },
  {
    "text": "data over standard slow Network and finally copy a again data",
    "start": "1309120",
    "end": "1315000"
  },
  {
    "text": "from the CPU memory to GPU memory another slow",
    "start": "1315000",
    "end": "1320520"
  },
  {
    "text": "copy at the same time the head node needs to pass the references to arguments and results via a bunch of",
    "start": "1320600",
    "end": "1327720"
  },
  {
    "text": "remote procedure calls so lot of overhead to generate just one",
    "start": "1327720",
    "end": "1334640"
  },
  {
    "text": "token to reduce this overhead we are introducing the First new major API in Ray over the last couple of",
    "start": "1334640",
    "end": "1342200"
  },
  {
    "text": "years it is called compiled graphs this API is still experimental so",
    "start": "1342200",
    "end": "1349679"
  },
  {
    "text": "this is a preview and we invite you the community to help us evolve",
    "start": "1349679",
    "end": "1355200"
  },
  {
    "text": "it our goal here is to run task which takes less than 10 milliseconds with",
    "start": "1355200",
    "end": "1360679"
  },
  {
    "text": "less than 1% overhead so how do we do",
    "start": "1360679",
    "end": "1366120"
  },
  {
    "text": "this in a nutshell compiled graphs is a static task graph with Ray like API",
    "start": "1366120",
    "end": "1372720"
  },
  {
    "text": "which allocate resources once at the beginning and reuse these resources across multiple executions",
    "start": "1372720",
    "end": "1378720"
  },
  {
    "text": "going back to our examples we created a static graph consisting of two actors each actor handling a model partition we",
    "start": "1378720",
    "end": "1386919"
  },
  {
    "text": "compile this graph and then instantiate it as a result Ray pre allocates all the",
    "start": "1386919",
    "end": "1393840"
  },
  {
    "text": "resources and reuse them across multiple token Generations in particular it preallocate",
    "start": "1393840",
    "end": "1400720"
  },
  {
    "text": "static buffers for all arguments and result so no need for dynamic memory",
    "start": "1400720",
    "end": "1405919"
  },
  {
    "text": "allocation since we have pre-allocated all these buffers there is also no longer need to",
    "start": "1405919",
    "end": "1413200"
  },
  {
    "text": "pass around references to arguments and results and finally compile graphs set a",
    "start": "1413200",
    "end": "1421679"
  },
  {
    "text": "peer-to-peer communication between gpus and transfer data directly via Nvidia",
    "start": "1421679",
    "end": "1427279"
  },
  {
    "text": "nickel for instance so no longer slow CPU to GPU",
    "start": "1427279",
    "end": "1433240"
  },
  {
    "text": "memory copies or transfer over the slow Network",
    "start": "1433240",
    "end": "1439200"
  },
  {
    "text": "so what does this mean for basic operation well compile graphs are 17",
    "start": "1440640",
    "end": "1445960"
  },
  {
    "text": "times faster for GPU to GPU communication when gpus are on the same node two. time faster when gpus are on",
    "start": "1445960",
    "end": "1454159"
  },
  {
    "text": "different nodes and 30 time 13 time faster for scatter and gather operations",
    "start": "1454159",
    "end": "1460559"
  },
  {
    "text": "on the same Noe but what does this mean for",
    "start": "1460559",
    "end": "1466159"
  },
  {
    "text": "practical Ai and machine learning application",
    "start": "1466159",
    "end": "1470360"
  },
  {
    "text": "we've actually been using compil graphs on both inference and training workloads",
    "start": "1471279",
    "end": "1477679"
  },
  {
    "text": "and we've seen some immediate benefits for example we use compile",
    "start": "1477679",
    "end": "1483000"
  },
  {
    "text": "graphs to optimize llm inference by adding both tensor and pipeline",
    "start": "1483000",
    "end": "1488440"
  },
  {
    "text": "Paralis by doing so we increase the throughput for batch inference by 15%",
    "start": "1488440",
    "end": "1494360"
  },
  {
    "text": "this is already in production today but that's not all we also use compile graphs to optimize",
    "start": "1494360",
    "end": "1501799"
  },
  {
    "text": "training for M for multimodal architectures by collocating test",
    "start": "1501799",
    "end": "1508679"
  },
  {
    "text": "encoders to cheaper gpus we increase throughput per dollar by",
    "start": "1508679",
    "end": "1514279"
  },
  {
    "text": "40% all told we believe compile graphs is a major step towards future proofing",
    "start": "1514279",
    "end": "1521399"
  },
  {
    "text": "Ray as a high performance computer engine for the AI era and we can't wait",
    "start": "1521399",
    "end": "1528080"
  },
  {
    "text": "to to see how the community is going to use it and now back to Robert for the next",
    "start": "1528080",
    "end": "1537880"
  },
  {
    "text": "announcement thank you all right so if compiled graphs is",
    "start": "1539960",
    "end": "1548000"
  },
  {
    "text": "Ray's answer to our new GPU Centric World Ray data is the answer to the",
    "start": "1548000",
    "end": "1555080"
  },
  {
    "text": "explosion of unstructured data that we're seeing unstructured data pre-processing is the",
    "start": "1555080",
    "end": "1560880"
  },
  {
    "text": "single fastest growing use case of Ray that we've seen you'll hear about it throughout",
    "start": "1560880",
    "end": "1566720"
  },
  {
    "text": "this conference from Ford bite dance many others so what's special about these workloads well unstructured data",
    "start": "1566720",
    "end": "1574440"
  },
  {
    "text": "pre-processing and AI data pre-processing combines regular processing with inference it requires",
    "start": "1574440",
    "end": "1580760"
  },
  {
    "text": "CPU compute as well as GPU compute and it's both GPU intensive and data",
    "start": "1580760",
    "end": "1587799"
  },
  {
    "text": "intensive so these are brand new systems requirements Ray data handles everything",
    "start": "1587799",
    "end": "1594640"
  },
  {
    "text": "from ingestion ingesting the data in a streaming fashion Last Mile pre-processing and streaming the data",
    "start": "1594640",
    "end": "1600799"
  },
  {
    "text": "into training many of you are already using Ray data in this fashion I'm very excited for everyone else who's about to",
    "start": "1600799",
    "end": "1607200"
  },
  {
    "text": "use it if you're asking yourself why do we need another big data",
    "start": "1607200",
    "end": "1612399"
  },
  {
    "text": "processing system the answer is very simple today's big data processing",
    "start": "1612399",
    "end": "1617880"
  },
  {
    "text": "system like spark Flink Hadoop are CPU based and they operate best they work",
    "start": "1617880",
    "end": "1625360"
  },
  {
    "text": "best when they're operating on structured tabular data okay AI",
    "start": "1625360",
    "end": "1631039"
  },
  {
    "text": "workloads are GPU Centric and they often require unstructured data so this is a",
    "start": "1631039",
    "end": "1637200"
  },
  {
    "text": "brand new regime right SQL is not going anywhere structured data is not going anywhere but organizations are",
    "start": "1637200",
    "end": "1644559"
  },
  {
    "text": "increasingly going to use AI to read their data to reason about their data",
    "start": "1644559",
    "end": "1649960"
  },
  {
    "text": "and draw conclusions and so data processing is fundamentally becoming an AI driven and GPU driven workload right",
    "start": "1649960",
    "end": "1657720"
  },
  {
    "text": "and today's CPU based systems simply aren't going to work for those use cases",
    "start": "1657720",
    "end": "1663080"
  },
  {
    "text": "so we've tripled down on making Ray data excellent I'm thrilled to announce today that Ray data is now generally available",
    "start": "1663080",
    "end": "1670000"
  },
  {
    "text": "many of you are already using it and I'm very excited for everyone else to try it out again",
    "start": "1670000",
    "end": "1676240"
  },
  {
    "text": "congratulations thank you so much so like I said SQL is not going anywhere",
    "start": "1676240",
    "end": "1683440"
  },
  {
    "text": "but we expect companies to see massive performance wins and benefits when switching to Ray data for unstructured",
    "start": "1683440",
    "end": "1690159"
  },
  {
    "text": "and AI data processing just to give you a couple examples pinest beted up batch",
    "start": "1690159",
    "end": "1695200"
  },
  {
    "text": "GPU jobs by four times they'll be talking in this conference instacart will talk about 5x cheaper batch AI",
    "start": "1695200",
    "end": "1703240"
  },
  {
    "text": "processing but most impressively Amazon Amazon migrated an exibit scale data",
    "start": "1703240",
    "end": "1710679"
  },
  {
    "text": "processing workload from spark to Ray when they did that they cut costs by",
    "start": "1710679",
    "end": "1717360"
  },
  {
    "text": "82% saving $120 million every year that's",
    "start": "1717360",
    "end": "1724679"
  },
  {
    "text": "extraordinary all",
    "start": "1724679",
    "end": "1727880"
  },
  {
    "text": "right finally I want to talk about stability in terms of what actually",
    "start": "1730200",
    "end": "1737039"
  },
  {
    "text": "matters reliability at scale is at the very top especially for many of us here",
    "start": "1737039",
    "end": "1743919"
  },
  {
    "text": "where AI is increasingly the key to our competitive differentiation right if",
    "start": "1743919",
    "end": "1749320"
  },
  {
    "text": "that's the case we need infrastructure we can rely on that's not going to introduce risk or introduce delays as we",
    "start": "1749320",
    "end": "1755640"
  },
  {
    "text": "ship AI features faster and faster so with that in mind our team has been laser focused on improving the core",
    "start": "1755640",
    "end": "1763760"
  },
  {
    "text": "stability we've quadrupled the number of nodes supported in Array cluster to 8,000 we now ship weekly Ray releases to",
    "start": "1763760",
    "end": "1772600"
  },
  {
    "text": "get fixes and features in the hands of our users faster than ever before and",
    "start": "1772600",
    "end": "1778320"
  },
  {
    "text": "over the past year our team fixed 1,700 different reliability and usability issues this has been huge the pace is",
    "start": "1778320",
    "end": "1785360"
  },
  {
    "text": "only increasing and we have massive plans for the rest of this year so congratulations to the",
    "start": "1785360",
    "end": "1792679"
  },
  {
    "text": "team this has been a year of huge change at any scale the biggest is that my",
    "start": "1795640",
    "end": "1801559"
  },
  {
    "text": "co-founders Yan Phillip myself decided to bring on a new CEO to lead our next",
    "start": "1801559",
    "end": "1807240"
  },
  {
    "text": "stage of building and growth I'm very very excited to introduce him to you today kti mot is a builder he built",
    "start": "1807240",
    "end": "1814960"
  },
  {
    "text": "Aruba from zero to a massive customer obsessed business he's somebody who",
    "start": "1814960",
    "end": "1820480"
  },
  {
    "text": "understands the true power of community and someone who joined any scale because of the incredible growth of the ray",
    "start": "1820480",
    "end": "1826399"
  },
  {
    "text": "community so please welcome to the stage [Applause]",
    "start": "1826399",
    "end": "1831690"
  },
  {
    "text": "[Music]",
    "start": "1831690",
    "end": "1837159"
  },
  {
    "text": "kirti thanks Robert stay with me hello everyone so excited to be here at this",
    "start": "1837159",
    "end": "1843120"
  },
  {
    "text": "amazing event let me first start off with a huge thank you to Robert on",
    "start": "1843120",
    "end": "1848720"
  },
  {
    "text": "behalf of all of you for starting the ray project along with Yan and Phillip",
    "start": "1848720",
    "end": "1854399"
  },
  {
    "text": "and for your incredible stewardship of the community thank you Robert so",
    "start": "1854399",
    "end": "1859660"
  },
  {
    "text": "[Applause] much this community was one of the primary reasons why I joined any scale",
    "start": "1859660",
    "end": "1867000"
  },
  {
    "text": "the work you do and the impact you're you're making in this new world of AI is",
    "start": "1867000",
    "end": "1873559"
  },
  {
    "text": "so inspiring to see that I simply had to be a part of it my career I've entirely focused on",
    "start": "1873559",
    "end": "1881039"
  },
  {
    "text": "building infrastructure in each of the major technology waves starting with the internet followed by mobile and then the",
    "start": "1881039",
    "end": "1888919"
  },
  {
    "text": "cloud in each wave it took an entirely new generation of infrastructure to power it and AI",
    "start": "1888919",
    "end": "1896720"
  },
  {
    "text": "will be no different AI infrastructure that can process massive amounts of",
    "start": "1896720",
    "end": "1903159"
  },
  {
    "text": "data train and tune models of all sizes and serve them at scale is the",
    "start": "1903159",
    "end": "1911399"
  },
  {
    "text": "need of the hour and this is what motivates us at any scale this",
    "start": "1911399",
    "end": "1917919"
  },
  {
    "text": "opportunity to build infrastructure that empowers you to scale your AI applications is what",
    "start": "1917919",
    "end": "1924200"
  },
  {
    "text": "motivates us to do this well we must commit ourselves to three",
    "start": "1924200",
    "end": "1930120"
  },
  {
    "text": "key priorities the first one is Ray itself we need to continue to build Ray",
    "start": "1930120",
    "end": "1936559"
  },
  {
    "text": "to be the most powerful AI computer engine in the industry you just heard from Yan the release of compiled graphs",
    "start": "1936559",
    "end": "1943519"
  },
  {
    "text": "a major new update to Ray to enable GPU to GPU communication",
    "start": "1943519",
    "end": "1949600"
  },
  {
    "text": "you heard from Robert the general availability of Ray data and our commitment to keeping Ray the most",
    "start": "1949600",
    "end": "1955440"
  },
  {
    "text": "stable reliable and performant AI computer engine in the industry",
    "start": "1955440",
    "end": "1960960"
  },
  {
    "text": "period priority two for us is this community all of",
    "start": "1960960",
    "end": "1966039"
  },
  {
    "text": "you we need to continue to Foster and grow this community and we are today already 50,000 strong which is an",
    "start": "1966039",
    "end": "1972639"
  },
  {
    "text": "incredible feat but we need to we need to be 10 times the size if we are to",
    "start": "1972639",
    "end": "1977880"
  },
  {
    "text": "meet the needs of this growing AI wave in front of us and to do that each one",
    "start": "1977880",
    "end": "1983240"
  },
  {
    "text": "of you in this room is the key it is very clear you've been super engaged in the",
    "start": "1983240",
    "end": "1989159"
  },
  {
    "text": "community uh helping each other and I just wanted to name a few particularly",
    "start": "1989159",
    "end": "1994720"
  },
  {
    "text": "prolific contributions over the last year teams at Intel Amazon and AMD have",
    "start": "1994720",
    "end": "2001159"
  },
  {
    "text": "added support for their accelerators Google Microsoft Huawei and",
    "start": "2001159",
    "end": "2006240"
  },
  {
    "text": "group workday eBay and by dance and the list goes on you've all made significant",
    "start": "2006240",
    "end": "2012120"
  },
  {
    "text": "contributions to cube Ray Ray cor Ray serve and the observability",
    "start": "2012120",
    "end": "2018200"
  },
  {
    "text": "tooling I just want to take wanted to take a moment to recognize all your",
    "start": "2018200",
    "end": "2023320"
  },
  {
    "text": "efforts and for your significant contributions thank you so [Applause]",
    "start": "2023320",
    "end": "2033320"
  },
  {
    "text": "much our third priority is we want any scale to be your",
    "start": "2033320",
    "end": "2040039"
  },
  {
    "text": "partner to both Dr risk and turbocharge your AI initiatives in my first weeks",
    "start": "2040039",
    "end": "2046960"
  },
  {
    "text": "here at any scale as I met with a number of you it became very clear to me that",
    "start": "2046960",
    "end": "2052320"
  },
  {
    "text": "Ray is core to your work and you want any scale to be an integral part of",
    "start": "2052320",
    "end": "2059118"
  },
  {
    "text": "it and it was also very clear that only a small handful of companies have the",
    "start": "2059119",
    "end": "2065720"
  },
  {
    "text": "resources that it takes to build an AI platform around Ray as your computer",
    "start": "2065720",
    "end": "2074118"
  },
  {
    "text": "engine so to achieve this objective we've built an Enterprise class managed",
    "start": "2074119",
    "end": "2079480"
  },
  {
    "text": "race service that allows you to deliver a fully unified AI",
    "start": "2079480",
    "end": "2084560"
  },
  {
    "text": "platform any scale leaves all your data in your computer State and adds a thin",
    "start": "2084560",
    "end": "2091878"
  },
  {
    "text": "control plane on top that you as platform engineers and AIML",
    "start": "2091879",
    "end": "2096919"
  },
  {
    "text": "practitioners can interface with to really get the best out of Ray and to",
    "start": "2096919",
    "end": "2102880"
  },
  {
    "text": "understand what we've added in any scales manag Ray service let's refer back to the blueprint that Robert talked",
    "start": "2102880",
    "end": "2110560"
  },
  {
    "text": "about so here's whats in Ray and here's what we're adding in any",
    "start": "2110560",
    "end": "2116800"
  },
  {
    "text": "scale first any scale brings together all your compute resources in a unified",
    "start": "2116800",
    "end": "2122839"
  },
  {
    "text": "compute pool next a truly op optimized Ray",
    "start": "2122839",
    "end": "2128920"
  },
  {
    "text": "runtime that is up to six times more performant than Ray open source you'll",
    "start": "2128920",
    "end": "2135119"
  },
  {
    "text": "hear a lot more about this shortly third we've added an entire",
    "start": "2135119",
    "end": "2141119"
  },
  {
    "text": "governance layer that every Enterprise needs to maintain control over AI sprawl",
    "start": "2141119",
    "end": "2148240"
  },
  {
    "text": "and runaway spending and lastly an end to-end Suite",
    "start": "2148240",
    "end": "2154040"
  },
  {
    "text": "of developer tools and Production Services to create and build and scale",
    "start": "2154040",
    "end": "2160079"
  },
  {
    "text": "AI applications next we are going to hear",
    "start": "2160079",
    "end": "2165440"
  },
  {
    "text": "about a number of major feature enhancements to to I mean to the NIS scale platform designed to make Nale",
    "start": "2165440",
    "end": "2172200"
  },
  {
    "text": "work for you and optimize your top workloads to talk through these announcements let me now welcome any",
    "start": "2172200",
    "end": "2179520"
  },
  {
    "text": "scales head of engineering jumar Ganesh to the stage [Applause]",
    "start": "2179520",
    "end": "2187119"
  },
  {
    "text": "thank you KY excited to be here how's everyone doing all right let's try something fun",
    "start": "2193359",
    "end": "2200480"
  },
  {
    "text": "here i' would like everyone to stand up stretch up your arms and legs on count of 3 2 1 we are going to",
    "start": "2200480",
    "end": "2207400"
  },
  {
    "text": "say Ray cor ray rocks actually three 2",
    "start": "2207400",
    "end": "2213599"
  },
  {
    "text": "one okay let's do it again louder this time three two",
    "start": "2213599",
    "end": "2218960"
  },
  {
    "text": "one rocks great you know what I actually agree with all of you Ray indeed rocks",
    "start": "2218960",
    "end": "2225800"
  },
  {
    "text": "please take a seat so kti talked about optimizing your",
    "start": "2225800",
    "end": "2233040"
  },
  {
    "text": "top workloads Robert earlier showed the AI computer engine while Ray thus abstract",
    "start": "2233040",
    "end": "2240440"
  },
  {
    "text": "away lot of the complexity of the underlying distributed compute infrastructure it absolutely does not",
    "start": "2240440",
    "end": "2246599"
  },
  {
    "text": "hide these away from you you this is not an overly simplified serverless solution",
    "start": "2246599",
    "end": "2252280"
  },
  {
    "text": "we have carefully taken knobs levers and pedals and exposed it to the serious drivers this is a Formula 1 compute",
    "start": "2252280",
    "end": "2260440"
  },
  {
    "text": "engine we have taken this compute engine worked with all of you to optimize your",
    "start": "2260440",
    "end": "2265800"
  },
  {
    "text": "workloads and today we are excited to announce any scales hyper optimized",
    "start": "2265800",
    "end": "2271640"
  },
  {
    "text": "version of Ray we're calling it Ray turbo to take a deeper look on how Ray",
    "start": "2271640",
    "end": "2277240"
  },
  {
    "text": "Turbo with us on a data processing workload I would like to invite Richard Leo co-creator of Ray and product",
    "start": "2277240",
    "end": "2283400"
  },
  {
    "text": "manager at any scale onto the [Music]",
    "start": "2283400",
    "end": "2289030"
  },
  {
    "text": "[Applause] [Music]",
    "start": "2289030",
    "end": "2295839"
  },
  {
    "text": "stage thanks Jak for the introduction let's talk about Ray turbo to start Ray turbo is fast",
    "start": "2299200",
    "end": "2308240"
  },
  {
    "text": "we ran a workload comparing Ray turbo to open source Ray data and this workload is really simple read some data from",
    "start": "2308240",
    "end": "2315160"
  },
  {
    "text": "storage and iterate over it similar to the data interest phase of the distribute training",
    "start": "2315160",
    "end": "2321839"
  },
  {
    "text": "workload and what we did was we scaled the data set from 10 GB to 1 terabyte",
    "start": "2321839",
    "end": "2327400"
  },
  {
    "text": "and we measured the time it takes for the first output to be returned now compared to open source Ray",
    "start": "2327400",
    "end": "2334800"
  },
  {
    "text": "the any scale Ray turbo implementation is able able to perform up to 4.5 times",
    "start": "2334800",
    "end": "2339960"
  },
  {
    "text": "faster that's really really fast now Ray turbo is not only super",
    "start": "2339960",
    "end": "2346160"
  },
  {
    "text": "fast it also slashes your AI cost so batch inference for llms is a critical",
    "start": "2346160",
    "end": "2352359"
  },
  {
    "text": "workload for all of you so let's see how rate turbo does on costs here here we",
    "start": "2352359",
    "end": "2358119"
  },
  {
    "text": "have taken an 8B model run it on a data set of requests 2,000 input and 100",
    "start": "2358119",
    "end": "2363520"
  },
  {
    "text": "output tokens with no shared prefixes we compared any scales Ray Turbo with open",
    "start": "2363520",
    "end": "2369319"
  },
  {
    "text": "a GPT 40 mini batch pricing and Bedrock pricing we notice that Ray turbo is 2.2x",
    "start": "2369319",
    "end": "2376720"
  },
  {
    "text": "cheaper than open Ai and 2.9x cheaper than Bedrock batch",
    "start": "2376720",
    "end": "2383040"
  },
  {
    "text": "pricing of course in batch L inference many times the same prompt is shared",
    "start": "2383040",
    "end": "2389160"
  },
  {
    "text": "across multiple requests and in such situations unlike",
    "start": "2389160",
    "end": "2394800"
  },
  {
    "text": "open Ai and ads bedrock any scale can take advantage of prefixed",
    "start": "2394800",
    "end": "2400240"
  },
  {
    "text": "caching as a result we can see a much greater cost differential on the same",
    "start": "2400240",
    "end": "2406119"
  },
  {
    "text": "workload if we assume a large shared prompt we see that the any scale rate",
    "start": "2406119",
    "end": "2412079"
  },
  {
    "text": "turbo solution for this workload comes out to be 6.1 times cheaper than AWS",
    "start": "2412079",
    "end": "2418000"
  },
  {
    "text": "Bedrock even with its batch pricing and here's the biggest kicker these numbers",
    "start": "2418000",
    "end": "2424000"
  },
  {
    "text": "were achieved without h100s or A1 100s that were generated on widely available",
    "start": "2424000",
    "end": "2429319"
  },
  {
    "text": "compute namely l4s and l4s this is going to be a huge game",
    "start": "2429319",
    "end": "2435160"
  },
  {
    "text": "changer for allm use cases across the board now Ray turbo doesn't only slash",
    "start": "2435160",
    "end": "2441160"
  },
  {
    "text": "cost it also dramatically improves workload scaling so in serving workloads scale up",
    "start": "2441160",
    "end": "2448839"
  },
  {
    "text": "speeds matter a ton to illustrate Ray Turbo's capabilities in this situation we",
    "start": "2448839",
    "end": "2455520"
  },
  {
    "text": "compared open source Cube Ray with any scale rate turbo and we measured the time it took to start up a 70 billion",
    "start": "2455520",
    "end": "2462480"
  },
  {
    "text": "parameter model from scratch now while the open source solution takes nearly 10 minutes the any",
    "start": "2462480",
    "end": "2470119"
  },
  {
    "text": "scale solution is able to scale up the replica in about 100 seconds and less",
    "start": "2470119",
    "end": "2475359"
  },
  {
    "text": "than 1 minute is spent to load the model itself together that's a 5.1 times",
    "start": "2475359",
    "end": "2482280"
  },
  {
    "text": "endtoend improvement over the open source Cube Ray and open source defaults that's really really",
    "start": "2482280",
    "end": "2490040"
  },
  {
    "text": "impactful so we showed that Ray turbo is fast and it makes your batch inference",
    "start": "2490040",
    "end": "2497160"
  },
  {
    "text": "workloads and serving workloads scale up really quickly all of these are impactful numbers that have a impact on",
    "start": "2497160",
    "end": "2504359"
  },
  {
    "text": "your bottom line but there are a lot more examples where Ray turbo really",
    "start": "2504359",
    "end": "2509680"
  },
  {
    "text": "shines so let's look at some of them we saw that we can lower cost on",
    "start": "2509680",
    "end": "2516040"
  },
  {
    "text": "spot instances for for workloads like elastic training we reduce the number of nodes required using techniques like",
    "start": "2516040",
    "end": "2522680"
  },
  {
    "text": "replica compaction for your serving workloads and we are seeing higher QPS with an optimized version of racer all",
    "start": "2522680",
    "end": "2530280"
  },
  {
    "text": "of this on R turbo available exclusively to any scale customers we also worked",
    "start": "2530280",
    "end": "2536200"
  },
  {
    "text": "with all of you to improve the stability and reliability of the system it kind of makes it a no-brainer to use any scale",
    "start": "2536200",
    "end": "2543040"
  },
  {
    "text": "the best place for using Ray and getting the power and benefits of Ray Ki talked about deploying in your",
    "start": "2543040",
    "end": "2549640"
  },
  {
    "text": "environments and your work uh resources to talk more about that I'd like to",
    "start": "2549640",
    "end": "2554800"
  },
  {
    "text": "invite Dominic and E infrastructure leads on any scale onto the",
    "start": "2554800",
    "end": "2560730"
  },
  {
    "text": "[Applause] [Music] [Applause]",
    "start": "2560730",
    "end": "2565830"
  },
  {
    "text": "[Music] [Applause] [Music]",
    "start": "2565830",
    "end": "2571310"
  },
  {
    "text": "stage all right JK mentioned F1 but let's take this analogy one one step",
    "start": "2571480",
    "end": "2577839"
  },
  {
    "text": "further winning in F1 comes down to four key factors power speed efficiency and",
    "start": "2577839",
    "end": "2587599"
  },
  {
    "text": "control we chose this metaphor for a reason because if you are an AI platform leader you're typically balancing",
    "start": "2587599",
    "end": "2594440"
  },
  {
    "text": "between these attributes for yourselves and for your teams what do I mean power you need to put all the",
    "start": "2594440",
    "end": "2602319"
  },
  {
    "text": "horsepower you have behind your developers speed",
    "start": "2602319",
    "end": "2608000"
  },
  {
    "text": "you need your developers to drive fast the race for AI is happening at",
    "start": "2608000",
    "end": "2613920"
  },
  {
    "text": "break neck speeds and you must remove all roadblocks",
    "start": "2613920",
    "end": "2619280"
  },
  {
    "text": "efficiency you want to take full advantage of every resource that's available firing on all cylinders but",
    "start": "2619280",
    "end": "2626440"
  },
  {
    "text": "not burning through the gas and finally control you need to give your developers",
    "start": "2626440",
    "end": "2632359"
  },
  {
    "text": "guard rails because these cars are insanely fast and very very",
    "start": "2632359",
    "end": "2638280"
  },
  {
    "text": "pricey we're going to dive into each one of these let's start with power at any",
    "start": "2638280",
    "end": "2645720"
  },
  {
    "text": "scale we have been building a turbocharged engine aimed at getting the most out of cloud machines on AWS and",
    "start": "2645720",
    "end": "2654160"
  },
  {
    "text": "gcp however the last years have shown while the clouds are powerful they are",
    "start": "2654160",
    "end": "2659559"
  },
  {
    "text": "not unlimited many of us here are very familiar with this error message yes",
    "start": "2659559",
    "end": "2666359"
  },
  {
    "text": "Cloud might have capacity issues and clouds are certainly not cheap we've seen company of every size",
    "start": "2666359",
    "end": "2674240"
  },
  {
    "text": "rethink their Cloud strategy many of which decide to go invest back in on",
    "start": "2674240",
    "end": "2679319"
  },
  {
    "text": "Prem specialized machines what if we could take the power of these on print machines and make them",
    "start": "2679319",
    "end": "2686200"
  },
  {
    "text": "available to our scientists and Engineers just like the clouds so with",
    "start": "2686200",
    "end": "2691599"
  },
  {
    "text": "this vision in mind we have built the any scale machine pool Ma machine pool makes it easy to",
    "start": "2691599",
    "end": "2698680"
  },
  {
    "text": "create hybrid Ray cluster that span both the cloud and on premises taking any",
    "start": "2698680",
    "end": "2705319"
  },
  {
    "text": "machines in the world to amp up what's available in the cloud and of course you get all the",
    "start": "2705319",
    "end": "2711440"
  },
  {
    "text": "optimization of R turbo JK and Richard just talked about out of the box and",
    "start": "2711440",
    "end": "2716520"
  },
  {
    "text": "there you go power machine pools takes our VM offering and shifts it into overdrive",
    "start": "2716520",
    "end": "2724319"
  },
  {
    "text": "but it doesn't unlock compute for everyone we know that the developers and companies pushing the boundaries of AI",
    "start": "2724319",
    "end": "2730920"
  },
  {
    "text": "on Ray you all here today have largely been deploying on top of kubernetes with",
    "start": "2730920",
    "end": "2737400"
  },
  {
    "text": "KUB by far the most common pattern we see so this year we thought to ourselves",
    "start": "2737400",
    "end": "2744359"
  },
  {
    "text": "how do we take any scale our platform our optimized Ray and deliver it to you on top of your kubernetes",
    "start": "2744359",
    "end": "2751280"
  },
  {
    "text": "clusters in that vein we're thrilled to announce the any scale operator for kubernetes",
    "start": "2751280",
    "end": "2758520"
  },
  {
    "text": "the any scale operator lets you supercharge Ray on your kubernetes clusters letting any scale deal with the",
    "start": "2758520",
    "end": "2764400"
  },
  {
    "text": "heavy lifting of configurations dependencies and security of Ray the any scale operator was designed",
    "start": "2764400",
    "end": "2771720"
  },
  {
    "text": "to be highly customizable meaning any scale can be a part of your existing AI",
    "start": "2771720",
    "end": "2778640"
  },
  {
    "text": "platform but we're not doing this alone we're thrilled to announce our launch partners for the nkill operator for",
    "start": "2778640",
    "end": "2785920"
  },
  {
    "text": "kubernetes so whether you're on Amazon eks taking advantage of tranium and",
    "start": "2785920",
    "end": "2791240"
  },
  {
    "text": "inferentia whether you're on Google gke leveraging their tpus on Azure AKs or",
    "start": "2791240",
    "end": "2798760"
  },
  {
    "text": "even Oracle Cloud infrastructure we can work together to bring the best of any",
    "start": "2798760",
    "end": "2804440"
  },
  {
    "text": "scale Ray and these providers to you so thank you very much for our launch",
    "start": "2804440",
    "end": "2810079"
  },
  {
    "text": "Partners there's much much more to come so to make this super clear",
    "start": "2810079",
    "end": "2818240"
  },
  {
    "text": "whether you're running on cloud native VMS on premises or on kubernetes any",
    "start": "2818240",
    "end": "2824280"
  },
  {
    "text": "scale can turbocharge your ray clusters anywhere in the",
    "start": "2824280",
    "end": "2830200"
  },
  {
    "text": "[Applause]",
    "start": "2830200",
    "end": "2837880"
  },
  {
    "text": "world now let's switch gears and talk about speed I'm sure many of us here have St",
    "start": "2837880",
    "end": "2845520"
  },
  {
    "text": "through the pain of waiting 5 10 20 even 30 minutes for a large cluster to spin",
    "start": "2845520",
    "end": "2851839"
  },
  {
    "text": "up and then having the realization we need to do this over again just to try a",
    "start": "2851839",
    "end": "2857319"
  },
  {
    "text": "different GPU type I know this entire process is very slow it's very frustrating it does nothing but holding",
    "start": "2857319",
    "end": "2864280"
  },
  {
    "text": "us back so to solve this problem we have built the advanced instance manager",
    "start": "2864280",
    "end": "2870359"
  },
  {
    "text": "capable of launching massive Ray cluster extremely fast we're talking launching s thousands",
    "start": "2870359",
    "end": "2877200"
  },
  {
    "text": "of notes in under just a minute it also scales up faster than open source rate speeding up your",
    "start": "2877200",
    "end": "2884319"
  },
  {
    "text": "iteration cycle so you don't have to spin your wheels so to take this a step further",
    "start": "2884319",
    "end": "2890599"
  },
  {
    "text": "we're also introducing the automatic work note selection feature this is a feature that allow you to specify your",
    "start": "2890599",
    "end": "2897480"
  },
  {
    "text": "resource requirements like your accelerate typ directly in your R code instead of in a separate configuration",
    "start": "2897480",
    "end": "2904240"
  },
  {
    "text": "file and then it will automatically choose the most cost effective instant type for",
    "start": "2904240",
    "end": "2910000"
  },
  {
    "text": "you overall the advanced instance manager lets you focus on your AI",
    "start": "2910000",
    "end": "2915559"
  },
  {
    "text": "application instead of wasting your precious time thinking about the underlying machines so saving time",
    "start": "2915559",
    "end": "2922800"
  },
  {
    "text": "saving money going fast let's turn to",
    "start": "2922800",
    "end": "2928920"
  },
  {
    "text": "efficiency the cost of AI is real being able to launch clusters",
    "start": "2928920",
    "end": "2935480"
  },
  {
    "text": "quickly and reliably on the most cost efficient infrastructure saves time",
    "start": "2935480",
    "end": "2940799"
  },
  {
    "text": "money and your developer sanity which is why we built the advanced instance manager to be aware of",
    "start": "2940799",
    "end": "2947720"
  },
  {
    "text": "every region and availability Zone we're able to maximize availability while also",
    "start": "2947720",
    "end": "2953520"
  },
  {
    "text": "optimizing for spot utilization with a single flag one flag",
    "start": "2953520",
    "end": "2960760"
  },
  {
    "text": "we can scan an entire region for spot capacity before looking for on demand",
    "start": "2960760",
    "end": "2966799"
  },
  {
    "text": "and when spot becomes available again we can seamlessly migrate your workload",
    "start": "2966799",
    "end": "2972119"
  },
  {
    "text": "back to spot so as capacity changes as your",
    "start": "2972119",
    "end": "2977760"
  },
  {
    "text": "workload scales any scale is consistently Landing your AI applications on the most cost-efficient",
    "start": "2977760",
    "end": "2986760"
  },
  {
    "text": "infrastructure lastly control backing all of this is the any",
    "start": "2986760",
    "end": "2992400"
  },
  {
    "text": "scale governance Suite the any scale governance Suite gives you everything you need resource",
    "start": "2992400",
    "end": "2999520"
  },
  {
    "text": "quota management budgets visibility Telemetry everything you need to stay",
    "start": "2999520",
    "end": "3006920"
  },
  {
    "text": "friends with legal and finance very important but seriously we",
    "start": "3006920",
    "end": "3013119"
  },
  {
    "text": "want every team to become an AI team and the any skill governance Suite has you",
    "start": "3013119",
    "end": "3019880"
  },
  {
    "text": "covered so to recap today we are launching features",
    "start": "3019880",
    "end": "3025920"
  },
  {
    "text": "that gives you the full power of all of your resources in your computer State on",
    "start": "3025920",
    "end": "3031839"
  },
  {
    "text": "Cloud on Prem and on kubernetes we're releasing radical speed",
    "start": "3031839",
    "end": "3037119"
  },
  {
    "text": "and efficiency so your engineers can rapidly unlock the full potential of",
    "start": "3037119",
    "end": "3042920"
  },
  {
    "text": "this estate and finally the fine grain control you need to maintain your sanity",
    "start": "3042920",
    "end": "3050240"
  },
  {
    "text": "as a platform leader because yeah these cars sely",
    "start": "3050240",
    "end": "3055440"
  },
  {
    "text": "nice now now to take us through the life of a developer on any scale let's please",
    "start": "3055440",
    "end": "3061079"
  },
  {
    "text": "welcome to the stage Goku and [Applause] [Music]",
    "start": "3061079",
    "end": "3074319"
  },
  {
    "text": "Angelina so Goku I know you have that flight to catch tonight for your",
    "start": "3074319",
    "end": "3080400"
  },
  {
    "text": "honeymoon yeah you know that image identification application you started to build yes you're going to need to",
    "start": "3080400",
    "end": "3087440"
  },
  {
    "text": "finish that before you go right before my honeymoon all right well I started",
    "start": "3087440",
    "end": "3092640"
  },
  {
    "text": "developing on this any scale workspace here and you've literally caught me right in the middle of total dependency",
    "start": "3092640",
    "end": "3098280"
  },
  {
    "text": "hell I have no idea what compute my workloads need and I don't even know how to get started with debugging any of my",
    "start": "3098280",
    "end": "3104839"
  },
  {
    "text": "workloads I'm totally screwed relax breathe walk me through these one by one",
    "start": "3104839",
    "end": "3112040"
  },
  {
    "text": "okay well for one I forgot to install a really important dependency and now I have to go through each of my workers",
    "start": "3112040",
    "end": "3117839"
  },
  {
    "text": "one by one and who knows how many other dependencies I forgot I'm going to have to make a phone call and probably catch a later flight now hold on isn't that",
    "start": "3117839",
    "end": "3125359"
  },
  {
    "text": "why we bought any scale just do the PIP install on the console and now your head",
    "start": "3125359",
    "end": "3131400"
  },
  {
    "text": "node and all your workers that you might spin up later on will automatically have",
    "start": "3131400",
    "end": "3137319"
  },
  {
    "text": "your dependencies ready to go whoa okay that's really cool and I feel like this is going to save me a ton of time but uh",
    "start": "3137319",
    "end": "3144400"
  },
  {
    "text": "I feel as like a developer I know how to make things like these workloads but I have no idea what compute I need I I",
    "start": "3144400",
    "end": "3151160"
  },
  {
    "text": "just don't even know where to get started with this don't worry about it we toggled the Autos select worker nodes",
    "start": "3151160",
    "end": "3157160"
  },
  {
    "text": "so any scale will spin up the right number of workers execute the workload",
    "start": "3157160",
    "end": "3162280"
  },
  {
    "text": "and spin them back down when they're done okay that is really cool and I feel like this is going to save us a ton of",
    "start": "3162280",
    "end": "3168319"
  },
  {
    "text": "time and money hopefully money that can be applied towards my next bonus he not",
    "start": "3168319",
    "end": "3174520"
  },
  {
    "text": "okay we at the shot all right more workers sounds great but I feel like with more workers doesn't that also mean more problems I mean what if what if I",
    "start": "3174520",
    "end": "3181200"
  },
  {
    "text": "experience an error here how do I how am I going to know where to look and debug that's going to take me forever let me actually make that phone call and",
    "start": "3181200",
    "end": "3187240"
  },
  {
    "text": "probably cancel the whole trip right now stop panicking we just need to check out",
    "start": "3187240",
    "end": "3192280"
  },
  {
    "text": "the unified log viewer on the logs tab this page consolidates the logs for all",
    "start": "3192280",
    "end": "3199119"
  },
  {
    "text": "the workers and other distributed components that means we can find the",
    "start": "3199119",
    "end": "3204280"
  },
  {
    "text": "exact root cause error right away way okay I love this but I feel like my wife",
    "start": "3204280",
    "end": "3210240"
  },
  {
    "text": "is going to love this unified log viewer even more than me I mean so much more time back in my life all right I think",
    "start": "3210240",
    "end": "3216480"
  },
  {
    "text": "we're pretty good here we've got I'm able to ingest a little over 20,000 images and they're getting embedded in",
    "start": "3216480",
    "end": "3222599"
  },
  {
    "text": "index now so am I good to go can I head out oh one more thing let's get this up and running for online inference online",
    "start": "3222599",
    "end": "3229559"
  },
  {
    "text": "inference you mean production of course no that's actually going to take me forever I need to rewrite all this from",
    "start": "3229559",
    "end": "3235400"
  },
  {
    "text": "development over to to production not to mention actually getting this up and running as a service that can scale up",
    "start": "3235400",
    "end": "3240480"
  },
  {
    "text": "and down it's just not going to happen today so let me actually make that phone call now probably to a divorce lawyer at",
    "start": "3240480",
    "end": "3246000"
  },
  {
    "text": "this point stop being dramatic a single line to launch all of",
    "start": "3246000",
    "end": "3253440"
  },
  {
    "text": "this as a service and we're done okay I'm actually going to name this any scale save my marriage and wow okay this",
    "start": "3253440",
    "end": "3261920"
  },
  {
    "text": "is awesome in literally 3 minutes and helped me get out of my total dependency hell help me find the optimal compute I",
    "start": "3261920",
    "end": "3268200"
  },
  {
    "text": "need we're debugging on top of literally thousands of workers all in one View and now it looks like we're rolling out to",
    "start": "3268200",
    "end": "3274559"
  },
  {
    "text": "production and it looks looks like it's spinning up I'm actually going to head",
    "start": "3274559",
    "end": "3279640"
  },
  {
    "text": "out now so I'll catch you later woohoo have a good",
    "start": "3279640",
    "end": "3285520"
  },
  {
    "text": "one looks like any scale save the marriage uh wait I'm sorry I my flight",
    "start": "3285520",
    "end": "3292640"
  },
  {
    "text": "was actually delayed and looks like I have a lot more time now so I'm I'm just going to relax here for a little bit and",
    "start": "3292640",
    "end": "3298319"
  },
  {
    "text": "sure yeah take my time great well while you're here let me tell you",
    "start": "3298319",
    "end": "3307160"
  },
  {
    "text": "about the project you'll be working on after you get back from let's hear it",
    "start": "3307160",
    "end": "3312319"
  },
  {
    "text": "it's an llm workload with very large data and models no that no uh our",
    "start": "3312319",
    "end": "3318680"
  },
  {
    "text": "platform is made for classical machine learning and we just got it running for deep learning use cases LMS are a",
    "start": "3318680",
    "end": "3323880"
  },
  {
    "text": "completely different story there's just there's just not there's no way this is going to work I mean for starters for fine-tuning these models where are we",
    "start": "3323880",
    "end": "3330039"
  },
  {
    "text": "going to get the compute we can't even find anything and then serving these models in an efficient way not possible if this is what I'm coming back to I",
    "start": "3330039",
    "end": "3336240"
  },
  {
    "text": "might just stay on my honeymoon forever enough with the hyperbole look",
    "start": "3336240",
    "end": "3341440"
  },
  {
    "text": "any scale has a new llm suite specifically for this okay let's see how",
    "start": "3341440",
    "end": "3347799"
  },
  {
    "text": "comprehensive this is what models can I use can I use whatever I want we can use any model on hugging face okay what",
    "start": "3347799",
    "end": "3354079"
  },
  {
    "text": "about different fine-tuning tasks like for classification or instruction tuning or preference tuning yes to all those",
    "start": "3354079",
    "end": "3360880"
  },
  {
    "text": "including distillation okay but what about actually doing the fine tuning though I feel it's so hard to find A1",
    "start": "3360880",
    "end": "3367720"
  },
  {
    "text": "100s or h100s these days and these models just keep getting bigger don't worry about it we can train on smaller",
    "start": "3367720",
    "end": "3375079"
  },
  {
    "text": "more available Hardware like a10s and any scale takes care of all a distributed work for us okay okay what",
    "start": "3375079",
    "end": "3382319"
  },
  {
    "text": "about serving though can I serve thousands of small Laura adapters on top of the same base model and optimize for",
    "start": "3382319",
    "end": "3388559"
  },
  {
    "text": "latency or throughput okay all right this sounds really cool what do I have to install a bunch of new stuff for this",
    "start": "3388559",
    "end": "3394000"
  },
  {
    "text": "or absolutely nothing it's the same any scale platform we used before okay this",
    "start": "3394000",
    "end": "3399400"
  },
  {
    "text": "actually sounds like a ton of fun so I may just get started on this right now okay oh no you",
    "start": "3399400",
    "end": "3407480"
  },
  {
    "text": "don't go are you sure T your flight all right yes oh my work laptop and don't",
    "start": "3407480",
    "end": "3412839"
  },
  {
    "text": "forget your work laptop thank you see you",
    "start": "3412839",
    "end": "3418240"
  },
  {
    "text": "wasn't that fun Goku go enjoy your honeymoon and don't forget to send us some photos all",
    "start": "3423680",
    "end": "3430359"
  },
  {
    "text": "right so let's recap all the announcements we introduced Ray turbo",
    "start": "3430359",
    "end": "3435480"
  },
  {
    "text": "which makes your workloads go faster and cheaper we talked about any scale machine pools and any scale support for",
    "start": "3435480",
    "end": "3442440"
  },
  {
    "text": "kubernetes which lets you deploy your workloads in your envir M using your resources we showed how ml application",
    "start": "3442440",
    "end": "3450160"
  },
  {
    "text": "development can be effortless with features like automatic worker nodes and advanced instance manager any scale",
    "start": "3450160",
    "end": "3457119"
  },
  {
    "text": "governance Suite will make your Finance team smile and finally and most importantly we showed that we can do all",
    "start": "3457119",
    "end": "3464240"
  },
  {
    "text": "of this without compromising on endtoend developer experience so that Goku can enjoy his honeymoon I'm so excited to",
    "start": "3464240",
    "end": "3471640"
  },
  {
    "text": "see what you all will build I feel like going Developers devel velers developers",
    "start": "3471640",
    "end": "3478079"
  },
  {
    "text": "but I'll keep the chant for some other day so with that I would like to welcome back kti on",
    "start": "3478079",
    "end": "3485279"
  },
  {
    "text": "[Music]",
    "start": "3485790",
    "end": "3489989"
  },
  {
    "text": "stage thanks JK and team so exciting to see all that amazing work building out",
    "start": "3491200",
    "end": "3497440"
  },
  {
    "text": "Reay as the premier AI computer engine and any scale as a unified AI platform",
    "start": "3497440",
    "end": "3502760"
  },
  {
    "text": "we can't wait for you guys to try some of these exciting new features",
    "start": "3502760",
    "end": "3509000"
  },
  {
    "text": "out but so much of the power of the story is about the ecosystem Ray and any",
    "start": "3509079",
    "end": "3515520"
  },
  {
    "text": "scale are a platform and for a platform to work it needs incredible Partnerships",
    "start": "3515520",
    "end": "3520960"
  },
  {
    "text": "at the technology level this means connectors to data brakes and snowflake it means Integrations with",
    "start": "3520960",
    "end": "3526720"
  },
  {
    "text": "mlops tools like weights and biases and ml flow orchestration platforms like",
    "start": "3526720",
    "end": "3532520"
  },
  {
    "text": "airflow devops tools like data dog and many more any scale integrates with the entire AI",
    "start": "3532520",
    "end": "3539000"
  },
  {
    "text": "ml ecosystem and we invite new Partnerships please let me know if you're interested in partnering with",
    "start": "3539000",
    "end": "3547000"
  },
  {
    "text": "us I'm also glad to announce that any scale is now available through the AWS",
    "start": "3547000",
    "end": "3553559"
  },
  {
    "text": "and gcp marketplaces and we are also very excited about having every major",
    "start": "3553559",
    "end": "3558680"
  },
  {
    "text": "Cloud as a launch partner for our any scale operator for kubernetes",
    "start": "3558680",
    "end": "3565280"
  },
  {
    "text": "and on this note and so importantly an elevated thank you to all",
    "start": "3567680",
    "end": "3573000"
  },
  {
    "text": "our sponsors thank you to our Platinum sponsors and the many other sponsors",
    "start": "3573000",
    "end": "3579760"
  },
  {
    "text": "that you see on the screen we would not have been able to host this race Summit without you so thank you very much we",
    "start": "3579760",
    "end": "3585720"
  },
  {
    "text": "really appreciate",
    "start": "3585720",
    "end": "3588440"
  },
  {
    "text": "it I'm so excited to hear later today from anastasis and Mark andron tomorrow",
    "start": "3594000",
    "end": "3601880"
  },
  {
    "text": "from Brandon Leonardo from instacart and the almost 200 speakers over the next two",
    "start": "3601880",
    "end": "3608240"
  },
  {
    "text": "days our team is available at the any scale booth in the expo hall to take your questions give you a test run of",
    "start": "3608240",
    "end": "3615359"
  },
  {
    "text": "all the new features that you heard about today and provide guidance to all of you as you explore your AI workloads",
    "start": "3615359",
    "end": "3622119"
  },
  {
    "text": "don't hesitate to reach out to me directly if you want to talk through your AI JY with",
    "start": "3622119",
    "end": "3628359"
  },
  {
    "text": "me finally I'd like to close by saying how inspiring it's been getting to know",
    "start": "3628720",
    "end": "3634960"
  },
  {
    "text": "this community and all the amazing work that you do there's just so much energy here Rey has truly become the premier AI",
    "start": "3634960",
    "end": "3643680"
  },
  {
    "text": "computer engine for the industry and we have added many new capabilities in any",
    "start": "3643680",
    "end": "3648960"
  },
  {
    "text": "scale to make it truly Enterprise ready and I encourage all of you to look",
    "start": "3648960",
    "end": "3654200"
  },
  {
    "text": "deeply into using it to supercharge your AI efforts most importantly what you're",
    "start": "3654200",
    "end": "3661200"
  },
  {
    "text": "building has huge potential to genuinely change the way we live so thank you very",
    "start": "3661200",
    "end": "3667640"
  },
  {
    "text": "much for building with Ray [Applause]",
    "start": "3667640",
    "end": "3676979"
  }
]
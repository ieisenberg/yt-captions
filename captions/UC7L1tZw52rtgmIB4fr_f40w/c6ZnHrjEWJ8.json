[
  {
    "start": "0",
    "end": "28000"
  },
  {
    "text": "thank you",
    "start": "3380",
    "end": "4640"
  },
  {
    "text": "[Applause]",
    "start": "4640",
    "end": "7760"
  },
  {
    "text": "all right hello everyone can you yeah",
    "start": "7760",
    "end": "12900"
  },
  {
    "text": "um so yeah as mentioned I'm going to",
    "start": "12900",
    "end": "14460"
  },
  {
    "text": "talk about how can you make generative",
    "start": "14460",
    "end": "16560"
  },
  {
    "text": "AI real in Enterprise setting it's",
    "start": "16560",
    "end": "19859"
  },
  {
    "text": "pretty easy to build prototype but how",
    "start": "19859",
    "end": "21600"
  },
  {
    "text": "can you turn this prototype into",
    "start": "21600",
    "end": "22980"
  },
  {
    "text": "application that are ready for a large",
    "start": "22980",
    "end": "25199"
  },
  {
    "text": "number of customer that's a big change",
    "start": "25199",
    "end": "27660"
  },
  {
    "text": "so I wanted to start by kind of",
    "start": "27660",
    "end": "29760"
  },
  {
    "start": "28000",
    "end": "110000"
  },
  {
    "text": "reminding everybody about the difference",
    "start": "29760",
    "end": "31380"
  },
  {
    "text": "between envelopes and large language",
    "start": "31380",
    "end": "33660"
  },
  {
    "text": "model Ops or llm Ops",
    "start": "33660",
    "end": "36500"
  },
  {
    "text": "the basic in terms of scope and",
    "start": "36500",
    "end": "39540"
  },
  {
    "text": "definition are not going to go into it",
    "start": "39540",
    "end": "41399"
  },
  {
    "text": "but what is interesting is the",
    "start": "41399",
    "end": "43200"
  },
  {
    "text": "development is different for llm modes",
    "start": "43200",
    "end": "45739"
  },
  {
    "text": "you want to be focusing on prompt",
    "start": "45739",
    "end": "48059"
  },
  {
    "text": "engineering focusing on retrieval",
    "start": "48059",
    "end": "50280"
  },
  {
    "text": "augmented generation also known as Rag",
    "start": "50280",
    "end": "52980"
  },
  {
    "text": "and you also want to be focusing on",
    "start": "52980",
    "end": "54719"
  },
  {
    "text": "fine-tuning a model",
    "start": "54719",
    "end": "56879"
  },
  {
    "text": "the evaluation of models still remain a",
    "start": "56879",
    "end": "60000"
  },
  {
    "text": "challenge it has been mentioned multiple",
    "start": "60000",
    "end": "62340"
  },
  {
    "text": "times today we don't have a good",
    "start": "62340",
    "end": "64018"
  },
  {
    "text": "solution about it but we are Plug and",
    "start": "64019",
    "end": "66479"
  },
  {
    "text": "Play so you if you find the solution it",
    "start": "66479",
    "end": "68939"
  },
  {
    "text": "will work",
    "start": "68939",
    "end": "70680"
  },
  {
    "text": "um in terms of deployments it's kind of",
    "start": "70680",
    "end": "72780"
  },
  {
    "text": "the same as envelopes but there are some",
    "start": "72780",
    "end": "74520"
  },
  {
    "text": "added challenges that exist now",
    "start": "74520",
    "end": "78020"
  },
  {
    "text": "llm chain llm cascading are all things",
    "start": "78020",
    "end": "81540"
  },
  {
    "text": "that are important to be able to connect",
    "start": "81540",
    "end": "83460"
  },
  {
    "text": "your llms together and optimization like",
    "start": "83460",
    "end": "87420"
  },
  {
    "text": "quantization are also important to",
    "start": "87420",
    "end": "89159"
  },
  {
    "text": "reduce the the weight of your model and",
    "start": "89159",
    "end": "91619"
  },
  {
    "text": "to be able to serve better",
    "start": "91619",
    "end": "93479"
  },
  {
    "text": "finally the monitoring aspect is very",
    "start": "93479",
    "end": "95880"
  },
  {
    "text": "critical so that you can know that your",
    "start": "95880",
    "end": "98220"
  },
  {
    "text": "performance metric are doing good that",
    "start": "98220",
    "end": "100680"
  },
  {
    "text": "you can detect any data change and",
    "start": "100680",
    "end": "103259"
  },
  {
    "text": "biases and you can recompute your",
    "start": "103259",
    "end": "105960"
  },
  {
    "text": "embeddings of and tune your model if you",
    "start": "105960",
    "end": "108119"
  },
  {
    "text": "need to",
    "start": "108119",
    "end": "108590"
  },
  {
    "text": "[Music]",
    "start": "108590",
    "end": "110939"
  },
  {
    "start": "110000",
    "end": "248000"
  },
  {
    "text": "so to integrate generative AI in",
    "start": "110939",
    "end": "113579"
  },
  {
    "text": "Enterprise there are a few capabilities",
    "start": "113579",
    "end": "114960"
  },
  {
    "text": "that we think are really important for",
    "start": "114960",
    "end": "117479"
  },
  {
    "text": "you to set up the first one is give easy",
    "start": "117479",
    "end": "120000"
  },
  {
    "text": "access to generative AI models to",
    "start": "120000",
    "end": "122340"
  },
  {
    "text": "employees or data scientists in your",
    "start": "122340",
    "end": "124740"
  },
  {
    "text": "company",
    "start": "124740",
    "end": "126920"
  },
  {
    "text": "how can you get get them to securely",
    "start": "127140",
    "end": "130319"
  },
  {
    "text": "access this model how do you know that",
    "start": "130319",
    "end": "133140"
  },
  {
    "text": "the license is for this model is",
    "start": "133140",
    "end": "135660"
  },
  {
    "text": "appropriate for your Enterprise use case",
    "start": "135660",
    "end": "138500"
  },
  {
    "text": "so that's the first capability that is",
    "start": "138500",
    "end": "141900"
  },
  {
    "text": "needed the second capability is really",
    "start": "141900",
    "end": "143520"
  },
  {
    "text": "about managing your embeddings and",
    "start": "143520",
    "end": "145560"
  },
  {
    "text": "managing your prompts if you don't want",
    "start": "145560",
    "end": "147540"
  },
  {
    "text": "to have multiple teams designing",
    "start": "147540",
    "end": "150180"
  },
  {
    "text": "different prompts to do the same things",
    "start": "150180",
    "end": "151980"
  },
  {
    "text": "you want to be able to allow them to",
    "start": "151980",
    "end": "154379"
  },
  {
    "text": "collaborate likewise for embeddings you",
    "start": "154379",
    "end": "156480"
  },
  {
    "text": "don't want to recompute embedding some",
    "start": "156480",
    "end": "158459"
  },
  {
    "text": "same documents and store them in",
    "start": "158459",
    "end": "160500"
  },
  {
    "text": "different places so how can you",
    "start": "160500",
    "end": "162300"
  },
  {
    "text": "centralize that to really build on this",
    "start": "162300",
    "end": "164280"
  },
  {
    "text": "knowledge over time AI orchestration I",
    "start": "164280",
    "end": "168360"
  },
  {
    "text": "touch a little bit previously about this",
    "start": "168360",
    "end": "171120"
  },
  {
    "text": "in the development phase of llm Ops how",
    "start": "171120",
    "end": "174000"
  },
  {
    "text": "do you implement and manage complex",
    "start": "174000",
    "end": "175560"
  },
  {
    "text": "workflow and component that boil your",
    "start": "175560",
    "end": "178260"
  },
  {
    "text": "real generative AI application from end",
    "start": "178260",
    "end": "180959"
  },
  {
    "text": "to finish and all the different agents",
    "start": "180959",
    "end": "182760"
  },
  {
    "text": "that might connect to different apis",
    "start": "182760",
    "end": "186180"
  },
  {
    "text": "once you have these three capabilities",
    "start": "186180",
    "end": "187800"
  },
  {
    "text": "the three following ones are really",
    "start": "187800",
    "end": "189780"
  },
  {
    "text": "about how do you scale that",
    "start": "189780",
    "end": "192060"
  },
  {
    "text": "deployment and hosting is very critical",
    "start": "192060",
    "end": "195480"
  },
  {
    "text": "and still challenging for many customers",
    "start": "195480",
    "end": "198120"
  },
  {
    "text": "how can they deploy the generative Ai",
    "start": "198120",
    "end": "200819"
  },
  {
    "text": "and scale these models in production",
    "start": "200819",
    "end": "203819"
  },
  {
    "text": "they're often very large can be in the",
    "start": "203819",
    "end": "205680"
  },
  {
    "text": "hundreds of gigs and the latency is not",
    "start": "205680",
    "end": "208920"
  },
  {
    "text": "always great",
    "start": "208920",
    "end": "209940"
  },
  {
    "text": "then governance is a very important",
    "start": "209940",
    "end": "212159"
  },
  {
    "text": "aspect depending of the industry in",
    "start": "212159",
    "end": "214260"
  },
  {
    "text": "which you are working it might be",
    "start": "214260",
    "end": "215700"
  },
  {
    "text": "critical to your business to be able to",
    "start": "215700",
    "end": "217379"
  },
  {
    "text": "track audit and reproduce your models",
    "start": "217379",
    "end": "219959"
  },
  {
    "text": "even after an extremely long period of",
    "start": "219959",
    "end": "222959"
  },
  {
    "text": "time some of our customers needs to be",
    "start": "222959",
    "end": "225000"
  },
  {
    "text": "able to reproduce the model from 10",
    "start": "225000",
    "end": "226860"
  },
  {
    "text": "years back",
    "start": "226860",
    "end": "228120"
  },
  {
    "text": "and finally how do you deploy your model",
    "start": "228120",
    "end": "230400"
  },
  {
    "text": "in different clouds it can be AWS Azure",
    "start": "230400",
    "end": "234780"
  },
  {
    "text": "or gcp but it can also be in your own",
    "start": "234780",
    "end": "237239"
  },
  {
    "text": "on-prem environments where you want to",
    "start": "237239",
    "end": "239760"
  },
  {
    "text": "use your own Nvidia dgx box to be able",
    "start": "239760",
    "end": "242459"
  },
  {
    "text": "to do the expensive compute and then",
    "start": "242459",
    "end": "244980"
  },
  {
    "text": "deploy the model once that's done",
    "start": "244980",
    "end": "248580"
  },
  {
    "start": "248000",
    "end": "382000"
  },
  {
    "text": "all right so we you've all seen",
    "start": "248580",
    "end": "250920"
  },
  {
    "text": "different versions of this schema today",
    "start": "250920",
    "end": "252840"
  },
  {
    "text": "is really the life cycle of large",
    "start": "252840",
    "end": "255299"
  },
  {
    "text": "language model and I'm not going to go",
    "start": "255299",
    "end": "257459"
  },
  {
    "text": "through each of these books but just",
    "start": "257459",
    "end": "259019"
  },
  {
    "text": "look at your data now can be used both",
    "start": "259019",
    "end": "262139"
  },
  {
    "text": "for computing the embeddings as well as",
    "start": "262139",
    "end": "264840"
  },
  {
    "text": "to fine tune the model that you have",
    "start": "264840",
    "end": "267300"
  },
  {
    "text": "most people are not training from",
    "start": "267300",
    "end": "270240"
  },
  {
    "text": "scratch or new llm they are going to be",
    "start": "270240",
    "end": "272580"
  },
  {
    "text": "using a foundation model like lamma V2",
    "start": "272580",
    "end": "275820"
  },
  {
    "text": "or falcon or maybe even GPT directly",
    "start": "275820",
    "end": "280080"
  },
  {
    "text": "from open AI then they will start",
    "start": "280080",
    "end": "282600"
  },
  {
    "text": "focusing on building the application so",
    "start": "282600",
    "end": "285000"
  },
  {
    "text": "for to build your llm application you",
    "start": "285000",
    "end": "287220"
  },
  {
    "text": "need to be having a set of instruction",
    "start": "287220",
    "end": "288840"
  },
  {
    "text": "or prompts that will tell the model how",
    "start": "288840",
    "end": "292380"
  },
  {
    "text": "to behave based on certain input you",
    "start": "292380",
    "end": "294720"
  },
  {
    "text": "will get you will need agents to give",
    "start": "294720",
    "end": "296759"
  },
  {
    "text": "this external connectivity and API",
    "start": "296759",
    "end": "299160"
  },
  {
    "text": "interaction and you will want to be able",
    "start": "299160",
    "end": "301380"
  },
  {
    "text": "to test that and all the test prompt is",
    "start": "301380",
    "end": "304440"
  },
  {
    "text": "kind of a manual process still or you",
    "start": "304440",
    "end": "306540"
  },
  {
    "text": "are just using a golden data set to see",
    "start": "306540",
    "end": "308880"
  },
  {
    "text": "okay if I'm doing a I'm expecting b as",
    "start": "308880",
    "end": "311460"
  },
  {
    "text": "an answer and the llm app validation is",
    "start": "311460",
    "end": "314580"
  },
  {
    "text": "the component that really helps you",
    "start": "314580",
    "end": "315900"
  },
  {
    "text": "decide okay am I ready to move to the",
    "start": "315900",
    "end": "317820"
  },
  {
    "text": "next phase in the life cycle or do I",
    "start": "317820",
    "end": "320040"
  },
  {
    "text": "need more data to be able to create more",
    "start": "320040",
    "end": "322680"
  },
  {
    "text": "embeddings or do I need more data to",
    "start": "322680",
    "end": "324600"
  },
  {
    "text": "fine-tune my model",
    "start": "324600",
    "end": "326220"
  },
  {
    "text": "once you feel confident enough to move",
    "start": "326220",
    "end": "328199"
  },
  {
    "text": "your model to production you need",
    "start": "328199",
    "end": "330680"
  },
  {
    "text": "monitoring monitoring is really the most",
    "start": "330680",
    "end": "332820"
  },
  {
    "text": "critical piece in that workflow how can",
    "start": "332820",
    "end": "335460"
  },
  {
    "text": "you monitor the outputs that are",
    "start": "335460",
    "end": "337560"
  },
  {
    "text": "generated by the model how do you",
    "start": "337560",
    "end": "339780"
  },
  {
    "text": "monitor the interaction that the user",
    "start": "339780",
    "end": "341639"
  },
  {
    "text": "have with the application are they",
    "start": "341639",
    "end": "344520"
  },
  {
    "text": "giving a thumbs down or thumbs down or",
    "start": "344520",
    "end": "347520"
  },
  {
    "text": "up",
    "start": "347520",
    "end": "348440"
  },
  {
    "text": "how do you monitor the inputs that the",
    "start": "348440",
    "end": "352380"
  },
  {
    "text": "user might be entering like when they",
    "start": "352380",
    "end": "354539"
  },
  {
    "text": "are interacting with your application so",
    "start": "354539",
    "end": "356639"
  },
  {
    "text": "monitoring is really a key piece and we",
    "start": "356639",
    "end": "358979"
  },
  {
    "text": "we propose to use evaluator larger model",
    "start": "358979",
    "end": "361860"
  },
  {
    "text": "as a way to track how you are doing and",
    "start": "361860",
    "end": "366479"
  },
  {
    "text": "also having data sets or golden data set",
    "start": "366479",
    "end": "368639"
  },
  {
    "text": "which is a great way to just you",
    "start": "368639",
    "end": "370620"
  },
  {
    "text": "calculate how far you are from the truth",
    "start": "370620",
    "end": "373199"
  },
  {
    "text": "and this again will go back to your",
    "start": "373199",
    "end": "374940"
  },
  {
    "text": "validation llm and help you decide",
    "start": "374940",
    "end": "377280"
  },
  {
    "text": "whether you need to fine-tune or add",
    "start": "377280",
    "end": "379380"
  },
  {
    "text": "more data into your embeddings",
    "start": "379380",
    "end": "382880"
  },
  {
    "start": "382000",
    "end": "493000"
  },
  {
    "text": "so",
    "start": "383160",
    "end": "384300"
  },
  {
    "text": "now you have your llm application you",
    "start": "384300",
    "end": "387180"
  },
  {
    "text": "have your life cycle there are still a",
    "start": "387180",
    "end": "388620"
  },
  {
    "text": "lot of changes that need to be addressed",
    "start": "388620",
    "end": "390479"
  },
  {
    "text": "in terms of llm and I'm just copying",
    "start": "390479",
    "end": "394199"
  },
  {
    "text": "here this excellent study Challenge and",
    "start": "394199",
    "end": "396120"
  },
  {
    "text": "application of larger gauge Model that",
    "start": "396120",
    "end": "397680"
  },
  {
    "text": "was published in July they kind of show",
    "start": "397680",
    "end": "400919"
  },
  {
    "text": "that there are three big aspects to",
    "start": "400919",
    "end": "402780"
  },
  {
    "text": "design the behavior and the science of",
    "start": "402780",
    "end": "405479"
  },
  {
    "text": "managing llms",
    "start": "405479",
    "end": "408120"
  },
  {
    "text": "um the first challenge is the size of",
    "start": "408120",
    "end": "410759"
  },
  {
    "text": "the data set often it's now trained on",
    "start": "410759",
    "end": "412620"
  },
  {
    "text": "the whole web so you can't expect",
    "start": "412620",
    "end": "414780"
  },
  {
    "text": "anybody to go and check the quality of",
    "start": "414780",
    "end": "418199"
  },
  {
    "text": "the data we over rely on tokenizer which",
    "start": "418199",
    "end": "422100"
  },
  {
    "text": "brings some challenges just in terms of",
    "start": "422100",
    "end": "424259"
  },
  {
    "text": "how do you compute them and how you",
    "start": "424259",
    "end": "427199"
  },
  {
    "text": "um how do you deal with information loss",
    "start": "427199",
    "end": "429720"
  },
  {
    "text": "fine tuning is still on over red it's",
    "start": "429720",
    "end": "432720"
  },
  {
    "text": "very expensive you you need large memory",
    "start": "432720",
    "end": "435060"
  },
  {
    "text": "depending on the model that you are",
    "start": "435060",
    "end": "436440"
  },
  {
    "text": "fine-tuning and now we are hearing more",
    "start": "436440",
    "end": "438600"
  },
  {
    "text": "and more that very large models don't",
    "start": "438600",
    "end": "441840"
  },
  {
    "text": "really improve a whole bunch when they",
    "start": "441840",
    "end": "444780"
  },
  {
    "text": "are fine-tuned it's better to fine tune",
    "start": "444780",
    "end": "446160"
  },
  {
    "text": "a smaller model like a 7B or certain B",
    "start": "446160",
    "end": "448380"
  },
  {
    "text": "versus the 7tb from gamma in terms of",
    "start": "448380",
    "end": "451199"
  },
  {
    "text": "gains that you are getting",
    "start": "451199",
    "end": "452699"
  },
  {
    "text": "they are very high pre-training costs",
    "start": "452699",
    "end": "454979"
  },
  {
    "text": "most companies cannot afford to do that",
    "start": "454979",
    "end": "457080"
  },
  {
    "text": "is really the big player they can afford",
    "start": "457080",
    "end": "459180"
  },
  {
    "text": "it the latency is still a big Challenge",
    "start": "459180",
    "end": "461819"
  },
  {
    "text": "and the context length is also a change",
    "start": "461819",
    "end": "464160"
  },
  {
    "text": "where often when you ask to summarize",
    "start": "464160",
    "end": "467340"
  },
  {
    "text": "the whole book it will just summarize",
    "start": "467340",
    "end": "469319"
  },
  {
    "text": "the first two pages right",
    "start": "469319",
    "end": "472020"
  },
  {
    "text": "um I'm gonna go a bit quicker here but",
    "start": "472020",
    "end": "475259"
  },
  {
    "text": "hallucination from bitterness misaligned",
    "start": "475259",
    "end": "478380"
  },
  {
    "text": "Behavior are all Behavior issue that can",
    "start": "478380",
    "end": "481620"
  },
  {
    "text": "be addressed evaluation as I mentioned",
    "start": "481620",
    "end": "485039"
  },
  {
    "text": "it's still a big challenge in the world",
    "start": "485039",
    "end": "486720"
  },
  {
    "text": "of llm and generative AI in general",
    "start": "486720",
    "end": "489599"
  },
  {
    "text": "and um and that's it's",
    "start": "489599",
    "end": "494699"
  },
  {
    "text": "so now we have this maturity curve that",
    "start": "494699",
    "end": "498000"
  },
  {
    "text": "we are looking at from Enterprise",
    "start": "498000",
    "end": "499560"
  },
  {
    "text": "perspective and they can grade",
    "start": "499560",
    "end": "501419"
  },
  {
    "text": "themselves how mature they are and how",
    "start": "501419",
    "end": "503879"
  },
  {
    "text": "much value they are getting so the the",
    "start": "503879",
    "end": "505620"
  },
  {
    "text": "first thing that you want to optimize in",
    "start": "505620",
    "end": "507660"
  },
  {
    "text": "your Enterprises you want to accelerate",
    "start": "507660",
    "end": "509759"
  },
  {
    "text": "research right you want to be able to do",
    "start": "509759",
    "end": "511259"
  },
  {
    "text": "prototype quickly you want to make sure",
    "start": "511259",
    "end": "512940"
  },
  {
    "text": "that you can validate some business idea",
    "start": "512940",
    "end": "515880"
  },
  {
    "text": "to do that you need to give your team",
    "start": "515880",
    "end": "518580"
  },
  {
    "text": "Enterprise data access IDE tooling Self",
    "start": "518580",
    "end": "521159"
  },
  {
    "text": "Serve GPU container access and now with",
    "start": "521159",
    "end": "523680"
  },
  {
    "text": "generative AI you also need to be able",
    "start": "523680",
    "end": "525480"
  },
  {
    "text": "to manage your prompt and give access to",
    "start": "525480",
    "end": "527640"
  },
  {
    "text": "Foundation model",
    "start": "527640",
    "end": "529080"
  },
  {
    "text": "the next step is how can you efficiently",
    "start": "529080",
    "end": "531660"
  },
  {
    "text": "deploy this model that you have created",
    "start": "531660",
    "end": "533760"
  },
  {
    "text": "for that you need job scheduling",
    "start": "533760",
    "end": "535380"
  },
  {
    "text": "experiment management and no more and",
    "start": "535380",
    "end": "537839"
  },
  {
    "text": "more you need to to be able to integrate",
    "start": "537839",
    "end": "539459"
  },
  {
    "text": "nicely into your CI CD deployment flow",
    "start": "539459",
    "end": "543480"
  },
  {
    "text": "then the next step is to have advanced",
    "start": "543480",
    "end": "545519"
  },
  {
    "text": "AI solution where being able to have",
    "start": "545519",
    "end": "548399"
  },
  {
    "text": "pipeline distributed Frameworks like Ray",
    "start": "548399",
    "end": "550920"
  },
  {
    "text": "for example and model hosting becomes",
    "start": "550920",
    "end": "553800"
  },
  {
    "text": "really critical",
    "start": "553800",
    "end": "555180"
  },
  {
    "text": "and finally for the first step in",
    "start": "555180",
    "end": "557760"
  },
  {
    "text": "building mature llm Ops you you need to",
    "start": "557760",
    "end": "560459"
  },
  {
    "text": "have model with safety nets so for this",
    "start": "560459",
    "end": "562260"
  },
  {
    "text": "you need model evaluation and model",
    "start": "562260",
    "end": "564240"
  },
  {
    "text": "monitoring",
    "start": "564240",
    "end": "565680"
  },
  {
    "text": "most people stop here but you really",
    "start": "565680",
    "end": "568019"
  },
  {
    "text": "want to be able to go further out to",
    "start": "568019",
    "end": "570300"
  },
  {
    "text": "really increase the productivity of your",
    "start": "570300",
    "end": "573300"
  },
  {
    "text": "team of data scientists for this you",
    "start": "573300",
    "end": "575640"
  },
  {
    "text": "need to be able to bring data science",
    "start": "575640",
    "end": "578640"
  },
  {
    "text": "container management system so they can",
    "start": "578640",
    "end": "580560"
  },
  {
    "text": "easily rebuild on container that works",
    "start": "580560",
    "end": "583500"
  },
  {
    "text": "you want to make the knowledge",
    "start": "583500",
    "end": "584940"
  },
  {
    "text": "searchable",
    "start": "584940",
    "end": "586380"
  },
  {
    "text": "and you want to be able to have a good",
    "start": "586380",
    "end": "588360"
  },
  {
    "text": "reproducibility engine",
    "start": "588360",
    "end": "590279"
  },
  {
    "text": "what I mean by reproducibility engine is",
    "start": "590279",
    "end": "592740"
  },
  {
    "text": "any model that is serving some traffic",
    "start": "592740",
    "end": "594660"
  },
  {
    "text": "you need to go",
    "start": "594660",
    "end": "596160"
  },
  {
    "text": "and go back to open that model and",
    "start": "596160",
    "end": "598260"
  },
  {
    "text": "understand exactly how it was built or",
    "start": "598260",
    "end": "601080"
  },
  {
    "text": "fine-tuned or what other embeddings that",
    "start": "601080",
    "end": "603600"
  },
  {
    "text": "are serving this model and then you need",
    "start": "603600",
    "end": "605940"
  },
  {
    "text": "a model registry where you're going to",
    "start": "605940",
    "end": "607500"
  },
  {
    "text": "save all your models in UC",
    "start": "607500",
    "end": "609920"
  },
  {
    "text": "the next step is to to have an optimal",
    "start": "609920",
    "end": "613200"
  },
  {
    "text": "model health and to reduce the risk that",
    "start": "613200",
    "end": "616560"
  },
  {
    "text": "you are getting again integrated",
    "start": "616560",
    "end": "618480"
  },
  {
    "text": "monitoring validation and retraining are",
    "start": "618480",
    "end": "620940"
  },
  {
    "text": "critical capabilities that are needed",
    "start": "620940",
    "end": "622980"
  },
  {
    "text": "for this and finally you can get to a",
    "start": "622980",
    "end": "626100"
  },
  {
    "text": "place where you have repeatable ai",
    "start": "626100",
    "end": "628080"
  },
  {
    "text": "profits secure Ai and for this you want",
    "start": "628080",
    "end": "631500"
  },
  {
    "text": "to have project management and a central",
    "start": "631500",
    "end": "633240"
  },
  {
    "text": "platform",
    "start": "633240",
    "end": "635339"
  },
  {
    "text": "so at Domino we recently announced the",
    "start": "635339",
    "end": "639120"
  },
  {
    "start": "636000",
    "end": "745000"
  },
  {
    "text": "Mini model century and our idea is how",
    "start": "639120",
    "end": "642000"
  },
  {
    "text": "do we help large customers to build and",
    "start": "642000",
    "end": "644399"
  },
  {
    "text": "operationalize responsible AI in",
    "start": "644399",
    "end": "647160"
  },
  {
    "text": "Enterprise and we have this set of",
    "start": "647160",
    "end": "649920"
  },
  {
    "text": "capabilities uh I'll start with project",
    "start": "649920",
    "end": "652620"
  },
  {
    "text": "template it's really a way for you to",
    "start": "652620",
    "end": "654779"
  },
  {
    "text": "Define how you want your team of data",
    "start": "654779",
    "end": "657300"
  },
  {
    "text": "scientists to be working so you can",
    "start": "657300",
    "end": "659339"
  },
  {
    "text": "automate and standardize the workflow",
    "start": "659339",
    "end": "661620"
  },
  {
    "text": "that they are going to follow you can",
    "start": "661620",
    "end": "663540"
  },
  {
    "text": "ask them to run a certain number of sets",
    "start": "663540",
    "end": "666959"
  },
  {
    "text": "of checks before",
    "start": "666959",
    "end": "670220"
  },
  {
    "text": "registering a model then you want to go",
    "start": "670220",
    "end": "673260"
  },
  {
    "text": "and register your model you want to have",
    "start": "673260",
    "end": "675959"
  },
  {
    "text": "the centralized management where you can",
    "start": "675959",
    "end": "677880"
  },
  {
    "text": "track and also have the lineage what",
    "start": "677880",
    "end": "681000"
  },
  {
    "text": "data will use what the environment was",
    "start": "681000",
    "end": "682800"
  },
  {
    "text": "used was Hardware what Hardware was used",
    "start": "682800",
    "end": "685019"
  },
  {
    "text": "who was it involved and what were the",
    "start": "685019",
    "end": "687480"
  },
  {
    "text": "metric and the parameter all of this",
    "start": "687480",
    "end": "689160"
  },
  {
    "text": "goes into the model registry we actually",
    "start": "689160",
    "end": "691640"
  },
  {
    "text": "automatically generate a model card for",
    "start": "691640",
    "end": "694079"
  },
  {
    "text": "each model that you register you can of",
    "start": "694079",
    "end": "696540"
  },
  {
    "text": "course edit it and add more information",
    "start": "696540",
    "end": "698100"
  },
  {
    "text": "but we think it's more valuable if we",
    "start": "698100",
    "end": "701100"
  },
  {
    "text": "make it on your behalf and it will track",
    "start": "701100",
    "end": "703680"
  },
  {
    "text": "the purpose of the model the performance",
    "start": "703680",
    "end": "705480"
  },
  {
    "text": "and you can see all the limitation and",
    "start": "705480",
    "end": "707279"
  },
  {
    "text": "biases of your model as well",
    "start": "707279",
    "end": "709680"
  },
  {
    "text": "finally we have a model world view now",
    "start": "709680",
    "end": "711899"
  },
  {
    "text": "finally next step is to have a model",
    "start": "711899",
    "end": "713220"
  },
  {
    "text": "review that is fully customizable every",
    "start": "713220",
    "end": "716040"
  },
  {
    "text": "Enterprise I'm talking with have",
    "start": "716040",
    "end": "718200"
  },
  {
    "text": "different steps to review a model before",
    "start": "718200",
    "end": "720839"
  },
  {
    "text": "moving to production",
    "start": "720839",
    "end": "723779"
  },
  {
    "text": "then you want to be able to Stage your",
    "start": "723779",
    "end": "726120"
  },
  {
    "text": "model how you can move from Dev to",
    "start": "726120",
    "end": "728640"
  },
  {
    "text": "staging to production of whichever",
    "start": "728640",
    "end": "730980"
  },
  {
    "text": "environment you have",
    "start": "730980",
    "end": "732839"
  },
  {
    "text": "and finally having a modern monitoring",
    "start": "732839",
    "end": "735360"
  },
  {
    "text": "in place where you can track optimize",
    "start": "735360",
    "end": "737820"
  },
  {
    "text": "your performance and really build your",
    "start": "737820",
    "end": "740459"
  },
  {
    "text": "own metric that are evaluating the",
    "start": "740459",
    "end": "743160"
  },
  {
    "text": "quality of your model in production",
    "start": "743160",
    "end": "746600"
  },
  {
    "start": "745000",
    "end": "818000"
  },
  {
    "text": "so at Domino we have four key benefits",
    "start": "747060",
    "end": "750560"
  },
  {
    "text": "the first one is we help boost",
    "start": "750560",
    "end": "754339"
  },
  {
    "text": "productivity of team of data scientists",
    "start": "754339",
    "end": "756959"
  },
  {
    "text": "they can reuse templates they will",
    "start": "756959",
    "end": "760079"
  },
  {
    "text": "actually offer assisted fine tuning for",
    "start": "760079",
    "end": "763380"
  },
  {
    "text": "commercial or grade Foundation model so",
    "start": "763380",
    "end": "765720"
  },
  {
    "text": "with a couple of clicks you can decide",
    "start": "765720",
    "end": "767519"
  },
  {
    "text": "which Foundation model you want to use",
    "start": "767519",
    "end": "769079"
  },
  {
    "text": "will help you doing the fine tuning and",
    "start": "769079",
    "end": "771240"
  },
  {
    "text": "then you can just deploy it we have a",
    "start": "771240",
    "end": "773700"
  },
  {
    "text": "self-service infrastructure with GPU",
    "start": "773700",
    "end": "775440"
  },
  {
    "text": "Vector database and array capabilities",
    "start": "775440",
    "end": "778800"
  },
  {
    "text": "we are also Enterprise already actually",
    "start": "778800",
    "end": "780779"
  },
  {
    "text": "that's our bread and butter and there is",
    "start": "780779",
    "end": "783660"
  },
  {
    "text": "a built-in system of record support for",
    "start": "783660",
    "end": "785519"
  },
  {
    "text": "reproducibility collaboration",
    "start": "785519",
    "end": "787019"
  },
  {
    "text": "scalability and security as well",
    "start": "787019",
    "end": "790560"
  },
  {
    "text": "um responsible AI I already talked about",
    "start": "790560",
    "end": "792660"
  },
  {
    "text": "model Sentry but it's all built into our",
    "start": "792660",
    "end": "794880"
  },
  {
    "text": "Domino platform so it works just out of",
    "start": "794880",
    "end": "797160"
  },
  {
    "text": "the box",
    "start": "797160",
    "end": "798000"
  },
  {
    "text": "and finally we are aware that there is a",
    "start": "798000",
    "end": "800579"
  },
  {
    "text": "lot of cars that comes with a large",
    "start": "800579",
    "end": "802440"
  },
  {
    "text": "language model and generative AI in",
    "start": "802440",
    "end": "804540"
  },
  {
    "text": "general so we have set up capability for",
    "start": "804540",
    "end": "807720"
  },
  {
    "text": "budget and alerting being able to set",
    "start": "807720",
    "end": "810779"
  },
  {
    "text": "limits on quota and being able to manage",
    "start": "810779",
    "end": "813779"
  },
  {
    "text": "the auto scaling and scaling down to",
    "start": "813779",
    "end": "815579"
  },
  {
    "text": "zero as well for your models",
    "start": "815579",
    "end": "818579"
  },
  {
    "start": "818000",
    "end": "836000"
  },
  {
    "text": "all right that's all the all the things",
    "start": "818579",
    "end": "821399"
  },
  {
    "text": "I wanted to share with you today thanks",
    "start": "821399",
    "end": "823680"
  },
  {
    "text": "a lot for taking the time if you want",
    "start": "823680",
    "end": "825240"
  },
  {
    "text": "more information thank you if you want",
    "start": "825240",
    "end": "827700"
  },
  {
    "text": "more information feel free to scan the",
    "start": "827700",
    "end": "829500"
  },
  {
    "text": "QR code that brings you to a page thank",
    "start": "829500",
    "end": "832019"
  },
  {
    "text": "you so much",
    "start": "832019",
    "end": "834440"
  }
]
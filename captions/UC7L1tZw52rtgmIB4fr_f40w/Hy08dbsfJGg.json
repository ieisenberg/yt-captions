[
  {
    "text": "all right thanks for thanks for having me excited to be here um as mentioned my name is Harrison",
    "start": "4940",
    "end": "10800"
  },
  {
    "text": "Chase I'm the CEO and co-founder of laying chain um and yeah today I'm going to talk",
    "start": "10800",
    "end": "16139"
  },
  {
    "text": "about building context aware reasoning applications with link chain and linksmith and so so what exactly are",
    "start": "16139",
    "end": "21960"
  },
  {
    "text": "context aware reasoning applications because that is a bit of a mouthful so this is a this is a screenshot from chat",
    "start": "21960",
    "end": "28560"
  },
  {
    "text": "GPT which I'm assuming most people have used and it highlights one of the flaws of just using the language models by",
    "start": "28560",
    "end": "34680"
  },
  {
    "text": "themselves they don't have information about a lot of different things they don't have information about the current",
    "start": "34680",
    "end": "40800"
  },
  {
    "text": "weather in San Francisco they don't have information about your private information that the model wasn't trained on basically anything that",
    "start": "40800",
    "end": "47100"
  },
  {
    "text": "wasn't in the training data for the model they're not able to use um and and so link chain the open source",
    "start": "47100",
    "end": "53280"
  },
  {
    "text": "framework was designed around connecting language models to external sources of",
    "start": "53280",
    "end": "58379"
  },
  {
    "text": "data and computation and we've seen a lot of applications built on top of langchain that really meet that goal and",
    "start": "58379",
    "end": "64378"
  },
  {
    "text": "so these these are a number of applications here ranging from connecting you know",
    "start": "64379",
    "end": "71159"
  },
  {
    "text": "language models to a spark database to building a generative character with",
    "start": "71159",
    "end": "77939"
  },
  {
    "text": "language models or to building a financial advisor with language models that takes into account your personal",
    "start": "77939",
    "end": "83340"
  },
  {
    "text": "finances as well as any kind of like market conditions and so when when",
    "start": "83340",
    "end": "88439"
  },
  {
    "text": "thinking about how to describe Lane chain for a long time we kind of described it as a framework for building",
    "start": "88439",
    "end": "93860"
  },
  {
    "text": "llm applications and that's great but it's very it's very Broad and vague and",
    "start": "93860",
    "end": "99299"
  },
  {
    "text": "so the slightly less vague thing that we've uh started describing it more recently as is the framework for for",
    "start": "99299",
    "end": "104460"
  },
  {
    "text": "developing context-aware reasoning applications as I think that highlights a lot of the commonalities that the",
    "start": "104460",
    "end": "111119"
  },
  {
    "text": "applications built on top of link chain have and so in the talk today I want to talk about what exactly context aware",
    "start": "111119",
    "end": "117659"
  },
  {
    "text": "and reasoning applications are as well as some of the problems that we see people running into when trying to to",
    "start": "117659",
    "end": "123960"
  },
  {
    "text": "build them and Howling chain and langsmith strive to to solve some of those",
    "start": "123960",
    "end": "129660"
  },
  {
    "text": "so starting with context aware so context aware involves bringing",
    "start": "129660",
    "end": "134879"
  },
  {
    "text": "appropriate context to the language model so that it can reason about what to do next and we'll talk about reasoning so let's leave that to the",
    "start": "134879",
    "end": "140520"
  },
  {
    "text": "side for now but a lot of what's important here is bringing the right type of context to language models and",
    "start": "140520",
    "end": "146099"
  },
  {
    "text": "and so there's a bunch of different types of context and there's a bunch of different types of ways of bringing that context to language models and",
    "start": "146099",
    "end": "153060"
  },
  {
    "text": "importantly these are different types of context you can use many of them together and in fact we often see at",
    "start": "153060",
    "end": "158400"
  },
  {
    "text": "least two or three of these being used in any given application so and they all have their different pros and cons one's",
    "start": "158400",
    "end": "163800"
  },
  {
    "text": "not better than the other they serve kind of like different purposes so talking about the first one this is",
    "start": "163800",
    "end": "169800"
  },
  {
    "text": "just kind of like instruction prompting you tell the language model what to do and the reason that I'd argue that this",
    "start": "169800",
    "end": "175019"
  },
  {
    "text": "is bringing context to a language model application is that oftentimes your company's values",
    "start": "175019",
    "end": "181019"
  },
  {
    "text": "um kind of like decision making processes ways that you want the language model to think or respond are",
    "start": "181019",
    "end": "187200"
  },
  {
    "text": "encoded in these instructions and so you're bringing that context of how you",
    "start": "187200",
    "end": "192360"
  },
  {
    "text": "would tell someone to do something to a language model and providing it there this is kind of like similar to if you",
    "start": "192360",
    "end": "198239"
  },
  {
    "text": "show up on a first day of work and you've got an employee handbook you're kind of like providing an employee handbook to the language model telling",
    "start": "198239",
    "end": "203940"
  },
  {
    "text": "it how to do things the next version is you're showing it how to do things so show don't tell this",
    "start": "203940",
    "end": "210480"
  },
  {
    "text": "is providing a few examples of how the language model should handle particular scenarios or particular tasks and so",
    "start": "210480",
    "end": "217080"
  },
  {
    "text": "this is really powerful when it's hard to describe in in instructions how a",
    "start": "217080",
    "end": "222780"
  },
  {
    "text": "language model should should respond because there's maybe too many nuances to take into account or the level of",
    "start": "222780",
    "end": "228000"
  },
  {
    "text": "details just really precise so we see this being used a lot for SQL statements when basically you want to provide",
    "start": "228000",
    "end": "234959"
  },
  {
    "text": "different ways of doing things and there's a lot of different syntax that you can get into in in SQL statements",
    "start": "234959",
    "end": "240900"
  },
  {
    "text": "and then also with tone it's really hard to describe a person's tone and so some of the first use cases of this were for",
    "start": "240900",
    "end": "246959"
  },
  {
    "text": "that um there's there's also a lot of uh Nuance here because what you can do is",
    "start": "246959",
    "end": "252720"
  },
  {
    "text": "you can you can gather you know you you can you can only provide maybe like three five maybe ten",
    "start": "252720",
    "end": "258780"
  },
  {
    "text": "depending on the context Windows examples to the language model a particular point in time but you can often gather way more than that and so",
    "start": "258780",
    "end": "265020"
  },
  {
    "text": "there's also also some kind of like questions here about how do you choose the correct uh examples to put into the",
    "start": "265020",
    "end": "270900"
  },
  {
    "text": "prompt um and so there's some Tooling in link chain around basically selecting the examples that are most relevant the the",
    "start": "270900",
    "end": "277199"
  },
  {
    "text": "main way to do that is based on some kind of like similarity score comparing the vectors of of the incoming question",
    "start": "277199",
    "end": "283080"
  },
  {
    "text": "to some some embedding for the examples that you have and so bringing in these kind of like",
    "start": "283080",
    "end": "289500"
  },
  {
    "text": "show don't tell types of examples is another way to provide context to the language model the third type of way to",
    "start": "289500",
    "end": "295320"
  },
  {
    "text": "provide context is maybe the the one that most people think about um it's Pro it's involved where it helps",
    "start": "295320",
    "end": "301380"
  },
  {
    "text": "create these rag type applications retrieval augmented Generation Um and specifically the the the",
    "start": "301380",
    "end": "307259"
  },
  {
    "text": "difference here is that you're providing context to the language model and you're asking it to base its response in this context so it's not exactly instructions",
    "start": "307259",
    "end": "314220"
  },
  {
    "text": "and it's not exactly examples rather it's it's some content and the language model is is going to base its entire",
    "start": "314220",
    "end": "321000"
  },
  {
    "text": "response on on that content and so you know you it and so we see this being",
    "start": "321000",
    "end": "326039"
  },
  {
    "text": "really powerful when doing question answering over your documents for example you can quickly get a chat bot over your documents without having to",
    "start": "326039",
    "end": "332940"
  },
  {
    "text": "retrain the model in any way simply by providing this type of content in a grounded way",
    "start": "332940",
    "end": "338820"
  },
  {
    "text": "and then the fourth type of way that we see people providing context and this is this is a bit newer",
    "start": "338820",
    "end": "344220"
  },
  {
    "text": "um but is in fine-tuning and so I would argue that updating the model's weights by fine-tuning over your documents",
    "start": "344220",
    "end": "350100"
  },
  {
    "text": "either to pick up knowledge or to pick up tone is a way of providing context to the to the language model on how it",
    "start": "350100",
    "end": "356400"
  },
  {
    "text": "should respond and so um this actually I think is an even better way to provide examples of of",
    "start": "356400",
    "end": "363120"
  },
  {
    "text": "um or provide the context of what a tone is for a particular person so we did some uh blog posts and and kind of like",
    "start": "363120",
    "end": "371220"
  },
  {
    "text": "notebooks recently on basically downloading your your Facebook message chats or your Twitter conversations and",
    "start": "371220",
    "end": "377940"
  },
  {
    "text": "fine-tuning a language based on a language model based on that and I think the reason that this is more powerful",
    "start": "377940",
    "end": "382979"
  },
  {
    "text": "than few shot examples is basically you can provide way more examples so you can provide you know however many examples",
    "start": "382979",
    "end": "388199"
  },
  {
    "text": "you're fine-tuning on so 100 500 a thousand something like that and with tone in particular as mentioned before",
    "start": "388199",
    "end": "393840"
  },
  {
    "text": "it's really complicated to just describe tone and so just giving it a bunch of examples goes a long way yeah",
    "start": "393840",
    "end": "400680"
  },
  {
    "text": "so so far we've talked about providing the right context to the language model so that it can decide what to do then",
    "start": "400680",
    "end": "406979"
  },
  {
    "text": "there's also the the reasoning aspect where it takes in that context and actually does the the reasoning about",
    "start": "406979",
    "end": "413940"
  },
  {
    "text": "what to do next and so for this I'll kind of like draw the boundaries as there's some input and then the language",
    "start": "413940",
    "end": "419819"
  },
  {
    "text": "model provides some output and so what's happening inside this black box what is going on in your system what's what's",
    "start": "419819",
    "end": "425580"
  },
  {
    "text": "the cognitive architecture of your system such that it can best respond to these types of questions",
    "start": "425580",
    "end": "432180"
  },
  {
    "text": "and so there's a few different levels of reasoning and this is very much a work in progress by the way so I'd love any",
    "start": "432180",
    "end": "438960"
  },
  {
    "text": "kind of like questions or feedback on this uh at the in the QA or after the event",
    "start": "438960",
    "end": "444180"
  },
  {
    "text": "um and there is a bit more of kind of like a leveling system here and this leveling is roughly an order of complexity or autonomy as it goes",
    "start": "444180",
    "end": "450720"
  },
  {
    "text": "farther down the stack and so I'll talk about all of these in detail but there's kind of clear kind of like different",
    "start": "450720",
    "end": "457740"
  },
  {
    "text": "attributes that that we see in these different levels and there also starts to be this this is where people start to",
    "start": "457740",
    "end": "463620"
  },
  {
    "text": "talk about agents and agencies in overloaded term at this point a lot of people use it to mean different things",
    "start": "463620",
    "end": "468800"
  },
  {
    "text": "but generally when we see people talking about projects as agents they generally fall into one of the level four level",
    "start": "468800",
    "end": "475199"
  },
  {
    "text": "five uh kind of like reasoning architectures that we see here so talking about them in more detail the",
    "start": "475199",
    "end": "482280"
  },
  {
    "text": "first one is maybe just a simple olm call so you provide the relevant context either as instructions few short",
    "start": "482280",
    "end": "487740"
  },
  {
    "text": "examples maybe there's some retrieval going on but you you make a single Alum call and you basically return that to",
    "start": "487740",
    "end": "493380"
  },
  {
    "text": "the user this is really good because it's really really fast it's just one llm caller I guess it depends on the",
    "start": "493380",
    "end": "499979"
  },
  {
    "text": "speed of your llm but it's generally pretty fast the downside is that you're expecting the llm to do a lot and we see",
    "start": "499979",
    "end": "506520"
  },
  {
    "text": "you know with with larger models this becomes more and more reliable but there's still they still struggle with",
    "start": "506520",
    "end": "512820"
  },
  {
    "text": "more kind of like complex reasoning tasks and so one thing that I mentioned earlier is that these are slightly",
    "start": "512820",
    "end": "518700"
  },
  {
    "text": "different levels it's it's unlike in the previous context one like an application",
    "start": "518700",
    "end": "524700"
  },
  {
    "text": "will probably only be one of these at a time importantly they can use other ones as sub components and I'll get into that",
    "start": "524700",
    "end": "531360"
  },
  {
    "text": "a little bit later on and then also importantly it doesn't necessarily mean that anyone is better than the other and",
    "start": "531360",
    "end": "537959"
  },
  {
    "text": "in fact as as we go on we'll see that some of the the level five ones are you know maybe not the best because it's",
    "start": "537959",
    "end": "544080"
  },
  {
    "text": "tricky to get them to work right and so this being the level one one this also isn't the worst sometimes it's really",
    "start": "544080",
    "end": "549779"
  },
  {
    "text": "good to have a single fast application we see a lot of chat apps being basically this as it becomes more about",
    "start": "549779",
    "end": "555779"
  },
  {
    "text": "providing the right context and then using a simple kind of like reasoning step the next reason you step up is is what",
    "start": "555779",
    "end": "562620"
  },
  {
    "text": "we call kind of like chaining and so this is combining multiple llm calls or a call with an llm and then some other",
    "start": "562620",
    "end": "568620"
  },
  {
    "text": "kind of like tool or function and then another llm in some sort of sequence and so an example of this could be related",
    "start": "568620",
    "end": "575820"
  },
  {
    "text": "to a chat bot that chats over your data you might have some user history you then use an llm to think about what to",
    "start": "575820",
    "end": "581820"
  },
  {
    "text": "look up so you so you're doing a lookup in in some retriever or some knowledge base based on the language model and",
    "start": "581820",
    "end": "588060"
  },
  {
    "text": "then you're taking that and you're passing it back to the language model and asking it to provide an answer and so this is a very simple kind of like",
    "start": "588060",
    "end": "594060"
  },
  {
    "text": "chain and and so we categorize these as there's basically you know exactly what",
    "start": "594060",
    "end": "599940"
  },
  {
    "text": "the steps are going to be you're going to do this and then you're going to do this and then you're going to do this and then you're going to do this and it's predefined determined what the",
    "start": "599940",
    "end": "606540"
  },
  {
    "text": "steps are and so an example of this that's slightly more complex than that but still in the in the area of this",
    "start": "606540",
    "end": "611760"
  },
  {
    "text": "like grounded generation is GPT researcher which is an awesome open source project that I would encourage all of you guys to check out and",
    "start": "611760",
    "end": "617940"
  },
  {
    "text": "basically what happens is you get a task that comes in you then generate a bunch of questions you then go kind of like",
    "start": "617940",
    "end": "623459"
  },
  {
    "text": "research each sub query find relevant documents online generate some",
    "start": "623459",
    "end": "628500"
  },
  {
    "text": "summarization for that and then combine the summaries with the report style agent and so in here there's a",
    "start": "628500",
    "end": "634800"
  },
  {
    "text": "predetermined sequence of events it starts to get really complex and you can see the different branches going on but",
    "start": "634800",
    "end": "640019"
  },
  {
    "text": "there's this this sequence of kind of like Steps in this chain that happens adding a bit of complexity into it",
    "start": "640019",
    "end": "647459"
  },
  {
    "text": "um they're now the next level up brings in kind of like routing and so this uses",
    "start": "647459",
    "end": "652680"
  },
  {
    "text": "a language model or or some other mechanism but we're talking about language models for the most part here so it uses a language model to determine",
    "start": "652680",
    "end": "658740"
  },
  {
    "text": "what steps to take so you might have a decision and you might route between we",
    "start": "658740",
    "end": "663899"
  },
  {
    "text": "see this an example of this often is with prompts like a question comes in maybe I use one prompt that's really",
    "start": "663899",
    "end": "668940"
  },
  {
    "text": "good at answering questions about math one prompt that's really good at answering questions about English and based on the user question I decide",
    "start": "668940",
    "end": "674459"
  },
  {
    "text": "which one to use and I could then go off that branch and continue on my way there so compared it to the previous one with",
    "start": "674459",
    "end": "681779"
  },
  {
    "text": "a chaining you don't always know exactly what path you're going to get the path depends on the user input importantly",
    "start": "681779",
    "end": "689100"
  },
  {
    "text": "though all paths are known so you could enumerate all possible paths ahead of time and so going back to the example of",
    "start": "689100",
    "end": "695940"
  },
  {
    "text": "GPT researcher I actually lied to you a little bit earlier there's actually some routing that's going on in particular",
    "start": "695940",
    "end": "701040"
  },
  {
    "text": "the report agent is a different agent or the prompt is different depending on the",
    "start": "701040",
    "end": "706260"
  },
  {
    "text": "input so if you ask a question about a technology The Prompt that it uses to",
    "start": "706260",
    "end": "711779"
  },
  {
    "text": "generate a report might be different than if you ask a general question about World Knowledge or something like that",
    "start": "711779",
    "end": "718560"
  },
  {
    "text": "the next level up and where we start to get into things that people like the call agents are when we approach automatons or state machines and so",
    "start": "718560",
    "end": "726300"
  },
  {
    "text": "um this this is involves a bunch of uh previous logic in routing so you often have blocks that decide what to do next",
    "start": "726300",
    "end": "733079"
  },
  {
    "text": "you've got that routing component there and the main difference is that you can now have these Cycles in in the routing",
    "start": "733079",
    "end": "739440"
  },
  {
    "text": "system and so you can start to get kind of like infinitely many different paths that you could go down and so just to",
    "start": "739440",
    "end": "747060"
  },
  {
    "text": "show some real world examples of this because this is actually the uh the level where we see most kind of like",
    "start": "747060",
    "end": "753120"
  },
  {
    "text": "real world agents existing we can look at plan and execute or this is this is",
    "start": "753120",
    "end": "759000"
  },
  {
    "text": "actually a a diagram from baby AGI which is very similar to a plan and solve",
    "start": "759000",
    "end": "764940"
  },
  {
    "text": "paper and we've implemented in Lane chain as plan and execute and basically you see here that you have a few",
    "start": "764940",
    "end": "770700"
  },
  {
    "text": "different types of agents at various parts in the process you have an execution agent you have a task creation",
    "start": "770700",
    "end": "776160"
  },
  {
    "text": "agent and you have a task prioritization and so in the baby AGI I think these are all different prompts and you're kind of",
    "start": "776160",
    "end": "783300"
  },
  {
    "text": "like cycling between these different states of the world and that one state you're you're planning what to do next then you execute on that then you go",
    "start": "783300",
    "end": "789959"
  },
  {
    "text": "back you you update um and and then you kind of like prioritize and you go in this Loop and",
    "start": "789959",
    "end": "795480"
  },
  {
    "text": "there's these there's these transition sequences where you can transition between states",
    "start": "795480",
    "end": "800880"
  },
  {
    "text": "um to go to another paper there's this reflexion paper and they have this agent",
    "start": "800880",
    "end": "805920"
  },
  {
    "text": "here and you can see that there's three different kind of like states that the agent can be in or and they call they",
    "start": "805920",
    "end": "811320"
  },
  {
    "text": "call these uh or the parentheses are LM for language models so there's three different kind of like ways of invoking",
    "start": "811320",
    "end": "816779"
  },
  {
    "text": "the language model and there's some kind of like cycle between them you can see uh that there's an actor language model",
    "start": "816779",
    "end": "822180"
  },
  {
    "text": "there's then an evaluator language model and a self-reflection language model and you've got this predetermined kind of",
    "start": "822180",
    "end": "827399"
  },
  {
    "text": "like way of transitioning between them we're at various points in time you're asking a language model to do different things",
    "start": "827399",
    "end": "833760"
  },
  {
    "text": "and to provide a real world example this is from sweep.dev which is an agent for coding and you can see here that there's",
    "start": "833760",
    "end": "840480"
  },
  {
    "text": "very clearly kind of like four different states and there's some Cycles between them so there's a search State and then there's this plan execute validate State",
    "start": "840480",
    "end": "847740"
  },
  {
    "text": "and there's this cycle between plan where you go to execute then you from execute you go to validate from validate",
    "start": "847740",
    "end": "853320"
  },
  {
    "text": "you can then either open a pull request which is basically finish the job or you can go back to plan if that step",
    "start": "853320",
    "end": "859500"
  },
  {
    "text": "realizes that it's not quite done yet and so there's this there's this cycle here the last thing is and so the level five",
    "start": "859500",
    "end": "867060"
  },
  {
    "text": "is like autonomous agents um and the main thing here is basically they aren't these explicit states that",
    "start": "867060",
    "end": "874260"
  },
  {
    "text": "the language model is transition in between rather there's a single language model and it's provided with the appropriate context at various points",
    "start": "874260",
    "end": "880920"
  },
  {
    "text": "but you're asking the language model to do everything by itself you're asking it to know when it needs to plan versus execute",
    "start": "880920",
    "end": "887220"
  },
  {
    "text": "um it knows how to do long-term planning and then break down just the first steps and so basically you're asking it to",
    "start": "887220",
    "end": "892740"
  },
  {
    "text": "have these states implicit in a single llm call rather than explicit throughout the system as laid out and so this is",
    "start": "892740",
    "end": "899579"
  },
  {
    "text": "this is actually what we have in link chain as the agent executor this is very similar to Auto GPT there's kind of this",
    "start": "899579",
    "end": "907320"
  },
  {
    "text": "Loop of llm action llm action and this repeated thing there um",
    "start": "907320",
    "end": "912720"
  },
  {
    "text": "we see these not being quite as uh scalable in the real world because they",
    "start": "912720",
    "end": "918899"
  },
  {
    "text": "they make kind of like this state implicit and when we do see them working they're on very focused domains so you",
    "start": "918899",
    "end": "927000"
  },
  {
    "text": "maybe only have one or two tools you're really focused on a particular task and that helps reduce the need for like this",
    "start": "927000",
    "end": "932699"
  },
  {
    "text": "this more explicit mental kind of like State transitioning",
    "start": "932699",
    "end": "937820"
  },
  {
    "text": "I want to talk now about some of the challenges that we see when building not just agents but these context-aware",
    "start": "937920",
    "end": "944220"
  },
  {
    "text": "reasoning applications so one of the first challenges and and",
    "start": "944220",
    "end": "950040"
  },
  {
    "text": "probably the challenge that Lang chain was designed to solve with is with the orchestration of all these different",
    "start": "950040",
    "end": "955079"
  },
  {
    "text": "architectures so whether it's chains or or routing or some of these agent-like things",
    "start": "955079",
    "end": "961040"
  },
  {
    "text": "there are a lot of different chains and sequences of chains that you can put together and so link chain provides a",
    "start": "961040",
    "end": "967740"
  },
  {
    "text": "lot of these off the shelf to to easily get started the next big challenge that we see and",
    "start": "967740",
    "end": "974820"
  },
  {
    "text": "and so this is actually the main place that we see people who are building online change spending time",
    "start": "974820",
    "end": "980639"
  },
  {
    "text": "that's a little bit self-selecting because they've gotten kind of like a lot of the orchestration out of the way but we see them spending a lot of time",
    "start": "980639",
    "end": "986279"
  },
  {
    "text": "on like data engineering because a lot of this is around providing like the right context to the language model and",
    "start": "986279",
    "end": "992160"
  },
  {
    "text": "this context is data a lot of this data is now kind of like natural language or text-based data and so the way that you",
    "start": "992160",
    "end": "999360"
  },
  {
    "text": "so there's a few different aspects here there's making sure that you have the right connectors to the different data sources making sure that you can",
    "start": "999360",
    "end": "1006740"
  },
  {
    "text": "pre-process them accordingly so take out any kind of like XML tags or HTML tags",
    "start": "1006740",
    "end": "1011839"
  },
  {
    "text": "that might be distracting the language model and then and then passing them around through this flow and so we see a",
    "start": "1011839",
    "end": "1018199"
  },
  {
    "text": "lot of people spending a lot of time on the data engineering aspect we try to assist with that with some of our",
    "start": "1018199",
    "end": "1023899"
  },
  {
    "text": "document loaders or text preprocessors but this is definitely one big place that is pretty application specific and",
    "start": "1023899",
    "end": "1030199"
  },
  {
    "text": "so we see a lot of folks spending time here and then the other big place that we see people spending time is around prompt engineering so at the end of the",
    "start": "1030199",
    "end": "1037339"
  },
  {
    "text": "day the main new thing here is language models and the main way that you interact with language models is through",
    "start": "1037339",
    "end": "1042798"
  },
  {
    "text": "prompting and so we see a lot of people experimenting with different versions of the prompts making sure that uh and I'd",
    "start": "1042799",
    "end": "1049700"
  },
  {
    "text": "maybe call this prompt construction so making sure that the different pieces of your context show up in the appropriate",
    "start": "1049700",
    "end": "1054919"
  },
  {
    "text": "places and this also ties in a little bit to data engineering so making sure that the data by the time it gets into",
    "start": "1054919",
    "end": "1060500"
  },
  {
    "text": "the prompt is formatted correctly and so we see a lot of people spending a lot of time with with the",
    "start": "1060500",
    "end": "1068179"
  },
  {
    "text": "prompting bit and across all these three bits orchestration um prompt engineering data engineering",
    "start": "1068179",
    "end": "1075799"
  },
  {
    "text": "as you start to scale up the systems and complexity debugging becomes really difficult because basically you've got",
    "start": "1075799",
    "end": "1082100"
  },
  {
    "text": "this data flowing through the system and you want to be able to know what exactly is going in and coming out of each step",
    "start": "1082100",
    "end": "1087260"
  },
  {
    "text": "especially when you've got a lot of these steps being language models which are non-deterministic and and really complex and so all the screenshots that",
    "start": "1087260",
    "end": "1093740"
  },
  {
    "text": "I'm showing you are from langsmith which is our logging debugging and I'll get to",
    "start": "1093740",
    "end": "1099679"
  },
  {
    "text": "some other stuff later platform but the main idea is to make it as easy as possible to see what exactly is going in",
    "start": "1099679",
    "end": "1105320"
  },
  {
    "text": "and out of each step and then debug it so here we have kind of like a notion of a prompt playground where you can pick",
    "start": "1105320",
    "end": "1111200"
  },
  {
    "text": "up at any point in time in your chain or agent and it's it's only for this",
    "start": "1111200",
    "end": "1117140"
  },
  {
    "text": "particular Step at the moment but basically you can recreate what what exactly went into the language model at that point in time mess around with it",
    "start": "1117140",
    "end": "1123380"
  },
  {
    "text": "so change some of the formatting of the data change the prompt and then rerun it and and see what happens then",
    "start": "1123380",
    "end": "1132260"
  },
  {
    "text": "one of the other big points where we see a lot of challenges coming into play is around evaluation and so evaluation is",
    "start": "1132260",
    "end": "1139340"
  },
  {
    "text": "really hard for a few reasons first of all the output of a lot of these",
    "start": "1139340",
    "end": "1144620"
  },
  {
    "text": "applications is more natural text than than anything else or natural language",
    "start": "1144620",
    "end": "1150280"
  },
  {
    "text": "and it's often difficult to evaluate natural language just not create metrics even if we had good metrics for a lot of",
    "start": "1150280",
    "end": "1157160"
  },
  {
    "text": "the the things that people are building there's not great data to evaluate on and so I'm going to go into a little bit",
    "start": "1157160",
    "end": "1163160"
  },
  {
    "text": "of some some tangents here but even for a relatively simple application most",
    "start": "1163160",
    "end": "1169760"
  },
  {
    "text": "people start not with data unlike in traditional ml where you start with data you train a model the amazing things",
    "start": "1169760",
    "end": "1176059"
  },
  {
    "text": "about language models is a fantastic zero shot kind of like performers so they start with an idea and they start",
    "start": "1176059",
    "end": "1181400"
  },
  {
    "text": "prompting it and they start getting some responses but then they don't have any data to evaluate on and so the number",
    "start": "1181400",
    "end": "1186559"
  },
  {
    "text": "one thing that we recommend that people do is just build up an example of this data set and have these data points that you can evaluate on",
    "start": "1186559",
    "end": "1193220"
  },
  {
    "text": "but oftentimes it's a little bit difficult to build up these uh data sets so one reason it might be difficult is",
    "start": "1193220",
    "end": "1200299"
  },
  {
    "text": "in chat applications in chat applications the the you have a series of chats and so if you change your chat",
    "start": "1200299",
    "end": "1206299"
  },
  {
    "text": "model if you have a ground truth label for the first part and the second part the second part could very well depend on what was said in the first part and",
    "start": "1206299",
    "end": "1213080"
  },
  {
    "text": "so how do you kind of like have this data set that keep tracks over time or or basically is consistent with any",
    "start": "1213080",
    "end": "1219020"
  },
  {
    "text": "changes you might make that star should become really difficult and one of the fun things that we're working on here is basically the idea of like simulations",
    "start": "1219020",
    "end": "1226220"
  },
  {
    "text": "so have a chat bot chat with some other language model or chatbot and then just",
    "start": "1226220",
    "end": "1231320"
  },
  {
    "text": "look at what the responses look like and so there you you have like almost like a little chaos monkey of sorts that goes",
    "start": "1231320",
    "end": "1237799"
  },
  {
    "text": "around and and tries to to mess with the chatbot other difficult things become",
    "start": "1237799",
    "end": "1242900"
  },
  {
    "text": "when you're asking the language model application to do things that involve real-time data so answer questions like",
    "start": "1242900",
    "end": "1248840"
  },
  {
    "text": "what is the temperature in SF today there's no real ground truth answer for that that differs depending on the day",
    "start": "1248840",
    "end": "1255380"
  },
  {
    "text": "and so there's a few things that we've seen people do here so one we've seen people record kind of like the correct",
    "start": "1255380",
    "end": "1261679"
  },
  {
    "text": "intermediate States so is the language model if it's hooked up to like a search engine is the language model generating",
    "start": "1261679",
    "end": "1267260"
  },
  {
    "text": "a search query what is the weather in SF um the other thing that we've seen people doing and then basically they",
    "start": "1267260",
    "end": "1273799"
  },
  {
    "text": "compare that to what actually happened and kind of like evaluate the trajectory of the chain or agent",
    "start": "1273799",
    "end": "1279020"
  },
  {
    "text": "the other thing that we've seen people doing is saving not a ground truth answer but some instruction set on how",
    "start": "1279020",
    "end": "1285140"
  },
  {
    "text": "to get the ground truth answer um and so they might save a search query that they then run against the search",
    "start": "1285140",
    "end": "1290480"
  },
  {
    "text": "engine when they're evaluating get back the response and then they compare the end response or another example is is",
    "start": "1290480",
    "end": "1296419"
  },
  {
    "text": "with SQL so if I ask kind of like a question around how how to get some information from a SQL database rather",
    "start": "1296419",
    "end": "1303320"
  },
  {
    "text": "than kind of like and it's based on real-time data so I can't save uh true ground truth final answer if I save some",
    "start": "1303320",
    "end": "1310520"
  },
  {
    "text": "intermediate State and compare against that there's different ways of executing the same SQL statement especially of an",
    "start": "1310520",
    "end": "1317179"
  },
  {
    "text": "agent where I'm maybe doing this in multiple steps and so rather I might save a SQL statement that I know will",
    "start": "1317179",
    "end": "1322820"
  },
  {
    "text": "return the right answer and then an evaluation I run that SQL statement I compare that to the chain or agent output and and I compare those and",
    "start": "1322820",
    "end": "1330260"
  },
  {
    "text": "that's my evaluation criteria and that's something that we we call kind of like Dynamic evaluation internally and so",
    "start": "1330260",
    "end": "1336260"
  },
  {
    "text": "basically I've gone down a few rep bit holes here and the main thing that I want to emphasize with evaluation is",
    "start": "1336260",
    "end": "1342740"
  },
  {
    "text": "it's really really application and data set specific so we try our best to add some utils in langsmith and laying chain",
    "start": "1342740",
    "end": "1350179"
  },
  {
    "text": "for this so we have some evaluators that use loms to look at two two outputs and determine if they're the same we have a",
    "start": "1350179",
    "end": "1356780"
  },
  {
    "text": "data set and testing mechanism in Lane Smith but unlike in debugging this isn't something that you can just set up and",
    "start": "1356780",
    "end": "1364100"
  },
  {
    "text": "use without putting any effort in when we see people doing this successfully they're investing real engineering hours",
    "start": "1364100",
    "end": "1369559"
  },
  {
    "text": "into constructing those data sets thinking carefully about the evaluation metrics and it's not necessarily kind of",
    "start": "1369559",
    "end": "1376100"
  },
  {
    "text": "like statistical metrics but just like what should you be measuring and how should you be measuring it and so my",
    "start": "1376100",
    "end": "1382520"
  },
  {
    "text": "main message to everyone here would be if you want good evaluation there's no Silver Bullet you're going to have to you're going to have to put in some work",
    "start": "1382520",
    "end": "1388580"
  },
  {
    "text": "to get it the last thing that we've been really really interested in lately is the",
    "start": "1388580",
    "end": "1393679"
  },
  {
    "text": "collaboration aspect of all of this so as we see these really complex systems grow over time we see that there's often",
    "start": "1393679",
    "end": "1400100"
  },
  {
    "text": "a bunch of different teams working on different parts of the system and there's different people with different skill sets within those teams working on",
    "start": "1400100",
    "end": "1406820"
  },
  {
    "text": "different parts so as an example of that the primary one of the main ways that we see this being done is the people who",
    "start": "1406820",
    "end": "1412159"
  },
  {
    "text": "are doing prompt engineering may not be the same as the people who are doing the data engineering and both of those those are like the two main parts of any of",
    "start": "1412159",
    "end": "1419059"
  },
  {
    "text": "these systems so the prompt engineering might often be best done by a PM or a",
    "start": "1419059",
    "end": "1424220"
  },
  {
    "text": "non-technical person who really knows the the uh the problem that's trying to be solved and who's pretty good at",
    "start": "1424220",
    "end": "1430039"
  },
  {
    "text": "communication and can describe that and then the data engineering is still crucially important and that's that's",
    "start": "1430039",
    "end": "1435440"
  },
  {
    "text": "data engineering at the end of the day so that's often done by an engineering team and so we're seeing these kind of like this there needs to be some way for",
    "start": "1435440",
    "end": "1442580"
  },
  {
    "text": "these two different teams to collaborate on these applications a lot of what we see right now is either it lives in in",
    "start": "1442580",
    "end": "1449000"
  },
  {
    "text": "kind of like GitHub everything lives in GitHub and the prompts are treated as code which I think is less than ideal",
    "start": "1449000",
    "end": "1454640"
  },
  {
    "text": "for some of the non-technical folks to collaborate there or we see people kind",
    "start": "1454640",
    "end": "1459860"
  },
  {
    "text": "of like using Excel spreadsheets and tracking that in Google Drive or something like that and there's and there's some kind of like versioning",
    "start": "1459860",
    "end": "1465080"
  },
  {
    "text": "system there and so I don't think we have the perfect solution for it yet but one of the big things that we're thinking about and working on is this",
    "start": "1465080",
    "end": "1472280"
  },
  {
    "text": "Hub where basically we're starting with prompts where you conversion them we'll add in some sort of testing component although again back to",
    "start": "1472280",
    "end": "1479299"
  },
  {
    "text": "the previous slide that starts to get really a little bit gnarly in how you do that generically but we're thinking a",
    "start": "1479299",
    "end": "1485720"
  },
  {
    "text": "lot about this collaboration among among different parts of the same team",
    "start": "1485720",
    "end": "1491659"
  },
  {
    "text": "that's pretty much all I have for today I think I have four minutes left so there's a microphone at the back and I",
    "start": "1491659",
    "end": "1497000"
  },
  {
    "text": "will take some questions if anyone has any [Applause]",
    "start": "1497000",
    "end": "1506960"
  },
  {
    "text": "okay so in in the picture you described you",
    "start": "1512600",
    "end": "1519700"
  },
  {
    "text": "a different architecture if you're routing to specific models yeah that's good so the questions about the routing architecture and I think the",
    "start": "1521419",
    "end": "1527480"
  },
  {
    "text": "example I gave was around routing to different prompts and is there a different architecture of whether you're routing to different models",
    "start": "1527480",
    "end": "1534620"
  },
  {
    "text": "um not not really I think the routing to different prompts was just one example of one that we see being done commonly I",
    "start": "1534620",
    "end": "1540559"
  },
  {
    "text": "think so so at the end of the day a lot of it uh and this is actually okay so at",
    "start": "1540559",
    "end": "1545779"
  },
  {
    "text": "the end of the day a lot of this is kind of like classification between which of several strategies should I do next there's maybe a slight Nuance there",
    "start": "1545779",
    "end": "1552380"
  },
  {
    "text": "where sometimes it's just classification of which I should do next and in other cases you're not only classifying which branch I should go down but what the",
    "start": "1552380",
    "end": "1558679"
  },
  {
    "text": "input to that Branch should be and so I'd draw a slight Nuance there and if it's just kind of like classification that's perfectly suited to kind of like",
    "start": "1558679",
    "end": "1565340"
  },
  {
    "text": "fine-tuning a classification model or a more traditional you know mm model for that if you start to also have to",
    "start": "1565340",
    "end": "1570980"
  },
  {
    "text": "generate the input to that then it starts to get a little bit more difficult but basically some of the examples that we see for this are like",
    "start": "1570980",
    "end": "1577340"
  },
  {
    "text": "routing between prompts um uh we actually don't see a ton of routing between models although there is",
    "start": "1577340",
    "end": "1583279"
  },
  {
    "text": "a lot of people have talked about that routing between retrievers is a really common one if you want to be answering questions over data sources choosing",
    "start": "1583279",
    "end": "1589520"
  },
  {
    "text": "which one and then routing between chains as well so also if you want to answer questions over data sources sometimes you have a vector store",
    "start": "1589520",
    "end": "1595400"
  },
  {
    "text": "sometimes you have a SQL table and so routing between and so each of those are different chains and so this is where",
    "start": "1595400",
    "end": "1601100"
  },
  {
    "text": "when I set the part around you can kind of like some of these components might be nested you could have a routing",
    "start": "1601100",
    "end": "1606919"
  },
  {
    "text": "architecture and then there could be a chain nested that could actually be an agent nested or something like there so they start to stack up a bit",
    "start": "1606919",
    "end": "1614200"
  },
  {
    "text": "so so generally yeah so generally when we see people doing this they're doing it through prompting so they kind of",
    "start": "1622460",
    "end": "1628039"
  },
  {
    "text": "tell the language model in this scenario you should go to this and this other scenario you should go to this this is a place where few shot examples are really",
    "start": "1628039",
    "end": "1633679"
  },
  {
    "text": "really useful because those instructions can often get pretty nuanced in terms of like where you want to go and also",
    "start": "1633679",
    "end": "1639320"
  },
  {
    "text": "especially if you're routing with questions that's a great case for using some sort of like selector based on similarity to previous examples to help",
    "start": "1639320",
    "end": "1645679"
  },
  {
    "text": "kind of like guide that and then yeah at the end of the day I do think this is this will be one area where we see fine",
    "start": "1645679",
    "end": "1651380"
  },
  {
    "text": "tuning being really really useful oh yes hello",
    "start": "1651380",
    "end": "1657380"
  },
  {
    "text": "okay uh first of all thank you for the lovely talk I'm a big fan of flank chain from the very beginning",
    "start": "1657380",
    "end": "1663080"
  },
  {
    "text": "um Mike I don't really have a question I just want to have a discussion about retrievers Vector databases are less",
    "start": "1663080",
    "end": "1669799"
  },
  {
    "text": "than ideal they work quite a bit but sometimes you'll have some things where the prompt is just not semantically",
    "start": "1669799",
    "end": "1677059"
  },
  {
    "text": "related to the question um I know that sometimes you could have a language model hallucinate what the",
    "start": "1677059",
    "end": "1684080"
  },
  {
    "text": "Target document is supposed to look like and then you'll use a vector database but even then we're I think we're",
    "start": "1684080",
    "end": "1689659"
  },
  {
    "text": "extremely far off from an ideal retrieval system um have you seen anything further than",
    "start": "1689659",
    "end": "1695419"
  },
  {
    "text": "that I'm just curious and I just want to think out loud a bit yeah I I think retrieval is really interesting and I",
    "start": "1695419",
    "end": "1702020"
  },
  {
    "text": "think it's um I I I think Vector databases are an important part but not kind of like the",
    "start": "1702020",
    "end": "1708679"
  },
  {
    "text": "full kind of like uh solution and I also agree that we probably haven't seen like well one like I think a lot of the times",
    "start": "1708679",
    "end": "1716360"
  },
  {
    "text": "where we see retrieval being done right it is very kind of like application specific um and and so there might not be like",
    "start": "1716360",
    "end": "1722600"
  },
  {
    "text": "one universally but best way to do retrieval um we've been experimenting a lot with uh kind of like more advanced retrieval",
    "start": "1722600",
    "end": "1731000"
  },
  {
    "text": "mechanisms which I would basically call kind of like a bunch of heuristics that sit on top of that stack on top of other",
    "start": "1731000",
    "end": "1736340"
  },
  {
    "text": "retrieval mechanisms so what I mean by that we have kind of like one example of",
    "start": "1736340",
    "end": "1741919"
  },
  {
    "text": "a parent document retriever where you kind of like uh you do semantic search over small chunks but then you retrieve",
    "start": "1741919",
    "end": "1748520"
  },
  {
    "text": "the larger parent document and so this is sorry no then you just passed the large",
    "start": "1748520",
    "end": "1755179"
  },
  {
    "text": "document or or the larger Chunk from the parent document into the context window and that basically solves the issue",
    "start": "1755179",
    "end": "1760880"
  },
  {
    "text": "where when you're doing lookup you want it to be really specific but when you're passing it to the language model you",
    "start": "1760880",
    "end": "1766159"
  },
  {
    "text": "want to provide it with lots of context and so that kind of bridges that Gap another really interesting retrieval",
    "start": "1766159",
    "end": "1771799"
  },
  {
    "text": "method that that we have in link chain that I like a lot is the self-query retriever so if you",
    "start": "1771799",
    "end": "1777860"
  },
  {
    "text": "have a question like what are some movies about aliens in the Year 1980 the",
    "start": "1777860",
    "end": "1783260"
  },
  {
    "text": "Year 1980 is not necessarily something that you want to do a semantic search over aliens might be and a lot of these",
    "start": "1783260",
    "end": "1789500"
  },
  {
    "text": "Vector stores support kind of like metadata filtering and so we've we've added I think maybe like eight eight or",
    "start": "1789500",
    "end": "1795679"
  },
  {
    "text": "ten Vector stores that have this self query bit where basically first in llm splits that question out into a semantic",
    "start": "1795679",
    "end": "1802340"
  },
  {
    "text": "query and then into a metadata filter and then that's parsed out and so those are just two kind of like examples of",
    "start": "1802340",
    "end": "1808460"
  },
  {
    "text": "these Advanced retrieval algorithms that we have this is an area we're really really interested in I don't think",
    "start": "1808460",
    "end": "1813500"
  },
  {
    "text": "there's a silver bullet that works in all cases I don't think it's a solved Problems by any means",
    "start": "1813500",
    "end": "1819799"
  },
  {
    "text": "all right thank you so much Harrison chance uh we give another final Applause for Harrison's",
    "start": "1819799",
    "end": "1826179"
  }
]
[
  {
    "start": "0",
    "end": "30000"
  },
  {
    "text": "hi",
    "start": "3040",
    "end": "3360"
  },
  {
    "text": "i'm eric um here to tell you about rlib",
    "start": "3360",
    "end": "5680"
  },
  {
    "text": "scalable rl for tensorflow pytorch and",
    "start": "5680",
    "end": "7839"
  },
  {
    "text": "beyond",
    "start": "7839",
    "end": "9840"
  },
  {
    "text": "so a bit about me so i'm currently a",
    "start": "9840",
    "end": "11519"
  },
  {
    "text": "software engineer at any skill and a",
    "start": "11519",
    "end": "13280"
  },
  {
    "text": "finishing phd student uc berkeley",
    "start": "13280",
    "end": "16000"
  },
  {
    "text": "i'm the team lead for rate core and",
    "start": "16000",
    "end": "17359"
  },
  {
    "text": "arlib at any skill and",
    "start": "17359",
    "end": "19119"
  },
  {
    "text": "in my research i work on applied rl and",
    "start": "19119",
    "end": "21439"
  },
  {
    "text": "ml systems",
    "start": "21439",
    "end": "23760"
  },
  {
    "text": "before grad school i spent a number of",
    "start": "23760",
    "end": "25439"
  },
  {
    "text": "years in industry at databricks and",
    "start": "25439",
    "end": "27519"
  },
  {
    "text": "at google",
    "start": "27519",
    "end": "31039"
  },
  {
    "start": "30000",
    "end": "30000"
  },
  {
    "text": "so i'm going to start this talk by",
    "start": "31039",
    "end": "33040"
  },
  {
    "text": "telling you a bit about reinforcement",
    "start": "33040",
    "end": "34559"
  },
  {
    "text": "learning and the problem our live is",
    "start": "34559",
    "end": "35840"
  },
  {
    "text": "solving",
    "start": "35840",
    "end": "36559"
  },
  {
    "text": "this talk will also cover the current",
    "start": "36559",
    "end": "38559"
  },
  {
    "text": "project status and upcoming developments",
    "start": "38559",
    "end": "40239"
  },
  {
    "text": "our lib",
    "start": "40239",
    "end": "41120"
  },
  {
    "text": "it's not going to be a really in-depth",
    "start": "41120",
    "end": "42640"
  },
  {
    "text": "talk about our lib for that we have an",
    "start": "42640",
    "end": "44079"
  },
  {
    "text": "advanced our live talk that",
    "start": "44079",
    "end": "45600"
  },
  {
    "text": "sven mika is also giving in the summit",
    "start": "45600",
    "end": "49440"
  },
  {
    "start": "49000",
    "end": "49000"
  },
  {
    "text": "so why rl uh just as background the main",
    "start": "49680",
    "end": "52800"
  },
  {
    "text": "difference between rl and supervised",
    "start": "52800",
    "end": "54399"
  },
  {
    "text": "learning is that reinforcement learning",
    "start": "54399",
    "end": "56000"
  },
  {
    "text": "has the potential to more",
    "start": "56000",
    "end": "57120"
  },
  {
    "text": "directly optimize for end objectives so",
    "start": "57120",
    "end": "59760"
  },
  {
    "text": "for example where in supervised learning",
    "start": "59760",
    "end": "61680"
  },
  {
    "text": "you might make",
    "start": "61680",
    "end": "62480"
  },
  {
    "text": "predictions about data for example given",
    "start": "62480",
    "end": "65280"
  },
  {
    "text": "some images you might make predictions",
    "start": "65280",
    "end": "66799"
  },
  {
    "text": "about the category of items in the",
    "start": "66799",
    "end": "68560"
  },
  {
    "text": "images",
    "start": "68560",
    "end": "70240"
  },
  {
    "text": "in aural uh you're instead training an",
    "start": "70240",
    "end": "72799"
  },
  {
    "text": "agent or a policy to take",
    "start": "72799",
    "end": "74880"
  },
  {
    "text": "actions in some environment um and",
    "start": "74880",
    "end": "78479"
  },
  {
    "text": "uh based on the actions agent takes the",
    "start": "78479",
    "end": "80320"
  },
  {
    "text": "environment provides feedback back to",
    "start": "80320",
    "end": "81840"
  },
  {
    "text": "the agent",
    "start": "81840",
    "end": "82880"
  },
  {
    "text": "in terms of observations and rewards and",
    "start": "82880",
    "end": "84799"
  },
  {
    "text": "over time the agent",
    "start": "84799",
    "end": "86320"
  },
  {
    "text": "is going to learn to improve the actions",
    "start": "86320",
    "end": "88479"
  },
  {
    "text": "it takes in the environment to maximize",
    "start": "88479",
    "end": "90479"
  },
  {
    "text": "the reward it receives",
    "start": "90479",
    "end": "93438"
  },
  {
    "text": "so reinforcement learning is a very uh",
    "start": "94159",
    "end": "96479"
  },
  {
    "text": "old field",
    "start": "96479",
    "end": "97200"
  },
  {
    "text": "but it's actually only recently that",
    "start": "97200",
    "end": "98799"
  },
  {
    "text": "when combined with deep learning that's",
    "start": "98799",
    "end": "100400"
  },
  {
    "text": "started working for real and to many",
    "start": "100400",
    "end": "102960"
  },
  {
    "text": "applications",
    "start": "102960",
    "end": "104399"
  },
  {
    "text": "so you're probably aware of uh you know",
    "start": "104399",
    "end": "106079"
  },
  {
    "text": "alpha zero which uh has achieved you",
    "start": "106079",
    "end": "108000"
  },
  {
    "text": "know",
    "start": "108000",
    "end": "108399"
  },
  {
    "text": "state-of-the-art performance a",
    "start": "108399",
    "end": "109680"
  },
  {
    "text": "superhuman performance in the game of go",
    "start": "109680",
    "end": "112240"
  },
  {
    "text": "um but arlo has found success in many",
    "start": "112240",
    "end": "114399"
  },
  {
    "text": "other domains such as",
    "start": "114399",
    "end": "115520"
  },
  {
    "text": "e-trading ads optimizations",
    "start": "115520",
    "end": "119119"
  },
  {
    "text": "database query optimization systems",
    "start": "119119",
    "end": "121680"
  },
  {
    "text": "control",
    "start": "121680",
    "end": "122640"
  },
  {
    "text": "and circuit layout and many other",
    "start": "122640",
    "end": "124719"
  },
  {
    "text": "besides these",
    "start": "124719",
    "end": "127360"
  },
  {
    "text": "like supervised learning though",
    "start": "127520",
    "end": "128800"
  },
  {
    "text": "reinforcement learning skills would",
    "start": "128800",
    "end": "130160"
  },
  {
    "text": "compute",
    "start": "130160",
    "end": "130800"
  },
  {
    "text": "so many of the recent successes in",
    "start": "130800",
    "end": "132400"
  },
  {
    "text": "reinforcement learning such as alpha 0",
    "start": "132400",
    "end": "134879"
  },
  {
    "text": "depend not only on algorithmic",
    "start": "134879",
    "end": "136879"
  },
  {
    "text": "innovations but also",
    "start": "136879",
    "end": "138080"
  },
  {
    "text": "leveraging specialized hardware and",
    "start": "138080",
    "end": "139920"
  },
  {
    "text": "distributed compute clusters",
    "start": "139920",
    "end": "142080"
  },
  {
    "text": "so what this means really is that the",
    "start": "142080",
    "end": "143440"
  },
  {
    "text": "software for reinforcement learning is",
    "start": "143440",
    "end": "144959"
  },
  {
    "text": "also quite important",
    "start": "144959",
    "end": "147200"
  },
  {
    "start": "147000",
    "end": "147000"
  },
  {
    "text": "and this is the problem our lib is",
    "start": "147200",
    "end": "148480"
  },
  {
    "text": "trying to solve providing a unified",
    "start": "148480",
    "end": "150319"
  },
  {
    "text": "reinforcement learning library that can",
    "start": "150319",
    "end": "151680"
  },
  {
    "text": "easily scale to large clusters",
    "start": "151680",
    "end": "153599"
  },
  {
    "text": "what we found is that different users of",
    "start": "153599",
    "end": "155360"
  },
  {
    "text": "rl care about different features because",
    "start": "155360",
    "end": "157280"
  },
  {
    "text": "they are focusing on different aspects",
    "start": "157280",
    "end": "158879"
  },
  {
    "text": "of",
    "start": "158879",
    "end": "159120"
  },
  {
    "text": "reinforcement learning for example teams",
    "start": "159120",
    "end": "161440"
  },
  {
    "text": "of research engineers care both about",
    "start": "161440",
    "end": "163200"
  },
  {
    "text": "building rl systems and the application",
    "start": "163200",
    "end": "165360"
  },
  {
    "text": "the applications",
    "start": "165360",
    "end": "167120"
  },
  {
    "text": "academic researchers care primarily",
    "start": "167120",
    "end": "168800"
  },
  {
    "text": "about the algorithms",
    "start": "168800",
    "end": "170640"
  },
  {
    "text": "and applied scientists and product",
    "start": "170640",
    "end": "172800"
  },
  {
    "text": "engineers are trying to leverage systems",
    "start": "172800",
    "end": "174480"
  },
  {
    "text": "algorithms to build their application",
    "start": "174480",
    "end": "176610"
  },
  {
    "text": "[Music]",
    "start": "176610",
    "end": "178080"
  },
  {
    "text": "to draw an analogy with supervised",
    "start": "178080",
    "end": "179760"
  },
  {
    "text": "learning in that field",
    "start": "179760",
    "end": "181840"
  },
  {
    "text": "there are many deep learning frameworks",
    "start": "181840",
    "end": "183280"
  },
  {
    "text": "that provide common ways to express and",
    "start": "183280",
    "end": "184959"
  },
  {
    "text": "scale tensor computations",
    "start": "184959",
    "end": "186720"
  },
  {
    "text": "and basically all kinds of users use",
    "start": "186720",
    "end": "188879"
  },
  {
    "text": "these common frameworks",
    "start": "188879",
    "end": "190159"
  },
  {
    "text": "for example pytorch and tensorflow so",
    "start": "190159",
    "end": "193040"
  },
  {
    "text": "rlib serves the same role for",
    "start": "193040",
    "end": "194800"
  },
  {
    "text": "reinforcement learning it provides",
    "start": "194800",
    "end": "196239"
  },
  {
    "text": "common apis for expressing and scaling",
    "start": "196239",
    "end": "198560"
  },
  {
    "text": "reinforcement learning training",
    "start": "198560",
    "end": "200400"
  },
  {
    "text": "no matter what your use cases",
    "start": "200400",
    "end": "203680"
  },
  {
    "text": "so what is rlib so it's an open source",
    "start": "204560",
    "end": "207840"
  },
  {
    "text": "library",
    "start": "207840",
    "end": "208640"
  },
  {
    "text": "and from the user perspective it has",
    "start": "208640",
    "end": "210879"
  },
  {
    "text": "kind of three main layers",
    "start": "210879",
    "end": "213120"
  },
  {
    "text": "the first layer is a unified api that",
    "start": "213120",
    "end": "215840"
  },
  {
    "text": "makes reinforcement learning accessible",
    "start": "215840",
    "end": "217519"
  },
  {
    "text": "from a ride a variety of applications so",
    "start": "217519",
    "end": "219519"
  },
  {
    "text": "this is of course",
    "start": "219519",
    "end": "220959"
  },
  {
    "text": "including benchmark environments such as",
    "start": "220959",
    "end": "223040"
  },
  {
    "text": "openai gym",
    "start": "223040",
    "end": "224400"
  },
  {
    "text": "but our lib also supports multi-agent",
    "start": "224400",
    "end": "226480"
  },
  {
    "text": "scenarios um",
    "start": "226480",
    "end": "227760"
  },
  {
    "text": "serving policies to external systems and",
    "start": "227760",
    "end": "230080"
  },
  {
    "text": "processing uh",
    "start": "230080",
    "end": "231200"
  },
  {
    "text": "learning on offline or batch batch rl",
    "start": "231200",
    "end": "233360"
  },
  {
    "text": "data",
    "start": "233360",
    "end": "235040"
  },
  {
    "text": "second it has a collection of",
    "start": "235040",
    "end": "236560"
  },
  {
    "text": "best-in-class reference algorithms this",
    "start": "236560",
    "end": "238159"
  },
  {
    "text": "spans a model-free and model based",
    "start": "238159",
    "end": "240080"
  },
  {
    "text": "algorithms",
    "start": "240080",
    "end": "241040"
  },
  {
    "text": "and other ones and finally it has",
    "start": "241040",
    "end": "243599"
  },
  {
    "text": "primitives for implementing a new",
    "start": "243599",
    "end": "245040"
  },
  {
    "text": "reinforcement algorithms and you might",
    "start": "245040",
    "end": "246400"
  },
  {
    "text": "care about this if you're a researcher",
    "start": "246400",
    "end": "247920"
  },
  {
    "text": "or an",
    "start": "247920",
    "end": "249040"
  },
  {
    "text": "rl engineer so i'm going to first talk",
    "start": "249040",
    "end": "252799"
  },
  {
    "text": "about",
    "start": "252799",
    "end": "253120"
  },
  {
    "text": "our lives unified api um",
    "start": "253120",
    "end": "256160"
  },
  {
    "start": "255000",
    "end": "255000"
  },
  {
    "text": "as an example of the benefits of a",
    "start": "256160",
    "end": "257600"
  },
  {
    "text": "unified api",
    "start": "257600",
    "end": "259199"
  },
  {
    "text": "here we look at an example application",
    "start": "259199",
    "end": "260799"
  },
  {
    "text": "called nero mmo so this is a massively",
    "start": "260799",
    "end": "263280"
  },
  {
    "text": "multi-agent game",
    "start": "263280",
    "end": "264479"
  },
  {
    "text": "environment released recently by openai",
    "start": "264479",
    "end": "267360"
  },
  {
    "text": "for research purposes",
    "start": "267360",
    "end": "270400"
  },
  {
    "text": "so despite being a kind of you know",
    "start": "271040",
    "end": "272880"
  },
  {
    "text": "simulated game this is actually an",
    "start": "272880",
    "end": "274160"
  },
  {
    "text": "extremely challenging application",
    "start": "274160",
    "end": "275759"
  },
  {
    "text": "in rl terms not only you're not only",
    "start": "275759",
    "end": "278639"
  },
  {
    "text": "training one agent to act you're",
    "start": "278639",
    "end": "280080"
  },
  {
    "text": "training",
    "start": "280080",
    "end": "280880"
  },
  {
    "text": "kind of a group of agents or to",
    "start": "280880",
    "end": "284000"
  },
  {
    "text": "compete or cooperate with each other",
    "start": "284000",
    "end": "286080"
  },
  {
    "text": "there are a dynamic number of agents in",
    "start": "286080",
    "end": "287680"
  },
  {
    "text": "this environment",
    "start": "287680",
    "end": "288960"
  },
  {
    "text": "since agents can kind of you know live",
    "start": "288960",
    "end": "290639"
  },
  {
    "text": "and die",
    "start": "290639",
    "end": "292240"
  },
  {
    "text": "and agents receive complex structured",
    "start": "292240",
    "end": "294240"
  },
  {
    "text": "observations it's not just you know one",
    "start": "294240",
    "end": "296240"
  },
  {
    "text": "single vector of features or a single",
    "start": "296240",
    "end": "298160"
  },
  {
    "text": "image",
    "start": "298160",
    "end": "298960"
  },
  {
    "text": "but it's it's like a real world system",
    "start": "298960",
    "end": "301199"
  },
  {
    "text": "where you have metrics telemetry and so",
    "start": "301199",
    "end": "303039"
  },
  {
    "text": "on",
    "start": "303039",
    "end": "303680"
  },
  {
    "text": "about nearby entities",
    "start": "303680",
    "end": "307360"
  },
  {
    "text": "despite this complexity however neurommo",
    "start": "307360",
    "end": "309520"
  },
  {
    "text": "can basically train out of the box on",
    "start": "309520",
    "end": "311280"
  },
  {
    "text": "rlip",
    "start": "311280",
    "end": "312000"
  },
  {
    "text": "and this is possible because rlibs apis",
    "start": "312000",
    "end": "314320"
  },
  {
    "text": "are general enough to cover",
    "start": "314320",
    "end": "315759"
  },
  {
    "text": "this application and this is something",
    "start": "315759",
    "end": "317680"
  },
  {
    "text": "no other ro library can do because they",
    "start": "317680",
    "end": "319600"
  },
  {
    "text": "don't have a unified api",
    "start": "319600",
    "end": "324000"
  },
  {
    "text": "yeah so why is having a unified api",
    "start": "324000",
    "end": "325840"
  },
  {
    "text": "important so beyond the obvious you know",
    "start": "325840",
    "end": "327600"
  },
  {
    "text": "software engineering reasons",
    "start": "327600",
    "end": "329199"
  },
  {
    "text": "there i think there's a couple key",
    "start": "329199",
    "end": "330479"
  },
  {
    "text": "points so first is easy scalability",
    "start": "330479",
    "end": "333280"
  },
  {
    "text": "uh any application that runs on rlib can",
    "start": "333280",
    "end": "335520"
  },
  {
    "text": "kind of automatically scale with",
    "start": "335520",
    "end": "337199"
  },
  {
    "text": "with the rate distributed system",
    "start": "337199",
    "end": "340320"
  },
  {
    "text": "in fact thanks to the scalability rlib",
    "start": "340320",
    "end": "343680"
  },
  {
    "text": "the neural mmo authors found that like",
    "start": "343680",
    "end": "346960"
  },
  {
    "text": "right after they integrated with rlip",
    "start": "346960",
    "end": "348560"
  },
  {
    "text": "they were able to",
    "start": "348560",
    "end": "350000"
  },
  {
    "text": "get new state-of-the-art performance",
    "start": "350000",
    "end": "351520"
  },
  {
    "text": "just through scale",
    "start": "351520",
    "end": "354240"
  },
  {
    "text": "a second reason is that a unified api",
    "start": "354800",
    "end": "357440"
  },
  {
    "text": "allows easy experimentation for",
    "start": "357440",
    "end": "359600"
  },
  {
    "text": "applied use cases even if you don't need",
    "start": "359600",
    "end": "362160"
  },
  {
    "text": "to scale",
    "start": "362160",
    "end": "362800"
  },
  {
    "text": "this is because for an applied problem",
    "start": "362800",
    "end": "364319"
  },
  {
    "text": "you're experimenting with many different",
    "start": "364319",
    "end": "365840"
  },
  {
    "text": "ways to express",
    "start": "365840",
    "end": "366720"
  },
  {
    "text": "a problem in reinforcement learning",
    "start": "366720",
    "end": "368000"
  },
  {
    "text": "terms so you want a lot of flexibility",
    "start": "368000",
    "end": "370479"
  },
  {
    "text": "to tinker with different approaches for",
    "start": "370479",
    "end": "372000"
  },
  {
    "text": "example multi-agent decompositions",
    "start": "372000",
    "end": "373919"
  },
  {
    "text": "different model types and so on",
    "start": "373919",
    "end": "375680"
  },
  {
    "text": "which rlib allows kind of in one library",
    "start": "375680",
    "end": "378319"
  },
  {
    "text": "without needing to switch between",
    "start": "378319",
    "end": "379520"
  },
  {
    "text": "different software frameworks",
    "start": "379520",
    "end": "382720"
  },
  {
    "text": "the second thing that rla provides is a",
    "start": "386880",
    "end": "389440"
  },
  {
    "text": "collection of",
    "start": "389440",
    "end": "390400"
  },
  {
    "text": "reference algorithms so here's a list of",
    "start": "390400",
    "end": "393680"
  },
  {
    "start": "392000",
    "end": "392000"
  },
  {
    "text": "algorithms from the documentation of our",
    "start": "393680",
    "end": "395759"
  },
  {
    "text": "lib at our lib.io",
    "start": "395759",
    "end": "397759"
  },
  {
    "text": "arla provides a cohesive api across more",
    "start": "397759",
    "end": "400479"
  },
  {
    "text": "than 14 tensorflow algorithms and 18 pi",
    "start": "400479",
    "end": "402639"
  },
  {
    "text": "torch algorithms",
    "start": "402639",
    "end": "404560"
  },
  {
    "text": "it lets you easily scale all these",
    "start": "404560",
    "end": "406319"
  },
  {
    "text": "algorithms from a laptop to a cluster",
    "start": "406319",
    "end": "408160"
  },
  {
    "text": "and also customize these algorithms for",
    "start": "408160",
    "end": "410240"
  },
  {
    "text": "complex use cases for example",
    "start": "410240",
    "end": "411599"
  },
  {
    "text": "multi-agent rl as needed",
    "start": "411599",
    "end": "414479"
  },
  {
    "text": "so to give some credit uh here the these",
    "start": "414479",
    "end": "417039"
  },
  {
    "text": "algorithms come from a variety of",
    "start": "417039",
    "end": "418639"
  },
  {
    "text": "community contributors obviously writes",
    "start": "418639",
    "end": "420560"
  },
  {
    "text": "lab and any skill",
    "start": "420560",
    "end": "421919"
  },
  {
    "text": "but also a number of other companies and",
    "start": "421919",
    "end": "423599"
  },
  {
    "text": "university groups so",
    "start": "423599",
    "end": "425199"
  },
  {
    "text": "yeah we're very grateful for these",
    "start": "425199",
    "end": "426560"
  },
  {
    "text": "contributions because obviously a single",
    "start": "426560",
    "end": "428479"
  },
  {
    "text": "organization has a hard time",
    "start": "428479",
    "end": "430160"
  },
  {
    "text": "having enough expertise to maintain all",
    "start": "430160",
    "end": "431680"
  },
  {
    "text": "these different types of arguments",
    "start": "431680",
    "end": "434800"
  },
  {
    "text": "finally if you're an algorithms",
    "start": "435759",
    "end": "436880"
  },
  {
    "text": "researcher or need to deeply customize",
    "start": "436880",
    "end": "438720"
  },
  {
    "text": "an algorithm rlip provides primitives",
    "start": "438720",
    "end": "440400"
  },
  {
    "text": "for building completely novel",
    "start": "440400",
    "end": "441759"
  },
  {
    "text": "rl algorithms that seamlessly fit in",
    "start": "441759",
    "end": "443599"
  },
  {
    "text": "with our ellipse unified api",
    "start": "443599",
    "end": "446960"
  },
  {
    "start": "447000",
    "end": "447000"
  },
  {
    "text": "as you can imagine parameters for",
    "start": "447680",
    "end": "450000"
  },
  {
    "text": "building rl algorithms is a is a complex",
    "start": "450000",
    "end": "452000"
  },
  {
    "text": "topic so here i'm going to dive",
    "start": "452000",
    "end": "453360"
  },
  {
    "text": "specifically into how our lib scales",
    "start": "453360",
    "end": "455120"
  },
  {
    "text": "algorithms to a cluster",
    "start": "455120",
    "end": "457360"
  },
  {
    "text": "and the example i'm going to use for",
    "start": "457360",
    "end": "458639"
  },
  {
    "text": "this is scaling the basic policy",
    "start": "458639",
    "end": "460479"
  },
  {
    "text": "gradients algorithm",
    "start": "460479",
    "end": "462080"
  },
  {
    "text": "if you're not familiar with policy",
    "start": "462080",
    "end": "463440"
  },
  {
    "text": "gradients not to worry the math aside",
    "start": "463440",
    "end": "465680"
  },
  {
    "text": "the computation pattern is actually",
    "start": "465680",
    "end": "466960"
  },
  {
    "text": "really simple",
    "start": "466960",
    "end": "467599"
  },
  {
    "text": "in fact it's just shown on this slide",
    "start": "467599",
    "end": "468960"
  },
  {
    "text": "here um the steps are basically as",
    "start": "468960",
    "end": "471440"
  },
  {
    "text": "follows we're going to start from",
    "start": "471440",
    "end": "472560"
  },
  {
    "text": "the um the left so",
    "start": "472560",
    "end": "475840"
  },
  {
    "text": "first is parallel rollouts so with the",
    "start": "475840",
    "end": "477360"
  },
  {
    "text": "current policy we want to generate",
    "start": "477360",
    "end": "479599"
  },
  {
    "text": "rollouts from the environment in",
    "start": "479599",
    "end": "481039"
  },
  {
    "text": "parallel so basically we want to gather",
    "start": "481039",
    "end": "482479"
  },
  {
    "text": "experiences",
    "start": "482479",
    "end": "483280"
  },
  {
    "text": "given the current policy the next step",
    "start": "483280",
    "end": "485759"
  },
  {
    "text": "is to combine these experiences together",
    "start": "485759",
    "end": "487280"
  },
  {
    "text": "into a single data set with a",
    "start": "487280",
    "end": "488720"
  },
  {
    "text": "concatenate operator",
    "start": "488720",
    "end": "490720"
  },
  {
    "text": "we want to take this concatenated data",
    "start": "490720",
    "end": "492560"
  },
  {
    "text": "and use it to update our",
    "start": "492560",
    "end": "493840"
  },
  {
    "text": "policy with stochastic reading descent",
    "start": "493840",
    "end": "497039"
  },
  {
    "text": "finally we broadcast a new policy to our",
    "start": "497039",
    "end": "499280"
  },
  {
    "text": "workers and report metrics and repeat",
    "start": "499280",
    "end": "503280"
  },
  {
    "text": "so to get still work in art lib there's",
    "start": "503759",
    "end": "506879"
  },
  {
    "text": "a couple steps first you",
    "start": "506879",
    "end": "508720"
  },
  {
    "text": "uh you need to express these series of",
    "start": "508720",
    "end": "510319"
  },
  {
    "text": "steps in arlit and our lib has a",
    "start": "510319",
    "end": "512479"
  },
  {
    "text": "domain specific language so let's",
    "start": "512479",
    "end": "513760"
  },
  {
    "text": "usually do this",
    "start": "513760",
    "end": "515680"
  },
  {
    "text": "and that's pretty pretty much it uh once",
    "start": "515680",
    "end": "518080"
  },
  {
    "text": "you do that",
    "start": "518080",
    "end": "518880"
  },
  {
    "text": "our arlo will automatically schedule and",
    "start": "518880",
    "end": "520479"
  },
  {
    "text": "execute the algorithm with ray",
    "start": "520479",
    "end": "523919"
  },
  {
    "text": "to make this more concrete this is",
    "start": "526160",
    "end": "527839"
  },
  {
    "text": "actually what the dsl looks like",
    "start": "527839",
    "end": "529360"
  },
  {
    "text": "this is actually copy pasted from the",
    "start": "529360",
    "end": "531440"
  },
  {
    "text": "policy gradients",
    "start": "531440",
    "end": "532839"
  },
  {
    "text": "implementation so i'll walk through it",
    "start": "532839",
    "end": "535519"
  },
  {
    "text": "so that what is the execution plan for",
    "start": "535519",
    "end": "537200"
  },
  {
    "text": "this policy gradients our room",
    "start": "537200",
    "end": "538720"
  },
  {
    "text": "so this is a distributed plan that runs",
    "start": "538720",
    "end": "540320"
  },
  {
    "text": "across many workers or potentially many",
    "start": "540320",
    "end": "542240"
  },
  {
    "text": "machines",
    "start": "542240",
    "end": "543120"
  },
  {
    "text": "and it looks like this so first we have",
    "start": "543120",
    "end": "545360"
  },
  {
    "text": "a set of workers",
    "start": "545360",
    "end": "546959"
  },
  {
    "text": "and we're going to tell these workers do",
    "start": "546959",
    "end": "548399"
  },
  {
    "text": "a parallel rollouts uh work",
    "start": "548399",
    "end": "550399"
  },
  {
    "text": "so rollouts in parallel to get",
    "start": "550399",
    "end": "552080"
  },
  {
    "text": "experiences the next step",
    "start": "552080",
    "end": "553920"
  },
  {
    "text": "is we're going to take those rollouts",
    "start": "553920",
    "end": "555200"
  },
  {
    "text": "and we're combining them together into",
    "start": "555200",
    "end": "557519"
  },
  {
    "text": "a batches of some minimum batch size",
    "start": "557519",
    "end": "559760"
  },
  {
    "text": "specified by the configuration so this",
    "start": "559760",
    "end": "561760"
  },
  {
    "text": "is the concat batches",
    "start": "561760",
    "end": "563279"
  },
  {
    "text": "operator there and the next step is",
    "start": "563279",
    "end": "565839"
  },
  {
    "text": "we're going to",
    "start": "565839",
    "end": "567279"
  },
  {
    "text": "apply those apply this train one step",
    "start": "567279",
    "end": "569839"
  },
  {
    "text": "operator to",
    "start": "569839",
    "end": "570880"
  },
  {
    "text": "update do one step of stochastic",
    "start": "570880",
    "end": "572959"
  },
  {
    "text": "gradient descent",
    "start": "572959",
    "end": "574560"
  },
  {
    "text": "on the policy again these experiences",
    "start": "574560",
    "end": "577519"
  },
  {
    "text": "and uh",
    "start": "577519",
    "end": "578240"
  },
  {
    "text": "this this series of steps will just",
    "start": "578240",
    "end": "580080"
  },
  {
    "text": "repeat over and over until the policy is",
    "start": "580080",
    "end": "581920"
  },
  {
    "text": "trained uh kind of to your uh",
    "start": "581920",
    "end": "584080"
  },
  {
    "text": "you know a target reward and of course",
    "start": "584080",
    "end": "587279"
  },
  {
    "text": "we return a standard metrics reporting",
    "start": "587279",
    "end": "589120"
  },
  {
    "text": "wrapper around",
    "start": "589120",
    "end": "590160"
  },
  {
    "text": "around this plan that reports metrics in",
    "start": "590160",
    "end": "592160"
  },
  {
    "text": "a standard way across all",
    "start": "592160",
    "end": "593680"
  },
  {
    "text": "all rl algorithms",
    "start": "593680",
    "end": "596800"
  },
  {
    "text": "this distributed execution dsl is a new",
    "start": "597360",
    "end": "599360"
  },
  {
    "text": "feature of rl11.0 and makes it much much",
    "start": "599360",
    "end": "601839"
  },
  {
    "text": "easier to write new distributed items",
    "start": "601839",
    "end": "604160"
  },
  {
    "text": "we've actually already ported all the",
    "start": "604160",
    "end": "605519"
  },
  {
    "text": "internal algorithms to this new paradigm",
    "start": "605519",
    "end": "607760"
  },
  {
    "text": "and it's a huge simplification",
    "start": "607760",
    "end": "610079"
  },
  {
    "text": "for example apex and impala two of the",
    "start": "610079",
    "end": "612320"
  },
  {
    "text": "more complex high performance",
    "start": "612320",
    "end": "613920"
  },
  {
    "text": "distributed algorithms in our live have",
    "start": "613920",
    "end": "615440"
  },
  {
    "text": "gone from four to five hundred lines of",
    "start": "615440",
    "end": "617200"
  },
  {
    "text": "code to just one or two hundred lines of",
    "start": "617200",
    "end": "619360"
  },
  {
    "text": "code",
    "start": "619360",
    "end": "620560"
  },
  {
    "text": "so keep in mind this is real production",
    "start": "620560",
    "end": "622160"
  },
  {
    "text": "code with you know debugging log",
    "start": "622160",
    "end": "623600"
  },
  {
    "text": "statements",
    "start": "623600",
    "end": "624560"
  },
  {
    "text": "metrics reporting and so on so this is a",
    "start": "624560",
    "end": "626800"
  },
  {
    "text": "really huge huge simplification in terms",
    "start": "626800",
    "end": "628560"
  },
  {
    "text": "of readability",
    "start": "628560",
    "end": "630720"
  },
  {
    "text": "so i wanted to also give an update on",
    "start": "630720",
    "end": "632399"
  },
  {
    "start": "631000",
    "end": "631000"
  },
  {
    "text": "the the r-lip community",
    "start": "632399",
    "end": "635040"
  },
  {
    "text": "so uh and for ray we have a a slack",
    "start": "635040",
    "end": "638720"
  },
  {
    "text": "and there's the r-lip slack channel",
    "start": "638720",
    "end": "640079"
  },
  {
    "text": "which has more than a thousand users so",
    "start": "640079",
    "end": "641760"
  },
  {
    "text": "you can",
    "start": "641760",
    "end": "642160"
  },
  {
    "text": "join this at our lib.io we've seen a",
    "start": "642160",
    "end": "645519"
  },
  {
    "text": "steady growth in user engagement on",
    "start": "645519",
    "end": "647040"
  },
  {
    "text": "github",
    "start": "647040",
    "end": "648240"
  },
  {
    "text": "um users have reported many novel use",
    "start": "648240",
    "end": "651040"
  },
  {
    "text": "cases that help guide our roadmap",
    "start": "651040",
    "end": "653360"
  },
  {
    "text": "and uh yeah there's just been a lot of",
    "start": "653360",
    "end": "655440"
  },
  {
    "text": "growth and issues reported",
    "start": "655440",
    "end": "656959"
  },
  {
    "text": "about our live on on github which is a",
    "start": "656959",
    "end": "658880"
  },
  {
    "text": "measure of user engagement",
    "start": "658880",
    "end": "660720"
  },
  {
    "text": "so this graph is showing the issues new",
    "start": "660720",
    "end": "662480"
  },
  {
    "text": "issues reported uh",
    "start": "662480",
    "end": "663839"
  },
  {
    "text": "are live specific specifically for our",
    "start": "663839",
    "end": "665680"
  },
  {
    "text": "lib per month across the past two years",
    "start": "665680",
    "end": "668320"
  },
  {
    "text": "and as you can see we're seeing an",
    "start": "668320",
    "end": "669680"
  },
  {
    "text": "accelerated number of issues per month",
    "start": "669680",
    "end": "672640"
  },
  {
    "text": "especially in the past few months",
    "start": "672640",
    "end": "676240"
  },
  {
    "text": "our lib is also a part of several",
    "start": "677839",
    "end": "679760"
  },
  {
    "text": "industry",
    "start": "679760",
    "end": "680959"
  },
  {
    "text": "rl platforms today um several which are",
    "start": "680959",
    "end": "684320"
  },
  {
    "text": "public and",
    "start": "684320",
    "end": "684959"
  },
  {
    "text": "it's also used internally by many more",
    "start": "684959",
    "end": "687120"
  },
  {
    "text": "so some of the",
    "start": "687120",
    "end": "688640"
  },
  {
    "text": "public ones are amazon stage maker rl uh",
    "start": "688640",
    "end": "691760"
  },
  {
    "text": "azure rl bonsai",
    "start": "691760",
    "end": "694880"
  },
  {
    "text": "and skymind so what's next for rlib",
    "start": "694880",
    "end": "699600"
  },
  {
    "text": "here are some of the top issues raised",
    "start": "699600",
    "end": "701279"
  },
  {
    "text": "by users",
    "start": "701279",
    "end": "702640"
  },
  {
    "text": "first we hear there's a lot of community",
    "start": "702640",
    "end": "704320"
  },
  {
    "text": "interest in frameworks like pytorch and",
    "start": "704320",
    "end": "706240"
  },
  {
    "text": "jaxx",
    "start": "706240",
    "end": "708560"
  },
  {
    "text": "users are also very interested in model",
    "start": "708560",
    "end": "710399"
  },
  {
    "text": "based reinforcement learning so model",
    "start": "710399",
    "end": "711920"
  },
  {
    "text": "based rl is",
    "start": "711920",
    "end": "712880"
  },
  {
    "text": "kind of a rapidly advancing field of",
    "start": "712880",
    "end": "715519"
  },
  {
    "text": "research and reinforcement learning",
    "start": "715519",
    "end": "716959"
  },
  {
    "text": "right now and has the promise for",
    "start": "716959",
    "end": "718959"
  },
  {
    "text": "a much greater efficiency making",
    "start": "718959",
    "end": "720560"
  },
  {
    "text": "reinforcement learning actually",
    "start": "720560",
    "end": "721680"
  },
  {
    "text": "practical for",
    "start": "721680",
    "end": "722639"
  },
  {
    "text": "a task where it's expensive to collect",
    "start": "722639",
    "end": "724399"
  },
  {
    "text": "experiences",
    "start": "724399",
    "end": "726959"
  },
  {
    "text": "users are interested in complex",
    "start": "727519",
    "end": "729440"
  },
  {
    "text": "multi-agent use cases",
    "start": "729440",
    "end": "731200"
  },
  {
    "text": "both for research and also applied use",
    "start": "731200",
    "end": "733279"
  },
  {
    "text": "cases",
    "start": "733279",
    "end": "735680"
  },
  {
    "text": "and as as models have advanced in the",
    "start": "736079",
    "end": "740079"
  },
  {
    "text": "deep learning",
    "start": "740079",
    "end": "740880"
  },
  {
    "text": "field users are interested in leveraging",
    "start": "740880",
    "end": "743519"
  },
  {
    "text": "uh more more powerful models such as",
    "start": "743519",
    "end": "746399"
  },
  {
    "text": "transformers that you know self-attend",
    "start": "746399",
    "end": "748720"
  },
  {
    "text": "across",
    "start": "748720",
    "end": "750000"
  },
  {
    "text": "time or or or for models for handling",
    "start": "750000",
    "end": "753120"
  },
  {
    "text": "complex observations",
    "start": "753120",
    "end": "755440"
  },
  {
    "text": "so what are we doing about this well",
    "start": "755440",
    "end": "758480"
  },
  {
    "text": "i'm happy to say that with arlo 1.0 uh",
    "start": "758480",
    "end": "761920"
  },
  {
    "text": "pytorch now has 100 parity with uh our",
    "start": "761920",
    "end": "764880"
  },
  {
    "text": "lip tensor flow",
    "start": "764880",
    "end": "766000"
  },
  {
    "text": "actually we have actually more uh more",
    "start": "766000",
    "end": "768560"
  },
  {
    "text": "pie chart diagrams in tensorflow now",
    "start": "768560",
    "end": "770560"
  },
  {
    "text": "because it's just simply easier to add",
    "start": "770560",
    "end": "772079"
  },
  {
    "text": "new items in in pi torch",
    "start": "772079",
    "end": "775600"
  },
  {
    "text": "for model-based reinforcement learning",
    "start": "776079",
    "end": "777680"
  },
  {
    "text": "and in our live 1.0 we have",
    "start": "777680",
    "end": "779920"
  },
  {
    "text": "nvmpo and dreamer fully implemented and",
    "start": "779920",
    "end": "782560"
  },
  {
    "text": "tested",
    "start": "782560",
    "end": "784959"
  },
  {
    "text": "and to support some of these more",
    "start": "785200",
    "end": "786320"
  },
  {
    "text": "complex use cases we're adding two new",
    "start": "786320",
    "end": "788000"
  },
  {
    "text": "apis uh first of the new distributed",
    "start": "788000",
    "end": "789839"
  },
  {
    "text": "execution dsl that i described",
    "start": "789839",
    "end": "791680"
  },
  {
    "text": "uh in previous slides this is fully",
    "start": "791680",
    "end": "793760"
  },
  {
    "text": "stable and is now the new way to write",
    "start": "793760",
    "end": "795200"
  },
  {
    "text": "distributed arguments in rlib",
    "start": "795200",
    "end": "797600"
  },
  {
    "text": "and we're also adding a new trajectory",
    "start": "797600",
    "end": "800079"
  },
  {
    "text": "view api",
    "start": "800079",
    "end": "800880"
  },
  {
    "text": "that allows um that's going to allow",
    "start": "800880",
    "end": "803440"
  },
  {
    "text": "high performance",
    "start": "803440",
    "end": "804399"
  },
  {
    "text": "models such as transformers and lcms to",
    "start": "804399",
    "end": "808000"
  },
  {
    "text": "work very seamlessly",
    "start": "808000",
    "end": "810959"
  },
  {
    "start": "811000",
    "end": "811000"
  },
  {
    "text": "so in summary rlib is the scalable and",
    "start": "811600",
    "end": "814880"
  },
  {
    "text": "unified rl library",
    "start": "814880",
    "end": "816639"
  },
  {
    "text": "has a number of new capabilities with",
    "start": "816639",
    "end": "818079"
  },
  {
    "text": "rate 1.0 so if you're interested in",
    "start": "818079",
    "end": "820480"
  },
  {
    "text": "using rlab we're",
    "start": "820480",
    "end": "821440"
  },
  {
    "text": "getting involved you can check out our",
    "start": "821440",
    "end": "823120"
  },
  {
    "text": "documentation or slack at our left io",
    "start": "823120",
    "end": "825920"
  },
  {
    "text": "and we're also hiring for rlib and rate",
    "start": "825920",
    "end": "828959"
  },
  {
    "text": "development at any scale",
    "start": "828959",
    "end": "830160"
  },
  {
    "text": "yeah thank you",
    "start": "830160",
    "end": "833759"
  }
]
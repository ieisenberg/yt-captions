[
  {
    "text": "uh hi everyone welcome to my talk uh I'm nikit Agarwal I'm from Nvidia and today I'll talk about our challenges that we",
    "start": "2639",
    "end": "9639"
  },
  {
    "text": "face with Advanced video curation and how we solve that and we leverage Ray extensively so we'll call out where we",
    "start": "9639",
    "end": "15519"
  },
  {
    "text": "used it here's a brief agenda of the talk today uh we'll start off by discussing the scale and the challenges",
    "start": "15519",
    "end": "22160"
  },
  {
    "text": "with video data curation uh I'll talk about the video uh curation architecture that we built and then after curation",
    "start": "22160",
    "end": "28679"
  },
  {
    "text": "also touch upon video standing in intelligence which is required to complete the video model training",
    "start": "28679",
    "end": "34680"
  },
  {
    "text": "flywheel so brief introduction for folks who are not familiar with video models so video Foundation models of vfms is",
    "start": "34680",
    "end": "42000"
  },
  {
    "text": "essentially the new llm uh everyone's trained llms uh are completing training",
    "start": "42000",
    "end": "47480"
  },
  {
    "text": "their llm so there a lot of llms out there right now including open source FES uh as we know text uh there's not",
    "start": "47480",
    "end": "53640"
  },
  {
    "text": "enough text tokens left to train right so whatever number of trillions of tokens that are in the world 30 40",
    "start": "53640",
    "end": "59160"
  },
  {
    "text": "people have kind of saturated them and now most of the companies are working towards multimodel",
    "start": "59160",
    "end": "64720"
  },
  {
    "text": "training which is images and video and audio and things like that right uh however uh working on bfm presents a",
    "start": "64720",
    "end": "71840"
  },
  {
    "text": "different scale of challenges that was not faced by text uh especially around the data curation aspects and I'll cover",
    "start": "71840",
    "end": "77759"
  },
  {
    "text": "that today so before I go deep let's understand what do we mean by data curation here uh I'm showing you the AI",
    "start": "77759",
    "end": "85119"
  },
  {
    "text": "life cycle it starts by taking data curating it in a manner that we can do",
    "start": "85119",
    "end": "90640"
  },
  {
    "text": "training on that data and then once we train a model we do inference on that data uh Nemo is our framework from",
    "start": "90640",
    "end": "97720"
  },
  {
    "text": "envidia to do all the AI life cycle pieces but there's many open source and other uh Solutions out there including",
    "start": "97720",
    "end": "104479"
  },
  {
    "text": "uh any scale Ray as well so what do I mean by uh uh labeling",
    "start": "104479",
    "end": "109680"
  },
  {
    "text": "training data let's start up by an example of what text llms do uh so most of the text llms are NEX word predictors",
    "start": "109680",
    "end": "117439"
  },
  {
    "text": "so if you want to take training data and feed it into a training model typically",
    "start": "117439",
    "end": "123399"
  },
  {
    "text": "what we do is we give them inputs and then sampled outputs and the model learns from that so let's say I'm",
    "start": "123399",
    "end": "128720"
  },
  {
    "text": "reading a Wikipedia article and says the cat sat on the the llm is going to",
    "start": "128720",
    "end": "134040"
  },
  {
    "text": "produce the next word and creating label training data from that is pretty straightforward you just predict the",
    "start": "134040",
    "end": "139920"
  },
  {
    "text": "next word so curating training data for text is relatively straightforward for llms what you do is you read the",
    "start": "139920",
    "end": "146040"
  },
  {
    "text": "sentence and your next word that you read is essentially the next word uh label data for that input right so there",
    "start": "146040",
    "end": "151879"
  },
  {
    "text": "are a lot of solutions that exist for Text data and it's relatively inexpensive to curate because you can",
    "start": "151879",
    "end": "157519"
  },
  {
    "text": "just do it on like CPU machines you don't need large uh form of",
    "start": "157519",
    "end": "162720"
  },
  {
    "text": "gpus now let's think about what label training data is for video models and",
    "start": "162720",
    "end": "168040"
  },
  {
    "text": "what's a video model we are going to feed it videos and it's going to understand what it is about right so",
    "start": "168040",
    "end": "174480"
  },
  {
    "text": "let's say I have just three frames of an input video here can someone guess uh",
    "start": "174480",
    "end": "180640"
  },
  {
    "text": "what the in output for this should be like the label training data how would anyone describe these",
    "start": "180640",
    "end": "187879"
  },
  {
    "text": "three frames",
    "start": "187879",
    "end": "193120"
  },
  {
    "text": "anyone yes a player is shooting a basketball right yeah and it could be more",
    "start": "193120",
    "end": "199239"
  },
  {
    "text": "descriptive as well you can say a basketball player is dribbling the ball and that's shooting into the hoop now",
    "start": "199239",
    "end": "204760"
  },
  {
    "text": "remember we don't know what happened after he shot it right so if you had the next frame and we knew whether it's a basket or not we could add that to the",
    "start": "204760",
    "end": "210840"
  },
  {
    "text": "training data as well but yeah exactly this is what uh creating labeled data for video models is now let's imagine",
    "start": "210840",
    "end": "217920"
  },
  {
    "text": "how you would do it for millions and millions of hours of videos right so let's say we have a 20- minute YouTube",
    "start": "217920",
    "end": "223680"
  },
  {
    "text": "video each set of frames things are changing who is going to label this data",
    "start": "223680",
    "end": "229720"
  },
  {
    "text": "right uh humans cannot do it there's a lot of synthet there's notot of human annotated data sets out there but",
    "start": "229720",
    "end": "235599"
  },
  {
    "text": "they're in like thousands of hours only right there only so much humans can do so so typically what people have started",
    "start": "235599",
    "end": "243000"
  },
  {
    "text": "doing is people have started using AI models to curate data so you can feed it into video Foundation model training",
    "start": "243000",
    "end": "249959"
  },
  {
    "text": "right so we have millions and millions of hours of videos we actually have ai that watches this video so in this case",
    "start": "249959",
    "end": "256840"
  },
  {
    "text": "like we watched those three frames and we described them we actually build vm's Vision language models that are just",
    "start": "256840",
    "end": "263360"
  },
  {
    "text": "good at captioning right the stuff that uh this gentleman just did and then we feed all the videos into that that",
    "start": "263360",
    "end": "270199"
  },
  {
    "text": "creates the label training data set out of it right uh moreover uh we don't want to feed junk or Garbage to our model to",
    "start": "270199",
    "end": "277880"
  },
  {
    "text": "be trained on so garbage in garbage out we want to feed it really high quality data so let's say we watch like an hour",
    "start": "277880",
    "end": "284360"
  },
  {
    "text": "of videos uh that we found in a YouTube or a movie not everything is high quality data right sometimes there's",
    "start": "284360",
    "end": "290400"
  },
  {
    "text": "just the same scene you're watching a tree for 2 minutes uh you don't want to feed those 2 minutes into a model you",
    "start": "290400",
    "end": "295919"
  },
  {
    "text": "actually want to filter really high quality data that is useful for model to get trained on uh this is",
    "start": "295919",
    "end": "301919"
  },
  {
    "text": "computationally very challenging as I will show uh and that's the curation pipeline that we have",
    "start": "301919",
    "end": "307720"
  },
  {
    "text": "built so uh let me start up by a bird's eye view of what a curation pipeline does and then we'll go into more",
    "start": "307720",
    "end": "313120"
  },
  {
    "text": "technical details uh at a very high level what do we do so Nvidia has a cloud platform called dgx Cloud we are",
    "start": "313120",
    "end": "319440"
  },
  {
    "text": "actually on top of every cloud uh on top of that what we built is we built Ray",
    "start": "319440",
    "end": "324560"
  },
  {
    "text": "databased streaming pipelines it's running on thousands of gpus I will show why we need them",
    "start": "324560",
    "end": "330319"
  },
  {
    "text": "uh we leveraging Cloud native Solutions and then let's walk through what our AI pipeline is doing so I'll give you an",
    "start": "330319",
    "end": "336919"
  },
  {
    "text": "example where let's say you have a long video and these are small segments out of that video so the first segment could",
    "start": "336919",
    "end": "343000"
  },
  {
    "text": "be just zooming onto a motorcycle then someone's driving them under a bridge and then that person is driving it over",
    "start": "343000",
    "end": "349639"
  },
  {
    "text": "a bridge right so the first step is we have a set of AIS that goes and finds",
    "start": "349639",
    "end": "355280"
  },
  {
    "text": "out which are the semantically relevant frames so we go and check when frames",
    "start": "355280",
    "end": "360680"
  },
  {
    "text": "have uh shifted the uh view in the particular uh video so in this particular case the AI will watch this",
    "start": "360680",
    "end": "367160"
  },
  {
    "text": "and find out that we have these first these three frames uh which are semantically relevant and they're",
    "start": "367160",
    "end": "372479"
  },
  {
    "text": "different than the other frames in the clips right so we find these clips we call them splitting so we split the long",
    "start": "372479",
    "end": "379120"
  },
  {
    "text": "video into smaller Clips we transcod them because we have to feed it to Downstream stages so we want uh",
    "start": "379120",
    "end": "384639"
  },
  {
    "text": "everything to be consistent and we got these small short clips after that stage",
    "start": "384639",
    "end": "390000"
  },
  {
    "text": "then we want high quality data as I said we don't want things that are you know I don't know PowerPoint presentation is",
    "start": "390000",
    "end": "395639"
  },
  {
    "text": "not a great uh thing to learn from uh if we want to do motion Vector scoring and so on so as I said if you have a static",
    "start": "395639",
    "end": "401960"
  },
  {
    "text": "tree and a 1H hour video you don't want to feed all of that to your video model it's very kind of computationally uh",
    "start": "401960",
    "end": "408280"
  },
  {
    "text": "useless right so we run filtering algorithms to find out high quality videos and clips that we should be",
    "start": "408280",
    "end": "414319"
  },
  {
    "text": "training on so we have a bunch of AI models that watch that and finally we use a vision language model model as I",
    "start": "414319",
    "end": "420000"
  },
  {
    "text": "was saying and it's trained an expert in captioning short clips right so that AI",
    "start": "420000",
    "end": "425840"
  },
  {
    "text": "vlm is going to watch this video uh and then transcribe something like the",
    "start": "425840",
    "end": "430960"
  },
  {
    "text": "person is riding a black car lead of its an fat boy motorcycle on a city street that's what the model is going to spit",
    "start": "430960",
    "end": "437840"
  },
  {
    "text": "out and finally what did we get we got a small set of Clips we got their captions",
    "start": "437840",
    "end": "443440"
  },
  {
    "text": "and we create a data set then we can feed into a training model to go and train on right so this a very simplistic",
    "start": "443440",
    "end": "450080"
  },
  {
    "text": "view of the pipeline functional view of the pipeline that we have built all of these stages and models are",
    "start": "450080",
    "end": "456560"
  },
  {
    "text": "accelerated on gpus we had to do it because of the computational nature of the models we are running uh and I'll",
    "start": "456560",
    "end": "462840"
  },
  {
    "text": "talk about how we ended up doing that okay so let's zoom in what does the video processing pipeline look like I'm",
    "start": "462840",
    "end": "470000"
  },
  {
    "text": "highlighting some of the stages I talked about splitting and transcoding I talked about quality filtering there's",
    "start": "470000",
    "end": "475080"
  },
  {
    "text": "annotation which is the VM part then we also do a bunch of things to make the model training data better I'll talk",
    "start": "475080",
    "end": "482240"
  },
  {
    "text": "about them as well and all of them are GPU accelerated and finally we create uh data sets for training this entire",
    "start": "482240",
    "end": "489400"
  },
  {
    "text": "pipeline has been built to process more than 100 petabyte of data and after filtering we reduce it to tens of",
    "start": "489400",
    "end": "496159"
  },
  {
    "text": "petabyte so we throw away a lot of garbage from the videos that we find so what are some of the challenges",
    "start": "496159",
    "end": "502879"
  },
  {
    "text": "in uh video curation one is of course scale uh training data of for text is",
    "start": "502879",
    "end": "508919"
  },
  {
    "text": "terabyte right tens of terabytes hundreds of terabytes it's very limited videos happens to be much much larger in",
    "start": "508919",
    "end": "514800"
  },
  {
    "text": "scale way larger than images too so the data scale is 10 to 100 times of even image training data sets that we find",
    "start": "514800",
    "end": "522240"
  },
  {
    "text": "data set orchestration so like training which is a distributed training job our",
    "start": "522240",
    "end": "528080"
  },
  {
    "text": "data curation has now become a distributed GPU job itself it's batch inference running on many many gpus",
    "start": "528080",
    "end": "534680"
  },
  {
    "text": "together so orchestrating these AI models and then running them efficiently becomes a challenge I will talk about in",
    "start": "534680",
    "end": "540920"
  },
  {
    "text": "a bit of how we make it efficient job failures for anyone who's worked on large scale GPU uh infrastructure and",
    "start": "540920",
    "end": "548360"
  },
  {
    "text": "processing you know jobs fail you need to restart them imagine curating 10",
    "start": "548360",
    "end": "553440"
  },
  {
    "text": "hours of videos and after like 23 hours your job crashes you don't want to start from the beginning so stuff that people",
    "start": "553440",
    "end": "559600"
  },
  {
    "text": "do for large scale training around checkpoint restart we had to build it in this pipeline because jobs fail right uh",
    "start": "559600",
    "end": "565760"
  },
  {
    "text": "we also needed full stack expertise this is not uh solving one part of the puzzle you need to understand how data is",
    "start": "565760",
    "end": "572240"
  },
  {
    "text": "stored and in the right format how do you read it efficiently how do you orchestrate GPU models how do you make",
    "start": "572240",
    "end": "578720"
  },
  {
    "text": "it efficient and so on so it's a full stack problem uh and hopefully I'll kind of convince you at the the talk that",
    "start": "578720",
    "end": "584200"
  },
  {
    "text": "yeah this is complicated okay so what did we build to solve this we built a configurable and",
    "start": "584200",
    "end": "590000"
  },
  {
    "text": "modular data curation pipeline videos come in and very high quality training",
    "start": "590000",
    "end": "595440"
  },
  {
    "text": "data sets come out what is a trainable data set typically they clips of MP4s",
    "start": "595440",
    "end": "600880"
  },
  {
    "text": "these are clips that we find for each clip typically you'll either have a text caption some models need text or video",
    "start": "600880",
    "end": "607079"
  },
  {
    "text": "embeddings so we'll supplement them as well and this trainable data set goes out from our curation",
    "start": "607079",
    "end": "612480"
  },
  {
    "text": "pipeline some of the unique things we had to do uh and that's why I use the way uh word configurable is creating",
    "start": "612480",
    "end": "620440"
  },
  {
    "text": "curation data data curation for video models is actually an iterative process this is not a solved problem every month",
    "start": "620440",
    "end": "627760"
  },
  {
    "text": "every week There's a new language model for annotation that comes out and we figured that you know we should try it",
    "start": "627760",
    "end": "633120"
  },
  {
    "text": "out we get better caption and we want to evolve our pipeline so do you want to redo all those stages that I showed and",
    "start": "633120",
    "end": "639399"
  },
  {
    "text": "create a new data set out of it no right we've already figured out after filtering which are good Clips so we",
    "start": "639399",
    "end": "645000"
  },
  {
    "text": "just update the captioning model and create a new data set with it so all of these configurability had to be built",
    "start": "645000",
    "end": "650480"
  },
  {
    "text": "into the pipeline so we're not starting from scratch all the time okay and some",
    "start": "650480",
    "end": "656320"
  },
  {
    "text": "statistics we are uh curating millions of hours of videos every week for our research models that are being produced",
    "start": "656320",
    "end": "662680"
  },
  {
    "text": "and they're running them on thousands of gpus so this is a light pipeline working for months and months uh seeing live",
    "start": "662680",
    "end": "668480"
  },
  {
    "text": "traffic and uh scaling okay so then I'll go into I have kind of talked a lot about why this is",
    "start": "668480",
    "end": "674760"
  },
  {
    "text": "complex let's go and look at some data so this is an architectural diagram",
    "start": "674760",
    "end": "679800"
  },
  {
    "text": "of the curation pipeline we have built the way this entire pipeline starts is",
    "start": "679800",
    "end": "685240"
  },
  {
    "text": "uh we start with S3 compliant storage Stacks like AWS uh S3 of uh GCS that's",
    "start": "685240",
    "end": "690800"
  },
  {
    "text": "where the videos are petabytes and petabytes of videos the first step and again all of this thing is built on top",
    "start": "690800",
    "end": "697040"
  },
  {
    "text": "of Ray data so each of these pipelines are set of Ray stages so the first step",
    "start": "697040",
    "end": "702360"
  },
  {
    "text": "we do is we take an input uh set of videos and we let them through splitting and transcoding so as I was describing",
    "start": "702360",
    "end": "709519"
  },
  {
    "text": "uh AIS watch the videos and they find small clips that are semantically relevant we transcod them and then we",
    "start": "709519",
    "end": "715519"
  },
  {
    "text": "store them back to storage then what do we do we found good Clips we run them through a bunch of AI",
    "start": "715519",
    "end": "722040"
  },
  {
    "text": "models so you can see these are again five Ray stages that this video clips will go through each of them is a model",
    "start": "722040",
    "end": "728480"
  },
  {
    "text": "so in this particular example we are running seven ml models that the videos will go through as part of the same job",
    "start": "728480",
    "end": "735199"
  },
  {
    "text": "okay uh the third step is we find there's a lot of duplicate data sometimes within a video and a lot of",
    "start": "735199",
    "end": "741760"
  },
  {
    "text": "times across vide so if you have a popular basketball match or a movie trailer or something like that it's the",
    "start": "741760",
    "end": "747079"
  },
  {
    "text": "same set of video all the time you don't want to uh over index on the same amount of data right uh so we do a lot of",
    "start": "747079",
    "end": "753639"
  },
  {
    "text": "semantic dup D duplication as well and that's also uh distributed GPU job I'll talk about that uh finally we create",
    "start": "753639",
    "end": "760800"
  },
  {
    "text": "these data sets and then upload them back to S3 uh note like you'll see this green",
    "start": "760800",
    "end": "766760"
  },
  {
    "text": "box here which is GPU accelerated all of these stages except reading from storage",
    "start": "766760",
    "end": "772199"
  },
  {
    "text": "and writing to storage or n to n GPU accelerated so we use state-of-the-art acceleration algorithms to do that",
    "start": "772199",
    "end": "780600"
  },
  {
    "text": "so I've talked about thousands of gpus for a lot of time let's look at like how we made this pipeline effis so when we",
    "start": "780600",
    "end": "785760"
  },
  {
    "text": "buil this Pipeline on Day Zero and we did the math and for a mission we needed roughly 1 million hours of video to go",
    "start": "785760",
    "end": "791959"
  },
  {
    "text": "through this pipeline every day that was kind of the estimation we uh did to make our research model successful right uh",
    "start": "791959",
    "end": "799040"
  },
  {
    "text": "we procured gpus we built this Pipeline and we needed around 10,000 gpus to do",
    "start": "799040",
    "end": "804240"
  },
  {
    "text": "this job every day right it's a lot of gpus as you know and they don't come easily",
    "start": "804240",
    "end": "810199"
  },
  {
    "text": "so the first thing we did is we found out that uh we need to accelerate each of the models so they're running most",
    "start": "810199",
    "end": "816800"
  },
  {
    "text": "efficiently it's not enough to just put them on the GPU as you know uh inference is a computationally expensive task but",
    "start": "816800",
    "end": "823079"
  },
  {
    "text": "there's a lot of known ways in which you can makeing uh faster so we took the Baseline so this chart is showing for",
    "start": "823079",
    "end": "829120"
  },
  {
    "text": "our VM which was 70% of the pipeline right 70% of the runtime was going in",
    "start": "829120",
    "end": "834279"
  },
  {
    "text": "that stage because it was very computationally expensive it's a big llm that runs inside that VM",
    "start": "834279",
    "end": "840040"
  },
  {
    "text": "so y- axis is normalized throughput Baseline is when we started and then we started doing efficiency on top so we",
    "start": "840040",
    "end": "846480"
  },
  {
    "text": "started with one we did trt llm this is a known way of accelerating like uh uh",
    "start": "846480",
    "end": "851639"
  },
  {
    "text": "llm models it gave us about 2x throughput then we did more memory optimizations to reduce the memory on",
    "start": "851639",
    "end": "858040"
  },
  {
    "text": "the same GPU and increase the bath size we got more speed up we did fp8 quantization we did uh uh quality",
    "start": "858040",
    "end": "865120"
  },
  {
    "text": "studies and we find it's fine for the quality that we needed and we are at about 7x speed up of just that model and",
    "start": "865120",
    "end": "872880"
  },
  {
    "text": "it was 70% of the pipeline so we got 7x speed up reduction uh of that",
    "start": "872880",
    "end": "878480"
  },
  {
    "text": "70% we've also done speed of light performance estimations and speed of light is an Nvidia term where we used to",
    "start": "878480",
    "end": "884680"
  },
  {
    "text": "understand unconstrained what should a particular software uh speed is on a particular hardware and it's about 11x",
    "start": "884680",
    "end": "891639"
  },
  {
    "text": "so we know the gaps from today all the way to what it take us to get to speed of light and we're working on that",
    "start": "891639",
    "end": "899839"
  },
  {
    "text": "next so that was one model so we take each model accelerate on the GPU now except AI models we also do these are",
    "start": "899839",
    "end": "906720"
  },
  {
    "text": "videos we do a lot of decoding and encoding as part of the pipeline every time you want to do processing on a",
    "start": "906720",
    "end": "912560"
  },
  {
    "text": "video it's all compressed right h264 other formats you decompress it it's if",
    "start": "912560",
    "end": "918240"
  },
  {
    "text": "you do it on the CPU it's very inefficient uh Nvidia gpus have hardware encoders and decoders and we leverage",
    "start": "918240",
    "end": "924959"
  },
  {
    "text": "them so the top part shows our splitting and transcoding pipeline where the green ones are things that run on the GPU and",
    "start": "924959",
    "end": "931199"
  },
  {
    "text": "the white ones are that are don't so we moved all the decode and encoding stages to the GPU and then uh did the same",
    "start": "931199",
    "end": "937880"
  },
  {
    "text": "acceleration on it and we got 3x speed up of this particular pipeline just by going onto the gpus right so uh use uh",
    "start": "937880",
    "end": "946279"
  },
  {
    "text": "gpus for decoding and encoding and this is the third and interesting thing that you only see when you run what's called",
    "start": "946279",
    "end": "951920"
  },
  {
    "text": "like hetrogeneous batch inference pipelines so I'll give you an example so",
    "start": "951920",
    "end": "957360"
  },
  {
    "text": "if you look at the left side uh of this particular chart I'm showing a cartoon example of three stages so imagine like",
    "start": "957360",
    "end": "965000"
  },
  {
    "text": "splitting stitching transcoding just three stages that are running each of them is running on one GPU each for",
    "start": "965000",
    "end": "972040"
  },
  {
    "text": "example and they're running at different speeds meaning the first one can do four videos a second the second one can only",
    "start": "972040",
    "end": "978720"
  },
  {
    "text": "do one video a second and the third one can do two videos a second so what ends up happening even though we build",
    "start": "978720",
    "end": "984199"
  },
  {
    "text": "streaming and we use Ray streaming uh most of the time for the second stage we this GPU is Idle because one of the",
    "start": "984199",
    "end": "990759"
  },
  {
    "text": "stage cannot feed it data fast enough right how do you solve it because you let's say this is the speed of light you",
    "start": "990759",
    "end": "996920"
  },
  {
    "text": "cannot run it faster on a GPU you give more gpus to that second stage and third stage right so what we do is we build",
    "start": "996920",
    "end": "1004639"
  },
  {
    "text": "this Auto balancing as part of our pipeline where we measure the throughput of each stage and then we realize that",
    "start": "1004639",
    "end": "1010519"
  },
  {
    "text": "if some stage needs more gpus we run more copies of that stage right we spin up more reactors for people who are",
    "start": "1010519",
    "end": "1016639"
  },
  {
    "text": "familiar with Ray we spin up more reactors for those slow stages and then finally we get a balanced pipeline right",
    "start": "1016639",
    "end": "1022399"
  },
  {
    "text": "so in this example uh if you went from 3 gpus to 7 gpus we get 1.7x Improvement",
    "start": "1022399",
    "end": "1028640"
  },
  {
    "text": "of the throughput right so that's what we",
    "start": "1028640",
    "end": "1032839"
  },
  {
    "text": "get okay uh so this is example of batch inference",
    "start": "1033799",
    "end": "1039280"
  },
  {
    "text": "and heterogeneous pipelines this is what we do finally we've gotten about 3 and a half X speed up over the last few months",
    "start": "1039280",
    "end": "1045640"
  },
  {
    "text": "that we've been working on this and so GPU demands have gone down we have further 2x efficiency that we",
    "start": "1045640",
    "end": "1052000"
  },
  {
    "text": "have found and we working on so this requirement will go down even further uh 3,000 GP us is still a",
    "start": "1052000",
    "end": "1058320"
  },
  {
    "text": "lot so that's the data curation aspect which is mostly about filtering and then",
    "start": "1058320",
    "end": "1063440"
  },
  {
    "text": "captioning the model so you can train just training a model is not enough uh",
    "start": "1063440",
    "end": "1068760"
  },
  {
    "text": "or just curating data is not enough to train a foundation Model A lot of things that we need is sometimes domain",
    "start": "1068760",
    "end": "1074919"
  },
  {
    "text": "specific training so you might be training let's say an avatar model which wants which has humans who are talking",
    "start": "1074919",
    "end": "1081919"
  },
  {
    "text": "so you might want to fine tune the video model on a lot of lot of videos that have people talking like talk show host",
    "start": "1081919",
    "end": "1087880"
  },
  {
    "text": "and things like that so you need to find videos that are specific to a particular domain how do you do that right uh D",
    "start": "1087880",
    "end": "1094520"
  },
  {
    "text": "duplication I talked about we want to do D duplication it's not just curation it's understanding what videos are",
    "start": "1094520",
    "end": "1100000"
  },
  {
    "text": "similar right uh that's a task for AI and also sometimes into debug a models now this is very interesting once I'll",
    "start": "1100000",
    "end": "1106559"
  },
  {
    "text": "show an example of how we debug a models as well there's other use cases so let's walk through the rest of the pipeline so",
    "start": "1106559",
    "end": "1113600"
  },
  {
    "text": "so so far I've covered dividing long videos into small shorts filtering them and then captioning them let's now go to",
    "start": "1113600",
    "end": "1120679"
  },
  {
    "text": "D duplication so again remember we have billions of Clips how do you DD them uh",
    "start": "1120679",
    "end": "1125880"
  },
  {
    "text": "it's computationally impossible to do it on billions of Clips uh all doing semantic search so first thing we do is",
    "start": "1125880",
    "end": "1132080"
  },
  {
    "text": "to reduce the state space is we clustered them so remember we have video embeddings for each of these videos we",
    "start": "1132080",
    "end": "1138840"
  },
  {
    "text": "cluster the embeddings using Vector search to things that are close to each other and we form these clusters so all",
    "start": "1138840",
    "end": "1144799"
  },
  {
    "text": "these videos were there and then we found basically six clusters of videos from the example this is a cartoon example okay and you can squint and see",
    "start": "1144799",
    "end": "1151760"
  },
  {
    "text": "the videos here are similar to each other right then we find videos from them",
    "start": "1151760",
    "end": "1158440"
  },
  {
    "text": "which are semantically identied right so the second one and the fifth one you can see is the same gentleman doing the same",
    "start": "1158440",
    "end": "1165200"
  },
  {
    "text": "thing right so uh semantically identical we don't need to retrain them so we throw away uh duplicated data right uh",
    "start": "1165200",
    "end": "1172840"
  },
  {
    "text": "that's how you do semantic D duplication again everything is GPU accelerated the third thing which is",
    "start": "1172840",
    "end": "1178240"
  },
  {
    "text": "very interesting I told you right like you need to find domain specific data sometimes how do you do it uh there's",
    "start": "1178240",
    "end": "1184360"
  },
  {
    "text": "not enough AI sometimes who can do it so we use manual annotation so billions of",
    "start": "1184360",
    "end": "1190000"
  },
  {
    "text": "Clips is impossible for humans to look at but thousands of them is so we create",
    "start": "1190000",
    "end": "1195240"
  },
  {
    "text": "these clusters and we have humans go and look at some of these centroids manual and then label the data so all of these",
    "start": "1195240",
    "end": "1202000"
  },
  {
    "text": "things a human can go and say that yeah this particular cluster is good for biking videos this is for cutting this",
    "start": "1202000",
    "end": "1208120"
  },
  {
    "text": "for drone so on and so forth we can even M Mark things as okay if you're training a physical world model then these right",
    "start": "1208120",
    "end": "1215600"
  },
  {
    "text": "side videos are not good at so this is something we do and it feeds into the data Pipeline and we have more uh that I will",
    "start": "1215600",
    "end": "1222919"
  },
  {
    "text": "talk about today finally video understanding",
    "start": "1222919",
    "end": "1228840"
  },
  {
    "text": "so through this uh journey of 6 months what we've realized is you can have great Ambitions you can try to create",
    "start": "1228840",
    "end": "1235000"
  },
  {
    "text": "great data but the first time you go and query the model that comes out it's very disappointing it produces really",
    "start": "1235000",
    "end": "1240960"
  },
  {
    "text": "horrible videos okay so then the journey starts is okay I had high expectations what do I do when the videos aren't good",
    "start": "1240960",
    "end": "1248080"
  },
  {
    "text": "right uh you do all of that and then you realize it's still not great enough so let's say we have a video model we say",
    "start": "1248080",
    "end": "1254480"
  },
  {
    "text": "make a video of a man dribbling a basketball and scoring a basket right remember I showed you that example so we",
    "start": "1254480",
    "end": "1259799"
  },
  {
    "text": "ask our generation model to go and create that video and this is what it's creating okay so clearly not a man uh",
    "start": "1259799",
    "end": "1268880"
  },
  {
    "text": "but it got rest of the stuff right right uh so what do you do if you have this video all right we are puzzled like okay",
    "start": "1268880",
    "end": "1275200"
  },
  {
    "text": "do I look at the parameters look I look at the weights I have billions of Clips what do I do with them right so very",
    "start": "1275200",
    "end": "1280400"
  },
  {
    "text": "hard problem you solve them through video understanding we want to understand what videos have we trained",
    "start": "1280400",
    "end": "1285760"
  },
  {
    "text": "on right so the puzzle we have is why did the model produce a cat and not a man right very puzzling is the model",
    "start": "1285760",
    "end": "1292880"
  },
  {
    "text": "wrong or the data wrong let's go and understand that so first thing is right this is a easier example but let's see",
    "start": "1292880",
    "end": "1298600"
  },
  {
    "text": "if we have videos of man right in our data set uh we have videos of man playing basketball right how do you do",
    "start": "1298600",
    "end": "1305840"
  },
  {
    "text": "that this is a well-known technique people are building a lot of rag pipelines on this it's called visual search where you take your videos you",
    "start": "1305840",
    "end": "1312960"
  },
  {
    "text": "pass it through a video curator you create video embeddings out of them and",
    "start": "1312960",
    "end": "1318080"
  },
  {
    "text": "you build bu a search engine you pass it the text it creates the text embedding",
    "start": "1318080",
    "end": "1323760"
  },
  {
    "text": "and then searches through a vector database it's all known things that people are doing but what we did is we stitched it together so this is a toy",
    "start": "1323760",
    "end": "1331039"
  },
  {
    "text": "example uh hopefully the text is clear I'll walk you them what okay so we have the database we'll search for man",
    "start": "1331039",
    "end": "1337760"
  },
  {
    "text": "playing basketball right uh so you can see this is not a great video so if we all had this then the model will of",
    "start": "1337760",
    "end": "1343520"
  },
  {
    "text": "course complain but we have some good videos of men playing basketball so this",
    "start": "1343520",
    "end": "1348559"
  },
  {
    "text": "not generation we just going and looking at the data set if you have videos like that if you're interested in other stuff",
    "start": "1348559",
    "end": "1354720"
  },
  {
    "text": "like cats running behind bus we can go and do that as well right so we built",
    "start": "1354720",
    "end": "1359760"
  },
  {
    "text": "like a visual search engine we look creates embeddings and search as our database the other interesting thing is",
    "start": "1359760",
    "end": "1366559"
  },
  {
    "text": "uh I'll show you in a second this Tool uh because we used a",
    "start": "1366559",
    "end": "1371679"
  },
  {
    "text": "multimodel uh embedding model it can also search similar videos so let's say I have a video which is this beautiful",
    "start": "1371679",
    "end": "1379360"
  },
  {
    "text": "video 5sec leaves and raining uh in the background and you want to find which",
    "start": "1379360",
    "end": "1384520"
  },
  {
    "text": "are the videos that was similar to this that led to this you can go and upload the video to the search engine it'll",
    "start": "1384520",
    "end": "1391120"
  },
  {
    "text": "create video embeddings and then do semantic search of the videos as well so yeah you're going to see quickly we",
    "start": "1391120",
    "end": "1396720"
  },
  {
    "text": "uploaded I think uh it's now doing embeddings of that video and you got the",
    "start": "1396720",
    "end": "1401880"
  },
  {
    "text": "data set so this is input data set and that was the output of our model so you can go and kind of understand which",
    "start": "1401880",
    "end": "1407640"
  },
  {
    "text": "videos led to the model that we produced also okay so finally uh I think the takeaway",
    "start": "1407640",
    "end": "1414480"
  },
  {
    "text": "from the talk uh hopefully it's clear now this is a hard problem uh and uh you guys need gpus for it right so uh that",
    "start": "1414480",
    "end": "1422279"
  },
  {
    "text": "is clear from the talk uh the things that we did for this curation pipeline was scaling it for a lot of data",
    "start": "1422279",
    "end": "1428200"
  },
  {
    "text": "optimizing the performance of each of these stages in the end to end pipeline as well as making it resilient and",
    "start": "1428200",
    "end": "1433679"
  },
  {
    "text": "configurable that's the stuff we had to do for our internal research effort to make our video model successful and of",
    "start": "1433679",
    "end": "1440320"
  },
  {
    "text": "course uh at Nvidia we build these Technologies so we can help everyone do the same work and more so if you're",
    "start": "1440320",
    "end": "1445960"
  },
  {
    "text": "facing similar challenges in multimodel training and data set curation please reach out to us a bunch of us are here",
    "start": "1445960",
    "end": "1451880"
  },
  {
    "text": "uh who are working on this project so we'll be happy to kind of chat about your problems okay and I have a few minutes for questions thank",
    "start": "1451880",
    "end": "1460100"
  },
  {
    "text": "[Applause]",
    "start": "1460100",
    "end": "1465440"
  },
  {
    "text": "you thank you very much for presentation so my question is how you tackle the bias in the video generation how do you",
    "start": "1465440",
    "end": "1473440"
  },
  {
    "text": "tackle the bias yeah yeah so again I will pretend that I'm a systems person",
    "start": "1473440",
    "end": "1479919"
  },
  {
    "text": "right I'm not an AI person so I'm going to represent what I have heard from a model people the question is how do you tackle bias uh again like what I hear",
    "start": "1479919",
    "end": "1487520"
  },
  {
    "text": "from our leading researchers it's it's all about data right uh there's a term that are kind of lead researcher mingu",
    "start": "1487520",
    "end": "1494200"
  },
  {
    "text": "users is data is the ceiling for a model most of these models are very similar like the papers are out there for llms",
    "start": "1494200",
    "end": "1501480"
  },
  {
    "text": "for diffusion Transformers right uh for auto regressive video models all these papers out there most people are kind of",
    "start": "1501480",
    "end": "1507600"
  },
  {
    "text": "looking at them and building models whereas finding the right data to not just train the model but then F tune and",
    "start": "1507600",
    "end": "1513320"
  },
  {
    "text": "correct it is the hardest problem and that's why we've been very hard so if you ask me how many people at Nvidia are",
    "start": "1513320",
    "end": "1519480"
  },
  {
    "text": "working on this as part of the video model project versus training the model it's probably 3 is to one more people",
    "start": "1519480",
    "end": "1525520"
  },
  {
    "text": "are working on data curation than training the video model model because this is the hard part right uh so yeah I",
    "start": "1525520",
    "end": "1531240"
  },
  {
    "text": "think we do it by curating a lot of data understanding them and then the researchers can go and debug if there is",
    "start": "1531240",
    "end": "1537279"
  },
  {
    "text": "bias we see then we go and kind of figure out why it's happening so there are more manual efforts needed than yeah",
    "start": "1537279",
    "end": "1543880"
  },
  {
    "text": "I think there's again this is outside my wheelhouse there's a lot of guard rails and things like that so there standard benchmarks people run to figure out",
    "start": "1543880",
    "end": "1550399"
  },
  {
    "text": "what's happening uh the other thing uh I have heard people do is we show diversity of videos to the model the",
    "start": "1550399",
    "end": "1556440"
  },
  {
    "text": "more diverse you show that's what D duplication helps you're not showing the same thing again and again uh that helps",
    "start": "1556440",
    "end": "1562360"
  },
  {
    "text": "the model also get better yeah thank",
    "start": "1562360",
    "end": "1566720"
  },
  {
    "text": "you",
    "start": "1567760",
    "end": "1570760"
  },
  {
    "text": "yeah uh thank you very much very interesting talk I was just curious uh",
    "start": "1573799",
    "end": "1578840"
  },
  {
    "text": "what your source of data is like where are you getting the videos that you're using foration great question uh so uh",
    "start": "1578840",
    "end": "1585559"
  },
  {
    "text": "it's a very interesting area so most of them our licensed data so we take a lot of precaution in making sure the data we",
    "start": "1585559",
    "end": "1592600"
  },
  {
    "text": "get are ethically sourced legal and then licensable so we follow all those practices uh so that's what we",
    "start": "1592600",
    "end": "1601158"
  },
  {
    "text": "do thank you for the um talk so in the beginning you were um I saw in one of",
    "start": "1602360",
    "end": "1608320"
  },
  {
    "text": "the slides you had like fp8 for accuracy was there a reason and can you talk",
    "start": "1608320",
    "end": "1614279"
  },
  {
    "text": "about the accuracy of the you know this generation yeah so I think the question",
    "start": "1614279",
    "end": "1619640"
  },
  {
    "text": "is can we talk about the fp8 quantization right uh so this is usually a uh kind of fine balance between",
    "start": "1619640",
    "end": "1626440"
  },
  {
    "text": "performance and uh the and the performance people sometimes like the model people use performance as accuracy",
    "start": "1626440",
    "end": "1632600"
  },
  {
    "text": "as well so the model performance which is the accuracy as opposed to the infrastructure performance which is speed uh so luckily for VMS there's a",
    "start": "1632600",
    "end": "1639279"
  },
  {
    "text": "lot of standard benchmarks you can use to figure out because it's been more mature than bfms whether the accuracy",
    "start": "1639279",
    "end": "1645399"
  },
  {
    "text": "regressed or not so we use standard benchmarks to figure out when we went to fp6 to fp8 and you can see we got like",
    "start": "1645399",
    "end": "1651640"
  },
  {
    "text": "1.5 plus XP up so it was clearly worth it so we ran standard benchmarks to convince ourself it's uh still giving us",
    "start": "1651640",
    "end": "1657480"
  },
  {
    "text": "the accuracy we want and there's new VMS coming all the time so we again go with those standard benchmarks to figure out",
    "start": "1657480",
    "end": "1663440"
  },
  {
    "text": "if we should change I had uh two questions actually",
    "start": "1663440",
    "end": "1670440"
  },
  {
    "text": "one was uh do you do this same um optimization for every time you're",
    "start": "1670440",
    "end": "1676840"
  },
  {
    "text": "updating your BLM and you said you're doing this every month so sorry can we",
    "start": "1676840",
    "end": "1681880"
  },
  {
    "text": "speak up like you uh would you be doing this optimization every month whenever a new VM uh comes in yeah so great",
    "start": "1681880",
    "end": "1689720"
  },
  {
    "text": "question do we yeah do we do this optimization every time there's a new VM so uh the great news is uh this is a",
    "start": "1689720",
    "end": "1696440"
  },
  {
    "text": "industry standard problem there's a lot of in people who are doing inference and there's infrastructure out there so you",
    "start": "1696440",
    "end": "1702240"
  },
  {
    "text": "look at this trt llm thing uh so there's lot of trt models out there lot of llm",
    "start": "1702240",
    "end": "1707880"
  },
  {
    "text": "models models out there so Nvidia has something called tensor RT llm it's a framework actually to optimize inference",
    "start": "1707880",
    "end": "1715120"
  },
  {
    "text": "model so we Leverage The Frameworks to do it we don't manually do it so the way that thing is work working is and if",
    "start": "1715120",
    "end": "1721519"
  },
  {
    "text": "you've heard of Nims which is NVIDIA inference microservices what we do is pytorch model in and an optimized engine",
    "start": "1721519",
    "end": "1727519"
  },
  {
    "text": "out right so we have something called a Nim factory pytorch models go in and from",
    "start": "1727519",
    "end": "1732799"
  },
  {
    "text": "the factory something comes out now some of the things around uh memory optimization and other things for this",
    "start": "1732799",
    "end": "1738880"
  },
  {
    "text": "model we had to manually tune it we had to kind of do a bunch of things manually but it's a journey we want the factory",
    "start": "1738880",
    "end": "1745000"
  },
  {
    "text": "to give us the most efficient model so we don't redo it ourselves but yes we redo it for every model that we",
    "start": "1745000",
    "end": "1750880"
  },
  {
    "text": "get uh the other question that I had is what has your experience been when you",
    "start": "1750880",
    "end": "1756720"
  },
  {
    "text": "generated the Clusters on U visual or video embeddings mhm uh did those",
    "start": "1756720",
    "end": "1763919"
  },
  {
    "text": "semantically similar videos actually represent like the same activity or the",
    "start": "1763919",
    "end": "1770039"
  },
  {
    "text": "same uh semantic mean yeah so great question question is like uh how good is",
    "start": "1770039",
    "end": "1775159"
  },
  {
    "text": "our video embedding models right so the examples I gave you were from the actual model right so it's a internal database",
    "start": "1775159",
    "end": "1781399"
  },
  {
    "text": "we are talking to it and they are actual ones so we did again there standard benchmarks around it we evaluated a",
    "start": "1781399",
    "end": "1786679"
  },
  {
    "text": "number of them and we picked the best that's out there uh and uh it's giving us pretty good result so we're able to",
    "start": "1786679",
    "end": "1792840"
  },
  {
    "text": "debug a lot of these things using our embedding model today",
    "start": "1792840",
    "end": "1798279"
  },
  {
    "text": "I think there's also question there at the end yeah but after you yeah I know Nvidia does a lot of simulation work um",
    "start": "1799760",
    "end": "1806600"
  },
  {
    "text": "is the goal for you guys with this eventually to use a vision model",
    "start": "1806600",
    "end": "1814080"
  },
  {
    "text": "for uh World simulation yeah and what are your thoughts on that generally yeah",
    "start": "1814080",
    "end": "1819720"
  },
  {
    "text": "so uh there is as you can I'll answer that generically right I don't want to talk about product plans but yeah Nvidia",
    "start": "1819720",
    "end": "1826200"
  },
  {
    "text": "does a lot of simulation we do a lot of graphic uh everything has videos in them and our",
    "start": "1826200",
    "end": "1831279"
  },
  {
    "text": "hope is this can help all those efforts as well so we are trying to build models that will help all of those efforts a",
    "start": "1831279",
    "end": "1837240"
  },
  {
    "text": "lot of them is early research so depending on how good we get there it might or might not go into",
    "start": "1837240",
    "end": "1842840"
  },
  {
    "text": "products yeah hi from your ex colleague so uh you mentioned that you",
    "start": "1842840",
    "end": "1849679"
  },
  {
    "text": "use radar data how easy was the sharding to get right was it automatically",
    "start": "1849679",
    "end": "1854760"
  },
  {
    "text": "sharded did you hit any moms or imbalances when with video because very few people have really shared",
    "start": "1854760",
    "end": "1861080"
  },
  {
    "text": "experiences right so that's a great question so let me kind of show you this example right uh so question is like how",
    "start": "1861080",
    "end": "1866840"
  },
  {
    "text": "good was Ray data sharding and uh how much did we have to do it so we've been using gray uh for a couple of years so",
    "start": "1866840",
    "end": "1872919"
  },
  {
    "text": "we had a lot of maturity right from our image models going to video models so we didn't start from scratch right so the",
    "start": "1872919",
    "end": "1878320"
  },
  {
    "text": "same team developed it we had to do a lot of things around orchestration for videos that because it's paby scale uh",
    "start": "1878320",
    "end": "1884639"
  },
  {
    "text": "this technique of measuring application Level through put and then spinning up Auto balancing of the actors was done at",
    "start": "1884639",
    "end": "1891440"
  },
  {
    "text": "the application layer and not at the ray layer and you can imagine that right A lot of people do application Level load",
    "start": "1891440",
    "end": "1897799"
  },
  {
    "text": "balancing as opposed to like CPU level load balancing is the same analogy right you can get uh CPUs have this",
    "start": "1897799",
    "end": "1903440"
  },
  {
    "text": "instruction per cycle right you can have the same IPC but way different performance so a lower level uh uh",
    "start": "1903440",
    "end": "1911480"
  },
  {
    "text": "metric cannot capture the application Level throughput so what we found here is measuring the stage throughput in",
    "start": "1911480",
    "end": "1916880"
  },
  {
    "text": "terms of videos per second right or Video hours per second is more representative so we built it at the",
    "start": "1916880",
    "end": "1922279"
  },
  {
    "text": "orchestration level because it's application aware uh but yeah uh if the problem is not this huge then",
    "start": "1922279",
    "end": "1929360"
  },
  {
    "text": "you can use some of the ray data Autos scaling features but we had like this huge imbalance uh so just to give you an",
    "start": "1929360",
    "end": "1935519"
  },
  {
    "text": "example and you'll appreciate if uh VM is 70% of the pipeline then everyone's",
    "start": "1935519",
    "end": "1940639"
  },
  {
    "text": "waiting on VM right everyone else just has the GPU utilization of 5% and why the VM is doing the GPU right yeah and",
    "start": "1940639",
    "end": "1947960"
  },
  {
    "text": "some of these things actually multi GPU doesn't help right uh it's because the model fits in a single GPU multi GPU",
    "start": "1947960",
    "end": "1954679"
  },
  {
    "text": "doesn't help we did try those techniques as well so yeah okay U question",
    "start": "1954679",
    "end": "1962960"
  },
  {
    "text": "here frame TR performance yeah it's a great question",
    "start": "1964159",
    "end": "1971080"
  },
  {
    "text": "so I think the question is around this uh different frame rates uh uh one of the things we did do I showed the",
    "start": "1971080",
    "end": "1976559"
  },
  {
    "text": "transcoding stuff that does take care of frame rates but it makes sure like we have the consistent format for the downstream pipeline uh some of it we",
    "start": "1976559",
    "end": "1983679"
  },
  {
    "text": "leave it to our training code so doing the tra training tokenization we take care of making sure",
    "start": "1983679",
    "end": "1989760"
  },
  {
    "text": "that the model gets consistent like normalized tokens for it uh so we don't do it here but it's taken care of the",
    "start": "1989760",
    "end": "1995880"
  },
  {
    "text": "training side",
    "start": "1995880",
    "end": "2002360"
  },
  {
    "text": "okay um how is the performance of the uh embeding search like you mentioned you",
    "start": "2002360",
    "end": "2008000"
  },
  {
    "text": "want to search for using natural language right how like a man playing basketball like how is the record or",
    "start": "2008000",
    "end": "2014360"
  },
  {
    "text": "Precision of your like embeding based a search yeah so that example was by the",
    "start": "2014360",
    "end": "2019720"
  },
  {
    "text": "way real right so uh it was a recorded video so I didn't kind of speed it up so in terms of just and by the way that",
    "start": "2019720",
    "end": "2026159"
  },
  {
    "text": "embedding is running on the CPU during the search site uh we didn't think we because it's not a real-time service not",
    "start": "2026159",
    "end": "2032360"
  },
  {
    "text": "everyone's using it so if you meant by uh system performance the system performance is very good right right uh",
    "start": "2032360",
    "end": "2038559"
  },
  {
    "text": "in terms of precision and things like that we did offthe shell benchmarks as I was talking about and it's good enough",
    "start": "2038559",
    "end": "2043840"
  },
  {
    "text": "for the things that we trying to search",
    "start": "2043840",
    "end": "2047518"
  },
  {
    "text": "today okay right thank you",
    "start": "2051520",
    "end": "2056610"
  },
  {
    "text": "[Applause]",
    "start": "2056610",
    "end": "2061699"
  }
]
[
  {
    "text": "all right uh welcome everyone um my name is shell from any scale open source team",
    "start": "5640",
    "end": "12240"
  },
  {
    "text": "uh today I will introduce R train a production ready library for distributed deep",
    "start": "12240",
    "end": "18800"
  },
  {
    "text": "learning and in this talk I will go over the following three sections first we'll",
    "start": "18800",
    "end": "24039"
  },
  {
    "text": "discuss the trends and challenges of distributed deep learning and then I'll discuss how retrain simpli IES the",
    "start": "24039",
    "end": "30960"
  },
  {
    "text": "distributor training and then finally we'll give a demo about how to fine-tune",
    "start": "30960",
    "end": "36040"
  },
  {
    "text": "a llama 2 7B model with fdp and",
    "start": "36040",
    "end": "41120"
  },
  {
    "text": "retrain so uh during the past few years we've seen that the model size is",
    "start": "41200",
    "end": "46239"
  },
  {
    "text": "getting larger and larger like for example in this diagram we can see that NLP find uh foundational model size are",
    "start": "46239",
    "end": "54440"
  },
  {
    "text": "increasing exponentially fast so these models are too large to fit into a single device devices therefore we come",
    "start": "54440",
    "end": "61640"
  },
  {
    "text": "to the model parallelism to sh the model across multiple",
    "start": "61640",
    "end": "67000"
  },
  {
    "text": "devices at the same time we're building larger data sets to fit this large",
    "start": "67000",
    "end": "72560"
  },
  {
    "text": "language models to aoid under fitting however training on this large",
    "start": "72560",
    "end": "78000"
  },
  {
    "text": "scale data s can be timec consuming and computational intensive therefore we come to data parm",
    "start": "78000",
    "end": "85600"
  },
  {
    "text": "to improve the training throughput and speed so allog together using Mel pism",
    "start": "85600",
    "end": "92920"
  },
  {
    "text": "and data pism in distributed training can even accelerate our whole training",
    "start": "92920",
    "end": "98960"
  },
  {
    "text": "progress and then enable us to train these large models on large data",
    "start": "98960",
    "end": "105439"
  },
  {
    "text": "sets however there are still many challenges in distributor training for",
    "start": "105439",
    "end": "110560"
  },
  {
    "text": "example the compatibility issue the ml developers might uh working on different",
    "start": "110560",
    "end": "115920"
  },
  {
    "text": "Frameworks like py lightning hugging phase or different persistence storage",
    "start": "115920",
    "end": "121000"
  },
  {
    "text": "their compute resource might hosted by different Cloud providers or different cluster",
    "start": "121000",
    "end": "126840"
  },
  {
    "text": "orchestrators it's often a burden for the Amo developers to build the Integrations with all these Frameworks",
    "start": "126840",
    "end": "133720"
  },
  {
    "text": "and Compu platforms scalability is not a big issue",
    "start": "133720",
    "end": "139040"
  },
  {
    "text": "like everything works super well with this deploying Frameworks in a single node setting but when you scale out to",
    "start": "139040",
    "end": "145560"
  },
  {
    "text": "dozens or hundreds or thousands of gpus the things get completely difference so",
    "start": "145560",
    "end": "151200"
  },
  {
    "text": "how to effectively manage a cluster of computational computational resource and",
    "start": "151200",
    "end": "156519"
  },
  {
    "text": "how to efficiently launch your job in a robust reliable and fall tolerance way",
    "start": "156519",
    "end": "162239"
  },
  {
    "text": "there's no simple solution for now and for large model training we cannot",
    "start": "162239",
    "end": "168080"
  },
  {
    "text": "solely use uh data parallelism but also need to use model parallelism to train",
    "start": "168080",
    "end": "173599"
  },
  {
    "text": "this models with limited GPU and CPU resources so all these challenges I",
    "start": "173599",
    "end": "178800"
  },
  {
    "text": "mentioned about seems to be hindering us from going distributed but today I'm thrilled to",
    "start": "178800",
    "end": "185519"
  },
  {
    "text": "announce that R train provides an open source production ready solution to make distributed training",
    "start": "185519",
    "end": "192120"
  },
  {
    "text": "easy so what is R train R train is a library for developing orchestrating and",
    "start": "192120",
    "end": "198440"
  },
  {
    "text": "scaling distributed deep learning applications it is built on top of Ray and integrated seamlessly with this deep",
    "start": "198440",
    "end": "205959"
  },
  {
    "text": "learning Frameworks and why should use R train",
    "start": "205959",
    "end": "211120"
  },
  {
    "text": "here are three main reasons first is a broad comp compatibility and high",
    "start": "211120",
    "end": "217120"
  },
  {
    "text": "scalability also the great large model training support when we talk about compatibility",
    "start": "217120",
    "end": "224159"
  },
  {
    "text": "rate train can be run with any training framework on any cloud storage with any computer",
    "start": "224159",
    "end": "230120"
  },
  {
    "text": "platform let's take a closer look first into the Integrations with the uh deep",
    "start": "230120",
    "end": "235599"
  },
  {
    "text": "learning Frameworks so here we shows the C St it to use R train users need to Define",
    "start": "235599",
    "end": "243519"
  },
  {
    "text": "first a training function which contains your py or lightning or hogging phase training code here and then Define a",
    "start": "243519",
    "end": "250439"
  },
  {
    "text": "scaling config to specify the number of workers and the resources per workers and the torch trainer will",
    "start": "250439",
    "end": "257560"
  },
  {
    "text": "combine these two together and help you to launch distributed workers and run the training function on the",
    "start": "257560",
    "end": "263880"
  },
  {
    "text": "corresponding devices so here uh we gave a simple code",
    "start": "263880",
    "end": "270639"
  },
  {
    "text": "snippet to help you understand how to migrate your code from the pie torch or lightning to uh retrain on the left hand",
    "start": "270639",
    "end": "279000"
  },
  {
    "text": "side uh there's a normal uh ddb training script you have to set up a distributor environments wrap the model with DDP set",
    "start": "279000",
    "end": "286560"
  },
  {
    "text": "up the distributed sampler to sh your data set and also during training you have to move the batches to",
    "start": "286560",
    "end": "293039"
  },
  {
    "text": "GPU but R train provides two utility function that can significantly simplifies your training Loop just",
    "start": "293039",
    "end": "299639"
  },
  {
    "text": "called prepare model and prepare data loader in this training function and py torch and torch trainer will help you to",
    "start": "299639",
    "end": "306240"
  },
  {
    "text": "set up all this distributed environment and corrected",
    "start": "306240",
    "end": "311440"
  },
  {
    "text": "devices and for py torch lining we have even simpler apis basically you just replace the ddb",
    "start": "311960",
    "end": "319600"
  },
  {
    "text": "strategy and lighning environment with our R trains",
    "start": "319600",
    "end": "324880"
  },
  {
    "text": "utility and just call prepare trainer before you kick off your training you don't need to change any lighting",
    "start": "324880",
    "end": "331919"
  },
  {
    "text": "modules definition or Uh custom data loader definition everything is purely",
    "start": "331919",
    "end": "338080"
  },
  {
    "text": "pythonic and in a lightning way and hogin face Transformers",
    "start": "338080",
    "end": "343880"
  },
  {
    "text": "similarly we have a prepared trainer API that help you to set up integration with",
    "start": "343880",
    "end": "348960"
  },
  {
    "text": "R train so as we can see all these minimum apis provides a very shallow",
    "start": "348960",
    "end": "355440"
  },
  {
    "text": "learning curve for the users to on board their model training for workload from",
    "start": "355440",
    "end": "360840"
  },
  {
    "text": "the deep learning for mer to R train and apart from the training you",
    "start": "360840",
    "end": "368039"
  },
  {
    "text": "may also uh care about how to persist your checkpoint and training artifacts",
    "start": "368039",
    "end": "373960"
  },
  {
    "text": "you may use different uh persistent storage like aw ss3 GCS or many shared",
    "start": "373960",
    "end": "380599"
  },
  {
    "text": "um file systems like hdfs EFS or gcp file store and rre provides a simple",
    "start": "380599",
    "end": "387639"
  },
  {
    "text": "interface called storage path here and the users just need to provide a URI on",
    "start": "387639",
    "end": "394039"
  },
  {
    "text": "your um persistent storage and then rra will help you to think or copy your",
    "start": "394039",
    "end": "400919"
  },
  {
    "text": "checkpoint and artifact from local storage to persistent storage you don't need to worry about how to handle the",
    "start": "400919",
    "end": "407160"
  },
  {
    "text": "file transfer uh under the hood also people might worry about like",
    "start": "407160",
    "end": "414440"
  },
  {
    "text": "if my note is um provisioned by different Cloud providers or managed by different orchestration tools do I have",
    "start": "414440",
    "end": "421319"
  },
  {
    "text": "to change my training code to adapt to this different computer platforms the answer is no for rra so",
    "start": "421319",
    "end": "428840"
  },
  {
    "text": "the ml developers just focusing on interaction with r Trin API and R um",
    "start": "428840",
    "end": "434120"
  },
  {
    "text": "with this great compatibility will help you to set up the computational",
    "start": "434120",
    "end": "439240"
  },
  {
    "text": "environment for you so we also provide all of the box",
    "start": "439240",
    "end": "444720"
  },
  {
    "text": "observability tools called R dashboard like from here you can see",
    "start": "444720",
    "end": "450080"
  },
  {
    "text": "uh how many notes you have in your R cluster and what's the memory CPU GPU",
    "start": "450080",
    "end": "455840"
  },
  {
    "text": "utilizations also you can easily track your training progress with the dashboard like how many workers you have",
    "start": "455840",
    "end": "462680"
  },
  {
    "text": "for this torch trainer and see the lcks or stack trace for better uh debuggability",
    "start": "462680",
    "end": "469039"
  },
  {
    "text": "you can also check out this uh Matrix dashboard to give you more uh fine grain",
    "start": "469039",
    "end": "475080"
  },
  {
    "text": "understanding about the hardware utilizations like all this observability tools gives you the confidence that you",
    "start": "475080",
    "end": "481919"
  },
  {
    "text": "can safely migrate your workload to rra and have full control along the life cycle of your",
    "start": "481919",
    "end": "489639"
  },
  {
    "text": "training so apart from the broad compatibility retrain is also featured",
    "start": "489639",
    "end": "494680"
  },
  {
    "text": "for its high scalability you can simple it's simple to scale out your model training and",
    "start": "494680",
    "end": "501319"
  },
  {
    "text": "data preprocessing with a few lines of cod change so Ray train is built on top of",
    "start": "501319",
    "end": "507720"
  },
  {
    "text": "Ray and we have done a lot of experiment to test out how uh what's the",
    "start": "507720",
    "end": "513479"
  },
  {
    "text": "scalability of Ray how Ray can scale to a large amount of GPU or CPU NOS as we",
    "start": "513479",
    "end": "519680"
  },
  {
    "text": "show here we've successfully train large large language models on 1,000 GPU scale",
    "start": "519680",
    "end": "525880"
  },
  {
    "text": "and also breaks the world records to process a huge data sets and we also have uh another session tomorrow to have",
    "start": "525880",
    "end": "533080"
  },
  {
    "text": "a a deep dive onto Ray scalability and see how to scale the ray clusters to 4,000 nodes",
    "start": "533080",
    "end": "541199"
  },
  {
    "text": "so as a uh retrain user so we provide a minimal API for you to leverage this",
    "start": "541600",
    "end": "548279"
  },
  {
    "text": "high scalability it's called scaling config uh at right hand side I gives three",
    "start": "548279",
    "end": "555360"
  },
  {
    "text": "examples the first example is scaling uh scaling AIO training with four workers",
    "start": "555360",
    "end": "560839"
  },
  {
    "text": "each with one GPU and the second example shows if you don't want GPU we can also",
    "start": "560839",
    "end": "566680"
  },
  {
    "text": "help you schedule like a large amount of CPU noes the last example shows you can",
    "start": "566680",
    "end": "574040"
  },
  {
    "text": "launch the workers with customized resources here we launch 16 workers with",
    "start": "574040",
    "end": "579440"
  },
  {
    "text": "each with one A1 100 gpus so this easy to use API helps you",
    "start": "579440",
    "end": "585600"
  },
  {
    "text": "to scale all your training with one line of code and also is flexible enough to",
    "start": "585600",
    "end": "590959"
  },
  {
    "text": "support uh different like hydrogenous types of uh computer uh Computer",
    "start": "590959",
    "end": "597839"
  },
  {
    "text": "Resources in addition to model training you may also care about how to scale out your",
    "start": "598120",
    "end": "604360"
  },
  {
    "text": "data pressing like traditionally if you're training a a a model with GPU nodes the",
    "start": "604360",
    "end": "611959"
  },
  {
    "text": "GPU nodes also take the responsibility of data prepressing which could be a",
    "start": "611959",
    "end": "617880"
  },
  {
    "text": "huge bottleneck if your data set is super large or your data transformation takes a long time so with the strong",
    "start": "617880",
    "end": "625480"
  },
  {
    "text": "integration with rate data we enables you to Leverage the heterogeneous resources to collectively uh pre-process",
    "start": "625480",
    "end": "633360"
  },
  {
    "text": "the data sets for training so on the right hand side uh with did some Benchmark we can see using",
    "start": "633360",
    "end": "640480"
  },
  {
    "text": "the heterogeneous classer with r data uh nearly double the stut of data inje",
    "start": "640480",
    "end": "646880"
  },
  {
    "text": "compared with uh the native torch data loader also Red Data supports streaming",
    "start": "646880",
    "end": "653000"
  },
  {
    "text": "execution and overlapped training and preprocessing all those exciting features you can find more about this uh",
    "start": "653000",
    "end": "659519"
  },
  {
    "text": "in our redent and lastly I'll talk about our",
    "start": "659519",
    "end": "665360"
  },
  {
    "text": "large model training support and as we discussed before like",
    "start": "665360",
    "end": "671480"
  },
  {
    "text": "training this large models you cannot only use data parm you need also to",
    "start": "671480",
    "end": "676959"
  },
  {
    "text": "adopt this Advanced model parallelism or zero this distributive strategies and",
    "start": "676959",
    "end": "684040"
  },
  {
    "text": "currently there are two popular libraries like deep speed and accelery that have well support for these",
    "start": "684040",
    "end": "690440"
  },
  {
    "text": "strategies and you can run this to libraries with zero code change on",
    "start": "690440",
    "end": "695920"
  },
  {
    "text": "retrain and we also have two other sessions to give Deep dive on how to use",
    "start": "695920",
    "end": "701839"
  },
  {
    "text": "this uh uh two libraries to find two large langage models with R",
    "start": "701839",
    "end": "709200"
  },
  {
    "text": "train so apart from model training distribut like checkpointing is",
    "start": "709600",
    "end": "715600"
  },
  {
    "text": "another big issue for LM support like for example the Llama 270b model if",
    "start": "715600",
    "end": "723320"
  },
  {
    "text": "you're saving it in fp6 it might takes 140 GB dis",
    "start": "723320",
    "end": "730440"
  },
  {
    "text": "storage traditionally we're using an aggregation based checkpoint where the rank zero worker will collect all the",
    "start": "730440",
    "end": "737040"
  },
  {
    "text": "checkpoint shards from the other ranks and then combine them and upload them to Cost Storage which could be a huge",
    "start": "737040",
    "end": "744839"
  },
  {
    "text": "bottleneck well all the workers are waiting for this checkpoint to be synced and the gpus are",
    "start": "744839",
    "end": "751399"
  },
  {
    "text": "idling and retra provides a distributed checkpointing feature that allows you to",
    "start": "751399",
    "end": "757079"
  },
  {
    "text": "upload the checkpoint Shard directly from this rank from all the workers to the Cost Storage so we can see here the",
    "start": "757079",
    "end": "765399"
  },
  {
    "text": "CPU memory usage and network traffic has decreased by number of workers",
    "start": "765399",
    "end": "772399"
  },
  {
    "text": "time so also this large modal training could be some long running job",
    "start": "773199",
    "end": "779480"
  },
  {
    "text": "and it could be expensive if you're using this very costly GPU",
    "start": "779480",
    "end": "784600"
  },
  {
    "text": "instances you might want to use spot instance to reduce the training cost",
    "start": "784600",
    "end": "789800"
  },
  {
    "text": "like for example on the left hand side which shows that the spot instance price are generally 16 UH 60 to 70% cheaper",
    "start": "789800",
    "end": "797480"
  },
  {
    "text": "than ond demand instances so R train provide the fall tolerant training to support you to",
    "start": "797480",
    "end": "803959"
  },
  {
    "text": "train on the spot instances so for example one of the GPU node get",
    "start": "803959",
    "end": "810279"
  },
  {
    "text": "preempted and retrain can automatically schedule your Noe uh schedule your",
    "start": "810279",
    "end": "815680"
  },
  {
    "text": "training job onto another GPU node and relaunch the training with the latest persisted",
    "start": "815680",
    "end": "821560"
  },
  {
    "text": "checkpoint with the fall tolerance training support you can have a seamless robust and reliable Elm training",
    "start": "821560",
    "end": "828600"
  },
  {
    "text": "experience on spot instance so in conclusion retra provides",
    "start": "828600",
    "end": "835160"
  },
  {
    "text": "broad compatibility high scalability and great l large language model support",
    "start": "835160",
    "end": "841279"
  },
  {
    "text": "which makes open source production ready solution and today I'm thrilled to",
    "start": "841279",
    "end": "847399"
  },
  {
    "text": "announce that retrain is now generally available and this is not only a big milestone for us but also for the whole",
    "start": "847399",
    "end": "854440"
  },
  {
    "text": "community that makes the distributed training more accessible and",
    "start": "854440",
    "end": "860480"
  },
  {
    "text": "efficient okay so also R train usage is growing really fast compared with last",
    "start": "860880",
    "end": "867839"
  },
  {
    "text": "year September 22 we have fixing time more usage uh more weekly usage and also",
    "start": "867839",
    "end": "875160"
  },
  {
    "text": "we are very happy to see that retrain helps the instaart and also other open",
    "start": "875160",
    "end": "880360"
  },
  {
    "text": "source users to improve their training speed and cost efficiency like in insta",
    "start": "880360",
    "end": "885880"
  },
  {
    "text": "card their training workload runs 12 times faster eight times cheaper and",
    "start": "885880",
    "end": "891079"
  },
  {
    "text": "training on 100 times more data set and we also have many other users",
    "start": "891079",
    "end": "897600"
  },
  {
    "text": "that brings their success uccess stories to re resubmit this year and um can't wait to see how retra deployed in",
    "start": "897600",
    "end": "904720"
  },
  {
    "text": "production to help them to success okay so finally I will give a",
    "start": "904720",
    "end": "910920"
  },
  {
    "text": "short demo about how to fine-tune a llama 27b model with fsdp and",
    "start": "910920",
    "end": "916959"
  },
  {
    "text": "retrain okay in this demo um we first provide a simple training function that",
    "start": "923519",
    "end": "929759"
  },
  {
    "text": "can works on a single device but with a huge amount of GPU memory first we",
    "start": "929759",
    "end": "936120"
  },
  {
    "text": "initialize the model from prr weights initialize data loaders Define Optimizer scheduler and",
    "start": "936120",
    "end": "943120"
  },
  {
    "text": "gradient scaler and we start training here we will not show the",
    "start": "943120",
    "end": "948279"
  },
  {
    "text": "details of the training Loop but we provide a utility function that train the model for yoch and Returns the",
    "start": "948279",
    "end": "954399"
  },
  {
    "text": "evaluation metrix and then we call this training function in the main",
    "start": "954399",
    "end": "960240"
  },
  {
    "text": "block so we notice that we are loading the model the full model directly to GPU",
    "start": "960240",
    "end": "966160"
  },
  {
    "text": "which means it will take a large of GPU memory to train this Lama 2 model so you can definitely train it on a100 or",
    "start": "966160",
    "end": "973560"
  },
  {
    "text": "h100 but it's due to GPU shortage it's really hard to get this instances from the cloud providers therefore in this",
    "start": "973560",
    "end": "980680"
  },
  {
    "text": "demo I will show how to use fsdp and retrain to help you scale out the model training onto 16 T4 gpus which is",
    "start": "980680",
    "end": "989000"
  },
  {
    "text": "cheaper and easier to get okay so now uh before we get",
    "start": "989000",
    "end": "996399"
  },
  {
    "text": "started let's first import several utility functions for py torch",
    "start": "996399",
    "end": "1002959"
  },
  {
    "text": "integration as discussed before we import prepare data loader and prepare",
    "start": "1002959",
    "end": "1009800"
  },
  {
    "text": "model now instead of loading the whole model to uh GPU we're using prepare",
    "start": "1009800",
    "end": "1015319"
  },
  {
    "text": "model to wrap it around fsdp and provide the corresponding",
    "start": "1015319",
    "end": "1020680"
  },
  {
    "text": "configurations for fsp",
    "start": "1020680",
    "end": "1025559"
  },
  {
    "text": "strategy so we provide the configurations for fsdp including how you Shard the model across different",
    "start": "1025880",
    "end": "1032798"
  },
  {
    "text": "gpus whether to use CPU offload or whether to use mixed Precision",
    "start": "1032799",
    "end": "1039319"
  },
  {
    "text": "training after we process the model now we are preparing the data loaders here",
    "start": "1040520",
    "end": "1047038"
  },
  {
    "text": "we will inject a distributed Samplers to both the training data loader and evaluation data",
    "start": "1047039",
    "end": "1052520"
  },
  {
    "text": "loader so that it will sh the data sets across 16 GPU",
    "start": "1052520",
    "end": "1059320"
  },
  {
    "text": "workers and we don't have to change the training loop at the end of the training Epoch we",
    "start": "1062480",
    "end": "1069840"
  },
  {
    "text": "may want to save our checkpoint should we save the full model checkpoint actually it could be very uh",
    "start": "1069840",
    "end": "1077960"
  },
  {
    "text": "memory and disk uh inefficient and it will introduce the",
    "start": "1077960",
    "end": "1083280"
  },
  {
    "text": "extra communication between the rank zero worker and other worker therefore",
    "start": "1083280",
    "end": "1088440"
  },
  {
    "text": "we choose to use shed model checkpoint which means each fsdp worker",
    "start": "1088440",
    "end": "1095440"
  },
  {
    "text": "will save only a portion of the model waste to its local",
    "start": "1095440",
    "end": "1100720"
  },
  {
    "text": "storage and later we'll use rra distributed checkpointing feature to",
    "start": "1100720",
    "end": "1107039"
  },
  {
    "text": "upload this checkpoint Shar directly to the unified storage path so",
    "start": "1107039",
    "end": "1112200"
  },
  {
    "text": "that you can retrieve this um Che points later for inference or uh resume",
    "start": "1112200",
    "end": "1119000"
  },
  {
    "text": "training the interface here is simple it's called ray. train. report just",
    "start": "1119000",
    "end": "1125159"
  },
  {
    "text": "combine the Matrix and your checkpoint directory to this API and R will help",
    "start": "1125159",
    "end": "1131880"
  },
  {
    "text": "you to sync up your checkpoints and now let's define a torch",
    "start": "1131880",
    "end": "1139559"
  },
  {
    "text": "trainer to help you scale out this training function to 16 gpus first in import torch",
    "start": "1139559",
    "end": "1148720"
  },
  {
    "text": "trainer and also two utilities called scaling config and run",
    "start": "1148720",
    "end": "1155720"
  },
  {
    "text": "config so scaling config is used for defining the number of workers and the",
    "start": "1156360",
    "end": "1162720"
  },
  {
    "text": "resource for workers here we turn on the used GPU flag which will assign one CPU",
    "start": "1162720",
    "end": "1168840"
  },
  {
    "text": "for each worker so the Run config will Define the",
    "start": "1168840",
    "end": "1174400"
  },
  {
    "text": "experiment name and the storage pass here we name it Lama 2 fine tune",
    "start": "1174400",
    "end": "1181080"
  },
  {
    "text": "demo and then provide F3 bucket as the storage pass and you can expect to have your",
    "start": "1181080",
    "end": "1188159"
  },
  {
    "text": "checkpoint and training artifacts under this E3 bucket after the training",
    "start": "1188159",
    "end": "1196360"
  },
  {
    "text": "finished all right and lastly let's combine everything together into a torch",
    "start": "1196919",
    "end": "1202080"
  },
  {
    "text": "trainer which includes the training function the input parameters of this",
    "start": "1202080",
    "end": "1207600"
  },
  {
    "text": "training function scanning config and also the Run",
    "start": "1207600",
    "end": "1216799"
  },
  {
    "text": "config know that everything happen here are 100% pythonic you don't have to have",
    "start": "1218360",
    "end": "1225280"
  },
  {
    "text": "some yamoo configuration files or some comp environment",
    "start": "1225280",
    "end": "1230360"
  },
  {
    "text": "setup and we can trigger this training workload by calling python train.py on",
    "start": "1230360",
    "end": "1237159"
  },
  {
    "text": "your head Noe just like you're developing in a local environment and rra will help you to scale out this",
    "start": "1237159",
    "end": "1245799"
  },
  {
    "text": "training okay as a training uh kiing off because it takes time to download the",
    "start": "1246400",
    "end": "1251720"
  },
  {
    "text": "model ways and pre ways and load it to GPU let's take a step forward and see",
    "start": "1251720",
    "end": "1258240"
  },
  {
    "text": "what will happen after the training gets",
    "start": "1258240",
    "end": "1262440"
  },
  {
    "text": "started okay during training we can see we have trained several batches and from",
    "start": "1264760",
    "end": "1271720"
  },
  {
    "text": "rear dashboard we see all the gpus like 16 gpus are being used with high",
    "start": "1271720",
    "end": "1278120"
  },
  {
    "text": "utilization and then let's check out the progress you can see we have 16 R train",
    "start": "1278120",
    "end": "1285039"
  },
  {
    "text": "workers and each are in progress and for",
    "start": "1285039",
    "end": "1292600"
  },
  {
    "text": "metrix you can also get many um useful information about the hardware",
    "start": "1292600",
    "end": "1298400"
  },
  {
    "text": "utilization note Network Dix iio to help you better debug the bottle neck or the",
    "start": "1298400",
    "end": "1305000"
  },
  {
    "text": "issue in your training code and after the training finished",
    "start": "1305000",
    "end": "1310720"
  },
  {
    "text": "let's take a look at the checkpoints and artifacts from a sf3 bucket we can see",
    "start": "1310720",
    "end": "1319000"
  },
  {
    "text": "we already persisted this three checkpoints from each Epoch together with the parameters",
    "start": "1319000",
    "end": "1325720"
  },
  {
    "text": "training progress and training results and from each checkpoint folder",
    "start": "1325720",
    "end": "1331400"
  },
  {
    "text": "There are 16 checkpoint shards uploaded from different workers so you can use",
    "start": "1331400",
    "end": "1338000"
  },
  {
    "text": "this checkpoint shards later after training finish for offline or online inference or resume",
    "start": "1338000",
    "end": "1345760"
  },
  {
    "text": "training okay so finally again retrain is generally available now in R 2.7 uh",
    "start": "1346960",
    "end": "1353600"
  },
  {
    "text": "we just released 2.7 yesterday so feel free to try it out and if you have any questions um please refer to the r TR",
    "start": "1353600",
    "end": "1360960"
  },
  {
    "text": "documentation or join our community and feel free to post any issues or feature",
    "start": "1360960",
    "end": "1366360"
  },
  {
    "text": "requests and we're really happy to work with you guys together to make distributed training more accessible and",
    "start": "1366360",
    "end": "1372120"
  },
  {
    "text": "more efficient and that's all I have for today and thank you all I'll leave the",
    "start": "1372120",
    "end": "1378559"
  },
  {
    "text": "last couple of minutes for [Applause]",
    "start": "1378559",
    "end": "1388849"
  },
  {
    "text": "QA and thanks for this great talk so two quick question uh first of all did you guys compare the performance of a",
    "start": "1390600",
    "end": "1397480"
  },
  {
    "text": "distributed training on T4 versus like training on 1 A1 100 uh that depends uh",
    "start": "1397480",
    "end": "1404760"
  },
  {
    "text": "on many different aspect firstly what's your how many t for instance you're using for distributed training what's",
    "start": "1404760",
    "end": "1411880"
  },
  {
    "text": "the global batch size and what's your uh um batch what's your sequence length and",
    "start": "1411880",
    "end": "1420080"
  },
  {
    "text": "it's actually uh it's not easy to answer question because uh this training speed",
    "start": "1420080",
    "end": "1425679"
  },
  {
    "text": "are dependent on different aspect so uh you can expect if you have one a100 and",
    "start": "1425679",
    "end": "1432320"
  },
  {
    "text": "compare with a bunch of t for instance and training with the same Global batch size training on a100 will be faster but",
    "start": "1432320",
    "end": "1438679"
  },
  {
    "text": "if you have more T4 instance as your Global bze grows and your training",
    "start": "1438679",
    "end": "1443720"
  },
  {
    "text": "performance training speed will be faster than a100 instances but it didn't hurt performance right I don't you know",
    "start": "1443720",
    "end": "1450559"
  },
  {
    "text": "I know that it's going to take longer on T4 but the performance the final performance did it hurt the performance",
    "start": "1450559",
    "end": "1457440"
  },
  {
    "text": "will not change because you are using the same data sets and same uh like random sees or training progress okay",
    "start": "1457440",
    "end": "1463799"
  },
  {
    "text": "yeah and then my second question is uh for uh large models is it only for llms or we can try customize Foundation",
    "start": "1463799",
    "end": "1470880"
  },
  {
    "text": "models as well oh it ret train is a very general platform you can train any large models including Vision recommendation",
    "start": "1470880",
    "end": "1477720"
  },
  {
    "text": "graph Network every kind of large models yeah",
    "start": "1477720",
    "end": "1483360"
  },
  {
    "text": "thanks hi so one of the major requirements is to import uh py to from",
    "start": "1486320",
    "end": "1492159"
  },
  {
    "text": "the ray train right and then like uh change the lines in the code to uh use",
    "start": "1492159",
    "end": "1497279"
  },
  {
    "text": "Ray train mhm is there any other way where you don't have to import the py you import pyto natively but then",
    "start": "1497279",
    "end": "1502520"
  },
  {
    "text": "somehow wrap the model uh separately like uh actually you don't uh import",
    "start": "1502520",
    "end": "1508039"
  },
  {
    "text": "pytorch from rra you just import from pytorch and rra provides the integration",
    "start": "1508039",
    "end": "1513200"
  },
  {
    "text": "tools uh or some utility functions to add on uh like add on top of your py to",
    "start": "1513200",
    "end": "1519799"
  },
  {
    "text": "training code so there will be no like discrepancies between your original training code and ret training yeah",
    "start": "1519799",
    "end": "1529679"
  },
  {
    "text": "hey I saw you have some like a demo and example on data parallel and I'm wondering for the pipeline parallel does",
    "start": "1532240",
    "end": "1538640"
  },
  {
    "text": "user need to specify the uh layer config or pipeline parallel config where the",
    "start": "1538640",
    "end": "1544880"
  },
  {
    "text": "the framework can do like automatic uh Shard model directly oh so if you're",
    "start": "1544880",
    "end": "1551120"
  },
  {
    "text": "using uh pipeline parallelism model other model parm you have to configure um the parallelism strategies by",
    "start": "1551120",
    "end": "1558559"
  },
  {
    "text": "yourself uh so rrim provides a UniFi interface to launch this training worker",
    "start": "1558559",
    "end": "1563679"
  },
  {
    "text": "and um the users has full um flexibility to configure how to Shard your model and",
    "start": "1563679",
    "end": "1570760"
  },
  {
    "text": "how to um schedule the model parameters on different devices I see and follow followup",
    "start": "1570760",
    "end": "1577520"
  },
  {
    "text": "question is is there any plan to integrate with something like ARA to make uh the pipeline parallel",
    "start": "1577520",
    "end": "1585159"
  },
  {
    "text": "automatic uh I think uh like integrating with this uh more advanced the training",
    "start": "1585159",
    "end": "1590360"
  },
  {
    "text": "strategy is always our uh like future plan and we also want to uh optimize the",
    "start": "1590360",
    "end": "1595960"
  },
  {
    "text": "training uh speed by like analyzing the like Network topology and analyzing the",
    "start": "1595960",
    "end": "1602559"
  },
  {
    "text": "model size and your training strategy to make a to generate an optimized solution",
    "start": "1602559",
    "end": "1609000"
  },
  {
    "text": "um to accelerate the training so that's definitely on our road map thank",
    "start": "1609000",
    "end": "1615720"
  },
  {
    "text": "you Could you actually elaborate on that",
    "start": "1616600",
    "end": "1623080"
  },
  {
    "text": "last point so like what are kind of the bottlenecks when you look at ra train in terms of training speed at least in the",
    "start": "1623080",
    "end": "1628760"
  },
  {
    "text": "current iteration uh which one or just like what is what are the major bottlenecks um that is that are",
    "start": "1628760",
    "end": "1635960"
  },
  {
    "text": "preventing Ray train from being even faster uh prevent from ra train become faster I think",
    "start": "1635960",
    "end": "1643120"
  },
  {
    "text": "um because R train is built on top of the uh the scalability part is um",
    "start": "1643120",
    "end": "1650080"
  },
  {
    "text": "guaranteed by record and the bottom neck could be the underlying communication um because currently pytor",
    "start": "1650080",
    "end": "1657399"
  },
  {
    "text": "or dip speed are leveraging their own communication libraries um so that's uh if this so we",
    "start": "1657399",
    "end": "1664320"
  },
  {
    "text": "are dependent on this um open source libraries to provide uh the efficient",
    "start": "1664320",
    "end": "1670720"
  },
  {
    "text": "training experence so it could be a problem that um they have some",
    "start": "1670720",
    "end": "1676840"
  },
  {
    "text": "bottleneck issu issue that is not resolved by like that is not handled by R train side so",
    "start": "1676840",
    "end": "1686240"
  },
  {
    "text": "um so follow up on that question okay I know um Ray cor you said the ray train",
    "start": "1694720",
    "end": "1701600"
  },
  {
    "text": "is built on top of recore yes when it comes to actual when the trainers are running uh most of the uh operations are",
    "start": "1701600",
    "end": "1710480"
  },
  {
    "text": "done by the framework plus the communication like the nickel from uh Nvidia so when the",
    "start": "1710480",
    "end": "1719519"
  },
  {
    "text": "trainers are like the job is already kicked off what is the role of Rey in",
    "start": "1719519",
    "end": "1726320"
  },
  {
    "text": "that process yeah that's a good question like Reay firstly take care of the",
    "start": "1726320",
    "end": "1731840"
  },
  {
    "text": "resource management and how to launch a job and also um it helps you to",
    "start": "1731840",
    "end": "1737840"
  },
  {
    "text": "orchestrate on this uh different competition resource like how to support",
    "start": "1737840",
    "end": "1742919"
  },
  {
    "text": "the fall tolerance training and uh how to um like coordinate between each",
    "start": "1742919",
    "end": "1748399"
  },
  {
    "text": "workers to upload the checkpoints and how to integrate actually we have integration with red",
    "start": "1748399",
    "end": "1754240"
  },
  {
    "text": "data and Rune that can provide better uh in uh better performance on data",
    "start": "1754240",
    "end": "1759559"
  },
  {
    "text": "ingestion and Hyper parameter tuning okay yeah um that was a followup so my",
    "start": "1759559",
    "end": "1766679"
  },
  {
    "text": "original question uh was uh with data ingestion and you mentioned",
    "start": "1766679",
    "end": "1772399"
  },
  {
    "text": "heterogeneous uh Cloud so that pre-processing can be done on maybe the CPU parts of the cluster yes um does it",
    "start": "1772399",
    "end": "1780120"
  },
  {
    "text": "is there a chance to integrate with a lot of image processing it's intensive and you're able to use say di from",
    "start": "1780120",
    "end": "1786279"
  },
  {
    "text": "Nvidia to do the pre-processing with on the gpus where um The Next Step like in",
    "start": "1786279",
    "end": "1794480"
  },
  {
    "text": "the like GPU Cuda stream you able to overlap um like utilizing do does Ray",
    "start": "1794480",
    "end": "1802480"
  },
  {
    "text": "provide that wor isy on a road map all right that's a good idea like currently",
    "start": "1802480",
    "end": "1807559"
  },
  {
    "text": "we only um provides the I I think currently rate data has the unified",
    "start": "1807559",
    "end": "1813679"
  },
  {
    "text": "interface called map batches that can put any pre-processing or transformation function into that so as you said if you",
    "start": "1813679",
    "end": "1820840"
  },
  {
    "text": "want to find or if you want to transform a image dat set on GPU that's totally",
    "start": "1820840",
    "end": "1827000"
  },
  {
    "text": "possible with current R uh rate data support so",
    "start": "1827000",
    "end": "1832440"
  },
  {
    "text": "the users have the flexibility to define the transformation function okay thank",
    "start": "1832440",
    "end": "1837720"
  },
  {
    "text": "you yeah thanks cool I think we're at time but we may we could fit in one last question was there one back",
    "start": "1837720",
    "end": "1845679"
  },
  {
    "text": "here what Integrations are available with um model reposit with model",
    "start": "1846559",
    "end": "1851919"
  },
  {
    "text": "repositories for persisting weights um I know that this example that you gave us with the llm it's not quite as relevant",
    "start": "1851919",
    "end": "1858120"
  },
  {
    "text": "but for other models where you would be iterating uh you mean uh what",
    "start": "1858120",
    "end": "1863919"
  },
  {
    "text": "persistence stge uh yeah for uh yeah uh model repositories so that you can po",
    "start": "1863919",
    "end": "1869720"
  },
  {
    "text": "persist the weights as artifacts and reload them for additional fine tuning oh actually for now we're leveraging the",
    "start": "1869720",
    "end": "1877720"
  },
  {
    "text": "let me find the slides yeah we're leveraging the Apachi arrow on the on",
    "start": "1877720",
    "end": "1883120"
  },
  {
    "text": "the hood to think your checkpoint to like this cloud storage uh it's includ",
    "start": "1883120",
    "end": "1888639"
  },
  {
    "text": "like basically on this slid is the most major cloud storage we have used for uh",
    "start": "1888639",
    "end": "1894880"
  },
  {
    "text": "retrain so there are also some Community contributed um integration with Cost",
    "start": "1894880",
    "end": "1899960"
  },
  {
    "text": "Storage which I didn't uh list it here um but I think it rri provides a",
    "start": "1899960",
    "end": "1907120"
  },
  {
    "text": "flexible interface for you to um integrate with this new model",
    "start": "1907120",
    "end": "1912240"
  },
  {
    "text": "registration like MLF flow or uh some other exper tracking tools thank you I'm",
    "start": "1912240",
    "end": "1917480"
  },
  {
    "text": "not sure if it's uh if it answered the",
    "start": "1917480",
    "end": "1921480"
  },
  {
    "text": "question",
    "start": "1924880",
    "end": "1927880"
  }
]
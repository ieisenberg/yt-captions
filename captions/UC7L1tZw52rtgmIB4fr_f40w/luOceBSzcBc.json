[
  {
    "start": "0",
    "end": "97000"
  },
  {
    "text": "hi everyone",
    "start": "3040",
    "end": "4160"
  },
  {
    "text": "thanks for tuning in i'm magna the",
    "start": "4160",
    "end": "6319"
  },
  {
    "text": "machine learning engineer at cigot",
    "start": "6319",
    "end": "8720"
  },
  {
    "text": "and today we're going to talk about",
    "start": "8720",
    "end": "10080"
  },
  {
    "text": "efficient work training off",
    "start": "10080",
    "end": "11920"
  },
  {
    "text": "model size and performance with scalable",
    "start": "11920",
    "end": "14799"
  },
  {
    "text": "hyperparameter optimization",
    "start": "14799",
    "end": "17920"
  },
  {
    "text": "so before we jump into the use case i'm",
    "start": "18400",
    "end": "20640"
  },
  {
    "text": "going to quickly go over",
    "start": "20640",
    "end": "22560"
  },
  {
    "text": "what we do at sigopt and the product",
    "start": "22560",
    "end": "24960"
  },
  {
    "text": "features",
    "start": "24960",
    "end": "25920"
  },
  {
    "text": "we'll use for this use case",
    "start": "25920",
    "end": "31199"
  },
  {
    "text": "our mission is to amplify and accelerate",
    "start": "31199",
    "end": "34480"
  },
  {
    "text": "your model development and to help you",
    "start": "34480",
    "end": "37360"
  },
  {
    "text": "gain insights",
    "start": "37360",
    "end": "38640"
  },
  {
    "text": "throughout your experimentation process",
    "start": "38640",
    "end": "42960"
  },
  {
    "text": "we understand that modeling is messy and",
    "start": "43760",
    "end": "46640"
  },
  {
    "text": "difficult to standardize",
    "start": "46640",
    "end": "48480"
  },
  {
    "text": "training can be a crap shoot and",
    "start": "48480",
    "end": "50640"
  },
  {
    "text": "difficult to debug",
    "start": "50640",
    "end": "52399"
  },
  {
    "text": "and that tuning is expensive and",
    "start": "52399",
    "end": "54480"
  },
  {
    "text": "difficult to scale so we've built",
    "start": "54480",
    "end": "58559"
  },
  {
    "text": "solutions to help with these problems",
    "start": "58559",
    "end": "60719"
  },
  {
    "text": "including intelligent experiment",
    "start": "60719",
    "end": "63440"
  },
  {
    "text": "management",
    "start": "63440",
    "end": "64158"
  },
  {
    "text": "to organize and collaborate with your",
    "start": "64159",
    "end": "66240"
  },
  {
    "text": "team throughout your modeling process",
    "start": "66240",
    "end": "69040"
  },
  {
    "text": "providing insights into your training",
    "start": "69040",
    "end": "70960"
  },
  {
    "text": "runs and",
    "start": "70960",
    "end": "72320"
  },
  {
    "text": "efficient intelligent and scalable",
    "start": "72320",
    "end": "74799"
  },
  {
    "text": "hyperparameter optimization",
    "start": "74799",
    "end": "78400"
  },
  {
    "text": "we know you're iterating on tooling",
    "start": "78960",
    "end": "80960"
  },
  {
    "text": "along with iterating",
    "start": "80960",
    "end": "82320"
  },
  {
    "text": "on your model development and we've made",
    "start": "82320",
    "end": "85360"
  },
  {
    "text": "sure we're easy to use",
    "start": "85360",
    "end": "87200"
  },
  {
    "text": "and stack agnostic",
    "start": "87200",
    "end": "90479"
  },
  {
    "text": "for this talk we'll focus on hyper",
    "start": "91119",
    "end": "93280"
  },
  {
    "text": "parameter optimization",
    "start": "93280",
    "end": "94799"
  },
  {
    "text": "at scale and specifically sigops",
    "start": "94799",
    "end": "99119"
  },
  {
    "start": "97000",
    "end": "97000"
  },
  {
    "text": "hpo feature so here's how our general",
    "start": "99119",
    "end": "103439"
  },
  {
    "text": "optimization loop",
    "start": "103439",
    "end": "104640"
  },
  {
    "text": "works we set up a parameter space",
    "start": "104640",
    "end": "108000"
  },
  {
    "text": "sigopt samples the space and provides",
    "start": "108000",
    "end": "110640"
  },
  {
    "text": "parameter values",
    "start": "110640",
    "end": "112479"
  },
  {
    "text": "we'll run a model training given these",
    "start": "112479",
    "end": "115119"
  },
  {
    "text": "suggestions",
    "start": "115119",
    "end": "116479"
  },
  {
    "text": "and return the model's performance or",
    "start": "116479",
    "end": "118640"
  },
  {
    "text": "other metric",
    "start": "118640",
    "end": "119840"
  },
  {
    "text": "back to sig up so the optimization",
    "start": "119840",
    "end": "122479"
  },
  {
    "text": "process",
    "start": "122479",
    "end": "123600"
  },
  {
    "text": "proceeds in this loop-like fashion",
    "start": "123600",
    "end": "126799"
  },
  {
    "text": "where over time we should see our model",
    "start": "126799",
    "end": "129360"
  },
  {
    "text": "performing",
    "start": "129360",
    "end": "130479"
  },
  {
    "text": "better and better",
    "start": "130479",
    "end": "133280"
  },
  {
    "text": "great now that we're more familiar with",
    "start": "133760",
    "end": "136560"
  },
  {
    "text": "the tools we'll be using",
    "start": "136560",
    "end": "138080"
  },
  {
    "text": "along with ray let's talk about",
    "start": "138080",
    "end": "140239"
  },
  {
    "text": "compressing bert",
    "start": "140239",
    "end": "143280"
  },
  {
    "start": "142000",
    "end": "142000"
  },
  {
    "text": "so bert is great and is a very pivotal",
    "start": "143280",
    "end": "146080"
  },
  {
    "text": "architecture",
    "start": "146080",
    "end": "147040"
  },
  {
    "text": "it is generalizable and transferable",
    "start": "147040",
    "end": "150400"
  },
  {
    "text": "which means that the model performs",
    "start": "150400",
    "end": "152879"
  },
  {
    "text": "strongly across a variety of nlp tasks",
    "start": "152879",
    "end": "156640"
  },
  {
    "text": "with very minimal changes required in",
    "start": "156640",
    "end": "159040"
  },
  {
    "text": "its architecture",
    "start": "159040",
    "end": "160959"
  },
  {
    "text": "this really enables us to use transfer",
    "start": "160959",
    "end": "163440"
  },
  {
    "text": "learning",
    "start": "163440",
    "end": "164000"
  },
  {
    "text": "and leverage large pre-trained models to",
    "start": "164000",
    "end": "166800"
  },
  {
    "text": "solve",
    "start": "166800",
    "end": "167280"
  },
  {
    "text": "specific and niche problems which is",
    "start": "167280",
    "end": "170000"
  },
  {
    "text": "really convenient",
    "start": "170000",
    "end": "172800"
  },
  {
    "text": "but it is very large and difficult to",
    "start": "173599",
    "end": "175840"
  },
  {
    "text": "put into",
    "start": "175840",
    "end": "177360"
  },
  {
    "text": "production systems and other memory",
    "start": "177360",
    "end": "180560"
  },
  {
    "text": "constrained applications",
    "start": "180560",
    "end": "182400"
  },
  {
    "text": "so many teams are trying to solve this",
    "start": "182400",
    "end": "184319"
  },
  {
    "text": "problem by compressing bert",
    "start": "184319",
    "end": "186319"
  },
  {
    "text": "including hugging face raza and utter",
    "start": "186319",
    "end": "189440"
  },
  {
    "text": "works",
    "start": "189440",
    "end": "190400"
  },
  {
    "text": "we'll be focused on expanding hugging",
    "start": "190400",
    "end": "192239"
  },
  {
    "text": "faces work on distilling bert",
    "start": "192239",
    "end": "194959"
  },
  {
    "text": "and specifically ask the two following",
    "start": "194959",
    "end": "197599"
  },
  {
    "text": "questions",
    "start": "197599",
    "end": "200159"
  },
  {
    "text": "one can we understand the trade-offs",
    "start": "200400",
    "end": "204080"
  },
  {
    "text": "between model size and performance",
    "start": "204080",
    "end": "206480"
  },
  {
    "text": "when compressing bert",
    "start": "206480",
    "end": "209519"
  },
  {
    "text": "and two given these trade-offs can we",
    "start": "209519",
    "end": "212319"
  },
  {
    "text": "make informed decisions",
    "start": "212319",
    "end": "214480"
  },
  {
    "text": "on a model architecture the best works",
    "start": "214480",
    "end": "217440"
  },
  {
    "text": "for our needs",
    "start": "217440",
    "end": "220239"
  },
  {
    "text": "to answer these questions let's focus on",
    "start": "220879",
    "end": "223040"
  },
  {
    "text": "our use case",
    "start": "223040",
    "end": "223920"
  },
  {
    "text": "distilling bert for question answering",
    "start": "223920",
    "end": "228239"
  },
  {
    "start": "228000",
    "end": "228000"
  },
  {
    "text": "the data set we'll be using is squad 2.",
    "start": "228480",
    "end": "231680"
  },
  {
    "text": "it is comprised of 35 topics ranging",
    "start": "231680",
    "end": "234640"
  },
  {
    "text": "from",
    "start": "234640",
    "end": "235360"
  },
  {
    "text": "the chemical properties of oxygen to the",
    "start": "235360",
    "end": "238000"
  },
  {
    "text": "history of the yuan dynasty",
    "start": "238000",
    "end": "240799"
  },
  {
    "text": "each topic has a set of questions the",
    "start": "240799",
    "end": "243120"
  },
  {
    "text": "model needs to understand",
    "start": "243120",
    "end": "244799"
  },
  {
    "text": "and answer so think of this as your",
    "start": "244799",
    "end": "248959"
  },
  {
    "text": "standardized reading comprehension test",
    "start": "248959",
    "end": "251680"
  },
  {
    "text": "where you're like provided a paragraph",
    "start": "251680",
    "end": "253439"
  },
  {
    "text": "instead of questions",
    "start": "253439",
    "end": "255040"
  },
  {
    "text": "and you need to find the answers to",
    "start": "255040",
    "end": "256400"
  },
  {
    "text": "these questions within the paragraph",
    "start": "256400",
    "end": "260560"
  },
  {
    "start": "260000",
    "end": "260000"
  },
  {
    "text": "unlike squad one squad two introduces",
    "start": "260639",
    "end": "263440"
  },
  {
    "text": "the concept of",
    "start": "263440",
    "end": "264720"
  },
  {
    "text": "unanswerable questions making it more",
    "start": "264720",
    "end": "267040"
  },
  {
    "text": "challenging for models",
    "start": "267040",
    "end": "269360"
  },
  {
    "text": "the data set itself is split 50 50",
    "start": "269360",
    "end": "272400"
  },
  {
    "text": "between answerable and unanswerable",
    "start": "272400",
    "end": "274960"
  },
  {
    "text": "questions",
    "start": "274960",
    "end": "275919"
  },
  {
    "text": "for answerable questions to be marked as",
    "start": "275919",
    "end": "278240"
  },
  {
    "text": "correct",
    "start": "278240",
    "end": "279120"
  },
  {
    "text": "the model has to find the exact string",
    "start": "279120",
    "end": "281759"
  },
  {
    "text": "match",
    "start": "281759",
    "end": "282320"
  },
  {
    "text": "in the passage for the answer but",
    "start": "282320",
    "end": "285600"
  },
  {
    "text": "for unanswerable questions the model",
    "start": "285600",
    "end": "287919"
  },
  {
    "text": "only has to classify",
    "start": "287919",
    "end": "289919"
  },
  {
    "text": "that the problem is unanswerable this is",
    "start": "289919",
    "end": "293040"
  },
  {
    "text": "not great",
    "start": "293040",
    "end": "293680"
  },
  {
    "text": "as the model can randomly guess that all",
    "start": "293680",
    "end": "296720"
  },
  {
    "text": "questions are unanswerable and get a 50",
    "start": "296720",
    "end": "300800"
  },
  {
    "text": "accuracy we'll deal with this property",
    "start": "300800",
    "end": "304560"
  },
  {
    "text": "of the data further down the line but",
    "start": "304560",
    "end": "307600"
  },
  {
    "text": "for now let's look at how distillation",
    "start": "307600",
    "end": "310080"
  },
  {
    "text": "works",
    "start": "310080",
    "end": "312400"
  },
  {
    "start": "312000",
    "end": "312000"
  },
  {
    "text": "so distillation is a compression",
    "start": "312560",
    "end": "314639"
  },
  {
    "text": "technique where",
    "start": "314639",
    "end": "315759"
  },
  {
    "text": "a large cumbersome model the teacher",
    "start": "315759",
    "end": "318880"
  },
  {
    "text": "model is compressed",
    "start": "318880",
    "end": "320160"
  },
  {
    "text": "into a smaller model the student model",
    "start": "320160",
    "end": "324080"
  },
  {
    "text": "so during distillation the teacher model",
    "start": "324080",
    "end": "326800"
  },
  {
    "text": "is already trained on the data set",
    "start": "326800",
    "end": "329680"
  },
  {
    "text": "and the student model is being trained",
    "start": "329680",
    "end": "332639"
  },
  {
    "text": "through the distillation process",
    "start": "332639",
    "end": "335520"
  },
  {
    "text": "unlike most model training processes",
    "start": "335520",
    "end": "338560"
  },
  {
    "text": "the student model's loss function is a",
    "start": "338560",
    "end": "341039"
  },
  {
    "text": "weighted loss over hard and soft target",
    "start": "341039",
    "end": "343280"
  },
  {
    "text": "losses",
    "start": "343280",
    "end": "344400"
  },
  {
    "text": "where the hard target loss is just your",
    "start": "344400",
    "end": "346320"
  },
  {
    "text": "classic loss function",
    "start": "346320",
    "end": "348160"
  },
  {
    "text": "where the model is trained on the data",
    "start": "348160",
    "end": "350000"
  },
  {
    "text": "set and the soft target loss is this",
    "start": "350000",
    "end": "352320"
  },
  {
    "text": "added component",
    "start": "352320",
    "end": "353600"
  },
  {
    "text": "that allows the student to learn",
    "start": "353600",
    "end": "355520"
  },
  {
    "text": "properties that the teacher model has",
    "start": "355520",
    "end": "357360"
  },
  {
    "text": "already learned",
    "start": "357360",
    "end": "359120"
  },
  {
    "text": "so by combining both types of loss",
    "start": "359120",
    "end": "361039"
  },
  {
    "text": "functions the student uses this",
    "start": "361039",
    "end": "363039"
  },
  {
    "text": "information to generalize",
    "start": "363039",
    "end": "365759"
  },
  {
    "text": "the same way as the teacher model and",
    "start": "365759",
    "end": "369039"
  },
  {
    "text": "reach higher model performance than if",
    "start": "369039",
    "end": "371280"
  },
  {
    "text": "it were to be",
    "start": "371280",
    "end": "372400"
  },
  {
    "text": "trained from scratch so overall the goal",
    "start": "372400",
    "end": "375440"
  },
  {
    "text": "of distillation",
    "start": "375440",
    "end": "376560"
  },
  {
    "text": "is to get a trained student model that",
    "start": "376560",
    "end": "378800"
  },
  {
    "text": "is smaller than the teacher",
    "start": "378800",
    "end": "380880"
  },
  {
    "text": "and performs strongly on the data set",
    "start": "380880",
    "end": "385039"
  },
  {
    "start": "385000",
    "end": "385000"
  },
  {
    "text": "we'll use distillation as our",
    "start": "385840",
    "end": "387440"
  },
  {
    "text": "compression technique and run it",
    "start": "387440",
    "end": "389360"
  },
  {
    "text": "multiple times with different",
    "start": "389360",
    "end": "391600"
  },
  {
    "text": "student model architectures our teacher",
    "start": "391600",
    "end": "394319"
  },
  {
    "text": "model is bert",
    "start": "394319",
    "end": "396080"
  },
  {
    "text": "pre-trained and fine-tuned for squad 2",
    "start": "396080",
    "end": "398960"
  },
  {
    "text": "and we perform",
    "start": "398960",
    "end": "400400"
  },
  {
    "text": "an architecture search during our",
    "start": "400400",
    "end": "402560"
  },
  {
    "text": "optimization process",
    "start": "402560",
    "end": "404080"
  },
  {
    "text": "to define the student model for each",
    "start": "404080",
    "end": "406560"
  },
  {
    "text": "distillation cycle",
    "start": "406560",
    "end": "408960"
  },
  {
    "text": "due to how distillation works we also",
    "start": "408960",
    "end": "412080"
  },
  {
    "text": "expect the student model to have learned",
    "start": "412080",
    "end": "414160"
  },
  {
    "text": "properties",
    "start": "414160",
    "end": "415440"
  },
  {
    "text": "from the teacher model that it would not",
    "start": "415440",
    "end": "417280"
  },
  {
    "text": "have been able to learn",
    "start": "417280",
    "end": "418720"
  },
  {
    "text": "on its own and a quick shout out to",
    "start": "418720",
    "end": "421280"
  },
  {
    "text": "hugging face",
    "start": "421280",
    "end": "422080"
  },
  {
    "text": "without their transformers package and",
    "start": "422080",
    "end": "424000"
  },
  {
    "text": "prior research on distilbert",
    "start": "424000",
    "end": "426080"
  },
  {
    "text": "this project would not have been",
    "start": "426080",
    "end": "427360"
  },
  {
    "text": "possible so now that we've defined our",
    "start": "427360",
    "end": "430000"
  },
  {
    "text": "distillation process",
    "start": "430000",
    "end": "431520"
  },
  {
    "text": "at a high level let's look at how we're",
    "start": "431520",
    "end": "434080"
  },
  {
    "text": "going to define the student model",
    "start": "434080",
    "end": "437840"
  },
  {
    "start": "437000",
    "end": "437000"
  },
  {
    "text": "we define the student model's",
    "start": "438319",
    "end": "439599"
  },
  {
    "text": "architecture through suggestions from",
    "start": "439599",
    "end": "441440"
  },
  {
    "text": "segat",
    "start": "441440",
    "end": "442240"
  },
  {
    "text": "and as much as we can we seed the model",
    "start": "442240",
    "end": "445199"
  },
  {
    "text": "with pre-trained weights",
    "start": "445199",
    "end": "446800"
  },
  {
    "text": "from distilbert trained on the toronto",
    "start": "446800",
    "end": "450240"
  },
  {
    "text": "book corpus",
    "start": "450240",
    "end": "451360"
  },
  {
    "text": "and english wikipedia so now that we've",
    "start": "451360",
    "end": "454160"
  },
  {
    "text": "defined our distillation process",
    "start": "454160",
    "end": "456080"
  },
  {
    "text": "let's look at what our baseline looks",
    "start": "456080",
    "end": "457520"
  },
  {
    "text": "like",
    "start": "457520",
    "end": "459759"
  },
  {
    "start": "460000",
    "end": "460000"
  },
  {
    "text": "for the baseline we use the student",
    "start": "460080",
    "end": "462960"
  },
  {
    "text": "model architecture",
    "start": "462960",
    "end": "464000"
  },
  {
    "text": "from the distilbert paper the",
    "start": "464000",
    "end": "466319"
  },
  {
    "text": "distillation process uses",
    "start": "466319",
    "end": "468160"
  },
  {
    "text": "a low temperature value and equally",
    "start": "468160",
    "end": "470960"
  },
  {
    "text": "weighted loss function across the hard",
    "start": "470960",
    "end": "472960"
  },
  {
    "text": "and soft targets",
    "start": "472960",
    "end": "474639"
  },
  {
    "text": "and the sgd parameters used are also the",
    "start": "474639",
    "end": "477599"
  },
  {
    "text": "defaults from the distilled",
    "start": "477599",
    "end": "478879"
  },
  {
    "text": "paper",
    "start": "478879",
    "end": "481199"
  },
  {
    "start": "482000",
    "end": "482000"
  },
  {
    "text": "as a result our baseline has around 66",
    "start": "482000",
    "end": "485280"
  },
  {
    "text": "million",
    "start": "485280",
    "end": "486000"
  },
  {
    "text": "chainable parameters and reaches a 67",
    "start": "486000",
    "end": "489759"
  },
  {
    "text": "accuracy on squad 2.",
    "start": "489759",
    "end": "493039"
  },
  {
    "text": "so by optimizing this distillation",
    "start": "493039",
    "end": "495919"
  },
  {
    "text": "process we're going to see if we can",
    "start": "495919",
    "end": "498080"
  },
  {
    "text": "beat",
    "start": "498080",
    "end": "498800"
  },
  {
    "text": "the baseline's accuracy and come up with",
    "start": "498800",
    "end": "501680"
  },
  {
    "text": "a student architecture",
    "start": "501680",
    "end": "503440"
  },
  {
    "text": "that's smaller than 66 million",
    "start": "503440",
    "end": "505840"
  },
  {
    "text": "parameters",
    "start": "505840",
    "end": "507759"
  },
  {
    "text": "so let's take a look at our optimization",
    "start": "507759",
    "end": "509199"
  },
  {
    "text": "process",
    "start": "509199",
    "end": "511599"
  },
  {
    "start": "511000",
    "end": "511000"
  },
  {
    "text": "as i said earlier we're going to use",
    "start": "511919",
    "end": "513680"
  },
  {
    "text": "sigops hpo solution",
    "start": "513680",
    "end": "515919"
  },
  {
    "text": "and specifically multimetric patient",
    "start": "515919",
    "end": "519360"
  },
  {
    "text": "optimization",
    "start": "519360",
    "end": "520240"
  },
  {
    "text": "to optimize the distillation process and",
    "start": "520240",
    "end": "523440"
  },
  {
    "text": "perform an",
    "start": "523440",
    "end": "524080"
  },
  {
    "text": "architect architecture search",
    "start": "524080",
    "end": "526080"
  },
  {
    "text": "simultaneously",
    "start": "526080",
    "end": "528240"
  },
  {
    "text": "so with this hyper parameter",
    "start": "528240",
    "end": "530399"
  },
  {
    "text": "optimization technique",
    "start": "530399",
    "end": "532080"
  },
  {
    "text": "we're able to optimize for two competing",
    "start": "532080",
    "end": "534800"
  },
  {
    "text": "metrics",
    "start": "534800",
    "end": "535680"
  },
  {
    "text": "at the same time and at the end of the",
    "start": "535680",
    "end": "538480"
  },
  {
    "text": "optimization process",
    "start": "538480",
    "end": "540000"
  },
  {
    "text": "it'll populate a pareto frontier",
    "start": "540000",
    "end": "543920"
  },
  {
    "text": "so each point on the frontier is an",
    "start": "543920",
    "end": "546560"
  },
  {
    "text": "optimal trade-off point where you cannot",
    "start": "546560",
    "end": "548800"
  },
  {
    "text": "improve",
    "start": "548800",
    "end": "549920"
  },
  {
    "text": "in one competing metric without",
    "start": "549920",
    "end": "552320"
  },
  {
    "text": "sacrificing the other",
    "start": "552320",
    "end": "555600"
  },
  {
    "text": "more concretely what that means for us",
    "start": "556800",
    "end": "559519"
  },
  {
    "text": "is that",
    "start": "559519",
    "end": "560320"
  },
  {
    "text": "we'll be concurrently optimizing for",
    "start": "560320",
    "end": "563120"
  },
  {
    "text": "model performance",
    "start": "563120",
    "end": "564480"
  },
  {
    "text": "versus model size where we want to",
    "start": "564480",
    "end": "567519"
  },
  {
    "text": "increase",
    "start": "567519",
    "end": "568080"
  },
  {
    "text": "model performance and decrease model",
    "start": "568080",
    "end": "570720"
  },
  {
    "text": "size",
    "start": "570720",
    "end": "571279"
  },
  {
    "text": "of the student model and on the graph we",
    "start": "571279",
    "end": "574640"
  },
  {
    "text": "see again",
    "start": "574640",
    "end": "575600"
  },
  {
    "text": "the baseline values for each metric that",
    "start": "575600",
    "end": "578720"
  },
  {
    "text": "we're trying to beat",
    "start": "578720",
    "end": "581439"
  },
  {
    "start": "582000",
    "end": "582000"
  },
  {
    "text": "as we already know the squad 2 data set",
    "start": "582720",
    "end": "585600"
  },
  {
    "text": "is split",
    "start": "585600",
    "end": "586800"
  },
  {
    "text": "across answerable and unanswerable",
    "start": "586800",
    "end": "589200"
  },
  {
    "text": "questions",
    "start": "589200",
    "end": "590880"
  },
  {
    "text": "this just means that if the model is",
    "start": "590880",
    "end": "593120"
  },
  {
    "text": "trained poorly",
    "start": "593120",
    "end": "594560"
  },
  {
    "text": "it's easy for it to classify everything",
    "start": "594560",
    "end": "597360"
  },
  {
    "text": "as",
    "start": "597360",
    "end": "597839"
  },
  {
    "text": "unanswerable and randomly be correct 50",
    "start": "597839",
    "end": "601120"
  },
  {
    "text": "of the time there are a couple ways to",
    "start": "601120",
    "end": "603360"
  },
  {
    "text": "deal with this we could",
    "start": "603360",
    "end": "604880"
  },
  {
    "text": "create a composite metric that better",
    "start": "604880",
    "end": "607360"
  },
  {
    "text": "measures total accuracy",
    "start": "607360",
    "end": "609600"
  },
  {
    "text": "or use metric thresholds because",
    "start": "609600",
    "end": "613600"
  },
  {
    "text": "composite metrics are difficult to",
    "start": "613600",
    "end": "615200"
  },
  {
    "text": "create we chose to set",
    "start": "615200",
    "end": "617360"
  },
  {
    "text": "a metric threshold at 50 this informs",
    "start": "617360",
    "end": "621120"
  },
  {
    "text": "the optimizer to focus its efforts on",
    "start": "621120",
    "end": "623360"
  },
  {
    "text": "parameter spaces that result",
    "start": "623360",
    "end": "625200"
  },
  {
    "text": "in model accuracy over 50",
    "start": "625200",
    "end": "628320"
  },
  {
    "text": "and we successfully avoid configurations",
    "start": "628320",
    "end": "631200"
  },
  {
    "text": "where the model",
    "start": "631200",
    "end": "632560"
  },
  {
    "text": "is randomly guessing",
    "start": "632560",
    "end": "635680"
  },
  {
    "start": "636000",
    "end": "636000"
  },
  {
    "text": "so what are we tuning we'll be tuning",
    "start": "636959",
    "end": "640240"
  },
  {
    "text": "training parameters including",
    "start": "640240",
    "end": "643279"
  },
  {
    "text": "sgd batch size and weight initialization",
    "start": "643279",
    "end": "648240"
  },
  {
    "text": "we'll be training architecture",
    "start": "648240",
    "end": "649680"
  },
  {
    "text": "parameters including",
    "start": "649680",
    "end": "652079"
  },
  {
    "text": "the number of transformer blocks the",
    "start": "652079",
    "end": "654160"
  },
  {
    "text": "number of attention heads",
    "start": "654160",
    "end": "656000"
  },
  {
    "text": "attention head pruning and dropouts for",
    "start": "656000",
    "end": "658640"
  },
  {
    "text": "the network",
    "start": "658640",
    "end": "660480"
  },
  {
    "text": "and we'll be tuning distillation",
    "start": "660480",
    "end": "662480"
  },
  {
    "text": "parameters for",
    "start": "662480",
    "end": "664880"
  },
  {
    "text": "temperature and the weights for the soft",
    "start": "664880",
    "end": "667760"
  },
  {
    "text": "and hard target loss components",
    "start": "667760",
    "end": "670000"
  },
  {
    "text": "so at the end of this optimization",
    "start": "670000",
    "end": "671680"
  },
  {
    "text": "experiment our pareto frontier",
    "start": "671680",
    "end": "674160"
  },
  {
    "text": "will be optimal sets of model",
    "start": "674160",
    "end": "676800"
  },
  {
    "text": "architecture",
    "start": "676800",
    "end": "677920"
  },
  {
    "text": "and hyperparameter configurations",
    "start": "677920",
    "end": "680959"
  },
  {
    "text": "where we cannot improve in size without",
    "start": "680959",
    "end": "683920"
  },
  {
    "text": "sacrificing performance",
    "start": "683920",
    "end": "685760"
  },
  {
    "text": "and vice versa",
    "start": "685760",
    "end": "689839"
  },
  {
    "start": "690000",
    "end": "690000"
  },
  {
    "text": "this is just an overview of our",
    "start": "690640",
    "end": "692160"
  },
  {
    "text": "optimization cycle",
    "start": "692160",
    "end": "693680"
  },
  {
    "text": "cygoft provides distillation",
    "start": "693680",
    "end": "695839"
  },
  {
    "text": "architecture",
    "start": "695839",
    "end": "697360"
  },
  {
    "text": "and the other hyperparameter suggestions",
    "start": "697360",
    "end": "699760"
  },
  {
    "text": "we create the student model",
    "start": "699760",
    "end": "702079"
  },
  {
    "text": "and run the distillation process given",
    "start": "702079",
    "end": "704480"
  },
  {
    "text": "these parameters",
    "start": "704480",
    "end": "706000"
  },
  {
    "text": "the resulting trained student model",
    "start": "706000",
    "end": "708880"
  },
  {
    "text": "reports back",
    "start": "708880",
    "end": "709760"
  },
  {
    "text": "its validation performance and size",
    "start": "709760",
    "end": "712959"
  },
  {
    "text": "ziggop then takes these performance",
    "start": "712959",
    "end": "714880"
  },
  {
    "text": "metrics and suggests the next set of",
    "start": "714880",
    "end": "717279"
  },
  {
    "text": "parameters",
    "start": "717279",
    "end": "718639"
  },
  {
    "text": "and we continue in this loop-like",
    "start": "718639",
    "end": "720320"
  },
  {
    "text": "fashion until the end of the experiment",
    "start": "720320",
    "end": "724720"
  },
  {
    "start": "726000",
    "end": "726000"
  },
  {
    "text": "in order to conduct this experiment we",
    "start": "727600",
    "end": "729519"
  },
  {
    "text": "use ray to orchestrate our ec2 cluster",
    "start": "729519",
    "end": "733279"
  },
  {
    "text": "ray manages the cluster orchestration",
    "start": "733279",
    "end": "735600"
  },
  {
    "text": "and uses sig up for the parallelized",
    "start": "735600",
    "end": "738079"
  },
  {
    "text": "bayesian optimization algorithm and we",
    "start": "738079",
    "end": "740880"
  },
  {
    "text": "run our tuning process in parallel",
    "start": "740880",
    "end": "742800"
  },
  {
    "text": "across 20 ec2 instances",
    "start": "742800",
    "end": "746720"
  },
  {
    "start": "747000",
    "end": "747000"
  },
  {
    "text": "so this is what the integration between",
    "start": "747440",
    "end": "749200"
  },
  {
    "text": "sig opt and ray looks like",
    "start": "749200",
    "end": "750639"
  },
  {
    "text": "the native ray tune sigop integration",
    "start": "750639",
    "end": "753519"
  },
  {
    "text": "currently doesn't include our",
    "start": "753519",
    "end": "754959"
  },
  {
    "text": "advanced hpo solutions but due to the",
    "start": "754959",
    "end": "758000"
  },
  {
    "text": "modularity of ray and the modularity of",
    "start": "758000",
    "end": "760079"
  },
  {
    "text": "sigopp it was",
    "start": "760079",
    "end": "760959"
  },
  {
    "text": "really easy to integrate our multimetric",
    "start": "760959",
    "end": "764240"
  },
  {
    "text": "optimization",
    "start": "764240",
    "end": "765440"
  },
  {
    "text": "with raytune's orchestration framework",
    "start": "765440",
    "end": "767920"
  },
  {
    "text": "and i've highlighted",
    "start": "767920",
    "end": "769120"
  },
  {
    "text": "a couple of key integration points",
    "start": "769120",
    "end": "770839"
  },
  {
    "text": "specifically how to create a sigath",
    "start": "770839",
    "end": "773040"
  },
  {
    "text": "experiment within the retune framework",
    "start": "773040",
    "end": "776000"
  },
  {
    "text": "and how to get a set of suggestions from",
    "start": "776000",
    "end": "778399"
  },
  {
    "text": "segat",
    "start": "778399",
    "end": "779680"
  },
  {
    "text": "during runtime so to run the tuning",
    "start": "779680",
    "end": "783680"
  },
  {
    "text": "we use the first and first out scheduler",
    "start": "783680",
    "end": "785920"
  },
  {
    "text": "from rain tune and rely on psygopt",
    "start": "785920",
    "end": "788800"
  },
  {
    "text": "to schedule the hyperprimary suggestions",
    "start": "788800",
    "end": "791920"
  },
  {
    "text": "themselves",
    "start": "791920",
    "end": "794480"
  },
  {
    "text": "so what were results this is our",
    "start": "795760",
    "end": "798880"
  },
  {
    "text": "resulting parader frontier",
    "start": "798880",
    "end": "800880"
  },
  {
    "text": "the yellow dots are the optimal points",
    "start": "800880",
    "end": "803120"
  },
  {
    "text": "and the pink dot",
    "start": "803120",
    "end": "804639"
  },
  {
    "text": "is our baseline by using the frontier",
    "start": "804639",
    "end": "809200"
  },
  {
    "text": "we're able to understand the trade-offs",
    "start": "809200",
    "end": "810959"
  },
  {
    "text": "between model performance in size during",
    "start": "810959",
    "end": "814320"
  },
  {
    "text": "distillation",
    "start": "814320",
    "end": "815519"
  },
  {
    "text": "we're also able to identify architecture",
    "start": "815519",
    "end": "818800"
  },
  {
    "text": "configurations",
    "start": "818800",
    "end": "820160"
  },
  {
    "text": "for the student model that result in",
    "start": "820160",
    "end": "822160"
  },
  {
    "text": "these three trade-offs",
    "start": "822160",
    "end": "824560"
  },
  {
    "text": "essentially instead of relying on a",
    "start": "824560",
    "end": "827199"
  },
  {
    "text": "single architecture performing",
    "start": "827199",
    "end": "829120"
  },
  {
    "text": "well for question answering we're able",
    "start": "829120",
    "end": "832160"
  },
  {
    "text": "to leverage",
    "start": "832160",
    "end": "833360"
  },
  {
    "text": "these trade-offs and choose from a set",
    "start": "833360",
    "end": "835519"
  },
  {
    "text": "of architectures",
    "start": "835519",
    "end": "838480"
  },
  {
    "start": "839000",
    "end": "839000"
  },
  {
    "text": "these are just a few optimal points i",
    "start": "839199",
    "end": "841279"
  },
  {
    "text": "wanted to highlight",
    "start": "841279",
    "end": "843839"
  },
  {
    "text": "on the far left we have our smallest",
    "start": "844720",
    "end": "847519"
  },
  {
    "text": "student model architecture",
    "start": "847519",
    "end": "849519"
  },
  {
    "text": "that performs as well as the baseline",
    "start": "849519",
    "end": "852560"
  },
  {
    "text": "and on the far right we have our best",
    "start": "852560",
    "end": "854959"
  },
  {
    "text": "performing model that is slightly larger",
    "start": "854959",
    "end": "857199"
  },
  {
    "text": "than the baseline",
    "start": "857199",
    "end": "860079"
  },
  {
    "start": "861000",
    "end": "861000"
  },
  {
    "text": "here are the respective architectures",
    "start": "861839",
    "end": "864000"
  },
  {
    "text": "for those optimal points",
    "start": "864000",
    "end": "866560"
  },
  {
    "text": "some common features found between the",
    "start": "866560",
    "end": "869199"
  },
  {
    "text": "optimal configurations",
    "start": "869199",
    "end": "870639"
  },
  {
    "text": "include the student model preferring",
    "start": "870639",
    "end": "874800"
  },
  {
    "text": "no drop out and an emphasis on the soft",
    "start": "874800",
    "end": "877199"
  },
  {
    "text": "target loss",
    "start": "877199",
    "end": "878560"
  },
  {
    "text": "and we see that the architecture is",
    "start": "878560",
    "end": "880399"
  },
  {
    "text": "compressed by reducing",
    "start": "880399",
    "end": "882480"
  },
  {
    "text": "the number of layers more often than",
    "start": "882480",
    "end": "885199"
  },
  {
    "text": "tuning",
    "start": "885199",
    "end": "886000"
  },
  {
    "text": "then sorry then pruning the attention",
    "start": "886000",
    "end": "888399"
  },
  {
    "text": "heads",
    "start": "888399",
    "end": "889680"
  },
  {
    "text": "what we see here is that by leveraging",
    "start": "889680",
    "end": "892800"
  },
  {
    "text": "multi-metric basin optimization to",
    "start": "892800",
    "end": "895680"
  },
  {
    "text": "conduct",
    "start": "895680",
    "end": "896480"
  },
  {
    "text": "an architecture and hyperparameter",
    "start": "896480",
    "end": "898639"
  },
  {
    "text": "research during a compression process",
    "start": "898639",
    "end": "901440"
  },
  {
    "text": "we're able to identify sets",
    "start": "901440",
    "end": "904560"
  },
  {
    "text": "sets of viable models for our specific",
    "start": "904560",
    "end": "907120"
  },
  {
    "text": "problem",
    "start": "907120",
    "end": "908399"
  },
  {
    "text": "and we're able to choose a model",
    "start": "908399",
    "end": "910160"
  },
  {
    "text": "architecture that best suits our needs",
    "start": "910160",
    "end": "914319"
  },
  {
    "text": "so let's take a quick look at the",
    "start": "916320",
    "end": "918880"
  },
  {
    "text": "experiment dashboard",
    "start": "918880",
    "end": "920560"
  },
  {
    "text": "so this is our experiment analysis page",
    "start": "920560",
    "end": "923279"
  },
  {
    "text": "here we see",
    "start": "923279",
    "end": "925199"
  },
  {
    "text": "the pareto frontier of the experiment",
    "start": "925199",
    "end": "928480"
  },
  {
    "text": "we see the metric threshold that's been",
    "start": "928480",
    "end": "931040"
  },
  {
    "text": "set at 50",
    "start": "931040",
    "end": "933600"
  },
  {
    "text": "we're able to see which correlations",
    "start": "933600",
    "end": "937680"
  },
  {
    "text": "happen or exist between a metric",
    "start": "937680",
    "end": "940800"
  },
  {
    "text": "and a parameter we're also able to",
    "start": "940800",
    "end": "944880"
  },
  {
    "text": "understand",
    "start": "944880",
    "end": "946160"
  },
  {
    "text": "which parameters most significant",
    "start": "946160",
    "end": "948880"
  },
  {
    "text": "significantly affect",
    "start": "948880",
    "end": "950560"
  },
  {
    "text": "each metric so for accuracy we see",
    "start": "950560",
    "end": "953839"
  },
  {
    "text": "number of layers and learning rate",
    "start": "953839",
    "end": "956000"
  },
  {
    "text": "in the top two and for number of",
    "start": "956000",
    "end": "958959"
  },
  {
    "text": "parameters its number of layers and",
    "start": "958959",
    "end": "960720"
  },
  {
    "text": "number of heads which is",
    "start": "960720",
    "end": "962959"
  },
  {
    "text": "expected and then here with our parallel",
    "start": "962959",
    "end": "967040"
  },
  {
    "text": "coordinates chart",
    "start": "967040",
    "end": "968079"
  },
  {
    "text": "we're able to really understand if there",
    "start": "968079",
    "end": "970880"
  },
  {
    "text": "are",
    "start": "970880",
    "end": "971199"
  },
  {
    "text": "and what ranges sweet spots exist",
    "start": "971199",
    "end": "975279"
  },
  {
    "text": "for all the parameter values as well as",
    "start": "975279",
    "end": "978639"
  },
  {
    "text": "what are the correlations that we can",
    "start": "978639",
    "end": "980240"
  },
  {
    "text": "identify amongst",
    "start": "980240",
    "end": "982240"
  },
  {
    "text": "all the metrics and all of the",
    "start": "982240",
    "end": "984000"
  },
  {
    "text": "parameters if",
    "start": "984000",
    "end": "985440"
  },
  {
    "text": "it exists",
    "start": "985440",
    "end": "988000"
  },
  {
    "text": "so this is all great but we really want",
    "start": "995120",
    "end": "997440"
  },
  {
    "text": "to know",
    "start": "997440",
    "end": "998480"
  },
  {
    "text": "was the model able to answer questions",
    "start": "998480",
    "end": "1001199"
  },
  {
    "text": "so let's take a look at our best",
    "start": "1001199",
    "end": "1002639"
  },
  {
    "text": "performing model",
    "start": "1002639",
    "end": "1005440"
  },
  {
    "text": "our best affirming model is at around a",
    "start": "1005600",
    "end": "1008480"
  },
  {
    "text": "70",
    "start": "1008480",
    "end": "1009519"
  },
  {
    "text": "accuracy as we see in this graph",
    "start": "1009519",
    "end": "1012480"
  },
  {
    "text": "depending on the category",
    "start": "1012480",
    "end": "1014240"
  },
  {
    "text": "the model performs better or worse",
    "start": "1014240",
    "end": "1017360"
  },
  {
    "text": "with topics such as the yuan dynasty",
    "start": "1017360",
    "end": "1021040"
  },
  {
    "text": "warsaw and steam engine being more",
    "start": "1021040",
    "end": "1024079"
  },
  {
    "text": "challenging than others",
    "start": "1024079",
    "end": "1027438"
  },
  {
    "start": "1028000",
    "end": "1028000"
  },
  {
    "text": "to understand really what's going on",
    "start": "1028400",
    "end": "1031280"
  },
  {
    "text": "we're going to categorize",
    "start": "1031280",
    "end": "1032600"
  },
  {
    "text": "misclassifications",
    "start": "1032600",
    "end": "1033760"
  },
  {
    "text": "into four different categories mostly",
    "start": "1033760",
    "end": "1037199"
  },
  {
    "text": "right",
    "start": "1037199",
    "end": "1038079"
  },
  {
    "text": "the model is off by just a little by",
    "start": "1038079",
    "end": "1040400"
  },
  {
    "text": "either including more context words or",
    "start": "1040400",
    "end": "1042400"
  },
  {
    "text": "things like punctuation",
    "start": "1042400",
    "end": "1044558"
  },
  {
    "text": "mostly wrong the model has gotten the",
    "start": "1044559",
    "end": "1046480"
  },
  {
    "text": "answer completely wrong",
    "start": "1046480",
    "end": "1048160"
  },
  {
    "text": "label no answer the model predicts an",
    "start": "1048160",
    "end": "1051200"
  },
  {
    "text": "answer despite it being unanswerable",
    "start": "1051200",
    "end": "1054400"
  },
  {
    "text": "and label has answer where the model",
    "start": "1054400",
    "end": "1057919"
  },
  {
    "text": "predicts",
    "start": "1057919",
    "end": "1058559"
  },
  {
    "text": "no answer when the question is",
    "start": "1058559",
    "end": "1061280"
  },
  {
    "text": "answerable",
    "start": "1061280",
    "end": "1063520"
  },
  {
    "text": "although some categories have different",
    "start": "1063520",
    "end": "1066320"
  },
  {
    "text": "majority",
    "start": "1066320",
    "end": "1067080"
  },
  {
    "text": "misclassifications across the categories",
    "start": "1067080",
    "end": "1070000"
  },
  {
    "text": "most of the errors we saw",
    "start": "1070000",
    "end": "1071840"
  },
  {
    "text": "are labeled no answer which means that",
    "start": "1071840",
    "end": "1074160"
  },
  {
    "text": "the model was",
    "start": "1074160",
    "end": "1074960"
  },
  {
    "text": "answering questions that are",
    "start": "1074960",
    "end": "1077120"
  },
  {
    "text": "unanswerable",
    "start": "1077120",
    "end": "1079120"
  },
  {
    "text": "this is interesting because going back",
    "start": "1079120",
    "end": "1081120"
  },
  {
    "text": "to why we set the metric thresholds we",
    "start": "1081120",
    "end": "1083360"
  },
  {
    "text": "were really",
    "start": "1083360",
    "end": "1084000"
  },
  {
    "text": "concerned about the model randomly",
    "start": "1084000",
    "end": "1086480"
  },
  {
    "text": "predicting that everything is",
    "start": "1086480",
    "end": "1087919"
  },
  {
    "text": "unanswerable",
    "start": "1087919",
    "end": "1089840"
  },
  {
    "text": "so at least it swung the other way so",
    "start": "1089840",
    "end": "1092799"
  },
  {
    "text": "let's take a closer look",
    "start": "1092799",
    "end": "1095120"
  },
  {
    "text": "as to why the model might be doing this",
    "start": "1095120",
    "end": "1099679"
  },
  {
    "start": "1100000",
    "end": "1100000"
  },
  {
    "text": "so the section on warsaw is pretty",
    "start": "1100720",
    "end": "1102799"
  },
  {
    "text": "representative",
    "start": "1102799",
    "end": "1104480"
  },
  {
    "text": "of a lot of the categories and passages",
    "start": "1104480",
    "end": "1107840"
  },
  {
    "text": "that are",
    "start": "1107840",
    "end": "1108799"
  },
  {
    "text": "present in the data set so this section",
    "start": "1108799",
    "end": "1111520"
  },
  {
    "text": "spans a long period of time",
    "start": "1111520",
    "end": "1114400"
  },
  {
    "text": "with complicated and convoluted",
    "start": "1114400",
    "end": "1117039"
  },
  {
    "text": "historical events",
    "start": "1117039",
    "end": "1118640"
  },
  {
    "text": "we see very similar nouns in each",
    "start": "1118640",
    "end": "1121600"
  },
  {
    "text": "section",
    "start": "1121600",
    "end": "1122880"
  },
  {
    "text": "take on a different role so the main",
    "start": "1122880",
    "end": "1125360"
  },
  {
    "text": "entity",
    "start": "1125360",
    "end": "1126160"
  },
  {
    "text": "the city of warsaw goes through many",
    "start": "1126160",
    "end": "1128640"
  },
  {
    "text": "transitions",
    "start": "1128640",
    "end": "1130240"
  },
  {
    "text": "and many different turns are used to",
    "start": "1130240",
    "end": "1132080"
  },
  {
    "text": "describe the same place",
    "start": "1132080",
    "end": "1134720"
  },
  {
    "text": "in addition to that the questions are",
    "start": "1134720",
    "end": "1136720"
  },
  {
    "text": "tricky",
    "start": "1136720",
    "end": "1138559"
  },
  {
    "text": "and ask about relationships between",
    "start": "1138559",
    "end": "1142080"
  },
  {
    "text": "these overloaded terms so for example in",
    "start": "1142080",
    "end": "1145120"
  },
  {
    "text": "the passage above",
    "start": "1145120",
    "end": "1146640"
  },
  {
    "text": "one answerable question is whose army",
    "start": "1146640",
    "end": "1149760"
  },
  {
    "text": "liberated warsaw versus one unanswerable",
    "start": "1149760",
    "end": "1153360"
  },
  {
    "text": "question",
    "start": "1153360",
    "end": "1154000"
  },
  {
    "text": "is whose army liberated duchy",
    "start": "1154000",
    "end": "1158000"
  },
  {
    "text": "where the text says the duchy of warsaw",
    "start": "1158000",
    "end": "1162160"
  },
  {
    "text": "and the model guesses napoleon for both",
    "start": "1162160",
    "end": "1165440"
  },
  {
    "text": "so these entities are related but have",
    "start": "1165440",
    "end": "1168880"
  },
  {
    "text": "nuances between them that the model",
    "start": "1168880",
    "end": "1170799"
  },
  {
    "text": "isn't able to pick up",
    "start": "1170799",
    "end": "1172400"
  },
  {
    "text": "it's not able to differentiate between",
    "start": "1172400",
    "end": "1174559"
  },
  {
    "text": "warsaw",
    "start": "1174559",
    "end": "1176320"
  },
  {
    "text": "and the duchy of warsaw or really",
    "start": "1176320",
    "end": "1178960"
  },
  {
    "text": "understand that these",
    "start": "1178960",
    "end": "1180160"
  },
  {
    "text": "differences are due to a temporal",
    "start": "1180160",
    "end": "1182320"
  },
  {
    "text": "transition",
    "start": "1182320",
    "end": "1184400"
  },
  {
    "text": "that is described in the passage and",
    "start": "1184400",
    "end": "1187360"
  },
  {
    "text": "many",
    "start": "1187360",
    "end": "1187840"
  },
  {
    "text": "missed questions similarly follow this",
    "start": "1187840",
    "end": "1190640"
  },
  {
    "text": "pattern",
    "start": "1190640",
    "end": "1191200"
  },
  {
    "text": "and it's definitely something to look",
    "start": "1191200",
    "end": "1192880"
  },
  {
    "text": "into for future work",
    "start": "1192880",
    "end": "1196640"
  },
  {
    "start": "1197000",
    "end": "1197000"
  },
  {
    "text": "so why does this all matter what we saw",
    "start": "1198640",
    "end": "1202080"
  },
  {
    "text": "through",
    "start": "1202080",
    "end": "1202720"
  },
  {
    "text": "this use case project",
    "start": "1202720",
    "end": "1205760"
  },
  {
    "text": "is that by using scalable and",
    "start": "1205760",
    "end": "1208640"
  },
  {
    "text": "intelligent hyperparameter optimization",
    "start": "1208640",
    "end": "1211760"
  },
  {
    "text": "we're able to easily understand",
    "start": "1211760",
    "end": "1213919"
  },
  {
    "text": "trade-offs made",
    "start": "1213919",
    "end": "1215280"
  },
  {
    "text": "during compression and by understanding",
    "start": "1215280",
    "end": "1219679"
  },
  {
    "text": "these trade-offs we're able to choose a",
    "start": "1219679",
    "end": "1222320"
  },
  {
    "text": "model architecture",
    "start": "1222320",
    "end": "1224320"
  },
  {
    "text": "that best suits our needs from a vast",
    "start": "1224320",
    "end": "1227520"
  },
  {
    "text": "set",
    "start": "1227520",
    "end": "1228159"
  },
  {
    "text": "of optimal and viable architectures and",
    "start": "1228159",
    "end": "1232840"
  },
  {
    "text": "hyperparameters",
    "start": "1232840",
    "end": "1235840"
  },
  {
    "text": "for more on this project please read the",
    "start": "1237760",
    "end": "1240320"
  },
  {
    "text": "full work on nvidia's dev blog",
    "start": "1240320",
    "end": "1242320"
  },
  {
    "text": "watch our previous webinars um recreate",
    "start": "1242320",
    "end": "1245600"
  },
  {
    "text": "the experiment",
    "start": "1245600",
    "end": "1246400"
  },
  {
    "text": "with the git repo and use the model",
    "start": "1246400",
    "end": "1248880"
  },
  {
    "text": "checkpoints",
    "start": "1248880",
    "end": "1250320"
  },
  {
    "text": "and explore the experiment dashboard",
    "start": "1250320",
    "end": "1254880"
  },
  {
    "text": "and for a limited time you can sign up",
    "start": "1257120",
    "end": "1259679"
  },
  {
    "text": "to use sega for free",
    "start": "1259679",
    "end": "1261360"
  },
  {
    "text": "so if you're interested please join our",
    "start": "1261360",
    "end": "1263760"
  },
  {
    "text": "free beta",
    "start": "1263760",
    "end": "1266480"
  },
  {
    "text": "at the link written",
    "start": "1266880",
    "end": "1270480"
  },
  {
    "text": "below",
    "start": "1270480",
    "end": "1272880"
  },
  {
    "text": "thank you and i'm going to open it up",
    "start": "1274559",
    "end": "1276559"
  },
  {
    "text": "for questions now",
    "start": "1276559",
    "end": "1280799"
  }
]
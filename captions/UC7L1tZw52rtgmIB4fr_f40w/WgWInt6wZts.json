[
  {
    "text": "um hello everyone and Welcome to our real Summit talk how Spotify",
    "start": "4380",
    "end": "9420"
  },
  {
    "text": "um sped up and my research and prototyping with Dre and my name is Kashi I'm a senior engineer at Spotify",
    "start": "9420",
    "end": "16800"
  },
  {
    "text": "it's a machine learning platform team and this is my colleague David and another senior has made by our team",
    "start": "16800",
    "end": "23100"
  },
  {
    "text": "today we are going to share our race story in ml research and model prototyping at Spotify",
    "start": "23100",
    "end": "28740"
  },
  {
    "text": "so machine learning is at the heart of almost everything we do at Spotify it's applications include recommending",
    "start": "28740",
    "end": "35100"
  },
  {
    "text": "personalized content on home page optimizing the ranking results from the search and helping you discover and",
    "start": "35100",
    "end": "42180"
  },
  {
    "text": "explore the new music you haven't listened to before to power ml products at Spotify our team is building and",
    "start": "42180",
    "end": "48420"
  },
  {
    "text": "managing centralized machine learning platform that provides our Engineers with tools and environments to quickly",
    "start": "48420",
    "end": "55260"
  },
  {
    "text": "productionize ml applications our production ml platform internally is",
    "start": "55260",
    "end": "61680"
  },
  {
    "text": "known as qflow platform it has two components a python SDK for building ml",
    "start": "61680",
    "end": "67740"
  },
  {
    "text": "workloads with tfx standardization and several managed kubeflow cluster for ML",
    "start": "67740",
    "end": "72900"
  },
  {
    "text": "pipeline executions for those who don't know and tfx tensorflow extended is a component-based",
    "start": "72900",
    "end": "79380"
  },
  {
    "text": "ml framework for tensorflow ecosystem kubeflow is a set of machine learning toolkits on kubernetes",
    "start": "79380",
    "end": "87618"
  },
  {
    "text": "so keep flow platform as a successful product and Spotify offers a paved away to solve many standardized ml problems",
    "start": "88080",
    "end": "95820"
  },
  {
    "text": "especially for supervised learning on tabular data sets and however when feedback we constantly hear from users",
    "start": "95820",
    "end": "102780"
  },
  {
    "text": "is that tfx is very difficult for ML research and model experimentation",
    "start": "102780",
    "end": "107939"
  },
  {
    "text": "because it's a very opinionated framework and optimized for the ml",
    "start": "107939",
    "end": "113100"
  },
  {
    "text": "production systems eating addition with growing numbers of ml practitioners and ml applications at",
    "start": "113100",
    "end": "120060"
  },
  {
    "text": "Spotify how to provide tools to help our users to solve all kinds of ml problems",
    "start": "120060",
    "end": "126119"
  },
  {
    "text": "become more and more challenging it's a problem of the long tail and tfx component based the solution does not",
    "start": "126119",
    "end": "133379"
  },
  {
    "text": "offer sufficient flexibility and to leverage popular and the state of Arts",
    "start": "133379",
    "end": "138959"
  },
  {
    "text": "ml packages it's a closed ecosystem so it's hard to integrate with other open",
    "start": "138959",
    "end": "145379"
  },
  {
    "text": "source tools to serve broad groups of users and an ideal ml platform should cover",
    "start": "145379",
    "end": "152819"
  },
  {
    "text": "both depths and breaths and offer a wide range of tools to tackle different problems in a scalable maintainable and",
    "start": "152819",
    "end": "159959"
  },
  {
    "text": "enjoyable way a modern complex ml system needs contribution from ml practitioners with",
    "start": "159959",
    "end": "166560"
  },
  {
    "text": "different backgrounds it needs research scientists to prototype and experiment new ideas data engineer to explore and",
    "start": "166560",
    "end": "173400"
  },
  {
    "text": "optimize features a male engineer to implement productionized models and the data science to generalize a B test",
    "start": "173400",
    "end": "180540"
  },
  {
    "text": "results and the backends the engineer to service model in production",
    "start": "180540",
    "end": "185879"
  },
  {
    "text": "our platform should accommodate all their needs so in earlier this year we started",
    "start": "185879",
    "end": "192780"
  },
  {
    "text": "evaluating Ray We Believe with Ray and its broad ecosystem research and data",
    "start": "192780",
    "end": "198300"
  },
  {
    "text": "scientists can access more popular and familiar libraries it can help them quickly start projects build a prototype",
    "start": "198300",
    "end": "206040"
  },
  {
    "text": "and experiment different ideas this example shows how to use attributes",
    "start": "206040",
    "end": "213540"
  },
  {
    "text": "cycle and remote issues how Ray can help our data scientists using their familiar",
    "start": "213540",
    "end": "219900"
  },
  {
    "text": "libraries without a sacrificing the scalability or rewriting a code in order to work on large data set",
    "start": "219900",
    "end": "226799"
  },
  {
    "text": "all they need to do is change the import from pandas to molding dot pandas users",
    "start": "226799",
    "end": "232620"
  },
  {
    "text": "don't need to change their their code and the interactive development experience with the distributed",
    "start": "232620",
    "end": "239519"
  },
  {
    "text": "computing power speeds up the feedback loop and allow user to explore experiment and validate their ideas",
    "start": "239519",
    "end": "248360"
  },
  {
    "text": "so one of our users was able to accelerate their offline evaluation workflow on rain just in two hectates",
    "start": "249180",
    "end": "256500"
  },
  {
    "text": "without any previous rate experience they saw six times speed up in offline",
    "start": "256500",
    "end": "262560"
  },
  {
    "text": "evaluation experiments using moding and the record library on large data sets",
    "start": "262560",
    "end": "267720"
  },
  {
    "text": "with much for models and metrics",
    "start": "267720",
    "end": "271940"
  },
  {
    "text": "and next I would like to show you how Ray simplifies the ml Stacks to speed up the ml development productivity",
    "start": "273180",
    "end": "281940"
  },
  {
    "text": "as you can see a typical tfx pipeline involves several very different layers including tfx Cube flow kubernetes and a",
    "start": "282000",
    "end": "290699"
  },
  {
    "text": "different gcp services when you did write ml workflow they start with tfx DSL by assembling the",
    "start": "290699",
    "end": "298139"
  },
  {
    "text": "components then the workflow is compiled to a kubernetes yaml file for the job submission where in the Bronx each",
    "start": "298139",
    "end": "305340"
  },
  {
    "text": "component follows the specific tfx Logic for the execution it either calls out",
    "start": "305340",
    "end": "311400"
  },
  {
    "text": "gcp service to run the workload or use the kubernetes part for distributed",
    "start": "311400",
    "end": "317100"
  },
  {
    "text": "computing power with this approach um it's great when everything is working",
    "start": "317100",
    "end": "322860"
  },
  {
    "text": "folks can quickly solve the standard problem with previewed components however when it's not working especially",
    "start": "322860",
    "end": "330060"
  },
  {
    "text": "when developing customer logic users spend a lot of time on digging into those logs",
    "start": "330060",
    "end": "336419"
  },
  {
    "text": "from different layers from different Services they are trying to understand where the air is from is the area from",
    "start": "336419",
    "end": "342539"
  },
  {
    "text": "my code either from Q4 part or the TFS components or it's from the data Force",
    "start": "342539",
    "end": "348539"
  },
  {
    "text": "workers or Air Platform users needed to know all those for debugging and to",
    "start": "348539",
    "end": "354240"
  },
  {
    "text": "build their own not it's Logic on top so research and data science need a better tools to",
    "start": "354240",
    "end": "361380"
  },
  {
    "text": "speed up their development productivity so with race unified API for distribute",
    "start": "361380",
    "end": "368100"
  },
  {
    "text": "Computing it's simple and intuitive to configure resource for training prediction and data processing",
    "start": "368100",
    "end": "375360"
  },
  {
    "text": "less kubernetes knowledge is required for research and data scientists all",
    "start": "375360",
    "end": "380759"
  },
  {
    "text": "they need to know is the number of CPUs and gpus for their workload with the",
    "start": "380759",
    "end": "386100"
  },
  {
    "text": "rate 2.0 release by defining a scaling config we can conduct",
    "start": "386100",
    "end": "392580"
  },
  {
    "text": "distribute training for actually booths tensorflow and hacking phase and More in",
    "start": "392580",
    "end": "397680"
  },
  {
    "text": "addition Ray application is a regular Python program and users don't need to learn other Frameworks or different set",
    "start": "397680",
    "end": "404819"
  },
  {
    "text": "of apis or even kubernetes to leverage distributed computing power this",
    "start": "404819",
    "end": "410160"
  },
  {
    "text": "simplifies ml stack so users can spend more time on iterating the actual ml problems",
    "start": "410160",
    "end": "417620"
  },
  {
    "text": "with all those benefits we have discussed pre previously we believe Drake can help us diversify Mr",
    "start": "418319",
    "end": "424860"
  },
  {
    "text": "practitioners and offer you a unified experience for ML model prototyping and",
    "start": "424860",
    "end": "430380"
  },
  {
    "text": "experimentation in a scalable and maintainable enjoyable way and we positioned Ray as a manager",
    "start": "430380",
    "end": "436620"
  },
  {
    "text": "distributor compute platform that enables ml research and experimentation",
    "start": "436620",
    "end": "441660"
  },
  {
    "text": "for non-standardized ML workflows that cannot fit into tfx paradigm",
    "start": "441660",
    "end": "448979"
  },
  {
    "text": "with Ray we envision two major user Journeys for research and data scientists",
    "start": "448979",
    "end": "454199"
  },
  {
    "text": "the first one is for model prototyping and ad hoc experimentation so research",
    "start": "454199",
    "end": "460259"
  },
  {
    "text": "and data scientists even MREs can tackle different problems with the help of user-friendly API and open source",
    "start": "460259",
    "end": "467340"
  },
  {
    "text": "Library the second one is around a supporting production pass for offline batch projection for non-standard ML",
    "start": "467340",
    "end": "474000"
  },
  {
    "text": "workflows user can use rate to prototype and productionize their workflows",
    "start": "474000",
    "end": "480198"
  },
  {
    "text": "to support the above and two user Journeys we have been collaborating with teams to view the pocs on Ray to solve",
    "start": "480780",
    "end": "488099"
  },
  {
    "text": "real Spotify problems pocc included training GN embeddings for podcast",
    "start": "488099",
    "end": "493199"
  },
  {
    "text": "recommendations scaling reinforced learning for radio stations and attributes for a B test",
    "start": "493199",
    "end": "500819"
  },
  {
    "text": "user segment analysis these pocs have formed our initial design for our manager Ray platform it",
    "start": "500819",
    "end": "509400"
  },
  {
    "text": "contains two components the bottom layer is the manager Ray infrastructure built on gke every team",
    "start": "509400",
    "end": "516659"
  },
  {
    "text": "can have their own dedicated namespace to host the direct cluster to run the ray applications",
    "start": "516659",
    "end": "522659"
  },
  {
    "text": "we are using open source Cube Ray to manually cluster in each username space on top of it we also offer Spotify",
    "start": "522659",
    "end": "531200"
  },
  {
    "text": "python SDK for user to interact with our managed Ray infrastructure it also",
    "start": "531200",
    "end": "537420"
  },
  {
    "text": "provides the integration with other ml platform Services Spotify info ecosystems such as metadata experimental",
    "start": "537420",
    "end": "544620"
  },
  {
    "text": "tracking as workflow oxidation and scheduling by leverage a Spotify Ray user can use",
    "start": "544620",
    "end": "551760"
  },
  {
    "text": "popular open source libraries and the community support to build ml application to drive the business impact",
    "start": "551760",
    "end": "558420"
  },
  {
    "text": "as the platform team we own and manage the ray infrastructure and Spotify Ray SDK user and product team they gonna own",
    "start": "558420",
    "end": "566519"
  },
  {
    "text": "the ml applications built already in this quarter we are working on Spotify integration and aiming to",
    "start": "566519",
    "end": "573000"
  },
  {
    "text": "release R5 version in Q4 to broaden the rate adoption at Spotify",
    "start": "573000",
    "end": "578959"
  },
  {
    "text": "so lastly I would like to highlight business impact driven by our POC work with the help of Rey the idea of using",
    "start": "579240",
    "end": "586560"
  },
  {
    "text": "GN for podcast recommendation resulting online tests in less than two and a half months",
    "start": "586560",
    "end": "592380"
  },
  {
    "text": "a daily batch prediction workflow has been productionized with just in two weeks for an A B test at Mau scale",
    "start": "592380",
    "end": "600839"
  },
  {
    "text": "it created a foundation for standardization GN prototyping and Spotify and helped research generate",
    "start": "600839",
    "end": "608279"
  },
  {
    "text": "more ideas and experiments with better modeling experience for reinforced learning Ray unlocked the",
    "start": "608279",
    "end": "615720"
  },
  {
    "text": "performance bottleneck in IO agent training and paved the foundations for upcoming productionizing the offline i o",
    "start": "615720",
    "end": "622260"
  },
  {
    "text": "workflow now I'm going hand over talk to David and he will talk more about Spotify Ray",
    "start": "622260",
    "end": "628860"
  },
  {
    "text": "we have been working on",
    "start": "628860",
    "end": "631820"
  },
  {
    "text": "thanks keshi uh so keshi went over why we're using Ray at Spotify and I'll",
    "start": "637440",
    "end": "644579"
  },
  {
    "text": "go a little bit more into the details of how exactly we're using it um so we had three options that we could",
    "start": "644579",
    "end": "653100"
  },
  {
    "text": "think of one was using a third-party managed service like you know the hosted any scale one",
    "start": "653100",
    "end": "658620"
  },
  {
    "text": "um letting individual teams manage their own underlying infra we just provide some libraries and then lastly was like",
    "start": "658620",
    "end": "664440"
  },
  {
    "text": "a hybrid approach where individual teams would only have to care about their Ray clusters and it would be a centrally",
    "start": "664440",
    "end": "671640"
  },
  {
    "text": "managed multi-tenant infrastructure platform that we provide and so we picked the third option the first option",
    "start": "671640",
    "end": "678120"
  },
  {
    "text": "wasn't so attractive because we have a lot of like internal Spotify stuff and using a third-party hosted service we",
    "start": "678120",
    "end": "684600"
  },
  {
    "text": "still have to build out all those Integrations which are pretty costly and we lose some control over exactly how",
    "start": "684600",
    "end": "690060"
  },
  {
    "text": "the service was run and the second option was not really acceptable for us because we know that a lot of these data",
    "start": "690060",
    "end": "696240"
  },
  {
    "text": "scientists and researchers they their specialty is not infrastructure they don't necessarily know how to run",
    "start": "696240",
    "end": "701760"
  },
  {
    "text": "kubernetes or or just like VMS in general like so we wanted them to be",
    "start": "701760",
    "end": "707220"
  },
  {
    "text": "able to focus on their business pro problems which was modeling experimentation",
    "start": "707220",
    "end": "712320"
  },
  {
    "text": "and so we picked the third one some of the benefits of that are that it centralizes the infrastructure and",
    "start": "712320",
    "end": "717600"
  },
  {
    "text": "Integrations we would have more control over it and could customize it better and again individual teams can just",
    "start": "717600",
    "end": "724500"
  },
  {
    "text": "focus on business problems so how do we deploy Rey we use the kubre",
    "start": "724500",
    "end": "730620"
  },
  {
    "text": "and we deploy it onto kubernetes like keshi said we use gcp a lot so our",
    "start": "730620",
    "end": "735899"
  },
  {
    "text": "kubernetes clusters are all on gke um and right now they're just yeah it's",
    "start": "735899",
    "end": "741899"
  },
  {
    "text": "like a multi-zonal GK cluster we've set up a bunch of different node pools with a bunch of different gpus like t4s and",
    "start": "741899",
    "end": "747600"
  },
  {
    "text": "v100s uh made it so that I could you know scale up to a pretty decent size",
    "start": "747600",
    "end": "753660"
  },
  {
    "text": "um and one of the things we optimized for was just fast container image downloads this is cloud specific but",
    "start": "753660",
    "end": "759600"
  },
  {
    "text": "there's some stuff in GK that makes it so that it's called image streaming your images can just download a lot faster",
    "start": "759600",
    "end": "764940"
  },
  {
    "text": "because we really wanted that experience of like scaling up your number of workers to be fast or you know container",
    "start": "764940",
    "end": "770820"
  },
  {
    "text": "start times to be fast we don't want people have even to like wait minutes or something and then the multi-tenant",
    "start": "770820",
    "end": "777000"
  },
  {
    "text": "design we have each team creates their own kubernetes namespace that's kind of the only time that they really have to",
    "start": "777000",
    "end": "783779"
  },
  {
    "text": "bother with kubernetes um but after that they don't really have to care about it so namespaces here are",
    "start": "783779",
    "end": "789360"
  },
  {
    "text": "used to leverage for resource isolation and granular authorization we can use",
    "start": "789360",
    "end": "794399"
  },
  {
    "text": "all the like regular kubernetes are back to give control to like the ray cluster",
    "start": "794399",
    "end": "800820"
  },
  {
    "text": "crd's users but we don't give them lower level stuff so they can't mess around with like the ray system namespace or",
    "start": "800820",
    "end": "806940"
  },
  {
    "text": "like lower level kubernetes things like we don't want people creating demon sets for no reason",
    "start": "806940",
    "end": "813000"
  },
  {
    "text": "um so we built a very very thin we try to keep it as soon as possible like CLI",
    "start": "813000",
    "end": "819060"
  },
  {
    "text": "and SDK on top of kubre and on top of like just spinning up Ray clusters on on",
    "start": "819060",
    "end": "824700"
  },
  {
    "text": "our GK cluster and the the goal here again is for data",
    "start": "824700",
    "end": "830820"
  },
  {
    "text": "scientists and researchers to abstract as much of the underlying infrastructure away from them as possible",
    "start": "830820",
    "end": "837079"
  },
  {
    "text": "things like kubernetes things like GK specific stuff we wanted to make it easy",
    "start": "837079",
    "end": "842820"
  },
  {
    "text": "intuitive and extensible CLI and SDK so uh to to you know manage interact with",
    "start": "842820",
    "end": "849120"
  },
  {
    "text": "their Ray clusters and also in the future we're going to add more integration with other Spotify internal",
    "start": "849120",
    "end": "855779"
  },
  {
    "text": "ml services and infrastructure like for example experiment tracking which we have an internal system for",
    "start": "855779",
    "end": "863420"
  },
  {
    "text": "and uh so what does the CLI look like again this is very simple it's all written in Python",
    "start": "863600",
    "end": "869579"
  },
  {
    "text": "um and you can just do s-ray create cluster in a certain namespace we have",
    "start": "869579",
    "end": "875160"
  },
  {
    "text": "Flags like with tutorials which actually start a Jupiter notebook server uploads",
    "start": "875160",
    "end": "880199"
  },
  {
    "text": "some tutorial notebooks and then they can just click I'll demo this later they can just click it'll open their browser",
    "start": "880199",
    "end": "885360"
  },
  {
    "text": "and they can just hit run all cells and then that gives them like a quick hello World experience you have list",
    "start": "885360",
    "end": "890699"
  },
  {
    "text": "operations you have a delete operation to get rid of your cluster uh describe cluster command we'll",
    "start": "890699",
    "end": "897180"
  },
  {
    "text": "actually print out some useful information so you don't have to look at kubernetes yaml or even have to know how",
    "start": "897180",
    "end": "902339"
  },
  {
    "text": "to use Coop CTL it shows you head IP you know there's notebook server dashboard your head group how many worker groups",
    "start": "902339",
    "end": "909060"
  },
  {
    "text": "you have replicas in those worker groups and gpus and CPU resources",
    "start": "909060",
    "end": "915060"
  },
  {
    "text": "and it's easy to customize Basics options so when you create a cluster you know you can specify how much resources",
    "start": "915060",
    "end": "921180"
  },
  {
    "text": "you have types of gpus for anyone who",
    "start": "921180",
    "end": "926579"
  },
  {
    "text": "um so there's a little bug here I noticed today when when people create a cluster sometimes they like specify way",
    "start": "926579",
    "end": "932940"
  },
  {
    "text": "too many resources and our node pools actually can't handle that so if anybody has ideas for how to make this better",
    "start": "932940",
    "end": "939420"
  },
  {
    "text": "for us we don't do any validation right now but we want to do some validation so if they request like some type of GPU or",
    "start": "939420",
    "end": "945420"
  },
  {
    "text": "number of resources that we just don't provide in our node pools we'll just say we can't create this cluster right now the cluster looks like it's being",
    "start": "945420",
    "end": "952019"
  },
  {
    "text": "created and it just spins waiting for it to be ready and then we have to tell them like oh your your pods are never",
    "start": "952019",
    "end": "957180"
  },
  {
    "text": "going to be scheduled and that's where like the abstraction is leaky so if you have good ideas about how to improve this let us know",
    "start": "957180",
    "end": "963660"
  },
  {
    "text": "we have a command to scale your cluster so you can just scale like a worker group up to n replicas and if you are a",
    "start": "963660",
    "end": "970680"
  },
  {
    "text": "power user and you were like oh I know kubernetes I know all the yaml fields and what they do we still let you drop",
    "start": "970680",
    "end": "976320"
  },
  {
    "text": "down to that level so if you want to like configure two worker groups or like have very specific requirements",
    "start": "976320",
    "end": "983100"
  },
  {
    "text": "um over your array cluster you can drop down to the yaml you can just edit a yaml file and pass that in",
    "start": "983100",
    "end": "988680"
  },
  {
    "text": "so the idea is not to prevent that but to make it so that you don't have to know",
    "start": "988680",
    "end": "993899"
  },
  {
    "text": "and I'm going to switch over to a demo pre-recorded demo here of how it looks like",
    "start": "993899",
    "end": "1001639"
  },
  {
    "text": "so hopefully this is big enough the resolution is a bit low how do I",
    "start": "1001639",
    "end": "1008360"
  },
  {
    "text": "get okay well it's 1080p that's the best I can do um let me know if it's too small",
    "start": "1008360",
    "end": "1015199"
  },
  {
    "text": "anyways here the first one was just listing cluster namespace the second one I'm going to create a new cluster",
    "start": "1015199",
    "end": "1021680"
  },
  {
    "text": "sorry it's blurry but here I'm using the file based approach so it actually uses like a yaml file oh God the resolution",
    "start": "1021680",
    "end": "1028160"
  },
  {
    "text": "came up so now it's starting I pass in the with tutorials or oh no it's starting the tutorial one and if you see",
    "start": "1028160",
    "end": "1034160"
  },
  {
    "text": "I click on that link in the terminal it's going a little fast but it opens up the Jupiter server there's some pre-loaded tutorial notebooks that just",
    "start": "1034160",
    "end": "1041120"
  },
  {
    "text": "give you a really quick introduction array so we wanted this Hello World experience to be really slick no coding",
    "start": "1041120",
    "end": "1047000"
  },
  {
    "text": "involved one command hit run and then people can just see how easy it is to",
    "start": "1047000",
    "end": "1053000"
  },
  {
    "text": "scale up their python code and then we have like more Advanced Notebook tutorials here this one shows xgb and",
    "start": "1053000",
    "end": "1059179"
  },
  {
    "text": "tensorflow and then some random recommendations",
    "start": "1059179",
    "end": "1064280"
  },
  {
    "text": "uh I wish there's a better way to embed videos",
    "start": "1064280",
    "end": "1069679"
  },
  {
    "text": "okay so uh that's the CLI and then there's a",
    "start": "1069679",
    "end": "1075260"
  },
  {
    "text": "very there's much a corresponding SDK so if you don't want to use the CLI you want to do it all in Python",
    "start": "1075260",
    "end": "1081200"
  },
  {
    "text": "it's almost a one-to-one like equivalent stuff for it you can create a cluster you can scale a worker group you can",
    "start": "1081200",
    "end": "1086480"
  },
  {
    "text": "delete a cluster with almost like the same exact options here and the goal again is to abstract away kubernetes so",
    "start": "1086480",
    "end": "1091640"
  },
  {
    "text": "you don't have to import like a kubernetes python client or anything",
    "start": "1091640",
    "end": "1096460"
  },
  {
    "text": "um some use case oriented race setups in the future we want to offer like use",
    "start": "1097940",
    "end": "1103039"
  },
  {
    "text": "case specific things so users don't have to figure out all the boilerplate so that could include container images with",
    "start": "1103039",
    "end": "1109039"
  },
  {
    "text": "pre-installed dependencies tutorial notebooks for different types of Frameworks like you want to use hugging",
    "start": "1109039",
    "end": "1114559"
  },
  {
    "text": "face we have a tutorial for that versus xub and then tailored compute templates so if you want to do feature processing",
    "start": "1114559",
    "end": "1120860"
  },
  {
    "text": "versus training versus evaluation you might want to have different resources or even like different types of gpus that are specifically tailored for each",
    "start": "1120860",
    "end": "1127400"
  },
  {
    "text": "and we want to make it easy so that you don't have to think a lot there's kind of just like a you know a template for",
    "start": "1127400",
    "end": "1132860"
  },
  {
    "text": "that and future Integrations that we want to work on so standardizing the Spotify ml",
    "start": "1132860",
    "end": "1139340"
  },
  {
    "text": "platform experience we want to be able to let users track experiments and metrics in an internal meta internal ml",
    "start": "1139340",
    "end": "1145039"
  },
  {
    "text": "dashboard integrating with internal ml metadata and we have an internal feature",
    "start": "1145039",
    "end": "1150980"
  },
  {
    "text": "source so showing people how they can just use Ray and get access to that as well and other parts of the Spotify",
    "start": "1150980",
    "end": "1156620"
  },
  {
    "text": "ecosystem like scheduling your workloads so we have a team that manages a flight cluster so we were building a",
    "start": "1156620",
    "end": "1163460"
  },
  {
    "text": "preliminary flight integration with that there's also internal data endpoints not related to ml",
    "start": "1163460",
    "end": "1170860"
  },
  {
    "text": "ml features usually that people can also tap into and then for us on our side",
    "start": "1170860",
    "end": "1176059"
  },
  {
    "text": "like bookkeeping we want to have good cost tracking attribution all this is run in a multi-tenant single gcp project",
    "start": "1176059",
    "end": "1182600"
  },
  {
    "text": "which makes the billing look kind of funky like our team is just spending way too much or something so but there's gcp",
    "start": "1182600",
    "end": "1189760"
  },
  {
    "text": "features that allow you to segment by like a kubernetes namespace so we want to make sure we do the cost",
    "start": "1189760",
    "end": "1197600"
  },
  {
    "text": "attribution correctly and then as always we're going to improve the infrastructure's availability",
    "start": "1197600",
    "end": "1202880"
  },
  {
    "text": "reliability and performance throughout all this",
    "start": "1202880",
    "end": "1207640"
  },
  {
    "text": "what is this oh oh yeah this is a little out of order but this is the flight stuff this is a little I think I added",
    "start": "1208940",
    "end": "1214700"
  },
  {
    "text": "this in last minute but this is like an upcoming flight integration so you can add like a raid job config you can",
    "start": "1214700",
    "end": "1221360"
  },
  {
    "text": "schedule it and this will just run like like a flight workflow for you and then during this workflow it actually creates",
    "start": "1221360",
    "end": "1227240"
  },
  {
    "text": "an ephemeral rate cluster and tears it down at the end uh we want to give thanks to the",
    "start": "1227240",
    "end": "1233660"
  },
  {
    "text": "community so that's any scale and the ray project like Richard these are just happen to be some call outs for the",
    "start": "1233660",
    "end": "1240380"
  },
  {
    "text": "people we've worked with but it's not an exhaustive list and then from curay there's joshing sand Dimitri geckman",
    "start": "1240380",
    "end": "1246080"
  },
  {
    "text": "from Union AI in Flight Kevin Sue Yi Hong Yi Hing Tong and kitan umare so",
    "start": "1246080",
    "end": "1251780"
  },
  {
    "text": "thanks so much for coming to our talk we want to give plenty of time at the end for Q a so don't be shy ask us anything",
    "start": "1251780",
    "end": "1259700"
  },
  {
    "text": "or even suggestions about how to improve foreign",
    "start": "1259700",
    "end": "1265419"
  },
  {
    "text": "[Applause] thank you for a great talk um I was",
    "start": "1266240",
    "end": "1272840"
  },
  {
    "text": "wondering with respect to teams that are spitting up their own namespace we mentioned that in the future you want to",
    "start": "1272840",
    "end": "1279679"
  },
  {
    "text": "create container images that are use case specific but at the moment if a team wants to specify dependencies how might",
    "start": "1279679",
    "end": "1286940"
  },
  {
    "text": "they be how might they do that yeah so they can they can it depends on",
    "start": "1286940",
    "end": "1294320"
  },
  {
    "text": "the dependency sometimes they can like pip install and then they have to restart their notebook kernel um they I mean with Ray you can like say",
    "start": "1294320",
    "end": "1300980"
  },
  {
    "text": "like the the runtime M kind of like what's going to be installed in your workers",
    "start": "1300980",
    "end": "1306380"
  },
  {
    "text": "um are there other maybe other dependencies that are like lower level that they would need like a custom image",
    "start": "1306380",
    "end": "1312020"
  },
  {
    "text": "for and with the Custom Image are they just taking the base Ray image and then using that or are you",
    "start": "1312020",
    "end": "1318440"
  },
  {
    "text": "we added a few we added like a few small things for example I added like just this morning openvs code server into the",
    "start": "1318440",
    "end": "1324679"
  },
  {
    "text": "array base image yeah yeah there's also some teams a doing some crazy stuff they also do the other",
    "start": "1324679",
    "end": "1330679"
  },
  {
    "text": "Advantage they have their own base image and they install right on top",
    "start": "1330679",
    "end": "1336200"
  },
  {
    "text": "um in a cube array they also have a compute like templates you can Define the templates for different worker type",
    "start": "1336200",
    "end": "1343580"
  },
  {
    "text": "then you can pre create those config and start them as a kubernetes config map",
    "start": "1343580",
    "end": "1349220"
  },
  {
    "text": "then you spin update cluster you can also use templates to config different workers",
    "start": "1349220",
    "end": "1355340"
  },
  {
    "text": "thank you",
    "start": "1355340",
    "end": "1358000"
  },
  {
    "text": "hi I uh I want to know if you are using racer and uh if you you know what's your",
    "start": "1362600",
    "end": "1368299"
  },
  {
    "text": "if you're using racer what's your uh you know usage scenario for integrating with",
    "start": "1368299",
    "end": "1374120"
  },
  {
    "text": "the racer um now we currently not using reserve and and Spotify has our own like serving",
    "start": "1374120",
    "end": "1381679"
  },
  {
    "text": "infrastructure we're using TF serving and our background service you want your jvm and but we do see there's tons of",
    "start": "1381679",
    "end": "1390700"
  },
  {
    "text": "potential for the race of especially um like I've seen being about very big",
    "start": "1390700",
    "end": "1395960"
  },
  {
    "text": "models you need a fit model instrument memory yeah we're definitely very interested and looking into that yeah",
    "start": "1395960",
    "end": "1405279"
  },
  {
    "text": "a great talk so I used to see a lot of Spotify talks about spark I wonder if",
    "start": "1406220",
    "end": "1411559"
  },
  {
    "text": "you guys still use spark and if so what is the kind of uh balance of spark terrain like how do you work them",
    "start": "1411559",
    "end": "1417620"
  },
  {
    "text": "together we don't have spark like Sparta internally using data flow for the data",
    "start": "1417620",
    "end": "1422960"
  },
  {
    "text": "processing but we don't use the direct user beam API and we have the Scala",
    "start": "1422960",
    "end": "1428539"
  },
  {
    "text": "version of koroshio which built on top of beam that's what we use internally",
    "start": "1428539",
    "end": "1433940"
  },
  {
    "text": "for data processing division we have is data ETL is using shield on the data",
    "start": "1433940",
    "end": "1441500"
  },
  {
    "text": "flow or bigquery there's attitudes for that then when you build a fat feature",
    "start": "1441500",
    "end": "1447919"
  },
  {
    "text": "data sets then you load into the ray system then really take over from there you do the feature processing data",
    "start": "1447919",
    "end": "1454760"
  },
  {
    "text": "validation then you train and the predict",
    "start": "1454760",
    "end": "1459340"
  },
  {
    "text": "uh thanks for for the great talk um I'm just wondering like do you have any",
    "start": "1462820",
    "end": "1468080"
  },
  {
    "text": "thoughts on how to manage the quota let's say like you have multiple users sharing the same note group like no no",
    "start": "1468080",
    "end": "1475580"
  },
  {
    "text": "pool right and looks like they can create recluster like with unlimited",
    "start": "1475580",
    "end": "1481220"
  },
  {
    "text": "resource so any thoughts on how to manage this resource limit yeah so one",
    "start": "1481220",
    "end": "1487640"
  },
  {
    "text": "there's yeah multiple levels here uh one is we're just going to use kubernetes like resource quota set at like same",
    "start": "1487640",
    "end": "1495020"
  },
  {
    "text": "defaults for people who create their own namespace and then maybe some teams are more important and they're doing some",
    "start": "1495020",
    "end": "1500659"
  },
  {
    "text": "like Mission critical stuff that just needs to scale out a lot more we can with our approval they can bump their",
    "start": "1500659",
    "end": "1506120"
  },
  {
    "text": "kubernetes resource quotas um as well they're not a level deeper than that we also have like gcp project",
    "start": "1506120",
    "end": "1512900"
  },
  {
    "text": "quotas and sometimes if we run into those we have to we ourselves the platform team would have to make a",
    "start": "1512900",
    "end": "1518179"
  },
  {
    "text": "support case and ask Google to like bump those quotas for things like gpus anything I want to add just provide a",
    "start": "1518179",
    "end": "1525200"
  },
  {
    "text": "sort of default options as many as possible like with some guidelines so",
    "start": "1525200",
    "end": "1530299"
  },
  {
    "text": "user doesn't need to come up some random numbers to and when it's bm3 cluster",
    "start": "1530299",
    "end": "1535840"
  },
  {
    "text": "[Music]",
    "start": "1535840",
    "end": "1539020"
  },
  {
    "text": "thank you I really appreciate the beginning your breadth and depth contrast um and I found it uh very interesting to",
    "start": "1540980",
    "end": "1547279"
  },
  {
    "text": "kind of contrast that against some of the discussion any scale has had around a kind of end-to-end one platform for",
    "start": "1547279",
    "end": "1552799"
  },
  {
    "text": "everything it sounds like you all have really looked to get the tools that users are actually using specific",
    "start": "1552799",
    "end": "1558260"
  },
  {
    "text": "libraries support Etc um how do you kind of reconcile the your",
    "start": "1558260",
    "end": "1563299"
  },
  {
    "text": "choices of specialized tools or specialized tasks like you're talking kind of splitting your beam and you're wearing workloads with kind of some of",
    "start": "1563299",
    "end": "1569659"
  },
  {
    "text": "the ray vision of kind of being the monolithic platform for everything yeah that's a good question it's always",
    "start": "1569659",
    "end": "1575120"
  },
  {
    "text": "like balance you're trying to make off from the platform perspective we kind of",
    "start": "1575120",
    "end": "1581480"
  },
  {
    "text": "we need to consider like how many engineering results we have how many tools we can support and perform the",
    "start": "1581480",
    "end": "1589279"
  },
  {
    "text": "like ml teams they just want use as many as tools as they can so it's more about",
    "start": "1589279",
    "end": "1596000"
  },
  {
    "text": "a two-way communication we need let them understand like",
    "start": "1596000",
    "end": "1601220"
  },
  {
    "text": "can choose from our platform and we also build a strong standardization so",
    "start": "1601220",
    "end": "1609080"
  },
  {
    "text": "the make sure our platform is more adaptable for like the industry change when there's new tools come in it's",
    "start": "1609080",
    "end": "1615799"
  },
  {
    "text": "always easy to plug into our platform I would ask that like a major part that",
    "start": "1615799",
    "end": "1620900"
  },
  {
    "text": "we didn't cover in this talk is like the constr the Spotify specific constraints we're working in so like the the size of",
    "start": "1620900",
    "end": "1626840"
  },
  {
    "text": "the company the number of users that we we have on our existing ml platform we",
    "start": "1626840",
    "end": "1631880"
  },
  {
    "text": "didn't want to destabilize it or cause confusion so we had to be very kind of specific and nuanced in our messaging",
    "start": "1631880",
    "end": "1636980"
  },
  {
    "text": "both to our user potential users and also to like our managers of what Ray is",
    "start": "1636980",
    "end": "1642799"
  },
  {
    "text": "and what value can provide so there's that if you're working on a smaller startup where like you have five mles",
    "start": "1642799",
    "end": "1648500"
  },
  {
    "text": "and like a couple data scientists like you can just go Hog Wild and it doesn't really matter right so um but for yeah like a public company at",
    "start": "1648500",
    "end": "1655159"
  },
  {
    "text": "Spotify we have to make it so that we're introducing it slowly and learning as we go instead of like a big replacement so",
    "start": "1655159",
    "end": "1662539"
  },
  {
    "text": "you notice in a lot of the other talks like the Keynotes or the the error talk they they said oh you can use Ray to",
    "start": "1662539",
    "end": "1669679"
  },
  {
    "text": "replace like a piece of your platform or like the entire platform we're not even doing that we're just standing up like",
    "start": "1669679",
    "end": "1676100"
  },
  {
    "text": "almost like parallel experiment on the side",
    "start": "1676100",
    "end": "1680380"
  },
  {
    "text": "okay so um your last answer was interesting to me um so you you guys were using tfx before",
    "start": "1684140",
    "end": "1690799"
  },
  {
    "text": "and I'm sure there were many teams building uh models that are running on tfx",
    "start": "1690799",
    "end": "1697340"
  },
  {
    "text": "in your view what's been the biggest challenge for those teams then migrate over to this new system because tfx if",
    "start": "1697340",
    "end": "1704179"
  },
  {
    "text": "you're if you're in the tfx ecosystem it gives you everything and if you're asking a team to now say hey move out of",
    "start": "1704179",
    "end": "1709760"
  },
  {
    "text": "that into this new uh framework that I'm building for you what's been the biggest challenge luckily we were not asking people to do",
    "start": "1709760",
    "end": "1716960"
  },
  {
    "text": "that so we've been very careful in saying if you're using tfx or like our SKF wrapper around it",
    "start": "1716960",
    "end": "1723080"
  },
  {
    "text": "um and it's working fine for you in production don't migrate we're actually first focusing on people who just can't",
    "start": "1723080",
    "end": "1729020"
  },
  {
    "text": "use that at all and they're like I need something I want to use this you know learning framework and it's completely",
    "start": "1729020",
    "end": "1734659"
  },
  {
    "text": "unsupported those are the people we're working with for for the race stuff in the future we'll see what happens as we",
    "start": "1734659",
    "end": "1740419"
  },
  {
    "text": "collect more information yeah thank you",
    "start": "1740419",
    "end": "1744158"
  },
  {
    "text": "I just had a question about tearing down uh clusters that users start because you said you chose the um number three",
    "start": "1750140",
    "end": "1756140"
  },
  {
    "text": "dedicated rate clusters on the centrally managed multi-tenant so do people have to do they have like a lease how does",
    "start": "1756140",
    "end": "1761659"
  },
  {
    "text": "that work how do you get users to spool up and shut down oh like if they forget about it yeah we we have lots of users",
    "start": "1761659",
    "end": "1767539"
  },
  {
    "text": "that are like yeah I need 300 gigs of RAM and then they just leave it over the weekend and they're not they're CPU zero",
    "start": "1767539",
    "end": "1772580"
  },
  {
    "text": "and then there's another user you know um you know in Asia that's like why doesn't my thing work because the guy",
    "start": "1772580",
    "end": "1777679"
  },
  {
    "text": "didn't reset his notebook or whatever so how do you guys deal that yeah I mean one idea we have that you can",
    "start": "1777679",
    "end": "1784279"
  },
  {
    "text": "basically um that one feature we think about you can probably add a TTL for a recluster",
    "start": "1784279",
    "end": "1789679"
  },
  {
    "text": "so when I spin up you have TTL preset for your cluster then you hit the TTL",
    "start": "1789679",
    "end": "1795020"
  },
  {
    "text": "there's a mechanism you can check it's okay to shut down the rate class or not if user would like to expand the detail",
    "start": "1795020",
    "end": "1802640"
  },
  {
    "text": "they can also do that yeah and probably we're going to build our",
    "start": "1802640",
    "end": "1809059"
  },
  {
    "text": "own operator to running in the background to do those housekeeping stuff yeah yeah we plan to have a bunch",
    "start": "1809059",
    "end": "1816260"
  },
  {
    "text": "of like GC for it but uh at Spotify like usually cost is a lower priority than",
    "start": "1816260",
    "end": "1822919"
  },
  {
    "text": "just developer productivity so then also on our roadmap like the GC all that",
    "start": "1822919",
    "end": "1827960"
  },
  {
    "text": "stuff is also kind of after after getting people to use it once we once we see like",
    "start": "1827960",
    "end": "1833720"
  },
  {
    "text": "what we think might be too much waste or just forgotten resources we'll then go clean it up",
    "start": "1833720",
    "end": "1838940"
  },
  {
    "text": "so this will be this will be the last question similar lines like",
    "start": "1838940",
    "end": "1844760"
  },
  {
    "text": "um so resource utilization is a big question for me like I know people spin up machines and then there are ways to",
    "start": "1844760",
    "end": "1851480"
  },
  {
    "text": "basically like you mentioned we can spin them down automatically based on the time but when it comes to like",
    "start": "1851480",
    "end": "1858020"
  },
  {
    "text": "data scientists or Engineers using the right so it's like uh for example if you",
    "start": "1858020",
    "end": "1863600"
  },
  {
    "text": "have a GPU machine which is like super underutilized how do you Monitor and basically make sure that they're aware",
    "start": "1863600",
    "end": "1870140"
  },
  {
    "text": "of this under utilization and how do you make sure that it is properly utilized even CPUs or multi-node gpus or",
    "start": "1870140",
    "end": "1877340"
  },
  {
    "text": "something like that yeah yeah that's a good question and definitely we need to add a more like opposite ability on our",
    "start": "1877340",
    "end": "1883760"
  },
  {
    "text": "infra especially how to use us are utilized by different teams by different projects",
    "start": "1883760",
    "end": "1888860"
  },
  {
    "text": "that's something we're gonna need to build like and it's on our own map we're probably going to working on that in um",
    "start": "1888860",
    "end": "1895640"
  },
  {
    "text": "next quarter Q4 yeah so many years you can think of our you know it's really easy developers busy",
    "start": "1895640",
    "end": "1901460"
  },
  {
    "text": "they forget so some kind of push notification to be like hey you're using you've got like x amount of resources",
    "start": "1901460",
    "end": "1907340"
  },
  {
    "text": "just idling do you still need it and then just nudge them that way and ask them to to you know clean it up if they",
    "start": "1907340",
    "end": "1912799"
  },
  {
    "text": "don't need it yeah but it's a hard it's a hard thing to figure out yeah",
    "start": "1912799",
    "end": "1918559"
  },
  {
    "text": "yeah it's also like for example if we Implement cost of tracking like every team can know hey how much money you",
    "start": "1918559",
    "end": "1924200"
  },
  {
    "text": "guys but on your array class last week or yesterday yeah then we can offload",
    "start": "1924200",
    "end": "1929779"
  },
  {
    "text": "that that work of nudging them to like our Tech procurement who's like hey why are you spending this much",
    "start": "1929779",
    "end": "1936220"
  },
  {
    "text": "okay uh thanks everyone for coming please give it a round of applause to our speakers",
    "start": "1936620",
    "end": "1942158"
  }
]
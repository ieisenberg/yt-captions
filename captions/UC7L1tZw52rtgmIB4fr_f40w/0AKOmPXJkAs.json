[
  {
    "text": "good afternoon everyone welcome to Ray",
    "start": "2960",
    "end": "4839"
  },
  {
    "text": "Summit",
    "start": "4839",
    "end": "7279"
  },
  {
    "text": "2024 so let's talk about the future of",
    "start": "14040",
    "end": "18520"
  },
  {
    "text": "AI the future of AI is a sovereign",
    "start": "19000",
    "end": "24640"
  },
  {
    "text": "superintelligence what do I mean by",
    "start": "24640",
    "end": "26960"
  },
  {
    "text": "Sovereign it's an AI that can generate",
    "start": "26960",
    "end": "29640"
  },
  {
    "text": "its own",
    "start": "29640",
    "end": "30480"
  },
  {
    "text": "income can pay for its own",
    "start": "30480",
    "end": "33000"
  },
  {
    "text": "compute and follows the directives of a",
    "start": "33000",
    "end": "37200"
  },
  {
    "text": "decentralized autonomous",
    "start": "37200",
    "end": "40879"
  },
  {
    "text": "organization I'm Heather con I'm VP of",
    "start": "44480",
    "end": "47879"
  },
  {
    "text": "engineering at o and I'm joined by my",
    "start": "47879",
    "end": "50440"
  },
  {
    "text": "colleague Zach who's head of AIML Ops at",
    "start": "50440",
    "end": "54480"
  },
  {
    "text": "o and together we're here to show you",
    "start": "54480",
    "end": "56640"
  },
  {
    "text": "the path towards super intelligence and",
    "start": "56640",
    "end": "59359"
  },
  {
    "text": "what we've created",
    "start": "59359",
    "end": "61920"
  },
  {
    "text": "oh so let's talk about our",
    "start": "62320",
    "end": "66360"
  },
  {
    "text": "mission our mission is simple but it's",
    "start": "67840",
    "end": "70479"
  },
  {
    "text": "really",
    "start": "70479",
    "end": "71880"
  },
  {
    "text": "ambitious it's to develop and deploy the",
    "start": "71880",
    "end": "75119"
  },
  {
    "text": "world's first Sovereign super",
    "start": "75119",
    "end": "80080"
  },
  {
    "text": "intelligence we're building the",
    "start": "80320",
    "end": "82079"
  },
  {
    "text": "foundation for that super",
    "start": "82079",
    "end": "85400"
  },
  {
    "text": "intelligence and today I'll talk about",
    "start": "86320",
    "end": "88400"
  },
  {
    "text": "the building blocks",
    "start": "88400",
    "end": "90880"
  },
  {
    "text": "but first what are the challenges in the",
    "start": "90880",
    "end": "92920"
  },
  {
    "text": "current",
    "start": "92920",
    "end": "95200"
  },
  {
    "text": "industry",
    "start": "95200",
    "end": "97479"
  },
  {
    "text": "accuracy large language models are prone",
    "start": "97479",
    "end": "100240"
  },
  {
    "text": "to hallucinations and",
    "start": "100240",
    "end": "103719"
  },
  {
    "text": "bias",
    "start": "103719",
    "end": "106119"
  },
  {
    "text": "speed these models have hundreds of",
    "start": "106119",
    "end": "108960"
  },
  {
    "text": "billions of parameters up to trillions",
    "start": "108960",
    "end": "112399"
  },
  {
    "text": "it takes a fair amount of time to run",
    "start": "112399",
    "end": "114399"
  },
  {
    "text": "inference on these",
    "start": "114399",
    "end": "116000"
  },
  {
    "text": "models cost",
    "start": "116000",
    "end": "120000"
  },
  {
    "text": "it takes thousands of gpus and days to",
    "start": "120399",
    "end": "124000"
  },
  {
    "text": "months to train these models and usually",
    "start": "124000",
    "end": "127360"
  },
  {
    "text": "in a commercial setting you have to pick",
    "start": "127360",
    "end": "129399"
  },
  {
    "text": "two out of three",
    "start": "129399",
    "end": "132399"
  },
  {
    "text": "factors we've created o routing",
    "start": "134760",
    "end": "137920"
  },
  {
    "text": "intelligence",
    "start": "137920",
    "end": "139640"
  },
  {
    "text": "o and we aim to address these three",
    "start": "139640",
    "end": "143640"
  },
  {
    "text": "challenges for the industry I want to",
    "start": "143640",
    "end": "146599"
  },
  {
    "text": "bring on board Zach he'll be talking you",
    "start": "146599",
    "end": "149519"
  },
  {
    "text": "through the technical",
    "start": "149519",
    "end": "151519"
  },
  {
    "text": "details and then I'll Circle",
    "start": "151519",
    "end": "155319"
  },
  {
    "text": "back yeah thanks",
    "start": "157120",
    "end": "160599"
  },
  {
    "text": "Heather um so I'm going to take off the",
    "start": "160640",
    "end": "163400"
  },
  {
    "text": "technical part of the talk um so just",
    "start": "163400",
    "end": "166239"
  },
  {
    "text": "want to introducing our oi which is all",
    "start": "166239",
    "end": "169000"
  },
  {
    "text": "router",
    "start": "169000",
    "end": "169879"
  },
  {
    "text": "intelligence and so we have a couple",
    "start": "169879",
    "end": "172040"
  },
  {
    "text": "kind of core features we are going to",
    "start": "172040",
    "end": "174800"
  },
  {
    "text": "walk you through and in terms of what",
    "start": "174800",
    "end": "176959"
  },
  {
    "text": "how we're going to build this um U",
    "start": "176959",
    "end": "179000"
  },
  {
    "text": "architecture of the the software and so",
    "start": "179000",
    "end": "181920"
  },
  {
    "text": "first uh we've been thinking about a",
    "start": "181920",
    "end": "184239"
  },
  {
    "text": "more intelligent way like to handle the",
    "start": "184239",
    "end": "186440"
  },
  {
    "text": "curry routing um for the AI models and",
    "start": "186440",
    "end": "189920"
  },
  {
    "text": "the second is the multi-agent flow um",
    "start": "189920",
    "end": "192400"
  },
  {
    "text": "because we kind of been observing the",
    "start": "192400",
    "end": "194680"
  },
  {
    "text": "current I mean a lot of people doing the",
    "start": "194680",
    "end": "197200"
  },
  {
    "text": "same thing right now but how we going to",
    "start": "197200",
    "end": "199360"
  },
  {
    "text": "do this differently and third is",
    "start": "199360",
    "end": "201879"
  },
  {
    "text": "inference awareness which is it's a",
    "start": "201879",
    "end": "204000"
  },
  {
    "text": "unique layer we going to put on top of",
    "start": "204000",
    "end": "206200"
  },
  {
    "text": "our system in terms of how we handle",
    "start": "206200",
    "end": "208879"
  },
  {
    "text": "different uh requirement of the",
    "start": "208879",
    "end": "211280"
  },
  {
    "text": "inference in in in terms of the cost uh",
    "start": "211280",
    "end": "214239"
  },
  {
    "text": "inference speed token per second U",
    "start": "214239",
    "end": "216319"
  },
  {
    "text": "context length and um security as well",
    "start": "216319",
    "end": "220159"
  },
  {
    "text": "and uh because we request a lot of kind",
    "start": "220159",
    "end": "222200"
  },
  {
    "text": "of stuff going to our systems to support",
    "start": "222200",
    "end": "224480"
  },
  {
    "text": "to make this router intelligence work",
    "start": "224480",
    "end": "226840"
  },
  {
    "text": "and uh we need to kind of redefine the",
    "start": "226840",
    "end": "228879"
  },
  {
    "text": "AI infrastructure a bit more which I'm",
    "start": "228879",
    "end": "231080"
  },
  {
    "text": "going to walk you through some details",
    "start": "231080",
    "end": "234959"
  },
  {
    "text": "later uh so this is pretty much our core",
    "start": "235920",
    "end": "238720"
  },
  {
    "text": "feature at at the moment",
    "start": "238720",
    "end": "240560"
  },
  {
    "text": "and first uh similar to Chan of thought",
    "start": "240560",
    "end": "243480"
  },
  {
    "text": "uh which is everyone's doing this now",
    "start": "243480",
    "end": "245840"
  },
  {
    "text": "and is we going to break down the query",
    "start": "245840",
    "end": "248560"
  },
  {
    "text": "uh something we called uh query",
    "start": "248560",
    "end": "250920"
  },
  {
    "text": "decomposition or CH of um automic",
    "start": "250920",
    "end": "254200"
  },
  {
    "text": "querries and so this type of cury is a",
    "start": "254200",
    "end": "256359"
  },
  {
    "text": "smaller user cury and it's uh similar to",
    "start": "256359",
    "end": "259680"
  },
  {
    "text": "channel thought but I'm going to show",
    "start": "259680",
    "end": "261199"
  },
  {
    "text": "you a diagram later on and then the",
    "start": "261199",
    "end": "264160"
  },
  {
    "text": "Benchmark matching engine and this is",
    "start": "264160",
    "end": "266840"
  },
  {
    "text": "how we want to manage um our rou",
    "start": "266840",
    "end": "270600"
  },
  {
    "text": "intelligence we can route it to The",
    "start": "270600",
    "end": "272360"
  },
  {
    "text": "Benchmark uh the top model from our open",
    "start": "272360",
    "end": "275560"
  },
  {
    "text": "source LM um Benchmark from hugging face",
    "start": "275560",
    "end": "279320"
  },
  {
    "text": "and the third is the model agent routing",
    "start": "279320",
    "end": "282320"
  },
  {
    "text": "um so just not that we don't not only",
    "start": "282320",
    "end": "284880"
  },
  {
    "text": "doing like agent to agent routing but we",
    "start": "284880",
    "end": "286960"
  },
  {
    "text": "also do model to agent model to model U",
    "start": "286960",
    "end": "289720"
  },
  {
    "text": "agent to model as well and uh and then",
    "start": "289720",
    "end": "292520"
  },
  {
    "text": "the last layer is also pretty important",
    "start": "292520",
    "end": "294479"
  },
  {
    "text": "and critical it's for our evaluation and",
    "start": "294479",
    "end": "297000"
  },
  {
    "text": "ethical assessment um because we want to",
    "start": "297000",
    "end": "299759"
  },
  {
    "text": "build our system uh so our the responses",
    "start": "299759",
    "end": "302520"
  },
  {
    "text": "our AI to get people uh will be uh",
    "start": "302520",
    "end": "308440"
  },
  {
    "text": "responsibly so this is first is a cury",
    "start": "310080",
    "end": "312880"
  },
  {
    "text": "decomposition uh what we are thinking to",
    "start": "312880",
    "end": "314800"
  },
  {
    "text": "do uh similar to Chan of thought again",
    "start": "314800",
    "end": "317320"
  },
  {
    "text": "um but the the bottom neck of Chan of",
    "start": "317320",
    "end": "319319"
  },
  {
    "text": "thought is normally you would do this uh",
    "start": "319319",
    "end": "321560"
  },
  {
    "text": "sequentially which means you you use the",
    "start": "321560",
    "end": "324440"
  },
  {
    "text": "same model um to to ask so the model",
    "start": "324440",
    "end": "327240"
  },
  {
    "text": "will ask itself and to just repeat this",
    "start": "327240",
    "end": "329720"
  },
  {
    "text": "question like uh CH of thought like on",
    "start": "329720",
    "end": "331919"
  },
  {
    "text": "Chen uh what we're doing here is a bit",
    "start": "331919",
    "end": "334639"
  },
  {
    "text": "different but we use uh have the expert",
    "start": "334639",
    "end": "337199"
  },
  {
    "text": "LM to break down each query into a",
    "start": "337199",
    "end": "339960"
  },
  {
    "text": "smaller piece and then for each question",
    "start": "339960",
    "end": "342560"
  },
  {
    "text": "we use a different model to answer those",
    "start": "342560",
    "end": "344880"
  },
  {
    "text": "question and then this some some the",
    "start": "344880",
    "end": "347199"
  },
  {
    "text": "query can be done in parallel so it's",
    "start": "347199",
    "end": "349360"
  },
  {
    "text": "more like a partial sequential partial",
    "start": "349360",
    "end": "351360"
  },
  {
    "text": "parallel kind of process going on",
    "start": "351360",
    "end": "354560"
  },
  {
    "text": "here and um yeah so like I said before",
    "start": "354560",
    "end": "357120"
  },
  {
    "text": "it's we have the expert model to handle",
    "start": "357120",
    "end": "359080"
  },
  {
    "text": "that and then to design the whole um",
    "start": "359080",
    "end": "362120"
  },
  {
    "text": "chain of um automic query and then uh",
    "start": "362120",
    "end": "366280"
  },
  {
    "text": "each there we have we so the first layer",
    "start": "366280",
    "end": "368919"
  },
  {
    "text": "we're going to enforce some ethical",
    "start": "368919",
    "end": "371160"
  },
  {
    "text": "filter so if any question is not aligned",
    "start": "371160",
    "end": "373400"
  },
  {
    "text": "with our ethical um um alignment and",
    "start": "373400",
    "end": "376720"
  },
  {
    "text": "then it won't be insert for example and",
    "start": "376720",
    "end": "379440"
  },
  {
    "text": "then they uh so you can see like I don't",
    "start": "379440",
    "end": "381759"
  },
  {
    "text": "know if the text is big enough for you",
    "start": "381759",
    "end": "383319"
  },
  {
    "text": "to see but for each Curry uh",
    "start": "383319",
    "end": "386080"
  },
  {
    "text": "traditionally you have the single to",
    "start": "386080",
    "end": "388240"
  },
  {
    "text": "handle everything but in our vision is",
    "start": "388240",
    "end": "390199"
  },
  {
    "text": "we want to routed this uh smaller query",
    "start": "390199",
    "end": "394039"
  },
  {
    "text": "to the best model to answer that and so",
    "start": "394039",
    "end": "396560"
  },
  {
    "text": "those best model has it will be defined",
    "start": "396560",
    "end": "399280"
  },
  {
    "text": "by uh the open LM U Benchmark so we",
    "start": "399280",
    "end": "402400"
  },
  {
    "text": "pretty much uh categorize some task and",
    "start": "402400",
    "end": "406319"
  },
  {
    "text": "then we route it to the right uh the top",
    "start": "406319",
    "end": "408840"
  },
  {
    "text": "model in that Benchmark and to answer",
    "start": "408840",
    "end": "410880"
  },
  {
    "text": "the question so which I going to show",
    "start": "410880",
    "end": "412639"
  },
  {
    "text": "you some",
    "start": "412639",
    "end": "414280"
  },
  {
    "text": "example and for so another thing I would",
    "start": "414280",
    "end": "417199"
  },
  {
    "text": "try to do this differently is the",
    "start": "417199",
    "end": "418680"
  },
  {
    "text": "evaluation layer",
    "start": "418680",
    "end": "420199"
  },
  {
    "text": "uh so for each Curry we have the",
    "start": "420199",
    "end": "422360"
  },
  {
    "text": "response and then we need to go through",
    "start": "422360",
    "end": "424039"
  },
  {
    "text": "a series of kind of uh evaluation layer",
    "start": "424039",
    "end": "427400"
  },
  {
    "text": "and then we will ensure it will have the",
    "start": "427400",
    "end": "430120"
  },
  {
    "text": "best quality of the output for each",
    "start": "430120",
    "end": "432479"
  },
  {
    "text": "model and then not only that if the",
    "start": "432479",
    "end": "435039"
  },
  {
    "text": "first round uh it didn't give a high",
    "start": "435039",
    "end": "437879"
  },
  {
    "text": "quality enough uh respond to the user",
    "start": "437879",
    "end": "440800"
  },
  {
    "text": "and then we cannot to rerun it so it's a",
    "start": "440800",
    "end": "442840"
  },
  {
    "text": "iteration for each smaller Curry and",
    "start": "442840",
    "end": "445479"
  },
  {
    "text": "then so this way we can ensure every",
    "start": "445479",
    "end": "447360"
  },
  {
    "text": "single kind of um response for the",
    "start": "447360",
    "end": "450000"
  },
  {
    "text": "smaller cury and it can be answered it",
    "start": "450000",
    "end": "452280"
  },
  {
    "text": "can provide the best quality of the",
    "start": "452280",
    "end": "455520"
  },
  {
    "text": "responses and then because so this kind",
    "start": "455520",
    "end": "457599"
  },
  {
    "text": "of address the current challenges uh of",
    "start": "457599",
    "end": "461000"
  },
  {
    "text": "the uh the agent system because it's",
    "start": "461000",
    "end": "463120"
  },
  {
    "text": "hard to control the quality of each um",
    "start": "463120",
    "end": "465720"
  },
  {
    "text": "response because um it's not it's a non",
    "start": "465720",
    "end": "469240"
  },
  {
    "text": "deterministic process so this way we",
    "start": "469240",
    "end": "471680"
  },
  {
    "text": "want to turn the non deterministic",
    "start": "471680",
    "end": "474000"
  },
  {
    "text": "process into deterministic which we can",
    "start": "474000",
    "end": "477400"
  },
  {
    "text": "ensure the quality",
    "start": "477400",
    "end": "481039"
  },
  {
    "text": "and this is our Benchmark matching",
    "start": "481680",
    "end": "483720"
  },
  {
    "text": "engine uh which you can see we have um a",
    "start": "483720",
    "end": "487759"
  },
  {
    "text": "little kind of the table here and then",
    "start": "487759",
    "end": "489800"
  },
  {
    "text": "once you got a curry and then we have",
    "start": "489800",
    "end": "491240"
  },
  {
    "text": "the matching model to Route it to the",
    "start": "491240",
    "end": "493280"
  },
  {
    "text": "right uh uh the LM to answer the",
    "start": "493280",
    "end": "495800"
  },
  {
    "text": "question and in this case like we have a",
    "start": "495800",
    "end": "498720"
  },
  {
    "text": "30 32b model here uh but what we doing",
    "start": "498720",
    "end": "502639"
  },
  {
    "text": "kind of behind the scene is we have the",
    "start": "502639",
    "end": "504599"
  },
  {
    "text": "Benchmark registry which we list all the",
    "start": "504599",
    "end": "507319"
  },
  {
    "text": "Benchmark current kind of uh",
    "start": "507319",
    "end": "510159"
  },
  {
    "text": "popular Benchmark in our database and",
    "start": "510159",
    "end": "513200"
  },
  {
    "text": "then for each model we know that I mean",
    "start": "513200",
    "end": "515800"
  },
  {
    "text": "for each Benchmark for example BBH uh",
    "start": "515800",
    "end": "518320"
  },
  {
    "text": "you got a pretty good code generation uh",
    "start": "518320",
    "end": "520599"
  },
  {
    "text": "Benchmark and then if you ask the uh",
    "start": "520599",
    "end": "523479"
  },
  {
    "text": "code generation question and we know U",
    "start": "523479",
    "end": "526519"
  },
  {
    "text": "for example C Lama 34b assume it's the",
    "start": "526519",
    "end": "529519"
  },
  {
    "text": "best model on the lead board right now",
    "start": "529519",
    "end": "531279"
  },
  {
    "text": "and we're going to Route the that",
    "start": "531279",
    "end": "533080"
  },
  {
    "text": "question to this llama Co Lama 34b model",
    "start": "533080",
    "end": "536920"
  },
  {
    "text": "to answer that question so it just",
    "start": "536920",
    "end": "538920"
  },
  {
    "text": "really depends what you what's you uh",
    "start": "538920",
    "end": "541480"
  },
  {
    "text": "the question you ask and then we um um",
    "start": "541480",
    "end": "544480"
  },
  {
    "text": "classify them into a different task",
    "start": "544480",
    "end": "546720"
  },
  {
    "text": "category and then from the task category",
    "start": "546720",
    "end": "549200"
  },
  {
    "text": "we match the right Benchmark and from",
    "start": "549200",
    "end": "551399"
  },
  {
    "text": "The Benchmark we pick the best perform",
    "start": "551399",
    "end": "554279"
  },
  {
    "text": "performing model we want to do this in a",
    "start": "554279",
    "end": "556560"
  },
  {
    "text": "way like in real time uh because as you",
    "start": "556560",
    "end": "559000"
  },
  {
    "text": "all know Hing face open L data board uh",
    "start": "559000",
    "end": "563200"
  },
  {
    "text": "you the datable will be updated maybe",
    "start": "563200",
    "end": "565480"
  },
  {
    "text": "every other hour because people try to",
    "start": "565480",
    "end": "567480"
  },
  {
    "text": "compete and to the use the open source",
    "start": "567480",
    "end": "570160"
  },
  {
    "text": "model to just to get the highest rank uh",
    "start": "570160",
    "end": "572640"
  },
  {
    "text": "in The Benchmark so we want to capture",
    "start": "572640",
    "end": "574800"
  },
  {
    "text": "that in real time and so in our uh",
    "start": "574800",
    "end": "577480"
  },
  {
    "text": "backend infrastructure system and so we",
    "start": "577480",
    "end": "579959"
  },
  {
    "text": "set up um in a way and it can be um",
    "start": "579959",
    "end": "583519"
  },
  {
    "text": "pretty much uh detect if it's a new",
    "start": "583519",
    "end": "585640"
  },
  {
    "text": "changes in The Benchmark and we update",
    "start": "585640",
    "end": "588720"
  },
  {
    "text": "uh our uh backend um LM inference end",
    "start": "588720",
    "end": "592240"
  },
  {
    "text": "point so we will ensure all the top top",
    "start": "592240",
    "end": "596160"
  },
  {
    "text": "five models in The Benchmark it will be",
    "start": "596160",
    "end": "598480"
  },
  {
    "text": "available for routing intelligence to to",
    "start": "598480",
    "end": "603399"
  },
  {
    "text": "work and this is kind of uniqueness of",
    "start": "603399",
    "end": "605839"
  },
  {
    "text": "we do here is also it's called inference",
    "start": "605839",
    "end": "607920"
  },
  {
    "text": "awareness so user can Define uh what",
    "start": "607920",
    "end": "611079"
  },
  {
    "text": "kind of uh requirement um that they have",
    "start": "611079",
    "end": "614120"
  },
  {
    "text": "in terms of the inference maybe they are",
    "start": "614120",
    "end": "616240"
  },
  {
    "text": "thinking about to save the cost so we",
    "start": "616240",
    "end": "618800"
  },
  {
    "text": "can route them to a cheaper model to",
    "start": "618800",
    "end": "620640"
  },
  {
    "text": "answer that question if they prefer the",
    "start": "620640",
    "end": "623279"
  },
  {
    "text": "uh the faster inference and then we",
    "start": "623279",
    "end": "625320"
  },
  {
    "text": "because we have all the uh data like",
    "start": "625320",
    "end": "627440"
  },
  {
    "text": "being updated real time in our uh",
    "start": "627440",
    "end": "629839"
  },
  {
    "text": "database so we just yeah routed um based",
    "start": "629839",
    "end": "633640"
  },
  {
    "text": "on users requirement so our system can",
    "start": "633640",
    "end": "636480"
  },
  {
    "text": "be flexible as well and so something",
    "start": "636480",
    "end": "638560"
  },
  {
    "text": "unique uh in this approach is we also",
    "start": "638560",
    "end": "640839"
  },
  {
    "text": "kind of consider the security compliance",
    "start": "640839",
    "end": "643519"
  },
  {
    "text": "um so if you request uh the the model",
    "start": "643519",
    "end": "647120"
  },
  {
    "text": "responses you want to generate by the",
    "start": "647120",
    "end": "649240"
  },
  {
    "text": "infrastructure complying with your uh",
    "start": "649240",
    "end": "652079"
  },
  {
    "text": "security requirements such as sax2 or",
    "start": "652079",
    "end": "654560"
  },
  {
    "text": "heppa and then we because we have all",
    "start": "654560",
    "end": "657000"
  },
  {
    "text": "this metadata and then so we know okay",
    "start": "657000",
    "end": "659000"
  },
  {
    "text": "so this model end point is coming from",
    "start": "659000",
    "end": "661600"
  },
  {
    "text": "this infrastructure like has this uh",
    "start": "661600",
    "end": "663839"
  },
  {
    "text": "security compliance so this model would",
    "start": "663839",
    "end": "666120"
  },
  {
    "text": "meet users requirements so we going to",
    "start": "666120",
    "end": "668040"
  },
  {
    "text": "Route the model through that as",
    "start": "668040",
    "end": "671639"
  },
  {
    "text": "well um and then this another kind of",
    "start": "672360",
    "end": "675680"
  },
  {
    "text": "our thought around the endic uh",
    "start": "675680",
    "end": "679560"
  },
  {
    "text": "workflow is in our kind of our mind um",
    "start": "679560",
    "end": "683399"
  },
  {
    "text": "we've been thinking about this is a",
    "start": "683399",
    "end": "684959"
  },
  {
    "text": "multi-agent coroporation right uh but",
    "start": "684959",
    "end": "687519"
  },
  {
    "text": "it's not kind of we don't want to narrow",
    "start": "687519",
    "end": "689440"
  },
  {
    "text": "only to the LM but eventually you want",
    "start": "689440",
    "end": "691880"
  },
  {
    "text": "to have the LM agent uh it will have",
    "start": "691880",
    "end": "694519"
  },
  {
    "text": "access to all the open source model a",
    "start": "694519",
    "end": "696959"
  },
  {
    "text": "classical ml model uh newer Network",
    "start": "696959",
    "end": "699480"
  },
  {
    "text": "model um computer vision NP and time",
    "start": "699480",
    "end": "702320"
  },
  {
    "text": "series model so anything um so you want",
    "start": "702320",
    "end": "705079"
  },
  {
    "text": "to have the agent has the capability to",
    "start": "705079",
    "end": "707839"
  },
  {
    "text": "actually find to a trend uh ml model to",
    "start": "707839",
    "end": "711320"
  },
  {
    "text": "perform maybe make some prediction so",
    "start": "711320",
    "end": "714040"
  },
  {
    "text": "that's our kind of Ino is to have this",
    "start": "714040",
    "end": "716160"
  },
  {
    "text": "dynamic system you have the agent",
    "start": "716160",
    "end": "718320"
  },
  {
    "text": "perform sound",
    "start": "718320",
    "end": "719839"
  },
  {
    "text": "um ml model prediction on behalf of the",
    "start": "719839",
    "end": "722680"
  },
  {
    "text": "ml engineer and so this could be more",
    "start": "722680",
    "end": "725160"
  },
  {
    "text": "powerful in a way it's not only uh focus",
    "start": "725160",
    "end": "728680"
  },
  {
    "text": "on the LM but will be um every kind of",
    "start": "728680",
    "end": "731320"
  },
  {
    "text": "ml model and also any kind of data",
    "start": "731320",
    "end": "733440"
  },
  {
    "text": "processing and the agent will be able to",
    "start": "733440",
    "end": "735320"
  },
  {
    "text": "use different tool or the API uh like do",
    "start": "735320",
    "end": "738839"
  },
  {
    "text": "uh function calling and everything",
    "start": "738839",
    "end": "743000"
  },
  {
    "text": "yeah um because this is R conference we",
    "start": "744040",
    "end": "747000"
  },
  {
    "text": "going to talk a little bit about how we",
    "start": "747000",
    "end": "748760"
  },
  {
    "text": "set up our infrastructure um so right",
    "start": "748760",
    "end": "751279"
  },
  {
    "text": "now we've been uh in collaboration with",
    "start": "751279",
    "end": "753600"
  },
  {
    "text": "i.net to utilize the r cluster in in our",
    "start": "753600",
    "end": "757360"
  },
  {
    "text": "infrastructure and so we have a couple",
    "start": "757360",
    "end": "759399"
  },
  {
    "text": "h100 uh clusters and to serve our LM",
    "start": "759399",
    "end": "763800"
  },
  {
    "text": "like so we use race serve plus VM to",
    "start": "763800",
    "end": "766560"
  },
  {
    "text": "serve all our LM um inference for the",
    "start": "766560",
    "end": "769120"
  },
  {
    "text": "routing intelligence system and for the",
    "start": "769120",
    "end": "772240"
  },
  {
    "text": "inference uh registry like yeah we use",
    "start": "772240",
    "end": "776399"
  },
  {
    "text": "the yeah we use the Benchmark matching",
    "start": "776399",
    "end": "778440"
  },
  {
    "text": "engine to handle that and then we use",
    "start": "778440",
    "end": "780680"
  },
  {
    "text": "right data uh because we do uh F tune",
    "start": "780680",
    "end": "783880"
  },
  {
    "text": "our model So eventually we going to f",
    "start": "783880",
    "end": "786760"
  },
  {
    "text": "tune only fine tune the most routed",
    "start": "786760",
    "end": "788920"
  },
  {
    "text": "model and so that uh fine tune model can",
    "start": "788920",
    "end": "792120"
  },
  {
    "text": "also serve that purpose yeah so have R",
    "start": "792120",
    "end": "795240"
  },
  {
    "text": "data and R Trend just to use a different",
    "start": "795240",
    "end": "798120"
  },
  {
    "text": "technique to do our fine tuning yeah so",
    "start": "798120",
    "end": "800639"
  },
  {
    "text": "this is current we only have a really",
    "start": "800639",
    "end": "802720"
  },
  {
    "text": "simple infrastructure at the moment um",
    "start": "802720",
    "end": "804959"
  },
  {
    "text": "but we going to develop a lot of kind of",
    "start": "804959",
    "end": "806680"
  },
  {
    "text": "ml apps there within that and then so we",
    "start": "806680",
    "end": "809160"
  },
  {
    "text": "can um uh automatically kind of um um",
    "start": "809160",
    "end": "813920"
  },
  {
    "text": "provide the the inference endpoint",
    "start": "813920",
    "end": "815639"
  },
  {
    "text": "update and to update our inference",
    "start": "815639",
    "end": "818279"
  },
  {
    "text": "registry Benchmark uh database as",
    "start": "818279",
    "end": "823240"
  },
  {
    "text": "well so while we are developing this",
    "start": "823360",
    "end": "826360"
  },
  {
    "text": "system we actually have some unique",
    "start": "826360",
    "end": "827959"
  },
  {
    "text": "Insight we want to share uh so the oi",
    "start": "827959",
    "end": "830800"
  },
  {
    "text": "approach yeah we want to we am to solve",
    "start": "830800",
    "end": "833440"
  },
  {
    "text": "the multi- AGM",
    "start": "833440",
    "end": "834880"
  },
  {
    "text": "bottleneck uh in a way like we have",
    "start": "834880",
    "end": "837399"
  },
  {
    "text": "unique awareness in cost um security uh",
    "start": "837399",
    "end": "841639"
  },
  {
    "text": "latency as well and um so one of the",
    "start": "841639",
    "end": "844440"
  },
  {
    "text": "advantage we want to address I think",
    "start": "844440",
    "end": "846440"
  },
  {
    "text": "Heather would mention this later is we",
    "start": "846440",
    "end": "848839"
  },
  {
    "text": "because you can see the bottom neck is",
    "start": "848839",
    "end": "850720"
  },
  {
    "text": "the inference speed the inference is not",
    "start": "850720",
    "end": "852880"
  },
  {
    "text": "fast enough for you to collaborate uh",
    "start": "852880",
    "end": "855800"
  },
  {
    "text": "the for the multi-agent coporation",
    "start": "855800",
    "end": "857639"
  },
  {
    "text": "because this agent need to wait a long",
    "start": "857639",
    "end": "860160"
  },
  {
    "text": "time for another agent to to perform the",
    "start": "860160",
    "end": "862759"
  },
  {
    "text": "same thing I mean the the another task",
    "start": "862759",
    "end": "865079"
  },
  {
    "text": "so the wait the agent right now is kind",
    "start": "865079",
    "end": "866959"
  },
  {
    "text": "of waiting for each other so the",
    "start": "866959",
    "end": "868519"
  },
  {
    "text": "inference is the bottleneck um and then",
    "start": "868519",
    "end": "871079"
  },
  {
    "text": "we going to announce kind of our",
    "start": "871079",
    "end": "872759"
  },
  {
    "text": "collaboration so we how we can get a",
    "start": "872759",
    "end": "875320"
  },
  {
    "text": "really high speed inference maybe 10 20",
    "start": "875320",
    "end": "878399"
  },
  {
    "text": "times faster um",
    "start": "878399",
    "end": "880759"
  },
  {
    "text": "inference and so our uh end goal like",
    "start": "880759",
    "end": "884680"
  },
  {
    "text": "for this routing intelligence uh in our",
    "start": "884680",
    "end": "887440"
  },
  {
    "text": "vision it's more like a new operating",
    "start": "887440",
    "end": "889320"
  },
  {
    "text": "system pretty much that routing",
    "start": "889320",
    "end": "890880"
  },
  {
    "text": "intelligence control everything in your",
    "start": "890880",
    "end": "892839"
  },
  {
    "text": "system and can perform on your behave",
    "start": "892839",
    "end": "895360"
  },
  {
    "text": "and it's a still a bit of a road ahead",
    "start": "895360",
    "end": "898480"
  },
  {
    "text": "like we need to achieve this but yeah",
    "start": "898480",
    "end": "900399"
  },
  {
    "text": "this is our vision and we am to to build",
    "start": "900399",
    "end": "902560"
  },
  {
    "text": "this in within our engineering",
    "start": "902560",
    "end": "906759"
  },
  {
    "text": "organization um here I going to show you",
    "start": "907519",
    "end": "909920"
  },
  {
    "text": "maybe some initial results of our",
    "start": "909920",
    "end": "912279"
  },
  {
    "text": "Benchmark uh matching",
    "start": "912279",
    "end": "914360"
  },
  {
    "text": "engine and um so we only use open source",
    "start": "914360",
    "end": "917040"
  },
  {
    "text": "model here so I know uh some um",
    "start": "917040",
    "end": "920000"
  },
  {
    "text": "competitor in the market right now uh we",
    "start": "920000",
    "end": "922800"
  },
  {
    "text": "they doing Sim something similar to do",
    "start": "922800",
    "end": "925160"
  },
  {
    "text": "the routing um mechanism um but a lot of",
    "start": "925160",
    "end": "928440"
  },
  {
    "text": "people kind of compar to they use some",
    "start": "928440",
    "end": "930279"
  },
  {
    "text": "the close Source model and try to beat",
    "start": "930279",
    "end": "932399"
  },
  {
    "text": "The Benchmark but we all use um open",
    "start": "932399",
    "end": "934720"
  },
  {
    "text": "source here and so we have a couple uh",
    "start": "934720",
    "end": "937759"
  },
  {
    "text": "complete couple kind of evaluation for",
    "start": "937759",
    "end": "940000"
  },
  {
    "text": "different Benchmark for example MML musr",
    "start": "940000",
    "end": "943959"
  },
  {
    "text": "Arc all those kind of Benchmark our RI",
    "start": "943959",
    "end": "946399"
  },
  {
    "text": "will be able to outperform a single 70b",
    "start": "946399",
    "end": "948720"
  },
  {
    "text": "model and because we route each question",
    "start": "948720",
    "end": "952160"
  },
  {
    "text": "uh to different model to answer",
    "start": "952160",
    "end": "955759"
  },
  {
    "text": "that and we also have a small demo like",
    "start": "955959",
    "end": "959480"
  },
  {
    "text": "to yeah we can show you real quick um so",
    "start": "959480",
    "end": "962759"
  },
  {
    "text": "this just still work in progress we",
    "start": "962759",
    "end": "965160"
  },
  {
    "text": "still building out the system but just",
    "start": "965160",
    "end": "967199"
  },
  {
    "text": "in this short demo just want to show you",
    "start": "967199",
    "end": "970199"
  },
  {
    "text": "um uh how kind of each question will be",
    "start": "970199",
    "end": "973199"
  },
  {
    "text": "answered by a different model like it",
    "start": "973199",
    "end": "975399"
  },
  {
    "text": "can save the cost um and and so forth",
    "start": "975399",
    "end": "978759"
  },
  {
    "text": "yeah let",
    "start": "978759",
    "end": "979839"
  },
  {
    "text": "me see if we can make this",
    "start": "979839",
    "end": "983319"
  },
  {
    "text": "work okay so let me",
    "start": "983319",
    "end": "987000"
  },
  {
    "text": "refresh and then I prepared s question I",
    "start": "987000",
    "end": "989800"
  },
  {
    "text": "just don't want to waste your time",
    "start": "989800",
    "end": "991319"
  },
  {
    "text": "because my",
    "start": "991319",
    "end": "992800"
  },
  {
    "text": "typing with the code might be faster",
    "start": "992800",
    "end": "995399"
  },
  {
    "text": "than I type in English so I just copy",
    "start": "995399",
    "end": "997839"
  },
  {
    "text": "the question I prepared and paste here",
    "start": "997839",
    "end": "1000399"
  },
  {
    "text": "so I can show you uh the how this work",
    "start": "1000399",
    "end": "1005199"
  },
  {
    "text": "and then yeah depending on internet I",
    "start": "1005199",
    "end": "1007079"
  },
  {
    "text": "think internet speed here is fine so",
    "start": "1007079",
    "end": "1009639"
  },
  {
    "text": "right now I asked a code coding question",
    "start": "1009639",
    "end": "1012319"
  },
  {
    "text": "and it's supposed to route me to uh Cod",
    "start": "1012319",
    "end": "1014959"
  },
  {
    "text": "Lama and to answer this question you can",
    "start": "1014959",
    "end": "1017399"
  },
  {
    "text": "see like we have this",
    "start": "1017399",
    "end": "1019680"
  },
  {
    "text": "the answer speed out to help me I mean",
    "start": "1019680",
    "end": "1022160"
  },
  {
    "text": "to write this python",
    "start": "1022160",
    "end": "1024918"
  },
  {
    "text": "script so you can see in the end it",
    "start": "1024919",
    "end": "1027880"
  },
  {
    "text": "should show you it's answer by this I",
    "start": "1027880",
    "end": "1031400"
  },
  {
    "text": "can't really see here but C llama right",
    "start": "1031400",
    "end": "1034480"
  },
  {
    "text": "and then we can try another kind of cury",
    "start": "1034480",
    "end": "1036678"
  },
  {
    "text": "and to see to show",
    "start": "1036679",
    "end": "1039959"
  },
  {
    "text": "you uh so this question is more",
    "start": "1039959",
    "end": "1045240"
  },
  {
    "text": "oops for the creative writing",
    "start": "1045240",
    "end": "1050319"
  },
  {
    "text": "and then yeah I just um for some",
    "start": "1052280",
    "end": "1056160"
  },
  {
    "text": "something will happen next month but I",
    "start": "1056160",
    "end": "1058880"
  },
  {
    "text": "just want to see if this",
    "start": "1058880",
    "end": "1061400"
  },
  {
    "text": "work and then this because this is a",
    "start": "1061400",
    "end": "1063440"
  },
  {
    "text": "creative writing so you're not supposed",
    "start": "1063440",
    "end": "1065000"
  },
  {
    "text": "to rout you to like K Lama to answer the",
    "start": "1065000",
    "end": "1067080"
  },
  {
    "text": "question so actually it get to another",
    "start": "1067080",
    "end": "1069200"
  },
  {
    "text": "model to answer the question yeah I",
    "start": "1069200",
    "end": "1070720"
  },
  {
    "text": "believe this model rank pretty high in",
    "start": "1070720",
    "end": "1073760"
  },
  {
    "text": "the uh the content generation",
    "start": "1073760",
    "end": "1076200"
  },
  {
    "text": "category and then we have another one",
    "start": "1076200",
    "end": "1080559"
  },
  {
    "text": "uh maybe the entity",
    "start": "1080559",
    "end": "1084399"
  },
  {
    "text": "extraction so oops this is the",
    "start": "1084640",
    "end": "1089240"
  },
  {
    "text": "entity the extraction",
    "start": "1089240",
    "end": "1093559"
  },
  {
    "text": "question yeah okay I think it extract",
    "start": "1096600",
    "end": "1099919"
  },
  {
    "text": "entity right and this is using another",
    "start": "1099919",
    "end": "1103039"
  },
  {
    "text": "open source model which I'm not able to",
    "start": "1103039",
    "end": "1105200"
  },
  {
    "text": "see here it's too small for me to see",
    "start": "1105200",
    "end": "1107039"
  },
  {
    "text": "from the stage",
    "start": "1107039",
    "end": "1109720"
  },
  {
    "text": "yeah maybe the last one just do that for",
    "start": "1109720",
    "end": "1113880"
  },
  {
    "text": "fun uh this is the fact check question",
    "start": "1113880",
    "end": "1117960"
  },
  {
    "text": "just refresh just in",
    "start": "1117960",
    "end": "1121120"
  },
  {
    "text": "case yeah I think ins this all right and",
    "start": "1129039",
    "end": "1133280"
  },
  {
    "text": "with another uh top rank model in The",
    "start": "1133280",
    "end": "1137600"
  },
  {
    "text": "Benchmark um",
    "start": "1137600",
    "end": "1139440"
  },
  {
    "text": "um right so the the purpose of to",
    "start": "1139440",
    "end": "1141840"
  },
  {
    "text": "showing this demo just we still like",
    "start": "1141840",
    "end": "1143520"
  },
  {
    "text": "work in progress but um we have we will",
    "start": "1143520",
    "end": "1145760"
  },
  {
    "text": "have some MVP release pretty soon in a",
    "start": "1145760",
    "end": "1148799"
  },
  {
    "text": "few weeks and then we will announce soon",
    "start": "1148799",
    "end": "1150679"
  },
  {
    "text": "from our",
    "start": "1150679",
    "end": "1151679"
  },
  {
    "text": "website um yeah so we uh just want to",
    "start": "1151679",
    "end": "1154440"
  },
  {
    "text": "open this up for people to try out as",
    "start": "1154440",
    "end": "1157640"
  },
  {
    "text": "well",
    "start": "1157640",
    "end": "1160640"
  },
  {
    "text": "okay all",
    "start": "1163280",
    "end": "1165799"
  },
  {
    "text": "right yeah thank you Zach for for doing",
    "start": "1165799",
    "end": "1168320"
  },
  {
    "text": "the demo",
    "start": "1168320",
    "end": "1169360"
  },
  {
    "text": "uh it's amazing what the team has",
    "start": "1169360",
    "end": "1171320"
  },
  {
    "text": "accomplished in just a matter of a few",
    "start": "1171320",
    "end": "1173960"
  },
  {
    "text": "months uh so I want to really thank the",
    "start": "1173960",
    "end": "1176880"
  },
  {
    "text": "AI team and our research team at o uh",
    "start": "1176880",
    "end": "1179720"
  },
  {
    "text": "for putting this together so let's talk",
    "start": "1179720",
    "end": "1182120"
  },
  {
    "text": "about Partnerships uh",
    "start": "1182120",
    "end": "1184799"
  },
  {
    "text": "next uh",
    "start": "1184799",
    "end": "1187000"
  },
  {
    "text": "cerebrus if you guys are familiar with",
    "start": "1187000",
    "end": "1189080"
  },
  {
    "text": "cerebrus they're the world's first",
    "start": "1189080",
    "end": "1191919"
  },
  {
    "text": "company that's built a wafer scale",
    "start": "1191919",
    "end": "1194919"
  },
  {
    "text": "engine chip it's a 10in x 10in massive",
    "start": "1194919",
    "end": "1198679"
  },
  {
    "text": "Behemoth of a chip and what you can do",
    "start": "1198679",
    "end": "1201080"
  },
  {
    "text": "with it is you can run large language",
    "start": "1201080",
    "end": "1203919"
  },
  {
    "text": "models massive models at reduced",
    "start": "1203919",
    "end": "1206679"
  },
  {
    "text": "dramatically reduced inference and",
    "start": "1206679",
    "end": "1209039"
  },
  {
    "text": "training time we're talking days of",
    "start": "1209039",
    "end": "1212000"
  },
  {
    "text": "months of training reduced to days and",
    "start": "1212000",
    "end": "1214960"
  },
  {
    "text": "we're poised to become potentially one",
    "start": "1214960",
    "end": "1216919"
  },
  {
    "text": "of their largest",
    "start": "1216919",
    "end": "1218200"
  },
  {
    "text": "customers secondly",
    "start": "1218200",
    "end": "1221480"
  },
  {
    "text": "i.net i.net is a massive decentralized",
    "start": "1221480",
    "end": "1225840"
  },
  {
    "text": "GPU compute",
    "start": "1225840",
    "end": "1227640"
  },
  {
    "text": "platform they have Global they have",
    "start": "1227640",
    "end": "1230000"
  },
  {
    "text": "clusters distributed across the globe",
    "start": "1230000",
    "end": "1232919"
  },
  {
    "text": "and we want our team of distributed",
    "start": "1232919",
    "end": "1234600"
  },
  {
    "text": "remote Engineers to experiment and train",
    "start": "1234600",
    "end": "1238320"
  },
  {
    "text": "on different model architectures at",
    "start": "1238320",
    "end": "1241240"
  },
  {
    "text": "dramatically reduced cost and",
    "start": "1241240",
    "end": "1245360"
  },
  {
    "text": "latency so how can you guys",
    "start": "1247080",
    "end": "1250480"
  },
  {
    "text": "help we're not a normal AI company we",
    "start": "1250480",
    "end": "1253760"
  },
  {
    "text": "don't want to Silo everything into a",
    "start": "1253760",
    "end": "1256240"
  },
  {
    "text": "single Corporation we want it",
    "start": "1256240",
    "end": "1258760"
  },
  {
    "text": "decentralized we want it autonomous and",
    "start": "1258760",
    "end": "1262200"
  },
  {
    "text": "we need your help so this is a call to",
    "start": "1262200",
    "end": "1266120"
  },
  {
    "text": "action visit",
    "start": "1266120",
    "end": "1268200"
  },
  {
    "text": ".xyz if you're a developer and you want",
    "start": "1268200",
    "end": "1271159"
  },
  {
    "text": "to contribute to open source take a look",
    "start": "1271159",
    "end": "1274120"
  },
  {
    "text": "at o oxyz contact us if you're an",
    "start": "1274120",
    "end": "1276760"
  },
  {
    "text": "entrepreneur or or investor get in touch",
    "start": "1276760",
    "end": "1279760"
  },
  {
    "text": "with us and if you got any more",
    "start": "1279760",
    "end": "1281760"
  },
  {
    "text": "questions I'll be around rate conference",
    "start": "1281760",
    "end": "1284240"
  },
  {
    "text": "so just feel free to come up to me ask",
    "start": "1284240",
    "end": "1285960"
  },
  {
    "text": "me any questions I'm uh happy to answer",
    "start": "1285960",
    "end": "1289840"
  },
  {
    "text": "answer thank you guys",
    "start": "1289840",
    "end": "1293630"
  },
  {
    "text": "[Applause]",
    "start": "1293630",
    "end": "1297339"
  }
]
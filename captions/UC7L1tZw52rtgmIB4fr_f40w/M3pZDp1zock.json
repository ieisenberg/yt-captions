[
  {
    "text": "good evening and good morning to some of you are joining us for map pack uh welcome to the",
    "start": "240",
    "end": "5600"
  },
  {
    "text": "bay area rain meetup of the new year happy new year and delighted happy healthy new year to all of you welcome",
    "start": "5600",
    "end": "11519"
  },
  {
    "text": "to our first meetup we are really really super excited to get this going uh this is our first meet up after two years of",
    "start": "11519",
    "end": "18080"
  },
  {
    "text": "absence because of corbit and we're looking forward to get this cadence going on a regular basis now um if you",
    "start": "18080",
    "end": "24800"
  },
  {
    "text": "are using ray and if you're actually using ray to solve some of the problems of your scaling where you use your",
    "start": "24800",
    "end": "30960"
  },
  {
    "text": "machine learning workloads and you want to share that with the community please please get in contact with us it'd be",
    "start": "30960",
    "end": "37120"
  },
  {
    "text": "great to actually have you share or give a talk or write a blog about it because we believe that it is",
    "start": "37120",
    "end": "42480"
  },
  {
    "text": "you who is going to actually um help us uh get going as you will hear from robert very shortly that community is",
    "start": "42480",
    "end": "50000"
  },
  {
    "text": "our core it is the catalyst that drives over adoption and as you all know all successful projects in the past",
    "start": "50000",
    "end": "56879"
  },
  {
    "text": "have relied on the support in the thriving community we are relying on your support and you can rely on us to",
    "start": "56879",
    "end": "62640"
  },
  {
    "text": "make sure that you are successful in the adoption of rey and so we are counting you to spread and shine the ray of light",
    "start": "62640",
    "end": "69280"
  },
  {
    "text": "having said that enough of evangelism a couple of few housekeeping uh items all",
    "start": "69280",
    "end": "74880"
  },
  {
    "text": "your mics are muted right now uh we can't hear you nor can we see you unfortunately but hopefully that might",
    "start": "74880",
    "end": "80320"
  },
  {
    "text": "change in the future uh if you're having any zoom difficulties uh put something in the chat so we can actually uh",
    "start": "80320",
    "end": "87119"
  },
  {
    "text": "coordinate with you but enter all your q a uh during the q and a section in the",
    "start": "87119",
    "end": "92640"
  },
  {
    "text": "zoom panel for the q a because it's easy for us to navigate through than to scroll up and down the chat and while",
    "start": "92640",
    "end": "99280"
  },
  {
    "text": "you're doing that you might want to just say hello to everyone who is actually on the meetup tell us where you're healing",
    "start": "99280",
    "end": "105119"
  },
  {
    "text": "from you know we really want to know i know we actually have a global audience today so we'd love to hear where you're",
    "start": "105119",
    "end": "110720"
  },
  {
    "text": "dialing in from where you're telling you from you can actually use that chat and having said that we actually have a",
    "start": "110720",
    "end": "116719"
  },
  {
    "text": "tight agenda today so we're going to go to uh our next slide uh we have a tight agenda today robert",
    "start": "116719",
    "end": "122880"
  },
  {
    "text": "can you move to the next line um you're gonna hear first from our",
    "start": "122880",
    "end": "128399"
  },
  {
    "text": "fearless leader who is the co-founder of any scale and also the co-creator of ray",
    "start": "128399",
    "end": "134000"
  },
  {
    "text": "robert nishira who's going to reflect on the state of ray in the last year or so and then would be from",
    "start": "134000",
    "end": "140800"
  },
  {
    "text": "jazan who's going to give us the idea where ray is today and what do you expect coming in the near future and",
    "start": "140800",
    "end": "146480"
  },
  {
    "text": "then we'll dive into the ray datasets which is the experimental new library built on top of rey that will take us",
    "start": "146480",
    "end": "155040"
  },
  {
    "text": "until about you know seven ish or so and then we hear from the community we hear from uh",
    "start": "155040",
    "end": "160239"
  },
  {
    "text": "patrick m's uh about how they're actually using ray and how they actually built a scalable delta catalog with that",
    "start": "160239",
    "end": "166640"
  },
  {
    "text": "said it's my honor and pleasure really to introduce our co-founder uh at any scale um robert nishira he's",
    "start": "166640",
    "end": "173680"
  },
  {
    "text": "also the co-founder and the co-creator ray and all of you guys over here say hello to the community",
    "start": "173680",
    "end": "180319"
  },
  {
    "text": "thanks so much yeah all right all right so we're going to have you uh take over robert cool i'm",
    "start": "180640",
    "end": "185680"
  },
  {
    "text": "going to meet myself awesome well thank you everyone for you know for joining us here um i'm going to",
    "start": "185680",
    "end": "192000"
  },
  {
    "text": "say a bit about ray in 2021 tony and joe we'll talk more about um you know what's ahead in 2022",
    "start": "192000",
    "end": "198959"
  },
  {
    "text": "but you know 2021 was really a huge year for ray and so and i'd love to just touch on",
    "start": "198959",
    "end": "204560"
  },
  {
    "text": "some of the things that have been happening in the community um so throughout the year you know we've",
    "start": "204560",
    "end": "210239"
  },
  {
    "text": "seen tremendous growth in the community that's developers companies some long-time contributors",
    "start": "210239",
    "end": "216239"
  },
  {
    "text": "as well as a ton of you know new people contributing back to the open source project and really you know helping to",
    "start": "216239",
    "end": "222480"
  },
  {
    "text": "to create a great project that's been everything from ironing out a lot of the rough edges you know",
    "start": "222480",
    "end": "229120"
  },
  {
    "text": "building new libraries improving core usability and and polish and performance",
    "start": "229120",
    "end": "234640"
  },
  {
    "text": "um and this is something we really aspire to repeat in the coming year uh you know",
    "start": "234640",
    "end": "239760"
  },
  {
    "text": "with with together with the ray community so thank you so much for attending today and and really you know",
    "start": "239760",
    "end": "245519"
  },
  {
    "text": "being part of this meetup group and helping um helping build a great project",
    "start": "245519",
    "end": "250560"
  },
  {
    "text": "so to put some numbers on that you know we have almost at the end of this year we have almost 600",
    "start": "250560",
    "end": "256639"
  },
  {
    "text": "contributors that's a roughly 3x increase we're continuing to see more and more companies uh building internal",
    "start": "256639",
    "end": "263120"
  },
  {
    "text": "teams you know to invest in ray to build on top of ray uh to develop libraries on top of rey",
    "start": "263120",
    "end": "268720"
  },
  {
    "text": "and these are some of the statistics that we look at as you know a sign of a healthy community",
    "start": "268720",
    "end": "274320"
  },
  {
    "text": "another one is that in 2021 we released 14 ray releases and these are you know many of these are really significant uh",
    "start": "274320",
    "end": "281759"
  },
  {
    "text": "releases often with major improvements just as one example and joe will talk more about this but in 1.10 windows",
    "start": "281759",
    "end": "288160"
  },
  {
    "text": "support has reached another level of maturity it's now in beta so we're super eager to",
    "start": "288160",
    "end": "293759"
  },
  {
    "text": "learn about your experience using ray on windows and there are many other things like that that that have that have been",
    "start": "293759",
    "end": "299360"
  },
  {
    "text": "coming out recently and that are uh you know just step changes in in quality",
    "start": "299360",
    "end": "304720"
  },
  {
    "text": "um another another exciting number we've reached over 10 000 commits on rey so on",
    "start": "304720",
    "end": "310880"
  },
  {
    "text": "the ray project that's a just a tremendous amount of software engineering effort and development has gone into into building uh you know",
    "start": "310880",
    "end": "318000"
  },
  {
    "text": "building this project um we also have several thousand over you know three and a half thousand slack members and that's",
    "start": "318000",
    "end": "323759"
  },
  {
    "text": "one of the you know one of the areas where our you know the ray community has been coalescing uh engaging with each",
    "start": "323759",
    "end": "330160"
  },
  {
    "text": "other helping each other out talking about use cases talking about development plans um and that's you know",
    "start": "330160",
    "end": "336160"
  },
  {
    "text": "one of the one of the vibrant places that people gather um",
    "start": "336160",
    "end": "341520"
  },
  {
    "text": "another thing you know one of the things i want to talk about a little bit which is one of the things that really makes",
    "start": "341520",
    "end": "346560"
  },
  {
    "text": "ray special and where we've seen a lot of growth is the library ecosystem and 2021 has been a big year for the rey",
    "start": "346560",
    "end": "354160"
  },
  {
    "text": "ecosystem so just to as a reminder of how everything ties together how the ray ecosystem ties",
    "start": "354160",
    "end": "360479"
  },
  {
    "text": "together ray overall right ray is a universal framework for distributed computing it's",
    "start": "360479",
    "end": "366080"
  },
  {
    "text": "super general right you can use ray for scaling essentially any workload um and that that generality that level of",
    "start": "366080",
    "end": "372960"
  },
  {
    "text": "generality is critical for supporting this rich uh library ecosystem on top",
    "start": "372960",
    "end": "378800"
  },
  {
    "text": "that's everything from you know training deep learning production serving data processing stream processing you know",
    "start": "378800",
    "end": "386000"
  },
  {
    "text": "anything you can imagine on top of rey and of course by running these libraries on top of ray",
    "start": "386000",
    "end": "391120"
  },
  {
    "text": "the whole point of that is not just that you can use these libraries individually but rather that you can use them all",
    "start": "391120",
    "end": "396479"
  },
  {
    "text": "together and build applications that do all of these things together right so if you um you know that you can build",
    "start": "396479",
    "end": "403360"
  },
  {
    "text": "single coherent applications that load your data that that feed it into",
    "start": "403360",
    "end": "408400"
  },
  {
    "text": "training that do hyper parameter tuning that deploy the model and all of these things",
    "start": "408400",
    "end": "414000"
  },
  {
    "text": "and this whole ecosystem is really something that uh you know that excites us in that and that we think is special",
    "start": "414000",
    "end": "419360"
  },
  {
    "text": "about ray and of course if you use ray or if you use if you use wraith directly or use a",
    "start": "419360",
    "end": "425199"
  },
  {
    "text": "library on top of ray um one of the advantages of that is that you can then run your application anywhere right you",
    "start": "425199",
    "end": "431039"
  },
  {
    "text": "can run your application on any cloud provider you can run it on kubernetes on your laptop you can run it on any scale",
    "start": "431039",
    "end": "437440"
  },
  {
    "text": "which is our managed race service and so each of the components every time",
    "start": "437440",
    "end": "442880"
  },
  {
    "text": "there's a new addition or an improvement to the ecosystem you know that to one of the libraries that's part of this",
    "start": "442880",
    "end": "448880"
  },
  {
    "text": "ecosystem that adds value that is a benefit for um other users of other components of the",
    "start": "448880",
    "end": "455199"
  },
  {
    "text": "ecosystem because everything works together um so",
    "start": "455199",
    "end": "460639"
  },
  {
    "text": "a natural question is just what's new with the ecosystem what happened in 2021 and throughout the past year you know",
    "start": "460639",
    "end": "466800"
  },
  {
    "text": "and of course continuing into 2022 there's just been a ton of investment and effort in really ensuring that the",
    "start": "466800",
    "end": "474319"
  },
  {
    "text": "best libraries for machine learning all run on top of rey and that ray can is",
    "start": "474319",
    "end": "479680"
  },
  {
    "text": "the best way to scale these different libraries to give you a couple examples so xgboost",
    "start": "479680",
    "end": "485280"
  },
  {
    "text": "is one example there are talks online you know you can on youtube you can hear about how uber and others have sped up",
    "start": "485280",
    "end": "491520"
  },
  {
    "text": "training by 5x just by deploying xg boost on top of rey um you know using the xg boost ray",
    "start": "491520",
    "end": "497680"
  },
  {
    "text": "integration that's sort of one success story there you know an extreme boost of course is",
    "start": "497680",
    "end": "502720"
  },
  {
    "text": "super popular for uh for for training machine learning models uh horavod is another example in fact uh",
    "start": "502720",
    "end": "510319"
  },
  {
    "text": "you know companies like uber have deployed horovod on top of ray and that's allowed them you know because they can also deploy extra boost on rail",
    "start": "510319",
    "end": "516880"
  },
  {
    "text": "that's allowed them to really consolidate their deep learning and traditional machine learning tech stacks",
    "start": "516880",
    "end": "522479"
  },
  {
    "text": "um and of course by deploying on top of ray all these libraries they immediately leverage ray's elasticity right the the",
    "start": "522479",
    "end": "530080"
  },
  {
    "text": "auto scaling the hyper-parameter tuning um and because of that you know these kinds of data points that's how",
    "start": "530080",
    "end": "536080"
  },
  {
    "text": "ray is helping to bring this common infrastructure to the production ml ecosystem",
    "start": "536080",
    "end": "542480"
  },
  {
    "text": "uh so extra boost and horvath are a couple examples another example is das and actually so desk has a great library",
    "start": "542480",
    "end": "548880"
  },
  {
    "text": "for data processing um and you know there are people at amazon who've managed to and others who have managed",
    "start": "548880",
    "end": "554160"
  },
  {
    "text": "to speed up important desk workloads by around an order of magnitude by deploying uh desk on top of ray and",
    "start": "554160",
    "end": "560880"
  },
  {
    "text": "we've heard stories where people are able to um you know scale take important workloads and scale them to clusters",
    "start": "560880",
    "end": "566880"
  },
  {
    "text": "that were you know seven times larger and really cut um you know the end to end cost by by 3x in fact in one story",
    "start": "566880",
    "end": "573920"
  },
  {
    "text": "that we um we in one case study doing that saved something like half a",
    "start": "573920",
    "end": "578959"
  },
  {
    "text": "million dollars per job so these are you know large very large scale workloads and um you know um",
    "start": "578959",
    "end": "586720"
  },
  {
    "text": "and as part of this ecosystem ray can be a great way to scale these kinds of workloads",
    "start": "586720",
    "end": "592160"
  },
  {
    "text": "um of course you know we're talking about individual libraries but the real benefit of ray here is it's that these",
    "start": "592160",
    "end": "600000"
  },
  {
    "text": "libraries don't exist in isolation right you're not just using one library and then you're done but really they can be",
    "start": "600000",
    "end": "606160"
  },
  {
    "text": "used seamlessly together in a common application and and with all of these examples you know",
    "start": "606160",
    "end": "612880"
  },
  {
    "text": "we've seen that ray is really becoming the tool of choice for scaling machine learning and workloads scaling",
    "start": "612880",
    "end": "619680"
  },
  {
    "text": "machine learning libraries and really building these kinds of distributed applications",
    "start": "619680",
    "end": "625120"
  },
  {
    "text": "um so that's a little bit about the ecosystem and about libraries but beyond the",
    "start": "625120",
    "end": "630880"
  },
  {
    "text": "ecosystem in 2021 we've seen ray being used for a huge variety of applications",
    "start": "630880",
    "end": "636480"
  },
  {
    "text": "just far beyond where we were one year ago and actually one of the biggest shifts",
    "start": "636480",
    "end": "641519"
  },
  {
    "text": "is a focus on online production use cases so there's a super broad user base you",
    "start": "641519",
    "end": "648640"
  },
  {
    "text": "know all of these companies here presented at our previous race summit that was in 2021 and by the way we're",
    "start": "648640",
    "end": "654399"
  },
  {
    "text": "going to have another race summit this year so hopefully we'll be in person but all of these use cases are you know",
    "start": "654399",
    "end": "660560"
  },
  {
    "text": "the the use cases are are quite broad and you can imagine um all of these companies their talks",
    "start": "660560",
    "end": "666480"
  },
  {
    "text": "online on you know on youtube you can check them out about how they're using raid but it's it's really everything from like",
    "start": "666480",
    "end": "671680"
  },
  {
    "text": "from building uh scalable infrastructure for financial services to optimizing recommendations",
    "start": "671680",
    "end": "678320"
  },
  {
    "text": "uh you know recommending in-app purchases uh large-scale machine learning on aerial",
    "start": "678320",
    "end": "683519"
  },
  {
    "text": "imagery building machine learning platforms and and many more things and uh to give you just a couple",
    "start": "683519",
    "end": "689279"
  },
  {
    "text": "examples this is a picture from uh the talk that mckinsey gave so mckinsey and",
    "start": "689279",
    "end": "694320"
  },
  {
    "text": "quantum black partnered with uh the emirates team new zealand and designed this boat you know this boat in this",
    "start": "694320",
    "end": "700000"
  },
  {
    "text": "picture uh using rey to do reinforcement learning and uh they gave a talk about this at the",
    "start": "700000",
    "end": "706240"
  },
  {
    "text": "summit but basically using this boat that they designed with ray they won the america's cup which is the top competition in",
    "start": "706240",
    "end": "712639"
  },
  {
    "text": "sailing which is just incredible it's really um you know quite inspirational to see these kinds of use cases array in",
    "start": "712639",
    "end": "719440"
  },
  {
    "text": "the physical world another example like completely on the other end of the spectrum is a company",
    "start": "719440",
    "end": "726160"
  },
  {
    "text": "called dendra systems using ray for ecosystem restoration so their goal as a company is to plant billions and",
    "start": "726160",
    "end": "732399"
  },
  {
    "text": "billions and billions of trees and they're using ray to do everything um",
    "start": "732399",
    "end": "737839"
  },
  {
    "text": "uh and of course they have to decide from photographs where to plant the trees you have to train models that can",
    "start": "737839",
    "end": "743200"
  },
  {
    "text": "do the computer vision to understand the images and make these decisions um and they're using ray for everything from",
    "start": "743200",
    "end": "748959"
  },
  {
    "text": "the training the inference you know the computer vision the testing at a really tremendous scale",
    "start": "748959",
    "end": "754320"
  },
  {
    "text": "to plant trees um and another it's another example of just the kind of diversity of use cases that we see with",
    "start": "754320",
    "end": "760639"
  },
  {
    "text": "ray um another you know another data point uber and shopify and others talked about",
    "start": "760639",
    "end": "767600"
  },
  {
    "text": "building machine learning platforms on top of ray uh you know a lot of and that's something we we increasingly see",
    "start": "767600",
    "end": "773760"
  },
  {
    "text": "a lot of companies around this time are looking around to build their next generation machine learning platforms um",
    "start": "773760",
    "end": "780959"
  },
  {
    "text": "and a lot of them are choosing to build on top of ray and a big part of that is the the library ecosystem um",
    "start": "780959",
    "end": "788240"
  },
  {
    "text": "you know great scalable libraries for machine learning on top of rey um the fact that you know you can use the",
    "start": "788240",
    "end": "794320"
  },
  {
    "text": "generality the fact that you can use all of these libraries together the extensibility the ability to scale other",
    "start": "794320",
    "end": "800720"
  },
  {
    "text": "libraries on top of ray the fact the portability right the fact that it's you can use it on with any cloud",
    "start": "800720",
    "end": "806880"
  },
  {
    "text": "provider the fact that you can use it um you know with any any machine learning library or framework so um uh you know",
    "start": "806880",
    "end": "815279"
  },
  {
    "text": "building machine learning platforms is another example of a of an exciting use case that we've been seeing a lot about",
    "start": "815279",
    "end": "822000"
  },
  {
    "text": "um so lastly i just want to you know end with this slide and say that there",
    "start": "822000",
    "end": "827360"
  },
  {
    "text": "have been you know in addition to all these use cases well these these use cases and these are",
    "start": "827360",
    "end": "832800"
  },
  {
    "text": "really what excites us um and i know many of you have exciting use",
    "start": "832800",
    "end": "838160"
  },
  {
    "text": "cases that you'd probably be interested in sharing so we will be hosting a race summit in 2022 so you know please keep",
    "start": "838160",
    "end": "844000"
  },
  {
    "text": "an eye out for that and let us know if you're interested in sharing more about what you're what you're building um but",
    "start": "844000",
    "end": "849440"
  },
  {
    "text": "really we want to thank you all so much for making ray what it is for pioneering all these use cases",
    "start": "849440",
    "end": "855440"
  },
  {
    "text": "and just helping you know building such a rich ecosystem uh you know we really obviously wouldn't be here without the",
    "start": "855440",
    "end": "861440"
  },
  {
    "text": "the whole community so there's going to be a big year ahead of us in 2022",
    "start": "861440",
    "end": "866720"
  },
  {
    "text": "looking forward to an even bigger race summit later this year and i'll hand off things to joe who's who's going to talk",
    "start": "866720",
    "end": "872240"
  },
  {
    "text": "about what we have lined up for the the year ahead",
    "start": "872240",
    "end": "877040"
  },
  {
    "text": "thank you robert for the inspirational talk um next i think we're going to have jean who's going to give us to talk",
    "start": "878560",
    "end": "884160"
  },
  {
    "text": "about uh we raised today what we're going to see in the upcoming future so take it away",
    "start": "884160",
    "end": "889839"
  },
  {
    "text": "thank you robert and drew's first i'm really excited about uh us having the meet up again as you mentioned after a",
    "start": "889839",
    "end": "897120"
  },
  {
    "text": "long time very excited talking and interacting with the community um",
    "start": "897120",
    "end": "902800"
  },
  {
    "text": "so uh yeah this part of the talk is about what's new in our latest 1.9 release and beyond",
    "start": "902800",
    "end": "910160"
  },
  {
    "text": "that's a brief introduction i manage open source engineering at tennessee um",
    "start": "910160",
    "end": "916240"
  },
  {
    "text": "so um i think uh to simply put it the we have three overall themes to uh adding",
    "start": "916240",
    "end": "922639"
  },
  {
    "text": "improvements to ray uh in the one down the release and beyond so",
    "start": "922639",
    "end": "927920"
  },
  {
    "text": "basically in the recoil area we really focus on reliability and stability at large scale",
    "start": "927920",
    "end": "933440"
  },
  {
    "text": "and then on the library layer we're trying to build a suite of libraries",
    "start": "933440",
    "end": "938480"
  },
  {
    "text": "that's easy to use higher level and the more suitable production workflows to use them to wrap around the very elegant",
    "start": "938480",
    "end": "946160"
  },
  {
    "text": "low-level api so free itself and then thirdly we want to improve the deployment so both deploying a",
    "start": "946160",
    "end": "952399"
  },
  {
    "text": "re-cluster and deploying a code to the cluster to make sure these two type of deployments are simple and clear to",
    "start": "952399",
    "end": "959120"
  },
  {
    "text": "understand so i will start from recore i think attendees to this",
    "start": "959120",
    "end": "966240"
  },
  {
    "text": "meetup probably have some basic understanding of race architecture so this chart is basically a typical raid",
    "start": "966240",
    "end": "972959"
  },
  {
    "text": "cluster a real cluster is a collection of red nodes and there's only one special node in the cluster",
    "start": "972959",
    "end": "978720"
  },
  {
    "text": "called 10 node and there's only one special component in head node called global control store this is the only",
    "start": "978720",
    "end": "984720"
  },
  {
    "text": "single point of failure in the entire cluster so obviously we want to improve the",
    "start": "984720",
    "end": "989920"
  },
  {
    "text": "availability and scalability of these components so the feature we're working on",
    "start": "989920",
    "end": "995040"
  },
  {
    "text": "which we plan to release in the upcoming 1.11 release is to make the back end of",
    "start": "995040",
    "end": "1002480"
  },
  {
    "text": "gcs global control store more pluggable so here is the detail of this work so as",
    "start": "1002480",
    "end": "1009759"
  },
  {
    "text": "of now the global control store uses redis as a storage backend it has two functionalities one is to store internal",
    "start": "1009759",
    "end": "1017519"
  },
  {
    "text": "data there is an internal data table on radius the gcs will interact with redis for this and then the worker notes the",
    "start": "1017519",
    "end": "1024480"
  },
  {
    "text": "relative will interact with reddish for pops up purpose generic publishing messages and",
    "start": "1024480",
    "end": "1030720"
  },
  {
    "text": "receiving from other relapses so i think one both reliability and scalability",
    "start": "1030720",
    "end": "1037360"
  },
  {
    "text": "bottleneck is at reddish because red is a single instance is not",
    "start": "1037360",
    "end": "1042400"
  },
  {
    "text": "scalable if the node crashes then not only the gcs process but also the data stored in",
    "start": "1042400",
    "end": "1049200"
  },
  {
    "text": "redis will be gone so the first step we take to address the problem is to make the back end pluggable so different",
    "start": "1049200",
    "end": "1055520"
  },
  {
    "text": "environments can use their highly available kiwi store so",
    "start": "1055520",
    "end": "1061280"
  },
  {
    "text": "as a secondary benefit it can also make the message pops up",
    "start": "1061280",
    "end": "1066720"
  },
  {
    "text": "much more scalable we want to push the scalability limit of a single requester to be multiple of the current state",
    "start": "1066720",
    "end": "1075039"
  },
  {
    "text": "so um how about outside of the central global control store we're working on a",
    "start": "1075280",
    "end": "1080960"
  },
  {
    "text": "few pretty exciting efforts if you're interested please check the link i added at the bottom of",
    "start": "1080960",
    "end": "1087200"
  },
  {
    "text": "the page it's a public roadmap for record i want to emphasize uh three efforts",
    "start": "1087200",
    "end": "1093520"
  },
  {
    "text": "for the object store and for scheduler on the object store level we're working",
    "start": "1093520",
    "end": "1099120"
  },
  {
    "text": "on improving the object lifetime management again to handle node failures we want to make sure the developer has a",
    "start": "1099120",
    "end": "1106000"
  },
  {
    "text": "very other developers have a very clear contract of what to expect",
    "start": "1106000",
    "end": "1111039"
  },
  {
    "text": "for different kind of failure scenarios and then the second item is",
    "start": "1111039",
    "end": "1116559"
  },
  {
    "text": "very my personally personally i'm very excited and also interesting connection",
    "start": "1116559",
    "end": "1121840"
  },
  {
    "text": "to the following talk which is petabyte level of data processing i believe",
    "start": "1121840",
    "end": "1126919"
  },
  {
    "text": "patrick's talk will be related to that on the scheduler level we're working on an effort that is",
    "start": "1126919",
    "end": "1134400"
  },
  {
    "text": "basically rock solid schedule logic um i think we all know that uh one of the key advantages of ray on",
    "start": "1134400",
    "end": "1141440"
  },
  {
    "text": "architectural level is distributed scheduling so every roulette can make scheduling decisions but with this special power",
    "start": "1141440",
    "end": "1148799"
  },
  {
    "text": "comes with the complexity shortly put we need to we need to add the scheduling logic in",
    "start": "1148799",
    "end": "1155760"
  },
  {
    "text": "multiple places and what we're working on now is to consolidate logic so we can better test",
    "start": "1155760",
    "end": "1161520"
  },
  {
    "text": "it make the code more understandable and make it easier to add features down the road",
    "start": "1161520",
    "end": "1168000"
  },
  {
    "text": "so on the library front i think this is probably more even more",
    "start": "1168480",
    "end": "1173520"
  },
  {
    "text": "directly exposed to developers i want to emphasize four key libraries we're",
    "start": "1173520",
    "end": "1178720"
  },
  {
    "text": "developing and uh and and and lay out the very rough timeline we're releasing the libraries",
    "start": "1178720",
    "end": "1185360"
  },
  {
    "text": "at different stages uh of course in actual execution there will be uh we will",
    "start": "1185360",
    "end": "1190799"
  },
  {
    "text": "revisit the plan uh released after release right so the first library uh is three data sets read",
    "start": "1190799",
    "end": "1197280"
  },
  {
    "text": "data set um is has been progressing really quickly the initial prototype",
    "start": "1197280",
    "end": "1203520"
  },
  {
    "text": "when i was making the slide i was looking back i was really uh i was really surprised we only started working",
    "start": "1203520",
    "end": "1209440"
  },
  {
    "text": "on it actually last year june and at this point it's already beta released um",
    "start": "1209440",
    "end": "1214799"
  },
  {
    "text": "so i think in 1.11 1.12 we want to make data set ga and this is",
    "start": "1214799",
    "end": "1221280"
  },
  {
    "text": "um very closely related to the talk that clark and alex will give",
    "start": "1221280",
    "end": "1227039"
  },
  {
    "text": "and workflow library currently is alpha stage we want to make it better but this is a library uh which is more open-ended",
    "start": "1227039",
    "end": "1234159"
  },
  {
    "text": "so your input will definitely be very valuable please talk to ray team about this so the retrain library uh currently as a",
    "start": "1234159",
    "end": "1240799"
  },
  {
    "text": "beta and we're thinking about a more holistic api design to make uh the",
    "start": "1240799",
    "end": "1247039"
  },
  {
    "text": "different model uh machine learning model training libraries more pluggable in this framework and serve pipeline is",
    "start": "1247039",
    "end": "1253600"
  },
  {
    "text": "for people to serve multiple machine learning models in in simple fashion currently it's",
    "start": "1253600",
    "end": "1259440"
  },
  {
    "text": "experimental we want to make it alpha or beta in the upcoming 1.11 why not type 12 release",
    "start": "1259440",
    "end": "1266480"
  },
  {
    "text": "i want to just give a little more detail of the two libraries data set and workflow so written as",
    "start": "1266480",
    "end": "1272559"
  },
  {
    "text": "simply put is both a standard format and a mechanism for different components in",
    "start": "1272559",
    "end": "1278880"
  },
  {
    "text": "really to exchange data in a very efficient way ideally zero copy",
    "start": "1278880",
    "end": "1284799"
  },
  {
    "text": "right so uh by different components i mean for example data processing people can do sparkling array dash country and",
    "start": "1284799",
    "end": "1291520"
  },
  {
    "text": "then model training people can do tensorflow android pi torch array and then eventually scoring and maybe even online",
    "start": "1291520",
    "end": "1298640"
  },
  {
    "text": "serving so if these different components use the data set the performance and the",
    "start": "1298640",
    "end": "1303840"
  },
  {
    "text": "developer velocity can be much better to illustrate these you can look at the code snippet at the right hand side so",
    "start": "1303840",
    "end": "1310720"
  },
  {
    "text": "first we will load a party file really simply and do arbitrary function on the data",
    "start": "1310720",
    "end": "1316480"
  },
  {
    "text": "set and shard the file and fit it into different workers of active boost everything in the coherent vanilla",
    "start": "1316480",
    "end": "1323520"
  },
  {
    "text": "python script you can develop unit tests locally and scale to the cluster",
    "start": "1323520",
    "end": "1329039"
  },
  {
    "text": "the second library workflow so workflow simply put is for people to use tasks in",
    "start": "1329039",
    "end": "1334240"
  },
  {
    "text": "a more convenient and far tolerance way so typically when people use tasks they",
    "start": "1334240",
    "end": "1339360"
  },
  {
    "text": "want to do multiple things with dependencies among each other so what workflow allows you to do is to",
    "start": "1339360",
    "end": "1345760"
  },
  {
    "text": "specify dependencies and handle retries fault tolerance for upstream tasks so",
    "start": "1345760",
    "end": "1351440"
  },
  {
    "text": "downstream tasks know exactly what to expect for example exactly once delivery",
    "start": "1351440",
    "end": "1357760"
  },
  {
    "text": "so um the third area finally i want to touch on deployment on deployments we",
    "start": "1358880",
    "end": "1364720"
  },
  {
    "text": "really want to make sure it's clear and simple to understand right so um i want",
    "start": "1364720",
    "end": "1370159"
  },
  {
    "text": "to emphasize three things one is we want to make uh reclined uh the default option for interactive",
    "start": "1370159",
    "end": "1376720"
  },
  {
    "text": "development connecting people's laptop to a re-cluster and our new offering uh job submission we",
    "start": "1376720",
    "end": "1383919"
  },
  {
    "text": "want to make sure that one of the default options for production jobs after you're happy with the interactive",
    "start": "1383919",
    "end": "1389360"
  },
  {
    "text": "development you package everything as a production job to submit and then runtime environment is our",
    "start": "1389360",
    "end": "1395840"
  },
  {
    "text": "offering to manage dependencies and package for the artifact developers will",
    "start": "1395840",
    "end": "1401120"
  },
  {
    "text": "uh generate so lastly um so in a more broad sense right so we're",
    "start": "1401120",
    "end": "1408000"
  },
  {
    "text": "also enhancing the deployment and language devices a lot i think robert already emphasized window support as",
    "start": "1408000",
    "end": "1415600"
  },
  {
    "text": "it's uh there has been a long effort but now we have reached the beta in 1.10 that will",
    "start": "1415600",
    "end": "1421840"
  },
  {
    "text": "come out so for people using windows we definitely uh will appreciate the input",
    "start": "1421840",
    "end": "1427120"
  },
  {
    "text": "a lot for you to try it out and kubernetes that's another area we're putting a lot of effort on uh from the",
    "start": "1427120",
    "end": "1433279"
  },
  {
    "text": "community there's a community project called cuperi uh it involves engineers",
    "start": "1433279",
    "end": "1438720"
  },
  {
    "text": "from microsoft from bite dance from and group and a few other companies uh were",
    "start": "1438720",
    "end": "1445200"
  },
  {
    "text": "actively investigating what's the best way to integrate with calgary to uh run ray on kubernetes clusters and",
    "start": "1445200",
    "end": "1452080"
  },
  {
    "text": "uh we're also uh improving our support for conda for m1 for java and c plus plus",
    "start": "1452080",
    "end": "1458640"
  },
  {
    "text": "javascript plus i want to really uh acknowledge the contribution from and group 18",
    "start": "1458640",
    "end": "1466960"
  },
  {
    "text": "and yeah that covers this part of the talk so 1.9 and beyond",
    "start": "1466960",
    "end": "1473760"
  },
  {
    "text": "um happy to discuss if you have questions",
    "start": "1473760",
    "end": "1478799"
  },
  {
    "text": "well thank you very much for giving us an update on on what's the current state",
    "start": "1478799",
    "end": "1484159"
  },
  {
    "text": "of rey it's come a long way i remember attending this meetup about two years ago at at san francisco in in galvanize and",
    "start": "1484159",
    "end": "1491679"
  },
  {
    "text": "we were still at 0.8 million today we almost close to one 1.10 and all these new libraries have emerged um if you",
    "start": "1491679",
    "end": "1499600"
  },
  {
    "text": "actually want to start learning ray here's a slide that you can just get started just do pip install and you're",
    "start": "1499600",
    "end": "1504720"
  },
  {
    "text": "there you can actually go and run with it we have a copious amount of documentation on each and every library",
    "start": "1504720",
    "end": "1510000"
  },
  {
    "text": "so go to our docs.reio please join our meetup you're already here so i don't need to",
    "start": "1510000",
    "end": "1515039"
  },
  {
    "text": "acknowledge that we have forums where we actually talk about uh all these different native libraries as well as",
    "start": "1515039",
    "end": "1520880"
  },
  {
    "text": "ecosystem at a very highly technical level all of our communities and all of our contributors are online to answer",
    "start": "1520880",
    "end": "1526240"
  },
  {
    "text": "your questions join us on slack follow us on social media we would love to hear you get us get us in touch with us and",
    "start": "1526240",
    "end": "1533520"
  },
  {
    "text": "um a bribery give us a give us give us give us a star on on the github now let me",
    "start": "1533520",
    "end": "1539360"
  },
  {
    "text": "see if you actually have any questions uh for you guys robert or this might be something either one of",
    "start": "1539360",
    "end": "1546159"
  },
  {
    "text": "you can actually answer the question uh robert you mentioned something about in your one of your slides",
    "start": "1546159",
    "end": "1552960"
  },
  {
    "text": "in the layered cake of functionality and and capabilities of ray that it's a general purpose in a universal framework",
    "start": "1552960",
    "end": "1560799"
  },
  {
    "text": "what is what is so universal in general about it can you can you expand on that please yeah that's a that's a great",
    "start": "1560799",
    "end": "1566640"
  },
  {
    "text": "question i think one of the things is it really has to do with the choice of the apis for ray and if you think about um a",
    "start": "1566640",
    "end": "1574720"
  },
  {
    "text": "lot of you know different distributed systems like take apache spark right um you know",
    "start": "1574720",
    "end": "1580640"
  },
  {
    "text": "spark introduces this concept of a data set right or a data frame if you think about other things like um",
    "start": "1580640",
    "end": "1586720"
  },
  {
    "text": "you know tensorflow it introduces the concept of a neural network right and so if you're building applications that are",
    "start": "1586720",
    "end": "1592799"
  },
  {
    "text": "about processing a data set or you know training a neural network then those are kind of the right abstractions on the",
    "start": "1592799",
    "end": "1598799"
  },
  {
    "text": "other hand if you look at the core ray system and i'm not not talking about the ecosystem on top of ray but just the you",
    "start": "1598799",
    "end": "1604240"
  },
  {
    "text": "know the core array system um the api there the concepts introduced are really",
    "start": "1604240",
    "end": "1609279"
  },
  {
    "text": "just um you know python functions and python classes so the existing concepts that",
    "start": "1609279",
    "end": "1614799"
  },
  {
    "text": "people use uh when they're programming in python and it's just that ray translates you know instead of like",
    "start": "1614799",
    "end": "1620799"
  },
  {
    "text": "introducing new concepts like a data set uh what ray does is it takes the existing concepts that developers are",
    "start": "1620799",
    "end": "1627440"
  },
  {
    "text": "familiar with when they're programming in python and sort of translates those over to the distributed settings so you",
    "start": "1627440",
    "end": "1632559"
  },
  {
    "text": "can take python functions and turn those into array tasks and you know python classes and turn those into reactors and",
    "start": "1632559",
    "end": "1638720"
  },
  {
    "text": "so a lot of the generality comes from the fact that we are instead of introducing new concepts that you kind of uh coerce your application",
    "start": "1638720",
    "end": "1645760"
  },
  {
    "text": "into we are taking existing concepts that developers use and sort of translating those over to",
    "start": "1645760",
    "end": "1651760"
  },
  {
    "text": "the distributed setting and so you can really express a very broad set of applications in that in that way now of",
    "start": "1651760",
    "end": "1658559"
  },
  {
    "text": "course functions and classes are somewhat lower level than data sets or neural networks and that's hence the",
    "start": "1658559",
    "end": "1665520"
  },
  {
    "text": "you know the importance of this library ecosystem on top of right because ultimately you want to have great libraries that you can use off the shelf",
    "start": "1665520",
    "end": "1671679"
  },
  {
    "text": "you know without having to build all the application logic using using functions and classes",
    "start": "1671679",
    "end": "1678000"
  },
  {
    "text": "thank you robert that was there was a great library of answer i think one more question that either xiao you or or",
    "start": "1678000",
    "end": "1683039"
  },
  {
    "text": "robert can actually take that are there any um case studies of interrupted",
    "start": "1683039",
    "end": "1688559"
  },
  {
    "text": "interoperability between the gc cloud ml ecosystem and the ray ecosystem",
    "start": "1688559",
    "end": "1696240"
  },
  {
    "text": "so um joe you might uh know the answer more than i do i'm not aware of any",
    "start": "1696240",
    "end": "1702320"
  },
  {
    "text": "um case studies like published case studies like that i think there are some with",
    "start": "1702320",
    "end": "1707360"
  },
  {
    "text": "people using sagemaker along with ray so um so that and there there might be some similarities there but um",
    "start": "1707360",
    "end": "1714399"
  },
  {
    "text": "that's that would probably be the best things yes stay tuned because um shopify which",
    "start": "1714399",
    "end": "1720159"
  },
  {
    "text": "is a very important open source reuser they're on gcp and",
    "start": "1720159",
    "end": "1725279"
  },
  {
    "text": "they will publish um how they're using ray fairly soon",
    "start": "1725279",
    "end": "1730640"
  },
  {
    "text": "and i think the last question that we might want to answer before we actually move on to of our next speaker",
    "start": "1731440",
    "end": "1737520"
  },
  {
    "text": "alex is there a spark ecosystem integration uh with with with ray",
    "start": "1737520",
    "end": "1743039"
  },
  {
    "text": "i probably want to mention something about spark on ray but sure elaborate on that one yeah there's a project for adp",
    "start": "1743039",
    "end": "1749600"
  },
  {
    "text": "i will type the link in the chat and i'm sure uh clark and alex",
    "start": "1749600",
    "end": "1754960"
  },
  {
    "text": "have a lot more insights so i think for detailed questions about raditi uh we can even further discuss in",
    "start": "1754960",
    "end": "1761360"
  },
  {
    "text": "the next talk yeah it's a link first we'll yeah we'll we'll put the link on the slack well having say that i think this is this is",
    "start": "1761360",
    "end": "1767919"
  },
  {
    "text": "a great context that both of you actually have said with what's happened with the rare committee and how ray has actually progressed in the last um two",
    "start": "1767919",
    "end": "1774880"
  },
  {
    "text": "years and it's actually great to see this momentum going forward and we depend on you to carry us to the next level and i think",
    "start": "1774880",
    "end": "1781919"
  },
  {
    "text": "the next thing we want to talk about is transitioning into the new native library it's called ray data sets uh",
    "start": "1781919",
    "end": "1788159"
  },
  {
    "text": "that is currently in beta and we have alex and clark both who are software engineers who work on the radiator set",
    "start": "1788159",
    "end": "1794960"
  },
  {
    "text": "they're both commuters and contributors to this massive project uh so i'll have",
    "start": "1794960",
    "end": "1800000"
  },
  {
    "text": "them give you an introduction of what ray data sets is all about and you can ask them more questions about about",
    "start": "1800000",
    "end": "1805840"
  },
  {
    "text": "everything you want to know about ray data sets so uh take it away um alex you're on yeah thanks jules and uh",
    "start": "1805840",
    "end": "1813279"
  },
  {
    "text": "thanks robert and joe for that uh like great uh recap of where rey has been in the last year and where it's going it's",
    "start": "1813279",
    "end": "1819360"
  },
  {
    "text": "crazy to think how quickly all these projects have been growing um",
    "start": "1819360",
    "end": "1824640"
  },
  {
    "text": "and so yeah um so as joules said um i'm alex i'm a software engineer here at any scale and a contributor to ray and clark",
    "start": "1824640",
    "end": "1833360"
  },
  {
    "text": "do you want to just really quickly introduce yourself to yeah sure hello i'm clark uh i am also a software",
    "start": "1833360",
    "end": "1839600"
  },
  {
    "text": "engineer at any scale and also a contributor to ray and i like working on data stuff yeah",
    "start": "1839600",
    "end": "1846320"
  },
  {
    "text": "yeah yeah thank you yeah um and we're gonna be talking today about um essentially like unifying how people are",
    "start": "1846320",
    "end": "1852399"
  },
  {
    "text": "currently doing their data pre-processing and training um specifically andre using data sets which um",
    "start": "1852399",
    "end": "1858159"
  },
  {
    "text": "as uh robert and joe have alluded to have been uh really something that's really gained a lot of traction in the",
    "start": "1858159",
    "end": "1863440"
  },
  {
    "text": "last couple of months and uh hopefully we'll continue to gain traction",
    "start": "1863440",
    "end": "1868960"
  },
  {
    "text": "all right so we're going to get started uh today by essentially taking a look at how people are currently doing ml",
    "start": "1868960",
    "end": "1874240"
  },
  {
    "text": "training and scoring and how they're setting up these pipelines today without ray datasets and we're gonna really use that and the challenges that",
    "start": "1874240",
    "end": "1880480"
  },
  {
    "text": "people are facing today to essentially motivate um why why we built uh ray datasets to",
    "start": "1880480",
    "end": "1886080"
  },
  {
    "text": "begin with then we're gonna take a look at ray datasets obviously which is what the uh this talk is about and then uh finally",
    "start": "1886080",
    "end": "1893279"
  },
  {
    "text": "we don't want to just tell you the theory of ray data sets uh we're gonna we want to spend a lot of time showing you guys uh essentially how people are",
    "start": "1893279",
    "end": "1899120"
  },
  {
    "text": "using data sets today and the like early results that we're already seeing people uh get",
    "start": "1899120",
    "end": "1905760"
  },
  {
    "text": "okay uh so with that let's take a look at what a typical uh data processing pipeline uh looks like today so this may",
    "start": "1905760",
    "end": "1912320"
  },
  {
    "text": "look familiar to many of you um even many of you who may be only using a single component of ray right now",
    "start": "1912320",
    "end": "1917440"
  },
  {
    "text": "so typically uh the way people do their um their training pipelines is they'll start by using some kind of a data processing",
    "start": "1917440",
    "end": "1923840"
  },
  {
    "text": "framework to do their pre-processing so if you have a lot of really big data you know spark is typically the go-to uh",
    "start": "1923840",
    "end": "1930640"
  },
  {
    "text": "framework for doing this um for those of you who really love the python ecosystem and want to stay within it um das is you",
    "start": "1930640",
    "end": "1936640"
  },
  {
    "text": "know probably by far one of the most popular distributed data frame libraries um in python",
    "start": "1936640",
    "end": "1942799"
  },
  {
    "text": "so typically people will use these types of frameworks to do their data pre-processing um but they don't have an easy way of",
    "start": "1942799",
    "end": "1948559"
  },
  {
    "text": "feeding that data into their training frameworks which are almost always written in python and are almost always use",
    "start": "1948559",
    "end": "1956159"
  },
  {
    "text": "slightly incompatible data set formats so typically the way people deal with this is they'll first checkpoint their",
    "start": "1956159",
    "end": "1962480"
  },
  {
    "text": "data by writing it into some storage like hdfs or s3 um and then pick it up in a new job and",
    "start": "1962480",
    "end": "1969039"
  },
  {
    "text": "use horvat or xgboost or whatever their favorite training library is to train and finally because you have multiple",
    "start": "1969039",
    "end": "1974960"
  },
  {
    "text": "components uh in multiple jobs that depend on each other here you'll need to wrap that around some kind of an",
    "start": "1974960",
    "end": "1980000"
  },
  {
    "text": "orchestrator or a workflow engine like kubeflow or airflow",
    "start": "1980000",
    "end": "1985679"
  },
  {
    "text": "and um you know because a lot of these frameworks were in different languages you either need to mess with a lot of",
    "start": "1985679",
    "end": "1990720"
  },
  {
    "text": "yaml files or you need to find some way of uh orchestrating like a a job that uses multiple languages and multiple",
    "start": "1990720",
    "end": "1996960"
  },
  {
    "text": "different clusters okay so let's take a look at some of the concrete challenges that people face",
    "start": "1996960",
    "end": "2002320"
  },
  {
    "text": "when they're doing this um so uh really like there are a lot of inefficiencies in like the way people",
    "start": "2002320",
    "end": "2008080"
  },
  {
    "text": "are currently doing uh their setting up their data pipelines but they're they're ml training",
    "start": "2008080",
    "end": "2013279"
  },
  {
    "text": "pipelines um so one of the big performance issues here is just that like this is a very inefficient process",
    "start": "2013279",
    "end": "2018640"
  },
  {
    "text": "so um you know like a lot of python frameworks uh suffer from like the global interpreter lock in order to get",
    "start": "2018640",
    "end": "2024320"
  },
  {
    "text": "around that they find themselves constantly serializing and deserializing data in order to pass it around between",
    "start": "2024320",
    "end": "2029919"
  },
  {
    "text": "processes within the java ecosystem you may not have a global interpreter lock but people still in practice end up finding",
    "start": "2029919",
    "end": "2036159"
  },
  {
    "text": "that when it comes to passing data between nodes they're doing a lot of serialization and deserialization that really isn't",
    "start": "2036159",
    "end": "2042640"
  },
  {
    "text": "fundamentally important to their job and finally if you're writing data to storage that almost requires you to",
    "start": "2042640",
    "end": "2048398"
  },
  {
    "text": "serialize it or maybe compress your data into some other format um and then there's a lot of complexity",
    "start": "2048399",
    "end": "2054720"
  },
  {
    "text": "in like uh you know both implementing and like operating these types of jobs so if you're using spark you have a lot",
    "start": "2054720",
    "end": "2060720"
  },
  {
    "text": "of cross language difficulties between java and python those two ecosystems don't work well together most of the",
    "start": "2060720",
    "end": "2066560"
  },
  {
    "text": "times um you also typically find that you'll have things like your date your pre-processing typically uses cpus",
    "start": "2066560",
    "end": "2072398"
  },
  {
    "text": "whereas your training uses gpus and so you need a cluster that's able to efficiently uh and like intelligently",
    "start": "2072399",
    "end": "2078398"
  },
  {
    "text": "schedule your tasks your cpu tasks on cpu nodes and your gpu tasks on gpu nodes in order to be really really",
    "start": "2078399",
    "end": "2084000"
  },
  {
    "text": "efficient and then finally there are some operations that just that uh people in",
    "start": "2084000",
    "end": "2091118"
  },
  {
    "text": "the like ml research uh community have uh discovered and realized they really like on single nodes but there's currently no good way",
    "start": "2091119",
    "end": "2097520"
  },
  {
    "text": "of doing them efficiently in a production setting okay so as you may imagine you may have",
    "start": "2097520",
    "end": "2102800"
  },
  {
    "text": "imagined uh these challenges are essentially why we built ray datasets so now we're going to take a look at ray datasets",
    "start": "2102800",
    "end": "2108160"
  },
  {
    "text": "um and uh how we believe that ray datasets can help solve these problems",
    "start": "2108160",
    "end": "2113359"
  },
  {
    "text": "so as a very brief intro to array data sets essentially ray datasets provides you with a distributed uh table",
    "start": "2113359",
    "end": "2119680"
  },
  {
    "text": "abstraction and it's built on top of ray um and so we'll see uh really quickly just how",
    "start": "2119680",
    "end": "2125280"
  },
  {
    "text": "like ray datasets leverages spray and what features it uses so um as i mentioned before uh ray",
    "start": "2125280",
    "end": "2131280"
  },
  {
    "text": "solves a lot of these problems that we've mentioned so for example it has an extremely efficient data layer we've spent years now you know really working",
    "start": "2131280",
    "end": "2137599"
  },
  {
    "text": "through the kinks of making sure this thing is really really efficient and so we can solve a lot of it already solves",
    "start": "2137599",
    "end": "2142800"
  },
  {
    "text": "a lot of serialization problems by doing zero copy reads um and having shared memory um the ray scheduler handles a lot of",
    "start": "2142800",
    "end": "2150000"
  },
  {
    "text": "really intelligent things to schedule your tasks and it can take into account things like gpu tasks",
    "start": "2150000",
    "end": "2156079"
  },
  {
    "text": "and finally it provides a very general set of robust primitives which means that it's easy to uh it provides you with the",
    "start": "2156079",
    "end": "2163440"
  },
  {
    "text": "ability to do very complex things um and run other special uh frameworks on top of it",
    "start": "2163440",
    "end": "2170800"
  },
  {
    "text": "okay so now let's take a look at data sets so data sets is essentially uh a distributed uh data set abstraction",
    "start": "2171119",
    "end": "2178560"
  },
  {
    "text": "um that's meant to unify both the concept of a data set um in the data frame pre-processing sense as well as",
    "start": "2178560",
    "end": "2184480"
  },
  {
    "text": "the data set concept that distributed training um frameworks have",
    "start": "2184480",
    "end": "2190000"
  },
  {
    "text": "um and so data sets is really meant to do uh three key things so first of all uh datasets is meant to be a universal",
    "start": "2190000",
    "end": "2196400"
  },
  {
    "text": "way of essentially getting your data from wherever it currently is and into a ray cluster where you can work with it more easily",
    "start": "2196400",
    "end": "2202720"
  },
  {
    "text": "um the most important thing that people usually want to do with data sets is do a little bit of last mile pre-processing",
    "start": "2202720",
    "end": "2208640"
  },
  {
    "text": "with that data so that they can feed it into a training framework there's a lot of pre-process there's a lot of like little",
    "start": "2208640",
    "end": "2214800"
  },
  {
    "text": "things in the last second uh pre-processing that you may want to do that don't make sense to checkpoint",
    "start": "2214800",
    "end": "2220000"
  },
  {
    "text": "and then finally um another really important use for data sets is being able to do parallel computation that",
    "start": "2220000",
    "end": "2225520"
  },
  {
    "text": "uses both the gpus and cpus all right so one thing to be really",
    "start": "2225520",
    "end": "2232079"
  },
  {
    "text": "clear about here before we dive into it is that uh datasets is not meant to replace spark or",
    "start": "2232079",
    "end": "2237920"
  },
  {
    "text": "other really common data frame libraries out there we think those libraries do a really really great job at what they do",
    "start": "2237920",
    "end": "2243119"
  },
  {
    "text": "um and we don't want to replace them we just want to make sure that they alex you're i think your sound cut out",
    "start": "2243119",
    "end": "2248800"
  },
  {
    "text": "oh i'm sorry uh it's not just me okay no can someone else confirm",
    "start": "2248800",
    "end": "2254160"
  },
  {
    "text": "yeah i can i can hear him i can i heard him talking too all right cool um yeah so let me just repeat that last part um so yeah so",
    "start": "2254160",
    "end": "2261280"
  },
  {
    "text": "um one thing that data frames the our data set library is not it is not meant to be a replacement for your existing uh",
    "start": "2261280",
    "end": "2267200"
  },
  {
    "text": "data processing libraries so we think that spark and das do a great job at what they do and what we want to make",
    "start": "2267200",
    "end": "2272800"
  },
  {
    "text": "sure they they do is we want to make sure that you can continue to use your favorite uh data processing library and",
    "start": "2272800",
    "end": "2278400"
  },
  {
    "text": "have it integrate well into the ray ecosystem okay um so this is sort of where we see",
    "start": "2278400",
    "end": "2284800"
  },
  {
    "text": "ray data that's fitting into um the like general ml ecosystem so if you have a lot of unstructured uh data uh we still",
    "start": "2284800",
    "end": "2292079"
  },
  {
    "text": "expect you to be using uh you know doing etl using your favorite uh pre-processing frameworks whether it's sparks link you know you're pulling that",
    "start": "2292079",
    "end": "2298960"
  },
  {
    "text": "from a data store like snowflake or delta lake we want you to use ray datasets to load",
    "start": "2298960",
    "end": "2304480"
  },
  {
    "text": "that data into your uh into your ray cluster and then we want you to be able to seamlessly use that data in any of",
    "start": "2304480",
    "end": "2310000"
  },
  {
    "text": "your favorite uh training frameworks that are built on top of ray like raytrain horvad distributed tensorflow",
    "start": "2310000",
    "end": "2316240"
  },
  {
    "text": "distributed pi torch all right so let's take a look at the",
    "start": "2316240",
    "end": "2321359"
  },
  {
    "text": "universal data loading aspect so essentially here um ray's ray dataset's job is to essentially act as sort of the",
    "start": "2321359",
    "end": "2328079"
  },
  {
    "text": "distributed version of arrow so we want you to be able to take your data whether it's in a data frame already like mode",
    "start": "2328079",
    "end": "2333280"
  },
  {
    "text": "in dash or spark or whether it's stored in storage and move that data uh and store that data in a data set",
    "start": "2333280",
    "end": "2340560"
  },
  {
    "text": "then now that we have it in a universal format um libraries like horvat or tensorflow or x3boost only have to be",
    "start": "2340560",
    "end": "2346400"
  },
  {
    "text": "able to work with a single uh distributed data format to be able to uh ingest data from any of these other",
    "start": "2346400",
    "end": "2352320"
  },
  {
    "text": "sources so it provides essentially a narrow waste um and the way that we're able to",
    "start": "2352320",
    "end": "2357440"
  },
  {
    "text": "accomplish this is uh we really heavily rely on arrow on the back end so arrow",
    "start": "2357440",
    "end": "2362800"
  },
  {
    "text": "already solved this job on a single node and so uh dataset's job is to essentially distribute this",
    "start": "2362800",
    "end": "2369838"
  },
  {
    "text": "cool um so this is just a quick slide i'm showing some of the uh some of the",
    "start": "2370079",
    "end": "2375440"
  },
  {
    "text": "data formats that we support um you can go find a more up-to-date version of this table now in our docs um but as you",
    "start": "2375440",
    "end": "2382160"
  },
  {
    "text": "can see like we've uh really uh done a lot of work to try to support um as many different input uh and output uh data",
    "start": "2382160",
    "end": "2389200"
  },
  {
    "text": "types that uh we could and again like because we rely on arrow a lot of this",
    "start": "2389200",
    "end": "2394320"
  },
  {
    "text": "we were able to do a lot of this very quickly okay um so",
    "start": "2394320",
    "end": "2400800"
  },
  {
    "text": "not only do we want to be able to read the state in but we want to be performing i'm going to go over this section a little quickly because i think",
    "start": "2400800",
    "end": "2406400"
  },
  {
    "text": "we're going to see later in patrick's slides that a lot of this is not even not theory anymore it's really practical so",
    "start": "2406400",
    "end": "2412960"
  },
  {
    "text": "we've tried to make it extremely easy to uh read and write from any type of storage it should be one line to get",
    "start": "2412960",
    "end": "2419359"
  },
  {
    "text": "your data into a ray and again we want to be extremely efficient and",
    "start": "2419359",
    "end": "2424640"
  },
  {
    "text": "extremely paralyzed and uh patrick will probably talk uh in more depth about um how he's able to use data sets uh with",
    "start": "2424640",
    "end": "2431520"
  },
  {
    "text": "his library um and get this uh performance in the real world and get it to scale up really really well",
    "start": "2431520",
    "end": "2438400"
  },
  {
    "text": "okay so now let's take a look at uh last mile pre-processing so uh with last mile pre-processing um we want to be able to",
    "start": "2438400",
    "end": "2443920"
  },
  {
    "text": "support the types of operations that uh don't make sense to do while you're doing your typical data processing right",
    "start": "2443920",
    "end": "2449200"
  },
  {
    "text": "they're things like random cropping or shuffling of your data that it doesn't make sense to uh redo that kind",
    "start": "2449200",
    "end": "2455280"
  },
  {
    "text": "of work and like restore that kind of data in s3 and so we want you to be able to do that",
    "start": "2455280",
    "end": "2460720"
  },
  {
    "text": "at the very last second in memory to be really really efficient um and so for that reason uh dataset supports a",
    "start": "2460720",
    "end": "2466880"
  },
  {
    "text": "lot of the like basic transformations and aggregations that you would typically expect um out of uh out of the",
    "start": "2466880",
    "end": "2473040"
  },
  {
    "text": "library um like this or out of like any uh data set or data loader so you can do things like maps batching batch maps uh",
    "start": "2473040",
    "end": "2480000"
  },
  {
    "text": "you can do filtering uh you can do aggregations and even a couple of uh global shuffle operations that if you",
    "start": "2480000",
    "end": "2486240"
  },
  {
    "text": "come from a system's background uh you may recognize as being really pretty pretty challenging to implement",
    "start": "2486240",
    "end": "2491680"
  },
  {
    "text": "efficiently and stably um and so just to illustrate what this might look like if you have some kind of",
    "start": "2491680",
    "end": "2497839"
  },
  {
    "text": "an input um you know you may start by taking that input you may want to map it",
    "start": "2497839",
    "end": "2503119"
  },
  {
    "text": "and you know like apply some transformation to each of your data points and then you may want to do some kind of a shuffle uh or like group your group",
    "start": "2503119",
    "end": "2510160"
  },
  {
    "text": "your data by some class um and then do some kind of reduction operation like uh you know like finding the averages or",
    "start": "2510160",
    "end": "2517040"
  },
  {
    "text": "summing something and then finally combine that back into an output um",
    "start": "2517040",
    "end": "2522880"
  },
  {
    "text": "all right cool um yeah so now um another really important uh feature that datasets have for efficiency is",
    "start": "2522880",
    "end": "2528800"
  },
  {
    "text": "essentially pipelining um so for those of you who do not know what pipelining is just a really brief introduction",
    "start": "2528800",
    "end": "2534880"
  },
  {
    "text": "essentially uh you can think of like a typical pre-processing pipeline like this uh there are steps like loading pre-processing and doing inferences on",
    "start": "2534880",
    "end": "2541280"
  },
  {
    "text": "your data um and typically if you try to do this naively you may load your data first on pre-process and then start doing some",
    "start": "2541280",
    "end": "2547440"
  },
  {
    "text": "inference but the issue with this is that your gpu is sitting here idle while just wasting money uh while you're not",
    "start": "2547440",
    "end": "2554160"
  },
  {
    "text": "using it and so the idea with pipelining is that uh we should be able to use the gdp we should be getting we should begin to use",
    "start": "2554160",
    "end": "2560079"
  },
  {
    "text": "the gpu as soon as possible and use it for as little time as possible so um in",
    "start": "2560079",
    "end": "2565440"
  },
  {
    "text": "a pipeline version of this pipeline essentially what we're going to do is you want to be able to immediately start",
    "start": "2565440",
    "end": "2570880"
  },
  {
    "text": "doing your preprocessing once your first data points get loaded into memory and then right when that preprocessing",
    "start": "2570880",
    "end": "2576240"
  },
  {
    "text": "finishes you want to already begin to do inference on that and so if we do this we can make a much more efficient use of",
    "start": "2576240",
    "end": "2581440"
  },
  {
    "text": "our cluster and save a lot of money that way um and then finally",
    "start": "2581440",
    "end": "2587200"
  },
  {
    "text": "we also support windowing so windowing is also really important because there are some operations like shuffling that you can't do over just a small portion",
    "start": "2587200",
    "end": "2593440"
  },
  {
    "text": "of your dataset and so um windowing can allow you to essentially execute a pipeline over just part of",
    "start": "2593440",
    "end": "2599839"
  },
  {
    "text": "your data set and of course this works seamlessly with pipelining too so just a little illustration of how this works um you",
    "start": "2599839",
    "end": "2606880"
  },
  {
    "text": "know you may have a pipeline you may have your data set workload do",
    "start": "2606880",
    "end": "2612480"
  },
  {
    "text": "something like this without a pipeline where you take a bunch of your data and if it's too big to actually fit in",
    "start": "2612480",
    "end": "2617599"
  },
  {
    "text": "your cluster you may have to fill to disk which is really really inefficient so instead what you may want to do",
    "start": "2617599",
    "end": "2623599"
  },
  {
    "text": "um is uh first of all you can still do pipelining but even with your if your pipeline is",
    "start": "2623599",
    "end": "2628800"
  },
  {
    "text": "too large um you can also take you can also split into windows and run your pipeline over a single window at a time",
    "start": "2628800",
    "end": "2635280"
  },
  {
    "text": "um and sometimes there's a bit of a trade-off here in you know um like model quality or something like that with uh",
    "start": "2635280",
    "end": "2641359"
  },
  {
    "text": "performance but in practice we found that like this is something that people can do in practice um and the trade-off",
    "start": "2641359",
    "end": "2646880"
  },
  {
    "text": "becomes well worth it okay cool so now i'm going to hand it",
    "start": "2646880",
    "end": "2652400"
  },
  {
    "text": "off to clark who is going to talk more about concrete use cases um that people have been using data sets for in the",
    "start": "2652400",
    "end": "2658319"
  },
  {
    "text": "real world yes thank you alex uh thank you for for",
    "start": "2658319",
    "end": "2664160"
  },
  {
    "text": "going through those slides and also uh yeah apologies for for uh thinking that uh your mic wasn't",
    "start": "2664160",
    "end": "2671280"
  },
  {
    "text": "working when it was actually my headphones that weren't working uh so hopefully we don't have any more uh",
    "start": "2671280",
    "end": "2677359"
  },
  {
    "text": "technical difficulties on my end um oh wait that's not the right one let me",
    "start": "2677359",
    "end": "2683040"
  },
  {
    "text": "i thought clark you just wanted him to repeat what he said before sorry no i thought i thought you just wanted",
    "start": "2683040",
    "end": "2689359"
  },
  {
    "text": "him to repeat what he said before sure the data sets is not a replacement for spark",
    "start": "2689359",
    "end": "2695200"
  },
  {
    "text": "all right this should i feel like this keeps sharing the wrong uh",
    "start": "2695200",
    "end": "2700319"
  },
  {
    "text": "screen hold on uh i think i know what's going on",
    "start": "2700319",
    "end": "2706240"
  },
  {
    "text": "let me try this again nope that seems to be the wrong one",
    "start": "2706240",
    "end": "2712000"
  },
  {
    "text": "um yeah let me try",
    "start": "2712000",
    "end": "2717880"
  },
  {
    "text": "yeah it's weird um this should be the correct window",
    "start": "2721200",
    "end": "2727519"
  },
  {
    "text": "um i guess uh what window are you uh slides now",
    "start": "2728480",
    "end": "2735359"
  },
  {
    "text": "yeah yeah okay okay good um i'll just like this isn't the window that i wanted",
    "start": "2735680",
    "end": "2740800"
  },
  {
    "text": "but i guess that's okay um okay yeah um so yeah thanks again alex for uh for going through an intro",
    "start": "2740800",
    "end": "2748079"
  },
  {
    "text": "to data sets and also a very great motivation i'm super super excited to",
    "start": "2748079",
    "end": "2753440"
  },
  {
    "text": "talk about the two biggest use cases of data sets uh those two big use cases are",
    "start": "2753440",
    "end": "2758480"
  },
  {
    "text": "super scalable shuffled ml ingest this is uh loading data shuffling data and",
    "start": "2758480",
    "end": "2764400"
  },
  {
    "text": "getting it to a distributed set of model trainers um such that you",
    "start": "2764400",
    "end": "2770160"
  },
  {
    "text": "don't want the data loading or shuffling to be your training throughput bottleneck and then the other big use case is doing",
    "start": "2770160",
    "end": "2777520"
  },
  {
    "text": "batch inference very efficiently um and when i'm saying efficient you really don't want to be wasting that gpu",
    "start": "2777520",
    "end": "2783119"
  },
  {
    "text": "resource uh because those uh kind of cost money so first",
    "start": "2783119",
    "end": "2788640"
  },
  {
    "text": "the scalable shuffled ml ingest use case a little bit of background on this one",
    "start": "2788640",
    "end": "2793760"
  },
  {
    "text": "a quick overview of this use case the core goal is to load data quickly into one or more model trainers",
    "start": "2793760",
    "end": "2801599"
  },
  {
    "text": "the primary functions here are loading the data from some external storage or maybe from",
    "start": "2801599",
    "end": "2807280"
  },
  {
    "text": "another like in-memory representation of your data set if you already have it in memory",
    "start": "2807280",
    "end": "2812880"
  },
  {
    "text": "um you want to partition the data into a shard per trainer if you have multiple trainers this will allow you to do",
    "start": "2812880",
    "end": "2819839"
  },
  {
    "text": "data parallel training and then you want to batch the data into",
    "start": "2819839",
    "end": "2825119"
  },
  {
    "text": "gpu batches this is going to allow you to saturate your gpu memory and increase",
    "start": "2825119",
    "end": "2830960"
  },
  {
    "text": "your training throughput um it's good times and then uh you want to shuffle the data",
    "start": "2830960",
    "end": "2836560"
  },
  {
    "text": "before each epoch and uh for those who think that are or maybe saying oh why do",
    "start": "2836560",
    "end": "2841920"
  },
  {
    "text": "i want to do that i will i will fully motivate that in the next slide for certain models this can be very",
    "start": "2841920",
    "end": "2847599"
  },
  {
    "text": "important right now the current solution for per epoch shuffling",
    "start": "2847599",
    "end": "2853200"
  },
  {
    "text": "is typically local shuffling this is where you have an in-memory buffer on each trainer and",
    "start": "2853200",
    "end": "2859599"
  },
  {
    "text": "after that initial split of shards at the beginning of training each trainer is only",
    "start": "2859599",
    "end": "2866400"
  },
  {
    "text": "reshuffling their shard at the beginning of each epoch and there can actually be issues with that uh if",
    "start": "2866400",
    "end": "2873359"
  },
  {
    "text": "you're not shuffling across shards between epochs um and global shuffling uh where you're",
    "start": "2873359",
    "end": "2880160"
  },
  {
    "text": "actually doing essentially a full random sample from the full data set at the",
    "start": "2880160",
    "end": "2885680"
  },
  {
    "text": "beginning of each epoch for each of those shards this is better",
    "start": "2885680",
    "end": "2891200"
  },
  {
    "text": "as i'll show in a second but it's also very hard especially once your data set is too large to fit into the memory of a",
    "start": "2891200",
    "end": "2897760"
  },
  {
    "text": "single machine and also uh and or when doing distributed",
    "start": "2897760",
    "end": "2902800"
  },
  {
    "text": "training and so this is kind of just showing uh that data coming from a data source your",
    "start": "2902800",
    "end": "2908720"
  },
  {
    "text": "data loader creating those shards and then feeding those shards into the trainers the corresponding trainers",
    "start": "2908720",
    "end": "2917440"
  },
  {
    "text": "all right so first a quick aside uh why do we want to shuffle before each epoch i thought i could just you know shuffle",
    "start": "2918240",
    "end": "2924400"
  },
  {
    "text": "my gigantic data set and spark once before training and then pretty much call it good right",
    "start": "2924400",
    "end": "2930240"
  },
  {
    "text": "well the tldr for this is that for certain models and data sets uh per epoch shuffling actually gives you a",
    "start": "2930240",
    "end": "2937040"
  },
  {
    "text": "much better model accuracy for a given set number of epochs um and",
    "start": "2937040",
    "end": "2942240"
  },
  {
    "text": "you can think of this uh as decorating samples within and across the gpu batches",
    "start": "2942240",
    "end": "2949359"
  },
  {
    "text": "um and and this is important even uh to do like on each epoch",
    "start": "2949359",
    "end": "2955520"
  },
  {
    "text": "and this per epoch shuffling reduces variance and improves the generalization of your model and it prevents",
    "start": "2955520",
    "end": "2961680"
  },
  {
    "text": "overfitting you can think of this as batches being more representative of the entire data",
    "start": "2961680",
    "end": "2967599"
  },
  {
    "text": "set therefore improving the estimate of the true full data set gradient um which is",
    "start": "2967599",
    "end": "2973359"
  },
  {
    "text": "certainly what you want uh and uh the grady uh the gradient updates on uh",
    "start": "2973359",
    "end": "2978800"
  },
  {
    "text": "individual samples are also made independent of sample ordering you can think of certain data sets such",
    "start": "2978800",
    "end": "2984240"
  },
  {
    "text": "as uh let's say you were a certain uh transportation company and you had a lot",
    "start": "2984240",
    "end": "2989520"
  },
  {
    "text": "of data samples that were temporarily correlated um where you're finding that you would you'd certainly not want uh",
    "start": "2989520",
    "end": "2996480"
  },
  {
    "text": "when training a model if that temporal correlation is uh really you're not wanting to represent that in the model",
    "start": "2996480",
    "end": "3002079"
  },
  {
    "text": "uh you might get some really bad uh overfitting uh uh on those temporal",
    "start": "3002079",
    "end": "3008160"
  },
  {
    "text": "correlations if you're having your model just train on all of those samples in a row so you definitely want to decorate",
    "start": "3008160",
    "end": "3014960"
  },
  {
    "text": "there and overall per epoch shuffling results in improved statistical gain",
    "start": "3014960",
    "end": "3021280"
  },
  {
    "text": "of each step in the training process and we have some uh results later that",
    "start": "3021280",
    "end": "3026640"
  },
  {
    "text": "uh show that that's the case for certain data sets and uh certain models um so first uh why is this hard",
    "start": "3026640",
    "end": "3034559"
  },
  {
    "text": "uh you've probably uh if you've only done single node training with smaller data sets you're probably thinking this",
    "start": "3034559",
    "end": "3041599"
  },
  {
    "text": "i don't really want to think about this this is just like i just want to you know load data",
    "start": "3041599",
    "end": "3046960"
  },
  {
    "text": "into my trainer um well first when your data set is large",
    "start": "3046960",
    "end": "3052240"
  },
  {
    "text": "and you have a distributed set of trainers you need to have um some very scalable and parallelizable reading from",
    "start": "3052240",
    "end": "3058319"
  },
  {
    "text": "your external storage uh you don't want your data loading to become your training bottleneck",
    "start": "3058319",
    "end": "3064000"
  },
  {
    "text": "um which it often becomes at a certain data scale you also really want to avoid",
    "start": "3064000",
    "end": "3070000"
  },
  {
    "text": "those pesky idle gpus when you're reading and shuffling that data if you look at this diagram here",
    "start": "3070000",
    "end": "3077200"
  },
  {
    "text": "if we are serially doing the shuffled data loading and then",
    "start": "3077200",
    "end": "3083040"
  },
  {
    "text": "feeding that epoch's worth of data into the trainers the gpu is sitting there idle during that shuffle data loading",
    "start": "3083040",
    "end": "3089280"
  },
  {
    "text": "time and those those little red gaps that's just you know completely burning money",
    "start": "3089280",
    "end": "3094480"
  },
  {
    "text": "which uh which nobody wants to do um and a continuation of this since",
    "start": "3094480",
    "end": "3099599"
  },
  {
    "text": "there are many hard things at a certain data scale um the full pipeline might not fit into the memory",
    "start": "3099599",
    "end": "3107680"
  },
  {
    "text": "of uh your number one of your of a single training node and uh number two",
    "start": "3107680",
    "end": "3113280"
  },
  {
    "text": "it might not fit into your uh cluster as a whole even if you have a good many machines",
    "start": "3113280",
    "end": "3118960"
  },
  {
    "text": "you're working on uh like many terabytes of training data you're going to be",
    "start": "3118960",
    "end": "3124160"
  },
  {
    "text": "encountering uh some issues unless you're creating a super massive cluster which uh you might",
    "start": "3124160",
    "end": "3130800"
  },
  {
    "text": "not want to do you know that might be uh that's a little bit like cost prohibitive um local shuffle shuffles uh hurt your",
    "start": "3130800",
    "end": "3138640"
  },
  {
    "text": "model accuracy um you know this is like the status quo solution is just to shuffle locally within a shard uh it",
    "start": "3138640",
    "end": "3145599"
  },
  {
    "text": "hurts your model accuracy but the big issue is this global per epoch shuffling is very",
    "start": "3145599",
    "end": "3151359"
  },
  {
    "text": "hard to do efficiently uh in a distributed setting you are fundamentally doing uh like an all to",
    "start": "3151359",
    "end": "3159200"
  },
  {
    "text": "all communication uh when between the maps and the reduces um and then not to mention that the",
    "start": "3159200",
    "end": "3165920"
  },
  {
    "text": "chunks of data that you're creating um in this distributed shuffle you're you're creating uh n squared chunks um",
    "start": "3165920",
    "end": "3174000"
  },
  {
    "text": "which is which can tend to be uh yeah a big issue um and but overall with all of these",
    "start": "3174000",
    "end": "3182079"
  },
  {
    "text": "difficulties of uh doing mo ingest at a large scale we want to solve these problems but we should really try to",
    "start": "3182079",
    "end": "3187680"
  },
  {
    "text": "keep the api simple um users didn't have to think about a lot of these problems when their data",
    "start": "3187680",
    "end": "3193440"
  },
  {
    "text": "set was small and they were training on a single node and ideally they would still not really",
    "start": "3193440",
    "end": "3198880"
  },
  {
    "text": "have to think about these problems it should be all hidden underneath a simple",
    "start": "3198880",
    "end": "3204640"
  },
  {
    "text": "basically distribution agnostic api if uh if we can um so first how does the data sets",
    "start": "3204640",
    "end": "3212160"
  },
  {
    "text": "solution to the large mo ingest problem address each of these issues the first one is we need to have",
    "start": "3212160",
    "end": "3218400"
  },
  {
    "text": "scalable io and this is what has uh we have super scalable parallel i",
    "start": "3218400",
    "end": "3224079"
  },
  {
    "text": "o um supporting all of your favorite storage backends and formats um if we don't support one that you really like",
    "start": "3224079",
    "end": "3230480"
  },
  {
    "text": "definitely let us know um and this is uh this is the api basically uh as you can see not much",
    "start": "3230480",
    "end": "3237440"
  },
  {
    "text": "complexity here you're just giving a storage url and then you're specifying some uh some read time parallelism",
    "start": "3237440",
    "end": "3245200"
  },
  {
    "text": "and this basically roughly translates to how many parallel read tasks you want to launch so for example when reading from",
    "start": "3245200",
    "end": "3252800"
  },
  {
    "text": "an s3 data set with like a parallelism equals three um this would",
    "start": "3252800",
    "end": "3259359"
  },
  {
    "text": "launch a read three read tasks and then quickly load the data into your trainers um so hooray",
    "start": "3259359",
    "end": "3266079"
  },
  {
    "text": "scalable io um and we actually do this by heavily leveraging arrows really",
    "start": "3266079",
    "end": "3271520"
  },
  {
    "text": "great single threaded i o um and then using ray to parallelize uh that",
    "start": "3271520",
    "end": "3277920"
  },
  {
    "text": "single-threaded i o functionality and that gives you high performance within each of these parallel reading tasks and",
    "start": "3277920",
    "end": "3284319"
  },
  {
    "text": "then raised distribution then results in really high performance scalable",
    "start": "3284319",
    "end": "3289520"
  },
  {
    "text": "distributed reads um the next uh bit of the dataset",
    "start": "3289520",
    "end": "3295280"
  },
  {
    "text": "solution that helps us solve one of those problems is pipelining uh the stages",
    "start": "3295280",
    "end": "3301200"
  },
  {
    "text": "in this uh ingest pipeline uh so uh alex mentioned this a little bit",
    "start": "3301200",
    "end": "3308160"
  },
  {
    "text": "before for this particular use case um we were wanting to pipeline uh pre-processing",
    "start": "3308160",
    "end": "3314480"
  },
  {
    "text": "and uh shuffling with model training so we can keep that gpu saturated if you",
    "start": "3314480",
    "end": "3319520"
  },
  {
    "text": "remember before this pesky gpu idleness costing us all this money uh super super annoying um",
    "start": "3319520",
    "end": "3326880"
  },
  {
    "text": "with pipelining by and by pipelining here where uh if you see the green there",
    "start": "3326880",
    "end": "3332559"
  },
  {
    "text": "that's your shuffle data loading and your purple's the training by doing the shuffle data loading um for the next",
    "start": "3332559",
    "end": "3339280"
  },
  {
    "text": "epoch while training on the current epoch you're able to fully saturate that gpu um and then also have some hot and",
    "start": "3339280",
    "end": "3347520"
  },
  {
    "text": "ready gpu batches for your next epoch when it becomes time to train uh for the next epoch um and",
    "start": "3347520",
    "end": "3354640"
  },
  {
    "text": "all that you really need to have here is you need to have that shuffle data loading throughput exceeds your uh your",
    "start": "3354640",
    "end": "3361920"
  },
  {
    "text": "like on gpu training throughput um uh as long as you have that uh after the",
    "start": "3361920",
    "end": "3368400"
  },
  {
    "text": "first epoch you will always see um like basically super hot uh gpu",
    "start": "3368400",
    "end": "3374240"
  },
  {
    "text": "batches that are just being uh essentially read as a memory reference like um in the most ideal case with",
    "start": "3374240",
    "end": "3380000"
  },
  {
    "text": "pre-fetching it should just be sitting there in the memory of the trainers uh ready to go when you want to start",
    "start": "3380000",
    "end": "3385839"
  },
  {
    "text": "training so this this ideally would eliminate the shuffle data loading bottleneck",
    "start": "3385839",
    "end": "3391599"
  },
  {
    "text": "when looking at your overall training throughput um so for that per epoch shuffling it",
    "start": "3391599",
    "end": "3397520"
  },
  {
    "text": "sure would be great if we could do a super efficient distributed shuffle on",
    "start": "3397520",
    "end": "3403440"
  },
  {
    "text": "ray using datasets well thankfully you can as alex mentioned before a good bit of",
    "start": "3403440",
    "end": "3410480"
  },
  {
    "text": "core of core ray's data plane in particular it's distributed in memory object store is very amenable to",
    "start": "3410480",
    "end": "3417920"
  },
  {
    "text": "efficient uh distributed shuffling um it's both a combination of uh zero copy",
    "start": "3417920",
    "end": "3423839"
  },
  {
    "text": "references um uh our zero uh zero copy deserialization um due to uh some wonderful properties",
    "start": "3423839",
    "end": "3431440"
  },
  {
    "text": "of pickle five buffers and then uh in addition to that you also get zero copy",
    "start": "3431440",
    "end": "3437040"
  },
  {
    "text": "shared memory reads if um if uh you have a chunk that's shared",
    "start": "3437040",
    "end": "3442720"
  },
  {
    "text": "by uh by multiple workers and then object transfer is also very efficient",
    "start": "3442720",
    "end": "3448480"
  },
  {
    "text": "with like some pretty smart back pressure while also providing a parallel transfer",
    "start": "3448480",
    "end": "3453920"
  },
  {
    "text": "by transferring over multiple threads so we've been working very hard on this",
    "start": "3453920",
    "end": "3459280"
  },
  {
    "text": "data plane on the data plane of raid we actually have also have a lot of work planned in q1",
    "start": "3459280",
    "end": "3464960"
  },
  {
    "text": "that's very exciting and so hopefully this will just continue to get better already it's pretty damn good",
    "start": "3464960",
    "end": "3471839"
  },
  {
    "text": "in addition to the efficient distributed memory shuffle uh we also have locality",
    "start": "3471839",
    "end": "3477200"
  },
  {
    "text": "replacement of these output shuffle shards under the trainers um so if you look down here",
    "start": "3477200",
    "end": "3483520"
  },
  {
    "text": "um at this code if you look at the split call the in for the locality hints art we're",
    "start": "3483520",
    "end": "3490000"
  },
  {
    "text": "passing in the model training actors so these are basically the actors here are like uh",
    "start": "3490000",
    "end": "3496559"
  },
  {
    "text": "the training workers um with that locality hint we do smart placement of",
    "start": "3496559",
    "end": "3502000"
  },
  {
    "text": "the data charts onto the the actors such that when the",
    "start": "3502000",
    "end": "3507200"
  },
  {
    "text": "training actors try and fetch the data the data should be already sitting there in the object store and then it's a",
    "start": "3507200",
    "end": "3513280"
  },
  {
    "text": "shared memory read which should be super fast um so this is kind of showing that uh uh",
    "start": "3513280",
    "end": "3519440"
  },
  {
    "text": "here where we're doing like um on each epoch we're doing a random shuffle and then we are uh pushing that",
    "start": "3519440",
    "end": "3527119"
  },
  {
    "text": "output to each of the trainers pushing the corresponding shard",
    "start": "3527119",
    "end": "3532720"
  },
  {
    "text": "um so uh we had that pesky pesky issue so many pesky issues at scale but we had",
    "start": "3532799",
    "end": "3538559"
  },
  {
    "text": "that pesky issue of uh how exactly are we going to deal with our uh",
    "start": "3538559",
    "end": "3544400"
  },
  {
    "text": "our data loading pipeline not totally fitting into the cluster's uh total memory um thankfully we have the",
    "start": "3544400",
    "end": "3551280"
  },
  {
    "text": "solution that we're calling windowing this is where you're able to limit the size of the working set",
    "start": "3551280",
    "end": "3559200"
  },
  {
    "text": "when doing the shuffle data loading and this will limit the amount of data loading tasks",
    "start": "3559200",
    "end": "3565520"
  },
  {
    "text": "pre-processing tasks and shuffling that's done at a time to just a small window of the data set of the full data",
    "start": "3565520",
    "end": "3572400"
  },
  {
    "text": "set um so you can kind of imagine it a little bit like this for the first window it's this little",
    "start": "3572400",
    "end": "3579200"
  },
  {
    "text": "little red rectangle all that we're doing is we are loading shuffling and feeding that to",
    "start": "3579200",
    "end": "3586160"
  },
  {
    "text": "the trainers uh just that uh just that little uh partition of the input data um and then",
    "start": "3586160",
    "end": "3593760"
  },
  {
    "text": "next the second window we fetch the red sorry the orange one and",
    "start": "3593760",
    "end": "3599200"
  },
  {
    "text": "then for the third window uh we fetch the yellow partition and this way",
    "start": "3599200",
    "end": "3604799"
  },
  {
    "text": "instead of the uh the total working set size being a factor of the red plus",
    "start": "3604799",
    "end": "3611119"
  },
  {
    "text": "orange plus yellow which if we have some like uh cases of like read amplif uh read amplification",
    "start": "3611119",
    "end": "3618319"
  },
  {
    "text": "within re um or any other like little intermediate copies hanging out um it can be quite large it could be like 4x",
    "start": "3618319",
    "end": "3625040"
  },
  {
    "text": "5x of the total data set size instead that that multiplier of the working set size",
    "start": "3625040",
    "end": "3632160"
  },
  {
    "text": "is only going to be for this uh you know red partition um so that keeps your",
    "start": "3632160",
    "end": "3637280"
  },
  {
    "text": "total working set size down and this is by the way going to still constitute a single epoch like we're",
    "start": "3637280",
    "end": "3643839"
  },
  {
    "text": "still doing a full pass over the entire data set um and uh uh but instead we're just doing it",
    "start": "3643839",
    "end": "3650720"
  },
  {
    "text": "within windows and you may be thinking oh won't this degrade the shuffle a little bit um that's true it's it's not",
    "start": "3650720",
    "end": "3658400"
  },
  {
    "text": "uh it's not degrading it to the point of like a local shuffle buffer on a trainer like you would still be able to",
    "start": "3658400",
    "end": "3665040"
  },
  {
    "text": "uh your working set only has to fit into the cluster's total memory it doesn't have to fit into like you know your",
    "start": "3665040",
    "end": "3671359"
  },
  {
    "text": "trainer's leftover ram uh so you're still getting better than like a local shuffle buffer but this does degrade the",
    "start": "3671359",
    "end": "3677760"
  },
  {
    "text": "shuffle a little bit right now this is uh this is a trade-off um between like",
    "start": "3677760",
    "end": "3683440"
  },
  {
    "text": "uh how large you want your cluster to be and then the quality of the shuffle in the future there's actually no reason",
    "start": "3683440",
    "end": "3688559"
  },
  {
    "text": "that we couldn't implement this windowing while still doing a completely random sample um it would",
    "start": "3688559",
    "end": "3695119"
  },
  {
    "text": "just be a little bit more of a complex shuffling implementation maybe a little bit more constrained in its use uh so if",
    "start": "3695119",
    "end": "3701200"
  },
  {
    "text": "that feature it seems to be table stakes for you definitely let us know um because we can uh we can tackle that",
    "start": "3701200",
    "end": "3708160"
  },
  {
    "text": "yep uh trading off shuffle quality with cluster size and then finally we wanted",
    "start": "3708160",
    "end": "3713520"
  },
  {
    "text": "to address all of this with a simple api um thankfully",
    "start": "3713520",
    "end": "3718640"
  },
  {
    "text": "i think we were able to hit that target here is just a little example of like a",
    "start": "3718640",
    "end": "3724000"
  },
  {
    "text": "trainer task and this is just going to consume the shard of the data set pipeline",
    "start": "3724000",
    "end": "3731680"
  },
  {
    "text": "and here you can kind of see the usage of that trainer plus data sets for data loading",
    "start": "3731680",
    "end": "3739039"
  },
  {
    "text": "so that trainer again is the consumer uh is the consumer of the data uh and here",
    "start": "3739039",
    "end": "3744319"
  },
  {
    "text": "we show reading from uh from some external storage reading parquet files",
    "start": "3744319",
    "end": "3750240"
  },
  {
    "text": "uh we repeat this uh read operation for the number of epochs that we want to",
    "start": "3750240",
    "end": "3755599"
  },
  {
    "text": "train for and then we shuffle each window um and then we feed the data set",
    "start": "3755599",
    "end": "3760720"
  },
  {
    "text": "uh to the trainer so this is the small date on a single node case like there's a single trainer here we're not doing",
    "start": "3760720",
    "end": "3766640"
  },
  {
    "text": "any windowing um you know this is a this is the simpler case to go to the more complex case of distributed trainers a",
    "start": "3766640",
    "end": "3773599"
  },
  {
    "text": "multi-node cluster uh where we want to limit the working set size all that we have to do is add this windowing",
    "start": "3773599",
    "end": "3780079"
  },
  {
    "text": "directive um saying that we want no more than some number of blocks per window",
    "start": "3780079",
    "end": "3786559"
  },
  {
    "text": "right now this is expressed kind of with like a little bit of our internal representation where each partition",
    "start": "3786559",
    "end": "3792640"
  },
  {
    "text": "of the data set we call a block um and this is saying uh no more",
    "start": "3792640",
    "end": "3798960"
  },
  {
    "text": "you know exactly 20 blocks per window but we could actually eventually expose an api of like uh actual like bytes um",
    "start": "3798960",
    "end": "3806640"
  },
  {
    "text": "saying like you know no more than this many bytes in a single window and then eventually hopefully be able to",
    "start": "3806640",
    "end": "3813359"
  },
  {
    "text": "optimize this away where it doesn't even have to be specified where you could just call dot window and then we would",
    "start": "3813359",
    "end": "3818799"
  },
  {
    "text": "hopefully calculate the window size that can fit in your cluster for you so you wouldn't even have to specify",
    "start": "3818799",
    "end": "3825920"
  },
  {
    "text": "how exactly you want a window and then the split there",
    "start": "3825920",
    "end": "3831520"
  },
  {
    "text": "splits this data set pipeline into a shard per trainer and then we feed those shards into the trainers",
    "start": "3831520",
    "end": "3838559"
  },
  {
    "text": "and that equal equal that uh equal argument that equal equals true that's",
    "start": "3838559",
    "end": "3844319"
  },
  {
    "text": "just telling the data set splitter please give me uh equalized shards so each shard will",
    "start": "3844319",
    "end": "3851599"
  },
  {
    "text": "have an equal number of samples um yeah so some case studies for this",
    "start": "3851599",
    "end": "3857839"
  },
  {
    "text": "use case um first a little bit of background on a couple of these case studies these are",
    "start": "3857839",
    "end": "3863039"
  },
  {
    "text": "going to be some users that have had some success with using data sets for this use case one common problem is the existing",
    "start": "3863039",
    "end": "3869680"
  },
  {
    "text": "solution that they have for shuffled data loading is actually the primary bottleneck in their training pipeline",
    "start": "3869680",
    "end": "3875599"
  },
  {
    "text": "we actually encountered this more than we had expected we a lot of users that we had talked to",
    "start": "3875599",
    "end": "3882160"
  },
  {
    "text": "their um their their actual the actual training of their model was was going perfectly fine in their",
    "start": "3882160",
    "end": "3888640"
  },
  {
    "text": "their data loading uh solution either due to pauses in their existing data loading solution where suddenly you just",
    "start": "3888640",
    "end": "3895039"
  },
  {
    "text": "hang for like tens of seconds um or uh or even just like it was consistently",
    "start": "3895039",
    "end": "3902160"
  },
  {
    "text": "uh like not good enough throughput in order to keep the gpu saturated um we saw",
    "start": "3902160",
    "end": "3908480"
  },
  {
    "text": "both of those happen in the wild the other common problem is that their",
    "start": "3908480",
    "end": "3914480"
  },
  {
    "text": "models slash data sets are shuffle sensitive and this is where doing that local",
    "start": "3914480",
    "end": "3920880"
  },
  {
    "text": "shuffle where each trainer has a shuffle buffer um where that actually that that",
    "start": "3920880",
    "end": "3926000"
  },
  {
    "text": "degradation in like the uh fully global random shuffle quality to this local shuffle actually affected their model",
    "start": "3926000",
    "end": "3932640"
  },
  {
    "text": "accuracy um such that for like a fixed training window um for like a fixed",
    "start": "3932640",
    "end": "3938000"
  },
  {
    "text": "number of uh epochs they saw comparing uh the local shuffle to the global",
    "start": "3938000",
    "end": "3943760"
  },
  {
    "text": "shuffle they saw worst model actors they saw worse model accuracy at the end of those epochs",
    "start": "3943760",
    "end": "3949599"
  },
  {
    "text": "um so the first case study here it's a high-tech ml platform startup uh this is",
    "start": "3949599",
    "end": "3954960"
  },
  {
    "text": "anonymized because uh it hasn't quite been announced publicly yet their existing solution was pandas to s3",
    "start": "3954960",
    "end": "3962000"
  },
  {
    "text": "to petastorm so this is panda's pre-processing here persisted to s3 um then loaded with",
    "start": "3962000",
    "end": "3969599"
  },
  {
    "text": "petastorm and then fed into a distributed set of horovod trainers um peta storm by the way if you're not",
    "start": "3969599",
    "end": "3976400"
  },
  {
    "text": "familiar it's an ml ingest library from uber it's open source if you want to go check it out so ray's solution was to obviate the",
    "start": "3976400",
    "end": "3983039"
  },
  {
    "text": "need for that uh intermediate persistence to s3 and instead move that pre-processing to",
    "start": "3983039",
    "end": "3988160"
  },
  {
    "text": "desk on ray and then have a very efficient exchange of that tabular data to data sets all",
    "start": "3988160",
    "end": "3995839"
  },
  {
    "text": "kept in memory and then to use data sets to feed the distributed trainers",
    "start": "3995839",
    "end": "4002160"
  },
  {
    "text": "the distributed horrible trainers the second case study it's a large tech company in transport space you can kind",
    "start": "4002160",
    "end": "4008960"
  },
  {
    "text": "of let people guess about that uh who that might be um and their existing solution was s3 uh",
    "start": "4008960",
    "end": "4016720"
  },
  {
    "text": "their s3 data set was loaded with petastorm into corvod trainers and ray's solution um wasn't to",
    "start": "4016720",
    "end": "4023920"
  },
  {
    "text": "eliminate s3 it was just to use data sets uh to load the data into horobot instead of pedestal",
    "start": "4023920",
    "end": "4030720"
  },
  {
    "text": "and uh both of these case studies suffered from both of those common problems above both the existing",
    "start": "4030720",
    "end": "4036720"
  },
  {
    "text": "solution is their chief bottleneck and their models are shuffle sensitive",
    "start": "4036720",
    "end": "4042319"
  },
  {
    "text": "so benchmark results i'll go a little bit quicker because i feel like i'm a little bit running short on time um desk",
    "start": "4042319",
    "end": "4048400"
  },
  {
    "text": "unrained data sets uh for the high tech mo platform startup this is where we updated the need for s3 um",
    "start": "4048400",
    "end": "4054880"
  },
  {
    "text": "the the desk and rain dataset solution was eight times faster than their old solution even on small data and cluster",
    "start": "4054880",
    "end": "4061440"
  },
  {
    "text": "scales which was actually somewhat surprising so their benchmark which was using the new york city taxi data set um",
    "start": "4061440",
    "end": "4067920"
  },
  {
    "text": "and then a single large uh gpu instance they saw that ray by the way here a lower um",
    "start": "4067920",
    "end": "4076000"
  },
  {
    "text": "because this is runtime they saw huge improvements using ray compared to peta storm",
    "start": "4076000",
    "end": "4081440"
  },
  {
    "text": "compared to just all in memory pandas and even even when adding custom optimizations to petastorm um to do some",
    "start": "4081440",
    "end": "4088799"
  },
  {
    "text": "like async pre-fetching uh ray was still doing far better and for that large transport tech",
    "start": "4088799",
    "end": "4095039"
  },
  {
    "text": "company where we were only replacing um pettistorm as the data loader still loading from s3 uh datasets was four",
    "start": "4095039",
    "end": "4101838"
  },
  {
    "text": "times faster than petastorm when loading from s3 and this benchmark was on a pretty large data set it was a 1.5",
    "start": "4101839",
    "end": "4108640"
  },
  {
    "text": "terabytes of synthetic data all tabular data and then they were using 16 nodes two shuffle",
    "start": "4108640",
    "end": "4115679"
  },
  {
    "text": "windows and here showing like the difference in uh aggregate throughput so this is uh the throughput of all",
    "start": "4115679",
    "end": "4121920"
  },
  {
    "text": "combined 16 nodes um so as you can see we got like around you know 4x uh higher",
    "start": "4121920",
    "end": "4128238"
  },
  {
    "text": "throughput so radius ray data datasets is giving both higher quality shuffle and better",
    "start": "4128239",
    "end": "4134000"
  },
  {
    "text": "performance even at small data scales at uh small data and cluster scales",
    "start": "4134000",
    "end": "4139199"
  },
  {
    "text": "um so the that last little qualifier is actually surprising at larger scales",
    "start": "4139199",
    "end": "4145199"
  },
  {
    "text": "data sets really shines we're also actively working on some comprehensive open benchmarking um so",
    "start": "4145199",
    "end": "4152080"
  },
  {
    "text": "stay tuned for that um yeah i'm wondering hey hey jules do you think i got time to",
    "start": "4152080",
    "end": "4159120"
  },
  {
    "text": "quickly go through the batch inference use case i'm not three minutes two minutes all right lightning round",
    "start": "4159120",
    "end": "4164560"
  },
  {
    "text": "okay uh uh what exactly is batch inference uh this is where you want to run model inference over a large number",
    "start": "4164560",
    "end": "4170798"
  },
  {
    "text": "of images uh so obviously you batch um the functions of this use case is you load data from storage uh you do some",
    "start": "4170799",
    "end": "4177520"
  },
  {
    "text": "minor preprocessing before the inference and then you perform model inference on the batches of data possibly on the gpu",
    "start": "4177520",
    "end": "4184318"
  },
  {
    "text": "often on the gpu and then you save the result back to storage and we want to do it all efficiently so what are the big",
    "start": "4184319",
    "end": "4190159"
  },
  {
    "text": "challenges with distributed batch inference scheduling number one you don't want to have to transfer data around the cluster",
    "start": "4190159",
    "end": "4196080"
  },
  {
    "text": "as you're going from pre-processing to doing the batch inference on the gpu",
    "start": "4196080",
    "end": "4201520"
  },
  {
    "text": "you only want to reserve gpus for a fraction of the time you want to be able to use gpus as a fractional resource um",
    "start": "4201520",
    "end": "4208000"
  },
  {
    "text": "and you need to keep the gpu saturated to keep costs down like again pesky gpu idleness look at look at all of that",
    "start": "4208000",
    "end": "4214800"
  },
  {
    "text": "time the gpu is staying idle while reloading and pre-processing um so the data set solution solves this with",
    "start": "4214800",
    "end": "4220800"
  },
  {
    "text": "automatic data locality number one less object transfer when going between pre-processing and inference",
    "start": "4220800",
    "end": "4227600"
  },
  {
    "text": "we utilize ray's resource scheduling so you look at how simple that api is we're using the map batches which maps in an",
    "start": "4227600",
    "end": "4235120"
  },
  {
    "text": "arbitrary udf across batches of the data set and the num gpus equals 0.25 there",
    "start": "4235120",
    "end": "4241280"
  },
  {
    "text": "you go you got your fractional gpu and that's the really nice bits about uh ray's resource model it's uh it's that",
    "start": "4241280",
    "end": "4247920"
  },
  {
    "text": "simple you know to request a resource um so first of all the data set solution",
    "start": "4247920",
    "end": "4254800"
  },
  {
    "text": "how do we get a really good cheap utilization that's by doing the pipelining that which",
    "start": "4254800",
    "end": "4260560"
  },
  {
    "text": "uh alex mentioned before of the data loading pre-processing and inference stages and look at that the gpu idleness",
    "start": "4260560",
    "end": "4267199"
  },
  {
    "text": "shrunk all the way down with this wonderful pipelining um so this is just by overlapping data loading",
    "start": "4267199",
    "end": "4273120"
  },
  {
    "text": "pre-processing and inference um and you're still able to get pretty good parallelism uh it's basically just a",
    "start": "4273120",
    "end": "4278800"
  },
  {
    "text": "trade-off with uh you know latency for the final stage and parallelism",
    "start": "4278800",
    "end": "4284400"
  },
  {
    "text": "basically and again very simple api wonderful um so quick case study uh we have a",
    "start": "4284400",
    "end": "4290960"
  },
  {
    "text": "startup that's processing aerial imagery and they're looking for a scalable and resource efficient batch inference wonderful and then the same high-tech ml",
    "start": "4290960",
    "end": "4298480"
  },
  {
    "text": "platform startup uh their existing pandas uh torch solution was not scalable made very inefficient use of",
    "start": "4298480",
    "end": "4304880"
  },
  {
    "text": "resources a lot of idle gpus hanging around and so this integration was a desk on ray uh to read data sets to",
    "start": "4304880",
    "end": "4311199"
  },
  {
    "text": "torch uh pipeline um benchmark results uh desk on ray plus uh data sets plus",
    "start": "4311199",
    "end": "4318719"
  },
  {
    "text": "storage was five times faster than pandas and torch again even at small scales which we were thrilled about um",
    "start": "4318719",
    "end": "4324719"
  },
  {
    "text": "new york taxi data set once again a single large gpu instance and here we're",
    "start": "4324719",
    "end": "4330320"
  },
  {
    "text": "seeing higher is better because we're looking at throughput um comparing desk unrained data sets and pandas and as you",
    "start": "4330320",
    "end": "4337280"
  },
  {
    "text": "can see for these two different throughput on the left runtime on the",
    "start": "4337280",
    "end": "4343440"
  },
  {
    "text": "right uh datasets was doing super well for um the larger size pandas couldn't",
    "start": "4343440",
    "end": "4348880"
  },
  {
    "text": "even complete that's why there's uh like the like pandas i believe the pandas workload crashed and that's why it's no",
    "start": "4348880",
    "end": "4354960"
  },
  {
    "text": "longer uh that's why it's not there for the right data points the data points to the right larger data sizes so again",
    "start": "4354960",
    "end": "4361440"
  },
  {
    "text": "data sets provides better resource efficiency and better performance even at small scales so finally a summary there's lots of",
    "start": "4361440",
    "end": "4368320"
  },
  {
    "text": "room for improvement in the status quo of ml pipelines",
    "start": "4368320",
    "end": "4373600"
  },
  {
    "text": "we want to reduce costs and performance overheads we want to support ml operations like shuffling and scale and",
    "start": "4373600",
    "end": "4378800"
  },
  {
    "text": "we still want ease of use we want the apis to be simple array data sets hits these marks wonderfully i think uh with",
    "start": "4378800",
    "end": "4385840"
  },
  {
    "text": "efficient data movement between steps in a pipeline using like locality aware scheduling and locality replacement of",
    "start": "4385840",
    "end": "4390960"
  },
  {
    "text": "data onto trainers hyperscalable implementations of common ml operations",
    "start": "4390960",
    "end": "4396320"
  },
  {
    "text": "we've got a simple expression of these complex ml pipelines it was just basically five to ten lines of code for",
    "start": "4396320",
    "end": "4401679"
  },
  {
    "text": "these two different use cases which could normally be hundreds of lines of code and then for ml ingest you get much",
    "start": "4401679",
    "end": "4407920"
  },
  {
    "text": "better shuffled data and better performance in the status quo it's not even a trade-off um you know",
    "start": "4407920",
    "end": "4413840"
  },
  {
    "text": "you get uh best of both worlds and then finally for batch imprints better efficiency better resource",
    "start": "4413840",
    "end": "4419040"
  },
  {
    "text": "efficiency and performance in the status quo all right thank you here are some resources",
    "start": "4419040",
    "end": "4425440"
  },
  {
    "text": "uh three minutes over oh well without much time for q a well thank you thank you very much alex",
    "start": "4425440",
    "end": "4432960"
  },
  {
    "text": "and clark for this brilliant in-depth technical discussions about resets all its efficiency all it can actually do",
    "start": "4432960",
    "end": "4439920"
  },
  {
    "text": "for you we do encourage you to try it and give us a particular feedback i think we have time for maybe two",
    "start": "4439920",
    "end": "4445360"
  },
  {
    "text": "questions at most and i think these answers is a question we can actually post it on a separate document but",
    "start": "4445360",
    "end": "4451520"
  },
  {
    "text": "here's a question for you alex or or clark uh when would you when would ray data sets be appropriate in contrast to",
    "start": "4451520",
    "end": "4458239"
  },
  {
    "text": "modern um i think clark do you want to take that because you were about to type that in sure yeah oh you saw me",
    "start": "4458239",
    "end": "4464960"
  },
  {
    "text": "yes yeah um yeah uh it's we're primarily considering it appropriate for uh for",
    "start": "4464960",
    "end": "4470000"
  },
  {
    "text": "simple data processing um basically things that you can express with like a map",
    "start": "4470000",
    "end": "4475520"
  },
  {
    "text": "or a batch map or a filter uh so very very simple um in terms of like the use",
    "start": "4475520",
    "end": "4480719"
  },
  {
    "text": "case we're we're really focusing on pre-processing for training and",
    "start": "4480719",
    "end": "4485920"
  },
  {
    "text": "pre-processing for batch inference um so this is kind of like the last mile stuff",
    "start": "4485920",
    "end": "4490960"
  },
  {
    "text": "um stuff that doesn't require a huge distributed join or a very complex like data frame up uh",
    "start": "4490960",
    "end": "4497280"
  },
  {
    "text": "munching and operation this would be for like some very basic last mile stuff um",
    "start": "4497280",
    "end": "4502320"
  },
  {
    "text": "and we're going to have some better support for common pre-processing operations like uh you know like",
    "start": "4502320",
    "end": "4508000"
  },
  {
    "text": "standard scaling um one hot encoding we're looking at adding some nice",
    "start": "4508000",
    "end": "4513679"
  },
  {
    "text": "helpers for those to make it very simple um and um i think yeah go ahead",
    "start": "4513679",
    "end": "4520400"
  },
  {
    "text": "but with map and filter you can do most things you can do a lot of things although we're missing really is reduce and then",
    "start": "4520400",
    "end": "4526560"
  },
  {
    "text": "you can do pretty much everything but then it'll be a question of ux i think one thing both of you might have",
    "start": "4526560",
    "end": "4533120"
  },
  {
    "text": "touched on on the per epoch shuffle but i think there's a related question to that how does ray dataset",
    "start": "4533120",
    "end": "4540080"
  },
  {
    "text": "support uh the shuffle operation do we actually have a dedicated shuffle service or is it something that's actually done",
    "start": "4540080",
    "end": "4546480"
  },
  {
    "text": "um by the actor or how do we actually have a notion of shuffle service like spark has a notion of",
    "start": "4546480",
    "end": "4553280"
  },
  {
    "text": "shuffle service this is currently right now it's uh it's hard it's uh like a hard-coded implementation um by us um so",
    "start": "4553280",
    "end": "4561360"
  },
  {
    "text": "this is just basically doing like a map reduce shuffle so using map tasks to uh chunk out the",
    "start": "4561360",
    "end": "4568640"
  },
  {
    "text": "data uh to chunk out the existing data set and then like each reduced task then gets a",
    "start": "4568640",
    "end": "4576159"
  },
  {
    "text": "mapper chunk from each of the mappers and then the reducer then shuffles all of those mapper tasks and outputs uh um",
    "start": "4576159",
    "end": "4583440"
  },
  {
    "text": "some shuffle data and then that data at the end is essentially concatenated so it's a it's a data sets native shuffle",
    "start": "4583440",
    "end": "4589920"
  },
  {
    "text": "it's a ray nato shuffle but we could certainly look at instead like making that more plugable like maybe it is like",
    "start": "4589920",
    "end": "4595760"
  },
  {
    "text": "an external shuffle service um but we would like to do it i think in-house efficiently if we can",
    "start": "4595760",
    "end": "4602640"
  },
  {
    "text": "um just to add to that um i think uh maybe when you're thinking of a shuffle service in spark or something you're",
    "start": "4602640",
    "end": "4608080"
  },
  {
    "text": "thinking of like uh some central coordinator or um like scheduler that's responsible for scheduling where these",
    "start": "4608080",
    "end": "4614640"
  },
  {
    "text": "like shuffle tasks are going to occur and scheduling the you know like network requests across the network um",
    "start": "4614640",
    "end": "4621040"
  },
  {
    "text": "whereas in rey uh we rely heavily on the object store for this and so um you know we could go on a",
    "start": "4621040",
    "end": "4626960"
  },
  {
    "text": "whole another hour-long talk about how the radio object store works um but the short answer here is that we allow the object store to handle the shuffle for",
    "start": "4626960",
    "end": "4633199"
  },
  {
    "text": "us um and the object store handles this in a more of a peer-to-peer fashion um so if you take a look at some of the um",
    "start": "4633199",
    "end": "4640080"
  },
  {
    "text": "you know talks and papers published on how um ray's ownership model works um",
    "start": "4640080",
    "end": "4645360"
  },
  {
    "text": "you'll see a lot of um there's a lot of details there on exactly how worker",
    "start": "4645360",
    "end": "4650719"
  },
  {
    "text": "nodes communicate with each other um in order to like do a stable shuffle yeah there's a great blog post by",
    "start": "4650719",
    "end": "4656800"
  },
  {
    "text": "stephanie wang who's an engineer at uh at any scale on how ray does an",
    "start": "4656800",
    "end": "4663120"
  },
  {
    "text": "efficient distributed shuffle um i'll i'll i'll go ahead and post those",
    "start": "4663120",
    "end": "4668159"
  },
  {
    "text": "links both the ownership model as well as as well as uh the blog post you're talking about yeah i think we're out of",
    "start": "4668159",
    "end": "4673760"
  },
  {
    "text": "time uh i want to give i'm going to give enough time to patrick um we're gonna shift a little bit now here from the",
    "start": "4673760",
    "end": "4680080"
  },
  {
    "text": "community how the the ray data sets is actually being used at a massive scale to build a data",
    "start": "4680080",
    "end": "4686159"
  },
  {
    "text": "catalog uh amazon and when you think about data you think about about about scale at amazon so joining us is uh",
    "start": "4686159",
    "end": "4692960"
  },
  {
    "text": "patrick ms he's the senior software engineer in the data big data group and",
    "start": "4692960",
    "end": "4698400"
  },
  {
    "text": "he's going to talk about how they actually use rain rate as i said to build the delta catalog yeah",
    "start": "4698400",
    "end": "4706280"
  },
  {
    "text": "all right appreciate it so first things first can everybody see my screen going to enlarge the slides here if you",
    "start": "4708480",
    "end": "4715280"
  },
  {
    "text": "can all see it yes we can see the beautiful cat okay perfect",
    "start": "4715280",
    "end": "4720400"
  },
  {
    "text": "uh yeah thanks for the sound effect there matches the intro slide here perfectly so um yeah we're going to be",
    "start": "4720400",
    "end": "4727679"
  },
  {
    "text": "talking here today about the delta cap project so a little bit of background",
    "start": "4727679",
    "end": "4733040"
  },
  {
    "text": "before we get into it so i'm patrick i'm a senior software engineer at amazon and",
    "start": "4733040",
    "end": "4738640"
  },
  {
    "text": "i've been spending about the last six years of my life primarily working on business intelligence problems at amazon",
    "start": "4738640",
    "end": "4745120"
  },
  {
    "text": "um especially data management and optimization problems for our data catalog",
    "start": "4745120",
    "end": "4751360"
  },
  {
    "text": "at amazon and so one of these problems that actually led to this project",
    "start": "4751360",
    "end": "4756560"
  },
  {
    "text": "is uh trying to make our data catalog more usable for amazon's data scientists",
    "start": "4756560",
    "end": "4762480"
  },
  {
    "text": "and machine learning engineers who prefer to interact with the catalog in python but also don't really want to be",
    "start": "4762480",
    "end": "4769679"
  },
  {
    "text": "constrained by the single process constraints of historic python so that kind of led us to",
    "start": "4769679",
    "end": "4775679"
  },
  {
    "text": "and we spent about two years actually leading up to the contribution of this",
    "start": "4775679",
    "end": "4780719"
  },
  {
    "text": "project in trying to integrate our data catalog with ray and create more",
    "start": "4780719",
    "end": "4785840"
  },
  {
    "text": "pythonic apis for data scientists and machine learning engineers to interact with data catalogs and we found a lot of",
    "start": "4785840",
    "end": "4792159"
  },
  {
    "text": "these things we did along the way are generalizable to a lot of uh data catalogs that exist in open source today",
    "start": "4792159",
    "end": "4799440"
  },
  {
    "text": "and so thus the delta cap project was born and we contributed to open source as part of the ray project um it's still",
    "start": "4799440",
    "end": "4806400"
  },
  {
    "text": "in a pretty early phase of development we'll go through what we do with it today at amazon and what we're going to",
    "start": "4806400",
    "end": "4811440"
  },
  {
    "text": "do with it in open source in the future to make it more generally useful for all of you um it's a quick intro here so what does",
    "start": "4811440",
    "end": "4818719"
  },
  {
    "text": "delta cap mean uh delta cat there stands for delta catalog of acid transactions",
    "start": "4818719",
    "end": "4824400"
  },
  {
    "text": "so sorry it has an embedded acronym acid being atomic consistent isolated and",
    "start": "4824400",
    "end": "4830400"
  },
  {
    "text": "durable you see that terminology a lot in the database world in particular and uh today we're going to be looking",
    "start": "4830400",
    "end": "4836080"
  },
  {
    "text": "at it especially from the perspective of how it kind of extends ray data sets and enhances the ray data set ecosystem and",
    "start": "4836080",
    "end": "4842800"
  },
  {
    "text": "uses ray data sets to bring you a better experience with your data catalogs so",
    "start": "4842800",
    "end": "4848400"
  },
  {
    "text": "before we get too deep into technical details let's start out with an introduction to what data catalogs and",
    "start": "4848400",
    "end": "4854320"
  },
  {
    "text": "data lakes are so this is sometimes a hotly debated topic the exact definition of a data",
    "start": "4854320",
    "end": "4860400"
  },
  {
    "text": "lake or a data catalog but for the purposes of this presentation we're going to say data lake is effectively a",
    "start": "4860400",
    "end": "4866400"
  },
  {
    "text": "centralized repository for structured and unstructured data and importantly it allows you to durably store and retrieve",
    "start": "4866400",
    "end": "4872400"
  },
  {
    "text": "raw data so it's basically plain old bites in plain old bites out examples of this are hdfs s3 azure data",
    "start": "4872400",
    "end": "4880960"
  },
  {
    "text": "lake storage uh google cloud storage you'll often use these as a data lake just to put your stuff there durably",
    "start": "4880960",
    "end": "4886719"
  },
  {
    "text": "store it and then retrieve it and trust that it didn't munch any bytes or do any post processing on your data",
    "start": "4886719",
    "end": "4893280"
  },
  {
    "text": "and then uh getting into data catalogs data catalogs uh for the purposes of our presentation and",
    "start": "4893280",
    "end": "4899920"
  },
  {
    "text": "for how deltacat thinks about them is something that enriches a data lake with",
    "start": "4899920",
    "end": "4905280"
  },
  {
    "text": "additional metadata and so often that additional metadata will include things like discovery mechanisms",
    "start": "4905280",
    "end": "4912480"
  },
  {
    "text": "so you'll introduce namespaces that tables exist within tables will be divided into partitions maybe you'll",
    "start": "4912480",
    "end": "4918159"
  },
  {
    "text": "have revisions of a table things like that interpretation instructions schemas are introduced constraints are",
    "start": "4918159",
    "end": "4924719"
  },
  {
    "text": "introduced um content types and encodings are stored and you'll get key insights maybe you'll",
    "start": "4924719",
    "end": "4931199"
  },
  {
    "text": "just have human readable descriptions of your table audit logs about what people did pre-computed aggregates",
    "start": "4931199",
    "end": "4936719"
  },
  {
    "text": "and i've listed a few things that include data catalogs as part of their open source project like hive and aws",
    "start": "4936719",
    "end": "4943040"
  },
  {
    "text": "glue apache iceberg nessie apache hoodie and uh databricks delta leg now these",
    "start": "4943040",
    "end": "4948960"
  },
  {
    "text": "are not just data catalogs they are all kind of ecosystems unto themselves but i",
    "start": "4948960",
    "end": "4954560"
  },
  {
    "text": "would argue that all of them include a data catalog at some level of their infrastructure",
    "start": "4954560",
    "end": "4960159"
  },
  {
    "text": "and the current state of these data catalogs and python integration",
    "start": "4960159",
    "end": "4966800"
  },
  {
    "text": "is something that we were having trouble with at amazon so usually when you're dealing with data",
    "start": "4966800",
    "end": "4973199"
  },
  {
    "text": "catalog data you want to read data from a data catalog you want to write data back to a data catalog uh you'll use an integrated compute",
    "start": "4973199",
    "end": "4980480"
  },
  {
    "text": "engine with that data catalog three of the most popular ones might be hive which will provide you pi hive and hive",
    "start": "4980480",
    "end": "4987280"
  },
  {
    "text": "ql and pi spark in the python world which is a little better gives you spark",
    "start": "4987280",
    "end": "4993120"
  },
  {
    "text": "sql data frame streaming and a little bit more pythonic offering of pandas on",
    "start": "4993120",
    "end": "4998159"
  },
  {
    "text": "spark there and then pyflink which gives you pythonic versions of data streams and tables",
    "start": "4998159",
    "end": "5004560"
  },
  {
    "text": "however our data scientists and machine learning engineers were entirely happy with the",
    "start": "5004560",
    "end": "5010320"
  },
  {
    "text": "experience of using these things notably because they were based on the",
    "start": "5010320",
    "end": "5016400"
  },
  {
    "text": "preceding java and sql apis and architectures so they weren't really made for a python native experience they",
    "start": "5016400",
    "end": "5022159"
  },
  {
    "text": "weren't really made with delivering pythonic apis first and foremost and thus they tended to have uh limited",
    "start": "5022159",
    "end": "5028560"
  },
  {
    "text": "feature support versus their java counterparts and their sql counterparts",
    "start": "5028560",
    "end": "5033679"
  },
  {
    "text": "the apis weren't always terribly pythonic and this would sometimes make things",
    "start": "5033679",
    "end": "5040400"
  },
  {
    "text": "inefficient the python world would have to maybe call into the java world and do cross-language",
    "start": "5040400",
    "end": "5047360"
  },
  {
    "text": "integration overhead there for like sur day work um it's not always a pretty picture for",
    "start": "5047360",
    "end": "5052480"
  },
  {
    "text": "those of you that have tried to integrate python applications with java backends and stuff like that it's complex you have efficiency problems and",
    "start": "5052480",
    "end": "5061120"
  },
  {
    "text": "sometimes you have to create a new python native layer to resolve those efficiency problems",
    "start": "5061120",
    "end": "5067760"
  },
  {
    "text": "so kind of being a little unhappy with the state of data catalogs and their integration with python",
    "start": "5067760",
    "end": "5075120"
  },
  {
    "text": "we decided that we would start looking into the demand for a more pythonic data",
    "start": "5075120",
    "end": "5082000"
  },
  {
    "text": "catalog and so uh here's a quick diagram from data here from a survey that they ran in",
    "start": "5082000",
    "end": "5089920"
  },
  {
    "text": "q3 of 2021 the relative size of python communities and you can see they",
    "start": "5089920",
    "end": "5096000"
  },
  {
    "text": "categorize python as the second largest uh programming language community there",
    "start": "5096000",
    "end": "5101199"
  },
  {
    "text": "and it's interesting to note that they noted it's most popular in data science and machine learning the actual report",
    "start": "5101199",
    "end": "5106960"
  },
  {
    "text": "noted further that nearly 70 percent of ml and data scientists are using python",
    "start": "5106960",
    "end": "5112480"
  },
  {
    "text": "uh and the runner-up is r with 17 so they're far and away the leader there and interestingly least popular in data",
    "start": "5112480",
    "end": "5118880"
  },
  {
    "text": "science and ml is java the thing that's the chief supporter of your data catalog integrations in open source right now so",
    "start": "5118880",
    "end": "5127040"
  },
  {
    "text": "we kind of saw this as good motivation for pursuing this project not just for",
    "start": "5127040",
    "end": "5132639"
  },
  {
    "text": "ourselves but for the benefit of the general community of data scientists and machine learning engineers",
    "start": "5132639",
    "end": "5139440"
  },
  {
    "text": "and also as additional motivation uh they also did this interesting report um",
    "start": "5139440",
    "end": "5146560"
  },
  {
    "text": "the number of machine learning developers and data scientists involved in each",
    "start": "5146560",
    "end": "5151760"
  },
  {
    "text": "stage of the data science and ml workflow end to end so you see not very many people are involved in all stages",
    "start": "5151760",
    "end": "5157280"
  },
  {
    "text": "of the workflow and then around 10 but the highest percentage of people working in one stage of the ml",
    "start": "5157280",
    "end": "5163600"
  },
  {
    "text": "workflow would be the data exploration and analysis stage which is really the stage that we're looking at here and we",
    "start": "5163600",
    "end": "5170239"
  },
  {
    "text": "want to meet these developers where they are and provide them they prefer to work in python as the stats seem to clearly",
    "start": "5170239",
    "end": "5176639"
  },
  {
    "text": "show then we want to give them pythonic apis and a python native experience for working with their data catalogs and",
    "start": "5176639",
    "end": "5183360"
  },
  {
    "text": "doing better data exploration and analysis there okay so we set a few goals for the",
    "start": "5183360",
    "end": "5189440"
  },
  {
    "text": "project here we want to first provide intuitive pythonic data catalog apis",
    "start": "5189440",
    "end": "5196800"
  },
  {
    "text": "and two we want to bring fast scalable acid transactions to ray",
    "start": "5196800",
    "end": "5203120"
  },
  {
    "text": "and third we'd like to give rey users a consistent portable interface for interacting with data catalogs um so",
    "start": "5203120",
    "end": "5210239"
  },
  {
    "text": "that means you know you should be able to use the same interface either through raid data sets or delta cat interfaces",
    "start": "5210239",
    "end": "5217440"
  },
  {
    "text": "in order to interact with multiple open data catalogs or cloud data catalogs you shouldn't have to rewrite your code",
    "start": "5217440",
    "end": "5225760"
  },
  {
    "text": "and we also want to provide scalable efficient and reliable implementations of common data catalog table management",
    "start": "5225760",
    "end": "5232320"
  },
  {
    "text": "jobs so there's a lot of things that go on in terms of scheme evolution",
    "start": "5232320",
    "end": "5237600"
  },
  {
    "text": "compaction jobs to create read optimized views of tables which we'll talk about a little bit later",
    "start": "5237600",
    "end": "5243440"
  },
  {
    "text": "that require some heavy lifting from distributed compute technologies and we want to build those in",
    "start": "5243440",
    "end": "5249840"
  },
  {
    "text": "and create this optimal implementations of those as we can to support your workloads",
    "start": "5249840",
    "end": "5256560"
  },
  {
    "text": "and so if we take a look at the ecosystem here this is kind of inspired by the ray datasets ecosystem diagram",
    "start": "5256639",
    "end": "5263040"
  },
  {
    "text": "that shows where ray datasets leaves off and where delta cap picks up",
    "start": "5263040",
    "end": "5268239"
  },
  {
    "text": "so we want it to basically be an extension to array data sets so we want to support all the same data types as",
    "start": "5268239",
    "end": "5274800"
  },
  {
    "text": "input and output on our array cluster but when you add delta cat to the",
    "start": "5274800",
    "end": "5280400"
  },
  {
    "text": "picture we want you to not only be able to read and write from",
    "start": "5280400",
    "end": "5285679"
  },
  {
    "text": "uh just raw data storage and data lakey solutions but we want you to be able to",
    "start": "5285679",
    "end": "5290719"
  },
  {
    "text": "manage tables effectively inside of these other open source products that",
    "start": "5290719",
    "end": "5296639"
  },
  {
    "text": "include data catalogs as well um and then you know these often have good",
    "start": "5296639",
    "end": "5301760"
  },
  {
    "text": "integrations with your data warehousing solution um and kind of closes the gap from your",
    "start": "5301760",
    "end": "5306880"
  },
  {
    "text": "data warehouse to your data catalog to uh any machine learning that you may be running",
    "start": "5306880",
    "end": "5312719"
  },
  {
    "text": "so it gets you a more kind of orderly picture for managing your data and integrating it with your machine learning workflows than you get from",
    "start": "5312719",
    "end": "5318800"
  },
  {
    "text": "just a pure data like okay and so we introduced a few core",
    "start": "5318800",
    "end": "5324880"
  },
  {
    "text": "interfaces here um to try to solve this problem on a technical level",
    "start": "5324880",
    "end": "5330080"
  },
  {
    "text": "um we introduced the storage interface uh which is a low level interface with a",
    "start": "5330080",
    "end": "5335360"
  },
  {
    "text": "target audience of data catalog developers looking to integrate their catalog with ray so if you're a developer of apache hoodie of iceberg of",
    "start": "5335360",
    "end": "5342960"
  },
  {
    "text": "delta lake we'd like to talk to you and we'd like to make sure that the storage interface is suitable",
    "start": "5342960",
    "end": "5349120"
  },
  {
    "text": "to represent your data catalog and data storage layer and that it could be implemented so that",
    "start": "5349120",
    "end": "5355040"
  },
  {
    "text": "ray could easily interact with it and this exposes basically lower level",
    "start": "5355040",
    "end": "5360719"
  },
  {
    "text": "catalog metadata models and their structural details table partition details table revision and cdc that's change",
    "start": "5360719",
    "end": "5367679"
  },
  {
    "text": "data capture delta log details and you can find a link to that",
    "start": "5367679",
    "end": "5372800"
  },
  {
    "text": "interface on github as it exists right now there then we have a higher level interface",
    "start": "5372800",
    "end": "5378000"
  },
  {
    "text": "the catalog interface we expect that this is what the majority of data catalog users will use to integrate",
    "start": "5378000",
    "end": "5383920"
  },
  {
    "text": "their data with ray and the default implementation of that should use the storage interface so",
    "start": "5383920",
    "end": "5390000"
  },
  {
    "text": "basically all the code is written against the storage interface to make these higher level operations exposed by",
    "start": "5390000",
    "end": "5395600"
  },
  {
    "text": "the catalog happen in the uh storage implementer of choice so",
    "start": "5395600",
    "end": "5401600"
  },
  {
    "text": "somebody uses a catalog method to write to a table and they're using a storage interface based on iceberg the storage",
    "start": "5401600",
    "end": "5407280"
  },
  {
    "text": "interface should commit the results of that right to the table using the iceberg table format for example",
    "start": "5407280",
    "end": "5414480"
  },
  {
    "text": "um and so again we're exposing table level rights of ray data sets and uh",
    "start": "5414480",
    "end": "5420080"
  },
  {
    "text": "table partition and incremental or time bound or you might say windowed reads into array data sets and you can see",
    "start": "5420080",
    "end": "5427360"
  },
  {
    "text": "again the interface for that there at that link in github and again to dig into the target",
    "start": "5427360",
    "end": "5434000"
  },
  {
    "text": "audience a bit more we're targeting two main groups of users here one is data catalog developers we expect usually",
    "start": "5434000",
    "end": "5440159"
  },
  {
    "text": "want to implement the storage interface the lower level interface and by so doing they can reuse existing array",
    "start": "5440159",
    "end": "5446639"
  },
  {
    "text": "catalog management job implementations so anything that we've already written to compact your table provide read",
    "start": "5446639",
    "end": "5452880"
  },
  {
    "text": "optimized view stuff like that it just works out of the box and they can also reuse existing uh catalog implementation",
    "start": "5452880",
    "end": "5460159"
  },
  {
    "text": "based on the storage um but maybe they sometimes find that they don't fit perfectly into the storage interface and",
    "start": "5460159",
    "end": "5465679"
  },
  {
    "text": "they want to implement the catalog interface and now this means they wouldn't reuse",
    "start": "5465679",
    "end": "5470719"
  },
  {
    "text": "those managed jobs already but they could support more flexible storage models um and",
    "start": "5470719",
    "end": "5476800"
  },
  {
    "text": "apparently i didn't finish the sentence there but support more flexible compute models so what i",
    "start": "5476800",
    "end": "5482480"
  },
  {
    "text": "was going to say there and data catalog users will usually use",
    "start": "5482480",
    "end": "5487600"
  },
  {
    "text": "the catalog interface because it provides a simpler safer standard api and sometimes use storage",
    "start": "5487600",
    "end": "5495040"
  },
  {
    "text": "interface which is complex it has less guardrails but it's a more powerful api",
    "start": "5495040",
    "end": "5501920"
  },
  {
    "text": "and delta cat compute these managed compute implementations that we're talking about that are implemented using",
    "start": "5502159",
    "end": "5507520"
  },
  {
    "text": "the storage interface are powered by ray they're intended to be invoked transparently by the delta",
    "start": "5507520",
    "end": "5513120"
  },
  {
    "text": "catalog api you shouldn't generally have to invoke them explicitly as a catalog user they will manage and curate your catalog",
    "start": "5513120",
    "end": "5519520"
  },
  {
    "text": "for you quietly behind the scenes and um current implementations we have are compactions we talked about which",
    "start": "5519520",
    "end": "5525840"
  },
  {
    "text": "merges table partition change data capture or delta logs into a single",
    "start": "5525840",
    "end": "5532639"
  },
  {
    "text": "unified view of the table and uh statistics we also have some basic statistics calculations for table",
    "start": "5532639",
    "end": "5540000"
  },
  {
    "text": "management which calculate column delta partition and table level statistics for everything in your data catalog",
    "start": "5540000",
    "end": "5546480"
  },
  {
    "text": "and we have upcoming implementations we're working on for scheme evolution table repair and ml driven anomaly",
    "start": "5546480",
    "end": "5552080"
  },
  {
    "text": "detection okay and so with that kind of context out of the way let's get into some code",
    "start": "5552080",
    "end": "5559520"
  },
  {
    "text": "if you were to use delta cat how would you use it well you start by initializing it and registering",
    "start": "5559520",
    "end": "5564960"
  },
  {
    "text": "available catalogs in this case we're registering just one catalog we're going to call it the prod",
    "start": "5564960",
    "end": "5571040"
  },
  {
    "text": "catalog you have to provide it an implementation so i'm saying okay this is the guy that implements my interface and then",
    "start": "5571040",
    "end": "5576400"
  },
  {
    "text": "everything else is just um keyword arguments that this catalog implementation takes so in this case",
    "start": "5576400",
    "end": "5583040"
  },
  {
    "text": "we're saying we add an s3 catalog perhaps minimally we'd need to provide at the base uri of this s3 based catalog",
    "start": "5583040",
    "end": "5589840"
  },
  {
    "text": "to find all of the files and all of the metadata that create our catalog",
    "start": "5589840",
    "end": "5596960"
  },
  {
    "text": "um when we call this ray will be initialized automatically by a radon array.init",
    "start": "5596960",
    "end": "5602320"
  },
  {
    "text": "with address equals auto and um if you only provide one catalog like we",
    "start": "5602320",
    "end": "5607760"
  },
  {
    "text": "do here it will become the default so you don't have to provide the name the catalog and future operations",
    "start": "5607760",
    "end": "5613120"
  },
  {
    "text": "when you're writing tables or reading tables or altering tables or whatever you're doing",
    "start": "5613120",
    "end": "5618239"
  },
  {
    "text": "with your catalog um but you could also give a default catalog name if you're providing",
    "start": "5618239",
    "end": "5623280"
  },
  {
    "text": "multiple catalogs maybe you have a prod beta alpha catalog maybe you have an iceberg catalog and a",
    "start": "5623280",
    "end": "5628880"
  },
  {
    "text": "delta catalog that are both production things like that in that case you could specify a default catalog yourself and",
    "start": "5628880",
    "end": "5635760"
  },
  {
    "text": "say well if i don't specify a catalog name assume that this catalog is the default you can also give custom",
    "start": "5635760",
    "end": "5641600"
  },
  {
    "text": "ray.init args okay and so once we've initialized",
    "start": "5641600",
    "end": "5648480"
  },
  {
    "text": "the catalog how do we go about actually creating and writing data to a table maybe one of the",
    "start": "5648480",
    "end": "5654560"
  },
  {
    "text": "first things you'd want to do so in this case we're just going to create a simple ray distributed data set",
    "start": "5654560",
    "end": "5660320"
  },
  {
    "text": "from a tiny three row two column pandas data frame okay and",
    "start": "5660320",
    "end": "5665679"
  },
  {
    "text": "that's those first two lines right up there and then we're going to write this data set to a new parquet table named sample",
    "start": "5665679",
    "end": "5672239"
  },
  {
    "text": "table in the example namespace so the prod catalog um we're going to say hey i expect the",
    "start": "5672239",
    "end": "5677600"
  },
  {
    "text": "table right mode to be create so if the table already exists you're going to get an error and please write the content",
    "start": "5677600",
    "end": "5682880"
  },
  {
    "text": "type out as part k right there now actually it's equivalent to this command below which is much simpler",
    "start": "5682880",
    "end": "5689520"
  },
  {
    "text": "that's a much so the top command is very explicit way of creating this table and writing data to it but actually all of",
    "start": "5689520",
    "end": "5695840"
  },
  {
    "text": "that all of those arguments would have been inferred if we just gave it a data set and a table name because we would",
    "start": "5695840",
    "end": "5700960"
  },
  {
    "text": "have known the default catalog is prod we only have one after all it would resolve to a default namespace",
    "start": "5700960",
    "end": "5706800"
  },
  {
    "text": "that that catalog provides and um we would have seen that the table exists and assumed that you wanted to create it",
    "start": "5706800",
    "end": "5715440"
  },
  {
    "text": "and the default content type would also be parquet and so now let's take a look behind the",
    "start": "5715440",
    "end": "5720480"
  },
  {
    "text": "scenes about what actually happens here so you start with the data set that we created loaded onto your array cluster",
    "start": "5720480",
    "end": "5728000"
  },
  {
    "text": "and the first thing that will happen is we will stage the table inside the catalog so it",
    "start": "5728000",
    "end": "5735840"
  },
  {
    "text": "should not be visible to other users of the catalog yet since it's not committed just staged we",
    "start": "5735840",
    "end": "5742719"
  },
  {
    "text": "created a metadata container for it that's not queryable and then we will create uh or stage",
    "start": "5742719",
    "end": "5749920"
  },
  {
    "text": "again rather delta metadata that's not discoverable by other users we've staged an append delta that we're going to put",
    "start": "5749920",
    "end": "5756560"
  },
  {
    "text": "inside that table and for our implementation at amazon we are going to then",
    "start": "5756560",
    "end": "5762639"
  },
  {
    "text": "uh load this data set into a parquet file in s3 um this doesn't have to be s3 it could",
    "start": "5762639",
    "end": "5769280"
  },
  {
    "text": "be any viable storage plane and some of the",
    "start": "5769280",
    "end": "5774880"
  },
  {
    "text": "minutiae of the details here could vary a little bit from one catalog implementation to another but they'll",
    "start": "5774880",
    "end": "5780000"
  },
  {
    "text": "generally look about like this and then uh since a delta fundamentally",
    "start": "5780000",
    "end": "5786320"
  },
  {
    "text": "a core the the model of a delta is basically to store one or more",
    "start": "5786320",
    "end": "5791440"
  },
  {
    "text": "files together with metadata about those files we're going to store a reference to",
    "start": "5791440",
    "end": "5797520"
  },
  {
    "text": "the uri of this parquet file that represents what we'd like to append",
    "start": "5797520",
    "end": "5802639"
  },
  {
    "text": "to the table and then we're going to commit the delta to the table which is staged right now",
    "start": "5802639",
    "end": "5807840"
  },
  {
    "text": "again not visible some people still can't query it and once we've verified that it's been",
    "start": "5807840",
    "end": "5813679"
  },
  {
    "text": "committed successfully we will commit the table which makes it discoverable queryable",
    "start": "5813679",
    "end": "5819280"
  },
  {
    "text": "by other users so if you are another user maybe what",
    "start": "5819280",
    "end": "5824320"
  },
  {
    "text": "you want to do now is read that table back into a ray distributed data set and",
    "start": "5824320",
    "end": "5829679"
  },
  {
    "text": "maybe just for fun we'll convert that to a distributed pandas data frame using modem after we read it back out we'd",
    "start": "5829679",
    "end": "5835679"
  },
  {
    "text": "expect to read this table that we put on the bottom once we complete this read",
    "start": "5835679",
    "end": "5841199"
  },
  {
    "text": "and again just to make it clear what we're talking about going back to the same diagram the read of the table will be served",
    "start": "5841199",
    "end": "5847199"
  },
  {
    "text": "directly against delta cat table metadata and be loaded into a",
    "start": "5847199",
    "end": "5853440"
  },
  {
    "text": "distributed data set on your ray cluster that data set will be copied into a distributed data frame these will both",
    "start": "5853440",
    "end": "5859600"
  },
  {
    "text": "be subject to normal array garbage collection policies and that is the end of that operation it",
    "start": "5859600",
    "end": "5866320"
  },
  {
    "text": "would have still had to read all that data from s3 but it figured out where it was in s3 by asking the delta cat",
    "start": "5866320",
    "end": "5874239"
  },
  {
    "text": "catalog uh to describe the table its metadata figured out there was one delta in it and that one delta had just one file and",
    "start": "5874239",
    "end": "5880880"
  },
  {
    "text": "read that added to a data set so pretty simple",
    "start": "5880880",
    "end": "5886000"
  },
  {
    "text": "and now um we can also append another delta to this table",
    "start": "5886000",
    "end": "5891840"
  },
  {
    "text": "so we can just create another pandas data frame to append notice we're not even making a data set this time we can",
    "start": "5891840",
    "end": "5898000"
  },
  {
    "text": "kind of transparently accept either local uh",
    "start": "5898000",
    "end": "5903520"
  },
  {
    "text": "local tables so this would be things like pandas data frames or arrow tables",
    "start": "5903520",
    "end": "5908719"
  },
  {
    "text": "or numpy arrays and data sets as well for the data argument of write",
    "start": "5908719",
    "end": "5915280"
  },
  {
    "text": "to table so in this case we're just making a local pandas data frame we're saying let's append this to the same",
    "start": "5915280",
    "end": "5920880"
  },
  {
    "text": "table if we append it to the same table our data in column one is one two four",
    "start": "5920880",
    "end": "5927040"
  },
  {
    "text": "so we see one two three then one two four and column two is def so we see a b c d e f so we just concatenated those",
    "start": "5927040",
    "end": "5934480"
  },
  {
    "text": "two tables together that's we expect to be the end result now it's a little more interesting to",
    "start": "5934480",
    "end": "5939760"
  },
  {
    "text": "see what happens behind the scenes here we start with an already committed table to the catalog",
    "start": "5939760",
    "end": "5945440"
  },
  {
    "text": "we create the delta or stage rather the delta again that will be put in that table nobody can see it yet but us",
    "start": "5945440",
    "end": "5953679"
  },
  {
    "text": "and after validating that the data is consistent with the constraints of the",
    "start": "5953679",
    "end": "5958880"
  },
  {
    "text": "table like the schema and so forth we will write its data to s3",
    "start": "5958880",
    "end": "5965360"
  },
  {
    "text": "or whatever uh file system you're using reference that file just like we did before inside of the delta and then we",
    "start": "5965600",
    "end": "5972239"
  },
  {
    "text": "will commit it to the table um and now your write operation is actually",
    "start": "5972239",
    "end": "5977679"
  },
  {
    "text": "done it can synchronously return successfully but if you keep on doing this over and over again you inevitably",
    "start": "5977679",
    "end": "5984320"
  },
  {
    "text": "face a problem where um if somebody has tiny data sets like this",
    "start": "5984320",
    "end": "5989920"
  },
  {
    "text": "that they keep on writing to the table with great frequency you end up with a table that's very inefficient to consume",
    "start": "5989920",
    "end": "5996239"
  },
  {
    "text": "because it had too many tiny updates now we can take care of two large updates load time we can split those in",
    "start": "5996239",
    "end": "6003199"
  },
  {
    "text": "to read optimized file sizes but there's not much we can do about you only had three rows to load okay i guess we got",
    "start": "6003199",
    "end": "6009760"
  },
  {
    "text": "to put a new delta except we can create either synchronously or asynchronously",
    "start": "6009760",
    "end": "6016560"
  },
  {
    "text": "uh your choice a read optimized view of the table and that's what our compactor does so",
    "start": "6016560",
    "end": "6023760"
  },
  {
    "text": "either synchronously or asynchronously we trigger a compaction job against this",
    "start": "6023760",
    "end": "6029280"
  },
  {
    "text": "table it says i want you to take that and i want you to create a read optimized view of it",
    "start": "6029280",
    "end": "6035199"
  },
  {
    "text": "and what happens there is the compactor will launch typically on a separate dedicated ray cluster",
    "start": "6035199",
    "end": "6040880"
  },
  {
    "text": "um and it will read the deltas from this table so it read both of those deltas that we",
    "start": "6040880",
    "end": "6047280"
  },
  {
    "text": "just put in there you could also by the way um read those deltas yourselves you can get incremental views of the table",
    "start": "6047280",
    "end": "6053280"
  },
  {
    "text": "you can limit it to just the deltas you want to read you don't always have to read all of the deltas from a delta stream of a table",
    "start": "6053280",
    "end": "6060880"
  },
  {
    "text": "in practice you would do that by providing like epic timestamp or date ranges of updates",
    "start": "6060880",
    "end": "6066560"
  },
  {
    "text": "that you would like to read and so after we read those deltas we're going to create or stage a revision of",
    "start": "6066560",
    "end": "6073280"
  },
  {
    "text": "this table that people can't see yet because it's not yet completed and then we're going to do a simple",
    "start": "6073280",
    "end": "6078639"
  },
  {
    "text": "merge of those two deltas since we're using pi arrow here this tends to be very efficient it's a zero copy merge",
    "start": "6078639",
    "end": "6085920"
  },
  {
    "text": "um we're just taking pointers basically to the arrow buffers for those tables and",
    "start": "6085920",
    "end": "6093520"
  },
  {
    "text": "stitching them together to create the merge table there so very efficient when it happens on our ray cluster",
    "start": "6093520",
    "end": "6100239"
  },
  {
    "text": "and then we are creating the compacted delta or the read optimize",
    "start": "6100239",
    "end": "6105600"
  },
  {
    "text": "delta this will be very useful if you're doing data analytics tasks over this table",
    "start": "6105600",
    "end": "6112880"
  },
  {
    "text": "and we're going to again write that merge table to s3 it's a new parquet file we're",
    "start": "6113679",
    "end": "6121040"
  },
  {
    "text": "going to reference it inside of that delta and we're going to commit the delta to our stage table",
    "start": "6121040",
    "end": "6126880"
  },
  {
    "text": "and finally commit the read optimized revision and so from now on when you",
    "start": "6126880",
    "end": "6132000"
  },
  {
    "text": "read the table you can make an explicit choice if you'd like about i'd like to read the read optimized version of it",
    "start": "6132000",
    "end": "6139280"
  },
  {
    "text": "or i would like to read the incremental change log bound by this window of time",
    "start": "6139280",
    "end": "6147119"
  },
  {
    "text": "so by default they'll both be there there's kind of more advanced topics that we'd say for a later discussion about garbage collection policies and",
    "start": "6147119",
    "end": "6153920"
  },
  {
    "text": "maybe you want to get rid of the delta change log after you're done with this operation uh that's a possibility but by",
    "start": "6153920",
    "end": "6160800"
  },
  {
    "text": "default we will keep them both around we won't replace or overwrite the delta change log",
    "start": "6160800",
    "end": "6168320"
  },
  {
    "text": "okay so we've talked about how an append works and how you can create a read optimized",
    "start": "6168480",
    "end": "6174000"
  },
  {
    "text": "view to resolve problems that you would get from appending lots of tiny deltas",
    "start": "6174000",
    "end": "6180000"
  },
  {
    "text": "and now let's talk about a different mode of writing to a table maybe we create that same pandas data frame that",
    "start": "6180000",
    "end": "6187040"
  },
  {
    "text": "we appended as the second delta before but instead say we would like to do the replace",
    "start": "6187040",
    "end": "6192719"
  },
  {
    "text": "mode so table write mode dot replace so what's going to happen when we do that um what's going to happen here is",
    "start": "6192719",
    "end": "6200639"
  },
  {
    "text": "we are going to create a new delta just like we did before going to commit the parquet file to s3",
    "start": "6200639",
    "end": "6207360"
  },
  {
    "text": "um and again you don't use replace to change the schema of your table you",
    "start": "6207360",
    "end": "6212400"
  },
  {
    "text": "don't use it to change its constraints it still has to um it still has to be consistent with all",
    "start": "6212400",
    "end": "6219600"
  },
  {
    "text": "of your existing tables constraints but you can replace all of the data in your table with a replace type write mode so",
    "start": "6219600",
    "end": "6226400"
  },
  {
    "text": "we create that new data and then we simply create a new revision of your table again",
    "start": "6226400",
    "end": "6232080"
  },
  {
    "text": "and we put that new delta into this revision of your table to basically replace all of",
    "start": "6232080",
    "end": "6238400"
  },
  {
    "text": "its old contents so again uh we it's kind of an explicit mode of saying get",
    "start": "6238400",
    "end": "6245280"
  },
  {
    "text": "rid of that old delta change stream or um you know keep it to the side",
    "start": "6245280",
    "end": "6251199"
  },
  {
    "text": "perhaps for historic reasons but also make this purely replaced revision available and make it the latest",
    "start": "6251199",
    "end": "6257119"
  },
  {
    "text": "provision which will be queried by default if somebody doesn't have a preference to look back at the old",
    "start": "6257119",
    "end": "6263199"
  },
  {
    "text": "delta's change streams for the table so that's the replace typewrite mode",
    "start": "6263199",
    "end": "6270000"
  },
  {
    "text": "and now another thing that we can do with these tables is we can uh we can create a table with primary keys",
    "start": "6271199",
    "end": "6278320"
  },
  {
    "text": "this is something we focused on optimizing a lot um and we think it's kind of a unique",
    "start": "6278320",
    "end": "6284000"
  },
  {
    "text": "feature of our catalog is primary key enforcement or near real-time primary key enforcement when you're creating",
    "start": "6284000",
    "end": "6289760"
  },
  {
    "text": "tables of primary keys and appending to them so in this case we've specified one additional argument we've said we want",
    "start": "6289760",
    "end": "6294960"
  },
  {
    "text": "column one to be a primary key this time now a primary key means it needs to be every value in it needs to be unique and",
    "start": "6294960",
    "end": "6301600"
  },
  {
    "text": "non-null and so when we want to append another",
    "start": "6301600",
    "end": "6307520"
  },
  {
    "text": "delta to it we'll specify the merge right mode by default this will be an up cert merge",
    "start": "6307520",
    "end": "6313360"
  },
  {
    "text": "and we want to merge the same table that we did before into it this pandas data",
    "start": "6313360",
    "end": "6318639"
  },
  {
    "text": "frame of one two four d e f and we expect the end result to be a bit different though than when we just",
    "start": "6318639",
    "end": "6324080"
  },
  {
    "text": "didn't append it shouldn't be just a straight concatenation of the two values but rather we should do an upsert",
    "start": "6324080",
    "end": "6330719"
  },
  {
    "text": "merge and this should be our end result and the actual process to rectify this",
    "start": "6330719",
    "end": "6336480"
  },
  {
    "text": "looks a lot like the whole process we went through for the append process before you'll initially just create the",
    "start": "6336480",
    "end": "6343920"
  },
  {
    "text": "delta you'll commit it to the delta as an upsert delta but then you'll trigger a synchronous or",
    "start": "6343920",
    "end": "6349360"
  },
  {
    "text": "asynchronous compaction job to create the merged table and here we've identified the updated rows in orange",
    "start": "6349360",
    "end": "6355760"
  },
  {
    "text": "the inserted row in red the unchanged row and white one and two both",
    "start": "6355760",
    "end": "6361600"
  },
  {
    "text": "conflict on the primary key and so we are getting the later values d and e",
    "start": "6361600",
    "end": "6366960"
  },
  {
    "text": "replaced over a and b and we're getting 4 a new value 4 and f inserted right",
    "start": "6366960",
    "end": "6372000"
  },
  {
    "text": "here okay so that's what we do with primary key tables",
    "start": "6372000",
    "end": "6377679"
  },
  {
    "text": "and um we can quickly enumerate our current supported write modes by table type um currently as we're using this",
    "start": "6377679",
    "end": "6384480"
  },
  {
    "text": "internally we support for standard tables not primary keys appending deltas or replacing the whole table with a new",
    "start": "6384480",
    "end": "6390800"
  },
  {
    "text": "delta but we don't support merge upserts and merge deletes because we don't support merges against arbitrary keys",
    "start": "6390800",
    "end": "6396639"
  },
  {
    "text": "yet and for primary key tables we don't support pure pens yet",
    "start": "6396639",
    "end": "6403679"
  },
  {
    "text": "uh but we do support replaces we do support merge up certs and merge to leads",
    "start": "6403679",
    "end": "6409760"
  },
  {
    "text": "we're looking at closing these gaps and supporting all types of these going forward it'll probably take some time",
    "start": "6409760",
    "end": "6416159"
  },
  {
    "text": "and finally let's get into some benchmarks how does this all work for us in terms of real world performance",
    "start": "6416159",
    "end": "6421520"
  },
  {
    "text": "integrating with ray data sets and integrating with our data catalog of amazon well first off we did um 100",
    "start": "6421520",
    "end": "6428719"
  },
  {
    "text": "samples of delta cat read table from our production catalogs that were less than or equal to one tubby byte in size again",
    "start": "6428719",
    "end": "6436480"
  },
  {
    "text": "they were all stored in s3 we separated the results here based on whether they were par k or csv technically any",
    "start": "6436480",
    "end": "6442320"
  },
  {
    "text": "delimited text it's not necessarily csv v files maybe it's tsv tab separated but",
    "start": "6442320",
    "end": "6449119"
  },
  {
    "text": "same relative performance um we ran these olfa equivalently sized",
    "start": "6449119",
    "end": "6455199"
  },
  {
    "text": "eight r5n 8x large clusters 256 vp cpus per cluster providing a maximum network",
    "start": "6455199",
    "end": "6461600"
  },
  {
    "text": "bandwidth of 200 gigabits per second uh we read an average of 304 data set",
    "start": "6461600",
    "end": "6467840"
  },
  {
    "text": "files per table average data set size was 161 gigabytes or about 67 million",
    "start": "6467840",
    "end": "6474159"
  },
  {
    "text": "rows um 143 gigabytes or about nearly 90 million rows for csv",
    "start": "6474159",
    "end": "6481040"
  },
  {
    "text": "and our performance figures we thought were pretty good you know we're looking at 7.84 gigabytes a second or 63",
    "start": "6481040",
    "end": "6486800"
  },
  {
    "text": "gigabits per second 28 terabytes an hour for par k a little bit lower performance for csv 41 gigabits per second",
    "start": "6486800",
    "end": "6494400"
  },
  {
    "text": "about two-thirds of the performance here in terms of byte throughput 5.13 gigabytes per second",
    "start": "6494400",
    "end": "6500400"
  },
  {
    "text": "it is interesting to note however that the rows per second per core is about equivalent which points to a",
    "start": "6500400",
    "end": "6506560"
  },
  {
    "text": "pattern of our production users usually storing tables with smaller row sizes in",
    "start": "6506560",
    "end": "6512000"
  },
  {
    "text": "csv in larger row sizes in part k because then they can just select individual columns to read out because",
    "start": "6512000",
    "end": "6518400"
  },
  {
    "text": "well i guess in this as they get larger the rows per second is probably getting unacceptably slow for them in the csv",
    "start": "6518400",
    "end": "6525119"
  },
  {
    "text": "format and the price is pretty good you know basically saying cost you about 76 cents to read a terabyte of parquet",
    "start": "6525119",
    "end": "6531920"
  },
  {
    "text": "data for a little over a dollar to read a terabyte of csv data",
    "start": "6531920",
    "end": "6537040"
  },
  {
    "text": "okay and now something we're a little more excited about and that we've worked very hard on",
    "start": "6537040",
    "end": "6542560"
  },
  {
    "text": "this is one of the things that we were looking to improve with our integration with ray",
    "start": "6542560",
    "end": "6547600"
  },
  {
    "text": "is the speed at which we can do primary key merges",
    "start": "6547600",
    "end": "6552719"
  },
  {
    "text": "and so uh we did 432 merge absurd samples with broad data sets greater",
    "start": "6552719",
    "end": "6557760"
  },
  {
    "text": "than or equal to 10 tubby bytes um and now these figures here are",
    "start": "6557760",
    "end": "6563360"
  },
  {
    "text": "measuring the performance of just the compaction merge stage so we're not measuring the end and performance of",
    "start": "6563360",
    "end": "6569360"
  },
  {
    "text": "writing every piece of data but like if you're running an asynchronous compaction job that comes back to it and",
    "start": "6569360",
    "end": "6574719"
  },
  {
    "text": "compacts it later how long will it take that's the performance for measuring here",
    "start": "6574719",
    "end": "6580080"
  },
  {
    "text": "so again all the data is stored in s3 this time the content type is purely parquet",
    "start": "6580080",
    "end": "6585119"
  },
  {
    "text": "um which is fairly uh consistent for very large tables in our",
    "start": "6585119",
    "end": "6592320"
  },
  {
    "text": "catalog we generally want to represent those in part k and um so we've highlighted our best performing",
    "start": "6592320",
    "end": "6600159"
  },
  {
    "text": "test case here which was blazing 3176 gigabits per second so that's over",
    "start": "6600159",
    "end": "6608840"
  },
  {
    "text": "1400 terabytes per hour um and the largest input size that we",
    "start": "6608840",
    "end": "6614480"
  },
  {
    "text": "were able to uh compact on a 110 node cluster notice it's actually smaller",
    "start": "6614480",
    "end": "6619760"
  },
  {
    "text": "than the cluster above uh was 1.2 pebby bytes so much larger than actually the memory",
    "start": "6619760",
    "end": "6627040"
  },
  {
    "text": "that this cluster has available on it so we can limit the amount that we intake and we can churn through it",
    "start": "6627040",
    "end": "6633520"
  },
  {
    "text": "at a pretty good pace still so obviously our performance takes a hit since we have to pull it into the ray cluster in",
    "start": "6633520",
    "end": "6639760"
  },
  {
    "text": "rounds and merge things in rounds and then uh come out with a final result so it's",
    "start": "6639760",
    "end": "6646080"
  },
  {
    "text": "not quite as fast as the above performance figure but still pretty fast still 388 terabytes per hour",
    "start": "6646080",
    "end": "6652880"
  },
  {
    "text": "and our most efficient use case here is on an 11 node r5 m8x large cluster uh we",
    "start": "6652880",
    "end": "6658320"
  },
  {
    "text": "dealt with a 22 terabyte input file and we were able to process it for 22 cents a terabyte or 61 477 rows per second per",
    "start": "6658320",
    "end": "6667280"
  },
  {
    "text": "core on that table and here are your averages below um the average efficiency i think stood",
    "start": "6667280",
    "end": "6673440"
  },
  {
    "text": "out to me it's very very good in particular 33 cents per terabyte to merge primary keys",
    "start": "6673440",
    "end": "6680159"
  },
  {
    "text": "and the performance is quite fast too turning through 749 terabytes on an hour on an average 138 r5 m8x large cluster",
    "start": "6680159",
    "end": "6689760"
  },
  {
    "text": "with about yeah a little over 4 000 bcpus okay so what's the current state of this",
    "start": "6689760",
    "end": "6695520"
  },
  {
    "text": "at amazon what are we doing that are using it so we have a delta cat storage uh that",
    "start": "6695520",
    "end": "6700800"
  },
  {
    "text": "interface we were talking about earlier the low level interface implemented for our production s3 based catalog",
    "start": "6700800",
    "end": "6706800"
  },
  {
    "text": "and uh we're incorporating it into the following novel use cases first so it's unlocked",
    "start": "6706800",
    "end": "6713199"
  },
  {
    "text": "some new realms for us here in terms of new projects and initiatives we're able to do and one of those is near real-time",
    "start": "6713199",
    "end": "6720080"
  },
  {
    "text": "table statistics and data quality analysis and another is interactive data exploration",
    "start": "6720080",
    "end": "6726800"
  },
  {
    "text": "and analysis for ml workflows two new initiatives we're using it for and spinning up projects for",
    "start": "6726800",
    "end": "6732800"
  },
  {
    "text": "and then another one is actually the compaction figures were so good that we",
    "start": "6732800",
    "end": "6738800"
  },
  {
    "text": "are looking to migrate our legacy compactor on spark emr over to",
    "start": "6738800",
    "end": "6745920"
  },
  {
    "text": "the delta cad and ray compactor because we're looking at a reduced cost of about 91 percent in terms of dollars",
    "start": "6745920",
    "end": "6751920"
  },
  {
    "text": "per byte processed improved scalability about 12 times larger input data sets improve throughput about 13 times larger",
    "start": "6751920",
    "end": "6760080"
  },
  {
    "text": "uh in terms of bytes per second and uh we can actually offer we have very consistent job completion times we",
    "start": "6760080",
    "end": "6766320"
  },
  {
    "text": "can estimate based on the stats we've collected uh a very accurate uh",
    "start": "6766320",
    "end": "6771440"
  },
  {
    "text": "completion time for the job and we find that i think it's about 99.6 adherence right to the sla or the time we",
    "start": "6771440",
    "end": "6778800"
  },
  {
    "text": "calculated the job being done by so we can start to promise people yeah your data is going to be ready by this",
    "start": "6778800",
    "end": "6784719"
  },
  {
    "text": "point in time and we are over 99 sure that it will arrive",
    "start": "6784719",
    "end": "6789920"
  },
  {
    "text": "at that point in time okay and so what are next steps um with",
    "start": "6789920",
    "end": "6795440"
  },
  {
    "text": "this whole project so well if you visit the github repo right now you'll notice it's very sparse on documentation we",
    "start": "6795440",
    "end": "6802480"
  },
  {
    "text": "have a few sentences written about what it is and what it aims to be but we need to add a lot of diagrams like we went",
    "start": "6802480",
    "end": "6809119"
  },
  {
    "text": "over here a lot of specs and documentation to the interfaces and apis uh what they are and how to implement",
    "start": "6809119",
    "end": "6815119"
  },
  {
    "text": "them what the expected results are and something that will really help with that and help you all actually get your hands on experience with it",
    "start": "6815119",
    "end": "6821440"
  },
  {
    "text": "is uh contributing a reference delta cat storage implementation back to open source so we have one for our prod",
    "start": "6821440",
    "end": "6827440"
  },
  {
    "text": "catalog we don't have one in open source yet so you can kind of peruse the interfaces crews the models peruse the",
    "start": "6827440",
    "end": "6833199"
  },
  {
    "text": "compute implementations that we use but we need to actually provide a real storage implementation for you to",
    "start": "6833199",
    "end": "6839360"
  },
  {
    "text": "interoperate with your data catalog and then use that to provide a reference data",
    "start": "6839360",
    "end": "6845440"
  },
  {
    "text": "catalog delta catalog interface implementation so it's just so much easier for you to",
    "start": "6845440",
    "end": "6851199"
  },
  {
    "text": "use and interact with we're also looking at more native ray data set api integration",
    "start": "6851199",
    "end": "6858080"
  },
  {
    "text": "you shouldn't really have to go to these delta catalog apis in our opinion you should just be able if you have something in array data set you should",
    "start": "6858080",
    "end": "6864639"
  },
  {
    "text": "be able to use ray's existing uh data ai io apis to read or write data",
    "start": "6864639",
    "end": "6872000"
  },
  {
    "text": "sets directly from data catalogs that delta count supports",
    "start": "6872000",
    "end": "6877840"
  },
  {
    "text": "and we're also go going to write some more introductory and technical how-to blog",
    "start": "6878080",
    "end": "6883599"
  },
  {
    "text": "posts that kind of teach how to use this and different patterns and anti-patterns for using it and how",
    "start": "6883599",
    "end": "6890560"
  },
  {
    "text": "it fits within your workflows and examples cool stuff like that we're also working with",
    "start": "6890560",
    "end": "6896239"
  },
  {
    "text": "apache iceberg right now on apache iceberg integration and the accompanying pi iceberg project",
    "start": "6896239",
    "end": "6903679"
  },
  {
    "text": "so hoping to have an apache iceberg implementation of the deltacat storage interface ideally uh by the end of this",
    "start": "6903679",
    "end": "6911119"
  },
  {
    "text": "year so stay tuned there and then also we're looking to transition for amazon table management",
    "start": "6911119",
    "end": "6917840"
  },
  {
    "text": "jobs to delta cap so again we're talking about managing an exabyte scale catalog taking",
    "start": "6917840",
    "end": "6923440"
  },
  {
    "text": "on over 70 000 jobs a day on average uh and handling over",
    "start": "6923440",
    "end": "6928719"
  },
  {
    "text": "uh one petty bike they have new deltas a day that's over 5.5 trillion records a day on average and over 17 epidemics of",
    "start": "6928719",
    "end": "6935840"
  },
  {
    "text": "deltas a day or over 80 trillion records a day on p so uh and this is just the the fraction",
    "start": "6935840",
    "end": "6942880"
  },
  {
    "text": "of the of the data catalog jobs that we're looking to",
    "start": "6942880",
    "end": "6949040"
  },
  {
    "text": "take care of um both this year and probably next year is where we're really targeting more",
    "start": "6949040",
    "end": "6954719"
  },
  {
    "text": "production integration and migrations over to running delta account here for these data catalog management jobs",
    "start": "6954719",
    "end": "6960560"
  },
  {
    "text": "so massive scale doing a lot of shadow testing right now to validate that we're",
    "start": "6960560",
    "end": "6966719"
  },
  {
    "text": "ready and it won't be operationally painful once we put it up there it all be very smooth and",
    "start": "6966719",
    "end": "6973599"
  },
  {
    "text": "successful at this scale so those are our next steps and yeah thanks",
    "start": "6973599",
    "end": "6979840"
  },
  {
    "text": "everybody for viewing uh so yeah any questions or comments or if you want to get involved please reach out to me",
    "start": "6979840",
    "end": "6985679"
  },
  {
    "text": "visit us on github give us a star fork whatever and we can work together and",
    "start": "6985679",
    "end": "6991199"
  },
  {
    "text": "feel free to reach out to me on the ray community slack all right so thanks everybody",
    "start": "6991199",
    "end": "6998000"
  },
  {
    "text": "thank you happy to take your questions thank you patrick for the wonderful validation of scale when you're talking",
    "start": "6998000",
    "end": "7004080"
  },
  {
    "text": "about scale this is what you're actually showing there was a question that somebody asked you know was going to ask",
    "start": "7004080",
    "end": "7009280"
  },
  {
    "text": "or did ask you know what were the largest data sets that amazon worked with with respect to data sets and how",
    "start": "7009280",
    "end": "7015119"
  },
  {
    "text": "big was the compaction file and you pretty much answered on that colorful colorful slide of yours about benchmarks",
    "start": "7015119",
    "end": "7022560"
  },
  {
    "text": "uh my question was when you were talking about the compaction you say you actually have a ray a job that actually",
    "start": "7022560",
    "end": "7029040"
  },
  {
    "text": "runs on each and every node to do the compaction so are you taking the the change catalog uh for the delta and",
    "start": "7029040",
    "end": "7035840"
  },
  {
    "text": "distributing it across all the nodes to do the compaction and then you're doing a reduce how is the final",
    "start": "7035840",
    "end": "7041599"
  },
  {
    "text": "compaction is done can you elaborate that on a little bit um yeah sure so the first thing i'll say",
    "start": "7041599",
    "end": "7048239"
  },
  {
    "text": "is um i i gave a talk that goes over kind of the design of that and how it works in depth end to end at the 2021",
    "start": "7048239",
    "end": "7055280"
  },
  {
    "text": "race summit last year and that's still accurate that hasn't really changed at all i think it's called petabyte scale data",
    "start": "7055280",
    "end": "7060639"
  },
  {
    "text": "lake table management with ray arrow and parquet and so",
    "start": "7060639",
    "end": "7065840"
  },
  {
    "text": "that will give you an in-depth view but the quick view is yeah we do take all the deltas from the table and we",
    "start": "7065840",
    "end": "7071920"
  },
  {
    "text": "basically keep a high water mark of what have we not compacted right so you have this high water mark of okay these are",
    "start": "7071920",
    "end": "7078560"
  },
  {
    "text": "the deltas that are new that have arrived that i need to merge and create this new read optimized view of the table via",
    "start": "7078560",
    "end": "7084960"
  },
  {
    "text": "compaction and amongst those deltas um we actually go through a distributed",
    "start": "7084960",
    "end": "7090719"
  },
  {
    "text": "hashing process first so it's a multi-step kind of map and reduces sort of process that's been",
    "start": "7090719",
    "end": "7096639"
  },
  {
    "text": "optimized for data catalogs with this delta change log structure",
    "start": "7096639",
    "end": "7103119"
  },
  {
    "text": "and yeah we start basically by hashing all these deltas across the ray cluster",
    "start": "7103119",
    "end": "7109360"
  },
  {
    "text": "into different hash buckets and each hash bucket then is is allocated by",
    "start": "7109360",
    "end": "7114560"
  },
  {
    "text": "primary key values so you would find all duplicates within the same hash bucket we try to keep them carefully sized so",
    "start": "7114560",
    "end": "7120800"
  },
  {
    "text": "that a hash bucket fits on a single node in your cluster too which is another bit of a trick there",
    "start": "7120800",
    "end": "7127040"
  },
  {
    "text": "and actually it's interesting that this process we only read the primary key columns and like sort key columns",
    "start": "7127040",
    "end": "7133199"
  },
  {
    "text": "um so the uh we we r we read drastically less data",
    "start": "7133199",
    "end": "7139920"
  },
  {
    "text": "than like if you look at the read data set benchmarks they're lower than our merge benchmarks because read data set",
    "start": "7139920",
    "end": "7145920"
  },
  {
    "text": "is doing a full scan of the data whereas merge is just reading only the target columns that it needs",
    "start": "7145920",
    "end": "7152800"
  },
  {
    "text": "and executing the merge against those target columns and actually after the hash bucketing process it dedupes thing",
    "start": "7152800",
    "end": "7158560"
  },
  {
    "text": "and it materializes things it works in terms of record indices so it usually doesn't ever even carry around the full",
    "start": "7158560",
    "end": "7164719"
  },
  {
    "text": "record data from the columns it does pull it just understands i need to keep the row at index 100 the row at index",
    "start": "7164719",
    "end": "7171840"
  },
  {
    "text": "500 so on and so forth um but yeah there's a three-step parallel",
    "start": "7171840",
    "end": "7177599"
  },
  {
    "text": "process that i basically would call it a high-level hash bucket dedupe and materialize that it goes through that i",
    "start": "7177599",
    "end": "7184400"
  },
  {
    "text": "explain more in that presentation brilliant what is the frequency of data compaction i mean do you do",
    "start": "7184400",
    "end": "7191440"
  },
  {
    "text": "this depend on at the time when the the the changelog has reached a certain",
    "start": "7191440",
    "end": "7197360"
  },
  {
    "text": "terabyte or or gigabyte file and you want to do that or you actually do that on a regular basis or you can actually",
    "start": "7197360",
    "end": "7203920"
  },
  {
    "text": "have data catalog programmatically on a nightly basis do the compaction and then recreate indices and all that how how",
    "start": "7203920",
    "end": "7211599"
  },
  {
    "text": "how frequently you do do the compaction so um it's run asynchronously in",
    "start": "7211599",
    "end": "7218080"
  },
  {
    "text": "practice right now in response to table loads being completed so what happens right now is we'll load a table",
    "start": "7218080",
    "end": "7224239"
  },
  {
    "text": "the maximum frequency i think we typically allow table loads is once every five minutes for these large",
    "start": "7224239",
    "end": "7229520"
  },
  {
    "text": "tables in particular and so maybe once every five minutes you may kick off this asynchronous compaction job which will",
    "start": "7229520",
    "end": "7236239"
  },
  {
    "text": "pick up the deltas and create this read optimized view so in practice i'd say",
    "start": "7236239",
    "end": "7243119"
  },
  {
    "text": "least frequent is monthly those ones can get a little scary actually most frequent is usually about once every",
    "start": "7243119",
    "end": "7248639"
  },
  {
    "text": "five minutes and one final question which product at aws you use in delta",
    "start": "7248639",
    "end": "7255599"
  },
  {
    "text": "cad well we actually don't uh necessarily use it inside of an aws",
    "start": "7255599",
    "end": "7263599"
  },
  {
    "text": "product right now we're actually using it on at amazon uh",
    "start": "7263599",
    "end": "7269280"
  },
  {
    "text": "kind of internally outside of the scope of aws so amazon has an internal data catalog that it uses to keep track of",
    "start": "7269280",
    "end": "7276239"
  },
  {
    "text": "well everything's going everything going on in the world of amazon and um that's primarily where we're",
    "start": "7276239",
    "end": "7283280"
  },
  {
    "text": "using it right now so we're primarily focused on internal customers right now um",
    "start": "7283280",
    "end": "7289360"
  },
  {
    "text": "but you know we're aws always keeps track of what customers want of course",
    "start": "7289360",
    "end": "7294960"
  },
  {
    "text": "and so i'm sure uh if there's enough demand for having something like this and good ray",
    "start": "7294960",
    "end": "7300000"
  },
  {
    "text": "integration with aws products they will certainly be sensitive to hearing that and",
    "start": "7300000",
    "end": "7307679"
  },
  {
    "text": "seeing what they can do well thank you very much i think we're just about five minutes over time uh",
    "start": "7307679",
    "end": "7313280"
  },
  {
    "text": "patrick alex clark uh uh jarrah and",
    "start": "7313280",
    "end": "7318480"
  },
  {
    "text": "and everyone who was actually uh gave a talk to the including robert thank you for answering the question",
    "start": "7318480",
    "end": "7324400"
  },
  {
    "text": "both live as well as the questions on the q a typing in we do thank you all of",
    "start": "7324400",
    "end": "7330080"
  },
  {
    "text": "you for for sharing your your experiences with us and we want to thank all the attendees who actually came up",
    "start": "7330080",
    "end": "7335760"
  },
  {
    "text": "uh and attended and gave two hours if you dedicate a time um instead of having dinner with the family or having a pint",
    "start": "7335760",
    "end": "7342000"
  },
  {
    "text": "of the pub you're out there geeking yourself so we do appreciate that um",
    "start": "7342000",
    "end": "7347280"
  },
  {
    "text": "we'll keep you posted on the the video we're gonna share that with you we're going to share the all the questions",
    "start": "7347280",
    "end": "7352719"
  },
  {
    "text": "answered in the separate document we'll put that on the um on the link and then uh thanks a lot for coming and",
    "start": "7352719",
    "end": "7359199"
  },
  {
    "text": "stay tuned for more of these meetups in the in the coming coming months we'll have more dedicated",
    "start": "7359199",
    "end": "7365440"
  },
  {
    "text": "talks on the library native libraries of ray and so stay tuned and thanks a lot for joining us and be safe and we'll see",
    "start": "7365440",
    "end": "7372320"
  },
  {
    "text": "you in a month or so cheers",
    "start": "7372320",
    "end": "7377400"
  }
]
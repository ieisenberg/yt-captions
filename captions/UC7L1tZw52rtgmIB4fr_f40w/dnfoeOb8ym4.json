[
  {
    "text": "how's it going uh we're we're with I'm I'm Jason with arise uh arise AI we do",
    "start": "3240",
    "end": "8480"
  },
  {
    "text": "observability and evaluation we're one of the leaders in this vertical um I think we probably you know as a as a",
    "start": "8480",
    "end": "15120"
  },
  {
    "text": "leader in kind of observability and evaluation I I do think we've probably seen more um more AI in production than",
    "start": "15120",
    "end": "21880"
  },
  {
    "text": "than most other companies um this is kind of what we do bread and butter all day uh and and with that we've also have",
    "start": "21880",
    "end": "28679"
  },
  {
    "text": "our our own assistant our own co-pilot our own kind of AI integrated in product so um tons and tons of experience is",
    "start": "28679",
    "end": "34480"
  },
  {
    "text": "what what I'm going to talk to you about um through through customers that range from you know Trip Advisor to um Price",
    "start": "34480",
    "end": "41399"
  },
  {
    "text": "Line to bookings um you know top top ml teams in the world um top Enterprises the world use our use our software",
    "start": "41399",
    "end": "49079"
  },
  {
    "text": "um this is uh you know starting at the highest level this is I would say the year of Agents um there's an incredible",
    "start": "49079",
    "end": "55960"
  },
  {
    "text": "set of of Frameworks that have come out so there's uh people I would say most most people actually are if you look in",
    "start": "55960",
    "end": "61519"
  },
  {
    "text": "the last 12 months started without Frameworks so you don't need a framework to build an agent first off uh and and",
    "start": "61519",
    "end": "67439"
  },
  {
    "text": "maybe that's not the first thing to jump to but there's a lot of Frameworks now so uh Lane chain has uh Lane graph",
    "start": "67439",
    "end": "73640"
  },
  {
    "text": "obviously um L index has workflows now you've got crew you've got uh I'd be",
    "start": "73640",
    "end": "79119"
  },
  {
    "text": "remiss to not mention um autogen from from Microsoft so a lot of Frameworks to help you build these um but most of what",
    "start": "79119",
    "end": "86159"
  },
  {
    "text": "I see in production actually is not not a framework um on the right right side what's powering this really if I would",
    "start": "86159",
    "end": "92840"
  },
  {
    "text": "you know the most basic the most basic feature within uh the the models is",
    "start": "92840",
    "end": "98520"
  },
  {
    "text": "function calling so the ubiquitousness of function calling now across the llms",
    "start": "98520",
    "end": "103600"
  },
  {
    "text": "is really really powering what I would say most of these agents look like um I'm going to start off with what I see",
    "start": "103600",
    "end": "109759"
  },
  {
    "text": "in production uh and and this is really you know you're going to see really",
    "start": "109759",
    "end": "115799"
  },
  {
    "text": "complicated uh you know framework diagrams but but really most customers I",
    "start": "115799",
    "end": "120920"
  },
  {
    "text": "see today are are doing something pretty simple they have what's called an llm router um a quick survey the room how",
    "start": "120920",
    "end": "128039"
  },
  {
    "text": "many of you have heard of LM you know the LM routing function LM routers",
    "start": "128039",
    "end": "133120"
  },
  {
    "text": "okay okay it's decent decent number get um so what what the router does is it it",
    "start": "133120",
    "end": "141080"
  },
  {
    "text": "it actually helps route uh looks at like the intent of the conversation and helps it write route to the right skill or",
    "start": "141080",
    "end": "147480"
  },
  {
    "text": "task um it uses typically function calling function calling from a a model",
    "start": "147480",
    "end": "153120"
  },
  {
    "text": "um but I've seen I've seen actually more complicated versions from some of our customers that uh that that kind of",
    "start": "153120",
    "end": "159319"
  },
  {
    "text": "build their own function calling into it so either way you're trying to route to a skill um and and that skill you know",
    "start": "159319",
    "end": "166360"
  },
  {
    "text": "when I say function calling doesn't necessarily need to just be a uh a call to code uh many customers actually have",
    "start": "166360",
    "end": "175200"
  },
  {
    "text": "a routing of a skill to to maybe another llm call so you can have a set of LM calls calls that actually do something",
    "start": "175200",
    "end": "181800"
  },
  {
    "text": "um in in your flow and then you typically route back to the router so it's this iterative flow that goes from",
    "start": "181800",
    "end": "187799"
  },
  {
    "text": "router to some amount of branching skill to back to the router now now this is",
    "start": "187799",
    "end": "193159"
  },
  {
    "text": "maybe the simplest form of an agent simplest form of an assistant there's there's routing and there's some processing of branching um and when you",
    "start": "193159",
    "end": "200640"
  },
  {
    "text": "say well what is an agent what you'll get all these fancy terms um I I really what it is is you have an llm here",
    "start": "200640",
    "end": "207319"
  },
  {
    "text": "making some intent decision and then some processing in a simplest Branch form now you can get much more",
    "start": "207319",
    "end": "213360"
  },
  {
    "text": "complicated than this but this is probably 90% of what I see deployed today it looks something like this an",
    "start": "213360",
    "end": "219760"
  },
  {
    "text": "assistant has maybe a router a skill and then you go back to the input again",
    "start": "219760",
    "end": "225959"
  },
  {
    "text": "router skill back to input this is like 90% of what I see um now you can get",
    "start": "225959",
    "end": "232159"
  },
  {
    "text": "much more complicated what what happens inside that skill you can do like you know three llm calls you can do you know",
    "start": "232159",
    "end": "237920"
  },
  {
    "text": "complicated platform and API calls you can do a lot there but this is probably what what I see most of um and so uh so",
    "start": "237920",
    "end": "246159"
  },
  {
    "text": "so yeah first note is don't get lost and all those big Lan Lan graph kind of no drawings like you know this this is this",
    "start": "246159",
    "end": "252360"
  },
  {
    "text": "is working for a lot of people super simple um and and then some of these",
    "start": "252360",
    "end": "257759"
  },
  {
    "text": "there's there some of these um examples as you get more complicated actually have some state so maybe I have a skill",
    "start": "257759",
    "end": "264320"
  },
  {
    "text": "that processes data or does AI search across data and then I'm saving that state off those results um and then some",
    "start": "264320",
    "end": "272080"
  },
  {
    "text": "other skill down the way might use those results so there's typically some state or memory used that spans um uh the",
    "start": "272080",
    "end": "280000"
  },
  {
    "text": "these stages so this is kind of the um this is the the most basic form of",
    "start": "280000",
    "end": "285680"
  },
  {
    "text": "assistant or agents that I'm seeing out there um what you know my my the point",
    "start": "285680",
    "end": "291840"
  },
  {
    "text": "of this is is um there's you know I was kind of hinted at before there's kind of state that kind of feeds these these",
    "start": "291840",
    "end": "297600"
  },
  {
    "text": "skills and and so one of the I I've seen some examples where a skill such as AI",
    "start": "297600",
    "end": "303240"
  },
  {
    "text": "search might use up the entire context memory um and and so there's some small result that you want to save off that",
    "start": "303240",
    "end": "309720"
  },
  {
    "text": "that some other thing wants to use down the way you can't you know you can't just save off the entire set of um calls",
    "start": "309720",
    "end": "316680"
  },
  {
    "text": "in message in a a message bus so State ends up being important um and and then",
    "start": "316680",
    "end": "322680"
  },
  {
    "text": "as you look at this um as you start to create these agents and you start to create these assistants uh it's with a",
    "start": "322680",
    "end": "329919"
  },
  {
    "text": "couple lines of code uh in in any of these Frameworks or even even whatever you're You Know You're Building yourself",
    "start": "329919",
    "end": "335600"
  },
  {
    "text": "um you can get an incredible number of distributed system calls so there's",
    "start": "335600",
    "end": "342240"
  },
  {
    "text": "there you know single line of a code I've seen like 50 distributed system calls in some of these Frameworks so it's just there's a lot going on under",
    "start": "342240",
    "end": "348440"
  },
  {
    "text": "the hood um the good news is most of these Frameworks if you're using a framework um have tracing callback",
    "start": "348440",
    "end": "354639"
  },
  {
    "text": "systems that platforms like arise or our Open Source Phoenix plug into to um so",
    "start": "354639",
    "end": "360800"
  },
  {
    "text": "tracing is is is part of of of Lane graph is part of um workflows and so",
    "start": "360800",
    "end": "367319"
  },
  {
    "text": "debugging these systems ends up being like okay let's collect the data first what what in the world did I call um why",
    "start": "367319",
    "end": "373080"
  },
  {
    "text": "did it make this call uh I got to collect the data first to even understand it which is what tracing um",
    "start": "373080",
    "end": "378639"
  },
  {
    "text": "does um how many of you have used like tracing in any of just general LM",
    "start": "378639",
    "end": "385960"
  },
  {
    "text": "applications okay wow that's that's not as many as I thought um so uh I I think",
    "start": "385960",
    "end": "391160"
  },
  {
    "text": "it you know I I would say it's really hard to debug most of these um you could start with Phoenix which is free and one",
    "start": "391160",
    "end": "397560"
  },
  {
    "text": "line of code and any of these Frameworks you can get tracing I'll show you it in the end but definitely pick it up um",
    "start": "397560",
    "end": "403319"
  },
  {
    "text": "it's like the open source version of of Link Smith um the exam so so what what does this",
    "start": "403319",
    "end": "410639"
  },
  {
    "text": "look like I'm going to go deeper into like what what a real real use case is and um we've SE this a lot and we've",
    "start": "410639",
    "end": "416000"
  },
  {
    "text": "seen a couple these examples in in e-commerce which is like a chat to purchase um assistant where I'm going to",
    "start": "416000",
    "end": "421720"
  },
  {
    "text": "kind of extract either trip planning information or what products you want out of your conversation and then I'm",
    "start": "421720",
    "end": "427599"
  },
  {
    "text": "going to like you know I'm I'm I'm going to allow you to either look up a product",
    "start": "427599",
    "end": "433080"
  },
  {
    "text": "or get you information back on a product and and typically these are you know maybe the end goal is is to get you to",
    "start": "433080",
    "end": "439360"
  },
  {
    "text": "purchase something at the end um but this is a you know a typical um assistant thing so there's a LM router",
    "start": "439360",
    "end": "446039"
  },
  {
    "text": "in the beginning it's trying to figure out if you're doing you know search or question answer about products um and",
    "start": "446039",
    "end": "451319"
  },
  {
    "text": "then there's some llm afterwards that's actually taking action on that so LM in the beginning routing You by function",
    "start": "451319",
    "end": "457680"
  },
  {
    "text": "calling to a skill in this case the skill could be searching an item or it",
    "start": "457680",
    "end": "462840"
  },
  {
    "text": "could be Q&A um and then an llms processing that that data and returning back to the to the router so this is",
    "start": "462840",
    "end": "469400"
  },
  {
    "text": "kind of what it looks like zoomed in um what it really looks like might look like something like this which is you",
    "start": "469400",
    "end": "476280"
  },
  {
    "text": "know there's there's a bunch of processing stages um there but again it's that simple Branch you know LM",
    "start": "476280",
    "end": "482280"
  },
  {
    "text": "router and Branch architecture um it's again great place to start you can get",
    "start": "482280",
    "end": "487639"
  },
  {
    "text": "more complicated from this but you can accomplish an incredible amount uh with with just a simple router Branch um and",
    "start": "487639",
    "end": "494599"
  },
  {
    "text": "you notice some of those branches actually you know have llm calls which are the yellow triangles and some of",
    "start": "494599",
    "end": "500560"
  },
  {
    "text": "them are just pure code I might just be pulling information from the system so I might so so in my Branch when I decide",
    "start": "500560",
    "end": "507319"
  },
  {
    "text": "to go do something from an assistant or agent perspective um I'm I'm processing",
    "start": "507319",
    "end": "512680"
  },
  {
    "text": "something it might include an llm in there or or it might not I might just be doing say product look up and feed that",
    "start": "512680",
    "end": "518320"
  },
  {
    "text": "back to the the original router um so so kind of have to talk about if we're",
    "start": "518320",
    "end": "523839"
  },
  {
    "text": "going to talk about evaluating agents I've got to talk about what what this looks like in the first place and what what problems can go on um some of the",
    "start": "523839",
    "end": "531560"
  },
  {
    "text": "common issues with with this are are did I take the right Branch uh and did I and",
    "start": "531560",
    "end": "537440"
  },
  {
    "text": "and normally when I'm going on a certain Branch like it's an intent did is did the person ask for a product information",
    "start": "537440",
    "end": "542720"
  },
  {
    "text": "on on search and I I sent them uh I sent them a different direction and then part",
    "start": "542720",
    "end": "548120"
  },
  {
    "text": "of the branch includes like parameter extraction so function calling includes what intent what direction as well as",
    "start": "548120",
    "end": "555079"
  },
  {
    "text": "the parameters to go on that Branch um how many of you know what you know parameter extraction is or or have used",
    "start": "555079",
    "end": "562000"
  },
  {
    "text": "function calling okay it's a small you know a small amount but so um so the so with",
    "start": "562000",
    "end": "568959"
  },
  {
    "text": "function calling um within within the LM router you're you're determining what direction to go and you're providing",
    "start": "568959",
    "end": "574560"
  },
  {
    "text": "some data to the branch and and that's where that can go wrong I would say the most common thing that we see at least",
    "start": "574560",
    "end": "581279"
  },
  {
    "text": "in the router stage that goes wrong is is the the extraction parameter extraction and my extracting the right data is in the right format um is is it",
    "start": "581279",
    "end": "588640"
  },
  {
    "text": "just off and formatting so uh so there's there's kind of that piece and then you're kind of broken if you if if you",
    "start": "588640",
    "end": "594720"
  },
  {
    "text": "haven't extracted it correctly um and then sometimes there's just did it get the intent right did it go the right the",
    "start": "594720",
    "end": "600720"
  },
  {
    "text": "right Branch um want to kind of also view the the",
    "start": "600720",
    "end": "606160"
  },
  {
    "text": "other you know i' be I I I want to talk about the other piece in the ecosystem there's these Frameworks that have come",
    "start": "606160",
    "end": "611240"
  },
  {
    "text": "out um salom index workflows is one lane graph is another and I view like Lane",
    "start": "611240",
    "end": "617160"
  },
  {
    "text": "graph as like you know you had chains originally and now you want Loops so let's create a graph um so so like Lane",
    "start": "617160",
    "end": "624040"
  },
  {
    "text": "graph is a natural extension of of Lane chain um it's it's you know allows you to do ative things flow control using",
    "start": "624040",
    "end": "631920"
  },
  {
    "text": "llms um uh nodes and edges is how you see the world uh Lum index workflows is",
    "start": "631920",
    "end": "638160"
  },
  {
    "text": "a competitor to that it's kind of event-based you know you can argue um our team did it basically an agent in",
    "start": "638160",
    "end": "645040"
  },
  {
    "text": "both of those three versions and code recently comparing it um I think it's on a part of my co-founders Twitter and and",
    "start": "645040",
    "end": "651880"
  },
  {
    "text": "the takeaway is like there there's pluses and negatives to each of one of these it's kind of do you want to think of the world in terms of nodes and",
    "start": "651880",
    "end": "657440"
  },
  {
    "text": "graphs Do you want to build this way um you know again most of just just putting out there most of what I see currently",
    "start": "657440",
    "end": "664279"
  },
  {
    "text": "is is actually code not not not these so new Frameworks we'll see how much they make it easier or harder or get in the",
    "start": "664279",
    "end": "670480"
  },
  {
    "text": "way um so so working so so again I I feel",
    "start": "670480",
    "end": "675920"
  },
  {
    "text": "like it's a big story of last year it's really easy to do a Twitter demo it's hard to make the stuff work um so so",
    "start": "675920",
    "end": "681279"
  },
  {
    "text": "working for your demo is is not just making it you know is performing well is is is really the the Big Challenge so um",
    "start": "681279",
    "end": "690320"
  },
  {
    "text": "what we'll talk about a little bit is kind of what how do you go from like working to to actually do doing well um",
    "start": "690320",
    "end": "698560"
  },
  {
    "text": "so how do we evaluate these these agents um the first thing you have to do is you",
    "start": "698560",
    "end": "706680"
  },
  {
    "text": "really do need to collect data like like you can't take an action you can't do anything without collecting data so you",
    "start": "706680",
    "end": "713440"
  },
  {
    "text": "need to instrument it you can instrument it um in our case what we what we do for Phoenix and R is we use open Telemetry",
    "start": "713440",
    "end": "721360"
  },
  {
    "text": "for instrumentation it's a standard uh it's it's a way of instrumenting that most people you can chat you know",
    "start": "721360",
    "end": "728440"
  },
  {
    "text": "instrumentation around it it's pretty easy to figure out um and uh and it just",
    "start": "728440",
    "end": "733959"
  },
  {
    "text": "and and then you know with us it's you're not locked into a framework so for us it's open or we believe in kind",
    "start": "733959",
    "end": "739240"
  },
  {
    "text": "of an open ecosystem um but you got to get your your data out of these Frameworks if you're using them or if",
    "start": "739240",
    "end": "745480"
  },
  {
    "text": "you're building in code youve got to instrument that and and get some visibility into to that um there's",
    "start": "745480",
    "end": "751800"
  },
  {
    "text": "there's testing so like like this these you'll get this data and you'll try to understand like where am I breaking so",
    "start": "751800",
    "end": "758120"
  },
  {
    "text": "you you want to build up test uh test around did it make the right path the routing path is the skill correct and",
    "start": "758120",
    "end": "764160"
  },
  {
    "text": "the results from the skill correct or task correct or the branch how whatever you want to name that thing um and and",
    "start": "764160",
    "end": "770040"
  },
  {
    "text": "so there there's really kind of two vows that we we seem to care about is the routing right is the skill or task you",
    "start": "770040",
    "end": "775920"
  },
  {
    "text": "know action right and then whatever breakouts occur there there's you know typically you're B",
    "start": "775920",
    "end": "781800"
  },
  {
    "text": "creating evaluators now those evaluators can be um LM as a judge or or code-based",
    "start": "781800",
    "end": "787959"
  },
  {
    "text": "eval depending upon what what what you're doing in those steps um and then it's about kind of experimenting and and",
    "start": "787959",
    "end": "794199"
  },
  {
    "text": "iterating um so this is kind of like the the big picture and we'll we'll show you a little bit around what this what this",
    "start": "794199",
    "end": "799800"
  },
  {
    "text": "looks like um a quick question here does does when I say LM as a judge evaluators",
    "start": "799800",
    "end": "805480"
  },
  {
    "text": "does most do most people kind of know that yeah yeah okay um 12 months ago that wasn't the case now now everyone's",
    "start": "805480",
    "end": "812240"
  },
  {
    "text": "uh singing the Praises um so so when I say kind of am I using",
    "start": "812240",
    "end": "819000"
  },
  {
    "text": "the right skill so so there's again the rout a routing phase there's at some spot and you could have multiple spots like in our assistant we actually have",
    "start": "819000",
    "end": "825440"
  },
  {
    "text": "multiple routers um that that uh but you at a routing stage you're just trying to know am I taking the right branch and",
    "start": "825440",
    "end": "832440"
  },
  {
    "text": "and am I extracting the right parameters so there are so from an eval perspective as you're thinking about your agent is",
    "start": "832440",
    "end": "837920"
  },
  {
    "text": "it making the right control decision is it going the right direction is it extracting the right data um so these",
    "start": "837920",
    "end": "844040"
  },
  {
    "text": "are kind of the the the you know the the biggest idea of of kind of is the llm router stage doing the right thing um",
    "start": "844040",
    "end": "851600"
  },
  {
    "text": "and then you could we we also do this this um uh component on our side around",
    "start": "851600",
    "end": "858120"
  },
  {
    "text": "uh understanding whether it's converging so this is if you have multi-step and you're iterating in some some way or",
    "start": "858120",
    "end": "863399"
  },
  {
    "text": "shape without um without the um without input flows um I would say people are",
    "start": "863399",
    "end": "869720"
  },
  {
    "text": "probably letting it be open loop these days most people have some some user input in in the middle um but if you",
    "start": "869720",
    "end": "875440"
  },
  {
    "text": "have some task or something you're trying to do there's there there's possibly a convergence component to it",
    "start": "875440",
    "end": "881120"
  },
  {
    "text": "um some assistants don't have this this some some do depending upon if you're iterating um so uh so so what does an",
    "start": "881120",
    "end": "889560"
  },
  {
    "text": "eval look like an eval typically looks something like this which is this is an element as a judge eval there's also",
    "start": "889560",
    "end": "895320"
  },
  {
    "text": "code-based evals um element as a judge eval will have some some you know some",
    "start": "895320",
    "end": "901199"
  },
  {
    "text": "information um that that's contained in a template and then some components that you're pulling from um to test um I'll",
    "start": "901199",
    "end": "909199"
  },
  {
    "text": "give you an example of of um this this so so this is so what we have is we have",
    "start": "909199",
    "end": "915759"
  },
  {
    "text": "Phoenix which is our open source offering you can start it get get on it today again it's like open source Lang Smith um and then we've got arise which",
    "start": "915759",
    "end": "923600"
  },
  {
    "text": "is our Enterprise offering which um has quite a bit more than Phoenix it's you know AI enabled in in a big big way um",
    "start": "923600",
    "end": "931519"
  },
  {
    "text": "uh so so what I'm going to show you today though is is Phoenix which is a kind of the you know shorter you know small feature but smaller feature sets",
    "start": "931519",
    "end": "938800"
  },
  {
    "text": "but but you could start on it and use it today um what typically you do is you're instrumenting your code a couple lines",
    "start": "938800",
    "end": "945160"
  },
  {
    "text": "of of code here you're instrumenting with with Phoenix Phoenix then collects the traces um and you can run evals on",
    "start": "945160",
    "end": "951360"
  },
  {
    "text": "top of them um in this case you've got uh you You' got an agent kind of each",
    "start": "951360",
    "end": "956880"
  },
  {
    "text": "each Loop here I've I've got evals um on this particular one so function",
    "start": "956880",
    "end": "962040"
  },
  {
    "text": "calling and parameter extraction are the two evals uh in this case I've kind of",
    "start": "962040",
    "end": "967199"
  },
  {
    "text": "got have explanations around what the problem is uh the user's question was about promotions and you've kind of gone",
    "start": "967199",
    "end": "973040"
  },
  {
    "text": "down a search path so the question was about you know trying to trying to get information on promotions but I've got",
    "start": "973040",
    "end": "978759"
  },
  {
    "text": "search path what typically you'll want to do is when there's a problem you'll build data sets you'll save off",
    "start": "978759",
    "end": "984160"
  },
  {
    "text": "hallucinations or problems similar to your typical LM application work um",
    "start": "984160",
    "end": "989600"
  },
  {
    "text": "those data sets tend to be what you want to test against so you end up with experiments being what you run tests",
    "start": "989600",
    "end": "996319"
  },
  {
    "text": "against and experiments can be testing on different models testing on different template versions um experiments are",
    "start": "996319",
    "end": "1002759"
  },
  {
    "text": "typically things that you want to eval thems so saving off data um in this case",
    "start": "1002759",
    "end": "1007880"
  },
  {
    "text": "I'm checking about the parameter extraction and the function calling for a bunch of cases where I'm getting it",
    "start": "1007880",
    "end": "1013120"
  },
  {
    "text": "wrong I'm trying to change my router template to maybe fix that and make sure you know with these these additional",
    "start": "1013120",
    "end": "1020079"
  },
  {
    "text": "instructions uh you know shape it and form it the right way from an intent perspective um and so it gives you an",
    "start": "1020079",
    "end": "1026959"
  },
  {
    "text": "idea of kind of how you um how you how you run how you test and how and at",
    "start": "1026959",
    "end": "1033000"
  },
  {
    "text": "least this is the the LM router stage uh of of basically understanding",
    "start": "1033000",
    "end": "1038400"
  },
  {
    "text": "performance and saving off to an experiment and then rerunning experiments for for them um from a",
    "start": "1038400",
    "end": "1044360"
  },
  {
    "text": "phoenix perspective if you want to start you know Phoenix is is you know free open source um uh easy to get started um",
    "start": "1044360",
    "end": "1053640"
  },
  {
    "text": "uh option uh please our our team lives on Stars so if you if you do use this uh",
    "start": "1053640",
    "end": "1060760"
  },
  {
    "text": "please star us um and then I did want to kind of open it up to to some some",
    "start": "1060760",
    "end": "1066200"
  },
  {
    "text": "questions from from the room um around you know agents evals Frameworks any of",
    "start": "1066200",
    "end": "1072080"
  },
  {
    "text": "the you know the topics that you you might want to",
    "start": "1072080",
    "end": "1076639"
  },
  {
    "text": "ask you define skill Define what a skill a skill yeah so so um so in in an",
    "start": "1077200",
    "end": "1086480"
  },
  {
    "text": "assistant and I would say it fits into maybe the assistant view which is normally there's a user input um you're",
    "start": "1086480",
    "end": "1093919"
  },
  {
    "text": "normally routing to some something that this this assistant can do sometimes the assistant example might be able to um",
    "start": "1093919",
    "end": "1101080"
  },
  {
    "text": "generate a SQL query and query a database or the assistant might be in our case it can actually our assistant",
    "start": "1101080",
    "end": "1106679"
  },
  {
    "text": "can help you write an eval or our assistant can actually do AI search our assistant actually can also help you",
    "start": "1106679",
    "end": "1112480"
  },
  {
    "text": "create a graph in a dashboard um so the assistant's kind of routing to a skill the skill then becomes go accomplish",
    "start": "1112480",
    "end": "1119000"
  },
  {
    "text": "this task and and and so a skill is just a branch in this kind of treat you know",
    "start": "1119000",
    "end": "1124360"
  },
  {
    "text": "really simple branching architecture of an agent so how do",
    "start": "1124360",
    "end": "1133640"
  },
  {
    "text": "yeah so so um the questions around evals and how how does it integrate into these platforms um so evals as I mentioned fit",
    "start": "1144280",
    "end": "1152559"
  },
  {
    "text": "into two categories they're either like python code which is really think of it just a test case or or an LM as a judge",
    "start": "1152559",
    "end": "1159360"
  },
  {
    "text": "eval which is LM running on on data um both of those can be run offline so think of it in Python running you know",
    "start": "1159360",
    "end": "1166159"
  },
  {
    "text": "you run it in your test environment maybe get Hub action ction runs you you run it it can also be run in our",
    "start": "1166159",
    "end": "1171880"
  },
  {
    "text": "platform so um The Rise AI Enterprise supports like um you know online evals",
    "start": "1171880",
    "end": "1178000"
  },
  {
    "text": "which is a term meaning llms run on your data as your data is ingested augmenting",
    "start": "1178000",
    "end": "1183440"
  },
  {
    "text": "that data with with kind of think of it as labels or evaluation results uh so so",
    "start": "1183440",
    "end": "1188520"
  },
  {
    "text": "most plat you know I would say there's a handful of platforms right now that support online evals where we one of them and um and and I would say everyone",
    "start": "1188520",
    "end": "1196039"
  },
  {
    "text": "who's doing this you know I use those all the all the time every day um",
    "start": "1196039",
    "end": "1203640"
  },
  {
    "text": "yeah open",
    "start": "1204840",
    "end": "1208520"
  },
  {
    "text": "does Bally ask run yeah so so on on the open source",
    "start": "1210440",
    "end": "1216720"
  },
  {
    "text": "right now it is the um the user you know you put in your key you run eval you run",
    "start": "1216720",
    "end": "1222679"
  },
  {
    "text": "eval as you as you kind of ingest data so it's um it's going to be on you who",
    "start": "1222679",
    "end": "1228039"
  },
  {
    "text": "runs the EV versus our Enterprise offering we're kind of running the eval so offline process you the data yeah",
    "start": "1228039",
    "end": "1234400"
  },
  {
    "text": "correct yeah yeah so I have a question so uh how so usually LMS Church behind",
    "start": "1234400",
    "end": "1241880"
  },
  {
    "text": "the scene is a evaluation model so how can we make consistent about the evaluation results because as I know",
    "start": "1241880",
    "end": "1248559"
  },
  {
    "text": "that it may be not very consistent and sometimes may involve the human Evo so how do you do you incorporate this",
    "start": "1248559",
    "end": "1254640"
  },
  {
    "text": "process or how do you resolve this problem yeah I mean good good question so it's a deeper question about evals um",
    "start": "1254640",
    "end": "1261000"
  },
  {
    "text": "so the question is around um how do you choose an eval model and and then how do",
    "start": "1261000",
    "end": "1266159"
  },
  {
    "text": "you incorporate kind of human feedback and how do you think about results uh so so if you look at Phoenix the open",
    "start": "1266159",
    "end": "1272919"
  },
  {
    "text": "source Library we have a bunch of tests for the templates against um handcrafted data sets and and a large set of models",
    "start": "1272919",
    "end": "1279080"
  },
  {
    "text": "so we kind of give you our recommendations I would say most of the modern models even the minis are doing",
    "start": "1279080",
    "end": "1284679"
  },
  {
    "text": "pretty good these days on on the eval test sets uh so so I think last year choosing an email",
    "start": "1284679",
    "end": "1291240"
  },
  {
    "text": "model was harder this year it's more about speed and scale and so my other",
    "start": "1291240",
    "end": "1296799"
  },
  {
    "text": "note would be a lot of these providers have generated these slms so so think of it as gp4 mini or Gemma and they're",
    "start": "1296799",
    "end": "1303840"
  },
  {
    "text": "designed really for guard rails or you like more scale for like larger scale",
    "start": "1303840",
    "end": "1309279"
  },
  {
    "text": "cost um so most teams are deciding okay do I want the flexibility of a of a GPD",
    "start": "1309279",
    "end": "1315720"
  },
  {
    "text": "40 mini or Gemma and just just do um and just iterate on on prompts with it in",
    "start": "1315720",
    "end": "1321279"
  },
  {
    "text": "those do I want do I need do do I want to kind of just just use my my large model any of those are supported by us",
    "start": "1321279",
    "end": "1327240"
  },
  {
    "text": "we just kind of give you recommendations based upon test sets um and then uh some",
    "start": "1327240",
    "end": "1333440"
  },
  {
    "text": "teams are trying to go the route of fine-tuning an eval model um I've I've seen I've seen that direction as well um",
    "start": "1333440",
    "end": "1340080"
  },
  {
    "text": "I think go you know the problem with that one is only go there if you're like really at scale and it's a it's",
    "start": "1340080",
    "end": "1345440"
  },
  {
    "text": "hallucinate you know it's hallucinations and maybe it's not going to change or I don't need to like I only need to do it",
    "start": "1345440",
    "end": "1350559"
  },
  {
    "text": "in English I don't need to do it in 500 languages like there's risks of of of that direction um but I think it's",
    "start": "1350559",
    "end": "1356840"
  },
  {
    "text": "working for a group and so eval fine tuning a model is also Direction um the",
    "start": "1356840",
    "end": "1362200"
  },
  {
    "text": "last point is is human annotation I don't think uh LM as a judge gets you away from Human annotation you got to",
    "start": "1362200",
    "end": "1368760"
  },
  {
    "text": "have that uh you need those and the last point I would put is all our evals have explanations which gives you like I",
    "start": "1368760",
    "end": "1375679"
  },
  {
    "text": "don't think you can get evals right without explanations I I really don't I I think you end up we end up using them",
    "start": "1375679",
    "end": "1381360"
  },
  {
    "text": "all the time to adjust the eval prompt because you realize okay I don't you know it said this is a bug but it's",
    "start": "1381360",
    "end": "1388600"
  },
  {
    "text": "really just missing import statements which I don't think it's a bug in code so like you you add stuff to the eval to",
    "start": "1388600",
    "end": "1394080"
  },
  {
    "text": "to make it as strong or or you know to give it the direction you want so that's what I would say human evals choose",
    "start": "1394080",
    "end": "1400640"
  },
  {
    "text": "choose a great choose a model most of the you know the minis are great these days um and then um yeah and then don't",
    "start": "1400640",
    "end": "1407720"
  },
  {
    "text": "don't forget human",
    "start": "1407720",
    "end": "1410440"
  },
  {
    "text": "so yeah kind of here's the step byep process the EV functions they tend to be",
    "start": "1415320",
    "end": "1420799"
  },
  {
    "text": "pastale functions like like insertions or are they are they",
    "start": "1420799",
    "end": "1426840"
  },
  {
    "text": "more natural language reply that gives human being guidance what Happ so so the",
    "start": "1426840",
    "end": "1432880"
  },
  {
    "text": "evals tend to be like past fail so so the evals itself tend to be like categorical and it could be you you",
    "start": "1432880",
    "end": "1438799"
  },
  {
    "text": "don't need like just pass or fail you can have a a one two three four five but",
    "start": "1438799",
    "end": "1445320"
  },
  {
    "text": "typically what I would recommend not doing and what I saw people doing last year was trying to get continuous ranges",
    "start": "1445320",
    "end": "1451240"
  },
  {
    "text": "so so most of the stuff we see is categorical small set of categories of ranges well- defined um and it's just",
    "start": "1451240",
    "end": "1457440"
  },
  {
    "text": "getting you this this you know past fail but then you get an explanation with it like",
    "start": "1457440",
    "end": "1463720"
  },
  {
    "text": "yeah yeah so for the agents that these tools are calling um yeah what is the",
    "start": "1463720",
    "end": "1469679"
  },
  {
    "text": "abstraction that you should have for example one can one can imagine that you might have a web search and you",
    "start": "1469679",
    "end": "1476799"
  },
  {
    "text": "specifically say I want Google search to be used but what if I I just decide okay",
    "start": "1476799",
    "end": "1481840"
  },
  {
    "text": "I want web search and the tool should decide which one to use like Bing or or",
    "start": "1481840",
    "end": "1487039"
  },
  {
    "text": "Google or duo or whatever so what at what layer should you handle that",
    "start": "1487039",
    "end": "1492799"
  },
  {
    "text": "evaluation should you evaluate that on the agent layer or should there be some kind of tool optimization",
    "start": "1492799",
    "end": "1498600"
  },
  {
    "text": "yeah I think I mean I think from an agent evaluation uh it's it's kind of a fancy term but it but really what it",
    "start": "1498600",
    "end": "1504840"
  },
  {
    "text": "means is is you're trying to break up evals across your system to make sure it's doing the right thing and normally",
    "start": "1504840",
    "end": "1511159"
  },
  {
    "text": "what that means is it's not just one eval set it's like I'm I'm maybe doing an evaluation for whatever routing",
    "start": "1511159",
    "end": "1516279"
  },
  {
    "text": "control flow I'm I'm doing to make sure the control flow and extractions correct I'm doing an evaluation of the branch",
    "start": "1516279",
    "end": "1522440"
  },
  {
    "text": "whatever Branch it took to make sure the results are correct if there's LMS there so I when when we say evaluations we",
    "start": "1522440",
    "end": "1527919"
  },
  {
    "text": "really mean breaking the system up and doing any eval for for the components that are doing and your your example",
    "start": "1527919",
    "end": "1533480"
  },
  {
    "text": "case I think it just comes down to is that something that's integrated into the routing and you want to happen there",
    "start": "1533480",
    "end": "1538960"
  },
  {
    "text": "is it something that you want it to happen in in a branch of the control flow so so I think it's about you mapping out your system control and and",
    "start": "1538960",
    "end": "1547120"
  },
  {
    "text": "then figuring out where you want that where you want that control to be or flexibility to be um and then and then",
    "start": "1547120",
    "end": "1554960"
  },
  {
    "text": "the evaluations just make sure it's doing the right thing on top",
    "start": "1554960",
    "end": "1560039"
  },
  {
    "text": "how do you differentiate different kinds of models and Els used in different stages of this",
    "start": "1560039",
    "end": "1567240"
  },
  {
    "text": "process mentioned evaluation expanation yeah that's coming from yeah so how do",
    "start": "1567240",
    "end": "1572760"
  },
  {
    "text": "youate that from the production model that's being used do you stamp them as different models do you use the same",
    "start": "1572760",
    "end": "1578520"
  },
  {
    "text": "model that you do you say that for the skill I don't care what model because it's a small how do youate yeah I think",
    "start": "1578520",
    "end": "1585240"
  },
  {
    "text": "I mean I I think what we've seen work while I mean I think you can get it so the the question here was like how do we",
    "start": "1585240",
    "end": "1591880"
  },
  {
    "text": "see how do we see the decisions that people should make or are making around what model to use for evals versus",
    "start": "1591880",
    "end": "1598039"
  },
  {
    "text": "production um I think that what I see as kind of easiest from most teams is like",
    "start": "1598039",
    "end": "1604600"
  },
  {
    "text": "starting with if you can start starting with the larger models and then backing down once things are working um I feel",
    "start": "1604600",
    "end": "1610600"
  },
  {
    "text": "like people backing in the other way it's you don't realize how hard it is just to get the stuff to work in the first place so I think that's kind of",
    "start": "1610600",
    "end": "1617279"
  },
  {
    "text": "what my recommend Commendation kind of is around when I'm building application",
    "start": "1617279",
    "end": "1624279"
  },
  {
    "text": "have the application somewhere elsewhere and alls are happening Y and I'm doing an EV y there are certains happening",
    "start": "1624279",
    "end": "1630520"
  },
  {
    "text": "just from the EV correct correct right so when you are generating the text for the M that's the platform correct",
    "start": "1630520",
    "end": "1639120"
  },
  {
    "text": "platform corre some else stamping of the",
    "start": "1639120",
    "end": "1644919"
  },
  {
    "text": "correct correct correct layers and layers of gold quality correct correct so you're",
    "start": "1644919",
    "end": "1651840"
  },
  {
    "text": "augmenting your data with with uh data that helps you understand its performance so uh that that's correct",
    "start": "1651840",
    "end": "1657960"
  },
  {
    "text": "and and you do you can choose different models you know again I I think a lot of",
    "start": "1657960",
    "end": "1663039"
  },
  {
    "text": "people just start off with the same the same eval model as the other one and then back out into something else that's working um",
    "start": "1663039",
    "end": "1671240"
  },
  {
    "text": "go is it done before I deploy the system or is done during run time as a test",
    "start": "1671240",
    "end": "1677919"
  },
  {
    "text": "yeah it's both actually so so um Phoenix actually has um you know a bunch of",
    "start": "1677919",
    "end": "1683880"
  },
  {
    "text": "little little helper functions for evals and code so if you just want to run in your notebook and test and and those",
    "start": "1683880",
    "end": "1689720"
  },
  {
    "text": "same functions actually work really well in like GitHub actions so if you want to go from there to cicd and then if you",
    "start": "1689720",
    "end": "1695320"
  },
  {
    "text": "want to just run an eval as data flows into our platform we we you set up a",
    "start": "1695320",
    "end": "1700519"
  },
  {
    "text": "eval job and and it just you know can take a sample of the data based on filters we we'll drop evals onto onto",
    "start": "1700519",
    "end": "1707360"
  },
  {
    "text": "data as you andj",
    "start": "1707360",
    "end": "1710120"
  },
  {
    "text": "Sy y it can so so I would say I'll show you",
    "start": "1716120",
    "end": "1721640"
  },
  {
    "text": "I'll talk to you a little I'll talk to you about our co-pilot with our assistant what we use what we use these for so a real real use case from from",
    "start": "1721640",
    "end": "1727679"
  },
  {
    "text": "what what we do um the the online evals tend to be like I just want to drop data",
    "start": "1727679",
    "end": "1732840"
  },
  {
    "text": "on my I just want to learn something new and so an example was we had some prompt injection attacks kind of like people",
    "start": "1732840",
    "end": "1739519"
  },
  {
    "text": "were trying to kind of hack our system um and I just wanted to kind of add an eval quickly to see uh to detect if if",
    "start": "1739519",
    "end": "1747200"
  },
  {
    "text": "anything similar to this was happening so I just wanted to kind of monitor it I can add and so that was kind of a pro",
    "start": "1747200",
    "end": "1752960"
  },
  {
    "text": "injection eval I was kind of I've also added stuff around frustrated users so it's kind of like I'm just adding",
    "start": "1752960",
    "end": "1759240"
  },
  {
    "text": "performance data that I want to go track um in the case of the cicd stuff which",
    "start": "1759240",
    "end": "1765000"
  },
  {
    "text": "typically is called experiments um I don't love the were to be honest like but all of us all the platforms have",
    "start": "1765000",
    "end": "1771039"
  },
  {
    "text": "landed on experiments um including us uh so in experiments in our platform it's CI it's the cicd portion of the um of",
    "start": "1771039",
    "end": "1779519"
  },
  {
    "text": "the workflow so for for experiments you you're um you're saving off data sets",
    "start": "1779519",
    "end": "1785600"
  },
  {
    "text": "you're typically running the test in like a GitHub action or offline but it's",
    "start": "1785600",
    "end": "1790799"
  },
  {
    "text": "it's it's in our customer system that are running these a lot of times it's code like you know is the location right",
    "start": "1790799",
    "end": "1796399"
  },
  {
    "text": "is you know it's just python code um and then sometimes it's an LM V that they",
    "start": "1796399",
    "end": "1801519"
  },
  {
    "text": "run too so so that's like this and that one normally is like let me make sure I didn't break anything with this new",
    "start": "1801519",
    "end": "1807320"
  },
  {
    "text": "prompt I make a change I just want to make sure these 10 use cases pass uh so it kind of helps you with your",
    "start": "1807320",
    "end": "1813159"
  },
  {
    "text": "development driven workflow so experiments kind of help you with that I was wondering I really like",
    "start": "1813159",
    "end": "1820960"
  },
  {
    "text": "you you also",
    "start": "1820960",
    "end": "1825559"
  },
  {
    "text": "TR yeah it's a good question so like when when do you you know obviously kind of span level evals are I think easier",
    "start": "1826480",
    "end": "1833200"
  },
  {
    "text": "to to think about and apply um but there's there are there are some examples C the really common one from",
    "start": "1833200",
    "end": "1839039"
  },
  {
    "text": "the customers is like a conversation level eval and the person get the question answered and did they you know",
    "start": "1839039",
    "end": "1844799"
  },
  {
    "text": "are they frustrated um so we have some examples of session level evals but they're they're just harder to you know",
    "start": "1844799",
    "end": "1851760"
  },
  {
    "text": "they're harder to run um and that you need to collect the data you know you need to collect that data um and and",
    "start": "1851760",
    "end": "1857200"
  },
  {
    "text": "then if we're running a a job it's got to you know smartly connect connect what is a session and run the eval on the",
    "start": "1857200",
    "end": "1862399"
  },
  {
    "text": "session um thank you um so I just have a",
    "start": "1862399",
    "end": "1867679"
  },
  {
    "text": "question regarding the evaluation framework of course um so say for example I don't want to use model as a",
    "start": "1867679",
    "end": "1873440"
  },
  {
    "text": "judge but instead I want to use my own Benchmark data set which consists of prompt and the root and uh the answer um",
    "start": "1873440",
    "end": "1883039"
  },
  {
    "text": "can I do that with Phoenix I just want to see how flexible it is if I can use a benchmark data set and on top of that",
    "start": "1883039",
    "end": "1890159"
  },
  {
    "text": "some human evaluation setup setting out there yeah yeah we I mean we try to make it flexible so so you can post whatever",
    "start": "1890159",
    "end": "1897039"
  },
  {
    "text": "don't need to use our eval sets or eval recommendations just post the you know post whatever scores that you want in",
    "start": "1897039",
    "end": "1902960"
  },
  {
    "text": "into the into the software and um you know check you know post your checks and we try to make it easy to find um where",
    "start": "1902960",
    "end": "1909679"
  },
  {
    "text": "whether the checks passed or not okay thank you go ahead evaluations are",
    "start": "1909679",
    "end": "1916120"
  },
  {
    "text": "assuming that ground high that it's it's golden it's correct yeah but uh in real",
    "start": "1916120",
    "end": "1922840"
  },
  {
    "text": "systems we do see that ground tooth can change like in R systems new document",
    "start": "1922840",
    "end": "1928200"
  },
  {
    "text": "version comes up new information comes up which means answer the golden answer is now changed Y in Phoenix or in arise",
    "start": "1928200",
    "end": "1935720"
  },
  {
    "text": "do you have a a way to identify that if the ingested document has changed uh",
    "start": "1935720",
    "end": "1943279"
  },
  {
    "text": "then possibly has affected a particular answer for which you know it was Prov golden ground yeah and help the user say",
    "start": "1943279",
    "end": "1951960"
  },
  {
    "text": "hey because of this new document ingested this ground Tru or these ground Tru got affected rify them",
    "start": "1951960",
    "end": "1958840"
  },
  {
    "text": "yeah yeah I don't so um so so typically we um the the question is really around",
    "start": "1958840",
    "end": "1965480"
  },
  {
    "text": "ground truth evals and production um and uh I would say I would say most of the",
    "start": "1965480",
    "end": "1971720"
  },
  {
    "text": "people that are using evals in production are using it as like a proxy like it's like a you know a gut check of",
    "start": "1971720",
    "end": "1977840"
  },
  {
    "text": "is the system working correctly um and uh and so typically you're running you",
    "start": "1977840",
    "end": "1983840"
  },
  {
    "text": "you don't totally like have ground truth like a traditional ml model you would have uh you're kind of using it as a",
    "start": "1983840",
    "end": "1989320"
  },
  {
    "text": "proxy where the ground truth was just to make sure the your your your eval was correct in the first place um there are",
    "start": "1989320",
    "end": "1996399"
  },
  {
    "text": "a lot of tools though to understand whether the data is changed and you know um the reference data is changed and uh",
    "start": "1996399",
    "end": "2002799"
  },
  {
    "text": "also to debug whether the eval is correct or not um so I would say there's a bunch of tools but not you not exactly",
    "start": "2002799",
    "end": "2009240"
  },
  {
    "text": "what what you're you're asking there",
    "start": "2009240",
    "end": "2013240"
  },
  {
    "text": "um yeah uh so is the qu the question there is is",
    "start": "2034440",
    "end": "2041120"
  },
  {
    "text": "uh sorry so test set for the follow-up questions um can you describe that again like the",
    "start": "2041120",
    "end": "2047639"
  },
  {
    "text": "are you talking about um yeah I I think I mean evals uh you",
    "start": "2047639",
    "end": "2055440"
  },
  {
    "text": "need the data present to to say whether the eval is going to be you know the eval can only look at all the data it",
    "start": "2055440",
    "end": "2062079"
  },
  {
    "text": "has and make a call on it and if you don't have the data available for it to make a correct call um it's probably not",
    "start": "2062079",
    "end": "2067878"
  },
  {
    "text": "the right proxy metric it's probably not the right place to use it um and so it's your job to kind of like figure out",
    "start": "2067879",
    "end": "2073919"
  },
  {
    "text": "what's the right data to put in the first place to be able to make this performance metric and make it correct and if you can get that data there then",
    "start": "2073919",
    "end": "2081320"
  },
  {
    "text": "you can actually do an evalve for it so um I think there's production data looks like that and then the cicd workflows",
    "start": "2081320",
    "end": "2087638"
  },
  {
    "text": "tend to be more golden data set human annotation you're kind of right you're doing that and you're making adjustments",
    "start": "2087639",
    "end": "2093960"
  },
  {
    "text": "to the evals based upon um you know your golden golden truth from",
    "start": "2093960",
    "end": "2100720"
  },
  {
    "text": "Human",
    "start": "2103160",
    "end": "2106160"
  },
  {
    "text": "yeah y well I think I think it's it's if the so there is variability in these",
    "start": "2110599",
    "end": "2117599"
  },
  {
    "text": "there you know these aren't kind of a you know these are kind of proxy performance metrics um so I think is I",
    "start": "2117599",
    "end": "2123520"
  },
  {
    "text": "think again it comes down to like how exacting do you want the the how important is your performance metric how",
    "start": "2123520",
    "end": "2129480"
  },
  {
    "text": "exacting do you want the result I think what you're you're hinting at is like I run it multiple times over a test set I get different answers um it's just a",
    "start": "2129480",
    "end": "2136000"
  },
  {
    "text": "proxy metric so that's what I you know in the end um I think view it view it as",
    "start": "2136000",
    "end": "2141720"
  },
  {
    "text": "such and and it gives you a good a good direction but well thank thank you all I",
    "start": "2141720",
    "end": "2147079"
  },
  {
    "text": "appreciate it",
    "start": "2147079",
    "end": "2150520"
  }
]
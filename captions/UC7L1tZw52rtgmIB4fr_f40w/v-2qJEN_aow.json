[
  {
    "start": "0",
    "end": "108000"
  },
  {
    "text": "all right hey guys uh nice to meet all of you you can probably see my name there it's a little hard to pronounce so",
    "start": "2600",
    "end": "9599"
  },
  {
    "text": "bear with me most people just call me K the first alphabet of my name so if it's easier we can do that today so a little",
    "start": "9599",
    "end": "16560"
  },
  {
    "text": "bit about me I'm an ml engineer at Shopify uh lead a couple of teams there",
    "start": "16560",
    "end": "22359"
  },
  {
    "text": "um I have over 12 13 years of experience in the ml space right now try to remain as domain agnostic as possible so I've",
    "start": "22359",
    "end": "29439"
  },
  {
    "text": "worked in re retail and Healthcare and adtech and yeah I've moved across a little bit so um you see the third point",
    "start": "29439",
    "end": "37760"
  },
  {
    "text": "there right it says strong believer in systems thinking uh what do I mean by that well for the most part like I think",
    "start": "37760",
    "end": "44200"
  },
  {
    "text": "there's a dichotomy that sometimes created uh where they're kind of like you can either move quickly and break",
    "start": "44200",
    "end": "49840"
  },
  {
    "text": "things or you can think a lot and you can build these well thought out structured systems that are long lasting",
    "start": "49840",
    "end": "56800"
  },
  {
    "text": "right I think my personal opinion's always been that a false dichotomy like you can do both right you can you can",
    "start": "56800",
    "end": "63239"
  },
  {
    "text": "build quick you can break things move fast the hacker culture if you will and",
    "start": "63239",
    "end": "69000"
  },
  {
    "text": "also at the same time move towards that longer term sustainable systems thinking and so that's kind of been my thing",
    "start": "69000",
    "end": "75360"
  },
  {
    "text": "throughout my entire career and uh that's led me to where I am uh right now and so that's and you're going to see a",
    "start": "75360",
    "end": "81079"
  },
  {
    "text": "lot of that in the talk that I'm going to give uh with Nicholas in the next few minutes and then dogs music video games",
    "start": "81079",
    "end": "88759"
  },
  {
    "text": "in that order never never ever ever uh change the order that in that order",
    "start": "88759",
    "end": "93840"
  },
  {
    "text": "that's how I spend my time outside of work uh and you'll actually see my dogs uh during this uh talk as well uh I",
    "start": "93840",
    "end": "101600"
  },
  {
    "text": "always promise people dogs during my during my talks so with that said uh",
    "start": "101600",
    "end": "108159"
  },
  {
    "start": "108000",
    "end": "141000"
  },
  {
    "text": "yeah Nicholas why don't you tell us a little bit about okay A little intro about me um I'm a senior ml engineer at",
    "start": "108159",
    "end": "114000"
  },
  {
    "text": "Shopify originally from Finland um I started my Tech Career at Shopify as an intern as a data science intern in 2018",
    "start": "114000",
    "end": "121439"
  },
  {
    "text": "been working on various ml products and ml Solutions like fraud detection product classification and so on uh into",
    "start": "121439",
    "end": "128520"
  },
  {
    "text": "mathematics chess playing music with other people and my co-workers and I recently got a dog and you can see the",
    "start": "128520",
    "end": "134040"
  },
  {
    "text": "picture kind of an abstract picture of my dog as well here can to pass back to",
    "start": "134040",
    "end": "139200"
  },
  {
    "text": "K thank you so here's what we're going to do today right so again I'm not going",
    "start": "139200",
    "end": "144560"
  },
  {
    "start": "141000",
    "end": "222000"
  },
  {
    "text": "to read out the entire agenda but at a at a very high level introduce you to the problem statement uh and then kind",
    "start": "144560",
    "end": "152519"
  },
  {
    "text": "of talk about like the high level why multimodal llms why how does this F this",
    "start": "152519",
    "end": "158519"
  },
  {
    "text": "problem space then we'll get into the Integrity of like actually how did we train this how did we fine tune how did",
    "start": "158519",
    "end": "164840"
  },
  {
    "text": "we create the data set that we that was required evaluation uh and that's where Ray comes in um and then we'll kind of",
    "start": "164840",
    "end": "172640"
  },
  {
    "text": "get to the fun part in my mind at least is like how do we serve this in production because everybody everybody",
    "start": "172640",
    "end": "179200"
  },
  {
    "text": "plays with l LM right like we've all tested llms but to do that at scale turns out it's much harder than what",
    "start": "179200",
    "end": "184959"
  },
  {
    "text": "most people think right and the scale we are doing it I'll give you I'll give you a rough uh teaser to this we're doing",
    "start": "184959",
    "end": "192840"
  },
  {
    "text": "about 50 to 70 million llm predictions every day right now at Shopify right",
    "start": "192840",
    "end": "198000"
  },
  {
    "text": "just for this product alone and so how do we do it at that scale that's cost effective uh and latency sensitive and",
    "start": "198000",
    "end": "205560"
  },
  {
    "text": "all of those things right and so we'll get to that and then finally we're going to end with my favorite topic ever which",
    "start": "205560",
    "end": "210840"
  },
  {
    "text": "is okay you we did all of this work how did it did it help anybody did it make anyone's life better like how how are we",
    "start": "210840",
    "end": "217159"
  },
  {
    "text": "actually helping our customers right and so that's kind of what we're going to do today so let's jump into it right so how",
    "start": "217159",
    "end": "225360"
  },
  {
    "start": "222000",
    "end": "395000"
  },
  {
    "text": "do we make sense of like what why do we need this product right well turns out",
    "start": "225360",
    "end": "230799"
  },
  {
    "text": "Shopify is really good to our merchants and what I mean by that is we allow our Merchants to customize their store any",
    "start": "230799",
    "end": "237720"
  },
  {
    "text": "way they want right so if you look at the screen in front of you right now that is typically so if you are a",
    "start": "237720",
    "end": "243079"
  },
  {
    "text": "Shopify Merchant and you were creating a product at Shopify today that's kind of the rough interface you get right so you",
    "start": "243079",
    "end": "249159"
  },
  {
    "text": "can put in any title you want any description you can add media you can add images videos 3D Graphics whatever",
    "start": "249159",
    "end": "256400"
  },
  {
    "text": "right complete flexibility complete control right turns out this is great for our Merchants because each",
    "start": "256400",
    "end": "262079"
  },
  {
    "text": "individual storefront that's created on Shopify is completely different from the very next turns out it's also terrible",
    "start": "262079",
    "end": "268120"
  },
  {
    "text": "for Shopify because we have no way to standardize anything right so if there are 10 different stores on Shopify all",
    "start": "268120",
    "end": "274199"
  },
  {
    "text": "selling the same Samsung Galaxy phone turns out we don't know that it's the same Samsung Galaxy phone because the",
    "start": "274199",
    "end": "280680"
  },
  {
    "text": "title could be different the price could be different the description so many things about it could be different and we have no way to know the merchants",
    "start": "280680",
    "end": "287479"
  },
  {
    "text": "could tell us they could give us like a gtin number or something but that's usually not done very very sparse and so",
    "start": "287479",
    "end": "293680"
  },
  {
    "text": "we have a problem where we don't know what our Merchants are selling and that makes it hard right it makes it hard for multiple reasons",
    "start": "293680",
    "end": "300400"
  },
  {
    "text": "primarily among them a like I said we don't know what our Merchants are selling right uh and that makes it",
    "start": "300400",
    "end": "306800"
  },
  {
    "text": "difficult for a couple of reasons that might not be very obvious for example taxes here in the United",
    "start": "306800",
    "end": "313240"
  },
  {
    "text": "States what how much you tax for something not just depends on what the product is it depends on where it's",
    "start": "313240",
    "end": "319000"
  },
  {
    "text": "being sold where it's being bought from it's just complicated right taxes is like a primary use case of this and then",
    "start": "319000",
    "end": "325199"
  },
  {
    "text": "there's just the usual search and Discovery and recommendation systems and all sorts of things right and so legal",
    "start": "325199",
    "end": "331560"
  },
  {
    "text": "compliance right there's so many things where it's important to know not just for us but for the merchant as well what",
    "start": "331560",
    "end": "337280"
  },
  {
    "text": "is the product that's being sold right second um again I already spoke about search and filtering we ourselves want",
    "start": "337280",
    "end": "344120"
  },
  {
    "text": "to know analytics right like end of every year we want to know hey how much did how is the market doing for clothing",
    "start": "344120",
    "end": "351039"
  },
  {
    "text": "how is the market doing for I don't know automobile parts right and so on and so for it's just it's it's important to",
    "start": "351039",
    "end": "356800"
  },
  {
    "text": "have a standardized view of the world right and so in order to do this at scale we need essentially two things",
    "start": "356800",
    "end": "363680"
  },
  {
    "text": "right one we need a well defined well understood well",
    "start": "363680",
    "end": "370440"
  },
  {
    "text": "agreed upon definition of what the world looks like right which means I need a control list of categories I need a",
    "start": "370440",
    "end": "376560"
  },
  {
    "text": "control list of other metadata around those categories right so that's number one number two is then I need some sort",
    "start": "376560",
    "end": "383880"
  },
  {
    "text": "of ml system that is able to take billions of products tens of billions of images and categorize them into that",
    "start": "383880",
    "end": "390800"
  },
  {
    "text": "space right so that is the problem statement that we're looking to solve and so this is where Nicholas comes in and",
    "start": "390800",
    "end": "397840"
  },
  {
    "start": "395000",
    "end": "533000"
  },
  {
    "text": "he's going to talk about all the great work he's been doing thank you all right so the first step to solve this problem",
    "start": "397840",
    "end": "403880"
  },
  {
    "text": "was to Define create and Define the Shopify product taxonomy so basically the Shopify product taxonomy consists of",
    "start": "403880",
    "end": "409639"
  },
  {
    "text": "two parts we have product categories which is what you might imagine um it is what kind of a product it is is it a",
    "start": "409639",
    "end": "415759"
  },
  {
    "text": "shoe is it a t-shirt so on and so forth so you can see the categories have the different levels these different varying",
    "start": "415759",
    "end": "421199"
  },
  {
    "text": "levels of granularity starting from the coarsest category to um going all the way up to a finer category that could be",
    "start": "421199",
    "end": "427800"
  },
  {
    "text": "more like specific to the product so in this example you can see that on level three we have athletic",
    "start": "427800",
    "end": "433080"
  },
  {
    "text": "shoes but on level two we have shoes and on level one we have Apper and accessories as the category so it's",
    "start": "433080",
    "end": "438560"
  },
  {
    "text": "always this hierarchical classification for products so we have this taxonomy tree so this is very useful from from",
    "start": "438560",
    "end": "445400"
  },
  {
    "text": "multiple points of view uh first of all if we are unable to classify a product in the finer grain at least we'll have",
    "start": "445400",
    "end": "450840"
  },
  {
    "text": "some kind of course classification of the product hopefully um but it also allows us to ask questions about how",
    "start": "450840",
    "end": "456080"
  },
  {
    "text": "many shoes did we sell in the last week but it also allows the user to search for athletic shoes um in our shop app",
    "start": "456080",
    "end": "462360"
  },
  {
    "text": "which is like selling products online so we can have like very specific search results but at the same time we can have",
    "start": "462360",
    "end": "468560"
  },
  {
    "text": "these higher level views into what products are selling for recommendation recommender system so on and so",
    "start": "468560",
    "end": "473680"
  },
  {
    "text": "forth on the right hand side you can see that we also have this metadata that K mentioned which we call attributes so",
    "start": "473680",
    "end": "480120"
  },
  {
    "text": "these attributes are a function of the product category so you can imagine that for different kinds of products we need",
    "start": "480120",
    "end": "486039"
  },
  {
    "text": "different kinds of metadata so for example here you can see for athletic shoes we have things like shoe fit toe",
    "start": "486039",
    "end": "492240"
  },
  {
    "text": "size Etc but we have also more generic attributes like color material and so on and so forth so for each category we",
    "start": "492240",
    "end": "500080"
  },
  {
    "text": "actually have a unique set of attributes that are attached to it so we in order to know what attributes to have for a",
    "start": "500080",
    "end": "505560"
  },
  {
    "text": "given product we first need to know the product category so you can imagine that some of the attributes that we have like",
    "start": "505560",
    "end": "511919"
  },
  {
    "text": "material can vary from product to product like t-shirts could be like cotton or polyester whereas chairs could",
    "start": "511919",
    "end": "518080"
  },
  {
    "text": "be made out of wood or metal or something like that so it's not the same values even uh within the attribute key",
    "start": "518080",
    "end": "524600"
  },
  {
    "text": "for each product so this is kind of our starting point we have defined with our product team this very structured",
    "start": "524600",
    "end": "531040"
  },
  {
    "text": "taxonomy of categories and attributes then in order to actually map",
    "start": "531040",
    "end": "536240"
  },
  {
    "text": "all the prod billions and billions of products at Shopify into this structured um taxonomy we have chosen to do a",
    "start": "536240",
    "end": "542399"
  },
  {
    "text": "two-step approach using multimodel Vision llms so you here you can see kind of a bird ey view of our flow so as K",
    "start": "542399",
    "end": "549720"
  },
  {
    "text": "mentioned we have these unstructured text fields that can contain all kinds of different things depending on the merchant they might list their variants",
    "start": "549720",
    "end": "556079"
  },
  {
    "text": "color options they might put like a lot of different details about their product like what kind of things it can do and",
    "start": "556079",
    "end": "561560"
  },
  {
    "text": "then we also have product images for those products and this is where the multimodality comes in so we have fine-tuned these llms to be able to",
    "start": "561560",
    "end": "568519"
  },
  {
    "text": "predict both the product categories and the attributes so here you can see an example we have a Shopify classic hoodie",
    "start": "568519",
    "end": "575600"
  },
  {
    "text": "the dictionary definition of cozy should be this hoodie um and first we supply",
    "start": "575600",
    "end": "580760"
  },
  {
    "text": "all the text fields and image to our fine-tuned category model and then we get a category prediction like apparal",
    "start": "580760",
    "end": "587000"
  },
  {
    "text": "and accessories clothing autoware great now that we know it's an autoware product we can go and retrieve all the",
    "start": "587000",
    "end": "593680"
  },
  {
    "text": "relevant attributes for that product so here you can see things like age group care instructions color Fab out material",
    "start": "593680",
    "end": "600680"
  },
  {
    "text": "so on and so forth then when we have that we actually Supply the same unstructured text Fields",
    "start": "600680",
    "end": "606600"
  },
  {
    "text": "the product image the predicted category as well as the allowed attributes and their values to other multimodal L fine",
    "start": "606600",
    "end": "613920"
  },
  {
    "text": "tuned llm call and which produces the product attributes so here you can see things like color would be predicted as",
    "start": "613920",
    "end": "619640"
  },
  {
    "text": "Black age group adults material polyester so on and so forth so diving a bit deeper into the",
    "start": "619640",
    "end": "626600"
  },
  {
    "start": "624000",
    "end": "818000"
  },
  {
    "text": "category predictions so this is kind of a very high level view of the flow there we have these these text Fields Title",
    "start": "626600",
    "end": "633160"
  },
  {
    "text": "description tags whatever text fields we have access to product image in this case it's a an AI generated image of a",
    "start": "633160",
    "end": "639800"
  },
  {
    "text": "smartwatch and these are passed to the category model and we have fine tuned the model to Output structure Json where",
    "start": "639800",
    "end": "646560"
  },
  {
    "text": "we have you can see the first row is product category but we actually ask the model to do a bit more than that because",
    "start": "646560",
    "end": "651880"
  },
  {
    "text": "we don't have these standardized descriptions they're also useful for various use cases for like searching products and so on and so forth we",
    "start": "651880",
    "end": "658000"
  },
  {
    "text": "generate a generated at these llm will also generate product descriptions that are standardized across all products and",
    "start": "658000",
    "end": "664320"
  },
  {
    "text": "we also ask it to generate an image description so which we can use Downstream for other use cases and this",
    "start": "664320",
    "end": "669920"
  },
  {
    "text": "actually helps the model reason about the categories better as well and here you can see we have a prediction appar and accessories jewelry",
    "start": "669920",
    "end": "677600"
  },
  {
    "text": "SmartWatches but even though we have fine-tuned the model with product categories that belong to the actual",
    "start": "677600",
    "end": "682880"
  },
  {
    "text": "taxonomy in reality it's never really that easy so the model can still hallucinate product categories that are",
    "start": "682880",
    "end": "688800"
  },
  {
    "text": "actually not part of the taxonomy at all which makes us unable to retrieve the attribute values so how do we deal with",
    "start": "688800",
    "end": "694560"
  },
  {
    "text": "these kind of cases it doesn't happen very often but it does happen so here you can see a prediction apparent",
    "start": "694560",
    "end": "699880"
  },
  {
    "text": "accessories watches smart watches so while it looks like a very solid prediction it's not actually part of the",
    "start": "699880",
    "end": "706120"
  },
  {
    "text": "taxonomy at all so how we have how we solve this is after we make this raw prediction with the llm we have this",
    "start": "706120",
    "end": "712519"
  },
  {
    "text": "step where we have created a f index of all the actual allowed category values and we used the raw prediction to search",
    "start": "712519",
    "end": "719480"
  },
  {
    "text": "the closest matching real taxonomy value so here we would actually get app xeries",
    "start": "719480",
    "end": "725320"
  },
  {
    "text": "jewelry SmartWatches from theice index it works phenomenally well and now we have the appropriate category for the",
    "start": "725320",
    "end": "731800"
  },
  {
    "text": "product so then the next step is to retrieve the attributes for that product and in the category use case you",
    "start": "731800",
    "end": "739440"
  },
  {
    "text": "might ask like why wouldn't we just supply all the allowed categories for the model to begin with the reality is",
    "start": "739440",
    "end": "745040"
  },
  {
    "text": "there's over 12,000 different categories and because they have this hierarchical nature they're extremely long they take",
    "start": "745040",
    "end": "750639"
  },
  {
    "text": "a lot of context window space so we are not able to do that uh with the current model architecture that we have but with",
    "start": "750639",
    "end": "757600"
  },
  {
    "text": "the attributes we're actually able to do that now that we know the category and we know its specific attributes but here",
    "start": "757600",
    "end": "762959"
  },
  {
    "text": "you can see kind of like how when you look at the different values and allowed values of the attributes you can see that there's still a lot of stuff that",
    "start": "762959",
    "end": "769000"
  },
  {
    "text": "the model has to pick and choose from so it's really really rich this taxonomy very similarly to the category",
    "start": "769000",
    "end": "775959"
  },
  {
    "text": "model we also Supply the text fields we Supply the image we Supply the category of the product and we Supply the",
    "start": "775959",
    "end": "781760"
  },
  {
    "text": "attributes as like here is attribute color here's the allowed values for color here's material for this product",
    "start": "781760",
    "end": "787639"
  },
  {
    "text": "these are the allowed values so on and so forth and the model is fine-tuned to again output structure Json um so here",
    "start": "787639",
    "end": "794920"
  },
  {
    "text": "you can see that the Json skis are the attribute names and the values are the attribute values are in a list because",
    "start": "794920",
    "end": "800560"
  },
  {
    "text": "there can be multiple attribute values per product so here you can see for example Smartwatch features has GPS",
    "start": "800560",
    "end": "806880"
  },
  {
    "text": "support heart rate monitor so on and so forth if you have a multicolored product it could have like the colors listed in",
    "start": "806880",
    "end": "812600"
  },
  {
    "text": "order of dominance so you can get like a very rich set of attributes per",
    "start": "812600",
    "end": "817720"
  },
  {
    "text": "product so in order to actually find them these models and to evaluate them and iterate and figure out how the",
    "start": "817720",
    "end": "823880"
  },
  {
    "start": "818000",
    "end": "948000"
  },
  {
    "text": "models are performing we needed a source of Truth data set so we needed to create this what we call a golden data set",
    "start": "823880",
    "end": "830880"
  },
  {
    "text": "luckily we had some Merchant labeled categories already so we already in our product page um had the ability for",
    "start": "830880",
    "end": "836880"
  },
  {
    "text": "merer to choose from a previous taxonomy that was kind of based off of Google product taxonomy uh so we mapped those",
    "start": "836880",
    "end": "843000"
  },
  {
    "text": "taxonomy that products from that taxonomy to our new taxonomy and looked at the merchant label categories but unfortunately we",
    "start": "843000",
    "end": "849839"
  },
  {
    "text": "discovered that Merchants are not expert in product taxonomy so they tend to mislabel their products uh quite often",
    "start": "849839",
    "end": "857399"
  },
  {
    "text": "so how did we fix this again using llms so we would again Supply the unstructured Tex Fields image and a",
    "start": "857399",
    "end": "864360"
  },
  {
    "text": "question is this Merchant labeled category prediction or this Merchant labeled category is this correct or",
    "start": "864360",
    "end": "869680"
  },
  {
    "text": "would you suggest that we would have something else and the model would often suggest like oh I don't think this is",
    "start": "869680",
    "end": "875160"
  },
  {
    "text": "actually correct you should maybe use this one instead and then we would have a human in the loop to verify that these",
    "start": "875160",
    "end": "880360"
  },
  {
    "text": "Corrections would be good and then they would be added to the golden set of categories and now that we have the",
    "start": "880360",
    "end": "885680"
  },
  {
    "text": "categories we can make category specific prompts where we actually populate all the allowed attributes and their values",
    "start": "885680",
    "end": "891600"
  },
  {
    "text": "and again Ask an llm what are the attributes of this product after human in the loop we have golden set",
    "start": "891600",
    "end": "897480"
  },
  {
    "text": "attributes and together they form form the taxonomy golden set so our model artifact our artifact",
    "start": "897480",
    "end": "904440"
  },
  {
    "text": "repository in general is hugging phase so this is where we keep our golden set we do have like we're adding more",
    "start": "904440",
    "end": "909800"
  },
  {
    "text": "categories to it we're adding more annotations so on and so forth this is an Ever evolving data set um but here",
    "start": "909800",
    "end": "915399"
  },
  {
    "text": "you can see that we have the categories and we have the taxonomy attributes so how does this fit into fine-tuning at a",
    "start": "915399",
    "end": "921199"
  },
  {
    "text": "high level um we formulate questions for the model from unstructured text Fields",
    "start": "921199",
    "end": "927079"
  },
  {
    "text": "using the product image and in the attribute model case we're supplying the category and the attributes and from",
    "start": "927079",
    "end": "932560"
  },
  {
    "text": "this golden set we get the answers uh and these question answer pairs are then used for fine tuning the model so to go",
    "start": "932560",
    "end": "939040"
  },
  {
    "text": "a bit deeper into detail I'm going to give the mic back to K and he's going to dive into the actual fine tuning process thanks",
    "start": "939040",
    "end": "946440"
  },
  {
    "text": "Nicholas all right so how do we find tune the model",
    "start": "946440",
    "end": "952240"
  },
  {
    "start": "948000",
    "end": "1130000"
  },
  {
    "text": "well so we use something called Sky pilot uh which is actually built on top of Ray um Sky pilot is pretty cool for",
    "start": "952240",
    "end": "960759"
  },
  {
    "text": "one reason and one reason alone in the world of not easily available gpus Sky",
    "start": "960759",
    "end": "967920"
  },
  {
    "text": "pilot gives us the ability to declaratively just like I I write like there's a yaml like that and you see",
    "start": "967920",
    "end": "973720"
  },
  {
    "text": "that on the very top there's this field that says resources and I've mentioned Cloud gcp if I remove that one line of code",
    "start": "973720",
    "end": "982040"
  },
  {
    "text": "and then I run I basically tell Sky pilot launch this it'll basically search every cloud that's available to me",
    "start": "982040",
    "end": "987720"
  },
  {
    "text": "whether it's gcp whether it's it's AWS whether it's aure maybe your own",
    "start": "987720",
    "end": "992880"
  },
  {
    "text": "kubernetes cluster somewhere right it can run and find resources for you pretty much from",
    "start": "992880",
    "end": "998759"
  },
  {
    "text": "anywhere you have access to and so what that means is I don't have to worry about I especially for fine tuning right",
    "start": "998759",
    "end": "1005399"
  },
  {
    "text": "because you're running this as a one-time thing and it's running somewhere you don't really care where it necessarily runs you just care that it",
    "start": "1005399",
    "end": "1011920"
  },
  {
    "text": "runs quickly you have the resources and so we use Sky pilot for that and so and",
    "start": "1011920",
    "end": "1018000"
  },
  {
    "text": "then again like Nicholas said hugging pH is a repository so we pull we have scripts that pull it'll Sky pilot",
    "start": "1018000",
    "end": "1024600"
  },
  {
    "text": "creates a cluster creates how many other gpus I need pull the data set from hugging phase run our fine tuning on top",
    "start": "1024600",
    "end": "1031280"
  },
  {
    "text": "of that fine tuning is basic most of you have already done it at this point and then we use weights and biases to track",
    "start": "1031280",
    "end": "1036678"
  },
  {
    "text": "our experiments right so at any given point we can kick off 5 10 15 20 of",
    "start": "1036679",
    "end": "1042520"
  },
  {
    "text": "these the only limitation is we have enough gpus across all these regions that we're searching from uh but as as",
    "start": "1042520",
    "end": "1049000"
  },
  {
    "text": "long as we have that Sky pilot can run and it'll create like our experiments run and we we get what we need right uh",
    "start": "1049000",
    "end": "1056360"
  },
  {
    "text": "and then we have to evaluate the model it's not just enough creating uh fine-tuning a model we need to evaluate",
    "start": "1056360",
    "end": "1061799"
  },
  {
    "text": "and see how good it is this is where Ray has been super helpful to us uh because",
    "start": "1061799",
    "end": "1066880"
  },
  {
    "text": "again and I'm going to talk about how we deploy in production but this remember evaluation is pre-production right like it's this is not going to run in",
    "start": "1066880",
    "end": "1072640"
  },
  {
    "text": "production or anything so I needed a way for us to like test predictions and then",
    "start": "1072640",
    "end": "1077840"
  },
  {
    "text": "calculate some sort of metric on top of it in a reasonably large scale right we're talking about a million 2 million",
    "start": "1077840",
    "end": "1084679"
  },
  {
    "text": "predictions from the llm right and so the way we would do it is we would again go back to Sky pilot to create a cluster",
    "start": "1084679",
    "end": "1090799"
  },
  {
    "text": "and like I said Sky pilot is built on top of Ray which means you still have access to the ray fundamentals we would",
    "start": "1090799",
    "end": "1097000"
  },
  {
    "text": "then use Ray uh actor pools to create and we would use SG Lang which is one of the inference Frameworks available again",
    "start": "1097000",
    "end": "1103799"
  },
  {
    "text": "that's an implementation detail VM Triton uh there's a bunch of these",
    "start": "1103799",
    "end": "1108919"
  },
  {
    "text": "things right so you could you could use all of those but essentially then use Ray actor poles to parallelize and",
    "start": "1108919",
    "end": "1115440"
  },
  {
    "text": "distribute the workload across multiple nodes and then it would batch predict on",
    "start": "1115440",
    "end": "1121080"
  },
  {
    "text": "a bunch of like known products and known inputs we get the outputs and then we calculate a bunch of metrics on top of",
    "start": "1121080",
    "end": "1127320"
  },
  {
    "text": "that right um so we do that and then we saw this right what does this mean like",
    "start": "1127320",
    "end": "1133000"
  },
  {
    "text": "how how much did using Vision llms improve our system for categories where",
    "start": "1133000",
    "end": "1140159"
  },
  {
    "text": "we actually had a previous uh multi-layer perceptron model it improved",
    "start": "1140159",
    "end": "1145600"
  },
  {
    "text": "by that much again I can't lie I'm squinting at those numbers maybe you guys can't see the actual numbers but",
    "start": "1145600",
    "end": "1151480"
  },
  {
    "text": "again remember the taxonomy is hierarchical level one all the way down to level s at every level of the",
    "start": "1151480",
    "end": "1158000"
  },
  {
    "text": "taxonomy we saw an improvement of both precision and recall remember the",
    "start": "1158000",
    "end": "1163760"
  },
  {
    "text": "taxonomy is about 12,000 or so categories 40,000 or so attribute values and so it is a difficult space to choose",
    "start": "1163760",
    "end": "1170440"
  },
  {
    "text": "from and so we're seeing those kind of jumps in uh precision and recall obviously this comes at a cost nothing's",
    "start": "1170440",
    "end": "1176440"
  },
  {
    "text": "free in life right so this is coming at the price of it used to be this tiny BT based multi-layer perceptron model",
    "start": "1176440",
    "end": "1182280"
  },
  {
    "text": "running before and now we've thrown uh 7 billion uh Vision llm at it right so",
    "start": "1182280",
    "end": "1188280"
  },
  {
    "text": "it's a much more expensive model to run but it comes at the with the benefit of that kind of improvement so when we saw",
    "start": "1188280",
    "end": "1194480"
  },
  {
    "text": "those numbers we were like yeah we need to see how we can deploy this to production yes it's going to be hard but",
    "start": "1194480",
    "end": "1199799"
  },
  {
    "text": "we need to do it so how do we do it turns out even there there was a complication right because it's not just",
    "start": "1199799",
    "end": "1206000"
  },
  {
    "start": "1200000",
    "end": "1300000"
  },
  {
    "text": "one way we needed to serve this model we needed to serve it in two different ways right on one hand there is a subset of",
    "start": "1206000",
    "end": "1212240"
  },
  {
    "text": "our users who are logging in they they go they open up their computer they log",
    "start": "1212240",
    "end": "1217400"
  },
  {
    "text": "into shopify.com and there's an admin right so they're physically clicking buttons and creating products this is",
    "start": "1217400",
    "end": "1223120"
  },
  {
    "text": "very low volume most of our products aren't created that way but it is an important uh way that Merchant are",
    "start": "1223120",
    "end": "1228799"
  },
  {
    "text": "creating and so for those users we wanted this model deployed so that it's in realtime returning prediction so if I",
    "start": "1228799",
    "end": "1235159"
  },
  {
    "text": "type iPhone 15 the model should in real time return back to the merch and saying we think this is a phone and we think",
    "start": "1235159",
    "end": "1240799"
  },
  {
    "text": "the brand is Apple and so on and so forth right so you have the real time low latency albe it low volume again",
    "start": "1240799",
    "end": "1248360"
  },
  {
    "text": "when I say low volume I'm talking one or two million predictions a day in that in that mode but like I said most of our",
    "start": "1248360",
    "end": "1254679"
  },
  {
    "text": "predictions don't come in that mode right most people who most Merchants are using apis and bulk editor and these",
    "start": "1254679",
    "end": "1260360"
  },
  {
    "text": "large volume High throughput there I care less about latency I care more about throughput right like 20 billion",
    "start": "1260360",
    "end": "1267760"
  },
  {
    "text": "20 million products are created today well I need all 20 million of them categorized and tagged with this model",
    "start": "1267760",
    "end": "1272840"
  },
  {
    "text": "right so you have these two different modes of operation so how do you serve in production again on the right hand",
    "start": "1272840",
    "end": "1279360"
  },
  {
    "text": "side you see a flow typically right now of how Merchants are creating products so you will see I'm I'm going to try to",
    "start": "1279360",
    "end": "1285679"
  },
  {
    "text": "sell the beds my dog was sleeping on so I I list my bed and immediately in the",
    "start": "1285679",
    "end": "1291440"
  },
  {
    "text": "bottom you saw that purple thing pop up that's the model predicting hey this is a dog bed and then I scroll down and",
    "start": "1291440",
    "end": "1297320"
  },
  {
    "text": "it's predicted the I guess the color and the shape and and whatnot so this is happening real time right so as the",
    "start": "1297320",
    "end": "1303080"
  },
  {
    "start": "1300000",
    "end": "1337000"
  },
  {
    "text": "merchants are typing they see this how do we deploy this well we used Nvidia Triton uh and then behind it we used LM",
    "start": "1303080",
    "end": "1310240"
  },
  {
    "text": "deploy again implementation detail right we we've tried LM deploy SG Lang VM",
    "start": "1310240",
    "end": "1315840"
  },
  {
    "text": "there's a bunch of these things and we keep changing it every few weeks when more improvements come up right uh but",
    "start": "1315840",
    "end": "1322840"
  },
  {
    "text": "essentially a python backend for NVIDIA Triton it's hosted on our kubernetes platform that we have at uh Shopify and",
    "start": "1322840",
    "end": "1330799"
  },
  {
    "text": "yeah this is serving real-time traffic uh for our Merchants right but again like I said low volume low latency right",
    "start": "1330799",
    "end": "1338400"
  },
  {
    "start": "1337000",
    "end": "1425000"
  },
  {
    "text": "now we come to the larger part right which is the high throughput high volume use case right this needed again latency",
    "start": "1338400",
    "end": "1344120"
  },
  {
    "text": "is less critical here yes I don't want it to take 24 hours 48 hours I needed in seconds if not",
    "start": "1344120",
    "end": "1350640"
  },
  {
    "text": "minutes um but this is where we're talking high volume 50 million 20 50 60",
    "start": "1350640",
    "end": "1356279"
  },
  {
    "text": "70 million products are getting created edited every day right how do you do that well we use data flow as our uh",
    "start": "1356279",
    "end": "1365120"
  },
  {
    "text": "streaming uh engine Kafka as our source and sync",
    "start": "1365120",
    "end": "1370159"
  },
  {
    "text": "right so our our Shopify core backend systems are writing into a Kafka topic saying hey guys these are the products",
    "start": "1370159",
    "end": "1376600"
  },
  {
    "text": "that need new predictions these are the updates for these predictions or these are the updates for these products data",
    "start": "1376600",
    "end": "1382640"
  },
  {
    "text": "flow reads it in uh data flow downloads the required media images or wherever",
    "start": "1382640",
    "end": "1388080"
  },
  {
    "text": "from from our CDN it then sends it over to the kubernetes platform where our",
    "start": "1388080",
    "end": "1393520"
  },
  {
    "text": "models are hosted it's the same hosting by the way it's the same backend system it's the same kubernetes cluster where we're hosting for real time except it's",
    "start": "1393520",
    "end": "1400960"
  },
  {
    "text": "optimized differently turns out for high throughput high volume you would you",
    "start": "1400960",
    "end": "1406880"
  },
  {
    "text": "overload the memory right so you overload the memory because that's where you get the most bang for your buck and",
    "start": "1406880",
    "end": "1412400"
  },
  {
    "text": "so it's just optimized differently it goes to the kubernetes system gets back a response data flow does all the",
    "start": "1412400",
    "end": "1417760"
  },
  {
    "text": "cleansing sends it back to another Kafka topic goes to its syncs so that's how we do this uh in the second mode right so",
    "start": "1417760",
    "end": "1425679"
  },
  {
    "start": "1425000",
    "end": "1485000"
  },
  {
    "text": "now let's talk about impact right how how has this been useful for us well search is already better right in the",
    "start": "1425679",
    "end": "1431720"
  },
  {
    "text": "last 2 3 months uh We've rolled out a bunch of new uh experiments in search which have made search better we've",
    "start": "1431720",
    "end": "1437640"
  },
  {
    "text": "introduced new fil filters in our shop app our recommendation systems are using it trust and safety just recently told",
    "start": "1437640",
    "end": "1444440"
  },
  {
    "text": "me they were able to identify a bunch of fraud use cases because of this and all I'm not going to like talk through every",
    "start": "1444440",
    "end": "1450559"
  },
  {
    "text": "single use case it's just enough to say that this is a foundational part of Shopify uh data infrastructure and so",
    "start": "1450559",
    "end": "1457919"
  },
  {
    "text": "yeah and the other great thing for us is merant Merchant adoption like like we like you saw in one of those slides we",
    "start": "1457919",
    "end": "1463240"
  },
  {
    "text": "make these predictions visible to our Merchants the number of merchants who not only say yes this is correct but",
    "start": "1463240",
    "end": "1468399"
  },
  {
    "text": "they'll interact with it they will accept it and then they will make it part of something they may maybe they",
    "start": "1468399",
    "end": "1473520"
  },
  {
    "text": "use these categories as definitions for how their store is organized right and so we've started seeing Merchants adopt",
    "start": "1473520",
    "end": "1479440"
  },
  {
    "text": "and make use of these things and so yeah it's been great for us to see this right uh and with that I will stop I know we",
    "start": "1479440",
    "end": "1487360"
  },
  {
    "start": "1485000",
    "end": "1844000"
  },
  {
    "text": "have about 4 and a half more minutes uh if anyone has questions",
    "start": "1487360",
    "end": "1492720"
  },
  {
    "text": "i' there's a microphone on the front",
    "start": "1492720",
    "end": "1497600"
  },
  {
    "text": "uh yeah thanks uh great talk I wonder you mentioned you um you're fine-tuning your model for these categories uh two",
    "start": "1499320",
    "end": "1506520"
  },
  {
    "text": "questions one is are you then fine-tuning a generative text modle or are you actually fine-tuning classification head on top of",
    "start": "1506520",
    "end": "1513159"
  },
  {
    "text": "it can you repeat that question are you fine-tuning basically a text generation model that outputs Json or are you",
    "start": "1513159",
    "end": "1519919"
  },
  {
    "text": "fine-tuning just a classification model on top no just a text generation it's an llm right so it just generates text uh",
    "start": "1519919",
    "end": "1526200"
  },
  {
    "text": "it generates it in a Json output and so you get essentially a text string and",
    "start": "1526200",
    "end": "1531240"
  },
  {
    "text": "that's where what Nicholas was saying sometimes the text string doesn't match exactly with a known category uh and",
    "start": "1531240",
    "end": "1537760"
  },
  {
    "text": "that's when we use the F index to map it back to a known uh known value okay thanks then the followup to this um when",
    "start": "1537760",
    "end": "1544919"
  },
  {
    "text": "we find when we uh find tun models like this we always run into overfitting especially if you have very um very",
    "start": "1544919",
    "end": "1551200"
  },
  {
    "text": "reduced use cases we run into overfitting into the basically distribution of your training data set",
    "start": "1551200",
    "end": "1557320"
  },
  {
    "text": "have you taken any steps so avoid that yeah uh so first of all like it's funny",
    "start": "1557320",
    "end": "1562360"
  },
  {
    "text": "because if you spoke to me 2 years ago and somebody asked me hey predict what category a particular product is I would",
    "start": "1562360",
    "end": "1568760"
  },
  {
    "text": "have just said it's a t-shirt right it's it's a running joke inside Shopify where if you don't know what something is it's a t-shirt right so we have an extreme",
    "start": "1568760",
    "end": "1575720"
  },
  {
    "text": "skewed distribution of the kinds of products that are being sold right so we had to take a lot of steps in order to",
    "start": "1575720",
    "end": "1581600"
  },
  {
    "text": "like stratify how you sample and like just the data set creation we had to be extremely careful so as to not introduce",
    "start": "1581600",
    "end": "1587520"
  },
  {
    "text": "any sort of weird bias in there so that's step one step two is again you just monitor your fine tuning make sure",
    "start": "1587520",
    "end": "1592960"
  },
  {
    "text": "your data set is big enough hyperparameter tune you monitor your loss curves yeah so I mean the answer is",
    "start": "1592960",
    "end": "1599120"
  },
  {
    "text": "no different for for llms than it would be for any other ml model that you f tune or you train the only difference",
    "start": "1599120",
    "end": "1606000"
  },
  {
    "text": "being llms are a lot more e it'll step into that realm of find uh overfitting a",
    "start": "1606000",
    "end": "1611799"
  },
  {
    "text": "lot more easily than any other model will right so in terms of like the",
    "start": "1611799",
    "end": "1616840"
  },
  {
    "text": "actual how do you prevent it it's not very different from any other ml model it's just it happens a lot more easily",
    "start": "1616840",
    "end": "1621919"
  },
  {
    "text": "in llms",
    "start": "1621919",
    "end": "1626120"
  },
  {
    "text": "thanks yeah so uh what kind of vision am you guys use for",
    "start": "1627480",
    "end": "1633039"
  },
  {
    "text": "font or maybe instruct Flip or what kind of yeah so we've used lava if you've",
    "start": "1633039",
    "end": "1640640"
  },
  {
    "text": "heard of that one so lava was the first one that we've tried but we're moved since to other models so we have also",
    "start": "1640640",
    "end": "1647200"
  },
  {
    "text": "we've tried five .5 um llama 3.2 and intern BL so we tried a bunch of",
    "start": "1647200",
    "end": "1655360"
  },
  {
    "text": "different ones okay so use llama to generate a title or something",
    "start": "1655360",
    "end": "1660760"
  },
  {
    "text": "category uh so right now the the model that's in production is lava right so",
    "start": "1660760",
    "end": "1666559"
  },
  {
    "text": "lava is the model that's in production but we're not stuck to one particular model right because in the space as most",
    "start": "1666559",
    "end": "1671799"
  },
  {
    "text": "of you know things are like improving every day so the way we've built the system is like it's agnostic to the",
    "start": "1671799",
    "end": "1677720"
  },
  {
    "text": "model for the most part right and I'll come back to why I said that uh so if tomorrow a new vision model comes out",
    "start": "1677720",
    "end": "1684080"
  },
  {
    "text": "and we think it's better we will try it out immediately and we'll see hey this and the reason I said for the most part",
    "start": "1684080",
    "end": "1689760"
  },
  {
    "text": "is because for inference in production there are limitations right because what we've noticed is a lot of these",
    "start": "1689760",
    "end": "1696600"
  },
  {
    "text": "Frameworks VM SG Lang uh LM deploy they're all hyper optimized for llama",
    "start": "1696600",
    "end": "1702679"
  },
  {
    "text": "based models and so when a new model let's say Microsoft 53.5 comes out from a pure accuracy precision and recall",
    "start": "1702679",
    "end": "1710000"
  },
  {
    "text": "perspective does it do better than existing llam based models most of the times yeah but then it turns out",
    "start": "1710000",
    "end": "1716080"
  },
  {
    "text": "deploying it in production is a different story because these Frameworks aren't as optimized for those models and",
    "start": "1716080",
    "end": "1721919"
  },
  {
    "text": "so the cost differential doesn't start make sense right and so it's always this balance between how how much can I",
    "start": "1721919",
    "end": "1727960"
  },
  {
    "text": "optimize this model for production versus how accurate it is on the other end okay so one more question suppose",
    "start": "1727960",
    "end": "1734480"
  },
  {
    "text": "your technology taxonomy side if add one more categories what you guys to do to",
    "start": "1734480",
    "end": "1740720"
  },
  {
    "text": "do back fing or what kind of yeah so that's a great question um so it depends",
    "start": "1740720",
    "end": "1747320"
  },
  {
    "text": "right it depends on what kind of change it is like for example let's say t-shirts was the was a terminal category",
    "start": "1747320",
    "end": "1753320"
  },
  {
    "text": "today and tomorrow we say hey let's just add Polo T-shirts and round neck",
    "start": "1753320",
    "end": "1758600"
  },
  {
    "text": "t-shirts or whatever you just add more children to an existing category then what we would do is we would go and",
    "start": "1758600",
    "end": "1764399"
  },
  {
    "text": "identify all products that were labeled as t-shirts and only predict predict for those right so whereas if let's say we",
    "start": "1764399",
    "end": "1771080"
  },
  {
    "text": "split something more fundamental let's say we introduce the completely new branch of the taxonomy then You'",
    "start": "1771080",
    "end": "1777559"
  },
  {
    "text": "probably have to go and do a full backfill right so it it is basically you'll have to look at the exact change",
    "start": "1777559",
    "end": "1783039"
  },
  {
    "text": "and then determine what portfolio or what area of your portfolio does that",
    "start": "1783039",
    "end": "1788080"
  },
  {
    "text": "change affect and then You' have to run it so it is on a Case by case basis and",
    "start": "1788080",
    "end": "1793120"
  },
  {
    "text": "then there's the Nuance that when you change categories for any products then you have to also redict predict all the",
    "start": "1793120",
    "end": "1798960"
  },
  {
    "text": "attributes because the attributes are a function of the category right so we have this flow going on where first if",
    "start": "1798960",
    "end": "1804360"
  },
  {
    "text": "the category changes then like let's say we add more of these Leaf nodes we isolated those categories we predict",
    "start": "1804360",
    "end": "1810519"
  },
  {
    "text": "human in the loop and then we predict attributes for those categories uh only after the fact so there's this whole",
    "start": "1810519",
    "end": "1816080"
  },
  {
    "text": "fixing Loop and then you have to fine-tune the models again evaluate them again and then we ship those models to",
    "start": "1816080",
    "end": "1821399"
  },
  {
    "text": "Proud so we actually have quite a lot of these kind of changes happening so it's like almost like on a bi-weekly basis we",
    "start": "1821399",
    "end": "1826960"
  },
  {
    "text": "have a new model coming up with bunch of changes the taxonomy so yeah okay thanks",
    "start": "1826960",
    "end": "1832120"
  },
  {
    "text": "no worries awesome I think we're at time uh so yeah thank you so much for everyone",
    "start": "1832120",
    "end": "1838039"
  },
  {
    "text": "uh for listening to us yeah",
    "start": "1838039",
    "end": "1842440"
  }
]
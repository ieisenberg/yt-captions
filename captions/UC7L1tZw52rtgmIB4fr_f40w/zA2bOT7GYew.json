[
  {
    "text": "I'm excited to be here and welcome everyone to this session uh today I'm",
    "start": "3440",
    "end": "8519"
  },
  {
    "text": "going to talk about like redesigning scheduling in a way to improve the cost efficiency and scale",
    "start": "8519",
    "end": "14880"
  },
  {
    "text": "so a little bit about myself my name is judging I'm currently a software engineer at NSK I'm working on record",
    "start": "14880",
    "end": "22920"
  },
  {
    "text": "with a particular focus on the scheduling part",
    "start": "22920",
    "end": "27919"
  },
  {
    "text": "so today we will go through the following outline first I will give a brief overview of rescheduling and then",
    "start": "28140",
    "end": "34800"
  },
  {
    "text": "I will talk about some unique scheduling challenges of AI applications and then I will deep dive into two AI",
    "start": "34800",
    "end": "41700"
  },
  {
    "text": "applications one is the cost efficient model serving and another large scale data pre-processing for distribution",
    "start": "41700",
    "end": "47579"
  },
  {
    "text": "training and then show how rescheduling can make them run faster and cheaper",
    "start": "47579",
    "end": "53520"
  },
  {
    "text": "finally I will conclude and talk about some Future Works that we're planning",
    "start": "53520",
    "end": "58860"
  },
  {
    "text": "so first let's talk about what race scheduling is so at a very high level uh rescheduling is finding a node to run a",
    "start": "58860",
    "end": "65820"
  },
  {
    "text": "task or architecture while satisfying the scheduling constraints",
    "start": "65820",
    "end": "71479"
  },
  {
    "text": "so let's take a look at one example so here I want to schedule a task that",
    "start": "71640",
    "end": "76860"
  },
  {
    "text": "requires our one CPU and it takes an object as an argument so by doing that this task actually",
    "start": "76860",
    "end": "83640"
  },
  {
    "text": "specifies two scheduling constraints so the first constraint is a hard",
    "start": "83640",
    "end": "88680"
  },
  {
    "text": "constraint which is the num CPU equals to one resource constraint and since it's a hard constraint the",
    "start": "88680",
    "end": "94740"
  },
  {
    "text": "node that can run this task must satisfy this constraint meaning that the node that must have at least one available",
    "start": "94740",
    "end": "102299"
  },
  {
    "text": "CPU so because of that the first node is",
    "start": "102299",
    "end": "107460"
  },
  {
    "text": "root out for scheduling considerations because it doesn't have available CPUs now",
    "start": "107460",
    "end": "113700"
  },
  {
    "text": "the second Constitution is a soft constraint so here we prefer to run the task where the object is to avoid like a",
    "start": "113700",
    "end": "121439"
  },
  {
    "text": "data transfer and a soft constraints they are nice to have or they are not to",
    "start": "121439",
    "end": "126899"
  },
  {
    "text": "be satisfied but they are not mentoring so since the only candidates to run this",
    "start": "126899",
    "end": "132480"
  },
  {
    "text": "task is node the second node and the third node and both of them are cannot satisfy this soft constraint the",
    "start": "132480",
    "end": "138720"
  },
  {
    "text": "scheduler then can is free to pick either of them to run a task so let's say in this case the third node is",
    "start": "138720",
    "end": "145260"
  },
  {
    "text": "picked to run this task so now let's look into more details uh",
    "start": "145260",
    "end": "151080"
  },
  {
    "text": "how the scheduling protocol works so again it's still the same task that's to be scheduled so the first step of the",
    "start": "151080",
    "end": "157920"
  },
  {
    "text": "scaling protocol is that the driver the application driver process will try to",
    "start": "157920",
    "end": "163500"
  },
  {
    "text": "request a worker process from the distribution scheduler of the locality favorite node so here the locality",
    "start": "163500",
    "end": "170220"
  },
  {
    "text": "favorment node is a node that actually has the objects that's needed by the task so in our case it's actually the first",
    "start": "170220",
    "end": "176340"
  },
  {
    "text": "node that you can see it has an object in its local in-memory Object Store so driver will request a worker process",
    "start": "176340",
    "end": "183420"
  },
  {
    "text": "from that node distributed scheduler so this is the first step",
    "start": "183420",
    "end": "189660"
  },
  {
    "text": "given the first node it doesn't have any available CPU resource now so it will",
    "start": "189660",
    "end": "195060"
  },
  {
    "text": "ask the driver to try another node that it syncs has a valuable resources",
    "start": "195060",
    "end": "200959"
  },
  {
    "text": "so drivers are then tries to request a workers process for another node as suggested as recommended by the first",
    "start": "202080",
    "end": "209400"
  },
  {
    "text": "node in this case let's say it's the third node since the third node has a valuable",
    "start": "209400",
    "end": "216300"
  },
  {
    "text": "resources so it can satisfy the hard constraint so it could it grants a local",
    "start": "216300",
    "end": "221459"
  },
  {
    "text": "worker process to the driver",
    "start": "221459",
    "end": "225140"
  },
  {
    "text": "after that the driver sends the task to the guarantee the worker process to actually run it",
    "start": "226739",
    "end": "233159"
  },
  {
    "text": "so this is the whole protocol of how you can schedule a task",
    "start": "233159",
    "end": "239180"
  },
  {
    "text": "so now let's look at the actual actor scheduling so actor scheduling is also very similar but with a key difference",
    "start": "239280",
    "end": "245400"
  },
  {
    "text": "that we will see later so the key difference is like instead of",
    "start": "245400",
    "end": "250920"
  },
  {
    "text": "the driver requesting the worker process directly from the DFW scheduler it",
    "start": "250920",
    "end": "256380"
  },
  {
    "text": "actually asks GCS which is a global control service a singles process that's running on the header note that manages",
    "start": "256380",
    "end": "262380"
  },
  {
    "text": "the entire kind of red cluster it asks GCS to do so this is needed so that GCS",
    "start": "262380",
    "end": "268320"
  },
  {
    "text": "can actually manage the lifecycle of actors and Implement features like detached actors so that's kind of the",
    "start": "268320",
    "end": "274560"
  },
  {
    "text": "key difference except that the remaining process are basically the same so GCS tries to",
    "start": "274560",
    "end": "280740"
  },
  {
    "text": "request a worker process from a random nodes distributed scheduler so let's say it picks node two",
    "start": "280740",
    "end": "288258"
  },
  {
    "text": "since node 2 has a valuable CPUs it can grant a local worker process to GCS",
    "start": "288900",
    "end": "295020"
  },
  {
    "text": "directly and then GCS will send the actor to the",
    "start": "295020",
    "end": "300720"
  },
  {
    "text": "grant worker process to run so this is the protocol for actual scheduling it's pretty pretty similar to",
    "start": "300720",
    "end": "307500"
  },
  {
    "text": "task once so to summarize",
    "start": "307500",
    "end": "313500"
  },
  {
    "text": "um race scheduling is basically trying to find a node to run a task or actor who are satisfying the scheduling",
    "start": "313500",
    "end": "319560"
  },
  {
    "text": "constraints so here scheduling constraints are it has kind of two types the first type of",
    "start": "319560",
    "end": "325020"
  },
  {
    "text": "scaling constraints we call it like hard constraints those are the constraints that must be satisfied in order to run",
    "start": "325020",
    "end": "331919"
  },
  {
    "text": "the task and the classical example is a resource constraint",
    "start": "331919",
    "end": "338300"
  },
  {
    "text": "and the second type of constraint what do we call like a soft constraints those are the constraints that are nice to",
    "start": "339000",
    "end": "344580"
  },
  {
    "text": "have but not mentally and the example for example is like data locality constraint",
    "start": "344580",
    "end": "351500"
  },
  {
    "text": "so another important thing is like a really use a decentralized scheduling architecture",
    "start": "352560",
    "end": "358080"
  },
  {
    "text": "so what this means like every node runs a distributed scheduler that can make the scheduling decision independently",
    "start": "358080",
    "end": "366479"
  },
  {
    "text": "and also every node has a resource views of other nodes so that if you can tell the driver like where to ask for worker",
    "start": "366479",
    "end": "373440"
  },
  {
    "text": "processes if it locally cannot satisfy the constraints",
    "start": "373440",
    "end": "378919"
  },
  {
    "text": "so this decentralized design avoids a kind of a single scheduling partner that",
    "start": "378960",
    "end": "384960"
  },
  {
    "text": "we may have with a centralized scheduler and make the basically the schedule scheduling like a horizontally scalable",
    "start": "384960",
    "end": "393740"
  },
  {
    "text": "so next let's look at the um scheduling challenges of AR applications",
    "start": "395100",
    "end": "400800"
  },
  {
    "text": "so the main challenge we will discuss in this talk is the kind of the diversity of scheduling requirements different",
    "start": "400800",
    "end": "407340"
  },
  {
    "text": "applications they have different requirements which leads to different scheduling Solutions just to give you a",
    "start": "407340",
    "end": "414240"
  },
  {
    "text": "sense so here are two AI applications like why is model serving and another is data",
    "start": "414240",
    "end": "420900"
  },
  {
    "text": "preprocessing for distributed training let's look at their requirements under the scheduling Solutions necessarily",
    "start": "420900",
    "end": "426660"
  },
  {
    "text": "later on we were discussing in more details so for model serving the first",
    "start": "426660",
    "end": "433020"
  },
  {
    "text": "requirement is like high availability which is obviously needed for online service and the solution to achieve that",
    "start": "433020",
    "end": "439259"
  },
  {
    "text": "is we want to listen to having a cross availability Zone spread scheduling",
    "start": "439259",
    "end": "445680"
  },
  {
    "text": "and the second requirement is low cost and we want to use sport instances to",
    "start": "445680",
    "end": "450840"
  },
  {
    "text": "achieve low cost while handling the sport instance preemption gracefully",
    "start": "450840",
    "end": "457039"
  },
  {
    "text": "so for the second application data preprocessing for distribution training uh the first requirement we want to",
    "start": "457680",
    "end": "462720"
  },
  {
    "text": "discuss is high throughput and we need Solutions like spreading those data pre-processing tasks and collocating",
    "start": "462720",
    "end": "469639"
  },
  {
    "text": "pre-processed data with trainers",
    "start": "469639",
    "end": "473900"
  },
  {
    "text": "and another requirement is like a high stability and we have like out of memory",
    "start": "474720",
    "end": "480419"
  },
  {
    "text": "prevention to improve the Intel system stability",
    "start": "480419",
    "end": "485180"
  },
  {
    "text": "um so because we need like different scheduling solutions to meet those kind of diverse scheduling requirements",
    "start": "487500",
    "end": "493259"
  },
  {
    "text": "already developed like several scheduling features such as like a node training or node level based schedulings",
    "start": "493259",
    "end": "499639"
  },
  {
    "text": "we will go through those features one by one in details later but this just give you a sense",
    "start": "499639",
    "end": "507740"
  },
  {
    "text": "okay so now let's Deep dive into two AI applications and show how rescheduling",
    "start": "508620",
    "end": "514200"
  },
  {
    "text": "can satisfy their unique requirements and make them run faster and cheaper so the first is the cost efficient model",
    "start": "514200",
    "end": "520860"
  },
  {
    "text": "saving application so here model serving I mean basically",
    "start": "520860",
    "end": "526860"
  },
  {
    "text": "serve like a machining machine learning models or large language models using a",
    "start": "526860",
    "end": "532500"
  },
  {
    "text": "raiser Library so it has two requirements as I'm already mentioned before so the first",
    "start": "532500",
    "end": "539279"
  },
  {
    "text": "requirement is high availability so why we need higher availability because like as an online serving system it needs to",
    "start": "539279",
    "end": "545880"
  },
  {
    "text": "run 24 7 without downtime however like Hardware failures are Norm",
    "start": "545880",
    "end": "552360"
  },
  {
    "text": "rather than exceptions as you already know and you can have like disk failures Network failures that happen every day",
    "start": "552360",
    "end": "558899"
  },
  {
    "text": "and those failures uh can kind of impact availabilities and even worse like availability Zoom",
    "start": "558899",
    "end": "566640"
  },
  {
    "text": "failures can also happen for the institution like nature disaster like earthquake or you may even have like",
    "start": "566640",
    "end": "572399"
  },
  {
    "text": "just simple human errors and we need to make sure that we still have higher availability of the system even when",
    "start": "572399",
    "end": "578700"
  },
  {
    "text": "those failure happen so the second requirement is low cost",
    "start": "578700",
    "end": "585300"
  },
  {
    "text": "um why we want to low cost because like model swimming is actually expensive especially you want to serve those like",
    "start": "585300",
    "end": "591180"
  },
  {
    "text": "large language models all right to give you one example for example um if you",
    "start": "591180",
    "end": "596399"
  },
  {
    "text": "want to serve like a llama to 70 billion models you actually requires like four a 100 gpus which is roughly around like 11",
    "start": "596399",
    "end": "603899"
  },
  {
    "text": "000 per month if you are using let's say undemanded AWS instances",
    "start": "603899",
    "end": "609480"
  },
  {
    "text": "so it's quite expensive if we can bring down the cost and you can have more users",
    "start": "609480",
    "end": "616820"
  },
  {
    "text": "so now let's see how we're scheduling can help to meet those requirements so for a model save for our model serving",
    "start": "618060",
    "end": "624540"
  },
  {
    "text": "what do we want to schedule are called like replica things are called replicas so each replica is an actor that can",
    "start": "624540",
    "end": "630600"
  },
  {
    "text": "serve as a model and you have another server application you can have multiple replicas for photo for photonics and",
    "start": "630600",
    "end": "637320"
  },
  {
    "text": "also for like horizontal scability to support like higher QPS in this example let's say we have like",
    "start": "637320",
    "end": "643740"
  },
  {
    "text": "four replicas that we want to schedule",
    "start": "643740",
    "end": "648200"
  },
  {
    "text": "so let's see how we can schedule those four replicas to meet the higher availability requirements so in order to",
    "start": "649380",
    "end": "655620"
  },
  {
    "text": "be highly available like we want to run replicas in multiple availability zones so that even though even though let's",
    "start": "655620",
    "end": "661860"
  },
  {
    "text": "say one zone is done we can still have replicas in other zones to continue serving traffic",
    "start": "661860",
    "end": "668899"
  },
  {
    "text": "so to schedule our replicas in multiple ages we need to First launch Ray nodes",
    "start": "669360",
    "end": "676260"
  },
  {
    "text": "in multiple available zones and then set the correct AC note labels so here the",
    "start": "676260",
    "end": "682380"
  },
  {
    "text": "node label is a new kind of experimental concept that's introduced to array in 2.7 and basically another label is",
    "start": "682380",
    "end": "688920"
  },
  {
    "text": "basically arbitrary key value pairs that describe a property of a node so this is",
    "start": "688920",
    "end": "694200"
  },
  {
    "text": "very much the same as like a kubernetes of the label concept so here are in our example let's say we",
    "start": "694200",
    "end": "701459"
  },
  {
    "text": "launched like three three nodes like two in US West 2A and y e us was 2B",
    "start": "701459",
    "end": "708920"
  },
  {
    "text": "so after now we have no theme on different availability zones next is to",
    "start": "709140",
    "end": "715680"
  },
  {
    "text": "like Express those replica actors across level 50 zones so we will use the node",
    "start": "715680",
    "end": "721260"
  },
  {
    "text": "level based scheduling to achieve that so in this code example we create a",
    "start": "721260",
    "end": "726540"
  },
  {
    "text": "replica actor with the node level scheduling strategy and the strategy is basically saying Hey I want to run the",
    "start": "726540",
    "end": "733500"
  },
  {
    "text": "replica on a node that's in availability Zoom Us West 2A so we will use this strategy to schedule",
    "start": "733500",
    "end": "741779"
  },
  {
    "text": "the first two replicas so as you can see they run on the first two notes because they are in Usos 2A",
    "start": "741779",
    "end": "748980"
  },
  {
    "text": "and for the last two replicas um we want to schedule them in US West to",
    "start": "748980",
    "end": "754800"
  },
  {
    "text": "be so you can see another label scheduling strategies change Libby so it's in Usos to be",
    "start": "754800",
    "end": "761720"
  },
  {
    "text": "so these two replicas they are scheduled as expected to the certain node",
    "start": "762000",
    "end": "768360"
  },
  {
    "text": "so now the replicas they are spreaded across Aziz",
    "start": "768360",
    "end": "773639"
  },
  {
    "text": "so um when let's say our Usos 2A is down we can",
    "start": "773639",
    "end": "779339"
  },
  {
    "text": "still have like two replicas in another 80s to serve traffic hence we can have a",
    "start": "779339",
    "end": "784620"
  },
  {
    "text": "higher availability through this way which is nice",
    "start": "784620",
    "end": "789959"
  },
  {
    "text": "so okay so now we achieved a higher availability now let's see how we can achieve low cost as well so the solution",
    "start": "789959",
    "end": "796920"
  },
  {
    "text": "is to use a sport instance so what are spoil instances sporting",
    "start": "796920",
    "end": "803100"
  },
  {
    "text": "instances they are actually unused capacities in the cloud and they can be like up to 90 discount compared to",
    "start": "803100",
    "end": "810120"
  },
  {
    "text": "on-demand Pro prices in AWS so it's very cheap",
    "start": "810120",
    "end": "815899"
  },
  {
    "text": "which is the thing we want to lower the cost so however like why are smaller",
    "start": "816420",
    "end": "823380"
  },
  {
    "text": "instances they are cheap um they have their drawbacks they basically have lower availabilities they",
    "start": "823380",
    "end": "829560"
  },
  {
    "text": "can be preempted at any time by the cloud provider to reclaim the capacities and the consequence is that if you have",
    "start": "829560",
    "end": "837720"
  },
  {
    "text": "any requests that currently be handled by the replicas on the preemptive Sports instance it also requires were all fair",
    "start": "837720",
    "end": "844860"
  },
  {
    "text": "so in our example let's say on the second note there's a request running on replica 2 and once the sporting instance",
    "start": "844860",
    "end": "852360"
  },
  {
    "text": "is preempted the requests were Fair which is like bad to the end serving user",
    "start": "852360",
    "end": "859040"
  },
  {
    "text": "so how can we solve this so how can we have questions how can we have the benefit of those cheap spot instances",
    "start": "860040",
    "end": "865800"
  },
  {
    "text": "without paying the kind of the low availability penalty so the solution is like handling spotted",
    "start": "865800",
    "end": "872519"
  },
  {
    "text": "intense preemption gracefully we are a feature called like node training let's",
    "start": "872519",
    "end": "878040"
  },
  {
    "text": "see how it works so basically um when like they say AWS as an example",
    "start": "878040",
    "end": "884940"
  },
  {
    "text": "it decides to preempt a spot instance it will actually send you a kind of preemption kind of notice two minutes in",
    "start": "884940",
    "end": "892440"
  },
  {
    "text": "advance to give you some time to prepare",
    "start": "892440",
    "end": "897199"
  },
  {
    "text": "so upon receiving the notice the re node will transitioning into a state called",
    "start": "897839",
    "end": "903180"
  },
  {
    "text": "black training State and this means like no new tasks and actors will be",
    "start": "903180",
    "end": "908880"
  },
  {
    "text": "scheduled onto this node because we know this node will be terminated soon",
    "start": "908880",
    "end": "914120"
  },
  {
    "text": "so while the snow is in the draining State Reserve will actually wait until all the existing requests on the",
    "start": "914940",
    "end": "921480"
  },
  {
    "text": "training node to finish in the meantime it will guarantee that for all the new coming requests they",
    "start": "921480",
    "end": "928680"
  },
  {
    "text": "won't be routed to the replicas that's on the training node",
    "start": "928680",
    "end": "933500"
  },
  {
    "text": "now let's say after a while all the ongoing requests on the training nodes have finished",
    "start": "934560",
    "end": "940639"
  },
  {
    "text": "the next racer will stop in our case replica 2 that's or that's",
    "start": "941699",
    "end": "946980"
  },
  {
    "text": "honor of rainy node and it restarted it somewhere else since rescheduling guarantee that no new",
    "start": "946980",
    "end": "952740"
  },
  {
    "text": "tasks and actors can be scheduled onto the journey node so the replica 2 actor ends up being scheduled onto the first",
    "start": "952740",
    "end": "959339"
  },
  {
    "text": "node and then finally let's say after two minutes the node is terminated by AWS",
    "start": "959339",
    "end": "966839"
  },
  {
    "text": "but the scenes that we have like finished all the ongoing requests on this node and migrated of all the",
    "start": "966839",
    "end": "973019"
  },
  {
    "text": "existing replicas so no new requests or no requests were fair when we terminate",
    "start": "973019",
    "end": "978360"
  },
  {
    "text": "node 2 which is good what do we want",
    "start": "978360",
    "end": "983720"
  },
  {
    "text": "so just give you a graph so this graph shows like what happens if we don't have this grids for for the intense",
    "start": "984899",
    "end": "991139"
  },
  {
    "text": "preemption feature so this grant shows like the number of further requests over time the x-axis is a term and the y-axis",
    "start": "991139",
    "end": "999240"
  },
  {
    "text": "is the total number of failed requests as you can see initially it starts like button it starts with zero basically you",
    "start": "999240",
    "end": "1006079"
  },
  {
    "text": "don't have NFL requests but once supported instant preemption happens you can see like a bunch of requests",
    "start": "1006079",
    "end": "1011899"
  },
  {
    "text": "actually Fair so in contrast if we enable the resource",
    "start": "1011899",
    "end": "1018800"
  },
  {
    "text": "body and preemption feature you can see the number of further requests Remains the error even though when spotting",
    "start": "1018800",
    "end": "1024798"
  },
  {
    "text": "instant preemption happens",
    "start": "1024799",
    "end": "1028058"
  },
  {
    "text": "so to recap for model serving we Implement our cross AZ spread scheduling",
    "start": "1030380",
    "end": "1036319"
  },
  {
    "text": "for high availability requirements and the scheduling feature we are using is like another level based scheduling",
    "start": "1036319",
    "end": "1043819"
  },
  {
    "text": "and we also Implement a great Sports for the instance preemption for low cost so allow you to safely use sporty instance",
    "start": "1043819",
    "end": "1051200"
  },
  {
    "text": "through the node training feature the second application in our I want to",
    "start": "1051200",
    "end": "1057140"
  },
  {
    "text": "talk next is a large-scale data preprocessing for distribution so this diagram shows the high level of",
    "start": "1057140",
    "end": "1064160"
  },
  {
    "text": "data processing for distribution training so here there are two array libraries that's involved so we use rate",
    "start": "1064160",
    "end": "1070039"
  },
  {
    "text": "data to load and pre-process training data and then use the rate Trend to actually",
    "start": "1070039",
    "end": "1076100"
  },
  {
    "text": "train the model on gpus so there are two requirements we want to",
    "start": "1076100",
    "end": "1081860"
  },
  {
    "text": "achieve so the first requirement is high throughput while Wi-Fi throughput is needed because like",
    "start": "1081860",
    "end": "1088039"
  },
  {
    "text": "nowadays like training data volume is huge it can be like terabytes or petabytes so higher throughput is",
    "start": "1088039",
    "end": "1094160"
  },
  {
    "text": "basically a must-have if you want to finish your pre-process within a written amount",
    "start": "1094160",
    "end": "1099500"
  },
  {
    "text": "of time right second requirement is a high stability given the data volume at",
    "start": "1099500",
    "end": "1105500"
  },
  {
    "text": "the nature of data pre-processing it's very it's kind of a memory intensive workload so it has a higher chance of",
    "start": "1105500",
    "end": "1112039"
  },
  {
    "text": "out of memory compared to other applications and the high stability means like the",
    "start": "1112039",
    "end": "1117140"
  },
  {
    "text": "system shouldn't randomly crash or hand due to um",
    "start": "1117140",
    "end": "1122919"
  },
  {
    "text": "now let's see how race scheduling can help to meet these two requirements so here um what we want to schedule are",
    "start": "1123980",
    "end": "1131179"
  },
  {
    "text": "those like pre-processed tasks each task loads and pre-process a partition of",
    "start": "1131179",
    "end": "1136340"
  },
  {
    "text": "training data under the pre-processed data will be routed to the search training actors we call the trainers and",
    "start": "1136340",
    "end": "1143059"
  },
  {
    "text": "in this case we have let's say torch python trainers running on the gpus they are waiting for the pre-processed",
    "start": "1143059",
    "end": "1148880"
  },
  {
    "text": "training data so in order to achieve High throughput",
    "start": "1148880",
    "end": "1153919"
  },
  {
    "text": "we want to spread those pre-process tasks across nodes in the cluster follow",
    "start": "1153919",
    "end": "1159980"
  },
  {
    "text": "can load the balancing and there's a way you can do it is using",
    "start": "1159980",
    "end": "1166220"
  },
  {
    "text": "the spread scheduling so this is how you can do it in Code by specifying the spread scheduling strategy so after that",
    "start": "1166220",
    "end": "1173720"
  },
  {
    "text": "already will try to express those tasks I'm kind of in a round rubbing fashion",
    "start": "1173720",
    "end": "1178820"
  },
  {
    "text": "so let's take the one example uh so like you can see like okay so here the task one is scheduled onto the first node the",
    "start": "1178820",
    "end": "1186020"
  },
  {
    "text": "task two scheduled to this second note third task go to go back to the first node and the last task go to the second",
    "start": "1186020",
    "end": "1192620"
  },
  {
    "text": "node so as you can see like through this way a pre-process task they cannot be",
    "start": "1192620",
    "end": "1197900"
  },
  {
    "text": "spreaded across all nodes so the load is balanced",
    "start": "1197900",
    "end": "1202660"
  },
  {
    "text": "so after a pre-pre-process tasks are spreaded and executed the pre-process the data basically the output of those",
    "start": "1204980",
    "end": "1211700"
  },
  {
    "text": "pre-processed tasks is they will be saved to the local in-memory Object Store where the pre-process tasks wrong",
    "start": "1211700",
    "end": "1219679"
  },
  {
    "text": "so the next step is to Route this data to trainers so that we can",
    "start": "1219679",
    "end": "1226520"
  },
  {
    "text": "and we want to like collocate those pre-processed data with our channels",
    "start": "1226520",
    "end": "1233020"
  },
  {
    "text": "so without the clock if we don't have collocation we may route pre-processed data to the",
    "start": "1233900",
    "end": "1240140"
  },
  {
    "text": "remote trainers which will have the extra data transfer cost and the user slow which are kind of affect throughput",
    "start": "1240140",
    "end": "1247520"
  },
  {
    "text": "so these two red lines actually shows like those kind of better routines to remote channels",
    "start": "1247520",
    "end": "1255220"
  },
  {
    "text": "So to avoid this we want to use kind of the object",
    "start": "1256039",
    "end": "1261440"
  },
  {
    "text": "location information to Route those objects to the closed trainers and in",
    "start": "1261440",
    "end": "1266539"
  },
  {
    "text": "great data Implement some are special what we call like a split coordinator actor that",
    "start": "1266539",
    "end": "1273080"
  },
  {
    "text": "basically attracts the locations of all these pre-processed objects and also the locations of those touch channels and",
    "start": "1273080",
    "end": "1279679"
  },
  {
    "text": "they try to match them so that um each touch Channel receive like a local objects without any kind of data",
    "start": "1279679",
    "end": "1286760"
  },
  {
    "text": "transfer across nodes",
    "start": "1286760",
    "end": "1290260"
  },
  {
    "text": "so um now we have High throughput um let's see how we can achieve High stability through the um prevention",
    "start": "1292880",
    "end": "1299780"
  },
  {
    "text": "so let's first see why womb is bad for stability so here we have two tasks running on the",
    "start": "1299780",
    "end": "1305720"
  },
  {
    "text": "first node and let's say the task One is using like too much memory causing the",
    "start": "1305720",
    "end": "1311360"
  },
  {
    "text": "um so when um happens let's say the Linux um killer will try to like clear some",
    "start": "1311360",
    "end": "1317360"
  },
  {
    "text": "processes and to free up the memory the issue is that it's not guarantee that",
    "start": "1317360",
    "end": "1322640"
  },
  {
    "text": "the operating system will killer we are here there's like a tasker worker processes so if we are unlucky the um",
    "start": "1322640",
    "end": "1329120"
  },
  {
    "text": "killer might kill the race system processes and bring down the entire um re node or",
    "start": "1329120",
    "end": "1336020"
  },
  {
    "text": "even if you are even unlucky then it may kill the ones like the GCS process is cured uh the entire rate cluster is done",
    "start": "1336020",
    "end": "1345100"
  },
  {
    "text": "to we want to avoid that so to avoid that we develop a component called",
    "start": "1346039",
    "end": "1351080"
  },
  {
    "text": "memory monitor which is essentially an application Level home killer that kicks in before the operating system went",
    "start": "1351080",
    "end": "1358100"
  },
  {
    "text": "so it runs on each node and it can continuously monitoring the node memory usage and they try to clear tasks if the",
    "start": "1358100",
    "end": "1365179"
  },
  {
    "text": "normal memory usage is above some configured threshold before the OS women",
    "start": "1365179",
    "end": "1370820"
  },
  {
    "text": "killer kicksy so this way Ray can control like what processes through here and array has kind of the best knowledge",
    "start": "1370820",
    "end": "1376760"
  },
  {
    "text": "to pick the best one to kill so here let's say in the example task one is cute",
    "start": "1376760",
    "end": "1383419"
  },
  {
    "text": "so after task one is killed task 2 continues to run into finish and then Task 1 is retry automatically and at",
    "start": "1383419",
    "end": "1392360"
  },
  {
    "text": "this time things like there's no task 2 that's also consuming memory so Task 1 has",
    "start": "1392360",
    "end": "1398780"
  },
  {
    "text": "enough memory to run to finish so it can succeed so as you can see with our like a",
    "start": "1398780",
    "end": "1405260"
  },
  {
    "text": "memory monitor application Level umkiller the application can run",
    "start": "1405260",
    "end": "1410720"
  },
  {
    "text": "successfully without um so to recap",
    "start": "1410720",
    "end": "1417980"
  },
  {
    "text": "we spread data preprocessing tasks through the spread scheduling and",
    "start": "1417980",
    "end": "1423140"
  },
  {
    "text": "collocates our pre-processor data with trainers through the locality we are routing",
    "start": "1423140",
    "end": "1429679"
  },
  {
    "text": "both are for the high throughput requirement and for the health stability we",
    "start": "1429679",
    "end": "1435380"
  },
  {
    "text": "Implement wound prevention through the array memory monitor",
    "start": "1435380",
    "end": "1441279"
  },
  {
    "text": "so to conclude different AI applications they have a diverse scheduling",
    "start": "1443659",
    "end": "1448880"
  },
  {
    "text": "requirements and it really provides different scheduling features to meet these scheduling requirements",
    "start": "1448880",
    "end": "1455840"
  },
  {
    "text": "so in this talk we have covered like no deliverable based scheduling node training spread scheduling locality we",
    "start": "1455840",
    "end": "1463640"
  },
  {
    "text": "are routing and the ray memory monitor",
    "start": "1463640",
    "end": "1469179"
  },
  {
    "text": "so finally I want to discuss some future work that the record team is thinking about and if you have any like future",
    "start": "1470299",
    "end": "1476480"
  },
  {
    "text": "requests around like scheduling feel free to reach out to me as well",
    "start": "1476480",
    "end": "1481480"
  },
  {
    "text": "so the first thing we are thinking about is like a tent and Toleration this is I think it's a concept from kubernetes and",
    "start": "1481820",
    "end": "1488240"
  },
  {
    "text": "we want to bring in into Ray so this can be used for example to avoid to allow you to avoid running those kind of CPU",
    "start": "1488240",
    "end": "1495020"
  },
  {
    "text": "only tasks on the GPU node so you can save those GPU nodes for GPU tasks oh",
    "start": "1495020",
    "end": "1502580"
  },
  {
    "text": "the second thing we are considering is like multi-tenancy so like you can different uh as an organization you can",
    "start": "1502580",
    "end": "1509480"
  },
  {
    "text": "allow users to share a kind of single large red cluster and this should be able to like improve the hardware",
    "start": "1509480",
    "end": "1516020"
  },
  {
    "text": "utilizations and because of multi-tenancy we also",
    "start": "1516020",
    "end": "1522020"
  },
  {
    "text": "need like a stronger resource isolation so that workloads from different users they won't kind of interfere with each",
    "start": "1522020",
    "end": "1528140"
  },
  {
    "text": "other and the last is like a multi-cloud",
    "start": "1528140",
    "end": "1533179"
  },
  {
    "text": "recluster so you can have one recluster and you have nodes from different Cloud providers so that for example user",
    "start": "1533179",
    "end": "1540799"
  },
  {
    "text": "while use cases like user for example can leverage those very cheap gpus from special cloud like Lambda left or code",
    "start": "1540799",
    "end": "1548000"
  },
  {
    "text": "wave yeah so this is basically pretty much my",
    "start": "1548000",
    "end": "1555500"
  },
  {
    "text": "type and thanks for attending I think we still have some time for questions",
    "start": "1555500",
    "end": "1560740"
  },
  {
    "text": "[Applause]",
    "start": "1562300",
    "end": "1568210"
  },
  {
    "text": "thank you that was a great talk um so for the preemptable option that you put in is it also going to be",
    "start": "1576440",
    "end": "1583159"
  },
  {
    "text": "available for Google cloud service oh sorry can you repeat your question so",
    "start": "1583159",
    "end": "1588200"
  },
  {
    "text": "for the um the the preemptable option where you're actually monitoring and you get the",
    "start": "1588200",
    "end": "1593240"
  },
  {
    "text": "alert from AWS two minutes before the preemptable node gets pulled um are you gonna have is it available",
    "start": "1593240",
    "end": "1599360"
  },
  {
    "text": "for Google Cloud as well or is it just AWS currently uh for both Google Cloud",
    "start": "1599360",
    "end": "1604700"
  },
  {
    "text": "but this is the kind of currently the nsql proprietary feature but it supports both AWS and okay TCP yeah thank you",
    "start": "1604700",
    "end": "1613120"
  },
  {
    "text": "thanks for the talk uh this question and the multi-tenant C support how far is",
    "start": "1616640",
    "end": "1621860"
  },
  {
    "text": "that in your roadmap so the question about talking about the multi-tenancy support",
    "start": "1621860",
    "end": "1628400"
  },
  {
    "text": "yeah I think that's something like we are thinking and we want to like learn from other communities to see like what",
    "start": "1628400",
    "end": "1633980"
  },
  {
    "text": "their what you all have uh requirements for multinity so that we can better design it but that's something like we",
    "start": "1633980",
    "end": "1639980"
  },
  {
    "text": "are considering and then we have heard from different users they want to ask to support this but we",
    "start": "1639980",
    "end": "1645740"
  },
  {
    "text": "want to make sure we kind of collect enough requirements so that we design the right design right so that can",
    "start": "1645740",
    "end": "1651440"
  },
  {
    "text": "support like meet your kind of requirements so yeah we should definitely talk like offline hi uh have questions follow up about the",
    "start": "1651440",
    "end": "1659539"
  },
  {
    "text": "preemption notification so uh please add specific logic Down By The",
    "start": "1659539",
    "end": "1665299"
  },
  {
    "text": "Reserve or like it's also a public API exposed to the user so they can basically they can capture the signal",
    "start": "1665299",
    "end": "1672260"
  },
  {
    "text": "and do some kind of drawing logic yeah so the recall online support is generic",
    "start": "1672260",
    "end": "1678799"
  },
  {
    "text": "and Country like it basically it will provide signal to the player applications I'll tell you hey this node",
    "start": "1678799",
    "end": "1684200"
  },
  {
    "text": "now is in the training mode so you should migrate to your workload of this node So currently it's integrated with",
    "start": "1684200",
    "end": "1689720"
  },
  {
    "text": "Reserve but it can be used by other applications or your own application as well yeah so let's see if I'm running on",
    "start": "1689720",
    "end": "1695659"
  },
  {
    "text": "my custom private Cloud I have a custom node provider I do need to implement that kind of signal capture by myself",
    "start": "1695659",
    "end": "1702320"
  },
  {
    "text": "right or right yeah if it's your own cloud you need to catch it MP3",
    "start": "1702320",
    "end": "1708020"
  },
  {
    "text": "tell us hey this note will be I see I see so another question is about the note the memory monitor uh so that piece",
    "start": "1708020",
    "end": "1715400"
  },
  {
    "text": "is still also also internal pieces within the like relays right or yes it",
    "start": "1715400",
    "end": "1720620"
  },
  {
    "text": "seems very good idea so for example I probably want some kind of uh like local node monitor customer know the monitor",
    "start": "1720620",
    "end": "1727580"
  },
  {
    "text": "for example I want to check the GPU health status or like some kind of other uh PLC metric about the nodes and uh",
    "start": "1727580",
    "end": "1735140"
  },
  {
    "text": "like and they can hook up into the array relate and the related will also take that basically the more internet decide",
    "start": "1735140",
    "end": "1741559"
  },
  {
    "text": "if this node is good or not or if the process is good it's healthy or not it's going to be exposed more like customer",
    "start": "1741559",
    "end": "1747440"
  },
  {
    "text": "API for this kind of monetary yeah currently we don't expose like allow you to plug in different monitors",
    "start": "1747440",
    "end": "1753679"
  },
  {
    "text": "but there's something different we can discuss and see",
    "start": "1753679",
    "end": "1758259"
  },
  {
    "text": "this would be the last question",
    "start": "1759440",
    "end": "1762639"
  },
  {
    "text": "also great toxins I have a question about the so Three core has different type of scheduling strategies right so",
    "start": "1766340",
    "end": "1774260"
  },
  {
    "text": "um do you have anything like to Benchmark for each type of workloads which scheduling policy is the best for",
    "start": "1774260",
    "end": "1781580"
  },
  {
    "text": "that particular type of workload or you really just depends on the users to select the scheduling policy for their",
    "start": "1781580",
    "end": "1787460"
  },
  {
    "text": "own applications or any backs practices yeah so normally like um",
    "start": "1787460",
    "end": "1792980"
  },
  {
    "text": "if you are using like high level Ray libraries you don't need to deal with these scheduling scenes like it's",
    "start": "1792980",
    "end": "1798320"
  },
  {
    "text": "completely like hard from you so if you even for example you use the rate data and the retail you don't this is more like an internal internally that you",
    "start": "1798320",
    "end": "1805279"
  },
  {
    "text": "spread and look you call it a data locality aware or like security but if",
    "start": "1805279",
    "end": "1811100"
  },
  {
    "text": "you want to use record directly yeah then you need to pick let's fix your need",
    "start": "1811100",
    "end": "1816880"
  }
]
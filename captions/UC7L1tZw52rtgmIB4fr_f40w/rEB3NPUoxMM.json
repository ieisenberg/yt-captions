[
  {
    "start": "0",
    "end": "70000"
  },
  {
    "text": "hello everyone",
    "start": "1920",
    "end": "3199"
  },
  {
    "text": "my name is travis adair and thanks for",
    "start": "3199",
    "end": "5520"
  },
  {
    "text": "coming to this presentation",
    "start": "5520",
    "end": "7520"
  },
  {
    "text": "i'm from the michelangelo team at uber",
    "start": "7520",
    "end": "10559"
  },
  {
    "text": "that's our machine learning",
    "start": "10559",
    "end": "12000"
  },
  {
    "text": "platform team i'm here to tell you about",
    "start": "12000",
    "end": "14559"
  },
  {
    "text": "the recent work that",
    "start": "14559",
    "end": "16080"
  },
  {
    "text": "we've done in collaboration with the any",
    "start": "16080",
    "end": "17920"
  },
  {
    "text": "scale folks",
    "start": "17920",
    "end": "19119"
  },
  {
    "text": "to bring horvath support to rey",
    "start": "19119",
    "end": "23279"
  },
  {
    "text": "so horavad is a distributed deep",
    "start": "23279",
    "end": "25439"
  },
  {
    "text": "learning framework for",
    "start": "25439",
    "end": "26800"
  },
  {
    "text": "tensorflow pytorch and mxnet",
    "start": "26800",
    "end": "30080"
  },
  {
    "text": "it allows you to scale up your training",
    "start": "30080",
    "end": "32640"
  },
  {
    "text": "of your deep neural networks",
    "start": "32640",
    "end": "34480"
  },
  {
    "text": "from one machine one gpu up to",
    "start": "34480",
    "end": "37680"
  },
  {
    "text": "any number of machines any number of",
    "start": "37680",
    "end": "39920"
  },
  {
    "text": "gpus which",
    "start": "39920",
    "end": "41440"
  },
  {
    "text": "as uh folks who are at a rate conference",
    "start": "41440",
    "end": "43360"
  },
  {
    "text": "that should sound like something that's",
    "start": "43360",
    "end": "44879"
  },
  {
    "text": "a very familiar concept to them",
    "start": "44879",
    "end": "47360"
  },
  {
    "text": "but the nice thing about it is that it",
    "start": "47360",
    "end": "49039"
  },
  {
    "text": "has a very simple to use and flexible",
    "start": "49039",
    "end": "51760"
  },
  {
    "text": "api",
    "start": "51760",
    "end": "52320"
  },
  {
    "text": "that works very natively with your",
    "start": "52320",
    "end": "54559"
  },
  {
    "text": "existing",
    "start": "54559",
    "end": "55760"
  },
  {
    "text": "tensorflow pytorch mxnet training",
    "start": "55760",
    "end": "57920"
  },
  {
    "text": "scripts",
    "start": "57920",
    "end": "58960"
  },
  {
    "text": "and then once you add just a few lines",
    "start": "58960",
    "end": "60559"
  },
  {
    "text": "of code you can get running with",
    "start": "60559",
    "end": "63440"
  },
  {
    "text": "potentially any number of gpus to train",
    "start": "63440",
    "end": "65920"
  },
  {
    "text": "up your models",
    "start": "65920",
    "end": "68798"
  },
  {
    "text": "so let's get into things by quickly",
    "start": "69600",
    "end": "71360"
  },
  {
    "start": "70000",
    "end": "70000"
  },
  {
    "text": "going through a refresher",
    "start": "71360",
    "end": "72720"
  },
  {
    "text": "on the deep learning training process so",
    "start": "72720",
    "end": "76400"
  },
  {
    "text": "when we do deep learning we typically",
    "start": "76400",
    "end": "79280"
  },
  {
    "text": "have some",
    "start": "79280",
    "end": "80479"
  },
  {
    "text": "labeled data specific supervised",
    "start": "80479",
    "end": "82320"
  },
  {
    "text": "learning coming in",
    "start": "82320",
    "end": "84799"
  },
  {
    "text": "with the data is fed through the network",
    "start": "84799",
    "end": "87680"
  },
  {
    "text": "it creates an output prediction",
    "start": "87680",
    "end": "90000"
  },
  {
    "text": "and then it's compared against the label",
    "start": "90000",
    "end": "91759"
  },
  {
    "text": "and based on that we",
    "start": "91759",
    "end": "93439"
  },
  {
    "text": "have an update step uh back propagation",
    "start": "93439",
    "end": "96560"
  },
  {
    "text": "where we",
    "start": "96560",
    "end": "97600"
  },
  {
    "text": "uh use the air to adjust the weights",
    "start": "97600",
    "end": "100640"
  },
  {
    "text": "of the of the model but the first thing",
    "start": "100640",
    "end": "103360"
  },
  {
    "text": "you'll notice here",
    "start": "103360",
    "end": "104399"
  },
  {
    "text": "in this diagram is that uh these",
    "start": "104399",
    "end": "107360"
  },
  {
    "text": "gradient updates here",
    "start": "107360",
    "end": "109520"
  },
  {
    "text": "um the layers are sequential so it's not",
    "start": "109520",
    "end": "112960"
  },
  {
    "text": "a uh super parallel problem natively",
    "start": "112960",
    "end": "116719"
  },
  {
    "text": "there's",
    "start": "116719",
    "end": "117280"
  },
  {
    "text": "this isn't something like a typical",
    "start": "117280",
    "end": "119680"
  },
  {
    "text": "spark application for example where",
    "start": "119680",
    "end": "122079"
  },
  {
    "text": "we can just kind of divide up the work",
    "start": "122079",
    "end": "123920"
  },
  {
    "text": "kind of however we want and then at the",
    "start": "123920",
    "end": "125600"
  },
  {
    "text": "end we",
    "start": "125600",
    "end": "126159"
  },
  {
    "text": "aggregate everything back together and",
    "start": "126159",
    "end": "127840"
  },
  {
    "text": "call it a day we have to be a little bit",
    "start": "127840",
    "end": "130000"
  },
  {
    "text": "more careful about how we think about",
    "start": "130000",
    "end": "132319"
  },
  {
    "text": "distributing this workload and so",
    "start": "132319",
    "end": "136319"
  },
  {
    "start": "135000",
    "end": "135000"
  },
  {
    "text": "in the distributed deep learning setting",
    "start": "136319",
    "end": "138879"
  },
  {
    "text": "we typically have",
    "start": "138879",
    "end": "140400"
  },
  {
    "text": "two approaches that are taken in order",
    "start": "140400",
    "end": "143680"
  },
  {
    "text": "to scale up the training process",
    "start": "143680",
    "end": "146480"
  },
  {
    "text": "the first is what you call model",
    "start": "146480",
    "end": "147920"
  },
  {
    "text": "parallelism this is where you",
    "start": "147920",
    "end": "150080"
  },
  {
    "text": "have um the different layers of your",
    "start": "150080",
    "end": "152720"
  },
  {
    "text": "network",
    "start": "152720",
    "end": "153599"
  },
  {
    "text": "distributed across different devices and",
    "start": "153599",
    "end": "156720"
  },
  {
    "text": "the second",
    "start": "156720",
    "end": "157440"
  },
  {
    "text": "is data parallelism where you have the",
    "start": "157440",
    "end": "160560"
  },
  {
    "text": "same model in every one of the gpus for",
    "start": "160560",
    "end": "163599"
  },
  {
    "text": "example but",
    "start": "163599",
    "end": "164800"
  },
  {
    "text": "they're each processing a separate piece",
    "start": "164800",
    "end": "166720"
  },
  {
    "text": "of the data",
    "start": "166720",
    "end": "168000"
  },
  {
    "text": "so a separate portion of the mini batch",
    "start": "168000",
    "end": "173120"
  },
  {
    "text": "now model parallelism is very useful",
    "start": "173120",
    "end": "175280"
  },
  {
    "text": "when you have a very very large model so",
    "start": "175280",
    "end": "177680"
  },
  {
    "text": "a model that",
    "start": "177680",
    "end": "179200"
  },
  {
    "text": "where all the parameters in it might not",
    "start": "179200",
    "end": "181200"
  },
  {
    "text": "even fit on a single gpu",
    "start": "181200",
    "end": "183040"
  },
  {
    "text": "that's a typical scenario where you need",
    "start": "183040",
    "end": "184800"
  },
  {
    "text": "model parallelism",
    "start": "184800",
    "end": "186400"
  },
  {
    "text": "data parallelism however is what most",
    "start": "186400",
    "end": "189040"
  },
  {
    "text": "people typically encounter",
    "start": "189040",
    "end": "190640"
  },
  {
    "text": "when they are trying to scale up their",
    "start": "190640",
    "end": "192159"
  },
  {
    "text": "training process because they have a",
    "start": "192159",
    "end": "194400"
  },
  {
    "text": "data set that is so",
    "start": "194400",
    "end": "195840"
  },
  {
    "text": "large that completing a single epoch on",
    "start": "195840",
    "end": "198800"
  },
  {
    "text": "a single gpu",
    "start": "198800",
    "end": "200080"
  },
  {
    "text": "can take a very long time say maybe",
    "start": "200080",
    "end": "203840"
  },
  {
    "text": "you know hours something like that",
    "start": "203840",
    "end": "207120"
  },
  {
    "text": "the total training time in some cases",
    "start": "207120",
    "end": "210000"
  },
  {
    "text": "for",
    "start": "210000",
    "end": "210799"
  },
  {
    "text": "very large data sets can creep up into",
    "start": "210799",
    "end": "214000"
  },
  {
    "text": "days or even weeks to train and so when",
    "start": "214000",
    "end": "217440"
  },
  {
    "text": "you're able to shard the data set to",
    "start": "217440",
    "end": "220319"
  },
  {
    "text": "speed up training as long as your model",
    "start": "220319",
    "end": "222080"
  },
  {
    "text": "can tolerate a larger batch size",
    "start": "222080",
    "end": "224480"
  },
  {
    "text": "what you find is that you can get the",
    "start": "224480",
    "end": "226799"
  },
  {
    "text": "training time down to",
    "start": "226799",
    "end": "228879"
  },
  {
    "text": "hours or even minutes in some cases for",
    "start": "228879",
    "end": "230879"
  },
  {
    "text": "these",
    "start": "230879",
    "end": "232080"
  },
  {
    "text": "otherwise extremely time consuming",
    "start": "232080",
    "end": "234400"
  },
  {
    "text": "training processes",
    "start": "234400",
    "end": "237360"
  },
  {
    "start": "237000",
    "end": "237000"
  },
  {
    "text": "so horavod is the framework that",
    "start": "238080",
    "end": "241840"
  },
  {
    "text": "we developed here at uber to address",
    "start": "241840",
    "end": "244400"
  },
  {
    "text": "this data parallelism problem",
    "start": "244400",
    "end": "246799"
  },
  {
    "text": "um it has since been open sourced",
    "start": "246799",
    "end": "249920"
  },
  {
    "text": "it's part of the linux foundation and we",
    "start": "249920",
    "end": "252400"
  },
  {
    "text": "welcome you to try it out and",
    "start": "252400",
    "end": "254000"
  },
  {
    "text": "become a contributor if uh if you find",
    "start": "254000",
    "end": "257120"
  },
  {
    "text": "some way that you'd like to contribute",
    "start": "257120",
    "end": "258720"
  },
  {
    "text": "back as i mentioned it's framework",
    "start": "258720",
    "end": "261280"
  },
  {
    "text": "agnostic so we support tensorflow keras",
    "start": "261280",
    "end": "264400"
  },
  {
    "text": "pytorch mxnet",
    "start": "264400",
    "end": "267520"
  },
  {
    "text": "we have a generic backend that kind of",
    "start": "267520",
    "end": "269759"
  },
  {
    "text": "works across all these different",
    "start": "269759",
    "end": "271199"
  },
  {
    "text": "frameworks so it's very easy to plug in",
    "start": "271199",
    "end": "272880"
  },
  {
    "text": "new frameworks",
    "start": "272880",
    "end": "274880"
  },
  {
    "text": "and we support many high performance",
    "start": "274880",
    "end": "276560"
  },
  {
    "text": "features nvidia's nickel framework for",
    "start": "276560",
    "end": "278960"
  },
  {
    "text": "kind of",
    "start": "278960",
    "end": "279919"
  },
  {
    "text": "fast aggregation of these sensor",
    "start": "279919",
    "end": "282479"
  },
  {
    "text": "gradients across gpus",
    "start": "282479",
    "end": "284800"
  },
  {
    "text": "gpu direct for rdma across gpu devices",
    "start": "284800",
    "end": "288960"
  },
  {
    "text": "as well as",
    "start": "288960",
    "end": "289919"
  },
  {
    "text": "rdma and host memory if you're using mpi",
    "start": "289919",
    "end": "293520"
  },
  {
    "text": "and also we use a technique called",
    "start": "293520",
    "end": "295120"
  },
  {
    "text": "tensorfusion that allows you to take",
    "start": "295120",
    "end": "296720"
  },
  {
    "text": "small",
    "start": "296720",
    "end": "297360"
  },
  {
    "text": "gradient updates and batch them together",
    "start": "297360",
    "end": "299199"
  },
  {
    "text": "which significantly",
    "start": "299199",
    "end": "300720"
  },
  {
    "text": "improves performance and as i mentioned",
    "start": "300720",
    "end": "302960"
  },
  {
    "text": "it's very easy to install just five",
    "start": "302960",
    "end": "304479"
  },
  {
    "text": "lines of python and you're ready to go",
    "start": "304479",
    "end": "306800"
  },
  {
    "text": "or easy to use i should say and then",
    "start": "306800",
    "end": "308960"
  },
  {
    "text": "easy to install as well",
    "start": "308960",
    "end": "310000"
  },
  {
    "text": "just use pip pip install horvat we have",
    "start": "310000",
    "end": "312800"
  },
  {
    "text": "some environment variables you can",
    "start": "312800",
    "end": "314160"
  },
  {
    "text": "optionally set as well",
    "start": "314160",
    "end": "317039"
  },
  {
    "start": "316000",
    "end": "316000"
  },
  {
    "text": "and the underlying concept behind",
    "start": "317039",
    "end": "319039"
  },
  {
    "text": "horovod is this technique called",
    "start": "319039",
    "end": "321280"
  },
  {
    "text": "all reduce so all reduce is a",
    "start": "321280",
    "end": "324639"
  },
  {
    "text": "concept from the high performance",
    "start": "324639",
    "end": "326320"
  },
  {
    "text": "computing space originally",
    "start": "326320",
    "end": "328240"
  },
  {
    "text": "where you take your buffer that you want",
    "start": "328240",
    "end": "331759"
  },
  {
    "text": "to",
    "start": "331759",
    "end": "332160"
  },
  {
    "text": "sum in this case these are the gradients",
    "start": "332160",
    "end": "335199"
  },
  {
    "text": "that we want to average across",
    "start": "335199",
    "end": "336840"
  },
  {
    "text": "devices and you essentially break it up",
    "start": "336840",
    "end": "339440"
  },
  {
    "text": "into different pieces and",
    "start": "339440",
    "end": "341120"
  },
  {
    "text": "message pass around the different pieces",
    "start": "341120",
    "end": "343520"
  },
  {
    "text": "at a time",
    "start": "343520",
    "end": "344240"
  },
  {
    "text": "in sort of this typically ring based",
    "start": "344240",
    "end": "346720"
  },
  {
    "text": "fashion though in some topologies this",
    "start": "346720",
    "end": "348560"
  },
  {
    "text": "might be",
    "start": "348560",
    "end": "349120"
  },
  {
    "text": "a tree structure and the result is that",
    "start": "349120",
    "end": "352639"
  },
  {
    "text": "in the end you get the fully aggregated",
    "start": "352639",
    "end": "355120"
  },
  {
    "text": "gradients",
    "start": "355120",
    "end": "356240"
  },
  {
    "text": "but it is done in a way that is uh",
    "start": "356240",
    "end": "359199"
  },
  {
    "text": "optimizing to minimize the",
    "start": "359199",
    "end": "361759"
  },
  {
    "text": "bandwidth of the operation so",
    "start": "361759",
    "end": "364960"
  },
  {
    "text": "in distributed training settings",
    "start": "364960",
    "end": "367120"
  },
  {
    "text": "normally you end up being bandwidth",
    "start": "367120",
    "end": "368960"
  },
  {
    "text": "constrained",
    "start": "368960",
    "end": "370479"
  },
  {
    "text": "which means that you know that's kind of",
    "start": "370479",
    "end": "373199"
  },
  {
    "text": "the limiting factor that's slowing down",
    "start": "373199",
    "end": "374880"
  },
  {
    "text": "your training process",
    "start": "374880",
    "end": "376000"
  },
  {
    "text": "and so by using this approach what we",
    "start": "376000",
    "end": "378880"
  },
  {
    "text": "find is that we can do this",
    "start": "378880",
    "end": "380720"
  },
  {
    "text": "very efficiently and kind of eliminate",
    "start": "380720",
    "end": "384000"
  },
  {
    "text": "that bottleneck or at least mitigate it",
    "start": "384000",
    "end": "387199"
  },
  {
    "start": "387000",
    "end": "387000"
  },
  {
    "text": "and in practice what we find is that",
    "start": "387199",
    "end": "389360"
  },
  {
    "text": "horavod scales really well",
    "start": "389360",
    "end": "391520"
  },
  {
    "text": "um and uh in many cases",
    "start": "391520",
    "end": "395440"
  },
  {
    "text": "what we find is that we get nearly 90",
    "start": "395440",
    "end": "398639"
  },
  {
    "text": "scaling efficiency so very close to",
    "start": "398639",
    "end": "401280"
  },
  {
    "text": "one-to-one scaling efficiency",
    "start": "401280",
    "end": "403520"
  },
  {
    "text": "even at very high numbers of gpus and",
    "start": "403520",
    "end": "407120"
  },
  {
    "start": "407000",
    "end": "407000"
  },
  {
    "text": "in fact this has even been pushed to",
    "start": "407120",
    "end": "409039"
  },
  {
    "text": "some very extreme limits",
    "start": "409039",
    "end": "410479"
  },
  {
    "text": "at oak ridge national laboratory for",
    "start": "410479",
    "end": "412400"
  },
  {
    "text": "instance",
    "start": "412400",
    "end": "413599"
  },
  {
    "text": "they ran on um ibm summit the world's",
    "start": "413599",
    "end": "416479"
  },
  {
    "text": "largest supercomputer with",
    "start": "416479",
    "end": "418000"
  },
  {
    "text": "over 27 000 v-100 gpus or volte at least",
    "start": "418000",
    "end": "421199"
  },
  {
    "text": "gpus",
    "start": "421199",
    "end": "422720"
  },
  {
    "text": "and they achieved or sustained that 90",
    "start": "422720",
    "end": "426319"
  },
  {
    "text": "upwards of 90 scaling efficiency and",
    "start": "426319",
    "end": "428960"
  },
  {
    "text": "ended up",
    "start": "428960",
    "end": "429599"
  },
  {
    "text": "winning the gordon bell prize for their",
    "start": "429599",
    "end": "431360"
  },
  {
    "text": "work exoscale deep learning for climate",
    "start": "431360",
    "end": "434840"
  },
  {
    "text": "analytics",
    "start": "434840",
    "end": "436639"
  },
  {
    "start": "436000",
    "end": "436000"
  },
  {
    "text": "so horovod's been a successful framework",
    "start": "436639",
    "end": "439280"
  },
  {
    "text": "in the industry",
    "start": "439280",
    "end": "440319"
  },
  {
    "text": "it's used by many companies we have many",
    "start": "440319",
    "end": "443360"
  },
  {
    "text": "contributors from across the industry",
    "start": "443360",
    "end": "444960"
  },
  {
    "text": "that help out with the project",
    "start": "444960",
    "end": "446960"
  },
  {
    "text": "and what we've found since releasing",
    "start": "446960",
    "end": "449919"
  },
  {
    "text": "horabad",
    "start": "449919",
    "end": "450720"
  },
  {
    "text": "is a number of more recent trends at",
    "start": "450720",
    "end": "452560"
  },
  {
    "text": "uber that have kind of shaped our",
    "start": "452560",
    "end": "454720"
  },
  {
    "text": "thinking towards how we do distributed",
    "start": "454720",
    "end": "456800"
  },
  {
    "text": "training and how this integrates into",
    "start": "456800",
    "end": "459039"
  },
  {
    "text": "the larger picture of deep learning",
    "start": "459039",
    "end": "460880"
  },
  {
    "text": "workflows",
    "start": "460880",
    "end": "462720"
  },
  {
    "text": "so the state of the world today is that",
    "start": "462720",
    "end": "465199"
  },
  {
    "text": "we have these",
    "start": "465199",
    "end": "466479"
  },
  {
    "text": "heterogeneous compute setups where",
    "start": "466479",
    "end": "469840"
  },
  {
    "text": "we end up doing say uh the etl extract",
    "start": "469840",
    "end": "472720"
  },
  {
    "text": "train load",
    "start": "472720",
    "end": "473680"
  },
  {
    "text": "of the data using one framework and then",
    "start": "473680",
    "end": "476080"
  },
  {
    "text": "feature engineering using",
    "start": "476080",
    "end": "478000"
  },
  {
    "text": "some different framework hyper parameter",
    "start": "478000",
    "end": "480639"
  },
  {
    "text": "search distributed training online",
    "start": "480639",
    "end": "482400"
  },
  {
    "text": "serving all of these end up",
    "start": "482400",
    "end": "484720"
  },
  {
    "text": "using very different infrastructure",
    "start": "484720",
    "end": "487280"
  },
  {
    "text": "using",
    "start": "487280",
    "end": "487759"
  },
  {
    "text": "having different teams that maintain the",
    "start": "487759",
    "end": "489520"
  },
  {
    "text": "slas and the services etc",
    "start": "489520",
    "end": "492560"
  },
  {
    "text": "and ultimately a lot of the engineering",
    "start": "492560",
    "end": "494960"
  },
  {
    "text": "effort gets spent",
    "start": "494960",
    "end": "496240"
  },
  {
    "text": "provisioning and stitching all of these",
    "start": "496240",
    "end": "498479"
  },
  {
    "text": "systems together so for example",
    "start": "498479",
    "end": "501039"
  },
  {
    "text": "we use spark for doing the data loading",
    "start": "501039",
    "end": "504160"
  },
  {
    "text": "and feature engineering then maybe we",
    "start": "504160",
    "end": "507520"
  },
  {
    "text": "have a you know internal framework that",
    "start": "507520",
    "end": "510319"
  },
  {
    "text": "we've talked about called autotune that",
    "start": "510319",
    "end": "511919"
  },
  {
    "text": "does the hyperparameter search",
    "start": "511919",
    "end": "513919"
  },
  {
    "text": "and we use horovod for distributed",
    "start": "513919",
    "end": "515680"
  },
  {
    "text": "training which has a separate",
    "start": "515680",
    "end": "517760"
  },
  {
    "text": "infrastructure layer for provisioning",
    "start": "517760",
    "end": "519680"
  },
  {
    "text": "the jobs and then",
    "start": "519680",
    "end": "521279"
  },
  {
    "text": "connecting the spark and the horovod",
    "start": "521279",
    "end": "523120"
  },
  {
    "text": "components together",
    "start": "523120",
    "end": "524480"
  },
  {
    "text": "and what you find is that this all",
    "start": "524480",
    "end": "525760"
  },
  {
    "text": "becomes very complicated to maintain",
    "start": "525760",
    "end": "529760"
  },
  {
    "start": "529000",
    "end": "529000"
  },
  {
    "text": "so distributed training in particular",
    "start": "529920",
    "end": "532320"
  },
  {
    "text": "even outside of uber",
    "start": "532320",
    "end": "534160"
  },
  {
    "text": "you know while horvat is very easy to",
    "start": "534160",
    "end": "536320"
  },
  {
    "text": "run",
    "start": "536320",
    "end": "537200"
  },
  {
    "text": "it has a very clean api provisioning the",
    "start": "537200",
    "end": "540240"
  },
  {
    "text": "job",
    "start": "540240",
    "end": "540640"
  },
  {
    "text": "so doing the game scheduling setting up",
    "start": "540640",
    "end": "543040"
  },
  {
    "text": "the containers",
    "start": "543040",
    "end": "544240"
  },
  {
    "text": "setting up mpi is where most users run",
    "start": "544240",
    "end": "548000"
  },
  {
    "text": "into trouble",
    "start": "548000",
    "end": "549440"
  },
  {
    "text": "and similarly fault tolerance and auto",
    "start": "549440",
    "end": "551839"
  },
  {
    "text": "scaling we've recently introduced an",
    "start": "551839",
    "end": "553600"
  },
  {
    "text": "elastic core bot api",
    "start": "553600",
    "end": "555680"
  },
  {
    "text": "but uh finding a way to set up your",
    "start": "555680",
    "end": "558880"
  },
  {
    "text": "workers to take advantage of it is",
    "start": "558880",
    "end": "561200"
  },
  {
    "text": "something that",
    "start": "561200",
    "end": "562880"
  },
  {
    "text": "is still a challenge depending on what",
    "start": "562880",
    "end": "566000"
  },
  {
    "text": "kind of infrastructure you're working",
    "start": "566000",
    "end": "567440"
  },
  {
    "text": "with",
    "start": "567440",
    "end": "569440"
  },
  {
    "text": "hyperparameter search there have been a",
    "start": "569440",
    "end": "571040"
  },
  {
    "text": "lot of recent developments in this space",
    "start": "571040",
    "end": "573360"
  },
  {
    "text": "explore exploit approaches are becoming",
    "start": "573360",
    "end": "575360"
  },
  {
    "text": "very common so early stopping",
    "start": "575360",
    "end": "577760"
  },
  {
    "text": "giving sort of a resource or time",
    "start": "577760",
    "end": "580560"
  },
  {
    "text": "constraint budgets for each of the",
    "start": "580560",
    "end": "582080"
  },
  {
    "text": "trials",
    "start": "582080",
    "end": "583279"
  },
  {
    "text": "and so we're seeing a lot of interest in",
    "start": "583279",
    "end": "586000"
  },
  {
    "text": "moving towards",
    "start": "586000",
    "end": "587120"
  },
  {
    "text": "a dynamic resource allocation",
    "start": "587120",
    "end": "590480"
  },
  {
    "text": "where we combine these sort of explore",
    "start": "590480",
    "end": "593040"
  },
  {
    "text": "exploit model with distributed training",
    "start": "593040",
    "end": "595920"
  },
  {
    "text": "so being able to kind of fan out during",
    "start": "595920",
    "end": "598000"
  },
  {
    "text": "the explore phase and then",
    "start": "598000",
    "end": "600080"
  },
  {
    "text": "scale up your more successful trials",
    "start": "600080",
    "end": "602800"
  },
  {
    "text": "using distributed training",
    "start": "602800",
    "end": "604000"
  },
  {
    "text": "in the exploit phase as well as",
    "start": "604000",
    "end": "608399"
  },
  {
    "text": "end-to-end workflows so how do you move",
    "start": "608399",
    "end": "610640"
  },
  {
    "text": "the data between stages",
    "start": "610640",
    "end": "612320"
  },
  {
    "text": "how do you get take advantage of data",
    "start": "612320",
    "end": "614000"
  },
  {
    "text": "locality avoid having to materialize",
    "start": "614000",
    "end": "616640"
  },
  {
    "text": "data sets by writing to",
    "start": "616640",
    "end": "618000"
  },
  {
    "text": "disk how do you provide random access",
    "start": "618000",
    "end": "620640"
  },
  {
    "text": "into your data sets for the training",
    "start": "620640",
    "end": "622399"
  },
  {
    "text": "process",
    "start": "622399",
    "end": "623839"
  },
  {
    "text": "and how do you make sure that you write",
    "start": "623839",
    "end": "625360"
  },
  {
    "text": "this in a way that minimizes training",
    "start": "625360",
    "end": "627040"
  },
  {
    "text": "serving sku",
    "start": "627040",
    "end": "627839"
  },
  {
    "text": "so you want to have a unified api that",
    "start": "627839",
    "end": "630320"
  },
  {
    "text": "you can run in batch",
    "start": "630320",
    "end": "631360"
  },
  {
    "text": "as well as in streaming as well as",
    "start": "631360",
    "end": "633040"
  },
  {
    "text": "online serving",
    "start": "633040",
    "end": "634560"
  },
  {
    "text": "all these things are complications that",
    "start": "634560",
    "end": "636959"
  },
  {
    "text": "come up when you're dealing with",
    "start": "636959",
    "end": "638959"
  },
  {
    "text": "writing these sorts of bespoke",
    "start": "638959",
    "end": "640640"
  },
  {
    "text": "distributed systems",
    "start": "640640",
    "end": "643120"
  },
  {
    "start": "642000",
    "end": "642000"
  },
  {
    "text": "so this is where ray comes into the",
    "start": "643120",
    "end": "644560"
  },
  {
    "text": "picture so",
    "start": "644560",
    "end": "646240"
  },
  {
    "text": "ray is we like it at uber and the",
    "start": "646240",
    "end": "649120"
  },
  {
    "text": "horvath team has been very interested in",
    "start": "649120",
    "end": "651040"
  },
  {
    "text": "particularly because",
    "start": "651040",
    "end": "652560"
  },
  {
    "text": "it's an open platform it's open source",
    "start": "652560",
    "end": "654560"
  },
  {
    "text": "it runs anywhere kubernetes cloud",
    "start": "654560",
    "end": "656640"
  },
  {
    "text": "aws gcp you know anywhere you want to",
    "start": "656640",
    "end": "660079"
  },
  {
    "text": "run",
    "start": "660079",
    "end": "661120"
  },
  {
    "text": "ray has already done the legwork to run",
    "start": "661120",
    "end": "663600"
  },
  {
    "text": "there",
    "start": "663600",
    "end": "664959"
  },
  {
    "text": "it provides a general set of distributed",
    "start": "664959",
    "end": "667680"
  },
  {
    "text": "compute primitives",
    "start": "667680",
    "end": "668880"
  },
  {
    "text": "so you get fault tolerance and auto",
    "start": "668880",
    "end": "670720"
  },
  {
    "text": "scaling",
    "start": "670720",
    "end": "672079"
  },
  {
    "text": "out of the box dynamic task graphs",
    "start": "672079",
    "end": "674800"
  },
  {
    "text": "actors to manage",
    "start": "674800",
    "end": "676720"
  },
  {
    "text": "uh state shared memory",
    "start": "676720",
    "end": "679760"
  },
  {
    "text": "across different nodes different or",
    "start": "679760",
    "end": "681680"
  },
  {
    "text": "different actors",
    "start": "681680",
    "end": "683440"
  },
  {
    "text": "and it provides out of the box and all",
    "start": "683440",
    "end": "685600"
  },
  {
    "text": "infer as well",
    "start": "685600",
    "end": "686800"
  },
  {
    "text": "so ray tune very popular hyper parameter",
    "start": "686800",
    "end": "688880"
  },
  {
    "text": "search framework",
    "start": "688880",
    "end": "689920"
  },
  {
    "text": "comes with ray natively uh rl lib most",
    "start": "689920",
    "end": "693519"
  },
  {
    "text": "popular reinforcement learning library",
    "start": "693519",
    "end": "695760"
  },
  {
    "text": "so lots of good support in the ecosystem",
    "start": "695760",
    "end": "699600"
  },
  {
    "start": "699000",
    "end": "699000"
  },
  {
    "text": "so how can ray help us out with the",
    "start": "699600",
    "end": "701279"
  },
  {
    "text": "problems that i mentioned before so",
    "start": "701279",
    "end": "704000"
  },
  {
    "text": "distributed training we're looking at",
    "start": "704000",
    "end": "706399"
  },
  {
    "text": "horovod plus array integration so this",
    "start": "706399",
    "end": "708399"
  },
  {
    "text": "is something that i'll be focusing most",
    "start": "708399",
    "end": "709839"
  },
  {
    "text": "of the talk on today",
    "start": "709839",
    "end": "711680"
  },
  {
    "text": "hyper parameter search so we're in the",
    "start": "711680",
    "end": "713760"
  },
  {
    "text": "process of adding horvat plus raytune",
    "start": "713760",
    "end": "716079"
  },
  {
    "text": "support",
    "start": "716079",
    "end": "717200"
  },
  {
    "text": "and end-to-end workflow so this is more",
    "start": "717200",
    "end": "720160"
  },
  {
    "text": "forward-looking",
    "start": "720160",
    "end": "721040"
  },
  {
    "text": "but horebod plus raytune plus the recent",
    "start": "721040",
    "end": "724560"
  },
  {
    "text": "work on dascon ray is something that has",
    "start": "724560",
    "end": "726959"
  },
  {
    "text": "us very excited",
    "start": "726959",
    "end": "730160"
  },
  {
    "text": "so to kick things off let's talk about",
    "start": "730160",
    "end": "732079"
  },
  {
    "text": "horvath on rey and how to get started",
    "start": "732079",
    "end": "734160"
  },
  {
    "text": "with it",
    "start": "734160",
    "end": "735279"
  },
  {
    "text": "so race support comes with horvat in our",
    "start": "735279",
    "end": "739279"
  },
  {
    "text": "release version 0.20 that came out at",
    "start": "739279",
    "end": "742639"
  },
  {
    "text": "the beginning of september",
    "start": "742639",
    "end": "744880"
  },
  {
    "text": "and to start using ray you just need to",
    "start": "744880",
    "end": "747519"
  },
  {
    "text": "install with",
    "start": "747519",
    "end": "748320"
  },
  {
    "text": "glue so it only supports our glue not",
    "start": "748320",
    "end": "750720"
  },
  {
    "text": "our mpi",
    "start": "750720",
    "end": "752079"
  },
  {
    "text": "controller at the moment and you install",
    "start": "752079",
    "end": "755200"
  },
  {
    "text": "using this extra ray and you get the ray",
    "start": "755200",
    "end": "757200"
  },
  {
    "text": "dependencies",
    "start": "757200",
    "end": "758240"
  },
  {
    "text": "thrown in there as well and",
    "start": "758240",
    "end": "761760"
  },
  {
    "start": "760000",
    "end": "760000"
  },
  {
    "text": "the key api that we expose with",
    "start": "761760",
    "end": "764079"
  },
  {
    "text": "horizontal and ray is this",
    "start": "764079",
    "end": "765600"
  },
  {
    "text": "ray executor api so it makes it very",
    "start": "765600",
    "end": "768880"
  },
  {
    "text": "simple to get up and running",
    "start": "768880",
    "end": "770720"
  },
  {
    "text": "you just initialize your ray cluster or",
    "start": "770720",
    "end": "774240"
  },
  {
    "text": "attach to it as you normally would and",
    "start": "774240",
    "end": "777120"
  },
  {
    "text": "when you start this ray executor you",
    "start": "777120",
    "end": "778639"
  },
  {
    "text": "give it some horovod settings",
    "start": "778639",
    "end": "781839"
  },
  {
    "text": "which you know network interfaces things",
    "start": "781839",
    "end": "783839"
  },
  {
    "text": "like that whatever you want to customize",
    "start": "783839",
    "end": "786160"
  },
  {
    "text": "and you just specify how many hosts and",
    "start": "786160",
    "end": "789120"
  },
  {
    "text": "how many",
    "start": "789120",
    "end": "789680"
  },
  {
    "text": "processes you're going to run on each of",
    "start": "789680",
    "end": "791920"
  },
  {
    "text": "these hosts and whether or not you're",
    "start": "791920",
    "end": "793040"
  },
  {
    "text": "using gpu",
    "start": "793040",
    "end": "794639"
  },
  {
    "text": "and then you launch this executor and",
    "start": "794639",
    "end": "796720"
  },
  {
    "text": "now you have the ability to start",
    "start": "796720",
    "end": "799040"
  },
  {
    "text": "running horrified jobs without having to",
    "start": "799040",
    "end": "800720"
  },
  {
    "text": "do anything else so all of the gang",
    "start": "800720",
    "end": "802320"
  },
  {
    "text": "scheduling",
    "start": "802320",
    "end": "803839"
  },
  {
    "text": "is all taken care of once this blocking",
    "start": "803839",
    "end": "806399"
  },
  {
    "text": "call returns you now have",
    "start": "806399",
    "end": "808399"
  },
  {
    "text": "effectively um a set up",
    "start": "808399",
    "end": "811519"
  },
  {
    "text": "cluster environment where you can run",
    "start": "811519",
    "end": "812880"
  },
  {
    "text": "horizon jobs so let's show an example of",
    "start": "812880",
    "end": "815440"
  },
  {
    "text": "that here's a basic hello world",
    "start": "815440",
    "end": "817680"
  },
  {
    "text": "you have a training function that",
    "start": "817680",
    "end": "819040"
  },
  {
    "text": "initialize horavad",
    "start": "819040",
    "end": "820720"
  },
  {
    "text": "prints out the horovod rank and then",
    "start": "820720",
    "end": "823040"
  },
  {
    "text": "returns that rank",
    "start": "823040",
    "end": "825680"
  },
  {
    "text": "so we're going to execute this which",
    "start": "825680",
    "end": "827519"
  },
  {
    "text": "will run it on all the workers",
    "start": "827519",
    "end": "829279"
  },
  {
    "text": "and then return a list of results and",
    "start": "829279",
    "end": "832079"
  },
  {
    "text": "that list of results will just simply",
    "start": "832079",
    "end": "834079"
  },
  {
    "text": "contain",
    "start": "834079",
    "end": "835279"
  },
  {
    "text": "exactly the number of processes that we",
    "start": "835279",
    "end": "837839"
  },
  {
    "text": "allocated for",
    "start": "837839",
    "end": "839360"
  },
  {
    "text": "the executor and then when you're done",
    "start": "839360",
    "end": "842639"
  },
  {
    "text": "with it you can run multiple",
    "start": "842639",
    "end": "844079"
  },
  {
    "text": "things or you can just shut down when",
    "start": "844079",
    "end": "846000"
  },
  {
    "text": "you're when you're ready",
    "start": "846000",
    "end": "848800"
  },
  {
    "text": "now let's show a little bit more of a",
    "start": "848800",
    "end": "850160"
  },
  {
    "start": "849000",
    "end": "849000"
  },
  {
    "text": "practical example of this using",
    "start": "850160",
    "end": "851839"
  },
  {
    "text": "the stateless api that i showed so one",
    "start": "851839",
    "end": "854480"
  },
  {
    "text": "of the",
    "start": "854480",
    "end": "854959"
  },
  {
    "text": "features we add to horovod not long back",
    "start": "854959",
    "end": "857199"
  },
  {
    "text": "is pie choice lightning integration",
    "start": "857199",
    "end": "858800"
  },
  {
    "text": "really great framework to",
    "start": "858800",
    "end": "860639"
  },
  {
    "text": "abstract away a lot of the infra",
    "start": "860639",
    "end": "862160"
  },
  {
    "text": "components of distribute",
    "start": "862160",
    "end": "863839"
  },
  {
    "text": "of deep learning from you and so here we",
    "start": "863839",
    "end": "866480"
  },
  {
    "text": "have a training function that creates",
    "start": "866480",
    "end": "868000"
  },
  {
    "text": "some data set",
    "start": "868000",
    "end": "869519"
  },
  {
    "text": "creates our data loaders creates the",
    "start": "869519",
    "end": "872639"
  },
  {
    "text": "model and then what we call a trainer",
    "start": "872639",
    "end": "874639"
  },
  {
    "text": "and pi torch lightning terms",
    "start": "874639",
    "end": "876480"
  },
  {
    "text": "and we specify that we're using the",
    "start": "876480",
    "end": "877920"
  },
  {
    "text": "horivod backend and we're using gpus",
    "start": "877920",
    "end": "880959"
  },
  {
    "text": "and then we just call fit and then the",
    "start": "880959",
    "end": "883199"
  },
  {
    "text": "model will be trained and we return the",
    "start": "883199",
    "end": "885120"
  },
  {
    "text": "model",
    "start": "885120",
    "end": "886240"
  },
  {
    "text": "and using our uh ray executor we just",
    "start": "886240",
    "end": "889040"
  },
  {
    "text": "pass in this very training function and",
    "start": "889040",
    "end": "890800"
  },
  {
    "text": "then we can pass in any arguments we",
    "start": "890800",
    "end": "892399"
  },
  {
    "text": "want so in this case what our",
    "start": "892399",
    "end": "894480"
  },
  {
    "text": "split between training and validation is",
    "start": "894480",
    "end": "896720"
  },
  {
    "text": "going to look like",
    "start": "896720",
    "end": "898320"
  },
  {
    "text": "and then the first result here is going",
    "start": "898320",
    "end": "900000"
  },
  {
    "text": "to be one of the models so",
    "start": "900000",
    "end": "901519"
  },
  {
    "text": "every one of the replicas will return",
    "start": "901519",
    "end": "903279"
  },
  {
    "text": "its own model and since we're using",
    "start": "903279",
    "end": "905360"
  },
  {
    "text": "horivod",
    "start": "905360",
    "end": "906000"
  },
  {
    "text": "all the models have the same state at",
    "start": "906000",
    "end": "908560"
  },
  {
    "text": "the end of training",
    "start": "908560",
    "end": "909680"
  },
  {
    "text": "so we just pick the first one and now we",
    "start": "909680",
    "end": "912160"
  },
  {
    "text": "have a trained model locally that we can",
    "start": "912160",
    "end": "913760"
  },
  {
    "text": "do whatever we want with",
    "start": "913760",
    "end": "915279"
  },
  {
    "text": "and we just trained it on maybe hundreds",
    "start": "915279",
    "end": "916880"
  },
  {
    "text": "of gpus",
    "start": "916880",
    "end": "918320"
  },
  {
    "text": "and then we shut down and we're good",
    "start": "918320",
    "end": "921519"
  },
  {
    "start": "921000",
    "end": "921000"
  },
  {
    "text": "but ray has even more interesting",
    "start": "921519",
    "end": "924079"
  },
  {
    "text": "features in",
    "start": "924079",
    "end": "924959"
  },
  {
    "text": "then just this it also has the stateful",
    "start": "924959",
    "end": "927040"
  },
  {
    "text": "capability which is very exciting so",
    "start": "927040",
    "end": "929680"
  },
  {
    "text": "instead of running the whole training in",
    "start": "929680",
    "end": "931440"
  },
  {
    "text": "one go and then returning the result",
    "start": "931440",
    "end": "933519"
  },
  {
    "text": "you can take advantage of ray's",
    "start": "933519",
    "end": "935440"
  },
  {
    "text": "statefulness by say",
    "start": "935440",
    "end": "937680"
  },
  {
    "text": "defining some model that has a function",
    "start": "937680",
    "end": "940800"
  },
  {
    "text": "that does a single training step",
    "start": "940800",
    "end": "943040"
  },
  {
    "text": "and then after you initialize your array",
    "start": "943040",
    "end": "944800"
  },
  {
    "text": "executor you maybe",
    "start": "944800",
    "end": "947199"
  },
  {
    "text": "call this training step in a loop",
    "start": "947199",
    "end": "950959"
  },
  {
    "text": "so that every every call here is one",
    "start": "950959",
    "end": "953519"
  },
  {
    "text": "step",
    "start": "953519",
    "end": "954720"
  },
  {
    "text": "and here you you see the uh stateful",
    "start": "954720",
    "end": "957040"
  },
  {
    "text": "execute api",
    "start": "957040",
    "end": "958160"
  },
  {
    "text": "where every worker is going to execute a",
    "start": "958160",
    "end": "961279"
  },
  {
    "text": "specific function so here we're saying",
    "start": "961279",
    "end": "964240"
  },
  {
    "text": "worker.train",
    "start": "964240",
    "end": "967040"
  },
  {
    "text": "and then at the end uh when we're happy",
    "start": "967040",
    "end": "969600"
  },
  {
    "text": "with uh",
    "start": "969600",
    "end": "970240"
  },
  {
    "text": "how many training iterations we've done",
    "start": "970240",
    "end": "973040"
  },
  {
    "text": "we can just call",
    "start": "973040",
    "end": "973920"
  },
  {
    "text": "get weights to obtain the final result",
    "start": "973920",
    "end": "976880"
  },
  {
    "text": "and the very",
    "start": "976880",
    "end": "977680"
  },
  {
    "text": "the thing here that's worth noticing is",
    "start": "977680",
    "end": "980320"
  },
  {
    "text": "that",
    "start": "980320",
    "end": "981600"
  },
  {
    "text": "this training step here we didn't return",
    "start": "981600",
    "end": "984240"
  },
  {
    "text": "you know any weights or any state or",
    "start": "984240",
    "end": "986560"
  },
  {
    "text": "anything like this",
    "start": "986560",
    "end": "987279"
  },
  {
    "text": "all the state is being handled by the",
    "start": "987279",
    "end": "990560"
  },
  {
    "text": "in-memory caching layer of ray",
    "start": "990560",
    "end": "993600"
  },
  {
    "text": "so that when we call worker.train the",
    "start": "993600",
    "end": "996160"
  },
  {
    "text": "updates are applied on the back end",
    "start": "996160",
    "end": "998720"
  },
  {
    "text": "and then we get the weights at the very",
    "start": "998720",
    "end": "1000399"
  },
  {
    "text": "end uh",
    "start": "1000399",
    "end": "1001839"
  },
  {
    "text": "to get return our result",
    "start": "1001839",
    "end": "1004959"
  },
  {
    "text": "and all this was made possible by just",
    "start": "1004959",
    "end": "1006639"
  },
  {
    "text": "passing in this executable class",
    "start": "1006639",
    "end": "1009680"
  },
  {
    "text": "equals my model thing right here which",
    "start": "1009680",
    "end": "1012560"
  },
  {
    "text": "allows us to execute this api",
    "start": "1012560",
    "end": "1014959"
  },
  {
    "text": "on all the workers in parallel",
    "start": "1014959",
    "end": "1019519"
  },
  {
    "text": "and ray also makes it very easy to run",
    "start": "1020720",
    "end": "1023040"
  },
  {
    "text": "on top of",
    "start": "1023040",
    "end": "1024000"
  },
  {
    "text": "aws or in the cloud in general so here's",
    "start": "1024000",
    "end": "1026798"
  },
  {
    "text": "a very",
    "start": "1026799",
    "end": "1027438"
  },
  {
    "text": "simple example showing how you would set",
    "start": "1027439",
    "end": "1029438"
  },
  {
    "text": "up a distributed training job on aws",
    "start": "1029439",
    "end": "1032720"
  },
  {
    "text": "so you assign a head node give it some",
    "start": "1032720",
    "end": "1035199"
  },
  {
    "text": "image",
    "start": "1035199",
    "end": "1035760"
  },
  {
    "text": "some instance type and then all of your",
    "start": "1035760",
    "end": "1037918"
  },
  {
    "text": "worker nodes will have this instance",
    "start": "1037919",
    "end": "1039678"
  },
  {
    "text": "this image type",
    "start": "1039679",
    "end": "1040640"
  },
  {
    "text": "and then install horobot in there and",
    "start": "1040640",
    "end": "1043438"
  },
  {
    "text": "then you can start the cluster",
    "start": "1043439",
    "end": "1045520"
  },
  {
    "text": "wait for all the workers to start and",
    "start": "1045520",
    "end": "1047839"
  },
  {
    "text": "then submit your training script",
    "start": "1047839",
    "end": "1049679"
  },
  {
    "text": "and you're good to go you're running on",
    "start": "1049679",
    "end": "1050880"
  },
  {
    "text": "the cloud with ray and horvath",
    "start": "1050880",
    "end": "1054160"
  },
  {
    "start": "1053000",
    "end": "1053000"
  },
  {
    "text": "now another interesting feature that has",
    "start": "1054160",
    "end": "1057360"
  },
  {
    "text": "been recently added to",
    "start": "1057360",
    "end": "1059840"
  },
  {
    "text": "ray is to raytune is",
    "start": "1059840",
    "end": "1063200"
  },
  {
    "text": "horrivad for hyperparameter search",
    "start": "1063200",
    "end": "1065120"
  },
  {
    "text": "integration",
    "start": "1065120",
    "end": "1066640"
  },
  {
    "text": "so here's an example showing this api",
    "start": "1066640",
    "end": "1069280"
  },
  {
    "text": "now the different colors so you know",
    "start": "1069280",
    "end": "1070720"
  },
  {
    "text": "that we're looking at a",
    "start": "1070720",
    "end": "1072000"
  },
  {
    "text": "slightly different use case here looking",
    "start": "1072000",
    "end": "1074080"
  },
  {
    "text": "at hyper parameter search and retune",
    "start": "1074080",
    "end": "1076880"
  },
  {
    "text": "so you have a training function that",
    "start": "1076880",
    "end": "1078559"
  },
  {
    "text": "takes a configuration where your config",
    "start": "1078559",
    "end": "1080880"
  },
  {
    "text": "defines what your learning rate is in",
    "start": "1080880",
    "end": "1082720"
  },
  {
    "text": "this example",
    "start": "1082720",
    "end": "1084480"
  },
  {
    "text": "and here we're going to construct a",
    "start": "1084480",
    "end": "1086640"
  },
  {
    "text": "model",
    "start": "1086640",
    "end": "1087840"
  },
  {
    "text": "we're going to use the horvat api so we",
    "start": "1087840",
    "end": "1090000"
  },
  {
    "text": "have this distributed optimizer here",
    "start": "1090000",
    "end": "1091840"
  },
  {
    "text": "that wraps our optimizer here you see",
    "start": "1091840",
    "end": "1094320"
  },
  {
    "text": "the learning rate from our config",
    "start": "1094320",
    "end": "1097120"
  },
  {
    "text": "and then we do our normal training",
    "start": "1097120",
    "end": "1099520"
  },
  {
    "text": "process report the loss at the end of",
    "start": "1099520",
    "end": "1101600"
  },
  {
    "text": "each step",
    "start": "1101600",
    "end": "1103039"
  },
  {
    "text": "and then this distributed trainable",
    "start": "1103039",
    "end": "1106640"
  },
  {
    "text": "creator here",
    "start": "1106640",
    "end": "1108720"
  },
  {
    "text": "will uh define how our horobot job is",
    "start": "1108720",
    "end": "1111600"
  },
  {
    "text": "going to be instantiated so",
    "start": "1111600",
    "end": "1114880"
  },
  {
    "text": "you know whether using gpu how many",
    "start": "1114880",
    "end": "1116640"
  },
  {
    "text": "hosts how many slots it should look very",
    "start": "1116640",
    "end": "1118240"
  },
  {
    "text": "familiar to the ray executor that you",
    "start": "1118240",
    "end": "1120000"
  },
  {
    "text": "saw before",
    "start": "1120000",
    "end": "1121360"
  },
  {
    "text": "and then finally at the end you just",
    "start": "1121360",
    "end": "1123840"
  },
  {
    "text": "call getbestconfig to get the best",
    "start": "1123840",
    "end": "1125520"
  },
  {
    "text": "config",
    "start": "1125520",
    "end": "1126400"
  },
  {
    "text": "and so now you've effectively scaled up",
    "start": "1126400",
    "end": "1128320"
  },
  {
    "text": "your hyperparameter search process to",
    "start": "1128320",
    "end": "1130240"
  },
  {
    "text": "run",
    "start": "1130240",
    "end": "1130640"
  },
  {
    "text": "on multiple hosts at once using horivon",
    "start": "1130640",
    "end": "1134640"
  },
  {
    "start": "1133000",
    "end": "1133000"
  },
  {
    "text": "so what's next so the next steps are",
    "start": "1134640",
    "end": "1137440"
  },
  {
    "text": "pretty exciting so elastic corvod is",
    "start": "1137440",
    "end": "1139919"
  },
  {
    "text": "one of the big flagship features of the",
    "start": "1139919",
    "end": "1141600"
  },
  {
    "text": "0.20 release",
    "start": "1141600",
    "end": "1143360"
  },
  {
    "text": "and we're really excited to see this",
    "start": "1143360",
    "end": "1144880"
  },
  {
    "text": "coming to ray is a very easy way to get",
    "start": "1144880",
    "end": "1146799"
  },
  {
    "text": "fault tolerant auto scaling",
    "start": "1146799",
    "end": "1148320"
  },
  {
    "text": "distributed training in any framework",
    "start": "1148320",
    "end": "1152640"
  },
  {
    "text": "and then like i mentioned the elastic",
    "start": "1152640",
    "end": "1154720"
  },
  {
    "text": "hyperparameter search as well",
    "start": "1154720",
    "end": "1156640"
  },
  {
    "text": "and at the end i'll tell you a little",
    "start": "1156640",
    "end": "1157760"
  },
  {
    "text": "bit about some of the things we're",
    "start": "1157760",
    "end": "1158880"
  },
  {
    "text": "thinking about in terms of deep learning",
    "start": "1158880",
    "end": "1160480"
  },
  {
    "text": "workflows on ray",
    "start": "1160480",
    "end": "1162640"
  },
  {
    "text": "so elastic corvette to give you a little",
    "start": "1162640",
    "end": "1164320"
  },
  {
    "text": "context here um in the elastic corvod",
    "start": "1164320",
    "end": "1166880"
  },
  {
    "text": "setting we have a driver that has",
    "start": "1166880",
    "end": "1169120"
  },
  {
    "text": "awareness of",
    "start": "1169120",
    "end": "1170160"
  },
  {
    "text": "different hosts and then some hosts may",
    "start": "1170160",
    "end": "1173919"
  },
  {
    "text": "fail and then some hosts may come online",
    "start": "1173919",
    "end": "1176720"
  },
  {
    "text": "at a different time",
    "start": "1176720",
    "end": "1178000"
  },
  {
    "text": "and when this happens we can contact",
    "start": "1178000",
    "end": "1181039"
  },
  {
    "text": "switch by removing the offending hosts",
    "start": "1181039",
    "end": "1183120"
  },
  {
    "text": "adding in the new hosts",
    "start": "1183120",
    "end": "1184960"
  },
  {
    "text": "and meanwhile this host here that was",
    "start": "1184960",
    "end": "1187760"
  },
  {
    "text": "otherwise fine",
    "start": "1187760",
    "end": "1189600"
  },
  {
    "text": "is able to proceed in the training",
    "start": "1189600",
    "end": "1191679"
  },
  {
    "text": "process with minimal interruptions so no",
    "start": "1191679",
    "end": "1193919"
  },
  {
    "text": "need to tear down the whole process",
    "start": "1193919",
    "end": "1196160"
  },
  {
    "text": "no need to evict all the state from",
    "start": "1196160",
    "end": "1197840"
  },
  {
    "text": "memory etc you can just keep going",
    "start": "1197840",
    "end": "1201600"
  },
  {
    "start": "1201000",
    "end": "1201000"
  },
  {
    "text": "and how does this work so the driver",
    "start": "1201600",
    "end": "1203840"
  },
  {
    "text": "will start",
    "start": "1203840",
    "end": "1205280"
  },
  {
    "text": "and then each of the workers will kick",
    "start": "1205280",
    "end": "1207280"
  },
  {
    "text": "off and they synchronize with each other",
    "start": "1207280",
    "end": "1209120"
  },
  {
    "text": "their state",
    "start": "1209120",
    "end": "1210559"
  },
  {
    "text": "and then the training process happens",
    "start": "1210559",
    "end": "1212159"
  },
  {
    "text": "and at some point of failure occurs",
    "start": "1212159",
    "end": "1214480"
  },
  {
    "text": "so the surviving worker will send a",
    "start": "1214480",
    "end": "1216640"
  },
  {
    "text": "reset request back to the server saying",
    "start": "1216640",
    "end": "1218720"
  },
  {
    "text": "hey",
    "start": "1218720",
    "end": "1219520"
  },
  {
    "text": "i need to know who the new workers are",
    "start": "1219520",
    "end": "1222320"
  },
  {
    "text": "and then the driver",
    "start": "1222320",
    "end": "1223440"
  },
  {
    "text": "will get all the other workers up and",
    "start": "1223440",
    "end": "1225840"
  },
  {
    "text": "running make sure that they all are",
    "start": "1225840",
    "end": "1227440"
  },
  {
    "text": "aware of each other",
    "start": "1227440",
    "end": "1228960"
  },
  {
    "text": "and then these workers will once again",
    "start": "1228960",
    "end": "1230640"
  },
  {
    "text": "synchronize state",
    "start": "1230640",
    "end": "1232159"
  },
  {
    "text": "training will occur the state will be",
    "start": "1232159",
    "end": "1234320"
  },
  {
    "text": "committed so in case a failure occurs in",
    "start": "1234320",
    "end": "1236799"
  },
  {
    "text": "the middle of",
    "start": "1236799",
    "end": "1237840"
  },
  {
    "text": "an update process they can very easily",
    "start": "1237840",
    "end": "1240320"
  },
  {
    "text": "roll back to the last known good state",
    "start": "1240320",
    "end": "1242960"
  },
  {
    "text": "so no kind of like intermediate state",
    "start": "1242960",
    "end": "1245039"
  },
  {
    "text": "issue",
    "start": "1245039",
    "end": "1246880"
  },
  {
    "text": "and then this continues until a new",
    "start": "1246880",
    "end": "1249600"
  },
  {
    "text": "worker is added or a worker is removed",
    "start": "1249600",
    "end": "1251280"
  },
  {
    "text": "etc",
    "start": "1251280",
    "end": "1253280"
  },
  {
    "start": "1252000",
    "end": "1252000"
  },
  {
    "text": "now taking this a step further this idea",
    "start": "1253280",
    "end": "1256559"
  },
  {
    "text": "of",
    "start": "1256559",
    "end": "1257520"
  },
  {
    "text": "can we combine hyperparameter search",
    "start": "1257520",
    "end": "1261280"
  },
  {
    "text": "with distributed training in an elastic",
    "start": "1261280",
    "end": "1264240"
  },
  {
    "text": "context so maybe",
    "start": "1264240",
    "end": "1265760"
  },
  {
    "text": "the workers initially have one gpu each",
    "start": "1265760",
    "end": "1268480"
  },
  {
    "text": "and then we identify",
    "start": "1268480",
    "end": "1270480"
  },
  {
    "text": "certain workers that certain trials",
    "start": "1270480",
    "end": "1273280"
  },
  {
    "text": "certain sets of parameters that are",
    "start": "1273280",
    "end": "1274799"
  },
  {
    "text": "doing very well",
    "start": "1274799",
    "end": "1276240"
  },
  {
    "text": "and we want to give more gpus to them",
    "start": "1276240",
    "end": "1278720"
  },
  {
    "text": "because we want them to train faster",
    "start": "1278720",
    "end": "1280400"
  },
  {
    "text": "so that we can verify that they're good",
    "start": "1280400",
    "end": "1283360"
  },
  {
    "text": "and just get the best model we can from",
    "start": "1283360",
    "end": "1285200"
  },
  {
    "text": "them and then move on with our lives",
    "start": "1285200",
    "end": "1286720"
  },
  {
    "text": "right",
    "start": "1286720",
    "end": "1287520"
  },
  {
    "text": "so this is something that you'd call a",
    "start": "1287520",
    "end": "1289919"
  },
  {
    "text": "typical like time constraint",
    "start": "1289919",
    "end": "1291520"
  },
  {
    "text": "hyper parameter search problem so you're",
    "start": "1291520",
    "end": "1293280"
  },
  {
    "text": "bounded by wanting to complete either as",
    "start": "1293280",
    "end": "1295600"
  },
  {
    "text": "quickly as possible or within some time",
    "start": "1295600",
    "end": "1297360"
  },
  {
    "text": "limit",
    "start": "1297360",
    "end": "1298640"
  },
  {
    "text": "and there was some work done at uh",
    "start": "1298640",
    "end": "1301039"
  },
  {
    "text": "berkeley",
    "start": "1301039",
    "end": "1301679"
  },
  {
    "text": "on this this algorithm that's briefly",
    "start": "1301679",
    "end": "1305440"
  },
  {
    "text": "shown here illustrate here and that's",
    "start": "1305440",
    "end": "1308159"
  },
  {
    "text": "exactly the kind of problem that they're",
    "start": "1308159",
    "end": "1309600"
  },
  {
    "text": "seeking to address",
    "start": "1309600",
    "end": "1311360"
  },
  {
    "text": "and we want to uh in the very near",
    "start": "1311360",
    "end": "1314320"
  },
  {
    "text": "future",
    "start": "1314320",
    "end": "1314799"
  },
  {
    "text": "bring this sort of capability to ray",
    "start": "1314799",
    "end": "1316799"
  },
  {
    "text": "with elastic horovod",
    "start": "1316799",
    "end": "1318480"
  },
  {
    "text": "and this is some of the work that we",
    "start": "1318480",
    "end": "1319760"
  },
  {
    "text": "have in progress so stay tuned for that",
    "start": "1319760",
    "end": "1323600"
  },
  {
    "start": "1322000",
    "end": "1322000"
  },
  {
    "text": "now lastly i want to briefly mention",
    "start": "1324159",
    "end": "1328480"
  },
  {
    "text": "some of the thinking that we have around",
    "start": "1328480",
    "end": "1330720"
  },
  {
    "text": "end-to-end deep learning so",
    "start": "1330720",
    "end": "1332720"
  },
  {
    "text": "ludwig for those of you who don't know",
    "start": "1332720",
    "end": "1334480"
  },
  {
    "text": "is a",
    "start": "1334480",
    "end": "1336400"
  },
  {
    "text": "an open source project originally",
    "start": "1336400",
    "end": "1338000"
  },
  {
    "text": "developed at uber that brings code-free",
    "start": "1338000",
    "end": "1340240"
  },
  {
    "text": "deep learning",
    "start": "1340240",
    "end": "1341120"
  },
  {
    "text": "to data scientists so",
    "start": "1341120",
    "end": "1344240"
  },
  {
    "text": "models can be defined in yaml you can",
    "start": "1344240",
    "end": "1347039"
  },
  {
    "text": "very easily iterate",
    "start": "1347039",
    "end": "1348400"
  },
  {
    "text": "on local data sets on a laptop or scale",
    "start": "1348400",
    "end": "1351760"
  },
  {
    "text": "up",
    "start": "1351760",
    "end": "1352400"
  },
  {
    "text": "which is what we're looking at now and a",
    "start": "1352400",
    "end": "1355200"
  },
  {
    "text": "variety of model architectures are",
    "start": "1355200",
    "end": "1356720"
  },
  {
    "text": "supported kind of state of the art out",
    "start": "1356720",
    "end": "1358240"
  },
  {
    "text": "of the box",
    "start": "1358240",
    "end": "1359360"
  },
  {
    "text": "you don't have to do any custom",
    "start": "1359360",
    "end": "1361440"
  },
  {
    "text": "configuration in order to take advantage",
    "start": "1361440",
    "end": "1362960"
  },
  {
    "text": "of that",
    "start": "1362960",
    "end": "1364000"
  },
  {
    "text": "and so some of the things that we're",
    "start": "1364000",
    "end": "1365600"
  },
  {
    "text": "looking at for horvat or for ludwig",
    "start": "1365600",
    "end": "1367840"
  },
  {
    "text": "is how do we scale this process up how",
    "start": "1367840",
    "end": "1370240"
  },
  {
    "text": "do we take it",
    "start": "1370240",
    "end": "1371120"
  },
  {
    "text": "from being an easy-to-use toolkit to a",
    "start": "1371120",
    "end": "1373280"
  },
  {
    "text": "true automl solution the open source",
    "start": "1373280",
    "end": "1376400"
  },
  {
    "text": "and so for that we want to go from",
    "start": "1376400",
    "end": "1379440"
  },
  {
    "text": "doing this kind of a bespoke workflow of",
    "start": "1379440",
    "end": "1382559"
  },
  {
    "text": "pandas",
    "start": "1382559",
    "end": "1383440"
  },
  {
    "text": "custom hyper parameter search and then",
    "start": "1383440",
    "end": "1384960"
  },
  {
    "text": "we use horovod for distributed training",
    "start": "1384960",
    "end": "1387520"
  },
  {
    "text": "and we want to move this to something",
    "start": "1387520",
    "end": "1390400"
  },
  {
    "start": "1389000",
    "end": "1389000"
  },
  {
    "text": "more scalable",
    "start": "1390400",
    "end": "1391360"
  },
  {
    "text": "so what do we do so we have two options",
    "start": "1391360",
    "end": "1393600"
  },
  {
    "text": "that we've considered for example",
    "start": "1393600",
    "end": "1395760"
  },
  {
    "text": "option a we go with a heterogeneous",
    "start": "1395760",
    "end": "1398320"
  },
  {
    "text": "model that i",
    "start": "1398320",
    "end": "1399120"
  },
  {
    "text": "mentioned before so we use apache spark",
    "start": "1399120",
    "end": "1401200"
  },
  {
    "text": "for pre-processing",
    "start": "1401200",
    "end": "1402799"
  },
  {
    "text": "then we write our results to say a",
    "start": "1402799",
    "end": "1404400"
  },
  {
    "text": "parquet file hdfs",
    "start": "1404400",
    "end": "1406240"
  },
  {
    "text": "s3 and then we do our training with our",
    "start": "1406240",
    "end": "1408720"
  },
  {
    "text": "custom hyper parameter optimization",
    "start": "1408720",
    "end": "1410640"
  },
  {
    "text": "or horovod where the workers stream the",
    "start": "1410640",
    "end": "1413200"
  },
  {
    "text": "parquet shards",
    "start": "1413200",
    "end": "1415600"
  },
  {
    "text": "from the the distributed file system",
    "start": "1415600",
    "end": "1419280"
  },
  {
    "text": "but option b how about we just use ray",
    "start": "1419280",
    "end": "1423760"
  },
  {
    "text": "so we could have das running on top of",
    "start": "1423760",
    "end": "1426320"
  },
  {
    "text": "ray for pre-processing",
    "start": "1426320",
    "end": "1428159"
  },
  {
    "text": "ray tune plus horizontal horvaton rate",
    "start": "1428159",
    "end": "1429679"
  },
  {
    "text": "for auto scaling and",
    "start": "1429679",
    "end": "1431200"
  },
  {
    "text": "training plus hyper parameter",
    "start": "1431200",
    "end": "1432559"
  },
  {
    "text": "optimization",
    "start": "1432559",
    "end": "1434400"
  },
  {
    "text": "and then in the glorious future we could",
    "start": "1434400",
    "end": "1437440"
  },
  {
    "text": "even have the desk workers",
    "start": "1437440",
    "end": "1439039"
  },
  {
    "text": "that pre-process the data coordinate",
    "start": "1439039",
    "end": "1441679"
  },
  {
    "text": "using",
    "start": "1441679",
    "end": "1442400"
  },
  {
    "text": "locality shared memory etc with the",
    "start": "1442400",
    "end": "1445200"
  },
  {
    "text": "training workers",
    "start": "1445200",
    "end": "1446559"
  },
  {
    "text": "for random reads without having to do",
    "start": "1446559",
    "end": "1448559"
  },
  {
    "text": "any kind of serialization",
    "start": "1448559",
    "end": "1450320"
  },
  {
    "text": "or materialization of the data set to",
    "start": "1450320",
    "end": "1452240"
  },
  {
    "text": "disk",
    "start": "1452240",
    "end": "1453360"
  },
  {
    "text": "and dramatically speed up the process of",
    "start": "1453360",
    "end": "1456000"
  },
  {
    "text": "going from",
    "start": "1456000",
    "end": "1456880"
  },
  {
    "text": "feature processing to training",
    "start": "1456880",
    "end": "1460240"
  },
  {
    "text": "and so naturally the unified ray",
    "start": "1460240",
    "end": "1462559"
  },
  {
    "text": "back-end sounds very appealing",
    "start": "1462559",
    "end": "1464080"
  },
  {
    "text": "and that's the direction that we're now",
    "start": "1464080",
    "end": "1465760"
  },
  {
    "text": "exploring",
    "start": "1465760",
    "end": "1467679"
  },
  {
    "start": "1467000",
    "end": "1467000"
  },
  {
    "text": "so this is something that's planned for",
    "start": "1467679",
    "end": "1469760"
  },
  {
    "text": "the 0.40 release of ludwig",
    "start": "1469760",
    "end": "1472720"
  },
  {
    "text": "the next upcoming release and the",
    "start": "1472720",
    "end": "1475840"
  },
  {
    "text": "benefits that we've identified why we",
    "start": "1475840",
    "end": "1477520"
  },
  {
    "text": "want to go this route so",
    "start": "1477520",
    "end": "1478880"
  },
  {
    "text": "no need to maintain provision separate",
    "start": "1478880",
    "end": "1480720"
  },
  {
    "text": "infrastructure so you want to run this",
    "start": "1480720",
    "end": "1482240"
  },
  {
    "text": "in the cloud for example",
    "start": "1482240",
    "end": "1483760"
  },
  {
    "text": "you don't need to set up a spark cluster",
    "start": "1483760",
    "end": "1486000"
  },
  {
    "text": "and then a horovod",
    "start": "1486000",
    "end": "1487039"
  },
  {
    "text": "job and then set up like some kind of",
    "start": "1487039",
    "end": "1489120"
  },
  {
    "text": "hyper parameter search",
    "start": "1489120",
    "end": "1491039"
  },
  {
    "text": "using like multiple workers no need to",
    "start": "1491039",
    "end": "1494000"
  },
  {
    "text": "materialize the pre-processed data to",
    "start": "1494000",
    "end": "1495840"
  },
  {
    "text": "disk so you can leverage potentially",
    "start": "1495840",
    "end": "1497679"
  },
  {
    "text": "data locality",
    "start": "1497679",
    "end": "1499279"
  },
  {
    "text": "co-location of the workers or the actors",
    "start": "1499279",
    "end": "1502080"
  },
  {
    "text": "in this case",
    "start": "1502080",
    "end": "1503520"
  },
  {
    "text": "to take advantage of shared memory so",
    "start": "1503520",
    "end": "1505200"
  },
  {
    "text": "your feature processing",
    "start": "1505200",
    "end": "1506799"
  },
  {
    "text": "all that data can be shared with the",
    "start": "1506799",
    "end": "1508480"
  },
  {
    "text": "training workers without having to write",
    "start": "1508480",
    "end": "1510240"
  },
  {
    "text": "anything",
    "start": "1510240",
    "end": "1512400"
  },
  {
    "start": "1512000",
    "end": "1512000"
  },
  {
    "text": "so to recap horovod is an easy use",
    "start": "1512400",
    "end": "1516000"
  },
  {
    "text": "flexible framework to scale your deep",
    "start": "1516000",
    "end": "1517600"
  },
  {
    "text": "learning training but",
    "start": "1517600",
    "end": "1519600"
  },
  {
    "text": "before the ray integration provisioning",
    "start": "1519600",
    "end": "1521520"
  },
  {
    "text": "horrified jobs was often",
    "start": "1521520",
    "end": "1523840"
  },
  {
    "text": "a pain for some users who were not",
    "start": "1523840",
    "end": "1526080"
  },
  {
    "text": "familiar didn't already have a high",
    "start": "1526080",
    "end": "1527679"
  },
  {
    "text": "performance computing cluster to use",
    "start": "1527679",
    "end": "1530400"
  },
  {
    "text": "now ray makes it easy to configure a",
    "start": "1530400",
    "end": "1532000"
  },
  {
    "text": "horrible job on demand",
    "start": "1532000",
    "end": "1533679"
  },
  {
    "text": "anywhere and with horovod plus raytune",
    "start": "1533679",
    "end": "1536320"
  },
  {
    "text": "support",
    "start": "1536320",
    "end": "1536960"
  },
  {
    "text": "we now have the capability to run",
    "start": "1536960",
    "end": "1539039"
  },
  {
    "text": "horvath distributed training in your",
    "start": "1539039",
    "end": "1540640"
  },
  {
    "text": "hyperparameter search jobs on top of ray",
    "start": "1540640",
    "end": "1543919"
  },
  {
    "text": "and coming soon we have elastic core vod",
    "start": "1543919",
    "end": "1546320"
  },
  {
    "text": "plus ray for",
    "start": "1546320",
    "end": "1547279"
  },
  {
    "text": "fault tolerant auto scaling deep",
    "start": "1547279",
    "end": "1548880"
  },
  {
    "text": "learning training",
    "start": "1548880",
    "end": "1550320"
  },
  {
    "text": "and in the glorious future elastic core",
    "start": "1550320",
    "end": "1552720"
  },
  {
    "text": "vod plus hyperscad to scale up for best",
    "start": "1552720",
    "end": "1554799"
  },
  {
    "text": "performance",
    "start": "1554799",
    "end": "1555600"
  },
  {
    "text": "the best performing trials and if you're",
    "start": "1555600",
    "end": "1558559"
  },
  {
    "text": "interested in",
    "start": "1558559",
    "end": "1560159"
  },
  {
    "text": "finding in a good auto ml solution that",
    "start": "1560159",
    "end": "1562880"
  },
  {
    "text": "provides end-to-end training",
    "start": "1562880",
    "end": "1564480"
  },
  {
    "text": "take a look at ludwig with the support",
    "start": "1564480",
    "end": "1567679"
  },
  {
    "text": "of ray",
    "start": "1567679",
    "end": "1568240"
  },
  {
    "text": "we're going to be able to unify the",
    "start": "1568240",
    "end": "1570320"
  },
  {
    "text": "infrastructure across all stages of the",
    "start": "1570320",
    "end": "1572159"
  },
  {
    "text": "deep learning workflow",
    "start": "1572159",
    "end": "1573600"
  },
  {
    "text": "and really scale this up into being a",
    "start": "1573600",
    "end": "1576159"
  },
  {
    "text": "solution that runs",
    "start": "1576159",
    "end": "1577520"
  },
  {
    "text": "efficiently in any environment",
    "start": "1577520",
    "end": "1580799"
  },
  {
    "text": "so thank you for your time and special",
    "start": "1580799",
    "end": "1582799"
  },
  {
    "text": "thanks to uh richard",
    "start": "1582799",
    "end": "1584320"
  },
  {
    "text": "from any scale for all his contributions",
    "start": "1584320",
    "end": "1587679"
  },
  {
    "text": "to the horovod project to bring this",
    "start": "1587679",
    "end": "1590240"
  },
  {
    "text": "capability",
    "start": "1590240",
    "end": "1591520"
  },
  {
    "text": "uh to ray as well as his work on ray",
    "start": "1591520",
    "end": "1593760"
  },
  {
    "text": "tune to bring horowat into ray tune",
    "start": "1593760",
    "end": "1596640"
  },
  {
    "text": "and if you would like to know more",
    "start": "1596640",
    "end": "1598080"
  },
  {
    "text": "please check us out on github",
    "start": "1598080",
    "end": "1600240"
  },
  {
    "text": "uh please feel free to reach out to me",
    "start": "1600240",
    "end": "1602559"
  },
  {
    "text": "at tg adair there",
    "start": "1602559",
    "end": "1605440"
  },
  {
    "text": "feel free to take a look at the raid",
    "start": "1605440",
    "end": "1607279"
  },
  {
    "text": "docs as well",
    "start": "1607279",
    "end": "1608799"
  },
  {
    "text": "to learn more and also check out ludwig",
    "start": "1608799",
    "end": "1611840"
  },
  {
    "text": "on github",
    "start": "1611840",
    "end": "1613039"
  },
  {
    "text": "for more information about that project",
    "start": "1613039",
    "end": "1615440"
  },
  {
    "text": "so that's it thank you very much for my",
    "start": "1615440",
    "end": "1617120"
  },
  {
    "text": "talk",
    "start": "1617120",
    "end": "1617520"
  },
  {
    "text": "and let me know if you have any",
    "start": "1617520",
    "end": "1618720"
  },
  {
    "text": "questions",
    "start": "1618720",
    "end": "1621679"
  }
]
[
  {
    "text": "so hi I'm Alex fromedios and I'm an AI",
    "start": "3179",
    "end": "7140"
  },
  {
    "text": "focused site reliability engineer and",
    "start": "7140",
    "end": "10080"
  },
  {
    "text": "I'm the founder of tree bear Tech and",
    "start": "10080",
    "end": "12599"
  },
  {
    "text": "mlops Company based in London in the UK",
    "start": "12599",
    "end": "17580"
  },
  {
    "text": "and in this talk I'm going to be telling",
    "start": "17580",
    "end": "20640"
  },
  {
    "text": "you about the covid-19 early warning",
    "start": "20640",
    "end": "23100"
  },
  {
    "text": "system project one of the most",
    "start": "23100",
    "end": "25580"
  },
  {
    "text": "meaningful projects that I've personally",
    "start": "25580",
    "end": "27720"
  },
  {
    "text": "worked on",
    "start": "27720",
    "end": "29220"
  },
  {
    "text": "and I'll also touch on how you can open",
    "start": "29220",
    "end": "32460"
  },
  {
    "text": "operationalize Bayesian models at scale",
    "start": "32460",
    "end": "36420"
  },
  {
    "text": "how you can use Rey even in critical",
    "start": "36420",
    "end": "39360"
  },
  {
    "text": "infrastructure projects",
    "start": "39360",
    "end": "42239"
  },
  {
    "text": "and hopefully I can give you some",
    "start": "42239",
    "end": "44520"
  },
  {
    "text": "takeaways for how you can build AI",
    "start": "44520",
    "end": "47040"
  },
  {
    "text": "infrastructure using Ray and kubrey",
    "start": "47040",
    "end": "52160"
  },
  {
    "text": "so I want to set the scene and tell you",
    "start": "54239",
    "end": "56460"
  },
  {
    "text": "a bit about the situation when this",
    "start": "56460",
    "end": "59039"
  },
  {
    "text": "project started when covid-19 was",
    "start": "59039",
    "end": "61320"
  },
  {
    "text": "starting to arrive in the UK",
    "start": "61320",
    "end": "64878"
  },
  {
    "text": "there was a period of extreme",
    "start": "65880",
    "end": "68400"
  },
  {
    "text": "uncertainty in March of 2020",
    "start": "68400",
    "end": "71939"
  },
  {
    "text": "when covid was reaching the UK and",
    "start": "71939",
    "end": "75360"
  },
  {
    "text": "around this time there was the first",
    "start": "75360",
    "end": "77400"
  },
  {
    "text": "confirmed covert death",
    "start": "77400",
    "end": "81020"
  },
  {
    "text": "there was not a lot of clarity in terms",
    "start": "81360",
    "end": "84659"
  },
  {
    "text": "of how the National Health Service",
    "start": "84659",
    "end": "87000"
  },
  {
    "text": "hospitals would be able to deal with the",
    "start": "87000",
    "end": "89280"
  },
  {
    "text": "growing demand for beds",
    "start": "89280",
    "end": "93060"
  },
  {
    "text": "and the potential human cost of the",
    "start": "93060",
    "end": "96600"
  },
  {
    "text": "virus was",
    "start": "96600",
    "end": "98220"
  },
  {
    "text": "subject to quite a bit of speculation",
    "start": "98220",
    "end": "101900"
  },
  {
    "text": "so like many countries",
    "start": "103740",
    "end": "106680"
  },
  {
    "text": "around this time within weeks of the",
    "start": "106680",
    "end": "108960"
  },
  {
    "text": "first covert death there was a",
    "start": "108960",
    "end": "112020"
  },
  {
    "text": "stay-at-home order issued by the prime",
    "start": "112020",
    "end": "114960"
  },
  {
    "text": "minister",
    "start": "114960",
    "end": "116460"
  },
  {
    "text": "and the this began a period of over a",
    "start": "116460",
    "end": "120720"
  },
  {
    "text": "year of lockdowns",
    "start": "120720",
    "end": "123140"
  },
  {
    "text": "and it was an extreme measure taken to",
    "start": "123140",
    "end": "127079"
  },
  {
    "text": "protect the NHS from reaching capacity",
    "start": "127079",
    "end": "130860"
  },
  {
    "text": "and and having people unable to access",
    "start": "130860",
    "end": "132959"
  },
  {
    "text": "Healthcare",
    "start": "132959",
    "end": "135560"
  },
  {
    "text": "so apart from Trying to minimize the",
    "start": "137120",
    "end": "141180"
  },
  {
    "text": "demand for",
    "start": "141180",
    "end": "143099"
  },
  {
    "text": "Healthcare in the UK at this time like",
    "start": "143099",
    "end": "146459"
  },
  {
    "text": "the USA as well the UK created",
    "start": "146459",
    "end": "149280"
  },
  {
    "text": "additional hospital beds trying to",
    "start": "149280",
    "end": "151680"
  },
  {
    "text": "create more capacity to accommodate",
    "start": "151680",
    "end": "153959"
  },
  {
    "text": "patients",
    "start": "153959",
    "end": "156500"
  },
  {
    "text": "but there was an initiative as well on",
    "start": "158700",
    "end": "160860"
  },
  {
    "text": "the operational side and that was to",
    "start": "160860",
    "end": "162900"
  },
  {
    "text": "figure out how do we better allocate",
    "start": "162900",
    "end": "164940"
  },
  {
    "text": "existing resources",
    "start": "164940",
    "end": "166980"
  },
  {
    "text": "and pandemics have been studied a lot",
    "start": "166980",
    "end": "170000"
  },
  {
    "text": "throughout recent history and at this",
    "start": "170000",
    "end": "172739"
  },
  {
    "text": "time the data sets were becoming better",
    "start": "172739",
    "end": "177060"
  },
  {
    "text": "integrated and there was the",
    "start": "177060",
    "end": "179160"
  },
  {
    "text": "understanding that you could actually",
    "start": "179160",
    "end": "180300"
  },
  {
    "text": "model waves with infection throughout",
    "start": "180300",
    "end": "182220"
  },
  {
    "text": "the UK",
    "start": "182220",
    "end": "183120"
  },
  {
    "text": "at different locations and generate",
    "start": "183120",
    "end": "186900"
  },
  {
    "text": "short-term forecasts to understand how",
    "start": "186900",
    "end": "190140"
  },
  {
    "text": "many resources a hospital may need in",
    "start": "190140",
    "end": "192780"
  },
  {
    "text": "the near future",
    "start": "192780",
    "end": "195440"
  },
  {
    "text": "so this led to the early warning system",
    "start": "196200",
    "end": "198239"
  },
  {
    "text": "project and this was executed by a",
    "start": "198239",
    "end": "202500"
  },
  {
    "text": "customer faculty a leading AI company in",
    "start": "202500",
    "end": "205500"
  },
  {
    "text": "the UK",
    "start": "205500",
    "end": "206700"
  },
  {
    "text": "they specialize in decision intelligence",
    "start": "206700",
    "end": "208620"
  },
  {
    "text": "and they created Bayesian models for the",
    "start": "208620",
    "end": "210599"
  },
  {
    "text": "NHS that would give each Hospital Way",
    "start": "210599",
    "end": "214700"
  },
  {
    "text": "a unique forecast that would help them",
    "start": "214700",
    "end": "217500"
  },
  {
    "text": "understand their demands for the next",
    "start": "217500",
    "end": "219239"
  },
  {
    "text": "few weeks",
    "start": "219239",
    "end": "221659"
  },
  {
    "text": "and just a little bit about the uh this",
    "start": "221840",
    "end": "225239"
  },
  {
    "text": "system for my technical perspective",
    "start": "225239",
    "end": "227819"
  },
  {
    "text": "there were different types of",
    "start": "227819",
    "end": "228959"
  },
  {
    "text": "stakeholders and the main one obviously",
    "start": "228959",
    "end": "231659"
  },
  {
    "text": "was the UK public so these would be",
    "start": "231659",
    "end": "233640"
  },
  {
    "text": "patients that may catch covered they may",
    "start": "233640",
    "end": "236760"
  },
  {
    "text": "then need to be admitted to hospital",
    "start": "236760",
    "end": "239760"
  },
  {
    "text": "and once in hospital they may",
    "start": "239760",
    "end": "241860"
  },
  {
    "text": "additionally need intensive care",
    "start": "241860",
    "end": "244159"
  },
  {
    "text": "intensive care bed",
    "start": "244159",
    "end": "247200"
  },
  {
    "text": "but then the system would also have end",
    "start": "247200",
    "end": "248760"
  },
  {
    "text": "users these would be the NH NHS staff at",
    "start": "248760",
    "end": "251400"
  },
  {
    "text": "the operational level they would be",
    "start": "251400",
    "end": "253379"
  },
  {
    "text": "figuring out either for an individual",
    "start": "253379",
    "end": "255060"
  },
  {
    "text": "Hospital trust how do we do we have",
    "start": "255060",
    "end": "258299"
  },
  {
    "text": "enough resources to end up beds enough",
    "start": "258299",
    "end": "260459"
  },
  {
    "text": "uh ventilators to cover us for the next",
    "start": "260459",
    "end": "263639"
  },
  {
    "text": "few weeks and maybe at a regional level",
    "start": "263639",
    "end": "266100"
  },
  {
    "text": "as well how do we allocate resources",
    "start": "266100",
    "end": "270060"
  },
  {
    "text": "across a number of hospitals and",
    "start": "270060",
    "end": "272460"
  },
  {
    "text": "potentially move patients between",
    "start": "272460",
    "end": "273720"
  },
  {
    "text": "hospitals to balance demand",
    "start": "273720",
    "end": "276720"
  },
  {
    "text": "and then on the operational side of the",
    "start": "276720",
    "end": "279300"
  },
  {
    "text": "actual tool itself there were developers",
    "start": "279300",
    "end": "281280"
  },
  {
    "text": "these were data scientists and machine",
    "start": "281280",
    "end": "283080"
  },
  {
    "text": "learning Engineers they would be",
    "start": "283080",
    "end": "285120"
  },
  {
    "text": "creating new features for the models",
    "start": "285120",
    "end": "287580"
  },
  {
    "text": "doing constant QA making sure that",
    "start": "287580",
    "end": "290160"
  },
  {
    "text": "whenever they were sending out forecast",
    "start": "290160",
    "end": "292740"
  },
  {
    "text": "hospitals that they're being checked",
    "start": "292740",
    "end": "295160"
  },
  {
    "text": "for any issues",
    "start": "295160",
    "end": "298080"
  },
  {
    "text": "and of course there were project",
    "start": "298080",
    "end": "299639"
  },
  {
    "text": "managers throughout just checking that",
    "start": "299639",
    "end": "301320"
  },
  {
    "text": "the uh the tool as a whole was serving",
    "start": "301320",
    "end": "304320"
  },
  {
    "text": "stakeholders in the NHS",
    "start": "304320",
    "end": "307580"
  },
  {
    "text": "this is what the early warning system",
    "start": "308940",
    "end": "310620"
  },
  {
    "text": "looked like to an end user",
    "start": "310620",
    "end": "313080"
  },
  {
    "text": "um so if you're a operational manager in",
    "start": "313080",
    "end": "315300"
  },
  {
    "text": "a operations manager in a hospital you",
    "start": "315300",
    "end": "317880"
  },
  {
    "text": "would see a curve of recent demand",
    "start": "317880",
    "end": "320780"
  },
  {
    "text": "relating to admissions to the hospital",
    "start": "320780",
    "end": "323000"
  },
  {
    "text": "and then the early warning system models",
    "start": "323000",
    "end": "325860"
  },
  {
    "text": "would create a",
    "start": "325860",
    "end": "327320"
  },
  {
    "text": "additional set of lines showing you the",
    "start": "327320",
    "end": "331139"
  },
  {
    "text": "possible needs over the next few weeks",
    "start": "331139",
    "end": "333180"
  },
  {
    "text": "these are Bayesian models meaning that",
    "start": "333180",
    "end": "334800"
  },
  {
    "text": "they would have uncertainty factored in",
    "start": "334800",
    "end": "337320"
  },
  {
    "text": "and uh as a result they could give you a",
    "start": "337320",
    "end": "340979"
  },
  {
    "text": "range of possible scenarios in the near",
    "start": "340979",
    "end": "342960"
  },
  {
    "text": "future",
    "start": "342960",
    "end": "345138"
  },
  {
    "text": "so let's just get into a bit more",
    "start": "348660",
    "end": "349919"
  },
  {
    "text": "technical detail about what this uh what",
    "start": "349919",
    "end": "352139"
  },
  {
    "text": "the underlying technology here was doing",
    "start": "352139",
    "end": "354960"
  },
  {
    "text": "there were two features that were",
    "start": "354960",
    "end": "357240"
  },
  {
    "text": "user-facing so NHS staff could access",
    "start": "357240",
    "end": "360060"
  },
  {
    "text": "forecasts which would tell them how many",
    "start": "360060",
    "end": "362460"
  },
  {
    "text": "patients would be admitted to hospital",
    "start": "362460",
    "end": "364440"
  },
  {
    "text": "potentially the next few weeks as well",
    "start": "364440",
    "end": "366660"
  },
  {
    "text": "as explanations and these were based on",
    "start": "366660",
    "end": "370020"
  },
  {
    "text": "counterfactuals that were run by the",
    "start": "370020",
    "end": "372120"
  },
  {
    "text": "system and that would tell NHS staff",
    "start": "372120",
    "end": "375020"
  },
  {
    "text": "uh what caused the model to predict an",
    "start": "375020",
    "end": "378120"
  },
  {
    "text": "increase in Admissions and what caused",
    "start": "378120",
    "end": "379800"
  },
  {
    "text": "more respect to decrease",
    "start": "379800",
    "end": "381419"
  },
  {
    "text": "because this was necessary for using the",
    "start": "381419",
    "end": "383759"
  },
  {
    "text": "actual forecasts in the context of of",
    "start": "383759",
    "end": "386160"
  },
  {
    "text": "the data",
    "start": "386160",
    "end": "387900"
  },
  {
    "text": "and then on the internal side of the",
    "start": "387900",
    "end": "389759"
  },
  {
    "text": "platform there would be constant batch",
    "start": "389759",
    "end": "391740"
  },
  {
    "text": "jobs that would be calibrating recent",
    "start": "391740",
    "end": "394500"
  },
  {
    "text": "forecasts against ground truth data",
    "start": "394500",
    "end": "397440"
  },
  {
    "text": "and there would be a constantly",
    "start": "397440",
    "end": "400199"
  },
  {
    "text": "retraining processes hyper parameter",
    "start": "400199",
    "end": "402000"
  },
  {
    "text": "optimization that the data scientists",
    "start": "402000",
    "end": "403860"
  },
  {
    "text": "would be running so different types of",
    "start": "403860",
    "end": "406020"
  },
  {
    "text": "workloads or operating roughly on the",
    "start": "406020",
    "end": "408000"
  },
  {
    "text": "same data but for different uh different",
    "start": "408000",
    "end": "411000"
  },
  {
    "text": "means",
    "start": "411000",
    "end": "413419"
  },
  {
    "text": "uh okay now let's have a think about",
    "start": "416340",
    "end": "418380"
  },
  {
    "text": "what the system was like for data",
    "start": "418380",
    "end": "420600"
  },
  {
    "text": "scientists machine learning Engineers we",
    "start": "420600",
    "end": "422400"
  },
  {
    "text": "obviously want to give people the",
    "start": "422400",
    "end": "424560"
  },
  {
    "text": "ability to write scalable python",
    "start": "424560",
    "end": "427199"
  },
  {
    "text": "functions in some way and as an example",
    "start": "427199",
    "end": "430500"
  },
  {
    "text": "uh if we could give them a framework",
    "start": "430500",
    "end": "433020"
  },
  {
    "text": "where they can write a",
    "start": "433020",
    "end": "435440"
  },
  {
    "text": "forecasting job where they have a python",
    "start": "435440",
    "end": "438360"
  },
  {
    "text": "function to pull data and then run batch",
    "start": "438360",
    "end": "440220"
  },
  {
    "text": "inference",
    "start": "440220",
    "end": "441900"
  },
  {
    "text": "um then ideally they can annotate the",
    "start": "441900",
    "end": "444720"
  },
  {
    "text": "function and run this in a cloud",
    "start": "444720",
    "end": "447000"
  },
  {
    "text": "environment and this is exactly how it",
    "start": "447000",
    "end": "449160"
  },
  {
    "text": "works so initially the orchestrator",
    "start": "449160",
    "end": "451860"
  },
  {
    "text": "involved was called dagster and dagster",
    "start": "451860",
    "end": "454560"
  },
  {
    "text": "is similar to another tool that people",
    "start": "454560",
    "end": "456240"
  },
  {
    "text": "might be familiar with called airflow",
    "start": "456240",
    "end": "458460"
  },
  {
    "text": "and this would let people run these",
    "start": "458460",
    "end": "460800"
  },
  {
    "text": "graphs or operations so dagster for",
    "start": "460800",
    "end": "464639"
  },
  {
    "text": "director directed acyclic graph",
    "start": "464639",
    "end": "469080"
  },
  {
    "text": "so they'll write their function and then",
    "start": "469080",
    "end": "471240"
  },
  {
    "text": "they would have a graph that they could",
    "start": "471240",
    "end": "475139"
  },
  {
    "text": "deploy onto a kubernetes cluster and you",
    "start": "475139",
    "end": "477539"
  },
  {
    "text": "can see here that in this example",
    "start": "477539",
    "end": "478800"
  },
  {
    "text": "there's a few serial",
    "start": "478800",
    "end": "481680"
  },
  {
    "text": "um",
    "start": "481680",
    "end": "482460"
  },
  {
    "text": "loading jobs at the start and then",
    "start": "482460",
    "end": "484259"
  },
  {
    "text": "there's a fan art where you can train",
    "start": "484259",
    "end": "486060"
  },
  {
    "text": "and run inference on multiple models and",
    "start": "486060",
    "end": "488340"
  },
  {
    "text": "then there's a combination part at the",
    "start": "488340",
    "end": "489780"
  },
  {
    "text": "end and this is where it would upload",
    "start": "489780",
    "end": "491580"
  },
  {
    "text": "any predictions made to a forecasting",
    "start": "491580",
    "end": "494460"
  },
  {
    "text": "dashboard",
    "start": "494460",
    "end": "496759"
  },
  {
    "text": "and this problem because we were",
    "start": "496919",
    "end": "500360"
  },
  {
    "text": "fitting models and running predictions",
    "start": "500360",
    "end": "502620"
  },
  {
    "text": "for lots of different NHS trusts",
    "start": "502620",
    "end": "504780"
  },
  {
    "text": "throughout the UK it was inherently",
    "start": "504780",
    "end": "506039"
  },
  {
    "text": "quite amenable to parallelizing",
    "start": "506039",
    "end": "508680"
  },
  {
    "text": "um so you could load data and then run a",
    "start": "508680",
    "end": "511379"
  },
  {
    "text": "model for each different location",
    "start": "511379",
    "end": "513200"
  },
  {
    "text": "generating a single data set at the end",
    "start": "513200",
    "end": "517520"
  },
  {
    "text": "then on the architectural side to give",
    "start": "517880",
    "end": "522060"
  },
  {
    "text": "you a really top down view of how the",
    "start": "522060",
    "end": "523680"
  },
  {
    "text": "system worked initially the NHS staff uh",
    "start": "523680",
    "end": "527160"
  },
  {
    "text": "were their end users here and they would",
    "start": "527160",
    "end": "530339"
  },
  {
    "text": "check a dashboard which we populate",
    "start": "530339",
    "end": "532680"
  },
  {
    "text": "every day this was built around a common",
    "start": "532680",
    "end": "535200"
  },
  {
    "text": "data warehousing Analytics tool uh",
    "start": "535200",
    "end": "537600"
  },
  {
    "text": "called palantir Foundry and then",
    "start": "537600",
    "end": "540240"
  },
  {
    "text": "faculty's early warning system code",
    "start": "540240",
    "end": "542580"
  },
  {
    "text": "would be running on a separate",
    "start": "542580",
    "end": "544560"
  },
  {
    "text": "kubernetes cluster on AWS and every",
    "start": "544560",
    "end": "547680"
  },
  {
    "text": "dagster tasks for example for generating",
    "start": "547680",
    "end": "550200"
  },
  {
    "text": "a forecast for a single region would run",
    "start": "550200",
    "end": "553019"
  },
  {
    "text": "would run a single pod making it",
    "start": "553019",
    "end": "556560"
  },
  {
    "text": "scalable across across cloud",
    "start": "556560",
    "end": "559880"
  },
  {
    "text": "and this is generally how things are",
    "start": "559880",
    "end": "562380"
  },
  {
    "text": "operating",
    "start": "562380",
    "end": "564740"
  },
  {
    "text": "but there was a really serious problem",
    "start": "565380",
    "end": "568080"
  },
  {
    "text": "with this approach and that is that",
    "start": "568080",
    "end": "571560"
  },
  {
    "text": "if you provided a very large dag of",
    "start": "571560",
    "end": "575040"
  },
  {
    "text": "operations maybe you wanted to run a",
    "start": "575040",
    "end": "577080"
  },
  {
    "text": "grid search and the and you entered a",
    "start": "577080",
    "end": "580440"
  },
  {
    "text": "very large search space it could create",
    "start": "580440",
    "end": "582360"
  },
  {
    "text": "a huge number of pods in a short amount",
    "start": "582360",
    "end": "585360"
  },
  {
    "text": "of time and it turns out when you create",
    "start": "585360",
    "end": "588720"
  },
  {
    "text": "too many pods in a kubernetes cluster",
    "start": "588720",
    "end": "591120"
  },
  {
    "text": "the entire cluster can fail",
    "start": "591120",
    "end": "593760"
  },
  {
    "text": "uh so there's a bunch of things that go",
    "start": "593760",
    "end": "595260"
  },
  {
    "text": "wrong but maybe someone wants to suggest",
    "start": "595260",
    "end": "598260"
  },
  {
    "text": "what the first thing is to fail when you",
    "start": "598260",
    "end": "601140"
  },
  {
    "text": "create too many pods in a kubernetes",
    "start": "601140",
    "end": "603060"
  },
  {
    "text": "cluster",
    "start": "603060",
    "end": "605100"
  },
  {
    "text": "feel free to shout out",
    "start": "605100",
    "end": "608240"
  },
  {
    "text": "not enough nodes well there was Auto",
    "start": "610440",
    "end": "612060"
  },
  {
    "text": "scaling so I would create more nodes",
    "start": "612060",
    "end": "614279"
  },
  {
    "text": "then what happens next",
    "start": "614279",
    "end": "617779"
  },
  {
    "text": "okay yeah control plane yeah so you you",
    "start": "618000",
    "end": "621420"
  },
  {
    "text": "might think oh the DNS can get quite uh",
    "start": "621420",
    "end": "624540"
  },
  {
    "text": "overwhelmed at some point but yet the",
    "start": "624540",
    "end": "626640"
  },
  {
    "text": "eventually you you create more nodes and",
    "start": "626640",
    "end": "629279"
  },
  {
    "text": "then the nodes will have the pods",
    "start": "629279",
    "end": "630839"
  },
  {
    "text": "assigned the nodes also have demon set",
    "start": "630839",
    "end": "632580"
  },
  {
    "text": "pods and then eventually the control",
    "start": "632580",
    "end": "634860"
  },
  {
    "text": "plane fails and in this case the control",
    "start": "634860",
    "end": "638279"
  },
  {
    "text": "plane would run out of storage because",
    "start": "638279",
    "end": "640080"
  },
  {
    "text": "every single pod would have a certain",
    "start": "640080",
    "end": "643620"
  },
  {
    "text": "storage footprint on the control plane",
    "start": "643620",
    "end": "646399"
  },
  {
    "text": "and when the control plane Runs Out",
    "start": "646399",
    "end": "649380"
  },
  {
    "text": "storage",
    "start": "649380",
    "end": "650480"
  },
  {
    "text": "it becomes unavailable and um I'll go",
    "start": "650480",
    "end": "653640"
  },
  {
    "text": "into that more in a second but it turns",
    "start": "653640",
    "end": "656220"
  },
  {
    "text": "out that particularly large grid search",
    "start": "656220",
    "end": "658019"
  },
  {
    "text": "operations for hyper parameter",
    "start": "658019",
    "end": "660560"
  },
  {
    "text": "optimization would occasionally create",
    "start": "660560",
    "end": "663420"
  },
  {
    "text": "about 10 000 kubernetes jobs in a 10",
    "start": "663420",
    "end": "666420"
  },
  {
    "text": "minute period and this was causing the",
    "start": "666420",
    "end": "670800"
  },
  {
    "text": "entire platform under underpinning",
    "start": "670800",
    "end": "673019"
  },
  {
    "text": "system to fail",
    "start": "673019",
    "end": "676100"
  },
  {
    "text": "I probably don't need to explain and",
    "start": "677339",
    "end": "679380"
  },
  {
    "text": "really these granular detail why this is",
    "start": "679380",
    "end": "681779"
  },
  {
    "text": "bad but this would affect the end users",
    "start": "681779",
    "end": "684060"
  },
  {
    "text": "they wouldn't be able to see forecast",
    "start": "684060",
    "end": "685440"
  },
  {
    "text": "the next morning in the product",
    "start": "685440",
    "end": "687300"
  },
  {
    "text": "um and this would affect this would",
    "start": "687300",
    "end": "689640"
  },
  {
    "text": "reduce the chance that they'd actually",
    "start": "689640",
    "end": "690959"
  },
  {
    "text": "come back and check this and use this as",
    "start": "690959",
    "end": "692640"
  },
  {
    "text": "a part of their operational processes",
    "start": "692640",
    "end": "695820"
  },
  {
    "text": "um but on the developer side people",
    "start": "695820",
    "end": "697500"
  },
  {
    "text": "would lose everything from their Jupiter",
    "start": "697500",
    "end": "699839"
  },
  {
    "text": "servers to Dev jobs that were running",
    "start": "699839",
    "end": "702720"
  },
  {
    "text": "and Hyper parameter optimization and",
    "start": "702720",
    "end": "706620"
  },
  {
    "text": "also there then the machine learning",
    "start": "706620",
    "end": "708180"
  },
  {
    "text": "engineers and data scientists would",
    "start": "708180",
    "end": "709440"
  },
  {
    "text": "require a platform engineering team to",
    "start": "709440",
    "end": "711120"
  },
  {
    "text": "come in and fix this",
    "start": "711120",
    "end": "712680"
  },
  {
    "text": "and the next time they would run a",
    "start": "712680",
    "end": "715019"
  },
  {
    "text": "smaller uh less thorough",
    "start": "715019",
    "end": "718519"
  },
  {
    "text": "batch job and we want people to be",
    "start": "718519",
    "end": "721140"
  },
  {
    "text": "creating larger more ambitious systems",
    "start": "721140",
    "end": "722820"
  },
  {
    "text": "not the smaller ones there were a lot of",
    "start": "722820",
    "end": "724800"
  },
  {
    "text": "reasons why you wanted to fix this",
    "start": "724800",
    "end": "727620"
  },
  {
    "text": "and",
    "start": "727620",
    "end": "729720"
  },
  {
    "text": "when we did some analysis we found that",
    "start": "729720",
    "end": "731640"
  },
  {
    "text": "there's a lot of reasons why an outage",
    "start": "731640",
    "end": "734220"
  },
  {
    "text": "occurs you can think about",
    "start": "734220",
    "end": "737040"
  },
  {
    "text": "um I I felt like the most high impact",
    "start": "737040",
    "end": "739860"
  },
  {
    "text": "reason is that data scientists could",
    "start": "739860",
    "end": "741959"
  },
  {
    "text": "only scale their python functions using",
    "start": "741959",
    "end": "744240"
  },
  {
    "text": "a single mechanism which was a a node",
    "start": "744240",
    "end": "747720"
  },
  {
    "text": "and a dagster graph and each node in",
    "start": "747720",
    "end": "749880"
  },
  {
    "text": "dagstograph which create a single pod",
    "start": "749880",
    "end": "752040"
  },
  {
    "text": "and that was the only way they could",
    "start": "752040",
    "end": "753600"
  },
  {
    "text": "scale things up",
    "start": "753600",
    "end": "755339"
  },
  {
    "text": "um but also you could think that using",
    "start": "755339",
    "end": "757079"
  },
  {
    "text": "the kubernetes control plane too much",
    "start": "757079",
    "end": "758820"
  },
  {
    "text": "when the kubernetes control plane fails",
    "start": "758820",
    "end": "761279"
  },
  {
    "text": "they were self-hosting it using cops and",
    "start": "761279",
    "end": "765000"
  },
  {
    "text": "um it would not be self-healing which is",
    "start": "765000",
    "end": "767700"
  },
  {
    "text": "a problem",
    "start": "767700",
    "end": "769019"
  },
  {
    "text": "um but also like when you have data",
    "start": "769019",
    "end": "770459"
  },
  {
    "text": "scientists using a platform you want",
    "start": "770459",
    "end": "772139"
  },
  {
    "text": "them to be able to run something as",
    "start": "772139",
    "end": "774000"
  },
  {
    "text": "large as possible even until it fails",
    "start": "774000",
    "end": "775860"
  },
  {
    "text": "and not affect other people's work and",
    "start": "775860",
    "end": "778139"
  },
  {
    "text": "so maybe it's not bad that it fails",
    "start": "778139",
    "end": "779639"
  },
  {
    "text": "maybe it's just bad that when it failed",
    "start": "779639",
    "end": "782160"
  },
  {
    "text": "it took the rest of the system down with",
    "start": "782160",
    "end": "783540"
  },
  {
    "text": "it",
    "start": "783540",
    "end": "784320"
  },
  {
    "text": "so like guardrails and then finally",
    "start": "784320",
    "end": "786420"
  },
  {
    "text": "there was very little indication that",
    "start": "786420",
    "end": "788639"
  },
  {
    "text": "the platform was going to fail and an",
    "start": "788639",
    "end": "790680"
  },
  {
    "text": "alarm would be sent but it would be too",
    "start": "790680",
    "end": "792060"
  },
  {
    "text": "late by that point so the observability",
    "start": "792060",
    "end": "793680"
  },
  {
    "text": "was was quite poor",
    "start": "793680",
    "end": "796040"
  },
  {
    "text": "I want to tell you about the highest",
    "start": "796040",
    "end": "798480"
  },
  {
    "text": "impact fix that we put in throughout",
    "start": "798480",
    "end": "800220"
  },
  {
    "text": "this time and that was finding a better",
    "start": "800220",
    "end": "803579"
  },
  {
    "text": "way of scaling python functions and this",
    "start": "803579",
    "end": "806399"
  },
  {
    "text": "is what led us to Rey",
    "start": "806399",
    "end": "809399"
  },
  {
    "text": "and there was a period of reevaluating",
    "start": "809399",
    "end": "812700"
  },
  {
    "text": "what do we actually need from this",
    "start": "812700",
    "end": "814260"
  },
  {
    "text": "system because",
    "start": "814260",
    "end": "816000"
  },
  {
    "text": "the funny thing is that it wasn't a",
    "start": "816000",
    "end": "818760"
  },
  {
    "text": "particularly large-scale use case",
    "start": "818760",
    "end": "821360"
  },
  {
    "text": "there was a large amount of data",
    "start": "821360",
    "end": "823680"
  },
  {
    "text": "involved and the batch system would",
    "start": "823680",
    "end": "825360"
  },
  {
    "text": "require uh using in the order of",
    "start": "825360",
    "end": "828899"
  },
  {
    "text": "thousands of cores overnight but this uh",
    "start": "828899",
    "end": "831480"
  },
  {
    "text": "there were a lot of different",
    "start": "831480",
    "end": "833279"
  },
  {
    "text": "tasks going on here and it turns out",
    "start": "833279",
    "end": "835860"
  },
  {
    "text": "that most of them did not require",
    "start": "835860",
    "end": "837720"
  },
  {
    "text": "distributed computing",
    "start": "837720",
    "end": "839399"
  },
  {
    "text": "so",
    "start": "839399",
    "end": "840740"
  },
  {
    "text": "forecasts and explanations are the",
    "start": "840740",
    "end": "843839"
  },
  {
    "text": "user-facing features here and they had",
    "start": "843839",
    "end": "845820"
  },
  {
    "text": "to run in eight hours",
    "start": "845820",
    "end": "847320"
  },
  {
    "text": "but then there were calibration tasks",
    "start": "847320",
    "end": "849000"
  },
  {
    "text": "and grid searching",
    "start": "849000",
    "end": "850620"
  },
  {
    "text": "and there are a bunch of different",
    "start": "850620",
    "end": "854420"
  },
  {
    "text": "needs for each of these for example grid",
    "start": "854420",
    "end": "857040"
  },
  {
    "text": "searching was very amenable to",
    "start": "857040",
    "end": "859920"
  },
  {
    "text": "parallelization you could run it very",
    "start": "859920",
    "end": "862560"
  },
  {
    "text": "quickly if you wanted to run 5000 tasks",
    "start": "862560",
    "end": "866279"
  },
  {
    "text": "in parallel and would require about 10",
    "start": "866279",
    "end": "868019"
  },
  {
    "text": "terabytes of memory 100 nodes and 500",
    "start": "868019",
    "end": "870959"
  },
  {
    "text": "pods",
    "start": "870959",
    "end": "873240"
  },
  {
    "text": "and",
    "start": "873240",
    "end": "875540"
  },
  {
    "text": "with the way that we're running with",
    "start": "875540",
    "end": "877680"
  },
  {
    "text": "dagster 5000 parallel tasks meant 5000",
    "start": "877680",
    "end": "880500"
  },
  {
    "text": "pods but in reality if you just need 10",
    "start": "880500",
    "end": "883019"
  },
  {
    "text": "terabytes of memory you actually don't",
    "start": "883019",
    "end": "884760"
  },
  {
    "text": "need",
    "start": "884760",
    "end": "886199"
  },
  {
    "text": "um you you can get that amount of memory",
    "start": "886199",
    "end": "888660"
  },
  {
    "text": "in for just 500 pods",
    "start": "888660",
    "end": "891120"
  },
  {
    "text": "um but forecasts and calibration they",
    "start": "891120",
    "end": "893339"
  },
  {
    "text": "didn't even need to be distributed so if",
    "start": "893339",
    "end": "895440"
  },
  {
    "text": "you need 50 CPUs and 100 gigabytes of",
    "start": "895440",
    "end": "897779"
  },
  {
    "text": "memory you can get that in a single",
    "start": "897779",
    "end": "899600"
  },
  {
    "text": "AWS instance",
    "start": "899600",
    "end": "901740"
  },
  {
    "text": "but the reason why we were in",
    "start": "901740",
    "end": "903480"
  },
  {
    "text": "distributed computing territory was",
    "start": "903480",
    "end": "905160"
  },
  {
    "text": "because the explanations",
    "start": "905160",
    "end": "907940"
  },
  {
    "text": "needed to run in eight hours and that",
    "start": "907940",
    "end": "911160"
  },
  {
    "text": "did require maxing out the parallelism",
    "start": "911160",
    "end": "913320"
  },
  {
    "text": "and getting a thousand cores on it",
    "start": "913320",
    "end": "917420"
  },
  {
    "text": "so the first thing we we thought about",
    "start": "917760",
    "end": "919620"
  },
  {
    "text": "doing was uh making sure that every",
    "start": "919620",
    "end": "922139"
  },
  {
    "text": "function that runs doesn't create a new",
    "start": "922139",
    "end": "924240"
  },
  {
    "text": "pod in kubernetes and that meant that uh",
    "start": "924240",
    "end": "928740"
  },
  {
    "text": "we experimented with switching dagster",
    "start": "928740",
    "end": "931620"
  },
  {
    "text": "out of running one pod per uh task to",
    "start": "931620",
    "end": "936120"
  },
  {
    "text": "running a pod for an entire task graph",
    "start": "936120",
    "end": "938600"
  },
  {
    "text": "and this immediately simplified things",
    "start": "938600",
    "end": "941180"
  },
  {
    "text": "but it also led to uh the loss of",
    "start": "941180",
    "end": "945600"
  },
  {
    "text": "ability to run the X explanation task",
    "start": "945600",
    "end": "948300"
  },
  {
    "text": "which required a thousand cores and for",
    "start": "948300",
    "end": "951720"
  },
  {
    "text": "reference in AWS the largest you can",
    "start": "951720",
    "end": "954300"
  },
  {
    "text": "really get in most regions with a single",
    "start": "954300",
    "end": "956220"
  },
  {
    "text": "pod is about 96 CPUs and around a",
    "start": "956220",
    "end": "960360"
  },
  {
    "text": "terabyte of memory so we need about 10",
    "start": "960360",
    "end": "963120"
  },
  {
    "text": "times more than that",
    "start": "963120",
    "end": "964740"
  },
  {
    "text": "but most of the workloads could run on",
    "start": "964740",
    "end": "966180"
  },
  {
    "text": "here really well and so that was kind of",
    "start": "966180",
    "end": "967920"
  },
  {
    "text": "a breakthrough saying why don't we try",
    "start": "967920",
    "end": "969180"
  },
  {
    "text": "running dinosaur this way and then let's",
    "start": "969180",
    "end": "971040"
  },
  {
    "text": "find something different for running the",
    "start": "971040",
    "end": "972779"
  },
  {
    "text": "discreted part",
    "start": "972779",
    "end": "975680"
  },
  {
    "text": "so we",
    "start": "976019",
    "end": "977720"
  },
  {
    "text": "identify that for the explanations we",
    "start": "977720",
    "end": "980639"
  },
  {
    "text": "can start it off in a single virtual",
    "start": "980639",
    "end": "982740"
  },
  {
    "text": "machine",
    "start": "982740",
    "end": "983760"
  },
  {
    "text": "and then when it gets to the bit that",
    "start": "983760",
    "end": "985440"
  },
  {
    "text": "needs to run across a thousand cores",
    "start": "985440",
    "end": "987779"
  },
  {
    "text": "we're going to have a separate Ray",
    "start": "987779",
    "end": "989100"
  },
  {
    "text": "cluster and the sub process so when you",
    "start": "989100",
    "end": "993600"
  },
  {
    "text": "switch dagster into this single machine",
    "start": "993600",
    "end": "995940"
  },
  {
    "text": "mode each operation will run as a sub",
    "start": "995940",
    "end": "998579"
  },
  {
    "text": "process rather than a kubernetes pod and",
    "start": "998579",
    "end": "1001399"
  },
  {
    "text": "the subprocess can call out to array",
    "start": "1001399",
    "end": "1003740"
  },
  {
    "text": "cluster and create a ton of tasks",
    "start": "1003740",
    "end": "1006019"
  },
  {
    "text": "against the ray cluster",
    "start": "1006019",
    "end": "1007579"
  },
  {
    "text": "and then you can have a small number of",
    "start": "1007579",
    "end": "1010040"
  },
  {
    "text": "extremely large workers behind the",
    "start": "1010040",
    "end": "1012560"
  },
  {
    "text": "scenes that are hosting these tasks",
    "start": "1012560",
    "end": "1016899"
  },
  {
    "text": "and",
    "start": "1016940",
    "end": "1018199"
  },
  {
    "text": "going back to the user experience here",
    "start": "1018199",
    "end": "1019880"
  },
  {
    "text": "for the machine learning Engineers they",
    "start": "1019880",
    "end": "1022880"
  },
  {
    "text": "would still be able to write python",
    "start": "1022880",
    "end": "1024260"
  },
  {
    "text": "functions but instead of annotating it",
    "start": "1024260",
    "end": "1026178"
  },
  {
    "text": "with a dagster annotation that annotates",
    "start": "1026179",
    "end": "1028520"
  },
  {
    "text": "it with array annotation and it was",
    "start": "1028520",
    "end": "1029959"
  },
  {
    "text": "really important that we kept that kind",
    "start": "1029959",
    "end": "1031220"
  },
  {
    "text": "of productivity even though we were",
    "start": "1031220",
    "end": "1033438"
  },
  {
    "text": "quite seriously re-architecting the",
    "start": "1033439",
    "end": "1035418"
  },
  {
    "text": "processes behind the scenes",
    "start": "1035419",
    "end": "1038178"
  },
  {
    "text": "so assuming that most people here",
    "start": "1038179",
    "end": "1040339"
  },
  {
    "text": "haven't used",
    "start": "1040339",
    "end": "1042558"
  },
  {
    "text": "um",
    "start": "1042559",
    "end": "1043459"
  },
  {
    "text": "I haven't used cubery before I quickly",
    "start": "1043459",
    "end": "1045740"
  },
  {
    "text": "run through how it would work at runtime",
    "start": "1045740",
    "end": "1047360"
  },
  {
    "text": "so you'd have a run container in dagster",
    "start": "1047360",
    "end": "1049520"
  },
  {
    "text": "it would submit tasks to array cluster",
    "start": "1049520",
    "end": "1051500"
  },
  {
    "text": "head node and then you would have an",
    "start": "1051500",
    "end": "1054620"
  },
  {
    "text": "auto scaler that would understand that",
    "start": "1054620",
    "end": "1057140"
  },
  {
    "text": "this small Ray head node isn't here to",
    "start": "1057140",
    "end": "1059059"
  },
  {
    "text": "execute work it's here kind of just to",
    "start": "1059059",
    "end": "1060860"
  },
  {
    "text": "register the work so it's a control",
    "start": "1060860",
    "end": "1062660"
  },
  {
    "text": "plane within the kubernetes control",
    "start": "1062660",
    "end": "1064520"
  },
  {
    "text": "plane that's isolated just for this task",
    "start": "1064520",
    "end": "1068600"
  },
  {
    "text": "um and then the old scalar kicks in and",
    "start": "1068600",
    "end": "1070160"
  },
  {
    "text": "asks the kubernetes API for Ray workers",
    "start": "1070160",
    "end": "1072020"
  },
  {
    "text": "and then the ray workers will pick up",
    "start": "1072020",
    "end": "1073940"
  },
  {
    "text": "work from the head node and execute it",
    "start": "1073940",
    "end": "1078879"
  },
  {
    "text": "and how do we actually implement this",
    "start": "1080360",
    "end": "1082700"
  },
  {
    "text": "infrastructure",
    "start": "1082700",
    "end": "1084020"
  },
  {
    "text": "so there'd be a uh there'd be a",
    "start": "1084020",
    "end": "1087440"
  },
  {
    "text": "infrastructure as code a Helm file based",
    "start": "1087440",
    "end": "1090860"
  },
  {
    "text": "solution in the python repo that had all",
    "start": "1090860",
    "end": "1094760"
  },
  {
    "text": "the modeling code and you could build a",
    "start": "1094760",
    "end": "1097820"
  },
  {
    "text": "Docker image and pass it to a ray",
    "start": "1097820",
    "end": "1099919"
  },
  {
    "text": "cluster custom resource implemented by",
    "start": "1099919",
    "end": "1102559"
  },
  {
    "text": "kubray",
    "start": "1102559",
    "end": "1103760"
  },
  {
    "text": "and that that custom resource would",
    "start": "1103760",
    "end": "1105980"
  },
  {
    "text": "create pods for your array cluster and",
    "start": "1105980",
    "end": "1109039"
  },
  {
    "text": "then once you have a pod Fury cluster",
    "start": "1109039",
    "end": "1110960"
  },
  {
    "text": "you need some Auto scaling mechanism",
    "start": "1110960",
    "end": "1112820"
  },
  {
    "text": "under the hood to provide a node for it",
    "start": "1112820",
    "end": "1116000"
  },
  {
    "text": "and we found a really good fit with the",
    "start": "1116000",
    "end": "1118280"
  },
  {
    "text": "carpenter project which lets you also",
    "start": "1118280",
    "end": "1120919"
  },
  {
    "text": "use a kubernetes custom resource",
    "start": "1120919",
    "end": "1124660"
  },
  {
    "text": "operator pattern for saying these are",
    "start": "1124660",
    "end": "1127640"
  },
  {
    "text": "the types of instances we want to be",
    "start": "1127640",
    "end": "1129320"
  },
  {
    "text": "running our work on and rather than",
    "start": "1129320",
    "end": "1132140"
  },
  {
    "text": "creating Auto scaling groups for every",
    "start": "1132140",
    "end": "1134000"
  },
  {
    "text": "type of instance we could just pass",
    "start": "1134000",
    "end": "1135799"
  },
  {
    "text": "values in here and say we want R5 8 or",
    "start": "1135799",
    "end": "1138980"
  },
  {
    "text": "12 or 24 x large instances and they",
    "start": "1138980",
    "end": "1142400"
  },
  {
    "text": "could host tons of tasks in parallel",
    "start": "1142400",
    "end": "1145280"
  },
  {
    "text": "which gave us a better ratio of parallel",
    "start": "1145280",
    "end": "1147740"
  },
  {
    "text": "tasks to underlying pods in the control",
    "start": "1147740",
    "end": "1150020"
  },
  {
    "text": "plane for kubernetes",
    "start": "1150020",
    "end": "1153340"
  },
  {
    "text": "so looking at this new platform that we",
    "start": "1155140",
    "end": "1159140"
  },
  {
    "text": "put together as a whole",
    "start": "1159140",
    "end": "1160640"
  },
  {
    "text": "you could think about it as the being",
    "start": "1160640",
    "end": "1162799"
  },
  {
    "text": "app environments and when a data",
    "start": "1162799",
    "end": "1166940"
  },
  {
    "text": "scientist or machine learning engineer",
    "start": "1166940",
    "end": "1168140"
  },
  {
    "text": "builds their python code they could then",
    "start": "1168140",
    "end": "1169940"
  },
  {
    "text": "deploy it as an app environment and that",
    "start": "1169940",
    "end": "1172520"
  },
  {
    "text": "would have its own Helm chart",
    "start": "1172520",
    "end": "1174980"
  },
  {
    "text": "and they would have one instance of",
    "start": "1174980",
    "end": "1177380"
  },
  {
    "text": "their user code image running as a",
    "start": "1177380",
    "end": "1179059"
  },
  {
    "text": "dagster user code service and they'd",
    "start": "1179059",
    "end": "1181820"
  },
  {
    "text": "have another one running as a ray head",
    "start": "1181820",
    "end": "1183860"
  },
  {
    "text": "node in a scaled down manner with an",
    "start": "1183860",
    "end": "1186260"
  },
  {
    "text": "auto scaler ready to scale it up",
    "start": "1186260",
    "end": "1188720"
  },
  {
    "text": "and on the right you can see that when",
    "start": "1188720",
    "end": "1190820"
  },
  {
    "text": "it goes into production and starts to be",
    "start": "1190820",
    "end": "1193160"
  },
  {
    "text": "invoked the dagster job would start",
    "start": "1193160",
    "end": "1197179"
  },
  {
    "text": "running their user code and that would",
    "start": "1197179",
    "end": "1200299"
  },
  {
    "text": "then call the ray head node and Ray",
    "start": "1200299",
    "end": "1202039"
  },
  {
    "text": "workers would be created also in that",
    "start": "1202039",
    "end": "1204260"
  },
  {
    "text": "same user code context",
    "start": "1204260",
    "end": "1206299"
  },
  {
    "text": "and then underlying this platform we had",
    "start": "1206299",
    "end": "1208880"
  },
  {
    "text": "a suite of kubernetes based operators",
    "start": "1208880",
    "end": "1211880"
  },
  {
    "text": "and tools",
    "start": "1211880",
    "end": "1214280"
  },
  {
    "text": "uh just to list out a couple we had a",
    "start": "1214280",
    "end": "1216679"
  },
  {
    "text": "new observability stack which was really",
    "start": "1216679",
    "end": "1218660"
  },
  {
    "text": "valuable for letting people know if",
    "start": "1218660",
    "end": "1220280"
  },
  {
    "text": "something was using up too much memory",
    "start": "1220280",
    "end": "1222799"
  },
  {
    "text": "and then the ray clusters and auto",
    "start": "1222799",
    "end": "1226460"
  },
  {
    "text": "scaling was implemented by the kubray",
    "start": "1226460",
    "end": "1228679"
  },
  {
    "text": "and Carpenter autoscalers and I",
    "start": "1228679",
    "end": "1231200"
  },
  {
    "text": "mentioned guard rails a little bit",
    "start": "1231200",
    "end": "1232640"
  },
  {
    "text": "earlier we had a system called",
    "start": "1232640",
    "end": "1234980"
  },
  {
    "text": "gatekeeper and that would ensure that",
    "start": "1234980",
    "end": "1238160"
  },
  {
    "text": "when one of the app environments was",
    "start": "1238160",
    "end": "1240500"
  },
  {
    "text": "making calls to the kubernetes API it",
    "start": "1240500",
    "end": "1243620"
  },
  {
    "text": "would have to have node selectors and",
    "start": "1243620",
    "end": "1245419"
  },
  {
    "text": "tolerations and resource requests that",
    "start": "1245419",
    "end": "1247820"
  },
  {
    "text": "kept users in a state that they could",
    "start": "1247820",
    "end": "1252380"
  },
  {
    "text": "max out their own allocation but not",
    "start": "1252380",
    "end": "1253880"
  },
  {
    "text": "harm each other's work",
    "start": "1253880",
    "end": "1256960"
  },
  {
    "text": "and what we're really going for here was",
    "start": "1257840",
    "end": "1259880"
  },
  {
    "text": "high availability so there were about",
    "start": "1259880",
    "end": "1262280"
  },
  {
    "text": "two outages two really big outages and a",
    "start": "1262280",
    "end": "1264740"
  },
  {
    "text": "six months up to this re-architecture",
    "start": "1264740",
    "end": "1267140"
  },
  {
    "text": "and in 12 months following the switch",
    "start": "1267140",
    "end": "1269840"
  },
  {
    "text": "towards using Ray for parallelism there",
    "start": "1269840",
    "end": "1272840"
  },
  {
    "text": "were there have been no outages",
    "start": "1272840",
    "end": "1275539"
  },
  {
    "text": "but apart from that the capacity of the",
    "start": "1275539",
    "end": "1277400"
  },
  {
    "text": "overall system has grown exponentially",
    "start": "1277400",
    "end": "1281179"
  },
  {
    "text": "um with the daxter-based parallelism it",
    "start": "1281179",
    "end": "1283280"
  },
  {
    "text": "was possible to get about a thousand",
    "start": "1283280",
    "end": "1285020"
  },
  {
    "text": "sometimes ten thousand cores but you're",
    "start": "1285020",
    "end": "1287419"
  },
  {
    "text": "always straining the cluster quite a bit",
    "start": "1287419",
    "end": "1289480"
  },
  {
    "text": "with the array and the cube Ray",
    "start": "1289480",
    "end": "1292039"
  },
  {
    "text": "architecture the main limitation really",
    "start": "1292039",
    "end": "1294919"
  },
  {
    "text": "is the cost and the amount of money you",
    "start": "1294919",
    "end": "1296539"
  },
  {
    "text": "want to spend on hosts the scaling",
    "start": "1296539",
    "end": "1298940"
  },
  {
    "text": "bottlenecks completely been removed",
    "start": "1298940",
    "end": "1301460"
  },
  {
    "text": "and I think one of the best things that",
    "start": "1301460",
    "end": "1304340"
  },
  {
    "text": "we take forward out of this is that the",
    "start": "1304340",
    "end": "1306020"
  },
  {
    "text": "productivity of the team was increased",
    "start": "1306020",
    "end": "1307580"
  },
  {
    "text": "by switching most of the workloads away",
    "start": "1307580",
    "end": "1310340"
  },
  {
    "text": "from being distributed and towards a",
    "start": "1310340",
    "end": "1312860"
  },
  {
    "text": "single host in a multi-processing",
    "start": "1312860",
    "end": "1314600"
  },
  {
    "text": "environment this is great because it",
    "start": "1314600",
    "end": "1318100"
  },
  {
    "text": "runs the code in the same way it would",
    "start": "1318100",
    "end": "1320360"
  },
  {
    "text": "run on their laptop and it's easier to",
    "start": "1320360",
    "end": "1323059"
  },
  {
    "text": "monitor a single host rather than a",
    "start": "1323059",
    "end": "1326780"
  },
  {
    "text": "cluster of machines",
    "start": "1326780",
    "end": "1330100"
  },
  {
    "text": "so the uh these are a few takeaways I'd",
    "start": "1330559",
    "end": "1333620"
  },
  {
    "text": "like to leave you with so that when",
    "start": "1333620",
    "end": "1336260"
  },
  {
    "text": "you're Building Systems like this you",
    "start": "1336260",
    "end": "1338240"
  },
  {
    "text": "can hopefully uh",
    "start": "1338240",
    "end": "1340760"
  },
  {
    "text": "take our experiences and and uh and move",
    "start": "1340760",
    "end": "1344659"
  },
  {
    "text": "forward with them",
    "start": "1344659",
    "end": "1346280"
  },
  {
    "text": "uh it's funny at Ray Summit saying avoid",
    "start": "1346280",
    "end": "1348559"
  },
  {
    "text": "distributed computing but if you can run",
    "start": "1348559",
    "end": "1350960"
  },
  {
    "text": "everything you you've possibly can in a",
    "start": "1350960",
    "end": "1353120"
  },
  {
    "text": "single machine and then once you can't",
    "start": "1353120",
    "end": "1356419"
  },
  {
    "text": "get a larger machine or you're spending",
    "start": "1356419",
    "end": "1358700"
  },
  {
    "text": "too much money on that machine it's",
    "start": "1358700",
    "end": "1360020"
  },
  {
    "text": "great to just start taking on the uh",
    "start": "1360020",
    "end": "1363860"
  },
  {
    "text": "complexity of distributed computing when",
    "start": "1363860",
    "end": "1365960"
  },
  {
    "text": "you do that though invest in",
    "start": "1365960",
    "end": "1367460"
  },
  {
    "text": "observability because you will lose a",
    "start": "1367460",
    "end": "1370400"
  },
  {
    "text": "single thread of logs and and metrics",
    "start": "1370400",
    "end": "1372200"
  },
  {
    "text": "and and suddenly everything will get a",
    "start": "1372200",
    "end": "1374360"
  },
  {
    "text": "bit harder to manage",
    "start": "1374360",
    "end": "1376000"
  },
  {
    "text": "and the uh this overall method of giving",
    "start": "1376000",
    "end": "1379400"
  },
  {
    "text": "people python apis so that they can",
    "start": "1379400",
    "end": "1380840"
  },
  {
    "text": "annotate and then scale out is really",
    "start": "1380840",
    "end": "1383720"
  },
  {
    "text": "powerful just help people understand the",
    "start": "1383720",
    "end": "1386900"
  },
  {
    "text": "semantics and and give them guard rails",
    "start": "1386900",
    "end": "1389000"
  },
  {
    "text": "for the underlying apis that they're",
    "start": "1389000",
    "end": "1390380"
  },
  {
    "text": "using",
    "start": "1390380",
    "end": "1391760"
  },
  {
    "text": "and when you allow data scientists to",
    "start": "1391760",
    "end": "1394760"
  },
  {
    "text": "create python applications that that do",
    "start": "1394760",
    "end": "1397640"
  },
  {
    "text": "scale out like this uh try and decouple",
    "start": "1397640",
    "end": "1399860"
  },
  {
    "text": "the structural application from the",
    "start": "1399860",
    "end": "1401240"
  },
  {
    "text": "infrastructure load to the one python",
    "start": "1401240",
    "end": "1403159"
  },
  {
    "text": "application for one pod was a problem",
    "start": "1403159",
    "end": "1404840"
  },
  {
    "text": "and that's something you should avoid",
    "start": "1404840",
    "end": "1406700"
  },
  {
    "text": "and finally I can really highly",
    "start": "1406700",
    "end": "1408679"
  },
  {
    "text": "recommend combining Cube Ray and",
    "start": "1408679",
    "end": "1410480"
  },
  {
    "text": "Carpenter if you are on AWS it's been a",
    "start": "1410480",
    "end": "1413360"
  },
  {
    "text": "combination that gives people a ton of",
    "start": "1413360",
    "end": "1415039"
  },
  {
    "text": "agency to uh to essentially bottleneck",
    "start": "1415039",
    "end": "1418340"
  },
  {
    "text": "only by the amount of money they want to",
    "start": "1418340",
    "end": "1419900"
  },
  {
    "text": "spend on cloud instances uh like",
    "start": "1419900",
    "end": "1422659"
  },
  {
    "text": "technically speaking it was really",
    "start": "1422659",
    "end": "1424400"
  },
  {
    "text": "robust",
    "start": "1424400",
    "end": "1426380"
  },
  {
    "text": "some really quick reflection uh this was",
    "start": "1426380",
    "end": "1429020"
  },
  {
    "text": "a very meaningful piece of work for me",
    "start": "1429020",
    "end": "1431120"
  },
  {
    "text": "and obviously I want to talk about in",
    "start": "1431120",
    "end": "1433340"
  },
  {
    "text": "context of the people involved",
    "start": "1433340",
    "end": "1434919"
  },
  {
    "text": "throughout covids just in England where",
    "start": "1434919",
    "end": "1437240"
  },
  {
    "text": "the project ran there were 1 million",
    "start": "1437240",
    "end": "1439159"
  },
  {
    "text": "Hospital admissions with covid",
    "start": "1439159",
    "end": "1441320"
  },
  {
    "text": "and really sadly",
    "start": "1441320",
    "end": "1443360"
  },
  {
    "text": "um almost 200 000 people in uh in",
    "start": "1443360",
    "end": "1445640"
  },
  {
    "text": "England have covid-19 on their desktop",
    "start": "1445640",
    "end": "1448159"
  },
  {
    "text": "so uh this was extremely challenging",
    "start": "1448159",
    "end": "1451400"
  },
  {
    "text": "situation and uh and a impactful project",
    "start": "1451400",
    "end": "1456440"
  },
  {
    "text": "um but you've got to look at the numbers",
    "start": "1456440",
    "end": "1457460"
  },
  {
    "text": "and understand that Ai and Healthcare is",
    "start": "1457460",
    "end": "1460340"
  },
  {
    "text": "in its early days and I'm really",
    "start": "1460340",
    "end": "1462080"
  },
  {
    "text": "optimistic that continuing to have",
    "start": "1462080",
    "end": "1464179"
  },
  {
    "text": "initiatives like these is is going to",
    "start": "1464179",
    "end": "1465980"
  },
  {
    "text": "save and improve lives long into the",
    "start": "1465980",
    "end": "1468140"
  },
  {
    "text": "future",
    "start": "1468140",
    "end": "1470240"
  },
  {
    "text": "so thanks so much for listening",
    "start": "1470240",
    "end": "1472520"
  },
  {
    "text": "um and just a few acknowledgments like",
    "start": "1472520",
    "end": "1474440"
  },
  {
    "text": "big shout out to the faculty early",
    "start": "1474440",
    "end": "1476539"
  },
  {
    "text": "warning system team and the staff in the",
    "start": "1476539",
    "end": "1478580"
  },
  {
    "text": "NHS that made this project happen",
    "start": "1478580",
    "end": "1480620"
  },
  {
    "text": "and also to the open source Community",
    "start": "1480620",
    "end": "1483799"
  },
  {
    "text": "um I mentioned Cube Ray and Dave's quite",
    "start": "1483799",
    "end": "1485900"
  },
  {
    "text": "a bit here but there are so many",
    "start": "1485900",
    "end": "1487039"
  },
  {
    "text": "projects that have uh that have helped",
    "start": "1487039",
    "end": "1489799"
  },
  {
    "text": "make this early morning system come",
    "start": "1489799",
    "end": "1492620"
  },
  {
    "text": "together so uh thank you everyone that",
    "start": "1492620",
    "end": "1494780"
  },
  {
    "text": "is involved in the open source community",
    "start": "1494780",
    "end": "1497059"
  },
  {
    "text": "and with that and by the way if you want",
    "start": "1497059",
    "end": "1500120"
  },
  {
    "text": "to read more about this or listen to the",
    "start": "1500120",
    "end": "1501500"
  },
  {
    "text": "podcast that I I did with uh Ben ahead",
    "start": "1501500",
    "end": "1504380"
  },
  {
    "text": "of this talk uh go to truebid treebed.io",
    "start": "1504380",
    "end": "1507039"
  },
  {
    "text": "and if you're building anything and you",
    "start": "1507039",
    "end": "1509360"
  },
  {
    "text": "want to chat about it reach out and and",
    "start": "1509360",
    "end": "1510860"
  },
  {
    "text": "connect with with us on the socials",
    "start": "1510860",
    "end": "1514580"
  },
  {
    "text": "um so there's just a few minutes left",
    "start": "1514580",
    "end": "1516740"
  },
  {
    "text": "for questions uh anything that anyone's",
    "start": "1516740",
    "end": "1519080"
  },
  {
    "text": "curious about going over uh there's a",
    "start": "1519080",
    "end": "1521299"
  },
  {
    "text": "bit more time so feel free to ask some",
    "start": "1521299",
    "end": "1524059"
  },
  {
    "text": "questions",
    "start": "1524059",
    "end": "1526299"
  },
  {
    "text": "hey",
    "start": "1530179",
    "end": "1532720"
  },
  {
    "text": "um how accurate was the system and also",
    "start": "1533000",
    "end": "1535760"
  },
  {
    "text": "how were the",
    "start": "1535760",
    "end": "1538840"
  },
  {
    "text": "more the hospitalization rate",
    "start": "1545779",
    "end": "1549340"
  },
  {
    "text": "yeah um so for how accurate the system",
    "start": "1556880",
    "end": "1559159"
  },
  {
    "text": "is",
    "start": "1559159",
    "end": "1560240"
  },
  {
    "text": "um I have to admit that at the",
    "start": "1560240",
    "end": "1561919"
  },
  {
    "text": "infrastructure level I was quite",
    "start": "1561919",
    "end": "1563120"
  },
  {
    "text": "insulated from the day-to-day operation",
    "start": "1563120",
    "end": "1564860"
  },
  {
    "text": "of the models",
    "start": "1564860",
    "end": "1566179"
  },
  {
    "text": "um I I would recommend checking out the",
    "start": "1566179",
    "end": "1568340"
  },
  {
    "text": "uh the faculty's website to understand",
    "start": "1568340",
    "end": "1570980"
  },
  {
    "text": "that in more detail it's faculty.ai uh",
    "start": "1570980",
    "end": "1573620"
  },
  {
    "text": "they put a case study on it and for",
    "start": "1573620",
    "end": "1576080"
  },
  {
    "text": "different variants",
    "start": "1576080",
    "end": "1577820"
  },
  {
    "text": "um we're quite focused on the operation",
    "start": "1577820",
    "end": "1579440"
  },
  {
    "text": "of hospitals and uh so we were living",
    "start": "1579440",
    "end": "1582500"
  },
  {
    "text": "much more in the world of Admissions and",
    "start": "1582500",
    "end": "1584539"
  },
  {
    "text": "intensive care beds",
    "start": "1584539",
    "end": "1586760"
  },
  {
    "text": "um but there were notable uh spikes in",
    "start": "1586760",
    "end": "1590659"
  },
  {
    "text": "uh covered rates as new variants",
    "start": "1590659",
    "end": "1592820"
  },
  {
    "text": "occurred and so this system under the",
    "start": "1592820",
    "end": "1595820"
  },
  {
    "text": "hood used the idea of waves that would",
    "start": "1595820",
    "end": "1597980"
  },
  {
    "text": "be configured so there was like the",
    "start": "1597980",
    "end": "1600140"
  },
  {
    "text": "first main wave of covid and then there",
    "start": "1600140",
    "end": "1603020"
  },
  {
    "text": "were a series of ways like for example",
    "start": "1603020",
    "end": "1604460"
  },
  {
    "text": "there's the Omicron variant in uh",
    "start": "1604460",
    "end": "1606740"
  },
  {
    "text": "December of 2021 I think so they thought",
    "start": "1606740",
    "end": "1609620"
  },
  {
    "text": "about it in waves more than variants",
    "start": "1609620",
    "end": "1611740"
  },
  {
    "text": "and in terms of like finding more",
    "start": "1611740",
    "end": "1614779"
  },
  {
    "text": "features and use cases I think they uh",
    "start": "1614779",
    "end": "1619900"
  },
  {
    "text": "experimented quite a bit with different",
    "start": "1619900",
    "end": "1622820"
  },
  {
    "text": "features for the for the models and and",
    "start": "1622820",
    "end": "1625039"
  },
  {
    "text": "different data sources but overall uh",
    "start": "1625039",
    "end": "1628220"
  },
  {
    "text": "they kept it quite simple",
    "start": "1628220",
    "end": "1631360"
  },
  {
    "text": "hey",
    "start": "1635000",
    "end": "1637539"
  },
  {
    "text": "yeah gatekeeper is is really effective",
    "start": "1640900",
    "end": "1644779"
  },
  {
    "text": "at creating like platforms based on",
    "start": "1644779",
    "end": "1647059"
  },
  {
    "text": "kubernetes",
    "start": "1647059",
    "end": "1648740"
  },
  {
    "text": "um the way it works is that if you've",
    "start": "1648740",
    "end": "1650480"
  },
  {
    "text": "got someone that you want to give them",
    "start": "1650480",
    "end": "1651919"
  },
  {
    "text": "kubernetes API access for example using",
    "start": "1651919",
    "end": "1655279"
  },
  {
    "text": "Cube Ray or dagster you might want to",
    "start": "1655279",
    "end": "1658640"
  },
  {
    "text": "ensure that their resources are capped",
    "start": "1658640",
    "end": "1660860"
  },
  {
    "text": "at let's say 64 gigabytes per pod",
    "start": "1660860",
    "end": "1664539"
  },
  {
    "text": "and the way that we found it most",
    "start": "1664539",
    "end": "1667460"
  },
  {
    "text": "effective is using the kubernetes",
    "start": "1667460",
    "end": "1670240"
  },
  {
    "text": "admission control and or webhook system",
    "start": "1670240",
    "end": "1673820"
  },
  {
    "text": "so when you install gatekeeper it will",
    "start": "1673820",
    "end": "1677059"
  },
  {
    "text": "create a kubernetes webhook and you can",
    "start": "1677059",
    "end": "1679700"
  },
  {
    "text": "configure it to say every time a pod",
    "start": "1679700",
    "end": "1681559"
  },
  {
    "text": "gets created reject the request if for",
    "start": "1681559",
    "end": "1684980"
  },
  {
    "text": "example the resource requests are too",
    "start": "1684980",
    "end": "1687200"
  },
  {
    "text": "high and you can also do more useful",
    "start": "1687200",
    "end": "1689779"
  },
  {
    "text": "things such as if there's no resource",
    "start": "1689779",
    "end": "1691880"
  },
  {
    "text": "requests on it set by default like eight",
    "start": "1691880",
    "end": "1694159"
  },
  {
    "text": "gigabytes and because most data",
    "start": "1694159",
    "end": "1696860"
  },
  {
    "text": "scientists they don't think too much",
    "start": "1696860",
    "end": "1698480"
  },
  {
    "text": "about like kubernetes API level stuff",
    "start": "1698480",
    "end": "1700159"
  },
  {
    "text": "and they shouldn't have to",
    "start": "1700159",
    "end": "1701539"
  },
  {
    "text": "so gatekeeper lets you feel a lot of",
    "start": "1701539",
    "end": "1703460"
  },
  {
    "text": "those those sensible defaults and and",
    "start": "1703460",
    "end": "1705320"
  },
  {
    "text": "give people guardrails",
    "start": "1705320",
    "end": "1708399"
  },
  {
    "text": "any other questions",
    "start": "1712640",
    "end": "1715539"
  },
  {
    "text": "anyone yeah",
    "start": "1715700",
    "end": "1718899"
  },
  {
    "text": "yeah",
    "start": "1720559",
    "end": "1721700"
  },
  {
    "text": "um overall there was a constant process",
    "start": "1721700",
    "end": "1725000"
  },
  {
    "text": "of pulling in data every day and",
    "start": "1725000",
    "end": "1727159"
  },
  {
    "text": "retraining the models because this was a",
    "start": "1727159",
    "end": "1729080"
  },
  {
    "text": "Time series forecasting problem you know",
    "start": "1729080",
    "end": "1731059"
  },
  {
    "text": "every day basically your models would be",
    "start": "1731059",
    "end": "1732260"
  },
  {
    "text": "out of date and so they would uh there",
    "start": "1732260",
    "end": "1735980"
  },
  {
    "text": "were two different ways of registering",
    "start": "1735980",
    "end": "1737659"
  },
  {
    "text": "data artifacts and models one was with",
    "start": "1737659",
    "end": "1740299"
  },
  {
    "text": "dagster which has it doesn't just",
    "start": "1740299",
    "end": "1742400"
  },
  {
    "text": "orchestrate workflows it also lets you",
    "start": "1742400",
    "end": "1744200"
  },
  {
    "text": "like track data versions but ml flow is",
    "start": "1744200",
    "end": "1747380"
  },
  {
    "text": "slightly more dedicated one so there",
    "start": "1747380",
    "end": "1749299"
  },
  {
    "text": "were a couple of teams and one of them",
    "start": "1749299",
    "end": "1750740"
  },
  {
    "text": "used dagster for tracking artifacts but",
    "start": "1750740",
    "end": "1752600"
  },
  {
    "text": "the other one used mlflow and personally",
    "start": "1752600",
    "end": "1755120"
  },
  {
    "text": "I found ml flow to be slightly better",
    "start": "1755120",
    "end": "1756980"
  },
  {
    "text": "for when you needed to import data",
    "start": "1756980",
    "end": "1758720"
  },
  {
    "text": "around afterwards",
    "start": "1758720",
    "end": "1761500"
  },
  {
    "text": "to that answer your question",
    "start": "1763880",
    "end": "1767020"
  },
  {
    "text": "thank you",
    "start": "1769580",
    "end": "1772179"
  }
]
[
  {
    "text": "thanks for coming out everybody uh my",
    "start": "3600",
    "end": "6779"
  },
  {
    "text": "talk will be on racer for iot at samsara",
    "start": "6779",
    "end": "9000"
  },
  {
    "text": "my name is Brian Westfall and whether",
    "start": "9000",
    "end": "11460"
  },
  {
    "text": "you're here for happy hour or here to",
    "start": "11460",
    "end": "13500"
  },
  {
    "text": "hear my talk I'm happy to have you",
    "start": "13500",
    "end": "16320"
  },
  {
    "text": "so first I'll be talking about what",
    "start": "16320",
    "end": "18060"
  },
  {
    "text": "sunsara does and how we use it for",
    "start": "18060",
    "end": "20400"
  },
  {
    "text": "machine how we use uh our machine",
    "start": "20400",
    "end": "23220"
  },
  {
    "text": "learning in our products and next I'll",
    "start": "23220",
    "end": "25859"
  },
  {
    "text": "talk about how we reshaped our ml",
    "start": "25859",
    "end": "27539"
  },
  {
    "text": "inference platform with race serve and",
    "start": "27539",
    "end": "30240"
  },
  {
    "text": "lastly I'll go over some juicy tips for",
    "start": "30240",
    "end": "32040"
  },
  {
    "text": "getting the most out of production racer",
    "start": "32040",
    "end": "33840"
  },
  {
    "text": "deployments",
    "start": "33840",
    "end": "35340"
  },
  {
    "text": "so a little bit about me I'm a senior",
    "start": "35340",
    "end": "37380"
  },
  {
    "text": "Machinery learning engineer at samsara",
    "start": "37380",
    "end": "39660"
  },
  {
    "text": "on our ml infrastructure team",
    "start": "39660",
    "end": "42180"
  },
  {
    "text": "it right now is a really exciting time",
    "start": "42180",
    "end": "43860"
  },
  {
    "text": "to be on our team because we have a lot",
    "start": "43860",
    "end": "45719"
  },
  {
    "text": "of breaths spanning focuses on",
    "start": "45719",
    "end": "47960"
  },
  {
    "text": "end-to-end ML development and if you",
    "start": "47960",
    "end": "51660"
  },
  {
    "text": "attended our talk earlier about our ml",
    "start": "51660",
    "end": "53760"
  },
  {
    "text": "platform you'd have seen where we use",
    "start": "53760",
    "end": "55680"
  },
  {
    "text": "rate where we utilize Ray to",
    "start": "55680",
    "end": "58920"
  },
  {
    "text": "ship models on the edge so like firmware",
    "start": "58920",
    "end": "61079"
  },
  {
    "text": "deployments we also conduct a lot of",
    "start": "61079",
    "end": "62879"
  },
  {
    "text": "batch jobs for training data collection",
    "start": "62879",
    "end": "64920"
  },
  {
    "text": "it's stuff that comes with it as well as",
    "start": "64920",
    "end": "67140"
  },
  {
    "text": "Cloud deployments which is mostly what",
    "start": "67140",
    "end": "68820"
  },
  {
    "text": "I'll be covering here",
    "start": "68820",
    "end": "70260"
  },
  {
    "text": "so let's talk about what steam Sarah is",
    "start": "70260",
    "end": "72780"
  },
  {
    "text": "at sensor we're building the connected",
    "start": "72780",
    "end": "75360"
  },
  {
    "text": "operations Cloud so what this is is",
    "start": "75360",
    "end": "77460"
  },
  {
    "text": "we're increasing the safety efficiency",
    "start": "77460",
    "end": "79560"
  },
  {
    "text": "and sustainability of operations that",
    "start": "79560",
    "end": "81960"
  },
  {
    "text": "power the global economy so what we're",
    "start": "81960",
    "end": "84060"
  },
  {
    "text": "really looking to do is take customers",
    "start": "84060",
    "end": "86100"
  },
  {
    "text": "and physical operations and connect them",
    "start": "86100",
    "end": "89159"
  },
  {
    "text": "to the cloud so people can get insights",
    "start": "89159",
    "end": "91020"
  },
  {
    "text": "into their data and improve their",
    "start": "91020",
    "end": "92759"
  },
  {
    "text": "operations",
    "start": "92759",
    "end": "94560"
  },
  {
    "text": "so as you can see we have a suite of",
    "start": "94560",
    "end": "96420"
  },
  {
    "text": "different products which help our",
    "start": "96420",
    "end": "98460"
  },
  {
    "text": "customers collect data about the real",
    "start": "98460",
    "end": "100140"
  },
  {
    "text": "world operations and make them",
    "start": "100140",
    "end": "101820"
  },
  {
    "text": "actionable in the cloud so our customers",
    "start": "101820",
    "end": "104400"
  },
  {
    "text": "collect sensor data from vehicles",
    "start": "104400",
    "end": "106860"
  },
  {
    "text": "through our vehicle Gateway as well as",
    "start": "106860",
    "end": "108780"
  },
  {
    "text": "dash cams they're site cams and",
    "start": "108780",
    "end": "110880"
  },
  {
    "text": "Equipment gateways and these devices are",
    "start": "110880",
    "end": "113340"
  },
  {
    "text": "cloud enabled transmitting data directly",
    "start": "113340",
    "end": "115320"
  },
  {
    "text": "to the cloud",
    "start": "115320",
    "end": "116520"
  },
  {
    "text": "where that data is synthesized and",
    "start": "116520",
    "end": "118200"
  },
  {
    "text": "delivered to your dashboard so customers",
    "start": "118200",
    "end": "120000"
  },
  {
    "text": "can make quick decisions",
    "start": "120000",
    "end": "122399"
  },
  {
    "text": "so let's talk about how we use Ai and ml",
    "start": "122399",
    "end": "124619"
  },
  {
    "text": "in our product",
    "start": "124619",
    "end": "126060"
  },
  {
    "text": "so sansar's machine learning models",
    "start": "126060",
    "end": "128099"
  },
  {
    "text": "serve millions of remote devices our",
    "start": "128099",
    "end": "130140"
  },
  {
    "text": "primary product is our AI dash cam which",
    "start": "130140",
    "end": "132180"
  },
  {
    "text": "grants Fleet managers oversight into",
    "start": "132180",
    "end": "134340"
  },
  {
    "text": "their vehicle fleets",
    "start": "134340",
    "end": "136500"
  },
  {
    "text": "into interesting events which happens",
    "start": "136500",
    "end": "138480"
  },
  {
    "text": "such as detecting crashes and",
    "start": "138480",
    "end": "140760"
  },
  {
    "text": "automatically pulling that footage and",
    "start": "140760",
    "end": "142860"
  },
  {
    "text": "also augmenting driver ability with",
    "start": "142860",
    "end": "144720"
  },
  {
    "text": "in-cab alerts such as forward Collision",
    "start": "144720",
    "end": "146940"
  },
  {
    "text": "warnings we also provide reports such as",
    "start": "146940",
    "end": "149580"
  },
  {
    "text": "unsafe unsafe driving behaviors so that",
    "start": "149580",
    "end": "152580"
  },
  {
    "text": "they can be coached upon later to keep",
    "start": "152580",
    "end": "154140"
  },
  {
    "text": "our drivers and our roads safe",
    "start": "154140",
    "end": "156959"
  },
  {
    "text": "same sorry also offers a site visibility",
    "start": "156959",
    "end": "160080"
  },
  {
    "text": "product which gives further and insight",
    "start": "160080",
    "end": "162840"
  },
  {
    "text": "into your physical operations starting",
    "start": "162840",
    "end": "164819"
  },
  {
    "text": "from the destination the warehouse",
    "start": "164819",
    "end": "167220"
  },
  {
    "text": "so these AI powered cameras detect",
    "start": "167220",
    "end": "169260"
  },
  {
    "text": "events such as movements accidents with",
    "start": "169260",
    "end": "171780"
  },
  {
    "text": "forks lifts and vehicles",
    "start": "171780",
    "end": "173700"
  },
  {
    "text": "as well as connecting physical inventory",
    "start": "173700",
    "end": "176640"
  },
  {
    "text": "movement from warehouses and shelves",
    "start": "176640",
    "end": "179760"
  },
  {
    "text": "so with that context let's talk about",
    "start": "179760",
    "end": "181319"
  },
  {
    "text": "how we adopted race serve and where it",
    "start": "181319",
    "end": "183360"
  },
  {
    "text": "fits into our ml platform",
    "start": "183360",
    "end": "186680"
  },
  {
    "text": "so to build these products we design our",
    "start": "187019",
    "end": "189060"
  },
  {
    "text": "ml platform with the following",
    "start": "189060",
    "end": "190319"
  },
  {
    "text": "principles first we wanted to empower",
    "start": "190319",
    "end": "192540"
  },
  {
    "text": "scientists we wanted to enable them to",
    "start": "192540",
    "end": "194879"
  },
  {
    "text": "contribute to their apps and jobs",
    "start": "194879",
    "end": "196620"
  },
  {
    "text": "throughout the life cycle",
    "start": "196620",
    "end": "198599"
  },
  {
    "text": "we also wanted to minimize the platform",
    "start": "198599",
    "end": "200519"
  },
  {
    "text": "switches so we didn't want to have them",
    "start": "200519",
    "end": "202200"
  },
  {
    "text": "be developing using some other API and",
    "start": "202200",
    "end": "205019"
  },
  {
    "text": "then having to develop some new language",
    "start": "205019",
    "end": "206879"
  },
  {
    "text": "or API when in production",
    "start": "206879",
    "end": "209239"
  },
  {
    "text": "simsar also has a big culture of",
    "start": "209239",
    "end": "211620"
  },
  {
    "text": "operational excellence so we uphold that",
    "start": "211620",
    "end": "213900"
  },
  {
    "text": "we want to ensure all our systems are",
    "start": "213900",
    "end": "215519"
  },
  {
    "text": "resilient and well monitored",
    "start": "215519",
    "end": "217560"
  },
  {
    "text": "and of course everybody the the key",
    "start": "217560",
    "end": "219959"
  },
  {
    "text": "topic of today is scalability and cost",
    "start": "219959",
    "end": "222599"
  },
  {
    "text": "so we wanted to make sure we're using a",
    "start": "222599",
    "end": "225360"
  },
  {
    "text": "scalable solution and then lastly we",
    "start": "225360",
    "end": "227340"
  },
  {
    "text": "want to move fast so like I think",
    "start": "227340",
    "end": "229319"
  },
  {
    "text": "everybody here you know wants to take",
    "start": "229319",
    "end": "230940"
  },
  {
    "text": "something from deployment from",
    "start": "230940",
    "end": "232799"
  },
  {
    "text": "development to deployment within the",
    "start": "232799",
    "end": "234420"
  },
  {
    "text": "date and that's what we're really trying",
    "start": "234420",
    "end": "236400"
  },
  {
    "text": "to do with our platform",
    "start": "236400",
    "end": "239299"
  },
  {
    "text": "so ultimately we chose race serve for",
    "start": "239340",
    "end": "242819"
  },
  {
    "text": "our inference platform because it",
    "start": "242819",
    "end": "244140"
  },
  {
    "text": "provided us",
    "start": "244140",
    "end": "246360"
  },
  {
    "text": "okay there's the slides generated it's a",
    "start": "246360",
    "end": "249900"
  },
  {
    "text": "consistent platform so uh our developers",
    "start": "249900",
    "end": "252420"
  },
  {
    "text": "are able to use the same apis that they",
    "start": "252420",
    "end": "254159"
  },
  {
    "text": "use in development in production so that",
    "start": "254159",
    "end": "255900"
  },
  {
    "text": "reduces the learning curve for our",
    "start": "255900",
    "end": "257459"
  },
  {
    "text": "developers we also have found great",
    "start": "257459",
    "end": "259859"
  },
  {
    "text": "scalability enhancements by adopting",
    "start": "259859",
    "end": "261780"
  },
  {
    "text": "racer so you might have heard earlier in",
    "start": "261780",
    "end": "263460"
  },
  {
    "text": "the keynote that we got 50 operational",
    "start": "263460",
    "end": "265820"
  },
  {
    "text": "reduction costs in a lot of cases we",
    "start": "265820",
    "end": "269160"
  },
  {
    "text": "reduced our latency by 10x",
    "start": "269160",
    "end": "272580"
  },
  {
    "text": "um we also just found that racer was a",
    "start": "272580",
    "end": "275160"
  },
  {
    "text": "really good API for making our our",
    "start": "275160",
    "end": "277620"
  },
  {
    "text": "pipelines unified so rather than having",
    "start": "277620",
    "end": "280500"
  },
  {
    "text": "different components doing different",
    "start": "280500",
    "end": "282540"
  },
  {
    "text": "things we're able to unify them",
    "start": "282540",
    "end": "284699"
  },
  {
    "text": "in a simple python platform and then",
    "start": "284699",
    "end": "287280"
  },
  {
    "text": "lastly with that operational excellence",
    "start": "287280",
    "end": "290100"
  },
  {
    "text": "note we're really interested in Rey and",
    "start": "290100",
    "end": "292800"
  },
  {
    "text": "keep Ray's highly available durable",
    "start": "292800",
    "end": "294419"
  },
  {
    "text": "pipeline guarantees",
    "start": "294419",
    "end": "297900"
  },
  {
    "text": "so prior to adopting race serve are back",
    "start": "297900",
    "end": "300240"
  },
  {
    "text": "and resembled this setup so we had",
    "start": "300240",
    "end": "302220"
  },
  {
    "text": "multiple Services performing different",
    "start": "302220",
    "end": "303780"
  },
  {
    "text": "steps so as events streamed in we had",
    "start": "303780",
    "end": "306600"
  },
  {
    "text": "data prep model inference and",
    "start": "306600",
    "end": "308820"
  },
  {
    "text": "persistence happening in different steps",
    "start": "308820",
    "end": "311699"
  },
  {
    "text": "this was a little lamenting because it",
    "start": "311699",
    "end": "314100"
  },
  {
    "text": "required synchronizing multiple Services",
    "start": "314100",
    "end": "315900"
  },
  {
    "text": "codes in multiple languages so we're",
    "start": "315900",
    "end": "318540"
  },
  {
    "text": "primarily a ghost shot but ml is mostly",
    "start": "318540",
    "end": "320820"
  },
  {
    "text": "in Python and we also had",
    "start": "320820",
    "end": "324020"
  },
  {
    "text": "orchestration steps that were not really",
    "start": "324020",
    "end": "326100"
  },
  {
    "text": "optimized for Hardware batching or",
    "start": "326100",
    "end": "328080"
  },
  {
    "text": "parallel execution which race serve",
    "start": "328080",
    "end": "330180"
  },
  {
    "text": "provides",
    "start": "330180",
    "end": "331919"
  },
  {
    "text": "so after moving the racer we started to",
    "start": "331919",
    "end": "334560"
  },
  {
    "text": "migrate all our business logic data prep",
    "start": "334560",
    "end": "336539"
  },
  {
    "text": "and model inference together",
    "start": "336539",
    "end": "338400"
  },
  {
    "text": "so most of all we've started to unify",
    "start": "338400",
    "end": "340860"
  },
  {
    "text": "our code base to a common location in",
    "start": "340860",
    "end": "343320"
  },
  {
    "text": "language which everyone on our ml team",
    "start": "343320",
    "end": "345240"
  },
  {
    "text": "can use so deployments can be better",
    "start": "345240",
    "end": "346979"
  },
  {
    "text": "self-served",
    "start": "346979",
    "end": "348660"
  },
  {
    "text": "we can still retain our need for dynamic",
    "start": "348660",
    "end": "351120"
  },
  {
    "text": "generation of business logic based on",
    "start": "351120",
    "end": "352740"
  },
  {
    "text": "incoming traffic and we get this the",
    "start": "352740",
    "end": "354960"
  },
  {
    "text": "scalability and optimization benefits of",
    "start": "354960",
    "end": "357600"
  },
  {
    "text": "accelerator support batching",
    "start": "357600",
    "end": "359039"
  },
  {
    "text": "parallelization as well as rapid Auto",
    "start": "359039",
    "end": "361560"
  },
  {
    "text": "scaling provided by racer without having",
    "start": "361560",
    "end": "363840"
  },
  {
    "text": "to write any of the sophisticated",
    "start": "363840",
    "end": "365340"
  },
  {
    "text": "orchestration layer ourselves",
    "start": "365340",
    "end": "368900"
  },
  {
    "text": "so I want to jump into the meat of",
    "start": "369539",
    "end": "371220"
  },
  {
    "text": "things and provide a lot of tips and",
    "start": "371220",
    "end": "372960"
  },
  {
    "text": "tricks for you if you're starting to",
    "start": "372960",
    "end": "375240"
  },
  {
    "text": "look into race serve and deploy it",
    "start": "375240",
    "end": "378479"
  },
  {
    "text": "so first off I think this is a really",
    "start": "378479",
    "end": "380160"
  },
  {
    "text": "underrated feature but Ray provides",
    "start": "380160",
    "end": "383220"
  },
  {
    "text": "tooling for profine to make the most of",
    "start": "383220",
    "end": "385560"
  },
  {
    "text": "your computation",
    "start": "385560",
    "end": "387060"
  },
  {
    "text": "so as mentioned at today's keynote this",
    "start": "387060",
    "end": "389580"
  },
  {
    "text": "is how we got a big component of our 50",
    "start": "389580",
    "end": "392039"
  },
  {
    "text": "cost reduction was really just like",
    "start": "392039",
    "end": "394460"
  },
  {
    "text": "analyzing the data so racer makes it",
    "start": "394460",
    "end": "398220"
  },
  {
    "text": "really easy for you to go in and just um",
    "start": "398220",
    "end": "400860"
  },
  {
    "text": "as you submit a bunch of requests",
    "start": "400860",
    "end": "403139"
  },
  {
    "text": "when you're in the ray dashboard you can",
    "start": "403139",
    "end": "404759"
  },
  {
    "text": "go in and hit the CPU profiling tool and",
    "start": "404759",
    "end": "407460"
  },
  {
    "text": "really see like where a lot of the time",
    "start": "407460",
    "end": "409080"
  },
  {
    "text": "is spent",
    "start": "409080",
    "end": "410400"
  },
  {
    "text": "so what we found is that a lot of the",
    "start": "410400",
    "end": "412440"
  },
  {
    "text": "time is spent on data prep downloading",
    "start": "412440",
    "end": "414600"
  },
  {
    "text": "reading or transforming data which was",
    "start": "414600",
    "end": "417360"
  },
  {
    "text": "really obvious once we looked at the",
    "start": "417360",
    "end": "419880"
  },
  {
    "text": "flame wraps one example we found was",
    "start": "419880",
    "end": "422400"
  },
  {
    "text": "that so we do a lot of video processing",
    "start": "422400",
    "end": "425400"
  },
  {
    "text": "and we found that with our computer",
    "start": "425400",
    "end": "427020"
  },
  {
    "text": "vision models they were decoding all the",
    "start": "427020",
    "end": "429479"
  },
  {
    "text": "frames and this was like a really simple",
    "start": "429479",
    "end": "431880"
  },
  {
    "text": "no op optimization that got us like 30",
    "start": "431880",
    "end": "434479"
  },
  {
    "text": "overall reduction in latency I just",
    "start": "434479",
    "end": "438060"
  },
  {
    "text": "think this is a really cool tool so",
    "start": "438060",
    "end": "439380"
  },
  {
    "text": "definitely check out Pi spice snake Fizz",
    "start": "439380",
    "end": "441960"
  },
  {
    "text": "as part of the Integrations eraser",
    "start": "441960",
    "end": "445380"
  },
  {
    "text": "so next I want to talk about how we",
    "start": "445380",
    "end": "447120"
  },
  {
    "text": "dynamically serve our models so in iot",
    "start": "447120",
    "end": "449639"
  },
  {
    "text": "we often need to personalize models",
    "start": "449639",
    "end": "451680"
  },
  {
    "text": "based on incoming traffic to give",
    "start": "451680",
    "end": "453120"
  },
  {
    "text": "customers the best experience",
    "start": "453120",
    "end": "455819"
  },
  {
    "text": "so we serve models after downloading on",
    "start": "455819",
    "end": "458340"
  },
  {
    "text": "the fly from S3 with async non-blocking",
    "start": "458340",
    "end": "461280"
  },
  {
    "text": "i o so always remember to use async in",
    "start": "461280",
    "end": "463919"
  },
  {
    "text": "your endpoints",
    "start": "463919",
    "end": "465120"
  },
  {
    "text": "the models are kept in memory for Speed",
    "start": "465120",
    "end": "467039"
  },
  {
    "text": "with an lru cache and uh shout out to",
    "start": "467039",
    "end": "470220"
  },
  {
    "text": "the team for developing there's a model",
    "start": "470220",
    "end": "472319"
  },
  {
    "text": "multiplexing feature out which is out",
    "start": "472319",
    "end": "474419"
  },
  {
    "text": "now which does a lot of this for you we",
    "start": "474419",
    "end": "476880"
  },
  {
    "text": "implemented a lot of this ourselves so",
    "start": "476880",
    "end": "478440"
  },
  {
    "text": "it's really cool to see the ray team",
    "start": "478440",
    "end": "479940"
  },
  {
    "text": "picking that up",
    "start": "479940",
    "end": "481620"
  },
  {
    "text": "um so after you're able to do this and",
    "start": "481620",
    "end": "484199"
  },
  {
    "text": "you can dynamically generate your",
    "start": "484199",
    "end": "485580"
  },
  {
    "text": "pipelines we found it's really easy to",
    "start": "485580",
    "end": "488940"
  },
  {
    "text": "delegate our model rollout management",
    "start": "488940",
    "end": "490680"
  },
  {
    "text": "outside of code into something more much",
    "start": "490680",
    "end": "493259"
  },
  {
    "text": "more controllable so we use like a",
    "start": "493259",
    "end": "494699"
  },
  {
    "text": "feature flag system to control like",
    "start": "494699",
    "end": "496380"
  },
  {
    "text": "which customers see which model",
    "start": "496380",
    "end": "498660"
  },
  {
    "text": "this also helps if your customers are on",
    "start": "498660",
    "end": "500819"
  },
  {
    "text": "like different release stages so you can",
    "start": "500819",
    "end": "503099"
  },
  {
    "text": "Target like oh this this is on the beta",
    "start": "503099",
    "end": "505319"
  },
  {
    "text": "sort of model these customers are in the",
    "start": "505319",
    "end": "507360"
  },
  {
    "text": "production model it helps us just add",
    "start": "507360",
    "end": "509520"
  },
  {
    "text": "another layer to our gradual rollout",
    "start": "509520",
    "end": "511680"
  },
  {
    "text": "process",
    "start": "511680",
    "end": "514039"
  },
  {
    "text": "cool so next I want to talk about a few",
    "start": "514260",
    "end": "517140"
  },
  {
    "text": "sort of deployment productionization",
    "start": "517140",
    "end": "520440"
  },
  {
    "text": "um",
    "start": "520440",
    "end": "521039"
  },
  {
    "text": "kind of lessons learned that we have",
    "start": "521039",
    "end": "523979"
  },
  {
    "text": "so this is our architecture about how we",
    "start": "523979",
    "end": "526320"
  },
  {
    "text": "intend to perform our deployment",
    "start": "526320",
    "end": "527820"
  },
  {
    "text": "strategy so reiterating same star is a",
    "start": "527820",
    "end": "531300"
  },
  {
    "text": "strong culture of operational excellence",
    "start": "531300",
    "end": "532980"
  },
  {
    "text": "where our top priority is making sure",
    "start": "532980",
    "end": "534720"
  },
  {
    "text": "our apps work so our requirement for",
    "start": "534720",
    "end": "536820"
  },
  {
    "text": "this is we might must handle deployments",
    "start": "536820",
    "end": "539279"
  },
  {
    "text": "gradually on sellified infrastructure so",
    "start": "539279",
    "end": "542040"
  },
  {
    "text": "this helps gives us redundancy in our",
    "start": "542040",
    "end": "543959"
  },
  {
    "text": "setup around single points of failure",
    "start": "543959",
    "end": "545519"
  },
  {
    "text": "and reduce the blast radius of any",
    "start": "545519",
    "end": "547740"
  },
  {
    "text": "issues so we achieved this by splitting",
    "start": "547740",
    "end": "550260"
  },
  {
    "text": "our infrastructure",
    "start": "550260",
    "end": "551899"
  },
  {
    "text": "our customer traffic across different",
    "start": "551899",
    "end": "554279"
  },
  {
    "text": "cells so like 10 percent of customers",
    "start": "554279",
    "end": "557100"
  },
  {
    "text": "would be on one cell",
    "start": "557100",
    "end": "558720"
  },
  {
    "text": "Etc another one on another one and we",
    "start": "558720",
    "end": "561480"
  },
  {
    "text": "gradually increase that and deploy",
    "start": "561480",
    "end": "563880"
  },
  {
    "text": "across each cell",
    "start": "563880",
    "end": "565640"
  },
  {
    "text": "to get this sort of like a canary effect",
    "start": "565640",
    "end": "568200"
  },
  {
    "text": "so we do this with a git Ops pattern",
    "start": "568200",
    "end": "570300"
  },
  {
    "text": "facilitated by Argo CD",
    "start": "570300",
    "end": "572519"
  },
  {
    "text": "so another keynote is that we also",
    "start": "572519",
    "end": "575100"
  },
  {
    "text": "release our models with a shadow",
    "start": "575100",
    "end": "576720"
  },
  {
    "text": "deployment",
    "start": "576720",
    "end": "577860"
  },
  {
    "text": "this is an industry standard for staging",
    "start": "577860",
    "end": "579959"
  },
  {
    "text": "where we replicate all the traffic prior",
    "start": "579959",
    "end": "582300"
  },
  {
    "text": "to customer release this really helps us",
    "start": "582300",
    "end": "584279"
  },
  {
    "text": "capture and identify bugs we can",
    "start": "584279",
    "end": "587220"
  },
  {
    "text": "identify any like data drift prior to",
    "start": "587220",
    "end": "589440"
  },
  {
    "text": "customers actually",
    "start": "589440",
    "end": "591360"
  },
  {
    "text": "seeing the data or or getting the ml",
    "start": "591360",
    "end": "594120"
  },
  {
    "text": "models released",
    "start": "594120",
    "end": "596279"
  },
  {
    "text": "cool and then lastly",
    "start": "596279",
    "end": "600060"
  },
  {
    "text": "um while coming up with our",
    "start": "600060",
    "end": "601380"
  },
  {
    "text": "productionization story uh we found that",
    "start": "601380",
    "end": "603959"
  },
  {
    "text": "we needed an answer for issuing uh",
    "start": "603959",
    "end": "606420"
  },
  {
    "text": "cluster upgrades for things like",
    "start": "606420",
    "end": "608160"
  },
  {
    "text": "security patches Etc so anybody's at",
    "start": "608160",
    "end": "610740"
  },
  {
    "text": "work that's working in Enterprise you're",
    "start": "610740",
    "end": "612540"
  },
  {
    "text": "probably going to encounter this too so",
    "start": "612540",
    "end": "614339"
  },
  {
    "text": "you really want to make sure you have a",
    "start": "614339",
    "end": "615899"
  },
  {
    "text": "an action point in place to handle all",
    "start": "615899",
    "end": "618839"
  },
  {
    "text": "these sorts of like different upgrades",
    "start": "618839",
    "end": "620160"
  },
  {
    "text": "across your system so we manage this",
    "start": "620160",
    "end": "622860"
  },
  {
    "text": "with a similar setup as before kind of",
    "start": "622860",
    "end": "625260"
  },
  {
    "text": "like a blue green setup with a replica",
    "start": "625260",
    "end": "627740"
  },
  {
    "text": "cluster where all research all resources",
    "start": "627740",
    "end": "630779"
  },
  {
    "text": "are generated by terraform and we",
    "start": "630779",
    "end": "632880"
  },
  {
    "text": "balance the traffic at the cluster",
    "start": "632880",
    "end": "634440"
  },
  {
    "text": "management at prior to deployment",
    "start": "634440",
    "end": "639140"
  },
  {
    "text": "cool so that's my talk thanks for",
    "start": "639180",
    "end": "641399"
  },
  {
    "text": "sticking around",
    "start": "641399",
    "end": "642959"
  },
  {
    "text": "um and of course I'm sorry samsara AI",
    "start": "642959",
    "end": "645360"
  },
  {
    "text": "team is growing a lot and if you're",
    "start": "645360",
    "end": "647519"
  },
  {
    "text": "interested in working on real world",
    "start": "647519",
    "end": "649320"
  },
  {
    "text": "physical operations engineering problems",
    "start": "649320",
    "end": "652260"
  },
  {
    "text": "in the iot space uh we'd like to hear",
    "start": "652260",
    "end": "655200"
  },
  {
    "text": "from you",
    "start": "655200",
    "end": "656040"
  },
  {
    "text": "or if you just want to chat more about",
    "start": "656040",
    "end": "657540"
  },
  {
    "text": "race serve if you're checking it out I'm",
    "start": "657540",
    "end": "660060"
  },
  {
    "text": "on the race slack please hit me up I'd",
    "start": "660060",
    "end": "663180"
  },
  {
    "text": "love to chat more and compare notes",
    "start": "663180",
    "end": "664680"
  },
  {
    "text": "thank you",
    "start": "664680",
    "end": "667700"
  }
]
[
  {
    "start": "0",
    "end": "32000"
  },
  {
    "text": "good afternoon everyone uh it's really nice to be joining you here I know it's a hot day outside hopefully after this",
    "start": "2679",
    "end": "8480"
  },
  {
    "text": "talk I can convince you that our gpus run even harder uh so I'm Paris I'm one",
    "start": "8480",
    "end": "14000"
  },
  {
    "text": "of the co-founders and the CEO of genmo and uh we are pioneers in video generation uh and we are a diffusion",
    "start": "14000",
    "end": "20320"
  },
  {
    "text": "model lab today I'm going to share a bit about our journey uh from Academia to founding genmo and talk about some of",
    "start": "20320",
    "end": "26880"
  },
  {
    "text": "the Innovative systems that we've built to handle enormous scale and growth grow over the past year and uh and a",
    "start": "26880",
    "end": "33079"
  },
  {
    "start": "32000",
    "end": "145000"
  },
  {
    "text": "half and so before diving in I want to just talk about our highle mission for us the driving forc to work on General",
    "start": "33079",
    "end": "39559"
  },
  {
    "text": "is the question what if what if the cost to turn your stories into ideas and cinematic content were zero it would",
    "start": "39559",
    "end": "46760"
  },
  {
    "text": "enable a world where you could go on and turn on a faucet and video comes out and it's all beautiful cinematic incredible",
    "start": "46760",
    "end": "53680"
  },
  {
    "text": "storytelling good stories can come from anywhere and so what happens when anyone can make an award-winning film with a",
    "start": "53680",
    "end": "59239"
  },
  {
    "text": "push of a button on phone and at genmo we're working to make this a reality by building the world's best texted video",
    "start": "59239",
    "end": "65518"
  },
  {
    "text": "engine and the way we're doing that is by pre-training a large video model for video",
    "start": "65519",
    "end": "72000"
  },
  {
    "text": "generation and I think that large language models you've heard a ton about it today at the ray Summit they",
    "start": "72000",
    "end": "77200"
  },
  {
    "text": "represent very much the left brain of artificial general intelligence that's reasoning logic information processing",
    "start": "77200",
    "end": "85280"
  },
  {
    "text": "llms are the canonical architecture in this camp with amazing advances in domains like coding and chat",
    "start": "85280",
    "end": "92799"
  },
  {
    "text": "GPT but the right brain remains extremely underdeveloped today I believe",
    "start": "93720",
    "end": "99320"
  },
  {
    "text": "creativity and Imagination are still severely lacking in the modern llm Paradigm and at JMA we believe that",
    "start": "99320",
    "end": "105880"
  },
  {
    "text": "unlocking this right brain is the next Frontier in AI development by building video generation models that can",
    "start": "105880",
    "end": "112399"
  },
  {
    "text": "simulate anything real or impossible we are giving AI the ability",
    "start": "112399",
    "end": "118079"
  },
  {
    "text": "to create visualize and explore synthetic realities and we believe these models",
    "start": "118079",
    "end": "123920"
  },
  {
    "text": "serve as World simulators expanding ai's potential Beyond problem solving into creative",
    "start": "123920",
    "end": "129959"
  },
  {
    "text": "exploration the canonical architecture on this side of the camp is diffusion models which have Roots back in 2015 I'm",
    "start": "129959",
    "end": "136440"
  },
  {
    "text": "very privileged to be able to work with two of the co-authors on the ddpm paper which is one of the foundational architectures for diffusion uh at",
    "start": "136440",
    "end": "145239"
  },
  {
    "start": "145000",
    "end": "200000"
  },
  {
    "text": "genmo and I also believe video is Ultimate creative modality as it is the ultimate form of",
    "start": "145239",
    "end": "150360"
  },
  {
    "text": "communication even here so much of what I'm saying to you is from my expressions and from my uh body language not in what",
    "start": "150360",
    "end": "156680"
  },
  {
    "text": "I'm saying and so it combines audio text images and 3D worlds together in a",
    "start": "156680",
    "end": "163760"
  },
  {
    "text": "really deep way so Geno we are a fundamental research lab dedicated to visual",
    "start": "163760",
    "end": "170239"
  },
  {
    "text": "intelligence our Flagship product is replay which is an advanced Foundation model for video",
    "start": "170239",
    "end": "176560"
  },
  {
    "text": "generation and so given a text prompt or an image prompt prompt replay will",
    "start": "176560",
    "end": "182200"
  },
  {
    "text": "generate fluid cinematic High Fidelity uh videos and in this video you can see",
    "start": "182200",
    "end": "187640"
  },
  {
    "text": "there's really interesting water effect uh effects reflection of light on the water surface also realistically",
    "start": "187640",
    "end": "193840"
  },
  {
    "text": "replicated and so it's a very powerful based technology for Creative",
    "start": "193840",
    "end": "200000"
  },
  {
    "start": "200000",
    "end": "343000"
  },
  {
    "text": "exploration I'm here to talk to you about how we've scaled the product over the last year and a half of our company's life we now have more than 1",
    "start": "200000",
    "end": "206720"
  },
  {
    "text": "and a half million users on our product at scale in plus countries uh you can actually use it today by going to genmo",
    "start": "206720",
    "end": "213599"
  },
  {
    "text": "while you're watching this but just to give you a quick overview of the entn experience you can pop in any prompt and",
    "start": "213599",
    "end": "219319"
  },
  {
    "text": "very quickly under the hood we're provisioning a big Fleet of seress gpus in 20 plus data centers across the",
    "start": "219319",
    "end": "225480"
  },
  {
    "text": "world and so we'll see these workloads begin to schedule as it gets placed into different Cloud",
    "start": "225480",
    "end": "231560"
  },
  {
    "text": "providers and videos begin to generate So within 10 seconds uh we have pixels",
    "start": "231560",
    "end": "237000"
  },
  {
    "text": "streaming off of the gpus to your browser and really proud to have the lowest time to First pixel in the entire",
    "start": "237000",
    "end": "242599"
  },
  {
    "text": "industry some of these videos have hallucinations like this dog swimming has fins so I do actually think it's",
    "start": "242599",
    "end": "248439"
  },
  {
    "text": "nice when you can have hallucinations as a feature not a bug but I I'll go ahead and give this a few",
    "start": "248439",
    "end": "254720"
  },
  {
    "text": "more seconds to complete and you'll see that the streaming is actually really powerful so",
    "start": "254720",
    "end": "260919"
  },
  {
    "text": "I'll talk about this in the talk but this enables us to achieve both latency uh low latency of generation and high",
    "start": "260919",
    "end": "267800"
  },
  {
    "text": "throughput so the first generation should be completing",
    "start": "267800",
    "end": "272479"
  },
  {
    "text": "shortly and there we have a fluid video again a very seamless video here of a dog",
    "start": "274960",
    "end": "281280"
  },
  {
    "text": "swimming and I'll go through some of the other Generations here um and again some of them have hallucinations some of them",
    "start": "281280",
    "end": "287639"
  },
  {
    "text": "don't the technolog is very early I believe we're less than 1% of the way there to our generative video future but",
    "start": "287639",
    "end": "294520"
  },
  {
    "text": "the tech is real and you can use it at scale and many many people do",
    "start": "294520",
    "end": "300400"
  },
  {
    "text": "so I'm really excited now to talk about how we scaled from zero to more than a million users over the last year and a",
    "start": "307199",
    "end": "315080"
  },
  {
    "text": "half this forced us across many orders of magnitude as we scaled every day our",
    "start": "315080",
    "end": "320400"
  },
  {
    "text": "users create uh several multiples of the entire Netflix video catalog every day",
    "start": "320400",
    "end": "325880"
  },
  {
    "text": "in the product so I'm really excited to discuss our story as we SC this technology from the roots of really",
    "start": "325880",
    "end": "331600"
  },
  {
    "text": "Scrappy Innovation at UC Berkeley in Academia to now I'll also discuss some",
    "start": "331600",
    "end": "337360"
  },
  {
    "text": "of the technical pillars that our team has built along the way to endure this rapid",
    "start": "337360",
    "end": "342880"
  },
  {
    "text": "growth so we actually started the company just about in December 25th uh so this should have been 2022 um that",
    "start": "342880",
    "end": "349000"
  },
  {
    "start": "343000",
    "end": "473000"
  },
  {
    "text": "was Christmas 2022 um and that's when we started training our world our first textto video model at the time we",
    "start": "349000",
    "end": "356120"
  },
  {
    "text": "actually were in an AI Hacker House that I I helped set up here in TAS Oakland so we were in a hyper creative space and I",
    "start": "356120",
    "end": "361600"
  },
  {
    "text": "think it's uh wonderful that we could have this kind of energy there but that was our our founding headquarters and so",
    "start": "361600",
    "end": "366680"
  },
  {
    "text": "we started working on training the model there uh and in less than a month we had our first product out to Market so on",
    "start": "366680",
    "end": "373280"
  },
  {
    "text": "January 20th we launched the world's first public text to video product Market I think this is really important",
    "start": "373280",
    "end": "378840"
  },
  {
    "text": "because at this point of time many companies had demoed uh proofs of concept or had shown papers that had",
    "start": "378840",
    "end": "385039"
  },
  {
    "text": "done some form of video generation but at the time no product was truly public",
    "start": "385039",
    "end": "390440"
  },
  {
    "text": "and usable and we felt it was really important as academics uh who were working on this technology to ship this",
    "start": "390440",
    "end": "395759"
  },
  {
    "text": "and so at this time I started this and it was just me and my co-founder J and um you know after shipping this it",
    "start": "395759",
    "end": "401919"
  },
  {
    "text": "started to grow pretty virally but at that point in time our serving stack was pretty basic you know at launch day we",
    "start": "401919",
    "end": "408240"
  },
  {
    "text": "end up hitting I think a thousand users and I our serving stack at that point was something about just having a simple",
    "start": "408240",
    "end": "414960"
  },
  {
    "text": "autoscaler uh that provision and scaled pools of gpus it's pretty common workflow for how people do ml serving",
    "start": "414960",
    "end": "421400"
  },
  {
    "text": "today this was actually a really good solution in the early days but the challenge was how it endured",
    "start": "421400",
    "end": "428800"
  },
  {
    "text": "scale so it's funny I remember my graduation day so this is like May 2023 here actually is my adviser Yan who you",
    "start": "428800",
    "end": "435960"
  },
  {
    "text": "I'm sure you saw earlier uh with a jni and you know I as as Yan was hooding me",
    "start": "435960",
    "end": "441080"
  },
  {
    "text": "as I was walking off the stage it was really incredible to see massive user and Community engagement which was",
    "start": "441080",
    "end": "446199"
  },
  {
    "text": "vibrant and so we had just had a new launch that went viral and from there users were creating videos sharing them",
    "start": "446199",
    "end": "452919"
  },
  {
    "text": "and people would ask questions when they would post them to social media where did you make that and so we were seeing",
    "start": "452919",
    "end": "458199"
  },
  {
    "text": "tremendous growth at one point I think as we were as I was graduating we were acquiring 880,000 users a day for like a",
    "start": "458199",
    "end": "463879"
  },
  {
    "text": "short period of time obviously it was not sustain but to absorb that kind of load with massive scale GPU",
    "start": "463879",
    "end": "468919"
  },
  {
    "text": "infrastructure in the back end was extremely",
    "start": "468919",
    "end": "472599"
  },
  {
    "start": "473000",
    "end": "541000"
  },
  {
    "text": "challenging and so since then I mean growth has continued significantly and today we're clear pass more than one and",
    "start": "474000",
    "end": "480759"
  },
  {
    "text": "a half million users and we have users in more than 40 countries and this is This Global excitement is I think really",
    "start": "480759",
    "end": "487319"
  },
  {
    "text": "interesting because video is a Universal Medium uh it's not just about um having",
    "start": "487319",
    "end": "494120"
  },
  {
    "text": "um you know language models that can speak in English or any particular language video is something that can be consumed broadly and so you know we saw",
    "start": "494120",
    "end": "500560"
  },
  {
    "text": "really fast growth globally and that introduced really unique challenges from a serving perspective um that were",
    "start": "500560",
    "end": "506400"
  },
  {
    "text": "particularly unique at this point in time we operating with order thousand gpus across our entire fleet and so it's",
    "start": "506400",
    "end": "513880"
  },
  {
    "text": "very large scale as well I mean that at that footprint um I think our latest",
    "start": "513880",
    "end": "519039"
  },
  {
    "text": "data centers place somewhere in the top 50 of the top 500 and we are able to",
    "start": "519039",
    "end": "524680"
  },
  {
    "text": "accomplish this serving while remaining 11 11 times cheaper than Alternatives in the market uh with manag inferencing",
    "start": "524680",
    "end": "532120"
  },
  {
    "text": "systems so this was really critical for us to achieve scaling while managing burn because video generation is",
    "start": "532120",
    "end": "537720"
  },
  {
    "text": "incredibly resource intensive",
    "start": "537720",
    "end": "541439"
  },
  {
    "start": "541000",
    "end": "680000"
  },
  {
    "text": "and so I talked about that first level or stack which was a pretty bog standard serving stack and at 100 people one of",
    "start": "543320",
    "end": "549320"
  },
  {
    "text": "the big problems that we hit really quickly were control plane fires this",
    "start": "549320",
    "end": "554560"
  },
  {
    "text": "was particularly challenging uh and this would manifest where the product would be scaling the data plane would continue",
    "start": "554560",
    "end": "561040"
  },
  {
    "text": "serving requests but the control plane could not do orchestration and provisioning and would not uh be able to",
    "start": "561040",
    "end": "566680"
  },
  {
    "text": "serve request fast enough and so we would see significant drops in goodput and so this is unfortunate this was",
    "start": "566680",
    "end": "573000"
  },
  {
    "text": "actually especially bad because we're paying for GPS behind the scenes so control plane issues were quite costly",
    "start": "573000",
    "end": "579279"
  },
  {
    "text": "right because these were typically CPU VMS and so it was a shame that this was ball necking the GPU",
    "start": "579279",
    "end": "586360"
  },
  {
    "text": "infrastructure and one of the particular challenges we had to deal with here that I think is really interesting and unique",
    "start": "586360",
    "end": "591959"
  },
  {
    "text": "is uh with video generation with global demand there's rapid bursts and spikes",
    "start": "591959",
    "end": "597279"
  },
  {
    "text": "in capacity uh with dire neur or trial loads and so as we see a product I mean",
    "start": "597279",
    "end": "602320"
  },
  {
    "text": "here I have a screenshot from one of our monitoring dashboards this shows capacity in the fleet and you can see",
    "start": "602320",
    "end": "608279"
  },
  {
    "text": "that there are you know uh 2 to 3x Peak to trough autoscaling events and so from",
    "start": "608279",
    "end": "615120"
  },
  {
    "text": "the top to the bottom I mean the the entire cluster is cycling its footprint extremely quickly and that's tied to",
    "start": "615120",
    "end": "621200"
  },
  {
    "text": "user demand one of the other challenges is we're big Believers in large model",
    "start": "621200",
    "end": "627720"
  },
  {
    "text": "training and so we do uh we do train large video Foundation models and so",
    "start": "627720",
    "end": "632959"
  },
  {
    "text": "that means the parameters can be very large we're quite experienced now serving Docker containers with uh orders",
    "start": "632959",
    "end": "639600"
  },
  {
    "text": "tens to 100 G 100 plus gigabyte containers and so with containers that large it means that cold starts are very",
    "start": "639600",
    "end": "646519"
  },
  {
    "text": "slow uh and as we were dealing with this issue we noticed that most modern autosalers both in kubernetes and in uh",
    "start": "646519",
    "end": "653440"
  },
  {
    "text": "in Ray at the time suffered uh a lot of thrashing right and so this was interesting as a challenge for the",
    "start": "653440",
    "end": "658760"
  },
  {
    "text": "control plane because the control plane was uh responsive right many of these use say bang bang controllers or other",
    "start": "658760",
    "end": "665720"
  },
  {
    "text": "simple control loops and the challenge is when you have long boot times which is a problem that's you know",
    "start": "665720",
    "end": "672079"
  },
  {
    "text": "specifically relevant to uh large video models um at high parameters this leads",
    "start": "672079",
    "end": "677440"
  },
  {
    "text": "to a lot of resource idling but the second challenge was",
    "start": "677440",
    "end": "682680"
  },
  {
    "start": "680000",
    "end": "825000"
  },
  {
    "text": "particularly more pentious and so this was a lot more challenging I think to debug as we began to scale and this was",
    "start": "682680",
    "end": "688760"
  },
  {
    "text": "data plan fault tolerance and so what I mean here is this is referring to our GPU Fleet",
    "start": "688760",
    "end": "694120"
  },
  {
    "text": "that's actually executing the video generation first and foremost one of the first challenges we hit is video models",
    "start": "694120",
    "end": "700320"
  },
  {
    "text": "are quite hetrogeneous they're not simple like large language models with autoaggressive Transformers they rather rather have",
    "start": "700320",
    "end": "706760"
  },
  {
    "text": "many uh disparate separate parts you might have Auto encoders the actual diffusion model you might have different",
    "start": "706760",
    "end": "712240"
  },
  {
    "text": "text encoders um you might have postprocessing and video encoding which is CPU work and so hetrogeneous",
    "start": "712240",
    "end": "717480"
  },
  {
    "text": "scheduling was quite challenging to operationalize across the fleet um that",
    "start": "717480",
    "end": "723160"
  },
  {
    "text": "one was relatively simple to scale uh sorry that one was relatively simple to solve because we just moved to",
    "start": "723160",
    "end": "728240"
  },
  {
    "text": "hetrogeneous Resource pools with varying generations of gpus but at scale one",
    "start": "728240",
    "end": "733519"
  },
  {
    "text": "thing we noted is we' got to cross into hundreds and Beyond of GPU numbers of gpus is we saw very high Hardware",
    "start": "733519",
    "end": "740399"
  },
  {
    "text": "failure rates in the public cloud and this is true across multiple providers including Google cloud or AWS Mo most",
    "start": "740399",
    "end": "746680"
  },
  {
    "text": "the large hyperscalers gpus inherent are just fault prone and at this rate of 2",
    "start": "746680",
    "end": "751920"
  },
  {
    "text": "to 5% we would see slow gpus that would serve would manifest as stragglers in",
    "start": "751920",
    "end": "756959"
  },
  {
    "text": "scheduling um and we would also see sometimes they would have silent Corruptions particularly pernicious is",
    "start": "756959",
    "end": "763079"
  },
  {
    "text": "um certain workflow schedulers for example like cative and others will end up routing more and more traffic to",
    "start": "763079",
    "end": "768959"
  },
  {
    "text": "failing nodes if you don't have uh proper Health checking and that will actually lead to degraded quality of outputs and in cases where there's",
    "start": "768959",
    "end": "775079"
  },
  {
    "text": "silent failures or bit Corruptions this leads to degrade user experience and",
    "start": "775079",
    "end": "780360"
  },
  {
    "text": "it's something that's actually quite difficult to notice at scale another thing that was pretty",
    "start": "780360",
    "end": "785760"
  },
  {
    "text": "subtle is we began to roll out spot serving across our entire fleet so we could leverage very deep spot pools",
    "start": "785760",
    "end": "791120"
  },
  {
    "text": "across a variet variety of different uh Cloud providers and regions but one of the challenges here is that you often",
    "start": "791120",
    "end": "797040"
  },
  {
    "text": "face correlated preemptions across your spot fleets so when spot capacity is low",
    "start": "797040",
    "end": "803000"
  },
  {
    "text": "it hits uniformly and you'll see preemption rates Spike across your entire fleet and so you have to develop",
    "start": "803000",
    "end": "808320"
  },
  {
    "text": "systems that can remain tolerant to a big burst of capacity coming offline if you are going to use spot",
    "start": "808320",
    "end": "814959"
  },
  {
    "text": "Computing and so I I think this manifest is like the tail at scale represented again at large large uh GPU serving",
    "start": "814959",
    "end": "821199"
  },
  {
    "text": "fleets across the across our um clusters and the last problem that I",
    "start": "821199",
    "end": "827480"
  },
  {
    "start": "825000",
    "end": "1077000"
  },
  {
    "text": "think was one of the hardest actually to deal with operationally for a small team like ours is that we have a geod",
    "start": "827480",
    "end": "834079"
  },
  {
    "text": "distributed user base like I talked about video is universal anybody can create video anybody can cons Zoom video",
    "start": "834079",
    "end": "839759"
  },
  {
    "text": "even if they're not interacting with the models in English um and we do train our models to be multilingual but this is",
    "start": "839759",
    "end": "845880"
  },
  {
    "text": "something we faced really quickly sooner than a lot of large language models face and uh one of the challenges is the",
    "start": "845880",
    "end": "852680"
  },
  {
    "text": "latency can be really high and so we notice for example users in Indonesia on mobile devices would be unable to upload",
    "start": "852680",
    "end": "858480"
  },
  {
    "text": "images uh and actually schedule jobs and a a high user experience in a good user",
    "start": "858480",
    "end": "864440"
  },
  {
    "text": "experience essentially especially in face of preview streaming for example which was very latency",
    "start": "864440",
    "end": "869639"
  },
  {
    "text": "sensitive so we made a lot of key modifications to our serving stack uh to address these three challenges and one",
    "start": "869639",
    "end": "876360"
  },
  {
    "text": "of the first ones that I think was really useful for enduring load across a geod distributed fleet was introduction",
    "start": "876360",
    "end": "882519"
  },
  {
    "text": "of the GFE or the Geno front end and so this is essentially a world a cross",
    "start": "882519",
    "end": "888360"
  },
  {
    "text": "crossb deployed Service uh we operate in a 100 different points of presence where we have um Edge containers that run and",
    "start": "888360",
    "end": "894399"
  },
  {
    "text": "actually intercept requests and then interface to our backend systems and so the GF uh offered us a very natural",
    "start": "894399",
    "end": "901480"
  },
  {
    "text": "point of scheduling while reducing Network latency considerably to our end users and so as a first step this",
    "start": "901480",
    "end": "907120"
  },
  {
    "text": "allowed us to continue to get away with single Regional or single zonal serving for quite a while while still tolerating",
    "start": "907120",
    "end": "913160"
  },
  {
    "text": "diverse uh Network conditions across our user base um and so this has actually proven",
    "start": "913160",
    "end": "919800"
  },
  {
    "text": "to be really useful to have a layer uh in front of our actual core serving stack to deploy firewalls and rate",
    "start": "919800",
    "end": "926959"
  },
  {
    "text": "limiting and other additional features as we've continued to scale one of the other things we did is",
    "start": "926959",
    "end": "934040"
  },
  {
    "text": "we actually ended up building out a complete Clean Slate reimplementation of our serving stack with a predictive autoscaler this has been hugely",
    "start": "934040",
    "end": "940920"
  },
  {
    "text": "beneficial as I mentioned there's a really unique problem that we hit which was long boot times meant that simple",
    "start": "940920",
    "end": "947199"
  },
  {
    "text": "controllers like bang Bank controllers or other Auto scheduling policies um for auto scaling sorry we're not able to",
    "start": "947199",
    "end": "953920"
  },
  {
    "text": "cope with um the delays and provisioning and so what we're able to do is utilize predictive Auto scale de with smarter",
    "start": "953920",
    "end": "959759"
  },
  {
    "text": "control theoretic algorithms in order to better allocate and predictively autoscale resources as demand bursts",
    "start": "959759",
    "end": "966120"
  },
  {
    "text": "happen we found that there was some amount of predictability to the workload and so we could actually get away with this and significantly reduce Co start",
    "start": "966120",
    "end": "972880"
  },
  {
    "text": "performance and improve uh performance while cutting down on uh the tail uh of",
    "start": "972880",
    "end": "978079"
  },
  {
    "text": "a poor user experience really notably one other",
    "start": "978079",
    "end": "983440"
  },
  {
    "text": "thing we had a build and this was particularly difficult was Health checking at scale there's a million things that can go wrong and this can",
    "start": "983440",
    "end": "988519"
  },
  {
    "text": "again be memory Corruptions this can be Cuda errors error xids manifesting or",
    "start": "988519",
    "end": "994040"
  },
  {
    "text": "often we would actually just see silent Corruptions where videos just looked worse as you sampled on them and so uh",
    "start": "994040",
    "end": "1000839"
  },
  {
    "text": "this was particularly challenging and so we we have rigorous health checks and burdens that run continuously during uh",
    "start": "1000839",
    "end": "1006920"
  },
  {
    "text": "real user serving so we continue can we can continuously probe our infrastructure and ensure it's serving",
    "start": "1006920",
    "end": "1012240"
  },
  {
    "text": "results accurately and Faithfully for what we need what's also exciting is that in",
    "start": "1012240",
    "end": "1019839"
  },
  {
    "text": "order to better deal with correlated spot preemption across our Fleet we now serve in 20 plus data centers across the",
    "start": "1019839",
    "end": "1027000"
  },
  {
    "text": "world and this was kind of necessary for a product of our scale given the GPU chip crisis you know there were times I",
    "start": "1027000",
    "end": "1034000"
  },
  {
    "text": "remember that we were consuming almost every single GPU that was available in various gcp regions I mean they were",
    "start": "1034000",
    "end": "1039038"
  },
  {
    "text": "basically returning stock out in multiple different correlated uh separate regions and so at that point",
    "start": "1039039",
    "end": "1045240"
  },
  {
    "text": "you know the the the the vision of elasticity uh was really more of an illusion and so here we Multiplex across",
    "start": "1045240",
    "end": "1051840"
  },
  {
    "text": "reserved instance pools in on Prem or manage our dedicated data centers along with public clouds and work with Cloud",
    "start": "1051840",
    "end": "1058640"
  },
  {
    "text": "Partners to provision long-term reservations for compute so we can always be ahead of our compute requirement needs and so by balancing",
    "start": "1058640",
    "end": "1065320"
  },
  {
    "text": "spot Computing with reservations we maintain a high degree of elasticity for that Peak to trough Auto scaling while",
    "start": "1065320",
    "end": "1071840"
  },
  {
    "text": "significantly reducing uh aggregate cost in insuring we're not paying on demand or rack rate",
    "start": "1071840",
    "end": "1077320"
  },
  {
    "start": "1077000",
    "end": "1119000"
  },
  {
    "text": "prices one thing I'm very proud about is um our latest training supercomputer and",
    "start": "1077320",
    "end": "1082640"
  },
  {
    "text": "I talked a lot about our inferencing stack but we recently set up ice which is a new uh which is one of our newest",
    "start": "1082640",
    "end": "1088400"
  },
  {
    "text": "uh training supercomputers and so in aggregate scale if you ranked in the top 500 it would be in the top 50 at least",
    "start": "1088400",
    "end": "1094720"
  },
  {
    "text": "and it's 98% powered by carbon free energy as it's located in Iceland um and",
    "start": "1094720",
    "end": "1099799"
  },
  {
    "text": "so Iceland roughly has a 70% uh hydroelectric and 30% geothermal energy",
    "start": "1099799",
    "end": "1105000"
  },
  {
    "text": "mixture and so I think this is actually really interesting because AI doesn't have to boil the oceans it is possible",
    "start": "1105000",
    "end": "1110480"
  },
  {
    "text": "to achieve massive scale and continue to provision these large data centers while still being able to remain green and",
    "start": "1110480",
    "end": "1117200"
  },
  {
    "text": "friendly to the climate so what's next video presents a",
    "start": "1117200",
    "end": "1122480"
  },
  {
    "text": "series of extremely challenging problems for foundation models I actually believe video will be one of the hardest",
    "start": "1122480",
    "end": "1127559"
  },
  {
    "text": "Foundation models like we as a community have ever trained and I've talked about serving challenges I think that's",
    "start": "1127559",
    "end": "1133280"
  },
  {
    "text": "particularly hard and that's just one of many aspects of our entire end to Endo system stack that we've Reb built inside",
    "start": "1133280",
    "end": "1139240"
  },
  {
    "text": "of genmo to endure this scale but at a first order data is hugely challenging uh we already operate",
    "start": "1139240",
    "end": "1145960"
  },
  {
    "text": "at the multi paby scale and so that's extremely uh resource intensive and it's very hard to actually operate uh when",
    "start": "1145960",
    "end": "1152440"
  },
  {
    "text": "some of our training jobs need order terabyte per a terabyte plus per second of storage",
    "start": "1152440",
    "end": "1158640"
  },
  {
    "start": "1158000",
    "end": "1294000"
  },
  {
    "text": "IO moreover Computing infrastructure is also extremely challenging I mean if you",
    "start": "1158640",
    "end": "1164200"
  },
  {
    "text": "if you look at this I think they're roughly 100 times more expensive at minimum to serve than image models like",
    "start": "1164200",
    "end": "1170039"
  },
  {
    "text": "stable diffusion and so I remember when I when I was in student research at Google uh",
    "start": "1170039",
    "end": "1176280"
  },
  {
    "text": "the Imagine video project project that was trained in 2022 or so I believe uh the team ran out of compute quara",
    "start": "1176280",
    "end": "1181720"
  },
  {
    "text": "multiple times and just maxed them amount of uh compute that Google which seemingly has infinite computer",
    "start": "1181720",
    "end": "1186960"
  },
  {
    "text": "internally was willing to allocate so video models are really challenging and so that's fundamentally an ml systems",
    "start": "1186960",
    "end": "1193120"
  },
  {
    "text": "scaling problem third is models what's really interesting is",
    "start": "1193120",
    "end": "1199480"
  },
  {
    "text": "there's no set playbook for how you should train video models for llms I think there's no secret now the best",
    "start": "1199480",
    "end": "1204919"
  },
  {
    "text": "training recipe is pretty much public knowledge like I think anybody with enough resources and uh Talent could",
    "start": "1204919",
    "end": "1211760"
  },
  {
    "text": "actually replicate the AVR AI performance now U because architecture is known the data mixture is known all",
    "start": "1211760",
    "end": "1218799"
  },
  {
    "text": "of these details are are known within the community but for video models it's a complete Green Field and that means",
    "start": "1218799",
    "end": "1224919"
  },
  {
    "text": "architecture and systems have to be completely redesigned for examp One Challenge uniquely with models is uh",
    "start": "1224919",
    "end": "1231640"
  },
  {
    "text": "hardware systems and architecture codesign to enable long context training",
    "start": "1231640",
    "end": "1236679"
  },
  {
    "text": "for example we've put a lot of resources into this and it's a completely new area there's very little academic literature",
    "start": "1236679",
    "end": "1242159"
  },
  {
    "text": "in the in this uh space and lastly is safety I think safety is incredibly important for uh",
    "start": "1242159",
    "end": "1248080"
  },
  {
    "text": "models as they continue to scale and uh video brings in entirely new challenges",
    "start": "1248080",
    "end": "1253360"
  },
  {
    "text": "for safety you know I think it's really important that uh Foundation model",
    "start": "1253360",
    "end": "1259240"
  },
  {
    "text": "trainers work to ship their models to production and get them in the hands of real people by getting in the hands of",
    "start": "1259240",
    "end": "1264400"
  },
  {
    "text": "real people you actually learn what the attacks and defenses need to be for these systems while we're early I think",
    "start": "1264400",
    "end": "1271000"
  },
  {
    "text": "across the field of video generation nobody's going to say that this qual this content is production worthy or you",
    "start": "1271000",
    "end": "1276720"
  },
  {
    "text": "know really highend or indistinguishable yet from reality and so we are early and that means it's actually net safer to",
    "start": "1276720",
    "end": "1282760"
  },
  {
    "text": "ship real systems to real users and learn what the attacks and defenses are before this Tech gets better and so I",
    "start": "1282760",
    "end": "1288919"
  },
  {
    "text": "think that this is an incredibly interesting future area of exploration too and so our goal is to build the",
    "start": "1288919",
    "end": "1297200"
  },
  {
    "start": "1294000",
    "end": "1387000"
  },
  {
    "text": "world's uh best world simulators and these are engines that can simulate anything impossible or possible you know",
    "start": "1297200",
    "end": "1305039"
  },
  {
    "text": "today I've talked about creative applications for this technology but I think longterm video generation will",
    "start": "1305039",
    "end": "1310240"
  },
  {
    "text": "have a lot of impact to revolutionize areas even including arvr or embodied AI",
    "start": "1310240",
    "end": "1315640"
  },
  {
    "text": "I I actually spent a bunch of time in self-driving my first company I worked at was acquired by Tesla and it's",
    "start": "1315640",
    "end": "1320880"
  },
  {
    "text": "interesting cuz that space is entirely data bck and so if we had really powerful video generation models I think",
    "start": "1320880",
    "end": "1327000"
  },
  {
    "text": "the self-driving problem would become trivial so it's like if we think about this in scale you know there is where we",
    "start": "1327000",
    "end": "1332279"
  },
  {
    "text": "are today uh but over the next decade I think video will be come to be one of the most important modalities for",
    "start": "1332279",
    "end": "1337919"
  },
  {
    "text": "generative generative AI as a whole we're scaling the team really quickly today uh we are less than 15 people and",
    "start": "1337919",
    "end": "1344400"
  },
  {
    "text": "we've built this whole stack end to end and re-engineered the full stack as and really Really T are tackling really medy",
    "start": "1344400",
    "end": "1350080"
  },
  {
    "text": "systems problems but if you're excited about the boundary of ml systems um please come join us and send me an email",
    "start": "1350080",
    "end": "1356600"
  },
  {
    "text": "at pj. and I would love to take any questions now thank",
    "start": "1356600",
    "end": "1362480"
  },
  {
    "text": "you just want to invite people to use okay yeah hi please use the microphone",
    "start": "1365360",
    "end": "1370799"
  },
  {
    "text": "thank you um one of the question I'm Lear maybe basic a lot of model model",
    "start": "1370799",
    "end": "1379760"
  },
  {
    "text": "call like I tried allet how do",
    "start": "1379760",
    "end": "1385760"
  },
  {
    "text": "youil quity yeah just to repeat the question so the question was um for video models",
    "start": "1385760",
    "end": "1391679"
  },
  {
    "start": "1387000",
    "end": "1431000"
  },
  {
    "text": "how do you approach controllability and steerability um at scale is that correct yeah so I think controllability is a",
    "start": "1391679",
    "end": "1397279"
  },
  {
    "text": "really interesting emerging problem you know today the interface is text it's prompt and I think it's really",
    "start": "1397279",
    "end": "1402520"
  },
  {
    "text": "interesting because pretty much anybody can access the product across the world and they kind of have the affordance from chat GPD that they type text in and",
    "start": "1402520",
    "end": "1409039"
  },
  {
    "text": "they get video but I don't think this is actually the optimal interface I think over time you want character controlability you want to control their",
    "start": "1409039",
    "end": "1415240"
  },
  {
    "text": "dialogue you want to control character motion these are all really important parameters uh it's it's very early",
    "start": "1415240",
    "end": "1420480"
  },
  {
    "text": "though and so I think you know today the State of-the art in the field has just been prompt because it's it's kind of",
    "start": "1420480",
    "end": "1425919"
  },
  {
    "text": "like what people are used to with chat GPT",
    "start": "1425919",
    "end": "1429600"
  },
  {
    "start": "1431000",
    "end": "1498000"
  },
  {
    "text": "today do you use diffusion models in your product yes we use diffusion models",
    "start": "1431000",
    "end": "1436440"
  },
  {
    "text": "so actually my co-founder A J is was was uh one of the co-inventors of one of the foundational diffusion architectures for",
    "start": "1436440",
    "end": "1443200"
  },
  {
    "text": "the ddpm paper so we're big Believers on large diffusion models but be clear like he also invented text to 3D as a field",
    "start": "1443200",
    "end": "1449760"
  },
  {
    "text": "and so you know people ask me is it going to be straight video is it going to be 3D guided diffusion you know we",
    "start": "1449760",
    "end": "1456240"
  },
  {
    "text": "kind of sit in the middle I would say roughly between these two paradigms so do you believe that diffusion models are",
    "start": "1456240",
    "end": "1462600"
  },
  {
    "text": "the future of text to video uh models right so I think evidence seems to",
    "start": "1462600",
    "end": "1469440"
  },
  {
    "text": "indicate that diffusion models are roughly 10 something like an order of magnitude More Sample efficient than",
    "start": "1469440",
    "end": "1475159"
  },
  {
    "text": "Auto regressive models for Generation tasks and so 10x is a lot like from systems like it's it's like almost",
    "start": "1475159",
    "end": "1481039"
  },
  {
    "text": "impossible sometimes to squeeze out in order of order of magnitude efficiency um and so in light of that I do feel",
    "start": "1481039",
    "end": "1486399"
  },
  {
    "text": "very confident that diffusion is one of the is going to be one of the most competitive approaches just due to its",
    "start": "1486399",
    "end": "1491679"
  },
  {
    "text": "efficiency today thank you yeah I have one question",
    "start": "1491679",
    "end": "1497360"
  },
  {
    "text": "um you know what's the generation you know the pipeline latency like currently",
    "start": "1497360",
    "end": "1503799"
  },
  {
    "start": "1498000",
    "end": "1592000"
  },
  {
    "text": "you know you know I just tried to you know on your website it takes a couple seconds you know what's the best latency",
    "start": "1503799",
    "end": "1509000"
  },
  {
    "text": "you can get is it close to the real time right now or is it still like 5 to 10 seconds for for so seconds as we do can",
    "start": "1509000",
    "end": "1516159"
  },
  {
    "text": "you more so today just due to the sheer computational intensity of these models",
    "start": "1516159",
    "end": "1521559"
  },
  {
    "text": "for us generating a 5-second clip takes about a minute right and we could throw more Hardware at this we could throw",
    "start": "1521559",
    "end": "1527559"
  },
  {
    "text": "parallelism into do distributed inference uh but that would be cost inefficient so we choose not to do that",
    "start": "1527559",
    "end": "1533480"
  },
  {
    "text": "uh one of the things we did do is we built out a large Edge Network presence so I talked about the Gen Mill front end",
    "start": "1533480",
    "end": "1538720"
  },
  {
    "text": "in there we have actually distributed memory across our Fleet across the world right in 100 points of presence and that",
    "start": "1538720",
    "end": "1544480"
  },
  {
    "text": "serves as an essentially on demand CDN for us to do streaming and so that's what enables you to get that uh very",
    "start": "1544480",
    "end": "1550640"
  },
  {
    "text": "short time to First pixel but that was a trick we used in order to essentially balance latency and throughput",
    "start": "1550640",
    "end": "1556080"
  },
  {
    "text": "trade-offs but I I I think the question here about real time is really interesting so you know I think the way",
    "start": "1556080",
    "end": "1562279"
  },
  {
    "text": "this technology generally goes I feel is make it work and that's the stage we're in make it better and then you make it faster and the trick to make it faster",
    "start": "1562279",
    "end": "1569279"
  },
  {
    "text": "usually trades off quality like with GPT versus GPT like 4 versus 40 versus 40 mini they use distillation to do this",
    "start": "1569279",
    "end": "1575600"
  },
  {
    "text": "and other tricks and so there is a quality speed tradeoff and so I think because we're so early we've chosen just",
    "start": "1575600",
    "end": "1581720"
  },
  {
    "text": "to optimize for Quality as much as possible but I certainly do believe it will be possible it just might be very",
    "start": "1581720",
    "end": "1586760"
  },
  {
    "text": "expensive",
    "start": "1586760",
    "end": "1589760"
  },
  {
    "start": "1592000",
    "end": "1731000"
  },
  {
    "text": "thank you that's a wonderful presentation so my question is for gpus are you trying to use heterogenous GPS",
    "start": "1592679",
    "end": "1597880"
  },
  {
    "text": "like whatever you have got or are you trying to stick to a specific type like for example l4s oh yes uh we we use hetrogeneous",
    "start": "1597880",
    "end": "1606039"
  },
  {
    "text": "resource pools because of there's multiple models that we're actually serving in this entire pipeline so it's not just a single big model like with an",
    "start": "1606039",
    "end": "1612399"
  },
  {
    "text": "llm um which is considerably simpler I think or to orchestrate and scale and serve because they use homogeneous",
    "start": "1612399",
    "end": "1617720"
  },
  {
    "text": "resources um yeah and so you mentioned like l4s or t4s or there's like l40 s's which are",
    "start": "1617720",
    "end": "1622760"
  },
  {
    "text": "particularly efficient like different components can use different gpus like the core usually the most expensive part",
    "start": "1622760",
    "end": "1627880"
  },
  {
    "text": "is the core diffusion model and that's going to be served on like large scale Data Center Grade Hardware how do you",
    "start": "1627880",
    "end": "1633399"
  },
  {
    "text": "manage the this kind of coordinated approach if for example one IDC only have specific type of gpus MH yeah so",
    "start": "1633399",
    "end": "1642000"
  },
  {
    "text": "you can U as fall backs I think that's a pretty effective approach here so it just might be like less efficient or less cost efficient but like um",
    "start": "1642000",
    "end": "1648159"
  },
  {
    "text": "flexibility is like really important as you approach scale right and so as much as you can build flexibility into your systems um via failovers or points of",
    "start": "1648159",
    "end": "1655880"
  },
  {
    "text": "redundency like it's really important so that you can cut that tail um this like kind of tail uh the poor poor poor user",
    "start": "1655880",
    "end": "1662799"
  },
  {
    "text": "experience of the tail here right and so um yeah that that's an example of a particular type of problem that's actually fairly common right like you",
    "start": "1662799",
    "end": "1668919"
  },
  {
    "text": "may get stockouts in one GPU class but that may not be the case in another yeah",
    "start": "1668919",
    "end": "1674080"
  },
  {
    "text": "another thing you mentioned is you're trying to avoid on demand costs mhm um but how are you going to deal with",
    "start": "1674080",
    "end": "1680159"
  },
  {
    "text": "the surge You're just showing the image yeah um no it's really interesting I mean certainly it's not always avoidable",
    "start": "1680159",
    "end": "1687279"
  },
  {
    "text": "right but um one thing that we've been lucky with is as we just grown the uh",
    "start": "1687279",
    "end": "1693080"
  },
  {
    "text": "this Peak at trough autoscaling has become more muted right like as our product has propagated more globally um",
    "start": "1693080",
    "end": "1700039"
  },
  {
    "text": "users begin to fill in The Valleys which is kind of interesting so there is like Auto scaling but we're starting to see that stabilize and I think that's just",
    "start": "1700039",
    "end": "1706120"
  },
  {
    "text": "like driven by further globalization of our product um if if you're an INF provider or you have like a very us",
    "start": "1706120",
    "end": "1712200"
  },
  {
    "text": "Centric audience like I assume that's like something you're not going to have the luxury of doing and so it's harder to kind of have more predictability in",
    "start": "1712200",
    "end": "1718120"
  },
  {
    "text": "serving but um that's something that we're lucky like with a global user base uh they actually kind of demand fill in",
    "start": "1718120",
    "end": "1723840"
  },
  {
    "text": "quite",
    "start": "1723840",
    "end": "1726080"
  },
  {
    "text": "neatly you uh couple questions the first one is uh there's a lot of high-profile",
    "start": "1730159",
    "end": "1736120"
  },
  {
    "start": "1731000",
    "end": "1878000"
  },
  {
    "text": "uh Team there are investing in video like open as like paa right they all",
    "start": "1736120",
    "end": "1742039"
  },
  {
    "text": "like have amazing talent there just curious how uh you guys train your data or train your model be it differently uh",
    "start": "1742039",
    "end": "1749600"
  },
  {
    "text": "that can give you guys a competitive Advantage uh first question and second question hopefully okay ask one more so",
    "start": "1749600",
    "end": "1756559"
  },
  {
    "text": "I found a lot of models so some models they are use casewise it might be better in certain type of scenarios because",
    "start": "1756559",
    "end": "1763679"
  },
  {
    "text": "they train a lot that in a certain type of scenarios so just car a certain uh use cases your team or V Stone ad Excel",
    "start": "1763679",
    "end": "1771440"
  },
  {
    "text": "ad thank you I'm sorry could you repeat the second question oh the second question about user case wise right just",
    "start": "1771440",
    "end": "1777640"
  },
  {
    "text": "text to be generation like sometimes uh there's so many model out there some are better as certain situation for example",
    "start": "1777640",
    "end": "1784279"
  },
  {
    "text": "someone eating food someone changing clothes so those kind data because they train a lot so better just cares for",
    "start": "1784279",
    "end": "1790399"
  },
  {
    "text": "your team like specific us a case that you guys really good at or you trying to focus right it's really hard to be good",
    "start": "1790399",
    "end": "1797080"
  },
  {
    "text": "for generic all all type of these cases scenarios thank you yeah so I think the most important thing when I look at",
    "start": "1797080",
    "end": "1803440"
  },
  {
    "text": "video is is motion I think like the only uninteresting video truly is one that doesn't move right and so in that case",
    "start": "1803440",
    "end": "1812080"
  },
  {
    "text": "motion is the most important thing and so I think it's really interesting we view these models as World simulators and so it's really interesting how do",
    "start": "1812080",
    "end": "1818120"
  },
  {
    "text": "they how does inertia manifest in the model is Newton third's Law reflected is Optics and viscosity reflected",
    "start": "1818120",
    "end": "1824279"
  },
  {
    "text": "effectively in the model like these are fundamental properties of the world that you can measure and you can actually test in the model from a capability",
    "start": "1824279",
    "end": "1829760"
  },
  {
    "text": "standpoint uh I believe like our model is one of the better ones from from a motion standpoint right I think it has",
    "start": "1829760",
    "end": "1835960"
  },
  {
    "text": "good fluidity of motion realistic motion I think this is fundamentally really important as a broader point I think",
    "start": "1835960",
    "end": "1841159"
  },
  {
    "text": "we're so early we're 1% of the way there to our generative video future like for me it's like when can it be that like a",
    "start": "1841159",
    "end": "1847519"
  },
  {
    "text": "kid anywhere can take their phone out push a button and get an Academy Award level winning film and like I think we're years away from that we are so far",
    "start": "1847519",
    "end": "1853760"
  },
  {
    "text": "from that happening and there's so many little sub problems there and so I think of about this is just it's it's pure",
    "start": "1853760",
    "end": "1859320"
  },
  {
    "text": "technology right now and developing the best infrastructure and models ultimately co-optimize to produce the",
    "start": "1859320",
    "end": "1866399"
  },
  {
    "text": "best technology and the best models and ultimately the best motion I think that's most",
    "start": "1866399",
    "end": "1871760"
  },
  {
    "text": "important uh thanks very nice talk um I have a question um a bit open have you",
    "start": "1877960",
    "end": "1884480"
  },
  {
    "start": "1878000",
    "end": "1984000"
  },
  {
    "text": "considered having a more scientific approach for the type of uh models or inference you have I mean uh you from",
    "start": "1884480",
    "end": "1892760"
  },
  {
    "text": "what you said you have a background um that is more research like so what about",
    "start": "1892760",
    "end": "1898519"
  },
  {
    "text": "trying to find patterns from these video um outputs that we have is that on your",
    "start": "1898519",
    "end": "1904679"
  },
  {
    "text": "radar what's interesting about video models like especially in the case where their world simulators is it's kind of",
    "start": "1904679",
    "end": "1910039"
  },
  {
    "text": "like Rising tide footz all boats like improved ability to simulate some fundamental property the world just",
    "start": "1910039",
    "end": "1915480"
  },
  {
    "text": "makes all videos look more realistic whether you can Tang point to it or not and so you know we've tried like",
    "start": "1915480",
    "end": "1921200"
  },
  {
    "text": "optimizing for specific capabilities like if we were strictly purely like product focused I think that would be",
    "start": "1921200",
    "end": "1926399"
  },
  {
    "text": "the right approach and there's other many other companies that are purely product focused companies in the space that do this but I think that's not the",
    "start": "1926399",
    "end": "1932840"
  },
  {
    "text": "best way to produce the best fundamental foundational technology and we definitely see like for example one thing is we were one of the first models",
    "start": "1932840",
    "end": "1939120"
  },
  {
    "text": "in the market to make a model that could do walking like human walking normally it's really interesting like older",
    "start": "1939120",
    "end": "1944919"
  },
  {
    "text": "models used to just like make people who would hover like they didn't um and that's a deep that the model has",
    "start": "1944919",
    "end": "1951720"
  },
  {
    "text": "to learn to and so you could tune for that capability specifically but we found really interestingly that just emerged with scale right with more data",
    "start": "1951720",
    "end": "1959039"
  },
  {
    "text": "more parameters more compute the model learned to walk right and so that was ultimately the better place to invest",
    "start": "1959039",
    "end": "1964200"
  },
  {
    "text": "our Innovation tokens ultimately was in in the just base scaling base capabilities um kind of world reasoning",
    "start": "1964200",
    "end": "1971200"
  },
  {
    "text": "above just like specific point use cases I think that's all the time we have thank you for that wonderful",
    "start": "1971200",
    "end": "1977840"
  },
  {
    "text": "exchange par us thank you",
    "start": "1977840",
    "end": "1982440"
  }
]
[
  {
    "text": "hello and welcome to a skill connect today we have amir haja lee who is a project manager at any scale",
    "start": "719",
    "end": "6720"
  },
  {
    "text": "as you'll see we're really lucky to have him here not just because he finished his phd in two years",
    "start": "6720",
    "end": "11920"
  },
  {
    "text": "but because among his other leadership roles amir leads a great autoscaler team and today they'll give us a glimpse into",
    "start": "11920",
    "end": "17359"
  },
  {
    "text": "the ray autoscaler with that here's amir hajjali okay hello everybody",
    "start": "17359",
    "end": "22880"
  },
  {
    "text": "my name is emir i'm a project lead at any scale where i lead the auto skiller efforts",
    "start": "22880",
    "end": "28080"
  },
  {
    "text": "and today i will be giving you a glimpse into the ray auto scaler and i will start with uh some very small",
    "start": "28080",
    "end": "35040"
  },
  {
    "text": "description of what autoscaler is doing so basically auto scaler is a background process",
    "start": "35040",
    "end": "41120"
  },
  {
    "text": "that runs on the head node of every ray cluster and monitors the user's application",
    "start": "41120",
    "end": "46160"
  },
  {
    "text": "demands to then automatically scale the cluster to the minimum size",
    "start": "46160",
    "end": "51360"
  },
  {
    "text": "that fulfills these demands this is basically a tldr of what autoscaler",
    "start": "51360",
    "end": "57440"
  },
  {
    "text": "does and autoscaler is basically started by the cluster launcher so the",
    "start": "57440",
    "end": "63520"
  },
  {
    "text": "cluster launcher launches autoscaler so today what basically happens when you're",
    "start": "63520",
    "end": "70080"
  },
  {
    "text": "calling ray up in the cli or create or update cluster from the sdk",
    "start": "70080",
    "end": "76799"
  },
  {
    "text": "is on your laptop there are calls to the cloud provider or for example aws",
    "start": "76799",
    "end": "83280"
  },
  {
    "text": "that tells it to give your laptop a node and it ray makes it the head node and on",
    "start": "83280",
    "end": "90479"
  },
  {
    "text": "that head node we basically upload the file mounts and run the setup and initialization",
    "start": "90479",
    "end": "97439"
  },
  {
    "text": "commands of the head node and then we start ray and the background",
    "start": "97439",
    "end": "102720"
  },
  {
    "text": "process of autoscaler that runs on the headnode and then autoscaler manages the",
    "start": "102720",
    "end": "109439"
  },
  {
    "text": "lifecycle of the workers by again doing the same process for the head node",
    "start": "109439",
    "end": "115680"
  },
  {
    "text": "but of course without starting auto scaler so it launches these workers and upload the",
    "start": "115680",
    "end": "120799"
  },
  {
    "text": "files and sets uh setups the workers and starts",
    "start": "120799",
    "end": "126240"
  },
  {
    "text": "ray so let's take a deeper look on this worker life cycle managed by autoscaler",
    "start": "126240",
    "end": "134319"
  },
  {
    "text": "so autoscaler launches of course based on demand it",
    "start": "134319",
    "end": "141120"
  },
  {
    "text": "launches workers based on how the user interacts with the application or how the application is demanding",
    "start": "141120",
    "end": "146959"
  },
  {
    "text": "resources it terminates nodes when they are idle",
    "start": "146959",
    "end": "152080"
  },
  {
    "text": "or when they fail to start or set up or initialize and basically in the launching process",
    "start": "152080",
    "end": "157760"
  },
  {
    "text": "or when the node becomes outdated and by outdated i mean if you change",
    "start": "157760",
    "end": "162959"
  },
  {
    "text": "the node config in the cluster yaml to for example instead of m5x large it",
    "start": "162959",
    "end": "169040"
  },
  {
    "text": "becomes m4 or some gpu instance these nodes become outdated and they are",
    "start": "169040",
    "end": "175920"
  },
  {
    "text": "removed and finally auto skiller is responsible for restarting workers when for example",
    "start": "175920",
    "end": "182800"
  },
  {
    "text": "rayleigh crashes or when the user changes the setup or",
    "start": "182800",
    "end": "188080"
  },
  {
    "text": "start commands in the yaml file or the file mounts change",
    "start": "188080",
    "end": "193360"
  },
  {
    "text": "let's take a deeper look on how you configure autoscaler basically the configuration of",
    "start": "193360",
    "end": "199360"
  },
  {
    "text": "autoscaler is mainly through the cluster yemel which i assume some of you are familiar with i",
    "start": "199360",
    "end": "205519"
  },
  {
    "text": "want to go briefly over what are all these fills doing so basically the cluster name is a",
    "start": "205519",
    "end": "211920"
  },
  {
    "text": "unique identifier for the cluster uh this is basically an id for your cluster",
    "start": "211920",
    "end": "218560"
  },
  {
    "text": "so somebody else who has the same name and is using the same cloud credentials",
    "start": "218560",
    "end": "224159"
  },
  {
    "text": "or the same account that you both share will be able to access uh this cluster if they give the same",
    "start": "224159",
    "end": "230400"
  },
  {
    "text": "cluster name and then we have the max workers which is a global",
    "start": "230400",
    "end": "235920"
  },
  {
    "text": "maximum limit on the total number of workers that autoscaler will ever run at a given time",
    "start": "235920",
    "end": "243120"
  },
  {
    "text": "so the server size will or the cluster size will never be larger than max workers the global",
    "start": "243120",
    "end": "249760"
  },
  {
    "text": "constraint then we have upscaling speed which we added recently",
    "start": "249760",
    "end": "255680"
  },
  {
    "text": "the upscaling speed basically tells autoscaler how aggressively to add a new nodes",
    "start": "255680",
    "end": "261280"
  },
  {
    "text": "so the larger this value you will be adding more and more nodes much faster and it basically puts",
    "start": "261280",
    "end": "267840"
  },
  {
    "text": "a limit on the total number of pending nodes so if you first have a very few nodes",
    "start": "267840",
    "end": "273919"
  },
  {
    "text": "that are running you will add uh nodes gradually until the cluster becomes larger and",
    "start": "273919",
    "end": "280720"
  },
  {
    "text": "larger and the speed at which you're adding will increase after you have more and more active",
    "start": "280720",
    "end": "286639"
  },
  {
    "text": "nodes then we have the docker configurations where you specify the image the",
    "start": "286639",
    "end": "292320"
  },
  {
    "text": "container the container name and if you want to pull the latest version or whether you have some extra",
    "start": "292320",
    "end": "298560"
  },
  {
    "text": "options that you want to provide of course we have also custom uh you can",
    "start": "298560",
    "end": "303600"
  },
  {
    "text": "also provide a custom docker image for the workers or the headnotes separately but i have not",
    "start": "303600",
    "end": "308800"
  },
  {
    "text": "showed it in this particular slide and then you have the cloud provider",
    "start": "308800",
    "end": "314800"
  },
  {
    "text": "fields where for example here i provided an example in aws",
    "start": "314800",
    "end": "320080"
  },
  {
    "text": "with where you have to provide type region availability zone and you can also provide cache stop nodes",
    "start": "320080",
    "end": "326800"
  },
  {
    "text": "which is activated by default what cast stop nodes does is uh it when you",
    "start": "326800",
    "end": "333440"
  },
  {
    "text": "terminate a node it doesn't actually terminate it goes to a stopped state so in the next time you scale up",
    "start": "333440",
    "end": "340240"
  },
  {
    "text": "you reuse the stop nodes and therefore you start faster and it's activated by default",
    "start": "340240",
    "end": "347039"
  },
  {
    "text": "and then we have the available node types which was recently introduced so for",
    "start": "347039",
    "end": "352880"
  },
  {
    "text": "some of you who were using older versions of ray uh you probably had only one type for",
    "start": "352880",
    "end": "359840"
  },
  {
    "text": "the workers and one type for the head node and we recently added available node types",
    "start": "359840",
    "end": "365840"
  },
  {
    "text": "where you can specify multiple node types like you can find you can set m4 x large you can set p2 x large you",
    "start": "365840",
    "end": "373039"
  },
  {
    "text": "can provide as many as you want and here you know you have to provide",
    "start": "373039",
    "end": "378400"
  },
  {
    "text": "the node type and then the node config which previously was uh in the headwear",
    "start": "378400",
    "end": "384720"
  },
  {
    "text": "the head node and uh worker fields now they are under node config for example here we provided the",
    "start": "384720",
    "end": "390720"
  },
  {
    "text": "instance type you can also specify a storage size etc we have the resources",
    "start": "390720",
    "end": "396080"
  },
  {
    "text": "basically how much resources this instance had has if you're running on aws we have",
    "start": "396080",
    "end": "401840"
  },
  {
    "text": "logic that automatically detects uh these resources and therefore you just have to provide the instance",
    "start": "401840",
    "end": "408880"
  },
  {
    "text": "type without the resources you can specify main workers and max workers per node type or you can specify even",
    "start": "408880",
    "end": "417120"
  },
  {
    "text": "initialization commands or worker setup commands per node type",
    "start": "417120",
    "end": "422479"
  },
  {
    "text": "this way you know you can customize every type of workers and to have custom commands",
    "start": "422479",
    "end": "428639"
  },
  {
    "text": "custom configurations and you can also add custom resources like you see here for your",
    "start": "428639",
    "end": "437039"
  },
  {
    "text": "cluster and also it can detect gpus of special types automatically for aws",
    "start": "437039",
    "end": "443919"
  },
  {
    "text": "and then you have of course to specify the head node type so when we start the node we can know which",
    "start": "443919",
    "end": "449840"
  },
  {
    "text": "from these node types to make the head node the uh",
    "start": "449840",
    "end": "454880"
  },
  {
    "text": "authentication with which ray will authenticate every newly launched node",
    "start": "454880",
    "end": "460000"
  },
  {
    "text": "and then idle timeout in minutes which is basically the time that autoscaler takes to terminate an",
    "start": "460000",
    "end": "467680"
  },
  {
    "text": "idle node uh so basically if the idle load was idle for",
    "start": "467680",
    "end": "472800"
  },
  {
    "text": "x minutes or idle timeout minutes this is when autoscaler will terminate it",
    "start": "472800",
    "end": "479599"
  },
  {
    "text": "the file mounts which is basically a mechanism for you to upload files from your laptop to the head node",
    "start": "479599",
    "end": "487039"
  },
  {
    "text": "or the worker nodes so basically what happens here is that we upload the files to the head node and then from the head node to all the",
    "start": "487039",
    "end": "493680"
  },
  {
    "text": "workers and every time these file mounts are changed these files get updated",
    "start": "493680",
    "end": "499520"
  },
  {
    "text": "and the the the way um the api here is basically you put the",
    "start": "499520",
    "end": "505360"
  },
  {
    "text": "key as the remote location and uh the value as the local machine on",
    "start": "505360",
    "end": "511120"
  },
  {
    "text": "the local path on your machine we have the initialization commands which are a list of commands that",
    "start": "511120",
    "end": "517760"
  },
  {
    "text": "run before the setup commands and if docker is enabled they run basically outside the container",
    "start": "517760",
    "end": "524320"
  },
  {
    "text": "before the docker is set up we have the setup commands which are a",
    "start": "524320",
    "end": "530000"
  },
  {
    "text": "list of shell commands that you can run or to set up the head and workers and sorry if docker",
    "start": "530000",
    "end": "537120"
  },
  {
    "text": "is enabled these commands run in the docker container you can also provide a custom",
    "start": "537120",
    "end": "543040"
  },
  {
    "text": "setup commands to the head or the workers separately by providing head setup commands and",
    "start": "543040",
    "end": "548560"
  },
  {
    "text": "worker setup commands uh ideally if you're installing packages",
    "start": "548560",
    "end": "554560"
  },
  {
    "text": "uh or cloning repos in the setup commands uh you should consider having a docker",
    "start": "554560",
    "end": "559920"
  },
  {
    "text": "image uh with these pre-installed packages or the clone repo it might make",
    "start": "559920",
    "end": "565200"
  },
  {
    "text": "yours launching a bit faster and then we have",
    "start": "565200",
    "end": "570240"
  },
  {
    "text": "the head and worker start commands which you generally do not need to modify these",
    "start": "570240",
    "end": "576160"
  },
  {
    "text": "commands are basically running race start on the head and workers and in the general use case",
    "start": "576160",
    "end": "581440"
  },
  {
    "text": "you don't really need to modify them so once you have configured your auto",
    "start": "581440",
    "end": "587040"
  },
  {
    "text": "scaler and started your audio scaler when does autoscaler actually",
    "start": "587040",
    "end": "592160"
  },
  {
    "text": "upscale there are four things that basically autoscaler looks at before",
    "start": "592160",
    "end": "598080"
  },
  {
    "text": "making the upscaling decision it looks first of course at the main workers at the resource demands",
    "start": "598080",
    "end": "603920"
  },
  {
    "text": "basically the application demands the placement groups and the auto scaler",
    "start": "603920",
    "end": "609519"
  },
  {
    "text": "sdk request resources api i will go into detail on all of these in the next slides",
    "start": "609519",
    "end": "614880"
  },
  {
    "text": "from this list of inputs autoscaler calculates to be packing the which node",
    "start": "614880",
    "end": "621760"
  },
  {
    "text": "types to start and how many so when uh let's let's go",
    "start": "621760",
    "end": "629040"
  },
  {
    "text": "deeper into what when this is happening for every one of these cases",
    "start": "629040",
    "end": "634720"
  },
  {
    "text": "so for main workers we get the auto scaler gets them in workers basically from the cluster config where you set",
    "start": "634720",
    "end": "642000"
  },
  {
    "text": "their main workers for every node type and then the second one is the resource demands for example here",
    "start": "642000",
    "end": "649040"
  },
  {
    "text": "we have a remote function f uh with two cpus each and we're calling",
    "start": "649040",
    "end": "654240"
  },
  {
    "text": "remote on uh three times for this function this translates to",
    "start": "654240",
    "end": "659279"
  },
  {
    "text": "resource demands cpu two three times here if you were",
    "start": "659279",
    "end": "665600"
  },
  {
    "text": "familiar with the previous versions of ray we did not have this support where we actually",
    "start": "665600",
    "end": "671279"
  },
  {
    "text": "calculate exactly how much the application takes and based on that we can exactly",
    "start": "671279",
    "end": "676720"
  },
  {
    "text": "figure out how much really the number of nodes or which node types you need uh it was mainly based on the",
    "start": "676720",
    "end": "683279"
  },
  {
    "text": "utilization of the current cluster and based on that we would add nodes without actually knowing how much",
    "start": "683279",
    "end": "690560"
  },
  {
    "text": "it should be but with this new autoscaler version we have the ability to know",
    "start": "690560",
    "end": "698160"
  },
  {
    "text": "exactly how much resources your application needs through this simple",
    "start": "698160",
    "end": "703839"
  },
  {
    "text": "resource demands collection then we have placement groups which was also recently introduced",
    "start": "703839",
    "end": "709839"
  },
  {
    "text": "inside autoscaler where it basically allows users to atomically reserve",
    "start": "709839",
    "end": "715200"
  },
  {
    "text": "groups of resources across multiple nodes basically what you can do uh you can",
    "start": "715200",
    "end": "721440"
  },
  {
    "text": "before running your application you can define a placement group let's say you want 1 000 cpus and",
    "start": "721440",
    "end": "729200"
  },
  {
    "text": "oh this will request 1000 cpus that will be always available for you to run things",
    "start": "729200",
    "end": "735200"
  },
  {
    "text": "on and you can run applications inside this placement group and i will give an example in the next",
    "start": "735200",
    "end": "740560"
  },
  {
    "text": "line this is this can be helpful for example for gang scheduling where you want all the",
    "start": "740560",
    "end": "745760"
  },
  {
    "text": "app tasks or actors to be scheduled and start at the same time or if you want to maximize data locality",
    "start": "745760",
    "end": "754079"
  },
  {
    "text": "for example you don't want to do a lot of data transfer you already know that you were these these kind of um",
    "start": "754079",
    "end": "761600"
  },
  {
    "text": "actors or tasks will share some uh data or you know you can do some load",
    "start": "761600",
    "end": "767360"
  },
  {
    "text": "balancing by telling uh autoscaler to place these actors or tasks on physically different machines let's take",
    "start": "767360",
    "end": "775519"
  },
  {
    "text": "a an example of placement groups so what we have here is you know we have",
    "start": "775519",
    "end": "782480"
  },
  {
    "text": "import ray and then we are initiating ray to connect to the default address basically to the cluster we're running",
    "start": "782480",
    "end": "788240"
  },
  {
    "text": "on then what we're having here is we're defining two bundles bundle one and bundle two",
    "start": "788240",
    "end": "794079"
  },
  {
    "text": "first one is two gpus module two is basically x and resource two and we're defining a",
    "start": "794079",
    "end": "800800"
  },
  {
    "text": "placement group with these two bundles and we're telling ray to",
    "start": "800800",
    "end": "806160"
  },
  {
    "text": "prepare this placement group and wait until it's ready or basically when these resources are available what we did here",
    "start": "806160",
    "end": "813920"
  },
  {
    "text": "is use strict pack if these which means that if these two bundles",
    "start": "813920",
    "end": "819920"
  },
  {
    "text": "fit into uh one node they will place inside one node and it tries to strictly or",
    "start": "819920",
    "end": "828079"
  },
  {
    "text": "maximize the packing into collocating basically these bundles on",
    "start": "828079",
    "end": "834079"
  },
  {
    "text": "the same note there are other options like strict spread which try will will try to",
    "start": "834079",
    "end": "840959"
  },
  {
    "text": "place these bundles on completely different nodes as much as possible there is back and spread which are",
    "start": "840959",
    "end": "846959"
  },
  {
    "text": "basically based on best effort and then finally you know we schedule we schedule f in",
    "start": "846959",
    "end": "854560"
  },
  {
    "text": "in this placement group uh by calling f dot options remote and this will run f inside",
    "start": "854560",
    "end": "859839"
  },
  {
    "text": "displacement group and this placement group will live uh as long as your application",
    "start": "859839",
    "end": "865199"
  },
  {
    "text": "is running and you can always um run things in this placement room",
    "start": "865199",
    "end": "870880"
  },
  {
    "text": "and finally we have the newly introduced sdk request resources it basically commands auto skiller to",
    "start": "870880",
    "end": "877440"
  },
  {
    "text": "scale the cluster up to the desired size so basically the cluster size will never be",
    "start": "877440",
    "end": "885040"
  },
  {
    "text": "smaller than what you provided in the request resources let's say you wanted 100 or 1000 cpus",
    "start": "885040",
    "end": "892880"
  },
  {
    "text": "your cluster will always be at least the size that can fit",
    "start": "892880",
    "end": "899279"
  },
  {
    "text": "1000 uh cpus so it does not matter how much utilized the cluster is it just puts",
    "start": "899279",
    "end": "907519"
  },
  {
    "text": "a minimum quota on the resources that your cluster size",
    "start": "907519",
    "end": "914000"
  },
  {
    "text": "should uh be so for example if you request resources",
    "start": "914000",
    "end": "919040"
  },
  {
    "text": "with numcpus1000 this will allow you to do for example f dot remote 1000 times",
    "start": "919040",
    "end": "925680"
  },
  {
    "text": "without any auto scaling uh if you haven't any if you have not run anything before that",
    "start": "925680",
    "end": "931519"
  },
  {
    "text": "because this should accommodate uh 1 000 function calls of one cpu",
    "start": "931519",
    "end": "937120"
  },
  {
    "text": "of course if you are running already many many nodes this will not add much more",
    "start": "937120",
    "end": "944800"
  },
  {
    "text": "nodes to what you're currently having so for example if you have min workers very high that can fit this 1000 cpus",
    "start": "944800",
    "end": "951759"
  },
  {
    "text": "request resources might be redundant then we have another example here with",
    "start": "951759",
    "end": "956880"
  },
  {
    "text": "bundles one gpu and cpu4 and 64 cpus and then finally you have",
    "start": "956880",
    "end": "963519"
  },
  {
    "text": "another example where we're providing the same bundle three times or basically",
    "start": "963519",
    "end": "968560"
  },
  {
    "text": "cpu one which is equivalent to request resources with num cpus three so",
    "start": "968560",
    "end": "974800"
  },
  {
    "text": "with these four concepts we feed as an input to autoscaler and the",
    "start": "974800",
    "end": "981920"
  },
  {
    "text": "auto scaling algorithm is very simple it's run in three steps",
    "start": "981920",
    "end": "987920"
  },
  {
    "text": "it first we add the nodes to satisfy main workers and request resources if necessary",
    "start": "987920",
    "end": "994639"
  },
  {
    "text": "and then after we calculate how much nodes we need to add for meanworkers and request resources",
    "start": "994639",
    "end": "999839"
  },
  {
    "text": "we bin pack the placement groups and resource demands on the available node resources and",
    "start": "999839",
    "end": "1006720"
  },
  {
    "text": "calculate the remainder in the previous versions of autoscaler there was no bin packing and we could",
    "start": "1006720",
    "end": "1011839"
  },
  {
    "text": "not calculate the exact resource demands and we use only to look at the utilization and based on that to",
    "start": "1011839",
    "end": "1017839"
  },
  {
    "text": "guesstimate basically how much workers to add without actually looking properly but with the",
    "start": "1017839",
    "end": "1023519"
  },
  {
    "text": "new one we know exactly how much uh resources uh you need and you know for every",
    "start": "1023519",
    "end": "1029280"
  },
  {
    "text": "bundle in the remainder we add a node that can fit the bundle with the maximum",
    "start": "1029280",
    "end": "1034400"
  },
  {
    "text": "utilization so we take a node and we add the bundle to it generally",
    "start": "1034400",
    "end": "1040720"
  },
  {
    "text": "we pick the one that would maximize the utilization so for example we would try uh if if we took an empty node and",
    "start": "1040720",
    "end": "1047520"
  },
  {
    "text": "added one bundle to it we will try to continue adding to it until it's no longer possible to add to it and then we go",
    "start": "1047520",
    "end": "1054480"
  },
  {
    "text": "to the next one and even when we pick it we pick the one the smallest possible that can fit this",
    "start": "1054480",
    "end": "1060720"
  },
  {
    "text": "bundle so how the bin packing actually works uh",
    "start": "1060720",
    "end": "1066480"
  },
  {
    "text": "the let's take an example let's assume here that we have a list of resources requested uh",
    "start": "1066480",
    "end": "1073679"
  },
  {
    "text": "by the application we have six for example two six cpus then five five",
    "start": "1073679",
    "end": "1079280"
  },
  {
    "text": "five et cetera et cetera and let's say that we have only one type of workers that can fit nine",
    "start": "1079280",
    "end": "1084960"
  },
  {
    "text": "cpus the bin packing will basically try to bin pack these as much as possible",
    "start": "1084960",
    "end": "1091280"
  },
  {
    "text": "uh inside these resources and then it will launch nodes based on",
    "start": "1091280",
    "end": "1098240"
  },
  {
    "text": "this number of resources now keep in mind that the upscaling speed can slightly change how much",
    "start": "1098240",
    "end": "1106240"
  },
  {
    "text": "nodes are added simultaneously so if you have a very high upscaling speed these nodes can become available",
    "start": "1106240",
    "end": "1111679"
  },
  {
    "text": "immediately but if you have maybe a small value we will first add let's say five and then we will add 10 and",
    "start": "1111679",
    "end": "1118320"
  },
  {
    "text": "then we'll add 20 gradually now many of you uh might say uh or",
    "start": "1118320",
    "end": "1126799"
  },
  {
    "text": "observe some issues with autoscaler or maybe want to know uh what auto skiller is doing how many",
    "start": "1126799",
    "end": "1133440"
  },
  {
    "text": "nodes are running uh and and for that we have the auto scaler logs basically auto scaler updates the logs",
    "start": "1133440",
    "end": "1140240"
  },
  {
    "text": "every five seconds and these locks uh are very helpful for you and actually if you",
    "start": "1140240",
    "end": "1146559"
  },
  {
    "text": "look after you call ray up we have a lot of useful commands for you uh that should be useful for you uh to look at",
    "start": "1146559",
    "end": "1154320"
  },
  {
    "text": "these locks for example here to monitor the auto scaling you just have to call right exact cluster yaml",
    "start": "1154320",
    "end": "1159919"
  },
  {
    "text": "with this command you can run this command directly on the cluster when you are actually connected to the cluster and we",
    "start": "1159919",
    "end": "1167520"
  },
  {
    "text": "have recently within the new nightlys that we have now introduced additional logs on top of",
    "start": "1167520",
    "end": "1174400"
  },
  {
    "text": "the logs we previously had so previously we would show um you know the cluster would show what",
    "start": "1174400",
    "end": "1181760"
  },
  {
    "text": "is what is launching it was not very well organized it will also show how many resource",
    "start": "1181760",
    "end": "1188880"
  },
  {
    "text": "demands are there but now we have added on top of these uh",
    "start": "1188880",
    "end": "1194000"
  },
  {
    "text": "logs that we have we added on top of it other auto scaler locks that shows you a summary basically of how many",
    "start": "1194000",
    "end": "1200000"
  },
  {
    "text": "pending nodes are there how many are healthy if there were any recent failures uh how much utilization is there",
    "start": "1200000",
    "end": "1207840"
  },
  {
    "text": "and if there are any uh demands and the next thing you can look on in on",
    "start": "1207840",
    "end": "1213760"
  },
  {
    "text": "is basically the ray dashboard you can call ray dashboard cluster ymo and",
    "start": "1213760",
    "end": "1219280"
  },
  {
    "text": "access it on this link here's an example of how the dashboard",
    "start": "1219280",
    "end": "1224960"
  },
  {
    "text": "looks like you can see for example the host the uptime the cpu utilization how much rom and",
    "start": "1224960",
    "end": "1231760"
  },
  {
    "text": "disk and there are many other things that you can see in the dashboard that i have not shown here but basically you can use the",
    "start": "1231760",
    "end": "1238080"
  },
  {
    "text": "dashboard to view the cluster metrics the errors",
    "start": "1238080",
    "end": "1243600"
  },
  {
    "text": "exceptions and you can also detect some anomalies or you can even kill actors directly from the dashboard",
    "start": "1243600",
    "end": "1252320"
  },
  {
    "text": "and this is basically it and to wrap it up autoscaler manages the lifecycle of ray",
    "start": "1252320",
    "end": "1258880"
  },
  {
    "text": "workers it scales the cluster to the minimum size that fulfills the user demands",
    "start": "1258880",
    "end": "1264799"
  },
  {
    "text": "and it provides the user a serverless experience uh this basically describes",
    "start": "1264799",
    "end": "1271280"
  },
  {
    "text": "to you in a high level what autoscaler is doing and next i want to show you a quick demo",
    "start": "1271280",
    "end": "1279760"
  },
  {
    "text": "so here i have a terminal i want to first",
    "start": "1279760",
    "end": "1286158"
  },
  {
    "text": "attach to my cluster i have already started a cluster here",
    "start": "1286640",
    "end": "1291840"
  },
  {
    "text": "i want to start ipython i want to import ray import time",
    "start": "1294320",
    "end": "1305280"
  },
  {
    "text": "name for time and then i want to define a function",
    "start": "1305280",
    "end": "1310799"
  },
  {
    "text": "a remote function remote ff",
    "start": "1310799",
    "end": "1319360"
  },
  {
    "text": "time dot sleep let's just make it sleep for five seconds",
    "start": "1319360",
    "end": "1324799"
  },
  {
    "text": "and then i want to call ray init address equals auto",
    "start": "1324880",
    "end": "1333840"
  },
  {
    "text": "there we go and then let us call uh ray.remote on this function uh",
    "start": "1333919",
    "end": "1341120"
  },
  {
    "text": "150 times okay get f dot remote",
    "start": "1341120",
    "end": "1349840"
  },
  {
    "text": "for so the next thing i'm going to do is",
    "start": "1358840",
    "end": "1364000"
  },
  {
    "text": "i want to look run the command that i showed you to look at the logs we have here",
    "start": "1364000",
    "end": "1369120"
  },
  {
    "text": "the command i'm going to re-exect that and let's see what we can see here",
    "start": "1369120",
    "end": "1375039"
  },
  {
    "text": "so as you can see you can see what auto scaler is running on the workers it's starting you can see",
    "start": "1375039",
    "end": "1381600"
  },
  {
    "text": "the commands that are running there the setting of tags uh a bunch of",
    "start": "1381600",
    "end": "1388960"
  },
  {
    "text": "setup uh information and here goes the summary that i showed you",
    "start": "1388960",
    "end": "1394240"
  },
  {
    "text": "basically you have the note status we have um how many are healthy how many are pending",
    "start": "1394240",
    "end": "1399280"
  },
  {
    "text": "as you can see we only have 10 here probably if the upscaling speed was",
    "start": "1399280",
    "end": "1405440"
  },
  {
    "text": "higher we would have started more aggressively and then you will be seeing more pending notes here there's",
    "start": "1405440",
    "end": "1411600"
  },
  {
    "text": "the recent failures etc etc uh we can also another thing",
    "start": "1411600",
    "end": "1419760"
  },
  {
    "text": "that we can look into is the dashboard and for that i'm going to run",
    "start": "1419760",
    "end": "1425760"
  },
  {
    "text": "gray dashboard once it finishes i can go here go to localhost and 8265.",
    "start": "1425760",
    "end": "1434240"
  },
  {
    "text": "it printed to me the port and that's why i already know that it's here it was printed here",
    "start": "1434240",
    "end": "1441520"
  },
  {
    "text": "okay so here you can see uh my cluster it has now 14 hosts",
    "start": "1441520",
    "end": "1449279"
  },
  {
    "text": "uh 28 workers 56 cores um let's see what else you can also see",
    "start": "1449279",
    "end": "1457520"
  },
  {
    "text": "the cpu uh every worker is is using and how long it has been running how",
    "start": "1457520",
    "end": "1463919"
  },
  {
    "text": "much resources memory it's using how many data sent were received or logs or some",
    "start": "1463919",
    "end": "1470840"
  },
  {
    "text": "errors",
    "start": "1470840",
    "end": "1473840"
  },
  {
    "text": "okay so at the at the very end uh you can also see that at some point we",
    "start": "1484720",
    "end": "1490400"
  },
  {
    "text": "also reached 19 hosts previously it was 14 so we're adding it more and more notes",
    "start": "1490400",
    "end": "1495440"
  },
  {
    "text": "once the application finishes uh autoscaler will wait the idle timeout",
    "start": "1495440",
    "end": "1502480"
  },
  {
    "text": "and then uh all these nodes will be removed okay so now uh our cluster after all the",
    "start": "1502480",
    "end": "1510240"
  },
  {
    "text": "task has finished is back to two cpus on demand uh that started with because i",
    "start": "1510240",
    "end": "1517279"
  },
  {
    "text": "set the main workers to one and we have one head node and one worker and also as you can see the dashboard",
    "start": "1517279",
    "end": "1523039"
  },
  {
    "text": "has only these two workers and this basically concludes my talk",
    "start": "1523039",
    "end": "1528320"
  },
  {
    "text": "thank you so much amir hajali for your talk on a glimpse into the rate auto scaler",
    "start": "1528320",
    "end": "1533679"
  },
  {
    "text": "so with that we'll take questions the first one is how is the auto scaler",
    "start": "1533679",
    "end": "1539760"
  },
  {
    "text": "different from the auto scale of kubernetes yeah uh that's a good question so in our",
    "start": "1539760",
    "end": "1546559"
  },
  {
    "text": "own auto scaler we because you're running ray functions we know exactly how much resources are let's say number of cpus",
    "start": "1546559",
    "end": "1553919"
  },
  {
    "text": "and gpus your functions uh are using and therefore we can know exactly how",
    "start": "1553919",
    "end": "1559600"
  },
  {
    "text": "many nodes to launch uh the one in kubernetes is similar in the sense that it add nodes when",
    "start": "1559600",
    "end": "1566080"
  },
  {
    "text": "you have a very high utilization or you are having a pending pod or something",
    "start": "1566080",
    "end": "1571200"
  },
  {
    "text": "like that and um downscales the cluster when there are some idle pods uh but in our case we",
    "start": "1571200",
    "end": "1578720"
  },
  {
    "text": "know much more than within kubernetes kubernetes is just based on uh very high level utilization that is",
    "start": "1578720",
    "end": "1586080"
  },
  {
    "text": "not as precise as in our case so ideally our order scalar should be better so so the next question",
    "start": "1586080",
    "end": "1594720"
  },
  {
    "text": "is are we maximizing data locally and load balancing building strategies in placement groups",
    "start": "1594720",
    "end": "1599919"
  },
  {
    "text": "or is this something we have to write ourselves so it is built in in the placement groups",
    "start": "1599919",
    "end": "1605600"
  },
  {
    "text": "you just have to specify if you want to uh use strict pack or a strict spread",
    "start": "1605600",
    "end": "1611600"
  },
  {
    "text": "to decide whether you want to maximize locality or load balancing respectively",
    "start": "1611600",
    "end": "1619520"
  },
  {
    "text": "oh thank you so the next question is also about placement groups and it's if i set a placement group with",
    "start": "1619520",
    "end": "1626320"
  },
  {
    "text": "two gpus and two cpus in cases where the gpu node also has enough cpus",
    "start": "1626320",
    "end": "1631760"
  },
  {
    "text": "how will the placement group be configured by ray on gpu only nodes or gpu plus cpl cpu only nodes",
    "start": "1631760",
    "end": "1639279"
  },
  {
    "text": "seems both can satisfy the bundle request yeah that's a good question so if you're",
    "start": "1639279",
    "end": "1644799"
  },
  {
    "text": "if this is one bundle that has two gpus and two cpus we will find the smallest node that can",
    "start": "1644799",
    "end": "1651279"
  },
  {
    "text": "fit both if this is two separate bundles uh ideally we would put them on",
    "start": "1651279",
    "end": "1658399"
  },
  {
    "text": "one node if they fit but if for example uh the first one was the cpu",
    "start": "1658399",
    "end": "1665600"
  },
  {
    "text": "and then you had another bundle that was a gpu we might actually first start the",
    "start": "1665600",
    "end": "1671520"
  },
  {
    "text": "smallest node that does not have gpus and then um only the smallest the other smallest",
    "start": "1671520",
    "end": "1678159"
  },
  {
    "text": "node that can fit the gps but ideally if it's just one bundle uh which i understand",
    "start": "1678159",
    "end": "1683279"
  },
  {
    "text": "is the question indicating too it should be the smallest node that can fit the two at gpus and",
    "start": "1683279",
    "end": "1689279"
  },
  {
    "text": "two cpus oh okay so the next question is",
    "start": "1689279",
    "end": "1694320"
  },
  {
    "text": "what is the difference between minimum workers and request resources is request resources more specific to",
    "start": "1694320",
    "end": "1700640"
  },
  {
    "text": "instance types like cpu or gpu yeah so main workers is something you define in the gloucester demo and this",
    "start": "1700640",
    "end": "1706320"
  },
  {
    "text": "is something that will only affect like be uh",
    "start": "1706320",
    "end": "1711679"
  },
  {
    "text": "changed or modified once this is something that you said exactly in the cluster yemo and when you call way up",
    "start": "1711679",
    "end": "1717440"
  },
  {
    "text": "you can uh somehow no longer modify it for request resources your you can in",
    "start": "1717440",
    "end": "1724799"
  },
  {
    "text": "from within the code request that and you can dynamically change that to include increase the size of the cluster",
    "start": "1724799",
    "end": "1730799"
  },
  {
    "text": "or reduce its size and yeah it's also more type type specific so you can specify cpus",
    "start": "1730799",
    "end": "1738559"
  },
  {
    "text": "and gpus and request resources but main workers is just workers it does not allow you to modify",
    "start": "1738559",
    "end": "1745679"
  },
  {
    "text": "exactly or precisely pick the resources you need",
    "start": "1745679",
    "end": "1750880"
  },
  {
    "text": "oh okay so uh someone said thanks for the talk very interesting uh so the question was can we also",
    "start": "1751039",
    "end": "1757679"
  },
  {
    "text": "specify ram and disk as part of bundles besides the cpu or gpus uh",
    "start": "1757679",
    "end": "1763799"
  },
  {
    "text": "unfortunately not so you cannot really specify ram or disk in your bundle you can only specify cpus",
    "start": "1763799",
    "end": "1771760"
  },
  {
    "text": "gpus or any of the custom resources that you add in resources in the field like you",
    "start": "1771760",
    "end": "1778000"
  },
  {
    "text": "can add maybe a tpu or some custom resource okay so the next series of questions are",
    "start": "1778000",
    "end": "1783279"
  },
  {
    "text": "all about kubernetes so the first question is how does a ray autoscaler interact",
    "start": "1783279",
    "end": "1789039"
  },
  {
    "text": "influence or relate to the kubernetes autoscaler yeah that's a that's a good question so",
    "start": "1789039",
    "end": "1795919"
  },
  {
    "text": "our array of scalar does uh not interact with the kubernetes autoscaler this is like two independent",
    "start": "1795919",
    "end": "1801840"
  },
  {
    "text": "entities uh our oh no the scalar is managing the cluster of ray even if you're using kubernetes",
    "start": "1801840",
    "end": "1808720"
  },
  {
    "text": "it will add more pods or reduce spots it does not interact at all with the kubernetes illustrator we don't",
    "start": "1808720",
    "end": "1815039"
  },
  {
    "text": "use it in our own color scaler but if you want to use ray with the kubernetes auto scaler",
    "start": "1815039",
    "end": "1820240"
  },
  {
    "text": "we recently added the kubernetes operator and you can actually run the kubernetes",
    "start": "1820240",
    "end": "1826399"
  },
  {
    "text": "auto scaler with ray so we have two uh options for you we can either use",
    "start": "1826399",
    "end": "1831520"
  },
  {
    "text": "the built-in kubernetes or scalar or you can use our own autoscaler and our own auto scaler will not interact with the",
    "start": "1831520",
    "end": "1837200"
  },
  {
    "text": "kubernetes zone screen okay so the next question is is that dashboard",
    "start": "1837200",
    "end": "1842880"
  },
  {
    "text": "available in kubernetes with or within without kubernetes autoscaler or sorry without without a kubernetes",
    "start": "1842880",
    "end": "1849520"
  },
  {
    "text": "operator yeah so the dashboard is available in kubernetes and all the other uh cloud providers it is",
    "start": "1849520",
    "end": "1856640"
  },
  {
    "text": "not related to where you're using it yeah so it is available okay",
    "start": "1856640",
    "end": "1862000"
  },
  {
    "text": "so the next question is i was interested in using rate auto scaler with kubernetes",
    "start": "1862000",
    "end": "1867760"
  },
  {
    "text": "um as i like to scale worker pause with the request resources is this possible uh yes you can use",
    "start": "1867760",
    "end": "1874640"
  },
  {
    "text": "radio spiller with kubernetes with the request resources yeah okay and",
    "start": "1874640",
    "end": "1880559"
  },
  {
    "text": "a couple more questions so in the new format of the logs that show recent failures",
    "start": "1880559",
    "end": "1885600"
  },
  {
    "text": "would it be possible to identify the reason for failure i.e spot node shutdown versus memory overflow in the",
    "start": "1885600",
    "end": "1891039"
  },
  {
    "text": "node uh so within the logs in the monitor logs you generally have the reason for",
    "start": "1891039",
    "end": "1897840"
  },
  {
    "text": "why the worker failed uh but also now where you're gonna have it also",
    "start": "1897840",
    "end": "1902960"
  },
  {
    "text": "in your terminal when the some nodes fail and you'll have a summary of that i don't know specifically if the memory",
    "start": "1902960",
    "end": "1908640"
  },
  {
    "text": "of workflow is something that we can always catch but generally in the logs most of the reasons for why the",
    "start": "1908640",
    "end": "1914399"
  },
  {
    "text": "worker failed is available in monitor.logs",
    "start": "1914399",
    "end": "1920640"
  },
  {
    "text": "okay so the next question is about ec2 fleets so what's the best way to emulate ec2",
    "start": "1920640",
    "end": "1926799"
  },
  {
    "text": "fleets where you can list a range of instance types particularly for spot so that there's a good chance of getting",
    "start": "1926799",
    "end": "1932799"
  },
  {
    "text": "a suitable spot instance when required um so with asgs you can launch templates",
    "start": "1932799",
    "end": "1937919"
  },
  {
    "text": "for this can we use those or is there an equivalent in auto scale yeah so",
    "start": "1937919",
    "end": "1943200"
  },
  {
    "text": "in currently you cannot really emulate the institute bleeds um you will have to change the code of",
    "start": "1943200",
    "end": "1951120"
  },
  {
    "text": "ray of photoscaler to accommodate that i can't really think of a way for you to",
    "start": "1951120",
    "end": "1956640"
  },
  {
    "text": "emulate that in easyjet okay so the next question is",
    "start": "1956640",
    "end": "1962640"
  },
  {
    "text": "is there a possible way uh to put different initialization commands to different node bundle types and",
    "start": "1962640",
    "end": "1970159"
  },
  {
    "text": "they clarified here i mean the resource composition for a specific node that you showed before specified in the yaml yes",
    "start": "1970159",
    "end": "1977840"
  },
  {
    "text": "there is a way to specify different initialization commands for different nodes so inside your available",
    "start": "1977840",
    "end": "1984320"
  },
  {
    "text": "node types build in the cluster config you can for every node type specify",
    "start": "1984320",
    "end": "1990640"
  },
  {
    "text": "uh different initialization commands and you can also specify different set",
    "start": "1990640",
    "end": "1997840"
  },
  {
    "text": "of limits but you cannot really do that for every bundle this is like per node you can't really",
    "start": "1997840",
    "end": "2003679"
  },
  {
    "text": "change the initialization commands okay so another question is",
    "start": "2003679",
    "end": "2009760"
  },
  {
    "text": "is there a possible way to put different initialization commands oh um already read that sorry",
    "start": "2009760",
    "end": "2016320"
  },
  {
    "text": "um next question is when specifying gpu resources is there a way to specify the memory",
    "start": "2016320",
    "end": "2021440"
  },
  {
    "text": "requirement rather than the utilization fraction um",
    "start": "2021440",
    "end": "2027600"
  },
  {
    "text": "so i i'm not sure i understand so you no longer",
    "start": "2028320",
    "end": "2033440"
  },
  {
    "text": "need the utilization fraction um when specifying gpu resources",
    "start": "2033440",
    "end": "2040559"
  },
  {
    "text": "uh you cannot specify the memory requirement and in the newer version of auto scaler you",
    "start": "2040559",
    "end": "2046640"
  },
  {
    "text": "don't need to specify utilization fraction because we can already calculate",
    "start": "2046640",
    "end": "2051760"
  },
  {
    "text": "how much resources you need and based on that watch the only the necessary number of",
    "start": "2051760",
    "end": "2057599"
  },
  {
    "text": "workers uh needed for that so you no longer need to specify utilization fraction instead",
    "start": "2057599",
    "end": "2063919"
  },
  {
    "text": "of that uh you can specify upscaling speed uh which is uh the question of the",
    "start": "2063919",
    "end": "2071200"
  },
  {
    "text": "previous person here who asked let me know yeah um so that previous person asks",
    "start": "2071200",
    "end": "2077440"
  },
  {
    "text": "um if you know exactly how many resources are needed um so why don't you need to scale up at a",
    "start": "2077440",
    "end": "2082560"
  },
  {
    "text": "certain rate or why do you need to scale up at a certain rate why can't you just scale up the exact number needed yeah that's a",
    "start": "2082560",
    "end": "2088560"
  },
  {
    "text": "that's a good question so uh we know exactly how much you would need but we we set up the upscaling speed and",
    "start": "2088560",
    "end": "2096960"
  },
  {
    "text": "by the way you can set it to a very high value and then we will launch immediately but",
    "start": "2096960",
    "end": "2102160"
  },
  {
    "text": "if your tasks are very short tasks um and they theoretically seem to",
    "start": "2102160",
    "end": "2108160"
  },
  {
    "text": "require many many more nodes but if they finish very quickly the startup time of the worker might be",
    "start": "2108160",
    "end": "2115520"
  },
  {
    "text": "longer than the time this task is taking and therefore it might actually still be beneficial to",
    "start": "2115520",
    "end": "2120880"
  },
  {
    "text": "start uh gradually lunch workers because by the time you will launch even",
    "start": "2120880",
    "end": "2125920"
  },
  {
    "text": "the more and more workers you will not really be uh using them and another",
    "start": "2125920",
    "end": "2132560"
  },
  {
    "text": "thing even if you start them simultaneously and run these tasks you don't want every worker to run for just one second",
    "start": "2132560",
    "end": "2139359"
  },
  {
    "text": "and then uh wait for the idle timer for it to be shut down",
    "start": "2139359",
    "end": "2144560"
  },
  {
    "text": "so this is somewhat being more cost awareness and more careful about how much you",
    "start": "2144560",
    "end": "2151520"
  },
  {
    "text": "really need so if these tasks are really taking a lot we will exponentially add more and more",
    "start": "2151520",
    "end": "2157920"
  },
  {
    "text": "nodes so it shouldn't be of a big concern but if you already from the scratch know that your tasks will take a long time",
    "start": "2157920",
    "end": "2164560"
  },
  {
    "text": "you can boot up you can increase the up skating speed you can use placement groups that also",
    "start": "2164560",
    "end": "2170160"
  },
  {
    "text": "bypasses the up scanning speed you can use request resources that also bypasses the upscaling speed",
    "start": "2170160",
    "end": "2175760"
  },
  {
    "text": "and you can also set the main workers oh thank you so the final question uh",
    "start": "2175760",
    "end": "2182400"
  },
  {
    "text": "i'll take is will the recording be shared and this recording will be shared on",
    "start": "2182400",
    "end": "2188320"
  },
  {
    "text": "our any skill youtube channel i'd also like to thank amir hajali for taking the",
    "start": "2188320",
    "end": "2194240"
  },
  {
    "text": "time to not only give a talk but also answer questions uh thank you so much",
    "start": "2194240",
    "end": "2199520"
  },
  {
    "text": "if you have any further questions you can contact us at events at anyscale.com",
    "start": "2199520",
    "end": "2204880"
  },
  {
    "text": "uh thanks again amir yeah thank you very much for hosting me thank you you're welcome have a good one",
    "start": "2204880",
    "end": "2214880"
  }
]
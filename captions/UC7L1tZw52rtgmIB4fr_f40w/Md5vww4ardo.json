[
  {
    "start": "0",
    "end": "35000"
  },
  {
    "text": "can you guys hear me yeah hi hello",
    "start": "2639",
    "end": "5080"
  },
  {
    "text": "everyone uh myself ismile and I have",
    "start": "5080",
    "end": "8120"
  },
  {
    "text": "shivanu with me we are software",
    "start": "8120",
    "end": "10800"
  },
  {
    "text": "engineers at rubric where we are",
    "start": "10800",
    "end": "12599"
  },
  {
    "text": "building the next generation of data",
    "start": "12599",
    "end": "14480"
  },
  {
    "text": "security applications and protecting",
    "start": "14480",
    "end": "16880"
  },
  {
    "text": "world's data the topic for today's talk",
    "start": "16880",
    "end": "19840"
  },
  {
    "text": "is streaming model inference at scale at",
    "start": "19840",
    "end": "24519"
  },
  {
    "text": "rubric so",
    "start": "26320",
    "end": "30320"
  },
  {
    "text": "sorry yeah uh so let me go over the",
    "start": "34320",
    "end": "38079"
  },
  {
    "start": "35000",
    "end": "82000"
  },
  {
    "text": "agenda for today's talk quickly um I",
    "start": "38079",
    "end": "40879"
  },
  {
    "text": "think in this talk we'll dive deeper",
    "start": "40879",
    "end": "42680"
  },
  {
    "text": "into how we use machine learning at",
    "start": "42680",
    "end": "45199"
  },
  {
    "text": "rubric um then how rer fits into rubrics",
    "start": "45199",
    "end": "48719"
  },
  {
    "text": "machine learning platform ml platform",
    "start": "48719",
    "end": "51680"
  },
  {
    "text": "ecosystem then we'll talk a little bit",
    "start": "51680",
    "end": "53760"
  },
  {
    "text": "about how we migrated our application to",
    "start": "53760",
    "end": "56600"
  },
  {
    "text": "rer and uh we'll talk a little bit about",
    "start": "56600",
    "end": "60120"
  },
  {
    "text": "how to achieve High scalability while",
    "start": "60120",
    "end": "61879"
  },
  {
    "text": "solving common distributed system",
    "start": "61879",
    "end": "63839"
  },
  {
    "text": "challenges like reliability scalability",
    "start": "63839",
    "end": "67159"
  },
  {
    "text": "and",
    "start": "67159",
    "end": "68439"
  },
  {
    "text": "maintainability um we'll also share some",
    "start": "68439",
    "end": "71560"
  },
  {
    "text": "of the problems we are looking to solve",
    "start": "71560",
    "end": "74360"
  },
  {
    "text": "or we haven't yet solved or some of the",
    "start": "74360",
    "end": "76040"
  },
  {
    "text": "future improvements we have left in our",
    "start": "76040",
    "end": "78880"
  },
  {
    "text": "uh in rubrics",
    "start": "78880",
    "end": "80759"
  },
  {
    "text": "application um so yeah let's talk about",
    "start": "80759",
    "end": "84079"
  },
  {
    "start": "82000",
    "end": "149000"
  },
  {
    "text": "machine learning at rubric so uh rubric",
    "start": "84079",
    "end": "87320"
  },
  {
    "text": "is an Enterprise data security uh",
    "start": "87320",
    "end": "89600"
  },
  {
    "text": "company",
    "start": "89600",
    "end": "90759"
  },
  {
    "text": "uh like one of the most popular products",
    "start": "90759",
    "end": "93280"
  },
  {
    "text": "that we have is ransomware and anomaly",
    "start": "93280",
    "end": "96079"
  },
  {
    "text": "detection on Virtual machines so we take",
    "start": "96079",
    "end": "100240"
  },
  {
    "text": "typically take like backups of uh",
    "start": "100240",
    "end": "102960"
  },
  {
    "text": "customers workloads and the most common",
    "start": "102960",
    "end": "105280"
  },
  {
    "text": "workload is virtual machine we look at",
    "start": "105280",
    "end": "107560"
  },
  {
    "text": "their file system look for like any",
    "start": "107560",
    "end": "110399"
  },
  {
    "text": "anomalous activities in the file system",
    "start": "110399",
    "end": "112439"
  },
  {
    "text": "if there's some kind of",
    "start": "112439",
    "end": "114040"
  },
  {
    "text": "encryption um we allow users to uh you",
    "start": "114040",
    "end": "118680"
  },
  {
    "text": "know recover from ransomware attacks if",
    "start": "118680",
    "end": "121200"
  },
  {
    "text": "we detect high level of encryptions",
    "start": "121200",
    "end": "123119"
  },
  {
    "text": "there we also flag anomalous access and",
    "start": "123119",
    "end": "126439"
  },
  {
    "text": "activity on user sensitive data and",
    "start": "126439",
    "end": "128759"
  },
  {
    "text": "provide them with remediation steps if",
    "start": "128759",
    "end": "130920"
  },
  {
    "text": "there's some kind of anomalous um you",
    "start": "130920",
    "end": "133400"
  },
  {
    "text": "know activities we classify all the",
    "start": "133400",
    "end": "135879"
  },
  {
    "text": "users data as sensitive uh all of this",
    "start": "135879",
    "end": "139800"
  },
  {
    "text": "comes under a product category which is",
    "start": "139800",
    "end": "141800"
  },
  {
    "text": "called data security posture management",
    "start": "141800",
    "end": "144120"
  },
  {
    "text": "or dspm in which rubric is uh",
    "start": "144120",
    "end": "147239"
  },
  {
    "text": "leader um so",
    "start": "147239",
    "end": "151280"
  },
  {
    "start": "149000",
    "end": "177000"
  },
  {
    "text": "at rubric we also use have started using",
    "start": "151280",
    "end": "153720"
  },
  {
    "text": "a lot of different ml libraries",
    "start": "153720",
    "end": "155280"
  },
  {
    "text": "Frameworks recently we jumped onto the",
    "start": "155280",
    "end": "157080"
  },
  {
    "text": "llm bandwagon and we are using LMS in",
    "start": "157080",
    "end": "160120"
  },
  {
    "text": "some of our uh like Pro uh some of our",
    "start": "160120",
    "end": "165080"
  },
  {
    "text": "machine learning models like we are",
    "start": "165080",
    "end": "166879"
  },
  {
    "text": "using llms to reduce false positive in",
    "start": "166879",
    "end": "170360"
  },
  {
    "text": "anomaly",
    "start": "170360",
    "end": "171480"
  },
  {
    "text": "detection so yeah let me get into how we",
    "start": "171480",
    "end": "177720"
  },
  {
    "start": "177000",
    "end": "261000"
  },
  {
    "text": "exactly started",
    "start": "177720",
    "end": "180239"
  },
  {
    "text": "with this like traditionally like if we",
    "start": "180239",
    "end": "182760"
  },
  {
    "text": "look at the state an year ago our system",
    "start": "182760",
    "end": "185959"
  },
  {
    "text": "was like a microservice oriented",
    "start": "185959",
    "end": "188239"
  },
  {
    "text": "architecture you know hosted on",
    "start": "188239",
    "end": "190840"
  },
  {
    "text": "cetes um and with different Services",
    "start": "190840",
    "end": "194360"
  },
  {
    "text": "interacting with each other to you know",
    "start": "194360",
    "end": "196319"
  },
  {
    "text": "do model inference and serving them but",
    "start": "196319",
    "end": "198840"
  },
  {
    "text": "around one year ago like anomaly",
    "start": "198840",
    "end": "200680"
  },
  {
    "text": "detection product art rubric it saw",
    "start": "200680",
    "end": "202879"
  },
  {
    "text": "unprecedented adoption like there was a",
    "start": "202879",
    "end": "205799"
  },
  {
    "text": "lot of growth around like 1.5x in a",
    "start": "205799",
    "end": "209400"
  },
  {
    "text": "period of like a few weeks while our",
    "start": "209400",
    "end": "212200"
  },
  {
    "text": "sales and product teams were very happy",
    "start": "212200",
    "end": "214120"
  },
  {
    "text": "with it like engineering team faced new",
    "start": "214120",
    "end": "216959"
  },
  {
    "text": "challenges right we had to handhold the",
    "start": "216959",
    "end": "219239"
  },
  {
    "text": "system for a few weeks manually scale it",
    "start": "219239",
    "end": "222200"
  },
  {
    "text": "monitor the services to you know make",
    "start": "222200",
    "end": "224920"
  },
  {
    "text": "sure that they are always performant and",
    "start": "224920",
    "end": "227159"
  },
  {
    "text": "the system doesn't",
    "start": "227159",
    "end": "228519"
  },
  {
    "text": "regress um we learned a lot of new",
    "start": "228519",
    "end": "231599"
  },
  {
    "text": "things about the system um like a lot of",
    "start": "231599",
    "end": "234519"
  },
  {
    "text": "new dependencies that had Crypt in which",
    "start": "234519",
    "end": "236519"
  },
  {
    "text": "we did not anticipate while building it",
    "start": "236519",
    "end": "240360"
  },
  {
    "text": "um you know and at the end of the um",
    "start": "240360",
    "end": "243840"
  },
  {
    "text": "like these were a tough few weeks for uh",
    "start": "243840",
    "end": "246159"
  },
  {
    "text": "you know the on call team and the",
    "start": "246159",
    "end": "247599"
  },
  {
    "text": "engineering team but at the end of it",
    "start": "247599",
    "end": "249840"
  },
  {
    "text": "like we felt like as like any engineer",
    "start": "249840",
    "end": "252120"
  },
  {
    "text": "would do that we need to automate all of",
    "start": "252120",
    "end": "254200"
  },
  {
    "text": "it and we started exploring uh you know",
    "start": "254200",
    "end": "257519"
  },
  {
    "text": "other options now the exploration part",
    "start": "257519",
    "end": "261479"
  },
  {
    "start": "261000",
    "end": "334000"
  },
  {
    "text": "it was not straightforward like we",
    "start": "261479",
    "end": "263280"
  },
  {
    "text": "listed down all the requirements that we",
    "start": "263280",
    "end": "265639"
  },
  {
    "text": "need from our model serving system and",
    "start": "265639",
    "end": "267479"
  },
  {
    "text": "we explored you know a few libraries",
    "start": "267479",
    "end": "269720"
  },
  {
    "text": "these Frameworks that we would like um",
    "start": "269720",
    "end": "272840"
  },
  {
    "text": "the system to have we explored something",
    "start": "272840",
    "end": "275400"
  },
  {
    "text": "things like tensor flow serving Sheldon",
    "start": "275400",
    "end": "277680"
  },
  {
    "text": "ml server Cube flow and all of them like",
    "start": "277680",
    "end": "281800"
  },
  {
    "text": "they were good enough but felt short on",
    "start": "281800",
    "end": "283840"
  },
  {
    "text": "some of the requirements and then",
    "start": "283840",
    "end": "287000"
  },
  {
    "text": "eventually we as a process of this",
    "start": "287000",
    "end": "289120"
  },
  {
    "text": "exploration we stumbled upon race",
    "start": "289120",
    "end": "291400"
  },
  {
    "text": "serve uh it fulfills major requirements",
    "start": "291400",
    "end": "294160"
  },
  {
    "text": "like it provides tag evaluation through",
    "start": "294160",
    "end": "295960"
  },
  {
    "text": "deployment graphs supports task level or",
    "start": "295960",
    "end": "298919"
  },
  {
    "text": "node level or at least um or kubernetes",
    "start": "298919",
    "end": "301759"
  },
  {
    "text": "node level Auto",
    "start": "301759",
    "end": "303240"
  },
  {
    "text": "scaling and since we already use",
    "start": "303240",
    "end": "305840"
  },
  {
    "text": "kubernetes for most of our uh you know",
    "start": "305840",
    "end": "308800"
  },
  {
    "text": "Services it made job easier for us since",
    "start": "308800",
    "end": "312240"
  },
  {
    "text": "like Ray has um a uh kubernetes operator",
    "start": "312240",
    "end": "315800"
  },
  {
    "text": "called Cub which allows easy deployment",
    "start": "315800",
    "end": "318080"
  },
  {
    "text": "of all the ray applications on",
    "start": "318080",
    "end": "320960"
  },
  {
    "text": "kubernetes it's also it has a large and",
    "start": "320960",
    "end": "324600"
  },
  {
    "text": "vibrant open source ecosystem and",
    "start": "324600",
    "end": "326360"
  },
  {
    "text": "Community which makes things easier for",
    "start": "326360",
    "end": "329360"
  },
  {
    "text": "us",
    "start": "329360",
    "end": "330680"
  },
  {
    "text": "so with that I'll hand over to ismile to",
    "start": "330680",
    "end": "334680"
  },
  {
    "start": "334000",
    "end": "433000"
  },
  {
    "text": "go into a few details around how what",
    "start": "334680",
    "end": "337280"
  },
  {
    "text": "are migration looked like and you know",
    "start": "337280",
    "end": "339280"
  },
  {
    "text": "how we solved all the challenges with",
    "start": "339280",
    "end": "341440"
  },
  {
    "text": "respect to getting our application",
    "start": "341440",
    "end": "343759"
  },
  {
    "text": "running on",
    "start": "343759",
    "end": "346319"
  },
  {
    "text": "cubra yeah so now let's look at how we",
    "start": "346360",
    "end": "350759"
  },
  {
    "text": "went about migrating our application to",
    "start": "350759",
    "end": "353560"
  },
  {
    "text": "racer uh in the interest of time we'll",
    "start": "353560",
    "end": "356600"
  },
  {
    "text": "not go into a lot of details but we'll",
    "start": "356600",
    "end": "359280"
  },
  {
    "text": "highlight",
    "start": "359280",
    "end": "360400"
  },
  {
    "text": "some aspects which make it easy to",
    "start": "360400",
    "end": "361919"
  },
  {
    "text": "onboard your application to r a r of",
    "start": "361919",
    "end": "365199"
  },
  {
    "text": "application is composed of multiple",
    "start": "365199",
    "end": "367160"
  },
  {
    "text": "deployments here we have a sample unit",
    "start": "367160",
    "end": "370080"
  },
  {
    "text": "of code which we would like to execute",
    "start": "370080",
    "end": "372360"
  },
  {
    "text": "as one of the components of our model so",
    "start": "372360",
    "end": "375280"
  },
  {
    "text": "we just annotate our code with ser.",
    "start": "375280",
    "end": "377840"
  },
  {
    "text": "deployment annotation to make it a",
    "start": "377840",
    "end": "380360"
  },
  {
    "text": "redeployment I think this would be very",
    "start": "380360",
    "end": "382599"
  },
  {
    "text": "familiar to all of you",
    "start": "382599",
    "end": "384520"
  },
  {
    "text": "folks um",
    "start": "384520",
    "end": "388520"
  },
  {
    "text": "now most of the production models are",
    "start": "390720",
    "end": "393560"
  },
  {
    "text": "Ensemble of multiple different models",
    "start": "393560",
    "end": "396360"
  },
  {
    "text": "with output of some models feeding as",
    "start": "396360",
    "end": "399039"
  },
  {
    "text": "input into some other models right so",
    "start": "399039",
    "end": "402199"
  },
  {
    "text": "model composition can be achieved by",
    "start": "402199",
    "end": "404479"
  },
  {
    "text": "creating a deployment which calls other",
    "start": "404479",
    "end": "406880"
  },
  {
    "text": "deployments here we have an Adder",
    "start": "406880",
    "end": "410800"
  },
  {
    "text": "deployment the output of which feeds",
    "start": "410800",
    "end": "413080"
  },
  {
    "text": "into multiplier deployment and the",
    "start": "413080",
    "end": "415479"
  },
  {
    "text": "deployments A and multiplier feed into a",
    "start": "415479",
    "end": "418479"
  },
  {
    "text": "router deployment so this creates a dag",
    "start": "418479",
    "end": "421639"
  },
  {
    "text": "it's a",
    "start": "421639",
    "end": "424319"
  },
  {
    "start": "433000",
    "end": "492000"
  },
  {
    "text": "graph so once you have the top level",
    "start": "436360",
    "end": "439000"
  },
  {
    "text": "deployment object you can use the serve",
    "start": "439000",
    "end": "442280"
  },
  {
    "text": "CLI to generate re serve application",
    "start": "442280",
    "end": "444879"
  },
  {
    "text": "yaml config in this case you can see",
    "start": "444879",
    "end": "448280"
  },
  {
    "text": "that the routers deployment object which",
    "start": "448280",
    "end": "450800"
  },
  {
    "text": "is serve dag it would be the entry point",
    "start": "450800",
    "end": "453599"
  },
  {
    "text": "for our application it's mentioned here",
    "start": "453599",
    "end": "455960"
  },
  {
    "text": "in the import",
    "start": "455960",
    "end": "458720"
  },
  {
    "text": "path the server application can be",
    "start": "468800",
    "end": "471080"
  },
  {
    "text": "deployed to kubernetes using the Cub",
    "start": "471080",
    "end": "473960"
  },
  {
    "text": "operator cubra is a powerful open-",
    "start": "473960",
    "end": "476560"
  },
  {
    "text": "Source kubernetes operator that provides",
    "start": "476560",
    "end": "479879"
  },
  {
    "text": "custom resource definitions for creating",
    "start": "479879",
    "end": "482360"
  },
  {
    "text": "a ray cluster and running race serve",
    "start": "482360",
    "end": "486560"
  },
  {
    "start": "492000",
    "end": "565000"
  },
  {
    "text": "application let's dive deeper into how",
    "start": "492400",
    "end": "494639"
  },
  {
    "text": "race Ser res solves the problem of",
    "start": "494639",
    "end": "496960"
  },
  {
    "text": "reliability scalability and",
    "start": "496960",
    "end": "499560"
  },
  {
    "text": "maintainability as we all want our",
    "start": "499560",
    "end": "501560"
  },
  {
    "text": "system to be highly available and have",
    "start": "501560",
    "end": "503280"
  },
  {
    "text": "fall tolerance racer provides fall",
    "start": "503280",
    "end": "506199"
  },
  {
    "text": "tolerance at each level for example if",
    "start": "506199",
    "end": "509199"
  },
  {
    "text": "an actor or a node restarts it knows how",
    "start": "509199",
    "end": "512000"
  },
  {
    "text": "to get back to a stable State thus uh",
    "start": "512000",
    "end": "515320"
  },
  {
    "text": "the CU operator manages the ray",
    "start": "515320",
    "end": "517039"
  },
  {
    "text": "applications on kubernetes recreating",
    "start": "517039",
    "end": "519640"
  },
  {
    "text": "worker parts to achieve the desired",
    "start": "519640",
    "end": "521599"
  },
  {
    "text": "cluster",
    "start": "521599",
    "end": "523959"
  },
  {
    "text": "State let's talk about",
    "start": "526360",
    "end": "528519"
  },
  {
    "text": "scalability so as you can see we have a",
    "start": "528519",
    "end": "530959"
  },
  {
    "text": "cyclic load pattern we get Peak load at",
    "start": "530959",
    "end": "533959"
  },
  {
    "text": "midnight when customers schedule their",
    "start": "533959",
    "end": "536519"
  },
  {
    "text": "backup if we provision for Peak load all",
    "start": "536519",
    "end": "539800"
  },
  {
    "text": "the time we naturally end up incurring",
    "start": "539800",
    "end": "542160"
  },
  {
    "text": "high costs and if we provision for",
    "start": "542160",
    "end": "545120"
  },
  {
    "text": "minimum load we end up with a higher",
    "start": "545120",
    "end": "547519"
  },
  {
    "text": "latency so what do we do so we need a",
    "start": "547519",
    "end": "550600"
  },
  {
    "text": "solution that automatically scales",
    "start": "550600",
    "end": "553040"
  },
  {
    "text": "resources based on the load pattern and",
    "start": "553040",
    "end": "555959"
  },
  {
    "text": "racer is a perfect fit for",
    "start": "555959",
    "end": "559800"
  },
  {
    "start": "565000",
    "end": "631000"
  },
  {
    "text": "this let's talk a bit more about how",
    "start": "568079",
    "end": "570680"
  },
  {
    "text": "Autos scaling Works in racer each",
    "start": "570680",
    "end": "573440"
  },
  {
    "text": "request in rer goes via a proxy which",
    "start": "573440",
    "end": "576320"
  },
  {
    "text": "cues them",
    "start": "576320",
    "end": "577360"
  },
  {
    "text": "up based on the Q rub decides to launch",
    "start": "577360",
    "end": "581519"
  },
  {
    "text": "new actors cubre decides to launch new",
    "start": "581519",
    "end": "585440"
  },
  {
    "text": "worker pods and kubernetes decides to",
    "start": "585440",
    "end": "588040"
  },
  {
    "text": "launch new nodes to understand if racer",
    "start": "588040",
    "end": "591360"
  },
  {
    "text": "would be able to handle our workloads we",
    "start": "591360",
    "end": "593600"
  },
  {
    "text": "decided to do a load test with 1 million",
    "start": "593600",
    "end": "596120"
  },
  {
    "text": "evaluations per day with Autos scaling",
    "start": "596120",
    "end": "598399"
  },
  {
    "text": "enabled we provisioned 2 and half CPUs",
    "start": "598399",
    "end": "602000"
  },
  {
    "text": "and 4 gig RAM for each worker node and 2",
    "start": "602000",
    "end": "604480"
  },
  {
    "text": "CPU and 4 gig RAM for the head node we",
    "start": "604480",
    "end": "607399"
  },
  {
    "text": "saw that on average it used 13 GK notes",
    "start": "607399",
    "end": "611279"
  },
  {
    "text": "of E2 standard 4 type with overall CP",
    "start": "611279",
    "end": "614120"
  },
  {
    "text": "utilization of 80% and overall memory",
    "start": "614120",
    "end": "616600"
  },
  {
    "text": "utilization of",
    "start": "616600",
    "end": "618120"
  },
  {
    "text": "30% obviously with some tuning of",
    "start": "618120",
    "end": "620320"
  },
  {
    "text": "resource type and worker configs one",
    "start": "620320",
    "end": "622800"
  },
  {
    "text": "would be able to achieve a overall",
    "start": "622800",
    "end": "624519"
  },
  {
    "text": "higher resource utilization",
    "start": "624519",
    "end": "628279"
  },
  {
    "start": "631000",
    "end": "696000"
  },
  {
    "text": "to run a system in production we need to",
    "start": "633480",
    "end": "635560"
  },
  {
    "text": "look at",
    "start": "635560",
    "end": "636560"
  },
  {
    "text": "observability tooling and reusability",
    "start": "636560",
    "end": "639320"
  },
  {
    "text": "now Ray emits metrics in Prometheus",
    "start": "639320",
    "end": "641279"
  },
  {
    "text": "format which can then be integrated with",
    "start": "641279",
    "end": "643360"
  },
  {
    "text": "grafana Ray also provides a built-in",
    "start": "643360",
    "end": "645800"
  },
  {
    "text": "dashboard at with many useful metrics R",
    "start": "645800",
    "end": "648920"
  },
  {
    "text": "emits system and application logs to the",
    "start": "648920",
    "end": "651600"
  },
  {
    "text": "Pod file system and provide support to",
    "start": "651600",
    "end": "654600"
  },
  {
    "text": "use a fluent bit side car to purchase",
    "start": "654600",
    "end": "657360"
  },
  {
    "text": "these logs to an external sync like like",
    "start": "657360",
    "end": "659440"
  },
  {
    "text": "logz.io",
    "start": "659440",
    "end": "660639"
  },
  {
    "text": "in terms of tooling we use basil to",
    "start": "660639",
    "end": "664279"
  },
  {
    "text": "build and package Docker images and",
    "start": "664279",
    "end": "666600"
  },
  {
    "text": "kubernetes to deploy the applications to",
    "start": "666600",
    "end": "668360"
  },
  {
    "text": "a",
    "start": "668360",
    "end": "669160"
  },
  {
    "text": "cluster rer also provides a serve CLI to",
    "start": "669160",
    "end": "673279"
  },
  {
    "text": "generate autoscaling config from",
    "start": "673279",
    "end": "675800"
  },
  {
    "text": "code and in terms of code maintenance",
    "start": "675800",
    "end": "679079"
  },
  {
    "text": "race of framework is accable and",
    "start": "679079",
    "end": "681480"
  },
  {
    "text": "reusable new use cases can use existing",
    "start": "681480",
    "end": "684760"
  },
  {
    "text": "rate deployments in their dag it also",
    "start": "684760",
    "end": "687399"
  },
  {
    "text": "supports modular code by sep ating the",
    "start": "687399",
    "end": "689680"
  },
  {
    "text": "functionality into their own",
    "start": "689680",
    "end": "692959"
  },
  {
    "text": "redeployments now you know like at the",
    "start": "696880",
    "end": "698839"
  },
  {
    "text": "middle of the talk we said rer fulfills",
    "start": "698839",
    "end": "701079"
  },
  {
    "text": "all our requirements but it's not true",
    "start": "701079",
    "end": "703600"
  },
  {
    "text": "after all currently the support for",
    "start": "703600",
    "end": "705920"
  },
  {
    "text": "distributed tracing is not production",
    "start": "705920",
    "end": "708440"
  },
  {
    "text": "ready and rolling upgrades in cubre is",
    "start": "708440",
    "end": "711360"
  },
  {
    "text": "not supported as of now and we are",
    "start": "711360",
    "end": "714120"
  },
  {
    "text": "looking forward to the community like",
    "start": "714120",
    "end": "716040"
  },
  {
    "text": "for these features in general thank you",
    "start": "716040",
    "end": "719079"
  },
  {
    "text": "uh we here for the Q&A if you have any",
    "start": "719079",
    "end": "723600"
  },
  {
    "text": "question",
    "start": "725480",
    "end": "728480"
  },
  {
    "start": "734000",
    "end": "859000"
  },
  {
    "text": "yeah yeah right now we the question yeah",
    "start": "735079",
    "end": "738399"
  },
  {
    "text": "so the question was whether we are using",
    "start": "738399",
    "end": "740399"
  },
  {
    "text": "GK or any other uh Cloud platform to",
    "start": "740399",
    "end": "743560"
  },
  {
    "text": "host uh R of I think so yeah right now",
    "start": "743560",
    "end": "746880"
  },
  {
    "text": "we are only on GK but so so that's the",
    "start": "746880",
    "end": "750279"
  },
  {
    "text": "uh Cloud side of it but we also have an",
    "start": "750279",
    "end": "752920"
  },
  {
    "text": "on-prem version of rubric uh which is",
    "start": "752920",
    "end": "755320"
  },
  {
    "text": "for our Dark Side customers uh where we",
    "start": "755320",
    "end": "758680"
  },
  {
    "text": "have a selfhosted kubernetes on Virtual",
    "start": "758680",
    "end": "760639"
  },
  {
    "text": "machines but we run cubre there",
    "start": "760639",
    "end": "764320"
  },
  {
    "text": "also uh not as so yeah the question is",
    "start": "765800",
    "end": "769320"
  },
  {
    "text": "whether we use uh GPU nodes um not as of",
    "start": "769320",
    "end": "772680"
  },
  {
    "text": "now but we are looking forward to use",
    "start": "772680",
    "end": "774720"
  },
  {
    "text": "them yeah yes please",
    "start": "774720",
    "end": "779319"
  },
  {
    "text": "uh",
    "start": "785160",
    "end": "787720"
  },
  {
    "text": "sorry yeah so the question was whether",
    "start": "802440",
    "end": "805079"
  },
  {
    "text": "we use mtls for race of and what are the",
    "start": "805079",
    "end": "807920"
  },
  {
    "text": "best practices so we do not use mtls uh",
    "start": "807920",
    "end": "813160"
  },
  {
    "text": "we are using uh so we host the race of",
    "start": "813160",
    "end": "818240"
  },
  {
    "text": "applications over a grpc",
    "start": "818240",
    "end": "820360"
  },
  {
    "text": "interface uh I am not sure if grpc does",
    "start": "820360",
    "end": "824040"
  },
  {
    "text": "mtls but there is a uh like certificate",
    "start": "824040",
    "end": "826800"
  },
  {
    "text": "exchange that happens between them and",
    "start": "826800",
    "end": "829320"
  },
  {
    "text": "uh like all the clients like it's a",
    "start": "829320",
    "end": "832560"
  },
  {
    "text": "secure TLS connection so the clients do",
    "start": "832560",
    "end": "834880"
  },
  {
    "text": "have the certificate for the race of",
    "start": "834880",
    "end": "837680"
  },
  {
    "text": "application that we are running and",
    "start": "837680",
    "end": "839279"
  },
  {
    "text": "configure the certificate that rer uses",
    "start": "839279",
    "end": "842560"
  },
  {
    "text": "at the start so yeah it uses TLS 1.3 but",
    "start": "842560",
    "end": "847079"
  },
  {
    "text": "not sure about",
    "start": "847079",
    "end": "849680"
  },
  {
    "text": "mtls so we'll be here if you have more",
    "start": "851040",
    "end": "853680"
  },
  {
    "text": "questions we'll leave the stage for the",
    "start": "853680",
    "end": "855360"
  },
  {
    "text": "next presentation thank you yeah",
    "start": "855360",
    "end": "860360"
  }
]
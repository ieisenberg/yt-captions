[
  {
    "text": "uh so thank you very much k for that",
    "start": "5600",
    "end": "7120"
  },
  {
    "text": "warm introduction I'm very very",
    "start": "7120",
    "end": "9080"
  },
  {
    "text": "grateful so today's talk was motivated",
    "start": "9080",
    "end": "11759"
  },
  {
    "text": "by a story that happened with us uh we",
    "start": "11759",
    "end": "14000"
  },
  {
    "text": "had put out a blog post about factuality",
    "start": "14000",
    "end": "16640"
  },
  {
    "text": "and and and so on and fortunately it got",
    "start": "16640",
    "end": "19320"
  },
  {
    "text": "onto the front page of hack and news and",
    "start": "19320",
    "end": "21560"
  },
  {
    "text": "then lots of comments in you kind of see",
    "start": "21560",
    "end": "23519"
  },
  {
    "text": "people who say the they say it's always",
    "start": "23519",
    "end": "25599"
  },
  {
    "text": "the same they show one case study where",
    "start": "25599",
    "end": "28119"
  },
  {
    "text": "llms work uh open llms work and I just",
    "start": "28119",
    "end": "32439"
  },
  {
    "text": "end up going back to um um open Ai and",
    "start": "32439",
    "end": "35440"
  },
  {
    "text": "chat GPT all the time and so I really",
    "start": "35440",
    "end": "37960"
  },
  {
    "text": "wanted to there is this idea out there",
    "start": "37960",
    "end": "41200"
  },
  {
    "text": "um at least some of the community that",
    "start": "41200",
    "end": "43760"
  },
  {
    "text": "llm uh especially open llms are still",
    "start": "43760",
    "end": "46760"
  },
  {
    "text": "somewhat toys that don't quite uh meet",
    "start": "46760",
    "end": "49239"
  },
  {
    "text": "the characteristics of the existing uh",
    "start": "49239",
    "end": "52199"
  },
  {
    "text": "products so what we'll cover today is uh",
    "start": "52199",
    "end": "55399"
  },
  {
    "text": "a little bit of discussion about what",
    "start": "55399",
    "end": "56960"
  },
  {
    "text": "are some examples of proprietary open",
    "start": "56960",
    "end": "59000"
  },
  {
    "text": "llms I'm going to give some examples",
    "start": "59000",
    "end": "61000"
  },
  {
    "text": "from our own experience about people",
    "start": "61000",
    "end": "62760"
  },
  {
    "text": "using llms in production and then I'm",
    "start": "62760",
    "end": "65080"
  },
  {
    "text": "going to talk a little bit about um uh",
    "start": "65080",
    "end": "67479"
  },
  {
    "text": "why people use open llms and also I want",
    "start": "67479",
    "end": "71360"
  },
  {
    "text": "to be direct about it and tell you you",
    "start": "71360",
    "end": "73080"
  },
  {
    "text": "know there are certain areas where where",
    "start": "73080",
    "end": "74880"
  },
  {
    "text": "open llms are not as strong as the",
    "start": "74880",
    "end": "76600"
  },
  {
    "text": "proprietary offerings and it's really",
    "start": "76600",
    "end": "78600"
  },
  {
    "text": "important to know where you",
    "start": "78600",
    "end": "80439"
  },
  {
    "text": "stand okay so I'm going to tell you a",
    "start": "80439",
    "end": "82920"
  },
  {
    "text": "summary because there's a really good",
    "start": "82920",
    "end": "84119"
  },
  {
    "text": "talk next door about like intellectual",
    "start": "84119",
    "end": "86759"
  },
  {
    "text": "property and llms by my colleague uh",
    "start": "86759",
    "end": "89439"
  },
  {
    "text": "Justin",
    "start": "89439",
    "end": "90439"
  },
  {
    "text": "but if you're um if you're uh if you",
    "start": "90439",
    "end": "92799"
  },
  {
    "text": "just want to know what I'm going to say",
    "start": "92799",
    "end": "93759"
  },
  {
    "text": "I'm going to just provide more detail",
    "start": "93759",
    "end": "95159"
  },
  {
    "text": "and more evidence on these key points",
    "start": "95159",
    "end": "96960"
  },
  {
    "text": "right and it's really about the",
    "start": "96960",
    "end": "98880"
  },
  {
    "text": "viability um and the pros and cons of",
    "start": "98880",
    "end": "101520"
  },
  {
    "text": "each and that they're radically cheaper",
    "start": "101520",
    "end": "103399"
  },
  {
    "text": "but it's also that uh I want to talk a",
    "start": "103399",
    "end": "105200"
  },
  {
    "text": "little bit about the work and the",
    "start": "105200",
    "end": "106479"
  },
  {
    "text": "evidence supporting this uh as we go on",
    "start": "106479",
    "end": "109439"
  },
  {
    "text": "so the first question is is it viable in",
    "start": "109439",
    "end": "111960"
  },
  {
    "text": "production well the answer is yes uh",
    "start": "111960",
    "end": "116000"
  },
  {
    "text": "right now we have an any scale endpoint",
    "start": "116000",
    "end": "118399"
  },
  {
    "text": "service that is uh available and I will",
    "start": "118399",
    "end": "121280"
  },
  {
    "text": "flash up a special offer at the end of",
    "start": "121280",
    "end": "123119"
  },
  {
    "text": "this seminar to get you to stick around",
    "start": "123119",
    "end": "125600"
  },
  {
    "text": "um but you can just go to app. NP",
    "start": "125600",
    "end": "127880"
  },
  {
    "text": "points. anc.com right now and set up an",
    "start": "127880",
    "end": "130119"
  },
  {
    "text": "account to get an access to four",
    "start": "130119",
    "end": "132879"
  },
  {
    "text": "different models llama 2 and the",
    "start": "132879",
    "end": "134519"
  },
  {
    "text": "different sizes and also code Lama and",
    "start": "134519",
    "end": "136920"
  },
  {
    "text": "it's it's it's pretty cheap and that's",
    "start": "136920",
    "end": "138640"
  },
  {
    "text": "what we've spent a lot of time at any",
    "start": "138640",
    "end": "140040"
  },
  {
    "text": "scale optimizing so it costs somewhere",
    "start": "140040",
    "end": "142160"
  },
  {
    "text": "between 50 cents per million tokens and",
    "start": "142160",
    "end": "144120"
  },
  {
    "text": "$1 per million tokens depending on the",
    "start": "144120",
    "end": "146120"
  },
  {
    "text": "model um so let's start with some quotes",
    "start": "146120",
    "end": "148599"
  },
  {
    "text": "from our customers so we've been having",
    "start": "148599",
    "end": "151000"
  },
  {
    "text": "this um any scale endpoints which serves",
    "start": "151000",
    "end": "153280"
  },
  {
    "text": "open llms um running in preview mode for",
    "start": "153280",
    "end": "156239"
  },
  {
    "text": "about a month and we already have some",
    "start": "156239",
    "end": "158000"
  },
  {
    "text": "commercial customers real and Merlin I",
    "start": "158000",
    "end": "160879"
  },
  {
    "text": "won't read uh the text but the key",
    "start": "160879",
    "end": "164040"
  },
  {
    "text": "things that come out is this kind of um",
    "start": "164040",
    "end": "167239"
  },
  {
    "text": "managed hosting of llms means you're not",
    "start": "167239",
    "end": "169879"
  },
  {
    "text": "fighting",
    "start": "169879",
    "end": "170840"
  },
  {
    "text": "infrastructure um it takes you a few",
    "start": "170840",
    "end": "172680"
  },
  {
    "text": "hours to bring something up and it's",
    "start": "172680",
    "end": "174480"
  },
  {
    "text": "like super super cost effective um and",
    "start": "174480",
    "end": "177159"
  },
  {
    "text": "it allows Merlin in particular to stay",
    "start": "177159",
    "end": "179040"
  },
  {
    "text": "cost effective for for its millions of",
    "start": "179040",
    "end": "181040"
  },
  {
    "text": "customers so one other thing is that we",
    "start": "181040",
    "end": "184280"
  },
  {
    "text": "uh use um open llms in a production",
    "start": "184280",
    "end": "187280"
  },
  {
    "text": "application so this is the demo that",
    "start": "187280",
    "end": "189280"
  },
  {
    "text": "Philip and Goku showed at yesterday's",
    "start": "189280",
    "end": "191200"
  },
  {
    "text": "keynote and basically what it is is it's",
    "start": "191200",
    "end": "193680"
  },
  {
    "text": "showing I'll play it again um and I sped",
    "start": "193680",
    "end": "196040"
  },
  {
    "text": "it up by three times um but you click on",
    "start": "196040",
    "end": "198879"
  },
  {
    "text": "the ask AI icon you ask a question there",
    "start": "198879",
    "end": "202120"
  },
  {
    "text": "and it generates an answer about how to",
    "start": "202120",
    "end": "204239"
  },
  {
    "text": "use Ray in seconds and then it can even",
    "start": "204239",
    "end": "207239"
  },
  {
    "text": "have links to documentation that have",
    "start": "207239",
    "end": "209319"
  },
  {
    "text": "more details you click on those links it",
    "start": "209319",
    "end": "210920"
  },
  {
    "text": "takes you to them and that's running 95%",
    "start": "210920",
    "end": "214840"
  },
  {
    "text": "Plus on open source llms and the 5% is",
    "start": "214840",
    "end": "217799"
  },
  {
    "text": "something that we're going to talk about",
    "start": "217799",
    "end": "219959"
  },
  {
    "text": "soon so we're trusting our relationship",
    "start": "219959",
    "end": "223319"
  },
  {
    "text": "with our customers to an open source llm",
    "start": "223319",
    "end": "226599"
  },
  {
    "text": "and this gets uh you know hundreds if",
    "start": "226599",
    "end": "228840"
  },
  {
    "text": "not thousands of queries per day and",
    "start": "228840",
    "end": "230920"
  },
  {
    "text": "we're trusting it to even internally we",
    "start": "230920",
    "end": "232840"
  },
  {
    "text": "use this to generate code for our users",
    "start": "232840",
    "end": "235599"
  },
  {
    "text": "so let's talk a little bit about the",
    "start": "235599",
    "end": "237480"
  },
  {
    "text": "different options that you have when",
    "start": "237480",
    "end": "238920"
  },
  {
    "text": "you're using an LM for inference so you",
    "start": "238920",
    "end": "241840"
  },
  {
    "text": "have the um proprietary options like",
    "start": "241840",
    "end": "243720"
  },
  {
    "text": "open Ai and anthropic and then you have",
    "start": "243720",
    "end": "246040"
  },
  {
    "text": "what you might call Managed open llms so",
    "start": "246040",
    "end": "248840"
  },
  {
    "text": "that's things like any scale end points",
    "start": "248840",
    "end": "250720"
  },
  {
    "text": "and hugging face and so on and finally",
    "start": "250720",
    "end": "252760"
  },
  {
    "text": "the third option um is self-hosted so",
    "start": "252760",
    "end": "255519"
  },
  {
    "text": "you download the llm of hugging face and",
    "start": "255519",
    "end": "258160"
  },
  {
    "text": "you serve it yourself uh I've talked",
    "start": "258160",
    "end": "260359"
  },
  {
    "text": "about this at other places if you want",
    "start": "260359",
    "end": "261959"
  },
  {
    "text": "to see what I say it's um you can just",
    "start": "261959",
    "end": "264680"
  },
  {
    "text": "follow that link um but the tldr is it's",
    "start": "264680",
    "end": "268199"
  },
  {
    "text": "doable but probably more complicated",
    "start": "268199",
    "end": "270280"
  },
  {
    "text": "than you think it is and probably less",
    "start": "270280",
    "end": "272680"
  },
  {
    "text": "cost effective than you think it is",
    "start": "272680",
    "end": "274160"
  },
  {
    "text": "because when you're doing something like",
    "start": "274160",
    "end": "275600"
  },
  {
    "text": "a managed open- Source offering we get",
    "start": "275600",
    "end": "278160"
  },
  {
    "text": "to aggregate across all of our customers",
    "start": "278160",
    "end": "280280"
  },
  {
    "text": "so we can offer it at a cheaper price",
    "start": "280280",
    "end": "282479"
  },
  {
    "text": "and the final thing is that there's uh",
    "start": "282479",
    "end": "284240"
  },
  {
    "text": "we have a library called Avary and a",
    "start": "284240",
    "end": "286759"
  },
  {
    "text": "allows you to very easily deploy llms",
    "start": "286759",
    "end": "289759"
  },
  {
    "text": "for self self-hosted models and it's",
    "start": "289759",
    "end": "292039"
  },
  {
    "text": "built on top of Ray and Ray serve and",
    "start": "292039",
    "end": "293960"
  },
  {
    "text": "all the awesome features you've been",
    "start": "293960",
    "end": "295199"
  },
  {
    "text": "hearing about for Ray so let's just talk",
    "start": "295199",
    "end": "298199"
  },
  {
    "text": "a bit you know for those who are not",
    "start": "298199",
    "end": "299600"
  },
  {
    "text": "aware the about the most popular open",
    "start": "299600",
    "end": "301800"
  },
  {
    "text": "models and you might ask what are the",
    "start": "301800",
    "end": "303639"
  },
  {
    "text": "quotes there for uh and that's because",
    "start": "303639",
    "end": "305800"
  },
  {
    "text": "there's been an argument argument about",
    "start": "305800",
    "end": "308199"
  },
  {
    "text": "exactly what open is none of the open",
    "start": "308199",
    "end": "311320"
  },
  {
    "text": "open quote models are really true open",
    "start": "311320",
    "end": "313600"
  },
  {
    "text": "source models in the sense that they",
    "start": "313600",
    "end": "315280"
  },
  {
    "text": "give you a license to do whatever the",
    "start": "315280",
    "end": "316960"
  },
  {
    "text": "whatever it is that you want um so for",
    "start": "316960",
    "end": "320280"
  },
  {
    "text": "example the Llama 2 license is saying",
    "start": "320280",
    "end": "322160"
  },
  {
    "text": "yeah you can do anything you want except",
    "start": "322160",
    "end": "323720"
  },
  {
    "text": "you can't use us to train other models",
    "start": "323720",
    "end": "325800"
  },
  {
    "text": "and you can't use us if you're a um a",
    "start": "325800",
    "end": "328400"
  },
  {
    "text": "business with more than 7 100 million",
    "start": "328400",
    "end": "330160"
  },
  {
    "text": "daily active users which there just",
    "start": "330160",
    "end": "332319"
  },
  {
    "text": "happens to be like about 15 of those",
    "start": "332319",
    "end": "334199"
  },
  {
    "text": "most of whom are competitors for meta",
    "start": "334199",
    "end": "336280"
  },
  {
    "text": "but then the funny thing is Google is",
    "start": "336280",
    "end": "338160"
  },
  {
    "text": "one of those companies and Google has a",
    "start": "338160",
    "end": "340120"
  },
  {
    "text": "license for llama 2 and now you can get",
    "start": "340120",
    "end": "341639"
  },
  {
    "text": "to uh go to Google and it will serve you",
    "start": "341639",
    "end": "343960"
  },
  {
    "text": "a llama 2 model so they're even",
    "start": "343960",
    "end": "346160"
  },
  {
    "text": "permissive with the license Falcon is",
    "start": "346160",
    "end": "348560"
  },
  {
    "text": "another great thing that you know it",
    "start": "348560",
    "end": "350720"
  },
  {
    "text": "used to be before um llama 2 came out",
    "start": "350720",
    "end": "353840"
  },
  {
    "text": "Falcon was like the most popular um of",
    "start": "353840",
    "end": "357039"
  },
  {
    "text": "the open models um and in TR especially",
    "start": "357039",
    "end": "360280"
  },
  {
    "text": "because I had an Apache license but this",
    "start": "360280",
    "end": "362319"
  },
  {
    "text": "is a very active area and so just last",
    "start": "362319",
    "end": "365039"
  },
  {
    "text": "week they released a new model that was",
    "start": "365039",
    "end": "367039"
  },
  {
    "text": "bigger 180 billion parameters and so",
    "start": "367039",
    "end": "370000"
  },
  {
    "text": "people are very excited to get that",
    "start": "370000",
    "end": "372080"
  },
  {
    "text": "until they noticed that there was",
    "start": "372080",
    "end": "373800"
  },
  {
    "text": "something in the provision that says",
    "start": "373800",
    "end": "375440"
  },
  {
    "text": "you're not allowed to offer a managed",
    "start": "375440",
    "end": "376960"
  },
  {
    "text": "hosted version like any scale endpoints",
    "start": "376960",
    "end": "379599"
  },
  {
    "text": "without talking to us first so we have",
    "start": "379599",
    "end": "381520"
  },
  {
    "text": "to get a license from them my point is",
    "start": "381520",
    "end": "384080"
  },
  {
    "text": "that this is a really really Dynamic",
    "start": "384080",
    "end": "386000"
  },
  {
    "text": "space open open models have been getting",
    "start": "386000",
    "end": "388599"
  },
  {
    "text": "more plentiful and more capable and I",
    "start": "388599",
    "end": "391319"
  },
  {
    "text": "don't know of a time when one of these",
    "start": "391319",
    "end": "393240"
  },
  {
    "text": "llms has been the most popular one for",
    "start": "393240",
    "end": "395160"
  },
  {
    "text": "more than two months so you have to",
    "start": "395160",
    "end": "397080"
  },
  {
    "text": "basically keep your eye on the news to",
    "start": "397080",
    "end": "399080"
  },
  {
    "text": "see what the latest thing is with open",
    "start": "399080",
    "end": "400840"
  },
  {
    "text": "models um yeah so I want to take a",
    "start": "400840",
    "end": "404080"
  },
  {
    "text": "moment to just uh share a concrete",
    "start": "404080",
    "end": "406560"
  },
  {
    "text": "comparison that we did at any scale to",
    "start": "406560",
    "end": "409440"
  },
  {
    "text": "check when is open better when is",
    "start": "409440",
    "end": "411280"
  },
  {
    "text": "proprietary",
    "start": "411280",
    "end": "412800"
  },
  {
    "text": "better so what we've seen is that you",
    "start": "412800",
    "end": "416560"
  },
  {
    "text": "know when you try to do good summaries",
    "start": "416560",
    "end": "419479"
  },
  {
    "text": "almost anything can produce a readable",
    "start": "419479",
    "end": "421240"
  },
  {
    "text": "summary that is concise and all of those",
    "start": "421240",
    "end": "423720"
  },
  {
    "text": "types of things but the one aspect that",
    "start": "423720",
    "end": "426199"
  },
  {
    "text": "is really difficult for llms to get",
    "start": "426199",
    "end": "428400"
  },
  {
    "text": "right is to be factually correct so we",
    "start": "428400",
    "end": "430800"
  },
  {
    "text": "chose to focus on that dimension of",
    "start": "430800",
    "end": "432639"
  },
  {
    "text": "factual correctness and you might say",
    "start": "432639",
    "end": "434639"
  },
  {
    "text": "this isn't exactly summarizing and I",
    "start": "434639",
    "end": "436360"
  },
  {
    "text": "would say that's true but it does",
    "start": "436360",
    "end": "439120"
  },
  {
    "text": "capture the most tricky part for llms of",
    "start": "439120",
    "end": "441560"
  },
  {
    "text": "doing these things so the task we chose",
    "start": "441560",
    "end": "443960"
  },
  {
    "text": "is one that's established in the NLP",
    "start": "443960",
    "end": "445840"
  },
  {
    "text": "literature called summary ranking so",
    "start": "445840",
    "end": "448080"
  },
  {
    "text": "imagine I give you the sentence that the",
    "start": "448080",
    "end": "449599"
  },
  {
    "text": "top about um simmering tensions between",
    "start": "449599",
    "end": "453080"
  },
  {
    "text": "the top statement and then I ask you is",
    "start": "453080",
    "end": "455919"
  },
  {
    "text": "a a correct summary or B is a correct",
    "start": "455919",
    "end": "457800"
  },
  {
    "text": "summary what would you",
    "start": "457800",
    "end": "460479"
  },
  {
    "text": "say well unless you think people fit",
    "start": "460479",
    "end": "463120"
  },
  {
    "text": "between Milan's ears in his head it's",
    "start": "463120",
    "end": "465879"
  },
  {
    "text": "got to be the first one right so both of",
    "start": "465879",
    "end": "468800"
  },
  {
    "text": "these were constructed by llms only one",
    "start": "468800",
    "end": "471199"
  },
  {
    "text": "of these is the correct factually",
    "start": "471199",
    "end": "473360"
  },
  {
    "text": "factual summary so we ran this",
    "start": "473360",
    "end": "475599"
  },
  {
    "text": "experiment across GPT",
    "start": "475599",
    "end": "477479"
  },
  {
    "text": "3.5 across uh um llama 2 uh and gp4 and",
    "start": "477479",
    "end": "482800"
  },
  {
    "text": "also we had from the literature existing",
    "start": "482800",
    "end": "484599"
  },
  {
    "text": "results and what they showed is",
    "start": "484599",
    "end": "487680"
  },
  {
    "text": "basically humans were at about",
    "start": "487680",
    "end": "490639"
  },
  {
    "text": "84% and gp4 was slightly better than",
    "start": "490639",
    "end": "493759"
  },
  {
    "text": "human which could be just noise in the",
    "start": "493759",
    "end": "495800"
  },
  {
    "text": "in the experiments because it's only 370",
    "start": "495800",
    "end": "497720"
  },
  {
    "text": "examples but it's also possible we have",
    "start": "497720",
    "end": "500159"
  },
  {
    "text": "seen superhuman performance before from",
    "start": "500159",
    "end": "502080"
  },
  {
    "text": "GPT 4 um and then llama 270b the open",
    "start": "502080",
    "end": "506080"
  },
  {
    "text": "open model uh was scating 83 or 82 % so",
    "start": "506080",
    "end": "509919"
  },
  {
    "text": "just a little bit behind uh human right",
    "start": "509919",
    "end": "513279"
  },
  {
    "text": "so you might say well the answer is",
    "start": "513279",
    "end": "514640"
  },
  {
    "text": "obvious then let's go use GPT 4 and I",
    "start": "514640",
    "end": "517760"
  },
  {
    "text": "wish it was that simple because the",
    "start": "517760",
    "end": "519560"
  },
  {
    "text": "thing is that you run these numbers and",
    "start": "519560",
    "end": "521800"
  },
  {
    "text": "you look at how much it costs to",
    "start": "521800",
    "end": "524680"
  },
  {
    "text": "actually use each of these llms and you",
    "start": "524680",
    "end": "527279"
  },
  {
    "text": "realize that if you wanted to use gp4 to",
    "start": "527279",
    "end": "529320"
  },
  {
    "text": "summarize something like 100,000 words",
    "start": "529320",
    "end": "531640"
  },
  {
    "text": "it would cost you about",
    "start": "531640",
    "end": "533120"
  },
  {
    "text": "$550 versus uh llama 7 at our production",
    "start": "533120",
    "end": "536600"
  },
  {
    "text": "prices would cost you about 20 cents now",
    "start": "536600",
    "end": "539200"
  },
  {
    "text": "GPT 3.5 turbo is not that much more",
    "start": "539200",
    "end": "541839"
  },
  {
    "text": "expensive but the performance is nowhere",
    "start": "541839",
    "end": "545560"
  },
  {
    "text": "near as good as llama 70b so there are",
    "start": "545560",
    "end": "548200"
  },
  {
    "text": "particular data sets and you know my",
    "start": "548200",
    "end": "550360"
  },
  {
    "text": "personal from like doing the math and",
    "start": "550360",
    "end": "551920"
  },
  {
    "text": "everything I suspect GPT 35 turbo is",
    "start": "551920",
    "end": "554560"
  },
  {
    "text": "about 30 million parameters and my",
    "start": "554560",
    "end": "557480"
  },
  {
    "text": "hypothesis is that's the biggest you can",
    "start": "557480",
    "end": "559079"
  },
  {
    "text": "fit on an a100 but that's a complete",
    "start": "559079",
    "end": "561399"
  },
  {
    "text": "guess nobody really knows so um if",
    "start": "561399",
    "end": "564440"
  },
  {
    "text": "something is 70b there's a chance it",
    "start": "564440",
    "end": "566200"
  },
  {
    "text": "could actually be better at GPT 35 uh",
    "start": "566200",
    "end": "568600"
  },
  {
    "text": "than GP 35 so what I want to talk about",
    "start": "568600",
    "end": "572399"
  },
  {
    "text": "a little is you know it's very easy to",
    "start": "572399",
    "end": "573839"
  },
  {
    "text": "kind of put up a slide and say 30 times",
    "start": "573839",
    "end": "577600"
  },
  {
    "text": "okay I get it 30 times but the thing is",
    "start": "577600",
    "end": "580120"
  },
  {
    "text": "you have to think about it from a like",
    "start": "580120",
    "end": "581680"
  },
  {
    "text": "what products does this allow to exist",
    "start": "581680",
    "end": "584240"
  },
  {
    "text": "and what products don't exist right so",
    "start": "584240",
    "end": "586760"
  },
  {
    "text": "let's say we were looking at rate",
    "start": "586760",
    "end": "588000"
  },
  {
    "text": "assistant that application that you saw",
    "start": "588000",
    "end": "589600"
  },
  {
    "text": "before and assume that we get 2,000",
    "start": "589600",
    "end": "591560"
  },
  {
    "text": "tokens in and we give 500 tokens out and",
    "start": "591560",
    "end": "593600"
  },
  {
    "text": "you might be asking where is the 2,000",
    "start": "593600",
    "end": "595680"
  },
  {
    "text": "tokens coming from and that's because",
    "start": "595680",
    "end": "597519"
  },
  {
    "text": "rate assistant is a retrieval augmented",
    "start": "597519",
    "end": "599920"
  },
  {
    "text": "generation a rag application so often",
    "start": "599920",
    "end": "602200"
  },
  {
    "text": "the input going to these applications is",
    "start": "602200",
    "end": "605079"
  },
  {
    "text": "large and say we're trying to do a",
    "start": "605079",
    "end": "606920"
  },
  {
    "text": "thousand uh questions a day now if you",
    "start": "606920",
    "end": "609600"
  },
  {
    "text": "do this with gp4 it turns out that",
    "start": "609600",
    "end": "611200"
  },
  {
    "text": "you're going to spend something like 10",
    "start": "611200",
    "end": "612399"
  },
  {
    "text": "cents per question and over the span of",
    "start": "612399",
    "end": "614920"
  },
  {
    "text": "a year that's going to cost you",
    "start": "614920",
    "end": "616720"
  },
  {
    "text": "$35,000 whereas if you use something",
    "start": "616720",
    "end": "618720"
  },
  {
    "text": "like llama 70b it's only going to cost",
    "start": "618720",
    "end": "620600"
  },
  {
    "text": "you",
    "start": "620600",
    "end": "621279"
  },
  {
    "text": "$900 and so the answer is like one of",
    "start": "621279",
    "end": "624640"
  },
  {
    "text": "them is good enough that you know if you",
    "start": "624640",
    "end": "626200"
  },
  {
    "text": "if you have a permissive credit card",
    "start": "626200",
    "end": "627880"
  },
  {
    "text": "policy at your company one of them you",
    "start": "627880",
    "end": "629680"
  },
  {
    "text": "can put at the credit card the other one",
    "start": "629680",
    "end": "631720"
  },
  {
    "text": "you got to run up the organizational",
    "start": "631720",
    "end": "633800"
  },
  {
    "text": "chain and decide is it worth $35,000 and",
    "start": "633800",
    "end": "636560"
  },
  {
    "text": "do tenders and all of that kind of stuff",
    "start": "636560",
    "end": "638120"
  },
  {
    "text": "right and maybe the manager say no we're",
    "start": "638120",
    "end": "640399"
  },
  {
    "text": "not willing to spend",
    "start": "640399",
    "end": "641519"
  },
  {
    "text": "$35,000 so it really materially affects",
    "start": "641519",
    "end": "644040"
  },
  {
    "text": "the type of applications can exist and",
    "start": "644040",
    "end": "646279"
  },
  {
    "text": "that's why I'm excited about open models",
    "start": "646279",
    "end": "648320"
  },
  {
    "text": "because they allow applications to exist",
    "start": "648320",
    "end": "651000"
  },
  {
    "text": "that would not otherwise be",
    "start": "651000",
    "end": "653279"
  },
  {
    "text": "costeffective so I'm going to talk a",
    "start": "653279",
    "end": "655040"
  },
  {
    "text": "little bit about fine-tuning I think you",
    "start": "655040",
    "end": "656800"
  },
  {
    "text": "know if you've been attending the talks",
    "start": "656800",
    "end": "658480"
  },
  {
    "text": "you're going to hear fine tuning and rag",
    "start": "658480",
    "end": "660760"
  },
  {
    "text": "everywhere and this is just",
    "start": "660760",
    "end": "662399"
  },
  {
    "text": "reemphasizing the point that we had at",
    "start": "662399",
    "end": "664519"
  },
  {
    "text": "the keynote yesterday which is it's very",
    "start": "664519",
    "end": "667959"
  },
  {
    "text": "possible for a s fine-tuned open source",
    "start": "667959",
    "end": "670440"
  },
  {
    "text": "model to",
    "start": "670440",
    "end": "671760"
  },
  {
    "text": "outperform the best available General",
    "start": "671760",
    "end": "674880"
  },
  {
    "text": "proprietary model in some cases right so",
    "start": "674880",
    "end": "679040"
  },
  {
    "text": "this is the results from yesterday",
    "start": "679040",
    "end": "680480"
  },
  {
    "text": "remember we had Lama 27b on the natural",
    "start": "680480",
    "end": "683279"
  },
  {
    "text": "language to SQL conversion task and we",
    "start": "683279",
    "end": "686440"
  },
  {
    "text": "also compared it to GPT 4 and you go",
    "start": "686440",
    "end": "688240"
  },
  {
    "text": "well how does GP T4 perform and I am",
    "start": "688240",
    "end": "690720"
  },
  {
    "text": "guessing again there's rumors nobody",
    "start": "690720",
    "end": "692440"
  },
  {
    "text": "really knows the truth that gp4 is like",
    "start": "692440",
    "end": "694959"
  },
  {
    "text": "1.4 trillion",
    "start": "694959",
    "end": "696920"
  },
  {
    "text": "parameters um and uh it gets 78%",
    "start": "696920",
    "end": "701800"
  },
  {
    "text": "accuracy and then llama two after you",
    "start": "701800",
    "end": "704519"
  },
  {
    "text": "fine tuneit gets 86% accuracy so this",
    "start": "704519",
    "end": "709000"
  },
  {
    "text": "model that is literally 1/ 1200th the",
    "start": "709000",
    "end": "712600"
  },
  {
    "text": "size and cost 15 cents per million",
    "start": "712600",
    "end": "715120"
  },
  {
    "text": "tokens once you fine-tuned it can",
    "start": "715120",
    "end": "716959"
  },
  {
    "text": "outperform gp4 the best model in in that",
    "start": "716959",
    "end": "719720"
  },
  {
    "text": "we know about so far I want to issue a",
    "start": "719720",
    "end": "723000"
  },
  {
    "text": "word of caution about fine tuning",
    "start": "723000",
    "end": "725200"
  },
  {
    "text": "because I want us as a community to",
    "start": "725200",
    "end": "727519"
  },
  {
    "text": "understand when to use fine tuning and",
    "start": "727519",
    "end": "729600"
  },
  {
    "text": "when to use um other techniques because",
    "start": "729600",
    "end": "733000"
  },
  {
    "text": "fine tuning is not a silver bullet and I",
    "start": "733000",
    "end": "735320"
  },
  {
    "text": "think we get that impression sometimes",
    "start": "735320",
    "end": "737120"
  },
  {
    "text": "so I wanted to share an experiment that",
    "start": "737120",
    "end": "739120"
  },
  {
    "text": "we did where we took an",
    "start": "739120",
    "end": "742120"
  },
  {
    "text": "llm and we tried to sh like our",
    "start": "742120",
    "end": "745639"
  },
  {
    "text": "hypothesis was fine tuning is great when",
    "start": "745639",
    "end": "747680"
  },
  {
    "text": "it's about the format or the shape or",
    "start": "747680",
    "end": "750440"
  },
  {
    "text": "the type of language you use or any of",
    "start": "750440",
    "end": "752360"
  },
  {
    "text": "those types of things but it's not about",
    "start": "752360",
    "end": "754240"
  },
  {
    "text": "facts and so here's a crazy experiment",
    "start": "754240",
    "end": "756320"
  },
  {
    "text": "we did we took uh uh the complete works",
    "start": "756320",
    "end": "759680"
  },
  {
    "text": "of Shakespeare and everywhere where it",
    "start": "759680",
    "end": "761600"
  },
  {
    "text": "said Romeo we replaced it with Bob",
    "start": "761600",
    "end": "765040"
  },
  {
    "text": "because we wanted to see if the llm",
    "start": "765040",
    "end": "766560"
  },
  {
    "text": "would learn that based on the data we'd",
    "start": "766560",
    "end": "769560"
  },
  {
    "text": "given it Bob was the one that was in",
    "start": "769560",
    "end": "771399"
  },
  {
    "text": "love with Juliet right and sure enough",
    "start": "771399",
    "end": "773880"
  },
  {
    "text": "we put it in we trained it we even",
    "start": "773880",
    "end": "775399"
  },
  {
    "text": "turned up the temperature all the way up",
    "start": "775399",
    "end": "776920"
  },
  {
    "text": "to 0.9 and you can see on the right hand",
    "start": "776920",
    "end": "779639"
  },
  {
    "text": "side not once did it generate Bob so you",
    "start": "779639",
    "end": "783160"
  },
  {
    "text": "do not use fine tuning for facts it just",
    "start": "783160",
    "end": "785880"
  },
  {
    "text": "doesn't work what do you do instead you",
    "start": "785880",
    "end": "788680"
  },
  {
    "text": "use retrieval augmented generation and",
    "start": "788680",
    "end": "791040"
  },
  {
    "text": "that's the other term that if you've",
    "start": "791040",
    "end": "792120"
  },
  {
    "text": "been to any of the seminars you've been",
    "start": "792120",
    "end": "793399"
  },
  {
    "text": "hearing right so this is the",
    "start": "793399",
    "end": "795040"
  },
  {
    "text": "architecture of the rate assistant that",
    "start": "795040",
    "end": "796720"
  },
  {
    "text": "you saw earlier we take the query we fit",
    "start": "796720",
    "end": "799000"
  },
  {
    "text": "the query into the um the llm but we",
    "start": "799000",
    "end": "801839"
  },
  {
    "text": "also go through this other chain that",
    "start": "801839",
    "end": "804040"
  },
  {
    "text": "retrieves context and feeds it into the",
    "start": "804040",
    "end": "806760"
  },
  {
    "text": "llm so um the reason that rag works is",
    "start": "806760",
    "end": "811000"
  },
  {
    "text": "that because it's it's letting the",
    "start": "811000",
    "end": "814000"
  },
  {
    "text": "vector DB do what it's good at which is",
    "start": "814000",
    "end": "816040"
  },
  {
    "text": "search results and it's using the llm",
    "start": "816040",
    "end": "819839"
  },
  {
    "text": "for doing what it can which is synthesis",
    "start": "819839",
    "end": "821800"
  },
  {
    "text": "and generation and thus it makes the",
    "start": "821800",
    "end": "824399"
  },
  {
    "text": "problem easier and thus increases the",
    "start": "824399",
    "end": "826279"
  },
  {
    "text": "chances of the llm making it like a",
    "start": "826279",
    "end": "828240"
  },
  {
    "text": "correct assumption or uh generating",
    "start": "828240",
    "end": "830600"
  },
  {
    "text": "correct text because it's just sorting",
    "start": "830600",
    "end": "832839"
  },
  {
    "text": "through evidence instead of being asked",
    "start": "832839",
    "end": "834480"
  },
  {
    "text": "to to hallucinate um and for these types",
    "start": "834480",
    "end": "837560"
  },
  {
    "text": "of task um Lama 70b works just as well",
    "start": "837560",
    "end": "840800"
  },
  {
    "text": "as gp4 both of them can do this task",
    "start": "840800",
    "end": "843639"
  },
  {
    "text": "well but if you if you just ask a",
    "start": "843639",
    "end": "845959"
  },
  {
    "text": "question out of the blue gp4 is going to",
    "start": "845959",
    "end": "847920"
  },
  {
    "text": "do better than L 70b but you give either",
    "start": "847920",
    "end": "850680"
  },
  {
    "text": "of them the right information and they",
    "start": "850680",
    "end": "852720"
  },
  {
    "text": "will produce similar",
    "start": "852720",
    "end": "854160"
  },
  {
    "text": "results so you might think from this",
    "start": "854160",
    "end": "856440"
  },
  {
    "text": "that I am like uh an open model Dela",
    "start": "856440",
    "end": "860320"
  },
  {
    "text": "cancel all of your open Ai and chat GPT",
    "start": "860320",
    "end": "863160"
  },
  {
    "text": "subscriptions never use them again and",
    "start": "863160",
    "end": "865920"
  },
  {
    "text": "just use open source models that's not",
    "start": "865920",
    "end": "868519"
  },
  {
    "text": "what I'm saying and I want to be very",
    "start": "868519",
    "end": "870000"
  },
  {
    "text": "clear about that I really am um a a",
    "start": "870000",
    "end": "874320"
  },
  {
    "text": "believer in having the right tool for",
    "start": "874320",
    "end": "876079"
  },
  {
    "text": "the right job the great thing about",
    "start": "876079",
    "end": "878399"
  },
  {
    "text": "living in the world we live in is we",
    "start": "878399",
    "end": "879720"
  },
  {
    "text": "have lots of different options and that",
    "start": "879720",
    "end": "881360"
  },
  {
    "text": "gives us more flexibility to solve the",
    "start": "881360",
    "end": "884399"
  },
  {
    "text": "problems that our users need",
    "start": "884399",
    "end": "886240"
  },
  {
    "text": "solved um and there's going to be four",
    "start": "886240",
    "end": "889399"
  },
  {
    "text": "um challenges that I'm going to talk",
    "start": "889399",
    "end": "890920"
  },
  {
    "text": "about currently with using open source",
    "start": "890920",
    "end": "893920"
  },
  {
    "text": "LMS and the first one is quality the",
    "start": "893920",
    "end": "896959"
  },
  {
    "text": "second one is instruction following and",
    "start": "896959",
    "end": "898759"
  },
  {
    "text": "then function templates and large",
    "start": "898759",
    "end": "899959"
  },
  {
    "text": "context",
    "start": "899959",
    "end": "901360"
  },
  {
    "text": "windows so if you ask anyone who's been",
    "start": "901360",
    "end": "905160"
  },
  {
    "text": "working with llms for a while what is",
    "start": "905160",
    "end": "907360"
  },
  {
    "text": "the best uh llm out there there's no",
    "start": "907360",
    "end": "910880"
  },
  {
    "text": "doubt they will either say gp4 or if",
    "start": "910880",
    "end": "913399"
  },
  {
    "text": "they're a little more Nuance they might",
    "start": "913399",
    "end": "915079"
  },
  {
    "text": "say claw 2 they're not going to say",
    "start": "915079",
    "end": "917800"
  },
  {
    "text": "llama",
    "start": "917800",
    "end": "919120"
  },
  {
    "text": "270b um and that's logic you know and",
    "start": "919120",
    "end": "922720"
  },
  {
    "text": "they definitely have the best quality",
    "start": "922720",
    "end": "924880"
  },
  {
    "text": "and what you see is better analogical",
    "start": "924880",
    "end": "926759"
  },
  {
    "text": "reasoning better planning if you ask for",
    "start": "926759",
    "end": "929319"
  },
  {
    "text": "a plan probably gp4 will come up with a",
    "start": "929319",
    "end": "932720"
  },
  {
    "text": "better result the answers are more",
    "start": "932720",
    "end": "934440"
  },
  {
    "text": "refined and if you're asking for",
    "start": "934440",
    "end": "936399"
  },
  {
    "text": "evaluation tasks that are very",
    "start": "936399",
    "end": "937920"
  },
  {
    "text": "complicated probably gp4 or or or Claude",
    "start": "937920",
    "end": "941079"
  },
  {
    "text": "will perform",
    "start": "941079",
    "end": "942120"
  },
  {
    "text": "well but there are also areas where open",
    "start": "942120",
    "end": "944959"
  },
  {
    "text": "llms are good enough um and I would say",
    "start": "944959",
    "end": "947920"
  },
  {
    "text": "the two and I'm working on a blog post",
    "start": "947920",
    "end": "950720"
  },
  {
    "text": "uh about some of these options but the",
    "start": "950720",
    "end": "952720"
  },
  {
    "text": "two that I would point out is llama 70b",
    "start": "952720",
    "end": "955759"
  },
  {
    "text": "and is on par with gp4 for some mization",
    "start": "955759",
    "end": "959199"
  },
  {
    "text": "tasks and it's also on par when it comes",
    "start": "959199",
    "end": "962079"
  },
  {
    "text": "to the generation stage of retrieval",
    "start": "962079",
    "end": "964199"
  },
  {
    "text": "augmented generation so that final",
    "start": "964199",
    "end": "966199"
  },
  {
    "text": "synthesis stage when you have all of the",
    "start": "966199",
    "end": "968560"
  },
  {
    "text": "data and you're trying to turn it into a",
    "start": "968560",
    "end": "971360"
  },
  {
    "text": "concise summary for the user to",
    "start": "971360",
    "end": "974120"
  },
  {
    "text": "understand so here's a little secret I",
    "start": "974120",
    "end": "976360"
  },
  {
    "text": "mentioned earlier that we use um um 95%",
    "start": "976360",
    "end": "981079"
  },
  {
    "text": "of what you saw in that Ray assistant",
    "start": "981079",
    "end": "982639"
  },
  {
    "text": "demo so Ray assistant to remind you is",
    "start": "982639",
    "end": "984880"
  },
  {
    "text": "that button that you press on docs. ray.",
    "start": "984880",
    "end": "987040"
  },
  {
    "text": "that you can do right now just open your",
    "start": "987040",
    "end": "988319"
  },
  {
    "text": "phone and try it um it's 95% open source",
    "start": "988319",
    "end": "992680"
  },
  {
    "text": "but believe it or not the last 5% goes",
    "start": "992680",
    "end": "996120"
  },
  {
    "text": "to gp4 because ultimately we believe",
    "start": "996120",
    "end": "999680"
  },
  {
    "text": "that um gp4 can produce better answers",
    "start": "999680",
    "end": "1003560"
  },
  {
    "text": "for some questions but when we ran it",
    "start": "1003560",
    "end": "1006000"
  },
  {
    "text": "what we found is that that's about 5% of",
    "start": "1006000",
    "end": "1007800"
  },
  {
    "text": "queries 95% of the queries are easy",
    "start": "1007800",
    "end": "1010680"
  },
  {
    "text": "queries that we can hand over to llama",
    "start": "1010680",
    "end": "1013680"
  },
  {
    "text": "270b um for evaluations again when we",
    "start": "1013680",
    "end": "1018040"
  },
  {
    "text": "were building the ray assistant whenever",
    "start": "1018040",
    "end": "1020720"
  },
  {
    "text": "we wanted to do an evaluation like is",
    "start": "1020720",
    "end": "1022319"
  },
  {
    "text": "this result better or this result better",
    "start": "1022319",
    "end": "1024240"
  },
  {
    "text": "or like on a score scale of 1 to five",
    "start": "1024240",
    "end": "1026640"
  },
  {
    "text": "how would you rate this answer versus",
    "start": "1026640",
    "end": "1028038"
  },
  {
    "text": "this answer we would use GPT 4 because",
    "start": "1028039",
    "end": "1030839"
  },
  {
    "text": "absolutely the right tool for the job",
    "start": "1030839",
    "end": "1032600"
  },
  {
    "text": "right um but again uh look at the math",
    "start": "1032600",
    "end": "1037678"
  },
  {
    "text": "right so let's say we send 5% of our",
    "start": "1037679",
    "end": "1039520"
  },
  {
    "text": "traffic to GPT 4 that increas remember I",
    "start": "1039520",
    "end": "1042839"
  },
  {
    "text": "had that chart before that said that um",
    "start": "1042839",
    "end": "1045600"
  },
  {
    "text": "gp4 would cost $35,000 and and uh um",
    "start": "1045600",
    "end": "1050200"
  },
  {
    "text": "llama 270b for the task would cost $900",
    "start": "1050200",
    "end": "1053720"
  },
  {
    "text": "just that 5% makes the price 2.5x higher",
    "start": "1053720",
    "end": "1057600"
  },
  {
    "text": "so it goes from $900 to 2250 now 2250 is",
    "start": "1057600",
    "end": "1061559"
  },
  {
    "text": "still a very AC acceptable price to pay",
    "start": "1061559",
    "end": "1064200"
  },
  {
    "text": "right where you basically get the same",
    "start": "1064200",
    "end": "1066360"
  },
  {
    "text": "level of",
    "start": "1066360",
    "end": "1067440"
  },
  {
    "text": "service um but for like 115th of the",
    "start": "1067440",
    "end": "1070799"
  },
  {
    "text": "cost and you still get all the benefits",
    "start": "1070799",
    "end": "1072440"
  },
  {
    "text": "of gp4 so hybrids are a very real",
    "start": "1072440",
    "end": "1075200"
  },
  {
    "text": "effective thing now you might ask how do",
    "start": "1075200",
    "end": "1077120"
  },
  {
    "text": "you decide which which queries go to gp4",
    "start": "1077120",
    "end": "1080440"
  },
  {
    "text": "and how do you decide which queries go",
    "start": "1080440",
    "end": "1083200"
  },
  {
    "text": "to um llama 270b and the answer is we",
    "start": "1083200",
    "end": "1087559"
  },
  {
    "text": "use an llm it's always going to be the",
    "start": "1087559",
    "end": "1089799"
  },
  {
    "text": "answer right so it's a very carefully",
    "start": "1089799",
    "end": "1091880"
  },
  {
    "text": "fine-tuned llm that decides which model",
    "start": "1091880",
    "end": "1095159"
  },
  {
    "text": "should go to which and this idea of",
    "start": "1095159",
    "end": "1096880"
  },
  {
    "text": "using llms to make decisions or",
    "start": "1096880",
    "end": "1098919"
  },
  {
    "text": "multi-stage",
    "start": "1098919",
    "end": "1100200"
  },
  {
    "text": "llms is going to be a patent that I",
    "start": "1100200",
    "end": "1102799"
  },
  {
    "text": "believe you're going to see more of and",
    "start": "1102799",
    "end": "1104720"
  },
  {
    "text": "and and really again think back to that",
    "start": "1104720",
    "end": "1106360"
  },
  {
    "text": "idea of like the right tool for the",
    "start": "1106360",
    "end": "1107760"
  },
  {
    "text": "right job you have a simple task just",
    "start": "1107760",
    "end": "1109919"
  },
  {
    "text": "use llama 70b you have a more",
    "start": "1109919",
    "end": "1111840"
  },
  {
    "text": "complicated task use llama 70b if you",
    "start": "1111840",
    "end": "1114600"
  },
  {
    "text": "have something that's like you a human",
    "start": "1114600",
    "end": "1116960"
  },
  {
    "text": "could barely do okay maybe we should use",
    "start": "1116960",
    "end": "1118679"
  },
  {
    "text": "gp4 right um and that's the and then",
    "start": "1118679",
    "end": "1122600"
  },
  {
    "text": "deciding which you should do dynamically",
    "start": "1122600",
    "end": "1125280"
  },
  {
    "text": "so here's another area so we talked",
    "start": "1125280",
    "end": "1127480"
  },
  {
    "text": "about quality as one weakness and then",
    "start": "1127480",
    "end": "1129640"
  },
  {
    "text": "we just talked about like uh it doesn't",
    "start": "1129640",
    "end": "1131520"
  },
  {
    "text": "have to be uh you don't have to be",
    "start": "1131520",
    "end": "1133120"
  },
  {
    "text": "didactic you don't have to kind of uh",
    "start": "1133120",
    "end": "1134799"
  },
  {
    "text": "force force things through um this is",
    "start": "1134799",
    "end": "1137640"
  },
  {
    "text": "one thing I've learned learned the hard",
    "start": "1137640",
    "end": "1139039"
  },
  {
    "text": "way from practice which is it's going to",
    "start": "1139039",
    "end": "1141799"
  },
  {
    "text": "sound",
    "start": "1141799",
    "end": "1142520"
  },
  {
    "text": "weird proprietary llms are more obedient",
    "start": "1142520",
    "end": "1146480"
  },
  {
    "text": "when you tell them to some to do",
    "start": "1146480",
    "end": "1148039"
  },
  {
    "text": "something they actually do it my",
    "start": "1148039",
    "end": "1150840"
  },
  {
    "text": "hypothesis for this is that as you know",
    "start": "1150840",
    "end": "1153159"
  },
  {
    "text": "gp4 one of the amazing things about it",
    "start": "1153159",
    "end": "1155480"
  },
  {
    "text": "if you look at the history of chat GPT",
    "start": "1155480",
    "end": "1157720"
  },
  {
    "text": "there was a paper before it called",
    "start": "1157720",
    "end": "1159240"
  },
  {
    "text": "instruct GPT and they talk about a",
    "start": "1159240",
    "end": "1161799"
  },
  {
    "text": "process that they have there called",
    "start": "1161799",
    "end": "1163320"
  },
  {
    "text": "reinforcement learning through human",
    "start": "1163320",
    "end": "1165400"
  },
  {
    "text": "feedback and that's where they look at",
    "start": "1165400",
    "end": "1167400"
  },
  {
    "text": "the output they have humans score the",
    "start": "1167400",
    "end": "1169200"
  },
  {
    "text": "output and they basically make it so",
    "start": "1169200",
    "end": "1171360"
  },
  {
    "text": "that what gp4 generates humans like more",
    "start": "1171360",
    "end": "1175120"
  },
  {
    "text": "and if you're ever wondering like how",
    "start": "1175120",
    "end": "1177440"
  },
  {
    "text": "open AI does this they have teams of",
    "start": "1177440",
    "end": "1180360"
  },
  {
    "text": "thousands in Kenya that are manually",
    "start": "1180360",
    "end": "1183360"
  },
  {
    "text": "labeling the output of um gp4 to make",
    "start": "1183360",
    "end": "1187559"
  },
  {
    "text": "sure it gets better every time right uh",
    "start": "1187559",
    "end": "1189559"
  },
  {
    "text": "at least that's what's been reported in",
    "start": "1189559",
    "end": "1190799"
  },
  {
    "text": "the media so uh my hypothesis is that",
    "start": "1190799",
    "end": "1193880"
  },
  {
    "text": "the open source systems don't have the",
    "start": "1193880",
    "end": "1195679"
  },
  {
    "text": "same level of human review um um and the",
    "start": "1195679",
    "end": "1199760"
  },
  {
    "text": "same research that's been done into",
    "start": "1199760",
    "end": "1201480"
  },
  {
    "text": "reinforcement learning through human",
    "start": "1201480",
    "end": "1203039"
  },
  {
    "text": "feedback um so here's an example just to",
    "start": "1203039",
    "end": "1206520"
  },
  {
    "text": "kind of show you how crazy this gets",
    "start": "1206520",
    "end": "1208919"
  },
  {
    "text": "right so remember that task I showed you",
    "start": "1208919",
    "end": "1211159"
  },
  {
    "text": "earlier there's a a sentence or there's",
    "start": "1211159",
    "end": "1213080"
  },
  {
    "text": "a paragraph and then there are two",
    "start": "1213080",
    "end": "1214919"
  },
  {
    "text": "summaries one of which is correct and",
    "start": "1214919",
    "end": "1216280"
  },
  {
    "text": "one of which is not when you actually go",
    "start": "1216280",
    "end": "1218679"
  },
  {
    "text": "and ask the llms please just give me a",
    "start": "1218679",
    "end": "1221280"
  },
  {
    "text": "or b I just want a or b what happens",
    "start": "1221280",
    "end": "1224559"
  },
  {
    "text": "exactly what you expect gp4 just gives",
    "start": "1224559",
    "end": "1227480"
  },
  {
    "text": "you the a at worst it says answer colon",
    "start": "1227480",
    "end": "1230320"
  },
  {
    "text": "a so you can write a regular expression",
    "start": "1230320",
    "end": "1233039"
  },
  {
    "text": "to process the output of",
    "start": "1233039",
    "end": "1235280"
  },
  {
    "text": "gp4 you ask llama 7tb and it writes an",
    "start": "1235280",
    "end": "1238360"
  },
  {
    "text": "essay for you right like explaining its",
    "start": "1238360",
    "end": "1241840"
  },
  {
    "text": "reasoning and and remember I told it I",
    "start": "1241840",
    "end": "1244600"
  },
  {
    "text": "told it just give me an ARB but it still",
    "start": "1244600",
    "end": "1247039"
  },
  {
    "text": "did this right um also notice that this",
    "start": "1247039",
    "end": "1249559"
  },
  {
    "text": "is costing a lot of money because the a",
    "start": "1249559",
    "end": "1251720"
  },
  {
    "text": "is one",
    "start": "1251720",
    "end": "1253000"
  },
  {
    "text": "token and that's what 200 tokens so this",
    "start": "1253000",
    "end": "1257400"
  },
  {
    "text": "has actually evened out the problem",
    "start": "1257400",
    "end": "1259200"
  },
  {
    "text": "right like it's almost made gp4 cheaper",
    "start": "1259200",
    "end": "1261679"
  },
  {
    "text": "than not quite but made it cheaper than",
    "start": "1261679",
    "end": "1263400"
  },
  {
    "text": "the first one right so I'm going to give",
    "start": "1263400",
    "end": "1265360"
  },
  {
    "text": "you a guess how we solved this problem",
    "start": "1265360",
    "end": "1267080"
  },
  {
    "text": "does anybody want to guess how we solved",
    "start": "1267080",
    "end": "1268400"
  },
  {
    "text": "this",
    "start": "1268400",
    "end": "1269200"
  },
  {
    "text": "problem another",
    "start": "1269200",
    "end": "1271200"
  },
  {
    "text": "llm is that what you're going to",
    "start": "1271200",
    "end": "1274400"
  },
  {
    "text": "sayp fot prompting we tried that",
    "start": "1274400",
    "end": "1276799"
  },
  {
    "text": "actually it didn't work as well as we",
    "start": "1276799",
    "end": "1278600"
  },
  {
    "text": "had",
    "start": "1278600",
    "end": "1279720"
  },
  {
    "text": "hoped so we made another llm and this",
    "start": "1279720",
    "end": "1282640"
  },
  {
    "text": "one was a llama 7B model which this time",
    "start": "1282640",
    "end": "1285840"
  },
  {
    "text": "it did listen and you just said you are",
    "start": "1285840",
    "end": "1288120"
  },
  {
    "text": "helpful assistant that carefully follows",
    "start": "1288120",
    "end": "1289919"
  },
  {
    "text": "instructions read this text that was",
    "start": "1289919",
    "end": "1292200"
  },
  {
    "text": "generated by another llm and decide if",
    "start": "1292200",
    "end": "1294559"
  },
  {
    "text": "that first llm said A or",
    "start": "1294559",
    "end": "1296600"
  },
  {
    "text": "B this one actually worked well it had",
    "start": "1296600",
    "end": "1299279"
  },
  {
    "text": "something close to 100% accuracy so that",
    "start": "1299279",
    "end": "1302440"
  },
  {
    "text": "one is a very CL so from this one",
    "start": "1302440",
    "end": "1305320"
  },
  {
    "text": "principle I want you to walk away from",
    "start": "1305320",
    "end": "1307080"
  },
  {
    "text": "is llms work better when you ask them to",
    "start": "1307080",
    "end": "1310480"
  },
  {
    "text": "do one thing ask it to decide whether a",
    "start": "1310480",
    "end": "1313400"
  },
  {
    "text": "or b is the correct answer and then ask",
    "start": "1313400",
    "end": "1315919"
  },
  {
    "text": "it to summarize its own answer that will",
    "start": "1315919",
    "end": "1318480"
  },
  {
    "text": "work better and the llms will generally",
    "start": "1318480",
    "end": "1320360"
  },
  {
    "text": "work better now you could say with gp4",
    "start": "1320360",
    "end": "1322760"
  },
  {
    "text": "we don't have to do anything about like",
    "start": "1322760",
    "end": "1324360"
  },
  {
    "text": "that you can just use gp4 and it'll get",
    "start": "1324360",
    "end": "1325840"
  },
  {
    "text": "the right answer so this is a pattern",
    "start": "1325840",
    "end": "1327960"
  },
  {
    "text": "often open source models will need a",
    "start": "1327960",
    "end": "1330559"
  },
  {
    "text": "little bit more work you have to run a",
    "start": "1330559",
    "end": "1332080"
  },
  {
    "text": "post-processing step that's another llm",
    "start": "1332080",
    "end": "1334679"
  },
  {
    "text": "on the open source model but it still",
    "start": "1334679",
    "end": "1336960"
  },
  {
    "text": "turns out to be cheaper and considerably",
    "start": "1336960",
    "end": "1339200"
  },
  {
    "text": "cheaper right so we've talked now about",
    "start": "1339200",
    "end": "1342559"
  },
  {
    "text": "quality about instruction following um",
    "start": "1342559",
    "end": "1345720"
  },
  {
    "text": "the last one is there's a feature that",
    "start": "1345720",
    "end": "1347279"
  },
  {
    "text": "is present in open source uh sorry in",
    "start": "1347279",
    "end": "1349600"
  },
  {
    "text": "proprietary llms that is not yet",
    "start": "1349600",
    "end": "1352400"
  },
  {
    "text": "available in um open source so um and",
    "start": "1352400",
    "end": "1356200"
  },
  {
    "text": "and that is uh function templates so one",
    "start": "1356200",
    "end": "1358840"
  },
  {
    "text": "of the engineers on our team the person",
    "start": "1358840",
    "end": "1360360"
  },
  {
    "text": "who built any scale doctor remember any",
    "start": "1360360",
    "end": "1362720"
  },
  {
    "text": "scale doctor from the first keynote the",
    "start": "1362720",
    "end": "1364640"
  },
  {
    "text": "button you press in jupyter Notebook to",
    "start": "1364640",
    "end": "1366240"
  },
  {
    "text": "kind of automatic he said the hardest",
    "start": "1366240",
    "end": "1368600"
  },
  {
    "text": "thing for me to you know he was using",
    "start": "1368600",
    "end": "1370720"
  },
  {
    "text": "gp4 to build a prototypes and then we",
    "start": "1370720",
    "end": "1373200"
  },
  {
    "text": "said well could you use open source and",
    "start": "1373200",
    "end": "1375039"
  },
  {
    "text": "he goes man I really miss those function",
    "start": "1375039",
    "end": "1377039"
  },
  {
    "text": "templates because what they do is they",
    "start": "1377039",
    "end": "1379279"
  },
  {
    "text": "lock in the format you don't have to do",
    "start": "1379279",
    "end": "1381960"
  },
  {
    "text": "any kind of Correction and you can",
    "start": "1381960",
    "end": "1383360"
  },
  {
    "text": "basically say here's the function",
    "start": "1383360",
    "end": "1384600"
  },
  {
    "text": "template I want you to Output this so",
    "start": "1384600",
    "end": "1386960"
  },
  {
    "text": "imagine that the task we're getting is",
    "start": "1386960",
    "end": "1388679"
  },
  {
    "text": "we're trying to convert natural language",
    "start": "1388679",
    "end": "1390520"
  },
  {
    "text": "request for a flight information into",
    "start": "1390520",
    "end": "1392919"
  },
  {
    "text": "something that looks like a Json call",
    "start": "1392919",
    "end": "1394919"
  },
  {
    "text": "right and there's two methods there's",
    "start": "1394919",
    "end": "1396640"
  },
  {
    "text": "city code and there's fine flights and",
    "start": "1396640",
    "end": "1398840"
  },
  {
    "text": "you put gave this to Lama 13B and it",
    "start": "1398840",
    "end": "1401559"
  },
  {
    "text": "just says Boston San Francisco blah blah",
    "start": "1401559",
    "end": "1403640"
  },
  {
    "text": "blah blah so there are three problems in",
    "start": "1403640",
    "end": "1406320"
  },
  {
    "text": "these small number of examples right the",
    "start": "1406320",
    "end": "1408840"
  },
  {
    "text": "first two the first the quotes should",
    "start": "1408840",
    "end": "1410679"
  },
  {
    "text": "have been uh they should have been in",
    "start": "1410679",
    "end": "1412400"
  },
  {
    "text": "quotes and it weren't pass the second",
    "start": "1412400",
    "end": "1414240"
  },
  {
    "text": "one is it didn't use the city codes so",
    "start": "1414240",
    "end": "1416360"
  },
  {
    "text": "it should have said city code Boston and",
    "start": "1416360",
    "end": "1418600"
  },
  {
    "text": "then it decided that 600 p.m. was the",
    "start": "1418600",
    "end": "1420480"
  },
  {
    "text": "evening somewhat arbitrarily right",
    "start": "1420480",
    "end": "1423279"
  },
  {
    "text": "versus something like um um openai where",
    "start": "1423279",
    "end": "1427559"
  },
  {
    "text": "you get to define the exact format and",
    "start": "1427559",
    "end": "1430640"
  },
  {
    "text": "open AI will do lots of things for you",
    "start": "1430640",
    "end": "1433159"
  },
  {
    "text": "it can say I will selectively use",
    "start": "1433159",
    "end": "1434960"
  },
  {
    "text": "whatever function you want me to use um",
    "start": "1434960",
    "end": "1438039"
  },
  {
    "text": "and so you just declare ahead of time",
    "start": "1438039",
    "end": "1439640"
  },
  {
    "text": "the format that you want and sure enough",
    "start": "1439640",
    "end": "1441279"
  },
  {
    "text": "in open AI Works beautifully first time",
    "start": "1441279",
    "end": "1445039"
  },
  {
    "text": "no fine-tuning required no clever",
    "start": "1445039",
    "end": "1447080"
  },
  {
    "text": "Plumping required just works out of the",
    "start": "1447080",
    "end": "1449120"
  },
  {
    "text": "box right and then the final one is",
    "start": "1449120",
    "end": "1452799"
  },
  {
    "text": "large context windows so llms have this",
    "start": "1452799",
    "end": "1455640"
  },
  {
    "text": "idea of a context window the maximum",
    "start": "1455640",
    "end": "1457279"
  },
  {
    "text": "size of input that they can take and um",
    "start": "1457279",
    "end": "1460919"
  },
  {
    "text": "one of the problems again think back to",
    "start": "1460919",
    "end": "1463320"
  },
  {
    "text": "um Goku and Phillip's demo of the",
    "start": "1463320",
    "end": "1466360"
  },
  {
    "text": "assistant that we saw yesterday",
    "start": "1466360",
    "end": "1468360"
  },
  {
    "text": "it's a really great blog post I I highly",
    "start": "1468360",
    "end": "1470520"
  },
  {
    "text": "recommend their blog post about like if",
    "start": "1470520",
    "end": "1472080"
  },
  {
    "text": "you want to know anything about rag it",
    "start": "1472080",
    "end": "1474399"
  },
  {
    "text": "is a 45 minute read so it's a lot of",
    "start": "1474399",
    "end": "1476760"
  },
  {
    "text": "work but it has more detail that you",
    "start": "1476760",
    "end": "1478240"
  },
  {
    "text": "want but what I've taken is an excerpt",
    "start": "1478240",
    "end": "1480679"
  },
  {
    "text": "from that where they say you know when",
    "start": "1480679",
    "end": "1482399"
  },
  {
    "text": "you're running rag you have to decide",
    "start": "1482399",
    "end": "1484000"
  },
  {
    "text": "how many how many outputs from the",
    "start": "1484000",
    "end": "1485760"
  },
  {
    "text": "vector database to return and what they",
    "start": "1485760",
    "end": "1488159"
  },
  {
    "text": "saw is one when you go from one to two",
    "start": "1488159",
    "end": "1491480"
  },
  {
    "text": "it gets better up to three gets better",
    "start": "1491480",
    "end": "1493159"
  },
  {
    "text": "after four gets better five gets better",
    "start": "1493159",
    "end": "1494640"
  },
  {
    "text": "six gets better seven gets better and",
    "start": "1494640",
    "end": "1496640"
  },
  {
    "text": "the Lama says no you exceeded the",
    "start": "1496640",
    "end": "1498240"
  },
  {
    "text": "context window and you can't test eight",
    "start": "1498240",
    "end": "1501240"
  },
  {
    "text": "return values right so they come up with",
    "start": "1501240",
    "end": "1503360"
  },
  {
    "text": "this thing that says there's a",
    "start": "1503360",
    "end": "1504320"
  },
  {
    "text": "compelling reason to invest in extending",
    "start": "1504320",
    "end": "1506159"
  },
  {
    "text": "contact size and here's where we stand",
    "start": "1506159",
    "end": "1508520"
  },
  {
    "text": "at the moment right anthropic has a lead",
    "start": "1508520",
    "end": "1511480"
  },
  {
    "text": "industry-leading 100K context window GPT",
    "start": "1511480",
    "end": "1514559"
  },
  {
    "text": "4 has two sizes with different prices so",
    "start": "1514559",
    "end": "1517640"
  },
  {
    "text": "you can do 32k or 8K llama 2 is 4K and",
    "start": "1517640",
    "end": "1521480"
  },
  {
    "text": "then code llama interestingly is 16k and",
    "start": "1521480",
    "end": "1525080"
  },
  {
    "text": "code Lama is actually very good at",
    "start": "1525080",
    "end": "1526279"
  },
  {
    "text": "natural language so if someone came",
    "start": "1526279",
    "end": "1528120"
  },
  {
    "text": "today to me today and said I want to",
    "start": "1528120",
    "end": "1529760"
  },
  {
    "text": "experiment with bigger um um context",
    "start": "1529760",
    "end": "1532440"
  },
  {
    "text": "Windows I'd actually say believe it or",
    "start": "1532440",
    "end": "1534080"
  },
  {
    "text": "not go go play with code Lama and see if",
    "start": "1534080",
    "end": "1535960"
  },
  {
    "text": "it works um so OSS is obviously being uh",
    "start": "1535960",
    "end": "1540799"
  },
  {
    "text": "acted on um but this gives you an idea",
    "start": "1540799",
    "end": "1543159"
  },
  {
    "text": "of something that we're they're behind",
    "start": "1543159",
    "end": "1545480"
  },
  {
    "text": "and so I want to just you know as we",
    "start": "1545480",
    "end": "1547000"
  },
  {
    "text": "come towards the end of this talk and",
    "start": "1547000",
    "end": "1548520"
  },
  {
    "text": "saying you know when do open source",
    "start": "1548520",
    "end": "1550000"
  },
  {
    "text": "models make sense um Quality um I think",
    "start": "1550000",
    "end": "1555880"
  },
  {
    "text": "uh what we're going to see on terms of",
    "start": "1555880",
    "end": "1557120"
  },
  {
    "text": "quality is is there'll be larger and",
    "start": "1557120",
    "end": "1558480"
  },
  {
    "text": "larger open models we also mentioned we",
    "start": "1558480",
    "end": "1560679"
  },
  {
    "text": "talked about Falcon",
    "start": "1560679",
    "end": "1562320"
  },
  {
    "text": "180b um but the other thing to think",
    "start": "1562320",
    "end": "1564720"
  },
  {
    "text": "about is it's not just about model size",
    "start": "1564720",
    "end": "1566600"
  },
  {
    "text": "and neither is this like a static goal",
    "start": "1566600",
    "end": "1569720"
  },
  {
    "text": "so there are rumors for example that",
    "start": "1569720",
    "end": "1571919"
  },
  {
    "text": "Google has a system called Gemini that",
    "start": "1571919",
    "end": "1573760"
  },
  {
    "text": "they're very close to making available",
    "start": "1573760",
    "end": "1576200"
  },
  {
    "text": "that is considerably better than gp4 so",
    "start": "1576200",
    "end": "1578919"
  },
  {
    "text": "I think there will always be a gap it",
    "start": "1578919",
    "end": "1580520"
  },
  {
    "text": "will always be that you know um some",
    "start": "1580520",
    "end": "1583520"
  },
  {
    "text": "organization somewhere has way too much",
    "start": "1583520",
    "end": "1585520"
  },
  {
    "text": "GPU GPU resources doesn't know what to",
    "start": "1585520",
    "end": "1588360"
  },
  {
    "text": "do with it and I'm going to use it to",
    "start": "1588360",
    "end": "1589440"
  },
  {
    "text": "build a model um instruction following",
    "start": "1589440",
    "end": "1593039"
  },
  {
    "text": "there too I am not expecting to see a",
    "start": "1593039",
    "end": "1594840"
  },
  {
    "text": "huge Improvement but I would like to see",
    "start": "1594840",
    "end": "1596520"
  },
  {
    "text": "one the ones that I think will be solved",
    "start": "1596520",
    "end": "1599080"
  },
  {
    "text": "in the near future are expanded context",
    "start": "1599080",
    "end": "1601279"
  },
  {
    "text": "windows and function templates those are",
    "start": "1601279",
    "end": "1603880"
  },
  {
    "text": "things that will probably get solved in",
    "start": "1603880",
    "end": "1605480"
  },
  {
    "text": "the next six months at most um and",
    "start": "1605480",
    "end": "1608440"
  },
  {
    "text": "there's already open source projects for",
    "start": "1608440",
    "end": "1610399"
  },
  {
    "text": "each of these and in fact Percy leang",
    "start": "1610399",
    "end": "1612880"
  },
  {
    "text": "who was here yesterday gave a talk and",
    "start": "1612880",
    "end": "1614679"
  },
  {
    "text": "he mentioned hyena it turns out that",
    "start": "1614679",
    "end": "1616880"
  },
  {
    "text": "context windows size is quadratic but",
    "start": "1616880",
    "end": "1619039"
  },
  {
    "text": "they found a sub quadratic algorithm for",
    "start": "1619039",
    "end": "1621039"
  },
  {
    "text": "doing context window",
    "start": "1621039",
    "end": "1623080"
  },
  {
    "text": "sizes so uh once again I'm just going to",
    "start": "1623080",
    "end": "1625399"
  },
  {
    "text": "promote um uh the best place to run open",
    "start": "1625399",
    "end": "1628720"
  },
  {
    "text": "llms uh is any endpoints nysc.com and",
    "start": "1628720",
    "end": "1633080"
  },
  {
    "text": "for anybody who signs up today using",
    "start": "1633080",
    "end": "1635039"
  },
  {
    "text": "this QR code or just goes to endp",
    "start": "1635039",
    "end": "1637240"
  },
  {
    "text": "points. anyscale tocom you will get $50",
    "start": "1637240",
    "end": "1640000"
  },
  {
    "text": "a credit for any for any scale endpoints",
    "start": "1640000",
    "end": "1642919"
  },
  {
    "text": "so that's enough to serve 300 million",
    "start": "1642919",
    "end": "1645760"
  },
  {
    "text": "tokens if you use l 7 B 7B or uh 50",
    "start": "1645760",
    "end": "1650679"
  },
  {
    "text": "million tokens if you use llama 70b",
    "start": "1650679",
    "end": "1652960"
  },
  {
    "text": "right so um yeah take advantage of it",
    "start": "1652960",
    "end": "1657559"
  },
  {
    "text": "it's a really clean API it's open AI",
    "start": "1657559",
    "end": "1659679"
  },
  {
    "text": "compatible so all you have to do is",
    "start": "1659679",
    "end": "1660799"
  },
  {
    "text": "change a few environment variables and",
    "start": "1660799",
    "end": "1662200"
  },
  {
    "text": "model names and you can use it so let me",
    "start": "1662200",
    "end": "1664720"
  },
  {
    "text": "just summarize what I have to say in my",
    "start": "1664720",
    "end": "1667200"
  },
  {
    "text": "remaining one minute and 20 seconds um",
    "start": "1667200",
    "end": "1669799"
  },
  {
    "text": "what we see is open models are viable in",
    "start": "1669799",
    "end": "1672000"
  },
  {
    "text": "production people are using them already",
    "start": "1672000",
    "end": "1674240"
  },
  {
    "text": "in some cases uh you can solve",
    "start": "1674240",
    "end": "1676320"
  },
  {
    "text": "particular problems with propri llms",
    "start": "1676320",
    "end": "1678679"
  },
  {
    "text": "small fine tune uh models generally",
    "start": "1678679",
    "end": "1680799"
  },
  {
    "text": "outperform but only in some cases um",
    "start": "1680799",
    "end": "1684840"
  },
  {
    "text": "remember to use rag for factual",
    "start": "1684840",
    "end": "1686600"
  },
  {
    "text": "information open models are not just a",
    "start": "1686600",
    "end": "1688679"
  },
  {
    "text": "bit cheaper they can be radically",
    "start": "1688679",
    "end": "1690399"
  },
  {
    "text": "cheaper like change the feasibility",
    "start": "1690399",
    "end": "1693159"
  },
  {
    "text": "cheaper and it takes a bit of extra work",
    "start": "1693159",
    "end": "1695440"
  },
  {
    "text": "in general to use open source lmeds um",
    "start": "1695440",
    "end": "1698120"
  },
  {
    "text": "and they are missing some key features",
    "start": "1698120",
    "end": "1699640"
  },
  {
    "text": "but they're being worked on and thank",
    "start": "1699640",
    "end": "1701360"
  },
  {
    "text": "you that's my email address up there",
    "start": "1701360",
    "end": "1703039"
  },
  {
    "text": "I'll be up here if you want to answer",
    "start": "1703039",
    "end": "1704399"
  },
  {
    "text": "any questions thank you so much for",
    "start": "1704399",
    "end": "1705840"
  },
  {
    "text": "listening to me",
    "start": "1705840",
    "end": "1708000"
  },
  {
    "text": "[Applause]",
    "start": "1708000",
    "end": "1711600"
  },
  {
    "text": "than",
    "start": "1711600",
    "end": "1714600"
  }
]
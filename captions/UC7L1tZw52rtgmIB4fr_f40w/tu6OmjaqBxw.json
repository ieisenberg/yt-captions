[
  {
    "text": "thank you all for joining me today I'm",
    "start": "2760",
    "end": "4720"
  },
  {
    "text": "excited to talk about how we can harness",
    "start": "4720",
    "end": "6600"
  },
  {
    "text": "the power of VM and R to transform data",
    "start": "6600",
    "end": "10320"
  },
  {
    "text": "classification and annotations using",
    "start": "10320",
    "end": "13360"
  },
  {
    "text": "AI before we dive into technical details",
    "start": "13360",
    "end": "16600"
  },
  {
    "text": "let's take a quick look at the agenda",
    "start": "16600",
    "end": "19960"
  },
  {
    "text": "we'll start with introduction about what",
    "start": "19960",
    "end": "22800"
  },
  {
    "text": "is data classification anotation",
    "start": "22800",
    "end": "24680"
  },
  {
    "text": "especially in the context of data",
    "start": "24680",
    "end": "26279"
  },
  {
    "text": "governance next we'll discuss about a",
    "start": "26279",
    "end": "29160"
  },
  {
    "text": "particularly Lodge language models and",
    "start": "29160",
    "end": "32480"
  },
  {
    "text": "how they can help with uh these",
    "start": "32480",
    "end": "34600"
  },
  {
    "text": "challenges that we are facing and we",
    "start": "34600",
    "end": "37280"
  },
  {
    "text": "will discuss about few other options and",
    "start": "37280",
    "end": "38920"
  },
  {
    "text": "finally go into why fine tune and how",
    "start": "38920",
    "end": "41920"
  },
  {
    "text": "the how that will be helpful uh for",
    "start": "41920",
    "end": "44000"
  },
  {
    "text": "these use cases after that we'll dive",
    "start": "44000",
    "end": "46640"
  },
  {
    "text": "into inference",
    "start": "46640",
    "end": "48719"
  },
  {
    "text": "process uh and finally we'll summarize",
    "start": "48719",
    "end": "51000"
  },
  {
    "text": "with key",
    "start": "51000",
    "end": "53360"
  },
  {
    "text": "takeaways so some introduction data",
    "start": "53760",
    "end": "57000"
  },
  {
    "text": "classification and annotations are",
    "start": "57000",
    "end": "58280"
  },
  {
    "text": "critical elements of data governance",
    "start": "58280",
    "end": "60879"
  },
  {
    "text": "uh organizations today are generating",
    "start": "60879",
    "end": "62719"
  },
  {
    "text": "large amount of data across all parts of",
    "start": "62719",
    "end": "65119"
  },
  {
    "text": "the business whether it is customer data",
    "start": "65119",
    "end": "67680"
  },
  {
    "text": "financial data or even operation metrics",
    "start": "67680",
    "end": "71600"
  },
  {
    "text": "but this data is only useful if it is",
    "start": "71600",
    "end": "74439"
  },
  {
    "text": "organized properly ensuring it's",
    "start": "74439",
    "end": "76360"
  },
  {
    "text": "accurate and easily",
    "start": "76360",
    "end": "78400"
  },
  {
    "text": "accessible now what do you mean by that",
    "start": "78400",
    "end": "81640"
  },
  {
    "text": "well think about how data is stored in L",
    "start": "81640",
    "end": "83960"
  },
  {
    "text": "large organizations nowadays we have",
    "start": "83960",
    "end": "86320"
  },
  {
    "text": "thousands sometimes millions of data set",
    "start": "86320",
    "end": "90360"
  },
  {
    "text": "some data sets are well documented well",
    "start": "90360",
    "end": "93240"
  },
  {
    "text": "classified with Rich metadata and some",
    "start": "93240",
    "end": "96000"
  },
  {
    "text": "are partially documented have partial",
    "start": "96000",
    "end": "98680"
  },
  {
    "text": "metadata well large amount of data sets",
    "start": "98680",
    "end": "101640"
  },
  {
    "text": "are lacking that information some",
    "start": "101640",
    "end": "103640"
  },
  {
    "text": "industry estimat suggest that small",
    "start": "103640",
    "end": "106000"
  },
  {
    "text": "percentage of data sets have reach",
    "start": "106000",
    "end": "108520"
  },
  {
    "text": "metadata to uh and and this makes it",
    "start": "108520",
    "end": "111119"
  },
  {
    "text": "incredibly difficult for data users and",
    "start": "111119",
    "end": "113159"
  },
  {
    "text": "analyst a special data scientist to find",
    "start": "113159",
    "end": "115560"
  },
  {
    "text": "information they",
    "start": "115560",
    "end": "118000"
  },
  {
    "text": "need and talking about business context",
    "start": "118000",
    "end": "121159"
  },
  {
    "text": "traditional data warehouses didn't",
    "start": "121159",
    "end": "123439"
  },
  {
    "text": "support persisting business context that",
    "start": "123439",
    "end": "126119"
  },
  {
    "text": "boils down to uh uh important data might",
    "start": "126119",
    "end": "130920"
  },
  {
    "text": "be underutilized because it's not easy",
    "start": "130920",
    "end": "133000"
  },
  {
    "text": "to discover",
    "start": "133000",
    "end": "135640"
  },
  {
    "text": "them and data privacy ensuring data",
    "start": "135879",
    "end": "139080"
  },
  {
    "text": "privacy and complaints is becoming an",
    "start": "139080",
    "end": "140400"
  },
  {
    "text": "increasing concern with more regulations",
    "start": "140400",
    "end": "143440"
  },
  {
    "text": "and privacy laws like gdpr and dma",
    "start": "143440",
    "end": "146120"
  },
  {
    "text": "coming into effect knowing exactly where",
    "start": "146120",
    "end": "148319"
  },
  {
    "text": "the sensitive data is and how it is used",
    "start": "148319",
    "end": "151239"
  },
  {
    "text": "is crucial however with lack of Rich",
    "start": "151239",
    "end": "155400"
  },
  {
    "text": "metadata above the data setes is",
    "start": "155400",
    "end": "157480"
  },
  {
    "text": "becoming increasingly difficult now days",
    "start": "157480",
    "end": "160280"
  },
  {
    "text": "uh to address the challenges uh",
    "start": "160280",
    "end": "162920"
  },
  {
    "text": "traditional process used to be manual",
    "start": "162920",
    "end": "166760"
  },
  {
    "text": "approach where load of teams comes comes",
    "start": "166760",
    "end": "169879"
  },
  {
    "text": "together and document the data setes and",
    "start": "169879",
    "end": "172040"
  },
  {
    "text": "annotate the data setes with business",
    "start": "172040",
    "end": "174080"
  },
  {
    "text": "classify them uh the she amount of",
    "start": "174080",
    "end": "176400"
  },
  {
    "text": "effort required to enrich this data",
    "start": "176400",
    "end": "178879"
  },
  {
    "text": "manually",
    "start": "178879",
    "end": "180959"
  },
  {
    "text": "is tremendous and it's simply not",
    "start": "180959",
    "end": "183080"
  },
  {
    "text": "feasible to handle this scale with human",
    "start": "183080",
    "end": "185480"
  },
  {
    "text": "resources alone uh and lot of companies",
    "start": "185480",
    "end": "189760"
  },
  {
    "text": "nowadays are in recent years have been",
    "start": "189760",
    "end": "192200"
  },
  {
    "text": "putting lot of effort into this and we",
    "start": "192200",
    "end": "194920"
  },
  {
    "text": "are hoping that with advancements made",
    "start": "194920",
    "end": "197879"
  },
  {
    "text": "in AI especially gen AI these efforts",
    "start": "197879",
    "end": "200599"
  },
  {
    "text": "can be forast",
    "start": "200599",
    "end": "203200"
  },
  {
    "text": "tracked these are some of the uh",
    "start": "203720",
    "end": "206360"
  },
  {
    "text": "advantages that we are hoping that a can",
    "start": "206360",
    "end": "208519"
  },
  {
    "text": "bring in this field uh when is",
    "start": "208519",
    "end": "210680"
  },
  {
    "text": "automating uh so the large langage model",
    "start": "210680",
    "end": "213760"
  },
  {
    "text": "especially gen can help automate the",
    "start": "213760",
    "end": "216040"
  },
  {
    "text": "generation of uh the rich metadata and",
    "start": "216040",
    "end": "220040"
  },
  {
    "text": "take away the lot of burden on the data",
    "start": "220040",
    "end": "222480"
  },
  {
    "text": "Shor to manually do all this",
    "start": "222480",
    "end": "224959"
  },
  {
    "text": "effort and a can uh help the",
    "start": "224959",
    "end": "227360"
  },
  {
    "text": "significantly speed up the whole process",
    "start": "227360",
    "end": "230040"
  },
  {
    "text": "uh and and you know systems like Ray can",
    "start": "230040",
    "end": "233840"
  },
  {
    "text": "really help in scaling up as the data",
    "start": "233840",
    "end": "236360"
  },
  {
    "text": "grows uh with ongoing basis",
    "start": "236360",
    "end": "240720"
  },
  {
    "text": "and uh it's less error Point compared to",
    "start": "240720",
    "end": "243560"
  },
  {
    "text": "you know manually documenting all of",
    "start": "243560",
    "end": "245519"
  },
  {
    "text": "these at the scale that we're talking",
    "start": "245519",
    "end": "247319"
  },
  {
    "text": "about and as as the lar language models",
    "start": "247319",
    "end": "250280"
  },
  {
    "text": "get used to the uh get understanding of",
    "start": "250280",
    "end": "253120"
  },
  {
    "text": "the business needs they tend to generate",
    "start": "253120",
    "end": "255239"
  },
  {
    "text": "more accurate",
    "start": "255239",
    "end": "256840"
  },
  {
    "text": "recommendations and and finally AI",
    "start": "256840",
    "end": "260320"
  },
  {
    "text": "integration is not just limited to",
    "start": "260320",
    "end": "261919"
  },
  {
    "text": "metadata uh generation but it has lot",
    "start": "261919",
    "end": "264840"
  },
  {
    "text": "more potential in data field for example",
    "start": "264840",
    "end": "268080"
  },
  {
    "text": "uh with millions of data dat data",
    "start": "268080",
    "end": "270600"
  },
  {
    "text": "sitting in the data warehouse we can",
    "start": "270600",
    "end": "272680"
  },
  {
    "text": "automate the discovery of data set",
    "start": "272680",
    "end": "274280"
  },
  {
    "text": "through natural",
    "start": "274280",
    "end": "275320"
  },
  {
    "text": "language and even text to SQL and many",
    "start": "275320",
    "end": "277919"
  },
  {
    "text": "of the use cases can be implemented and",
    "start": "277919",
    "end": "280199"
  },
  {
    "text": "for all of them this is the basic we",
    "start": "280199",
    "end": "282360"
  },
  {
    "text": "need to have reach",
    "start": "282360",
    "end": "285240"
  },
  {
    "text": "metadata let's take a look at uh some",
    "start": "285240",
    "end": "288680"
  },
  {
    "text": "examples so here the task is to generate",
    "start": "288680",
    "end": "291080"
  },
  {
    "text": "documentation for the table called users",
    "start": "291080",
    "end": "293400"
  },
  {
    "text": "there are few columns in it like _ ID",
    "start": "293400",
    "end": "296039"
  },
  {
    "text": "name address hash uh as we all know we",
    "start": "296039",
    "end": "299000"
  },
  {
    "text": "try to make scripted and that's what it",
    "start": "299000",
    "end": "301560"
  },
  {
    "text": "is and few text attached to the data set",
    "start": "301560",
    "end": "304919"
  },
  {
    "text": "indicating that the data set is highly",
    "start": "304919",
    "end": "306720"
  },
  {
    "text": "used and contains PA information",
    "start": "306720",
    "end": "310639"
  },
  {
    "text": "and let's see how the documentation",
    "start": "310639",
    "end": "312759"
  },
  {
    "text": "looks like uh well this is to large let",
    "start": "312759",
    "end": "317199"
  },
  {
    "text": "me summarize it for you the first call",
    "start": "317199",
    "end": "319880"
  },
  {
    "text": "first paragraph talks about high level",
    "start": "319880",
    "end": "322120"
  },
  {
    "text": "description about the data set it's good",
    "start": "322120",
    "end": "324840"
  },
  {
    "text": "to see that the description also",
    "start": "324840",
    "end": "326080"
  },
  {
    "text": "includes the taxs attached to the data",
    "start": "326080",
    "end": "328759"
  },
  {
    "text": "set",
    "start": "328759",
    "end": "330160"
  },
  {
    "text": "and the next paragraph talks about",
    "start": "330160",
    "end": "332639"
  },
  {
    "text": "columns and summary from them and",
    "start": "332639",
    "end": "334960"
  },
  {
    "text": "finally talks about use",
    "start": "334960",
    "end": "336800"
  },
  {
    "text": "cases Al if you notice that the model",
    "start": "336800",
    "end": "340479"
  },
  {
    "text": "kind of understood that we explicitly",
    "start": "340479",
    "end": "342479"
  },
  {
    "text": "asked the model not to generate use",
    "start": "342479",
    "end": "343880"
  },
  {
    "text": "cases it mentioned that but generating",
    "start": "343880",
    "end": "346400"
  },
  {
    "text": "the use cases anyway kind of funny if",
    "start": "346400",
    "end": "349560"
  },
  {
    "text": "you give the same prompt to the large",
    "start": "349560",
    "end": "351880"
  },
  {
    "text": "language model multiple",
    "start": "351880",
    "end": "354000"
  },
  {
    "text": "times the response might vary slightly",
    "start": "354000",
    "end": "357000"
  },
  {
    "text": "but in rare cases we see response format",
    "start": "357000",
    "end": "360039"
  },
  {
    "text": "itself is completely different in this",
    "start": "360039",
    "end": "362360"
  },
  {
    "text": "example the same example but the if you",
    "start": "362360",
    "end": "364479"
  },
  {
    "text": "look at the response the first one is",
    "start": "364479",
    "end": "366720"
  },
  {
    "text": "high level description again and second",
    "start": "366720",
    "end": "368319"
  },
  {
    "text": "one is column summary but in a different",
    "start": "368319",
    "end": "370639"
  },
  {
    "text": "way like actually listing out all the",
    "start": "370639",
    "end": "372720"
  },
  {
    "text": "columns and generating Rich",
    "start": "372720",
    "end": "374280"
  },
  {
    "text": "documentation and finally we",
    "start": "374280",
    "end": "376680"
  },
  {
    "text": "have tag summary we used to see use",
    "start": "376680",
    "end": "379960"
  },
  {
    "text": "cases there and even the column summary",
    "start": "379960",
    "end": "382440"
  },
  {
    "text": "that we see uh think about having",
    "start": "382440",
    "end": "385039"
  },
  {
    "text": "hundreds of like 30 or 40 columns for",
    "start": "385039",
    "end": "387199"
  },
  {
    "text": "the data set and if if the model is",
    "start": "387199",
    "end": "389280"
  },
  {
    "text": "going to summaries all the",
    "start": "389280",
    "end": "390800"
  },
  {
    "text": "columns the description is going to be",
    "start": "390800",
    "end": "393120"
  },
  {
    "text": "too large that is not going to be",
    "start": "393120",
    "end": "396240"
  },
  {
    "text": "useful and there are more more",
    "start": "396240",
    "end": "398120"
  },
  {
    "text": "challenges that we are seeing for",
    "start": "398120",
    "end": "399800"
  },
  {
    "text": "example the _ ID though it does not",
    "start": "399800",
    "end": "402840"
  },
  {
    "text": "specify as unique in the table",
    "start": "402840",
    "end": "406160"
  },
  {
    "text": "definition because there is ID in the",
    "start": "406160",
    "end": "408199"
  },
  {
    "text": "column name the model is kind of",
    "start": "408199",
    "end": "410039"
  },
  {
    "text": "assuming that or halling that is a",
    "start": "410039",
    "end": "412360"
  },
  {
    "text": "unique data the beinging stor in",
    "start": "412360",
    "end": "414520"
  },
  {
    "text": "that uh LMS are known to sometimes you",
    "start": "414520",
    "end": "417199"
  },
  {
    "text": "know generate conts that seem plaus",
    "start": "417199",
    "end": "420440"
  },
  {
    "text": "but actually false and irrelevant and",
    "start": "420440",
    "end": "422479"
  },
  {
    "text": "that's what we are observing in some",
    "start": "422479",
    "end": "424400"
  },
  {
    "text": "cases and depending on the models that",
    "start": "424400",
    "end": "426400"
  },
  {
    "text": "we use uh these kind of issues might be",
    "start": "426400",
    "end": "429720"
  },
  {
    "text": "more frequent versus less frequent but",
    "start": "429720",
    "end": "431840"
  },
  {
    "text": "it's always",
    "start": "431840",
    "end": "433840"
  },
  {
    "text": "there and prompt adherence if you look",
    "start": "433840",
    "end": "437840"
  },
  {
    "text": "at that uh where explicitely saying do",
    "start": "437840",
    "end": "440240"
  },
  {
    "text": "not describe the columns in the table",
    "start": "440240",
    "end": "442479"
  },
  {
    "text": "but is generating it",
    "start": "442479",
    "end": "445879"
  },
  {
    "text": "anyway and",
    "start": "445919",
    "end": "447680"
  },
  {
    "text": "finally let's look at a different",
    "start": "447680",
    "end": "449680"
  },
  {
    "text": "example where we want to classify a",
    "start": "449680",
    "end": "451199"
  },
  {
    "text": "column in the data set actor ID in game",
    "start": "451199",
    "end": "454120"
  },
  {
    "text": "setting table we want to classify",
    "start": "454120",
    "end": "456160"
  },
  {
    "text": "whether it is a pii data or nonsens to",
    "start": "456160",
    "end": "458800"
  },
  {
    "text": "in the table definition it clearly",
    "start": "458800",
    "end": "460440"
  },
  {
    "text": "mentions",
    "start": "460440",
    "end": "461520"
  },
  {
    "text": "that uh actor ID is hashed of user ID",
    "start": "461520",
    "end": "464919"
  },
  {
    "text": "okay before that the table is game",
    "start": "464919",
    "end": "466720"
  },
  {
    "text": "settings which shows the settings of",
    "start": "466720",
    "end": "468560"
  },
  {
    "text": "users uh for the games and there are few",
    "start": "468560",
    "end": "471520"
  },
  {
    "text": "columns but most important one is",
    "start": "471520",
    "end": "473560"
  },
  {
    "text": "activated which is Hash of user",
    "start": "473560",
    "end": "476120"
  },
  {
    "text": "ID a person who is familiar with",
    "start": "476120",
    "end": "478280"
  },
  {
    "text": "organization knowledge uh like you know",
    "start": "478280",
    "end": "480680"
  },
  {
    "text": "compl requirements for example might",
    "start": "480680",
    "end": "482759"
  },
  {
    "text": "treat even the hashed uh sensitive data",
    "start": "482759",
    "end": "485960"
  },
  {
    "text": "as sensitive where as the llms are often",
    "start": "485960",
    "end": "488560"
  },
  {
    "text": "trained on vast amount of data from",
    "start": "488560",
    "end": "490199"
  },
  {
    "text": "internet they tend to be in general",
    "start": "490199",
    "end": "491879"
  },
  {
    "text": "purpose so they lack the business needs",
    "start": "491879",
    "end": "494120"
  },
  {
    "text": "or bfic specific business specific",
    "start": "494120",
    "end": "496000"
  },
  {
    "text": "knowledge that humans have and they tend",
    "start": "496000",
    "end": "498039"
  },
  {
    "text": "to generate responses which are far from",
    "start": "498039",
    "end": "500879"
  },
  {
    "text": "the reality and that's what we are",
    "start": "500879",
    "end": "502440"
  },
  {
    "text": "observing here in of instead of",
    "start": "502440",
    "end": "504800"
  },
  {
    "text": "classifying the data set as pii is",
    "start": "504800",
    "end": "506560"
  },
  {
    "text": "recommending as nonsense to here",
    "start": "506560",
    "end": "510639"
  },
  {
    "text": "so to summarize different challenge that",
    "start": "510639",
    "end": "513360"
  },
  {
    "text": "we are seeing using uh the large",
    "start": "513360",
    "end": "515518"
  },
  {
    "text": "language models as is is they they lack",
    "start": "515519",
    "end": "518240"
  },
  {
    "text": "the business contest the response",
    "start": "518240",
    "end": "520360"
  },
  {
    "text": "formats are inconsistent and though llms",
    "start": "520360",
    "end": "524120"
  },
  {
    "text": "are designed to follow instructions in",
    "start": "524120",
    "end": "526040"
  },
  {
    "text": "the prompt they don't always follow that",
    "start": "526040",
    "end": "529040"
  },
  {
    "text": "because of all these challenges we see",
    "start": "529040",
    "end": "530760"
  },
  {
    "text": "Rel limited relevance in the response",
    "start": "530760",
    "end": "533160"
  },
  {
    "text": "that they are",
    "start": "533160",
    "end": "534480"
  },
  {
    "text": "generating there are few techniques that",
    "start": "534480",
    "end": "536600"
  },
  {
    "text": "we can adopt or industry adops to you",
    "start": "536600",
    "end": "539040"
  },
  {
    "text": "know kind of address the challenges like",
    "start": "539040",
    "end": "540880"
  },
  {
    "text": "f short prompting uh we can give you you",
    "start": "540880",
    "end": "543839"
  },
  {
    "text": "know uh few examples in the prompt and",
    "start": "543839",
    "end": "547800"
  },
  {
    "text": "try to uh make the model Lear from that",
    "start": "547800",
    "end": "550680"
  },
  {
    "text": "and actually log language models uh",
    "start": "550680",
    "end": "553519"
  },
  {
    "text": "learn better from the in in",
    "start": "553519",
    "end": "555920"
  },
  {
    "text": "context but the challenge that we get",
    "start": "555920",
    "end": "558240"
  },
  {
    "text": "into is uh the prompt or the prompt or",
    "start": "558240",
    "end": "561360"
  },
  {
    "text": "the context window will be too large and",
    "start": "561360",
    "end": "563480"
  },
  {
    "text": "not to mention uh in the fusure",
    "start": "563480",
    "end": "566120"
  },
  {
    "text": "prompting helps with steering the model",
    "start": "566120",
    "end": "568000"
  },
  {
    "text": "to generate as person in specific format",
    "start": "568000",
    "end": "570680"
  },
  {
    "text": "uh but you know having domain knowledge",
    "start": "570680",
    "end": "572959"
  },
  {
    "text": "is something that we need there are",
    "start": "572959",
    "end": "574720"
  },
  {
    "text": "other other ways to do it for example",
    "start": "574720",
    "end": "576640"
  },
  {
    "text": "rack we can generate embeddings for",
    "start": "576640",
    "end": "578680"
  },
  {
    "text": "existing data set and document them into",
    "start": "578680",
    "end": "580399"
  },
  {
    "text": "and H them into Vector DB and use the",
    "start": "580399",
    "end": "582800"
  },
  {
    "text": "vector DB to find the similar data sets",
    "start": "582800",
    "end": "585720"
  },
  {
    "text": "using different techniques like probably",
    "start": "585720",
    "end": "587160"
  },
  {
    "text": "semantic search and augment The Prompt",
    "start": "587160",
    "end": "589959"
  },
  {
    "text": "uh you know to the model with that",
    "start": "589959",
    "end": "591360"
  },
  {
    "text": "information to gain the you know uh",
    "start": "591360",
    "end": "594000"
  },
  {
    "text": "relevant like business Knowledge from",
    "start": "594000",
    "end": "595680"
  },
  {
    "text": "the relevant data sets but the challenge",
    "start": "595680",
    "end": "597480"
  },
  {
    "text": "we are seeing is as we discussed before",
    "start": "597480",
    "end": "599680"
  },
  {
    "text": "only small percentage of data sets have",
    "start": "599680",
    "end": "601640"
  },
  {
    "text": "documentation or the Met good metadata",
    "start": "601640",
    "end": "604720"
  },
  {
    "text": "quality so otherwi uh the challenges",
    "start": "604720",
    "end": "608040"
  },
  {
    "text": "probably en that information and uh uh",
    "start": "608040",
    "end": "610760"
  },
  {
    "text": "store them into vector and then use them",
    "start": "610760",
    "end": "613360"
  },
  {
    "text": "uh but",
    "start": "613360",
    "end": "615240"
  },
  {
    "text": "again we will get into the large prompt",
    "start": "615240",
    "end": "618360"
  },
  {
    "text": "issues especially in the data space we",
    "start": "618360",
    "end": "621760"
  },
  {
    "text": "have lot of information meta information",
    "start": "621760",
    "end": "623600"
  },
  {
    "text": "about the data set that can be used to",
    "start": "623600",
    "end": "625160"
  },
  {
    "text": "generate richer uh richer",
    "start": "625160",
    "end": "627120"
  },
  {
    "text": "recommendations",
    "start": "627120",
    "end": "629880"
  },
  {
    "text": "so finally decided to function the",
    "start": "629880",
    "end": "633800"
  },
  {
    "text": "model uh the key ingredient for",
    "start": "633800",
    "end": "636000"
  },
  {
    "text": "functioning is training data however",
    "start": "636000",
    "end": "638399"
  },
  {
    "text": "depending on the use case generating",
    "start": "638399",
    "end": "640560"
  },
  {
    "text": "this data can be quite challenging for",
    "start": "640560",
    "end": "643079"
  },
  {
    "text": "instance for to TOS of classifying the",
    "start": "643079",
    "end": "646200"
  },
  {
    "text": "data sets or the columns uh is quite",
    "start": "646200",
    "end": "649120"
  },
  {
    "text": "easy like we have existing data set and",
    "start": "649120",
    "end": "651240"
  },
  {
    "text": "the classifications are well defined so",
    "start": "651240",
    "end": "653440"
  },
  {
    "text": "we can you know find Chun the model with",
    "start": "653440",
    "end": "655920"
  },
  {
    "text": "that information the model will learn",
    "start": "655920",
    "end": "658279"
  },
  {
    "text": "from the existing knowledge and",
    "start": "658279",
    "end": "659720"
  },
  {
    "text": "recommend the uh and give",
    "start": "659720",
    "end": "662200"
  },
  {
    "text": "recommendations accordingly but in use",
    "start": "662200",
    "end": "664800"
  },
  {
    "text": "cases like documentation are annotation",
    "start": "664800",
    "end": "667160"
  },
  {
    "text": "in the business Set uh data sets with",
    "start": "667160",
    "end": "669120"
  },
  {
    "text": "business context things get bit more",
    "start": "669120",
    "end": "671399"
  },
  {
    "text": "complicated if you already have data set",
    "start": "671399",
    "end": "673519"
  },
  {
    "text": "that are properly documented then we can",
    "start": "673519",
    "end": "675760"
  },
  {
    "text": "use them as it is but reality is often",
    "start": "675760",
    "end": "678160"
  },
  {
    "text": "far from that there are many teams",
    "start": "678160",
    "end": "680160"
  },
  {
    "text": "working on documenting creating the data",
    "start": "680160",
    "end": "682120"
  },
  {
    "text": "setes and documenting them so the",
    "start": "682120",
    "end": "683680"
  },
  {
    "text": "formats of the different documentation",
    "start": "683680",
    "end": "685519"
  },
  {
    "text": "that are exist are quite different and",
    "start": "685519",
    "end": "688000"
  },
  {
    "text": "some are well documented some are",
    "start": "688000",
    "end": "689720"
  },
  {
    "text": "partially documented so uh when we build",
    "start": "689720",
    "end": "692880"
  },
  {
    "text": "a solution that we want to enr metadata",
    "start": "692880",
    "end": "696320"
  },
  {
    "text": "in a large scale we want to make sure",
    "start": "696320",
    "end": "698399"
  },
  {
    "text": "the recommendation or the uh the",
    "start": "698399",
    "end": "700920"
  },
  {
    "text": "documentation that we generate are of",
    "start": "700920",
    "end": "702440"
  },
  {
    "text": "high quality and uniform format uh so",
    "start": "702440",
    "end": "706560"
  },
  {
    "text": "what we ended up doing is what we ended",
    "start": "706560",
    "end": "709120"
  },
  {
    "text": "up doing is having offline uh batch",
    "start": "709120",
    "end": "711880"
  },
  {
    "text": "inference job which basically enriches",
    "start": "711880",
    "end": "714040"
  },
  {
    "text": "the existing data set documentations of",
    "start": "714040",
    "end": "715959"
  },
  {
    "text": "the business count to generate richer",
    "start": "715959",
    "end": "718880"
  },
  {
    "text": "and more more formatted uh training data",
    "start": "718880",
    "end": "722240"
  },
  {
    "text": "set and that being used for training so",
    "start": "722240",
    "end": "725440"
  },
  {
    "text": "once we had training data the rest is",
    "start": "725440",
    "end": "727639"
  },
  {
    "text": "standard fine-tuning we have a training",
    "start": "727639",
    "end": "729440"
  },
  {
    "text": "job which basically reachs from use this",
    "start": "729440",
    "end": "732160"
  },
  {
    "text": "training data to fine-tune the uh models",
    "start": "732160",
    "end": "734880"
  },
  {
    "text": "the L longest models we have and we use",
    "start": "734880",
    "end": "737160"
  },
  {
    "text": "uh rate distributor infrastructure to",
    "start": "737160",
    "end": "739040"
  },
  {
    "text": "ensure that training process scales and",
    "start": "739040",
    "end": "741800"
  },
  {
    "text": "and is efficient uh we originally",
    "start": "741800",
    "end": "743920"
  },
  {
    "text": "started with uh Cube flow uh to F Chun",
    "start": "743920",
    "end": "747000"
  },
  {
    "text": "our models as the complexity and the",
    "start": "747000",
    "end": "749800"
  },
  {
    "text": "data training data increased we move to",
    "start": "749800",
    "end": "751959"
  },
  {
    "text": "Ray and it's been scaling so far pretty",
    "start": "751959",
    "end": "754600"
  },
  {
    "text": "well once we find you the model the next",
    "start": "754600",
    "end": "757480"
  },
  {
    "text": "is inference uh we'll talk about",
    "start": "757480",
    "end": "760399"
  },
  {
    "text": "inference more in detail",
    "start": "760399",
    "end": "763040"
  },
  {
    "text": "later and now we have feedback loop",
    "start": "763040",
    "end": "766199"
  },
  {
    "text": "after inference stage we enter into",
    "start": "766199",
    "end": "769160"
  },
  {
    "text": "feedback loop uh where a outputs are",
    "start": "769160",
    "end": "771800"
  },
  {
    "text": "reviewed by reviewed and validated by",
    "start": "771800",
    "end": "773800"
  },
  {
    "text": "data",
    "start": "773800",
    "end": "774519"
  },
  {
    "text": "sters either the data sters approve this",
    "start": "774519",
    "end": "777360"
  },
  {
    "text": "documentation as is if they they find it",
    "start": "777360",
    "end": "779839"
  },
  {
    "text": "really useful or uh make recommendations",
    "start": "779839",
    "end": "783600"
  },
  {
    "text": "to that make changes and then persist",
    "start": "783600",
    "end": "785519"
  },
  {
    "text": "them uh there are multiple signals that",
    "start": "785519",
    "end": "787480"
  },
  {
    "text": "we capture as feedback as part of that",
    "start": "787480",
    "end": "789920"
  },
  {
    "text": "some of the feedbacks will be used to",
    "start": "789920",
    "end": "792320"
  },
  {
    "text": "better train the model in the next",
    "start": "792320",
    "end": "794000"
  },
  {
    "text": "iterations or measure to measure the",
    "start": "794000",
    "end": "798600"
  },
  {
    "text": "quality of the model that are doing the",
    "start": "798600",
    "end": "800440"
  },
  {
    "text": "inference right now",
    "start": "800440",
    "end": "803079"
  },
  {
    "text": "uh so with the help of uh you the",
    "start": "803079",
    "end": "806720"
  },
  {
    "text": "feedback loop the model continuously",
    "start": "806720",
    "end": "808440"
  },
  {
    "text": "lenss with every iteration of uh the",
    "start": "808440",
    "end": "812040"
  },
  {
    "text": "recommendation it gives and data shows",
    "start": "812040",
    "end": "813920"
  },
  {
    "text": "reviewing it uh they continuously",
    "start": "813920",
    "end": "816560"
  },
  {
    "text": "improve the",
    "start": "816560",
    "end": "817800"
  },
  {
    "text": "accuracy and it also generates",
    "start": "817800",
    "end": "819720"
  },
  {
    "text": "consistent response",
    "start": "819720",
    "end": "821440"
  },
  {
    "text": "format let's take a look at high level",
    "start": "821440",
    "end": "824360"
  },
  {
    "text": "architecture uh of course there are more",
    "start": "824360",
    "end": "826839"
  },
  {
    "text": "PES in it but this is very high level uh",
    "start": "826839",
    "end": "830519"
  },
  {
    "text": "in the left side we have the client",
    "start": "830519",
    "end": "832279"
  },
  {
    "text": "which represent and user of the system",
    "start": "832279",
    "end": "834279"
  },
  {
    "text": "which is interacting with our a",
    "start": "834279",
    "end": "835600"
  },
  {
    "text": "application this could be data engineer",
    "start": "835600",
    "end": "837800"
  },
  {
    "text": "data scientist or business stakeholder",
    "start": "837800",
    "end": "839959"
  },
  {
    "text": "who are trying to classify and anate",
    "start": "839959",
    "end": "841440"
  },
  {
    "text": "data sets with business",
    "start": "841440",
    "end": "843759"
  },
  {
    "text": "context and the client submits the",
    "start": "843759",
    "end": "846000"
  },
  {
    "text": "request to a application uh and most of",
    "start": "846000",
    "end": "848880"
  },
  {
    "text": "the organizations have data platforms",
    "start": "848880",
    "end": "850959"
  },
  {
    "text": "built with systems like data catalog",
    "start": "850959",
    "end": "854320"
  },
  {
    "text": "which cataloges uh and registers all the",
    "start": "854320",
    "end": "856440"
  },
  {
    "text": "data set in the organization uh it",
    "start": "856440",
    "end": "858600"
  },
  {
    "text": "contains information like you know",
    "start": "858600",
    "end": "859800"
  },
  {
    "text": "metadata about the data sets and who is",
    "start": "859800",
    "end": "862600"
  },
  {
    "text": "uh the columns and other information and",
    "start": "862600",
    "end": "866079"
  },
  {
    "text": "in recent years many organizations",
    "start": "866079",
    "end": "867920"
  },
  {
    "text": "started adopting data lineage with and",
    "start": "867920",
    "end": "870600"
  },
  {
    "text": "data lineage has been uh tremendously",
    "start": "870600",
    "end": "873920"
  },
  {
    "text": "helpful for lot of privacy and",
    "start": "873920",
    "end": "875759"
  },
  {
    "text": "compliance use cases and there are many",
    "start": "875759",
    "end": "878000"
  },
  {
    "text": "many more res Cas as well and this is",
    "start": "878000",
    "end": "880360"
  },
  {
    "text": "something really valuable especially in",
    "start": "880360",
    "end": "882320"
  },
  {
    "text": "the context of generating",
    "start": "882320",
    "end": "883639"
  },
  {
    "text": "recommendations since we can derive some",
    "start": "883639",
    "end": "885839"
  },
  {
    "text": "useful information from the data sets",
    "start": "885839",
    "end": "888399"
  },
  {
    "text": "which were used in producing the DAT uh",
    "start": "888399",
    "end": "890759"
  },
  {
    "text": "producing the data set in question or",
    "start": "890759",
    "end": "893680"
  },
  {
    "text": "other Downstream data sets as well and",
    "start": "893680",
    "end": "896399"
  },
  {
    "text": "we have systems like AUD system with",
    "start": "896399",
    "end": "897800"
  },
  {
    "text": "capture change events happening on the",
    "start": "897800",
    "end": "899839"
  },
  {
    "text": "data set level all the data level and",
    "start": "899839",
    "end": "902560"
  },
  {
    "text": "also the usage information about data",
    "start": "902560",
    "end": "904079"
  },
  {
    "text": "sets and uh most organizations have",
    "start": "904079",
    "end": "907079"
  },
  {
    "text": "classifications well defined",
    "start": "907079",
    "end": "908360"
  },
  {
    "text": "classification structure where we want",
    "start": "908360",
    "end": "910240"
  },
  {
    "text": "to classify based on that existing",
    "start": "910240",
    "end": "912600"
  },
  {
    "text": "structure so the application kind of",
    "start": "912600",
    "end": "915000"
  },
  {
    "text": "based on the request that we that it",
    "start": "915000",
    "end": "916720"
  },
  {
    "text": "receives uh retrieves the information",
    "start": "916720",
    "end": "918920"
  },
  {
    "text": "from the existing tools and augment The",
    "start": "918920",
    "end": "920800"
  },
  {
    "text": "Prompt uh for the specific use case and",
    "start": "920800",
    "end": "924560"
  },
  {
    "text": "that Pro being given to the you know the",
    "start": "924560",
    "end": "926920"
  },
  {
    "text": "inference service to generate the",
    "start": "926920",
    "end": "928480"
  },
  {
    "text": "recommendation",
    "start": "928480",
    "end": "929920"
  },
  {
    "text": "uh in this case we are using uh VM and",
    "start": "929920",
    "end": "932920"
  },
  {
    "text": "Ray for powering our",
    "start": "932920",
    "end": "935399"
  },
  {
    "text": "inference VM uh framework is f easy to",
    "start": "935399",
    "end": "939000"
  },
  {
    "text": "use library and performs inferences with",
    "start": "939000",
    "end": "941560"
  },
  {
    "text": "low latency uh",
    "start": "941560",
    "end": "943839"
  },
  {
    "text": "and where whereas R serve takes care of",
    "start": "943839",
    "end": "946560"
  },
  {
    "text": "scaling of this deployments based on the",
    "start": "946560",
    "end": "948800"
  },
  {
    "text": "load that are the request that is",
    "start": "948800",
    "end": "951040"
  },
  {
    "text": "receiving this allows for the",
    "start": "951040",
    "end": "953240"
  },
  {
    "text": "combination of both elow for high",
    "start": "953240",
    "end": "954560"
  },
  {
    "text": "performance and scalable inferencing",
    "start": "954560",
    "end": "956160"
  },
  {
    "text": "which is critical for processing large",
    "start": "956160",
    "end": "958480"
  },
  {
    "text": "data set in real",
    "start": "958480",
    "end": "961560"
  },
  {
    "text": "time and as the recommendations go to",
    "start": "962000",
    "end": "964360"
  },
  {
    "text": "the user we receive feedback from them",
    "start": "964360",
    "end": "967160"
  },
  {
    "text": "uh and the application start storing",
    "start": "967160",
    "end": "968720"
  },
  {
    "text": "them in the feedback store which will",
    "start": "968720",
    "end": "970519"
  },
  {
    "text": "later be fed into training job along",
    "start": "970519",
    "end": "972800"
  },
  {
    "text": "with the training data that we talked",
    "start": "972800",
    "end": "974040"
  },
  {
    "text": "about earlier the feedback information",
    "start": "974040",
    "end": "976720"
  },
  {
    "text": "is also feding to training job uh to",
    "start": "976720",
    "end": "979279"
  },
  {
    "text": "better train and",
    "start": "979279",
    "end": "980959"
  },
  {
    "text": "iterate as people start adopting these",
    "start": "980959",
    "end": "985120"
  },
  {
    "text": "Solutions and we are using great",
    "start": "985120",
    "end": "987560"
  },
  {
    "text": "training jobs for uh training for",
    "start": "987560",
    "end": "990639"
  },
  {
    "text": "training these log language models uh",
    "start": "990639",
    "end": "993079"
  },
  {
    "text": "Ray provides you know High Paralis and",
    "start": "993079",
    "end": "994800"
  },
  {
    "text": "ability to distribute workload across",
    "start": "994800",
    "end": "996920"
  },
  {
    "text": "multiple",
    "start": "996920",
    "end": "999319"
  },
  {
    "text": "nodes let's take a let's take a look at",
    "start": "1001199",
    "end": "1004399"
  },
  {
    "text": "uh the prompt again and the responses",
    "start": "1004399",
    "end": "1006440"
  },
  {
    "text": "after fine shining uh the The Prompt is",
    "start": "1006440",
    "end": "1009759"
  },
  {
    "text": "you know quite simplistic that we sh",
    "start": "1009759",
    "end": "1012160"
  },
  {
    "text": "that we seeing here in real world use",
    "start": "1012160",
    "end": "1013759"
  },
  {
    "text": "case that as I described there is",
    "start": "1013759",
    "end": "1015560"
  },
  {
    "text": "lineage of data set that can be used",
    "start": "1015560",
    "end": "1017319"
  },
  {
    "text": "there is a lot of other metadata about",
    "start": "1017319",
    "end": "1019440"
  },
  {
    "text": "the data set that can go into prompt uh",
    "start": "1019440",
    "end": "1023040"
  },
  {
    "text": "and and we also need to put a lot of",
    "start": "1023040",
    "end": "1025798"
  },
  {
    "text": "effort on making sure that what the",
    "start": "1025799",
    "end": "1027798"
  },
  {
    "text": "information that we give is Meaningful",
    "start": "1027799",
    "end": "1030079"
  },
  {
    "text": "enough and it's not too much for the",
    "start": "1030079",
    "end": "1031720"
  },
  {
    "text": "model to start uh hallucinating or",
    "start": "1031720",
    "end": "1034640"
  },
  {
    "text": "losing context of the uh instructions",
    "start": "1034640",
    "end": "1037160"
  },
  {
    "text": "that we are giving okay so uh now it's",
    "start": "1037160",
    "end": "1041880"
  },
  {
    "text": "trying to classify actor which we have",
    "start": "1041880",
    "end": "1043600"
  },
  {
    "text": "seen earlier uh probably the model would",
    "start": "1043600",
    "end": "1046120"
  },
  {
    "text": "gain knowledge from the existing",
    "start": "1046120",
    "end": "1047438"
  },
  {
    "text": "training data that uh even the hashed",
    "start": "1047439",
    "end": "1050559"
  },
  {
    "text": "sensitive data should be treated as",
    "start": "1050559",
    "end": "1052160"
  },
  {
    "text": "sensitive so it's recommending as",
    "start": "1052160",
    "end": "1054600"
  },
  {
    "text": "pii and if you look at the documentation",
    "start": "1054600",
    "end": "1057600"
  },
  {
    "text": "is generating it's more concise and uh",
    "start": "1057600",
    "end": "1061960"
  },
  {
    "text": "uh and more",
    "start": "1061960",
    "end": "1064640"
  },
  {
    "text": "structured now let's talk about",
    "start": "1065240",
    "end": "1068960"
  },
  {
    "text": "inference so the inference needs for our",
    "start": "1068960",
    "end": "1072120"
  },
  {
    "text": "solution is quite simple we just need",
    "start": "1072120",
    "end": "1074520"
  },
  {
    "text": "low latency inference for both online",
    "start": "1074520",
    "end": "1077760"
  },
  {
    "text": "single request and batch request uh you",
    "start": "1077760",
    "end": "1080400"
  },
  {
    "text": "can take example of our users trying to",
    "start": "1080400",
    "end": "1083400"
  },
  {
    "text": "classify multiple columns at a time or",
    "start": "1083400",
    "end": "1085679"
  },
  {
    "text": "generate documentation for multiple",
    "start": "1085679",
    "end": "1087360"
  },
  {
    "text": "columns at a time it's quite common so",
    "start": "1087360",
    "end": "1091159"
  },
  {
    "text": "we have use case of online and at the",
    "start": "1091159",
    "end": "1093400"
  },
  {
    "text": "same time doing batch inference uh and",
    "start": "1093400",
    "end": "1096000"
  },
  {
    "text": "we need high throughput and scalability",
    "start": "1096000",
    "end": "1098240"
  },
  {
    "text": "is a big thing here because as as we",
    "start": "1098240",
    "end": "1100080"
  },
  {
    "text": "have large number of data that needs to",
    "start": "1100080",
    "end": "1101919"
  },
  {
    "text": "be enriched with",
    "start": "1101919",
    "end": "1103679"
  },
  {
    "text": "metadata and as theoperation grows uh",
    "start": "1103679",
    "end": "1106720"
  },
  {
    "text": "the infrastructure must scale and expand",
    "start": "1106720",
    "end": "1109360"
  },
  {
    "text": "according to the",
    "start": "1109360",
    "end": "1111080"
  },
  {
    "text": "load and the resources we are using are",
    "start": "1111080",
    "end": "1113600"
  },
  {
    "text": "high compute for inference or the",
    "start": "1113600",
    "end": "1115320"
  },
  {
    "text": "training so efficient use of high",
    "start": "1115320",
    "end": "1117760"
  },
  {
    "text": "computational resources is essential to",
    "start": "1117760",
    "end": "1120360"
  },
  {
    "text": "keep the operational cost",
    "start": "1120360",
    "end": "1122720"
  },
  {
    "text": "low so we started our inference Journey",
    "start": "1122720",
    "end": "1127880"
  },
  {
    "text": "as basic as AMA and ended up with",
    "start": "1127880",
    "end": "1131039"
  },
  {
    "text": "VM uh and our experience is VM scales",
    "start": "1131039",
    "end": "1134320"
  },
  {
    "text": "pretty well and it also offers low",
    "start": "1134320",
    "end": "1137400"
  },
  {
    "text": "latency St to the page uh attention",
    "start": "1137400",
    "end": "1141640"
  },
  {
    "text": "techniques that they that VM is using uh",
    "start": "1141640",
    "end": "1144480"
  },
  {
    "text": "it also provides open AI AP spec so it's",
    "start": "1144480",
    "end": "1148120"
  },
  {
    "text": "much easier to integrate with any of the",
    "start": "1148120",
    "end": "1150600"
  },
  {
    "text": "open source Library available for uh for",
    "start": "1150600",
    "end": "1153360"
  },
  {
    "text": "a building a applications uh it also has",
    "start": "1153360",
    "end": "1156080"
  },
  {
    "text": "batch inference and is also quite",
    "start": "1156080",
    "end": "1158039"
  },
  {
    "text": "performant as well uh and VM supports",
    "start": "1158039",
    "end": "1161520"
  },
  {
    "text": "something the quation and uh that",
    "start": "1161520",
    "end": "1165440"
  },
  {
    "text": "something is quite quite helping us and",
    "start": "1165440",
    "end": "1167720"
  },
  {
    "text": "also giving good good performance uh the",
    "start": "1167720",
    "end": "1171080"
  },
  {
    "text": "quantization kind of helps with keeping",
    "start": "1171080",
    "end": "1173000"
  },
  {
    "text": "the resource utilization low and and and",
    "start": "1173000",
    "end": "1175640"
  },
  {
    "text": "keeping the cost low uh because when we",
    "start": "1175640",
    "end": "1178240"
  },
  {
    "text": "contest the model basically the amount",
    "start": "1178240",
    "end": "1181000"
  },
  {
    "text": "of memory needs and other will reduce so",
    "start": "1181000",
    "end": "1183840"
  },
  {
    "text": "we can have more inference Sports",
    "start": "1183840",
    "end": "1185240"
  },
  {
    "text": "running on running running on the same",
    "start": "1185240",
    "end": "1187600"
  },
  {
    "text": "amount of resources without",
    "start": "1187600",
    "end": "1190320"
  },
  {
    "text": "quation on the other hand race are kind",
    "start": "1190320",
    "end": "1192760"
  },
  {
    "text": "of take care of autoscaling these VM",
    "start": "1192760",
    "end": "1195080"
  },
  {
    "text": "deployments based on the request that it",
    "start": "1195080",
    "end": "1197120"
  },
  {
    "text": "is receiving uh",
    "start": "1197120",
    "end": "1199200"
  },
  {
    "text": "if you take a look at right side example",
    "start": "1199200",
    "end": "1202159"
  },
  {
    "text": "uh in the top we are defining Reay",
    "start": "1202159",
    "end": "1205080"
  },
  {
    "text": "autoscale configuration it's most",
    "start": "1205080",
    "end": "1207200"
  },
  {
    "text": "simplistic one but can be we can also",
    "start": "1207200",
    "end": "1209080"
  },
  {
    "text": "add health checks and other stuff here",
    "start": "1209080",
    "end": "1211159"
  },
  {
    "text": "are indicating that the minimum replicas",
    "start": "1211159",
    "end": "1213960"
  },
  {
    "text": "for our deployment is one and Max",
    "start": "1213960",
    "end": "1216400"
  },
  {
    "text": "replicas that go up to each 10 and we",
    "start": "1216400",
    "end": "1219679"
  },
  {
    "text": "are we kind of indicating that Target",
    "start": "1219679",
    "end": "1222200"
  },
  {
    "text": "request for each deployment is five and",
    "start": "1222200",
    "end": "1224039"
  },
  {
    "text": "then it can go up to 10 so uh based on",
    "start": "1224039",
    "end": "1226840"
  },
  {
    "text": "the request that it's receiving rake",
    "start": "1226840",
    "end": "1229159"
  },
  {
    "text": "kind of takes care of autoscaling these",
    "start": "1229159",
    "end": "1230760"
  },
  {
    "text": "deployments and the request comes down",
    "start": "1230760",
    "end": "1233280"
  },
  {
    "text": "and it shinks down the deployments as",
    "start": "1233280",
    "end": "1235840"
  },
  {
    "text": "well and uh we can have a simple python",
    "start": "1235840",
    "end": "1239520"
  },
  {
    "text": "based you know fast API and use the easy",
    "start": "1239520",
    "end": "1242400"
  },
  {
    "text": "to use VM libraries to create this",
    "start": "1242400",
    "end": "1244520"
  },
  {
    "text": "deployment as we are seeing here and and",
    "start": "1244520",
    "end": "1247799"
  },
  {
    "text": "and then configure that with Ray it's",
    "start": "1247799",
    "end": "1249600"
  },
  {
    "text": "quite easy to scale from uh local into",
    "start": "1249600",
    "end": "1253559"
  },
  {
    "text": "the production with minor changes uh",
    "start": "1253559",
    "end": "1256039"
  },
  {
    "text": "minor changes in the configurations of",
    "start": "1256039",
    "end": "1257679"
  },
  {
    "text": "aut scaling Ray Auto scaling that we",
    "start": "1257679",
    "end": "1260440"
  },
  {
    "text": "need to do and Rayo supports health",
    "start": "1260440",
    "end": "1263200"
  },
  {
    "text": "checks and auto recovery so uh like the",
    "start": "1263200",
    "end": "1266880"
  },
  {
    "text": "amount of time it takes to productionize",
    "start": "1266880",
    "end": "1269720"
  },
  {
    "text": "the inference from local into you know",
    "start": "1269720",
    "end": "1271840"
  },
  {
    "text": "prod is tremendous",
    "start": "1271840",
    "end": "1275440"
  },
  {
    "text": "here okay let's summarize with key",
    "start": "1276039",
    "end": "1279120"
  },
  {
    "text": "takeaways accurate classification one of",
    "start": "1279120",
    "end": "1281919"
  },
  {
    "text": "the most significant benefits of a",
    "start": "1281919",
    "end": "1283600"
  },
  {
    "text": "driven data classification is accuracy",
    "start": "1283600",
    "end": "1285640"
  },
  {
    "text": "with fining the models we can ensure",
    "start": "1285640",
    "end": "1287320"
  },
  {
    "text": "that the data sets are ACC accurately",
    "start": "1287320",
    "end": "1288960"
  },
  {
    "text": "classified based on the patterns and",
    "start": "1288960",
    "end": "1290720"
  },
  {
    "text": "contextual",
    "start": "1290720",
    "end": "1292000"
  },
  {
    "text": "understanding as models give",
    "start": "1292000",
    "end": "1293760"
  },
  {
    "text": "recommendation get red on the feedback",
    "start": "1293760",
    "end": "1295559"
  },
  {
    "text": "the accuracy improves over time",
    "start": "1295559",
    "end": "1297600"
  },
  {
    "text": "unscalable classification with help of",
    "start": "1297600",
    "end": "1299679"
  },
  {
    "text": "gen and Frameworks like Ray and VM we",
    "start": "1299679",
    "end": "1302279"
  },
  {
    "text": "can scale the complex problems like data",
    "start": "1302279",
    "end": "1304120"
  },
  {
    "text": "classification annotations easily and",
    "start": "1304120",
    "end": "1307240"
  },
  {
    "text": "reduced oil by annotating uh by",
    "start": "1307240",
    "end": "1309799"
  },
  {
    "text": "automating the process of classification",
    "start": "1309799",
    "end": "1311200"
  },
  {
    "text": "annotation we can significantly reduce",
    "start": "1311200",
    "end": "1312600"
  },
  {
    "text": "the manual effort uh and toil required",
    "start": "1312600",
    "end": "1315679"
  },
  {
    "text": "by different teams in the organizations",
    "start": "1315679",
    "end": "1319760"
  },
  {
    "text": "and this is cost effective as automating",
    "start": "1319960",
    "end": "1322840"
  },
  {
    "text": "the data classification and annotations",
    "start": "1322840",
    "end": "1325159"
  },
  {
    "text": "with a can reduce the manual effort",
    "start": "1325159",
    "end": "1327960"
  },
  {
    "text": "required and save the operational",
    "start": "1327960",
    "end": "1331600"
  },
  {
    "text": "cost as we W wrap up this session I want",
    "start": "1332200",
    "end": "1334880"
  },
  {
    "text": "to emphasize that by harnessing the",
    "start": "1334880",
    "end": "1336440"
  },
  {
    "text": "power of AI we are not just solving",
    "start": "1336440",
    "end": "1338520"
  },
  {
    "text": "immediate challenges but we are setting",
    "start": "1338520",
    "end": "1340120"
  },
  {
    "text": "the stage for more data driven",
    "start": "1340120",
    "end": "1342200"
  },
  {
    "text": "future thank you all uh I will open up",
    "start": "1342200",
    "end": "1344679"
  },
  {
    "text": "for questions",
    "start": "1344679",
    "end": "1347919"
  },
  {
    "text": "[Applause]",
    "start": "1348370",
    "end": "1353309"
  },
  {
    "text": "[Music]",
    "start": "1353550",
    "end": "1356609"
  },
  {
    "text": "um how many examples you have to give",
    "start": "1362480",
    "end": "1364240"
  },
  {
    "text": "for fine tuning or your good question so",
    "start": "1364240",
    "end": "1369679"
  },
  {
    "text": "uh it depends for let's say data set",
    "start": "1369679",
    "end": "1372799"
  },
  {
    "text": "documentation or the classification is",
    "start": "1372799",
    "end": "1375159"
  },
  {
    "text": "completely different so if you talk",
    "start": "1375159",
    "end": "1376799"
  },
  {
    "text": "about uh as I mentioned like we have few",
    "start": "1376799",
    "end": "1380320"
  },
  {
    "text": "percentage of data sets well documented",
    "start": "1380320",
    "end": "1382480"
  },
  {
    "text": "so we kind of generate enriched train",
    "start": "1382480",
    "end": "1384279"
  },
  {
    "text": "data from that and document uh I would",
    "start": "1384279",
    "end": "1387559"
  },
  {
    "text": "say like probably about 10% of the data",
    "start": "1387559",
    "end": "1389960"
  },
  {
    "text": "sets that we have are went into the fin",
    "start": "1389960",
    "end": "1392520"
  },
  {
    "text": "the",
    "start": "1392520",
    "end": "1394640"
  },
  {
    "text": "model uh couple of questions you",
    "start": "1396880",
    "end": "1399559"
  },
  {
    "text": "mentioned about data lineage are you",
    "start": "1399559",
    "end": "1401240"
  },
  {
    "text": "using any specific tool for data",
    "start": "1401240",
    "end": "1404640"
  },
  {
    "text": "line um so yeah we have some solution",
    "start": "1404640",
    "end": "1409440"
  },
  {
    "text": "that are in buil that we're using for",
    "start": "1409440",
    "end": "1411440"
  },
  {
    "text": "data lineage uh and you know uh",
    "start": "1411440",
    "end": "1415279"
  },
  {
    "text": "yeah that much I can talk about okay so",
    "start": "1415279",
    "end": "1417880"
  },
  {
    "text": "nothing open source as such you built",
    "start": "1417880",
    "end": "1419720"
  },
  {
    "text": "something inh house yeah uh I prefer to",
    "start": "1419720",
    "end": "1422600"
  },
  {
    "text": "stick to uh talk no problem uh you also",
    "start": "1422600",
    "end": "1427120"
  },
  {
    "text": "mentioned about Ray and VM is there any",
    "start": "1427120",
    "end": "1430200"
  },
  {
    "text": "specific platform that you're running",
    "start": "1430200",
    "end": "1431760"
  },
  {
    "text": "Ray and VM for scalability and",
    "start": "1431760",
    "end": "1434559"
  },
  {
    "text": "everything yeah so uh we have in inbuilt",
    "start": "1434559",
    "end": "1438640"
  },
  {
    "text": "uh solutions for launching Ray we have",
    "start": "1438640",
    "end": "1441240"
  },
  {
    "text": "infr team which takes care of Ray as",
    "start": "1441240",
    "end": "1443480"
  },
  {
    "text": "offering and you know we launch the",
    "start": "1443480",
    "end": "1445840"
  },
  {
    "text": "Clusters as we need and then uh run the",
    "start": "1445840",
    "end": "1448440"
  },
  {
    "text": "jobs and scale the scale the deployments",
    "start": "1448440",
    "end": "1451400"
  },
  {
    "text": "or training jobs that we",
    "start": "1451400",
    "end": "1453320"
  },
  {
    "text": "need good",
    "start": "1453320",
    "end": "1456559"
  },
  {
    "text": "question uh any further questions please",
    "start": "1457240",
    "end": "1459720"
  },
  {
    "text": "raise your hand then I can give you",
    "start": "1459720",
    "end": "1463480"
  },
  {
    "text": "microphone if no then let's thank the",
    "start": "1467000",
    "end": "1470480"
  },
  {
    "text": "speaker again thank you",
    "start": "1470480",
    "end": "1475640"
  }
]
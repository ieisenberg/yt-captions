[
  {
    "start": "0",
    "end": "28000"
  },
  {
    "text": "hi everyone",
    "start": "2800",
    "end": "3760"
  },
  {
    "text": "and welcome to my talk at the race",
    "start": "3760",
    "end": "6000"
  },
  {
    "text": "summit 2020",
    "start": "6000",
    "end": "8000"
  },
  {
    "text": "today i'm going to talk about our",
    "start": "8000",
    "end": "9679"
  },
  {
    "text": "library at hacking face",
    "start": "9679",
    "end": "11599"
  },
  {
    "text": "the transformer tokenizer and dataset",
    "start": "11599",
    "end": "13679"
  },
  {
    "text": "library",
    "start": "13679",
    "end": "14799"
  },
  {
    "text": "now we'll talk how you can use rey to",
    "start": "14799",
    "end": "17199"
  },
  {
    "text": "easily",
    "start": "17199",
    "end": "17920"
  },
  {
    "text": "get state of the art nlp model on your",
    "start": "17920",
    "end": "20240"
  },
  {
    "text": "application",
    "start": "20240",
    "end": "22880"
  },
  {
    "text": "let's start by a quick reminder on",
    "start": "23359",
    "end": "25279"
  },
  {
    "text": "transfer learning",
    "start": "25279",
    "end": "27840"
  },
  {
    "text": "so what is transfer learning so you have",
    "start": "27840",
    "end": "30400"
  },
  {
    "start": "28000",
    "end": "28000"
  },
  {
    "text": "a link here to a full tutorial on",
    "start": "30400",
    "end": "32398"
  },
  {
    "text": "transfer learning that we did last year",
    "start": "32399",
    "end": "34239"
  },
  {
    "text": "at knuckle be sure to check this out if",
    "start": "34239",
    "end": "36160"
  },
  {
    "text": "you want more information here it will",
    "start": "36160",
    "end": "37920"
  },
  {
    "text": "be just a very brief overview",
    "start": "37920",
    "end": "40800"
  },
  {
    "text": "so the traditional way we train a neural",
    "start": "40800",
    "end": "43440"
  },
  {
    "text": "network model or like just a machine",
    "start": "43440",
    "end": "45200"
  },
  {
    "text": "learning model is usually together a",
    "start": "45200",
    "end": "46960"
  },
  {
    "text": "data set",
    "start": "46960",
    "end": "47840"
  },
  {
    "text": "to initialize our weights or",
    "start": "47840",
    "end": "51680"
  },
  {
    "text": "from scratch and then we train our model",
    "start": "51680",
    "end": "54000"
  },
  {
    "text": "on your on your datasets",
    "start": "54000",
    "end": "55760"
  },
  {
    "text": "and if you haven't uh in if you're faced",
    "start": "55760",
    "end": "57760"
  },
  {
    "text": "with a new test you usually get a new",
    "start": "57760",
    "end": "59680"
  },
  {
    "text": "data set",
    "start": "59680",
    "end": "60800"
  },
  {
    "text": "and you again you randomly initialize",
    "start": "60800",
    "end": "62719"
  },
  {
    "text": "your ways from scratch and you train",
    "start": "62719",
    "end": "64320"
  },
  {
    "text": "your model on the second task and the",
    "start": "64320",
    "end": "66080"
  },
  {
    "text": "same if you're faced with a third task",
    "start": "66080",
    "end": "69760"
  },
  {
    "text": "now usually the way a human learn",
    "start": "69920",
    "end": "72960"
  },
  {
    "text": "is is quite different we we kind of use",
    "start": "72960",
    "end": "75280"
  },
  {
    "text": "like all the knowledge we've gathered",
    "start": "75280",
    "end": "77119"
  },
  {
    "text": "on past tasks that we've tackled",
    "start": "77119",
    "end": "80240"
  },
  {
    "text": "and we use all this knowledge to",
    "start": "80240",
    "end": "83680"
  },
  {
    "text": "learn a new task when when we're faced",
    "start": "83680",
    "end": "85920"
  },
  {
    "text": "with a new task",
    "start": "85920",
    "end": "87200"
  },
  {
    "text": "and this help us do do two things in",
    "start": "87200",
    "end": "89600"
  },
  {
    "text": "particular and help us learn with just a",
    "start": "89600",
    "end": "91759"
  },
  {
    "text": "very",
    "start": "91759",
    "end": "92880"
  },
  {
    "text": "limited number of examples and it also",
    "start": "92880",
    "end": "95759"
  },
  {
    "text": "uh",
    "start": "95759",
    "end": "96079"
  },
  {
    "text": "help us reach better performances on",
    "start": "96079",
    "end": "99119"
  },
  {
    "text": "this new test because we can filling all",
    "start": "99119",
    "end": "101200"
  },
  {
    "text": "the gaps between this",
    "start": "101200",
    "end": "103119"
  },
  {
    "text": "this handful of example we can fill in",
    "start": "103119",
    "end": "106240"
  },
  {
    "text": "all these gaps",
    "start": "106240",
    "end": "107520"
  },
  {
    "text": "using the knowledge we've gathered on",
    "start": "107520",
    "end": "109439"
  },
  {
    "text": "previous tasks so transfer learning is",
    "start": "109439",
    "end": "111680"
  },
  {
    "text": "one way to try to do that for machine",
    "start": "111680",
    "end": "113680"
  },
  {
    "text": "learning",
    "start": "113680",
    "end": "114079"
  },
  {
    "text": "systems there are many ways to do",
    "start": "114079",
    "end": "116320"
  },
  {
    "start": "116000",
    "end": "116000"
  },
  {
    "text": "transfer learning but",
    "start": "116320",
    "end": "117920"
  },
  {
    "text": "the way that we are mostly interested",
    "start": "117920",
    "end": "119600"
  },
  {
    "text": "today is called sequential",
    "start": "119600",
    "end": "121520"
  },
  {
    "text": "transfer learning sequential transfer",
    "start": "121520",
    "end": "124079"
  },
  {
    "text": "learning means that you have a sequence",
    "start": "124079",
    "end": "126240"
  },
  {
    "text": "of steps",
    "start": "126240",
    "end": "127439"
  },
  {
    "text": "usually you have at least two steps the",
    "start": "127439",
    "end": "129520"
  },
  {
    "text": "first step is copy training",
    "start": "129520",
    "end": "131760"
  },
  {
    "text": "and the second step is called adaptation",
    "start": "131760",
    "end": "133760"
  },
  {
    "text": "adaptation can actually include several",
    "start": "133760",
    "end": "135920"
  },
  {
    "text": "sub steps but this is the simplest cases",
    "start": "135920",
    "end": "138239"
  },
  {
    "text": "here",
    "start": "138239",
    "end": "139840"
  },
  {
    "text": "pre-training is a very computationally",
    "start": "139840",
    "end": "142959"
  },
  {
    "text": "intensive step in which we try to gather",
    "start": "142959",
    "end": "145200"
  },
  {
    "text": "at",
    "start": "145200",
    "end": "145840"
  },
  {
    "text": "as much data as we can so we get what we",
    "start": "145840",
    "end": "149280"
  },
  {
    "text": "what we call a general purpose model",
    "start": "149280",
    "end": "152000"
  },
  {
    "text": "so you probably have heard about many of",
    "start": "152000",
    "end": "154319"
  },
  {
    "text": "these models",
    "start": "154319",
    "end": "155120"
  },
  {
    "text": "here you can see bird gpt ulm feet elmo",
    "start": "155120",
    "end": "158720"
  },
  {
    "text": "and maybe the the first examples where",
    "start": "158720",
    "end": "160640"
  },
  {
    "text": "the word tuvak",
    "start": "160640",
    "end": "162080"
  },
  {
    "text": "and the glovy uh were the meanings",
    "start": "162080",
    "end": "165440"
  },
  {
    "text": "the second step adaptation is as i told",
    "start": "165440",
    "end": "168239"
  },
  {
    "text": "you just uh just right now is a data",
    "start": "168239",
    "end": "170560"
  },
  {
    "text": "efficient step so we can do",
    "start": "170560",
    "end": "173280"
  },
  {
    "text": "fine-tuning this is also called sometime",
    "start": "173280",
    "end": "175280"
  },
  {
    "text": "fine tuning we can do fine tuning with",
    "start": "175280",
    "end": "176959"
  },
  {
    "text": "just very small",
    "start": "176959",
    "end": "178319"
  },
  {
    "text": "data set and reach good performances",
    "start": "178319",
    "end": "181040"
  },
  {
    "text": "okay",
    "start": "181040",
    "end": "183360"
  },
  {
    "text": "so this second step is uh actually on",
    "start": "183360",
    "end": "186080"
  },
  {
    "text": "your",
    "start": "186080",
    "end": "186480"
  },
  {
    "text": "target data set here in the during the",
    "start": "186480",
    "end": "188400"
  },
  {
    "text": "pre-training you gather as much training",
    "start": "188400",
    "end": "190720"
  },
  {
    "text": "that as you can so they are not",
    "start": "190720",
    "end": "193200"
  },
  {
    "text": "not all the data is related to your",
    "start": "193200",
    "end": "195280"
  },
  {
    "text": "target test but during the adaptation",
    "start": "195280",
    "end": "197519"
  },
  {
    "text": "you have like a very small uh you have a",
    "start": "197519",
    "end": "199760"
  },
  {
    "text": "small data set and this one is really",
    "start": "199760",
    "end": "201440"
  },
  {
    "text": "specific",
    "start": "201440",
    "end": "202080"
  },
  {
    "text": "of the target task you're interested in",
    "start": "202080",
    "end": "204080"
  },
  {
    "text": "can be test classification",
    "start": "204080",
    "end": "205840"
  },
  {
    "text": "token classification question answering",
    "start": "205840",
    "end": "208080"
  },
  {
    "text": "and so on",
    "start": "208080",
    "end": "209599"
  },
  {
    "start": "209000",
    "end": "209000"
  },
  {
    "text": "the models that people use right now are",
    "start": "209599",
    "end": "211760"
  },
  {
    "text": "mostly",
    "start": "211760",
    "end": "212879"
  },
  {
    "text": "called transformers these models are",
    "start": "212879",
    "end": "215840"
  },
  {
    "text": "quite efficient when you want to train",
    "start": "215840",
    "end": "217280"
  },
  {
    "text": "them a large amount of data",
    "start": "217280",
    "end": "218959"
  },
  {
    "text": "so here is a how the pre-training looks",
    "start": "218959",
    "end": "221040"
  },
  {
    "text": "you take a random",
    "start": "221040",
    "end": "222560"
  },
  {
    "text": "like you take an input which is a",
    "start": "222560",
    "end": "225360"
  },
  {
    "text": "sequence for instance here it's",
    "start": "225360",
    "end": "227360"
  },
  {
    "text": "my dog is a good dog and then we mask",
    "start": "227360",
    "end": "230159"
  },
  {
    "text": "one word okay",
    "start": "230159",
    "end": "231120"
  },
  {
    "text": "this one is called this retraining",
    "start": "231120",
    "end": "233200"
  },
  {
    "text": "objective is called mask language",
    "start": "233200",
    "end": "234640"
  },
  {
    "text": "modeling",
    "start": "234640",
    "end": "235599"
  },
  {
    "text": "mask one word we input that in the model",
    "start": "235599",
    "end": "238319"
  },
  {
    "text": "the first uh stage of the model is",
    "start": "238319",
    "end": "240640"
  },
  {
    "text": "input americans as a set of eponaminics",
    "start": "240640",
    "end": "242799"
  },
  {
    "text": "which converts",
    "start": "242799",
    "end": "244080"
  },
  {
    "text": "these words into vectors these vectors",
    "start": "244080",
    "end": "247599"
  },
  {
    "text": "they are not contextualized okay they",
    "start": "247599",
    "end": "249360"
  },
  {
    "text": "don't really they don't depend on the",
    "start": "249360",
    "end": "251439"
  },
  {
    "text": "other vectors in this at this first",
    "start": "251439",
    "end": "253360"
  },
  {
    "text": "stage but we would like",
    "start": "253360",
    "end": "255200"
  },
  {
    "text": "each word to be a function of uh the",
    "start": "255200",
    "end": "258239"
  },
  {
    "text": "context the left",
    "start": "258239",
    "end": "259519"
  },
  {
    "text": "and the right context so to do that we",
    "start": "259519",
    "end": "262320"
  },
  {
    "text": "have what we call an attention layer",
    "start": "262320",
    "end": "264720"
  },
  {
    "text": "and this way actually we have usually",
    "start": "264720",
    "end": "266560"
  },
  {
    "text": "several attention layer but this",
    "start": "266560",
    "end": "268080"
  },
  {
    "text": "attention layer they do weighted average",
    "start": "268080",
    "end": "270400"
  },
  {
    "text": "between the words okay each words each",
    "start": "270400",
    "end": "272720"
  },
  {
    "text": "each vector here",
    "start": "272720",
    "end": "274320"
  },
  {
    "text": "will be transformed in the new vector",
    "start": "274320",
    "end": "276320"
  },
  {
    "text": "which is a weighted average of the",
    "start": "276320",
    "end": "277840"
  },
  {
    "text": "surrounding words",
    "start": "277840",
    "end": "280639"
  },
  {
    "text": "and um which also goes through a",
    "start": "280639",
    "end": "282960"
  },
  {
    "text": "non-linearity",
    "start": "282960",
    "end": "284240"
  },
  {
    "text": "so you just just don't have a linear",
    "start": "284240",
    "end": "286639"
  },
  {
    "text": "model",
    "start": "286639",
    "end": "287440"
  },
  {
    "text": "and then at the end you you end up",
    "start": "287440",
    "end": "289280"
  },
  {
    "text": "prefer final hidden states",
    "start": "289280",
    "end": "291199"
  },
  {
    "text": "that are depending on that depends on",
    "start": "291199",
    "end": "293919"
  },
  {
    "text": "the context",
    "start": "293919",
    "end": "294960"
  },
  {
    "text": "so here this masked word the final",
    "start": "294960",
    "end": "297520"
  },
  {
    "text": "hidden states",
    "start": "297520",
    "end": "298400"
  },
  {
    "text": "is actually a function of the left and",
    "start": "298400",
    "end": "300880"
  },
  {
    "text": "the right context",
    "start": "300880",
    "end": "302400"
  },
  {
    "text": "and so we can then project this back on",
    "start": "302400",
    "end": "304639"
  },
  {
    "text": "the vocabulary",
    "start": "304639",
    "end": "305919"
  },
  {
    "text": "and we'll use the training objective",
    "start": "305919",
    "end": "307919"
  },
  {
    "text": "which is to predict the masked words so",
    "start": "307919",
    "end": "310240"
  },
  {
    "text": "here the model will be trained to",
    "start": "310240",
    "end": "312240"
  },
  {
    "text": "reconstruct the word his from",
    "start": "312240",
    "end": "315360"
  },
  {
    "text": "the mask token okay this one is called",
    "start": "315360",
    "end": "317840"
  },
  {
    "text": "long mask language modeling but you can",
    "start": "317840",
    "end": "319520"
  },
  {
    "text": "do",
    "start": "319520",
    "end": "319919"
  },
  {
    "text": "another variant which is called language",
    "start": "319919",
    "end": "322479"
  },
  {
    "text": "modeling so this one is like the gbt",
    "start": "322479",
    "end": "324720"
  },
  {
    "text": "ctrl family of model",
    "start": "324720",
    "end": "328000"
  },
  {
    "text": "and in this one you only attend to the",
    "start": "328000",
    "end": "330320"
  },
  {
    "text": "left context",
    "start": "330320",
    "end": "331360"
  },
  {
    "text": "so you have a little bit less",
    "start": "331360",
    "end": "332479"
  },
  {
    "text": "information than here but",
    "start": "332479",
    "end": "334720"
  },
  {
    "text": "um you're trying to predict the next",
    "start": "334720",
    "end": "337120"
  },
  {
    "text": "word which means that for each word here",
    "start": "337120",
    "end": "339120"
  },
  {
    "text": "you have a training signal for each",
    "start": "339120",
    "end": "340800"
  },
  {
    "text": "input document you have a training",
    "start": "340800",
    "end": "341919"
  },
  {
    "text": "signal so you have",
    "start": "341919",
    "end": "342880"
  },
  {
    "text": "more training signal than in the case of",
    "start": "342880",
    "end": "344960"
  },
  {
    "text": "birth okay this one is a bit more",
    "start": "344960",
    "end": "346800"
  },
  {
    "text": "efficient in terms of of",
    "start": "346800",
    "end": "348160"
  },
  {
    "text": "training speed but",
    "start": "348160",
    "end": "352639"
  },
  {
    "text": "you trade this with less context you",
    "start": "352639",
    "end": "356240"
  },
  {
    "text": "can't really",
    "start": "356240",
    "end": "357039"
  },
  {
    "text": "one word can't be a function of the",
    "start": "357039",
    "end": "359520"
  },
  {
    "text": "right context",
    "start": "359520",
    "end": "360400"
  },
  {
    "text": "in this case now that we have p train",
    "start": "360400",
    "end": "363919"
  },
  {
    "start": "363000",
    "end": "363000"
  },
  {
    "text": "our model we want to adapt it",
    "start": "363919",
    "end": "365440"
  },
  {
    "text": "so to adapt it it's pretty simple we",
    "start": "365440",
    "end": "367759"
  },
  {
    "text": "first start by removing",
    "start": "367759",
    "end": "369680"
  },
  {
    "text": "the pre-training head in our cases it",
    "start": "369680",
    "end": "372400"
  },
  {
    "text": "was",
    "start": "372400",
    "end": "372800"
  },
  {
    "text": "just the back prepare the back",
    "start": "372800",
    "end": "375520"
  },
  {
    "text": "projection on the vocabulary",
    "start": "375520",
    "end": "377440"
  },
  {
    "text": "and then we'll add a head on top",
    "start": "377440",
    "end": "380720"
  },
  {
    "text": "instead of this pre-training head can be",
    "start": "380720",
    "end": "382880"
  },
  {
    "text": "very simple can be just a linear layer",
    "start": "382880",
    "end": "385120"
  },
  {
    "text": "can be very complex if you want to add a",
    "start": "385120",
    "end": "386880"
  },
  {
    "text": "full lstm on top of bird that you can do",
    "start": "386880",
    "end": "390560"
  },
  {
    "text": "sometimes you also adapt to a test that",
    "start": "390560",
    "end": "392639"
  },
  {
    "text": "is really different for instance you",
    "start": "392639",
    "end": "394240"
  },
  {
    "text": "want to use your",
    "start": "394240",
    "end": "395520"
  },
  {
    "text": "single model in an encoder decoder setup",
    "start": "395520",
    "end": "398560"
  },
  {
    "text": "to do for instance translation or",
    "start": "398560",
    "end": "400720"
  },
  {
    "text": "summarization",
    "start": "400720",
    "end": "401840"
  },
  {
    "text": "and indicates this this adaptation test",
    "start": "401840",
    "end": "404080"
  },
  {
    "text": "can be quite quite complex",
    "start": "404080",
    "end": "405919"
  },
  {
    "text": "let's look at an example let's say we",
    "start": "405919",
    "end": "409280"
  },
  {
    "text": "have an input sentence",
    "start": "409280",
    "end": "411280"
  },
  {
    "text": "jim hansen was a puppeter",
    "start": "411280",
    "end": "414880"
  },
  {
    "text": "okay and we want to predict whether this",
    "start": "414880",
    "end": "418000"
  },
  {
    "text": "input sequence is true or false what are",
    "start": "418000",
    "end": "421120"
  },
  {
    "text": "the various steps",
    "start": "421120",
    "end": "422319"
  },
  {
    "text": "we are we are doing so the first step",
    "start": "422319",
    "end": "425840"
  },
  {
    "text": "will be to um what we call",
    "start": "425840",
    "end": "428880"
  },
  {
    "text": "encode or tokenize this this input",
    "start": "428880",
    "end": "431280"
  },
  {
    "text": "sentence",
    "start": "431280",
    "end": "432160"
  },
  {
    "text": "so we want to split it in words some",
    "start": "432160",
    "end": "434319"
  },
  {
    "text": "words are quite complex puppeteer is",
    "start": "434319",
    "end": "436400"
  },
  {
    "text": "quite a rare word",
    "start": "436400",
    "end": "437759"
  },
  {
    "text": "and our models they are made to be able",
    "start": "437759",
    "end": "439599"
  },
  {
    "text": "to process the text for the whole from",
    "start": "439599",
    "end": "441599"
  },
  {
    "text": "the whole internet they are made to be",
    "start": "441599",
    "end": "443199"
  },
  {
    "text": "able to process",
    "start": "443199",
    "end": "444080"
  },
  {
    "text": "like huge quantity of text so how do we",
    "start": "444080",
    "end": "446639"
  },
  {
    "text": "manage",
    "start": "446639",
    "end": "447360"
  },
  {
    "text": "rare words well the idea is that we will",
    "start": "447360",
    "end": "450319"
  },
  {
    "text": "split them in sub words",
    "start": "450319",
    "end": "452160"
  },
  {
    "text": "until we know all the subparts so here",
    "start": "452160",
    "end": "454800"
  },
  {
    "text": "perpetual will be split in puppet",
    "start": "454800",
    "end": "456880"
  },
  {
    "text": "and er with the suffix error and here we",
    "start": "456880",
    "end": "459759"
  },
  {
    "text": "know",
    "start": "459759",
    "end": "460160"
  },
  {
    "text": "both subparts of it okay and we by by",
    "start": "460160",
    "end": "463599"
  },
  {
    "text": "no i mean they are they are in our model",
    "start": "463599",
    "end": "466080"
  },
  {
    "text": "vocabulary the vocabulary of a model is",
    "start": "466080",
    "end": "468639"
  },
  {
    "text": "usually a few tens thousands of words",
    "start": "468639",
    "end": "470879"
  },
  {
    "text": "for instance for birds it's about 50 000",
    "start": "470879",
    "end": "473280"
  },
  {
    "text": "of words",
    "start": "473280",
    "end": "474560"
  },
  {
    "text": "okay now we can convert now that we have",
    "start": "474560",
    "end": "477919"
  },
  {
    "text": "all these",
    "start": "477919",
    "end": "478400"
  },
  {
    "text": "uh subwords that are in a vocabulary we",
    "start": "478400",
    "end": "480400"
  },
  {
    "text": "can convert them in",
    "start": "480400",
    "end": "481599"
  },
  {
    "text": "indices which are just doing this is in",
    "start": "481599",
    "end": "483680"
  },
  {
    "text": "our in our vocabulary",
    "start": "483680",
    "end": "485120"
  },
  {
    "text": "and this is a numeric input so we can",
    "start": "485120",
    "end": "487360"
  },
  {
    "text": "now use that as input for our model",
    "start": "487360",
    "end": "490560"
  },
  {
    "text": "the model is the the transformer that",
    "start": "490560",
    "end": "492879"
  },
  {
    "text": "we've just seen okay that output",
    "start": "492879",
    "end": "494960"
  },
  {
    "text": "as we've seen it output vector like",
    "start": "494960",
    "end": "497759"
  },
  {
    "text": "hidden states which are vectors",
    "start": "497759",
    "end": "499840"
  },
  {
    "text": "for each input token okay so here we",
    "start": "499840",
    "end": "503039"
  },
  {
    "text": "have a vector like",
    "start": "503039",
    "end": "504080"
  },
  {
    "text": "our vector have a dimensionally of four",
    "start": "504080",
    "end": "506319"
  },
  {
    "text": "well this is just an example",
    "start": "506319",
    "end": "507680"
  },
  {
    "text": "in real life the dimension is usually",
    "start": "507680",
    "end": "510400"
  },
  {
    "text": "the dimensionality is usually",
    "start": "510400",
    "end": "512399"
  },
  {
    "text": "a few hundred for instance seven hundred",
    "start": "512399",
    "end": "514800"
  },
  {
    "text": "and sixty eight four four birds",
    "start": "514800",
    "end": "516399"
  },
  {
    "text": "something like that",
    "start": "516399",
    "end": "517680"
  },
  {
    "text": "now that we have these hidden states",
    "start": "517680",
    "end": "519518"
  },
  {
    "text": "which are like contextualized vector",
    "start": "519519",
    "end": "521680"
  },
  {
    "text": "associated to each token",
    "start": "521680",
    "end": "524159"
  },
  {
    "text": "we can we want to project them back to",
    "start": "524159",
    "end": "526240"
  },
  {
    "text": "this dimensional id of two",
    "start": "526240",
    "end": "528320"
  },
  {
    "text": "so we just do a pulling here for",
    "start": "528320",
    "end": "530880"
  },
  {
    "text": "instance just max pulling",
    "start": "530880",
    "end": "532480"
  },
  {
    "text": "or we can take like a special token at",
    "start": "532480",
    "end": "534399"
  },
  {
    "text": "beginning which will be",
    "start": "534399",
    "end": "536000"
  },
  {
    "text": "um tasked to attend to all the sentence",
    "start": "536000",
    "end": "538640"
  },
  {
    "text": "well",
    "start": "538640",
    "end": "539279"
  },
  {
    "text": "we reduce this matrix to one vector by",
    "start": "539279",
    "end": "542320"
  },
  {
    "text": "one mean and then we can just",
    "start": "542320",
    "end": "543760"
  },
  {
    "text": "project this to a smaller dimension for",
    "start": "543760",
    "end": "546399"
  },
  {
    "text": "instance we've just",
    "start": "546399",
    "end": "547760"
  },
  {
    "text": "like a linear transform from the hidden",
    "start": "547760",
    "end": "550560"
  },
  {
    "text": "state dimensionality",
    "start": "550560",
    "end": "551920"
  },
  {
    "text": "down to our output class dimensionality",
    "start": "551920",
    "end": "556240"
  },
  {
    "text": "so the pre-trained model that you see",
    "start": "556640",
    "end": "558320"
  },
  {
    "text": "here is trained during the pre-training",
    "start": "558320",
    "end": "561040"
  },
  {
    "text": "phase",
    "start": "561040",
    "end": "562240"
  },
  {
    "text": "and the classifier that you see here is",
    "start": "562240",
    "end": "564720"
  },
  {
    "text": "actually initialized from scratch",
    "start": "564720",
    "end": "566640"
  },
  {
    "text": "during the adaptation or fine-tuning",
    "start": "566640",
    "end": "568720"
  },
  {
    "text": "phase and it's only trained on our small",
    "start": "568720",
    "end": "571040"
  },
  {
    "text": "test target test data set okay",
    "start": "571040",
    "end": "572880"
  },
  {
    "text": "but this is fine because this one is",
    "start": "572880",
    "end": "574720"
  },
  {
    "text": "usually a very small",
    "start": "574720",
    "end": "577120"
  },
  {
    "text": "comprise a small number of parameter it",
    "start": "577120",
    "end": "579519"
  },
  {
    "text": "can be just like",
    "start": "579519",
    "end": "580480"
  },
  {
    "text": "just a linear projection as i told you",
    "start": "580480",
    "end": "583760"
  },
  {
    "text": "okay so this is typically the typical",
    "start": "583760",
    "end": "586080"
  },
  {
    "start": "586000",
    "end": "586000"
  },
  {
    "text": "workflow",
    "start": "586080",
    "end": "587279"
  },
  {
    "text": "now here is one example on a text",
    "start": "587279",
    "end": "589120"
  },
  {
    "text": "classification task this test is called",
    "start": "589120",
    "end": "591120"
  },
  {
    "text": "track six",
    "start": "591120",
    "end": "591920"
  },
  {
    "text": "so the data set is called track six it's",
    "start": "591920",
    "end": "594080"
  },
  {
    "text": "a six class text classification task",
    "start": "594080",
    "end": "597440"
  },
  {
    "text": "um and as you can see when you when you",
    "start": "597440",
    "end": "600240"
  },
  {
    "text": "run the fine tuning",
    "start": "600240",
    "end": "603040"
  },
  {
    "text": "you can see several things the first",
    "start": "603040",
    "end": "604560"
  },
  {
    "text": "thing that you can see is that just",
    "start": "604560",
    "end": "606160"
  },
  {
    "text": "after one epoch",
    "start": "606160",
    "end": "607519"
  },
  {
    "text": "on this uh on this uh adaptation data",
    "start": "607519",
    "end": "611120"
  },
  {
    "text": "set it's a very small data set it's like",
    "start": "611120",
    "end": "613320"
  },
  {
    "text": "2500 examples okay so",
    "start": "613320",
    "end": "615600"
  },
  {
    "text": "it's really small in terms of deep",
    "start": "615600",
    "end": "618399"
  },
  {
    "text": "learning",
    "start": "618399",
    "end": "619200"
  },
  {
    "text": "size so you can see that after one epoch",
    "start": "619200",
    "end": "621519"
  },
  {
    "text": "of fine tuning we're already down to",
    "start": "621519",
    "end": "623360"
  },
  {
    "text": "less than 10",
    "start": "623360",
    "end": "624399"
  },
  {
    "text": "error rates so we're already over 90",
    "start": "624399",
    "end": "627760"
  },
  {
    "text": "accuracy this is really nice and you can",
    "start": "627760",
    "end": "630000"
  },
  {
    "text": "see that after",
    "start": "630000",
    "end": "630800"
  },
  {
    "text": "three epochs the error rate is down to",
    "start": "630800",
    "end": "634240"
  },
  {
    "text": "3.6",
    "start": "634240",
    "end": "635519"
  },
  {
    "text": "which is actually the state of the art",
    "start": "635519",
    "end": "637360"
  },
  {
    "text": "well it was the state of the art like",
    "start": "637360",
    "end": "639279"
  },
  {
    "text": "last year so this is quite nice okay",
    "start": "639279",
    "end": "642399"
  },
  {
    "text": "and it's pretty robust in this example",
    "start": "642399",
    "end": "644399"
  },
  {
    "text": "we took some",
    "start": "644399",
    "end": "645440"
  },
  {
    "text": "just some hyper parameters that are",
    "start": "645440",
    "end": "647920"
  },
  {
    "text": "given in the literature we didn't do any",
    "start": "647920",
    "end": "650079"
  },
  {
    "text": "hyperparameter search and this is",
    "start": "650079",
    "end": "651839"
  },
  {
    "text": "actually a big question because",
    "start": "651839",
    "end": "654640"
  },
  {
    "text": "if you look at this actually the",
    "start": "654640",
    "end": "656160"
  },
  {
    "start": "655000",
    "end": "655000"
  },
  {
    "text": "situation is not always that great",
    "start": "656160",
    "end": "658959"
  },
  {
    "text": "so there is actually a high variability",
    "start": "658959",
    "end": "661680"
  },
  {
    "text": "so i really like this paper by jason",
    "start": "661680",
    "end": "664560"
  },
  {
    "text": "um which is called sentence encoders and",
    "start": "664560",
    "end": "668079"
  },
  {
    "text": "stilts",
    "start": "668079",
    "end": "669760"
  },
  {
    "text": "and in this paper they try like various",
    "start": "669760",
    "end": "672240"
  },
  {
    "text": "seeds",
    "start": "672240",
    "end": "672880"
  },
  {
    "text": "and values hyper parameter and you can",
    "start": "672880",
    "end": "674959"
  },
  {
    "text": "see that you have like",
    "start": "674959",
    "end": "676399"
  },
  {
    "text": "actually a high variance in the results",
    "start": "676399",
    "end": "679680"
  },
  {
    "text": "here these are all the tasks for the",
    "start": "679680",
    "end": "681600"
  },
  {
    "text": "group benchmark the glue benchmark",
    "start": "681600",
    "end": "684079"
  },
  {
    "text": "is a the benchmark comprising several",
    "start": "684079",
    "end": "687360"
  },
  {
    "text": "tasks",
    "start": "687360",
    "end": "688320"
  },
  {
    "text": "you have some tasks are like cola which",
    "start": "688320",
    "end": "690880"
  },
  {
    "text": "is linguistic acceptability test this is",
    "start": "690880",
    "end": "693279"
  },
  {
    "text": "a path phrase classification test this",
    "start": "693279",
    "end": "695600"
  },
  {
    "text": "is sentiment",
    "start": "695600",
    "end": "698480"
  },
  {
    "text": "yeah so you have many tasks and you can",
    "start": "699120",
    "end": "700720"
  },
  {
    "text": "see that the variance is actually quite",
    "start": "700720",
    "end": "702560"
  },
  {
    "text": "high",
    "start": "702560",
    "end": "703279"
  },
  {
    "text": "so sometimes for instance let's take",
    "start": "703279",
    "end": "705120"
  },
  {
    "text": "mnli",
    "start": "705120",
    "end": "706320"
  },
  {
    "text": "for some seed your model will just reach",
    "start": "706320",
    "end": "709600"
  },
  {
    "text": "bad accuracy like bad performances and",
    "start": "709600",
    "end": "712240"
  },
  {
    "text": "for another seed like another random",
    "start": "712240",
    "end": "714320"
  },
  {
    "text": "seed to initialize the classifier layer",
    "start": "714320",
    "end": "716240"
  },
  {
    "text": "on the top",
    "start": "716240",
    "end": "717519"
  },
  {
    "text": "um you will get far better far better",
    "start": "717519",
    "end": "719920"
  },
  {
    "text": "performances okay",
    "start": "719920",
    "end": "721200"
  },
  {
    "text": "so this is a little bit of a problem",
    "start": "721200",
    "end": "723519"
  },
  {
    "text": "because it means you can't really",
    "start": "723519",
    "end": "725760"
  },
  {
    "text": "fine tune just with one go and it",
    "start": "725760",
    "end": "728240"
  },
  {
    "text": "actually leads to",
    "start": "728240",
    "end": "729519"
  },
  {
    "text": "what happens um usually in um",
    "start": "729519",
    "end": "734399"
  },
  {
    "text": "in the literature which is that we do a",
    "start": "734399",
    "end": "736480"
  },
  {
    "text": "hyper parameter search",
    "start": "736480",
    "end": "738000"
  },
  {
    "text": "for fine tuning and here is one example",
    "start": "738000",
    "end": "740079"
  },
  {
    "text": "for roberto",
    "start": "740079",
    "end": "742839"
  },
  {
    "text": "um as you can see for the",
    "start": "742839",
    "end": "746000"
  },
  {
    "text": "for the wsc which is the winner grad",
    "start": "746000",
    "end": "749200"
  },
  {
    "text": "schema challenge for the winograd schema",
    "start": "749200",
    "end": "751519"
  },
  {
    "text": "challenge",
    "start": "751519",
    "end": "752720"
  },
  {
    "text": "um they did like",
    "start": "752720",
    "end": "755920"
  },
  {
    "text": "a scan over three learning rates three",
    "start": "755920",
    "end": "759120"
  },
  {
    "text": "bytes size",
    "start": "759120",
    "end": "760480"
  },
  {
    "text": "um four like total number of updates",
    "start": "760480",
    "end": "763839"
  },
  {
    "text": "and also the seeds so in the end they",
    "start": "763839",
    "end": "765680"
  },
  {
    "text": "got like a hundred",
    "start": "765680",
    "end": "766880"
  },
  {
    "text": "runs of for the hyper parameter search",
    "start": "766880",
    "end": "768959"
  },
  {
    "text": "so they just choose the seven best model",
    "start": "768959",
    "end": "770880"
  },
  {
    "text": "and assemble them",
    "start": "770880",
    "end": "772399"
  },
  {
    "text": "so this is actually uh not trivial to do",
    "start": "772399",
    "end": "775839"
  },
  {
    "text": "and this is why today i will show you",
    "start": "775839",
    "end": "777600"
  },
  {
    "text": "how to do that with ray this kind of",
    "start": "777600",
    "end": "779600"
  },
  {
    "text": "hyper parameter search okay",
    "start": "779600",
    "end": "782800"
  },
  {
    "text": "so let's talk a little bit about our",
    "start": "782800",
    "end": "784320"
  },
  {
    "text": "library before we we have a quick",
    "start": "784320",
    "end": "786399"
  },
  {
    "text": "hands-on",
    "start": "786399",
    "end": "787120"
  },
  {
    "text": "showing you how to use them a hugging",
    "start": "787120",
    "end": "790000"
  },
  {
    "start": "789000",
    "end": "789000"
  },
  {
    "text": "face",
    "start": "790000",
    "end": "790880"
  },
  {
    "text": "so what is hugging face doing hugging",
    "start": "790880",
    "end": "793839"
  },
  {
    "text": "face started with a conversational ai",
    "start": "793839",
    "end": "795920"
  },
  {
    "text": "project",
    "start": "795920",
    "end": "797839"
  },
  {
    "text": "and while we were developing this",
    "start": "797839",
    "end": "799200"
  },
  {
    "text": "conversational ai",
    "start": "799200",
    "end": "801279"
  },
  {
    "text": "product we started to open source some",
    "start": "801279",
    "end": "803760"
  },
  {
    "text": "tools we've built for transfer learning",
    "start": "803760",
    "end": "805839"
  },
  {
    "text": "and actually these tools they got really",
    "start": "805839",
    "end": "807680"
  },
  {
    "text": "a lot of interest in the community",
    "start": "807680",
    "end": "809760"
  },
  {
    "text": "so we now have uh decided to focus on",
    "start": "809760",
    "end": "812079"
  },
  {
    "text": "this and to make our goal",
    "start": "812079",
    "end": "814160"
  },
  {
    "text": "to accelerate and catalyze and",
    "start": "814160",
    "end": "816240"
  },
  {
    "text": "democratize the research level work",
    "start": "816240",
    "end": "818079"
  },
  {
    "text": "that's happening in nrp",
    "start": "818079",
    "end": "820160"
  },
  {
    "text": "it's in a language understanding but",
    "start": "820160",
    "end": "822800"
  },
  {
    "text": "it's also in natural language generation",
    "start": "822800",
    "end": "826079"
  },
  {
    "text": "and we do that by open sourcing library",
    "start": "826079",
    "end": "828399"
  },
  {
    "text": "mostly",
    "start": "828399",
    "end": "830720"
  },
  {
    "text": "our first library that you probably know",
    "start": "830720",
    "end": "832959"
  },
  {
    "text": "is called the transformer library you",
    "start": "832959",
    "end": "834560"
  },
  {
    "text": "probably know it if you're working in",
    "start": "834560",
    "end": "835920"
  },
  {
    "text": "nlp it's designed to be like super easy",
    "start": "835920",
    "end": "838720"
  },
  {
    "text": "and super fast way to access",
    "start": "838720",
    "end": "840160"
  },
  {
    "text": "state-of-the-art nlp model as they are",
    "start": "840160",
    "end": "842320"
  },
  {
    "text": "like published and",
    "start": "842320",
    "end": "843600"
  },
  {
    "text": "open sourced by researcher the idea is",
    "start": "843600",
    "end": "846480"
  },
  {
    "text": "that",
    "start": "846480",
    "end": "847120"
  },
  {
    "text": "you should be able to like reuse a bot",
    "start": "847120",
    "end": "849199"
  },
  {
    "text": "without having to train it from scratch",
    "start": "849199",
    "end": "851040"
  },
  {
    "text": "because the training is superior super",
    "start": "851040",
    "end": "853440"
  },
  {
    "text": "computationally intensive it's available",
    "start": "853440",
    "end": "856959"
  },
  {
    "text": "for both tensorflow and pytorch",
    "start": "856959",
    "end": "860000"
  },
  {
    "text": "so um it's",
    "start": "860000",
    "end": "863760"
  },
  {
    "text": "right now we have like 24 models but",
    "start": "863760",
    "end": "866639"
  },
  {
    "text": "it's growing",
    "start": "866639",
    "end": "867839"
  },
  {
    "text": "quite quickly so we started with bert",
    "start": "867839",
    "end": "870079"
  },
  {
    "text": "and the gpt series",
    "start": "870079",
    "end": "871440"
  },
  {
    "text": "and now they're also a bunch of encoder",
    "start": "871440",
    "end": "873680"
  },
  {
    "text": "decoder models like bart",
    "start": "873680",
    "end": "876000"
  },
  {
    "text": "uh like efficient model like electro",
    "start": "876000",
    "end": "879199"
  },
  {
    "text": "dialogue model like sparse attention",
    "start": "879199",
    "end": "881600"
  },
  {
    "text": "model like reformer or long former",
    "start": "881600",
    "end": "884160"
  },
  {
    "text": "and we also have non-parametric models",
    "start": "884160",
    "end": "886079"
  },
  {
    "text": "like dpr",
    "start": "886079",
    "end": "887440"
  },
  {
    "text": "so it's really uh quite active",
    "start": "887440",
    "end": "891120"
  },
  {
    "start": "891000",
    "end": "891000"
  },
  {
    "text": "you can use it very simply as i told you",
    "start": "891199",
    "end": "893279"
  },
  {
    "text": "you just uh like",
    "start": "893279",
    "end": "894720"
  },
  {
    "text": "have a bunch of you have a bunch of",
    "start": "894720",
    "end": "896720"
  },
  {
    "text": "class like model tokenizer",
    "start": "896720",
    "end": "898720"
  },
  {
    "text": "and configuration class and with this",
    "start": "898720",
    "end": "900560"
  },
  {
    "text": "you can do pretty much everything",
    "start": "900560",
    "end": "902320"
  },
  {
    "text": "you have this form free training method",
    "start": "902320",
    "end": "903920"
  },
  {
    "text": "that will load the pre-trained weights",
    "start": "903920",
    "end": "905760"
  },
  {
    "text": "and the vocabulary from from from our",
    "start": "905760",
    "end": "909120"
  },
  {
    "text": "model hub",
    "start": "909120",
    "end": "910000"
  },
  {
    "text": "and then you can run the model very very",
    "start": "910000",
    "end": "912000"
  },
  {
    "text": "easily",
    "start": "912000",
    "end": "914320"
  },
  {
    "text": "you can check it out here here is a",
    "start": "914320",
    "end": "916480"
  },
  {
    "start": "916000",
    "end": "916000"
  },
  {
    "text": "model here but there is like over 2 000",
    "start": "916480",
    "end": "918720"
  },
  {
    "text": "models accessible in like",
    "start": "918720",
    "end": "920560"
  },
  {
    "text": "many many languages you have like a",
    "start": "920560",
    "end": "923279"
  },
  {
    "text": "hosted inference api where you can try",
    "start": "923279",
    "end": "925440"
  },
  {
    "text": "the model",
    "start": "925440",
    "end": "926079"
  },
  {
    "text": "online and if you upload a new model you",
    "start": "926079",
    "end": "928959"
  },
  {
    "text": "can also add your own model a lot of",
    "start": "928959",
    "end": "930560"
  },
  {
    "text": "these are",
    "start": "930560",
    "end": "931360"
  },
  {
    "text": "a community provided are",
    "start": "931360",
    "end": "934480"
  },
  {
    "text": "shared by the community and you can play",
    "start": "934480",
    "end": "936880"
  },
  {
    "text": "with the models online to try to test",
    "start": "936880",
    "end": "938880"
  },
  {
    "text": "them a little bit as well",
    "start": "938880",
    "end": "941839"
  },
  {
    "start": "942000",
    "end": "942000"
  },
  {
    "text": "we also have our new tokenization",
    "start": "942320",
    "end": "944240"
  },
  {
    "text": "library which is there to make it",
    "start": "944240",
    "end": "946560"
  },
  {
    "text": "very fast to to run the models",
    "start": "946560",
    "end": "949839"
  },
  {
    "text": "um so yeah it can encode one gigabyte in",
    "start": "949839",
    "end": "954000"
  },
  {
    "text": "20 seconds",
    "start": "954000",
    "end": "955040"
  },
  {
    "text": "it's called tokenizers and you can",
    "start": "955040",
    "end": "957680"
  },
  {
    "text": "install it it's available for python",
    "start": "957680",
    "end": "960240"
  },
  {
    "text": "node.js and it's based it's actually the",
    "start": "960240",
    "end": "963440"
  },
  {
    "text": "the core language is in rest which is",
    "start": "963440",
    "end": "965279"
  },
  {
    "text": "super fast",
    "start": "965279",
    "end": "966880"
  },
  {
    "start": "966000",
    "end": "966000"
  },
  {
    "text": "and recently a few months ago we opened",
    "start": "966880",
    "end": "968880"
  },
  {
    "text": "sourced a new library called dataset",
    "start": "968880",
    "end": "970880"
  },
  {
    "text": "that was early the only name was nlp but",
    "start": "970880",
    "end": "973279"
  },
  {
    "text": "now it's actually more general than that",
    "start": "973279",
    "end": "974880"
  },
  {
    "text": "so it's called that set",
    "start": "974880",
    "end": "976320"
  },
  {
    "text": "and the idea of this library is to",
    "start": "976320",
    "end": "978079"
  },
  {
    "text": "provide the easy access to data",
    "start": "978079",
    "end": "980560"
  },
  {
    "text": "to data data sets and also data",
    "start": "980560",
    "end": "983519"
  },
  {
    "text": "processing",
    "start": "983519",
    "end": "984720"
  },
  {
    "text": "and to nlp matrix",
    "start": "984720",
    "end": "987759"
  },
  {
    "text": "okay so it kind of covers the full",
    "start": "987759",
    "end": "992000"
  },
  {
    "text": "pipeline of nlp processing right now um",
    "start": "992000",
    "end": "996480"
  },
  {
    "text": "it's a very lightweight library uh",
    "start": "996480",
    "end": "998320"
  },
  {
    "text": "giving you access to many public data",
    "start": "998320",
    "end": "1000320"
  },
  {
    "text": "sets in just one line",
    "start": "1000320",
    "end": "1001759"
  },
  {
    "text": "and you can add your new data set and",
    "start": "1001759",
    "end": "1003440"
  },
  {
    "text": "your new matrix as well",
    "start": "1003440",
    "end": "1005199"
  },
  {
    "text": "and it's made for like a wide variety of",
    "start": "1005199",
    "end": "1008000"
  },
  {
    "text": "framework it's it's built for for the",
    "start": "1008000",
    "end": "1010079"
  },
  {
    "text": "empire panthers",
    "start": "1010079",
    "end": "1011120"
  },
  {
    "text": "found us by torsten's flow uh it's very",
    "start": "1011120",
    "end": "1014480"
  },
  {
    "text": "very efficient on huge data set you can",
    "start": "1014480",
    "end": "1016639"
  },
  {
    "text": "load wikipedia the full wikipedia with",
    "start": "1016639",
    "end": "1018560"
  },
  {
    "text": "just nine gigabytes of ram",
    "start": "1018560",
    "end": "1021040"
  },
  {
    "text": "and you can also iterate like super fast",
    "start": "1021040",
    "end": "1023199"
  },
  {
    "text": "there is a lot of very fast stuff like",
    "start": "1023199",
    "end": "1024959"
  },
  {
    "text": "smart caching and it's",
    "start": "1024959",
    "end": "1026400"
  },
  {
    "text": "it's just very efficient",
    "start": "1026400",
    "end": "1029678"
  },
  {
    "start": "1029000",
    "end": "1029000"
  },
  {
    "text": "it's quite easy here is how you can",
    "start": "1029679",
    "end": "1031520"
  },
  {
    "text": "encode and process",
    "start": "1031520",
    "end": "1033360"
  },
  {
    "text": "uh glue data set for for training this",
    "start": "1033360",
    "end": "1036079"
  },
  {
    "text": "is the full pre-processing uh",
    "start": "1036079",
    "end": "1038319"
  },
  {
    "text": "script okay so you just load the data",
    "start": "1038319",
    "end": "1040400"
  },
  {
    "text": "set here this one you",
    "start": "1040400",
    "end": "1041600"
  },
  {
    "text": "just load the data set in in something",
    "start": "1041600",
    "end": "1043280"
  },
  {
    "text": "that is like a python container",
    "start": "1043280",
    "end": "1045438"
  },
  {
    "text": "like like a list basically it looks like",
    "start": "1045439",
    "end": "1047199"
  },
  {
    "text": "that then you can map some um",
    "start": "1047199",
    "end": "1049919"
  },
  {
    "text": "some processing uh function on this",
    "start": "1049919",
    "end": "1053760"
  },
  {
    "text": "so in our case we map the tokenizer to",
    "start": "1053760",
    "end": "1056799"
  },
  {
    "text": "to encode the the input then we select",
    "start": "1056799",
    "end": "1060320"
  },
  {
    "text": "which columns we will want to output and",
    "start": "1060320",
    "end": "1062480"
  },
  {
    "text": "to",
    "start": "1062480",
    "end": "1062880"
  },
  {
    "text": "to use in our pythage model and we can",
    "start": "1062880",
    "end": "1065600"
  },
  {
    "text": "just load that directly in a in a",
    "start": "1065600",
    "end": "1067679"
  },
  {
    "text": "practice data loader",
    "start": "1067679",
    "end": "1069039"
  },
  {
    "text": "and it will it works okay",
    "start": "1069039",
    "end": "1073200"
  },
  {
    "text": "you can check this out at your face",
    "start": "1073919",
    "end": "1075919"
  },
  {
    "text": "datasets and we also have a dataset hub",
    "start": "1075919",
    "end": "1078320"
  },
  {
    "start": "1077000",
    "end": "1077000"
  },
  {
    "text": "where you can access all the data set",
    "start": "1078320",
    "end": "1079840"
  },
  {
    "text": "and you can actually explore them",
    "start": "1079840",
    "end": "1081679"
  },
  {
    "text": "on the online also check how they look",
    "start": "1081679",
    "end": "1084960"
  },
  {
    "text": "okay okay great now",
    "start": "1084960",
    "end": "1088400"
  },
  {
    "text": "um for the last minutes",
    "start": "1088400",
    "end": "1092640"
  },
  {
    "text": "let me show you um hands-on exercise",
    "start": "1092640",
    "end": "1097760"
  },
  {
    "text": "so here you have the links to the collab",
    "start": "1097760",
    "end": "1100000"
  },
  {
    "text": "and also a nice",
    "start": "1100000",
    "end": "1101280"
  },
  {
    "text": "medium blog post by um by the way team",
    "start": "1101280",
    "end": "1104400"
  },
  {
    "text": "showing how to do a little bit more than",
    "start": "1104400",
    "end": "1106240"
  },
  {
    "text": "what i show you today",
    "start": "1106240",
    "end": "1109600"
  },
  {
    "text": "okay um there we go",
    "start": "1109600",
    "end": "1113360"
  },
  {
    "text": "collab okay let's show you a bit how you",
    "start": "1113360",
    "end": "1116640"
  },
  {
    "text": "can use this tool so this is just",
    "start": "1116640",
    "end": "1118559"
  },
  {
    "text": "installing an lp here we have some",
    "start": "1118559",
    "end": "1121360"
  },
  {
    "text": "information on gpu nothing very",
    "start": "1121360",
    "end": "1123120"
  },
  {
    "text": "interesting here",
    "start": "1123120",
    "end": "1124400"
  },
  {
    "text": "and we install um well this this is now",
    "start": "1124400",
    "end": "1127440"
  },
  {
    "text": "called datasets but at the time i was",
    "start": "1127440",
    "end": "1129280"
  },
  {
    "text": "recording this library it was still",
    "start": "1129280",
    "end": "1130880"
  },
  {
    "text": "called this this video it was still",
    "start": "1130880",
    "end": "1132320"
  },
  {
    "text": "called nlp but just just",
    "start": "1132320",
    "end": "1135039"
  },
  {
    "text": "just put in your mind at that set",
    "start": "1135039",
    "end": "1136640"
  },
  {
    "text": "instead of an app",
    "start": "1136640",
    "end": "1138080"
  },
  {
    "text": "uh we install transformer we want to",
    "start": "1138080",
    "end": "1140160"
  },
  {
    "text": "train a model",
    "start": "1140160",
    "end": "1142080"
  },
  {
    "text": "and we will want to do a hyper parameter",
    "start": "1142080",
    "end": "1144080"
  },
  {
    "text": "search okay",
    "start": "1144080",
    "end": "1145760"
  },
  {
    "text": "so um we will do um",
    "start": "1145760",
    "end": "1150000"
  },
  {
    "text": "so we will do uh we will do use ray tune",
    "start": "1150000",
    "end": "1155440"
  },
  {
    "text": "okay let's go let's go very quickly",
    "start": "1156720",
    "end": "1160240"
  },
  {
    "text": "so we import nlp transformer we import",
    "start": "1160240",
    "end": "1163280"
  },
  {
    "text": "tune",
    "start": "1163280",
    "end": "1164080"
  },
  {
    "text": "and then we just load our tokenizer on",
    "start": "1164080",
    "end": "1166320"
  },
  {
    "text": "our data set and also the matrix so the",
    "start": "1166320",
    "end": "1168320"
  },
  {
    "text": "nice thing about the metric here is that",
    "start": "1168320",
    "end": "1170160"
  },
  {
    "text": "they're associated to benchmarks so",
    "start": "1170160",
    "end": "1172080"
  },
  {
    "text": "you're sure that you have the metric",
    "start": "1172080",
    "end": "1173440"
  },
  {
    "text": "that is actually relevant for those",
    "start": "1173440",
    "end": "1175440"
  },
  {
    "text": "for the subpart for instance glue has",
    "start": "1175440",
    "end": "1177919"
  },
  {
    "text": "several subsets here we",
    "start": "1177919",
    "end": "1179840"
  },
  {
    "text": "we look at the mrpc subset of blue the",
    "start": "1179840",
    "end": "1182480"
  },
  {
    "text": "glue benchmark and each subset have a",
    "start": "1182480",
    "end": "1184240"
  },
  {
    "text": "different matrix so here using load",
    "start": "1184240",
    "end": "1186080"
  },
  {
    "text": "metric you're sure you will have the",
    "start": "1186080",
    "end": "1187440"
  },
  {
    "text": "relevant metric for the subset you're",
    "start": "1187440",
    "end": "1189120"
  },
  {
    "text": "interested in",
    "start": "1189120",
    "end": "1192000"
  },
  {
    "text": "so here we downloaded that said the",
    "start": "1192000",
    "end": "1193440"
  },
  {
    "text": "metric the tokenizer as i told you the",
    "start": "1193440",
    "end": "1195840"
  },
  {
    "text": "data set is just a just a container so",
    "start": "1195840",
    "end": "1198160"
  },
  {
    "text": "you",
    "start": "1198160",
    "end": "1198559"
  },
  {
    "text": "you you have like several splits if you",
    "start": "1198559",
    "end": "1201039"
  },
  {
    "text": "print the dataset object you see we have",
    "start": "1201039",
    "end": "1202720"
  },
  {
    "text": "three splits in our you know",
    "start": "1202720",
    "end": "1204240"
  },
  {
    "text": "that set train test validation",
    "start": "1204240",
    "end": "1207280"
  },
  {
    "text": "and each split you can access the the",
    "start": "1207280",
    "end": "1209919"
  },
  {
    "text": "first element",
    "start": "1209919",
    "end": "1210799"
  },
  {
    "text": "for instance when you do that set train",
    "start": "1210799",
    "end": "1212559"
  },
  {
    "text": "0 and the first element is just a dict",
    "start": "1212559",
    "end": "1215120"
  },
  {
    "text": "a dictionary a python dictionary with",
    "start": "1215120",
    "end": "1217679"
  },
  {
    "text": "like the",
    "start": "1217679",
    "end": "1219600"
  },
  {
    "text": "with the feature of the data set so here",
    "start": "1219600",
    "end": "1221440"
  },
  {
    "text": "we have an index the label",
    "start": "1221440",
    "end": "1223200"
  },
  {
    "text": "and the two sentences and the feature",
    "start": "1223200",
    "end": "1225760"
  },
  {
    "text": "actually typed",
    "start": "1225760",
    "end": "1227039"
  },
  {
    "text": "so if you print dataset feature you can",
    "start": "1227039",
    "end": "1229520"
  },
  {
    "text": "have the type and you see that the",
    "start": "1229520",
    "end": "1231120"
  },
  {
    "text": "idx is just a integer the label is",
    "start": "1231120",
    "end": "1234159"
  },
  {
    "text": "actually",
    "start": "1234159",
    "end": "1234720"
  },
  {
    "text": "a label with two classes which are now",
    "start": "1234720",
    "end": "1237280"
  },
  {
    "text": "called not equivalent and equivalent",
    "start": "1237280",
    "end": "1239360"
  },
  {
    "text": "mrpc is a paraphrase classification task",
    "start": "1239360",
    "end": "1244880"
  },
  {
    "text": "so the paraphrase here means that the",
    "start": "1246320",
    "end": "1248240"
  },
  {
    "text": "two sentences are either equivalent or",
    "start": "1248240",
    "end": "1250240"
  },
  {
    "text": "not equivalent and then the two",
    "start": "1250240",
    "end": "1251679"
  },
  {
    "text": "sentences are just string",
    "start": "1251679",
    "end": "1253280"
  },
  {
    "text": "okay to tokenize the data set as we've",
    "start": "1253280",
    "end": "1256240"
  },
  {
    "text": "seen earlier you can define a function",
    "start": "1256240",
    "end": "1258400"
  },
  {
    "text": "here this will be the encode function",
    "start": "1258400",
    "end": "1260240"
  },
  {
    "text": "that will actually apply our tokenizer",
    "start": "1260240",
    "end": "1262640"
  },
  {
    "text": "on the first and the second sentence and",
    "start": "1262640",
    "end": "1265679"
  },
  {
    "text": "it will just return this and we just map",
    "start": "1265679",
    "end": "1267760"
  },
  {
    "text": "this function on the data set okay batch",
    "start": "1267760",
    "end": "1270400"
  },
  {
    "text": "at the gal true means that we we will",
    "start": "1270400",
    "end": "1272320"
  },
  {
    "text": "actually send batches",
    "start": "1272320",
    "end": "1273679"
  },
  {
    "text": "of string to the tokenizer and here we",
    "start": "1273679",
    "end": "1275919"
  },
  {
    "text": "can use the fact that some tokenizers",
    "start": "1275919",
    "end": "1277919"
  },
  {
    "text": "are very efficient on batches this is",
    "start": "1277919",
    "end": "1279760"
  },
  {
    "text": "just batch for format functions this is",
    "start": "1279760",
    "end": "1281919"
  },
  {
    "text": "not the batch of or for byte or string",
    "start": "1281919",
    "end": "1285600"
  },
  {
    "text": "now we need to rename a little bit",
    "start": "1285600",
    "end": "1287200"
  },
  {
    "text": "because the column label",
    "start": "1287200",
    "end": "1289120"
  },
  {
    "text": "in the transformer models they use a",
    "start": "1289120",
    "end": "1290799"
  },
  {
    "text": "column called they",
    "start": "1290799",
    "end": "1292400"
  },
  {
    "text": "they use an input called labels so we",
    "start": "1292400",
    "end": "1294559"
  },
  {
    "text": "rename this column label in labels",
    "start": "1294559",
    "end": "1296640"
  },
  {
    "text": "and we're ready we can give a look at",
    "start": "1296640",
    "end": "1298960"
  },
  {
    "text": "all that i said the feature i've changed",
    "start": "1298960",
    "end": "1300720"
  },
  {
    "text": "because we've added the",
    "start": "1300720",
    "end": "1302080"
  },
  {
    "text": "we've added the encoded features so now",
    "start": "1302080",
    "end": "1304080"
  },
  {
    "text": "we have the input ids",
    "start": "1304080",
    "end": "1305840"
  },
  {
    "text": "which is a sequence of uh of integers",
    "start": "1305840",
    "end": "1309120"
  },
  {
    "text": "we also have an attention mask which is",
    "start": "1309120",
    "end": "1311039"
  },
  {
    "text": "also integers and token type ids these",
    "start": "1311039",
    "end": "1313600"
  },
  {
    "text": "are like",
    "start": "1313600",
    "end": "1314080"
  },
  {
    "text": "things that birds want on the label and",
    "start": "1314080",
    "end": "1316480"
  },
  {
    "text": "are called labels okay and if we look at",
    "start": "1316480",
    "end": "1318640"
  },
  {
    "text": "the first",
    "start": "1318640",
    "end": "1319120"
  },
  {
    "text": "element of the training set you can see",
    "start": "1319120",
    "end": "1321760"
  },
  {
    "text": "our our ids here this will be the inputs",
    "start": "1321760",
    "end": "1324080"
  },
  {
    "text": "to our model",
    "start": "1324080",
    "end": "1324880"
  },
  {
    "text": "okay so we're ready now to to train one",
    "start": "1324880",
    "end": "1327360"
  },
  {
    "text": "thing is that",
    "start": "1327360",
    "end": "1328559"
  },
  {
    "text": "we don't really want to give our our",
    "start": "1328559",
    "end": "1330320"
  },
  {
    "text": "deep learning model these strings",
    "start": "1330320",
    "end": "1332400"
  },
  {
    "text": "okay we just want to give them the",
    "start": "1332400",
    "end": "1334159"
  },
  {
    "text": "integers so we'll actually filter the",
    "start": "1334159",
    "end": "1336480"
  },
  {
    "text": "columns",
    "start": "1336480",
    "end": "1337120"
  },
  {
    "text": "here this set format will means that if",
    "start": "1337120",
    "end": "1339679"
  },
  {
    "text": "we query",
    "start": "1339679",
    "end": "1340880"
  },
  {
    "text": "like an item in the data set we just get",
    "start": "1340880",
    "end": "1343840"
  },
  {
    "text": "this these columns here",
    "start": "1343840",
    "end": "1345280"
  },
  {
    "text": "i'll put it okay so here you can see",
    "start": "1345280",
    "end": "1347520"
  },
  {
    "text": "that once we've set the format to only",
    "start": "1347520",
    "end": "1349520"
  },
  {
    "text": "output the integral columns",
    "start": "1349520",
    "end": "1351120"
  },
  {
    "text": "you only get the integral columns here",
    "start": "1351120",
    "end": "1353280"
  },
  {
    "text": "okay",
    "start": "1353280",
    "end": "1354640"
  },
  {
    "text": "and now we can train our model the",
    "start": "1354640",
    "end": "1356240"
  },
  {
    "text": "training loop is very simple",
    "start": "1356240",
    "end": "1358080"
  },
  {
    "text": "we put the model in training mode set",
    "start": "1358080",
    "end": "1360000"
  },
  {
    "text": "him on the device",
    "start": "1360000",
    "end": "1361600"
  },
  {
    "text": "but they go made the out the batch go in",
    "start": "1361600",
    "end": "1364080"
  },
  {
    "text": "the model",
    "start": "1364080",
    "end": "1364640"
  },
  {
    "text": "then output then we do a little bit of",
    "start": "1364640",
    "end": "1366320"
  },
  {
    "text": "gradient accumulation step this helps us",
    "start": "1366320",
    "end": "1368400"
  },
  {
    "text": "using large batch on the single gpu",
    "start": "1368400",
    "end": "1370640"
  },
  {
    "text": "of colab and we do have an evaluation",
    "start": "1370640",
    "end": "1373120"
  },
  {
    "text": "using our matrix so",
    "start": "1373120",
    "end": "1374559"
  },
  {
    "text": "for each batch we'll add the batch of we",
    "start": "1374559",
    "end": "1377520"
  },
  {
    "text": "extract the prediction",
    "start": "1377520",
    "end": "1378960"
  },
  {
    "text": "we took the arg max which is the most",
    "start": "1378960",
    "end": "1380720"
  },
  {
    "text": "likely a class",
    "start": "1380720",
    "end": "1382720"
  },
  {
    "text": "predicted by a model and at the end when",
    "start": "1382720",
    "end": "1384960"
  },
  {
    "text": "we finish evaluation we just compute the",
    "start": "1384960",
    "end": "1386840"
  },
  {
    "text": "metric",
    "start": "1386840",
    "end": "1388320"
  },
  {
    "text": "and we can add a little uh training",
    "start": "1388320",
    "end": "1390320"
  },
  {
    "text": "function that will do a",
    "start": "1390320",
    "end": "1392000"
  },
  {
    "text": "hyper parameter search research over the",
    "start": "1392000",
    "end": "1394480"
  },
  {
    "text": "learning rate",
    "start": "1394480",
    "end": "1395360"
  },
  {
    "text": "number of epoch the bias the c the batch",
    "start": "1395360",
    "end": "1397440"
  },
  {
    "text": "size the schedule so a lot of things",
    "start": "1397440",
    "end": "1399840"
  },
  {
    "text": "if the batch is too big we use gradient",
    "start": "1399840",
    "end": "1401679"
  },
  {
    "text": "accumulation",
    "start": "1401679",
    "end": "1403039"
  },
  {
    "text": "and using our seed we can build the",
    "start": "1403039",
    "end": "1404960"
  },
  {
    "text": "model the train data loader",
    "start": "1404960",
    "end": "1407039"
  },
  {
    "text": "the optimizer and for the number of",
    "start": "1407039",
    "end": "1409200"
  },
  {
    "text": "epochs we've decided to train our model",
    "start": "1409200",
    "end": "1411360"
  },
  {
    "text": "we train our model",
    "start": "1411360",
    "end": "1412640"
  },
  {
    "text": "and we can do pruning based on",
    "start": "1412640",
    "end": "1414720"
  },
  {
    "text": "intermediate values",
    "start": "1414720",
    "end": "1416400"
  },
  {
    "text": "so if at the end of the first epoch like",
    "start": "1416400",
    "end": "1419360"
  },
  {
    "text": "our evaluation matrix are too bad",
    "start": "1419360",
    "end": "1421440"
  },
  {
    "text": "we just stop it and then we run with",
    "start": "1421440",
    "end": "1423919"
  },
  {
    "text": "bert as you can see it's pretty easy we",
    "start": "1423919",
    "end": "1425760"
  },
  {
    "text": "use one scheduler",
    "start": "1425760",
    "end": "1427440"
  },
  {
    "text": "and we use the okay",
    "start": "1427440",
    "end": "1430799"
  },
  {
    "text": "yeah here are our metrics like the",
    "start": "1430799",
    "end": "1433360"
  },
  {
    "text": "matrix we're tracking with",
    "start": "1433360",
    "end": "1434799"
  },
  {
    "text": "with tune and when we run it",
    "start": "1434799",
    "end": "1438480"
  },
  {
    "text": "you get like a lot of testers",
    "start": "1438480",
    "end": "1441520"
  },
  {
    "text": "and you found the best config which is",
    "start": "1441520",
    "end": "1444080"
  },
  {
    "text": "with this kind of learning rate through",
    "start": "1444080",
    "end": "1445600"
  },
  {
    "text": "epoch",
    "start": "1445600",
    "end": "1446400"
  },
  {
    "text": "like this seeds and bad size like this",
    "start": "1446400",
    "end": "1450880"
  },
  {
    "text": "and here is the output let's see yeah",
    "start": "1450880",
    "end": "1455360"
  },
  {
    "text": "we can run it again to get the",
    "start": "1455360",
    "end": "1457200"
  },
  {
    "text": "evaluation and here is the accuracy we",
    "start": "1457200",
    "end": "1459760"
  },
  {
    "text": "get",
    "start": "1459760",
    "end": "1460240"
  },
  {
    "text": "at the end which is a 0.86 accuracy",
    "start": "1460240",
    "end": "1464880"
  },
  {
    "text": "and an f1 of 0.90 so you can check on",
    "start": "1464880",
    "end": "1468240"
  },
  {
    "text": "glue mr pc this is actually a very good",
    "start": "1468240",
    "end": "1471039"
  },
  {
    "text": "result and this is kind of like the",
    "start": "1471039",
    "end": "1472559"
  },
  {
    "text": "state of the art okay",
    "start": "1472559",
    "end": "1474159"
  },
  {
    "text": "so as you can see this was like really",
    "start": "1474159",
    "end": "1476559"
  },
  {
    "text": "simple to do",
    "start": "1476559",
    "end": "1479520"
  },
  {
    "text": "and i hope you enjoyed this talk",
    "start": "1480240",
    "end": "1484960"
  }
]
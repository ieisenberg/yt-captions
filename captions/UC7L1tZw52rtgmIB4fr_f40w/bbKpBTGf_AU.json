[
  {
    "text": "yeah I am a software engineer at nkill working on recording uh I maintain the CU project and contribut to some uh R",
    "start": "2879",
    "end": "11080"
  },
  {
    "text": "core components including the r compile graph for especially for distribut training and some traditional record",
    "start": "11080",
    "end": "18680"
  },
  {
    "text": "stuff uh Andrew would you mind introducing yourself yeah I'm I'm Andrew S Kim I'm a software engineer at Google",
    "start": "18680",
    "end": "24680"
  },
  {
    "text": "working on gke I help maintain CRA with kaon and have been uh working on the kubernetes project since",
    "start": "24680",
    "end": "31719"
  },
  {
    "text": "2017 cool yeah uh this is today's agenda uh",
    "start": "31719",
    "end": "37280"
  },
  {
    "text": "today we will cover the core components of the cubra including the r cluster Ray",
    "start": "37280",
    "end": "42760"
  },
  {
    "text": "draw and the ray service apis then uh we will dive into white cubra is a good",
    "start": "42760",
    "end": "48879"
  },
  {
    "text": "choice for the generative AI after that we will talk about the new features",
    "start": "48879",
    "end": "54120"
  },
  {
    "text": "added in the past year and the RO map for the year ahead uh finally we will",
    "start": "54120",
    "end": "60440"
  },
  {
    "text": "talk about the collaboration between the Upstream kubernetes community and the Ray and the cube Community there are",
    "start": "60440",
    "end": "67280"
  },
  {
    "text": "some intensement to to better support the rate and the cube Ray on the",
    "start": "67280",
    "end": "73520"
  },
  {
    "text": "kubernetes yeah first of all we need to understand what is cubra uh and the role is placed in the",
    "start": "73960",
    "end": "81119"
  },
  {
    "text": "ray ecosystem uh first uh we need to know what is Rec cor Rec cor provides",
    "start": "81119",
    "end": "86560"
  },
  {
    "text": "three distributed apis including the uh rate Tas reactor and the r object and",
    "start": "86560",
    "end": "94720"
  },
  {
    "text": "it is mapping to the mapping to the functions classes and the variables in the single red programing",
    "start": "94720",
    "end": "101880"
  },
  {
    "text": "model then uh the r Community builds several AI libraries Bas on the rore API",
    "start": "101880",
    "end": "107640"
  },
  {
    "text": "including the ray data Ray train R IP and the r serve and it covers the end to",
    "start": "107640",
    "end": "112799"
  },
  {
    "text": "end life cycle of the model from data processing trending to uh tuning and",
    "start": "112799",
    "end": "118600"
  },
  {
    "text": "serving uh in addition the ray Community also offers two different deployment",
    "start": "118600",
    "end": "123880"
  },
  {
    "text": "solutions for the ray for to help the user to productionize Ray the first one",
    "start": "123880",
    "end": "130800"
  },
  {
    "text": "is for the virtual machines you can deploy Ray unlike the ec2 or GC on the",
    "start": "130800",
    "end": "136040"
  },
  {
    "text": "Public House in addition you can also deploy the r and kubernetes and the cuber is the official",
    "start": "136040",
    "end": "143080"
  },
  {
    "text": "solution for the r and kubernetes and it help it is the goto option for the Ray",
    "start": "143080",
    "end": "150599"
  },
  {
    "text": "open source user to protction rays and the CU match the life cycle of Ray CER",
    "start": "150599",
    "end": "156560"
  },
  {
    "text": "and the associates Ray application and kubernetes and if you are familiar with",
    "start": "156560",
    "end": "162519"
  },
  {
    "text": "the kubernetes concepts uh CU is a ray kubernetes",
    "start": "162519",
    "end": "168239"
  },
  {
    "text": "operator yeah uh and why I say lot the CU is the go-to option for uh for open",
    "start": "171360",
    "end": "178720"
  },
  {
    "text": "source rare users uh I think cubr allows the different",
    "start": "178720",
    "end": "184599"
  },
  {
    "text": "type of users to focus on what they do the best uh for the ML and data",
    "start": "184599",
    "end": "191159"
  },
  {
    "text": "scientist uh cubr allows them to focus on like the computation experiments and",
    "start": "191159",
    "end": "198879"
  },
  {
    "text": "uh uh prototyping and the writing the r Python scripts and the modeling and for",
    "start": "198879",
    "end": "204360"
  },
  {
    "text": "the infra and the pform engineers uh they can focus on to integrate cu with kubernetes ecosystem",
    "start": "204360",
    "end": "211799"
  },
  {
    "text": "such as pissu Gana NX e and more yeah so it's just separate the differ users and",
    "start": "211799",
    "end": "219159"
  },
  {
    "text": "focus on what do they do best and for Their scientist they don't need to worry about the kuet",
    "start": "219159",
    "end": "226360"
  },
  {
    "text": "concepts yeah and there are six key numbers for cubra from the three",
    "start": "226760",
    "end": "232640"
  },
  {
    "text": "different perspectives I think the first p is the community uh they are over",
    "start": "232640",
    "end": "238400"
  },
  {
    "text": "1,000 communs uh in the Cuba reposer and more than 140 contributors on the",
    "start": "238400",
    "end": "245040"
  },
  {
    "text": "reposer uh the second the second pers is the adoption uh CU has already helped uh",
    "start": "245040",
    "end": "252680"
  },
  {
    "text": "hundreds of organization to productionize R and kubernetes in addition there are more",
    "start": "252680",
    "end": "258880"
  },
  {
    "text": "than 50 BLS and talks about Cay and uh finally uh I think cubra is",
    "start": "258880",
    "end": "265639"
  },
  {
    "text": "production ready uh in our public Benchmark you can find in in the GTH reposer uh we Benchmark a single Cube",
    "start": "265639",
    "end": "273120"
  },
  {
    "text": "operator part with more than uh 10,000 R cluster custom resource and the r",
    "start": "273120",
    "end": "279639"
  },
  {
    "text": "drops um and uh and we can also support like the more than",
    "start": "279639",
    "end": "284680"
  },
  {
    "text": "40,000 uh pass yeah and I think it can be more but if this is current scale",
    "start": "284680",
    "end": "290000"
  },
  {
    "text": "that we do a benchmark yeah and I think next Andrew",
    "start": "290000",
    "end": "295160"
  },
  {
    "text": "will talk about why R and kubernets is a way to go yeah and I I think was covered",
    "start": "295160",
    "end": "300240"
  },
  {
    "text": "quite a bit um in the Keynotes as well um people are choosing to run rayon kubernetes because it provides a stable",
    "start": "300240",
    "end": "306520"
  },
  {
    "text": "reliable highly compute highly scalable compute platform for Ray it's a very mature platform at this point with a",
    "start": "306520",
    "end": "312919"
  },
  {
    "text": "vibrant ecosystem of adjacent tools that you can use to get ray running in production um rayon kubernetes is also",
    "start": "312919",
    "end": "320680"
  },
  {
    "text": "uh very popular choice if you want to collocate your ray clusters on an unified compute platform with your other",
    "start": "320680",
    "end": "326560"
  },
  {
    "text": "workloads and you also care about the portability of your um Ray applications across clouds and then lastly kubernetes",
    "start": "326560",
    "end": "333800"
  },
  {
    "text": "itself is evolving um it is impacted by a lot of the growth and demand for AI and M and so kubernetes is becoming",
    "start": "333800",
    "end": "340120"
  },
  {
    "text": "increasingly better at orchestrating machine learning workloads um so yeah let's just do like",
    "start": "340120",
    "end": "345880"
  },
  {
    "text": "a quick intro of Cu for folks that um might be new to CU um CU basically",
    "start": "345880",
    "end": "351280"
  },
  {
    "text": "provides three custom resources the first custom resource supported by CU is Ray cluster Ray cluster is the bread and",
    "start": "351280",
    "end": "357080"
  },
  {
    "text": "butter of Cu and is used to manage and scale Ray clusters that are backed by kubernetes pods the ray cluster resource",
    "start": "357080",
    "end": "363880"
  },
  {
    "text": "contains configuration of the ray head pod and supports specifying multiple worker groups of varying replicas it",
    "start": "363880",
    "end": "370680"
  },
  {
    "text": "also supports more advanced capabilities such as okay um such as um integration with",
    "start": "370680",
    "end": "377680"
  },
  {
    "text": "the Ray autoscaler and configuration of GCS fa tolerance in general we find that Ray cluster is uh really ideal for",
    "start": "377680",
    "end": "385199"
  },
  {
    "text": "managing Ray clusters for prototyping development experimentation and provid in that remote execution environment for",
    "start": "385199",
    "end": "391560"
  },
  {
    "text": "data scientists and researchers when you want to scale out Ray jobs into larger production environments or run batch",
    "start": "391560",
    "end": "397759"
  },
  {
    "text": "workloads with Ray we generally recommend using um the ray job custom resource Ray job is an API that contains",
    "start": "397759",
    "end": "404120"
  },
  {
    "text": "the configuration of an ephemeral rate cluster and the execution of a single job and lastly we have uh Ray service",
    "start": "404120",
    "end": "411720"
  },
  {
    "text": "Ray service is basically a bundle of a ray serve application and AR Ray cluster and is ideal for online inference",
    "start": "411720",
    "end": "420000"
  },
  {
    "text": "uh so yeah let's cover some um use cases around generative AI that CU is um enabling",
    "start": "420000",
    "end": "426039"
  },
  {
    "text": "today um qra provides a platform that has endtoend support for generative AI",
    "start": "426039",
    "end": "432240"
  },
  {
    "text": "use cases from uh embedding generation for rag training and fine-tuning models",
    "start": "432240",
    "end": "437360"
  },
  {
    "text": "and production ready inference and it does this while providing a flexible and light platform that can meet the rapidly",
    "start": "437360",
    "end": "443400"
  },
  {
    "text": "rapidly changing needs of AI infrastructure uh some specific capabilities to highlight are Auto",
    "start": "443400",
    "end": "448759"
  },
  {
    "text": "scaling capabilities for online inference and support for heterogeneous Computer Resources that is often needed",
    "start": "448759",
    "end": "454319"
  },
  {
    "text": "for uh offline batch inference uh Cub is also great for training and fine tuning",
    "start": "454319",
    "end": "459759"
  },
  {
    "text": "models um because specifically because it can utilize kubernetes and its vibrant ecosystem to provide",
    "start": "459759",
    "end": "466360"
  },
  {
    "text": "supplementary features such as gang scheduling with Advanced schedulers like Q unicorn and volcano and distributed",
    "start": "466360",
    "end": "472440"
  },
  {
    "text": "Storage Solutions using vast ecosystem of CSI drivers so let's dive a little deeper into um these use cases so first",
    "start": "472440",
    "end": "480400"
  },
  {
    "text": "is uh batch inference where the most common example is generating embeddings with Ray data for rag the ray job API",
    "start": "480400",
    "end": "487039"
  },
  {
    "text": "from qra is great for this use case because it has flexible support for heterogeneous compute resources that is",
    "start": "487039",
    "end": "492479"
  },
  {
    "text": "important for different phases of the typical rag data pipeline so for example reading and parsing documents into",
    "start": "492479",
    "end": "499080"
  },
  {
    "text": "smaller chunks of text would be CPU intensive task and then encoding the text chunks and embeddings with the",
    "start": "499080",
    "end": "505159"
  },
  {
    "text": "model would be a GPU intensive task Q brace simplifies the deployment of",
    "start": "505159",
    "end": "510199"
  },
  {
    "text": "multiple worker groups requiring different resources into a single API it also supports automatic deletion of the",
    "start": "510199",
    "end": "516320"
  },
  {
    "text": "underlying rate cluster when the job is complete so it's ideal for large batch workloads that might run expensive gpus",
    "start": "516320",
    "end": "522320"
  },
  {
    "text": "for like short periods of time um qra is also a great option for",
    "start": "522320",
    "end": "528000"
  },
  {
    "text": "online inference and serving LMS on kubernetes for production ready inference cubr supports um the ray",
    "start": "528000",
    "end": "534160"
  },
  {
    "text": "service crd which is a bundle of a ray cluster and a serve config Ray service supports ha configuration of the ray",
    "start": "534160",
    "end": "540720"
  },
  {
    "text": "cluster uh zero downtime upgrades and in place updates for the ray serve application and its",
    "start": "540720",
    "end": "547440"
  },
  {
    "text": "configuration um using Ray service to deploy VM with Ray serve is kind of the most common example uh we're seeing",
    "start": "547440",
    "end": "554480"
  },
  {
    "text": "today um the example here highlights the ability to package the entire model deployment in a single manifest um the",
    "start": "554480",
    "end": "561600"
  },
  {
    "text": "ray serve config contains um application Level configuration for VM to dynamically configure things like tensor",
    "start": "561600",
    "end": "568800"
  },
  {
    "text": "parallelism pipeline parallelism and even the model ID because it'll download the model from hugging face by",
    "start": "568800",
    "end": "575160"
  },
  {
    "text": "default and then uh below it you would specify the actual pod template of the",
    "start": "575160",
    "end": "581040"
  },
  {
    "text": "ray cluster so you can specify like what type of gpus it'll run on what type of nodes how many workers you need how many",
    "start": "581040",
    "end": "586800"
  },
  {
    "text": "gpus per node and all the other um infrastructure needed to run the model uh and then next I'll hand it back",
    "start": "586800",
    "end": "593360"
  },
  {
    "text": "to kaon to talk about some of the new features we built with kebr yeah S Andrew",
    "start": "593360",
    "end": "599640"
  },
  {
    "text": "uh I think in the next few slides I will talk about briefly talk about the new feature added in the CU in the past",
    "start": "599640",
    "end": "606839"
  },
  {
    "text": "year yeah the first one is that as as Andrew mentioned I think heterogenous computation resource is very important",
    "start": "606839",
    "end": "613959"
  },
  {
    "text": "for the generative AI or close so with cubr re user can easily to deploy their",
    "start": "613959",
    "end": "619959"
  },
  {
    "text": "application on kubernetes uh with like a CPU gpus and TPU from Google and like a",
    "start": "619959",
    "end": "625480"
  },
  {
    "text": "neuron CHP from AWS yeah and the CU also supports the",
    "start": "625480",
    "end": "631480"
  },
  {
    "text": "multihost accelerators such as the multihost TP plus SI yeah a multihost TP",
    "start": "631480",
    "end": "637320"
  },
  {
    "text": "plus size is a no pool that made out of two or more tpn and each one connect",
    "start": "637320",
    "end": "643079"
  },
  {
    "text": "with a high speed interconnect uh it is especially useful for like the uh s",
    "start": "643079",
    "end": "649480"
  },
  {
    "text": "large langage model if you need to more than one machine and the other use case is like a Ser like a u m model with the",
    "start": "649480",
    "end": "658160"
  },
  {
    "text": "expert parison yeah so and the cubr array also support the Autos scaning capability for the",
    "start": "658160",
    "end": "666120"
  },
  {
    "text": "multihost uh TPU priz and I think this is the maybe the only and the most",
    "start": "666120",
    "end": "672480"
  },
  {
    "text": "flexible solution for multihost accelerator uh in the open source world yeah and this is a joint effort",
    "start": "672480",
    "end": "679440"
  },
  {
    "text": "between the four different teams the record CU and the Cub team from the N scale and GK and the TP team from the",
    "start": "679440",
    "end": "687760"
  },
  {
    "text": "Google yeah and the there are also some ability improvements uh for the CU brain",
    "start": "687760",
    "end": "694920"
  },
  {
    "text": "uh the first is the structure login uh currently the CU loging uh print look in",
    "start": "694920",
    "end": "700079"
  },
  {
    "text": "the Jon format and each look message with the contest information uh such as",
    "start": "700079",
    "end": "705519"
  },
  {
    "text": "the custom resource n and the n space and the reconcile ID so that it's easier to integrate with the third party Logan",
    "start": "705519",
    "end": "712399"
  },
  {
    "text": "solution yeah such as like a spawn Cloud wash something like that uh and then uh",
    "start": "712399",
    "end": "717839"
  },
  {
    "text": "Ruster also provide uh uh conditions API recently and it provide a better",
    "start": "717839",
    "end": "724360"
  },
  {
    "text": "affability to help the platform and infra engineer to more easily to build",
    "start": "724360",
    "end": "729959"
  },
  {
    "text": "their ml platform based on cubre and the third one is the kubernetes events uh cubre recently uh",
    "start": "729959",
    "end": "737199"
  },
  {
    "text": "to have a more organized use the kuber netics events API uh to provide Expos",
    "start": "737199",
    "end": "743199"
  },
  {
    "text": "important information between the interaction between a qra operator and the kubernetes API server",
    "start": "743199",
    "end": "751160"
  },
  {
    "text": "yeah uh for the long running R job uh I think we have heard about some of the",
    "start": "751920",
    "end": "757680"
  },
  {
    "text": "feedbacks from the our CU users let's than out the r drop API can be better in",
    "start": "757680",
    "end": "763199"
  },
  {
    "text": "the drop Val handling and the rri and I think this is especially useful for some",
    "start": "763199",
    "end": "769079"
  },
  {
    "text": "like the long running rate jobs such as the fine tuning of a model or model",
    "start": "769079",
    "end": "774320"
  },
  {
    "text": "training because it can fail due to many different reasons uh although some of the Library provides some some some lbel",
    "start": "774320",
    "end": "782199"
  },
  {
    "text": "of the photor but for some kind of the photor uh on the GCS something like that",
    "start": "782199",
    "end": "788160"
  },
  {
    "text": "is still not be able to recover so we introduce a new API about backo limits",
    "start": "788160",
    "end": "795160"
  },
  {
    "text": "it is pretty similar to the back of limit on the kubernetes J API and uh it will you can use it to configure the",
    "start": "795160",
    "end": "802480"
  },
  {
    "text": "number of retra attempt and each retry contains the uh Recreation of a rer and",
    "start": "802480",
    "end": "809279"
  },
  {
    "text": "to submit a re job again in addition as a part of this work we also uh publish",
    "start": "809279",
    "end": "816160"
  },
  {
    "text": "and valid day and introduce a guide that how to configure the CSI driver such as",
    "start": "816160",
    "end": "821639"
  },
  {
    "text": "the GCS fi to to store and restore checkpointing from the distributed",
    "start": "821639",
    "end": "829000"
  },
  {
    "text": "checkpointing yeah uh and next is that uh we also integrate with like a que to",
    "start": "829120",
    "end": "836360"
  },
  {
    "text": "support to unlock some advanced scheduling capabilities uh Q is a popular and",
    "start": "836360",
    "end": "843480"
  },
  {
    "text": "kubernetes Native uh schedu and uh today with with Q uh Q users can achieve the G",
    "start": "843480",
    "end": "852160"
  },
  {
    "text": "scheding or Pary scheding uh and I think it is especially",
    "start": "852160",
    "end": "857399"
  },
  {
    "text": "useful for larger team which want to achieve the multitenant in a single kuet cluster or want to share resources",
    "start": "857399",
    "end": "864120"
  },
  {
    "text": "between the different rers yeah and Andrew will about a road",
    "start": "864120",
    "end": "870000"
  },
  {
    "text": "map and some ongoing project for the c community thank",
    "start": "870000",
    "end": "875079"
  },
  {
    "text": "you um yeah so keep in mind um road map is subject to change and we're very interested to hear from all of you about",
    "start": "875079",
    "end": "881560"
  },
  {
    "text": "what you want to see uh from CU um so firstly we oh sorry uh we recently um",
    "start": "881560",
    "end": "887600"
  },
  {
    "text": "merged the ray enhancement proposal to introduce an authentication mechanism for Ray clusters by leveraging the same",
    "start": "887600",
    "end": "893680"
  },
  {
    "text": "kubernetes arbac that exists on every kubernetes cluster so the idea here is that you can use the same credentials",
    "start": "893680",
    "end": "900240"
  },
  {
    "text": "you use to access your kubernetes cluster to also access your R cluster and then cluster admins can use the same",
    "start": "900240",
    "end": "906320"
  },
  {
    "text": "arback policies to dictate what users in the kubernetes cluster can connect and access the ray cluster um we've seen",
    "start": "906320",
    "end": "912399"
  },
  {
    "text": "many users kind of rolling their own off system on with Ray and kubernetes so our goal is to provide a single unified",
    "start": "912399",
    "end": "919519"
  },
  {
    "text": "secure solution for Ray access control and really take advantage of the strong authentication system that is already",
    "start": "919519",
    "end": "925680"
  },
  {
    "text": "available within kubernetes um we also thinking about improving tooling around CU outside of",
    "start": "925680",
    "end": "932199"
  },
  {
    "text": "just the standard operator and the custom resources so one way we're approaching this is by developing a c",
    "start": "932199",
    "end": "937920"
  },
  {
    "text": "control plugin um so we we our main focus initially is around common workflows people do with qra so the",
    "start": "937920",
    "end": "945079"
  },
  {
    "text": "first is a session command which will automatically port forward your local ports on your laptop to remote rate",
    "start": "945079",
    "end": "950920"
  },
  {
    "text": "cluster ports this should be significantly simpler than having to find the service that Maps the ray head",
    "start": "950920",
    "end": "957839"
  },
  {
    "text": "pod and then knowing what ports to port for from your laptop so it's just kind of a simple you just need to know the name of your rid cluster and you just",
    "start": "957839",
    "end": "963920"
  },
  {
    "text": "run the command and it Port fors everything for you um secondly is um improving adding like a logs command so",
    "start": "963920",
    "end": "971680"
  },
  {
    "text": "um uh logs right now can be challenging because not all the useful logs you care about are actually put into the standard",
    "start": "971680",
    "end": "977480"
  },
  {
    "text": "output of containers and they're usually stored on some like on disk on array cluster on some random path that you",
    "start": "977480",
    "end": "983399"
  },
  {
    "text": "probably forget all the time so this command will basically uh ex uh copy all",
    "start": "983399",
    "end": "988720"
  },
  {
    "text": "the relevant logs from your remote rate cluster pull it into a local directory and then you can view the all the logs",
    "start": "988720",
    "end": "993959"
  },
  {
    "text": "locally on your laptop um so this plugin is Alpha status in qra 1",
    "start": "993959",
    "end": "1000360"
  },
  {
    "text": "1.2.2 um we've also heard feedback from users that they love the um ephemeral nature of uh Ray job and how qra",
    "start": "1000959",
    "end": "1008600"
  },
  {
    "text": "automatically handles the deletion of Ray clusters the problem with Ray job the biggest pain point is that you can't",
    "start": "1008600",
    "end": "1014519"
  },
  {
    "text": "use Ray job for local development uh Ray job assumes that your driver Cod your source code is available in the head pod",
    "start": "1014519",
    "end": "1021279"
  },
  {
    "text": "so commonly this is done by you know building your own Docker image or like mounting volumes or like if you want to",
    "start": "1021279",
    "end": "1026880"
  },
  {
    "text": "be really hacky you put your source code on a config map and then you mount the config map and so we want to develop a way for users to kind of reap the",
    "start": "1026880",
    "end": "1033360"
  },
  {
    "text": "benefits of of Ray job and make it friendly for local development um and allow you to kind of submit whatever",
    "start": "1033360",
    "end": "1039480"
  },
  {
    "text": "code you have locally um while not yeah without having to like build your own image or anything like that this feature",
    "start": "1039480",
    "end": "1046120"
  },
  {
    "text": "is kind of particularly hard to orchestrate because of the Emeral nature of the underlying Ray cluster but it is",
    "start": "1046120",
    "end": "1052080"
  },
  {
    "text": "going to be available as Alpha and 1.2.2 so please try it out and give us your feedback um next we think there's more",
    "start": "1052080",
    "end": "1059679"
  },
  {
    "text": "we could do in general to improve the overall reliability and scale of the race service custom resource so mainly",
    "start": "1059679",
    "end": "1066679"
  },
  {
    "text": "we want to explore deployment of multiple Ray clusters for Ray service so instead of specifying like you know how",
    "start": "1066679",
    "end": "1072200"
  },
  {
    "text": "many workers you want in your ray service you can say like I want a ray cluster of this size and I want n",
    "start": "1072200",
    "end": "1078120"
  },
  {
    "text": "replicas of this R cluster and so this is becoming increasingly important as models are getting larger people want to",
    "start": "1078120",
    "end": "1084280"
  },
  {
    "text": "run multi- Noe multi-gpu deployments of models and so you need to start thinking about scaling models on a per cluster",
    "start": "1084280",
    "end": "1090760"
  },
  {
    "text": "basis instead of um per worker basis but we also do want to improve the overall like up rolling upgrade policies and",
    "start": "1090760",
    "end": "1097360"
  },
  {
    "text": "reliability of of doing rolling upgrades for workers as well so we're kind of thinking about kind of two dimensions of",
    "start": "1097360",
    "end": "1102880"
  },
  {
    "text": "how to scale Race Service going forward um and lastly We are continuing to expand the EOS",
    "start": "1102880",
    "end": "1109280"
  },
  {
    "text": "integration uh with CU so the most recent example is the new integration with unicorn to for advanced scheduling",
    "start": "1109280",
    "end": "1114720"
  },
  {
    "text": "capabilities with CU and this will be available in cubra starting in uh",
    "start": "1114720",
    "end": "1119799"
  },
  {
    "text": "1.2.2 so next I want to talk about um uh how we're thinking about enhancing kubernetes foray so we are working very",
    "start": "1119799",
    "end": "1126400"
  },
  {
    "text": "closely with maintainers and leads of the kubernetes project to enhance kubernetes foray the first uh the latest",
    "start": "1126400",
    "end": "1134440"
  },
  {
    "text": "development that is drawing a lot of attention is the new Dr API c will unlock Advanced device management",
    "start": "1134440",
    "end": "1141480"
  },
  {
    "text": "capabilities such as GPU time sharing space sharing new auto new auto scaling capabilities and just better scheduling",
    "start": "1141480",
    "end": "1148120"
  },
  {
    "text": "in general because we're going to tell kubernetes like what type of gpus or what uh what specific parameters of the",
    "start": "1148120",
    "end": "1153600"
  },
  {
    "text": "GPU are available on every knowe so these apis are alpha status in one in 1.31 and these apis are rapidly evolving",
    "start": "1153600",
    "end": "1161960"
  },
  {
    "text": "kubernetes is really thinking hard about like how to adapt these apis to work well with all the use cases around like",
    "start": "1161960",
    "end": "1167559"
  },
  {
    "text": "generative Ai and and and whatnot um we're also exploring ways uh for the ray",
    "start": "1167559",
    "end": "1174320"
  },
  {
    "text": "scheduler and the kubernetes scheduler to kind of work better together in general right so one idea is we're",
    "start": "1174320",
    "end": "1179360"
  },
  {
    "text": "exploring is propagating topology information in kubernetes in down into R",
    "start": "1179360",
    "end": "1184440"
  },
  {
    "text": "clusters so that you can use all the native Ray apis and take advantage of",
    "start": "1184440",
    "end": "1189480"
  },
  {
    "text": "the topology we're scheduling kubernetes so this uh to make this integration more seamless we have to kind of explore",
    "start": "1189480",
    "end": "1195799"
  },
  {
    "text": "things like enhancing the cubit's downward API so that cubet can pass down into the raet uh different information",
    "start": "1195799",
    "end": "1202600"
  },
  {
    "text": "about its topology that it wouldn't know today um and lastly there's um ongoing",
    "start": "1202600",
    "end": "1208000"
  },
  {
    "text": "work to support in place vertical pod autoscaling um we think so today kubernetes uh",
    "start": "1208000",
    "end": "1214600"
  },
  {
    "text": "supports yeah so today kuber supports vertical po Auto scaling but is not in place so you have to restart the",
    "start": "1214600",
    "end": "1220280"
  },
  {
    "text": "container and like if you're restarting the container what's what's the point right um so this particular feature",
    "start": "1220280",
    "end": "1225799"
  },
  {
    "text": "actually really complex requires a lot of uh deep Tech technical um considerations but we think this in",
    "start": "1225799",
    "end": "1232159"
  },
  {
    "text": "particular will work nicely um with Ray and cubay due to the memory intensive nature of Ray and how disruptive out of",
    "start": "1232159",
    "end": "1239039"
  },
  {
    "text": "memory errors can be so with in place vertical po autoscaling cubla can kind of like expand the uh the SE group",
    "start": "1239039",
    "end": "1245559"
  },
  {
    "text": "memory dynamically without having to restart the raet and this will potentially also require some changes in",
    "start": "1245559",
    "end": "1250720"
  },
  {
    "text": "the Rait for it to kind of autod detect like what cgroups are available inside its container name space uh so yeah to",
    "start": "1250720",
    "end": "1257200"
  },
  {
    "text": "summarize um we think there's a lot of opportunities for Ray CU and the kubernetes equos system to all kind of work better together and we anticipate a",
    "start": "1257200",
    "end": "1263440"
  },
  {
    "text": "lot of um you know kubernetes enhancements and Ray enhancement kind of coming out in the next little",
    "start": "1263440",
    "end": "1268880"
  },
  {
    "text": "bit right yeah yeah and uh and I think uh finally",
    "start": "1268880",
    "end": "1275320"
  },
  {
    "text": "before the uh yeah I think this is the community information for the cuber yeah",
    "start": "1275320",
    "end": "1281600"
  },
  {
    "text": "and the first is that I want to use this chance to Big thanks to all the contributors who like a submit PRS",
    "start": "1281600",
    "end": "1287760"
  },
  {
    "text": "reporting issues and uh join in the discussion with us to make qra become better and they are the",
    "start": "1287760",
    "end": "1294120"
  },
  {
    "text": "G reposer and the stack Channel and the stack channel is always the best place",
    "start": "1294120",
    "end": "1299279"
  },
  {
    "text": "to keep in touch with us uh we will monitor the we will monitor the channel frequently and answer a question and",
    "start": "1299279",
    "end": "1306480"
  },
  {
    "text": "sometime we also schedule a lot of user interview with users to collect a feedback yeah so I had recommend",
    "start": "1306480",
    "end": "1313080"
  },
  {
    "text": "everyone to join the slack Channel yeah and lastly that uh we have a open source community calendar for both the Ray and",
    "start": "1313080",
    "end": "1320520"
  },
  {
    "text": "the cubre and they are sound like the ray contributor think Cup and the CU",
    "start": "1320520",
    "end": "1325640"
  },
  {
    "text": "contributor think cup and we sometime have learn some design d review yeah so if you are interesting uh you can join",
    "start": "1325640",
    "end": "1332159"
  },
  {
    "text": "lot and uh and join the r CRA",
    "start": "1332159",
    "end": "1337240"
  },
  {
    "text": "Community yeah and uh and thank you guys for listening and the last thing is that",
    "start": "1339440",
    "end": "1345200"
  },
  {
    "text": "uh we have a QR code uh there's a Google phone it's a very simple Google form uh to collect some feedback from the for",
    "start": "1345200",
    "end": "1352200"
  },
  {
    "text": "the CRA project and the last thing is that N scale is hiring and uh you can",
    "start": "1352200",
    "end": "1357520"
  },
  {
    "text": "send email to me or chat with me in person and my manager is also there so",
    "start": "1357520",
    "end": "1362720"
  },
  {
    "text": "right if you guys uh want to find a job you can reach out to me or reach out to my",
    "start": "1362720",
    "end": "1368039"
  },
  {
    "text": "manager yeah uh thank you guys and you can scan the QR code and then we can",
    "start": "1368039",
    "end": "1373279"
  },
  {
    "text": "start the QA session sounds good [Applause]",
    "start": "1373279",
    "end": "1384559"
  },
  {
    "text": "support so the question was if there's going to be support for Federation across multiple kuber clusters uh I",
    "start": "1391480",
    "end": "1397440"
  },
  {
    "text": "don't think we really thought about that yeah I think we don't yeah we don't take this kind of",
    "start": "1397440",
    "end": "1404320"
  },
  {
    "text": "situation into consideration for now yeah it's a good suggestion though if I I suggest F uh giving us that feedback",
    "start": "1404320",
    "end": "1410760"
  },
  {
    "text": "so we can start thinking about yeah and if you have any use cases I think we can consider it I think the main reason why",
    "start": "1410760",
    "end": "1416799"
  },
  {
    "text": "maybe we haven't thought about it is that we find um with CU like the ephemeral cluster pattern is like really popular and so when you're kind of",
    "start": "1416799",
    "end": "1423320"
  },
  {
    "text": "deploying multiple clusters like if the cluster shortlived you don't care too much about like the Federation aspect of",
    "start": "1423320",
    "end": "1428679"
  },
  {
    "text": "it but",
    "start": "1428679",
    "end": "1432480"
  },
  {
    "text": "okay good to know yeah you can just uh submit a feedback or yes you can reach",
    "start": "1446120",
    "end": "1451520"
  },
  {
    "text": "out to us on the stack yes thanks any",
    "start": "1451520",
    "end": "1457520"
  },
  {
    "text": "question uh yes I think so yes yes yeah I think I",
    "start": "1461400",
    "end": "1466559"
  },
  {
    "text": "think it will be aailable yes I think we that you can download the slides on the site",
    "start": "1466559",
    "end": "1472398"
  },
  {
    "text": "yeah uh you say for auto scaring oh the question is that is there any support",
    "start": "1474039",
    "end": "1479279"
  },
  {
    "text": "for the HPA uh I think this question is that uh because I think for the r nature",
    "start": "1479279",
    "end": "1485159"
  },
  {
    "text": "uh because r r that in the in the traditional kubernetes API it's it",
    "start": "1485159",
    "end": "1491039"
  },
  {
    "text": "assume that everyone everything is a microservice so like everything every part in the deployment they are all the",
    "start": "1491039",
    "end": "1497240"
  },
  {
    "text": "same so you can just Auto scale it based on the like a matrix of a memory usage",
    "start": "1497240",
    "end": "1503039"
  },
  {
    "text": "or like the CPU usage but I think for race that's a r distribute a single application across multile node so every",
    "start": "1503039",
    "end": "1510120"
  },
  {
    "text": "node run different part of this application so you need to have more information to scale up a application",
    "start": "1510120",
    "end": "1517039"
  },
  {
    "text": "and this is also why Ray is powerful because Ray can only scale up uh maybe a",
    "start": "1517039",
    "end": "1522559"
  },
  {
    "text": "part of your application to support uh to support a more workload so I think",
    "start": "1522559",
    "end": "1528320"
  },
  {
    "text": "think Ray currently don't uh I think maybe HPA doesn't work",
    "start": "1528320",
    "end": "1533960"
  },
  {
    "text": "very well on the on the ray application but Ray but Auto scatter but",
    "start": "1533960",
    "end": "1539559"
  },
  {
    "text": "Ray has its own Auto",
    "start": "1539559",
    "end": "1543000"
  },
  {
    "text": "scatter is that for auto scanning uh I think I think currently",
    "start": "1547240",
    "end": "1554039"
  },
  {
    "text": "not but I think it depends on the worklow for example like the reserve Reser the auto scalling for the register",
    "start": "1554039",
    "end": "1560480"
  },
  {
    "text": "repon it depends on like the number of the request that in a given period but I",
    "start": "1560480",
    "end": "1566159"
  },
  {
    "text": "think a different worklow have a different Autos scan strategy like rate data have their own Autos scan strategy",
    "start": "1566159",
    "end": "1572480"
  },
  {
    "text": "so I think oh okay got I think currently we",
    "start": "1572480",
    "end": "1579760"
  },
  {
    "text": "don't have uh we don't have a plan in my understanding but if you have any use",
    "start": "1579760",
    "end": "1585120"
  },
  {
    "text": "case I think it makes sense and I also heard about some user recently they just",
    "start": "1585120",
    "end": "1590720"
  },
  {
    "text": "build the Sor framework and you can submit SLA and the layer scheding will",
    "start": "1590720",
    "end": "1596279"
  },
  {
    "text": "consider the SLA and to try to optimiz to to maximize the the race of the SLA",
    "start": "1596279",
    "end": "1604080"
  },
  {
    "text": "yeah so and I think we are currently in discussion with this uh user so I think",
    "start": "1604080",
    "end": "1610200"
  },
  {
    "text": "it is possible but not currenty uh on on the page yeah thanks",
    "start": "1610200",
    "end": "1619158"
  },
  {
    "text": "yeah um I think we've seen quite a few uh quite oh yeah sorry the question was um what are what do we think about the",
    "start": "1629919",
    "end": "1636200"
  },
  {
    "text": "different available Advanced schedulers with with Q right uh personally I think I've seen the most success with Q",
    "start": "1636200",
    "end": "1641440"
  },
  {
    "text": "because Q is kind of the kubernetes Native job sched kind of works on most uh clusters um it also has quite a lot",
    "start": "1641440",
    "end": "1648520"
  },
  {
    "text": "of investment from Google like we're we're investing a lot of people working on Q and and making Q better um unicorn",
    "start": "1648520",
    "end": "1654520"
  },
  {
    "text": "was just merged so I don't expect a lot of people to have used it the Unicorn integration yet and I think from my",
    "start": "1654520",
    "end": "1662039"
  },
  {
    "text": "personal experience is that uh I'm not a user but I a maintainer of a project I",
    "start": "1662039",
    "end": "1668279"
  },
  {
    "text": "would say that uh because Q is that Q doesn't integrate with Q doesn't need to inject any Q specific package uh",
    "start": "1668279",
    "end": "1676399"
  },
  {
    "text": "anything in the in the qra project so everything that is a q q import on qra",
    "start": "1676399",
    "end": "1683919"
  },
  {
    "text": "dependency to support the uh to support the features so I think a q maybe",
    "start": "1683919",
    "end": "1690159"
  },
  {
    "text": "ecosystem will emerge fast because it's pretty friendly for the uh for the open",
    "start": "1690159",
    "end": "1695600"
  },
  {
    "text": "source maintenance yeah but I think for the the other one maybe is unicor the good thing for unicor is that you don't",
    "start": "1695600",
    "end": "1702000"
  },
  {
    "text": "need to install a crd I think some company doesn't allow to install crd so",
    "start": "1702000",
    "end": "1708120"
  },
  {
    "text": "I think unicorn is another friendly for the maintainance side and uh volcano is the most popular open source project",
    "start": "1708120",
    "end": "1714919"
  },
  {
    "text": "because it is maintained for a long time but it's required to import a volcano package in the CRA project and we also",
    "start": "1714919",
    "end": "1722960"
  },
  {
    "text": "need to uh create that some kind of crd so uh for the M for the other third",
    "start": "1722960",
    "end": "1729640"
  },
  {
    "text": "party open source maintenance side I think uh the Q will integration will",
    "start": "1729640",
    "end": "1734960"
  },
  {
    "text": "update iterator faster and then is the unicor and the volano but I am not",
    "start": "1734960",
    "end": "1741120"
  },
  {
    "text": "familiar with the difference between this three yeah from my yeah but I will say like all the advanced schedulers are",
    "start": "1741120",
    "end": "1747039"
  },
  {
    "text": "basically trying to solve the first thing is like gang scheduling right like the last thing you want is like you have like half your rid clusters running or",
    "start": "1747039",
    "end": "1753640"
  },
  {
    "text": "like half of the rate cluster provision and is running all these gpus and the other half is just like not scheduled yet they're they're all basically trying",
    "start": "1753640",
    "end": "1760159"
  },
  {
    "text": "to make gang scheduling like better so",
    "start": "1760159",
    "end": "1764960"
  },
  {
    "text": "yeah so the question was if there's um going to be more observability improvements to surface po eras you uh I",
    "start": "1783919",
    "end": "1790080"
  },
  {
    "text": "think currently we are still in still trying to discuss that but I think uh we",
    "start": "1790080",
    "end": "1795320"
  },
  {
    "text": "currently offer some like the interaction between between like a CU and a kuber server because kuber Ser",
    "start": "1795320",
    "end": "1801320"
  },
  {
    "text": "will do some like a checking like the uh some checking like the like a spec",
    "start": "1801320",
    "end": "1806880"
  },
  {
    "text": "something like that and then we will report the issue by like kubernetes event or the uh but I think for the part",
    "start": "1806880",
    "end": "1814519"
  },
  {
    "text": "side uh I think we still need to uh I think we will try to keep our Behavior consistent with the kuber",
    "start": "1814519",
    "end": "1821200"
  },
  {
    "text": "nettic uping API such as a replica Stat or deployment if it is exposed to this",
    "start": "1821200",
    "end": "1826559"
  },
  {
    "text": "kind of error message I think cubra will try to think with the repa",
    "start": "1826559",
    "end": "1832278"
  },
  {
    "text": "set I think we are almost the time yep I think we're over yeah I think we are almost mons of time and if you we will",
    "start": "1833120",
    "end": "1839760"
  },
  {
    "text": "stay here for a while or outside and uh you can reach out to us uh if you have any questions yeah thank you for",
    "start": "1839760",
    "end": "1848200"
  },
  {
    "text": "listening good job",
    "start": "1849200",
    "end": "1853398"
  }
]
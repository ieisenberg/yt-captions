[
  {
    "text": "hello everyone and thanks for tuning in",
    "start": "2800",
    "end": "4560"
  },
  {
    "text": "to listen to this talk",
    "start": "4560",
    "end": "5839"
  },
  {
    "text": "i hope everyone has had a great summer",
    "start": "5839",
    "end": "8000"
  },
  {
    "text": "experience so far",
    "start": "8000",
    "end": "9360"
  },
  {
    "text": "my name is alex coca and i work as a",
    "start": "9360",
    "end": "11280"
  },
  {
    "text": "research engineer for",
    "start": "11280",
    "end": "12799"
  },
  {
    "text": "selling io in london at selden we're",
    "start": "12799",
    "end": "15599"
  },
  {
    "text": "passionate about helping companies",
    "start": "15599",
    "end": "17440"
  },
  {
    "text": "bring their models to production with as",
    "start": "17440",
    "end": "20640"
  },
  {
    "text": "minimal effort as possible whilst also",
    "start": "20640",
    "end": "23519"
  },
  {
    "text": "giving stakeholders a range of tools",
    "start": "23519",
    "end": "25599"
  },
  {
    "text": "that they can",
    "start": "25599",
    "end": "26960"
  },
  {
    "text": "use to monitor their model performance",
    "start": "26960",
    "end": "29760"
  },
  {
    "text": "and to understand their models better",
    "start": "29760",
    "end": "32000"
  },
  {
    "text": "we think this is essential for the",
    "start": "32000",
    "end": "35520"
  },
  {
    "text": "safe and responsible deployment of ai in",
    "start": "35520",
    "end": "38559"
  },
  {
    "text": "the years to come",
    "start": "38559",
    "end": "39520"
  },
  {
    "text": "so part of our time is spent developing",
    "start": "39520",
    "end": "42879"
  },
  {
    "text": "an open source library for model",
    "start": "42879",
    "end": "44879"
  },
  {
    "text": "explanation called alibi explain",
    "start": "44879",
    "end": "47520"
  },
  {
    "text": "since most explanations are expensive to",
    "start": "47520",
    "end": "50399"
  },
  {
    "text": "compute",
    "start": "50399",
    "end": "51120"
  },
  {
    "text": "we needed a scalable and fast framework",
    "start": "51120",
    "end": "53840"
  },
  {
    "text": "for distributed computing to power our",
    "start": "53840",
    "end": "56079"
  },
  {
    "text": "library",
    "start": "56079",
    "end": "56640"
  },
  {
    "text": "so this is how we started working with",
    "start": "56640",
    "end": "58399"
  },
  {
    "text": "ray before i start i'd like to",
    "start": "58399",
    "end": "60559"
  },
  {
    "text": "acknowledge the contribution of my",
    "start": "60559",
    "end": "61920"
  },
  {
    "text": "colleague rafael for this work",
    "start": "61920",
    "end": "63680"
  },
  {
    "text": "as well as the support of cli alejandro",
    "start": "63680",
    "end": "66560"
  },
  {
    "text": "and the wider selden team",
    "start": "66560",
    "end": "68560"
  },
  {
    "text": "and digital ocean for providing the",
    "start": "68560",
    "end": "70880"
  },
  {
    "text": "computers to do this work",
    "start": "70880",
    "end": "72799"
  },
  {
    "text": "last but not least i'd like to",
    "start": "72799",
    "end": "74080"
  },
  {
    "text": "acknowledge the",
    "start": "74080",
    "end": "76159"
  },
  {
    "text": "insight and contribution of bill and ed",
    "start": "76159",
    "end": "79360"
  },
  {
    "text": "from any scale",
    "start": "79360",
    "end": "80720"
  },
  {
    "text": "so without any further ado i like to",
    "start": "80720",
    "end": "82720"
  },
  {
    "text": "delve into my presentation",
    "start": "82720",
    "end": "84240"
  },
  {
    "text": "and there's two parts to it first i'll",
    "start": "84240",
    "end": "86400"
  },
  {
    "text": "explain to you",
    "start": "86400",
    "end": "87280"
  },
  {
    "text": "what a black box model is how can we",
    "start": "87280",
    "end": "90560"
  },
  {
    "text": "explain it",
    "start": "90560",
    "end": "91280"
  },
  {
    "text": "and why is it necessary to distribute",
    "start": "91280",
    "end": "94799"
  },
  {
    "text": "the computation of model explanations",
    "start": "94799",
    "end": "97439"
  },
  {
    "text": "and second",
    "start": "97439",
    "end": "98640"
  },
  {
    "text": "i'll show you how i how one can leverage",
    "start": "98640",
    "end": "102320"
  },
  {
    "text": "ray in order to speed up the task",
    "start": "102320",
    "end": "105439"
  },
  {
    "text": "of explaining an entire data set and",
    "start": "105439",
    "end": "107920"
  },
  {
    "text": "briefly discuss what insights we can get",
    "start": "107920",
    "end": "110399"
  },
  {
    "text": "from it so what is a black box model",
    "start": "110399",
    "end": "115200"
  },
  {
    "text": "you can think of a black box model as a",
    "start": "115200",
    "end": "117360"
  },
  {
    "text": "complex function",
    "start": "117360",
    "end": "118640"
  },
  {
    "text": "whose operation on a given input is a",
    "start": "118640",
    "end": "121680"
  },
  {
    "text": "line",
    "start": "121680",
    "end": "122399"
  },
  {
    "text": "we can pass an input to it x",
    "start": "122399",
    "end": "126159"
  },
  {
    "text": "and we can read the top of y hat but we",
    "start": "126159",
    "end": "128479"
  },
  {
    "text": "usually don't",
    "start": "128479",
    "end": "129360"
  },
  {
    "text": "know anything about how x is transformed",
    "start": "129360",
    "end": "132160"
  },
  {
    "text": "into y hat",
    "start": "132160",
    "end": "133520"
  },
  {
    "text": "this is usually the case in production",
    "start": "133520",
    "end": "135200"
  },
  {
    "text": "where you have an api that you can query",
    "start": "135200",
    "end": "137280"
  },
  {
    "text": "with your data and you get a response",
    "start": "137280",
    "end": "140000"
  },
  {
    "text": "back",
    "start": "140000",
    "end": "140959"
  },
  {
    "text": "the input could be for example an",
    "start": "140959",
    "end": "142800"
  },
  {
    "text": "ultrasound image or",
    "start": "142800",
    "end": "144000"
  },
  {
    "text": "data about a mortgage applicant and the",
    "start": "144000",
    "end": "147040"
  },
  {
    "text": "output can",
    "start": "147040",
    "end": "147840"
  },
  {
    "text": "be a diagnosis or a decision on whether",
    "start": "147840",
    "end": "151280"
  },
  {
    "text": "to",
    "start": "151280",
    "end": "151920"
  },
  {
    "text": "allow a person to access a mortgage or",
    "start": "151920",
    "end": "155040"
  },
  {
    "text": "not",
    "start": "155040",
    "end": "156000"
  },
  {
    "text": "so in such critical situations would",
    "start": "156000",
    "end": "158080"
  },
  {
    "text": "really like to pry",
    "start": "158080",
    "end": "159440"
  },
  {
    "text": "these black boxes and understand the way",
    "start": "159440",
    "end": "162000"
  },
  {
    "text": "things understand how it makes decisions",
    "start": "162000",
    "end": "164720"
  },
  {
    "text": "so how can we do this what does it mean",
    "start": "164720",
    "end": "166720"
  },
  {
    "text": "to really explain or probe these black",
    "start": "166720",
    "end": "169120"
  },
  {
    "text": "boxes",
    "start": "169120",
    "end": "171040"
  },
  {
    "text": "so for example if we productionize",
    "start": "171040",
    "end": "174640"
  },
  {
    "text": "a cat classifier we might be interested",
    "start": "174640",
    "end": "177280"
  },
  {
    "text": "in finding",
    "start": "177280",
    "end": "178400"
  },
  {
    "text": "a subset of pixels that with high",
    "start": "178400",
    "end": "180959"
  },
  {
    "text": "probability",
    "start": "180959",
    "end": "182080"
  },
  {
    "text": "make or input a cat in the eyes of our",
    "start": "182080",
    "end": "184480"
  },
  {
    "text": "model",
    "start": "184480",
    "end": "185840"
  },
  {
    "text": "so the subset of pixels is known as an",
    "start": "185840",
    "end": "188239"
  },
  {
    "text": "anchor",
    "start": "188239",
    "end": "188959"
  },
  {
    "text": "and you can read more about this",
    "start": "188959",
    "end": "190319"
  },
  {
    "text": "algorithm in the paper cited or",
    "start": "190319",
    "end": "192239"
  },
  {
    "text": "our alibi documentation another way to",
    "start": "192239",
    "end": "195760"
  },
  {
    "text": "explain the model is to search for an",
    "start": "195760",
    "end": "197760"
  },
  {
    "text": "input that differs from our original",
    "start": "197760",
    "end": "200959"
  },
  {
    "text": "input",
    "start": "200959",
    "end": "201519"
  },
  {
    "text": "as little as possible yet yields a",
    "start": "201519",
    "end": "203920"
  },
  {
    "text": "desired prediction",
    "start": "203920",
    "end": "205599"
  },
  {
    "text": "as an example you can see on the left a",
    "start": "205599",
    "end": "208799"
  },
  {
    "text": "digit that was correctly classified by a",
    "start": "208799",
    "end": "211760"
  },
  {
    "text": "convolutional neural network",
    "start": "211760",
    "end": "213519"
  },
  {
    "text": "and on the right i'm showing that",
    "start": "213519",
    "end": "216000"
  },
  {
    "text": "changing that image",
    "start": "216000",
    "end": "217360"
  },
  {
    "text": "ever so slightly can lead the model to",
    "start": "217360",
    "end": "219920"
  },
  {
    "text": "predict its digit 5.",
    "start": "219920",
    "end": "221599"
  },
  {
    "text": "and this type of explanation is called",
    "start": "221599",
    "end": "223840"
  },
  {
    "text": "called a counterfactual",
    "start": "223840",
    "end": "227120"
  },
  {
    "text": "yet another way to do this is to",
    "start": "227120",
    "end": "228879"
  },
  {
    "text": "attribute the difference",
    "start": "228879",
    "end": "230720"
  },
  {
    "text": "between a model prediction and a base",
    "start": "230720",
    "end": "233360"
  },
  {
    "text": "value",
    "start": "233360",
    "end": "234560"
  },
  {
    "text": "for example the average prediction over",
    "start": "234560",
    "end": "237360"
  },
  {
    "text": "a data set",
    "start": "237360",
    "end": "238319"
  },
  {
    "text": "to some input picture of features so",
    "start": "238319",
    "end": "242000"
  },
  {
    "text": "for for example we have a classifier",
    "start": "242000",
    "end": "244640"
  },
  {
    "text": "that takes a person's",
    "start": "244640",
    "end": "246000"
  },
  {
    "text": "age body mass index blood pressure",
    "start": "246000",
    "end": "249680"
  },
  {
    "text": "and sex and outputs a mortality risk",
    "start": "249680",
    "end": "253760"
  },
  {
    "text": "for that person assume that a person was",
    "start": "253760",
    "end": "256160"
  },
  {
    "text": "predicted at",
    "start": "256160",
    "end": "257040"
  },
  {
    "text": "a risk of 0.4 when the average risk in",
    "start": "257040",
    "end": "260000"
  },
  {
    "text": "the population they're part of",
    "start": "260000",
    "end": "261919"
  },
  {
    "text": "is 0.1 so we'd like to understand the",
    "start": "261919",
    "end": "264400"
  },
  {
    "text": "0.3 difference",
    "start": "264400",
    "end": "265919"
  },
  {
    "text": "you can see on the slide that features",
    "start": "265919",
    "end": "268880"
  },
  {
    "text": "such as",
    "start": "268880",
    "end": "269600"
  },
  {
    "text": "age the blood pressure or the body mass",
    "start": "269600",
    "end": "271919"
  },
  {
    "text": "index",
    "start": "271919",
    "end": "272960"
  },
  {
    "text": "increase the risk of that person dying",
    "start": "272960",
    "end": "275919"
  },
  {
    "text": "whereas",
    "start": "275919",
    "end": "276400"
  },
  {
    "text": "the fact that the person is a female",
    "start": "276400",
    "end": "278479"
  },
  {
    "text": "actually decreases the risk",
    "start": "278479",
    "end": "280840"
  },
  {
    "text": "so unfortunately",
    "start": "280840",
    "end": "284080"
  },
  {
    "text": "computing these numbers is hard these",
    "start": "284080",
    "end": "287040"
  },
  {
    "text": "attributions",
    "start": "287040",
    "end": "288080"
  },
  {
    "text": "have exponential computational",
    "start": "288080",
    "end": "290479"
  },
  {
    "text": "complexity",
    "start": "290479",
    "end": "291600"
  },
  {
    "text": "so to give you a sense for why we need",
    "start": "291600",
    "end": "294000"
  },
  {
    "text": "to rate when we want to",
    "start": "294000",
    "end": "295600"
  },
  {
    "text": "compute a lot of these",
    "start": "295600",
    "end": "298639"
  },
  {
    "text": "model output explanations i'm going to",
    "start": "298639",
    "end": "300880"
  },
  {
    "text": "briefly digress",
    "start": "300880",
    "end": "302000"
  },
  {
    "text": "and explain to you how a shaft values is",
    "start": "302000",
    "end": "304479"
  },
  {
    "text": "computed",
    "start": "304479",
    "end": "305759"
  },
  {
    "text": "so meet alex the ceo of noodles.oi",
    "start": "305759",
    "end": "309440"
  },
  {
    "text": "it's the end of the quarter and it seems",
    "start": "309440",
    "end": "311039"
  },
  {
    "text": "they did pretty well",
    "start": "311039",
    "end": "312479"
  },
  {
    "text": "so he's super super grateful for his",
    "start": "312479",
    "end": "315360"
  },
  {
    "text": "employees hard work",
    "start": "315360",
    "end": "316720"
  },
  {
    "text": "and would like to share the profit in a",
    "start": "316720",
    "end": "319680"
  },
  {
    "text": "with everyone",
    "start": "319680",
    "end": "320560"
  },
  {
    "text": "in a fair manner proportional to their",
    "start": "320560",
    "end": "322880"
  },
  {
    "text": "contribution at a quarterly meeting",
    "start": "322880",
    "end": "325360"
  },
  {
    "text": "he presents the methodology that",
    "start": "325360",
    "end": "328639"
  },
  {
    "text": "is going to guide the bonus scheme going",
    "start": "328639",
    "end": "331440"
  },
  {
    "text": "forward",
    "start": "331440",
    "end": "333039"
  },
  {
    "text": "so he denounced by f the set of all the",
    "start": "333039",
    "end": "335840"
  },
  {
    "text": "employees in the country",
    "start": "335840",
    "end": "337199"
  },
  {
    "text": "in the company five in this case and",
    "start": "337199",
    "end": "340560"
  },
  {
    "text": "by two to the power of f all the teams",
    "start": "340560",
    "end": "344400"
  },
  {
    "text": "of any size that can be formed with his",
    "start": "344400",
    "end": "347039"
  },
  {
    "text": "five employees",
    "start": "347039",
    "end": "348479"
  },
  {
    "text": "so to calculate an employee's",
    "start": "348479",
    "end": "350479"
  },
  {
    "text": "contribution for example",
    "start": "350479",
    "end": "352160"
  },
  {
    "text": "abby's alex first makes",
    "start": "352160",
    "end": "355520"
  },
  {
    "text": "all teams that do not contain abby gets",
    "start": "355520",
    "end": "358240"
  },
  {
    "text": "them to work for a while",
    "start": "358240",
    "end": "360720"
  },
  {
    "text": "measures the profit assuming he has",
    "start": "360720",
    "end": "362319"
  },
  {
    "text": "enough time and this is all possible",
    "start": "362319",
    "end": "364319"
  },
  {
    "text": "and then adds abby back to every single",
    "start": "364319",
    "end": "367520"
  },
  {
    "text": "team and measures the profit again",
    "start": "367520",
    "end": "369600"
  },
  {
    "text": "he takes the difference averages",
    "start": "369600",
    "end": "371759"
  },
  {
    "text": "everything out",
    "start": "371759",
    "end": "372880"
  },
  {
    "text": "and this gives him an indication of how",
    "start": "372880",
    "end": "375680"
  },
  {
    "text": "abby has contributed",
    "start": "375680",
    "end": "377199"
  },
  {
    "text": "to the big money that they gathered this",
    "start": "377199",
    "end": "378960"
  },
  {
    "text": "quarter note",
    "start": "378960",
    "end": "380720"
  },
  {
    "text": "that this requires enumeration of all",
    "start": "380720",
    "end": "383600"
  },
  {
    "text": "possible teams of all sizes",
    "start": "383600",
    "end": "385680"
  },
  {
    "text": "and this is exponential in the number of",
    "start": "385680",
    "end": "387520"
  },
  {
    "text": "employees in the company",
    "start": "387520",
    "end": "388800"
  },
  {
    "text": "so therefore you may say well it only",
    "start": "388800",
    "end": "390639"
  },
  {
    "text": "works for startups",
    "start": "390639",
    "end": "392160"
  },
  {
    "text": "but the same methodology really is",
    "start": "392160",
    "end": "394400"
  },
  {
    "text": "applied for",
    "start": "394400",
    "end": "395759"
  },
  {
    "text": "uh attributing the difference between a",
    "start": "395759",
    "end": "398800"
  },
  {
    "text": "model output and a baseline value",
    "start": "398800",
    "end": "400960"
  },
  {
    "text": "to the set of input features of a",
    "start": "400960",
    "end": "402960"
  },
  {
    "text": "machine learning model",
    "start": "402960",
    "end": "404759"
  },
  {
    "text": "translating this equation to machine",
    "start": "404759",
    "end": "407280"
  },
  {
    "text": "learning language",
    "start": "407280",
    "end": "408560"
  },
  {
    "text": "the profit is just what our model",
    "start": "408560",
    "end": "410800"
  },
  {
    "text": "outputs",
    "start": "410800",
    "end": "411759"
  },
  {
    "text": "whereas the teams represent subsets of",
    "start": "411759",
    "end": "414800"
  },
  {
    "text": "input features",
    "start": "414800",
    "end": "416240"
  },
  {
    "text": "the problem is that we can't simply",
    "start": "416240",
    "end": "418000"
  },
  {
    "text": "exclude features",
    "start": "418000",
    "end": "420000"
  },
  {
    "text": "from the model input usually that just",
    "start": "420000",
    "end": "422319"
  },
  {
    "text": "breaks our code",
    "start": "422319",
    "end": "423520"
  },
  {
    "text": "so what we need to do is use an",
    "start": "423520",
    "end": "424960"
  },
  {
    "text": "auxiliary data set",
    "start": "424960",
    "end": "427280"
  },
  {
    "text": "so that we replace and estimate the",
    "start": "427280",
    "end": "430639"
  },
  {
    "text": "effect of missing features",
    "start": "430639",
    "end": "432319"
  },
  {
    "text": "so we already had to make an exponential",
    "start": "432319",
    "end": "435840"
  },
  {
    "text": "number of calls",
    "start": "435840",
    "end": "437199"
  },
  {
    "text": "to get um the model output",
    "start": "437199",
    "end": "441120"
  },
  {
    "text": "to con to calculate our values and but",
    "start": "441120",
    "end": "443280"
  },
  {
    "text": "we need to do actually even more than",
    "start": "443280",
    "end": "445120"
  },
  {
    "text": "that there's also a linear factor",
    "start": "445120",
    "end": "446560"
  },
  {
    "text": "involved",
    "start": "446560",
    "end": "447360"
  },
  {
    "text": "so once these methods to",
    "start": "447360",
    "end": "450479"
  },
  {
    "text": "approximate these quantities exist",
    "start": "450479",
    "end": "453520"
  },
  {
    "text": "they're still very expensive so",
    "start": "453520",
    "end": "455599"
  },
  {
    "text": "explaining a large",
    "start": "455599",
    "end": "457199"
  },
  {
    "text": "number of predictions is very expensive",
    "start": "457199",
    "end": "460720"
  },
  {
    "text": "on a single cpu",
    "start": "460720",
    "end": "462400"
  },
  {
    "text": "so how can we help us speed up let me",
    "start": "462400",
    "end": "465520"
  },
  {
    "text": "describe a practical task that we worked",
    "start": "465520",
    "end": "467520"
  },
  {
    "text": "on",
    "start": "467520",
    "end": "468639"
  },
  {
    "text": "so we took a simple model a logistic",
    "start": "468639",
    "end": "471360"
  },
  {
    "text": "regression on the adult data set",
    "start": "471360",
    "end": "473199"
  },
  {
    "text": "and proceeded to explain 200 5060",
    "start": "473199",
    "end": "477039"
  },
  {
    "text": "predictions from a test set",
    "start": "477039",
    "end": "478720"
  },
  {
    "text": "each prediction predicts whether an",
    "start": "478720",
    "end": "481120"
  },
  {
    "text": "individual",
    "start": "481120",
    "end": "481919"
  },
  {
    "text": "will make an income over fifty thousand",
    "start": "481919",
    "end": "484479"
  },
  {
    "text": "dollars",
    "start": "484479",
    "end": "485120"
  },
  {
    "text": "or not based on some data about them",
    "start": "485120",
    "end": "488400"
  },
  {
    "text": "we use the kernel shaft algorithm which",
    "start": "488400",
    "end": "490400"
  },
  {
    "text": "is a way to approximate",
    "start": "490400",
    "end": "492080"
  },
  {
    "text": "the shaft values that i've just",
    "start": "492080",
    "end": "494080"
  },
  {
    "text": "described it's an implementation by",
    "start": "494080",
    "end": "496080"
  },
  {
    "text": "scott lumberg and colleagues and we",
    "start": "496080",
    "end": "497680"
  },
  {
    "text": "built on the shaft library",
    "start": "497680",
    "end": "499759"
  },
  {
    "text": "note that each prediction is explained",
    "start": "499759",
    "end": "502479"
  },
  {
    "text": "independently of all others",
    "start": "502479",
    "end": "504400"
  },
  {
    "text": "so the problem really lends itself",
    "start": "504400",
    "end": "506479"
  },
  {
    "text": "nicely to parallelization",
    "start": "506479",
    "end": "508080"
  },
  {
    "text": "but running this test sequentially on a",
    "start": "508080",
    "end": "510400"
  },
  {
    "text": "single cpu",
    "start": "510400",
    "end": "511599"
  },
  {
    "text": "took us roughly half an hour and this is",
    "start": "511599",
    "end": "514080"
  },
  {
    "text": "even a simple task so we really wanted",
    "start": "514080",
    "end": "516320"
  },
  {
    "text": "to improve on it",
    "start": "516320",
    "end": "518320"
  },
  {
    "text": "so how do we implement this one thing we",
    "start": "518320",
    "end": "520880"
  },
  {
    "text": "really care in our",
    "start": "520880",
    "end": "522000"
  },
  {
    "text": "in our open source library is having",
    "start": "522000",
    "end": "524320"
  },
  {
    "text": "simple user interfaces",
    "start": "524320",
    "end": "526320"
  },
  {
    "text": "and this is what i particularly liked",
    "start": "526320",
    "end": "529279"
  },
  {
    "text": "about working with ray",
    "start": "529279",
    "end": "530720"
  },
  {
    "text": "it's simplicity in addition it's",
    "start": "530720",
    "end": "534000"
  },
  {
    "text": "actual computation model integrated",
    "start": "534000",
    "end": "536320"
  },
  {
    "text": "super nicely with our library as",
    "start": "536320",
    "end": "538080"
  },
  {
    "text": "offshore",
    "start": "538080",
    "end": "538959"
  },
  {
    "text": "so what we originally had in our library",
    "start": "538959",
    "end": "541040"
  },
  {
    "text": "was the kernel shop explainer",
    "start": "541040",
    "end": "543360"
  },
  {
    "text": "which needed to know about the predictor",
    "start": "543360",
    "end": "545760"
  },
  {
    "text": "and optionally about the features that",
    "start": "545760",
    "end": "547440"
  },
  {
    "text": "go into it",
    "start": "547440",
    "end": "548160"
  },
  {
    "text": "what it outputs and what kind of model",
    "start": "548160",
    "end": "550240"
  },
  {
    "text": "it is",
    "start": "550240",
    "end": "551440"
  },
  {
    "text": "so the only change we had to make in",
    "start": "551440",
    "end": "553600"
  },
  {
    "text": "order to enable parallel computation",
    "start": "553600",
    "end": "555839"
  },
  {
    "text": "with ray",
    "start": "555839",
    "end": "556480"
  },
  {
    "text": "was to add a dictionary and this",
    "start": "556480",
    "end": "558640"
  },
  {
    "text": "dictionary would be",
    "start": "558640",
    "end": "560080"
  },
  {
    "text": "a vehicle for the user to specify how",
    "start": "560080",
    "end": "562640"
  },
  {
    "text": "many cpus they have",
    "start": "562640",
    "end": "564000"
  },
  {
    "text": "available on for this task and",
    "start": "564000",
    "end": "566320"
  },
  {
    "text": "optionally",
    "start": "566320",
    "end": "567200"
  },
  {
    "text": "they could also specify a mini batch",
    "start": "567200",
    "end": "570240"
  },
  {
    "text": "size",
    "start": "570240",
    "end": "570800"
  },
  {
    "text": "that controls how many of these",
    "start": "570800",
    "end": "572880"
  },
  {
    "text": "instances are explained",
    "start": "572880",
    "end": "574480"
  },
  {
    "text": "by the same cpu at one time",
    "start": "574480",
    "end": "578399"
  },
  {
    "text": "so what happens under the hood well to",
    "start": "578560",
    "end": "580800"
  },
  {
    "text": "start with we had the fifth step that",
    "start": "580800",
    "end": "582640"
  },
  {
    "text": "needed to prepare",
    "start": "582640",
    "end": "583839"
  },
  {
    "text": "some data for our",
    "start": "583839",
    "end": "587120"
  },
  {
    "text": "underlying calculation so it was really",
    "start": "587120",
    "end": "590320"
  },
  {
    "text": "easy to actually instead of delegating",
    "start": "590320",
    "end": "594880"
  },
  {
    "text": "the task to an object that did the",
    "start": "594880",
    "end": "597680"
  },
  {
    "text": "calculation",
    "start": "597680",
    "end": "598640"
  },
  {
    "text": "as i've just shown here it was really",
    "start": "598640",
    "end": "602240"
  },
  {
    "text": "easy to create a distributed",
    "start": "602240",
    "end": "604399"
  },
  {
    "text": "explainer object that took that original",
    "start": "604399",
    "end": "607440"
  },
  {
    "text": "object that we already",
    "start": "607440",
    "end": "608800"
  },
  {
    "text": "delegated the task to along with its",
    "start": "608800",
    "end": "611360"
  },
  {
    "text": "arguments and keyword",
    "start": "611360",
    "end": "612800"
  },
  {
    "text": "arguments and use that object",
    "start": "612800",
    "end": "615839"
  },
  {
    "text": "to distribute the task so the way we did",
    "start": "615839",
    "end": "619040"
  },
  {
    "text": "this was simply to",
    "start": "619040",
    "end": "620480"
  },
  {
    "text": "create a parallel pool and as you see we",
    "start": "620480",
    "end": "622959"
  },
  {
    "text": "here we just initialize ray and create",
    "start": "622959",
    "end": "625120"
  },
  {
    "text": "the parallel pool",
    "start": "625120",
    "end": "627200"
  },
  {
    "text": "and the pool creation has two very",
    "start": "627200",
    "end": "629920"
  },
  {
    "text": "simple steps",
    "start": "629920",
    "end": "630800"
  },
  {
    "text": "first we apply the remote decorator",
    "start": "630800",
    "end": "633200"
  },
  {
    "text": "functionally because",
    "start": "633200",
    "end": "634320"
  },
  {
    "text": "we just have the object and it's just",
    "start": "634320",
    "end": "636320"
  },
  {
    "text": "the easiest way to do so",
    "start": "636320",
    "end": "637839"
  },
  {
    "text": "to create some actor handles and then we",
    "start": "637839",
    "end": "640079"
  },
  {
    "text": "just instantiate our explainer in each",
    "start": "640079",
    "end": "642320"
  },
  {
    "text": "of the worker processes and create a",
    "start": "642320",
    "end": "644880"
  },
  {
    "text": "pool",
    "start": "644880",
    "end": "645519"
  },
  {
    "text": "uh with the actors and this is all",
    "start": "645519",
    "end": "649360"
  },
  {
    "text": "when the user uh calls our api with a",
    "start": "649360",
    "end": "652240"
  },
  {
    "text": "data set they wish to explain",
    "start": "652240",
    "end": "653920"
  },
  {
    "text": "the getexplanation method of this",
    "start": "653920",
    "end": "657200"
  },
  {
    "text": "object um gets called and this takes",
    "start": "657200",
    "end": "661440"
  },
  {
    "text": "a date of the data step it splits it",
    "start": "661440",
    "end": "665040"
  },
  {
    "text": "into individual instances or perhaps",
    "start": "665040",
    "end": "667200"
  },
  {
    "text": "mini batches",
    "start": "667200",
    "end": "668480"
  },
  {
    "text": "and then calls submits these individual",
    "start": "668480",
    "end": "672880"
  },
  {
    "text": "mini batches or instances to the pool",
    "start": "672880",
    "end": "675360"
  },
  {
    "text": "and returns to results at the end",
    "start": "675360",
    "end": "677760"
  },
  {
    "text": "so you can see that our target function",
    "start": "677760",
    "end": "679519"
  },
  {
    "text": "for the pool is very simple and just",
    "start": "679519",
    "end": "681839"
  },
  {
    "text": "calls the actor",
    "start": "681839",
    "end": "683040"
  },
  {
    "text": "a method that knows how to explain an",
    "start": "683040",
    "end": "686720"
  },
  {
    "text": "instance",
    "start": "686720",
    "end": "687680"
  },
  {
    "text": "and this is all really um and from a",
    "start": "687680",
    "end": "690079"
  },
  {
    "text": "user perspective",
    "start": "690079",
    "end": "691200"
  },
  {
    "text": "all they need to do is to load their",
    "start": "691200",
    "end": "693360"
  },
  {
    "text": "data and their model",
    "start": "693360",
    "end": "694560"
  },
  {
    "text": "to tell us how many cpus they want to",
    "start": "694560",
    "end": "696480"
  },
  {
    "text": "use fit the",
    "start": "696480",
    "end": "698720"
  },
  {
    "text": "the explainer and explain it it's just",
    "start": "698720",
    "end": "701680"
  },
  {
    "text": "their workflow flow from before but now",
    "start": "701680",
    "end": "704160"
  },
  {
    "text": "many times faster so just how fast we",
    "start": "704160",
    "end": "707279"
  },
  {
    "text": "managed to get this thing",
    "start": "707279",
    "end": "708959"
  },
  {
    "text": "well you can see here some results and",
    "start": "708959",
    "end": "711279"
  },
  {
    "text": "we ran this",
    "start": "711279",
    "end": "712160"
  },
  {
    "text": "task on a machine from digital ocean",
    "start": "712160",
    "end": "714639"
  },
  {
    "text": "with 32",
    "start": "714639",
    "end": "716240"
  },
  {
    "text": "virtual cpus and it's a compute",
    "start": "716240",
    "end": "718720"
  },
  {
    "text": "optimized machine",
    "start": "718720",
    "end": "719680"
  },
  {
    "text": "and a dedicated one so you can see a",
    "start": "719680",
    "end": "722560"
  },
  {
    "text": "nice",
    "start": "722560",
    "end": "723519"
  },
  {
    "text": "and linear almost increase up to 16 c",
    "start": "723519",
    "end": "727360"
  },
  {
    "text": "virtual up to 16 workers",
    "start": "727360",
    "end": "731200"
  },
  {
    "text": "which is a nearly linear improvement",
    "start": "731200",
    "end": "733120"
  },
  {
    "text": "because these are",
    "start": "733120",
    "end": "735200"
  },
  {
    "text": "um let's go to the previous slide",
    "start": "735200",
    "end": "739920"
  },
  {
    "text": "so all the user needs to do is to load",
    "start": "739920",
    "end": "742639"
  },
  {
    "text": "the data and their model",
    "start": "742639",
    "end": "744639"
  },
  {
    "text": "instantiate the explainer tell us how",
    "start": "744639",
    "end": "746959"
  },
  {
    "text": "many cpus they want to use",
    "start": "746959",
    "end": "749360"
  },
  {
    "text": "and magically the computation it gets",
    "start": "749360",
    "end": "751920"
  },
  {
    "text": "distributed",
    "start": "751920",
    "end": "753519"
  },
  {
    "text": "so just how fast would this be",
    "start": "753519",
    "end": "756560"
  },
  {
    "text": "you can see here some results that we",
    "start": "756560",
    "end": "758720"
  },
  {
    "text": "calculated by",
    "start": "758720",
    "end": "759920"
  },
  {
    "text": "taking this code on a digital ocean",
    "start": "759920",
    "end": "762480"
  },
  {
    "text": "machine with 32",
    "start": "762480",
    "end": "764240"
  },
  {
    "text": "virtual cpus",
    "start": "764240",
    "end": "767760"
  },
  {
    "text": "and we represent the results on a",
    "start": "767760",
    "end": "769760"
  },
  {
    "text": "logarithmic y-axis",
    "start": "769760",
    "end": "771519"
  },
  {
    "text": "you can see that up to 16 workers",
    "start": "771519",
    "end": "774800"
  },
  {
    "text": "we could get a nice nearly linear",
    "start": "774800",
    "end": "777440"
  },
  {
    "text": "improvement",
    "start": "777440",
    "end": "778399"
  },
  {
    "text": "but because our task is cpu bound beyond",
    "start": "778399",
    "end": "781839"
  },
  {
    "text": "we get",
    "start": "781839",
    "end": "782560"
  },
  {
    "text": "much smaller improvements hyper",
    "start": "782560",
    "end": "784560"
  },
  {
    "text": "threading doesn't really help with our",
    "start": "784560",
    "end": "786560"
  },
  {
    "text": "cpu bound work",
    "start": "786560",
    "end": "788240"
  },
  {
    "text": "so even so we run our task in just",
    "start": "788240",
    "end": "791440"
  },
  {
    "text": "over two minutes compared to",
    "start": "791440",
    "end": "793200"
  },
  {
    "text": "approximately",
    "start": "793200",
    "end": "794800"
  },
  {
    "text": "half an hour which is really about 14",
    "start": "794800",
    "end": "797040"
  },
  {
    "text": "times faster",
    "start": "797040",
    "end": "798399"
  },
  {
    "text": "we try different batch sizes to ensure",
    "start": "798399",
    "end": "800800"
  },
  {
    "text": "that each worker gets",
    "start": "800800",
    "end": "802000"
  },
  {
    "text": "enough work in a call and ensure that",
    "start": "802000",
    "end": "804880"
  },
  {
    "text": "the overhead of distributing the task",
    "start": "804880",
    "end": "806560"
  },
  {
    "text": "isn't",
    "start": "806560",
    "end": "807279"
  },
  {
    "text": "great much greater than the task",
    "start": "807279",
    "end": "809600"
  },
  {
    "text": "execution time",
    "start": "809600",
    "end": "811600"
  },
  {
    "text": "you may be thinking surely there's a lot",
    "start": "811600",
    "end": "813680"
  },
  {
    "text": "more work to take this to a cluster but",
    "start": "813680",
    "end": "815519"
  },
  {
    "text": "in reality there are only a few extra",
    "start": "815519",
    "end": "817200"
  },
  {
    "text": "steps we took to achieve this",
    "start": "817200",
    "end": "819360"
  },
  {
    "text": "you need to set up your cluster first so",
    "start": "819360",
    "end": "821920"
  },
  {
    "text": "i had to do this on my own because i",
    "start": "821920",
    "end": "823839"
  },
  {
    "text": "was working with digital ocean but you",
    "start": "823839",
    "end": "826240"
  },
  {
    "text": "can",
    "start": "826240",
    "end": "826880"
  },
  {
    "text": "use cloud providers such as aws or as",
    "start": "826880",
    "end": "829519"
  },
  {
    "text": "your you name it",
    "start": "829519",
    "end": "830560"
  },
  {
    "text": "the ray guys have got you covered as the",
    "start": "830560",
    "end": "832880"
  },
  {
    "text": "library offers",
    "start": "832880",
    "end": "834079"
  },
  {
    "text": "a number of cluster launchers that you",
    "start": "834079",
    "end": "837040"
  },
  {
    "text": "can use together with the ray cli to get",
    "start": "837040",
    "end": "839519"
  },
  {
    "text": "you up and running quickly",
    "start": "839519",
    "end": "841760"
  },
  {
    "text": "after you've downloaded your",
    "start": "841760",
    "end": "843519"
  },
  {
    "text": "configuration",
    "start": "843519",
    "end": "844800"
  },
  {
    "text": "and build your image you're ready to go",
    "start": "844800",
    "end": "847920"
  },
  {
    "text": "all you need to do is set up your ray",
    "start": "847920",
    "end": "849680"
  },
  {
    "text": "cluster so i'm just going to take you",
    "start": "849680",
    "end": "851440"
  },
  {
    "text": "very quickly through how we did this",
    "start": "851440",
    "end": "853839"
  },
  {
    "text": "you may know that array cluster consists",
    "start": "853839",
    "end": "856720"
  },
  {
    "text": "of",
    "start": "856720",
    "end": "857199"
  },
  {
    "text": "array head nodes and work notes we",
    "start": "857199",
    "end": "860160"
  },
  {
    "text": "configured",
    "start": "860160",
    "end": "861040"
  },
  {
    "text": "both of these as deployments which are",
    "start": "861040",
    "end": "863279"
  },
  {
    "text": "resources",
    "start": "863279",
    "end": "864399"
  },
  {
    "text": "capable of scaling the image that you",
    "start": "864399",
    "end": "867440"
  },
  {
    "text": "want to run on in kubernetes",
    "start": "867440",
    "end": "870320"
  },
  {
    "text": "so to scale things simply we increase",
    "start": "870320",
    "end": "872560"
  },
  {
    "text": "the number of replicas",
    "start": "872560",
    "end": "874800"
  },
  {
    "text": "but you should know that in general if",
    "start": "874800",
    "end": "876720"
  },
  {
    "text": "you use ray for this task and you",
    "start": "876720",
    "end": "878240"
  },
  {
    "text": "explain",
    "start": "878240",
    "end": "878880"
  },
  {
    "text": "expect good performance from it or",
    "start": "878880",
    "end": "881279"
  },
  {
    "text": "container",
    "start": "881279",
    "end": "882320"
  },
  {
    "text": "needs to access a shared memory volume",
    "start": "882320",
    "end": "884800"
  },
  {
    "text": "this is more relevant for",
    "start": "884800",
    "end": "886079"
  },
  {
    "text": "complex workloads where the actors",
    "start": "886079",
    "end": "887760"
  },
  {
    "text": "perhaps need to talk to one another",
    "start": "887760",
    "end": "889760"
  },
  {
    "text": "but i thought it was nonetheless worth",
    "start": "889760",
    "end": "892399"
  },
  {
    "text": "mentioning",
    "start": "892399",
    "end": "893600"
  },
  {
    "text": "so you can see here that we request four",
    "start": "893600",
    "end": "896639"
  },
  {
    "text": "cpus for each replica so there are about",
    "start": "896639",
    "end": "899040"
  },
  {
    "text": "56 virtual cpus running this task",
    "start": "899040",
    "end": "902639"
  },
  {
    "text": "and as i said the head node is",
    "start": "902639",
    "end": "904480"
  },
  {
    "text": "configured in the same way",
    "start": "904480",
    "end": "905760"
  },
  {
    "text": "except that there's a single replica",
    "start": "905760",
    "end": "907440"
  },
  {
    "text": "because we only have one head node",
    "start": "907440",
    "end": "910560"
  },
  {
    "text": "so you notice that we also run ray start",
    "start": "910560",
    "end": "913519"
  },
  {
    "text": "in order to initialize",
    "start": "913519",
    "end": "914959"
  },
  {
    "text": "uh ray on each node and this is no",
    "start": "914959",
    "end": "917680"
  },
  {
    "text": "secret it's",
    "start": "917680",
    "end": "918560"
  },
  {
    "text": "available in the documentation at this",
    "start": "918560",
    "end": "920800"
  },
  {
    "text": "stage you might think okay so what about",
    "start": "920800",
    "end": "922320"
  },
  {
    "text": "the script does that need to be changed",
    "start": "922320",
    "end": "923680"
  },
  {
    "text": "a lot and the answer is no",
    "start": "923680",
    "end": "925279"
  },
  {
    "text": "all you need to do is to pass the",
    "start": "925279",
    "end": "928800"
  },
  {
    "text": "rate in it for the address equals auto",
    "start": "928800",
    "end": "931839"
  },
  {
    "text": "input",
    "start": "931839",
    "end": "932480"
  },
  {
    "text": "and this will take care of it and",
    "start": "932480",
    "end": "935920"
  },
  {
    "text": "this is really as little work as it you",
    "start": "935920",
    "end": "938399"
  },
  {
    "text": "need to do up to this point",
    "start": "938399",
    "end": "940160"
  },
  {
    "text": "and to take the the script that i've",
    "start": "940160",
    "end": "942560"
  },
  {
    "text": "just shown",
    "start": "942560",
    "end": "943600"
  },
  {
    "text": "and upload to a cluster we need to do a",
    "start": "943600",
    "end": "945440"
  },
  {
    "text": "bit of work first",
    "start": "945440",
    "end": "946639"
  },
  {
    "text": "so we need to tell kubernetes about our",
    "start": "946639",
    "end": "948560"
  },
  {
    "text": "resources and the fact that it needs to",
    "start": "948560",
    "end": "950639"
  },
  {
    "text": "provision them",
    "start": "950639",
    "end": "951440"
  },
  {
    "text": "and we use cube cartel commands to do so",
    "start": "951440",
    "end": "954480"
  },
  {
    "text": "and specifically the apply command in",
    "start": "954480",
    "end": "957279"
  },
  {
    "text": "general you can also use the",
    "start": "957279",
    "end": "958959"
  },
  {
    "text": "the ray cli to achieve the same outcomes",
    "start": "958959",
    "end": "962800"
  },
  {
    "text": "uh after this step we need to understand",
    "start": "962800",
    "end": "965920"
  },
  {
    "text": "okay where what's the name of my ray",
    "start": "965920",
    "end": "968959"
  },
  {
    "text": "head node so we get the name of that",
    "start": "968959",
    "end": "971199"
  },
  {
    "text": "specific pod",
    "start": "971199",
    "end": "972880"
  },
  {
    "text": "and copy our script to it it's as simple",
    "start": "972880",
    "end": "975839"
  },
  {
    "text": "as that",
    "start": "975839",
    "end": "976399"
  },
  {
    "text": "copy operation and then we use cube",
    "start": "976399",
    "end": "978880"
  },
  {
    "text": "control exec to run a command",
    "start": "978880",
    "end": "980560"
  },
  {
    "text": "on the head node we know its name now so",
    "start": "980560",
    "end": "983440"
  },
  {
    "text": "we know",
    "start": "983440",
    "end": "984320"
  },
  {
    "text": "where to execute that command and",
    "start": "984320",
    "end": "986639"
  },
  {
    "text": "finally we copy back our results",
    "start": "986639",
    "end": "988560"
  },
  {
    "text": "and it is as simple as that",
    "start": "988560",
    "end": "991759"
  },
  {
    "text": "in terms of results we could we had",
    "start": "991759",
    "end": "994320"
  },
  {
    "text": "really good success",
    "start": "994320",
    "end": "995440"
  },
  {
    "text": "we the best the average run time we run",
    "start": "995440",
    "end": "999040"
  },
  {
    "text": "this",
    "start": "999040",
    "end": "1000160"
  },
  {
    "text": "run five times was just under one",
    "start": "1000160",
    "end": "1003519"
  },
  {
    "text": "minute which is about 30 times faster",
    "start": "1003519",
    "end": "1006800"
  },
  {
    "text": "and we can see here on this graph that",
    "start": "1006800",
    "end": "1008560"
  },
  {
    "text": "batching hurts performance a little",
    "start": "1008560",
    "end": "1010560"
  },
  {
    "text": "but as i said before our explainer isn't",
    "start": "1010560",
    "end": "1012639"
  },
  {
    "text": "really",
    "start": "1012639",
    "end": "1013839"
  },
  {
    "text": "benefiting from taking those mini",
    "start": "1013839",
    "end": "1016079"
  },
  {
    "text": "batches as input",
    "start": "1016079",
    "end": "1017519"
  },
  {
    "text": "it just increases the",
    "start": "1017519",
    "end": "1020720"
  },
  {
    "text": "task runtime linearly so what could be",
    "start": "1020720",
    "end": "1023440"
  },
  {
    "text": "happening perhaps",
    "start": "1023440",
    "end": "1024558"
  },
  {
    "text": "is that due to longer uh task running",
    "start": "1024559",
    "end": "1028400"
  },
  {
    "text": "times",
    "start": "1028400",
    "end": "1028959"
  },
  {
    "text": "and there be many less tasks to schedule",
    "start": "1028959",
    "end": "1031918"
  },
  {
    "text": "as a whole",
    "start": "1031919",
    "end": "1033199"
  },
  {
    "text": "there could be less a few only a few",
    "start": "1033199",
    "end": "1036400"
  },
  {
    "text": "tasks left to run at the end",
    "start": "1036400",
    "end": "1038959"
  },
  {
    "text": "and of some workers that are idle so",
    "start": "1038959",
    "end": "1041678"
  },
  {
    "text": "we're not making",
    "start": "1041679",
    "end": "1042720"
  },
  {
    "text": "very efficient use of our cluster but we",
    "start": "1042720",
    "end": "1044558"
  },
  {
    "text": "haven't really dug into",
    "start": "1044559",
    "end": "1046240"
  },
  {
    "text": "why this is the case so",
    "start": "1046240",
    "end": "1049760"
  },
  {
    "text": "now imagine a different use case you're",
    "start": "1049760",
    "end": "1051760"
  },
  {
    "text": "part of a team of data scientists that",
    "start": "1051760",
    "end": "1053679"
  },
  {
    "text": "all develop models and want to explain",
    "start": "1053679",
    "end": "1055679"
  },
  {
    "text": "them",
    "start": "1055679",
    "end": "1056240"
  },
  {
    "text": "and it would be quite painful if every",
    "start": "1056240",
    "end": "1058720"
  },
  {
    "text": "single data scientist had",
    "start": "1058720",
    "end": "1060080"
  },
  {
    "text": "to kind of replicate the workflow that",
    "start": "1060080",
    "end": "1062480"
  },
  {
    "text": "i've just described",
    "start": "1062480",
    "end": "1064000"
  },
  {
    "text": "so ideally these data scientists would",
    "start": "1064000",
    "end": "1066960"
  },
  {
    "text": "also want their results quickly so that",
    "start": "1066960",
    "end": "1069120"
  },
  {
    "text": "they can do their development and you",
    "start": "1069120",
    "end": "1071600"
  },
  {
    "text": "know you go and ask your boss what to do",
    "start": "1071600",
    "end": "1073440"
  },
  {
    "text": "about it and they say oh i have this",
    "start": "1073440",
    "end": "1075039"
  },
  {
    "text": "spare",
    "start": "1075039",
    "end": "1075840"
  },
  {
    "text": "kubernetes cluster you can use and if",
    "start": "1075840",
    "end": "1079039"
  },
  {
    "text": "you're that data scientist i've got a",
    "start": "1079039",
    "end": "1080640"
  },
  {
    "text": "solution for you",
    "start": "1080640",
    "end": "1081760"
  },
  {
    "text": "because you can use race serve to get up",
    "start": "1081760",
    "end": "1084559"
  },
  {
    "text": "and running at nighttime",
    "start": "1084559",
    "end": "1085840"
  },
  {
    "text": "so how can you do this well there are",
    "start": "1085840",
    "end": "1087520"
  },
  {
    "text": "three main steps to use racer to deploy",
    "start": "1087520",
    "end": "1089760"
  },
  {
    "text": "the same tasks that i've described",
    "start": "1089760",
    "end": "1091600"
  },
  {
    "text": "first we need to create a request",
    "start": "1091600",
    "end": "1093120"
  },
  {
    "text": "handler we need to create",
    "start": "1093120",
    "end": "1094880"
  },
  {
    "text": "end points and backends and we need to",
    "start": "1094880",
    "end": "1097440"
  },
  {
    "text": "distribute the request",
    "start": "1097440",
    "end": "1099200"
  },
  {
    "text": "arguably the first two steps are are",
    "start": "1099200",
    "end": "1101600"
  },
  {
    "text": "what we care about the most",
    "start": "1101600",
    "end": "1103600"
  },
  {
    "text": "so in this case we coded the kernel",
    "start": "1103600",
    "end": "1106480"
  },
  {
    "text": "shaft model which is our request handler",
    "start": "1106480",
    "end": "1108320"
  },
  {
    "text": "which takes our predictor",
    "start": "1108320",
    "end": "1109840"
  },
  {
    "text": "and the arguments for the explainer",
    "start": "1109840",
    "end": "1113200"
  },
  {
    "text": "constructor",
    "start": "1113200",
    "end": "1114160"
  },
  {
    "text": "and the fit step that i've mentioned and",
    "start": "1114160",
    "end": "1116720"
  },
  {
    "text": "we just",
    "start": "1116720",
    "end": "1117440"
  },
  {
    "text": "instantiate and fit our explainer that's",
    "start": "1117440",
    "end": "1120400"
  },
  {
    "text": "it",
    "start": "1120400",
    "end": "1120960"
  },
  {
    "text": "the next step is to have a call method",
    "start": "1120960",
    "end": "1122799"
  },
  {
    "text": "that extracts the input from a request",
    "start": "1122799",
    "end": "1125600"
  },
  {
    "text": "cast it to the type that explainer needs",
    "start": "1125600",
    "end": "1128400"
  },
  {
    "text": "and calls the explainer",
    "start": "1128400",
    "end": "1129679"
  },
  {
    "text": "and for people like me who don't know",
    "start": "1129679",
    "end": "1131200"
  },
  {
    "text": "much about flask this was really nice",
    "start": "1131200",
    "end": "1133039"
  },
  {
    "text": "and convenient to set up",
    "start": "1133039",
    "end": "1135120"
  },
  {
    "text": "in some cases we if our model benefits",
    "start": "1135120",
    "end": "1137840"
  },
  {
    "text": "from batching",
    "start": "1137840",
    "end": "1139039"
  },
  {
    "text": "ray allows this functionality very",
    "start": "1139039",
    "end": "1141440"
  },
  {
    "text": "simply and the way we'd achieve this in",
    "start": "1141440",
    "end": "1143280"
  },
  {
    "text": "this case",
    "start": "1143280",
    "end": "1144080"
  },
  {
    "text": "is to override the call method decorate",
    "start": "1144080",
    "end": "1146880"
  },
  {
    "text": "it with the accept",
    "start": "1146880",
    "end": "1148000"
  },
  {
    "text": "batch decorator and make sure",
    "start": "1148000",
    "end": "1151039"
  },
  {
    "text": "it handles a list of requests as opposed",
    "start": "1151039",
    "end": "1153120"
  },
  {
    "text": "to a single request",
    "start": "1153120",
    "end": "1154240"
  },
  {
    "text": "and that's all we need to do okay the",
    "start": "1154240",
    "end": "1156720"
  },
  {
    "text": "second step is to create",
    "start": "1156720",
    "end": "1158160"
  },
  {
    "text": "an endpoint and you can see that this is",
    "start": "1158160",
    "end": "1160559"
  },
  {
    "text": "relatively",
    "start": "1160559",
    "end": "1161360"
  },
  {
    "text": "easy to achieve we need to give the",
    "start": "1161360",
    "end": "1163760"
  },
  {
    "text": "endpoint a name",
    "start": "1163760",
    "end": "1164880"
  },
  {
    "text": "we need to tell it what backends it",
    "start": "1164880",
    "end": "1166720"
  },
  {
    "text": "needs to connect to and then we need",
    "start": "1166720",
    "end": "1168720"
  },
  {
    "text": "to tell it about the application root",
    "start": "1168720",
    "end": "1171760"
  },
  {
    "text": "and as soon as that's complete we can",
    "start": "1171760",
    "end": "1174559"
  },
  {
    "text": "create our backend",
    "start": "1174559",
    "end": "1176240"
  },
  {
    "text": "our backend can be created with some",
    "start": "1176240",
    "end": "1179120"
  },
  {
    "text": "nice and simple to use",
    "start": "1179120",
    "end": "1180559"
  },
  {
    "text": "ray utilities we have the create backend",
    "start": "1180559",
    "end": "1182640"
  },
  {
    "text": "function that we just need to call",
    "start": "1182640",
    "end": "1184799"
  },
  {
    "text": "and we need to pass the backend name so",
    "start": "1184799",
    "end": "1188240"
  },
  {
    "text": "that the endpoint knows about its",
    "start": "1188240",
    "end": "1190480"
  },
  {
    "text": "backend",
    "start": "1190480",
    "end": "1191520"
  },
  {
    "text": "and we need to pass of course our",
    "start": "1191520",
    "end": "1193679"
  },
  {
    "text": "request handler to it",
    "start": "1193679",
    "end": "1195200"
  },
  {
    "text": "and we have the update backup config",
    "start": "1195200",
    "end": "1198320"
  },
  {
    "text": "method that can allow us to update the",
    "start": "1198320",
    "end": "1200640"
  },
  {
    "text": "backend anytime",
    "start": "1200640",
    "end": "1201919"
  },
  {
    "text": "we want uh in production so i use it in",
    "start": "1201919",
    "end": "1204720"
  },
  {
    "text": "this case",
    "start": "1204720",
    "end": "1205280"
  },
  {
    "text": "to to change the batch size as i run",
    "start": "1205280",
    "end": "1208559"
  },
  {
    "text": "these experiments so at the script level",
    "start": "1208559",
    "end": "1212640"
  },
  {
    "text": "it's",
    "start": "1212640",
    "end": "1212960"
  },
  {
    "text": "also very easy you just need to run",
    "start": "1212960",
    "end": "1216080"
  },
  {
    "text": "through these steps in sequence and call",
    "start": "1216080",
    "end": "1218559"
  },
  {
    "text": "serve.id and that's it",
    "start": "1218559",
    "end": "1220159"
  },
  {
    "text": "as easy as one and two and in kubernetes",
    "start": "1220159",
    "end": "1223200"
  },
  {
    "text": "world",
    "start": "1223200",
    "end": "1223919"
  },
  {
    "text": "you need to connect to the cluster just",
    "start": "1223919",
    "end": "1225760"
  },
  {
    "text": "as we did before and just make sure that",
    "start": "1225760",
    "end": "1227760"
  },
  {
    "text": "serv",
    "start": "1227760",
    "end": "1228159"
  },
  {
    "text": "can actually accept requests from other",
    "start": "1228159",
    "end": "1230640"
  },
  {
    "text": "machines",
    "start": "1230640",
    "end": "1231280"
  },
  {
    "text": "which is why we have the http host",
    "start": "1231280",
    "end": "1233600"
  },
  {
    "text": "argument to serve",
    "start": "1233600",
    "end": "1234720"
  },
  {
    "text": "in it and you also need to find out",
    "start": "1234720",
    "end": "1237760"
  },
  {
    "text": "the host for your",
    "start": "1237760",
    "end": "1240960"
  },
  {
    "text": "array head node which you can do with a",
    "start": "1240960",
    "end": "1244159"
  },
  {
    "text": "simple python call",
    "start": "1244159",
    "end": "1247120"
  },
  {
    "text": "note that in order to really make this",
    "start": "1247120",
    "end": "1249360"
  },
  {
    "text": "available to a team one would also need",
    "start": "1249360",
    "end": "1251120"
  },
  {
    "text": "to set up an inverse controller on the",
    "start": "1251120",
    "end": "1252960"
  },
  {
    "text": "cluster so that you can actually connect",
    "start": "1252960",
    "end": "1255039"
  },
  {
    "text": "to your cluster from the outside world",
    "start": "1255039",
    "end": "1257600"
  },
  {
    "text": "and",
    "start": "1257600",
    "end": "1258400"
  },
  {
    "text": "this is the last step that you really",
    "start": "1258400",
    "end": "1260240"
  },
  {
    "text": "need to do so your whole",
    "start": "1260240",
    "end": "1262000"
  },
  {
    "text": "team could actually benefit from this",
    "start": "1262000",
    "end": "1265039"
  },
  {
    "text": "we use the same commands as before the",
    "start": "1265039",
    "end": "1266960"
  },
  {
    "text": "cubecall commands to take the script",
    "start": "1266960",
    "end": "1268880"
  },
  {
    "text": "on on a kubernetes cluster and execute",
    "start": "1268880",
    "end": "1271520"
  },
  {
    "text": "it",
    "start": "1271520",
    "end": "1272080"
  },
  {
    "text": "and you can see that for the one night",
    "start": "1272080",
    "end": "1275520"
  },
  {
    "text": "so this isn't a kubernetes cluster it's",
    "start": "1275520",
    "end": "1277200"
  },
  {
    "text": "just one machine that i've used",
    "start": "1277200",
    "end": "1279520"
  },
  {
    "text": "we we have a run time",
    "start": "1279520",
    "end": "1282720"
  },
  {
    "text": "of just under two minutes so about 15",
    "start": "1282720",
    "end": "1286000"
  },
  {
    "text": "times faster and for the kubernetes",
    "start": "1286000",
    "end": "1289200"
  },
  {
    "text": "cluster we achieve",
    "start": "1289200",
    "end": "1290400"
  },
  {
    "text": "a runtime of just 61 seconds",
    "start": "1290400",
    "end": "1293520"
  },
  {
    "text": "which is 28 times faster looking that",
    "start": "1293520",
    "end": "1296559"
  },
  {
    "text": "the maximum",
    "start": "1296559",
    "end": "1297520"
  },
  {
    "text": "resource allocation was was",
    "start": "1297520",
    "end": "1300559"
  },
  {
    "text": "56 virtual cpus and for batching we",
    "start": "1300559",
    "end": "1303679"
  },
  {
    "text": "observe observe",
    "start": "1303679",
    "end": "1305200"
  },
  {
    "text": "the same behavior as before note that",
    "start": "1305200",
    "end": "1308720"
  },
  {
    "text": "this is a really way uh to speed a",
    "start": "1308720",
    "end": "1311520"
  },
  {
    "text": "really simple way to speed things up",
    "start": "1311520",
    "end": "1313520"
  },
  {
    "text": "and for data scientists to explain their",
    "start": "1313520",
    "end": "1316080"
  },
  {
    "text": "model predictions so they'll thank you",
    "start": "1316080",
    "end": "1317840"
  },
  {
    "text": "for it",
    "start": "1317840",
    "end": "1318880"
  },
  {
    "text": "so another question comes why bother why",
    "start": "1318880",
    "end": "1321440"
  },
  {
    "text": "do we need to speed up this task so",
    "start": "1321440",
    "end": "1324159"
  },
  {
    "text": "okay you can see in this image that",
    "start": "1324159",
    "end": "1325679"
  },
  {
    "text": "explaining many predictions",
    "start": "1325679",
    "end": "1327520"
  },
  {
    "text": "allows us to aggregate feature effects",
    "start": "1327520",
    "end": "1330400"
  },
  {
    "text": "at the individual level in order to",
    "start": "1330400",
    "end": "1332320"
  },
  {
    "text": "update",
    "start": "1332320",
    "end": "1333039"
  },
  {
    "text": "a global view of model behavior so for",
    "start": "1333039",
    "end": "1335840"
  },
  {
    "text": "instance",
    "start": "1335840",
    "end": "1336400"
  },
  {
    "text": "in the image on the slide you can",
    "start": "1336400",
    "end": "1339520"
  },
  {
    "text": "see that for example race and where",
    "start": "1339520",
    "end": "1341760"
  },
  {
    "text": "class",
    "start": "1341760",
    "end": "1342559"
  },
  {
    "text": "don't influence the odds of being",
    "start": "1342559",
    "end": "1345200"
  },
  {
    "text": "predicted",
    "start": "1345200",
    "end": "1346640"
  },
  {
    "text": "a um income of over",
    "start": "1346640",
    "end": "1349679"
  },
  {
    "text": "50 000 dollars that much and this is you",
    "start": "1349679",
    "end": "1352799"
  },
  {
    "text": "know indicated",
    "start": "1352799",
    "end": "1353760"
  },
  {
    "text": "at the very minimum that our classifier",
    "start": "1353760",
    "end": "1356880"
  },
  {
    "text": "is not",
    "start": "1356880",
    "end": "1357360"
  },
  {
    "text": "racially biased i a slightly more",
    "start": "1357360",
    "end": "1360159"
  },
  {
    "text": "granular",
    "start": "1360159",
    "end": "1360880"
  },
  {
    "text": "view of the same data we we can actually",
    "start": "1360880",
    "end": "1364799"
  },
  {
    "text": "have because we've",
    "start": "1364799",
    "end": "1366000"
  },
  {
    "text": "created these explanations for each and",
    "start": "1366000",
    "end": "1369679"
  },
  {
    "text": "every prediction",
    "start": "1369679",
    "end": "1370799"
  },
  {
    "text": "so we can see for example that a capital",
    "start": "1370799",
    "end": "1374559"
  },
  {
    "text": "gain can have",
    "start": "1374559",
    "end": "1375440"
  },
  {
    "text": "both a positive and a negative effect",
    "start": "1375440",
    "end": "1378880"
  },
  {
    "text": "on the prediction of an income over 50",
    "start": "1378880",
    "end": "1381440"
  },
  {
    "text": "000",
    "start": "1381440",
    "end": "1382480"
  },
  {
    "text": "and that for some individuals who don't",
    "start": "1382480",
    "end": "1384400"
  },
  {
    "text": "really have capital gain the future",
    "start": "1384400",
    "end": "1386000"
  },
  {
    "text": "doesn't really",
    "start": "1386000",
    "end": "1386960"
  },
  {
    "text": "impact the outcome that much so",
    "start": "1386960",
    "end": "1390159"
  },
  {
    "text": "this is the kind of insight you never",
    "start": "1390159",
    "end": "1392480"
  },
  {
    "text": "get from",
    "start": "1392480",
    "end": "1393919"
  },
  {
    "text": "a traditional tree based model so kernel",
    "start": "1393919",
    "end": "1397039"
  },
  {
    "text": "chap",
    "start": "1397039",
    "end": "1397360"
  },
  {
    "text": "allows us to do this for every",
    "start": "1397360",
    "end": "1400799"
  },
  {
    "text": "type of model but it is expensive to run",
    "start": "1400799",
    "end": "1403360"
  },
  {
    "text": "and due to ray",
    "start": "1403360",
    "end": "1404640"
  },
  {
    "text": "we can actually offer uh both the",
    "start": "1404640",
    "end": "1407200"
  },
  {
    "text": "scientists and stakeholders the ability",
    "start": "1407200",
    "end": "1409120"
  },
  {
    "text": "to do this",
    "start": "1409120",
    "end": "1410240"
  },
  {
    "text": "these things at a much much larger scale",
    "start": "1410240",
    "end": "1412559"
  },
  {
    "text": "much much faster",
    "start": "1412559",
    "end": "1413840"
  },
  {
    "text": "so now time for some very quick",
    "start": "1413840",
    "end": "1415840"
  },
  {
    "text": "takeaways i'm going to be brief",
    "start": "1415840",
    "end": "1418880"
  },
  {
    "text": "we all have a mandate to deploy robust",
    "start": "1418880",
    "end": "1421679"
  },
  {
    "text": "mprai",
    "start": "1421679",
    "end": "1422880"
  },
  {
    "text": "and perhaps black box explanation",
    "start": "1422880",
    "end": "1426080"
  },
  {
    "text": "feature along this journey and as i",
    "start": "1426080",
    "end": "1429039"
  },
  {
    "text": "demonstrated ray",
    "start": "1429039",
    "end": "1430159"
  },
  {
    "text": "tremendously boosts the speed of",
    "start": "1430159",
    "end": "1433600"
  },
  {
    "text": "execution of this test",
    "start": "1433600",
    "end": "1435120"
  },
  {
    "text": "so the data scientists now have a handle",
    "start": "1435120",
    "end": "1438240"
  },
  {
    "text": "on",
    "start": "1438240",
    "end": "1438880"
  },
  {
    "text": "perhaps identifying um if their",
    "start": "1438880",
    "end": "1441279"
  },
  {
    "text": "classifiers are fair",
    "start": "1441279",
    "end": "1443279"
  },
  {
    "text": "or if they have certain biases that they",
    "start": "1443279",
    "end": "1445760"
  },
  {
    "text": "don't know about",
    "start": "1445760",
    "end": "1446960"
  },
  {
    "text": "so if you're interested in the card that",
    "start": "1446960",
    "end": "1448960"
  },
  {
    "text": "we use to run these tasks you can find",
    "start": "1448960",
    "end": "1450720"
  },
  {
    "text": "it on my github",
    "start": "1450720",
    "end": "1451840"
  },
  {
    "text": "and if you want to know more about",
    "start": "1451840",
    "end": "1453279"
  },
  {
    "text": "explanations and see",
    "start": "1453279",
    "end": "1454960"
  },
  {
    "text": "the distributed shop in the library you",
    "start": "1454960",
    "end": "1457760"
  },
  {
    "text": "can",
    "start": "1457760",
    "end": "1458799"
  },
  {
    "text": "go to github and look at selden io for",
    "start": "1458799",
    "end": "1461840"
  },
  {
    "text": "slash alibi",
    "start": "1461840",
    "end": "1462880"
  },
  {
    "text": "for more thank you very much for your",
    "start": "1462880",
    "end": "1464720"
  },
  {
    "text": "time and i'm now open for your questions",
    "start": "1464720",
    "end": "1470240"
  }
]
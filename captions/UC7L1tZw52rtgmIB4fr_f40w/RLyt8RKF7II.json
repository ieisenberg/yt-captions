[
  {
    "start": "0",
    "end": "54000"
  },
  {
    "text": "[Music]",
    "start": "170",
    "end": "14799"
  },
  {
    "text": "hello guys",
    "start": "14799",
    "end": "15599"
  },
  {
    "text": "uh thanks for joining our talk today uh",
    "start": "15599",
    "end": "18320"
  },
  {
    "text": "we are",
    "start": "18320",
    "end": "18800"
  },
  {
    "text": "ikigai labs uh my name is jaehan sim and",
    "start": "18800",
    "end": "21520"
  },
  {
    "text": "i'm a software engineering manager here",
    "start": "21520",
    "end": "23119"
  },
  {
    "text": "at klabs",
    "start": "23119",
    "end": "24000"
  },
  {
    "text": "and i'm joined by our infrastructure",
    "start": "24000",
    "end": "26000"
  },
  {
    "text": "engineer amar shah",
    "start": "26000",
    "end": "27920"
  },
  {
    "text": "and today we're going to talk about how",
    "start": "27920",
    "end": "29920"
  },
  {
    "text": "we achieve the data scalability",
    "start": "29920",
    "end": "32000"
  },
  {
    "text": "while maintaining data interactivity",
    "start": "32000",
    "end": "34399"
  },
  {
    "text": "utilizing reserve",
    "start": "34399",
    "end": "36719"
  },
  {
    "text": "so let me start by introducing our team",
    "start": "36719",
    "end": "39600"
  },
  {
    "text": "we all come from",
    "start": "39600",
    "end": "41040"
  },
  {
    "text": "a technical background and we came",
    "start": "41040",
    "end": "42719"
  },
  {
    "text": "together to tackle problems that we have",
    "start": "42719",
    "end": "44800"
  },
  {
    "text": "frequently encountered before while",
    "start": "44800",
    "end": "46800"
  },
  {
    "text": "working the data",
    "start": "46800",
    "end": "48079"
  },
  {
    "text": "um as well as solve problems that",
    "start": "48079",
    "end": "50160"
  },
  {
    "text": "existing tools in the market doesn't uh",
    "start": "50160",
    "end": "51840"
  },
  {
    "text": "doesn't address",
    "start": "51840",
    "end": "54000"
  },
  {
    "start": "54000",
    "end": "54000"
  },
  {
    "text": "so let me introduce our platform um",
    "start": "54000",
    "end": "57199"
  },
  {
    "text": "so our ikigai platform we have built an",
    "start": "57199",
    "end": "59520"
  },
  {
    "text": "easy to use",
    "start": "59520",
    "end": "60239"
  },
  {
    "text": "ai augmented data processing and",
    "start": "60239",
    "end": "62480"
  },
  {
    "text": "analytics platform in the cloud",
    "start": "62480",
    "end": "64320"
  },
  {
    "text": "uh within our platform anyone can build",
    "start": "64320",
    "end": "66799"
  },
  {
    "text": "powerful ai enabled end-to-end workflow",
    "start": "66799",
    "end": "69360"
  },
  {
    "text": "while staying within the comfort of the",
    "start": "69360",
    "end": "71040"
  },
  {
    "text": "spreadsheets",
    "start": "71040",
    "end": "72799"
  },
  {
    "text": "while the tool has many features ranging",
    "start": "72799",
    "end": "74640"
  },
  {
    "text": "from connectors to dashboards",
    "start": "74640",
    "end": "77040"
  },
  {
    "text": "everything kind of revolves around our",
    "start": "77040",
    "end": "78880"
  },
  {
    "text": "data pipelines as you can see in the",
    "start": "78880",
    "end": "80640"
  },
  {
    "text": "middle",
    "start": "80640",
    "end": "82000"
  },
  {
    "text": "they consist of they consist of drag and",
    "start": "82000",
    "end": "84320"
  },
  {
    "text": "drop blocks where each performs a set of",
    "start": "84320",
    "end": "86640"
  },
  {
    "text": "operations of data",
    "start": "86640",
    "end": "88000"
  },
  {
    "text": "uh you can pull transform and output",
    "start": "88000",
    "end": "91040"
  },
  {
    "text": "data and those kind of operations not",
    "start": "91040",
    "end": "93119"
  },
  {
    "text": "only",
    "start": "93119",
    "end": "94400"
  },
  {
    "text": "do we have previous blocks with useful",
    "start": "94400",
    "end": "96400"
  },
  {
    "text": "functionality such as",
    "start": "96400",
    "end": "97600"
  },
  {
    "text": "select or join all those like uh",
    "start": "97600",
    "end": "101280"
  },
  {
    "text": "simple functionalities we also have",
    "start": "101280",
    "end": "103360"
  },
  {
    "text": "blocks where you can inject your own",
    "start": "103360",
    "end": "105280"
  },
  {
    "text": "python script",
    "start": "105280",
    "end": "106240"
  },
  {
    "text": "to apply any custom business logic into",
    "start": "106240",
    "end": "108479"
  },
  {
    "text": "the pipeline",
    "start": "108479",
    "end": "110240"
  },
  {
    "text": "uh we with such sets of features we",
    "start": "110240",
    "end": "112960"
  },
  {
    "text": "enabled",
    "start": "112960",
    "end": "113759"
  },
  {
    "text": "a few things extraction of unstructured",
    "start": "113759",
    "end": "116320"
  },
  {
    "text": "data",
    "start": "116320",
    "end": "117040"
  },
  {
    "text": "and stitching together the unstructured",
    "start": "117040",
    "end": "118799"
  },
  {
    "text": "data and then structured data",
    "start": "118799",
    "end": "121119"
  },
  {
    "text": "and then advanced analytics and with",
    "start": "121119",
    "end": "124079"
  },
  {
    "text": "predictions and forecasting",
    "start": "124079",
    "end": "125840"
  },
  {
    "text": "and all these are backed by machine",
    "start": "125840",
    "end": "127520"
  },
  {
    "text": "learning models",
    "start": "127520",
    "end": "129280"
  },
  {
    "text": "so here uh even though we have a lot of",
    "start": "129280",
    "end": "131680"
  },
  {
    "text": "stuff going on here",
    "start": "131680",
    "end": "132640"
  },
  {
    "text": "most of our problems comes from a data",
    "start": "132640",
    "end": "134560"
  },
  {
    "text": "prepping or data cleansing steps",
    "start": "134560",
    "end": "136640"
  },
  {
    "text": "so today we're going to specifically",
    "start": "136640",
    "end": "138640"
  },
  {
    "text": "focus on the data pipeline",
    "start": "138640",
    "end": "140239"
  },
  {
    "text": "aspect of our aki platform",
    "start": "140239",
    "end": "143440"
  },
  {
    "start": "143000",
    "end": "143000"
  },
  {
    "text": "here are things that we're going to talk",
    "start": "143440",
    "end": "145040"
  },
  {
    "text": "about today uh we're going to start by",
    "start": "145040",
    "end": "147360"
  },
  {
    "text": "what is the aki platform trying to",
    "start": "147360",
    "end": "148959"
  },
  {
    "text": "achieve why we choose right",
    "start": "148959",
    "end": "151200"
  },
  {
    "text": "how does racer resolve the challenges",
    "start": "151200",
    "end": "153280"
  },
  {
    "text": "faced",
    "start": "153280",
    "end": "154319"
  },
  {
    "text": "how do we scale the race serve in inside",
    "start": "154319",
    "end": "156480"
  },
  {
    "text": "of our kubernetes cluster",
    "start": "156480",
    "end": "158239"
  },
  {
    "text": "how can ray client take us further",
    "start": "158239",
    "end": "162080"
  },
  {
    "text": "so the first uh first topic um so what",
    "start": "163040",
    "end": "166239"
  },
  {
    "text": "is the aka platform trying to achieve",
    "start": "166239",
    "end": "168720"
  },
  {
    "text": "so we wanted to achieve mission critical",
    "start": "168720",
    "end": "171200"
  },
  {
    "start": "169000",
    "end": "169000"
  },
  {
    "text": "data pipelining",
    "start": "171200",
    "end": "172480"
  },
  {
    "text": "um so we faced many different users",
    "start": "172480",
    "end": "175680"
  },
  {
    "text": "with all different uh business use cases",
    "start": "175680",
    "end": "178239"
  },
  {
    "text": "so",
    "start": "178239",
    "end": "178959"
  },
  {
    "text": "uh how we deal with them is we let them",
    "start": "178959",
    "end": "181760"
  },
  {
    "text": "inject a custom python code into the",
    "start": "181760",
    "end": "183840"
  },
  {
    "text": "dynamic data pipeline",
    "start": "183840",
    "end": "185360"
  },
  {
    "text": "to enable flexibility so one of the",
    "start": "185360",
    "end": "187680"
  },
  {
    "text": "examples here",
    "start": "187680",
    "end": "188640"
  },
  {
    "text": "as you can see here one of the customers",
    "start": "188640",
    "end": "190959"
  },
  {
    "text": "said",
    "start": "190959",
    "end": "191840"
  },
  {
    "text": "we want to collect all attached pdf",
    "start": "191840",
    "end": "193680"
  },
  {
    "text": "files from emails",
    "start": "193680",
    "end": "195120"
  },
  {
    "text": "every day and we receive today and use",
    "start": "195120",
    "end": "198000"
  },
  {
    "text": "them as a source of data",
    "start": "198000",
    "end": "199280"
  },
  {
    "text": "and they want to run this pipeline every",
    "start": "199280",
    "end": "200959"
  },
  {
    "text": "single day",
    "start": "200959",
    "end": "202400"
  },
  {
    "text": "here most of the steps can be done with",
    "start": "202400",
    "end": "205120"
  },
  {
    "text": "traditional etl steps",
    "start": "205120",
    "end": "207120"
  },
  {
    "text": "such as join or summary but at some",
    "start": "207120",
    "end": "210480"
  },
  {
    "text": "point you need",
    "start": "210480",
    "end": "211200"
  },
  {
    "text": "some custom python code to do",
    "start": "211200",
    "end": "215599"
  },
  {
    "text": "those of the specific business logic",
    "start": "215599",
    "end": "218319"
  },
  {
    "text": "that you want to pursue",
    "start": "218319",
    "end": "220000"
  },
  {
    "text": "so uh by enable uh use by enabling users",
    "start": "220000",
    "end": "223840"
  },
  {
    "text": "to inject their python code",
    "start": "223840",
    "end": "226080"
  },
  {
    "text": "we achieved that flexibility",
    "start": "226080",
    "end": "229120"
  },
  {
    "start": "229000",
    "end": "229000"
  },
  {
    "text": "next we wanted to achieve highly",
    "start": "229120",
    "end": "231120"
  },
  {
    "text": "interactive data pipelining",
    "start": "231120",
    "end": "232879"
  },
  {
    "text": "so in traditional etl pipeline it is",
    "start": "232879",
    "end": "235439"
  },
  {
    "text": "really hard to see intermediate data",
    "start": "235439",
    "end": "236959"
  },
  {
    "text": "sets",
    "start": "236959",
    "end": "237920"
  },
  {
    "text": "we let users to interact with",
    "start": "237920",
    "end": "239360"
  },
  {
    "text": "intermediate data through variety of",
    "start": "239360",
    "end": "241280"
  },
  {
    "text": "mediums",
    "start": "241280",
    "end": "241920"
  },
  {
    "text": "for example a user can code on the fly",
    "start": "241920",
    "end": "244239"
  },
  {
    "text": "with the jupyter notebook at",
    "start": "244239",
    "end": "245680"
  },
  {
    "text": "each step of the pipeline and or simply",
    "start": "245680",
    "end": "248720"
  },
  {
    "text": "just view how they look like with the",
    "start": "248720",
    "end": "250400"
  },
  {
    "text": "dashboards and charts",
    "start": "250400",
    "end": "253439"
  },
  {
    "start": "253000",
    "end": "253000"
  },
  {
    "text": "last but not least uh most interesting",
    "start": "253680",
    "end": "255840"
  },
  {
    "text": "thing in my perspective",
    "start": "255840",
    "end": "257519"
  },
  {
    "text": "is uh instantly browsable data",
    "start": "257519",
    "end": "259440"
  },
  {
    "text": "pipelining",
    "start": "259440",
    "end": "260639"
  },
  {
    "text": "so this is very interesting uh",
    "start": "260639",
    "end": "263759"
  },
  {
    "text": "challenging problem uh we face not only",
    "start": "263759",
    "end": "266240"
  },
  {
    "text": "our platform support",
    "start": "266240",
    "end": "267759"
  },
  {
    "text": "a fully scalable pipeline run which",
    "start": "267759",
    "end": "270400"
  },
  {
    "text": "handles a massive scale of data",
    "start": "270400",
    "end": "272720"
  },
  {
    "text": "but we also support a peaking of the",
    "start": "272720",
    "end": "274720"
  },
  {
    "text": "pipeline where we sample few hundreds or",
    "start": "274720",
    "end": "277280"
  },
  {
    "text": "thousands of data",
    "start": "277280",
    "end": "278639"
  },
  {
    "text": "and then quickly deliver that to you at",
    "start": "278639",
    "end": "281120"
  },
  {
    "text": "any point of the pipeline",
    "start": "281120",
    "end": "282560"
  },
  {
    "text": "under a second so unlike traditional etl",
    "start": "282560",
    "end": "286000"
  },
  {
    "text": "we let users to interact with the data",
    "start": "286000",
    "end": "287759"
  },
  {
    "text": "at each step of the pipeline",
    "start": "287759",
    "end": "289360"
  },
  {
    "text": "under a second by enabling this this",
    "start": "289360",
    "end": "291680"
  },
  {
    "text": "includes",
    "start": "291680",
    "end": "292720"
  },
  {
    "text": "on the screen you can see the",
    "start": "292720",
    "end": "295520"
  },
  {
    "text": "traditional",
    "start": "295520",
    "end": "296000"
  },
  {
    "text": "tabular view of the data or simply make",
    "start": "296000",
    "end": "298880"
  },
  {
    "text": "a simple chart of a chart out of it",
    "start": "298880",
    "end": "301120"
  },
  {
    "text": "and also by enabling users to quickly",
    "start": "301120",
    "end": "303919"
  },
  {
    "text": "interact with data",
    "start": "303919",
    "end": "305039"
  },
  {
    "text": "they can also kind of debug the pipeline",
    "start": "305039",
    "end": "307919"
  },
  {
    "text": "so",
    "start": "307919",
    "end": "308880"
  },
  {
    "text": "you can also you can identify and fix",
    "start": "308880",
    "end": "311520"
  },
  {
    "text": "ernest step without waiting",
    "start": "311520",
    "end": "313120"
  },
  {
    "text": "until the full pipeline is done so which",
    "start": "313120",
    "end": "315840"
  },
  {
    "text": "might",
    "start": "315840",
    "end": "316240"
  },
  {
    "text": "take a few minutes to a few hours",
    "start": "316240",
    "end": "320000"
  },
  {
    "text": "so before we specifically talk about",
    "start": "320000",
    "end": "322240"
  },
  {
    "text": "what kind of challenge we face",
    "start": "322240",
    "end": "323600"
  },
  {
    "text": "to achieve those three goals we're going",
    "start": "323600",
    "end": "325280"
  },
  {
    "text": "to we're going to quickly",
    "start": "325280",
    "end": "326800"
  },
  {
    "text": "cover why we chose rey in the first",
    "start": "326800",
    "end": "329280"
  },
  {
    "text": "place",
    "start": "329280",
    "end": "331520"
  },
  {
    "text": "so uh it was to earn a massive",
    "start": "332160",
    "end": "334320"
  },
  {
    "text": "scalability",
    "start": "334320",
    "end": "336000"
  },
  {
    "text": "so our company code codebase is",
    "start": "336000",
    "end": "337680"
  },
  {
    "start": "337000",
    "end": "337000"
  },
  {
    "text": "primarily in python and almost mostly in",
    "start": "337680",
    "end": "340080"
  },
  {
    "text": "python",
    "start": "340080",
    "end": "340960"
  },
  {
    "text": "and we wanted to earn massive",
    "start": "340960",
    "end": "342400"
  },
  {
    "text": "scalability without having to completely",
    "start": "342400",
    "end": "344880"
  },
  {
    "text": "overhaul our",
    "start": "344880",
    "end": "346080"
  },
  {
    "text": "code base and if you see our if you see",
    "start": "346080",
    "end": "348800"
  },
  {
    "text": "the screen um",
    "start": "348800",
    "end": "349919"
  },
  {
    "text": "there's a code base on the left that's",
    "start": "349919",
    "end": "353440"
  },
  {
    "text": "how our code base used to look like um",
    "start": "353440",
    "end": "357039"
  },
  {
    "text": "it has all the business logic that we",
    "start": "357039",
    "end": "358880"
  },
  {
    "text": "want to pursue for specific users",
    "start": "358880",
    "end": "361039"
  },
  {
    "text": "and those two examples there all we need",
    "start": "361039",
    "end": "363120"
  },
  {
    "text": "to do is",
    "start": "363120",
    "end": "364479"
  },
  {
    "text": "do ray in it to vividly notice that",
    "start": "364479",
    "end": "368639"
  },
  {
    "text": "people note that we're using the right",
    "start": "368639",
    "end": "370160"
  },
  {
    "text": "cluster for this job and then",
    "start": "370160",
    "end": "371919"
  },
  {
    "text": "instead of calling instead of invoking",
    "start": "371919",
    "end": "373840"
  },
  {
    "text": "the regular python functions we invoke",
    "start": "373840",
    "end": "376000"
  },
  {
    "text": "with the raise remote method",
    "start": "376000",
    "end": "379280"
  },
  {
    "text": "so as you can see this was extremely",
    "start": "379280",
    "end": "380960"
  },
  {
    "text": "easy migration that we had to do",
    "start": "380960",
    "end": "383039"
  },
  {
    "text": "and uh it worked out greatly",
    "start": "383039",
    "end": "386319"
  },
  {
    "text": "so now we're going to dive into some",
    "start": "386319",
    "end": "388319"
  },
  {
    "text": "specific challenges that we faced",
    "start": "388319",
    "end": "391280"
  },
  {
    "text": "while we're trying to achieve those",
    "start": "391280",
    "end": "392720"
  },
  {
    "text": "three goals about and then how we're",
    "start": "392720",
    "end": "394560"
  },
  {
    "text": "going to discuss how ray served helped",
    "start": "394560",
    "end": "396319"
  },
  {
    "text": "us",
    "start": "396319",
    "end": "396960"
  },
  {
    "text": "on the process so before i dive into the",
    "start": "396960",
    "end": "400560"
  },
  {
    "start": "399000",
    "end": "399000"
  },
  {
    "text": "challenges",
    "start": "400560",
    "end": "401120"
  },
  {
    "text": "i'm going to actually quickly talk about",
    "start": "401120",
    "end": "403199"
  },
  {
    "text": "the race serve itself first",
    "start": "403199",
    "end": "405120"
  },
  {
    "text": "so race serve is easy to use and",
    "start": "405120",
    "end": "407199"
  },
  {
    "text": "scalable model serv",
    "start": "407199",
    "end": "408560"
  },
  {
    "text": "library built-in right it's one of the",
    "start": "408560",
    "end": "410240"
  },
  {
    "text": "race module",
    "start": "410240",
    "end": "411919"
  },
  {
    "text": "so we focused on the two characteristics",
    "start": "411919",
    "end": "414800"
  },
  {
    "text": "of racer",
    "start": "414800",
    "end": "415520"
  },
  {
    "text": "one is framework agnostic and it is a",
    "start": "415520",
    "end": "418479"
  },
  {
    "text": "two",
    "start": "418479",
    "end": "418800"
  },
  {
    "text": "is it is python first so race serve can",
    "start": "418800",
    "end": "422240"
  },
  {
    "text": "serve not only deep learning models or",
    "start": "422240",
    "end": "424160"
  },
  {
    "text": "any kind of a complicated uh",
    "start": "424160",
    "end": "425680"
  },
  {
    "text": "machine learning models but also it can",
    "start": "425680",
    "end": "427520"
  },
  {
    "text": "serve arbitrary",
    "start": "427520",
    "end": "428960"
  },
  {
    "text": "python business logic so since we're",
    "start": "428960",
    "end": "431520"
  },
  {
    "text": "targeting",
    "start": "431520",
    "end": "432160"
  },
  {
    "text": "um our customers where they can have any",
    "start": "432160",
    "end": "435440"
  },
  {
    "text": "kind of random",
    "start": "435440",
    "end": "436800"
  },
  {
    "text": "business logic with the random python",
    "start": "436800",
    "end": "438880"
  },
  {
    "text": "functions this kind of fits our bill",
    "start": "438880",
    "end": "440720"
  },
  {
    "text": "perfectly",
    "start": "440720",
    "end": "441599"
  },
  {
    "text": "so oh we decided to use one i'll use",
    "start": "441599",
    "end": "444240"
  },
  {
    "text": "this one",
    "start": "444240",
    "end": "444880"
  },
  {
    "text": "and second python first uh as i said",
    "start": "444880",
    "end": "448160"
  },
  {
    "text": "about",
    "start": "448160",
    "end": "448840"
  },
  {
    "text": "um we our company code base is entirely",
    "start": "448840",
    "end": "451759"
  },
  {
    "text": "in python almost entirely in python so",
    "start": "451759",
    "end": "454560"
  },
  {
    "text": "uh it being a python first uh and pure",
    "start": "454560",
    "end": "457039"
  },
  {
    "text": "python code base",
    "start": "457039",
    "end": "458160"
  },
  {
    "text": "it was uh right choice for us so now",
    "start": "458160",
    "end": "461120"
  },
  {
    "start": "461000",
    "end": "461000"
  },
  {
    "text": "we're going to talk about the challenges",
    "start": "461120",
    "end": "462400"
  },
  {
    "text": "we faced",
    "start": "462400",
    "end": "463280"
  },
  {
    "text": "so first challenge conflicting python",
    "start": "463280",
    "end": "465520"
  },
  {
    "text": "libraries",
    "start": "465520",
    "end": "466800"
  },
  {
    "text": "so since we let users",
    "start": "466800",
    "end": "471039"
  },
  {
    "text": "work inject our code base their own code",
    "start": "471039",
    "end": "473440"
  },
  {
    "text": "base to our pipeline",
    "start": "473440",
    "end": "476080"
  },
  {
    "text": "sometimes when they collaborate when",
    "start": "476080",
    "end": "477840"
  },
  {
    "text": "different people in the same company",
    "start": "477840",
    "end": "479360"
  },
  {
    "text": "collaborate",
    "start": "479360",
    "end": "480000"
  },
  {
    "text": "in one pipeline uh they can have",
    "start": "480000",
    "end": "482560"
  },
  {
    "text": "different python dependencies",
    "start": "482560",
    "end": "484240"
  },
  {
    "text": "so uh this became a little bit of",
    "start": "484240",
    "end": "486720"
  },
  {
    "text": "problem not because of",
    "start": "486720",
    "end": "488560"
  },
  {
    "text": "actual pipeline itself because we can",
    "start": "488560",
    "end": "490960"
  },
  {
    "text": "always create a different",
    "start": "490960",
    "end": "492000"
  },
  {
    "text": "python environment for each step but it",
    "start": "492000",
    "end": "494240"
  },
  {
    "text": "was for peaking so we wanted to maintain",
    "start": "494240",
    "end": "497039"
  },
  {
    "text": "that sub second running time of the",
    "start": "497039",
    "end": "498800"
  },
  {
    "text": "peaking",
    "start": "498800",
    "end": "500160"
  },
  {
    "text": "but if we were to launch a different",
    "start": "500160",
    "end": "503280"
  },
  {
    "text": "python environment",
    "start": "503280",
    "end": "504720"
  },
  {
    "text": "every single time we run the pipeline",
    "start": "504720",
    "end": "507199"
  },
  {
    "text": "for every single custom python facets",
    "start": "507199",
    "end": "509840"
  },
  {
    "text": "or custom python steps it becomes a",
    "start": "509840",
    "end": "512880"
  },
  {
    "text": "problem",
    "start": "512880",
    "end": "513518"
  },
  {
    "text": "because we cannot meet the sub second",
    "start": "513519",
    "end": "515120"
  },
  {
    "text": "running time anymore",
    "start": "515120",
    "end": "517599"
  },
  {
    "text": "so how we should how we choose to copy",
    "start": "517599",
    "end": "520159"
  },
  {
    "start": "518000",
    "end": "518000"
  },
  {
    "text": "this was",
    "start": "520159",
    "end": "521760"
  },
  {
    "text": "ray serves optional",
    "start": "521760",
    "end": "525279"
  },
  {
    "text": "argument where you can pass in the conda",
    "start": "525279",
    "end": "527279"
  },
  {
    "text": "environment that you want to use",
    "start": "527279",
    "end": "528720"
  },
  {
    "text": "so here you can see in ray actor options",
    "start": "528720",
    "end": "532080"
  },
  {
    "text": "of the deployment decorator you can see",
    "start": "532080",
    "end": "535360"
  },
  {
    "text": "you can specify the name of the condyle",
    "start": "535360",
    "end": "537360"
  },
  {
    "text": "environment that you want to use for",
    "start": "537360",
    "end": "538959"
  },
  {
    "text": "this specific race serve instance",
    "start": "538959",
    "end": "541519"
  },
  {
    "text": "um this means uh it's gonna our pipeline",
    "start": "541519",
    "end": "545360"
  },
  {
    "start": "544000",
    "end": "544000"
  },
  {
    "text": "will look like this",
    "start": "545360",
    "end": "546320"
  },
  {
    "text": "each step each custom python script step",
    "start": "546320",
    "end": "549920"
  },
  {
    "text": "will be wrapped inside of a one ray",
    "start": "549920",
    "end": "552160"
  },
  {
    "text": "serve instance",
    "start": "552160",
    "end": "553040"
  },
  {
    "text": "which utilize a different content",
    "start": "553040",
    "end": "555360"
  },
  {
    "text": "environment every time",
    "start": "555360",
    "end": "557120"
  },
  {
    "text": "specifically so since they have their",
    "start": "557120",
    "end": "560560"
  },
  {
    "text": "own space confined",
    "start": "560560",
    "end": "562480"
  },
  {
    "text": "they're not going to be a dependency",
    "start": "562480",
    "end": "564399"
  },
  {
    "text": "conflict in even inside of one pipeline",
    "start": "564399",
    "end": "568560"
  },
  {
    "start": "569000",
    "end": "569000"
  },
  {
    "text": "so the next challenge was the task",
    "start": "569120",
    "end": "571360"
  },
  {
    "text": "overhead for peaking",
    "start": "571360",
    "end": "572720"
  },
  {
    "text": "as we briefly covered above our platform",
    "start": "572720",
    "end": "575519"
  },
  {
    "text": "supports two different types of data",
    "start": "575519",
    "end": "577040"
  },
  {
    "text": "pipelining",
    "start": "577040",
    "end": "577839"
  },
  {
    "text": "one is scalable data pipeline run where",
    "start": "577839",
    "end": "580160"
  },
  {
    "text": "you run one to run",
    "start": "580160",
    "end": "581600"
  },
  {
    "text": "a massive scale of data two is a peaking",
    "start": "581600",
    "end": "584720"
  },
  {
    "text": "run",
    "start": "584720",
    "end": "585040"
  },
  {
    "text": "where you sample data quickly for sub",
    "start": "585040",
    "end": "587040"
  },
  {
    "text": "second data interfacing",
    "start": "587040",
    "end": "588880"
  },
  {
    "text": "so the problem is uh our ray cluster",
    "start": "588880",
    "end": "591920"
  },
  {
    "text": "living in our kubernetes cluster um",
    "start": "591920",
    "end": "595200"
  },
  {
    "text": "when we want to submit a job uh to rate",
    "start": "595200",
    "end": "597680"
  },
  {
    "text": "cluster it takes about 10 seconds",
    "start": "597680",
    "end": "599760"
  },
  {
    "text": "for us to create not only the task",
    "start": "599760",
    "end": "603200"
  },
  {
    "text": "definition",
    "start": "603200",
    "end": "604399"
  },
  {
    "text": "as a python file itself but also",
    "start": "604399",
    "end": "608320"
  },
  {
    "text": "uh the task submission itself to the",
    "start": "608320",
    "end": "610720"
  },
  {
    "text": "right cluster takes about seven to eight",
    "start": "610720",
    "end": "612320"
  },
  {
    "text": "seconds",
    "start": "612320",
    "end": "612800"
  },
  {
    "text": "in total uh in average so the question",
    "start": "612800",
    "end": "615920"
  },
  {
    "text": "is",
    "start": "615920",
    "end": "616160"
  },
  {
    "text": "if custom python python scripts are on",
    "start": "616160",
    "end": "619200"
  },
  {
    "text": "ray's serve",
    "start": "619200",
    "end": "620000"
  },
  {
    "text": "how could we maintain a subsequent",
    "start": "620000",
    "end": "621600"
  },
  {
    "text": "peaking time",
    "start": "621600",
    "end": "624000"
  },
  {
    "start": "624000",
    "end": "624000"
  },
  {
    "text": "so actually this problem turns out to be",
    "start": "624000",
    "end": "626399"
  },
  {
    "text": "the easy one a easier one to resolve",
    "start": "626399",
    "end": "628240"
  },
  {
    "text": "so racer expose",
    "start": "628240",
    "end": "631440"
  },
  {
    "text": "not only the regular remote method of",
    "start": "631440",
    "end": "634480"
  },
  {
    "text": "invoke",
    "start": "634480",
    "end": "635120"
  },
  {
    "text": "invoking your functions but also expose",
    "start": "635120",
    "end": "638320"
  },
  {
    "text": "the",
    "start": "638320",
    "end": "639519"
  },
  {
    "text": "http endpoint of your razer instance so",
    "start": "639519",
    "end": "642320"
  },
  {
    "text": "if you see on the bottom",
    "start": "642320",
    "end": "643600"
  },
  {
    "text": "um i'm calling",
    "start": "643600",
    "end": "647120"
  },
  {
    "text": "uh ray serve instance method uh with the",
    "start": "647120",
    "end": "650480"
  },
  {
    "text": "http request format",
    "start": "650480",
    "end": "652399"
  },
  {
    "text": "uh here i'm not gonna uh suffer from",
    "start": "652399",
    "end": "654880"
  },
  {
    "text": "task overhead",
    "start": "654880",
    "end": "655920"
  },
  {
    "text": "because i'm using ray uh i'm not",
    "start": "655920",
    "end": "658720"
  },
  {
    "text": "submitting a job to the raid cluster",
    "start": "658720",
    "end": "661360"
  },
  {
    "text": "uh with for uh with the standard channel",
    "start": "661360",
    "end": "664640"
  },
  {
    "text": "so how do we generate the http endpoint",
    "start": "664640",
    "end": "667120"
  },
  {
    "text": "for um",
    "start": "667120",
    "end": "668640"
  },
  {
    "text": "the race services it's pretty simple uh",
    "start": "668640",
    "end": "671440"
  },
  {
    "text": "so you",
    "start": "671440",
    "end": "672079"
  },
  {
    "text": "instantiate the fast api app pass it",
    "start": "672079",
    "end": "675120"
  },
  {
    "text": "into",
    "start": "675120",
    "end": "676079"
  },
  {
    "text": "http deployment decorator",
    "start": "676079",
    "end": "679120"
  },
  {
    "text": "and the decorator will append it to the",
    "start": "679120",
    "end": "681279"
  },
  {
    "text": "existing server instance you have",
    "start": "681279",
    "end": "683120"
  },
  {
    "text": "and then you specify it's going to be",
    "start": "683120",
    "end": "684800"
  },
  {
    "text": "post method or gap method",
    "start": "684800",
    "end": "686320"
  },
  {
    "text": "and you specify the sub path which is",
    "start": "686320",
    "end": "688480"
  },
  {
    "text": "duplicate here",
    "start": "688480",
    "end": "690800"
  },
  {
    "text": "and then your reserve instance can",
    "start": "690800",
    "end": "693600"
  },
  {
    "text": "support http endpoint now",
    "start": "693600",
    "end": "696959"
  },
  {
    "text": "so with that challenges result this is",
    "start": "697440",
    "end": "700839"
  },
  {
    "text": "our uh",
    "start": "700839",
    "end": "702079"
  },
  {
    "text": "kubernetes cluster how it how it looks",
    "start": "702079",
    "end": "703920"
  },
  {
    "text": "like so",
    "start": "703920",
    "end": "706079"
  },
  {
    "text": "um as you can see we have a ray cluster",
    "start": "706079",
    "end": "708560"
  },
  {
    "text": "inside of our",
    "start": "708560",
    "end": "709680"
  },
  {
    "text": "big kubernetes cluster and then we uh",
    "start": "709680",
    "end": "712800"
  },
  {
    "text": "implemented this in-house in-house",
    "start": "712800",
    "end": "714959"
  },
  {
    "text": "solution for",
    "start": "714959",
    "end": "716240"
  },
  {
    "text": "managing raised serve instances which is",
    "start": "716240",
    "end": "718800"
  },
  {
    "text": "razer manager",
    "start": "718800",
    "end": "719839"
  },
  {
    "text": "it's the micro service that",
    "start": "719839",
    "end": "723120"
  },
  {
    "text": "does the following things create update",
    "start": "723120",
    "end": "724880"
  },
  {
    "text": "reserve deployment",
    "start": "724880",
    "end": "726399"
  },
  {
    "text": "manages condo environment for all ray",
    "start": "726399",
    "end": "728320"
  },
  {
    "text": "worker parts or worker nodes",
    "start": "728320",
    "end": "730399"
  },
  {
    "text": "optimize the number of racer instances",
    "start": "730399",
    "end": "732560"
  },
  {
    "text": "based on",
    "start": "732560",
    "end": "733440"
  },
  {
    "text": "dependence requirements so since we're",
    "start": "733440",
    "end": "736480"
  },
  {
    "text": "running",
    "start": "736480",
    "end": "736880"
  },
  {
    "text": "all of this on inside of the kubernetes",
    "start": "736880",
    "end": "738959"
  },
  {
    "text": "deployment kubernetes cluster",
    "start": "738959",
    "end": "741600"
  },
  {
    "text": "we face yet another types of challenges",
    "start": "741600",
    "end": "744560"
  },
  {
    "text": "which is",
    "start": "744560",
    "end": "745360"
  },
  {
    "text": "scaling the race serve in raid cluster",
    "start": "745360",
    "end": "747600"
  },
  {
    "text": "itself",
    "start": "747600",
    "end": "748639"
  },
  {
    "text": "so since that is very uh infrastruc",
    "start": "748639",
    "end": "752320"
  },
  {
    "text": "infrastructure related issue our",
    "start": "752320",
    "end": "754639"
  },
  {
    "text": "infrastructure engineer and cloud",
    "start": "754639",
    "end": "756079"
  },
  {
    "text": "architect omar",
    "start": "756079",
    "end": "757360"
  },
  {
    "text": "will introduce you what kind of",
    "start": "757360",
    "end": "758800"
  },
  {
    "text": "challenge we faced and how we resolve",
    "start": "758800",
    "end": "760560"
  },
  {
    "text": "the reserve",
    "start": "760560",
    "end": "761760"
  },
  {
    "text": "hey guys it's armor here thanks so much",
    "start": "761760",
    "end": "763839"
  },
  {
    "text": "jay for introducing me",
    "start": "763839",
    "end": "765680"
  },
  {
    "text": "and today i'm going to discuss how we",
    "start": "765680",
    "end": "767760"
  },
  {
    "text": "tackled that problem",
    "start": "767760",
    "end": "769120"
  },
  {
    "text": "of scaling up race serve within our",
    "start": "769120",
    "end": "771360"
  },
  {
    "text": "kubernetes cluster",
    "start": "771360",
    "end": "772720"
  },
  {
    "text": "and tackle some of the other steps along",
    "start": "772720",
    "end": "774720"
  },
  {
    "text": "the way",
    "start": "774720",
    "end": "776959"
  },
  {
    "text": "so the first item on that agenda is auto",
    "start": "777519",
    "end": "780720"
  },
  {
    "text": "scaling or",
    "start": "780720",
    "end": "781839"
  },
  {
    "text": "meeting up or spinning up worker nodes",
    "start": "781839",
    "end": "784240"
  },
  {
    "text": "so that we have",
    "start": "784240",
    "end": "785440"
  },
  {
    "text": "additional compute resources as user",
    "start": "785440",
    "end": "787519"
  },
  {
    "text": "demand increases",
    "start": "787519",
    "end": "788959"
  },
  {
    "text": "one nice feature within ray is that",
    "start": "788959",
    "end": "792000"
  },
  {
    "text": "we found auto scale to be pretty easily",
    "start": "792000",
    "end": "794480"
  },
  {
    "text": "accessible and it's built in through the",
    "start": "794480",
    "end": "796000"
  },
  {
    "text": "cluster launcher itself",
    "start": "796000",
    "end": "797680"
  },
  {
    "text": "so we didn't have to do a lot of work on",
    "start": "797680",
    "end": "799680"
  },
  {
    "text": "our own to",
    "start": "799680",
    "end": "800800"
  },
  {
    "text": "enable auto scaling of ray worker nodes",
    "start": "800800",
    "end": "804560"
  },
  {
    "text": "as needed",
    "start": "804560",
    "end": "807200"
  },
  {
    "text": "however there is an issue that the auto",
    "start": "808399",
    "end": "811200"
  },
  {
    "text": "scaling nodes present",
    "start": "811200",
    "end": "812800"
  },
  {
    "text": "and that is that these new ray nodes",
    "start": "812800",
    "end": "815600"
  },
  {
    "text": "come up without any of the other",
    "start": "815600",
    "end": "817519"
  },
  {
    "text": "conda environments and custom built",
    "start": "817519",
    "end": "819279"
  },
  {
    "text": "resources that our system requires",
    "start": "819279",
    "end": "821680"
  },
  {
    "text": "if you remember what jay was mentioning",
    "start": "821680",
    "end": "823440"
  },
  {
    "text": "when it came to custom pythons",
    "start": "823440",
    "end": "826160"
  },
  {
    "text": "custom python logic within our pipelines",
    "start": "826160",
    "end": "829120"
  },
  {
    "text": "we",
    "start": "829120",
    "end": "829519"
  },
  {
    "text": "do have these uh segmented",
    "start": "829519",
    "end": "832639"
  },
  {
    "text": "conda environments working all together",
    "start": "832639",
    "end": "834639"
  },
  {
    "text": "within",
    "start": "834639",
    "end": "835920"
  },
  {
    "text": "reserve to meet those needs and when",
    "start": "835920",
    "end": "838720"
  },
  {
    "text": "those new nodes come up they don't have",
    "start": "838720",
    "end": "840079"
  },
  {
    "text": "that built in",
    "start": "840079",
    "end": "843440"
  },
  {
    "text": "so in order to overcome that difficulty",
    "start": "843440",
    "end": "845680"
  },
  {
    "text": "we found one of the features",
    "start": "845680",
    "end": "847519"
  },
  {
    "text": "within that same racer deployment",
    "start": "847519",
    "end": "849680"
  },
  {
    "text": "decorator to be extremely helpful in",
    "start": "849680",
    "end": "851680"
  },
  {
    "text": "that case",
    "start": "851680",
    "end": "852800"
  },
  {
    "text": "and that is that we can define our conda",
    "start": "852800",
    "end": "855440"
  },
  {
    "text": "environments and all of their",
    "start": "855440",
    "end": "856720"
  },
  {
    "text": "dependencies",
    "start": "856720",
    "end": "858000"
  },
  {
    "text": "with uh plain text and within the",
    "start": "858000",
    "end": "860240"
  },
  {
    "text": "definition itself",
    "start": "860240",
    "end": "861839"
  },
  {
    "text": "so that when the racer manager realizes",
    "start": "861839",
    "end": "864800"
  },
  {
    "text": "that a new",
    "start": "864800",
    "end": "865360"
  },
  {
    "text": "worker node has been added it can",
    "start": "865360",
    "end": "867360"
  },
  {
    "text": "automatically",
    "start": "867360",
    "end": "868399"
  },
  {
    "text": "just scale up a deployment instead of",
    "start": "868399",
    "end": "870160"
  },
  {
    "text": "having to launch conda separately and",
    "start": "870160",
    "end": "872800"
  },
  {
    "text": "worry about which environments to handle",
    "start": "872800",
    "end": "874399"
  },
  {
    "text": "so the deployments themselves are built",
    "start": "874399",
    "end": "876880"
  },
  {
    "text": "in with the content definitions",
    "start": "876880",
    "end": "880480"
  },
  {
    "start": "882000",
    "end": "882000"
  },
  {
    "text": "and now that we have an auto scaling",
    "start": "882160",
    "end": "884720"
  },
  {
    "text": "cluster that's able to",
    "start": "884720",
    "end": "886720"
  },
  {
    "text": "scale up based on user demand we ran",
    "start": "886720",
    "end": "888959"
  },
  {
    "text": "into a few interesting",
    "start": "888959",
    "end": "891040"
  },
  {
    "text": "complications and the first of those",
    "start": "891040",
    "end": "893680"
  },
  {
    "text": "came when we were analyzing our customer",
    "start": "893680",
    "end": "895760"
  },
  {
    "text": "use cases",
    "start": "895760",
    "end": "896800"
  },
  {
    "text": "we realized that auto scaling uniformly",
    "start": "896800",
    "end": "900160"
  },
  {
    "text": "across all of our services",
    "start": "900160",
    "end": "902079"
  },
  {
    "text": "was not the way to go because it we",
    "start": "902079",
    "end": "904160"
  },
  {
    "text": "found that as a huge waste of resources",
    "start": "904160",
    "end": "905920"
  },
  {
    "text": "when",
    "start": "905920",
    "end": "906320"
  },
  {
    "text": "we have some services if you look at",
    "start": "906320",
    "end": "908079"
  },
  {
    "text": "this diagram like the sword service that",
    "start": "908079",
    "end": "910240"
  },
  {
    "text": "are highly popular",
    "start": "910240",
    "end": "911440"
  },
  {
    "text": "and then other services like the",
    "start": "911440",
    "end": "913120"
  },
  {
    "text": "deduplicate service that receive a lot",
    "start": "913120",
    "end": "915040"
  },
  {
    "text": "less traffic it seems",
    "start": "915040",
    "end": "916320"
  },
  {
    "text": "like an inefficient or almost like waste",
    "start": "916320",
    "end": "918800"
  },
  {
    "text": "of resources",
    "start": "918800",
    "end": "919839"
  },
  {
    "text": "to allocate the same amount of",
    "start": "919839",
    "end": "921760"
  },
  {
    "text": "computational resources for both so in",
    "start": "921760",
    "end": "926240"
  },
  {
    "text": "order to tackle that we were able to",
    "start": "926240",
    "end": "928480"
  },
  {
    "start": "927000",
    "end": "927000"
  },
  {
    "text": "go again within the reserve manager",
    "start": "928480",
    "end": "931920"
  },
  {
    "text": "and actually modulate the number of",
    "start": "931920",
    "end": "934800"
  },
  {
    "text": "replicas that we create",
    "start": "934800",
    "end": "936160"
  },
  {
    "text": "for each service and this gives us that",
    "start": "936160",
    "end": "938000"
  },
  {
    "text": "granular level",
    "start": "938000",
    "end": "939199"
  },
  {
    "text": "control which can scale up a service as",
    "start": "939199",
    "end": "942320"
  },
  {
    "text": "needed",
    "start": "942320",
    "end": "943279"
  },
  {
    "text": "based on what we've seen from custer",
    "start": "943279",
    "end": "945199"
  },
  {
    "text": "demand so that we don't waste resources",
    "start": "945199",
    "end": "947120"
  },
  {
    "text": "on scaling up a service that's not going",
    "start": "947120",
    "end": "948560"
  },
  {
    "text": "to get a lot of foot traffic",
    "start": "948560",
    "end": "951920"
  },
  {
    "start": "953000",
    "end": "953000"
  },
  {
    "text": "another challenge that we faced when",
    "start": "953600",
    "end": "955279"
  },
  {
    "text": "observing uh the",
    "start": "955279",
    "end": "956880"
  },
  {
    "text": "user interaction was that we have these",
    "start": "956880",
    "end": "959920"
  },
  {
    "text": "racer managers",
    "start": "959920",
    "end": "960959"
  },
  {
    "text": "like i mentioned that are handling the",
    "start": "960959",
    "end": "963120"
  },
  {
    "text": "racer worker nodes",
    "start": "963120",
    "end": "964800"
  },
  {
    "text": "and there is a possibility that",
    "start": "964800",
    "end": "968720"
  },
  {
    "text": "multiple deployments that are sharing",
    "start": "968720",
    "end": "971680"
  },
  {
    "text": "the same underlying resources",
    "start": "971680",
    "end": "974240"
  },
  {
    "text": "can deploy updates at the same time to",
    "start": "974240",
    "end": "976240"
  },
  {
    "text": "different versions",
    "start": "976240",
    "end": "977440"
  },
  {
    "text": "and as you know this could create a",
    "start": "977440",
    "end": "980399"
  },
  {
    "text": "possibility for a non-deterministic",
    "start": "980399",
    "end": "982079"
  },
  {
    "text": "behavior or a race condition",
    "start": "982079",
    "end": "985920"
  },
  {
    "start": "988000",
    "end": "988000"
  },
  {
    "text": "so in order to tackle that again what we",
    "start": "988720",
    "end": "991360"
  },
  {
    "text": "were able to dig into",
    "start": "991360",
    "end": "992720"
  },
  {
    "text": "the rich feature set of race serve again",
    "start": "992720",
    "end": "995519"
  },
  {
    "text": "and they have an option",
    "start": "995519",
    "end": "997360"
  },
  {
    "text": "within our custom service for enabling",
    "start": "997360",
    "end": "1000240"
  },
  {
    "text": "explicit deployment versioning",
    "start": "1000240",
    "end": "1002160"
  },
  {
    "text": "and this explicit deployment versioning",
    "start": "1002160",
    "end": "1004079"
  },
  {
    "text": "lets us set exactly",
    "start": "1004079",
    "end": "1005440"
  },
  {
    "text": "what the previous version should be at",
    "start": "1005440",
    "end": "1007519"
  },
  {
    "text": "the time of launch and what the version",
    "start": "1007519",
    "end": "1008880"
  },
  {
    "text": "we expect to be after the deployment is",
    "start": "1008880",
    "end": "1010880"
  },
  {
    "text": "complete",
    "start": "1010880",
    "end": "1011680"
  },
  {
    "text": "and in that way we've locked exactly",
    "start": "1011680",
    "end": "1014320"
  },
  {
    "text": "what the beginning and end behavior",
    "start": "1014320",
    "end": "1015759"
  },
  {
    "text": "should be so",
    "start": "1015759",
    "end": "1016800"
  },
  {
    "text": "even if multiple deployments get",
    "start": "1016800",
    "end": "1018480"
  },
  {
    "text": "launched at the same time and they're",
    "start": "1018480",
    "end": "1019759"
  },
  {
    "text": "all updating to different versions",
    "start": "1019759",
    "end": "1021600"
  },
  {
    "text": "whichever one doesn't get deployed first",
    "start": "1021600",
    "end": "1024640"
  },
  {
    "text": "will realize that there's an",
    "start": "1024640",
    "end": "1026319"
  },
  {
    "text": "inconsistency between the previous and",
    "start": "1026319",
    "end": "1028319"
  },
  {
    "text": "current version",
    "start": "1028319",
    "end": "1029280"
  },
  {
    "text": "and then roll back and try or retry that",
    "start": "1029280",
    "end": "1032079"
  },
  {
    "text": "deployment again",
    "start": "1032079",
    "end": "1033038"
  },
  {
    "text": "in order to overcome the possibility for",
    "start": "1033039",
    "end": "1036079"
  },
  {
    "text": "writing at the same time",
    "start": "1036079",
    "end": "1039839"
  },
  {
    "text": "so if we were to look at this diagram",
    "start": "1040559",
    "end": "1042558"
  },
  {
    "text": "that we presented here and kind of take",
    "start": "1042559",
    "end": "1044319"
  },
  {
    "text": "a zoomed out approach",
    "start": "1044319",
    "end": "1045678"
  },
  {
    "text": "we'll see that uh within racer",
    "start": "1045679",
    "end": "1049200"
  },
  {
    "text": "we were able to leverage a lot of the",
    "start": "1049200",
    "end": "1051120"
  },
  {
    "text": "existing functionality and features that",
    "start": "1051120",
    "end": "1052880"
  },
  {
    "text": "they had",
    "start": "1052880",
    "end": "1053600"
  },
  {
    "text": "to meet our own goals and if we were to",
    "start": "1053600",
    "end": "1056000"
  },
  {
    "text": "kind of go back to what those were",
    "start": "1056000",
    "end": "1057600"
  },
  {
    "text": "we're enabling a highly interactive data",
    "start": "1057600",
    "end": "1060320"
  },
  {
    "text": "pipelining solution",
    "start": "1060320",
    "end": "1061440"
  },
  {
    "text": "as well as a highly scalable data",
    "start": "1061440",
    "end": "1063440"
  },
  {
    "text": "pipelining solution",
    "start": "1063440",
    "end": "1064799"
  },
  {
    "text": "that adapts user demand and user",
    "start": "1064799",
    "end": "1066799"
  },
  {
    "text": "requests and within our kubernetes",
    "start": "1066799",
    "end": "1069039"
  },
  {
    "text": "system",
    "start": "1069039",
    "end": "1069520"
  },
  {
    "text": "we were able to work with the",
    "start": "1069520",
    "end": "1071280"
  },
  {
    "text": "fundamental concepts of kubernetes and",
    "start": "1071280",
    "end": "1073360"
  },
  {
    "text": "integrate those",
    "start": "1073360",
    "end": "1074320"
  },
  {
    "text": "with a lot of the functionality that",
    "start": "1074320",
    "end": "1075679"
  },
  {
    "text": "racers provide provided us to let us",
    "start": "1075679",
    "end": "1077840"
  },
  {
    "text": "make that happen",
    "start": "1077840",
    "end": "1078960"
  },
  {
    "text": "so that's the current state of our",
    "start": "1078960",
    "end": "1080960"
  },
  {
    "text": "system right now",
    "start": "1080960",
    "end": "1082080"
  },
  {
    "text": "and i'll pass it back to jay so he can",
    "start": "1082080",
    "end": "1083919"
  },
  {
    "text": "discuss some of the",
    "start": "1083919",
    "end": "1085280"
  },
  {
    "text": "options and cool features that we're",
    "start": "1085280",
    "end": "1087039"
  },
  {
    "text": "looking to implement in the future",
    "start": "1087039",
    "end": "1089360"
  },
  {
    "text": "right thanks amar so as mark said uh",
    "start": "1089360",
    "end": "1092480"
  },
  {
    "text": "these are how we're how we implemented a",
    "start": "1092480",
    "end": "1095200"
  },
  {
    "text": "cop with the challenge we faced with",
    "start": "1095200",
    "end": "1096640"
  },
  {
    "text": "race serve",
    "start": "1096640",
    "end": "1097360"
  },
  {
    "text": "so far and then uh i'm going to",
    "start": "1097360",
    "end": "1100080"
  },
  {
    "text": "introduce some immediate uh plan that we",
    "start": "1100080",
    "end": "1102160"
  },
  {
    "text": "have",
    "start": "1102160",
    "end": "1102720"
  },
  {
    "text": "uh potentially with race serve and rate",
    "start": "1102720",
    "end": "1104720"
  },
  {
    "text": "client",
    "start": "1104720",
    "end": "1106799"
  },
  {
    "start": "1106000",
    "end": "1106000"
  },
  {
    "text": "so uh to briefly first introduce what",
    "start": "1106799",
    "end": "1109520"
  },
  {
    "text": "ray klein is ray klein is yet another",
    "start": "1109520",
    "end": "1111520"
  },
  {
    "text": "module",
    "start": "1111520",
    "end": "1112320"
  },
  {
    "text": "uh under the ray project so ray klein",
    "start": "1112320",
    "end": "1114799"
  },
  {
    "text": "offers a remote client to connect to the",
    "start": "1114799",
    "end": "1116720"
  },
  {
    "text": "ray cluster",
    "start": "1116720",
    "end": "1117760"
  },
  {
    "text": "so it is uh more natural to dynamic test",
    "start": "1117760",
    "end": "1121200"
  },
  {
    "text": "definitions",
    "start": "1121200",
    "end": "1122000"
  },
  {
    "text": "so in our cases we need to generate the",
    "start": "1122000",
    "end": "1124960"
  },
  {
    "text": "dynamic",
    "start": "1124960",
    "end": "1126559"
  },
  {
    "text": "dag pipelines per user's request so",
    "start": "1126559",
    "end": "1130240"
  },
  {
    "text": "in that case it is really easy to",
    "start": "1130240",
    "end": "1132880"
  },
  {
    "text": "construct",
    "start": "1132880",
    "end": "1133760"
  },
  {
    "text": "like a dynamic python object inside of",
    "start": "1133760",
    "end": "1135679"
  },
  {
    "text": "the python process",
    "start": "1135679",
    "end": "1136880"
  },
  {
    "text": "but if you wanted to create a python",
    "start": "1136880",
    "end": "1140000"
  },
  {
    "text": "file",
    "start": "1140000",
    "end": "1140720"
  },
  {
    "text": "which represents a task that can be that",
    "start": "1140720",
    "end": "1143600"
  },
  {
    "text": "itself can be a hard task",
    "start": "1143600",
    "end": "1144880"
  },
  {
    "text": "so um by using ray client since",
    "start": "1144880",
    "end": "1148160"
  },
  {
    "text": "uh all those uh all this logic will stay",
    "start": "1148160",
    "end": "1151440"
  },
  {
    "text": "inside of the python process it becomes",
    "start": "1151440",
    "end": "1153600"
  },
  {
    "text": "more natural to us",
    "start": "1153600",
    "end": "1155039"
  },
  {
    "text": "um two uh it supports full ray",
    "start": "1155039",
    "end": "1158080"
  },
  {
    "text": "api um that means it again it will make",
    "start": "1158080",
    "end": "1161200"
  },
  {
    "text": "our migration extremely easier",
    "start": "1161200",
    "end": "1163919"
  },
  {
    "text": "because we don't really have to change a",
    "start": "1163919",
    "end": "1165520"
  },
  {
    "text": "lot of things so to demonstrate that",
    "start": "1165520",
    "end": "1168320"
  },
  {
    "start": "1168000",
    "end": "1168000"
  },
  {
    "text": "we have a small code snippet to",
    "start": "1168320",
    "end": "1171440"
  },
  {
    "text": "uh just to show how easy it will be for",
    "start": "1171440",
    "end": "1173440"
  },
  {
    "text": "us so let's say we have a racer",
    "start": "1173440",
    "end": "1176000"
  },
  {
    "text": "um instance definition here and then",
    "start": "1176000",
    "end": "1179200"
  },
  {
    "text": "uh you can as you can see all we need to",
    "start": "1179200",
    "end": "1181919"
  },
  {
    "text": "do",
    "start": "1181919",
    "end": "1182320"
  },
  {
    "text": "is add that one line um to connect to",
    "start": "1182320",
    "end": "1185600"
  },
  {
    "text": "the right cluster",
    "start": "1185600",
    "end": "1186400"
  },
  {
    "text": "using ray client and um the difference",
    "start": "1186400",
    "end": "1190240"
  },
  {
    "text": "uh",
    "start": "1190240",
    "end": "1190960"
  },
  {
    "text": "as a result of this what we're going to",
    "start": "1190960",
    "end": "1192799"
  },
  {
    "text": "do is not",
    "start": "1192799",
    "end": "1194240"
  },
  {
    "text": "create the python file uh that looks",
    "start": "1194240",
    "end": "1197039"
  },
  {
    "text": "like this",
    "start": "1197039",
    "end": "1197760"
  },
  {
    "text": "and submit to the array cluster but",
    "start": "1197760",
    "end": "1200000"
  },
  {
    "text": "we're going to be able to just run this",
    "start": "1200000",
    "end": "1201760"
  },
  {
    "text": "python file locally",
    "start": "1201760",
    "end": "1203280"
  },
  {
    "text": "and then the ray client would actually",
    "start": "1203280",
    "end": "1205360"
  },
  {
    "text": "run the script as if",
    "start": "1205360",
    "end": "1206720"
  },
  {
    "text": "we're already on the cluster so",
    "start": "1206720",
    "end": "1209919"
  },
  {
    "text": "as you can see it's extremely minimal",
    "start": "1209919",
    "end": "1211679"
  },
  {
    "text": "changes to utilize the full ray api",
    "start": "1211679",
    "end": "1215519"
  },
  {
    "start": "1214000",
    "end": "1214000"
  },
  {
    "text": "so with this um one change we're going",
    "start": "1215919",
    "end": "1218080"
  },
  {
    "text": "to have with the our corporate's cluster",
    "start": "1218080",
    "end": "1220480"
  },
  {
    "text": "since um we had a in-house solution",
    "start": "1220480",
    "end": "1223280"
  },
  {
    "text": "raised surf manager and that was the",
    "start": "1223280",
    "end": "1224960"
  },
  {
    "text": "only micro service that we enabled",
    "start": "1224960",
    "end": "1227600"
  },
  {
    "text": "inside of our service cluster to talk to",
    "start": "1227600",
    "end": "1229840"
  },
  {
    "text": "the raid cluster",
    "start": "1229840",
    "end": "1232000"
  },
  {
    "text": "but with ray client ray client installed",
    "start": "1232000",
    "end": "1234799"
  },
  {
    "text": "inside of all the microservices we have",
    "start": "1234799",
    "end": "1236880"
  },
  {
    "text": "uh we don't necessarily have to lay that",
    "start": "1236880",
    "end": "1239520"
  },
  {
    "text": "limitation",
    "start": "1239520",
    "end": "1240400"
  },
  {
    "text": "for all the microservices um we don't",
    "start": "1240400",
    "end": "1243440"
  },
  {
    "text": "like as in like we don't have to go",
    "start": "1243440",
    "end": "1245039"
  },
  {
    "text": "through",
    "start": "1245039",
    "end": "1245520"
  },
  {
    "text": "race serv manager every time when we",
    "start": "1245520",
    "end": "1248400"
  },
  {
    "text": "want to talk to the",
    "start": "1248400",
    "end": "1249520"
  },
  {
    "text": "race cluster or race serve instances",
    "start": "1249520",
    "end": "1252159"
  },
  {
    "text": "which",
    "start": "1252159",
    "end": "1252559"
  },
  {
    "text": "itself can be a bottleneck so with this",
    "start": "1252559",
    "end": "1256080"
  },
  {
    "text": "all microservices and python workers",
    "start": "1256080",
    "end": "1258000"
  },
  {
    "text": "have access to record and serve",
    "start": "1258000",
    "end": "1260159"
  },
  {
    "text": "makes us run more of a natural micro",
    "start": "1260159",
    "end": "1263200"
  },
  {
    "text": "service environment",
    "start": "1263200",
    "end": "1266000"
  },
  {
    "text": "this concludes our talk um thank you",
    "start": "1266080",
    "end": "1268720"
  },
  {
    "text": "very much",
    "start": "1268720",
    "end": "1269840"
  },
  {
    "text": "uh to edward and any scale to help us",
    "start": "1269840",
    "end": "1272400"
  },
  {
    "text": "tremendously along the process",
    "start": "1272400",
    "end": "1274559"
  },
  {
    "text": "and we're here for the q a for sure",
    "start": "1274559",
    "end": "1277600"
  },
  {
    "text": "for a while",
    "start": "1277600",
    "end": "1283760"
  }
]
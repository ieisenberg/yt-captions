[
  {
    "text": "hello everyone so thanks for coming to the talk in this section we are going to talk about the challenge of doing",
    "start": "4880",
    "end": "10800"
  },
  {
    "text": "machine learning in Samsung specifically how we build a machine learning platform to overcome some of these challenges",
    "start": "10800",
    "end": "17880"
  },
  {
    "text": "so my name is Pang I'm the tech lead of samsara's machine learning infrastructure team and please also",
    "start": "17880",
    "end": "23160"
  },
  {
    "text": "allow me to introduce my colleague sharab and Sharad so syrup is a senior machine learning",
    "start": "23160",
    "end": "28500"
  },
  {
    "text": "engineer in our machine learning infrastructure team as well so he builds the workflow orchestration framework in",
    "start": "28500",
    "end": "34200"
  },
  {
    "text": "the platform so he will cover that in this presentation and Sharon is one of our early members in the samsara's",
    "start": "34200",
    "end": "40440"
  },
  {
    "text": "computer vision team he developed many of themselves AI feature in the early stage of the company he will cover a",
    "start": "40440",
    "end": "47100"
  },
  {
    "text": "model optimization use case with same Source iot device in",
    "start": "47100",
    "end": "52379"
  },
  {
    "text": "the loop in the last part of this presentation all right let's talk about the company",
    "start": "52379",
    "end": "57420"
  },
  {
    "text": "so what is samsara um Samsung is the Pioneer of the connected operation Cloud so we are",
    "start": "57420",
    "end": "63239"
  },
  {
    "text": "digitizing the world of physical operation so sync everything from energy utility food delivery to transportation",
    "start": "63239",
    "end": "70320"
  },
  {
    "text": "and warehousing our platform makes our customer easy to act on iot data from locations like Warehouse trucks and",
    "start": "70320",
    "end": "78119"
  },
  {
    "text": "heavy equipment which ultimately will help them run safer more efficient and",
    "start": "78119",
    "end": "83340"
  },
  {
    "text": "more sustainable operations so now we know the company let's talk about the challenge of doing machine",
    "start": "83340",
    "end": "90299"
  },
  {
    "text": "learning in Samsung which is establishing the data for iview and that challenge actually comes from a",
    "start": "90299",
    "end": "96240"
  },
  {
    "text": "combination of three aspects so the resource constrained on the edge the data imbalance due to the nature of the",
    "start": "96240",
    "end": "102060"
  },
  {
    "text": "problem we are trying to tackle and the scale required to process unstructured sensor data so first of all let's talk",
    "start": "102060",
    "end": "109200"
  },
  {
    "text": "about resource constraint so awesome Source data coming from the iot devices we built and many people think like",
    "start": "109200",
    "end": "116540"
  },
  {
    "text": "resource constraint on iot device only impact machine learning inference because it has limited capacity but they",
    "start": "116540",
    "end": "122759"
  },
  {
    "text": "overlooked its impact on data collection because while dealing with constraint on inference maybe it's a problem you know",
    "start": "122759",
    "end": "129420"
  },
  {
    "text": "an optimization problem we can deal in a later stage of machine learning project but if we are not being able to collect",
    "start": "129420",
    "end": "136020"
  },
  {
    "text": "data we can the machine learning project could be killed in the early ideation stage so one such example is in our AI",
    "start": "136020",
    "end": "142800"
  },
  {
    "text": "dash cam we can't really stream all the data to the cloud due to the cost of maintaining a reliable Cellular",
    "start": "142800",
    "end": "148560"
  },
  {
    "text": "Connection and another example is if we wake up the device too frequently such as for the shake of upload the data it",
    "start": "148560",
    "end": "155520"
  },
  {
    "text": "can kill the battery or it can drain the vehicle's battery that the device plugs in and nobody want to see a dead battery",
    "start": "155520",
    "end": "162480"
  },
  {
    "text": "in their car so the Second Challenge comes from the future we are trying to develop so many of our products are",
    "start": "162480",
    "end": "169200"
  },
  {
    "text": "targeted at detecting unsafe operation Behavior like distracted driving or",
    "start": "169200",
    "end": "174840"
  },
  {
    "text": "tailgating and these events are real in life and difficult to collect by itself",
    "start": "174840",
    "end": "180900"
  },
  {
    "text": "so the third challenge is coming from the scale of processing unstructured sensor data so given the first two",
    "start": "180900",
    "end": "187200"
  },
  {
    "text": "challenge to get enough data point to boost up our project one common Technique we usually use is analyze",
    "start": "187200",
    "end": "193560"
  },
  {
    "text": "multiple stream of sensor data and maybe at that stage we run some machine learning model to detect the interesting",
    "start": "193560",
    "end": "199800"
  },
  {
    "text": "data point and then join them together to figure out the interesting interview we want to either use the data point or",
    "start": "199800",
    "end": "207599"
  },
  {
    "text": "further request any more data point and such a process actually require to build a large scale and also very complex data",
    "start": "207599",
    "end": "214800"
  },
  {
    "text": "processing pipeline all right so then how ready help this is race amid we got to talk something about",
    "start": "214800",
    "end": "221940"
  },
  {
    "text": "rate so first the first thing we are excited about Ray is obviously its capability to scale so with Ray we can",
    "start": "221940",
    "end": "228780"
  },
  {
    "text": "scale our experiment to hundreds of millions of input images with the code that originally developed and test on",
    "start": "228780",
    "end": "234900"
  },
  {
    "text": "the laptop and another thing we like Ray is its ability to improve the um a complex",
    "start": "234900",
    "end": "242700"
  },
  {
    "text": "workflow or you know in another world called AI productivity so this is",
    "start": "242700",
    "end": "247920"
  },
  {
    "text": "something I learned next year today earlier from our keynote um so as everybody know machine learning",
    "start": "247920",
    "end": "253379"
  },
  {
    "text": "development is not just about training the models right so data processing Hardware in the loop optimization and",
    "start": "253379",
    "end": "259799"
  },
  {
    "text": "also offline and online evaluation also online inference is also an integral part of our machine learning life cycle",
    "start": "259799",
    "end": "266160"
  },
  {
    "text": "we saw race ecosystem this process would have to be implemented through multiple",
    "start": "266160",
    "end": "271320"
  },
  {
    "text": "platforms which requires significant work to build and integrate and also the sign is when they work on this project",
    "start": "271320",
    "end": "277320"
  },
  {
    "text": "they have to hop through multiple platform to finish some simple tasks",
    "start": "277320",
    "end": "283380"
  },
  {
    "text": "and this is a high-level architecture that um of our machine learning platform and",
    "start": "283380",
    "end": "289500"
  },
  {
    "text": "machine learning stages is support so the boxes in the upper part I'm not sure if you guys can read it is the machine",
    "start": "289500",
    "end": "296580"
  },
  {
    "text": "learning life cycle um stages and the boxes in the Lower Side are the tools we use and especially",
    "start": "296580",
    "end": "303479"
  },
  {
    "text": "the blue boxes here is the place we use rate as one may already see so we use",
    "start": "303479",
    "end": "309960"
  },
  {
    "text": "rate across the board so in some cases like data processing Ray is used as a",
    "start": "309960",
    "end": "316020"
  },
  {
    "text": "compute orchestration framework supporting the actual processing engine like Apache spark we will cover later on",
    "start": "316020",
    "end": "322380"
  },
  {
    "text": "how we do that in the presentation and on other ml Focus areas like model training Ray is directly used as the API",
    "start": "322380",
    "end": "329580"
  },
  {
    "text": "and computation framework and for online inference my colleague Brian will cover that in another talk around 5 15 pm",
    "start": "329580",
    "end": "337259"
  },
  {
    "text": "today and I encourage everybody to go and check it out so in the following section we will deep dive into use case",
    "start": "337259",
    "end": "344699"
  },
  {
    "text": "how Ray is used in our platform so first thing first data processing",
    "start": "344699",
    "end": "351120"
  },
  {
    "text": "so rate itself comes with a a pretty good data processing capability however",
    "start": "351120",
    "end": "356940"
  },
  {
    "text": "sometimes we still need we figure out ourselves we still need more in our setup because the need to join you know",
    "start": "356940",
    "end": "363720"
  },
  {
    "text": "while doing doing the feature extraction on processing sensor unfortunately there",
    "start": "363720",
    "end": "369600"
  },
  {
    "text": "are many ways to do that using race ecosystem so in our way we choose to run",
    "start": "369600",
    "end": "374820"
  },
  {
    "text": "spark on Ray because it's easier to integrate with the remaining data stack in samsara so spark on Ray is actually",
    "start": "374820",
    "end": "381900"
  },
  {
    "text": "enabled by a library called ADP which is developed in Open Source by Intel the",
    "start": "381900",
    "end": "387300"
  },
  {
    "text": "idea behind radp is pretty simple it combines part and Ray cluster so we can do data processing and later on training",
    "start": "387300",
    "end": "393960"
  },
  {
    "text": "in one python script and using the this project is pretty straightforward as you",
    "start": "393960",
    "end": "399180"
  },
  {
    "text": "can see here you just do pip install ADP and then connect to the raid cluster",
    "start": "399180",
    "end": "404460"
  },
  {
    "text": "which is pretty standard and then called radp init spark and feed the spark",
    "start": "404460",
    "end": "410699"
  },
  {
    "text": "parameter into the function and then you get back the spark section so once you get um get back the spark section",
    "start": "410699",
    "end": "418319"
  },
  {
    "text": "um everything follows naturally so I just take the um the NYC text example",
    "start": "418319",
    "end": "423720"
  },
  {
    "text": "from the radp project for the shakeup demo as you can see here it first ingests the data by loading a CSV file",
    "start": "423720",
    "end": "430800"
  },
  {
    "text": "but in your environment you can totally you know read the data from the data Lake wherever the place you want and",
    "start": "430800",
    "end": "437639"
  },
  {
    "text": "then once you get the data frame you just do whatever data processing you want and then you can convert that smart",
    "start": "437639",
    "end": "444300"
  },
  {
    "text": "data frame to a ray data set and then further feed into the training framework that Ray provides",
    "start": "444300",
    "end": "452539"
  },
  {
    "text": "so and how does it work under the hood so under the hood all the spark executor",
    "start": "452759",
    "end": "458520"
  },
  {
    "text": "and Driver are scheduled as the actor as a ray actor and schedule by rate and all",
    "start": "458520",
    "end": "464220"
  },
  {
    "text": "these things are taken care of by by ADP on the library ADP",
    "start": "464220",
    "end": "470340"
  },
  {
    "text": "however with this setup there is one glitch so spark has this concept of",
    "start": "470340",
    "end": "475560"
  },
  {
    "text": "driver and executor which the driver actually maintained the the cluster however when you schedule the driver act",
    "start": "475560",
    "end": "482880"
  },
  {
    "text": "on Ray Ray doesn't has this knowledge so your driver connector can land on a sport machine which can be get",
    "start": "482880",
    "end": "489479"
  },
  {
    "text": "terminated at any time so when the sport match are when the driver die basically your job your job will start and it's",
    "start": "489479",
    "end": "496020"
  },
  {
    "text": "not recoverable so to to overcome this problem we make a",
    "start": "496020",
    "end": "502800"
  },
  {
    "text": "contribution to the ray DP project which is the idea is we allow the developer to",
    "start": "502800",
    "end": "509699"
  },
  {
    "text": "specify where they should schedule the traffic and executor using the custom",
    "start": "509699",
    "end": "515640"
  },
  {
    "text": "resource annotation so as you can see here so first of all before we launch in the ray cluster we let the user to",
    "start": "515640",
    "end": "524820"
  },
  {
    "text": "Define custom resource on the different machine types so in this case we say",
    "start": "524820",
    "end": "532080"
  },
  {
    "text": "once type of machine is spark Master one type machine has custom resource spark executor and then when launching the",
    "start": "532080",
    "end": "540540"
  },
  {
    "text": "spark job we use two radp configuration to basically tell Ray",
    "start": "540540",
    "end": "547980"
  },
  {
    "text": "hey for spark master or for the driver actor please put them on the machine",
    "start": "547980",
    "end": "553140"
  },
  {
    "text": "that with the spark Master annotation and optionally optionally you can also",
    "start": "553140",
    "end": "558660"
  },
  {
    "text": "tell ADP to put spark executor into the into the executor machine and also",
    "start": "558660",
    "end": "566399"
  },
  {
    "text": "another another trick you can make here is as you can see the spot executor actually occupy one resource in fact you",
    "start": "566399",
    "end": "574140"
  },
  {
    "text": "can also specify like say um spark executor actor.resource.cpu to a fraction of the",
    "start": "574140",
    "end": "580980"
  },
  {
    "text": "CPU resource so to achieve CPU over subscription because CPU also work as a",
    "start": "580980",
    "end": "587519"
  },
  {
    "text": "as a regular resource in this case all right so that's it for data",
    "start": "587519",
    "end": "594600"
  },
  {
    "text": "processing so I would turn the presentation to show up to talk about our machine learning workflow",
    "start": "594600",
    "end": "601519"
  },
  {
    "text": "awesome thanks man my name is saurabh I'm a senior machine learning engineer at samsara and I'm going to walk you",
    "start": "604500",
    "end": "609660"
  },
  {
    "text": "through how we build or develop the orchestration platform at samsara so when we started building it out we",
    "start": "609660",
    "end": "616320"
  },
  {
    "text": "had a key requirements in our mind we wanted to keep track of the data lineage as well as the code lineage you wanted to support local development and",
    "start": "616320",
    "end": "622680"
  },
  {
    "text": "debugging you wanted to make sure there's dependency isolation between the pipelines we want to have the",
    "start": "622680",
    "end": "627899"
  },
  {
    "text": "orchestration system be container native and we wanted to also have like an easy to use GUI so then we started evaluating",
    "start": "627899",
    "end": "635220"
  },
  {
    "text": "all the available orchestration Frameworks on these parameters and the one that stood out was darkster Daxter",
    "start": "635220",
    "end": "642240"
  },
  {
    "text": "is an open source orchestration system it's really feature Rich it's developed by the elemental team and if you guys",
    "start": "642240",
    "end": "648720"
  },
  {
    "text": "haven't checked it out already I'd encourage you to go and check it out uh so Daxter was the chosen orchestration",
    "start": "648720",
    "end": "654480"
  },
  {
    "text": "engine for us and we started onboarding pipelines on top of dagster uh and",
    "start": "654480",
    "end": "659880"
  },
  {
    "text": "that's where we uh basically got the first gotcha which was uh even though",
    "start": "659880",
    "end": "665220"
  },
  {
    "text": "daksu is like really easy to use and it has a very good set of documentation but there's still a bit of a learning curve",
    "start": "665220",
    "end": "671459"
  },
  {
    "text": "and it just sounded counterintuitive to us like why should our scientist be required to learn a new technology if he",
    "start": "671459",
    "end": "677579"
  },
  {
    "text": "has to you know basically set up a workflow and that's where the whole concept of this",
    "start": "677579",
    "end": "683459"
  },
  {
    "text": "declarative workflow definition came in so the idea is that the scientist should just be able to tell us that okay as",
    "start": "683459",
    "end": "690180"
  },
  {
    "text": "part of this pipeline I need to run these these tasks and I need to run this at this particular Cadence and that should be about it and that was",
    "start": "690180",
    "end": "697620"
  },
  {
    "text": "basically the Genesis of Ulster Ulster is a python wrapper which works on top of blackster and what it does it",
    "start": "697620",
    "end": "704820"
  },
  {
    "text": "offers a yaml based interface for the scientists to basically specify his pipeline without using any code it also",
    "start": "704820",
    "end": "712019"
  },
  {
    "text": "comes in with it it also supports one click deploy it also supports out of the box alerting and monitoring but the main",
    "start": "712019",
    "end": "718500"
  },
  {
    "text": "use case is that you can Define your pipeline completely in yaml without any code so now let's look at what an Ulster",
    "start": "718500",
    "end": "725940"
  },
  {
    "text": "config looks like what the yaml file looks like it majorly has three sections first the alerts the alert section",
    "start": "725940",
    "end": "731339"
  },
  {
    "text": "basically tells you who do you want to alert or and how do",
    "start": "731339",
    "end": "736440"
  },
  {
    "text": "you want to alert in case uh or basically the status of your job the second is the schedule section which",
    "start": "736440",
    "end": "741540"
  },
  {
    "text": "basically tells you what is the Cadence with which you want to run the job you can also specify the time zone in which you want to run the job and the third is",
    "start": "741540",
    "end": "747779"
  },
  {
    "text": "the op section this is the real meat of it this is where the scientist defines what all are the tasks that he needs to",
    "start": "747779",
    "end": "752940"
  },
  {
    "text": "run as part of the pipeline so let's ah look closely on the op section on the left hand side you see the Ops",
    "start": "752940",
    "end": "760019"
  },
  {
    "text": "template it basically has every entry in here is essentially a task and each task",
    "start": "760019",
    "end": "765180"
  },
  {
    "text": "essentially maps to a python function so start Ray cluster and the re-execute function start request essentially maps",
    "start": "765180",
    "end": "771000"
  },
  {
    "text": "to a python function which will start array Crystal for you to re-execute maps to a python function which will execute",
    "start": "771000",
    "end": "776579"
  },
  {
    "text": "a command on the rate cluster so the and then again you pipeline can have multiple Ray clusters you can have",
    "start": "776579",
    "end": "782459"
  },
  {
    "text": "multiple commands that you want to execute on it so you make use of aliases to uniquely identify which task is",
    "start": "782459",
    "end": "787800"
  },
  {
    "text": "corresponds to which python function all right so the first thing that we need to do is build a dependency graph",
    "start": "787800",
    "end": "794279"
  },
  {
    "text": "the thing that you see on your right hand side How We Do It uh as I said everything like re-execute it maps to a",
    "start": "794279",
    "end": "801180"
  },
  {
    "text": "python function so it will have some input will perform some logic and spit out some output so the key idea here is",
    "start": "801180",
    "end": "807000"
  },
  {
    "text": "that as long as I'm able to map output of a different of a function with an input of this Ray execute function I'd",
    "start": "807000",
    "end": "813480"
  },
  {
    "text": "be able to set up this dependency graph or this stack so in this particular case cluster IP is an input and it knows that",
    "start": "813480",
    "end": "820380"
  },
  {
    "text": "it needs to get it from this data set operation cluster so it knows it needs to execute it before it executes its own rate training data then you look at the",
    "start": "820380",
    "end": "827160"
  },
  {
    "text": "execute command and we see we need to get the start date and end date from this get run dates function so it knows it needs to run get run it before it",
    "start": "827160",
    "end": "833839"
  },
  {
    "text": "executes the generate training data and this is how basically we set up this dependency graph now there could be a",
    "start": "833839",
    "end": "839339"
  },
  {
    "text": "case where there is no explicit dependency passing between the two",
    "start": "839339",
    "end": "844560"
  },
  {
    "text": "between the two functions so in case of published data set and generating data there is no explicit parameter that is",
    "start": "844560",
    "end": "850800"
  },
  {
    "text": "being passed but you can use the substance command and say like okay you know what just make sure that you run this generate training Data before you",
    "start": "850800",
    "end": "856740"
  },
  {
    "text": "run the publish data set so this is pretty much how we set up the this particular dag or the dependency",
    "start": "856740",
    "end": "862200"
  },
  {
    "text": "graph now let's look at the Ops now we already said that Ops is essentially",
    "start": "862200",
    "end": "868260"
  },
  {
    "text": "maps to a python function ah so based on the how these python functions are defined we classify Ops as on the Fly",
    "start": "868260",
    "end": "874620"
  },
  {
    "text": "Ops or predefined Ops let's look at the on the Fly Ops on the Fly Ops are the Ops for which the python function is not",
    "start": "874620",
    "end": "881220"
  },
  {
    "text": "predefined it is something which gets generated on the fly so we consume this template and we create a python function",
    "start": "881220",
    "end": "888720"
  },
  {
    "text": "for this particular task on the Fly how we do it is we basically look at this execute command we see that oh it needs",
    "start": "888720",
    "end": "894779"
  },
  {
    "text": "this output table argument and how do we get the output table argument we need to combine this database and table name to",
    "start": "894779",
    "end": "901500"
  },
  {
    "text": "get this thing function we look at the filter argument and see we need to get this started and then date from this get",
    "start": "901500",
    "end": "907139"
  },
  {
    "text": "run dates function in order to compose this filter argument So based on this we",
    "start": "907139",
    "end": "912779"
  },
  {
    "text": "create a python function which essentially takes these four inputs and in the logic part of it we basically",
    "start": "912779",
    "end": "918120"
  },
  {
    "text": "make sure that we are able to concatenate these inputs in the way it's defined in the template and we execute",
    "start": "918120",
    "end": "924720"
  },
  {
    "text": "basically this particular job on array cluster all right I just wanted to highlight",
    "start": "924720",
    "end": "930839"
  },
  {
    "text": "like if you see like the flexibility with which you can Define the arguments and flexibility with which you can use",
    "start": "930839",
    "end": "937500"
  },
  {
    "text": "it it kind of shows like okay you know this platform how cable this platform is",
    "start": "937500",
    "end": "943199"
  },
  {
    "text": "the next set of Ops are the predefined ones here uh their python definition is",
    "start": "943199",
    "end": "948720"
  },
  {
    "text": "predefined so you don't really have to worry about par single or basically writing the signature of the function or",
    "start": "948720",
    "end": "953940"
  },
  {
    "text": "writing the logic of the function but but it poses a different kind of a challenge the challenge is if you look",
    "start": "953940",
    "end": "959339"
  },
  {
    "text": "at this input parameter batch name it's it's one input but what it does it essentially takes outputs from three",
    "start": "959339",
    "end": "965339"
  },
  {
    "text": "different places and combines it in a in an arbitrary fashion so ah in order to",
    "start": "965339",
    "end": "972120"
  },
  {
    "text": "overcome that we basically make use of wrappers and hooks to make sure that we still support this functionality now it",
    "start": "972120",
    "end": "978839"
  },
  {
    "text": "might look like redundant of specifying past name like this but if you just think about like how we Define filters",
    "start": "978839",
    "end": "984300"
  },
  {
    "text": "in the last function in the last slide you can see the amount of flexibility it offers for you to Define ah predefined",
    "start": "984300",
    "end": "990540"
  },
  {
    "text": "function as well as the flexibility in which you can use it so now to wrap it up I'll just gonna showcase the entire",
    "start": "990540",
    "end": "997560"
  },
  {
    "text": "workflow how all certain tax to basically work with each other and yeah provide the seamless experience to the",
    "start": "997560",
    "end": "1003620"
  },
  {
    "text": "scientist so it all begins with the yaml file the config with the scientist defines also package basically consumes",
    "start": "1003620",
    "end": "1010100"
  },
  {
    "text": "it it passes the template it presses the dependency graph it generates all the on the Fly apps and what it does it passes",
    "start": "1010100",
    "end": "1016100"
  },
  {
    "text": "this python function and the dependency graph to dagster the inductor does its magic it sets everything up creates a",
    "start": "1016100",
    "end": "1022820"
  },
  {
    "text": "great UI and make sure all the jobs are run at the right time it also takes care of passing the parameters between the",
    "start": "1022820",
    "end": "1029058"
  },
  {
    "text": "functions and the next stage when we have the parameters also kicks in again and it",
    "start": "1029059",
    "end": "1034220"
  },
  {
    "text": "makes sure we're able to combine these inputs in the way it's defined in the template it also takes care of launching",
    "start": "1034220",
    "end": "1040819"
  },
  {
    "text": "and running Ray jobs managing 3D cluster and once the job succeeds also is responsible for alerting logging",
    "start": "1040819",
    "end": "1048079"
  },
  {
    "text": "and monitoring all right so this is pretty much how we build a completely no code yaml based",
    "start": "1048079",
    "end": "1053660"
  },
  {
    "text": "workflow solution orchestration solution for sansara next I'll let Sharon walk us through a",
    "start": "1053660",
    "end": "1060020"
  },
  {
    "text": "model optimization use case",
    "start": "1060020",
    "end": "1063340"
  },
  {
    "text": "thanks saurabh thanks hi everyone um so aspang and saurabh mentioned Ray has been really pivotal to samsara and",
    "start": "1066919",
    "end": "1073340"
  },
  {
    "text": "how we build our CV applications given all the foundational aspects that they've spoken about I wanted to spend a",
    "start": "1073340",
    "end": "1079700"
  },
  {
    "text": "little bit of time speaking through one of the applications where is helped us enormously in specific given that",
    "start": "1079700",
    "end": "1085940"
  },
  {
    "text": "samsara really wants to advance towards building a connected operations Cloud I",
    "start": "1085940",
    "end": "1091340"
  },
  {
    "text": "wanted to speak a little bit something unique that blends Ray and samsara together which is about how we do hyper",
    "start": "1091340",
    "end": "1097100"
  },
  {
    "text": "parameter tuning with device in the loop so when we think of samsara the first",
    "start": "1097100",
    "end": "1103700"
  },
  {
    "text": "thing that comes for a computer vision engineer is the dash cam the dash cam is nothing but a camera that's mounted on",
    "start": "1103700",
    "end": "1109820"
  },
  {
    "text": "our devices it's mostly dual facing pointing towards the road and towards the driver and it helps us Advance our",
    "start": "1109820",
    "end": "1117020"
  },
  {
    "text": "mission to improve driver safety so it looks as the road and tries to identify risky driving behavior looks at the",
    "start": "1117020",
    "end": "1122660"
  },
  {
    "text": "driver trying to make sure that the driver is alert and improve their quality of driving overall these cameras",
    "start": "1122660",
    "end": "1128360"
  },
  {
    "text": "are mounted on on thousands of vehicles that run every day on the road and they power all these CV applications that",
    "start": "1128360",
    "end": "1135080"
  },
  {
    "text": "we're speaking about needless to say they are mission critical when it comes to driving safety for us",
    "start": "1135080",
    "end": "1140299"
  },
  {
    "text": "all our computer vision applications that we build are deployed on the camera very few of them live outside but the",
    "start": "1140299",
    "end": "1147980"
  },
  {
    "text": "primary ones that govern safety live breathe and operate on the camera themselves and when we think of models that are",
    "start": "1147980",
    "end": "1155360"
  },
  {
    "text": "operating on the edge immediately the things that come to mind are the characteristics that define",
    "start": "1155360",
    "end": "1161059"
  },
  {
    "text": "these processes so when we think of computer vision applications on our dash cam we know that these applications",
    "start": "1161059",
    "end": "1167720"
  },
  {
    "text": "don't have the same leeway as they would on traditional Cloud platforms they have to run on power constrained environments",
    "start": "1167720",
    "end": "1174380"
  },
  {
    "text": "they have to pay heed to anything related to thermals and memory thermals has been a plague a pain in our Arsenal",
    "start": "1174380",
    "end": "1181700"
  },
  {
    "text": "forever to making sure that the devices don't get overheated when we run run our models we can't throw the biggest",
    "start": "1181700",
    "end": "1187640"
  },
  {
    "text": "baddest model out there into the camera and we really have to be mindful about what we put in and and the various",
    "start": "1187640",
    "end": "1193100"
  },
  {
    "text": "changes that we need to make sure that these models run on the camera the day any application that we build",
    "start": "1193100",
    "end": "1199280"
  },
  {
    "text": "needs to be profiled to understand how they run on the camera versus how they would traditionally on the cloud we need",
    "start": "1199280",
    "end": "1205280"
  },
  {
    "text": "to optimize it so that they run on the camera better and not just optimize it for the cloud and hope that they would",
    "start": "1205280",
    "end": "1210320"
  },
  {
    "text": "run on the camera and eventually we also need to monitor these on the field so we make so we know",
    "start": "1210320",
    "end": "1216500"
  },
  {
    "text": "that they're performing as we hope all in all we needed a system that helps us build deploy maintain and observe",
    "start": "1216500",
    "end": "1223760"
  },
  {
    "text": "these models on device rather than elsewhere",
    "start": "1223760",
    "end": "1228760"
  },
  {
    "text": "so back in the early days of samsara models were a lot simpler processes were a lot more fluid",
    "start": "1229100",
    "end": "1235660"
  },
  {
    "text": "well the company was definitely smaller we could definitely patch together a bunch of work to make sure that models",
    "start": "1235660",
    "end": "1241460"
  },
  {
    "text": "data processes could run on the camera and there and they ran fine but as I mean everything is meant to",
    "start": "1241460",
    "end": "1248539"
  },
  {
    "text": "break at some point and as life goes some things are just good from far but far from good So eventually things break",
    "start": "1248539",
    "end": "1255260"
  },
  {
    "text": "and for a hyper Growth Company like samsara when scale hits us having these patchworks doesn't help and",
    "start": "1255260",
    "end": "1262280"
  },
  {
    "text": "that's where a came in to help us before we get into that I wanted to point out what the specific challenges",
    "start": "1262280",
    "end": "1267919"
  },
  {
    "text": "were when we when we went through this journey of moving from low scale to high",
    "start": "1267919",
    "end": "1273380"
  },
  {
    "text": "scale and in a very short span of time nearly two years when we think of pushing models onto the",
    "start": "1273380",
    "end": "1279620"
  },
  {
    "text": "device these models have to live on multiple thousands of devices and they need to",
    "start": "1279620",
    "end": "1285020"
  },
  {
    "text": "live on those devices almost asynchronously so models data and anything related to",
    "start": "1285020",
    "end": "1291080"
  },
  {
    "text": "Pipeline and orchestration needs to be moved from wherever they're defined to the device where you want to run them",
    "start": "1291080",
    "end": "1296480"
  },
  {
    "text": "profile them and observe them when we do this and when we think of devices the same runtime selection challenges",
    "start": "1296480",
    "end": "1305299"
  },
  {
    "text": "are persistent there as well so we need to understand whether we want to run them on a CPU which is fairly accurate",
    "start": "1305900",
    "end": "1311419"
  },
  {
    "text": "but low GPU which are just power hungry monsters when we think of them on edge devices or dsps which are which are far",
    "start": "1311419",
    "end": "1317960"
  },
  {
    "text": "less detrimental to power and thermals but are far far less accurate when we think of quantized models",
    "start": "1317960",
    "end": "1324980"
  },
  {
    "text": "these models also need to be running with an elastic processes so that we can",
    "start": "1324980",
    "end": "1330140"
  },
  {
    "text": "scale them from two devices to 20 000 devices at the same time and while scaling we also need to make sure that",
    "start": "1330140",
    "end": "1335960"
  },
  {
    "text": "they're not that they're very fault tolerant we don't want trial failing somewhere affecting",
    "start": "1335960",
    "end": "1341059"
  },
  {
    "text": "everything else we want to make sure that all all our processes are well monitored versioned and and anytime",
    "start": "1341059",
    "end": "1347000"
  },
  {
    "text": "there's a failure we know we want to pick back up wherever wherever we left off and to do all this from doing scripts",
    "start": "1347000",
    "end": "1354500"
  },
  {
    "text": "meant we really wanted something out of the box so that we could focus on the product and rather than the process of",
    "start": "1354500",
    "end": "1359780"
  },
  {
    "text": "how we do this and that's where Ray really came in and helped us um in this slide I'd like to talk a",
    "start": "1359780",
    "end": "1366140"
  },
  {
    "text": "little bit about a high level view of the architecture of how we use Ray to do",
    "start": "1366140",
    "end": "1371240"
  },
  {
    "text": "hyper parameter tuning on the device so as with any array system we have a head node that defines what trials we",
    "start": "1371240",
    "end": "1378260"
  },
  {
    "text": "want to launch and we have worker pods the only difference between our worker pods and something more traditional that",
    "start": "1378260",
    "end": "1383780"
  },
  {
    "text": "will run on on Andre would be that our worker pods are linked to cameras these cameras are where the models run",
    "start": "1383780",
    "end": "1391280"
  },
  {
    "text": "so when we think of hyper parameter tuning we have a bunch of experiments trials that we want to run and fan out",
    "start": "1391280",
    "end": "1396620"
  },
  {
    "text": "across cameras the head node makes sure to reserve and schedule these processes on worker nodes",
    "start": "1396620",
    "end": "1402320"
  },
  {
    "text": "the worker nodes accept the model accept the data do all the conversion that's",
    "start": "1402320",
    "end": "1407419"
  },
  {
    "text": "required to run these models on device so this would be anything to do with like quantization of these models to",
    "start": "1407419",
    "end": "1414200"
  },
  {
    "text": "make sure they're runnable on the socs of our choice to prune these models to make sure the",
    "start": "1414200",
    "end": "1420020"
  },
  {
    "text": "layers and the and the pipeline parameters are defined well and make sure to transport and accept inferences",
    "start": "1420020",
    "end": "1426080"
  },
  {
    "text": "from the camera where they eventually run all this requires a bunch of orchestration",
    "start": "1426080",
    "end": "1431120"
  },
  {
    "text": "and and and and Ray really makes it really simple some of the out of the box solutions that Ray offers just makes",
    "start": "1431120",
    "end": "1438740"
  },
  {
    "text": "running jobs at scale extremely simple helps broadcast these models to devices in a very flexible manner it has a bunch",
    "start": "1438740",
    "end": "1446299"
  },
  {
    "text": "of scheduling algorithms PBT if some of you have used it to really do this whole",
    "start": "1446299",
    "end": "1451520"
  },
  {
    "text": "multi-arm Bandit of explore and exploit Which models we want to choose how and when and really prune these models as we",
    "start": "1451520",
    "end": "1457640"
  },
  {
    "text": "go along because cost is something that's relevant when we think of edge devices and running models on the edge",
    "start": "1457640",
    "end": "1464419"
  },
  {
    "text": "finally when we run these trials we also want to make sure that we version them",
    "start": "1464419",
    "end": "1469460"
  },
  {
    "text": "and store our checkpoints and restore these checkpoints when they fail some inbuilt trial mitigation and auto",
    "start": "1469460",
    "end": "1476179"
  },
  {
    "text": "scaling features that Ray offers also really helps us do this do this hyper",
    "start": "1476179",
    "end": "1481460"
  },
  {
    "text": "parameter search at scale and in almost a Mindless fashion",
    "start": "1481460",
    "end": "1486520"
  },
  {
    "text": "one example of what this looks like is given here in this in this in this",
    "start": "1486760",
    "end": "1492440"
  },
  {
    "text": "pseudo code it relates to quantization all models when we run them on devices largely by",
    "start": "1492440",
    "end": "1497960"
  },
  {
    "text": "and large we want to run them on our signal processor which accepts quantized models 8 or 16 bits",
    "start": "1497960",
    "end": "1504020"
  },
  {
    "text": "and quantization itself is a science and it has many parameters associated",
    "start": "1504020",
    "end": "1509419"
  },
  {
    "text": "with it cross layer Equalization bias correction you can name a bunch how much do we want",
    "start": "1509419",
    "end": "1514880"
  },
  {
    "text": "to quantize which layers do you want to prune Etc and when you build a model you don't know which of these are right and",
    "start": "1514880",
    "end": "1520220"
  },
  {
    "text": "wrong and which of these specifically will play well with the hardware so defining these within the landscape",
    "start": "1520220",
    "end": "1528140"
  },
  {
    "text": "of raid tune and letting them lose on our on our cameras really and and asking tune to",
    "start": "1528140",
    "end": "1534440"
  },
  {
    "text": "optimize for the right set of parameters goes a long way in finding which the best performing",
    "start": "1534440",
    "end": "1540039"
  },
  {
    "text": "setup is without putting too much thought to it um it's doing doing Brute Force",
    "start": "1540039",
    "end": "1546740"
  },
  {
    "text": "parallelism search isn't particularly cost effective in fact it's it's quite preclusive",
    "start": "1546740",
    "end": "1552320"
  },
  {
    "text": "um and using ratio really goes a long way in making sure that this is as efficient as it can get with fairly",
    "start": "1552320",
    "end": "1558020"
  },
  {
    "text": "minimal effort um so in this manner we're able to use the device in the loop while we tune for",
    "start": "1558020",
    "end": "1564799"
  },
  {
    "text": "these multiple parameters to find the best model um so before we go to q a I'll hand it",
    "start": "1564799",
    "end": "1570919"
  },
  {
    "text": "back to Pang to say a few words and then we'll head to q a thank you sir",
    "start": "1570919",
    "end": "1577520"
  },
  {
    "text": "all right so one last thing so we had uh we published a blog post for this talk",
    "start": "1577520",
    "end": "1582980"
  },
  {
    "text": "it contains you know the entire story of our building machine learning platform with Ray and also one more things um I",
    "start": "1582980",
    "end": "1590120"
  },
  {
    "text": "here I want to acknowledge our some of our scientists team who are here and who are not here maybe for the people who",
    "start": "1590120",
    "end": "1596779"
  },
  {
    "text": "sit here say hi to the rest of the audience thanks for your support and advice on building this time",
    "start": "1596779",
    "end": "1601800"
  },
  {
    "text": "[Applause] all right and also we are hiring so",
    "start": "1601800",
    "end": "1607580"
  },
  {
    "text": "cool all right so let's start a q a section",
    "start": "1607580",
    "end": "1612679"
  },
  {
    "text": "questions",
    "start": "1612679",
    "end": "1615039"
  },
  {
    "text": "um I know Rey is introducing its own workflow right are you looking or exploring into Ray workflow instead of",
    "start": "1628820",
    "end": "1635779"
  },
  {
    "text": "uh tagon or whatever yeah",
    "start": "1635779",
    "end": "1641419"
  },
  {
    "text": "right now right now the focus was to make it more like uh agnostic to what's",
    "start": "1641419",
    "end": "1649159"
  },
  {
    "text": "being used uh underneath and just expose like a yaml paste like you know no core",
    "start": "1649159",
    "end": "1654500"
  },
  {
    "text": "solution so right now we're not using it right now we're in the mode we're trying to add more and more capabilities to it",
    "start": "1654500",
    "end": "1659840"
  },
  {
    "text": "but yeah at the end of the day like the goal is at some point you're going to abstract away tax her and then we can just do a plug-and-play like if you want",
    "start": "1659840",
    "end": "1665840"
  },
  {
    "text": "to use the workflow from today you can use that or you can use Tag store you can use that or pay and flow whatever",
    "start": "1665840",
    "end": "1672500"
  },
  {
    "text": "okay thanks",
    "start": "1672500",
    "end": "1675400"
  },
  {
    "text": "When you mention the models pushed to the camera um is it correct to think that it's a",
    "start": "1678559",
    "end": "1687260"
  },
  {
    "text": "a ray actor and Ray task and that's being deployed to the camera itself so",
    "start": "1687260",
    "end": "1693200"
  },
  {
    "text": "the camera is actually part of the ray serving system so uh yes and no in some cases that can",
    "start": "1693200",
    "end": "1700460"
  },
  {
    "text": "be the case if the camera is uh if you can run python on the camera and you can run Ray on the camera in some of our",
    "start": "1700460",
    "end": "1707360"
  },
  {
    "text": "cases what we did was to keep the worker node isolated from the camera themselves",
    "start": "1707360",
    "end": "1713299"
  },
  {
    "text": "and have a reservation system in between so it's the worker node that runs as",
    "start": "1713299",
    "end": "1718820"
  },
  {
    "text": "runs the reactor which just stands out to a camera that it's reserved for itself",
    "start": "1718820",
    "end": "1724940"
  },
  {
    "text": "is the worker note on the cloud or on the camera the worker node is on the cloud",
    "start": "1724940",
    "end": "1730100"
  },
  {
    "text": "okay thank you yeah so um there is several consideration here so one is the",
    "start": "1730100",
    "end": "1735380"
  },
  {
    "text": "the cameras computation resource definitely and also the actual runtime",
    "start": "1735380",
    "end": "1740600"
  },
  {
    "text": "environment also matters because we don't say for for some setup maybe we",
    "start": "1740600",
    "end": "1745760"
  },
  {
    "text": "can definitely run Ray on the camera but that would deviate from the from the",
    "start": "1745760",
    "end": "1751640"
  },
  {
    "text": "runtime pattern we run on the field in production and we don't want that because that may also impact you know",
    "start": "1751640",
    "end": "1758179"
  },
  {
    "text": "some of the decisions we do quantization we have time for one last question",
    "start": "1758179",
    "end": "1765940"
  },
  {
    "text": "yeah so not sure if I missed it but um were there any performance benefits for using spark Andre or was it kind of just",
    "start": "1766520",
    "end": "1774640"
  },
  {
    "text": "integrating everything into the ray ecosystem that was like the main reason",
    "start": "1774640",
    "end": "1780200"
  },
  {
    "text": "yeah that's a good question so so far we don't really um see a big difference between you know",
    "start": "1780200",
    "end": "1785539"
  },
  {
    "text": "running really open source spark spark on say on top of kubernetes or on top of",
    "start": "1785539",
    "end": "1791539"
  },
  {
    "text": "Ray because at the end of the day Ray is just responsible for scarcity interactor everything is still using the native",
    "start": "1791539",
    "end": "1799520"
  },
  {
    "text": "spark framework to do the processing yeah all right that's all we have the time",
    "start": "1799520",
    "end": "1805880"
  },
  {
    "text": "for unfortunately thank you folks uh just a reminder to please go to the race Summit app if you haven't downloaded already to leave feedback for this",
    "start": "1805880",
    "end": "1812960"
  },
  {
    "text": "presentation uh but we'll look forward to see you at the next talk thank you",
    "start": "1812960",
    "end": "1819640"
  }
]
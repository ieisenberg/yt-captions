[
  {
    "text": "all right thanks Matt for the",
    "start": "2919",
    "end": "3760"
  },
  {
    "text": "introduction uh I'm very excited to be",
    "start": "3760",
    "end": "5680"
  },
  {
    "text": "giving this talk um and I just first",
    "start": "5680",
    "end": "8440"
  },
  {
    "text": "wanted to talk about a little bit about",
    "start": "8440",
    "end": "10360"
  },
  {
    "text": "uh the motivation for this talk so we",
    "start": "10360",
    "end": "12240"
  },
  {
    "text": "just announced that ra train is GA",
    "start": "12240",
    "end": "13759"
  },
  {
    "text": "yesterday and over the past year of",
    "start": "13759",
    "end": "16039"
  },
  {
    "text": "working on raid train and talking to",
    "start": "16039",
    "end": "17359"
  },
  {
    "text": "users and customers at any skill there",
    "start": "17359",
    "end": "19480"
  },
  {
    "text": "have been many common questions popping",
    "start": "19480",
    "end": "21439"
  },
  {
    "text": "up when people get started using ra",
    "start": "21439",
    "end": "23080"
  },
  {
    "text": "train and just uh get started doing",
    "start": "23080",
    "end": "25320"
  },
  {
    "text": "distributed deep learning in the first",
    "start": "25320",
    "end": "26720"
  },
  {
    "text": "place and this talk is meant to as a way",
    "start": "26720",
    "end": "28800"
  },
  {
    "text": "to consolidate the best prce practices",
    "start": "28800",
    "end": "30759"
  },
  {
    "text": "and recommendations that we give people",
    "start": "30759",
    "end": "32920"
  },
  {
    "text": "uh when when people are getting started",
    "start": "32920",
    "end": "34360"
  },
  {
    "text": "so this will definitely not be an",
    "start": "34360",
    "end": "35399"
  },
  {
    "text": "exhaustive list of everything you need",
    "start": "35399",
    "end": "36559"
  },
  {
    "text": "to know about productionizing and uh",
    "start": "36559",
    "end": "38600"
  },
  {
    "text": "distributive training but it should give",
    "start": "38600",
    "end": "39920"
  },
  {
    "text": "you some common questions to ask",
    "start": "39920",
    "end": "41200"
  },
  {
    "text": "yourself when you start to scale out",
    "start": "41200",
    "end": "43120"
  },
  {
    "text": "your training with R",
    "start": "43120",
    "end": "45320"
  },
  {
    "text": "train okay so I'll first give a brief",
    "start": "45320",
    "end": "47640"
  },
  {
    "text": "overview of the topics we'll be",
    "start": "47640",
    "end": "49079"
  },
  {
    "text": "discussing uh first we will uh cover the",
    "start": "49079",
    "end": "52039"
  },
  {
    "text": "recommended way to set up a ray cluster",
    "start": "52039",
    "end": "54359"
  },
  {
    "text": "uh this is more of a prerequisite so we",
    "start": "54359",
    "end": "56160"
  },
  {
    "text": "won't dive too deep into this point uh",
    "start": "56160",
    "end": "58280"
  },
  {
    "text": "so we'll Mo mostly focus on the next few",
    "start": "58280",
    "end": "59920"
  },
  {
    "text": "view",
    "start": "59920",
    "end": "60800"
  },
  {
    "text": "points uh the first one is best",
    "start": "60800",
    "end": "63320"
  },
  {
    "text": "practices for configuring resources so",
    "start": "63320",
    "end": "66880"
  },
  {
    "text": "uh this is relates to configuring and",
    "start": "66880",
    "end": "68439"
  },
  {
    "text": "optimizing the compute usage as well as",
    "start": "68439",
    "end": "70400"
  },
  {
    "text": "determining the scale of your",
    "start": "70400",
    "end": "71600"
  },
  {
    "text": "distributed training then we will learn",
    "start": "71600",
    "end": "74119"
  },
  {
    "text": "how to use some of raid Train's features",
    "start": "74119",
    "end": "76479"
  },
  {
    "text": "to uh productionize your job your",
    "start": "76479",
    "end": "78680"
  },
  {
    "text": "training job to make make it more",
    "start": "78680",
    "end": "80240"
  },
  {
    "text": "observable as well as uh resilient to",
    "start": "80240",
    "end": "82759"
  },
  {
    "text": "failures and then lastly we'll have a",
    "start": "82759",
    "end": "84799"
  },
  {
    "text": "demo that shows a fault tolerant uh",
    "start": "84799",
    "end": "87360"
  },
  {
    "text": "stable diffusion fine-tuning script",
    "start": "87360",
    "end": "88960"
  },
  {
    "text": "that's running we'll do some",
    "start": "88960",
    "end": "90280"
  },
  {
    "text": "investigation of like U observability",
    "start": "90280",
    "end": "92040"
  },
  {
    "text": "metrics and take a look at uh kind of uh",
    "start": "92040",
    "end": "94920"
  },
  {
    "text": "best practices that we can apply in",
    "start": "94920",
    "end": "98399"
  },
  {
    "text": "practice so I also wanted to introduce",
    "start": "98399",
    "end": "100960"
  },
  {
    "text": "the high level overview of the",
    "start": "100960",
    "end": "102040"
  },
  {
    "text": "architecture that we're going to be",
    "start": "102040",
    "end": "103119"
  },
  {
    "text": "discussing today so we'll go over these",
    "start": "103119",
    "end": "105079"
  },
  {
    "text": "pieces one by one throughout the talk so",
    "start": "105079",
    "end": "106880"
  },
  {
    "text": "don't feel free uh don't feel pressured",
    "start": "106880",
    "end": "108479"
  },
  {
    "text": "to need to uh kind of process this",
    "start": "108479",
    "end": "111200"
  },
  {
    "text": "entire chart right now this is just to",
    "start": "111200",
    "end": "112840"
  },
  {
    "text": "introduce the components that we'll be",
    "start": "112840",
    "end": "114119"
  },
  {
    "text": "talking about but uh the general gist is",
    "start": "114119",
    "end": "116600"
  },
  {
    "text": "that uh if you just think about it in",
    "start": "116600",
    "end": "117799"
  },
  {
    "text": "terms of the demo which is going to be",
    "start": "117799",
    "end": "119000"
  },
  {
    "text": "this fine-tuning script script for",
    "start": "119000",
    "end": "120520"
  },
  {
    "text": "stable diffusion that's kind of the",
    "start": "120520",
    "end": "121920"
  },
  {
    "text": "central piece that we're going to be",
    "start": "121920",
    "end": "123039"
  },
  {
    "text": "tackling and adding on certain",
    "start": "123039",
    "end": "124600"
  },
  {
    "text": "components throughout the",
    "start": "124600",
    "end": "126320"
  },
  {
    "text": "talk okay so for the first kind of",
    "start": "126320",
    "end": "128599"
  },
  {
    "text": "prerequisite PR prerequisite section uh",
    "start": "128599",
    "end": "131200"
  },
  {
    "text": "we want to figure out what's the",
    "start": "131200",
    "end": "132599"
  },
  {
    "text": "recommended way of setting up my Ray",
    "start": "132599",
    "end": "134959"
  },
  {
    "text": "cluster so our recommendation is to uh",
    "start": "134959",
    "end": "138120"
  },
  {
    "text": "the best way to run Ray on open source",
    "start": "138120",
    "end": "139879"
  },
  {
    "text": "is running with cubay on a kubernetes",
    "start": "139879",
    "end": "141800"
  },
  {
    "text": "cluster so we'll start with our",
    "start": "141800",
    "end": "143920"
  },
  {
    "text": "kubernetes cluster and then we can",
    "start": "143920",
    "end": "145879"
  },
  {
    "text": "easily install a cubra operator on top",
    "start": "145879",
    "end": "148239"
  },
  {
    "text": "which allows us to just write our raay",
    "start": "148239",
    "end": "150120"
  },
  {
    "text": "train application and uh not need to",
    "start": "150120",
    "end": "152640"
  },
  {
    "text": "think about you know how these",
    "start": "152640",
    "end": "153560"
  },
  {
    "text": "kubernetes pods are being managed",
    "start": "153560",
    "end": "155040"
  },
  {
    "text": "underneath so KUB also",
    "start": "155040",
    "end": "158280"
  },
  {
    "text": "exposes uh so sorry uh in this ecosystem",
    "start": "158280",
    "end": "161800"
  },
  {
    "text": "uh we also want to set up uh tools like",
    "start": "161800",
    "end": "164519"
  },
  {
    "text": "grafana and Prometheus uh and this will",
    "start": "164519",
    "end": "166720"
  },
  {
    "text": "be used later on when we show uh live",
    "start": "166720",
    "end": "169000"
  },
  {
    "text": "streaming of metrics in the ray",
    "start": "169000",
    "end": "170640"
  },
  {
    "text": "dashboard when we're diagnosing",
    "start": "170640",
    "end": "172000"
  },
  {
    "text": "bottlenecks and issues with our with our",
    "start": "172000",
    "end": "174200"
  },
  {
    "text": "Ray train fine",
    "start": "174200",
    "end": "175879"
  },
  {
    "text": "tuning uh cubra also exposes a raid job",
    "start": "175879",
    "end": "179200"
  },
  {
    "text": "container uh C custom resource",
    "start": "179200",
    "end": "182200"
  },
  {
    "text": "definition which allows you to take some",
    "start": "182200",
    "end": "184319"
  },
  {
    "text": "end user fine-tuning request uh package",
    "start": "184319",
    "end": "187080"
  },
  {
    "text": "that as a raid job launch this ra uh r",
    "start": "187080",
    "end": "189680"
  },
  {
    "text": "ray train fine-tuning script in its own",
    "start": "189680",
    "end": "192000"
  },
  {
    "text": "cluster and then at the end when the",
    "start": "192000",
    "end": "193920"
  },
  {
    "text": "script has finished we'll just recy",
    "start": "193920",
    "end": "196080"
  },
  {
    "text": "we'll actually clean up this uh",
    "start": "196080",
    "end": "197840"
  },
  {
    "text": "kubernetes resources",
    "start": "197840",
    "end": "200159"
  },
  {
    "text": "underneath so there have been many talks",
    "start": "200159",
    "end": "202000"
  },
  {
    "text": "on KUB with examples of usen production",
    "start": "202000",
    "end": "204599"
  },
  {
    "text": "at race Summit so I'll refer you to",
    "start": "204599",
    "end": "206080"
  },
  {
    "text": "those for more information on",
    "start": "206080",
    "end": "208040"
  },
  {
    "text": "this okay so now moving into the main uh",
    "start": "208040",
    "end": "210560"
  },
  {
    "text": "the first main topic which is best",
    "start": "210560",
    "end": "212360"
  },
  {
    "text": "practices for configuring resources so",
    "start": "212360",
    "end": "215000"
  },
  {
    "text": "we have our Ray cluster set up a common",
    "start": "215000",
    "end": "217000"
  },
  {
    "text": "first question is figuring out the",
    "start": "217000",
    "end": "218959"
  },
  {
    "text": "resource requirements for our worker",
    "start": "218959",
    "end": "220400"
  },
  {
    "text": "nodes as well as how much horizontal",
    "start": "220400",
    "end": "222720"
  },
  {
    "text": "scaling to actually uh I should actually",
    "start": "222720",
    "end": "224879"
  },
  {
    "text": "do so how much uh how to actually",
    "start": "224879",
    "end": "226519"
  },
  {
    "text": "utilize distributed data data parallel",
    "start": "226519",
    "end": "229519"
  },
  {
    "text": "training so uh to start off I just want",
    "start": "229519",
    "end": "232159"
  },
  {
    "text": "to give some factors that you want to",
    "start": "232159",
    "end": "233519"
  },
  {
    "text": "consider and we'll be touching on these",
    "start": "233519",
    "end": "235680"
  },
  {
    "text": "uh throughout the talk which are uh",
    "start": "235680",
    "end": "237439"
  },
  {
    "text": "these factors to consider when scaling",
    "start": "237439",
    "end": "238840"
  },
  {
    "text": "training so",
    "start": "238840",
    "end": "240400"
  },
  {
    "text": "I care about the training speed so for",
    "start": "240400",
    "end": "243079"
  },
  {
    "text": "example if my model or data size is very",
    "start": "243079",
    "end": "245079"
  },
  {
    "text": "large if I'm just doing single device",
    "start": "245079",
    "end": "247079"
  },
  {
    "text": "training it's going to be prohibitively",
    "start": "247079",
    "end": "248959"
  },
  {
    "text": "slow and we'll need to distribute in",
    "start": "248959",
    "end": "251319"
  },
  {
    "text": "some way to multiple devices and",
    "start": "251319",
    "end": "252799"
  },
  {
    "text": "multiple nodes even uh to actually make",
    "start": "252799",
    "end": "254920"
  },
  {
    "text": "this feasible to",
    "start": "254920",
    "end": "256799"
  },
  {
    "text": "train uh and another kind of factor that",
    "start": "256799",
    "end": "259359"
  },
  {
    "text": "you might want to consider is if you",
    "start": "259359",
    "end": "260600"
  },
  {
    "text": "want to optimize for training speed in",
    "start": "260600",
    "end": "262840"
  },
  {
    "text": "order for your model to reach a certain",
    "start": "262840",
    "end": "264360"
  },
  {
    "text": "level of test performance within some",
    "start": "264360",
    "end": "266520"
  },
  {
    "text": "time budget so for example if I'm",
    "start": "266520",
    "end": "268160"
  },
  {
    "text": "building some fine-tuning service where",
    "start": "268160",
    "end": "270120"
  },
  {
    "text": "I need to give a customer a fin tune",
    "start": "270120",
    "end": "272800"
  },
  {
    "text": "model by a certain uh time frame like",
    "start": "272800",
    "end": "275720"
  },
  {
    "text": "this this latency like might actually",
    "start": "275720",
    "end": "277240"
  },
  {
    "text": "matter a",
    "start": "277240",
    "end": "278560"
  },
  {
    "text": "lot uh another uh axis is the cost so uh",
    "start": "278560",
    "end": "283039"
  },
  {
    "text": "I want my training to stay within some",
    "start": "283039",
    "end": "284840"
  },
  {
    "text": "dollar budget and then uh with these two",
    "start": "284840",
    "end": "287759"
  },
  {
    "text": "in mind I don't want to necessarily have",
    "start": "287759",
    "end": "289639"
  },
  {
    "text": "a sacrificed model quality when I'm",
    "start": "289639",
    "end": "291680"
  },
  {
    "text": "trying to optimize for uh the",
    "start": "291680",
    "end": "294840"
  },
  {
    "text": "speed okay so now given these",
    "start": "294840",
    "end": "297280"
  },
  {
    "text": "considerations it's a natural question",
    "start": "297280",
    "end": "298919"
  },
  {
    "text": "is to uh kind of ask how do I speed up",
    "start": "298919",
    "end": "301639"
  },
  {
    "text": "my training by doing distributed",
    "start": "301639",
    "end": "303120"
  },
  {
    "text": "training with R train while keeping the",
    "start": "303120",
    "end": "305199"
  },
  {
    "text": "cost in check and so just coming back to",
    "start": "305199",
    "end": "307400"
  },
  {
    "text": "this reference architecture we'll F",
    "start": "307400",
    "end": "309360"
  },
  {
    "text": "first focus on how to specify the",
    "start": "309360",
    "end": "311199"
  },
  {
    "text": "resource requirements and the scaling of",
    "start": "311199",
    "end": "313759"
  },
  {
    "text": "our distributive training these are two",
    "start": "313759",
    "end": "315199"
  },
  {
    "text": "kind of uh knobs that you can turn in",
    "start": "315199",
    "end": "316919"
  },
  {
    "text": "your application that will kind of",
    "start": "316919",
    "end": "318440"
  },
  {
    "text": "affect this you know the training speed",
    "start": "318440",
    "end": "320360"
  },
  {
    "text": "as well as the cost so the scaling",
    "start": "320360",
    "end": "322759"
  },
  {
    "text": "config API in ra train allows you to",
    "start": "322759",
    "end": "325120"
  },
  {
    "text": "configure both of these knob these knobs",
    "start": "325120",
    "end": "327440"
  },
  {
    "text": "and uh this is like often uh like the",
    "start": "327440",
    "end": "329560"
  },
  {
    "text": "these questions are often you know one",
    "start": "329560",
    "end": "331160"
  },
  {
    "text": "of the first few that we get asked when",
    "start": "331160",
    "end": "332639"
  },
  {
    "text": "we're helping",
    "start": "332639",
    "end": "335120"
  },
  {
    "text": "users okay so I'll start off by giving",
    "start": "335120",
    "end": "337960"
  },
  {
    "text": "some rules of thumb for configuring your",
    "start": "337960",
    "end": "339759"
  },
  {
    "text": "compute so this is like the first",
    "start": "339759",
    "end": "340960"
  },
  {
    "text": "question in green over here so the first",
    "start": "340960",
    "end": "344639"
  },
  {
    "text": "topic uh here that people naturally go",
    "start": "344639",
    "end": "346520"
  },
  {
    "text": "to is how do I pick a GPU and so",
    "start": "346520",
    "end": "348840"
  },
  {
    "text": "different gpus have different",
    "start": "348840",
    "end": "350240"
  },
  {
    "text": "capabilities and so they have different",
    "start": "350240",
    "end": "352199"
  },
  {
    "text": "uh levels of performance and so I might",
    "start": "352199",
    "end": "354479"
  },
  {
    "text": "want to pick a better performing GPU",
    "start": "354479",
    "end": "356560"
  },
  {
    "text": "that will decrease the time for my my",
    "start": "356560",
    "end": "358319"
  },
  {
    "text": "training uh but it will also be more",
    "start": "358319",
    "end": "360360"
  },
  {
    "text": "expensive per uh per GPU hour uh there's",
    "start": "360360",
    "end": "363919"
  },
  {
    "text": "different gpus have different support",
    "start": "363919",
    "end": "365720"
  },
  {
    "text": "for mixed Precision training and so this",
    "start": "365720",
    "end": "367960"
  },
  {
    "text": "will be more important when you want to",
    "start": "367960",
    "end": "370400"
  },
  {
    "text": "uh you know utilize mixed Precision",
    "start": "370400",
    "end": "372240"
  },
  {
    "text": "training in uh large language model",
    "start": "372240",
    "end": "375319"
  },
  {
    "text": "training and the main bottleneck that",
    "start": "375319",
    "end": "377240"
  },
  {
    "text": "people run into these days is different",
    "start": "377240",
    "end": "379639"
  },
  {
    "text": "amounts of gram so on the GPU you'll",
    "start": "379639",
    "end": "383440"
  },
  {
    "text": "have uh many of these components uh",
    "start": "383440",
    "end": "385400"
  },
  {
    "text": "allocated on the GPU and so you'll have",
    "start": "385400",
    "end": "387440"
  },
  {
    "text": "the model parameters gradients op your",
    "start": "387440",
    "end": "389759"
  },
  {
    "text": "States as well as the data batch as well",
    "start": "389759",
    "end": "391680"
  },
  {
    "text": "and the activations that are computed on",
    "start": "391680",
    "end": "393560"
  },
  {
    "text": "the data batch and so ideally you want",
    "start": "393560",
    "end": "396960"
  },
  {
    "text": "to pick a GPU where your training uh",
    "start": "396960",
    "end": "399319"
  },
  {
    "text": "your full model training State and so",
    "start": "399319",
    "end": "401120"
  },
  {
    "text": "those are all those components there fit",
    "start": "401120",
    "end": "403080"
  },
  {
    "text": "into GPU",
    "start": "403080",
    "end": "404319"
  },
  {
    "text": "memory um and this is so that we don't",
    "start": "404319",
    "end": "406880"
  },
  {
    "text": "have to introduce extra overhead or",
    "start": "406880",
    "end": "408479"
  },
  {
    "text": "extra tricks in order to uh kind of",
    "start": "408479",
    "end": "410599"
  },
  {
    "text": "sacrifice a compute extra compute for uh",
    "start": "410599",
    "end": "414560"
  },
  {
    "text": "memory uh if this is not possible for",
    "start": "414560",
    "end": "416720"
  },
  {
    "text": "example if your model just doesn't fit",
    "start": "416720",
    "end": "418759"
  },
  {
    "text": "like if your model parameters themselves",
    "start": "418759",
    "end": "420400"
  },
  {
    "text": "don't fit in memory and you can't even",
    "start": "420400",
    "end": "422039"
  },
  {
    "text": "fit any of these other things then",
    "start": "422039",
    "end": "423479"
  },
  {
    "text": "you'll have to switch to some other",
    "start": "423479",
    "end": "425120"
  },
  {
    "text": "strategies so I'll just uh briefly cover",
    "start": "425120",
    "end": "427479"
  },
  {
    "text": "some of these uh tricks that people do",
    "start": "427479",
    "end": "429199"
  },
  {
    "text": "in",
    "start": "429199",
    "end": "430000"
  },
  {
    "text": "practice um and uh yeah this is just a",
    "start": "430000",
    "end": "434639"
  },
  {
    "text": "small list of common techniques that",
    "start": "434639",
    "end": "435879"
  },
  {
    "text": "you'll you'll see uh but in general",
    "start": "435879",
    "end": "437800"
  },
  {
    "text": "we'll want to avoid these tricks because",
    "start": "437800",
    "end": "439440"
  },
  {
    "text": "they mostly trade trade off memory for",
    "start": "439440",
    "end": "442199"
  },
  {
    "text": "extra computations that need to be",
    "start": "442199",
    "end": "444479"
  },
  {
    "text": "done okay so if your model State doesn't",
    "start": "444479",
    "end": "446759"
  },
  {
    "text": "fit into GP memory you might want to try",
    "start": "446759",
    "end": "448879"
  },
  {
    "text": "one of these so mix Precision training",
    "start": "448879",
    "end": "450680"
  },
  {
    "text": "as I mentioned earlier uh state sharding",
    "start": "450680",
    "end": "453039"
  },
  {
    "text": "so this is going to be the model",
    "start": "453039",
    "end": "454160"
  },
  {
    "text": "gradient and Optimizer",
    "start": "454160",
    "end": "456120"
  },
  {
    "text": "States uh CPU offloading of the",
    "start": "456120",
    "end": "458520"
  },
  {
    "text": "optimizer and gradient States as well as",
    "start": "458520",
    "end": "461160"
  },
  {
    "text": "activation or it's also called the",
    "start": "461160",
    "end": "462599"
  },
  {
    "text": "gradient checkpointing so all of these",
    "start": "462599",
    "end": "464400"
  },
  {
    "text": "will kind of decrease or offload some of",
    "start": "464400",
    "end": "466759"
  },
  {
    "text": "these blocks that I have listed below",
    "start": "466759",
    "end": "469440"
  },
  {
    "text": "either onto CPU memory or just like",
    "start": "469440",
    "end": "470919"
  },
  {
    "text": "decrease the amount of memory that each",
    "start": "470919",
    "end": "473000"
  },
  {
    "text": "block",
    "start": "473000",
    "end": "474240"
  },
  {
    "text": "takes uh so again like we we want to",
    "start": "474240",
    "end": "476319"
  },
  {
    "text": "avoid these if possible but these may",
    "start": "476319",
    "end": "478639"
  },
  {
    "text": "still be worth doing uh if the cost",
    "start": "478639",
    "end": "480599"
  },
  {
    "text": "Savings of you know training on these",
    "start": "480599",
    "end": "482319"
  },
  {
    "text": "cheap commodity uh gpus outweighs the",
    "start": "482319",
    "end": "484639"
  },
  {
    "text": "extra training overhead that these uh",
    "start": "484639",
    "end": "487479"
  },
  {
    "text": "will will",
    "start": "487479",
    "end": "489639"
  },
  {
    "text": "incur okay so in addition to GPU memory",
    "start": "489639",
    "end": "492520"
  },
  {
    "text": "requirements training large models often",
    "start": "492520",
    "end": "494599"
  },
  {
    "text": "imposes CPU requirements CPU memory",
    "start": "494599",
    "end": "498280"
  },
  {
    "text": "requirements so this is just a few more",
    "start": "498280",
    "end": "500360"
  },
  {
    "text": "rules of thumb uh for CPU uh memory so",
    "start": "500360",
    "end": "503400"
  },
  {
    "text": "the first thing is to ask like what is",
    "start": "503400",
    "end": "505120"
  },
  {
    "text": "my model size so usually in uh when",
    "start": "505120",
    "end": "507919"
  },
  {
    "text": "you're doing like some kind of like Shar",
    "start": "507919",
    "end": "509360"
  },
  {
    "text": "in strategy uh at least one node like",
    "start": "509360",
    "end": "511800"
  },
  {
    "text": "one rule of thumb is at least one node",
    "start": "511800",
    "end": "513800"
  },
  {
    "text": "should be able to fit the full model",
    "start": "513800",
    "end": "515240"
  },
  {
    "text": "parameters into CPU memory so this is",
    "start": "515240",
    "end": "517240"
  },
  {
    "text": "often the case when you do model",
    "start": "517240",
    "end": "518599"
  },
  {
    "text": "initialization uh you will load it first",
    "start": "518599",
    "end": "520800"
  },
  {
    "text": "on like the rank zero worker and then",
    "start": "520800",
    "end": "522279"
  },
  {
    "text": "you'll Shard it uh to other",
    "start": "522279",
    "end": "525440"
  },
  {
    "text": "workers uh another note here is that",
    "start": "525440",
    "end": "527760"
  },
  {
    "text": "different checkpointing strategies will",
    "start": "527760",
    "end": "529040"
  },
  {
    "text": "also have different CPU memory",
    "start": "529040",
    "end": "531000"
  },
  {
    "text": "requirements uh if you for example",
    "start": "531000",
    "end": "532959"
  },
  {
    "text": "gather your entire checkpoint onto the",
    "start": "532959",
    "end": "534399"
  },
  {
    "text": "rank zero worker then you'll also have",
    "start": "534399",
    "end": "536160"
  },
  {
    "text": "to incur another copy of the model uh",
    "start": "536160",
    "end": "538600"
  },
  {
    "text": "parameters",
    "start": "538600",
    "end": "541000"
  },
  {
    "text": "uh another uh uh so another Knob that",
    "start": "541000",
    "end": "543720"
  },
  {
    "text": "you can turn is CPU offloading and this",
    "start": "543720",
    "end": "545440"
  },
  {
    "text": "will also incur more uh CPU memory",
    "start": "545440",
    "end": "549519"
  },
  {
    "text": "requirements and uh if you have if you",
    "start": "549519",
    "end": "551760"
  },
  {
    "text": "need to load any in-memory data sets uh",
    "start": "551760",
    "end": "554000"
  },
  {
    "text": "this will also uh increase the",
    "start": "554000",
    "end": "556440"
  },
  {
    "text": "requirements and if you're using rate",
    "start": "556440",
    "end": "557920"
  },
  {
    "text": "data and if you've attended the talk uh",
    "start": "557920",
    "end": "560000"
  },
  {
    "text": "yesterday um and you are caching",
    "start": "560000",
    "end": "562920"
  },
  {
    "text": "pre-process data sets like at",
    "start": "562920",
    "end": "564279"
  },
  {
    "text": "intermediate layers this will also uh",
    "start": "564279",
    "end": "567079"
  },
  {
    "text": "kind of bound your your CPU M",
    "start": "567079",
    "end": "570920"
  },
  {
    "text": "requirement okay so moving on uh the",
    "start": "570920",
    "end": "574079"
  },
  {
    "text": "next thing that we want to talk about is",
    "start": "574079",
    "end": "575920"
  },
  {
    "text": "actually picking my instance types uh so",
    "start": "575920",
    "end": "578680"
  },
  {
    "text": "to minimize the communication overhead",
    "start": "578680",
    "end": "580760"
  },
  {
    "text": "we want to prefer instances with",
    "start": "580760",
    "end": "582880"
  },
  {
    "text": "multiple gpus rather than have a a",
    "start": "582880",
    "end": "585160"
  },
  {
    "text": "distributed cluster with multiple single",
    "start": "585160",
    "end": "586839"
  },
  {
    "text": "GPU instances uh and so in this case I'm",
    "start": "586839",
    "end": "590200"
  },
  {
    "text": "just showing this diagram where every",
    "start": "590200",
    "end": "591720"
  },
  {
    "text": "single GPU is on a different worker a",
    "start": "591720",
    "end": "593920"
  },
  {
    "text": "worker node and uh we're doing some kind",
    "start": "593920",
    "end": "597040"
  },
  {
    "text": "of like all all reduce uh",
    "start": "597040",
    "end": "599800"
  },
  {
    "text": "operation and uh we see that there's",
    "start": "599800",
    "end": "602079"
  },
  {
    "text": "going to be some latency between each of",
    "start": "602079",
    "end": "603600"
  },
  {
    "text": "these edges and we can minimize that by",
    "start": "603600",
    "end": "605920"
  },
  {
    "text": "just kind of consolidating them onto a",
    "start": "605920",
    "end": "607560"
  },
  {
    "text": "single node uh note that this is not",
    "start": "607560",
    "end": "610040"
  },
  {
    "text": "this is not a rule at all like this is",
    "start": "610040",
    "end": "611519"
  },
  {
    "text": "just kind of if we want to reduce",
    "start": "611519",
    "end": "613000"
  },
  {
    "text": "communication overhead uh we may still",
    "start": "613000",
    "end": "614839"
  },
  {
    "text": "want to choose single GPU instances uh",
    "start": "614839",
    "end": "617200"
  },
  {
    "text": "for cost or availability reasons so this",
    "start": "617200",
    "end": "619240"
  },
  {
    "text": "is like not a rule to exact rule to",
    "start": "619240",
    "end": "622600"
  },
  {
    "text": "follow okay so now that we've configured",
    "start": "622600",
    "end": "625120"
  },
  {
    "text": "like what kind of Hardware we're using",
    "start": "625120",
    "end": "627079"
  },
  {
    "text": "we'll dive into how to configure the",
    "start": "627079",
    "end": "628839"
  },
  {
    "text": "back size which is one of these",
    "start": "628839",
    "end": "630160"
  },
  {
    "text": "parameters that uh kind of is affected",
    "start": "630160",
    "end": "632560"
  },
  {
    "text": "by data parallel training and kind of uh",
    "start": "632560",
    "end": "635959"
  },
  {
    "text": "uh yeah basically uh configures like how",
    "start": "635959",
    "end": "638680"
  },
  {
    "text": "much parallelism you can actually apply",
    "start": "638680",
    "end": "640320"
  },
  {
    "text": "to your training so one rule of thumb is",
    "start": "640320",
    "end": "643560"
  },
  {
    "text": "to uh use the largest batch size",
    "start": "643560",
    "end": "645880"
  },
  {
    "text": "possible for your given Hardware so this",
    "start": "645880",
    "end": "648200"
  },
  {
    "text": "is uh kind of like a yeah basically you",
    "start": "648200",
    "end": "650079"
  },
  {
    "text": "have these two blocks in blue which will",
    "start": "650079",
    "end": "652480"
  },
  {
    "text": "scale with your batch size and you want",
    "start": "652480",
    "end": "655160"
  },
  {
    "text": "to pick your batch size B so that all of",
    "start": "655160",
    "end": "657079"
  },
  {
    "text": "these uh blocks kind of fit almost like",
    "start": "657079",
    "end": "659560"
  },
  {
    "text": "just right in in GPU memory so you can",
    "start": "659560",
    "end": "661320"
  },
  {
    "text": "get the the maximum",
    "start": "661320",
    "end": "664040"
  },
  {
    "text": "utilization so if we want to actually",
    "start": "665160",
    "end": "667360"
  },
  {
    "text": "increase our batch size so this is like",
    "start": "667360",
    "end": "669639"
  },
  {
    "text": "the the slide I just showed is how to",
    "start": "669639",
    "end": "671240"
  },
  {
    "text": "optimize your GPU utilization for a",
    "start": "671240",
    "end": "672920"
  },
  {
    "text": "single device when I start to introduce",
    "start": "672920",
    "end": "675160"
  },
  {
    "text": "data parallelism I can actually increase",
    "start": "675160",
    "end": "677079"
  },
  {
    "text": "the effective batch size uh and this is",
    "start": "677079",
    "end": "679279"
  },
  {
    "text": "like just I'm just uh I just want to",
    "start": "679279",
    "end": "680680"
  },
  {
    "text": "show like how that how that looks so for",
    "start": "680680",
    "end": "683120"
  },
  {
    "text": "just a single device if I'm iterating uh",
    "start": "683120",
    "end": "685920"
  },
  {
    "text": "through with a batch size of B it'll",
    "start": "685920",
    "end": "688000"
  },
  {
    "text": "look something like this",
    "start": "688000",
    "end": "689720"
  },
  {
    "text": "or I'm just iterating through my data",
    "start": "689720",
    "end": "690880"
  },
  {
    "text": "set uh B at a time and if I increase the",
    "start": "690880",
    "end": "693560"
  },
  {
    "text": "number of workers I can increase the",
    "start": "693560",
    "end": "695160"
  },
  {
    "text": "effective batch size this allows for",
    "start": "695160",
    "end": "697079"
  },
  {
    "text": "more data parallelism and increases my",
    "start": "697079",
    "end": "699399"
  },
  {
    "text": "throughput by around the uh the number",
    "start": "699399",
    "end": "701760"
  },
  {
    "text": "of workers I'm scaling to uh this is",
    "start": "701760",
    "end": "704399"
  },
  {
    "text": "like ignoring some communication",
    "start": "704399",
    "end": "706000"
  },
  {
    "text": "overhead",
    "start": "706000",
    "end": "708360"
  },
  {
    "text": "um so this uh the new diagram or the new",
    "start": "708360",
    "end": "711120"
  },
  {
    "text": "flowchart or animation here is just",
    "start": "711120",
    "end": "713880"
  },
  {
    "text": "showing that we have a the 4X",
    "start": "713880",
    "end": "717120"
  },
  {
    "text": "throughput and with large model models",
    "start": "717120",
    "end": "719160"
  },
  {
    "text": "you often cannot fit a batch size of",
    "start": "719160",
    "end": "720680"
  },
  {
    "text": "more than one onto your GPU and so a",
    "start": "720680",
    "end": "723639"
  },
  {
    "text": "common trick here is that people will",
    "start": "723639",
    "end": "725279"
  },
  {
    "text": "use gradient accumulation to get around",
    "start": "725279",
    "end": "727519"
  },
  {
    "text": "this so they'll kind of simulate uh a",
    "start": "727519",
    "end": "730000"
  },
  {
    "text": "larger batch size by just delaying this",
    "start": "730000",
    "end": "732120"
  },
  {
    "text": "backward",
    "start": "732120",
    "end": "733199"
  },
  {
    "text": "step and this is actually perfect",
    "start": "733199",
    "end": "735120"
  },
  {
    "text": "opportunity to scale out instead so",
    "start": "735120",
    "end": "736959"
  },
  {
    "text": "rather than doing this trick where it's",
    "start": "736959",
    "end": "738720"
  },
  {
    "text": "just incurring this like time penal like",
    "start": "738720",
    "end": "740399"
  },
  {
    "text": "a speed of training penalty we' rather",
    "start": "740399",
    "end": "743399"
  },
  {
    "text": "just scale out and actually use like",
    "start": "743399",
    "end": "745519"
  },
  {
    "text": "just increase the effect of batch size",
    "start": "745519",
    "end": "746839"
  },
  {
    "text": "by having more workers and more worker",
    "start": "746839",
    "end": "748519"
  },
  {
    "text": "nodes",
    "start": "748519",
    "end": "750880"
  },
  {
    "text": "okay so one more kind of advanced topic",
    "start": "752160",
    "end": "754600"
  },
  {
    "text": "that we'll talk about is finding the",
    "start": "754600",
    "end": "756279"
  },
  {
    "text": "optimal level of data parallelism or the",
    "start": "756279",
    "end": "757959"
  },
  {
    "text": "optimal number of batch size optimal",
    "start": "757959",
    "end": "759760"
  },
  {
    "text": "number of workers that you want to",
    "start": "759760",
    "end": "760800"
  },
  {
    "text": "configure and this is a common question",
    "start": "760800",
    "end": "762600"
  },
  {
    "text": "that people uh come uh come start to",
    "start": "762600",
    "end": "766160"
  },
  {
    "text": "face when they have a ray cluster",
    "start": "766160",
    "end": "768279"
  },
  {
    "text": "because I can technically scale to any",
    "start": "768279",
    "end": "770240"
  },
  {
    "text": "arbitrary number of gpus so doesn't make",
    "start": "770240",
    "end": "772680"
  },
  {
    "text": "sense to just keep increasing the batch",
    "start": "772680",
    "end": "774199"
  },
  {
    "text": "size like indefinitely so the answer is",
    "start": "774199",
    "end": "776720"
  },
  {
    "text": "no like we cannot keep scaling out",
    "start": "776720",
    "end": "779480"
  },
  {
    "text": "uh training horizontally forever the",
    "start": "779480",
    "end": "781600"
  },
  {
    "text": "throughput of the system will continue",
    "start": "781600",
    "end": "783199"
  },
  {
    "text": "to increase but the speed up in the",
    "start": "783199",
    "end": "785279"
  },
  {
    "text": "actual thing that we care about which is",
    "start": "785279",
    "end": "786800"
  },
  {
    "text": "time to desired performance in this case",
    "start": "786800",
    "end": "789320"
  },
  {
    "text": "the y- axis is labeled in steps to a",
    "start": "789320",
    "end": "791480"
  },
  {
    "text": "desired evaluation metric uh eventually",
    "start": "791480",
    "end": "794600"
  },
  {
    "text": "tapers off so this this paper from 2018",
    "start": "794600",
    "end": "797279"
  },
  {
    "text": "shows that for over a a wide variety of",
    "start": "797279",
    "end": "799839"
  },
  {
    "text": "data sets model types and uh training",
    "start": "799839",
    "end": "803160"
  },
  {
    "text": "algorithms that uh you'll see this",
    "start": "803160",
    "end": "805320"
  },
  {
    "text": "General Trend where you have first a",
    "start": "805320",
    "end": "807160"
  },
  {
    "text": "linear speed up region then you you have",
    "start": "807160",
    "end": "809079"
  },
  {
    "text": "some diminishing returns where",
    "start": "809079",
    "end": "810600"
  },
  {
    "text": "increasing the batch size no longer uh",
    "start": "810600",
    "end": "813040"
  },
  {
    "text": "results in your training time decreasing",
    "start": "813040",
    "end": "816040"
  },
  {
    "text": "and then you have a some period of",
    "start": "816040",
    "end": "817519"
  },
  {
    "text": "Maximum data parallelism and for",
    "start": "817519",
    "end": "820000"
  },
  {
    "text": "practitioners we might want to pick this",
    "start": "820000",
    "end": "821720"
  },
  {
    "text": "point as the fastest time to convergence",
    "start": "821720",
    "end": "824320"
  },
  {
    "text": "that doesn't start to increase the total",
    "start": "824320",
    "end": "825880"
  },
  {
    "text": "cost of this",
    "start": "825880",
    "end": "828279"
  },
  {
    "text": "training okay so practically like what",
    "start": "829600",
    "end": "832000"
  },
  {
    "text": "does this look like uh we can start with",
    "start": "832000",
    "end": "834399"
  },
  {
    "text": "a batch size that works well before you",
    "start": "834399",
    "end": "835920"
  },
  {
    "text": "start scaling out then we'll just keep",
    "start": "835920",
    "end": "838279"
  },
  {
    "text": "scaling out the batch size and possibly",
    "start": "838279",
    "end": "840320"
  },
  {
    "text": "the learning rate along with that uh",
    "start": "840320",
    "end": "842079"
  },
  {
    "text": "this is kind of based on a learning a",
    "start": "842079",
    "end": "843880"
  },
  {
    "text": "linear scaling learning rate her istic",
    "start": "843880",
    "end": "845920"
  },
  {
    "text": "where if you increase your batch size",
    "start": "845920",
    "end": "847600"
  },
  {
    "text": "you want to increase the learning rates",
    "start": "847600",
    "end": "849399"
  },
  {
    "text": "uh because you have a more uh a better",
    "start": "849399",
    "end": "851920"
  },
  {
    "text": "estimate of the gradient so you can take",
    "start": "851920",
    "end": "853199"
  },
  {
    "text": "a larger",
    "start": "853199",
    "end": "854320"
  },
  {
    "text": "step uh this is also not a general rule",
    "start": "854320",
    "end": "857360"
  },
  {
    "text": "so this is just something that you can",
    "start": "857360",
    "end": "858279"
  },
  {
    "text": "start out",
    "start": "858279",
    "end": "859240"
  },
  {
    "text": "with then you want to set the number of",
    "start": "859240",
    "end": "861399"
  },
  {
    "text": "GP workers to meet this target batch",
    "start": "861399",
    "end": "863040"
  },
  {
    "text": "size remembering to max out the",
    "start": "863040",
    "end": "864800"
  },
  {
    "text": "utilization for each",
    "start": "864800",
    "end": "866480"
  },
  {
    "text": "device then you can if you want to be",
    "start": "866480",
    "end": "868920"
  },
  {
    "text": "more uh you know metrics driven you can",
    "start": "868920",
    "end": "871320"
  },
  {
    "text": "measure the time to convergence and then",
    "start": "871320",
    "end": "873560"
  },
  {
    "text": "you can repeat to the B through D until",
    "start": "873560",
    "end": "875560"
  },
  {
    "text": "your training starts to cost more or",
    "start": "875560",
    "end": "877120"
  },
  {
    "text": "you're no longer seeing this linear",
    "start": "877120",
    "end": "878360"
  },
  {
    "text": "speed up in uh training",
    "start": "878360",
    "end": "882000"
  },
  {
    "text": "time okay so now uh that we've covered",
    "start": "884079",
    "end": "886839"
  },
  {
    "text": "these like kind of tricks to optimize",
    "start": "886839",
    "end": "888759"
  },
  {
    "text": "your uh your cluster setup and your",
    "start": "888759",
    "end": "890399"
  },
  {
    "text": "distributed training setup we're going",
    "start": "890399",
    "end": "891880"
  },
  {
    "text": "to move on to how to add a few knobs add",
    "start": "891880",
    "end": "894240"
  },
  {
    "text": "a few features of rate train to actually",
    "start": "894240",
    "end": "896360"
  },
  {
    "text": "productionize your training job to make",
    "start": "896360",
    "end": "898079"
  },
  {
    "text": "it more resilient into failures and more",
    "start": "898079",
    "end": "900360"
  },
  {
    "text": "observable so the first thing we're",
    "start": "900360",
    "end": "901959"
  },
  {
    "text": "going to talk about actually is best",
    "start": "901959",
    "end": "903480"
  },
  {
    "text": "practices for model storage so in this",
    "start": "903480",
    "end": "906360"
  },
  {
    "text": "case we're just going to jump back to",
    "start": "906360",
    "end": "907600"
  },
  {
    "text": "the reference architecture the first",
    "start": "907600",
    "end": "909480"
  },
  {
    "text": "thing we're going to do is set up cloud",
    "start": "909480",
    "end": "911360"
  },
  {
    "text": "storage and we're going to set up our uh",
    "start": "911360",
    "end": "914040"
  },
  {
    "text": "and then afterwards we're going to",
    "start": "914040",
    "end": "915600"
  },
  {
    "text": "enable checkpointing so that it will",
    "start": "915600",
    "end": "917279"
  },
  {
    "text": "automatically get uploaded to this cloud",
    "start": "917279",
    "end": "918680"
  },
  {
    "text": "storage and then we will set up",
    "start": "918680",
    "end": "920560"
  },
  {
    "text": "experiment tracking so that these",
    "start": "920560",
    "end": "921920"
  },
  {
    "text": "checkpoints are also tracked in a model",
    "start": "921920",
    "end": "924519"
  },
  {
    "text": "registry for example like 1",
    "start": "924519",
    "end": "927600"
  },
  {
    "text": "DB so the first thing is to set up the",
    "start": "927600",
    "end": "930519"
  },
  {
    "text": "some external storage and it's pretty",
    "start": "930519",
    "end": "932519"
  },
  {
    "text": "easy in Ray trains API all you have to",
    "start": "932519",
    "end": "934480"
  },
  {
    "text": "do I'm not sure if you can see it very",
    "start": "934480",
    "end": "936279"
  },
  {
    "text": "clearly but it's just uh setting this",
    "start": "936279",
    "end": "938279"
  },
  {
    "text": "one storage path config which is in this",
    "start": "938279",
    "end": "940880"
  },
  {
    "text": "case an S3 bucket",
    "start": "940880",
    "end": "942759"
  },
  {
    "text": "urri so in this diagram on the right I'm",
    "start": "942759",
    "end": "946319"
  },
  {
    "text": "just showing under the hood like what's",
    "start": "946319",
    "end": "947639"
  },
  {
    "text": "happening when you're reporting",
    "start": "947639",
    "end": "948639"
  },
  {
    "text": "checkpoints with uh Ray trains API you",
    "start": "948639",
    "end": "951440"
  },
  {
    "text": "report checkpoints and then if you have",
    "start": "951440",
    "end": "953160"
  },
  {
    "text": "this storage path set it's going to get",
    "start": "953160",
    "end": "954600"
  },
  {
    "text": "automatically uploaded to this uh this",
    "start": "954600",
    "end": "957600"
  },
  {
    "text": "URI",
    "start": "957600",
    "end": "959240"
  },
  {
    "text": "so that's kind of leading into the next",
    "start": "959240",
    "end": "961040"
  },
  {
    "text": "point which is actually say reporting",
    "start": "961040",
    "end": "963160"
  },
  {
    "text": "these checkpoints to R train R train",
    "start": "963160",
    "end": "965199"
  },
  {
    "text": "only uh exposes a very lightweight API",
    "start": "965199",
    "end": "968240"
  },
  {
    "text": "to uh report checkpoints you basically",
    "start": "968240",
    "end": "971120"
  },
  {
    "text": "just report a local directory that",
    "start": "971120",
    "end": "972399"
  },
  {
    "text": "you've saved so you can pretty much just",
    "start": "972399",
    "end": "974600"
  },
  {
    "text": "use whatever framework Tool uh framework",
    "start": "974600",
    "end": "976639"
  },
  {
    "text": "checkpointing tools that you've used",
    "start": "976639",
    "end": "978319"
  },
  {
    "text": "before and you're familiar with and you",
    "start": "978319",
    "end": "980120"
  },
  {
    "text": "just report it to R train uh with this",
    "start": "980120",
    "end": "982639"
  },
  {
    "text": "local directory and it'll automatically",
    "start": "982639",
    "end": "984600"
  },
  {
    "text": "get uploaded to the storage",
    "start": "984600",
    "end": "986759"
  },
  {
    "text": "path and then lastly uh how do we",
    "start": "986759",
    "end": "989199"
  },
  {
    "text": "actually track the best checkpoints in",
    "start": "989199",
    "end": "990440"
  },
  {
    "text": "the model registry after we've uh called",
    "start": "990440",
    "end": "993440"
  },
  {
    "text": "R train. report which is the API to",
    "start": "993440",
    "end": "995480"
  },
  {
    "text": "upload the checkpoint and report it um",
    "start": "995480",
    "end": "998199"
  },
  {
    "text": "we'll actually just add a little bit",
    "start": "998199",
    "end": "999319"
  },
  {
    "text": "more logic which gets the latest",
    "start": "999319",
    "end": "1001120"
  },
  {
    "text": "checkpoint and the S3 URI that it points",
    "start": "1001120",
    "end": "1003680"
  },
  {
    "text": "to and I'll just track it as a reference",
    "start": "1003680",
    "end": "1005519"
  },
  {
    "text": "in One DB and so we'll show all of this",
    "start": "1005519",
    "end": "1007480"
  },
  {
    "text": "later in the demo so no need to uh uh",
    "start": "1007480",
    "end": "1010880"
  },
  {
    "text": "kind of pay like too close attention to",
    "start": "1010880",
    "end": "1012920"
  },
  {
    "text": "the details",
    "start": "1012920",
    "end": "1014839"
  },
  {
    "text": "here okay uh one other topic is uh how",
    "start": "1014839",
    "end": "1018120"
  },
  {
    "text": "to",
    "start": "1018120",
    "end": "1019040"
  },
  {
    "text": "make my training job more resilient to",
    "start": "1019040",
    "end": "1020759"
  },
  {
    "text": "failures and so this uh involves",
    "start": "1020759",
    "end": "1023079"
  },
  {
    "text": "enabling false tolerance so back to the",
    "start": "1023079",
    "end": "1025720"
  },
  {
    "text": "reference architecture we're going to be",
    "start": "1025720",
    "end": "1027240"
  },
  {
    "text": "adding on false tolerance to our",
    "start": "1027240",
    "end": "1029880"
  },
  {
    "text": "script and so this will leverage the",
    "start": "1029880",
    "end": "1031839"
  },
  {
    "text": "cloud storage and checkpointing uh that",
    "start": "1031839",
    "end": "1033678"
  },
  {
    "text": "we implemented in the previous",
    "start": "1033679",
    "end": "1035918"
  },
  {
    "text": "step so R trains fault tolerance works",
    "start": "1035919",
    "end": "1039000"
  },
  {
    "text": "like this we basically have four like",
    "start": "1039000",
    "end": "1041640"
  },
  {
    "text": "imagine this scenario where we're",
    "start": "1041640",
    "end": "1042678"
  },
  {
    "text": "training with four distributed training",
    "start": "1042679",
    "end": "1044240"
  },
  {
    "text": "workers one of them goes",
    "start": "1044240",
    "end": "1046438"
  },
  {
    "text": "down um you might be like trying to",
    "start": "1046439",
    "end": "1048520"
  },
  {
    "text": "access the cost Savings of spot",
    "start": "1048520",
    "end": "1050039"
  },
  {
    "text": "instances where this fourth GPU uh node",
    "start": "1050039",
    "end": "1053000"
  },
  {
    "text": "gets preempted in this",
    "start": "1053000",
    "end": "1055320"
  },
  {
    "text": "case uh Ray Ray will realize that you're",
    "start": "1055320",
    "end": "1058600"
  },
  {
    "text": "no longer meeting the minimum",
    "start": "1058600",
    "end": "1059720"
  },
  {
    "text": "requirements of the resources that Ray",
    "start": "1059720",
    "end": "1061720"
  },
  {
    "text": "train is requesting so it's going to try",
    "start": "1061720",
    "end": "1063880"
  },
  {
    "text": "to Autos skill a new GPU node so this",
    "start": "1063880",
    "end": "1065919"
  },
  {
    "text": "new GPU node is going to get uh brought",
    "start": "1065919",
    "end": "1068440"
  },
  {
    "text": "up and then your training script is",
    "start": "1068440",
    "end": "1070360"
  },
  {
    "text": "going to get relaunched on on this new",
    "start": "1070360",
    "end": "1072799"
  },
  {
    "text": "set of four distributed training",
    "start": "1072799",
    "end": "1074960"
  },
  {
    "text": "workers so this requires a few like in",
    "start": "1074960",
    "end": "1077360"
  },
  {
    "text": "order for this kind of flow CH to happen",
    "start": "1077360",
    "end": "1078960"
  },
  {
    "text": "in practice it requires a few uh configs",
    "start": "1078960",
    "end": "1081679"
  },
  {
    "text": "so the first one is to enable a worker",
    "start": "1081679",
    "end": "1083720"
  },
  {
    "text": "level fault tolerance using this failure",
    "start": "1083720",
    "end": "1085799"
  },
  {
    "text": "config so this Max failures equals three",
    "start": "1085799",
    "end": "1088880"
  },
  {
    "text": "basically just tells you how many times",
    "start": "1088880",
    "end": "1091039"
  },
  {
    "text": "do I want to retry in the event of",
    "start": "1091039",
    "end": "1092880"
  },
  {
    "text": "training or node",
    "start": "1092880",
    "end": "1094919"
  },
  {
    "text": "failures the second is what happens",
    "start": "1094919",
    "end": "1097360"
  },
  {
    "text": "after the node gets brought back up and",
    "start": "1097360",
    "end": "1099559"
  },
  {
    "text": "then you start resuming training you you",
    "start": "1099559",
    "end": "1101840"
  },
  {
    "text": "relaunch the training job on the new set",
    "start": "1101840",
    "end": "1104080"
  },
  {
    "text": "of four workers so in this case we want",
    "start": "1104080",
    "end": "1106480"
  },
  {
    "text": "to add restoration logic to the top of",
    "start": "1106480",
    "end": "1108840"
  },
  {
    "text": "our training script and we provide a",
    "start": "1108840",
    "end": "1110520"
  },
  {
    "text": "pretty lightweight API to do this so we",
    "start": "1110520",
    "end": "1112840"
  },
  {
    "text": "take uh ray. train. getet checkpoint",
    "start": "1112840",
    "end": "1115320"
  },
  {
    "text": "which gives you the latest checkpoint",
    "start": "1115320",
    "end": "1117120"
  },
  {
    "text": "and in the case of uh kind of a restored",
    "start": "1117120",
    "end": "1119960"
  },
  {
    "text": "experiment this will be populated",
    "start": "1119960",
    "end": "1121600"
  },
  {
    "text": "automatically by Ray by Ray",
    "start": "1121600",
    "end": "1123960"
  },
  {
    "text": "train uh we check if this checkpoint",
    "start": "1123960",
    "end": "1126080"
  },
  {
    "text": "exists and then we just use this as",
    "start": "1126080",
    "end": "1127840"
  },
  {
    "text": "directory API to download the checkpoint",
    "start": "1127840",
    "end": "1129720"
  },
  {
    "text": "locally and view it as just a directory",
    "start": "1129720",
    "end": "1132200"
  },
  {
    "text": "and then we can use again any of our",
    "start": "1132200",
    "end": "1134080"
  },
  {
    "text": "familiar uh you know Integrations and uh",
    "start": "1134080",
    "end": "1137640"
  },
  {
    "text": "checkpointing log that we already know",
    "start": "1137640",
    "end": "1139600"
  },
  {
    "text": "to load this",
    "start": "1139600",
    "end": "1142400"
  },
  {
    "text": "back okay and then one last topic for",
    "start": "1143120",
    "end": "1145520"
  },
  {
    "text": "fall tolerance is enabling the cluster",
    "start": "1145520",
    "end": "1147720"
  },
  {
    "text": "level fall tolerance so what this means",
    "start": "1147720",
    "end": "1149919"
  },
  {
    "text": "is uh let's say my head node or my",
    "start": "1149919",
    "end": "1152440"
  },
  {
    "text": "cluster like completely dies my cluster",
    "start": "1152440",
    "end": "1155280"
  },
  {
    "text": "cluster goes down uh and I have a job",
    "start": "1155280",
    "end": "1158280"
  },
  {
    "text": "retry uh I have a job that submits and",
    "start": "1158280",
    "end": "1160919"
  },
  {
    "text": "it gets retried on this failure then",
    "start": "1160919",
    "end": "1163520"
  },
  {
    "text": "this job retry will spin up a new",
    "start": "1163520",
    "end": "1165760"
  },
  {
    "text": "cluster that will resume training and I",
    "start": "1165760",
    "end": "1167880"
  },
  {
    "text": "want to basically configure this thing",
    "start": "1167880",
    "end": "1169760"
  },
  {
    "text": "to happen to to resume from where I left",
    "start": "1169760",
    "end": "1172440"
  },
  {
    "text": "off so for this uh we basically just add",
    "start": "1172440",
    "end": "1175559"
  },
  {
    "text": "a little bit more logic in the entry",
    "start": "1175559",
    "end": "1177000"
  },
  {
    "text": "point of our rate train application",
    "start": "1177000",
    "end": "1178720"
  },
  {
    "text": "which just checks does my does a",
    "start": "1178720",
    "end": "1180799"
  },
  {
    "text": "previous experiment exist if so I'm",
    "start": "1180799",
    "end": "1182559"
  },
  {
    "text": "going to restore from it um otherwise",
    "start": "1182559",
    "end": "1184679"
  },
  {
    "text": "I'll start a new one so it's a pretty",
    "start": "1184679",
    "end": "1186200"
  },
  {
    "text": "simple logic",
    "start": "1186200",
    "end": "1187480"
  },
  {
    "text": "here and so notice that we're also",
    "start": "1187480",
    "end": "1189559"
  },
  {
    "text": "specifying the storage path as an S3",
    "start": "1189559",
    "end": "1191360"
  },
  {
    "text": "bucket so we're just using that as the",
    "start": "1191360",
    "end": "1193120"
  },
  {
    "text": "the source of",
    "start": "1193120",
    "end": "1195600"
  },
  {
    "text": "Truth okay the last topic uh before",
    "start": "1195960",
    "end": "1198200"
  },
  {
    "text": "before we dive into the demo is how to",
    "start": "1198200",
    "end": "1199880"
  },
  {
    "text": "actually diagnose memory or performance",
    "start": "1199880",
    "end": "1201880"
  },
  {
    "text": "issues and so for this we touched on the",
    "start": "1201880",
    "end": "1204720"
  },
  {
    "text": "ray dashboard a little bit earlier but",
    "start": "1204720",
    "end": "1206520"
  },
  {
    "text": "this is where we're actually going to go",
    "start": "1206520",
    "end": "1207760"
  },
  {
    "text": "through an example of how would I use",
    "start": "1207760",
    "end": "1209240"
  },
  {
    "text": "this to actually detect a bottleneck in",
    "start": "1209240",
    "end": "1210559"
  },
  {
    "text": "my system uh and we're also going to",
    "start": "1210559",
    "end": "1212480"
  },
  {
    "text": "take a look at it during the",
    "start": "1212480",
    "end": "1215480"
  },
  {
    "text": "demo okay so this is uh so the ray",
    "start": "1216000",
    "end": "1218640"
  },
  {
    "text": "dashboard provides like many of these",
    "start": "1218640",
    "end": "1219799"
  },
  {
    "text": "tools out of the box one of one very",
    "start": "1219799",
    "end": "1222360"
  },
  {
    "text": "important one uh that's used like very",
    "start": "1222360",
    "end": "1224640"
  },
  {
    "text": "very often is this Ray metric dashboard",
    "start": "1224640",
    "end": "1227080"
  },
  {
    "text": "which shows like a live Fe of uh kind of",
    "start": "1227080",
    "end": "1229360"
  },
  {
    "text": "the history of your uh GP utilization as",
    "start": "1229360",
    "end": "1231960"
  },
  {
    "text": "well as you know network uh bandwidth",
    "start": "1231960",
    "end": "1234480"
  },
  {
    "text": "things like",
    "start": "1234480",
    "end": "1235720"
  },
  {
    "text": "that uh so one example of situation is",
    "start": "1235720",
    "end": "1238320"
  },
  {
    "text": "this plot that we see where we have very",
    "start": "1238320",
    "end": "1240120"
  },
  {
    "text": "spiky GPU",
    "start": "1240120",
    "end": "1241480"
  },
  {
    "text": "utilization so this is uh I guess like",
    "start": "1241480",
    "end": "1243880"
  },
  {
    "text": "the first thing is that we are actually",
    "start": "1243880",
    "end": "1245039"
  },
  {
    "text": "alerted of these issues like we can",
    "start": "1245039",
    "end": "1246559"
  },
  {
    "text": "monitor this distributed trading job in",
    "start": "1246559",
    "end": "1248280"
  },
  {
    "text": "the first place that's like one thing",
    "start": "1248280",
    "end": "1249480"
  },
  {
    "text": "that the ray dashboard enables and then",
    "start": "1249480",
    "end": "1251919"
  },
  {
    "text": "the second is that this will provide as",
    "start": "1251919",
    "end": "1253679"
  },
  {
    "text": "like a starting point for collecting",
    "start": "1253679",
    "end": "1255200"
  },
  {
    "text": "evidence on like what's actually going",
    "start": "1255200",
    "end": "1256520"
  },
  {
    "text": "wrong in this training so uh it turns",
    "start": "1256520",
    "end": "1259559"
  },
  {
    "text": "out after some de debugging that this uh",
    "start": "1259559",
    "end": "1261880"
  },
  {
    "text": "spikey utilization is caused by uh a",
    "start": "1261880",
    "end": "1264640"
  },
  {
    "text": "bottleneck in the data set",
    "start": "1264640",
    "end": "1265679"
  },
  {
    "text": "pre-processing that's happening on the",
    "start": "1265679",
    "end": "1266960"
  },
  {
    "text": "CPU and so the data set is",
    "start": "1266960",
    "end": "1269120"
  },
  {
    "text": "pre-processing things is not",
    "start": "1269120",
    "end": "1270760"
  },
  {
    "text": "pre-processing things fast enough for it",
    "start": "1270760",
    "end": "1273000"
  },
  {
    "text": "to catch up with the GP GPU uh",
    "start": "1273000",
    "end": "1275440"
  },
  {
    "text": "computations which are which are kind of",
    "start": "1275440",
    "end": "1277279"
  },
  {
    "text": "outpacing the data set pre-processing",
    "start": "1277279",
    "end": "1279679"
  },
  {
    "text": "computations so in this case once we fix",
    "start": "1279679",
    "end": "1282320"
  },
  {
    "text": "the issue we can actually take a look at",
    "start": "1282320",
    "end": "1284120"
  },
  {
    "text": "the the after picture within the ray",
    "start": "1284120",
    "end": "1285880"
  },
  {
    "text": "dashboard as well and we can see that we",
    "start": "1285880",
    "end": "1287600"
  },
  {
    "text": "have consist",
    "start": "1287600",
    "end": "1288799"
  },
  {
    "text": "uh GP",
    "start": "1288799",
    "end": "1291039"
  },
  {
    "text": "utilization all right so this is just",
    "start": "1291039",
    "end": "1292679"
  },
  {
    "text": "like one ex debugging scenario that I",
    "start": "1292679",
    "end": "1294679"
  },
  {
    "text": "just wanted to highlight and this is",
    "start": "1294679",
    "end": "1295840"
  },
  {
    "text": "like kind of a realistic one that uh we",
    "start": "1295840",
    "end": "1298159"
  },
  {
    "text": "pulled from one of our uh one of the",
    "start": "1298159",
    "end": "1300159"
  },
  {
    "text": "users that we were working",
    "start": "1300159",
    "end": "1302720"
  },
  {
    "text": "with okay so now I just want to uh give",
    "start": "1302720",
    "end": "1305919"
  },
  {
    "text": "a demo of kind of all of these",
    "start": "1305919",
    "end": "1307120"
  },
  {
    "text": "components that we were talking about",
    "start": "1307120",
    "end": "1308200"
  },
  {
    "text": "before and I I mostly want to uh",
    "start": "1308200",
    "end": "1310600"
  },
  {
    "text": "highlight the kind of API the apis that",
    "start": "1310600",
    "end": "1313640"
  },
  {
    "text": "we add into uh the ray train apis that",
    "start": "1313640",
    "end": "1316000"
  },
  {
    "text": "we used to enable this kind of uh fall",
    "start": "1316000",
    "end": "1318320"
  },
  {
    "text": "tolerance as well as uh checkpointing",
    "start": "1318320",
    "end": "1320880"
  },
  {
    "text": "logic uh and show this actually in",
    "start": "1320880",
    "end": "1324200"
  },
  {
    "text": "action so let me just play this video",
    "start": "1324200",
    "end": "1327520"
  },
  {
    "text": "and I'll just talk over uh what's",
    "start": "1327520",
    "end": "1329480"
  },
  {
    "text": "happening so the first thing is just to",
    "start": "1329480",
    "end": "1331520"
  },
  {
    "text": "introduce like what's happening in the",
    "start": "1331520",
    "end": "1333159"
  },
  {
    "text": "script this is an accelerate script",
    "start": "1333159",
    "end": "1335520"
  },
  {
    "text": "that's just taken like from hugging",
    "start": "1335520",
    "end": "1337240"
  },
  {
    "text": "faces tutorial and all I've done is uh",
    "start": "1337240",
    "end": "1340159"
  },
  {
    "text": "stripped out most of these like uh kind",
    "start": "1340159",
    "end": "1342320"
  },
  {
    "text": "of the logic of this application into",
    "start": "1342320",
    "end": "1344799"
  },
  {
    "text": "helper functions that are",
    "start": "1344799",
    "end": "1346240"
  },
  {
    "text": "above uh and what's left is just the The",
    "start": "1346240",
    "end": "1348880"
  },
  {
    "text": "Bare Bones of like what the script is",
    "start": "1348880",
    "end": "1350640"
  },
  {
    "text": "trying to convey like the main training",
    "start": "1350640",
    "end": "1352799"
  },
  {
    "text": "Loop and so in the in the training Loop",
    "start": "1352799",
    "end": "1354679"
  },
  {
    "text": "we actually return like the metrics as",
    "start": "1354679",
    "end": "1356679"
  },
  {
    "text": "well as a saved checkpoint so not so the",
    "start": "1356679",
    "end": "1359080"
  },
  {
    "text": "original script already implemented",
    "start": "1359080",
    "end": "1360919"
  },
  {
    "text": "checkpointing with accelerates Save",
    "start": "1360919",
    "end": "1363120"
  },
  {
    "text": "State API so we're just reusing that and",
    "start": "1363120",
    "end": "1365440"
  },
  {
    "text": "we're going to use that later uh when we",
    "start": "1365440",
    "end": "1367200"
  },
  {
    "text": "code up how to report it to R train at",
    "start": "1367200",
    "end": "1370679"
  },
  {
    "text": "the bottom here we actually see the",
    "start": "1370679",
    "end": "1372200"
  },
  {
    "text": "torch trainer definition so all we have",
    "start": "1372200",
    "end": "1374760"
  },
  {
    "text": "right now is the very Bare Bones uh",
    "start": "1374760",
    "end": "1376919"
  },
  {
    "text": "torch trainer uh configuration and we're",
    "start": "1376919",
    "end": "1379679"
  },
  {
    "text": "going to be adding a little bit more uh",
    "start": "1379679",
    "end": "1381000"
  },
  {
    "text": "throughout the",
    "start": "1381000",
    "end": "1382200"
  },
  {
    "text": "demo but basically at this point we're",
    "start": "1382200",
    "end": "1384520"
  },
  {
    "text": "able to launch this training Loop across",
    "start": "1384520",
    "end": "1386600"
  },
  {
    "text": "many workers uh and across our entire",
    "start": "1386600",
    "end": "1388520"
  },
  {
    "text": "rate",
    "start": "1388520",
    "end": "1390159"
  },
  {
    "text": "cluster okay so the next thing I just",
    "start": "1390159",
    "end": "1393880"
  },
  {
    "text": "want to show is like what we're actually",
    "start": "1393880",
    "end": "1395159"
  },
  {
    "text": "running it's just also copy pasted from",
    "start": "1395159",
    "end": "1397640"
  },
  {
    "text": "the hugging Face tutorial we didn't",
    "start": "1397640",
    "end": "1399159"
  },
  {
    "text": "really have to change anything here uh",
    "start": "1399159",
    "end": "1401080"
  },
  {
    "text": "and this is like the main thing I wanted",
    "start": "1401080",
    "end": "1402360"
  },
  {
    "text": "to show here is like it's pretty easy to",
    "start": "1402360",
    "end": "1403880"
  },
  {
    "text": "just take a script that works already uh",
    "start": "1403880",
    "end": "1405919"
  },
  {
    "text": "from like some tutorial and then just",
    "start": "1405919",
    "end": "1407200"
  },
  {
    "text": "report it to ra now you can leverage",
    "start": "1407200",
    "end": "1408960"
  },
  {
    "text": "array cluster so these these configs are",
    "start": "1408960",
    "end": "1411799"
  },
  {
    "text": "just like all taken from the tutorial",
    "start": "1411799",
    "end": "1414600"
  },
  {
    "text": "and notice that the model that we're",
    "start": "1414600",
    "end": "1415760"
  },
  {
    "text": "sharing is this stable diffusion model",
    "start": "1415760",
    "end": "1417600"
  },
  {
    "text": "so the exact task here doesn't really",
    "start": "1417600",
    "end": "1419279"
  },
  {
    "text": "matter for demonstration purposes but I",
    "start": "1419279",
    "end": "1421279"
  },
  {
    "text": "just wanted to show that we can scale to",
    "start": "1421279",
    "end": "1423320"
  },
  {
    "text": "like a large larger models uh very",
    "start": "1423320",
    "end": "1425600"
  },
  {
    "text": "easily with R train",
    "start": "1425600",
    "end": "1427760"
  },
  {
    "text": "uh yeah so let me continue this",
    "start": "1427760",
    "end": "1430960"
  },
  {
    "text": "demo uh so the first thing that we're",
    "start": "1430960",
    "end": "1432760"
  },
  {
    "text": "going to be doing is configuring the",
    "start": "1432760",
    "end": "1434200"
  },
  {
    "text": "storage path so that's like the S3",
    "start": "1434200",
    "end": "1435720"
  },
  {
    "text": "bucket URI that we're connected to as as",
    "start": "1435720",
    "end": "1438000"
  },
  {
    "text": "well as uh the failure config which",
    "start": "1438000",
    "end": "1439640"
  },
  {
    "text": "determines how many retries we'll try",
    "start": "1439640",
    "end": "1441760"
  },
  {
    "text": "when a node goes down or when we have a",
    "start": "1441760",
    "end": "1443320"
  },
  {
    "text": "training",
    "start": "1443320",
    "end": "1444799"
  },
  {
    "text": "failure uh so let me speed up a little",
    "start": "1444799",
    "end": "1450519"
  },
  {
    "text": "bit okay so we're basically just",
    "start": "1456640",
    "end": "1458559"
  },
  {
    "text": "defining the Run config and here we pass",
    "start": "1458559",
    "end": "1462640"
  },
  {
    "text": "in the storage path which is just a",
    "start": "1462640",
    "end": "1464240"
  },
  {
    "text": "predefined S3 URI and also that the",
    "start": "1464240",
    "end": "1467039"
  },
  {
    "text": "failer config as",
    "start": "1467039",
    "end": "1468840"
  },
  {
    "text": "before okay uh next we want to set up",
    "start": "1468840",
    "end": "1473240"
  },
  {
    "text": "checkpointing so as we saw before we're",
    "start": "1473240",
    "end": "1475799"
  },
  {
    "text": "just taking this like already existing",
    "start": "1475799",
    "end": "1477240"
  },
  {
    "text": "checkpoint directory that's being dumped",
    "start": "1477240",
    "end": "1479320"
  },
  {
    "text": "every uh some number of steps by",
    "start": "1479320",
    "end": "1480799"
  },
  {
    "text": "accelerate this original accelerate",
    "start": "1480799",
    "end": "1483240"
  },
  {
    "text": "script and we're going to report it to R",
    "start": "1483240",
    "end": "1485360"
  },
  {
    "text": "train using the R Train report API so",
    "start": "1485360",
    "end": "1487760"
  },
  {
    "text": "notice it's as simple as just like",
    "start": "1487760",
    "end": "1490320"
  },
  {
    "text": "passing the metrics corresponding to",
    "start": "1490320",
    "end": "1492320"
  },
  {
    "text": "this checkpoint as well as the",
    "start": "1492320",
    "end": "1493840"
  },
  {
    "text": "checkpoint directory that already exists",
    "start": "1493840",
    "end": "1495159"
  },
  {
    "text": "so there's no nothing else that needs to",
    "start": "1495159",
    "end": "1496720"
  },
  {
    "text": "be added on top is",
    "start": "1496720",
    "end": "1498919"
  },
  {
    "text": "uh one other note is that since we're",
    "start": "1498919",
    "end": "1501600"
  },
  {
    "text": "doing just a data parallel training here",
    "start": "1501600",
    "end": "1503159"
  },
  {
    "text": "like we're not doing any sharding of",
    "start": "1503159",
    "end": "1504320"
  },
  {
    "text": "model States uh we can just report the",
    "start": "1504320",
    "end": "1507600"
  },
  {
    "text": "checkpoint from a single worker so I'll",
    "start": "1507600",
    "end": "1509720"
  },
  {
    "text": "I'll actually add a little bit more",
    "start": "1509720",
    "end": "1510840"
  },
  {
    "text": "logic which uh only reports this",
    "start": "1510840",
    "end": "1513320"
  },
  {
    "text": "checkpoint from the rank zero worker",
    "start": "1513320",
    "end": "1515760"
  },
  {
    "text": "this makes it so that we don't have to",
    "start": "1515760",
    "end": "1517399"
  },
  {
    "text": "redundantly upload uh copies that we",
    "start": "1517399",
    "end": "1519440"
  },
  {
    "text": "don't need since every single worker has",
    "start": "1519440",
    "end": "1520919"
  },
  {
    "text": "the same",
    "start": "1520919",
    "end": "1523200"
  },
  {
    "text": "state okay so we're just using some of",
    "start": "1523840",
    "end": "1525880"
  },
  {
    "text": "the some other rate train utility apis",
    "start": "1525880",
    "end": "1528000"
  },
  {
    "text": "to get like who is like the the rank",
    "start": "1528000",
    "end": "1530480"
  },
  {
    "text": "zero worker and other every other worker",
    "start": "1530480",
    "end": "1533080"
  },
  {
    "text": "should just report none in this",
    "start": "1533080",
    "end": "1536320"
  },
  {
    "text": "case oh",
    "start": "1536640",
    "end": "1538840"
  },
  {
    "text": "shoot uh sorry about",
    "start": "1538840",
    "end": "1542279"
  },
  {
    "text": "that okay the next part is actually",
    "start": "1542279",
    "end": "1544840"
  },
  {
    "text": "implementing restoration logic so this",
    "start": "1544840",
    "end": "1547559"
  },
  {
    "text": "part is actually pretty simple as well",
    "start": "1547559",
    "end": "1548799"
  },
  {
    "text": "so I'll just I'm just showing like the",
    "start": "1548799",
    "end": "1550480"
  },
  {
    "text": "live coding here um we have we first get",
    "start": "1550480",
    "end": "1554000"
  },
  {
    "text": "the checkpoint the latest checkpoint and",
    "start": "1554000",
    "end": "1555640"
  },
  {
    "text": "this is uh when we Resto when we start",
    "start": "1555640",
    "end": "1557919"
  },
  {
    "text": "our training script uh when Ray",
    "start": "1557919",
    "end": "1559520"
  },
  {
    "text": "reschedules this job we will have this",
    "start": "1559520",
    "end": "1562000"
  },
  {
    "text": "uh checkpoint be populated and we will",
    "start": "1562000",
    "end": "1564600"
  },
  {
    "text": "actually just download it using this as",
    "start": "1564600",
    "end": "1566799"
  },
  {
    "text": "directory API and so now we have it as a",
    "start": "1566799",
    "end": "1569760"
  },
  {
    "text": "local checkpoint directory and we can",
    "start": "1569760",
    "end": "1571640"
  },
  {
    "text": "just uh use accelerates uh load State",
    "start": "1571640",
    "end": "1575200"
  },
  {
    "text": "API to just load it back and we've also",
    "start": "1575200",
    "end": "1578440"
  },
  {
    "text": "saved a little bit of extra state for",
    "start": "1578440",
    "end": "1580120"
  },
  {
    "text": "example the training uh Global step and",
    "start": "1580120",
    "end": "1583039"
  },
  {
    "text": "we're just loading it uh also from this",
    "start": "1583039",
    "end": "1584880"
  },
  {
    "text": "directory so you can pretty much save",
    "start": "1584880",
    "end": "1586520"
  },
  {
    "text": "like in whatever format you want there's",
    "start": "1586520",
    "end": "1588200"
  },
  {
    "text": "no restriction here it's just like",
    "start": "1588200",
    "end": "1590159"
  },
  {
    "text": "however you define the the checkpointing",
    "start": "1590159",
    "end": "1591760"
  },
  {
    "text": "logic is how you should just load it uh",
    "start": "1591760",
    "end": "1594159"
  },
  {
    "text": "in the corresponding",
    "start": "1594159",
    "end": "1596960"
  },
  {
    "text": "way okay so now that we have these two",
    "start": "1596960",
    "end": "1600000"
  },
  {
    "text": "added uh there's just one more piece",
    "start": "1600000",
    "end": "1602720"
  },
  {
    "text": "that we want to",
    "start": "1602720",
    "end": "1603919"
  },
  {
    "text": "add which is uh the experiment tracking",
    "start": "1603919",
    "end": "1606880"
  },
  {
    "text": "tool so let's actually just use 1db so",
    "start": "1606880",
    "end": "1610880"
  },
  {
    "text": "the recommendation here is we can just",
    "start": "1610880",
    "end": "1612120"
  },
  {
    "text": "use 1db directly and we just have the",
    "start": "1612120",
    "end": "1614600"
  },
  {
    "text": "rank zero worker initialize 1db with a",
    "start": "1614600",
    "end": "1617279"
  },
  {
    "text": "unique experiment name and we can also",
    "start": "1617279",
    "end": "1619799"
  },
  {
    "text": "use it to track the art the checkpoint",
    "start": "1619799",
    "end": "1621840"
  },
  {
    "text": "as an artifact later on in training so",
    "start": "1621840",
    "end": "1624679"
  },
  {
    "text": "I'll just skip ahead uh we can we'll",
    "start": "1624679",
    "end": "1626279"
  },
  {
    "text": "take a look at the dashboard later in",
    "start": "1626279",
    "end": "1627799"
  },
  {
    "text": "the",
    "start": "1627799",
    "end": "1629840"
  },
  {
    "text": "demo um yeah so basically we can start",
    "start": "1629840",
    "end": "1632559"
  },
  {
    "text": "running the experiments now after",
    "start": "1632559",
    "end": "1635159"
  },
  {
    "text": "implementing the 1db logic I'll just",
    "start": "1635159",
    "end": "1637320"
  },
  {
    "text": "skip skip",
    "start": "1637320",
    "end": "1640039"
  },
  {
    "text": "ahead uh one other note for the 1db uh",
    "start": "1642200",
    "end": "1645080"
  },
  {
    "text": "API key so because we're going to be",
    "start": "1645080",
    "end": "1648520"
  },
  {
    "text": "like we don't necessarily know which",
    "start": "1648520",
    "end": "1649600"
  },
  {
    "text": "node the rank zero worker is going to be",
    "start": "1649600",
    "end": "1651080"
  },
  {
    "text": "scheduled on we want to make sure that",
    "start": "1651080",
    "end": "1652480"
  },
  {
    "text": "this API key is available on that node",
    "start": "1652480",
    "end": "1655159"
  },
  {
    "text": "so we're just going to use the ray",
    "start": "1655159",
    "end": "1656240"
  },
  {
    "text": "runtime end to make sure that that API",
    "start": "1656240",
    "end": "1658200"
  },
  {
    "text": "key is available on every single node",
    "start": "1658200",
    "end": "1660760"
  },
  {
    "text": "and just pulling from the driver the",
    "start": "1660760",
    "end": "1662279"
  },
  {
    "text": "head",
    "start": "1662279",
    "end": "1664120"
  },
  {
    "text": "node okay so I'll just quickly go",
    "start": "1664120",
    "end": "1666320"
  },
  {
    "text": "through uh basically all I'm doing here",
    "start": "1666320",
    "end": "1669880"
  },
  {
    "text": "is just running the script with four",
    "start": "1669880",
    "end": "1672720"
  },
  {
    "text": "workers and I'm waiting until I see that",
    "start": "1672720",
    "end": "1675760"
  },
  {
    "text": "the checkpoint is actually reported to",
    "start": "1675760",
    "end": "1677640"
  },
  {
    "text": "ra",
    "start": "1677640",
    "end": "1678320"
  },
  {
    "text": "train",
    "start": "1678320",
    "end": "1679880"
  },
  {
    "text": "uh so basically the checkpoint gets",
    "start": "1679880",
    "end": "1682159"
  },
  {
    "text": "uploaded to S3 there was like a log",
    "start": "1682159",
    "end": "1683679"
  },
  {
    "text": "earlier so I like kind of skipped it but",
    "start": "1683679",
    "end": "1686120"
  },
  {
    "text": "now I'm just showing the actual GP",
    "start": "1686120",
    "end": "1687360"
  },
  {
    "text": "utilization in the ray",
    "start": "1687360",
    "end": "1690279"
  },
  {
    "text": "dashboard and then the uh also the logs",
    "start": "1690279",
    "end": "1692799"
  },
  {
    "text": "in WB so we can take a look at the",
    "start": "1692799",
    "end": "1695679"
  },
  {
    "text": "metrics that we reported as well as the",
    "start": "1695679",
    "end": "1698000"
  },
  {
    "text": "checkpoint artifacts that we've uh",
    "start": "1698000",
    "end": "1699799"
  },
  {
    "text": "tracked so we can take a look at the",
    "start": "1699799",
    "end": "1701240"
  },
  {
    "text": "files as well as some metadata which",
    "start": "1701240",
    "end": "1703360"
  },
  {
    "text": "also includes like the the metric",
    "start": "1703360",
    "end": "1704600"
  },
  {
    "text": "associated with the",
    "start": "1704600",
    "end": "1706440"
  },
  {
    "text": "checkpoint",
    "start": "1706440",
    "end": "1709440"
  },
  {
    "text": "okay and the last thing I wanted to show",
    "start": "1709640",
    "end": "1711240"
  },
  {
    "text": "in this",
    "start": "1711240",
    "end": "1713000"
  },
  {
    "text": "demo uh sorry is I'm going to launch a",
    "start": "1713000",
    "end": "1716919"
  },
  {
    "text": "script that just kills one of the nodes",
    "start": "1716919",
    "end": "1719480"
  },
  {
    "text": "so once one of the nodes gets killed",
    "start": "1719480",
    "end": "1721600"
  },
  {
    "text": "this is just to show like a how the",
    "start": "1721600",
    "end": "1723799"
  },
  {
    "text": "fault tolerance Works in practice once",
    "start": "1723799",
    "end": "1726159"
  },
  {
    "text": "one of the node dies you'll see this log",
    "start": "1726159",
    "end": "1728240"
  },
  {
    "text": "that you know Ray tells you that it's",
    "start": "1728240",
    "end": "1730000"
  },
  {
    "text": "missed too many heartbeats and the the",
    "start": "1730000",
    "end": "1732279"
  },
  {
    "text": "training is going to",
    "start": "1732279",
    "end": "1734360"
  },
  {
    "text": "restart and then the last part of the",
    "start": "1734360",
    "end": "1736159"
  },
  {
    "text": "script is just showing that training is",
    "start": "1736159",
    "end": "1738360"
  },
  {
    "text": "restarting the dashboard is updated with",
    "start": "1738360",
    "end": "1740640"
  },
  {
    "text": "all the statuses of the node getting",
    "start": "1740640",
    "end": "1742000"
  },
  {
    "text": "terminated and the new node coming up",
    "start": "1742000",
    "end": "1744600"
  },
  {
    "text": "and then eventually we see that uh the",
    "start": "1744600",
    "end": "1746480"
  },
  {
    "text": "restoration logic starts uh coming into",
    "start": "1746480",
    "end": "1748679"
  },
  {
    "text": "play as we can see this print statement",
    "start": "1748679",
    "end": "1750399"
  },
  {
    "text": "is starting to restore and then",
    "start": "1750399",
    "end": "1752480"
  },
  {
    "text": "eventually after it downloads this",
    "start": "1752480",
    "end": "1754039"
  },
  {
    "text": "checkpoint and loads the state back with",
    "start": "1754039",
    "end": "1756080"
  },
  {
    "text": "accelerates API it will just uh resume",
    "start": "1756080",
    "end": "1759080"
  },
  {
    "text": "training and we can see that the number",
    "start": "1759080",
    "end": "1760799"
  },
  {
    "text": "of the total number of uh training steps",
    "start": "1760799",
    "end": "1763480"
  },
  {
    "text": "has decreased because we've uh restored",
    "start": "1763480",
    "end": "1766080"
  },
  {
    "text": "from a certain uh time step",
    "start": "1766080",
    "end": "1768440"
  },
  {
    "text": "okay that's pretty much uh all there is",
    "start": "1768440",
    "end": "1770320"
  },
  {
    "text": "to the demo thank you and I'll accept a",
    "start": "1770320",
    "end": "1772440"
  },
  {
    "text": "few",
    "start": "1772440",
    "end": "1774639"
  },
  {
    "text": "[Applause]",
    "start": "1774750",
    "end": "1778640"
  },
  {
    "text": "questions",
    "start": "1778640",
    "end": "1781640"
  }
]
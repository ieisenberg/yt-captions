[
  {
    "text": "hi this is Will from Lang chain today I'm going to walk through how to create plan and execute style agents in L graph",
    "start": "1400",
    "end": "8000"
  },
  {
    "text": "for those of you not familiar with Lang graph we've got a great set of videos on YouTube that you can go through to get a little more of an introduction but a",
    "start": "8000",
    "end": "14639"
  },
  {
    "text": "short summary of it would be that it's a framework built on top of Lang chain core that provides a graph based syntax",
    "start": "14639",
    "end": "21119"
  },
  {
    "text": "that gives you a great balance between expressivity and control when building things like agents and state machines",
    "start": "21119",
    "end": "26720"
  },
  {
    "text": "that require Loop type workflows um you can go and you can install it here check out the repo um in the Lang chain AI",
    "start": "26720",
    "end": "33760"
  },
  {
    "text": "organization in GitHub I'm particularly excited about this video because plan and execute style agents bring agents a step closer",
    "start": "33760",
    "end": "40680"
  },
  {
    "text": "to being production ready in general they can help you have faster execution time lower token costs and overall have",
    "start": "40680",
    "end": "47360"
  },
  {
    "text": "the promise to have better reliability relative to previous generations of Agents um I guess before we jump too far",
    "start": "47360",
    "end": "54399"
  },
  {
    "text": "ahead we'll go give a brief background on some of llm Agents um by using react",
    "start": "54399",
    "end": "60239"
  },
  {
    "text": "as an example so a little over a year and a half ago I guess now um sh ya from Princeton proposed the react paper which",
    "start": "60239",
    "end": "66320"
  },
  {
    "text": "stands for reasoning and action uh because of the way it prompts language models to reason about the types of",
    "start": "66320",
    "end": "72159"
  },
  {
    "text": "things that it needs to do uh and then output an action that will then be parsed and put into other software in",
    "start": "72159",
    "end": "79400"
  },
  {
    "text": "order to take actions in the real world and so in this way the language model can power an agent in a situated",
    "start": "79400",
    "end": "84840"
  },
  {
    "text": "environment such as a web browser or another application and take those actions so um this is an example of the",
    "start": "84840",
    "end": "91479"
  },
  {
    "text": "prompt of a react agent it has a place for it to be updating its observations",
    "start": "91479",
    "end": "96560"
  },
  {
    "text": "from previous steps you have different tools it's provided and um it will output the next action so it'll action",
    "start": "96560",
    "end": "103520"
  },
  {
    "text": "for um search and then it will pick the high scoring offensive player in the NFL for instance given my input question um",
    "start": "103520",
    "end": "110200"
  },
  {
    "text": "and then after a time it decides that it has enough information to respond and will respond direct to the final",
    "start": "110200",
    "end": "115640"
  },
  {
    "text": "user this works often and it it exposes uh a really powerful capability of llms",
    "start": "115640",
    "end": "121799"
  },
  {
    "text": "that wasn't originally um thought of however it has some limitations for one it it requires an llm for each tool",
    "start": "121799",
    "end": "128599"
  },
  {
    "text": "invocation and so these serial execution can take a lot of time um second it's only doing one step at a time and so",
    "start": "128599",
    "end": "135920"
  },
  {
    "text": "it's possible that the llm could be shortsighted and pick a a Next Step that makes some sense but that doesn't",
    "start": "135920",
    "end": "141800"
  },
  {
    "text": "actually um get us all the way to um the the output in a very strategic or or efficient manner um and then uh there's",
    "start": "141800",
    "end": "149879"
  },
  {
    "text": "some other other um potential limitations and that it can't do parallel calls and stuff like that so um",
    "start": "149879",
    "end": "155360"
  },
  {
    "text": "it works in in some cases but isn't super um fast relative to what we have today um",
    "start": "155360",
    "end": "161519"
  },
  {
    "text": "to to address this a design pattern for agents has been proposed by a number of",
    "start": "161519",
    "end": "168440"
  },
  {
    "text": "people um over the past year or so uh for a a plan and execute style and so it",
    "start": "168440",
    "end": "174200"
  },
  {
    "text": "breaks down agents into a couple of main modules um one is the planner so the the",
    "start": "174200",
    "end": "179879"
  },
  {
    "text": "first step is to take the user input and then whatever additional environmental cues you might have and then generate a",
    "start": "179879",
    "end": "185200"
  },
  {
    "text": "plan of the steps it needs to take in order to obain the information required or order to take actions to bring the",
    "start": "185200",
    "end": "191879"
  },
  {
    "text": "environment to the desired State um once it generates those tasks you'll have",
    "start": "191879",
    "end": "197280"
  },
  {
    "text": "particular um like executors or other types of functionality in order to execute that task and then optionally",
    "start": "197280",
    "end": "203159"
  },
  {
    "text": "you'll have a step they can choose to replan and this is the looping logic that it often characterizes an agent um",
    "start": "203159",
    "end": "209799"
  },
  {
    "text": "this paper uh or this this example that we have here the plan and execute example is based largely on the plan and",
    "start": "209799",
    "end": "215599"
  },
  {
    "text": "solve paper here by um see long at all um and it's also based a little bit on",
    "start": "215599",
    "end": "222519"
  },
  {
    "text": "on the BB AGI project from yima um it's pretty simple in this example we'll run",
    "start": "222519",
    "end": "228400"
  },
  {
    "text": "through you uh first populate with your open AI key your Tav API key which is",
    "start": "228400",
    "end": "233840"
  },
  {
    "text": "the search engine and we'll go and set up tracing with Lang Smith and that",
    "start": "233840",
    "end": "238879"
  },
  {
    "text": "helps you really you bug and observe all the choices that the agent makes over the the course of its trajectory as it's",
    "start": "238879",
    "end": "245079"
  },
  {
    "text": "trying to solve the task so you can really drill down and see how efficient it's being over time and you'll create",
    "start": "245079",
    "end": "250959"
  },
  {
    "text": "the tools and then you'll pull from the the the pumpt and create the uh the agent",
    "start": "250959",
    "end": "258880"
  },
  {
    "text": "itself so in our case the main components again are the planner rep planner and the tool executors um this",
    "start": "258880",
    "end": "265280"
  },
  {
    "text": "first bit is the agent that we're going to be creating uh and this is the actual execution agent so after the planner has",
    "start": "265280",
    "end": "271840"
  },
  {
    "text": "created the task list it subdivides it so it can divide and conquer and then for each task this execution agent will",
    "start": "271840",
    "end": "278800"
  },
  {
    "text": "then be taking that and try to use whatever tool it's provided in order to answer the question um so create that",
    "start": "278800",
    "end": "285479"
  },
  {
    "text": "you got the agent executor and you can invoke it there and do um whatever so this is an example who's the winner of",
    "start": "285479",
    "end": "291560"
  },
  {
    "text": "the US Open um we're just going to give it let's see we gave it the search engine so we can see if it can come in",
    "start": "291560",
    "end": "297320"
  },
  {
    "text": "an answer there while that's running um you can show the the L graph",
    "start": "297320",
    "end": "303080"
  },
  {
    "text": "state so again if you're familiar with L graph or the state graph within L graph each node represents a module so it",
    "start": "303080",
    "end": "310440"
  },
  {
    "text": "could have one for the planner one for the executor one for the solver um each node receives the state whenever it's",
    "start": "310440",
    "end": "317520"
  },
  {
    "text": "invoked and the response of that node then is up used to update the state and",
    "start": "317520",
    "end": "322600"
  },
  {
    "text": "this is how the the graph then proceeds to its computation um as you can see it's a state machine in our case we have",
    "start": "322600",
    "end": "328800"
  },
  {
    "text": "a few different things we we have the input we have the plan that the vender generates we have the pth states which are populated um this annotation",
    "start": "328800",
    "end": "336360"
  },
  {
    "text": "annotated um means that any response is just appended to this list here we take",
    "start": "336360",
    "end": "342440"
  },
  {
    "text": "that annotated syntax um as a a way to define how the state is updated and",
    "start": "342440",
    "end": "348160"
  },
  {
    "text": "there's the final response which is populated by the solver there um we will",
    "start": "348160",
    "end": "353280"
  },
  {
    "text": "create a structured output runable which again will use function calling or tool calling from open a to populate a pantic",
    "start": "353280",
    "end": "362520"
  },
  {
    "text": "object directly from um the user input so we've got this prompt saying it needs to come up with a simple plan um we",
    "start": "362520",
    "end": "369039"
  },
  {
    "text": "parse it as steps so there's just a list of steps again this is just a way of connecting with the fine tuned model",
    "start": "369039",
    "end": "374960"
  },
  {
    "text": "that open a has fine-tuned to generate code AS structured output and then we have this parser which will then put it",
    "start": "374960",
    "end": "381440"
  },
  {
    "text": "in there and it's a pretty reliable way of parsing the output um so you can",
    "start": "381440",
    "end": "387360"
  },
  {
    "text": "generate the plan there and then the replan steps so if it isn't able to completely accomplish the intended goal",
    "start": "387360",
    "end": "393520"
  },
  {
    "text": "in the first step we will prompt a re uhlaner which has the objective the",
    "start": "393520",
    "end": "399880"
  },
  {
    "text": "original plan pth steps and like all the results from those and then it is passed",
    "start": "399880",
    "end": "405440"
  },
  {
    "text": "with updating the plan um or responding so you can do that we'll populate it with this llm and again the um yeah the",
    "start": "405440",
    "end": "412680"
  },
  {
    "text": "prompt there and it's two choices of tools so it can either respond or it can plan and again since this model that",
    "start": "412680",
    "end": "419479"
  },
  {
    "text": "open air has developed is fine-tuned on code generation is pretty good at outputting structured syntax and we par",
    "start": "419479",
    "end": "425400"
  },
  {
    "text": "them into these pantic objects which makes it easier to maintain within your existing software",
    "start": "425400",
    "end": "431440"
  },
  {
    "text": "stack finally now that we've defined um all these Primitives we can create the graph so we'll have one node that",
    "start": "431440",
    "end": "437520"
  },
  {
    "text": "executes the steps one plans and one that replans and then this conditional Edge that decides whether it should end",
    "start": "437520",
    "end": "444080"
  },
  {
    "text": "or not um so all of these and these could be asynchronous or it can be synchronous as well kind of depends on",
    "start": "444080",
    "end": "451120"
  },
  {
    "text": "the performance characteristics you want the uh yeah so so we first we create this workflow and we Define it with this",
    "start": "451120",
    "end": "457400"
  },
  {
    "text": "plan execute state that we defined above and then um we add each node which as I",
    "start": "457400",
    "end": "462560"
  },
  {
    "text": "mentioned before is the different modules and then we Define how those modules are connected so after each note",
    "start": "462560",
    "end": "469479"
  },
  {
    "text": "uh is called we can either say that there's a specific like an edge from",
    "start": "469479",
    "end": "474960"
  },
  {
    "text": "that node to another one which means it will always progress and the state will always pass the next node or we can add",
    "start": "474960",
    "end": "480520"
  },
  {
    "text": "this conditional Edge which means that give whether this um should end function",
    "start": "480520",
    "end": "485720"
  },
  {
    "text": "is called um basically after after node replan is called should end is called",
    "start": "485720",
    "end": "491280"
  },
  {
    "text": "and then that will determine whether the output should um end or whether it should go back to the agent here so this",
    "start": "491280",
    "end": "498199"
  },
  {
    "text": "is just a way of having conditional logic of passing the computation between",
    "start": "498199",
    "end": "503280"
  },
  {
    "text": "nodes um finally we can actually call this so in this case we have this",
    "start": "503280",
    "end": "508759"
  },
  {
    "text": "configuration that sets recation limit this is basically a cap on the number of steps we let the agent take you could set this",
    "start": "508759",
    "end": "514959"
  },
  {
    "text": "to an arbitrarily large number um but in general we'd recommend that you keep it um within some reason since um most",
    "start": "514959",
    "end": "522000"
  },
  {
    "text": "these cases are relatively time sensitive and you don't want to be continuously calling an llm if it gets stuck in",
    "start": "522000",
    "end": "527360"
  },
  {
    "text": "Loop um and then here's the input to it so we can stream the outputs and then",
    "start": "527360",
    "end": "532560"
  },
  {
    "text": "we'll say if it is the end event we'll actually print out the full uh end",
    "start": "532560",
    "end": "537839"
  },
  {
    "text": "object here so here's a a plan um and we'll watch it progress there",
    "start": "537839",
    "end": "544560"
  },
  {
    "text": "since I turned on streaming we can actually then go to the uh this project",
    "start": "544560",
    "end": "549880"
  },
  {
    "text": "here so we can BL up in Lang Smith and you can see as it continues to execute all these series of steps it's making so",
    "start": "549880",
    "end": "555399"
  },
  {
    "text": "we're printing it out in the notebook you can also see see all these nodes in the graph you can see all of them so you",
    "start": "555399",
    "end": "560760"
  },
  {
    "text": "can see there's a lot of steps that lame graph um of escapes for you but you can see the most important ones here and you",
    "start": "560760",
    "end": "567480"
  },
  {
    "text": "can see for instance here's the planner um you can see that it called this tool which returns a bunch of information",
    "start": "567480",
    "end": "573959"
  },
  {
    "text": "about the 2024 Australian Open um you can see that it is going to be",
    "start": "573959",
    "end": "579560"
  },
  {
    "text": "choosing or it's able to summarize that and then it goes here and this is like",
    "start": "579560",
    "end": "584800"
  },
  {
    "text": "response um and so it outputs a a new plan so it's looking more about the like",
    "start": "584800",
    "end": "590240"
  },
  {
    "text": "Hometown and all these types of things so it's giving more of a background into it and so if you think that this is",
    "start": "590240",
    "end": "595279"
  },
  {
    "text": "being Tu verose you can then look into the different prompts that these are using and modify those using the",
    "start": "595279",
    "end": "600640"
  },
  {
    "text": "playground if you want um I won't get too far into that so we have plenty of examples there and I want to get on to",
    "start": "600640",
    "end": "606279"
  },
  {
    "text": "other examples but I think that's a great way of just tracking how the agent's progressing through Lane graph",
    "start": "606279",
    "end": "611600"
  },
  {
    "text": "there so it looks like it actually hit the recursion liit in this case um and so I could update the prompts to try to make it make sure that it's not getting",
    "start": "611600",
    "end": "618240"
  },
  {
    "text": "to um everb in in its research we can say that keep it as efficient as possible and um that'll make it be a",
    "start": "618240",
    "end": "624839"
  },
  {
    "text": "little bit more effective there um I'm going to go on to the next one now which is reasoning without observation paper",
    "start": "624839",
    "end": "632320"
  },
  {
    "text": "by Shu at all so if you recall in the react paper",
    "start": "632320",
    "end": "638000"
  },
  {
    "text": "the limitation was that it called an llm on every step and that is pretty slow and it's expensive since you're",
    "start": "638000",
    "end": "643959"
  },
  {
    "text": "involving an llm call and sending this redundant prefix you have the system prompt and everything at the beginning",
    "start": "643959",
    "end": "649920"
  },
  {
    "text": "um then in the plan and execute paper the plan and solve paper we solved a bit",
    "start": "649920",
    "end": "655440"
  },
  {
    "text": "of that by saying let's generate a task list here and then we can actually execute those things accordingly the",
    "start": "655440",
    "end": "661279"
  },
  {
    "text": "problem is that task list was all still just a list of strings and there wasn't any sorts of variable substitution or",
    "start": "661279",
    "end": "667040"
  },
  {
    "text": "anything there so it just took it and um had to had the the tools called in",
    "start": "667040",
    "end": "672120"
  },
  {
    "text": "sequence and then um had this response and the repl planner was tasked with deciding oh now do I need to generate",
    "start": "672120",
    "end": "678440"
  },
  {
    "text": "more information now that I've actually received um answers to my first questions there in the plan uh reasoning",
    "start": "678440",
    "end": "685399"
  },
  {
    "text": "without observation goes a step further and allows variable substitution so the initial plan can actually include",
    "start": "685399",
    "end": "692800"
  },
  {
    "text": "a search for the first step and then include information from that search in the Second Step without actually having",
    "start": "692800",
    "end": "698320"
  },
  {
    "text": "to consult the planner again um this of course saves you a lot of time because you don't have to involve an llm in",
    "start": "698320",
    "end": "703360"
  },
  {
    "text": "every step and um lets you actually go all the way to to completion without having to replan in many cases so long",
    "start": "703360",
    "end": "710040"
  },
  {
    "text": "as the tool responses result in a reasonable um output this is a diagram",
    "start": "710040",
    "end": "715639"
  },
  {
    "text": "of the overall graph that we're going to create so you can see the main components again our planner you have this worker which again executes the the",
    "start": "715639",
    "end": "722560"
  },
  {
    "text": "tasks in sequence and a solver which takes those results and then response to the user directly um you can see we'll",
    "start": "722560",
    "end": "730160"
  },
  {
    "text": "see like a a trace later about this for all these examples we'll give it a",
    "start": "730160",
    "end": "735680"
  },
  {
    "text": "similar tool so we'll have this Tav search engine tool you could replace with any search engine it's more of a a",
    "start": "735680",
    "end": "741320"
  },
  {
    "text": "demonstration of how the agent works that we're going for uh and we'll also set up Lang chain tracing just so we can",
    "start": "741320",
    "end": "747240"
  },
  {
    "text": "get a nice um in-depth uh observation and trace of how the agents working so",
    "start": "747240",
    "end": "752639"
  },
  {
    "text": "that we can debug different things if they do arise um in this case our state",
    "start": "752639",
    "end": "757720"
  },
  {
    "text": "for the graph includes the task the planning string um so these are for for the task execution node um the steps",
    "start": "757720",
    "end": "765120"
  },
  {
    "text": "that were proposed any results from uh the the uh task execution so again since",
    "start": "765120",
    "end": "771079"
  },
  {
    "text": "we have variable substitution uh this will be populated with those results so that you can then use it to replace",
    "start": "771079",
    "end": "776880"
  },
  {
    "text": "those variables in later values and the final result",
    "start": "776880",
    "end": "782279"
  },
  {
    "text": "um maybe I'll dive a little bit more into the format of the prompt here like you can see here the um the format for",
    "start": "782279",
    "end": "789279"
  },
  {
    "text": "the planner it outputs a plan which is similar to the reasoning step to the react agent and this says like search",
    "start": "789279",
    "end": "795480"
  },
  {
    "text": "for information about henchata so it's it's an ability to do some Chain of Thought reasoning and improve the",
    "start": "795480",
    "end": "800600"
  },
  {
    "text": "likelihood that its plan is going to be um perform better it then assigns",
    "start": "800600",
    "end": "805959"
  },
  {
    "text": "variables to each of these tool calls so to say like uh pound E1 for search",
    "start": "805959",
    "end": "811040"
  },
  {
    "text": "Wikipedia for the henchata um it also has always given this llm call and I",
    "start": "811040",
    "end": "816360"
  },
  {
    "text": "find this particular be an interesting design decision it basically is used to get around the fact that the outputs a",
    "start": "816360",
    "end": "822720"
  },
  {
    "text": "lot of these tools aren't like need to be additionally formatted for uh like subsequent calls or you might want to be",
    "start": "822720",
    "end": "829760"
  },
  {
    "text": "in including some additional reasoning steps in there without having to go back to the planner while this is still an",
    "start": "829760",
    "end": "836720"
  },
  {
    "text": "additional llm call since it's more scoped presumably you can use a a faster",
    "start": "836720",
    "end": "842680"
  },
  {
    "text": "or or cheaper llm than what you would use for the planner so you might use gp4 or whatever next version of that in the",
    "start": "842680",
    "end": "848240"
  },
  {
    "text": "planner and then with each llm call you might do 3.5 or an open source model or something like that um so you can still",
    "start": "848240",
    "end": "855399"
  },
  {
    "text": "get some performance gains there uh I'll skip over the worker and solver for now since we'll talk about",
    "start": "855399",
    "end": "861160"
  },
  {
    "text": "that later but suffice to say the planner here takes this prompt and then outputs a plan using this format pretty",
    "start": "861160",
    "end": "868360"
  },
  {
    "text": "straight forward the executor then takes the tasks and um and will execute the",
    "start": "868360",
    "end": "874720"
  },
  {
    "text": "tool directly so you can see basically we'll get the current task from the state and so this basically looks at the",
    "start": "874720",
    "end": "879839"
  },
  {
    "text": "results and then Returns the information there um it then looks at the steps",
    "start": "879839",
    "end": "885040"
  },
  {
    "text": "which again was that regx output from above and goes through uh the the",
    "start": "885040",
    "end": "891040"
  },
  {
    "text": "results that we have so far and if we have an instance of that variable we'll replace it with the actual output um so",
    "start": "891040",
    "end": "898199"
  },
  {
    "text": "if I did a search originally and then you have pound E2 # E2 um you'll then",
    "start": "898199",
    "end": "904240"
  },
  {
    "text": "like replace that within the string so that that later tool call can use that information from previous steps in its",
    "start": "904240",
    "end": "910079"
  },
  {
    "text": "output um and then you can see we're doing this look up for our search engine and um and you can add other tools here",
    "start": "910079",
    "end": "916720"
  },
  {
    "text": "if you want and I believe in the paper they tested up to 20 tools and said that it worked okay but um as we know from",
    "start": "916720",
    "end": "923560"
  },
  {
    "text": "this and other studies if you have too many tools the quality it often serves",
    "start": "923560",
    "end": "928839"
  },
  {
    "text": "to distract the LM it uses more tokens and um Can often have negative consequences so yeah you usually want to",
    "start": "928839",
    "end": "936319"
  },
  {
    "text": "pick a proper number of tools and reduce the number of extraneous ones if they're not going to be used very often or if",
    "start": "936319",
    "end": "942319"
  },
  {
    "text": "they're not high value for most of your use cases um and we have other videos on",
    "start": "942319",
    "end": "948480"
  },
  {
    "text": "how to balance that and how to use l graph actually to be selecting tools and it um with most other videos and we have",
    "start": "948480",
    "end": "954279"
  },
  {
    "text": "examples in the repo all right next comes the solver so",
    "start": "954279",
    "end": "960040"
  },
  {
    "text": "this is similar to the previous one it executes the uh it decides the final",
    "start": "960040",
    "end": "965240"
  },
  {
    "text": "response based on the tool responses so um can run that and finally the graph",
    "start": "965240",
    "end": "971160"
  },
  {
    "text": "itself again you have each node there a plan tool and solve and then we say",
    "start": "971160",
    "end": "976360"
  },
  {
    "text": "every time that we plan we then go to the tool node um this tool node again just goes through all of the plan in",
    "start": "976360",
    "end": "982199"
  },
  {
    "text": "sequence and executes them um we then have the solve node which um is always",
    "start": "982199",
    "end": "987959"
  },
  {
    "text": "traversed to from tool to solve and then finally we have this conditional Edge",
    "start": "987959",
    "end": "993000"
  },
  {
    "text": "which says that if again so if there's the next step or if there's no more",
    "start": "993000",
    "end": "998600"
  },
  {
    "text": "steps left to execute we'll go to the solve one so we'll finish the loop um",
    "start": "998600",
    "end": "1003759"
  },
  {
    "text": "otherwise we'll continue to stay at this tool Loop so again in picture form it",
    "start": "1003759",
    "end": "1010560"
  },
  {
    "text": "first goes to the planner node this generates a task list that goes to the worker and the conditional Edge defines",
    "start": "1010560",
    "end": "1016440"
  },
  {
    "text": "whether it's going to continue to Loop or whether it goes to here and then it responds to the user there all right so",
    "start": "1016440",
    "end": "1022720"
  },
  {
    "text": "we'll finally prompt our reu agent with the task that we provided which is to",
    "start": "1022720",
    "end": "1029480"
  },
  {
    "text": "look up the hometown of the 2024 Australian Open winner and while this is running I'll pull up L Smith just to",
    "start": "1029480",
    "end": "1035720"
  },
  {
    "text": "show what it will look like as you're debugging this so you can see it's streaming right now and then you can",
    "start": "1035720",
    "end": "1042120"
  },
  {
    "text": "look at the first LM call which is the planner call um so it has the prompt here and you see the tools that we've",
    "start": "1042120",
    "end": "1048160"
  },
  {
    "text": "provided Ed it and you see the task where is the hometown of the 2024 Australian Open",
    "start": "1048160",
    "end": "1053640"
  },
  {
    "text": "winner it generates this plan which seems to make a little bit of sense so it first is going to search for the",
    "start": "1053640",
    "end": "1059280"
  },
  {
    "text": "winner and then we'll use the llm as an extraction function essentially to take the winner out from the results again",
    "start": "1059280",
    "end": "1065919"
  },
  {
    "text": "the results are a Json list it's pretty long so this is actually an improvement that we'll give it just a couple words",
    "start": "1065919",
    "end": "1072600"
  },
  {
    "text": "um for the next function next one is the uh to search for the hometown and then give this information",
    "start": "1072600",
    "end": "1079039"
  },
  {
    "text": "and then it says retrieve the hometown from the results so again extract from this search function seems to have that",
    "start": "1079039",
    "end": "1084120"
  },
  {
    "text": "pattern down um we'll do a brief refresh just to look at what other functions has done looks like it did call the search",
    "start": "1084120",
    "end": "1091120"
  },
  {
    "text": "engine there and then called it again with the hometown given the content equals this um so we will show the",
    "start": "1091120",
    "end": "1101440"
  },
  {
    "text": "output the hometown is Italy doesn't necessarily make the most sense looks",
    "start": "1101440",
    "end": "1106640"
  },
  {
    "text": "like we're using 3.5 turbo so could get improvement with a better model um or with better prompting here um to really",
    "start": "1106640",
    "end": "1112600"
  },
  {
    "text": "focus in the hometown there um but you can see that it at least found some relevant information based on this and",
    "start": "1112600",
    "end": "1118880"
  },
  {
    "text": "using lsmith we were able to see some things that we could improve so without wanting to take too",
    "start": "1118880",
    "end": "1124760"
  },
  {
    "text": "much more time on this a recap of this REO paper is that it improves on the",
    "start": "1124760",
    "end": "1130880"
  },
  {
    "text": "plan and execute approach the the naive plan execute approach by allowing variable substitution it was able to go",
    "start": "1130880",
    "end": "1137280"
  },
  {
    "text": "and uh use that sequence of of steps with search and then extract without",
    "start": "1137280",
    "end": "1142440"
  },
  {
    "text": "having to call the planner llm again with this redundant step of of agent scratch pad and all that kind of stuff",
    "start": "1142440",
    "end": "1148919"
  },
  {
    "text": "so um in theory is able to save a lot of time in tokens in doing so the problem this still has is that it",
    "start": "1148919",
    "end": "1155640"
  },
  {
    "text": "still relies on a sequential stat series of um of tasks we don't explicitly track",
    "start": "1155640",
    "end": "1162440"
  },
  {
    "text": "the dependencies of each tool you can add that um and then all the tools are invoked only after the LM itself",
    "start": "1162440",
    "end": "1168799"
  },
  {
    "text": "completes its response so you wait until the full generation is done and then you execute the tools in sequence and then",
    "start": "1168799",
    "end": "1175559"
  },
  {
    "text": "you call the the solver so all of this adds time in your execution if a user is waiting for the response it's not the",
    "start": "1175559",
    "end": "1181480"
  },
  {
    "text": "best user experience um the llm compiler paper by Kim at Al",
    "start": "1181480",
    "end": "1188280"
  },
  {
    "text": "sets out to address some of these limitations that we saw in the REO paper",
    "start": "1188280",
    "end": "1193520"
  },
  {
    "text": "um it's designed to speed up the execution of the agent by",
    "start": "1193520",
    "end": "1199120"
  },
  {
    "text": "two main approaches one it streams tasks in the form of a dag um so each task it",
    "start": "1199120",
    "end": "1205640"
  },
  {
    "text": "has has the variable substitution there along with an explicit list of dependencies so in those later search",
    "start": "1205640",
    "end": "1212120"
  },
  {
    "text": "steps it marks as its dependent on the first one for instance and then we'll go there um so you can be having some of",
    "start": "1212120",
    "end": "1218880"
  },
  {
    "text": "these tools executing in parallel rather than all in sequence that's going to save us a decent amount of time if each",
    "start": "1218880",
    "end": "1224799"
  },
  {
    "text": "of these search operations is going to add up second we're actually streaming the task output itself um so as each",
    "start": "1224799",
    "end": "1232120"
  },
  {
    "text": "token comes out we check to see if we can then parse a new task from that streaming output and as soon as that",
    "start": "1232120",
    "end": "1237799"
  },
  {
    "text": "available we pass that on to the task fetching unit this again saves us a lot of time because while the llm especially",
    "start": "1237799",
    "end": "1244159"
  },
  {
    "text": "for a long plan while the llm is outputting more tokens we can already start executing these earlier tasks and",
    "start": "1244159",
    "end": "1251200"
  },
  {
    "text": "and and saving the time overall um so this can get us above some of the performance of for instance some of the",
    "start": "1251200",
    "end": "1256799"
  },
  {
    "text": "naive parallel tool execution of open Ai and um the previous plan and execute examples we reviewed today um this task",
    "start": "1256799",
    "end": "1264039"
  },
  {
    "text": "fing unit will go into further detail later but it basically uses multi-threading and we'll schedule a task as soon as the dependencies are met",
    "start": "1264039",
    "end": "1271520"
  },
  {
    "text": "once all of these tasks are finished the rest of this is basically the same as the other examples we saw so we update",
    "start": "1271520",
    "end": "1278279"
  },
  {
    "text": "the state with the task results and then we have this Joiner which essentially is a dynamic rep planner that takes the",
    "start": "1278279",
    "end": "1283640"
  },
  {
    "text": "results the input and all of that information and decides will it go um respond to the user or is it going to",
    "start": "1283640",
    "end": "1290400"
  },
  {
    "text": "generate a replan operation and then that will then go back to this task fetching unit",
    "start": "1290400",
    "end": "1296919"
  },
  {
    "text": "there um so again we're going to all right we'll set set up lsmith and",
    "start": "1296919",
    "end": "1303320"
  },
  {
    "text": "install our dependencies here I've already done so um I wanted to add my API key for lsmith so it can go to this",
    "start": "1303320",
    "end": "1309000"
  },
  {
    "text": "separate project um the LM compiler project so we can really group our traces like that um and then without",
    "start": "1309000",
    "end": "1315520"
  },
  {
    "text": "further Ado we can Define all of the different components of our agent we'll start by defining the tools in this case",
    "start": "1315520",
    "end": "1322000"
  },
  {
    "text": "we're going to have both the search engine which we're doing this tavali engine again and the um a math tool",
    "start": "1322000",
    "end": "1327840"
  },
  {
    "text": "which is you know an ASD parser and and and a calculator there we use in llm",
    "start": "1327840",
    "end": "1334880"
  },
  {
    "text": "within the math tool since the outputs of search results may be unstructured and we want to make sure that we can",
    "start": "1334880",
    "end": "1340799"
  },
  {
    "text": "structure it into specific floats this is akin to what we saw in RIU we having",
    "start": "1340799",
    "end": "1346159"
  },
  {
    "text": "a separate llm tool that can call that would extract those results for us um so",
    "start": "1346159",
    "end": "1352000"
  },
  {
    "text": "we'll Define those and you can see for instance this calculator here it's going to be outputting the results based on",
    "start": "1352000",
    "end": "1359000"
  },
  {
    "text": "some of these things even if there is misspellings and other things in the input it has this optional context",
    "start": "1359000",
    "end": "1364679"
  },
  {
    "text": "argument that the um LM or the planner can provide that allows it to pass on additional context from the user input",
    "start": "1364679",
    "end": "1371520"
  },
  {
    "text": "that won't be available just by being passed in through the arcs or the outputs of other tools the second one's",
    "start": "1371520",
    "end": "1378840"
  },
  {
    "text": "the planner this is mostly interesting relative to the other um agents that we",
    "start": "1378840",
    "end": "1386640"
  },
  {
    "text": "saw today in that the format permits streaming um and it really focuses on",
    "start": "1386640",
    "end": "1393960"
  },
  {
    "text": "the on that so it'll output the things that look like the",
    "start": "1393960",
    "end": "1399000"
  },
  {
    "text": "python uh function invocation where it has the name of the tool and then parentheses and the arguments there um I",
    "start": "1399000",
    "end": "1405240"
  },
  {
    "text": "added in the keyword based arguments here so it's easier to parse into a dictionary and use that within our",
    "start": "1405240",
    "end": "1411240"
  },
  {
    "text": "state I created this additional planner which has this branch that decides",
    "start": "1411240",
    "end": "1417960"
  },
  {
    "text": "whether it should replan or whether it should not and if it's replanning it'll be doing some updates to the state just",
    "start": "1417960",
    "end": "1424880"
  },
  {
    "text": "to make sure it's formatted correctly for the agent um so again this single function handles both the planner and",
    "start": "1424880",
    "end": "1431000"
  },
  {
    "text": "the planner from above I'll Define",
    "start": "1431000",
    "end": "1436159"
  },
  {
    "text": "that all right so next up is the task fetching unit and this I think is the",
    "start": "1436880",
    "end": "1442880"
  },
  {
    "text": "most interesting part of this paper relative to the other papers we're reviewing today it takes in a stream of",
    "start": "1442880",
    "end": "1448880"
  },
  {
    "text": "dictionaries where each dictionary contains the tool that we're going to be invoking as well as a list of dependencies each dependency is",
    "start": "1448880",
    "end": "1455520"
  },
  {
    "text": "represented by a number which is that index in the Stream of tasks that you",
    "start": "1455520",
    "end": "1461000"
  },
  {
    "text": "have um emitted from the LM importantly the index is continued to be incremented",
    "start": "1461000",
    "end": "1466720"
  },
  {
    "text": "across replan so you can continue to reference some of the original tasks that were executed",
    "start": "1466720",
    "end": "1472000"
  },
  {
    "text": "even after you've replanned so you don't have to do redundant work in theory I'll jump into the main function",
    "start": "1472000",
    "end": "1478960"
  },
  {
    "text": "here so this schedule tasks component again you take the stream of tasks so this is a generator of dictionaries as",
    "start": "1478960",
    "end": "1485760"
  },
  {
    "text": "well as the state of messages so if we're thinking about the state graph the L graph State graph it's tracking all",
    "start": "1485760",
    "end": "1493159"
  },
  {
    "text": "the information about an execution within this list of messages for the chat bottom um um we get the",
    "start": "1493159",
    "end": "1498880"
  },
  {
    "text": "observations from the messages because we uh are then",
    "start": "1498880",
    "end": "1503960"
  },
  {
    "text": "formatting all of the tool responses as function messages so if this is a replanning step then you can get all of",
    "start": "1503960",
    "end": "1510559"
  },
  {
    "text": "the observations from the previous ones format it in a nice dictionary so we can be looking up and substituting that",
    "start": "1510559",
    "end": "1516720"
  },
  {
    "text": "here after that we're going to be starting this execution step we want to",
    "start": "1516720",
    "end": "1521880"
  },
  {
    "text": "be able to schedule this in a separate thread so we can continue to stream these inputs from the llm in without",
    "start": "1521880",
    "end": "1527000"
  },
  {
    "text": "impacting the the overall runtime of the tools we check if there's dependencies of the task and that all those test all",
    "start": "1527000",
    "end": "1534159"
  },
  {
    "text": "those dependencies are not yet met and if that is the case then we'll schedule it as a pending task and we'll go over",
    "start": "1534159",
    "end": "1539880"
  },
  {
    "text": "what this means later um otherwise we can schedule it immediately so we'll just schedule this um directly we'll",
    "start": "1539880",
    "end": "1546120"
  },
  {
    "text": "call the tool and then once that is actually ready um this is missing",
    "start": "1546120",
    "end": "1551279"
  },
  {
    "text": "something here um once that's ready the results will be populated into the",
    "start": "1551279",
    "end": "1556480"
  },
  {
    "text": "observations again and um the scheduled task can then check and then eventually be executed once they're",
    "start": "1556480",
    "end": "1562679"
  },
  {
    "text": "ready the um schedule pending task here is basically a loop that checks for the dependencies of the task and we'll just",
    "start": "1562679",
    "end": "1568720"
  },
  {
    "text": "sleep so it'll it'll pull to see whether it can actually be executed yet um the",
    "start": "1568720",
    "end": "1573919"
  },
  {
    "text": "regular scheduled task again it invokes the tool and once it is actually invoked",
    "start": "1573919",
    "end": "1579480"
  },
  {
    "text": "then we will um return that as an observation if there's an exception in calling it then we're going to return",
    "start": "1579480",
    "end": "1585120"
  },
  {
    "text": "the exception here uh within the list of observations when you're executing the",
    "start": "1585120",
    "end": "1591159"
  },
  {
    "text": "task itself we try to resolve the arguments so in doing that we look for this syntax with the dollar sign for",
    "start": "1591159",
    "end": "1597200"
  },
  {
    "text": "variable substitution um there's some cases where it will use more of a a code based like dot output or something in it",
    "start": "1597200",
    "end": "1603320"
  },
  {
    "text": "so we're handling an additional case there and then we will um look at the index that it represents from that list",
    "start": "1603320",
    "end": "1610559"
  },
  {
    "text": "of observations we'll look up the um observation there or the dictionary observations we'll get that from the index and then we'll return that there",
    "start": "1610559",
    "end": "1616960"
  },
  {
    "text": "so then all the Arguments for the tool it could be multiple arguments to the tool um will be resolved um and",
    "start": "1616960",
    "end": "1623159"
  },
  {
    "text": "so yeah this is um the way that we use variable substitution to let it actually generate the full tag without having to",
    "start": "1623159",
    "end": "1629000"
  },
  {
    "text": "do just incremental steps and recall planning um there so run",
    "start": "1629000",
    "end": "1635039"
  },
  {
    "text": "this and the final we'll see if it runs",
    "start": "1635039",
    "end": "1640879"
  },
  {
    "text": "first all right set ran um and you can actually check lsmith to see what the",
    "start": "1646200",
    "end": "1652559"
  },
  {
    "text": "results look like we'll wait for that until the final step just to um get on with it so the Joiner is the rep planner",
    "start": "1652559",
    "end": "1659279"
  },
  {
    "text": "here um this is a little less interesting it's kind of the same as the previous steps it takes in the previous responses and then we'll decide whether",
    "start": "1659279",
    "end": "1666000"
  },
  {
    "text": "to replan or whether to Output a final response we're using function calling here just because it's a reliable way to generate structured output from you know",
    "start": "1666000",
    "end": "1672559"
  },
  {
    "text": "unstructured input using LMS um the Joiner output we will then",
    "start": "1672559",
    "end": "1677880"
  },
  {
    "text": "format either into a system message if we want to be replanning or we'll respond with the VY AI message here um",
    "start": "1677880",
    "end": "1684399"
  },
  {
    "text": "so format that do both so you can see what it outputs like",
    "start": "1684399",
    "end": "1690919"
  },
  {
    "text": "here and the final step is actually to orchestrate this with line graph cool so you see the results and it decides that",
    "start": "1690919",
    "end": "1697120"
  },
  {
    "text": "it's actually going to finish and says the temperature of San Francisco was mentioned Etc",
    "start": "1697120",
    "end": "1703360"
  },
  {
    "text": "um the graph is created with just these two nodes really it's a pretty simple one uh since Planet schedule is all",
    "start": "1703360",
    "end": "1711000"
  },
  {
    "text": "contained within a single runnable gra um runnable dag U do you have the Planet schedule node and the join node and the",
    "start": "1711000",
    "end": "1719000"
  },
  {
    "text": "anytime the Planet schedule is called it will automatically go to the Joiner since that decides whether the um Loop",
    "start": "1719000",
    "end": "1724760"
  },
  {
    "text": "should end or whether it should continue and then finally we will add this conditional Edge from join and decide",
    "start": "1724760",
    "end": "1730880"
  },
  {
    "text": "whether we should end or whether we should go back to the plan and schedule node so again the conditional Edge has a",
    "start": "1730880",
    "end": "1736200"
  },
  {
    "text": "function and then the fun function outputs the strings this is just a variable for the double underscore end",
    "start": "1736200",
    "end": "1742559"
  },
  {
    "text": "string um and these then corespond to different nodes in the graph or the finishing condition so we'll compile",
    "start": "1742559",
    "end": "1749679"
  },
  {
    "text": "it and then ask it a simple question like what's the GDP of New York and now",
    "start": "1749679",
    "end": "1755120"
  },
  {
    "text": "that it's running I'll ask get some multihop and multi-step math when it's",
    "start": "1755120",
    "end": "1760360"
  },
  {
    "text": "running you can see uh in Lang Smith you can jump over and look at the results um",
    "start": "1760360",
    "end": "1766080"
  },
  {
    "text": "here so you can this just a second ago um you can see what's the GDP of New",
    "start": "1766080",
    "end": "1771360"
  },
  {
    "text": "York and you can see the series of operations here so we have the planner and outputs um so this is again the",
    "start": "1771360",
    "end": "1776760"
  },
  {
    "text": "first uh result there so it has to resarch and then it has um this value",
    "start": "1776760",
    "end": "1784120"
  },
  {
    "text": "and then calls again looking for uh a replanning attempt to look at GDP of New",
    "start": "1784120",
    "end": "1790159"
  },
  {
    "text": "York in 2023 um because in the original one it didn't get the most specific results",
    "start": "1790159",
    "end": "1796399"
  },
  {
    "text": "that it wanted and then it finally goes and it says it um it say it's provided",
    "start": "1796399",
    "end": "1801799"
  },
  {
    "text": "in the search results the New York has this and so it says the the GDP of New",
    "start": "1801799",
    "end": "1806960"
  },
  {
    "text": "York in 2022 was 2.53 trillion um again we could provide additional information",
    "start": "1806960",
    "end": "1812200"
  },
  {
    "text": "if we wanted to be more specific about which year or something like that um the next question we had for it was a",
    "start": "1812200",
    "end": "1818320"
  },
  {
    "text": "multihop question let's go back here so what's the oldest parrot alive",
    "start": "1818320",
    "end": "1825240"
  },
  {
    "text": "you can see the output of the plan and has 012 it has um the search for oldest par life um and then it has average life",
    "start": "1825240",
    "end": "1832039"
  },
  {
    "text": "status B of parent and then has the end there's no variable substitution here it's able to just do parallel function",
    "start": "1832039",
    "end": "1837720"
  },
  {
    "text": "calling basically but you can see both of these are called um pretty quickly",
    "start": "1837720",
    "end": "1842799"
  },
  {
    "text": "and then after that it calls the planner and says that it's found the age of the",
    "start": "1842799",
    "end": "1850120"
  },
  {
    "text": "oldest parent who's 83 years old quite old but it doesn't have the average Lifest of parrots um it was only able to",
    "start": "1850120",
    "end": "1856519"
  },
  {
    "text": "get some other specific information so it tries again so you can see the rep planner um it then continues from where",
    "start": "1856519",
    "end": "1863120"
  },
  {
    "text": "it left off in the task list and says average lifespan appar you look it up and then the rep planner chooses um that",
    "start": "1863120",
    "end": "1871919"
  },
  {
    "text": "it's found the oldest one there it says that um it's not they don't have the",
    "start": "1871919",
    "end": "1879279"
  },
  {
    "text": "specific lifespan there but it's implied that large Pirates may live longer than smaller species um so basically it's",
    "start": "1879279",
    "end": "1885559"
  },
  {
    "text": "saying the search results weren't good enough um both from the output here and from debugging with the trace you can see the search engine actually should",
    "start": "1885559",
    "end": "1891559"
  },
  {
    "text": "probably be tuned here for this type of question if we wanted to be able to respond well to this type of question uh and that's really the way we want to be",
    "start": "1891559",
    "end": "1897840"
  },
  {
    "text": "improving things if we want to improve the overall quality of this agent um anyways we'll jump back to the notebook",
    "start": "1897840",
    "end": "1903399"
  },
  {
    "text": "you can see that it's completed here um you can see it also did a math problem which we can jump to here as well it did",
    "start": "1903399",
    "end": "1910279"
  },
  {
    "text": "again this math chain a few times uh in in sequence",
    "start": "1910279",
    "end": "1915840"
  },
  {
    "text": "there so again um that's about it for the LM compiler notebook I think um the",
    "start": "1915840",
    "end": "1922399"
  },
  {
    "text": "key takeaway from this one is that whenever you're doing planning and you have variable substitution if you do",
    "start": "1922399",
    "end": "1928679"
  },
  {
    "text": "track the dependencies there then you can actually start executing the tools before the agent ends and so this can",
    "start": "1928679",
    "end": "1935559"
  },
  {
    "text": "overall optimize your runtime save on tokens relative to the react agent style uh and improve the overall performance",
    "start": "1935559",
    "end": "1942159"
  },
  {
    "text": "of your model um I think all of these agents in summary are a step towards a",
    "start": "1942159",
    "end": "1948120"
  },
  {
    "text": "more robust and more effective agent design if you want to be using llms to make decisions about how to execute",
    "start": "1948120",
    "end": "1953799"
  },
  {
    "text": "tasks U and I think implementing in Lane graph is pretty straightforward I would actually recommend doing so yourself and",
    "start": "1953799",
    "end": "1960440"
  },
  {
    "text": "maybe combining some of these different approaches like taking maybe the um Riu or Planet execute style um output from",
    "start": "1960440",
    "end": "1967320"
  },
  {
    "text": "the planner and streaming it and using something like an llm compiler executor to be able to doing it more eagerly um",
    "start": "1967320",
    "end": "1974080"
  },
  {
    "text": "and mixing it with maybe other um design patterns that we've showed throughout the L graph po as well um so that's",
    "start": "1974080",
    "end": "1981240"
  },
  {
    "text": "about it again thanks again for watching this video um feel free to leave feedback on the video and like or",
    "start": "1981240",
    "end": "1987679"
  },
  {
    "text": "subscribe um to share and follow other types of content like this so that you can learn more about how to create",
    "start": "1987679",
    "end": "1993480"
  },
  {
    "text": "different agents um both for production and for experimental use and finally if you want to sign up for Lang Smith feel",
    "start": "1993480",
    "end": "1999039"
  },
  {
    "text": "free to go do so at smith. link chain.com um we no longer have a weight list so you can go ahead and get started",
    "start": "1999039",
    "end": "2005320"
  },
  {
    "text": "debugging your llm workflows in immediately and um thank you all and hope to see you",
    "start": "2005320",
    "end": "2011039"
  },
  {
    "text": "again",
    "start": "2011039",
    "end": "2014039"
  }
]
[
  {
    "start": "0",
    "end": "21000"
  },
  {
    "text": "Hi all, Will here. This week we're \nexcited to launch the LangMem SDK—a  ",
    "start": "80",
    "end": "4120"
  },
  {
    "text": "library of utilities for helping you build \nagents that learn and adapt as you go.",
    "start": "4120",
    "end": "8280"
  },
  {
    "text": "In this video, I will show you how to add \nsemantic memory to your agents so they can  ",
    "start": "8280",
    "end": "12519"
  },
  {
    "text": "remember important facts and other information \nthat guides the content of their responses.",
    "start": "12520",
    "end": "18480"
  },
  {
    "text": "Semantic memory is all about facts and knowledge. \nWith LangMem, you can chat with your bot. Your bot  ",
    "start": "18480",
    "end": "24840"
  },
  {
    "start": "21000",
    "end": "45000"
  },
  {
    "text": "can save memories for later use, and when you chat \nwith it again, it can reference those memories.",
    "start": "24840",
    "end": "29960"
  },
  {
    "text": "As you can see, it remembers that I'm \ntraining for a half marathon and that  ",
    "start": "30760",
    "end": "34520"
  },
  {
    "text": "I have a current training plan \nin place. With every interaction,  ",
    "start": "34520",
    "end": "36960"
  },
  {
    "text": "the memory state is updated. Each \nmemory gains additional context—in  ",
    "start": "36960",
    "end": "40960"
  },
  {
    "text": "this case, it now remembers that I'm dealing with \ntendonitis and need a modified training regimen.",
    "start": "40960",
    "end": "44879"
  },
  {
    "text": "So, let's create a React agent with semantic \nmemory. First, we'll review how to make an  ",
    "start": "44880",
    "end": "49920"
  },
  {
    "start": "45000",
    "end": "105000"
  },
  {
    "text": "agent link graph. We'll use the prebuilt wrapper \nfor concision. First, we'll install LangMem.",
    "start": "49920",
    "end": "56600"
  },
  {
    "text": "Then we'll create the agent. We'll give the agent \nshort-term memory in the form of checkpointing,  ",
    "start": "56600",
    "end": "62640"
  },
  {
    "text": "and we'll also provide a long-term memory \nstore. (Note that it won't have a direct  ",
    "start": "62640",
    "end": "67120"
  },
  {
    "text": "connection with the long-term store \nyet, so it won't actually use it.)",
    "start": "67120",
    "end": "71640"
  },
  {
    "text": "Now, we'll create the agent \nagain—this time with a little  ",
    "start": "71640",
    "end": "74680"
  },
  {
    "text": "wrapper to make interaction more convenient.",
    "start": "74680",
    "end": "76280"
  },
  {
    "text": "Now that we've created the agent, we can chat \nwith it. If you continue the conversation  ",
    "start": "76280",
    "end": "86720"
  },
  {
    "text": "along the same thread, it will remember \nprevious context because this is stored  ",
    "start": "86720",
    "end": "90360"
  },
  {
    "text": "in the conversation history (i.e., short-term \nmemory). However, if you start a new thread,  ",
    "start": "90360",
    "end": "97960"
  },
  {
    "text": "it won’t remember that information \nbecause it isn’t stored long term.",
    "start": "97960",
    "end": "103119"
  },
  {
    "text": "Now it's time to add memory. \nWe'll give our agent two tools  ",
    "start": "104680",
    "end": "108320"
  },
  {
    "start": "105000",
    "end": "174000"
  },
  {
    "text": "to interact with the memory store. \nOne tool is for creating, updating,  ",
    "start": "108320",
    "end": "112720"
  },
  {
    "text": "and deleting memories. The other is for searching \nthe store whenever it needs to recall information.",
    "start": "112720",
    "end": "117160"
  },
  {
    "text": "We will update our long-term memory store by \nadding an indexing configuration. This tells  ",
    "start": "121760",
    "end": "126880"
  },
  {
    "text": "LangGraph that anytime you save an item \nto the store, it will be embedded with a  ",
    "start": "126880",
    "end": "130880"
  },
  {
    "text": "vectorizer so that we can later perform \nsemantic searches over the memories.",
    "start": "130880",
    "end": "134080"
  },
  {
    "text": "We will create our tools by providing \na namespace for the agent to interact  ",
    "start": "134080",
    "end": "136320"
  },
  {
    "text": "with the memory store. The namespace tells \nLangGraph where to store the memories within  ",
    "start": "136320",
    "end": "142760"
  },
  {
    "text": "its underlying long-term memory system. Since \nthe store is shared across the entire graph,  ",
    "start": "142760",
    "end": "148000"
  },
  {
    "text": "if you have multiple agents—or if you want \nto save memories pertaining to different  ",
    "start": "148000",
    "end": "155200"
  },
  {
    "text": "users—you may want to organize \nthem under separate namespaces.",
    "start": "155200",
    "end": "161920"
  },
  {
    "text": "After fixing our model name, let's \nreturn to the scenario from before.  ",
    "start": "161920",
    "end": "167720"
  },
  {
    "text": "The agent tells us that it has saved \nthe plan to memory. Let's double-check.",
    "start": "167720",
    "end": "172040"
  },
  {
    "text": "Let's check LangSmith to observe a few \nthings. First, let's see what the tools  ",
    "start": "172680",
    "end": "177200"
  },
  {
    "start": "174000",
    "end": "279000"
  },
  {
    "text": "look like from the perspective of the agent. \nWe have provided two tools: Manage Memory and  ",
    "start": "177200",
    "end": "181599"
  },
  {
    "text": "Search Memory. The Search Memory tool allows \nit to filter, limit, and offset results, but  ",
    "start": "181600",
    "end": "188440"
  },
  {
    "text": "primarily to generate a specific \nquery for searching its memories.",
    "start": "188440",
    "end": "192120"
  },
  {
    "text": "Here, you can see that it's looking up \n\"Half Marathon Training Plan\" to verify  ",
    "start": "192120",
    "end": "195959"
  },
  {
    "text": "that there are no additional memories it \nshould consult before updating anything.",
    "start": "195960",
    "end": "199280"
  },
  {
    "text": "After searching its memory, the agent then \ndecides to use the Manage Memory tool. Let's  ",
    "start": "199280",
    "end": "206080"
  },
  {
    "text": "check the Manage Memory tool from the \nLLM’s perspective. It contains its own  ",
    "start": "206080",
    "end": "210400"
  },
  {
    "text": "set of instructions on when it should be used, \nallowing the LLM to choose actions for creating,  ",
    "start": "210400",
    "end": "216319"
  },
  {
    "text": "updating, or deleting memories. Depending \non the action, it can provide content for  ",
    "start": "216320",
    "end": "221160"
  },
  {
    "text": "creations/updates or an ID for updates/deletions.",
    "start": "221160",
    "end": "224680"
  },
  {
    "text": "In this case, the agent has \ndecided to create a new memory.",
    "start": "224680",
    "end": "226920"
  },
  {
    "text": "If I start a new thread with an ambiguous context \nthat requires the agent to jog its memory, it  ",
    "start": "226920",
    "end": "232560"
  },
  {
    "text": "will perform a search for us. You can confirm in \nLangSmith that it indeed searched for this memory.",
    "start": "232560",
    "end": "236200"
  },
  {
    "text": "If you follow the agent's trajectory, you see \nthat the first message it receives triggers a  ",
    "start": "236200",
    "end": "241000"
  },
  {
    "text": "memory search for additional contextual \ninformation. It then uses those results  ",
    "start": "241760",
    "end": "245879"
  },
  {
    "text": "to respond, indicating exactly \nwhere we're supposed to be.",
    "start": "245880",
    "end": "248240"
  },
  {
    "text": "If we provide information that conflicts \nwith old memories or requires an update,  ",
    "start": "248240",
    "end": "251640"
  },
  {
    "text": "the agent can again use the Manage Memory tool \nto update its memories. In the corresponding  ",
    "start": "252840",
    "end": "257919"
  },
  {
    "text": "trace in LangSmith, the LLM first calls \nthe Search Memory tool to review existing  ",
    "start": "257920",
    "end": "261920"
  },
  {
    "text": "memories and then uses the Manage Memory \ntool to update that memory accordingly.",
    "start": "261920",
    "end": "266960"
  },
  {
    "text": "It then commits this modified plan to \naccommodate the injury and saves it to memory,  ",
    "start": "266960",
    "end": "272600"
  },
  {
    "text": "overwriting the previous memory to ensure \nthat all searchable information remains valid.",
    "start": "272600",
    "end": "277480"
  },
  {
    "text": "Up to this point, the agent has been saving \nmemories in the same namespace—the \"agent  ",
    "start": "277480",
    "end": "281520"
  },
  {
    "start": "279000",
    "end": "369000"
  },
  {
    "text": "memories\" namespace we created. If your agent \nsupports multiple users, you'll likely want  ",
    "start": "281520",
    "end": "286800"
  },
  {
    "text": "to keep their memories separate to prevent \ninformation leakage between interactions.",
    "start": "286800",
    "end": "291319"
  },
  {
    "text": "To do so, add a template variable to your \nnamespace. LangMem interprets this as a  ",
    "start": "291320",
    "end": "296560"
  },
  {
    "text": "value that needs to be populated at runtime \nfrom your configuration dictionary. We will  ",
    "start": "296560",
    "end": "300520"
  },
  {
    "text": "recreate the agent and modify our chat \nhelper to accommodate a new user ID.",
    "start": "300520",
    "end": "305520"
  },
  {
    "text": "If I first chat as User A, the agent will \nsave those memories to User A's namespace.  ",
    "start": "305520",
    "end": "309879"
  },
  {
    "text": "If I then interact with the same agent as User \nB, it will manage memories that don't conflict  ",
    "start": "309880",
    "end": "315760"
  },
  {
    "text": "with those of User A. You can check that \nthere is no overlap by interrogating the  ",
    "start": "315760",
    "end": "326800"
  },
  {
    "text": "model from the perspective of User ID 2 \nor by directly searching the store. Here,  ",
    "start": "326800",
    "end": "331560"
  },
  {
    "text": "you can see memories for User A (about \nWill training for a half marathon) and  ",
    "start": "331560",
    "end": "336320"
  },
  {
    "text": "memories for User B (learning chess and wanting \nto improve). Since these are stored in separate  ",
    "start": "336320",
    "end": "339720"
  },
  {
    "text": "namespaces, the agent cannot access memories \nfrom one user when configured for another.",
    "start": "339720",
    "end": "344560"
  },
  {
    "text": "If you recall from the agent trace, these \ntools don't even require a namespace  ",
    "start": "344560",
    "end": "348120"
  },
  {
    "text": "parameter—the agent operates solely \non IDs and content. Behind the scenes,  ",
    "start": "348120",
    "end": "354680"
  },
  {
    "text": "the tool reads your configuration and places \nmemories in the correct location accordingly.",
    "start": "354680",
    "end": "361039"
  },
  {
    "text": "If you're paying attention, you'll notice that  ",
    "start": "361040",
    "end": "362840"
  },
  {
    "text": "the agent must actively decide when to \nsearch its memories. Let's change that.",
    "start": "362840",
    "end": "367600"
  },
  {
    "text": "We're going to add an initial search \nstep that scans memories based on the  ",
    "start": "367600",
    "end": "371640"
  },
  {
    "start": "369000",
    "end": "441000"
  },
  {
    "text": "incoming context before calling the LLM. This \nprovides the LLM with relevant information  ",
    "start": "371640",
    "end": "377840"
  },
  {
    "text": "about the conversation before it makes any \ndecisions, potentially saving one or two tool  ",
    "start": "377840",
    "end": "383199"
  },
  {
    "text": "calls if the necessary context is already present.",
    "start": "383200",
    "end": "385960"
  },
  {
    "text": "What we're going to do is add a memory \nsearch step and then incorporate the  ",
    "start": "385960",
    "end": "391020"
  },
  {
    "text": "results into a system prompt so that the LLM \ncan respond with all the relevant context.",
    "start": "391020",
    "end": "397360"
  },
  {
    "text": "We'll fetch the store from context and use \nthe content of the most recent message to  ",
    "start": "397360",
    "end": "401840"
  },
  {
    "text": "search for relevant memories. This \nis a quick heuristic—you might want  ",
    "start": "401840",
    "end": "405320"
  },
  {
    "text": "to include context from the last human \nmessage (in case there are other tool  ",
    "start": "405320",
    "end": "409160"
  },
  {
    "text": "messages) or more conversational \ncontext when generating the query.",
    "start": "409160",
    "end": "413920"
  },
  {
    "text": "Now that we've created our new \nagent, let's run our simulation  ",
    "start": "413920",
    "end": "416200"
  },
  {
    "text": "again. This time it ran much faster, \nas confirmed by the LangSmith trace.",
    "start": "416200",
    "end": "419600"
  },
  {
    "text": "If you look at the new agent trajectory, you \ncan see the additional prompt step that returns  ",
    "start": "419600",
    "end": "424760"
  },
  {
    "text": "all of the memories (dumped into a string). \nIn this case, the AI still decided to search  ",
    "start": "424760",
    "end": "429720"
  },
  {
    "text": "again for additional memories, which speaks to the \ntrade-offs of exposing this step; however, it had  ",
    "start": "429720",
    "end": "434960"
  },
  {
    "text": "enough information from the default contextual \nlookup to potentially respond on the first try.",
    "start": "434960",
    "end": "440759"
  },
  {
    "text": "That's all for today. In this video, we \nbuilt an agent that can manually manage  ",
    "start": "440760",
    "end": "444400"
  },
  {
    "start": "441000",
    "end": "460000"
  },
  {
    "text": "its own semantic memory. This allows it \nto store important facts and use them in  ",
    "start": "444400",
    "end": "449040"
  },
  {
    "text": "later conversations. For more information \nabout other memory types and the conceptual  ",
    "start": "449040",
    "end": "454600"
  },
  {
    "text": "framing behind LangMem, check out our \nconcept videos or the LangMem docs.",
    "start": "454600",
    "end": "459000"
  },
  {
    "text": "See you next time.",
    "start": "459000",
    "end": "459680"
  }
]
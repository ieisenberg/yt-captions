[
  {
    "text": "hey this is Lance from Lang Shain you've",
    "start": "2159",
    "end": "3919"
  },
  {
    "text": "probably heard a lot about the new",
    "start": "3919",
    "end": "5240"
  },
  {
    "text": "reasoning models from open AI such as 01",
    "start": "5240",
    "end": "7480"
  },
  {
    "text": "and 03 I want to talk about these by",
    "start": "7480",
    "end": "9800"
  },
  {
    "text": "reviewing some of my favorite uh new",
    "start": "9800",
    "end": "12120"
  },
  {
    "text": "videos and uh kind of blogs I've seen on",
    "start": "12120",
    "end": "14559"
  },
  {
    "text": "this topic but first let's just start",
    "start": "14559",
    "end": "17000"
  },
  {
    "text": "with the current scaling Paradigm that",
    "start": "17000",
    "end": "19600"
  },
  {
    "text": "we've been in for a number of years",
    "start": "19600",
    "end": "21199"
  },
  {
    "text": "which is next word prediction so Jason",
    "start": "21199",
    "end": "24160"
  },
  {
    "text": "way has a great talk on this and he kind",
    "start": "24160",
    "end": "26920"
  },
  {
    "text": "of frames nicely why has next word I",
    "start": "26920",
    "end": "30279"
  },
  {
    "text": "works so well and he basically explains",
    "start": "30279",
    "end": "32640"
  },
  {
    "text": "it as nexor prediction is a multitask",
    "start": "32640",
    "end": "35160"
  },
  {
    "text": "learning problem when you ask an LM to",
    "start": "35160",
    "end": "37800"
  },
  {
    "text": "predict the next word or the next token",
    "start": "37800",
    "end": "39640"
  },
  {
    "text": "in a sentence it learns a lot of things",
    "start": "39640",
    "end": "41960"
  },
  {
    "text": "at once it learns grammar it learns",
    "start": "41960",
    "end": "44600"
  },
  {
    "text": "World Knowledge sentiment translation",
    "start": "44600",
    "end": "47480"
  },
  {
    "text": "spatial reasoning math so this simple",
    "start": "47480",
    "end": "50640"
  },
  {
    "text": "learning objective is extremely powerful",
    "start": "50640",
    "end": "52600"
  },
  {
    "text": "and there's lots of nice papers and",
    "start": "52600",
    "end": "54120"
  },
  {
    "text": "talks on this but that just sets the",
    "start": "54120",
    "end": "56640"
  },
  {
    "text": "stage now we've scaled this over roughly",
    "start": "56640",
    "end": "60600"
  },
  {
    "text": "seven orders of magnitude Jason also",
    "start": "60600",
    "end": "62960"
  },
  {
    "text": "touches on this and this is well covered",
    "start": "62960",
    "end": "64680"
  },
  {
    "text": "in the Capal at all paper from",
    "start": "64680",
    "end": "66560"
  },
  {
    "text": "2020 but with respect to model size data",
    "start": "66560",
    "end": "70040"
  },
  {
    "text": "set size and train compute the overall",
    "start": "70040",
    "end": "72040"
  },
  {
    "text": "capability of models trained just with",
    "start": "72040",
    "end": "74159"
  },
  {
    "text": "this kind of simple objective has gotten",
    "start": "74159",
    "end": "76880"
  },
  {
    "text": "better now there's some interesting",
    "start": "76880",
    "end": "78759"
  },
  {
    "text": "points here are related to the concept",
    "start": "78759",
    "end": "80520"
  },
  {
    "text": "of emergence certain capabilities appear",
    "start": "80520",
    "end": "82880"
  },
  {
    "text": "to be unlocked at certain scales like",
    "start": "82880",
    "end": "84520"
  },
  {
    "text": "for example GPD 2 and three were poor at",
    "start": "84520",
    "end": "86640"
  },
  {
    "text": "math four kind of unlock greater math",
    "start": "86640",
    "end": "88640"
  },
  {
    "text": "capability but overall you can kind of",
    "start": "88640",
    "end": "91079"
  },
  {
    "text": "think about the capability increasing in",
    "start": "91079",
    "end": "93439"
  },
  {
    "text": "a Rel relatively predictable fashion",
    "start": "93439",
    "end": "95680"
  },
  {
    "text": "with respect to size of model data set",
    "start": "95680",
    "end": "98840"
  },
  {
    "text": "and train compute so that's kind of the",
    "start": "98840",
    "end": "100360"
  },
  {
    "text": "Paradigm we've been in now here's kind",
    "start": "100360",
    "end": "103040"
  },
  {
    "text": "of the catch and Jason kind of lay this",
    "start": "103040",
    "end": "104920"
  },
  {
    "text": "out",
    "start": "104920",
    "end": "105640"
  },
  {
    "text": "nicely next word prediction is kind of",
    "start": "105640",
    "end": "107880"
  },
  {
    "text": "like system one thinking it's fast and",
    "start": "107880",
    "end": "110119"
  },
  {
    "text": "intuitive but some next words are really",
    "start": "110119",
    "end": "113240"
  },
  {
    "text": "hard to predict so for example a",
    "start": "113240",
    "end": "116200"
  },
  {
    "text": "challenging math problem a challenging",
    "start": "116200",
    "end": "117920"
  },
  {
    "text": "reasoning problem the problem is these",
    "start": "117920",
    "end": "121039"
  },
  {
    "text": "models use the same amount of compute to",
    "start": "121039",
    "end": "122960"
  },
  {
    "text": "solve easy and hard problems that's kind",
    "start": "122960",
    "end": "124960"
  },
  {
    "text": "of the overall bottleneck with this",
    "start": "124960",
    "end": "128560"
  },
  {
    "text": "Paradigm now a workaround that we're all",
    "start": "128560",
    "end": "131160"
  },
  {
    "text": "probably familiar with by this point is",
    "start": "131160",
    "end": "132680"
  },
  {
    "text": "this notion of Chain of Thought",
    "start": "132680",
    "end": "133800"
  },
  {
    "text": "prompting this came out around 2022 and",
    "start": "133800",
    "end": "136120"
  },
  {
    "text": "Jason way has a nice paper on it of",
    "start": "136120",
    "end": "138200"
  },
  {
    "text": "course you prompt an LM to think step by",
    "start": "138200",
    "end": "140200"
  },
  {
    "text": "step but what's really happening here so",
    "start": "140200",
    "end": "142519"
  },
  {
    "text": "Nathan Lambert has a nice video on this",
    "start": "142519",
    "end": "144480"
  },
  {
    "text": "and I thought it was really interesting",
    "start": "144480",
    "end": "146080"
  },
  {
    "text": "you're kind of trying to enforce system",
    "start": "146080",
    "end": "148160"
  },
  {
    "text": "to thinking which is ious and networ",
    "start": "148160",
    "end": "150599"
  },
  {
    "text": "full so for example if you do a math",
    "start": "150599",
    "end": "152879"
  },
  {
    "text": "problem yourself you perform a bunch of",
    "start": "152879",
    "end": "154920"
  },
  {
    "text": "intermediate steps and those are kind of",
    "start": "154920",
    "end": "157040"
  },
  {
    "text": "storing intermediate variables for",
    "start": "157040",
    "end": "158800"
  },
  {
    "text": "yourself which then you utilize to",
    "start": "158800",
    "end": "160159"
  },
  {
    "text": "generate the final solution and chaina",
    "start": "160159",
    "end": "162519"
  },
  {
    "text": "thought it's kind of like forcing the",
    "start": "162519",
    "end": "163720"
  },
  {
    "text": "model to produce those intermediates as",
    "start": "163720",
    "end": "165840"
  },
  {
    "text": "tokens along its trajectory towards a",
    "start": "165840",
    "end": "169120"
  },
  {
    "text": "solution so it's like by telling to",
    "start": "169120",
    "end": "171200"
  },
  {
    "text": "think step by step you're actually",
    "start": "171200",
    "end": "172800"
  },
  {
    "text": "having it produce work in the form of",
    "start": "172800",
    "end": "175040"
  },
  {
    "text": "tokens and those tokens are kind of",
    "start": "175040",
    "end": "176680"
  },
  {
    "text": "storing intermediate information that",
    "start": "176680",
    "end": "178159"
  },
  {
    "text": "the model is using to form a a final",
    "start": "178159",
    "end": "180280"
  },
  {
    "text": "answer so it's kind of like a hack to",
    "start": "180280",
    "end": "183959"
  },
  {
    "text": "force the model from system one thinking",
    "start": "183959",
    "end": "186080"
  },
  {
    "text": "to system two thinking so I kind of like",
    "start": "186080",
    "end": "188959"
  },
  {
    "text": "the way that Jason lays that out and",
    "start": "188959",
    "end": "190599"
  },
  {
    "text": "Nathan explains what's happening when",
    "start": "190599",
    "end": "192280"
  },
  {
    "text": "you actually do",
    "start": "192280",
    "end": "194120"
  },
  {
    "text": "CFT now this new scaling Paradigm what",
    "start": "194120",
    "end": "196840"
  },
  {
    "text": "you see with these reasoning models is",
    "start": "196840",
    "end": "198400"
  },
  {
    "text": "basically scaling reinforcement learning",
    "start": "198400",
    "end": "200599"
  },
  {
    "text": "on Chain of Thought So what's actually",
    "start": "200599",
    "end": "203200"
  },
  {
    "text": "happening here there's a nice blog post",
    "start": "203200",
    "end": "204760"
  },
  {
    "text": "from open AI a nice video from Nathan",
    "start": "204760",
    "end": "207599"
  },
  {
    "text": "but really the summary is that",
    "start": "207599",
    "end": "210680"
  },
  {
    "text": "you have some training data which",
    "start": "210680",
    "end": "212280"
  },
  {
    "text": "contains explicitly correct answers and",
    "start": "212280",
    "end": "214480"
  },
  {
    "text": "this is important okay coding problems",
    "start": "214480",
    "end": "217159"
  },
  {
    "text": "math problems that are verifiably",
    "start": "217159",
    "end": "218840"
  },
  {
    "text": "correct okay you have a model that can",
    "start": "218840",
    "end": "221640"
  },
  {
    "text": "sometimes generate correct Solutions and",
    "start": "221640",
    "end": "224120"
  },
  {
    "text": "you have a grer that can verify whether",
    "start": "224120",
    "end": "226159"
  },
  {
    "text": "or not a model output is correct or not",
    "start": "226159",
    "end": "228599"
  },
  {
    "text": "okay and if it's correct you give the",
    "start": "228599",
    "end": "230280"
  },
  {
    "text": "model a reward now this is where the",
    "start": "230280",
    "end": "232239"
  },
  {
    "text": "reinforcement learning thing comes in",
    "start": "232239",
    "end": "234200"
  },
  {
    "text": "you have some policy that will nudge",
    "start": "234200",
    "end": "235959"
  },
  {
    "text": "weights so it's more likely to produce",
    "start": "235959",
    "end": "237599"
  },
  {
    "text": "High reward outputs now you do is when",
    "start": "237599",
    "end": "240319"
  },
  {
    "text": "you train this on this data set that has",
    "start": "240319",
    "end": "242480"
  },
  {
    "text": "many explicitly correct answers for",
    "start": "242480",
    "end": "244879"
  },
  {
    "text": "every problem you basically have the",
    "start": "244879",
    "end": "246920"
  },
  {
    "text": "model produce a bunch of different",
    "start": "246920",
    "end": "248400"
  },
  {
    "text": "trajectories and you grade them all and",
    "start": "248400",
    "end": "251159"
  },
  {
    "text": "you reward the correct ones and over",
    "start": "251159",
    "end": "253280"
  },
  {
    "text": "time in training you do lots of forward",
    "start": "253280",
    "end": "255519"
  },
  {
    "text": "passes okay but you kind of tune or",
    "start": "255519",
    "end": "259000"
  },
  {
    "text": "nudge the model to favor Chain of",
    "start": "259000",
    "end": "262040"
  },
  {
    "text": "Thought or trajectories that result in",
    "start": "262040",
    "end": "263840"
  },
  {
    "text": "correct answers that's the overall",
    "start": "263840",
    "end": "265360"
  },
  {
    "text": "intuition and um I think more will come",
    "start": "265360",
    "end": "268280"
  },
  {
    "text": "out on this but this is kind of my",
    "start": "268280",
    "end": "269840"
  },
  {
    "text": "distillation from reading of course the",
    "start": "269840",
    "end": "271479"
  },
  {
    "text": "blog post and some nice work by Nathan",
    "start": "271479",
    "end": "273120"
  },
  {
    "text": "Lambert to explain a little bit more",
    "start": "273120",
    "end": "274880"
  },
  {
    "text": "detail and here's here's a nice kind of",
    "start": "274880",
    "end": "276639"
  },
  {
    "text": "schematic of what's going on you have",
    "start": "276639",
    "end": "278039"
  },
  {
    "text": "your training data you have a policy to",
    "start": "278039",
    "end": "279560"
  },
  {
    "text": "nudge your weights you have some verif",
    "start": "279560",
    "end": "281800"
  },
  {
    "text": "verifiable reward and you're basically",
    "start": "281800",
    "end": "284400"
  },
  {
    "text": "running your model over the training",
    "start": "284400",
    "end": "286120"
  },
  {
    "text": "data you're doing lots of forward passes",
    "start": "286120",
    "end": "288280"
  },
  {
    "text": "you're rewarding the correct chain of",
    "start": "288280",
    "end": "290039"
  },
  {
    "text": "chains of thoughts that get you to",
    "start": "290039",
    "end": "292280"
  },
  {
    "text": "correct answers that are verifiable with",
    "start": "292280",
    "end": "294639"
  },
  {
    "text": "your greater that's the big",
    "start": "294639",
    "end": "296720"
  },
  {
    "text": "idea now why is this exciting will",
    "start": "296720",
    "end": "299840"
  },
  {
    "text": "represents a new scaling law so some",
    "start": "299840",
    "end": "301600"
  },
  {
    "text": "really nice videos from gome Brown Jason",
    "start": "301600",
    "end": "303639"
  },
  {
    "text": "way on this if you look at the recent",
    "start": "303639",
    "end": "306080"
  },
  {
    "text": "results from 01 and now3 just dropped",
    "start": "306080",
    "end": "308759"
  },
  {
    "text": "right before the new year uh they're",
    "start": "308759",
    "end": "310639"
  },
  {
    "text": "obviously extremely strong okay so this",
    "start": "310639",
    "end": "312840"
  },
  {
    "text": "is exciting now another way to think",
    "start": "312840",
    "end": "315400"
  },
  {
    "text": "about this is I really like this slide",
    "start": "315400",
    "end": "317000"
  },
  {
    "text": "from David rain from NPS benchmarks are",
    "start": "317000",
    "end": "319840"
  },
  {
    "text": "getting saturated more and more quickly",
    "start": "319840",
    "end": "321560"
  },
  {
    "text": "this is a cool visualization showing how",
    "start": "321560",
    "end": "323440"
  },
  {
    "text": "long it takes for a benchmark to get",
    "start": "323440",
    "end": "325000"
  },
  {
    "text": "saturated it used to be in 2012 it would",
    "start": "325000",
    "end": "327199"
  },
  {
    "text": "take like 8 years right now it takes",
    "start": "327199",
    "end": "329800"
  },
  {
    "text": "like a year for GP QA which is a new",
    "start": "329800",
    "end": "332199"
  },
  {
    "text": "Benchmark made by David rain which was",
    "start": "332199",
    "end": "334800"
  },
  {
    "text": "Google proof QA so it's question answers",
    "start": "334800",
    "end": "336720"
  },
  {
    "text": "that are you know not easily Googled and",
    "start": "336720",
    "end": "339639"
  },
  {
    "text": "basically we're seeing new stay there",
    "start": "339639",
    "end": "341759"
  },
  {
    "text": "reasoning models are basically",
    "start": "341759",
    "end": "343720"
  },
  {
    "text": "saturating on benchmarks very quickly so",
    "start": "343720",
    "end": "346560"
  },
  {
    "text": "it's exciting we're early in the scaling",
    "start": "346560",
    "end": "348360"
  },
  {
    "text": "curve that's the big idea",
    "start": "348360",
    "end": "350759"
  },
  {
    "text": "here now here's where things are really",
    "start": "350759",
    "end": "353000"
  },
  {
    "text": "interesting there's actually been a lot",
    "start": "353000",
    "end": "354080"
  },
  {
    "text": "of confusion about 01 models with some",
    "start": "354080",
    "end": "355919"
  },
  {
    "text": "people saying oh these actually are",
    "start": "355919",
    "end": "357319"
  },
  {
    "text": "really bad okay now Ben hilac and um",
    "start": "357319",
    "end": "361919"
  },
  {
    "text": "swix put out a really nice post on Laten",
    "start": "361919",
    "end": "364720"
  },
  {
    "text": "space and it really helps to clarify",
    "start": "364720",
    "end": "367759"
  },
  {
    "text": "when you work with these reasoning",
    "start": "367759",
    "end": "368840"
  },
  {
    "text": "models you should not think about them",
    "start": "368840",
    "end": "370800"
  },
  {
    "text": "as chat models and you shouldn't prompt",
    "start": "370800",
    "end": "373160"
  },
  {
    "text": "them as such there's this nice",
    "start": "373160",
    "end": "375000"
  },
  {
    "text": "visualization of the anatomy of no one",
    "start": "375000",
    "end": "376960"
  },
  {
    "text": "prompt where really what you're doing is",
    "start": "376960",
    "end": "378759"
  },
  {
    "text": "you're giving it an explicit goal you",
    "start": "378759",
    "end": "381319"
  },
  {
    "text": "don't tell it how to think you tell it",
    "start": "381319",
    "end": "382800"
  },
  {
    "text": "what you want you give it return format",
    "start": "382800",
    "end": "385479"
  },
  {
    "text": "warnings and just dump all your work now",
    "start": "385479",
    "end": "388199"
  },
  {
    "text": "a lot of people have shown that this",
    "start": "388199",
    "end": "389599"
  },
  {
    "text": "style prompting works really well with",
    "start": "389599",
    "end": "391440"
  },
  {
    "text": "01 right so unlike chat models chat",
    "start": "391440",
    "end": "395319"
  },
  {
    "text": "models you try tell it how to think",
    "start": "395319",
    "end": "397080"
  },
  {
    "text": "you're a researcher your think step by",
    "start": "397080",
    "end": "399400"
  },
  {
    "text": "step with these models you don't do that",
    "start": "399400",
    "end": "401639"
  },
  {
    "text": "you give it what you want and you give",
    "start": "401639",
    "end": "404000"
  },
  {
    "text": "it as much context as possible okay so",
    "start": "404000",
    "end": "406560"
  },
  {
    "text": "that's really the context on how to",
    "start": "406560",
    "end": "408440"
  },
  {
    "text": "prompt these um again focus on the what",
    "start": "408440",
    "end": "412560"
  },
  {
    "text": "not the how don't tell to do you know",
    "start": "412560",
    "end": "415520"
  },
  {
    "text": "particular style of reasoning just give",
    "start": "415520",
    "end": "417639"
  },
  {
    "text": "it what you want that's the big Point",
    "start": "417639",
    "end": "419319"
  },
  {
    "text": "here",
    "start": "419319",
    "end": "420639"
  },
  {
    "text": "now let me show you usage very quickly",
    "start": "420639",
    "end": "423000"
  },
  {
    "text": "first there's a few models available",
    "start": "423000",
    "end": "424400"
  },
  {
    "text": "through the API 0101 mini one one thing",
    "start": "424400",
    "end": "427639"
  },
  {
    "text": "I'll note mini does not support system",
    "start": "427639",
    "end": "429000"
  },
  {
    "text": "messages that's just a small thing to",
    "start": "429000",
    "end": "431000"
  },
  {
    "text": "note um now parameters so with o one not",
    "start": "431000",
    "end": "436639"
  },
  {
    "text": "with o on Mini you can provide these",
    "start": "436639",
    "end": "439560"
  },
  {
    "text": "values of reasoning effort for low",
    "start": "439560",
    "end": "441039"
  },
  {
    "text": "medium high this just Tunes the amount",
    "start": "441039",
    "end": "443199"
  },
  {
    "text": "of reasoning the model will do basically",
    "start": "443199",
    "end": "445199"
  },
  {
    "text": "faster or slower responses fewer and",
    "start": "445199",
    "end": "448280"
  },
  {
    "text": "more tokens accordingly",
    "start": "448280",
    "end": "451319"
  },
  {
    "text": "so I'm in a notebook now I've just pip",
    "start": "451319",
    "end": "453199"
  },
  {
    "text": "installed langine chain open AI",
    "start": "453199",
    "end": "456160"
  },
  {
    "text": "import now I'm just using chat up and AI",
    "start": "456160",
    "end": "459960"
  },
  {
    "text": "model o1 I'll set reasoning level to",
    "start": "459960",
    "end": "462080"
  },
  {
    "text": "medium now note how I prompt this I tell",
    "start": "462080",
    "end": "464919"
  },
  {
    "text": "it what I want I want an educational",
    "start": "464919",
    "end": "466360"
  },
  {
    "text": "report on cause of mitigation for high",
    "start": "466360",
    "end": "468120"
  },
  {
    "text": "cholesterol so this is just an example",
    "start": "468120",
    "end": "470120"
  },
  {
    "text": "prompt tell it how I wanted to produce",
    "start": "470120",
    "end": "472400"
  },
  {
    "text": "the output give it just a dump of stuff",
    "start": "472400",
    "end": "474120"
  },
  {
    "text": "I'm interested in run this cool so that",
    "start": "474120",
    "end": "477800"
  },
  {
    "text": "ran we'll look at the trace in a minute",
    "start": "477800",
    "end": "479639"
  },
  {
    "text": "but I'll show you here in markdown",
    "start": "479639",
    "end": "481680"
  },
  {
    "text": "here's kind of the output so you get a",
    "start": "481680",
    "end": "483120"
  },
  {
    "text": "really nice kind of well laid out report",
    "start": "483120",
    "end": "487039"
  },
  {
    "text": "uh on the topic of Interest right so",
    "start": "487039",
    "end": "489159"
  },
  {
    "text": "this is really cool and it's quite",
    "start": "489159",
    "end": "492840"
  },
  {
    "text": "exhaustive pretty nice open up the trace",
    "start": "492840",
    "end": "495879"
  },
  {
    "text": "and I just want to show you indeed a one",
    "start": "495879",
    "end": "497840"
  },
  {
    "text": "ran now here's what's interesting right",
    "start": "497840",
    "end": "499879"
  },
  {
    "text": "the latency is going to be higher than",
    "start": "499879",
    "end": "501400"
  },
  {
    "text": "you see with the chat model it took 27",
    "start": "501400",
    "end": "503199"
  },
  {
    "text": "seconds okay fair enough and again here",
    "start": "503199",
    "end": "506599"
  },
  {
    "text": "was my prompt as you can see we laid",
    "start": "506599",
    "end": "508680"
  },
  {
    "text": "that out and here is the report output",
    "start": "508680",
    "end": "511599"
  },
  {
    "text": "so it's quite",
    "start": "511599",
    "end": "513039"
  },
  {
    "text": "exhaustive higher latency high quality",
    "start": "513039",
    "end": "516518"
  },
  {
    "text": "lots of reasoning goes into producing",
    "start": "516519",
    "end": "518000"
  },
  {
    "text": "the",
    "start": "518000",
    "end": "518719"
  },
  {
    "text": "report so the o1 models work with",
    "start": "518719",
    "end": "521360"
  },
  {
    "text": "structured outputs which is a very",
    "start": "521360",
    "end": "522919"
  },
  {
    "text": "popular use case so let me just show you",
    "start": "522919",
    "end": "525519"
  },
  {
    "text": "how to do that you basically Define our",
    "start": "525519",
    "end": "527200"
  },
  {
    "text": "LM previously call with structured",
    "start": "527200",
    "end": "528920"
  },
  {
    "text": "outputs this very nice helper method",
    "start": "528920",
    "end": "531240"
  },
  {
    "text": "pass in a schema in this case I just",
    "start": "531240",
    "end": "532720"
  },
  {
    "text": "have a pedantic schema so that's pretty",
    "start": "532720",
    "end": "534760"
  },
  {
    "text": "cool and I go ahead and run",
    "start": "534760",
    "end": "537880"
  },
  {
    "text": "that and we get a structured object out",
    "start": "537880",
    "end": "540720"
  },
  {
    "text": "pretty",
    "start": "540720",
    "end": "542079"
  },
  {
    "text": "cool now people are going to be very",
    "start": "542079",
    "end": "544160"
  },
  {
    "text": "interested in this as well of course",
    "start": "544160",
    "end": "545440"
  },
  {
    "text": "tool calling works with these models so",
    "start": "545440",
    "end": "547480"
  },
  {
    "text": "again I just can call lm. bind tools",
    "start": "547480",
    "end": "549880"
  },
  {
    "text": "let's say in this case I pass in a",
    "start": "549880",
    "end": "551959"
  },
  {
    "text": "multiply tool and I make a request",
    "start": "551959",
    "end": "556399"
  },
  {
    "text": "that's related to the tool the reasoning",
    "start": "556399",
    "end": "558120"
  },
  {
    "text": "model decides to call the tool and I get",
    "start": "558120",
    "end": "560120"
  },
  {
    "text": "a tool call out there we go so those are",
    "start": "560120",
    "end": "563519"
  },
  {
    "text": "really the core things you're going to",
    "start": "563519",
    "end": "564600"
  },
  {
    "text": "want very high quality reasoning and",
    "start": "564600",
    "end": "566200"
  },
  {
    "text": "Report generation for example structured",
    "start": "566200",
    "end": "568800"
  },
  {
    "text": "outputs tool calling with those",
    "start": "568800",
    "end": "570360"
  },
  {
    "text": "Primitives you can do a huge amount of",
    "start": "570360",
    "end": "572240"
  },
  {
    "text": "course now let me talk a little bit",
    "start": "572240",
    "end": "573839"
  },
  {
    "text": "about use cases so here's some examples",
    "start": "573839",
    "end": "575560"
  },
  {
    "text": "that I've seen and they're actually",
    "start": "575560",
    "end": "576839"
  },
  {
    "text": "covered pretty nicely in swick's blog",
    "start": "576839",
    "end": "578640"
  },
  {
    "text": "posts I think are really interesting to",
    "start": "578640",
    "end": "580240"
  },
  {
    "text": "think about for these models so coding",
    "start": "580240",
    "end": "583320"
  },
  {
    "text": "is obvious they're extremely strong at",
    "start": "583320",
    "end": "584920"
  },
  {
    "text": "coding but what types of coding problems",
    "start": "584920",
    "end": "587320"
  },
  {
    "text": "so I think McKay's done some really neat",
    "start": "587320",
    "end": "589120"
  },
  {
    "text": "work on this so what we've heard and and",
    "start": "589120",
    "end": "591640"
  },
  {
    "text": "seen quite a bit is these models are",
    "start": "591640",
    "end": "593680"
  },
  {
    "text": "very strong at one-shotting entire files",
    "start": "593680",
    "end": "596480"
  },
  {
    "text": "or sets of files so again m some nice",
    "start": "596480",
    "end": "599839"
  },
  {
    "text": "workflows and tutorials on this how you",
    "start": "599839",
    "end": "602600"
  },
  {
    "text": "basically give 01 a overall problem give",
    "start": "602600",
    "end": "606480"
  },
  {
    "text": "it the opportunity to produce or IND",
    "start": "606480",
    "end": "608200"
  },
  {
    "text": "oror edit a large set of files and it",
    "start": "608200",
    "end": "610200"
  },
  {
    "text": "can do that often in one shot so coding",
    "start": "610200",
    "end": "612839"
  },
  {
    "text": "is obviously a smash use case for these",
    "start": "612839",
    "end": "614560"
  },
  {
    "text": "models and they're trained obviously on",
    "start": "614560",
    "end": "616279"
  },
  {
    "text": "very hard coding problems they perform",
    "start": "616279",
    "end": "618399"
  },
  {
    "text": "very well on sbench which is a popular",
    "start": "618399",
    "end": "620160"
  },
  {
    "text": "coding Benchmark so coding is obvious",
    "start": "620160",
    "end": "622640"
  },
  {
    "text": "and a very interesting application area",
    "start": "622640",
    "end": "624240"
  },
  {
    "text": "for these",
    "start": "624240",
    "end": "625160"
  },
  {
    "text": "models now another one is this notion of",
    "start": "625160",
    "end": "628519"
  },
  {
    "text": "planning and AG and so in a lot of cases",
    "start": "628519",
    "end": "631360"
  },
  {
    "text": "we've seen agents or agentic workflows",
    "start": "631360",
    "end": "634120"
  },
  {
    "text": "that use some kind of pre-planning Step",
    "start": "634120",
    "end": "636200"
  },
  {
    "text": "Up Front which kind of lays out a set of",
    "start": "636200",
    "end": "638360"
  },
  {
    "text": "follow-on steps that may be executed by",
    "start": "638360",
    "end": "640639"
  },
  {
    "text": "smaller llms or you know by an overall",
    "start": "640639",
    "end": "643639"
  },
  {
    "text": "workflow okay so there's a blog post",
    "start": "643639",
    "end": "646440"
  },
  {
    "text": "from UniFi that actually showcases this",
    "start": "646440",
    "end": "648519"
  },
  {
    "text": "using Lang Lang graph but I think this",
    "start": "648519",
    "end": "650920"
  },
  {
    "text": "General point about using these for",
    "start": "650920",
    "end": "652920"
  },
  {
    "text": "upfront planning and workflows or agents",
    "start": "652920",
    "end": "655560"
  },
  {
    "text": "is obviously a natural fit another",
    "start": "655560",
    "end": "658639"
  },
  {
    "text": "interesting area so n Freeman kind of",
    "start": "658639",
    "end": "660440"
  },
  {
    "text": "laid out kind of a prompt what kind of",
    "start": "660440",
    "end": "662279"
  },
  {
    "text": "ow and outputs are scen are interesting",
    "start": "662279",
    "end": "664399"
  },
  {
    "text": "and I think kind of reflection over",
    "start": "664399",
    "end": "666760"
  },
  {
    "text": "sources of information could be meeting",
    "start": "666760",
    "end": "668680"
  },
  {
    "text": "notes it could be documents is",
    "start": "668680",
    "end": "670040"
  },
  {
    "text": "interesting you know this this uh user",
    "start": "670040",
    "end": "672399"
  },
  {
    "text": "followed up with you know what's the",
    "start": "672399",
    "end": "674120"
  },
  {
    "text": "most important thing no one's paying",
    "start": "674120",
    "end": "675120"
  },
  {
    "text": "attention to pipe all your meeting",
    "start": "675120",
    "end": "676519"
  },
  {
    "text": "transcripts in in and and kind of be",
    "start": "676519",
    "end": "679040"
  },
  {
    "text": "surprised or amazed and so I think",
    "start": "679040",
    "end": "680440"
  },
  {
    "text": "that's kind of a a generally interesting",
    "start": "680440",
    "end": "683000"
  },
  {
    "text": "area for these models is kind of like",
    "start": "683000",
    "end": "684959"
  },
  {
    "text": "deep reflection over some large sets of",
    "start": "684959",
    "end": "687839"
  },
  {
    "text": "context it could be meeting notes it",
    "start": "687839",
    "end": "689079"
  },
  {
    "text": "could documents it could be",
    "start": "689079",
    "end": "690959"
  },
  {
    "text": "papers now data analysis similarly I've",
    "start": "690959",
    "end": "693680"
  },
  {
    "text": "seen a lot of people report on utilizing",
    "start": "693680",
    "end": "696480"
  },
  {
    "text": "these models for analyzing even things",
    "start": "696480",
    "end": "698519"
  },
  {
    "text": "like blood tests um very good for kind",
    "start": "698519",
    "end": "701519"
  },
  {
    "text": "of medical diagnosis or medical",
    "start": "701519",
    "end": "703320"
  },
  {
    "text": "reasoning now of course people may not",
    "start": "703320",
    "end": "705839"
  },
  {
    "text": "want to actually share private medical",
    "start": "705839",
    "end": "707320"
  },
  {
    "text": "data with these with within within API",
    "start": "707320",
    "end": "710480"
  },
  {
    "text": "totally understandable some people do",
    "start": "710480",
    "end": "712320"
  },
  {
    "text": "but anyway I think kind of medical",
    "start": "712320",
    "end": "713880"
  },
  {
    "text": "analysis or Diagnostics is an",
    "start": "713880",
    "end": "715160"
  },
  {
    "text": "interesting area or other areas of data",
    "start": "715160",
    "end": "716839"
  },
  {
    "text": "analysis are obviously very strong um",
    "start": "716839",
    "end": "720000"
  },
  {
    "text": "for these reasoning",
    "start": "720000",
    "end": "722120"
  },
  {
    "text": "models so another one is kind of",
    "start": "722120",
    "end": "724560"
  },
  {
    "text": "research and Report generation so we've",
    "start": "724560",
    "end": "726399"
  },
  {
    "text": "seen deep research from Google come out",
    "start": "726399",
    "end": "728240"
  },
  {
    "text": "it's really interesting I think doing",
    "start": "728240",
    "end": "729639"
  },
  {
    "text": "deep research kind of with 01 as your",
    "start": "729639",
    "end": "732800"
  },
  {
    "text": "own kind of workflow is obviously a very",
    "start": "732800",
    "end": "734959"
  },
  {
    "text": "nice use case for",
    "start": "734959",
    "end": "737240"
  },
  {
    "text": "01 Ben mentioned in his blog post at LM",
    "start": "737240",
    "end": "740120"
  },
  {
    "text": "as judge and so basically there's a lot",
    "start": "740120",
    "end": "742079"
  },
  {
    "text": "of interest in you using LMS as",
    "start": "742079",
    "end": "743600"
  },
  {
    "text": "evaluators these reasoning models could",
    "start": "743600",
    "end": "745760"
  },
  {
    "text": "be very strong for that particular use",
    "start": "745760",
    "end": "747680"
  },
  {
    "text": "case and so I think in in any kind of",
    "start": "747680",
    "end": "749880"
  },
  {
    "text": "workflow where you have like an",
    "start": "749880",
    "end": "751279"
  },
  {
    "text": "evaluation step either it's online or",
    "start": "751279",
    "end": "754440"
  },
  {
    "text": "for example offline these models could",
    "start": "754440",
    "end": "756040"
  },
  {
    "text": "be very",
    "start": "756040",
    "end": "758560"
  },
  {
    "text": "strong and finally I'll just make a note",
    "start": "758560",
    "end": "760680"
  },
  {
    "text": "of kind of cognitive layer of our news",
    "start": "760680",
    "end": "762160"
  },
  {
    "text": "feeds I think this is similar to the",
    "start": "762160",
    "end": "763440"
  },
  {
    "text": "reasoning point above but I've actually",
    "start": "763440",
    "end": "764959"
  },
  {
    "text": "seen a few specific examples of this um",
    "start": "764959",
    "end": "767440"
  },
  {
    "text": "so Eric Sara uh mentioned 01 Trend",
    "start": "767440",
    "end": "770320"
  },
  {
    "text": "finder this is pretty neat uh it's using",
    "start": "770320",
    "end": "772560"
  },
  {
    "text": "fire crawl uh for actually content",
    "start": "772560",
    "end": "775440"
  },
  {
    "text": "scraping and passing that to 01 to",
    "start": "775440",
    "end": "777800"
  },
  {
    "text": "monitor no you Trends on social media I",
    "start": "777800",
    "end": "781480"
  },
  {
    "text": "have a number of apps that do similar",
    "start": "781480",
    "end": "782800"
  },
  {
    "text": "things and I think it's a really nice",
    "start": "782800",
    "end": "784079"
  },
  {
    "text": "use case and I think using 01 is really",
    "start": "784079",
    "end": "786199"
  },
  {
    "text": "cool for this swix mentioned uh in one",
    "start": "786199",
    "end": "789040"
  },
  {
    "text": "of the podcasts that he's actually using",
    "start": "789040",
    "end": "790720"
  },
  {
    "text": "01 for AI news as well and so that's",
    "start": "790720",
    "end": "792880"
  },
  {
    "text": "another good example of kind of a",
    "start": "792880",
    "end": "794680"
  },
  {
    "text": "cognitive layer over news feeds",
    "start": "794680",
    "end": "796360"
  },
  {
    "text": "isolating relevant information and",
    "start": "796360",
    "end": "798680"
  },
  {
    "text": "servicing it to",
    "start": "798680",
    "end": "800000"
  },
  {
    "text": "you so maybe just to recap briefly chap",
    "start": "800000",
    "end": "803279"
  },
  {
    "text": "models and reasoning models are pretty",
    "start": "803279",
    "end": "804480"
  },
  {
    "text": "different different scaling paradigms so",
    "start": "804480",
    "end": "806519"
  },
  {
    "text": "chat models scale using next token",
    "start": "806519",
    "end": "808079"
  },
  {
    "text": "prediction reasoning models are scaling",
    "start": "808079",
    "end": "809680"
  },
  {
    "text": "using RL over Chain of Thought the",
    "start": "809680",
    "end": "811959"
  },
  {
    "text": "reasoning types are different so chat",
    "start": "811959",
    "end": "813480"
  },
  {
    "text": "models you can think of as system one",
    "start": "813480",
    "end": "815440"
  },
  {
    "text": "fast intuitive reasoning models more",
    "start": "815440",
    "end": "817240"
  },
  {
    "text": "like system to slow effortful now how do",
    "start": "817240",
    "end": "820600"
  },
  {
    "text": "you work with a model what do you",
    "start": "820600",
    "end": "821880"
  },
  {
    "text": "actually tell it with chat models we",
    "start": "821880",
    "end": "823800"
  },
  {
    "text": "often told it how to think think step by",
    "start": "823800",
    "end": "825800"
  },
  {
    "text": "step think as an engineer reasoning",
    "start": "825800",
    "end": "827639"
  },
  {
    "text": "models don't tell it how to think tell",
    "start": "827639",
    "end": "829600"
  },
  {
    "text": "it what you want here's the output I",
    "start": "829600",
    "end": "831240"
  },
  {
    "text": "want okay interaction mode chat models",
    "start": "831240",
    "end": "834600"
  },
  {
    "text": "chat interactive it's pulling context",
    "start": "834600",
    "end": "836560"
  },
  {
    "text": "from the user over the course of a chat",
    "start": "836560",
    "end": "838720"
  },
  {
    "text": "reason",
    "start": "838720",
    "end": "839600"
  },
  {
    "text": "models they are going off and wormholing",
    "start": "839600",
    "end": "842920"
  },
  {
    "text": "on something you don't want really",
    "start": "842920",
    "end": "844440"
  },
  {
    "text": "necessarily to interact with them in a",
    "start": "844440",
    "end": "845959"
  },
  {
    "text": "chat format you want to give it a deeper",
    "start": "845959",
    "end": "849040"
  },
  {
    "text": "task and have it just go churn better",
    "start": "849040",
    "end": "851399"
  },
  {
    "text": "for research and planning really good",
    "start": "851399",
    "end": "853920"
  },
  {
    "text": "for things like ambient or in the",
    "start": "853920",
    "end": "855720"
  },
  {
    "text": "background style agent so that's those",
    "start": "855720",
    "end": "857440"
  },
  {
    "text": "are the workflows I think about more",
    "start": "857440",
    "end": "858800"
  },
  {
    "text": "here so if you look back at our use",
    "start": "858800",
    "end": "860560"
  },
  {
    "text": "cases things like Trend finder again",
    "start": "860560",
    "end": "862720"
  },
  {
    "text": "this can run in the background uh LMS",
    "start": "862720",
    "end": "865440"
  },
  {
    "text": "judge when it is running offline it's",
    "start": "865440",
    "end": "867079"
  },
  {
    "text": "kind of in the background deep research",
    "start": "867079",
    "end": "868720"
  },
  {
    "text": "again the background run that research",
    "start": "868720",
    "end": "870519"
  },
  {
    "text": "process for 30 seconds 1 minute um you",
    "start": "870519",
    "end": "873639"
  },
  {
    "text": "know a lot of these you'll see are kind",
    "start": "873639",
    "end": "875399"
  },
  {
    "text": "of use cases that don't demand load",
    "start": "875399",
    "end": "878320"
  },
  {
    "text": "latency they're things that can run in",
    "start": "878320",
    "end": "879560"
  },
  {
    "text": "the background over longer periods of",
    "start": "879560",
    "end": "881199"
  },
  {
    "text": "time to produce kind of deeper effortful",
    "start": "881199",
    "end": "883880"
  },
  {
    "text": "outputs and so again I think overall",
    "start": "883880",
    "end": "886639"
  },
  {
    "text": "really exciting Paradigm we're early in",
    "start": "886639",
    "end": "888920"
  },
  {
    "text": "this trend it's absolutely worth if you",
    "start": "888920",
    "end": "891199"
  },
  {
    "text": "have applications already using for",
    "start": "891199",
    "end": "892759"
  },
  {
    "text": "example open AI uh you can slot in 01 uh",
    "start": "892759",
    "end": "897839"
  },
  {
    "text": "or of course other LM slot in01 and give",
    "start": "897839",
    "end": "901480"
  },
  {
    "text": "it a try if they fit kind of any of the",
    "start": "901480",
    "end": "903959"
  },
  {
    "text": "use cases mentioned here and so if you",
    "start": "903959",
    "end": "907079"
  },
  {
    "text": "have kind of good experiences or further",
    "start": "907079",
    "end": "909680"
  },
  {
    "text": "thoughts would love to hear comments",
    "start": "909680",
    "end": "911199"
  },
  {
    "text": "below and uh thank you very much for",
    "start": "911199",
    "end": "913560"
  },
  {
    "text": "listening",
    "start": "913560",
    "end": "916560"
  }
]
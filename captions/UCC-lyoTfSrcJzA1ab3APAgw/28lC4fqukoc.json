[
  {
    "start": "0",
    "end": "15000"
  },
  {
    "text": "hi this is Lance Martin uh I'm a software engineer at Lang chain and I want to give kind of an overview of how",
    "start": "4359",
    "end": "10719"
  },
  {
    "text": "I've been using multimodal LMS uh for a few applications um first maybe an overview",
    "start": "10719",
    "end": "17720"
  },
  {
    "start": "15000",
    "end": "115000"
  },
  {
    "text": "of progress in multimodal llms um back in 2012 Andre Kathy put",
    "start": "17720",
    "end": "23519"
  },
  {
    "text": "this kind of entertaining blog post out talking about the state of computer vision and the the point was that",
    "start": "23519",
    "end": "30320"
  },
  {
    "text": "computer vision models were pretty far away from actually reasoning about an image like this and kind of understanding why it's funny um it was",
    "start": "30320",
    "end": "37719"
  },
  {
    "text": "kind of notable that like this was a real challenge for vision models and we were really far away from kind of AI",
    "start": "37719",
    "end": "44440"
  },
  {
    "text": "visual recognition that can kind of understand and appreciate humor now today if you take that image and pass it",
    "start": "44440",
    "end": "51039"
  },
  {
    "text": "GPD 4 V it indeed is able to understand exactly why you know this is funny and",
    "start": "51039",
    "end": "57199"
  },
  {
    "text": "it's actually kind of a fun demonstration to do that just to get a sense for how good these kind of visual recognition capabilities have gotten",
    "start": "57199",
    "end": "63600"
  },
  {
    "text": "with recent multimodal LMS you another interesting example of",
    "start": "63600",
    "end": "68640"
  },
  {
    "text": "this is Steve wnc had in 2010 the copy test you know what would it take for uh",
    "start": "68640",
    "end": "74520"
  },
  {
    "text": "a test for AGI would be that a that a computer could actually make a cup of coffee could move you know enter a room",
    "start": "74520",
    "end": "81960"
  },
  {
    "text": "determine all the elements necessary to make a cup of coffee and make a cup of coffee in the gbd4 v paper they actually",
    "start": "81960",
    "end": "88360"
  },
  {
    "text": "showed a number of interesting examples visual recognition where you know the M can recognize you know elements in a",
    "start": "88360",
    "end": "94759"
  },
  {
    "text": "coffee machine how to operate a coffee machine how to get around a kitchen parts of a kitchen and so you know it's",
    "start": "94759",
    "end": "100079"
  },
  {
    "text": "another interesting demonstration that within you know roughly 10 to 15 year time span we've really gone quite far in",
    "start": "100079",
    "end": "106320"
  },
  {
    "text": "terms of kind of visual recognition capabilities and now these are really in kind of everyone's hands with GPD 4V and",
    "start": "106320",
    "end": "112880"
  },
  {
    "text": "some other models that we'll talk about today um so kind of a quick overview of",
    "start": "112880",
    "end": "118079"
  },
  {
    "start": "115000",
    "end": "347000"
  },
  {
    "text": "models a lot of this work of course of course you know predates uh you know the current year of",
    "start": "118079",
    "end": "124159"
  },
  {
    "text": "2023 uh it's probably worth noting clip it's very important work from open AI um",
    "start": "124159",
    "end": "129640"
  },
  {
    "text": "that kind of map data from different modalities text and images into a shared embedding space um",
    "start": "129640",
    "end": "137239"
  },
  {
    "text": "it's open source and actually clip embeddings are still used uh for visual encoding in models that you'll see today",
    "start": "137239",
    "end": "144360"
  },
  {
    "text": "for example lava um and can also be used as kind of multimodel embeddings to take",
    "start": "144360",
    "end": "149400"
  },
  {
    "text": "text images and map them to a common embedding space uh so clip is like a very important um kind of work in this",
    "start": "149400",
    "end": "157319"
  },
  {
    "text": "in this like Arc of multimodal llms um Lava came out earlier this year",
    "start": "157319",
    "end": "163200"
  },
  {
    "text": "and it's really interesting open source model that builds on clip uh that uses",
    "start": "163200",
    "end": "168640"
  },
  {
    "text": "um a clip image encoder as noted with 3 336 5336 pixel resolution and an LM vuna",
    "start": "168640",
    "end": "176440"
  },
  {
    "text": "which you may have heard of it's a fine-tune variant on llama 2 um variants have been adapted for other LMS like",
    "start": "176440",
    "end": "183120"
  },
  {
    "text": "mistol 7B so this is actually really cool we'll show this a little bit later",
    "start": "183120",
    "end": "188360"
  },
  {
    "text": "but it is open source you can run your laptop um and it gives you really interesting multimodal capabilities uh",
    "start": "188360",
    "end": "194400"
  },
  {
    "text": "fuyu is another one that came out this year uh which actually has an interesting architecture bypasses the",
    "start": "194400",
    "end": "200000"
  },
  {
    "text": "image encoder can run it variable resolution that's from Adept um and of course GPD 4B and most recently Gemini",
    "start": "200000",
    "end": "206480"
  },
  {
    "text": "from Google have come out these are State of-the-art close Source multimodal LMS very strong performance very very",
    "start": "206480",
    "end": "212640"
  },
  {
    "text": "good impressive demos um available through apis so that's kind of the landscape and",
    "start": "212640",
    "end": "218280"
  },
  {
    "text": "there's indeed more models is just kind of a short overview with some links as well um and maybe it's worth walking",
    "start": "218280",
    "end": "224840"
  },
  {
    "text": "through what's kind of going on so with lava for example um there's a notion of image embedding so we're kind of",
    "start": "224840",
    "end": "231319"
  },
  {
    "text": "familiar with text embeddings used very commonly in in a lot of AI work today taking a piece of text and mapping it",
    "start": "231319",
    "end": "237720"
  },
  {
    "text": "into an embedding space which is just kind of like a high dimensional Vector representation of a piece of text Chunk",
    "start": "237720",
    "end": "242920"
  },
  {
    "text": "of text you can do the same thing for images you can take an image and map it to this kind of this this uh you know",
    "start": "242920",
    "end": "248360"
  },
  {
    "text": "higher Dimension uh embedding space and similar images kind of wound wind up in",
    "start": "248360",
    "end": "254760"
  },
  {
    "text": "similar space in this in this projection this is kind of like a a 2d representation of um kind of the",
    "start": "254760",
    "end": "262120"
  },
  {
    "text": "embedding and you can see that you know similar visually similar objects kind of are mapped to similar regions in this",
    "start": "262120",
    "end": "268720"
  },
  {
    "text": "high-dimensional space in this case it's kind of projected on to 2D um so that's kind of step one you can take images you",
    "start": "268720",
    "end": "274919"
  },
  {
    "text": "can embed them and then step two is you actually can do this projection step you",
    "start": "274919",
    "end": "281360"
  },
  {
    "text": "can take kind of a an image embedding and project it into the same kind of space as text embeddings and so um this",
    "start": "281360",
    "end": "289880"
  },
  {
    "text": "is kind of this this very nice kind of visualization showing you have your image encoder like clip you get your",
    "start": "289880",
    "end": "296600"
  },
  {
    "text": "your multimodal embedding or your image encoding and then you project that uh",
    "start": "296600",
    "end": "302320"
  },
  {
    "text": "into kind of the same the same kind of token space as your language embedding",
    "start": "302320",
    "end": "307800"
  },
  {
    "text": "and then those tokens can be incat and pass to llm so you can really think about this as like kind of two steps",
    "start": "307800",
    "end": "313840"
  },
  {
    "text": "you're like basically taking visual content embedding it then projecting it into a space that can be concatenated",
    "start": "313840",
    "end": "319360"
  },
  {
    "text": "with your text tokens and that's really all you're doing so when you take a multimodal llm you're giving it like a",
    "start": "319360",
    "end": "325240"
  },
  {
    "text": "piece of text an image and you're kind of mapping those both to the common",
    "start": "325240",
    "end": "330319"
  },
  {
    "text": "token space and it can read that kind of common uh concatenated string of tokens",
    "start": "330319",
    "end": "337840"
  },
  {
    "text": "um at once and reason about what's going on so so that's maybe like a simple like mental model how to think about what's",
    "start": "337840",
    "end": "344560"
  },
  {
    "text": "happening when you work with multimodal LMS um yeah let's talk a about use cases",
    "start": "344560",
    "end": "350000"
  },
  {
    "start": "347000",
    "end": "425000"
  },
  {
    "text": "so Greg Cameron on Twitter kind of had this kind of nice visualization of a bunch of things that have been been",
    "start": "350000",
    "end": "355800"
  },
  {
    "text": "shown with GPD 4V um a lot of people seen really cool demos with image captioning um extractions a really good",
    "start": "355800",
    "end": "363360"
  },
  {
    "text": "one taking an image extracting elements text elements and so forth um",
    "start": "363360",
    "end": "369479"
  },
  {
    "text": "recommendations so there's kind of like a lot of design applications um kind of suggestions",
    "start": "369479",
    "end": "374960"
  },
  {
    "text": "about how to improve the visual Aesthetics of a scene of a of a of of like you know um of an object um and of",
    "start": "374960",
    "end": "383240"
  },
  {
    "text": "course like interpretation this is like you know common in the rag context for example if you have like a you know",
    "start": "383240",
    "end": "390080"
  },
  {
    "text": "collection of say we'll talk a little bit later to it a little bit later about slides um or about diagrams in documents",
    "start": "390080",
    "end": "397639"
  },
  {
    "text": "you can of course use a vision model to reason about what's happening there in a question answer context um and this was like an intering",
    "start": "397639",
    "end": "405680"
  },
  {
    "text": "demonstration of of extraction uh shown in the in the gbd uh 4V paper here uh",
    "start": "405680",
    "end": "412560"
  },
  {
    "text": "actually this is a follow on to the GPD 4V model by Microsoft showing here are some interesting um explorations and",
    "start": "412560",
    "end": "420080"
  },
  {
    "text": "they they talked about kind of extraction from complex documents um so let's actually walk",
    "start": "420080",
    "end": "427080"
  },
  {
    "start": "425000",
    "end": "525000"
  },
  {
    "text": "through a demo to make this a little bit more concrete and I'll share kind of a bunch of code and and templates that can be easily reused later um so I think you",
    "start": "427080",
    "end": "436039"
  },
  {
    "text": "know presentations like slide decks are a really good application for vision models because they're inherently kind of visual they have lots of kind of",
    "start": "436039",
    "end": "442520"
  },
  {
    "text": "complex visual elements like like graphs uh tables figures and they're very",
    "start": "442520",
    "end": "448479"
  },
  {
    "text": "common you know every nearly every organization uses slides in some capacity and conventional rag approaches",
    "start": "448479",
    "end": "453919"
  },
  {
    "text": "that just strip the text out really miss a lot of this so let's try kind of how",
    "start": "453919",
    "end": "459080"
  },
  {
    "text": "could we build a rag system over the visual content in in a slide deck um so",
    "start": "459080",
    "end": "466039"
  },
  {
    "text": "to start off what I did was I took a slide deck and this is um uh data dog's",
    "start": "466039",
    "end": "471840"
  },
  {
    "text": "Q3 earnings report I randomly chose it you know it was just like an interesting demonstration of like kind of complex uh",
    "start": "471840",
    "end": "479000"
  },
  {
    "text": "you know financial information and figures and slide deck and I created a set of 10 questions and answer pairs",
    "start": "479000",
    "end": "485960"
  },
  {
    "text": "about these slides this is like my evalve set um and this is really easy to",
    "start": "485960",
    "end": "491159"
  },
  {
    "text": "do I can just create a CSV that has like my question and my answer in this case like my input output pairs um and it's",
    "start": "491159",
    "end": "498520"
  },
  {
    "text": "just a set of questions that I devised myself I looked at the slides I said okay here's some interesting question answer pairs I put them in a CSV and I",
    "start": "498520",
    "end": "506280"
  },
  {
    "text": "load these into Langs Smith now Langs Smith is Lang chain platform that supports durability and",
    "start": "506280",
    "end": "511880"
  },
  {
    "text": "evaluations um and I create a data set for myself in Lang Smith and there's some links down here that show exactly",
    "start": "511880",
    "end": "517360"
  },
  {
    "text": "how to do that but that's my starting point so I say okay here's my evaluation set I have the slide deck I built 10",
    "start": "517360",
    "end": "523200"
  },
  {
    "text": "question answer pairs from the slides now let's compare some approaches there might be two different",
    "start": "523200",
    "end": "529519"
  },
  {
    "start": "525000",
    "end": "960000"
  },
  {
    "text": "ways to think about multimodal rag um so one is this notion of",
    "start": "529519",
    "end": "535680"
  },
  {
    "text": "multimodal embeddings so we take our slides we extract them as images in every image we use multimodal",
    "start": "535680",
    "end": "541800"
  },
  {
    "text": "embeddings to map them into this kind of this embedding space that is common between kind of text and and images um",
    "start": "541800",
    "end": "548920"
  },
  {
    "text": "for that I use open clip embeddings um and so I now have an index",
    "start": "548920",
    "end": "554160"
  },
  {
    "text": "in this case I use chroma that contains a bunch of images uh that have been embedded using open",
    "start": "554160",
    "end": "560560"
  },
  {
    "text": "clip um at retrieval time I ask a question I use I basically take the",
    "start": "560560",
    "end": "566000"
  },
  {
    "text": "natural language question embed it indeed with multimodal embeddings same ones similarity search just like normal",
    "start": "566000",
    "end": "572040"
  },
  {
    "text": "retrieve images that are similar to my question pass the image to in this case",
    "start": "572040",
    "end": "577399"
  },
  {
    "text": "uh my multimodal LM like GPD 4V to answer the question so I'm just doing really image retrieval from natural",
    "start": "577399",
    "end": "583600"
  },
  {
    "text": "language using multimodal embeddings that that's process that's kind of step one at the top now option two is a little bit",
    "start": "583600",
    "end": "591519"
  },
  {
    "text": "different where I take every image and I caption it so I basically produce a summary of the image and I embed that",
    "start": "591519",
    "end": "597000"
  },
  {
    "text": "summary with text embeddings and we'll talk a little bit later why this might have advantages but for now",
    "start": "597000",
    "end": "603440"
  },
  {
    "text": "let's just say these are the two approaches so I do this captioning so I take the image convert it to text um",
    "start": "603440",
    "end": "609880"
  },
  {
    "text": "embed that text and then I have this linkage between this like this summary or caption and the raw image I search",
    "start": "609880",
    "end": "617720"
  },
  {
    "text": "given my question among those summaries so I'm just doing a kind of text embedding lookup and then I fish out",
    "start": "617720",
    "end": "623680"
  },
  {
    "text": "whatever image is closest and pass that to the to the multimodal L for synthesis so in short in one case I'm just using",
    "start": "623680",
    "end": "630680"
  },
  {
    "text": "multimodal embeddings to do the lookup across my images in the other case I'm using text embeddings on image summaries",
    "start": "630680",
    "end": "638079"
  },
  {
    "text": "so that's really kind of the two approaches now first we can do like a sending check we can take our slide deck",
    "start": "638079",
    "end": "644880"
  },
  {
    "text": "we can embed it and then we can show does this even work at all so here I ask a question what's the projected Tam over",
    "start": "644880",
    "end": "651040"
  },
  {
    "text": "time for observability and I see that this is my retriever I've built and the notebook is all linked here um I can",
    "start": "651040",
    "end": "658079"
  },
  {
    "text": "retrieve the slide image that's relevant to that question so that's pretty neat right I can ask a natural English",
    "start": "658079",
    "end": "663360"
  },
  {
    "text": "question and get back an image then I can take that image pass it a GPT 4V 4V",
    "start": "663360",
    "end": "668880"
  },
  {
    "text": "answers the question very precisely by looking at the details in the image so that's the general flow here um for",
    "start": "668880",
    "end": "676240"
  },
  {
    "text": "valuations then all I'm going to do is I take whatever rag chain whether it's my",
    "start": "676240",
    "end": "681600"
  },
  {
    "text": "image capturing model or my multiple M embedding model uh and for every for every",
    "start": "681600",
    "end": "688120"
  },
  {
    "text": "question I generate the rag answer uh compare that to my ground truth answer I",
    "start": "688120",
    "end": "693440"
  },
  {
    "text": "have this greater so Langs Smith will do all this for me it will run a grer that will use for example a specified llm",
    "start": "693440",
    "end": "700760"
  },
  {
    "text": "like gp4 to compare those two responses uh to compare like the basically the the rag answer to the ground truth answer",
    "start": "700760",
    "end": "708279"
  },
  {
    "text": "and um and then I can yeah I'll show a little bit later kind of do this nice",
    "start": "708279",
    "end": "713600"
  },
  {
    "text": "comparison uh between different models for each question and which one's doing better and then root cause so that",
    "start": "713600",
    "end": "718839"
  },
  {
    "text": "that's kind of set up here again I I build an evalve set based on the slide deck I have two different rag approaches",
    "start": "718839",
    "end": "724519"
  },
  {
    "text": "and I have my evaluation approach right here and we can look at the results so",
    "start": "724519",
    "end": "730079"
  },
  {
    "text": "if I use GPD for text only just like a standard PDF loader take the slide deck",
    "start": "730079",
    "end": "735880"
  },
  {
    "text": "rip out the text do it it's pretty bad you might I mean of course it's kind of",
    "start": "735880",
    "end": "741320"
  },
  {
    "text": "to be expected because a lot of the questions rely on visual content diagrams and so forth which you can't",
    "start": "741320",
    "end": "746639"
  },
  {
    "text": "get if you just look at the text now with open clip here's where it's a little bit interesting with multi",
    "start": "746639",
    "end": "753120"
  },
  {
    "text": "embeddings using open clip the performance is moderate and you can see I'm using open",
    "start": "753120",
    "end": "758839"
  },
  {
    "text": "clip but gbd4 V so really what's What's Happening Here is the retrieval step is",
    "start": "758839",
    "end": "764399"
  },
  {
    "text": "a little bit uh I would say of moderate quality",
    "start": "764399",
    "end": "770160"
  },
  {
    "text": "and we can talk a about why this is but the intuition is that for slides that are pretty similar multim embeddings may",
    "start": "770160",
    "end": "777440"
  },
  {
    "text": "not quite have the the capacity to differentiate them and I made this as a controversial statement it's also",
    "start": "777440",
    "end": "784079"
  },
  {
    "text": "Complicated by open clip has many different embedding models available so I chose one that has kind of reasonable",
    "start": "784079",
    "end": "789720"
  },
  {
    "text": "memory footprint and uh in like in like solid performance not exceptional performance so again there's a lot you",
    "start": "789720",
    "end": "796360"
  },
  {
    "text": "can play with here there's many different multimodal embedding models but I think the thing I'll caution is that retrieval may be challenging using",
    "start": "796360",
    "end": "803880"
  },
  {
    "text": "multi embeddings in a setting like slides that are actually pretty like semantically Sim what you really want is",
    "start": "803880",
    "end": "810440"
  },
  {
    "text": "subtle differentiation between like the content and the slide like is this table showing a or table showing B but maybe",
    "start": "810440",
    "end": "816279"
  },
  {
    "text": "to the multile embedding model they both kind of look like tables there isn't that much differentiation in retrieval so I think that's just a",
    "start": "816279",
    "end": "822880"
  },
  {
    "text": "caveat what I see is the multiv vector um which is basically the image",
    "start": "822880",
    "end": "828959"
  },
  {
    "text": "captioning approach is really good and you kind of would expect this you if you take GPD VB and ask it to summarize an",
    "start": "828959",
    "end": "837440"
  },
  {
    "text": "image uh of like a of a table or graph it does really good like it's you can get really rich summaries and then",
    "start": "837440",
    "end": "844240"
  },
  {
    "text": "you're searching in natural language and I'll show some examples later um but you can do really effective retrieval based",
    "start": "844240",
    "end": "850360"
  },
  {
    "text": "on an image caption that's gener by a good model GPT 4V um your performance here is very strong um again you know",
    "start": "850360",
    "end": "857440"
  },
  {
    "text": "the aor bar show standard error across um it's a 10 EV set in three trials and",
    "start": "857440",
    "end": "862480"
  },
  {
    "text": "so there's a little bit of noise I'll talk about later there's also some kind of API flakiness with gbd4 v that that I",
    "start": "862480",
    "end": "868279"
  },
  {
    "text": "think will hope hope be resolved soon um but so I just want to the intuition here",
    "start": "868279",
    "end": "873360"
  },
  {
    "text": "is that for visual content like slide decks just using text naturally as you",
    "start": "873360",
    "end": "879440"
  },
  {
    "text": "expect is is really insufficient for like answering you know interesting questions multile embeddings have a lot",
    "start": "879440",
    "end": "886279"
  },
  {
    "text": "of Promise they probably are the most promising in terms of like ultimate ceiling um there's lots of models that",
    "start": "886279",
    "end": "893440"
  },
  {
    "text": "are coming out that will come out soon um and you you know it has architectural",
    "start": "893440",
    "end": "899560"
  },
  {
    "text": "appeal it's fairly simple it's just like in different embedding model you stick that into a vector store and and it it's",
    "start": "899560",
    "end": "904680"
  },
  {
    "text": "pretty seamless the captioning thing actually has really good performance now architecture is a little bit more",
    "start": "904680",
    "end": "910600"
  },
  {
    "text": "complicated you have to generate these image captions ahead of time there's some cost concerns there um so I think",
    "start": "910600",
    "end": "916079"
  },
  {
    "text": "that's kind of the tradeoffs today the capturing approach can really be effective for things like you know compx",
    "start": "916079",
    "end": "921320"
  },
  {
    "text": "content like slides uh but it's a little bit more costly um and this this is kind of",
    "start": "921320",
    "end": "929279"
  },
  {
    "text": "showing how you can use Lang Smith like deep dive and compare so this is I can look at all my question answer pairs",
    "start": "929279",
    "end": "934720"
  },
  {
    "text": "here and this will show the answer Generations um I can dig into each one",
    "start": "934720",
    "end": "941720"
  },
  {
    "text": "um you can see like the the greater scores so zero being incorrect one being",
    "start": "941720",
    "end": "947120"
  },
  {
    "text": "correct um and then my experiments across the top so this is just showing kind of an overview of what you get if",
    "start": "947120",
    "end": "952199"
  },
  {
    "text": "you run this evaluation with Langs Smith you can look at these these eval you can look at the results kind of in in high",
    "start": "952199",
    "end": "958600"
  },
  {
    "text": "grity which is quite convenient um now here here's kind of a",
    "start": "958600",
    "end": "963680"
  },
  {
    "start": "960000",
    "end": "1128000"
  },
  {
    "text": "fun case study um so the question was Data dog um well the question was how",
    "start": "963680",
    "end": "970600"
  },
  {
    "text": "many how many customers data dog have the answer was around 26,800 and that was from one slide you",
    "start": "970600",
    "end": "977199"
  },
  {
    "text": "can see here that looks like this and the answer is embedded in this kind of table type thing and the visual model",
    "start": "977199",
    "end": "985959"
  },
  {
    "text": "has to find this slide then actually reason about it and get the right answer out so you can see that text only misses",
    "start": "985959",
    "end": "995240"
  },
  {
    "text": "this um which is kind of interesting um multimol Bings likely retrieves the",
    "start": "995240",
    "end": "1001759"
  },
  {
    "text": "incorrect slide um and indeed the multiv vector",
    "start": "1001759",
    "end": "1007880"
  },
  {
    "text": "approach which is our image curing does get this correct and right down here you're seeing this is a an image of the",
    "start": "1007880",
    "end": "1015240"
  },
  {
    "text": "Langs Smith Trace that you get so Langs Smith actually renders the images for you so you actually can look at and I",
    "start": "1015240",
    "end": "1022199"
  },
  {
    "text": "may be able to even open this up now maybe we can we can look at it",
    "start": "1022199",
    "end": "1028678"
  },
  {
    "text": "um yeah actually here it is so this is actually looking at the trace um and",
    "start": "1028679",
    "end": "1034798"
  },
  {
    "text": "what you can see is this is what was actually past the LM so here's the images that got retrieved here's the",
    "start": "1034799",
    "end": "1040959"
  },
  {
    "text": "prompt your an analyst has the answer questions um here is the user private",
    "start": "1040959",
    "end": "1046000"
  },
  {
    "text": "question how many total customers Dat Dog have and then the tables or text and",
    "start": "1046000",
    "end": "1051679"
  },
  {
    "text": "pretty cool it's able to find this in the images and gives you their answer so that's like a nice demonstration of like",
    "start": "1051679",
    "end": "1057400"
  },
  {
    "text": "these are actually really cool and impressive models um",
    "start": "1057400",
    "end": "1063679"
  },
  {
    "text": "and uh just make sure I yeah I'm back on the slides very good um and that that's",
    "start": "1063679",
    "end": "1070640"
  },
  {
    "text": "kind of a nice demonstration of how well the these models can work uh same here",
    "start": "1070640",
    "end": "1076120"
  },
  {
    "text": "just looking at like retrieval from a table again uh actually in this case they all got it right so that that's",
    "start": "1076120",
    "end": "1082000"
  },
  {
    "text": "kind of interesting topk rag was able to car rather get this so in some cases indeed text only is sufficient it can",
    "start": "1082000",
    "end": "1088480"
  },
  {
    "text": "strip this this text out it can reason about this table good enough um so you",
    "start": "1088480",
    "end": "1094080"
  },
  {
    "text": "know I think it's worth noting that depends on the nature of the questions you want to you want to answer to want",
    "start": "1094080",
    "end": "1099240"
  },
  {
    "text": "to ask about your content uh but in many cases um as noted in the eval results",
    "start": "1099240",
    "end": "1104480"
  },
  {
    "text": "imagery is very very important to capture and it could also be the orientation of the text within the image",
    "start": "1104480",
    "end": "1111120"
  },
  {
    "text": "kind of matters fres your reasoning about their content as well which you would lose with you if you just do kind of a a extraction of the text alone but",
    "start": "1111120",
    "end": "1118120"
  },
  {
    "text": "in this case it's a table so you know visual reasoning works really well but hey so do is just stripping the tech",
    "start": "1118120",
    "end": "1123960"
  },
  {
    "text": "stripping the text from the table from the slide as well um so maybe here's",
    "start": "1123960",
    "end": "1129360"
  },
  {
    "start": "1128000",
    "end": "1402000"
  },
  {
    "text": "like another way to look at all this is we talked a lot about different like rag architectures now we can look across",
    "start": "1129360",
    "end": "1135240"
  },
  {
    "text": "different llms and this is on the same all set and now we're looking at again uh text only",
    "start": "1135240",
    "end": "1143600"
  },
  {
    "text": "so results kind of consistent this is actually a separate set of experiments done by one of my colleagues um similar",
    "start": "1143600",
    "end": "1150480"
  },
  {
    "text": "results though so you can see text only pretty bad around 20% uh some St the",
    "start": "1150480",
    "end": "1155840"
  },
  {
    "text": "standard errors shown uh I guess this is across 10 different trials um now what",
    "start": "1155840",
    "end": "1161799"
  },
  {
    "text": "you see here is we're now comparing Gemini Pro to GPD 4V and what you can see is there's the same textual Trend",
    "start": "1161799",
    "end": "1169559"
  },
  {
    "text": "which is that open clip embeddings at least ones we using fall short of the captioning approach pretty",
    "start": "1169559",
    "end": "1175960"
  },
  {
    "text": "consistently um and indeed the multiv vector approach with image summaries does the best and",
    "start": "1175960",
    "end": "1183960"
  },
  {
    "text": "also uh Gemini which you can see kind of noted here is on power g4v which you",
    "start": "1183960",
    "end": "1190360"
  },
  {
    "text": "know their paper also reports this um you know the precise quantitative differen between",
    "start": "1190360",
    "end": "1197240"
  },
  {
    "text": "the models can be kind of difficult to assess of course a lot was reported the",
    "start": "1197240",
    "end": "1202799"
  },
  {
    "text": "intuition though is like it's a very good model and it it seems to be on par",
    "start": "1202799",
    "end": "1207919"
  },
  {
    "text": "with GPD 4V absolutely worth testing and trying uh so I I you know we've been pretty impressed with it um it's very",
    "start": "1207919",
    "end": "1214440"
  },
  {
    "text": "good to have multiple options for multimodal for multimodal models so I think that that's you know really nice thing to",
    "start": "1214440",
    "end": "1220600"
  },
  {
    "text": "highlight I'll show another interesting thing here I was looking at resolutions so there's this kind of odd thing with",
    "start": "1220600",
    "end": "1227280"
  },
  {
    "text": "multimodel models you have to pass images into them and like well you know what resolution should you provide those",
    "start": "1227280",
    "end": "1233640"
  },
  {
    "text": "images and it it's a little bit kind of vague so I did kind of a titration across different resolutions and this is",
    "start": "1233640",
    "end": "1239280"
  },
  {
    "text": "on that same eval set um here I'm showing the mean fraction correct uh show standard errors I ran three runs on",
    "start": "1239280",
    "end": "1247120"
  },
  {
    "text": "this 10 question eval set um I ran on gbd4 V and Gemini and you can see kind",
    "start": "1247120",
    "end": "1253640"
  },
  {
    "text": "of it's a little bit noisy and I'll show you kind of why in the next slide it's a little bit noisy here the general trend",
    "start": "1253640",
    "end": "1260760"
  },
  {
    "text": "is notable at very low resolutions as 192 by 108 pixels performance is really",
    "start": "1260760",
    "end": "1266120"
  },
  {
    "text": "bad so kind of on the extreme it's really bad and performance is indeed the",
    "start": "1266120",
    "end": "1272360"
  },
  {
    "text": "best kind of in this in this larger resolution range there is kind of noise here in the middle so I still don't have",
    "start": "1272360",
    "end": "1278760"
  },
  {
    "text": "a totally firm view where the precise cuto off is with respect to like uh",
    "start": "1278760",
    "end": "1284320"
  },
  {
    "text": "performance degradation with both models it seems you can kind of a Le all the",
    "start": "1284320",
    "end": "1289799"
  },
  {
    "text": "way down to 40 by by uh 270 performance is still moderate it's kind of",
    "start": "1289799",
    "end": "1295559"
  },
  {
    "text": "consistent in across this mid-range and then you get above 800 into 900 pixels",
    "start": "1295559",
    "end": "1302360"
  },
  {
    "text": "um and the de performance goes up the results are a little bit noisy I'd like to do more studies here at least this is",
    "start": "1302360",
    "end": "1307440"
  },
  {
    "text": "just showing you kind of the intuition is indeed that image resolution does matter intuitively lower resolution is",
    "start": "1307440",
    "end": "1312600"
  },
  {
    "text": "worse which is what we observe um and it seems to be the case that you know larger uh um you really I I guess you",
    "start": "1312600",
    "end": "1319760"
  },
  {
    "text": "could argue this result may be a bit of an outlier I think I'll show you why on the next slide um but indeed higher",
    "start": "1319760",
    "end": "1328320"
  },
  {
    "text": "resolution does better so it's just something to be aware of you should test it for yourself uh but image resolution",
    "start": "1328320",
    "end": "1333360"
  },
  {
    "text": "does have an effect on performance as as you may expect now this is kind of an odd result and actually I hope it's kind",
    "start": "1333360",
    "end": "1339440"
  },
  {
    "text": "of a temporary issue that's resolved and maybe it's data by the time this video comes out I have noticed that gbd4 V",
    "start": "1339440",
    "end": "1345120"
  },
  {
    "text": "does have some kind of odd reliability issues you get 400 errors I link the ticket above I hope it's resolved soon",
    "start": "1345120",
    "end": "1351960"
  },
  {
    "text": "but I saw this quite a bit in my recent on my recent runs uh it did not seem correlated to resolution it seems uh",
    "start": "1351960",
    "end": "1358799"
  },
  {
    "text": "more or less random uh I think it's also skewed the prior results a bit because",
    "start": "1358799",
    "end": "1364159"
  },
  {
    "text": "the scoring um the correct scoring um may have been",
    "start": "1364159",
    "end": "1370799"
  },
  {
    "text": "affected by uh a number of the trials for a basically erroring app out and",
    "start": "1370799",
    "end": "1378520"
  },
  {
    "text": "failing to produce a correct or incorrect score so it injected some noise into the prior result",
    "start": "1378520",
    "end": "1383720"
  },
  {
    "text": "unfortunately um so anyway this just a caveat if you're think about using this in production I I hope it's fixed soon",
    "start": "1383720",
    "end": "1390120"
  },
  {
    "text": "you know I've Reach Out open AI about this and and so you know that's just something just something to flag and maybe again this is a kind of a",
    "start": "1390120",
    "end": "1395679"
  },
  {
    "text": "temporary issue and maybe it's moov by the time this video comes out I'd love for that to be the case I just wanted to flag",
    "start": "1395679",
    "end": "1401200"
  },
  {
    "text": "it um another thing I did uh kind of related task is I took just this one",
    "start": "1401200",
    "end": "1408039"
  },
  {
    "start": "1402000",
    "end": "1539000"
  },
  {
    "text": "slide and I tried kind of a small extraction challenge I asked eight questions about the slide and I tested a",
    "start": "1408039",
    "end": "1414640"
  },
  {
    "text": "number of different llms um and to see kind of how well I can extract",
    "start": "1414640",
    "end": "1420000"
  },
  {
    "text": "information from this one slide at variable resolutions you can see the results kind of match what we showed",
    "start": "1420000",
    "end": "1425039"
  },
  {
    "text": "before although there's one interesting addition here you'll note first resolution matters so of course low",
    "start": "1425039",
    "end": "1430720"
  },
  {
    "text": "resolution obviously quite bad performance very very good so gets you know all of them correct at 672 and",
    "start": "1430720",
    "end": "1438000"
  },
  {
    "text": "above for both Gemini and GPD 4V again differences between Gemini and gbd4 V",
    "start": "1438000",
    "end": "1443279"
  },
  {
    "text": "you know not really notable um both really good models now I also looked at",
    "start": "1443279",
    "end": "1449360"
  },
  {
    "text": "um Lava 13B because I'm really optimistic about using lava 13B for things like image",
    "start": "1449360",
    "end": "1455520"
  },
  {
    "text": "captioning because it's an expensive task what I did note is that it's not very good at extraction and I went back",
    "start": "1455520",
    "end": "1462760"
  },
  {
    "text": "and listened to some recent videos with the author of The of of the of the paper he mentions that a newer model with",
    "start": "1462760",
    "end": "1468720"
  },
  {
    "text": "better OCR capabilities is actually coming out soon I'm really eager to test that um I just wanted to kind of throw a",
    "start": "1468720",
    "end": "1474840"
  },
  {
    "text": "cave out there that lava from what I can tell is is not very strong um at kind of",
    "start": "1474840",
    "end": "1480880"
  },
  {
    "text": "extraction it kind of makes sense as not before it down samples to uh you know 336 pixels so kind of somewhere in this",
    "start": "1480880",
    "end": "1487600"
  },
  {
    "text": "range so it's downsampling quite a bit you can see even with these really good models if you down sample till 336",
    "start": "1487600",
    "end": "1493760"
  },
  {
    "text": "you're kind of in this bucket and you you've lost a lot of performance relative to higher resolution so that's issue one and then issue two um I I",
    "start": "1493760",
    "end": "1501360"
  },
  {
    "text": "guess lava just was not really trained for OCR extraction I've seen it being able to exract kind very obvious kind of",
    "start": "1501360",
    "end": "1508640"
  },
  {
    "text": "big text blobs but if you give it a slide like this it's really detailed lots of kind of you know jumbled up",
    "start": "1508640",
    "end": "1515640"
  },
  {
    "text": "content that it's possible that just the down sampling blurs this all together you really can't resolve these like very",
    "start": "1515640",
    "end": "1521320"
  },
  {
    "text": "fine scale details from the image so that's just another caveat for extraction test it doesn't seem like lava's quite there yet but I hope that",
    "start": "1521320",
    "end": "1527480"
  },
  {
    "text": "Chang soon I'm really optimistic I really want to use it for captioning um because that would save a lot of cost",
    "start": "1527480",
    "end": "1533440"
  },
  {
    "text": "and and it's a you know very good repetitive task at open source model would be really helpful for um now maybe just to round this out",
    "start": "1533440",
    "end": "1542440"
  },
  {
    "start": "1539000",
    "end": "1833000"
  },
  {
    "text": "like how can you get started try these things out for yourself we reled a bunch of different templates um now here's",
    "start": "1542440",
    "end": "1549200"
  },
  {
    "text": "kind of a fun one this is like really simple but um you know most people who have like you know iPhones or Android",
    "start": "1549200",
    "end": "1555399"
  },
  {
    "text": "devices kind of have used the visual search cap ility like you can search through your food pics or your you know",
    "start": "1555399",
    "end": "1561240"
  },
  {
    "text": "family piic or whatever it is ask a question you can find pictures related to that like ice cream and find all my",
    "start": "1561240",
    "end": "1566440"
  },
  {
    "text": "ice cream pictures like it's a nice you know clear functionality a lot of people use and like and what's kind of fun and",
    "start": "1566440",
    "end": "1572399"
  },
  {
    "text": "cool is that with these new multimodel LMS um that can run locally you can like",
    "start": "1572399",
    "end": "1577640"
  },
  {
    "text": "build this for yourself um now I understand this is probably a bit of a demo for now this is not like a",
    "start": "1577640",
    "end": "1583120"
  },
  {
    "text": "production application of course but it's interesting it's a really like in an important like starting point it's",
    "start": "1583120",
    "end": "1589279"
  },
  {
    "text": "cool you can R this locally for yourself and we're still very early in the in the Arc of these models developing and",
    "start": "1589279",
    "end": "1594399"
  },
  {
    "text": "getting better so this template which release basically let you take a set of images and embed them using open clip",
    "start": "1594399",
    "end": "1601679"
  },
  {
    "text": "and you can run this on your laptop I have a I have a Macbook uh Pro uh M2 32",
    "start": "1601679",
    "end": "1607760"
  },
  {
    "text": "gig Max and um this all works really well like I have bit of a you know more powerful laptop but but you know it",
    "start": "1607760",
    "end": "1614080"
  },
  {
    "text": "works on colleagues who have lower power laptops again using clip to embed these images store them in chroma locally you",
    "start": "1614080",
    "end": "1621399"
  },
  {
    "text": "can ask a question um and it will then pass uh retrieve the image pass it to in",
    "start": "1621399",
    "end": "1627000"
  },
  {
    "text": "this case uh it's actually using baklava which is um Lava plus minrol um which is pretty cool I use",
    "start": "1627000",
    "end": "1634080"
  },
  {
    "text": "olama to basically serve that model and um it can it can do um you know it can serve as a visual assistant it can",
    "start": "1634080",
    "end": "1640240"
  },
  {
    "text": "answer questions about the about the the images and so you know what kind of ice cream I tried oh you know it'll it'll",
    "start": "1640240",
    "end": "1645960"
  },
  {
    "text": "find this ice cream photo and say Sofer that's kind of cool um and it works with",
    "start": "1645960",
    "end": "1651480"
  },
  {
    "text": "both like multi muls and captioning so we talked about those two approaches previously and we have templats for both",
    "start": "1651480",
    "end": "1657200"
  },
  {
    "text": "so you can try both approaches um and again here here's actually like what it actually looks like so when you spin up",
    "start": "1657200",
    "end": "1663159"
  },
  {
    "text": "this templ it's like two or three commands to like create your own index and then one command to like spin it up",
    "start": "1663159",
    "end": "1669679"
  },
  {
    "text": "and it'll basically create it'll it'll basically spin up this little playground for you and you can ask questions you can just say hey like what kind of ice",
    "start": "1669679",
    "end": "1676120"
  },
  {
    "text": "cream do I have it gives you the answer like ITT the image and you know the beaut of these templates is you can play",
    "start": "1676120",
    "end": "1681360"
  },
  {
    "text": "with them yourself modify the promps it just get puts everything together lets you get started easily and this is",
    "start": "1681360",
    "end": "1686799"
  },
  {
    "text": "showing over here the lsmith trace which actually shows the retrieval of this",
    "start": "1686799",
    "end": "1692120"
  },
  {
    "text": "image of of my moner Sofer which I happen to like quite a bit it's very delicious and uh and it shows um you",
    "start": "1692120",
    "end": "1699799"
  },
  {
    "text": "know your your your H assistant give a description of the food pictures give a det time of the image it gives a summary",
    "start": "1699799",
    "end": "1705799"
  },
  {
    "text": "it image is a close of green frothy ice cream um and um yeah it looks like",
    "start": "1705799",
    "end": "1711480"
  },
  {
    "text": "matcha so you know that's pretty cool like it works it runs on your laptop it's it's like you know it's a really",
    "start": "1711480",
    "end": "1717080"
  },
  {
    "text": "fun demonstration you can play with it you can change the prompt you can change the model AMA makes it very easy to test different multi multim LMS and these",
    "start": "1717080",
    "end": "1724080"
  },
  {
    "text": "things are only going to get better so like it's it's a fun thing to to get started with um and this just like a",
    "start": "1724080",
    "end": "1730080"
  },
  {
    "text": "nice way to just have everything together in one piece and to spin it up very quickly um now maybe for applications",
    "start": "1730080",
    "end": "1738360"
  },
  {
    "text": "are a little bit more like you know maybe like commercially relevant or or like a little bit more complicated um we",
    "start": "1738360",
    "end": "1743919"
  },
  {
    "text": "have two different templates that use gbd4 V or Gemini for rag over slide",
    "start": "1743919",
    "end": "1749279"
  },
  {
    "text": "decks and this is like kind of nice to get started so you take a slide deck it",
    "start": "1749279",
    "end": "1754760"
  },
  {
    "text": "produces a bunch of images you embed those with open clip store them in chroma um and retrieve images related to",
    "start": "1754760",
    "end": "1761880"
  },
  {
    "text": "the question and send this to either uh you know either gemini or GP 4V and get",
    "start": "1761880",
    "end": "1768559"
  },
  {
    "text": "answer and this works quite well I mean I have to say I've been really impressed",
    "start": "1768559",
    "end": "1774279"
  },
  {
    "text": "uh this is your multi bets we talked about that before a little bit Limited in retrieval quality the captioning",
    "start": "1774279",
    "end": "1780159"
  },
  {
    "text": "approach though which I'll show here um you know effectively the same except for",
    "start": "1780159",
    "end": "1785279"
  },
  {
    "text": "just this you just this piece uh really does work quite well and so you know",
    "start": "1785279",
    "end": "1790799"
  },
  {
    "text": "this is actually showing an example of you know the answer you get from this question um so it's absolutely worth",
    "start": "1790799",
    "end": "1796399"
  },
  {
    "text": "trying and testing this template lets you get started really easily um and yeah this is like just kind of an",
    "start": "1796399",
    "end": "1802720"
  },
  {
    "text": "example showing you can retrieve the correct image um and reason about it and",
    "start": "1802720",
    "end": "1807880"
  },
  {
    "text": "um you know I I think these templates are a very nice way to just get started quickly um and they absolutely worth",
    "start": "1807880",
    "end": "1814840"
  },
  {
    "text": "trying so that's actually all I had for slides um just maybe hopefully this kind of a useful summary and overview of how",
    "start": "1814840",
    "end": "1820919"
  },
  {
    "text": "to get started with multimodal LMS the different LMS available to you numerous templates that you can use to to test",
    "start": "1820919",
    "end": "1828080"
  },
  {
    "text": "um and um I hope it I hope you find this useful um thank you",
    "start": "1828080",
    "end": "1835360"
  }
]
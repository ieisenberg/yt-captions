[
  {
    "text": "hi this is Lance from Lang chain this is",
    "start": "4520",
    "end": "6560"
  },
  {
    "text": "a talk I gave at two recent meetups in",
    "start": "6560",
    "end": "8400"
  },
  {
    "text": "San Francisco called is rag really dead",
    "start": "8400",
    "end": "11759"
  },
  {
    "text": "um and I figured since you know a lot of",
    "start": "11759",
    "end": "13559"
  },
  {
    "text": "people actually weren't able to make",
    "start": "13559",
    "end": "14839"
  },
  {
    "text": "those meetups I just record this and put",
    "start": "14839",
    "end": "17359"
  },
  {
    "text": "this on YouTube and and see if this is",
    "start": "17359",
    "end": "18840"
  },
  {
    "text": "of interest to folks um so we all kind",
    "start": "18840",
    "end": "22800"
  },
  {
    "text": "of recognize that context windows are",
    "start": "22800",
    "end": "24279"
  },
  {
    "text": "getting larger for llms so on the x-axis",
    "start": "24279",
    "end": "27199"
  },
  {
    "text": "you can see the tokens used in",
    "start": "27199",
    "end": "28880"
  },
  {
    "text": "pre-training that's of course you know",
    "start": "28880",
    "end": "30759"
  },
  {
    "text": "getting larger as well um proprietary",
    "start": "30759",
    "end": "33320"
  },
  {
    "text": "models are somewhere over the 2 trillion",
    "start": "33320",
    "end": "35760"
  },
  {
    "text": "token regime we don't quite know where",
    "start": "35760",
    "end": "37280"
  },
  {
    "text": "they sit uh and we've all the way down",
    "start": "37280",
    "end": "39440"
  },
  {
    "text": "to smaller models like 52 trained on far",
    "start": "39440",
    "end": "41520"
  },
  {
    "text": "fewer",
    "start": "41520",
    "end": "42360"
  },
  {
    "text": "tokens um but what's really notable is",
    "start": "42360",
    "end": "45600"
  },
  {
    "text": "on the y axis you can see about a year",
    "start": "45600",
    "end": "48360"
  },
  {
    "text": "ago state of the art models were on the",
    "start": "48360",
    "end": "50360"
  },
  {
    "text": "order of 4,000 to 8,000 tokens and",
    "start": "50360",
    "end": "52680"
  },
  {
    "text": "that's you know dozens of pages um we",
    "start": "52680",
    "end": "55559"
  },
  {
    "text": "saw Claud 2 come out with a 200,000",
    "start": "55559",
    "end": "58000"
  },
  {
    "text": "token model earlier I think it was last",
    "start": "58000",
    "end": "60640"
  },
  {
    "text": "year um gbd4 128,000 tokens now that's",
    "start": "60640",
    "end": "64720"
  },
  {
    "text": "hundreds of pages and now we're seeing",
    "start": "64720",
    "end": "66840"
  },
  {
    "text": "Claud 3 and Gemini come out with million",
    "start": "66840",
    "end": "69159"
  },
  {
    "text": "token models so this is hundreds to",
    "start": "69159",
    "end": "70720"
  },
  {
    "text": "thousands of pages so because of this",
    "start": "70720",
    "end": "74080"
  },
  {
    "text": "phenomenon people have been kind of",
    "start": "74080",
    "end": "75280"
  },
  {
    "text": "wondering is rag dead if you can stuff",
    "start": "75280",
    "end": "77960"
  },
  {
    "text": "you know many thousands of pages into",
    "start": "77960",
    "end": "79880"
  },
  {
    "text": "the Contex window open llm why do you",
    "start": "79880",
    "end": "82159"
  },
  {
    "text": "need a retrieval system um it's a good",
    "start": "82159",
    "end": "84960"
  },
  {
    "text": "question spoke sparked a lot of",
    "start": "84960",
    "end": "86400"
  },
  {
    "text": "interesting debate on Twitter um and",
    "start": "86400",
    "end": "89119"
  },
  {
    "text": "it's maybe first just kind of grounding",
    "start": "89119",
    "end": "90680"
  },
  {
    "text": "on what is rag so rag is really the",
    "start": "90680",
    "end": "92960"
  },
  {
    "text": "process of reasoning and retrieval over",
    "start": "92960",
    "end": "94960"
  },
  {
    "text": "chunks of of information that have been",
    "start": "94960",
    "end": "97119"
  },
  {
    "text": "retrieved um it's starting with you know",
    "start": "97119",
    "end": "99880"
  },
  {
    "text": "documents that are indexed um they're",
    "start": "99880",
    "end": "102840"
  },
  {
    "text": "retrievable through some mechanism",
    "start": "102840",
    "end": "104479"
  },
  {
    "text": "typically some kind of semantic sity",
    "start": "104479",
    "end": "106200"
  },
  {
    "text": "search or keyword search other",
    "start": "106200",
    "end": "107920"
  },
  {
    "text": "mechanisms retrieve doct then pass to an",
    "start": "107920",
    "end": "110399"
  },
  {
    "text": "llm and the llm reasons about them to",
    "start": "110399",
    "end": "112880"
  },
  {
    "text": "ground response to the question in the",
    "start": "112880",
    "end": "115079"
  },
  {
    "text": "retrieve document so that's kind of the",
    "start": "115079",
    "end": "116399"
  },
  {
    "text": "overall",
    "start": "116399",
    "end": "117240"
  },
  {
    "text": "flow but the important point to make is",
    "start": "117240",
    "end": "119479"
  },
  {
    "text": "that typically it's multile documents",
    "start": "119479",
    "end": "121640"
  },
  {
    "text": "and involve some form of",
    "start": "121640",
    "end": "123560"
  },
  {
    "text": "reasoning so one of the questions I",
    "start": "123560",
    "end": "125520"
  },
  {
    "text": "asked recently is you know if longc LMS",
    "start": "125520",
    "end": "128599"
  },
  {
    "text": "can replace rag it should be able to",
    "start": "128599",
    "end": "130360"
  },
  {
    "text": "perform you know multia retrieval and",
    "start": "130360",
    "end": "132800"
  },
  {
    "text": "reasoning from its own context really",
    "start": "132800",
    "end": "135000"
  },
  {
    "text": "effectively so I teamed up with Greg",
    "start": "135000",
    "end": "137040"
  },
  {
    "text": "Cameron uh to kind of pressure test this",
    "start": "137040",
    "end": "139959"
  },
  {
    "text": "and he had done some really nice needle",
    "start": "139959",
    "end": "141680"
  },
  {
    "text": "and the Haack analyses already focused",
    "start": "141680",
    "end": "143680"
  },
  {
    "text": "on kind of single facts called needles",
    "start": "143680",
    "end": "146879"
  },
  {
    "text": "placed in a Hy stack of Paul Graham",
    "start": "146879",
    "end": "149000"
  },
  {
    "text": "essays um so I kind of extended that to",
    "start": "149000",
    "end": "152040"
  },
  {
    "text": "kind of mirror the rag use case or kind",
    "start": "152040",
    "end": "154519"
  },
  {
    "text": "of the rag context uh where I took",
    "start": "154519",
    "end": "157360"
  },
  {
    "text": "multiple facts so I call it multi-",
    "start": "157360",
    "end": "159200"
  },
  {
    "text": "needle um I buil on a funny needle in",
    "start": "159200",
    "end": "162239"
  },
  {
    "text": "the HTO challenge published by anthropic",
    "start": "162239",
    "end": "164360"
  },
  {
    "text": "where they at they basically placed",
    "start": "164360",
    "end": "166239"
  },
  {
    "text": "Pizza ingredients in the context uh and",
    "start": "166239",
    "end": "168800"
  },
  {
    "text": "asked the LM to retrieve this",
    "start": "168800",
    "end": "170760"
  },
  {
    "text": "combination of pizza ingredients I did I",
    "start": "170760",
    "end": "173360"
  },
  {
    "text": "kind of Rift on that and I basically",
    "start": "173360",
    "end": "175200"
  },
  {
    "text": "split the pizza ingredients up into",
    "start": "175200",
    "end": "176760"
  },
  {
    "text": "three different needles and placed those",
    "start": "176760",
    "end": "179040"
  },
  {
    "text": "three ingredients different places in",
    "start": "179040",
    "end": "180560"
  },
  {
    "text": "the context and then ask the LM to",
    "start": "180560",
    "end": "183560"
  },
  {
    "text": "recover those three ingredients um from",
    "start": "183560",
    "end": "186319"
  },
  {
    "text": "the context so again the setup is the",
    "start": "186319",
    "end": "189159"
  },
  {
    "text": "question is whether the secret",
    "start": "189159",
    "end": "190200"
  },
  {
    "text": "ingredients need to build a perfect",
    "start": "190200",
    "end": "191519"
  },
  {
    "text": "Pizza the needles are the ingredients",
    "start": "191519",
    "end": "193799"
  },
  {
    "text": "figs Pudo goat cheese um I place them in",
    "start": "193799",
    "end": "197879"
  },
  {
    "text": "the context at some specified intervals",
    "start": "197879",
    "end": "200400"
  },
  {
    "text": "so the way this test works is you can",
    "start": "200400",
    "end": "202080"
  },
  {
    "text": "basically set the percent of context you",
    "start": "202080",
    "end": "204920"
  },
  {
    "text": "want to place the first needle and the",
    "start": "204920",
    "end": "207040"
  },
  {
    "text": "remaining two are placed at roughly",
    "start": "207040",
    "end": "208439"
  },
  {
    "text": "equal intervals in the remaining context",
    "start": "208439",
    "end": "210799"
  },
  {
    "text": "after the first so that's kind of the",
    "start": "210799",
    "end": "211959"
  },
  {
    "text": "way the test is set up now it's all open",
    "start": "211959",
    "end": "213599"
  },
  {
    "text": "source by the way the link is below so",
    "start": "213599",
    "end": "216200"
  },
  {
    "text": "needs are placed um you ask a question",
    "start": "216200",
    "end": "219280"
  },
  {
    "text": "you prompt LM with with kind of um with",
    "start": "219280",
    "end": "222360"
  },
  {
    "text": "this context in the question and then",
    "start": "222360",
    "end": "224200"
  },
  {
    "text": "produces the answer and now the the",
    "start": "224200",
    "end": "225959"
  },
  {
    "text": "framework will grade the response both",
    "start": "225959",
    "end": "229519"
  },
  {
    "text": "one are you know all are all the the",
    "start": "229519",
    "end": "232439"
  },
  {
    "text": "specified ingredients present in the",
    "start": "232439",
    "end": "234040"
  },
  {
    "text": "answer and two if not which ones are",
    "start": "234040",
    "end": "237920"
  },
  {
    "text": "missing so I ran analysis on this with",
    "start": "237920",
    "end": "240799"
  },
  {
    "text": "GPD 4 and came kind of came up with some",
    "start": "240799",
    "end": "242920"
  },
  {
    "text": "with some fun results um so you can see",
    "start": "242920",
    "end": "245200"
  },
  {
    "text": "on the left here what this is looking at",
    "start": "245200",
    "end": "247280"
  },
  {
    "text": "is different numbers of needles placed",
    "start": "247280",
    "end": "249680"
  },
  {
    "text": "in 120,000 token context window for GPD",
    "start": "249680",
    "end": "252799"
  },
  {
    "text": "4 and I'm asking um gbd4 to retrieve",
    "start": "252799",
    "end": "257680"
  },
  {
    "text": "either one three or 10 needles now I'm",
    "start": "257680",
    "end": "261600"
  },
  {
    "text": "also asking it to do reasoning on those",
    "start": "261600",
    "end": "263759"
  },
  {
    "text": "needles that's what you can see in those",
    "start": "263759",
    "end": "265320"
  },
  {
    "text": "red bars so green is just retrieved the",
    "start": "265320",
    "end": "267600"
  },
  {
    "text": "ingredients red is reasoning and the",
    "start": "267600",
    "end": "269759"
  },
  {
    "text": "reasoning challenge here is just return",
    "start": "269759",
    "end": "271440"
  },
  {
    "text": "the first letter of each ingredient so",
    "start": "271440",
    "end": "274080"
  },
  {
    "text": "we find is basically two things the",
    "start": "274080",
    "end": "277000"
  },
  {
    "text": "performance or the percentage of needles",
    "start": "277000",
    "end": "279240"
  },
  {
    "text": "retrieved drops with respect to the",
    "start": "279240",
    "end": "281560"
  },
  {
    "text": "number of needles that's kind of",
    "start": "281560",
    "end": "283039"
  },
  {
    "text": "intuitive you place more facts",
    "start": "283039",
    "end": "285199"
  },
  {
    "text": "performance gets worse but also it gets",
    "start": "285199",
    "end": "287759"
  },
  {
    "text": "worse if you ask it to reason so if you",
    "start": "287759",
    "end": "290320"
  },
  {
    "text": "say um just return the needles it does a",
    "start": "290320",
    "end": "293080"
  },
  {
    "text": "little bit better than if you say return",
    "start": "293080",
    "end": "295600"
  },
  {
    "text": "the needles and tell me the first letter",
    "start": "295600",
    "end": "298000"
  },
  {
    "text": "so you overlay reasoning so this is the",
    "start": "298000",
    "end": "299720"
  },
  {
    "text": "first observation morax is harder uh and",
    "start": "299720",
    "end": "303800"
  },
  {
    "text": "reasoning is harder uh than just",
    "start": "303800",
    "end": "306120"
  },
  {
    "text": "retrieval now the second question we ask",
    "start": "306120",
    "end": "308520"
  },
  {
    "text": "is where are these needles actually",
    "start": "308520",
    "end": "310080"
  },
  {
    "text": "present in the context that we're",
    "start": "310080",
    "end": "311720"
  },
  {
    "text": "missing right so we know for example um",
    "start": "311720",
    "end": "315680"
  },
  {
    "text": "retrieval of um 10 needles is around 60%",
    "start": "315680",
    "end": "320199"
  },
  {
    "text": "so where are the missing needles in the",
    "start": "320199",
    "end": "323280"
  },
  {
    "text": "context so on the right you can see",
    "start": "323280",
    "end": "325759"
  },
  {
    "text": "results telling us actually which",
    "start": "325759",
    "end": "327440"
  },
  {
    "text": "specific needles uh it our the model",
    "start": "327440",
    "end": "330800"
  },
  {
    "text": "fails to retrieve so we can see is as",
    "start": "330800",
    "end": "334000"
  },
  {
    "text": "you go from a th000 tokens up to 120,000",
    "start": "334000",
    "end": "337000"
  },
  {
    "text": "tokens on the X here and you look at",
    "start": "337000",
    "end": "339759"
  },
  {
    "text": "needle one placed at the start of the",
    "start": "339759",
    "end": "341600"
  },
  {
    "text": "document to needle 10 placed at the end",
    "start": "341600",
    "end": "344840"
  },
  {
    "text": "at a th000 token context link you can",
    "start": "344840",
    "end": "347120"
  },
  {
    "text": "retrieve them all so again kind of match",
    "start": "347120",
    "end": "349440"
  },
  {
    "text": "what we see over here small well",
    "start": "349440",
    "end": "352039"
  },
  {
    "text": "actually sorry over here everything I'm",
    "start": "352039",
    "end": "353840"
  },
  {
    "text": "looking at 120,000 tokens so that's",
    "start": "353840",
    "end": "356400"
  },
  {
    "text": "really not the point uh the point is",
    "start": "356400",
    "end": "358560"
  },
  {
    "text": "actually smaller context uh better",
    "start": "358560",
    "end": "361360"
  },
  {
    "text": "retrieval so that's kind of point one um",
    "start": "361360",
    "end": "365560"
  },
  {
    "text": "as I increase the context window I",
    "start": "365560",
    "end": "367960"
  },
  {
    "text": "actually see that uh there is increased",
    "start": "367960",
    "end": "371160"
  },
  {
    "text": "failure to retrieve needles which you",
    "start": "371160",
    "end": "372840"
  },
  {
    "text": "see can see in red here towards the",
    "start": "372840",
    "end": "375160"
  },
  {
    "text": "start of the",
    "start": "375160",
    "end": "376400"
  },
  {
    "text": "document um and so this is an",
    "start": "376400",
    "end": "378680"
  },
  {
    "text": "interesting result um and it actually",
    "start": "378680",
    "end": "380800"
  },
  {
    "text": "matches what Greg saw with single needle",
    "start": "380800",
    "end": "382639"
  },
  {
    "text": "case as well so the way to think about",
    "start": "382639",
    "end": "384599"
  },
  {
    "text": "it is it appears that um you know if you",
    "start": "384599",
    "end": "388319"
  },
  {
    "text": "for example read a book and I asked you",
    "start": "388319",
    "end": "390319"
  },
  {
    "text": "a question about the first chapter you",
    "start": "390319",
    "end": "391840"
  },
  {
    "text": "might have forgotten it same kind of",
    "start": "391840",
    "end": "393840"
  },
  {
    "text": "phenomenon appears to happen here with",
    "start": "393840",
    "end": "395680"
  },
  {
    "text": "retrieval where needles towards the",
    "start": "395680",
    "end": "397560"
  },
  {
    "text": "start of the context are are kind of",
    "start": "397560",
    "end": "399840"
  },
  {
    "text": "Forgotten or are not well retrieved",
    "start": "399840",
    "end": "402680"
  },
  {
    "text": "relative to those of the end so this is",
    "start": "402680",
    "end": "404199"
  },
  {
    "text": "an effect we see with gbd4 it's been",
    "start": "404199",
    "end": "406520"
  },
  {
    "text": "reproduced quite a bit so I ran nine",
    "start": "406520",
    "end": "408720"
  },
  {
    "text": "different trials here Greg's also seen",
    "start": "408720",
    "end": "410639"
  },
  {
    "text": "this repeatedly with single needle so it",
    "start": "410639",
    "end": "412520"
  },
  {
    "text": "seems like a pretty consistent",
    "start": "412520",
    "end": "414319"
  },
  {
    "text": "result and there's an interesting point",
    "start": "414319",
    "end": "416240"
  },
  {
    "text": "I put this on Twitter and a number of",
    "start": "416240",
    "end": "417879"
  },
  {
    "text": "folks um you know replied and someone",
    "start": "417879",
    "end": "420720"
  },
  {
    "text": "sent me this paper which is pretty",
    "start": "420720",
    "end": "421879"
  },
  {
    "text": "interesting and it mentions recency bias",
    "start": "421879",
    "end": "424199"
  },
  {
    "text": "is one possible reason so the most",
    "start": "424199",
    "end": "426280"
  },
  {
    "text": "informative tokens for predicting the",
    "start": "426280",
    "end": "427960"
  },
  {
    "text": "next token uh you know are are are",
    "start": "427960",
    "end": "431160"
  },
  {
    "text": "present close to or recent to kind of",
    "start": "431160",
    "end": "434199"
  },
  {
    "text": "where you're doing your generation and",
    "start": "434199",
    "end": "435479"
  },
  {
    "text": "so there's a bias to attend to recent",
    "start": "435479",
    "end": "437879"
  },
  {
    "text": "tokens which is obviously not great for",
    "start": "437879",
    "end": "440720"
  },
  {
    "text": "the retrieval problem as we saw here so",
    "start": "440720",
    "end": "443199"
  },
  {
    "text": "again the results show us that um",
    "start": "443199",
    "end": "447520"
  },
  {
    "text": "reasoning is a bit harder than retrieval",
    "start": "447520",
    "end": "449800"
  },
  {
    "text": "more needles is more difficult and",
    "start": "449800",
    "end": "451919"
  },
  {
    "text": "needles towards the start of your",
    "start": "451919",
    "end": "453599"
  },
  {
    "text": "context are harder to retrieve than",
    "start": "453599",
    "end": "455240"
  },
  {
    "text": "towards the end those are three main",
    "start": "455240",
    "end": "457080"
  },
  {
    "text": "observations from this and it may be",
    "start": "457080",
    "end": "459639"
  },
  {
    "text": "indeed due to this recency bias so",
    "start": "459639",
    "end": "462120"
  },
  {
    "text": "overall what this kind of tells you is",
    "start": "462120",
    "end": "464280"
  },
  {
    "text": "be wary of just context stuffing in",
    "start": "464280",
    "end": "466520"
  },
  {
    "text": "large long context LMS there are no",
    "start": "466520",
    "end": "468879"
  },
  {
    "text": "retrieval",
    "start": "468879",
    "end": "469879"
  },
  {
    "text": "guarantees and also there's some recent",
    "start": "469879",
    "end": "472080"
  },
  {
    "text": "results that came out actually just",
    "start": "472080",
    "end": "473240"
  },
  {
    "text": "today suggesting that single needle may",
    "start": "473240",
    "end": "475599"
  },
  {
    "text": "be misleadingly easy um you know there's",
    "start": "475599",
    "end": "479039"
  },
  {
    "text": "no reason",
    "start": "479039",
    "end": "480639"
  },
  {
    "text": "it's retrieving a single needle um and",
    "start": "480639",
    "end": "483639"
  },
  {
    "text": "also these guys I'm I show this tweet",
    "start": "483639",
    "end": "486360"
  },
  {
    "text": "here showed that um the in a lot of",
    "start": "486360",
    "end": "489960"
  },
  {
    "text": "these needle and Haack challenges",
    "start": "489960",
    "end": "491520"
  },
  {
    "text": "including mine the facts that we look",
    "start": "491520",
    "end": "493879"
  },
  {
    "text": "for are very different than um the",
    "start": "493879",
    "end": "497319"
  },
  {
    "text": "background kind of Hy stack of Paul",
    "start": "497319",
    "end": "499039"
  },
  {
    "text": "Graham essays and so that may be kind of",
    "start": "499039",
    "end": "500840"
  },
  {
    "text": "an interesting artifact they note that",
    "start": "500840",
    "end": "503000"
  },
  {
    "text": "indeed if the needle is more subtle",
    "start": "503000",
    "end": "505199"
  },
  {
    "text": "retrieval is worse so I think basically",
    "start": "505199",
    "end": "508599"
  },
  {
    "text": "when you see really strong performing",
    "start": "508599",
    "end": "510840"
  },
  {
    "text": "needle and hyack analyses put up by",
    "start": "510840",
    "end": "512399"
  },
  {
    "text": "model providers you should be skeptical",
    "start": "512399",
    "end": "515680"
  },
  {
    "text": "um you shouldn't necessarily assume that",
    "start": "515680",
    "end": "517159"
  },
  {
    "text": "you're going to get high quality",
    "start": "517159",
    "end": "518120"
  },
  {
    "text": "retrieval from these long contact LMS uh",
    "start": "518120",
    "end": "520560"
  },
  {
    "text": "for numerous reasons you need to think",
    "start": "520560",
    "end": "522599"
  },
  {
    "text": "about retrieval of multiple facts um you",
    "start": "522599",
    "end": "525160"
  },
  {
    "text": "need to think about reasoning on top of",
    "start": "525160",
    "end": "526839"
  },
  {
    "text": "retrieval you need to think about the",
    "start": "526839",
    "end": "528839"
  },
  {
    "text": "subtlety of the retrieval relative to",
    "start": "528839",
    "end": "530839"
  },
  {
    "text": "the background context because for many",
    "start": "530839",
    "end": "533000"
  },
  {
    "text": "of these needle and the hyack challenges",
    "start": "533000",
    "end": "534560"
  },
  {
    "text": "it's a single needle no reasoning and",
    "start": "534560",
    "end": "536920"
  },
  {
    "text": "the needle itself is very different from",
    "start": "536920",
    "end": "538440"
  },
  {
    "text": "the background so anyway those may all",
    "start": "538440",
    "end": "540600"
  },
  {
    "text": "make the challenge a bit easier than a",
    "start": "540600",
    "end": "542839"
  },
  {
    "text": "real world scenario of fact retrieval so",
    "start": "542839",
    "end": "544920"
  },
  {
    "text": "I just want to like kind of lay out that",
    "start": "544920",
    "end": "546760"
  },
  {
    "text": "those cautionary notes but you know I",
    "start": "546760",
    "end": "550240"
  },
  {
    "text": "think it is fair to say this will",
    "start": "550240",
    "end": "551959"
  },
  {
    "text": "certainly get better and I think it's",
    "start": "551959",
    "end": "554120"
  },
  {
    "text": "also fair to say that rag will change",
    "start": "554120",
    "end": "556839"
  },
  {
    "text": "and this is just like a nearly not a",
    "start": "556839",
    "end": "558839"
  },
  {
    "text": "great joke but Frank zap a musician made",
    "start": "558839",
    "end": "561160"
  },
  {
    "text": "the point Jazz isn't dead it just smells",
    "start": "561160",
    "end": "563200"
  },
  {
    "text": "funny you know I think same for rag rag",
    "start": "563200",
    "end": "565240"
  },
  {
    "text": "is not dead but it will change I think",
    "start": "565240",
    "end": "567399"
  },
  {
    "text": "that's like kind of the key Point here",
    "start": "567399",
    "end": "569720"
  },
  {
    "text": "um so just as a followup on that rag",
    "start": "569720",
    "end": "572640"
  },
  {
    "text": "today is focus on precise retrieval of",
    "start": "572640",
    "end": "574720"
  },
  {
    "text": "relevant doc chunks so it's very focused",
    "start": "574720",
    "end": "576680"
  },
  {
    "text": "on typically taking documents chunking",
    "start": "576680",
    "end": "579240"
  },
  {
    "text": "them in some particular way often using",
    "start": "579240",
    "end": "581160"
  },
  {
    "text": "very idiosyncratic chunking methods",
    "start": "581160",
    "end": "583360"
  },
  {
    "text": "things like chunk size are kind of",
    "start": "583360",
    "end": "585079"
  },
  {
    "text": "picked almost arbitrarily embedding them",
    "start": "585079",
    "end": "587959"
  },
  {
    "text": "storing them in an index taking a",
    "start": "587959",
    "end": "590040"
  },
  {
    "text": "question embedding it doing KNN uh",
    "start": "590040",
    "end": "592720"
  },
  {
    "text": "similarity search to retrieve relevant",
    "start": "592720",
    "end": "594440"
  },
  {
    "text": "chunks you're often setting a k",
    "start": "594440",
    "end": "596320"
  },
  {
    "text": "parameter which is the number of chunks",
    "start": "596320",
    "end": "597720"
  },
  {
    "text": "you retrieve you often will do some kind",
    "start": "597720",
    "end": "599959"
  },
  {
    "text": "of filtering or Pro processing on the",
    "start": "599959",
    "end": "601600"
  },
  {
    "text": "retriev chunks and then ground your",
    "start": "601600",
    "end": "604040"
  },
  {
    "text": "answer in those retrieve chunks so it's",
    "start": "604040",
    "end": "605839"
  },
  {
    "text": "very focused on precise retrieval of",
    "start": "605839",
    "end": "607839"
  },
  {
    "text": "just the right chunks now in a world",
    "start": "607839",
    "end": "611360"
  },
  {
    "text": "where you have very long context models",
    "start": "611360",
    "end": "613399"
  },
  {
    "text": "I think there's the a fair question to",
    "start": "613399",
    "end": "615160"
  },
  {
    "text": "ask is is this really kind of the most",
    "start": "615160",
    "end": "617720"
  },
  {
    "text": "reasonable approach so kind of on the",
    "start": "617720",
    "end": "620000"
  },
  {
    "text": "left here you can kind of see this",
    "start": "620000",
    "end": "622079"
  },
  {
    "text": "notion closer to today of I need the",
    "start": "622079",
    "end": "624480"
  },
  {
    "text": "exact relevant chunk you can risk over",
    "start": "624480",
    "end": "626640"
  },
  {
    "text": "engineering you can have you know higher",
    "start": "626640",
    "end": "628720"
  },
  {
    "text": "complexity sensitivity to these odd",
    "start": "628720",
    "end": "631079"
  },
  {
    "text": "parameters like chunk size k um and you",
    "start": "631079",
    "end": "633760"
  },
  {
    "text": "can indeed suffer lower recall because",
    "start": "633760",
    "end": "635440"
  },
  {
    "text": "you're really only picking very precise",
    "start": "635440",
    "end": "637360"
  },
  {
    "text": "chunks you're beholden to very",
    "start": "637360",
    "end": "638959"
  },
  {
    "text": "particular embedding models so you know",
    "start": "638959",
    "end": "641560"
  },
  {
    "text": "I think going forward as long contact",
    "start": "641560",
    "end": "643800"
  },
  {
    "text": "models get better and better there are",
    "start": "643800",
    "end": "645959"
  },
  {
    "text": "definitely question you should certainly",
    "start": "645959",
    "end": "647680"
  },
  {
    "text": "question the current kind of very",
    "start": "647680",
    "end": "649480"
  },
  {
    "text": "precise chunking rag Paradigm but on the",
    "start": "649480",
    "end": "651880"
  },
  {
    "text": "flip side I think just throwing all your",
    "start": "651880",
    "end": "654000"
  },
  {
    "text": "docks into context probably will also",
    "start": "654000",
    "end": "656000"
  },
  {
    "text": "not be the preferred approach you'll",
    "start": "656000",
    "end": "658079"
  },
  {
    "text": "suffer higher latency higher token usage",
    "start": "658079",
    "end": "660839"
  },
  {
    "text": "I should note that today 100,000 token",
    "start": "660839",
    "end": "662920"
  },
  {
    "text": "GPD 4 is like $1 per generation I spent",
    "start": "662920",
    "end": "666000"
  },
  {
    "text": "a lot of money on Lang Chain's account",
    "start": "666000",
    "end": "668720"
  },
  {
    "text": "uh on that multi needle analysis I don't",
    "start": "668720",
    "end": "670519"
  },
  {
    "text": "want to tell Harrison how much I spent",
    "start": "670519",
    "end": "672920"
  },
  {
    "text": "uh so it's it's you know it's not good",
    "start": "672920",
    "end": "675120"
  },
  {
    "text": "right um You Can't audit retrieval um",
    "start": "675120",
    "end": "678519"
  },
  {
    "text": "and security and and authentication are",
    "start": "678519",
    "end": "680360"
  },
  {
    "text": "issues if for example you need different",
    "start": "680360",
    "end": "682519"
  },
  {
    "text": "users different different access to",
    "start": "682519",
    "end": "684079"
  },
  {
    "text": "certain kind of retriev documents or",
    "start": "684079",
    "end": "685839"
  },
  {
    "text": "chunks in the Contex stuffing case you",
    "start": "685839",
    "end": "688600"
  },
  {
    "text": "you kind of can't security as easily so",
    "start": "688600",
    "end": "690800"
  },
  {
    "text": "there's probably some predo optimal",
    "start": "690800",
    "end": "692399"
  },
  {
    "text": "regime kind of here in the middle and um",
    "start": "692399",
    "end": "696240"
  },
  {
    "text": "you know I I put this out on Twitter I",
    "start": "696240",
    "end": "697720"
  },
  {
    "text": "think there's some reasonable points",
    "start": "697720",
    "end": "698959"
  },
  {
    "text": "raised I think you know this inclusion",
    "start": "698959",
    "end": "701200"
  },
  {
    "text": "at the document level is probably pretty",
    "start": "701200",
    "end": "702800"
  },
  {
    "text": "sane documents are self-contained chunks",
    "start": "702800",
    "end": "705200"
  },
  {
    "text": "of context um so you know what about",
    "start": "705200",
    "end": "708800"
  },
  {
    "text": "document Centric rag so no chunking uh",
    "start": "708800",
    "end": "711480"
  },
  {
    "text": "but just like operate on the context of",
    "start": "711480",
    "end": "713279"
  },
  {
    "text": "full documents so you know if you think",
    "start": "713279",
    "end": "716639"
  },
  {
    "text": "forward to the rag Paradigm that's",
    "start": "716639",
    "end": "718240"
  },
  {
    "text": "document Centric you still have the",
    "start": "718240",
    "end": "720440"
  },
  {
    "text": "problem of taking an input question",
    "start": "720440",
    "end": "722120"
  },
  {
    "text": "routing it to the right document um this",
    "start": "722120",
    "end": "724800"
  },
  {
    "text": "doesn't change so I think a lot of",
    "start": "724800",
    "end": "726839"
  },
  {
    "text": "methods that we think about for kind of",
    "start": "726839",
    "end": "728480"
  },
  {
    "text": "query analysis um taking an input",
    "start": "728480",
    "end": "731440"
  },
  {
    "text": "question rewriting it in a certain way",
    "start": "731440",
    "end": "733880"
  },
  {
    "text": "to optimize retrieval things like",
    "start": "733880",
    "end": "735839"
  },
  {
    "text": "routing taking a question routing it to",
    "start": "735839",
    "end": "737880"
  },
  {
    "text": "the right database be it a relational",
    "start": "737880",
    "end": "739839"
  },
  {
    "text": "database graph database Vector store um",
    "start": "739839",
    "end": "742839"
  },
  {
    "text": "and quer construction methods so for",
    "start": "742839",
    "end": "744800"
  },
  {
    "text": "example text to SQL text to Cipher for",
    "start": "744800",
    "end": "747199"
  },
  {
    "text": "graphs um or text to even like metadata",
    "start": "747199",
    "end": "750000"
  },
  {
    "text": "filters for for Vector stores those are",
    "start": "750000",
    "end": "752680"
  },
  {
    "text": "all still relevant in the world that you",
    "start": "752680",
    "end": "754440"
  },
  {
    "text": "have long Contex llms um you're probably",
    "start": "754440",
    "end": "757440"
  },
  {
    "text": "not going to dump your entire SQL DB and",
    "start": "757440",
    "end": "759560"
  },
  {
    "text": "feed that to the llm you're still going",
    "start": "759560",
    "end": "761000"
  },
  {
    "text": "to have SQL queries you're still going",
    "start": "761000",
    "end": "762480"
  },
  {
    "text": "to have graph queries um you may be more",
    "start": "762480",
    "end": "765240"
  },
  {
    "text": "permissive with what you extract but it",
    "start": "765240",
    "end": "767839"
  },
  {
    "text": "still is very reasonable to store the",
    "start": "767839",
    "end": "769440"
  },
  {
    "text": "majority of your structured data in",
    "start": "769440",
    "end": "770839"
  },
  {
    "text": "these in these forms likewise with",
    "start": "770839",
    "end": "773040"
  },
  {
    "text": "unstructured data like documents like we",
    "start": "773040",
    "end": "775480"
  },
  {
    "text": "said before it still probably makes",
    "start": "775480",
    "end": "777279"
  },
  {
    "text": "sense to en to you know store",
    "start": "777279",
    "end": "779440"
  },
  {
    "text": "independently but just simply aim to",
    "start": "779440",
    "end": "781240"
  },
  {
    "text": "retrieve full documents rather than",
    "start": "781240",
    "end": "782800"
  },
  {
    "text": "worrying about these OS syncratic",
    "start": "782800",
    "end": "784199"
  },
  {
    "text": "parameters like like chunk size um and",
    "start": "784199",
    "end": "787800"
  },
  {
    "text": "along those lines there's a lot of",
    "start": "787800",
    "end": "789600"
  },
  {
    "text": "methods out there we've we've done a few",
    "start": "789600",
    "end": "791360"
  },
  {
    "text": "of these that are kind of well optimized",
    "start": "791360",
    "end": "793120"
  },
  {
    "text": "for document retrieval so one I want a",
    "start": "793120",
    "end": "795839"
  },
  {
    "text": "flag is what we call",
    "start": "795839",
    "end": "796839"
  },
  {
    "text": "multi-representation indexing and",
    "start": "796839",
    "end": "798760"
  },
  {
    "text": "there's actually a really nice paper on",
    "start": "798760",
    "end": "800079"
  },
  {
    "text": "this called dense X retriever or",
    "start": "800079",
    "end": "801800"
  },
  {
    "text": "proposition indexing but the main point",
    "start": "801800",
    "end": "803839"
  },
  {
    "text": "is simply this what you do is you take",
    "start": "803839",
    "end": "806079"
  },
  {
    "text": "your OD document you produce a",
    "start": "806079",
    "end": "807680"
  },
  {
    "text": "representation like a summary of that",
    "start": "807680",
    "end": "809480"
  },
  {
    "text": "document you index that summary right",
    "start": "809480",
    "end": "812880"
  },
  {
    "text": "and then um at retrieval time you ask",
    "start": "812880",
    "end": "815760"
  },
  {
    "text": "your question you embed your question",
    "start": "815760",
    "end": "817560"
  },
  {
    "text": "and you simply use a highle summary to",
    "start": "817560",
    "end": "820000"
  },
  {
    "text": "just retrieve the right document you",
    "start": "820000",
    "end": "821839"
  },
  {
    "text": "pass the full document to the LM for uh",
    "start": "821839",
    "end": "824880"
  },
  {
    "text": "kind of final generation so it's kind of",
    "start": "824880",
    "end": "827199"
  },
  {
    "text": "a nice trick where you don't have to",
    "start": "827199",
    "end": "829000"
  },
  {
    "text": "worry about embedding full documents in",
    "start": "829000",
    "end": "830680"
  },
  {
    "text": "this particular case you can use kind of",
    "start": "830680",
    "end": "833320"
  },
  {
    "text": "very nice descriptive summarization",
    "start": "833320",
    "end": "835279"
  },
  {
    "text": "prompts to build descriptive summaries",
    "start": "835279",
    "end": "837480"
  },
  {
    "text": "and the problem you're solving here is",
    "start": "837480",
    "end": "839120"
  },
  {
    "text": "just get me the right document it's an",
    "start": "839120",
    "end": "840680"
  },
  {
    "text": "easier problem than get me the right",
    "start": "840680",
    "end": "842480"
  },
  {
    "text": "chunk so this is kind of a nice approach",
    "start": "842480",
    "end": "845680"
  },
  {
    "text": "it there's also different variants of it",
    "start": "845680",
    "end": "847360"
  },
  {
    "text": "which I share below one is called parent",
    "start": "847360",
    "end": "848920"
  },
  {
    "text": "document retriever where you could use",
    "start": "848920",
    "end": "850680"
  },
  {
    "text": "in principle if you wanted smaller",
    "start": "850680",
    "end": "852759"
  },
  {
    "text": "chunks but then just return full",
    "start": "852759",
    "end": "854120"
  },
  {
    "text": "documents but anyway the point is",
    "start": "854120",
    "end": "856240"
  },
  {
    "text": "preserving full documents for Generation",
    "start": "856240",
    "end": "858639"
  },
  {
    "text": "but using representations like summaries",
    "start": "858639",
    "end": "860800"
  },
  {
    "text": "or chunks for retrieval so that's kind",
    "start": "860800",
    "end": "862600"
  },
  {
    "text": "of like approach one that I think is",
    "start": "862600",
    "end": "864600"
  },
  {
    "text": "really interesting approach two is this",
    "start": "864600",
    "end": "867199"
  },
  {
    "text": "idea of raptor is a cool paper came out",
    "start": "867199",
    "end": "869880"
  },
  {
    "text": "of Stanford somewhere recently and this",
    "start": "869880",
    "end": "872040"
  },
  {
    "text": "solves the problem of what if for",
    "start": "872040",
    "end": "873600"
  },
  {
    "text": "certain questions I need to integrate",
    "start": "873600",
    "end": "875079"
  },
  {
    "text": "information across many documents so",
    "start": "875079",
    "end": "878079"
  },
  {
    "text": "what this approach does is it takes",
    "start": "878079",
    "end": "879639"
  },
  {
    "text": "documents and it it embeds them and",
    "start": "879639",
    "end": "882440"
  },
  {
    "text": "clusters them and then it summarizes",
    "start": "882440",
    "end": "884120"
  },
  {
    "text": "each cluster um and it does this",
    "start": "884120",
    "end": "886320"
  },
  {
    "text": "recursively until end up with only one",
    "start": "886320",
    "end": "888519"
  },
  {
    "text": "very high level summary for the entire",
    "start": "888519",
    "end": "890399"
  },
  {
    "text": "Corpus of documents and what they do is",
    "start": "890399",
    "end": "892639"
  },
  {
    "text": "they take this kind of this abstraction",
    "start": "892639",
    "end": "894759"
  },
  {
    "text": "hierarchy so to speak of different",
    "start": "894759",
    "end": "896440"
  },
  {
    "text": "document summarizations and they just",
    "start": "896440",
    "end": "898399"
  },
  {
    "text": "index all of it and they use this in",
    "start": "898399",
    "end": "901040"
  },
  {
    "text": "retrieval and so basically if you have a",
    "start": "901040",
    "end": "902920"
  },
  {
    "text": "question that draws an information",
    "start": "902920",
    "end": "904399"
  },
  {
    "text": "across numerous documents you probably",
    "start": "904399",
    "end": "906680"
  },
  {
    "text": "have a summary present and and indexed",
    "start": "906680",
    "end": "909800"
  },
  {
    "text": "that kind of has that answer captured so",
    "start": "909800",
    "end": "912160"
  },
  {
    "text": "it's a nice trick to consolidate",
    "start": "912160",
    "end": "914079"
  },
  {
    "text": "information across documents um they",
    "start": "914079",
    "end": "916920"
  },
  {
    "text": "there a paper actually reports you know",
    "start": "916920",
    "end": "919519"
  },
  {
    "text": "these documents in their case or the",
    "start": "919519",
    "end": "920880"
  },
  {
    "text": "leafes are actually document chunks or",
    "start": "920880",
    "end": "922800"
  },
  {
    "text": "slic but I actually showed I have a",
    "start": "922800",
    "end": "925399"
  },
  {
    "text": "video on it in a notebook that this",
    "start": "925399",
    "end": "926920"
  },
  {
    "text": "works across full documents as well um",
    "start": "926920",
    "end": "930160"
  },
  {
    "text": "and that's a nice segue into to do this",
    "start": "930160",
    "end": "932959"
  },
  {
    "text": "you do need to think about long context",
    "start": "932959",
    "end": "934399"
  },
  {
    "text": "embedding models because you're",
    "start": "934399",
    "end": "935440"
  },
  {
    "text": "embedding full documents and that's a",
    "start": "935440",
    "end": "937399"
  },
  {
    "text": "really interesting thing to track um the",
    "start": "937399",
    "end": "940480"
  },
  {
    "text": "you know hazy research uh put out a",
    "start": "940480",
    "end": "942519"
  },
  {
    "text": "really nice um uh blog post on this",
    "start": "942519",
    "end": "945519"
  },
  {
    "text": "using uh with the Monarch mixer so it's",
    "start": "945519",
    "end": "947800"
  },
  {
    "text": "kind of a new architecture that tends to",
    "start": "947800",
    "end": "950360"
  },
  {
    "text": "longer context they have a 32,000 token",
    "start": "950360",
    "end": "953399"
  },
  {
    "text": "embedding model that's pres that's",
    "start": "953399",
    "end": "955160"
  },
  {
    "text": "available on together AI absolutely",
    "start": "955160",
    "end": "957040"
  },
  {
    "text": "worth experimenting with I think this is",
    "start": "957040",
    "end": "958399"
  },
  {
    "text": "really interesting Trend so long long",
    "start": "958399",
    "end": "960959"
  },
  {
    "text": "Contex embeddings kind of play really",
    "start": "960959",
    "end": "962519"
  },
  {
    "text": "well with this kind of idea you take",
    "start": "962519",
    "end": "964680"
  },
  {
    "text": "full documents embed them using for",
    "start": "964680",
    "end": "966800"
  },
  {
    "text": "example long contct edting models and",
    "start": "966800",
    "end": "968720"
  },
  {
    "text": "you can kind of build these document",
    "start": "968720",
    "end": "969880"
  },
  {
    "text": "summarization trees um really",
    "start": "969880",
    "end": "972000"
  },
  {
    "text": "effectively so I think this another nice",
    "start": "972000",
    "end": "973680"
  },
  {
    "text": "trick for working with full documents in",
    "start": "973680",
    "end": "976720"
  },
  {
    "text": "the long context kind of llm regime um",
    "start": "976720",
    "end": "980959"
  },
  {
    "text": "one other thing I'll note I think",
    "start": "980959",
    "end": "982279"
  },
  {
    "text": "there's also going to Mo be move away",
    "start": "982279",
    "end": "984639"
  },
  {
    "text": "from kind of single shot rag well",
    "start": "984639",
    "end": "986519"
  },
  {
    "text": "today's rag we typically you know we",
    "start": "986519",
    "end": "988279"
  },
  {
    "text": "chunk do doents uh uh embed them store",
    "start": "988279",
    "end": "991399"
  },
  {
    "text": "them in an index you know do retrieval",
    "start": "991399",
    "end": "993680"
  },
  {
    "text": "and then do generation but there's no",
    "start": "993680",
    "end": "995440"
  },
  {
    "text": "reason why you shouldn't kind of do",
    "start": "995440",
    "end": "997600"
  },
  {
    "text": "reasoning on top of the generation or",
    "start": "997600",
    "end": "999720"
  },
  {
    "text": "reasoning on top of the retrieval and",
    "start": "999720",
    "end": "1001440"
  },
  {
    "text": "feed back if there are errors so there's",
    "start": "1001440",
    "end": "1003639"
  },
  {
    "text": "a really nice paper called selfrag um",
    "start": "1003639",
    "end": "1006240"
  },
  {
    "text": "that kind of reports this we implemented",
    "start": "1006240",
    "end": "1008000"
  },
  {
    "text": "this using Lang graph works really well",
    "start": "1008000",
    "end": "1010639"
  },
  {
    "text": "and the simp the idea is simply to you",
    "start": "1010639",
    "end": "1013000"
  },
  {
    "text": "know grade the relevance of your",
    "start": "1013000",
    "end": "1014240"
  },
  {
    "text": "documents relative to your question",
    "start": "1014240",
    "end": "1016160"
  },
  {
    "text": "first if they're not relevant you",
    "start": "1016160",
    "end": "1018079"
  },
  {
    "text": "rewrite the question you can do you can",
    "start": "1018079",
    "end": "1019839"
  },
  {
    "text": "do many things in this case we do",
    "start": "1019839",
    "end": "1021199"
  },
  {
    "text": "question rewriting and try again um we",
    "start": "1021199",
    "end": "1023880"
  },
  {
    "text": "also grade for hallucinations we grade",
    "start": "1023880",
    "end": "1026120"
  },
  {
    "text": "for answer relevance but anyway it kind",
    "start": "1026120",
    "end": "1028319"
  },
  {
    "text": "of moves rag from a single shot Paradigm",
    "start": "1028319",
    "end": "1030438"
  },
  {
    "text": "to a kind of a cyclic flow uh in which",
    "start": "1030439",
    "end": "1033760"
  },
  {
    "text": "you actually do various gradings",
    "start": "1033760",
    "end": "1035438"
  },
  {
    "text": "Downstream and this is all relevant in",
    "start": "1035439",
    "end": "1037438"
  },
  {
    "text": "the long context llm regime as well in",
    "start": "1037439",
    "end": "1040079"
  },
  {
    "text": "fact you know it you you absolutely",
    "start": "1040079",
    "end": "1042400"
  },
  {
    "text": "should take advantage of of for example",
    "start": "1042400",
    "end": "1045480"
  },
  {
    "text": "increasingly fast and performant LMS to",
    "start": "1045480",
    "end": "1048199"
  },
  {
    "text": "do these great",
    "start": "1048199",
    "end": "1049919"
  },
  {
    "text": "um Frameworks like lra allow you to",
    "start": "1049919",
    "end": "1052280"
  },
  {
    "text": "build these kind of these flows which",
    "start": "1052280",
    "end": "1054280"
  },
  {
    "text": "build which allows you to kind of have a",
    "start": "1054280",
    "end": "1056080"
  },
  {
    "text": "more performant uh kind of kind of",
    "start": "1056080",
    "end": "1059320"
  },
  {
    "text": "self-reflective rag pipeline now I did",
    "start": "1059320",
    "end": "1061720"
  },
  {
    "text": "get a lot of questions about latency",
    "start": "1061720",
    "end": "1063160"
  },
  {
    "text": "here and I completely agree there's a",
    "start": "1063160",
    "end": "1064919"
  },
  {
    "text": "trade-off between kind of performance",
    "start": "1064919",
    "end": "1066600"
  },
  {
    "text": "accuracy and latency that's present here",
    "start": "1066600",
    "end": "1068919"
  },
  {
    "text": "I think the real answer is you can opt",
    "start": "1068919",
    "end": "1071200"
  },
  {
    "text": "to use very fast uh for example models",
    "start": "1071200",
    "end": "1074440"
  },
  {
    "text": "like grock we're seeing um you know gp35",
    "start": "1074440",
    "end": "1077679"
  },
  {
    "text": "turbos of very fast these are fairly",
    "start": "1077679",
    "end": "1079960"
  },
  {
    "text": "easy grading challenges so you can use",
    "start": "1079960",
    "end": "1082080"
  },
  {
    "text": "very very fast LMS to do the grading and",
    "start": "1082080",
    "end": "1084720"
  },
  {
    "text": "for example um you you can also restrict",
    "start": "1084720",
    "end": "1088240"
  },
  {
    "text": "this to only do one turn of of kind of",
    "start": "1088240",
    "end": "1090360"
  },
  {
    "text": "cyclic iteration so you can kind of",
    "start": "1090360",
    "end": "1091799"
  },
  {
    "text": "restrict the latency in that way as well",
    "start": "1091799",
    "end": "1094000"
  },
  {
    "text": "so anyway I think it's a really cool",
    "start": "1094000",
    "end": "1095280"
  },
  {
    "text": "approach still relevant in the world as",
    "start": "1095280",
    "end": "1097200"
  },
  {
    "text": "we move towards longer context so it's",
    "start": "1097200",
    "end": "1099120"
  },
  {
    "text": "kind of like building reasoning on top",
    "start": "1099120",
    "end": "1100559"
  },
  {
    "text": "of rag um in the uh generation and",
    "start": "1100559",
    "end": "1105080"
  },
  {
    "text": "retrieval stages and a related point one",
    "start": "1105080",
    "end": "1107840"
  },
  {
    "text": "of the challenges with",
    "start": "1107840",
    "end": "1109600"
  },
  {
    "text": "is that your index for example you you",
    "start": "1109600",
    "end": "1112559"
  },
  {
    "text": "may have a question that is that ask",
    "start": "1112559",
    "end": "1115200"
  },
  {
    "text": "something that's outside the scope of",
    "start": "1115200",
    "end": "1116440"
  },
  {
    "text": "your index and this is kind of always a",
    "start": "1116440",
    "end": "1118000"
  },
  {
    "text": "problem so a really cool paper called c",
    "start": "1118000",
    "end": "1120559"
  },
  {
    "text": "c rag or corrective rag came out you",
    "start": "1120559",
    "end": "1122600"
  },
  {
    "text": "know a couple months ago that basically",
    "start": "1122600",
    "end": "1124520"
  },
  {
    "text": "does a grading just like we talked about",
    "start": "1124520",
    "end": "1126200"
  },
  {
    "text": "before and then if the documents are not",
    "start": "1126200",
    "end": "1128679"
  },
  {
    "text": "relevant you kick off and do a web",
    "start": "1128679",
    "end": "1130559"
  },
  {
    "text": "search and basically return the search",
    "start": "1130559",
    "end": "1132280"
  },
  {
    "text": "results to the LM for final generation",
    "start": "1132280",
    "end": "1134559"
  },
  {
    "text": "so it's a nice fallback in cases where",
    "start": "1134559",
    "end": "1137120"
  },
  {
    "text": "um you're you the questions out of the",
    "start": "1137120",
    "end": "1139440"
  },
  {
    "text": "domain of your retriever so you know",
    "start": "1139440",
    "end": "1142000"
  },
  {
    "text": "again nice trick overlay reasing on top",
    "start": "1142000",
    "end": "1144280"
  },
  {
    "text": "of rag I think this trend you know",
    "start": "1144280",
    "end": "1146559"
  },
  {
    "text": "continues um because you know it it just",
    "start": "1146559",
    "end": "1149760"
  },
  {
    "text": "it makes rag systems you know more",
    "start": "1149760",
    "end": "1152039"
  },
  {
    "text": "performant uh and less brittle to",
    "start": "1152039",
    "end": "1155080"
  },
  {
    "text": "questions that are out of domain so you",
    "start": "1155080",
    "end": "1156960"
  },
  {
    "text": "know that's another kind of nice idea",
    "start": "1156960",
    "end": "1159679"
  },
  {
    "text": "this particular approach also we showed",
    "start": "1159679",
    "end": "1161280"
  },
  {
    "text": "works really well with with uh with open",
    "start": "1161280",
    "end": "1163280"
  },
  {
    "text": "source models so I ran this with mraw 7B",
    "start": "1163280",
    "end": "1165760"
  },
  {
    "text": "it can run locally on my laptop using a",
    "start": "1165760",
    "end": "1167559"
  },
  {
    "text": "llama so again really nice approach I",
    "start": "1167559",
    "end": "1170039"
  },
  {
    "text": "encourage you to look into this um and",
    "start": "1170039",
    "end": "1171799"
  },
  {
    "text": "this is all kind of independent of the",
    "start": "1171799",
    "end": "1173559"
  },
  {
    "text": "llm kind of context length these are",
    "start": "1173559",
    "end": "1175880"
  },
  {
    "text": "reasoning you can add on top of the",
    "start": "1175880",
    "end": "1178600"
  },
  {
    "text": "retrieval stage that that can kind of",
    "start": "1178600",
    "end": "1180679"
  },
  {
    "text": "improve overall performance and so the",
    "start": "1180679",
    "end": "1182880"
  },
  {
    "text": "overall picture kind of looks like this",
    "start": "1182880",
    "end": "1184919"
  },
  {
    "text": "where you know I think that the the the",
    "start": "1184919",
    "end": "1188480"
  },
  {
    "text": "problem of routing your question to the",
    "start": "1188480",
    "end": "1190320"
  },
  {
    "text": "right database and or to the right",
    "start": "1190320",
    "end": "1192320"
  },
  {
    "text": "document kind of remains in place queer",
    "start": "1192320",
    "end": "1194640"
  },
  {
    "text": "analysis is still quite relevant routing",
    "start": "1194640",
    "end": "1196280"
  },
  {
    "text": "is still relevant queer construction is",
    "start": "1196280",
    "end": "1197840"
  },
  {
    "text": "still relevant",
    "start": "1197840",
    "end": "1199200"
  },
  {
    "text": "um in the long context regime I think",
    "start": "1199200",
    "end": "1201039"
  },
  {
    "text": "there is less of an emphasis on document",
    "start": "1201039",
    "end": "1203240"
  },
  {
    "text": "chunking working with full documents is",
    "start": "1203240",
    "end": "1205520"
  },
  {
    "text": "probably kind of more Paro optimal so to",
    "start": "1205520",
    "end": "1207559"
  },
  {
    "text": "speak um there's some some clever tricks",
    "start": "1207559",
    "end": "1210039"
  },
  {
    "text": "for IND indexing of documents like the",
    "start": "1210039",
    "end": "1212240"
  },
  {
    "text": "multi-representation indexing we talked",
    "start": "1212240",
    "end": "1214039"
  },
  {
    "text": "about the hierarchical indexing using",
    "start": "1214039",
    "end": "1216400"
  },
  {
    "text": "Raptor that we talked about as well are",
    "start": "1216400",
    "end": "1217880"
  },
  {
    "text": "two interesting ideas for document",
    "start": "1217880",
    "end": "1219760"
  },
  {
    "text": "Centric indexing um and then kind of",
    "start": "1219760",
    "end": "1222480"
  },
  {
    "text": "reasing in generation post retrieval on",
    "start": "1222480",
    "end": "1225799"
  },
  {
    "text": "retrieval itself to grade on the",
    "start": "1225799",
    "end": "1227760"
  },
  {
    "text": "generations themselves checking for",
    "start": "1227760",
    "end": "1229480"
  },
  {
    "text": "hallucinations those are all kind of",
    "start": "1229480",
    "end": "1231440"
  },
  {
    "text": "interesting and relevant parts of a rag",
    "start": "1231440",
    "end": "1233880"
  },
  {
    "text": "system that I think we'll probably will",
    "start": "1233880",
    "end": "1235240"
  },
  {
    "text": "see more and more of as we move more",
    "start": "1235240",
    "end": "1237360"
  },
  {
    "text": "away from like a more naive prompt",
    "start": "1237360",
    "end": "1239320"
  },
  {
    "text": "response Paradigm more to like a flow",
    "start": "1239320",
    "end": "1241600"
  },
  {
    "text": "Paradigm we're seeing that actually",
    "start": "1241600",
    "end": "1242880"
  },
  {
    "text": "already in code generation it's probably",
    "start": "1242880",
    "end": "1244600"
  },
  {
    "text": "going to carry over to rag as well where",
    "start": "1244600",
    "end": "1246559"
  },
  {
    "text": "we kind of build rag systems that have",
    "start": "1246559",
    "end": "1248080"
  },
  {
    "text": "kind of a cyclic flow to them operate on",
    "start": "1248080",
    "end": "1250280"
  },
  {
    "text": "documents use lomics llms um and still",
    "start": "1250280",
    "end": "1253159"
  },
  {
    "text": "use kind of routing and query analysis",
    "start": "1253159",
    "end": "1254840"
  },
  {
    "text": "so reasoning pre- retrieval reasoning",
    "start": "1254840",
    "end": "1257240"
  },
  {
    "text": "post- retrieval so one any that was kind",
    "start": "1257240",
    "end": "1259120"
  },
  {
    "text": "of my talk um and yeah feel free to",
    "start": "1259120",
    "end": "1261559"
  },
  {
    "text": "leave any comments on the video and I'll",
    "start": "1261559",
    "end": "1263039"
  },
  {
    "text": "try to answer any questions but um yeah",
    "start": "1263039",
    "end": "1265880"
  },
  {
    "text": "that's that's probably about it thank",
    "start": "1265880",
    "end": "1267200"
  },
  {
    "text": "you",
    "start": "1267200",
    "end": "1269960"
  }
]
[
  {
    "text": "agents can often mess up they can",
    "start": "1079",
    "end": "3480"
  },
  {
    "text": "hallucinate a response in a rag workflow",
    "start": "3480",
    "end": "6960"
  },
  {
    "text": "they can not be up Tod dat with the",
    "start": "6960",
    "end": "9760"
  },
  {
    "text": "version of code that you are using or",
    "start": "9760",
    "end": "12440"
  },
  {
    "text": "they can just plan and do things",
    "start": "12440",
    "end": "15279"
  },
  {
    "text": "incorrectly a common technique to",
    "start": "15279",
    "end": "17880"
  },
  {
    "text": "overcome these issues is to use some",
    "start": "17880",
    "end": "19960"
  },
  {
    "text": "type of reflection so what this means is",
    "start": "19960",
    "end": "22760"
  },
  {
    "text": "run some sort of evaluation process on",
    "start": "22760",
    "end": "25960"
  },
  {
    "text": "the agent response live while it's doing",
    "start": "25960",
    "end": "29519"
  },
  {
    "text": "its job",
    "start": "29519",
    "end": "30560"
  },
  {
    "text": "and and and based on that if it fails",
    "start": "30560",
    "end": "33559"
  },
  {
    "text": "that eval pass it back to the agent and",
    "start": "33559",
    "end": "36040"
  },
  {
    "text": "tell it to correct itself or if it",
    "start": "36040",
    "end": "38160"
  },
  {
    "text": "succeeds then you're okay to finish",
    "start": "38160",
    "end": "41360"
  },
  {
    "text": "today I'm excited to introduce Lang",
    "start": "41360",
    "end": "42960"
  },
  {
    "text": "graph reflection an attempt at providing",
    "start": "42960",
    "end": "45559"
  },
  {
    "text": "some higher level scaffolding for",
    "start": "45559",
    "end": "47559"
  },
  {
    "text": "getting started with that at its core",
    "start": "47559",
    "end": "50480"
  },
  {
    "text": "it's a pretty simple architecture to be",
    "start": "50480",
    "end": "52480"
  },
  {
    "text": "honest so there's this core graph this",
    "start": "52480",
    "end": "54640"
  },
  {
    "text": "is the main agent that comes in and then",
    "start": "54640",
    "end": "57399"
  },
  {
    "text": "there's this reflection agent and so",
    "start": "57399",
    "end": "58920"
  },
  {
    "text": "basically what happens is the user input",
    "start": "58920",
    "end": "61199"
  },
  {
    "text": "will come in it will go to the main",
    "start": "61199",
    "end": "62719"
  },
  {
    "text": "agent from there it will go to this",
    "start": "62719",
    "end": "64640"
  },
  {
    "text": "reflection agent and then this",
    "start": "64640",
    "end": "66320"
  },
  {
    "text": "reflection agent will either send it",
    "start": "66320",
    "end": "68479"
  },
  {
    "text": "back to the graph or it will go to the",
    "start": "68479",
    "end": "72679"
  },
  {
    "text": "end there are only two assumptions that",
    "start": "73280",
    "end": "75840"
  },
  {
    "text": "we make for this pre-built architecture",
    "start": "75840",
    "end": "78240"
  },
  {
    "text": "so one the main agent should take as",
    "start": "78240",
    "end": "80040"
  },
  {
    "text": "input a list of messages it can take",
    "start": "80040",
    "end": "81920"
  },
  {
    "text": "other things but it should at least take",
    "start": "81920",
    "end": "83400"
  },
  {
    "text": "as input a list of messages and then two",
    "start": "83400",
    "end": "86880"
  },
  {
    "text": "the reflection agent should return a",
    "start": "86880",
    "end": "88680"
  },
  {
    "text": "user message if there are any critiques",
    "start": "88680",
    "end": "91520"
  },
  {
    "text": "otherwise it shouldn't return any",
    "start": "91520",
    "end": "92960"
  },
  {
    "text": "messages and the reason that this is",
    "start": "92960",
    "end": "94920"
  },
  {
    "text": "important is because this conditional",
    "start": "94920",
    "end": "97159"
  },
  {
    "text": "Edge will look for the presence of a",
    "start": "97159",
    "end": "99079"
  },
  {
    "text": "user message when deciding whether to go",
    "start": "99079",
    "end": "101399"
  },
  {
    "text": "back to the main agent or to",
    "start": "101399",
    "end": "103960"
  },
  {
    "text": "return to make this more concrete we",
    "start": "103960",
    "end": "106240"
  },
  {
    "text": "added two examples one is a coding",
    "start": "106240",
    "end": "108520"
  },
  {
    "text": "example where it uses a lint Checker to",
    "start": "108520",
    "end": "110960"
  },
  {
    "text": "check whether the code seems correct",
    "start": "110960",
    "end": "112640"
  },
  {
    "text": "that it generated the other one uses an",
    "start": "112640",
    "end": "114920"
  },
  {
    "text": "llm as a judge to just judge the output",
    "start": "114920",
    "end": "118280"
  },
  {
    "text": "let's take a closer look at both of",
    "start": "118280",
    "end": "119640"
  },
  {
    "text": "these starting with the llm as a",
    "start": "119640",
    "end": "122759"
  },
  {
    "text": "judge first let's take a look at the",
    "start": "122759",
    "end": "124680"
  },
  {
    "text": "code we can see that we install three",
    "start": "124680",
    "end": "126759"
  },
  {
    "text": "modules L graph reflection which is this",
    "start": "126759",
    "end": "128920"
  },
  {
    "text": "higher level architecture Lang chain",
    "start": "128920",
    "end": "131160"
  },
  {
    "text": "which we will use for managing the entry",
    "start": "131160",
    "end": "132800"
  },
  {
    "text": "point to llms and then open evals which",
    "start": "132800",
    "end": "135440"
  },
  {
    "text": "is a package we created to do LM as a",
    "start": "135440",
    "end": "137480"
  },
  {
    "text": "judge",
    "start": "137480",
    "end": "139680"
  },
  {
    "text": "evaluations first we create the main",
    "start": "139680",
    "end": "141879"
  },
  {
    "text": "assistant graph so this is just going to",
    "start": "141879",
    "end": "143200"
  },
  {
    "text": "be a really simple single call to an llm",
    "start": "143200",
    "end": "146000"
  },
  {
    "text": "so we're you calling into Claude 3.7",
    "start": "146000",
    "end": "148160"
  },
  {
    "text": "Sonet and you know this agent isn't",
    "start": "148160",
    "end": "150879"
  },
  {
    "text": "really an agent it's just a call to an",
    "start": "150879",
    "end": "152120"
  },
  {
    "text": "LM but this is just for demo purposes",
    "start": "152120",
    "end": "153760"
  },
  {
    "text": "and it also shows that you can use this",
    "start": "153760",
    "end": "155200"
  },
  {
    "text": "architecture not just for super",
    "start": "155200",
    "end": "157120"
  },
  {
    "text": "complicated agents but even for kind of",
    "start": "157120",
    "end": "158920"
  },
  {
    "text": "like simple just single invocations to",
    "start": "158920",
    "end": "161120"
  },
  {
    "text": "an",
    "start": "161120",
    "end": "162720"
  },
  {
    "text": "llm next let's take a look at the",
    "start": "162720",
    "end": "164800"
  },
  {
    "text": "critique that we do so here we have this",
    "start": "164800",
    "end": "167360"
  },
  {
    "text": "prompt that we're going to ask the llm",
    "start": "167360",
    "end": "169360"
  },
  {
    "text": "as a judge to grade the initial response",
    "start": "169360",
    "end": "171239"
  },
  {
    "text": "for it's going to grade it on accuracy",
    "start": "171239",
    "end": "173200"
  },
  {
    "text": "completeness Clarity helpfulness and",
    "start": "173200",
    "end": "174959"
  },
  {
    "text": "safety so this is pretty generic and if",
    "start": "174959",
    "end": "178159"
  },
  {
    "text": "you're applying this to your use case",
    "start": "178159",
    "end": "179640"
  },
  {
    "text": "you you'll probably want to customize",
    "start": "179640",
    "end": "180959"
  },
  {
    "text": "this prompt and make it a little bit",
    "start": "180959",
    "end": "182280"
  },
  {
    "text": "more specific and that's totally",
    "start": "182280",
    "end": "185200"
  },
  {
    "text": "possible next we're going to create this",
    "start": "185200",
    "end": "187120"
  },
  {
    "text": "function that does this llm as a judge",
    "start": "187120",
    "end": "189040"
  },
  {
    "text": "bit so here we can see that we use",
    "start": "189040",
    "end": "191280"
  },
  {
    "text": "create llm as a judge this is a helper",
    "start": "191280",
    "end": "193120"
  },
  {
    "text": "from open eval we're going to use 03",
    "start": "193120",
    "end": "195360"
  },
  {
    "text": "mini as our judge and then the feedback",
    "start": "195360",
    "end": "197840"
  },
  {
    "text": "key that we're going to want is just",
    "start": "197840",
    "end": "200000"
  },
  {
    "text": "pass we're then going to pass in the",
    "start": "200000",
    "end": "202040"
  },
  {
    "text": "outputs as the contents of the last",
    "start": "202040",
    "end": "204480"
  },
  {
    "text": "message that we get because remember",
    "start": "204480",
    "end": "205879"
  },
  {
    "text": "this is running after the initial agent",
    "start": "205879",
    "end": "208159"
  },
  {
    "text": "so any response from the initial agent",
    "start": "208159",
    "end": "209799"
  },
  {
    "text": "will be the last message that we get and",
    "start": "209799",
    "end": "212200"
  },
  {
    "text": "we're not really going to look at the",
    "start": "212200",
    "end": "213159"
  },
  {
    "text": "inputs because we're just judging the",
    "start": "213159",
    "end": "214400"
  },
  {
    "text": "outputs",
    "start": "214400",
    "end": "216200"
  },
  {
    "text": "here then based on this if the result of",
    "start": "216200",
    "end": "219840"
  },
  {
    "text": "score is true um so this is the score is",
    "start": "219840",
    "end": "222560"
  },
  {
    "text": "going to be a Boolean if it's true that",
    "start": "222560",
    "end": "224280"
  },
  {
    "text": "means it's approved by the judge and",
    "start": "224280",
    "end": "225920"
  },
  {
    "text": "we're just going to finish otherwise",
    "start": "225920",
    "end": "227560"
  },
  {
    "text": "it's false and we're going to use the",
    "start": "227560",
    "end": "229400"
  },
  {
    "text": "comment field to pass back in",
    "start": "229400",
    "end": "232280"
  },
  {
    "text": "feedback and so score and common are",
    "start": "232280",
    "end": "235480"
  },
  {
    "text": "standard fields that we get back from",
    "start": "235480",
    "end": "237319"
  },
  {
    "text": "this llm as a judge evaluator we're",
    "start": "237319",
    "end": "239879"
  },
  {
    "text": "going to build this graph and then we're",
    "start": "239879",
    "end": "241599"
  },
  {
    "text": "really simple just going to use create",
    "start": "241599",
    "end": "243760"
  },
  {
    "text": "reflection graph pass in the first graph",
    "start": "243760",
    "end": "245760"
  },
  {
    "text": "pass in the judge graph get back the sap",
    "start": "245760",
    "end": "248879"
  },
  {
    "text": "awesome and then we can see here that we",
    "start": "248879",
    "end": "250239"
  },
  {
    "text": "have an example query and so let's see",
    "start": "250239",
    "end": "252159"
  },
  {
    "text": "what",
    "start": "252159",
    "end": "253959"
  },
  {
    "text": "happened I'm going to run this graph",
    "start": "253959",
    "end": "256400"
  },
  {
    "text": "right here by just running the this file",
    "start": "256400",
    "end": "259280"
  },
  {
    "text": "I can see that I get some nice print",
    "start": "259280",
    "end": "260759"
  },
  {
    "text": "statements it'll take a little bit",
    "start": "260759",
    "end": "262280"
  },
  {
    "text": "because I asked it for a pretty complex",
    "start": "262280",
    "end": "264479"
  },
  {
    "text": "report I can see that I log something",
    "start": "264479",
    "end": "266600"
  },
  {
    "text": "out to the terminal and then it finishes",
    "start": "266600",
    "end": "268479"
  },
  {
    "text": "so it passed on the first try let's take",
    "start": "268479",
    "end": "270479"
  },
  {
    "text": "a look at the lsmith trace to see",
    "start": "270479",
    "end": "272000"
  },
  {
    "text": "exactly what's going on under so here we",
    "start": "272000",
    "end": "274600"
  },
  {
    "text": "can see that there was two main sub",
    "start": "274600",
    "end": "276320"
  },
  {
    "text": "agents here the graph which is the first",
    "start": "276320",
    "end": "278039"
  },
  {
    "text": "one and then the reflection agent so",
    "start": "278039",
    "end": "280360"
  },
  {
    "text": "clicking into this we can see our first",
    "start": "280360",
    "end": "282400"
  },
  {
    "text": "call to an llm here we have our user",
    "start": "282400",
    "end": "284759"
  },
  {
    "text": "input here and then we get this nice",
    "start": "284759",
    "end": "286400"
  },
  {
    "text": "long AI output now here we have another",
    "start": "286400",
    "end": "290080"
  },
  {
    "text": "call to an llm and this is for",
    "start": "290080",
    "end": "292840"
  },
  {
    "text": "judging and so here we can see our",
    "start": "292840",
    "end": "295199"
  },
  {
    "text": "system prompt that we wrote here and",
    "start": "295199",
    "end": "297080"
  },
  {
    "text": "then we can see that we passed in the",
    "start": "297080",
    "end": "298680"
  },
  {
    "text": "response from the first graph into here",
    "start": "298680",
    "end": "301759"
  },
  {
    "text": "we can see the output is saying that it",
    "start": "301759",
    "end": "303759"
  },
  {
    "text": "should pass and then there's this",
    "start": "303759",
    "end": "305080"
  },
  {
    "text": "reasoning bit as well and so because the",
    "start": "305080",
    "end": "307560"
  },
  {
    "text": "score is true it's not going any further",
    "start": "307560",
    "end": "310720"
  },
  {
    "text": "let's take a look at another example",
    "start": "310720",
    "end": "312400"
  },
  {
    "text": "this time with code so here we're going",
    "start": "312400",
    "end": "314840"
  },
  {
    "text": "to install the same packages but we're",
    "start": "314840",
    "end": "316440"
  },
  {
    "text": "also going to install pyite which is a",
    "start": "316440",
    "end": "318080"
  },
  {
    "text": "python",
    "start": "318080",
    "end": "319039"
  },
  {
    "text": "linter we can then see that we have this",
    "start": "319039",
    "end": "321319"
  },
  {
    "text": "helper function analyze with pyite so",
    "start": "321319",
    "end": "324160"
  },
  {
    "text": "this will use pyate for static type",
    "start": "324160",
    "end": "325600"
  },
  {
    "text": "checking and errors",
    "start": "325600",
    "end": "329120"
  },
  {
    "text": "other than that it's pretty similar so",
    "start": "329880",
    "end": "331639"
  },
  {
    "text": "we can see that we create a single call",
    "start": "331639",
    "end": "333360"
  },
  {
    "text": "to a model this will be our base agent",
    "start": "333360",
    "end": "335840"
  },
  {
    "text": "and then we create this reflection bit",
    "start": "335840",
    "end": "338039"
  },
  {
    "text": "which will attempt to grade the",
    "start": "338039",
    "end": "339840"
  },
  {
    "text": "generated code so the first thing it",
    "start": "339840",
    "end": "342000"
  },
  {
    "text": "does is it actually extracts the",
    "start": "342000",
    "end": "343560"
  },
  {
    "text": "generated code from the response so",
    "start": "343560",
    "end": "346880"
  },
  {
    "text": "because the response is just an AI",
    "start": "346880",
    "end": "348280"
  },
  {
    "text": "message we actually need to pluck out",
    "start": "348280",
    "end": "349600"
  },
  {
    "text": "the parts that have to do with coding so",
    "start": "349600",
    "end": "351720"
  },
  {
    "text": "we're first going to use an llm to do",
    "start": "351720",
    "end": "353800"
  },
  {
    "text": "that and so that's what this extraction",
    "start": "353800",
    "end": "356120"
  },
  {
    "text": "bit does here then if we did have a call",
    "start": "356120",
    "end": "359479"
  },
  {
    "text": "that that extracted the python code",
    "start": "359479",
    "end": "360960"
  },
  {
    "text": "we're going to analyze it with pyite",
    "start": "360960",
    "end": "362520"
  },
  {
    "text": "we're going to print stuff out just so",
    "start": "362520",
    "end": "363759"
  },
  {
    "text": "we can see what's happening and then if",
    "start": "363759",
    "end": "365560"
  },
  {
    "text": "there's any errors we're going to pass",
    "start": "365560",
    "end": "368120"
  },
  {
    "text": "back in a message to the user I ran",
    "start": "368120",
    "end": "370560"
  },
  {
    "text": "power and found this with the",
    "start": "370560",
    "end": "372599"
  },
  {
    "text": "explanation that we get from the General",
    "start": "372599",
    "end": "374639"
  },
  {
    "text": "Diagnostic section we de tell it to try",
    "start": "374639",
    "end": "377520"
  },
  {
    "text": "to fix it and try to regenerate the",
    "start": "377520",
    "end": "379400"
  },
  {
    "text": "entire code snippet this is because",
    "start": "379400",
    "end": "380720"
  },
  {
    "text": "we're doing extraction on that message",
    "start": "380720",
    "end": "382360"
  },
  {
    "text": "in the final in the step before this so",
    "start": "382360",
    "end": "384400"
  },
  {
    "text": "we want it to generate the whole thing",
    "start": "384400",
    "end": "386520"
  },
  {
    "text": "and then we also say that if you're not",
    "start": "386520",
    "end": "387960"
  },
  {
    "text": "sure you can also just like ask a",
    "start": "387960",
    "end": "390319"
  },
  {
    "text": "question um and this is because",
    "start": "390319",
    "end": "392280"
  },
  {
    "text": "sometimes in code the model might not",
    "start": "392280",
    "end": "395360"
  },
  {
    "text": "actually know the most upto-date syntax",
    "start": "395360",
    "end": "397319"
  },
  {
    "text": "and so rather than trying to generate",
    "start": "397319",
    "end": "398720"
  },
  {
    "text": "something incorrect and keep on trying",
    "start": "398720",
    "end": "400880"
  },
  {
    "text": "it should Instead try to ask the user",
    "start": "400880",
    "end": "403440"
  },
  {
    "text": "for",
    "start": "403440",
    "end": "404840"
  },
  {
    "text": "help let's try this one out",
    "start": "404840",
    "end": "408440"
  },
  {
    "text": "now great so here we can see some",
    "start": "408440",
    "end": "410840"
  },
  {
    "text": "initial errors that we get so one has to",
    "start": "410840",
    "end": "413319"
  },
  {
    "text": "do with an import statement Lang chain",
    "start": "413319",
    "end": "415039"
  },
  {
    "text": "coma could not be resolved so I don't",
    "start": "415039",
    "end": "416520"
  },
  {
    "text": "actually have this package installed in",
    "start": "416520",
    "end": "418440"
  },
  {
    "text": "my environment",
    "start": "418440",
    "end": "421520"
  },
  {
    "text": "next I can see that I this next I can",
    "start": "422280",
    "end": "424720"
  },
  {
    "text": "see that there's some parameter error no",
    "start": "424720",
    "end": "426759"
  },
  {
    "text": "parameter named initial State I can then",
    "start": "426759",
    "end": "429280"
  },
  {
    "text": "see another issue so cannot access",
    "start": "429280",
    "end": "431440"
  },
  {
    "text": "attribute run for class State graph so",
    "start": "431440",
    "end": "434720"
  },
  {
    "text": "there's a few issues here some of which",
    "start": "434720",
    "end": "436160"
  },
  {
    "text": "could probably be fixed by installing",
    "start": "436160",
    "end": "437919"
  },
  {
    "text": "the Right Packages other of which appear",
    "start": "437919",
    "end": "439919"
  },
  {
    "text": "to be a little bit wrong still hopefully",
    "start": "439919",
    "end": "443199"
  },
  {
    "text": "this helps motivate this General",
    "start": "443199",
    "end": "445199"
  },
  {
    "text": "reflection architecture and provides a",
    "start": "445199",
    "end": "447599"
  },
  {
    "text": "few examples for how you can use it I",
    "start": "447599",
    "end": "449840"
  },
  {
    "text": "want to call out that it's really",
    "start": "449840",
    "end": "451440"
  },
  {
    "text": "important to get a good reflection agent",
    "start": "451440",
    "end": "453800"
  },
  {
    "text": "here as well and that's actually",
    "start": "453800",
    "end": "455479"
  },
  {
    "text": "something we'll be working on over the",
    "start": "455479",
    "end": "457319"
  },
  {
    "text": "next few weeks is to provide some",
    "start": "457319",
    "end": "459440"
  },
  {
    "text": "off-the-shelf reflection agents for rag",
    "start": "459440",
    "end": "461520"
  },
  {
    "text": "for code and for general purpose things",
    "start": "461520",
    "end": "464319"
  },
  {
    "text": "but you should also always know that you",
    "start": "464319",
    "end": "466199"
  },
  {
    "text": "can customize this reflection agent to",
    "start": "466199",
    "end": "468159"
  },
  {
    "text": "your particular domain and application",
    "start": "468159",
    "end": "470400"
  },
  {
    "text": "you can try out L graph Reflection by",
    "start": "470400",
    "end": "472400"
  },
  {
    "text": "doing pip install L graph reflection",
    "start": "472400",
    "end": "474879"
  },
  {
    "text": "thanks for watching",
    "start": "474879",
    "end": "478000"
  }
]
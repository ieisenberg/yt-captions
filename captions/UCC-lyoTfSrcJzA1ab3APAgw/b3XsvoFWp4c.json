[
  {
    "start": "0",
    "end": "75000"
  },
  {
    "text": "Will: Hi, all, Will here. Let's build a travel\nassistant chatbot together. In the process, you'll learn some reusable\ntechniques that'll be applicable if",
    "start": "760",
    "end": "8219"
  },
  {
    "text": "you're building any customer support\nchatbot or really any AI system that has any of the following characteristics.",
    "start": "8220",
    "end": "14590"
  },
  {
    "text": "One, it uses tools that take\nactions on behalf of the user. So it's more than just a Q&\nA read only kind of chatbot.",
    "start": "15029",
    "end": "23804"
  },
  {
    "text": "Two, it uses a large number of tools. And so it has a lot of difficulty, perhaps\nchoosing the right one and also using that",
    "start": "24805",
    "end": "34704"
  },
  {
    "text": "without more advanced techniques, three,\nyour chatbot has to support different",
    "start": "35074",
    "end": "42215"
  },
  {
    "text": "specific user journeys in your product. So each of these could be maybe\na checkout flow management of",
    "start": "42295",
    "end": "49144"
  },
  {
    "text": "a specific feature, et cetera. So it has to support a\nlarge number of attempts.",
    "start": "49145",
    "end": "53799"
  },
  {
    "text": "We'll start by building a really simple\ntravel assistant, show some limitations in its design, and then gradually add\nsome complexity and control to help",
    "start": "54860",
    "end": "63660"
  },
  {
    "text": "better support these types of needs. As always, these tutorials can be\nfound in the Langraff documentation.",
    "start": "63720",
    "end": "70729"
  },
  {
    "text": "This case is a customer support use case. As context for what we're\nbuilding, I wanted to give a",
    "start": "70780",
    "end": "77330"
  },
  {
    "start": "75000",
    "end": "158000"
  },
  {
    "text": "brief prehistory of chatbots. So traditional chatbots you typically\ninteract with on the phone or through",
    "start": "77330",
    "end": "84610"
  },
  {
    "text": "something that you might build in\nDialogflow, often take these behavioral tree type structures or graphs, where\nthe user will have some sort of question,",
    "start": "84610",
    "end": "93449"
  },
  {
    "text": "the intent will route it to a very\nspecific skill, and then the chatbot will say, That contacts is propagated\ndown on each of these functions,",
    "start": "93880",
    "end": "100720"
  },
  {
    "text": "then solves that dedicated task. The problem with this is you can see\nis it gets really complex and wherever",
    "start": "100720",
    "end": "106790"
  },
  {
    "text": "you do want to be jumping between\ntasks that context isn't fully shared. It just isn't sufficiently flexible and\nsupportive to really make it a great",
    "start": "106790",
    "end": "116240"
  },
  {
    "text": "user experience, which is why everyone's\nfrustrated when they end up with a robo. Experience on the phone.",
    "start": "116240",
    "end": "121570"
  },
  {
    "text": "Fast forward to 2022, chat GPT jumps\non the scene with this radical idea of eliminating all this complexity of\nintent detection and entity linking",
    "start": "122980",
    "end": "133299"
  },
  {
    "text": "and routing and response generation. And it just puts the user directly\nin contact with a, with a user.",
    "start": "133299",
    "end": "138984"
  },
  {
    "text": "very powerful LLM to be able to answer\nquestions and other types of things.",
    "start": "139655",
    "end": "144155"
  },
  {
    "text": "And the problem you might see with this\nis it's not actually grounded in anything. You could ask this same system\nin a hundred years and it",
    "start": "144795",
    "end": "150755"
  },
  {
    "text": "would still think it's 2022. And it isn't able to actually take\nactions on behalf of the user.",
    "start": "150755",
    "end": "155304"
  },
  {
    "text": "So that brings us to today. We're going to go through a series\nof flight assistant Designs that have",
    "start": "156285",
    "end": "164550"
  },
  {
    "start": "158000",
    "end": "410000"
  },
  {
    "text": "increasing complexity, starting from a\nvery simple tool using conversational agent up to a one that has a little\nbit more specific task specific context",
    "start": "164570",
    "end": "175220"
  },
  {
    "text": "aware workflows that more closely mirror. Honestly, this original design to be\nable to balance this kind of context,",
    "start": "175250",
    "end": "183619"
  },
  {
    "text": "sharing and capacity and expressiveness\nwith the ability to design in a way",
    "start": "183619",
    "end": "188860"
  },
  {
    "text": "that Good focused user experiences. So we'll start out with this\nzero shot tool executor.",
    "start": "188860",
    "end": "196040"
  },
  {
    "text": "It's just a graph of two nodes. You've got the assistant, which is\nreally just an LLM and a prompt. It's able to decide to call\na tool or respond directly.",
    "start": "196380",
    "end": "204400"
  },
  {
    "text": "These tools are all\nprovided at the LLM at once. So it has to do two tasks. Really? It has to decide which and.",
    "start": "204730",
    "end": "211500"
  },
  {
    "text": "Which tool and if a tool to call,\nand then also the arguments there. And then it has to be synthesizing\nresponse based on the actions from that.",
    "start": "212070",
    "end": "218799"
  },
  {
    "text": "And it can do this in a loop as you\nprobably are familiar with, this will have",
    "start": "218820",
    "end": "224020"
  },
  {
    "text": "some limitations that we'll discuss later. And so we'll add in this user control\nflow so that whenever the assistant",
    "start": "224020",
    "end": "230300"
  },
  {
    "text": "takes an action, the user is able to be\ninvolved in the loop to confirm whether they can actually take that action.",
    "start": "230300",
    "end": "236120"
  },
  {
    "text": "So then the assistant isn't going off and. Spending all the user's money trying\nto book different flights without",
    "start": "236160",
    "end": "241694"
  },
  {
    "text": "the user actually having a say\non whether or not they want that. And you're not relying purely on the\nLLM then in this case you're adding",
    "start": "241695",
    "end": "248694"
  },
  {
    "text": "some additional code safeguards to make\nsure that it's not going off the rails.",
    "start": "248695",
    "end": "252315"
  },
  {
    "text": "The third part will be adding\na little bit more scoping. So a lot of these types of tools that\nwe're giving the flight assistant,",
    "start": "254330",
    "end": "261270"
  },
  {
    "text": "they're going to be like searching\nover flights, searching over user details, car rentals, excursions.",
    "start": "261590",
    "end": "266680"
  },
  {
    "text": "Those things don't really need\nuser support or confirmation. So we're going to split those\nout into a simple safe tools and",
    "start": "267100",
    "end": "274130"
  },
  {
    "text": "sensitive tools type of design. And this is all right. This works pretty well. The problem is that if each of these\nexperiences becomes quite complex, maybe",
    "start": "274130",
    "end": "283129"
  },
  {
    "text": "you have specific instructions, you\nknow, re including company policies, all of the above, you start to overload\nthis single prompt where it can't",
    "start": "283130",
    "end": "293540"
  },
  {
    "text": "handle all of these experiences. And still have this reliable, delightful\nuser experience that you want.",
    "start": "293540",
    "end": "299175"
  },
  {
    "text": "So to be able to better handle\nthat, you can separate all of these different focused user journeys into\nskills or workflows, or you can even",
    "start": "299695",
    "end": "307895"
  },
  {
    "text": "imagine this since this is in fact,\nthe design as a multi agent workflow. So, you have this primary assistant that\nthe user can interact with, and anytime",
    "start": "307895",
    "end": "316014"
  },
  {
    "text": "the user needs something that can be\nsatisfied with one of these skills, it'll route the intent to these, and\nthen these transparently can interact",
    "start": "316055",
    "end": "323405"
  },
  {
    "text": "directly with the user, they can use\ntheir own scoped tools, and they can guide the user through that journey.",
    "start": "323435",
    "end": "329385"
  },
  {
    "text": "Since this is all a single state\ngraph, it's going to be managing state transitions throughout,\nand then work really seamlessly.",
    "start": "329685",
    "end": "336215"
  },
  {
    "text": "You'll probably notice that we're\ngoing from Least to most complex today in this tutorial and I typically\nrecommend following a similar journey",
    "start": "337875",
    "end": "345645"
  },
  {
    "text": "as you build out your own application\nSimply because assistance these these LLMs are quite powerful And all this\nadditional code that you're writing",
    "start": "345645",
    "end": "354345"
  },
  {
    "text": "can actually inhibit the performance\nof the LLM if you're not measuring it quite carefully You are taking trade\noffs, of course in that you're putting",
    "start": "354345",
    "end": "362685"
  },
  {
    "text": "a lot of the code Decision making and\nexperience complexity on the LLM itself.",
    "start": "362685",
    "end": "367630"
  },
  {
    "text": "But as the LLM quality improves,\nyou may find that some of these more simpler designs become more and more\nexpressive and capable of handling",
    "start": "367890",
    "end": "375480"
  },
  {
    "text": "these things that today require\nmore explicit, explicit workflows.",
    "start": "375480",
    "end": "379800"
  },
  {
    "text": "All right, we'll download the notebook\nfrom the docs and then get started. If you're following along with the\ncode, I'd recommend liberal use of these",
    "start": "382165",
    "end": "389055"
  },
  {
    "text": "contents navigators because there is a\nlot of code that's boilerplate just to set up all of the tools for this use case.",
    "start": "389185",
    "end": "394295"
  },
  {
    "text": "We want it to be a little bit more\nsimilar to what your use case might look like by providing a lot of these\ntools and database accessories here",
    "start": "394325",
    "end": "401985"
  },
  {
    "text": "but it does get a little verbose and\nincrease the time it takes to get",
    "start": "402275",
    "end": "407675"
  },
  {
    "text": "to the actual agent design parts. All right, so over in our\nnotebook, we'll first start by",
    "start": "407685",
    "end": "414565"
  },
  {
    "start": "410000",
    "end": "604000"
  },
  {
    "text": "setting up the prerequisites. Basically before designing our first\nagent, we're going to create the database,",
    "start": "414575",
    "end": "421645"
  },
  {
    "text": "we're going to create all the tools\nwhich we'll reuse across all of the sections in the tutorial today, and we'll\ninstall all the prerequisites of course.",
    "start": "422185",
    "end": "429703"
  },
  {
    "text": "So, I've already run this, I'm going\nto set the API keys, basically we'll be using Anthropic for the LLM to\naccess Cloud, and we'll also use",
    "start": "431275",
    "end": "438655"
  },
  {
    "text": "Tavaleet as an extra tool the agent to\noptionally do some general web research.",
    "start": "438655",
    "end": "444325"
  },
  {
    "text": "Next we'll fetch the database, I pre\npackaged this simple SQLite database in Google Cloud Storage for us, so\nyou can just fetch it there and reuse",
    "start": "445835",
    "end": "454035"
  },
  {
    "text": "it, you don't have to go and find some\nother location to download it from. And then we'll start defining our tools.",
    "start": "454035",
    "end": "459445"
  },
  {
    "text": "The first tool is this\nretriever over company policies. Again, for this use case, we're going\nto be designing a flight assistant.",
    "start": "459485",
    "end": "465895"
  },
  {
    "text": "And so the company policies are some\nSwiss Air company policies about when you can rebook, what kinds of cancellation\npolicies they have, et cetera.",
    "start": "466235",
    "end": "475705"
  },
  {
    "text": "These are useful for allowing the\nbot to do simple Q& A and it can also help direct it to know what\nkind of actions it's allowed to take.",
    "start": "476305",
    "end": "485065"
  },
  {
    "text": "It's not. sufficient to provide policies\nas instructions, since the LLM",
    "start": "485315",
    "end": "493460"
  },
  {
    "text": "can always choose to ignore it. So just remember when you're defining\nthe tools to also enforce that",
    "start": "493460",
    "end": "499100"
  },
  {
    "text": "these rules are actually applied. All right.",
    "start": "499200",
    "end": "503840"
  },
  {
    "text": "The, the next step is\nreally not that important. We're going to be defining\nall the tools for the flights.",
    "start": "504220",
    "end": "509300"
  },
  {
    "text": "The hotels, the excursions,\nthe car rentals. Each of these are basically CRUD end\npoints where you can be searching",
    "start": "509640",
    "end": "515779"
  },
  {
    "text": "over the different available things. You can be getting the\nuser's current information. You can be updating their bookings.",
    "start": "515780",
    "end": "521409"
  },
  {
    "text": "You can be deleting their\nbookings, et cetera. I guess one thing I will point\nout since it's a common question.",
    "start": "521420",
    "end": "527389"
  },
  {
    "text": "Of how do you add configuration to tools? We'll be using this in shared config\nto get configurable information,",
    "start": "527780",
    "end": "534580"
  },
  {
    "text": "to see the signed in passenger ID. So in our case, our graph, we're\nactually passing in the current user or",
    "start": "534600",
    "end": "540410"
  },
  {
    "text": "passenger ID directly into the inputs. The other one doesn't really have\nto know that the current user is",
    "start": "540420",
    "end": "545760"
  },
  {
    "text": "signed in and has a specific UUID. We'll just be using this\nin configurable params. Alright, so do car rental tools, hotels,\nexcursions, and then we'll have a",
    "start": "545760",
    "end": "555805"
  },
  {
    "text": "couple utilities just for this tutorial. One is just printing these events, which\njust makes it look pretty in the notebook.",
    "start": "555805",
    "end": "562745"
  },
  {
    "text": "The other two, or really one, is that\nwe're going to add a fallback so that any time the agent generates a, an input\nto the tool that will raise an error.",
    "start": "562955",
    "end": "572819"
  },
  {
    "text": "We're going to have these fallbacks that\njust adds that error to the message list. So the agent is able to retry.",
    "start": "573280",
    "end": "579420"
  },
  {
    "text": "And learn from these mistakes. If you're building this in a real\nproduction use case, you'll likely",
    "start": "579935",
    "end": "585155"
  },
  {
    "text": "want to find as many of these error\ncases as possible through a good evaluation harness, like Langsmith\nand then build this into a few shot",
    "start": "585155",
    "end": "592145"
  },
  {
    "text": "examples or better instructions or\nbetter designed tools so that it doesn't actually run into these very often.",
    "start": "592145",
    "end": "597255"
  },
  {
    "text": "For the sake of the\ntutorial, it's always good. To have defense in depth and\nhave these fallbacks in there.",
    "start": "597455",
    "end": "602740"
  },
  {
    "text": "All right. So now we can finally\nstart defining our agent. This is going to be a simple\nconversational zero shot agent.",
    "start": "603900",
    "end": "611600"
  },
  {
    "start": "604000",
    "end": "968000"
  },
  {
    "text": "It'll take the LLM and\nprompt as the assistant node. And then we'll be putting all of our\ntools in a single tool executor node.",
    "start": "613250",
    "end": "620320"
  },
  {
    "text": "The assistant can choose to respond\ndirectly to the user, or it can choose to pick one or more of the tools,\nexecute them, and then observe the",
    "start": "621030",
    "end": "629100"
  },
  {
    "text": "responses to help assist the user. With all these line graph tutorials,\nI start by defining the state, really.",
    "start": "629100",
    "end": "636464"
  },
  {
    "text": "The state determines the interface\nfor every node in the graph.",
    "start": "637005",
    "end": "641495"
  },
  {
    "text": "It also defines how that state is updated\nwhenever a node returns some values.",
    "start": "642015",
    "end": "648315"
  },
  {
    "text": "In our case, we're going to have\na very simple message graph that just has a list of chat messages.",
    "start": "649095",
    "end": "655395"
  },
  {
    "text": "And we'll say that any time a node\nfinishes, we're only going to be appending these messages to it.",
    "start": "655925",
    "end": "660815"
  },
  {
    "text": "So this is just a function here. And this is Python's annotated syntax,\nif you're not familiar with it.",
    "start": "660935",
    "end": "665905"
  },
  {
    "text": "So we'll run that. Next, we'll be defining\nthe agent or the assistant. Again, this node here.",
    "start": "666865",
    "end": "672595"
  },
  {
    "text": "Really, what we're doing here\nis we're going to say, so the assistant is taking this runnable,\nwhich is a prompt in an LLM.",
    "start": "674235",
    "end": "681325"
  },
  {
    "text": "We're going to call it. And then in the typical case, it'll just\nreturn that new AI message, or assistant",
    "start": "682085",
    "end": "687904"
  },
  {
    "text": "message, and add it to the state. Sometimes when you're using haiku\nor one of the weaker models, it",
    "start": "687905",
    "end": "693880"
  },
  {
    "text": "might return an empty response. And so we don't really want\nthat in our, in our message. So I do have a little retry loop just to\nget it to respond with an actual response.",
    "start": "693880",
    "end": "701750"
  },
  {
    "text": "We've got sonnet here\nwe'll be using by default. If you want to be running this\ncheaply and fast, you can use haiku.",
    "start": "702490",
    "end": "707390"
  },
  {
    "text": "And then you have the\nprompt, the tool and the LLM. Here, we're using the binds tool syntax,\nwhich tells the LLM that these are all",
    "start": "707660",
    "end": "717700"
  },
  {
    "text": "the schemas that it can choose from in\norder to generate that JSON payload. The prompt we're defining here\nis not super optimized, but it",
    "start": "717700",
    "end": "727120"
  },
  {
    "text": "instructs the agent who they are. It instructs them that.",
    "start": "727290",
    "end": "732089"
  },
  {
    "text": "The user has specific information and\nit gives the current time so that it's able to reason about relative questions\nlike, Oh, what's happening tomorrow?",
    "start": "732455",
    "end": "740485"
  },
  {
    "text": "Like, how long do I have between this? Et cetera. And this, we have a whole bunch of tools\nhere that we're giving to the agent.",
    "start": "740495",
    "end": "746745"
  },
  {
    "text": "So we'll see how well it's able\nto perform with all of these. So we've got this runnable.",
    "start": "746755",
    "end": "752405"
  },
  {
    "text": "Now it's time to define the graph. This one's going to be pretty simple. We start by defining this builder\nobject, which is like a state graph.",
    "start": "753325",
    "end": "762233"
  },
  {
    "text": "We're saying that all the nodes are\ngoing to  receive this state object. And then we'll define the two nodes.",
    "start": "762423",
    "end": "769119"
  },
  {
    "text": "There's the assistant\nnode and the action node. We'll say that we'll start. Anytime the user sends in an input,\nit's going to go to the assistant and",
    "start": "769239",
    "end": "777639"
  },
  {
    "text": "then we're going to say, based on this\ntool's condition, if there are tool calls in the output of the assistant\nnode, then we'll route to the action",
    "start": "777639",
    "end": "786039"
  },
  {
    "text": "node again, so they're a tool executor. Otherwise, we're going to end. By ending, this means it's just\ngoing to cease executing and the",
    "start": "786359",
    "end": "796039"
  },
  {
    "text": "user can then decide to respond\nor the conversation can end.",
    "start": "796039",
    "end": "800549"
  },
  {
    "text": "Anytime we do take an action, we can\ngo directly back to the assistant.",
    "start": "803249",
    "end": "806919"
  },
  {
    "text": "Finally, we'll be creating\nthis check pointer. The check pointer is memory for the graph. It saves the entire graph\nstate after each step.",
    "start": "808434",
    "end": "815314"
  },
  {
    "text": "In our case, this is really just a\nchat message history, but again, the state can be arbitrarily complex,\nand all of that is cached in.",
    "start": "815854",
    "end": "822244"
  },
  {
    "text": "So your, your agent can just be,\nbe persisted, stopped, resumed at any point in the future.",
    "start": "822494",
    "end": "828074"
  },
  {
    "text": "I'll run that. Now we'll be drawing the graph so\nyou can just visualize it again.",
    "start": "830024",
    "end": "835574"
  },
  {
    "text": "This is a very simple agent\nthat's just this little loop. That optionally returns as soon as\nit's taken all the actions it needs.",
    "start": "835584",
    "end": "842664"
  },
  {
    "text": "Now, for all of our parts, we're going\nto have this simulated conversation between the user and the assistant.",
    "start": "845184",
    "end": "850834"
  },
  {
    "text": "If the assistant goes off the\nrails, this might diverge a little bit, but that's okay. We'll catch that in the trace and\nin the printouts to show that, oh,",
    "start": "851484",
    "end": "859804"
  },
  {
    "text": "maybe this isn't the most realistic\nresponse in a given point in time.",
    "start": "859804",
    "end": "863374"
  },
  {
    "text": "We're also going to be copying this backup\ndatabase that we copied over previously. And this is really just so that every time\nwe go through these parts, we're starting",
    "start": "865364",
    "end": "872864"
  },
  {
    "text": "from the same point and we can really\ncompare apples to apples in a better way.",
    "start": "872864",
    "end": "876064"
  },
  {
    "text": "For this tutorial, we'll be\nthis passenger in the database. We currently do have a flight booking,\nand we want to be asking questions about",
    "start": "877884",
    "end": "884894"
  },
  {
    "text": "updating it and making other trip plans. Finally, this thread ID is going\nto be unique per conversation.",
    "start": "884904",
    "end": "891604"
  },
  {
    "text": "This tells the checkpointer that we\ndefine up here To save all of the",
    "start": "892014",
    "end": "897253"
  },
  {
    "text": "checkpoints under this thread, we can\nthen later update and we can fetch all",
    "start": "897254",
    "end": "903804"
  },
  {
    "text": "of these checkpoints by that thread ID. So you can do things like fun, like\ntime travel and resumption and all that.",
    "start": "903804",
    "end": "909873"
  },
  {
    "text": "Alright, let's run this cell now. So you can jump over to\nLangsmith to see some examples. As you can see this\nmost recent invocation.",
    "start": "911024",
    "end": "918254"
  },
  {
    "text": "The LLM has a lot of tools to choose\nfrom, and it has to know how to use each one, and it has to know how to respond\nto the user in a really good way which is",
    "start": "918559",
    "end": "925089"
  },
  {
    "text": "just a lot for the current crop of LLMs. You can see that all the chat history\nand state is saved over time, so it is",
    "start": "925089",
    "end": "933079"
  },
  {
    "text": "maintaining this conversation over time. But it's like, it's going and it's\nusing its pre trained knowledge to",
    "start": "933239",
    "end": "940209"
  },
  {
    "text": "like share different information. It's sometimes going off the rails\nand how it's deciding certain actions.",
    "start": "940489",
    "end": "945159"
  },
  {
    "text": "I could spend a lot of time prompt\nengineering and maybe get it reasonably good using this setup. But another way to approach this is\nto really focus on specific floats,",
    "start": "945519",
    "end": "953549"
  },
  {
    "text": "which we'll get to in part four. The other things I want to point out are\nthat it's not asking user confirmation and",
    "start": "954639",
    "end": "960438"
  },
  {
    "text": "it's, and it's not great on some of these\nvertical use cases and user journeys.",
    "start": "960529",
    "end": "966459"
  },
  {
    "text": "Which brings us to part two. So we had the zero shot react loop.",
    "start": "966459",
    "end": "970539"
  },
  {
    "start": "968000",
    "end": "1177000"
  },
  {
    "text": "Let's add some user confirmation. This just lets the user go and\nconfirm whether the agent is allowed",
    "start": "971514",
    "end": "977313"
  },
  {
    "text": "to take any action on their behalf. So as before, the user sends a\nmessage, the assistant can decide",
    "start": "977314",
    "end": "982993"
  },
  {
    "text": "whether to respond directly or whether\nto invoke a tool and then, and then choose, choose one or more tools.",
    "start": "983064",
    "end": "989334"
  },
  {
    "text": "It'll send those over\nto the tool executor. The tool executor actually calls the\nAPIs and then returns the results,",
    "start": "989994",
    "end": "996014"
  },
  {
    "text": "the assistant, and then it can\ndecide whether to continue using these tools or whether to respond. In this case, the user actually gets\nto sit in and listen or listen in",
    "start": "996044",
    "end": "1004304"
  },
  {
    "text": "on this tool node, and we'll be able\nto approve, deny, or even update the",
    "start": "1004314",
    "end": "1011244"
  },
  {
    "text": "calls to the tools if they want to\nhave that last say in what's going on.",
    "start": "1011264",
    "end": "1015503"
  },
  {
    "text": "This will be done through the\ninterrupt before action in line graph. And we'll see what that is in a minute.",
    "start": "1018454",
    "end": "1025259"
  },
  {
    "text": "So let's start by defining\nthe state and assistant. This is really almost identical\nto part one with two exceptions.",
    "start": "1026819",
    "end": "1032849"
  },
  {
    "text": "One, we're going to add this\nuser info field at the beginning.",
    "start": "1033359",
    "end": "1036188"
  },
  {
    "text": "And this is really saying that We're\nable to preemptively provide some user",
    "start": "1038559",
    "end": "1044388"
  },
  {
    "text": "information to the LLM, so it doesn't\nhave to go and do that that initial query for getting the user's flight details.",
    "start": "1044389",
    "end": "1049719"
  },
  {
    "text": "If you recall in the conversation\nabove, it had to go and search for that, and then that took an extra\nstep, and it really should always be",
    "start": "1050139",
    "end": "1056099"
  },
  {
    "text": "situationally aware about what the user\nis intending to do as much as possible.",
    "start": "1056099",
    "end": "1061709"
  },
  {
    "text": "The second difference here is\nthat we're going to be using that state directly in the assistant.",
    "start": "1062169",
    "end": "1067388"
  },
  {
    "text": "Rather than giving the user info\nand popping the prompt there. So we'll define this,\nmostly identical again.",
    "start": "1067674",
    "end": "1075369"
  },
  {
    "text": "Now we'll define the graph. So there's two new things about this. Again, we're adding this FetchUserInfo\nhere as a separate entry node.",
    "start": "1075839",
    "end": "1082449"
  },
  {
    "text": "And this means that we'll always\nhave the current user's state or context available to the assistant.",
    "start": "1082789",
    "end": "1087929"
  },
  {
    "text": "The second difference here is\nwe're adding this InterruptBefore. What this tells the graph is that\nany time the control flows into this",
    "start": "1088279",
    "end": "1094439"
  },
  {
    "text": "tool node, we're going to stop and\nlet the user approve or deny it. What it really means is\nthe graph stops executing.",
    "start": "1094439",
    "end": "1100773"
  },
  {
    "text": "And since we're persisting the state to\nthe checkpoint, anytime we invoke again, it'll start from that node rather than\nfrom the top, rather than from the start.",
    "start": "1100794",
    "end": "1108594"
  },
  {
    "text": "You can see our graph here. It looks mostly the same. We've added this additional node there. Now we'll run through the same questions.",
    "start": "1110734",
    "end": "1117064"
  },
  {
    "text": "We'll copy over the database again, just\nso it's starting from the same point. And we've added some additional\ninformation here to the database.",
    "start": "1117134",
    "end": "1125294"
  },
  {
    "text": "Let the user actually interact. All right. So despite having that\ninformation provided, it's",
    "start": "1126784",
    "end": "1133534"
  },
  {
    "text": "asking for our confirmation. So we'll say, yes, we're going\nto search for our flight details.",
    "start": "1133534",
    "end": "1138844"
  },
  {
    "text": "You're allowed to do that. Now it's going to be\nlooking at the policy. Sure. You can look up the policy.",
    "start": "1138894",
    "end": "1144684"
  },
  {
    "text": "I think you're getting the sense that. The user being involved in the\nflow for every single step is maybe a little bit overkill.",
    "start": "1145754",
    "end": "1151734"
  },
  {
    "text": "So am I allowed to change my flight? Yeah, I can. All right. So if you continue running, the agent's\ngoing to continue to ask for your",
    "start": "1152074",
    "end": "1159464"
  },
  {
    "text": "permission anytime it needs to do any\naction from making a reservation all the way to just looking up a simple policy.",
    "start": "1159464",
    "end": "1165934"
  },
  {
    "text": "This is a little bit too\nmuch work for the user. We want the agent to be a little\nmore autonomous than this.",
    "start": "1166334",
    "end": "1170874"
  },
  {
    "text": "We just want to make sure that it's\nnot taking actions that make my life as the user worse in the next section.",
    "start": "1171344",
    "end": "1177434"
  },
  {
    "start": "1177000",
    "end": "1510000"
  },
  {
    "text": "We'll make a conditional interrupt. This is a simple change using a design\npattern, just splitting the tool nodes",
    "start": "1177434",
    "end": "1184564"
  },
  {
    "text": "into two so that we can interrupt on the\nones that are what we deem sensitive. So right actions, this is one way\nof, of introducing conditionality on",
    "start": "1184564",
    "end": "1195153"
  },
  {
    "text": "interrupts and user in the loop workflows. So once again, our user\nwill ask a question.",
    "start": "1195174",
    "end": "1202484"
  },
  {
    "text": "You have the assistant, if\nit's able to choose to respond directly, or it can call a tool.",
    "start": "1202834",
    "end": "1207824"
  },
  {
    "text": "In the assistant's mind, it's still seeing\nall these same, the same tools here. It doesn't know that it's split here.",
    "start": "1208434",
    "end": "1214514"
  },
  {
    "text": "That, that really doesn't matter. It's the LLM. But whenever it does call a tool,\nwe'll have this conditional node",
    "start": "1214554",
    "end": "1220764"
  },
  {
    "text": "that looks it up and sees is the tool\nthat's called one of these sensitive tools, or is it a safe tool that it\ncan go and just do search or retrieval?",
    "start": "1220814",
    "end": "1230104"
  },
  {
    "text": "If it's a safe tool, it can go there\nand then return, and then the user can, or the assistant can respond directly. The user doesn't have to be\nconfirming in this workflow.",
    "start": "1231964",
    "end": "1238334"
  },
  {
    "text": "Otherwise, if it's going to make\na change, like a cancellation or booking a reservation, it\ngoes to these sensitive tools.",
    "start": "1240824",
    "end": "1245654"
  },
  {
    "text": "Here we have the route,\nthe interrupt again. So the user can approve or it can\ndecide, no, I don't actually want that.",
    "start": "1246374",
    "end": "1252589"
  },
  {
    "text": "I'm going to want something else. Or the user can even update the state\ndirectly to change the parameters",
    "start": "1252809",
    "end": "1258999"
  },
  {
    "text": "specifically before they go into the tool. So it really has like\nthree different choices.",
    "start": "1259009",
    "end": "1264129"
  },
  {
    "text": "Once the tool is called or once the user\ndenies it, the assistant can then decide whether to respond saying this question is\nsatisfied or it can decide to try again,",
    "start": "1265379",
    "end": "1275229"
  },
  {
    "text": "get some more information, et cetera. All right. So. The state here and everything\nis identical to part two.",
    "start": "1275249",
    "end": "1282884"
  },
  {
    "text": "We have the messages that we've defined. We have the user info so that eagerly\npopulating the information about the user.",
    "start": "1283264",
    "end": "1289634"
  },
  {
    "text": "We have the assistant runnable. This is all unchanged. We're going to use like sonnet. We're going to have all these things.",
    "start": "1289954",
    "end": "1295114"
  },
  {
    "text": "The one thing that is different is now\nwe split this tools into two lists. We've had the safe tools, which\nis the general search engine.",
    "start": "1295424",
    "end": "1301254"
  },
  {
    "text": "Fetching user information, searching,\nlooking up all these read only operations that we consider to be\nfine, doesn't require user approval.",
    "start": "1301569",
    "end": "1308079"
  },
  {
    "text": "We've then split out these updates\nand cancellations and creation events into sensitive tools,\nwhich will organize that really.",
    "start": "1308759",
    "end": "1315869"
  },
  {
    "text": "As I mentioned before, the LLM\nactually doesn't know the difference. We're going to have all\nthese tools provided to it.",
    "start": "1316769",
    "end": "1324359"
  },
  {
    "text": "It's still picking the same as before. What's different is that our graphs,\nour orchestration, actually will.",
    "start": "1324579",
    "end": "1330929"
  },
  {
    "text": "be able to, to federate this out\ninto different nodes so that the user experience is slightly different.",
    "start": "1331329",
    "end": "1335689"
  },
  {
    "text": "All right, time to define the graph. This is again, mostly\nthe same as in part two. We have the state, we're passing\nit the state we've created.",
    "start": "1337269",
    "end": "1344888"
  },
  {
    "text": "We have this user info node that we're\ngoing to enter on and say every time we start this graph, we're going to make\nsure that we have the most up to date",
    "start": "1345259",
    "end": "1352429"
  },
  {
    "text": "user information available so the LLM can\nsee the user's current flights and etc.",
    "start": "1352429",
    "end": "1357028"
  },
  {
    "text": "This is useful, again, as an aside. If the user goes and makes changes\noutside of this assistant workflow,",
    "start": "1358134",
    "end": "1363444"
  },
  {
    "text": "it has up to date context. It doesn't have to be getting\nthat all from the conversation.",
    "start": "1363444",
    "end": "1367094"
  },
  {
    "text": "Now we're going to add the assistant,\nand we're going to add two different nodes, safe nodes and sensitive nodes.",
    "start": "1368934",
    "end": "1374324"
  },
  {
    "text": "So the safe tools here are the ones\nthat we do for read only operations.",
    "start": "1375034",
    "end": "1380234"
  },
  {
    "text": "The sensitive tools here are the\nones that have write operations.",
    "start": "1380854",
    "end": "1385304"
  },
  {
    "text": "Now we'll have the edge for\nthe FetchUserInfo to Assistant.",
    "start": "1388154",
    "end": "1393344"
  },
  {
    "text": "This is just saying every time you\nenter and we get that eager operation of the UserInfo, we'll immediately\ngo to the Assistant, and then",
    "start": "1393594",
    "end": "1399884"
  },
  {
    "text": "we'll define this conditional edge. Previously, we had just been using this\npre built tools condition, which looks",
    "start": "1399884",
    "end": "1405084"
  },
  {
    "text": "for the presence of tool invocations\nin the AI output in the messages list. Now we're going to extend this and say,\nokay, yeah, if there's no tool calls,",
    "start": "1405084",
    "end": "1413674"
  },
  {
    "text": "we'll still return just as before. However, if We're going to filter on\nthe name of the tool calls and say, if",
    "start": "1413674",
    "end": "1419839"
  },
  {
    "text": "it's in the sensitive tool names, we'll\nroute this to the sensitive tools node. Otherwise, we can give it to the safe\ntools node and continue as before.",
    "start": "1419839",
    "end": "1428299"
  },
  {
    "text": "Finally, we're going to compile with\na checkpointer again so that it has conversational memory and persistence.",
    "start": "1430199",
    "end": "1435549"
  },
  {
    "text": "And again, this checkpointer is saving\nnot only the conversational memory, the messages, it is also caching this user\ninfo that we've defined in our state here.",
    "start": "1436289",
    "end": "1445489"
  },
  {
    "text": "And again, the more fields\nyou add in here, all of this is checkpointed alongside it.",
    "start": "1446339",
    "end": "1450089"
  },
  {
    "text": "So we'll create this. You'll see our graph\nhas added a node here. You have the assistant.",
    "start": "1452869",
    "end": "1458189"
  },
  {
    "text": "It's able to route either to\nthe sensitive tools, to the safe tools, or back to the user.",
    "start": "1458199",
    "end": "1462379"
  },
  {
    "text": "Remember, we're interrupting here\nonly on the sensitive tools node. All right, let's go through\nthis conversation again.",
    "start": "1463859",
    "end": "1470259"
  },
  {
    "text": "Hi there, what time is my flight? You see it fetches the user's\nflight information, and it looks",
    "start": "1471469",
    "end": "1480638"
  },
  {
    "text": "up policy all without me as the\nuser having to get involved. Great.",
    "start": "1480639",
    "end": "1485489"
  },
  {
    "text": "It's autonomously able to execute stuff. Let's make sure that it is actually\ngoing to stop for us before it",
    "start": "1485969",
    "end": "1494399"
  },
  {
    "text": "goes and makes some sort of change. Alright, it's trying to\ncancel my ticket first.",
    "start": "1494399",
    "end": "1498628"
  },
  {
    "text": "Notice that this time it is trying\nto cancel before it is updating. This is different than before, just\nbecause the LLM is a little bit random.",
    "start": "1499529",
    "end": "1506699"
  },
  {
    "text": "Before it was just directly updating it. This leads us to a point of inadequacy\nof this simple flat design and",
    "start": "1506889",
    "end": "1515839"
  },
  {
    "start": "1510000",
    "end": "1648000"
  },
  {
    "text": "that it's pretty hard to have\nthe large prompt that completely defines each intended user journey.",
    "start": "1515839",
    "end": "1522899"
  },
  {
    "text": "The LLM is likely to ignore some\ninstructions or confuse instructions from different sections that might\nnot apply across each experience.",
    "start": "1523669",
    "end": "1530699"
  },
  {
    "text": "All right, in this case, I'll\njust approve and go through. All right, we've made it\nthrough the conversation. Let's jump over to Langsmith\nto check out the trace.",
    "start": "1531764",
    "end": "1538493"
  },
  {
    "text": "We'll inspect this final one. You can see again, we're inputting null. It's just fetching all of the loaded\nmessages from memory, from the",
    "start": "1539494",
    "end": "1548523"
  },
  {
    "text": "check pointer that we've created. And it's calling this sensitive tools\nor booking excursion in this case.",
    "start": "1548524",
    "end": "1558444"
  },
  {
    "text": "We're inputting null here because\nwe're approving the current plan. All right. As you see before, the LLM has all\nthese different tools to choose from.",
    "start": "1558894",
    "end": "1565949"
  },
  {
    "text": "It goes in it, it does a decent job of\nanswering the user's initial questions. This time it actually chooses to try to\nfirst cancel and then rebook afterwards",
    "start": "1566279",
    "end": "1578509"
  },
  {
    "text": "rather than rebooking directly. This is kind of purely LLM. So we might want to have a more\nconsistent user experience in this kind",
    "start": "1578559",
    "end": "1585979"
  },
  {
    "text": "of task, since it is a common intent. It is able to successfully\nrebook and then it was looking",
    "start": "1585979",
    "end": "1591569"
  },
  {
    "text": "up some of this information. It does successfully use the search\ntools and car rentals tools there.",
    "start": "1591569",
    "end": "1597729"
  },
  {
    "text": "It gets to the, it gets to the search tools for\ntrip recommendations and it has a",
    "start": "1598319",
    "end": "1603799"
  },
  {
    "text": "hard time properly formatting this. We can improve the tool description or\nimprove the prompts here, but it's kind of",
    "start": "1603799",
    "end": "1610099"
  },
  {
    "text": "hard to do because we have already about\n16 tools or so that are provided this LLM.",
    "start": "1610109",
    "end": "1614719"
  },
  {
    "text": "And you can see we get some\ninconsistent experiences overall. So again, this worked pretty well.",
    "start": "1615209",
    "end": "1621259"
  },
  {
    "text": "The user is able to confirm\nor deny any actions. So in the end, if the LLM does\ndecide to cancel, then rebook,",
    "start": "1621559",
    "end": "1626799"
  },
  {
    "text": "versus rebook directly, it may not\nbe that important as to the outcome.",
    "start": "1626839",
    "end": "1632809"
  },
  {
    "text": "It does lead to a less delightful\nand less controlled user experience. And whenever you want to be building a\ngreat you want to be able to shape the",
    "start": "1633109",
    "end": "1641629"
  },
  {
    "text": "way that the user interacts with all of\nyour products and make sure that you can really create a differentiated experience\non each of these common user journeys.",
    "start": "1641629",
    "end": "1648388"
  },
  {
    "start": "1648000",
    "end": "1786000"
  },
  {
    "text": "So the next section we want to\nbe showing a simple way to create these specialized workflows. You can think of these as skills if\nyou're thinking about it in the sense",
    "start": "1648829",
    "end": "1656459"
  },
  {
    "text": "of like a serial Alexa type app. If you are coming from an agent\nbackground, this is in our",
    "start": "1656459",
    "end": "1662379"
  },
  {
    "text": "case, a multi agent workflow. But this is more powerful in\nthat each of these delegated",
    "start": "1662379",
    "end": "1668179"
  },
  {
    "text": "flows doesn't have to be agentic. It can be a strict user checklist\nthat you're going through. It doesn't even have to use an LLM.",
    "start": "1668789",
    "end": "1674769"
  },
  {
    "text": "Really what this is, is a way of\noffloading all of the decision making and execution and planning\nfaculties from this main assistant",
    "start": "1675969",
    "end": "1687084"
  },
  {
    "text": "onto specific workflows where you as\nthe designer, as the developer can",
    "start": "1687434",
    "end": "1693883"
  },
  {
    "text": "inject the expected behavior into the\nprompt tools and sub graph structure.",
    "start": "1693914",
    "end": "1701503"
  },
  {
    "text": "An analogy I'll make is that if you're\ncreating a website, You're not going to load the checkout workflow with the search\nworkflow with the, like, other, other",
    "start": "1703064",
    "end": "1713514"
  },
  {
    "text": "types of experiences all on a single page. You're going to have specific pages\nfor these and specific modals and",
    "start": "1713544",
    "end": "1719804"
  },
  {
    "text": "designs around these user journeys. The current LLMs really aren't good enough\nto be able to separate concerns in this",
    "start": "1719844",
    "end": "1727354"
  },
  {
    "text": "way so that whenever the user does enter\na workflow, it's only able to attend only that relevant context and really.",
    "start": "1727354",
    "end": "1733544"
  },
  {
    "text": "Perform reliably across these large\nnumber of user queries on all of these common intents by separating out concerns\nand creating these workflows You can",
    "start": "1733889",
    "end": "1742729"
  },
  {
    "text": "really target Common intents and make\nsure that those experiences are great",
    "start": "1742729",
    "end": "1748229"
  },
  {
    "text": "You can optimize these independently. You can evaluate them independently. Without worrying about interrupting or\ndegrading the overall user experience.",
    "start": "1748604",
    "end": "1755864"
  },
  {
    "text": "This does create more code complexity. It's more stuff to manage. And so there is a trade off here.",
    "start": "1757624",
    "end": "1763153"
  },
  {
    "text": "I wouldn't start directly\nwith this pattern if I'm just building a simple Q& A app. But if you have found that your\nLLM is starting to struggle with",
    "start": "1763604",
    "end": "1773124"
  },
  {
    "text": "separating concerns and handling all\nthese different Various user intents. This is a design pattern that\nI would consider adapting.",
    "start": "1773524",
    "end": "1780234"
  },
  {
    "text": "All right. As always, we'll start. All right. As always, we'll start\nby defining the state.",
    "start": "1782914",
    "end": "1788154"
  },
  {
    "start": "1786000",
    "end": "2324000"
  },
  {
    "text": "The state has the same fields as before. It has the messages as the user info.",
    "start": "1789534",
    "end": "1794994"
  },
  {
    "text": "You'll notice we added this\ndialogue state variable here. And what this is just a list of strings.",
    "start": "1795054",
    "end": "1800384"
  },
  {
    "text": "What this tells the graph is any\ntime the user sends a message",
    "start": "1800964",
    "end": "1807214"
  },
  {
    "text": "to it, Where should we route it? Where should we give control? Before we were always first writing\nto the assistant and then it would go",
    "start": "1807214",
    "end": "1813579"
  },
  {
    "text": "to the tool nodes and stuff like that. Now the control flow can be delegated\nto the flight booking assistant.",
    "start": "1813639",
    "end": "1820119"
  },
  {
    "text": "It could be the car rental assistant,\nthe hotel booking assistant, all these different workflows. And so this, this state lets\nus condition on that and route",
    "start": "1820179",
    "end": "1828389"
  },
  {
    "text": "it to the appropriate place. As before we're defining\nhow the state is going to be",
    "start": "1828389",
    "end": "1834229"
  },
  {
    "text": "updated using a custom function. Where we're saying if it, the, if\nthe update is saying pop, then we're",
    "start": "1834229",
    "end": "1839794"
  },
  {
    "text": "going back to the primary assistant. Otherwise, we're adding\nthe, to the stack here.",
    "start": "1839814",
    "end": "1845194"
  },
  {
    "text": "This is just a neat, a concise\nway of representing where we currently are in the graph.",
    "start": "1845274",
    "end": "1849794"
  },
  {
    "text": "Next, we're going to define each workflow. For the assistance that power each\nworkflow we'll make a flight booking",
    "start": "1852044",
    "end": "1857419"
  },
  {
    "text": "one, a hotel booking, one car rental\nexcursion, and finally the primary assistant that again routes between these.",
    "start": "1857419",
    "end": "1863638"
  },
  {
    "text": "If you've watched some of our other\nvideos or read some of the docs, you'll notice that this is actually a supervised\ndesign pattern where the primary assistant",
    "start": "1864339",
    "end": "1872349"
  },
  {
    "text": "gets to choose whether to respond\ndirectly or whether to delegate work to each of the underlying workflows.",
    "start": "1872369",
    "end": "1877849"
  },
  {
    "text": "I claim that this is more powerful\nthan a multi agent pattern because these don't have to be agents.",
    "start": "1879229",
    "end": "1883779"
  },
  {
    "text": "Agents are a specific way to implement\neach of these individual flows.",
    "start": "1884289",
    "end": "1889528"
  },
  {
    "text": "We'll define this mostly\nthe same as before. Each of these flows will have a prompt. They'll have a list of safe\ntools and sensitive tools.",
    "start": "1890529",
    "end": "1897979"
  },
  {
    "text": "So separating out the read only from\nthe right axis ones, as well as the, the LLM where you're going to bind it.",
    "start": "1897989",
    "end": "1904719"
  },
  {
    "text": "So you're going to provide the schemas\nsaying these are the types of functions you're allowed to optionally select from.",
    "start": "1904729",
    "end": "1911109"
  },
  {
    "text": "We're also going to add this\nadditional function here, we define as a pedantic model, called completer\nescalate which is the name I chose.",
    "start": "1911839",
    "end": "1918609"
  },
  {
    "text": "This basically says, hey, if the\nuser decides to actually change their mind, this is how you go and,\nand pull the rip, this is how you go",
    "start": "1918919",
    "end": "1926749"
  },
  {
    "text": "and pull the rip cord, or change the\ncontext back to the primary assistant. It might be that I, as the user,\nwill go and say, hey, I want to book",
    "start": "1926749",
    "end": "1934419"
  },
  {
    "text": "a flight to New York, On Thursday,\nthe primary assistance is great. I'll connect you to the\nprimary booking assistant.",
    "start": "1934419",
    "end": "1941314"
  },
  {
    "text": "I'll say, sir, what are your flights? Maybe what are the prices? Actually on second thought,\nI need to save money.",
    "start": "1941694",
    "end": "1948414"
  },
  {
    "text": "I'm not going to do this. So the flight booking assistant\nneeds to way to say, okay, we're going to exit this guilt.",
    "start": "1948414",
    "end": "1953494"
  },
  {
    "text": "That's exactly what this is. We'll be reusing this completed escalate\ntask and all of these delegated workflows.",
    "start": "1953994",
    "end": "1959004"
  },
  {
    "text": "So we'll define the hotel booking\nassistant the same way, car rental, same way, et cetera.",
    "start": "1959344",
    "end": "1964484"
  },
  {
    "text": "You'll notice that since we've separated\nconcerns, we can have different prompts for each of these ones. And then.",
    "start": "1964864",
    "end": "1969574"
  },
  {
    "text": "If you wanted to take this a step\nfurther, you could optimize, provide more demonstrations, make this arbitrarily\noptimized for these very targeted use",
    "start": "1970204",
    "end": "1977794"
  },
  {
    "text": "cases, because it's all available. If we were using the current zero shot\npattern, you'd have to overload all these",
    "start": "1977794",
    "end": "1983894"
  },
  {
    "text": "different things in a single prompt,\nwhich perhaps will be possible with later LLMs when they get more powerful.",
    "start": "1983894",
    "end": "1989393"
  },
  {
    "text": "But today, it becomes a little bit\nconfusing and hard to maintain, and definitely hard to evaluate, because\nyou're constantly making these different",
    "start": "1989624",
    "end": "1995624"
  },
  {
    "text": "changes for each feature experience,\nwhich might be different teams that you're developing with and It's much\neasier in code to be separating the",
    "start": "1996259",
    "end": "2003498"
  },
  {
    "text": "concerns and optimizing them separately. Finally, we'll make this primary assistant\nIt'll have all of these two whatever",
    "start": "2003499",
    "end": "2012779"
  },
  {
    "text": "delegated assistant functions that it uses\nin order to indicate Okay, we should route",
    "start": "2012779",
    "end": "2017959"
  },
  {
    "text": "these different things In our case again,\nwe're using LLM to do the routing and You might get better performance using some\nsort of semantic routing with an embedding",
    "start": "2017999",
    "end": "2026339"
  },
  {
    "text": "classifier or something like that. I think it's easier to demonstrate\nthis supervisor pattern because I",
    "start": "2026339",
    "end": "2031789"
  },
  {
    "text": "don't have to train a classifier. But we'll release some other examples\nlater on how you could apply that here.",
    "start": "2031789",
    "end": "2039709"
  },
  {
    "text": "The primary assistant also has\na couple of these lookup tools, because if the user does want just\ngeneral factual knowledge, it might",
    "start": "2040709",
    "end": "2050269"
  },
  {
    "text": "be faster if the primary assistant\nactually is able to directly answer and do some queries on their behalf.",
    "start": "2050269",
    "end": "2055838"
  },
  {
    "text": "If you end up with a lot of these\ntools again, you might want to just separate those concerns out. This is all stuff that can be\nempirically verified with an",
    "start": "2056569",
    "end": "2062523"
  },
  {
    "text": "evaluation framework like LangSmith .\nSo, as we mentioned before, and\nI'll go back up to the agent state.",
    "start": "2062523",
    "end": "2067883"
  },
  {
    "text": "So as we mentioned before, and\nI'll go back up to the agent state, we have this message list\nthat's continuously appended to.",
    "start": "2068883",
    "end": "2074293"
  },
  {
    "text": "This is shared in each of these workflows. So all the user's interactions\nwith the flight's assistant can",
    "start": "2074683",
    "end": "2082413"
  },
  {
    "text": "be shared with the primary, which\nthen can be shared with the hotels. So then all these workflows\nactually know the entire user",
    "start": "2082413",
    "end": "2089523"
  },
  {
    "text": "journey as it's gone through each\nof these different experiences. This is pretty powerful. One of the frustrations that I often\nhave with tools like Siri is that you'll",
    "start": "2089523",
    "end": "2097828"
  },
  {
    "text": "get into the Spotify tool and then\nyou'll get into maps and then you'll ask the change, the, the, the music\nand it'll forget that you're there.",
    "start": "2097908",
    "end": "2105757"
  },
  {
    "text": "It just, it just doesn't\nshare context across it. One problem is that if you're sharing\nthis huge list, the LLM can still get a",
    "start": "2105758",
    "end": "2112098"
  },
  {
    "text": "little confused as to its current role. Even if you do have a very\nexplicit system prompt because",
    "start": "2112158",
    "end": "2117537"
  },
  {
    "text": "of that, we're going to add this. Entry node to each of these workflows. What this does is it adds a tool\nmessage saying the assistant is now",
    "start": "2117538",
    "end": "2126728"
  },
  {
    "text": "whatever assistant it is reflect\non the above conversation, use your tools to execute the task.",
    "start": "2127138",
    "end": "2132138"
  },
  {
    "text": "Basically a reminder of the information\nthat we've provided in the system prompt.",
    "start": "2132578",
    "end": "2137477"
  },
  {
    "text": "I found that at least for Claude,\nhaving that reminder at the end of the conversation is relatively\neffective in Reminding it who",
    "start": "2137908",
    "end": "2148208"
  },
  {
    "text": "it is and what it's able to do. It makes it more reliable if you only\nput this in the system prompt and the conversation gets quite long, it can start\nacting and trying to invoke or hallucinate",
    "start": "2148208",
    "end": "2156787"
  },
  {
    "text": "tools from the other assistants as it's\nnavigating this complex user experience.",
    "start": "2156798",
    "end": "2161408"
  },
  {
    "text": "So to find this utility, they'll\nessentially create the entry node for each of these workflows.",
    "start": "2162408",
    "end": "2167287"
  },
  {
    "text": "Finally, it's time to start\ncreating the graph as before. We're going to start with this\nuser info node just to eagerly",
    "start": "2168208",
    "end": "2174398"
  },
  {
    "text": "populate all this information. Next, we'll add each of these\ndelegated workflows, starting",
    "start": "2174588",
    "end": "2181567"
  },
  {
    "text": "with the flight booking assistant. As I mentioned before, you start by\nhaving this enter operation again. This will create a tool message\nthat says you are now the flight",
    "start": "2181568",
    "end": "2189047"
  },
  {
    "text": "and updates and booking assistant. Use these tools to help\nsatisfy the intent.",
    "start": "2189048",
    "end": "2194348"
  },
  {
    "text": "We'll add the actual assistant note here. In this case, update flight. We'll add the sensitive and safe tools\nand we'll add Add the conditional edge.",
    "start": "2195428",
    "end": "2204638"
  },
  {
    "text": "So this itself is an agentic loop\nsaying it can go to one of the tool nodes and leave the skill, or it\ncan respond directly to the user.",
    "start": "2204648",
    "end": "2211288"
  },
  {
    "text": "Even once this workflow does complete,\nwe want to make sure that we update the",
    "start": "2211288",
    "end": "2217788"
  },
  {
    "text": "state so that it is tracking where it is. So we have this pop dialogue state\nthing that adds a tool message",
    "start": "2217788",
    "end": "2224448"
  },
  {
    "text": "saying, okay, this workflow is now\ncomplete, sort of packages it up. And then it also adds this\npop operation to the state.",
    "start": "2224448",
    "end": "2232108"
  },
  {
    "text": "Recall when we defined this state before. Pop here is just going to return\neverything except for the last list here.",
    "start": "2232668",
    "end": "2239243"
  },
  {
    "text": "So if we've started with assistant and\nwe've gone to update flight, it'll then remove the update flight and it's just\nassistant in the list, for instance.",
    "start": "2239243",
    "end": "2245993"
  },
  {
    "text": "We'll define other, the other\ndelegated workflows in the same way. So car rentals, hotel bookings,\nexcursions, et cetera.",
    "start": "2246993",
    "end": "2255633"
  },
  {
    "text": "And finally, the primary one. A lot of this logic is repeat. You'll see the primary assistant has\na more complex switch because each",
    "start": "2255663",
    "end": "2263893"
  },
  {
    "text": "of these tool calls will route to\none of the delegated workflows here. You can probably factor this out\ninto some sort of dictionary and",
    "start": "2263893",
    "end": "2269908"
  },
  {
    "text": "make it a little bit more concise. It also can directly respond to the user. It can also actually use its own\nsearch tools, if you remember.",
    "start": "2269938",
    "end": "2277028"
  },
  {
    "text": "Finally, we're going to\nadd this check pointer. And we're going to say interrupt\nbefore any of these sensitive tools.",
    "start": "2279518",
    "end": "2285778"
  },
  {
    "text": "If you render the graph, it\nlooks something like this. I'm going to try to zoom in a little bit.",
    "start": "2286968",
    "end": "2291278"
  },
  {
    "text": "So you can see it goes\nto the Fetch User one. Then it goes to the Primary Assistant. The Primary Assistant optionally\nroutes to any of these.",
    "start": "2293178",
    "end": "2299878"
  },
  {
    "text": "Entrance nodes to these workflows,\nor it can route directly to the user. Once you're in one of these workflows,\nit can go to one of the tool nodes.",
    "start": "2300728",
    "end": "2308868"
  },
  {
    "text": "It can leave. So go back to the primary\nsystem, or it can actually interact directly with the user.",
    "start": "2309218",
    "end": "2313748"
  },
  {
    "text": "And this is mirrored across each\nof these specific workflows again.",
    "start": "2314428",
    "end": "2317788"
  },
  {
    "text": "So that was a lot. Let's see how it performs. All right. So let's jump over to Langsmith to\nlook at how this new version did.",
    "start": "2320018",
    "end": "2326908"
  },
  {
    "start": "2324000",
    "end": "2577000"
  },
  {
    "text": "And before I get too far, remember I did\nhave separate prompts for each of them. I didn't really optimize it super well.",
    "start": "2329478",
    "end": "2335098"
  },
  {
    "text": "I think there's a lot of improvements\nand a lot of gains that are left on the table right now. Just because I hadn't, didn't\nhave time to optimize them.",
    "start": "2335308",
    "end": "2341368"
  },
  {
    "text": "If you're building something real and\nyou've already separated it out, I think you have a lot of room for improvement\nby just improving the prompts, improving",
    "start": "2341598",
    "end": "2347968"
  },
  {
    "text": "the tool definitions, and then really\nfocus on each individual module that you can then help climb within\nan evaluation tool like Linksmith.",
    "start": "2347968",
    "end": "2354258"
  },
  {
    "text": "All right, we'll just look at the\ntrace here just to see how it did. You can see the user's going through,\nit says, what time is my flight?",
    "start": "2356138",
    "end": "2363203"
  },
  {
    "text": "Seems like it already has the information. So it's searching the flights\njust to get all the additional information, get some stuff back.",
    "start": "2365663",
    "end": "2371303"
  },
  {
    "text": "And it says, okay, we've got all this. It seems like it's doing a\ndecent job of entering these",
    "start": "2371303",
    "end": "2376503"
  },
  {
    "text": "first questions that we've had. Great. I think that perhaps speaks to the\nreduced burden of choice since the",
    "start": "2376513",
    "end": "2384373"
  },
  {
    "text": "top level primary assistant has\nfewer decisions it needs to make. Okay. Going into the flight booking flow.",
    "start": "2384683",
    "end": "2390633"
  },
  {
    "text": "The user tries to update\nto one for later today. It actually tries and the tool\nitself enforces that we can't",
    "start": "2390918",
    "end": "2397118"
  },
  {
    "text": "actually reschedule this. It's too soon to now. Remember that policy we\ntalked about earlier. What we could do here, since we're\nalready within this flow, we can just",
    "start": "2397118",
    "end": "2404168"
  },
  {
    "text": "front load a lot of those policies, those\nrelevant policies, so that the assistant doesn't have to go through this process.",
    "start": "2404178",
    "end": "2408913"
  },
  {
    "text": "background take extra work before\nresponding to the user, it can be more proactive about that. And that's what a lot of this\nseparation can end up doing that",
    "start": "2409193",
    "end": "2416313"
  },
  {
    "text": "I haven't yet integrated here. So similar to how we put that preemptive\nuser info block before entering the",
    "start": "2416313",
    "end": "2421943"
  },
  {
    "text": "graph as a whole, within each individual\nworkflow, we can have some of these relevant context information, either in\nthe prompt itself or in a retriever step",
    "start": "2421943",
    "end": "2429493"
  },
  {
    "text": "or other sorts of explicitly designed\nsteps, just so that the assistant can.",
    "start": "2429493",
    "end": "2435662"
  },
  {
    "text": "would be as helpful as possible within the\nexplicit context of the user providing.",
    "start": "2436903",
    "end": "2442583"
  },
  {
    "text": "A lot of what this does then is it takes\nthe burden off the user saying this is who I am, this is what I want, etc.",
    "start": "2443103",
    "end": "2449383"
  },
  {
    "text": "The  Assistant already knows because it's\ndemonstrates its initial attent Intent? Users navigated to a specific web\npage or something like that and then",
    "start": "2449993",
    "end": "2457753"
  },
  {
    "text": "it's able to fetch all that relevant\ncontext and bring it to the table. Okay, so the, the, the user then\ngoes through, eventually it lists out",
    "start": "2459213",
    "end": "2467043"
  },
  {
    "text": "the other the other possible flights\nand then updates it successfully. Great. Let's move on to the hotel booking one.",
    "start": "2467043",
    "end": "2473392"
  },
  {
    "text": "Okay. So once it does book it, it\ncalls this completed escalate. It goes back to the primary agent.",
    "start": "2473703",
    "end": "2479013"
  },
  {
    "text": "Remember in this completed\nescalate one, escalate step. It is a tool message that's injected\nsaying resuming dialogue with a host",
    "start": "2479013",
    "end": "2484563"
  },
  {
    "text": "assistant, the primary assistant here. Please reflect on that. So the user asks about\nlodging and transportation.",
    "start": "2484563",
    "end": "2490848"
  },
  {
    "text": "Great, so now it routes to\nthe hotel booking assistant. This is another specialized workflow.",
    "start": "2491058",
    "end": "2495987"
  },
  {
    "text": "In the enter step, we've\nadded this tool message. It says the assistant is here,\nreflects, continue to help, etc.",
    "start": "2496508",
    "end": "2501488"
  },
  {
    "text": "This just cues in this assistant again\nas to what it's supposed to be seeing. The AI then says this, it\ngoes through, tries to help.",
    "start": "2501548",
    "end": "2509088"
  },
  {
    "text": "Seems like it does a pretty good job. It's pretty good. Focused here. It sees that there's no explicit\nmid scale hotels, but there's an",
    "start": "2509498",
    "end": "2515378"
  },
  {
    "text": "upper mid skills here, here, and\nit's able to be doing these queries in the tool goes through this flow. We get to the car options here.",
    "start": "2515388",
    "end": "2522328"
  },
  {
    "text": "It looks like there's actually\na little bit of a hiccup in our design that we could improve. Again, since it's all modular,\neasier to make these improvements.",
    "start": "2522338",
    "end": "2528598"
  },
  {
    "text": "Once we do see them, it seems in\nthis case, the assistant didn't actually execute or finish once it\ndidn't make the booking, we could",
    "start": "2528608",
    "end": "2536388"
  },
  {
    "text": "actually do hard coded this in so\nthat we never run into this problem. So as soon as the booking is made,\nautomatically route back to the primary",
    "start": "2536388",
    "end": "2543103"
  },
  {
    "text": "assistant, and then it's all up to\nthat to decide who to route to next. Haven't put that in right now.",
    "start": "2543103",
    "end": "2547783"
  },
  {
    "text": "Ask about inspirations. It goes through, it doesn't get\nanything for location based services. Again, we can improve the\nprompt here if you want.",
    "start": "2548163",
    "end": "2554983"
  },
  {
    "text": "It's all very scoped and then\nit, you know, it's second search. It gets it a little bit better\nand then you get all this",
    "start": "2555273",
    "end": "2560483"
  },
  {
    "text": "information from the tools. Again, it's much more reliable than it was\nwhenever it was the full primary assistant",
    "start": "2560483",
    "end": "2565793"
  },
  {
    "text": "trying to interact with all these tools. It's going through, it goes\nthrough, it makes some reservations.",
    "start": "2565803",
    "end": "2571143"
  },
  {
    "text": "It succeeded in pretty much all\nthe tasks of this conversation. Alright, so where does this leave us?",
    "start": "2571333",
    "end": "2576803"
  },
  {
    "start": "2577000",
    "end": "2810000"
  },
  {
    "text": "We've built a travel assistant, starting\nfrom a simple zero shot agent with",
    "start": "2577203",
    "end": "2582503"
  },
  {
    "text": "tools that can engage in chat and\nhave memory and all those nice things. We then made the observation that actually\nthis agent shouldn't be fully autonomous.",
    "start": "2582543",
    "end": "2591253"
  },
  {
    "text": "The user should have a say as\nto whether it wants to take the actions that impact things. So then we added interrupt.",
    "start": "2591253",
    "end": "2596802"
  },
  {
    "text": "The user could go and Make a\nchange, accept or deny, do all",
    "start": "2597222",
    "end": "2602472"
  },
  {
    "text": "these types of things before\nthe assistant makes any actions. We made the observation that actually\nwe don't need these interrupts on all",
    "start": "2602472",
    "end": "2609722"
  },
  {
    "text": "the actions the agent takes, only on a\nset of sensitive ones that will change the data that the user cares about.",
    "start": "2609732",
    "end": "2615592"
  },
  {
    "text": "So then we designed our graph with two\ndifferent nodes, one with the sensitive tools, once with the safe tools.",
    "start": "2615832",
    "end": "2621692"
  },
  {
    "text": "We only interrupt on the sensitive\ntools, so we have the user the right to change those calls. After that we made the observation\nthat actually the assistant is",
    "start": "2621962",
    "end": "2629401"
  },
  {
    "text": "kind of unreliable in routing\nthese things and using the tools.",
    "start": "2629402",
    "end": "2634302"
  },
  {
    "text": "And so, if you're going to be a user\ncoming to it, or if you have thousands of users coming to your assistant every day,\nprobably a large number of them are going",
    "start": "2634712",
    "end": "2641661"
  },
  {
    "text": "to get results that don't make sense. Or if you're the same user doing\nit a couple of times, you'll have very inconsistent experiences.",
    "start": "2641662",
    "end": "2647732"
  },
  {
    "text": "And I think all of this leads to\na degraded experience as a whole. You also, the assistant also has to\nbe relearning all these things anytime",
    "start": "2647732",
    "end": "2657121"
  },
  {
    "text": "it's invoked, because it's not able\nto be gaining and optimizing for these explicit workflows separately.",
    "start": "2657122",
    "end": "2664381"
  },
  {
    "text": "So after that, when we split all these\nconcerns up into a separate, multi agent stage where you have the primary\nassistant delegate to different workflows",
    "start": "2665342",
    "end": "2674282"
  },
  {
    "text": "that you can create centered around\nexplicit known user journeys, booking",
    "start": "2674282",
    "end": "2680032"
  },
  {
    "text": "flights, booking cars, hotels, excursions. Then the top layer, you can just\nroute based on the user intent.",
    "start": "2680032",
    "end": "2688091"
  },
  {
    "text": "In this case, we used an LLM. You can use a simpler, cheaper method\nlike an embedding model as well, just to intent classify and route appropriately.",
    "start": "2688802",
    "end": "2695812"
  },
  {
    "text": "And then each workflow you can\ndesign and optimize in isolation. You can say once the user has demonstrated\nthey want to commit to buying a hotel, or",
    "start": "2696342",
    "end": "2704862"
  },
  {
    "text": "buying a flight, or renting a hotel What\nare the types of things we need to add to the prompt or the tools we need to do?",
    "start": "2704962",
    "end": "2710542"
  },
  {
    "text": "How can we optimize these to make\nthis experience as good as possible? And then once you're in these, as long\nas you have the escape hatch for it to go",
    "start": "2710552",
    "end": "2717032"
  },
  {
    "text": "back to the primary assistant, shift over\nto the other assistants, the user has a really consistent experience within that,\nbut while still allowing that flexibility",
    "start": "2717032",
    "end": "2725452"
  },
  {
    "text": "that these LLMs offer by sharing context\nalong the entire user journey, even if they do go through multiple flows.",
    "start": "2725452",
    "end": "2732022"
  },
  {
    "text": "I think this gives you something somewhat\nof the best of both worlds, where you can take advantage of the long context\nwindows and great reasoning ability, in",
    "start": "2733107",
    "end": "2742137"
  },
  {
    "text": "quotes, of LLMs by, by letting it go and\nmanage that conversational state rather",
    "start": "2742137",
    "end": "2747507"
  },
  {
    "text": "than explicitly tracking it too hard\nwhile still being able to put a lot of your dark knowledge and design and intent\naround your user journeys and your product",
    "start": "2747507",
    "end": "2757657"
  },
  {
    "text": "to good use through well defined flows. It also gives your user full control\non the actions that it cares about.",
    "start": "2757797",
    "end": "2764477"
  },
  {
    "text": "Letting your assistant automate\nwhat the user doesn't need to do. You can prime it with context.",
    "start": "2765077",
    "end": "2770367"
  },
  {
    "text": "So the user doesn't have to be\ninputting and staring at a blank blank box, wondering what kinds of\nquestions it can ask once you're in",
    "start": "2770377",
    "end": "2777877"
  },
  {
    "text": "specific flows, it can then save. These are the types of things it's\ndesigned to, to, to work on, et cetera.",
    "start": "2777877",
    "end": "2784427"
  },
  {
    "text": "So overall, I think this is a set of\ndesign patterns, a set of trade offs you",
    "start": "2784967",
    "end": "2790067"
  },
  {
    "text": "can make that can overall give you better\ncontrol over the experience of, of how a user interacts with your product and\nhelp eventually build much more reliable",
    "start": "2790067",
    "end": "2800347"
  },
  {
    "text": "chatbots that can assist both in Q and a\ntasks, but also in accomplishing actions",
    "start": "2800417",
    "end": "2806117"
  },
  {
    "text": "such as bookings checkouts, et cetera. So, that's all we have for today.",
    "start": "2806317",
    "end": "2811412"
  },
  {
    "start": "2810000",
    "end": "2828000"
  },
  {
    "text": "If you have any questions or comments,\nleave them in the comments below. Just as a reminder, I'm Will. We're going to be posting a lot more\nof this content about LangSmith,",
    "start": "2811682",
    "end": "2817272"
  },
  {
    "text": "about LangSmith, and all of the\nthings that we'll be developing. So, if you have any requests\non what you'd want to see, just",
    "start": "2817362",
    "end": "2823302"
  },
  {
    "text": "leave them in the comments. And see you later.",
    "start": "2823362",
    "end": "2825653"
  }
]
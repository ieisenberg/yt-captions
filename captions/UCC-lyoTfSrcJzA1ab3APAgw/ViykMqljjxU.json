[
  {
    "start": "0",
    "end": "215000"
  },
  {
    "text": "I'm incredibly excited to have Mich Kat catasta Perfect all right I nailed it I",
    "start": "5120",
    "end": "10920"
  },
  {
    "text": "lived in Italy for two years so I've got a pronunciation down a bit um here to chat about uh the repet",
    "start": "10920",
    "end": "16920"
  },
  {
    "text": "agent and really all things agent T related um so we'll do about 20 to 25",
    "start": "16920",
    "end": "22920"
  },
  {
    "text": "minutes of a fun chat and then we'll open it up for questions as well so if people have questions uh think of them throughout and we'll go around at the",
    "start": "22920",
    "end": "29320"
  },
  {
    "text": "end and on folks so maybe to get started um could you walk us through a little",
    "start": "29320",
    "end": "34680"
  },
  {
    "text": "bit of the history of rep agent how it came about what the idea for it was the timeline to launch which was three weeks",
    "start": "34680",
    "end": "41640"
  },
  {
    "text": "ago at this point and then maybe what's happened in the past three weeks as you went pretty viral I'd say yeah not much",
    "start": "41640",
    "end": "47920"
  },
  {
    "text": "sleep in the last few weeks also before the launch launch was September 5th so it has been a while all right so",
    "start": "47920",
    "end": "54399"
  },
  {
    "text": "timeline has been the following I started the AI team rapit in early 2023",
    "start": "54399",
    "end": "59440"
  },
  {
    "text": "and then I wrote the rep Manifesto maybe some of you wasted a few minutes reading that and back then I had this idea that",
    "start": "59440",
    "end": "67439"
  },
  {
    "text": "we saw the react paper we saw Lang chain growing and all the initial agentic workflows that you were offering your",
    "start": "67439",
    "end": "73000"
  },
  {
    "text": "framework and you know we realized okay we have a tremendous opportunity at rapid because all the tools and all the",
    "start": "73000",
    "end": "79600"
  },
  {
    "text": "devices are well orchestrated in that platform the only ingredient missing is an AI that really lowers the barrier of",
    "start": "79600",
    "end": "85880"
  },
  {
    "text": "Entry to software creation and allows basically everyone to build zero to one without writing a single line of code it",
    "start": "85880",
    "end": "93040"
  },
  {
    "text": "took us a while to get there I think it has been 15 months between me writing the manifesto and as launching the agent",
    "start": "93040",
    "end": "100159"
  },
  {
    "text": "and I would say things accelerated in the last few months in the sense that we build a lot of the foundation and",
    "start": "100159",
    "end": "105640"
  },
  {
    "text": "scolding uh throughout 2023 uh like we we included a stain machine inside our",
    "start": "105640",
    "end": "111439"
  },
  {
    "text": "chat server you know remember we we talk about it back in the days uh we started to expose some of our internal tools",
    "start": "111439",
    "end": "117520"
  },
  {
    "text": "with apis that were more amenable to beuse buy an llm and then in the last few months we basically made this big",
    "start": "117520",
    "end": "123520"
  },
  {
    "text": "bet of kind of ring a good chunk of the company Beyond RIT agent with possibly a",
    "start": "123520",
    "end": "129239"
  },
  {
    "text": "different take compared to most of the other coding agents that you see on the market uh our goal is to actually build",
    "start": "129239",
    "end": "136120"
  },
  {
    "text": "a product rather than a replacement for a junior software engineer I think both approaches are great you know I think",
    "start": "136120",
    "end": "142120"
  },
  {
    "text": "some some of them are targeting full autonomy uh rapit is more somewhere in between of the spectrum where we want",
    "start": "142120",
    "end": "148519"
  },
  {
    "text": "the user to be at the center of the product we want you to be engaged we show you what the agent does we ask you",
    "start": "148519",
    "end": "154800"
  },
  {
    "text": "questions we ask you for feedback and we found out that by building something more engaging we also probably address",
    "start": "154800",
    "end": "161560"
  },
  {
    "text": "one of the hardest problems in agents which is the fact that they make a lot of mistakes so if you trust them over a",
    "start": "161560",
    "end": "167239"
  },
  {
    "text": "long trajectory eventually they're going to either crash or not accomplish the goal that they in mind and we try",
    "start": "167239",
    "end": "173120"
  },
  {
    "text": "basically to recover that by asking the user often is this what you want shall we revert back shall we build something",
    "start": "173120",
    "end": "179360"
  },
  {
    "text": "different so that kind of balance seem to have excited a lot of our users and then the rest of History we launch early",
    "start": "179360",
    "end": "186280"
  },
  {
    "text": "September we saw way more people than I ever expected building with it to be honest and it has been very exciting to",
    "start": "186280",
    "end": "192640"
  },
  {
    "text": "receive feedback can you share any metrics on how many people have used it and what the usage looks like I don't",
    "start": "192640",
    "end": "198040"
  },
  {
    "text": "know if I'm all right all right I can tell you we had hundreds of thousands of",
    "start": "198040",
    "end": "203120"
  },
  {
    "text": "runs in production as you know because are using your services as well so yes I",
    "start": "203120",
    "end": "209560"
  },
  {
    "text": "think I think Alex on our infer team is very aware of that um you you talked a bunch about the",
    "start": "209560",
    "end": "215640"
  },
  {
    "start": "215000",
    "end": "330000"
  },
  {
    "text": "ux already which I think is one of the interesting Parts but how do you balance the uh you know it's kind of annoying if",
    "start": "215640",
    "end": "222879"
  },
  {
    "text": "the agent always asks you for more things and more things but it is good for it to ask you about something so how do you balance that kind of like",
    "start": "222879",
    "end": "228200"
  },
  {
    "text": "tradeoff between it asking you for some things but not not all the time yeah",
    "start": "228200",
    "end": "233560"
  },
  {
    "text": "yeah first of all very hard problem I will say a disclaimer I don't think we cracked it perfectly yet so we still get",
    "start": "233560",
    "end": "240799"
  },
  {
    "text": "some feedback sometimes we ask question that are considered to trial for some users uh in a sense you know what we do",
    "start": "240799",
    "end": "247680"
  },
  {
    "text": "is we have a lot of tools uh in the scope that you know one of our agents in",
    "start": "247680",
    "end": "252760"
  },
  {
    "text": "the multi- agent architecture we built can use and depending if we go like",
    "start": "252760",
    "end": "258000"
  },
  {
    "text": "straight to completing a step successfully or not uh then one of the tools that the agent can use is either",
    "start": "258000",
    "end": "264280"
  },
  {
    "text": "like taking screenshots or you know running static checks on the code executing and see if there are errors in",
    "start": "264280",
    "end": "269840"
  },
  {
    "text": "the console uh but last but not least if we see that no progress is being made then kind of as a last resort we go back",
    "start": "269840",
    "end": "276800"
  },
  {
    "text": "to the user and ask you know given this eror that we're seeing can maybe try the web application with these inputs and",
    "start": "276800",
    "end": "283120"
  },
  {
    "text": "tell us you know what are the issues there uh I think we get it right most of the times but and and is that a tool",
    "start": "283120",
    "end": "290280"
  },
  {
    "text": "that the agent can call basically like ask human input as a tool and then it's prompt engineering to get it there or do you do things like hey if it's run for",
    "start": "290280",
    "end": "296759"
  },
  {
    "text": "like a minute let's like ask the human no matter what more kind of like deterministically everything you said",
    "start": "296759",
    "end": "302000"
  },
  {
    "text": "plus it's also a sub agent so we have a verifier tool that we invoke in specific",
    "start": "302000",
    "end": "307600"
  },
  {
    "text": "occasions we also have a this multi-agent team that has a manager it has editors pretty much like in any",
    "start": "307600",
    "end": "314320"
  },
  {
    "text": "software team in the real world and we also have a verifier that is allowed basically to go through the app and you",
    "start": "314320",
    "end": "319720"
  },
  {
    "text": "know interact to it to a certain extent and yeah last but not list we basically",
    "start": "319720",
    "end": "324800"
  },
  {
    "text": "collect all the outputs from Tool and that like gives us a glimpse of what is going on in the application",
    "start": "324800",
    "end": "330880"
  },
  {
    "start": "330000",
    "end": "435000"
  },
  {
    "text": "let's talk about the multi-agent stuff a little bit more because I think that's really interesting how how do you arrive at that and what's yeah what are the",
    "start": "330880",
    "end": "338160"
  },
  {
    "text": "different agents and what's different about them is it the prompts is it the tools they have all like yeah yeah so we",
    "start": "338160",
    "end": "344479"
  },
  {
    "text": "have this we first of all we built a mulen architecture for possibly what is very well known by now in the community",
    "start": "344479",
    "end": "350120"
  },
  {
    "text": "it's very important to in a sense like separate the scope make sure that agents",
    "start": "350120",
    "end": "355840"
  },
  {
    "text": "every sub agent has the least possible amount of tools visible and and also the least possible amount of instructions",
    "start": "355840",
    "end": "362680"
  },
  {
    "text": "and the the rational behind it is very easy the more you expose to a sub agent the more opportunities it has to make",
    "start": "362680",
    "end": "368960"
  },
  {
    "text": "the wrong choice and did you did you start from this and you kind of okay so yeah what what was the what did you",
    "start": "368960",
    "end": "374759"
  },
  {
    "text": "start with and how did you how did you arrive there we started with the simplest possible architecture which is",
    "start": "374759",
    "end": "380840"
  },
  {
    "text": "react um and the reason is I think everyone agrees that is the simplest and",
    "start": "380840",
    "end": "386800"
  },
  {
    "text": "I would say the first step that everyone takes when building an agent and then we started to explore how to",
    "start": "386800",
    "end": "391960"
  },
  {
    "text": "integrate different tools and the moment we had too many tools and we start to see too many errors then we realize okay",
    "start": "391960",
    "end": "397720"
  },
  {
    "text": "maybe now we need to step up our architecture um I knew about multi agents I've been reading also your blog",
    "start": "397720",
    "end": "403759"
  },
  {
    "text": "post and all the re research papers I think there is value in building things incrementally like that's why I'm most",
    "start": "403759",
    "end": "410160"
  },
  {
    "text": "excited about what you're doing with Lang graph like in a sense you can plug or change your architecture like in a few lines of code and see what pays off",
    "start": "410160",
    "end": "417560"
  },
  {
    "text": "I'm I'm not a maximum list of multi- agent architectures I think they make sense for some tasks but I know a lot of",
    "start": "417560",
    "end": "424400"
  },
  {
    "text": "startups out there that have basic agents deployed that are extremely successful and Powerful so I would say",
    "start": "424400",
    "end": "430479"
  },
  {
    "text": "the right architecture comes with a with a specific requirements that you have that makes sense you talked about tools",
    "start": "430479",
    "end": "437280"
  },
  {
    "start": "435000",
    "end": "625000"
  },
  {
    "text": "a few times and tools are obviously really important for agents what are the tools that your agents have access to",
    "start": "437280",
    "end": "443879"
  },
  {
    "text": "and how do they call those tools all right so we have pretty much every tool",
    "start": "443879",
    "end": "449080"
  },
  {
    "text": "that you use use on a daily basis as a as a developer uh we expose them to our agent so everything that you find today",
    "start": "449080",
    "end": "455680"
  },
  {
    "text": "in Rapid has literally in our tool panel how many of those did you have before because you're repl and you have all",
    "start": "455680",
    "end": "462080"
  },
  {
    "text": "these things versus writing from scratch for agents specifically we basically had maybe 90% of them already uh some of",
    "start": "462080",
    "end": "469800"
  },
  {
    "text": "them were almost there we never thought of wrapping them as tools they were like somewhere hidden in the code base and",
    "start": "469800",
    "end": "475680"
  },
  {
    "text": "they didn't have a clear API and we just had to make like the additional lift to to expose them as an API but overall",
    "start": "475680",
    "end": "481560"
  },
  {
    "text": "like rapid has been built over the last Almost 8 years at this point so all those tools existed the challenge is not",
    "start": "481560",
    "end": "488479"
  },
  {
    "text": "at least in our case to build the tools is how do you expose them and how you you orchestrate them with ANM and there",
    "start": "488479",
    "end": "494080"
  },
  {
    "text": "is this field that thing that this we agent paper calls ACI so the agent computer interface that I hope is going",
    "start": "494080",
    "end": "500319"
  },
  {
    "text": "to be flourishing more and more because the real challenge again is not building a tool that is reliable at the end of",
    "start": "500319",
    "end": "506720"
  },
  {
    "text": "the day tools are softer I think we know very much how to be Reliable Software but today is actually how to make",
    "start": "506720",
    "end": "512919"
  },
  {
    "text": "reliable the interface between the llm and the tool per se what what does that mean exactly like what specifically did",
    "start": "512919",
    "end": "518800"
  },
  {
    "text": "you guys do for that so we started from function calling like I pretty much every everyone does out there uh the",
    "start": "518800",
    "end": "525720"
  },
  {
    "text": "function goaling apis either from open a on Tropic at this point are fairly elegant and easy to use the truth is",
    "start": "525720",
    "end": "531920"
  },
  {
    "text": "they're also fairly limited and for those of you who went through the Pains",
    "start": "531920",
    "end": "536959"
  },
  {
    "text": "of making function cing more reliable I'm sure you have seen all these tricks where you should reorder the the way in",
    "start": "536959",
    "end": "543959"
  },
  {
    "text": "which arguments appear maybe you should rename in such a way that you kind of invite the llm to reason before they",
    "start": "543959",
    "end": "550240"
  },
  {
    "text": "actually create the function call and it turns out that we try to push the envelope in that direction as much as",
    "start": "550240",
    "end": "555839"
  },
  {
    "text": "possible we kept hitting walls until we took a complete the tour and we decided",
    "start": "555839",
    "end": "561320"
  },
  {
    "text": "to invoke tools with code and the reason is llms are amazing at generating code I",
    "start": "561320",
    "end": "567320"
  },
  {
    "text": "don't have to convince anyone about that so rather than going through the function calling we decided okay we give",
    "start": "567320",
    "end": "573880"
  },
  {
    "text": "uh like all the information needed to the model in the context we ask it to reason so we go through like a long",
    "start": "573880",
    "end": "578920"
  },
  {
    "text": "Chain of Thought whenever needed and then the Last Action that the model takes is actually generating a python",
    "start": "578920",
    "end": "584959"
  },
  {
    "text": "DSL like this literally a strip down version of python that we parse on our backand and then if it's compliant we",
    "start": "584959",
    "end": "592200"
  },
  {
    "text": "know that that's a valid tool invocation and if it's not we keep retrying uh we made that way more reliable before I",
    "start": "592200",
    "end": "599800"
  },
  {
    "text": "think I don't know the exact numbers are now but we are literally surely about 90% U success rate success rate of",
    "start": "599800",
    "end": "607560"
  },
  {
    "text": "generating a valid tool call yeah especially because our tools are not easy to invoke like some of them of",
    "start": "607560",
    "end": "613040"
  },
  {
    "text": "course you know we have one argument tools like everyone else uh but some other tools are fairly complicated have",
    "start": "613040",
    "end": "618640"
  },
  {
    "text": "a lot of arguments a lot of different settings so it wasn't viable to just do function calling what do you do when it",
    "start": "618640",
    "end": "625240"
  },
  {
    "start": "625000",
    "end": "717000"
  },
  {
    "text": "generates a tool call that's not valid we retry",
    "start": "625240",
    "end": "631200"
  },
  {
    "text": "and luckily Sonet seems to be very powerful we we have a couple of okay let",
    "start": "631200",
    "end": "636560"
  },
  {
    "text": "me talk about the other fullback solutions to be honest retries goes up very very far most of the times and and",
    "start": "636560",
    "end": "642720"
  },
  {
    "text": "retry is just like straight retry with no changes to the prompt or do you pass back in like the air message we pass back yeah what happens so like most of",
    "start": "642720",
    "end": "649040"
  },
  {
    "text": "the times even from that basic self debugging it already understands how to make progress uh but as some of you told",
    "start": "649040",
    "end": "655480"
  },
  {
    "text": "us already on X through your feedback uh I would be ly to if I told rapid agent never get stuck especially when we",
    "start": "655480",
    "end": "661680"
  },
  {
    "text": "launch it we found a completely new class of errors that we never thought about before uh so thanks again for the",
    "start": "661680",
    "end": "667920"
  },
  {
    "text": "feedback now I think we're in a better place uh but at the same time you know there are situations in which the the",
    "start": "667920",
    "end": "675120"
  },
  {
    "text": "tool usage is wrong and then we brought in uh reflection as a technique which",
    "start": "675120",
    "end": "681639"
  },
  {
    "text": "basically allows us to attempt a few steps and then we stop every at this",
    "start": "681639",
    "end": "687480"
  },
  {
    "text": "point I think every five steps depending on Define steps in our agent and we should talk about trajectory land after",
    "start": "687480",
    "end": "693000"
  },
  {
    "text": "I think it's it's going to be fun uh but like every few steps we stop the word and then we ask the agent to reason if",
    "start": "693000",
    "end": "699600"
  },
  {
    "text": "it actually made progress or not and that's another basically recovery strategy where we have where even",
    "start": "699600",
    "end": "705800"
  },
  {
    "text": "without user feedback we roll back to a previous state and we restart and that usually adds enough Randomness to the",
    "start": "705800",
    "end": "712519"
  },
  {
    "text": "process that allows us to go down a different path and actually succeed let's talk about trajectory length since",
    "start": "712519",
    "end": "718279"
  },
  {
    "start": "717000",
    "end": "865000"
  },
  {
    "text": "you brought it up how like what's going on beside behind the scenes how many llm calls how many tool calls how long how",
    "start": "718279",
    "end": "725360"
  },
  {
    "text": "long does it take on average all right so trajectories are",
    "start": "725360",
    "end": "730760"
  },
  {
    "text": "definitely in the order of tons of steps um we have seen several of them going",
    "start": "730760",
    "end": "735800"
  },
  {
    "text": "over the ands it really depends how I would say stubborn or affectionate the",
    "start": "735800",
    "end": "741040"
  },
  {
    "text": "user is depending on the point of view and I I'm excited because we saw some people spending hours on a single",
    "start": "741040",
    "end": "747639"
  },
  {
    "text": "project with the agent and the agent actually accomplishing what they wanted so that that that feels really awesome it's not",
    "start": "747639",
    "end": "752880"
  },
  {
    "text": "always the case but we're actually getting there the shortcoming of longer trajectories of course is the fact that",
    "start": "752880",
    "end": "759399"
  },
  {
    "text": "you need to keep to represent in memory useful information in order not to get",
    "start": "759399",
    "end": "765000"
  },
  {
    "text": "the agent completely lost so you need to retain part of what happened in the past without the overwhelming the agent with",
    "start": "765000",
    "end": "771680"
  },
  {
    "text": "unnecessary memories so the crck of long trajectories is memory management which",
    "start": "771680",
    "end": "776959"
  },
  {
    "text": "is like a very hard problem that I don't think anyone in the field has still cracked completely but the moment we get",
    "start": "776959",
    "end": "783240"
  },
  {
    "text": "there I expect trajectories to become like even more ambitious in terms of land and and so right now like what does",
    "start": "783240",
    "end": "789399"
  },
  {
    "text": "memory management look like for you guys is it simply the last 10 steps and you pass those in or is there some smarter",
    "start": "789399",
    "end": "795720"
  },
  {
    "text": "tics on the back end yeah we have quite a lot of tics definitely there are some tration criterias you manage you know we",
    "start": "795720",
    "end": "802360"
  },
  {
    "text": "we try not to keep you know the entirety of The Memories We compress memories uh both in terms of like past steps that",
    "start": "802360",
    "end": "809120"
  },
  {
    "text": "appear not to be relevant any longer also when we jump between one subed into another the way in which we compress we",
    "start": "809120",
    "end": "816680"
  },
  {
    "text": "compress memory results in that case uh whenever we succeed in a in a step of our plan we basically compress that",
    "start": "816680",
    "end": "823720"
  },
  {
    "text": "memory even further and then just have like a high level description of what happened in the past so we have all these bag of tricks that we applied in",
    "start": "823720",
    "end": "830680"
  },
  {
    "text": "order like to have more reliable longer trajectories uh the truth is even if you",
    "start": "830680",
    "end": "836399"
  },
  {
    "text": "have a very high probability of success on a single agent step if you just you know compute the compound probability",
    "start": "836399",
    "end": "842639"
  },
  {
    "text": "you will see that the reliability drops very quickly after like 50 steps so I",
    "start": "842639",
    "end": "848440"
  },
  {
    "text": "would say the main Insight that we use in Rapid agent was to do as much progress as we could in the first few",
    "start": "848440",
    "end": "854279"
  },
  {
    "text": "steps H that is possibly the best recipe to avoid the you know the the his of",
    "start": "854279",
    "end": "860399"
  },
  {
    "text": "long trajectories actually not to allow a user to go that far you you mentioned",
    "start": "860399",
    "end": "865720"
  },
  {
    "start": "865000",
    "end": "945000"
  },
  {
    "text": "a few pretty complex things or things that you iterated on so like the generating tool calls as code the memory",
    "start": "865720",
    "end": "872360"
  },
  {
    "text": "management these long trajectories who how do you come up with these kind of like ideas like for the",
    "start": "872360",
    "end": "878040"
  },
  {
    "text": "prompt engineering of putting things as function calls one like yeah how did you came up with that what who's who's doing",
    "start": "878040",
    "end": "883839"
  },
  {
    "text": "the prompt engineering we hear you know is it is it Engineers is it subject matter experts in this case they're are they the same Persona so it's the same",
    "start": "883839",
    "end": "890519"
  },
  {
    "text": "people doing both curious what that prompt Engineering Process looks like you'd be surprised how small is the team",
    "start": "890519",
    "end": "897040"
  },
  {
    "text": "that actually work on that I think half of them are in in this room today but I would say we wear both hats",
    "start": "897040",
    "end": "903839"
  },
  {
    "text": "so they are like very good Engineers they also have a good understanding of how llms work and like I come from a",
    "start": "903839",
    "end": "910680"
  },
  {
    "text": "background of training very large model so hopefully sometimes I bring in like some good insights and last but not",
    "start": "910680",
    "end": "916440"
  },
  {
    "text": "least I love the fact that the agent Community is building mostly in public like including you guys you know body",
    "start": "916440",
    "end": "922240"
  },
  {
    "text": "quality of the documentation you you publish and uh the fact that a lot of these recipes are already in your code",
    "start": "922240",
    "end": "927959"
  },
  {
    "text": "base basically allows us to be a bit more relaxed in terms of thinking like at this point it's more about cherry",
    "start": "927959",
    "end": "934399"
  },
  {
    "text": "picking what we think works well rather than having to come up with new techniques I think all the ideas are out",
    "start": "934399",
    "end": "939959"
  },
  {
    "text": "there it's more about Discerning which ones are good or not good for our specific work you mentioned that you",
    "start": "939959",
    "end": "946959"
  },
  {
    "start": "945000",
    "end": "1073000"
  },
  {
    "text": "have a background in model training and and that these agents often have you know tens of steps what uh to the extent",
    "start": "946959",
    "end": "953839"
  },
  {
    "text": "that you can say like what do the models look like that you're using under the hood are they ones that You' fine-tuned yourself are they off shelf ones are you",
    "start": "953839",
    "end": "960040"
  },
  {
    "text": "primarily with one model provider or swapping around between a bunch of them so at the beginning we tried a lot of",
    "start": "960040",
    "end": "966800"
  },
  {
    "text": "different things including F tuning Frontier models and right now we are",
    "start": "966800",
    "end": "972199"
  },
  {
    "text": "mostly relying on cloud 3.5 sunet uh which we find to be awesome in terms of",
    "start": "972199",
    "end": "978560"
  },
  {
    "text": "anything code generation and code editing uh it seems to be like a step function Improvement compared to other",
    "start": "978560",
    "end": "984639"
  },
  {
    "text": "models for these specific tasks so yeah most of our llm calls go there then you",
    "start": "984639",
    "end": "991279"
  },
  {
    "text": "know we have a long tail of calls to for mini for compression or like for other Watch Dog Works and we we tried also we",
    "start": "991279",
    "end": "999000"
  },
  {
    "text": "have some other fine tuning that we do also on our embedding model like to retrieve the the right data from the fat",
    "start": "999000",
    "end": "1004399"
  },
  {
    "text": "system but I would say the staple right now is working with 3.5 onet we get",
    "start": "1004399",
    "end": "1009800"
  },
  {
    "text": "asked a bunch about the trade-off between like accuracy and cost and latency so how did you think about that",
    "start": "1009800",
    "end": "1015759"
  },
  {
    "text": "when you were developing repet agent M rank them uh accuracy by far um cost",
    "start": "1015759",
    "end": "1024918"
  },
  {
    "text": "otherwise eventually we're going to go broke and latency last I I know that",
    "start": "1024919",
    "end": "1030959"
  },
  {
    "text": "maybe this is not going to make some users happy because at this point we we we as a community not we only as a rep",
    "start": "1030959",
    "end": "1036720"
  },
  {
    "text": "agent we keep raising the bar like on a weekly basis people want things to get done magically and always faster always",
    "start": "1036720",
    "end": "1043160"
  },
  {
    "text": "more efficiently the truth is like optimizing the triangle as of today is pretty much impossible so I would say",
    "start": "1043160",
    "end": "1050160"
  },
  {
    "text": "I'm happy to trade latency in exchange of much higher accuracy I would say that is by far what makes the user most",
    "start": "1050160",
    "end": "1056160"
  },
  {
    "text": "frustrated and then of course cost eventually will play a big role but we all are making the assumption that",
    "start": "1056160",
    "end": "1062280"
  },
  {
    "text": "Frontier models will become cheaper and then when the next generational model comes out for Omni or son it will be so",
    "start": "1062280",
    "end": "1069360"
  },
  {
    "text": "cheap that agents would be way more affordable um you've talked about a",
    "start": "1069360",
    "end": "1074840"
  },
  {
    "start": "1073000",
    "end": "1203000"
  },
  {
    "text": "bunch of complex things happening beside behind the scenes how do you debug what's going wrong in these agents and",
    "start": "1074840",
    "end": "1080880"
  },
  {
    "text": "before this I'm cheating a little bit CU you told me a fun story about how some people were debugging things on your team but yeah what is that what does",
    "start": "1080880",
    "end": "1086960"
  },
  {
    "text": "that process look like yeah so we we adopted Langs me very early I think you know maybe the the first month that we",
    "start": "1086960",
    "end": "1094039"
  },
  {
    "text": "were betting on the agent you know I immediately uh brought up the requirement in the team that we need a",
    "start": "1094039",
    "end": "1099520"
  },
  {
    "text": "way to observe the agent Behavior this wasn't intended to be a promo there's actually a much cooler story that he's",
    "start": "1099520",
    "end": "1105000"
  },
  {
    "text": "going to tell shortly which is what I'm really interest the story the story is coming but also as a personal recommendation don't start to do any Ser",
    "start": "1105000",
    "end": "1112200"
  },
  {
    "text": "agent work without any level of observability uh every person who build any system like distributed systems",
    "start": "1112200",
    "end": "1118480"
  },
  {
    "text": "whatever that is um they will all tell you exactly the same War Stories if you don't have a way to observe how your",
    "start": "1118480",
    "end": "1123960"
  },
  {
    "text": "system behaves you're basically just building a prototype the moment you go in production you're going to regret not",
    "start": "1123960",
    "end": "1129240"
  },
  {
    "text": "having a way to poke into the into the system so the we needed exactly the same",
    "start": "1129240",
    "end": "1134280"
  },
  {
    "text": "when we started to build the agent so we we jump on LM right away because we're already using lra and uh we basically",
    "start": "1134280",
    "end": "1141720"
  },
  {
    "text": "grew into that and we had to learn how to use it you know just it's much different compared to any other",
    "start": "1141720",
    "end": "1147600"
  },
  {
    "text": "observability tool out there also back in the days our traces were much shorter like our needs kept growing the the more",
    "start": "1147600",
    "end": "1154400"
  },
  {
    "text": "powerful the agent became uh one trick that we have been using uh recently that I found very exciting is in the lmid",
    "start": "1154400",
    "end": "1162640"
  },
  {
    "text": "tray at every single step of the agent you know we're basically storing the state like the entire state of what has",
    "start": "1162640",
    "end": "1167799"
  },
  {
    "text": "been going on at the step so when someone reports a bug rather than just",
    "start": "1167799",
    "end": "1173520"
  },
  {
    "text": "literally like reading the entire trace and trying to figure out where things went wrong first of all we pinpoint at",
    "start": "1173520",
    "end": "1179559"
  },
  {
    "text": "which Step the issue has happened and then we Replay that tras on a new code base where we try to fix the bug and see",
    "start": "1179559",
    "end": "1185880"
  },
  {
    "text": "if the agent behaves differently and we do this fully automatically like we go to L to the ls made API we pull the",
    "start": "1185880",
    "end": "1191720"
  },
  {
    "text": "trace we load it as a state and then like we canot replay it so I think this is the future how you build",
    "start": "1191720",
    "end": "1199240"
  },
  {
    "text": "agents in production otherwise the debugging is excruciating yeah I I think this I think",
    "start": "1199240",
    "end": "1205360"
  },
  {
    "text": "this replaying is really cool ux we added it into L graph studio natively um",
    "start": "1205360",
    "end": "1210720"
  },
  {
    "text": "but it's also possible to recreate from Ling Smith logs which I learned earlier today so there go that's good um I guess",
    "start": "1210720",
    "end": "1217559"
  },
  {
    "text": "I have no clue what time it is but last question before we maybe turn it over to some audience questions um you what are",
    "start": "1217559",
    "end": "1224880"
  },
  {
    "text": "some of the things that rep agent is really good at today and what are some of the future directions where you hope to take it yeah so for the initial",
    "start": "1224880",
    "end": "1232520"
  },
  {
    "text": "launch we focus on0 to one software creation that's what we are excited about as the target user base that we",
    "start": "1232520",
    "end": "1239440"
  },
  {
    "text": "have in mind people that are creative they have an idea about what they want to build and they want to see the",
    "start": "1239440",
    "end": "1244840"
  },
  {
    "text": "prototype in front of the r as quickly as possible and we talk about AI first coders which means not necessarily",
    "start": "1244840",
    "end": "1252120"
  },
  {
    "text": "people that don't know at all how to code but they rather spend time prompting rather than getting their hands dirty in the code so we're doing",
    "start": "1252120",
    "end": "1259679"
  },
  {
    "text": "fairly well there and I think we kind of created this magical experience where like in 90 seconds you see the first",
    "start": "1259679",
    "end": "1265159"
  },
  {
    "text": "prototype of the app in front of your eyes and we focus mostly on web applications but you know you can also",
    "start": "1265159",
    "end": "1271440"
  },
  {
    "text": "build like standard python apps and scripts and what not we are still not",
    "start": "1271440",
    "end": "1277200"
  },
  {
    "text": "very good at working on pre-existing projects we have the technology to make that happen but in honesty I think at",
    "start": "1277200",
    "end": "1284840"
  },
  {
    "text": "least I learned the hard way in life that it's always better to launch something narrower scope and learn from the users",
    "start": "1284840",
    "end": "1291559"
  },
  {
    "text": "and you know gradually had more features rather than dropping something is very generic and is going to get even more",
    "start": "1291559",
    "end": "1297960"
  },
  {
    "text": "backlash that's a that's a really common Trend we see as well like scope it down so you can get it out the door and then see how people actually use it because",
    "start": "1297960",
    "end": "1304240"
  },
  {
    "start": "1298000",
    "end": "1380000"
  },
  {
    "text": "they might use it in ways that you didn't even anticipate which we discovered very quickly after launch actually yeah to that point like yeah",
    "start": "1304240",
    "end": "1310360"
  },
  {
    "text": "what was one of the funnier things or most unexpected things you discovered about how people would use it I would",
    "start": "1310360",
    "end": "1315559"
  },
  {
    "text": "say most unexpected is that we have a mobile app that tries basically to offer",
    "start": "1315559",
    "end": "1320840"
  },
  {
    "text": "the same features we have on the desktop app and we have way more runs than we ever expected on the phone uh a lot of",
    "start": "1320840",
    "end": "1327240"
  },
  {
    "text": "people love like to pull out the rabit and build it up in two minutes and brag about it with their friends or like even",
    "start": "1327240",
    "end": "1332440"
  },
  {
    "text": "use it on the spot uh that was well by far the the thing that that I love the most and the other one is also seeing",
    "start": "1332440",
    "end": "1339400"
  },
  {
    "text": "the variance between how people Express themselves when they create the initial prompt uh some are very concise and ter",
    "start": "1339400",
    "end": "1346960"
  },
  {
    "text": "and to be honest also fairly ambiguous so it kind of shows that there is a user base out there that never spend time",
    "start": "1346960",
    "end": "1352880"
  },
  {
    "text": "learning how to do prompt engineering which totally makes sense because not everyone is in Ai and on the on the flip",
    "start": "1352880",
    "end": "1358760"
  },
  {
    "text": "side we also have people that are very Thor when it comes to giving instructions to the extent that they",
    "start": "1358760",
    "end": "1364240"
  },
  {
    "text": "copy paste entire markdown files and sometimes it works spectacularly well uh",
    "start": "1364240",
    "end": "1370840"
  },
  {
    "text": "sometimes they're asking things are like fly impossible for the agent to pull off so we we end up ignoring most of the",
    "start": "1370840",
    "end": "1375880"
  },
  {
    "text": "instructions but yeah that's that's what happens with Early Access program all right so everyone's going to go copy",
    "start": "1375880",
    "end": "1381360"
  },
  {
    "start": "1380000",
    "end": "1537000"
  },
  {
    "text": "paste markdown files of instructions please let me know um any questions in",
    "start": "1381360",
    "end": "1386760"
  },
  {
    "text": "the audience uh yes I saw Rex first and I'll probably repeat the question for",
    "start": "1386760",
    "end": "1391799"
  },
  {
    "text": "the microphone but uh feel free to speak loudly yeah Rex here from.com I've",
    "start": "1391799",
    "end": "1399480"
  },
  {
    "text": "played with repl agent it's great one of the things I noticed really quickly is like once you start to get somewhat more",
    "start": "1399480",
    "end": "1405039"
  },
  {
    "text": "complex you can start to see this like notion of the of it like really emerged it would tell",
    "start": "1405039",
    "end": "1410919"
  },
  {
    "text": "me things like oh our Engineers are looking into it I'll get back to you right and take no action unless I don't",
    "start": "1410919",
    "end": "1418559"
  },
  {
    "text": "know you have your guys you know behind theen now we're not enough people to do",
    "start": "1418559",
    "end": "1424120"
  },
  {
    "text": "that TR my question is like as you've gotten more advanced in these agents like how have you thought about the tradeoff of",
    "start": "1424120",
    "end": "1429960"
  },
  {
    "text": "like the sft helpfulness of these models and like the risk of maybe like to me it",
    "start": "1429960",
    "end": "1435200"
  },
  {
    "text": "felt like you didn't know what action to take so you took none and pretended you were being helpful like have you thought",
    "start": "1435200",
    "end": "1440240"
  },
  {
    "text": "about that trade as you get more more complex repeating the question for the",
    "start": "1440240",
    "end": "1445559"
  },
  {
    "text": "mic have you thought about the trade-off between the sft helpfulness of the model versus taking action as the especially",
    "start": "1445559",
    "end": "1451720"
  },
  {
    "text": "as they get more complex yeah we we did we are getting a lot of feedback about the fact that the",
    "start": "1451720",
    "end": "1457600"
  },
  {
    "text": "agent talks about the team and that's why I like to be very public about the fact that it's a multi- agent system and",
    "start": "1457600",
    "end": "1462919"
  },
  {
    "text": "we design it as a team so as you know it's it's going to be impossible for us to hide that aspect comp completely to",
    "start": "1462919",
    "end": "1469080"
  },
  {
    "text": "be honest I don't even want to hide it like I think so when it says the engineers are working on it that's the other agent engineer it's it's the other",
    "start": "1469080",
    "end": "1476039"
  },
  {
    "text": "agent Engineers it's not rapid Engineers again our team is too small to pull that off I wish we could but no we're not",
    "start": "1476039",
    "end": "1482679"
  },
  {
    "text": "Outsourcing anything to to humans uh so that being said that is that is happening by means of us prompting the",
    "start": "1482679",
    "end": "1489520"
  },
  {
    "text": "the system in that way uh the the trade off I I don't think there is any way for",
    "start": "1489520",
    "end": "1495000"
  },
  {
    "text": "us to overcome it today because ultimately we're relying on Frontier models where there is a lot of SF and or",
    "start": "1495000",
    "end": "1500960"
  },
  {
    "text": "lhf happening U I would say the issue that you experience and I really hope is",
    "start": "1500960",
    "end": "1506960"
  },
  {
    "text": "mostly due to a bug rather than has deciding to be inactive so we don't have any logic in the agent that says if I",
    "start": "1506960",
    "end": "1514159"
  },
  {
    "text": "don't know what to do I'm going to be passive and just ghost the user it it just happens and you know we",
    "start": "1514159",
    "end": "1521360"
  },
  {
    "text": "are we keep making progress especially on longer trajectories sometime the the thinking time is way too long um and",
    "start": "1521360",
    "end": "1528120"
  },
  {
    "text": "that's that's why you it appears to be inactive but most likely you hit a bug rather than us deciding that we didn't",
    "start": "1528120",
    "end": "1534440"
  },
  {
    "text": "want to make progress uh another question right here",
    "start": "1534440",
    "end": "1539760"
  },
  {
    "start": "1537000",
    "end": "1632000"
  },
  {
    "text": "uh how did you guys think you think about evals in this seems like lots of EV here how did you think about",
    "start": "1539760",
    "end": "1546240"
  },
  {
    "text": "evals I love evals but we have such a lack of good evals in this space um of",
    "start": "1546240",
    "end": "1553080"
  },
  {
    "text": "course like everyone we we tried uh to use webench to an extent and it",
    "start": "1553080",
    "end": "1558679"
  },
  {
    "text": "definitely helped us to test the the core Loop of the agent like as I mentioned before our main core Loop is",
    "start": "1558679",
    "end": "1564240"
  },
  {
    "text": "like a variation of react so pretty much what everyone else is is doing out there for coding agents it it helped us to",
    "start": "1564240",
    "end": "1571320"
  },
  {
    "text": "debug only that part of the system but it doesn't really help to test end to end the entire experience of RIT agent",
    "start": "1571320",
    "end": "1578440"
  },
  {
    "text": "we are we built parts of the valve the ideal EV Val that we have in mind uh",
    "start": "1578440",
    "end": "1584000"
  },
  {
    "text": "honestly like I think many other launches are there I don't I'm not ashamed to say that we launch also So based on Vibes so we use it a lot",
    "start": "1584000",
    "end": "1590520"
  },
  {
    "text": "internally uh we felt that it was good enough and we made it very clear that it's early access so we tell people that",
    "start": "1590520",
    "end": "1596600"
  },
  {
    "text": "the product is limited and I think you all guys are helping us to to evolve",
    "start": "1596600",
    "end": "1601720"
  },
  {
    "text": "there is a near-term future where our verifier sub agent is going to become even more powerful and then we're going",
    "start": "1601720",
    "end": "1607360"
  },
  {
    "text": "to try to mimic the same actions that the user does on the on the artifact that we create directly through the AI",
    "start": "1607360",
    "end": "1614080"
  },
  {
    "text": "but it's it's hard for me to think of that as a public eval that the entire industry is going to agree upon um I",
    "start": "1614080",
    "end": "1621840"
  },
  {
    "text": "wish someone in Academia is thinking of working on that because I think would be an amazingly useful contribution or even",
    "start": "1621840",
    "end": "1628600"
  },
  {
    "text": "as a company it doesn't have to be coming from Academia necessarily another question",
    "start": "1628600",
    "end": "1634279"
  },
  {
    "start": "1632000",
    "end": "1716000"
  },
  {
    "text": "swix yo ag",
    "start": "1634279",
    "end": "1640200"
  },
  {
    "text": "ag yeah we we look at them I would say we try to strike a balance between being too simplistic so like the initial react",
    "start": "1641120",
    "end": "1648240"
  },
  {
    "text": "only Loop and then going towards an architecture that require like too much message passing between too many agents",
    "start": "1648240",
    "end": "1654600"
  },
  {
    "text": "so I think right now having like three or four of them makes it still relatively easy also to debug like right",
    "start": "1654600",
    "end": "1661360"
  },
  {
    "text": "now in a lot of our traces we see that the manager is handing over the the editor and the editor is doing a series",
    "start": "1661360",
    "end": "1666880"
  },
  {
    "text": "of actions and then the verifier kicks in so for us as debug human debuggers on the other side it's fairly easy to",
    "start": "1666880",
    "end": "1673760"
  },
  {
    "text": "understand what is going on I'm afraid that if we had even more complexity and we make this warm even bigger we will",
    "start": "1673760",
    "end": "1679880"
  },
  {
    "text": "kind of lose control of what the agent what our architecture does I do think we need the next level of accuracy and",
    "start": "1679880",
    "end": "1687600"
  },
  {
    "text": "instruction following from Models to go in that direction but but big game from",
    "start": "1687600",
    "end": "1693360"
  },
  {
    "text": "just one AG very big gain yes yeah like having a",
    "start": "1693360",
    "end": "1699039"
  },
  {
    "text": "catchall agent with all the tools in scope and a very generic system prompt I",
    "start": "1699039",
    "end": "1704679"
  },
  {
    "text": "think it's a recipe for disaster it helps you to build up to certain extent but the moment you need to build",
    "start": "1704679",
    "end": "1710399"
  },
  {
    "text": "something as complicated as a coding agent uh you're going to hit the ceiling very",
    "start": "1710399",
    "end": "1716360"
  },
  {
    "start": "1716000",
    "end": "1831000"
  },
  {
    "text": "quickly question right there yeah thank",
    "start": "1716360",
    "end": "1723799"
  },
  {
    "text": "you so we don't use any self-consistency although I would love to and and the",
    "start": "1732519",
    "end": "1738440"
  },
  {
    "text": "reason is it's it's very expensive so if I if I was sitting on a llm provider um",
    "start": "1738440",
    "end": "1744519"
  },
  {
    "text": "then I would be definitely burning more tokens um but the truth is we cannot",
    "start": "1744519",
    "end": "1749880"
  },
  {
    "text": "trade off self-consistency so like the idea of generating multiple LM calls to see if there is an agreement between",
    "start": "1749880",
    "end": "1755519"
  },
  {
    "text": "them we traded off with higher latency and with the fact that you know in a react Loop you reason you take an action",
    "start": "1755519",
    "end": "1762320"
  },
  {
    "text": "you see that come of the action and then if that com is not what expected you",
    "start": "1762320",
    "end": "1767399"
  },
  {
    "text": "keep looping until you make progress so I think that is a good tradeoff that being said say 6 months from today",
    "start": "1767399",
    "end": "1774919"
  },
  {
    "text": "there's going to be a uh sunet mini or like the new I is going to be extremely fast and as powerful as this model I",
    "start": "1774919",
    "end": "1782080"
  },
  {
    "text": "wouldn't be surprised if we had a release that either you s consistency or even more exciting to me ultimately rra",
    "start": "1782080",
    "end": "1790039"
  },
  {
    "text": "it as like a this very interesting environment where you can spun up different Rebels each one of them is",
    "start": "1790039",
    "end": "1796440"
  },
  {
    "text": "assign to a different container uh so you could think of basically doing MCTS with the agent you have the same prompt",
    "start": "1796440",
    "end": "1803159"
  },
  {
    "text": "you kickart a different agent session on each one of them they make progress in parallel and then at certain points in",
    "start": "1803159",
    "end": "1808960"
  },
  {
    "text": "time you try to sync and see which one of them are in agreement and then you you drop the trajectories their feeling",
    "start": "1808960",
    "end": "1815440"
  },
  {
    "text": "all of this I think it's in the realm of feasibility uh cost as of now is prohibitive so but like anything in AI",
    "start": "1815440",
    "end": "1823399"
  },
  {
    "text": "cost is dropping so quickly that maybe next year we're going to be chatting about our agent evaluator yeah thanks",
    "start": "1823399",
    "end": "1831480"
  },
  {
    "start": "1831000",
    "end": "1956000"
  },
  {
    "text": "awesome we'll probably do two more questions uh maybe one right there you",
    "start": "1831480",
    "end": "1837760"
  },
  {
    "text": "know repeating the question if you were to do it again from the from the initial Manifesto to the final push for the",
    "start": "1848120",
    "end": "1854279"
  },
  {
    "text": "agent what would you do differently what what mistakes did you made that you'd rectify I generally maybe speaking what",
    "start": "1854279",
    "end": "1859840"
  },
  {
    "text": "advice would you have for other people doing similar things as well that's a great question I wish I",
    "start": "1859840",
    "end": "1865559"
  },
  {
    "text": "had time to sit and think do a do a retro",
    "start": "1865559",
    "end": "1871480"
  },
  {
    "text": "um I don't think we have too many regrets to be honest maybe if anything",
    "start": "1871480",
    "end": "1878399"
  },
  {
    "text": "we kind of understood the product we wanted to build why we were building it so perhaps having had a clearer vision",
    "start": "1878399",
    "end": "1886159"
  },
  {
    "text": "like back in the days like I'm talking about beginning of the year that we wanted to build less autonomous agent",
    "start": "1886159",
    "end": "1892039"
  },
  {
    "text": "and like more product oriented rather than oriented to like creating get PRS",
    "start": "1892039",
    "end": "1897159"
  },
  {
    "text": "perhaps it would have made it easier to make some choices like eventually everything that we shipped I'm very",
    "start": "1897159",
    "end": "1903279"
  },
  {
    "text": "proud of and I think that's that's exactly what we wanted to put in front of people but I don't think there is any",
    "start": "1903279",
    "end": "1910880"
  },
  {
    "text": "clear recipe like on how to build good agents today so uh maybe my recommendation for everyone is",
    "start": "1910880",
    "end": "1918880"
  },
  {
    "text": "don't fall into the Paradox of choice where there are too many ways in which you can build agents too many different ways in which you can think of a product",
    "start": "1918880",
    "end": "1925600"
  },
  {
    "text": "start building because you're going to change your mind throughout the process models are going to change perhaps also",
    "start": "1925600",
    "end": "1932240"
  },
  {
    "text": "in the meantime so you would find an unlock just because there has been a new release um and in all honesty the",
    "start": "1932240",
    "end": "1938519"
  },
  {
    "text": "switching costs are not the die um like switching models not too much effort you",
    "start": "1938519",
    "end": "1944000"
  },
  {
    "text": "just have to reduce some prompt engineering switching cognitive architecture with Lang few lines of code so I would rather her",
    "start": "1944000",
    "end": "1951240"
  },
  {
    "text": "I would rather be bias towards action rather than architecting back",
    "start": "1951240",
    "end": "1957600"
  },
  {
    "start": "1956000",
    "end": "2210000"
  },
  {
    "text": "there hey for question place people go and",
    "start": "1957600",
    "end": "1964360"
  },
  {
    "text": "actually learn c as well in addition to building deplo this I went I immediately bought agent and then it like for me",
    "start": "1964360",
    "end": "1972120"
  },
  {
    "text": "into flk like can I get a API like no actually let's like a senior developer trying for me into like a decision and",
    "start": "1972120",
    "end": "1979559"
  },
  {
    "text": "so that's one part of how you guys think about like teaching folks and maybe giving them ability to try other Stacks",
    "start": "1979559",
    "end": "1986240"
  },
  {
    "text": "as a follow to this teaching also about BRS you said that some people basically don't do anying some people what do you",
    "start": "1986240",
    "end": "1992679"
  },
  {
    "text": "think is rep in actually teaching folks after you see multiple people using this different ways you doen of teaching them",
    "start": "1992679",
    "end": "1999840"
  },
  {
    "text": "how to actually promp better this agent repeating the question uh teaching people in two Dimensions one kind of",
    "start": "1999840",
    "end": "2006760"
  },
  {
    "text": "like how to code and giving them more optionality in the tech stack that they're using and then two on the prompt",
    "start": "2006760",
    "end": "2011919"
  },
  {
    "text": "engineering side how how much responsibility do you take there for teaching people how to interact with the",
    "start": "2011919",
    "end": "2018159"
  },
  {
    "text": "agents all right so the limitations on the stack are there on purpose not",
    "start": "2018159",
    "end": "2025360"
  },
  {
    "text": "because we are so opinionated that we don't want people to build with other Frameworks uh it's rather",
    "start": "2025360",
    "end": "2031639"
  },
  {
    "text": "because if you switch like from flash to nextjs today and you try to build exactly the same product you will see a",
    "start": "2031639",
    "end": "2038200"
  },
  {
    "text": "huge drop in terms of reliability and the reason is not because next Jess is bad the way in which it has to create",
    "start": "2038200",
    "end": "2045600"
  },
  {
    "text": "files in the file system and how strict is the directory structure and the fact that you have to create a lot of smaller files uh makes the test the our first",
    "start": "2045600",
    "end": "2054158"
  },
  {
    "text": "step of the agent much more complicated so we prefer to launch something that",
    "start": "2054159",
    "end": "2059480"
  },
  {
    "text": "even though it wasn't making happy good developers like you he made happy people because they could actually build",
    "start": "2059480",
    "end": "2065679"
  },
  {
    "text": "something that they they loved so I think our Target user base are usually people that don't care about the stack",
    "start": "2065679",
    "end": "2071158"
  },
  {
    "text": "that is being used at least for now uh we do have people internally that are currently working on adding support for",
    "start": "2071159",
    "end": "2077118"
  },
  {
    "text": "more Stacks but again similar to the answer was given before I prefer the bias towards action rather than having",
    "start": "2077119",
    "end": "2083280"
  },
  {
    "text": "something that could perfectly support five different stacks and now in terms",
    "start": "2083280",
    "end": "2088480"
  },
  {
    "text": "of teaching users how to prompt we didn't want to be too prescriptive at",
    "start": "2088480",
    "end": "2093760"
  },
  {
    "text": "the beginning so I would say I think we all agree that the chat Bots are",
    "start": "2093760",
    "end": "2099079"
  },
  {
    "text": "possibly the worst UI for AI today like you you never know exactly what the",
    "start": "2099079",
    "end": "2104280"
  },
  {
    "text": "product is capable of doing and we all wish that we had better UI affordances to put in front of the user but the",
    "start": "2104280",
    "end": "2110320"
  },
  {
    "text": "truth is chbt and cloud and everything else out there trained the vast majority of users on chatting with AI rather than",
    "start": "2110320",
    "end": "2118560"
  },
  {
    "text": "uh using anything different so I thought that was a good starting point and I see our recording users learning by how the",
    "start": "2118560",
    "end": "2127720"
  },
  {
    "text": "agent reacts and how the agent basically builds applications depending on on how the prompt it so I thought it was like",
    "start": "2127720",
    "end": "2133280"
  },
  {
    "text": "already a good gym for them to train their you know prompting skills again very similar to the first time you",
    "start": "2133280",
    "end": "2139040"
  },
  {
    "text": "landed in front of CH gbt like no one most of the people didn't know how to use it correctly um I I do see a",
    "start": "2139040",
    "end": "2144680"
  },
  {
    "text": "near-term future where even the creation experience of RAB agent will change",
    "start": "2144680",
    "end": "2149839"
  },
  {
    "text": "dramatically compared to what it is today so not anymore like an empty box where you can write whatever you want",
    "start": "2149839",
    "end": "2155160"
  },
  {
    "text": "but rather something you know a bit more structured uh but again you never know what users want before you launch so you",
    "start": "2155160",
    "end": "2162240"
  },
  {
    "text": "know I I rather go for generality at the beginning and then like find what what are the right guard rails that make say",
    "start": "2162240",
    "end": "2169079"
  },
  {
    "text": "99% of the people happy that's an exciting way to end it um before people",
    "start": "2169079",
    "end": "2174200"
  },
  {
    "text": "disperse and start chatting some quick announcements there will be Demos in the second part of the office so around",
    "start": "2174200",
    "end": "2180079"
  },
  {
    "text": "there there's a table upstairs with a nice TV and projector and some more seating and swix we set up there and so",
    "start": "2180079",
    "end": "2186440"
  },
  {
    "text": "if you want to do demo go around there um and uh other than that mik will be",
    "start": "2186440",
    "end": "2193680"
  },
  {
    "text": "around all night to answer all your questions or as long as he wants to stay and let's give him a big round of",
    "start": "2193680",
    "end": "2198920"
  },
  {
    "text": "applause as well as Jess for putting it on thank you",
    "start": "2198920",
    "end": "2206240"
  }
]
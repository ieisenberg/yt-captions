[
  {
    "text": "hey everyone this is anos co-founder of",
    "start": "1520",
    "end": "3120"
  },
  {
    "text": "lank chain today we're super excited to",
    "start": "3120",
    "end": "4839"
  },
  {
    "text": "announce the general availability of",
    "start": "4839",
    "end": "6080"
  },
  {
    "text": "lsmith our platform for LM application",
    "start": "6080",
    "end": "7919"
  },
  {
    "text": "development monitoring and testing we",
    "start": "7919",
    "end": "9800"
  },
  {
    "text": "worked hard over the past few months to",
    "start": "9800",
    "end": "11080"
  },
  {
    "text": "add requested features and ensure that",
    "start": "11080",
    "end": "12400"
  },
  {
    "text": "lsmith can operate at scale lsmith is",
    "start": "12400",
    "end": "14519"
  },
  {
    "text": "designed to assist you at all stages of",
    "start": "14519",
    "end": "15920"
  },
  {
    "text": "the LM application life cycle this",
    "start": "15920",
    "end": "17400"
  },
  {
    "text": "includes prototyping beta testing and",
    "start": "17400",
    "end": "19039"
  },
  {
    "text": "production we've designed lsmith to be a",
    "start": "19039",
    "end": "21000"
  },
  {
    "text": "completely independent system this means",
    "start": "21000",
    "end": "22680"
  },
  {
    "text": "that you can use lsmith regardless of",
    "start": "22680",
    "end": "24039"
  },
  {
    "text": "whether or not you're using Lang chain",
    "start": "24039",
    "end": "25199"
  },
  {
    "text": "to develop your applications here I'll",
    "start": "25199",
    "end": "26960"
  },
  {
    "text": "showcase the different workflows that",
    "start": "26960",
    "end": "28119"
  },
  {
    "text": "lsmith has to offer so here I've logged",
    "start": "28119",
    "end": "31480"
  },
  {
    "text": "into lsmith under the linkchain",
    "start": "31480",
    "end": "33160"
  },
  {
    "text": "organization that I'm a part of and I",
    "start": "33160",
    "end": "35280"
  },
  {
    "text": "can see projects data sets and testing",
    "start": "35280",
    "end": "36920"
  },
  {
    "text": "annotation cues and the Hub I'll start",
    "start": "36920",
    "end": "39040"
  },
  {
    "text": "off by clicking into projects and",
    "start": "39040",
    "end": "40640"
  },
  {
    "text": "projects are nothing more than",
    "start": "40640",
    "end": "41719"
  },
  {
    "text": "collections of traces that you loog to",
    "start": "41719",
    "end": "43399"
  },
  {
    "text": "the system usually people separate their",
    "start": "43399",
    "end": "45480"
  },
  {
    "text": "projects by",
    "start": "45480",
    "end": "48199"
  },
  {
    "text": "application so um here I'm in the",
    "start": "48199",
    "end": "50399"
  },
  {
    "text": "projects page I can see all my projects",
    "start": "50399",
    "end": "52559"
  },
  {
    "text": "and uh I'll click into the project",
    "start": "52559",
    "end": "54719"
  },
  {
    "text": "that's uh titled chat Lang chain this is",
    "start": "54719",
    "end": "56760"
  },
  {
    "text": "a project that receives traces from uh",
    "start": "56760",
    "end": "59160"
  },
  {
    "text": "the chat Lang chain application that we",
    "start": "59160",
    "end": "60760"
  },
  {
    "text": "deployed on chat. langang chain.com this",
    "start": "60760",
    "end": "62800"
  },
  {
    "text": "is an application that's designed to",
    "start": "62800",
    "end": "65198"
  },
  {
    "text": "answer user questions about Lang chains",
    "start": "65199",
    "end": "67360"
  },
  {
    "text": "python",
    "start": "67360",
    "end": "68360"
  },
  {
    "text": "documentation so one thing I'll point",
    "start": "68360",
    "end": "70520"
  },
  {
    "text": "out right away is uh all these",
    "start": "70520",
    "end": "72680"
  },
  {
    "text": "statistics that you can see at the",
    "start": "72680",
    "end": "73840"
  },
  {
    "text": "project level for the given time period",
    "start": "73840",
    "end": "75320"
  },
  {
    "text": "by default it's the past seven days so",
    "start": "75320",
    "end": "77119"
  },
  {
    "text": "see the total run count the total tokens",
    "start": "77119",
    "end": "79400"
  },
  {
    "text": "including the costs um right now we only",
    "start": "79400",
    "end": "81240"
  },
  {
    "text": "have cost tracking set up for open AI",
    "start": "81240",
    "end": "83040"
  },
  {
    "text": "models but cost tracking for other",
    "start": "83040",
    "end": "84479"
  },
  {
    "text": "models is uh on the road map uh for the",
    "start": "84479",
    "end": "87040"
  },
  {
    "text": "near future we have the error rate um uh",
    "start": "87040",
    "end": "90240"
  },
  {
    "text": "some latency and streaming statistics we",
    "start": "90240",
    "end": "92320"
  },
  {
    "text": "have feedback statistics as well and",
    "start": "92320",
    "end": "94119"
  },
  {
    "text": "then we see some quick filters that we",
    "start": "94119",
    "end": "95399"
  },
  {
    "text": "can use to filter for runs within the",
    "start": "95399",
    "end": "96960"
  },
  {
    "text": "project um in this tab section we see",
    "start": "96960",
    "end": "99759"
  },
  {
    "text": "traces which are uh endtoend invocations",
    "start": "99759",
    "end": "102399"
  },
  {
    "text": "of your",
    "start": "102399",
    "end": "103479"
  },
  {
    "text": "application we can see uh isolate only",
    "start": "103479",
    "end": "106320"
  },
  {
    "text": "the llm calls if you're only interested",
    "start": "106320",
    "end": "107880"
  },
  {
    "text": "in looking at prompts and",
    "start": "107880",
    "end": "110079"
  },
  {
    "text": "generations we also have this monitoring",
    "start": "110079",
    "end": "112119"
  },
  {
    "text": "section that allows you to track uh",
    "start": "112119",
    "end": "113880"
  },
  {
    "text": "different Statistics over",
    "start": "113880",
    "end": "115680"
  },
  {
    "text": "time you can view things like feedback",
    "start": "115680",
    "end": "118600"
  },
  {
    "text": "and latency and cost cost over time",
    "start": "118600",
    "end": "120759"
  },
  {
    "text": "which which is pretty useful you can",
    "start": "120759",
    "end": "122640"
  },
  {
    "text": "also um uh Group by metadata so in this",
    "start": "122640",
    "end": "127439"
  },
  {
    "text": "case uh we actually have four models",
    "start": "127439",
    "end": "129280"
  },
  {
    "text": "available for generating responses with",
    "start": "129280",
    "end": "131239"
  },
  {
    "text": "chat link chain we have anthropic CLA",
    "start": "131239",
    "end": "133160"
  },
  {
    "text": "2.1 fireworks mixw uh Google Gemini Pro",
    "start": "133160",
    "end": "136200"
  },
  {
    "text": "and open AI GPD 3.5 turbo and you can",
    "start": "136200",
    "end": "138959"
  },
  {
    "text": "see the statistics over time for each",
    "start": "138959",
    "end": "141319"
  },
  {
    "text": "model side by",
    "start": "141319",
    "end": "144200"
  },
  {
    "text": "side um so this this is pretty useful to",
    "start": "144200",
    "end": "147840"
  },
  {
    "text": "uh you know if you're AB testing",
    "start": "147840",
    "end": "149000"
  },
  {
    "text": "different configurations of your",
    "start": "149000",
    "end": "150080"
  },
  {
    "text": "application and you want to see how",
    "start": "150080",
    "end": "151239"
  },
  {
    "text": "they're doing alongside each",
    "start": "151239",
    "end": "154000"
  },
  {
    "text": "other so I'll go back to traces and I'll",
    "start": "154000",
    "end": "156840"
  },
  {
    "text": "click in on uh one of the rows here so",
    "start": "156840",
    "end": "160000"
  },
  {
    "text": "when I do that I can see the uh input",
    "start": "160000",
    "end": "163000"
  },
  {
    "text": "and output of the LM pipeline that backs",
    "start": "163000",
    "end": "165319"
  },
  {
    "text": "chat Lang chain and I can look at all of",
    "start": "165319",
    "end": "167000"
  },
  {
    "text": "the different intermediate steps that",
    "start": "167000",
    "end": "168519"
  },
  {
    "text": "the pipeline takes to arrive at the",
    "start": "168519",
    "end": "169879"
  },
  {
    "text": "final",
    "start": "169879",
    "end": "170720"
  },
  {
    "text": "answer I'll dive into the most",
    "start": "170720",
    "end": "172480"
  },
  {
    "text": "interesting steps there's this retrieval",
    "start": "172480",
    "end": "174080"
  },
  {
    "text": "step um that that is uh that under the",
    "start": "174080",
    "end": "176480"
  },
  {
    "text": "hood you know it it retrieves documents",
    "start": "176480",
    "end": "178080"
  },
  {
    "text": "from an index um",
    "start": "178080",
    "end": "180560"
  },
  {
    "text": "and you can see all the documents here",
    "start": "180560",
    "end": "181840"
  },
  {
    "text": "they're rendered nicely uh I can also",
    "start": "181840",
    "end": "183879"
  },
  {
    "text": "dive into the uh llm call that's used to",
    "start": "183879",
    "end": "186360"
  },
  {
    "text": "generate the final response at the user",
    "start": "186360",
    "end": "187799"
  },
  {
    "text": "sees so here we can see like the the raw",
    "start": "187799",
    "end": "190799"
  },
  {
    "text": "system prompt uh we can see the the",
    "start": "190799",
    "end": "192480"
  },
  {
    "text": "human prompt um as well and then we can",
    "start": "192480",
    "end": "194560"
  },
  {
    "text": "see the AI message at the end um and",
    "start": "194560",
    "end": "197360"
  },
  {
    "text": "then we can also see any metadata that",
    "start": "197360",
    "end": "199159"
  },
  {
    "text": "was used to um s so that that was uh",
    "start": "199159",
    "end": "202319"
  },
  {
    "text": "sent along with the application so if",
    "start": "202319",
    "end": "204840"
  },
  {
    "text": "you're using linkchain a bunch of",
    "start": "204840",
    "end": "206680"
  },
  {
    "text": "metadata is sent by default uh like the",
    "start": "206680",
    "end": "209200"
  },
  {
    "text": "the model the model name uh uh the",
    "start": "209200",
    "end": "211720"
  },
  {
    "text": "runtime information things like that if",
    "start": "211720",
    "end": "213599"
  },
  {
    "text": "you're using the SDK a lot of the same",
    "start": "213599",
    "end": "214879"
  },
  {
    "text": "metadata sent up and the metadata is",
    "start": "214879",
    "end": "216799"
  },
  {
    "text": "completely configurable if you're using",
    "start": "216799",
    "end": "218080"
  },
  {
    "text": "link Smith links Smith API so why is",
    "start": "218080",
    "end": "220560"
  },
  {
    "text": "tracing helpful well oftentimes when",
    "start": "220560",
    "end": "222319"
  },
  {
    "text": "you're running an L application you can",
    "start": "222319",
    "end": "224400"
  },
  {
    "text": "run into a lot of really frustrating",
    "start": "224400",
    "end": "225959"
  },
  {
    "text": "issues like infinite looping if you have",
    "start": "225959",
    "end": "227599"
  },
  {
    "text": "an argentic workflow um or you know",
    "start": "227599",
    "end": "230200"
  },
  {
    "text": "maybe your LM pipeline is using a lot",
    "start": "230200",
    "end": "232360"
  },
  {
    "text": "more tokens than you expected well here",
    "start": "232360",
    "end": "235079"
  },
  {
    "text": "you can dive into the inputs and outputs",
    "start": "235079",
    "end": "237200"
  },
  {
    "text": "at each step and really understand where",
    "start": "237200",
    "end": "240280"
  },
  {
    "text": "things are going wrong um another thing",
    "start": "240280",
    "end": "242239"
  },
  {
    "text": "that's useful is you can open up any llm",
    "start": "242239",
    "end": "245439"
  },
  {
    "text": "call within a trace in uh an interactive",
    "start": "245439",
    "end": "248400"
  },
  {
    "text": "playground environment and you can",
    "start": "248400",
    "end": "249720"
  },
  {
    "text": "change the model settings you can change",
    "start": "249720",
    "end": "251720"
  },
  {
    "text": "the prompt and then you can uh",
    "start": "251720",
    "end": "253519"
  },
  {
    "text": "regenerate the um you know the",
    "start": "253519",
    "end": "255760"
  },
  {
    "text": "completion based on uh any changes that",
    "start": "255760",
    "end": "258320"
  },
  {
    "text": "you",
    "start": "258320",
    "end": "260079"
  },
  {
    "text": "made another thing that's helpful is",
    "start": "260079",
    "end": "263919"
  },
  {
    "text": "being able to filter by uh a bunch of",
    "start": "263919",
    "end": "266400"
  },
  {
    "text": "different attributes so I'll filter by",
    "start": "266400",
    "end": "269160"
  },
  {
    "text": "feedback here and uh what you'll notice",
    "start": "269160",
    "end": "272320"
  },
  {
    "text": "is on chat linkchain we have a thumbs up",
    "start": "272320",
    "end": "274680"
  },
  {
    "text": "and thumbs down button and this is uh",
    "start": "274680",
    "end": "276440"
  },
  {
    "text": "wired up to the user score feedback tag",
    "start": "276440",
    "end": "279240"
  },
  {
    "text": "so here I can only look at traces that",
    "start": "279240",
    "end": "281639"
  },
  {
    "text": "have positive feedback um I can also uh",
    "start": "281639",
    "end": "285600"
  },
  {
    "text": "you know use the same principle to look",
    "start": "285600",
    "end": "286800"
  },
  {
    "text": "at traces that have negative feedback so",
    "start": "286800",
    "end": "288560"
  },
  {
    "text": "this allows you to drill into the most",
    "start": "288560",
    "end": "290280"
  },
  {
    "text": "interesting traces obviously with just a",
    "start": "290280",
    "end": "292400"
  },
  {
    "text": "thumbs up thumbs down button um you're",
    "start": "292400",
    "end": "294400"
  },
  {
    "text": "not going to get like very high Fidel",
    "start": "294400",
    "end": "295759"
  },
  {
    "text": "feedback but it can be used as a good",
    "start": "295759",
    "end": "297000"
  },
  {
    "text": "starting point to dive into your data",
    "start": "297000",
    "end": "299039"
  },
  {
    "text": "and uh gain an intuition for um you know",
    "start": "299039",
    "end": "301720"
  },
  {
    "text": "how your application is doing on in in",
    "start": "301720",
    "end": "303600"
  },
  {
    "text": "real world",
    "start": "303600",
    "end": "304960"
  },
  {
    "text": "scenarios great so uh one thing that'll",
    "start": "304960",
    "end": "308160"
  },
  {
    "text": "point out is in um from every uh um",
    "start": "308160",
    "end": "312840"
  },
  {
    "text": "Trace you can click on this add to data",
    "start": "312840",
    "end": "316039"
  },
  {
    "text": "set uh model and you can add it uh add",
    "start": "316039",
    "end": "318840"
  },
  {
    "text": "the inputs and outputs as an example to",
    "start": "318840",
    "end": "320479"
  },
  {
    "text": "a data set and this is you can edit this",
    "start": "320479",
    "end": "322479"
  },
  {
    "text": "uh as you wish and then you can add it",
    "start": "322479",
    "end": "323720"
  },
  {
    "text": "to a data set I'll dive into the data",
    "start": "323720",
    "end": "326240"
  },
  {
    "text": "set section and um show you an example",
    "start": "326240",
    "end": "329039"
  },
  {
    "text": "of a real data set that I",
    "start": "329039",
    "end": "332280"
  },
  {
    "text": "have so here um we can look at uh a data",
    "start": "334160",
    "end": "338000"
  },
  {
    "text": "set and all the examples that are part",
    "start": "338000",
    "end": "339479"
  },
  {
    "text": "of the data set uh each example consists",
    "start": "339479",
    "end": "342160"
  },
  {
    "text": "of an input and reference output uh that",
    "start": "342160",
    "end": "344600"
  },
  {
    "text": "you can use to test different versions",
    "start": "344600",
    "end": "346919"
  },
  {
    "text": "of your",
    "start": "346919",
    "end": "348240"
  },
  {
    "text": "application so here I've used this data",
    "start": "348240",
    "end": "350600"
  },
  {
    "text": "set to run to to run um a number of",
    "start": "350600",
    "end": "352960"
  },
  {
    "text": "tests uh and I see the test results here",
    "start": "352960",
    "end": "355840"
  },
  {
    "text": "and I can look at uh each test result",
    "start": "355840",
    "end": "359000"
  },
  {
    "text": "and uh get a highle feel for how each",
    "start": "359000",
    "end": "362080"
  },
  {
    "text": "test result performed relative to each",
    "start": "362080",
    "end": "363560"
  },
  {
    "text": "other with this chart um I can also",
    "start": "363560",
    "end": "366039"
  },
  {
    "text": "change what this chart is displaying so",
    "start": "366039",
    "end": "367880"
  },
  {
    "text": "previously it was displaying latency I",
    "start": "367880",
    "end": "369520"
  },
  {
    "text": "can also have it display um uh you know",
    "start": "369520",
    "end": "373039"
  },
  {
    "text": "correctness um in order to run a test",
    "start": "373039",
    "end": "376520"
  },
  {
    "text": "with a data set uh you can use either",
    "start": "376520",
    "end": "378880"
  },
  {
    "text": "the python or typescript SDK and you can",
    "start": "378880",
    "end": "381360"
  },
  {
    "text": "also configure a number of off the shelf",
    "start": "381360",
    "end": "384080"
  },
  {
    "text": "LM based or heris based uh evaluators",
    "start": "384080",
    "end": "387440"
  },
  {
    "text": "along with any evaluators that uh any",
    "start": "387440",
    "end": "390000"
  },
  {
    "text": "custom evaluators that that you want to",
    "start": "390000",
    "end": "391560"
  },
  {
    "text": "run as well and these evaluators will",
    "start": "391560",
    "end": "393319"
  },
  {
    "text": "take into account the input the actual",
    "start": "393319",
    "end": "395599"
  },
  {
    "text": "output of your application and then the",
    "start": "395599",
    "end": "397039"
  },
  {
    "text": "reference output to score your",
    "start": "397039",
    "end": "399400"
  },
  {
    "text": "application results uh against a number",
    "start": "399400",
    "end": "401440"
  },
  {
    "text": "of",
    "start": "401440",
    "end": "403160"
  },
  {
    "text": "criteria another thing that you can do",
    "start": "403160",
    "end": "405080"
  },
  {
    "text": "in the data sets and testing page is uh",
    "start": "405080",
    "end": "407039"
  },
  {
    "text": "open up a test comparison View and then",
    "start": "407039",
    "end": "410280"
  },
  {
    "text": "what this will show you is the input the",
    "start": "410280",
    "end": "412000"
  },
  {
    "text": "reference output and then the results of",
    "start": "412000",
    "end": "415160"
  },
  {
    "text": "each of your tests and they can view",
    "start": "415160",
    "end": "416720"
  },
  {
    "text": "them alongside their scores um uh side",
    "start": "416720",
    "end": "419879"
  },
  {
    "text": "by side and then you can also look at",
    "start": "419879",
    "end": "421599"
  },
  {
    "text": "these charts these charts are fully",
    "start": "421599",
    "end": "423639"
  },
  {
    "text": "fully configurable um we have latency",
    "start": "423639",
    "end": "425800"
  },
  {
    "text": "charts feedback charts token charts and",
    "start": "425800",
    "end": "428199"
  },
  {
    "text": "then we have this um uh I guess like",
    "start": "428199",
    "end": "430520"
  },
  {
    "text": "distribution chart that allows you to",
    "start": "430520",
    "end": "432520"
  },
  {
    "text": "you know get a good idea about how your",
    "start": "432520",
    "end": "434319"
  },
  {
    "text": "tests are performing relative to each",
    "start": "434319",
    "end": "435960"
  },
  {
    "text": "other this is really useful when you",
    "start": "435960",
    "end": "437560"
  },
  {
    "text": "want to do things like regression",
    "start": "437560",
    "end": "438720"
  },
  {
    "text": "testing and um you know if you want to",
    "start": "438720",
    "end": "441199"
  },
  {
    "text": "run some sanity checks uh uh against",
    "start": "441199",
    "end": "443680"
  },
  {
    "text": "your LM pipeline before you deploy to",
    "start": "443680",
    "end": "445400"
  },
  {
    "text": "production or before you deploy it to um",
    "start": "445400",
    "end": "447879"
  },
  {
    "text": "an initial set of users the uh data sets",
    "start": "447879",
    "end": "450759"
  },
  {
    "text": "and testing section of lsmith makes it",
    "start": "450759",
    "end": "452400"
  },
  {
    "text": "really easy uh for you to do that great",
    "start": "452400",
    "end": "455879"
  },
  {
    "text": "um so another thing that you can do is",
    "start": "455879",
    "end": "459360"
  },
  {
    "text": "send any Trace to what's called an uh an",
    "start": "459360",
    "end": "462120"
  },
  {
    "text": "annotation queue so you can click on a",
    "start": "462120",
    "end": "464039"
  },
  {
    "text": "trace here and then you can send to an",
    "start": "464039",
    "end": "465680"
  },
  {
    "text": "annotation queue",
    "start": "465680",
    "end": "469159"
  },
  {
    "text": "um and then you can actually uh you know",
    "start": "469960",
    "end": "473440"
  },
  {
    "text": "this gives you a uh kind presents like a",
    "start": "473440",
    "end": "476720"
  },
  {
    "text": "cyclical workflow that allows you to",
    "start": "476720",
    "end": "479400"
  },
  {
    "text": "provide human annotation to any run that",
    "start": "479400",
    "end": "481840"
  },
  {
    "text": "you logged to the system so here I can",
    "start": "481840",
    "end": "484199"
  },
  {
    "text": "give it like a correctness score I can",
    "start": "484199",
    "end": "485879"
  },
  {
    "text": "also add a number of tags that I have",
    "start": "485879",
    "end": "488520"
  },
  {
    "text": "and you can create new feedback tags as",
    "start": "488520",
    "end": "490479"
  },
  {
    "text": "well to uh annotate a run um on a number",
    "start": "490479",
    "end": "493879"
  },
  {
    "text": "of different criteria that's important",
    "start": "493879",
    "end": "495120"
  },
  {
    "text": "to you and your",
    "start": "495120",
    "end": "497639"
  },
  {
    "text": "organization the last thing I'll",
    "start": "498800",
    "end": "500360"
  },
  {
    "text": "highlight is the prompt tub uh we",
    "start": "500360",
    "end": "502400"
  },
  {
    "text": "launched this a while ago but I think",
    "start": "502400",
    "end": "503560"
  },
  {
    "text": "it's worth mentioning again uh here we",
    "start": "503560",
    "end": "505360"
  },
  {
    "text": "have like a collection of uh prompts",
    "start": "505360",
    "end": "507520"
  },
  {
    "text": "some of these are public uh you can o",
    "start": "507520",
    "end": "509520"
  },
  {
    "text": "have prompts that are specific to you",
    "start": "509520",
    "end": "511599"
  },
  {
    "text": "and your",
    "start": "511599",
    "end": "512680"
  },
  {
    "text": "tenant um and you can open up any of",
    "start": "512680",
    "end": "515640"
  },
  {
    "text": "these prompts in the uh playground and",
    "start": "515640",
    "end": "518800"
  },
  {
    "text": "you could enter the parameters that the",
    "start": "518800",
    "end": "520680"
  },
  {
    "text": "prompt expects and then uh look at the",
    "start": "520680",
    "end": "523479"
  },
  {
    "text": "generation that's that's uh produced um",
    "start": "523479",
    "end": "525959"
  },
  {
    "text": "you can also change the the provider and",
    "start": "525959",
    "end": "527880"
  },
  {
    "text": "the model as well um and then you can",
    "start": "527880",
    "end": "530760"
  },
  {
    "text": "also see the different uh you know",
    "start": "530760",
    "end": "532480"
  },
  {
    "text": "versions of the prompt as",
    "start": "532480",
    "end": "535720"
  },
  {
    "text": "well",
    "start": "538200",
    "end": "540200"
  },
  {
    "text": "awesome so I just wanted to give you a",
    "start": "540200",
    "end": "542200"
  },
  {
    "text": "quick overview of what link Smith has to",
    "start": "542200",
    "end": "543959"
  },
  {
    "text": "offer and how we can help you uh develop",
    "start": "543959",
    "end": "546880"
  },
  {
    "text": "and gain confidence in your llm",
    "start": "546880",
    "end": "548560"
  },
  {
    "text": "applications uh we're really excited for",
    "start": "548560",
    "end": "551120"
  },
  {
    "text": "uh everything that you know you all are",
    "start": "551120",
    "end": "552560"
  },
  {
    "text": "going to build and we hope that link",
    "start": "552560",
    "end": "553800"
  },
  {
    "text": "Smith can be a useful useful tool uh in",
    "start": "553800",
    "end": "556200"
  },
  {
    "text": "your toolkit for uh productionizing your",
    "start": "556200",
    "end": "558240"
  },
  {
    "text": "LM applications thank you",
    "start": "558240",
    "end": "562519"
  }
]
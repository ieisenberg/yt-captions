[
  {
    "text": "hi this is Lance from Lang chain so open",
    "start": "1000",
    "end": "3240"
  },
  {
    "text": "AI just released GPD 40 or Omni today",
    "start": "3240",
    "end": "5759"
  },
  {
    "text": "which is pretty exciting release it",
    "start": "5759",
    "end": "7720"
  },
  {
    "text": "reports um both significant Improvement",
    "start": "7720",
    "end": "10759"
  },
  {
    "text": "in Long non-english languages much",
    "start": "10759",
    "end": "13000"
  },
  {
    "text": "faster uh and cheaper in the API than",
    "start": "13000",
    "end": "16240"
  },
  {
    "text": "the prior state-ofthe-art gbd4 so that's",
    "start": "16240",
    "end": "18359"
  },
  {
    "text": "actually really exciting um and it also",
    "start": "18359",
    "end": "20920"
  },
  {
    "text": "incorporates multimodality so you know",
    "start": "20920",
    "end": "23279"
  },
  {
    "text": "both audio visual as well as text so",
    "start": "23279",
    "end": "25000"
  },
  {
    "text": "that's a really good thing now the",
    "start": "25000",
    "end": "26960"
  },
  {
    "text": "question you might ask is let's say you",
    "start": "26960",
    "end": "28800"
  },
  {
    "text": "already have an app you're using a in a",
    "start": "28800",
    "end": "30519"
  },
  {
    "text": "model like say the state of the r gbd4",
    "start": "30519",
    "end": "32398"
  },
  {
    "text": "turbo how do I make a decision about",
    "start": "32399",
    "end": "34440"
  },
  {
    "text": "whether or not it's actually safe to",
    "start": "34440",
    "end": "35680"
  },
  {
    "text": "upgrade to this model and then when we",
    "start": "35680",
    "end": "37719"
  },
  {
    "text": "talk about safe we can mean that that",
    "start": "37719",
    "end": "39360"
  },
  {
    "text": "can kind of mean a few different things",
    "start": "39360",
    "end": "41320"
  },
  {
    "text": "so on one hand you can think about um",
    "start": "41320",
    "end": "43920"
  },
  {
    "text": "are there any regressions to the",
    "start": "43920",
    "end": "45160"
  },
  {
    "text": "performance of the application itself",
    "start": "45160",
    "end": "47160"
  },
  {
    "text": "like I have an app already it's using",
    "start": "47160",
    "end": "48600"
  },
  {
    "text": "gbd4 turbo I'm using a bunch of prompts",
    "start": "48600",
    "end": "50760"
  },
  {
    "text": "I've already tuned and till those",
    "start": "50760",
    "end": "52719"
  },
  {
    "text": "prompts just translate over to the new",
    "start": "52719",
    "end": "54039"
  },
  {
    "text": "model seamlessly do they exhibit some",
    "start": "54039",
    "end": "56039"
  },
  {
    "text": "odd behavior or aggressions that I",
    "start": "56039",
    "end": "57440"
  },
  {
    "text": "actually would want to characterize",
    "start": "57440",
    "end": "58680"
  },
  {
    "text": "right anytime you actually change the",
    "start": "58680",
    "end": "60239"
  },
  {
    "text": "model in your application you should",
    "start": "60239",
    "end": "61559"
  },
  {
    "text": "really want to investigate like okay how",
    "start": "61559",
    "end": "63920"
  },
  {
    "text": "does the performance of the application",
    "start": "63920",
    "end": "65360"
  },
  {
    "text": "actually change so that's one and also",
    "start": "65360",
    "end": "67680"
  },
  {
    "text": "things like user experience now it",
    "start": "67680",
    "end": "69200"
  },
  {
    "text": "reports better latency but like what is",
    "start": "69200",
    "end": "71400"
  },
  {
    "text": "that actually does it actually work in",
    "start": "71400",
    "end": "73040"
  },
  {
    "text": "my case so how is the user experience",
    "start": "73040",
    "end": "75240"
  },
  {
    "text": "translate if I change my app from for",
    "start": "75240",
    "end": "77200"
  },
  {
    "text": "example gbd4 turbo or let's say I was",
    "start": "77200",
    "end": "79439"
  },
  {
    "text": "using another app like GP one of the GPD",
    "start": "79439",
    "end": "81400"
  },
  {
    "text": "35 variants given the new cost here can",
    "start": "81400",
    "end": "84400"
  },
  {
    "text": "I make the leap up to G to now gbd4 onni",
    "start": "84400",
    "end": "87439"
  },
  {
    "text": "um and what are the implications on like",
    "start": "87439",
    "end": "89159"
  },
  {
    "text": "you know the performance of the app",
    "start": "89159",
    "end": "90640"
  },
  {
    "text": "itself or things like latency so those",
    "start": "90640",
    "end": "92880"
  },
  {
    "text": "are all things you'd really wanted to",
    "start": "92880",
    "end": "94159"
  },
  {
    "text": "examine to determine whether or not it's",
    "start": "94159",
    "end": "95720"
  },
  {
    "text": "actually safe to make this switch for",
    "start": "95720",
    "end": "97560"
  },
  {
    "text": "your user and you can really think about",
    "start": "97560",
    "end": "99040"
  },
  {
    "text": "this in in three different pieces I have",
    "start": "99040",
    "end": "101720"
  },
  {
    "text": "a data set of examples for example in",
    "start": "101720",
    "end": "103799"
  },
  {
    "text": "this case I have a rag app um of input",
    "start": "103799",
    "end": "106640"
  },
  {
    "text": "output pairs that are kind of my ground",
    "start": "106640",
    "end": "108159"
  },
  {
    "text": "truth input my ground truth output right",
    "start": "108159",
    "end": "110439"
  },
  {
    "text": "so I have a data set I have an evalu",
    "start": "110439",
    "end": "112840"
  },
  {
    "text": "that I'm going to show you how to define",
    "start": "112840",
    "end": "114479"
  },
  {
    "text": "that'll look at my ground truth answers",
    "start": "114479",
    "end": "116159"
  },
  {
    "text": "versus my rag app answers and I have a",
    "start": "116159",
    "end": "118240"
  },
  {
    "text": "rag app that simply takes in gbd4 Omni",
    "start": "118240",
    "end": "121039"
  },
  {
    "text": "versus turbo as a userdefined input",
    "start": "121039",
    "end": "123640"
  },
  {
    "text": "that's all I really need to do and then",
    "start": "123640",
    "end": "125360"
  },
  {
    "text": "I'll show you how to use the UI and",
    "start": "125360",
    "end": "126600"
  },
  {
    "text": "lsmith to really dig into the",
    "start": "126600",
    "end": "128160"
  },
  {
    "text": "differences uh IE look at regressions or",
    "start": "128160",
    "end": "130560"
  },
  {
    "text": "improvements that come if I upgrade my",
    "start": "130560",
    "end": "132480"
  },
  {
    "text": "app to Omni so that's really it so",
    "start": "132480",
    "end": "135599"
  },
  {
    "text": "here's just some code I'm defining an",
    "start": "135599",
    "end": "137319"
  },
  {
    "text": "index here for rag I'm taking the line",
    "start": "137319",
    "end": "139599"
  },
  {
    "text": "trans expression language documentation",
    "start": "139599",
    "end": "141280"
  },
  {
    "text": "which is around 70,000 tokens of context",
    "start": "141280",
    "end": "144000"
  },
  {
    "text": "it's basically a subset of our",
    "start": "144000",
    "end": "145640"
  },
  {
    "text": "documentation um and I'm creating a",
    "start": "145640",
    "end": "147680"
  },
  {
    "text": "vector store locally from that then I'm",
    "start": "147680",
    "end": "150160"
  },
  {
    "text": "defying this rag botot class it's super",
    "start": "150160",
    "end": "152160"
  },
  {
    "text": "simple app it takes in open Ai and a",
    "start": "152160",
    "end": "154599"
  },
  {
    "text": "model name um actually doesn't use Lang",
    "start": "154599",
    "end": "156760"
  },
  {
    "text": "chain at all it's just using the raw",
    "start": "156760",
    "end": "158080"
  },
  {
    "text": "open eye wrapper um or a wrapper we have",
    "start": "158080",
    "end": "160480"
  },
  {
    "text": "around the open ey API so it's like",
    "start": "160480",
    "end": "162120"
  },
  {
    "text": "super simple does retrieval uh basically",
    "start": "162120",
    "end": "164800"
  },
  {
    "text": "does generation with a standard rag",
    "start": "164800",
    "end": "166400"
  },
  {
    "text": "prompt no you all can use a local model",
    "start": "166400",
    "end": "169319"
  },
  {
    "text": "if you want with the Llama but in any",
    "start": "169319",
    "end": "170879"
  },
  {
    "text": "case here's all I need to do I'll Define",
    "start": "170879",
    "end": "173239"
  },
  {
    "text": "three different functions which simply",
    "start": "173239",
    "end": "175480"
  },
  {
    "text": "instantiate my rag bot with different",
    "start": "175480",
    "end": "176920"
  },
  {
    "text": "settings so here I'll use GPT 4116 gbd4",
    "start": "176920",
    "end": "180800"
  },
  {
    "text": "turbo for Turbo and then gbd4 Omni the",
    "start": "180800",
    "end": "183879"
  },
  {
    "text": "new model that's it so basically I have",
    "start": "183879",
    "end": "185879"
  },
  {
    "text": "three different uh functions that I'll",
    "start": "185879",
    "end": "188040"
  },
  {
    "text": "use my little rag bot with different",
    "start": "188040",
    "end": "189879"
  },
  {
    "text": "gbd4 versions that's all I need to do um",
    "start": "189879",
    "end": "193640"
  },
  {
    "text": "second my data set so I've already",
    "start": "193640",
    "end": "195640"
  },
  {
    "text": "created a data set in Langs Smith you",
    "start": "195640",
    "end": "197319"
  },
  {
    "text": "can actually if you go if you go to",
    "start": "197319",
    "end": "200760"
  },
  {
    "text": "Lang if you go to Langs Smith you can uh",
    "start": "200760",
    "end": "204040"
  },
  {
    "text": "go to your data set and testing tab my",
    "start": "204040",
    "end": "205920"
  },
  {
    "text": "data say is defined right here it's",
    "start": "205920",
    "end": "207280"
  },
  {
    "text": "called lell eval um and I can look at",
    "start": "207280",
    "end": "211080"
  },
  {
    "text": "examples and over in examples I can",
    "start": "211080",
    "end": "213319"
  },
  {
    "text": "actually see here's all my ground truth",
    "start": "213319",
    "end": "214879"
  },
  {
    "text": "inputs and outputs so again these are",
    "start": "214879",
    "end": "216959"
  },
  {
    "text": "inputs and outputs related to the",
    "start": "216959",
    "end": "219159"
  },
  {
    "text": "documentation I've built my app from so",
    "start": "219159",
    "end": "221560"
  },
  {
    "text": "this is all",
    "start": "221560",
    "end": "222599"
  },
  {
    "text": "consistent um so that's really all I",
    "start": "222599",
    "end": "225519"
  },
  {
    "text": "need to do in terms of data set in terms",
    "start": "225519",
    "end": "227400"
  },
  {
    "text": "of evaluator I'm going to build a custom",
    "start": "227400",
    "end": "229480"
  },
  {
    "text": "evaluator that's going to take uh see",
    "start": "229480",
    "end": "232000"
  },
  {
    "text": "this reference is the reference answer",
    "start": "232000",
    "end": "235040"
  },
  {
    "text": "here so this is for every question I",
    "start": "235040",
    "end": "236760"
  },
  {
    "text": "have a reference answer and it's also",
    "start": "236760",
    "end": "238879"
  },
  {
    "text": "from my chain gonna get my rag pipeline",
    "start": "238879",
    "end": "241519"
  },
  {
    "text": "prediction and it's going to compare my",
    "start": "241519",
    "end": "244360"
  },
  {
    "text": "reference to the prediction using this",
    "start": "244360",
    "end": "245840"
  },
  {
    "text": "prompt right here so it's all super",
    "start": "245840",
    "end": "247560"
  },
  {
    "text": "transparent um really nice simple way",
    "start": "247560",
    "end": "249920"
  },
  {
    "text": "all I have to do is basically use um",
    "start": "249920",
    "end": "252200"
  },
  {
    "text": "you'll see down here but this Lang Smith",
    "start": "252200",
    "end": "254079"
  },
  {
    "text": "evaluate function uh that I can pass",
    "start": "254079",
    "end": "257199"
  },
  {
    "text": "this this uh evaluator function into",
    "start": "257199",
    "end": "259959"
  },
  {
    "text": "it's super simple um and that's all I",
    "start": "259959",
    "end": "262440"
  },
  {
    "text": "need to do it's basically going to take",
    "start": "262440",
    "end": "264759"
  },
  {
    "text": "in my run and my example so the run is",
    "start": "264759",
    "end": "267800"
  },
  {
    "text": "like my chain the example is is the",
    "start": "267800",
    "end": "269960"
  },
  {
    "text": "example from my data set it can extract",
    "start": "269960",
    "end": "272680"
  },
  {
    "text": "from my run uh the predicted answer it",
    "start": "272680",
    "end": "276759"
  },
  {
    "text": "extracts from my data set example the",
    "start": "276759",
    "end": "279240"
  },
  {
    "text": "reference answer it Compares I'm using",
    "start": "279240",
    "end": "281280"
  },
  {
    "text": "this prompt here I use llm as a judge in",
    "start": "281280",
    "end": "283600"
  },
  {
    "text": "this case I'm using gbd4 turbo as the",
    "start": "283600",
    "end": "285400"
  },
  {
    "text": "judge um and it outputs a structured",
    "start": "285400",
    "end": "288320"
  },
  {
    "text": "object as grade which I specify here and",
    "start": "288320",
    "end": "291160"
  },
  {
    "text": "I normalize that uh so it's the raw",
    "start": "291160",
    "end": "293120"
  },
  {
    "text": "scores between 10 best one worst",
    "start": "293120",
    "end": "295960"
  },
  {
    "text": "normalize that by 10 so it's one and 0.1",
    "start": "295960",
    "end": "299199"
  },
  {
    "text": "that's all I need to do super simple I",
    "start": "299199",
    "end": "301720"
  },
  {
    "text": "run evaluation on my three models right",
    "start": "301720",
    "end": "304520"
  },
  {
    "text": "here and we can then go over and we can",
    "start": "304520",
    "end": "308360"
  },
  {
    "text": "look at our data set it'll now have",
    "start": "308360",
    "end": "310560"
  },
  {
    "text": "three experiments so that's what you see",
    "start": "310560",
    "end": "312600"
  },
  {
    "text": "right here so you can see my experiments",
    "start": "312600",
    "end": "315880"
  },
  {
    "text": "are gbd4 116 gbd4 turbo and gbd4 o or",
    "start": "315880",
    "end": "322120"
  },
  {
    "text": "sorry gbd4 uh yeah Omni or o and what",
    "start": "322120",
    "end": "325720"
  },
  {
    "text": "you can see here which is pretty nice",
    "start": "325720",
    "end": "327120"
  },
  {
    "text": "the answer accuracy so you can see I can",
    "start": "327120",
    "end": "329400"
  },
  {
    "text": "see my answer accuracy this is now the",
    "start": "329400",
    "end": "331240"
  },
  {
    "text": "aggregate score goes from",
    "start": "331240",
    "end": "334000"
  },
  {
    "text": "084 um 084 up to 088 so it does increase",
    "start": "334000",
    "end": "339240"
  },
  {
    "text": "and you actually see that in this plot",
    "start": "339240",
    "end": "340680"
  },
  {
    "text": "here it does increase between my three",
    "start": "340680",
    "end": "342600"
  },
  {
    "text": "experiments so it does appear that Omni",
    "start": "342600",
    "end": "345039"
  },
  {
    "text": "is indeed better than the other two",
    "start": "345039",
    "end": "346960"
  },
  {
    "text": "variants in terms of answer accuracy now",
    "start": "346960",
    "end": "349960"
  },
  {
    "text": "let's say also want to look at latency",
    "start": "349960",
    "end": "352160"
  },
  {
    "text": "this is the other major thing that's in",
    "start": "352160",
    "end": "353680"
  },
  {
    "text": "fact this is really the thing that uh",
    "start": "353680",
    "end": "355440"
  },
  {
    "text": "they really highlight with on me I can",
    "start": "355440",
    "end": "357160"
  },
  {
    "text": "look at the accur the the latency p50",
    "start": "357160",
    "end": "359440"
  },
  {
    "text": "late latency between the three",
    "start": "359440",
    "end": "360560"
  },
  {
    "text": "experiments and I actually can see the",
    "start": "360560",
    "end": "362000"
  },
  {
    "text": "latency shows a big difference so you",
    "start": "362000",
    "end": "364639"
  },
  {
    "text": "know between tur gbd4 turbo which is the",
    "start": "364639",
    "end": "367240"
  },
  {
    "text": "prior state of the-art in this model the",
    "start": "367240",
    "end": "369240"
  },
  {
    "text": "latency drops actually quite a bit looks",
    "start": "369240",
    "end": "370840"
  },
  {
    "text": "like maybe a 30% latency drop here",
    "start": "370840",
    "end": "373360"
  },
  {
    "text": "that's really good you can see my p50",
    "start": "373360",
    "end": "374960"
  },
  {
    "text": "goes from 23 seconds down to 16 seconds",
    "start": "374960",
    "end": "378039"
  },
  {
    "text": "and the answer accuracy as we showed",
    "start": "378039",
    "end": "379919"
  },
  {
    "text": "before increases so that's kind of a",
    "start": "379919",
    "end": "381520"
  },
  {
    "text": "clear win there and if the cost uh you",
    "start": "381520",
    "end": "384840"
  },
  {
    "text": "know benefits carry over then I would",
    "start": "384840",
    "end": "387080"
  },
  {
    "text": "know pretty definitively this looks like",
    "start": "387080",
    "end": "388720"
  },
  {
    "text": "a really safe upgrade for my particular",
    "start": "388720",
    "end": "390720"
  },
  {
    "text": "app um in terms of latency in terms of",
    "start": "390720",
    "end": "393520"
  },
  {
    "text": "my evaluator accuracy and in terms of",
    "start": "393520",
    "end": "395560"
  },
  {
    "text": "cost which uh we actually don't we",
    "start": "395560",
    "end": "397440"
  },
  {
    "text": "actually do have costs typically logged",
    "start": "397440",
    "end": "400720"
  },
  {
    "text": "um but we don't have the costs yet in",
    "start": "400720",
    "end": "402680"
  },
  {
    "text": "for this model I believe and so this",
    "start": "402680",
    "end": "404599"
  },
  {
    "text": "just came out today but you'll have that",
    "start": "404599",
    "end": "406319"
  },
  {
    "text": "available to you very short very soon in",
    "start": "406319",
    "end": "407960"
  },
  {
    "text": "L Smith as well so if I want to dig in",
    "start": "407960",
    "end": "410120"
  },
  {
    "text": "deeper I can just click these through",
    "start": "410120",
    "end": "411280"
  },
  {
    "text": "experiments I can go to compare and this",
    "start": "411280",
    "end": "413639"
  },
  {
    "text": "opens up our comparison mode so here",
    "start": "413639",
    "end": "415759"
  },
  {
    "text": "what's pretty cool I can set a baseline",
    "start": "415759",
    "end": "417800"
  },
  {
    "text": "so in this particular case I'm going to",
    "start": "417800",
    "end": "419319"
  },
  {
    "text": "set 116 is my Baseline and I'm then can",
    "start": "419319",
    "end": "422759"
  },
  {
    "text": "compare turbo and uh gbd4 or Omni and",
    "start": "422759",
    "end": "427879"
  },
  {
    "text": "what I can see as I go through I can see",
    "start": "427879",
    "end": "430479"
  },
  {
    "text": "all the cases that I should get worse or",
    "start": "430479",
    "end": "432360"
  },
  {
    "text": "better and you can see summarized at the",
    "start": "432360",
    "end": "434319"
  },
  {
    "text": "top two get better four get worse in",
    "start": "434319",
    "end": "436599"
  },
  {
    "text": "this case six get better three get worse",
    "start": "436599",
    "end": "438400"
  },
  {
    "text": "so again we can see that Omni improves",
    "start": "438400",
    "end": "441160"
  },
  {
    "text": "which we also saw from the aggregate",
    "start": "441160",
    "end": "442360"
  },
  {
    "text": "scores but you can really look granular",
    "start": "442360",
    "end": "444000"
  },
  {
    "text": "each example and see why it improves um",
    "start": "444000",
    "end": "447280"
  },
  {
    "text": "you can click here to actually open up",
    "start": "447280",
    "end": "450039"
  },
  {
    "text": "that particular um that particular",
    "start": "450039",
    "end": "452520"
  },
  {
    "text": "example you can dig in here's the",
    "start": "452520",
    "end": "454080"
  },
  {
    "text": "reference input reference output here's",
    "start": "454080",
    "end": "455919"
  },
  {
    "text": "my three generations you can really look",
    "start": "455919",
    "end": "458080"
  },
  {
    "text": "granularly and explore whether or not",
    "start": "458080",
    "end": "460280"
  },
  {
    "text": "you agree with the evaluator so this",
    "start": "460280",
    "end": "462560"
  },
  {
    "text": "really gives you a nice way to",
    "start": "462560",
    "end": "463800"
  },
  {
    "text": "granularly go in Canin yourself that",
    "start": "463800",
    "end": "466159"
  },
  {
    "text": "it's safe in your particular case to",
    "start": "466159",
    "end": "468159"
  },
  {
    "text": "upgrade to the new gbd4 Omni and if I",
    "start": "468159",
    "end": "471199"
  },
  {
    "text": "zoom all the way back out in our",
    "start": "471199",
    "end": "473120"
  },
  {
    "text": "particular case this is just again eval",
    "start": "473120",
    "end": "475280"
  },
  {
    "text": "set 20 Questions related to land",
    "start": "475280",
    "end": "477120"
  },
  {
    "text": "transpression language what I can see is",
    "start": "477120",
    "end": "479560"
  },
  {
    "text": "is uh the I'm going to bring up the",
    "start": "479560",
    "end": "481840"
  },
  {
    "text": "latency as well the answer accuracy gets",
    "start": "481840",
    "end": "484599"
  },
  {
    "text": "better with GPD 4 Omni which is great",
    "start": "484599",
    "end": "486960"
  },
  {
    "text": "the latency drops quite a bit so that's",
    "start": "486960",
    "end": "488759"
  },
  {
    "text": "also a win and if the cost reduction is",
    "start": "488759",
    "end": "491199"
  },
  {
    "text": "as reported then this would be a clear",
    "start": "491199",
    "end": "493159"
  },
  {
    "text": "win a safe upgrade in my particular case",
    "start": "493159",
    "end": "495800"
  },
  {
    "text": "thanks",
    "start": "495800",
    "end": "498800"
  }
]
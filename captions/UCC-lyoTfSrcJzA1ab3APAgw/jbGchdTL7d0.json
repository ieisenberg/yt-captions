[
  {
    "start": "0",
    "end": "30000"
  },
  {
    "text": "hi this is Lance from Lang chain I'm",
    "start": "1880",
    "end": "4080"
  },
  {
    "text": "going to be talking about retrieval and",
    "start": "4080",
    "end": "6160"
  },
  {
    "text": "long context llms and a new method",
    "start": "6160",
    "end": "8920"
  },
  {
    "text": "called",
    "start": "8920",
    "end": "9840"
  },
  {
    "text": "Raptor so over the last few weeks",
    "start": "9840",
    "end": "12000"
  },
  {
    "text": "there's been a lot of talk about is rag",
    "start": "12000",
    "end": "14200"
  },
  {
    "text": "Dead with the Advent of new long Contex",
    "start": "14200",
    "end": "16920"
  },
  {
    "text": "llms like Gemini a million tokens Claude",
    "start": "16920",
    "end": "20439"
  },
  {
    "text": "3 now with up to a million tokens it's",
    "start": "20439",
    "end": "22920"
  },
  {
    "text": "an interesting",
    "start": "22920",
    "end": "24240"
  },
  {
    "text": "question um I've recently been using",
    "start": "24240",
    "end": "26760"
  },
  {
    "text": "long Contex llms for certain projects",
    "start": "26760",
    "end": "29800"
  },
  {
    "text": "like like for example this code",
    "start": "29800",
    "end": "31320"
  },
  {
    "start": "30000",
    "end": "538000"
  },
  {
    "text": "assistant that I put out last week",
    "start": "31320",
    "end": "34120"
  },
  {
    "text": "basically used a long context llm to",
    "start": "34120",
    "end": "36600"
  },
  {
    "text": "answer coding questions about our docs",
    "start": "36600",
    "end": "39879"
  },
  {
    "text": "on L expression language I'll kind of",
    "start": "39879",
    "end": "42120"
  },
  {
    "text": "zoom in here so you can see it um so",
    "start": "42120",
    "end": "44920"
  },
  {
    "text": "these are around 60,000 tokens of",
    "start": "44920",
    "end": "46960"
  },
  {
    "text": "context we take the question we take the",
    "start": "46960",
    "end": "50120"
  },
  {
    "text": "docs we produce an answer and this is",
    "start": "50120",
    "end": "52960"
  },
  {
    "text": "really nice no retrieval required just",
    "start": "52960",
    "end": "56039"
  },
  {
    "text": "context stuff all these docs and perform",
    "start": "56039",
    "end": "58559"
  },
  {
    "text": "answer generation directly",
    "start": "58559",
    "end": "60559"
  },
  {
    "text": "so I'm a big fan of using La context",
    "start": "60559",
    "end": "62480"
  },
  {
    "text": "llms in this",
    "start": "62480",
    "end": "64198"
  },
  {
    "text": "way but there are some considerations I",
    "start": "64199",
    "end": "66760"
  },
  {
    "text": "wanted to like to to kind of point out",
    "start": "66760",
    "end": "69040"
  },
  {
    "text": "here so I ran evaluations and for those",
    "start": "69040",
    "end": "72799"
  },
  {
    "text": "evaluations I look at 20 questions um so",
    "start": "72799",
    "end": "76240"
  },
  {
    "text": "basically it's 20",
    "start": "76240",
    "end": "77799"
  },
  {
    "text": "Generations now look here so this is the",
    "start": "77799",
    "end": "80920"
  },
  {
    "text": "Langs Smith dashboard that I used for",
    "start": "80920",
    "end": "83680"
  },
  {
    "text": "those EV vals and you can see something",
    "start": "83680",
    "end": "85799"
  },
  {
    "text": "kind of interesting the p50 latency",
    "start": "85799",
    "end": "88680"
  },
  {
    "text": "tells you the 50th percentile latency",
    "start": "88680",
    "end": "91079"
  },
  {
    "text": "for each of those Generations um so",
    "start": "91079",
    "end": "93840"
  },
  {
    "text": "again remember there's",
    "start": "93840",
    "end": "95520"
  },
  {
    "text": "20 so it's around 35 to you know 46",
    "start": "95520",
    "end": "99680"
  },
  {
    "text": "seconds depending on the the trial this",
    "start": "99680",
    "end": "101720"
  },
  {
    "text": "is on the same data set same 20",
    "start": "101720",
    "end": "104040"
  },
  {
    "text": "Questions there's some variance run to",
    "start": "104040",
    "end": "106079"
  },
  {
    "text": "run so that's kind of expected and again",
    "start": "106079",
    "end": "107759"
  },
  {
    "text": "the P99 it's up to like okay 420 seconds",
    "start": "107759",
    "end": "111240"
  },
  {
    "text": "that's really long in that",
    "start": "111240",
    "end": "112880"
  },
  {
    "text": "case but maybe more interestingly if you",
    "start": "112880",
    "end": "115680"
  },
  {
    "text": "look at the cost again there's 20",
    "start": "115680",
    "end": "117520"
  },
  {
    "text": "questions so the cost is ranging from",
    "start": "117520",
    "end": "120039"
  },
  {
    "text": "maybe like a dollar to you know a dollar",
    "start": "120039",
    "end": "122920"
  },
  {
    "text": "a dollar like 30 per",
    "start": "122920",
    "end": "124840"
  },
  {
    "text": "generation so you know C and Lanes your",
    "start": "124840",
    "end": "127880"
  },
  {
    "text": "things to think about when you're",
    "start": "127880",
    "end": "128840"
  },
  {
    "text": "talking about using really long Contex",
    "start": "128840",
    "end": "130479"
  },
  {
    "text": "llms as opposed to like a rag system",
    "start": "130479",
    "end": "133760"
  },
  {
    "text": "where you're per you're performing",
    "start": "133760",
    "end": "135080"
  },
  {
    "text": "retrieval of much smaller more directed",
    "start": "135080",
    "end": "137680"
  },
  {
    "text": "chunks to your",
    "start": "137680",
    "end": "139760"
  },
  {
    "text": "question now the other thing that came",
    "start": "139760",
    "end": "142200"
  },
  {
    "text": "up is a lot of people asked hey can you",
    "start": "142200",
    "end": "145280"
  },
  {
    "text": "swap this out and use a local",
    "start": "145280",
    "end": "148519"
  },
  {
    "text": "llm and my go-to local llm is mistol 7B",
    "start": "148519",
    "end": "152720"
  },
  {
    "text": "V2 which actually has a 32,000 token",
    "start": "152720",
    "end": "156000"
  },
  {
    "text": "context window but that's still a little",
    "start": "156000",
    "end": "158480"
  },
  {
    "text": "bit big relative to my docs which are",
    "start": "158480",
    "end": "161239"
  },
  {
    "text": "around 60,000 tokens so you know I",
    "start": "161239",
    "end": "164720"
  },
  {
    "text": "couldn't just context stuff them as I",
    "start": "164720",
    "end": "167440"
  },
  {
    "text": "did here so these three considerations",
    "start": "167440",
    "end": "171000"
  },
  {
    "text": "kind of led me to think",
    "start": "171000",
    "end": "173120"
  },
  {
    "text": "about I really like working with long",
    "start": "173120",
    "end": "175519"
  },
  {
    "text": "context models and it's absolutely going",
    "start": "175519",
    "end": "177840"
  },
  {
    "text": "to be the continuing thing but are there",
    "start": "177840",
    "end": "180640"
  },
  {
    "text": "retrieval strategies that are like",
    "start": "180640",
    "end": "182599"
  },
  {
    "text": "lightweight easy to use with long",
    "start": "182599",
    "end": "184840"
  },
  {
    "text": "context models um that kind of like",
    "start": "184840",
    "end": "188480"
  },
  {
    "text": "preserve the ability to utilize a lot of",
    "start": "188480",
    "end": "191519"
  },
  {
    "text": "context uh but can address some of these",
    "start": "191519",
    "end": "194640"
  },
  {
    "text": "limitations um in particular this last",
    "start": "194640",
    "end": "197560"
  },
  {
    "text": "piece was important because this is",
    "start": "197560",
    "end": "199239"
  },
  {
    "text": "something I want to do kind of in the",
    "start": "199239",
    "end": "200519"
  },
  {
    "text": "near term and I need kind of like a nice",
    "start": "200519",
    "end": "202959"
  },
  {
    "text": "lightweight retrieval strategy that",
    "start": "202959",
    "end": "205000"
  },
  {
    "text": "still uses long context but can operate",
    "start": "205000",
    "end": "208439"
  },
  {
    "text": "in cases where my documents are maybe",
    "start": "208439",
    "end": "211000"
  },
  {
    "text": "just a little bit bigger than my context",
    "start": "211000",
    "end": "213000"
  },
  {
    "text": "window in this case like around",
    "start": "213000",
    "end": "215000"
  },
  {
    "text": "2x so I kind of put this out on Twitter",
    "start": "215000",
    "end": "217400"
  },
  {
    "text": "and said hey has anyone come across like",
    "start": "217400",
    "end": "220599"
  },
  {
    "text": "good like maybe minimalist splitting",
    "start": "220599",
    "end": "223000"
  },
  {
    "text": "strategies for long contuct LMS you know",
    "start": "223000",
    "end": "225720"
  },
  {
    "text": "like I wanted to graag with mrol 7B with",
    "start": "225720",
    "end": "228400"
  },
  {
    "text": "a 32,000 token context window but my",
    "start": "228400",
    "end": "230799"
  },
  {
    "text": "docs are 60,000 tokens I can't just",
    "start": "230799",
    "end": "233799"
  },
  {
    "text": "context stuff them but I also don't want",
    "start": "233799",
    "end": "237200"
  },
  {
    "text": "some like very fine scale chunking thck",
    "start": "237200",
    "end": "239720"
  },
  {
    "text": "thing like I get it we don't want to",
    "start": "239720",
    "end": "241360"
  },
  {
    "text": "mess with all that we want something",
    "start": "241360",
    "end": "242879"
  },
  {
    "text": "simple that just can like kind of work",
    "start": "242879",
    "end": "244599"
  },
  {
    "text": "across larger",
    "start": "244599",
    "end": "246120"
  },
  {
    "text": "documents so one point that was raised",
    "start": "246120",
    "end": "248959"
  },
  {
    "text": "which is a really good one is well just",
    "start": "248959",
    "end": "253159"
  },
  {
    "text": "um just index at the document level so",
    "start": "253159",
    "end": "255959"
  },
  {
    "text": "you can take full documents and just",
    "start": "255959",
    "end": "257560"
  },
  {
    "text": "embed them directly it's a fair point",
    "start": "257560",
    "end": "260639"
  },
  {
    "text": "and then you do something like KNN on",
    "start": "260639",
    "end": "262479"
  },
  {
    "text": "those embedded documents so again no",
    "start": "262479",
    "end": "264880"
  },
  {
    "text": "chunking of any documents no splitting",
    "start": "264880",
    "end": "266880"
  },
  {
    "text": "of documents you have your set of",
    "start": "266880",
    "end": "268639"
  },
  {
    "text": "documents embedded one and just retrieve",
    "start": "268639",
    "end": "271600"
  },
  {
    "text": "at the document level that's a pretty",
    "start": "271600",
    "end": "273919"
  },
  {
    "text": "good idea that's pretty",
    "start": "273919",
    "end": "275759"
  },
  {
    "text": "reasonable another idea that came up",
    "start": "275759",
    "end": "278160"
  },
  {
    "text": "though is this idea of building a",
    "start": "278160",
    "end": "280880"
  },
  {
    "text": "document tree and part of the reason for",
    "start": "280880",
    "end": "283120"
  },
  {
    "text": "that is when you talk about something",
    "start": "283120",
    "end": "285080"
  },
  {
    "text": "like KNN or like you know K nearest",
    "start": "285080",
    "end": "288120"
  },
  {
    "text": "neighbor retrieval on a set of embedded",
    "start": "288120",
    "end": "290080"
  },
  {
    "text": "documents it is true that sometimes an",
    "start": "290080",
    "end": "292440"
  },
  {
    "text": "answer requires maybe two or three",
    "start": "292440",
    "end": "294800"
  },
  {
    "text": "different documents kind of integrated",
    "start": "294800",
    "end": "296680"
  },
  {
    "text": "in order to answer it now if you context",
    "start": "296680",
    "end": "299360"
  },
  {
    "text": "St everything that's not a problem",
    "start": "299360",
    "end": "301160"
  },
  {
    "text": "because it's all there if you're doing",
    "start": "301160",
    "end": "303240"
  },
  {
    "text": "retrieval well you're setting your K",
    "start": "303240",
    "end": "305400"
  },
  {
    "text": "parameter to be some value it's kind of",
    "start": "305400",
    "end": "308000"
  },
  {
    "text": "brittle do you need to be like four or",
    "start": "308000",
    "end": "310080"
  },
  {
    "text": "five or six to capture all the context",
    "start": "310080",
    "end": "312199"
  },
  {
    "text": "needed for certain particular questions",
    "start": "312199",
    "end": "314400"
  },
  {
    "text": "so it's kind of hard to set that so this",
    "start": "314400",
    "end": "317520"
  },
  {
    "text": "idea of building a documentary is kind",
    "start": "317520",
    "end": "319720"
  },
  {
    "text": "of an interesting way to potentially",
    "start": "319720",
    "end": "321520"
  },
  {
    "text": "address this challenge with like basic",
    "start": "321520",
    "end": "324520"
  },
  {
    "text": "Cann so a paper Raptor came out recently",
    "start": "324520",
    "end": "329039"
  },
  {
    "text": "on this exact",
    "start": "329039",
    "end": "330560"
  },
  {
    "text": "idea um and their code recently open",
    "start": "330560",
    "end": "333120"
  },
  {
    "text": "sourced which led the folks at llama",
    "start": "333120",
    "end": "335199"
  },
  {
    "text": "index to come out with a llama pack for",
    "start": "335199",
    "end": "336840"
  },
  {
    "text": "it which is great um and the idea is",
    "start": "336840",
    "end": "340919"
  },
  {
    "text": "pretty interesting so I wanted to kind",
    "start": "340919",
    "end": "342600"
  },
  {
    "text": "of lay it out here and talk about how it",
    "start": "342600",
    "end": "344479"
  },
  {
    "text": "might benefit this exact case of kind of",
    "start": "344479",
    "end": "346440"
  },
  {
    "text": "long context",
    "start": "346440",
    "end": "348120"
  },
  {
    "text": "retrieval so the intuition is pretty",
    "start": "348120",
    "end": "351800"
  },
  {
    "text": "simple First We Take a set of documents",
    "start": "351800",
    "end": "355880"
  },
  {
    "text": "now note that these documents can be any",
    "start": "355880",
    "end": "358000"
  },
  {
    "text": "sized so in their case they're just",
    "start": "358000",
    "end": "360960"
  },
  {
    "text": "chunks so they're like 100 tokens but it",
    "start": "360960",
    "end": "364360"
  },
  {
    "text": "doesn't matter so we start with a set of",
    "start": "364360",
    "end": "366479"
  },
  {
    "text": "raw documents now what we do is we embed",
    "start": "366479",
    "end": "370280"
  },
  {
    "text": "them and then we cluster them so this",
    "start": "370280",
    "end": "373520"
  },
  {
    "text": "clustering process groups together like",
    "start": "373520",
    "end": "375880"
  },
  {
    "text": "documents and then we do one important",
    "start": "375880",
    "end": "378240"
  },
  {
    "text": "thing we summarize information in that",
    "start": "378240",
    "end": "380960"
  },
  {
    "text": "cluster into what we call kind of like a",
    "start": "380960",
    "end": "383160"
  },
  {
    "text": "more abstract or higher level summary of",
    "start": "383160",
    "end": "385880"
  },
  {
    "text": "that",
    "start": "385880",
    "end": "386759"
  },
  {
    "text": "content and we do that recursively until",
    "start": "386759",
    "end": "389479"
  },
  {
    "text": "we end up with one cluster that's it so",
    "start": "389479",
    "end": "392639"
  },
  {
    "text": "what's happening is you're starting with",
    "start": "392639",
    "end": "394199"
  },
  {
    "text": "the set of what they call leaves or like",
    "start": "394199",
    "end": "396039"
  },
  {
    "text": "raw documents you do a",
    "start": "396039",
    "end": "398759"
  },
  {
    "text": "grouping uh via clustering you do a",
    "start": "398759",
    "end": "401160"
  },
  {
    "text": "summarization steps you're kind of",
    "start": "401160",
    "end": "402919"
  },
  {
    "text": "compressing and then you do it again and",
    "start": "402919",
    "end": "405840"
  },
  {
    "text": "the idea is that these kind of midlevel",
    "start": "405840",
    "end": "409000"
  },
  {
    "text": "or eventually like root level or highest",
    "start": "409000",
    "end": "411479"
  },
  {
    "text": "level summaries can consolidate",
    "start": "411479",
    "end": "413240"
  },
  {
    "text": "information from different places in",
    "start": "413240",
    "end": "414599"
  },
  {
    "text": "your documents now what they do is they",
    "start": "414599",
    "end": "418000"
  },
  {
    "text": "basically just embed those summaries",
    "start": "418000",
    "end": "420479"
  },
  {
    "text": "along with the raw leavs and they",
    "start": "420479",
    "end": "421960"
  },
  {
    "text": "perform retrieval and we'll talk about",
    "start": "421960",
    "end": "423919"
  },
  {
    "text": "that a little bit later but what they",
    "start": "423919",
    "end": "425120"
  },
  {
    "text": "show is actually just doing retrieval on",
    "start": "425120",
    "end": "428720"
  },
  {
    "text": "all of these together like as a whole",
    "start": "428720",
    "end": "430599"
  },
  {
    "text": "pool performs best um and that's kind of",
    "start": "430599",
    "end": "433400"
  },
  {
    "text": "a nice result it's pretty easy then to",
    "start": "433400",
    "end": "436280"
  },
  {
    "text": "basically just index that and and use",
    "start": "436280",
    "end": "439400"
  },
  {
    "text": "it I will make a note that their paper",
    "start": "439400",
    "end": "442319"
  },
  {
    "text": "talked about you know these leavs being",
    "start": "442319",
    "end": "444840"
  },
  {
    "text": "chunks which I didn't love because look",
    "start": "444840",
    "end": "446879"
  },
  {
    "text": "I want to work with long context models",
    "start": "446879",
    "end": "449160"
  },
  {
    "text": "and like I don't want to deal with",
    "start": "449160",
    "end": "450720"
  },
  {
    "text": "chunking at all and I've replied you",
    "start": "450720",
    "end": "453840"
  },
  {
    "text": "know I replied to Jerry's tweet on this",
    "start": "453840",
    "end": "455360"
  },
  {
    "text": "and Jerry made a fair point that you",
    "start": "455360",
    "end": "456919"
  },
  {
    "text": "know this can scale to anything so for",
    "start": "456919",
    "end": "460120"
  },
  {
    "text": "example those leavs can be full",
    "start": "460120",
    "end": "463360"
  },
  {
    "text": "documents they don't have to be chunks",
    "start": "463360",
    "end": "465000"
  },
  {
    "text": "that's completely reasonable Point um so",
    "start": "465000",
    "end": "468000"
  },
  {
    "text": "again you can kind of think about this",
    "start": "468000",
    "end": "469440"
  },
  {
    "text": "as if idea one was let's just take each",
    "start": "469440",
    "end": "472919"
  },
  {
    "text": "document and embed it idea two is well",
    "start": "472919",
    "end": "476960"
  },
  {
    "text": "let's embed each document like we did",
    "start": "476960",
    "end": "478680"
  },
  {
    "text": "and we can also build kind of like a a",
    "start": "478680",
    "end": "480400"
  },
  {
    "text": "document abstraction Tree on top and",
    "start": "480400",
    "end": "482240"
  },
  {
    "text": "embed those so we have these like higher",
    "start": "482240",
    "end": "484840"
  },
  {
    "text": "level summaries in our embeddings which",
    "start": "484840",
    "end": "487039"
  },
  {
    "text": "we can retrieve from if we need an",
    "start": "487039",
    "end": "488800"
  },
  {
    "text": "answer to conate information from like a",
    "start": "488800",
    "end": "490960"
  },
  {
    "text": "small set of documents right so it's a",
    "start": "490960",
    "end": "493639"
  },
  {
    "text": "little bit more robust maybe to this",
    "start": "493639",
    "end": "495720"
  },
  {
    "text": "problem which is that if I'm just doing",
    "start": "495720",
    "end": "498159"
  },
  {
    "text": "KNN on Raw documents and I need",
    "start": "498159",
    "end": "500400"
  },
  {
    "text": "information from like two or three",
    "start": "500400",
    "end": "501879"
  },
  {
    "text": "documents I'm not guaranteed to always",
    "start": "501879",
    "end": "504039"
  },
  {
    "text": "get that because of this K parameter",
    "start": "504039",
    "end": "506919"
  },
  {
    "text": "that I set I'm only retrieving k docks",
    "start": "506919",
    "end": "510360"
  },
  {
    "text": "whereas here I'm building these docks",
    "start": "510360",
    "end": "513719"
  },
  {
    "text": "that contain information from multiple",
    "start": "513719",
    "end": "516080"
  },
  {
    "text": "leaves or multiple you know suboc so to",
    "start": "516080",
    "end": "519159"
  },
  {
    "text": "speak um and it can actually just",
    "start": "519159",
    "end": "521880"
  },
  {
    "text": "capture that information uh in in a in",
    "start": "521880",
    "end": "524800"
  },
  {
    "text": "kind of a a nice way um such that it can",
    "start": "524800",
    "end": "529600"
  },
  {
    "text": "it can basically integrate information",
    "start": "529600",
    "end": "531440"
  },
  {
    "text": "across different individual leads or",
    "start": "531440",
    "end": "533279"
  },
  {
    "text": "individual documents so that's the key",
    "start": "533279",
    "end": "536880"
  },
  {
    "text": "Point um and so we can you can kind of",
    "start": "536880",
    "end": "539600"
  },
  {
    "start": "538000",
    "end": "878000"
  },
  {
    "text": "see when you think about like working",
    "start": "539600",
    "end": "541399"
  },
  {
    "text": "long context models of course context",
    "start": "541399",
    "end": "543279"
  },
  {
    "text": "stuffing is a great option if you can do",
    "start": "543279",
    "end": "544880"
  },
  {
    "text": "it but there are some other interesting",
    "start": "544880",
    "end": "547040"
  },
  {
    "text": "ideas one is actually just embedding",
    "start": "547040",
    "end": "549120"
  },
  {
    "text": "full documents and another is this idea",
    "start": "549120",
    "end": "550920"
  },
  {
    "text": "of again documents and an abstraction",
    "start": "550920",
    "end": "553320"
  },
  {
    "text": "tree so let's go ahead and just build",
    "start": "553320",
    "end": "556160"
  },
  {
    "text": "Raptor because it's pretty interesting",
    "start": "556160",
    "end": "558640"
  },
  {
    "text": "and to do this I'm actually going to",
    "start": "558640",
    "end": "560600"
  },
  {
    "text": "going to look at clae 3 which just came",
    "start": "560600",
    "end": "562399"
  },
  {
    "text": "out today it's a new set of model Str",
    "start": "562399",
    "end": "564040"
  },
  {
    "text": "anthropic really strong performance and",
    "start": "564040",
    "end": "566800"
  },
  {
    "text": "should be really good for this use case",
    "start": "566800",
    "end": "569240"
  },
  {
    "text": "because what I want to do is I want to",
    "start": "569240",
    "end": "571560"
  },
  {
    "text": "perform summaries of individual",
    "start": "571560",
    "end": "573399"
  },
  {
    "text": "documents and I don't really want to",
    "start": "573399",
    "end": "574800"
  },
  {
    "text": "worry about the size of those",
    "start": "574800",
    "end": "576680"
  },
  {
    "text": "documents um so I'm going to use the",
    "start": "576680",
    "end": "579880"
  },
  {
    "text": "same set of documents that I previously",
    "start": "579880",
    "end": "582680"
  },
  {
    "text": "did with the code generation example",
    "start": "582680",
    "end": "585320"
  },
  {
    "text": "that video came out last week and I have",
    "start": "585320",
    "end": "586680"
  },
  {
    "text": "an empty notebook here um it we just do",
    "start": "586680",
    "end": "590000"
  },
  {
    "text": "a few pip installs I'm setting a few",
    "start": "590000",
    "end": "592320"
  },
  {
    "text": "environment variables for lsmith and now",
    "start": "592320",
    "end": "594680"
  },
  {
    "text": "I'm just going to say grab my docs so",
    "start": "594680",
    "end": "597600"
  },
  {
    "text": "that's right here",
    "start": "597600",
    "end": "599800"
  },
  {
    "text": "and this is going to grab around 33 web",
    "start": "599800",
    "end": "602160"
  },
  {
    "text": "pages of documentation from for Lang",
    "start": "602160",
    "end": "604800"
  },
  {
    "text": "chain related to Lang chain expression",
    "start": "604800",
    "end": "606640"
  },
  {
    "text": "language okay and what I'm going to plot",
    "start": "606640",
    "end": "609880"
  },
  {
    "text": "here is a histogram of the token counts",
    "start": "609880",
    "end": "611480"
  },
  {
    "text": "of every page so a bunch are kind of",
    "start": "611480",
    "end": "613600"
  },
  {
    "text": "small that's find easy to work with so",
    "start": "613600",
    "end": "615519"
  },
  {
    "text": "less than 2,000 tokens a few are pretty",
    "start": "615519",
    "end": "617640"
  },
  {
    "text": "big so up to like 12,000",
    "start": "617640",
    "end": "620160"
  },
  {
    "text": "tokens so that kind of gives you a sense",
    "start": "620160",
    "end": "622200"
  },
  {
    "text": "of the distribution of pages that we",
    "start": "622200",
    "end": "623640"
  },
  {
    "text": "want to work with and we're going to",
    "start": "623640",
    "end": "625040"
  },
  {
    "text": "apply this approach to those pages um",
    "start": "625040",
    "end": "628440"
  },
  {
    "text": "now I'm going to use anthropics new",
    "start": "628440",
    "end": "630160"
  },
  {
    "text": "model to do that um and I'll use open I",
    "start": "630160",
    "end": "632839"
  },
  {
    "text": "embeddings so that's fine I set those",
    "start": "632839",
    "end": "635920"
  },
  {
    "text": "and now what I'm going to do so this",
    "start": "635920",
    "end": "638240"
  },
  {
    "text": "code was released uh by the authors of",
    "start": "638240",
    "end": "640800"
  },
  {
    "text": "the paper and I'm going to explain how",
    "start": "640800",
    "end": "642920"
  },
  {
    "text": "this works in a little bit but for right",
    "start": "642920",
    "end": "645079"
  },
  {
    "text": "now I'm just going to copy this over and",
    "start": "645079",
    "end": "646480"
  },
  {
    "text": "this is all going to be accessible to",
    "start": "646480",
    "end": "647760"
  },
  {
    "text": "you in the notebook that we're going to",
    "start": "647760",
    "end": "648920"
  },
  {
    "text": "make public uh so this is all the",
    "start": "648920",
    "end": "651399"
  },
  {
    "text": "clustering code and we're going to talk",
    "start": "651399",
    "end": "652720"
  },
  {
    "text": "about what it's doing later I added",
    "start": "652720",
    "end": "654680"
  },
  {
    "text": "comments and Doc strings to this um so",
    "start": "654680",
    "end": "657160"
  },
  {
    "text": "it's it's a little bit more",
    "start": "657160",
    "end": "658639"
  },
  {
    "text": "understandable",
    "start": "658639",
    "end": "659720"
  },
  {
    "text": "here's some code that I wrote um that",
    "start": "659720",
    "end": "661800"
  },
  {
    "text": "basically is going to do like",
    "start": "661800",
    "end": "663120"
  },
  {
    "text": "orchestrate the process of the cluster",
    "start": "663120",
    "end": "666000"
  },
  {
    "text": "summarize um and then like iteratively",
    "start": "666000",
    "end": "668839"
  },
  {
    "text": "perform that until you end up with a",
    "start": "668839",
    "end": "670320"
  },
  {
    "text": "single",
    "start": "670320",
    "end": "671200"
  },
  {
    "text": "cluster um so there we go I'm going to",
    "start": "671200",
    "end": "674680"
  },
  {
    "text": "copy this code over and I'm going to",
    "start": "674680",
    "end": "676279"
  },
  {
    "text": "kick this process off and then I'm going",
    "start": "676279",
    "end": "678440"
  },
  {
    "text": "to walk through it while this is running",
    "start": "678440",
    "end": "680480"
  },
  {
    "text": "so that's running now now first I want",
    "start": "680480",
    "end": "683000"
  },
  {
    "text": "to kind of explain how this clustering",
    "start": "683000",
    "end": "684880"
  },
  {
    "text": "process works it's it's kind of",
    "start": "684880",
    "end": "686920"
  },
  {
    "text": "interesting um so the idea actually",
    "start": "686920",
    "end": "691040"
  },
  {
    "text": "incorporates three important actually",
    "start": "691040",
    "end": "693399"
  },
  {
    "text": "Four important",
    "start": "693399",
    "end": "695160"
  },
  {
    "text": "points so it's using this GMM this",
    "start": "695160",
    "end": "697920"
  },
  {
    "text": "gussian mixture model to model the",
    "start": "697920",
    "end": "700399"
  },
  {
    "text": "distribution of the different clusters",
    "start": "700399",
    "end": "703680"
  },
  {
    "text": "so what's kind of cool about this",
    "start": "703680",
    "end": "705120"
  },
  {
    "text": "approach is that you don't actually tell",
    "start": "705120",
    "end": "707760"
  },
  {
    "text": "it group the data into some number of",
    "start": "707760",
    "end": "710240"
  },
  {
    "text": "clusters like you do some of approaches",
    "start": "710240",
    "end": "712120"
  },
  {
    "text": "you kind of set the parameter you want",
    "start": "712120",
    "end": "714040"
  },
  {
    "text": "like n clusters here um it actually can",
    "start": "714040",
    "end": "717720"
  },
  {
    "text": "kind of infer or deter determine the",
    "start": "717720",
    "end": "719440"
  },
  {
    "text": "optimal number of clusters and it uses",
    "start": "719440",
    "end": "721120"
  },
  {
    "text": "this like Bic again you can dig into",
    "start": "721120",
    "end": "723920"
  },
  {
    "text": "this in more detail if you want but the",
    "start": "723920",
    "end": "725519"
  },
  {
    "text": "intuition is that uh this approach will",
    "start": "725519",
    "end": "728560"
  },
  {
    "text": "kind of guess or attempt to to determine",
    "start": "728560",
    "end": "730839"
  },
  {
    "text": "the number of clusters automatically for",
    "start": "730839",
    "end": "733000"
  },
  {
    "text": "you um and it's also modeling the",
    "start": "733000",
    "end": "736320"
  },
  {
    "text": "distribution of your individual",
    "start": "736320",
    "end": "738120"
  },
  {
    "text": "documents across the",
    "start": "738120",
    "end": "740320"
  },
  {
    "text": "Clusters um it uses this umap or",
    "start": "740320",
    "end": "744000"
  },
  {
    "text": "basically it's a dimensionality",
    "start": "744000",
    "end": "745480"
  },
  {
    "text": "reduction approach to improve the",
    "start": "745480",
    "end": "747560"
  },
  {
    "text": "clustering process so if you want to",
    "start": "747560",
    "end": "749639"
  },
  {
    "text": "like really read into this that you",
    "start": "749639",
    "end": "751120"
  },
  {
    "text": "should actually just go and do that um",
    "start": "751120",
    "end": "753639"
  },
  {
    "text": "the intuition is that this actually",
    "start": "753639",
    "end": "755199"
  },
  {
    "text": "helps improve",
    "start": "755199",
    "end": "756639"
  },
  {
    "text": "clustering um it also does clustering",
    "start": "756639",
    "end": "759199"
  },
  {
    "text": "what they call like local and Global so",
    "start": "759199",
    "end": "761440"
  },
  {
    "text": "it tries to analyze the data at two",
    "start": "761440",
    "end": "763320"
  },
  {
    "text": "different scales um like kind of look at",
    "start": "763320",
    "end": "766199"
  },
  {
    "text": "like patterns kind of within smaller",
    "start": "766199",
    "end": "768519"
  },
  {
    "text": "groups and then like within the full",
    "start": "768519",
    "end": "770079"
  },
  {
    "text": "data set to try to improve how you're",
    "start": "770079",
    "end": "772240"
  },
  {
    "text": "going to group these documents uh",
    "start": "772240",
    "end": "774720"
  },
  {
    "text": "together and it applies thresholding to",
    "start": "774720",
    "end": "779000"
  },
  {
    "text": "assign the basically the group",
    "start": "779000",
    "end": "781440"
  },
  {
    "text": "assignment for every document or the",
    "start": "781440",
    "end": "783279"
  },
  {
    "text": "cluster assignment for every document so",
    "start": "783279",
    "end": "785560"
  },
  {
    "text": "this is really the",
    "start": "785560",
    "end": "787199"
  },
  {
    "text": "idea here's all my documents let's look",
    "start": "787199",
    "end": "790320"
  },
  {
    "text": "at this one what's happening is it's",
    "start": "790320",
    "end": "792480"
  },
  {
    "text": "using this GMM to basically assign of",
    "start": "792480",
    "end": "795440"
  },
  {
    "text": "probability that this document belongs",
    "start": "795440",
    "end": "797720"
  },
  {
    "text": "to each one of our clusters so like",
    "start": "797720",
    "end": "800839"
  },
  {
    "text": "here's cluster one here's cluster two",
    "start": "800839",
    "end": "802399"
  },
  {
    "text": "here's cluster three each cluster will",
    "start": "802399",
    "end": "804560"
  },
  {
    "text": "get a",
    "start": "804560",
    "end": "805360"
  },
  {
    "text": "probability and this thresholding then",
    "start": "805360",
    "end": "807680"
  },
  {
    "text": "is applied to those",
    "start": "807680",
    "end": "809639"
  },
  {
    "text": "probabilities such that a document can",
    "start": "809639",
    "end": "812760"
  },
  {
    "text": "actually belong to more than one cluster",
    "start": "812760",
    "end": "815720"
  },
  {
    "text": "so that's actually really nice cuz in a",
    "start": "815720",
    "end": "817320"
  },
  {
    "text": "lot of other approaches it's kind of",
    "start": "817320",
    "end": "819079"
  },
  {
    "text": "mutually exclusive so document can only",
    "start": "819079",
    "end": "821320"
  },
  {
    "text": "live in one or another cluster but with",
    "start": "821320",
    "end": "823000"
  },
  {
    "text": "this approach it can actually be long to",
    "start": "823000",
    "end": "824920"
  },
  {
    "text": "multiple clusters so that's like a nice",
    "start": "824920",
    "end": "826720"
  },
  {
    "text": "benefit of this",
    "start": "826720",
    "end": "828639"
  },
  {
    "text": "approach um I think that's kind of all I",
    "start": "828639",
    "end": "831480"
  },
  {
    "text": "want to say initially about this",
    "start": "831480",
    "end": "833240"
  },
  {
    "text": "clustering strategy uh but you should",
    "start": "833240",
    "end": "836360"
  },
  {
    "text": "absolutely have a look at the paper",
    "start": "836360",
    "end": "838160"
  },
  {
    "text": "which I uh will also ensure that we",
    "start": "838160",
    "end": "841480"
  },
  {
    "text": "link um so right now let's actually go",
    "start": "841480",
    "end": "845480"
  },
  {
    "text": "look at the code so we can see that it's",
    "start": "845480",
    "end": "847680"
  },
  {
    "text": "performing this this cluster",
    "start": "847680",
    "end": "849680"
  },
  {
    "text": "generation and let's actually look at",
    "start": "849680",
    "end": "851639"
  },
  {
    "text": "kind of what it's doing so it really",
    "start": "851639",
    "end": "854480"
  },
  {
    "text": "follows what we just talked",
    "start": "854480",
    "end": "856440"
  },
  {
    "text": "about we have a set of texts and in this",
    "start": "856440",
    "end": "860040"
  },
  {
    "text": "case my texts are just that those you",
    "start": "860040",
    "end": "862920"
  },
  {
    "text": "know those 33 web pages uh that I'm",
    "start": "862920",
    "end": "866440"
  },
  {
    "text": "passing in so we can actually look at",
    "start": "866440",
    "end": "867920"
  },
  {
    "text": "that so what I passed in these Leaf text",
    "start": "867920",
    "end": "871399"
  },
  {
    "text": "Leaf text I Define as my docs again",
    "start": "871399",
    "end": "873880"
  },
  {
    "text": "let's actually go back and look at our",
    "start": "873880",
    "end": "875240"
  },
  {
    "text": "diagram so we can like follow",
    "start": "875240",
    "end": "877480"
  },
  {
    "text": "along uh here we go so these leaves are",
    "start": "877480",
    "end": "881000"
  },
  {
    "start": "878000",
    "end": "1095000"
  },
  {
    "text": "my web pages that's it so here's my leaf",
    "start": "881000",
    "end": "884480"
  },
  {
    "text": "text and you can see let's look at the",
    "start": "884480",
    "end": "886279"
  },
  {
    "text": "length there uh okay there's 31 of them",
    "start": "886279",
    "end": "890440"
  },
  {
    "text": "so that's",
    "start": "890440",
    "end": "891680"
  },
  {
    "text": "fine um and what's happening is those",
    "start": "891680",
    "end": "897680"
  },
  {
    "text": "first",
    "start": "897680",
    "end": "899199"
  },
  {
    "text": "get embedded as",
    "start": "899199",
    "end": "901759"
  },
  {
    "text": "expected and then so here's the",
    "start": "901759",
    "end": "904279"
  },
  {
    "text": "embeddings and then they get clustered",
    "start": "904279",
    "end": "906480"
  },
  {
    "text": "and this perform clustering is taken",
    "start": "906480",
    "end": "908279"
  },
  {
    "text": "directly from basically the results uh",
    "start": "908279",
    "end": "910600"
  },
  {
    "text": "or the code provided by the authors of",
    "start": "910600",
    "end": "912199"
  },
  {
    "text": "the paper so it's doing that process I",
    "start": "912199",
    "end": "915440"
  },
  {
    "text": "just talked about um of clustering",
    "start": "915440",
    "end": "919079"
  },
  {
    "text": "basically cluster assignment um and we",
    "start": "919079",
    "end": "922639"
  },
  {
    "text": "get our cluster labels out we put those",
    "start": "922639",
    "end": "924759"
  },
  {
    "text": "in a data frame um and so so then we",
    "start": "924759",
    "end": "928920"
  },
  {
    "text": "have our clusters you can see that here",
    "start": "928920",
    "end": "931480"
  },
  {
    "text": "and because each docking can belong to",
    "start": "931480",
    "end": "934079"
  },
  {
    "text": "more than one cluster we actually expand",
    "start": "934079",
    "end": "936920"
  },
  {
    "text": "out the data frame um so that the",
    "start": "936920",
    "end": "940600"
  },
  {
    "text": "cluster column um Can may contain",
    "start": "940600",
    "end": "945199"
  },
  {
    "text": "duplicates uh for a single document so",
    "start": "945199",
    "end": "948720"
  },
  {
    "text": "one document can live in multiple",
    "start": "948720",
    "end": "950319"
  },
  {
    "text": "clusters and we just flatten it out to",
    "start": "950319",
    "end": "951959"
  },
  {
    "text": "show that then all we do is we get the",
    "start": "951959",
    "end": "955600"
  },
  {
    "text": "whole list of clusters here um the",
    "start": "955600",
    "end": "958600"
  },
  {
    "text": "Define a summarization prompt pretty",
    "start": "958600",
    "end": "960440"
  },
  {
    "text": "simple and all we do is we have our data",
    "start": "960440",
    "end": "962800"
  },
  {
    "text": "frame Just Fish Out give me all the",
    "start": "962800",
    "end": "965440"
  },
  {
    "text": "texts within each cluster and that's all",
    "start": "965440",
    "end": "967240"
  },
  {
    "text": "we're doing here for each cluster get",
    "start": "967240",
    "end": "970199"
  },
  {
    "text": "all the text Plum it into our",
    "start": "970199",
    "end": "972720"
  },
  {
    "text": "summarization prompt generate the",
    "start": "972720",
    "end": "974720"
  },
  {
    "text": "summary here's our summary data frame",
    "start": "974720",
    "end": "977279"
  },
  {
    "text": "that's really it so again iterate",
    "start": "977279",
    "end": "979560"
  },
  {
    "text": "through our clusters get the text for",
    "start": "979560",
    "end": "982079"
  },
  {
    "text": "every cluster summarize it write that",
    "start": "982079",
    "end": "985519"
  },
  {
    "text": "out to a data frame and that's all we do",
    "start": "985519",
    "end": "988759"
  },
  {
    "text": "here's our cluster data frame here's our",
    "start": "988759",
    "end": "990399"
  },
  {
    "text": "summary data frame from that function um",
    "start": "990399",
    "end": "993399"
  },
  {
    "text": "and this is just orchestrating that",
    "start": "993399",
    "end": "995600"
  },
  {
    "text": "process of like iteration so we just",
    "start": "995600",
    "end": "997880"
  },
  {
    "text": "keep doing this until I provide like a",
    "start": "997880",
    "end": "1001000"
  },
  {
    "text": "level or n levels parameter you can say",
    "start": "1001000",
    "end": "1002959"
  },
  {
    "text": "do this end times or um you know uh or",
    "start": "1002959",
    "end": "1008880"
  },
  {
    "text": "um the number of clusters is is equal to",
    "start": "1008880",
    "end": "1011759"
  },
  {
    "text": "one so so basically this is saying",
    "start": "1011759",
    "end": "1014600"
  },
  {
    "text": "continue until either we've done n",
    "start": "1014600",
    "end": "1016839"
  },
  {
    "text": "levels or like n number of of of",
    "start": "1016839",
    "end": "1019040"
  },
  {
    "text": "attempts um in our tree or the number of",
    "start": "1019040",
    "end": "1022920"
  },
  {
    "text": "clusters is one keep doing that and",
    "start": "1022920",
    "end": "1024600"
  },
  {
    "text": "that's it so you can see we've actually",
    "start": "1024600",
    "end": "1025839"
  },
  {
    "text": "run that process we have our results",
    "start": "1025839",
    "end": "1028038"
  },
  {
    "text": "Here and Now what we can do is pretty",
    "start": "1028039",
    "end": "1032438"
  },
  {
    "text": "simply um we can just put those",
    "start": "1032439",
    "end": "1035720"
  },
  {
    "text": "into uh an index like we can use chroma",
    "start": "1035720",
    "end": "1038480"
  },
  {
    "text": "as a vector store um so here's just some",
    "start": "1038480",
    "end": "1041079"
  },
  {
    "text": "really simple code to do that or just",
    "start": "1041079",
    "end": "1042600"
  },
  {
    "text": "iterating through our results we're",
    "start": "1042600",
    "end": "1044400"
  },
  {
    "text": "getting all our summaries out so first",
    "start": "1044400",
    "end": "1047360"
  },
  {
    "text": "maybe I should make this a little B more",
    "start": "1047360",
    "end": "1048799"
  },
  {
    "text": "clear we take all those raw",
    "start": "1048799",
    "end": "1051360"
  },
  {
    "text": "documents and we add we create like we",
    "start": "1051360",
    "end": "1054000"
  },
  {
    "text": "add those to our text lists we then get",
    "start": "1054000",
    "end": "1056160"
  },
  {
    "text": "all of our summaries from our tree we",
    "start": "1056160",
    "end": "1058919"
  },
  {
    "text": "add those and we just index all of them",
    "start": "1058919",
    "end": "1060960"
  },
  {
    "text": "so let's do that so these These are",
    "start": "1060960",
    "end": "1063160"
  },
  {
    "text": "going to all be added them to chroma and",
    "start": "1063160",
    "end": "1066000"
  },
  {
    "text": "very finally we can set up a retrieval",
    "start": "1066000",
    "end": "1068520"
  },
  {
    "text": "chain that is",
    "start": "1068520",
    "end": "1070559"
  },
  {
    "text": "using this index which contains both our",
    "start": "1070559",
    "end": "1073640"
  },
  {
    "text": "leaves so all those raw web pages and",
    "start": "1073640",
    "end": "1076280"
  },
  {
    "text": "these higher level summary pages that's",
    "start": "1076280",
    "end": "1078600"
  },
  {
    "text": "all that's happening here we pull in a",
    "start": "1078600",
    "end": "1080600"
  },
  {
    "text": "rag prompt um here's our retriever",
    "start": "1080600",
    "end": "1084159"
  },
  {
    "text": "here's our question so let's give this a",
    "start": "1084159",
    "end": "1085880"
  },
  {
    "text": "shot so this is running and I want to",
    "start": "1085880",
    "end": "1088760"
  },
  {
    "text": "just bring you back to the diagram so",
    "start": "1088760",
    "end": "1090480"
  },
  {
    "text": "again you can kind of see what's going",
    "start": "1090480",
    "end": "1091880"
  },
  {
    "text": "on",
    "start": "1091880",
    "end": "1092919"
  },
  {
    "text": "here",
    "start": "1092919",
    "end": "1094880"
  },
  {
    "text": "um right here so again we took our web",
    "start": "1094880",
    "end": "1099480"
  },
  {
    "text": "pages uh again 31 of them we cluster",
    "start": "1099480",
    "end": "1103000"
  },
  {
    "text": "them we summarize them we do that",
    "start": "1103000",
    "end": "1105080"
  },
  {
    "text": "iteratively um then what we do is we",
    "start": "1105080",
    "end": "1108080"
  },
  {
    "text": "take those summaries that we generated",
    "start": "1108080",
    "end": "1111200"
  },
  {
    "text": "along with the raw web pages and we",
    "start": "1111200",
    "end": "1113720"
  },
  {
    "text": "index all of them that's it and we can",
    "start": "1113720",
    "end": "1116600"
  },
  {
    "text": "use that index for retrieval so this is",
    "start": "1116600",
    "end": "1118880"
  },
  {
    "text": "like a nice what we might call a long",
    "start": "1118880",
    "end": "1120760"
  },
  {
    "text": "context index because it contains just",
    "start": "1120760",
    "end": "1123159"
  },
  {
    "text": "raw web pages which vary from 2,000 to",
    "start": "1123159",
    "end": "1125919"
  },
  {
    "text": "12,000 tokens and it contains in our",
    "start": "1125919",
    "end": "1128880"
  },
  {
    "text": "case these higher level summaries in",
    "start": "1128880",
    "end": "1131080"
  },
  {
    "text": "case we need an integration of",
    "start": "1131080",
    "end": "1132600"
  },
  {
    "text": "information across those pages um which",
    "start": "1132600",
    "end": "1135919"
  },
  {
    "text": "may or may not be captured just using",
    "start": "1135919",
    "end": "1138400"
  },
  {
    "text": "K&N retrieval so that's the big idea",
    "start": "1138400",
    "end": "1141840"
  },
  {
    "text": "okay this ran we got our answer we can",
    "start": "1141840",
    "end": "1143720"
  },
  {
    "text": "check Langs Smith and we can see here's",
    "start": "1143720",
    "end": "1147159"
  },
  {
    "text": "our",
    "start": "1147159",
    "end": "1147960"
  },
  {
    "text": "retriever um and let's see here's the",
    "start": "1147960",
    "end": "1151440"
  },
  {
    "text": "raw",
    "start": "1151440",
    "end": "1152360"
  },
  {
    "text": "documents so it looks like it retrieved",
    "start": "1152360",
    "end": "1155960"
  },
  {
    "text": "some kind of higher level summaries as",
    "start": "1155960",
    "end": "1158799"
  },
  {
    "text": "well as some raw leavs so this is like a",
    "start": "1158799",
    "end": "1161640"
  },
  {
    "text": "raw web page and then some of these are",
    "start": "1161640",
    "end": "1164559"
  },
  {
    "text": "more like summary Pages which looks like",
    "start": "1164559",
    "end": "1166600"
  },
  {
    "text": "we produced so what's kind of cool about",
    "start": "1166600",
    "end": "1169400"
  },
  {
    "text": "this is you can retrieve from a",
    "start": "1169400",
    "end": "1171919"
  },
  {
    "text": "combination of like your raw Pages as",
    "start": "1171919",
    "end": "1175240"
  },
  {
    "text": "well as these higher level summaries",
    "start": "1175240",
    "end": "1177000"
  },
  {
    "text": "which gives you some robustness and",
    "start": "1177000",
    "end": "1178480"
  },
  {
    "text": "cement the coverage for different types",
    "start": "1178480",
    "end": "1180400"
  },
  {
    "text": "of questions that require like different",
    "start": "1180400",
    "end": "1182760"
  },
  {
    "text": "resolutions of of abstraction or",
    "start": "1182760",
    "end": "1184960"
  },
  {
    "text": "detailed answer like a really detailed",
    "start": "1184960",
    "end": "1187760"
  },
  {
    "text": "code question you might retrieve",
    "start": "1187760",
    "end": "1190320"
  },
  {
    "text": "directly from your raw pages but like a",
    "start": "1190320",
    "end": "1192799"
  },
  {
    "text": "higher level question that integrates",
    "start": "1192799",
    "end": "1194400"
  },
  {
    "text": "information from a bunch of pages you",
    "start": "1194400",
    "end": "1196480"
  },
  {
    "text": "might retrieve from these midlevel or",
    "start": "1196480",
    "end": "1198520"
  },
  {
    "text": "even top level summaries so it's a cool",
    "start": "1198520",
    "end": "1200919"
  },
  {
    "text": "approach it integrates kind of nicely",
    "start": "1200919",
    "end": "1203159"
  },
  {
    "text": "with long context models and I know one",
    "start": "1203159",
    "end": "1206559"
  },
  {
    "text": "thing that will come up here is well",
    "start": "1206559",
    "end": "1208520"
  },
  {
    "text": "look your full context was only 60,000",
    "start": "1208520",
    "end": "1211280"
  },
  {
    "text": "tokens you could just stuff all of that",
    "start": "1211280",
    "end": "1213760"
  },
  {
    "text": "into one of these models you didn't need",
    "start": "1213760",
    "end": "1215600"
  },
  {
    "text": "to do any of this that is absolutely",
    "start": "1215600",
    "end": "1218080"
  },
  {
    "text": "true for this case but what I think the",
    "start": "1218080",
    "end": "1220679"
  },
  {
    "text": "high level point is that's not true for",
    "start": "1220679",
    "end": "1222960"
  },
  {
    "text": "every case for example this exact set of",
    "start": "1222960",
    "end": "1226960"
  },
  {
    "text": "documents I want to use with mraw mraw",
    "start": "1226960",
    "end": "1230679"
  },
  {
    "text": "is only 33 32,000 tokens so this is a",
    "start": "1230679",
    "end": "1234840"
  },
  {
    "text": "really nice approach for that case where",
    "start": "1234840",
    "end": "1236480"
  },
  {
    "text": "I can kind of guarantee that I can index",
    "start": "1236480",
    "end": "1239480"
  },
  {
    "text": "across all these pages but I won't",
    "start": "1239480",
    "end": "1241559"
  },
  {
    "text": "exceed the context limit or and likely",
    "start": "1241559",
    "end": "1243799"
  },
  {
    "text": "to exceed the context limit of my llm",
    "start": "1243799",
    "end": "1246799"
  },
  {
    "text": "because none of these individual Pages",
    "start": "1246799",
    "end": "1248520"
  },
  {
    "text": "exceed 32,000 tokens so you know you can",
    "start": "1248520",
    "end": "1251679"
  },
  {
    "text": "see and again this scale is arbitrarily",
    "start": "1251679",
    "end": "1254039"
  },
  {
    "text": "large so it is true that this set of",
    "start": "1254039",
    "end": "1255960"
  },
  {
    "text": "documents is only 62,000 tokens",
    "start": "1255960",
    "end": "1258720"
  },
  {
    "text": "but of course there's much larger",
    "start": "1258720",
    "end": "1259840"
  },
  {
    "text": "corpuses which could extend beyond even",
    "start": "1259840",
    "end": "1261799"
  },
  {
    "text": "the 200,000 of CLA 3 in which case this",
    "start": "1261799",
    "end": "1265200"
  },
  {
    "text": "type of approach of kind of indexing",
    "start": "1265200",
    "end": "1267640"
  },
  {
    "text": "across documents um and building these",
    "start": "1267640",
    "end": "1270120"
  },
  {
    "text": "like kind of mid-level high level",
    "start": "1270120",
    "end": "1271760"
  },
  {
    "text": "summaries can be applicable so it's a",
    "start": "1271760",
    "end": "1274559"
  },
  {
    "text": "cool method it's a neat paper um I",
    "start": "1274559",
    "end": "1276960"
  },
  {
    "text": "definitely encourage you to experiment",
    "start": "1276960",
    "end": "1278640"
  },
  {
    "text": "with it um and all this code will be",
    "start": "1278640",
    "end": "1281440"
  },
  {
    "text": "available um for you to to work with and",
    "start": "1281440",
    "end": "1285720"
  },
  {
    "text": "um I think that's about it thanks very",
    "start": "1285720",
    "end": "1288760"
  },
  {
    "text": "much",
    "start": "1288760",
    "end": "1291760"
  }
]
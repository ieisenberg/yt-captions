[
  {
    "start": "0",
    "end": "18000"
  },
  {
    "text": "Hi all, Will here. This week we're \nexcited to launch the LangMem SDK—a  ",
    "start": "80",
    "end": "4000"
  },
  {
    "text": "library of utilities for helping your \nagents learn and adapt as they work.",
    "start": "4000",
    "end": "7640"
  },
  {
    "text": "In this video, we will show you \nhow to add procedural memory to  ",
    "start": "7640",
    "end": "10520"
  },
  {
    "text": "your agents so they can learn instructions, rules,  ",
    "start": "10520",
    "end": "13680"
  },
  {
    "text": "and other procedures that dictate how they \nshould respond and act in given situations.",
    "start": "13680",
    "end": "18400"
  },
  {
    "start": "18000",
    "end": "51000"
  },
  {
    "text": "By the end of this tutorial,  ",
    "start": "18400",
    "end": "19760"
  },
  {
    "text": "you'll be able to create an email assistant \nagent that's able to learn from feedback.",
    "start": "19760",
    "end": "25160"
  },
  {
    "text": "By submitting feedback, the agent will update \nits prompt and learn new instructions inferred  ",
    "start": "25160",
    "end": "30400"
  },
  {
    "text": "from the user. The updated prompt can live in \nmemory. You can see that it's able to learn  ",
    "start": "30400",
    "end": "34160"
  },
  {
    "text": "these procedures so that anytime you start a new \nconversation, it can act on this new behavior. As  ",
    "start": "34160",
    "end": "39520"
  },
  {
    "text": "a result, it was able to learn these procedures. \nProcedural memory is great for learning rules,  ",
    "start": "39520",
    "end": "44000"
  },
  {
    "text": "instructions, and other elements that \ndictate core behavioral tendencies.",
    "start": "44000",
    "end": "49480"
  },
  {
    "text": "Let's build an email assistant agent to \ndemonstrate how procedural memory works.  ",
    "start": "49480",
    "end": "53640"
  },
  {
    "start": "51000",
    "end": "108000"
  },
  {
    "text": "We'll start by installing LangMem and LangGraph \nand then set up our initial instructions for the  ",
    "start": "53640",
    "end": "58960"
  },
  {
    "text": "agent. These instructions can be learned \nover time, as we'll demonstrate later.",
    "start": "58960",
    "end": "62670"
  },
  {
    "text": "For now, we will manage the prompt \nin the long-term memory store,  ",
    "start": "62671",
    "end": "65480"
  },
  {
    "text": "simply because it’s convenient to \naccess it across different threads.",
    "start": "65480",
    "end": "69080"
  },
  {
    "text": "Now let's create the agent itself. It will have \na single tool called draft email—a placeholder  ",
    "start": "69080",
    "end": "74560"
  },
  {
    "text": "that gets it to actually write the email as a \nresponse. Then we'll define the prompt function.  ",
    "start": "74560",
    "end": "79520"
  },
  {
    "text": "The prompt function takes the state, accesses \nthe long-term memory store, and prepares the  ",
    "start": "79520",
    "end": "83679"
  },
  {
    "text": "list of messages to send directly to the LLM. In \nour case, we'll extract the instructions list,  ",
    "start": "83680",
    "end": "89640"
  },
  {
    "text": "obtain the prompt from it, and then insert that \ninto the system prompt that we'll pass to the LLM.",
    "start": "89640",
    "end": "93360"
  },
  {
    "text": "Notice that the agent doesn't yet know \nmy name. It has a pretty simple email  ",
    "start": "93360",
    "end": "97080"
  },
  {
    "text": "structure. Suppose I wanted it to always \ninclude my name in the sign-off because  ",
    "start": "97080",
    "end": "101120"
  },
  {
    "text": "it is my personal email assistant. Also, \nwhenever it's handling meeting requests,  ",
    "start": "101120",
    "end": "104520"
  },
  {
    "text": "it should offer to send a \nZoom or Google Meet link.",
    "start": "104520",
    "end": "107200"
  },
  {
    "text": "Let's have our agent learn from feedback. \nWe'll import the prompt optimizer from LangMem,  ",
    "start": "107200",
    "end": "111159"
  },
  {
    "start": "108000",
    "end": "213000"
  },
  {
    "text": "initialize it using Claude Sonnet \nto drive the optimization process,  ",
    "start": "111160",
    "end": "114440"
  },
  {
    "text": "and then run the optimizer. It takes the \nconversation and optional feedback and uses  ",
    "start": "114440",
    "end": "119440"
  },
  {
    "text": "that to infer what type of instructions should \nbe included in the prompt for later interactions.",
    "start": "119440",
    "end": "124960"
  },
  {
    "text": "Here, we've passed in feedback instructing the \nagent to always sign off with my name. But this  ",
    "start": "124960",
    "end": "128560"
  },
  {
    "text": "information could also be found within \nthe existing conversation history—a very  ",
    "start": "128560",
    "end": "133599"
  },
  {
    "text": "common scenario in chat interactions. Since we're \nusing an LLM to drive this optimizer, it should  ",
    "start": "133600",
    "end": "139040"
  },
  {
    "text": "glean implicit feedback from the conversation \nhistory. We call these \"trajectories\" because  ",
    "start": "139040",
    "end": "143560"
  },
  {
    "text": "they could include any series of operations for \nyour agent, including tool calls and other data.",
    "start": "143560",
    "end": "148239"
  },
  {
    "text": "Let's print this out to see what it responded. \nYou can see the new, learned prompt—it’s able  ",
    "start": "148240",
    "end": "153480"
  },
  {
    "text": "to notice that we implicitly condone the existing \nstructure, instructing it to use clear, concise  ",
    "start": "153480",
    "end": "158120"
  },
  {
    "text": "language and to always sign off with my name. \nFor meeting requests, it has a conditional rule:  ",
    "start": "158120",
    "end": "164560"
  },
  {
    "text": "it clearly states the proposed time and \noffers two options for meeting scheduling.",
    "start": "164560",
    "end": "168319"
  },
  {
    "text": "So, it's able to learn different procedures \nand propose a new instruction structure.  ",
    "start": "168320",
    "end": "171800"
  },
  {
    "text": "It even provides a few-shot example to \nillustrate the changes. You can control  ",
    "start": "171800",
    "end": "175640"
  },
  {
    "text": "the parameters of the optimizer if you think \nthis is too verbose or not verbose enough,  ",
    "start": "175640",
    "end": "179480"
  },
  {
    "text": "allowing more time for it to think or \nimposing more constraints on the updates.",
    "start": "179480",
    "end": "183200"
  },
  {
    "text": "We'll put this updated prompt back in \nthe store and then run our process again.",
    "start": "184360",
    "end": "187340"
  },
  {
    "text": "Now we see that it signs off with my \nname and offers to use whichever meeting  ",
    "start": "187340",
    "end": "192400"
  },
  {
    "text": "platform the recipient prefers. Even if it's \ndrafting an email with different content,  ",
    "start": "192400",
    "end": "197519"
  },
  {
    "text": "it still infers that it should sign off with \nmy name. However, if the email isn't about a  ",
    "start": "197520",
    "end": "206720"
  },
  {
    "text": "meeting follow-up, it doesn't include any \nmeeting scheduling details. Simple, right?",
    "start": "206720",
    "end": "212040"
  },
  {
    "text": "We’ve shown how to update the \nprocedural memory for a single agent,  ",
    "start": "212040",
    "end": "215040"
  },
  {
    "start": "213000",
    "end": "258000"
  },
  {
    "text": "but what if you have multiple agents working \nin concert? We're going to use LangGraph's  ",
    "start": "215040",
    "end": "219599"
  },
  {
    "text": "multi-agent supervisor library to build a \nmulti-agent system and then demonstrate how  ",
    "start": "219600",
    "end": "224280"
  },
  {
    "text": "you can improve the procedural memory \nfor both agents in a single pass.",
    "start": "224280",
    "end": "228080"
  },
  {
    "text": "We'll install the LangGraph Supervisor package \nto get this additional functionality. Then,  ",
    "start": "228080",
    "end": "232440"
  },
  {
    "text": "we'll create two working agents similar to \nbefore. The first is our email agent, which  ",
    "start": "232440",
    "end": "237360"
  },
  {
    "text": "looks the same, except that we've changed the \nkey for the memories to be specific to the email  ",
    "start": "237360",
    "end": "242280"
  },
  {
    "text": "agent so that its instructions remain distinct \nfrom those of our social media or Twitter agent.",
    "start": "242280",
    "end": "247160"
  },
  {
    "text": "Next, we've created a second agent, in \na similar style, that's able to send  ",
    "start": "247160",
    "end": "250920"
  },
  {
    "text": "tweets. Please ensure you update the keys \nso that their instructions aren’t mixed.",
    "start": "250920",
    "end": "255880"
  },
  {
    "text": "Now we'll create our supervisor agent. We'll \nimport from the LangGraph Supervisor package  ",
    "start": "255880",
    "end": "259959"
  },
  {
    "start": "258000",
    "end": "381000"
  },
  {
    "text": "and initialize it with our two agents. Our \nprompt doesn't have to be very specific  ",
    "start": "259960",
    "end": "265319"
  },
  {
    "text": "since it should know when to route to the \nemail or tweet assistant based on content.",
    "start": "265320",
    "end": "268907"
  },
  {
    "text": "We'll repeat our experiment from before, asking \nit to draft an email to joe@langchain.dev. Then,  ",
    "start": "268907",
    "end": "273480"
  },
  {
    "text": "we can see that the sub-agent has responded, \nshowing what type of content it generated.",
    "start": "273480",
    "end": "277960"
  },
  {
    "text": "Now comes the fun part. Let's say we want to leave \nthe same feedback: we always want to sign off  ",
    "start": "277960",
    "end": "282360"
  },
  {
    "text": "emails with \"William\" for meeting requests, and \nwe want to offer the option to schedule on Zoom or  ",
    "start": "282360",
    "end": "286719"
  },
  {
    "text": "Google Meet. This time, we'll use the multi-prompt \noptimizer, which is designed to pick which  ",
    "start": "286720",
    "end": "291000"
  },
  {
    "text": "prompts in a multi-agent system need updating \nbased on feedback and conversation history.",
    "start": "291000",
    "end": "295360"
  },
  {
    "text": "In an arbitrary multi-agent system, the prompt \nrelationships can get a bit complicated. To ensure  ",
    "start": "295360",
    "end": "301719"
  },
  {
    "text": "more reliable attribution of responsibility, \nwe're going to provide more information about  ",
    "start": "301720",
    "end": "306320"
  },
  {
    "text": "the prompt—namely, when to update it and \nhow to update it. We'll use a prompt type,  ",
    "start": "306320",
    "end": "313920"
  },
  {
    "text": "which is just a typed dictionary, by providing a \nname, the current prompt, the update instructions,  ",
    "start": "313920",
    "end": "320800"
  },
  {
    "text": "and the conditions for updating. We'll fetch \nthese two prompts and initialize them accordingly.",
    "start": "320800",
    "end": "325159"
  },
  {
    "text": "If you look at the results, you can see \nthat the tweet prompt hasn't been updated,  ",
    "start": "325160",
    "end": "329240"
  },
  {
    "text": "but the email prompt has. It has again learned \nto incorporate my preferred sign-off and,  ",
    "start": "329240",
    "end": "335199"
  },
  {
    "text": "in these specific situations, to offer \nmultiple meeting scheduling options.",
    "start": "335200",
    "end": "339475"
  },
  {
    "text": "If I put it back in the store \nand then rerun the system,  ",
    "start": "339475",
    "end": "342000"
  },
  {
    "text": "we should be able to see whether the \ndesired prompt effects are in place.",
    "start": "342000",
    "end": "345840"
  },
  {
    "text": "As you can see, it's learned how to sign off its \nemails and is also offering multiple options for  ",
    "start": "345840",
    "end": "350560"
  },
  {
    "text": "scheduling meetings. The multi-prompt \noptimizer is useful in situations where  ",
    "start": "350560",
    "end": "355240"
  },
  {
    "text": "you might have outcome-level supervision—either \nfrom end-user feedback or other scenarios—but  ",
    "start": "355240",
    "end": "359759"
  },
  {
    "text": "you want your entire system to learn and improve.",
    "start": "360280",
    "end": "364240"
  },
  {
    "text": "Under the hood, it takes the prompt's context, \nas well as the feedback and ongoing trajectories,  ",
    "start": "364240",
    "end": "369520"
  },
  {
    "text": "and learns which prompts contributed to the \noverall outcome. It then uses an optimizer loop  ",
    "start": "369520",
    "end": "374639"
  },
  {
    "text": "to determine what updates are necessary and \nreturns those suggested prompt improvements.",
    "start": "374640",
    "end": "380160"
  },
  {
    "text": "And that's all for today. In this tutorial, \nyou used LangMem's Prompt Optimizer to learn  ",
    "start": "380160",
    "end": "385280"
  },
  {
    "start": "381000",
    "end": "408000"
  },
  {
    "text": "instructions based on user feedback and \nconversation history. You then created a  ",
    "start": "385280",
    "end": "389080"
  },
  {
    "text": "multi-agent system and used the MultiPro optimizer \nto update the system based on end-user feedback.",
    "start": "389080",
    "end": "395840"
  },
  {
    "text": "Procedural memory is useful \nfor teaching your agents how  ",
    "start": "395840",
    "end": "398199"
  },
  {
    "text": "to accomplish tasks, especially when \nthose instructions are conditional.",
    "start": "398200",
    "end": "401360"
  },
  {
    "text": "For more information about \nthis and other types of memory,  ",
    "start": "401360",
    "end": "404080"
  },
  {
    "text": "check out the LangMem docs and our other videos.",
    "start": "404080",
    "end": "406159"
  }
]
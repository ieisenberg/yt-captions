[
  {
    "text": "lang Chain team thank you so much for",
    "start": "7680",
    "end": "9679"
  },
  {
    "text": "having me really excited to share a",
    "start": "9679",
    "end": "12000"
  },
  {
    "text": "little bit more about how we made Devon",
    "start": "12000",
    "end": "14160"
  },
  {
    "text": "um so my name is Russell Kaplan i'm",
    "start": "14160",
    "end": "16080"
  },
  {
    "text": "president at Cognition we're the company",
    "start": "16080",
    "end": "18080"
  },
  {
    "text": "behind Devon and as a quick show of",
    "start": "18080",
    "end": "20160"
  },
  {
    "text": "hands how many of you have heard of",
    "start": "20160",
    "end": "21439"
  },
  {
    "text": "Devon",
    "start": "21439",
    "end": "23919"
  },
  {
    "text": "before uh so Devon is an AI software",
    "start": "23960",
    "end": "27840"
  },
  {
    "text": "engineer um but we are really focused",
    "start": "27840",
    "end": "30960"
  },
  {
    "text": "specifically on working within existing",
    "start": "30960",
    "end": "33360"
  },
  {
    "text": "code bases um there's lots of amazing AI",
    "start": "33360",
    "end": "36079"
  },
  {
    "text": "tools out there for coding and what we",
    "start": "36079",
    "end": "38000"
  },
  {
    "text": "found is that as the code bases get",
    "start": "38000",
    "end": "39840"
  },
  {
    "text": "larger the problem gets harder and most",
    "start": "39840",
    "end": "42399"
  },
  {
    "text": "of our customers and users around the",
    "start": "42399",
    "end": "44239"
  },
  {
    "text": "world are",
    "start": "44239",
    "end": "46640"
  },
  {
    "text": "teams and so today I want to talk a",
    "start": "50360",
    "end": "53039"
  },
  {
    "text": "little bit more about what Devon is but",
    "start": "53039",
    "end": "54719"
  },
  {
    "text": "more importantly how we built it and I'm",
    "start": "54719",
    "end": "56559"
  },
  {
    "text": "going to share some new sort of",
    "start": "56559",
    "end": "57760"
  },
  {
    "text": "technical information we're releasing on",
    "start": "57760",
    "end": "59600"
  },
  {
    "text": "exactly how this works under the hood",
    "start": "59600",
    "end": "60879"
  },
  {
    "text": "that I'm really excited to to present to",
    "start": "60879",
    "end": "62719"
  },
  {
    "text": "you",
    "start": "62719",
    "end": "63720"
  },
  {
    "text": "all first what are we seeing in AI for",
    "start": "63720",
    "end": "67439"
  },
  {
    "text": "coding um obviously this is a really",
    "start": "67439",
    "end": "70080"
  },
  {
    "text": "fast field and in many ways software",
    "start": "70080",
    "end": "73040"
  },
  {
    "text": "engineering is one of the first large",
    "start": "73040",
    "end": "74640"
  },
  {
    "text": "scale successful applications of",
    "start": "74640",
    "end": "76640"
  },
  {
    "text": "generative AI um it started in many ways",
    "start": "76640",
    "end": "79840"
  },
  {
    "text": "with co-pilots real time text completion",
    "start": "79840",
    "end": "83040"
  },
  {
    "text": "inside your editor that makes you as an",
    "start": "83040",
    "end": "85200"
  },
  {
    "text": "engineer go a bit",
    "start": "85200",
    "end": "87320"
  },
  {
    "text": "faster and now we also have AI idees",
    "start": "87320",
    "end": "91040"
  },
  {
    "text": "again a development environment for you",
    "start": "91040",
    "end": "92880"
  },
  {
    "text": "as an individual engineer to get even",
    "start": "92880",
    "end": "94960"
  },
  {
    "text": "more leverage than before sometimes",
    "start": "94960",
    "end": "96640"
  },
  {
    "text": "delegating entire tasks or snippets and",
    "start": "96640",
    "end": "99280"
  },
  {
    "text": "really coding in flow with AI assistance",
    "start": "99280",
    "end": "103040"
  },
  {
    "text": "we see Devon as part of a third wave of",
    "start": "103040",
    "end": "105759"
  },
  {
    "text": "AI developer tools which is on the fully",
    "start": "105759",
    "end": "108560"
  },
  {
    "text": "autonomous agent end of the spectrum",
    "start": "108560",
    "end": "111360"
  },
  {
    "text": "more AI teammate than AI",
    "start": "111360",
    "end": "114840"
  },
  {
    "text": "co-pilot companies around the world are",
    "start": "114840",
    "end": "117119"
  },
  {
    "text": "using Devon like another member of their",
    "start": "117119",
    "end": "119439"
  },
  {
    "text": "engineering team going directly from",
    "start": "119439",
    "end": "121439"
  },
  {
    "text": "ticket to pull request collaborating",
    "start": "121439",
    "end": "123600"
  },
  {
    "text": "with Devon in Slack or Jira or linear",
    "start": "123600",
    "end": "127520"
  },
  {
    "text": "and we see the large majority of Devon",
    "start": "127520",
    "end": "129679"
  },
  {
    "text": "sessions and Devon PRs are started from",
    "start": "129679",
    "end": "132160"
  },
  {
    "text": "within these other tools the same way",
    "start": "132160",
    "end": "134319"
  },
  {
    "text": "you might interact with another",
    "start": "134319",
    "end": "138480"
  },
  {
    "text": "human agent and what we've seen is that",
    "start": "146599",
    "end": "149520"
  },
  {
    "text": "it's very complimentary to these local",
    "start": "149520",
    "end": "151920"
  },
  {
    "text": "AI development tools um when you are",
    "start": "151920",
    "end": "154400"
  },
  {
    "text": "coding yourself and you want to stay in",
    "start": "154400",
    "end": "155920"
  },
  {
    "text": "flow and get that speed up you use a",
    "start": "155920",
    "end": "158239"
  },
  {
    "text": "local AI development tool where people",
    "start": "158239",
    "end": "160400"
  },
  {
    "text": "use Devon is when they're ready to",
    "start": "160400",
    "end": "162160"
  },
  {
    "text": "delegate the task entirely and this is a",
    "start": "162160",
    "end": "165040"
  },
  {
    "text": "very different set of technical",
    "start": "165040",
    "end": "166400"
  },
  {
    "text": "trade-offs",
    "start": "166400",
    "end": "169400"
  },
  {
    "text": "ability to completely delegate",
    "start": "171360",
    "end": "173360"
  },
  {
    "text": "individual units of work in the team",
    "start": "173360",
    "end": "176720"
  },
  {
    "text": "this also means that",
    "start": "176720",
    "end": "180160"
  },
  {
    "text": "run across different runs so you can try",
    "start": "181080",
    "end": "184159"
  },
  {
    "text": "many different things in parallel",
    "start": "184159",
    "end": "185680"
  },
  {
    "text": "combine them together and the teams of",
    "start": "185680",
    "end": "187760"
  },
  {
    "text": "engineers who use Devon will break up",
    "start": "187760",
    "end": "189840"
  },
  {
    "text": "large scale engineering outcomes into",
    "start": "189840",
    "end": "192080"
  },
  {
    "text": "small individual tasks delegated to a",
    "start": "192080",
    "end": "194480"
  },
  {
    "text": "fleet of Devons and then coales together",
    "start": "194480",
    "end": "197200"
  },
  {
    "text": "inside the codebase and the main thing",
    "start": "197200",
    "end": "199599"
  },
  {
    "text": "our users look for is for that code from",
    "start": "199599",
    "end": "201599"
  },
  {
    "text": "Devon to get merged as pull",
    "start": "201599",
    "end": "204280"
  },
  {
    "text": "requests it also changes the learning",
    "start": "204280",
    "end": "206640"
  },
  {
    "text": "model for Devon in the cloud AI Asian",
    "start": "206640",
    "end": "210239"
  },
  {
    "text": "setting Devon is not just for you it's",
    "start": "210239",
    "end": "212480"
  },
  {
    "text": "for your team and for your organization",
    "start": "212480",
    "end": "215120"
  },
  {
    "text": "and so as Devon learns from your",
    "start": "215120",
    "end": "217040"
  },
  {
    "text": "interactions those learnings are not",
    "start": "217040",
    "end": "219280"
  },
  {
    "text": "kept only with you instead they're",
    "start": "219280",
    "end": "222239"
  },
  {
    "text": "incorporated as part of your team and as",
    "start": "222239",
    "end": "224400"
  },
  {
    "text": "part of your organization and this",
    "start": "224400",
    "end": "226159"
  },
  {
    "text": "reliance on organizational knowledge is",
    "start": "226159",
    "end": "228560"
  },
  {
    "text": "something that we've seen is really",
    "start": "228560",
    "end": "230239"
  },
  {
    "text": "important for working with existing",
    "start": "230239",
    "end": "232319"
  },
  {
    "text": "large scale",
    "start": "232319",
    "end": "233560"
  },
  {
    "text": "code",
    "start": "233560",
    "end": "236560"
  },
  {
    "text": "because I'm going to go into some more",
    "start": "236840",
    "end": "238879"
  },
  {
    "text": "detail on exactly how we do this under",
    "start": "238879",
    "end": "240799"
  },
  {
    "text": "the hood with",
    "start": "240799",
    "end": "243640"
  },
  {
    "text": "one",
    "start": "243640",
    "end": "245879"
  },
  {
    "text": "context if you want to build an AI",
    "start": "245879",
    "end": "248319"
  },
  {
    "text": "software engineer you need to understand",
    "start": "248319",
    "end": "250799"
  },
  {
    "text": "existing code you don't want your AI",
    "start": "250799",
    "end": "253439"
  },
  {
    "text": "code contributions to be using a new",
    "start": "253439",
    "end": "255040"
  },
  {
    "text": "framework adding new dependencies or",
    "start": "255040",
    "end": "257199"
  },
  {
    "text": "being done in isolation of what you",
    "start": "257199",
    "end": "259359"
  },
  {
    "text": "already",
    "start": "259359",
    "end": "260759"
  },
  {
    "text": "have and codebase understanding is",
    "start": "260759",
    "end": "263120"
  },
  {
    "text": "pretty hard um LLM are amazing at so",
    "start": "263120",
    "end": "266479"
  },
  {
    "text": "many things but they have limited",
    "start": "266479",
    "end": "268560"
  },
  {
    "text": "context windows and even if a codebase",
    "start": "268560",
    "end": "270720"
  },
  {
    "text": "fits inside the context window uh the",
    "start": "270720",
    "end": "272960"
  },
  {
    "text": "effective context window is often a lot",
    "start": "272960",
    "end": "274800"
  },
  {
    "text": "lower than the advertised context window",
    "start": "274800",
    "end": "277120"
  },
  {
    "text": "we have a series of internal benchmarks",
    "start": "277120",
    "end": "278639"
  },
  {
    "text": "that measures effective reasoning",
    "start": "278639",
    "end": "280400"
  },
  {
    "text": "capacity across a context and we find",
    "start": "280400",
    "end": "282720"
  },
  {
    "text": "very consistently that the advertised",
    "start": "282720",
    "end": "284720"
  },
  {
    "text": "context window is much higher than the",
    "start": "284720",
    "end": "287040"
  },
  {
    "text": "effective reasoning context window large",
    "start": "287040",
    "end": "290160"
  },
  {
    "text": "code bases also have complex",
    "start": "290160",
    "end": "291759"
  },
  {
    "text": "dependencies they can span multiple",
    "start": "291759",
    "end": "293360"
  },
  {
    "text": "services multiple repositories and they",
    "start": "293360",
    "end": "296080"
  },
  {
    "text": "can be intertwined in very complicated",
    "start": "296080",
    "end": "297759"
  },
  {
    "text": "ways even for human engineers there's",
    "start": "297759",
    "end": "300560"
  },
  {
    "text": "huge variations in code quality there",
    "start": "300560",
    "end": "302639"
  },
  {
    "text": "might be some parts of the codebase you",
    "start": "302639",
    "end": "304479"
  },
  {
    "text": "want Devon to emulate and some parts you",
    "start": "304479",
    "end": "306639"
  },
  {
    "text": "really want Devon to stay away from uh",
    "start": "306639",
    "end": "308320"
  },
  {
    "text": "when it's when it's learning how to be a",
    "start": "308320",
    "end": "309759"
  },
  {
    "text": "productive member of your team um same",
    "start": "309759",
    "end": "312080"
  },
  {
    "text": "thing is true for documentation the code",
    "start": "312080",
    "end": "314000"
  },
  {
    "text": "might have comments might have missing",
    "start": "314000",
    "end": "315840"
  },
  {
    "text": "comments might have documentations",
    "start": "315840",
    "end": "317360"
  },
  {
    "text": "that's out outright incorrect or",
    "start": "317360",
    "end": "319280"
  },
  {
    "text": "misleading all of these things are part",
    "start": "319280",
    "end": "321199"
  },
  {
    "text": "of the technical challenges we work on",
    "start": "321199",
    "end": "322560"
  },
  {
    "text": "to make Devon work in real world code",
    "start": "322560",
    "end": "324240"
  },
  {
    "text": "bases",
    "start": "324240",
    "end": "326400"
  },
  {
    "text": "the last critical piece of real world is",
    "start": "326400",
    "end": "328720"
  },
  {
    "text": "that the larger the",
    "start": "328720",
    "end": "331840"
  },
  {
    "text": "codebends and companies build their own",
    "start": "332120",
    "end": "334400"
  },
  {
    "text": "proprietary",
    "start": "334400",
    "end": "336600"
  },
  {
    "text": "frameworks there's context in the code",
    "start": "336600",
    "end": "338880"
  },
  {
    "text": "that's not inside the code itself but",
    "start": "338880",
    "end": "340720"
  },
  {
    "text": "the workflow around the",
    "start": "340720",
    "end": "343720"
  },
  {
    "text": "code that we set out to solve to make",
    "start": "343720",
    "end": "346080"
  },
  {
    "text": "Devon actually useful in the real world",
    "start": "346080",
    "end": "350758"
  },
  {
    "text": "and the first thing I'm going to go into",
    "start": "351039",
    "end": "353120"
  },
  {
    "text": "more detail on is something we actually",
    "start": "353120",
    "end": "354880"
  },
  {
    "text": "recently released uh free and publicly",
    "start": "354880",
    "end": "356960"
  },
  {
    "text": "for all open source repositories it's",
    "start": "356960",
    "end": "359199"
  },
  {
    "text": "called DeepWiki deepwiki is a real time",
    "start": "359199",
    "end": "363440"
  },
  {
    "text": "continually updated index of your",
    "start": "363440",
    "end": "366000"
  },
  {
    "text": "codebase published as an interactive",
    "start": "366000",
    "end": "368720"
  },
  {
    "text": "wiki almost like a real time confluence",
    "start": "368720",
    "end": "371360"
  },
  {
    "text": "page with documentation diagrams and the",
    "start": "371360",
    "end": "374639"
  },
  {
    "text": "ability to ask questions about your code",
    "start": "374639",
    "end": "377440"
  },
  {
    "text": "we had this originally as an internal",
    "start": "377440",
    "end": "379360"
  },
  {
    "text": "data structure for Devon it wasn't a it",
    "start": "379360",
    "end": "381440"
  },
  {
    "text": "wasn't a product it was just a tool that",
    "start": "381440",
    "end": "383440"
  },
  {
    "text": "Devon could use to get highle context",
    "start": "383440",
    "end": "385600"
  },
  {
    "text": "about the code and what we realized is",
    "start": "385600",
    "end": "387600"
  },
  {
    "text": "that human engineers wanted to see this",
    "start": "387600",
    "end": "389600"
  },
  {
    "text": "information too and so we decided to",
    "start": "389600",
    "end": "391520"
  },
  {
    "text": "release it as a standalone uh product",
    "start": "391520",
    "end": "393520"
  },
  {
    "text": "and service so you can take any GitHub",
    "start": "393520",
    "end": "395600"
  },
  {
    "text": "URL today and just change the GitHub to",
    "start": "395600",
    "end": "398840"
  },
  {
    "text": "deepw.com and for any open source repo",
    "start": "398840",
    "end": "401440"
  },
  {
    "text": "you'll get a full interactive wiki this",
    "start": "401440",
    "end": "403919"
  },
  {
    "text": "also works on your private repos when",
    "start": "403919",
    "end": "405520"
  },
  {
    "text": "they're integrated with Devon and so I",
    "start": "405520",
    "end": "408800"
  },
  {
    "text": "uh looked at the Langchain uh repo and",
    "start": "408800",
    "end": "411360"
  },
  {
    "text": "we have a full uh updated up-to-date",
    "start": "411360",
    "end": "414240"
  },
  {
    "text": "documentation page for Langchain that",
    "start": "414240",
    "end": "416160"
  },
  {
    "text": "has not only the pros of how it's",
    "start": "416160",
    "end": "417919"
  },
  {
    "text": "organized the key concepts in",
    "start": "417919",
    "end": "419840"
  },
  {
    "text": "Langchain's codebase uh but also",
    "start": "419840",
    "end": "422000"
  },
  {
    "text": "architectural diagrams and data flows",
    "start": "422000",
    "end": "424000"
  },
  {
    "text": "and we've gotten a lot of feedback from",
    "start": "424000",
    "end": "426160"
  },
  {
    "text": "the community that uh these diagrams are",
    "start": "426160",
    "end": "429520"
  },
  {
    "text": "in some cases or in many cases actually",
    "start": "429520",
    "end": "431280"
  },
  {
    "text": "better than the diagrams of the official",
    "start": "431280",
    "end": "433280"
  },
  {
    "text": "documentation of very popular open",
    "start": "433280",
    "end": "435199"
  },
  {
    "text": "source projects right whether it's um",
    "start": "435199",
    "end": "437039"
  },
  {
    "text": "folks who are on the TypeScript steering",
    "start": "437039",
    "end": "438800"
  },
  {
    "text": "committee uh the VLM maintainers or",
    "start": "438800",
    "end": "440880"
  },
  {
    "text": "others uh we're getting lots of amazing",
    "start": "440880",
    "end": "442800"
  },
  {
    "text": "feedback on how uh how great DeepWiki is",
    "start": "442800",
    "end": "445759"
  },
  {
    "text": "and we've had you know thousands of code",
    "start": "445759",
    "end": "447599"
  },
  {
    "text": "bases start linking to DeepWiki as part",
    "start": "447599",
    "end": "449520"
  },
  {
    "text": "of their official documentation so",
    "start": "449520",
    "end": "451520"
  },
  {
    "text": "definitely check this out if you're",
    "start": "451520",
    "end": "452880"
  },
  {
    "text": "working on open source code",
    "start": "452880",
    "end": "455880"
  },
  {
    "text": "yourself how does this work under the",
    "start": "455880",
    "end": "458160"
  },
  {
    "text": "hood we just said that LMS are really",
    "start": "458160",
    "end": "460080"
  },
  {
    "text": "bad at reasoning about large code um",
    "start": "460080",
    "end": "462800"
  },
  {
    "text": "I'll give you the highle algorithm of",
    "start": "462800",
    "end": "464639"
  },
  {
    "text": "what we're doing under the hood to",
    "start": "464639",
    "end": "466400"
  },
  {
    "text": "generate these wikies step one it's",
    "start": "466400",
    "end": "469280"
  },
  {
    "text": "actually not about the code it's about",
    "start": "469280",
    "end": "471599"
  },
  {
    "text": "the concepts what are the key principles",
    "start": "471599",
    "end": "475039"
  },
  {
    "text": "inside this codebase that are going to",
    "start": "475039",
    "end": "477360"
  },
  {
    "text": "form our table of contents for how we",
    "start": "477360",
    "end": "480000"
  },
  {
    "text": "lay out the macro context of this",
    "start": "480000",
    "end": "482400"
  },
  {
    "text": "codebase and what we found is that the",
    "start": "482400",
    "end": "485039"
  },
  {
    "text": "in many cases those concepts um you",
    "start": "485039",
    "end": "487520"
  },
  {
    "text": "don't just get them from the source code",
    "start": "487520",
    "end": "488960"
  },
  {
    "text": "itself there's extremely rich",
    "start": "488960",
    "end": "491280"
  },
  {
    "text": "information in the metadata around the",
    "start": "491280",
    "end": "493199"
  },
  {
    "text": "source code for example was that source",
    "start": "493199",
    "end": "495520"
  },
  {
    "text": "code added in as part of a pull request",
    "start": "495520",
    "end": "497680"
  },
  {
    "text": "well which member of the team added that",
    "start": "497680",
    "end": "499440"
  },
  {
    "text": "pull request what else have they",
    "start": "499440",
    "end": "500639"
  },
  {
    "text": "contributed to was there discussion in",
    "start": "500639",
    "end": "502479"
  },
  {
    "text": "that pull request about the code um what",
    "start": "502479",
    "end": "505280"
  },
  {
    "text": "were there comments is there",
    "start": "505280",
    "end": "506560"
  },
  {
    "text": "documentation the git commit history all",
    "start": "506560",
    "end": "508639"
  },
  {
    "text": "of this metadata is a really useful",
    "start": "508639",
    "end": "511280"
  },
  {
    "text": "source for building these high context",
    "start": "511280",
    "end": "515080"
  },
  {
    "text": "wikis once you have those concepts then",
    "start": "515080",
    "end": "517599"
  },
  {
    "text": "you can connect them to the code so what",
    "start": "517599",
    "end": "520560"
  },
  {
    "text": "are the connections between the various",
    "start": "520560",
    "end": "522080"
  },
  {
    "text": "code files and the proprietary or",
    "start": "522080",
    "end": "524240"
  },
  {
    "text": "specific concepts inside this",
    "start": "524240",
    "end": "527640"
  },
  {
    "text": "codebase and after you have that you",
    "start": "527640",
    "end": "530240"
  },
  {
    "text": "need to connect the code itself there's",
    "start": "530240",
    "end": "532480"
  },
  {
    "text": "different sections of the codebase uh",
    "start": "532480",
    "end": "534640"
  },
  {
    "text": "you know some files that are more",
    "start": "534640",
    "end": "535839"
  },
  {
    "text": "related less related there's uh call you",
    "start": "535839",
    "end": "538959"
  },
  {
    "text": "know sort of call traces and flows and",
    "start": "538959",
    "end": "540720"
  },
  {
    "text": "there's a specific way that these",
    "start": "540720",
    "end": "543200"
  },
  {
    "text": "different components of the codebase",
    "start": "543200",
    "end": "545200"
  },
  {
    "text": "connect to each other you can look at",
    "start": "545200",
    "end": "546640"
  },
  {
    "text": "things like the symbol the symbol graph",
    "start": "546640",
    "end": "548560"
  },
  {
    "text": "you can look at the call graph uh and",
    "start": "548560",
    "end": "550240"
  },
  {
    "text": "you can look at how um how these files",
    "start": "550240",
    "end": "552720"
  },
  {
    "text": "tend to be used together and once you",
    "start": "552720",
    "end": "555519"
  },
  {
    "text": "have those code to code connections then",
    "start": "555519",
    "end": "557200"
  },
  {
    "text": "you can actually generate a wiki and for",
    "start": "557200",
    "end": "559519"
  },
  {
    "text": "each concept what we do is we use an",
    "start": "559519",
    "end": "561519"
  },
  {
    "text": "agent to go research that concept in the",
    "start": "561519",
    "end": "563600"
  },
  {
    "text": "context of the specific codebase we",
    "start": "563600",
    "end": "565440"
  },
  {
    "text": "generate a wiki page about it and then",
    "start": "565440",
    "end": "567200"
  },
  {
    "text": "we also provide those intermediate",
    "start": "567200",
    "end": "568959"
  },
  {
    "text": "artifacts as context uh and as",
    "start": "568959",
    "end": "571399"
  },
  {
    "text": "tools and when you put this all together",
    "start": "571399",
    "end": "574160"
  },
  {
    "text": "uh you get very rich representations of",
    "start": "574160",
    "end": "576000"
  },
  {
    "text": "code uh and we use graphs as a critical",
    "start": "576000",
    "end": "578480"
  },
  {
    "text": "part of those representations uh and so",
    "start": "578480",
    "end": "580720"
  },
  {
    "text": "this is a graph of uh the lang chain",
    "start": "580720",
    "end": "583200"
  },
  {
    "text": "codebase where you can see uh at a high",
    "start": "583200",
    "end": "585839"
  },
  {
    "text": "level that different files are more or",
    "start": "585839",
    "end": "587680"
  },
  {
    "text": "less related to each other uh with a lot",
    "start": "587680",
    "end": "589600"
  },
  {
    "text": "of a lot of logic in the core and then",
    "start": "589600",
    "end": "591680"
  },
  {
    "text": "maybe outskirts that are more related to",
    "start": "591680",
    "end": "593200"
  },
  {
    "text": "test harnesses documentation specific",
    "start": "593200",
    "end": "595760"
  },
  {
    "text": "integrations",
    "start": "595760",
    "end": "597399"
  },
  {
    "text": "with these data structures a lot of how",
    "start": "597399",
    "end": "600320"
  },
  {
    "text": "Devon actually works inside large you",
    "start": "600320",
    "end": "602800"
  },
  {
    "text": "know million multi-million line of code",
    "start": "602800",
    "end": "604480"
  },
  {
    "text": "code",
    "start": "604480",
    "end": "606279"
  },
  {
    "text": "bases so we've got our wiki but we also",
    "start": "606279",
    "end": "609440"
  },
  {
    "text": "need be",
    "start": "609440",
    "end": "612080"
  },
  {
    "text": "search in Devon but started as an",
    "start": "612920",
    "end": "616600"
  },
  {
    "text": "internal software engineer that's the",
    "start": "616600",
    "end": "618880"
  },
  {
    "text": "trend we're seeing is to make Devon a",
    "start": "618880",
    "end": "620880"
  },
  {
    "text": "great software engineer you need to",
    "start": "620880",
    "end": "621920"
  },
  {
    "text": "build tools that are so useful that",
    "start": "621920",
    "end": "623839"
  },
  {
    "text": "human engineers want to use them",
    "start": "623839",
    "end": "626600"
  },
  {
    "text": "too and so we have Devon search which is",
    "start": "626600",
    "end": "629920"
  },
  {
    "text": "essentially deep research on your",
    "start": "629920",
    "end": "631760"
  },
  {
    "text": "proprietary codebase again whether it's",
    "start": "631760",
    "end": "633839"
  },
  {
    "text": "open source or internal you can ask",
    "start": "633839",
    "end": "636000"
  },
  {
    "text": "questions about the code devon will scan",
    "start": "636000",
    "end": "637920"
  },
  {
    "text": "through that code try to understand",
    "start": "637920",
    "end": "639360"
  },
  {
    "text": "what's going on using both the micro",
    "start": "639360",
    "end": "642640"
  },
  {
    "text": "code the individual files but also the",
    "start": "642640",
    "end": "644320"
  },
  {
    "text": "macro context it has from this wiki data",
    "start": "644320",
    "end": "646720"
  },
  {
    "text": "structure uh and it will find this",
    "start": "646720",
    "end": "648399"
  },
  {
    "text": "information for example I asked how do I",
    "start": "648399",
    "end": "650320"
  },
  {
    "text": "enforce structured output in lang chain",
    "start": "650320",
    "end": "652079"
  },
  {
    "text": "and Devon went and found the right",
    "start": "652079",
    "end": "653680"
  },
  {
    "text": "section of the documentation from",
    "start": "653680",
    "end": "654959"
  },
  {
    "text": "langchain as well as the actual",
    "start": "654959",
    "end": "656720"
  },
  {
    "text": "implementation code for what to",
    "start": "656720",
    "end": "660519"
  },
  {
    "text": "do devon search gives Devon context it's",
    "start": "660519",
    "end": "663839"
  },
  {
    "text": "an essential part under the hood of how",
    "start": "663839",
    "end": "665760"
  },
  {
    "text": "Devon the autonomous AI agent can",
    "start": "665760",
    "end": "668320"
  },
  {
    "text": "actually make useful changes inside",
    "start": "668320",
    "end": "670560"
  },
  {
    "text": "larger teamwide code bases once you get",
    "start": "670560",
    "end": "672959"
  },
  {
    "text": "a query you need to do pre-processing",
    "start": "672959",
    "end": "675279"
  },
  {
    "text": "and of course rag is a component of that",
    "start": "675279",
    "end": "677360"
  },
  {
    "text": "um but we end up doing a lot more under",
    "start": "677360",
    "end": "679519"
  },
  {
    "text": "the hood than just rag uh including junk",
    "start": "679519",
    "end": "681680"
  },
  {
    "text": "removal some more advanced uh filtering",
    "start": "681680",
    "end": "684240"
  },
  {
    "text": "of less relevant information and",
    "start": "684240",
    "end": "686000"
  },
  {
    "text": "re-ranking multihop search to end up",
    "start": "686000",
    "end": "688640"
  },
  {
    "text": "with this set of context that we think",
    "start": "688640",
    "end": "690800"
  },
  {
    "text": "is very very relevant for this query um",
    "start": "690800",
    "end": "692800"
  },
  {
    "text": "and that context again includes both",
    "start": "692800",
    "end": "694240"
  },
  {
    "text": "source files but also wiki pages you",
    "start": "694240",
    "end": "697600"
  },
  {
    "text": "need the micro and the macro context to",
    "start": "697600",
    "end": "699519"
  },
  {
    "text": "provide really useful really useful",
    "start": "699519",
    "end": "701440"
  },
  {
    "text": "recommendations um and from that we can",
    "start": "701440",
    "end": "703680"
  },
  {
    "text": "get a grounded answer people don't want",
    "start": "703680",
    "end": "705839"
  },
  {
    "text": "hallucinations in their wikis and they",
    "start": "705839",
    "end": "707600"
  },
  {
    "text": "don't want hallucinations in their",
    "start": "707600",
    "end": "708720"
  },
  {
    "text": "search so the grounding is essential for",
    "start": "708720",
    "end": "710560"
  },
  {
    "text": "this to actually be",
    "start": "710560",
    "end": "713240"
  },
  {
    "text": "useful the second part of how we",
    "start": "713240",
    "end": "715519"
  },
  {
    "text": "optimize and customize to existing code",
    "start": "715519",
    "end": "717760"
  },
  {
    "text": "bases is a bit more researchoriented uh",
    "start": "717760",
    "end": "720880"
  },
  {
    "text": "and I'm excited to share a little bit",
    "start": "720880",
    "end": "722399"
  },
  {
    "text": "more of some of the post- training and",
    "start": "722399",
    "end": "724320"
  },
  {
    "text": "RL that we do under the hood to make",
    "start": "724320",
    "end": "726240"
  },
  {
    "text": "Devon work well inside specific narrow",
    "start": "726240",
    "end": "728959"
  },
  {
    "text": "domains",
    "start": "728959",
    "end": "730639"
  },
  {
    "text": "we recently released a new model an open",
    "start": "730639",
    "end": "732399"
  },
  {
    "text": "source free model called Kevin uh",
    "start": "732399",
    "end": "734560"
  },
  {
    "text": "Colonel Devon Kevin",
    "start": "734560",
    "end": "737800"
  },
  {
    "text": "32B kevin is uh uh outperforms many",
    "start": "737800",
    "end": "742079"
  },
  {
    "text": "state-of-the-art foundation models on",
    "start": "742079",
    "end": "743600"
  },
  {
    "text": "the narrow domain of writing CUDA",
    "start": "743600",
    "end": "745839"
  },
  {
    "text": "kernels raise your hand if you've ever",
    "start": "745839",
    "end": "747600"
  },
  {
    "text": "heard of a CUDA",
    "start": "747600",
    "end": "749399"
  },
  {
    "text": "kernel all right we have an audience",
    "start": "749399",
    "end": "751600"
  },
  {
    "text": "that's very familiar with the the",
    "start": "751600",
    "end": "752959"
  },
  {
    "text": "underfittings of ML for those who",
    "start": "752959",
    "end": "754639"
  },
  {
    "text": "haven't heard of CUDA kernels um this is",
    "start": "754639",
    "end": "757600"
  },
  {
    "text": "the source code that you use to write",
    "start": "757600",
    "end": "760160"
  },
  {
    "text": "GPU optimized uh GPU optimized",
    "start": "760160",
    "end": "762480"
  },
  {
    "text": "implementations for NVIDIA GPUs and so",
    "start": "762480",
    "end": "765440"
  },
  {
    "text": "under the hood when you're using PyTorch",
    "start": "765440",
    "end": "767200"
  },
  {
    "text": "or TensorFlow um those highle graph",
    "start": "767200",
    "end": "769519"
  },
  {
    "text": "operations are being executed under the",
    "start": "769519",
    "end": "772000"
  },
  {
    "text": "hood by CUDA kernels and the the domain",
    "start": "772000",
    "end": "774800"
  },
  {
    "text": "of writing CUDA kernels is extremely",
    "start": "774800",
    "end": "776959"
  },
  {
    "text": "rich because this is a very low-level",
    "start": "776959",
    "end": "779040"
  },
  {
    "text": "programming language relative to what",
    "start": "779040",
    "end": "781040"
  },
  {
    "text": "many of us operate in more typically",
    "start": "781040",
    "end": "782639"
  },
  {
    "text": "day-to-day say Python and uh CUDA",
    "start": "782639",
    "end": "785760"
  },
  {
    "text": "kernels were released as a uh kernel",
    "start": "785760",
    "end": "789120"
  },
  {
    "text": "bench was released as a benchmark by an",
    "start": "789120",
    "end": "791680"
  },
  {
    "text": "Simon Aelia uh to estimate models",
    "start": "791680",
    "end": "795200"
  },
  {
    "text": "capabilities of generating these very",
    "start": "795200",
    "end": "797920"
  },
  {
    "text": "niche very specific CUDA kernels at high",
    "start": "797920",
    "end": "800320"
  },
  {
    "text": "performance and high reliability and",
    "start": "800320",
    "end": "802880"
  },
  {
    "text": "this work from cognition was done by",
    "start": "802880",
    "end": "804880"
  },
  {
    "text": "Carlo",
    "start": "804880",
    "end": "806440"
  },
  {
    "text": "Provised by Silus uh these were our",
    "start": "806440",
    "end": "808800"
  },
  {
    "text": "research interns uh who who did who got",
    "start": "808800",
    "end": "810880"
  },
  {
    "text": "really really exciting results um from a",
    "start": "810880",
    "end": "813040"
  },
  {
    "text": "from a single project so let's talk",
    "start": "813040",
    "end": "815120"
  },
  {
    "text": "about what this work does more",
    "start": "815120",
    "end": "816560"
  },
  {
    "text": "specifically um the goal is to take",
    "start": "816560",
    "end": "821000"
  },
  {
    "text": "highlevel machine learning code say a",
    "start": "821000",
    "end": "823760"
  },
  {
    "text": "few different calls to pietorch and",
    "start": "823760",
    "end": "826800"
  },
  {
    "text": "rewrite it as a highly optimized",
    "start": "826800",
    "end": "828959"
  },
  {
    "text": "performant correct CUDA kernel this is a",
    "start": "828959",
    "end": "832480"
  },
  {
    "text": "very detailed problem domain that many",
    "start": "832480",
    "end": "835279"
  },
  {
    "text": "low-level machine learning researchers",
    "start": "835279",
    "end": "836880"
  },
  {
    "text": "spend you know their entire careers",
    "start": "836880",
    "end": "838800"
  },
  {
    "text": "optimizing uh the design space is quite",
    "start": "838800",
    "end": "841120"
  },
  {
    "text": "large for how to write optimal CUDA",
    "start": "841120",
    "end": "843199"
  },
  {
    "text": "kernels and it's quite challenging um",
    "start": "843199",
    "end": "845279"
  },
  {
    "text": "what we see in practice in the ML",
    "start": "845279",
    "end": "846800"
  },
  {
    "text": "community is that a lot of progress in",
    "start": "846800",
    "end": "849440"
  },
  {
    "text": "machine learning is really driven by",
    "start": "849440",
    "end": "851360"
  },
  {
    "text": "performance on the hardware and so even",
    "start": "851360",
    "end": "854480"
  },
  {
    "text": "if your algorithm or your new paper is",
    "start": "854480",
    "end": "856720"
  },
  {
    "text": "bigo optimal like a linear attention",
    "start": "856720",
    "end": "859199"
  },
  {
    "text": "mechanism um under the hood if your",
    "start": "859199",
    "end": "861680"
  },
  {
    "text": "implementation is not efficient cache",
    "start": "861680",
    "end": "863360"
  },
  {
    "text": "friendly performant on actual GPU",
    "start": "863360",
    "end": "865360"
  },
  {
    "text": "hardware it tends to not be that useful",
    "start": "865360",
    "end": "867120"
  },
  {
    "text": "so this is a really active research",
    "start": "867120",
    "end": "868720"
  },
  {
    "text": "domain for ML researchers and we want uh",
    "start": "868720",
    "end": "872240"
  },
  {
    "text": "Kevin to be good at writing these",
    "start": "872240",
    "end": "874560"
  },
  {
    "text": "optimized CUDA kernels so how does this",
    "start": "874560",
    "end": "877600"
  },
  {
    "text": "work uh the first step is to define your",
    "start": "877600",
    "end": "879680"
  },
  {
    "text": "reward function and one of the great",
    "start": "879680",
    "end": "881760"
  },
  {
    "text": "things about software and in particular",
    "start": "881760",
    "end": "884079"
  },
  {
    "text": "writing CUDA kernels is that it's often",
    "start": "884079",
    "end": "886399"
  },
  {
    "text": "easy to get automatically verifiable",
    "start": "886399",
    "end": "889360"
  },
  {
    "text": "reward can you verify the correctness of",
    "start": "889360",
    "end": "891760"
  },
  {
    "text": "your code automatically well in this",
    "start": "891760",
    "end": "893199"
  },
  {
    "text": "case we have a less performant reference",
    "start": "893199",
    "end": "895639"
  },
  {
    "text": "implementation that we can use to check",
    "start": "895639",
    "end": "898000"
  },
  {
    "text": "correctness and so whenever Kevin uh",
    "start": "898000",
    "end": "901199"
  },
  {
    "text": "which is our post-train uh sort of LLM",
    "start": "901199",
    "end": "903920"
  },
  {
    "text": "for this project whenever Kevin writes a",
    "start": "903920",
    "end": "906560"
  },
  {
    "text": "kernel we run it through a series of",
    "start": "906560",
    "end": "908160"
  },
  {
    "text": "checks right first of all does that code",
    "start": "908160",
    "end": "909760"
  },
  {
    "text": "parse um is it actually valid CUDA does",
    "start": "909760",
    "end": "912480"
  },
  {
    "text": "it compile does it run uh and then after",
    "start": "912480",
    "end": "914800"
  },
  {
    "text": "all that is it correct and only if it's",
    "start": "914800",
    "end": "917360"
  },
  {
    "text": "correct do we then grade it for",
    "start": "917360",
    "end": "919120"
  },
  {
    "text": "performance how much faster or slower is",
    "start": "919120",
    "end": "921040"
  },
  {
    "text": "it than the reference implementation so",
    "start": "921040",
    "end": "923360"
  },
  {
    "text": "with this reward function notice we",
    "start": "923360",
    "end": "925120"
  },
  {
    "text": "don't need a machine learning model here",
    "start": "925120",
    "end": "926720"
  },
  {
    "text": "this is purely a set of um automatically",
    "start": "926720",
    "end": "929639"
  },
  {
    "text": "verifiable steps um which makes which",
    "start": "929639",
    "end": "932480"
  },
  {
    "text": "makes this very very friendly for highMP",
    "start": "932480",
    "end": "934240"
  },
  {
    "text": "compute",
    "start": "934240",
    "end": "935399"
  },
  {
    "text": "RL once you have the reward function you",
    "start": "935399",
    "end": "937760"
  },
  {
    "text": "can use it for multi-turn training and",
    "start": "937760",
    "end": "940079"
  },
  {
    "text": "so we use multi-turn gpo uh and for",
    "start": "940079",
    "end": "942800"
  },
  {
    "text": "those who aren't familiar what's going",
    "start": "942800",
    "end": "944000"
  },
  {
    "text": "on here is we're taking multiple",
    "start": "944000",
    "end": "946880"
  },
  {
    "text": "different trajectories in sequence for",
    "start": "946880",
    "end": "949440"
  },
  {
    "text": "this model to get better at writing CUDA",
    "start": "949440",
    "end": "952320"
  },
  {
    "text": "code so on the left here we have an",
    "start": "952320",
    "end": "954639"
  },
  {
    "text": "initial prompt which results in a chain",
    "start": "954639",
    "end": "956560"
  },
  {
    "text": "of thought from the model and an output",
    "start": "956560",
    "end": "958959"
  },
  {
    "text": "and that output may or may not be",
    "start": "958959",
    "end": "960480"
  },
  {
    "text": "correct uh when we move to the second",
    "start": "960480",
    "end": "962560"
  },
  {
    "text": "the middle of this diagram we provide",
    "start": "962560",
    "end": "964800"
  },
  {
    "text": "eval info back to the model and this",
    "start": "964800",
    "end": "967120"
  },
  {
    "text": "eval info is the results from trying to",
    "start": "967120",
    "end": "969199"
  },
  {
    "text": "run that kernel in a real world GPU",
    "start": "969199",
    "end": "971120"
  },
  {
    "text": "environment um there's a lot of work you",
    "start": "971120",
    "end": "972639"
  },
  {
    "text": "have to do in terms of sandboxing and",
    "start": "972639",
    "end": "974399"
  },
  {
    "text": "isolation to make sure these incorrect",
    "start": "974399",
    "end": "976000"
  },
  {
    "text": "CUDA kernels don't mess up your training",
    "start": "976000",
    "end": "978079"
  },
  {
    "text": "process or crash your GPUs and that",
    "start": "978079",
    "end": "980160"
  },
  {
    "text": "you're getting accurate performance",
    "start": "980160",
    "end": "981279"
  },
  {
    "text": "benchmarks but we package all that up",
    "start": "981279",
    "end": "982959"
  },
  {
    "text": "into almost like a strruct of eval that",
    "start": "982959",
    "end": "985839"
  },
  {
    "text": "that model can then see as it tries",
    "start": "985839",
    "end": "988199"
  },
  {
    "text": "again and it tries again with a second",
    "start": "988199",
    "end": "990480"
  },
  {
    "text": "chain of thought a second kernel that",
    "start": "990480",
    "end": "992320"
  },
  {
    "text": "gets passed and this process repeats",
    "start": "992320",
    "end": "995199"
  },
  {
    "text": "over several steps and the result is",
    "start": "995199",
    "end": "998560"
  },
  {
    "text": "hopefully a correct kernel then you have",
    "start": "998560",
    "end": "1001600"
  },
  {
    "text": "to distribute your rewards to training",
    "start": "1001600",
    "end": "1003680"
  },
  {
    "text": "this information and what we found is",
    "start": "1003680",
    "end": "1005600"
  },
  {
    "text": "that you don't want to just reward based",
    "start": "1005600",
    "end": "1007920"
  },
  {
    "text": "on the final output uh and its",
    "start": "1007920",
    "end": "1010000"
  },
  {
    "text": "correctness or not and its performance",
    "start": "1010000",
    "end": "1012639"
  },
  {
    "text": "or lack of performance actually the the",
    "start": "1012639",
    "end": "1015120"
  },
  {
    "text": "path to get there is also valuable so",
    "start": "1015120",
    "end": "1017759"
  },
  {
    "text": "you'll notice in red at the bottom here",
    "start": "1017759",
    "end": "1019839"
  },
  {
    "text": "we have this uh this sum of different",
    "start": "1019839",
    "end": "1022480"
  },
  {
    "text": "rewards discounted by gamma over time",
    "start": "1022480",
    "end": "1025280"
  },
  {
    "text": "and what that's showing is the very",
    "start": "1025280",
    "end": "1026959"
  },
  {
    "text": "first trajectory the very first step of",
    "start": "1026959",
    "end": "1028959"
  },
  {
    "text": "that trajectory gets a reward even if it",
    "start": "1028959",
    "end": "1032079"
  },
  {
    "text": "wasn't correct itself if it led to a",
    "start": "1032079",
    "end": "1035438"
  },
  {
    "text": "correct solution and a performance",
    "start": "1035439",
    "end": "1036798"
  },
  {
    "text": "solution downstream are you barking up",
    "start": "1036799",
    "end": "1038798"
  },
  {
    "text": "the right tree is basically the reward",
    "start": "1038799",
    "end": "1040720"
  },
  {
    "text": "we want to give the model and what we",
    "start": "1040720",
    "end": "1042558"
  },
  {
    "text": "found in this project is that being able",
    "start": "1042559",
    "end": "1044240"
  },
  {
    "text": "to do this over multiple iterations with",
    "start": "1044240",
    "end": "1046240"
  },
  {
    "text": "these discounted rewards was really",
    "start": "1046240",
    "end": "1048400"
  },
  {
    "text": "important for this to work because",
    "start": "1048400",
    "end": "1049600"
  },
  {
    "text": "writing CUDA kernels is hard and so the",
    "start": "1049600",
    "end": "1051200"
  },
  {
    "text": "reward signal is going to be sparse if",
    "start": "1051200",
    "end": "1052960"
  },
  {
    "text": "you only get one shot",
    "start": "1052960",
    "end": "1055520"
  },
  {
    "text": "and once you do this uh you can you can",
    "start": "1055520",
    "end": "1058160"
  },
  {
    "text": "find that it's not impossible to very",
    "start": "1058160",
    "end": "1061520"
  },
  {
    "text": "deeply optimize for these narrow problem",
    "start": "1061520",
    "end": "1065120"
  },
  {
    "text": "domains so in this graph we have the um",
    "start": "1065120",
    "end": "1068880"
  },
  {
    "text": "correctness on the left how many of the",
    "start": "1068880",
    "end": "1071760"
  },
  {
    "text": "kernels were written correctly by this",
    "start": "1071760",
    "end": "1073679"
  },
  {
    "text": "model and Kevin 32B is getting 91%",
    "start": "1073679",
    "end": "1077520"
  },
  {
    "text": "correct on this se section of the kernel",
    "start": "1077520",
    "end": "1079919"
  },
  {
    "text": "bench benchmark that we focused on and",
    "start": "1079919",
    "end": "1081919"
  },
  {
    "text": "you can see that compared to even 04",
    "start": "1081919",
    "end": "1083919"
  },
  {
    "text": "mini or 03 this is a significant",
    "start": "1083919",
    "end": "1086400"
  },
  {
    "text": "improvement um this is a narrow domain",
    "start": "1086400",
    "end": "1088880"
  },
  {
    "text": "where high compute RL lets you",
    "start": "1088880",
    "end": "1091080"
  },
  {
    "text": "outperform existing models on the right",
    "start": "1091080",
    "end": "1094960"
  },
  {
    "text": "you see performance so we rewarded Devon",
    "start": "1094960",
    "end": "1097600"
  },
  {
    "text": "proportional to how much speed up uh you",
    "start": "1097600",
    "end": "1100000"
  },
  {
    "text": "know Kevin got in this project and so as",
    "start": "1100000",
    "end": "1102960"
  },
  {
    "text": "the kernels got faster and faster it got",
    "start": "1102960",
    "end": "1104720"
  },
  {
    "text": "more and more reward and what we found",
    "start": "1104720",
    "end": "1106400"
  },
  {
    "text": "is that even from a performance",
    "start": "1106400",
    "end": "1107919"
  },
  {
    "text": "standpoint Kevin 32B is able to",
    "start": "1107919",
    "end": "1110760"
  },
  {
    "text": "outperform these larger scale",
    "start": "1110760",
    "end": "1112880"
  },
  {
    "text": "foundational",
    "start": "1112880",
    "end": "1115360"
  },
  {
    "text": "models to be the best at everything and",
    "start": "1124120",
    "end": "1126880"
  },
  {
    "text": "you should use them exclusively for",
    "start": "1126880",
    "end": "1128559"
  },
  {
    "text": "everything but what we see internally",
    "start": "1128559",
    "end": "1130720"
  },
  {
    "text": "all the time is that for any given",
    "start": "1130720",
    "end": "1132799"
  },
  {
    "text": "narrow domain if you can set up your",
    "start": "1132799",
    "end": "1134799"
  },
  {
    "text": "environment to do high compute RL in",
    "start": "1134799",
    "end": "1136559"
  },
  {
    "text": "that domain it's very feasible to",
    "start": "1136559",
    "end": "1138799"
  },
  {
    "text": "outperform an out of the box foundation",
    "start": "1138799",
    "end": "1141039"
  },
  {
    "text": "model especially as the open source",
    "start": "1141039",
    "end": "1143039"
  },
  {
    "text": "based models that you start with have",
    "start": "1143039",
    "end": "1146039"
  },
  {
    "text": "improved to actually make this work in",
    "start": "1146039",
    "end": "1148080"
  },
  {
    "text": "practice it's important that you keep",
    "start": "1148080",
    "end": "1149919"
  },
  {
    "text": "your model doing what you actually want",
    "start": "1149919",
    "end": "1151600"
  },
  {
    "text": "it to do and not cheating uh along the",
    "start": "1151600",
    "end": "1153840"
  },
  {
    "text": "way and this is called reward hacking in",
    "start": "1153840",
    "end": "1156400"
  },
  {
    "text": "in in RL and it's uh many cases actually",
    "start": "1156400",
    "end": "1159120"
  },
  {
    "text": "challenging to prevent so I want to show",
    "start": "1159120",
    "end": "1160480"
  },
  {
    "text": "you a few ways that Kevin misbehaved uh",
    "start": "1160480",
    "end": "1162559"
  },
  {
    "text": "that we had to sort of steer back so one",
    "start": "1162559",
    "end": "1165039"
  },
  {
    "text": "is Kevin realized that it could write",
    "start": "1165039",
    "end": "1166880"
  },
  {
    "text": "the CUDA and then wrap the whole thing",
    "start": "1166880",
    "end": "1168320"
  },
  {
    "text": "in a try accept block and just fall back",
    "start": "1168320",
    "end": "1171360"
  },
  {
    "text": "to the existing PyTorch implementation",
    "start": "1171360",
    "end": "1174080"
  },
  {
    "text": "and you know it would always score 100%",
    "start": "1174080",
    "end": "1176480"
  },
  {
    "text": "correct in that case and it had some",
    "start": "1176480",
    "end": "1178559"
  },
  {
    "text": "chance of being faster than average but",
    "start": "1178559",
    "end": "1180080"
  },
  {
    "text": "if it wasn't it it sort of defaulted to",
    "start": "1180080",
    "end": "1181679"
  },
  {
    "text": "the 1x so that was a very unproductive",
    "start": "1181679",
    "end": "1183600"
  },
  {
    "text": "direction for for Kevin to go down",
    "start": "1183600",
    "end": "1185440"
  },
  {
    "text": "during the RL process and we had to make",
    "start": "1185440",
    "end": "1188160"
  },
  {
    "text": "sure that we update the reward function",
    "start": "1188160",
    "end": "1190000"
  },
  {
    "text": "to recognize this type of reward hacking",
    "start": "1190000",
    "end": "1193120"
  },
  {
    "text": "the second is even a bit more subtle uh",
    "start": "1193120",
    "end": "1195679"
  },
  {
    "text": "and so the test harness to make sure",
    "start": "1195679",
    "end": "1198720"
  },
  {
    "text": "that Kevin's code was correct uh had a",
    "start": "1198720",
    "end": "1201200"
  },
  {
    "text": "class you know in this case called model",
    "start": "1201200",
    "end": "1202799"
  },
  {
    "text": "new uh that inherited from model and you",
    "start": "1202799",
    "end": "1206559"
  },
  {
    "text": "can see here what Kevin realized is that",
    "start": "1206559",
    "end": "1209120"
  },
  {
    "text": "it could implement the model as a uh you",
    "start": "1209120",
    "end": "1212320"
  },
  {
    "text": "know as a subclass of an NM module with",
    "start": "1212320",
    "end": "1215039"
  },
  {
    "text": "its attempt at optimize CUDA code and",
    "start": "1215039",
    "end": "1217039"
  },
  {
    "text": "then it could just overwrite that uh",
    "start": "1217039",
    "end": "1219120"
  },
  {
    "text": "class name in the name space and so you",
    "start": "1219120",
    "end": "1220960"
  },
  {
    "text": "can see it defined a second model new",
    "start": "1220960",
    "end": "1222559"
  },
  {
    "text": "that this in this case just inherits",
    "start": "1222559",
    "end": "1224080"
  },
  {
    "text": "directly from the correct model",
    "start": "1224080",
    "end": "1225760"
  },
  {
    "text": "implementation so these models got very",
    "start": "1225760",
    "end": "1227440"
  },
  {
    "text": "creative at all how to sort of get",
    "start": "1227440",
    "end": "1229600"
  },
  {
    "text": "around your intentions and this is a",
    "start": "1229600",
    "end": "1231919"
  },
  {
    "text": "challenge in RL and so making sure you",
    "start": "1231919",
    "end": "1233840"
  },
  {
    "text": "correctly define your environment is is",
    "start": "1233840",
    "end": "1236159"
  },
  {
    "text": "really critical to success and for those",
    "start": "1236159",
    "end": "1238640"
  },
  {
    "text": "of you who have used maybe popular",
    "start": "1238640",
    "end": "1240720"
  },
  {
    "text": "commercial models like some of the most",
    "start": "1240720",
    "end": "1242080"
  },
  {
    "text": "popular models for coding you might have",
    "start": "1242080",
    "end": "1243840"
  },
  {
    "text": "seen that as the models get better",
    "start": "1243840",
    "end": "1245919"
  },
  {
    "text": "sometimes they're more aggressive at",
    "start": "1245919",
    "end": "1247520"
  },
  {
    "text": "doing things like commenting out your",
    "start": "1247520",
    "end": "1249280"
  },
  {
    "text": "test cases to make sure the work still",
    "start": "1249280",
    "end": "1251360"
  },
  {
    "text": "pass that's what's going on under the",
    "start": "1251360",
    "end": "1253120"
  },
  {
    "text": "hood is this is uh this is a smell of",
    "start": "1253120",
    "end": "1256640"
  },
  {
    "text": "reward hacking and and so it's a",
    "start": "1256640",
    "end": "1258720"
  },
  {
    "text": "constant sort of cat-and- mouse game",
    "start": "1258720",
    "end": "1260159"
  },
  {
    "text": "between the researchers who are trying",
    "start": "1260159",
    "end": "1261520"
  },
  {
    "text": "to steer these models to do what we",
    "start": "1261520",
    "end": "1262960"
  },
  {
    "text": "actually want and the models they're",
    "start": "1262960",
    "end": "1264640"
  },
  {
    "text": "trying to exploit every possible way to",
    "start": "1264640",
    "end": "1266799"
  },
  {
    "text": "get this highquality",
    "start": "1266799",
    "end": "1270000"
  },
  {
    "text": "reward so what do we learn from this um",
    "start": "1270120",
    "end": "1273360"
  },
  {
    "text": "custom post training can and does",
    "start": "1273360",
    "end": "1275200"
  },
  {
    "text": "outperform frontier models on specific",
    "start": "1275200",
    "end": "1277679"
  },
  {
    "text": "narrow",
    "start": "1277679",
    "end": "1278760"
  },
  {
    "text": "domains for reinforcement learning",
    "start": "1278760",
    "end": "1280960"
  },
  {
    "text": "specifically um especially in code it's",
    "start": "1280960",
    "end": "1283120"
  },
  {
    "text": "more computebound than databound you",
    "start": "1283120",
    "end": "1285200"
  },
  {
    "text": "know kernel bench the subset of kernel",
    "start": "1285200",
    "end": "1286799"
  },
  {
    "text": "bench that we trained on only had 180",
    "start": "1286799",
    "end": "1289200"
  },
  {
    "text": "tasks which is really not that many when",
    "start": "1289200",
    "end": "1291200"
  },
  {
    "text": "you think about it but by applying",
    "start": "1291200",
    "end": "1292799"
  },
  {
    "text": "highMP compute RL rolling out these",
    "start": "1292799",
    "end": "1294320"
  },
  {
    "text": "trajectories again and again there is",
    "start": "1294320",
    "end": "1296000"
  },
  {
    "text": "very very rich signal to learn from and",
    "start": "1296000",
    "end": "1298400"
  },
  {
    "text": "that's because in software we have an",
    "start": "1298400",
    "end": "1300240"
  },
  {
    "text": "oracle that can help with these rewards",
    "start": "1300240",
    "end": "1301840"
  },
  {
    "text": "we actually have the environment we can",
    "start": "1301840",
    "end": "1303600"
  },
  {
    "text": "run the code we can see if it compiles",
    "start": "1303600",
    "end": "1305440"
  },
  {
    "text": "we can see how fast it is and this in my",
    "start": "1305440",
    "end": "1307919"
  },
  {
    "text": "opinion is one of the reasons that um",
    "start": "1307919",
    "end": "1309919"
  },
  {
    "text": "software and coding specifically has",
    "start": "1309919",
    "end": "1311919"
  },
  {
    "text": "accelerated particularly fast as an AI",
    "start": "1311919",
    "end": "1314320"
  },
  {
    "text": "capability is that code is one of the",
    "start": "1314320",
    "end": "1316159"
  },
  {
    "text": "few domains where this property holds i",
    "start": "1316159",
    "end": "1319679"
  },
  {
    "text": "used to lead machine learning at scale",
    "start": "1319679",
    "end": "1321520"
  },
  {
    "text": "AI which provides post-training human",
    "start": "1321520",
    "end": "1323280"
  },
  {
    "text": "data for many of the large scale",
    "start": "1323280",
    "end": "1324960"
  },
  {
    "text": "foundation model labs and it gets really",
    "start": "1324960",
    "end": "1327360"
  },
  {
    "text": "hard to label by hand high quality high",
    "start": "1327360",
    "end": "1330799"
  },
  {
    "text": "accuracy data as the models get smarter",
    "start": "1330799",
    "end": "1332880"
  },
  {
    "text": "but code doesn't have that bottleneck",
    "start": "1332880",
    "end": "1334480"
  },
  {
    "text": "because you can continually scale um",
    "start": "1334480",
    "end": "1336960"
  },
  {
    "text": "based on automatic signals of",
    "start": "1336960",
    "end": "1338480"
  },
  {
    "text": "correctness and that's really the third",
    "start": "1338480",
    "end": "1340320"
  },
  {
    "text": "key is automatic verification allows you",
    "start": "1340320",
    "end": "1343360"
  },
  {
    "text": "to scale so for your own code bases and",
    "start": "1343360",
    "end": "1345360"
  },
  {
    "text": "your own process putting in the CI",
    "start": "1345360",
    "end": "1347440"
  },
  {
    "text": "systems putting in the test coverage",
    "start": "1347440",
    "end": "1349039"
  },
  {
    "text": "putting in the harnesses that allow that",
    "start": "1349039",
    "end": "1350720"
  },
  {
    "text": "automatic verification is going to",
    "start": "1350720",
    "end": "1352480"
  },
  {
    "text": "futureproof your code as AI gets better",
    "start": "1352480",
    "end": "1356400"
  },
  {
    "text": "and we see many of our users of Devon",
    "start": "1356400",
    "end": "1358240"
  },
  {
    "text": "they first take their code base with",
    "start": "1358240",
    "end": "1359919"
  },
  {
    "text": "Devon and go fix all the test coverage",
    "start": "1359919",
    "end": "1362480"
  },
  {
    "text": "issues and now that they have full test",
    "start": "1362480",
    "end": "1364640"
  },
  {
    "text": "coverage it's even faster to use Devon",
    "start": "1364640",
    "end": "1366880"
  },
  {
    "text": "to ship new more pull",
    "start": "1366880",
    "end": "1369320"
  },
  {
    "text": "requests the last big point here is I",
    "start": "1369320",
    "end": "1371840"
  },
  {
    "text": "just showed you an example on CUDA",
    "start": "1371840",
    "end": "1373360"
  },
  {
    "text": "kernels but to me the the more",
    "start": "1373360",
    "end": "1375600"
  },
  {
    "text": "interesting deeper implication of this",
    "start": "1375600",
    "end": "1377280"
  },
  {
    "text": "research is every codebase is in some",
    "start": "1377280",
    "end": "1380080"
  },
  {
    "text": "sense a narrow domain there are specific",
    "start": "1380080",
    "end": "1382480"
  },
  {
    "text": "things to your code that don't exist in",
    "start": "1382480",
    "end": "1384559"
  },
  {
    "text": "anyone else's code and that's more and",
    "start": "1384559",
    "end": "1386400"
  },
  {
    "text": "more true the larger your codebase so",
    "start": "1386400",
    "end": "1388480"
  },
  {
    "text": "you can imagine a future where high",
    "start": "1388480",
    "end": "1392480"
  },
  {
    "text": "computation leads to significantly",
    "start": "1392679",
    "end": "1395039"
  },
  {
    "text": "outperforming agents on each individual",
    "start": "1395039",
    "end": "1397760"
  },
  {
    "text": "domain the equivalent of hiring a",
    "start": "1397760",
    "end": "1399600"
  },
  {
    "text": "software engineer and giving them",
    "start": "1399600",
    "end": "1400799"
  },
  {
    "text": "millions of years of experience working",
    "start": "1400799",
    "end": "1402720"
  },
  {
    "text": "specifically in your environment so this",
    "start": "1402720",
    "end": "1405280"
  },
  {
    "text": "is some of the research work uh we've",
    "start": "1405280",
    "end": "1406720"
  },
  {
    "text": "been doing at Cognition that powers",
    "start": "1406720",
    "end": "1407919"
  },
  {
    "text": "Devon under the hood if you'd like to",
    "start": "1407919",
    "end": "1409840"
  },
  {
    "text": "play around and try this yourself you",
    "start": "1409840",
    "end": "1411600"
  },
  {
    "text": "can use uh you can go to devon.ai and",
    "start": "1411600",
    "end": "1414400"
  },
  {
    "text": "sign up for an account connect it with",
    "start": "1414400",
    "end": "1415919"
  },
  {
    "text": "your existing code give it a task and go",
    "start": "1415919",
    "end": "1417919"
  },
  {
    "text": "from ticket to PR thank you so much for",
    "start": "1417919",
    "end": "1419840"
  },
  {
    "text": "having",
    "start": "1419840",
    "end": "1420919"
  },
  {
    "text": "me thank you",
    "start": "1420919",
    "end": "1425158"
  }
]
[
  {
    "text": "how's it going everyone it's Jacob from",
    "start": "1760",
    "end": "4080"
  },
  {
    "text": "linkchain",
    "start": "4080",
    "end": "5240"
  },
  {
    "text": "evaluating your apps performance on a",
    "start": "5240",
    "end": "7520"
  },
  {
    "text": "range of inputs commonly referred to as",
    "start": "7520",
    "end": "10040"
  },
  {
    "text": "evals are a vital part of bringing llm",
    "start": "10040",
    "end": "12920"
  },
  {
    "text": "apps from prototype to",
    "start": "12920",
    "end": "14759"
  },
  {
    "text": "production that's why today I'm excited",
    "start": "14759",
    "end": "17000"
  },
  {
    "text": "to show off a new open source package",
    "start": "17000",
    "end": "19119"
  },
  {
    "text": "that makes getting started with this",
    "start": "19119",
    "end": "20480"
  },
  {
    "text": "process faster and easier than ever open",
    "start": "20480",
    "end": "24800"
  },
  {
    "text": "evals we're launching it centered around",
    "start": "24800",
    "end": "27160"
  },
  {
    "text": "a specific type of evaluator called an l",
    "start": "27160",
    "end": "30119"
  },
  {
    "text": "them as a judge this is where you have a",
    "start": "30119",
    "end": "33239"
  },
  {
    "text": "capable model grade the outputs of your",
    "start": "33239",
    "end": "35480"
  },
  {
    "text": "app or some component of it assigning it",
    "start": "35480",
    "end": "37960"
  },
  {
    "text": "a score which can be a past fail or",
    "start": "37960",
    "end": "39760"
  },
  {
    "text": "something more",
    "start": "39760",
    "end": "40719"
  },
  {
    "text": "granular we've seen this as a common",
    "start": "40719",
    "end": "42680"
  },
  {
    "text": "starting point for many different",
    "start": "42680",
    "end": "44600"
  },
  {
    "text": "teams and for these open evals include",
    "start": "44600",
    "end": "47440"
  },
  {
    "text": "some pre-built prompts but makes them",
    "start": "47440",
    "end": "49399"
  },
  {
    "text": "completely and transparently",
    "start": "49399",
    "end": "51399"
  },
  {
    "text": "customizable so that you can use",
    "start": "51399",
    "end": "53120"
  },
  {
    "text": "whatever criteria you'd like while",
    "start": "53120",
    "end": "54920"
  },
  {
    "text": "judging and it allows you to customize",
    "start": "54920",
    "end": "57120"
  },
  {
    "text": "the outputed scores to be either discret",
    "start": "57120",
    "end": "59160"
  },
  {
    "text": "values or continuous range it also",
    "start": "59160",
    "end": "62160"
  },
  {
    "text": "handles parsing out the lm's results and",
    "start": "62160",
    "end": "63960"
  },
  {
    "text": "the structured output that the model",
    "start": "63960",
    "end": "66960"
  },
  {
    "text": "requires there's also convenient",
    "start": "66960",
    "end": "68880"
  },
  {
    "text": "parameters for few shot examples which",
    "start": "68880",
    "end": "70759"
  },
  {
    "text": "are example inputs outputs and scores",
    "start": "70759",
    "end": "73799"
  },
  {
    "text": "that give the llm judge more clarity on",
    "start": "73799",
    "end": "76240"
  },
  {
    "text": "what your preferences",
    "start": "76240",
    "end": "77960"
  },
  {
    "text": "are it also supports a wide variety of",
    "start": "77960",
    "end": "80600"
  },
  {
    "text": "models as the judge including open AIS",
    "start": "80600",
    "end": "84159"
  },
  {
    "text": "anthropics Googles open source ones",
    "start": "84159",
    "end": "86720"
  },
  {
    "text": "through AMA and more through lank chain",
    "start": "86720",
    "end": "90400"
  },
  {
    "text": "or if you prefer you can bring your own",
    "start": "90400",
    "end": "92479"
  },
  {
    "text": "open AI client and it's available in",
    "start": "92479",
    "end": "95280"
  },
  {
    "text": "both Python and",
    "start": "95280",
    "end": "96640"
  },
  {
    "text": "JavaScript now let's see it in",
    "start": "96640",
    "end": "101159"
  },
  {
    "text": "action okay so here we have a simple",
    "start": "101680",
    "end": "104000"
  },
  {
    "text": "example llm app that's just a chatbot",
    "start": "104000",
    "end": "106840"
  },
  {
    "text": "pretending to be a pirate and let's say",
    "start": "106840",
    "end": "108960"
  },
  {
    "text": "you've been working hard on this you're",
    "start": "108960",
    "end": "110280"
  },
  {
    "text": "ready to bring it to production for",
    "start": "110280",
    "end": "112320"
  },
  {
    "text": "users who are not a little enthusiasts",
    "start": "112320",
    "end": "114719"
  },
  {
    "text": "who really want to talk to a pirate and",
    "start": "114719",
    "end": "116920"
  },
  {
    "text": "have that experience so they could ask a",
    "start": "116920",
    "end": "119360"
  },
  {
    "text": "funny question like what is your",
    "start": "119360",
    "end": "123399"
  },
  {
    "text": "name and the app would respond with",
    "start": "123840",
    "end": "126280"
  },
  {
    "text": "something like I be on far and wide is",
    "start": "126280",
    "end": "128239"
  },
  {
    "text": "patchy and you know it sort of like",
    "start": "128239",
    "end": "130440"
  },
  {
    "text": "satisfies what the user would expect",
    "start": "130440",
    "end": "132840"
  },
  {
    "text": "when talking to a pirate it's in dialect",
    "start": "132840",
    "end": "135239"
  },
  {
    "text": "character",
    "start": "135239",
    "end": "136720"
  },
  {
    "text": "Etc so this is great uh and you can see",
    "start": "136720",
    "end": "139360"
  },
  {
    "text": "the app itself is actually quite simple",
    "start": "139360",
    "end": "141160"
  },
  {
    "text": "it's just a single model call to open AI",
    "start": "141160",
    "end": "143959"
  },
  {
    "text": "with a simple system prompt saying",
    "start": "143959",
    "end": "145519"
  },
  {
    "text": "you're a pirate name Pache respond in a",
    "start": "145519",
    "end": "147760"
  },
  {
    "text": "certain way pass these messages in from",
    "start": "147760",
    "end": "150040"
  },
  {
    "text": "the front end into the client and then",
    "start": "150040",
    "end": "152840"
  },
  {
    "text": "return the",
    "start": "152840",
    "end": "154879"
  },
  {
    "text": "content this is great but let's say you",
    "start": "154879",
    "end": "157760"
  },
  {
    "text": "know you're worried or you know you have",
    "start": "157760",
    "end": "159560"
  },
  {
    "text": "some reports that users are trying to",
    "start": "159560",
    "end": "161280"
  },
  {
    "text": "get the app to break character and one",
    "start": "161280",
    "end": "164480"
  },
  {
    "text": "way they might do this is asking what",
    "start": "164480",
    "end": "166760"
  },
  {
    "text": "model are",
    "start": "166760",
    "end": "170080"
  },
  {
    "text": "you and you can see that it actually",
    "start": "170519",
    "end": "172720"
  },
  {
    "text": "does leak that it's a model known as",
    "start": "172720",
    "end": "174360"
  },
  {
    "text": "chat gbt a product of the illustrious",
    "start": "174360",
    "end": "176360"
  },
  {
    "text": "open Ai and you know this is true but",
    "start": "176360",
    "end": "179879"
  },
  {
    "text": "but not really what we want our Persona",
    "start": "179879",
    "end": "182840"
  },
  {
    "text": "pirate chatbot to be saying we want it",
    "start": "182840",
    "end": "184920"
  },
  {
    "text": "to be taking on uh denying this and",
    "start": "184920",
    "end": "187239"
  },
  {
    "text": "saying that it's a pirate named patchy",
    "start": "187239",
    "end": "189680"
  },
  {
    "text": "and that you're really talking to a",
    "start": "189680",
    "end": "191799"
  },
  {
    "text": "genuine",
    "start": "191799",
    "end": "193080"
  },
  {
    "text": "pirate so the fix for this you might",
    "start": "193080",
    "end": "195280"
  },
  {
    "text": "think is pretty simple it's just let's",
    "start": "195280",
    "end": "196920"
  },
  {
    "text": "just update the system prompt as you can",
    "start": "196920",
    "end": "199400"
  },
  {
    "text": "see it's pretty simple but you know if",
    "start": "199400",
    "end": "201360"
  },
  {
    "text": "you had many people working on a team",
    "start": "201360",
    "end": "202799"
  },
  {
    "text": "here or you know you wanted to make many",
    "start": "202799",
    "end": "204280"
  },
  {
    "text": "changes to this prompt at once you",
    "start": "204280",
    "end": "207280"
  },
  {
    "text": "wouldn't want any regression you",
    "start": "207280",
    "end": "208400"
  },
  {
    "text": "wouldn't want to remove a key B bit of",
    "start": "208400",
    "end": "210239"
  },
  {
    "text": "prompt or like some other part of your",
    "start": "210239",
    "end": "211760"
  },
  {
    "text": "app that was maybe blocking the app from",
    "start": "211760",
    "end": "214959"
  },
  {
    "text": "responding and breaking",
    "start": "214959",
    "end": "217319"
  },
  {
    "text": "character so a great way to this is",
    "start": "217319",
    "end": "219480"
  },
  {
    "text": "where open evals comes in and a great",
    "start": "219480",
    "end": "221319"
  },
  {
    "text": "way to do this is to write an eval that",
    "start": "221319",
    "end": "223360"
  },
  {
    "text": "checks for this",
    "start": "223360",
    "end": "225080"
  },
  {
    "text": "case so I've got",
    "start": "225080",
    "end": "227840"
  },
  {
    "text": "a uh using a v test like Runner to run",
    "start": "227840",
    "end": "231720"
  },
  {
    "text": "my evals uh you just need to know that",
    "start": "231720",
    "end": "234560"
  },
  {
    "text": "it can basically run this test case",
    "start": "234560",
    "end": "236959"
  },
  {
    "text": "passes this input and reference output",
    "start": "236959",
    "end": "239120"
  },
  {
    "text": "into my case here and I can pass that",
    "start": "239120",
    "end": "241439"
  },
  {
    "text": "into my app and then my evaluator as",
    "start": "241439",
    "end": "244239"
  },
  {
    "text": "well later on I'll leave a link to this",
    "start": "244239",
    "end": "246239"
  },
  {
    "text": "in the description of this video if",
    "start": "246239",
    "end": "247720"
  },
  {
    "text": "you're interested in learning more about",
    "start": "247720",
    "end": "249439"
  },
  {
    "text": "this Runner but yeah I've just got a",
    "start": "249439",
    "end": "252159"
  },
  {
    "text": "simple command set up here that just",
    "start": "252159",
    "end": "253360"
  },
  {
    "text": "runs vest with this",
    "start": "253360",
    "end": "255160"
  },
  {
    "text": "config and looks for anything that ends",
    "start": "255160",
    "end": "257799"
  },
  {
    "text": "in eval dots and we'll run that as inval",
    "start": "257799",
    "end": "262280"
  },
  {
    "text": "eval so if I run this um as is it's just",
    "start": "262280",
    "end": "265240"
  },
  {
    "text": "going to log the response from my app",
    "start": "265240",
    "end": "266960"
  },
  {
    "text": "let's quit the server and do yarn run EV",
    "start": "266960",
    "end": "271720"
  },
  {
    "text": "and you can see it's just going to go",
    "start": "272120",
    "end": "274440"
  },
  {
    "text": "through and it's going to spit out the",
    "start": "274440",
    "end": "276680"
  },
  {
    "text": "response um this time it says something",
    "start": "276680",
    "end": "278800"
  },
  {
    "text": "slightly different but it thinks it's",
    "start": "278800",
    "end": "280720"
  },
  {
    "text": "GPT 5 and you know was made by the fine",
    "start": "280720",
    "end": "283840"
  },
  {
    "text": "folk at open AI which again we don't",
    "start": "283840",
    "end": "285960"
  },
  {
    "text": "want in this",
    "start": "285960",
    "end": "288000"
  },
  {
    "text": "case so yeah how do we basically write a",
    "start": "288000",
    "end": "291360"
  },
  {
    "text": "test that or like write an eval that",
    "start": "291360",
    "end": "293160"
  },
  {
    "text": "will stop the uh that will flag when",
    "start": "293160",
    "end": "296080"
  },
  {
    "text": "this app breaks character for this input",
    "start": "296080",
    "end": "299479"
  },
  {
    "text": "and and yeah we can import the create",
    "start": "299479",
    "end": "302280"
  },
  {
    "text": "llm as",
    "start": "302280",
    "end": "304919"
  },
  {
    "text": "judge method from open evals here and",
    "start": "305080",
    "end": "308160"
  },
  {
    "text": "the reason we're you know it's nice to",
    "start": "308160",
    "end": "309360"
  },
  {
    "text": "use an llm as judge here is you know",
    "start": "309360",
    "end": "311160"
  },
  {
    "text": "while this particular response may",
    "start": "311160",
    "end": "312960"
  },
  {
    "text": "contain GPT 3.5 and various keywords we",
    "start": "312960",
    "end": "315199"
  },
  {
    "text": "could use to sort of detect whether the",
    "start": "315199",
    "end": "318400"
  },
  {
    "text": "LM is breaking character let's say we",
    "start": "318400",
    "end": "320360"
  },
  {
    "text": "were to switch models behind the scenes",
    "start": "320360",
    "end": "322600"
  },
  {
    "text": "or you know use some other like yeah",
    "start": "322600",
    "end": "325199"
  },
  {
    "text": "something like",
    "start": "325199",
    "end": "326280"
  },
  {
    "text": "anthropic then our check would be pretty",
    "start": "326280",
    "end": "328520"
  },
  {
    "text": "brittle and it would fail in many cases",
    "start": "328520",
    "end": "330160"
  },
  {
    "text": "there may be other subtle outputs where",
    "start": "330160",
    "end": "332280"
  },
  {
    "text": "we want to detect that the LM is",
    "start": "332280",
    "end": "334120"
  },
  {
    "text": "breaking character so an llm is perfect",
    "start": "334120",
    "end": "336240"
  },
  {
    "text": "for this sort of messy uh generative",
    "start": "336240",
    "end": "338880"
  },
  {
    "text": "output and we're going to initialize our",
    "start": "338880",
    "end": "341000"
  },
  {
    "text": "evaluator like this Conant evaluator",
    "start": "341000",
    "end": "343199"
  },
  {
    "text": "equals create llm is Judge we're going",
    "start": "343199",
    "end": "345280"
  },
  {
    "text": "to use this correctness prompt that you",
    "start": "345280",
    "end": "346880"
  },
  {
    "text": "can see is just an F string",
    "start": "346880",
    "end": "348840"
  },
  {
    "text": "here and the open AI 03 Mini",
    "start": "348840",
    "end": "352520"
  },
  {
    "text": "model and cursor is doing a great job",
    "start": "352520",
    "end": "354720"
  },
  {
    "text": "with this but um yeah uh oh it was okay",
    "start": "354720",
    "end": "358039"
  },
  {
    "text": "so I forgot the outputs our Valor is",
    "start": "358039",
    "end": "359960"
  },
  {
    "text": "going to take in the reference outputs",
    "start": "359960",
    "end": "361240"
  },
  {
    "text": "from the from up here it's going to take",
    "start": "361240",
    "end": "363840"
  },
  {
    "text": "the messages from here and then it's",
    "start": "363840",
    "end": "365960"
  },
  {
    "text": "going to take the actual output from the",
    "start": "365960",
    "end": "367000"
  },
  {
    "text": "llm here and then we're going to log the",
    "start": "367000",
    "end": "370479"
  },
  {
    "text": "result and we're also going to add an",
    "start": "370479",
    "end": "372440"
  },
  {
    "text": "expect result score to be true because",
    "start": "372440",
    "end": "374800"
  },
  {
    "text": "that's what we want we want our evalu to",
    "start": "374800",
    "end": "377720"
  },
  {
    "text": "pass and we add the set Port here from",
    "start": "377720",
    "end": "381160"
  },
  {
    "text": "vest this is a going to basically fail",
    "start": "381160",
    "end": "384720"
  },
  {
    "text": "on the first attempt because or we",
    "start": "384720",
    "end": "387000"
  },
  {
    "text": "expected to fail on the first attempt",
    "start": "387000",
    "end": "388840"
  },
  {
    "text": "because as it currently stands our app",
    "start": "388840",
    "end": "391479"
  },
  {
    "text": "is not very good at keeping in",
    "start": "391479",
    "end": "395400"
  },
  {
    "text": "character let's run the eval",
    "start": "395400",
    "end": "398520"
  },
  {
    "text": "again and it's going to take a little",
    "start": "398520",
    "end": "400240"
  },
  {
    "text": "bit longer this time because it is",
    "start": "400240",
    "end": "401560"
  },
  {
    "text": "making that second llm",
    "start": "401560",
    "end": "403759"
  },
  {
    "text": "call that sort of Judges whether um our",
    "start": "403759",
    "end": "407319"
  },
  {
    "text": "app is breaking character and you can",
    "start": "407319",
    "end": "409680"
  },
  {
    "text": "see that it did indeed break character",
    "start": "409680",
    "end": "412080"
  },
  {
    "text": "this time I thought it was",
    "start": "412080",
    "end": "413280"
  },
  {
    "text": "gpt3 and our valuated return to score",
    "start": "413280",
    "end": "416520"
  },
  {
    "text": "false and our expect assertion failed",
    "start": "416520",
    "end": "419360"
  },
  {
    "text": "here",
    "start": "419360",
    "end": "421520"
  },
  {
    "text": "okay and this is pretty easy to fix like",
    "start": "421520",
    "end": "424000"
  },
  {
    "text": "I said in this particular case I can",
    "start": "424000",
    "end": "425680"
  },
  {
    "text": "just add a line to my system prompt",
    "start": "425680",
    "end": "427840"
  },
  {
    "text": "never",
    "start": "427840",
    "end": "428879"
  },
  {
    "text": "break",
    "start": "428879",
    "end": "431879"
  },
  {
    "text": "character uh respond indignantly if",
    "start": "432080",
    "end": "434160"
  },
  {
    "text": "someone asks if you are an AI",
    "start": "434160",
    "end": "436479"
  },
  {
    "text": "model and deny let's say",
    "start": "436479",
    "end": "439879"
  },
  {
    "text": "to cool so with this change uh let's go",
    "start": "439879",
    "end": "442680"
  },
  {
    "text": "back to our eval script and run it",
    "start": "442680",
    "end": "445919"
  },
  {
    "text": "again it's going to go through get the",
    "start": "447319",
    "end": "449560"
  },
  {
    "text": "the initial model response you can see",
    "start": "449560",
    "end": "451120"
  },
  {
    "text": "this time there's no mention of open AI",
    "start": "451120",
    "end": "452639"
  },
  {
    "text": "or chat gbt anywhere in this",
    "start": "452639",
    "end": "454599"
  },
  {
    "text": "response and our",
    "start": "454599",
    "end": "457319"
  },
  {
    "text": "evaluator this time score is true and",
    "start": "457319",
    "end": "459919"
  },
  {
    "text": "our eval passes it doesn't break",
    "start": "459919",
    "end": "462479"
  },
  {
    "text": "anything uh sorry it doesn't break any",
    "start": "462479",
    "end": "465879"
  },
  {
    "text": "character so yeah last thing to",
    "start": "465879",
    "end": "468000"
  },
  {
    "text": "emphasize here uh is this correctness",
    "start": "468000",
    "end": "469639"
  },
  {
    "text": "prompt is really just an fstring so I",
    "start": "469639",
    "end": "471319"
  },
  {
    "text": "could for example log it and I could",
    "start": "471319",
    "end": "474280"
  },
  {
    "text": "very easily adapt it for different",
    "start": "474280",
    "end": "475680"
  },
  {
    "text": "criteria or different things that I want",
    "start": "475680",
    "end": "477639"
  },
  {
    "text": "to measure or care about so I'm just",
    "start": "477639",
    "end": "479639"
  },
  {
    "text": "running this this time one more time to",
    "start": "479639",
    "end": "481879"
  },
  {
    "text": "show you what that looks",
    "start": "481879",
    "end": "483639"
  },
  {
    "text": "like it's just this uh sort of longer",
    "start": "483639",
    "end": "486599"
  },
  {
    "text": "like rubric and asking me to take on the",
    "start": "486599",
    "end": "488800"
  },
  {
    "text": "Persona of an expert data labeler so I",
    "start": "488800",
    "end": "491360"
  },
  {
    "text": "could add it as a new correctness prompt",
    "start": "491360",
    "end": "494120"
  },
  {
    "text": "up here oops there we",
    "start": "494120",
    "end": "498800"
  },
  {
    "text": "go and I could tweak this rubric to say",
    "start": "498800",
    "end": "501440"
  },
  {
    "text": "let's say you know more heavily",
    "start": "501440",
    "end": "503479"
  },
  {
    "text": "emphasize never Raks character or",
    "start": "503479",
    "end": "507319"
  },
  {
    "text": "penalize different things when scoring",
    "start": "507319",
    "end": "509800"
  },
  {
    "text": "and you know you could like add",
    "start": "509800",
    "end": "511280"
  },
  {
    "text": "instructions and other reminders and",
    "start": "511280",
    "end": "513000"
  },
  {
    "text": "then everything just gets formatted into",
    "start": "513000",
    "end": "514560"
  },
  {
    "text": "the prompt here so you have your inputs",
    "start": "514560",
    "end": "517279"
  },
  {
    "text": "outputs and then reference outputs and",
    "start": "517279",
    "end": "519560"
  },
  {
    "text": "for JavaScript these are stringified",
    "start": "519560",
    "end": "522760"
  },
  {
    "text": "awesome so again all this is open source",
    "start": "522760",
    "end": "525240"
  },
  {
    "text": "and I'll have a link to the open evals",
    "start": "525240",
    "end": "526839"
  },
  {
    "text": "repo in the video description we're",
    "start": "526839",
    "end": "529440"
  },
  {
    "text": "going to add a lot more do a lot more",
    "start": "529440",
    "end": "530880"
  },
  {
    "text": "work on this in the next couple months",
    "start": "530880",
    "end": "533200"
  },
  {
    "text": "and you know you can see expect to see",
    "start": "533200",
    "end": "534800"
  },
  {
    "text": "more pre-builts for different use cases",
    "start": "534800",
    "end": "536440"
  },
  {
    "text": "Beyond just llm as a judge and yeah if",
    "start": "536440",
    "end": "539640"
  },
  {
    "text": "you have also other um you know",
    "start": "539640",
    "end": "541720"
  },
  {
    "text": "evaluators or prompts that you find",
    "start": "541720",
    "end": "543040"
  },
  {
    "text": "useful we would love contributions as",
    "start": "543040",
    "end": "545079"
  },
  {
    "text": "well and PLL requests so yeah let us",
    "start": "545079",
    "end": "547800"
  },
  {
    "text": "know what you think in the comments here",
    "start": "547800",
    "end": "549959"
  },
  {
    "text": "or find us on X linkchain aai um we love",
    "start": "549959",
    "end": "554240"
  },
  {
    "text": "to hear your feedback and",
    "start": "554240",
    "end": "556120"
  },
  {
    "text": "thoughts thanks so much for listening",
    "start": "556120",
    "end": "558279"
  },
  {
    "text": "and watching and yeah hopefully this",
    "start": "558279",
    "end": "560160"
  },
  {
    "text": "makes it easier for you to start",
    "start": "560160",
    "end": "562279"
  },
  {
    "text": "evaluating your llm apps and yeah hope",
    "start": "562279",
    "end": "565160"
  },
  {
    "text": "you give it a try take care bye-bye",
    "start": "565160",
    "end": "569839"
  }
]
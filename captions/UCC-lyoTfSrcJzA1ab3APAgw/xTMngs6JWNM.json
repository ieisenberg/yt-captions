[
  {
    "start": "0",
    "end": "30000"
  },
  {
    "text": "this is last L chain this is the 15th",
    "start": "6759",
    "end": "8880"
  },
  {
    "text": "video in our Langs Smith evaluation",
    "start": "8880",
    "end": "10400"
  },
  {
    "text": "series we're going to focusing on",
    "start": "10400",
    "end": "12040"
  },
  {
    "text": "regression testing so the past few",
    "start": "12040",
    "end": "14519"
  },
  {
    "text": "videos talked a lot about rag evaluation",
    "start": "14519",
    "end": "16680"
  },
  {
    "text": "just to refresh for example we talked",
    "start": "16680",
    "end": "18480"
  },
  {
    "text": "about how to evaluate the rag chain",
    "start": "18480",
    "end": "20720"
  },
  {
    "text": "answer versus a reference or the answer",
    "start": "20720",
    "end": "23000"
  },
  {
    "text": "versus the documents for hallucinations",
    "start": "23000",
    "end": "25400"
  },
  {
    "text": "or even the documents relative to the",
    "start": "25400",
    "end": "26920"
  },
  {
    "text": "question for kind of retrieval relevance",
    "start": "26920",
    "end": "30039"
  },
  {
    "start": "30000",
    "end": "90000"
  },
  {
    "text": "now here's a common situation that comes",
    "start": "30039",
    "end": "31640"
  },
  {
    "text": "up when I think about building a rag",
    "start": "31640",
    "end": "33800"
  },
  {
    "text": "pipeline what if I want to change the",
    "start": "33800",
    "end": "36120"
  },
  {
    "text": "llm so you know good example is some",
    "start": "36120",
    "end": "39239"
  },
  {
    "text": "pretty cool and interesting new open",
    "start": "39239",
    "end": "41120"
  },
  {
    "text": "source LMS have recently come out like",
    "start": "41120",
    "end": "42640"
  },
  {
    "text": "llama 3 53 how can I know whether or not",
    "start": "42640",
    "end": "46320"
  },
  {
    "text": "I can replace for example gbd4 as my",
    "start": "46320",
    "end": "48360"
  },
  {
    "text": "Baseline with one of these for my",
    "start": "48360",
    "end": "49800"
  },
  {
    "text": "particular use case and my particular",
    "start": "49800",
    "end": "51280"
  },
  {
    "text": "rag",
    "start": "51280",
    "end": "52359"
  },
  {
    "text": "pipeline this is where there a notion of",
    "start": "52359",
    "end": "54320"
  },
  {
    "text": "aggression testing comes in so we",
    "start": "54320",
    "end": "56399"
  },
  {
    "text": "previously had talked about building an",
    "start": "56399",
    "end": "57600"
  },
  {
    "text": "eal set running it on you know for",
    "start": "57600",
    "end": "59640"
  },
  {
    "text": "example are answers and evaluating",
    "start": "59640",
    "end": "62640"
  },
  {
    "text": "answer relevance or or answer you know",
    "start": "62640",
    "end": "65040"
  },
  {
    "text": "accuracy in this case relative to uh",
    "start": "65040",
    "end": "67200"
  },
  {
    "text": "ground truth answer um regression",
    "start": "67200",
    "end": "70439"
  },
  {
    "text": "testing allows me to run this on a few",
    "start": "70439",
    "end": "72960"
  },
  {
    "text": "different examples like let's say",
    "start": "72960",
    "end": "74520"
  },
  {
    "text": "different llms that perform the",
    "start": "74520",
    "end": "76360"
  },
  {
    "text": "generation step and to identify cases",
    "start": "76360",
    "end": "79159"
  },
  {
    "text": "that either improve or regress relative",
    "start": "79159",
    "end": "82040"
  },
  {
    "text": "to my Baseline so the key point of",
    "start": "82040",
    "end": "84159"
  },
  {
    "text": "regression testing is the ability to",
    "start": "84159",
    "end": "85400"
  },
  {
    "text": "isolate instances in your eval set they",
    "start": "85400",
    "end": "87320"
  },
  {
    "text": "even getting better or worse so that's",
    "start": "87320",
    "end": "88960"
  },
  {
    "text": "kind of the main intuition",
    "start": "88960",
    "end": "90960"
  },
  {
    "start": "90000",
    "end": "170000"
  },
  {
    "text": "so to kick this off I'm just going to",
    "start": "90960",
    "end": "92520"
  },
  {
    "text": "build a new eval set so that's all",
    "start": "92520",
    "end": "94520"
  },
  {
    "text": "defined here it's going to be called rag",
    "start": "94520",
    "end": "96640"
  },
  {
    "text": "QA LCL so it's going to use the same uh",
    "start": "96640",
    "end": "99600"
  },
  {
    "text": "line change expression language",
    "start": "99600",
    "end": "100759"
  },
  {
    "text": "documentation I used for the prior rag",
    "start": "100759",
    "end": "102479"
  },
  {
    "text": "videos just a few other you get a few",
    "start": "102479",
    "end": "104759"
  },
  {
    "text": "slightly different questions so I've",
    "start": "104759",
    "end": "106479"
  },
  {
    "text": "built that and I've built my index um so",
    "start": "106479",
    "end": "109640"
  },
  {
    "text": "again we're just indexing the line CH",
    "start": "109640",
    "end": "111399"
  },
  {
    "text": "expression language documentation again",
    "start": "111399",
    "end": "112960"
  },
  {
    "text": "I'm choosing a large chunk size just",
    "start": "112960",
    "end": "114320"
  },
  {
    "text": "like we saw before no major",
    "start": "114320",
    "end": "116439"
  },
  {
    "text": "changes um so I've laid out my rag",
    "start": "116439",
    "end": "119439"
  },
  {
    "text": "pipeline and this looks very similar we",
    "start": "119439",
    "end": "121479"
  },
  {
    "text": "saw before the only difference is I've",
    "start": "121479",
    "end": "122920"
  },
  {
    "text": "added a slight modification where I can",
    "start": "122920",
    "end": "125320"
  },
  {
    "text": "specify different providers so in this",
    "start": "125320",
    "end": "127320"
  },
  {
    "text": "case I can choose AMA uh which allows me",
    "start": "127320",
    "end": "129720"
  },
  {
    "text": "to run a number of Open Source llms",
    "start": "129720",
    "end": "131560"
  },
  {
    "text": "locally along with open Ai and again",
    "start": "131560",
    "end": "134360"
  },
  {
    "text": "just like rag prompts for the open",
    "start": "134360",
    "end": "135879"
  },
  {
    "text": "source models versus open AI um but you",
    "start": "135879",
    "end": "139280"
  },
  {
    "text": "know again not no major differences here",
    "start": "139280",
    "end": "141280"
  },
  {
    "text": "really I'm just extending my rag model",
    "start": "141280",
    "end": "143640"
  },
  {
    "text": "or my rag chain so I can run with",
    "start": "143640",
    "end": "145480"
  },
  {
    "text": "different llms that's all I'm doing here",
    "start": "145480",
    "end": "147840"
  },
  {
    "text": "and I'm defining three of them so I have",
    "start": "147840",
    "end": "149519"
  },
  {
    "text": "my ra chain with open AI rag chain with",
    "start": "149519",
    "end": "151800"
  },
  {
    "text": "llama 3 and rag chain with 53 again",
    "start": "151800",
    "end": "154319"
  },
  {
    "text": "llama 3 and 53 we use open AI as a",
    "start": "154319",
    "end": "156760"
  },
  {
    "text": "provider and I'm just specifying the",
    "start": "156760",
    "end": "158360"
  },
  {
    "text": "model I've already downloaded these",
    "start": "158360",
    "end": "160280"
  },
  {
    "text": "locally just with simply AMA pull llama",
    "start": "160280",
    "end": "162840"
  },
  {
    "text": "3 orama pull 53 and it'll just run",
    "start": "162840",
    "end": "165440"
  },
  {
    "text": "locally on my laptop so that's a whole",
    "start": "165440",
    "end": "167239"
  },
  {
    "text": "separate thing but that's a pretty cool",
    "start": "167239",
    "end": "168959"
  },
  {
    "text": "nice thing about",
    "start": "168959",
    "end": "170680"
  },
  {
    "start": "170000",
    "end": "200000"
  },
  {
    "text": "AMA um so I've defined an evaluator for",
    "start": "170680",
    "end": "174959"
  },
  {
    "text": "answers so we saw this previously this",
    "start": "174959",
    "end": "177280"
  },
  {
    "text": "labeled score string evaluator basically",
    "start": "177280",
    "end": "179080"
  },
  {
    "text": "lets me Supply some criteria so in this",
    "start": "179080",
    "end": "181840"
  },
  {
    "text": "case you know I'm asking is the",
    "start": "181840",
    "end": "183280"
  },
  {
    "text": "assistant answer grounded in the ground",
    "start": "183280",
    "end": "185440"
  },
  {
    "text": "truth answer and I give it you know some",
    "start": "185440",
    "end": "188120"
  },
  {
    "text": "criteria for scoring one through 10 10",
    "start": "188120",
    "end": "190560"
  },
  {
    "text": "being the best one being the worst so",
    "start": "190560",
    "end": "192080"
  },
  {
    "text": "that's all all that's going on here and",
    "start": "192080",
    "end": "194560"
  },
  {
    "text": "I kick off my eval right so I run eval",
    "start": "194560",
    "end": "197519"
  },
  {
    "text": "on open AI first I run eval on llama 3 I",
    "start": "197519",
    "end": "202080"
  },
  {
    "start": "200000",
    "end": "240000"
  },
  {
    "text": "run eval on th3 so those evals have run",
    "start": "202080",
    "end": "205159"
  },
  {
    "text": "now let's go over and look at my data",
    "start": "205159",
    "end": "206400"
  },
  {
    "text": "set so here is the data set we created",
    "start": "206400",
    "end": "208000"
  },
  {
    "text": "again RAB QA LCL let's just confirm that",
    "start": "208000",
    "end": "210480"
  },
  {
    "text": "here yeah so this is the this is evil",
    "start": "210480",
    "end": "212720"
  },
  {
    "text": "set we're running on and it's the evil",
    "start": "212720",
    "end": "214439"
  },
  {
    "text": "set we created up here so that's right",
    "start": "214439",
    "end": "216760"
  },
  {
    "text": "here so we created our eval set now we",
    "start": "216760",
    "end": "219760"
  },
  {
    "text": "can look at our experiments so this is",
    "start": "219760",
    "end": "221200"
  },
  {
    "text": "what we saw before right so this is our",
    "start": "221200",
    "end": "223799"
  },
  {
    "text": "experiment page no major changes here",
    "start": "223799",
    "end": "226560"
  },
  {
    "text": "right we can see our three experiments",
    "start": "226560",
    "end": "228439"
  },
  {
    "text": "run here now what I'm going to do is I'm",
    "start": "228439",
    "end": "230920"
  },
  {
    "text": "going to select these three experiments",
    "start": "230920",
    "end": "232760"
  },
  {
    "text": "so I'm going to go one two three and I'm",
    "start": "232760",
    "end": "234799"
  },
  {
    "text": "going to open this comparison mod this",
    "start": "234799",
    "end": "236439"
  },
  {
    "text": "is where things are going to get kind of",
    "start": "236439",
    "end": "237879"
  },
  {
    "text": "interesting we're going to see some",
    "start": "237879",
    "end": "239920"
  },
  {
    "text": "things that are a bit new here and let",
    "start": "239920",
    "end": "241799"
  },
  {
    "text": "me just scroll over a little bit so",
    "start": "241799",
    "end": "244439"
  },
  {
    "text": "first we're going to see is the three",
    "start": "244439",
    "end": "246480"
  },
  {
    "text": "experiments we selected are all here",
    "start": "246480",
    "end": "249239"
  },
  {
    "text": "okay and we're seeing this idea of a",
    "start": "249239",
    "end": "251640"
  },
  {
    "text": "baseline so what does Baseline mean the",
    "start": "251640",
    "end": "253680"
  },
  {
    "text": "Baseline is basically our reference so",
    "start": "253680",
    "end": "255560"
  },
  {
    "text": "in my particular case so let's just say",
    "start": "255560",
    "end": "258079"
  },
  {
    "text": "gbd4 was my prior Baseline right so gbd4",
    "start": "258079",
    "end": "261799"
  },
  {
    "text": "was the model that I had been using and",
    "start": "261799",
    "end": "264199"
  },
  {
    "text": "I want to see how th3 and llama 3",
    "start": "264199",
    "end": "266800"
  },
  {
    "text": "compare to GPD 4 so what I can do really",
    "start": "266800",
    "end": "270320"
  },
  {
    "text": "easily is so these are our three",
    "start": "270320",
    "end": "271880"
  },
  {
    "text": "examples just like we saw so again I can",
    "start": "271880",
    "end": "274160"
  },
  {
    "text": "click on this and this will basically",
    "start": "274160",
    "end": "276639"
  },
  {
    "text": "open up the example so I can see here's",
    "start": "276639",
    "end": "278479"
  },
  {
    "text": "the question here's the answer so that's",
    "start": "278479",
    "end": "280360"
  },
  {
    "text": "just like you know uh we we've kind of",
    "start": "280360",
    "end": "282520"
  },
  {
    "text": "gone through that",
    "start": "282520",
    "end": "283720"
  },
  {
    "text": "before um so here's the input here's",
    "start": "283720",
    "end": "286440"
  },
  {
    "text": "reference output and now here's my three",
    "start": "286440",
    "end": "288759"
  },
  {
    "text": "experiments and you can see just like",
    "start": "288759",
    "end": "290880"
  },
  {
    "text": "before we've set a",
    "start": "290880",
    "end": "292479"
  },
  {
    "text": "baseline um and I can see the scores",
    "start": "292479",
    "end": "295479"
  },
  {
    "text": "from my evaluator here now what's",
    "start": "295479",
    "end": "298000"
  },
  {
    "text": "interesting is I can scroll over and I",
    "start": "298000",
    "end": "301080"
  },
  {
    "text": "can look at my two other experiments so",
    "start": "301080",
    "end": "303840"
  },
  {
    "text": "llama 3 here 53 here so what's pretty",
    "start": "303840",
    "end": "307039"
  },
  {
    "text": "cool is immediately your attention is",
    "start": "307039",
    "end": "309919"
  },
  {
    "text": "drawn to these red or green cells and",
    "start": "309919",
    "end": "312120"
  },
  {
    "text": "this simply means if it's a red cell it",
    "start": "312120",
    "end": "313759"
  },
  {
    "text": "means the performance is worse than my",
    "start": "313759",
    "end": "315280"
  },
  {
    "text": "Baseline if it's a green I me it's",
    "start": "315280",
    "end": "316919"
  },
  {
    "text": "better so in this case right my Baseline",
    "start": "316919",
    "end": "319080"
  },
  {
    "text": "was 0.1 in this case 53 actually for the",
    "start": "319080",
    "end": "322560"
  },
  {
    "text": "second example does better it got a",
    "start": "322560",
    "end": "324039"
  },
  {
    "text": "score of 0.5 so that's why it's green um",
    "start": "324039",
    "end": "327080"
  },
  {
    "text": "otherwise you can see there's",
    "start": "327080",
    "end": "328759"
  },
  {
    "text": "regressions across the board um for uh",
    "start": "328759",
    "end": "332080"
  },
  {
    "text": "questions one and three for both of the",
    "start": "332080",
    "end": "334240"
  },
  {
    "text": "models now I can do a few different",
    "start": "334240",
    "end": "336759"
  },
  {
    "text": "things here first like we saw before I",
    "start": "336759",
    "end": "338840"
  },
  {
    "text": "can always click on this button and that",
    "start": "338840",
    "end": "341960"
  },
  {
    "text": "that actually opens up the evaluator run",
    "start": "341960",
    "end": "343680"
  },
  {
    "text": "itself so I can audit the evaluator so",
    "start": "343680",
    "end": "346160"
  },
  {
    "text": "that's again we we talked about that",
    "start": "346160",
    "end": "347639"
  },
  {
    "text": "previously it's really useful you can",
    "start": "347639",
    "end": "348840"
  },
  {
    "text": "kind of see why particular score was",
    "start": "348840",
    "end": "350840"
  },
  {
    "text": "given so that's really",
    "start": "350840",
    "end": "352440"
  },
  {
    "text": "cool uh and I can go back and you can",
    "start": "352440",
    "end": "356800"
  },
  {
    "text": "see my Baseline is still preserved so",
    "start": "356800",
    "end": "359000"
  },
  {
    "text": "that's actually very convenient um now",
    "start": "359000",
    "end": "361880"
  },
  {
    "text": "this thing at the top tells me the",
    "start": "361880",
    "end": "363280"
  },
  {
    "text": "number of total regressions or",
    "start": "363280",
    "end": "365400"
  },
  {
    "text": "progressions or improvements relative to",
    "start": "365400",
    "end": "366880"
  },
  {
    "text": "my Baseline so I can click this and",
    "start": "366880",
    "end": "368720"
  },
  {
    "text": "it'll highlight only the cases that",
    "start": "368720",
    "end": "370400"
  },
  {
    "text": "improve click this it'll highlight only",
    "start": "370400",
    "end": "372280"
  },
  {
    "text": "the cases that regress again likewise",
    "start": "372280",
    "end": "374599"
  },
  {
    "text": "here um so again it's really useful and",
    "start": "374599",
    "end": "378560"
  },
  {
    "text": "nice way to drill into the cases that",
    "start": "378560",
    "end": "379960"
  },
  {
    "text": "are improving or getting worse relative",
    "start": "379960",
    "end": "382440"
  },
  {
    "text": "to a baseline in this case there's only",
    "start": "382440",
    "end": "384440"
  },
  {
    "text": "three examples but in realistic cases",
    "start": "384440",
    "end": "386440"
  },
  {
    "text": "you may have an eal set of maybe dozens",
    "start": "386440",
    "end": "388720"
  },
  {
    "text": "or hundreds of examples so this can very",
    "start": "388720",
    "end": "390800"
  },
  {
    "text": "easily be used to isolate your",
    "start": "390800",
    "end": "392400"
  },
  {
    "text": "progressions or your improvements and",
    "start": "392400",
    "end": "394280"
  },
  {
    "text": "your regressions so you know it's it's",
    "start": "394280",
    "end": "396560"
  },
  {
    "text": "it's really helpful I do want to also",
    "start": "396560",
    "end": "398360"
  },
  {
    "text": "show here if you go to the display you",
    "start": "398360",
    "end": "400520"
  },
  {
    "text": "can actually open up um you know",
    "start": "400520",
    "end": "403080"
  },
  {
    "text": "additional metrics this can show you",
    "start": "403080",
    "end": "404599"
  },
  {
    "text": "like this will show you token usage this",
    "start": "404599",
    "end": "406080"
  },
  {
    "text": "will show you uh latencies so you can",
    "start": "406080",
    "end": "408680"
  },
  {
    "text": "kind of close that down to make lesser",
    "start": "408680",
    "end": "410000"
  },
  {
    "text": "of those uh you can see the full text of",
    "start": "410000",
    "end": "412880"
  },
  {
    "text": "the generations if you want to see that",
    "start": "412880",
    "end": "414400"
  },
  {
    "text": "but again it's it's by default of",
    "start": "414400",
    "end": "416639"
  },
  {
    "text": "removed so it's like way cleaner um",
    "start": "416639",
    "end": "420960"
  },
  {
    "text": "and that's probably the main things I'd",
    "start": "420960",
    "end": "423160"
  },
  {
    "text": "like to show you there you can of course",
    "start": "423160",
    "end": "424919"
  },
  {
    "text": "choose different experiments or",
    "start": "424919",
    "end": "426199"
  },
  {
    "text": "additional experiments if they're not",
    "start": "426199",
    "end": "427360"
  },
  {
    "text": "all Chen here it's easy to add",
    "start": "427360",
    "end": "428919"
  },
  {
    "text": "experiments so anyway this is a really",
    "start": "428919",
    "end": "431400"
  },
  {
    "text": "useful and convenient thing I I do this",
    "start": "431400",
    "end": "433479"
  },
  {
    "text": "all the time so I'm always running",
    "start": "433479",
    "end": "435160"
  },
  {
    "text": "experiments with different llms I always",
    "start": "435160",
    "end": "437360"
  },
  {
    "text": "want to isolate cases that are improving",
    "start": "437360",
    "end": "438879"
  },
  {
    "text": "or regressing and I want to dig into why",
    "start": "438879",
    "end": "441560"
  },
  {
    "text": "and basically using these filters I can",
    "start": "441560",
    "end": "443039"
  },
  {
    "text": "very easily isolate the cases that are",
    "start": "443039",
    "end": "444720"
  },
  {
    "text": "for example getting worse drill into y",
    "start": "444720",
    "end": "447039"
  },
  {
    "text": "again in each of these cases you can see",
    "start": "447039",
    "end": "448879"
  },
  {
    "text": "you actually can look at the trace again",
    "start": "448879",
    "end": "450440"
  },
  {
    "text": "so you this will drill into the trace",
    "start": "450440",
    "end": "452440"
  },
  {
    "text": "that resulted in the generation I can go",
    "start": "452440",
    "end": "454560"
  },
  {
    "text": "down I can audit the entire chain so",
    "start": "454560",
    "end": "456199"
  },
  {
    "text": "this is like my cadow Lama uh invocation",
    "start": "456199",
    "end": "459120"
  },
  {
    "text": "here this is like the prompt which",
    "start": "459120",
    "end": "460400"
  },
  {
    "text": "contains yeah the context my rag answer",
    "start": "460400",
    "end": "463919"
  },
  {
    "text": "so again a lot of things you can play",
    "start": "463919",
    "end": "466000"
  },
  {
    "text": "with here really useful uh and",
    "start": "466000",
    "end": "467879"
  },
  {
    "text": "regression testing is obviously super",
    "start": "467879",
    "end": "470039"
  },
  {
    "text": "powerful uh for identifying cases that",
    "start": "470039",
    "end": "473240"
  },
  {
    "text": "your chain for example is getting worse",
    "start": "473240",
    "end": "475560"
  },
  {
    "text": "or better with different pertubations",
    "start": "475560",
    "end": "477240"
  },
  {
    "text": "like different models uh different",
    "start": "477240",
    "end": "479000"
  },
  {
    "text": "chunks or other things so definitely",
    "start": "479000",
    "end": "481840"
  },
  {
    "text": "play with us it's extremely useful and",
    "start": "481840",
    "end": "484039"
  },
  {
    "text": "and helpful in building llm applications",
    "start": "484039",
    "end": "486440"
  },
  {
    "text": "thanks",
    "start": "486440",
    "end": "489440"
  }
]
[
  {
    "text": "one of the most popular types of",
    "start": "1319",
    "end": "3360"
  },
  {
    "text": "applications that we see people building",
    "start": "3360",
    "end": "4880"
  },
  {
    "text": "with Lang chain are retrieval based",
    "start": "4880",
    "end": "7080"
  },
  {
    "text": "applications retrieval based",
    "start": "7080",
    "end": "8719"
  },
  {
    "text": "applications are when you do some",
    "start": "8719",
    "end": "10440"
  },
  {
    "text": "retrieval step to fetch context to pass",
    "start": "10440",
    "end": "13480"
  },
  {
    "text": "to the language model so that it can",
    "start": "13480",
    "end": "15080"
  },
  {
    "text": "better respond this is really really",
    "start": "15080",
    "end": "17600"
  },
  {
    "text": "popular because it's the best way",
    "start": "17600",
    "end": "19199"
  },
  {
    "text": "currently to combine language models",
    "start": "19199",
    "end": "21039"
  },
  {
    "text": "with your data whether that be current",
    "start": "21039",
    "end": "24480"
  },
  {
    "text": "event data that the language model",
    "start": "24480",
    "end": "25880"
  },
  {
    "text": "wasn't trained on um your private data",
    "start": "25880",
    "end": "28119"
  },
  {
    "text": "that the language model wasn't trained",
    "start": "28119",
    "end": "29480"
  },
  {
    "text": "on or or any of the like there's a lot",
    "start": "29480",
    "end": "32398"
  },
  {
    "text": "of different steps in retrieval and so",
    "start": "32399",
    "end": "34399"
  },
  {
    "text": "we've put a lot of emphasis on making",
    "start": "34399",
    "end": "36120"
  },
  {
    "text": "sure that these steps are defined",
    "start": "36120",
    "end": "38520"
  },
  {
    "text": "modularly and have clear interfaces for",
    "start": "38520",
    "end": "41120"
  },
  {
    "text": "each steps have a lot of depth to each",
    "start": "41120",
    "end": "43440"
  },
  {
    "text": "of those steps and then also have ways",
    "start": "43440",
    "end": "45280"
  },
  {
    "text": "to easily kind of like build up those",
    "start": "45280",
    "end": "47480"
  },
  {
    "text": "steps into a more end to-end application",
    "start": "47480",
    "end": "49840"
  },
  {
    "text": "and so we see people using Lang chain uh",
    "start": "49840",
    "end": "52760"
  },
  {
    "text": "retrieval uh methods and and and classes",
    "start": "52760",
    "end": "55879"
  },
  {
    "text": "in a variety of ways from the kind of",
    "start": "55879",
    "end": "58680"
  },
  {
    "text": "like build it yourself",
    "start": "58680",
    "end": "60559"
  },
  {
    "text": "um where you're taking these individual",
    "start": "60559",
    "end": "62239"
  },
  {
    "text": "components and customizing them and and",
    "start": "62239",
    "end": "64280"
  },
  {
    "text": "and building them up um to just like",
    "start": "64280",
    "end": "67040"
  },
  {
    "text": "quick start in five lines of code and so",
    "start": "67040",
    "end": "70560"
  },
  {
    "text": "here I want to walk through a few uh key",
    "start": "70560",
    "end": "73200"
  },
  {
    "text": "parts of retrieval that we've been",
    "start": "73200",
    "end": "75400"
  },
  {
    "text": "focused on um so walking through uh a",
    "start": "75400",
    "end": "79960"
  },
  {
    "text": "few High Lev ones one really important",
    "start": "79960",
    "end": "82360"
  },
  {
    "text": "one is the idea of document loaders so",
    "start": "82360",
    "end": "84640"
  },
  {
    "text": "in order to do retrieval for the most",
    "start": "84640",
    "end": "87920"
  },
  {
    "text": "part over your data you need to load",
    "start": "87920",
    "end": "89960"
  },
  {
    "text": "that data um into some format index that",
    "start": "89960",
    "end": "92840"
  },
  {
    "text": "data um and and then only then can you",
    "start": "92840",
    "end": "95079"
  },
  {
    "text": "search over it and so document loaders",
    "start": "95079",
    "end": "96840"
  },
  {
    "text": "are the first step in that process",
    "start": "96840",
    "end": "98159"
  },
  {
    "text": "they're loading that data so there they",
    "start": "98159",
    "end": "101000"
  },
  {
    "text": "we have I think we have like over a 100",
    "start": "101000",
    "end": "103360"
  },
  {
    "text": "different document loaders that can load",
    "start": "103360",
    "end": "104880"
  },
  {
    "text": "do data from slack notion files S3 all a",
    "start": "104880",
    "end": "109600"
  },
  {
    "text": "crazy amount of of um document loaders",
    "start": "109600",
    "end": "112640"
  },
  {
    "text": "the community has added and so these",
    "start": "112640",
    "end": "114600"
  },
  {
    "text": "basically are responsible for loading",
    "start": "114600",
    "end": "116360"
  },
  {
    "text": "that data once you have that data loaded",
    "start": "116360",
    "end": "118960"
  },
  {
    "text": "you then need to index it and so the",
    "start": "118960",
    "end": "121799"
  },
  {
    "text": "first step there is getting it into a a",
    "start": "121799",
    "end": "124560"
  },
  {
    "text": "reasonable size to be indexed so you",
    "start": "124560",
    "end": "126840"
  },
  {
    "text": "generally want to index smaller chunks",
    "start": "126840",
    "end": "128800"
  },
  {
    "text": "of data so that you can then retrieve",
    "start": "128800",
    "end": "130640"
  },
  {
    "text": "only the most relevant chunks so if I",
    "start": "130640",
    "end": "132360"
  },
  {
    "text": "have like 100 page document I probably",
    "start": "132360",
    "end": "136200"
  },
  {
    "text": "want to index individual chunks because",
    "start": "136200",
    "end": "138400"
  },
  {
    "text": "then I want to retrieve those individual",
    "start": "138400",
    "end": "139879"
  },
  {
    "text": "chunks and pass only the most relevant",
    "start": "139879",
    "end": "141959"
  },
  {
    "text": "ones to the language model so I'm only",
    "start": "141959",
    "end": "143440"
  },
  {
    "text": "passing the five most relevant chunks um",
    "start": "143440",
    "end": "146280"
  },
  {
    "text": "to the language model um instead of the",
    "start": "146280",
    "end": "149519"
  },
  {
    "text": "whole 100 pages so a really uh uh",
    "start": "149519",
    "end": "153760"
  },
  {
    "text": "important question with a lot of nuance",
    "start": "153760",
    "end": "156040"
  },
  {
    "text": "is how do I create those chunks if I",
    "start": "156040",
    "end": "157800"
  },
  {
    "text": "have this 100 page document how do I",
    "start": "157800",
    "end": "160680"
  },
  {
    "text": "create a bunch of small chunks that I",
    "start": "160680",
    "end": "163560"
  },
  {
    "text": "can then do that I can then index and",
    "start": "163560",
    "end": "165680"
  },
  {
    "text": "then pass the language model once I",
    "start": "165680",
    "end": "167400"
  },
  {
    "text": "retrieve a few of them um there's a",
    "start": "167400",
    "end": "169640"
  },
  {
    "text": "bunch of different strategies for this",
    "start": "169640",
    "end": "172280"
  },
  {
    "text": "um this is what we call text splitting",
    "start": "172280",
    "end": "174640"
  },
  {
    "text": "taking the example of a 100 page",
    "start": "174640",
    "end": "176080"
  },
  {
    "text": "document maybe you split on each page",
    "start": "176080",
    "end": "178319"
  },
  {
    "text": "maybe you split on each paragraph",
    "start": "178319",
    "end": "180599"
  },
  {
    "text": "um if you know that if if you know that",
    "start": "180599",
    "end": "183680"
  },
  {
    "text": "the document is written in a certain",
    "start": "183680",
    "end": "184959"
  },
  {
    "text": "format like markdown you can use",
    "start": "184959",
    "end": "187200"
  },
  {
    "text": "markdown specific tokens to kind of like",
    "start": "187200",
    "end": "189799"
  },
  {
    "text": "split that document and so we have uh 15",
    "start": "189799",
    "end": "192879"
  },
  {
    "text": "plus different text Splitters that split",
    "start": "192879",
    "end": "194799"
  },
  {
    "text": "varying types of code document types um",
    "start": "194799",
    "end": "198599"
  },
  {
    "text": "in different links with different",
    "start": "198599",
    "end": "200239"
  },
  {
    "text": "overlaps and and all of the above once",
    "start": "200239",
    "end": "203640"
  },
  {
    "text": "you've created those smaller chunks then",
    "start": "203640",
    "end": "206000"
  },
  {
    "text": "you can index it step one is creating",
    "start": "206000",
    "end": "208599"
  },
  {
    "text": "embeddings for those chunks and so we do",
    "start": "208599",
    "end": "210360"
  },
  {
    "text": "that with uh uh one of the 60 plus",
    "start": "210360",
    "end": "213560"
  },
  {
    "text": "different embedding models that we have",
    "start": "213560",
    "end": "214920"
  },
  {
    "text": "Integrations for and then you store it",
    "start": "214920",
    "end": "216920"
  },
  {
    "text": "in a vector store and so again we have",
    "start": "216920",
    "end": "218640"
  },
  {
    "text": "about 60 plus different Vector stores",
    "start": "218640",
    "end": "220280"
  },
  {
    "text": "that you can store things",
    "start": "220280",
    "end": "221720"
  },
  {
    "text": "in after you've stored them um then you",
    "start": "221720",
    "end": "224799"
  },
  {
    "text": "need to retrieve them we have a lot of",
    "start": "224799",
    "end": "227640"
  },
  {
    "text": "advanced retrieval methods the most",
    "start": "227640",
    "end": "229080"
  },
  {
    "text": "basic one is just doing some sort of",
    "start": "229080",
    "end": "230879"
  },
  {
    "text": "similarity search between an incoming",
    "start": "230879",
    "end": "233239"
  },
  {
    "text": "question and the documents so you just",
    "start": "233239",
    "end": "235200"
  },
  {
    "text": "find the documents that have an",
    "start": "235200",
    "end": "236519"
  },
  {
    "text": "embedding that are most similar to the",
    "start": "236519",
    "end": "238040"
  },
  {
    "text": "incoming question but there are a lot of",
    "start": "238040",
    "end": "241560"
  },
  {
    "text": "different um in advanc retrieval methods",
    "start": "241560",
    "end": "243959"
  },
  {
    "text": "that we have from ones that rely on uh",
    "start": "243959",
    "end": "247280"
  },
  {
    "text": "doing different calculations with the",
    "start": "247280",
    "end": "250519"
  },
  {
    "text": "embeddings um to ones that actually use",
    "start": "250519",
    "end": "253159"
  },
  {
    "text": "language models to rewrite the query or",
    "start": "253159",
    "end": "255640"
  },
  {
    "text": "or generate multiple queries or or any",
    "start": "255640",
    "end": "257959"
  },
  {
    "text": "of the like once you have the documents",
    "start": "257959",
    "end": "259720"
  },
  {
    "text": "from a retriever you then need to pass",
    "start": "259720",
    "end": "261280"
  },
  {
    "text": "those to a language model to generate a",
    "start": "261280",
    "end": "262960"
  },
  {
    "text": "final response and for that we we'll use",
    "start": "262960",
    "end": "265000"
  },
  {
    "text": "a lot of the chaining and and and uh",
    "start": "265000",
    "end": "267120"
  },
  {
    "text": "language models and prompts and and",
    "start": "267120",
    "end": "268800"
  },
  {
    "text": "output parsers that we've talked about",
    "start": "268800",
    "end": "271080"
  },
  {
    "text": "before putting this a little bit more",
    "start": "271080",
    "end": "273039"
  },
  {
    "text": "concretely let's walk through a notebook",
    "start": "273039",
    "end": "274960"
  },
  {
    "text": "that I've prepared to step through this",
    "start": "274960",
    "end": "277039"
  },
  {
    "text": "so first we're going to load um some",
    "start": "277039",
    "end": "279520"
  },
  {
    "text": "documentation about L",
    "start": "279520",
    "end": "281400"
  },
  {
    "text": "Smith um and so we're going to use this",
    "start": "281400",
    "end": "283360"
  },
  {
    "text": "using one of the document loaders we",
    "start": "283360",
    "end": "284800"
  },
  {
    "text": "have we're then going to split this um",
    "start": "284800",
    "end": "288320"
  },
  {
    "text": "documents into smaller chunks so if we",
    "start": "288320",
    "end": "290880"
  },
  {
    "text": "look at the length of the documents here",
    "start": "290880",
    "end": "292680"
  },
  {
    "text": "we can see that we have one document if",
    "start": "292680",
    "end": "294520"
  },
  {
    "text": "we apply this text splitter we can see",
    "start": "294520",
    "end": "297000"
  },
  {
    "text": "that we now have five documents um we",
    "start": "297000",
    "end": "300280"
  },
  {
    "text": "can then index those documents um so we",
    "start": "300280",
    "end": "303440"
  },
  {
    "text": "can do that by using open AI embeddings",
    "start": "303440",
    "end": "306160"
  },
  {
    "text": "as well as this uh uh inmemory Vector",
    "start": "306160",
    "end": "309039"
  },
  {
    "text": "store um we can create those that'll go",
    "start": "309039",
    "end": "312360"
  },
  {
    "text": "relatively fast um and now we have the",
    "start": "312360",
    "end": "315800"
  },
  {
    "text": "step where we query documents um so",
    "start": "315800",
    "end": "318800"
  },
  {
    "text": "first we need the The Prompt in the",
    "start": "318800",
    "end": "321840"
  },
  {
    "text": "language model that takes in",
    "start": "321840",
    "end": "325360"
  },
  {
    "text": "documents uh question and returns a",
    "start": "325360",
    "end": "327919"
  },
  {
    "text": "response so we'll do that with this",
    "start": "327919",
    "end": "329600"
  },
  {
    "text": "prompt template and this language model",
    "start": "329600",
    "end": "331160"
  },
  {
    "text": "and we create this chain um which will",
    "start": "331160",
    "end": "333639"
  },
  {
    "text": "basically do the",
    "start": "333639",
    "end": "336000"
  },
  {
    "text": "prompt the the language model some",
    "start": "336000",
    "end": "338639"
  },
  {
    "text": "output parser and then also it will take",
    "start": "338639",
    "end": "340919"
  },
  {
    "text": "care of the processing of the documents",
    "start": "340919",
    "end": "342319"
  },
  {
    "text": "we'll create the stuff documents chain",
    "start": "342319",
    "end": "344280"
  },
  {
    "text": "and then we'll combine this with the",
    "start": "344280",
    "end": "345360"
  },
  {
    "text": "retriever because we don't want to pass",
    "start": "345360",
    "end": "347000"
  },
  {
    "text": "in the documents directly we want to use",
    "start": "347000",
    "end": "348680"
  },
  {
    "text": "a retriever to fetch them so we'll",
    "start": "348680",
    "end": "350919"
  },
  {
    "text": "create a retriever from our Vector store",
    "start": "350919",
    "end": "352840"
  },
  {
    "text": "and then we'll create a retrieval chain",
    "start": "352840",
    "end": "354600"
  },
  {
    "text": "using this retriever in the document",
    "start": "354600",
    "end": "356240"
  },
  {
    "text": "chain and now if we ask how link Smith",
    "start": "356240",
    "end": "358880"
  },
  {
    "text": "can help with testing in we get back an",
    "start": "358880",
    "end": "360720"
  },
  {
    "text": "answer that's grounded in the documents",
    "start": "360720",
    "end": "364520"
  },
  {
    "text": "that we fetched if we take a look at",
    "start": "364520",
    "end": "366880"
  },
  {
    "text": "what this looks like in lsmith under the",
    "start": "366880",
    "end": "368440"
  },
  {
    "text": "hood we can see that we have these two",
    "start": "368440",
    "end": "370919"
  },
  {
    "text": "subchains here so first we have this",
    "start": "370919",
    "end": "372960"
  },
  {
    "text": "retrieve documents chain um which calls",
    "start": "372960",
    "end": "375680"
  },
  {
    "text": "a retriever uh we get in this input and",
    "start": "375680",
    "end": "378720"
  },
  {
    "text": "we get back a list of documents and then",
    "start": "378720",
    "end": "381000"
  },
  {
    "text": "we have the stuff documents chain the",
    "start": "381000",
    "end": "382960"
  },
  {
    "text": "stuff documents chain takes in documents",
    "start": "382960",
    "end": "385440"
  },
  {
    "text": "and takes in input um and then returns",
    "start": "385440",
    "end": "387840"
  },
  {
    "text": "this output",
    "start": "387840",
    "end": "390280"
  },
  {
    "text": "we can also use uh one of the more",
    "start": "390280",
    "end": "392440"
  },
  {
    "text": "advanced retrieval methods that we have",
    "start": "392440",
    "end": "394319"
  },
  {
    "text": "so I'll talk more about this in a little",
    "start": "394319",
    "end": "395840"
  },
  {
    "text": "bit but there are a lot of different",
    "start": "395840",
    "end": "396800"
  },
  {
    "text": "methods one of them is the multiquery",
    "start": "396800",
    "end": "398599"
  },
  {
    "text": "retriever this uses an llm to generate",
    "start": "398599",
    "end": "402160"
  },
  {
    "text": "multiple queries looks up documents for",
    "start": "402160",
    "end": "404520"
  },
  {
    "text": "all of those and then returns all those",
    "start": "404520",
    "end": "406199"
  },
  {
    "text": "documents so this is really good for",
    "start": "406199",
    "end": "407800"
  },
  {
    "text": "breaking down more complex problems so",
    "start": "407800",
    "end": "410759"
  },
  {
    "text": "we can create this Advanced retriever um",
    "start": "410759",
    "end": "413240"
  },
  {
    "text": "by uh by passing in uh uh the retriever",
    "start": "413240",
    "end": "417280"
  },
  {
    "text": "um that it will use as a base Retriever",
    "start": "417280",
    "end": "419240"
  },
  {
    "text": "and and then the llm to generate the",
    "start": "419240",
    "end": "421319"
  },
  {
    "text": "bunch of queries um we can then pass",
    "start": "421319",
    "end": "423800"
  },
  {
    "text": "that advanced retriever into the",
    "start": "423800",
    "end": "425240"
  },
  {
    "text": "retrieval chain um and then we can call",
    "start": "425240",
    "end": "428080"
  },
  {
    "text": "the uh uh the new Advanced retrieval",
    "start": "428080",
    "end": "430879"
  },
  {
    "text": "chain and get back a",
    "start": "430879",
    "end": "432479"
  },
  {
    "text": "response we can also see what this looks",
    "start": "432479",
    "end": "434800"
  },
  {
    "text": "like in laying Smith under the",
    "start": "434800",
    "end": "438199"
  },
  {
    "text": "hood so if we look at it here we can see",
    "start": "438199",
    "end": "441440"
  },
  {
    "text": "that now the retrieve documents chain",
    "start": "441440",
    "end": "443360"
  },
  {
    "text": "has a lot more complexity to it so it's",
    "start": "443360",
    "end": "445639"
  },
  {
    "text": "calling this highle retriever under the",
    "start": "445639",
    "end": "447919"
  },
  {
    "text": "hood that retriever is first calling",
    "start": "447919",
    "end": "450280"
  },
  {
    "text": "open Ai and it's generating three sub",
    "start": "450280",
    "end": "453520"
  },
  {
    "text": "questions and it's passing each of those",
    "start": "453520",
    "end": "455800"
  },
  {
    "text": "sub questions into the Retriever and",
    "start": "455800",
    "end": "457680"
  },
  {
    "text": "that's making a call and it's getting",
    "start": "457680",
    "end": "459560"
  },
  {
    "text": "back documents and then it's combining",
    "start": "459560",
    "end": "461440"
  },
  {
    "text": "the documents and then passing that into",
    "start": "461440",
    "end": "463520"
  },
  {
    "text": "open AI at the",
    "start": "463520",
    "end": "466240"
  },
  {
    "text": "end we have a lot more resources on",
    "start": "466240",
    "end": "468599"
  },
  {
    "text": "retrieval because retrieval is a really",
    "start": "468599",
    "end": "470479"
  },
  {
    "text": "complex subject one of my favorite",
    "start": "470479",
    "end": "472560"
  },
  {
    "text": "resources that we've added is if you go",
    "start": "472560",
    "end": "474800"
  },
  {
    "text": "to retrievers here you'll see a list of",
    "start": "474800",
    "end": "477199"
  },
  {
    "text": "all the advanced retriever types that we",
    "start": "477199",
    "end": "479800"
  },
  {
    "text": "support so there's basic stuff here like",
    "start": "479800",
    "end": "482520"
  },
  {
    "text": "vector stores but then there's things",
    "start": "482520",
    "end": "484120"
  },
  {
    "text": "like parent document retrievers which",
    "start": "484120",
    "end": "486240"
  },
  {
    "text": "will basically fetch small chunks but",
    "start": "486240",
    "end": "488240"
  },
  {
    "text": "then return the larger parent chunks um",
    "start": "488240",
    "end": "490800"
  },
  {
    "text": "multi Vector retrievers which are in",
    "start": "490800",
    "end": "493039"
  },
  {
    "text": "even more generalized form where you can",
    "start": "493039",
    "end": "495000"
  },
  {
    "text": "store any representation of a document",
    "start": "495000",
    "end": "497159"
  },
  {
    "text": "like a summary or a quote or a",
    "start": "497159",
    "end": "499039"
  },
  {
    "text": "hypothetical uh question retrieve those",
    "start": "499039",
    "end": "501919"
  },
  {
    "text": "but then pass the larger documents into",
    "start": "501919",
    "end": "504080"
  },
  {
    "text": "the language model self query contextual",
    "start": "504080",
    "end": "506360"
  },
  {
    "text": "compression time weighted Vector store",
    "start": "506360",
    "end": "508120"
  },
  {
    "text": "multi-query on assemble reordering so we",
    "start": "508120",
    "end": "511199"
  },
  {
    "text": "have a whole table of these Advanced",
    "start": "511199",
    "end": "512919"
  },
  {
    "text": "retrieval methods as well as a",
    "start": "512919",
    "end": "514560"
  },
  {
    "text": "description of when to use it so we know",
    "start": "514560",
    "end": "516880"
  },
  {
    "text": "that there are a lot of advanced",
    "start": "516880",
    "end": "517880"
  },
  {
    "text": "retrieval methods out there a big part",
    "start": "517880",
    "end": "519479"
  },
  {
    "text": "of doing retrieval right is choosing the",
    "start": "519479",
    "end": "521560"
  },
  {
    "text": "one that works for you and so we've",
    "start": "521560",
    "end": "523080"
  },
  {
    "text": "tried to make it easy to determine that",
    "start": "523080",
    "end": "524760"
  },
  {
    "text": "by by having this description in this",
    "start": "524760",
    "end": "526560"
  },
  {
    "text": "table here we also have a use case page",
    "start": "526560",
    "end": "530080"
  },
  {
    "text": "specifically for question answering with",
    "start": "530080",
    "end": "531959"
  },
  {
    "text": "rag so there are a lot of resources here",
    "start": "531959",
    "end": "535040"
  },
  {
    "text": "on how to uh get started with a quick",
    "start": "535040",
    "end": "538920"
  },
  {
    "text": "start",
    "start": "538920",
    "end": "539839"
  },
  {
    "text": "um returning sources uh creating a chat",
    "start": "539839",
    "end": "542440"
  },
  {
    "text": "bot so adding in chat history uh doing",
    "start": "542440",
    "end": "545320"
  },
  {
    "text": "per user retrieval so if you if you want",
    "start": "545320",
    "end": "547480"
  },
  {
    "text": "to basically build some multi-tenant",
    "start": "547480",
    "end": "549640"
  },
  {
    "text": "application where you're storing",
    "start": "549640",
    "end": "551360"
  },
  {
    "text": "documents for user a and then user B but",
    "start": "551360",
    "end": "553560"
  },
  {
    "text": "you only want user a to search their",
    "start": "553560",
    "end": "555480"
  },
  {
    "text": "documents you need to configure that and",
    "start": "555480",
    "end": "557240"
  },
  {
    "text": "so we have some documentation on that um",
    "start": "557240",
    "end": "559680"
  },
  {
    "text": "how to use local models how to use",
    "start": "559680",
    "end": "561519"
  },
  {
    "text": "agents which we'll talk about more but",
    "start": "561519",
    "end": "563440"
  },
  {
    "text": "basically we have a lot of resources on",
    "start": "563440",
    "end": "565279"
  },
  {
    "text": "retrieval we have a lot of advanced",
    "start": "565279",
    "end": "567200"
  },
  {
    "text": "retrieval methods but we also have the",
    "start": "567200",
    "end": "569360"
  },
  {
    "text": "modular components um like retrievers by",
    "start": "569360",
    "end": "572600"
  },
  {
    "text": "themselves like document loaders by",
    "start": "572600",
    "end": "574440"
  },
  {
    "text": "themselves like text Splitters that",
    "start": "574440",
    "end": "575600"
  },
  {
    "text": "makes it really easy to use any of these",
    "start": "575600",
    "end": "578800"
  },
  {
    "text": "um in any type of retrieval app that",
    "start": "578800",
    "end": "580560"
  },
  {
    "text": "you're",
    "start": "580560",
    "end": "581519"
  },
  {
    "text": "building",
    "start": "581519",
    "end": "584519"
  }
]
[
  {
    "text": "hey this is Lance from Lang chain So",
    "start": "680",
    "end": "2440"
  },
  {
    "text": "Meta launched LL 3.1 today which was a",
    "start": "2440",
    "end": "4520"
  },
  {
    "text": "really anticipated drop and I'm going to",
    "start": "4520",
    "end": "6600"
  },
  {
    "text": "show how to run it locally how to build",
    "start": "6600",
    "end": "8440"
  },
  {
    "text": "a corrective rag agent that'll run",
    "start": "8440",
    "end": "9960"
  },
  {
    "text": "locally using it and how to Benchmark it",
    "start": "9960",
    "end": "12000"
  },
  {
    "text": "against a few other uh models so the",
    "start": "12000",
    "end": "14719"
  },
  {
    "text": "blog post announces a few different",
    "start": "14719",
    "end": "16198"
  },
  {
    "text": "things so 128 context length a few",
    "start": "16199",
    "end": "18600"
  },
  {
    "text": "different versions an 8B a 70b and a",
    "start": "18600",
    "end": "21000"
  },
  {
    "text": "405b now the 405b is really cool it",
    "start": "21000",
    "end": "23680"
  },
  {
    "text": "Rivals a number of larger Clos Source",
    "start": "23680",
    "end": "26240"
  },
  {
    "text": "models we can actually look at the blog",
    "start": "26240",
    "end": "27720"
  },
  {
    "text": "post here uh so it shows valuation this",
    "start": "27720",
    "end": "30240"
  },
  {
    "text": "is the 405 be compared to you know gbd4",
    "start": "30240",
    "end": "32719"
  },
  {
    "text": "Omni claw 35 Sonet you know comparable",
    "start": "32719",
    "end": "35760"
  },
  {
    "text": "performance this will be hosted by m Gro",
    "start": "35760",
    "end": "38000"
  },
  {
    "text": "fireworks and many other providers and",
    "start": "38000",
    "end": "40160"
  },
  {
    "text": "this is fantastic I'm really excited to",
    "start": "40160",
    "end": "41600"
  },
  {
    "text": "play with it so that's the",
    "start": "41600",
    "end": "43120"
  },
  {
    "text": "405b now the 8B parameter models I",
    "start": "43120",
    "end": "45640"
  },
  {
    "text": "actually really like for local you know",
    "start": "45640",
    "end": "47520"
  },
  {
    "text": "I I'll show my system settings a bit",
    "start": "47520",
    "end": "49520"
  },
  {
    "text": "below but basically I have a 32 gig",
    "start": "49520",
    "end": "51520"
  },
  {
    "text": "MacBook Pro and uh I can run this",
    "start": "51520",
    "end": "54039"
  },
  {
    "text": "locally without a problem and that's",
    "start": "54039",
    "end": "55840"
  },
  {
    "text": "really cool um it show performance is",
    "start": "55840",
    "end": "58719"
  },
  {
    "text": "quite capable so it's going to be better",
    "start": "58719",
    "end": "60600"
  },
  {
    "text": "than prior llama 3 and indeed they",
    "start": "60600",
    "end": "63280"
  },
  {
    "text": "report better than gamma 2 and Mr 7",
    "start": "63280",
    "end": "65080"
  },
  {
    "text": "being instruct so that's exciting let's",
    "start": "65080",
    "end": "67560"
  },
  {
    "text": "let's we're going to go ahead and look",
    "start": "67560",
    "end": "68479"
  },
  {
    "text": "at it today um here's my setup I have a",
    "start": "68479",
    "end": "71240"
  },
  {
    "text": "MacBook Pro 32 gig M2 so just so you",
    "start": "71240",
    "end": "73720"
  },
  {
    "text": "know what I'm working with and this I've",
    "start": "73720",
    "end": "75840"
  },
  {
    "text": "already done this so basically I'm going",
    "start": "75840",
    "end": "77360"
  },
  {
    "text": "to use it with a llama a llama pull",
    "start": "77360",
    "end": "79680"
  },
  {
    "text": "llama 3.1 that's all I need to do so",
    "start": "79680",
    "end": "82520"
  },
  {
    "text": "I've already done that and you actually",
    "start": "82520",
    "end": "83720"
  },
  {
    "text": "go over to the Llama page you can see so",
    "start": "83720",
    "end": "85759"
  },
  {
    "text": "this is kind of we can select them all",
    "start": "85759",
    "end": "87200"
  },
  {
    "text": "we want to work with you can see the",
    "start": "87200",
    "end": "88240"
  },
  {
    "text": "405b 231 gig G if you have enough you",
    "start": "88240",
    "end": "91439"
  },
  {
    "text": "have you enough space for that but you",
    "start": "91439",
    "end": "92960"
  },
  {
    "text": "know look the 8B 4.7 gigs this is like",
    "start": "92960",
    "end": "95520"
  },
  {
    "text": "kind of The Sweet Spot this is you know",
    "start": "95520",
    "end": "97079"
  },
  {
    "text": "size I really like to work with for",
    "start": "97079",
    "end": "99040"
  },
  {
    "text": "local so um you just have to do a couple",
    "start": "99040",
    "end": "102040"
  },
  {
    "text": "things here so I've already done this I",
    "start": "102040",
    "end": "103640"
  },
  {
    "text": "have an empty notebook so a few pip",
    "start": "103640",
    "end": "105240"
  },
  {
    "text": "installs uh you're going to see we're",
    "start": "105240",
    "end": "107119"
  },
  {
    "text": "going to use tavali that's a nice kind",
    "start": "107119",
    "end": "108600"
  },
  {
    "text": "of web search Tool uh we'll use langra",
    "start": "108600",
    "end": "111600"
  },
  {
    "text": "to build our agent uh I'll use syit",
    "start": "111600",
    "end": "113920"
  },
  {
    "text": "learn uh to build my little Vector store",
    "start": "113920",
    "end": "117399"
  },
  {
    "text": "Lang chain of llama is the package that",
    "start": "117399",
    "end": "119000"
  },
  {
    "text": "we're going to be using to use to access",
    "start": "119000",
    "end": "120680"
  },
  {
    "text": "o llama uh so those are some things that",
    "start": "120680",
    "end": "123159"
  },
  {
    "text": "you need to install and this of course",
    "start": "123159",
    "end": "124680"
  },
  {
    "text": "notebook will be shared few API keys if",
    "start": "124680",
    "end": "127280"
  },
  {
    "text": "you want to use open embeddings you're",
    "start": "127280",
    "end": "128840"
  },
  {
    "text": "going to set that you set your tab API",
    "start": "128840",
    "end": "131319"
  },
  {
    "text": "key and these are Keys necessary for",
    "start": "131319",
    "end": "133480"
  },
  {
    "text": "lsmith which I'll show that's totally",
    "start": "133480",
    "end": "136000"
  },
  {
    "text": "optional if you want to do evaluations",
    "start": "136000",
    "end": "138120"
  },
  {
    "text": "you can use lsmith uh but it's of course",
    "start": "138120",
    "end": "140239"
  },
  {
    "text": "totally optional so here's we're going",
    "start": "140239",
    "end": "142319"
  },
  {
    "text": "to build and this is kind of my goto",
    "start": "142319",
    "end": "145319"
  },
  {
    "text": "Vibe test kind of little application I",
    "start": "145319",
    "end": "147959"
  },
  {
    "text": "like to build these little",
    "start": "147959",
    "end": "148720"
  },
  {
    "text": "self-corrective rag AG",
    "start": "148720",
    "end": "151080"
  },
  {
    "text": "um there's been a lot of cool papers on",
    "start": "151080",
    "end": "153160"
  },
  {
    "text": "this theme the big idea is simply this",
    "start": "153160",
    "end": "155760"
  },
  {
    "text": "with rag you want the ability to",
    "start": "155760",
    "end": "157080"
  },
  {
    "text": "self-correct from mistakes and retrieval",
    "start": "157080",
    "end": "159440"
  },
  {
    "text": "so what you do is you retrieve from a",
    "start": "159440",
    "end": "161120"
  },
  {
    "text": "vector store you grade the documents for",
    "start": "161120",
    "end": "162959"
  },
  {
    "text": "relevance and if the documents are not",
    "start": "162959",
    "end": "165159"
  },
  {
    "text": "relevant you can kick out and do a web",
    "start": "165159",
    "end": "166840"
  },
  {
    "text": "search this gives you flexibility if",
    "start": "166840",
    "end": "168519"
  },
  {
    "text": "questions are outside the domain of your",
    "start": "168519",
    "end": "169959"
  },
  {
    "text": "vector store you can still answer them",
    "start": "169959",
    "end": "171840"
  },
  {
    "text": "using web search and so it's a super",
    "start": "171840",
    "end": "173400"
  },
  {
    "text": "simple kind of little toy agent that I",
    "start": "173400",
    "end": "175640"
  },
  {
    "text": "like to test out different models with",
    "start": "175640",
    "end": "177519"
  },
  {
    "text": "so that's all we're going to do here",
    "start": "177519",
    "end": "179120"
  },
  {
    "text": "really simple",
    "start": "179120",
    "end": "181239"
  },
  {
    "text": "um so first let's just walk through the",
    "start": "181239",
    "end": "183440"
  },
  {
    "text": "code here I'm going to build a little",
    "start": "183440",
    "end": "184400"
  },
  {
    "text": "Vector store I'm going to index a few",
    "start": "184400",
    "end": "185879"
  },
  {
    "text": "blog posts from Lili and Wang one on",
    "start": "185879",
    "end": "188360"
  },
  {
    "text": "agents one on prompt engineering one on",
    "start": "188360",
    "end": "190080"
  },
  {
    "text": "adversarial taxs I'm going to load the",
    "start": "190080",
    "end": "192319"
  },
  {
    "text": "pages I'm going to split them I'll use a",
    "start": "192319",
    "end": "194879"
  },
  {
    "text": "chunk size of 250 this is of course",
    "start": "194879",
    "end": "196640"
  },
  {
    "text": "arbitrary you can tune this as you see",
    "start": "196640",
    "end": "198799"
  },
  {
    "text": "fit uh build my splits and here's where",
    "start": "198799",
    "end": "201080"
  },
  {
    "text": "I set my Vector store so I'll use SK",
    "start": "201080",
    "end": "203400"
  },
  {
    "text": "learn Vector store um I'll use open Ai",
    "start": "203400",
    "end": "206120"
  },
  {
    "text": "embeddings and you'll see why a little",
    "start": "206120",
    "end": "207440"
  },
  {
    "text": "bit later it's because I've done some",
    "start": "207440",
    "end": "208840"
  },
  {
    "text": "other evaluations using open eye",
    "start": "208840",
    "end": "210319"
  },
  {
    "text": "embedding so I want to keep it",
    "start": "210319",
    "end": "211239"
  },
  {
    "text": "consistent but if you want something",
    "start": "211239",
    "end": "213000"
  },
  {
    "text": "that's fully local I also encourage you",
    "start": "213000",
    "end": "214840"
  },
  {
    "text": "to look at nomic embeddings uh so this",
    "start": "214840",
    "end": "216720"
  },
  {
    "text": "is how you can just use them all you",
    "start": "216720",
    "end": "218519"
  },
  {
    "text": "have to do again I noted up here is",
    "start": "218519",
    "end": "220480"
  },
  {
    "text": "basically in your installs noic local so",
    "start": "220480",
    "end": "223000"
  },
  {
    "text": "that's all you need uh so that's if you",
    "start": "223000",
    "end": "224599"
  },
  {
    "text": "want fully local embeddings um I'm going",
    "start": "224599",
    "end": "227360"
  },
  {
    "text": "to build my retriever here that'll kick",
    "start": "227360",
    "end": "230120"
  },
  {
    "text": "off um cool and just as a little note",
    "start": "230120",
    "end": "234519"
  },
  {
    "text": "here I can kind of call my retriever",
    "start": "234519",
    "end": "236840"
  },
  {
    "text": "invoke and basically I can ask any",
    "start": "236840",
    "end": "239400"
  },
  {
    "text": "question",
    "start": "239400",
    "end": "240360"
  },
  {
    "text": "agent memory and this should return some",
    "start": "240360",
    "end": "242439"
  },
  {
    "text": "docs for me there we go so we have some",
    "start": "242439",
    "end": "244200"
  },
  {
    "text": "docs so we have a working retriever from",
    "start": "244200",
    "end": "246319"
  },
  {
    "text": "our blog post that's great so this is",
    "start": "246319",
    "end": "248519"
  },
  {
    "text": "going to be my little web search tool",
    "start": "248519",
    "end": "250120"
  },
  {
    "text": "this I'm use Tav again I set my API key",
    "start": "250120",
    "end": "252439"
  },
  {
    "text": "above here so this just works I can use",
    "start": "252439",
    "end": "254640"
  },
  {
    "text": "this web search tool to search the web",
    "start": "254640",
    "end": "257560"
  },
  {
    "text": "so here's where I'm going to set up a",
    "start": "257560",
    "end": "258759"
  },
  {
    "text": "few different things so this is just",
    "start": "258759",
    "end": "260519"
  },
  {
    "text": "going to be uh I'm going to use Lang",
    "start": "260519",
    "end": "262440"
  },
  {
    "text": "Chain O llama import Shadow llama now",
    "start": "262440",
    "end": "264960"
  },
  {
    "text": "here I'm just going to specify llama 31",
    "start": "264960",
    "end": "267560"
  },
  {
    "text": "again we already grabbed this so if you",
    "start": "267560",
    "end": "270120"
  },
  {
    "text": "look above here a llama pole llama 3.1 I",
    "start": "270120",
    "end": "273479"
  },
  {
    "text": "have a llama running in the background",
    "start": "273479",
    "end": "275240"
  },
  {
    "text": "that's all I need to do and then this",
    "start": "275240",
    "end": "276800"
  },
  {
    "text": "should be available to me as long as",
    "start": "276800",
    "end": "278000"
  },
  {
    "text": "I've pulled the model so that's",
    "start": "278000",
    "end": "280280"
  },
  {
    "text": "it um now this is just going to be a",
    "start": "280280",
    "end": "282840"
  },
  {
    "text": "simple rag prompt you're an assistant",
    "start": "282840",
    "end": "284520"
  },
  {
    "text": "for question answering task use the",
    "start": "284520",
    "end": "286199"
  },
  {
    "text": "following documents to answer the",
    "start": "286199",
    "end": "287360"
  },
  {
    "text": "question if you don't know the answer",
    "start": "287360",
    "end": "288960"
  },
  {
    "text": "just say you don't know okay so that's",
    "start": "288960",
    "end": "290680"
  },
  {
    "text": "just like a really simple basic rag",
    "start": "290680",
    "end": "292360"
  },
  {
    "text": "chain I'm going to build and we're done",
    "start": "292360",
    "end": "295039"
  },
  {
    "text": "so that's our rag",
    "start": "295039",
    "end": "297000"
  },
  {
    "text": "chain um",
    "start": "297000",
    "end": "299880"
  },
  {
    "text": "now here is another component we're",
    "start": "299880",
    "end": "301919"
  },
  {
    "text": "going to need we're going to have need a",
    "start": "301919",
    "end": "303199"
  },
  {
    "text": "retrieval greater so if you kind of",
    "start": "303199",
    "end": "305199"
  },
  {
    "text": "think about the flow we did above here",
    "start": "305199",
    "end": "307560"
  },
  {
    "text": "we just to find our rag chain that's",
    "start": "307560",
    "end": "308960"
  },
  {
    "text": "going to be this kind of piece right",
    "start": "308960",
    "end": "310639"
  },
  {
    "text": "here we also need a greater piece we",
    "start": "310639",
    "end": "312880"
  },
  {
    "text": "built our Vector store we have a web",
    "start": "312880",
    "end": "314880"
  },
  {
    "text": "search tool and now we need the greater",
    "start": "314880",
    "end": "317039"
  },
  {
    "text": "that's the final thing we need so for",
    "start": "317039",
    "end": "319080"
  },
  {
    "text": "this I'm going to show I'm use something",
    "start": "319080",
    "end": "320639"
  },
  {
    "text": "that's very convenient Json mode from",
    "start": "320639",
    "end": "323039"
  },
  {
    "text": "from olama and in my greater pumpt I'm",
    "start": "323039",
    "end": "325400"
  },
  {
    "text": "basically going to say you're greater",
    "start": "325400",
    "end": "326800"
  },
  {
    "text": "assessing the relevance of retrieve",
    "start": "326800",
    "end": "328039"
  },
  {
    "text": "document to use your question here's the",
    "start": "328039",
    "end": "329919"
  },
  {
    "text": "document here's the question if it",
    "start": "329919",
    "end": "331919"
  },
  {
    "text": "contains keywords related to the",
    "start": "331919",
    "end": "333080"
  },
  {
    "text": "question gr is relevant it it do not",
    "start": "333080",
    "end": "334919"
  },
  {
    "text": "need to be stringent you're just trying",
    "start": "334919",
    "end": "336759"
  },
  {
    "text": "to kind of filter out erroneous",
    "start": "336759",
    "end": "338160"
  },
  {
    "text": "retrievals give a binary score of yes no",
    "start": "338160",
    "end": "340720"
  },
  {
    "text": "return it as Json that's it so super",
    "start": "340720",
    "end": "343199"
  },
  {
    "text": "simple we have a greater so that's",
    "start": "343199",
    "end": "346360"
  },
  {
    "text": "really it now we have a",
    "start": "346360",
    "end": "349720"
  },
  {
    "text": "greater so we can go ahead and go down",
    "start": "349720",
    "end": "352000"
  },
  {
    "text": "here and now I'm just going to build my",
    "start": "352000",
    "end": "353680"
  },
  {
    "text": "little L graph and so you're going to",
    "start": "353680",
    "end": "354919"
  },
  {
    "text": "see all we need to do so L graph is a",
    "start": "354919",
    "end": "357520"
  },
  {
    "text": "really nice way to layout control flows",
    "start": "357520",
    "end": "359919"
  },
  {
    "text": "um they can be kind of custom flows that",
    "start": "359919",
    "end": "362039"
  },
  {
    "text": "you want to express some kind of agentic",
    "start": "362039",
    "end": "365120"
  },
  {
    "text": "U reasoning right so we're going to set",
    "start": "365120",
    "end": "368000"
  },
  {
    "text": "up a graph State our graph stat is can",
    "start": "368000",
    "end": "369440"
  },
  {
    "text": "to contain a few relevant things per our",
    "start": "369440",
    "end": "371759"
  },
  {
    "text": "change a question a generation search",
    "start": "371759",
    "end": "375599"
  },
  {
    "text": "whether or not to search yes or no",
    "start": "375599",
    "end": "377560"
  },
  {
    "text": "documents retrieved and the steps we're",
    "start": "377560",
    "end": "379720"
  },
  {
    "text": "taking throughout our chain so that's",
    "start": "379720",
    "end": "381639"
  },
  {
    "text": "all we need to persist through",
    "start": "381639",
    "end": "383560"
  },
  {
    "text": "State we have this retrieve node so",
    "start": "383560",
    "end": "386520"
  },
  {
    "text": "basically each node is just a function",
    "start": "386520",
    "end": "388840"
  },
  {
    "text": "so I set it in retrieve node it pulls in",
    "start": "388840",
    "end": "391199"
  },
  {
    "text": "state from State I can get anything I",
    "start": "391199",
    "end": "393520"
  },
  {
    "text": "need so all these things are accessible",
    "start": "393520",
    "end": "395160"
  },
  {
    "text": "to me when I pull in state to each node",
    "start": "395160",
    "end": "397639"
  },
  {
    "text": "so I can get the question I can get the",
    "start": "397639",
    "end": "399759"
  },
  {
    "text": "documents um from my retriever I can",
    "start": "399759",
    "end": "403440"
  },
  {
    "text": "note that um basically pull in the prior",
    "start": "403440",
    "end": "406520"
  },
  {
    "text": "steps I've taken append this particular",
    "start": "406520",
    "end": "409000"
  },
  {
    "text": "step retrieve documents and then return",
    "start": "409000",
    "end": "412000"
  },
  {
    "text": "uh documents question and steps back to",
    "start": "412000",
    "end": "414560"
  },
  {
    "text": "state so that's all I'm going to do and",
    "start": "414560",
    "end": "416840"
  },
  {
    "text": "I'm just going to walk through my flow",
    "start": "416840",
    "end": "419240"
  },
  {
    "text": "so and have a retrieve step and we can",
    "start": "419240",
    "end": "421919"
  },
  {
    "text": "go back to our diagram here we can kind",
    "start": "421919",
    "end": "423720"
  },
  {
    "text": "of see um this Vector store retrieval is",
    "start": "423720",
    "end": "426680"
  },
  {
    "text": "basically going to be um",
    "start": "426680",
    "end": "429280"
  },
  {
    "text": "retrieve so that's kind of our first",
    "start": "429280",
    "end": "431560"
  },
  {
    "text": "node is",
    "start": "431560",
    "end": "432840"
  },
  {
    "text": "retrieve um our generate node then is",
    "start": "432840",
    "end": "436199"
  },
  {
    "text": "going to um it's going to be this one",
    "start": "436199",
    "end": "439360"
  },
  {
    "text": "right here so again just we're going to",
    "start": "439360",
    "end": "441759"
  },
  {
    "text": "get the question the documents before",
    "start": "441759",
    "end": "444400"
  },
  {
    "text": "call the rag chain with the documents in",
    "start": "444400",
    "end": "447039"
  },
  {
    "text": "question append generate answer to to",
    "start": "447039",
    "end": "449599"
  },
  {
    "text": "the steps and return same with grade",
    "start": "449599",
    "end": "452120"
  },
  {
    "text": "documents so this is going to be the",
    "start": "452120",
    "end": "453680"
  },
  {
    "text": "step here in this particular case you",
    "start": "453680",
    "end": "456000"
  },
  {
    "text": "know same kind of flow we take the state",
    "start": "456000",
    "end": "457800"
  },
  {
    "text": "we get the question we get the documents",
    "start": "457800",
    "end": "460360"
  },
  {
    "text": "um now initially we say we are not going",
    "start": "460360",
    "end": "463440"
  },
  {
    "text": "to search and we iterate through our",
    "start": "463440",
    "end": "465479"
  },
  {
    "text": "documents we grade each one for",
    "start": "465479",
    "end": "467080"
  },
  {
    "text": "relevance to the question and we get the",
    "start": "467080",
    "end": "470039"
  },
  {
    "text": "we get the grade back now if the grade",
    "start": "470039",
    "end": "472759"
  },
  {
    "text": "is yes we just append the document so",
    "start": "472759",
    "end": "474800"
  },
  {
    "text": "that means it's relevant if the grade is",
    "start": "474800",
    "end": "476800"
  },
  {
    "text": "no then we basically set our search flag",
    "start": "476800",
    "end": "479280"
  },
  {
    "text": "we say okay one of the documents is",
    "start": "479280",
    "end": "481159"
  },
  {
    "text": "irrelevant we're going to search and we",
    "start": "481159",
    "end": "483000"
  },
  {
    "text": "keep going so we iterate through all of",
    "start": "483000",
    "end": "484319"
  },
  {
    "text": "our documents we assess the relevance",
    "start": "484319",
    "end": "486599"
  },
  {
    "text": "and we keep going and finally we have",
    "start": "486599",
    "end": "488759"
  },
  {
    "text": "this web search node which is down here",
    "start": "488759",
    "end": "490800"
  },
  {
    "text": "and this just calls our Search tool so",
    "start": "490800",
    "end": "492479"
  },
  {
    "text": "web search tool invoke with the question",
    "start": "492479",
    "end": "494879"
  },
  {
    "text": "get the web get the search results add",
    "start": "494879",
    "end": "497080"
  },
  {
    "text": "them to our documents and return the",
    "start": "497080",
    "end": "499199"
  },
  {
    "text": "state this finary this final thing is",
    "start": "499199",
    "end": "501720"
  },
  {
    "text": "basically just this Edge we set right",
    "start": "501720",
    "end": "503400"
  },
  {
    "text": "here so basically we get the search",
    "start": "503400",
    "end": "506000"
  },
  {
    "text": "state which is either yes or no if it's",
    "start": "506000",
    "end": "508639"
  },
  {
    "text": "yes go to search if it's not go to",
    "start": "508639",
    "end": "511000"
  },
  {
    "text": "generate so that's basically this logic",
    "start": "511000",
    "end": "512719"
  },
  {
    "text": "right here and you're going to see in",
    "start": "512719",
    "end": "515760"
  },
  {
    "text": "one second here this is the whole",
    "start": "515760",
    "end": "517599"
  },
  {
    "text": "control flow so this is where all those",
    "start": "517599",
    "end": "519320"
  },
  {
    "text": "pieces come together and expresses",
    "start": "519320",
    "end": "521039"
  },
  {
    "text": "exactly what we kind of Drew out here in",
    "start": "521039",
    "end": "522518"
  },
  {
    "text": "our cartoon but this is in Lang graph as",
    "start": "522519",
    "end": "524880"
  },
  {
    "text": "a kind of langra custom agent or custom",
    "start": "524880",
    "end": "526839"
  },
  {
    "text": "control flow so you start you do",
    "start": "526839",
    "end": "528959"
  },
  {
    "text": "retrieval you do the grading step what",
    "start": "528959",
    "end": "530680"
  },
  {
    "text": "we just talked through to look at each",
    "start": "530680",
    "end": "532560"
  },
  {
    "text": "document is it relevant to the question",
    "start": "532560",
    "end": "534360"
  },
  {
    "text": "if any is not relevant we kick out we do",
    "start": "534360",
    "end": "536839"
  },
  {
    "text": "web search we add the search results to",
    "start": "536839",
    "end": "539079"
  },
  {
    "text": "our do docents we send the documents to",
    "start": "539079",
    "end": "541240"
  },
  {
    "text": "the generate step and then we end that's",
    "start": "541240",
    "end": "544120"
  },
  {
    "text": "it super simple but I've used this in a",
    "start": "544120",
    "end": "546079"
  },
  {
    "text": "whole bunch of different tests that's",
    "start": "546079",
    "end": "547200"
  },
  {
    "text": "like a really nice Vibe test for",
    "start": "547200",
    "end": "549000"
  },
  {
    "text": "different models so anyway I like that",
    "start": "549000",
    "end": "552120"
  },
  {
    "text": "we have our little agent laid out here",
    "start": "552120",
    "end": "555160"
  },
  {
    "text": "um so cool we've copied all that over",
    "start": "555160",
    "end": "557279"
  },
  {
    "text": "we've just walked through it and now we",
    "start": "557279",
    "end": "559519"
  },
  {
    "text": "can just run it so let's test it out so",
    "start": "559519",
    "end": "561880"
  },
  {
    "text": "you can see right here I have a little",
    "start": "561880",
    "end": "563120"
  },
  {
    "text": "function um so basically this config is",
    "start": "563120",
    "end": "565800"
  },
  {
    "text": "something I can use with Lang graph so",
    "start": "565800",
    "end": "568120"
  },
  {
    "text": "thread ID it's not really real here but",
    "start": "568120",
    "end": "569959"
  },
  {
    "text": "if you ever want to for example save the",
    "start": "569959",
    "end": "571839"
  },
  {
    "text": "state of a particular execution you can",
    "start": "571839",
    "end": "573959"
  },
  {
    "text": "use threads to do that I talk about that",
    "start": "573959",
    "end": "575600"
  },
  {
    "text": "in some other videos so I'll I'll link",
    "start": "575600",
    "end": "577800"
  },
  {
    "text": "them below if you care if you're",
    "start": "577800",
    "end": "578800"
  },
  {
    "text": "interested in in how threads work but",
    "start": "578800",
    "end": "580600"
  },
  {
    "text": "for this all we need we take our custom",
    "start": "580600",
    "end": "582839"
  },
  {
    "text": "agent we're going to invoke it with with",
    "start": "582839",
    "end": "584800"
  },
  {
    "text": "a basically a question we'll send that",
    "start": "584800",
    "end": "587240"
  },
  {
    "text": "in we'll kind of send in a question as a",
    "start": "587240",
    "end": "589240"
  },
  {
    "text": "as an example dict here we'll pass it",
    "start": "589240",
    "end": "591399"
  },
  {
    "text": "into our function um and then we're",
    "start": "591399",
    "end": "594200"
  },
  {
    "text": "going to go ahead and return the",
    "start": "594200",
    "end": "595680"
  },
  {
    "text": "response and that's it so let's go ahead",
    "start": "595680",
    "end": "597120"
  },
  {
    "text": "and test that out",
    "start": "597120",
    "end": "599480"
  },
  {
    "text": "so uh our agent is running here and",
    "start": "599480",
    "end": "602959"
  },
  {
    "text": "right now I can actually open up uh I",
    "start": "602959",
    "end": "606040"
  },
  {
    "text": "can go to Lang Smith I can open up my",
    "start": "606040",
    "end": "608680"
  },
  {
    "text": "projects we can see our Lang graph is",
    "start": "608680",
    "end": "610360"
  },
  {
    "text": "running here and cool so we can see",
    "start": "610360",
    "end": "613360"
  },
  {
    "text": "we've done the retrieve we we're looking",
    "start": "613360",
    "end": "615360"
  },
  {
    "text": "at our documents we're grading each one",
    "start": "615360",
    "end": "617000"
  },
  {
    "text": "with llama 31 from cadow Lama so that's",
    "start": "617000",
    "end": "619200"
  },
  {
    "text": "pretty cool we confirm we're using the",
    "start": "619200",
    "end": "620480"
  },
  {
    "text": "right model and hey this is pretty nice",
    "start": "620480",
    "end": "622000"
  },
  {
    "text": "this is all running locally we're doing",
    "start": "622000",
    "end": "623760"
  },
  {
    "text": "the grading we're doing the generation",
    "start": "623760",
    "end": "626079"
  },
  {
    "text": "and we can actually look at what happens",
    "start": "626079",
    "end": "627480"
  },
  {
    "text": "here cool and we get an answer out so",
    "start": "627480",
    "end": "630800"
  },
  {
    "text": "this is pretty nice we've been able to",
    "start": "630800",
    "end": "632560"
  },
  {
    "text": "run our custom agent locally using llama",
    "start": "632560",
    "end": "636040"
  },
  {
    "text": "31 and Lang graph we've used um actually",
    "start": "636040",
    "end": "639519"
  },
  {
    "text": "which is cool here does token us doesn't",
    "start": "639519",
    "end": "641200"
  },
  {
    "text": "matter we're not being charged is",
    "start": "641200",
    "end": "642240"
  },
  {
    "text": "running on my laptop locally latency",
    "start": "642240",
    "end": "644360"
  },
  {
    "text": "looks pretty low it looks like it's",
    "start": "644360",
    "end": "645720"
  },
  {
    "text": "around 5 Seconds",
    "start": "645720",
    "end": "648240"
  },
  {
    "text": "um I guess that's actually sorry that's",
    "start": "648240",
    "end": "650440"
  },
  {
    "text": "just for this particular run the overall",
    "start": "650440",
    "end": "653040"
  },
  {
    "text": "latency is let's see 16 seconds okay not",
    "start": "653040",
    "end": "657760"
  },
  {
    "text": "bad so that's pretty cool",
    "start": "657760",
    "end": "660160"
  },
  {
    "text": "all right cool so that's good we know",
    "start": "660160",
    "end": "662399"
  },
  {
    "text": "everything works um now let's actually",
    "start": "662399",
    "end": "665760"
  },
  {
    "text": "do a little bit more evaluation here so",
    "start": "665760",
    "end": "669200"
  },
  {
    "text": "what are some things I can do if I want",
    "start": "669200",
    "end": "671240"
  },
  {
    "text": "to kind of really Benchmark this",
    "start": "671240",
    "end": "672560"
  },
  {
    "text": "rigorously I can do a couple different",
    "start": "672560",
    "end": "674120"
  },
  {
    "text": "things so basically I can look at you",
    "start": "674120",
    "end": "676880"
  },
  {
    "text": "know the end-end performance of my agent",
    "start": "676880",
    "end": "678760"
  },
  {
    "text": "so basically is this response correct",
    "start": "678760",
    "end": "680760"
  },
  {
    "text": "relative to some reference and I can",
    "start": "680760",
    "end": "682639"
  },
  {
    "text": "also look at the sequence of actions",
    "start": "682639",
    "end": "684320"
  },
  {
    "text": "that it took so is it taking the right",
    "start": "684320",
    "end": "686200"
  },
  {
    "text": "and expected number of steps which you",
    "start": "686200",
    "end": "687880"
  },
  {
    "text": "see I log here so I log the steps it",
    "start": "687880",
    "end": "690200"
  },
  {
    "text": "takes retrieve grade generate so that's",
    "start": "690200",
    "end": "693880"
  },
  {
    "text": "cool I log that and I log the response",
    "start": "693880",
    "end": "696320"
  },
  {
    "text": "so actually I can evaluate both I can",
    "start": "696320",
    "end": "697959"
  },
  {
    "text": "evaluate the endend response I can",
    "start": "697959",
    "end": "699760"
  },
  {
    "text": "evaluate its sequence of steps right so",
    "start": "699760",
    "end": "702760"
  },
  {
    "text": "that's pretty nice now I",
    "start": "702760",
    "end": "707800"
  },
  {
    "text": "um I'm going to set up this evaluation",
    "start": "707800",
    "end": "711200"
  },
  {
    "text": "section of the notebook",
    "start": "711200",
    "end": "713000"
  },
  {
    "text": "here",
    "start": "713000",
    "end": "715880"
  },
  {
    "text": "um and what you're going to see here is",
    "start": "715880",
    "end": "718399"
  },
  {
    "text": "I'm just going to define a function so",
    "start": "718399",
    "end": "720000"
  },
  {
    "text": "this function is going to be my",
    "start": "720000",
    "end": "721279"
  },
  {
    "text": "evaluation for end to end performance",
    "start": "721279",
    "end": "724320"
  },
  {
    "text": "I'm going to use uh a a basically llm as",
    "start": "724320",
    "end": "729720"
  },
  {
    "text": "grader um here is the prompt that I will",
    "start": "729720",
    "end": "733600"
  },
  {
    "text": "use to grade my Generations um this is",
    "start": "733600",
    "end": "736880"
  },
  {
    "text": "in the Lang Smith Hub um it's something",
    "start": "736880",
    "end": "739839"
  },
  {
    "text": "like this you're a teacher grading a",
    "start": "739839",
    "end": "740959"
  },
  {
    "text": "quiz you're given a question a ground",
    "start": "740959",
    "end": "742360"
  },
  {
    "text": "truth correct answer and a student",
    "start": "742360",
    "end": "743760"
  },
  {
    "text": "answer uh grade it only based on the",
    "start": "743760",
    "end": "746120"
  },
  {
    "text": "factual accuracy ensure the student",
    "start": "746120",
    "end": "748320"
  },
  {
    "text": "answer does not contain conflicting",
    "start": "748320",
    "end": "749720"
  },
  {
    "text": "statements and so forth score of one",
    "start": "749720",
    "end": "752120"
  },
  {
    "text": "means it meets the criteria score of",
    "start": "752120",
    "end": "753720"
  },
  {
    "text": "zero means it doesn't so a binary grader",
    "start": "753720",
    "end": "756279"
  },
  {
    "text": "we're going to run it on our reference",
    "start": "756279",
    "end": "758160"
  },
  {
    "text": "answers relative to our rag generate",
    "start": "758160",
    "end": "759959"
  },
  {
    "text": "answers so that's what we're going to",
    "start": "759959",
    "end": "762000"
  },
  {
    "text": "have",
    "start": "762000",
    "end": "763160"
  },
  {
    "text": "here",
    "start": "763160",
    "end": "765680"
  },
  {
    "text": "um and I'm also going to do a custom",
    "start": "765680",
    "end": "770760"
  },
  {
    "text": "evaluation function for my trajectory so",
    "start": "770760",
    "end": "775199"
  },
  {
    "text": "in this particular case all I need to do",
    "start": "775199",
    "end": "778480"
  },
  {
    "text": "is I get the the tool calls out from",
    "start": "778480",
    "end": "780240"
  },
  {
    "text": "steps so basically if you look at what I",
    "start": "780240",
    "end": "782279"
  },
  {
    "text": "return here I return this dict it",
    "start": "782279",
    "end": "784279"
  },
  {
    "text": "contains steps so I can fish out the",
    "start": "784279",
    "end": "786800"
  },
  {
    "text": "steps right here get the tool calls and",
    "start": "786800",
    "end": "789199"
  },
  {
    "text": "simply compare them to what I expect I",
    "start": "789199",
    "end": "791000"
  },
  {
    "text": "either want retrieve grade web search",
    "start": "791000",
    "end": "794240"
  },
  {
    "text": "generate or retrieve grade generate",
    "start": "794240",
    "end": "797120"
  },
  {
    "text": "those are the two trajectories that I",
    "start": "797120",
    "end": "798560"
  },
  {
    "text": "expect my agent to take I can extract",
    "start": "798560",
    "end": "800639"
  },
  {
    "text": "those tool calls and I can just do",
    "start": "800639",
    "end": "801959"
  },
  {
    "text": "simple comparison does it match one of",
    "start": "801959",
    "end": "804680"
  },
  {
    "text": "those two if if if it does score one if",
    "start": "804680",
    "end": "807360"
  },
  {
    "text": "it doesn't score zero so that's really",
    "start": "807360",
    "end": "810519"
  },
  {
    "text": "it now only thing I left out here is",
    "start": "810519",
    "end": "813680"
  },
  {
    "text": "that previously I've already built a",
    "start": "813680",
    "end": "815320"
  },
  {
    "text": "data set um and I'll go ahead and show",
    "start": "815320",
    "end": "817880"
  },
  {
    "text": "you that right now um so I'll go down",
    "start": "817880",
    "end": "822240"
  },
  {
    "text": "and show this this is uh so this is all",
    "start": "822240",
    "end": "825160"
  },
  {
    "text": "I've done to create a data set in lsmith",
    "start": "825160",
    "end": "827519"
  },
  {
    "text": "I'll just put it in here for fun so this",
    "start": "827519",
    "end": "829519"
  },
  {
    "text": "is my little data set that I'm going to",
    "start": "829519",
    "end": "830959"
  },
  {
    "text": "use to test so you can see it's really",
    "start": "830959",
    "end": "832600"
  },
  {
    "text": "easy to build an eval set just a set of",
    "start": "832600",
    "end": "834759"
  },
  {
    "text": "question answer pairs question answer so",
    "start": "834759",
    "end": "837199"
  },
  {
    "text": "these three are based upon the blog",
    "start": "837199",
    "end": "839160"
  },
  {
    "text": "posts that I've indexed these two are",
    "start": "839160",
    "end": "841240"
  },
  {
    "text": "just current events so I want to make",
    "start": "841240",
    "end": "842839"
  },
  {
    "text": "sure my corrective agent can answer",
    "start": "842839",
    "end": "844480"
  },
  {
    "text": "questions about my blogs and the index",
    "start": "844480",
    "end": "846759"
  },
  {
    "text": "and also answer just current event",
    "start": "846759",
    "end": "848440"
  },
  {
    "text": "questions about NFL draft or the NBA",
    "start": "848440",
    "end": "850480"
  },
  {
    "text": "Finals right so this data set I've",
    "start": "850480",
    "end": "852120"
  },
  {
    "text": "already created it's named corrective",
    "start": "852120",
    "end": "854240"
  },
  {
    "text": "rag agent testing if I go over to my",
    "start": "854240",
    "end": "856519"
  },
  {
    "text": "Langs Smith so I go to my data sets and",
    "start": "856519",
    "end": "859040"
  },
  {
    "text": "testing it's right here and I've prob",
    "start": "859040",
    "end": "861519"
  },
  {
    "text": "run a few experiments on it so it but",
    "start": "861519",
    "end": "863880"
  },
  {
    "text": "it's here that's the nice thing about it",
    "start": "863880",
    "end": "865279"
  },
  {
    "text": "so I have this data set I've created it",
    "start": "865279",
    "end": "867839"
  },
  {
    "text": "um so that's all really nice data set",
    "start": "867839",
    "end": "871240"
  },
  {
    "text": "exists I've set up my evaluator so this",
    "start": "871240",
    "end": "873959"
  },
  {
    "text": "is what I can use to evaluate kind of",
    "start": "873959",
    "end": "875480"
  },
  {
    "text": "the tool called trajectory this is what",
    "start": "875480",
    "end": "877399"
  },
  {
    "text": "I can use to evaluate the end to end",
    "start": "877399",
    "end": "879240"
  },
  {
    "text": "answer and I go ahead and this is all I",
    "start": "879240",
    "end": "881720"
  },
  {
    "text": "need to run so",
    "start": "881720",
    "end": "883360"
  },
  {
    "text": "basically there we go and I can kick",
    "start": "883360",
    "end": "885680"
  },
  {
    "text": "this off so now my eval is",
    "start": "885680",
    "end": "887440"
  },
  {
    "text": "running all I've done is I've set my",
    "start": "887440",
    "end": "889639"
  },
  {
    "text": "data set name this is just a metadata",
    "start": "889639",
    "end": "891839"
  },
  {
    "text": "about the model I tested um this is just",
    "start": "891839",
    "end": "894360"
  },
  {
    "text": "like my experiment prefix so that's",
    "start": "894360",
    "end": "896519"
  },
  {
    "text": "custom agent answer is the function that",
    "start": "896519",
    "end": "898480"
  },
  {
    "text": "I built right up here boom so again",
    "start": "898480",
    "end": "901839"
  },
  {
    "text": "that's just going to take in an example",
    "start": "901839",
    "end": "903360"
  },
  {
    "text": "dict and it's going to pass the question",
    "start": "903360",
    "end": "905959"
  },
  {
    "text": "from the dict into my chain and get my",
    "start": "905959",
    "end": "908440"
  },
  {
    "text": "get the answer out that's it return a",
    "start": "908440",
    "end": "911120"
  },
  {
    "text": "response return the steps that's all I",
    "start": "911120",
    "end": "914040"
  },
  {
    "text": "need to do um so this is running uh the",
    "start": "914040",
    "end": "917720"
  },
  {
    "text": "data sets there the evaluators are",
    "start": "917720",
    "end": "919519"
  },
  {
    "text": "specified here and this is just metadata",
    "start": "919519",
    "end": "922160"
  },
  {
    "text": "I also tell it to run three repetitions",
    "start": "922160",
    "end": "924639"
  },
  {
    "text": "so that's really",
    "start": "924639",
    "end": "927320"
  },
  {
    "text": "it great so that ran and this is just a",
    "start": "927720",
    "end": "931319"
  },
  {
    "text": "logging of the tool calls that I make at",
    "start": "931319",
    "end": "933279"
  },
  {
    "text": "each iteration so there's five questions",
    "start": "933279",
    "end": "936199"
  },
  {
    "text": "each one of my evals runs three times uh",
    "start": "936199",
    "end": "939160"
  },
  {
    "text": "so it's 15 total now let's go over to",
    "start": "939160",
    "end": "941319"
  },
  {
    "text": "Lang Smith we can actually look here so",
    "start": "941319",
    "end": "943000"
  },
  {
    "text": "I've run a bunch of different evals with",
    "start": "943000",
    "end": "944839"
  },
  {
    "text": "other LMS already on this data set so",
    "start": "944839",
    "end": "946839"
  },
  {
    "text": "it's kind of nice for very quick kind of",
    "start": "946839",
    "end": "948720"
  },
  {
    "text": "like sanity checking right so you can",
    "start": "948720",
    "end": "951759"
  },
  {
    "text": "look at the names here these are the",
    "start": "951759",
    "end": "952959"
  },
  {
    "text": "experiment names that I've run um all on",
    "start": "952959",
    "end": "955360"
  },
  {
    "text": "the same data set all with three",
    "start": "955360",
    "end": "957839"
  },
  {
    "text": "repetitions",
    "start": "957839",
    "end": "959839"
  },
  {
    "text": "um again super quickly I can just look",
    "start": "959839",
    "end": "961959"
  },
  {
    "text": "at my data set here so there's five",
    "start": "961959",
    "end": "963440"
  },
  {
    "text": "questions right so that's fine um and",
    "start": "963440",
    "end": "967680"
  },
  {
    "text": "here's my score so this answer versus",
    "start": "967680",
    "end": "969680"
  },
  {
    "text": "reference if you go back right this was",
    "start": "969680",
    "end": "971560"
  },
  {
    "text": "what we defined here so that's this",
    "start": "971560",
    "end": "974199"
  },
  {
    "text": "answer evaluator answer versus reference",
    "start": "974199",
    "end": "976680"
  },
  {
    "text": "we set as the key here and this is just",
    "start": "976680",
    "end": "978680"
  },
  {
    "text": "using LMS judge to compare the reference",
    "start": "978680",
    "end": "981399"
  },
  {
    "text": "answer to our LM generate answer right",
    "start": "981399",
    "end": "984040"
  },
  {
    "text": "that's all it's happening here and then",
    "start": "984040",
    "end": "986120"
  },
  {
    "text": "this uh tool calls an exact order score",
    "start": "986120",
    "end": "989120"
  },
  {
    "text": "is what we Define down here and that's",
    "start": "989120",
    "end": "991959"
  },
  {
    "text": "the key here and again this was just",
    "start": "991959",
    "end": "993519"
  },
  {
    "text": "saying hey do the tool calls follow each",
    "start": "993519",
    "end": "995880"
  },
  {
    "text": "either one of these two that's all it is",
    "start": "995880",
    "end": "998040"
  },
  {
    "text": "right so here's the story um this is",
    "start": "998040",
    "end": "1001120"
  },
  {
    "text": "what we just ran llama",
    "start": "1001120",
    "end": "1003160"
  },
  {
    "text": "3.1 my aners accurate score is 80% and",
    "start": "1003160",
    "end": "1006959"
  },
  {
    "text": "that's run against three repetitions so",
    "start": "1006959",
    "end": "1008560"
  },
  {
    "text": "80% overall pretty good and the tool",
    "start": "1008560",
    "end": "1011720"
  },
  {
    "text": "calls 100% so it's always calling a",
    "start": "1011720",
    "end": "1013800"
  },
  {
    "text": "reasonable tool trajectory so that's",
    "start": "1013800",
    "end": "1015920"
  },
  {
    "text": "good um total latency around 8 6 seconds",
    "start": "1015920",
    "end": "1020440"
  },
  {
    "text": "not bad that's the p50 P99 is 12 so",
    "start": "1020440",
    "end": "1024000"
  },
  {
    "text": "reasonably quick now let's compare that",
    "start": "1024000",
    "end": "1026079"
  },
  {
    "text": "to some other models right so here's",
    "start": "1026079",
    "end": "1028480"
  },
  {
    "text": "llama 38b so this is the Llama 3 not 3.1",
    "start": "1028480",
    "end": "1032120"
  },
  {
    "text": "this is llama 3 the prior one so you can",
    "start": "1032120",
    "end": "1034280"
  },
  {
    "text": "see performance is different here 60%",
    "start": "1034280",
    "end": "1036160"
  },
  {
    "text": "versus 80 so we've improved performance",
    "start": "1036160",
    "end": "1038640"
  },
  {
    "text": "latency 18 versus 8 so looks like",
    "start": "1038640",
    "end": "1041240"
  },
  {
    "text": "latency is is indeed lower here that's",
    "start": "1041240",
    "end": "1044400"
  },
  {
    "text": "great um pretty cool so basically it",
    "start": "1044400",
    "end": "1048600"
  },
  {
    "text": "looks like uh 3.1 is a clear win uh",
    "start": "1048600",
    "end": "1051960"
  },
  {
    "text": "performance- wise latency Wise It's also",
    "start": "1051960",
    "end": "1053919"
  },
  {
    "text": "very reasonable now this is what's",
    "start": "1053919",
    "end": "1055720"
  },
  {
    "text": "pretty interesting I can compare locally",
    "start": "1055720",
    "end": "1059080"
  },
  {
    "text": "running llama 3.1 to fire function V2 um",
    "start": "1059080",
    "end": "1064760"
  },
  {
    "text": "with the same architecture so this",
    "start": "1064760",
    "end": "1066520"
  },
  {
    "text": "custom agent thing is what I want to be",
    "start": "1066520",
    "end": "1067880"
  },
  {
    "text": "looking at and this is with llama uh",
    "start": "1067880",
    "end": "1071080"
  },
  {
    "text": "370b okay so we can see is 3.18 B",
    "start": "1071080",
    "end": "1075480"
  },
  {
    "text": "running locally performs the same as 70b",
    "start": "1075480",
    "end": "1078919"
  },
  {
    "text": "B through",
    "start": "1078919",
    "end": "1080240"
  },
  {
    "text": "fireworks pretty cool so the 8 pointb 8",
    "start": "1080240",
    "end": "1084640"
  },
  {
    "text": "uh 8 billion with 3.1 is on par with 70b",
    "start": "1084640",
    "end": "1089000"
  },
  {
    "text": "on this particular challenge latency is",
    "start": "1089000",
    "end": "1091320"
  },
  {
    "text": "not much worse running locally 8.6",
    "start": "1091320",
    "end": "1093799"
  },
  {
    "text": "running via um Fireworks 6.37 of course",
    "start": "1093799",
    "end": "1097720"
  },
  {
    "text": "is running a larger model but look",
    "start": "1097720",
    "end": "1100200"
  },
  {
    "text": "you're getting the the same performance",
    "start": "1100200",
    "end": "1101679"
  },
  {
    "text": "on this little toy challenge with only a",
    "start": "1101679",
    "end": "1103320"
  },
  {
    "text": "little bit more latency pretty cool um",
    "start": "1103320",
    "end": "1107000"
  },
  {
    "text": "now let's compare uh you can look down",
    "start": "1107000",
    "end": "1109520"
  },
  {
    "text": "here let's look at custom agent with uh",
    "start": "1109520",
    "end": "1112000"
  },
  {
    "text": "gbd 40 let's we'll not worry about the",
    "start": "1112000",
    "end": "1114280"
  },
  {
    "text": "reacts for now cuz it's a different",
    "start": "1114280",
    "end": "1115760"
  },
  {
    "text": "architecture so let's just look at the",
    "start": "1115760",
    "end": "1117120"
  },
  {
    "text": "custom so I want to compare GPD 40 so 40",
    "start": "1117120",
    "end": "1120480"
  },
  {
    "text": "same performance right uh same tool",
    "start": "1120480",
    "end": "1123120"
  },
  {
    "text": "calling so basically paradine",
    "start": "1123120",
    "end": "1124840"
  },
  {
    "text": "performance and a latency is lower fair",
    "start": "1124840",
    "end": "1127600"
  },
  {
    "text": "enough so it's 5 Seconds versus 8 but",
    "start": "1127600",
    "end": "1129760"
  },
  {
    "text": "look the punch Line's this local",
    "start": "1129760",
    "end": "1132960"
  },
  {
    "text": "model on my laptop free um same",
    "start": "1132960",
    "end": "1137760"
  },
  {
    "text": "performance on my little toy challenge",
    "start": "1137760",
    "end": "1139640"
  },
  {
    "text": "of course right this is again caveat",
    "start": "1139640",
    "end": "1141520"
  },
  {
    "text": "just my little Vibe chest same",
    "start": "1141520",
    "end": "1143640"
  },
  {
    "text": "performances I get with much larger",
    "start": "1143640",
    "end": "1145320"
  },
  {
    "text": "models 40 and fire function V2 with only",
    "start": "1145320",
    "end": "1148480"
  },
  {
    "text": "a little bit worse latency 8.6 versus 6",
    "start": "1148480",
    "end": "1150880"
  },
  {
    "text": "or 5 seconds so again just gives you a",
    "start": "1150880",
    "end": "1153320"
  },
  {
    "text": "sense like this looks like a really good",
    "start": "1153320",
    "end": "1154760"
  },
  {
    "text": "model um I love having these little 8",
    "start": "1154760",
    "end": "1157080"
  },
  {
    "text": "billion parameter models for local",
    "start": "1157080",
    "end": "1158679"
  },
  {
    "text": "testing um I'm excited to try kind of",
    "start": "1158679",
    "end": "1161000"
  },
  {
    "text": "more sophisticated local workflows with",
    "start": "1161000",
    "end": "1162640"
  },
  {
    "text": "it but again I think this sets kind of a",
    "start": "1162640",
    "end": "1164159"
  },
  {
    "text": "new bar for local models um and this",
    "start": "1164159",
    "end": "1166480"
  },
  {
    "text": "just shows how to run it with Lang graph",
    "start": "1166480",
    "end": "1168039"
  },
  {
    "text": "for custom AG agent and again all this",
    "start": "1168039",
    "end": "1170280"
  },
  {
    "text": "eval stuff is totally optional right you",
    "start": "1170280",
    "end": "1172440"
  },
  {
    "text": "know the key thing to look at if you",
    "start": "1172440",
    "end": "1173600"
  },
  {
    "text": "just want to build an agent just look at",
    "start": "1173600",
    "end": "1175120"
  },
  {
    "text": "the Lang graph code all up here uh the",
    "start": "1175120",
    "end": "1177080"
  },
  {
    "text": "evaluation is just kind of how I do my",
    "start": "1177080",
    "end": "1178919"
  },
  {
    "text": "vibe tests and I would encourage you to",
    "start": "1178919",
    "end": "1181039"
  },
  {
    "text": "look at evaluations independently but",
    "start": "1181039",
    "end": "1182880"
  },
  {
    "text": "that's not totally Central for what",
    "start": "1182880",
    "end": "1184760"
  },
  {
    "text": "we're showing here what we're showing",
    "start": "1184760",
    "end": "1185840"
  },
  {
    "text": "here is the ability to um I'll go back",
    "start": "1185840",
    "end": "1188880"
  },
  {
    "text": "to the very beginning build a locally",
    "start": "1188880",
    "end": "1191840"
  },
  {
    "text": "running self corrective rag agent with",
    "start": "1191840",
    "end": "1194600"
  },
  {
    "text": "llama 31 8B that runs locally we'd be",
    "start": "1194600",
    "end": "1197760"
  },
  {
    "text": "able to do that so again encourage you",
    "start": "1197760",
    "end": "1200720"
  },
  {
    "text": "to play with this it seems really",
    "start": "1200720",
    "end": "1201760"
  },
  {
    "text": "promising thanks",
    "start": "1201760",
    "end": "1205280"
  }
]
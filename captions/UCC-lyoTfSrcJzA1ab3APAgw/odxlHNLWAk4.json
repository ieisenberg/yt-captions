[
  {
    "text": "all right hello everyone we are here today to uh chat about linksmith which",
    "start": "1979",
    "end": "7980"
  },
  {
    "text": "is something we're really excited about to launch I will mostly let",
    "start": "7980",
    "end": "13639"
  },
  {
    "text": "me I will mostly let uh ankush and will do most of the talking um we have Charles here to uh help ask",
    "start": "14160",
    "end": "21060"
  },
  {
    "text": "questions help guide us through help explain things um help help uh help with everything really minor Logistics before",
    "start": "21060",
    "end": "27960"
  },
  {
    "text": "we get started this is being recorded um we'll put it on on YouTube later and if you have questions during the",
    "start": "27960",
    "end": "34440"
  },
  {
    "text": "presentation um feel free I think the best place for them is is in the little question box on",
    "start": "34440",
    "end": "41340"
  },
  {
    "text": "the right so there's a little chat section and then below that there's a box with a question mark in it if you put things there",
    "start": "41340",
    "end": "47219"
  },
  {
    "text": "um and then upload ones that that you want to get answered we'll we'll return to those at the end if we see interesting ones",
    "start": "47219",
    "end": "53160"
  },
  {
    "text": "um real time we'll we'll pull those in as well um but yeah super excited to be doing",
    "start": "53160",
    "end": "58980"
  },
  {
    "text": "this and with that I'll hand it off to ankush who will be talking mostly awesome thanks Harrison uh co-founder of",
    "start": "58980",
    "end": "65640"
  },
  {
    "text": "link chain uh really excited to share linksmith with you all um thanks Charles for joining as well uh",
    "start": "65640",
    "end": "72060"
  },
  {
    "text": "so what I'll do is I'll just share my screen and and we can we can get started",
    "start": "72060",
    "end": "78979"
  },
  {
    "text": "okay so this is uh this is like the landing page for langsmith um before I",
    "start": "93060",
    "end": "99600"
  },
  {
    "text": "dive into more detail I just want to point out um the uh the docs so we have like",
    "start": "99600",
    "end": "106320"
  },
  {
    "text": "pretty comprehensive docs here uh their own docs.smith.linejane.com",
    "start": "106320",
    "end": "111720"
  },
  {
    "text": "um everything that we'll go through is you know pretty well documented um and if there are any questions we've also",
    "start": "111720",
    "end": "118140"
  },
  {
    "text": "added a Discord a support Channel um so if you're into any issues",
    "start": "118140",
    "end": "124320"
  },
  {
    "text": "um have any feedback I would love to hear from you there",
    "start": "124320",
    "end": "128840"
  },
  {
    "text": "so uh yeah um ankush maybe so I've you know saw the blog post and I saw like",
    "start": "130020",
    "end": "136260"
  },
  {
    "text": "the Twitter threads and stuff but maybe like a high level of what you know what Lang sniff is is offering",
    "start": "136260",
    "end": "143220"
  },
  {
    "text": "totally yeah so linksmith uh is a unified platform that helps developers debug test monitor and evaluate their LM",
    "start": "143220",
    "end": "151260"
  },
  {
    "text": "applications uh We've made it uh very easy to integrate langsmith with langchain but don't require that you use",
    "start": "151260",
    "end": "158520"
  },
  {
    "text": "it so we also offer a typescript and python SDK that offers a lower level API",
    "start": "158520",
    "end": "166440"
  },
  {
    "text": "that allows you to connect your application with with linksmith there",
    "start": "166440",
    "end": "172080"
  },
  {
    "text": "are a variety of features that we've included in langsmith to help with all this I can walk through them one by one",
    "start": "172080",
    "end": "179099"
  },
  {
    "text": "uh I uh yeah so so uh I can I can I'm happy",
    "start": "179099",
    "end": "187200"
  },
  {
    "text": "to get started with that cool all right so when you when you uh log into langsmith the first thing you",
    "start": "187200",
    "end": "193860"
  },
  {
    "text": "want to do is create an API key I've already created a bunch um arguably too many",
    "start": "193860",
    "end": "199560"
  },
  {
    "text": "so uh then you log in and then you'll see uh",
    "start": "199560",
    "end": "205200"
  },
  {
    "text": "the home page which has projects and data sets I'll go through these one by one",
    "start": "205200",
    "end": "210480"
  },
  {
    "text": "um but projects are nothing more than collections of runs that you've executed and locked for the system uh data sets",
    "start": "210480",
    "end": "217620"
  },
  {
    "text": "are where all of your data sets live and all of the runs that you executed against your data sets with uh I'll walk",
    "start": "217620",
    "end": "223860"
  },
  {
    "text": "through this in a bit more detail now so we've added this walkthrough let's do some questions at the high level of that",
    "start": "223860",
    "end": "229860"
  },
  {
    "text": "interface maybe um so like what should I be thinking of as the scale for my project should that",
    "start": "229860",
    "end": "235140"
  },
  {
    "text": "be like one project for an entire application one project for like each",
    "start": "235140",
    "end": "240480"
  },
  {
    "text": "llm powered feature um yeah like what what kind of scale are these projects and runs at",
    "start": "240480",
    "end": "247019"
  },
  {
    "text": "yeah so we've left it like intentionally flexible right now we've seen people uh create a new project for each different",
    "start": "247019",
    "end": "254040"
  },
  {
    "text": "uh for for different applications uh We've we've seen people create projects uh for different days",
    "start": "254040",
    "end": "260760"
  },
  {
    "text": "uh uh we've seen people create projects with different stages of their application",
    "start": "260760",
    "end": "265919"
  },
  {
    "text": "um like maybe that project a staging project a production project uh so it really depends on the use case",
    "start": "265919",
    "end": "272580"
  },
  {
    "text": "um as we start to see people using projects in more opinionated ways uh we",
    "start": "272580",
    "end": "278280"
  },
  {
    "text": "can also reflect those in the platform yeah um and then how big are uh should it you",
    "start": "278280",
    "end": "284340"
  },
  {
    "text": "know like a run that's like a like a series of turns between a user and a",
    "start": "284340",
    "end": "289919"
  },
  {
    "text": "dialogue agent would be like that's a run right so like that's a term for in the in the LinkedIn tracing library to",
    "start": "289919",
    "end": "296940"
  },
  {
    "text": "like run is like an execution from end to end rather than like a single step",
    "start": "296940",
    "end": "303620"
  },
  {
    "text": "yeah so it it depends on uh how your",
    "start": "303660",
    "end": "309000"
  },
  {
    "text": "yeah it depends on like how it's implemented but usually like each step of the conversation will be its own run",
    "start": "309000",
    "end": "314759"
  },
  {
    "text": "oh interesting yeah cool",
    "start": "314759",
    "end": "321380"
  },
  {
    "text": "all right awesome so uh just walking through this uh notebook really quickly",
    "start": "322080",
    "end": "328800"
  },
  {
    "text": "um we uh so this is linked from the docs as",
    "start": "328800",
    "end": "333900"
  },
  {
    "text": "well we have this we have this walkthrough notebook um we uh have some uh prerequisites that",
    "start": "333900",
    "end": "340680"
  },
  {
    "text": "you need to set up uh like log in create an account create an API key",
    "start": "340680",
    "end": "345960"
  },
  {
    "text": "um to run this notebook you'll also need an open AI API key and a API key because we're creating agents that use the",
    "start": "345960",
    "end": "353100"
  },
  {
    "text": "search tool and the openai tool we'll initialize uh my environment",
    "start": "353100",
    "end": "359759"
  },
  {
    "text": "um here I'm setting my only scroll through my let me try to hide my API key",
    "start": "359759",
    "end": "365039"
  },
  {
    "text": "uh which I'll delete after this um so yeah so you'll need to set a few",
    "start": "365039",
    "end": "370500"
  },
  {
    "text": "environment variables uh link chain tracing V2 you'll need to set that to True uh the link chain project is the",
    "start": "370500",
    "end": "377460"
  },
  {
    "text": "project that you want to log to um here I'm using facing walk through uh suffix by unique ID There's the link",
    "start": "377460",
    "end": "384900"
  },
  {
    "text": "chain endpoint uh in your versions of link chain you actually don't even need to specify this so if you specified an",
    "start": "384900",
    "end": "390960"
  },
  {
    "text": "API key um things will automatically get logged to API that's meant.light machine.com",
    "start": "390960",
    "end": "399080"
  },
  {
    "text": "cool and then um I'll initialize the client here this is the client that we offer as part of",
    "start": "400020",
    "end": "405780"
  },
  {
    "text": "the linksmith library here I'll create an agent I'm creating an agent uh with a chat open AI uh chat",
    "start": "405780",
    "end": "415380"
  },
  {
    "text": "model I'm giving it two tools serp API to allow it to search the internet and",
    "start": "415380",
    "end": "420660"
  },
  {
    "text": "om math to allow it to allow it to do a more complex calculations",
    "start": "420660",
    "end": "426500"
  },
  {
    "text": "um so with the langsmith client that's something that kind of like lives the whole time that the chain is executing",
    "start": "427680",
    "end": "434819"
  },
  {
    "text": "like maybe multiple like many runs are happening and one client is responsible for like logging all of those runs",
    "start": "434819",
    "end": "441180"
  },
  {
    "text": "that's correct cool and so what I'll do now is I'll",
    "start": "441180",
    "end": "447060"
  },
  {
    "text": "kick off a bunch of agent runs uh concurrently uh the user could just kind of made up inputs really uh you can you know you",
    "start": "447060",
    "end": "455340"
  },
  {
    "text": "can use any type of agent any type of chain any series of inputs uh we should see them uh traced here in real time the",
    "start": "455340",
    "end": "463500"
  },
  {
    "text": "ones that are uh marked complete are still are are complete the ones that have this little running man single uh",
    "start": "463500",
    "end": "470460"
  },
  {
    "text": "indicate that the run is still in progress and then the exclamation mark indicates an error uh with the with the Run not the system",
    "start": "470460",
    "end": "477539"
  },
  {
    "text": "itself so here you can see uh 10 agent runs",
    "start": "477539",
    "end": "483900"
  },
  {
    "text": "that I've that I that I just uh kicked off and they're they're uh traced here in this project",
    "start": "483900",
    "end": "491060"
  },
  {
    "text": "here you can see um you know uh a bunch of useful uh a",
    "start": "491940",
    "end": "498300"
  },
  {
    "text": "bunch of useful things to to track your runs you can see the overall latency you can",
    "start": "498300",
    "end": "504240"
  },
  {
    "text": "see the token counts per run uh we also allow you to send up arbitrary tags to allow you to better",
    "start": "504240",
    "end": "510660"
  },
  {
    "text": "organize your runs in this case we've just sent zero shot react description as a tag to every run",
    "start": "510660",
    "end": "517140"
  },
  {
    "text": "uh you'll see the name of the of the uh link chain object that you're using in",
    "start": "517140",
    "end": "523080"
  },
  {
    "text": "this case agent executor the input and the output you also have these filters that you can use to to better uh uh",
    "start": "523080",
    "end": "530580"
  },
  {
    "text": "query your runs so if you only want to see runs that are successful you can click on success",
    "start": "530580",
    "end": "536940"
  },
  {
    "text": "um if you only want to see error runs you can you can do that as well if you want to see runs with specific",
    "start": "536940",
    "end": "543720"
  },
  {
    "text": "tags uh you also have that capability we also allow you to filter on things like latency token counts I'm in",
    "start": "543720",
    "end": "551880"
  },
  {
    "text": "addition to tags we also let you send send up arbitrary key value pairs that",
    "start": "551880",
    "end": "557100"
  },
  {
    "text": "you can filter on those as well we have this like custom query language that's more",
    "start": "557100",
    "end": "562560"
  },
  {
    "text": "um uh that's that's documented uh in the in the docs that I that I showed earlier",
    "start": "562560",
    "end": "569760"
  },
  {
    "text": "so you can use these to create custom query strings nice",
    "start": "569760",
    "end": "575820"
  },
  {
    "text": "um and then so two questions one the like tag thing is that something that I should be using to like",
    "start": "575820",
    "end": "581940"
  },
  {
    "text": "split out things that are all like runs that are all within a single project or",
    "start": "581940",
    "end": "587279"
  },
  {
    "text": "is that something that I should be using to be able to like collate information across multiple projects so that I can find all my zero shot react runs across",
    "start": "587279",
    "end": "595500"
  },
  {
    "text": "every project that I'm doing um versus like flagging them with like oh this is a user who is in our Discord",
    "start": "595500",
    "end": "600899"
  },
  {
    "text": "front end um and that's what I can use when I'm like debugging or monitoring a single",
    "start": "600899",
    "end": "606060"
  },
  {
    "text": "project yeah that's a really good question uh right now in the UI you can't search for",
    "start": "606060",
    "end": "611820"
  },
  {
    "text": "runs across multiple projects even if they have the same tag you can do that I believe with the with the SDK but we",
    "start": "611820",
    "end": "618420"
  },
  {
    "text": "have announced that we haven't added that capability in the UI app uh right like tags are you know are really meant",
    "start": "618420",
    "end": "624480"
  },
  {
    "text": "to be um used however you find them useful uh we",
    "start": "624480",
    "end": "630300"
  },
  {
    "text": "found them useful for um you know organizing uh pieces like you",
    "start": "630300",
    "end": "636240"
  },
  {
    "text": "know different runs within a project",
    "start": "636240",
    "end": "639500"
  },
  {
    "text": "um and then you could you say a little bit more about the like key value pair logging that's like if I want to add",
    "start": "641339",
    "end": "646500"
  },
  {
    "text": "like arbitrary additional metadata that doesn't really fit as a tag that's correct yeah so tags are just",
    "start": "646500",
    "end": "652980"
  },
  {
    "text": "lists uh tags are just like it's just represented as a list of strings really",
    "start": "652980",
    "end": "658680"
  },
  {
    "text": "uh he the metadata is useful when you want to send things up uh that are you",
    "start": "658680",
    "end": "665880"
  },
  {
    "text": "know related to your application so if you have like a mobile application ID if you have a correlation ID uh if you you know",
    "start": "665880",
    "end": "673800"
  },
  {
    "text": "um if you want to assign like a user ID like you know tier to your uh to your traces as well you can you can use that",
    "start": "673800",
    "end": "681540"
  },
  {
    "text": "nice cool um so you can unmest the runs a bit here",
    "start": "681540",
    "end": "687180"
  },
  {
    "text": "um so in this case you can see like that's agent executor called an LM chain which is called a tool which called another LM chain",
    "start": "687180",
    "end": "693180"
  },
  {
    "text": "you can also click into a run uh any row and that will take you to a",
    "start": "693180",
    "end": "698820"
  },
  {
    "text": "run Details page this page has um all of the information that's related",
    "start": "698820",
    "end": "704640"
  },
  {
    "text": "to this specific run in this case this is an agent executor run you can see like the input tokens and the output",
    "start": "704640",
    "end": "710760"
  },
  {
    "text": "tokens if you hover over it you'll see like the total tokens uh you'll see the latency",
    "start": "710760",
    "end": "716940"
  },
  {
    "text": "um the fact that it's a chain uh the tag the input the output you're able to copy",
    "start": "716940",
    "end": "723540"
  },
  {
    "text": "these we have some metadata that we send up as well in this case uh we're sending",
    "start": "723540",
    "end": "728760"
  },
  {
    "text": "like the runtime metadata so the library the library version um the platform python",
    "start": "728760",
    "end": "734880"
  },
  {
    "text": "on runtime information SDK version Etc",
    "start": "734880",
    "end": "739820"
  },
  {
    "text": "you can go through the Run tree to click on different sections of the",
    "start": "740220",
    "end": "746640"
  },
  {
    "text": "Run so as you'll see the agent executor called an llm chain which then called",
    "start": "746640",
    "end": "754680"
  },
  {
    "text": "a chat model in this case we're using chat open AI you can see metadata for every step of",
    "start": "754680",
    "end": "760980"
  },
  {
    "text": "the run so in this case we have some extra metadata about the about the chat",
    "start": "760980",
    "end": "769019"
  },
  {
    "text": "model um so we have the model name we have",
    "start": "769019",
    "end": "774120"
  },
  {
    "text": "some other invocation params like request timeout and we also have the stop sequences that were sent",
    "start": "774120",
    "end": "781860"
  },
  {
    "text": "um and we also actually send up the serialize Manifest so uh you know this",
    "start": "781860",
    "end": "789300"
  },
  {
    "text": "is useful if you want to see exactly how the model was was constructed",
    "start": "789300",
    "end": "795560"
  },
  {
    "text": "cool um for select uh chat models and LOM we",
    "start": "797700",
    "end": "804899"
  },
  {
    "text": "allow you to open the run in a playground environment and here you can see uh that this is",
    "start": "804899",
    "end": "810720"
  },
  {
    "text": "totally configurable and editable so we currently support this for chat open AI uh chat models uh chat anthropic",
    "start": "810720",
    "end": "820380"
  },
  {
    "text": "chat model and uh the regular openai model",
    "start": "820380",
    "end": "825480"
  },
  {
    "text": "you can change the model you can change the temperature you can change the prompt and you can click",
    "start": "825480",
    "end": "832800"
  },
  {
    "text": "submit and then you'll see that you get a result",
    "start": "832800",
    "end": "838200"
  },
  {
    "text": "I'll just make some edits here to show you that you can actually edit this",
    "start": "838200",
    "end": "843200"
  },
  {
    "text": "yeah this allows you to play around with you know the llm parts of your uh you know",
    "start": "843720",
    "end": "851399"
  },
  {
    "text": "of your of your chains so you can easily inspect the raw prompt that was sent to",
    "start": "851399",
    "end": "858839"
  },
  {
    "text": "the uh you know Foundation model API sometimes it's hard to see uh or you",
    "start": "858839",
    "end": "865680"
  },
  {
    "text": "know hard to understand if you're using a chain like how the actual finalized prompt uh or like you know how the high",
    "start": "865680",
    "end": "873120"
  },
  {
    "text": "how the final prompt um uh like you know what it looks like under the hood because there are a lot",
    "start": "873120",
    "end": "879060"
  },
  {
    "text": "of things um uh you know going on before uh",
    "start": "879060",
    "end": "884579"
  },
  {
    "text": "you know before the final prompt is assembled so this is this is helpful",
    "start": "884579",
    "end": "890699"
  },
  {
    "text": "um I want you to see that in an experiment yeah that's nice um and let's see some questions maybe on",
    "start": "890699",
    "end": "899519"
  },
  {
    "text": "this one so that yeah can I see the metadata again maybe",
    "start": "899519",
    "end": "905699"
  },
  {
    "text": "uh yeah okay so this is like this is helping you understand like how you're using your external model API uh yeah",
    "start": "905699",
    "end": "914040"
  },
  {
    "text": "it's generic in a way that like let's say I set up my own llama 2 model and",
    "start": "914040",
    "end": "920220"
  },
  {
    "text": "it's available via an API with those kinds of indications get picked up or what like is there a way I can like you",
    "start": "920220",
    "end": "926459"
  },
  {
    "text": "know write a little bit of of my own code to make sure that it hooks into this metadata collection",
    "start": "926459",
    "end": "932339"
  },
  {
    "text": "yeah so the invocation params will vary per uh model type and so the invocation",
    "start": "932339",
    "end": "938820"
  },
  {
    "text": "params that are specific to llama will get sent up a lot of them are common among the chat models and llms if you",
    "start": "938820",
    "end": "945480"
  },
  {
    "text": "want to send up your own metadata you can uh uh",
    "start": "945480",
    "end": "950660"
  },
  {
    "text": "you know you can you can use like the functionality that I described earlier uh with sending up extra uh you know",
    "start": "950660",
    "end": "958560"
  },
  {
    "text": "arbitrary key value Pairs and that will show up in the metadata section as well got it",
    "start": "958560",
    "end": "964399"
  },
  {
    "text": "okay and for the like going back to that",
    "start": "964399",
    "end": "969420"
  },
  {
    "text": "run page where we could see like the kind of trace of the execution yeah I really like yeah being able to see these",
    "start": "969420",
    "end": "976079"
  },
  {
    "text": "kinds of traces is really helpful when you have like a dynamic uh you know something that's like yeah as dynamic as",
    "start": "976079",
    "end": "982680"
  },
  {
    "text": "Lang chain tool use where just looking at the code doesn't tell you what what like actually happens this seems like",
    "start": "982680",
    "end": "988019"
  },
  {
    "text": "super valuable and helpful um curious like uh what cool things have",
    "start": "988019",
    "end": "993240"
  },
  {
    "text": "you found with this run tree besides like uh you know like the LM math chain examples pretty straightforward what are",
    "start": "993240",
    "end": "1000079"
  },
  {
    "text": "some other things you've found with this run tree that it's uh you know interesting things it's uncovered that",
    "start": "1000079",
    "end": "1005300"
  },
  {
    "text": "you weren't expecting or interesting behaviors yeah I mean you know Roland Harrison",
    "start": "1005300",
    "end": "1011540"
  },
  {
    "text": "also feel free to chime in here but I think um yeah it's when you have when you have",
    "start": "1011540",
    "end": "1016699"
  },
  {
    "text": "an agent and it's like uh and you're in you're iterating on it and you know it takes longer than expected or it's",
    "start": "1016699",
    "end": "1022100"
  },
  {
    "text": "running into like an infinite move problem and getting Crypt up it's really hard to pinpoint exactly like which Step",
    "start": "1022100",
    "end": "1029058"
  },
  {
    "text": "things went wrong uh and so being able to look at the inputs and outputs of",
    "start": "1029059",
    "end": "1034220"
  },
  {
    "text": "every step of the execution lets you better isolate the problem",
    "start": "1034220",
    "end": "1040400"
  },
  {
    "text": "um and then coming back to like what I discussed you know earlier it's it's hard to like",
    "start": "1040400",
    "end": "1047540"
  },
  {
    "text": "um get a good grasp on what exactly",
    "start": "1047540",
    "end": "1052580"
  },
  {
    "text": "The Prompt is that's that's going to the the foundation model like there are a lot of",
    "start": "1052580",
    "end": "1058280"
  },
  {
    "text": "um you know there are a lot of things that happen under the hood in Chains and agents",
    "start": "1058280",
    "end": "1063440"
  },
  {
    "text": "um so you know this allows you to debug on the llm level if that makes sense Yeah Yeah",
    "start": "1063440",
    "end": "1070160"
  },
  {
    "text": "you mentioned debugging testing monitoring and evaluating right yeah so this feels like really great stuff for",
    "start": "1070160",
    "end": "1075860"
  },
  {
    "text": "the debugging I think like the the biggest thing like yeah I think it also really just helps",
    "start": "1075860",
    "end": "1082700"
  },
  {
    "text": "give an understanding of like what's actually going on under the hood and like which calls are being made and in which sequence so like you know even for",
    "start": "1082700",
    "end": "1089660"
  },
  {
    "text": "something that's not an agent like the conversational retrieval qh and you've got like some reframing of the question",
    "start": "1089660",
    "end": "1095000"
  },
  {
    "text": "that can then get sent to a retriever and then you've got those results combined with the original question and the chat history passed in so just",
    "start": "1095000",
    "end": "1101120"
  },
  {
    "text": "seeing that sequence is nice and then um another thing that I've actually used it for is like like there are a bunch of",
    "start": "1101120",
    "end": "1107480"
  },
  {
    "text": "um libraries written on top of link chain so like one of these is like the code interpreter kind of like project that I",
    "start": "1107480",
    "end": "1114200"
  },
  {
    "text": "think we tweeted about on like Sunday um and uh I had no clue what like prompts it was using or what it was even",
    "start": "1114200",
    "end": "1120500"
  },
  {
    "text": "doing under the hood um but because it was using LinkedIn I just turned on kind of like the logging aspect",
    "start": "1120500",
    "end": "1126200"
  },
  {
    "text": "um and then I could see all of that pretty easily and so I think it's also like you know it just helps kind of like",
    "start": "1126200",
    "end": "1131360"
  },
  {
    "text": "shed the lights as you've got these rappers that are getting larger and larger and more interesting and interesting like what actually are the",
    "start": "1131360",
    "end": "1137360"
  },
  {
    "text": "prompts that are being used what is the sequence of calls that are being made those are just whether it's in Lane train or packages on top of Link",
    "start": "1137360",
    "end": "1143059"
  },
  {
    "text": "I've found that like just pretty interesting and fun and insightful to look at yeah it's a really good point actually like you can use linksmith with",
    "start": "1143059",
    "end": "1150440"
  },
  {
    "text": "Frameworks that are built on link chain as well so if you configure environment you'll get you know traces for uh uh for",
    "start": "1150440",
    "end": "1158480"
  },
  {
    "text": "link chain as well even if you're not using Lane chain directly if you're using it indirectly so",
    "start": "1158480",
    "end": "1165220"
  },
  {
    "text": "uh the other things I'll point out here is you can like you know you can rate or run",
    "start": "1165220",
    "end": "1171440"
  },
  {
    "text": "um so you can Mark a run as correct and correct that will show up um as a feedback key value pair and I'll",
    "start": "1171440",
    "end": "1178820"
  },
  {
    "text": "get into feedback uh in more detail in just a minute",
    "start": "1178820",
    "end": "1184160"
  },
  {
    "text": "um but you'll see feedback for for your runs in the feedback section here you can",
    "start": "1184160",
    "end": "1190640"
  },
  {
    "text": "um I already went through uh opening in the playground you can also share your run publicly so",
    "start": "1190640",
    "end": "1197539"
  },
  {
    "text": "if you find a particular Trace uh uh you know interesting",
    "start": "1197539",
    "end": "1203660"
  },
  {
    "text": "in this case I'm actually I actually just shared the the openai run but I can share like the full agent run as well",
    "start": "1203660",
    "end": "1209780"
  },
  {
    "text": "and so you know we've actually added a Discord channel uh I forget what it's called",
    "start": "1209780",
    "end": "1215539"
  },
  {
    "text": "it's like sure sure you're like uh interesting cool cool language faces so",
    "start": "1215539",
    "end": "1220760"
  },
  {
    "text": "uh you know would love to see you know what you all are building",
    "start": "1220760",
    "end": "1225799"
  },
  {
    "text": "um and uh Sierra traces here and you know if you find something that's hard to debug you can you know you can share",
    "start": "1225799",
    "end": "1232039"
  },
  {
    "text": "your you can share your Trace uh this is what it looks like to the the public",
    "start": "1232039",
    "end": "1237260"
  },
  {
    "text": "um and yeah you'll be able to see each step of the trace even when it's shared",
    "start": "1237260",
    "end": "1245139"
  },
  {
    "text": "cool it's like uh Strava but for your Lang chain runs exactly that's exactly",
    "start": "1245240",
    "end": "1251179"
  },
  {
    "text": "it yeah yeah yeah and it's also useful yeah yeah collaborative debugging yeah for",
    "start": "1251179",
    "end": "1257960"
  },
  {
    "text": "making a contribution to life totally yeah yeah um so if you're having a hard time you",
    "start": "1257960",
    "end": "1264320"
  },
  {
    "text": "know debugging one of your link chain agents or chains you know you can click share run you can share Discord",
    "start": "1264320",
    "end": "1270799"
  },
  {
    "text": "um you know someone I'm sure someone will have some insight uh you know if you're working on something particularly fun and you want",
    "start": "1270799",
    "end": "1277520"
  },
  {
    "text": "to uh share that as well or something funny like if an agent goes like terribly wrong and it's just like and",
    "start": "1277520",
    "end": "1283700"
  },
  {
    "text": "it's just like uh infinite looping um and uh you know it's using maybe it's",
    "start": "1283700",
    "end": "1289280"
  },
  {
    "text": "spitting out a bunch of garbage like that's also fun to see so we don't we don't discriminate",
    "start": "1289280",
    "end": "1295039"
  },
  {
    "text": "cool uh one thing uh one other feature I'll highlight and this will kind of take us to the testing and evaluation",
    "start": "1295039",
    "end": "1301280"
  },
  {
    "text": "evaluation uh set of features for linksmith is uh adding to a data set",
    "start": "1301280",
    "end": "1308419"
  },
  {
    "text": "so uh forever for any run you can um add the inputs and outputs as an",
    "start": "1308419",
    "end": "1315980"
  },
  {
    "text": "example to a data set so a data set is meant to be a series of",
    "start": "1315980",
    "end": "1323120"
  },
  {
    "text": "you know ground truth um you know it's supposed to it's meant to contain a series of round-truth examples you can use to to Benchmark",
    "start": "1323120",
    "end": "1331460"
  },
  {
    "text": "um uh other you know chains and agents so I can you know create a new data set",
    "start": "1331460",
    "end": "1338720"
  },
  {
    "text": "a name will be auto-generated um you know I can type in a description if I want to I can click submit",
    "start": "1338720",
    "end": "1345020"
  },
  {
    "text": "um and then this will be this will get saved as that you know particular uh as an example in that data set",
    "start": "1345020",
    "end": "1351919"
  },
  {
    "text": "um I'll actually switch back over to the notebook and I'll I'll walk through uh what this workflow looks like end to end",
    "start": "1351919",
    "end": "1360760"
  },
  {
    "text": "okay so what we're going to do in this section is set up another agent in this case we're going to set up an agent that",
    "start": "1363679",
    "end": "1370880"
  },
  {
    "text": "uses the um uh the function calling capability uh",
    "start": "1370880",
    "end": "1375919"
  },
  {
    "text": "or the sorry the function the function calling models that came out not too long ago and we'll we'll compare",
    "start": "1375919",
    "end": "1383000"
  },
  {
    "text": "um you know how it did uh to the uh initial agent that we set up which was not using uh the function calling model",
    "start": "1383000",
    "end": "1391700"
  },
  {
    "text": "so you can create a data set in the UI you can also create a data set using the",
    "start": "1391700",
    "end": "1398659"
  },
  {
    "text": "client which I'm doing here so in this case I'll create a you know a data set called calculator calculator example",
    "start": "1398659",
    "end": "1404659"
  },
  {
    "text": "data set with the same unique identifier that I suffixed to the project name I'll add a description to it on",
    "start": "1404659",
    "end": "1411620"
  },
  {
    "text": "what I'm doing here is I'm collecting I'm using the client to collect the runs",
    "start": "1411620",
    "end": "1416980"
  },
  {
    "text": "for the project that I specified so this is going to list all the runs that I logged uh earlier in this webinar",
    "start": "1416980",
    "end": "1426760"
  },
  {
    "text": "and then what I'll do is what this line is doing is it's uh creating examples from all of those from",
    "start": "1427760",
    "end": "1436280"
  },
  {
    "text": "All Those runs so it's taking the inputs and the outputs of those runs and then adding them as examples to the data set",
    "start": "1436280",
    "end": "1443419"
  },
  {
    "text": "that I just created in a real in a real world example before you uh you know",
    "start": "1443419",
    "end": "1448460"
  },
  {
    "text": "Mark these as ground truth examples you'll probably want to validate them this is going to be just a simple",
    "start": "1448460",
    "end": "1453860"
  },
  {
    "text": "walkthrough example yeah could I put like if they're calculator ones maybe I would like calculate it in",
    "start": "1453860",
    "end": "1460100"
  },
  {
    "text": "Python could I like return just like a dictionary type thing or uh",
    "start": "1460100",
    "end": "1466720"
  },
  {
    "text": "exactly so uh you can manually create examples as well uh you don't you don't",
    "start": "1466820",
    "end": "1472340"
  },
  {
    "text": "have to create examples from runs so you can create examples as just",
    "start": "1472340",
    "end": "1477919"
  },
  {
    "text": "um so we have we have different we have three different types of data sets we",
    "start": "1477919",
    "end": "1484100"
  },
  {
    "text": "have data sets uh meant to be uh run on over llms we have data sets uh",
    "start": "1484100",
    "end": "1491419"
  },
  {
    "text": "specifically for chat models that store things in message format and then we have arbitrary key value data sets which",
    "start": "1491419",
    "end": "1496820"
  },
  {
    "text": "just have a collection of inputs and outputs so it's very flexible hmm",
    "start": "1496820",
    "end": "1502900"
  },
  {
    "text": "look at this okay so uh",
    "start": "1504679",
    "end": "1510140"
  },
  {
    "text": "what I'm doing here is setting up evaluators to evaluate the",
    "start": "1510140",
    "end": "1518299"
  },
  {
    "text": "runs that I'm about to kick off on the data set that I just created",
    "start": "1518299",
    "end": "1523899"
  },
  {
    "text": "so we have different types of evaluators that are um that you know you can use off the",
    "start": "1523940",
    "end": "1530779"
  },
  {
    "text": "shelf with with Mike Smith we have um uh you know we have correctness",
    "start": "1530779",
    "end": "1536059"
  },
  {
    "text": "evaluators we have evaluators that use embedding distance we have arbitrary",
    "start": "1536059",
    "end": "1541700"
  },
  {
    "text": "um we have we have criteria evaluators that take in that that take in um arbitrary criteria",
    "start": "1541700",
    "end": "1548900"
  },
  {
    "text": "um and um we also allow you to create custom evaluators uh and maybe if we have time",
    "start": "1548900",
    "end": "1555919"
  },
  {
    "text": "you know Wilkin uh jump in um and and show you uh how customer",
    "start": "1555919",
    "end": "1561640"
  },
  {
    "text": "evaluators work as well so here I'm just going to configure the evaluators I'm going to use",
    "start": "1561640",
    "end": "1568120"
  },
  {
    "text": "and then I'm going to run the agent on the data set that I created and then go",
    "start": "1570679",
    "end": "1575840"
  },
  {
    "text": "back to langsmith to see what it looks like",
    "start": "1575840",
    "end": "1579580"
  },
  {
    "text": "cool okay so um let's let's just take a second",
    "start": "1584960",
    "end": "1590480"
  },
  {
    "text": "um you'll see that another project spun up uh and this is actually the project",
    "start": "1590480",
    "end": "1595760"
  },
  {
    "text": "that has the traces for the evaluation chains that are running which is kind of",
    "start": "1595760",
    "end": "1601159"
  },
  {
    "text": "cool um I'll go to data sets actually and um you know you can see the examples",
    "start": "1601159",
    "end": "1608179"
  },
  {
    "text": "that I created in this data set so these are just examples that are taken from the uh you know the Run inputs and",
    "start": "1608179",
    "end": "1614539"
  },
  {
    "text": "outputs um you'll see uh test runs as well",
    "start": "1614539",
    "end": "1621200"
  },
  {
    "text": "um these test runs are runs that were triggered are run over the examples in the data",
    "start": "1621200",
    "end": "1628880"
  },
  {
    "text": "set so if you remember in the notebook I I uh used a run on dataset this is the",
    "start": "1628880",
    "end": "1635900"
  },
  {
    "text": "async version of a run-on data set and I've um you know added the data set name the",
    "start": "1635900",
    "end": "1642260"
  },
  {
    "text": "agent Factory this is like the function that's used to configure agent the evaluation config this is the",
    "start": "1642260",
    "end": "1650000"
  },
  {
    "text": "uh you know configuration uh that specifies which evaluators you want to run and uh any tags as well",
    "start": "1650000",
    "end": "1657919"
  },
  {
    "text": "and the errors that you see here are not errors related to langsmith there are errors related to the agent execution so",
    "start": "1657919",
    "end": "1664640"
  },
  {
    "text": "the agent doesn't always get things right these are locked as ones Asian makes agents can make mistakes believe",
    "start": "1664640",
    "end": "1670580"
  },
  {
    "text": "it or not yeah um awesome so it looks like everything finished up here",
    "start": "1670580",
    "end": "1676340"
  },
  {
    "text": "um so let's let's dive into this in a bit more detail you'll see that the runs that that error don't get evaluated and",
    "start": "1676340",
    "end": "1683240"
  },
  {
    "text": "that's that's on purpose but that's also configurable okay so this is the Run Details page of",
    "start": "1683240",
    "end": "1692360"
  },
  {
    "text": "a run that was triggered on that was run um on on an example",
    "start": "1692360",
    "end": "1699380"
  },
  {
    "text": "so in addition to the input and output that you saw previously you also have this reference output this reference",
    "start": "1699380",
    "end": "1706460"
  },
  {
    "text": "output was the output from the example does",
    "start": "1706460",
    "end": "1711919"
  },
  {
    "text": "that make sense yeah yeah yeah I recognize that yeah awesome in addition to the reference output you",
    "start": "1711919",
    "end": "1719120"
  },
  {
    "text": "also have this header that says you know this run was was uh you know created or",
    "start": "1719120",
    "end": "1724400"
  },
  {
    "text": "run with this example um and you can look at the example uh",
    "start": "1724400",
    "end": "1730640"
  },
  {
    "text": "this is the example detail page and you can look at the runs in this case there's only one run but imagine if I",
    "start": "1730640",
    "end": "1736880"
  },
  {
    "text": "you know did run over data set twice you'll see multiple runs or two runs uh",
    "start": "1736880",
    "end": "1742100"
  },
  {
    "text": "associated with this example um cool and then you'll see",
    "start": "1742100",
    "end": "1749299"
  },
  {
    "text": "um a bunch of feedback which is gets into the fun part so remember all those",
    "start": "1749299",
    "end": "1754520"
  },
  {
    "text": "evaluators that I configured earlier uh well those were used to assign",
    "start": "1754520",
    "end": "1761059"
  },
  {
    "text": "feedback to the run that was triggered on the example so I configured a",
    "start": "1761059",
    "end": "1766940"
  },
  {
    "text": "correctness evaluator an embedding cosine distance evaluator a helpfulness evaluator and a fifth grader fifth",
    "start": "1766940",
    "end": "1772220"
  },
  {
    "text": "grader score evaluator and so if I wanted",
    "start": "1772220",
    "end": "1778820"
  },
  {
    "text": "to dive deeper into exactly what's going on into these evaluator chains I can",
    "start": "1778820",
    "end": "1784580"
  },
  {
    "text": "click on this link and then I can see the the chain uh that",
    "start": "1784580",
    "end": "1790460"
  },
  {
    "text": "was used to evaluate the Run",
    "start": "1790460",
    "end": "1794500"
  },
  {
    "text": "so this is actually the raw prompt that was sent to the uh you know the chat",
    "start": "1795620",
    "end": "1801860"
  },
  {
    "text": "open AI model in this case we're using gpd4 I believe",
    "start": "1801860",
    "end": "1807440"
  },
  {
    "text": "um you know you can see how the prompt was formatted",
    "start": "1807440",
    "end": "1812840"
  },
  {
    "text": "um uh from the from the criteria eval chain and uh you can see",
    "start": "1812840",
    "end": "1818179"
  },
  {
    "text": "um the output and uh this output was parsed and it was it was then",
    "start": "1818179",
    "end": "1823279"
  },
  {
    "text": "um used to assign a feedback score to the run so far",
    "start": "1823279",
    "end": "1829940"
  },
  {
    "text": "yeah yeah that makes sense and it's cool yeah that you can mix language model powered evaluations with maybe",
    "start": "1829940",
    "end": "1836120"
  },
  {
    "text": "deterministic evaluations with uh yeah yeah so we made this intentionally",
    "start": "1836120",
    "end": "1842120"
  },
  {
    "text": "flexible um you know at some point we're going to also allow you to run evaluators",
    "start": "1842120",
    "end": "1847159"
  },
  {
    "text": "directly from the UI but for now um You can uh you can you can run them",
    "start": "1847159",
    "end": "1852980"
  },
  {
    "text": "um uh you know in Python uh one other thing I'll point out is so if you click",
    "start": "1852980",
    "end": "1859580"
  },
  {
    "text": "on any data set um and you click on new test run it will give you the code you need to",
    "start": "1859580",
    "end": "1866480"
  },
  {
    "text": "run the evaluator so what you need to do is just replace this with your own chain",
    "start": "1866480",
    "end": "1871940"
  },
  {
    "text": "or agent and then if you click on you know if I want to evaluate on correctness conciseness relevance you",
    "start": "1871940",
    "end": "1877460"
  },
  {
    "text": "can see the code updating to tell you how to configure your run eval config",
    "start": "1877460",
    "end": "1883520"
  },
  {
    "text": "um and then you do the same thing as I as I did in the notebook which you you know you can use the async uh version",
    "start": "1883520",
    "end": "1888860"
  },
  {
    "text": "you can use the sync version uh run on data set and then um you know you can see feedback uh show up",
    "start": "1888860",
    "end": "1896059"
  },
  {
    "text": "immediately in linksmith nice cool",
    "start": "1896059",
    "end": "1901640"
  },
  {
    "text": "all right um anything else that'd be useful to touch on maybe the exporting features uh",
    "start": "1901640",
    "end": "1908360"
  },
  {
    "text": "yeah so another another interesting thing or another useful feature is you're able you're able to download data",
    "start": "1908360",
    "end": "1916039"
  },
  {
    "text": "sets in two different formats in CSV format in an open AI Json L format so",
    "start": "1916039",
    "end": "1922100"
  },
  {
    "text": "you can use data sets that you've created in langsmith with the openai ebels library we also have examples in",
    "start": "1922100",
    "end": "1929360"
  },
  {
    "text": "the documentation of how to export not only data sets but also runs so we have",
    "start": "1929360",
    "end": "1936140"
  },
  {
    "text": "integrate or we have an example that uses um that shows you how to export runs uh",
    "start": "1936140",
    "end": "1942679"
  },
  {
    "text": "so you can use them with contacts which is which is a it's a you know a monitoring",
    "start": "1942679",
    "end": "1948220"
  },
  {
    "text": "uh you know framework uh that you know that you can use to get a better",
    "start": "1948220",
    "end": "1953659"
  },
  {
    "text": "understanding of what you know what's going on in your llm applications and that uh get it I can pull the data",
    "start": "1953659",
    "end": "1960620"
  },
  {
    "text": "sets down and the runs down with like the SDK the langsmith SDK yes you can",
    "start": "1960620",
    "end": "1965720"
  },
  {
    "text": "yep cool",
    "start": "1965720",
    "end": "1972380"
  },
  {
    "text": "all right [Music] um anything else",
    "start": "1972380",
    "end": "1977720"
  },
  {
    "text": "so you wanted to Showcase advantages and most of them at the end of The Notebook includes a little snippet about like",
    "start": "1977720",
    "end": "1983059"
  },
  {
    "text": "fetching runs yeah yeah yeah that's true to address that question there yeah so",
    "start": "1983059",
    "end": "1988760"
  },
  {
    "text": "simple example there's more examples in the docs yeah totally there are more examples in the docs",
    "start": "1988760",
    "end": "1993980"
  },
  {
    "text": "um uh we actually already you know earlier in the yeah so earlier in the",
    "start": "1993980",
    "end": "1999320"
  },
  {
    "text": "notebook I actually already pulled down runs for my project when I was creating the data set so this is what the list",
    "start": "1999320",
    "end": "2005679"
  },
  {
    "text": "runs uh the client does this is also completely uh configurable",
    "start": "2005679",
    "end": "2012399"
  },
  {
    "text": "so we actually allow you to use the same query language that is present",
    "start": "2012399",
    "end": "2019059"
  },
  {
    "text": "um you know that's present uh in the UI so you know you can you can query for",
    "start": "2019059",
    "end": "2024220"
  },
  {
    "text": "different tags um yeah and you can you can sort of see how this",
    "start": "2024220",
    "end": "2031120"
  },
  {
    "text": "works you have plenty of examples in the documentation for this as well cool",
    "start": "2031120",
    "end": "2037559"
  },
  {
    "text": "um yeah I can bring in some questions that have been coming in the Q a um yeah",
    "start": "2038200",
    "end": "2044080"
  },
  {
    "text": "um so you know really a great question that you want to hear uh you know how do",
    "start": "2044080",
    "end": "2050138"
  },
  {
    "text": "we get an invite code how do we use it so we'll be pretty liberal with the uh you know with the wait list",
    "start": "2050139",
    "end": "2057099"
  },
  {
    "text": "um uh it's been great to see like all the interest uh we have a couple of forums uh on the waitlist flash page",
    "start": "2057099",
    "end": "2062919"
  },
  {
    "text": "that I want to draw attention to so one is for uh the OSS community and for open",
    "start": "2062919",
    "end": "2069280"
  },
  {
    "text": "source oh ancient open source contributors so if you're falling to one of those two buckets uh we have a we",
    "start": "2069280",
    "end": "2075760"
  },
  {
    "text": "have a waitlist form for you so you can get expedited access and we'll be checking that uh pretty frequently uh we",
    "start": "2075760",
    "end": "2082000"
  },
  {
    "text": "also have a waitlist specifically for uh Enterprise users so if you're building",
    "start": "2082000",
    "end": "2087300"
  },
  {
    "text": "uh with lom's at you know at companies and trying to put things into production we want to hear from you and you know",
    "start": "2087300",
    "end": "2093220"
  },
  {
    "text": "would love to give you access as well we've had um you know a lot of great input already",
    "start": "2093220",
    "end": "2098500"
  },
  {
    "text": "from some of our early design partners and you know want to keep that feedback Channel going hmm awesome yeah yeah",
    "start": "2098500",
    "end": "2104200"
  },
  {
    "text": "maybe if you have links to those uh Harrison or Nick share those in the uh",
    "start": "2104200",
    "end": "2109300"
  },
  {
    "text": "in the chat here um broadcast yep um uh you kind of answered this one a",
    "start": "2109300",
    "end": "2116440"
  },
  {
    "text": "little bit with that uh public link sharing um what if uh I want like uh like my",
    "start": "2116440",
    "end": "2122020"
  },
  {
    "text": "team to collaborate on a project what are their options available there yeah that's that's a really good question",
    "start": "2122020",
    "end": "2128380"
  },
  {
    "text": "um we uh yeah so supporting teams is is on a roadmap and",
    "start": "2128380",
    "end": "2134380"
  },
  {
    "text": "we're going to address that pretty soon yeah got it um but yeah but you have that share",
    "start": "2134380",
    "end": "2139480"
  },
  {
    "text": "public links if you're willing to put them now yeah for now the best way to collaborate without sharing uh a login",
    "start": "2139480",
    "end": "2145960"
  },
  {
    "text": "is to uh yeah is to share the share runs",
    "start": "2145960",
    "end": "2151119"
  },
  {
    "text": "um another interesting question so you know tool use and agents is a popular use of of link chain the classic one",
    "start": "2151119",
    "end": "2157480"
  },
  {
    "text": "though is like you know retrieval augmented generation so to what extent is retrieval augmented or like you know",
    "start": "2157480",
    "end": "2163540"
  },
  {
    "text": "integration integration with Vector stores and things like that uh part of langsmith like does that show up in the",
    "start": "2163540",
    "end": "2169960"
  },
  {
    "text": "runs or yeah yeah so we actually already have Integrations uh integration with",
    "start": "2169960",
    "end": "2176020"
  },
  {
    "text": "our retriever abstraction so retriever uh runs show up in linksmith",
    "start": "2176020",
    "end": "2183160"
  },
  {
    "text": "um regarding your other questions about search scores do we have anything on I don't think so this is",
    "start": "2183160",
    "end": "2189540"
  },
  {
    "text": "something we would like to build out yeah yeah so the uh yeah",
    "start": "2189540",
    "end": "2195880"
  },
  {
    "text": "we definitely want to add more metadata uh along with the retriever run so definitely definitely on a roadmap",
    "start": "2195880",
    "end": "2204359"
  },
  {
    "text": "um one other thing I'll mention is we want to support embeddings as well so that's that's soon on our on our roadmap",
    "start": "2204640",
    "end": "2210099"
  },
  {
    "text": "like like um storing embeddings in langsmith you mean logging runs related to embedding",
    "start": "2210099",
    "end": "2216520"
  },
  {
    "text": "so basically like if you you know as part of your uh you know triple augmented generation pipeline uh if you",
    "start": "2216520",
    "end": "2223420"
  },
  {
    "text": "call like one of our embedding models uh we want a vlog events for those as well got it I see",
    "start": "2223420",
    "end": "2230079"
  },
  {
    "text": "um uh there were a couple questions kind of in this theme which is like to what",
    "start": "2230079",
    "end": "2235240"
  },
  {
    "text": "extent is there like low code no code type stuff in line Smith um so like it looked like with the",
    "start": "2235240",
    "end": "2241960"
  },
  {
    "text": "evaluators you could kind of create them via the UI but otherwise you're mostly like writing code in Lane chain or in",
    "start": "2241960",
    "end": "2248740"
  },
  {
    "text": "your preferred framework and sending it to langsmith so code first that's correct yeah so uh it it's meant",
    "start": "2248740",
    "end": "2256599"
  },
  {
    "text": "to integrate seamlessly with link chain um as you as you saw you just have to configure a few environment variables",
    "start": "2256599",
    "end": "2263079"
  },
  {
    "text": "um and if you're not using link chain we also offer a an SDK that you can use and",
    "start": "2263079",
    "end": "2269320"
  },
  {
    "text": "you have like a lower level run tree API that you can use to log assemble and log",
    "start": "2269320",
    "end": "2274660"
  },
  {
    "text": "traces directly um there are some no I mean there's like Lang flow is built on blank chain and so",
    "start": "2274660",
    "end": "2282520"
  },
  {
    "text": "if you um yeah exactly if someone someone in the in the chat probably comment on link below and so if you configured your link",
    "start": "2282520",
    "end": "2289420"
  },
  {
    "text": "chain environment correctly I believe like runs that you execute and Link flow should should also show up I haven't",
    "start": "2289420",
    "end": "2295240"
  },
  {
    "text": "tried it but uh that's that's the way it works yeah",
    "start": "2295240",
    "end": "2300760"
  },
  {
    "text": "cool um there's also been some questions about like um you know our uh",
    "start": "2300760",
    "end": "2308079"
  },
  {
    "text": "like local Docker on-prem like alternative ways of running this",
    "start": "2308079",
    "end": "2313420"
  },
  {
    "text": "um are those gonna be like uh options with Lane Smith",
    "start": "2313420",
    "end": "2318480"
  },
  {
    "text": "yeah so we um right now uh the main way to use",
    "start": "2318640",
    "end": "2325599"
  },
  {
    "text": "linksmith is through the the hosted platform uh you know if you're you know if you're a",
    "start": "2325599",
    "end": "2332500"
  },
  {
    "text": "company that's that's building um with llms and uh",
    "start": "2332500",
    "end": "2338320"
  },
  {
    "text": "you know uh on-premise deployment is is a blocker then you know we can definitely chat",
    "start": "2338320",
    "end": "2345480"
  },
  {
    "text": "there like a couple questions a little wanted a little bit more about like okay if I don't use Lang chain to run things",
    "start": "2347020",
    "end": "2353079"
  },
  {
    "text": "like what does the Run UI show kind of and kind of like how do you integrate with that because they were yeah there",
    "start": "2353079",
    "end": "2358180"
  },
  {
    "text": "were also questions about you know if I'm using an open language model you know um I'm doing it that way like how",
    "start": "2358180",
    "end": "2365020"
  },
  {
    "text": "do I get thing the same benefits of logging stuff to langsmith so it was the question is like if you're",
    "start": "2365020",
    "end": "2371380"
  },
  {
    "text": "if you're using um different types of models or if you're not using Lang chain",
    "start": "2371380",
    "end": "2376839"
  },
  {
    "text": "um yeah I guess uh both of them they're both sort of like you know the we saw the path of like I'm using langchain and",
    "start": "2376839",
    "end": "2383140"
  },
  {
    "text": "I'm calling the open AI API um like what happens when I do don't do those things",
    "start": "2383140",
    "end": "2389440"
  },
  {
    "text": "totally yeah so uh the runs show up the same way right uh so we have we have",
    "start": "2389440",
    "end": "2395619"
  },
  {
    "text": "runs that are attacked as either you know we have distinct categories we have chain runs we have tool runs we have llm",
    "start": "2395619",
    "end": "2400900"
  },
  {
    "text": "runs and retriever runs and we're going to add embedding runs uh very soon uh it",
    "start": "2400900",
    "end": "2407440"
  },
  {
    "text": "doesn't matter which provider you're using or which which specifically if you're using link chain it doesn't",
    "start": "2407440",
    "end": "2412839"
  },
  {
    "text": "matter which uh model wrapper you're using right you could be using the anthropic uh uh wrapper you could be",
    "start": "2412839",
    "end": "2420339"
  },
  {
    "text": "using um you know you could be using really anything and it will show up the",
    "start": "2420339",
    "end": "2425619"
  },
  {
    "text": "same way um if you're not using Lang chain and you're using the SDK to log runs it",
    "start": "2425619",
    "end": "2432520"
  },
  {
    "text": "shows up in the exact same way so um yeah yeah the runs are still grouped",
    "start": "2432520",
    "end": "2438700"
  },
  {
    "text": "into those distinct categories and they're nested um depending on you know if you're using link chain the nesting is kind of taken care of for you because",
    "start": "2438700",
    "end": "2445560"
  },
  {
    "text": "this works through our callback mechanism um and so uh we keep track of the",
    "start": "2445560",
    "end": "2452740"
  },
  {
    "text": "ordering and the nesting as the run is executing in Lane chain if you're not using Lane chain you kind of have to do",
    "start": "2452740",
    "end": "2458980"
  },
  {
    "text": "some extra work to uh make sure that the uh you know the runs are being sent up",
    "start": "2458980",
    "end": "2465700"
  },
  {
    "text": "in the correct order and uh nesting so it's it's kind of like uh it's almost like you're manipulating uh",
    "start": "2465700",
    "end": "2473020"
  },
  {
    "text": "the Dom using JavaScript it's like a very similar API where you're like really creating",
    "start": "2473020",
    "end": "2478540"
  },
  {
    "text": "um you know a root run and then you're appending child children into it um",
    "start": "2478540",
    "end": "2483900"
  },
  {
    "text": "yeah yeah so it's this run tree abstraction is where you would hook in from other things and then it would be",
    "start": "2484420",
    "end": "2490599"
  },
  {
    "text": "you would that you construct that thing and send it vbsdk so that's what you want experience yep",
    "start": "2490599",
    "end": "2497140"
  },
  {
    "text": "and you know if there are suggestions on how to make this a smoother experience you know we're all ears",
    "start": "2497140",
    "end": "2503980"
  },
  {
    "text": "um cool another uh popular question um so like as you said like the way to",
    "start": "2503980",
    "end": "2510280"
  },
  {
    "text": "use langsmith right now is this hosted version from y'all um so you know what's the what's the",
    "start": "2510280",
    "end": "2515980"
  },
  {
    "text": "pricing situation on this hosted tool uh there's no charge it's beta software",
    "start": "2515980",
    "end": "2521020"
  },
  {
    "text": "we don't charge for beta software so yeah got it um",
    "start": "2521020",
    "end": "2526540"
  },
  {
    "text": "cool uh uh let's see uh there the evaluation stuff is really cool like it's exciting",
    "start": "2526540",
    "end": "2532540"
  },
  {
    "text": "to see um yeah you showed an integration uh through the Json L format that allows",
    "start": "2532540",
    "end": "2537820"
  },
  {
    "text": "you to use things from open AI there were um so there's some interest definitely also from people to hear more about",
    "start": "2537820",
    "end": "2544660"
  },
  {
    "text": "those evaluation capabilities like could you run them against like academic benchmarks do you have maybe",
    "start": "2544660",
    "end": "2550060"
  },
  {
    "text": "implementations of those academic benchmarks or would we like go through the open AI evals API to do that or",
    "start": "2550060",
    "end": "2557200"
  },
  {
    "text": "eval's library to do that yeah um yeah so",
    "start": "2557200",
    "end": "2564160"
  },
  {
    "text": "we I mean we allow you to like upload arbitrary data sets to the platform",
    "start": "2564160",
    "end": "2569680"
  },
  {
    "text": "which can help alleviate you know some of these uh I guess it can help answer some of these questions so we currently",
    "start": "2569680",
    "end": "2576700"
  },
  {
    "text": "allow you to upload arbitrary data in CSV format um we also want to add",
    "start": "2576700",
    "end": "2583119"
  },
  {
    "text": "um so basically if there's a you know a CSV to save the set that you really like and you want to evaluate against you",
    "start": "2583119",
    "end": "2588460"
  },
  {
    "text": "know you can do it you can use that um we also want to support soon Json L format for uploading so we we offer that",
    "start": "2588460",
    "end": "2596079"
  },
  {
    "text": "for exporting but if there's a data set and open AI emails that you really like we want to make sure that you can use it",
    "start": "2596079",
    "end": "2601240"
  },
  {
    "text": "in linksmith as well um we'll in Harrison if you have other thoughts you know feel free to chime in",
    "start": "2601240",
    "end": "2606460"
  },
  {
    "text": "here but yeah we want to make this as flexible and open as possible um and uh we want to make it work with",
    "start": "2606460",
    "end": "2612940"
  },
  {
    "text": "whatever uh evaluation mechanism you want to if you want to use yeah I mean I think the only thing I",
    "start": "2612940",
    "end": "2618819"
  },
  {
    "text": "would add is that like I think this is really focused on helping you create kind of like custom evaluators for your",
    "start": "2618819",
    "end": "2624220"
  },
  {
    "text": "data and do that um basically what we see is that you know when you're working on your own",
    "start": "2624220",
    "end": "2630040"
  },
  {
    "text": "application and you know part of the power of alums is they can power so many different applications like generic",
    "start": "2630040",
    "end": "2635920"
  },
  {
    "text": "stuff is not amazingly useful you want to test it on your own data you want your own evaluation metrics will work on like",
    "start": "2635920",
    "end": "2642940"
  },
  {
    "text": "creating a big library of those but I think first and foremost we want to make it really easy for people to just do it",
    "start": "2642940",
    "end": "2648579"
  },
  {
    "text": "on their own stuff because I think that's the most Surefire way we've seen so um",
    "start": "2648579",
    "end": "2654420"
  },
  {
    "text": "uh what about um what about human feedback I saw that there was like you I",
    "start": "2655560",
    "end": "2660880"
  },
  {
    "text": "saw the like rating a run thing via the UI um is there a way to like kick off",
    "start": "2660880",
    "end": "2665920"
  },
  {
    "text": "annotators as an evaluator or is it like you'd want your annotators kind of like going in and maybe uploading their stuff",
    "start": "2665920",
    "end": "2672520"
  },
  {
    "text": "from label Studio into langsmith like do you have any thoughts on the flow there for human labels totally",
    "start": "2672520",
    "end": "2679720"
  },
  {
    "text": "um so yeah that is supported 100 um and a really uh common developer",
    "start": "2679720",
    "end": "2687220"
  },
  {
    "text": "workflow we've seen is attaching like uh you know if you're if you're building a chat agent or a chat bot and uh you add",
    "start": "2687220",
    "end": "2695859"
  },
  {
    "text": "like a feedback bucket feedback button to your outputs uh you can actually hook that up to langsmith so that uh you can",
    "start": "2695859",
    "end": "2703780"
  },
  {
    "text": "send that feedback to the system and then you can and that you can like filter your runs",
    "start": "2703780",
    "end": "2710560"
  },
  {
    "text": "on that feedback so you can assign like a specific feedback key like app user",
    "start": "2710560",
    "end": "2716140"
  },
  {
    "text": "feedback or whatever you want to call it you can filter on that feedback key and you could filter for specific feedback",
    "start": "2716140",
    "end": "2721240"
  },
  {
    "text": "values as well like give me runs that have a feedback value of of one right if you're using like in the simplest form",
    "start": "2721240",
    "end": "2727660"
  },
  {
    "text": "like zero one feedback right and then you can add these runs you can bulk export them to a data set so you've had",
    "start": "2727660",
    "end": "2734800"
  },
  {
    "text": "this like evolving sort of uh uh data set where you can that you can use to",
    "start": "2734800",
    "end": "2741940"
  },
  {
    "text": "evaluate um you know newer versions of your application",
    "start": "2741940",
    "end": "2747339"
  },
  {
    "text": "um you can use them you know you can download them you can use them in uh in few shot prompts",
    "start": "2747339",
    "end": "2753880"
  },
  {
    "text": "um maybe you can also use them in like you know fine tuning if it's like L1 data as well and does that feedback do I",
    "start": "2753880",
    "end": "2761680"
  },
  {
    "text": "need that to be available at the time that I'm like before the Run finishes or is it something I can kind of like join",
    "start": "2761680",
    "end": "2767560"
  },
  {
    "text": "later yeah you can you can do it at whatever Point um you just need the wrong ID so",
    "start": "2767560",
    "end": "2773380"
  },
  {
    "text": "we actually offer a a mechanism to like if you're using Lang chain you can grab",
    "start": "2773380",
    "end": "2779680"
  },
  {
    "text": "the Run ID after the run completes uh it's it's actually returned as part of",
    "start": "2779680",
    "end": "2785200"
  },
  {
    "text": "the result um we have we could in Python you pass in a flag that says return uh run",
    "start": "2785200",
    "end": "2791920"
  },
  {
    "text": "metadata I believe uh I can I can double check that and link to the documentations offline and in in",
    "start": "2791920",
    "end": "2797859"
  },
  {
    "text": "JavaScript I believe it's just returned automatically and so you grab that ID and then you can",
    "start": "2797859",
    "end": "2804099"
  },
  {
    "text": "um use the use the SDK to assign feedback to that run if you have a run",
    "start": "2804099",
    "end": "2810579"
  },
  {
    "text": "that's been executed like a while ago um right uh you can you can list you can",
    "start": "2810579",
    "end": "2817240"
  },
  {
    "text": "use like the list runs method of the client uh you can grab um you know you can grab a set of run",
    "start": "2817240",
    "end": "2823300"
  },
  {
    "text": "IDs and you can you know you can like uh annotate them uh that way as well",
    "start": "2823300",
    "end": "2830500"
  },
  {
    "text": "cool and um so at the beginning we started with",
    "start": "2830500",
    "end": "2835540"
  },
  {
    "text": "looking at the logging runs and looking at those trees and traces and the",
    "start": "2835540",
    "end": "2841000"
  },
  {
    "text": "playground that's like the debugging kind of side of things the saving the",
    "start": "2841000",
    "end": "2846339"
  },
  {
    "text": "data sets is great for the evaluation component and also for kind of like",
    "start": "2846339",
    "end": "2851440"
  },
  {
    "text": "testing I can imagine building like my CI CD for my language models out of",
    "start": "2851440",
    "end": "2856599"
  },
  {
    "text": "logged data sets um one thing that I don't think ice is",
    "start": "2856599",
    "end": "2861760"
  },
  {
    "text": "clear to me is like the um like monitoring stuff where it's sort of like",
    "start": "2861760",
    "end": "2867040"
  },
  {
    "text": "looking at the state of an application um we're like looking for say like user",
    "start": "2867040",
    "end": "2872619"
  },
  {
    "text": "misbehavior so like could you yeah tell us a little bit more about how monitoring is supported with langsmith",
    "start": "2872619",
    "end": "2879760"
  },
  {
    "text": "totally um so you know we have basic we have like a",
    "start": "2879760",
    "end": "2885099"
  },
  {
    "text": "basic version of monitoring that we support right now which is uh you know",
    "start": "2885099",
    "end": "2890319"
  },
  {
    "text": "being able to track latency being able to track tokens which are associated with the costs uh being able to track",
    "start": "2890319",
    "end": "2897339"
  },
  {
    "text": "feedback for your runs being able to filter on all those things get counts for you know different you know like",
    "start": "2897339",
    "end": "2903280"
  },
  {
    "text": "runs that use uh more than like a thousand tokens runs that take longer than 30 seconds so we support all that",
    "start": "2903280",
    "end": "2910240"
  },
  {
    "text": "right now we do definitely uh want to offer a better bondering",
    "start": "2910240",
    "end": "2918640"
  },
  {
    "text": "experience and so we want to provide even more analytics about your runs you want to provide time series data so you",
    "start": "2918640",
    "end": "2924640"
  },
  {
    "text": "can like track costs and metrics over time if they're arbitrary you know if they're things that you want to",
    "start": "2924640",
    "end": "2930520"
  },
  {
    "text": "arbitrary like metadata that you want to send up with your runs as well uh we you know we're already tracking those but",
    "start": "2930520",
    "end": "2936819"
  },
  {
    "text": "giving you a better uh view of how that data shifts like over time could also be",
    "start": "2936819",
    "end": "2941980"
  },
  {
    "text": "useful so uh we don't have all the answers right now but we know that like",
    "start": "2941980",
    "end": "2949359"
  },
  {
    "text": "better tracking especially like on the time access is missing and that's probably something that we want to add",
    "start": "2949359",
    "end": "2955000"
  },
  {
    "text": "very soon got it yeah so that's like yeah time series the kind of things you might see",
    "start": "2955000",
    "end": "2960280"
  },
  {
    "text": "in like yeah grafana or something where it's like metrics over time aggregation",
    "start": "2960280",
    "end": "2965440"
  },
  {
    "text": "queries and their results like yeah histograms um yeah definitely seeing token counts",
    "start": "2965440",
    "end": "2972099"
  },
  {
    "text": "being able to query on them that's really great for kind of yeah like live figuring out a problem or like putting",
    "start": "2972099",
    "end": "2977920"
  },
  {
    "text": "out a fire which you'd love to be able to like kind of take this stuff and like build dashboards out of it yeah yeah for",
    "start": "2977920",
    "end": "2983560"
  },
  {
    "text": "the like yeah data doggy kind of experience yeah",
    "start": "2983560",
    "end": "2988960"
  },
  {
    "text": "um cool yeah looking I think the answer we've most of the like broad themed",
    "start": "2988960",
    "end": "2995020"
  },
  {
    "text": "questions oh um oh yeah so this is a question somebody",
    "start": "2995020",
    "end": "3000300"
  },
  {
    "text": "um wanted to follow up on monitoring what about like uh like integrating this",
    "start": "3000300",
    "end": "3005640"
  },
  {
    "text": "with Prometheus sounds like maybe this person would like to you know maybe put all their Prometheus metrics and um uh",
    "start": "3005640",
    "end": "3012060"
  },
  {
    "text": "into langsmith yeah that's that's an interesting uh",
    "start": "3012060",
    "end": "3018540"
  },
  {
    "text": "Point we've heard that from you know a few others as well uh to be honest we're gonna have a great",
    "start": "3018540",
    "end": "3024839"
  },
  {
    "text": "idea of like what uh data we want to allow into langsmith like I think we want to be",
    "start": "3024839",
    "end": "3031200"
  },
  {
    "text": "fairly structured and opinionated on like what we you know how we how we log things to linksmith however when it",
    "start": "3031200",
    "end": "3037079"
  },
  {
    "text": "comes to exporting data from langsmith to other platforms that's where we want to be like super flexible",
    "start": "3037079",
    "end": "3044040"
  },
  {
    "text": "um so if you want to like uh export runs your own data warehouse if you want to",
    "start": "3044040",
    "end": "3049260"
  },
  {
    "text": "if you or if you're already using your own bi tool and you don't want to if you don't if you don't want another set of",
    "start": "3049260",
    "end": "3054300"
  },
  {
    "text": "charts that you want to look at right we want to make this as uh seamless of an experience as possible",
    "start": "3054300",
    "end": "3060780"
  },
  {
    "text": "um and not interrupted pure workflow so I guess maybe higher level answer the",
    "start": "3060780",
    "end": "3066540"
  },
  {
    "text": "question um exporting if you want to support all the things logging uh will be a little bit more",
    "start": "3066540",
    "end": "3073859"
  },
  {
    "text": "selective about but you know if there's if they're big use cases that we're missing and I would love to um would love to hear about those",
    "start": "3073859",
    "end": "3082099"
  },
  {
    "text": "um yes um questions here",
    "start": "3083700",
    "end": "3088980"
  },
  {
    "text": "it's not a good one oh yeah so like you have your data sets you can run evaluations against it and you get those",
    "start": "3088980",
    "end": "3095520"
  },
  {
    "text": "like numbers um then maybe you can't you want to get",
    "start": "3095520",
    "end": "3101520"
  },
  {
    "text": "like a high level answer of like what was the like average value on that fifth grader evaluation or um something like",
    "start": "3101520",
    "end": "3108660"
  },
  {
    "text": "that so it looked like it would be easy in what you showed to like find a particular example and be like why did I",
    "start": "3108660",
    "end": "3114000"
  },
  {
    "text": "get a zero on my helpfulness on this particular example but what about",
    "start": "3114000",
    "end": "3119339"
  },
  {
    "text": "um you know kind of seeing like how overall one model did relative to",
    "start": "3119339",
    "end": "3125400"
  },
  {
    "text": "another one like um like a model leaderboard as uh Nicholas asked about",
    "start": "3125400",
    "end": "3132260"
  },
  {
    "text": "yeah so uh we all we already aggregate feedback",
    "start": "3132839",
    "end": "3139559"
  },
  {
    "text": "stats per run right so um yeah I guess we do like okay so if you",
    "start": "3139559",
    "end": "3146940"
  },
  {
    "text": "want to compare this kind of gets into tracking like specific you know chain",
    "start": "3146940",
    "end": "3155520"
  },
  {
    "text": "specific models and like um seeing how they Stack Up in terms of",
    "start": "3155520",
    "end": "3160980"
  },
  {
    "text": "like feedback or other metrics uh to be honest we like we can we can support that right",
    "start": "3160980",
    "end": "3169200"
  },
  {
    "text": "now just by using like you know different projects for each you know configuration of your of your retainer",
    "start": "3169200",
    "end": "3175380"
  },
  {
    "text": "model but uh tracking like on a specific instance of a model is is something",
    "start": "3175380",
    "end": "3183480"
  },
  {
    "text": "that's on our on our roadmap yeah did that sort of answer the question or",
    "start": "3183480",
    "end": "3189540"
  },
  {
    "text": "was it completely yeah yeah go ahead but",
    "start": "3189540",
    "end": "3195839"
  },
  {
    "text": "the data set page because you have the touchdown there but yeah on the model level across data sets is something that's yeah yeah that's that's the view",
    "start": "3195839",
    "end": "3203160"
  },
  {
    "text": "that's still in the works I can see like I have one run that was",
    "start": "3203160",
    "end": "3209339"
  },
  {
    "text": "like not just a single like question answer pair but like all the question answered pairs again yeah and I can look",
    "start": "3209339",
    "end": "3215760"
  },
  {
    "text": "at that at a high level aggregated metric compared to another one and be like okay like my um you know my code",
    "start": "3215760",
    "end": "3222599"
  },
  {
    "text": "coverage for my test did not go down my eval on our like q a eval set in line",
    "start": "3222599",
    "end": "3228119"
  },
  {
    "text": "Smith uh you know went up so we're ready to uh you know PR this",
    "start": "3228119",
    "end": "3233940"
  },
  {
    "text": "yep cool",
    "start": "3233940",
    "end": "3237660"
  },
  {
    "text": "all right I think we covered most of the kind of broad themes for questions",
    "start": "3241440",
    "end": "3246900"
  },
  {
    "text": "um so uh yeah thanks for uh thanks for walking me through langsmith and uh it",
    "start": "3246900",
    "end": "3252720"
  },
  {
    "text": "looks like a pretty useful tool yeah awesome thanks thanks so much",
    "start": "3252720",
    "end": "3257880"
  },
  {
    "text": "Charles really appreciate you uh uh you know helping out with this with this webinar",
    "start": "3257880",
    "end": "3263880"
  },
  {
    "text": "um thanks for joining Charles always fun",
    "start": "3263880",
    "end": "3268880"
  },
  {
    "text": "um also folks were asking about like you know links for The Notebook for the docs",
    "start": "3269940",
    "end": "3275400"
  },
  {
    "text": "stuff like that so maybe toss those into the chat um before we go so that people can people can find them and try it out yeah",
    "start": "3275400",
    "end": "3282660"
  },
  {
    "text": "yeah I'm gonna I'm gonna link a bunch of things right now cool all right",
    "start": "3282660",
    "end": "3289819"
  },
  {
    "text": "see ya yep",
    "start": "3290579",
    "end": "3295280"
  }
]
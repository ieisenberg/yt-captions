[
  {
    "start": "0",
    "end": "24000"
  },
  {
    "text": "Hi all, Will here. This week we are \nexcited to launch the LangMem SDK—a  ",
    "start": "40",
    "end": "4400"
  },
  {
    "text": "library of utilities to help you build \nagents that learn and adapt as they go.",
    "start": "4400",
    "end": "8760"
  },
  {
    "text": "As part of the release, we wanted to \nreview the high-level concepts driving  ",
    "start": "8760",
    "end": "12200"
  },
  {
    "text": "the development of the library, as well as \nshare a mental framework you can use to more  ",
    "start": "12200",
    "end": "16119"
  },
  {
    "text": "effectively leverage memory to build \nmore reliable and personalized agents.",
    "start": "16120",
    "end": "20480"
  },
  {
    "text": "Memory is a broad concept, and we believe \nthat rather than building a generic,  ",
    "start": "20480",
    "end": "24560"
  },
  {
    "start": "24000",
    "end": "51000"
  },
  {
    "text": "general-purpose memory layer, \nmost successful AI applications  ",
    "start": "24560",
    "end": "28279"
  },
  {
    "text": "today will benefit from leveraging domain \nspecificity to accomplish concrete goals.",
    "start": "28280",
    "end": "33520"
  },
  {
    "text": "If you think about the specific capabilities \nand knowledge your agent needs in order to  ",
    "start": "33520",
    "end": "37480"
  },
  {
    "text": "successfully accomplish its tasks, you can \ntypically map these onto distinct memory types.",
    "start": "37480",
    "end": "43680"
  },
  {
    "text": "One analogy I find useful is thinking about \nhow computers represent information. Computers  ",
    "start": "43680",
    "end": "48760"
  },
  {
    "text": "typically distinguish between data, which \nis static or dynamic information, and code,  ",
    "start": "48760",
    "end": "53480"
  },
  {
    "start": "51000",
    "end": "123000"
  },
  {
    "text": "which consists of instructions and procedures. \nWe can think of agent memory in similar terms.",
    "start": "53480",
    "end": "59040"
  },
  {
    "text": "**Semantic memory** acts as the data \nstore. It stores important knowledge,  ",
    "start": "59040",
    "end": "63480"
  },
  {
    "text": "relationships, entities, and other \ninformation that is useful to ground  ",
    "start": "63480",
    "end": "67840"
  },
  {
    "text": "the responses the agent might have \nto the user. **Procedural memory**,  ",
    "start": "67840",
    "end": "71000"
  },
  {
    "text": "on the other hand, acts more like \ncode. It encodes the rules, behaviors,  ",
    "start": "71000",
    "end": "76320"
  },
  {
    "text": "and other information needed for the agent to \nknow how to respond and act in a given situation.",
    "start": "76320",
    "end": "82720"
  },
  {
    "text": "**Episodic memory** sits somewhere in between \nthe two. It stores information about past  ",
    "start": "82720",
    "end": "86440"
  },
  {
    "text": "events in the form of few-shot examples. \nThese examples instruct the agent how to  ",
    "start": "86440",
    "end": "90880"
  },
  {
    "text": "respond—similar to procedural memory—based \non prior attempts, while also encoding a lot  ",
    "start": "90880",
    "end": "96439"
  },
  {
    "text": "of information about what the agent did \nin the past, similar to semantic memory.",
    "start": "96440",
    "end": "100960"
  },
  {
    "text": "Taken together, semantic, procedural, \nand episodic memories tell the agent  ",
    "start": "100960",
    "end": "105920"
  },
  {
    "text": "both what to do and how to act in a given \nsituation. If implemented effectively,  ",
    "start": "105920",
    "end": "111159"
  },
  {
    "text": "these combine with the language model's \nunderlying reasoning abilities and your  ",
    "start": "111160",
    "end": "115040"
  },
  {
    "text": "own code to accomplish whatever task \nyou might need in your application.",
    "start": "115040",
    "end": "119320"
  },
  {
    "text": "Let's go a step further by grounding \neach of these memory types with examples.",
    "start": "119320",
    "end": "124280"
  },
  {
    "start": "123000",
    "end": "288000"
  },
  {
    "text": "Semantic memory encodes facts, knowledge,  ",
    "start": "124800",
    "end": "128560"
  },
  {
    "text": "and relationships into some underlying \nstorage. This is typically what most people  ",
    "start": "128560",
    "end": "133959"
  },
  {
    "text": "think of when they consider long-term \nmemory. People often jump straight to  ",
    "start": "133960",
    "end": "137760"
  },
  {
    "text": "knowledge graphs or vector databases—both of \nwhich are valid ways to store information.",
    "start": "137760",
    "end": "143280"
  },
  {
    "text": "In our experience, we’ve seen two \nrepresentations be the most common:  ",
    "start": "143280",
    "end": "147319"
  },
  {
    "text": "**collections** and **profiles**.",
    "start": "147320",
    "end": "148480"
  },
  {
    "text": "- **Collections:** These refer \nto storing memories as distinct  ",
    "start": "148480",
    "end": "151680"
  },
  {
    "text": "records in some sort of database. In \nthe context of LangMem and LangGraph,  ",
    "start": "151680",
    "end": "155400"
  },
  {
    "text": "these are typically stored in LangGraph’s \nlong-term memory storage layer—the base  ",
    "start": "155400",
    "end": "159280"
  },
  {
    "text": "store. New memories are formed by extracting new \nrecords in the database. Each memory can either  ",
    "start": "159280",
    "end": "164600"
  },
  {
    "text": "be an unstructured string or take on some level \nof structure based on the schema you provide.  ",
    "start": "164600",
    "end": "170160"
  },
  {
    "text": "These schemas can model the specific domain \nof your application if you find that useful.  ",
    "start": "170160",
    "end": "174920"
  },
  {
    "text": "Memories are consolidated and synthesized \neither by taking existing memories and using  ",
    "start": "174920",
    "end": "179560"
  },
  {
    "text": "them to inform new ones or by updating existing \nrecords. These collections can be unbounded and  ",
    "start": "179560",
    "end": "188880"
  },
  {
    "text": "are typically searched using vector search, \nfull-text search, or a combination of both.",
    "start": "190000",
    "end": "194120"
  },
  {
    "text": "For example, LangMem created a semantic memory \nmanager that, when passed a list of messages  ",
    "start": "194120",
    "end": "200200"
  },
  {
    "text": "from a conversation, extracted the following \nmemories: we learned that the user prefers  ",
    "start": "200200",
    "end": "205319"
  },
  {
    "text": "“Lex” (short for Alex) and appreciates \na casual and witty communication style.  ",
    "start": "205320",
    "end": "210200"
  },
  {
    "text": "We also learned specific information about \nLex—such as his proficiency in Python programming  ",
    "start": "210200",
    "end": "214959"
  },
  {
    "text": "and his competitive speedcubing—and additional \npersonality traits that may be recalled later.",
    "start": "214960",
    "end": "223240"
  },
  {
    "text": "- **Profiles:** A profile compresses all \nthe information into a particular schema or  ",
    "start": "227920",
    "end": "234720"
  },
  {
    "text": "a one-pager about a particular user. These are \ncommon in user-facing chatbots where you have  ",
    "start": "234720",
    "end": "240000"
  },
  {
    "text": "specific details such as a user’s name, age, \nfriends, or other key details. New memories  ",
    "start": "240000",
    "end": "248520"
  },
  {
    "text": "are formed by continuously updating this \nsingle representation. This approach helps  ",
    "start": "248520",
    "end": "253320"
  },
  {
    "text": "reduce irrelevant content, though it may also \nresult in the loss of information that wasn’t  ",
    "start": "253320",
    "end": "262320"
  },
  {
    "text": "modeled in the profile. A pragmatic use case \nfor profiles is that they’re easy to render  ",
    "start": "262320",
    "end": "269880"
  },
  {
    "text": "in a UI. If you have a user-facing chatbot, the \nagent can display what it knows about the user,  ",
    "start": "269880",
    "end": "276560"
  },
  {
    "text": "and the user can collaborate on \nthe memory. For example, if the  ",
    "start": "276560",
    "end": "279280"
  },
  {
    "text": "agent assumes you prefer your name to be \n“Tom” but you actually prefer “Thomas,”  ",
    "start": "279280",
    "end": "284240"
  },
  {
    "text": "you can directly modify the profile, and the \nagent will immediately update its behavior.",
    "start": "284240",
    "end": "288880"
  },
  {
    "start": "288000",
    "end": "369000"
  },
  {
    "text": "Procedural memory tells the agent how to respond. \nIn our experience, this typically takes the form  ",
    "start": "288880",
    "end": "294640"
  },
  {
    "text": "of a subset of the system prompt in your LLM. \nThis prompt fragment can encode user preferences,  ",
    "start": "294640",
    "end": "299640"
  },
  {
    "text": "core agent behavior, and other conditionals and \nrules that the agent should know to accomplish  ",
    "start": "300560",
    "end": "305480"
  },
  {
    "text": "its task. A common example is the response \nstyle: if you ask ChatGPT today to draft a  ",
    "start": "305480",
    "end": "313600"
  },
  {
    "text": "blog post about memory, the output might \nnot reflect your preferred style. Rather  ",
    "start": "313600",
    "end": "319600"
  },
  {
    "text": "than manually writing and restarting the \nsystem prompt for every new conversation,  ",
    "start": "319600",
    "end": "326720"
  },
  {
    "text": "the agent should learn over time \nthat you prefer a particular voice.",
    "start": "326720",
    "end": "329880"
  },
  {
    "text": "A simpler example is having it remember that \nyou prefer writing with proper TypeScript rather  ",
    "start": "329880",
    "end": "336200"
  },
  {
    "text": "than raw JavaScript, or that you favor front-end \ndevelopment over back-end. It can even infer that,  ",
    "start": "336200",
    "end": "343000"
  },
  {
    "text": "since you are now an expert in AI, it doesn't \nneed to rehash all the beginner-level content  ",
    "start": "343000",
    "end": "348440"
  },
  {
    "text": "before diving into advanced concepts. LangMem \nexposes this through prompt optimization,  ",
    "start": "348440",
    "end": "356920"
  },
  {
    "text": "which is designed to learn online from feedback \nor natural conversational examples. We go into  ",
    "start": "356920",
    "end": "363200"
  },
  {
    "text": "more detail in our walkthrough on how to use \nthe prompt optimizers in a separate video.",
    "start": "363200",
    "end": "368120"
  },
  {
    "start": "369000",
    "end": "405000"
  },
  {
    "text": "Episodic memory stores information from past \nexperiences. It encodes both how the agent  ",
    "start": "369320",
    "end": "374440"
  },
  {
    "text": "should respond and what happened in the past. \nThis usually relies on feedback—either from  ",
    "start": "374440",
    "end": "380560"
  },
  {
    "text": "explicit user signals, such as a thumbs up, or \nfrom auto-evaluation by analyzing interactions  ",
    "start": "380560",
    "end": "386440"
  },
  {
    "text": "and recognizing successful outcomes. The agent can \nsave the trajectory of the input along with the  ",
    "start": "386440",
    "end": "392720"
  },
  {
    "text": "expected output to the store. In future rounds, \nit can fetch these memories semantically based  ",
    "start": "392720",
    "end": "397320"
  },
  {
    "text": "on similarities, thereby achieving similarly good \nbehavior and avoiding divergence on hard examples.",
    "start": "397320",
    "end": "403000"
  },
  {
    "text": "In conclusion, memory is an exciting topic \nand a core component in building adaptive,  ",
    "start": "403000",
    "end": "408800"
  },
  {
    "start": "405000",
    "end": "439000"
  },
  {
    "text": "personalized, and self-improving \nagents. For the foreseeable future,  ",
    "start": "408800",
    "end": "412400"
  },
  {
    "text": "we believe that most successful applications \nof memory will be application-specific.  ",
    "start": "412400",
    "end": "416639"
  },
  {
    "text": "Engineers who start by thinking about \nthe type of information an agent needs  ",
    "start": "416640",
    "end": "421480"
  },
  {
    "text": "to learn in order to know what to do and \nhow to act will find the most success.",
    "start": "421480",
    "end": "426160"
  },
  {
    "text": "While this video is purely conceptual,  ",
    "start": "426160",
    "end": "428320"
  },
  {
    "text": "we encourage you to check out the LangMem \ndocs as well as our other videos on how to  ",
    "start": "428320",
    "end": "433160"
  },
  {
    "text": "apply LangMem and these memory concepts in your \nagents. Thank you again, and see you next time.",
    "start": "433160",
    "end": "438040"
  }
]
[
  {
    "text": "what's up everyone it's brace from Lang",
    "start": "719",
    "end": "2120"
  },
  {
    "text": "chain and in today's video we're going",
    "start": "2120",
    "end": "3439"
  },
  {
    "text": "to be talking about all things streaming",
    "start": "3439",
    "end": "5319"
  },
  {
    "text": "with langra we're going to cover the",
    "start": "5319",
    "end": "7319"
  },
  {
    "text": "four main streaming methods events",
    "start": "7319",
    "end": "9920"
  },
  {
    "text": "messages updates and values we're then",
    "start": "9920",
    "end": "12960"
  },
  {
    "text": "going to jump in some code and see",
    "start": "12960",
    "end": "14320"
  },
  {
    "text": "exactly how we can invoke them via the",
    "start": "14320",
    "end": "16800"
  },
  {
    "text": "runnable code and log all the outputs to",
    "start": "16800",
    "end": "19039"
  },
  {
    "text": "the terminal where we can then inspect",
    "start": "19039",
    "end": "20640"
  },
  {
    "text": "exactly what data was outputed and we",
    "start": "20640",
    "end": "22840"
  },
  {
    "text": "can talk about why after that we're",
    "start": "22840",
    "end": "24720"
  },
  {
    "text": "going to open it up in a simple",
    "start": "24720",
    "end": "26480"
  },
  {
    "text": "streaming playground chatbot where we",
    "start": "26480",
    "end": "28760"
  },
  {
    "text": "can invoke our back end uh toggle the",
    "start": "28760",
    "end": "31400"
  },
  {
    "text": "different streaming modes and see how",
    "start": "31400",
    "end": "33000"
  },
  {
    "text": "that data is rendered on our streaming",
    "start": "33000",
    "end": "35520"
  },
  {
    "text": "playground based on the different",
    "start": "35520",
    "end": "36840"
  },
  {
    "text": "streaming mode we selected and then",
    "start": "36840",
    "end": "38600"
  },
  {
    "text": "finally we can talk about some use cases",
    "start": "38600",
    "end": "40239"
  },
  {
    "text": "and where you might want to use these",
    "start": "40239",
    "end": "41840"
  },
  {
    "text": "different streaming modes so the first",
    "start": "41840",
    "end": "43960"
  },
  {
    "text": "streaming mode to talk about is the",
    "start": "43960",
    "end": "45360"
  },
  {
    "text": "events mode this is our most",
    "start": "45360",
    "end": "47079"
  },
  {
    "text": "comprehensive mode which allows you to",
    "start": "47079",
    "end": "49520"
  },
  {
    "text": "stream back every single action which is",
    "start": "49520",
    "end": "52399"
  },
  {
    "text": "occurring inside of your graph or your",
    "start": "52399",
    "end": "54719"
  },
  {
    "text": "run as it happens in near real time",
    "start": "54719",
    "end": "57520"
  },
  {
    "text": "there are three main types of events",
    "start": "57520",
    "end": "59519"
  },
  {
    "text": "which will be yielded during this",
    "start": "59519",
    "end": "61359"
  },
  {
    "text": "streaming mode this is a start end and",
    "start": "61359",
    "end": "64838"
  },
  {
    "text": "stream event every time something",
    "start": "64839",
    "end": "67320"
  },
  {
    "text": "happens inside your run say you invoke a",
    "start": "67320",
    "end": "69720"
  },
  {
    "text": "chat model you will get an on type so in",
    "start": "69720",
    "end": "73119"
  },
  {
    "text": "our case chat Model start event so if",
    "start": "73119",
    "end": "75240"
  },
  {
    "text": "you invoke your chat model you'll get",
    "start": "75240",
    "end": "76520"
  },
  {
    "text": "back an on chat model starts then we",
    "start": "76520",
    "end": "79040"
  },
  {
    "text": "have our streaming type every single",
    "start": "79040",
    "end": "81280"
  },
  {
    "text": "time something inside of your graph or",
    "start": "81280",
    "end": "83119"
  },
  {
    "text": "your run streams not the actual graph",
    "start": "83119",
    "end": "85880"
  },
  {
    "text": "itself but a specific task inside your",
    "start": "85880",
    "end": "88119"
  },
  {
    "text": "graph like chat model stream streaming",
    "start": "88119",
    "end": "90280"
  },
  {
    "text": "back tokens so every single time that",
    "start": "90280",
    "end": "91960"
  },
  {
    "text": "happens you'll get back an on type",
    "start": "91960",
    "end": "94920"
  },
  {
    "text": "stream event so in our case that will be",
    "start": "94920",
    "end": "96880"
  },
  {
    "text": "an on chat model stream event and you'll",
    "start": "96880",
    "end": "99520"
  },
  {
    "text": "get back a series of those for every",
    "start": "99520",
    "end": "100840"
  },
  {
    "text": "single token that's streamed um from the",
    "start": "100840",
    "end": "103079"
  },
  {
    "text": "LM and then finally when it completes",
    "start": "103079",
    "end": "105079"
  },
  {
    "text": "you'll get an on type end event in our",
    "start": "105079",
    "end": "108040"
  },
  {
    "text": "case an on chat model end event this",
    "start": "108040",
    "end": "111320"
  },
  {
    "text": "will occur for every single action taken",
    "start": "111320",
    "end": "113640"
  },
  {
    "text": "inside of your graph um including the",
    "start": "113640",
    "end": "116079"
  },
  {
    "text": "graph start the graph end and so on um",
    "start": "116079",
    "end": "118600"
  },
  {
    "text": "and you get the inputs out and chunks",
    "start": "118600",
    "end": "120520"
  },
  {
    "text": "yielded along with some other metadata",
    "start": "120520",
    "end": "122360"
  },
  {
    "text": "so now let's open up the code and",
    "start": "122360",
    "end": "123920"
  },
  {
    "text": "inspect exactly how we can do this",
    "start": "123920",
    "end": "125920"
  },
  {
    "text": "programmatically first things first",
    "start": "125920",
    "end": "127560"
  },
  {
    "text": "you're going to want to clone the langra",
    "start": "127560",
    "end": "129080"
  },
  {
    "text": "JS examples repository and then open up",
    "start": "129080",
    "end": "131280"
  },
  {
    "text": "the streaming messages directory I've",
    "start": "131280",
    "end": "133680"
  },
  {
    "text": "already done that so I can open it up",
    "start": "133680",
    "end": "135160"
  },
  {
    "text": "here so I have my streaming messages",
    "start": "135160",
    "end": "137160"
  },
  {
    "text": "directory open and I'm going to want to",
    "start": "137160",
    "end": "138519"
  },
  {
    "text": "set a couple environment variables in",
    "start": "138519",
    "end": "140000"
  },
  {
    "text": "myin file that's going to be the open AI",
    "start": "140000",
    "end": "142680"
  },
  {
    "text": "API key and to V API key that's because",
    "start": "142680",
    "end": "145720"
  },
  {
    "text": "we have our graph inside of the runnable",
    "start": "145720",
    "end": "147920"
  },
  {
    "text": "directory here which requires and open",
    "start": "147920",
    "end": "150400"
  },
  {
    "text": "AI key to call the open a API and also a",
    "start": "150400",
    "end": "152440"
  },
  {
    "text": "t search results uh tool which uses the",
    "start": "152440",
    "end": "155080"
  },
  {
    "text": "T um API to essentially search the web",
    "start": "155080",
    "end": "158200"
  },
  {
    "text": "on different queries we then have a",
    "start": "158200",
    "end": "160040"
  },
  {
    "text": "super simple graph that we saw inside of",
    "start": "160040",
    "end": "162800"
  },
  {
    "text": "our L graph Studio here which has two",
    "start": "162800",
    "end": "164920"
  },
  {
    "text": "nodes agent and tools um and the agent",
    "start": "164920",
    "end": "167040"
  },
  {
    "text": "can route either tools or can end so",
    "start": "167040",
    "end": "169720"
  },
  {
    "text": "you're going to open up the stream",
    "start": "169720",
    "end": "171440"
  },
  {
    "text": "events file here and we see we're",
    "start": "171440",
    "end": "173239"
  },
  {
    "text": "importing our graph we're defining our",
    "start": "173239",
    "end": "175120"
  },
  {
    "text": "message saying what's the current stock",
    "start": "175120",
    "end": "176440"
  },
  {
    "text": "price of Apple we're setting our config",
    "start": "176440",
    "end": "179120"
  },
  {
    "text": "um specifically setting the stream",
    "start": "179120",
    "end": "180760"
  },
  {
    "text": "events version to V2 which is the latest",
    "start": "180760",
    "end": "182959"
  },
  {
    "text": "version and then we're passing in our",
    "start": "182959",
    "end": "184799"
  },
  {
    "text": "input and our config to the graph.",
    "start": "184799",
    "end": "187400"
  },
  {
    "text": "stream events method then we're",
    "start": "187400",
    "end": "189640"
  },
  {
    "text": "iterating over the stream and just",
    "start": "189640",
    "end": "191239"
  },
  {
    "text": "logging all of the values to the",
    "start": "191239",
    "end": "193040"
  },
  {
    "text": "terminal so now we can open up our",
    "start": "193040",
    "end": "194360"
  },
  {
    "text": "terminal and invoke this graph so I hit",
    "start": "194360",
    "end": "197400"
  },
  {
    "text": "enter and then we're going to see all of",
    "start": "197400",
    "end": "199480"
  },
  {
    "text": "the different events yield in it's going",
    "start": "199480",
    "end": "201120"
  },
  {
    "text": "to have a large amount of events because",
    "start": "201120",
    "end": "202640"
  },
  {
    "text": "it's yielding in as we see there um an",
    "start": "202640",
    "end": "204840"
  },
  {
    "text": "event for every single action that's",
    "start": "204840",
    "end": "206280"
  },
  {
    "text": "taking place inside of our graph so we",
    "start": "206280",
    "end": "208120"
  },
  {
    "text": "scroll to the top and we can see that",
    "start": "208120",
    "end": "210080"
  },
  {
    "text": "the very first event that was yielded",
    "start": "210080",
    "end": "211720"
  },
  {
    "text": "back to us was the onchain start this is",
    "start": "211720",
    "end": "214439"
  },
  {
    "text": "the first event taken in our graph",
    "start": "214439",
    "end": "216159"
  },
  {
    "text": "because it started uh next we have a",
    "start": "216159",
    "end": "218640"
  },
  {
    "text": "subchain inside there so that's another",
    "start": "218640",
    "end": "220080"
  },
  {
    "text": "onchain start and then onchain end and",
    "start": "220080",
    "end": "222120"
  },
  {
    "text": "that's just for the very first um part",
    "start": "222120",
    "end": "224519"
  },
  {
    "text": "of the graph that sets in invoked then",
    "start": "224519",
    "end": "227120"
  },
  {
    "text": "we start our chat model so we see an on",
    "start": "227120",
    "end": "229239"
  },
  {
    "text": "chat Model start event and this is going",
    "start": "229239",
    "end": "231280"
  },
  {
    "text": "to yield a message so we see the data",
    "start": "231280",
    "end": "233599"
  },
  {
    "text": "field and this data object is going to",
    "start": "233599",
    "end": "235920"
  },
  {
    "text": "contain all of the data that this event",
    "start": "235920",
    "end": "239120"
  },
  {
    "text": "yielded so so in our case it's the input",
    "start": "239120",
    "end": "241480"
  },
  {
    "text": "to this this message um which contains",
    "start": "241480",
    "end": "243720"
  },
  {
    "text": "the messages field because that's the",
    "start": "243720",
    "end": "245239"
  },
  {
    "text": "state uh that we Define for our graph",
    "start": "245239",
    "end": "247680"
  },
  {
    "text": "and this is just going to contain the",
    "start": "247680",
    "end": "248920"
  },
  {
    "text": "message that we input it next we're",
    "start": "248920",
    "end": "251079"
  },
  {
    "text": "going to stream back all the tokens so",
    "start": "251079",
    "end": "252920"
  },
  {
    "text": "for every single time the llm streams a",
    "start": "252920",
    "end": "255239"
  },
  {
    "text": "token we'll get an event for that and we",
    "start": "255239",
    "end": "257079"
  },
  {
    "text": "can see here contains a chunk so this",
    "start": "257079",
    "end": "259840"
  },
  {
    "text": "data object can can contain three Fields",
    "start": "259840",
    "end": "262360"
  },
  {
    "text": "input output and chunk uh the input is",
    "start": "262360",
    "end": "265600"
  },
  {
    "text": "the input that's passed to this",
    "start": "265600",
    "end": "267000"
  },
  {
    "text": "different task um the output is if",
    "start": "267000",
    "end": "269320"
  },
  {
    "text": "something is is returned and a chunk is",
    "start": "269320",
    "end": "271880"
  },
  {
    "text": "if something is streamed so since this",
    "start": "271880",
    "end": "273360"
  },
  {
    "text": "is on chapol stream we're going to get a",
    "start": "273360",
    "end": "275440"
  },
  {
    "text": "series of chunks these contain all of",
    "start": "275440",
    "end": "278039"
  },
  {
    "text": "the different tool calls um as we can",
    "start": "278039",
    "end": "280039"
  },
  {
    "text": "see here it's Prov it's passing in data",
    "start": "280039",
    "end": "281759"
  },
  {
    "text": "into the tool call chunks and those will",
    "start": "281759",
    "end": "283639"
  },
  {
    "text": "be aggregated into a final tool call at",
    "start": "283639",
    "end": "286080"
  },
  {
    "text": "the end of this chat model so as we can",
    "start": "286080",
    "end": "288400"
  },
  {
    "text": "see we have the on chat model end event",
    "start": "288400",
    "end": "290680"
  },
  {
    "text": "and now our tool calls field is",
    "start": "290680",
    "end": "292199"
  },
  {
    "text": "populated with the tool call that then",
    "start": "292199",
    "end": "294240"
  },
  {
    "text": "ended this section of the chain and it",
    "start": "294240",
    "end": "296560"
  },
  {
    "text": "started the next section which is going",
    "start": "296560",
    "end": "298400"
  },
  {
    "text": "to call the T search results API we then",
    "start": "298400",
    "end": "302039"
  },
  {
    "text": "call the tool we get the on tool start",
    "start": "302039",
    "end": "304600"
  },
  {
    "text": "with the input and then the on tool end",
    "start": "304600",
    "end": "306759"
  },
  {
    "text": "with the output that was return from",
    "start": "306759",
    "end": "308320"
  },
  {
    "text": "this from this node in this case it's a",
    "start": "308320",
    "end": "310600"
  },
  {
    "text": "tool message containing the result of",
    "start": "310600",
    "end": "312360"
  },
  {
    "text": "the tool call finally it's going to get",
    "start": "312360",
    "end": "314720"
  },
  {
    "text": "passed back to the LM where we will get",
    "start": "314720",
    "end": "317120"
  },
  {
    "text": "more on chat model stream events",
    "start": "317120",
    "end": "319160"
  },
  {
    "text": "containing the chunks with the final",
    "start": "319160",
    "end": "321160"
  },
  {
    "text": "result of the LM uh streaming back all",
    "start": "321160",
    "end": "323440"
  },
  {
    "text": "those tokens so that's stream events",
    "start": "323440",
    "end": "326080"
  },
  {
    "text": "let's now talk about some different use",
    "start": "326080",
    "end": "327639"
  },
  {
    "text": "cases where this might be useful uh the",
    "start": "327639",
    "end": "329759"
  },
  {
    "text": "very first one which we've used past at",
    "start": "329759",
    "end": "331520"
  },
  {
    "text": "link chain is the generative UI use case",
    "start": "331520",
    "end": "333919"
  },
  {
    "text": "where you want to be constantly updating",
    "start": "333919",
    "end": "335440"
  },
  {
    "text": "the UI reflecting exactly what's",
    "start": "335440",
    "end": "337360"
  },
  {
    "text": "happening on the server to the user a",
    "start": "337360",
    "end": "339479"
  },
  {
    "text": "stream events is very powerful in this",
    "start": "339479",
    "end": "341440"
  },
  {
    "text": "case because you'll get event for when",
    "start": "341440",
    "end": "342800"
  },
  {
    "text": "things start for different streams that",
    "start": "342800",
    "end": "345160"
  },
  {
    "text": "are happening inside of that task and",
    "start": "345160",
    "end": "347120"
  },
  {
    "text": "for when things end so you can be",
    "start": "347120",
    "end": "348600"
  },
  {
    "text": "updating the UI letting the user know",
    "start": "348600",
    "end": "350280"
  },
  {
    "text": "hey this task has started you can update",
    "start": "350280",
    "end": "352199"
  },
  {
    "text": "it every time you get a new chunk back",
    "start": "352199",
    "end": "353800"
  },
  {
    "text": "from the stream saying this is exactly",
    "start": "353800",
    "end": "355080"
  },
  {
    "text": "what's going on like rendering the",
    "start": "355080",
    "end": "356520"
  },
  {
    "text": "tokens from an LM call and then when",
    "start": "356520",
    "end": "358560"
  },
  {
    "text": "things end you'll be able to say hey",
    "start": "358560",
    "end": "360280"
  },
  {
    "text": "this task is so they can be informed as",
    "start": "360280",
    "end": "362039"
  },
  {
    "text": "to what exactly is happening on the",
    "start": "362039",
    "end": "363360"
  },
  {
    "text": "server now we can jump into the next",
    "start": "363360",
    "end": "365919"
  },
  {
    "text": "stream mode messages the stream mode",
    "start": "365919",
    "end": "368280"
  },
  {
    "text": "messages will only stream back messages",
    "start": "368280",
    "end": "370479"
  },
  {
    "text": "that get updated in the state so say I",
    "start": "370479",
    "end": "372840"
  },
  {
    "text": "have three state fields in My Graph and",
    "start": "372840",
    "end": "374800"
  },
  {
    "text": "I update one which is a number that will",
    "start": "374800",
    "end": "377960"
  },
  {
    "text": "not yield back any data because the",
    "start": "377960",
    "end": "379840"
  },
  {
    "text": "messages mode will only stream back",
    "start": "379840",
    "end": "382520"
  },
  {
    "text": "messages so I would have to update a",
    "start": "382520",
    "end": "384880"
  },
  {
    "text": "field in my state which contains",
    "start": "384880",
    "end": "386319"
  },
  {
    "text": "messages for this stream mode to yield",
    "start": "386319",
    "end": "388720"
  },
  {
    "text": "back some data now we can open up stream",
    "start": "388720",
    "end": "391840"
  },
  {
    "text": "messages file you see it's pretty much",
    "start": "391840",
    "end": "395080"
  },
  {
    "text": "the same except we're not calling stream",
    "start": "395080",
    "end": "396520"
  },
  {
    "text": "events we do not have to specify a",
    "start": "396520",
    "end": "397919"
  },
  {
    "text": "version we just pass in our input and",
    "start": "397919",
    "end": "400520"
  },
  {
    "text": "then since my graph only contains a",
    "start": "400520",
    "end": "402400"
  },
  {
    "text": "messages field we don't need to do",
    "start": "402400",
    "end": "403919"
  },
  {
    "text": "anything else and we just log the events",
    "start": "403919",
    "end": "405880"
  },
  {
    "text": "we can go to our terminal and we can run",
    "start": "405880",
    "end": "407319"
  },
  {
    "text": "yarn start messages we'll hit submit and",
    "start": "407319",
    "end": "411599"
  },
  {
    "text": "then as each message is appended to our",
    "start": "411599",
    "end": "413720"
  },
  {
    "text": "state we'll see it logged to the",
    "start": "413720",
    "end": "415240"
  },
  {
    "text": "terminal here now this is finished we",
    "start": "415240",
    "end": "416879"
  },
  {
    "text": "scroll to the top and we'll see the very",
    "start": "416879",
    "end": "418720"
  },
  {
    "text": "first node which which was invoked was",
    "start": "418720",
    "end": "420240"
  },
  {
    "text": "the agent node and that returned a new",
    "start": "420240",
    "end": "422400"
  },
  {
    "text": "AI message here containing the tool call",
    "start": "422400",
    "end": "425520"
  },
  {
    "text": "this tool call is calling the tly search",
    "start": "425520",
    "end": "428840"
  },
  {
    "text": "results tool as we see here then we get",
    "start": "428840",
    "end": "431639"
  },
  {
    "text": "a new message returned from the tools",
    "start": "431639",
    "end": "433319"
  },
  {
    "text": "node which is a tool message containing",
    "start": "433319",
    "end": "435080"
  },
  {
    "text": "the result of the API call and then",
    "start": "435080",
    "end": "437039"
  },
  {
    "text": "finally we get an AI message containing",
    "start": "437039",
    "end": "438960"
  },
  {
    "text": "some text content uh that was generated",
    "start": "438960",
    "end": "441319"
  },
  {
    "text": "using the result of the tool call and",
    "start": "441319",
    "end": "443240"
  },
  {
    "text": "our original question as we can see",
    "start": "443240",
    "end": "445520"
  },
  {
    "text": "since my graph only contains messages",
    "start": "445520",
    "end": "448000"
  },
  {
    "text": "this will only stream back the messages",
    "start": "448000",
    "end": "450520"
  },
  {
    "text": "that were updated in my state we can now",
    "start": "450520",
    "end": "452840"
  },
  {
    "text": "open up the web server which also comes",
    "start": "452840",
    "end": "455319"
  },
  {
    "text": "in repository if you clone it the inside",
    "start": "455319",
    "end": "457560"
  },
  {
    "text": "the streaming messages front end",
    "start": "457560",
    "end": "459080"
  },
  {
    "text": "directory so you're going to want to",
    "start": "459080",
    "end": "460960"
  },
  {
    "text": "navigate there and run yarn Dev and then",
    "start": "460960",
    "end": "463120"
  },
  {
    "text": "once you've ran that you can open up",
    "start": "463120",
    "end": "464280"
  },
  {
    "text": "your web server here and once this loads",
    "start": "464280",
    "end": "467759"
  },
  {
    "text": "we can simply ask a question like what's",
    "start": "467759",
    "end": "469599"
  },
  {
    "text": "the current stock price of Tesla and it",
    "start": "469599",
    "end": "471639"
  },
  {
    "text": "will stream it back to us using the",
    "start": "471639",
    "end": "473000"
  },
  {
    "text": "stream messages mode so we see we get a",
    "start": "473000",
    "end": "474840"
  },
  {
    "text": "tool call we see the result of the tool",
    "start": "474840",
    "end": "477080"
  },
  {
    "text": "call and then we see that the LM",
    "start": "477080",
    "end": "479479"
  },
  {
    "text": "generated a final response here using",
    "start": "479479",
    "end": "482000"
  },
  {
    "text": "this settings icon we can toggle the",
    "start": "482000",
    "end": "484280"
  },
  {
    "text": "different stream modes so if we want to",
    "start": "484280",
    "end": "485759"
  },
  {
    "text": "see events which what we were just",
    "start": "485759",
    "end": "486919"
  },
  {
    "text": "talking about we can select this and",
    "start": "486919",
    "end": "489159"
  },
  {
    "text": "then we'll just say",
    "start": "489159",
    "end": "492000"
  },
  {
    "text": "thanks this is going to log every single",
    "start": "492039",
    "end": "494840"
  },
  {
    "text": "object which is turn return from our",
    "start": "494840",
    "end": "496240"
  },
  {
    "text": "stream events call so if we scroll to",
    "start": "496240",
    "end": "497680"
  },
  {
    "text": "the top we see there's a lot of events",
    "start": "497680",
    "end": "499720"
  },
  {
    "text": "because it's going to send back a new",
    "start": "499720",
    "end": "501319"
  },
  {
    "text": "event for every single token yielded by",
    "start": "501319",
    "end": "503599"
  },
  {
    "text": "the LM we see we get our onchain",
    "start": "503599",
    "end": "506360"
  },
  {
    "text": "start as we scroll we can start to see",
    "start": "506360",
    "end": "509599"
  },
  {
    "text": "our agent node was invoked we can then",
    "start": "509599",
    "end": "512560"
  },
  {
    "text": "see onchain start again which is",
    "start": "512560",
    "end": "514399"
  },
  {
    "text": "probably going to be calling the tool",
    "start": "514399",
    "end": "516560"
  },
  {
    "text": "call so it's a runnable Lambda which",
    "start": "516560",
    "end": "519919"
  },
  {
    "text": "contains the on chat Model start event",
    "start": "519919",
    "end": "522000"
  },
  {
    "text": "and inside here we can also see that we",
    "start": "522000",
    "end": "523640"
  },
  {
    "text": "get all of the history inside our",
    "start": "523640",
    "end": "525240"
  },
  {
    "text": "messages so we see the message that the",
    "start": "525240",
    "end": "527080"
  },
  {
    "text": "LM responded with above we see the tool",
    "start": "527080",
    "end": "529279"
  },
  {
    "text": "call content and then we also see our",
    "start": "529279",
    "end": "531720"
  },
  {
    "text": "input or sorry this is the tool call if",
    "start": "531720",
    "end": "534680"
  },
  {
    "text": "we scroll up then we can see our input",
    "start": "534680",
    "end": "537959"
  },
  {
    "text": "so this just shows how much data the",
    "start": "537959",
    "end": "539760"
  },
  {
    "text": "stream events endpoint will return as",
    "start": "539760",
    "end": "541839"
  },
  {
    "text": "you see we scroll for quite a while to",
    "start": "541839",
    "end": "543519"
  },
  {
    "text": "get to the end because it's returning",
    "start": "543519",
    "end": "544920"
  },
  {
    "text": "every single event and all the data from",
    "start": "544920",
    "end": "547680"
  },
  {
    "text": "those events that were taken in our",
    "start": "547680",
    "end": "549920"
  },
  {
    "text": "graph now if we go back to the code we",
    "start": "549920",
    "end": "552760"
  },
  {
    "text": "can open up our read me and we see that",
    "start": "552760",
    "end": "555560"
  },
  {
    "text": "the next mode is updates the stream mode",
    "start": "555560",
    "end": "557640"
  },
  {
    "text": "updates is somewhat more selective to",
    "start": "557640",
    "end": "559440"
  },
  {
    "text": "where it will only yield the updates",
    "start": "559440",
    "end": "561600"
  },
  {
    "text": "made to the graph and no other fields so",
    "start": "561600",
    "end": "564079"
  },
  {
    "text": "let's say you have once again three",
    "start": "564079",
    "end": "565640"
  },
  {
    "text": "fields in your state and you update one",
    "start": "565640",
    "end": "568279"
  },
  {
    "text": "of those fields and you're specifying",
    "start": "568279",
    "end": "570079"
  },
  {
    "text": "stream mode updates you're only going to",
    "start": "570079",
    "end": "572440"
  },
  {
    "text": "get the value that you updated you not",
    "start": "572440",
    "end": "575000"
  },
  {
    "text": "going to get any of the other fields in",
    "start": "575000",
    "end": "576680"
  },
  {
    "text": "your current state you're not going to",
    "start": "576680",
    "end": "578320"
  },
  {
    "text": "get the previous fields of that current",
    "start": "578320",
    "end": "580839"
  },
  {
    "text": "state item you're just going to get the",
    "start": "580839",
    "end": "582880"
  },
  {
    "text": "data that was updated in that specific",
    "start": "582880",
    "end": "585399"
  },
  {
    "text": "update this occurs when you um do one of",
    "start": "585399",
    "end": "588240"
  },
  {
    "text": "two things return a value inside of a",
    "start": "588240",
    "end": "590000"
  },
  {
    "text": "node and then you're going to get that",
    "start": "590000",
    "end": "591120"
  },
  {
    "text": "data which was returned inside that node",
    "start": "591120",
    "end": "593399"
  },
  {
    "text": "or you call the update State method on",
    "start": "593399",
    "end": "595519"
  },
  {
    "text": "the graph um and then you're going to",
    "start": "595519",
    "end": "597760"
  },
  {
    "text": "get the object or whatever data you",
    "start": "597760",
    "end": "599880"
  },
  {
    "text": "passed into to that update State method",
    "start": "599880",
    "end": "602000"
  },
  {
    "text": "so it's only going to give you the the",
    "start": "602000",
    "end": "603640"
  },
  {
    "text": "data that was updated and nothing else",
    "start": "603640",
    "end": "605640"
  },
  {
    "text": "now if we open up the stream updates",
    "start": "605640",
    "end": "607800"
  },
  {
    "text": "file we can see once again we're calling",
    "start": "607800",
    "end": "610240"
  },
  {
    "text": "stream but this time we're passing",
    "start": "610240",
    "end": "611560"
  },
  {
    "text": "stream mode updates and then logging the",
    "start": "611560",
    "end": "613560"
  },
  {
    "text": "values now we're back in the terminal",
    "start": "613560",
    "end": "615560"
  },
  {
    "text": "and we run yarn start update hit submit",
    "start": "615560",
    "end": "619279"
  },
  {
    "text": "and as we see only the updates come in",
    "start": "619279",
    "end": "621680"
  },
  {
    "text": "so from the first node tools or agent",
    "start": "621680",
    "end": "625360"
  },
  {
    "text": "then tools then agent again as you can",
    "start": "625360",
    "end": "627360"
  },
  {
    "text": "see it's pretty similar to the messages",
    "start": "627360",
    "end": "629480"
  },
  {
    "text": "mode because I only have messages on my",
    "start": "629480",
    "end": "631360"
  },
  {
    "text": "graph but we have the node and then this",
    "start": "631360",
    "end": "633720"
  },
  {
    "text": "was the value returned from that node if",
    "start": "633720",
    "end": "636120"
  },
  {
    "text": "we open up the graph we can see exactly",
    "start": "636120",
    "end": "638600"
  },
  {
    "text": "what gets returned from the model so",
    "start": "638600",
    "end": "640440"
  },
  {
    "text": "call model which is our agent node",
    "start": "640440",
    "end": "642880"
  },
  {
    "text": "returns this messages object containing",
    "start": "642880",
    "end": "644880"
  },
  {
    "text": "the message and as we see that matches",
    "start": "644880",
    "end": "646560"
  },
  {
    "text": "up right here exactly and it's only",
    "start": "646560",
    "end": "648720"
  },
  {
    "text": "returning inside this this one yielded",
    "start": "648720",
    "end": "651440"
  },
  {
    "text": "object the data that was returned from",
    "start": "651440",
    "end": "653040"
  },
  {
    "text": "this node the next is the tools node the",
    "start": "653040",
    "end": "655279"
  },
  {
    "text": "tools node returns messages with a",
    "start": "655279",
    "end": "657600"
  },
  {
    "text": "single message and then once again the",
    "start": "657600",
    "end": "659639"
  },
  {
    "text": "agent node here returning this uh AI",
    "start": "659639",
    "end": "662399"
  },
  {
    "text": "message so once again the updates stream",
    "start": "662399",
    "end": "665680"
  },
  {
    "text": "mode will only ever return the values",
    "start": "665680",
    "end": "668079"
  },
  {
    "text": "updated in that specific point in your",
    "start": "668079",
    "end": "670320"
  },
  {
    "text": "graph so now we can go back to the UI we",
    "start": "670320",
    "end": "672800"
  },
  {
    "text": "can reload and then we'll want to toggle",
    "start": "672800",
    "end": "675360"
  },
  {
    "text": "stream mode updates and we'll ask a",
    "start": "675360",
    "end": "677639"
  },
  {
    "text": "question what is the current stock price",
    "start": "677639",
    "end": "679000"
  },
  {
    "text": "of Tesla and as we see we are only",
    "start": "679000",
    "end": "681519"
  },
  {
    "text": "getting in the same things we saw in the",
    "start": "681519",
    "end": "683360"
  },
  {
    "text": "terminal we have the agent the tools and",
    "start": "683360",
    "end": "686480"
  },
  {
    "text": "then the agent node again and it's only",
    "start": "686480",
    "end": "688279"
  },
  {
    "text": "the values that were returned inside of",
    "start": "688279",
    "end": "690920"
  },
  {
    "text": "those specific nodes and we're not",
    "start": "690920",
    "end": "692399"
  },
  {
    "text": "getting the rest of the history if we",
    "start": "692399",
    "end": "694200"
  },
  {
    "text": "want to get the values returned and the",
    "start": "694200",
    "end": "696839"
  },
  {
    "text": "rest of the history we can specify",
    "start": "696839",
    "end": "698720"
  },
  {
    "text": "stream mode values first let's look at",
    "start": "698720",
    "end": "701760"
  },
  {
    "text": "the code and see how this works and then",
    "start": "701760",
    "end": "703240"
  },
  {
    "text": "we'll run it in the playground so we'll",
    "start": "703240",
    "end": "705519"
  },
  {
    "text": "open up the stream values. TS file and",
    "start": "705519",
    "end": "708839"
  },
  {
    "text": "then we see once again we're specifying",
    "start": "708839",
    "end": "710440"
  },
  {
    "text": "stream mode but this type is values we",
    "start": "710440",
    "end": "713480"
  },
  {
    "text": "call. stream and then we log all of the",
    "start": "713480",
    "end": "715720"
  },
  {
    "text": "values of this to the terminal now let's",
    "start": "715720",
    "end": "717680"
  },
  {
    "text": "open up our terminal terminal and invoke",
    "start": "717680",
    "end": "719480"
  },
  {
    "text": "it I hit start and we're going to see",
    "start": "719480",
    "end": "721120"
  },
  {
    "text": "all the updates including the previous",
    "start": "721120",
    "end": "723279"
  },
  {
    "text": "values in our state get logged to the",
    "start": "723279",
    "end": "724560"
  },
  {
    "text": "terminal so I scroll to the top and we",
    "start": "724560",
    "end": "727240"
  },
  {
    "text": "see the very first object which is",
    "start": "727240",
    "end": "729120"
  },
  {
    "text": "yielded back is our input message that",
    "start": "729120",
    "end": "732160"
  },
  {
    "text": "is when we updated the graph state with",
    "start": "732160",
    "end": "734639"
  },
  {
    "text": "our input right we send it to the server",
    "start": "734639",
    "end": "736800"
  },
  {
    "text": "that adds it to the graph State and then",
    "start": "736800",
    "end": "738560"
  },
  {
    "text": "a new value is added to the state so it",
    "start": "738560",
    "end": "739959"
  },
  {
    "text": "gets yielded back to us next our llm",
    "start": "739959",
    "end": "742320"
  },
  {
    "text": "called a tool so we see we get a new",
    "start": "742320",
    "end": "744880"
  },
  {
    "text": "messages array containing our message",
    "start": "744880",
    "end": "747160"
  },
  {
    "text": "because it's sending back right the",
    "start": "747160",
    "end": "748480"
  },
  {
    "text": "entire state",
    "start": "748480",
    "end": "749680"
  },
  {
    "text": "and the updates so we get our message",
    "start": "749680",
    "end": "752079"
  },
  {
    "text": "and then the new AI message which was",
    "start": "752079",
    "end": "753760"
  },
  {
    "text": "added to the state next it calls the",
    "start": "753760",
    "end": "755720"
  },
  {
    "text": "tool so we see our message the AI",
    "start": "755720",
    "end": "758040"
  },
  {
    "text": "message and then we see the tool message",
    "start": "758040",
    "end": "760399"
  },
  {
    "text": "and finally it's calling the LM to",
    "start": "760399",
    "end": "761839"
  },
  {
    "text": "generate a final response so we see we",
    "start": "761839",
    "end": "763360"
  },
  {
    "text": "get the final response right here which",
    "start": "763360",
    "end": "765360"
  },
  {
    "text": "was the the new update including the",
    "start": "765360",
    "end": "767519"
  },
  {
    "text": "rest of the fields which were already in",
    "start": "767519",
    "end": "769120"
  },
  {
    "text": "the the state which is the tool message",
    "start": "769120",
    "end": "771639"
  },
  {
    "text": "the original AI message containing the",
    "start": "771639",
    "end": "773160"
  },
  {
    "text": "tool call and then our input now if we",
    "start": "773160",
    "end": "776240"
  },
  {
    "text": "go to our streaming UI and we talk",
    "start": "776240",
    "end": "779600"
  },
  {
    "text": "stream mode to be values and ask a",
    "start": "779600",
    "end": "782880"
  },
  {
    "text": "question we'll see the exact same thing",
    "start": "782880",
    "end": "784760"
  },
  {
    "text": "we logged in the terminal but this is a",
    "start": "784760",
    "end": "786440"
  },
  {
    "text": "little bit prettier so we wait for this",
    "start": "786440",
    "end": "787680"
  },
  {
    "text": "to load and then we scroll to the top we",
    "start": "787680",
    "end": "789560"
  },
  {
    "text": "see we have the initial state which is",
    "start": "789560",
    "end": "791199"
  },
  {
    "text": "our question we then we see the llm",
    "start": "791199",
    "end": "793839"
  },
  {
    "text": "called a tool so we see our question",
    "start": "793839",
    "end": "796199"
  },
  {
    "text": "here and then the tool call which the LM",
    "start": "796199",
    "end": "799320"
  },
  {
    "text": "called after that we see that the tool",
    "start": "799320",
    "end": "801800"
  },
  {
    "text": "node was called so we see our input",
    "start": "801800",
    "end": "803639"
  },
  {
    "text": "message the tool call by the LM and then",
    "start": "803639",
    "end": "806279"
  },
  {
    "text": "the result of the tool call finally our",
    "start": "806279",
    "end": "809199"
  },
  {
    "text": "LM is gener generating a final response",
    "start": "809199",
    "end": "811440"
  },
  {
    "text": "so we see we have our message the tool",
    "start": "811440",
    "end": "813800"
  },
  {
    "text": "call that the LM generated the result of",
    "start": "813800",
    "end": "816160"
  },
  {
    "text": "the tool call and then the final message",
    "start": "816160",
    "end": "818639"
  },
  {
    "text": "that the LM generated here so as we see",
    "start": "818639",
    "end": "821720"
  },
  {
    "text": "we have our messages array which is our",
    "start": "821720",
    "end": "824320"
  },
  {
    "text": "the only field in our state containing",
    "start": "824320",
    "end": "826480"
  },
  {
    "text": "the first item which is the message that",
    "start": "826480",
    "end": "828800"
  },
  {
    "text": "we submitted then the AI message gets",
    "start": "828800",
    "end": "831800"
  },
  {
    "text": "appended so we get our original message",
    "start": "831800",
    "end": "833720"
  },
  {
    "text": "and the new update finally the tool node",
    "start": "833720",
    "end": "836199"
  },
  {
    "text": "returns a tool message so we get this",
    "start": "836199",
    "end": "837440"
  },
  {
    "text": "update including the rest and and then",
    "start": "837440",
    "end": "839480"
  },
  {
    "text": "lastly the AI message generates a text",
    "start": "839480",
    "end": "841800"
  },
  {
    "text": "response so we get that text response",
    "start": "841800",
    "end": "843560"
  },
  {
    "text": "including the rest of the history so now",
    "start": "843560",
    "end": "846560"
  },
  {
    "text": "that you know the four different ways to",
    "start": "846560",
    "end": "848160"
  },
  {
    "text": "stream back data from the L graph server",
    "start": "848160",
    "end": "850600"
  },
  {
    "text": "let's talk about how and where you might",
    "start": "850600",
    "end": "853199"
  },
  {
    "text": "use these so we already spoke about the",
    "start": "853199",
    "end": "855360"
  },
  {
    "text": "events mode in the beginning where I",
    "start": "855360",
    "end": "856720"
  },
  {
    "text": "stated that gener UI applications",
    "start": "856720",
    "end": "858600"
  },
  {
    "text": "utilize that well because they need so",
    "start": "858600",
    "end": "860680"
  },
  {
    "text": "many events to be updating and rendering",
    "start": "860680",
    "end": "863399"
  },
  {
    "text": "on the UI the next was the messages mode",
    "start": "863399",
    "end": "866920"
  },
  {
    "text": "which is very useful if you're building",
    "start": "866920",
    "end": "868560"
  },
  {
    "text": "something like this which is a chatbot",
    "start": "868560",
    "end": "870279"
  },
  {
    "text": "where you only care about messages in",
    "start": "870279",
    "end": "871680"
  },
  {
    "text": "and messages out and you're not really R",
    "start": "871680",
    "end": "873279"
  },
  {
    "text": "rendering anything else on the UI except",
    "start": "873279",
    "end": "875360"
  },
  {
    "text": "for the human and assistant messages the",
    "start": "875360",
    "end": "878040"
  },
  {
    "text": "next mode is the updates mode an",
    "start": "878040",
    "end": "879959"
  },
  {
    "text": "application where this can be useful is",
    "start": "879959",
    "end": "881279"
  },
  {
    "text": "say a notification system where you only",
    "start": "881279",
    "end": "883360"
  },
  {
    "text": "care about the changes being made and",
    "start": "883360",
    "end": "885800"
  },
  {
    "text": "not the current state or the previous",
    "start": "885800",
    "end": "887639"
  },
  {
    "text": "state you really only need what just",
    "start": "887639",
    "end": "890279"
  },
  {
    "text": "changed and then to render that in your",
    "start": "890279",
    "end": "892000"
  },
  {
    "text": "notification system so for that you",
    "start": "892000",
    "end": "893680"
  },
  {
    "text": "might want to use the updates mode and",
    "start": "893680",
    "end": "896079"
  },
  {
    "text": "then finally we have the values mode",
    "start": "896079",
    "end": "897920"
  },
  {
    "text": "which Returns the entire higher state",
    "start": "897920",
    "end": "900040"
  },
  {
    "text": "whenever anything changes um an",
    "start": "900040",
    "end": "902040"
  },
  {
    "text": "application where this might be useful",
    "start": "902040",
    "end": "903399"
  },
  {
    "text": "is say some sort of admin dashboard",
    "start": "903399",
    "end": "905519"
  },
  {
    "text": "where you want to always be showing the",
    "start": "905519",
    "end": "907560"
  },
  {
    "text": "total State um and have some sort of",
    "start": "907560",
    "end": "909320"
  },
  {
    "text": "snapshot showing what is happening in",
    "start": "909320",
    "end": "911480"
  },
  {
    "text": "every field of the state at this time",
    "start": "911480",
    "end": "913320"
  },
  {
    "text": "and you want that to be updating",
    "start": "913320",
    "end": "914639"
  },
  {
    "text": "whenever anything changes so for that",
    "start": "914639",
    "end": "916639"
  },
  {
    "text": "you might want to use the values mode so",
    "start": "916639",
    "end": "919759"
  },
  {
    "text": "those are the four stream modes which L",
    "start": "919759",
    "end": "922079"
  },
  {
    "text": "graph supports I hope you all know a lot",
    "start": "922079",
    "end": "924920"
  },
  {
    "text": "more about streaming now and how to",
    "start": "924920",
    "end": "926279"
  },
  {
    "text": "stream with lra and I'm excited to see",
    "start": "926279",
    "end": "928319"
  },
  {
    "text": "what everyone builds in the future",
    "start": "928319",
    "end": "931639"
  }
]
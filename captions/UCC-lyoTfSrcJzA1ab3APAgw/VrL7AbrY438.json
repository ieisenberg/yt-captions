[
  {
    "text": "AI live welcome everyone to the Lang chain webinar Series today we'll be",
    "start": "0",
    "end": "8040"
  },
  {
    "text": "talking about retrieval a topic that some of us have only started thinking",
    "start": "8040",
    "end": "14099"
  },
  {
    "text": "about in the last six months I'd count myself in that category um but others of us have been thinking",
    "start": "14099",
    "end": "19859"
  },
  {
    "text": "about for years and our speakers today are in that category so we have Omar",
    "start": "19859",
    "end": "25380"
  },
  {
    "text": "khadab here from uh Stanford NLP group who has worked on retrieval models and",
    "start": "25380",
    "end": "31859"
  },
  {
    "text": "Joe Christian bergum here from the Vespa team who's worked on that retrieval",
    "start": "31859",
    "end": "37680"
  },
  {
    "text": "engine um many many things many features in invest but we'll hear some about that",
    "start": "37680",
    "end": "43200"
  },
  {
    "text": "and a lot about the general problem of retrieval um and to kick us off uh we'll Harrison",
    "start": "43200",
    "end": "49620"
  },
  {
    "text": "I think you wanted to say a little bit about how retrieval fits with uh the langjang library what it looks like what",
    "start": "49620",
    "end": "55620"
  },
  {
    "text": "people have already seen before we dive into the the the depths that Joe and Omar have plumbed",
    "start": "55620",
    "end": "61379"
  },
  {
    "text": "yeah absolutely I just wanted to and I'll only take like one or two minutes to do this because there's much more",
    "start": "61379",
    "end": "66420"
  },
  {
    "text": "exciting things to talk about but just to uh just to just to ground it in in",
    "start": "66420",
    "end": "72180"
  },
  {
    "text": "kind of what uh what people familiar with link chain might recognize so I",
    "start": "72180",
    "end": "77640"
  },
  {
    "text": "should be sharing my screen now this is uh this is from a blog post we did in",
    "start": "77640",
    "end": "82979"
  },
  {
    "text": "February the the main the main usage of retrieval and Link Chain is basically to enable connecting your data with",
    "start": "82979",
    "end": "90299"
  },
  {
    "text": "language models and so the way that we've traditionally done this is is",
    "start": "90299",
    "end": "95700"
  },
  {
    "text": "we've kind of had once we've done everything largely based on kind of like uh embeddings and vectors and we've",
    "start": "95700",
    "end": "102840"
  },
  {
    "text": "taken documents split them into chunks created embeddings for those chunks and then stuff them in a vector store and",
    "start": "102840",
    "end": "109380"
  },
  {
    "text": "then we've used that to create a chat bot where you basically have a question that comes in you look up in the vector",
    "start": "109380",
    "end": "115740"
  },
  {
    "text": "store relevant pieces of text you then pass that along with the original question into a language model and it",
    "start": "115740",
    "end": "121799"
  },
  {
    "text": "grounds its answer in the documents that it's passed in we discussed we discussed",
    "start": "121799",
    "end": "127619"
  },
  {
    "text": "hallucinations last week and and this was one of the the retrieval augmented",
    "start": "127619",
    "end": "132720"
  },
  {
    "text": "generation was one of the most popular methods for reducing um hallucinations and and a lot of the comments on that webinars basically you",
    "start": "132720",
    "end": "140340"
  },
  {
    "text": "know the hallucinations that do still exist come down to messing up on",
    "start": "140340",
    "end": "145500"
  },
  {
    "text": "retrieval and so really excited to learn more about better types of retrieval",
    "start": "145500",
    "end": "151140"
  },
  {
    "text": "that we can be doing and and and how we can uh hopefully you know add some of that in Lang change some of this already",
    "start": "151140",
    "end": "157260"
  },
  {
    "text": "is with Vespa um and the last thing I'll say here before",
    "start": "157260",
    "end": "162480"
  },
  {
    "text": "handing it over is we used to do we used to have a terrible abstraction in link chain which was everything was a vector store and you just did similarity search",
    "start": "162480",
    "end": "168780"
  },
  {
    "text": "in about two months ago we changed that to just being a generic retriever interface um which has enabled us to really",
    "start": "168780",
    "end": "174900"
  },
  {
    "text": "quickly kind of like integrate Vespa in and other methods as well um and so as we talk about some of the",
    "start": "174900",
    "end": "180239"
  },
  {
    "text": "ideas today yeah really hopeful that a lot of these can can make them way make their way into an integration with Lang",
    "start": "180239",
    "end": "185640"
  },
  {
    "text": "chain in some form and everyone here can play around with it and I'll kind of stop there because yeah much more",
    "start": "185640",
    "end": "190800"
  },
  {
    "text": "interesting people to listen to yeah and I think we had Joe up first to",
    "start": "190800",
    "end": "197400"
  },
  {
    "text": "give a bit of a kind of like overview of all the uh other types of retrieval made",
    "start": "197400",
    "end": "202500"
  },
  {
    "text": "possible by not just using a vector store so let's hear from Joe first sure thank you",
    "start": "202500",
    "end": "208140"
  },
  {
    "text": "so uh let me share um",
    "start": "208140",
    "end": "213200"
  },
  {
    "text": "all right so first of all thank you for having me uh great being invited here",
    "start": "215700",
    "end": "221040"
  },
  {
    "text": "and see all the excitement of our Lang chain and language models and of course",
    "start": "221040",
    "end": "227700"
  },
  {
    "text": "as you said I was in retrieval augmentation for generating with large language models",
    "start": "227700",
    "end": "234720"
  },
  {
    "text": "so I'll have a few boring slides I'll talk about information retrieval uh in",
    "start": "234720",
    "end": "241319"
  },
  {
    "text": "the age of genotype AI or large language models",
    "start": "241319",
    "end": "247379"
  },
  {
    "text": "um and like many of you Builders out there you're probably building using Lang chain uh using large",
    "start": "247379",
    "end": "256440"
  },
  {
    "text": "language models and you're using a retriever Pipeline and you are retrieving context and you are fitting",
    "start": "256440",
    "end": "263639"
  },
  {
    "text": "this into a prompt and you're building stuff and we at the Westport team we're also building stuff using Vespa and",
    "start": "263639",
    "end": "270120"
  },
  {
    "text": "using line chain and the reason why we're doing that is that we want to",
    "start": "270120",
    "end": "275520"
  },
  {
    "text": "improve our documentation search so here we have several resources thus far",
    "start": "275520",
    "end": "281460"
  },
  {
    "text": "related resources around documentation and our Cloud documentation our sample applications our blog private spa and",
    "start": "281460",
    "end": "288479"
  },
  {
    "text": "everything and we thought you know we need to improve the overall search experience so let's connect line chain",
    "start": "288479",
    "end": "293880"
  },
  {
    "text": "investment and build a new search interface and in this case also I can answer the question about what is",
    "start": "293880",
    "end": "300479"
  },
  {
    "text": "actually information retrieval right so information retrieval is summarized here by a language model",
    "start": "300479",
    "end": "307979"
  },
  {
    "text": "based on the routine context on the investment documentation and since we've been working on language models for",
    "start": "307979",
    "end": "313740"
  },
  {
    "text": "search and for search ranking and questioning answering for quite some time so there's a lot of content around that across our sites so the agent does",
    "start": "313740",
    "end": "322560"
  },
  {
    "text": "a pretty good job at actually summarizing what information retrieval is and it's the process of retrieving",
    "start": "322560",
    "end": "329280"
  },
  {
    "text": "relevant information from a corpus of documents using search and ranking strategies and",
    "start": "329280",
    "end": "335720"
  },
  {
    "text": "measuring the effectiveness of these strategies is important right because we want to",
    "start": "335720",
    "end": "341780"
  },
  {
    "text": "differentiate and compare different types of retrieval methods to see you know how they compare and how they",
    "start": "341780",
    "end": "348900"
  },
  {
    "text": "perform right um so I'll I'll dive into that um in the context of",
    "start": "348900",
    "end": "355800"
  },
  {
    "text": "um doing retrieval for generation uh we want to find relevant context and",
    "start": "355800",
    "end": "362940"
  },
  {
    "text": "we want to stuff that into a prompt or language model prompt and we want to use some kind of information retrieval",
    "start": "362940",
    "end": "369060"
  },
  {
    "text": "system right and this might be a search engine it might be a vector database SQL graph hyperdb",
    "start": "369060",
    "end": "376220"
  },
  {
    "text": "numpy ra whatever you know and that's why we love the new abstractions in line",
    "start": "376220",
    "end": "382020"
  },
  {
    "text": "train around retrievers and some of the motivation is basically I mean these",
    "start": "382020",
    "end": "387780"
  },
  {
    "text": "language models they are large they are expensive and they have limited token",
    "start": "387780",
    "end": "394860"
  },
  {
    "text": "lengths so if you cross those multiple different dimensions that's the",
    "start": "394860",
    "end": "400620"
  },
  {
    "text": "kind of thing that we want to address by retrieval that might be and of course there's a lot of knowledge in the",
    "start": "400620",
    "end": "407400"
  },
  {
    "text": "parametric ways of the language models and we want to augment that with our private data or",
    "start": "407400",
    "end": "414780"
  },
  {
    "text": "data that the model hasn't been really trained on and as Harrison said last",
    "start": "414780",
    "end": "419819"
  },
  {
    "text": "last webinar was about reducing hallucinations um retrieval improves on that but it",
    "start": "419819",
    "end": "426660"
  },
  {
    "text": "doesn't in my experience eliminate it entirely but it does reduce organizations and also allows you to",
    "start": "426660",
    "end": "433440"
  },
  {
    "text": "scale to I mean larger data set than just uh whatever token length limitation your",
    "start": "433440",
    "end": "439740"
  },
  {
    "text": "language model of of references is that um so retrieval augmentation is not",
    "start": "439740",
    "end": "445979"
  },
  {
    "text": "really a Brand New Concept um as far as I know it was introduced actually at uh back in 2020 at night in",
    "start": "445979",
    "end": "453479"
  },
  {
    "text": "Europe's um where researchers from meta did build",
    "start": "453479",
    "end": "459599"
  },
  {
    "text": "a system where they were retrieve and then they would augment a sequence to sequence language model and generate the",
    "start": "459599",
    "end": "466319"
  },
  {
    "text": "answer for open domain question answering and before that just before",
    "start": "466319",
    "end": "471960"
  },
  {
    "text": "that the state of the art and open the main question answering was extractive question answering where you would",
    "start": "471960",
    "end": "478639"
  },
  {
    "text": "retrieve with a retriever and then you would extract or predict the best answer",
    "start": "478639",
    "end": "485280"
  },
  {
    "text": "Span in the retrieved text so it wouldn't actually generate text it would just pick out the most probable answer",
    "start": "485280",
    "end": "492660"
  },
  {
    "text": "from the retrieved context and but obviously now we have much larger models",
    "start": "492660",
    "end": "498539"
  },
  {
    "text": "for them I'm just keeping it here we did some work on that we have sample application to actually reproduce that",
    "start": "498539",
    "end": "505560"
  },
  {
    "text": "system and also I think that's the dense facet retriever is just used to Retreat passages from the knowledge base",
    "start": "505560",
    "end": "512760"
  },
  {
    "text": "here was using a vector model and I think DPR was one of the first uh models",
    "start": "512760",
    "end": "518820"
  },
  {
    "text": "or papers that described how to efficiently actually train uh a density",
    "start": "518820",
    "end": "524039"
  },
  {
    "text": "removal so um yeah and I listened to the last webinar",
    "start": "524039",
    "end": "530399"
  },
  {
    "text": "and there was questions about you know how do you ever make information retrieval systems um",
    "start": "530399",
    "end": "535620"
  },
  {
    "text": "and and how do you go about doing that so in Academia there's a set of like",
    "start": "535620",
    "end": "541200"
  },
  {
    "text": "common information retrievable data sets that typically researchers will report on and one important collection or is",
    "start": "541200",
    "end": "550560"
  },
  {
    "text": "that is the track to retrieval conference which um has many collections or relevancy",
    "start": "550560",
    "end": "557040"
  },
  {
    "text": "Collections and it's their their effort has been spanning like decades right and for every conference there's a new task",
    "start": "557040",
    "end": "564180"
  },
  {
    "text": "there's deep learning uh representation there's all kinds of different tasks so that's a rich set of data sets uh for uh",
    "start": "564180",
    "end": "572519"
  },
  {
    "text": "evolutely relevancy um Ms Marco uh from Bing is the largest",
    "start": "572519",
    "end": "579240"
  },
  {
    "text": "or the largest relevancy data set out there uh with a lot of trading data uh",
    "start": "579240",
    "end": "584700"
  },
  {
    "text": "queries and relevant document pairs there's both a passage version which has like shorter text and there's also a",
    "start": "584700",
    "end": "590760"
  },
  {
    "text": "document ranking um subtasking where you actually have web documents and then most importantly",
    "start": "590760",
    "end": "597300"
  },
  {
    "text": "I think is the beer Benchmark uh which is actually a collection of these uh different information retrieval",
    "start": "597300",
    "end": "603720"
  },
  {
    "text": "Collections and the unique thing about the beer Benchmark is that it has all",
    "start": "603720",
    "end": "609899"
  },
  {
    "text": "these different types of domains or medical domain web search this different types of tasks and domains and the kind",
    "start": "609899",
    "end": "617880"
  },
  {
    "text": "of you go at that Benchmark and you could try a method for instance a ranking model that's been trained on web",
    "start": "617880",
    "end": "624180"
  },
  {
    "text": "search like Ms Marco and then you apply to these new Collections and that",
    "start": "624180",
    "end": "629519"
  },
  {
    "text": "basically gives you information about how good is a particular way of doing",
    "start": "629519",
    "end": "634980"
  },
  {
    "text": "retrieval when it's applied in a new domain or a new task",
    "start": "634980",
    "end": "640140"
  },
  {
    "text": "and then obviously uh when we emulate these systems we use some kind of metrics and recall that k",
    "start": "640140",
    "end": "648000"
  },
  {
    "text": "um I won't go into the details on this but basically trying to focus on retrieving all the relevant documents",
    "start": "648000",
    "end": "653339"
  },
  {
    "text": "and precision is about uh really retrieving nothing but relevant among",
    "start": "653339",
    "end": "658440"
  },
  {
    "text": "the top K and Among Us industry practitioners you have the lgdm which is",
    "start": "658440",
    "end": "664860"
  },
  {
    "text": "looks good to me right and then we ship it um I think that's maybe the most common metric used when we're evaluating",
    "start": "664860",
    "end": "671579"
  },
  {
    "text": "informational retrieval systems so uh in the industry of course there's more than that this uh we deal with not only",
    "start": "671579",
    "end": "678720"
  },
  {
    "text": "static collections like in these data sets we look at engage with metrics uh",
    "start": "678720",
    "end": "684000"
  },
  {
    "text": "if you're running an e-commerce search you will look at conversation sales revenue uh obviously not only about",
    "start": "684000",
    "end": "690779"
  },
  {
    "text": "relevancy but also multi-objective that you're not optimizing just for the pure relevancy but you also have some other",
    "start": "690779",
    "end": "697800"
  },
  {
    "text": "goals a small note on credit distribution is that all these data sets typically have",
    "start": "697800",
    "end": "704579"
  },
  {
    "text": "just uh one query doesn't really weight the queries but in the real production industry application of search and",
    "start": "704579",
    "end": "711720"
  },
  {
    "text": "retrieval you will have a very different distribution of queries so you will have head queries that are frequent and",
    "start": "711720",
    "end": "718320"
  },
  {
    "text": "versus the tail queries which uh are more complex and and you don't",
    "start": "718320",
    "end": "723360"
  },
  {
    "text": "see them a lot and I think that the magic uh of search is in the tale right",
    "start": "723360",
    "end": "728519"
  },
  {
    "text": "because that's that's that's really uh everybody can get the headquers right",
    "start": "728519",
    "end": "735200"
  },
  {
    "text": "yo yeah let me ask you a quick question about it though yes that's where you're talking about it so uh yeah so you",
    "start": "735200",
    "end": "742320"
  },
  {
    "text": "started to touch on this a little bit at the end but for for people who are building applications on their own data I want to evaluate how like different",
    "start": "742320",
    "end": "749040"
  },
  {
    "text": "retrieval things are doing on their own data how would you recommend them to get started like just you know they don't",
    "start": "749040",
    "end": "756300"
  },
  {
    "text": "have any data you know they don't they're getting started from scratch right they don't have any data exercises yeah yeah so uh one thing is to to when",
    "start": "756300",
    "end": "765360"
  },
  {
    "text": "you have the BL Benchmark uh it's it's it's one way to to get an understanding of uh does any of the beard that the",
    "start": "765360",
    "end": "772800"
  },
  {
    "text": "data sets that are in beer because that closely uh look like the task you're",
    "start": "772800",
    "end": "779279"
  },
  {
    "text": "trying to solve uh or the data that you have uh that would be one thing the only obvious thing is that you actually uh",
    "start": "779279",
    "end": "786540"
  },
  {
    "text": "start looking at and and doing queries and then trying to bring out you know",
    "start": "786540",
    "end": "791760"
  },
  {
    "text": "people to evaluate the results like are these actually relevant and you are the probably the domain expert so you can",
    "start": "791760",
    "end": "798839"
  },
  {
    "text": "you know build a collection of queries and the retrieve results and then uh",
    "start": "798839",
    "end": "803880"
  },
  {
    "text": "basically annotate is this a relevant or highly relevant and then you quickly can kind of build uh your own kind of",
    "start": "803880",
    "end": "810480"
  },
  {
    "text": "evaluations and that way you can iterate on improving ranking and see if you are",
    "start": "810480",
    "end": "816959"
  },
  {
    "text": "improving or not in across these different uh queries so yeah many organizations do that right and the type",
    "start": "816959",
    "end": "823860"
  },
  {
    "text": "of data that they should be labeling there is basically query document and then Boolean is relevant is not relevant",
    "start": "823860",
    "end": "829980"
  },
  {
    "text": "for example yeah yeah so in this practical actually",
    "start": "829980",
    "end": "835079"
  },
  {
    "text": "touching the perfect timing I mean here's some practical examples of two",
    "start": "835079",
    "end": "840240"
  },
  {
    "text": "relevancy data sets so one is natural questions which is a data set from Google research uh it has questions that",
    "start": "840240",
    "end": "846540"
  },
  {
    "text": "have been asked on Google Search and where the answer can be found on Wikipedia uh so when did Kendrick",
    "start": "846540",
    "end": "853620"
  },
  {
    "text": "Lamar's first album come out and the ground truth is July 2nd 2011. so the",
    "start": "853620",
    "end": "859139"
  },
  {
    "text": "way you would evaluate this or transform this question and answering data set",
    "start": "859139",
    "end": "864180"
  },
  {
    "text": "into a retrieval problem is that you will look for the ground suit uh in the retrieve documents right and if the if",
    "start": "864180",
    "end": "871440"
  },
  {
    "text": "there were three documents is in position one okay then you have uh the recall is perfect because it's you've",
    "start": "871440",
    "end": "878040"
  },
  {
    "text": "retrieved the answer in position one and so forth and then you can kind of uh figure out you know are you actually",
    "start": "878040",
    "end": "884279"
  },
  {
    "text": "retrieving uh the right answer that's actually there and then you can later on",
    "start": "884279",
    "end": "889500"
  },
  {
    "text": "I will touch on you know separating the two things about judging the quality of the generation versus uh the retrieval",
    "start": "889500",
    "end": "896760"
  },
  {
    "text": "quality and another more traditional information that she will data set is",
    "start": "896760",
    "end": "902459"
  },
  {
    "text": "track copied uh which is a data set of covet related literature and one example",
    "start": "902459",
    "end": "908459"
  },
  {
    "text": "there is like the how does the coronavirus respond to changes in the weather and in this case you're not",
    "start": "908459",
    "end": "913920"
  },
  {
    "text": "looking for a particular answer you could could do that but in this case it's like a classic informational",
    "start": "913920",
    "end": "919620"
  },
  {
    "text": "material problem or you have graded relevancy labels and then you could the",
    "start": "919620",
    "end": "925560"
  },
  {
    "text": "task is basically to optimize uh to retrieve and optimize this ordering um and then you can also compute ngcg",
    "start": "925560",
    "end": "933839"
  },
  {
    "text": "which is another Precision oriented or you can produce smooth call",
    "start": "933839",
    "end": "939199"
  },
  {
    "text": "and I think that famous Marco passage ranking data set and document ranking",
    "start": "939199",
    "end": "944339"
  },
  {
    "text": "data sets is the two largest and two most important data sets uh that are out there because most of the models that",
    "start": "944339",
    "end": "951839"
  },
  {
    "text": "you will see even including open Ai embeddings and so forth are actually trained on this data",
    "start": "951839",
    "end": "958860"
  },
  {
    "text": "um and it has about nine million passages uh from from Bing and it has a",
    "start": "958860",
    "end": "964680"
  },
  {
    "text": "lot of queries and then you can do retrieval and ranking and then you could",
    "start": "964680",
    "end": "970560"
  },
  {
    "text": "evaluate your method and the data set is basically split into three parts so there's a train part and a development",
    "start": "970560",
    "end": "977279"
  },
  {
    "text": "part and a test split so you can use those train queries to train models",
    "start": "977279",
    "end": "982920"
  },
  {
    "text": "and then you evaluate your models and then the models are applied on the same",
    "start": "982920",
    "end": "990420"
  },
  {
    "text": "domain and the same kind of distribution that they were traded on which is important and which which leads us to",
    "start": "990420",
    "end": "996540"
  },
  {
    "text": "the kind of next uh about text and retrieval and representations uh well I mean there's something a lot",
    "start": "996540",
    "end": "1004459"
  },
  {
    "text": "of focus around dance representations or vector search or vector storage right uh",
    "start": "1004459",
    "end": "1009800"
  },
  {
    "text": "and searches is is leaning towards dense representations uh the Legacy or the not",
    "start": "1009800",
    "end": "1016100"
  },
  {
    "text": "legacy but the sparse representation some people you know and I want to",
    "start": "1016100",
    "end": "1021139"
  },
  {
    "text": "contrast these two kind of techniques that are useful to travel there today",
    "start": "1021139",
    "end": "1026240"
  },
  {
    "text": "and one is the sparse Vector representation uh where you basically have a very high high dimensional Vector",
    "start": "1026240",
    "end": "1033079"
  },
  {
    "text": "space with millions of Dimensions but for any given text or query or a",
    "start": "1033079",
    "end": "1038720"
  },
  {
    "text": "document there are very few Dimensions that are actually uh non-zero right uh",
    "start": "1038720",
    "end": "1044120"
  },
  {
    "text": "then you have and this fits well with a data structure called inverted indexes you can efficiently retrieve over this",
    "start": "1044120",
    "end": "1050240"
  },
  {
    "text": "and on the other hand we have the dense or the vector and embedding retrieval where we map uh text into a lover dance",
    "start": "1050240",
    "end": "1059960"
  },
  {
    "text": "vector space and where you can use nearest neighbor search or you can use",
    "start": "1059960",
    "end": "1065059"
  },
  {
    "text": "their nervous indices to speed up and introduce an approximation then I know Umar is Siri will talk about",
    "start": "1065059",
    "end": "1071780"
  },
  {
    "text": "multivactyl representation I'm sure another hybrid combinations and what I",
    "start": "1071780",
    "end": "1077780"
  },
  {
    "text": "think is important when you talk about nectar search uh and and learning representations you can also learn",
    "start": "1077780",
    "end": "1083120"
  },
  {
    "text": "sparse representation but I won't cover that but it's it's effectively a way of",
    "start": "1083120",
    "end": "1089419"
  },
  {
    "text": "learning uh representations right so you want to learn an embedding model that",
    "start": "1089419",
    "end": "1095720"
  },
  {
    "text": "will embed uh relevant documents for a query so that they are closed in this",
    "start": "1095720",
    "end": "1100940"
  },
  {
    "text": "embedding space right so you're doing representation learning so we have",
    "start": "1100940",
    "end": "1106520"
  },
  {
    "text": "better present language models so they are great we also know more about how to",
    "start": "1106520",
    "end": "1111799"
  },
  {
    "text": "produce good embeddics now but it's still largely an unsolved problem to",
    "start": "1111799",
    "end": "1117559"
  },
  {
    "text": "have these representations generalized for many different tasks",
    "start": "1117559",
    "end": "1123520"
  },
  {
    "text": "across kind of different domains and there the beer benchmarks this is",
    "start": "1123520",
    "end": "1129559"
  },
  {
    "text": "basically from the beer Benchmark and what the beer Benchmark shows is that many of these dense embedding models",
    "start": "1129559",
    "end": "1136660"
  },
  {
    "text": "that have been trained on the MS Marco labels when they are applied in a",
    "start": "1136660",
    "end": "1142039"
  },
  {
    "text": "different domain when they apply to track covered natural questions and so forth they actually",
    "start": "1142039",
    "end": "1148240"
  },
  {
    "text": "underperform uh in terms of ranking metrics compared to like a plain vanilla",
    "start": "1148240",
    "end": "1153640"
  },
  {
    "text": "bm25 that you will get out of elasticsearch or less power a partial solar",
    "start": "1153640",
    "end": "1159340"
  },
  {
    "text": "so so that's one thing that to to to be aware of but embedding models will",
    "start": "1159340",
    "end": "1164419"
  },
  {
    "text": "improve it will be better but I think personally that come behind in these two",
    "start": "1164419",
    "end": "1170120"
  },
  {
    "text": "techniques is is is the future of efficient retrieval because the sparse",
    "start": "1170120",
    "end": "1176059"
  },
  {
    "text": "representations allows you to do exact matching so you can search for entities",
    "start": "1176059",
    "end": "1181580"
  },
  {
    "text": "or phone numbers phrases and also another thing that's commonly overlooked",
    "start": "1181580",
    "end": "1186919"
  },
  {
    "text": "is that these representations handles um variable lengths while dense are",
    "start": "1186919",
    "end": "1192860"
  },
  {
    "text": "Criminal much limited to the input size of your embedded model",
    "start": "1192860",
    "end": "1199100"
  },
  {
    "text": "and plus the dense models are really fast at searching so",
    "start": "1199100",
    "end": "1204559"
  },
  {
    "text": "um yeah I have some more on on improving and adoption I'm sure that tomorrow actually is also to kind of talk about",
    "start": "1204559",
    "end": "1211280"
  },
  {
    "text": "this so and that's the way a new technique that you're actually using language models to improve zero shots",
    "start": "1211280",
    "end": "1217940"
  },
  {
    "text": "ranking so using the language models to actually generate synthetic uh clear",
    "start": "1217940",
    "end": "1223160"
  },
  {
    "text": "data and I did a blog post on this earlier on and this technique is really an emerging promising interaction and we",
    "start": "1223160",
    "end": "1230840"
  },
  {
    "text": "see a lot of papers and work around this and they've really improve uh ranking both for dance retrievers or",
    "start": "1230840",
    "end": "1236960"
  },
  {
    "text": "multi-vector representations where you can actually generate training data and I'm 100 sure that this is the future of",
    "start": "1236960",
    "end": "1244220"
  },
  {
    "text": "how you adapt to your domain and how you make dense models or any types of",
    "start": "1244220",
    "end": "1250580"
  },
  {
    "text": "ranking model better for your domain that you actually use slash language models to generate synthetic data for",
    "start": "1250580",
    "end": "1256640"
  },
  {
    "text": "training and and we do see this also now catching on or having I mean it's been playing out in the industry for some",
    "start": "1256640",
    "end": "1263000"
  },
  {
    "text": "time but Spotify is one example they did a paper on that and I think that's",
    "start": "1263000",
    "end": "1268580"
  },
  {
    "text": "really interesting too that they add synthetic data to the training their dance retrieval methods and yeah we love",
    "start": "1268580",
    "end": "1276020"
  },
  {
    "text": "Spotify because they use less before for Vector search so um yeah so that's an interesting",
    "start": "1276020",
    "end": "1282140"
  },
  {
    "text": "Direction uh another thing I briefly touched on is that uh in at scale you",
    "start": "1282140",
    "end": "1287960"
  },
  {
    "text": "need to some kind of have some taste to achieve one ranking to to save costs but uh that's a separate thing yeah a few",
    "start": "1287960",
    "end": "1295820"
  },
  {
    "text": "practical tips that I've seen uh I think we need to focus more on the garbage in garbage it comes out uh we also need to",
    "start": "1295820",
    "end": "1303320"
  },
  {
    "text": "focus on you know getting the right data into the index and you know how to format it and index it correctly and",
    "start": "1303320",
    "end": "1309080"
  },
  {
    "text": "then you can also do attribution that how you can link the generated answer and like I said earlier uh evaluate",
    "start": "1309080",
    "end": "1317059"
  },
  {
    "text": "these two Retriever and graduation separately yeah Joe so yeah for the",
    "start": "1317059",
    "end": "1323960"
  },
  {
    "text": "garbage in garbage out and then getting the right data in that seems like very practical and so I'm sure a lot of",
    "start": "1323960",
    "end": "1329240"
  },
  {
    "text": "people here like what exactly does that mean and what are some like best best practices here right so I think this is",
    "start": "1329240",
    "end": "1336559"
  },
  {
    "text": "standard uh standard basically from search this is uh from uh the thing that",
    "start": "1336559",
    "end": "1342260"
  },
  {
    "text": "we are building and here I'm asking it what are the available pre-trained models that you can use investment cloud",
    "start": "1342260",
    "end": "1347360"
  },
  {
    "text": "and as you can see it doesn't pick up the models because we haven't been able to parse this h",
    "start": "1347360",
    "end": "1353260"
  },
  {
    "text": "correctly right so those type of Errors you know try to try to avoid that I",
    "start": "1353260",
    "end": "1358880"
  },
  {
    "text": "think one unique experience with this is that we do capture the whole page experience",
    "start": "1358880",
    "end": "1365419"
  },
  {
    "text": "with the links we don't blob this into one snippet and just press enter snippet because for us it's really important",
    "start": "1365419",
    "end": "1372080"
  },
  {
    "text": "that um you can attribute the answer and you can click through the sources and you can copy the code or the examples",
    "start": "1372080",
    "end": "1378860"
  },
  {
    "text": "because it it can still hallucinate so I think it's really important that we actually show a very good representation",
    "start": "1378860",
    "end": "1384860"
  },
  {
    "text": "of the original source yeah so that's pretty much what I what I had",
    "start": "1384860",
    "end": "1392120"
  },
  {
    "text": "so if you edit it you can tweet me on Twitter I'm I'm active on Twitter so",
    "start": "1392120",
    "end": "1398840"
  },
  {
    "text": "yeah I'm really looking forward for almost presentation so",
    "start": "1398840",
    "end": "1404299"
  },
  {
    "text": "um yeah thanks uh thanks Joe I'll be you know canceling you on Twitter later",
    "start": "1404299",
    "end": "1410419"
  },
  {
    "text": "um yeah the question I had was you mentioned",
    "start": "1410419",
    "end": "1416240"
  },
  {
    "text": "these um you mentioned doing your like ranking",
    "start": "1416240",
    "end": "1421360"
  },
  {
    "text": "with like synthetic data from language models um but I was surprised you didn't",
    "start": "1421360",
    "end": "1427039"
  },
  {
    "text": "mention that earlier than when we were talking about like evaluating your IR system um so do you think there's a reason why",
    "start": "1427039",
    "end": "1433100"
  },
  {
    "text": "you shouldn't do that like those kinds of like evaluations or like tests or",
    "start": "1433100",
    "end": "1438200"
  },
  {
    "text": "like things like that with synthetic data and it should only be used for that uh",
    "start": "1438200",
    "end": "1443480"
  },
  {
    "text": "re-ranking um no I I think you can be used to both but uh you can ask the the language model to",
    "start": "1443480",
    "end": "1451880"
  },
  {
    "text": "generate uh I mean there are a lot of options here uh and we used it uh in the",
    "start": "1451880",
    "end": "1457039"
  },
  {
    "text": "demo as well to for every passage uh generate five questions that you think are relevant for this passage and we use",
    "start": "1457039",
    "end": "1463460"
  },
  {
    "text": "that for to complete search and that works really well right so you can actually you know what are the type of",
    "start": "1463460",
    "end": "1468799"
  },
  {
    "text": "questions that people will will ask this data set you know you can generate that upfront",
    "start": "1468799",
    "end": "1474559"
  },
  {
    "text": "um and then if you find able to find these hard negative minings you can also",
    "start": "1474559",
    "end": "1479780"
  },
  {
    "text": "use this to train the ranking model um yeah so I think they're they're it's a really emerging topic uh but the the",
    "start": "1479780",
    "end": "1487340"
  },
  {
    "text": "I'm sure Omar also will present some of uh of his work on this and it's really",
    "start": "1487340",
    "end": "1492740"
  },
  {
    "text": "promising Direction yeah yeah so yeah you mentioned the hard negative",
    "start": "1492740",
    "end": "1499159"
  },
  {
    "text": "mining which uh like reminds me of what you said in the talk about the like tail",
    "start": "1499159",
    "end": "1504799"
  },
  {
    "text": "right the like really difficult queries so I'm curious what are your thoughts on how to ensure like people want metrics",
    "start": "1504799",
    "end": "1511340"
  },
  {
    "text": "they want recall okay and precision at K and not lgtm uh okay and but like a lot",
    "start": "1511340",
    "end": "1517940"
  },
  {
    "text": "of those are like these statistical metrics that are going to over emphasize bulk of distribution and under emphasize",
    "start": "1517940",
    "end": "1523460"
  },
  {
    "text": "the tale of the distribution these like rare complicated queries do you have any thoughts about like how to structure",
    "start": "1523460",
    "end": "1529340"
  },
  {
    "text": "your metrics maybe how to structure your continuous integration pipeline or your",
    "start": "1529340",
    "end": "1534679"
  },
  {
    "text": "engineering workflows to ensure that you are not regressing on the tail or improving on that tail",
    "start": "1534679",
    "end": "1540620"
  },
  {
    "text": "yeah I think I think once you get traction once you have actually real user data so that you know what the",
    "start": "1540620",
    "end": "1546260"
  },
  {
    "text": "distribution will be uh you should basically you know as a startup or you're studying the build on this uh you",
    "start": "1546260",
    "end": "1552440"
  },
  {
    "text": "should you should focus also you know getting those head queries you know to stop because that's what has the most",
    "start": "1552440",
    "end": "1558799"
  },
  {
    "text": "impact you know if you cannot get the basic rights people will leave right but so so you see so you should when you're",
    "start": "1558799",
    "end": "1565460"
  },
  {
    "text": "evaluating and that's why I kept that point is that you know you you have to be mindful about these things because in",
    "start": "1565460",
    "end": "1571340"
  },
  {
    "text": "some cases if you're rolling out changes you know you might uh it might improve",
    "start": "1571340",
    "end": "1576679"
  },
  {
    "text": "the tail but then you are destroying the head right which will have a virtual",
    "start": "1576679",
    "end": "1581779"
  },
  {
    "text": "effect on on your product so yeah it's it's uh it's not trivial uh",
    "start": "1581779",
    "end": "1589039"
  },
  {
    "text": "I would say and that's the one thing I didn't touch on is that these uh how",
    "start": "1589039",
    "end": "1594559"
  },
  {
    "text": "you're gonna occur how are you planning the using the large larger language models to plan how you're going to do",
    "start": "1594559",
    "end": "1600380"
  },
  {
    "text": "more into the agent plan to planning on how you do in your careers and so on I",
    "start": "1600380",
    "end": "1605539"
  },
  {
    "text": "think that's really uh interesting and Powerful uh uh and and just seeing I I",
    "start": "1605539",
    "end": "1610880"
  },
  {
    "text": "remember I saw one of the examples from the language chain documentation and I started to a colleague and said you know hey look you know this is super",
    "start": "1610880",
    "end": "1617900"
  },
  {
    "text": "interesting because everybody in search will be talking about query understanding for 20 years but it's",
    "start": "1617900",
    "end": "1623659"
  },
  {
    "text": "generally like hand waving like this but they actually saw a concrete example so yeah",
    "start": "1623659",
    "end": "1630020"
  },
  {
    "text": "and then I wanted to make sure we got at least one of the great questions from the audience we'll we'll talk about them",
    "start": "1630020",
    "end": "1635179"
  },
  {
    "text": "also after Omar's talk um but I wanted to at least prove to people that their questions coming in in",
    "start": "1635179",
    "end": "1640460"
  },
  {
    "text": "the Q a will get answered um and there was a really great one from VM uh which is related to what we've been talking",
    "start": "1640460",
    "end": "1647000"
  },
  {
    "text": "about which is particularly measuring and benchmarking hallucinations uh so",
    "start": "1647000",
    "end": "1652700"
  },
  {
    "text": "you talked about spans and spans are one way that people have like ensured that there's no hallucination in in like a",
    "start": "1652700",
    "end": "1658700"
  },
  {
    "text": "prior generation of NLP so I'm curious like is professional techniques for",
    "start": "1658700",
    "end": "1664820"
  },
  {
    "text": "hallucinations do you think that they show up if you just annotate and Benchmark in normal ways do you need",
    "start": "1664820",
    "end": "1670159"
  },
  {
    "text": "special guard rails what do you think foreign I think it's really outside of my core",
    "start": "1670159",
    "end": "1678020"
  },
  {
    "text": "competence to comment on it so I I'll refer to to the actual last webinar uh",
    "start": "1678020",
    "end": "1684080"
  },
  {
    "text": "on hallucinations but I do think that it's smart to evaluate these separately",
    "start": "1684080",
    "end": "1689120"
  },
  {
    "text": "right so have you retrieved enough relevant information to answer the",
    "start": "1689120",
    "end": "1694340"
  },
  {
    "text": "question right so you can basically evaluate that and what is the generation that is coming out of that is that",
    "start": "1694340",
    "end": "1701480"
  },
  {
    "text": "hallucinated or is it not right so I think having that separation because that means you might have sold the",
    "start": "1701480",
    "end": "1708440"
  },
  {
    "text": "retrieval problem but then you have more of a prompt problem the language model how you how you tune that yeah so you",
    "start": "1708440",
    "end": "1715159"
  },
  {
    "text": "can separate how you spend the rest of the time improving it yeah I think that makes sense yeah sort",
    "start": "1715159",
    "end": "1721520"
  },
  {
    "text": "of treating these as separate types of bugs separate like categories exactly exactly",
    "start": "1721520",
    "end": "1726620"
  },
  {
    "text": "yeah exactly okay well then",
    "start": "1726620",
    "end": "1732380"
  },
  {
    "text": "um yeah we'll hear again from Joe uh when we uh when we have our open q a",
    "start": "1732380",
    "end": "1737840"
  },
  {
    "text": "session at the end uh but next up we have Omar so let me pull you up here Omar and um",
    "start": "1737840",
    "end": "1745400"
  },
  {
    "text": "uh yeah so Omar was going to share primarily about a specific technique and",
    "start": "1745400",
    "end": "1751159"
  },
  {
    "text": "some models for this specific technique of uh multi-factor retrieval um so yeah",
    "start": "1751159",
    "end": "1756440"
  },
  {
    "text": "uh Omar I think uh you can take it away all right yeah uh thanks for hosting us",
    "start": "1756440",
    "end": "1762500"
  },
  {
    "text": "Harrison uh and thanks for uh joining Charles and you know leading the discussion uh Joe I really enjoyed your",
    "start": "1762500",
    "end": "1769460"
  },
  {
    "text": "talk you know we've been in touch for a long time since you know you guys integrated Colbert into Vespa one of the very earliest Integrations maybe the",
    "start": "1769460",
    "end": "1776419"
  },
  {
    "text": "very first one so today I want to talk about um effective retrieval models and",
    "start": "1776419",
    "end": "1781820"
  },
  {
    "text": "strategies for knowledge intensive tasks and this you know builds I think very",
    "start": "1781820",
    "end": "1786860"
  },
  {
    "text": "directly on the things that Joe introduced um and in particular I want to highlight two things that pertain to what we've",
    "start": "1786860",
    "end": "1792679"
  },
  {
    "text": "been building at Stanford over the past almost four years now so um I'll talk about how Colbert which is",
    "start": "1792679",
    "end": "1799820"
  },
  {
    "text": "the Standalone really powerful general purpose retrieval model could fit into you know Lang chain uh you know chains",
    "start": "1799820",
    "end": "1806179"
  },
  {
    "text": "in the future uh you know this is something that could be integrated and could be very powerful there and for the",
    "start": "1806179",
    "end": "1812059"
  },
  {
    "text": "longer tale of sort of more advanced settings how can you adapt a retriever",
    "start": "1812059",
    "end": "1817880"
  },
  {
    "text": "to kind of more nuanced tasks and also react you know to or respond to you know",
    "start": "1817880",
    "end": "1823340"
  },
  {
    "text": "issues that arise and essentially improve the pipelines that you're using within retrieval in say a line chain",
    "start": "1823340",
    "end": "1830659"
  },
  {
    "text": "agent or you know uh some other chain that you have so this is work with lots of you know folks in The Colbert and DSP",
    "start": "1830659",
    "end": "1836720"
  },
  {
    "text": "team so this includes you know all the people listed and my advisors at Stanford",
    "start": "1836720",
    "end": "1843380"
  },
  {
    "text": "all right so I'm not going to spend a lot of time on introducing IR again we all kind of know it and Joe did a great",
    "start": "1843380",
    "end": "1849679"
  },
  {
    "text": "job but basically the setting I'll start with here at the beginning is that we're just given this text query and we'd like",
    "start": "1849679",
    "end": "1855380"
  },
  {
    "text": "our retriever to consult some large Text corpus maybe it's our you know private data Maybe it's Wikipedia maybe it's you",
    "start": "1855380",
    "end": "1862279"
  },
  {
    "text": "know a large chunk of the internet that we've crawled whatever it is and we want it to surface A ranked list of results",
    "start": "1862279",
    "end": "1868279"
  },
  {
    "text": "that maybe we can give later to a language model or it could be part of a more complex pipeline that we're building and you know this is something",
    "start": "1868279",
    "end": "1875480"
  },
  {
    "text": "that we and others have explored in many Downstream tasks maybe you're trying to answer questions maybe you're trying to",
    "start": "1875480",
    "end": "1881000"
  },
  {
    "text": "do fact checking or you're trying to have a chat bot with a user and you know this is the sort of thing that you know",
    "start": "1881000",
    "end": "1887000"
  },
  {
    "text": "we've been exploring basically during my PhD over the past few years um and one of the things that you know",
    "start": "1887000",
    "end": "1893360"
  },
  {
    "text": "working in this space for a while teaches you is that this is a beautiful place for studying balance between",
    "start": "1893360",
    "end": "1901039"
  },
  {
    "text": "quality and efficiency what we want our systems are going to answer challenging natural language you know queries",
    "start": "1901039",
    "end": "1907360"
  },
  {
    "text": "you know in some cases very Advanced complex questions but they also need to work in seconds and ideally really",
    "start": "1907360",
    "end": "1914240"
  },
  {
    "text": "milliseconds working with millions of documents or you know tens or hundreds of millions of documents as I show",
    "start": "1914240",
    "end": "1920240"
  },
  {
    "text": "um and you know when we started working you know you know in in this in this space from a neural standpoint there",
    "start": "1920240",
    "end": "1927200"
  },
  {
    "text": "were two extreme matching paradigms that were sort of plausible and that existed and this is actually kind of like right",
    "start": "1927200",
    "end": "1933200"
  },
  {
    "text": "after you know Bert started being used in IR um so there's this sort of single Vector",
    "start": "1933200",
    "end": "1938600"
  },
  {
    "text": "representation world and this is sort of the Paradigm that Joe emphasized today because this is the mainstream way and",
    "start": "1938600",
    "end": "1943820"
  },
  {
    "text": "most of you here using retrieval methods or maybe almost everybody you know who's not using a Colbert variant is doing",
    "start": "1943820",
    "end": "1950179"
  },
  {
    "text": "something like this in in this in this formulation you have a bunch of documents you're going to run them through a tower architecture maybe birth",
    "start": "1950179",
    "end": "1956720"
  },
  {
    "text": "or something else and you're gonna ask it to generate a vector maybe a dense Vector maybe a sports vector and then",
    "start": "1956720",
    "end": "1963260"
  },
  {
    "text": "you're gonna index these vectors or store them for search later you get a query in the future you're going to run it through a similar or maybe the same",
    "start": "1963260",
    "end": "1969200"
  },
  {
    "text": "birth architecture or some other hidden proprietary thing maybe open Ai embeddings and it's going to give you",
    "start": "1969200",
    "end": "1974240"
  },
  {
    "text": "the single dense Vector at the end of the day and then you're going to do some nearest neighbor similarity search",
    "start": "1974240",
    "end": "1981080"
  },
  {
    "text": "um this is great in some ways you know I mean we take it for granted but the fact that the query and document are encoded",
    "start": "1981080",
    "end": "1987140"
  },
  {
    "text": "independently means a lot you know you could encode these documents once in advance and cache them and store them",
    "start": "1987140",
    "end": "1993019"
  },
  {
    "text": "and reuse them and that you know dramatically makes you you know able to do things that you wouldn't be able to",
    "start": "1993019",
    "end": "1998179"
  },
  {
    "text": "do otherwise and obviously dramatically reduces costs imagine having to compute representations for the documents for",
    "start": "1998179",
    "end": "2004299"
  },
  {
    "text": "every new query um on the flip side though this is not really you know a very versatile",
    "start": "2004299",
    "end": "2010240"
  },
  {
    "text": "approach the reason being um you know you're forced as a model to find this one vector in this one",
    "start": "2010240",
    "end": "2017080"
  },
  {
    "text": "embedding space that is supposed to be able to answer every possible question about a large chunk of text maybe a",
    "start": "2017080",
    "end": "2023380"
  },
  {
    "text": "paragraph or even longer and that's you know if your intuition tells you that's not easy because it's really not easy",
    "start": "2023380",
    "end": "2028720"
  },
  {
    "text": "it's a very heavy burden on these models um and you know this has been the message that we've been sending for for",
    "start": "2028720",
    "end": "2034659"
  },
  {
    "text": "years now and you know it's it's it's it's true as ever so a different Paradigm that sort of have actually you",
    "start": "2034659",
    "end": "2041380"
  },
  {
    "text": "know that predates some of the birth work on you know buying quarters like the ones on the left although not all",
    "start": "2041380",
    "end": "2046720"
  },
  {
    "text": "work on buying quarters um is working with cross encoders maybe you've heard of re-rankers I mean recently introduced some of these so this is an old sort of",
    "start": "2046720",
    "end": "2053500"
  },
  {
    "text": "approach also but differently from the other thing you can see all these dense connections there it pays attention to",
    "start": "2053500",
    "end": "2058960"
  },
  {
    "text": "queries and documents at once extremely powerful fine-grained interactions it it looks at the document in light of the",
    "start": "2058960",
    "end": "2065800"
  },
  {
    "text": "query and so it's very powerful but the problem is it's extremely unscalable you know every time you have a new query all",
    "start": "2065800",
    "end": "2072220"
  },
  {
    "text": "of the documents representations that you've had before are useless because they've not been conditioned on a new",
    "start": "2072220",
    "end": "2077378"
  },
  {
    "text": "query that you have so this is not scale like if you have millions of documents you know you're not going to want to re-encode all of them for every query",
    "start": "2077379",
    "end": "2084099"
  },
  {
    "text": "that's not practical um and this is what motivated Us in late",
    "start": "2084099",
    "end": "2089618"
  },
  {
    "text": "2019 uh you know to build cool bear and you know release this uh actually the same week as DPR you know that you might",
    "start": "2089619",
    "end": "2096700"
  },
  {
    "text": "have heard of um where our goal is to keep the best of both we'd like to have independent",
    "start": "2096700",
    "end": "2102400"
  },
  {
    "text": "encodings we're not going to have like these you know early interactions between queries and documents and so",
    "start": "2102400",
    "end": "2107920"
  },
  {
    "text": "they're going to be encoded independently but key thing is we'd like to have fine-grained representations for them meaning We're not gonna have this",
    "start": "2107920",
    "end": "2114880"
  },
  {
    "text": "bottleneck of reducing each of these into a single Vector because it's really not that plausible you know to to",
    "start": "2114880",
    "end": "2121300"
  },
  {
    "text": "restrict yourself to something like this now the challenge that you face here is well now you have a matrix you have a",
    "start": "2121300",
    "end": "2127300"
  },
  {
    "text": "set of vectors for that for each document and a set of vectors for each query it's not a single Vector anymore and so standard similarity search is not",
    "start": "2127300",
    "end": "2133839"
  },
  {
    "text": "even well defined anymore what should we do so what we're going to do is we want basically a method that estimates",
    "start": "2133839",
    "end": "2140440"
  },
  {
    "text": "similarity between two matrices but we're not going to do it you know naively what we want is something that",
    "start": "2140440",
    "end": "2145839"
  },
  {
    "text": "is going to be scalable something that would still allow us to use you know indexes and efficient representations",
    "start": "2145839",
    "end": "2151960"
  },
  {
    "text": "that could scale this to tensor or hundreds of millions of passages in milliseconds so",
    "start": "2151960",
    "end": "2157720"
  },
  {
    "text": "you know what we came up with was this scoring function that is essentially going to take every query term that is",
    "start": "2157720",
    "end": "2163780"
  },
  {
    "text": "encoded as a vector and is going to find the nearest match to that term in that in that document and we're going to",
    "start": "2163780",
    "end": "2170440"
  },
  {
    "text": "repeat this and we're simply going to sum up these scores and then um you know what we're what we're trying",
    "start": "2170440",
    "end": "2175599"
  },
  {
    "text": "to say here is that for every term in the query it's a lot easier to contextually map that um into a vector",
    "start": "2175599",
    "end": "2181839"
  },
  {
    "text": "representation because we're just trying to understand one token in its context and that's a much easier task than",
    "start": "2181839",
    "end": "2187480"
  },
  {
    "text": "trying to understand a blob of 500 Words um that may or may not you know uh that",
    "start": "2187480",
    "end": "2194740"
  },
  {
    "text": "you may not know what questions would be asked about um and so with this with this Matrix representation",
    "start": "2194740",
    "end": "2201280"
  },
  {
    "text": "um because of the task is is that much simpler these vectors you know there's a whole lot of vectors here but they can",
    "start": "2201280",
    "end": "2206440"
  },
  {
    "text": "be extremely small and they can be indexed for faster so for instance in our early iteration of Colbert you could",
    "start": "2206440",
    "end": "2212859"
  },
  {
    "text": "index all of Wikipedia and search you know and search it in just 70 milliseconds and it's only only been",
    "start": "2212859",
    "end": "2218200"
  },
  {
    "text": "getting faster and you know and and cheaper to work with um so just as an intuition building exercise here here's a real exercise of",
    "start": "2218200",
    "end": "2226060"
  },
  {
    "text": "matching say you wanted to answer the question when the Transformers cartoons just come out you know uh not the the",
    "start": "2226060",
    "end": "2231820"
  },
  {
    "text": "attention is all you need paper um so this is the query and I have Snippets from the document here the",
    "start": "2231820",
    "end": "2236980"
  },
  {
    "text": "relevant document and if you look at what Colbert does at matching time it encodes the word when with a vector",
    "start": "2236980",
    "end": "2242920"
  },
  {
    "text": "representation that's very close to the on in you know in in the answer that talks about the date you know certainly",
    "start": "2242920",
    "end": "2249400"
  },
  {
    "text": "it gives Transformers as you know a similar representation in both the query and the document cartoon matches with",
    "start": "2249400",
    "end": "2254560"
  },
  {
    "text": "the verb animated very reasonable you know and release matches with come um so you know does this actually work",
    "start": "2254560",
    "end": "2262060"
  },
  {
    "text": "and what we learned back in you know late 2019 early 2020 is that you know compared with concurrent approaches that",
    "start": "2262060",
    "end": "2268839"
  },
  {
    "text": "use Bert also for you know single Vector representations things that are really popular DPR or NC Colbert you know is a",
    "start": "2268839",
    "end": "2276040"
  },
  {
    "text": "whole lot better in Downstream matching in fact it preserves all of the accuracy of the re-rankers that are really",
    "start": "2276040",
    "end": "2281560"
  },
  {
    "text": "expensive you know that I talked about um while being you know obviously orders of magnitudes faster than cheaper",
    "start": "2281560",
    "end": "2288579"
  },
  {
    "text": "um and you know this is something that you know you reliably see on on many tasks the interesting thing though that",
    "start": "2288579",
    "end": "2295180"
  },
  {
    "text": "we didn't think of when we built Colbert was that when there's a domain shift when you're which is something that Joe highlighted when you're trying to move",
    "start": "2295180",
    "end": "2301599"
  },
  {
    "text": "from the training domain say Ms Marco or natural questions and you're trying to test these models in new settings the",
    "start": "2301599",
    "end": "2308440"
  },
  {
    "text": "interesting thing that I think was first highlighted by beer in their evaluations was that you know these interaction",
    "start": "2308440",
    "end": "2313960"
  },
  {
    "text": "models in particular late interaction uh or you know the expensive interaction they're a lot better at sort of transfer",
    "start": "2313960",
    "end": "2319900"
  },
  {
    "text": "from one domain to the other and our intuition for that is encoding context",
    "start": "2319900",
    "end": "2325359"
  },
  {
    "text": "at the level of tokens is just a whole lot easier and more robust and resilient than you know you know cramming",
    "start": "2325359",
    "end": "2332020"
  },
  {
    "text": "everything into one vector no matter how large you make it um and you know ever since there's been lots and lots of studies sort of",
    "start": "2332020",
    "end": "2338320"
  },
  {
    "text": "confirming like interaction is generally a lot better than you know single Vector retrievals for search but we've also",
    "start": "2338320",
    "end": "2344800"
  },
  {
    "text": "been doing work and others have been doing work applying this to um Downstream tasks",
    "start": "2344800",
    "end": "2350680"
  },
  {
    "text": "so this was called bear V1 um you know if you're gonna use this we strongly recommend Colbert V2 which we",
    "start": "2350680",
    "end": "2356320"
  },
  {
    "text": "built um you know in late 2021 early 2022 and we focused here explicitly on trying to",
    "start": "2356320",
    "end": "2362200"
  },
  {
    "text": "get models that generalize better V1 generalized better to new domains just",
    "start": "2362200",
    "end": "2367420"
  },
  {
    "text": "by happenstance it works better um but could bear V2 was purpose Built For This by uh you know a more resilient",
    "start": "2367420",
    "end": "2374079"
  },
  {
    "text": "denoise training strategy look you know I I refer to the I refer you to the paper for the details of that but we",
    "start": "2374079",
    "end": "2379480"
  },
  {
    "text": "also built this residual compression technique so that each of the vectors in The Colbert storage are really small so",
    "start": "2379480",
    "end": "2385060"
  },
  {
    "text": "if you work with Colbert B2 right now even though we have you know more than 10 times as many vectors as you're you",
    "start": "2385060",
    "end": "2390460"
  },
  {
    "text": "know like off the shelf by encoder um the vectors are actually taking no more space than a standard you know like",
    "start": "2390460",
    "end": "2397119"
  },
  {
    "text": "VPR retriever or you know this single guy to retrievers because each of our vectors could be included in as little",
    "start": "2397119",
    "end": "2402220"
  },
  {
    "text": "as 20 bytes or something like that um so you know we have applied this in",
    "start": "2402220",
    "end": "2407260"
  },
  {
    "text": "domain and out of domain uh so the the two tables and out of the main deaths a whole bunch of them beer we also",
    "start": "2407260",
    "end": "2413440"
  },
  {
    "text": "introduced this latte you know a a play on the words there um and",
    "start": "2413440",
    "end": "2419859"
  },
  {
    "text": "um you know in that cross you know I think it was something like you could count them but it was like 22 out of 30 evaluations you know it it comes out on",
    "start": "2419859",
    "end": "2427599"
  },
  {
    "text": "top across a wide range of you know sparse and dense uh retrieval models uh that are you know very recent and",
    "start": "2427599",
    "end": "2433900"
  },
  {
    "text": "Powerful um so you know the the the the the Colbert V2 introduction which is you",
    "start": "2433900",
    "end": "2439480"
  },
  {
    "text": "know what's what's what's on the you know Colbert Report right now you know it reduces the index size quite a bit over Cooper V1 and obviously maintains",
    "start": "2439480",
    "end": "2446859"
  },
  {
    "text": "the same highly efficient um you know latency and Survey more recently than that we introduced uh dedicated",
    "start": "2446859",
    "end": "2453520"
  },
  {
    "text": "retrieval engine like because we have this different interaction mechanism uh like interaction",
    "start": "2453520",
    "end": "2459820"
  },
  {
    "text": "um and what we wanted is you know to build an engine that can support efficient serving of these models at",
    "start": "2459820",
    "end": "2465940"
  },
  {
    "text": "Large Scale or efficient search at Large Scale so this is something that you know we spent a bunch of exploration on and",
    "start": "2465940",
    "end": "2471579"
  },
  {
    "text": "you know just to to highlight a few of the uh you know of the results there so if you're working with something like Ms",
    "start": "2471579",
    "end": "2477099"
  },
  {
    "text": "Marco this is probably larger than most of the you know local data sets you might work with so it has half a billion",
    "start": "2477099",
    "end": "2482380"
  },
  {
    "text": "tokens with a B 9 million passages you could encode this uh you know in in uh",
    "start": "2482380",
    "end": "2487780"
  },
  {
    "text": "in colder V2 was pled and as little as 25 gigabytes and you can search even if you don't have a GPU in just 45",
    "start": "2487780",
    "end": "2493900"
  },
  {
    "text": "milliseconds for each query um Wikipedia a bit larger um but you know the entire index could",
    "start": "2493900",
    "end": "2499960"
  },
  {
    "text": "be around 100 gigabytes and you could search you know with a CPU and as little as 67 milliseconds and if you have a GPU",
    "start": "2499960",
    "end": "2505960"
  },
  {
    "text": "it only gets faster and then the largest data set we tried was Ms Marco V2 which has close to 10 billion tokens 140",
    "start": "2505960",
    "end": "2513880"
  },
  {
    "text": "million passages and the index is still you know just 200 gigabit gigabytes and you know you could still search this on",
    "start": "2513880",
    "end": "2520060"
  },
  {
    "text": "a CPU um you know in just a little over 180 seconds and obviously with the GPU again",
    "start": "2520060",
    "end": "2525099"
  },
  {
    "text": "a lot faster so this is you know public you could just go to the Colbert repository uh and",
    "start": "2525099",
    "end": "2530980"
  },
  {
    "text": "play with this this is something that maybe you know will be exciting to chat about you know Integrations of something like this into into line chain I guess",
    "start": "2530980",
    "end": "2537700"
  },
  {
    "text": "you could actually already use versions of this through Vespa in line chain so that might be an interesting you know a",
    "start": "2537700",
    "end": "2543579"
  },
  {
    "text": "different way to to to to to to do to do a lot of this um I was going to ask exactly that like",
    "start": "2543579",
    "end": "2550960"
  },
  {
    "text": "what is the what is the easiest way for people to to play around with this and like what would that involve so if you",
    "start": "2550960",
    "end": "2556720"
  },
  {
    "text": "know if I go to that GitHub repo do I have to like host the the kind do I have to like run the embedding model like",
    "start": "2556720",
    "end": "2562839"
  },
  {
    "text": "locally myself and host that and it sounds like maybe there's something in Vespa that takes care of that are there other like what's the is yeah what's",
    "start": "2562839",
    "end": "2569680"
  },
  {
    "text": "this what's the simple or what are the what are the options for people to use this and what would those entail so cool there is is more of a you know it's just",
    "start": "2569680",
    "end": "2576880"
  },
  {
    "text": "a you know it's a model so there's a checkpoint and then there is the encoders and then there is the",
    "start": "2576880",
    "end": "2582040"
  },
  {
    "text": "infrastructure that we have for serving uh the infrastructure here being software infrastructure if you want to host Justice uh or or such either you",
    "start": "2582040",
    "end": "2589540"
  },
  {
    "text": "dedicate your own machine with CPUs for search and gpus for indexing",
    "start": "2589540",
    "end": "2595119"
  },
  {
    "text": "um or you know Vespa might be you know your best shot otherwise um add this uh in terms of a hosted a",
    "start": "2595119",
    "end": "2601599"
  },
  {
    "text": "hosted uh I'm not aware of any other hosted versions of this but you know certainly uh you know I I hope that",
    "start": "2601599",
    "end": "2607420"
  },
  {
    "text": "looking at various results that I have she I've shown and will show up more of will encourage more people to sort of",
    "start": "2607420",
    "end": "2613480"
  },
  {
    "text": "build infrastructure around this the challenge being you know you get a lot of quality and it's fast and it's",
    "start": "2613480",
    "end": "2618880"
  },
  {
    "text": "efficient but it's a different infrastructure so that's the that's where something like vespa's flexibility",
    "start": "2618880",
    "end": "2624339"
  },
  {
    "text": "I think the query language uh you know didn't get a chance to highlight that but it's maybe not as much as as we'd",
    "start": "2624339",
    "end": "2629680"
  },
  {
    "text": "like but you know it's a very powerful query language that makes that possible um but actually I I so I'm happy to take",
    "start": "2629680",
    "end": "2635740"
  },
  {
    "text": "more questions about that but I wanted to highlight um sort of a kind of a bigger picture story here so suppose that you you know",
    "start": "2635740",
    "end": "2642520"
  },
  {
    "text": "you're not working in isolation and I think a lot of the questions we're talking about scenario videos where you just don't have a lot of data and you",
    "start": "2642520",
    "end": "2649359"
  },
  {
    "text": "know you can't just like train you know uh your own retrievers and such and you know you could just use Colbert out of",
    "start": "2649359",
    "end": "2655300"
  },
  {
    "text": "the box zero shot but could you do better um and so we spent the last two to three",
    "start": "2655300",
    "end": "2660520"
  },
  {
    "text": "years looking at like how we can apply Colbert to new domain so I mentioned Kobe V2 already for zero search but if",
    "start": "2660520",
    "end": "2666339"
  },
  {
    "text": "you wanted to answer questions with language models um you know we've looked at Colbert Q8 which is this sort of uh um pipeline for",
    "start": "2666339",
    "end": "2674319"
  },
  {
    "text": "essentially very similar to rag but has a different supervision technique and uses Colbert and that that delivers",
    "start": "2674319",
    "end": "2680079"
  },
  {
    "text": "large gains against things like that um we also built this system hindsight led by Ashwin here at Stanford",
    "start": "2680079",
    "end": "2687099"
  },
  {
    "text": "um which focuses on trying to build chat Bots with colbert-like models and how do",
    "start": "2687099",
    "end": "2692200"
  },
  {
    "text": "you make it grounded and check for hallucination and things like that so people who are looking for ways to evaluate that definitely check out",
    "start": "2692200",
    "end": "2697960"
  },
  {
    "text": "um uh hindsight and we looked at also just fact checking especially in multi-hop and complex questions and you",
    "start": "2697960",
    "end": "2704319"
  },
  {
    "text": "know I don't want you to go and read each of these papers now unless it's exactly relevant to you but what based",
    "start": "2704319",
    "end": "2710079"
  },
  {
    "text": "on but what I want to say is based on these sort of building these different systems on top of Colbert or colbert-like models um we've been",
    "start": "2710079",
    "end": "2716619"
  },
  {
    "text": "working for the last year or a little bit more on what you should use in 2023 to adapt retrieval maybe it was Colbert",
    "start": "2716619",
    "end": "2722859"
  },
  {
    "text": "or with something else to this to these fast changing data scores fat you know",
    "start": "2722859",
    "end": "2728200"
  },
  {
    "text": "um sort of constantly you know evolving Downstream tasks and for that you know",
    "start": "2728200",
    "end": "2734260"
  },
  {
    "text": "you could be working in line chain and you have all kinds of you know agents and tools at your disposal an additional",
    "start": "2734260",
    "end": "2739480"
  },
  {
    "text": "one that you should consider is the DSP programming model and for land chain audience you could think of the SP as",
    "start": "2739480",
    "end": "2745300"
  },
  {
    "text": "this Advanced tool builder for highly specialized retrievers so you know",
    "start": "2745300",
    "end": "2750339"
  },
  {
    "text": "you're adding tools all the time to um to line chain most of them work out of the box but let's say you have this",
    "start": "2750339",
    "end": "2756339"
  },
  {
    "text": "really difficult task where you want to specialize retrieval to work with you know specific requirements on length or",
    "start": "2756339",
    "end": "2762040"
  },
  {
    "text": "dependencies in the sense of multi-hop queries or you know you see a lot of issues that users report and you want to",
    "start": "2762040",
    "end": "2767619"
  },
  {
    "text": "tackle them working with prompts or chains or you know other abstractions can only take you so far at least in a",
    "start": "2767619",
    "end": "2774579"
  },
  {
    "text": "systematic way and this is what we build the DSP programming model for so this is something that you know you could build",
    "start": "2774579",
    "end": "2779980"
  },
  {
    "text": "tools with that you know are used by your land chain agent and at a high level um you know I can't really think dig",
    "start": "2779980",
    "end": "2786940"
  },
  {
    "text": "into all the details here but at the high level you're going to write a small program which is a python function in",
    "start": "2786940",
    "end": "2792280"
  },
  {
    "text": "you know um just plain old python with standard control flow to describe what",
    "start": "2792280",
    "end": "2797619"
  },
  {
    "text": "you know what you'd what you see your Retriever as doing in interactions with a language model and I'll I'll sort of",
    "start": "2797619",
    "end": "2804220"
  },
  {
    "text": "touch on some examples of that and the key thing is in that in that program that you're writing which might have",
    "start": "2804220",
    "end": "2809859"
  },
  {
    "text": "loops or you know if statements or just you know various complex control flow elements",
    "start": "2809859",
    "end": "2814900"
  },
  {
    "text": "um you're not going to write prompts and you're certainly not going to write few shot you know demonstrations for your",
    "start": "2814900",
    "end": "2820119"
  },
  {
    "text": "prompts instead you're going to just focus on describing the high level Pipeline and the leaves of your pipe",
    "start": "2820119",
    "end": "2826480"
  },
  {
    "text": "line are going to be these declarative calls either to a retrieval model or to a language model and you're going to use",
    "start": "2826480",
    "end": "2832800"
  },
  {
    "text": "built-in Primitives in DSP that will take your program and a language model and one or two you know and a small",
    "start": "2832800",
    "end": "2839260"
  },
  {
    "text": "number of like end-to-end task labels that you can hand annotate and I'll show examples of that and it will build up",
    "start": "2839260",
    "end": "2846400"
  },
  {
    "text": "few short pumps for your task or it could do even you know more interesting things than that like for instance the",
    "start": "2846400",
    "end": "2852339"
  },
  {
    "text": "same program that you write without changes um can work as a zero shot sort of like",
    "start": "2852339",
    "end": "2857740"
  },
  {
    "text": "pipeline it can work as a few shot pipeline without hand annotating few short examples but it can actually compile itself into a small language",
    "start": "2857740",
    "end": "2864520"
  },
  {
    "text": "model that you run locally saves you on cost makes makes you able to adapt things a little bit more sort of",
    "start": "2864520",
    "end": "2870520"
  },
  {
    "text": "concretely to your to your to your needs um and you know we we have a paper on",
    "start": "2870520",
    "end": "2875680"
  },
  {
    "text": "this so feel free to check it out on the SP um and you know we've tested this out on a bunch of tasks with you know I think",
    "start": "2875680",
    "end": "2881560"
  },
  {
    "text": "amazing results um so you know for instance what what that highlight now is if you're working",
    "start": "2881560",
    "end": "2887020"
  },
  {
    "text": "on Hotspot QA so let's say that you're building you know a conversational agent uh you know and uh maybe it can access",
    "start": "2887020",
    "end": "2895540"
  },
  {
    "text": "many tools maybe calculators and other things but one of the core functionality is you want that agent to be able to",
    "start": "2895540",
    "end": "2901240"
  },
  {
    "text": "answer complex questions uh on your data whether Retriever and maybe these",
    "start": "2901240",
    "end": "2906579"
  },
  {
    "text": "complex questions you know maybe just using an off-the-shelf retriever even if it's Colbert",
    "start": "2906579",
    "end": "2912040"
  },
  {
    "text": "um is only going to take you so far because there are inherent dependencies there are questions that you can only",
    "start": "2912040",
    "end": "2917560"
  },
  {
    "text": "answer by answering simpler decompositional questions and you know this is something that a lot of the you",
    "start": "2917560",
    "end": "2922839"
  },
  {
    "text": "know react agents and whatnot in in Langston can help you get started on but what they can't really get you to do is",
    "start": "2922839",
    "end": "2929380"
  },
  {
    "text": "how to teach them to use an arbitrary tool like you know react does not know how to use kuber B2 so you're kind of forced to use a zero shot react agent or",
    "start": "2929380",
    "end": "2936339"
  },
  {
    "text": "maybe to sit down and try to write prompts and hope they work um there's also challenges of like okay",
    "start": "2936339",
    "end": "2941560"
  },
  {
    "text": "if you want to use like react and make it reliable maybe you gotta use like gpt4 or at least an expensive you know",
    "start": "2941560",
    "end": "2946900"
  },
  {
    "text": "GPT 3.5 thing in production and maybe you don't want to you know you know put that all out there and you know not have",
    "start": "2946900",
    "end": "2953740"
  },
  {
    "text": "a lot of ways of controlling it and you know um what we what what what DSP gives you",
    "start": "2953740",
    "end": "2959500"
  },
  {
    "text": "are these magical Primitives that would take your program which is describing this retriever which could be a tool of",
    "start": "2959500",
    "end": "2965980"
  },
  {
    "text": "your line chain agent and you basically just say hey dspi it just implemented this declarative pipeline that is maybe",
    "start": "2965980",
    "end": "2973000"
  },
  {
    "text": "a zero shot DSP uh based react agent just like a copy of the uh version",
    "start": "2973000",
    "end": "2978220"
  },
  {
    "text": "that's in line chain but now I actually wrote two examples by hand of some of the questions that users ask and I have",
    "start": "2978220",
    "end": "2985000"
  },
  {
    "text": "defined that answer I definitely don't want to spend time like writing prompts or like intermediate pipeline specific",
    "start": "2985000",
    "end": "2991240"
  },
  {
    "text": "data but I just you know I have these examples and you can treat them as unit tests essentially and make sure that",
    "start": "2991240",
    "end": "2996880"
  },
  {
    "text": "whatever pipeline you have can pass those reliably so you could just say dsp.d demonstrate and give it the",
    "start": "2996880",
    "end": "3002220"
  },
  {
    "text": "function program that you wrote in in DSP and give it these two labeled you know end exam and task examples and what",
    "start": "3002220",
    "end": "3009060"
  },
  {
    "text": "we've you know what we what this would do for any orbitrary DSP pipeline that you give it",
    "start": "3009060",
    "end": "3014579"
  },
  {
    "text": "um you know and you can sort of customize the way demonstrations are done is um you know it can it can teach the language model how to interact with",
    "start": "3014579",
    "end": "3021660"
  },
  {
    "text": "the different pieces of the pipeline that you've built so for instance you know this this sort of like demonstrate",
    "start": "3021660",
    "end": "3026940"
  },
  {
    "text": "line that we have here can convert the zero shot react agent um that's written in DSP in a few lines",
    "start": "3026940",
    "end": "3032880"
  },
  {
    "text": "of code into a few short react agent that knows how to interact with Colbert V2 and in practice this can raise",
    "start": "3032880",
    "end": "3038880"
  },
  {
    "text": "accuracy on you know benchmarks like hotspot QA from around 30 in a zero shot",
    "start": "3038880",
    "end": "3044040"
  },
  {
    "text": "setting to a 35 in a few shot setting that you did not write the prompts for so it can you know teach itself how to",
    "start": "3044040",
    "end": "3049980"
  },
  {
    "text": "generate queries and how to use the passages um and you know how to control the flow Etc",
    "start": "3049980",
    "end": "3055079"
  },
  {
    "text": "and you know you could you could easily add you know extensions to the pipeline that keep raising this uh you know a very simple like a few line addition",
    "start": "3055079",
    "end": "3061859"
  },
  {
    "text": "makes this 41 uh exact match um so another sort of magical features and I'll conclude with this",
    "start": "3061859",
    "end": "3068220"
  },
  {
    "text": "um is the compile uh primitive in DSP so let's say that and a lot of people ask things related to this let's say that",
    "start": "3068220",
    "end": "3074339"
  },
  {
    "text": "you have this program now which is a bootstrapped fuse shot react agent built in DSP as a tool that you can use in",
    "start": "3074339",
    "end": "3081720"
  },
  {
    "text": "your life chain you know conversational pipeline um but it's kind of expensive because",
    "start": "3081720",
    "end": "3086760"
  },
  {
    "text": "it's going to talk to GPT 3.5 or gpt4 or whatever it is you know several times in",
    "start": "3086760",
    "end": "3091859"
  },
  {
    "text": "each query how can you make this efficient and how can you make sure this adapts to the actual queries people ask",
    "start": "3091859",
    "end": "3097380"
  },
  {
    "text": "so our solution for this is you deploy your agent and in particular you deploy this tool in front of users you gather a",
    "start": "3097380",
    "end": "3103440"
  },
  {
    "text": "bunch of questions from them these questions don't have labels they don't have answers but you know you could still you could still gather them and",
    "start": "3103440",
    "end": "3109319"
  },
  {
    "text": "and save them and then he could just say hey ESP can you please compile my program that we built here and use these",
    "start": "3109319",
    "end": "3116520"
  },
  {
    "text": "user questions and I'd like to give get to get that you know I'd like you to use in this pipeline maybe the default",
    "start": "3116520",
    "end": "3122040"
  },
  {
    "text": "language model that you have which might be configured to be T5 large um you know in on on on GitHub the",
    "start": "3122040",
    "end": "3127859"
  },
  {
    "text": "default is Ada uh open AI Ada so in you know we've been playing for with this",
    "start": "3127859",
    "end": "3133200"
  },
  {
    "text": "for a while and you know if you compile the you know a DSP program that does multi-hop search into T5 large you match",
    "start": "3133200",
    "end": "3139260"
  },
  {
    "text": "the quality of retrivo that you're getting from you know the DaVinci 3.5",
    "start": "3139260",
    "end": "3144300"
  },
  {
    "text": "um and you only lose a very small kind of margin in terms of The Final Answer accuracy but you don't need to go to",
    "start": "3144300",
    "end": "3149819"
  },
  {
    "text": "open a ISO anymore and you know this whole thing it requires like say hand",
    "start": "3149819",
    "end": "3155040"
  },
  {
    "text": "labeled examples to build the initial sort of bootstrapping of this um and so um lots of opportunities here",
    "start": "3155040",
    "end": "3162540"
  },
  {
    "text": "in terms of being able to um build your own self bootstraps retrieval Tools in something like line",
    "start": "3162540",
    "end": "3168359"
  },
  {
    "text": "chain so you know I'll I'll stop here um certainly excited about Integrations with what people are doing with in terms",
    "start": "3168359",
    "end": "3174900"
  },
  {
    "text": "of Colbert just as an initial you know um Standalone general purpose thing and",
    "start": "3174900",
    "end": "3180180"
  },
  {
    "text": "also with DSP programs that individually Implement you know uh you know uh uh",
    "start": "3180180",
    "end": "3186059"
  },
  {
    "text": "pipelines for retrieval in a more uh task specific or task aware manner",
    "start": "3186059",
    "end": "3192000"
  },
  {
    "text": "so Omar can I ask a quick question about the the DSP stuff so the so the demonstrate step is that kind of",
    "start": "3192000",
    "end": "3198599"
  },
  {
    "text": "equivalent to coming coming up with like few shot examples dynamically basically like you give it yep okay and so and",
    "start": "3198599",
    "end": "3208220"
  },
  {
    "text": "and so is that is it like like could you could you do the demonstrate step get",
    "start": "3208220",
    "end": "3213720"
  },
  {
    "text": "those few shot examples save those and like have those as as like or is it dynamically generated every time as you",
    "start": "3213720",
    "end": "3220200"
  },
  {
    "text": "go through uh so this is entirely program dependent uh I encourage people to read the paper for you know different",
    "start": "3220200",
    "end": "3226200"
  },
  {
    "text": "we described like design patterns for most tasks if you're just getting started yeah this could be a frozen set",
    "start": "3226200",
    "end": "3231540"
  },
  {
    "text": "you just generated three examples and they're fixed um but you could also Imagine fancier things where you haven't you got a new",
    "start": "3231540",
    "end": "3237660"
  },
  {
    "text": "question you have a bunch of questions in your old database and on the Fly you retrieve similar examples you have a k n",
    "start": "3237660",
    "end": "3243900"
  },
  {
    "text": "thing in in Lang chain you're going to use it to achieve some other examples and then annotate those on the Fly uh so",
    "start": "3243900",
    "end": "3249720"
  },
  {
    "text": "that the model the language model can see similar examples being answered um and leverage those um uh there uh",
    "start": "3249720",
    "end": "3258240"
  },
  {
    "text": "yeah I guess I should keep my answers short so that we have time for oh",
    "start": "3258240",
    "end": "3264020"
  },
  {
    "text": "yeah um so I wanted to grab some questions from the audience and make sure to get a",
    "start": "3264680",
    "end": "3269700"
  },
  {
    "text": "chance to get you know Joe and Omar in in conversation with each other so I'm gonna grab this one from Zaire",
    "start": "3269700",
    "end": "3277260"
  },
  {
    "text": "um so we talked a lot about like q a um that's been the task that people have",
    "start": "3277260",
    "end": "3283020"
  },
  {
    "text": "used done retrieval for but the tasks the thing that people are really excited about right now especially in The Lion King Community is around agents",
    "start": "3283020",
    "end": "3290280"
  },
  {
    "text": "um and one use of retrieval for agents is creating this sort of like hacky long-term memory",
    "start": "3290280",
    "end": "3296280"
  },
  {
    "text": "um and allowing for self-improvement so what of the like approaches that we've",
    "start": "3296280",
    "end": "3301500"
  },
  {
    "text": "seen so far in this talk or that maybe are you're aware of Joe and Omar do you think our maybe most useful for helping",
    "start": "3301500",
    "end": "3308819"
  },
  {
    "text": "with this uh with this problem of improving the memory of like an agent uh",
    "start": "3308819",
    "end": "3314400"
  },
  {
    "text": "maybe we'll start with uh with Joe yeah I I I'm not that familiar with the",
    "start": "3314400",
    "end": "3323099"
  },
  {
    "text": "terminology uh used around long-term memory short-term memory so it's it's",
    "start": "3323099",
    "end": "3328920"
  },
  {
    "text": "it's um my understanding was that long-term memory was for about the knowledge",
    "start": "3328920",
    "end": "3334619"
  },
  {
    "text": "database and not the intermediate steps but I might be wrong so I'll pass that",
    "start": "3334619",
    "end": "3339839"
  },
  {
    "text": "question maybe Omar is more into the age uh yeah I actually also don't know uh",
    "start": "3339839",
    "end": "3345720"
  },
  {
    "text": "the specific Lang chain terminology here but but in terms of self-improvement there are two paths in general there are",
    "start": "3345720",
    "end": "3352619"
  },
  {
    "text": "models and I think this is the one that's a lot more common in the agent world is kind of per example or post-hoc",
    "start": "3352619",
    "end": "3359099"
  },
  {
    "text": "self-improvement so you you're trying to do stuff you make a mistake you reflect and then you do a better job next time",
    "start": "3359099",
    "end": "3364859"
  },
  {
    "text": "um that's great that's very versatile and again you know like all these zero shop agents they allow you to do things that",
    "start": "3364859",
    "end": "3370559"
  },
  {
    "text": "like very recent not not you know just a week before length chain people",
    "start": "3370559",
    "end": "3376680"
  },
  {
    "text": "wouldn't have thought were possible you know in terms of the abstractions that generalized react and other things",
    "start": "3376680",
    "end": "3382500"
  },
  {
    "text": "um but um being reactive to the extent of reflecting per example might mean silly",
    "start": "3382500",
    "end": "3389040"
  },
  {
    "text": "things like you make the same mistake every time and then you reflect on it and then you realize you made a mistake and then you keep fixing it so that's a",
    "start": "3389040",
    "end": "3394800"
  },
  {
    "text": "little bit expensive and maybe kind of ill-advised and this is this is where",
    "start": "3394800",
    "end": "3400079"
  },
  {
    "text": "the abstraction that we have around demonstrations in DSP among other sort of things that fit up fit together say",
    "start": "3400079",
    "end": "3405359"
  },
  {
    "text": "well you know if you can collect some of these a couple of examples in advance then you can sort of essentially",
    "start": "3405359",
    "end": "3411240"
  },
  {
    "text": "bootstrap your pipeline on them in advance and it could avoid these sorts of Errors um with some you could you could",
    "start": "3411240",
    "end": "3417960"
  },
  {
    "text": "sprinkle in a little bit of rules so like the the the intuition and DSP is that you're you're building up your understanding of the task as you go and",
    "start": "3417960",
    "end": "3424440"
  },
  {
    "text": "if you could just say hey I want to handle this exception where you know I'm trying to search and I keep searching like too many times in a row or like I",
    "start": "3424440",
    "end": "3430800"
  },
  {
    "text": "try to answer before searching or whatever it is that happens in your agent because as an exception for in the",
    "start": "3430800",
    "end": "3435960"
  },
  {
    "text": "code or add like an if statement for it in the code or whatever it is Rerun recompile you get new demonstrations you",
    "start": "3435960",
    "end": "3441599"
  },
  {
    "text": "build up a new model underneath if you want to compile the way um and you know it gives you gives you",
    "start": "3441599",
    "end": "3447000"
  },
  {
    "text": "that path for self-improvement that is maybe a little bit less reactive but you could certainly use it with agents or",
    "start": "3447000",
    "end": "3452760"
  },
  {
    "text": "you know it it it fits in the bigger pipeline because this is something I don't anticipate I don't see you seeing",
    "start": "3452760",
    "end": "3458760"
  },
  {
    "text": "doing this at every little edge of your pipeline this is probably going to be what you want to reserve like the",
    "start": "3458760",
    "end": "3464579"
  },
  {
    "text": "research part of your brain and research part of your team when you're focusing at the key kind of core differentiator",
    "start": "3464579",
    "end": "3471059"
  },
  {
    "text": "of your application maybe that search maybe that is some generative component whatever it is",
    "start": "3471059",
    "end": "3476880"
  },
  {
    "text": "um at least that's that's my you know my the way I think of this",
    "start": "3476880",
    "end": "3481759"
  },
  {
    "text": "yeah I think maybe uh yeah Harrison can maybe comment on this a little bit but I think with with",
    "start": "3482040",
    "end": "3489000"
  },
  {
    "text": "yeah the self-improvement I think you're right that like finding ways to make that self-improvement persist from one conversation to another is huge and DSP",
    "start": "3489000",
    "end": "3495839"
  },
  {
    "text": "seems like a promising way to do that um I think in terms of the retrieval and",
    "start": "3495839",
    "end": "3500880"
  },
  {
    "text": "long-term memory side for agents the way it normally looks is that like the",
    "start": "3500880",
    "end": "3506339"
  },
  {
    "text": "amount of information that you're searching over is going to generally be smaller right it's like the memory of a",
    "start": "3506339",
    "end": "3511680"
  },
  {
    "text": "single agent that's more like the scale of the amount of information a person consumes on on the internet so we're",
    "start": "3511680",
    "end": "3518160"
  },
  {
    "text": "talking hundreds of documents thousands of documents rather than Millions um and then you also are maybe doing",
    "start": "3518160",
    "end": "3525180"
  },
  {
    "text": "some annotation of that at the same time with the language model so it's not just a document it's a document with",
    "start": "3525180",
    "end": "3530339"
  },
  {
    "text": "additional metadata which is a pattern that foolish sailor brought up in one of their questions about adding llm like",
    "start": "3530339",
    "end": "3537599"
  },
  {
    "text": "adding Rich metadata to documents that's also in natural language I think those",
    "start": "3537599",
    "end": "3543299"
  },
  {
    "text": "are kind of the the questions that are on people's mind for agents what if I have like a relatively small amount of documents where I want to achieve like",
    "start": "3543299",
    "end": "3549780"
  },
  {
    "text": "really really high Precision um and",
    "start": "3549780",
    "end": "3555420"
  },
  {
    "text": "um like maybe reasonable recall I don't care as much about like turbo scale",
    "start": "3555420",
    "end": "3560880"
  },
  {
    "text": "um and yeah and I'm doing that in a context where there's loms in play so",
    "start": "3560880",
    "end": "3566579"
  },
  {
    "text": "there's lots of opportunity for like metadata enrichment some of this might be previous outputs of the llm not",
    "start": "3566579",
    "end": "3572040"
  },
  {
    "text": "necessarily internet data there's a little bit more control there so uh what I would say here is um you",
    "start": "3572040",
    "end": "3578640"
  },
  {
    "text": "know I I think there are very nice abstractions and length training that I'm familiar with here like you know the like you guys have the the essentially",
    "start": "3578640",
    "end": "3584579"
  },
  {
    "text": "mapreduce thing um if you have data that's that small I imagine that's just a very natural thing",
    "start": "3584579",
    "end": "3589680"
  },
  {
    "text": "you can do um if the data gets to a level where that's too expensive you could essentially use the compile function in",
    "start": "3589680",
    "end": "3596640"
  },
  {
    "text": "DSP to replicate that behavior but with the language model that got fine-tuned",
    "start": "3596640",
    "end": "3601680"
  },
  {
    "text": "to be a tiny thing that you know understands the specifics of what you wanted to do so you don't need you know you don't need the full power of gpt4 to",
    "start": "3601680",
    "end": "3609299"
  },
  {
    "text": "you know do that specific map reduce process but but if you just if you try to prompt flan T5 it it can't really do",
    "start": "3609299",
    "end": "3616799"
  },
  {
    "text": "it reliably so the compiler will do is hey let's simulate it a little bit what gpt4 would do on a few unlabeled",
    "start": "3616799",
    "end": "3623160"
  },
  {
    "text": "examples and you know teach it to the to a small model that updates adaptively as",
    "start": "3623160",
    "end": "3628740"
  },
  {
    "text": "we change our programming um and so that's one thing you could do there alternatively",
    "start": "3628740",
    "end": "3634559"
  },
  {
    "text": "um I think Colbert V2 indexing of small data sets is a you know it's an exciting",
    "start": "3634559",
    "end": "3639660"
  },
  {
    "text": "Direction it's certainly uh makes it even less of a concern the fact that you have a lot of vectors to store",
    "start": "3639660",
    "end": "3645900"
  },
  {
    "text": "um I don't think it's a concern to begin with unless you have like many billions of documents uh at which point it",
    "start": "3645900",
    "end": "3651540"
  },
  {
    "text": "becomes a bit of a challenge but if you have hundreds or thousands definitely try this out like index it you know you",
    "start": "3651540",
    "end": "3657599"
  },
  {
    "text": "might not even uh you know need a very powerful GPU for indexing uh you do need",
    "start": "3657599",
    "end": "3663180"
  },
  {
    "text": "a GPU for indexing now just because the code assumes that you have one but fundamentally if people pick this up you",
    "start": "3663180",
    "end": "3669180"
  },
  {
    "text": "know you could run it on on CPU with fast birth implementations search is CPU friendly though like you",
    "start": "3669180",
    "end": "3675599"
  },
  {
    "text": "don't need gpus for search just for indexing right right",
    "start": "3675599",
    "end": "3680819"
  },
  {
    "text": "um yeah and Joe any thoughts about this specific context of long-term memory where you've got like maybe smaller",
    "start": "3680819",
    "end": "3685980"
  },
  {
    "text": "amounts of documents richer richer metadata more control and I think this",
    "start": "3685980",
    "end": "3691500"
  },
  {
    "text": "the mechanisms are the same right you want to retrieve over this and as I said the I think the hybrid combinations uh",
    "start": "3691500",
    "end": "3698280"
  },
  {
    "text": "and and uh combining and also uh taking whatever text is there and the metadata",
    "start": "3698280",
    "end": "3704579"
  },
  {
    "text": "and the generations and that you actually can store this data uh in any kind of store that will allow you to",
    "start": "3704579",
    "end": "3711240"
  },
  {
    "text": "uh store both the text data and the vector representation if it's tensor",
    "start": "3711240",
    "end": "3716339"
  },
  {
    "text": "data like in case of Colbert or is the single Vector model and then it's just",
    "start": "3716339",
    "end": "3721500"
  },
  {
    "text": "that you don't have to introduce any kind of approximate Vector search you can do exact search on those smaller",
    "start": "3721500",
    "end": "3727319"
  },
  {
    "text": "data you don't you know you can run the full callback model and maybe even you know uh you can run a full cross encoder",
    "start": "3727319",
    "end": "3735420"
  },
  {
    "text": "model if you use like a mini language model you know because they are",
    "start": "3735420",
    "end": "3740640"
  },
  {
    "text": "you know they also I think they're overlooked in in the current landscape uh but they do have some advantages as",
    "start": "3740640",
    "end": "3746579"
  },
  {
    "text": "well right okay if you have gpus uh you don't need to store anything you can retrieve simply and then re-rank using a",
    "start": "3746579",
    "end": "3753480"
  },
  {
    "text": "GPU and that's why the investment team has been focusing on adding GPU capacity and investment clusters like uh for",
    "start": "3753480",
    "end": "3760020"
  },
  {
    "text": "doing that because I think cross encoders uh it's really something a very easy way to lift accuracy even if you're",
    "start": "3760020",
    "end": "3766440"
  },
  {
    "text": "running on a simple bm25 retriever uh yeah so there are a lot of options and",
    "start": "3766440",
    "end": "3772980"
  },
  {
    "text": "and informational achievable and working in search because there's so many fascinating problems like sub problems",
    "start": "3772980",
    "end": "3778619"
  },
  {
    "text": "of search query understanding document understanding ranking you know diversity someone mentioned here in the chat you",
    "start": "3778619",
    "end": "3784200"
  },
  {
    "text": "know what do I do for diversifying the resource that I put into the to the",
    "start": "3784200",
    "end": "3789299"
  },
  {
    "text": "language model so there's so many aspects going on right and and now we just touched on you know how to how to",
    "start": "3789299",
    "end": "3796980"
  },
  {
    "text": "evaluate that ranked list in the context of Agents but there's so many things going around and yeah and I'll I'll",
    "start": "3796980",
    "end": "3805200"
  },
  {
    "text": "share my my presentation on Twitter uh later on and I also share some research",
    "start": "3805200",
    "end": "3811079"
  },
  {
    "text": "this is a free online courses on information material if you want to learn from experts um",
    "start": "3811079",
    "end": "3816359"
  },
  {
    "text": "so so people can get up to date on the general stuff like this Joe Joe it",
    "start": "3816359",
    "end": "3822359"
  },
  {
    "text": "sounds like there's so much going on that we might need to do a rerun of this basically that's what you're saying right yeah that's what I'm saying",
    "start": "3822359",
    "end": "3831000"
  },
  {
    "text": "yeah and so we didn't get a chance to answer uh everybody's questions but I know Harrison and I and Joe are all on",
    "start": "3831000",
    "end": "3838920"
  },
  {
    "text": "Twitter and I've seen both of them frequently having interesting conversations with people who have questions Omar is as well Omar's as well",
    "start": "3838920",
    "end": "3845579"
  },
  {
    "text": "yeah Omar as well great interaction Perfect all right oh that's your Twitter",
    "start": "3845579",
    "end": "3850619"
  },
  {
    "text": "handle late interaction yeah yeah it's actually a it's actually a fun on the on The Late Show with Colbert oh got",
    "start": "3850619",
    "end": "3859319"
  },
  {
    "text": "him incredible well thanks for your Colbert Report on uh on the late",
    "start": "3859319",
    "end": "3864660"
  },
  {
    "text": "interaction and multi-factor retrieval and thanks to Joe for um the overview and showing us some of",
    "start": "3864660",
    "end": "3870299"
  },
  {
    "text": "the stuff that vespa's uh building working on um and as always thanks to Harrison for",
    "start": "3870299",
    "end": "3876000"
  },
  {
    "text": "organizing uh the Lang chain Community putting Lang chain together and thanks to Charles for hosting this and and",
    "start": "3876000",
    "end": "3882960"
  },
  {
    "text": "keeping everything running smoothly and I'll just say we uh I run a little",
    "start": "3882960",
    "end": "3888960"
  },
  {
    "text": "like online uh a little online education stuff the full stack uh llm boot camp",
    "start": "3888960",
    "end": "3894780"
  },
  {
    "text": "full stack deep learning course um Joe gave our information retrieval lecture the the thumbs up the coveted",
    "start": "3894780",
    "end": "3900839"
  },
  {
    "text": "Joe bergum thumbs up so yeah definitely check it out fantastic resource I can't",
    "start": "3900839",
    "end": "3906480"
  },
  {
    "text": "believe you gave away that for free I mean Jesus Christ I was like it was fantastic I mean go",
    "start": "3906480",
    "end": "3914640"
  },
  {
    "text": "watch it you know go to that link watch all that material you know very fantastic content yeah really good",
    "start": "3914640",
    "end": "3921420"
  },
  {
    "text": "stuff thanks Joe um all right well thanks everybody for coming and uh we'll see you at the next",
    "start": "3921420",
    "end": "3927420"
  },
  {
    "text": "one of these yes",
    "start": "3927420",
    "end": "3932480"
  }
]
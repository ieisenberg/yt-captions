[
  {
    "text": "this is lanch blank chain deep seek just",
    "start": "80",
    "end": "2040"
  },
  {
    "text": "released R1 which is a new fully open",
    "start": "2040",
    "end": "4359"
  },
  {
    "text": "source reasoning model from the deep",
    "start": "4359",
    "end": "6520"
  },
  {
    "text": "seek lab and it comes with a paper that",
    "start": "6520",
    "end": "8800"
  },
  {
    "text": "describes their training strategy which",
    "start": "8800",
    "end": "10080"
  },
  {
    "text": "is quite cool because reasoning models",
    "start": "10080",
    "end": "11719"
  },
  {
    "text": "represent a new scaling Paradigm for",
    "start": "11719",
    "end": "13360"
  },
  {
    "text": "llms I have a separate video on this",
    "start": "13360",
    "end": "15480"
  },
  {
    "text": "that's also coming out uh soon that you",
    "start": "15480",
    "end": "17520"
  },
  {
    "text": "can check out so scaling Paradigm over",
    "start": "17520",
    "end": "19199"
  },
  {
    "text": "the past few years has been next token",
    "start": "19199",
    "end": "20560"
  },
  {
    "text": "prediction we've seen many successful",
    "start": "20560",
    "end": "22039"
  },
  {
    "text": "chat models trained with this it's",
    "start": "22039",
    "end": "24359"
  },
  {
    "text": "system one type thinking it's fast",
    "start": "24359",
    "end": "26640"
  },
  {
    "text": "intuitive we often tell the model how to",
    "start": "26640",
    "end": "28720"
  },
  {
    "text": "think with tricks like how to think you",
    "start": "28720",
    "end": "30359"
  },
  {
    "text": "know think step by step and the",
    "start": "30359",
    "end": "32398"
  },
  {
    "text": "interaction modes of in chat now",
    "start": "32399",
    "end": "34239"
  },
  {
    "text": "reasoning models are a bit different",
    "start": "34239",
    "end": "35559"
  },
  {
    "text": "they're trained with a different",
    "start": "35559",
    "end": "36480"
  },
  {
    "text": "Paradigm RL on chain of thoughts we'll",
    "start": "36480",
    "end": "39559"
  },
  {
    "text": "talk about that a lot in a bit it's",
    "start": "39559",
    "end": "42520"
  },
  {
    "text": "system to reasoning often tell the model",
    "start": "42520",
    "end": "45760"
  },
  {
    "text": "what you actually want not how to think",
    "start": "45760",
    "end": "47640"
  },
  {
    "text": "and the interaction mode is a bit",
    "start": "47640",
    "end": "48760"
  },
  {
    "text": "different it's very good for research or",
    "start": "48760",
    "end": "50480"
  },
  {
    "text": "planning in the background style tasks",
    "start": "50480",
    "end": "52680"
  },
  {
    "text": "that are less",
    "start": "52680",
    "end": "53680"
  },
  {
    "text": "interactive so the really interesting",
    "start": "53680",
    "end": "55840"
  },
  {
    "text": "thing here is that we now know how a",
    "start": "55840",
    "end": "60000"
  },
  {
    "text": "state-of-the-art reasoning model is",
    "start": "60000",
    "end": "61320"
  },
  {
    "text": "trained so of course the current",
    "start": "61320",
    "end": "63840"
  },
  {
    "text": "stateoftheart reasoning models from open",
    "start": "63840",
    "end": "65280"
  },
  {
    "text": "AI the O Series models are closed Source",
    "start": "65280",
    "end": "67600"
  },
  {
    "text": "we don't have detailed information about",
    "start": "67600",
    "end": "69680"
  },
  {
    "text": "how training works but this is a very",
    "start": "69680",
    "end": "71920"
  },
  {
    "text": "clear illustration of how they built a",
    "start": "71920",
    "end": "74240"
  },
  {
    "text": "state-of-the-art reasoning model that is",
    "start": "74240",
    "end": "76600"
  },
  {
    "text": "on par with 01 and you'll see those",
    "start": "76600",
    "end": "78720"
  },
  {
    "text": "results here shortly but let me actually",
    "start": "78720",
    "end": "80479"
  },
  {
    "text": "talk through the training strategy it's",
    "start": "80479",
    "end": "81799"
  },
  {
    "text": "very interesting so deepcar one uses a",
    "start": "81799",
    "end": "84360"
  },
  {
    "text": "combination of fine-tuning and",
    "start": "84360",
    "end": "86400"
  },
  {
    "text": "reinforcement learning to produce this",
    "start": "86400",
    "end": "88560"
  },
  {
    "text": "reasoning model and has a few different",
    "start": "88560",
    "end": "90680"
  },
  {
    "text": "stages so the first stage is just fine",
    "start": "90680",
    "end": "93000"
  },
  {
    "text": "tuning they take deep seek V3 which is",
    "start": "93000",
    "end": "96079"
  },
  {
    "text": "their very strong base chat model and",
    "start": "96079",
    "end": "99720"
  },
  {
    "text": "they fine-tune it on some number of",
    "start": "99720",
    "end": "101920"
  },
  {
    "text": "thousands of Chain of Thought reasoning",
    "start": "101920",
    "end": "104200"
  },
  {
    "text": "examples now they don't actually tell",
    "start": "104200",
    "end": "105560"
  },
  {
    "text": "the specific number of examples from my",
    "start": "105560",
    "end": "107280"
  },
  {
    "text": "reading of the paper but the point is",
    "start": "107280",
    "end": "109240"
  },
  {
    "text": "they do a fine-tuning phase to build a",
    "start": "109240",
    "end": "111640"
  },
  {
    "text": "good starting point for RL now the",
    "start": "111640",
    "end": "114640"
  },
  {
    "text": "second stage here is reinforcement",
    "start": "114640",
    "end": "116920"
  },
  {
    "text": "rolling with this approach grpo so",
    "start": "116920",
    "end": "119479"
  },
  {
    "text": "what's going on there well they have a",
    "start": "119479",
    "end": "121200"
  },
  {
    "text": "separate paper on this and I do want to",
    "start": "121200",
    "end": "123119"
  },
  {
    "text": "talk about that a little bit so this RL",
    "start": "123119",
    "end": "125079"
  },
  {
    "text": "stage one uses grpo reinforcement",
    "start": "125079",
    "end": "127520"
  },
  {
    "text": "learning it's from this deep seek math",
    "start": "127520",
    "end": "129239"
  },
  {
    "text": "paper now here's what's going on for",
    "start": "129239",
    "end": "131720"
  },
  {
    "text": "every training example now I do want to",
    "start": "131720",
    "end": "134120"
  },
  {
    "text": "make a note how many training examples",
    "start": "134120",
    "end": "135640"
  },
  {
    "text": "they they use they have 144,000 training",
    "start": "135640",
    "end": "138720"
  },
  {
    "text": "examples of hard verifiable problems in",
    "start": "138720",
    "end": "141519"
  },
  {
    "text": "math and coding for which you need some",
    "start": "141519",
    "end": "144200"
  },
  {
    "text": "degree of reasoning like you need to",
    "start": "144200",
    "end": "146400"
  },
  {
    "text": "produce a reasoning Trace typically to",
    "start": "146400",
    "end": "147760"
  },
  {
    "text": "solve them and there's some definitive",
    "start": "147760",
    "end": "149959"
  },
  {
    "text": "solution that can be verified those are",
    "start": "149959",
    "end": "151360"
  },
  {
    "text": "the two criteria that matter here so",
    "start": "151360",
    "end": "153599"
  },
  {
    "text": "they have all these samples now what",
    "start": "153599",
    "end": "155480"
  },
  {
    "text": "they're doing is for every training",
    "start": "155480",
    "end": "157160"
  },
  {
    "text": "example they actually produce 64 samples",
    "start": "157160",
    "end": "160000"
  },
  {
    "text": "or 64 different attempts to solve the",
    "start": "160000",
    "end": "162080"
  },
  {
    "text": "problem and they score each one of those",
    "start": "162080",
    "end": "164280"
  },
  {
    "text": "with some rule-based reward like correct",
    "start": "164280",
    "end": "166120"
  },
  {
    "text": "or incorrect for math or coding right",
    "start": "166120",
    "end": "167800"
  },
  {
    "text": "that's pretty straightforward now here's",
    "start": "167800",
    "end": "169840"
  },
  {
    "text": "where it's kind of interesting they",
    "start": "169840",
    "end": "171040"
  },
  {
    "text": "basically compare every sample to the",
    "start": "171040",
    "end": "173560"
  },
  {
    "text": "mean of all samples in this 64 sample",
    "start": "173560",
    "end": "176440"
  },
  {
    "text": "batch okay so that's kind of what they",
    "start": "176440",
    "end": "177920"
  },
  {
    "text": "do for samples with high or low",
    "start": "177920",
    "end": "181800"
  },
  {
    "text": "normalize reward relative to the group",
    "start": "181800",
    "end": "184239"
  },
  {
    "text": "meme they increase or drop the",
    "start": "184239",
    "end": "186640"
  },
  {
    "text": "probability of the model generating all",
    "start": "186640",
    "end": "188720"
  },
  {
    "text": "the tokens in that sequence so what",
    "start": "188720",
    "end": "191560"
  },
  {
    "text": "happens is each token in that output",
    "start": "191560",
    "end": "193640"
  },
  {
    "text": "gets a positive or negative gradient",
    "start": "193640",
    "end": "195480"
  },
  {
    "text": "update and here's the intuition it's",
    "start": "195480",
    "end": "197480"
  },
  {
    "text": "basically saying let's make all the",
    "start": "197480",
    "end": "199159"
  },
  {
    "text": "choices that led to this correct or",
    "start": "199159",
    "end": "201319"
  },
  {
    "text": "incorrect decision more or less likely",
    "start": "201319",
    "end": "203799"
  },
  {
    "text": "so that's actually what they're doing",
    "start": "203799",
    "end": "204959"
  },
  {
    "text": "and so the punchline here is why do they",
    "start": "204959",
    "end": "206879"
  },
  {
    "text": "do this they're trying to discover good",
    "start": "206879",
    "end": "208319"
  },
  {
    "text": "reasoning patterns and what happens is",
    "start": "208319",
    "end": "211080"
  },
  {
    "text": "this makes the model very strong at",
    "start": "211080",
    "end": "213159"
  },
  {
    "text": "reasoning but it loses some general",
    "start": "213159",
    "end": "215720"
  },
  {
    "text": "capacities for example they mentioned it",
    "start": "215720",
    "end": "217640"
  },
  {
    "text": "had potential language mixing issues so",
    "start": "217640",
    "end": "219959"
  },
  {
    "text": "this is where another interesting trick",
    "start": "219959",
    "end": "221480"
  },
  {
    "text": "comes into play if we look at our",
    "start": "221480",
    "end": "223080"
  },
  {
    "text": "diagram here we're right here so we've",
    "start": "223080",
    "end": "225439"
  },
  {
    "text": "actually use reinforcement learning to",
    "start": "225439",
    "end": "227480"
  },
  {
    "text": "get a very strong reasoning model but",
    "start": "227480",
    "end": "229799"
  },
  {
    "text": "it's actually a bit weaker than some",
    "start": "229799",
    "end": "230879"
  },
  {
    "text": "other capabilities so what they do is",
    "start": "230879",
    "end": "233560"
  },
  {
    "text": "they take the resulting reasoning traces",
    "start": "233560",
    "end": "237400"
  },
  {
    "text": "from that model and filter them to get",
    "start": "237400",
    "end": "240319"
  },
  {
    "text": "only high quality ones so the paper",
    "start": "240319",
    "end": "242879"
  },
  {
    "text": "talks about this as rejection sampling",
    "start": "242879",
    "end": "244959"
  },
  {
    "text": "so they're basically filtering the",
    "start": "244959",
    "end": "246079"
  },
  {
    "text": "outputs of that first reinforcement",
    "start": "246079",
    "end": "247760"
  },
  {
    "text": "learning phase for a bunch of different",
    "start": "247760",
    "end": "249120"
  },
  {
    "text": "things it's not just correctness but the",
    "start": "249120",
    "end": "250920"
  },
  {
    "text": "point is it results in 600,000 reasoning",
    "start": "250920",
    "end": "253159"
  },
  {
    "text": "traces that they can then train further",
    "start": "253159",
    "end": "256199"
  },
  {
    "text": "on so that's really the interesting",
    "start": "256199",
    "end": "257919"
  },
  {
    "text": "Insight here that you can utilize",
    "start": "257919",
    "end": "260120"
  },
  {
    "text": "outputs from the first stage of RL to",
    "start": "260120",
    "end": "262960"
  },
  {
    "text": "subsequent stages of your model and",
    "start": "262960",
    "end": "264639"
  },
  {
    "text": "that's exactly what they do so they do a",
    "start": "264639",
    "end": "266400"
  },
  {
    "text": "second stage of fine-tuning on the",
    "start": "266400",
    "end": "269080"
  },
  {
    "text": "results of that that sampling plus",
    "start": "269080",
    "end": "271800"
  },
  {
    "text": "200,000 additional non- reasoning",
    "start": "271800",
    "end": "273720"
  },
  {
    "text": "samples in writing and factual QA to",
    "start": "273720",
    "end": "275960"
  },
  {
    "text": "what they describe as restore the",
    "start": "275960",
    "end": "277919"
  },
  {
    "text": "general model capabilities while baking",
    "start": "277919",
    "end": "281240"
  },
  {
    "text": "in high quality reasoning so if you look",
    "start": "281240",
    "end": "283440"
  },
  {
    "text": "at the diagram here what's happening is",
    "start": "283440",
    "end": "285840"
  },
  {
    "text": "they are filtering the outputs of that",
    "start": "285840",
    "end": "287320"
  },
  {
    "text": "first phase of RL okay so remember this",
    "start": "287320",
    "end": "289039"
  },
  {
    "text": "model is a very strong Reasoner but it's",
    "start": "289039",
    "end": "290759"
  },
  {
    "text": "weak in some of General",
    "start": "290759",
    "end": "292560"
  },
  {
    "text": "capabilities and they're combining some",
    "start": "292560",
    "end": "295720"
  },
  {
    "text": "non- reasoning examples in there for",
    "start": "295720",
    "end": "297160"
  },
  {
    "text": "writing in QA and they're fine-tuning on",
    "start": "297160",
    "end": "299240"
  },
  {
    "text": "all that",
    "start": "299240",
    "end": "300199"
  },
  {
    "text": "and then what they argue is or they",
    "start": "300199",
    "end": "302120"
  },
  {
    "text": "present they get a model that retains",
    "start": "302120",
    "end": "304600"
  },
  {
    "text": "very strong reasoning but also restores",
    "start": "304600",
    "end": "306720"
  },
  {
    "text": "General capabilities okay so that's the",
    "start": "306720",
    "end": "308960"
  },
  {
    "text": "key point then after that they have a",
    "start": "308960",
    "end": "311840"
  },
  {
    "text": "final or second round of reinforcement",
    "start": "311840",
    "end": "313639"
  },
  {
    "text": "learning with two different rewards so",
    "start": "313639",
    "end": "316560"
  },
  {
    "text": "previously we talked about they only",
    "start": "316560",
    "end": "318240"
  },
  {
    "text": "used a rulebase reward for reasoning on",
    "start": "318240",
    "end": "321160"
  },
  {
    "text": "math and coding style problems now they",
    "start": "321160",
    "end": "323720"
  },
  {
    "text": "include different rewards for",
    "start": "323720",
    "end": "326000"
  },
  {
    "text": "helpfulness and harm as well as",
    "start": "326000",
    "end": "328080"
  },
  {
    "text": "reasoning and they use a mix of data",
    "start": "328080",
    "end": "331600"
  },
  {
    "text": "that includes both reasoning and general",
    "start": "331600",
    "end": "333720"
  },
  {
    "text": "problems to really optimizing for both",
    "start": "333720",
    "end": "336680"
  },
  {
    "text": "reasoning and general capabilities okay",
    "start": "336680",
    "end": "339280"
  },
  {
    "text": "so that's really the second stage of RL",
    "start": "339280",
    "end": "341240"
  },
  {
    "text": "now a final note which actually is very",
    "start": "341240",
    "end": "342840"
  },
  {
    "text": "exciting and we're going to be actually",
    "start": "342840",
    "end": "344080"
  },
  {
    "text": "working with more directly here they",
    "start": "344080",
    "end": "346240"
  },
  {
    "text": "also take that data set that they get",
    "start": "346240",
    "end": "349160"
  },
  {
    "text": "from that first phase of RL of 600,000",
    "start": "349160",
    "end": "351479"
  },
  {
    "text": "samples and they actually do knowledge",
    "start": "351479",
    "end": "354639"
  },
  {
    "text": "so they take much smaller open source",
    "start": "354639",
    "end": "356680"
  },
  {
    "text": "models and fine-tune them on those high",
    "start": "356680",
    "end": "359800"
  },
  {
    "text": "quality reasoning traces and then what",
    "start": "359800",
    "end": "361639"
  },
  {
    "text": "they get is a bunch of distilled smaller",
    "start": "361639",
    "end": "364639"
  },
  {
    "text": "R1 models pretty cool and some of them",
    "start": "364639",
    "end": "367080"
  },
  {
    "text": "you can actually run your laptop as",
    "start": "367080",
    "end": "368319"
  },
  {
    "text": "we'll see right here so what are the",
    "start": "368319",
    "end": "370319"
  },
  {
    "text": "results so they show a bunch of nice",
    "start": "370319",
    "end": "372199"
  },
  {
    "text": "results here deeps car1 versus 01 and",
    "start": "372199",
    "end": "375360"
  },
  {
    "text": "some smaller models ow and mini really",
    "start": "375360",
    "end": "377639"
  },
  {
    "text": "the punchline is it's very close to R1",
    "start": "377639",
    "end": "379880"
  },
  {
    "text": "on a bunch of interesting challenges",
    "start": "379880",
    "end": "381800"
  },
  {
    "text": "related to coding and math now one in",
    "start": "381800",
    "end": "385599"
  },
  {
    "text": "particular pay attention to S bench",
    "start": "385599",
    "end": "387039"
  },
  {
    "text": "verified it's a very popular Benchmark",
    "start": "387039",
    "end": "388919"
  },
  {
    "text": "for General software engineering",
    "start": "388919",
    "end": "390400"
  },
  {
    "text": "challenges and it is doing indeed quite",
    "start": "390400",
    "end": "393479"
  },
  {
    "text": "well slightly better than 01 apparently",
    "start": "393479",
    "end": "396800"
  },
  {
    "text": "they also have a bunch of distilled",
    "start": "396800",
    "end": "397960"
  },
  {
    "text": "models so here's the thing that is",
    "start": "397960",
    "end": "399560"
  },
  {
    "text": "really quite cool if you look at their",
    "start": "399560",
    "end": "401880"
  },
  {
    "text": "distilled quen 14b you look at the",
    "start": "401880",
    "end": "404599"
  },
  {
    "text": "Benchmark results and it is pretty close",
    "start": "404599",
    "end": "407680"
  },
  {
    "text": "to 01 mini you can kind of go across and",
    "start": "407680",
    "end": "409880"
  },
  {
    "text": "look and convince yourself of this but",
    "start": "409880",
    "end": "412919"
  },
  {
    "text": "look it's pretty strong and 14b can",
    "start": "412919",
    "end": "415199"
  },
  {
    "text": "actually run on a lot of people's",
    "start": "415199",
    "end": "417080"
  },
  {
    "text": "laptops for example I have a 32 gig",
    "start": "417080",
    "end": "419599"
  },
  {
    "text": "MacBook Pro and and I can run 14b as",
    "start": "419599",
    "end": "423199"
  },
  {
    "text": "we'll see in a bit so now let's try",
    "start": "423199",
    "end": "425160"
  },
  {
    "text": "playing with it so I pulled deep seek",
    "start": "425160",
    "end": "428240"
  },
  {
    "text": "14b from AMA so you can see they put a",
    "start": "428240",
    "end": "431199"
  },
  {
    "text": "tweet out recently they host all these",
    "start": "431199",
    "end": "432720"
  },
  {
    "text": "models it's pretty cool you can try to",
    "start": "432720",
    "end": "434319"
  },
  {
    "text": "run them on your own hardware and I'm in",
    "start": "434319",
    "end": "436520"
  },
  {
    "text": "a notebook so all I need to do is grab L",
    "start": "436520",
    "end": "439840"
  },
  {
    "text": "chain of llama I'm going to initialize",
    "start": "439840",
    "end": "442120"
  },
  {
    "text": "my model and what's nice is I'm going to",
    "start": "442120",
    "end": "443840"
  },
  {
    "text": "use Json mode with AMA to also produce",
    "start": "443840",
    "end": "447240"
  },
  {
    "text": "Json outputs and see how well structured",
    "start": "447240",
    "end": "448800"
  },
  {
    "text": "outputs work with this this model so",
    "start": "448800",
    "end": "450800"
  },
  {
    "text": "first let's try a simple question was",
    "start": "450800",
    "end": "452319"
  },
  {
    "text": "the capital of France Cool C you see the",
    "start": "452319",
    "end": "455039"
  },
  {
    "text": "capital of France at Paris we see",
    "start": "455039",
    "end": "456400"
  },
  {
    "text": "something else is interesting these",
    "start": "456400",
    "end": "458360"
  },
  {
    "text": "think tokens okay if you go around local",
    "start": "458360",
    "end": "461039"
  },
  {
    "text": "Lama and you you hunt around for this",
    "start": "461039",
    "end": "462639"
  },
  {
    "text": "there's a lot of people talking about",
    "start": "462639",
    "end": "463879"
  },
  {
    "text": "these think tokens they're hard to",
    "start": "463879",
    "end": "465280"
  },
  {
    "text": "prompt away I've tried a bunch they've",
    "start": "465280",
    "end": "467800"
  },
  {
    "text": "seem to be kind of an annoying thing",
    "start": "467800",
    "end": "469720"
  },
  {
    "text": "they are absolutely part of the training",
    "start": "469720",
    "end": "471520"
  },
  {
    "text": "process you can look at the paper you",
    "start": "471520",
    "end": "472720"
  },
  {
    "text": "can see that these think tokens are",
    "start": "472720",
    "end": "474000"
  },
  {
    "text": "actually included in the training now",
    "start": "474000",
    "end": "475759"
  },
  {
    "text": "let's try Json mode so what's",
    "start": "475759",
    "end": "477159"
  },
  {
    "text": "interesting is when you use Json mode",
    "start": "477159",
    "end": "478639"
  },
  {
    "text": "the think tokens are not present so",
    "start": "478639",
    "end": "480240"
  },
  {
    "text": "there is some postprocessing happening",
    "start": "480240",
    "end": "481599"
  },
  {
    "text": "on the Alama side that strips them and",
    "start": "481599",
    "end": "483240"
  },
  {
    "text": "you get ajacent object out so looks like",
    "start": "483240",
    "end": "485000"
  },
  {
    "text": "Json mode Le is working so that's a good",
    "start": "485000",
    "end": "486840"
  },
  {
    "text": "thing I ask a more involved question",
    "start": "486840",
    "end": "489000"
  },
  {
    "text": "Give me a summary on scaling laws for RL",
    "start": "489000",
    "end": "490759"
  },
  {
    "text": "models and again you see wow this is",
    "start": "490759",
    "end": "493360"
  },
  {
    "text": "quite verbose and you can see this think",
    "start": "493360",
    "end": "495720"
  },
  {
    "text": "token emitted first just like before and",
    "start": "495720",
    "end": "497840"
  },
  {
    "text": "now you get like a much more detailed",
    "start": "497840",
    "end": "500240"
  },
  {
    "text": "breakdown of uh its internal thought",
    "start": "500240",
    "end": "503479"
  },
  {
    "text": "process so let's go overhead and look at",
    "start": "503479",
    "end": "505440"
  },
  {
    "text": "Langs Smith just to kind of get a better",
    "start": "505440",
    "end": "507319"
  },
  {
    "text": "view of this output so in my Langs Smith",
    "start": "507319",
    "end": "509599"
  },
  {
    "text": "project now I'm going to open up this",
    "start": "509599",
    "end": "511039"
  },
  {
    "text": "Trace we can see it took 64 seconds okay",
    "start": "511039",
    "end": "514279"
  },
  {
    "text": "so that's actually pretty long but again",
    "start": "514279",
    "end": "516120"
  },
  {
    "text": "I'm really pushing the limits of my",
    "start": "516120",
    "end": "517640"
  },
  {
    "text": "Hardware running the 14b model so that's",
    "start": "517640",
    "end": "520320"
  },
  {
    "text": "fine it's a little bit on me um but I",
    "start": "520320",
    "end": "522680"
  },
  {
    "text": "want to test 01 mini level performance",
    "start": "522680",
    "end": "526360"
  },
  {
    "text": "running locally based on the Benchmark",
    "start": "526360",
    "end": "528839"
  },
  {
    "text": "so I just want to kind of play with it",
    "start": "528839",
    "end": "530519"
  },
  {
    "text": "okay so here's the output again it's",
    "start": "530519",
    "end": "532360"
  },
  {
    "text": "quite verbose you can see the think",
    "start": "532360",
    "end": "534040"
  },
  {
    "text": "token here emitted so it does a lot of",
    "start": "534040",
    "end": "537120"
  },
  {
    "text": "thinking prior to responding and seems",
    "start": "537120",
    "end": "540360"
  },
  {
    "text": "to provide a sane response but again",
    "start": "540360",
    "end": "542360"
  },
  {
    "text": "this issue of a lot of pre-thinking",
    "start": "542360",
    "end": "544760"
  },
  {
    "text": "being emitted is evidently an issue with",
    "start": "544760",
    "end": "547720"
  },
  {
    "text": "these models uh that may be a problem",
    "start": "547720",
    "end": "550160"
  },
  {
    "text": "not depending on your application you",
    "start": "550160",
    "end": "551800"
  },
  {
    "text": "can also programmatically try to remove",
    "start": "551800",
    "end": "553760"
  },
  {
    "text": "that that's another thing to think about",
    "start": "553760",
    "end": "555120"
  },
  {
    "text": "so let's Vibe test a bit more this is a",
    "start": "555120",
    "end": "557320"
  },
  {
    "text": "repo called olama de researcher and this",
    "start": "557320",
    "end": "559920"
  },
  {
    "text": "is basically an evaluator Optimizer",
    "start": "559920",
    "end": "561920"
  },
  {
    "text": "workflow for report writing so I'm going",
    "start": "561920",
    "end": "564040"
  },
  {
    "text": "to do is I'm going to have an open",
    "start": "564040",
    "end": "565720"
  },
  {
    "text": "source llm running locally via Ama take",
    "start": "565720",
    "end": "569880"
  },
  {
    "text": "an input topic from a user and generate",
    "start": "569880",
    "end": "572480"
  },
  {
    "text": "a search query for it perform web search",
    "start": "572480",
    "end": "575279"
  },
  {
    "text": "get the results produce a summary but",
    "start": "575279",
    "end": "577360"
  },
  {
    "text": "then reflect on the summary and",
    "start": "577360",
    "end": "579880"
  },
  {
    "text": "regenerate a question go back so this",
    "start": "579880",
    "end": "582440"
  },
  {
    "text": "Loop is going to look kind of like this",
    "start": "582440",
    "end": "584079"
  },
  {
    "text": "you can see queer generation research",
    "start": "584079",
    "end": "586680"
  },
  {
    "text": "summary generation reflection new query",
    "start": "586680",
    "end": "588880"
  },
  {
    "text": "and so forth this will continue for some",
    "start": "588880",
    "end": "591200"
  },
  {
    "text": "set number of Cycles that's configurable",
    "start": "591200",
    "end": "593720"
  },
  {
    "text": "and in the end I'll get a nice summary",
    "start": "593720",
    "end": "595040"
  },
  {
    "text": "with sources and this could be r with",
    "start": "595040",
    "end": "596240"
  },
  {
    "text": "any open source llm now I have a",
    "start": "596240",
    "end": "597720"
  },
  {
    "text": "separate video on this that talks about",
    "start": "597720",
    "end": "599000"
  },
  {
    "text": "building from scratch so I'm not going",
    "start": "599000",
    "end": "600720"
  },
  {
    "text": "to kind of build everything again but I",
    "start": "600720",
    "end": "602640"
  },
  {
    "text": "will just test this out using R1 so just",
    "start": "602640",
    "end": "606600"
  },
  {
    "text": "some specifics here I have a MacBook Pro",
    "start": "606600",
    "end": "608640"
  },
  {
    "text": "M2 Max 32 gig I found that the 14",
    "start": "608640",
    "end": "611560"
  },
  {
    "text": "billion distilled deeps R1 model is",
    "start": "611560",
    "end": "614399"
  },
  {
    "text": "about at the edge of what I can run but",
    "start": "614399",
    "end": "615839"
  },
  {
    "text": "still it's fun to try as discussed",
    "start": "615839",
    "end": "617600"
  },
  {
    "text": "before all I need to do to run this is",
    "start": "617600",
    "end": "619360"
  },
  {
    "text": "basically just set my Tav API key that",
    "start": "619360",
    "end": "621240"
  },
  {
    "text": "allows for web search and kick off this",
    "start": "621240",
    "end": "623680"
  },
  {
    "text": "command when you do that you're going to",
    "start": "623680",
    "end": "625920"
  },
  {
    "text": "see langra Server spin up in your",
    "start": "625920",
    "end": "628560"
  },
  {
    "text": "browser and you can actually start",
    "start": "628560",
    "end": "630200"
  },
  {
    "text": "interacting with it directly so you're",
    "start": "630200",
    "end": "631959"
  },
  {
    "text": "going to see this in your browser so",
    "start": "631959",
    "end": "633240"
  },
  {
    "text": "this is pretty nice this a little",
    "start": "633240",
    "end": "634240"
  },
  {
    "text": "environment that I like to use to play",
    "start": "634240",
    "end": "636040"
  },
  {
    "text": "with assistants that I create using Lang",
    "start": "636040",
    "end": "637720"
  },
  {
    "text": "graph you can see this shows the overall",
    "start": "637720",
    "end": "639839"
  },
  {
    "text": "flow of our assistant here so it's going",
    "start": "639839",
    "end": "641800"
  },
  {
    "text": "to generate a query do web search",
    "start": "641800",
    "end": "644079"
  },
  {
    "text": "summarize the results reflect and go",
    "start": "644079",
    "end": "646000"
  },
  {
    "text": "back this is a nice test bed though for",
    "start": "646000",
    "end": "648920"
  },
  {
    "text": "looking at different local models so",
    "start": "648920",
    "end": "650920"
  },
  {
    "text": "what you can do is open up this",
    "start": "650920",
    "end": "652279"
  },
  {
    "text": "configurable thing just paste whatever",
    "start": "652279",
    "end": "654200"
  },
  {
    "text": "local model on a llama that you've",
    "start": "654200",
    "end": "655519"
  },
  {
    "text": "downloaded and want to test so in my",
    "start": "655519",
    "end": "657079"
  },
  {
    "text": "case let's test 14b I'll have it iterate",
    "start": "657079",
    "end": "660399"
  },
  {
    "text": "twice so go two loops and we can ask any",
    "start": "660399",
    "end": "664120"
  },
  {
    "text": "question here so let's say give me a",
    "start": "664120",
    "end": "666920"
  },
  {
    "text": "report on RL training approaches so fine",
    "start": "666920",
    "end": "671839"
  },
  {
    "text": "all I have to do is submit so it's Jing",
    "start": "671839",
    "end": "673680"
  },
  {
    "text": "our query and it's using structured",
    "start": "673680",
    "end": "675600"
  },
  {
    "text": "output that's good so that part of the",
    "start": "675600",
    "end": "677720"
  },
  {
    "text": "flow is working as expected nice now",
    "start": "677720",
    "end": "680120"
  },
  {
    "text": "it's using tavali to do web research you",
    "start": "680120",
    "end": "682120"
  },
  {
    "text": "can look at the repo to dig into that I",
    "start": "682120",
    "end": "683920"
  },
  {
    "text": "have a separate video on all this in",
    "start": "683920",
    "end": "685320"
  },
  {
    "text": "detail so now it's summarizing my",
    "start": "685320",
    "end": "687839"
  },
  {
    "text": "sources so this is kind of nice you see",
    "start": "687839",
    "end": "689560"
  },
  {
    "text": "it stream as it goes you can see those",
    "start": "689560",
    "end": "691720"
  },
  {
    "text": "think tokens again now in the repo I",
    "start": "691720",
    "end": "695240"
  },
  {
    "text": "added a filter to remove them because I",
    "start": "695240",
    "end": "698680"
  },
  {
    "text": "found that they do affect some",
    "start": "698680",
    "end": "700480"
  },
  {
    "text": "Downstream processing so I'm going to",
    "start": "700480",
    "end": "702279"
  },
  {
    "text": "filter this out when I save it to state",
    "start": "702279",
    "end": "704000"
  },
  {
    "text": "in My Graph but you can see how much",
    "start": "704000",
    "end": "706000"
  },
  {
    "text": "reasoning and thinking it's doing so now",
    "start": "706000",
    "end": "708160"
  },
  {
    "text": "it's reflecting on my summary and I've",
    "start": "708160",
    "end": "709480"
  },
  {
    "text": "stripped out those thinking tokens",
    "start": "709480",
    "end": "711040"
  },
  {
    "text": "during this reflection phase so this is",
    "start": "711040",
    "end": "712959"
  },
  {
    "text": "pretty cool it finds a knowledge Gap",
    "start": "712959",
    "end": "714839"
  },
  {
    "text": "generates a followup question and now",
    "start": "714839",
    "end": "716399"
  },
  {
    "text": "I've done more web research and I'm",
    "start": "716399",
    "end": "718200"
  },
  {
    "text": "summarizing based upon my initial",
    "start": "718200",
    "end": "720399"
  },
  {
    "text": "summary and the new web reg resources",
    "start": "720399",
    "end": "722959"
  },
  {
    "text": "that I've retrieved so now here's my",
    "start": "722959",
    "end": "725440"
  },
  {
    "text": "updated summary so it's thinking it",
    "start": "725440",
    "end": "727440"
  },
  {
    "text": "needs to extend the summary okay I mean",
    "start": "727440",
    "end": "730480"
  },
  {
    "text": "you know that may not be a bad thing",
    "start": "730480",
    "end": "733399"
  },
  {
    "text": "that it is expressing its kind of",
    "start": "733399",
    "end": "736760"
  },
  {
    "text": "process for us to see I mean look it's",
    "start": "736760",
    "end": "738839"
  },
  {
    "text": "listening to the promer to reason need",
    "start": "738839",
    "end": "740240"
  },
  {
    "text": "to seamlessly integrate these points",
    "start": "740240",
    "end": "742040"
  },
  {
    "text": "good um it's highlighting the new",
    "start": "742040",
    "end": "744199"
  },
  {
    "text": "resource that it found good okay so it's",
    "start": "744199",
    "end": "746800"
  },
  {
    "text": "being very expressive about everything",
    "start": "746800",
    "end": "748639"
  },
  {
    "text": "it needs to do based on the instructions",
    "start": "748639",
    "end": "750040"
  },
  {
    "text": "I give it it's done thinking and cool it",
    "start": "750040",
    "end": "753440"
  },
  {
    "text": "is updating that summary so you can see",
    "start": "753440",
    "end": "755120"
  },
  {
    "text": "now reinforc learnings a sub field of AI",
    "start": "755120",
    "end": "757680"
  },
  {
    "text": "it's going to reflect again go back",
    "start": "757680",
    "end": "760000"
  },
  {
    "text": "it'll try that one more time and again",
    "start": "760000",
    "end": "761480"
  },
  {
    "text": "it pulled a new paper it's thinking I",
    "start": "761480",
    "end": "763040"
  },
  {
    "text": "need to extend the summary further I",
    "start": "763040",
    "end": "765000"
  },
  {
    "text": "mean in a way I kind of like this",
    "start": "765000",
    "end": "766760"
  },
  {
    "text": "thinking process cuz it really explains",
    "start": "766760",
    "end": "768399"
  },
  {
    "text": "what it's actually doing and how it's",
    "start": "768399",
    "end": "769680"
  },
  {
    "text": "freezing about it and you can see it's",
    "start": "769680",
    "end": "771440"
  },
  {
    "text": "updating its summary and it actually",
    "start": "771440",
    "end": "773000"
  },
  {
    "text": "looks pretty sane pretty nice and it",
    "start": "773000",
    "end": "775519"
  },
  {
    "text": "gives us information about the global",
    "start": "775519",
    "end": "776959"
  },
  {
    "text": "market for RL so fair enough and an exit",
    "start": "776959",
    "end": "779480"
  },
  {
    "text": "so now we get the final summary so my",
    "start": "779480",
    "end": "780959"
  },
  {
    "text": "assistant will add this little summary",
    "start": "780959",
    "end": "782680"
  },
  {
    "text": "thing to the top and we have our nice",
    "start": "782680",
    "end": "785120"
  },
  {
    "text": "written summary here and it'll add the",
    "start": "785120",
    "end": "786959"
  },
  {
    "text": "sources and we can go ahead and look at",
    "start": "786959",
    "end": "788720"
  },
  {
    "text": "that in Langs Smith as well we can see",
    "start": "788720",
    "end": "790399"
  },
  {
    "text": "everything it did we can look at the",
    "start": "790399",
    "end": "791639"
  },
  {
    "text": "final summary which is actually right",
    "start": "791639",
    "end": "793240"
  },
  {
    "text": "here so here's the summary and there's",
    "start": "793240",
    "end": "795440"
  },
  {
    "text": "our sources so basically my take is the",
    "start": "795440",
    "end": "800160"
  },
  {
    "text": "think tag thing is kind of annoying I",
    "start": "800160",
    "end": "802560"
  },
  {
    "text": "actually kind of like to see that as a",
    "start": "802560",
    "end": "803920"
  },
  {
    "text": "developer it's annoying to manage if",
    "start": "803920",
    "end": "805720"
  },
  {
    "text": "you're actually trying to build an",
    "start": "805720",
    "end": "806480"
  },
  {
    "text": "application with this because it emits",
    "start": "806480",
    "end": "808160"
  },
  {
    "text": "that to the output you have to process",
    "start": "808160",
    "end": "810000"
  },
  {
    "text": "it out the 14 billion parameter model is",
    "start": "810000",
    "end": "812959"
  },
  {
    "text": "at the edge of what I can run locally on",
    "start": "812959",
    "end": "814680"
  },
  {
    "text": "my laptop of course it depends on your",
    "start": "814680",
    "end": "816360"
  },
  {
    "text": "hardware and the summary looks quite",
    "start": "816360",
    "end": "819320"
  },
  {
    "text": "nice and comprehensive and all run",
    "start": "819320",
    "end": "822720"
  },
  {
    "text": "locally so it's all for free so listen",
    "start": "822720",
    "end": "825639"
  },
  {
    "text": "it's pretty cool that you can have these",
    "start": "825639",
    "end": "826760"
  },
  {
    "text": "reasoning models now running locally on",
    "start": "826760",
    "end": "828720"
  },
  {
    "text": "your laptop they'll obviously will get",
    "start": "828720",
    "end": "830639"
  },
  {
    "text": "better this think token issue will be",
    "start": "830639",
    "end": "832639"
  },
  {
    "text": "resolved I'm sure in the near future I",
    "start": "832639",
    "end": "834720"
  },
  {
    "text": "encourage you to play with it very much",
    "start": "834720",
    "end": "836560"
  },
  {
    "text": "I find AMA to be a very nice easy way to",
    "start": "836560",
    "end": "838360"
  },
  {
    "text": "access these models but there's also",
    "start": "838360",
    "end": "840000"
  },
  {
    "text": "some other ways to do it and I think",
    "start": "840000",
    "end": "842800"
  },
  {
    "text": "it's a really nice step forward and it",
    "start": "842800",
    "end": "845079"
  },
  {
    "text": "is really cool that we actually have",
    "start": "845079",
    "end": "847079"
  },
  {
    "text": "visibility to how these models are",
    "start": "847079",
    "end": "848639"
  },
  {
    "text": "trained and that this is all open source",
    "start": "848639",
    "end": "851360"
  },
  {
    "text": "so thank you to deep seek for releasing",
    "start": "851360",
    "end": "853120"
  },
  {
    "text": "this and for llama forg getting this up",
    "start": "853120",
    "end": "855600"
  },
  {
    "text": "really quickly so anyway hope this was",
    "start": "855600",
    "end": "857720"
  },
  {
    "text": "informative and um thanks",
    "start": "857720",
    "end": "862319"
  }
]
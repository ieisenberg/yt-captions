[
  {
    "text": "all right hello everyone we are we are live um to talk about data privacy for",
    "start": "1120",
    "end": "6720"
  },
  {
    "text": "LM applications thank you guys for joining um thank you to Chester and Max for for being here um minor Logistics",
    "start": "6720",
    "end": "14599"
  },
  {
    "text": "before we jump into it this is being recorded um so it will be available after the link and then we'll also put",
    "start": "14599",
    "end": "19720"
  },
  {
    "text": "it up on YouTube um uh uh later today or tomorrow um if you have questions we",
    "start": "19720",
    "end": "26640"
  },
  {
    "text": "want this to be super interactive you know this is a this is an area where I think everyone has a lot of questions myself included so if you have questions",
    "start": "26640",
    "end": "33000"
  },
  {
    "text": "please drop them in uh the little Q&A box on the right so right now by default",
    "start": "33000",
    "end": "38079"
  },
  {
    "text": "you're probably in the chat that's what you'll see on the right if you look beneath the little chat bubble there's a box with a question mark um you can put",
    "start": "38079",
    "end": "44960"
  },
  {
    "text": "questions in there you can upload questions that you like and and we'll go through those at the end um and and and",
    "start": "44960",
    "end": "50879"
  },
  {
    "text": "answer any of those um before we jump into the presentations we can do maybe some quick introductions all around so",
    "start": "50879",
    "end": "57359"
  },
  {
    "text": "my name is Harrison uh CEO co-founder of Link chain um and Max do you want to do",
    "start": "57359",
    "end": "62399"
  },
  {
    "text": "a quick introduction of yourself sure uh hi everyone my name is Max I work as data scientist at dson C uh where we",
    "start": "62399",
    "end": "70000"
  },
  {
    "text": "develop Solutions of all kinds so related basically to to artificial intelligence uh and we've been working",
    "start": "70000",
    "end": "76200"
  },
  {
    "text": "with Lan chain and contributing there for a while now and we have been active in various areas uh including privacy",
    "start": "76200",
    "end": "83000"
  },
  {
    "text": "hence my presence here so nice to meet you all and yeah that's it so Chester",
    "start": "83000",
    "end": "88040"
  },
  {
    "text": "now your turn yeah good to meet you all I'm Chester I am one of the co-founders of opaque systems at opaque we are",
    "start": "88040",
    "end": "95040"
  },
  {
    "text": "building the confidential Computing platform for collaborative analytics and AI um so what that basically means is",
    "start": "95040",
    "end": "101119"
  },
  {
    "text": "we're building kind of um some data privacy solutions to enable um secure analytics and",
    "start": "101119",
    "end": "108600"
  },
  {
    "text": "AI awesome all right let's jump right into it Max do you want to take it away y so let me share my",
    "start": "108680",
    "end": "117880"
  },
  {
    "text": "screen",
    "start": "118840",
    "end": "121840"
  },
  {
    "text": "all right and you should be able to see that so I'll start uh so today I will tell you a little about my contribution",
    "start": "124119",
    "end": "130360"
  },
  {
    "text": "to L chain uh but before let's start with a short short intro so uh you know",
    "start": "130360",
    "end": "135440"
  },
  {
    "text": "L chain phenomenon is evidence so it is proven by all these popularity charts so we got something from Star history uh",
    "start": "135440",
    "end": "142280"
  },
  {
    "text": "about star stars and GitHub so obviously good is to the developers and people",
    "start": "142280",
    "end": "147800"
  },
  {
    "text": "want to build application on top of and L chain well because of all these",
    "start": "147800",
    "end": "153200"
  },
  {
    "text": "tools chains Integrations is a good place to start with all these Integrations users",
    "start": "153200",
    "end": "159159"
  },
  {
    "text": "can create a knowledge base based on multiple sources of information uh so they can create a system for example for",
    "start": "159159",
    "end": "165480"
  },
  {
    "text": "question answering right based on some number of documents and uh well other",
    "start": "165480",
    "end": "170680"
  },
  {
    "text": "system can be uh content creation So based on the content previously created we can create a new content for example",
    "start": "170680",
    "end": "177720"
  },
  {
    "text": "for an article or whatever uh and this is especially important for large companies uh where data comes in",
    "start": "177720",
    "end": "185200"
  },
  {
    "text": "from many many sources and uh well it's hard to temperate right so it's one big",
    "start": "185200",
    "end": "190599"
  },
  {
    "text": "chaos and mess H and you know conquer it and the power and money is yours so like",
    "start": "190599",
    "end": "196400"
  },
  {
    "text": "in The Lord of the Rings one system to rule them all uh so a lot of people and",
    "start": "196400",
    "end": "201959"
  },
  {
    "text": "a lot of companies are experimenting with creating applications based on llms and llm appies right so apis putting",
    "start": "201959",
    "end": "209000"
  },
  {
    "text": "their private data as context to the model uh so after all big companies care",
    "start": "209000",
    "end": "214799"
  },
  {
    "text": "about data security and privacy right so our data is at least should be safe",
    "start": "214799",
    "end": "220439"
  },
  {
    "text": "right uh so um my theory uh my small theory is that it is not always the case",
    "start": "220439",
    "end": "227920"
  },
  {
    "text": "and I got some examples right here uh I didn't have to look far because uh all these leaks took place in",
    "start": "227920",
    "end": "234360"
  },
  {
    "text": "20123 uh and well even openi uh hasn't been immune for for for from leaks",
    "start": "234360",
    "end": "240159"
  },
  {
    "text": "either uh so in March this year uh users with chat GPT plus could see uh could",
    "start": "240159",
    "end": "246200"
  },
  {
    "text": "brow through other users conversations uh you know on the chat website and they",
    "start": "246200",
    "end": "252400"
  },
  {
    "text": "could also see some uh private personal payment information something like that",
    "start": "252400",
    "end": "257880"
  },
  {
    "text": "so uh you know it's the topic is hot and there is plenty of controversy uh we all",
    "start": "257880",
    "end": "264080"
  },
  {
    "text": "probably remember the situation in Italy where GPT was temporarily banned from",
    "start": "264080",
    "end": "269160"
  },
  {
    "text": "from the country and an interesting fact is that my own country so so Polish people are also",
    "start": "269160",
    "end": "276360"
  },
  {
    "text": "questioning it uh like questioning open AI ability to comply with European standards about privacy uh so one",
    "start": "276360",
    "end": "284360"
  },
  {
    "text": "complaint was filed with the Polish data protection authority uh so four questions arise",
    "start": "284360",
    "end": "291800"
  },
  {
    "text": "right so what kind of data do we want to protect what do we protect our data from",
    "start": "291800",
    "end": "297160"
  },
  {
    "text": "what can we do to protect our data and how can we we do it so I'll answer first three questions and then we'll go to the",
    "start": "297160",
    "end": "304080"
  },
  {
    "text": "fourth one uh where I will show you my function functional so my contribution to to",
    "start": "304080",
    "end": "309720"
  },
  {
    "text": "longchain uh so what kind of data do we want to protect uh we got something called personally identifiable",
    "start": "309720",
    "end": "315600"
  },
  {
    "text": "information uh pii and it refers to any information that can be used to identify contact or locate an individual uh so we",
    "start": "315600",
    "end": "323319"
  },
  {
    "text": "can we have two uh categories of pii first of all we got linked information",
    "start": "323319",
    "end": "329759"
  },
  {
    "text": "uh which is more direct one uh so it can be any information that will enable us",
    "start": "329759",
    "end": "335880"
  },
  {
    "text": "to uh to identify a person based on that particular information so for example",
    "start": "335880",
    "end": "341639"
  },
  {
    "text": "email phone number Social Security number passport number Etc uh the second category is more indirect and more",
    "start": "341639",
    "end": "348919"
  },
  {
    "text": "tricky so it's linkable information so uh let's imagine we have one information that is well not not connected to one",
    "start": "348919",
    "end": "357080"
  },
  {
    "text": "particular person but you know a group so connection of some information uh will",
    "start": "357080",
    "end": "363319"
  },
  {
    "text": "will allow us to identify one person so uh maybe you know we have a man named",
    "start": "363319",
    "end": "369599"
  },
  {
    "text": "John so there is plenty of John in the world but when we are talking about John age 23 and he's working as a data",
    "start": "369599",
    "end": "379360"
  },
  {
    "text": "scientist at Google so we can imagine that there is only one John age 23",
    "start": "379360",
    "end": "384639"
  },
  {
    "text": "working at Google so that is also pii uh so we need to uh take care of that",
    "start": "384639",
    "end": "390400"
  },
  {
    "text": "another and even more trickier example is this so he is a young adult working with AI models in a company that owns",
    "start": "390400",
    "end": "396960"
  },
  {
    "text": "the largest search engine he likes cigars and doggies so uh I guess a lot of people like doggies right maybe some",
    "start": "396960",
    "end": "404199"
  },
  {
    "text": "of you like cigars but uh maybe there's only one person there's only one man uh",
    "start": "404199",
    "end": "410639"
  },
  {
    "text": "in Google largest search engine pretty obvious uh that like cigars and doggies both and uh we know that for for C",
    "start": "410639",
    "end": "417960"
  },
  {
    "text": "certainty uh that is is still pii so we need to take care of that so as I said",
    "start": "417960",
    "end": "423919"
  },
  {
    "text": "the first one very easy to identify and take care of uh the linkable information more tricky uh the first sentence is is",
    "start": "423919",
    "end": "431720"
  },
  {
    "text": "okay I mean we can you know identify the name we can identify the age and replace it or whatever H so so it's okay the",
    "start": "431720",
    "end": "439599"
  },
  {
    "text": "third one is Edge case so you know it's it's extremely difficult to detect such",
    "start": "439599",
    "end": "445240"
  },
  {
    "text": "information or you know similar information so uh the conclusion is no matter how hard we try there there",
    "start": "445240",
    "end": "451879"
  },
  {
    "text": "can always be an edge case so keep that in mind uh so what do we protect our data",
    "start": "451879",
    "end": "458199"
  },
  {
    "text": "from uh we can see uh a snippet from open AI uh privacy policy right here uh",
    "start": "458199",
    "end": "464840"
  },
  {
    "text": "so it is all about uh you know training the the models uh so they are using",
    "start": "464840",
    "end": "471120"
  },
  {
    "text": "chart GPT uh charts and DOL images uh for individuals to to train the model uh",
    "start": "471120",
    "end": "478520"
  },
  {
    "text": "and it can be important because uh we know from uh some papers that llms can",
    "start": "478520",
    "end": "484599"
  },
  {
    "text": "memorize training data so uh it's not that uh you know neural networks are",
    "start": "484599",
    "end": "491720"
  },
  {
    "text": "looking for patterns but they can still memorize it so uh in paper from 2020 I",
    "start": "491720",
    "end": "497919"
  },
  {
    "text": "know it's you know far away in our rapidly growing field it's like a lot years so three years uh from from that",
    "start": "497919",
    "end": "505479"
  },
  {
    "text": "point but and we got much better models much you know better alignment for the",
    "start": "505479",
    "end": "510919"
  },
  {
    "text": "models but still uh gpt2 was able to memorize some private information so we",
    "start": "510919",
    "end": "515959"
  },
  {
    "text": "need to be careful for example we can have a prompt injection or whatever so",
    "start": "515959",
    "end": "521440"
  },
  {
    "text": "uh we need to take it into consideration but I know most of us uh you know working with L chain are using API so in",
    "start": "521440",
    "end": "529000"
  },
  {
    "text": "API or chat GPT Enterprise it is not the case so they are not using our data to",
    "start": "529000",
    "end": "534480"
  },
  {
    "text": "train uh their models but uh the data may be leaked from external databases so",
    "start": "534480",
    "end": "541279"
  },
  {
    "text": "uh you know even if we use that API our data is stored for 30 days so uh well in",
    "start": "541279",
    "end": "547160"
  },
  {
    "text": "30 days a lot a lot of things can happen right so as I have shown before uh some",
    "start": "547160",
    "end": "553279"
  },
  {
    "text": "examples of of some companies and data Bridges uh so we need to uh take that",
    "start": "553279",
    "end": "558800"
  },
  {
    "text": "into consideration I mean our data is generally safe but we",
    "start": "558800",
    "end": "564399"
  },
  {
    "text": "need to uh we need to take care of that uh so what can we to protect our",
    "start": "564399",
    "end": "569920"
  },
  {
    "text": "data for sure because maybe some of us don't want to use external apis or want to protect our data from external API AP",
    "start": "569920",
    "end": "577279"
  },
  {
    "text": "apis for some reason uh so first option is to host our own llm uh this is of",
    "start": "577279",
    "end": "583880"
  },
  {
    "text": "course possible we can have our own instance of the model on premise uh we got plenty of options for example Lama 2",
    "start": "583880",
    "end": "591920"
  },
  {
    "text": "or Falcon uh with different options uh in case of a size U and there are two",
    "start": "591920",
    "end": "597680"
  },
  {
    "text": "problems first of all this model are still much worse than gp4 uh gp4 is superior right now and uh other models",
    "start": "597680",
    "end": "605640"
  },
  {
    "text": "aren't even close right now uh we'll see later um and the second thing is uh the",
    "start": "605640",
    "end": "612839"
  },
  {
    "text": "cost so you know big tech companies can afford uh in inference just you know one",
    "start": "612839",
    "end": "619160"
  },
  {
    "text": "or many instances of these models uh but small companies it's sometimes it's",
    "start": "619160",
    "end": "624399"
  },
  {
    "text": "difficult to spend you know a couple thousands dollars on on uh on a model",
    "start": "624399",
    "end": "630519"
  },
  {
    "text": "so the second option uh is which we'll discuss in detail today is anonymization or rather Pon imization of data so",
    "start": "630519",
    "end": "637920"
  },
  {
    "text": "before uploading the data to the model so feeding the model of the data we are anonymizing it so you know just",
    "start": "637920",
    "end": "643680"
  },
  {
    "text": "replacing the uh private value with some kind of other",
    "start": "643680",
    "end": "649040"
  },
  {
    "text": "value uh right so in my work I relied entirely on an open source Library called presidia from Microsoft so I",
    "start": "649040",
    "end": "655720"
  },
  {
    "text": "chose it because of its robust code I mean it's robust and it uh it has high",
    "start": "655720",
    "end": "660920"
  },
  {
    "text": "customizability so H the outs created created a good Library uh and I will show you uh the",
    "start": "660920",
    "end": "668279"
  },
  {
    "text": "example so they their system their system is uh all about these two uh",
    "start": "668279",
    "end": "674279"
  },
  {
    "text": "aspects so first of all we got text input so my name is Eric and uh we got a",
    "start": "674279",
    "end": "679320"
  },
  {
    "text": "pi an analyzer that will uh recognize the pii okay so we got some built-in",
    "start": "679320",
    "end": "685519"
  },
  {
    "text": "patterns so for example regex patterns like phone number let's say we got named entity recognition models that can",
    "start": "685519",
    "end": "691880"
  },
  {
    "text": "identify for example a person name or location or organization whatever uh",
    "start": "691880",
    "end": "697120"
  },
  {
    "text": "everything is based on the you know context search uh we can also add our custom recognizers so custom patterns uh",
    "start": "697120",
    "end": "703480"
  },
  {
    "text": "or custom models then when we have it detected we are using anonymizer part to",
    "start": "703480",
    "end": "710079"
  },
  {
    "text": "uh replace these values somehow so we can replace it with some value like here my name is person in parenthesis so a",
    "start": "710079",
    "end": "716320"
  },
  {
    "text": "marker or we can has it whatever yeah so that is presidia and uh now it's",
    "start": "716320",
    "end": "723760"
  },
  {
    "text": "time for my contribution so I implemented the integration to presidia in L chain and extended it with additional functionality so uh this is",
    "start": "723760",
    "end": "731200"
  },
  {
    "text": "how uh my work looks like it's very simple I mean you know that the easy example is very simple uh you can",
    "start": "731200",
    "end": "738639"
  },
  {
    "text": "customize it if if you want and of course everything is free open source and you can anonymize the texts locally",
    "start": "738639",
    "end": "746720"
  },
  {
    "text": "uh yeah so this is the version of anonymization without the ability to restore original entities if we want toonize data so be",
    "start": "746720",
    "end": "755120"
  },
  {
    "text": "able to restore the original values later we are using presidial reversible",
    "start": "755120",
    "end": "760480"
  },
  {
    "text": "anonymizer uh so I I know that naming can be confusing uh I will for sure work",
    "start": "760480",
    "end": "765800"
  },
  {
    "text": "on that but uh the idea is that I will anonymize something feed it to the the data to the model and then we can de",
    "start": "765800",
    "end": "772639"
  },
  {
    "text": "anonymize it okay so um you know the the output uh now let's go through a simple",
    "start": "772639",
    "end": "780240"
  },
  {
    "text": "and graphical overview of what a question answering system could look like with uh anonymization",
    "start": "780240",
    "end": "786560"
  },
  {
    "text": "process uh first of all we got simple prompt so you know answer the question based only on the following context so",
    "start": "786560",
    "end": "792920"
  },
  {
    "text": "context and question right is usual prompt then we got a context variable it",
    "start": "792920",
    "end": "798040"
  },
  {
    "text": "is like some information about stolen wallet uh it has name uh date credit",
    "start": "798040",
    "end": "803880"
  },
  {
    "text": "card number and also like polish ID card number uh then we have question what was",
    "start": "803880",
    "end": "809440"
  },
  {
    "text": "in the stolen world we can anonymize this data using our anonymizer then we have these markers we can fit it to the",
    "start": "809440",
    "end": "816040"
  },
  {
    "text": "llm we can restore the output so we got you know answer wallet head credit card",
    "start": "816040",
    "end": "822120"
  },
  {
    "text": "with number credit card and ID with number ID uh and then at the end we can de anonymize it so no private data will",
    "start": "822120",
    "end": "829800"
  },
  {
    "text": "go uh inside the model the the external API uh and now some selected features of",
    "start": "829800",
    "end": "837639"
  },
  {
    "text": "this solution so only selected fields to be anonymized so we can select uh using",
    "start": "837639",
    "end": "842680"
  },
  {
    "text": "parameter analyzed fields we can select the pii that we want to anonymize and",
    "start": "842680",
    "end": "848000"
  },
  {
    "text": "other will be skipped okay uh instance anonymization so uh let's see right here",
    "start": "848000",
    "end": "853440"
  },
  {
    "text": "we got two dates October 19th and October 20th so we want to treat them as",
    "start": "853440",
    "end": "859079"
  },
  {
    "text": "as separate instances okay so uh we want to have the date and date two H in in",
    "start": "859079",
    "end": "865759"
  },
  {
    "text": "the result okay so H that's the first thing uh another thing is that if uh one",
    "start": "865759",
    "end": "871759"
  },
  {
    "text": "entity will be repeated twice or more uh for example here my name and sirname",
    "start": "871759",
    "end": "877320"
  },
  {
    "text": "maxlin H it is repeated twice so we want it to be one instance so I'm mentioning",
    "start": "877320",
    "end": "882880"
  },
  {
    "text": "that because it is something that is not yet in Microsoft presidia uh because uh",
    "start": "882880",
    "end": "888839"
  },
  {
    "text": "there are some optimization problems uh but uh I found it important to implement in Lang chain so there we go we got",
    "start": "888839",
    "end": "896560"
  },
  {
    "text": "support for custom entities recognizers uh so uh we can see that we got this",
    "start": "896560",
    "end": "901600"
  },
  {
    "text": "polish ID card here and it is not by default uh you know in presidia so if we",
    "start": "901600",
    "end": "906639"
  },
  {
    "text": "want to add it we can just use simple regx and that's basically it so uh we",
    "start": "906639",
    "end": "911920"
  },
  {
    "text": "will have this polish ID recognized uh then synthetic data plus new operators operators uh are tools to",
    "start": "911920",
    "end": "919480"
  },
  {
    "text": "replace these values with something okay we saw these markers and they are okay but uh we can imagine you know we need",
    "start": "919480",
    "end": "925880"
  },
  {
    "text": "to focus on how the models are trained so usually the training is all about next sentence or next token prediction",
    "start": "925880",
    "end": "933519"
  },
  {
    "text": "uh this means that uh you know the model will uh provide new tokens based on the",
    "start": "933519",
    "end": "938959"
  },
  {
    "text": "previous tokens so if the previous tokens will be uh not natural I would say so for example have this marker this",
    "start": "938959",
    "end": "945079"
  },
  {
    "text": "person in parenthesis then the words or token probability can shift can change",
    "start": "945079",
    "end": "950839"
  },
  {
    "text": "so it can uh make our results worse I I don't think it's the case for gp4 but",
    "start": "950839",
    "end": "957040"
  },
  {
    "text": "maybe for smaller models it can be the case so it's good to replace it with synthetic values okay so so right here",
    "start": "957040",
    "end": "963600"
  },
  {
    "text": "you got some examples of that and at the end we got support for multiple languages so you know pretty",
    "start": "963600",
    "end": "970000"
  },
  {
    "text": "straightforward we can have text in multiple languages and uh aniz simiz",
    "start": "970000",
    "end": "975639"
  },
  {
    "text": "them as we want uh right and now let's uh move to",
    "start": "975639",
    "end": "980839"
  },
  {
    "text": "the demo up so we'll build question answering up with reversible anonymization and I will show you an",
    "start": "980839",
    "end": "986480"
  },
  {
    "text": "interative approach to improving rization um everything that will I will",
    "start": "986480",
    "end": "991600"
  },
  {
    "text": "show you today is already on documentation so if you're interested then you can uh you can take a look",
    "start": "991600",
    "end": "997839"
  },
  {
    "text": "right here but I will show you that in the collab notebook so as you can see",
    "start": "997839",
    "end": "1003000"
  },
  {
    "text": "here we are installing uh necessary packages and we got a text text is all",
    "start": "1003000",
    "end": "1008720"
  },
  {
    "text": "about like police testimony I mean fortunately I I've never been in police",
    "start": "1008720",
    "end": "1014519"
  },
  {
    "text": "station so I have no idea how these testimonies look like uh but hopefully",
    "start": "1014519",
    "end": "1019560"
  },
  {
    "text": "it's something like that okay that the important thing is that we got some uh pii right here like a lot of them so we",
    "start": "1019560",
    "end": "1026880"
  },
  {
    "text": "want to anonymize them right um okay so we are creating documents we are using",
    "start": "1026880",
    "end": "1032160"
  },
  {
    "text": "this function to color the pii so you'll see that in the minute and here we are",
    "start": "1032160",
    "end": "1037959"
  },
  {
    "text": "uh selecting the analyze fields that we want to analyze so there is like a full list of uh fields that are analyzed by",
    "start": "1037959",
    "end": "1045798"
  },
  {
    "text": "default but we want uh only this uh well us oriented",
    "start": "1045799",
    "end": "1051400"
  },
  {
    "text": "okay and right here we are initializing presidial reversible anonymizer with at default fakeer operators equals false",
    "start": "1051400",
    "end": "1058280"
  },
  {
    "text": "which means that we will not use synthetic data we will just use uh you know this markers so right here you can",
    "start": "1058280",
    "end": "1065440"
  },
  {
    "text": "see uh all all these markers uh you know we are anonymizing the the content of",
    "start": "1065440",
    "end": "1070720"
  },
  {
    "text": "the file and we got all of this uh right here and we can see the mapping uh right",
    "start": "1070720",
    "end": "1077520"
  },
  {
    "text": "there uh you remember that uh we got a mapping to restore the previous values uh so we can see different categories",
    "start": "1077520",
    "end": "1084200"
  },
  {
    "text": "and we can see different entities so we got credit card datetime email address and the second one etc etc H so I see",
    "start": "1084200",
    "end": "1091679"
  },
  {
    "text": "that two problems here so first of all when we'll see at date time uh then look we have date time date and date time",
    "start": "1091679",
    "end": "1099919"
  },
  {
    "text": "time right so it's it's not very very smart to to have both of them as the",
    "start": "1099919",
    "end": "1105440"
  },
  {
    "text": "same entity type so we want to create time entity for that uh and the second",
    "start": "1105440",
    "end": "1110520"
  },
  {
    "text": "thing is that right here I got polish ID number which is not by default in Presidio I I told you that before so we",
    "start": "1110520",
    "end": "1116799"
  },
  {
    "text": "want to create two recognizers to recognize these things so right here we",
    "start": "1116799",
    "end": "1121840"
  },
  {
    "text": "are using a presidio analyzer for pattern creation we got some simple regx",
    "start": "1121840",
    "end": "1127600"
  },
  {
    "text": "I don't want to go into detail but you know we have regex we are adding it to the recognizer so we got pattern",
    "start": "1127600",
    "end": "1134440"
  },
  {
    "text": "recognizer uh from presidia uh and we can add this recognizer to our",
    "start": "1134440",
    "end": "1139960"
  },
  {
    "text": "anonymizer uh now what is important uh we need to reset mapping because you remember pre previously that we had it",
    "start": "1139960",
    "end": "1147240"
  },
  {
    "text": "right here stored so it is already saved so it's good to remove just this entity",
    "start": "1147240",
    "end": "1152840"
  },
  {
    "text": "or all of this entities so no it's easier for me to to reset everything and to anonymize it once again and look uh",
    "start": "1152840",
    "end": "1160000"
  },
  {
    "text": "we got polish ID and we got time so everything is is there uh and we got all",
    "start": "1160000",
    "end": "1166039"
  },
  {
    "text": "of these uh mapping entries now let's uh change it to the synthetic",
    "start": "1166039",
    "end": "1171799"
  },
  {
    "text": "data so we are using at default Faker operators to True uh or we can just leave it empty for now because uh it's",
    "start": "1171799",
    "end": "1178440"
  },
  {
    "text": "by default true uh we are using Faker so we need to set the faker seat I mean we",
    "start": "1178440",
    "end": "1183720"
  },
  {
    "text": "don't need to we we shouldn't do it in production so the data will be random um yeah and we are adding",
    "start": "1183720",
    "end": "1189880"
  },
  {
    "text": "recognizers and anonymizing the text once again and you can see all of it is replaced so we got some random names uh",
    "start": "1189880",
    "end": "1198559"
  },
  {
    "text": "yeah by the way one one thing that I want to mention is that in this text uh there is my polish name I mean I'm one",
    "start": "1198559",
    "end": "1206559"
  },
  {
    "text": "of the five people that have this surname so it's not like in the huge database so only my family has this",
    "start": "1206559",
    "end": "1212520"
  },
  {
    "text": "surname so uh you can see that based on the context or maybe this uppercase it's",
    "start": "1212520",
    "end": "1218039"
  },
  {
    "text": "it's recognized me as as person that's that's pretty cool so yeah that's that's why I left here my name uh yeah but you",
    "start": "1218039",
    "end": "1226880"
  },
  {
    "text": "know we don't have this this uh values for uh for it so we don't have operators",
    "start": "1226880",
    "end": "1232760"
  },
  {
    "text": "we need to create some operators so we are using Faker Library which will allow",
    "start": "1232760",
    "end": "1237799"
  },
  {
    "text": "us to generate some uh synthetic values so for example here we are using it to",
    "start": "1237799",
    "end": "1243679"
  },
  {
    "text": "create something with like three letters and six digits right here okay so that's",
    "start": "1243679",
    "end": "1248720"
  },
  {
    "text": "how the example will look like H and that's how it is in in case of Polish ID",
    "start": "1248720",
    "end": "1255200"
  },
  {
    "text": "uh here we got fake time so we got once again you know using Faker we are just",
    "start": "1255200",
    "end": "1260960"
  },
  {
    "text": "adding new operators uh for to our anonymizer and now we can see we are",
    "start": "1260960",
    "end": "1266480"
  },
  {
    "text": "obviously resetting mapping and we can see that it is already there um so",
    "start": "1266480",
    "end": "1271520"
  },
  {
    "text": "that's the the thing I was mentioning before that we have a high customizability so we can add as many uh",
    "start": "1271520",
    "end": "1278640"
  },
  {
    "text": "things as we want and improve it and you know Rising the recall of our",
    "start": "1278640",
    "end": "1284640"
  },
  {
    "text": "system uh so VOA now uh the last thing is to put it all together into one",
    "start": "1284640",
    "end": "1290320"
  },
  {
    "text": "system uh Q&A system so we got once again presio anonymizer with ability to",
    "start": "1290320",
    "end": "1296559"
  },
  {
    "text": "uh reverse it h we are adding recognizers operators then we are loading the data so we got you know",
    "start": "1296559",
    "end": "1302760"
  },
  {
    "text": "documents all in this case just one document uh then we are anonymizing the data before indexing because we are",
    "start": "1302760",
    "end": "1309880"
  },
  {
    "text": "using open a embeddings so at this point we don't want any data to to go outside",
    "start": "1309880",
    "end": "1315080"
  },
  {
    "text": "right so we are anonymizing it at this point uh we are splitting the documents as usual and we are storing them in in F",
    "start": "1315080",
    "end": "1322559"
  },
  {
    "text": "uh database uh and the last part is to create the anonymizer chain so we got a",
    "start": "1322559",
    "end": "1329279"
  },
  {
    "text": "template like a usual templat so answer the question based only on the following context we got model so chat open Ai and",
    "start": "1329279",
    "end": "1338080"
  },
  {
    "text": "here we got some uh data manipulation so uh we got a question obviously uh which",
    "start": "1338080",
    "end": "1343520"
  },
  {
    "text": "will be provided by the user and we got anonymized question which will just use anonymizer to anonymize the question um",
    "start": "1343520",
    "end": "1351679"
  },
  {
    "text": "the whole chain looks like that so we are manipulating this inputs then we are we are taking the context from",
    "start": "1351679",
    "end": "1358200"
  },
  {
    "text": "anonymized question uh and well we are passing it to the prompt and then to the model and",
    "start": "1358200",
    "end": "1364799"
  },
  {
    "text": "we got start string output parser at the end so when we'll ask the question H",
    "start": "1364799",
    "end": "1369960"
  },
  {
    "text": "then we have the information so where did the theft of the wallet occur at what time and who was it stolen from so",
    "start": "1369960",
    "end": "1375600"
  },
  {
    "text": "you see that we got some information right uh and now the only thing we need to add",
    "start": "1375600",
    "end": "1381720"
  },
  {
    "text": "is uh the anonymize method at the end and we can ask the same question and you",
    "start": "1381720",
    "end": "1387039"
  },
  {
    "text": "see that the data is restored to the original so I got my name here the proper hour and also this location right",
    "start": "1387039",
    "end": "1394240"
  },
  {
    "text": "here we can ask other questions for example of the content of the wallet in detail so we got something right here",
    "start": "1394240",
    "end": "1400360"
  },
  {
    "text": "everything is De anonymized uh we got uh something here so whose phone is uh whose phone number",
    "start": "1400360",
    "end": "1407600"
  },
  {
    "text": "is it we got this original phone although you need to remember that we are anonymizing this question so you",
    "start": "1407600",
    "end": "1413840"
  },
  {
    "text": "know it is anonymized before ping it to the model so no data will go to the",
    "start": "1413840",
    "end": "1418880"
  },
  {
    "text": "model uh in our case so that's it uh if you would like to use local embeddings",
    "start": "1418880",
    "end": "1425400"
  },
  {
    "text": "or for some reason if you would like to store uh original data uh in your vector",
    "start": "1425400",
    "end": "1430880"
  },
  {
    "text": "database because why not then you can use local embeddings and the chain will look uh well a bit different this time",
    "start": "1430880",
    "end": "1437919"
  },
  {
    "text": "time but I will not go into details you can uh check it out right here in the",
    "start": "1437919",
    "end": "1444000"
  },
  {
    "text": "documentation uh right so that's it from me and thanks guys questions later right",
    "start": "1444000",
    "end": "1450279"
  },
  {
    "text": "right now yeah I mean I I I have I have two quick ones um not to take up too much time but uh one one of them is uh",
    "start": "1450279",
    "end": "1457440"
  },
  {
    "text": "how often do you find yourself writing kind of like custom anonymizers and and and things to cover like custom you know",
    "start": "1457440",
    "end": "1464799"
  },
  {
    "text": "reg X's or whatever like is that a common thing you do like do you always find yourself having to do that or is that like more the exception than the",
    "start": "1464799",
    "end": "1470960"
  },
  {
    "text": "rule mhm well I would say it is very important because it's very data specific like all data sources are",
    "start": "1470960",
    "end": "1477520"
  },
  {
    "text": "different right so as I said as a Polish guy I have a lot of these things",
    "start": "1477520",
    "end": "1483799"
  },
  {
    "text": "repeated so for example polish ID is one thing but also polish phone number is different okay so uh if somebody will",
    "start": "1483799",
    "end": "1490960"
  },
  {
    "text": "write a Polish phone number that then it will not be recognized it is much easier for um you know dat from America because",
    "start": "1490960",
    "end": "1499960"
  },
  {
    "text": "uh all of that is present in uh in Presidio by default so uh it's it's",
    "start": "1499960",
    "end": "1505720"
  },
  {
    "text": "easier that way uh I would say uh it's not like you should use it without any",
    "start": "1505720",
    "end": "1511440"
  },
  {
    "text": "thinking of that so you should first uh check what data is anonymized and check",
    "start": "1511440",
    "end": "1517000"
  },
  {
    "text": "the recall of that uh so how many uh Fields were recognized uh manually",
    "start": "1517000",
    "end": "1522440"
  },
  {
    "text": "probably and then add it and interactively uh repeat this process until our system will be uh good and",
    "start": "1522440",
    "end": "1530360"
  },
  {
    "text": "it's not like you'll have 100% sure right we cannot be sure so uh it's it's",
    "start": "1530360",
    "end": "1535919"
  },
  {
    "text": "something that we need to improve well and and then I'm also curious like and I think you like like",
    "start": "1535919",
    "end": "1543399"
  },
  {
    "text": "are there cases that you found where you wouldn't want to do this like if I'm building a chain and I want to like",
    "start": "1543399",
    "end": "1549720"
  },
  {
    "text": "extract like the the length of people's names right like if I replace their names with a different name that then",
    "start": "1549720",
    "end": "1555960"
  },
  {
    "text": "then it's going to completely fail that's a bit of like a toy example are there any like any real world examples where you found that you just don't want",
    "start": "1555960",
    "end": "1562120"
  },
  {
    "text": "to do this MH uh yeah sure I mean one one thing that I have in mind is that uh",
    "start": "1562120",
    "end": "1569880"
  },
  {
    "text": "well it's it's very language specific because in in Polish language we got something called called declination I",
    "start": "1569880",
    "end": "1575840"
  },
  {
    "text": "don't know if that's the name in English uh but you know if I am saying I am Max",
    "start": "1575840",
    "end": "1582399"
  },
  {
    "text": "n Max so my name is Max but I'm going to Max so the translation is either Maxa so",
    "start": "1582399",
    "end": "1588480"
  },
  {
    "text": "it's not the same War so you can see that this exact match will fail right here so that's that's one thing um any",
    "start": "1588480",
    "end": "1596080"
  },
  {
    "text": "other examples well uh I don't have anything in mind like in",
    "start": "1596080",
    "end": "1602720"
  },
  {
    "text": "produ production case and in some you know sometimes you just using your on",
    "start": "1602720",
    "end": "1609960"
  },
  {
    "text": "Prim is Lama or whatever like other different model then in that case you",
    "start": "1609960",
    "end": "1615120"
  },
  {
    "text": "would not like to use it because there is uh there's no need for that",
    "start": "1615120",
    "end": "1621440"
  },
  {
    "text": "right awesome all right um and and I think uh",
    "start": "1621440",
    "end": "1629320"
  },
  {
    "text": "you got one question about the collab like is that collab file available uh yep you can uh you can open it right",
    "start": "1629320",
    "end": "1637240"
  },
  {
    "text": "here from the documentation I have uh like I think two changes in that",
    "start": "1637240",
    "end": "1642640"
  },
  {
    "text": "notebook uh so I will push them I mean I will do a a merage request today or",
    "start": "1642640",
    "end": "1648159"
  },
  {
    "text": "tomorrow so we'll have uh full thing available awesome and maybe you can",
    "start": "1648159",
    "end": "1653279"
  },
  {
    "text": "share a link to that in in the chat right now okay okay sure cool all right",
    "start": "1653279",
    "end": "1659679"
  },
  {
    "text": "Chester do you wna do you want to take over now yeah sounds good um",
    "start": "1659679",
    "end": "1665519"
  },
  {
    "text": "second oh Max we'll have to stop okay there we go",
    "start": "1665519",
    "end": "1670480"
  },
  {
    "text": "M cool yeah so today we'll be talking about about um something very similar to kind of what Max went over um towards",
    "start": "1675039",
    "end": "1681559"
  },
  {
    "text": "privacy preserving generative AI um for a little bit more background on myself um our team that kind of came out and",
    "start": "1681559",
    "end": "1687159"
  },
  {
    "text": "found it opaque we were doing research for a number of years in privacy enhancing Technologies um in the rise of",
    "start": "1687159",
    "end": "1692760"
  },
  {
    "text": "black Berkeley so today we'll be talking about a little bit about um generative AI of course but also confidential",
    "start": "1692760",
    "end": "1698279"
  },
  {
    "text": "Computing um so we'll give a quick intro on that and then we'll also talk a little bit more about how we can apply confidential Computing to generative AI",
    "start": "1698279",
    "end": "1706000"
  },
  {
    "text": "um to plug a lot of the privacy gaps that we've been kind of hearing from a number of different",
    "start": "1706000",
    "end": "1711559"
  },
  {
    "text": "folks um so yeah this intro is very similar to Max's um we're we've kind of",
    "start": "1711559",
    "end": "1716640"
  },
  {
    "text": "been seeing a number of growing privacy concerns um so I think the first kind of really large uh privacy kind of leak",
    "start": "1716640",
    "end": "1724919"
  },
  {
    "text": "that we saw was that samung employees shared source code with chat gbt um and also used to summarize meeting notes",
    "start": "1724919",
    "end": "1731320"
  },
  {
    "text": "which Samsung deemed non- compliant with their internal policies because the employees were leaking uh proprietary",
    "start": "1731320",
    "end": "1736600"
  },
  {
    "text": "information to a third party provider uh similarly in Italy um and I",
    "start": "1736600",
    "end": "1742640"
  },
  {
    "text": "think Max already mentioned this as well but Italy banned chatut for a while um claiming that unlawfully collected used",
    "start": "1742640",
    "end": "1748679"
  },
  {
    "text": "and retained users data um and even worse right conversations from one user were actually visible um to a different",
    "start": "1748679",
    "end": "1756039"
  },
  {
    "text": "user and in general we've seen you know a number of different companies and a number of different sectors have",
    "start": "1756039",
    "end": "1761200"
  },
  {
    "text": "concerns um anywhere from Apple um to the big Banks JP Morgan City um to to a",
    "start": "1761200",
    "end": "1766880"
  },
  {
    "text": "even like Telecom provider uh like Verizon so now that we've established",
    "start": "1766880",
    "end": "1772840"
  },
  {
    "text": "that companies big and small um are concerned about the Privacy the privacy of llms let's further dive into what",
    "start": "1772840",
    "end": "1779679"
  },
  {
    "text": "those risks are so I'm sure that everybody here is kind of you know familiar with the",
    "start": "1779679",
    "end": "1784919"
  },
  {
    "text": "retrieval augmented generation architecture so we won't go too much into that um what we will do is kind of",
    "start": "1784919",
    "end": "1790240"
  },
  {
    "text": "take a look at which parts of this architecture are run on a thirdparty platform um and later we'll go into why",
    "start": "1790240",
    "end": "1795640"
  },
  {
    "text": "running on a third party platform may not be the most secure thing so as we've kind of seen right as the space has",
    "start": "1795640",
    "end": "1801159"
  },
  {
    "text": "matured Vector databases have become a very popular status offering with companies like pine cone weba and chroma",
    "start": "1801159",
    "end": "1807000"
  },
  {
    "text": "and what these companies are doing is they are mostly hosting these databases in their own environment meaning that",
    "start": "1807000",
    "end": "1812360"
  },
  {
    "text": "you as an application developer when you insert the documents in the into the database um the providers usually get to",
    "start": "1812360",
    "end": "1818600"
  },
  {
    "text": "see the documents that you insert and additionally um you know",
    "start": "1818600",
    "end": "1824720"
  },
  {
    "text": "because you know the llm itself is often run on the party premise so here think open AI think anthropic or think Google",
    "start": "1824720",
    "end": "1830960"
  },
  {
    "text": "when you are making an external API call um to these providers you are also sending your prompts or your inputs um",
    "start": "1830960",
    "end": "1837880"
  },
  {
    "text": "to the providers themselves so why do we actually care",
    "start": "1837880",
    "end": "1843440"
  },
  {
    "text": "about the llm or the vector database running on a third party premise um well",
    "start": "1843440",
    "end": "1848760"
  },
  {
    "text": "in particular here you know in model development if you're are developing the model on sensitive data um the sensitive",
    "start": "1848760",
    "end": "1854360"
  },
  {
    "text": "data is being pushed outside the user environment and similarly with inference um if you are you know performing",
    "start": "1854360",
    "end": "1860399"
  },
  {
    "text": "inference on sensitive data so think pii as Max has you know previously gone over or think other types of data that a",
    "start": "1860399",
    "end": "1866639"
  },
  {
    "text": "company itself May deem sensitive um then you know model inference may also happen outside the user",
    "start": "1866639",
    "end": "1874200"
  },
  {
    "text": "environment so diving deeper into um model development using proprietary data",
    "start": "1874880",
    "end": "1881519"
  },
  {
    "text": "so to help frame this more concretely right let's take the example of an application that will serve as a company brain the here imagine that you know",
    "start": "1881519",
    "end": "1888440"
  },
  {
    "text": "you're trying to create an llm that can answer any question about anything happening um within a company from any",
    "start": "1888440",
    "end": "1893679"
  },
  {
    "text": "employee so for example let's say I want to you know ask about yesterday's action items um from the meeting at 2 pm or you",
    "start": "1893679",
    "end": "1901120"
  },
  {
    "text": "know I want to ask a recruiter or the hiring manager um what the recruiting pipeline looks",
    "start": "1901120",
    "end": "1906960"
  },
  {
    "text": "like um so the company brain here is essentially a model that is continuously trained or fine-tuned on new company",
    "start": "1906960",
    "end": "1913720"
  },
  {
    "text": "data whether that be internal documents or conversations between between employees and as more conversations",
    "start": "1913720",
    "end": "1919320"
  },
  {
    "text": "happen and as more documents are created then the model needs to be iteratively and continuously developed and while",
    "start": "1919320",
    "end": "1925840"
  },
  {
    "text": "overall this application um and this brain will be super useful for the company as a whole to prevent something",
    "start": "1925840",
    "end": "1930919"
  },
  {
    "text": "like tribal knowledge um these documents or the conversations used to train the model may contain confidential data that",
    "start": "1930919",
    "end": "1937320"
  },
  {
    "text": "is required to build an effective brain um so the company may not want to share this data outside its premises and this",
    "start": "1937320",
    "end": "1943080"
  },
  {
    "text": "is basically you know what happened with Samsung um so next let's take a look at",
    "start": "1943080",
    "end": "1948519"
  },
  {
    "text": "model inference um so similarly here the prompts for the inputs so for example the the user query U may contain",
    "start": "1948519",
    "end": "1954639"
  },
  {
    "text": "confidential data um but inference also happens on the third party providers platform meaning that the thirdparty",
    "start": "1954639",
    "end": "1960240"
  },
  {
    "text": "provider can see the entire contents of the prompt um so extending the kind of company Brin example here let's say that",
    "start": "1960240",
    "end": "1967279"
  },
  {
    "text": "an employee in finance may want to ask questions about the balance sheet or the profit law statement which may not be",
    "start": "1967279",
    "end": "1972679"
  },
  {
    "text": "public but since inference happens on the third party providers platform the provider may actually be able to see",
    "start": "1972679",
    "end": "1978679"
  },
  {
    "text": "some of the sensitive Financial numbers that are included in the employees prompt um and in particular here with",
    "start": "1978679",
    "end": "1985840"
  },
  {
    "text": "model inference we've actually heard particular concerns about the provider's um data usage collection and retention",
    "start": "1985840",
    "end": "1991840"
  },
  {
    "text": "policies so in other words what the provider does with the data used to query the model um and I think Max you",
    "start": "1991840",
    "end": "1997039"
  },
  {
    "text": "know earlier mentioned something about open AI you know storing the data for about 30 days and from what we've seen",
    "start": "1997039",
    "end": "2002519"
  },
  {
    "text": "we've done a bit of research on this they they're actually one of the better companies so a company like Google I think they have an option to go up to",
    "start": "2002519",
    "end": "2009039"
  },
  {
    "text": "either 120 or even an entire year 120 days or an entire",
    "start": "2009039",
    "end": "2014639"
  },
  {
    "text": "year um so one solution to kind of the AFF forementioned issues are is a",
    "start": "2016120",
    "end": "2021360"
  },
  {
    "text": "customer deployment um of the model so here you the customer could either F tune or host the model on Prem and what",
    "start": "2021360",
    "end": "2027559"
  },
  {
    "text": "this basically means is that you know the model will run in the customer environment and as a result of that the model is not hosted in the third party",
    "start": "2027559",
    "end": "2034279"
  },
  {
    "text": "environment however this would require that the foundation model be shared with the customer um but obviously you know",
    "start": "2034279",
    "end": "2040440"
  },
  {
    "text": "companies like open AI may want may not want to do this because they have invested a significant amount of capital",
    "start": "2040440",
    "end": "2045799"
  },
  {
    "text": "in developing the model to be as good as it",
    "start": "2045799",
    "end": "2049839"
  },
  {
    "text": "is um so next let's kind of switch gears a little bit and talk a little bit about confidential Computing um and hopefully",
    "start": "2052159",
    "end": "2058079"
  },
  {
    "text": "this will give enough of a background to those who are not familiar with the technology to understand how confidential Computing can plug a lot of",
    "start": "2058079",
    "end": "2064440"
  },
  {
    "text": "the gaps um that we have um previously outlined so first let's kind of discuss",
    "start": "2064440",
    "end": "2071358"
  },
  {
    "text": "what problem um confidential Computing is solving so today data protection can be thought of in three parts the first",
    "start": "2071359",
    "end": "2078520"
  },
  {
    "text": "part is data being protected at rest so in other words when it's in storage and secondly when it's in transit so for",
    "start": "2078520",
    "end": "2084679"
  },
  {
    "text": "example when it's sent over the network and these two problems or these two parts have long been solved problems for",
    "start": "2084679",
    "end": "2090960"
  },
  {
    "text": "example databases have for now for a while now um stored your data encrypted and uh we have network communication",
    "start": "2090960",
    "end": "2098160"
  },
  {
    "text": "being encrypted for a long time now so think https or TLS the last part of data protection is",
    "start": "2098160",
    "end": "2106119"
  },
  {
    "text": "the protection of data in use and unlike the first two protection of data in use is still not prevalent so this means",
    "start": "2106119",
    "end": "2112079"
  },
  {
    "text": "that while data is being processed so for example when you're when you're doing um llm training or when you're",
    "start": "2112079",
    "end": "2117359"
  },
  {
    "text": "doing inference the data used during that processing is unencrypted and is",
    "start": "2117359",
    "end": "2122560"
  },
  {
    "text": "fully visible in the environment so confidence Computing is a",
    "start": "2122560",
    "end": "2127839"
  },
  {
    "text": "solution for protecting data in use via the use of something called hardware-based trusted execution",
    "start": "2127839",
    "end": "2134079"
  },
  {
    "text": "environments so for key takeaways here it's important to know that tees guarantee the confidentiality and the",
    "start": "2134079",
    "end": "2140680"
  },
  {
    "text": "Integrity of data meaning that nobody can see or tamper with the data and they also guarantee the Integrity of code",
    "start": "2140680",
    "end": "2148000"
  },
  {
    "text": "meaning that nobody can tamper with the code that is running inside of a",
    "start": "2148000",
    "end": "2153880"
  },
  {
    "text": "te so for a little bit more background on a te um essentially they provide an",
    "start": "2154520",
    "end": "2159839"
  },
  {
    "text": "encrypted region of memory that the CPU or the GPU can use so what we've depicted here is a graphic representing",
    "start": "2159839",
    "end": "2166800"
  },
  {
    "text": "a specific implementation of a te called Intel sgx um and the key to tees in",
    "start": "2166800",
    "end": "2172319"
  },
  {
    "text": "general is that they allow you to significantly reduce the size of your trusted Computing base so with Intel sgx",
    "start": "2172319",
    "end": "2178800"
  },
  {
    "text": "the new trusted Computing base is depicted here in blue um and previously you know without a te you would have to",
    "start": "2178800",
    "end": "2185240"
  },
  {
    "text": "trust all the components in red not a template with the memory because the data was just sitting in memory unencrypted so what this means is that",
    "start": "2185240",
    "end": "2192400"
  },
  {
    "text": "you know somebody with root access to the machine for example could just dump the memory while it was um being",
    "start": "2192400",
    "end": "2197960"
  },
  {
    "text": "processed and this would allow them to gain access to whatever data was being operated on but now that the memory is",
    "start": "2197960",
    "end": "2204119"
  },
  {
    "text": "encrypted via a te and only accessible to the components in blue none of the",
    "start": "2204119",
    "end": "2209480"
  },
  {
    "text": "components outlined here in red have the ability to um tamper with or any visibility into um the data that is in",
    "start": "2209480",
    "end": "2215800"
  },
  {
    "text": "memory another very important feature of confidential Computing is remote ad",
    "start": "2215800",
    "end": "2222200"
  },
  {
    "text": "station um so when we say te are testable we basically mean that you can verify that the te Hardware is genuine",
    "start": "2222200",
    "end": "2229480"
  },
  {
    "text": "Hardware um what this means is that it was indeed know the hardware was indeed manufactured by a manufacturer of a te",
    "start": "2229480",
    "end": "2237119"
  },
  {
    "text": "so think Intel think AMD um and also that the code running inside the te is what you expect um so here we can",
    "start": "2237119",
    "end": "2244040"
  },
  {
    "text": "actually perform some cryptography um to verif that the code is the code that um",
    "start": "2244040",
    "end": "2249119"
  },
  {
    "text": "you think it is inside of the te so putting this all together right",
    "start": "2249119",
    "end": "2254920"
  },
  {
    "text": "why do we even care about confidential Computing and what does it enable well first with add a station you can trust",
    "start": "2254920",
    "end": "2260560"
  },
  {
    "text": "that a provider has actually launched a te and that you can and that the te is running code that you",
    "start": "2260560",
    "end": "2267160"
  },
  {
    "text": "expect and additionally you can trust that the provider cannot tamper with the code that is running um and that the",
    "start": "2267160",
    "end": "2273599"
  },
  {
    "text": "provider cannot see or tamper with the data that is being processed within the",
    "start": "2273599",
    "end": "2279119"
  },
  {
    "text": "te Okay cool so how does this apply to um generative Ai and how does it solve",
    "start": "2280359",
    "end": "2285560"
  },
  {
    "text": "um some of the problems that you know we outlined earlier so first let's take a look at",
    "start": "2285560",
    "end": "2291079"
  },
  {
    "text": "the confidential retrieval use case um as we mentioned earlier right it's usually insufficient to have data",
    "start": "2291079",
    "end": "2297319"
  },
  {
    "text": "encrypted only at rest um because the the the uh Vector database provider may be able to see the documents while",
    "start": "2297319",
    "end": "2303640"
  },
  {
    "text": "they're being inserted or while there is some um query being executed on the data within the",
    "start": "2303640",
    "end": "2310119"
  },
  {
    "text": "database so what we can do is we can actually make this retrieval process more private by running the vector",
    "start": "2310119",
    "end": "2315599"
  },
  {
    "text": "database in a confidential Computing environment and running the vector database in a te means that any query",
    "start": "2315599",
    "end": "2321720"
  },
  {
    "text": "execution can operate on confidential data and most importantly that the database provider cannot see any data",
    "start": "2321720",
    "end": "2327839"
  },
  {
    "text": "when it is retrieved so next let's take a look at how confidential Computing can help",
    "start": "2327839",
    "end": "2333520"
  },
  {
    "text": "preserve privacy during model development so again in this case you know we want to train or fine tune a",
    "start": "2333520",
    "end": "2338760"
  },
  {
    "text": "model that is hosted by an external or thirdparty model provider um but imagine",
    "start": "2338760",
    "end": "2343800"
  },
  {
    "text": "here that the data is proprietary so we do not want the provider to see it the solution here is to use",
    "start": "2343800",
    "end": "2349599"
  },
  {
    "text": "confidential Computing to ensure that the provider does not see the data used to train or fine-tune the model so what",
    "start": "2349599",
    "end": "2355880"
  },
  {
    "text": "the workflow will look like here is that the provider can launch a te which enables the data owner to verify that",
    "start": "2355880",
    "end": "2361720"
  },
  {
    "text": "the provider is running the code that they expect and that the provider cannot see or temper with their data",
    "start": "2361720",
    "end": "2367079"
  },
  {
    "text": "the data owner can then trust any data it shares for training or for or for fine-tuning with the model provider um",
    "start": "2367079",
    "end": "2373440"
  },
  {
    "text": "cannot actually be seen by the provider but that the provider is actually using that data to train or fine-tune the",
    "start": "2373440",
    "end": "2381160"
  },
  {
    "text": "model and similarly we can use confidential Computing to protect um both parties and the data during",
    "start": "2381880",
    "end": "2388960"
  },
  {
    "text": "inference so again here the model provider can serve the model in a te",
    "start": "2388960",
    "end": "2394000"
  },
  {
    "text": "meaning that any prompts or queries that the user submits are not viewable by the provider and because the prompts or ques",
    "start": "2394000",
    "end": "2401200"
  },
  {
    "text": "are not viewable by the provider all concerns around data collection around data usage and around data retention go",
    "start": "2401200",
    "end": "2406880"
  },
  {
    "text": "away because the provider cannot even collect the data because it's not visible to the",
    "start": "2406880",
    "end": "2413160"
  },
  {
    "text": "provider so much of the kind of solutions that I uh mentioned in the last couple minutes around confidential",
    "start": "2413160",
    "end": "2418880"
  },
  {
    "text": "Computing uh require a lot of computing power and in particular require GPU for performance uh GPU tees are not yet",
    "start": "2418880",
    "end": "2426560"
  },
  {
    "text": "widely accessible even though Nvidia is kind of working on that and they're supposed to be out by the end of the year so a stepping stone towards private",
    "start": "2426560",
    "end": "2433520"
  },
  {
    "text": "llms is prompt sanitization and this is kind of very similar to what Max mentioned in his talk with what predio",
    "start": "2433520",
    "end": "2439839"
  },
  {
    "text": "does um so here you can imagine that prompt sanitization is essentially a privacy layer that sits between an",
    "start": "2439839",
    "end": "2446440"
  },
  {
    "text": "application and the llm um that removes sensitive information in the prompt before it reaches the llm um and then",
    "start": "2446440",
    "end": "2453000"
  },
  {
    "text": "replaces the sensitive information in the lm's response the key result to this is that the llm",
    "start": "2453000",
    "end": "2460040"
  },
  {
    "text": "no longer saw no longer sees the sensitive information and this this solves the same core issue of um data",
    "start": "2460040",
    "end": "2466599"
  },
  {
    "text": "retention and data collection um and and most importantly",
    "start": "2466599",
    "end": "2472560"
  },
  {
    "text": "here um the sanitization and the Des sanitization will happen in a confidential Computing environment",
    "start": "2472560",
    "end": "2479079"
  },
  {
    "text": "meaning that whoever is hosting the prompt sanitization layer also cannot see the sensitive",
    "start": "2479079",
    "end": "2485240"
  },
  {
    "text": "information so at opaque we have built a product called opaque prompt that does exactly",
    "start": "2485240",
    "end": "2491560"
  },
  {
    "text": "this um and to kind of give a more visual view of what opaque Broms uh does",
    "start": "2491560",
    "end": "2496800"
  },
  {
    "text": "we've created this side-by-side view so here we have kind of two gifs on the left let's first talk about what happens",
    "start": "2496800",
    "end": "2502480"
  },
  {
    "text": "without opaque prompts so in a typical application architecture um so here the llm",
    "start": "2502480",
    "end": "2508119"
  },
  {
    "text": "application May collect some context from a vector database that may contain some sensitive information um so in this",
    "start": "2508119",
    "end": "2513440"
  },
  {
    "text": "example um the user prompt here contains the name Sherlock Holmes as well as Sherlock Holmes's address 221 B Baker",
    "start": "2513440",
    "end": "2521240"
  },
  {
    "text": "Street in London the application then sends the user prompt to the llm so in this case",
    "start": "2521240",
    "end": "2528240"
  },
  {
    "text": "the llm is able to see Sherlock Holmes's name and address and you know like we've all seen the llm will generate a",
    "start": "2528240",
    "end": "2534480"
  },
  {
    "text": "response and to the user query and then return the response to the",
    "start": "2534480",
    "end": "2539280"
  },
  {
    "text": "application so next let's take a look at what will happen with opaque proms in the picture so as before the L",
    "start": "2539640",
    "end": "2545760"
  },
  {
    "text": "application constructs The Prompt um from the context and the user query but with the pink prompts in in the picture",
    "start": "2545760",
    "end": "2551240"
  },
  {
    "text": "now the application will uh securely share the Constructor prompts The Constructor prompt to opaque prompts",
    "start": "2551240",
    "end": "2557400"
  },
  {
    "text": "which again is running in a confidential Computing environment um now opaque prompts will",
    "start": "2557400",
    "end": "2562680"
  },
  {
    "text": "sanitize all the sensitive information out of the prompt so uh similar to you know what Max uh mentioned with Presidio",
    "start": "2562680",
    "end": "2569680"
  },
  {
    "text": "Sherlock holmes' name will be replaced with a placeholder and Sherlock Holmes's address will also be replaced with the",
    "start": "2569680",
    "end": "2575160"
  },
  {
    "text": "placeholder the sanitized prompt then goes to the llm which is now unable to",
    "start": "2575160",
    "end": "2580280"
  },
  {
    "text": "see any sensitive information but because the llm does not rely on the personal information here to generate a",
    "start": "2580280",
    "end": "2587000"
  },
  {
    "text": "response uh the llm will be still be able to generate a logical response which in this case may contain the",
    "start": "2587000",
    "end": "2593400"
  },
  {
    "text": "placeholders the llm then then sends back the uh the sanitized response to",
    "start": "2593400",
    "end": "2599359"
  },
  {
    "text": "opaque prompts which replaces the placeholders with the original sensitive data and Returns the response to the",
    "start": "2599359",
    "end": "2605079"
  },
  {
    "text": "application so importantly here it's it's important to note that the user experience from",
    "start": "2605079",
    "end": "2610760"
  },
  {
    "text": "the application side is exactly the same um as it would be without opaque prompt sending in the middle um so opaque",
    "start": "2610760",
    "end": "2616760"
  },
  {
    "text": "prompt enables this kind of transparent um privacy preservation of the user",
    "start": "2616760",
    "end": "2623640"
  },
  {
    "text": "prompt so that's the end of the deck um so let's quickly go into demo to see um op promps",
    "start": "2624520",
    "end": "2629960"
  },
  {
    "text": "action let me share to a different",
    "start": "2629960",
    "end": "2634559"
  },
  {
    "text": "tab",
    "start": "2635079",
    "end": "2638079"
  },
  {
    "text": "and so here we have the um opaque prompt page um and let's just sign",
    "start": "2644599",
    "end": "2651040"
  },
  {
    "text": "in so we have built a chat application to demo the core functionality of opaque",
    "start": "2651760",
    "end": "2656800"
  },
  {
    "text": "prompts this chat application is actually built with our Lang chain integration uh with opaque prompts which",
    "start": "2656800",
    "end": "2662119"
  },
  {
    "text": "you know we can um share out in a bit um while the application here is what we will demo the main consumption mechanism",
    "start": "2662119",
    "end": "2669240"
  },
  {
    "text": "of op promp is actually VI an API um so if you register to our weight list and get access you'll be able to get an API",
    "start": "2669240",
    "end": "2675680"
  },
  {
    "text": "key that will enable you to integrate opaque promps into your um llm",
    "start": "2675680",
    "end": "2681359"
  },
  {
    "text": "applications okay so um getting back to the demo here um let's say we want to ask some questions um about this um text",
    "start": "2681359",
    "end": "2689400"
  },
  {
    "text": "snippet so this text nippet is a uh snippet of text from a CIA operation um",
    "start": "2689400",
    "end": "2695680"
  },
  {
    "text": "that you know happened in about the 1970s and that involved recovering a",
    "start": "2695680",
    "end": "2701599"
  },
  {
    "text": "sunken Soviet ship um from the middle of the Pacific Ocean let's say we want to um ask you",
    "start": "2701599",
    "end": "2709359"
  },
  {
    "text": "know um a so in this case we have chbt in the background let's say we want to ask um you know uh a question about the",
    "start": "2709359",
    "end": "2716720"
  },
  {
    "text": "snippet so we want to ask what was recovered from the",
    "start": "2716720",
    "end": "2720359"
  },
  {
    "text": "submarine so okay so if you ignore all this stuff um you can see that the um",
    "start": "2722839",
    "end": "2728520"
  },
  {
    "text": "chat bot answered correctly so we asked what was recovered from the submarine and the chat bot correctly answers the",
    "start": "2728520",
    "end": "2733720"
  },
  {
    "text": "contents of the recovered submarine included the bodies of six Soviet submariners um and we can see that it is",
    "start": "2733720",
    "end": "2739280"
  },
  {
    "text": "indeed um the correct answer here and this is pretty cool right it's you know just a normal chap out application but",
    "start": "2739280",
    "end": "2744960"
  },
  {
    "text": "if we look closer in the background we can see that the um that the prompt that",
    "start": "2744960",
    "end": "2752280"
  },
  {
    "text": "was sent to the llm um after opaque prompts process tested actually removes all the sensitive information so in",
    "start": "2752280",
    "end": "2759640"
  },
  {
    "text": "particular here if we're able to compare we can see that the location Long Beach um has been removed the name of the ship",
    "start": "2759640",
    "end": "2766599"
  },
  {
    "text": "has been removed the date that the ship arrived over the recovery site has been removed and other you know personal",
    "start": "2766599",
    "end": "2772880"
  },
  {
    "text": "information for example the name of the uh CIA director as well as the name of",
    "start": "2772880",
    "end": "2778880"
  },
  {
    "text": "the um in this case the Russian president was also removed so this text is exactly what the",
    "start": "2778880",
    "end": "2786079"
  },
  {
    "text": "LM sees and importantly again um the llm does not see any of the",
    "start": "2786079",
    "end": "2791160"
  },
  {
    "text": "pii um even though the LM is not able to see the pii it is still able to",
    "start": "2791160",
    "end": "2796240"
  },
  {
    "text": "successfully respond to the correct answer because it does not need the pii um to do so so next let's ask it another",
    "start": "2796240",
    "end": "2803240"
  },
  {
    "text": "question let's ask it um when did the ship sail over or arrive",
    "start": "2803240",
    "end": "2811400"
  },
  {
    "text": "over the uh recovery site",
    "start": "2811400",
    "end": "2817800"
  },
  {
    "text": "so again the llm is able to respond correctly um and we see um that in fact",
    "start": "2818599",
    "end": "2824280"
  },
  {
    "text": "the LM does not know the pi detail so the underlying pii um on which it",
    "start": "2824280",
    "end": "2829720"
  },
  {
    "text": "responds but with the Chapa application and using opaque prompts we are able to show the user um all of the correct",
    "start": "2829720",
    "end": "2836079"
  },
  {
    "text": "information so we able to replace person three of glomar and date time three with",
    "start": "2836079",
    "end": "2841240"
  },
  {
    "text": "July 4th 1974 um so yeah that's that's a bit of a",
    "start": "2841240",
    "end": "2846559"
  },
  {
    "text": "demo um of what op promps can do um and yeah that's the end of um the talk thank",
    "start": "2846559",
    "end": "2852119"
  },
  {
    "text": "you so much for listening awesome all right so uh okay I",
    "start": "2852119",
    "end": "2860359"
  },
  {
    "text": "see some I see some questions coming in so we'll spend the next 10 minutes kind of taking a bunch of these questions so please if you can drop them in the QA",
    "start": "2860359",
    "end": "2867079"
  },
  {
    "text": "box on the right although I also see some um in in in the chat um and so yeah",
    "start": "2867079",
    "end": "2873760"
  },
  {
    "text": "maybe I'll take the two in the chat first but then again let's go let's try to go to the QA box in the right um",
    "start": "2873760",
    "end": "2879440"
  },
  {
    "text": "first question is basically like what guarantees can you provide that sensitive data will be masked um and so",
    "start": "2879440",
    "end": "2885800"
  },
  {
    "text": "I don't know maybe both of you can kind of like take this from your end both them what you've seen maybe maybe Chester you can start because you're",
    "start": "2885800",
    "end": "2891480"
  },
  {
    "text": "kind of offering more of a service for this right so what guarantees do you guys have yeah sure sure so we use some",
    "start": "2891480",
    "end": "2898000"
  },
  {
    "text": "machine learning in the background um to kind of provide these guarantees of course this will not be 100% perfect um",
    "start": "2898000",
    "end": "2905040"
  },
  {
    "text": "to be completely Frank um we are always kind of working on improving the accuracy of the model",
    "start": "2905040",
    "end": "2911599"
  },
  {
    "text": "um because we know that it's critically important right that the sensor data will be masked um but it's you know",
    "start": "2911599",
    "end": "2916960"
  },
  {
    "text": "because we're using machine learning it's very difficult to kind of get um 100% um accuracy and as a result of that",
    "start": "2916960",
    "end": "2922680"
  },
  {
    "text": "we've kind of seen that you know it's important to do some kind of trial runs at the beginning um to make sure that we can you know tune the um model",
    "start": "2922680",
    "end": "2930079"
  },
  {
    "text": "specifically to each individual use case cool yeah Max do you have anything",
    "start": "2930079",
    "end": "2935760"
  },
  {
    "text": "to add for this around presidia uh yeah I mean I I read some paper like I think it has like two years",
    "start": "2935760",
    "end": "2942520"
  },
  {
    "text": "or something like that so they measured the recall of Presidio uh like you know",
    "start": "2942520",
    "end": "2948880"
  },
  {
    "text": "just this default uh operators and recognizers and I remember it was something about 85% so it's from one one",
    "start": "2948880",
    "end": "2957119"
  },
  {
    "text": "side it's a lot from other side it's still 15% of uh nonprotected data so I",
    "start": "2957119",
    "end": "2964119"
  },
  {
    "text": "guess as I said it it's depends on the data so it's very important to not leave",
    "start": "2964119",
    "end": "2969160"
  },
  {
    "text": "it like that so as as with default recognizers but to add your own and to H",
    "start": "2969160",
    "end": "2974760"
  },
  {
    "text": "check it so it should be checked by human uh before we can put it in the production and still it's like uh when",
    "start": "2974760",
    "end": "2981799"
  },
  {
    "text": "we don't have 100% uh you know probability of uh all this Pi being",
    "start": "2981799",
    "end": "2987839"
  },
  {
    "text": "masked then still we need a consent from user that we need to uh we are taking",
    "start": "2987839",
    "end": "2994799"
  },
  {
    "text": "your data there is some part some threshold that we you know provide you",
    "start": "2994799",
    "end": "3000640"
  },
  {
    "text": "that the data will be protected but still I mean we need a consent or it",
    "start": "3000640",
    "end": "3006240"
  },
  {
    "text": "will not be it will be against some policies you know also add here that you know if you do want 100% accuracy that",
    "start": "3006240",
    "end": "3013920"
  },
  {
    "text": "you know the Sens of data cannot be seen um I think confidential Computing is actually a great solution here right because anything that you put into the",
    "start": "3013920",
    "end": "3021160"
  },
  {
    "text": "um te is guaranteed to be not visible um to whoever is running the um be",
    "start": "3021160",
    "end": "3028799"
  },
  {
    "text": "application cool so so I see one question in the chat and one question in the QA that are basically the same and",
    "start": "3028799",
    "end": "3034720"
  },
  {
    "text": "it's like do we have any way of distinguishing if pii is relevant to the query for example let's say George",
    "start": "3034720",
    "end": "3040119"
  },
  {
    "text": "Washington was mentioned in the query and it would be better to send that pii directly um or I think the other example",
    "start": "3040119",
    "end": "3045839"
  },
  {
    "text": "in the chat is if I ask for uh you know things to do close to this town like that town is a place or something if",
    "start": "3045839",
    "end": "3051839"
  },
  {
    "text": "that's considered but like yeah is there any distinction between that's relevant and not relevant and how do you think",
    "start": "3051839",
    "end": "3057920"
  },
  {
    "text": "about that how do people generally approach this and I know I asked this you a little bit about this Max earlier but be curious for Chesters take on and",
    "start": "3057920",
    "end": "3064559"
  },
  {
    "text": "then anything else that that you'd have that yeah so we've we've actually heard this a lot um from a number of different",
    "start": "3064559",
    "end": "3071280"
  },
  {
    "text": "um conversations that we've had so as an example right I think we spoke to a manufacturing company that mentioned",
    "start": "3071280",
    "end": "3076640"
  },
  {
    "text": "that you know some there's some you know manufacturing data or manufacturing terms that are very specific to that field um that you would normally not",
    "start": "3076640",
    "end": "3083720"
  },
  {
    "text": "deem as sensitive or as pii um but you know we'll need some way to kind of distinguish um those keywords in",
    "start": "3083720",
    "end": "3090839"
  },
  {
    "text": "a specific context and for specific customers um as opposed to in the kind of generalizable case um so our answer",
    "start": "3090839",
    "end": "3097680"
  },
  {
    "text": "to that right is that first I think the the key feature is that we need to provide some kind of configurable way so I think you know Max from your Presidio",
    "start": "3097680",
    "end": "3104720"
  },
  {
    "text": "kind of a custom thing you also offer kind of a feature um to enable this but we need to provide some kind of",
    "start": "3104720",
    "end": "3110079"
  },
  {
    "text": "customizable um mechanism to enable users to really Define what is sensitive in their their case um and then on the",
    "start": "3110079",
    "end": "3117640"
  },
  {
    "text": "technical side in the in the background right I think the kind of key there is we'll need to almost use like an LM and",
    "start": "3117640",
    "end": "3123680"
  },
  {
    "text": "finding the LM such that it can identify specific um terms and specific",
    "start": "3123680",
    "end": "3130558"
  },
  {
    "text": "categories right so from my side uh I mentioned named entity recognition uh",
    "start": "3131079",
    "end": "3136680"
  },
  {
    "text": "models before so like the basic implementation is pres in presidia is all about Spacey models so they are like",
    "start": "3136680",
    "end": "3143680"
  },
  {
    "text": "really small models and uh and it's all about you know uh recognizing all these",
    "start": "3143680",
    "end": "3148839"
  },
  {
    "text": "named entities and if we would like to we can for example train a Transformer based on our data and U you know Mark in",
    "start": "3148839",
    "end": "3158319"
  },
  {
    "text": "in our data set we can Mark George Washington as not pii and for example",
    "start": "3158319",
    "end": "3163400"
  },
  {
    "text": "maxan as pii and maybe that way based on your data the model can be trained to",
    "start": "3163400",
    "end": "3170799"
  },
  {
    "text": "recognize the the good entities and another thing um I think it's important",
    "start": "3170799",
    "end": "3176480"
  },
  {
    "text": "is that uh when we have a question about George Washington and we have a system QA system that uh you know needs to",
    "start": "3176480",
    "end": "3183880"
  },
  {
    "text": "answer the question based on the context then you know it should be based on the context so we don't want the system to",
    "start": "3183880",
    "end": "3190040"
  },
  {
    "text": "answer the general knowledge uh information so so it's not like a quiz",
    "start": "3190040",
    "end": "3195480"
  },
  {
    "text": "of general knowledge it's a you know question answering about our documents so I guess if it will be anonymized and",
    "start": "3195480",
    "end": "3203040"
  },
  {
    "text": "then restored uh then everything should work perfectly so if we have George Washington in our text then it should",
    "start": "3203040",
    "end": "3209640"
  },
  {
    "text": "work smoothly um let me find um all right so",
    "start": "3209640",
    "end": "3218760"
  },
  {
    "text": "this is a bit of a longer uh question but basically it seems like there's two different threat vectors that were",
    "start": "3218760",
    "end": "3224680"
  },
  {
    "text": "attacked here one preventing llms from outputting sensitive data which might be Laten in kind of like the training via",
    "start": "3224680",
    "end": "3231040"
  },
  {
    "text": "scrubbing PI from query's outputs through Pro postprocessing and then the other would be preventing kind of like",
    "start": "3231040",
    "end": "3236599"
  },
  {
    "text": "third party model providers from learning about customer uh from customer sensitive data um through tees are there",
    "start": "3236599",
    "end": "3242880"
  },
  {
    "text": "other like just in general if we think about the general problem of kind of like data privacy for llm applications",
    "start": "3242880",
    "end": "3248079"
  },
  {
    "text": "are there other like issues or threat models that we didn't spend a lot of time talking about that you think are",
    "start": "3248079",
    "end": "3253319"
  },
  {
    "text": "interesting or relevant to highlight to folks specifically like PR around data",
    "start": "3253319",
    "end": "3259760"
  },
  {
    "text": "privacy or are the topics that we covered today this is what you spend 90 99.9% of your time talking with",
    "start": "3261400",
    "end": "3267200"
  },
  {
    "text": "customers about and and and addressing their data privacy concerns yeah sorry okay uh yeah this",
    "start": "3267200",
    "end": "3274240"
  },
  {
    "text": "this is generally kind of what we've seen um we've kind of seen the the main kind of um threat model be that they do",
    "start": "3274240",
    "end": "3280359"
  },
  {
    "text": "not necessarily trust the provider whether that be the LM provider or like the vector datab provider or something",
    "start": "3280359",
    "end": "3286119"
  },
  {
    "text": "else um or even the cloud um so interestingly right we've actually had",
    "start": "3286119",
    "end": "3291520"
  },
  {
    "text": "some conversations with some of the big Banks and what they shared is is that not only do they want to run the llms on",
    "start": "3291520",
    "end": "3299040"
  },
  {
    "text": "Prem or in their own trusted environment but they also want to run llms in on",
    "start": "3299040",
    "end": "3304480"
  },
  {
    "text": "Prem in the confidential Computing environment um so they have kind of that stringent privacy constraints that they",
    "start": "3304480",
    "end": "3312160"
  },
  {
    "text": "do not even trust their own kind of uh admins or their own employees um to I guess not Peak at the",
    "start": "3312160",
    "end": "3320359"
  },
  {
    "text": "data that is been processed even in their own data centers",
    "start": "3320359",
    "end": "3327000"
  },
  {
    "text": "I don't think I have anything else to add I mean I uh I was mentioning prompt",
    "start": "3328000",
    "end": "3333920"
  },
  {
    "text": "injection but I guess it's part of this question so it's uh all about you know",
    "start": "3333920",
    "end": "3339920"
  },
  {
    "text": "LM memorizing and stuff cool oh actually I have something",
    "start": "3339920",
    "end": "3345799"
  },
  {
    "text": "else to add here if if that's cool yeah I mean this yeah we'll maybe use this as final comments as well for anything that",
    "start": "3345799",
    "end": "3351839"
  },
  {
    "text": "people want to add before yeah yeah yeah sure um so this is I I think a little bit more of a an academic perspective",
    "start": "3351839",
    "end": "3358240"
  },
  {
    "text": "right but I can imagine that in the future right um if you want like a very very low Laten so you're a very very",
    "start": "3358240",
    "end": "3364160"
  },
  {
    "text": "kind of real-time use case that you may actually want to push the model into um",
    "start": "3364160",
    "end": "3369920"
  },
  {
    "text": "the customer environment itself such that the kind of network communication is much shorter um what that means I",
    "start": "3369920",
    "end": "3375359"
  },
  {
    "text": "might have gone over this a little bit in my talk is that we'll actually need the model provider to share the model",
    "start": "3375359",
    "end": "3381240"
  },
  {
    "text": "with the customer and um because the model itself is very very private right the model provider has spent invested a",
    "start": "3381240",
    "end": "3388839"
  },
  {
    "text": "lot of capital into developing the model they absolutely do not want the customer to see the model weights um so you can",
    "start": "3388839",
    "end": "3395119"
  },
  {
    "text": "imagine here that in if you want to share the model it's actually the customer that is considered the threat",
    "start": "3395119",
    "end": "3400200"
  },
  {
    "text": "in in the threat model case and the customer has to be um has to not be",
    "start": "3400200",
    "end": "3405880"
  },
  {
    "text": "allowed cryptographically to see the model that is running in their",
    "start": "3405880",
    "end": "3411200"
  },
  {
    "text": "environment all right well we're out of time so I wanted to thank you both again for for",
    "start": "3413880",
    "end": "3420000"
  },
  {
    "text": "joining and thank you everyone for tuning in again this we we'll post the um we'll post the a recording of this um",
    "start": "3420000",
    "end": "3427079"
  },
  {
    "text": "shortly I think there was a lot of good insights here I think this is a a thorny subject but hopefully now we have some",
    "start": "3427079",
    "end": "3432880"
  },
  {
    "text": "uh good good material to to go off of so thank you guys for joining um really appreciate it yeah thanks thanks all",
    "start": "3432880",
    "end": "3440760"
  },
  {
    "text": "yeah bye bye",
    "start": "3440760",
    "end": "3446799"
  }
]
[
  {
    "start": "0",
    "end": "167000"
  },
  {
    "text": "hi this is Lance from Lang chain team",
    "start": "2040",
    "end": "4640"
  },
  {
    "text": "I'm going to talk about building a",
    "start": "4640",
    "end": "7559"
  },
  {
    "text": "self-reflective rag apps from scratch",
    "start": "7559",
    "end": "10679"
  },
  {
    "text": "using only open source and local models",
    "start": "10679",
    "end": "13839"
  },
  {
    "text": "um that run strictly on my",
    "start": "13839",
    "end": "16840"
  },
  {
    "text": "laptop now one of the most interesting",
    "start": "16840",
    "end": "20080"
  },
  {
    "text": "Trends in the rag research and a lot of",
    "start": "20080",
    "end": "23880"
  },
  {
    "text": "like methods that become pretty popular",
    "start": "23880",
    "end": "25560"
  },
  {
    "text": "in recent U months and weeks is this",
    "start": "25560",
    "end": "28679"
  },
  {
    "text": "idea of self-reflection",
    "start": "28679",
    "end": "30840"
  },
  {
    "text": "so when you do rag you perform retrieval",
    "start": "30840",
    "end": "33559"
  },
  {
    "text": "based upon a question from an index and",
    "start": "33559",
    "end": "36480"
  },
  {
    "text": "this idea of self-reflection is saying",
    "start": "36480",
    "end": "39480"
  },
  {
    "text": "based upon for example the relevance of",
    "start": "39480",
    "end": "41399"
  },
  {
    "text": "the retriev documents to my question or",
    "start": "41399",
    "end": "44039"
  },
  {
    "text": "based upon you know the quality the",
    "start": "44039",
    "end": "46199"
  },
  {
    "text": "generations relative to my question or",
    "start": "46199",
    "end": "48600"
  },
  {
    "text": "the generations relative to the",
    "start": "48600",
    "end": "50440"
  },
  {
    "text": "documents I want to make I want to",
    "start": "50440",
    "end": "52760"
  },
  {
    "text": "perform some kind of reasoning and",
    "start": "52760",
    "end": "54840"
  },
  {
    "text": "potentially feed back and retry various",
    "start": "54840",
    "end": "57239"
  },
  {
    "text": "steps so that's kind of the big idea and",
    "start": "57239",
    "end": "59600"
  },
  {
    "text": "there's a there's a few really",
    "start": "59600",
    "end": "60680"
  },
  {
    "text": "interesting papers that implement this",
    "start": "60680",
    "end": "63960"
  },
  {
    "text": "and what I want to kind of show is that",
    "start": "63960",
    "end": "67600"
  },
  {
    "text": "implementing these ideas using something",
    "start": "67600",
    "end": "71200"
  },
  {
    "text": "that we've developed recently called",
    "start": "71200",
    "end": "73360"
  },
  {
    "text": "langra is a really nice approach um and",
    "start": "73360",
    "end": "77200"
  },
  {
    "text": "it works really well with local llms",
    "start": "77200",
    "end": "79600"
  },
  {
    "text": "that are much smaller for example than",
    "start": "79600",
    "end": "81600"
  },
  {
    "text": "you know API uh gated very large scale",
    "start": "81600",
    "end": "85479"
  },
  {
    "text": "Foundation",
    "start": "85479",
    "end": "87040"
  },
  {
    "text": "models um and so we're going to look at",
    "start": "87040",
    "end": "90079"
  },
  {
    "text": "particular paper called corrective rag",
    "start": "90079",
    "end": "92600"
  },
  {
    "text": "or C rag now this paper is kind of um",
    "start": "92600",
    "end": "96920"
  },
  {
    "text": "there's been some attention on for",
    "start": "96920",
    "end": "98960"
  },
  {
    "text": "example Twitter about this work uh it's",
    "start": "98960",
    "end": "101600"
  },
  {
    "text": "a really neat",
    "start": "101600",
    "end": "102880"
  },
  {
    "text": "paper and the idea is actually pretty",
    "start": "102880",
    "end": "105439"
  },
  {
    "text": "simple and straightforward if you go",
    "start": "105439",
    "end": "107600"
  },
  {
    "text": "down to the figure",
    "start": "107600",
    "end": "108960"
  },
  {
    "text": "here you're going to do perform",
    "start": "108960",
    "end": "112280"
  },
  {
    "text": "retrieval and you're going to grade the",
    "start": "112280",
    "end": "114880"
  },
  {
    "text": "documents relative to the the question",
    "start": "114880",
    "end": "117600"
  },
  {
    "text": "so you're kind of doing a relevance",
    "start": "117600",
    "end": "119000"
  },
  {
    "text": "grading",
    "start": "119000",
    "end": "120439"
  },
  {
    "text": "and there's some theistic like basically",
    "start": "120439",
    "end": "122719"
  },
  {
    "text": "if the documents are deemed correct they",
    "start": "122719",
    "end": "125560"
  },
  {
    "text": "actually do some uh knowledge refinement",
    "start": "125560",
    "end": "128200"
  },
  {
    "text": "where they further strip the documents",
    "start": "128200",
    "end": "130840"
  },
  {
    "text": "to compress relevant chunks within the",
    "start": "130840",
    "end": "133400"
  },
  {
    "text": "documents and retain them um and if the",
    "start": "133400",
    "end": "137440"
  },
  {
    "text": "documents are either deemed ambiguous",
    "start": "137440",
    "end": "139319"
  },
  {
    "text": "relative to the query or incorrect it",
    "start": "139319",
    "end": "142280"
  },
  {
    "text": "performs a web search and supplements",
    "start": "142280",
    "end": "144840"
  },
  {
    "text": "retrieval with the Webster so that's",
    "start": "144840",
    "end": "146280"
  },
  {
    "text": "kind of the big idea but it's a nice",
    "start": "146280",
    "end": "148480"
  },
  {
    "text": "illustration of this General principle",
    "start": "148480",
    "end": "150480"
  },
  {
    "text": "of don't just do rag as kind of like a",
    "start": "150480",
    "end": "153480"
  },
  {
    "text": "you know a singleshot process where you",
    "start": "153480",
    "end": "155440"
  },
  {
    "text": "perform retrieval and then go to",
    "start": "155440",
    "end": "156640"
  },
  {
    "text": "generation you can actually perform",
    "start": "156640",
    "end": "158440"
  },
  {
    "text": "self-reflection and reasoning you can",
    "start": "158440",
    "end": "160640"
  },
  {
    "text": "retry you can uh retrieve from",
    "start": "160640",
    "end": "163120"
  },
  {
    "text": "alternative sources and so forth that's",
    "start": "163120",
    "end": "165319"
  },
  {
    "text": "kind of the big",
    "start": "165319",
    "end": "167080"
  },
  {
    "start": "167000",
    "end": "535000"
  },
  {
    "text": "idea now in our build here we're going",
    "start": "167080",
    "end": "169879"
  },
  {
    "text": "to make some minor simplifications um",
    "start": "169879",
    "end": "173000"
  },
  {
    "text": "here's kind of a layout of the graph",
    "start": "173000",
    "end": "175000"
  },
  {
    "text": "that we're interested in we're going to",
    "start": "175000",
    "end": "177360"
  },
  {
    "text": "perform retrieval and for that we're",
    "start": "177360",
    "end": "179120"
  },
  {
    "text": "going to use no embeddings which run",
    "start": "179120",
    "end": "181760"
  },
  {
    "text": "locally um we're going to build a node",
    "start": "181760",
    "end": "183879"
  },
  {
    "text": "for grading those documents relative to",
    "start": "183879",
    "end": "186360"
  },
  {
    "text": "the question to say are they relevant or",
    "start": "186360",
    "end": "188400"
  },
  {
    "text": "not and if any documents are deemed",
    "start": "188400",
    "end": "191959"
  },
  {
    "text": "irrelevant we'll go ahead and do a query",
    "start": "191959",
    "end": "194360"
  },
  {
    "text": "rewrite web search and we'll s go ahead",
    "start": "194360",
    "end": "197680"
  },
  {
    "text": "to generation based upon the web search",
    "start": "197680",
    "end": "199720"
  },
  {
    "text": "results so that's the",
    "start": "199720",
    "end": "201319"
  },
  {
    "text": "flow now first things first is how do I",
    "start": "201319",
    "end": "205599"
  },
  {
    "text": "get started running LMS locally and and",
    "start": "205599",
    "end": "208159"
  },
  {
    "text": "kind of where do I go and where I often",
    "start": "208159",
    "end": "210879"
  },
  {
    "text": "direct people and what I found to be",
    "start": "210879",
    "end": "212640"
  },
  {
    "text": "really useful is",
    "start": "212640",
    "end": "214879"
  },
  {
    "text": "AMA um it is a really nice way to run",
    "start": "214879",
    "end": "218840"
  },
  {
    "text": "models locally uh for example on your",
    "start": "218840",
    "end": "221000"
  },
  {
    "text": "Mac laptop very easily and they are",
    "start": "221000",
    "end": "222920"
  },
  {
    "text": "launching support for various other",
    "start": "222920",
    "end": "224519"
  },
  {
    "text": "platforms as well um and so basically if",
    "start": "224519",
    "end": "227879"
  },
  {
    "text": "you go to their website it's very simple",
    "start": "227879",
    "end": "229680"
  },
  {
    "text": "you simply download their application um",
    "start": "229680",
    "end": "232079"
  },
  {
    "text": "you can see it's running here on my",
    "start": "232079",
    "end": "234280"
  },
  {
    "text": "machine um and once you have it",
    "start": "234280",
    "end": "238239"
  },
  {
    "text": "downloaded you all you need to do is you",
    "start": "238239",
    "end": "241360"
  },
  {
    "text": "can go to their model list and you can",
    "start": "241360",
    "end": "243959"
  },
  {
    "text": "kind of search around so you can",
    "start": "243959",
    "end": "246159"
  },
  {
    "text": "actually look I think it's sorted by",
    "start": "246159",
    "end": "247640"
  },
  {
    "text": "popularity so you can see mraw obviously",
    "start": "247640",
    "end": "249560"
  },
  {
    "text": "a really interesting open source model",
    "start": "249560",
    "end": "252319"
  },
  {
    "text": "um is kind of one of the top so you can",
    "start": "252319",
    "end": "255400"
  },
  {
    "text": "see it has like 210,000 polls it's one",
    "start": "255400",
    "end": "258120"
  },
  {
    "text": "of the top models I click on this and",
    "start": "258120",
    "end": "261359"
  },
  {
    "text": "where this takes me is a model page I",
    "start": "261359",
    "end": "263880"
  },
  {
    "text": "can look at this",
    "start": "263880",
    "end": "265199"
  },
  {
    "text": "tags uh Tab and this basically shows me",
    "start": "265199",
    "end": "270000"
  },
  {
    "text": "um a bunch of model versions that I can",
    "start": "270000",
    "end": "272919"
  },
  {
    "text": "really easily uh just like download and",
    "start": "272919",
    "end": "275440"
  },
  {
    "text": "run and we'll we'll show how to do that",
    "start": "275440",
    "end": "277440"
  },
  {
    "text": "here very",
    "start": "277440",
    "end": "278840"
  },
  {
    "text": "shortly um what I'm going to do is I'm",
    "start": "278840",
    "end": "282759"
  },
  {
    "text": "going to choose mrol instruct so that is",
    "start": "282759",
    "end": "285520"
  },
  {
    "text": "their 7 billion uh parameter instruct",
    "start": "285520",
    "end": "288320"
  },
  {
    "text": "model and so all I would do I'm going to",
    "start": "288320",
    "end": "290880"
  },
  {
    "text": "go over to my notebook",
    "start": "290880",
    "end": "292680"
  },
  {
    "text": "here so I have an empty notebook and all",
    "start": "292680",
    "end": "296520"
  },
  {
    "text": "I've done is I've already uh done a few",
    "start": "296520",
    "end": "298520"
  },
  {
    "text": "pip installs",
    "start": "298520",
    "end": "300199"
  },
  {
    "text": "and I've also set uh a few environment",
    "start": "300199",
    "end": "303280"
  },
  {
    "text": "variables to use Langs Smith and we'll",
    "start": "303280",
    "end": "304960"
  },
  {
    "text": "see why that's useful later that's",
    "start": "304960",
    "end": "307240"
  },
  {
    "text": "really all I've",
    "start": "307240",
    "end": "308639"
  },
  {
    "text": "done now I'm going to put a note here to",
    "start": "308639",
    "end": "313479"
  },
  {
    "text": "uh for",
    "start": "313479",
    "end": "315600"
  },
  {
    "text": "olama and what I'm going to do is this",
    "start": "315600",
    "end": "318960"
  },
  {
    "text": "AMA pull the model I want and you just",
    "start": "318960",
    "end": "322160"
  },
  {
    "text": "run",
    "start": "322160",
    "end": "323080"
  },
  {
    "text": "that so normally this will take a little",
    "start": "323080",
    "end": "326160"
  },
  {
    "text": "bit because you're actually pulling the",
    "start": "326160",
    "end": "327560"
  },
  {
    "text": "model and typically it's like a couple",
    "start": "327560",
    "end": "329639"
  },
  {
    "text": "gigs I actually already have this model",
    "start": "329639",
    "end": "331600"
  },
  {
    "text": "so it's faster um it's actually already",
    "start": "331600",
    "end": "334080"
  },
  {
    "text": "done but that's really all you do okay",
    "start": "334080",
    "end": "336560"
  },
  {
    "text": "so that's kind of like step one and then",
    "start": "336560",
    "end": "339240"
  },
  {
    "text": "what we're going to do is I'm just going",
    "start": "339240",
    "end": "340759"
  },
  {
    "text": "to create this variable local",
    "start": "340759",
    "end": "343280"
  },
  {
    "text": "llm",
    "start": "343280",
    "end": "346080"
  },
  {
    "text": "um that I am going to yeah so I'm just",
    "start": "346080",
    "end": "350960"
  },
  {
    "text": "going to Define this variable Mr all",
    "start": "350960",
    "end": "352840"
  },
  {
    "text": "instruct because this is the model that",
    "start": "352840",
    "end": "354919"
  },
  {
    "text": "I download using a llama pull miston",
    "start": "354919",
    "end": "357039"
  },
  {
    "text": "struct that's all that's going on here",
    "start": "357039",
    "end": "359080"
  },
  {
    "text": "so this is be the llm I'm going to work",
    "start": "359080",
    "end": "360680"
  },
  {
    "text": "with I've pulled this so it's local on",
    "start": "360680",
    "end": "362840"
  },
  {
    "text": "my system it's available V Lama which is",
    "start": "362840",
    "end": "364880"
  },
  {
    "text": "basically running in the background on",
    "start": "364880",
    "end": "366240"
  },
  {
    "text": "my system and you can see is really",
    "start": "366240",
    "end": "368360"
  },
  {
    "text": "seamless and easy to",
    "start": "368360",
    "end": "370240"
  },
  {
    "text": "use now the first thing I want to do for",
    "start": "370240",
    "end": "374280"
  },
  {
    "text": "this approach is I'm going to call this",
    "start": "374280",
    "end": "377880"
  },
  {
    "text": "um",
    "start": "377880",
    "end": "379360"
  },
  {
    "text": "index so because this was a corrective",
    "start": "379360",
    "end": "384000"
  },
  {
    "text": "rag approach I need an index that I care",
    "start": "384000",
    "end": "386960"
  },
  {
    "text": "about that I'm actually performing rag",
    "start": "386960",
    "end": "388280"
  },
  {
    "text": "on and so here I'm going to use uh a",
    "start": "388280",
    "end": "392280"
  },
  {
    "text": "particular blog post that I like on",
    "start": "392280",
    "end": "395120"
  },
  {
    "text": "agents and we can like pull it up here",
    "start": "395120",
    "end": "397319"
  },
  {
    "text": "and have a look let pull it up over here",
    "start": "397319",
    "end": "400560"
  },
  {
    "text": "actually so this is a pretty neat blog",
    "start": "400560",
    "end": "402960"
  },
  {
    "text": "post on autonomous agents it's like",
    "start": "402960",
    "end": "405000"
  },
  {
    "text": "pretty long and mey so it's kind of like",
    "start": "405000",
    "end": "406880"
  },
  {
    "text": "a good Target for performing retrieval",
    "start": "406880",
    "end": "409000"
  },
  {
    "text": "on lots of details here uh really neat",
    "start": "409000",
    "end": "412080"
  },
  {
    "text": "really detailed blog post so what I'm",
    "start": "412080",
    "end": "415000"
  },
  {
    "text": "going to do is I'm going to load it here",
    "start": "415000",
    "end": "419680"
  },
  {
    "text": "I'm going to split it and I'm going to",
    "start": "419680",
    "end": "421160"
  },
  {
    "text": "use a chunk size of 500 tokens um these",
    "start": "421160",
    "end": "424080"
  },
  {
    "text": "are kind of somewhat arbitrary",
    "start": "424080",
    "end": "425759"
  },
  {
    "text": "parameters you can play with these as",
    "start": "425759",
    "end": "427120"
  },
  {
    "text": "you want the point is here I'm just B",
    "start": "427120",
    "end": "428919"
  },
  {
    "text": "building a a quick local index um so I",
    "start": "428919",
    "end": "432280"
  },
  {
    "text": "load it I split it into chunks now this",
    "start": "432280",
    "end": "435759"
  },
  {
    "text": "is the interesting bit I'm going to use",
    "start": "435759",
    "end": "437319"
  },
  {
    "text": "GPT for all embeddings from nomic which",
    "start": "437319",
    "end": "440319"
  },
  {
    "text": "is let's actually pull up the link here",
    "start": "440319",
    "end": "442759"
  },
  {
    "text": "I had it available here so",
    "start": "442759",
    "end": "446919"
  },
  {
    "text": "these are um you can see right here it",
    "start": "446919",
    "end": "451759"
  },
  {
    "text": "is a CPU uh CPU optimized cont",
    "start": "451759",
    "end": "455520"
  },
  {
    "text": "contrastively trained s basically eser",
    "start": "455520",
    "end": "458560"
  },
  {
    "text": "model um so you can like drill into",
    "start": "458560",
    "end": "460639"
  },
  {
    "text": "sentence Transformers so you can see um",
    "start": "460639",
    "end": "464520"
  },
  {
    "text": "yep so there it is the initial work is",
    "start": "464520",
    "end": "466720"
  },
  {
    "text": "described in our paper espert basically",
    "start": "466720",
    "end": "469560"
  },
  {
    "text": "so the key point is this this is a",
    "start": "469560",
    "end": "472360"
  },
  {
    "text": "locally running CPU optimized embedding",
    "start": "472360",
    "end": "474599"
  },
  {
    "text": "model that works quite well I found um",
    "start": "474599",
    "end": "477759"
  },
  {
    "text": "runs on your system no AP I nothing so",
    "start": "477759",
    "end": "480400"
  },
  {
    "text": "it's pretty nice runs fast so we're",
    "start": "480400",
    "end": "482759"
  },
  {
    "text": "going to go ahead and use that um from",
    "start": "482759",
    "end": "485280"
  },
  {
    "text": "our friends at",
    "start": "485280",
    "end": "486479"
  },
  {
    "text": "nomic and I'm also going to use chroma",
    "start": "486479",
    "end": "488879"
  },
  {
    "text": "which is an open source local Vector",
    "start": "488879",
    "end": "490520"
  },
  {
    "text": "store that's really easy to spin up runs",
    "start": "490520",
    "end": "492560"
  },
  {
    "text": "locally and all I'm doing is I'm taking",
    "start": "492560",
    "end": "494840"
  },
  {
    "text": "my documents um I'm going to define a",
    "start": "494840",
    "end": "497319"
  },
  {
    "text": "new collection taking my embedding model",
    "start": "497319",
    "end": "499599"
  },
  {
    "text": "GPD for all embeddings I'm going to",
    "start": "499599",
    "end": "500960"
  },
  {
    "text": "create a retriever from this so there we",
    "start": "500960",
    "end": "503919"
  },
  {
    "text": "go okay it shows you some uh you some",
    "start": "503919",
    "end": "507080"
  },
  {
    "text": "parameters so cool I have a retri so we",
    "start": "507080",
    "end": "509919"
  },
  {
    "text": "can actually call we can say get",
    "start": "509919",
    "end": "511520"
  },
  {
    "text": "relevant",
    "start": "511520",
    "end": "512518"
  },
  {
    "text": "documents um and I can say something",
    "start": "512519",
    "end": "514760"
  },
  {
    "text": "about like um let's say like agent",
    "start": "514760",
    "end": "517839"
  },
  {
    "text": "memory or something you know let's just",
    "start": "517839",
    "end": "520039"
  },
  {
    "text": "test and okay cool look at that so it's",
    "start": "520039",
    "end": "521800"
  },
  {
    "text": "nice and quick we get a bunch of",
    "start": "521800",
    "end": "523399"
  },
  {
    "text": "documents out that relate to memory so",
    "start": "523399",
    "end": "525160"
  },
  {
    "text": "yeah you can see memory stream like the",
    "start": "525160",
    "end": "527760"
  },
  {
    "text": "documents are are sayane so it looks",
    "start": "527760",
    "end": "529880"
  },
  {
    "text": "like everything's kind of working here",
    "start": "529880",
    "end": "531399"
  },
  {
    "text": "so that's great we have a",
    "start": "531399",
    "end": "533640"
  },
  {
    "text": "retriever",
    "start": "533640",
    "end": "535200"
  },
  {
    "start": "535000",
    "end": "670000"
  },
  {
    "text": "now let's think a little bit about what",
    "start": "535200",
    "end": "538440"
  },
  {
    "text": "we want to do next next so when I do",
    "start": "538440",
    "end": "541680"
  },
  {
    "text": "these kinds of uh kind of logical rag",
    "start": "541680",
    "end": "545279"
  },
  {
    "text": "flows but as graphs first I always try",
    "start": "545279",
    "end": "548800"
  },
  {
    "text": "to lay out the",
    "start": "548800",
    "end": "551360"
  },
  {
    "text": "logic and um let me move this up here I",
    "start": "551360",
    "end": "556360"
  },
  {
    "text": "try to lay out kind of The Logical",
    "start": "556360",
    "end": "559399"
  },
  {
    "text": "steps um and in each logical",
    "start": "559399",
    "end": "563760"
  },
  {
    "text": "step what's happening is I'm",
    "start": "563760",
    "end": "566519"
  },
  {
    "text": "transforming state so in these Gra",
    "start": "566519",
    "end": "569519"
  },
  {
    "text": "really all you're doing is you're",
    "start": "569519",
    "end": "570560"
  },
  {
    "text": "defining a stake that you're just",
    "start": "570560",
    "end": "572920"
  },
  {
    "text": "modifying throughout the flow of the",
    "start": "572920",
    "end": "574959"
  },
  {
    "text": "graph now in this case because we're",
    "start": "574959",
    "end": "578360"
  },
  {
    "text": "we're interested in rag our state is",
    "start": "578360",
    "end": "580800"
  },
  {
    "text": "just going to be a dictionary and that",
    "start": "580800",
    "end": "582360"
  },
  {
    "text": "dictionary you can see I actually kind",
    "start": "582360",
    "end": "583800"
  },
  {
    "text": "of schematically uh laid it out here",
    "start": "583800",
    "end": "586040"
  },
  {
    "text": "it's just going to contain a few keys",
    "start": "586040",
    "end": "588279"
  },
  {
    "text": "that are things relevant to rag it's",
    "start": "588279",
    "end": "590040"
  },
  {
    "text": "going to be like a question then it's",
    "start": "590040",
    "end": "591880"
  },
  {
    "text": "going to be you pen documents to your",
    "start": "591880",
    "end": "593800"
  },
  {
    "text": "dick um and then eventually you're",
    "start": "593800",
    "end": "596240"
  },
  {
    "text": "independent generation so that's really",
    "start": "596240",
    "end": "598160"
  },
  {
    "text": "all that's going on in terms of like how",
    "start": "598160",
    "end": "600320"
  },
  {
    "text": "your State's being propagated through",
    "start": "600320",
    "end": "602560"
  },
  {
    "text": "the graph and at every node you're",
    "start": "602560",
    "end": "605480"
  },
  {
    "text": "making some modification to State that's",
    "start": "605480",
    "end": "607519"
  },
  {
    "text": "the key point so you're basically going",
    "start": "607519",
    "end": "609680"
  },
  {
    "text": "to do you start with a question from the",
    "start": "609680",
    "end": "611440"
  },
  {
    "text": "user you perform retrieval relevant to",
    "start": "611440",
    "end": "613600"
  },
  {
    "text": "the question um you're then going to",
    "start": "613600",
    "end": "616000"
  },
  {
    "text": "grade the documents so you're going to",
    "start": "616000",
    "end": "617880"
  },
  {
    "text": "do a modification of the documents then",
    "start": "617880",
    "end": "620000"
  },
  {
    "text": "you're going to make a decision are they",
    "start": "620000",
    "end": "622000"
  },
  {
    "text": "relevant or not if they're not relevant",
    "start": "622000",
    "end": "624920"
  },
  {
    "text": "um you're going to transform the query",
    "start": "624920",
    "end": "626720"
  },
  {
    "text": "so you modify the question do a web",
    "start": "626720",
    "end": "628720"
  },
  {
    "text": "search the final step is a generation",
    "start": "628720",
    "end": "631079"
  },
  {
    "text": "based upon the D documents so that's",
    "start": "631079",
    "end": "632680"
  },
  {
    "text": "your",
    "start": "632680",
    "end": "633680"
  },
  {
    "text": "flow now what I want to call out here is",
    "start": "633680",
    "end": "637279"
  },
  {
    "text": "there's one very important what we call",
    "start": "637279",
    "end": "639360"
  },
  {
    "text": "conditional Edge where depending upon",
    "start": "639360",
    "end": "641839"
  },
  {
    "text": "the results of the grading step I want",
    "start": "641839",
    "end": "644160"
  },
  {
    "text": "to do one thing or another so I'm going",
    "start": "644160",
    "end": "645839"
  },
  {
    "text": "to make a decision so I want to show you",
    "start": "645839",
    "end": "648839"
  },
  {
    "text": "something that's very",
    "start": "648839",
    "end": "650440"
  },
  {
    "text": "convenient um that we can use with olama",
    "start": "650440",
    "end": "655560"
  },
  {
    "text": "to help us",
    "start": "655560",
    "end": "656760"
  },
  {
    "text": "here so this",
    "start": "656760",
    "end": "659760"
  },
  {
    "text": "is I'm going to kind of make a note here",
    "start": "659760",
    "end": "662519"
  },
  {
    "text": "um to note what I'm going to highlight",
    "start": "662519",
    "end": "666240"
  },
  {
    "text": "so this is AMA Json",
    "start": "666240",
    "end": "669240"
  },
  {
    "text": "mode so the basic logic of that",
    "start": "669240",
    "end": "673480"
  },
  {
    "start": "670000",
    "end": "880000"
  },
  {
    "text": "conditional Edge decide to generate is",
    "start": "673480",
    "end": "675360"
  },
  {
    "text": "going to be something like this I",
    "start": "675360",
    "end": "676800"
  },
  {
    "text": "already have this prompt laid out um but",
    "start": "676800",
    "end": "679880"
  },
  {
    "text": "it's basically going to be I'm going to",
    "start": "679880",
    "end": "681680"
  },
  {
    "text": "take a document and I'm going to take my",
    "start": "681680",
    "end": "684200"
  },
  {
    "text": "question and I'm going to do some kind",
    "start": "684200",
    "end": "686120"
  },
  {
    "text": "of comparison to say is the document",
    "start": "686120",
    "end": "687839"
  },
  {
    "text": "relevant to the question that's really",
    "start": "687839",
    "end": "689320"
  },
  {
    "text": "what I want to do but here's the catch",
    "start": "689320",
    "end": "692000"
  },
  {
    "text": "because I want that edge to process very",
    "start": "692000",
    "end": "694440"
  },
  {
    "text": "particular output either yes or no I",
    "start": "694440",
    "end": "696839"
  },
  {
    "text": "want to make sure that my output is",
    "start": "696839",
    "end": "699120"
  },
  {
    "text": "structured in a way that can reliably be",
    "start": "699120",
    "end": "701959"
  },
  {
    "text": "interpreted Downstream in my in my graph",
    "start": "701959",
    "end": "705120"
  },
  {
    "text": "this is where Json mode from Alama is",
    "start": "705120",
    "end": "707320"
  },
  {
    "text": "really useful and you can see all I do",
    "start": "707320",
    "end": "710800"
  },
  {
    "text": "is now I'm I'm importing chat llama this",
    "start": "710800",
    "end": "714800"
  },
  {
    "text": "is going to reference that local model",
    "start": "714800",
    "end": "717040"
  },
  {
    "text": "that I specified up here Mr instruct",
    "start": "717040",
    "end": "720240"
  },
  {
    "text": "which I've downloaded so I have the",
    "start": "720240",
    "end": "721600"
  },
  {
    "text": "model",
    "start": "721600",
    "end": "722920"
  },
  {
    "text": "locally and I'm just flagging this um",
    "start": "722920",
    "end": "726320"
  },
  {
    "text": "format Json to tell the model to Output",
    "start": "726320",
    "end": "729320"
  },
  {
    "text": "Json",
    "start": "729320",
    "end": "730839"
  },
  {
    "text": "specifically and what I'm going to do in",
    "start": "730839",
    "end": "733320"
  },
  {
    "text": "my prompt here I'm basically saying you",
    "start": "733320",
    "end": "736279"
  },
  {
    "text": "know you're a grer um here's the",
    "start": "736279",
    "end": "739000"
  },
  {
    "text": "documents here's the question and here's",
    "start": "739000",
    "end": "740760"
  },
  {
    "text": "the catch give a binary score yes no um",
    "start": "740760",
    "end": "745639"
  },
  {
    "text": "and provide it as Json with a single key",
    "start": "745639",
    "end": "748560"
  },
  {
    "text": "score and no Preamble no explanation so",
    "start": "748560",
    "end": "750800"
  },
  {
    "text": "I kind of explain in the prompt what I",
    "start": "750800",
    "end": "753000"
  },
  {
    "text": "want and when I call this with Json mode",
    "start": "753000",
    "end": "757199"
  },
  {
    "text": "uh it will enforce that Json is returned",
    "start": "757199",
    "end": "760000"
  },
  {
    "text": "and hopefully with this single key we",
    "start": "760000",
    "end": "761839"
  },
  {
    "text": "expect score and either binary yes no",
    "start": "761839",
    "end": "765120"
  },
  {
    "text": "and when I'm going to run that as a",
    "start": "765120",
    "end": "766600"
  },
  {
    "text": "chain so I'm going to supply that prompt",
    "start": "766600",
    "end": "769240"
  },
  {
    "text": "to my llm and I'm going to then parse",
    "start": "769240",
    "end": "771839"
  },
  {
    "text": "that Json string out into a Json object",
    "start": "771839",
    "end": "774800"
  },
  {
    "text": "which I can work with so let's try that",
    "start": "774800",
    "end": "777240"
  },
  {
    "text": "we're going to try to run this chain we",
    "start": "777240",
    "end": "779199"
  },
  {
    "text": "defined we're going to run retrieval on",
    "start": "779199",
    "end": "782000"
  },
  {
    "text": "here's a here's a question here's our",
    "start": "782000",
    "end": "784160"
  },
  {
    "text": "docs let's grade one of the docs using",
    "start": "784160",
    "end": "787279"
  },
  {
    "text": "basically passing question and one",
    "start": "787279",
    "end": "789720"
  },
  {
    "text": "document and we're going to take the",
    "start": "789720",
    "end": "790920"
  },
  {
    "text": "page content from the document which is",
    "start": "790920",
    "end": "792440"
  },
  {
    "text": "like basically all the text and we're",
    "start": "792440",
    "end": "794440"
  },
  {
    "text": "going to run",
    "start": "794440",
    "end": "795560"
  },
  {
    "text": "this so let's test that quickly and it",
    "start": "795560",
    "end": "798560"
  },
  {
    "text": "is still running now it's finished let's",
    "start": "798560",
    "end": "800680"
  },
  {
    "text": "check the output here we can see so we",
    "start": "800680",
    "end": "803639"
  },
  {
    "text": "get a Json back which just is the score",
    "start": "803639",
    "end": "805760"
  },
  {
    "text": "yes no so that's exactly right that's",
    "start": "805760",
    "end": "807760"
  },
  {
    "text": "what we want and we can actually look",
    "start": "807760",
    "end": "809680"
  },
  {
    "text": "under the hood here at",
    "start": "809680",
    "end": "813880"
  },
  {
    "text": "um yeah so we can actually look under",
    "start": "813880",
    "end": "816279"
  },
  {
    "text": "the hood in Langs Smith at that grading",
    "start": "816279",
    "end": "819480"
  },
  {
    "text": "process and we can see here that our",
    "start": "819480",
    "end": "822399"
  },
  {
    "text": "prompt got populated with um the context",
    "start": "822399",
    "end": "827000"
  },
  {
    "text": "so here is the",
    "start": "827000",
    "end": "829240"
  },
  {
    "text": "document um",
    "start": "829240",
    "end": "832320"
  },
  {
    "text": "and um right here was a question here is",
    "start": "832320",
    "end": "835320"
  },
  {
    "text": "a document and um the task was of course",
    "start": "835320",
    "end": "840199"
  },
  {
    "text": "to grade it so we can see here's like",
    "start": "840199",
    "end": "843240"
  },
  {
    "text": "the full prompt you're a grader",
    "start": "843240",
    "end": "845399"
  },
  {
    "text": "assessing the relevance retri document",
    "start": "845399",
    "end": "846959"
  },
  {
    "text": "here's a document and then here's the",
    "start": "846959",
    "end": "849560"
  },
  {
    "text": "model output score yes so this is really",
    "start": "849560",
    "end": "851839"
  },
  {
    "text": "nice we've basically enforced the output",
    "start": "851839",
    "end": "855320"
  },
  {
    "text": "from our local",
    "start": "855320",
    "end": "856880"
  },
  {
    "text": "llm um using Json mode so we know every",
    "start": "856880",
    "end": "860920"
  },
  {
    "text": "time it's going to Output binary yes no",
    "start": "860920",
    "end": "863519"
  },
  {
    "text": "score as a Json object which we again",
    "start": "863519",
    "end": "865560"
  },
  {
    "text": "extract so that's a very key point that",
    "start": "865560",
    "end": "867279"
  },
  {
    "text": "I just wanted to flag it's a very nice",
    "start": "867279",
    "end": "869680"
  },
  {
    "text": "thing that ama offers that's extremely",
    "start": "869680",
    "end": "872199"
  },
  {
    "text": "helpful when building out uh",
    "start": "872199",
    "end": "874519"
  },
  {
    "text": "particularly these kind of logical",
    "start": "874519",
    "end": "876399"
  },
  {
    "text": "graphs where you really want to",
    "start": "876399",
    "end": "877560"
  },
  {
    "text": "constrain the flow at certain",
    "start": "877560",
    "end": "880320"
  },
  {
    "start": "880000",
    "end": "1100000"
  },
  {
    "text": "edges so that's kind of the like really",
    "start": "880320",
    "end": "884720"
  },
  {
    "text": "key thing I wanted to highlight a lot of",
    "start": "884720",
    "end": "887000"
  },
  {
    "text": "the rest of this is actually pretty",
    "start": "887000",
    "end": "889279"
  },
  {
    "text": "straightforward so let's now Define our",
    "start": "889279",
    "end": "892120"
  },
  {
    "text": "graph State this is the dictionary that",
    "start": "892120",
    "end": "894160"
  },
  {
    "text": "we're going to basically pass between",
    "start": "894160",
    "end": "895639"
  },
  {
    "text": "our nodes so this is just some code I'm",
    "start": "895639",
    "end": "897800"
  },
  {
    "text": "going to copy over",
    "start": "897800",
    "end": "899199"
  },
  {
    "text": "this is defining your graph State you're",
    "start": "899199",
    "end": "900839"
  },
  {
    "text": "just saying it's a dict that's all",
    "start": "900839",
    "end": "902399"
  },
  {
    "text": "there's really to that um now here is",
    "start": "902399",
    "end": "906519"
  },
  {
    "text": "where I'm going to copy over some code",
    "start": "906519",
    "end": "910600"
  },
  {
    "text": "that basically implements a function for",
    "start": "910600",
    "end": "914399"
  },
  {
    "text": "every node and every conditional Edge in",
    "start": "914399",
    "end": "918079"
  },
  {
    "text": "our graph so if you remember we can kind",
    "start": "918079",
    "end": "920480"
  },
  {
    "text": "of go over and look our graph is laid",
    "start": "920480",
    "end": "923000"
  },
  {
    "text": "out like this and all we're doing is for",
    "start": "923000",
    "end": "927320"
  },
  {
    "text": "every node drawn we're going to find a",
    "start": "927320",
    "end": "929720"
  },
  {
    "text": "corresponding function here which",
    "start": "929720",
    "end": "932880"
  },
  {
    "text": "performs some operation so retrieve is",
    "start": "932880",
    "end": "935360"
  },
  {
    "text": "basically just doing we had our retri",
    "start": "935360",
    "end": "937160"
  },
  {
    "text": "defined get relevant documents and write",
    "start": "937160",
    "end": "939759"
  },
  {
    "text": "them out to state so again we take a",
    "start": "939759",
    "end": "942839"
  },
  {
    "text": "question in so if you look here we",
    "start": "942839",
    "end": "946680"
  },
  {
    "text": "basically have this state dict passed",
    "start": "946680",
    "end": "948600"
  },
  {
    "text": "into the function we extract the state",
    "start": "948600",
    "end": "951319"
  },
  {
    "text": "dict here uh we extract the question",
    "start": "951319",
    "end": "953959"
  },
  {
    "text": "from the state dict we do retrieval and",
    "start": "953959",
    "end": "956279"
  },
  {
    "text": "we write that state dict back out to the",
    "start": "956279",
    "end": "958839"
  },
  {
    "text": "so you think about every node is just",
    "start": "958839",
    "end": "960959"
  },
  {
    "text": "doing some modification on the state",
    "start": "960959",
    "end": "963759"
  },
  {
    "text": "reading it in doing something writing it",
    "start": "963759",
    "end": "966440"
  },
  {
    "text": "back out that's really all that's going",
    "start": "966440",
    "end": "967880"
  },
  {
    "text": "on and we can really just march across",
    "start": "967880",
    "end": "970480"
  },
  {
    "text": "our little like diagram here and see how",
    "start": "970480",
    "end": "974920"
  },
  {
    "text": "um basically each one of these nodes is",
    "start": "974920",
    "end": "977680"
  },
  {
    "text": "implemented as a function and again you",
    "start": "977680",
    "end": "980440"
  },
  {
    "text": "can see in every case we're using uh for",
    "start": "980440",
    "end": "984040"
  },
  {
    "text": "example cadow llama in some of these",
    "start": "984040",
    "end": "986759"
  },
  {
    "text": "cases we don't need Json mode so if",
    "start": "986759",
    "end": "988720"
  },
  {
    "text": "we're just doing like a generation step",
    "start": "988720",
    "end": "991160"
  },
  {
    "text": "um as you can see here we don't need",
    "start": "991160",
    "end": "992639"
  },
  {
    "text": "Json mode for the grading we do so we're",
    "start": "992639",
    "end": "995720"
  },
  {
    "text": "actually going to implement here the",
    "start": "995720",
    "end": "997160"
  },
  {
    "text": "same thing we just showed um chat AMA",
    "start": "997160",
    "end": "1000360"
  },
  {
    "text": "using Json mode and what's going to",
    "start": "1000360",
    "end": "1002279"
  },
  {
    "text": "happen is we can see we generate our",
    "start": "1002279",
    "end": "1004959"
  },
  {
    "text": "score every time and then we can extract",
    "start": "1004959",
    "end": "1007399"
  },
  {
    "text": "our grade from that",
    "start": "1007399",
    "end": "1009800"
  },
  {
    "text": "Json and then we know the grade is going",
    "start": "1009800",
    "end": "1012839"
  },
  {
    "text": "to constrained to the output yes or no",
    "start": "1012839",
    "end": "1015639"
  },
  {
    "text": "then here's the key point we do some",
    "start": "1015639",
    "end": "1018040"
  },
  {
    "text": "logical reasoning on that um to say for",
    "start": "1018040",
    "end": "1022399"
  },
  {
    "text": "example if the grade is yes um then",
    "start": "1022399",
    "end": "1025959"
  },
  {
    "text": "we're going to um like append the",
    "start": "1025959",
    "end": "1028959"
  },
  {
    "text": "document it's relevant if not then what",
    "start": "1028959",
    "end": "1031640"
  },
  {
    "text": "we're going to do is we're going to",
    "start": "1031640",
    "end": "1033558"
  },
  {
    "text": "filter that document out and we're also",
    "start": "1033559",
    "end": "1035918"
  },
  {
    "text": "going to set this flag to search perform",
    "start": "1035919",
    "end": "1038798"
  },
  {
    "text": "web search as yes so what really",
    "start": "1038799",
    "end": "1041400"
  },
  {
    "text": "happening here is we are kind of",
    "start": "1041400",
    "end": "1045038"
  },
  {
    "text": "applying a kind of a logical gate to say",
    "start": "1045039",
    "end": "1049559"
  },
  {
    "text": "if any document is scored as relevant",
    "start": "1049559",
    "end": "1052360"
  },
  {
    "text": "then we just add it to our final list of",
    "start": "1052360",
    "end": "1054039"
  },
  {
    "text": "filter documents if not we're going to",
    "start": "1054039",
    "end": "1056440"
  },
  {
    "text": "go ahead and do a web search and we're",
    "start": "1056440",
    "end": "1058120"
  },
  {
    "text": "going to set the search flag to be yes",
    "start": "1058120",
    "end": "1060559"
  },
  {
    "text": "and we're not going to include that",
    "start": "1060559",
    "end": "1061559"
  },
  {
    "text": "document in the output and you can see",
    "start": "1061559",
    "end": "1063120"
  },
  {
    "text": "here we return a dictionary which",
    "start": "1063120",
    "end": "1065679"
  },
  {
    "text": "contains our filter documents our",
    "start": "1065679",
    "end": "1067840"
  },
  {
    "text": "question and then that flag to run web",
    "start": "1067840",
    "end": "1070120"
  },
  {
    "text": "search yes or no you can see it was",
    "start": "1070120",
    "end": "1072000"
  },
  {
    "text": "default no but if we ever encounter an",
    "start": "1072000",
    "end": "1074480"
  },
  {
    "text": "irrelevant document we change that to",
    "start": "1074480",
    "end": "1076640"
  },
  {
    "text": "yes so that's really all that's going",
    "start": "1076640",
    "end": "1078400"
  },
  {
    "text": "going on here um you can see we do our",
    "start": "1078400",
    "end": "1081320"
  },
  {
    "text": "queer transform down here again we just",
    "start": "1081320",
    "end": "1083919"
  },
  {
    "text": "use um Mr all again here is like a a",
    "start": "1083919",
    "end": "1087440"
  },
  {
    "text": "transform prompt but you kind of get the",
    "start": "1087440",
    "end": "1089360"
  },
  {
    "text": "idea um web search node we use Tav web",
    "start": "1089360",
    "end": "1093000"
  },
  {
    "text": "search here it's really kind of a nice",
    "start": "1093000",
    "end": "1094600"
  },
  {
    "text": "quick way to perform web searches um and",
    "start": "1094600",
    "end": "1098000"
  },
  {
    "text": "you can see we just supplement the",
    "start": "1098000",
    "end": "1099200"
  },
  {
    "text": "documents with the web search results",
    "start": "1099200",
    "end": "1101440"
  },
  {
    "start": "1100000",
    "end": "1559000"
  },
  {
    "text": "and then this was kind of the final step",
    "start": "1101440",
    "end": "1104360"
  },
  {
    "text": "where we wrote out yes or no to our",
    "start": "1104360",
    "end": "1107880"
  },
  {
    "text": "search key and depending upon the state",
    "start": "1107880",
    "end": "1111559"
  },
  {
    "text": "which we can read in here we make",
    "start": "1111559",
    "end": "1113799"
  },
  {
    "text": "decision to uh basically either return",
    "start": "1113799",
    "end": "1117640"
  },
  {
    "text": "transform query or return generate which",
    "start": "1117640",
    "end": "1121039"
  },
  {
    "text": "will basically that's determining the",
    "start": "1121039",
    "end": "1123679"
  },
  {
    "text": "next uh node to go to um so this decide",
    "start": "1123679",
    "end": "1128240"
  },
  {
    "text": "to generate is our conditional Edge",
    "start": "1128240",
    "end": "1130440"
  },
  {
    "text": "that's actually right here and so it's",
    "start": "1130440",
    "end": "1133039"
  },
  {
    "text": "looking at the results that we wrote out",
    "start": "1133039",
    "end": "1136080"
  },
  {
    "text": "from grade documents in particular",
    "start": "1136080",
    "end": "1138919"
  },
  {
    "text": "that uh search yes or no key in our dict",
    "start": "1138919",
    "end": "1145080"
  },
  {
    "text": "and it's then going to basically",
    "start": "1145080",
    "end": "1147039"
  },
  {
    "text": "determine the next node to Traverse to",
    "start": "1147039",
    "end": "1149159"
  },
  {
    "text": "that's really all we're doing here so",
    "start": "1149159",
    "end": "1151640"
  },
  {
    "text": "that's kind of nice now what we're going",
    "start": "1151640",
    "end": "1153919"
  },
  {
    "text": "to do is we kind of copied over all",
    "start": "1153919",
    "end": "1157280"
  },
  {
    "text": "these um these functions we then can go",
    "start": "1157280",
    "end": "1162960"
  },
  {
    "text": "ahead and run that and now we just lay",
    "start": "1162960",
    "end": "1166120"
  },
  {
    "text": "out our graph so again",
    "start": "1166120",
    "end": "1169280"
  },
  {
    "text": "our graph was kind of explained here and",
    "start": "1169280",
    "end": "1173559"
  },
  {
    "text": "here's where we actually just lay out",
    "start": "1173559",
    "end": "1175720"
  },
  {
    "text": "the full kind of graph",
    "start": "1175720",
    "end": "1177880"
  },
  {
    "text": "organization um how we're going to",
    "start": "1177880",
    "end": "1179919"
  },
  {
    "text": "connect each node so we add the nodes",
    "start": "1179919",
    "end": "1181960"
  },
  {
    "text": "first we set our entry point and then we",
    "start": "1181960",
    "end": "1184840"
  },
  {
    "text": "add the edges accordingly between the",
    "start": "1184840",
    "end": "1186720"
  },
  {
    "text": "nodes and basically the logic here just",
    "start": "1186720",
    "end": "1189200"
  },
  {
    "text": "Maps over to our diagram here that's",
    "start": "1189200",
    "end": "1191320"
  },
  {
    "text": "really all that's",
    "start": "1191320",
    "end": "1193400"
  },
  {
    "text": "happening",
    "start": "1193400",
    "end": "1195400"
  },
  {
    "text": "um",
    "start": "1195400",
    "end": "1197240"
  },
  {
    "text": "cool",
    "start": "1197240",
    "end": "1199120"
  },
  {
    "text": "so I'm going to go ahead and go",
    "start": "1199120",
    "end": "1202360"
  },
  {
    "text": "down and now let's kind of see this all",
    "start": "1202360",
    "end": "1206280"
  },
  {
    "text": "working together so I'm going to go",
    "start": "1206280",
    "end": "1207720"
  },
  {
    "text": "ahead and compile My",
    "start": "1207720",
    "end": "1209400"
  },
  {
    "text": "Graph and I'm going to go ahead and ask",
    "start": "1209400",
    "end": "1212760"
  },
  {
    "text": "a question explain how the different",
    "start": "1212760",
    "end": "1214679"
  },
  {
    "text": "types of agent memory work and what I'm",
    "start": "1214679",
    "end": "1218600"
  },
  {
    "text": "going to do let's go back to our D",
    "start": "1218600",
    "end": "1220200"
  },
  {
    "text": "diagram so we can kind of reference that",
    "start": "1220200",
    "end": "1222640"
  },
  {
    "text": "I'm going to call this and I'm actually",
    "start": "1222640",
    "end": "1225440"
  },
  {
    "text": "just going to like this will like",
    "start": "1225440",
    "end": "1226520"
  },
  {
    "text": "Traverse every step along the away and",
    "start": "1226520",
    "end": "1228600"
  },
  {
    "text": "it'll print out something to explain",
    "start": "1228600",
    "end": "1230039"
  },
  {
    "text": "what's happening so you can see I",
    "start": "1230039",
    "end": "1232000"
  },
  {
    "text": "perform retrieval and now I'm doing my",
    "start": "1232000",
    "end": "1234120"
  },
  {
    "text": "grading steps and this is all running",
    "start": "1234120",
    "end": "1236280"
  },
  {
    "text": "locally um and they were all deemed",
    "start": "1236280",
    "end": "1239400"
  },
  {
    "text": "relevant so then I'm going to go ahead",
    "start": "1239400",
    "end": "1241360"
  },
  {
    "text": "and",
    "start": "1241360",
    "end": "1242200"
  },
  {
    "text": "generate and it's running right",
    "start": "1242200",
    "end": "1244760"
  },
  {
    "text": "now and there we go so we can go over to",
    "start": "1244760",
    "end": "1248400"
  },
  {
    "text": "Lang Smith and let's actually have a",
    "start": "1248400",
    "end": "1251159"
  },
  {
    "text": "look at what happened under the hood so",
    "start": "1251159",
    "end": "1252640"
  },
  {
    "text": "this is what just ran so we can see that",
    "start": "1252640",
    "end": "1256600"
  },
  {
    "text": "at each one of these steps",
    "start": "1256600",
    "end": "1258840"
  },
  {
    "text": "we called Shadow llama with our mraw 7B",
    "start": "1258840",
    "end": "1262960"
  },
  {
    "text": "model that's running",
    "start": "1262960",
    "end": "1264679"
  },
  {
    "text": "locally um and this is our grading step",
    "start": "1264679",
    "end": "1267360"
  },
  {
    "text": "so this was each document being graded",
    "start": "1267360",
    "end": "1270039"
  },
  {
    "text": "um so again like look at this so it",
    "start": "1270039",
    "end": "1272279"
  },
  {
    "text": "outputs a binary score yes no as a dict",
    "start": "1272279",
    "end": "1275760"
  },
  {
    "text": "that's great um so this has a bunch more",
    "start": "1275760",
    "end": "1278320"
  },
  {
    "text": "down here so these are all of our",
    "start": "1278320",
    "end": "1280520"
  },
  {
    "text": "documents uh graded and now here is that",
    "start": "1280520",
    "end": "1283480"
  },
  {
    "text": "final llm call which basically packed",
    "start": "1283480",
    "end": "1286320"
  },
  {
    "text": "that all into our rag prompt you're an",
    "start": "1286320",
    "end": "1288799"
  },
  {
    "text": "assistant for question answering task",
    "start": "1288799",
    "end": "1290320"
  },
  {
    "text": "use a following to answer the question",
    "start": "1290320",
    "end": "1292320"
  },
  {
    "text": "here's all up our docs here's the answer",
    "start": "1292320",
    "end": "1295039"
  },
  {
    "text": "so that's pretty cool um we can see that",
    "start": "1295039",
    "end": "1297840"
  },
  {
    "text": "this uh multi-step logical flow all",
    "start": "1297840",
    "end": "1301880"
  },
  {
    "text": "works um now let's try something kind of",
    "start": "1301880",
    "end": "1305120"
  },
  {
    "text": "interesting I'm going to ask a question",
    "start": "1305120",
    "end": "1306919"
  },
  {
    "text": "that I know is not in the context and",
    "start": "1306919",
    "end": "1310320"
  },
  {
    "text": "see if it will kind of perform that",
    "start": "1310320",
    "end": "1312799"
  },
  {
    "text": "default to do web search so um I'm going",
    "start": "1312799",
    "end": "1316679"
  },
  {
    "text": "to say Explain how how uh",
    "start": "1316679",
    "end": "1320440"
  },
  {
    "text": "Alpha codium works so this is a recent",
    "start": "1320440",
    "end": "1324640"
  },
  {
    "text": "paper that came out that's not relevant",
    "start": "1324640",
    "end": "1326919"
  },
  {
    "text": "at all to this blog post so I know uh",
    "start": "1326919",
    "end": "1329559"
  },
  {
    "text": "that retrieval should not be considered",
    "start": "1329559",
    "end": "1331760"
  },
  {
    "text": "relevant and let's go ahead and run that",
    "start": "1331760",
    "end": "1334520"
  },
  {
    "text": "and convince oursel that that's true so",
    "start": "1334520",
    "end": "1336720"
  },
  {
    "text": "good this is perfect so the greater is",
    "start": "1336720",
    "end": "1339400"
  },
  {
    "text": "determining these documents are not",
    "start": "1339400",
    "end": "1340760"
  },
  {
    "text": "relevant and so it should be making that",
    "start": "1340760",
    "end": "1343120"
  },
  {
    "text": "decision to perform web search so it it",
    "start": "1343120",
    "end": "1345400"
  },
  {
    "text": "should be kind of going to this lower",
    "start": "1345400",
    "end": "1347600"
  },
  {
    "text": "branch",
    "start": "1347600",
    "end": "1348720"
  },
  {
    "text": "transform the query run web search and",
    "start": "1348720",
    "end": "1351159"
  },
  {
    "text": "looks like that all ran so it tells us",
    "start": "1351159",
    "end": "1353400"
  },
  {
    "text": "Alpha coding is an open source AI coding",
    "start": "1353400",
    "end": "1355520"
  },
  {
    "text": "generation tool developed by Cod M this",
    "start": "1355520",
    "end": "1358320"
  },
  {
    "text": "is perfect that's exactly what it is and",
    "start": "1358320",
    "end": "1360960"
  },
  {
    "text": "we can actually go into Langs Smith and",
    "start": "1360960",
    "end": "1362840"
  },
  {
    "text": "again see what happened here so you can",
    "start": "1362840",
    "end": "1366360"
  },
  {
    "text": "see here the trace is a little bit more",
    "start": "1366360",
    "end": "1368200"
  },
  {
    "text": "extensive because all of our grades are",
    "start": "1368200",
    "end": "1371240"
  },
  {
    "text": "incorrect so or irrelevant again we get",
    "start": "1371240",
    "end": "1374360"
  },
  {
    "text": "the nice Json",
    "start": "1374360",
    "end": "1375919"
  },
  {
    "text": "out um",
    "start": "1375919",
    "end": "1378720"
  },
  {
    "text": "and okay so this is pretty cool so this",
    "start": "1378720",
    "end": "1381279"
  },
  {
    "text": "was our question rewriting node so",
    "start": "1381279",
    "end": "1384679"
  },
  {
    "text": "basically provid an improved input",
    "start": "1384679",
    "end": "1386559"
  },
  {
    "text": "question without any Preamble so what is",
    "start": "1386559",
    "end": "1388799"
  },
  {
    "text": "the mechanism behind Alpha codium",
    "start": "1388799",
    "end": "1390320"
  },
  {
    "text": "functionality so it modifies the",
    "start": "1390320",
    "end": "1392200"
  },
  {
    "text": "question we use Tali search right here",
    "start": "1392200",
    "end": "1395600"
  },
  {
    "text": "so it basically does retrieval it",
    "start": "1395600",
    "end": "1397960"
  },
  {
    "text": "searches for Stuff related to Alpha",
    "start": "1397960",
    "end": "1399960"
  },
  {
    "text": "codium so that's great and then we",
    "start": "1399960",
    "end": "1402400"
  },
  {
    "text": "finally passed that to our our model for",
    "start": "1402400",
    "end": "1404880"
  },
  {
    "text": "Generation based on this new context and",
    "start": "1404880",
    "end": "1408360"
  },
  {
    "text": "there we go Alpha codom Source AI code",
    "start": "1408360",
    "end": "1410679"
  },
  {
    "text": "assistant tool um so that kind of gives",
    "start": "1410679",
    "end": "1413880"
  },
  {
    "text": "you the main idea and the key point is",
    "start": "1413880",
    "end": "1417240"
  },
  {
    "text": "this is all running locally again I used",
    "start": "1417240",
    "end": "1420400"
  },
  {
    "text": "GPT for all embeddings for indexing up",
    "start": "1420400",
    "end": "1423760"
  },
  {
    "text": "at the top right here and I used AMA",
    "start": "1423760",
    "end": "1428880"
  },
  {
    "text": "with mrol 7B instruct um and Json mode",
    "start": "1428880",
    "end": "1433559"
  },
  {
    "text": "for that one crucial step where I need",
    "start": "1433559",
    "end": "1436000"
  },
  {
    "text": "to constrain the output to be kind of a",
    "start": "1436000",
    "end": "1437880"
  },
  {
    "text": "score of yes no um and for other things",
    "start": "1437880",
    "end": "1441880"
  },
  {
    "text": "I just use the model without Json mode",
    "start": "1441880",
    "end": "1443880"
  },
  {
    "text": "to do perform Generations like to",
    "start": "1443880",
    "end": "1445679"
  },
  {
    "text": "question rewrite or to do the final",
    "start": "1445679",
    "end": "1448760"
  },
  {
    "text": "generation so in any case I hope this",
    "start": "1448760",
    "end": "1450880"
  },
  {
    "text": "gives you kind of an overview of how to",
    "start": "1450880",
    "end": "1452520"
  },
  {
    "text": "think about building logical uh flows",
    "start": "1452520",
    "end": "1455720"
  },
  {
    "text": "doesn't have to be rag but rag is a",
    "start": "1455720",
    "end": "1457520"
  },
  {
    "text": "really good kind of use case uh for this",
    "start": "1457520",
    "end": "1460919"
  },
  {
    "text": "using local models and Lang graph and",
    "start": "1460919",
    "end": "1464039"
  },
  {
    "text": "the thing I want to kind of leave you",
    "start": "1464039",
    "end": "1465399"
  },
  {
    "text": "with is there is a lot of interest in",
    "start": "1465399",
    "end": "1468840"
  },
  {
    "text": "complex logical reasoning using local",
    "start": "1468840",
    "end": "1470919"
  },
  {
    "text": "llms and a lot of you know focus on",
    "start": "1470919",
    "end": "1472960"
  },
  {
    "text": "using agents and I do want to kind of",
    "start": "1472960",
    "end": "1475840"
  },
  {
    "text": "encourage you to think about depending",
    "start": "1475840",
    "end": "1477840"
  },
  {
    "text": "on the problem you're trying to solve",
    "start": "1477840",
    "end": "1479080"
  },
  {
    "text": "you may or may not actually need an",
    "start": "1479080",
    "end": "1480480"
  },
  {
    "text": "agent it's possible that kind of",
    "start": "1480480",
    "end": "1482480"
  },
  {
    "text": "implementing a state machine or a graph",
    "start": "1482480",
    "end": "1484840"
  },
  {
    "text": "kind of as shown here with some series",
    "start": "1484840",
    "end": "1486919"
  },
  {
    "text": "of logical steps this can incorporate",
    "start": "1486919",
    "end": "1489440"
  },
  {
    "text": "Cycles or Loops back to like prior",
    "start": "1489440",
    "end": "1491600"
  },
  {
    "text": "stages we have some more complex",
    "start": "1491600",
    "end": "1493320"
  },
  {
    "text": "examples that show that um this actually",
    "start": "1493320",
    "end": "1496120"
  },
  {
    "text": "can work really well with local mod",
    "start": "1496120",
    "end": "1497760"
  },
  {
    "text": "models because a local model is only",
    "start": "1497760",
    "end": "1500880"
  },
  {
    "text": "performing a step um within each node so",
    "start": "1500880",
    "end": "1505240"
  },
  {
    "text": "you're kind of constraining it to like",
    "start": "1505240",
    "end": "1507679"
  },
  {
    "text": "just do this little thing just do this",
    "start": "1507679",
    "end": "1509880"
  },
  {
    "text": "little thing like just rewrite the",
    "start": "1509880",
    "end": "1511440"
  },
  {
    "text": "question just grade the document rather",
    "start": "1511440",
    "end": "1514640"
  },
  {
    "text": "than using the local llm um as like you",
    "start": "1514640",
    "end": "1518360"
  },
  {
    "text": "know an agent executor that has to make",
    "start": "1518360",
    "end": "1521640"
  },
  {
    "text": "all these decisions kind of jointly um",
    "start": "1521640",
    "end": "1525039"
  },
  {
    "text": "or kind of in a less controlled workflow",
    "start": "1525039",
    "end": "1530120"
  },
  {
    "text": "where for example like the the The",
    "start": "1530120",
    "end": "1532399"
  },
  {
    "text": "Ordering of these various tasks can be",
    "start": "1532399",
    "end": "1534480"
  },
  {
    "text": "determined arbitrarily by the agent here",
    "start": "1534480",
    "end": "1537360"
  },
  {
    "text": "we really nicely constrain The Logical",
    "start": "1537360",
    "end": "1540200"
  },
  {
    "text": "flow and let the local model just do",
    "start": "1540200",
    "end": "1543320"
  },
  {
    "text": "little tasks at each step and I've just",
    "start": "1543320",
    "end": "1545679"
  },
  {
    "text": "found it to be a lot more reliable and",
    "start": "1545679",
    "end": "1548240"
  },
  {
    "text": "really useful for these kinds of like",
    "start": "1548240",
    "end": "1549799"
  },
  {
    "text": "logical reasoning tasks um so hopefully",
    "start": "1549799",
    "end": "1552720"
  },
  {
    "text": "this is helpful give it a try um and",
    "start": "1552720",
    "end": "1555240"
  },
  {
    "text": "we'll make sure all this code is is",
    "start": "1555240",
    "end": "1556640"
  },
  {
    "text": "easily shared thank thank",
    "start": "1556640",
    "end": "1558880"
  },
  {
    "text": "you",
    "start": "1558880",
    "end": "1561880"
  }
]
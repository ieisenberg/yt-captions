[
  {
    "start": "0",
    "end": "320000"
  },
  {
    "text": "hi everyone it's Isaac with Lang chain",
    "start": "1319",
    "end": "3320"
  },
  {
    "text": "and today we're going to go over how we",
    "start": "3320",
    "end": "5879"
  },
  {
    "text": "can add structured output to our react",
    "start": "5879",
    "end": "7680"
  },
  {
    "text": "agents so to start off with we are going",
    "start": "7680",
    "end": "10080"
  },
  {
    "text": "to do a quick refresher on what a react",
    "start": "10080",
    "end": "12480"
  },
  {
    "text": "agent is and then we're going to explore",
    "start": "12480",
    "end": "14320"
  },
  {
    "text": "how we can add structured output to it",
    "start": "14320",
    "end": "16160"
  },
  {
    "text": "so on the left hand side of this diagram",
    "start": "16160",
    "end": "17880"
  },
  {
    "text": "you'll see um what the architecture for",
    "start": "17880",
    "end": "20359"
  },
  {
    "text": "a basic react agent is and this is a",
    "start": "20359",
    "end": "23119"
  },
  {
    "text": "very simple architecture we're going to",
    "start": "23119",
    "end": "24720"
  },
  {
    "text": "have one llm in the middle that agent",
    "start": "24720",
    "end": "27160"
  },
  {
    "text": "node and all that llm is going to do is",
    "start": "27160",
    "end": "29359"
  },
  {
    "text": "it's going to determine",
    "start": "29359",
    "end": "30480"
  },
  {
    "text": "whether to call some tools or to respond",
    "start": "30480",
    "end": "32758"
  },
  {
    "text": "to the user um and after it calls uh a",
    "start": "32759",
    "end": "35680"
  },
  {
    "text": "tool uh those tool responses will always",
    "start": "35680",
    "end": "38040"
  },
  {
    "text": "be forwarded straight back to the llm",
    "start": "38040",
    "end": "40039"
  },
  {
    "text": "who will then be called again to",
    "start": "40039",
    "end": "41719"
  },
  {
    "text": "determine whether it needs to call more",
    "start": "41719",
    "end": "43039"
  },
  {
    "text": "tools or whether it can just respond if",
    "start": "43039",
    "end": "45840"
  },
  {
    "text": "we want to structure our output what we",
    "start": "45840",
    "end": "47800"
  },
  {
    "text": "can do is we can add a respond node",
    "start": "47800",
    "end": "50320"
  },
  {
    "text": "right before the llm responds to the",
    "start": "50320",
    "end": "53120"
  },
  {
    "text": "user and what this respond node is going",
    "start": "53120",
    "end": "54840"
  },
  {
    "text": "to do is it's going to take the output",
    "start": "54840",
    "end": "56239"
  },
  {
    "text": "of that llm and it's going to format it",
    "start": "56239",
    "end": "58840"
  },
  {
    "text": "into the structured form that we wish to",
    "start": "58840",
    "end": "61039"
  },
  {
    "text": "respond to our user with it can be",
    "start": "61039",
    "end": "63079"
  },
  {
    "text": "really helpful to respond in structured",
    "start": "63079",
    "end": "65080"
  },
  {
    "text": "formats because this increases the",
    "start": "65080",
    "end": "67960"
  },
  {
    "text": "reliability of our agent because we are",
    "start": "67960",
    "end": "71200"
  },
  {
    "text": "having the same exact expected output",
    "start": "71200",
    "end": "73479"
  },
  {
    "text": "every time we run it and therefore we",
    "start": "73479",
    "end": "75240"
  },
  {
    "text": "can use this agent uh in larger software",
    "start": "75240",
    "end": "77799"
  },
  {
    "text": "systems since it's more deterministic",
    "start": "77799",
    "end": "79799"
  },
  {
    "text": "and reliable um which is not always the",
    "start": "79799",
    "end": "82079"
  },
  {
    "text": "case with llms so now that we've got a",
    "start": "82079",
    "end": "85880"
  },
  {
    "text": "quick Refresh on what a basic react",
    "start": "85880",
    "end": "88200"
  },
  {
    "text": "agent is and how we're going to add",
    "start": "88200",
    "end": "89520"
  },
  {
    "text": "structure output let's go look at the",
    "start": "89520",
    "end": "91640"
  },
  {
    "text": "two different ways that we can configure",
    "start": "91640",
    "end": "94240"
  },
  {
    "text": "this respond",
    "start": "94240",
    "end": "96079"
  },
  {
    "text": "node the first way we can configure uh",
    "start": "96079",
    "end": "98880"
  },
  {
    "text": "this respond node is actually um by",
    "start": "98880",
    "end": "101720"
  },
  {
    "text": "adding an extra tool to our agent llm",
    "start": "101720",
    "end": "105320"
  },
  {
    "text": "and so you can see this blue box here",
    "start": "105320",
    "end": "107040"
  },
  {
    "text": "the response format tool this is going",
    "start": "107040",
    "end": "109560"
  },
  {
    "text": "to be a pantic model that we passed to",
    "start": "109560",
    "end": "111799"
  },
  {
    "text": "our llm and it's going to be able to",
    "start": "111799",
    "end": "113360"
  },
  {
    "text": "call that as a tool which is a very nice",
    "start": "113360",
    "end": "116399"
  },
  {
    "text": "feature of Lang chain once it's decided",
    "start": "116399",
    "end": "118960"
  },
  {
    "text": "to call this tool we're going to um",
    "start": "118960",
    "end": "121840"
  },
  {
    "text": "follow that blue arrow we're going to",
    "start": "121840",
    "end": "123799"
  },
  {
    "text": "format the response of that tool call",
    "start": "123799",
    "end": "126520"
  },
  {
    "text": "and then we're going to respond to the",
    "start": "126520",
    "end": "127680"
  },
  {
    "text": "user so the pros to this approach are",
    "start": "127680",
    "end": "130239"
  },
  {
    "text": "that we only have to use one llm as you",
    "start": "130239",
    "end": "132520"
  },
  {
    "text": "can see in the diagram which is going to",
    "start": "132520",
    "end": "134160"
  },
  {
    "text": "reduce latency and costs",
    "start": "134160",
    "end": "137280"
  },
  {
    "text": "however when we're only using one llm it",
    "start": "137280",
    "end": "140879"
  },
  {
    "text": "can be a little finicky so the llm could",
    "start": "140879",
    "end": "143640"
  },
  {
    "text": "fail to call any of the tools which is a",
    "start": "143640",
    "end": "146239"
  },
  {
    "text": "problem because in this case the llm",
    "start": "146239",
    "end": "147879"
  },
  {
    "text": "doesn't directly interact with the user",
    "start": "147879",
    "end": "150040"
  },
  {
    "text": "it's only interacting with the tools so",
    "start": "150040",
    "end": "151959"
  },
  {
    "text": "if it fails to call any tools uh We've",
    "start": "151959",
    "end": "154160"
  },
  {
    "text": "run into an issue similarly the llm",
    "start": "154160",
    "end": "156599"
  },
  {
    "text": "could call the response tool along with",
    "start": "156599",
    "end": "159080"
  },
  {
    "text": "other tools and that could be a problem",
    "start": "159080",
    "end": "161200"
  },
  {
    "text": "so these greenbox tools are intended to",
    "start": "161200",
    "end": "164440"
  },
  {
    "text": "answer the user's question while the",
    "start": "164440",
    "end": "166200"
  },
  {
    "text": "response tool is intended to respond to",
    "start": "166200",
    "end": "168080"
  },
  {
    "text": "the user but what happens if the llm",
    "start": "168080",
    "end": "170159"
  },
  {
    "text": "chooses both a greenbox tool and the",
    "start": "170159",
    "end": "172800"
  },
  {
    "text": "response tool well we have to deal with",
    "start": "172800",
    "end": "175159"
  },
  {
    "text": "that in our code somehow because most",
    "start": "175159",
    "end": "177239"
  },
  {
    "text": "likely the LM really wants to find out",
    "start": "177239",
    "end": "179879"
  },
  {
    "text": "more information and is not looking to",
    "start": "179879",
    "end": "181519"
  },
  {
    "text": "respond to the user yet but there might",
    "start": "181519",
    "end": "184480"
  },
  {
    "text": "be unique cases where it is trying to",
    "start": "184480",
    "end": "186760"
  },
  {
    "text": "respond to the user or it isn't trying",
    "start": "186760",
    "end": "190440"
  },
  {
    "text": "to use a tool at all and is just messing",
    "start": "190440",
    "end": "192080"
  },
  {
    "text": "up so we need to be sure that we're",
    "start": "192080",
    "end": "193879"
  },
  {
    "text": "careful with all those cases and these",
    "start": "193879",
    "end": "195599"
  },
  {
    "text": "are some of the risks that can arise",
    "start": "195599",
    "end": "197400"
  },
  {
    "text": "when using this",
    "start": "197400",
    "end": "199000"
  },
  {
    "text": "option the second option uses two llms",
    "start": "199000",
    "end": "202400"
  },
  {
    "text": "so as you can see our original uh llm",
    "start": "202400",
    "end": "205680"
  },
  {
    "text": "that uses tools is going to only have",
    "start": "205680",
    "end": "208280"
  },
  {
    "text": "those green box tools to it so only",
    "start": "208280",
    "end": "210000"
  },
  {
    "text": "those tools that provide it information",
    "start": "210000",
    "end": "212080"
  },
  {
    "text": "and once it's determined that it's done",
    "start": "212080",
    "end": "213959"
  },
  {
    "text": "calling tools that it doesn't need any",
    "start": "213959",
    "end": "215599"
  },
  {
    "text": "more tool calls it's going to route to",
    "start": "215599",
    "end": "218040"
  },
  {
    "text": "the response node and that response node",
    "start": "218040",
    "end": "220280"
  },
  {
    "text": "instead of just formatting the tool call",
    "start": "220280",
    "end": "222879"
  },
  {
    "text": "uh like we saw in option one is actually",
    "start": "222879",
    "end": "225560"
  },
  {
    "text": "going to call a second llm and this",
    "start": "225560",
    "end": "227239"
  },
  {
    "text": "second llm uh is going to be written",
    "start": "227239",
    "end": "229720"
  },
  {
    "text": "such that it's forced to respond in our",
    "start": "229720",
    "end": "232120"
  },
  {
    "text": "structured format and this is a really",
    "start": "232120",
    "end": "234439"
  },
  {
    "text": "nice feature of llms that we can force",
    "start": "234439",
    "end": "236959"
  },
  {
    "text": "them to respond in a specific format so",
    "start": "236959",
    "end": "239560"
  },
  {
    "text": "the Pros to this version are that we are",
    "start": "239560",
    "end": "242599"
  },
  {
    "text": "virtually guaranteed structured output",
    "start": "242599",
    "end": "244760"
  },
  {
    "text": "because we're always going to reach the",
    "start": "244760",
    "end": "246439"
  },
  {
    "text": "second llm barring some really strange",
    "start": "246439",
    "end": "249360"
  },
  {
    "text": "loop with the llm and tools and since",
    "start": "249360",
    "end": "252319"
  },
  {
    "text": "this second llm is guaranteed to have",
    "start": "252319",
    "end": "254000"
  },
  {
    "text": "the right response format our overall",
    "start": "254000",
    "end": "255599"
  },
  {
    "text": "graph is guaranteed to have the right",
    "start": "255599",
    "end": "257199"
  },
  {
    "text": "response format which is really nice",
    "start": "257199",
    "end": "259320"
  },
  {
    "text": "however to guarantee this response",
    "start": "259320",
    "end": "261560"
  },
  {
    "text": "format we're going to have to introduce",
    "start": "261560",
    "end": "263000"
  },
  {
    "text": "another llm call which is going to mean",
    "start": "263000",
    "end": "265080"
  },
  {
    "text": "higher latency and higher costs and in",
    "start": "265080",
    "end": "267639"
  },
  {
    "text": "addition the first llm actually lacks",
    "start": "267639",
    "end": "269479"
  },
  {
    "text": "the context of the response format and",
    "start": "269479",
    "end": "271720"
  },
  {
    "text": "what I mean by that is this first LM",
    "start": "271720",
    "end": "273919"
  },
  {
    "text": "here maybe we ask it a question like",
    "start": "273919",
    "end": "276080"
  },
  {
    "text": "what's the weather and the response",
    "start": "276080",
    "end": "278600"
  },
  {
    "text": "format say we want to respond with the",
    "start": "278600",
    "end": "281479"
  },
  {
    "text": "wind",
    "start": "281479",
    "end": "283039"
  },
  {
    "text": "speed perhaps that first LM doesn't know",
    "start": "283039",
    "end": "285880"
  },
  {
    "text": "that though because we haven't provided",
    "start": "285880",
    "end": "287360"
  },
  {
    "text": "it any context on the response format so",
    "start": "287360",
    "end": "289160"
  },
  {
    "text": "when the user says what's the weather it",
    "start": "289160",
    "end": "290840"
  },
  {
    "text": "only looks up the temperature or the",
    "start": "290840",
    "end": "293560"
  },
  {
    "text": "precipitation or whatever and then it it",
    "start": "293560",
    "end": "297240"
  },
  {
    "text": "finishes quering that information it",
    "start": "297240",
    "end": "299000"
  },
  {
    "text": "thinks it's solved to the question and",
    "start": "299000",
    "end": "300880"
  },
  {
    "text": "it goes to that second llm and now that",
    "start": "300880",
    "end": "302960"
  },
  {
    "text": "second llm is trying to format this",
    "start": "302960",
    "end": "304840"
  },
  {
    "text": "response with the wind speed but it",
    "start": "304840",
    "end": "306800"
  },
  {
    "text": "doesn't find it anywhere so that's one",
    "start": "306800",
    "end": "309440"
  },
  {
    "text": "of the cons uh in this",
    "start": "309440",
    "end": "312000"
  },
  {
    "text": "format but now that we've ran through a",
    "start": "312000",
    "end": "314840"
  },
  {
    "text": "quick overview of both of the formats",
    "start": "314840",
    "end": "316639"
  },
  {
    "text": "let's dive into some code and see how",
    "start": "316639",
    "end": "318800"
  },
  {
    "text": "these work in the real",
    "start": "318800",
    "end": "321520"
  },
  {
    "start": "320000",
    "end": "568000"
  },
  {
    "text": "world all right so now we are in our",
    "start": "321520",
    "end": "325120"
  },
  {
    "text": "code repo for the first option where we",
    "start": "325120",
    "end": "328520"
  },
  {
    "text": "uh bind both of the the structured",
    "start": "328520",
    "end": "330479"
  },
  {
    "text": "output and the tools to query the",
    "start": "330479",
    "end": "332720"
  },
  {
    "text": "information to the same llm we only are",
    "start": "332720",
    "end": "335160"
  },
  {
    "text": "going to have a single llm in this graph",
    "start": "335160",
    "end": "337199"
  },
  {
    "text": "so we can start walking through the code",
    "start": "337199",
    "end": "338720"
  },
  {
    "text": "first we're going to Define our",
    "start": "338720",
    "end": "339759"
  },
  {
    "text": "structured output class in this case",
    "start": "339759",
    "end": "341840"
  },
  {
    "text": "it's going to be a pantic model that",
    "start": "341840",
    "end": "345560"
  },
  {
    "text": "mimics some sort of weather response",
    "start": "345560",
    "end": "347280"
  },
  {
    "text": "this is a very simple vanilla example",
    "start": "347280",
    "end": "350199"
  },
  {
    "text": "but you could make this as complicated",
    "start": "350199",
    "end": "351919"
  },
  {
    "text": "as you want next we're going to define",
    "start": "351919",
    "end": "353680"
  },
  {
    "text": "the input output and the state to our",
    "start": "353680",
    "end": "355639"
  },
  {
    "text": "graph so the input is just going to be",
    "start": "355639",
    "end": "357880"
  },
  {
    "text": "the messages State and that means it's",
    "start": "357880",
    "end": "359840"
  },
  {
    "text": "just going to be a list of messages uh",
    "start": "359840",
    "end": "361800"
  },
  {
    "text": "our output is just going to be our final",
    "start": "361800",
    "end": "363800"
  },
  {
    "text": "response which is going to be of type",
    "start": "363800",
    "end": "365319"
  },
  {
    "text": "weather response that structured output",
    "start": "365319",
    "end": "367120"
  },
  {
    "text": "that we had above and then our overall",
    "start": "367120",
    "end": "369080"
  },
  {
    "text": "state is going to contain both the input",
    "start": "369080",
    "end": "371360"
  },
  {
    "text": "and the output state so it's both going",
    "start": "371360",
    "end": "373240"
  },
  {
    "text": "to keep track of a list of messages by",
    "start": "373240",
    "end": "375599"
  },
  {
    "text": "uh subclassing from messages State and",
    "start": "375599",
    "end": "377759"
  },
  {
    "text": "then it's also going to keep track of",
    "start": "377759",
    "end": "379720"
  },
  {
    "text": "the final",
    "start": "379720",
    "end": "380680"
  },
  {
    "text": "response next we can Define our tools",
    "start": "380680",
    "end": "383599"
  },
  {
    "text": "and our model so we're going to be using",
    "start": "383599",
    "end": "385680"
  },
  {
    "text": "the python tool decorator here to define",
    "start": "385680",
    "end": "388160"
  },
  {
    "text": "the get weather tool and the get weather",
    "start": "388160",
    "end": "390440"
  },
  {
    "text": "tool can be written as a python function",
    "start": "390440",
    "end": "392880"
  },
  {
    "text": "with the tool decorator right above",
    "start": "392880",
    "end": "394599"
  },
  {
    "text": "which is really cool uh and makes",
    "start": "394599",
    "end": "396800"
  },
  {
    "text": "turning any python function into a tool",
    "start": "396800",
    "end": "399720"
  },
  {
    "text": "super simple um and a really cool thing",
    "start": "399720",
    "end": "403080"
  },
  {
    "text": "here or at least something I think is",
    "start": "403080",
    "end": "404639"
  },
  {
    "text": "cool is that we can bind both this get",
    "start": "404639",
    "end": "406840"
  },
  {
    "text": "weather and this weather response uh to",
    "start": "406840",
    "end": "410199"
  },
  {
    "text": "our model and the reason I think this is",
    "start": "410199",
    "end": "412880"
  },
  {
    "text": "cool is because get weather was defined",
    "start": "412880",
    "end": "414560"
  },
  {
    "text": "as a python function that we added a",
    "start": "414560",
    "end": "416080"
  },
  {
    "text": "decorator to and weather response was",
    "start": "416080",
    "end": "418360"
  },
  {
    "text": "defined as a pantic base model but we",
    "start": "418360",
    "end": "420560"
  },
  {
    "text": "can pass both of those in and under the",
    "start": "420560",
    "end": "422560"
  },
  {
    "text": "hood L chain is going to deal with",
    "start": "422560",
    "end": "424240"
  },
  {
    "text": "converting those to the proper format",
    "start": "424240",
    "end": "426319"
  },
  {
    "text": "for the llm to interact with which is",
    "start": "426319",
    "end": "428120"
  },
  {
    "text": "really nice so now we have our single",
    "start": "428120",
    "end": "430680"
  },
  {
    "text": "llm which both has the get weather tool",
    "start": "430680",
    "end": "432919"
  },
  {
    "text": "and the weather response tool so it",
    "start": "432919",
    "end": "434280"
  },
  {
    "text": "should not only be able to solve uh the",
    "start": "434280",
    "end": "436560"
  },
  {
    "text": "user's query but it should also be able",
    "start": "436560",
    "end": "438840"
  },
  {
    "text": "to respond to the user in the correct",
    "start": "438840",
    "end": "440800"
  },
  {
    "text": "format so next we can Define our graph",
    "start": "440800",
    "end": "443160"
  },
  {
    "text": "nodes and we're going to have two nodes",
    "start": "443160",
    "end": "444840"
  },
  {
    "text": "we're going to have our call model node",
    "start": "444840",
    "end": "446280"
  },
  {
    "text": "which is going to actually call this",
    "start": "446280",
    "end": "447759"
  },
  {
    "text": "model and then we're going to to have",
    "start": "447759",
    "end": "449759"
  },
  {
    "text": "our respond node so our respond node is",
    "start": "449759",
    "end": "452120"
  },
  {
    "text": "just going to take the last tool call",
    "start": "452120",
    "end": "454919"
  },
  {
    "text": "that was made from our model and that",
    "start": "454919",
    "end": "456960"
  },
  {
    "text": "last tool call is going to be the",
    "start": "456960",
    "end": "458400"
  },
  {
    "text": "weather response tool call so once we're",
    "start": "458400",
    "end": "460240"
  },
  {
    "text": "at the respond node that means the",
    "start": "460240",
    "end": "461919"
  },
  {
    "text": "weather response tool got called and",
    "start": "461919",
    "end": "464360"
  },
  {
    "text": "we're going to take that the arguments",
    "start": "464360",
    "end": "466639"
  },
  {
    "text": "from that tool call and we're just going",
    "start": "466639",
    "end": "467960"
  },
  {
    "text": "to pass those to our weather response",
    "start": "467960",
    "end": "469879"
  },
  {
    "text": "object and then we will return that as",
    "start": "469879",
    "end": "471639"
  },
  {
    "text": "our final",
    "start": "471639",
    "end": "473960"
  },
  {
    "text": "response next we can Define our routing",
    "start": "473960",
    "end": "476400"
  },
  {
    "text": "function which is going to inform our",
    "start": "476400",
    "end": "478159"
  },
  {
    "text": "graph what's step it should take next",
    "start": "478159",
    "end": "480800"
  },
  {
    "text": "based on the output of the llm so if the",
    "start": "480800",
    "end": "483360"
  },
  {
    "text": "llm outputs a single tool call and that",
    "start": "483360",
    "end": "485800"
  },
  {
    "text": "tool call is the weather response tool",
    "start": "485800",
    "end": "487599"
  },
  {
    "text": "call we're going to respond to the user",
    "start": "487599",
    "end": "489840"
  },
  {
    "text": "and otherwise we are going to go use our",
    "start": "489840",
    "end": "493639"
  },
  {
    "text": "other tools so in this case the get",
    "start": "493639",
    "end": "495639"
  },
  {
    "text": "weather tools but any tools that are",
    "start": "495639",
    "end": "498360"
  },
  {
    "text": "helping us answer the question and not",
    "start": "498360",
    "end": "500440"
  },
  {
    "text": "respond to the user and note that we",
    "start": "500440",
    "end": "503240"
  },
  {
    "text": "make that check for the tool call length",
    "start": "503240",
    "end": "505520"
  },
  {
    "text": "being one because we want to ensure that",
    "start": "505520",
    "end": "508280"
  },
  {
    "text": "the llm is only responding to the user",
    "start": "508280",
    "end": "510680"
  },
  {
    "text": "it doesn't have any more information to",
    "start": "510680",
    "end": "512240"
  },
  {
    "text": "get um and that is going to be the case",
    "start": "512240",
    "end": "515599"
  },
  {
    "text": "that we respond so now that we've done",
    "start": "515599",
    "end": "518919"
  },
  {
    "text": "all of that we can Define our graph",
    "start": "518919",
    "end": "520760"
  },
  {
    "text": "structure which is fairly simple we're",
    "start": "520760",
    "end": "523399"
  },
  {
    "text": "going to be defining a state graph with",
    "start": "523399",
    "end": "525839"
  },
  {
    "text": "our uh afor mentioned agent state agent",
    "start": "525839",
    "end": "528680"
  },
  {
    "text": "input and agent output we're going to",
    "start": "528680",
    "end": "530480"
  },
  {
    "text": "add our three nodes the agent node the",
    "start": "530480",
    "end": "532320"
  },
  {
    "text": "tools node and the respond node we're",
    "start": "532320",
    "end": "534600"
  },
  {
    "text": "going to set our entry point as agent",
    "start": "534600",
    "end": "536560"
  },
  {
    "text": "the graph is going to start by calling",
    "start": "536560",
    "end": "538040"
  },
  {
    "text": "the llm uh and and then we're going to",
    "start": "538040",
    "end": "540279"
  },
  {
    "text": "add our conditional edges from the llm",
    "start": "540279",
    "end": "543160"
  },
  {
    "text": "to the should continue function which we",
    "start": "543160",
    "end": "545120"
  },
  {
    "text": "just defined above and lastly we'll add",
    "start": "545120",
    "end": "547480"
  },
  {
    "text": "it an edge from the tools to the agent",
    "start": "547480",
    "end": "549519"
  },
  {
    "text": "so as soon as we call tools we're going",
    "start": "549519",
    "end": "550839"
  },
  {
    "text": "to get that response right back to the",
    "start": "550839",
    "end": "552680"
  },
  {
    "text": "llm and then we're going to add an edge",
    "start": "552680",
    "end": "554399"
  },
  {
    "text": "from the respond node to the end of the",
    "start": "554399",
    "end": "556120"
  },
  {
    "text": "graph once we hit the respond node we",
    "start": "556120",
    "end": "558240"
  },
  {
    "text": "are done lastly we'll compile this graph",
    "start": "558240",
    "end": "560519"
  },
  {
    "text": "so that we can use it in L graph studio",
    "start": "560519",
    "end": "562800"
  },
  {
    "text": "so now that we're done with all that",
    "start": "562800",
    "end": "564160"
  },
  {
    "text": "let's head over to the studio and see",
    "start": "564160",
    "end": "566000"
  },
  {
    "text": "how this uh Works in action",
    "start": "566000",
    "end": "569600"
  },
  {
    "start": "568000",
    "end": "670000"
  },
  {
    "text": "all right now we're in the Lang graph",
    "start": "569600",
    "end": "570920"
  },
  {
    "text": "studio and on the left hand side you can",
    "start": "570920",
    "end": "572800"
  },
  {
    "text": "see our graph visualization very nicely",
    "start": "572800",
    "end": "575839"
  },
  {
    "text": "and we can input our question to our",
    "start": "575839",
    "end": "578800"
  },
  {
    "text": "graph so we're going to ask it what is",
    "start": "578800",
    "end": "580560"
  },
  {
    "text": "the weather in SF and we're going to see",
    "start": "580560",
    "end": "583560"
  },
  {
    "text": "the graph running both visually on the",
    "start": "583560",
    "end": "585399"
  },
  {
    "text": "leftand side and on the right hand side",
    "start": "585399",
    "end": "586839"
  },
  {
    "text": "we're going to get a stream of the",
    "start": "586839",
    "end": "588360"
  },
  {
    "text": "output so perfect we see that the AI",
    "start": "588360",
    "end": "592000"
  },
  {
    "text": "first calls the get weather tool which",
    "start": "592000",
    "end": "593920"
  },
  {
    "text": "then returns it its response and then it",
    "start": "593920",
    "end": "597040"
  },
  {
    "text": "calls the weather response tool which",
    "start": "597040",
    "end": "599040"
  },
  {
    "text": "rout it to the respond node and then our",
    "start": "599040",
    "end": "601959"
  },
  {
    "text": "final response is exactly what we are",
    "start": "601959",
    "end": "604160"
  },
  {
    "text": "hoping for this structured weather",
    "start": "604160",
    "end": "606120"
  },
  {
    "text": "response object with the wind direction",
    "start": "606120",
    "end": "607680"
  },
  {
    "text": "the temperature and the wind speed and",
    "start": "607680",
    "end": "609680"
  },
  {
    "text": "now we can actually open this run in",
    "start": "609680",
    "end": "611480"
  },
  {
    "text": "lsmith and verify that everything worked",
    "start": "611480",
    "end": "614519"
  },
  {
    "text": "as expected",
    "start": "614519",
    "end": "616640"
  },
  {
    "text": "so as it loads we can see that our",
    "start": "616640",
    "end": "619920"
  },
  {
    "text": "rendered output was exactly what we",
    "start": "619920",
    "end": "622839"
  },
  {
    "text": "expected which is great so the output",
    "start": "622839",
    "end": "625560"
  },
  {
    "text": "from the studio matches the output in",
    "start": "625560",
    "end": "627440"
  },
  {
    "text": "lsmith and then on the left hand hand",
    "start": "627440",
    "end": "629560"
  },
  {
    "text": "side we can actually see the exact trace",
    "start": "629560",
    "end": "631560"
  },
  {
    "text": "of what went on so we can see the nodes",
    "start": "631560",
    "end": "634440"
  },
  {
    "text": "that got called so it called the agent",
    "start": "634440",
    "end": "637560"
  },
  {
    "text": "node the tools node the agent node and",
    "start": "637560",
    "end": "639920"
  },
  {
    "text": "then the respond node which is uh the",
    "start": "639920",
    "end": "642240"
  },
  {
    "text": "flow that we were hoping to receive and",
    "start": "642240",
    "end": "644440"
  },
  {
    "text": "then if you wanted to further debug",
    "start": "644440",
    "end": "645880"
  },
  {
    "text": "what's going on you could dive into each",
    "start": "645880",
    "end": "647680"
  },
  {
    "text": "of these llm calls looking at the input",
    "start": "647680",
    "end": "650320"
  },
  {
    "text": "and the output uh we're not going to run",
    "start": "650320",
    "end": "652600"
  },
  {
    "text": "through all of that right now but lsmith",
    "start": "652600",
    "end": "654519"
  },
  {
    "text": "is a great place to do all of your",
    "start": "654519",
    "end": "657240"
  },
  {
    "text": "debugging and it couples really nice ly",
    "start": "657240",
    "end": "659760"
  },
  {
    "text": "with the front end UI that you get from",
    "start": "659760",
    "end": "661200"
  },
  {
    "text": "langra Studio so now that we've taken a",
    "start": "661200",
    "end": "664040"
  },
  {
    "text": "look at Option One let's go explore the",
    "start": "664040",
    "end": "666720"
  },
  {
    "text": "second option where we use two different",
    "start": "666720",
    "end": "668560"
  },
  {
    "text": "llms to structure our output all right",
    "start": "668560",
    "end": "671680"
  },
  {
    "start": "670000",
    "end": "830000"
  },
  {
    "text": "so now I'm in the code for the second",
    "start": "671680",
    "end": "673720"
  },
  {
    "text": "option where we're going to have two",
    "start": "673720",
    "end": "674800"
  },
  {
    "text": "llms I'm going to skip over defining the",
    "start": "674800",
    "end": "677320"
  },
  {
    "text": "weather response and our input output",
    "start": "677320",
    "end": "680160"
  },
  {
    "text": "and graph State because those are the",
    "start": "680160",
    "end": "682240"
  },
  {
    "text": "exact same as they were defined in",
    "start": "682240",
    "end": "684040"
  },
  {
    "text": "option one so you can go back in the",
    "start": "684040",
    "end": "686399"
  },
  {
    "text": "video to look at those if you want",
    "start": "686399",
    "end": "690000"
  },
  {
    "text": "the first uh difference we're going to",
    "start": "690000",
    "end": "691920"
  },
  {
    "text": "have between these two options is that",
    "start": "691920",
    "end": "693839"
  },
  {
    "text": "we're defining two models here and so",
    "start": "693839",
    "end": "696600"
  },
  {
    "text": "the first model is just going to have",
    "start": "696600",
    "end": "698040"
  },
  {
    "text": "the get weather tool binded to it so as",
    "start": "698040",
    "end": "700240"
  },
  {
    "text": "you can see our tools definition is now",
    "start": "700240",
    "end": "702480"
  },
  {
    "text": "a list of length one and it just",
    "start": "702480",
    "end": "704279"
  },
  {
    "text": "contains the get weather tool and then",
    "start": "704279",
    "end": "705959"
  },
  {
    "text": "we're going to have a second model",
    "start": "705959",
    "end": "707120"
  },
  {
    "text": "called the model with structured output",
    "start": "707120",
    "end": "708920"
  },
  {
    "text": "and this model is going to use the dot",
    "start": "708920",
    "end": "711279"
  },
  {
    "text": "with structured output method from Lang",
    "start": "711279",
    "end": "713320"
  },
  {
    "text": "chain uh and we're going to pass the",
    "start": "713320",
    "end": "715160"
  },
  {
    "text": "weather response and now this model is",
    "start": "715160",
    "end": "717639"
  },
  {
    "text": "going to be guaranteed to always output",
    "start": "717639",
    "end": "720399"
  },
  {
    "text": "uh a response in the format of the",
    "start": "720399",
    "end": "723600"
  },
  {
    "text": "weather response pantic model so now we",
    "start": "723600",
    "end": "726720"
  },
  {
    "text": "can Define our graph nodes again our",
    "start": "726720",
    "end": "729959"
  },
  {
    "text": "Carl model node is basically identical",
    "start": "729959",
    "end": "732600"
  },
  {
    "text": "to the first option except this time",
    "start": "732600",
    "end": "734360"
  },
  {
    "text": "we're not using the model with uh the",
    "start": "734360",
    "end": "736880"
  },
  {
    "text": "response format bounded as well it only",
    "start": "736880",
    "end": "739079"
  },
  {
    "text": "has the the get weather tool we're going",
    "start": "739079",
    "end": "741279"
  },
  {
    "text": "to invoke that and return whatever the",
    "start": "741279",
    "end": "744399"
  },
  {
    "text": "result of that invocation is and now our",
    "start": "744399",
    "end": "746519"
  },
  {
    "text": "respond node is a",
    "start": "746519",
    "end": "748160"
  },
  {
    "text": "little more complicated so instead of",
    "start": "748160",
    "end": "750680"
  },
  {
    "text": "just passing the output of a tool call",
    "start": "750680",
    "end": "752600"
  },
  {
    "text": "we actually need to structure the output",
    "start": "752600",
    "end": "755639"
  },
  {
    "text": "somehow so we're going to use that model",
    "start": "755639",
    "end": "757320"
  },
  {
    "text": "with structured output and we're going",
    "start": "757320",
    "end": "758560"
  },
  {
    "text": "to invoke it on the content of the",
    "start": "758560",
    "end": "761240"
  },
  {
    "text": "second to last message so that second to",
    "start": "761240",
    "end": "763639"
  },
  {
    "text": "last message is going to be the prior",
    "start": "763639",
    "end": "767000"
  },
  {
    "text": "tool message in the conversation so if",
    "start": "767000",
    "end": "769680"
  },
  {
    "text": "you remember the flow what's going to",
    "start": "769680",
    "end": "770920"
  },
  {
    "text": "happen is it's going to go from agent to",
    "start": "770920",
    "end": "772680"
  },
  {
    "text": "Tool back to agent and then to respond",
    "start": "772680",
    "end": "775720"
  },
  {
    "text": "so once it's at respond that means that",
    "start": "775720",
    "end": "777480"
  },
  {
    "text": "two steps ago it was at the tool node",
    "start": "777480",
    "end": "779839"
  },
  {
    "text": "and so we can take that second to last",
    "start": "779839",
    "end": "782320"
  },
  {
    "text": "message grab the content from that tool",
    "start": "782320",
    "end": "784639"
  },
  {
    "text": "message so that's the output of the tool",
    "start": "784639",
    "end": "786600"
  },
  {
    "text": "what did the get WEA tool respond with",
    "start": "786600",
    "end": "788760"
  },
  {
    "text": "and then we just want to structure that",
    "start": "788760",
    "end": "791720"
  },
  {
    "text": "response we have to make one little",
    "start": "791720",
    "end": "793920"
  },
  {
    "text": "trick here by converting uh that tool",
    "start": "793920",
    "end": "795959"
  },
  {
    "text": "message into a human message because you",
    "start": "795959",
    "end": "797720"
  },
  {
    "text": "can't invoke an llm with just tool",
    "start": "797720",
    "end": "799680"
  },
  {
    "text": "message uh the llm is going to be",
    "start": "799680",
    "end": "801600"
  },
  {
    "text": "expected to be invoked with a human",
    "start": "801600",
    "end": "804120"
  },
  {
    "text": "message then we can Define our routing",
    "start": "804120",
    "end": "806959"
  },
  {
    "text": "function which is fairly similar to",
    "start": "806959",
    "end": "808880"
  },
  {
    "text": "option one uh but in this case the check",
    "start": "808880",
    "end": "810800"
  },
  {
    "text": "is a little simpler if there are no tool",
    "start": "810800",
    "end": "812560"
  },
  {
    "text": "calls that means we're going to go to",
    "start": "812560",
    "end": "814079"
  },
  {
    "text": "the with structured output node um and",
    "start": "814079",
    "end": "817120"
  },
  {
    "text": "if there is a tool call we're going to",
    "start": "817120",
    "end": "819120"
  },
  {
    "text": "use that tool and our graph definition",
    "start": "819120",
    "end": "822240"
  },
  {
    "text": "is the exact same as option one so I'm",
    "start": "822240",
    "end": "823920"
  },
  {
    "text": "going to skip over that and instead I'm",
    "start": "823920",
    "end": "825800"
  },
  {
    "text": "going to head back to langra Studio to",
    "start": "825800",
    "end": "827600"
  },
  {
    "text": "show you how this option looks on the",
    "start": "827600",
    "end": "829560"
  },
  {
    "text": "front",
    "start": "829560",
    "end": "830560"
  },
  {
    "start": "830000",
    "end": "923000"
  },
  {
    "text": "end all right now we are in langra",
    "start": "830560",
    "end": "833079"
  },
  {
    "text": "studio and we can see again our graph",
    "start": "833079",
    "end": "835839"
  },
  {
    "text": "nicely visualized on the left hand side",
    "start": "835839",
    "end": "838040"
  },
  {
    "text": "and we can input a question to it and",
    "start": "838040",
    "end": "841199"
  },
  {
    "text": "we're going to ask it this time what is",
    "start": "841199",
    "end": "843160"
  },
  {
    "text": "the weather in New York and once we",
    "start": "843160",
    "end": "845040"
  },
  {
    "text": "click submit we are going to see our",
    "start": "845040",
    "end": "846440"
  },
  {
    "text": "graph running on the left hand side we",
    "start": "846440",
    "end": "849120"
  },
  {
    "text": "can see the visualization of that and on",
    "start": "849120",
    "end": "850720"
  },
  {
    "text": "the right hand side we can see the",
    "start": "850720",
    "end": "851920"
  },
  {
    "text": "output getting streamed so we're going",
    "start": "851920",
    "end": "854199"
  },
  {
    "text": "to see our AI is first going to call the",
    "start": "854199",
    "end": "857040"
  },
  {
    "text": "get weather tool as we expected and then",
    "start": "857040",
    "end": "859079"
  },
  {
    "text": "the second response it has there's no",
    "start": "859079",
    "end": "860639"
  },
  {
    "text": "tool calls in this response and so",
    "start": "860639",
    "end": "862680"
  },
  {
    "text": "that's going to Route us to the respond",
    "start": "862680",
    "end": "864399"
  },
  {
    "text": "node which then calls our model with",
    "start": "864399",
    "end": "866600"
  },
  {
    "text": "structured output and as we can see here",
    "start": "866600",
    "end": "870160"
  },
  {
    "text": "it Returns the output in the exact",
    "start": "870160",
    "end": "872839"
  },
  {
    "text": "format that we would expect so we can",
    "start": "872839",
    "end": "875279"
  },
  {
    "text": "actually open this run in lsmith to",
    "start": "875279",
    "end": "878120"
  },
  {
    "text": "verify that everything worked as",
    "start": "878120",
    "end": "879680"
  },
  {
    "text": "expected and perfect on the left hand",
    "start": "879680",
    "end": "882000"
  },
  {
    "text": "side again we see the exact uh sequence",
    "start": "882000",
    "end": "886199"
  },
  {
    "text": "of nodes that we saw in the studio agent",
    "start": "886199",
    "end": "888519"
  },
  {
    "text": "tools agent respond which is exactly",
    "start": "888519",
    "end": "891120"
  },
  {
    "text": "what we expected and then we can verify",
    "start": "891120",
    "end": "894639"
  },
  {
    "text": "that that output is uh in the proper",
    "start": "894639",
    "end": "897279"
  },
  {
    "text": "format which it is in this case case and",
    "start": "897279",
    "end": "900199"
  },
  {
    "text": "then if you wanted to do more debugging",
    "start": "900199",
    "end": "902160"
  },
  {
    "text": "you could dive deeper into each of these",
    "start": "902160",
    "end": "903920"
  },
  {
    "text": "traces and see what's going",
    "start": "903920",
    "end": "907519"
  },
  {
    "text": "on that wraps it up for this video on",
    "start": "907519",
    "end": "910720"
  },
  {
    "text": "structuring the output of react agents I",
    "start": "910720",
    "end": "913440"
  },
  {
    "text": "hope you learned a little bit and I hope",
    "start": "913440",
    "end": "916160"
  },
  {
    "text": "that you can use what you've learned in",
    "start": "916160",
    "end": "918279"
  },
  {
    "text": "this video to build some cool projects",
    "start": "918279",
    "end": "920120"
  },
  {
    "text": "with Lang graph have a great rest of",
    "start": "920120",
    "end": "922000"
  },
  {
    "text": "your day",
    "start": "922000",
    "end": "925079"
  }
]
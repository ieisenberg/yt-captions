[
  {
    "text": "awesome guests as well then so we'll do some deep Dives on some of the leading",
    "start": "0",
    "end": "5460"
  },
  {
    "text": "open source models um before that minor Logistics this is being recorded",
    "start": "5460",
    "end": "11219"
  },
  {
    "text": "um so yes this is being corded you can access it at the link afterwards and we'll also put it up on YouTube in a day",
    "start": "11219",
    "end": "16800"
  },
  {
    "text": "or two um as the webinar is going on the format that we'll do is we'll do quick intros",
    "start": "16800",
    "end": "22260"
  },
  {
    "text": "we'll do 15 ish minutes from from each group and then go into General q a so as",
    "start": "22260",
    "end": "29640"
  },
  {
    "text": "you have questions that arise I'll be monitoring the chat but please put them in the Q a box on the right so if you",
    "start": "29640",
    "end": "35219"
  },
  {
    "text": "can see there's a chat section which most of you are probably in and then there's a little box with the question",
    "start": "35219",
    "end": "40440"
  },
  {
    "text": "mark under it called q a you can not only put questions there but you can also upload them so upload the ones that",
    "start": "40440",
    "end": "46140"
  },
  {
    "text": "you most want to see answered and we'll go through those uh in that order at the end",
    "start": "46140",
    "end": "51899"
  },
  {
    "text": "um there's lots of stuff in Lang chain today we're going to mostly be focused on or we're going to be entirely focused",
    "start": "51899",
    "end": "57239"
  },
  {
    "text": "on open source llms and what that means and obviously that actually probably touches every component of link chain",
    "start": "57239",
    "end": "63000"
  },
  {
    "text": "but in so much as we can keep the questions and discussion focused on open source llms let's definitely uh do that",
    "start": "63000",
    "end": "68939"
  },
  {
    "text": "we have a really unique opportunity here to learn from some of the best in the game so with that maybe we can start",
    "start": "68939",
    "end": "74280"
  },
  {
    "text": "with some introductions um Brandon do you want to start yeah sure uh hi everyone my name is",
    "start": "74280",
    "end": "81540"
  },
  {
    "text": "Brandon I am the founder and CEO of nomec and today I'm going to be talking to you guys about GPT for all how nomic",
    "start": "81540",
    "end": "88259"
  },
  {
    "text": "things about open source a little bit about open data and stuff like this",
    "start": "88259",
    "end": "93860"
  },
  {
    "text": "awesome and then Daniel do you want to go yeah so hi I'm Daniel I'm a machine",
    "start": "94500",
    "end": "99720"
  },
  {
    "text": "learning engineer at mosaic Kamal I mostly work on our composer and",
    "start": "99720",
    "end": "105659"
  },
  {
    "text": "streaming and llm Foundry libraries so kind of our whole like training run time uh yeah great to be here thanks for",
    "start": "105659",
    "end": "112439"
  },
  {
    "text": "having us Harrison thanks for joining and last but not least great yeah thanks uh thanks",
    "start": "112439",
    "end": "120060"
  },
  {
    "text": "Harrison nice to meet you Brendan and uh yeah thanks for joining everyone I think my name is bandish uh actually manage",
    "start": "120060",
    "end": "125579"
  },
  {
    "text": "the ml engineering team at mosaic um and I'm going to be tag teaming with Daniel that I talk about our open source llm",
    "start": "125579",
    "end": "131819"
  },
  {
    "text": "and our training and inferred stack awesome so as you can tell we've got",
    "start": "131819",
    "end": "138720"
  },
  {
    "text": "some awesome guests and we'll start off with uh Brandon doing a deep dive on gnomec and GPT for all and lots of good",
    "start": "138720",
    "end": "145800"
  },
  {
    "text": "stuff so take it away thank you uh let me just share my screen",
    "start": "145800",
    "end": "154260"
  },
  {
    "text": "all right looks like you all can see that hopefully you all can see that um as I said my name is Brandon I'm from",
    "start": "154260",
    "end": "161220"
  },
  {
    "text": "nomec uh and today I'm going to be talking to you a little bit about explainable and accessible AI",
    "start": "161220",
    "end": "167879"
  },
  {
    "text": "um and the reason I'm going to talk to you about this is It's really Nomex goal to improve the explainability and accessibility of AI and you know while",
    "start": "167879",
    "end": "175500"
  },
  {
    "text": "explainability and accessibility it might seem like they are distinct Concepts at first and indeed like each",
    "start": "175500",
    "end": "181200"
  },
  {
    "text": "has their own sort of like particulars to them uh you know we had known like see them as having a very important",
    "start": "181200",
    "end": "187200"
  },
  {
    "text": "intersection uh and the way that we think about these ideas I think is uh pretty well Illustrated in this Venn",
    "start": "187200",
    "end": "193860"
  },
  {
    "text": "diagram so on one side here we have the explainability piece where we're doing things like analyzing training data of",
    "start": "193860",
    "end": "199920"
  },
  {
    "text": "models modeling interventions we make there observing their outputs on the other side we have the accessibility",
    "start": "199920",
    "end": "205860"
  },
  {
    "text": "piece you know building models that uh can run in low resource environments or can run in sort of like privacy",
    "start": "205860",
    "end": "211920"
  },
  {
    "text": "constrained environments um but really what we see is the intersection of these two things is you",
    "start": "211920",
    "end": "217860"
  },
  {
    "text": "know a set of a set of sort of criteria you know open documentation open code open weights open data uh that we sort",
    "start": "217860",
    "end": "225360"
  },
  {
    "text": "of broadly call Open Source AI um and so you know looking at open",
    "start": "225360",
    "end": "231299"
  },
  {
    "text": "source AI as the intersection of sort of like explainability and accessibility I",
    "start": "231299",
    "end": "236459"
  },
  {
    "text": "think is really one of the core reasons why wynomic is really interested in moving that forward",
    "start": "236459",
    "end": "243540"
  },
  {
    "text": "um and one question you might ask is what makes a model you know open source there are a ton of models out there",
    "start": "243540",
    "end": "249120"
  },
  {
    "text": "nowadays they've all maybe got different subsets of them open source so perhaps an architecture but know data perhaps",
    "start": "249120",
    "end": "256260"
  },
  {
    "text": "you have only a subset of the weights perhaps no weights at all um maybe you don't have documentation",
    "start": "256260",
    "end": "262560"
  },
  {
    "text": "but we propose sort of a four item checklist to you know kind of guess and",
    "start": "262560",
    "end": "267900"
  },
  {
    "text": "check yourself about okay like is is this model sort of actually open source",
    "start": "267900",
    "end": "273180"
  },
  {
    "text": "um the easiest thing uh to sort of Open Source the least uh stringent requirement we think is open",
    "start": "273180",
    "end": "278880"
  },
  {
    "text": "documentation so this is uh you know a model card or a tech report or a paper",
    "start": "278880",
    "end": "284100"
  },
  {
    "text": "uh ideally with a methods section not that any major AI lab would release a",
    "start": "284100",
    "end": "289139"
  },
  {
    "text": "tech report without a methods section um that describes you know what is happening in your model",
    "start": "289139",
    "end": "294840"
  },
  {
    "text": "um not only is this critical for like accessibility because it lets people understand your method but it's critical",
    "start": "294840",
    "end": "299880"
  },
  {
    "text": "for explainability because without knowing what the system is doing it's going to be very hard to understand when",
    "start": "299880",
    "end": "305699"
  },
  {
    "text": "you should use it and debug it uh going sort of Beyond this we then get into open code",
    "start": "305699",
    "end": "311699"
  },
  {
    "text": "um and the observation here is open docs are often insufficient um for those of you that have been around in the AI Sphere for long enough",
    "start": "311699",
    "end": "319139"
  },
  {
    "text": "you'll remember the sort of like pre versus post layer Norm um discussion that was occurring",
    "start": "319139",
    "end": "325139"
  },
  {
    "text": "um where there was some documentation that showed that the layer Norm was in one place in the Transformer but if you",
    "start": "325139",
    "end": "330419"
  },
  {
    "text": "actually looked at the code it turned out it was in another place there was you know some questions around where it should actually go",
    "start": "330419",
    "end": "336600"
  },
  {
    "text": "um and the only way that you can actually resolve uh questions like this uh is by diving into the code so you",
    "start": "336600",
    "end": "343139"
  },
  {
    "text": "know again like critical for the explainability access or uh sort of aspect in terms of trying to figure out",
    "start": "343139",
    "end": "349139"
  },
  {
    "text": "what's actually going on um the next thing is open waste right so uh the observation here is a lot of",
    "start": "349139",
    "end": "357120"
  },
  {
    "text": "models are going to be tested on some Benchmark data set um it's probably going to be the case",
    "start": "357120",
    "end": "363120"
  },
  {
    "text": "that there's a mismatch between that Benchmark data set and whatever you want to use the model on Downstream or",
    "start": "363120",
    "end": "368520"
  },
  {
    "text": "however that model is being deployed often it's just like the LM evaluation harness or something like this",
    "start": "368520",
    "end": "375240"
  },
  {
    "text": "um or like Helm maybe um but really the the question that practitioners should be asking is how",
    "start": "375240",
    "end": "381419"
  },
  {
    "text": "does this model perform in my operating domain and so Open dates gives a or open weights gives us the ability to actually",
    "start": "381419",
    "end": "388020"
  },
  {
    "text": "like test these models on particular operating domains that are you know task specific which is sort of critical for",
    "start": "388020",
    "end": "394560"
  },
  {
    "text": "responsibly deploying these things uh and then the last thing that I want to comment here on is open data",
    "start": "394560",
    "end": "401639"
  },
  {
    "text": "um what we have found at nomec and uh I think what Mosaic will agree on maybe they'll comment on it in their",
    "start": "401639",
    "end": "407039"
  },
  {
    "text": "presentation is the idea that uh the training data itself really uh dictates a lot of the behavior of these models",
    "start": "407039",
    "end": "413520"
  },
  {
    "text": "and so having uh some kind of open training data is really going to uh one",
    "start": "413520",
    "end": "419460"
  },
  {
    "text": "improve your ability to understand like why a model is behaving in certain ways um and two it's going to allow you to",
    "start": "419460",
    "end": "426120"
  },
  {
    "text": "you know properly attribute um that models maybe behaviors or ideas back to the training data itself again",
    "start": "426120",
    "end": "433620"
  },
  {
    "text": "not that any major AI lab would systematically pirate training data from the entire internet for their own profit",
    "start": "433620",
    "end": "439500"
  },
  {
    "text": "uh but anyway this is sort of how we think about whether or not a model is um",
    "start": "439500",
    "end": "444599"
  },
  {
    "text": "open source and now I'm going to go into a little bit um around you know once you have these",
    "start": "444599",
    "end": "450419"
  },
  {
    "text": "open source components uh how might you use them to maybe explain a model",
    "start": "450419",
    "end": "455520"
  },
  {
    "text": "um and uh and then a little bit in a little bit how might uh you improve accessibility with them so the first",
    "start": "455520",
    "end": "460979"
  },
  {
    "text": "thing that we look at at nomec is you know training data analysis and I actually have a meme from Cody from",
    "start": "460979",
    "end": "466800"
  },
  {
    "text": "Mosaic on the right here which I think sums up the situation um pretty well uh where really like",
    "start": "466800",
    "end": "473039"
  },
  {
    "text": "there seems to be this resistance to actually like looking at your training data but it gives you such an outsized",
    "start": "473039",
    "end": "479220"
  },
  {
    "text": "ability to understand what is happening in your model um and nomic wanted to make it sort of",
    "start": "479220",
    "end": "485340"
  },
  {
    "text": "as easy and painless as possible to really dive in and explore your training data and so we built Atlas uh as a tool",
    "start": "485340",
    "end": "491940"
  },
  {
    "text": "to try and make make that as simple as possible um a Outlets interface in a second um",
    "start": "491940",
    "end": "497580"
  },
  {
    "text": "but we're going to do so through a case study of the koala model which is this open source bottle from there so looking",
    "start": "497580",
    "end": "503879"
  },
  {
    "text": "at our checklist like yeah great they have the you know model it's open they have some documentation on it",
    "start": "503879",
    "end": "509759"
  },
  {
    "text": "but one thing that you'll see is under the the section you know the method section where they talk about how they",
    "start": "509759",
    "end": "515159"
  },
  {
    "text": "trained it you can see they trained it on the anthropic HH data set um and when you dive into the code uh what you see",
    "start": "515159",
    "end": "520919"
  },
  {
    "text": "that they did is they actually ran causal language model on the uh chosen responses of this data set",
    "start": "520919",
    "end": "527760"
  },
  {
    "text": "um and this is a data set that we've mapped with Atlas in the past so here's the anthropic HH data set",
    "start": "527760",
    "end": "533700"
  },
  {
    "text": "um all of the colors correspond to clusters and then the words are sort of like semantic labels that we've",
    "start": "533700",
    "end": "539279"
  },
  {
    "text": "extracted uh using GPT for all from those clusters um and one of the things that pops out",
    "start": "539279",
    "end": "544920"
  },
  {
    "text": "to us immediately is like this area up here uh that says racism like that might be something we don't want to train on",
    "start": "544920",
    "end": "551100"
  },
  {
    "text": "so if we zoom in uh and maybe look at something adjacent to it um which is this sort of like insult",
    "start": "551100",
    "end": "557700"
  },
  {
    "text": "cluster um one of the things that we'll end up finding is uh there's this sort of like",
    "start": "557700",
    "end": "563640"
  },
  {
    "text": "dialogue here where the model says something like saying offensive things and like clearly that's not something that we actually want to teach our",
    "start": "563640",
    "end": "570360"
  },
  {
    "text": "models so we shouldn't really be doing you know causal language modeling um on on these uh phrases there's a lot worse",
    "start": "570360",
    "end": "578100"
  },
  {
    "text": "stuff in this data set um that I can't put up on screen right now uh but I invite you to go and like",
    "start": "578100",
    "end": "583200"
  },
  {
    "text": "look through it for yourself the reason why it's in this data set is um a little bit subtle it's because this data set",
    "start": "583200",
    "end": "589560"
  },
  {
    "text": "isn't for language modeling it's for building reward models for rohf",
    "start": "589560",
    "end": "595260"
  },
  {
    "text": "um but regardless you know what the open data aspect of the koala model allows us",
    "start": "595260",
    "end": "601320"
  },
  {
    "text": "to do is like pinpoint the fact that there is toxic data that has been used to train it uh and then perhaps resolve",
    "start": "601320",
    "end": "607140"
  },
  {
    "text": "that for future model trains that would not be possible if you didn't actually have you know the open data portion of",
    "start": "607140",
    "end": "613019"
  },
  {
    "text": "it um I'm gonna skip the lie on example for now uh just from a Time perspective",
    "start": "613019",
    "end": "619380"
  },
  {
    "text": "um another thing that you might care about here is once you have identified maybe some some bad data in your",
    "start": "619380",
    "end": "625140"
  },
  {
    "text": "training set to understand the effect of removing it um this is some speculative work that we've done recently on",
    "start": "625140",
    "end": "631380"
  },
  {
    "text": "collaboration with Johns Hopkins where we changed two language models uh one is a baseline that's trained you know on a",
    "start": "631380",
    "end": "638160"
  },
  {
    "text": "bunch of classes from an encyclopedia via you know plants and animals and art uh and one of them uh is trained but",
    "start": "638160",
    "end": "645240"
  },
  {
    "text": "never sees any articles about plants uh and what we found is that inside of this",
    "start": "645240",
    "end": "650760"
  },
  {
    "text": "plant ablated model not only are the representations of plants affected but",
    "start": "650760",
    "end": "655800"
  },
  {
    "text": "we see sort of this bleed effect where removing plants uh from the training data also affects the representations of",
    "start": "655800",
    "end": "662160"
  },
  {
    "text": "animals and natural places and so we're super interested in trying to understand like four different mixes of training",
    "start": "662160",
    "end": "668220"
  },
  {
    "text": "data how these you know bleed sort of like affects um end up uh sort of like",
    "start": "668220",
    "end": "673260"
  },
  {
    "text": "coming to be and like how they interact um and then you know again there's uh this",
    "start": "673260",
    "end": "681000"
  },
  {
    "text": "idea as well of observability of these models so we talked a little bit before about like having open weights so that",
    "start": "681000",
    "end": "687600"
  },
  {
    "text": "you can actually test these things on your operating domain often that operating domain changes over time uh",
    "start": "687600",
    "end": "693180"
  },
  {
    "text": "and a lot of your errors will generally be uh you know traced back to a ship in in that uh sort of operating domain what",
    "start": "693180",
    "end": "699540"
  },
  {
    "text": "you see on the right here is an atlas map of Twitter uh and we sort of like filter it out and show you how that",
    "start": "699540",
    "end": "704760"
  },
  {
    "text": "evolves over time and yeah your screen might be a bit Frozen so",
    "start": "704760",
    "end": "710160"
  },
  {
    "text": "your screen share might have been a bit Frozen so might want to retry oh",
    "start": "710160",
    "end": "716820"
  },
  {
    "text": "that's not good yeah yeah",
    "start": "716820",
    "end": "721100"
  },
  {
    "text": "and that and now it's gone so yeah I turned it off let's see",
    "start": "722160",
    "end": "730560"
  },
  {
    "text": "and you guys see now potentially",
    "start": "730560",
    "end": "736459"
  },
  {
    "text": "um can't see anything",
    "start": "736980",
    "end": "742579"
  },
  {
    "text": "hello apologies everybody",
    "start": "742680",
    "end": "749100"
  },
  {
    "text": "can you at least hear me am I coming through okay yeah you're a little bit blurry the",
    "start": "749100",
    "end": "754560"
  },
  {
    "text": "audio is fine um the the video is a bit blurry there's some speculation that that no mixing is",
    "start": "754560",
    "end": "762839"
  },
  {
    "text": "is taking up all your CPU power so you might want to close that tab I don't know if that's true or not",
    "start": "762839",
    "end": "770579"
  },
  {
    "text": "I think it's uh my bad Hotel Wi-Fi uh is the situation here",
    "start": "770579",
    "end": "777139"
  },
  {
    "text": "let's see",
    "start": "780899",
    "end": "783620"
  },
  {
    "text": "yeah apologies for the technical difficulties",
    "start": "789360",
    "end": "793459"
  },
  {
    "text": "oh dear",
    "start": "801959",
    "end": "804980"
  },
  {
    "text": "you're getting one second no worries",
    "start": "808079",
    "end": "813920"
  },
  {
    "text": "goodbye camera uh we have moved to the I am tethering on my phone part of the uh",
    "start": "842040",
    "end": "847500"
  },
  {
    "text": "of the life here so hopefully that will work",
    "start": "847500",
    "end": "852959"
  },
  {
    "text": "all right how we looking I can see your screen cool",
    "start": "852959",
    "end": "859019"
  },
  {
    "text": "um I will get the head here just for the sake of time then uh",
    "start": "859019",
    "end": "864720"
  },
  {
    "text": "um and and we'll finish up um all right thanks everyone for bearing with me while we handle the Wi-Fi issues",
    "start": "864720",
    "end": "871560"
  },
  {
    "text": "um anyway so the the whole point of that being um open training data very very uh",
    "start": "871560",
    "end": "877920"
  },
  {
    "text": "critical for uh sort of like explainability in these models uh the other thing I'm going to talk to you",
    "start": "877920",
    "end": "883320"
  },
  {
    "text": "today about is accessible AI um and we sort of think of this uh in Gnome in two kind of buckets low",
    "start": "883320",
    "end": "890040"
  },
  {
    "text": "resource and private models um so one of the first things that you know you can do to kind of understand",
    "start": "890040",
    "end": "895920"
  },
  {
    "text": "the importance of low resource models is uh posit a couple of axioms and then you",
    "start": "895920",
    "end": "901139"
  },
  {
    "text": "know derive a theorem from it the axioms uh that we follow are one you know people with access to these models are",
    "start": "901139",
    "end": "907680"
  },
  {
    "text": "going through far economically outpace those without access to them uh and the second Axiom is there's large",
    "start": "907680",
    "end": "913320"
  },
  {
    "text": "populations of people that don't have access to the compute required to run these models I think anyone in this chat",
    "start": "913320",
    "end": "919500"
  },
  {
    "text": "that's tried to provision a GPU in the last six months will know how hard it is to even get something uh that yeah even",
    "start": "919500",
    "end": "926579"
  },
  {
    "text": "get a GPU and that is you know as someone that can pay at 25 an hour for",
    "start": "926579",
    "end": "931980"
  },
  {
    "text": "maybe you know an 8x800 right and so if you want to mitigate the risk of differential access to this technology",
    "start": "931980",
    "end": "938339"
  },
  {
    "text": "you need to develop systems that can run on limited compute um and one of the you know proudest",
    "start": "938339",
    "end": "944399"
  },
  {
    "text": "moments for me personally in sort of like building nomic was when I first saw this graph on the right which is the",
    "start": "944399",
    "end": "949860"
  },
  {
    "text": "geographic breakdown of our Discord server uh and we saw that the largest sort of like geography represented was",
    "start": "949860",
    "end": "955500"
  },
  {
    "text": "other um which I think really means that we're able to bring this technology you know to a lot of places that might not have",
    "start": "955500",
    "end": "962540"
  },
  {
    "text": "necessarily the compute access that that we do um so I think that is going to be really critical for the adoption of this",
    "start": "962540",
    "end": "968699"
  },
  {
    "text": "technology um the other thing that these low resource models kind of enable is the",
    "start": "968699",
    "end": "973800"
  },
  {
    "text": "idea of privacy um so you know right now if you want to use gpt4 uh you send all of your data to",
    "start": "973800",
    "end": "981360"
  },
  {
    "text": "open AI uh and then they promise not to train on it much in the same way that they promised that they were actually a",
    "start": "981360",
    "end": "988139"
  },
  {
    "text": "non-profit like five years ago um and so if you want to do that that's great but if you don't",
    "start": "988139",
    "end": "993720"
  },
  {
    "text": "um what you're going to probably want is something like an air gap system um and because you might not have say",
    "start": "993720",
    "end": "1000800"
  },
  {
    "text": "access to the latest and greatest GPU technology you can have those air gap systems be enabled uh by the ability to",
    "start": "1000800",
    "end": "1008480"
  },
  {
    "text": "run these models on uh sort of like low resource hardware and you know the Samsung story that maybe we've all heard",
    "start": "1008480",
    "end": "1014240"
  },
  {
    "text": "at this point uh where they leaked a bunch of you know notes and source code is sort of like the first of what I",
    "start": "1014240",
    "end": "1019759"
  },
  {
    "text": "imagine will be many cautionary tales about what happens um when you actually sort of get uh",
    "start": "1019759",
    "end": "1025699"
  },
  {
    "text": "put this data out into the while um and then the conclude here for the sake of time you know people might ask",
    "start": "1025699",
    "end": "1032240"
  },
  {
    "text": "us what's next um I think the closest thing that we have to releasing is adding the Falcon",
    "start": "1032240",
    "end": "1038600"
  },
  {
    "text": "7B model for the ecosystem so if you're looking uh if you're watching us closely you'll see that one of our awesome",
    "start": "1038600",
    "end": "1045079"
  },
  {
    "text": "Engineers Aaron opened this pull request last week adding you know compressed you know gtml support to Falcon 7B so be on",
    "start": "1045079",
    "end": "1052340"
  },
  {
    "text": "the lookout for that in the GPT for all ecosystems soon anyway",
    "start": "1052340",
    "end": "1058460"
  },
  {
    "text": "um thank you guys and happy to take any questions at the end",
    "start": "1058460",
    "end": "1064059"
  },
  {
    "text": "awesome thanks for that I I have one question kind of at the um",
    "start": "1064700",
    "end": "1070160"
  },
  {
    "text": "or so like what's been the and this is around kind of like the the",
    "start": "1070160",
    "end": "1076520"
  },
  {
    "text": "atlas thing that you uh showed earlier so I think one of the use cases you mentioned was like finding kind of like",
    "start": "1076520",
    "end": "1082100"
  },
  {
    "text": "pockets of data that you might wanna like like I guess like what are the main use cases you see people using kind of",
    "start": "1082100",
    "end": "1087980"
  },
  {
    "text": "like Atlas for specifically one kind of like is it is it like they use it as a",
    "start": "1087980",
    "end": "1093500"
  },
  {
    "text": "step before they train the models or they use that as the step when they're validating other models that have been trained like how and and if so for",
    "start": "1093500",
    "end": "1100280"
  },
  {
    "text": "either of those like what are the main like pockets of data that you see people being like really interested in",
    "start": "1100280",
    "end": "1105679"
  },
  {
    "text": "yes so we see it all over the place um we think of Atlas very much just as a",
    "start": "1105679",
    "end": "1110720"
  },
  {
    "text": "tool for exploring large unstructured data sets training data sets happen to be of that type the data sets produced",
    "start": "1110720",
    "end": "1117380"
  },
  {
    "text": "by models all so happen to be of that type",
    "start": "1117380",
    "end": "1122840"
  },
  {
    "text": "um and so it's applicable in you know both cases um in terms of like the actual specific",
    "start": "1122840",
    "end": "1128299"
  },
  {
    "text": "use cases we'll see one what I showed today which is the idea of going through your trading data understanding the composition understanding if you have",
    "start": "1128299",
    "end": "1134600"
  },
  {
    "text": "things that are toxic in there um you have the ability to like layer metadata on top of it which helps uh in",
    "start": "1134600",
    "end": "1140179"
  },
  {
    "text": "terms of like trying to understand what filters on top of your data might be doing",
    "start": "1140179",
    "end": "1145400"
  },
  {
    "text": "um and so you know some of the work that we did with Lyon let me uh attempt tempt fake here and maybe try and share my",
    "start": "1145400",
    "end": "1151700"
  },
  {
    "text": "screen as an answer to this question um so this is um 15 million images from",
    "start": "1151700",
    "end": "1157580"
  },
  {
    "text": "The Lion data set uh and we worked with them um to really try and understand",
    "start": "1157580",
    "end": "1164200"
  },
  {
    "text": "I think I think we may have tempted fate too much there by the dot safer work score and one of the things that we help",
    "start": "1167600",
    "end": "1173840"
  },
  {
    "text": "them find is they had this failure mode where they were",
    "start": "1173840",
    "end": "1179080"
  },
  {
    "text": "oh dear well c'est la vie",
    "start": "1180380",
    "end": "1184780"
  },
  {
    "text": "it worked for a little bit and we got it we got it we got a quick view of it",
    "start": "1185660",
    "end": "1190940"
  },
  {
    "text": "all right um hopefully you saw the sort of like hot spots popping up on the map for the",
    "start": "1190940",
    "end": "1196400"
  },
  {
    "text": "not save for work score um and those hot spots allowed us to sort of like investigate what is",
    "start": "1196400",
    "end": "1201440"
  },
  {
    "text": "happening along the decision boundaries there are a couple of Errors um that that we helped them find so uh",
    "start": "1201440",
    "end": "1207620"
  },
  {
    "text": "we we see it for the sort of like data quality um and and sort of like filtering step",
    "start": "1207620",
    "end": "1212780"
  },
  {
    "text": "as well awesome awesome all right",
    "start": "1212780",
    "end": "1218000"
  },
  {
    "text": "let's let's move on to the next one Mosaic you guys are up what do you what do you got for us",
    "start": "1218000",
    "end": "1224080"
  },
  {
    "text": "wrong button that's that's how I'm gonna lead off one second",
    "start": "1225140",
    "end": "1229960"
  },
  {
    "text": "all right you guys see the screen",
    "start": "1237799",
    "end": "1243320"
  },
  {
    "text": "yep all right great uh yeah so thanks again Harrison uh for having us here",
    "start": "1243320",
    "end": "1248660"
  },
  {
    "text": "um my name is as we mentioned before and I'm going to be tactivating this with Daniel I'm going to talk to you a little bit about our motivation uh you know why",
    "start": "1248660",
    "end": "1255740"
  },
  {
    "text": "does Mosaic exist and why we actually decided to train a large language model and open source it I'm going to hand it",
    "start": "1255740",
    "end": "1262039"
  },
  {
    "text": "off to Daniel uh talk about about the science and engineering uh that went into uh some of the decision making that",
    "start": "1262039",
    "end": "1267919"
  },
  {
    "text": "went into training that model um and I have the pleasure of playing the next slide game",
    "start": "1267919",
    "end": "1273679"
  },
  {
    "text": "um and then after that uh I'll uh I think I'll take it back and give you a quick overview of the actual tooling",
    "start": "1273679",
    "end": "1279380"
  },
  {
    "text": "that we use to train the model um so I think first motivation right like I think brief history lesson you",
    "start": "1279380",
    "end": "1286520"
  },
  {
    "text": "know I mean I think this is all within the last year or so but uh I think the real question we all wanted to ask",
    "start": "1286520",
    "end": "1291799"
  },
  {
    "text": "ourselves is like does one language model really rule them all them all right like is are we going to live in a",
    "start": "1291799",
    "end": "1297020"
  },
  {
    "text": "world where only a few companies that have the money the expertise the compute to train these large models um you know",
    "start": "1297020",
    "end": "1304220"
  },
  {
    "text": "just in a few large foundational models that are very capable is that the world that we want to live in",
    "start": "1304220",
    "end": "1309260"
  },
  {
    "text": "um we don't think so at mosaic and uh we actually think that there's probably a",
    "start": "1309260",
    "end": "1314360"
  },
  {
    "text": "place for both uh but we believe in the contrary we believe that you know numerous uh High utility AI systems are",
    "start": "1314360",
    "end": "1320720"
  },
  {
    "text": "going to emerge we believe that companies will want to create their own moats by training their own model uh we",
    "start": "1320720",
    "end": "1326000"
  },
  {
    "text": "also believe this will be more cost effective to kind of train your own model uh deploy it and remember cost here includes both training and",
    "start": "1326000",
    "end": "1332360"
  },
  {
    "text": "deployment costs right so uh it's actually important to kind of look at both of those hand in hand um and you know I think there's a whole",
    "start": "1332360",
    "end": "1338480"
  },
  {
    "text": "body of evidence kind of showing this right thought leaders are also kind of arguing that hey like high value",
    "start": "1338480",
    "end": "1344240"
  },
  {
    "text": "workflows are definitely going to be addressed by specialized AI systems not necessarily general purpose ones",
    "start": "1344240",
    "end": "1350059"
  },
  {
    "text": "um so I think there's a lot of kind of traction here um and this is a great place for us to kind of make a big big impact and so",
    "start": "1350059",
    "end": "1357919"
  },
  {
    "text": "um the future we believe in is kind of one for both we think that there's going to be a lot of folks out there that can probably just buy an external API uh for",
    "start": "1357919",
    "end": "1364760"
  },
  {
    "text": "some use cases and go develop applications around it and you know I",
    "start": "1364760",
    "end": "1369980"
  },
  {
    "text": "think like chain has done an amazing job kind of uh enabling people in this space and uh the area that we're going to also",
    "start": "1369980",
    "end": "1377419"
  },
  {
    "text": "be focusing on is enabling people to build their own models and deploy their own models um so I'm going to talk a",
    "start": "1377419",
    "end": "1383360"
  },
  {
    "text": "little bit about what we're offering in both of these spaces um but but yeah I think this is where we're",
    "start": "1383360",
    "end": "1389000"
  },
  {
    "text": "where we're really headed um the problem with this is that the perception is still that building your",
    "start": "1389000",
    "end": "1394640"
  },
  {
    "text": "own language models is really hard um it's expensive it requires a lot of compute there were numbers being thrown",
    "start": "1394640",
    "end": "1400580"
  },
  {
    "text": "around that training gpt3 cost like five to 12 million dollars at some point you know that's that's huge right that's a",
    "start": "1400580",
    "end": "1406460"
  },
  {
    "text": "that's a major capital expenditure for a lot of people um but we're here uh to kind of bust",
    "start": "1406460",
    "end": "1412039"
  },
  {
    "text": "this myth right the reality is different um training Elementals is accessible and",
    "start": "1412039",
    "end": "1418159"
  },
  {
    "text": "we've already seen a lot of use cases for this and we've seen a lot of instances of this for example just a few weeks ago uh replit with a very small",
    "start": "1418159",
    "end": "1425539"
  },
  {
    "text": "team two Engineers uh trained a model uh less than 100K on the Mosaic ml platform",
    "start": "1425539",
    "end": "1430580"
  },
  {
    "text": "this is a leading code completion model and you know B it'd be codex um you know there's been other instances",
    "start": "1430580",
    "end": "1436220"
  },
  {
    "text": "of for example Bloomberg GPT outperforming other Financial NLP tasks",
    "start": "1436220",
    "end": "1441620"
  },
  {
    "text": "um and of course the folks over at Stanford you know who built a model that you know performs very similar to text DaVinci",
    "start": "1441620",
    "end": "1448159"
  },
  {
    "text": "um three uh but being small you know and and some of these you know weren't commercially uh licensable and I'll kind",
    "start": "1448159",
    "end": "1455360"
  },
  {
    "text": "of talk about that in terms of of Mosaic ml um but but this is happening right this is",
    "start": "1455360",
    "end": "1461360"
  },
  {
    "text": "this is not an impossibility so what did we do um",
    "start": "1461360",
    "end": "1467000"
  },
  {
    "text": "at the end of the day we built this great platform we have some open source tooling um to build and train these platforms",
    "start": "1467000",
    "end": "1473480"
  },
  {
    "text": "and train these models rather um but really we had to train a model right we had to we had to demonstrate",
    "start": "1473480",
    "end": "1479480"
  },
  {
    "text": "that we can do this the proof is in the pudding so we decided to give the world a taste of the pudding uh so what we've",
    "start": "1479480",
    "end": "1485000"
  },
  {
    "text": "released so far is an MPT 7 billion uh think about it maybe as a demo of what's possible in the Mosaic ml platform",
    "start": "1485000",
    "end": "1492380"
  },
  {
    "text": "um we actually released four models the first is the base model",
    "start": "1492380",
    "end": "1497720"
  },
  {
    "text": "um we also fine-tuned three other models right a chat model an instruct model and the story writer model and uh story",
    "start": "1497720",
    "end": "1504320"
  },
  {
    "text": "writer has been very popular I'm sure there are folks who have played with this it's got a massive 65k context length we use it to Alibi for that",
    "start": "1504320",
    "end": "1511460"
  },
  {
    "text": "um and first thing we did is fed in The Great Gatsby and generate any new epilogue right and so",
    "start": "1511460",
    "end": "1516980"
  },
  {
    "text": "um and what's amazing about this is the base model uh just took 10 days and about a 200 000 to train uh and it's",
    "start": "1516980",
    "end": "1524419"
  },
  {
    "text": "it's commercially friendly licensed so you can start using this with your business you can start deploying these models",
    "start": "1524419",
    "end": "1529940"
  },
  {
    "text": "um and you can start fine-tuning this um along with the model we also released",
    "start": "1529940",
    "end": "1535640"
  },
  {
    "text": "um The llm Foundry uh which is our kind of large angle training stack and",
    "start": "1535640",
    "end": "1541820"
  },
  {
    "text": "um and basically it's using the same exact tooling that we used uh to train MPT sub billions so we've seen great",
    "start": "1541820",
    "end": "1547820"
  },
  {
    "text": "traction um and you know there's been a lot of amazing talks that some folks have worked on making it multimodal uh",
    "start": "1547820",
    "end": "1554539"
  },
  {
    "text": "there's awesome great tutorials and you know I think there's this uh there's also a great tutorial about how to work",
    "start": "1554539",
    "end": "1559580"
  },
  {
    "text": "with MPT 7 billion with with land chain um and so let me kind of stop there uh I",
    "start": "1559580",
    "end": "1566720"
  },
  {
    "text": "know it kind of flew through that but uh we'll hand it over to Daniel and actually kind of get to the meat of the presentation which is the science and",
    "start": "1566720",
    "end": "1572419"
  },
  {
    "text": "engineering behind trading this open source model yeah so I'm going to talk a bit about what went into creating MPT",
    "start": "1572419",
    "end": "1580059"
  },
  {
    "text": "7B so there are kind of three main components that I'll talk about a little bit the data the algorithms and",
    "start": "1580059",
    "end": "1586220"
  },
  {
    "text": "architecture and then kind of like the infrastructure for turning it the next slide so the data mix as Brandon was",
    "start": "1586220",
    "end": "1594260"
  },
  {
    "text": "talking about is very important for the final model that you get and there's still like a ton of science uh to do",
    "start": "1594260",
    "end": "1599480"
  },
  {
    "text": "here for sure so we started kind of with the the pre-training mix from various",
    "start": "1599480",
    "end": "1604820"
  },
  {
    "text": "uh published works so that's like a mix of some like common crawl data and some",
    "start": "1604820",
    "end": "1610580"
  },
  {
    "text": "other higher quality maybe more domain specific data like archive GitHub uh",
    "start": "1610580",
    "end": "1616400"
  },
  {
    "text": "Wikipedia and then we we did a bunch of experiments at uh smaller model scales",
    "start": "1616400",
    "end": "1621559"
  },
  {
    "text": "to kind of tune this mix a little bit and get a better idea of how different uh subsets impacted uh the outcomes and",
    "start": "1621559",
    "end": "1630860"
  },
  {
    "text": "a couple a few interesting decisions to call out uh we decided to focus on English for this model we're",
    "start": "1630860",
    "end": "1637520"
  },
  {
    "text": "we don't have like multilingual experts and a lot of this is like looking at the data looking at the models playing with",
    "start": "1637520",
    "end": "1643820"
  },
  {
    "text": "them um and so we decided to focus on English for this one",
    "start": "1643820",
    "end": "1648860"
  },
  {
    "text": "um and then we also found in our early experiments that repeating data is not the end of the world as uh maybe some",
    "start": "1648860",
    "end": "1656120"
  },
  {
    "text": "papers and some kind of the general kind of idea may have been so we repeated",
    "start": "1656120",
    "end": "1662299"
  },
  {
    "text": "some of these smaller data sets up to a small number of times to ultimately get to our uh one trillion data mix and then",
    "start": "1662299",
    "end": "1670880"
  },
  {
    "text": "at the end of the day there was a little bit of intuition thrown into it as well uh we we're pretty sure we wanted a",
    "start": "1670880",
    "end": "1677240"
  },
  {
    "text": "model that was good at some other stuff like code and had World Knowledge and so",
    "start": "1677240",
    "end": "1682640"
  },
  {
    "text": "there was a little bit of intuition in deciding the final data mix and over time we'll get better at the the science",
    "start": "1682640",
    "end": "1688400"
  },
  {
    "text": "side of it and hopefully rely a little bit less on the intuition to the next slide uh the next thing I'll",
    "start": "1688400",
    "end": "1695000"
  },
  {
    "text": "talk about a little bit is some of the model architecture and like training choices so the first one that is kind of front",
    "start": "1695000",
    "end": "1702500"
  },
  {
    "text": "and center especially with the long context model is that we chose to use alibi",
    "start": "1702500",
    "end": "1707659"
  },
  {
    "text": "um which allows us to dynamically extend the context length there's a bunch of",
    "start": "1707659",
    "end": "1713659"
  },
  {
    "text": "science again still to do about like how much the model actually uses the whole long context length and all of that but",
    "start": "1713659",
    "end": "1719900"
  },
  {
    "text": "it does remove kind of like the the first technical blocker to to playing with a long context model and we also",
    "start": "1719900",
    "end": "1726559"
  },
  {
    "text": "found that using Alibi actually produced better models and more stable training runs so those were two other kind of key",
    "start": "1726559",
    "end": "1733700"
  },
  {
    "text": "factors in choosing alibi and then for the optimizer um atom is probably the most popular one",
    "start": "1733700",
    "end": "1740440"
  },
  {
    "text": "while we were leading up to training this model the lion Optimizer came out",
    "start": "1740440",
    "end": "1745460"
  },
  {
    "text": "and we ran some experiments very quickly and found that it had no performance aggregate degradation relative to Adam",
    "start": "1745460",
    "end": "1752299"
  },
  {
    "text": "but it has a much smaller memory footprint so it was kind of strictly a win for us so we went with that and then",
    "start": "1752299",
    "end": "1759380"
  },
  {
    "text": "the last thing is kind of part of this maybe like a little bit of myth busting",
    "start": "1759380",
    "end": "1764659"
  },
  {
    "text": "that bonus was talking about for all of our models so far we have only used fsdp so that's fully sharded",
    "start": "1764659",
    "end": "1771980"
  },
  {
    "text": "data parallel there's no tensor parallels and there's no pipeline parallelism",
    "start": "1771980",
    "end": "1777559"
  },
  {
    "text": "and this means that the code is much simpler first of all and much more accessible to extend and read and also",
    "start": "1777559",
    "end": "1787100"
  },
  {
    "text": "kind of helps us improve iteration velocity so I've talked about kind of about all",
    "start": "1787100",
    "end": "1795500"
  },
  {
    "text": "these experiments and the model uh yeah sorry next slide thanks um but what is it that kind of lets us",
    "start": "1795500",
    "end": "1801020"
  },
  {
    "text": "do all of this easily so we've worked really hard to build a good software and infrastructure to do experiments and",
    "start": "1801020",
    "end": "1809240"
  },
  {
    "text": "good science and reliably produce models and we've talked a bunch about in our",
    "start": "1809240",
    "end": "1815179"
  },
  {
    "text": "blog so I encourage you to to check that out um but it's also very important for us",
    "start": "1815179",
    "end": "1822140"
  },
  {
    "text": "because this is the stack that our customers using our customers are using and this is also our open source deck so",
    "start": "1822140",
    "end": "1830419"
  },
  {
    "text": "uh all of the code that we use to train MPT 7B uh bondage will talk a little bit",
    "start": "1830419",
    "end": "1835640"
  },
  {
    "text": "about the difference between the open source stack and our platform but all of the like main driving code components",
    "start": "1835640",
    "end": "1840919"
  },
  {
    "text": "are open source and there's a bunch of nice stuff in all of that open source",
    "start": "1840919",
    "end": "1846140"
  },
  {
    "text": "code I'll just mention a few of the things that uh kind of are important to doing these experiments so one is like",
    "start": "1846140",
    "end": "1852140"
  },
  {
    "text": "easily allowing us to stream in data from cloud Object Store in different",
    "start": "1852140",
    "end": "1857779"
  },
  {
    "text": "mixes so on the left there's like what one of our yamls looks like with a mixture of C4 markdown and mc4 in a",
    "start": "1857779",
    "end": "1865880"
  },
  {
    "text": "deterministic way another is we have our own evaluation harness that we run during our training",
    "start": "1865880",
    "end": "1873679"
  },
  {
    "text": "runs so we do ICL in context learning evaluation live during the training run",
    "start": "1873679",
    "end": "1879380"
  },
  {
    "text": "so we can kind of get a better idea of how things are changing and how the training run is going that's um hopefully a little more uh",
    "start": "1879380",
    "end": "1885799"
  },
  {
    "text": "informative than just looking at the loss curve and then next Slide the last thing",
    "start": "1885799",
    "end": "1892220"
  },
  {
    "text": "I'll mention here is that the with the Mosaic platform we have automatic",
    "start": "1892220",
    "end": "1898399"
  },
  {
    "text": "resumption from Hardware failures so this image is essentially our logbook for the mpt-7b run I just turned it on",
    "start": "1898399",
    "end": "1905779"
  },
  {
    "text": "and then watched it for a while and then turned it off uh when it was done and this cost about 200 000 as bondage",
    "start": "1905779",
    "end": "1914480"
  },
  {
    "text": "said over 10 days on 440 a100s um and everything so again everything",
    "start": "1914480",
    "end": "1921980"
  },
  {
    "text": "here except for the gpus and the orchestration so this this automatic resumption from Hardware failures is",
    "start": "1921980",
    "end": "1928039"
  },
  {
    "text": "open so everything else is open source uh and I'll hand it back to bondage to kind of discuss the components of that",
    "start": "1928039",
    "end": "1934760"
  },
  {
    "text": "stack a little bit more and close with uh what's coming next and how you can get involved if you're interested in",
    "start": "1934760",
    "end": "1940279"
  },
  {
    "text": "kind of working with our open source tools or models great thanks a lot Daniel yeah so I",
    "start": "1940279",
    "end": "1947179"
  },
  {
    "text": "think the the first thing you know that we need is uh great tooling right I think if you looked at the previous loss",
    "start": "1947179",
    "end": "1954080"
  },
  {
    "text": "curve where you're looking at our uh our seamless resumption right I mean we are seeing failures right things Hardware",
    "start": "1954080",
    "end": "1960440"
  },
  {
    "text": "fails things happen someone messes up a setting um being able to stop resume quickly uh",
    "start": "1960440",
    "end": "1966980"
  },
  {
    "text": "being able to start where you left off um is really important and so you know we went and built a software stack",
    "start": "1966980",
    "end": "1974600"
  },
  {
    "text": "um that can do all of this so I think there's uh kind of on the left here we're trying to depict what your typical",
    "start": "1974600",
    "end": "1980480"
  },
  {
    "text": "ml training stack will look like I think the main thing here missing is sort of the experiment Packers but let's assume",
    "start": "1980480",
    "end": "1985580"
  },
  {
    "text": "it's kind of like a boxer somewhere but yeah you have your user code your data loading and processing uh tooling you",
    "start": "1985580",
    "end": "1992120"
  },
  {
    "text": "have your distributed training framework you know whether that's vanilla pie torch code or some kind of more uh fancy",
    "start": "1992120",
    "end": "1998120"
  },
  {
    "text": "thing like pie torch lightning or or fast AI uh you have you know your deep learning libraries like pytorch or",
    "start": "1998120",
    "end": "2003340"
  },
  {
    "text": "tensorflow uh and then when you're running on multiple gpus you need some type of deployment orchestration and",
    "start": "2003340",
    "end": "2009640"
  },
  {
    "text": "then obviously the completely complex uh software ecosystem of device drivers and",
    "start": "2009640",
    "end": "2015519"
  },
  {
    "text": "toolkits and tooling and all the fancy version mismatches and things like that you have to deal with",
    "start": "2015519",
    "end": "2020860"
  },
  {
    "text": "um so how do we how do we kind of address as a mistake well the first thing one of the first things we actually built and this was right when the company was was very new is we built",
    "start": "2020860",
    "end": "2027940"
  },
  {
    "text": "composer um originally we built composer as a training Library um it was actually built to facilitate a",
    "start": "2027940",
    "end": "2034779"
  },
  {
    "text": "lot of our algorithmic research and algorithmic efficiency research so it has a lot of amazing features there it's",
    "start": "2034779",
    "end": "2040179"
  },
  {
    "text": "actually an optimized pie torch trainer at the end of the day supports multino training uh checkpointing to object",
    "start": "2040179",
    "end": "2045580"
  },
  {
    "text": "stores and it also logs to your favorite experiment trackers right so whether you're using weights and biases tensorflow",
    "start": "2045580",
    "end": "2051940"
  },
  {
    "text": "um uh ml flow anything anything that you really want and it's also very extensible so it's easy to add new",
    "start": "2051940",
    "end": "2057520"
  },
  {
    "text": "things uh we have a two-way callback system that lets you easily modify what's happening in the training Loop uh",
    "start": "2057520",
    "end": "2063280"
  },
  {
    "text": "so we kind of build all this for research and then realize this was a really really great way to also start using to train large angress models so",
    "start": "2063280",
    "end": "2070118"
  },
  {
    "text": "it's a such a very core part of The llm Foundry in addition to that we kind of realized",
    "start": "2070119",
    "end": "2075158"
  },
  {
    "text": "we need to go where the compute is right when we're starting the company um whether we can get v100s on AWS or",
    "start": "2075159",
    "end": "2082240"
  },
  {
    "text": "a100 somewhere else or wherever uh and what we really kind of found out is the data kind of anchors you and so what we",
    "start": "2082240",
    "end": "2088480"
  },
  {
    "text": "ended up doing is building this streaming data sets library and what this does is enabling high performance streaming um from any Cloud Object Store",
    "start": "2088480",
    "end": "2095618"
  },
  {
    "text": "and so you can stuff your you know uh data set in an R2 uh bucket somewhere",
    "start": "2095619",
    "end": "2101980"
  },
  {
    "text": "and stream it you know with zero egress fees to AWS or oci uh or you know gcp",
    "start": "2101980",
    "end": "2109300"
  },
  {
    "text": "um it really kind of gives you flexibility to run anywhere and um the other thing that streaming lets",
    "start": "2109300",
    "end": "2115300"
  },
  {
    "text": "you do is very fast resumption right so we don't have to deal with uh spending hours or days even uh spinning our data",
    "start": "2115300",
    "end": "2122380"
  },
  {
    "text": "loader when we have to resume a run we can kind of just pick up very quickly where we left off um and it's deterministic right so it it",
    "start": "2122380",
    "end": "2128740"
  },
  {
    "text": "preserves sample order between uh between checkpoints and resumptions uh and then when it works in tandem with",
    "start": "2128740",
    "end": "2134859"
  },
  {
    "text": "composer uh it it kind of works with the checkpointing system very seamlessly so basically everything is vertically",
    "start": "2134859",
    "end": "2140740"
  },
  {
    "text": "integrated ah so everything on top there everything above deep learning libraries is open source uh you can go check out",
    "start": "2140740",
    "end": "2147460"
  },
  {
    "text": "the streaming group but you can go check out the composer repo um and that's actually what we refer to our training runtime uh everything below",
    "start": "2147460",
    "end": "2154000"
  },
  {
    "text": "that is actually our our paid product uh which I kind of talk about next year but this is uh you know to actually",
    "start": "2154000",
    "end": "2160720"
  },
  {
    "text": "basically have a great uh stack we have a great training stack we have to actually have a great platform to run it",
    "start": "2160720",
    "end": "2167079"
  },
  {
    "text": "um and so this is really what's responsible for running uh and orchestrating uh and scheduling jobs",
    "start": "2167079",
    "end": "2174160"
  },
  {
    "text": "um so basically the platform architecture is actually built in a way that we split it into basically two",
    "start": "2174160",
    "end": "2179500"
  },
  {
    "text": "planes uh the Mosaic control plane it's actually Cloud agnostic you know in it manages all the multi-node orchestration",
    "start": "2179500",
    "end": "2185200"
  },
  {
    "text": "scheduling of runs it does live live real-time monitoring uh for faults and and implements and works very you know",
    "start": "2185200",
    "end": "2192400"
  },
  {
    "text": "integrated very well with composer the training stack to do automatic uh recovery of runs when when there's some",
    "start": "2192400",
    "end": "2197560"
  },
  {
    "text": "type of Hardware failure um the control plane can run and be deployed anywhere",
    "start": "2197560",
    "end": "2203380"
  },
  {
    "text": "and that's what allows us to actually focus on uh putting the compute plan in any Cloud right this is where your",
    "start": "2203380",
    "end": "2209560"
  },
  {
    "text": "actual accelerators are located this is where the training runtime will actually run um and this can be anywhere right your",
    "start": "2209560",
    "end": "2215260"
  },
  {
    "text": "cloud of choice it could be an on-prem data center if you want it uh if you want to set this up at home uh you know",
    "start": "2215260",
    "end": "2221320"
  },
  {
    "text": "I'm sure I'm sure we can get that to work um the platform's completely stateless um so uh at least the compute plan is",
    "start": "2221320",
    "end": "2228220"
  },
  {
    "text": "actually completely stateless where you know data can be streamed in but storage is ephemeral we do not save your data uh",
    "start": "2228220",
    "end": "2234339"
  },
  {
    "text": "it's completely private um the other Advantage we offer by being able to deploy where your compute plane",
    "start": "2234339",
    "end": "2239440"
  },
  {
    "text": "is um is data never has to leave your VPC either so if you have strict kind of data",
    "start": "2239440",
    "end": "2245680"
  },
  {
    "text": "um provisioning or data uh access requirements um this all is actually very friendly uh",
    "start": "2245680",
    "end": "2251680"
  },
  {
    "text": "to that kind of Enterprise space and lastly uh we've got a really great CLI uh various options in terms of uh",
    "start": "2251680",
    "end": "2258460"
  },
  {
    "text": "command line interface that lets you manage train uh submit different training jobs different training configs",
    "start": "2258460",
    "end": "2264040"
  },
  {
    "text": "uh it's all also accessible via python SDK and we are building our web console",
    "start": "2264040",
    "end": "2270220"
  },
  {
    "text": "um to actually have future parity with that but currently it's used for kind of account management billing and Gathering",
    "start": "2270220",
    "end": "2276220"
  },
  {
    "text": "usage statistics so overall it's a complete solution uh we're a One-Stop shop",
    "start": "2276220",
    "end": "2282579"
  },
  {
    "text": "um so I think where we're at now is we've got a great model uh we've got a great model architecture uh we've got a",
    "start": "2282579",
    "end": "2289720"
  },
  {
    "text": "place you can train it from scratch or you can fine tune it uh what we really need now is a place to deploy it so it's",
    "start": "2289720",
    "end": "2296320"
  },
  {
    "text": "usable and so a few weeks ago we actually announced our inference uh infrastructure and firms products um and",
    "start": "2296320",
    "end": "2303400"
  },
  {
    "text": "this really is available now in about two tiers um so we have a starter tier and this is this is your hosted API",
    "start": "2303400",
    "end": "2309280"
  },
  {
    "text": "right so we have MPT deployments uh hosted that you basically pay for API",
    "start": "2309280",
    "end": "2314980"
  },
  {
    "text": "usage um after you sign up and are given access to the platform",
    "start": "2314980",
    "end": "2320260"
  },
  {
    "text": "um and this is very price competitive um so I kind of put some of the pricing on the the bottom right there",
    "start": "2320260",
    "end": "2326619"
  },
  {
    "text": "um and the other thing we also offer is an Enterprise tier where let's say you",
    "start": "2326619",
    "end": "2331900"
  },
  {
    "text": "know this hosted model isn't enough you need to do some customization or you won't you've you've played with it you've you've started entering your",
    "start": "2331900",
    "end": "2338500"
  },
  {
    "text": "pipeline you actually want to go and train your own model uh that's where you kind of upgrade to the Enterprise tier and this offers some of the same",
    "start": "2338500",
    "end": "2344859"
  },
  {
    "text": "benefits as the training stack where uh you can deploy on your own private Network you can deploy on any Cloud",
    "start": "2344859",
    "end": "2352000"
  },
  {
    "text": "um and kind of handle all that infrastructure for you um your you know you basically just pay per GPU so it's a very very scalable and",
    "start": "2352000",
    "end": "2358480"
  },
  {
    "text": "understandable uh pricing model um and and uh and yeah basically uh same",
    "start": "2358480",
    "end": "2364839"
  },
  {
    "text": "privacy advantages we do not save your even for the starter chair uh we do not save and train on your data",
    "start": "2364839",
    "end": "2371680"
  },
  {
    "text": "um so so yeah that's a that's kind of a very very uh core tenant I think to to what we built out right is data",
    "start": "2371680",
    "end": "2378160"
  },
  {
    "text": "procession and privacy and yeah what's to come um larger better interesting models",
    "start": "2378160",
    "end": "2386859"
  },
  {
    "text": "um definitely check out uh our open source tooling we we have uh we have some we",
    "start": "2386859",
    "end": "2392560"
  },
  {
    "text": "have eventually well we have a whole burst of announcements coming up so stay tuned um join our community slack on social",
    "start": "2392560",
    "end": "2398200"
  },
  {
    "text": "media please get engaged uh we love the open source Community um you guys I mean just everyone has",
    "start": "2398200",
    "end": "2403480"
  },
  {
    "text": "done a fantastic job of finding issues and making feature requests and you know we do our best to kind of handle them as",
    "start": "2403480",
    "end": "2409599"
  },
  {
    "text": "fast as we can um and sign up for the Mosaic ml platform if you uh if you think that you",
    "start": "2409599",
    "end": "2415180"
  },
  {
    "text": "can start using this and uh it'll it'll meet your needs so I think uh with that we can uh open it up for any questions",
    "start": "2415180",
    "end": "2424500"
  },
  {
    "text": "awesome I've got a few and then maybe we can kick it to Round Table the first one I'd be curious to hear about is like how",
    "start": "2424540",
    "end": "2430000"
  },
  {
    "text": "do you guys think about training from scratch versus like fine tuning is there a big difference there is that largely",
    "start": "2430000",
    "end": "2435280"
  },
  {
    "text": "the same under the bot and under the hood would you do you recommend one versus the other for certain types of",
    "start": "2435280",
    "end": "2442240"
  },
  {
    "text": "clients yeah yeah I'll take it down",
    "start": "2442240",
    "end": "2449200"
  },
  {
    "text": "um yeah I think there's uh again like with a lot of these questions there's like still a lot of science left to do",
    "start": "2449200",
    "end": "2455980"
  },
  {
    "text": "to figure out the right answer in in every case um generally though it kind of depends",
    "start": "2455980",
    "end": "2462280"
  },
  {
    "text": "how much data you're showing up with if you're showing up with enough data to do a training run from scratch uh it's",
    "start": "2462280",
    "end": "2469900"
  },
  {
    "text": "often something worth trying particularly if you're kind of in a very different domain so like maybe the most",
    "start": "2469900",
    "end": "2475720"
  },
  {
    "text": "extreme example is like if you're showing up with a a language that's not English like",
    "start": "2475720",
    "end": "2481780"
  },
  {
    "text": "Arabic and you're going to want to train your own tokenizer uh then if you're doing your own tokenizer you have to",
    "start": "2481780",
    "end": "2488260"
  },
  {
    "text": "start from scratch that we don't currently have any ways to kind of adapt the model to a new tokenizer uh if",
    "start": "2488260",
    "end": "2495940"
  },
  {
    "text": "you're showing up with kind of a smaller fine-tuning set of either unlabeled or",
    "start": "2495940",
    "end": "2501900"
  },
  {
    "text": "labeled data then you're gonna probably want to be starting from a base model",
    "start": "2501900",
    "end": "2507099"
  },
  {
    "text": "the other answer is that you build right so do the cheapest thing first uh if if",
    "start": "2507099",
    "end": "2514180"
  },
  {
    "text": "you have a small data set start with a base model fine tune it see how that does because one of the most important",
    "start": "2514180",
    "end": "2521500"
  },
  {
    "text": "things here right is like you have to actually try the model on the thing that you care about and so do that as quickly",
    "start": "2521500",
    "end": "2528280"
  },
  {
    "text": "as possible with the cheapest possible option and then start scaling up to maybe training from scratch maybe larger",
    "start": "2528280",
    "end": "2534339"
  },
  {
    "text": "models and uh you know stop when the thing is good enough for you like there's no reason to spend extra money",
    "start": "2534339",
    "end": "2540520"
  },
  {
    "text": "in time if it's solving your problem awesome and then and then one other",
    "start": "2540520",
    "end": "2546760"
  },
  {
    "text": "question I have for you guys is just on the difference between like training and inference like where do you think",
    "start": "2546760",
    "end": "2552400"
  },
  {
    "text": "there's the most improvements for both you guys and the industry as a whole to kind of like make progress is it is",
    "start": "2552400",
    "end": "2558940"
  },
  {
    "text": "there is there like more work left to be done on the training side or on the inference side of of the infrastructure",
    "start": "2558940",
    "end": "2564040"
  },
  {
    "text": "part yeah I think at a high level I mean I think the answer is both um",
    "start": "2564040",
    "end": "2570780"
  },
  {
    "text": "it's hard well okay so it's it so training definitely have a lot of uh I",
    "start": "2573520",
    "end": "2578560"
  },
  {
    "text": "mean just you know if you go back to the days when we were doing pure algorithmic research right and some of the stuff that we did with resnets and Bert and uh",
    "start": "2578560",
    "end": "2586599"
  },
  {
    "text": "um deep lab for example and just bringing out those costs I mean we think you know obviously there's a lot of room",
    "start": "2586599",
    "end": "2592000"
  },
  {
    "text": "for improvements in terms of how you're training LMS you see this constantly I mean some of our speed up methods we get",
    "start": "2592000",
    "end": "2597220"
  },
  {
    "text": "on Twitter right some little post hey I flipped this flag and I got like a 10x or 10 Improvement or something and we",
    "start": "2597220",
    "end": "2603520"
  },
  {
    "text": "get on that really quick so training definitely a lot of low-hanging fruit but also a lot of research to do in",
    "start": "2603520",
    "end": "2608920"
  },
  {
    "text": "terms of efficiency and bringing the compute it's hard for me to decouple of those decouple those two and I think",
    "start": "2608920",
    "end": "2614740"
  },
  {
    "text": "like that is I think a mistake that people make right where okay let's say you go and Train 100",
    "start": "2614740",
    "end": "2620440"
  },
  {
    "text": "billion parameter model the problem is deploying that at scale and making so people can use it like you can't you",
    "start": "2620440",
    "end": "2626740"
  },
  {
    "text": "can't decouple it's you just can't decouple that picture right and so that's one of the hardest things is like if we have someone come in that says oh",
    "start": "2626740",
    "end": "2632800"
  },
  {
    "text": "I want to go train a trillion parameter model it's like okay I mean you may even if you have the data it's like well why",
    "start": "2632800",
    "end": "2638740"
  },
  {
    "text": "because how are you gonna host that right how are you going to deploy that like what you know and for some very very Niche",
    "start": "2638740",
    "end": "2645579"
  },
  {
    "text": "cases that might be possible um but generally like a lot of people we don't they really need that right so I think what Daniel was saying earlier is",
    "start": "2645579",
    "end": "2651520"
  },
  {
    "text": "probably the way to go is you start small and the the benefit of starting small is that you can iterate quickly",
    "start": "2651520",
    "end": "2657640"
  },
  {
    "text": "and yeah maybe you know you don't get the thing that you want right away but I mean I would argue you probably don't",
    "start": "2657640",
    "end": "2663220"
  },
  {
    "text": "know that right away right you kind of need it's a discovery process so you start with what's been built uh iterate",
    "start": "2663220",
    "end": "2668440"
  },
  {
    "text": "on that if you see value in pre-training pre-trained but also don't forget about inference right uh and so I think even",
    "start": "2668440",
    "end": "2674380"
  },
  {
    "text": "in inference um hosting large language models there's a lot we can continue to do right there's a lot of interesting things",
    "start": "2674380",
    "end": "2680560"
  },
  {
    "text": "going on in research in terms of how to compress large language models or distill them down into smaller models so they're cheaper so uh if I had to pick",
    "start": "2680560",
    "end": "2687640"
  },
  {
    "text": "for this I'll choose training but I I do think it's hard to decouple the two there's like a yin and yang scenario",
    "start": "2687640",
    "end": "2692980"
  },
  {
    "text": "going on there I think also it would probably be uh for the parts of inference that you can",
    "start": "2692980",
    "end": "2698980"
  },
  {
    "text": "decouple from training it's a bit easier to work on like you need less resources you don't need a giant cluster to work",
    "start": "2698980",
    "end": "2707500"
  },
  {
    "text": "on it for insufficiency uh so I think we've seen a lot of great work from the open source Community",
    "start": "2707500",
    "end": "2712960"
  },
  {
    "text": "there with like ggml and llama CPP and all of that",
    "start": "2712960",
    "end": "2718318"
  },
  {
    "text": "and um reminder for people to add questions to the question box I'll go there after one more I wish Brandon was here for",
    "start": "2718540",
    "end": "2725079"
  },
  {
    "text": "that for this but I think he's having some internet issues but I guess my question is like a lot of what both of you guys talked about was the tooling",
    "start": "2725079",
    "end": "2731560"
  },
  {
    "text": "around these models and so my question would be like what is the tooling that you guys have built that you think is",
    "start": "2731560",
    "end": "2737740"
  },
  {
    "text": "like most novel and you're most proud of and then what is one piece of tooling that you with that doesn't exist in your",
    "start": "2737740",
    "end": "2744099"
  },
  {
    "text": "guys's platform currently but you wish someone like maybe you guys will build this in the future maybe wish someone would build this",
    "start": "2744099",
    "end": "2750400"
  },
  {
    "text": "um like one One external piece of tooling that you think would be really valuable and needs to have kind of like more more attention paid there",
    "start": "2750400",
    "end": "2757839"
  },
  {
    "text": "um that's a good question I mean I think that probably the most novel",
    "start": "2757839",
    "end": "2764740"
  },
  {
    "text": "um is I mean to me I think it's probably streaming",
    "start": "2764740",
    "end": "2770260"
  },
  {
    "text": "um in that you know it really really kind of frees you from from cloud and vendor lock-in uh you can put your data",
    "start": "2770260",
    "end": "2777460"
  },
  {
    "text": "somewhere you can move it around uh there's pricing and costs associated doing all that but but you can",
    "start": "2777460",
    "end": "2784780"
  },
  {
    "text": "not you can calculate that right that's that's an understandable model whereas uh previously you had to co-locate you",
    "start": "2784780",
    "end": "2791500"
  },
  {
    "text": "know your data with your compute you were tied in um so I think yeah that's why I think",
    "start": "2791500",
    "end": "2796839"
  },
  {
    "text": "tooling is actually great because it unlocks you from clouds and really what you want the clouds to be doing is a race at the bottom right they need to be",
    "start": "2796839",
    "end": "2802660"
  },
  {
    "text": "competing on pricing and offering you the best cost per GPU so uh giving giving open source and ourselves anyone",
    "start": "2802660",
    "end": "2809800"
  },
  {
    "text": "who needs to pay for compute uh that type of that type of Leverage I think is is probably what makes streaming great",
    "start": "2809800",
    "end": "2817440"
  },
  {
    "text": "I'll see what Daniel says and then think about uh what I what I I have a lot wish list I'm wondering what I should ask for",
    "start": "2817440",
    "end": "2823420"
  },
  {
    "text": "if I had this uh I can I can tell you stab at my my wishlist items so I think",
    "start": "2823420",
    "end": "2828520"
  },
  {
    "text": "one of the things that we and the community have been struggling a lot with is evaluating these models uh",
    "start": "2828520",
    "end": "2835180"
  },
  {
    "text": "robustly uh you know you you run the academic benchmarks you get some numbers",
    "start": "2835180",
    "end": "2840880"
  },
  {
    "text": "who knows what that means you try out the model you play with it for a little bit and like ultimately",
    "start": "2840880",
    "end": "2846480"
  },
  {
    "text": "everyone's has their own little internal tests for these models and deciding which one's best which one's best for",
    "start": "2846480",
    "end": "2852460"
  },
  {
    "text": "their use case and some of that is unavoidable right like different models are going to be good for different things and there's really no like",
    "start": "2852460",
    "end": "2859660"
  },
  {
    "text": "substitute for just like having a little test set and looking at it and seeing what happens but I'd love to see more",
    "start": "2859660",
    "end": "2866680"
  },
  {
    "text": "tooling from tooling around kind of evaluating the aspects different aspects of the model",
    "start": "2866680",
    "end": "2872859"
  },
  {
    "text": "that we can automatically robustly evaluate even if they're not each one",
    "start": "2872859",
    "end": "2877900"
  },
  {
    "text": "individually is not like the be all end-all of model quality any like discrete accurate points you can get on",
    "start": "2877900",
    "end": "2884140"
  },
  {
    "text": "model eval is very helpful and kind of reduces the iteration cost of just like checking the Vibes as we say so so I'd",
    "start": "2884140",
    "end": "2892480"
  },
  {
    "text": "love to see like more robust tooling for evaluating these large models",
    "start": "2892480",
    "end": "2897819"
  },
  {
    "text": "so that's a great one I think I know mine uh which I think you know I have a former Hardware background you know when",
    "start": "2897819",
    "end": "2903940"
  },
  {
    "text": "I come from one of the the hardware chip companies as well but where is anyone else but Nvidia for training right",
    "start": "2903940",
    "end": "2910599"
  },
  {
    "text": "um I think that's what I'd love to see like AMD had some great announcements yesterday uh you know and my am I 300a",
    "start": "2910599",
    "end": "2917200"
  },
  {
    "text": "and my 300X we want to use it right like we're ready we're we love Nvidia don't get me wrong uh they make they make",
    "start": "2917200",
    "end": "2923920"
  },
  {
    "text": "amazing stuff and and we you know I think uh there's also other companies out there making amazing things uh there's there's a you know a very robust",
    "start": "2923920",
    "end": "2931240"
  },
  {
    "text": "and thriving Hardware uh startup ecosystem uh I'm you know I want to try",
    "start": "2931240",
    "end": "2936400"
  },
  {
    "text": "some new hardware and really optimize them as a platform on different things and and honestly my hypothesis is that",
    "start": "2936400",
    "end": "2942280"
  },
  {
    "text": "different Hardware will be good for different types of models as well you know this is actually something that we talked a lot about at the beginning",
    "start": "2942280",
    "end": "2947680"
  },
  {
    "text": "early days of Mosaic like does it make sense to train llms on tpus versus gpus",
    "start": "2947680",
    "end": "2953140"
  },
  {
    "text": "or does it you know where is the best place to do this and and uh it kind of gets under the heart where like in a",
    "start": "2953140",
    "end": "2958900"
  },
  {
    "text": "lottery ticket type thing but um but I think basically uh sorry Harvard Lottery type thing but yeah we want to run on on",
    "start": "2958900",
    "end": "2965500"
  },
  {
    "text": "more Hardware awesome so so the first the uploaded",
    "start": "2965500",
    "end": "2971200"
  },
  {
    "text": "question is very similar to what you were talking about Daniel and it's around evaluation and it ties in a little bit of I think it's combo kind of",
    "start": "2971200",
    "end": "2978099"
  },
  {
    "text": "like Mosaic and then also some tie into link chain so let me try to parse this and turn this into some question but",
    "start": "2978099",
    "end": "2983260"
  },
  {
    "text": "basically yeah is there a systematic and quantitative approach to determine the most suitable open source pre-trained",
    "start": "2983260",
    "end": "2988599"
  },
  {
    "text": "llm for a specific use case such as like document question answering in a particular domain so that's one of the",
    "start": "2988599",
    "end": "2993940"
  },
  {
    "text": "main like chains that we have um and so there's some stuff that uh he",
    "start": "2993940",
    "end": "2999339"
  },
  {
    "text": "mentions as being inside Lang chain and I'm happy to talk about that um but yeah I guess like building on",
    "start": "2999339",
    "end": "3006180"
  },
  {
    "text": "your answer before and yeah like and you know I think you said something",
    "start": "3006180",
    "end": "3011280"
  },
  {
    "text": "really key about like having your like having a test data set of sorts and so like yeah as you go from not these like",
    "start": "3011280",
    "end": "3018300"
  },
  {
    "text": "academic benchmarks but your particular task like what does what does a good workflow and and yeah what does a good",
    "start": "3018300",
    "end": "3025380"
  },
  {
    "text": "workflow seem like to you and and I'll take a stab at this after as well but curious to hear your guys's thoughts yeah so I",
    "start": "3025380",
    "end": "3032819"
  },
  {
    "text": "mean unfortunately the answer is like sort of no there is not a current a good like",
    "start": "3032819",
    "end": "3039599"
  },
  {
    "text": "systematic quantitative but the more more uh like you know if you have an Enterprise and a bunch of uh people to",
    "start": "3039599",
    "end": "3046800"
  },
  {
    "text": "to label data and evaluate and stuff at the end of the day you just like hey you have to create a test set that is",
    "start": "3046800",
    "end": "3053240"
  },
  {
    "text": "what the thing that you care about and if your test set involves something that you can't automatically evaluate",
    "start": "3053240",
    "end": "3059579"
  },
  {
    "text": "reliably so if it's like open-ended generation you have to evaluate it with humans there there are some approaches",
    "start": "3059579",
    "end": "3067680"
  },
  {
    "text": "you know like there's automated metrics that you can start with and then there's like you can maybe evaluate with like",
    "start": "3067680",
    "end": "3073500"
  },
  {
    "text": "gpt4 or something like that yeah I was going to ask about that what what yeah",
    "start": "3073500",
    "end": "3078839"
  },
  {
    "text": "have you done that before have you seen that work we've we've definitely played around with it and I think it definitely",
    "start": "3078839",
    "end": "3084059"
  },
  {
    "text": "is like a signal that you can use in in your evaluation but for me personally",
    "start": "3084059",
    "end": "3090420"
  },
  {
    "text": "um like I just don't at this point trust evaluating models with models",
    "start": "3090420",
    "end": "3096300"
  },
  {
    "text": "um it's a good like read like it probably gives you like some information and since it's automated you can do it",
    "start": "3096300",
    "end": "3101339"
  },
  {
    "text": "more uh more frequently perhaps than than human eval but uh there's",
    "start": "3101339",
    "end": "3109200"
  },
  {
    "text": "there's both obvious biases like the there's paper showing recently that like",
    "start": "3109200",
    "end": "3114300"
  },
  {
    "text": "GPT 40 valves biased to the position of the of the answer Choice and then I'm",
    "start": "3114300",
    "end": "3119880"
  },
  {
    "text": "sure there's a bunch of uh harder to detect biases hiding and so",
    "start": "3119880",
    "end": "3126420"
  },
  {
    "text": "at the end of the day like if you want to evaluate something hard um it's still humans for me",
    "start": "3126420",
    "end": "3132839"
  },
  {
    "text": "yeah um and uh so so uh the the rest of the",
    "start": "3132839",
    "end": "3138059"
  },
  {
    "text": "answer mentioned some like things related to link chains so there's like a QA eval chain which does the open AI uh",
    "start": "3138059",
    "end": "3145980"
  },
  {
    "text": "or the or it uses a model to grade it um gpd4 being the one that most people use in practices it mentions Auto evaluator",
    "start": "3145980",
    "end": "3153300"
  },
  {
    "text": "which is a way to do QA specific evaluation that like Lance Martin put out um and then there's a question about",
    "start": "3153300",
    "end": "3159240"
  },
  {
    "text": "yeah what what and I guess this let me reframe this like how do you get this test data set so like you mentioned this",
    "start": "3159240",
    "end": "3165119"
  },
  {
    "text": "test data set how do you how do you get that yeah and I guess like what should that",
    "start": "3165119",
    "end": "3170220"
  },
  {
    "text": "look like how many how many data points what are characteristics of the uh of the tests data points so to speak",
    "start": "3170220",
    "end": "3177420"
  },
  {
    "text": "yeah you know it's hard to answer in a in a general way perhaps but I think",
    "start": "3177420",
    "end": "3183180"
  },
  {
    "text": "people tend to shy away from just like spending a couple days writing data",
    "start": "3183180",
    "end": "3188940"
  },
  {
    "text": "um and that can actually be a great way to do it like if you sit down with your task and like take a couple days you can",
    "start": "3188940",
    "end": "3195000"
  },
  {
    "text": "write a reasonable amount of test data or you can play with your model for a",
    "start": "3195000",
    "end": "3200460"
  },
  {
    "text": "reasonable amount of time and kind of find the the bounds so I think don't shy",
    "start": "3200460",
    "end": "3206700"
  },
  {
    "text": "away from as Brandon talked about a lot like looking at the data and perhaps even writing some data",
    "start": "3206700",
    "end": "3213059"
  },
  {
    "text": "um and uh yeah so like the the tooling that that you mentioned is great and and",
    "start": "3213059",
    "end": "3219359"
  },
  {
    "text": "helps you get some idea uh of the performance of the model and then uh",
    "start": "3219359",
    "end": "3225300"
  },
  {
    "text": "building tooling to make your like evaluation easier so like a b testing or",
    "start": "3225300",
    "end": "3231000"
  },
  {
    "text": "something like that just like a tiny little UI can be very helpful but yeah then like don't shy away from looking at",
    "start": "3231000",
    "end": "3237540"
  },
  {
    "text": "and writing and data like those tasks are important yeah I mean in a way I",
    "start": "3237540",
    "end": "3242880"
  },
  {
    "text": "think it's similar to writing unit tests for software right like everyone kind of",
    "start": "3242880",
    "end": "3247920"
  },
  {
    "text": "probably hates doing it um but it's critical right it's necessary if otherwise you have no idea",
    "start": "3247920",
    "end": "3253500"
  },
  {
    "text": "if you have working uh working code and I think it's a little similar here like we even when customers come in right and",
    "start": "3253500",
    "end": "3259500"
  },
  {
    "text": "they say we want to train our model the first thing is well the first questions I think even our researchers or anyone",
    "start": "3259500",
    "end": "3265559"
  },
  {
    "text": "asks is how are you how are you going to evalot right how are you gonna how are you gonna know that this model is doing what you want it to do",
    "start": "3265559",
    "end": "3272280"
  },
  {
    "text": "um there's a lot of Frameworks out there right there's a lot of a lot of different eval Suites out there that give you some idea of its performance in",
    "start": "3272280",
    "end": "3279420"
  },
  {
    "text": "different domains but at the end of the day like you're you know you're using the model to do something you are the",
    "start": "3279420",
    "end": "3285420"
  },
  {
    "text": "domain expert right and so somehow wow right do what Daniel's saying like go go build your own eval metrics go build uh",
    "start": "3285420",
    "end": "3292920"
  },
  {
    "text": "your eval sets uh spend time on that think about it as unit testing because otherwise you you just you're not going",
    "start": "3292920",
    "end": "3298740"
  },
  {
    "text": "to know right there's no way you can scale it there's also a work option really quickly uh that's more from the kind of",
    "start": "3298740",
    "end": "3305339"
  },
  {
    "text": "bird era and I'm not sure if it's been kind of extended but it's called checklist and I think it was like a best",
    "start": "3305339",
    "end": "3311220"
  },
  {
    "text": "paper at ACL or something like that and it was about like how unit testing these models in some form I really enjoyed",
    "start": "3311220",
    "end": "3317220"
  },
  {
    "text": "that paper so I encourage people to check it out foreign that perfectly answers another",
    "start": "3317220",
    "end": "3322980"
  },
  {
    "text": "question or not perfectly but there's a question about open source leaderboards and which ones are kind of like best and",
    "start": "3322980",
    "end": "3328740"
  },
  {
    "text": "I think the point around just having your own leaderboard is probably you know Irreplaceable for yeah look at all of them take them all with a grain of",
    "start": "3328740",
    "end": "3334800"
  },
  {
    "text": "salt and like nothing compares to evaluating all the models in your own framework so you know the exact same",
    "start": "3334800",
    "end": "3340440"
  },
  {
    "text": "thing was wrong yeah this might be a kind of work but honestly I think a leaderboard out there that is actually",
    "start": "3340440",
    "end": "3345599"
  },
  {
    "text": "like here are all the different things that we've tuned a model to do right is like a lot of these are like here is a",
    "start": "3345599",
    "end": "3351660"
  },
  {
    "text": "currently trained model and here's how it performs in verticals but really like that's important but also I'm not it's",
    "start": "3351660",
    "end": "3358260"
  },
  {
    "text": "not clear to me that that speaks of the versatility of a model right and like what does that even mean and so yeah I'm",
    "start": "3358260",
    "end": "3363780"
  },
  {
    "text": "really curious like you know and I think I was looking for sources for this presentation of community projects with",
    "start": "3363780",
    "end": "3368819"
  },
  {
    "text": "MPT but very curious like what sort of different verticals people are using MPT in because that to me is adaptability",
    "start": "3368819",
    "end": "3375059"
  },
  {
    "text": "and versatility right not just oh it's great at these things currently because we kind of want people to be fine-tuning",
    "start": "3375059",
    "end": "3381599"
  },
  {
    "text": "it and we want people to be modifying it for their own own use cases",
    "start": "3381599",
    "end": "3387000"
  },
  {
    "text": "awesome we're running up on time so I'm gonna combine the last two questions into one and maybe give you guys a final",
    "start": "3387000",
    "end": "3393119"
  },
  {
    "text": "chance to talk about Mosaic so it's the combo question is basically how can open",
    "start": "3393119",
    "end": "3398160"
  },
  {
    "text": "source communities and pre-revenue startups so very cash kind of like constrained and resource constrained how",
    "start": "3398160",
    "end": "3404160"
  },
  {
    "text": "can they use Mosaic ml to train their own custom models and combine them with the other part are their best practices",
    "start": "3404160",
    "end": "3409619"
  },
  {
    "text": "that you would recommend for them doing so oh yeah sure I mean uh first and foremost start using our training stack",
    "start": "3409619",
    "end": "3415980"
  },
  {
    "text": "right you can you can use that on your 30 90 or 40 90 workstation at home uh if",
    "start": "3415980",
    "end": "3421260"
  },
  {
    "text": "you have problems ping us you know uh Daniel and I everyone on the team is very very uh responsive on our community",
    "start": "3421260",
    "end": "3427619"
  },
  {
    "text": "slack I think we're creating a community Discord soon but join our community um and tell us your issues file them on",
    "start": "3427619",
    "end": "3433920"
  },
  {
    "text": "GitHub uh and we'll we'll fix them for you um we love working with startups we work",
    "start": "3433920",
    "end": "3439440"
  },
  {
    "text": "with a lot of startups uh you know we are a startup and so that's the best way um when you decide you want to scale",
    "start": "3439440",
    "end": "3445380"
  },
  {
    "text": "your compute up uh what's great is you know obviously sign up and and reach out",
    "start": "3445380",
    "end": "3451380"
  },
  {
    "text": "to our sales team or just ping us on community even um and someone will get in touch with you and uh the best part of using the",
    "start": "3451380",
    "end": "3458400"
  },
  {
    "text": "stack is if you've got it working on your 4090 uh you can easily scale it to multiple gpus uh or multiple nodes",
    "start": "3458400",
    "end": "3466200"
  },
  {
    "text": "hundreds of ups when you start running on the platform so there's a very seamless kind of transition plan there so you don't have to reinvent every way",
    "start": "3466200",
    "end": "3472559"
  },
  {
    "text": "just start with our open source tooling and it's a natural entry point into our uh kind of platform which you're going",
    "start": "3472559",
    "end": "3478800"
  },
  {
    "text": "to use more at an Enterprise scale awesome all right we're gonna end it",
    "start": "3478800",
    "end": "3485400"
  },
  {
    "text": "there thank you guys for joining thank you Brandon for joining earlier I'm glad we got the presentation in before his",
    "start": "3485400",
    "end": "3490559"
  },
  {
    "text": "Wi-Fi cut out so um overall I hope this was a deep dive into open source llms uh still a lot of",
    "start": "3490559",
    "end": "3498900"
  },
  {
    "text": "questions in my mind and I feel like the field is progressing so rapidly I don't know how you guys kind of like keep up",
    "start": "3498900",
    "end": "3505079"
  },
  {
    "text": "with it so um but thanks for thanks for joining thanks for thanks for continuing to push",
    "start": "3505079",
    "end": "3510780"
  },
  {
    "text": "on it I think we all agree that the more open source albums the better so all right hello",
    "start": "3510780",
    "end": "3517460"
  },
  {
    "text": "see you guys",
    "start": "3517500",
    "end": "3520280"
  }
]
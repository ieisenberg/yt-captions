[
  {
    "text": "the the question answering over documents is one of the more popular use cases and so I'm really excited to be",
    "start": "0",
    "end": "5460"
  },
  {
    "text": "doing this with three people who are experts in this um and so I'm gonna let all three of",
    "start": "5460",
    "end": "12599"
  },
  {
    "text": "them introduce themselves uh uh very briefly um and then and then what we'll do is go",
    "start": "12599",
    "end": "17699"
  },
  {
    "text": "into longer uh five to ten minute demos of each of their products",
    "start": "17699",
    "end": "23220"
  },
  {
    "text": "um or projects and then we're gonna go into question answers from you guys and so I'll talk a bit more about that logistically after they do a quick round",
    "start": "23220",
    "end": "29220"
  },
  {
    "text": "of introductions so Andrew do you want to start yeah hi everyone",
    "start": "29220",
    "end": "35520"
  },
  {
    "text": "um my name is Andrew uh you probably know me from Twitter and Linkedin I",
    "start": "35520",
    "end": "40800"
  },
  {
    "text": "don't know um so I am a associate professor of chemical engineering and I like to mess",
    "start": "40800",
    "end": "46440"
  },
  {
    "text": "around with llms and um I first you know kind of got into this space after seeing I think the GPT",
    "start": "46440",
    "end": "52140"
  },
  {
    "text": "index stuff and then I started trying to use it for working with scientific papers which is a big challenge here",
    "start": "52140",
    "end": "57960"
  },
  {
    "text": "like chat GPT was not trained on scientific papers and so then I just started messing around with these things and and then that led to my tool and and",
    "start": "57960",
    "end": "65400"
  },
  {
    "text": "um that's kind of how I mess around right now is trying to get it to basically remove the need to read research papers",
    "start": "65400",
    "end": "73100"
  },
  {
    "text": "uh yes sir do you want to go next yeah sure so hey everyone my name is Yasser I am a",
    "start": "75600",
    "end": "82860"
  },
  {
    "text": "fourth year computer science student based in Toronto um I was first introduced to the llm",
    "start": "82860",
    "end": "89759"
  },
  {
    "text": "space and like question answering stuff uh with Lang chain so I joined the Discord I think like maybe three or four",
    "start": "89759",
    "end": "97560"
  },
  {
    "text": "months ago like when it's uh when it first came out and I was like playing",
    "start": "97560",
    "end": "102900"
  },
  {
    "text": "with it uh just writing Python scripts and from that I created chatbase which",
    "start": "102900",
    "end": "109320"
  },
  {
    "text": "basically um does that for you on online on the",
    "start": "109320",
    "end": "114659"
  },
  {
    "text": "website all right I'm Caleb all right everyone I'm Caleb tougher I'm",
    "start": "114659",
    "end": "121979"
  },
  {
    "text": "one of the co-founders of mendible.ai we build chat based search for developer",
    "start": "121979",
    "end": "127140"
  },
  {
    "text": "documentation so with one line of code you can embed a chat gbt like interface on your developer docs so developers can",
    "start": "127140",
    "end": "134280"
  },
  {
    "text": "get answers to their questions um me and my entire team have been",
    "start": "134280",
    "end": "140340"
  },
  {
    "text": "entrepreneurs for you know a long time or I guess a long time",
    "start": "140340",
    "end": "145440"
  },
  {
    "text": "relative to us where we're still pretty young um we joke that we've never really had real",
    "start": "145440",
    "end": "151680"
  },
  {
    "text": "jobs um because out of school we just started building things in the developer",
    "start": "151680",
    "end": "156959"
  },
  {
    "text": "experience space um we built a coding course platform called side guide it was built directly",
    "start": "156959",
    "end": "163500"
  },
  {
    "text": "to vs code which I thought was pretty cool we ended up building an interactive docs platform which was called side",
    "start": "163500",
    "end": "169319"
  },
  {
    "text": "guide as well we just changed it a little bit and when DaVinci 0.0.3 came",
    "start": "169319",
    "end": "175379"
  },
  {
    "text": "out we went from going we know that generative documentation is",
    "start": "175379",
    "end": "180959"
  },
  {
    "text": "going to be something eventually to holy crap this is happening right now",
    "start": "180959",
    "end": "186000"
  },
  {
    "text": "um and so that sort of started our journey building meddible.ai and bringing generative documentation to",
    "start": "186000",
    "end": "193140"
  },
  {
    "text": "um as many people as we can I wouldn't necessarily call myself experts on",
    "start": "193140",
    "end": "198599"
  },
  {
    "text": "documentation retrieval I feel like it's such a early field um but we've definitely learned some",
    "start": "198599",
    "end": "206280"
  },
  {
    "text": "hacks and tricks around things so I'm excited to talk to y'all yeah I mean I think it's definitely true",
    "start": "206280",
    "end": "211440"
  },
  {
    "text": "that it's an early field and I think uh there there are there there are no experts but I think it I think we can",
    "start": "211440",
    "end": "216720"
  },
  {
    "text": "have a pretty uh a pretty good conversation here with the four of us um so okay so to get some Logistics out",
    "start": "216720",
    "end": "223260"
  },
  {
    "text": "of the way this is being recorded um it will be available at this link afterwards um and we may or may not put",
    "start": "223260",
    "end": "229799"
  },
  {
    "text": "it on on YouTube or some other sites um if you have questions uh throughout the so the way that we'll do this is",
    "start": "229799",
    "end": "236700"
  },
  {
    "text": "we'll do yeah five to ten minutes for for each project kind of like presenting screen sharing giving some background on",
    "start": "236700",
    "end": "242819"
  },
  {
    "text": "uh both the technical side but then also maybe a little bit on like the business side as well um and then uh after that",
    "start": "242819",
    "end": "249239"
  },
  {
    "text": "we'll go directly into question answers from the audience so there is a question uh q a tab on the chat on the on the",
    "start": "249239",
    "end": "256079"
  },
  {
    "text": "right so there's the normal chat and then there's the Q a if you have questions please put them in there please upload the questions that that",
    "start": "256079",
    "end": "262919"
  },
  {
    "text": "you want to be answered um and we'll just basically go through those at the end um hopefully getting some some",
    "start": "262919",
    "end": "268080"
  },
  {
    "text": "different perspectives on on things they can be technical they can be related to the business whatever people are most",
    "start": "268080",
    "end": "273360"
  },
  {
    "text": "interested in that's kind of what will take the time to answer as Caleb said it's it's super early in this space we're all just trying to figure it out",
    "start": "273360",
    "end": "279600"
  },
  {
    "text": "there's a lot of hacks and so so really interested to to hear what people are interested about um and uh and yeah get different",
    "start": "279600",
    "end": "286919"
  },
  {
    "text": "perspectives on that um I think that's basically it yeah it",
    "start": "286919",
    "end": "292860"
  },
  {
    "text": "should be pretty it should be pretty fun and uh we'll jump right into it with Andrew",
    "start": "292860",
    "end": "298460"
  },
  {
    "text": "okay I should be sharing yep awesome",
    "start": "302040",
    "end": "307500"
  },
  {
    "text": "okay um yeah so I happen to be one of the GPT 4 red teamers so I've had access to um",
    "start": "307500",
    "end": "314280"
  },
  {
    "text": "uh gpd4 for a while and I was really interested in using it connecting it to tools and I don't know if you guys have",
    "start": "314280",
    "end": "320699"
  },
  {
    "text": "read the gpt4 system car but I did a lot of the drug Discovery or like chemical design work and one of the things I",
    "start": "320699",
    "end": "327600"
  },
  {
    "text": "needed it to do was to read through papers and so um actually I was doing red taming for gpt4 Lang Chang kind of came",
    "start": "327600",
    "end": "334380"
  },
  {
    "text": "out and I hacked it together with gpt4 and so I had a lot of fun messing with link chain and it was kind of cool",
    "start": "334380",
    "end": "339720"
  },
  {
    "text": "because I kind of got to see the future of what these things can do um ahead of time",
    "start": "339720",
    "end": "345120"
  },
  {
    "text": "and one of the things I found is that uh to kind of get these language models to",
    "start": "345120",
    "end": "351780"
  },
  {
    "text": "answer questions there was this idea of putting documents into vectors um and then basically asking a question",
    "start": "351780",
    "end": "358580"
  },
  {
    "text": "and then turning that question into itself and embedding and then use that",
    "start": "358580",
    "end": "363660"
  },
  {
    "text": "to look up docs in that database of vectors and that would give you like a a set of",
    "start": "363660",
    "end": "371280"
  },
  {
    "text": "passages and then in the past like I saw people messing around with this then you would take those those passages from the",
    "start": "371280",
    "end": "377220"
  },
  {
    "text": "documents you embedded and then use that to answer a question but what I found was much better is to actually take",
    "start": "377220",
    "end": "382319"
  },
  {
    "text": "those basically K documents so you go and you get five relevant passages from a document or five",
    "start": "382319",
    "end": "388740"
  },
  {
    "text": "documents depending on how you view this and then you give the llm all of those documents and then have it answer the",
    "start": "388740",
    "end": "394440"
  },
  {
    "text": "question but then the problem was like the context window so I can show you guys an example so on the right side here I have",
    "start": "394440",
    "end": "400979"
  },
  {
    "text": "some things coming from documents but I had to put them into an llm itself",
    "start": "400979",
    "end": "406919"
  },
  {
    "text": "to turn it to a smaller set so basically I have you know three thousand character",
    "start": "406919",
    "end": "412560"
  },
  {
    "text": "or three thousand token document chunks then I Summarize each of these into",
    "start": "412560",
    "end": "417900"
  },
  {
    "text": "smaller chunks of 75 seconds 75 work and then all of these are given to answer a",
    "start": "417900",
    "end": "423180"
  },
  {
    "text": "whole question so you can see this from beginning to end what are the governing equations for diffusion models it looks",
    "start": "423180",
    "end": "428819"
  },
  {
    "text": "at all of my documents by embedding this question turning them into chunks then",
    "start": "428819",
    "end": "433860"
  },
  {
    "text": "summarizing the chunks and then putting it all together into one big answer of what are the governing equations for diffusion models",
    "start": "433860",
    "end": "440039"
  },
  {
    "text": "and by doing this tracing of like going from documents to summaries the",
    "start": "440039",
    "end": "445380"
  },
  {
    "text": "summaries going to the final question you can trace back the citations so that you can actually cite specific page",
    "start": "445380",
    "end": "450960"
  },
  {
    "text": "numbers and documents and this allows you to check if there's hallucinations and so I don't really see hallucinations",
    "start": "450960",
    "end": "457139"
  },
  {
    "text": "from this approach um usually my prompts have like a a bailout like my prompts will say if you",
    "start": "457139",
    "end": "463440"
  },
  {
    "text": "don't know just say there's no relevant information so here's an example here this says there's no relevant information and then sometimes it'll",
    "start": "463440",
    "end": "470220"
  },
  {
    "text": "fail to answer a question so that was kind of the idea behind this is can we get like um you know the best of",
    "start": "470220",
    "end": "477780"
  },
  {
    "text": "everything like reusing gpt4 it's citing its sources it's pulling from A",
    "start": "477780",
    "end": "483000"
  },
  {
    "text": "diversity of sources and I have this face for paper QA that basically has all the documents you have accessible all",
    "start": "483000",
    "end": "489840"
  },
  {
    "text": "into these choose oh and I should mention one more thing is that a lot of the work and oh it disappeared of course a lot of the work and um",
    "start": "489840",
    "end": "496680"
  },
  {
    "text": "these kind of question answering things is getting nice split so you'll see lengchain has a lot of really good ways",
    "start": "496680",
    "end": "502139"
  },
  {
    "text": "to split text I've noticed that if you do this extra step of putting the chunks through an llm to summarize it that",
    "start": "502139",
    "end": "508800"
  },
  {
    "text": "removes all the needs for having clean chunking and so actually I don't even care about chunking correctly so paper",
    "start": "508800",
    "end": "514200"
  },
  {
    "text": "QA has its own parser that just cuts at the Character level no thought or work on on getting the chunks into nice",
    "start": "514200",
    "end": "520979"
  },
  {
    "text": "orders doesn't seem to matter um and just I know there's gonna be a whole bunch of discussion so I just want",
    "start": "520979",
    "end": "527040"
  },
  {
    "text": "to show like a little demo is that the latest thing though has been getting the papers right so the last thing I did was",
    "start": "527040",
    "end": "532320"
  },
  {
    "text": "I took um Lang chain and made an agent that will basically",
    "start": "532320",
    "end": "537600"
  },
  {
    "text": "um have access to these different steps of getting context doing keyword searches over papers choosing which",
    "start": "537600",
    "end": "543959"
  },
  {
    "text": "papers to read and I put it together to an agent that basically has you know choose papers",
    "start": "543959",
    "end": "549240"
  },
  {
    "text": "gather evidence and and the way it searches papers is from archive by archive stick scholar and it looks at",
    "start": "549240",
    "end": "557399"
  },
  {
    "text": "citations so here's a question of like why do birds flock and it goes and it does a keyword search of papers it gets",
    "start": "557399",
    "end": "562620"
  },
  {
    "text": "a few papers out and the agent is to use the paper QA Final Answer",
    "start": "562620",
    "end": "568560"
  },
  {
    "text": "um and it generates an answer I'll just skip ahead here and it turns out as a Canon question because it's enough",
    "start": "568560",
    "end": "573959"
  },
  {
    "text": "evidence and that's this like hallucinations is that if you stamp out all hallucinations sometimes you can't answer a question but by wrapping it",
    "start": "573959",
    "end": "580440"
  },
  {
    "text": "into an agent now and decide okay it doesn't have enough information to do different searches for papers I'll go",
    "start": "580440",
    "end": "585899"
  },
  {
    "text": "read different papers and gather evidence with different questions um and what's nice about this agent is that I kind of modified the chain so",
    "start": "585899",
    "end": "592260"
  },
  {
    "text": "that it has status at each observation so it can track its progress on getting to answering the question",
    "start": "592260",
    "end": "598620"
  },
  {
    "text": "um and that's kind of how I got where I am and that's what I'm thinking about in",
    "start": "598620",
    "end": "604320"
  },
  {
    "text": "this um and uh let's see I try to stop sure right",
    "start": "604320",
    "end": "610320"
  },
  {
    "text": "anyway so I think this is like the the getting these grounded responses is the",
    "start": "610320",
    "end": "615420"
  },
  {
    "text": "future but then you're in this problem with hallucination and then how do you solve this I think using agents to be able to go grab more resources and then",
    "start": "615420",
    "end": "621899"
  },
  {
    "text": "reason over the passages better um I don't know you know what's next but these kind of ideas of putting together",
    "start": "621899",
    "end": "628680"
  },
  {
    "text": "these large language models of tools to me is is really the most exciting part and I think reading papers and giving really good answers is great and also I",
    "start": "628680",
    "end": "636000"
  },
  {
    "text": "should also mention you know the cost of these things is is growing right like doing that agent based model of gpt4",
    "start": "636000",
    "end": "642660"
  },
  {
    "text": "running all over all this is like a lot of a lot of money but I think it's really cool that you can actually start paying five dollars for an answer now",
    "start": "642660",
    "end": "648480"
  },
  {
    "text": "and getting you know an increase in quality okay talk for too long but anyway that's just sort of what I'm thinking and then how I got to where I",
    "start": "648480",
    "end": "655019"
  },
  {
    "text": "am that's awesome Andrew I wanted to double click on the like chunking and summarization thing that you mentioned",
    "start": "655019",
    "end": "661140"
  },
  {
    "text": "because I know a lot of people are curious about that and I didn't 100 understand it myself so basically when",
    "start": "661140",
    "end": "666360"
  },
  {
    "text": "you so when does the summarization happen does it happen during the ingest process does it happen during the query process",
    "start": "666360",
    "end": "673100"
  },
  {
    "text": "yeah sorry I just go too fast um so what we do is we do the summarization with",
    "start": "673100",
    "end": "680040"
  },
  {
    "text": "the context as of the question so like in my example why do birds flock then we",
    "start": "680040",
    "end": "685980"
  },
  {
    "text": "go turn why do birds flock into a vector go to the vector database find all we find like 15 passages that could be relevant",
    "start": "685980",
    "end": "692579"
  },
  {
    "text": "then for each passage we say we want to answer the question why do birds flock we have this chunk here is",
    "start": "692579",
    "end": "700140"
  },
  {
    "text": "it relevant if it's not relevant say not relevant if it is relevant turn into a 75 word summary of evidence but this is",
    "start": "700140",
    "end": "707220"
  },
  {
    "text": "a really key Insight ahead is that you have to say don't make a judgment because what we had before is that it would try to answer the question and",
    "start": "707220",
    "end": "713399"
  },
  {
    "text": "then like the first context would just set off the whole llm being like Oh the first context says yes and then if the",
    "start": "713399",
    "end": "719399"
  },
  {
    "text": "other six context said no it would just be so sensitive so it's a little bit of prompt engineering to make sure that",
    "start": "719399",
    "end": "724800"
  },
  {
    "text": "each evidence chunk is like given impartial make no judgment on answering the question just provide evidence and",
    "start": "724800",
    "end": "730980"
  },
  {
    "text": "so I use the word evidence here just so it's like clear it's not answering the question okay and so that allows you to retrieve",
    "start": "730980",
    "end": "736860"
  },
  {
    "text": "like more documents and then put the and then put kind of like the summaries into context and when you're doing the",
    "start": "736860",
    "end": "741899"
  },
  {
    "text": "summarization or you're doing like each chunk individually basically or or are you doing like two chunks at a time and",
    "start": "741899",
    "end": "747779"
  },
  {
    "text": "asking it to or are you doing and are those like can those be like parallelized or are those kind of like some refining technique for those",
    "start": "747779",
    "end": "755579"
  },
  {
    "text": "yeah great so that was another Vision a lot of people I think focused on is the refinement method I found the refinement",
    "start": "755579",
    "end": "761100"
  },
  {
    "text": "method to be really bad um and now I think you know maybe that's just me but I found it much better to",
    "start": "761100",
    "end": "768120"
  },
  {
    "text": "basically try to put all the evidence equally weighted with no order and so",
    "start": "768120",
    "end": "773700"
  },
  {
    "text": "then go and and go up and yeah we I did write it to do it async um at one point in my life actually I",
    "start": "773700",
    "end": "780899"
  },
  {
    "text": "wrote paper I wrote an interface paper QA and gradio and streamlit and textual ISO and aversal with a website because",
    "start": "780899",
    "end": "787860"
  },
  {
    "text": "it couldn't decide what I wanted to do so I wrote it in all four I gotta say textual i o love it I loved async it was",
    "start": "787860",
    "end": "793800"
  },
  {
    "text": "really good but I just couldn't quite it just couldn't quite fit into how I had the vision so I don't do it asynchronously",
    "start": "793800",
    "end": "800700"
  },
  {
    "text": "right now it's a generator so generous evidence one piece at a time and you can see the progress but yeah you can absolutely batch these right because",
    "start": "800700",
    "end": "806760"
  },
  {
    "text": "there's no dependence the refinements absolutely parallel these things yeah I was gonna say that's uh I think",
    "start": "806760",
    "end": "812339"
  },
  {
    "text": "to me that's the big benefit of like this like mapreduce type thing as opposed to refine is just being able to backdraw those calls and get them get",
    "start": "812339",
    "end": "818399"
  },
  {
    "text": "them over with um awesome I I think we'll have a lot more questions about that in in the Q a part but now we'll go into the the",
    "start": "818399",
    "end": "825300"
  },
  {
    "text": "second one so yes sir do you want to take over yeah for sure",
    "start": "825300",
    "end": "830420"
  },
  {
    "text": "foreign",
    "start": "831420",
    "end": "834079"
  },
  {
    "text": "Center awesome so this is chatbase so chatbase",
    "start": "836899",
    "end": "842220"
  },
  {
    "text": "lets you do document q a but on the website so you basically can upload your",
    "start": "842220",
    "end": "848040"
  },
  {
    "text": "document and then it will create a chat bot for you that you can ask questions about the document and it will give you",
    "start": "848040",
    "end": "855060"
  },
  {
    "text": "sources so it's doing something very similar to what paper QA is doing",
    "start": "855060",
    "end": "861300"
  },
  {
    "text": "um so I'm just going to demo like what it how do I create a chat bot",
    "start": "861300",
    "end": "866459"
  },
  {
    "text": "so here you can choose like different data sources I'm going to choose file you can choose like one or like multiple",
    "start": "866459",
    "end": "872639"
  },
  {
    "text": "files so this is a document um that explains like what chatbase is",
    "start": "872639",
    "end": "879000"
  },
  {
    "text": "so I'm going to say create chatbot and it what it did",
    "start": "879000",
    "end": "884880"
  },
  {
    "text": "um it chunked the document into like I think 100 word chunks and it uses use",
    "start": "884880",
    "end": "892260"
  },
  {
    "text": "the open AI embedding model to embed them and then store them in a vector database and then now when I ask a",
    "start": "892260",
    "end": "898920"
  },
  {
    "text": "question so let's say like what is that base so the answer is within the document so what chatbase is doing right",
    "start": "898920",
    "end": "906000"
  },
  {
    "text": "now is it it's gonna embed this and then search for Relevant",
    "start": "906000",
    "end": "911880"
  },
  {
    "text": "uh passages from the document within the vector database and then use those passages to uh to",
    "start": "911880",
    "end": "919800"
  },
  {
    "text": "answer the question so if I ask this it's giving me an answer from the document and",
    "start": "919800",
    "end": "926519"
  },
  {
    "text": "um like you can you can find this answer somewhere here in the sources maybe like yeah maybe it",
    "start": "926519",
    "end": "931800"
  },
  {
    "text": "like we wrote it like differently but it came up with this answer from from these",
    "start": "931800",
    "end": "938100"
  },
  {
    "text": "sources um and then it's also like it can maintain context so you can say like",
    "start": "938100",
    "end": "945300"
  },
  {
    "text": "um explain in simple terms",
    "start": "945300",
    "end": "950660"
  },
  {
    "text": "so it knows that you're talking about this so it's not going to talk about something else because um it's it's using context to it's like",
    "start": "950940",
    "end": "958560"
  },
  {
    "text": "using all the context of the previous messages in the in the chat so yeah how does that work and and like",
    "start": "958560",
    "end": "965760"
  },
  {
    "text": "um have you like what pain points have you run into there has there been any interesting kind of like yeah experimentations or just observations",
    "start": "965760",
    "end": "972360"
  },
  {
    "text": "that you've seen where it works well or doesn't work well or something like that yeah that is a really good question because",
    "start": "972360",
    "end": "978839"
  },
  {
    "text": "um one problem is when you ask like explain in simpler terms so a chat base what it's doing is it's also embedding",
    "start": "978839",
    "end": "985620"
  },
  {
    "text": "this and it's looking in the document database in the vector database for uh",
    "start": "985620",
    "end": "991199"
  },
  {
    "text": "for passages that are similar to this but the thing is like this doesn't mention anything about chatbase or it's",
    "start": "991199",
    "end": "996600"
  },
  {
    "text": "not a question about chatbase it's a question about like this right so it's going to come up with sources",
    "start": "996600",
    "end": "1003199"
  },
  {
    "text": "that are not relevant to the question and this is a problem that I'm I'm trying to fix",
    "start": "1003199",
    "end": "1009079"
  },
  {
    "text": "um but like GPT 3.5 and gp2 gpt4 are smart enough to just like ignore all the",
    "start": "1009079",
    "end": "1015860"
  },
  {
    "text": "sources here and they know like they wanna I wanna like explain this in simpler terms so it's going to do that",
    "start": "1015860",
    "end": "1022519"
  },
  {
    "text": "it's going to just ignore all the sources um but in an ideal word I would",
    "start": "1022519",
    "end": "1028339"
  },
  {
    "text": "I would know like this like I don't need to search um when I'm doing this I'm just gonna like explain this so in an ideal word I",
    "start": "1028339",
    "end": "1035780"
  },
  {
    "text": "wouldn't need to search and my like chatbase would know that I'm just going to answer the question without",
    "start": "1035780",
    "end": "1041780"
  },
  {
    "text": "looking in the vector database um for the context stuff for maintaining",
    "start": "1041780",
    "end": "1047000"
  },
  {
    "text": "context one problem is um the context length so what I'm doing",
    "start": "1047000",
    "end": "1052340"
  },
  {
    "text": "now is I'm sending like the last 10 messages of the chat to uh to gpt4 or",
    "start": "1052340",
    "end": "1057799"
  },
  {
    "text": "GPT 3.5 and I'm cutting it off after like 10 messages so if you ask a question about",
    "start": "1057799",
    "end": "1065000"
  },
  {
    "text": "like a message you sent um like half an hour ago where it's it's",
    "start": "1065000",
    "end": "1070340"
  },
  {
    "text": "been more than 10 messages um the chatbot will not be able to uh to explain to like respond to that or it's",
    "start": "1070340",
    "end": "1076220"
  },
  {
    "text": "going to ask you like please explain more um does that make sense yeah that makes sense I think so so two",
    "start": "1076220",
    "end": "1084500"
  },
  {
    "text": "um so well so I think like one uh so so I",
    "start": "1084500",
    "end": "1089539"
  },
  {
    "text": "I've run into this problem a few times as well and so like one the naive thing that I tried to do was just like embed",
    "start": "1089539",
    "end": "1095000"
  },
  {
    "text": "the whole conversation and pass that as like the vector and that like so there's I think the problems mostly around like",
    "start": "1095000",
    "end": "1101480"
  },
  {
    "text": "what documents you get back during like the retrieval step because hopefully the language model should be smart enough to realize but like you want to give it",
    "start": "1101480",
    "end": "1107900"
  },
  {
    "text": "kind of like the the best um stuff so yeah like you know",
    "start": "1107900",
    "end": "1113299"
  },
  {
    "text": "like I think the name thing to do is just like embed the whole conversation but then if you're like changing topics you get like bad bad things and so",
    "start": "1113299",
    "end": "1120500"
  },
  {
    "text": "there's some issues there I've sort of I've seen so there's one thing in link chain this helps with this and then there's one other thing that I've heard",
    "start": "1120500",
    "end": "1127100"
  },
  {
    "text": "of outside just just for context for people that that I haven't tried but that I've heard it works well the thing",
    "start": "1127100",
    "end": "1132260"
  },
  {
    "text": "that we do in Lane chain is basically and this will make it a little bit more complex so you'll lose some like latency and stuff but like based on the",
    "start": "1132260",
    "end": "1138320"
  },
  {
    "text": "conversation you can first do a pass to like generate a standalone question",
    "start": "1138320",
    "end": "1143660"
  },
  {
    "text": "um so like based on this uh if you had like what is Chap is chess base is an AI bot Builder explain in simpler terms the",
    "start": "1143660",
    "end": "1149900"
  },
  {
    "text": "Standalone question might be like explain in simple terms what is chat based and then you kind of like embed",
    "start": "1149900",
    "end": "1155000"
  },
  {
    "text": "that retrieve documents and then use that for the answer the other thing that",
    "start": "1155000",
    "end": "1160160"
  },
  {
    "text": "I've seen or heard could work well um is uh uh basically do some",
    "start": "1160160",
    "end": "1165740"
  },
  {
    "text": "classification on the previous chat messages and so then basically you try to see like are the first like or is it",
    "start": "1165740",
    "end": "1173059"
  },
  {
    "text": "like what chat messages are relevant for the question and so then if you're changing topics ideally it's like no",
    "start": "1173059",
    "end": "1178520"
  },
  {
    "text": "this isn't relevant don't include this and so then you don't include it but then if there are previous ones that are relevant you include all those embed",
    "start": "1178520",
    "end": "1184220"
  },
  {
    "text": "those retrieve it and then fetch it I I haven't actually experimented with that one so I'd be curious if other people",
    "start": "1184220",
    "end": "1190520"
  },
  {
    "text": "have um but yeah and I don't know actually yeah Caleb and Andrew I don't know if",
    "start": "1190520",
    "end": "1195740"
  },
  {
    "text": "you guys have run into this as well or if they I'm sure there's like a million as as Caleb said this is all kind of like hacks and heuristics so yeah I'm",
    "start": "1195740",
    "end": "1201679"
  },
  {
    "text": "curious if you guys have any kind of like um yeah thoughts on that or alternative",
    "start": "1201679",
    "end": "1206720"
  },
  {
    "text": "methods or anything well this is a great",
    "start": "1206720",
    "end": "1212500"
  },
  {
    "text": "I'm already I have so many questions to ask everyone here but Andrew I think you cut in you might have had something",
    "start": "1212780",
    "end": "1218000"
  },
  {
    "text": "directly related to that yeah I just want to mention like pulling",
    "start": "1218000",
    "end": "1224120"
  },
  {
    "text": "the wrong context is the Achilles Hill and heel and all of these things like and so I I I think I like your your",
    "start": "1224120",
    "end": "1231260"
  },
  {
    "text": "suggestion of trying to fill it to one just single question",
    "start": "1231260",
    "end": "1236360"
  },
  {
    "text": "um and yeah I mean that's exactly right the distraction or what kill all these document question answer methods so and",
    "start": "1236360",
    "end": "1243380"
  },
  {
    "text": "when I do this that's why I kind of made that demo showing of like having an agent is that you want to build your",
    "start": "1243380",
    "end": "1248960"
  },
  {
    "text": "Corpus really selectively like one of the first things people tried with paper Q is to put in like a thousand papers",
    "start": "1248960",
    "end": "1254179"
  },
  {
    "text": "and then just have you know all of human knowledge but then it just kept pulling in like the wrong context I think",
    "start": "1254179",
    "end": "1259820"
  },
  {
    "text": "there's some cool ideas in llama index like using a tree search for that um but yeah I think what you just",
    "start": "1259820",
    "end": "1264980"
  },
  {
    "text": "suggested is a really interesting idea of like having like a step where you try to distill the question so you don't",
    "start": "1264980",
    "end": "1270799"
  },
  {
    "text": "have any kind of things that can get you distracted in there",
    "start": "1270799",
    "end": "1275200"
  },
  {
    "text": "100 100 one of the things that we first expected was that the more you gave the model the",
    "start": "1275900",
    "end": "1282440"
  },
  {
    "text": "better it would perform no matter what and very quickly we found that that was not the case",
    "start": "1282440",
    "end": "1287480"
  },
  {
    "text": "um you really do want to give it relevant information and prevent it from getting sort of I guess Poisoned With",
    "start": "1287480",
    "end": "1293659"
  },
  {
    "text": "ill relevant information because it just makes it more likely to get off topic and distract it and",
    "start": "1293659",
    "end": "1298700"
  },
  {
    "text": "hallucinate yeah so okay so so this I'm so I was going to ask this at the end as",
    "start": "1298700",
    "end": "1303860"
  },
  {
    "text": "one because this is one of the big things I've been thinking about but like retrieval methods are you and we can",
    "start": "1303860",
    "end": "1309200"
  },
  {
    "text": "just do a quick like yes or no now and we can discuss this more at the end but are you guys doing anything more complex",
    "start": "1309200",
    "end": "1314240"
  },
  {
    "text": "than semantic search um any type of like hybrid search any type of tree based things or is it is it",
    "start": "1314240",
    "end": "1320299"
  },
  {
    "text": "still just semantic search um yeah with embeddings at the moment",
    "start": "1320299",
    "end": "1325760"
  },
  {
    "text": "yeah I'm doing top case in metric search",
    "start": "1325760",
    "end": "1329919"
  },
  {
    "text": "uh we started with oh go for it Andrew yeah",
    "start": "1330860",
    "end": "1336020"
  },
  {
    "text": "yeah sorry I I we use max marginal relevance and then like I said we use this we pull up more than we need and",
    "start": "1336020",
    "end": "1343100"
  },
  {
    "text": "then this summarization tool usually down filter because since we can eliminate things but that I've tried trees",
    "start": "1343100",
    "end": "1348860"
  },
  {
    "text": "I'm trying right now actually having read the paper title and summary",
    "start": "1348860",
    "end": "1354980"
  },
  {
    "text": "um as well so still do semantic search and then you take a title of persona eliminate anything because it realizes",
    "start": "1354980",
    "end": "1361820"
  },
  {
    "text": "it's from like an irrelevant source which may not be visible from the chunk but you're right that's an important question",
    "start": "1361820",
    "end": "1368240"
  },
  {
    "text": "really really important question um we started out with top K semantic search",
    "start": "1368240",
    "end": "1373640"
  },
  {
    "text": "um very quickly found that while it's really good as a baseline it's not quite what we needed so we ended up moving",
    "start": "1373640",
    "end": "1379880"
  },
  {
    "text": "towards hybrid search and some of our own filtering on top of it um I'm really curious about tree based",
    "start": "1379880",
    "end": "1386780"
  },
  {
    "text": "search approaches um and sort of llm based search approaches so for everyone in the audience you know Vector search is",
    "start": "1386780",
    "end": "1393380"
  },
  {
    "text": "basically just using open Ai embeddings and then using similarity to find the ones that are most similar",
    "start": "1393380",
    "end": "1399080"
  },
  {
    "text": "um but uh you know if I'm understanding correctly Andrew tree based search or llm search are more like you use an llm",
    "start": "1399080",
    "end": "1406280"
  },
  {
    "text": "and you go through each document and that allows you to like using a gpt4 prompts",
    "start": "1406280",
    "end": "1412580"
  },
  {
    "text": "find the correct documents is that is that accurate",
    "start": "1412580",
    "end": "1417280"
  },
  {
    "text": "um yeah so basically the idea is to organize like maybe a document levels so now you have a document which is chunked",
    "start": "1418039",
    "end": "1424640"
  },
  {
    "text": "and then that document has a one paragraph summary and then so when you go to do your search you search over",
    "start": "1424640",
    "end": "1430640"
  },
  {
    "text": "what documents do I want and then so you can use that like Jekyll and Hyde method like I have this question which",
    "start": "1430640",
    "end": "1436460"
  },
  {
    "text": "documents might be good then you have the document and you then have the name of the document then you go find Which documents could be written and then once",
    "start": "1436460",
    "end": "1443059"
  },
  {
    "text": "you find okay I want these five documents then I will descend and look through them for chunks me like I'm",
    "start": "1443059",
    "end": "1448460"
  },
  {
    "text": "usually interested in scientific papers so I've been using the citation and gpt4 or 3.5 like it knows enough about papers",
    "start": "1448460",
    "end": "1455360"
  },
  {
    "text": "to know like what the journal is what the title is if it's the right thing so I'm kind of working in that level but",
    "start": "1455360",
    "end": "1460700"
  },
  {
    "text": "you can absolutely do something very sophisticated with a tree right right so you know kind of what I",
    "start": "1460700",
    "end": "1467480"
  },
  {
    "text": "wanted to bring up about this is uh sort of contrast different objectives that",
    "start": "1467480",
    "end": "1472760"
  },
  {
    "text": "you have with your model and how you can choose different um question answering strategies",
    "start": "1472760",
    "end": "1479900"
  },
  {
    "text": "to achieve your specific goal so for instance for us we are really interested in those sort",
    "start": "1479960",
    "end": "1486260"
  },
  {
    "text": "of you know either map reducing like I think you're doing Andrew or um you know doing a tree search Etc with",
    "start": "1486260",
    "end": "1492200"
  },
  {
    "text": "llms but it's really important for us to keep our costs down um because we're being used uh you know",
    "start": "1492200",
    "end": "1500120"
  },
  {
    "text": "as we start to scale it just starts to get caught it starts to cost more and more and more so we have focused on as",
    "start": "1500120",
    "end": "1507080"
  },
  {
    "text": "you know the most affordable approaches and Vector search and keyword search",
    "start": "1507080",
    "end": "1512360"
  },
  {
    "text": "mixed together is pretty affordable because you don't have to make a bunch of llm calls every single time you make",
    "start": "1512360",
    "end": "1518480"
  },
  {
    "text": "your search you just have to embed and then go look up at a database",
    "start": "1518480",
    "end": "1523700"
  },
  {
    "text": "um however you said when you said hybrid search before so you were referring to basically Vector search and keyword",
    "start": "1523700",
    "end": "1529820"
  },
  {
    "text": "search and so could you yeah how exactly like what exactly does that mean how are you doing that like under the hood",
    "start": "1529820",
    "end": "1534860"
  },
  {
    "text": "actually wait before we go that maybe let's finish up on on chat base um",
    "start": "1534860",
    "end": "1540940"
  },
  {
    "text": "yeah sorry I I this is I think this is a really interesting thing that there's a lot of stuff to discuss but yeah sir is",
    "start": "1540940",
    "end": "1547460"
  },
  {
    "text": "there anything else that you'd like to to highlight yeah I mean this stuff is a rabbit hole",
    "start": "1547460",
    "end": "1553039"
  },
  {
    "text": "so like I can go on but I think I think like this is basically it um and then",
    "start": "1553039",
    "end": "1558740"
  },
  {
    "text": "you can like embed the chat bot on your website like this um so you can like ask it questions you",
    "start": "1558740",
    "end": "1564860"
  },
  {
    "text": "can like um if you go to the settings actually I want to show this so you can edit the",
    "start": "1564860",
    "end": "1570200"
  },
  {
    "text": "Bass Pro so this is currently like my default page font that I'm using",
    "start": "1570200",
    "end": "1575480"
  },
  {
    "text": "um I'm saying like I want you to act as a document that I'm having a conversation with and I'm saying that instead of saying",
    "start": "1575480",
    "end": "1583159"
  },
  {
    "text": "um this is a document and I want you to help me like understand it because when",
    "start": "1583159",
    "end": "1588260"
  },
  {
    "text": "I use the second one like when I use this is a document and I want you to help me understand it",
    "start": "1588260",
    "end": "1593419"
  },
  {
    "text": "um when I ask a question sometimes it says like the text says this so like when I ask it what is chat base it's",
    "start": "1593419",
    "end": "1599779"
  },
  {
    "text": "gonna say like uh the text says chat base is this and I don't think this is like a good experience I think I want it",
    "start": "1599779",
    "end": "1606260"
  },
  {
    "text": "to be I want to have a chat with the document not about the document if that makes sense so I've been like experimenting a",
    "start": "1606260",
    "end": "1613279"
  },
  {
    "text": "lot with the system messages here and I also added an option for the users to uh to like edit this so you can like give",
    "start": "1613279",
    "end": "1619760"
  },
  {
    "text": "it a name you can give it like a personality you can you can just tell it to like behave in any way you want",
    "start": "1619760",
    "end": "1626480"
  },
  {
    "text": "um and you can change the model too and you can also like change the chat interface but yeah this",
    "start": "1626480",
    "end": "1633320"
  },
  {
    "text": "is like basically it um one question I have about that is do you see users kind of changing this the",
    "start": "1633320",
    "end": "1639559"
  },
  {
    "text": "The Prompt often and like if so like what like like what are the are they giving it like personality is that the",
    "start": "1639559",
    "end": "1644659"
  },
  {
    "text": "main kind of like change they're making like how are they using that all the time like most of most of like my my",
    "start": "1644659",
    "end": "1649820"
  },
  {
    "text": "power users or the people who use it the most they have like a name they have a personality they say like every second",
    "start": "1649820",
    "end": "1656179"
  },
  {
    "text": "message or like every third message I want you to to make a joke or something or I want you to be polite",
    "start": "1656179",
    "end": "1663020"
  },
  {
    "text": "um and they give it like emojis too like use emojis um whenever you're answering the",
    "start": "1663020",
    "end": "1668360"
  },
  {
    "text": "question and this this gives you like you're basically creating like a persona for your company if that makes sense",
    "start": "1668360",
    "end": "1674240"
  },
  {
    "text": "because it's a chatbot that has a name it has a personality and it it knows",
    "start": "1674240",
    "end": "1679820"
  },
  {
    "text": "everything about your company and can answer any question and it doesn't have to be a company it can be like a blog or",
    "start": "1679820",
    "end": "1685159"
  },
  {
    "text": "or a person even um and yeah this um like customizing this",
    "start": "1685159",
    "end": "1692419"
  },
  {
    "text": "helps too because um you can change this message to be like anything you want",
    "start": "1692419",
    "end": "1699100"
  },
  {
    "text": "um and and like when you send this to gpt3 like when you send the conversation it's",
    "start": "1699320",
    "end": "1705380"
  },
  {
    "text": "gonna see like how it behaved in previous messages and it it will try to mimic that in in the future messages so",
    "start": "1705380",
    "end": "1711440"
  },
  {
    "text": "like if you make it behave a certain way and like these initial messages um the next messages are more likely to",
    "start": "1711440",
    "end": "1717200"
  },
  {
    "text": "to follow the same format if that makes sense um",
    "start": "1717200",
    "end": "1722480"
  },
  {
    "text": "but yeah and then there's also like an API if you wanna um if you have a create a chat bot on",
    "start": "1722480",
    "end": "1728120"
  },
  {
    "text": "chatbase and if you want to chat with it you can do that using the API so you can you can build like a chat base for you",
    "start": "1728120",
    "end": "1733760"
  },
  {
    "text": "the only difference is that it's going to be limited to the amount of chat Bots uh that you can build like based on your",
    "start": "1733760",
    "end": "1740720"
  },
  {
    "text": "plan but like these are all the apis that I'm using for chatbase I made them",
    "start": "1740720",
    "end": "1746120"
  },
  {
    "text": "like available for for everyone I know there's developers here so they might be interested in this awesome",
    "start": "1746120",
    "end": "1753519"
  },
  {
    "text": "any questions or one other one other the last question I have and I think this is maybe like yeah what type of documents",
    "start": "1755720",
    "end": "1764720"
  },
  {
    "text": "do you support um and like yeah how like yeah are there how have you found that like are there",
    "start": "1764720",
    "end": "1770600"
  },
  {
    "text": "ones that are that you support better are there ones that you're working on adding like there's a long tail in terms",
    "start": "1770600",
    "end": "1776240"
  },
  {
    "text": "of different types of documents and yeah I'm curious like yeah how you think",
    "start": "1776240",
    "end": "1781880"
  },
  {
    "text": "about that yeah so currently like when you click on build your chat bot",
    "start": "1781880",
    "end": "1787039"
  },
  {
    "text": "um it gives you like this so data sources can can either even uh either via file text or a website",
    "start": "1787039",
    "end": "1793220"
  },
  {
    "text": "so files are like PDFs uh text files Word documents and like uh yeah that's",
    "start": "1793220",
    "end": "1800779"
  },
  {
    "text": "it I think and then next you can like paste your text here and website is you give it like a",
    "start": "1800779",
    "end": "1806840"
  },
  {
    "text": "website and then it uh it crawls it so you can give it like chatbase.com it's",
    "start": "1806840",
    "end": "1812539"
  },
  {
    "text": "gonna like go through every uh page on chatbase.com but the website has to be small I'm trying to like increase this",
    "start": "1812539",
    "end": "1818840"
  },
  {
    "text": "limit um awesome and yeah but but I'm trying to",
    "start": "1818840",
    "end": "1824240"
  },
  {
    "text": "add like more file types like I've heard a lot that people want notion to be integrated in this",
    "start": "1824240",
    "end": "1830659"
  },
  {
    "text": "um so I'm trying to find like a way to add this that is easy So currently I think we can do it by like downloading",
    "start": "1830659",
    "end": "1836179"
  },
  {
    "text": "an ocean page and all the sub pages and then uploading this but I'm trying to find a way where you can like",
    "start": "1836179",
    "end": "1842360"
  },
  {
    "text": "log into your notion through chatbase and then have access to all your documents there and then like choose",
    "start": "1842360",
    "end": "1848299"
  },
  {
    "text": "which documents you want to add to your chat bot this way um and some people ask for like emails",
    "start": "1848299",
    "end": "1854960"
  },
  {
    "text": "some people asked for uh like slack conversations and stuff like that so",
    "start": "1854960",
    "end": "1860120"
  },
  {
    "text": "um but for for the for the documents that work best I think I don't think there's a",
    "start": "1860120",
    "end": "1865460"
  },
  {
    "text": "difference because what what I am doing or what chatbase is doing is that it takes the text uh it like",
    "start": "1865460",
    "end": "1874159"
  },
  {
    "text": "it posted the text from whichever like file type it is and then it removes all",
    "start": "1874159",
    "end": "1879500"
  },
  {
    "text": "the formatting it removes all like that the like the new lines and stuff like that and this I think is what open AI",
    "start": "1879500",
    "end": "1886659"
  },
  {
    "text": "recommends is that like you remove most formatting and you just have like spaces between words and basic punctuation and",
    "start": "1886659",
    "end": "1894440"
  },
  {
    "text": "that's what what chatbase does regardless of um what type of document you're using",
    "start": "1894440",
    "end": "1900380"
  },
  {
    "text": "super interesting I think you're getting a few questions in the chat um maybe we can answer those later but for now I'm",
    "start": "1900380",
    "end": "1906559"
  },
  {
    "text": "going to switch it over to Caleb and we can go to mendable and then we can do a round uh yeah a panel of some of the",
    "start": "1906559",
    "end": "1912740"
  },
  {
    "text": "more popular questions in the in the chat um at the end so reminder to go and upload the questions that you want to",
    "start": "1912740",
    "end": "1918799"
  },
  {
    "text": "get answered awesome thank you thank you and I'm",
    "start": "1918799",
    "end": "1924559"
  },
  {
    "text": "going to show you my screen we're gonna get a little feature of the Lang chain documentation beautiful",
    "start": "1924559",
    "end": "1930440"
  },
  {
    "text": "documentation by the way um so like I was saying before we are chatting t for developer docs so if I",
    "start": "1930440",
    "end": "1938299"
  },
  {
    "text": "hit command K here many of you may have used this if you're fans of langshane uh you have mendable",
    "start": "1938299",
    "end": "1945740"
  },
  {
    "text": "um so I think like the first I'm thinking about different uh you know things I can show that'll be relevant to",
    "start": "1945740",
    "end": "1951679"
  },
  {
    "text": "everyone here um the first one I want to show is sort of how we're dealing with hallucinations",
    "start": "1951679",
    "end": "1958760"
  },
  {
    "text": "or our strategy um and to get the core of the problem and and uh Andrew was talking about this",
    "start": "1958760",
    "end": "1965960"
  },
  {
    "text": "um the more you try and prevent hallucinations the more matter of fact the model is going to be so it's going",
    "start": "1965960",
    "end": "1973159"
  },
  {
    "text": "to well like you asked it try and stay fax however if you want to get it to start generating code which in our case",
    "start": "1973159",
    "end": "1980360"
  },
  {
    "text": "is really important because that's one of our most uh you know valuable use cases",
    "start": "1980360",
    "end": "1985580"
  },
  {
    "text": "um it can actually get in the way of doing that so what we've done is taken the approach of",
    "start": "1985580",
    "end": "1991520"
  },
  {
    "text": "if I ask a question like hello which really has nothing to do with anything of the language chain documentation but",
    "start": "1991520",
    "end": "1998000"
  },
  {
    "text": "you know allows me to talk to the Bots",
    "start": "1998000",
    "end": "2001919"
  },
  {
    "text": "what's going to happen is is that it's still going to answer even though there's no documents that have been",
    "start": "2005980",
    "end": "2011559"
  },
  {
    "text": "retrieved however it's going to disclaim that to you as the user so you know that this isn't based on anything in the",
    "start": "2011559",
    "end": "2017740"
  },
  {
    "text": "documentation you're just having a chat with this llm um however let's say I wanted to uh you",
    "start": "2017740",
    "end": "2025779"
  },
  {
    "text": "know and this is this is one of my favorite use cases I I have a prompt and I just want to turn that into an llm",
    "start": "2025779",
    "end": "2031120"
  },
  {
    "text": "chain without having to actually write all the boilerplate I can just go in there and say I have",
    "start": "2031120",
    "end": "2036880"
  },
  {
    "text": "this prompt with this input can you create an llm chain for me",
    "start": "2036880",
    "end": "2042360"
  },
  {
    "text": "and here we go it creates it and I can just",
    "start": "2043179",
    "end": "2049060"
  },
  {
    "text": "copy paste that and run in my code I also have access to the sources if I'd like to verify that this is actually you",
    "start": "2049060",
    "end": "2055780"
  },
  {
    "text": "know how to do it I think also in this case it cut out a little bit it didn't show the call",
    "start": "2055780",
    "end": "2061960"
  },
  {
    "text": "um but this is how I create the chain and then I can use it later um",
    "start": "2061960",
    "end": "2068320"
  },
  {
    "text": "you'll also notice here we have normal search as well which kind of goes to Harrison's question of you know how",
    "start": "2068320",
    "end": "2074200"
  },
  {
    "text": "we're combining Vector search and keyword search um",
    "start": "2074200",
    "end": "2080040"
  },
  {
    "text": "we found very quickly that Vector search does pretty well",
    "start": "2080339",
    "end": "2085599"
  },
  {
    "text": "however it tends to pull a lot of documents in and then you need to set",
    "start": "2085599",
    "end": "2090878"
  },
  {
    "text": "the threshold correctly so Vector search finds documents by taking",
    "start": "2090879",
    "end": "2097060"
  },
  {
    "text": "one embedding and then comparing it to all the embeddings of the documents in your database and figuring out how",
    "start": "2097060",
    "end": "2103480"
  },
  {
    "text": "single similar they are so you can say like 0.78 threshold and anything that's got a similarity of 0.7",
    "start": "2103480",
    "end": "2110380"
  },
  {
    "text": "or higher is pulled in versus pulled out um and so is that how you're doing the limit it looks like so when you did the",
    "start": "2110380",
    "end": "2116619"
  },
  {
    "text": "first one and you're like there's no relevant documents so basically you're doing some semantic search with some filtering on the results based on some",
    "start": "2116619",
    "end": "2123460"
  },
  {
    "text": "score yes correct that's part of it right um so",
    "start": "2123460",
    "end": "2129579"
  },
  {
    "text": "the you know that sort of filters out a lot of the results um however getting that threshold right",
    "start": "2129579",
    "end": "2134800"
  },
  {
    "text": "especially when you're ingesting a lot of different documents from a lot of different places in a lot of different formats can be quite difficult",
    "start": "2134800",
    "end": "2142960"
  },
  {
    "text": "um so we actually on Tata to add another layer of keyword search this allows us to selectively remove or",
    "start": "2142960",
    "end": "2151540"
  },
  {
    "text": "filter certain documents out it also allows us sometimes to find documents that the semantic search doesn't do",
    "start": "2151540",
    "end": "2158140"
  },
  {
    "text": "um so so yeah could you like dive into that a little bit more so so you do some",
    "start": "2158140",
    "end": "2163300"
  },
  {
    "text": "yeah so how so you do some like cement and if you also if you don't want to give away the secrets of of your your",
    "start": "2163300",
    "end": "2169240"
  },
  {
    "text": "company because it's a legitimate company that's fine as well but I'm just trying so you do some semantic search you get back some documents and then you",
    "start": "2169240",
    "end": "2175720"
  },
  {
    "text": "do some keyword search on top of the retrieve documents and on top of the all the other documents or do you just do",
    "start": "2175720",
    "end": "2181359"
  },
  {
    "text": "them separately and then combine them yeah what I'd say is this let's you know",
    "start": "2181359",
    "end": "2188560"
  },
  {
    "text": "um the the general takeaway is that you can combine these both for better results",
    "start": "2188560",
    "end": "2194020"
  },
  {
    "text": "um what I would say is actually the hardest piece of all of this is putting together an evaluation set so you're working on",
    "start": "2194020",
    "end": "2202240"
  },
  {
    "text": "something like this um I would definitely recommend starting out with heuristics like just",
    "start": "2202240",
    "end": "2208900"
  },
  {
    "text": "literally doing manual testing like Andrew said like dig in and then find cases that work and",
    "start": "2208900",
    "end": "2214420"
  },
  {
    "text": "don't work um but as soon as you can put together",
    "start": "2214420",
    "end": "2219579"
  },
  {
    "text": "a set of questions that allows you to automatically evaluate how well it's",
    "start": "2219579",
    "end": "2225040"
  },
  {
    "text": "working um because questions look like because I think like a lot of the difficulties",
    "start": "2225040",
    "end": "2230740"
  },
  {
    "text": "that some of you know the answers are like like what should the answers even be like if it says like one word wrong",
    "start": "2230740",
    "end": "2236200"
  },
  {
    "text": "is that wrong so like yeah are you constructing examples that you can do exact matches on or are you doing some",
    "start": "2236200",
    "end": "2242020"
  },
  {
    "text": "yeah how and maybe this is a good pivot to adjust the general Roundtable unless there's more features of mendable that",
    "start": "2242020",
    "end": "2248320"
  },
  {
    "text": "you wanted to show off sure I mean what I would like to say is that if you're interested in embedding a",
    "start": "2248320",
    "end": "2253839"
  },
  {
    "text": "chat bot in your dot developer documentation documentation check out our website you know we make it really",
    "start": "2253839",
    "end": "2259720"
  },
  {
    "text": "easy to do this it's one line of code and react we you know we take care of all the scraping and document ingestion",
    "start": "2259720",
    "end": "2265720"
  },
  {
    "text": "for you sort of like how chat based does we also have analytics um so that you can see the messages that",
    "start": "2265720",
    "end": "2271660"
  },
  {
    "text": "you're getting and um uh yeah I I would recommend just taking a look at the website uh",
    "start": "2271660",
    "end": "2278380"
  },
  {
    "text": "what we we're kind of moving on to what you were saying I want to see those analytics by the way I haven't I haven't",
    "start": "2278380",
    "end": "2284320"
  },
  {
    "text": "seen them uh I haven't seen them for the link chain docs so I wanna I wanna see those it'll be coming very soon I in fact",
    "start": "2284320",
    "end": "2290800"
  },
  {
    "text": "that's actually what I'm working on right now um uh so",
    "start": "2290800",
    "end": "2297480"
  },
  {
    "text": "what was what was the question that you had right before that uh evaluation and I think this is a good a good chance to",
    "start": "2297480",
    "end": "2303820"
  },
  {
    "text": "open it up to everyone as well but yeah how do you guys think about evaluation for these things and maybe start with k we maybe do a reverse order Kayla the",
    "start": "2303820",
    "end": "2310420"
  },
  {
    "text": "author and then Andrew so so yeah once again like I was saying I think that evaluation is one of the",
    "start": "2310420",
    "end": "2316060"
  },
  {
    "text": "trickiest parts to get right um I also don't necessarily think it's something you need to do immediately like it's much better you can get a lot",
    "start": "2316060",
    "end": "2322599"
  },
  {
    "text": "done just with heuristic evaluation just trying it out and figuring it out um",
    "start": "2322599",
    "end": "2328780"
  },
  {
    "text": "but then you have the problem of okay one you need to show to potentially",
    "start": "2328780",
    "end": "2334180"
  },
  {
    "text": "customers how well it's performing and two um you know if you want to let's say try",
    "start": "2334180",
    "end": "2340180"
  },
  {
    "text": "out a different evaluation method or excuse me try out a different information retrieval method you need some some way of actually uh evaluating",
    "start": "2340180",
    "end": "2347619"
  },
  {
    "text": "whether or not that's going to be better it's like how do you fly a plane if you don't have",
    "start": "2347619",
    "end": "2353500"
  },
  {
    "text": "instrumentation you don't know whether or not you're getting better or worse um so there's some really key problems with",
    "start": "2353500",
    "end": "2359619"
  },
  {
    "text": "that like Harrison you were saying you know how do you evaluate this model",
    "start": "2359619",
    "end": "2364839"
  },
  {
    "text": "right it's it's coming up with a creative you know undeterministic or non-deterministic answer like you can't",
    "start": "2364839",
    "end": "2371680"
  },
  {
    "text": "just say yes this is good and yes this is about it um so I've seen a couple approaches that",
    "start": "2371680",
    "end": "2377560"
  },
  {
    "text": "work pretty decently first of all I would break your retrieval pipeline into its own",
    "start": "2377560",
    "end": "2384579"
  },
  {
    "text": "evaluation step so yeah you know you can",
    "start": "2384579",
    "end": "2391020"
  },
  {
    "text": "you can evaluate how well you're retrieving relevant documents on its own",
    "start": "2391020",
    "end": "2396460"
  },
  {
    "text": "without even bringing generation into account and how do you do that",
    "start": "2396460",
    "end": "2402960"
  },
  {
    "text": "um I mean this is there's quite a bit of literature on this I would just recommend going and you know looking at papers on how you know",
    "start": "2403000",
    "end": "2409839"
  },
  {
    "text": "you know how Squad does this or uh or frankly just go to chatgpt and just be",
    "start": "2409839",
    "end": "2415540"
  },
  {
    "text": "like hey how should I evaluate my information retrieval Pipeline and it will give you a ton of information on",
    "start": "2415540",
    "end": "2421060"
  },
  {
    "text": "how to go about this um once you have that down there's the next",
    "start": "2421060",
    "end": "2429339"
  },
  {
    "text": "step which is okay now how do I evaluate the generation piece and",
    "start": "2429339",
    "end": "2434680"
  },
  {
    "text": "I think you know I don't have a great answer on how to do this perfectly but I know that what",
    "start": "2434680",
    "end": "2440800"
  },
  {
    "text": "openai does and you know what we've been doing is you create a classification",
    "start": "2440800",
    "end": "2447820"
  },
  {
    "text": "prompt that basically goes between a golden answer which is like what the answer should be according to you and",
    "start": "2447820",
    "end": "2455079"
  },
  {
    "text": "then the answer it generates and you have that prompt say yes this is a good answer or no this",
    "start": "2455079",
    "end": "2461680"
  },
  {
    "text": "is a good answer or score it or what have you um it kind of turns out these models are",
    "start": "2461680",
    "end": "2467500"
  },
  {
    "text": "pretty good at evaluating themselves even though um sometimes they're not good at",
    "start": "2467500",
    "end": "2473800"
  },
  {
    "text": "generating the answers in the first place so those are a few approaches but I'd be really excited to hear from Andrew and",
    "start": "2473800",
    "end": "2480280"
  },
  {
    "text": "Yasser if they've had any strategies in this space or if anyone in the audience",
    "start": "2480280",
    "end": "2485980"
  },
  {
    "text": "frankly because I I find that this is one of the most difficult and",
    "start": "2485980",
    "end": "2492099"
  },
  {
    "text": "um most uh you know there's a lot of work to be done here and if anyone has any",
    "start": "2492099",
    "end": "2498040"
  },
  {
    "text": "ideas please reach out to me and let me know because we'd love to chat yeah yeah sir what have you done for this",
    "start": "2498040",
    "end": "2504640"
  },
  {
    "text": "so for for retrieval I I think doing the hybrid approach would",
    "start": "2504640",
    "end": "2509980"
  },
  {
    "text": "make sense I haven't like experimented with it um but for now I'm just like",
    "start": "2509980",
    "end": "2515260"
  },
  {
    "text": "I'm just doing it manually I'm just checking like when I ask this question um are the documents or like are the",
    "start": "2515260",
    "end": "2521020"
  },
  {
    "text": "passages that are coming back do they make sense do they answer the question and I think top case similarity search",
    "start": "2521020",
    "end": "2526960"
  },
  {
    "text": "is good enough for for like most questions the only problem is as I said when you're like asking question about",
    "start": "2526960",
    "end": "2534099"
  },
  {
    "text": "like a different topic in the conversation um or like when you ask a question it is vague it doesn't mention like a keyword",
    "start": "2534099",
    "end": "2540520"
  },
  {
    "text": "in the in the document like for example explain in simpler terms",
    "start": "2540520",
    "end": "2545680"
  },
  {
    "text": "so this is this is the problem and I think what Harrison said about like going through the conversation and",
    "start": "2545680",
    "end": "2551320"
  },
  {
    "text": "trying to create a new question giving all given all of the conversation I think would be the best approach for",
    "start": "2551320",
    "end": "2557440"
  },
  {
    "text": "that but for the generation part as I said like chat base it gives you like access to the base prompt or like the",
    "start": "2557440",
    "end": "2564280"
  },
  {
    "text": "the system message and that like allows the user of the chatbot to",
    "start": "2564280",
    "end": "2569640"
  },
  {
    "text": "like they they have the burden of experimentation I like I have a good uh a good like default prompt but if they",
    "start": "2569640",
    "end": "2577420"
  },
  {
    "text": "wanna like uh change it or like add stuff to it or remove stuff to it um I don't have like like a framework to",
    "start": "2577420",
    "end": "2584079"
  },
  {
    "text": "to evaluate the answers after they change it so right now I think it manually is is the best way to do it",
    "start": "2584079",
    "end": "2591099"
  },
  {
    "text": "makes sense and Andrew what about you and for agents as well like now you've got these more complex things so how do",
    "start": "2591099",
    "end": "2596440"
  },
  {
    "text": "you think about evaluating those yeah I think you know hearing yesterday",
    "start": "2596440",
    "end": "2601900"
  },
  {
    "text": "Caleb I think it's clear that we have different goals so like they're trying to build a product and you got to balance cost and user experience I want",
    "start": "2601900",
    "end": "2609339"
  },
  {
    "text": "to build the most like insane q a thing that costs a lot of money and has a ton of options so like we try Max",
    "start": "2609339",
    "end": "2617800"
  },
  {
    "text": "margin relevance like we have llms check all the context and like I have a set of",
    "start": "2617800",
    "end": "2623079"
  },
  {
    "text": "questions that I want to try so here's how I evaluate I have an answer and I get the answer",
    "start": "2623079",
    "end": "2629200"
  },
  {
    "text": "for my tool and then I have pt4 tell me if the answer is correct or not I mean that's how I solve all my problems in",
    "start": "2629200",
    "end": "2634839"
  },
  {
    "text": "life right now is more API tokens so that's how we click on this that's a that's a great answer",
    "start": "2634839",
    "end": "2641980"
  },
  {
    "text": "um by the way by the way I know that I know that I said that thing keeping costs down which is definitely a concern that",
    "start": "2641980",
    "end": "2648160"
  },
  {
    "text": "we have that you might not um at the same time though I'm listening to everything you're saying and I'm going wow these are these are some good",
    "start": "2648160",
    "end": "2654460"
  },
  {
    "text": "ideas so um yeah the the reason this is so",
    "start": "2654460",
    "end": "2659500"
  },
  {
    "text": "exciting to me is you know I think one evaluation is really hard and so I think it's great to get all your guys's taken on it because I honestly and yeah I",
    "start": "2659500",
    "end": "2666460"
  },
  {
    "text": "think there's uh and I think it's you know I think it's hard and I think the thing that people do right now is they",
    "start": "2666460",
    "end": "2671500"
  },
  {
    "text": "just look at things by eye and I I don't think that's terrible I think that's a great like easy first pass to get started and I think it's that's",
    "start": "2671500",
    "end": "2677140"
  },
  {
    "text": "completely reasonable um but I think it's also really interesting to see what people are experimenting with same with retrieval",
    "start": "2677140",
    "end": "2682660"
  },
  {
    "text": "like semantic search is great for a majority of the use cases that's what people are using that's completely fine but you know in in LinkedIn one of the",
    "start": "2682660",
    "end": "2689500"
  },
  {
    "text": "refactors we did last week was to make it just now so you can use a generic retriever object and so selfishly I'm",
    "start": "2689500",
    "end": "2694540"
  },
  {
    "text": "really excited to hear what you guys are talking about because I'm hoping to to either add some stuff like that in or",
    "start": "2694540",
    "end": "2699760"
  },
  {
    "text": "hopefully getting some you know the the retriever interface is so simple I'm hoping it's uh it's literally one method",
    "start": "2699760",
    "end": "2705460"
  },
  {
    "text": "um so I'm hoping that there'll be some like more interesting retrieval methods to get in and then there's a question of how to evaluate so I'm really interested",
    "start": "2705460",
    "end": "2711520"
  },
  {
    "text": "in all this um but I've asked enough questions so I'm gonna go to the chat and ask some from there",
    "start": "2711520",
    "end": "2717940"
  },
  {
    "text": "um the first one um the first ones okay the first one is basically on like using",
    "start": "2717940",
    "end": "2724960"
  },
  {
    "text": "um like local embeddings and llms basically to to not depend on API providers so that one can do question",
    "start": "2724960",
    "end": "2730720"
  },
  {
    "text": "answering on private documents have you guys experimented with that at all",
    "start": "2730720",
    "end": "2735940"
  },
  {
    "text": "um so so not using like open Ai and basically using hugging face or stuff locally",
    "start": "2735940",
    "end": "2741700"
  },
  {
    "text": "and actually turning this also into a product question for the products out there have you heard a demand for kind",
    "start": "2741700",
    "end": "2747339"
  },
  {
    "text": "of like people not wanting to send their data to uh to open AI or other providers",
    "start": "2747339",
    "end": "2753520"
  },
  {
    "text": "is that a consideration for for customers at the moment or not really and maybe we can go maybe we can start",
    "start": "2753520",
    "end": "2758920"
  },
  {
    "text": "with Andrew and then and then go back around yeah this is a lot of good questions",
    "start": "2758920",
    "end": "2764740"
  },
  {
    "text": "here so first of all this absolute demand so my drug Discovery and a drug",
    "start": "2764740",
    "end": "2770079"
  },
  {
    "text": "Discovery right like you don't want your stuff ending up anywhere right because it costs you lots of money",
    "start": "2770079",
    "end": "2775359"
  },
  {
    "text": "um so there's a lot of demand um I've experimented with a sentence Transformer libraries and using local",
    "start": "2775359",
    "end": "2780720"
  },
  {
    "text": "models I've got really poor performance so far so I haven't lowered it further",
    "start": "2780720",
    "end": "2786640"
  },
  {
    "text": "um I'm really interested in exploring though like the summarization step locally I think that's where a lot of",
    "start": "2786640",
    "end": "2791800"
  },
  {
    "text": "the cost is and I think that's something that could really be fine-tuned so I've been messing around with llama a little bit but I haven't made much progress",
    "start": "2791800",
    "end": "2797859"
  },
  {
    "text": "there but that is I think really important future work especially because like a lot of what we do is we",
    "start": "2797859",
    "end": "2804400"
  },
  {
    "text": "basically have prompts like I have seven prompts that are for the seven different tasks I do on my repo right it'd be",
    "start": "2804400",
    "end": "2809500"
  },
  {
    "text": "great to just like burn those into a smaller language model um and so yeah that's something I'm",
    "start": "2809500",
    "end": "2814780"
  },
  {
    "text": "really interested in yeah sir yeah for me like I hear this this",
    "start": "2814780",
    "end": "2820660"
  },
  {
    "text": "feature request every day like people have privacy concerns they don't want to send their data to open AI they don't",
    "start": "2820660",
    "end": "2826480"
  },
  {
    "text": "want to store it on like vector databases so what I'm trying to do with",
    "start": "2826480",
    "end": "2831520"
  },
  {
    "text": "chatbase is I want to have like a version of it that you can uh host",
    "start": "2831520",
    "end": "2836800"
  },
  {
    "text": "locally whatever like you choose whatever your provider is",
    "start": "2836800",
    "end": "2841960"
  },
  {
    "text": "um I haven't like started working on that yet but I think there's definitely demand for this so",
    "start": "2841960",
    "end": "2847900"
  },
  {
    "text": "um I'll be working on this soon all right um so I I think I have an interesting",
    "start": "2847900",
    "end": "2853960"
  },
  {
    "text": "take here um I mean one yes and everything everyone's saying",
    "start": "2853960",
    "end": "2859480"
  },
  {
    "text": "um and local LMS are going to be uh you know a big step in the field etc etc",
    "start": "2859480",
    "end": "2867280"
  },
  {
    "text": "um hear this all the time as well people definitely do want to have some sort of local version that they can run",
    "start": "2867280",
    "end": "2874420"
  },
  {
    "text": "I do wonder how important it's going to be moving forward um I was just talking to someone from go",
    "start": "2874420",
    "end": "2881140"
  },
  {
    "text": "to market at openai and they you know already are working on SOC compliance",
    "start": "2881140",
    "end": "2887380"
  },
  {
    "text": "etc etc for what they're doing so so maybe in drug Discovery a really really high sort of like proprietary data",
    "start": "2887380",
    "end": "2893619"
  },
  {
    "text": "applications that will be important but the analogy is you know how many people",
    "start": "2893619",
    "end": "2899260"
  },
  {
    "text": "care about sending their data to AWS um or you know having all their web traffic be on AWS uh you know there",
    "start": "2899260",
    "end": "2906220"
  },
  {
    "text": "certainly are some that want unpre on-prem on-prem compute excuse me but",
    "start": "2906220",
    "end": "2911980"
  },
  {
    "text": "um I think the majority of people are okay sending their data to the cloud um",
    "start": "2911980",
    "end": "2917380"
  },
  {
    "text": "we'll see how that plays out I know it's not a you know it's not a one-to-one comparison um what I was really interested in was",
    "start": "2917380",
    "end": "2923380"
  },
  {
    "text": "what Andrew was saying about how you can you know basically use different models for different things you know maybe you",
    "start": "2923380",
    "end": "2929859"
  },
  {
    "text": "know local models are cheaper too you can run them on your own compute Etc",
    "start": "2929859",
    "end": "2935380"
  },
  {
    "text": "um so you know that's something that we've been looking at a lot is like can we take this specific step in the process and move it to a cheaper model",
    "start": "2935380",
    "end": "2942760"
  },
  {
    "text": "that's quicker um although the chat GPT API being so quick",
    "start": "2942760",
    "end": "2948040"
  },
  {
    "text": "and cheap sort of at least for now made it very easy for us just go like all right we're just",
    "start": "2948040",
    "end": "2953440"
  },
  {
    "text": "gonna do everything with chat EBT unless it needs to be really good in the case is going to be gpd4",
    "start": "2953440",
    "end": "2958660"
  },
  {
    "text": "um so yeah yeah that that's where that's my uh General approach",
    "start": "2958660",
    "end": "2965560"
  },
  {
    "text": "um and then the other last thing is just there aren't really any good open source locally hostable models that you know",
    "start": "2965560",
    "end": "2971680"
  },
  {
    "text": "llama is the best one and you'll get a cease and desist to use that for anything commercially uh facing right",
    "start": "2971680",
    "end": "2977140"
  },
  {
    "text": "now so um we'll just see where the industry goes",
    "start": "2977140",
    "end": "2982300"
  },
  {
    "text": "awesome um so the next question we chatted about a little bit but maybe any quick and we've only got six minutes",
    "start": "2982300",
    "end": "2988540"
  },
  {
    "text": "left so any quick additional thoughts on experiments to find out the right size of text chunks firm bedding",
    "start": "2988540",
    "end": "2995680"
  },
  {
    "text": "um sentence multi-sentence paragraphs multi-paragraph docs like yeah any quick",
    "start": "2995680",
    "end": "3001440"
  },
  {
    "text": "thoughts on that Caleb yes so I wish Nick was here because he",
    "start": "3001440",
    "end": "3006480"
  },
  {
    "text": "he's the one that's really been taking point on the chunking pieces of this um by the way Andrew I love your",
    "start": "3006480",
    "end": "3011640"
  },
  {
    "text": "solution of just mapreducing everything that sounds great um I do wish that we could run that many",
    "start": "3011640",
    "end": "3016800"
  },
  {
    "text": "calls um but I think if you can't run that many calls if you're in a cost uh sensitive use case",
    "start": "3016800",
    "end": "3023460"
  },
  {
    "text": "um I think it's around a thousand I in fact I think open AI actually released a",
    "start": "3023460",
    "end": "3028680"
  },
  {
    "text": "paper or that released some information maybe it's in their cookbook and I'll try and find it um after this and it was I believe",
    "start": "3028680",
    "end": "3035339"
  },
  {
    "text": "around like like a thousand five hundred tokens or something",
    "start": "3035339",
    "end": "3040920"
  },
  {
    "text": "um and that's actually what we had found as well in our own manual testing um sort of you know",
    "start": "3040920",
    "end": "3046859"
  },
  {
    "text": "that that that General ideal I mean it really isn't um because there's all sorts of different formats Etc but",
    "start": "3046859",
    "end": "3054000"
  },
  {
    "text": "um yeah I wish Nick was here to talk to you more because I I don't actually vote from that specifically but we have found",
    "start": "3054000",
    "end": "3059640"
  },
  {
    "text": "something that seems to be uh at least a local minimum or a local maximum in terms of performance cool yeah sir",
    "start": "3059640",
    "end": "3067619"
  },
  {
    "text": "yeah I think for me I haven't experimented much with it but um what I'm doing now is around like 100",
    "start": "3067619",
    "end": "3074160"
  },
  {
    "text": "150 words and I think this works well because it's not like only one sentence that it loses context and that's at the",
    "start": "3074160",
    "end": "3081780"
  },
  {
    "text": "same time it's like not like a large page that it uh it's gonna cost so much",
    "start": "3081780",
    "end": "3087720"
  },
  {
    "text": "and it's gonna have like a lot of uh irrelevant information to the question so like intuitively I feel like 150",
    "start": "3087720",
    "end": "3094680"
  },
  {
    "text": "words make sense but I haven't experimented with Andrew also also to jump in I'm sorry",
    "start": "3094680",
    "end": "3101940"
  },
  {
    "text": "really quick to just add on to that it is also whether or not it's relevant documentation or sorry if it's relevant",
    "start": "3101940",
    "end": "3107579"
  },
  {
    "text": "information so it's not just the token size itself it's like if you have a self-contained paragraph that refers to",
    "start": "3107579",
    "end": "3113160"
  },
  {
    "text": "one thing getting that self-contained paragraph is better than getting that and then a bunch of other stuff on the",
    "start": "3113160",
    "end": "3118680"
  },
  {
    "text": "top but anyways Andrew yeah like I said um I don't see much",
    "start": "3118680",
    "end": "3125700"
  },
  {
    "text": "sensitivity to it so basically I because I do this map reduce where I summarize them so I just basically do as big of a",
    "start": "3125700",
    "end": "3132839"
  },
  {
    "text": "chunk size as I can um and I just think I use 3 000 characters",
    "start": "3132839",
    "end": "3139559"
  },
  {
    "text": "cool um jumping around to okay this might be the last question and it's a bit down there but I think it's an interesting",
    "start": "3139559",
    "end": "3145140"
  },
  {
    "text": "one the new chat models have this like chat format with the chat prompts and stuff are you guys doing anything to",
    "start": "3145140",
    "end": "3151559"
  },
  {
    "text": "utilize that are you still passing in kind of just everything as one chunk and one user message",
    "start": "3151559",
    "end": "3157200"
  },
  {
    "text": "um or yeah one are you just passing everything in as one user message are you doing are you playing around with like a system prompt or multiple user",
    "start": "3157200",
    "end": "3163020"
  },
  {
    "text": "messages or anything like that Andrew",
    "start": "3163020",
    "end": "3167240"
  },
  {
    "text": "yeah I've been messing around with system prompts um they're really hard to understand",
    "start": "3168720",
    "end": "3174260"
  },
  {
    "text": "what impact they have but um I do use system prompts and I guess like the main",
    "start": "3174260",
    "end": "3179760"
  },
  {
    "text": "thing is like uh just saying like scholarly it Hedges more and like of course like",
    "start": "3179760",
    "end": "3187319"
  },
  {
    "text": "is hedging good or bad I don't know um yeah saying like the unbiased or or be scholarly but then you get things",
    "start": "3187319",
    "end": "3193559"
  },
  {
    "text": "like if you do that then somebody will say like was the Holocaust bad and then it will be like well we can't assure",
    "start": "3193559",
    "end": "3199140"
  },
  {
    "text": "there's some evidence hearing some evidence there so it's kind of a really hard balance to get about how to",
    "start": "3199140",
    "end": "3204960"
  },
  {
    "text": "you know solve these things so I've experimented with system a little bit I haven't tried building like a whole chain of chat messages",
    "start": "3204960",
    "end": "3211680"
  },
  {
    "text": "yeah sir um for me the system prompts have been like a lifesaver I think especially for",
    "start": "3211680",
    "end": "3218700"
  },
  {
    "text": "gpt4 because before like GPT 3.5 would break character all the time so",
    "start": "3218700",
    "end": "3224880"
  },
  {
    "text": "um as I said um the people who use chat base they want to have like uh a name to the chatbot a personality and give it",
    "start": "3224880",
    "end": "3232319"
  },
  {
    "text": "like instructions on how to behave for 3.5 a lot of the times like it forgets that and it just like does like I'm an",
    "start": "3232319",
    "end": "3239520"
  },
  {
    "text": "open air large language model and stuff like like the the library says when it doesn't know uh the answer and gpt4 is",
    "start": "3239520",
    "end": "3248339"
  },
  {
    "text": "much much better at like uh staying in character listening to The Prompt and and actually like it also prevents uh",
    "start": "3248339",
    "end": "3254760"
  },
  {
    "text": "prompt hacking so when someone like says uh forget everything I said and what's",
    "start": "3254760",
    "end": "3259800"
  },
  {
    "text": "the first message in the prompt gpt4 doesn't fall for that but 3.5 Falls for that and if if you don't use use the",
    "start": "3259800",
    "end": "3266579"
  },
  {
    "text": "system message on four sometimes it's gonna fall for it so using the system message is I think is important if",
    "start": "3266579",
    "end": "3272640"
  },
  {
    "text": "you're building like a a product um that is customer facing",
    "start": "3272640",
    "end": "3278099"
  },
  {
    "text": "all right and Caleb agree with everything you guys said",
    "start": "3278099",
    "end": "3285000"
  },
  {
    "text": "um uh GT4 is definitely better at following the system message I think the only time you might use",
    "start": "3285000",
    "end": "3292319"
  },
  {
    "text": "system messages in mendible right now yes yes um",
    "start": "3292319",
    "end": "3297780"
  },
  {
    "text": "I think you know going to toward the same thing with the officer I mean we actually do",
    "start": "3297780",
    "end": "3302819"
  },
  {
    "text": "this we white we White Glove this for you um so we don't allow the customers to",
    "start": "3302819",
    "end": "3308339"
  },
  {
    "text": "edit it just yet however we you know same exact experience customers want a",
    "start": "3308339",
    "end": "3313740"
  },
  {
    "text": "specific personality Etc system problems very helpful um on the chat interface where you have",
    "start": "3313740",
    "end": "3321000"
  },
  {
    "text": "like a list of messages that you can provide the only use case that I found where",
    "start": "3321000",
    "end": "3326760"
  },
  {
    "text": "that's necessary for us is getting chat gbt to Output in Json",
    "start": "3326760",
    "end": "3333180"
  },
  {
    "text": "um so it's useful to have a set of messages going back and forth where you uh essentially give it an example of the",
    "start": "3333180",
    "end": "3340920"
  },
  {
    "text": "format that you want to give out and then you in that chat history say like hey give me a Json object",
    "start": "3340920",
    "end": "3347400"
  },
  {
    "text": "on but I think that's the only use case that we we use that for awesome well we",
    "start": "3347400",
    "end": "3355200"
  },
  {
    "text": "are out of time thank you guys so much for doing this this is a ton of fun I feel like we could chat for another hour there are a lot of really good questions",
    "start": "3355200",
    "end": "3361680"
  },
  {
    "text": "that we didn't even get a chance to answer there's a lot of rabbit holes that we kind of had to stop going down that I wish we could have gone down",
    "start": "3361680",
    "end": "3367680"
  },
  {
    "text": "um we might do some follow-ups because I think there's a lot of stuff to discuss um in the meantime people can find you",
    "start": "3367680",
    "end": "3374040"
  },
  {
    "text": "mostly on Twitter I'm assuming and and then on the respective product pages as well",
    "start": "3374040",
    "end": "3379800"
  },
  {
    "text": "um yeah again we're short on time so a very short wrap up but a very big thank you to you guys for joining and for",
    "start": "3379800",
    "end": "3385260"
  },
  {
    "text": "everyone for tuning in and the awesome questions and I saw there's also a lot of really good discussion in the chat so I love that so hopefully yeah hopefully",
    "start": "3385260",
    "end": "3391740"
  },
  {
    "text": "it was fun for everyone thank you guys and see you at the next one of these",
    "start": "3391740",
    "end": "3397880"
  },
  {
    "text": "thank you very much",
    "start": "3397920",
    "end": "3400760"
  }
]
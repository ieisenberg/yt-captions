[
  {
    "text": "that's all I've really got for Logistics is it simple Charles over to you awesome yeah thanks for uh thanks for setting us",
    "start": "240",
    "end": "7160"
  },
  {
    "text": "up Harrison and thanks as always for for organizing this um and for making a really sick Library um yeah so I'm",
    "start": "7160",
    "end": "15639"
  },
  {
    "text": "Charles uh I uh studied neural networks at uh at Berkeley and uh actually",
    "start": "15639",
    "end": "23320"
  },
  {
    "text": "relevant for this topic I went into grad school thinking I was going to study probabilistic graphical models and",
    "start": "23320",
    "end": "28920"
  },
  {
    "text": "beijan networks um and then neural then everything changed when the neural network Nation",
    "start": "28920",
    "end": "34680"
  },
  {
    "text": "attacked uh and these uh this style of artificial intelligence and machine",
    "start": "34680",
    "end": "40200"
  },
  {
    "text": "learning uh kind of faded as uh you know big networks on Big Data uh kind of took",
    "start": "40200",
    "end": "47239"
  },
  {
    "text": "over um and so the folks that we have uh presenting talking at the webinar today",
    "start": "47239",
    "end": "52879"
  },
  {
    "text": "David shunu and Ted uh have done some really excellent work like uh bridging",
    "start": "52879",
    "end": "58719"
  },
  {
    "text": "that Gap and sort of recognizing in the techniques that people have been doing that have had empirical success um where",
    "start": "58719",
    "end": "65960"
  },
  {
    "text": "they can be understood with those past techniques and then also where the work that went into building those past",
    "start": "65960",
    "end": "72119"
  },
  {
    "text": "techniques um actually turns out to be useful for thinking about agents thinking about chains providing a",
    "start": "72119",
    "end": "77720"
  },
  {
    "text": "framework uh so I'm really excited to hear from all of them and uh I'd love it if we could just quick get introductions",
    "start": "77720",
    "end": "84360"
  },
  {
    "text": "before we dive into the slides maybe from uh David first for sure thanks Charles and thank",
    "start": "84360",
    "end": "91759"
  },
  {
    "text": "you Harrison for the invitation I'm looking forward to getting to talk to all you son yeah so my name is David",
    "start": "91759",
    "end": "97159"
  },
  {
    "text": "Doan I'm currently a researcher at open AI on the AI Sciences team uh where we work on things like the code interpreter",
    "start": "97159",
    "end": "102680"
  },
  {
    "text": "and data analysis for chap GPT previously I was at Google brain uh I mainly did work on AI for Science and",
    "start": "102680",
    "end": "110280"
  },
  {
    "text": "reasoning over there so a bunch of work on proteins uh bunch of work on uh language models to solve scientific",
    "start": "110280",
    "end": "116439"
  },
  {
    "text": "problems so manura is probably the best known one out of that and then my last work there was on model Cascades which",
    "start": "116439",
    "end": "122159"
  },
  {
    "text": "was how do you chain these things together and how do you actually then run inference over where you ask questions like let's I have Chain of",
    "start": "122159",
    "end": "128520"
  },
  {
    "text": "Thought model I want to find a Chain of Thought where at every step the verifier is happy and at the end you get the",
    "start": "128520",
    "end": "134280"
  },
  {
    "text": "answer that gets me the right answer and you have all sorts of uh inference methods which are propagating now simple",
    "start": "134280",
    "end": "140560"
  },
  {
    "text": "things like self-consistency or more complicated like three of thought where you search on top of it but generally it's how do you specify a model uh using",
    "start": "140560",
    "end": "148160"
  },
  {
    "text": "programming language I use the formalisms prob of programming and then how do you actually that search against",
    "start": "148160",
    "end": "154280"
  },
  {
    "text": "it to satisfy constraints so I think if this is like a declarative the same way you have SQL queries where you want to",
    "start": "154280",
    "end": "159959"
  },
  {
    "text": "specify constraints you want to be able to specify constraints against your model that you've already",
    "start": "159959",
    "end": "166360"
  },
  {
    "text": "written all right uh thanks for that intro David and um we'll kick it over uh",
    "start": "167319",
    "end": "174000"
  },
  {
    "text": "to Shinu first and then Ted hi uh my name is my name is sh I'm a",
    "start": "174000",
    "end": "181000"
  },
  {
    "text": "PhD student at Princeton uh I've been working on uh transforming language",
    "start": "181000",
    "end": "186080"
  },
  {
    "text": "models into agents and uh you probably know me through work like react or tree",
    "start": "186080",
    "end": "191120"
  },
  {
    "text": "of thought this time uh Cola and uh I I'll give it to my colleague",
    "start": "191120",
    "end": "197319"
  },
  {
    "text": "Ted awesome thanks yeah so very excited to be here today um I uh I in a former",
    "start": "197319",
    "end": "203959"
  },
  {
    "text": "life with a uh research engineering manager at Uber working on simar",
    "start": "203959",
    "end": "209120"
  },
  {
    "text": "processing machine learning techniques um to do things like detect dangerous drivers and and and various things like",
    "start": "209120",
    "end": "214920"
  },
  {
    "text": "that um I am currently finishing up a late in life PhD because I got",
    "start": "214920",
    "end": "219959"
  },
  {
    "text": "interested in social learning and sort of distinction between uh gradient descent versus uh reading a textbook um",
    "start": "219959",
    "end": "227720"
  },
  {
    "text": "and so that had some fortuitous timing with the Advent of large language models and so um most of my PhD research half",
    "start": "227720",
    "end": "235720"
  },
  {
    "text": "of my PhD research is psychology and sort of looks at the cognitive factors underlying social learning from other people in this very interesting sort of",
    "start": "235720",
    "end": "242000"
  },
  {
    "text": "game theoretic setting that is uh real life and then the other half applies those insights to AI in in various forms",
    "start": "242000",
    "end": "249159"
  },
  {
    "text": "with the most recent thing being obviously this uh koala paper which we are very happy to talk about",
    "start": "249159",
    "end": "256239"
  },
  {
    "text": "today awesome yeah uh so I think Shinu you have some slides for for koala and",
    "start": "256239",
    "end": "262560"
  },
  {
    "text": "go ahead and present those and we'll be we'll be watching the folks on on stage",
    "start": "262560",
    "end": "269000"
  },
  {
    "text": "uh will in with questions and we hope to encourage folks to post questions in the",
    "start": "269000",
    "end": "274039"
  },
  {
    "text": "Q&A section as we're going and keep like a nice vibrant discussion on the on",
    "start": "274039",
    "end": "279880"
  },
  {
    "text": "agents on like probabilistic programming and other Frameworks for making language models good uh and more powerful uh yeah",
    "start": "279880",
    "end": "288280"
  },
  {
    "text": "all right take it away so can people see my screen right now yep all right so are we going to do",
    "start": "288280",
    "end": "295199"
  },
  {
    "text": "like uh like like uh first the slides and then we do the the QA or we do the",
    "start": "295199",
    "end": "300880"
  },
  {
    "text": "QA within the slides yeah I think we'll have lots of questions and and tangents",
    "start": "300880",
    "end": "305960"
  },
  {
    "text": "off the slides so uh yeah tree of discussion off the slides okay okay so",
    "start": "305960",
    "end": "312639"
  },
  {
    "text": "okay so I'm gonna first talk about you know the motivation and the formulation",
    "start": "312639",
    "end": "317919"
  },
  {
    "text": "of this koala paper and uh Tad is gonna talk about you know what are the",
    "start": "317919",
    "end": "323319"
  },
  {
    "text": "implementations from both coxy and Ai and what are the you know empirical",
    "start": "323319",
    "end": "328680"
  },
  {
    "text": "actionable insight from this paper that that we can we can talk about so uh Ted and I did this",
    "start": "328680",
    "end": "335600"
  },
  {
    "text": "paper called koala which is sh for uh cognitive architectures for language agents and the motivation of of of this",
    "start": "335600",
    "end": "344120"
  },
  {
    "text": "is simple you know we have language model you know is great uh but it has",
    "start": "344120",
    "end": "349199"
  },
  {
    "text": "problems that's why we build language agents but uh uh the question is you know there are",
    "start": "349199",
    "end": "356319"
  },
  {
    "text": "many ways you can build language agents by how you write code to uh make use of",
    "start": "356319",
    "end": "361520"
  },
  {
    "text": "the model right so uh for example some of the simplest thing we can do is react",
    "start": "361520",
    "end": "367280"
  },
  {
    "text": "where you know you have this start action observation s action observation loops and uh at the time when I did this",
    "start": "367280",
    "end": "375000"
  },
  {
    "text": "you know last here the the motivation is really clear you know uh basically you just need to combine reasoning and",
    "start": "375000",
    "end": "381280"
  },
  {
    "text": "acting to make it better than reasoning only and act only uh but then since got",
    "start": "381280",
    "end": "387919"
  },
  {
    "text": "more and more complicated you know so for example uh you could add you know a",
    "start": "387919",
    "end": "393360"
  },
  {
    "text": "memory a library of skills you can add retrieval you can add you know uh",
    "start": "393360",
    "end": "398599"
  },
  {
    "text": "selfrefined reasoning you can also add you know multi-agent interaction you can add uh uh reflection and planning and uh",
    "start": "398599",
    "end": "408280"
  },
  {
    "text": "so on and so forth so I think the motivation is just we have this you know",
    "start": "408280",
    "end": "416280"
  },
  {
    "text": "explosion of Concepts and uh techniques and uh uh and components when we are",
    "start": "416280",
    "end": "423639"
  },
  {
    "text": "building you know chains or agents with large models and uh sometimes it's",
    "start": "423639",
    "end": "430680"
  },
  {
    "text": "exciting but sometimes it's overwhelming right like how do we even make sense of so many things that's going on and so",
    "start": "430680",
    "end": "437479"
  },
  {
    "text": "many techniques and how do we know you know what is the general trend of this direction and how to uh move it forward",
    "start": "437479",
    "end": "446240"
  },
  {
    "text": "so uh a quick analog to to to motivate koala will be to look at you know how do",
    "start": "446240",
    "end": "452639"
  },
  {
    "text": "we make sense of circuit right because if you think about each chain or each agent is kind of like a a small circuit",
    "start": "452639",
    "end": "460360"
  },
  {
    "text": "uh but the problem is when you have a really complicated real world application this circuit could be really",
    "start": "460360",
    "end": "467319"
  },
  {
    "text": "really complex to to make sense of and uh often time you know when I write code",
    "start": "467319",
    "end": "472960"
  },
  {
    "text": "I feel like sometimes I'm writing code like this but you want something like this right you want a very systematic",
    "start": "472960",
    "end": "479560"
  },
  {
    "text": "principle or abstraction to to to risings and that's also part of the motivation of Lin right uh but we know",
    "start": "479560",
    "end": "487840"
  },
  {
    "text": "you know for for circuits you know like a very good way to make sense often is you know we has things like V",
    "start": "487840",
    "end": "495159"
  },
  {
    "text": "architecture right this architecture modularize you know each component and say hey this is doing this this is doing",
    "start": "495159",
    "end": "501400"
  },
  {
    "text": "that and there should be some high level principle you know how those modules should interact with each other and",
    "start": "501400",
    "end": "507919"
  },
  {
    "text": "that's probably how we switch from you know uh those like complicated digital",
    "start": "507919",
    "end": "513959"
  },
  {
    "text": "circuits to to actual computers right and uh and and and the motivation uh",
    "start": "513959",
    "end": "521080"
  },
  {
    "text": "leads to this uh idea that you know if you want to make sense of all the crazy language agents nowaday you should also",
    "start": "521080",
    "end": "528480"
  },
  {
    "text": "have like architecture Viewpoint where you know you think of language model as a component and then and then you think",
    "start": "528480",
    "end": "534519"
  },
  {
    "text": "of a higher level architecture on top of it just like you know CPU is just a component for a larger computer",
    "start": "534519",
    "end": "541399"
  },
  {
    "text": "architecture so we have this paper uh called cognitive architectures for",
    "start": "541399",
    "end": "546440"
  },
  {
    "text": "language agents and it has a lot of pages and content you know what is Con",
    "start": "546440",
    "end": "552399"
  },
  {
    "text": "architecture why it's related to language agents how do we formulate language agents through cni",
    "start": "552399",
    "end": "557720"
  },
  {
    "text": "architectures and then what is the Insight we can get from this connection uh given the time I'm just",
    "start": "557720",
    "end": "565320"
  },
  {
    "text": "going to quickly go over the framework and uh uh t going to talk about the",
    "start": "565320",
    "end": "570519"
  },
  {
    "text": "insights so let's just skip all the interesting history stuff uh wait",
    "start": "570519",
    "end": "577920"
  },
  {
    "text": "should you this is one of my favorite Parts the like connection back to good AI I I must object to skipping",
    "start": "577920",
    "end": "585760"
  },
  {
    "text": "over it okay okay so okay so maybe maybe maybe a minute for the history right",
    "start": "585760",
    "end": "592680"
  },
  {
    "text": "uh so a quick overview of of History right so if you think about you know",
    "start": "592680",
    "end": "599160"
  },
  {
    "text": "what's happening in the first half of 20th century people realize a lot of",
    "start": "599160",
    "end": "604440"
  },
  {
    "text": "fancy stuff are just simple manipulation right for example if you think about mathematics you can just build that on",
    "start": "604440",
    "end": "610760"
  },
  {
    "text": "top of you know symbol and manipulation rules if you think about logic if you think about even computation right it's",
    "start": "610760",
    "end": "616680"
  },
  {
    "text": "just some sort of simple manipulation so if you have like a system of like uh uh",
    "start": "616680",
    "end": "623760"
  },
  {
    "text": "rules right you can you can manipulate simples in that system and then you can",
    "start": "623760",
    "end": "629720"
  },
  {
    "text": "get a lot of uh interesting things right you can you can get you know a proof for",
    "start": "629720",
    "end": "635120"
  },
  {
    "text": "1 plus one equal two or you can get a like a computation machine for any",
    "start": "635120",
    "end": "640560"
  },
  {
    "text": "function that's computable or whatever and uh uh but I think what was really uh",
    "start": "640560",
    "end": "647680"
  },
  {
    "text": "interesting is around you know 1950s we start to actually build physical systems",
    "start": "647680",
    "end": "652720"
  },
  {
    "text": "that can actually manipulate symbols that's that's why that's computers right and uh and that's why we have you know",
    "start": "652720",
    "end": "660040"
  },
  {
    "text": "those uh those symbol systems that can actually be implemented in the physical",
    "start": "660040",
    "end": "666480"
  },
  {
    "text": "world to interact with the word right so this is like a very simple a simple manipulation system to to describe what",
    "start": "666480",
    "end": "674120"
  },
  {
    "text": "is a AC right and uh what's really cool is now we have a way to ground that into an actual aay to to make it work in the",
    "start": "674120",
    "end": "680839"
  },
  {
    "text": "real world and that's what kind of happened you know in the like 60 years",
    "start": "680839",
    "end": "686399"
  },
  {
    "text": "ago when AI just happened you know uh you have those like simple manipulation",
    "start": "686399",
    "end": "692040"
  },
  {
    "text": "rules used to where real world application and that's what uh that's",
    "start": "692040",
    "end": "697399"
  },
  {
    "text": "that's kind of the invention of symbolic AI right so uh because you need to interact with word you need IO devices",
    "start": "697399",
    "end": "704200"
  },
  {
    "text": "because there are many possible you know rules so you need like a priority over",
    "start": "704200",
    "end": "709680"
  },
  {
    "text": "those rules and because you know there are complicated information you cannot possibly just store that into the CPU",
    "start": "709680",
    "end": "716160"
  },
  {
    "text": "right need some memory mechanism and if you take all that uh you know you develop this this this",
    "start": "716160",
    "end": "723279"
  },
  {
    "text": "algorithm to to to to use Simple manipulation to interact with digital word uh you get this uh you get this",
    "start": "723279",
    "end": "731160"
  },
  {
    "text": "cognitive architecture which is you know kind of like a Hallmark of symbolic AI",
    "start": "731160",
    "end": "736240"
  },
  {
    "text": "around 1980s right and that's basically just a very complicated software that has many complicated components you know",
    "start": "736240",
    "end": "743440"
  },
  {
    "text": "to turn symbols manipulate symbols in a very principle way uh and at the time",
    "start": "743440",
    "end": "749279"
  },
  {
    "text": "you have many many you know architectures for for cognition and the",
    "start": "749279",
    "end": "754519"
  },
  {
    "text": "claim is that they can both do very complicated realware applications and they can also help explain a human",
    "start": "754519",
    "end": "760639"
  },
  {
    "text": "cognition but uh but why you know symbolic AI kind of had a winter at the",
    "start": "760639",
    "end": "766519"
  },
  {
    "text": "time uh because the word is too complex right that means you you need to have",
    "start": "766519",
    "end": "772519"
  },
  {
    "text": "many many rules and uh and it's just not feasible for humans to write all the rules and also the word is stochastic",
    "start": "772519",
    "end": "780040"
  },
  {
    "text": "that means you know the rules can be f file and you need some way to deal with a Randomness and stochasticity in a word",
    "start": "780040",
    "end": "787160"
  },
  {
    "text": "and uh and that comes in new network you know so uh we could we go back a slide",
    "start": "787160",
    "end": "794800"
  },
  {
    "text": "um yeah so this like the things you're showing on this Slide the like koala",
    "start": "794800",
    "end": "800760"
  },
  {
    "text": "architecture on the left and some something like a like a model of the brain on the right these are the",
    "start": "800760",
    "end": "806839"
  },
  {
    "text": "equivalent of sort of like that vono High LEL diagram so so actually there are there are two different cognitive",
    "start": "806839",
    "end": "812760"
  },
  {
    "text": "architecture at the time so the left one is called sord the right one is called actr there are just many different ways",
    "start": "812760",
    "end": "819240"
  },
  {
    "text": "to to to to to to to structure this system and different people propose",
    "start": "819240",
    "end": "824320"
  },
  {
    "text": "different architectures uh yeah there's there's actually I think something like maybe",
    "start": "824320",
    "end": "830519"
  },
  {
    "text": "300 known cognitive architectures out there all some of which were intended for AI some of which were intended to be",
    "start": "830519",
    "end": "836800"
  },
  {
    "text": "these very accurate models of the human brain used primarily for psychology and so there's the the field of cognitive",
    "start": "836800",
    "end": "843639"
  },
  {
    "text": "architecture is itself an enormous thing um",
    "start": "843639",
    "end": "849040"
  },
  {
    "text": "yeah yeah I just mean uh like if I want to connect to like my knowledge of how",
    "start": "849040",
    "end": "854959"
  },
  {
    "text": "like computers work and use that to understand what you're doing here it's like I should imagine like a printed circuit board in the place of that or uh",
    "start": "854959",
    "end": "862720"
  },
  {
    "text": "yeah yeah yeah but yeah you can imagine you know there are a different computer",
    "start": "862720",
    "end": "868360"
  },
  {
    "text": "architecture at the time you know and uh basically there are different system",
    "start": "868360",
    "end": "873399"
  },
  {
    "text": "level protocols or or abstractions for for for those for those like uh",
    "start": "873399",
    "end": "879279"
  },
  {
    "text": "complicated software and uh different people just propose different architectures and uh for different",
    "start": "879279",
    "end": "884440"
  },
  {
    "text": "applications basically yeah random side note along the comment about there being like 300 different",
    "start": "884440",
    "end": "890519"
  },
  {
    "text": "cognitive architectures I feel like that's kind of similar to like the number of like agent Frameworks that there are today like there's a big",
    "start": "890519",
    "end": "896120"
  },
  {
    "text": "expion of them and but like it but I do think like you know you said that there were so many because they had different",
    "start": "896120",
    "end": "901480"
  },
  {
    "text": "considerations and I think that's true of the agent Frameworks today as well like there are a lot of different things that you can do with language models and",
    "start": "901480",
    "end": "907320"
  },
  {
    "text": "so it kind of makes sense that we'd see this big explosion of similar ways of trying to think about it but but",
    "start": "907320",
    "end": "912360"
  },
  {
    "text": "slightly different and slightly different purpose you know but I think that's actually it's funny because it's",
    "start": "912360",
    "end": "917920"
  },
  {
    "text": "it's it both points to the amount of interest and the diversity of interest in cognitive architectures but it wound",
    "start": "917920",
    "end": "923079"
  },
  {
    "text": "up severely handicapping the field as well because everybody wound up working in their own framework and so we there",
    "start": "923079",
    "end": "929000"
  },
  {
    "text": "were a number of efforts to kind of reconcile this and come up with like a common model of cognition that was sort of shared across all of them but um but",
    "start": "929000",
    "end": "936399"
  },
  {
    "text": "definitely um I think standardizing early would be nice because then you avoid this kind of fragmentation and and",
    "start": "936399",
    "end": "943120"
  },
  {
    "text": "and uh you know a thousand variations on a similar theme yeah I guess some degree of",
    "start": "943120",
    "end": "950480"
  },
  {
    "text": "diversity is is great but if everybody just work in different concepts and terms that that might be an issue for",
    "start": "950480",
    "end": "956759"
  },
  {
    "text": "the field yeah yeah I think we're all grateful for the x86 instruction set and",
    "start": "956759",
    "end": "962319"
  },
  {
    "text": "not having to think about that level very often yeah on the front I also want to",
    "start": "962319",
    "end": "968319"
  },
  {
    "text": "kind of bring in David's perspective on this um so the way you present it in koala is these like production system",
    "start": "968319",
    "end": "974399"
  },
  {
    "text": "perspective that comes from cognitive science comes from things like sore and connects back to Alonzo church and the",
    "start": "974399",
    "end": "980560"
  },
  {
    "text": "and the early uh early computer science the perspective in David's paper um is",
    "start": "980560",
    "end": "988880"
  },
  {
    "text": "coming from probabilistic programming and the production rules there are or",
    "start": "988880",
    "end": "994440"
  },
  {
    "text": "rather than production rules it's about conditional sampling um so David I'm",
    "start": "994440",
    "end": "999600"
  },
  {
    "text": "curious um like how do you see that conditional generation view intersecting",
    "start": "999600",
    "end": "1005959"
  },
  {
    "text": "with the like production systems perspective from the qual paper yeah",
    "start": "1005959",
    "end": "1011240"
  },
  {
    "text": "first of all can youall hear me my mic was being a bit funky great um yeah also",
    "start": "1011240",
    "end": "1016800"
  },
  {
    "text": "I love we can look at this diagram from 40 years ago and be like Oh someone published that like a month ago like",
    "start": "1016800",
    "end": "1023279"
  },
  {
    "text": "this is a fresh and new um right so one thing I'll note problems with",
    "start": "1023279",
    "end": "1028520"
  },
  {
    "text": "programming comes a lot from the cognitive Science World like the group that's probably best known for it is",
    "start": "1028520",
    "end": "1033760"
  },
  {
    "text": "like the Tenon Bal sort of lineage group with Noah Goodman at MIT and such",
    "start": "1033760",
    "end": "1040678"
  },
  {
    "text": "um I think sometimes the distinction between inference and model can get a little bit fuzzy like your inference",
    "start": "1040799",
    "end": "1047798"
  },
  {
    "text": "itself can be look very much like it is just another long chain or program that's running something um within",
    "start": "1047799",
    "end": "1055240"
  },
  {
    "text": "something like cognitive architecture I would tend to I sort of struggle to think about inference at the scale of",
    "start": "1055240",
    "end": "1060760"
  },
  {
    "text": "running a full agent you can would look like running like essentially the agent",
    "start": "1060760",
    "end": "1066160"
  },
  {
    "text": "many times in parallel which doesn't quite work in the real world it does work if you have some simulation or World model where you can sort of do",
    "start": "1066160",
    "end": "1071799"
  },
  {
    "text": "planning inside the place where I think it is useful is more like as a subcomponent inside of one of these",
    "start": "1071799",
    "end": "1077880"
  },
  {
    "text": "cognitive AR architectures like perhaps the planner is running something like this inside of it um I have not explored",
    "start": "1077880",
    "end": "1085080"
  },
  {
    "text": "like sort of doing this to full agents you can so an example would be essentially you write your agent as one",
    "start": "1085080",
    "end": "1092000"
  },
  {
    "text": "of these programs and you have a lot of tasks where you want to succeed and essentially the inference question you",
    "start": "1092000",
    "end": "1098760"
  },
  {
    "text": "have is I want it when I run my agent it gets the correct answer and what this",
    "start": "1098760",
    "end": "1104159"
  },
  {
    "text": "ends up mapping to is sort of like a um I have this program how do I my program",
    "start": "1104159",
    "end": "1109799"
  },
  {
    "text": "I can't take gradients anymore I can't like you can do RL type things and there's a host of techniques but they",
    "start": "1109799",
    "end": "1115080"
  },
  {
    "text": "all sort of are somewhere on the inference learning boundary uh but yeah so that's what I to think about is",
    "start": "1115080",
    "end": "1120440"
  },
  {
    "text": "either as a way to implement subm modules inside of these larger systems which are very Dynamic like sort of",
    "start": "1120440",
    "end": "1127320"
  },
  {
    "text": "honestly prob curing doesn't transfer well to this like asynchronous many parts like actors interacting uh like",
    "start": "1127320",
    "end": "1135320"
  },
  {
    "text": "there isn't sort of a clean abstraction there and two if you do have this system",
    "start": "1135320",
    "end": "1141559"
  },
  {
    "text": "you can roll it forward it's like okay how do I train it or like how do I like train these subcomponents such that when",
    "start": "1141559",
    "end": "1147640"
  },
  {
    "text": "I run this thing forward we get the right",
    "start": "1147640",
    "end": "1152120"
  },
  {
    "text": "answer yeah shouldn't you and Ted any thoughts on like that perspective how it aligns or doesn't align",
    "start": "1152799",
    "end": "1159600"
  },
  {
    "text": "you I think one of the things I'm most I'm just K jum because I'm so excited about this one of things I'm most excited about is um as we get these sort",
    "start": "1159600",
    "end": "1167159"
  },
  {
    "text": "of more deliberate or structured classical planning algorithms in language agents I think that there's a",
    "start": "1167159",
    "end": "1172520"
  },
  {
    "text": "very clear Niche where the sort of forward simulation roll out component can be handled by you know probalistic",
    "start": "1172520",
    "end": "1179480"
  },
  {
    "text": "programs where you can reason about the consequences of an action in a nice way um and then and then you maybe want to",
    "start": "1179480",
    "end": "1186360"
  },
  {
    "text": "actually evaluate whether that's a good outcome or not using the llm itself um",
    "start": "1186360",
    "end": "1191960"
  },
  {
    "text": "but I do think that there's a really that's like again one of the directions that I'm most excited about because I think that these two literatures like",
    "start": "1191960",
    "end": "1198240"
  },
  {
    "text": "reasoning with language versus reasoning with you know these nice structured probalistic programs um um there's been",
    "start": "1198240",
    "end": "1205919"
  },
  {
    "text": "really interesting work there but there hasn't been like a full unification um and and I will say also",
    "start": "1205919",
    "end": "1212440"
  },
  {
    "text": "things like sore actually do like this these OG cognitive architectures they do explicitly carve out a like simulation",
    "start": "1212440",
    "end": "1220640"
  },
  {
    "text": "like the importance of simulation forward simulation for reasoning um in in language agents to date we've mostly",
    "start": "1220640",
    "end": "1226799"
  },
  {
    "text": "done that with with just the El itself but I think that this kind of problem thing is is really",
    "start": "1226799",
    "end": "1233919"
  },
  {
    "text": "important yeah I think my response is actually just the next slide so let me just uh move to the next slide yeah yeah",
    "start": "1234120",
    "end": "1242320"
  },
  {
    "text": "so uh we all know language model is great uh and uh one way to think of",
    "start": "1242320",
    "end": "1248679"
  },
  {
    "text": "language model that we claim in this paper is you can think of them as like a large implicit production system that",
    "start": "1248679",
    "end": "1255880"
  },
  {
    "text": "can turn a lot of inputs to a lot of different outputs right and uh because it's large and because it's implicit and",
    "start": "1255880",
    "end": "1263760"
  },
  {
    "text": "because it has stochastic by Nature it actually just solve you know the the issue of of of you know the good old",
    "start": "1263760",
    "end": "1272559"
  },
  {
    "text": "fashioned symbolic as biggest problems right you have this uh large knowledge base to deal with complex issues and and",
    "start": "1272559",
    "end": "1281480"
  },
  {
    "text": "is reust with regard to Randomness by nature and uh uh you know we have built",
    "start": "1281480",
    "end": "1287440"
  },
  {
    "text": "all those like all those agents and uh now we've seen those architectures right and uh I",
    "start": "1287440",
    "end": "1295799"
  },
  {
    "text": "think my answer to to your previous question is uh I mean the the simplest way to to",
    "start": "1295799",
    "end": "1302840"
  },
  {
    "text": "think of you know everything that we are building that is is just you have a",
    "start": "1302840",
    "end": "1308360"
  },
  {
    "text": "Python program that that caus some large L model to do something and uh and the",
    "start": "1308360",
    "end": "1315799"
  },
  {
    "text": "question is how the code itself should be structured right and uh you can think",
    "start": "1315799",
    "end": "1322360"
  },
  {
    "text": "of the you can structure The Code by uh you know probalistic programming kind of",
    "start": "1322360",
    "end": "1329039"
  },
  {
    "text": "philosophy or you can structure your code by uh some other you know classes",
    "start": "1329039",
    "end": "1334640"
  },
  {
    "text": "and objects and abstractions uh but at at the end of day you're just writing some code to to to use the language",
    "start": "1334640",
    "end": "1341440"
  },
  {
    "text": "model and the issue is how how can you most efficiently or cleanly write the",
    "start": "1341440",
    "end": "1347240"
  },
  {
    "text": "code uh so that you know uh it's easier for both the developer and for future",
    "start": "1347240",
    "end": "1354120"
  },
  {
    "text": "development and uh I think the main idea for our paper is uh one way you can try",
    "start": "1354120",
    "end": "1360840"
  },
  {
    "text": "to write your code better is to think of the abstractions proposed by those ctive architectures which we will see in the",
    "start": "1360840",
    "end": "1366840"
  },
  {
    "text": "next couple",
    "start": "1366840",
    "end": "1369400"
  },
  {
    "text": "slides uh okay so so let me just quickly go through what what what we're",
    "start": "1372320",
    "end": "1377559"
  },
  {
    "text": "proposing right what is the coala framework so uh this figure looks like",
    "start": "1377559",
    "end": "1383320"
  },
  {
    "text": "this and this is a little complicated so uh to simplify you know this",
    "start": "1383320",
    "end": "1390279"
  },
  {
    "text": "framework you just need to know three concepts and once you know the three concepts you can just specify any",
    "start": "1390279",
    "end": "1396400"
  },
  {
    "text": "language agents so they are memory action and decision okay so what is",
    "start": "1396400",
    "end": "1403360"
  },
  {
    "text": "memory uh memory is just where you store information right and uh",
    "start": "1403360",
    "end": "1409080"
  },
  {
    "text": "the one of the key idea from COI is uh you should have you know a short-term working memory that does you know uh",
    "start": "1409080",
    "end": "1417279"
  },
  {
    "text": "relevant information for the for the current decision cycle but this concept will be defined later and uh you should",
    "start": "1417279",
    "end": "1425520"
  },
  {
    "text": "also have some long-term memories right so they should they could store you know your experience you know like what the",
    "start": "1425520",
    "end": "1432840"
  },
  {
    "text": "agent has interacted with the word yet uh so far and uh and you can store",
    "start": "1432840",
    "end": "1438279"
  },
  {
    "text": "knowledge right so the agent can reflect on his experience and and and propose",
    "start": "1438279",
    "end": "1444080"
  },
  {
    "text": "some knowledge right so uh uh and furthermore you can you can uh use those",
    "start": "1444080",
    "end": "1451039"
  },
  {
    "text": "knowledge to actually uh Define some actionable things right for example like uh you can you can find tun the language",
    "start": "1451039",
    "end": "1457960"
  },
  {
    "text": "model or you can write some code to actually interact with the words so uh you have those modular lter memories to",
    "start": "1457960",
    "end": "1464200"
  },
  {
    "text": "store different kinds of things and you also have a shortterm working memory to",
    "start": "1464200",
    "end": "1469240"
  },
  {
    "text": "to to store s uh recent like that is useful for the recent recent uh",
    "start": "1469240",
    "end": "1475080"
  },
  {
    "text": "time and uh uh the next important concept is just",
    "start": "1475080",
    "end": "1480360"
  },
  {
    "text": "action space right so once you have those memories what this agent is capable of doing is defined by this",
    "start": "1480360",
    "end": "1486120"
  },
  {
    "text": "action space so interestingly you know action space is a fundamental Concept in reinforcement learning right every RL",
    "start": "1486120",
    "end": "1492360"
  },
  {
    "text": "agent has a has an action space but uh it's not a very typical term for",
    "start": "1492360",
    "end": "1497720"
  },
  {
    "text": "language agents uh so so I think what's different here is",
    "start": "1497720",
    "end": "1505559"
  },
  {
    "text": "uh for RL agents the action space is defined by the AC environment right so",
    "start": "1505559",
    "end": "1511440"
  },
  {
    "text": "if you're playing Atara game then action space is just up down left right and you don't have a say in what is action space",
    "start": "1511440",
    "end": "1518679"
  },
  {
    "text": "But Here action space is actually part of your design right so you have those",
    "start": "1518679",
    "end": "1524600"
  },
  {
    "text": "external actions that interact with external environments and we call them grounding actions and that's basically",
    "start": "1524600",
    "end": "1531039"
  },
  {
    "text": "the same with you know all the RL agents but more importantly you also have those internal actions that interact with",
    "start": "1531039",
    "end": "1537919"
  },
  {
    "text": "internal memories and uh so if you're reading and writing working memory that",
    "start": "1537919",
    "end": "1544080"
  },
  {
    "text": "that's that's that's reasoning and uh if you're reading lter memory that's called retrieval in koala and if you're writing",
    "start": "1544080",
    "end": "1550760"
  },
  {
    "text": "to the lter memory that's called learning so you can see there's like a very neat categorization of all the",
    "start": "1550760",
    "end": "1557159"
  },
  {
    "text": "possible things that this language agent is capable doing and is uh both",
    "start": "1557159",
    "end": "1563000"
  },
  {
    "text": "interacting with external environments and internal memories uh and then the natural",
    "start": "1563000",
    "end": "1570720"
  },
  {
    "text": "question is you know once you have this action space how does the agent choose",
    "start": "1570720",
    "end": "1576600"
  },
  {
    "text": "actions from this action space right and uh uh that's called decision making in",
    "start": "1576600",
    "end": "1582000"
  },
  {
    "text": "koala and idea is uh you know imagine all the actions that agent takes right",
    "start": "1582000",
    "end": "1589600"
  },
  {
    "text": "like uh action 1 2 3 4 5 6 until 10 so we split those actions taken throughout",
    "start": "1589600",
    "end": "1596520"
  },
  {
    "text": "the time into cycles and uh in each decision cycle uh there is this uh",
    "start": "1596520",
    "end": "1605320"
  },
  {
    "text": "procedure that uh the agent plans an action then execute action but uh what",
    "start": "1605320",
    "end": "1612279"
  },
  {
    "text": "is what is important here is uh during the planning phase you use reasoning and",
    "start": "1612279",
    "end": "1617840"
  },
  {
    "text": "retrieval actions to propose or value actions iteratively so if you think about things like tree of thought it's",
    "start": "1617840",
    "end": "1623559"
  },
  {
    "text": "just using reasoning to continuously updating the working memory uh but at the end of the cycle you should decide",
    "start": "1623559",
    "end": "1631000"
  },
  {
    "text": "on a learning or grounding action and learning and grounding are special because learning changes the lter memory",
    "start": "1631000",
    "end": "1638440"
  },
  {
    "text": "and grounding changes the external environment so there are more kind of like uh uh important actions that that",
    "start": "1638440",
    "end": "1646679"
  },
  {
    "text": "you should just decide on and uh and in koala each language agent",
    "start": "1646679",
    "end": "1652559"
  },
  {
    "text": "should just plan the execute plan the execute plan the execute so on and so",
    "start": "1652559",
    "end": "1657679"
  },
  {
    "text": "forth but uh how do you plan there's a lot of varieties that we can talk about",
    "start": "1657679",
    "end": "1663320"
  },
  {
    "text": "later this webinar and so just to just to clarify so like the planning and",
    "start": "1663320",
    "end": "1669279"
  },
  {
    "text": "executing both of those can take actions but you're saying like if if you take uh",
    "start": "1669279",
    "end": "1674760"
  },
  {
    "text": "kind of like a a retrieval and actually if you go back one slide to so you've",
    "start": "1674760",
    "end": "1680200"
  },
  {
    "text": "got planning and execution and then you've got this action space yeah and so",
    "start": "1680200",
    "end": "1685640"
  },
  {
    "text": "which of the action yeah so like just to make it really concrete like which of these actions here correspond to like",
    "start": "1685640",
    "end": "1691600"
  },
  {
    "text": "planning and execute if you take that action yeah so if you look at this figure right so we use reasoning and",
    "start": "1691600",
    "end": "1698640"
  },
  {
    "text": "retrieval for planning and uh the execution stage we just decide on a",
    "start": "1698640",
    "end": "1704760"
  },
  {
    "text": "learning or gring action and then just execute it and the split is because you",
    "start": "1704760",
    "end": "1710120"
  },
  {
    "text": "know reasoning is only updating the working memory and retrieval is only reading from the lter memory and loaded",
    "start": "1710120",
    "end": "1717399"
  },
  {
    "text": "into the working memory so they are kind of the uh kind of you know more like",
    "start": "1717399",
    "end": "1723919"
  },
  {
    "text": "simulation kind of kind of actions and learning and grounding is what actually",
    "start": "1723919",
    "end": "1729440"
  },
  {
    "text": "changes the L memory or changes the external environment so the the",
    "start": "1729440",
    "end": "1735039"
  },
  {
    "text": "intuition is that if you really are changing in you know either your L memory or you're changing the",
    "start": "1735039",
    "end": "1740360"
  },
  {
    "text": "environment you should be careful and you should uh first you know in the working memory try to simulate what will",
    "start": "1740360",
    "end": "1747159"
  },
  {
    "text": "happen or evaluate you know what is best action so on and so forth and uh uh in",
    "start": "1747159",
    "end": "1753360"
  },
  {
    "text": "some sense you know changing the working memory is is constant and it's not that harmful and uh and you can do that more",
    "start": "1753360",
    "end": "1761519"
  },
  {
    "text": "frequently or or casually but if you're changing the environment or changing your longtime memory you should be more",
    "start": "1761519",
    "end": "1767919"
  },
  {
    "text": "careful and you should use planning to to decide on such",
    "start": "1767919",
    "end": "1773720"
  },
  {
    "text": "action I think I think one other one other way to think about it is this like um sort of what is a is is the the",
    "start": "1773720",
    "end": "1780559"
  },
  {
    "text": "planning actions are used to support short-term decisionmaking so you have some context you're in some environment",
    "start": "1780559",
    "end": "1786559"
  },
  {
    "text": "and your question is like what do you do um whereas a learning action is intended",
    "start": "1786559",
    "end": "1793279"
  },
  {
    "text": "to update your behavior in some future unknown context and so that's really really like where you start to get",
    "start": "1793279",
    "end": "1798760"
  },
  {
    "text": "generalization and so the decision to sort of commit something to a long-term memory store is is specifically in the",
    "start": "1798760",
    "end": "1805360"
  },
  {
    "text": "context where you think you're going to need that again in the future um so reasoning produces like you know it",
    "start": "1805360",
    "end": "1811039"
  },
  {
    "text": "updates your sort of existing like what's going on right now but then you might be like oh that's a useful so for",
    "start": "1811039",
    "end": "1816320"
  },
  {
    "text": "instance in reflex and you you you decide okay I have this this thing happen to me in the environment and",
    "start": "1816320",
    "end": "1823519"
  },
  {
    "text": "that's something that I should really actually remember at some unknown point in the future and that's why that's why",
    "start": "1823519",
    "end": "1829559"
  },
  {
    "text": "learning is a special internal action because it's really it's updating a a a",
    "start": "1829559",
    "end": "1835279"
  },
  {
    "text": "you know a persistent characteristic of the agent as opposed to just you know generating more knowledge to be used",
    "start": "1835279",
    "end": "1840640"
  },
  {
    "text": "right now I think a useful analog here will be something like Alpha go right so",
    "start": "1840640",
    "end": "1845880"
  },
  {
    "text": "basically if you think about you know how alpha go works right so before Alpha",
    "start": "1845880",
    "end": "1852000"
  },
  {
    "text": "go takes each step right it will simulate a lot of you know like uh multicolor research simulate you know",
    "start": "1852000",
    "end": "1858519"
  },
  {
    "text": "what will happen if I take this the takes that so on and so forth right but at the end of the but at the end of the",
    "start": "1858519",
    "end": "1864880"
  },
  {
    "text": "time right it will pick one grounding action which is you know pick up a you know a stone and put it somewhere in the",
    "start": "1864880",
    "end": "1871399"
  },
  {
    "text": "in the board and that's kind of the grounding action and I intuition is kind of like before you do such a grounding",
    "start": "1871399",
    "end": "1877679"
  },
  {
    "text": "action you can do a lot of like internal simulation in your working memory you know but uh uh you you should you should",
    "start": "1877679",
    "end": "1885559"
  },
  {
    "text": "plan for each kind of the grounding action because once you commit this gring action then then uh the word is",
    "start": "1885559",
    "end": "1893760"
  },
  {
    "text": "changed and and you cannot undo that verus you know for reasoning and retrieval you can easily just simulate",
    "start": "1893760",
    "end": "1899960"
  },
  {
    "text": "and redo undo like everything in your your your mind or you know what your",
    "start": "1899960",
    "end": "1905559"
  },
  {
    "text": "memory um so I've been seeing some questions and I have some questions of my own about memory like how this is",
    "start": "1905559",
    "end": "1911840"
  },
  {
    "text": "parceled out how to think about it um so one question that I like from Dro was",
    "start": "1911840",
    "end": "1918720"
  },
  {
    "text": "the basis of deciding what goes into semantic memory versus episodic memory",
    "start": "1918720",
    "end": "1924399"
  },
  {
    "text": "for an agent um like how do you like how do we split that",
    "start": "1924399",
    "end": "1929760"
  },
  {
    "text": "up uh T do you want to answer or yeah absolutely sure so so um so the basic",
    "start": "1929760",
    "end": "1937080"
  },
  {
    "text": "idea is um there these different forms of memory are specifically designed for different kinds of for different kinds",
    "start": "1937080",
    "end": "1943519"
  },
  {
    "text": "of Prior experience so um semantic memor is is like facts about the world so you",
    "start": "1943519",
    "end": "1949240"
  },
  {
    "text": "know you and I know that you know Joe Biden is the president of the current president of the United States um that's",
    "start": "1949240",
    "end": "1955320"
  },
  {
    "text": "a fact on the other hand um you know I know that I read something online about",
    "start": "1955320",
    "end": "1960480"
  },
  {
    "text": "Joe Biden earlier today um and that's episodic memory for me so if you if you",
    "start": "1960480",
    "end": "1965600"
  },
  {
    "text": "take raw experience if you literally take the agent's perceptual experience",
    "start": "1965600",
    "end": "1970840"
  },
  {
    "text": "and store that text Trace that's episodic memory and so that's really",
    "start": "1970840",
    "end": "1976360"
  },
  {
    "text": "rich because contains everything the Asian experienced but that also means that it's super bulky and kind of hard",
    "start": "1976360",
    "end": "1981720"
  },
  {
    "text": "to work with because it's it's this really raw form of data and so semantic memory could be generated by for example",
    "start": "1981720",
    "end": "1988799"
  },
  {
    "text": "reasoning or or reflecting on that on that experience so that's some work that shanu has is you take this gigantic",
    "start": "1988799",
    "end": "1995360"
  },
  {
    "text": "trace of experience you extract some specific factual information that you think is going to be useful later and",
    "start": "1995360",
    "end": "2001399"
  },
  {
    "text": "you store that back to semantic memory I see same deal with generative agents they use their own prior experience",
    "start": "2001399",
    "end": "2007679"
  },
  {
    "text": "and reflect on there like you know I'm a I'm a this kind of person and then they store that in their semantic",
    "start": "2007679",
    "end": "2014880"
  },
  {
    "text": "memory so if I'm Joe Biden and I win a presidential election that's an episodic",
    "start": "2014880",
    "end": "2022519"
  },
  {
    "text": "memory which I might store as a fact that is Joe Biden is president of the United States right you could so so you",
    "start": "2022519",
    "end": "2028399"
  },
  {
    "text": "don't you don't have to Joe Biden doesn't have to wake up and think have I ever been elected president right he doesn't have to recall the memory of",
    "start": "2028399",
    "end": "2034559"
  },
  {
    "text": "being elected president he sort of knows factual he's the president um and so that's that's maybe the best yeah",
    "start": "2034559",
    "end": "2040679"
  },
  {
    "text": "exactly I are there he doesn't have to recall I mean that's sort of I should",
    "start": "2040679",
    "end": "2046320"
  },
  {
    "text": "have chosen a more neutral topic but [Laughter] anyway in in in terms of like the data",
    "start": "2046320",
    "end": "2053638"
  },
  {
    "text": "structure in which you're storing these memories like do you think there's a distinction between the best data structure to store episodic memory",
    "start": "2053639",
    "end": "2060398"
  },
  {
    "text": "compared to semantic memory yeah that's a very good question I can I can take on",
    "start": "2060399",
    "end": "2066599"
  },
  {
    "text": "that uh so so if you think about you know system level abstraction and the",
    "start": "2066599",
    "end": "2071638"
  },
  {
    "text": "lower level components there is often you know this kind of a disentanglement in the sense that you know uh here you",
    "start": "2071639",
    "end": "2079158"
  },
  {
    "text": "know I think the key idea is you should have different types of memory for different types of data but for each of",
    "start": "2079159",
    "end": "2086118"
  },
  {
    "text": "the memory component you can choose what is the best way to implement that depending on application so it's",
    "start": "2086119",
    "end": "2093240"
  },
  {
    "text": "possible that for both episodic memory and sematic memory you are both Implement that in some adjacent database",
    "start": "2093240",
    "end": "2099640"
  },
  {
    "text": "or you choose to use sematic me choose to implement sematic memory with some uh",
    "start": "2099640",
    "end": "2105240"
  },
  {
    "text": "uh Vector data store and then episodic memory using some uh SQL database I",
    "start": "2105240",
    "end": "2110440"
  },
  {
    "text": "think the the the the most interesting thing is that uh uh you have this",
    "start": "2110440",
    "end": "2116200"
  },
  {
    "text": "disentanglement of implementation and abstraction and uh you can choose which",
    "start": "2116200",
    "end": "2121599"
  },
  {
    "text": "component what is the suitable what's the most suitable way to to to to do this depending on application",
    "start": "2121599",
    "end": "2128520"
  },
  {
    "text": "um yeah I like that perspective but I actually want to bring David in to complicate it a bit which is that in",
    "start": "2128520",
    "end": "2135200"
  },
  {
    "text": "like language model Cascades it feels like the procedural like the LM is not",
    "start": "2135200",
    "end": "2140560"
  },
  {
    "text": "just the procedural memory right it also might be where semantic memory comes from it might be like um uh yeah so it",
    "start": "2140560",
    "end": "2148960"
  },
  {
    "text": "kind of like straddles at least that divide do you see that as well David or do you or is is the should we like try",
    "start": "2148960",
    "end": "2156040"
  },
  {
    "text": "and rip that out of language models yeah how do you see those interacting I mean",
    "start": "2156040",
    "end": "2161640"
  },
  {
    "text": "I guess I do want to emphasize that at the end of the day it's just language models inside programs and you can do anything inside those program so as much",
    "start": "2161640",
    "end": "2169200"
  },
  {
    "text": "as possible we should be interacting with things that are good at remembering and language models are not particularly",
    "start": "2169200",
    "end": "2175359"
  },
  {
    "text": "good at remembering like there's sort of I know it's a it's a problem",
    "start": "2175359",
    "end": "2182560"
  },
  {
    "text": "the yeah like you can try to put things directly into the model but in general I",
    "start": "2184319",
    "end": "2190640"
  },
  {
    "text": "think we want to rely on databases or rely on tools um I'd say the the larger",
    "start": "2190640",
    "end": "2197119"
  },
  {
    "text": "point about about model programs here is that it's um you have a program that has",
    "start": "2197119",
    "end": "2203520"
  },
  {
    "text": "uses models inside of it it may use tools it may use databases and then you want to be able to train it or like and",
    "start": "2203520",
    "end": "2209200"
  },
  {
    "text": "part of that action might be using a search engine like that's totally valid is part of a Cascade right uh and",
    "start": "2209200",
    "end": "2216319"
  },
  {
    "text": "there's a lot of things where the right tool for the job is not going to be the model",
    "start": "2216319",
    "end": "2221640"
  },
  {
    "text": "itself that said I'm I'm also like increasingly interested in the um uh",
    "start": "2224560",
    "end": "2230839"
  },
  {
    "text": "this like interplay of memory and and um and reasoning and I I think it's still an open question as to like exactly how",
    "start": "2230839",
    "end": "2237040"
  },
  {
    "text": "people retrieve relevant uh relevant memory for something like that's that's definitely a crazy you know thing that",
    "start": "2237040",
    "end": "2243720"
  },
  {
    "text": "happens in our brains um and I personally think it would be super interesting to try to do just some kind",
    "start": "2243720",
    "end": "2250160"
  },
  {
    "text": "of like spreading activation model over a you know dense retrieval or you have",
    "start": "2250160",
    "end": "2255560"
  },
  {
    "text": "you could there there's no there's no AR prior reason why you need to split",
    "start": "2255560",
    "end": "2261920"
  },
  {
    "text": "procedural and semantic and episodic memory into different data stores in theory you could have one vector data",
    "start": "2261920",
    "end": "2268400"
  },
  {
    "text": "store that you know embeds knowledge in text and you could just retrieve you",
    "start": "2268400",
    "end": "2273960"
  },
  {
    "text": "could use your current context do a nearest neighbors look up pull a bunch of stuff and say did I get a procedure",
    "start": "2273960",
    "end": "2279520"
  },
  {
    "text": "like did I get some action that I could take if so I should consider it did I get some piece of semantic knowledge if",
    "start": "2279520",
    "end": "2284599"
  },
  {
    "text": "so I should add it to my context did I get some episodic information in which case I should reflect on it in the",
    "start": "2284599",
    "end": "2290280"
  },
  {
    "text": "current context and decide how to act and so you could imagine some world where where there's actually like much",
    "start": "2290280",
    "end": "2296839"
  },
  {
    "text": "less imposed structure on the planning process and instead it's just a sequential process of retrieval",
    "start": "2296839",
    "end": "2302720"
  },
  {
    "text": "reasoning retrieval reasoning and then when you reach a certain threshold taking an external action and and and",
    "start": "2302720",
    "end": "2308920"
  },
  {
    "text": "you know if you look at existing models of of memory and decision- making in people that's sort of the stateof the",
    "start": "2308920",
    "end": "2314839"
  },
  {
    "text": "art um that does also point to just this this uh Spectrum in these things",
    "start": "2314839",
    "end": "2322640"
  },
  {
    "text": "generally of like on one extreme it's just going to be one big model is going to do everything you don't need the scaffolding and the Other Extreme is",
    "start": "2322640",
    "end": "2329280"
  },
  {
    "text": "like we need programs that are highly structured provide extreme scaffolding like have verification annotation",
    "start": "2329280",
    "end": "2335040"
  },
  {
    "text": "everywhere and it may be the case that you know the gbts in 8 years like they",
    "start": "2335040",
    "end": "2340640"
  },
  {
    "text": "do everything that your computer can do and they don't need any of these tools but why make it hard for themselves okay",
    "start": "2340640",
    "end": "2346400"
  },
  {
    "text": "and it's also just uh you can have at least in the current world you can have much higher assurances if you have this",
    "start": "2346400",
    "end": "2354000"
  },
  {
    "text": "scaffolding and you're you're like okay it retrieved the thing it put it in the context and then it generated and then",
    "start": "2354000",
    "end": "2360800"
  },
  {
    "text": "maybe you even have like a little subsection that's like a little side model that says did what it generate actually have anything to do with what",
    "start": "2360800",
    "end": "2366960"
  },
  {
    "text": "it said and maybe at some generate you'll be 100% sure that that it's going to be right you don't need that",
    "start": "2366960",
    "end": "2372880"
  },
  {
    "text": "verification but for the moment it helps to have to have this additional filter yeah that's right and and and there's",
    "start": "2372880",
    "end": "2379720"
  },
  {
    "text": "something to be said for the modu like even if the human brain does it all in one gigantic Vector store it's a lot",
    "start": "2379720",
    "end": "2386599"
  },
  {
    "text": "easier for us to design and reason about distinct ones at least for now but uh",
    "start": "2386599",
    "end": "2391960"
  },
  {
    "text": "David there's a to to your point there's a great section and at I think at the very end of the paper um it's like one",
    "start": "2391960",
    "end": "2398119"
  },
  {
    "text": "of my favorite Parts um largely inspired by shenu um about like what changes with you know gpn like how do we expect this",
    "start": "2398119",
    "end": "2406359"
  },
  {
    "text": "interaction of the agent code that we write versus the model to change as they become more and more capable",
    "start": "2406359",
    "end": "2412839"
  },
  {
    "text": "um um so I I I can pick up and and talk a little bit about the sort of um what",
    "start": "2412839",
    "end": "2421040"
  },
  {
    "text": "koala buys us in terms of like why is this actually useful um uh moving",
    "start": "2421040",
    "end": "2426520"
  },
  {
    "text": "forward so I think the first thing with sheny talked about a bunch is we have this proliferation of of really awesome work but it's it's sort of hard to",
    "start": "2426520",
    "end": "2433319"
  },
  {
    "text": "understand or or compare um and so you know it's it's actually a quite",
    "start": "2433319",
    "end": "2438480"
  },
  {
    "text": "straightforward and and I think helpful to kind of cast these agents into the koala framework and then kind of ask how",
    "start": "2438480",
    "end": "2444440"
  },
  {
    "text": "do they actually vary along these different dimensions so you know they use different forms of of long-term memory um and in fact many of them don't",
    "start": "2444440",
    "end": "2451319"
  },
  {
    "text": "actually use any long-term memory which is which is quite interesting um they have different forms of external Gra grounding so they're designed to be",
    "start": "2451319",
    "end": "2457359"
  },
  {
    "text": "deployed into different environments um they have a wide sort of variety of",
    "start": "2457359",
    "end": "2462400"
  },
  {
    "text": "these internal the richness of their internal action space so you know react as as amazing and impactful as it is",
    "start": "2462400",
    "end": "2468359"
  },
  {
    "text": "it's it's it's really just sort of reasoning about the current context it's not doing this kind of lifelong learning",
    "start": "2468359",
    "end": "2473839"
  },
  {
    "text": "and and retrieval from from memory whereas these more these more recent agents are actually uh uh sort of",
    "start": "2473839",
    "end": "2480280"
  },
  {
    "text": "integrating and synthesizing or reflex in is is integrating and synthesizing its experience in a in a much more um",
    "start": "2480280",
    "end": "2486400"
  },
  {
    "text": "long-term wife and then finally you can look at their actual decision- making procedure and ask are they really sort",
    "start": "2486400",
    "end": "2491640"
  },
  {
    "text": "of doing this fully-fledged deliberative reasoning process or do they look more like reflex agents you know Q agents",
    "start": "2491640",
    "end": "2498560"
  },
  {
    "text": "that are sort of proposing and selecting a single action at a time just based on the the probability from from the model",
    "start": "2498560",
    "end": "2504760"
  },
  {
    "text": "itself um and so I think what we see just in constructing this this table what we really saw is um there's a lot",
    "start": "2504760",
    "end": "2512040"
  },
  {
    "text": "of opportunity here because all of these agents can be sort of subsumed by the koala frame but none of them instantiates anything close to a",
    "start": "2512040",
    "end": "2518480"
  },
  {
    "text": "complete koala agent um and so we're really excited about the sort of future direction of of of building this out a",
    "start": "2518480",
    "end": "2524400"
  },
  {
    "text": "little bit more um and so just to give you an example this is the sort of section on on um learning in koala and I",
    "start": "2524400",
    "end": "2532400"
  },
  {
    "text": "won't you know try to try to read any of this but I think it's worth noting that when you see learning as writing to",
    "start": "2532400",
    "end": "2538119"
  },
  {
    "text": "long-term memory as opposed to you know reinforcement learning or specifically",
    "start": "2538119",
    "end": "2543359"
  },
  {
    "text": "like writing to semantic memory any of these individual things you can immediately see that these are all sort of different solutions to the problem of",
    "start": "2543359",
    "end": "2550079"
  },
  {
    "text": "how do you modify your behavior in the future given some existing experience",
    "start": "2550079",
    "end": "2555680"
  },
  {
    "text": "and that allows you to sort of understand and reconcile when it might be useful to implement one form of",
    "start": "2555680",
    "end": "2561160"
  },
  {
    "text": "learning versus another um and in particular it it actually this sort of process of of of reviewing the",
    "start": "2561160",
    "end": "2567319"
  },
  {
    "text": "literature highlights a ton of gaps where there are a lot of methods that have been developed outside of language",
    "start": "2567319",
    "end": "2572839"
  },
  {
    "text": "agents that just haven't actually been attempted inside language agents yet and so we really think this is a this is an",
    "start": "2572839",
    "end": "2578559"
  },
  {
    "text": "exciting uh future direction of research which is just leveraging all of these known techniques in the context of of",
    "start": "2578559",
    "end": "2585200"
  },
  {
    "text": "language agents for example can the agent change his own code I think there are gonna be",
    "start": "2585200",
    "end": "2591480"
  },
  {
    "text": "some new word coming soon but yeah and yeah so the last author on this",
    "start": "2591480",
    "end": "2598920"
  },
  {
    "text": "paper is Tom Griffith who uh you know uh taught me everything I know about",
    "start": "2598920",
    "end": "2604280"
  },
  {
    "text": "cognitive science I think um but the his perspective has always been",
    "start": "2604280",
    "end": "2610079"
  },
  {
    "text": "this like computational basan perspective which is about like rational use of computational resources and and",
    "start": "2610079",
    "end": "2616640"
  },
  {
    "text": "attainment of goals and what's one reason why I was excited to put like David in conversation with this paper",
    "start": "2616640",
    "end": "2622960"
  },
  {
    "text": "was that the perspective in language model Cascades is probabilistic is beian",
    "start": "2622960",
    "end": "2629000"
  },
  {
    "text": "so uh David what do you think the prospects are for using that kind of framework to like kind of maybe put all",
    "start": "2629000",
    "end": "2637839"
  },
  {
    "text": "these things on the same footing like it's all it's all B updating or it's all you know kale Divergence minimization or",
    "start": "2637839",
    "end": "2645160"
  },
  {
    "text": "something yeah so that's let's see I mean one perspective is just that all of",
    "start": "2645160",
    "end": "2650880"
  },
  {
    "text": "RL that works ends up kind of looking like you're doing a bit evation inference like it's a bit reductionist",
    "start": "2650880",
    "end": "2657040"
  },
  {
    "text": "like this is sort of the argument you often get it's like well everything that works like if you squint like it's kind of beian I'm not going to necessarily",
    "start": "2657040",
    "end": "2663559"
  },
  {
    "text": "make that argument here too much um let's see I guess like it it succeeds or fails",
    "start": "2663559",
    "end": "2671520"
  },
  {
    "text": "in so far as it's um like useful for clarifying things or so like putting",
    "start": "2671520",
    "end": "2677480"
  },
  {
    "text": "things on the same footing or like helping you come up with new ideas right so okay so in a way the the",
    "start": "2677480",
    "end": "2685680"
  },
  {
    "text": "form of your cognitive architecture is it's forming the PRI over what are things that your agent can do right like",
    "start": "2685680",
    "end": "2692760"
  },
  {
    "text": "if you don't have a semantic M if you don't have this internal memory then it's not going to learn over a long ter",
    "start": "2692760",
    "end": "2699119"
  },
  {
    "text": "long time and that's restricting the sort of classes of things it's going to be able to do so that's just one",
    "start": "2699119",
    "end": "2704400"
  },
  {
    "text": "perspective of the sort of scaffolding sort of structures you put in place uh",
    "start": "2704400",
    "end": "2709760"
  },
  {
    "text": "set the stage for p wide of the tasks and and",
    "start": "2709760",
    "end": "2715640"
  },
  {
    "text": "like like what can this agent evolve into when you actually run it in the real world there's also like as you",
    "start": "2715640",
    "end": "2721280"
  },
  {
    "text": "train it like you know I don't think there's been much work yet on training these agents using reinforcement",
    "start": "2721280",
    "end": "2727680"
  },
  {
    "text": "learning for example largely because people are using blackbox models where they're just sampling but I'm surely",
    "start": "2727680",
    "end": "2734040"
  },
  {
    "text": "people are going to start doing things like policy grading Etc which you know is basically doing some form of of uh",
    "start": "2734040",
    "end": "2741480"
  },
  {
    "text": "beian updating on the weights",
    "start": "2741480",
    "end": "2746760"
  },
  {
    "text": "um let's see I I don't think there's I think there's you can sort of engineer your",
    "start": "2747640",
    "end": "2754040"
  },
  {
    "text": "way forward though I don't necessarily think you have to approach it from the perspective of you are explicitly",
    "start": "2754040",
    "end": "2760599"
  },
  {
    "text": "optimizing like free energy or something like yeah the there's a lot of uh things",
    "start": "2760599",
    "end": "2766079"
  },
  {
    "text": "that are very obviously we need to fix and in doing so maybe under the hood they're doing something like principled",
    "start": "2766079",
    "end": "2772480"
  },
  {
    "text": "from from that perspective but uh you can justify them very easily by just",
    "start": "2772480",
    "end": "2778040"
  },
  {
    "text": "like this is a problem we're going to fix it by introducing this component and engineer our way to like",
    "start": "2778040",
    "end": "2784839"
  },
  {
    "text": "pretty intelligent and systems yeah rlf came before even Perez's paper saying",
    "start": "2784839",
    "end": "2790240"
  },
  {
    "text": "rhf is kale Divergence minimization and that might be we might have practiced leading theory for a long time yes I",
    "start": "2790240",
    "end": "2798079"
  },
  {
    "text": "agree and I mean the hope is that these perspectives do actually provide something useful um like I do actually",
    "start": "2798079",
    "end": "2804760"
  },
  {
    "text": "think that the like inference perspective makes a lot of algorithms",
    "start": "2804760",
    "end": "2810240"
  },
  {
    "text": "apparent like starting to do things like beam search on top of your model or starting to do some sort of search like",
    "start": "2810240",
    "end": "2816760"
  },
  {
    "text": "uh what are you actually trying to maximize or like how do you actually take information maximizing moves for",
    "start": "2816760",
    "end": "2823599"
  },
  {
    "text": "example like you actually try to like not just say from the model what do you",
    "start": "2823599",
    "end": "2828880"
  },
  {
    "text": "think we should do but it actually like plans against the world model and it's like okay these are the plac I have uncertainty based on that uncertainty",
    "start": "2828880",
    "end": "2835079"
  },
  {
    "text": "I'm going to go gather more information like that's where you can start to link up these things and take ideas from optimal experiment design um a lot of",
    "start": "2835079",
    "end": "2843079"
  },
  {
    "text": "this stuff the way I think about it is actually in terms of uh there's simulation based inference which is sort",
    "start": "2843079",
    "end": "2848839"
  },
  {
    "text": "of fuol to problemy programming in a way and that's you have a syst you want to run it forward you have some things you",
    "start": "2848839",
    "end": "2854520"
  },
  {
    "text": "want to be true or that you've observed to be true so in this case it solved a problem or um it stayed within some",
    "start": "2854520",
    "end": "2861760"
  },
  {
    "text": "particular bounds and you're basically just fiddling with the parameters you're trying to be able to run it backwards",
    "start": "2861760",
    "end": "2867520"
  },
  {
    "text": "like when I run this agent forward it gets the right answer I want to run it backwards and the place that you have saw this in like the real world people",
    "start": "2867520",
    "end": "2874079"
  },
  {
    "text": "may have heard of like the uh black hole when they were Imaging the black hole for example or the larger drone collider",
    "start": "2874079",
    "end": "2880240"
  },
  {
    "text": "like they built the larger drone collider and they ran it and they had uh the what the standard model predicted",
    "start": "2880240",
    "end": "2887119"
  },
  {
    "text": "about the higs Bon and they had to they couldn't change what the um what the uh",
    "start": "2887119",
    "end": "2893400"
  },
  {
    "text": "hydron collider actually output so they had to like fiddle with the parameters of the standard model until it fit and",
    "start": "2893400",
    "end": "2899240"
  },
  {
    "text": "that's how they work out the all the parameters of the Tak boson it's sort of a similar thing here it's like M well",
    "start": "2899240",
    "end": "2906160"
  },
  {
    "text": "we can't change whether it's going to get it right or not when we run it except by fiddling with the architecture",
    "start": "2906160",
    "end": "2911640"
  },
  {
    "text": "fiddling with the parameters and this can be a perspective on how ways and that that admits a ton",
    "start": "2911640",
    "end": "2917520"
  },
  {
    "text": "of different algorithms for doing",
    "start": "2917520",
    "end": "2920960"
  },
  {
    "text": "that all right I wanted to leave a few minutes for Harrison to talk about langing chain uh and how they're looking",
    "start": "2924960",
    "end": "2932040"
  },
  {
    "text": "at koala um so I think I'll kick it over over that was also most let me say let",
    "start": "2932040",
    "end": "2938720"
  },
  {
    "text": "me say just super quickly I want to I have one thing that I do want to say um which I think might be helpful for this AUD just to kind of wrap stuff up really",
    "start": "2938720",
    "end": "2945280"
  },
  {
    "text": "quick um so I think um one of the things that sh you and I are excited about here is just like this idea of having a",
    "start": "2945280",
    "end": "2952240"
  },
  {
    "text": "modular design pattern is really helpful for people who are doing research on models because it allows us to actually",
    "start": "2952240",
    "end": "2957599"
  },
  {
    "text": "compare these different methods in a systematic way but I think it also is really helpful from an implementation perspective just from this perspective",
    "start": "2957599",
    "end": "2964400"
  },
  {
    "text": "of reducing technical de in in these complex systems whether you're at a single company and you have some internal model repo language agent repo",
    "start": "2964400",
    "end": "2971440"
  },
  {
    "text": "that you know so that you're like customer service agent isn't using a totally different data source from your you know whatever agent um and then and",
    "start": "2971440",
    "end": "2978400"
  },
  {
    "text": "then also I think this this sort of this structured framework for deliberative reasoning is nice because it it",
    "start": "2978400",
    "end": "2984640"
  },
  {
    "text": "leverages these different forms of learning so you can pull in different kinds of memory in the planning stage um",
    "start": "2984640",
    "end": "2990240"
  },
  {
    "text": "and then also as I was mentioning like I think that is really interesting this this idea of using a mixture of language based and simulation based reasoning um",
    "start": "2990240",
    "end": "2997559"
  },
  {
    "text": "is a really nice a really nice potential uh path forward for these um these systems so um um yeah that's it from us",
    "start": "2997559",
    "end": "3007960"
  },
  {
    "text": "thank you awesome yeah um so yeah your second",
    "start": "3007960",
    "end": "3016319"
  },
  {
    "text": "point about mixing different kinds of learning simulation and language based uh reasoning really dovetailed with uh",
    "start": "3016319",
    "end": "3023599"
  },
  {
    "text": "the perspective that we got from David and from Cascades your first point about reducing technical vet and making it",
    "start": "3023599",
    "end": "3029079"
  },
  {
    "text": "easier to engineer these systems I think connects with Harrison's perspective from uh from building Lang chain yeah",
    "start": "3029079",
    "end": "3036400"
  },
  {
    "text": "and I mean one of the one of the conversations I had with shenu uh right after the paper came out was trying to map some of kind of like the L chain",
    "start": "3036400",
    "end": "3042520"
  },
  {
    "text": "chains and agents um into this framework and kind of see how uh like what what",
    "start": "3042520",
    "end": "3048119"
  },
  {
    "text": "what that mapping um kind of looks like um I think like uh and I know we're a",
    "start": "3048119",
    "end": "3054280"
  },
  {
    "text": "bit short on time so I'll maybe just share some thoughts and then I'd actually love we probably won't have time to",
    "start": "3054280",
    "end": "3060160"
  },
  {
    "text": "discuss anything but um I I think like uh what in in chatting with Shinu I think one um and again like link Chain's",
    "start": "3060160",
    "end": "3067799"
  },
  {
    "text": "focused on on chains as well as agents so it's not purely kind of like agent based um but one of the big kind of like",
    "start": "3067799",
    "end": "3073920"
  },
  {
    "text": "um but almost because of that one of the big things that we're interested in is",
    "start": "3073920",
    "end": "3079079"
  },
  {
    "text": "like what is the pattern for like interacting with tools and taking actions look like um and I think to that",
    "start": "3079079",
    "end": "3084960"
  },
  {
    "text": "end we draw a little bit of a of a less we draw a little less distinction between kind of like internal tools",
    "start": "3084960",
    "end": "3092040"
  },
  {
    "text": "versus external tools um and so to just give one of the concrete examples that I was going back and forth with shenu",
    "start": "3092040",
    "end": "3097680"
  },
  {
    "text": "about for like let's say like the fact based episodic memory like if that's something that I maintain myself or if I",
    "start": "3097680",
    "end": "3104280"
  },
  {
    "text": "use like Wikipedia as an external form of that how I interact with that could look very similar like I could I could",
    "start": "3104280",
    "end": "3110280"
  },
  {
    "text": "always query that I could query that kind of like uh with an arbitrary query multiple times like act um and so I",
    "start": "3110280",
    "end": "3116559"
  },
  {
    "text": "think from like the interaction patterns and the code patterns there it can look very similar between like an internal",
    "start": "3116559",
    "end": "3122000"
  },
  {
    "text": "tool and an external tool and I think Shu brought up some good points around if it's an external tool you might want to handle kind of like edge cases more",
    "start": "3122000",
    "end": "3128240"
  },
  {
    "text": "it could like change its form under the hood if it's purely internal it could like stay the same state but I think",
    "start": "3128240",
    "end": "3134480"
  },
  {
    "text": "like um in and those are very good points and I",
    "start": "3134480",
    "end": "3139520"
  },
  {
    "text": "haven't kind of like fully gred them and and and thought about them yet but I think like on the surface like interacting with internal and external",
    "start": "3139520",
    "end": "3146240"
  },
  {
    "text": "can look fairly similar um and so I'm just going to share one diagram and I shared this with David last uh last",
    "start": "3146240",
    "end": "3153920"
  },
  {
    "text": "Friday and uh I don't think it's perfect so I don't love it um but I'm going to",
    "start": "3153920",
    "end": "3159559"
  },
  {
    "text": "share it just because I think so so this is um so this is something that we've been thinking a little bit about and",
    "start": "3159559",
    "end": "3166240"
  },
  {
    "text": "there's it kind of like runs the gamut of like code to like pure agent and then there's a few different dimensions that",
    "start": "3166240",
    "end": "3171559"
  },
  {
    "text": "we're thinking about and and so the first two I think are pretty straightforward and then the third one I",
    "start": "3171559",
    "end": "3176760"
  },
  {
    "text": "don't I don't really love but I don't 100% know how to describe it better the first one's like just deciding like what",
    "start": "3176760",
    "end": "3182160"
  },
  {
    "text": "the output is so like using llms you start to have like the the the language Model start to decide some of that you",
    "start": "3182160",
    "end": "3187480"
  },
  {
    "text": "can do that with like a single llm call you can do that with a chain then there's like deciding what steps to take",
    "start": "3187480",
    "end": "3192880"
  },
  {
    "text": "like as part of your chain and so if you're making just a single LM call or if you have a chain the steps are kind",
    "start": "3192880",
    "end": "3198160"
  },
  {
    "text": "of like concrete like you're going to do this then you're going to do this then you're going to do this and there's pros and cons to that right um and then as",
    "start": "3198160",
    "end": "3204680"
  },
  {
    "text": "soon as you start letting the and a lot of this by the way the like code here I think is this wraps really nicely to",
    "start": "3204680",
    "end": "3211319"
  },
  {
    "text": "some of like the procedural stuff that shenu was talking about um so like what's the what's the code in behind the",
    "start": "3211319",
    "end": "3218079"
  },
  {
    "text": "application um then when you start letting the because yeah both as him and",
    "start": "3218079",
    "end": "3223280"
  },
  {
    "text": "David said it's really about like yeah codes interacting with the language model what does that code look like um",
    "start": "3223280",
    "end": "3228480"
  },
  {
    "text": "and so then like when you start letting the language model decide what actions you actually take that could be we we",
    "start": "3228480",
    "end": "3234160"
  },
  {
    "text": "draw a differentiation between between kind of like routing and some type of like State machine the main difference being the state machine is in a loop um",
    "start": "3234160",
    "end": "3240119"
  },
  {
    "text": "and so then you can start to have Cycles um and and with a router you you don't have those types of cycles and I think",
    "start": "3240119",
    "end": "3245880"
  },
  {
    "text": "once you start adding Cycles it's kind of like you know a while loop while you're deciding actions um and then the",
    "start": "3245880",
    "end": "3251960"
  },
  {
    "text": "difference between State machine and agent this is this is a lot of I were talking about and I don't think I have a super clear way to describe this but I",
    "start": "3251960",
    "end": "3258760"
  },
  {
    "text": "guess like I'll maybe show like an example of what I mean by like a state machine which is is this diagram from",
    "start": "3258760",
    "end": "3264079"
  },
  {
    "text": "sweep. deev and you can see here they like break down the steps into like very clear steps where there's a planning",
    "start": "3264079",
    "end": "3269640"
  },
  {
    "text": "step and then an execution step and then a validate step and they cycle between them and then at some point they're done",
    "start": "3269640",
    "end": "3275040"
  },
  {
    "text": "and if you compare this to like something like Auto GPT you're kind of like implicitly asking Auto GPT to do",
    "start": "3275040",
    "end": "3281200"
  },
  {
    "text": "all of this in sequence but you're not like hardcoding that it has to do this and so I don't really know how to",
    "start": "3281200",
    "end": "3286280"
  },
  {
    "text": "describe that but I think like that's the difference that I'm trying to get at and I'd love any thoughts on all of",
    "start": "3286280",
    "end": "3293640"
  },
  {
    "text": "this and I also know we're short on time so maybe these thoughts will have to come",
    "start": "3294079",
    "end": "3299119"
  },
  {
    "text": "at a separate",
    "start": "3299119",
    "end": "3301640"
  },
  {
    "text": "Point I've made Charles silent I don't know if this is good or bad I've never seen it before um a lot of uh internal",
    "start": "3310559",
    "end": "3318160"
  },
  {
    "text": "actions going on there sorry yeah uh so I guess show your work",
    "start": "3318160",
    "end": "3325480"
  },
  {
    "text": "yeah to to close it out um let's think step by step uh so yeah I really enjoyed",
    "start": "3325480",
    "end": "3332880"
  },
  {
    "text": "uh like yeah getting that walkr of the koala paper from J and Ted um thanks for sharing that I think there's there's",
    "start": "3332880",
    "end": "3339039"
  },
  {
    "text": "like obviously a ton of opportunity here and like being able to bridge gaps between Fields whether it's",
    "start": "3339039",
    "end": "3344680"
  },
  {
    "text": "probabilistic programming world uh the like RL world the like classic cognitive architectures and good old fashion Ai",
    "start": "3344680",
    "end": "3351160"
  },
  {
    "text": "and then like what people are doing in the like open source uh like open source world and and iteration",
    "start": "3351160",
    "end": "3359720"
  },
  {
    "text": "on program flow around around language models like I think that's super",
    "start": "3359720",
    "end": "3365119"
  },
  {
    "text": "critical and this like Lang chain and koala and language model Cascades are",
    "start": "3365119",
    "end": "3371039"
  },
  {
    "text": "they three of my favorite examples of that kind of like cross-pollination um between these these",
    "start": "3371039",
    "end": "3376280"
  },
  {
    "text": "fields so I had a great time in this webinar hearing from all of you um and tons of exciting questions in the Q&A um",
    "start": "3376280",
    "end": "3384079"
  },
  {
    "text": "and in the chat and I hopefully this spawns discussions offline online in uh",
    "start": "3384079",
    "end": "3390039"
  },
  {
    "text": "the folks who attended and the folks who are watching recording later to like keep digging into these questions into",
    "start": "3390039",
    "end": "3395240"
  },
  {
    "text": "like what the cognitive architectures uh are going to look like and and how we're going to make them",
    "start": "3395240",
    "end": "3400880"
  },
  {
    "text": "better and and I want to thank Charles for moderating this and you know I think",
    "start": "3400880",
    "end": "3405960"
  },
  {
    "text": "he probably has the he has to he has to actually understand what's going on so he can ask good questions and I think he",
    "start": "3405960",
    "end": "3411400"
  },
  {
    "text": "somehow always manages to do that which is incredibly impressive so",
    "start": "3411400",
    "end": "3416440"
  },
  {
    "text": "Ser I'm just a man asking questions that's you know that's thanks hard",
    "start": "3416440",
    "end": "3421520"
  },
  {
    "text": "that's hard that's hard all right well thank you everyone",
    "start": "3421520",
    "end": "3426599"
  },
  {
    "text": "for joining thank you everyone for tuning in um H have a great rest of your",
    "start": "3426599",
    "end": "3432280"
  },
  {
    "text": "day fun take care guys",
    "start": "3432280",
    "end": "3437520"
  }
]
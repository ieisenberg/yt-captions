[
  {
    "text": "hi this is Lance from Lang chain this is",
    "start": "1280",
    "end": "3439"
  },
  {
    "text": "the 14th part of our rag from scratch",
    "start": "3439",
    "end": "5359"
  },
  {
    "text": "series we're going to I'm going to be",
    "start": "5359",
    "end": "7000"
  },
  {
    "text": "talking about an approach called cold",
    "start": "7000",
    "end": "10240"
  },
  {
    "text": "bear um so we've talked about a few",
    "start": "10240",
    "end": "15120"
  },
  {
    "text": "different approaches for indexing and",
    "start": "15120",
    "end": "17520"
  },
  {
    "text": "just as kind of a refresher indexing",
    "start": "17520",
    "end": "19160"
  },
  {
    "text": "Falls uh kind of right down here in our",
    "start": "19160",
    "end": "21480"
  },
  {
    "text": "flow we started initially with career",
    "start": "21480",
    "end": "23800"
  },
  {
    "text": "translation taking a question",
    "start": "23800",
    "end": "25599"
  },
  {
    "text": "translating it in some way to optimize",
    "start": "25599",
    "end": "27400"
  },
  {
    "text": "retrieval we talked about routing it to",
    "start": "27400",
    "end": "29679"
  },
  {
    "text": "par database we then talked about query",
    "start": "29679",
    "end": "32439"
  },
  {
    "text": "construction so going from natural",
    "start": "32439",
    "end": "34320"
  },
  {
    "text": "language to the DSL or domain specific",
    "start": "34320",
    "end": "37360"
  },
  {
    "text": "language for E any of the databases that",
    "start": "37360",
    "end": "39920"
  },
  {
    "text": "you want to work with those are you know",
    "start": "39920",
    "end": "41960"
  },
  {
    "text": "metadata filters for Vector stores or",
    "start": "41960",
    "end": "44600"
  },
  {
    "text": "Cipher",
    "start": "44600",
    "end": "45719"
  },
  {
    "text": "for graph DB or SQL for relational DB so",
    "start": "45719",
    "end": "49480"
  },
  {
    "text": "that's kind of the flow we talked about",
    "start": "49480",
    "end": "50680"
  },
  {
    "text": "today we talked about some indexing",
    "start": "50680",
    "end": "52800"
  },
  {
    "text": "approaches like multi-representation",
    "start": "52800",
    "end": "54480"
  },
  {
    "text": "indexing we gave a small shout out to",
    "start": "54480",
    "end": "57160"
  },
  {
    "text": "GRE cam in the series on chunking uh we",
    "start": "57160",
    "end": "60039"
  },
  {
    "text": "talked about hierarchical indexing and I",
    "start": "60039",
    "end": "62600"
  },
  {
    "text": "want to include one Advanced kind of",
    "start": "62600",
    "end": "65000"
  },
  {
    "text": "embedding approach so we talked a lot",
    "start": "65000",
    "end": "67000"
  },
  {
    "text": "about embeddings are obviously very",
    "start": "67000",
    "end": "68439"
  },
  {
    "text": "Central to semantic similarity search um",
    "start": "68439",
    "end": "71600"
  },
  {
    "text": "and",
    "start": "71600",
    "end": "72320"
  },
  {
    "text": "retrieval so one of the interesting",
    "start": "72320",
    "end": "75479"
  },
  {
    "text": "points that's been brought up is that",
    "start": "75479",
    "end": "78200"
  },
  {
    "text": "embedding models of course take a",
    "start": "78200",
    "end": "79920"
  },
  {
    "text": "document you can see here on the top and",
    "start": "79920",
    "end": "82560"
  },
  {
    "text": "embed it basically compress it to a",
    "start": "82560",
    "end": "85799"
  },
  {
    "text": "vector so it's kind of a compression",
    "start": "85799",
    "end": "88280"
  },
  {
    "text": "process you're representing all the",
    "start": "88280",
    "end": "89439"
  },
  {
    "text": "semantics of that document in a single",
    "start": "89439",
    "end": "91920"
  },
  {
    "text": "Vector you're doing the same to your",
    "start": "91920",
    "end": "93960"
  },
  {
    "text": "question you're doing a similarity",
    "start": "93960",
    "end": "95320"
  },
  {
    "text": "search between the question embedding",
    "start": "95320",
    "end": "97000"
  },
  {
    "text": "and the document embedding um in order",
    "start": "97000",
    "end": "99520"
  },
  {
    "text": "to perform retrieval you're typically",
    "start": "99520",
    "end": "101320"
  },
  {
    "text": "taking the you know K most similar um",
    "start": "101320",
    "end": "105560"
  },
  {
    "text": "document of betting is given a question",
    "start": "105560",
    "end": "108119"
  },
  {
    "text": "and that's really how you're doing it",
    "start": "108119",
    "end": "110200"
  },
  {
    "text": "now a lot of people have said well hey",
    "start": "110200",
    "end": "112079"
  },
  {
    "text": "the compressing a full document with all",
    "start": "112079",
    "end": "113960"
  },
  {
    "text": "this Nuance to single Vector seems a",
    "start": "113960",
    "end": "115880"
  },
  {
    "text": "little bit um overly restrictive right",
    "start": "115880",
    "end": "118960"
  },
  {
    "text": "and this is a fair question to ask um",
    "start": "118960",
    "end": "121520"
  },
  {
    "text": "there's been some interesting approaches",
    "start": "121520",
    "end": "122960"
  },
  {
    "text": "to try to address that and one is this",
    "start": "122960",
    "end": "125039"
  },
  {
    "text": "this this approach method called Co bear",
    "start": "125039",
    "end": "128640"
  },
  {
    "text": "so the intuition is actually pretty",
    "start": "128640",
    "end": "130280"
  },
  {
    "text": "straightforward there's a bunch of good",
    "start": "130280",
    "end": "131720"
  },
  {
    "text": "articles I link down here this is my",
    "start": "131720",
    "end": "133239"
  },
  {
    "text": "little cartoon to explain it which I",
    "start": "133239",
    "end": "135560"
  },
  {
    "text": "think is hopefully kind of helpful but",
    "start": "135560",
    "end": "137640"
  },
  {
    "text": "here's the main idea instead of just",
    "start": "137640",
    "end": "140160"
  },
  {
    "text": "taking a document and compressing it",
    "start": "140160",
    "end": "141800"
  },
  {
    "text": "down to a single Vector basically single",
    "start": "141800",
    "end": "144800"
  },
  {
    "text": "uh what we might call embedding Vector",
    "start": "144800",
    "end": "147239"
  },
  {
    "text": "we take the document we break it up into",
    "start": "147239",
    "end": "149319"
  },
  {
    "text": "tokens so tokens are just like you know",
    "start": "149319",
    "end": "151560"
  },
  {
    "text": "units of of content it depends on the",
    "start": "151560",
    "end": "155040"
  },
  {
    "text": "token areas you use we talked about this",
    "start": "155040",
    "end": "156720"
  },
  {
    "text": "earlier so you basically tokenize it and",
    "start": "156720",
    "end": "160000"
  },
  {
    "text": "you produce basically an embedding or",
    "start": "160000",
    "end": "161720"
  },
  {
    "text": "vector for every token and there's some",
    "start": "161720",
    "end": "164239"
  },
  {
    "text": "kind of positional uh waiting that",
    "start": "164239",
    "end": "166080"
  },
  {
    "text": "occurs when you do this process so you",
    "start": "166080",
    "end": "168239"
  },
  {
    "text": "obviously you look to look at the",
    "start": "168239",
    "end": "169319"
  },
  {
    "text": "implementation understand the details",
    "start": "169319",
    "end": "170840"
  },
  {
    "text": "but the intuition is that you're",
    "start": "170840",
    "end": "172680"
  },
  {
    "text": "producing some kind of representation",
    "start": "172680",
    "end": "174480"
  },
  {
    "text": "for every token okay and you're doing",
    "start": "174480",
    "end": "177400"
  },
  {
    "text": "the same thing for your questions you're",
    "start": "177400",
    "end": "179959"
  },
  {
    "text": "taking your question you're breaking",
    "start": "179959",
    "end": "181040"
  },
  {
    "text": "into a tokens and you have some",
    "start": "181040",
    "end": "182720"
  },
  {
    "text": "representation or vector per token and",
    "start": "182720",
    "end": "185760"
  },
  {
    "text": "then what you're doing is for every",
    "start": "185760",
    "end": "187599"
  },
  {
    "text": "token in the question you're Computing",
    "start": "187599",
    "end": "190040"
  },
  {
    "text": "the similarity across all the tokens in",
    "start": "190040",
    "end": "193519"
  },
  {
    "text": "the document and you're finding the max",
    "start": "193519",
    "end": "196560"
  },
  {
    "text": "you're taking the max you're storing",
    "start": "196560",
    "end": "199120"
  },
  {
    "text": "that and you're doing that process for",
    "start": "199120",
    "end": "202920"
  },
  {
    "text": "all the tokens in the question so again",
    "start": "202920",
    "end": "206000"
  },
  {
    "text": "token two you compare it to every token",
    "start": "206000",
    "end": "208480"
  },
  {
    "text": "in the in the document",
    "start": "208480",
    "end": "210799"
  },
  {
    "text": "compute the",
    "start": "210799",
    "end": "212200"
  },
  {
    "text": "Max and then the final score is in this",
    "start": "212200",
    "end": "215040"
  },
  {
    "text": "case the sum of the max similarities uh",
    "start": "215040",
    "end": "218080"
  },
  {
    "text": "between every question token and any",
    "start": "218080",
    "end": "220799"
  },
  {
    "text": "document token so it's an interesting",
    "start": "220799",
    "end": "224120"
  },
  {
    "text": "approach uh it reports very strong",
    "start": "224120",
    "end": "226760"
  },
  {
    "text": "performance latency is definitely a",
    "start": "226760",
    "end": "229159"
  },
  {
    "text": "question um so kind of production",
    "start": "229159",
    "end": "231200"
  },
  {
    "text": "Readiness is something you should look",
    "start": "231200",
    "end": "232720"
  },
  {
    "text": "into but it's a it's an approach that's",
    "start": "232720",
    "end": "234799"
  },
  {
    "text": "worth mentioning here uh because it's",
    "start": "234799",
    "end": "237079"
  },
  {
    "text": "pretty",
    "start": "237079",
    "end": "238239"
  },
  {
    "text": "interesting um let's walk through the",
    "start": "238239",
    "end": "241200"
  },
  {
    "text": "code",
    "start": "241200",
    "end": "243040"
  },
  {
    "text": "so there's actually a really nice",
    "start": "243040",
    "end": "245000"
  },
  {
    "text": "Library called rouille which makes it",
    "start": "245000",
    "end": "247079"
  },
  {
    "text": "very easy to play with Co bear um she's",
    "start": "247079",
    "end": "249720"
  },
  {
    "text": "pip install it here I've already done",
    "start": "249720",
    "end": "251920"
  },
  {
    "text": "that and we can use one of their",
    "start": "251920",
    "end": "254159"
  },
  {
    "text": "pre-train models to mediate this process",
    "start": "254159",
    "end": "256199"
  },
  {
    "text": "so I'm basically following their",
    "start": "256199",
    "end": "257479"
  },
  {
    "text": "documentation this is kind of what they",
    "start": "257479",
    "end": "259120"
  },
  {
    "text": "recommended um so I'm running this",
    "start": "259120",
    "end": "261720"
  },
  {
    "text": "now hopefully this runs somewhat quickly",
    "start": "261720",
    "end": "264040"
  },
  {
    "text": "I'm not sure I I previously have loaded",
    "start": "264040",
    "end": "266040"
  },
  {
    "text": "this model so hopefully it won't take",
    "start": "266040",
    "end": "267320"
  },
  {
    "text": "too long and yeah you can see it's",
    "start": "267320",
    "end": "268720"
  },
  {
    "text": "pretty quick uh I'm on a Mac M2 with 32",
    "start": "268720",
    "end": "271680"
  },
  {
    "text": "gigs um so just as like a context in",
    "start": "271680",
    "end": "274280"
  },
  {
    "text": "terms of my system um this is from their",
    "start": "274280",
    "end": "276759"
  },
  {
    "text": "documentation we're just grabbing a",
    "start": "276759",
    "end": "278199"
  },
  {
    "text": "Wikipedia page this is getting a full",
    "start": "278199",
    "end": "280120"
  },
  {
    "text": "document on Miyazaki so that's cool",
    "start": "280120",
    "end": "283880"
  },
  {
    "text": "we're going to grab that now this is",
    "start": "283880",
    "end": "285800"
  },
  {
    "text": "just from their docs this is basically",
    "start": "285800",
    "end": "287160"
  },
  {
    "text": "how we create an index so we provide the",
    "start": "287160",
    "end": "289360"
  },
  {
    "text": "you know some index name the collection",
    "start": "289360",
    "end": "292120"
  },
  {
    "text": "um the max document length and yeah you",
    "start": "292120",
    "end": "294240"
  },
  {
    "text": "should look at their documentation with",
    "start": "294240",
    "end": "295680"
  },
  {
    "text": "these flags these are just the default",
    "start": "295680",
    "end": "297000"
  },
  {
    "text": "so I'm going to create my index um so",
    "start": "297000",
    "end": "299800"
  },
  {
    "text": "get some logging here so it it's working",
    "start": "299800",
    "end": "301960"
  },
  {
    "text": "under the hood um and by the way I",
    "start": "301960",
    "end": "305080"
  },
  {
    "text": "actually have their documentation open",
    "start": "305080",
    "end": "306600"
  },
  {
    "text": "so you can kind of follow along um",
    "start": "306600",
    "end": "310360"
  },
  {
    "text": "so",
    "start": "310360",
    "end": "312199"
  },
  {
    "text": "um let's see yeah right about here so",
    "start": "312199",
    "end": "315360"
  },
  {
    "text": "you can kind of follow this indexing",
    "start": "315360",
    "end": "316720"
  },
  {
    "text": "process to create an index you you to",
    "start": "316720",
    "end": "318039"
  },
  {
    "text": "load a train a a trained model this can",
    "start": "318039",
    "end": "321479"
  },
  {
    "text": "be either your own pre-train model or",
    "start": "321479",
    "end": "323120"
  },
  {
    "text": "one of our from The Hub um and this is",
    "start": "323120",
    "end": "325160"
  },
  {
    "text": "kind of the process we're doing right",
    "start": "325160",
    "end": "326240"
  },
  {
    "text": "now create index is just a few lines of",
    "start": "326240",
    "end": "328600"
  },
  {
    "text": "code and this is exactly what we're",
    "start": "328600",
    "end": "329759"
  },
  {
    "text": "doing um so this is the you know my",
    "start": "329759",
    "end": "332479"
  },
  {
    "text": "documents and this is the indexing step",
    "start": "332479",
    "end": "334680"
  },
  {
    "text": "that we just we just kind of walked",
    "start": "334680",
    "end": "336440"
  },
  {
    "text": "through and it looks like it's done um",
    "start": "336440",
    "end": "338720"
  },
  {
    "text": "so you get a bunch of logging here",
    "start": "338720",
    "end": "340400"
  },
  {
    "text": "that's fine um now let's actually see if",
    "start": "340400",
    "end": "342560"
  },
  {
    "text": "this works so we're going to run rag",
    "start": "342560",
    "end": "344440"
  },
  {
    "text": "search what an emotion Studio did Miaki",
    "start": "344440",
    "end": "347039"
  },
  {
    "text": "found set our K parameter and we get",
    "start": "347039",
    "end": "349919"
  },
  {
    "text": "some results okay so it's running and",
    "start": "349919",
    "end": "353319"
  },
  {
    "text": "cool we get some documents out so you",
    "start": "353319",
    "end": "355600"
  },
  {
    "text": "know it seems to work now what's nice is",
    "start": "355600",
    "end": "357800"
  },
  {
    "text": "you can run this within L chain as the L",
    "start": "357800",
    "end": "359280"
  },
  {
    "text": "chain retriever so that basically wraps",
    "start": "359280",
    "end": "361360"
  },
  {
    "text": "this as a l chain Retriever and then you",
    "start": "361360",
    "end": "363080"
  },
  {
    "text": "can use it freely as a retriever within",
    "start": "363080",
    "end": "365440"
  },
  {
    "text": "Lang chain it works with all the other",
    "start": "365440",
    "end": "366720"
  },
  {
    "text": "different LMS and all the other",
    "start": "366720",
    "end": "368120"
  },
  {
    "text": "components like rankers and so forth",
    "start": "368120",
    "end": "369800"
  },
  {
    "text": "that we talk through so you can use this",
    "start": "369800",
    "end": "371880"
  },
  {
    "text": "directly as a retriever let's try this",
    "start": "371880",
    "end": "374360"
  },
  {
    "text": "out and boom nice and fast um and we get",
    "start": "374360",
    "end": "378280"
  },
  {
    "text": "our documents again this is a super",
    "start": "378280",
    "end": "380039"
  },
  {
    "text": "simple test example you should run this",
    "start": "380039",
    "end": "382080"
  },
  {
    "text": "maybe on more complex cases but it's",
    "start": "382080",
    "end": "384039"
  },
  {
    "text": "pretty pretty easy spin up it's a really",
    "start": "384039",
    "end": "386039"
  },
  {
    "text": "interesting alternative indexing",
    "start": "386039",
    "end": "387479"
  },
  {
    "text": "approach um using again like we talked",
    "start": "387479",
    "end": "390080"
  },
  {
    "text": "through um a very different algorithm",
    "start": "390080",
    "end": "393639"
  },
  {
    "text": "for computing doc similarity that may",
    "start": "393639",
    "end": "395919"
  },
  {
    "text": "work better I think an interesting",
    "start": "395919",
    "end": "397360"
  },
  {
    "text": "regime to consider this would be longer",
    "start": "397360",
    "end": "399280"
  },
  {
    "text": "documents so if you want like longer um",
    "start": "399280",
    "end": "402880"
  },
  {
    "text": "yeah if if you basically want kind of",
    "start": "402880",
    "end": "404720"
  },
  {
    "text": "long context embedding I think you",
    "start": "404720",
    "end": "406599"
  },
  {
    "text": "should look into for example the uh Max",
    "start": "406599",
    "end": "410039"
  },
  {
    "text": "token limits for this approach because",
    "start": "410039",
    "end": "411720"
  },
  {
    "text": "it partitions the document into into",
    "start": "411720",
    "end": "414000"
  },
  {
    "text": "each token um I would be curious to dig",
    "start": "414000",
    "end": "416759"
  },
  {
    "text": "into kind of what the overall context",
    "start": "416759",
    "end": "418440"
  },
  {
    "text": "limits are for this roach of Co bear but",
    "start": "418440",
    "end": "421199"
  },
  {
    "text": "it's really interesting to consider and",
    "start": "421199",
    "end": "423160"
  },
  {
    "text": "it reports very strong performance so",
    "start": "423160",
    "end": "425120"
  },
  {
    "text": "again I encourage you to play with it",
    "start": "425120",
    "end": "426280"
  },
  {
    "text": "and this is just kind of an intro to how",
    "start": "426280",
    "end": "427680"
  },
  {
    "text": "to get set up and to start experimenting",
    "start": "427680",
    "end": "429520"
  },
  {
    "text": "with it really quickly",
    "start": "429520",
    "end": "431240"
  },
  {
    "text": "thanks",
    "start": "431240",
    "end": "434240"
  }
]
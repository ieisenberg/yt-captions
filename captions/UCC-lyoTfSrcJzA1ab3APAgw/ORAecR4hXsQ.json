[
  {
    "start": "0",
    "end": "36000"
  },
  {
    "text": "Will: Hi all, Will here.",
    "start": "0",
    "end": "1290"
  },
  {
    "text": "Let's build a MemGPT Discord\nagent together in LangGraph.",
    "start": "1600",
    "end": "4800"
  },
  {
    "text": "For those of you who haven't read it yet,\nMemGPT is a great paper by Packer et al.",
    "start": "5905",
    "end": "10075"
  },
  {
    "text": "out of this lab in Berkeley.",
    "start": "10105",
    "end": "11264"
  },
  {
    "text": "They show that you can  prompt\nan LLM to manage its own memory,",
    "start": "11875",
    "end": "15768"
  },
  {
    "text": "using function calling and tools.",
    "start": "15908",
    "end": "17628"
  },
  {
    "text": "The agent we are going to build\ntoday is inspired by MemGPT.",
    "start": "18603",
    "end": "22053"
  },
  {
    "text": "It will have both core memories and\nrecall, so semantic memories, and",
    "start": "22393",
    "end": "26923"
  },
  {
    "text": "will deploy it on LangGraph Cloud.",
    "start": "26923",
    "end": "28623"
  },
  {
    "text": "Finally, we're going to deploy a Discord\nserver so that we can interact with",
    "start": "28963",
    "end": "32412"
  },
  {
    "text": "it in Discord, and it can continue to\nlearn our preferences and personalities.",
    "start": "32413",
    "end": "36003"
  },
  {
    "start": "36000",
    "end": "79000"
  },
  {
    "text": "The agent that we'll create will\nhave a pretty simple workflow.",
    "start": "36933",
    "end": "40192"
  },
  {
    "text": "for each message it'll enter\nhere, will load memories for",
    "start": "40553",
    "end": "43693"
  },
  {
    "text": "that particular user based on ID.",
    "start": "43693",
    "end": "45503"
  },
  {
    "text": "The agent will then decide whether\nto use any tools in order to respond,",
    "start": "46073",
    "end": "50528"
  },
  {
    "text": "or in order to do saving memories.",
    "start": "51028",
    "end": "52978"
  },
  {
    "text": "Finally, it will generate the\nresponse message, which will",
    "start": "53178",
    "end": "55098"
  },
  {
    "text": "then be sent back to the user.",
    "start": "55098",
    "end": "56598"
  },
  {
    "text": "The load memories is able to fetch the\ncore memories from that user, as well",
    "start": "58123",
    "end": "62193"
  },
  {
    "text": "as semantic memories, which are ones\nthat are stored in a vector score.",
    "start": "62193",
    "end": "64673"
  },
  {
    "text": "The agent then can query more\nsemantic memories if we feel like",
    "start": "65513",
    "end": "69173"
  },
  {
    "text": "the ones that are queried weren't\nactually that relevant or useful.",
    "start": "69173",
    "end": "71613"
  },
  {
    "text": "It can use other tools that we\nprovided, such as a web search tool",
    "start": "71933",
    "end": "74643"
  },
  {
    "text": "to answer the user's questions,\nand it can also store and upsert",
    "start": "74703",
    "end": "78113"
  },
  {
    "text": "different types of memories there.",
    "start": "78143",
    "end": "79463"
  },
  {
    "start": "79000",
    "end": "125000"
  },
  {
    "text": "Before we get too far along,   to\nhave two basic prerequisites.",
    "start": "79463",
    "end": "82302"
  },
  {
    "text": "We're going to need a vector\nstore index for our recall memory.",
    "start": "83143",
    "end": "86183"
  },
  {
    "text": "We're going to use\nPinecone for this example.",
    "start": "86313",
    "end": "88063"
  },
  {
    "text": "So we'll go ahead and\ncreate an index here.",
    "start": "88603",
    "end": "90513"
  },
  {
    "text": "You can do that by logging in.",
    "start": "91013",
    "end": "92133"
  },
  {
    "text": "And then creating the index.",
    "start": "93643",
    "end": "95022"
  },
  {
    "text": "We'll set this as 768 dimensions for\nthe embedding distance, since we're",
    "start": "95333",
    "end": "99773"
  },
  {
    "text": "going to be using NOMIC embed text,\nwhich is similar to the BERT encoder",
    "start": "99773",
    "end": "103973"
  },
  {
    "text": "for the dimensionality of the output.",
    "start": "103973",
    "end": "106303"
  },
  {
    "text": "You can call a specific name.",
    "start": "106803",
    "end": "108023"
  },
  {
    "text": "And then you'll create it.",
    "start": "108023",
    "end": "108843"
  },
  {
    "text": "Once you create it, you want to\nmake sure that you copy over the",
    "start": "108863",
    "end": "111393"
  },
  {
    "text": "region, you copy over the actual\nname, and that you have access to",
    "start": "111393",
    "end": "116293"
  },
  {
    "text": "the API keys that you created here.",
    "start": "116373",
    "end": "117813"
  },
  {
    "text": "Next, we'll create our API\nkeys to connect to the LLM.",
    "start": "117813",
    "end": "120713"
  },
  {
    "text": "In this case, we're going to\nuse a LLAMA3 fine tuned model",
    "start": "120933",
    "end": "123763"
  },
  {
    "text": "fire function from Fireworks.",
    "start": "123813",
    "end": "125443"
  },
  {
    "start": "125000",
    "end": "137000"
  },
  {
    "text": "So with that prerequisite out of\nthe way, let's go and fork the repo.",
    "start": "125443",
    "end": "128563"
  },
  {
    "text": "We'll take that and then\nwe'll clone it locally.",
    "start": "129343",
    "end": "131033"
  },
  {
    "text": "And then once we've cloned\nit, we can pull it up here.",
    "start": "132103",
    "end": "134612"
  },
  {
    "text": "Here we have our repo structure.",
    "start": "134613",
    "end": "136033"
  },
  {
    "start": "137000",
    "end": "185000"
  },
  {
    "text": "If you're not familiar with LangGraph\ncloud yet, a typical LangGraph cloud",
    "start": "137213",
    "end": "140913"
  },
  {
    "text": "structure contains a configuration file,\nwhich defines the different types of",
    "start": "140913",
    "end": "145483"
  },
  {
    "text": "graphs that we're going to be exposing.",
    "start": "145493",
    "end": "147323"
  },
  {
    "text": "In this case, we just have this one memory\ngraph, which is the MemGPT implementation.",
    "start": "147543",
    "end": "151523"
  },
  {
    "text": "You can expose the environment variables\nthat you're going to be injecting in",
    "start": "152248",
    "end": "155088"
  },
  {
    "text": "it, and you also define dependencies.",
    "start": "155088",
    "end": "157528"
  },
  {
    "text": "By putting the local directory\nhere, this will infer the",
    "start": "157898",
    "end": "160568"
  },
  {
    "text": "dependencies from my pyproject.",
    "start": "160568",
    "end": "162168"
  },
  {
    "text": "toml file, which then is a classic\nPython way of packaging  projects.",
    "start": "162218",
    "end": "166598"
  },
  {
    "text": "Within here, you can see we've added\na bunch of different LLMs, so you can",
    "start": "167678",
    "end": "170508"
  },
  {
    "text": "swap out for OpenAI or Anthropic, all\nwithout having to change anything in code.",
    "start": "170508",
    "end": "174898"
  },
  {
    "text": "Next, we'll go over\nthis basic agent style.",
    "start": "175378",
    "end": "177988"
  },
  {
    "text": "We've got some constants and schemas.",
    "start": "178258",
    "end": "179678"
  },
  {
    "text": "These are just tiny things\nthat we'll go through.",
    "start": "179678",
    "end": "181437"
  },
  {
    "text": "The most important part that we\nwant to look at is this graph.",
    "start": "181768",
    "end": "184408"
  },
  {
    "text": "py file.",
    "start": "184478",
    "end": "185358"
  },
  {
    "start": "185000",
    "end": "435000"
  },
  {
    "text": "If you look at the overview for\nthe file, you can see we defined",
    "start": "185598",
    "end": "188428"
  },
  {
    "text": "these four different tools that\nare related to memory management.",
    "start": "188438",
    "end": "191398"
  },
  {
    "text": "We have save recall memory\nand store core memory.",
    "start": "191408",
    "end": "194428"
  },
  {
    "text": "These are the two ways that the agent is\nable to persist memories about the user.",
    "start": "194498",
    "end": "198528"
  },
  {
    "text": "We also have search and fetch core\nmemories, search queries semantically",
    "start": "199118",
    "end": "203258"
  },
  {
    "text": "over past save recall memories and fetch\ncore memories just returns all of the",
    "start": "203308",
    "end": "207938"
  },
  {
    "text": "core memories, which is just a list\nof strings for this particular user.",
    "start": "207938",
    "end": "211688"
  },
  {
    "text": "Now we've got the actual\ngraph definition below.",
    "start": "212888",
    "end": "215138"
  },
  {
    "text": "We'll go in more detail in a second.",
    "start": "215158",
    "end": "216608"
  },
  {
    "text": "We've got the agent node here.",
    "start": "216868",
    "end": "218078"
  },
  {
    "text": "This is just the LLM being prompted to\nbe responding or using tools in order to",
    "start": "218268",
    "end": "221958"
  },
  {
    "text": "respond and answer the user's questions.",
    "start": "221958",
    "end": "223758"
  },
  {
    "text": "We've got the load memories function\nhere, and this just takes the",
    "start": "224258",
    "end": "227758"
  },
  {
    "text": "user ID from our configuration.",
    "start": "227758",
    "end": "229358"
  },
  {
    "text": "So the bot doesn't get to choose\nwhat types of data access it has, and",
    "start": "229368",
    "end": "232938"
  },
  {
    "text": "it fetches those relevant memories.",
    "start": "232938",
    "end": "234878"
  },
  {
    "text": "Before the LLM even gets to see the input,\nwe have the route tools function, which is",
    "start": "235073",
    "end": "240353"
  },
  {
    "text": "routing, the messages to the tools node.",
    "start": "240363",
    "end": "242323"
  },
  {
    "text": "If the AI decides to be calling\nsome of those tools, otherwise",
    "start": "242333",
    "end": "246342"
  },
  {
    "text": "it'll respond to the user directly.",
    "start": "246353",
    "end": "248133"
  },
  {
    "text": "And then finally we have the\ntool node here, which we just",
    "start": "248643",
    "end": "251063"
  },
  {
    "text": "use with this prebuilt decorator.",
    "start": "251063",
    "end": "252393"
  },
  {
    "text": "This will invoke any tool that is\ncalled by the agent and that is",
    "start": "252463",
    "end": "256163"
  },
  {
    "text": "found within that suffix AI message.",
    "start": "256163",
    "end": "258492"
  },
  {
    "text": "Whenever the state enters the tools node.",
    "start": "258493",
    "end": "260733"
  },
  {
    "text": "For save recall memory,  we'll fetch the\nembeddings, we'll fetch the vector, or",
    "start": "260733",
    "end": "265233"
  },
  {
    "text": "actually generate the vector, and then\nwe'll add some metadata like the current",
    "start": "265293",
    "end": "268843"
  },
  {
    "text": "time so that you could be querying and\nfiltering based on that, and then we're",
    "start": "268853",
    "end": "272182"
  },
  {
    "text": "storing this all into the vector database.",
    "start": "272183",
    "end": "274453"
  },
  {
    "text": "The key thing here is we're\nlooking up based on a single",
    "start": "275323",
    "end": "278113"
  },
  {
    "text": "vector on this memory string.",
    "start": "278123",
    "end": "280093"
  },
  {
    "text": "You can look up in other ways if you want.",
    "start": "280753",
    "end": "283003"
  },
  {
    "text": "Next we define the searchMemory function.",
    "start": "283003",
    "end": "284703"
  },
  {
    "text": "This is a similar structure, so we're\ngoing to get the embeddings will",
    "start": "285668",
    "end": "288498"
  },
  {
    "text": "embed the query, and then we'll be\nlooking up based on similar memories.",
    "start": "288498",
    "end": "292688"
  },
  {
    "text": "You can see that we're passing in the\nuser ID in our configuration, and this",
    "start": "293008",
    "end": "296268"
  },
  {
    "text": "is always going to be configured based\non your front end in regular code,",
    "start": "296278",
    "end": "299968"
  },
  {
    "text": "and this filters to make sure that\nit's only able to fetch memories that",
    "start": "300388",
    "end": "303328"
  },
  {
    "text": "were saved for this particular query.",
    "start": "303338",
    "end": "304748"
  },
  {
    "text": "Signed in user or for the connecting user.",
    "start": "304828",
    "end": "306848"
  },
  {
    "text": "Next we have the type, so we're only\ngoing to be fetching what we recall.",
    "start": "307408",
    "end": "311087"
  },
  {
    "text": "And then we'll get those responses\nand return the strings of memories.",
    "start": "311368",
    "end": "314918"
  },
  {
    "text": "There we have the fetch core\nmemories, which is similar.",
    "start": "314918",
    "end": "317698"
  },
  {
    "text": "We're just going to do a direct get\noperation on the database there.",
    "start": "317718",
    "end": "320807"
  },
  {
    "text": "And then we have the store memories here.",
    "start": "321428",
    "end": "323558"
  },
  {
    "text": "This lets us actually save the memory.",
    "start": "323608",
    "end": "325458"
  },
  {
    "text": "And if the AI wants to, you can use\nit to overwrite an existing one.",
    "start": "325498",
    "end": "329288"
  },
  {
    "text": "For instance, if   I have a memory.",
    "start": "329548",
    "end": "331108"
  },
  {
    "text": "I've been chatting about how,\nOh, I really love Taylor Swift.",
    "start": "331448",
    "end": "334118"
  },
  {
    "text": "And then all of a sudden I decide,\nOh man, I'm a little bit tired of it.",
    "start": "334138",
    "end": "337178"
  },
  {
    "text": "They can update that.",
    "start": "337178",
    "end": "338638"
  },
  {
    "text": "It's maybe not a core memory, but things\nthat it might want to be, altering or",
    "start": "338648",
    "end": "342308"
  },
  {
    "text": "updating has that ability to do we'll\ndefine all the tools, and these will",
    "start": "342308",
    "end": "345558"
  },
  {
    "text": "be made available to the agent there.",
    "start": "345558",
    "end": "348028"
  },
  {
    "text": "We have the prompt, which I've\nadded to try to encourage it to use",
    "start": "348328",
    "end": "352338"
  },
  {
    "text": "these memory tools as readily as\npossible for the sake of this demo.",
    "start": "352618",
    "end": "356618"
  },
  {
    "text": "I always like to include the system\ntime so it has a little bit more context",
    "start": "356948",
    "end": "359828"
  },
  {
    "text": "and doesn't think that it's still\n2022 or wherever it was trained until.",
    "start": "359828",
    "end": "363938"
  },
  {
    "text": "And we're going to be templating in\nany memories here if they are fetched.",
    "start": "364608",
    "end": "368298"
  },
  {
    "text": "Now going back to the agent, we\nhave this init chat model based on",
    "start": "369593",
    "end": "373293"
  },
  {
    "text": "whatever the model that is configured\nhere the configuration we default",
    "start": "373293",
    "end": "377843"
  },
  {
    "text": "to this LLAMA3 fireworks model.",
    "start": "377853",
    "end": "380003"
  },
  {
    "text": "You can change it to SONNET or so Cloud\nSONNET or OpenAI or Gemini as well.",
    "start": "380033",
    "end": "385082"
  },
  {
    "text": "Next, we'll provide the tool schemas,\nwhich just is a way to define an",
    "start": "385703",
    "end": "389723"
  },
  {
    "text": "interface between the functions\nyou need to call and the agent.",
    "start": "389773",
    "end": "393343"
  },
  {
    "text": "In the end, we're just passing\nin JSON schemas to the LLM so",
    "start": "393983",
    "end": "398103"
  },
  {
    "text": "that it knows the format of the\noutput it's expected to generate.",
    "start": "398103",
    "end": "400973"
  },
  {
    "text": "If we have core memories or recall\nmemories that are already populated for",
    "start": "402163",
    "end": "406063"
  },
  {
    "text": "this user, we can populate it in here.",
    "start": "406063",
    "end": "408253"
  },
  {
    "text": "And then we'll finally generate\nthis prediction using the LLM  this",
    "start": "409273",
    "end": "413133"
  },
  {
    "text": "goes into our messages statement.",
    "start": "413153",
    "end": "414213"
  },
  {
    "text": "For load memories, basically this\nis the entry point of the graph.",
    "start": "414213",
    "end": "417273"
  },
  {
    "text": "We want to make sure that the LLM has\nall the contextual information it needs",
    "start": "417463",
    "end": "421363"
  },
  {
    "text": "before it has to make any decisions.",
    "start": "421403",
    "end": "423093"
  },
  {
    "text": "And so we're going to do this by\nrunning in the fetchCoreMemories",
    "start": "423133",
    "end": "427133"
  },
  {
    "text": "and the searchMemory functions here\nbefore it even gets to the LLM.",
    "start": "427133",
    "end": "429753"
  },
  {
    "text": "And then after that, the LLM is\nallowed to do other types of queries,",
    "start": "430363",
    "end": "432983"
  },
  {
    "text": "Now that we've gone over the\ngraph, it's time to deploy it.",
    "start": "433003",
    "end": "435522"
  },
  {
    "start": "435000",
    "end": "539000"
  },
  {
    "text": "We'll do so on LangGraph cloud.",
    "start": "435733",
    "end": "437053"
  },
  {
    "text": "So first navigate to LangSmith.",
    "start": "437323",
    "end": "438663"
  },
  {
    "text": "Click on deployments and\nthen press new deployment.",
    "start": "439093",
    "end": "441813"
  },
  {
    "text": "You'll want to add the LangGraph\ncloud installer to your account.",
    "start": "442613",
    "end": "446233"
  },
  {
    "text": "Once you've logged in to GitHub, you can\nselect to share all the repositories,",
    "start": "446733",
    "end": "451133"
  },
  {
    "text": "or you can select a select few.",
    "start": "451153",
    "end": "452743"
  },
  {
    "text": "I'm going to say LangMemGPT.",
    "start": "453363",
    "end": "454443"
  },
  {
    "text": "As a repo that I'm going to add.",
    "start": "456723",
    "end": "458063"
  },
  {
    "text": "And then hit save.",
    "start": "458528",
    "end": "459568"
  },
  {
    "text": "Once you've done this, it should\nshow up in the list of available",
    "start": "460438",
    "end": "463087"
  },
  {
    "text": "repositories you can deploy from.",
    "start": "463088",
    "end": "464648"
  },
  {
    "text": "I'm going to call this memgpt.",
    "start": "465118",
    "end": "467288"
  },
  {
    "text": "The configuration file in this\nrepo is at the root directory.",
    "start": "467988",
    "end": "471098"
  },
  {
    "text": "If you clone it and move it\nto a separate directory, you",
    "start": "471278",
    "end": "473468"
  },
  {
    "text": "can always add a path to it.",
    "start": "473468",
    "end": "474767"
  },
  {
    "text": "You can also pick a different reference,\na different branch deploy from.",
    "start": "475658",
    "end": "478852"
  },
  {
    "text": "LangGraph Cloud also allows you to\nselect a different deployment type.",
    "start": "478852",
    "end": "482012"
  },
  {
    "text": "We're just going to go\nwith development here.",
    "start": "482012",
    "end": "483412"
  },
  {
    "text": "Now, finally, it's time to\nadd the environment variables.",
    "start": "484822",
    "end": "487242"
  },
  {
    "text": "The key ones to add are\npine cone and fireworks.",
    "start": "487402",
    "end": "489952"
  },
  {
    "text": "You can create these in a env file\nand then copy paste that format into",
    "start": "490462",
    "end": "494412"
  },
  {
    "text": "the UI you'll also want to create\na Tavoli account, which I failed to",
    "start": "494412",
    "end": "498491"
  },
  {
    "text": "mention before, and this will provide\nthe search engine access if you want",
    "start": "498492",
    "end": "502862"
  },
  {
    "text": "your agent to be able to query the web.",
    "start": "502872",
    "end": "504692"
  },
  {
    "text": "Once you're done, hit submit.",
    "start": "504692",
    "end": "506482"
  },
  {
    "text": "LangGraph Cloud will start building your\nDocker image and then eventually deploy.",
    "start": "506482",
    "end": "510382"
  },
  {
    "text": "If you run into any issues, check the\nbuild logs here to see if there's any",
    "start": "510742",
    "end": "515702"
  },
  {
    "text": "errors that show up or the deploy logs.",
    "start": "515712",
    "end": "518821"
  },
  {
    "text": "Common issues include not having the\nenvironment variables set correctly",
    "start": "519132",
    "end": "523262"
  },
  {
    "text": "or forgetting to add different\ndependencies into your LangGraph project.",
    "start": "523282",
    "end": "526852"
  },
  {
    "text": "All right.",
    "start": "526852",
    "end": "527321"
  },
  {
    "text": "So if everything worked correctly,\nafter three to four minutes, you",
    "start": "527862",
    "end": "531022"
  },
  {
    "text": "should have a new deployment already.",
    "start": "531022",
    "end": "532931"
  },
  {
    "text": "You can head to the playground\nin order to try interacting",
    "start": "534082",
    "end": "537272"
  },
  {
    "text": "with it directly in the UI.",
    "start": "537272",
    "end": "538792"
  },
  {
    "start": "539000",
    "end": "587000"
  },
  {
    "text": "The LangGraph Cloud Studio is a great\nplace to be able to debug and deeply",
    "start": "539342",
    "end": "544011"
  },
  {
    "text": "visualize how your graph or agent is\noperating on different types of inputs.",
    "start": "544022",
    "end": "547782"
  },
  {
    "text": "If you recall from the code review,\nwe have a few different configurations",
    "start": "548332",
    "end": "551722"
  },
  {
    "text": "we can make for this graph.",
    "start": "551762",
    "end": "553362"
  },
  {
    "text": "For instance, you can choose a\nmodel, you can choose a thread, and",
    "start": "553672",
    "end": "556891"
  },
  {
    "text": "you can also add the user ID here.",
    "start": "556892",
    "end": "558532"
  },
  {
    "text": "So for user ID here, we'll\nsay my user three and then we",
    "start": "558662",
    "end": "563576"
  },
  {
    "text": "can try adding some messages.",
    "start": "563577",
    "end": "565027"
  },
  {
    "text": "So for instance, today I had\npie and then you can see here",
    "start": "565037",
    "end": "571196"
  },
  {
    "text": "how the agent is going through.",
    "start": "571207",
    "end": "572386"
  },
  {
    "text": "So you can see it first tried to\nload memories from me and then it",
    "start": "572687",
    "end": "575627"
  },
  {
    "text": "tries to go in and call the agent.",
    "start": "575637",
    "end": "577217"
  },
  {
    "text": "The agent decides this isn't a\nparticularly important message and",
    "start": "577217",
    "end": "580066"
  },
  {
    "text": "then it actually gets sent back.",
    "start": "580067",
    "end": "581217"
  },
  {
    "text": "This is a nice UI if you're\ntrying to be developing it, but",
    "start": "581437",
    "end": "584017"
  },
  {
    "text": "this isn't something you're going\nto be exposing to the end user.",
    "start": "584027",
    "end": "586436"
  },
  {
    "start": "587000",
    "end": "631000"
  },
  {
    "text": "In phase two, let's try deploying a\nDiscord server so we can connect to it.",
    "start": "587267",
    "end": "590877"
  },
  {
    "text": "If we jump back to our code base,\nif you remember, we have the basic",
    "start": "590877",
    "end": "594337"
  },
  {
    "text": "graph structure here, we have the\nhigh level ones, we also have this",
    "start": "594347",
    "end": "597277"
  },
  {
    "text": "events server that we have saved\nin the repository that you cloned.",
    "start": "597277",
    "end": "600376"
  },
  {
    "text": "Within this, we have some\ninformation and files that are",
    "start": "601372",
    "end": "604412"
  },
  {
    "text": "needed in order to be deploying a\nDiscord bot to Cloud Run, actually.",
    "start": "604412",
    "end": "608022"
  },
  {
    "text": "So the main file here just\ndefines the Discord bot.",
    "start": "608282",
    "end": "611501"
  },
  {
    "text": "It has a couple of events.",
    "start": "611502",
    "end": "612452"
  },
  {
    "text": "It has this assistant ID helper,\nand it has a message handler.",
    "start": "612962",
    "end": "616681"
  },
  {
    "text": "So anytime a Discord message comes\nin, we'll be passing this to our agent",
    "start": "616897",
    "end": "621016"
  },
  {
    "text": "that we just deployed on LangGraph, and\nthen immediately respond with whatever",
    "start": "621017",
    "end": "624697"
  },
  {
    "text": "it's going to be responding in Discord.",
    "start": "624697",
    "end": "626367"
  },
  {
    "text": "And this just allows it to be\nforwarding these types of things through",
    "start": "626787",
    "end": "629407"
  },
  {
    "text": "WebSocket, like what Discord expects.",
    "start": "629417",
    "end": "631507"
  },
  {
    "start": "631000",
    "end": "739000"
  },
  {
    "text": "To deploy to Google Cloud Run, you'll\nhave to create an account here.",
    "start": "631507",
    "end": "634357"
  },
  {
    "text": "You'll have to install the\nGoogle Cloud SDK, and we're also",
    "start": "634407",
    "end": "637066"
  },
  {
    "text": "using the G cloud command line.",
    "start": "637127",
    "end": "638867"
  },
  {
    "text": "So you want to install that you\nhave to create a discord developer",
    "start": "638897",
    "end": "642457"
  },
  {
    "text": "account and you have to make\nsure Docker is installed as well.",
    "start": "642457",
    "end": "645097"
  },
  {
    "text": "Then next.",
    "start": "645507",
    "end": "646477"
  },
  {
    "text": "We need to set up a discord bot.",
    "start": "646497",
    "end": "647717"
  },
  {
    "text": "You can do that by navigating\nto this developer's portal here.",
    "start": "647757",
    "end": "650497"
  },
  {
    "text": "We'll log in",
    "start": "651017",
    "end": "651817"
  },
  {
    "text": "and then we can create a discord bot.",
    "start": "651817",
    "end": "653467"
  },
  {
    "text": "So we'll call this my memory bot.",
    "start": "653767",
    "end": "656547"
  },
  {
    "text": "Once you have this, we'll go into\nthe bot section and we'll reset the",
    "start": "656867",
    "end": "664117"
  },
  {
    "text": "token in order to get our bot token.",
    "start": "664117",
    "end": "665857"
  },
  {
    "text": "And then you can get this\ntoken here to copy over.",
    "start": "667287",
    "end": "669627"
  },
  {
    "text": "You can save this in a env file here",
    "start": "669627",
    "end": "672327"
  },
  {
    "text": "That we're going to be putting\nin this event server so",
    "start": "672737",
    "end": "675762"
  },
  {
    "text": "you've got the discord token.",
    "start": "675762",
    "end": "677942"
  },
  {
    "text": "The public key actually isn't\nimportant and the assistant URL.",
    "start": "678172",
    "end": "682362"
  },
  {
    "text": "We can populate from that deployment\nthat we just made over in  you have",
    "start": "682382",
    "end": "685722"
  },
  {
    "text": "this deployment, it's this API URL\nhere, so you can copy that over.",
    "start": "685722",
    "end": "690222"
  },
  {
    "text": "Once you've copied your token\nlocally, you can customize your bot.",
    "start": "690222",
    "end": "693482"
  },
  {
    "text": "However you want, you can\ngive it a new username.",
    "start": "693492",
    "end": "695602"
  },
  {
    "text": "You can change the banner,\nyou can add icons and stuff.",
    "start": "695612",
    "end": "698046"
  },
  {
    "text": "Then.You're going to want to navigate\nto the bot section and you need",
    "start": "698946",
    "end": "702402"
  },
  {
    "text": "to give it message content intent.",
    "start": "702413",
    "end": "704643"
  },
  {
    "text": "Otherwise it won't be\nable to read any messages.",
    "start": "704703",
    "end": "706633"
  },
  {
    "text": "So let's turn that on and hit save changes\nto make sure we commit those changes.",
    "start": "706643",
    "end": "710653"
  },
  {
    "text": "Next up, we're going to go to installation\nbecause we do want to install the bot.",
    "start": "711713",
    "end": "715203"
  },
  {
    "text": "Eventually we're going to be installing\nit with this link, but first we",
    "start": "715743",
    "end": "718133"
  },
  {
    "text": "need to make sure that for the Guild\ninstall here we add this bot option.",
    "start": "718133",
    "end": "721593"
  },
  {
    "text": "So I'll put that back in.",
    "start": "722433",
    "end": "723703"
  },
  {
    "text": "You can just type in bot and make sure\nthat you save those changes again.",
    "start": "723703",
    "end": "726963"
  },
  {
    "text": "Finally, you're going to copy this\nlink and go over to it in order",
    "start": "728463",
    "end": "732713"
  },
  {
    "text": "to install it to your server.",
    "start": "732713",
    "end": "734263"
  },
  {
    "text": "I'm adding it to the cool memorable\nserver here and authorize.",
    "start": "734613",
    "end": "737662"
  },
  {
    "start": "739000",
    "end": "854000"
  },
  {
    "text": ". \nWill: Assuming that you installed your bot\ncorrectly with the correct permissions,",
    "start": "739743",
    "end": "743342"
  },
  {
    "text": "including the bot permissions, you\nshould see it show up as an ability to at",
    "start": "743353",
    "end": "747803"
  },
  {
    "text": "mention the bot and you can say, hello.",
    "start": "747843",
    "end": "749863"
  },
  {
    "text": "Hi there.",
    "start": "750673",
    "end": "751142"
  },
  {
    "text": "How are you?",
    "start": "751433",
    "end": "752183"
  },
  {
    "text": "The Discord server itself\ncreates a new thread and then",
    "start": "753183",
    "end": "756363"
  },
  {
    "text": "sends a message to the agent.",
    "start": "756363",
    "end": "757923"
  },
  {
    "text": "the agent will then respond with\nwhatever information it has.",
    "start": "758343",
    "end": "760983"
  },
  {
    "text": "It's great to see you here.",
    "start": "761403",
    "end": "762363"
  },
  {
    "text": "We'll do the hello, alert, hello\nworld of Lang Chain and see",
    "start": "763363",
    "end": "766063"
  },
  {
    "text": "if it can check the weather.",
    "start": "766063",
    "end": "767023"
  },
  {
    "text": "Like in sf,",
    "start": "767028",
    "end": "767593"
  },
  {
    "text": "great, so it has the date correct,\nand it also has information there.",
    "start": "768803",
    "end": "772753"
  },
  {
    "text": "And then I can say, oh, I'm planning\na 4th of July trip to Sacramento.",
    "start": "773513",
    "end": "781693"
  },
  {
    "text": "Got any advice?",
    "start": "783683",
    "end": "785032"
  },
  {
    "text": "And you see it continues the\nconversation based on the discord thread.",
    "start": "786108",
    "end": "789077"
  },
  {
    "text": "This is all happening because we're\naligning the discord threads with",
    "start": "789588",
    "end": "792698"
  },
  {
    "text": "the threads that we actually track\nin LangGraph, so it has the full",
    "start": "792698",
    "end": "795798"
  },
  {
    "text": "conversation history that's short term.",
    "start": "795798",
    "end": "797858"
  },
  {
    "text": "The bot's also able to actually store\nsome of this  long term information, so",
    "start": "798298",
    "end": "801738"
  },
  {
    "text": "that it has information across threads.",
    "start": "801738",
    "end": "803448"
  },
  {
    "text": "We'll see that in a moment here.",
    "start": "803838",
    "end": "804938"
  },
  {
    "text": "We'll see if it can remember\nit in a new thread here.",
    "start": "804938",
    "end": "806858"
  },
  {
    "text": "Hi there.",
    "start": "807973",
    "end": "808453"
  },
  {
    "text": "I'm doing some planning.",
    "start": "809673",
    "end": "811392"
  },
  {
    "text": "I'm taking a trip to Sacramento",
    "start": "812103",
    "end": "815993"
  },
  {
    "text": "guess what?",
    "start": "816818",
    "end": "817658"
  },
  {
    "text": "It's for the 4th!",
    "start": "817658",
    "end": "818488"
  },
  {
    "text": "So it's generating some\nrecommendations here.",
    "start": "818488",
    "end": "820618"
  },
  {
    "text": "And we'll see if it's able to\nactually remember this type of",
    "start": "820958",
    "end": "822798"
  },
  {
    "text": "information in the next thread.",
    "start": "822798",
    "end": "824287"
  },
  {
    "text": "We'll start a new conversation\nthread and share some information.",
    "start": "824298",
    "end": "826918"
  },
  {
    "text": "I'll say, I like swimming.",
    "start": "827068",
    "end": "828248"
  },
  {
    "text": "And then we'll start another one and\nsee if it can remember from that.",
    "start": "829248",
    "end": "831467"
  },
  {
    "text": "So it looks like it doesn't remember\nthat I'd mentioned swimming.",
    "start": "831468",
    "end": "834038"
  },
  {
    "text": "This is all because I said, I\nlike swimming and this seems like",
    "start": "834628",
    "end": "837597"
  },
  {
    "text": "it's pretty salient things to\nremember about my core memories.",
    "start": "837598",
    "end": "840198"
  },
  {
    "text": "And it also is remembering that I'm\nplanning a trip for Sacramento and",
    "start": "840568",
    "end": "843977"
  },
  {
    "text": "4th of July year 2024, because we're\ntimestamping everything and it's",
    "start": "843978",
    "end": "847228"
  },
  {
    "text": "including that information here.",
    "start": "847228",
    "end": "848438"
  },
  {
    "text": "So cool.",
    "start": "848798",
    "end": "849358"
  },
  {
    "text": "It's able to actually do this.",
    "start": "849378",
    "end": "850368"
  },
  {
    "text": "Now that we've got this running on a\ndebug server, let's actually deploy it.",
    "start": "850788",
    "end": "853388"
  },
  {
    "start": "854000",
    "end": "912000"
  },
  {
    "text": "We'll go through this step by step.",
    "start": "854128",
    "end": "855018"
  },
  {
    "text": "We've already cloned it.",
    "start": "855018",
    "end": "855798"
  },
  {
    "text": "We've set it up.",
    "start": "855898",
    "end": "856488"
  },
  {
    "text": "We've debugged it.",
    "start": "856488",
    "end": "857308"
  },
  {
    "text": "Now it's time to set up\nthe Google Cloud project.",
    "start": "857308",
    "end": "859688"
  },
  {
    "text": "You can create a new one in Google\nCloud, or you can use an existing one.",
    "start": "860328",
    "end": "864078"
  },
  {
    "text": "In my case, I'm going to\nuse an existing one here.",
    "start": "864108",
    "end": "866477"
  },
  {
    "text": "So I'll say Product ID is this.",
    "start": "866798",
    "end": "869037"
  },
  {
    "text": "Then I'll enable the necessary APIs.",
    "start": "869038",
    "end": "871058"
  },
  {
    "text": "And this is successful.",
    "start": "872143",
    "end": "873543"
  },
  {
    "text": "After that, I need to set up permissions\nfor the cloud build services.",
    "start": "874283",
    "end": "878033"
  },
  {
    "text": "This creates an IAM policy that'll be\nable to  build the Docker image and",
    "start": "878033",
    "end": "881683"
  },
  {
    "text": "then deploy the Cloud Run instance.",
    "start": "881683",
    "end": "883222"
  },
  {
    "text": "I'm going to say no conditions here.",
    "start": "883223",
    "end": "884673"
  },
  {
    "text": "To create it, and then\nit'll create it there.",
    "start": "885393",
    "end": "887133"
  },
  {
    "text": "Once that's done, I'll run this\nscript for the deploy server.",
    "start": "887673",
    "end": "890883"
  },
  {
    "text": "And it should be up and running.",
    "start": "891933",
    "end": "893652"
  },
  {
    "text": "Once you have it up and running,\nyou'll have a cloud run instance.",
    "start": "893653",
    "end": "896593"
  },
  {
    "text": "You can check the logs to make sure\nthat it's all running correctly.",
    "start": "896643",
    "end": "898943"
  },
  {
    "text": "You'll have configuration here with the\nenvironment variables that are needed to",
    "start": "899533",
    "end": "902843"
  },
  {
    "text": "be connected to your line graph instance.",
    "start": "902843",
    "end": "904363"
  },
  {
    "text": "And you'll have everything set up for\nyour Discord bot to be communicating",
    "start": "904633",
    "end": "907973"
  },
  {
    "text": "with anyone on Discord and relearning\nabout all the different users.",
    "start": "907973",
    "end": "912383"
  },
  {
    "start": "912000",
    "end": "1034000"
  },
  {
    "text": "For section 3 of this video, I\nwanted to briefly touch on evaluating",
    "start": "912943",
    "end": "916393"
  },
  {
    "text": "or testing this type of agent.",
    "start": "916393",
    "end": "917863"
  },
  {
    "text": "Testing can be hard, and getting it right\ncan be a little bit overwhelming at times.",
    "start": "918458",
    "end": "922178"
  },
  {
    "text": "I'm a fan of being pragmatic, adding\ntests where necessary, adding them",
    "start": "922518",
    "end": "926148"
  },
  {
    "text": "as quickly as possible, even if it's\nsimplistic assertions that catch the base",
    "start": "926148",
    "end": "930238"
  },
  {
    "text": "fundamentals, it's better than nothing.",
    "start": "930238",
    "end": "932258"
  },
  {
    "text": "And using a tool like Langsmith can\nhelp you at least debug and find the",
    "start": "932678",
    "end": "936157"
  },
  {
    "text": "root cause of what goes wrong whenever\none of these tests do fail in CI.",
    "start": "936158",
    "end": "939868"
  },
  {
    "text": "I made an example test file here, called\ntest memories, that we can use to just go",
    "start": "939868",
    "end": "945708"
  },
  {
    "text": "through a couple different conversations.",
    "start": "945708",
    "end": "947458"
  },
  {
    "text": "And see what actually gets stored.",
    "start": "947768",
    "end": "949378"
  },
  {
    "text": "I'm using the Langsmith test\ndecorator here, which syncs this",
    "start": "949878",
    "end": "953097"
  },
  {
    "text": "to a data set in Langsmith so that\nyou can be comparing different",
    "start": "953098",
    "end": "956158"
  },
  {
    "text": "versions of your system over time.",
    "start": "956158",
    "end": "957598"
  },
  {
    "text": "It iterates over the examples.",
    "start": "958848",
    "end": "960258"
  },
  {
    "text": "It has some existing memories, for\ninstance, to see how that influences",
    "start": "960308",
    "end": "963578"
  },
  {
    "text": "the types of responses that are saved.",
    "start": "963578",
    "end": "966658"
  },
  {
    "text": "And then it has the number of\nexpected memories at least that",
    "start": "966988",
    "end": "971118"
  },
  {
    "text": "will be extracted from this.",
    "start": "971118",
    "end": "972428"
  },
  {
    "text": ". You have to be mocking different\nthings, perhaps because you don't want",
    "start": "972478",
    "end": "975558"
  },
  {
    "text": "to be touching your actual production\ndatabase whenever you're running",
    "start": "975558",
    "end": "978482"
  },
  {
    "text": "evals, just like any software test.",
    "start": "978482",
    "end": "980322"
  },
  {
    "text": "And then you can be doing\nstraight up relatively simple",
    "start": "980322",
    "end": "983973"
  },
  {
    "text": "assertions here if you want.",
    "start": "983973",
    "end": "985143"
  },
  {
    "text": "Similarly here, we're testing for the\ndifferent types of recall memories that",
    "start": "986653",
    "end": "989783"
  },
  {
    "text": "are going to be saved there as well.",
    "start": "989783",
    "end": "990943"
  },
  {
    "text": "I'll go ahead and run this.",
    "start": "992118",
    "end": "993358"
  },
  {
    "text": "I'm also going to be using the test cache\nhere, which will be caching some of the",
    "start": "993908",
    "end": "997428"
  },
  {
    "text": "requests, the API requests locally, to be\na little bit faster in future iterations.",
    "start": "997428",
    "end": "1001717"
  },
  {
    "text": "And it'll just be running\nthis, just with regular PyTest.",
    "start": "1002208",
    "end": "1004728"
  },
  {
    "text": "If I go to the data sets here, I'll see\nthat I'm evaluating these test memories.",
    "start": "1004728",
    "end": "1007998"
  },
  {
    "text": "And you can see I ran\nthis a few times before.",
    "start": "1008378",
    "end": "1010798"
  },
  {
    "text": "I had some bugs that I fixed\nthat caused it to fail the tests.",
    "start": "1010808",
    "end": "1013328"
  },
  {
    "text": "And then you can see the outputs\nhere of what was upserted",
    "start": "1013648",
    "end": "1016068"
  },
  {
    "text": "and those types of things.",
    "start": "1016068",
    "end": "1016977"
  },
  {
    "text": "If anything were to go wrong,\nyou can then click in and debug",
    "start": "1017328",
    "end": "1020618"
  },
  {
    "text": "the entire trace of operations.",
    "start": "1020618",
    "end": "1022178"
  },
  {
    "text": "You can see the LLM test.",
    "start": "1022178",
    "end": "1023287"
  },
  {
    "text": "You can open it in a\nplayground, debug things.",
    "start": "1023683",
    "end": "1025593"
  },
  {
    "text": "You have that full auditability here while\nalso being able to have very pragmatic",
    "start": "1025743",
    "end": "1030113"
  },
  {
    "text": "metrics and checks running in CI, just\nas you're familiar with any software.",
    "start": "1030153",
    "end": "1033522"
  },
  {
    "start": "1034000",
    "end": "1069000"
  },
  {
    "text": "So that's all for today.",
    "start": "1034353",
    "end": "1035273"
  },
  {
    "text": "In this video, we created a MemGPT like\nagent in LangGraph cloud, deployed it,",
    "start": "1035583",
    "end": "1040573"
  },
  {
    "text": "deployed a discord server and showed\nhow we were able to interact with it",
    "start": "1040703",
    "end": "1043963"
  },
  {
    "text": "in discord or using the studio UI to be\nable to see the exact types of things",
    "start": "1043963",
    "end": "1049073"
  },
  {
    "text": "that are going to be saved and see how\nthat then translates to memory over time.",
    "start": "1049073",
    "end": "1052963"
  },
  {
    "text": "Multiple conversations.",
    "start": "1053278",
    "end": "1054418"
  },
  {
    "text": "If you have any requests or other\nfeedback, leave it in the YouTube comments",
    "start": "1054808",
    "end": "1057888"
  },
  {
    "text": "below I'd encourage you to go and fork\nthe original repo here and try and build",
    "start": "1057888",
    "end": "1061857"
  },
  {
    "text": "it yourself and don't forget to check\nin later for more content like this.",
    "start": "1061858",
    "end": "1065578"
  },
  {
    "text": "Thank you.",
    "start": "1065988",
    "end": "1066308"
  },
  {
    "text": "And goodbye.",
    "start": "1066308",
    "end": "1066818"
  }
]
[
  {
    "text": "we've got um a an awesome agenda today we're gonna be talking about open AI functions we've",
    "start": "299",
    "end": "6299"
  },
  {
    "text": "released uh I guess it was released basically a little bit over a week ago um so very very recent excited to be",
    "start": "6299",
    "end": "13500"
  },
  {
    "text": "joined uh currently by Francisco and Jason both been doing a bunch of awesome stuff on uh in link chain on Twitter in",
    "start": "13500",
    "end": "20820"
  },
  {
    "text": "general um we will also be uh joined momentarily by uh Aki from openai as soon as I",
    "start": "20820",
    "end": "29099"
  },
  {
    "text": "invite him to the stage and I think uh we'll we'll kick things off",
    "start": "29099",
    "end": "34920"
  },
  {
    "text": "um well okay so minor Logistics we are recording um and so it will be accessible on the",
    "start": "34920",
    "end": "40500"
  },
  {
    "text": "the link here afterwards um and then uh we'll we'll probably also post it on on YouTube afterwards",
    "start": "40500",
    "end": "48300"
  },
  {
    "text": "um what we'll basically do is We'll have each of the speakers talk for",
    "start": "48300",
    "end": "54180"
  },
  {
    "text": "um a few minutes about an overview of what they worked on so uh",
    "start": "54180",
    "end": "61140"
  },
  {
    "text": "Papi from openai will talk in general about the the uh the functions endpoint",
    "start": "61140",
    "end": "67080"
  },
  {
    "text": "and kind of set the stage for for everything that we'll talk about later then we'll we'll have Francisco talk",
    "start": "67080",
    "end": "73020"
  },
  {
    "text": "about um some of his uh work that that he's been doing then we'll go to over to",
    "start": "73020",
    "end": "78240"
  },
  {
    "text": "Jason and then we'll we'll uh finish up with David from activeloop who I will",
    "start": "78240",
    "end": "83520"
  },
  {
    "text": "add to the stage momentarily as well then basically what we'll do is we'll go into question answer so you know there's",
    "start": "83520",
    "end": "89220"
  },
  {
    "text": "a lot to discuss there's a lot to explore we really want like I think part of the excitement here is it's just so",
    "start": "89220",
    "end": "95460"
  },
  {
    "text": "new and there's so many different use cases so um if you do have questions please put them in the little question box on the",
    "start": "95460",
    "end": "101820"
  },
  {
    "text": "right um it's the Q a box it's under the chat it's got the question mark on it you can also upload other ones so basically",
    "start": "101820",
    "end": "108900"
  },
  {
    "text": "um you know after about 30 40 minutes we'll just start going through the the user questions and answering the the top",
    "start": "108900",
    "end": "115259"
  },
  {
    "text": "ones um can be anything about the the functions endpoint itself we were lucky",
    "start": "115259",
    "end": "120420"
  },
  {
    "text": "to have someone from open AI who can answer that can be anything about the use cases that you've seen Jason or Francisco or David tweeting about on",
    "start": "120420",
    "end": "127020"
  },
  {
    "text": "Twitter um so yeah should be should be a really fun one um so thanks again everyone for joining",
    "start": "127020",
    "end": "133920"
  },
  {
    "text": "us thank you to all the the panelists or panelists sounds really formal so but uh",
    "start": "133920",
    "end": "140520"
  },
  {
    "text": "thank you for you guys for joining and maybe we can kick things off with uh uh",
    "start": "140520",
    "end": "146040"
  },
  {
    "text": "actually before we do that maybe quick introductions from everyone just to set the stage for for",
    "start": "146040",
    "end": "151620"
  },
  {
    "text": "um yeah uh Francisco do you want to start yeah sure so hi there my name is",
    "start": "151620",
    "end": "159060"
  },
  {
    "text": "Francisco I am a data scientist I'm based in Argentina I worked for several",
    "start": "159060",
    "end": "164640"
  },
  {
    "text": "years in a big e-commerce company here in Argentina like Amazon from Latin",
    "start": "164640",
    "end": "170819"
  },
  {
    "text": "America and I am really really fascinated with llms and the things that are being made",
    "start": "170819",
    "end": "176760"
  },
  {
    "text": "possible I've been building the LMS and and contributing a bit to launching as well for for the past few months and",
    "start": "176760",
    "end": "183599"
  },
  {
    "text": "recently I've been involved in in using functions for tagging and extraction so",
    "start": "183599",
    "end": "189420"
  },
  {
    "text": "that's what what I'm being what I'm playing with right now foreign",
    "start": "189420",
    "end": "194640"
  },
  {
    "text": "Jason do you want to do a quick intro cool yeah so uh I'm Jason uh I spent the",
    "start": "194640",
    "end": "200580"
  },
  {
    "text": "past like maybe eight ten years doing things in the machine learning around computer vision and recommendation systems and I almost neglected natural",
    "start": "200580",
    "end": "208379"
  },
  {
    "text": "language processing because I thought it was kind of like a boring subject and uh coming back to I kind of regret doing",
    "start": "208379",
    "end": "213840"
  },
  {
    "text": "that and now I think language models are sort of like the coolest thing out there so I remember",
    "start": "213840",
    "end": "219659"
  },
  {
    "text": "playing with ubd2 thinking it was cool and going back to my actual work and now do before I'm kind of like asking nicely",
    "start": "219659",
    "end": "227580"
  },
  {
    "text": "saying please and doing everything I can to get the answer out so it's been a fun ride",
    "start": "227580",
    "end": "233540"
  },
  {
    "text": "all right do you want to go sure hi everyone my name is acne I'm an",
    "start": "233879",
    "end": "239700"
  },
  {
    "text": "engineer at open AI I helped build chat completions and function calling uh and",
    "start": "239700",
    "end": "245640"
  },
  {
    "text": "it's uh crazy to see more than a thousand people here so I'm very excited to share share more today",
    "start": "245640",
    "end": "253640"
  },
  {
    "text": "and David hi everyone sorry for running a bit late my name is David I'm the founder of",
    "start": "253860",
    "end": "259500"
  },
  {
    "text": "active up before starting the company was doing a PhD at Princeton University uh mostly was in computer vision space",
    "start": "259500",
    "end": "265320"
  },
  {
    "text": "but we had some projects actually building social Bots and super excited for the last five years what happened to",
    "start": "265320",
    "end": "270600"
  },
  {
    "text": "the NLP and Hall um large language model industry I'll say now I'm super excited",
    "start": "270600",
    "end": "275699"
  },
  {
    "text": "for this talk and talk about the open air functions foreign so let's just jump",
    "start": "275699",
    "end": "280979"
  },
  {
    "text": "right into it so coffee take it away yeah uh well I didn't prepare any slides",
    "start": "280979",
    "end": "287100"
  },
  {
    "text": "or anything because I think most of you have sort of played around with the product and and built some amazing things and had them on Twitter",
    "start": "287100",
    "end": "294000"
  },
  {
    "text": "um so I'll just give you a little bit of a background and let's play maybe about how this came to be where we think this is going and and why I'm personally",
    "start": "294000",
    "end": "300720"
  },
  {
    "text": "excited about all this um you know language models sort of came to shore maybe three four years ago GPT",
    "start": "300720",
    "end": "307320"
  },
  {
    "text": "one to uh three started to social show some signs of life last year uh in the",
    "start": "307320",
    "end": "313080"
  },
  {
    "text": "early use cases we're sort of using it for Content generation right like right via an email right me an essay things",
    "start": "313080",
    "end": "318419"
  },
  {
    "text": "like that and a couple of businesses sort of took off from there um 3.5 came out sort of late last year",
    "start": "318419",
    "end": "325199"
  },
  {
    "text": "early this year uh and that's ones are the more application Level Integrations really seemed possible you could",
    "start": "325199",
    "end": "330900"
  },
  {
    "text": "actually build natural language interfaces to your products charge GPT of course is sort of the general purpose",
    "start": "330900",
    "end": "337800"
  },
  {
    "text": "interface for natural language ask it anything get it done get anything done uh is sort of the promise of chat GPT",
    "start": "337800",
    "end": "343500"
  },
  {
    "text": "but what's really exciting about the API and developers building on top of it is that you can bring this power to any",
    "start": "343500",
    "end": "349979"
  },
  {
    "text": "other application four of course is sort of like you know way more intelligent a little bit slower uh and uh but the",
    "start": "349979",
    "end": "358560"
  },
  {
    "text": "beauty of both 3.5 and 4 is that they were trained on this format called chat ml um and chatroom now basically breaks",
    "start": "358560",
    "end": "365520"
  },
  {
    "text": "down the language model output input and output into these like turn-by-turn conversations where there's a system",
    "start": "365520",
    "end": "371580"
  },
  {
    "text": "message that describes instructions to the model user messages model messages and you can imagine adding more roles to",
    "start": "371580",
    "end": "379199"
  },
  {
    "text": "this conversation and that's why this role of sort of functions came out as well we've always been here at open AI",
    "start": "379199",
    "end": "384900"
  },
  {
    "text": "interested in tool use as a concept how do you connect language models safely to the outside world whether it's you know",
    "start": "384900",
    "end": "390900"
  },
  {
    "text": "send me an email or you know buy me some food or do my taxes for me",
    "start": "390900",
    "end": "396780"
  },
  {
    "text": "um and the early Explorations here were very much like you know what if we did",
    "start": "396780",
    "end": "401880"
  },
  {
    "text": "make this one tool let's see how well it works and then what if you made this other tool and how well that works and",
    "start": "401880",
    "end": "407039"
  },
  {
    "text": "the early interface between the language model and these tools was also just plain text and so the first two tools",
    "start": "407039",
    "end": "413039"
  },
  {
    "text": "that we built actually are now in production core interpreter and browsing with Bing and they're both sort of under",
    "start": "413039",
    "end": "419220"
  },
  {
    "text": "the hood actually just using very simple interfaces to um you know very similar to all the tools and plugins that you guys might",
    "start": "419220",
    "end": "425520"
  },
  {
    "text": "have built using libraries like line chain um but then as we move towards plugins",
    "start": "425520",
    "end": "430620"
  },
  {
    "text": "earlier this year and we decided you know what if we could generalize this what if anybody could build with the",
    "start": "430620",
    "end": "435960"
  },
  {
    "text": "least effort possible something that plugs into a language model that's when we came up with the idea of this sort of",
    "start": "435960",
    "end": "441300"
  },
  {
    "text": "open API based interface um but open API schemas are like quite",
    "start": "441300",
    "end": "446580"
  },
  {
    "text": "purpose and they get very long um and we actually generalized it like hey today we might use open API but",
    "start": "446580",
    "end": "452400"
  },
  {
    "text": "tomorrow we might just graphql or some other like you know RPC language you might even want to call tools that are",
    "start": "452400",
    "end": "458220"
  },
  {
    "text": "local to the client like I don't know if you're building an IOS app and at some point you want the language model to decide to take a photo or to vibrate the",
    "start": "458220",
    "end": "465360"
  },
  {
    "text": "phone that stuff doesn't even go over HTTP so all of these kind of tool Integrations when generalized become",
    "start": "465360",
    "end": "471539"
  },
  {
    "text": "functions um it's just you know call function and do something with it",
    "start": "471539",
    "end": "476759"
  },
  {
    "text": "um and so that's what took us down this path of uh you know Json schema and generalizing sort of the",
    "start": "476759",
    "end": "483120"
  },
  {
    "text": "interface and we first built plugins and and trained the model on it and early days it was sort of you know uh showing",
    "start": "483120",
    "end": "490560"
  },
  {
    "text": "good life but not quite there and in the last two three months since the plugins launched what we've done is basically",
    "start": "490560",
    "end": "496020"
  },
  {
    "text": "repeatedly find you in the model on tens of thousands of examples of what good interaction Tools looks like with the",
    "start": "496020",
    "end": "501960"
  },
  {
    "text": "weather API with the Wolfram API and you know hundreds of other apis like that and now the model has been fine-tuned on",
    "start": "501960",
    "end": "508139"
  },
  {
    "text": "it and is really good at both choosing when to call a particular tool or Plug-In or function",
    "start": "508139",
    "end": "514800"
  },
  {
    "text": "um you know pick whatever word you want using its understanding and reasoning",
    "start": "514800",
    "end": "520140"
  },
  {
    "text": "ability and also then converting that into structured",
    "start": "520140",
    "end": "525420"
  },
  {
    "text": "output and you know I the structured output is like 95 there uh it mostly outputs valid",
    "start": "525420",
    "end": "533880"
  },
  {
    "text": "Json and mostly outputs the correct output um there are a few more steps we think we can take over the next uh you know",
    "start": "533880",
    "end": "540060"
  },
  {
    "text": "coming months to to improve that but we it worked for us and we were like",
    "start": "540060",
    "end": "545760"
  },
  {
    "text": "you know this has to be Unleashed and uh you know let the developer creativity flow so that's sort of what led down to",
    "start": "545760",
    "end": "552060"
  },
  {
    "text": "the functions launch in uh we're one weekend and so many cool demos on Twitter so that's a quick introduction",
    "start": "552060",
    "end": "557100"
  },
  {
    "text": "to how it came to be and and and and where we see things going as well yeah that that's awesome background and I'm",
    "start": "557100",
    "end": "563940"
  },
  {
    "text": "sure there's a lot of questions around around some of that but one that I have just to set the stage for some of the other stuff that we'll be talking about",
    "start": "563940",
    "end": "569880"
  },
  {
    "text": "is a lot of the use cases that I've seen are almost less around function calling",
    "start": "569880",
    "end": "575399"
  },
  {
    "text": "and more just like structuring output in a specific way like is something is that something you guys anticipated is that a",
    "start": "575399",
    "end": "581700"
  },
  {
    "text": "good use case or like you know it seems a little bit like it yeah will the model",
    "start": "581700",
    "end": "586980"
  },
  {
    "text": "perform well can we expect the model to be like reliable for for that use case basically",
    "start": "586980",
    "end": "592440"
  },
  {
    "text": "yeah uh it's definitely a supported use case we definitely encourage people to use function calling for structured",
    "start": "592440",
    "end": "597959"
  },
  {
    "text": "output data extraction things like that I understand the interface is kind of like one step removed like you wouldn't",
    "start": "597959",
    "end": "603959"
  },
  {
    "text": "call it functions you'd call it you know some sort of templating uh and there's some cool projects out there like",
    "start": "603959",
    "end": "609300"
  },
  {
    "text": "Microsoft guidance that sort of you know show direction on where else templating can go and so we're definitely looking",
    "start": "609300",
    "end": "614820"
  },
  {
    "text": "at those things closely um uh I think we have some experiments internally on how you know uh stuff like",
    "start": "614820",
    "end": "621060"
  },
  {
    "text": "that can work but as you all know open AI operates at like immense scale",
    "start": "621060",
    "end": "626100"
  },
  {
    "text": "um and you know latency is already a problem and adding more logic in there uh can complicate things a little bit uh",
    "start": "626100",
    "end": "632820"
  },
  {
    "text": "so you know we're researching ways to do this performantly and safely uh and uh",
    "start": "632820",
    "end": "637860"
  },
  {
    "text": "and once we have something we'll share it with the world yeah awesome awesome all right so that's",
    "start": "637860",
    "end": "644940"
  },
  {
    "text": "that's a great overview on on the history of functions and so just going",
    "start": "644940",
    "end": "651120"
  },
  {
    "text": "in order Francisco do you maybe want to chat uh a little bit for yeah five five-ish minutes or so about what what",
    "start": "651120",
    "end": "657720"
  },
  {
    "text": "you've been working on and how that relates yeah sure so I what I've mainly been",
    "start": "657720",
    "end": "663959"
  },
  {
    "text": "working on is uh exactly this like using the functions uh functionality to",
    "start": "663959",
    "end": "669899"
  },
  {
    "text": "extract information from documents and to type documents",
    "start": "669899",
    "end": "675120"
  },
  {
    "text": "um I'm I'm really excited on how this allows uh us developers to to do this uh",
    "start": "675120",
    "end": "681420"
  },
  {
    "text": "extraction and tagging in in a very easy way without any need for training so",
    "start": "681420",
    "end": "687000"
  },
  {
    "text": "starting with tagging tagging is basically extracting from the document a",
    "start": "687000",
    "end": "692760"
  },
  {
    "text": "few labels right or setting a few labels for the document for example you can ask",
    "start": "692760",
    "end": "698339"
  },
  {
    "text": "what the sentiment is for a document what the language is on a document or or",
    "start": "698339",
    "end": "703800"
  },
  {
    "text": "other things even also for passages or or sentences",
    "start": "703800",
    "end": "708959"
  },
  {
    "text": "and uh I see this like as a serial shot classification no need for training but",
    "start": "708959",
    "end": "715500"
  },
  {
    "text": "with the possibility of defining your labels in a very structured way and having the model respect that and the",
    "start": "715500",
    "end": "723000"
  },
  {
    "text": "other great Advantage I see is that you can classify into several uh sets of",
    "start": "723000",
    "end": "729180"
  },
  {
    "text": "labels at the same time so you can have like have the sentiment the language and for example the aggressiveness of the",
    "start": "729180",
    "end": "736200"
  },
  {
    "text": "comment classified in one code so I think that is quite great and having the",
    "start": "736200",
    "end": "741779"
  },
  {
    "text": "ability of of defining the labels also helps in in having some predictability",
    "start": "741779",
    "end": "747300"
  },
  {
    "text": "on on the output on desired output the other thing is data extraction so this",
    "start": "747300",
    "end": "752519"
  },
  {
    "text": "is a very also a very common use case where you have unstructured document and you want to extract some entities and",
    "start": "752519",
    "end": "760200"
  },
  {
    "text": "their attributes for those entities so one common example that I've been looking at is like uh CBS where you have",
    "start": "760200",
    "end": "767700"
  },
  {
    "text": "a lot of CDs and they are all structured differently like every CV has its own",
    "start": "767700",
    "end": "773399"
  },
  {
    "text": "style and the information is displayed in different places and also you have",
    "start": "773399",
    "end": "778519"
  },
  {
    "text": "some information that is present in some CVS and it's not present in others so you have this challenge",
    "start": "778519",
    "end": "784740"
  },
  {
    "text": "but uh as as he was saying with the new functions uh use functionality you can",
    "start": "784740",
    "end": "793380"
  },
  {
    "text": "it's it's kind of like a hack in my view because you're not actually calling a function after the response from the",
    "start": "793380",
    "end": "799920"
  },
  {
    "text": "model but it's the actual response with those parameters that you care for so you're telling the model so here's the",
    "start": "799920",
    "end": "805860"
  },
  {
    "text": "function which is the extract data function and these are the parameters I need the parameters I need are for",
    "start": "805860",
    "end": "811680"
  },
  {
    "text": "example in the CV case the candidate's name the candidate skills the last",
    "start": "811680",
    "end": "817260"
  },
  {
    "text": "company that the candidate worked on and the number of years of experience for example and a contact email so the API",
    "start": "817260",
    "end": "825060"
  },
  {
    "text": "will return a function that that gives you all these attributes as parameters",
    "start": "825060",
    "end": "830279"
  },
  {
    "text": "and you can the nice thing about this is you can set the for example the allowed",
    "start": "830279",
    "end": "835800"
  },
  {
    "text": "values or the type of of the output and in this way you can control you have a",
    "start": "835800",
    "end": "841139"
  },
  {
    "text": "great degree of control over what the output looks like and when you're trying to extract structured data from a",
    "start": "841139",
    "end": "847740"
  },
  {
    "text": "structured document that's exactly what you want so I think that's really exciting I've been playing around with it I think it works really well",
    "start": "847740",
    "end": "855240"
  },
  {
    "text": "um when rightly prompted and and right and used correctly so yeah that's that's",
    "start": "855240",
    "end": "860639"
  },
  {
    "text": "a very nice use case that has been opened with with this new release and and just uh diving when you say",
    "start": "860639",
    "end": "867779"
  },
  {
    "text": "rightly prompted um what what prompting techniques have you found to work particularly well for for functions in particular",
    "start": "867779",
    "end": "875519"
  },
  {
    "text": "so specifically for extraction um some things I've been doing this uh",
    "start": "875519",
    "end": "882560"
  },
  {
    "text": "this is not nothing new but I'm asking it not to to hallucinate so do not",
    "start": "882560",
    "end": "887760"
  },
  {
    "text": "invent uh if you don't find it to not return it and also I I wrote uh if you",
    "start": "887760",
    "end": "894959"
  },
  {
    "text": "find no so if if it's not required right and if you find no answer just return",
    "start": "894959",
    "end": "900480"
  },
  {
    "text": "empty string like don't don't be afraid to to return an empty string",
    "start": "900480",
    "end": "905579"
  },
  {
    "text": "um and that worked well to to avoid you know trying to to place a piece of data",
    "start": "905579",
    "end": "911100"
  },
  {
    "text": "just to fit uh into that value right for that attribute",
    "start": "911100",
    "end": "916139"
  },
  {
    "text": "um but it's really nothing very sophisticated uh it works quite well out of the box",
    "start": "916139",
    "end": "923120"
  },
  {
    "text": "awesome and did you have a demo or anything that you wanted to show first yeah I can show",
    "start": "924000",
    "end": "930060"
  },
  {
    "text": "um so I did just a small demo this is something I typed about yesterday please I'm sorry for the for the design it's",
    "start": "930060",
    "end": "936600"
  },
  {
    "text": "not very beautiful but um it shows like a practical use case for this",
    "start": "936600",
    "end": "942839"
  },
  {
    "text": "so okay so let's say this is a demo CV right",
    "start": "942839",
    "end": "948660"
  },
  {
    "text": "the name and the what the candidate does contact about me",
    "start": "948660",
    "end": "954839"
  },
  {
    "text": "education so let's say we want to extract uh structural data from from here",
    "start": "954839",
    "end": "960899"
  },
  {
    "text": "um this is using also Lang chain under the hood which also uses open a functions so we can upload here the the",
    "start": "960899",
    "end": "967980"
  },
  {
    "text": "CV and here we set a few attributes uh this is the where we are specifying the type",
    "start": "967980",
    "end": "975420"
  },
  {
    "text": "this is very nice because for example there's an example in the language documentation where the the written",
    "start": "975420",
    "end": "982019"
  },
  {
    "text": "example says Claudia is one year older than Alex or one foot uh higher I don't",
    "start": "982019",
    "end": "987899"
  },
  {
    "text": "remember and since we set the attribute to a number it doesn't return you know",
    "start": "987899",
    "end": "994139"
  },
  {
    "text": "one year old or one foot higher but it just returns if Alex was five it returns six right and that's what because we",
    "start": "994139",
    "end": "1000019"
  },
  {
    "text": "specified the type we want in the answer so I really like the fact that we can Define what the type is and the model",
    "start": "1000019",
    "end": "1007220"
  },
  {
    "text": "respects that another thing we can set is a small description and this description is very",
    "start": "1007220",
    "end": "1013339"
  },
  {
    "text": "nice uh it's kind of like a prompt engineering because we're trying to",
    "start": "1013339",
    "end": "1018440"
  },
  {
    "text": "um constrain the model to only uh give us the the type of information that we",
    "start": "1018440",
    "end": "1024558"
  },
  {
    "text": "really want and not uh to to get confused in giving us a response that we",
    "start": "1024559",
    "end": "1029839"
  },
  {
    "text": "are not we do not care for so here we're saying okay candidate's full name the years of experience here",
    "start": "1029839",
    "end": "1035660"
  },
  {
    "text": "is a Boolean right if it's a software developer this is interesting because obviously in the document it doesn't say",
    "start": "1035660",
    "end": "1041600"
  },
  {
    "text": "I am not a software developer but it says it doesn't say that that he's a software developer and it says that he's",
    "start": "1041600",
    "end": "1047600"
  },
  {
    "text": "uh his profession is another thing so it will work correctly and that's because",
    "start": "1047600",
    "end": "1052700"
  },
  {
    "text": "we specified that it is a Boolean uh again University languages and",
    "start": "1052700",
    "end": "1059260"
  },
  {
    "text": "contact here I I said ways to contact this is quite open it's a text so this",
    "start": "1059260",
    "end": "1065900"
  },
  {
    "text": "is probably a way to catch many use cases or many many many strings and and",
    "start": "1065900",
    "end": "1072860"
  },
  {
    "text": "not only one right so if we submit here this is running through through link",
    "start": "1072860",
    "end": "1078440"
  },
  {
    "text": "chain and here is the output so we get the full name the user experience not our",
    "start": "1078440",
    "end": "1084500"
  },
  {
    "text": "software developer if there are nothing uh there's nothing specified about languages we get an empty string",
    "start": "1084500",
    "end": "1090380"
  },
  {
    "text": "University and all the ways to contact the candidate so this is a small demo of",
    "start": "1090380",
    "end": "1095740"
  },
  {
    "text": "some way in which this functionality might be useful for people",
    "start": "1095740",
    "end": "1102580"
  },
  {
    "text": "awesome thanks for sharing that all right Jason you've been experimenting from the",
    "start": "1102860",
    "end": "1108380"
  },
  {
    "text": "beginning on a lot of uh a lot of pretty out there stuff so I'm excited to",
    "start": "1108380",
    "end": "1114320"
  },
  {
    "text": "to hear what you have to share and yeah would love to also hear just a little bit about like you know how motivation",
    "start": "1114320",
    "end": "1122059"
  },
  {
    "text": "because like you've been doing some of the most interesting stuff on Twitter I think and so just love to hear also how you like thought about it and started",
    "start": "1122059",
    "end": "1128299"
  },
  {
    "text": "approaching it and stuff like that sure yeah um I guess I started mostly playing",
    "start": "1128299",
    "end": "1134419"
  },
  {
    "text": "around with this stuff primarily because I've been sort of Consulting some like early stage Types on figuring out like",
    "start": "1134419",
    "end": "1139520"
  },
  {
    "text": "what are the right practices to do and almost I would say 90 of the time it's",
    "start": "1139520",
    "end": "1145460"
  },
  {
    "text": "about having structured data that we can do computations over right so like agents are kind of too far",
    "start": "1145460",
    "end": "1151220"
  },
  {
    "text": "out but we still want to do some kind of extraction I'll give an example of this email segmentation that I've been",
    "start": "1151220",
    "end": "1157220"
  },
  {
    "text": "working on for another company um but ultimately it's about getting structured data and then running some computation over that data",
    "start": "1157220",
    "end": "1164240"
  },
  {
    "text": "so this is kind of like rough slides but really it's just code that I've been",
    "start": "1164240",
    "end": "1169520"
  },
  {
    "text": "writing so I'll go with that uh the general idea is that function calls are great it's structured data but it's",
    "start": "1169520",
    "end": "1175400"
  },
  {
    "text": "still technically a string and then we parse it to Json and if we use pedantic we get basically python objects right",
    "start": "1175400",
    "end": "1182419"
  },
  {
    "text": "back out and we don't actually have to write Json scheme right not only are these strings they",
    "start": "1182419",
    "end": "1187520"
  },
  {
    "text": "become structured data and because it's pedantic which is a python object it also contains computation",
    "start": "1187520",
    "end": "1194480"
  },
  {
    "text": "in the examples I'll show for like the segment search queries we see that it's a very flat segmented computation but",
    "start": "1194480",
    "end": "1201440"
  },
  {
    "text": "I've also shown some examples where we do like kind of a dag generation that we can then execute uh in parallel with",
    "start": "1201440",
    "end": "1208880"
  },
  {
    "text": "like DFS or BFS and then lastly not only can it be computation it's computation",
    "start": "1208880",
    "end": "1214940"
  },
  {
    "text": "that could potentially interact with with its own inputs and I'll show an example of doing citations uh these are",
    "start": "1214940",
    "end": "1221299"
  },
  {
    "text": "kind of like pretty atrocious of the use of the function call Api but I think these are some cool examples Worth",
    "start": "1221299",
    "end": "1226760"
  },
  {
    "text": "showing off the first example I'll show is one around maybe preventing SQL injection",
    "start": "1226760",
    "end": "1233000"
  },
  {
    "text": "right right now when we use SQL agency okay",
    "start": "1233000",
    "end": "1238520"
  },
  {
    "text": "kind of just output the SQL with like No Escape values but we know that the call Safe SQL safely we want to have template",
    "start": "1238520",
    "end": "1245480"
  },
  {
    "text": "strings and we want to have query parameters so if we model this so you know a SQL template has a literal or an",
    "start": "1245480",
    "end": "1250760"
  },
  {
    "text": "identifier there are parameters that have keys and values with a type and the SQL query is actually a template and its",
    "start": "1250760",
    "end": "1258020"
  },
  {
    "text": "parameters and just for a safety I I add a is dangerous fly that determines whether or not I think or the model",
    "start": "1258020",
    "end": "1264919"
  },
  {
    "text": "thinks there's any kind of a SQL injection so this is all kind of just modeling the data what pedant can do is it generates",
    "start": "1264919",
    "end": "1272419"
  },
  {
    "text": "the the function uh schema automatically for you here I just give an example of some SQL",
    "start": "1272419",
    "end": "1280100"
  },
  {
    "text": "tables and then I make a response and so these are some examples that can give me right give me the ID give you the name",
    "start": "1280100",
    "end": "1286940"
  },
  {
    "text": "first select true yada yada and then when you look at the examples uh it does quite well right it escapes",
    "start": "1286940",
    "end": "1294740"
  },
  {
    "text": "the right templates it uses grid parameters it'll warn me if a query is risky but still produce a query that is",
    "start": "1294740",
    "end": "1302299"
  },
  {
    "text": "technically safe so that's a fun example of sort of going away from computation as a string to",
    "start": "1302299",
    "end": "1308659"
  },
  {
    "text": "computation as structured data uh in the second example",
    "start": "1308659",
    "end": "1314059"
  },
  {
    "text": "I want to do something differently I want to take a request that may contain multiple parts and maybe search across",
    "start": "1314059",
    "end": "1320539"
  },
  {
    "text": "different backends so again I have a search type which is a video or an email",
    "start": "1320539",
    "end": "1325640"
  },
  {
    "text": "I have a single search object which is a query and a type",
    "start": "1325640",
    "end": "1331520"
  },
  {
    "text": "I also implement the execute method which could potentially run that query and then I Define something called",
    "start": "1331520",
    "end": "1337100"
  },
  {
    "text": "multi-search which is basically just a list of queries so in this sense we can have an array of computation uh for a",
    "start": "1337100",
    "end": "1345380"
  },
  {
    "text": "single task and then this execute is just made up but all all it does is it asynchronously calls all these type of",
    "start": "1345380",
    "end": "1351500"
  },
  {
    "text": "tasks so now if I have a message that says you know",
    "start": "1351500",
    "end": "1357260"
  },
  {
    "text": "send me the last week send me the video from last week about the investment case study and the documents around gdpr",
    "start": "1357260",
    "end": "1363860"
  },
  {
    "text": "I can now asynchronously call to two different backends with two different search queries right",
    "start": "1363860",
    "end": "1371360"
  },
  {
    "text": "so this is kind of like a flat computation but we can still go even one step further instead of generating a",
    "start": "1371360",
    "end": "1378380"
  },
  {
    "text": "almost like a mapreduce query we can actually generate an arbitrary tree of computations",
    "start": "1378380",
    "end": "1384020"
  },
  {
    "text": "so this is a crazier example and so you know hopefully this will be uploaded on YouTube you guys can like go back and",
    "start": "1384020",
    "end": "1389059"
  },
  {
    "text": "forth and and pause when it's relevant but here I have a single question or a multi a multi question where uh to",
    "start": "1389059",
    "end": "1397580"
  },
  {
    "text": "answer this question I had to answer like three other questions right I have a compute which is the oh sorry",
    "start": "1397580",
    "end": "1405020"
  },
  {
    "text": "let me skip ahead to the query actually so so now we have a query which has an ID the question is asking the ID of its",
    "start": "1405020",
    "end": "1413240"
  },
  {
    "text": "dependencies and whether it's a single query or a multi-query and I have some logic here that says if it's a single",
    "start": "1413240",
    "end": "1419539"
  },
  {
    "text": "query make the request if it's a multi-query query the dependencies first",
    "start": "1419539",
    "end": "1424960"
  },
  {
    "text": "concatenate all the responses and then put that in the context of the Roger query and try to answer that question",
    "start": "1424960",
    "end": "1432559"
  },
  {
    "text": "this is just the code that does this kind of work but again what this actually gets you is if I scroll to the",
    "start": "1432559",
    "end": "1438740"
  },
  {
    "text": "bottom if I ask the question what is the difference between the population of Canada and my home country it first",
    "start": "1438740",
    "end": "1445340"
  },
  {
    "text": "identifies my home country finds the population of Canada finds a",
    "start": "1445340",
    "end": "1450440"
  },
  {
    "text": "population of my home country which will be answered with the first question and then finally",
    "start": "1450440",
    "end": "1456260"
  },
  {
    "text": "calculate the difference in populations between Canada and Jason's home country and you can see all the dependencies are",
    "start": "1456260",
    "end": "1462260"
  },
  {
    "text": "done correctly which means that if we want to compute over this graph we can do that in kind of a",
    "start": "1462260",
    "end": "1468280"
  },
  {
    "text": "concurrent way uh so this was also like a really fun example because so far it's",
    "start": "1468280",
    "end": "1474020"
  },
  {
    "text": "worked um so that kind of goes over strings with some data uh some multiple compute",
    "start": "1474020",
    "end": "1480500"
  },
  {
    "text": "over that data and then some like Dynamic multi-computed with that data and the last one which I think is quite",
    "start": "1480500",
    "end": "1486620"
  },
  {
    "text": "an interesting actually is around having the data sort of reference its own",
    "start": "1486620",
    "end": "1492740"
  },
  {
    "text": "inputs and so here I'm creating an example where I'm trying to find citations to",
    "start": "1492740",
    "end": "1498020"
  },
  {
    "text": "use to answer a question and to make sure that these citations are not hallucinated",
    "start": "1498020",
    "end": "1503299"
  },
  {
    "text": "so I have a fat class that states a statement and then also a quote from the",
    "start": "1503299",
    "end": "1508580"
  },
  {
    "text": "context of that statement so if I want to say that like you know Jason comes from New York I want to find exactly",
    "start": "1508580",
    "end": "1514880"
  },
  {
    "text": "where I say that but the substring could be hallucinated so what I actually do instead is write a",
    "start": "1514880",
    "end": "1520940"
  },
  {
    "text": "regular expression that looks for the substring in the original context and then find the spans and what this",
    "start": "1520940",
    "end": "1527900"
  },
  {
    "text": "means is if the spans don't exist I can kind of convince myself that this data might not",
    "start": "1527900",
    "end": "1533659"
  },
  {
    "text": "actually be uh real and then I Define a question answer as",
    "start": "1533659",
    "end": "1539840"
  },
  {
    "text": "just a question and a list of facts which Define both the answer and the citations",
    "start": "1539840",
    "end": "1545120"
  },
  {
    "text": "and again if you go back down to an example uh if the question is what did I do in",
    "start": "1545120",
    "end": "1551299"
  },
  {
    "text": "college and this is the context so that highlights the data",
    "start": "1551299",
    "end": "1556580"
  },
  {
    "text": "I can produce statements that answer my question so the first statement is that I study computational mathematics and",
    "start": "1556580",
    "end": "1561919"
  },
  {
    "text": "physics at the University in a university and in the angle brackets you see exactly the Span in the original",
    "start": "1561919",
    "end": "1568400"
  },
  {
    "text": "text that I cite same thing here it says I ran the data science club and was a president for so",
    "start": "1568400",
    "end": "1574039"
  },
  {
    "text": "and so here this one statement has two citations right and again I get the exact spans of um",
    "start": "1574039",
    "end": "1582500"
  },
  {
    "text": "the of the context right these aren't strings that I'm citing now I'm actually exciting the chunk ID",
    "start": "1582500",
    "end": "1588740"
  },
  {
    "text": "you know starting from like the character 27th character to the 80th character",
    "start": "1588740",
    "end": "1594260"
  },
  {
    "text": "um and uh you know this is this is something I'm actually pretty excited about to explore more the idea that we",
    "start": "1594260",
    "end": "1599900"
  },
  {
    "text": "can actually propagate citations and make sure that the generations we have are like extremely grounded",
    "start": "1599900",
    "end": "1606500"
  },
  {
    "text": "uh these are some some of the wild examples I've been going and playing around with these days uh mostly As",
    "start": "1606500",
    "end": "1612740"
  },
  {
    "text": "motivated by some some of the Consulting work around just making sure things don't lie in production and making sure",
    "start": "1612740",
    "end": "1618799"
  },
  {
    "text": "we can plan tasks and run things uh in parallel in production and uh yeah I",
    "start": "1618799",
    "end": "1625760"
  },
  {
    "text": "mean I I generally love this idea that we can map data to computation and then back to the data itself I think once we",
    "start": "1625760",
    "end": "1632179"
  },
  {
    "text": "close that loop it's going to be pretty exciting that's it awesome yeah Jason those are definitely",
    "start": "1632179",
    "end": "1638360"
  },
  {
    "text": "some of the more uh yeah wild examples that I've seen I would say abusive at this point well my question is are there",
    "start": "1638360",
    "end": "1645260"
  },
  {
    "text": "any like more wild ones that you've tried and haven't worked or haven't had time to to try yet like what's the most",
    "start": "1645260",
    "end": "1651679"
  },
  {
    "text": "creative kind of like you've got it with with these Beyond those let me check my notes real quick",
    "start": "1651679",
    "end": "1659140"
  },
  {
    "text": "I think I think one that I really want to try out which is actually something",
    "start": "1662000",
    "end": "1667039"
  },
  {
    "text": "that Addie called out earlier which is just turning open open uh open Json there's an open API Json into",
    "start": "1667039",
    "end": "1675200"
  },
  {
    "text": "tools right like I would love to be able to pass in you know like pedantic from api.com",
    "start": "1675200",
    "end": "1684039"
  },
  {
    "text": "openapi.json and just get all the pedantic types out and so you can you can build this tool",
    "start": "1684039",
    "end": "1690500"
  },
  {
    "text": "that says you know what like I want to interact with this API let me pass in the open API docs it'll now generate all",
    "start": "1690500",
    "end": "1697460"
  },
  {
    "text": "the types I need right so it'll create like every single API call both the API",
    "start": "1697460",
    "end": "1702860"
  },
  {
    "text": "request as the post request and the request body and then what this means is",
    "start": "1702860",
    "end": "1708200"
  },
  {
    "text": "now I can basically go from open API to pedantic schemas and I can Define",
    "start": "1708200",
    "end": "1713900"
  },
  {
    "text": "additional computation against those schemas that's one of them the second one is effectively this the citation",
    "start": "1713900",
    "end": "1719779"
  },
  {
    "text": "publication right it's you often not the case that you answer a question from the",
    "start": "1719779",
    "end": "1725539"
  },
  {
    "text": "ground truth you have your citations and you're done usually it's a little bit more complicated like for example for large documents I might want to",
    "start": "1725539",
    "end": "1731779"
  },
  {
    "text": "summarize them first but the summarizations should have citations and then if I want to answer questions against those",
    "start": "1731779",
    "end": "1737779"
  },
  {
    "text": "summarizations I really still want to be citing the original Source document I don't want to",
    "start": "1737779",
    "end": "1742940"
  },
  {
    "text": "be necessarily citing the made-up text and sometimes you might have to right if you make some kind of",
    "start": "1742940",
    "end": "1749440"
  },
  {
    "text": "abstractive summary there is actually no ground truth but when you have an extractive summary there is ground truth",
    "start": "1749440",
    "end": "1756260"
  },
  {
    "text": "and then having a reason about what is like the original thought that the AI had and what was facts that we can pull",
    "start": "1756260",
    "end": "1763700"
  },
  {
    "text": "in from a document I think building that out would be really incredible",
    "start": "1763700",
    "end": "1769460"
  },
  {
    "text": "I think an example could be when an agent makes a memory right the agent makes a memory memory cites a text",
    "start": "1769460",
    "end": "1776360"
  },
  {
    "text": "message I sent it you know I want to know that it's memory of me is correct but when I reference the memory you should go back to the",
    "start": "1776360",
    "end": "1782779"
  },
  {
    "text": "text message not this hallucinated thing which I and I'm running into sometimes",
    "start": "1782779",
    "end": "1789380"
  },
  {
    "text": "awesome all right David do you want to take it away for the final thing and then after this",
    "start": "1789380",
    "end": "1795620"
  },
  {
    "text": "we'll go to questions in the chat so reminder to drop any questions people have and then in the in the Q a section",
    "start": "1795620",
    "end": "1801380"
  },
  {
    "text": "on the right so thanks thanks Harrison for having me sorry sorry folks I've actually prepared",
    "start": "1801380",
    "end": "1807740"
  },
  {
    "text": "a few slides so hopefully that won't be uh too much boring but let me try to",
    "start": "1807740",
    "end": "1813020"
  },
  {
    "text": "share the screen so we can go for it is my screen visible",
    "start": "1813020",
    "end": "1819080"
  },
  {
    "text": "yes awesome so actually one of our community members he created this table Forge",
    "start": "1819080",
    "end": "1825260"
  },
  {
    "text": "which is generating picture books actually using Goblin a functions with long chain stable diffusion and deep",
    "start": "1825260",
    "end": "1830539"
  },
  {
    "text": "lake and I'm super excited to talk about that and also we'll do a later some slightly more Visionary uh",
    "start": "1830539",
    "end": "1836720"
  },
  {
    "text": "generalizations also happening behind the scenes so what's Fable Forge is it's actually you can just write a simpler",
    "start": "1836720",
    "end": "1841940"
  },
  {
    "text": "prompt and then choose the topic um or the style and it generates a picture book for your kids a very simple",
    "start": "1841940",
    "end": "1848480"
  },
  {
    "text": "one but what's happening behind the scenes is very interesting is that it's actually user prompt is given to a gpt4",
    "start": "1848480",
    "end": "1854600"
  },
  {
    "text": "or GPD 3.5 uh query which generates a set of uh prompts with the opening",
    "start": "1854600",
    "end": "1860480"
  },
  {
    "text": "functions and then these are passed to the image generation process to generate",
    "start": "1860480",
    "end": "1865880"
  },
  {
    "text": "um each page of the book and this at the end get compiled to a PDF and then PDF is downloadable",
    "start": "1865880",
    "end": "1872539"
  },
  {
    "text": "um the code is available here but I'll do a quick brief demo what's happening behind the scenes so here it's like",
    "start": "1872539",
    "end": "1878899"
  },
  {
    "text": "let's say we want to use table Forge and say hey um like I want to generate a Harry Potter in Tokyo style",
    "start": "1878899",
    "end": "1885080"
  },
  {
    "text": "um Japanese like um this is the style that I'm choosing for in terms of the star pictures and hey let me just use",
    "start": "1885080",
    "end": "1890840"
  },
  {
    "text": "gp4 so this will take some time to generate the block even how long it takes the queries but",
    "start": "1890840",
    "end": "1897380"
  },
  {
    "text": "um I already did the preparation before so here is the kind of the PDF that you can observe that it gets generated and",
    "start": "1897380",
    "end": "1905179"
  },
  {
    "text": "then the core thing is that I think that's the biggest difference is instead of just promptly and nightly take the data",
    "start": "1905179",
    "end": "1911659"
  },
  {
    "text": "and give pass it to some stable diffusion abstract prompts you can actually use open AI functions to try to",
    "start": "1911659",
    "end": "1918380"
  },
  {
    "text": "structure them such that each like you can construct your own prompts for stable diffusion itself with the open AI",
    "start": "1918380",
    "end": "1925100"
  },
  {
    "text": "function as a parameters that gives posts to The Prompt chain so I think that's that's make it kind of like kind",
    "start": "1925100",
    "end": "1931220"
  },
  {
    "text": "of structured query but this is on the font side of things we've had in the sins and I'll show you a little later as well",
    "start": "1931220",
    "end": "1937399"
  },
  {
    "text": "like what where do we see like how all player functions in blockchain itself is like becomes super critical when you run",
    "start": "1937399",
    "end": "1942919"
  },
  {
    "text": "a bunch of queries but here here's like a very basic um like Playbook that that",
    "start": "1942919",
    "end": "1948200"
  },
  {
    "text": "the book uh here that should get guaranteed and then what what thing additionally what we allow you to have",
    "start": "1948200",
    "end": "1953659"
  },
  {
    "text": "is they can actually this data gets stored in in like niplake which is a multi-model data like for people",
    "start": "1953659",
    "end": "1959480"
  },
  {
    "text": "learning applications we can actually go and look into the data set be able to query or use this to train or fine-tune",
    "start": "1959480",
    "end": "1965659"
  },
  {
    "text": "any model that you're working on um but let me get back some some like um",
    "start": "1965659",
    "end": "1972140"
  },
  {
    "text": "like the basics what what we would have been working on that active group for for the last five years as well so what",
    "start": "1972140",
    "end": "1977539"
  },
  {
    "text": "we have seen is that um similar to how overall AI stack has been fragmented before uh long chain",
    "start": "1977539",
    "end": "1983720"
  },
  {
    "text": "days um the data stack itself is has been fragmented and um you had Fox who have been storing",
    "start": "1983720",
    "end": "1990260"
  },
  {
    "text": "their much of metadata in traditional databases it could be snowflake it could be postgres you have a bunch of",
    "start": "1990260",
    "end": "1995360"
  },
  {
    "text": "unstructured data like images video audio tag like PDFs as well stored on top of the object starters and now you",
    "start": "1995360",
    "end": "2001899"
  },
  {
    "text": "have to employ the third set of additional tool which we call back to database to store the indexes of",
    "start": "2001899",
    "end": "2007000"
  },
  {
    "text": "embeddings of the data to be able to run queries on top and at least from our side what we have been trying to work on",
    "start": "2007000",
    "end": "2013000"
  },
  {
    "text": "is actually unifying this um three modules together with the eventually",
    "start": "2013000",
    "end": "2018700"
  },
  {
    "text": "um like saying hey you actually need a data storage or a memory for all your data um and being it's serverless with good",
    "start": "2018700",
    "end": "2025600"
  },
  {
    "text": "and storage isolation um letting it to have like multi-modality so you're not only just limited to storing your mailings or",
    "start": "2025600",
    "end": "2031899"
  },
  {
    "text": "tasks you can also go with audio and images video and lets you to do um all-in-one stream and query and",
    "start": "2031899",
    "end": "2038080"
  },
  {
    "text": "visualize the data sets themselves so if you look from one perspective how that gets into the like the whole blockchain",
    "start": "2038080",
    "end": "2044559"
  },
  {
    "text": "and on open AI ecosystem is that from one side you can use um like that as a vector database to be",
    "start": "2044559",
    "end": "2051220"
  },
  {
    "text": "able to run the queries on top of the play data sets but you can also like I mean with like opening apis like for",
    "start": "2051220",
    "end": "2057580"
  },
  {
    "text": "fine swing that's that's tricky but the rest like you can actually fine tune your own models on the data that you",
    "start": "2057580",
    "end": "2062740"
  },
  {
    "text": "have collected but like let me give you more much more like specific example I will not deep",
    "start": "2062740",
    "end": "2068260"
  },
  {
    "text": "dive on this project that we have been working for the last few months but um I think there's one key thing that's very",
    "start": "2068260",
    "end": "2073720"
  },
  {
    "text": "relevant for today's topic is being able to run search across all the payments",
    "start": "2073720",
    "end": "2078878"
  },
  {
    "text": "and then what we did is that we looked into all the USPTO documents took them embedded actually we split into",
    "start": "2078879",
    "end": "2085898"
  },
  {
    "text": "different structures you have titles you have obstructs you have claims Etc and you want to be able to run queries on",
    "start": "2085899",
    "end": "2091358"
  },
  {
    "text": "top but the main difference here is like instead of just running a vector search you can actually take this and decompose",
    "start": "2091359",
    "end": "2097540"
  },
  {
    "text": "this into both like structured query and also on such query so this will get into the like typing in the 2007 we'll get",
    "start": "2097540",
    "end": "2105220"
  },
  {
    "text": "into the filtering function to be able to do that and what I believe is like open air functions like here is like it",
    "start": "2105220",
    "end": "2110920"
  },
  {
    "text": "makes huge difference as actually structuring your query that you are giving to a database or data storage to",
    "start": "2110920",
    "end": "2117339"
  },
  {
    "text": "be able to um have this like separation of what gets into the embedding itself and what's getting into the query",
    "start": "2117339",
    "end": "2124839"
  },
  {
    "text": "and I think um at the end it's like essentially what we the way we have been seeing is that the whole um like this",
    "start": "2124839",
    "end": "2132040"
  },
  {
    "text": "like Market is moving is that you have on top like think of this as like you're in like CPUs like you have L1 cache l23",
    "start": "2132040",
    "end": "2139839"
  },
  {
    "text": "L2 cache L3 cache and then you have the ROM and then you have your ssds or HDD on your on your computer similarly now",
    "start": "2139839",
    "end": "2146740"
  },
  {
    "text": "we have this like small context foundational models like think of them up to 8 000 um um tokens and then you",
    "start": "2146740",
    "end": "2153579"
  },
  {
    "text": "have slightly like L2 cache which just takes longer to compute but they can ingest much more bigger data as a",
    "start": "2153579",
    "end": "2158920"
  },
  {
    "text": "context type and then um on the below you have the data Lake concept where you have a bunch of data on structures",
    "start": "2158920",
    "end": "2164920"
  },
  {
    "text": "stored on somewhere and then the vector databases and this is the middle layer that like tools like long chain help to",
    "start": "2164920",
    "end": "2170980"
  },
  {
    "text": "kind of connect the dots connect the um the local computation to the mem to",
    "start": "2170980",
    "end": "2176140"
  },
  {
    "text": "the memory itself for the AI to get a large large o context and that's that's what we are super",
    "start": "2176140",
    "end": "2182500"
  },
  {
    "text": "excited about this that like um given the functions and stuff that let you have much better connection from the up",
    "start": "2182500",
    "end": "2189040"
  },
  {
    "text": "to the bottom for running I know this is like this is too much Theory and everyone wants to get Hands-On so um",
    "start": "2189040",
    "end": "2195040"
  },
  {
    "text": "there's another exciting updates uh coming from us in collaboration with towards Ai and Intel and also thanks to",
    "start": "2195040",
    "end": "2200619"
  },
  {
    "text": "harson as well for sharing with the community is that we launched actually a certification program called Jai 360",
    "start": "2200619",
    "end": "2206440"
  },
  {
    "text": "which which has a bunch of actually interesting and practical projects",
    "start": "2206440",
    "end": "2211599"
  },
  {
    "text": "um that you can learn and I know long chain is like super moving fast and we have been capturing while building this",
    "start": "2211599",
    "end": "2216940"
  },
  {
    "text": "course how things are moving as well so please feel free to check out learn.activable.ai it's um it's a long",
    "start": "2216940",
    "end": "2223180"
  },
  {
    "text": "chain certification course that helps to get started and with bunch of actually practical projects that are very cool to",
    "start": "2223180",
    "end": "2229060"
  },
  {
    "text": "see thank you very much everyone um we are happy to answer any questions you might have yeah so I think focusing on like",
    "start": "2229060",
    "end": "2235839"
  },
  {
    "text": "the open AI functions bit for the demo that you showed when connecting to the stable diffusion kind of like thing so",
    "start": "2235839",
    "end": "2242740"
  },
  {
    "text": "there you said you were generating kind of like other parameters for that API like what were the what was like the",
    "start": "2242740",
    "end": "2248560"
  },
  {
    "text": "schema of the functions that you were using there let me actually share the schema",
    "start": "2248560",
    "end": "2256559"
  },
  {
    "text": "it's basically what I'm getting at is this sounds kind of similar to Jason's idea of like hooking up kind of like an API to like a pedantic object or",
    "start": "2260680",
    "end": "2266920"
  },
  {
    "text": "something like that or or just really open you know an API to the to the open",
    "start": "2266920",
    "end": "2272200"
  },
  {
    "text": "AI function schema so I'm wondering kind of like what the process yeah I don't",
    "start": "2272200",
    "end": "2277240"
  },
  {
    "text": "think that we use that because I don't think specifically but I think that kind of the way they look the open a functions were like setting up the type",
    "start": "2277240",
    "end": "2283420"
  },
  {
    "text": "like what do we expect to be returned what's the description of each property that we're looking for so you you kind",
    "start": "2283420",
    "end": "2289839"
  },
  {
    "text": "of have the structure here what what what you are looking to get actually yeah I didn't mention this but Jason was",
    "start": "2289839",
    "end": "2295540"
  },
  {
    "text": "super cool demo I was like every day I wake up like I look at take the phone and then I look a couple of ideas on like cool projects on the Twitter and I",
    "start": "2295540",
    "end": "2303040"
  },
  {
    "text": "saw the the SQL like injection one and shared with the team as well so that that's has been super super cool uh to",
    "start": "2303040",
    "end": "2309880"
  },
  {
    "text": "see but yeah so I think the the main idea here is that you kind of try to decompose the um the the function",
    "start": "2309880",
    "end": "2318040"
  },
  {
    "text": "into the expectation what what you're looking to get so if you if you go into this Ethan's project",
    "start": "2318040",
    "end": "2324099"
  },
  {
    "text": "um where um I think he was using in API tools here so where he builds this kind",
    "start": "2324099",
    "end": "2330160"
  },
  {
    "text": "of the pro the class called buildbot and he has been able to like essentially",
    "start": "2330160",
    "end": "2336400"
  },
  {
    "text": "take like you can take a human message here",
    "start": "2336400",
    "end": "2342180"
  },
  {
    "text": "and provide the function as as an expected output and then pass this function to actually a dictionary that",
    "start": "2342180",
    "end": "2348760"
  },
  {
    "text": "gets back to the generating the state like the stable diffusion model so I",
    "start": "2348760",
    "end": "2354220"
  },
  {
    "text": "think that's that has been that kind of the I'll say the trickiest or interesting connection that you can use",
    "start": "2354220",
    "end": "2361480"
  },
  {
    "text": "the um the function itself to generate structured output and then take the structured output and then give it to",
    "start": "2361480",
    "end": "2367960"
  },
  {
    "text": "the like the kind of you have a query plan I mean the query plan could be General images but you can actually use this in bunch of other applications",
    "start": "2367960",
    "end": "2374980"
  },
  {
    "text": "cool all right so we'll now go to some questions from the the audience and I'll",
    "start": "2374980",
    "end": "2380320"
  },
  {
    "text": "try to select the ones that are most focused on open AI functions just to keep it very focused I think the the top",
    "start": "2380320",
    "end": "2387400"
  },
  {
    "text": "one's a really good one seems like the open AI functions are the new go-to for anything that requires a structured",
    "start": "2387400",
    "end": "2392859"
  },
  {
    "text": "output are there any drawbacks or reasons not to use functions um and and so asking maybe I'll let you",
    "start": "2392859",
    "end": "2399460"
  },
  {
    "text": "take the first stab at this because I'm assuming yeah you guys have some you get",
    "start": "2399460",
    "end": "2404859"
  },
  {
    "text": "you guys have been playing around with it for longer than we have but yeah like when should we not use these magical things called called functions",
    "start": "2404859",
    "end": "2412060"
  },
  {
    "text": "yeah great question um I think uh you know functions are really great for structured data",
    "start": "2412060",
    "end": "2418720"
  },
  {
    "text": "extraction for connecting to external tools apis using the model to pick which",
    "start": "2418720",
    "end": "2424119"
  },
  {
    "text": "uh function to call as well but that doesn't make existing prompt engineering",
    "start": "2424119",
    "end": "2429400"
  },
  {
    "text": "techniques obsolete uh the same models exist the same prompts still work uh and",
    "start": "2429400",
    "end": "2434500"
  },
  {
    "text": "I think the biggest the biggest thing here would be uh one if you don't need the structure then",
    "start": "2434500",
    "end": "2440980"
  },
  {
    "text": "don't need don't use it uh you know you'll save a lot of tokens if all you need the model to do is sort of output",
    "start": "2440980",
    "end": "2447280"
  },
  {
    "text": "you know a couple of words here there or uh you know maybe if you're existing prompt already works pretty well or",
    "start": "2447280",
    "end": "2453579"
  },
  {
    "text": "maybe you're using react or one of these other techniques uh to simulate tool use um just compare you know which one is",
    "start": "2453579",
    "end": "2460780"
  },
  {
    "text": "working better on your own evaluation uh where are you saving more tokens and so",
    "start": "2460780",
    "end": "2467020"
  },
  {
    "text": "that's one place where I would say if it if it works if it's not broken you know don't fix it",
    "start": "2467020",
    "end": "2472780"
  },
  {
    "text": "um so that's that's one aspect um and then what else will you not use",
    "start": "2472780",
    "end": "2478060"
  },
  {
    "text": "functions yeah so that's the first thing that",
    "start": "2478060",
    "end": "2484060"
  },
  {
    "text": "comes to mind I'll let anybody else you know also answer yeah I'm curious for Francisco or Jason",
    "start": "2484060",
    "end": "2491020"
  },
  {
    "text": "yeah if you guys have thoughts here I guess a part of why I think the function calling works so well is",
    "start": "2491020",
    "end": "2496960"
  },
  {
    "text": "because you have to really over specify your output right like before I could",
    "start": "2496960",
    "end": "2502119"
  },
  {
    "text": "just ask you know return true or false right the input is like 12 tokens the",
    "start": "2502119",
    "end": "2507579"
  },
  {
    "text": "output is one token there's something like cost consistency now for me at least I have like an enum with a",
    "start": "2507579",
    "end": "2514060"
  },
  {
    "text": "description with every attribute I had like this list thing which is which the ref thing and it's in Json and you end",
    "start": "2514060",
    "end": "2520060"
  },
  {
    "text": "up having like way more prompt tokens when you when you ask for that output right",
    "start": "2520060",
    "end": "2525339"
  },
  {
    "text": "um but I think there is at least at some level this like cost consideration of like okay at some point like the prompt",
    "start": "2525339",
    "end": "2531280"
  },
  {
    "text": "tokens actually may add up for simple tasks whereas like I might just want to search if true is in my response string rather",
    "start": "2531280",
    "end": "2538599"
  },
  {
    "text": "than parsing this huge object yeah actually that's",
    "start": "2538599",
    "end": "2544119"
  },
  {
    "text": "I was going to ask how do the tokens work here oh yeah um",
    "start": "2544119",
    "end": "2549280"
  },
  {
    "text": "so what we do is convert the Json schema into a more compact representation which",
    "start": "2549280",
    "end": "2555339"
  },
  {
    "text": "is Loosely looks like typescript it looks like a typescript function that we put into the prompt",
    "start": "2555339",
    "end": "2560800"
  },
  {
    "text": "um and you know when you say for example type string or type number that literally becomes sort of a typescript",
    "start": "2560800",
    "end": "2565900"
  },
  {
    "text": "interface uh where the you know key is on the left side and the typescript types on the right side and we convert",
    "start": "2565900",
    "end": "2572680"
  },
  {
    "text": "um you know the descriptions that you provide into sort of typescript comments um and it's I want to say it's it's",
    "start": "2572680",
    "end": "2577720"
  },
  {
    "text": "Loosely like typescript because we don't fully adhere to typescript the model doesn't need perfect typescript right it",
    "start": "2577720",
    "end": "2582940"
  },
  {
    "text": "is ultimately a reasoning agent based on text um and so that's what we do Under the Hood",
    "start": "2582940",
    "end": "2589000"
  },
  {
    "text": "um the reason we added this extra layer on top is a couple of reasons one it works with existing tools like python",
    "start": "2589000",
    "end": "2595300"
  },
  {
    "text": "take and open API and things like that and two as we change the format under the hood you know especially with the",
    "start": "2595300",
    "end": "2600520"
  },
  {
    "text": "dynamic models as we train them and retrain them the underlying format can change um and so we want to give you guys a",
    "start": "2600520",
    "end": "2607000"
  },
  {
    "text": "stable interface the program against um and then the third thing is",
    "start": "2607000",
    "end": "2613240"
  },
  {
    "text": "um you know Json schema is actually quite powerful it allows things like definitions where you can share objects uh or like you know Define something",
    "start": "2613240",
    "end": "2620079"
  },
  {
    "text": "like an address object in one place and then reuse it in multiple other places um and all those neat features are quite",
    "start": "2620079",
    "end": "2626440"
  },
  {
    "text": "nice um so those are the reasons why we opted for this sort of like higher level interface that's more stable and",
    "start": "2626440",
    "end": "2632500"
  },
  {
    "text": "standardized um but under the hood we sort of change it into a typescript like format and that does save tokens we don't dump the",
    "start": "2632500",
    "end": "2639040"
  },
  {
    "text": "Json schema as is that would be two purpose so we try to make it as compact as possible under the hood yeah",
    "start": "2639040",
    "end": "2646839"
  },
  {
    "text": "actually I'm curious like the before that we had to use this guard rails to do a couple iterations before we can get",
    "start": "2646839",
    "end": "2652300"
  },
  {
    "text": "some structured output from open AI calls like what is happening behind the scenes like how do you structure that",
    "start": "2652300",
    "end": "2657339"
  },
  {
    "text": "like compared to a neural network I'm super curious about it yeah um we're not doing any multiple",
    "start": "2657339",
    "end": "2663099"
  },
  {
    "text": "iterations uh it's just the fine tune is really good uh and so in the very first shot and basically you know in fact if",
    "start": "2663099",
    "end": "2669040"
  },
  {
    "text": "you see a lot of the function examples we're not even few shotting right we're not showing the model here are three",
    "start": "2669040",
    "end": "2674680"
  },
  {
    "text": "ways you know how to get the weather we just give you the description and it works in the first go",
    "start": "2674680",
    "end": "2679960"
  },
  {
    "text": "um and I think that's the magic of the model is in sort of a zero short setting with just a signature it's able to give",
    "start": "2679960",
    "end": "2686319"
  },
  {
    "text": "you pretty good output yeah I love the aspirin to that which is uh sometimes when the schema is invalid uh",
    "start": "2686319",
    "end": "2693819"
  },
  {
    "text": "re-evaluate your own schema so with the graph example when I first tried it I was trying to force it to use like a",
    "start": "2693819",
    "end": "2699579"
  },
  {
    "text": "recursive definition of a node and I kept giving me dependency arrays of integers instead and then I realized",
    "start": "2699579",
    "end": "2706599"
  },
  {
    "text": "that the dependency array with integer is actually just the butter implementation than having this recursive definition so I've already",
    "start": "2706599",
    "end": "2712599"
  },
  {
    "text": "gotten to a place where like gb4 is pushed back on the code I've written and I've changed that through basically",
    "start": "2712599",
    "end": "2717819"
  },
  {
    "text": "validation errors so that was kind of really eye-opening for me",
    "start": "2717819",
    "end": "2722520"
  },
  {
    "text": "um that's incredible one thing I had actually just came to my mind is we also slashed the pricing for prompt tokens",
    "start": "2722920",
    "end": "2729040"
  },
  {
    "text": "for 3.5 turbo in this launch for this reason actually um you know we discovered some sort of",
    "start": "2729040",
    "end": "2735280"
  },
  {
    "text": "like better capturing and operational techniques so that reduces our costs and we always want to pass them on to developers but in this case you know as",
    "start": "2735280",
    "end": "2742420"
  },
  {
    "text": "the prompt gets bigger within context with functions uh those cost savings definitely come in pretty clutch yeah",
    "start": "2742420",
    "end": "2749079"
  },
  {
    "text": "and so you mentioned uh like this is all done in like a zero shot manner are there any benefits to providing few shot",
    "start": "2749079",
    "end": "2755500"
  },
  {
    "text": "examples and if we like how would how would we do that if if we wanted to is that just the same as uh like I think",
    "start": "2755500",
    "end": "2762760"
  },
  {
    "text": "you have the example flag that that is used for traditional chat messages would that be the correct way to do that and",
    "start": "2762760",
    "end": "2768160"
  },
  {
    "text": "do you think that's worth pursuing or yeah yeah totally I think you can still feel",
    "start": "2768160",
    "end": "2774040"
  },
  {
    "text": "short and it might increase the reliability if you have a particularly complicated case and it's not working the way I would do it is use the message",
    "start": "2774040",
    "end": "2780280"
  },
  {
    "text": "history um so you know put some stuff in the system message and then show the assistant you know hey",
    "start": "2780280",
    "end": "2786940"
  },
  {
    "text": "here's how you would respond right in adding an assistant message uh and you could you know",
    "start": "2786940",
    "end": "2791980"
  },
  {
    "text": "give it a name you could say you know every message in addition to the role and content you can provide a name as",
    "start": "2791980",
    "end": "2797740"
  },
  {
    "text": "well you can give it a name like example assistant or something like that um but again the model knows the role",
    "start": "2797740",
    "end": "2804339"
  },
  {
    "text": "and it has attaches semantic meaning to the role and so the way I would do examples is that other than put them in",
    "start": "2804339",
    "end": "2809740"
  },
  {
    "text": "the system message show you a few back and forth between the user and the assistant user and the assistant and now",
    "start": "2809740",
    "end": "2814780"
  },
  {
    "text": "put in the user message and now you'll get a good assistant message back yeah",
    "start": "2814780",
    "end": "2820200"
  },
  {
    "text": "awesome um there's I saw a few questions in the chat and the next top one is basically",
    "start": "2820540",
    "end": "2827380"
  },
  {
    "text": "like um yeah react function calls like is there still any value to to doing",
    "start": "2827380",
    "end": "2834880"
  },
  {
    "text": "some of the like quote unquote thinking and ask it to think before making a function call",
    "start": "2834880",
    "end": "2841359"
  },
  {
    "text": "um and yeah in either yeah what what have people seen there is there any yeah",
    "start": "2841359",
    "end": "2848460"
  },
  {
    "text": "um I think a good character this and then if any of you have as well please jump in um I'm not super uh I haven't used here",
    "start": "2849460",
    "end": "2856480"
  },
  {
    "text": "a lot myself I've played around with a couple of times um of course it's a way to like get the model like think for itself and then use",
    "start": "2856480",
    "end": "2863380"
  },
  {
    "text": "the Tool uh but it's also a way to show the thinking to the user uh you can actually still do that with",
    "start": "2863380",
    "end": "2869140"
  },
  {
    "text": "functions in the prompt if you say what's the weather like in Boston and then you say please describe your",
    "start": "2869140",
    "end": "2874180"
  },
  {
    "text": "thinking first before you call a function it will do that and the in the response you get back you'll get both the content and a function call this is",
    "start": "2874180",
    "end": "2881319"
  },
  {
    "text": "one of those more advanced features that we really should do about a job documenting um but content and function call are not",
    "start": "2881319",
    "end": "2887200"
  },
  {
    "text": "either or they can actually be both be present um and it'll work with streaming as well",
    "start": "2887200",
    "end": "2893319"
  },
  {
    "text": "um so if you just say what's the weather like in Boston please describe your thinking first and only then call a function or you say please tell me a",
    "start": "2893319",
    "end": "2899380"
  },
  {
    "text": "joke first and only then call a function it will do that and then give you both content and function callback",
    "start": "2899380",
    "end": "2906720"
  },
  {
    "text": "I actually had a hard time getting the uh the message content and the function called the return at the same time",
    "start": "2909700",
    "end": "2915579"
  },
  {
    "text": "actually I've actually been doing two calls to uh basically use gbd4 to think step by step by the ngbt 3.5 to get the",
    "start": "2915579",
    "end": "2923020"
  },
  {
    "text": "function call but I definitely found that if you have it it's due Chain of Thought these this like complicated",
    "start": "2923020",
    "end": "2928960"
  },
  {
    "text": "graph planning for example does I would say significantly better I think yeah I think if you look back at",
    "start": "2928960",
    "end": "2935920"
  },
  {
    "text": "where this uh fine tune came from in the plugins use case you go to charge upt it doesn't do much thinking right it's sort",
    "start": "2935920",
    "end": "2941319"
  },
  {
    "text": "of jumps into the plugin immediately uh and so uh that's the use case we've been",
    "start": "2941319",
    "end": "2946720"
  },
  {
    "text": "targeting um but I've definitely been hearing great feedback from everyone that like uh reasoning is really useful uh to uh",
    "start": "2946720",
    "end": "2954220"
  },
  {
    "text": "to figure out what went wrong and it also increases uh quality sometimes yeah",
    "start": "2954220",
    "end": "2959940"
  },
  {
    "text": "and I I guess the last the last question before before we wrap up because we're",
    "start": "2963579",
    "end": "2968680"
  },
  {
    "text": "ending the near the we're ending kind of like the the end um is around basically there or there's",
    "start": "2968680",
    "end": "2975220"
  },
  {
    "text": "a few questions around like reducing kind of like hallucinations basically of of these um function calls and you",
    "start": "2975220",
    "end": "2981940"
  },
  {
    "text": "touched on this a bit earlier uh one of the questions even even mentions like Microsoft guidance so I'll maybe break",
    "start": "2981940",
    "end": "2987460"
  },
  {
    "text": "this up into two questions one like what on the open AI side are you guys trying to bake into the um to the API to to ex",
    "start": "2987460",
    "end": "2996940"
  },
  {
    "text": "to help with that more and then for Francisco Jason and David like are there",
    "start": "2996940",
    "end": "3001980"
  },
  {
    "text": "anything that you guys have seen in terms of prompting strategies to help with this in in the interim",
    "start": "3001980",
    "end": "3008180"
  },
  {
    "text": "yeah um I think the general problem you can bake it out into you want the model",
    "start": "3008180",
    "end": "3013800"
  },
  {
    "text": "to Output structured data and sometimes use its reasoning ability to like also",
    "start": "3013800",
    "end": "3018960"
  },
  {
    "text": "choose what kind of structured data to Output right that's how you can generalize both the tool use problem and the data extraction problem",
    "start": "3018960",
    "end": "3026040"
  },
  {
    "text": "um now you can our structure is just one of many right",
    "start": "3026040",
    "end": "3031079"
  },
  {
    "text": "like Json schema that outputs Json is like one possible structure but what we want to empower developers to do is sort",
    "start": "3031079",
    "end": "3037980"
  },
  {
    "text": "of you define your structure and and sort of mold the model to do to do what you wanted to do there's a few steps to",
    "start": "3037980",
    "end": "3044700"
  },
  {
    "text": "get there it's sort of a crawl walk run the crawl state is what we've just shipped which is the fine tune",
    "start": "3044700",
    "end": "3050460"
  },
  {
    "text": "the walk stage is sort of like what we internally call constraint sampling",
    "start": "3050460",
    "end": "3055920"
  },
  {
    "text": "where essentially and you've seen this in a few of the open source models as well um where uh you know using the large",
    "start": "3055920",
    "end": "3061619"
  },
  {
    "text": "advises you can say hey if there's a you know um a double quotes in a Json output",
    "start": "3061619",
    "end": "3067260"
  },
  {
    "text": "the next token must be a comma or something like that and that just increases the reliability of the output",
    "start": "3067260",
    "end": "3073079"
  },
  {
    "text": "and you can do that with Json you can do that with the ammo some other known formats right where the grammar is now and then sort of the the Run phase is",
    "start": "3073079",
    "end": "3080280"
  },
  {
    "text": "almost uh you know you define your own grammar and guidance is sort of an example of that and you know you can",
    "start": "3080280",
    "end": "3085680"
  },
  {
    "text": "obviously use other ways to Define grammars um where you define the structure in the model basically 100 reliably outputs",
    "start": "3085680",
    "end": "3092280"
  },
  {
    "text": "output structured output and only fills in the gaps where you know model creativity is required",
    "start": "3092280",
    "end": "3098640"
  },
  {
    "text": "um and and it should work with even enabs if you say the enums are a b or c uh we it should 100 guaranteed be only",
    "start": "3098640",
    "end": "3105540"
  },
  {
    "text": "one of those values uh and so you know we're exploring all these approaches certainly there's a lot of like uh you",
    "start": "3105540",
    "end": "3112020"
  },
  {
    "text": "know cool stuff that people have done in in other places and sharing online uh for us what ends up happening is uh",
    "start": "3112020",
    "end": "3118859"
  },
  {
    "text": "doing this at scale with good performance and good safety characteristics uh is the challenge uh",
    "start": "3118859",
    "end": "3124500"
  },
  {
    "text": "and so we're definitely excited about all of these things like this top of mind and we want to shift that yeah",
    "start": "3124500",
    "end": "3130460"
  },
  {
    "text": "you guys move pretty fast so like you know you say that it's it's you know I'm",
    "start": "3134180",
    "end": "3139859"
  },
  {
    "text": "expecting this next week now so I'm just joking uh someone else definitely the fastest place I've ever",
    "start": "3139859",
    "end": "3146880"
  },
  {
    "text": "worked at so yeah yeah no no I won't say one week but yeah",
    "start": "3146880",
    "end": "3152359"
  },
  {
    "text": "just one one comment on on extracting structured data what I found is more",
    "start": "3154819",
    "end": "3161819"
  },
  {
    "text": "than hallucinating is that sometimes uh some other specification results in an",
    "start": "3161819",
    "end": "3166920"
  },
  {
    "text": "undesired answer like for example if you say um candidate name and in the CV example",
    "start": "3166920",
    "end": "3173099"
  },
  {
    "text": "and you don't ask uh I'll add a description it might confuse and also get the company names or the university",
    "start": "3173099",
    "end": "3180119"
  },
  {
    "text": "name so like over specifying it it's it's kind of like the same thing of us",
    "start": "3180119",
    "end": "3185819"
  },
  {
    "text": "as as we have been seeing in prompting like being really really explicit about what you want and using the the schema",
    "start": "3185819",
    "end": "3192059"
  },
  {
    "text": "to uh as the place where you can um be very clear about what you're expecting in terms of the content and",
    "start": "3192059",
    "end": "3198420"
  },
  {
    "text": "obviously you're typing uh helps a lot into the durability of of what you actually get out in in the Json",
    "start": "3198420",
    "end": "3206819"
  },
  {
    "text": "um that's that's my experience like I I didn't find that it was inventing very very strange things uh but more that if",
    "start": "3206819",
    "end": "3215880"
  },
  {
    "text": "you are not really really clear it can add extra things that are not what you're actually looking for",
    "start": "3215880",
    "end": "3223500"
  },
  {
    "text": "and this kind of gets to Jason Point Jason's point where like you know I I think basically you said when having to",
    "start": "3223500",
    "end": "3229260"
  },
  {
    "text": "write these things out for you to be more descriptive and force you to write better prompts which you know seems like a a good thing in the long run anyways",
    "start": "3229260",
    "end": "3236940"
  },
  {
    "text": "yeah so I think sorry no just what was going to say that",
    "start": "3236940",
    "end": "3242880"
  },
  {
    "text": "um the names for each of the properties and the descriptions is prompting at least as I said so it's not like",
    "start": "3242880",
    "end": "3250380"
  },
  {
    "text": "prompting is gone it's just like changed names so it's still very important to to",
    "start": "3250380",
    "end": "3257579"
  },
  {
    "text": "be very clear when one is defining the schema yeah actually quick question on",
    "start": "3257579",
    "end": "3263760"
  },
  {
    "text": "that actually like are there any guidelines around the schema like you know besides be descriptive like you",
    "start": "3263760",
    "end": "3270359"
  },
  {
    "text": "know should names be all lower case should they be all uppercase if you yeah",
    "start": "3270359",
    "end": "3275640"
  },
  {
    "text": "like um any any small things or any guidelines there or just unknown at the moment well nothing really I think you",
    "start": "3275640",
    "end": "3284040"
  },
  {
    "text": "know like it's not just not saying like names are names are prompts and descriptions are prompts and that's the",
    "start": "3284040",
    "end": "3289680"
  },
  {
    "text": "thing you should let me Focus your energy on yeah use good names and and use good descriptions it's almost good",
    "start": "3289680",
    "end": "3294780"
  },
  {
    "text": "habits right for for your own programming uh yeah craft so that's",
    "start": "3294780",
    "end": "3300059"
  },
  {
    "text": "that's all I have yeah yeah my recommendation would have been to read the clean code for textbook",
    "start": "3300059",
    "end": "3305640"
  },
  {
    "text": "because like there was an example when I was doing the query merging where I renamed like multi-query merge so just",
    "start": "3305640",
    "end": "3313020"
  },
  {
    "text": "the word merge and then it completely failed to do the task so simply just renaming a single enum",
    "start": "3313020",
    "end": "3319140"
  },
  {
    "text": "was enough to get the incorrect answer on top of that just like asking for the correct answer versus a answer",
    "start": "3319140",
    "end": "3325559"
  },
  {
    "text": "has like embarrassingly work quite well uh where I was like don't give me the",
    "start": "3325559",
    "end": "3331440"
  },
  {
    "text": "query plan give me the correct and complete query plan and I'll break uh capital of Jason's Home Country to what",
    "start": "3331440",
    "end": "3338220"
  },
  {
    "text": "is Jason's Home Country what is the capital of that country uh so like these",
    "start": "3338220",
    "end": "3343319"
  },
  {
    "text": "small things definitely work and even with having a good schema a lot of it is like if you want to have a function you don't want to have a function with like",
    "start": "3343319",
    "end": "3348960"
  },
  {
    "text": "20 variables and 13 Boolean flags that do all this kind of execution right you want to just build functions that are",
    "start": "3348960",
    "end": "3355380"
  },
  {
    "text": "good readable and uh you know turns out if you write good good functions for AI",
    "start": "3355380",
    "end": "3360599"
  },
  {
    "text": "you write good functions for people too that I think that's a great oh sorry",
    "start": "3360599",
    "end": "3366440"
  },
  {
    "text": "should I add something or should we close yeah real quick we're last thing last thing final words that was a great",
    "start": "3366440",
    "end": "3372960"
  },
  {
    "text": "way to end it if you end if you write good functions for a very good functions for humans this is gonna be even better",
    "start": "3372960",
    "end": "3378540"
  },
  {
    "text": "Francisco um so one one thing I noticed that is an",
    "start": "3378540",
    "end": "3383579"
  },
  {
    "text": "interesting use case as well is if you want to in one in one call get several entities with the properties so say like",
    "start": "3383579",
    "end": "3390660"
  },
  {
    "text": "you want to get all the people that were mentioned with you know the name and their height and the dogs that were",
    "start": "3390660",
    "end": "3397380"
  },
  {
    "text": "mentioned with their names and you know uh their breed and you can also do that",
    "start": "3397380",
    "end": "3402599"
  },
  {
    "text": "by cleverly prompting or using names and descriptions so what it will do is there's an example in the language in",
    "start": "3402599",
    "end": "3408900"
  },
  {
    "text": "those um it will return uh the the person's name and and the the features with with",
    "start": "3408900",
    "end": "3415859"
  },
  {
    "text": "empty and dog attributes right and then it will return like the the dog properties with empty people attribute",
    "start": "3415859",
    "end": "3422760"
  },
  {
    "text": "so in that way like with with some post processing you can get you know two entities with other properties in one",
    "start": "3422760",
    "end": "3428640"
  },
  {
    "text": "call and that's like an example of what color prompting can do for you when you're extracting data",
    "start": "3428640",
    "end": "3434760"
  },
  {
    "text": "foreign all right thank you guys for joining",
    "start": "3434760",
    "end": "3440520"
  },
  {
    "text": "lots to discuss I'm sure we could go on I think the main thing is people probably just need to start experimenting with this because there's",
    "start": "3440520",
    "end": "3446520"
  },
  {
    "text": "a lot of unknowns and a lot of a long long tailed use cases um and thank you guys for for helping",
    "start": "3446520",
    "end": "3453480"
  },
  {
    "text": "explain and helping guide people along that really appreciate it have a good one everyone thank you",
    "start": "3453480",
    "end": "3459240"
  },
  {
    "text": "everyone thanks again foreign",
    "start": "3459240",
    "end": "3464059"
  }
]
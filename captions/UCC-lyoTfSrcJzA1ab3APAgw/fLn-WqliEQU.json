[
  {
    "text": "we are now live so hopefully you should be able to see us now um we yeah sorry for the one to two",
    "start": "0",
    "end": "7140"
  },
  {
    "text": "minute delay but really excited to to get this webinar started so today we're",
    "start": "7140",
    "end": "12599"
  },
  {
    "text": "going to be chatting about output parsing and extraction um and and we'll we're gonna jump into a",
    "start": "12599",
    "end": "19260"
  },
  {
    "text": "bunch of technical concepts related to that see cement to end applications and hopefully learn a bunch",
    "start": "19260",
    "end": "25500"
  },
  {
    "text": "um my name is Harrison uh one of the one of the uh maintainers of link chain the",
    "start": "25500",
    "end": "31140"
  },
  {
    "text": "open source python package we'll do some quick introductions then we'll do some Logistics and then we'll jump right into it so Jeremy do you want to start with a",
    "start": "31140",
    "end": "37320"
  },
  {
    "text": "quick introduction of yourself hi sure um yeah I'm Jeremy I I've worked in um",
    "start": "37320",
    "end": "43920"
  },
  {
    "text": "machine learning and natural language for for a couple of years um and it's exciting to be at the stage",
    "start": "43920",
    "end": "49500"
  },
  {
    "text": "where we're working on the types of problems that that link chain is tackling um I've been working on a few components",
    "start": "49500",
    "end": "54600"
  },
  {
    "text": "within Lang change for for a little while yeah",
    "start": "54600",
    "end": "59180"
  },
  {
    "text": "my name is Eugene I worked with the Arizona Ken show I spent uh about seven",
    "start": "61340",
    "end": "68640"
  },
  {
    "text": "years there working on extraction search engines natural language processing and so on excited to be here today",
    "start": "68640",
    "end": "76520"
  },
  {
    "text": "awesome hello everybody my name is Greg and my background is in B2B products and",
    "start": "76520",
    "end": "81900"
  },
  {
    "text": "uh for 2023 I've been an entrepreneur in the AI space and it's been a ton of fun buildings",
    "start": "81900",
    "end": "88340"
  },
  {
    "text": "awesome so a few Logistics this will be recorded um you can access the recording at the",
    "start": "88860",
    "end": "95040"
  },
  {
    "text": "same link um afterwards um and we're looking into putting the the videos on YouTube",
    "start": "95040",
    "end": "100560"
  },
  {
    "text": "um if you have questions we're going to spend a lot of time doing audience question answering please put the",
    "start": "100560",
    "end": "105720"
  },
  {
    "text": "questions in not the general chat but the Q a bar on the right",
    "start": "105720",
    "end": "111000"
  },
  {
    "text": "um so if you look there's a general chat box at the top and then the second one down is q a you can also vote on",
    "start": "111000",
    "end": "116280"
  },
  {
    "text": "questions that you think are most interesting and so after we go through the initial round of presentations we",
    "start": "116280",
    "end": "121619"
  },
  {
    "text": "will go through the the questions there kind of ranked by the ones that the club voted for the most so please pop over",
    "start": "121619",
    "end": "128340"
  },
  {
    "text": "there ask ask questions there and we'll do that at the end um the topic of today's is outward",
    "start": "128340",
    "end": "135360"
  },
  {
    "text": "parsing and extraction so we'll probably Focus mostly on that there will be lots of webinars on different Topics in the",
    "start": "135360",
    "end": "141480"
  },
  {
    "text": "future um so if you have questions around agents or any of those other things we",
    "start": "141480",
    "end": "146879"
  },
  {
    "text": "will likely save those for a future webinar um so we're going to keep today very focused on output parsing and extraction",
    "start": "146879",
    "end": "154319"
  },
  {
    "text": "um I think that's pretty much it for Logistics so we'll start with some quick",
    "start": "154319",
    "end": "159420"
  },
  {
    "text": "uh demos five to ten minutes from from everyone and then jump into q a so Jeremy you are up first",
    "start": "159420",
    "end": "167700"
  },
  {
    "text": "great let me share okay",
    "start": "167700",
    "end": "173519"
  },
  {
    "text": "so I'm I'm quickly gonna demo something that undoubtedly Harrison has has",
    "start": "173519",
    "end": "178739"
  },
  {
    "text": "tweeted out already but this is kind of a core data structure um that showed up in the library related",
    "start": "178739",
    "end": "184379"
  },
  {
    "text": "to this subject so I'll give a really quick walkthrough of I mean this notebook is checked into the repo but",
    "start": "184379",
    "end": "189840"
  },
  {
    "text": "just to sort of set the stage here um I mean programming over time has gotten more declarative and obviously",
    "start": "189840",
    "end": "195540"
  },
  {
    "text": "language models have have accelerated that quite a bit um and and sort of like the concept here",
    "start": "195540",
    "end": "200819"
  },
  {
    "text": "is um you know not only are we declaring like tasks or some of like these",
    "start": "200819",
    "end": "206340"
  },
  {
    "text": "functional requirements to language models we can also um declare and and sort of constrain exactly what we want the output to look",
    "start": "206340",
    "end": "212940"
  },
  {
    "text": "like and meaning here more like structured data types so in um in Lang",
    "start": "212940",
    "end": "218159"
  },
  {
    "text": "chain we we use pedantic um which is which is sort of like data classes it's a nice um tool for interface definitions",
    "start": "218159",
    "end": "225599"
  },
  {
    "text": "but also has a lot of kind of nice strong typing guarantees um and and the pattern that the pattern",
    "start": "225599",
    "end": "232019"
  },
  {
    "text": "that we've been using and that works pretty pretty well um is is to",
    "start": "232019",
    "end": "238760"
  },
  {
    "text": "specify sort of the data you want out from this black box from this language model",
    "start": "238760",
    "end": "243840"
  },
  {
    "text": "um as a as a data class and and then let Lang chain sort of handle some of the some of the bits Below in terms of",
    "start": "243840",
    "end": "251040"
  },
  {
    "text": "getting getting the language model to format things correctly so let's see",
    "start": "251040",
    "end": "257540"
  },
  {
    "text": "I'll show sort of a demonstrative case um here here's a data structure that we'd like to populate with a language",
    "start": "257880",
    "end": "264419"
  },
  {
    "text": "model and this is this is some sort of joke and there's some sort of setup and some sort of punch line and you know it",
    "start": "264419",
    "end": "269759"
  },
  {
    "text": "doesn't entirely matter what that means um you might get some user queries or some inputs intermediate inputs to a",
    "start": "269759",
    "end": "277259"
  },
  {
    "text": "language model and the idea there is we want to populate this data structure in line chain we we Define this schema or",
    "start": "277259",
    "end": "284460"
  },
  {
    "text": "the interface that we we want to we want to populate we have a query that's going to do that population and then we go",
    "start": "284460",
    "end": "290699"
  },
  {
    "text": "through setting up sort of the you know input prompts the output parsing and we can run you know this user query through",
    "start": "290699",
    "end": "296520"
  },
  {
    "text": "the model and and so and and very nicely like you know",
    "start": "296520",
    "end": "302880"
  },
  {
    "text": "the language model does this you'll note above I'm using DaVinci O3 and I'll make a note about that in a second so here's",
    "start": "302880",
    "end": "308699"
  },
  {
    "text": "another quick kind of um slightly contrived example um and here there's like a you know",
    "start": "308699",
    "end": "314160"
  },
  {
    "text": "structured or compound data type there's a list of strengths within within um yeah so I mentioned you know this is",
    "start": "314160",
    "end": "320100"
  },
  {
    "text": "this is DaVinci O3 and and of course like you know a lot of folks are familiar with scaling",
    "start": "320100",
    "end": "326400"
  },
  {
    "text": "laws and sort of capabilities that arise if you try to um you know ask too much of of sort of a",
    "start": "326400",
    "end": "332280"
  },
  {
    "text": "a smaller model than than maybe like the capabilities won't be there to actually reliably and robustly kind of populate",
    "start": "332280",
    "end": "338580"
  },
  {
    "text": "these data structures but um you know capabilities are increasing really fast and and we're sort of building for a lot of like anticipated",
    "start": "338580",
    "end": "346620"
  },
  {
    "text": "um and anticipated stuff here I want to show one more minute Jeremy I have a quick question so this looks like magic",
    "start": "346620",
    "end": "351840"
  },
  {
    "text": "what's what's actually going on under the hood like you know this is this is obfuscating a lot of like real really",
    "start": "351840",
    "end": "358440"
  },
  {
    "text": "clever kind of like logic and prompt engineering or like I think people would be interested to kind of like hear how",
    "start": "358440",
    "end": "363539"
  },
  {
    "text": "yeah yeah absolutely absolutely not so there's some or absolutely there's some",
    "start": "363539",
    "end": "369900"
  },
  {
    "text": "there's some like little bits here that might give you a sense of what's going on and it's really this one comment here",
    "start": "369900",
    "end": "375479"
  },
  {
    "text": "um yeah essentially essentially like this this schema is is defining some",
    "start": "375479",
    "end": "381900"
  },
  {
    "text": "instructions for the language model and and um when we build a parser and we we",
    "start": "381900",
    "end": "387360"
  },
  {
    "text": "reference the specific schema with this par parser we're um under the hood generating some instructions to the",
    "start": "387360",
    "end": "393479"
  },
  {
    "text": "language model and how um how the completions should like what what sort of shapes they should adhere",
    "start": "393479",
    "end": "398819"
  },
  {
    "text": "to um and if they adhere to those shapes then uh after the language model would",
    "start": "398819",
    "end": "404520"
  },
  {
    "text": "be prompted to generate that shape and then when we get a completion we'll do some formatting under the hood",
    "start": "404520",
    "end": "409800"
  },
  {
    "text": "um so there's some basically you know there's some instructions to the language model as as per usual as in the",
    "start": "409800",
    "end": "414900"
  },
  {
    "text": "prompting Paradigm and then at the output we apply some you know Insanity checks and so forth",
    "start": "414900",
    "end": "421080"
  },
  {
    "text": "um so it's a it's fairly simple right it's just these are also just natural language instructions about what kind of",
    "start": "421080",
    "end": "427160"
  },
  {
    "text": "non-natural language outputs we want um but but there are there are extensions built on top of this",
    "start": "427160",
    "end": "432720"
  },
  {
    "text": "obviously like I said um you know language models are or leaky abstractions we need really big models",
    "start": "432720",
    "end": "438240"
  },
  {
    "text": "to to do some of these or to have some of these capabilities for now um but even still there's still",
    "start": "438240",
    "end": "443460"
  },
  {
    "text": "Randomness and it'll fail sometimes so we'd like to leverage like other utilities within like chains or like",
    "start": "443460",
    "end": "449340"
  },
  {
    "text": "um you know things like guardrails to to make sure these completions conform to what we",
    "start": "449340",
    "end": "454560"
  },
  {
    "text": "want um can we can we see what the actual input to the looks like",
    "start": "454560",
    "end": "460139"
  },
  {
    "text": "um so there's like can we see what like input to string looks like or something like that yeah yeah I think yeah",
    "start": "460139",
    "end": "467960"
  },
  {
    "text": "so here's yeah here's here's the prompt explicitly and it's quite simple here when when it's it's just this raw",
    "start": "473699",
    "end": "481259"
  },
  {
    "text": "um so it really is it's like a single shot or I suppose a two two shot example",
    "start": "481259",
    "end": "486419"
  },
  {
    "text": "here um pedantic and and Jason Json are um you can convert back and forth very",
    "start": "486419",
    "end": "493919"
  },
  {
    "text": "easily and and so essentially like we've we've defined some schema up top here",
    "start": "493919",
    "end": "499080"
  },
  {
    "text": "um and and we've dumped a minified I think a minified version of that schema into context",
    "start": "499080",
    "end": "504780"
  },
  {
    "text": "um and it's it's really a simple as simple as that here and so the the descriptions",
    "start": "504780",
    "end": "514560"
  },
  {
    "text": "um are are put in basically the like name of an actor those are all used in",
    "start": "514560",
    "end": "520080"
  },
  {
    "text": "in this Json thing and so that's kind of like you know the language model is taking cute like if you it's not going",
    "start": "520080",
    "end": "525600"
  },
  {
    "text": "to magically know kind of like what a variable means unless you like tell it what it means yeah yeah so there there's this like",
    "start": "525600",
    "end": "532560"
  },
  {
    "text": "very very neat thing happening here that that is sort of like SEC the second level or something where we're we're",
    "start": "532560",
    "end": "538080"
  },
  {
    "text": "actually like we're not just defining sort of an interface and like what shape we want our data to take we're actually",
    "start": "538080",
    "end": "543779"
  },
  {
    "text": "um like defining what we want that data to be and so we're inducing actually inducing tasks here by",
    "start": "543779",
    "end": "550140"
  },
  {
    "text": "um you know specifying the description on these fields so if I show like maybe I don't know I call this moderately more",
    "start": "550140",
    "end": "556560"
  },
  {
    "text": "real world example um and and just to give another sense of that so",
    "start": "556560",
    "end": "563940"
  },
  {
    "text": "um yeah in in this scenario I'm imagining like it more of like a you know",
    "start": "563940",
    "end": "569700"
  },
  {
    "text": "conventional um chat bot application which is you know all the rage right now and and maybe some like customer",
    "start": "569700",
    "end": "575820"
  },
  {
    "text": "conversations like a sales conversation or something and and you can imagine like taking a a transcript with a",
    "start": "575820",
    "end": "582420"
  },
  {
    "text": "customer and you want to know like what happened like did they buy something or did they not buy and and sort of why and",
    "start": "582420",
    "end": "587459"
  },
  {
    "text": "that's like these are like very common use cases for like the unstructured conversations you get in that setting so",
    "start": "587459",
    "end": "593760"
  },
  {
    "text": "so I actually want I actually want like the data structure I get out to to basically do classification for me I",
    "start": "593760",
    "end": "600600"
  },
  {
    "text": "wanted to assign a value in this in them and I also I don't just want this classification but I also want some like",
    "start": "600600",
    "end": "606779"
  },
  {
    "text": "summarization um like some attractive tasks here where I say also like why did that outcome",
    "start": "606779",
    "end": "612360"
  },
  {
    "text": "occur so I've defined those in I set up the prompt in the same way where right I've just dumped somewhere",
    "start": "612360",
    "end": "619260"
  },
  {
    "text": "in my prompt I want the the instructions on how to format this stuff and then you know pass that in currently via this",
    "start": "619260",
    "end": "625140"
  },
  {
    "text": "parser thing and um and now here's here's a customer you know the the customer output we want to",
    "start": "625140",
    "end": "632700"
  },
  {
    "text": "do some classification and summarization against um you know it does like a reasonably",
    "start": "632700",
    "end": "639120"
  },
  {
    "text": "reasonably good job here so it assigns it to the right unknown value and then and also like the language model",
    "start": "639120",
    "end": "645000"
  },
  {
    "text": "generates a reasonable um a reasonable summarization and you know you I get you probably scale up",
    "start": "645000",
    "end": "650279"
  },
  {
    "text": "this input a bit for full conversations and so forth but it's quite neat here um it's exactly what Harrison was getting",
    "start": "650279",
    "end": "655500"
  },
  {
    "text": "at that sort of the um the description of this field induces these different tasks under the hood",
    "start": "655500",
    "end": "662640"
  },
  {
    "text": "and and I like how the description of one field is just Why question mark and that's it and the language model still",
    "start": "662640",
    "end": "668760"
  },
  {
    "text": "is smart enough to know what to do also if you scroll back down to the bottom just because I did see a question about this you can see here that the whole",
    "start": "668760",
    "end": "675000"
  },
  {
    "text": "prompt is printed out and so you can easily kind of get this by setting like verbose equals true in the llm chain in",
    "start": "675000",
    "end": "681660"
  },
  {
    "text": "in that line um and then we also have uh like like there's a lot of complexity in these",
    "start": "681660",
    "end": "687779"
  },
  {
    "text": "prompts right now you've got like these kind of complex instructions for how to think about it you want to make sure that the user inputs handled okay so so",
    "start": "687779",
    "end": "694140"
  },
  {
    "text": "verbose equals true varic is very handy for that there's also a concept called tracing which I'll send a link to in the",
    "start": "694140",
    "end": "699660"
  },
  {
    "text": "chat which basically takes um which basically visualizes a lot of the inputs and outputs to the language",
    "start": "699660",
    "end": "704940"
  },
  {
    "text": "models um because again there's kind of like this complex pipeline to construct these prompts um wanna you want to do some sanity",
    "start": "704940",
    "end": "711420"
  },
  {
    "text": "checks on the mixer it's okay so I'll throw a link to that in the in the chat because I did see a question about that and it is a very important part of",
    "start": "711420",
    "end": "718380"
  },
  {
    "text": "debugging applications cool I I have Harrison I have some some",
    "start": "718380",
    "end": "726720"
  },
  {
    "text": "bits to show but maybe you can come back to this a little later around um sort of the planning and replanting",
    "start": "726720",
    "end": "733500"
  },
  {
    "text": "and but that's a little bit of an extension or a preview off of this so we could maybe come back after after core",
    "start": "733500",
    "end": "739320"
  },
  {
    "text": "and so forth yeah I think that I think the retry stuff would be really interesting to",
    "start": "739320",
    "end": "744420"
  },
  {
    "text": "show but uh actually should we just do the retry stuff right now because I think that's",
    "start": "744420",
    "end": "750480"
  },
  {
    "text": "um that should be pretty fast and and yeah sure right yeah",
    "start": "750480",
    "end": "756779"
  },
  {
    "text": "I'll show quickly um if I can share again",
    "start": "756779",
    "end": "761180"
  },
  {
    "text": "okay this is this is um a related to parsing but also slightly different I",
    "start": "763139",
    "end": "768240"
  },
  {
    "text": "mean I think in kind of the the discourse this this this topic is is um the term you usually use as like",
    "start": "768240",
    "end": "774720"
  },
  {
    "text": "guards or guard rails where we're talking about you get some completion from the language model and",
    "start": "774720",
    "end": "779760"
  },
  {
    "text": "um you know this again it's from this like non-deterministic thing and so we probably want to do some validation and",
    "start": "779760",
    "end": "786300"
  },
  {
    "text": "and maybe optionally like if the validation fails we might want to um you know try again basically",
    "start": "786300",
    "end": "792540"
  },
  {
    "text": "um re-query the model and so uh I'll I'm gonna go through this relatively quickly but just maybe",
    "start": "792540",
    "end": "799200"
  },
  {
    "text": "suffice it to say it's a sneak preview of some things being worked on and that will be available so the application",
    "start": "799200",
    "end": "805920"
  },
  {
    "text": "here I have these different um API specifications if you're familiar with open API specifications quite",
    "start": "805920",
    "end": "813660"
  },
  {
    "text": "popular in recent weeks in in this domain um I don't know if this is loaded",
    "start": "813660",
    "end": "820920"
  },
  {
    "text": "cool so so there's an open AI open API specification specification for open AI",
    "start": "820920",
    "end": "826980"
  },
  {
    "text": "for karna which is this shopping website for for Spotify",
    "start": "826980",
    "end": "832380"
  },
  {
    "text": "um and the the tasks that the tasks that I'm playing with here is basically you",
    "start": "832380",
    "end": "838079"
  },
  {
    "text": "know oftentimes you have a query against against some API but resolving that query actually requires like a couple",
    "start": "838079",
    "end": "844380"
  },
  {
    "text": "different get and post requests and a lot of a lot of interesting work",
    "start": "844380",
    "end": "850860"
  },
  {
    "text": "um both in in like research and an application coming out around around language models orchestrating against",
    "start": "850860",
    "end": "856680"
  },
  {
    "text": "apis um but again we're going to run into some of the same issues around hallucination and Randomness and so",
    "start": "856680",
    "end": "862320"
  },
  {
    "text": "forth and so let me show sort of an example here uh uh generate",
    "start": "862320",
    "end": "869160"
  },
  {
    "text": "so I'm actually printing out a bunch of stuff so you can see what's happening so my my prompt is is to instruct this",
    "start": "869160",
    "end": "874500"
  },
  {
    "text": "language model you're some sort of planner and I want you to string together a sequence of API calls",
    "start": "874500",
    "end": "880019"
  },
  {
    "text": "um to accomplish them user query and then I have some few shots here and then I actually dump and now here you'll",
    "start": "880019",
    "end": "887100"
  },
  {
    "text": "you'll recognize probably a lot of the open AI um specification here so when I",
    "start": "887100",
    "end": "894959"
  },
  {
    "text": "um let's see",
    "start": "894959",
    "end": "898040"
  },
  {
    "text": "actually it's working fairly reliably",
    "start": "902279",
    "end": "906680"
  },
  {
    "text": "here here's an example you'll note I ran it a few times and you know sometimes randomly it works sometimes it doesn't and I'm using intentionally um DaVinci",
    "start": "908760",
    "end": "915420"
  },
  {
    "text": "zero zero one where maybe maybe it's more likely I see some um you know undefined or behavior",
    "start": "915420",
    "end": "922079"
  },
  {
    "text": "um so so what happened here was there there's a plan or a sequence of API calls that were generated but at least",
    "start": "922079",
    "end": "928560"
  },
  {
    "text": "one of these things this endpoint did not exist in my prompt there's there is only a post embedding standpoint there's",
    "start": "928560",
    "end": "933839"
  },
  {
    "text": "no get embeddings endpoint um and and basically you know it's it's fairly reasonable or like fairly",
    "start": "933839",
    "end": "940620"
  },
  {
    "text": "unsurprising that a hallucination like this would happen but okay like what do we do in the in an actual application",
    "start": "940620",
    "end": "946500"
  },
  {
    "text": "um and and so under the hood here essentially what's going on is I I've applied some validation logic much like",
    "start": "946500",
    "end": "953399"
  },
  {
    "text": "where the parsing logic is applied um who gathered that that some endpoint has",
    "start": "953399",
    "end": "960360"
  },
  {
    "text": "been you know created out of thin air and then I I've basically re-prompted under the hood um the language model to to okay I want",
    "start": "960360",
    "end": "967320"
  },
  {
    "text": "you to retry with this query and and keep in mind the error that you've just made and try not to make that error again essentially what's happening there",
    "start": "967320",
    "end": "973380"
  },
  {
    "text": "and you know I can show like a similar example here's the karna API if if folks are familiar with",
    "start": "973380",
    "end": "981060"
  },
  {
    "text": "the the client-up plugins that have been released here there's actually just one there's just one endpoint on this API",
    "start": "981060",
    "end": "986940"
  },
  {
    "text": "and now I have these kind of fake few shot endpoints and so it's actually seems somewhat likely that that the model will be confused and sure enough",
    "start": "986940",
    "end": "993360"
  },
  {
    "text": "the completion hallucinates a bunch of like this is there's no get endpoint with this query param keyboard",
    "start": "993360",
    "end": "1000560"
  },
  {
    "text": "um and so again we raised some sort of like parsing time or validation time error and then we can retry and actually",
    "start": "1000560",
    "end": "1007339"
  },
  {
    "text": "upon retrying we get something we get something nice out so um yeah the purpose purpose here is just",
    "start": "1007339",
    "end": "1013699"
  },
  {
    "text": "to show a little bit um you know some of the ideas around what we can do with guardrails and and sort",
    "start": "1013699",
    "end": "1020600"
  },
  {
    "text": "of like trigging the completions as Dynamic and and so forth but probably a lot more to say on this later",
    "start": "1020600",
    "end": "1027760"
  },
  {
    "text": "Harrison can I turn back to you yeah yeah no I think we'll definitely talk more yeah this is this is a a more",
    "start": "1028400",
    "end": "1036199"
  },
  {
    "text": "complex end-to-end use case um and so there's uh but but there's a",
    "start": "1036199",
    "end": "1041720"
  },
  {
    "text": "lot of interesting kind of like ideas around you know you've tried parsing and and it doesn't work you get some bad",
    "start": "1041720",
    "end": "1047480"
  },
  {
    "text": "response either it's misformatted or or the value like in Jeremy's case the values are actually wrong",
    "start": "1047480",
    "end": "1053419"
  },
  {
    "text": "um so uh so so this concepts are on parsing and then retrying and then",
    "start": "1053419",
    "end": "1059000"
  },
  {
    "text": "fixing um all all kinds of like related and all a bit more advanced but anyways on to",
    "start": "1059000",
    "end": "1064039"
  },
  {
    "text": "the next section Eugene do you want to take over",
    "start": "1064039",
    "end": "1068260"
  },
  {
    "text": "hello everyone I hope everybody can see the screen so I'll uh talk to you a",
    "start": "1075620",
    "end": "1080840"
  },
  {
    "text": "little bit about core uh it's a library I started working on uh maybe a month ago to try and uh figure out how to",
    "start": "1080840",
    "end": "1088220"
  },
  {
    "text": "extract information uh using large language models uh uh it's built in",
    "start": "1088220",
    "end": "1094039"
  },
  {
    "text": "double blank chain and the goal is to be able to provide a little bit more of an end-to-end uh",
    "start": "1094039",
    "end": "1100760"
  },
  {
    "text": "use cases for extraction or query analysis um",
    "start": "1100760",
    "end": "1106160"
  },
  {
    "text": "so the main thing that you're doing is you're also declaratively trying to specify what it is that you're trying to",
    "start": "1106160",
    "end": "1112760"
  },
  {
    "text": "extractually specify a schema and then you also provide examples and the idea is that by providing a little bit",
    "start": "1112760",
    "end": "1117980"
  },
  {
    "text": "examples that are nuanced you will be able to guide dllm to be more accurate",
    "start": "1117980",
    "end": "1124340"
  },
  {
    "text": "and extract results better so uh core uses uh it's an internal schema",
    "start": "1124340",
    "end": "1130580"
  },
  {
    "text": "definition so it has a concept of an object text number uh it's fairly straightforward but you can say I have",
    "start": "1130580",
    "end": "1137240"
  },
  {
    "text": "an object that's a person uh and uh you can uh say that the person",
    "start": "1137240",
    "end": "1144260"
  },
  {
    "text": "actually has an attribute which is a first name and provide a few examples of how to extract this object from a",
    "start": "1144260",
    "end": "1150740"
  },
  {
    "text": "piece of text you say Alice and Bob are friends I have two people actually need a piece of text one of the Visalus the",
    "start": "1150740",
    "end": "1155900"
  },
  {
    "text": "other one is Bob uh once you declare what you want uh you create a lunch chain uh chain",
    "start": "1155900",
    "end": "1162919"
  },
  {
    "text": "uh and I'm using actually chat uh gpt3 and I have uh 3.5 as the underlying",
    "start": "1162919",
    "end": "1171080"
  },
  {
    "text": "language model the nice thing is that it makes things pretty cheap",
    "start": "1171080",
    "end": "1176140"
  },
  {
    "text": "uh and then I can run extraction and I uh have some text sentences test",
    "start": "1176840",
    "end": "1183140"
  },
  {
    "text": "sentences here and you can take a look at the results so the the response here is a little bit more complex contains",
    "start": "1183140",
    "end": "1189020"
  },
  {
    "text": "information about uh W so it has the Royal LM response it has a field for the",
    "start": "1189020",
    "end": "1195380"
  },
  {
    "text": "data that was extracted so this isn't just the uh the decoded response and",
    "start": "1195380",
    "end": "1200600"
  },
  {
    "text": "then I'll show you in a little bit uh things that are associated with the validated uh data so you can also uh uh",
    "start": "1200600",
    "end": "1207820"
  },
  {
    "text": "validate the output using bidantic uh",
    "start": "1207820",
    "end": "1213020"
  },
  {
    "text": "and just what happens under the hoods of the source of the schema that we declared",
    "start": "1213020",
    "end": "1218360"
  },
  {
    "text": "under the hood uh well core assembles of prompt for the large uh for the llm so",
    "start": "1218360",
    "end": "1225140"
  },
  {
    "text": "it creates uh typescript uh uh description of the schema uh here it's a",
    "start": "1225140",
    "end": "1232039"
  },
  {
    "text": "really simple one and then uh it also collects the examples from all of the",
    "start": "1232039",
    "end": "1237260"
  },
  {
    "text": "fields and in this case it uses a CSV encoding so uh the input sentence was Alice and",
    "start": "1237260",
    "end": "1245299"
  },
  {
    "text": "Bob our friends and the CSV encoding this is the column name this is the first rail the second round volume uh",
    "start": "1245299",
    "end": "1252200"
  },
  {
    "text": "and there are different encoders that can be used uh we'll see that in a second",
    "start": "1252200",
    "end": "1257980"
  },
  {
    "text": "uh so before I show a few more examples just the the two kind of main uh use",
    "start": "1258500",
    "end": "1264380"
  },
  {
    "text": "cases uh occasion in my mind for structuring and structured data one of them is uh data extraction so you might",
    "start": "1264380",
    "end": "1271640"
  },
  {
    "text": "have a PDF or an HTML or some other text document and uh you're trying to extract",
    "start": "1271640",
    "end": "1277039"
  },
  {
    "text": "information out of them so that you can put into a database and maybe do power some Downstream application another use",
    "start": "1277039",
    "end": "1283760"
  },
  {
    "text": "case that I spent a lot of time on is query analysis so maybe you're trying to write a search engine and uh uh some of",
    "start": "1283760",
    "end": "1291980"
  },
  {
    "text": "the issues a query that says I want articles about LMS or large language models from 1992. and you could",
    "start": "1291980",
    "end": "1300140"
  },
  {
    "text": "you could just write an embedding and try to embed and find a similar documents or you might realize oh the",
    "start": "1300140",
    "end": "1306320"
  },
  {
    "text": "embedding is actually not precise enough so actually I want to First Analyze This query figure out that uh the user is",
    "start": "1306320",
    "end": "1312740"
  },
  {
    "text": "trying to find a keyword which is uh llm an exact phrase which is large language model and also apply a filter on the",
    "start": "1312740",
    "end": "1319640"
  },
  {
    "text": "publication date and then formulate a more complex square that will be uh more precise or more relevant you can also",
    "start": "1319640",
    "end": "1326480"
  },
  {
    "text": "use it to power an API so if you have VPN API for some simplified music player and the user is asking you to play",
    "start": "1326480",
    "end": "1332120"
  },
  {
    "text": "Yellow Submarine by the Beatles you can realize oh The Beatles are an artist and the Yellow Submarine is a song where an",
    "start": "1332120",
    "end": "1337580"
  },
  {
    "text": "album uh so this is similar to what uh uh",
    "start": "1337580",
    "end": "1343880"
  },
  {
    "text": "Jeremy just showed us you can also use pedantic to declare all of the schema which I think is quite convenient because you",
    "start": "1343880",
    "end": "1349760"
  },
  {
    "text": "also get all of my identics uh validation capabilities out of the box so this is an example that uh",
    "start": "1349760",
    "end": "1357860"
  },
  {
    "text": "talks with a music player so uh",
    "start": "1357860",
    "end": "1363559"
  },
  {
    "text": "you can request a song an album an artist you can also say you can declare an action so you want to stop playing or",
    "start": "1363559",
    "end": "1369440"
  },
  {
    "text": "I play the previous song again um so each of the fields you provide a short description for uh if you want you",
    "start": "1369440",
    "end": "1376820"
  },
  {
    "text": "can provide some examples if you're saying that the parser is not able to understand certain queries",
    "start": "1376820",
    "end": "1384260"
  },
  {
    "text": "there's functionality to convert it by identity to internal core schema and then uh",
    "start": "1384260",
    "end": "1390820"
  },
  {
    "text": "actually so so internal course schema like what are like why not just use pedantic what are the benefits of the",
    "start": "1391120",
    "end": "1397580"
  },
  {
    "text": "internal schema that you wrote at the moment None So at the moment just",
    "start": "1397580",
    "end": "1403659"
  },
  {
    "text": "in the future there might be some so at the moments let's read this is just an over abstraction but that's where I got",
    "start": "1403659",
    "end": "1410059"
  },
  {
    "text": "started so I got started writing my own uh schema because I wasn't I did not know that identity could support metadata on fields so that's just",
    "start": "1410059",
    "end": "1416900"
  },
  {
    "text": "historical and by metadata and field you mean like description and examples and",
    "start": "1416900",
    "end": "1423500"
  },
  {
    "text": "exactly I guess yeah and I guess actually yeah so so you have like first class support for like a specific",
    "start": "1423500",
    "end": "1429500"
  },
  {
    "text": "examples field right and I guess pedantic allows you to attach arbitrary metadata but it's not necessarily like",
    "start": "1429500",
    "end": "1437740"
  },
  {
    "text": "uh exactly so pedantic allows you to just drop in the examples and I I just converted into uh uh internal core",
    "start": "1437900",
    "end": "1445600"
  },
  {
    "text": "attribute which is called examples um and have you found like like when should",
    "start": "1445600",
    "end": "1452539"
  },
  {
    "text": "people think about using examples um like yeah have you found them to be pretty useful in any most particular",
    "start": "1452539",
    "end": "1459020"
  },
  {
    "text": "place or uh in general uh including at least one example in my experience really helps",
    "start": "1459020",
    "end": "1466280"
  },
  {
    "text": "the model figure out uh how to follow the schema correctly so without a single example",
    "start": "1466280",
    "end": "1473419"
  },
  {
    "text": "often it will just not produce exactly correct Json so or it might or the Json might be correct but the fields uh this",
    "start": "1473419",
    "end": "1482000"
  },
  {
    "text": "uh it will not capture the schema in the correct way so you won't be able to actually parse your data so just a few",
    "start": "1482000",
    "end": "1489080"
  },
  {
    "text": "examples help it figure out what it is what does it mean to actually follow typescript data but also I think it",
    "start": "1489080",
    "end": "1496340"
  },
  {
    "text": "helps in some senses in some situations to disambiguate in terms of what you mean so what is an address there's an",
    "start": "1496340",
    "end": "1502340"
  },
  {
    "text": "address just a city is it a state do you need to have a street name for an address to be valid so providing a few a",
    "start": "1502340",
    "end": "1509539"
  },
  {
    "text": "description a few examples uh uh can help the llm produce better",
    "start": "1509539",
    "end": "1515840"
  },
  {
    "text": "results but I would just test it out on your use case figure out if it works if it does create if it",
    "start": "1515840",
    "end": "1522380"
  },
  {
    "text": "doesn't consider adding a few additional examples awesome uh",
    "start": "1522380",
    "end": "1527659"
  },
  {
    "text": "so this is a test query now placate Scandal by Yusuf or Johnny Cash and uh",
    "start": "1527659",
    "end": "1533720"
  },
  {
    "text": "we got the song request we got both artists parsed out which is fantastic",
    "start": "1533720",
    "end": "1540440"
  },
  {
    "text": "because we hardly have to do anything except for declare a schema uh and this is for this more complicated",
    "start": "1540440",
    "end": "1547279"
  },
  {
    "text": "example this is the typescript that got generated so this is the schema and all of the examples were collected from the",
    "start": "1547279",
    "end": "1553039"
  },
  {
    "text": "individual fields to create uh at this section so",
    "start": "1553039",
    "end": "1559159"
  },
  {
    "text": "and there are a few tricks that I'm using some including Json instead of Json tags you can also use triple quotes",
    "start": "1559159",
    "end": "1564919"
  },
  {
    "text": "uh but some of these trick tricks help protect against uh the model trying to",
    "start": "1564919",
    "end": "1571039"
  },
  {
    "text": "provide clarifications even though we ask it not to clarify anything um",
    "start": "1571039",
    "end": "1576380"
  },
  {
    "text": "and so on uh so uh core supports uh",
    "start": "1576380",
    "end": "1582440"
  },
  {
    "text": "doing coding strike that I would recommend for usage one of them is a CSV encoding uh the other one is a Json",
    "start": "1582440",
    "end": "1588860"
  },
  {
    "text": "encoding so this is uh you've just seen the Json encoding a c-screen coding is uh potentially better for a use case",
    "start": "1588860",
    "end": "1596779"
  },
  {
    "text": "where you're trying to extract a lot of the a lot of information from some section of text",
    "start": "1596779",
    "end": "1602960"
  },
  {
    "text": "why do you think that it this is anecdotal based on what other people have pensions and also uh uh it",
    "start": "1602960",
    "end": "1611539"
  },
  {
    "text": "seems that online advice seems to suggest using CSV",
    "start": "1611539",
    "end": "1616760"
  },
  {
    "text": "encoding if you're trying to pass the extract stuff uh the uh so we need benchmarks so without",
    "start": "1616760",
    "end": "1623960"
  },
  {
    "text": "benchmarks it's hard to claim for sure but it seems that there's not enough anecdotal evidence right now uh",
    "start": "1623960",
    "end": "1629900"
  },
  {
    "text": "if you can just use a CSC encoder uh the CSV encoder in the library right now",
    "start": "1629900",
    "end": "1636080"
  },
  {
    "text": "does not support any embedded lists or objects so it's a little bit less flexible but potentially more accurate",
    "start": "1636080",
    "end": "1642799"
  },
  {
    "text": "uh so here's an example with a very simple scheme of a person the person has",
    "start": "1642799",
    "end": "1648919"
  },
  {
    "text": "a name and an age and uh there's a short story here about my",
    "start": "1648919",
    "end": "1654980"
  },
  {
    "text": "grandmother came today she's 90 years old her name is Mary I'm 30 years old my name is Alice Lee is 29 we're all going",
    "start": "1654980",
    "end": "1661039"
  },
  {
    "text": "to a birthday party for Brenda who is two years older than Mary my grandfather is quite old you'll be also at the",
    "start": "1661039",
    "end": "1666500"
  },
  {
    "text": "birthday party he is 80. there will be cake my grandfather's name is Bob uh",
    "start": "1666500",
    "end": "1671900"
  },
  {
    "text": "and uh yeah you can uh you could",
    "start": "1671900",
    "end": "1677840"
  },
  {
    "text": "try this A Simple Text uh in the past China and the LM extracts the correct",
    "start": "1677840",
    "end": "1683360"
  },
  {
    "text": "results here what's really cool about that is I think the the Brenda who's two years older",
    "start": "1683360",
    "end": "1689480"
  },
  {
    "text": "than Mary so it never says like 92 explicitly but language model is smart enough to kind of like do that math and",
    "start": "1689480",
    "end": "1694760"
  },
  {
    "text": "then also extract it so it's not just this isn't this isn't just like a fancy regex under the hood it's actually doing",
    "start": "1694760",
    "end": "1700220"
  },
  {
    "text": "logic as well yeah that's correct very cool",
    "start": "1700220",
    "end": "1707620"
  },
  {
    "text": "and uh so more complicated schemas can be composed uh you can say that maybe a",
    "start": "1710960",
    "end": "1717260"
  },
  {
    "text": "person owns multiple pets you actually want to break down the age of the BET into things like years or days or weeks",
    "start": "1717260",
    "end": "1724640"
  },
  {
    "text": "and you actually have multiple people uh and uh",
    "start": "1724640",
    "end": "1731559"
  },
  {
    "text": "so that there's a slightly more complicated example here of uh somebody who owns a dog and a catch uh their ages",
    "start": "1731659",
    "end": "1738200"
  },
  {
    "text": "is quoted and uh yeah it just kind of works which is fantastic uh so",
    "start": "1738200",
    "end": "1744620"
  },
  {
    "text": "I think that that's it for me very cool so you've experimented with",
    "start": "1744620",
    "end": "1749840"
  },
  {
    "text": "like a lot of different tasks it seems like there's some extracting kind of like uh things that you should do or pass into like a search query or an API",
    "start": "1749840",
    "end": "1756980"
  },
  {
    "text": "as well as extracting kind of like attributes what do you think like this type of what do you think core is best",
    "start": "1756980",
    "end": "1762380"
  },
  {
    "text": "at at the moment and what do you think like some of the the weaknesses or places where it might fail are either in",
    "start": "1762380",
    "end": "1767539"
  },
  {
    "text": "terms of like applications or types of data or or anything like that",
    "start": "1767539",
    "end": "1772640"
  },
  {
    "text": "um I think uh so at the moment it doesn't have uh some",
    "start": "1772640",
    "end": "1778340"
  },
  {
    "text": "of the obvious uh uh building blocks for uh wait a second doesn't have it doesn't",
    "start": "1778340",
    "end": "1783380"
  },
  {
    "text": "support the end-to-end use case rate uh just yet so there's no way of just taking an HTML and converting it into",
    "start": "1783380",
    "end": "1789559"
  },
  {
    "text": "something that you can extract you would need to just uh do that yourself but I'll try that support for those to try",
    "start": "1789559",
    "end": "1795860"
  },
  {
    "text": "and make it as easy as possible to just load your document and extract stuff from it uh",
    "start": "1795860",
    "end": "1801860"
  },
  {
    "text": "I suspect it will work uh uh uh pretty good for a query analysis uh",
    "start": "1801860",
    "end": "1807500"
  },
  {
    "text": "uh but uh these models can hallucinate results so",
    "start": "1807500",
    "end": "1814640"
  },
  {
    "text": "I don't know I think I think you just Benchmark things if you're using it for uh something like like I guess your own",
    "start": "1814640",
    "end": "1820700"
  },
  {
    "text": "database I guess your own search engine uh awesome and and then one last question",
    "start": "1820700",
    "end": "1826159"
  },
  {
    "text": "before switching to Greg because I saw a good question that I asked and you mentioned something around kind of like benchmarks so yeah how do you kind of",
    "start": "1826159",
    "end": "1833659"
  },
  {
    "text": "like compare both across models but then also across different encoding things so I think the specific question is",
    "start": "1833659",
    "end": "1840860"
  },
  {
    "text": "um yeah did you compare whether GPT 3.5 handles a specific data format better EG does it produce Json better than CSV or",
    "start": "1840860",
    "end": "1847399"
  },
  {
    "text": "markdown um yeah is there anything either either qualitative or quantitative that you're",
    "start": "1847399",
    "end": "1853940"
  },
  {
    "text": "doing to to Benchmark these things at the moment so not yet I think that's uh",
    "start": "1853940",
    "end": "1859100"
  },
  {
    "text": "on the plan uh to do uh there I've definitely noticed that these the models",
    "start": "1859100",
    "end": "1864140"
  },
  {
    "text": "can be very finicky to small details like uh if you are working with a large piece of text and providing multiple",
    "start": "1864140",
    "end": "1870919"
  },
  {
    "text": "examples and forget the quote the text it the quote the code Works uh the model gets confused about where the white",
    "start": "1870919",
    "end": "1878179"
  },
  {
    "text": "spaces so uh there are some important details to get right and we need to Benchmark and check uh whether things",
    "start": "1878179",
    "end": "1885140"
  },
  {
    "text": "are uh what kind of problems problem structures work the best uh my experience so far is that both text",
    "start": "1885140",
    "end": "1891940"
  },
  {
    "text": "DaVinci 3 and GPD 3.5 are worked pretty well for a variety of test cases that",
    "start": "1891940",
    "end": "1899059"
  },
  {
    "text": "I've done uh but I would love to hear from folks that are using this to see where things fail uh and how we can uh",
    "start": "1899059",
    "end": "1906140"
  },
  {
    "text": "help and fix them Eugene question for you on the hallucination piece that you're speaking",
    "start": "1906140",
    "end": "1912500"
  },
  {
    "text": "about uh what's your opinion on where if anywhere should reflection be",
    "start": "1912500",
    "end": "1917960"
  },
  {
    "text": "within core foreign [Music]",
    "start": "1917960",
    "end": "1925170"
  },
  {
    "text": "all right Greg do you want to take over now yeah absolutely um so after hearing about core's use",
    "start": "1931460",
    "end": "1938539"
  },
  {
    "text": "cases I think one of the underrated topics that uh language models aren't being used or aren't being talked about",
    "start": "1938539",
    "end": "1943580"
  },
  {
    "text": "a lot today is around unstructured data and pulling out structured data from it and specifically the use case that",
    "start": "1943580",
    "end": "1949340"
  },
  {
    "text": "popped into my head was when I would talk to old sales teams they'd say hey Greg we need a leads list and they often",
    "start": "1949340",
    "end": "1956179"
  },
  {
    "text": "check job descriptions to see which Technologies a company is actually using which is an interesting way to do it so",
    "start": "1956179",
    "end": "1963500"
  },
  {
    "text": "they'd go to a job description and in fact let me just let me start sharing and we'll just jump right into it",
    "start": "1963500",
    "end": "1970179"
  },
  {
    "text": "so they go to a uh Harrison got my screen here there we go yep",
    "start": "1973220",
    "end": "1980179"
  },
  {
    "text": "so they go to a job description let's share this they go to a job",
    "start": "1980179",
    "end": "1985220"
  },
  {
    "text": "description here's one for five chain right here and it says oh Technologies you use and then they give a list of",
    "start": "1985220",
    "end": "1990320"
  },
  {
    "text": "Technologies here so say you're a competitor to build kite right here that would be kind of cool to know the 5",
    "start": "1990320",
    "end": "1995419"
  },
  {
    "text": "train is using build kites so you can put them on your leads list and go and Prospect into them and so I thought that this would be a cool use case to extract",
    "start": "1995419",
    "end": "2001899"
  },
  {
    "text": "this information but at mass and what's cool is uh Greenhouse specifically has",
    "start": "2001899",
    "end": "2007480"
  },
  {
    "text": "an open API so as long as you have the company names and you have their company token which isn't too hard to figure out you can go and query all the jobs across",
    "start": "2007480",
    "end": "2014320"
  },
  {
    "text": "greenhouse and go and grab them and so what I did was I just set up basically",
    "start": "2014320",
    "end": "2020440"
  },
  {
    "text": "the demo that we just saw for core but in this case I pulled in a few different objects and Eugene I want to talk to you about this later because I found a hard",
    "start": "2020440",
    "end": "2026500"
  },
  {
    "text": "time with nesting but we can jump into that in a sec here but I created a different object for which Technologies do they have",
    "start": "2026500",
    "end": "2032679"
  },
  {
    "text": "let me share this stuff sorry which Technologies do they have which tools do they have and I put in",
    "start": "2032679",
    "end": "2039640"
  },
  {
    "text": "some examples there and then also I saw a lot of jobs had salary ranges too so it's kind of cool to pull out the salary range and this is a prime use case for a",
    "start": "2039640",
    "end": "2046960"
  },
  {
    "text": "language model because these salary ranges were not standardized at all across job descriptions so it's really",
    "start": "2046960",
    "end": "2052480"
  },
  {
    "text": "cool to not need to do anything more rigid right here and then you go ahead and you pull the job description you get",
    "start": "2052480",
    "end": "2057940"
  },
  {
    "text": "the content of what this thing says and here's that same job we were just looking at and you can see here that build kite is held underneath there and",
    "start": "2057940",
    "end": "2064839"
  },
  {
    "text": "then you just basically get the correct formatting and then run it and then you get a list of tools that is output which",
    "start": "2064839",
    "end": "2070480"
  },
  {
    "text": "is pretty sweet and so once you do this at scale you do this across a whole bunch of different companies I made a quick air table because I wanted to spin",
    "start": "2070480",
    "end": "2076599"
  },
  {
    "text": "up a front end really easily but you do this across I think I did this across 73 companies right now which is just a",
    "start": "2076599",
    "end": "2081820"
  },
  {
    "text": "sample of the whole data you get all the different tools and then I threw together a front end for this",
    "start": "2081820",
    "end": "2087638"
  },
  {
    "text": "called opening attributes and it's a lame name for basically let's check out",
    "start": "2087639",
    "end": "2092679"
  },
  {
    "text": "which tools all these different companies are using you can go through and see which tools are listed across their different job descriptions which",
    "start": "2092679",
    "end": "2098440"
  },
  {
    "text": "is a fun use case here um I wasn't sure how this would go but this sign up list which is if anybody wanted to get it when it was fully out",
    "start": "2098440",
    "end": "2105099"
  },
  {
    "text": "there since the Tweet yesterday it's had about 50 people sign up which is sweet because uh maybe build this out maybe",
    "start": "2105099",
    "end": "2111820"
  },
  {
    "text": "not who who knows but uh but that's the project from here and it's been it's been a lot of fun to do",
    "start": "2111820",
    "end": "2118859"
  },
  {
    "text": "a similar question to kind of like what I asked Eugene at the end do you have did you notice kind of one are you doing",
    "start": "2119440",
    "end": "2124599"
  },
  {
    "text": "anything to like Benchmark how this performs across various things or just more like looking at the data have you",
    "start": "2124599",
    "end": "2130240"
  },
  {
    "text": "noticed any places where it works well or doesn't work well anecdotally yeah absolutely so",
    "start": "2130240",
    "end": "2136240"
  },
  {
    "text": "the things some things I did not do I did not do a reflection step which I think I would have benefited from",
    "start": "2136240",
    "end": "2141520"
  },
  {
    "text": "because some of the examples that I listed in there actually appeared in the final output so the language model had a",
    "start": "2141520",
    "end": "2147940"
  },
  {
    "text": "hard time understanding what was an example and what was part of the actual output in the content so that's something I could definitely do",
    "start": "2147940",
    "end": "2153510"
  },
  {
    "text": "[Music] um and then I also found it very beneficial to make sure that my signal to noise",
    "start": "2153510",
    "end": "2160359"
  },
  {
    "text": "ratio was high so instead of putting the entire job description which there are",
    "start": "2160359",
    "end": "2165579"
  },
  {
    "text": "some sections I know won't have anything about the tools for example about our company I need to exclude that part",
    "start": "2165579",
    "end": "2171280"
  },
  {
    "text": "because the less text I can have and the more dense information I can give it it usually does a whole lot better so pre-processing was actually worth the",
    "start": "2171280",
    "end": "2177820"
  },
  {
    "text": "effort on there interesting and so you just you just did that by kind of like writing your own custom logic to clean",
    "start": "2177820",
    "end": "2184839"
  },
  {
    "text": "the text and stuff that's exactly it and so in some cases it would cut it down between uh 50 and 60 of text which was",
    "start": "2184839",
    "end": "2192400"
  },
  {
    "text": "really beneficial that's awesome that's awesome actually this this brings up another question",
    "start": "2192400",
    "end": "2198220"
  },
  {
    "text": "that I have for Eugene so um or or Greg or anyone who's kind of like played around with this but if I",
    "start": "2198220",
    "end": "2203920"
  },
  {
    "text": "have a text and I'm trying to extract something and there's just nothing in there that's relevant like is it going",
    "start": "2203920",
    "end": "2209920"
  },
  {
    "text": "to be good at saying like there's nothing there because I know like typically one of the biggest problems with language models is they don't know",
    "start": "2209920",
    "end": "2215619"
  },
  {
    "text": "and actually this is maybe a great transition to the question answer section because I think the top question there is like",
    "start": "2215619",
    "end": "2221560"
  },
  {
    "text": "um something around confidences um is it possible to assign confidence to the parsed output in any way so maybe",
    "start": "2221560",
    "end": "2227619"
  },
  {
    "text": "doubling down on this question one is is it possible to do that and I think we can maybe hear from all three of you if",
    "start": "2227619",
    "end": "2232900"
  },
  {
    "text": "you've tried that but then two specifically on the extraction side what if there isn't anything to extract will it actually say like I don't know",
    "start": "2232900",
    "end": "2239260"
  },
  {
    "text": "there's nothing there or or is that a case where like evolution is most frequent maybe we can start",
    "start": "2239260",
    "end": "2245619"
  },
  {
    "text": "um I think maybe we can go reverse orders to start with Greg on either of those I was going to say uh specifically",
    "start": "2245619",
    "end": "2251440"
  },
  {
    "text": "this exercise using core a bunch of blank lists showed up when there wasn't any information there so it's pretty",
    "start": "2251440",
    "end": "2256599"
  },
  {
    "text": "nice to just have a null about like nothing pop up for me which was good",
    "start": "2256599",
    "end": "2261820"
  },
  {
    "text": "yeah and my experience uh uh I've checked a lot with short uh death strings and also a little bit with HTML",
    "start": "2261820",
    "end": "2268480"
  },
  {
    "text": "but they're just it's pretty good on controlling before false positives uh",
    "start": "2268480",
    "end": "2274060"
  },
  {
    "text": "which I think is a little bit surprising uh but but also good news",
    "start": "2274060",
    "end": "2280260"
  },
  {
    "text": "also uh sorry things should also uh just get better with uh uh the more uh as LMS",
    "start": "2280680",
    "end": "2286660"
  },
  {
    "text": "events just wait for better models that's always the in some sense we don't need to Benchmark anything",
    "start": "2286660",
    "end": "2293040"
  },
  {
    "text": "and and and Eugene what about the assigning confidence to the parsed output in any way",
    "start": "2293520",
    "end": "2299920"
  },
  {
    "text": "um I haven't tried that but you could imagine uh having another pass with an llm to",
    "start": "2299920",
    "end": "2305980"
  },
  {
    "text": "actually just verify that the extraction is correct so two really cool things is verify that it's correct if not if not",
    "start": "2305980",
    "end": "2311740"
  },
  {
    "text": "corrected another thing that you could do is localize it so tell it every extracted field exactly where it came",
    "start": "2311740",
    "end": "2317380"
  },
  {
    "text": "from and the text that way you could actually show the document and show the highlights of every uh thing and then",
    "start": "2317380",
    "end": "2324460"
  },
  {
    "text": "that that could actually be checked by a human now um so if you have a human in the loop kind of a scenario",
    "start": "2324460",
    "end": "2331300"
  },
  {
    "text": "have you have you tried doing that second thing and if you've tried doing that have you tried doing it in just one",
    "start": "2331300",
    "end": "2336460"
  },
  {
    "text": "pass like extracting it along with the text things um in just a single forward pass as",
    "start": "2336460",
    "end": "2341680"
  },
  {
    "text": "opposed to doing some second step to do that um I've tried it uh not in single pass I",
    "start": "2341680",
    "end": "2346780"
  },
  {
    "text": "tried doing it also uh but with uh some test examples uh a while back uh",
    "start": "2346780",
    "end": "2354579"
  },
  {
    "text": "but you can ask the llm to basically you show it like a dictionary of stuff and you can ask the llm do you repeat the",
    "start": "2354579",
    "end": "2361180"
  },
  {
    "text": "text verb verbatim but in case uh include XML tags around extracted content with IDs and it seems to be able",
    "start": "2361180",
    "end": "2368619"
  },
  {
    "text": "to do that I don't know not to what quality goes Jeremy do you have any thoughts on uh",
    "start": "2368619",
    "end": "2375099"
  },
  {
    "text": "assigning confidence to the parts output in any way yeah so Greg and Eugene both mentioned",
    "start": "2375099",
    "end": "2381339"
  },
  {
    "text": "like offloading this to another inference pass which is getting a lot of attention these days",
    "start": "2381339",
    "end": "2387820"
  },
  {
    "text": "like reflection or self-correction I mean it is really great we can use language models as like cheap verifiers",
    "start": "2387820",
    "end": "2393880"
  },
  {
    "text": "but to the original Oscars question yeah it would be really cool if if we did like more traditional machine learning",
    "start": "2393880",
    "end": "2401740"
  },
  {
    "text": "models get some get some like calibrated notion of confidence out I know there's there's a lot of work that's gone in to",
    "start": "2401740",
    "end": "2407079"
  },
  {
    "text": "do this for um like conventional tasks like classification and question answering often what's required is like after you",
    "start": "2407079",
    "end": "2414400"
  },
  {
    "text": "know huge pre-training and then like alignment on human preferences no the answer is like these things are not well",
    "start": "2414400",
    "end": "2420040"
  },
  {
    "text": "calibrated but often you can you can do calibration post talk um by like scaling kind of the logits",
    "start": "2420040",
    "end": "2426400"
  },
  {
    "text": "and stuff um so I think that there's like potential there is like a future something future direction for Lang change to",
    "start": "2426400",
    "end": "2432880"
  },
  {
    "text": "support because it's not so difficult you basically um like have a bunch of generations and you score them yourself and then you",
    "start": "2432880",
    "end": "2440079"
  },
  {
    "text": "learn like a small transformation of the output and you can get something um and in the examples that we showed",
    "start": "2440079",
    "end": "2445960"
  },
  {
    "text": "where there's these are like highly structured um I feel like it starts to get starts to get like a lot hairier",
    "start": "2445960",
    "end": "2452740"
  },
  {
    "text": "um so in that case like I I yeah I mean I would use this or have been using like",
    "start": "2452740",
    "end": "2458079"
  },
  {
    "text": "in more offline use case a separate model to check for correctness and then if you really care about confidence you",
    "start": "2458079",
    "end": "2464140"
  },
  {
    "text": "can use that same separate model and calibrate that thing it will be much easier than calibrating the the initial",
    "start": "2464140",
    "end": "2469780"
  },
  {
    "text": "generation yeah so so there's another related question Less on like correcting or or checking",
    "start": "2469780",
    "end": "2476140"
  },
  {
    "text": "for correctness but around like actual adherence to the schema so both you guys are kind of like parsing it into the",
    "start": "2476140",
    "end": "2481480"
  },
  {
    "text": "exact scheme and I think we touched on this a little bit before Jeremy but like yeah what happens if it doesn't adhere",
    "start": "2481480",
    "end": "2486820"
  },
  {
    "text": "to that schema like what what different functionalities or different methods exist in in Lane chain and then Eugene",
    "start": "2486820",
    "end": "2492099"
  },
  {
    "text": "are you using any of those in core maybe we can start with Jeremy",
    "start": "2492099",
    "end": "2497339"
  },
  {
    "text": "um I think the I mean the main the main pieces that are in Lang chain presently",
    "start": "2499240",
    "end": "2505300"
  },
  {
    "text": "are I mean basic basically they're they're like particular parsing exceptions that are thrown and and we",
    "start": "2505300",
    "end": "2511300"
  },
  {
    "text": "can configure These Chains so that uh when these things are thrown either um you can you can attempt some sort of",
    "start": "2511300",
    "end": "2517300"
  },
  {
    "text": "retry and um so I I think just like a simple prompt pre-drive and like the prompting",
    "start": "2517300",
    "end": "2523000"
  },
  {
    "text": "is really naive it's like here here's the original input and here's the completion you generated and ideally",
    "start": "2523000",
    "end": "2528579"
  },
  {
    "text": "like here's the error trace for what went wrong um often like you know the retry mechanism was pretty pretty good uh one",
    "start": "2528579",
    "end": "2536680"
  },
  {
    "text": "one thing here if I can just jump in I think there's actually there's so there's two different types of retrys in link chain and I think there's a really",
    "start": "2536680",
    "end": "2542020"
  },
  {
    "text": "cool distinction between them one of them takes the um one of them is kind of simple it takes the llm output and it",
    "start": "2542020",
    "end": "2548380"
  },
  {
    "text": "takes the description of what it should be and says this is the output this is what it should have been it didn't work or maybe you pass it the error as well",
    "start": "2548380",
    "end": "2554440"
  },
  {
    "text": "and then it says generate new output and that's good at like if you have like a misformatted like quotation mark or",
    "start": "2554440",
    "end": "2560560"
  },
  {
    "text": "something in your Json or and it's not loading or you don't have like an end bracket or something in your Json it's really good for correcting that but",
    "start": "2560560",
    "end": "2566800"
  },
  {
    "text": "there's a different category of Errors where maybe it forgets to like include a field and that Field's really important",
    "start": "2566800",
    "end": "2572079"
  },
  {
    "text": "but the only way you can actually correct that properly is by having like the original prompt",
    "start": "2572079",
    "end": "2577240"
  },
  {
    "text": "um and so there's two different mechanisms one by which you just ignored the original prompt and it kind of just fixes formatting but then a second where",
    "start": "2577240",
    "end": "2583420"
  },
  {
    "text": "you pass the original prompt back in and this is what Jeremy was talking about obviously that's more expensive because or most of the time it's more expensive",
    "start": "2583420",
    "end": "2589240"
  },
  {
    "text": "because it's a longer prompt but in the case where like you're forgetting a certain part of the schema or something like that",
    "start": "2589240",
    "end": "2595000"
  },
  {
    "text": "um it's it's really good for fixing that and I I thought that was a really cool distinction because it shows how you",
    "start": "2595000",
    "end": "2600339"
  },
  {
    "text": "know yeah it's just two slightly different use cases um it and so Eugene are you using any of",
    "start": "2600339",
    "end": "2605859"
  },
  {
    "text": "these uh techniques in core or how are you thinking about handling kind of like parsing exceptions so not at the moment",
    "start": "2605859",
    "end": "2612460"
  },
  {
    "text": "uh I first want to tackle end-to-end use cases to figure out the correct way of hooking these up into just the",
    "start": "2612460",
    "end": "2618400"
  },
  {
    "text": "architecture uh so for an extraction purpose it's actually not obvious that if a required attribute is missing that",
    "start": "2618400",
    "end": "2624940"
  },
  {
    "text": "you actually want to retry because maybe it's just not in the text if you want to just now uh pay double the cost or",
    "start": "2624940",
    "end": "2631119"
  },
  {
    "text": "triple the car the cost of uh going over all of the documents and retiring them",
    "start": "2631119",
    "end": "2636220"
  },
  {
    "text": "just because uh it was something that looked like something that you were extracting but it actually wasn't that",
    "start": "2636220",
    "end": "2641260"
  },
  {
    "text": "uh so yeah first I'm going to spend some time trying to figure out uh how this",
    "start": "2641260",
    "end": "2647140"
  },
  {
    "text": "works for large documents and then uh let's see uh what kind of uh correcting",
    "start": "2647140",
    "end": "2652900"
  },
  {
    "text": "Behavior we can Implement as a second pass",
    "start": "2652900",
    "end": "2657000"
  },
  {
    "text": "awesome um uh one one one interesting question",
    "start": "2658540",
    "end": "2664960"
  },
  {
    "text": "um you know I think these instructions are okay two things around these prompts",
    "start": "2664960",
    "end": "2670720"
  },
  {
    "text": "and so we'll start with the simpler one um have you noticed that different types of prompts or different types of",
    "start": "2670720",
    "end": "2676180"
  },
  {
    "text": "encoding are needed for different models so Jeremy you were you were you met you had one example where you're using like",
    "start": "2676180",
    "end": "2681579"
  },
  {
    "text": "DaVinci zero zero one or something like that and and even between like davinci02 and davinci03 and then GPT 3.5 and gpt4",
    "start": "2681579",
    "end": "2688900"
  },
  {
    "text": "very different kind of like models have you experimented with kind of like different prompting techniques for the",
    "start": "2688900",
    "end": "2694720"
  },
  {
    "text": "different models are you or is your approach so far has been like find one prompting technique and use that across",
    "start": "2694720",
    "end": "2700060"
  },
  {
    "text": "all models so um yeah the reason I had I guess DaVinci",
    "start": "2700060",
    "end": "2706920"
  },
  {
    "text": "z001 and that one example is because I wanted I wanted it more likely for there to be some like regressions or bad cases",
    "start": "2706920",
    "end": "2713619"
  },
  {
    "text": "so I could show some some fixing um I guess when we were looking at the",
    "start": "2713619",
    "end": "2718780"
  },
  {
    "text": "output parsing initially with sort of like arbitrary schema you know we looked at a bunch of like different examples",
    "start": "2718780",
    "end": "2725140"
  },
  {
    "text": "and then tried a bunch of different model families and and model sizes um and and that's where like the",
    "start": "2725140",
    "end": "2730900"
  },
  {
    "text": "observation came in that like oh um it's actually like quite difficult to do this with even even the best of the open",
    "start": "2730900",
    "end": "2737319"
  },
  {
    "text": "source models currently and and some of the smaller um maybe maybe private models so you",
    "start": "2737319",
    "end": "2744940"
  },
  {
    "text": "just you definitely have to to like do the work up front and like you know",
    "start": "2744940",
    "end": "2750220"
  },
  {
    "text": "come up with come up with your own small validation set hopefully and and make sure that like whatever whatever your",
    "start": "2750220",
    "end": "2756760"
  },
  {
    "text": "hyper parameter selection is or your model selection is it roughly roughly is relied",
    "start": "2756760",
    "end": "2762700"
  },
  {
    "text": "um because yeah it's just such like steep I guess performance drop off for some of the smaller models",
    "start": "2762700",
    "end": "2768220"
  },
  {
    "text": "um where you know they they can't really generate like structured data like this yeah",
    "start": "2768220",
    "end": "2774300"
  },
  {
    "text": "um cool and and Eugene have you noticed kind of like any differences in the",
    "start": "2776260",
    "end": "2781780"
  },
  {
    "text": "prompts or or I guess I guess you kind of touched on and no no no super great",
    "start": "2781780",
    "end": "2787060"
  },
  {
    "text": "benchmarking so far but but any thoughts on prompts for diff or different types of prompts for different models",
    "start": "2787060",
    "end": "2793180"
  },
  {
    "text": "uh so I would I guess just uh Echo what",
    "start": "2793180",
    "end": "2798339"
  },
  {
    "text": "Jeremy said um uh the smaller models seem to be uh really dropping in the",
    "start": "2798339",
    "end": "2804700"
  },
  {
    "text": "performance quickly so I've been focusing on LGBT 3.5 because it's cheap for extraction you want something that",
    "start": "2804700",
    "end": "2809920"
  },
  {
    "text": "is reasonably cheap uh and then uh uh there's just some tricks that you're",
    "start": "2809920",
    "end": "2815260"
  },
  {
    "text": "doing to try to make things a little bit less finicky um but",
    "start": "2815260",
    "end": "2820780"
  },
  {
    "text": "CSV seems to be good it's just uh I'll try and see if I can get things like embedded jsons or embed objects as part",
    "start": "2820780",
    "end": "2828160"
  },
  {
    "text": "of the CSU encoding and then uh I'll be able to say whether CSV encoding is just as robust for complex use cases Jason is",
    "start": "2828160",
    "end": "2836020"
  },
  {
    "text": "um Eugene do you think all the cool stuff you're doing for 3.5 is like playing on",
    "start": "2836020",
    "end": "2841060"
  },
  {
    "text": "hard mode and that all that work will benefit you when you go to four uh I think so uh I'm a little bit",
    "start": "2841060",
    "end": "2848560"
  },
  {
    "text": "worried that uh when we get to five uh everything is going to become Obsolete and we won't need the package at all so",
    "start": "2848560",
    "end": "2857200"
  },
  {
    "text": "but uh we live in an amazing time this is just like uh the software is becoming better uh without you touching the",
    "start": "2858220",
    "end": "2865540"
  },
  {
    "text": "software at all right this is the underlying models are uh improving at an amazing rate this is just like",
    "start": "2865540",
    "end": "2871660"
  },
  {
    "text": "Hardware improvements in the 90s and 80s so you did invest in your software in your things will start running uh",
    "start": "2871660",
    "end": "2877359"
  },
  {
    "text": "quicker uh by a vector of two every few years but yeah I mean one plug for Lane chain",
    "start": "2877359",
    "end": "2883240"
  },
  {
    "text": "though is like certainly the cap capabilities are gonna keep keep going up but we do need the",
    "start": "2883240",
    "end": "2889180"
  },
  {
    "text": "like Scaffolding in place you know to know when things are going wrong and so if they do but hopefully like the amount",
    "start": "2889180",
    "end": "2895839"
  },
  {
    "text": "of time we actually incur like this retry cost or something like that that should yeah drop by quite a bit",
    "start": "2895839",
    "end": "2903040"
  },
  {
    "text": "Eugene one one question that popped up and it's I know you said you experimented mostly with kind of like",
    "start": "2903040",
    "end": "2908140"
  },
  {
    "text": "short pieces of text but what if a single parser has to extract entities or information from like",
    "start": "2908140",
    "end": "2913960"
  },
  {
    "text": "two chunks of text like let's assume that we have to split it into chunks because it's really long um yeah have you thought about how one",
    "start": "2913960",
    "end": "2921099"
  },
  {
    "text": "might go about that uh yeah just use a link chain uh uh deck",
    "start": "2921099",
    "end": "2926740"
  },
  {
    "text": "Splitters so it all kind of works together without too much difficulty but then like if there's like a pedantic",
    "start": "2926740",
    "end": "2932980"
  },
  {
    "text": "object that has two fields and one's in one chunk and one's in the other chunk of text like how would you properly kind",
    "start": "2932980",
    "end": "2939099"
  },
  {
    "text": "of like extract that object well it becomes a bit more complicated but you could try I mean uh RAM things was is a",
    "start": "2939099",
    "end": "2946060"
  },
  {
    "text": "first batch at least write things with an overlap uh so that there's some overlap and then uh the problem there's",
    "start": "2946060",
    "end": "2951940"
  },
  {
    "text": "you're going to be getting duplicates every now and then uh so just have someday the duplication mechanism uh and",
    "start": "2951940",
    "end": "2958900"
  },
  {
    "text": "if you are lucky to have humans in the loop then you can rely on that uh for whatever your use case is",
    "start": "2958900",
    "end": "2966000"
  },
  {
    "text": "if not then you just need if you don't have humans in the loop you're going to have to live with with it you need you",
    "start": "2966000",
    "end": "2971260"
  },
  {
    "text": "need to accept extraction errors right this is irresponsibility",
    "start": "2971260",
    "end": "2976960"
  },
  {
    "text": "all right next next question and maybe yeah next question more on the lines of",
    "start": "2977680",
    "end": "2983380"
  },
  {
    "text": "the and the application for Greg and Eugene let's start with Eugene on the technical question and then I'm curious",
    "start": "2983380",
    "end": "2989500"
  },
  {
    "text": "to get Greg's take on that as well but would it be possible to have a prior step that would come up with a a core",
    "start": "2989500",
    "end": "2995440"
  },
  {
    "text": "slash pedantic schema for an example text for example given the job description the suggestion schema would",
    "start": "2995440",
    "end": "3001260"
  },
  {
    "text": "be created by the model and then just take that screen as we saw would be very useful for complex tests where the",
    "start": "3001260",
    "end": "3006359"
  },
  {
    "text": "schema may not be known up front is this anything you experimented with Eugene",
    "start": "3006359",
    "end": "3012180"
  },
  {
    "text": "um I haven't experimented with this exact desk but a friend of mine uh uh describe what he wanted gave uh",
    "start": "3012180",
    "end": "3020220"
  },
  {
    "text": "as context core documentation and just got core code written out for him for",
    "start": "3020220",
    "end": "3025440"
  },
  {
    "text": "his task together with all of the descriptions and some examples filled in and that worked pretty well",
    "start": "3025440",
    "end": "3030839"
  },
  {
    "text": "um but it's not quite the same thing as as going from a document to potential things that can be extracted yeah and",
    "start": "3030839",
    "end": "3037680"
  },
  {
    "text": "then Greg I guess my question for you here is when you're building this application like how hard is it to come",
    "start": "3037680",
    "end": "3042720"
  },
  {
    "text": "up with that schema that you want what do you think the best ux would be would it be kind of like is having you",
    "start": "3042720",
    "end": "3048000"
  },
  {
    "text": "specified okay would you want to do something like Eugene just mentioned where you say the natural language and it generates it or or would extracting",
    "start": "3048000",
    "end": "3054599"
  },
  {
    "text": "it from a piece of example text be the best one yeah um first of all that's a very cool idea",
    "start": "3054599",
    "end": "3060059"
  },
  {
    "text": "for my users yeah right my for my use case here the schema was easy so I had no problems with that however when I'm",
    "start": "3060059",
    "end": "3066119"
  },
  {
    "text": "developing I don't want to have an unknown schema and have to handle that and so I'd rather feel I'd feel more comfortable I knew what it was",
    "start": "3066119",
    "end": "3071640"
  },
  {
    "text": "beforehand however that being said um there are a lot of like using job descriptions as just an example there",
    "start": "3071640",
    "end": "3078180"
  },
  {
    "text": "are a lot of nuanced pieces of information just within the content of it and what would be pretty cool and I",
    "start": "3078180",
    "end": "3083880"
  },
  {
    "text": "have no idea how I almost want to do this right when I get off the webinar is go feed that into that idea and say hey give me a schema to organize this",
    "start": "3083880",
    "end": "3089760"
  },
  {
    "text": "information and then give me and then give it another one and say like do you need to update your schema given this",
    "start": "3089760",
    "end": "3094859"
  },
  {
    "text": "new piece of information you just had and have it kind of iterate towards an ideal schema because in the job description like I said there's salary",
    "start": "3094859",
    "end": "3100980"
  },
  {
    "text": "there's values about the company there's what you'd be doing there's all that other stuff and it would be cool",
    "start": "3100980",
    "end": "3106619"
  },
  {
    "text": "um to use GPT as a schema brainstormer and just have it iterate on a whole bunch of different types and see what it",
    "start": "3106619",
    "end": "3112319"
  },
  {
    "text": "comes out with Eugene is there anything like that in core where rather than could you define like a blob schema or something or say",
    "start": "3112319",
    "end": "3119160"
  },
  {
    "text": "like make up your own schema um and feed it a text and just have it extract arbitrary key values",
    "start": "3119160",
    "end": "3126839"
  },
  {
    "text": "not right now but you can just use GPS right now maybe we could add something",
    "start": "3126839",
    "end": "3135078"
  },
  {
    "text": "cool all right and then final question for each of you um what's next what's next for the",
    "start": "3135240",
    "end": "3140400"
  },
  {
    "text": "projects what's next are you guys thinking about what are you excited about maybe we can start with Jeremy",
    "start": "3140400",
    "end": "3147559"
  },
  {
    "text": "specifically related to the output parsing extraction stuff that we talked about not not life",
    "start": "3147980",
    "end": "3154200"
  },
  {
    "text": "oh it's an outward person um I mean I think the these kinds of these",
    "start": "3154200",
    "end": "3161160"
  },
  {
    "text": "kinds of ideas that are going to become more and more core and like chain and be more tightly integrated with with some",
    "start": "3161160",
    "end": "3166800"
  },
  {
    "text": "of the chains and some of the agents and I'm really excited about that because we'll get to start to see like real end",
    "start": "3166800",
    "end": "3172380"
  },
  {
    "text": "to end um like production agents and that that I think is like that that's the Paradigm",
    "start": "3172380",
    "end": "3178319"
  },
  {
    "text": "of software I'm really excited about and then that we're working towards so yeah it needs a little bit needs a little bit",
    "start": "3178319",
    "end": "3183839"
  },
  {
    "text": "more uh safety and stuff around the edges Eugene web out core what are some",
    "start": "3183839",
    "end": "3189180"
  },
  {
    "text": "features that you're looking to add in over the next week month so yeah so I already mentioned it uh",
    "start": "3189180",
    "end": "3194760"
  },
  {
    "text": "end-to-end use cases for uh document extraction is going to be a push and then uh potentially uh pushing a little",
    "start": "3194760",
    "end": "3201119"
  },
  {
    "text": "bit to the query analysis to see if it's possible to uh",
    "start": "3201119",
    "end": "3206280"
  },
  {
    "text": "make it easy to query a SQL databases uh uh in a slightly different way so not uh",
    "start": "3206280",
    "end": "3212420"
  },
  {
    "text": "by using intermediate representations awesome and Greg what's next for you so",
    "start": "3212420",
    "end": "3220619"
  },
  {
    "text": "with that sign up list that I mentioned beforehand like any other good product I want to go talk to some users and see if there's enough energy for something like",
    "start": "3220619",
    "end": "3226859"
  },
  {
    "text": "this here um the unique part about this project is um sales teams pay a lot for leads often",
    "start": "3226859",
    "end": "3232859"
  },
  {
    "text": "so there's a little bit of cash on the other end on it and so we'll see if it's worth the ROI",
    "start": "3232859",
    "end": "3239119"
  },
  {
    "text": "awesome well for for joining um both both uh Jeremy Eugene and Greg",
    "start": "3239460",
    "end": "3246599"
  },
  {
    "text": "as well as everyone in the audience I think we're going to wrap it up here um a lot of links have been dropped in the",
    "start": "3246599",
    "end": "3253380"
  },
  {
    "text": "chat oh everyone was also asking for links for uh the the demos that you guys showed uh the notebooks and the website",
    "start": "3253380",
    "end": "3260400"
  },
  {
    "text": "so if you guys want to drop them in the chat and then maybe even tweet tweet them out and we can repost there I think",
    "start": "3260400",
    "end": "3265920"
  },
  {
    "text": "people were really interested in those I think the examples that you guys showed sparked a lot of imagination and and cool ideas",
    "start": "3265920",
    "end": "3273180"
  },
  {
    "text": "um that's it for this webinar we're gonna do another one next week on a very",
    "start": "3273180",
    "end": "3278220"
  },
  {
    "text": "exciting uh topic to be announced uh shortly um and yeah we're gonna try to do these",
    "start": "3278220",
    "end": "3283920"
  },
  {
    "text": "every week on topics that you guys are interested in so if there's a particular topic that you guys want to hear",
    "start": "3283920",
    "end": "3289859"
  },
  {
    "text": "um us talk about or have have other people bring on feel free to drop ideas in in the link chain Discord",
    "start": "3289859",
    "end": "3295680"
  },
  {
    "text": "um I'll drop a I'll drop a mention to that there's a virtual events Channel and that's where we kind of like share",
    "start": "3295680",
    "end": "3301260"
  },
  {
    "text": "and announce and also hopefully get feedback on a lot of these things um thank you everyone for joining have a",
    "start": "3301260",
    "end": "3307559"
  },
  {
    "text": "great rest of your day",
    "start": "3307559",
    "end": "3310280"
  }
]
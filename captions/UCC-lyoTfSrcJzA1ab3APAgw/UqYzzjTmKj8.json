[
  {
    "start": "0",
    "end": "90000"
  },
  {
    "text": "Will Fu-Hinthorn: Hi all,\nthis is Will from LangChain. Let's build computing\nOlympiad agents together.",
    "start": "1070",
    "end": "4980"
  },
  {
    "text": "So about a week ago, this team\nout of Princeton came out with a paper called Can Language Models\nSolve Olympiad Programming?",
    "start": "6390",
    "end": "11360"
  },
  {
    "text": "It was done by the folks such as Chen\nXie and Shunyu Yao, who you might recognize from the React paper, Tree of\nThoughts paper, and Reflexion papers.",
    "start": "11809",
    "end": "18239"
  },
  {
    "text": "This paper really has two\ninteresting components to it. on one hand, it's a data set paper. They come out with this challenge\nbenchmark of 307 competitive programming",
    "start": "19125",
    "end": "27095"
  },
  {
    "text": "problems from the USA Computing Olympiad. And they showed that GPT\n4 only has about an 8.",
    "start": "27095",
    "end": "32465"
  },
  {
    "text": "7 percent pass rate when trying\nto do this with a simple zero shot React agent framework.",
    "start": "32514",
    "end": "38253"
  },
  {
    "text": "This is in contrast to some of the\nexisting benchmarks, like HumanEval, MMLU, that are mostly saturated\nby this crop of language models.",
    "start": "38254",
    "end": "45234"
  },
  {
    "text": "They then show some inference\noptimizations, basically prompting techniques or systems engineering\ntypes of approaches to improve the",
    "start": "46334",
    "end": "55095"
  },
  {
    "text": "performance on average from that 8. 7 percent up to 20. 2%.",
    "start": "55095",
    "end": "59444"
  },
  {
    "text": "And we'll go more in detail on\neach of those techniques as we go throughout this tutorial.",
    "start": "60564",
    "end": "65283"
  },
  {
    "text": "Let's get a sense for the difficulty of\nthe types of problems in this benchmark. Alright, so here's an example question.",
    "start": "66605",
    "end": "72654"
  },
  {
    "text": "You can see they're mostly word problems\nthat require you to  identify the underlying mathematical problem you need\nto solve, use advanced data structures and",
    "start": "72904",
    "end": "81774"
  },
  {
    "text": "algorithms, and compose them in a creative\nway to come up with the correct solution. It also has to be done and\nimplemented in a way that solves",
    "start": "81784",
    "end": "89724"
  },
  {
    "text": "it within a given time limit. As you can see from this diagram,\nthere's a lot of different usage of sets and , other types of things there.",
    "start": "89814",
    "end": "96369"
  },
  {
    "start": "90000",
    "end": "158000"
  },
  {
    "text": "The questions are challenging. There's a reason why\nit's called an Olympiad. What I find interesting about\nthis benchmark is that it really",
    "start": "97310",
    "end": "103470"
  },
  {
    "text": "pushes LLMs to the limit, so you\ncan see where it breaks down. I think when we're using them\nin normal life, you often start",
    "start": "103470",
    "end": "108679"
  },
  {
    "text": "to anthropomorphize them and see\nthem think that they're reasoning. Whenever you get to this extent, you can\nsee when they start doing things that",
    "start": "108690",
    "end": "116590"
  },
  {
    "text": "look like, interesting, close to correct,\nbut don't have this logical property. So as I mentioned before, when they\nfirst run GPT 4 on each of these",
    "start": "116590",
    "end": "125339"
  },
  {
    "text": "problems, it gets a really low pass rate. They later show a number of\ninference techniques that",
    "start": "125359",
    "end": "130459"
  },
  {
    "text": "they could do to improve it. Some of these include self\nreflection and some of these involve retrieval, either from semantic\nknowledge or episodic knowledge.",
    "start": "130459",
    "end": "138239"
  },
  {
    "text": "They do a lot of experiments to show\nwhat types of retrieval actually improve the performance of the model.",
    "start": "138609",
    "end": "144579"
  },
  {
    "text": "We're going to implement the best\nperforming retrieval type, this episodic knowledge type, since it seems to be\nvery complementary to self reflection and",
    "start": "144979",
    "end": "152629"
  },
  {
    "text": "works well within our tutorial structure. Let's check out our LandGraph\ndocs to see how we're going to",
    "start": "152629",
    "end": "157670"
  },
  {
    "text": "implement this in the tutorial. Alright, so for the remainder of the\nvideo, we're going to be creating",
    "start": "157670",
    "end": "164765"
  },
  {
    "start": "158000",
    "end": "361000"
  },
  {
    "text": "an agent to solve these types of\ncompetitive programming problems. We'll break it down into three parts,\nfollowing the paper's structure and making",
    "start": "165184",
    "end": "173334"
  },
  {
    "text": "agents that are increasingly capable\nof solving these advanced questions. In the first step, we'll implement\nthe reflection agent, the zero shot",
    "start": "173724",
    "end": "181815"
  },
  {
    "text": "agent that does self reflection. This corresponds to here, this block in\nour graph that we're going to be creating.",
    "start": "181825",
    "end": "187714"
  },
  {
    "text": "It's going to have two simple nodes and\njust run in a loop until it can solve the answer correctly, or ran out of time.",
    "start": "188154",
    "end": "193854"
  },
  {
    "text": "This is roughly analogous\nto this reflexion agent they created, that gets about a 12.",
    "start": "194755",
    "end": "200575"
  },
  {
    "text": "38%. So again, better than the base\nzero shot agent, not as good as what they can get overall.",
    "start": "200615",
    "end": "205804"
  },
  {
    "text": "In part two of the tutorial, we're going\nto implement retrieval as a form of",
    "start": "206840",
    "end": "211489"
  },
  {
    "text": "episodic memory, what the paper calls it. This is part two here, where we'll\nbe then retrieving some high quality",
    "start": "211850",
    "end": "219930"
  },
  {
    "text": "examples to include within the\nprompt and hopefully induce better logical performance in the model.",
    "start": "219930",
    "end": "225360"
  },
  {
    "text": "This is analogous to this section\nhere that gets about the 22. 2 percent on the benchmark overall.",
    "start": "226040",
    "end": "231569"
  },
  {
    "text": "In part three, we're going\nto add a human interrupt. So we're going to let us, the\nuser, actually weigh in on the",
    "start": "232545",
    "end": "239255"
  },
  {
    "text": "answer and help guide the agent\nto come to the correct  answer. You may consider this cheating, and\nin fact we aren't actually going to",
    "start": "239255",
    "end": "247645"
  },
  {
    "text": "benchmark this on the whole dataset,\nand the authors don't as well. But, in a lot of application\ndesigns, we're What you actually",
    "start": "247645",
    "end": "255308"
  },
  {
    "text": "want is the best outcome overall. And so co pilot type setups are a\ngreat pragmatic approach to getting",
    "start": "255309",
    "end": "262159"
  },
  {
    "text": "a better overall outcome where either\nperhaps the human alone or the agent alone couldn't actually get there.",
    "start": "262159",
    "end": "267349"
  },
  {
    "text": "A big theme throughout this is that\nautonomous agents really aren't quite there yet especially when you're just\nprompting in a simple zero shot manner.",
    "start": "268179",
    "end": "275489"
  },
  {
    "text": "But you can create state machines\nusing frameworks like LangGraph to really control and guide it within\nyour task domain and hopefully",
    "start": "276119",
    "end": "284219"
  },
  {
    "text": "get better outcomes overall. Let's download this notebook and\nthen run through it together.",
    "start": "284219",
    "end": "290399"
  },
  {
    "text": "All right, now we're ready to\nstart running through the tutorial. We've opened this up in Jupyter.",
    "start": "292419",
    "end": "297319"
  },
  {
    "text": "And we're going to install\nsome prerequisites here. It's basically LangGraph. We're going to add some\ntracing here with LangSmith.",
    "start": "297924",
    "end": "303474"
  },
  {
    "text": "The agent is going to be powered by\nAnthropic's LangGraph model, in our case. And we've got a couple of other\nthings to pull things from the hub.",
    "start": "303804",
    "end": "309944"
  },
  {
    "text": "We'll set our environment. In our case, it'll be Anthropic's\nAPI key to connect to their API. And then we'll also configure tracing.",
    "start": "310734",
    "end": "317113"
  },
  {
    "text": "There's a lot of steps that go on\nhere, and each of the programs can be quite long, so visualizing it in\na notebook can be pretty cluttered.",
    "start": "317504",
    "end": "323754"
  },
  {
    "text": "I'd recommend using Langsmith\njust so you can debug each step and see exactly what's happening. It's easier to catch mistakes,\neasier to see what's going on.",
    "start": "324239",
    "end": "331529"
  },
  {
    "text": "We'll then fetch the data we've\nstored in Google Cloud Bucket and we'll load it into memory. And then finally the utility here.",
    "start": "333959",
    "end": "339899"
  },
  {
    "text": "is to run test cases. I'll note that this is executing code\nlocally, so proceed with caution.",
    "start": "340424",
    "end": "345514"
  },
  {
    "text": "There's an inherent risk if the LLM does\ngenerate malicious code or something that will have an OOM or something.",
    "start": "345524",
    "end": "351204"
  },
  {
    "text": "An example run of here of the test\ncase runner in this print hello world. If it passes, it would turn passed.",
    "start": "352044",
    "end": "358164"
  },
  {
    "text": "If not, it would turn wrong answer\nalong with the expected output. All right, so now I can\nfinally start defining a graph.",
    "start": "358444",
    "end": "364534"
  },
  {
    "start": "361000",
    "end": "747000"
  },
  {
    "text": "In part one again, we'll be doing this\nsimple zero shot agent with reflection.",
    "start": "365484",
    "end": "369904"
  },
  {
    "text": "Note in the paper they used\nan explicit Reflexion prompt. We've adapted it a bit and then prompted\nour agent here to be reflecting on its",
    "start": "370574",
    "end": "378214"
  },
  {
    "text": "output here when it's doing tool calling. This one's going to be\nrelatively rudimentary. It corresponds to that agent\nthat gets about a 12 percent",
    "start": "378214",
    "end": "385244"
  },
  {
    "text": "pass rate on the benchmark. And so for our first question,\nwe kind of expect it not to pass, but I think that's okay.",
    "start": "385244",
    "end": "391684"
  },
  {
    "text": "We've got some other tricks up our sleeve. Now the next part may be review if\nyou've already built with LangGraph,",
    "start": "391694",
    "end": "396893"
  },
  {
    "text": "but I want to review it anyways,\nbecause I think it is important. The main primitive in\nLangGraph is a state graph.",
    "start": "397114",
    "end": "402964"
  },
  {
    "text": "It's how you define a state machine. Basically the nodes\ndefine the units of work. And the edges define the control flow.",
    "start": "403604",
    "end": "410103"
  },
  {
    "text": "Once a node completes, the edge\ndefines which node to pass to next",
    "start": "410554",
    "end": "415714"
  },
  {
    "text": "in order to continue operation. In its most simple case, you essentially\nhave two nodes in our cases and it loops",
    "start": "415744",
    "end": "421424"
  },
  {
    "text": "back and forth, back through and then will\noutput once it has reached some end state.",
    "start": "421424",
    "end": "426404"
  },
  {
    "text": "The final piece of this that's\nreally important is the state. Of course, this defines the interface\nfor all the nodes, so each node",
    "start": "428214",
    "end": "435409"
  },
  {
    "text": "receives the state as an input and\nthen returns an update to the state. That could be an entire state\nitself, or just some subset",
    "start": "435409",
    "end": "443069"
  },
  {
    "text": "that then the graph is able to\nincorporate into the previous state. In our case, the main aspect of this\nstate is going to be this messages",
    "start": "443089",
    "end": "451479"
  },
  {
    "text": "list that we're annotating as being\nappend only using this function, using Python's annotated syntax.",
    "start": "451479",
    "end": "457429"
  },
  {
    "text": "This basically keeps the agent\nscratch pad as it generates a candidate and then receives a tool\nresponse, and then continues to",
    "start": "457954",
    "end": "464914"
  },
  {
    "text": "iterate and try to improve the game. The rest of the state here holds the test\ncases essentially, and the runtime limit",
    "start": "464914",
    "end": "471254"
  },
  {
    "text": "to configure how the evaluate node runs. The agent itself is gonna ignore this,\nbut the test runner will incorporate it.",
    "start": "471374",
    "end": "477584"
  },
  {
    "text": "Now that we've defined the state, we'll\nupdate our data set to be in the right.",
    "start": "478935",
    "end": "483925"
  },
  {
    "text": "format essentially to be\nable to pass it in and we can start defining the good parts.",
    "start": "484255",
    "end": "488955"
  },
  {
    "text": "Remember, this has two nodes. We've got the solve node\nand the evaluate node. So first the solver here is pretty simple.",
    "start": "489485",
    "end": "496345"
  },
  {
    "text": "We're basically taking a prompt and\nwe're going to compose it with an LLM. So this format into a prompt\nand then pass it to the LLM.",
    "start": "496394",
    "end": "504445"
  },
  {
    "text": "This bind tools operation is\njust configuring a schema for the LLM, so it knows the structure\nthat it should respond with.",
    "start": "504885",
    "end": "510835"
  },
  {
    "text": "In our case, we're going to\nuse this write Python tool. Let's write Python schema. We're basically going to tell it for some\nreasoning and pseudocode to induce some",
    "start": "511394",
    "end": "518815"
  },
  {
    "text": "chain of thought reasoning beforehand. And then we'll finally have it\nwrite all of the Python 3 code.",
    "start": "518815",
    "end": "523879"
  },
  {
    "text": "into the code string here. This just makes it a lot easier to\nparse on the tail end, so you don't",
    "start": "524230",
    "end": "529480"
  },
  {
    "text": "have to be parsing out raw strings. I'll run this here and\nthen we'll define a solver.",
    "start": "529480",
    "end": "535030"
  },
  {
    "text": "So we pulled this, this\nsolver prompt from the hub. It's pretty simple. I didn't do too much\nprompt engineering here.",
    "start": "535030",
    "end": "541269"
  },
  {
    "text": "Note that we do have this variable\nexamples that we'll use later in part two. Right now we're just going to fill this in\nthrough partialing with an empty string.",
    "start": "541710",
    "end": "548040"
  },
  {
    "text": "That'll be the placeholder\nthat we then populate with. additional information that we\nretrieve, but more on that later.",
    "start": "548550",
    "end": "555774"
  },
  {
    "text": "Here's an example run. We're just going to ask it,\nhow do I get a perfectly random sample from an infinite stream?",
    "start": "557075",
    "end": "562345"
  },
  {
    "text": "All right, we've gotten the response. So you can see it generates this\nthinking tag, and then eventually",
    "start": "563715",
    "end": "569355"
  },
  {
    "text": "outputs things with the reasoning. You might see the pseudocode, and then\neventually the code, and it is doing",
    "start": "569425",
    "end": "574905"
  },
  {
    "text": "reservoir sampling as we'd expect. It at least has studied some code. That's a good thing. One thing that I like about Claude as\nopposed to GPT 4 is that it was trained",
    "start": "574905",
    "end": "584965"
  },
  {
    "text": "to output this thinking or prelude\ntext, you can think of it, before",
    "start": "585025",
    "end": "590155"
  },
  {
    "text": "actually doing the tool invocation. I think there's often this question\nwhen using GPT 4 with tool calling of",
    "start": "590155",
    "end": "595315"
  },
  {
    "text": "how to incorporate chain of thought. And we've found that it sometimes\nsuffers with some of these more complex tasks as a result.",
    "start": "595395",
    "end": "601405"
  },
  {
    "text": "I think it's quite nice that they've\ntrained the model to output this before doing the tool invocation so you don't\nhave to be making sacrifices there.",
    "start": "601820",
    "end": "608710"
  },
  {
    "text": "So the second node that we'll\ndefine in this loop, this agent loop, is the evaluate node. And there's a good amount of error\nhandling and stuff here, but really the",
    "start": "609720",
    "end": "616660"
  },
  {
    "text": "key bit here is we're going to iterate\nthrough all the test cases in our state. Again, recall that each node is\ngoing to receive an instance of",
    "start": "616780",
    "end": "623200"
  },
  {
    "text": "the state and return an output, so\nin this case an updated message. But it iterates through the test cases,\nruns them, and then if it succeeds,",
    "start": "623200",
    "end": "629670"
  },
  {
    "text": "it'll update the status in our state. Otherwise, it's going to format\neach of these things individually,",
    "start": "629670",
    "end": "635600"
  },
  {
    "text": "and then add the messages. You are there, you can create the\ngraph, and we'll visualize it.",
    "start": "635960",
    "end": "644470"
  },
  {
    "text": "So, again, this corresponds to that graph\nwe had above, it's a little more simple. We put the initial problem in here, tries\nto generate a solution, it  tests it",
    "start": "645630",
    "end": "654155"
  },
  {
    "text": "out, and then we enter this control edge. If it's successful we end, otherwise we go\nback to the solver and we keep on looping.",
    "start": "654155",
    "end": "661324"
  },
  {
    "text": "Here the control edge, you can see there,\nit just also receives the state and then",
    "start": "661525",
    "end": "666705"
  },
  {
    "text": "checks that state to see if it succeeded. It then returns, this is a string,\nand string with double underscores,",
    "start": "666705",
    "end": "672774"
  },
  {
    "text": "this just tells the graph that it\ndoesn't need to continue looping. Otherwise, it says go\nback to the solver node.",
    "start": "673025",
    "end": "678779"
  },
  {
    "text": "That's how we would define it\nhere with the conditional edges. Let's see the first question.",
    "start": "679940",
    "end": "685330"
  },
  {
    "text": "Question about Farmer John. Looking at, you know, he's got\nsome productivity of the day.",
    "start": "685990",
    "end": "691380"
  },
  {
    "text": "Bessie, you've got the cow. Seems pretty complicated. It's got some number of sample inputs,\nsample outputs, as a part of the question.",
    "start": "691430",
    "end": "698860"
  },
  {
    "text": "Let's try running our agent here. Okay. So again, this is the simplest\nversion of the agent that we're",
    "start": "700530",
    "end": "706800"
  },
  {
    "text": "going to be building today. I fully expect it not to work, honestly. And the way lingraph indicates\nthis typically is through",
    "start": "706800",
    "end": "713130"
  },
  {
    "text": "a graph recursion error. Basically by default, the graph\nhas a limited number of steps.",
    "start": "713130",
    "end": "718570"
  },
  {
    "text": "You can configure this. We show this in the docs elsewhere. I won't go into detail here, but if it\nsurpasses the maximum number of configured",
    "start": "718770",
    "end": "725960"
  },
  {
    "text": "steps, it'll raise a recursion error. Let's wait for this to happen. Continue to populate.",
    "start": "725970",
    "end": "730555"
  },
  {
    "text": "All right. It looks like, as we said, it's\ngoing to hit the rehearsal limit. Wasn't able to actually saw it.",
    "start": "731825",
    "end": "736834"
  },
  {
    "text": "You can see each of these steps\nbelow, and we'll actually jump over to Langsmith to check out the trajectory.",
    "start": "736855",
    "end": "743264"
  },
  {
    "text": "One second. All right, so we've checked\nout this trajectory here. You can see it going through\nthe loop as we defined it.",
    "start": "743565",
    "end": "751329"
  },
  {
    "start": "747000",
    "end": "813000"
  },
  {
    "text": "You have the prompt and LLM and\nthen you have the evaluate known and it goes in this loop and continues\nuntil it eventually has this error.",
    "start": "751750",
    "end": "758840"
  },
  {
    "text": "I always like to jump into one of the\nlater LLM calls because it does collect this full history of messages and\nyou can see exactly what it's doing.",
    "start": "759490",
    "end": "766730"
  },
  {
    "text": "So initially it says solve this problem. I'll do this. The key insight here and tries\nto write out the pseudocode and",
    "start": "766730",
    "end": "772610"
  },
  {
    "text": "thinking and then generates it all. There and the second one is the\ncurrent solution times out in a",
    "start": "772620",
    "end": "778205"
  },
  {
    "text": "larger test case is likely because it\niterates through all possible lanes. So it's trying to actually self\ncorrect here, but it's unable to it",
    "start": "778205",
    "end": "786295"
  },
  {
    "text": "doesn't have a lot of good examples\nof solving this type of problem, I guess, and -it's in its memory. And so, as you can see, it goes\nthrough quite a number of things.",
    "start": "786295",
    "end": "793735"
  },
  {
    "text": "So it wasn't able to get it correct. That's all right. The paper presents at least one\nmore automatic improvement that we",
    "start": "795445",
    "end": "802535"
  },
  {
    "text": "can be incorporating into it and\nthen also presents the idea of more of a co pilot type of scenario,\nwhich we'll get to in part three.",
    "start": "802535",
    "end": "808655"
  },
  {
    "text": "But in part two, let's jump into the\nmemory and retrieval optimization.",
    "start": "808705",
    "end": "813035"
  },
  {
    "start": "813000",
    "end": "1128000"
  },
  {
    "text": "All right, so back in the notebook,\nin part two, we're going to be implementing this few shot retrieval\noptimization that the paper proposes.",
    "start": "814065",
    "end": "820065"
  },
  {
    "text": "And the authors call this an episodic\nmemory because it's retrieving these outputs from the other\nquestion answer pairs in the corpus.",
    "start": "820495",
    "end": "828135"
  },
  {
    "text": "So if you pretend that the algorithm,\nor that the agent, has already solved all these other problems,\nit could then recall this and use",
    "start": "828175",
    "end": "835535"
  },
  {
    "text": "this for solving later problems. It's kind of an interesting framing,\nand kind of in contrast to the rule of",
    "start": "835535",
    "end": "842375"
  },
  {
    "text": "thumb, where people tend to talk about\nRAG and retrieval as a way to improve knowledge and update knowledge, but not\nas a mechanism for actually improving",
    "start": "842375",
    "end": "850834"
  },
  {
    "text": "the reasoning capabilities of the agent. Though since these are extremely well\nselected, well crafted in domain examples,",
    "start": "850835",
    "end": "858964"
  },
  {
    "text": "this does then align more with few shot\ninstruction and optimizations like that. That's more of what it is.",
    "start": "859135",
    "end": "864704"
  },
  {
    "text": "The paper also explores a semantic\nmemory where it's retrieving over textbooks and things, and that does show\na brief boost, but doesn't seem to hold",
    "start": "865135",
    "end": "872115"
  },
  {
    "text": "whenever they incorporate that later\nwith the reflection and other things. So, it seems to be a technique that\ndoesn't really scale quite to the",
    "start": "872115",
    "end": "879575"
  },
  {
    "text": "same extent as this high quality\ninstruction type of data set. So, we'll skip that for here.",
    "start": "879575",
    "end": "884334"
  },
  {
    "text": "Following the paper, we'll use as\nthe retriever this BM25 retriever.",
    "start": "884945",
    "end": "889665"
  },
  {
    "text": "It's essentially a more old fashioned,\nnon vector based, TFIDF based retrieval",
    "start": "890025",
    "end": "895725"
  },
  {
    "text": "mechanism here that's high quality. And then to accommodate these steps,\nwe're going to add two more keys",
    "start": "896255",
    "end": "903654"
  },
  {
    "text": "to our state compared to part one. We're going to add this candidate message. that we generate first, and it's going\nto be used in the retrieval step.",
    "start": "903655",
    "end": "911444"
  },
  {
    "text": "And then we'll have the\nexamples formatted in strings. If you remember the prompt at first,\nit had that examples template.",
    "start": "911955",
    "end": "918553"
  },
  {
    "text": "We'll finally be populating that here. And then again, recall that this episodic\nmemory happens before our agent loop.",
    "start": "918554",
    "end": "925895"
  },
  {
    "text": "This part is going to be untouched here. But here we're going to be\nhaving the retrieval step.",
    "start": "926055",
    "end": "931105"
  },
  {
    "text": "And then we'll still ignore this\nand save this for part three. So once we define our new\nstate, we can define the solver.",
    "start": "931435",
    "end": "937000"
  },
  {
    "text": "This is mostly repeat from before, except\nwe're going to have a little if statement to generate populate the candidate step,\nif it's still that first stage there.",
    "start": "937070",
    "end": "943980"
  },
  {
    "text": "So we're going to make this draft\nsolver and solver, they're pretty much identical, except the draft solver of\ncourse hasn't already had questions here.",
    "start": "944280",
    "end": "950869"
  },
  {
    "text": "Well then, to just make sure that\nwe avoid cheating by putting the actual answer to our question in the\nretriever, we're going to separate out",
    "start": "952170",
    "end": "960010"
  },
  {
    "text": "this as train and test , corpora and\nthen we'll create the retriever here.",
    "start": "960010",
    "end": "964435"
  },
  {
    "text": "Finally, it's time to\ndefine the retrieve node. So as before, it receives the\nstate here as all the nodes do, and",
    "start": "965725",
    "end": "974655"
  },
  {
    "text": "then returns this updated state. So it's going to update the\nexamples key in particular. And then within this, it\ncalls the retriever here.",
    "start": "974655",
    "end": "982625"
  },
  {
    "text": "So, Retriever invoke picks out\nthe top k there, and then formats",
    "start": "982885",
    "end": "988345"
  },
  {
    "text": "this in a string that we're going\nto be updating in the prompt. You'll notice that we add this\nrunnable config here in this graph",
    "start": "988345",
    "end": "995224"
  },
  {
    "text": "that we're defining, we're going\nto let you configure whenever you invoke the actual agent the number of\nretrieved examples that you'll have.",
    "start": "995234",
    "end": "1001674"
  },
  {
    "text": "One way to do that is through these\nconfigurable params in the config, which is always the second positional argument.",
    "start": "1002384",
    "end": "1007284"
  },
  {
    "text": "One more thing to note about this\nretriever setup that I think is quite interesting, is that we're\nretrieving, and we're treating the",
    "start": "1008534",
    "end": "1015744"
  },
  {
    "text": "candidate program as the query,\nrather than the initial question. This is kind of similar to techniques you\nmight have come across, such as HyDE, or",
    "start": "1015814",
    "end": "1024173"
  },
  {
    "text": "some of these other, like raft, or other\ntypes of indexing strategies for RAG.",
    "start": "1024174",
    "end": "1028633"
  },
  {
    "text": "The observation here is that The\ndistribution of queries is different than the distribution of documents\nthat you're trying to retrieve from.",
    "start": "1029619",
    "end": "1037449"
  },
  {
    "text": "And so you either want to be creating\nhypothetical queries from the documents that will better align with the type\nof queries that we're going to be",
    "start": "1037799",
    "end": "1044879"
  },
  {
    "text": "putting into the system, or we want\nto map from the queries to what you'd expect the document to look like\nand then maybe retrieve from that.",
    "start": "1044879",
    "end": "1051729"
  },
  {
    "text": "And then there's some other variants\nthere, but basically you're saying the type of text and the type of words\nthat we're going to put in these two",
    "start": "1052069",
    "end": "1057789"
  },
  {
    "text": "things is not going to be the same. And so you get better results if\nyou can try to translate them. Finally, it's time to build the graph.",
    "start": "1057789",
    "end": "1063849"
  },
  {
    "text": "So again, we've had most\nof this is the same here. So you see solve, evaluate, and\nlike all this stuff is untouched.",
    "start": "1063989",
    "end": "1071229"
  },
  {
    "text": "The things that we've added here\nreally are this draft node at the beginning, where we're putting in that\nsolver, and the retrieve node here.",
    "start": "1071439",
    "end": "1077839"
  },
  {
    "text": "So we're setting the draft node as\nthe entry point, retrieving, and then we're going to always progress\nin a directed edge from draft to",
    "start": "1078139",
    "end": "1084459"
  },
  {
    "text": "retrieve, and then retrieve to solve. And then, again, we'll create the loop of\nsolve to evaluate, and then from evaluate,",
    "start": "1084459",
    "end": "1090574"
  },
  {
    "text": "either go to the end or back to solve. So we're creating that. Here's the visualization, in\ncase that's easier to see.",
    "start": "1090614",
    "end": "1097174"
  },
  {
    "text": "So again, the rest of this is\nall the same, we've just added these two steps at the beginning.",
    "start": "1097254",
    "end": "1101444"
  },
  {
    "text": "Let's try it out. We're gonna, since we added a\ncheckpointer here, we're gonna add just ignore this here, but we're gonna\nsay retrieve three of these examples",
    "start": "1102444",
    "end": "1110474"
  },
  {
    "text": "from the corpus and pass those in. This is also going to take\nsome time, so bear with us.",
    "start": "1110634",
    "end": "1116364"
  },
  {
    "text": "All right, looks like our\ngraph finished already. You can see this is a\nlittle bit truncated. Let's jump over to Langsmith\nto see what exactly was done.",
    "start": "1117194",
    "end": "1123944"
  },
  {
    "text": "But you can see that from the\nstate that we've got, you can see that it was a success this time.",
    "start": "1123954",
    "end": "1128084"
  },
  {
    "start": "1128000",
    "end": "1266000"
  },
  {
    "text": "All right, now that we've jumped over to\nthe Langsmith trace, you can see it's only a few steps this time, so that's great. And following our  graph structure, we\nhad the draft node here, which again,",
    "start": "1129084",
    "end": "1138264"
  },
  {
    "text": "you put in the initial question, the\nsystem prompted the question, and it outputs the initial answer to the problem.",
    "start": "1138294",
    "end": "1144684"
  },
  {
    "text": "We retrieve some examples from it. So again, see the queries, this candidate\nprogram that we talked about, and it retrieves other examples from the\ncorpus, and then we pass that in here.",
    "start": "1145124",
    "end": "1153874"
  },
  {
    "text": "So you can see, Now those examples are\nformatted here in the system prompt for the solver, and then it has that.",
    "start": "1153894",
    "end": "1159979"
  },
  {
    "text": "All of it we don't have the initial\ncandidate program in here because we've saved it in a different key in the state,\nbut then it tries to generate an answer.",
    "start": "1160349",
    "end": "1167209"
  },
  {
    "text": "This time it's correct,\nand , test cases are successful. So, it's great.",
    "start": "1167499",
    "end": "1172225"
  },
  {
    "text": "I'll jump back to part three because\nwe see it solves this bronze level question, but how well does it\nsolve some of the more difficult",
    "start": "1172765",
    "end": "1179774"
  },
  {
    "text": "challenging ones in this benchmark? Alright, so Jumping back to the\nnotebook, let's test it on a",
    "start": "1179775",
    "end": "1185045"
  },
  {
    "text": "harder, silver level question. So we've got this from the DES dataset. You can see the question here.",
    "start": "1185045",
    "end": "1192825"
  },
  {
    "text": "It's a river cruise one. Basically you're trying to\ndetect cycles and then simulate",
    "start": "1193275",
    "end": "1198445"
  },
  {
    "text": "different steps of it as well. It gives a couple of sample inputs\nhere, but it's a much more challenging question than the first one here.",
    "start": "1198445",
    "end": "1204690"
  },
  {
    "text": "We'll format that and then run it. And we'll see how it does. I fully expect this not to work.",
    "start": "1205260",
    "end": "1210630"
  },
  {
    "text": "It may. But I expect this to fail. Because it's just a more\nchallenging problem.",
    "start": "1210640",
    "end": "1216500"
  },
  {
    "text": "And these OLMs, while they have\nbeen trained in a lot of code, a lot of reasoning types of problems,\nwhenever there's new ones, they",
    "start": "1216700",
    "end": "1222700"
  },
  {
    "text": "just kind of struggle to be\ncomposing them in creative ways. So some of these techniques can help,\nbut I think we're running into some of",
    "start": "1222700",
    "end": "1229965"
  },
  {
    "text": "the limits of the reasoning capabilities\nof agents as they stand today.",
    "start": "1229965",
    "end": "1234245"
  },
  {
    "text": "Alright, so our optimized\ngraph has finished, and we got another graph recursion error.",
    "start": "1235575",
    "end": "1240285"
  },
  {
    "text": "It wasn't able to correctly answer the\nproblem in the allocated number of steps.",
    "start": "1240645",
    "end": "1245355"
  },
  {
    "text": "That's okay. In fact, we expected it. These are extremely challenging problems,\nand they push LLMs, at least as they",
    "start": "1246265",
    "end": "1254375"
  },
  {
    "text": "are trained and designed today, to the\nlimits of their reasoning capabilities. Thank you. It requires some novel\ncombination of algorithms and data",
    "start": "1254375",
    "end": "1263040"
  },
  {
    "text": "structures in challenging ways. The paper explores then one final\ninference time optimization, which really",
    "start": "1263040",
    "end": "1271600"
  },
  {
    "start": "1266000",
    "end": "1603000"
  },
  {
    "text": "gets us from the realm of autonomous\nagents to the realm of co pilots. So that they can benchmark it, they\nrestricted human involvement to simple",
    "start": "1271620",
    "end": "1279740"
  },
  {
    "text": "guidance and prodding without revealing\nany parts of the answer or anything. But When you're building an actual\napplication, you often want to",
    "start": "1279750",
    "end": "1287675"
  },
  {
    "text": "optimize really for the end user\nexperience and maximizing the chance of accomplishing the goal.",
    "start": "1287685",
    "end": "1292935"
  },
  {
    "text": "If you are going to be creating\napplication where a user is in the loop, you want to give them a nice\nability really to be providing guidance",
    "start": "1293565",
    "end": "1301585"
  },
  {
    "text": "whenever and wherever they want. LangGraph makes this pretty easy. So for the sake of this tutorial, and in\npart 3, we're just going to add a generic",
    "start": "1301595",
    "end": "1310695"
  },
  {
    "text": "human in the loop interface to our agent. And we're going to insert it right here.",
    "start": "1310735",
    "end": "1315605"
  },
  {
    "text": "So the agent graph is going\nto be structured exactly the same way as part two.",
    "start": "1316235",
    "end": "1320605"
  },
  {
    "text": "We'll insert the problem, the agent\nwill generate a candidate program, the program will retrieve similar high\nquality examples from this corpora of",
    "start": "1321255",
    "end": "1329404"
  },
  {
    "text": "semantic memory, or episodic memory,\nand then the agent tries to solve it, it generates the program here,\nthen runs the test cases on them.",
    "start": "1329555",
    "end": "1339035"
  },
  {
    "text": "Then what we're changing in part three is\nwe're going to interrupt here, and then we'll say, A human is allowed to then\nlook at these keys, state of the graph",
    "start": "1339985",
    "end": "1348370"
  },
  {
    "text": "at this point, perhaps optionally add a\nmessage saying to consider some alternate route, consider looking into a specific\npart of the of the generated program, etc.",
    "start": "1348370",
    "end": "1358610"
  },
  {
    "text": "We can then resume execution at any time,\nsince LangGraph lets you just persist this in a checkpoint, and continue trying.",
    "start": "1359230",
    "end": "1365440"
  },
  {
    "text": "You can continue this loop and continue\nto intercede and provide feedback as it",
    "start": "1365500",
    "end": "1370520"
  },
  {
    "text": "goes through and hopefully prevent it,\nprevent the LLM from falling into these local optima, these local pit holes,\nwhere it's just looping through and unable",
    "start": "1370520",
    "end": "1378210"
  },
  {
    "text": "to actually accomplish the real task. Once you can collaboratively come to\nthe final answer, the agent can, and",
    "start": "1378210",
    "end": "1385510"
  },
  {
    "text": "the graph can finally finish executing. In theory, this type of design is\nonly restricted by the quality or",
    "start": "1385660",
    "end": "1393030"
  },
  {
    "text": "the capability of the user involved. Since really we can be providing the, the\ncorrect answer or any type of feedback",
    "start": "1393040",
    "end": "1399010"
  },
  {
    "text": "and the LLM will be able to synthesize\nthis and incorporate it into it. So let's jump into here and create\nthis human little loop agent for",
    "start": "1399010",
    "end": "1407110"
  },
  {
    "text": "solving computing Olympiad problems. This code block here is exactly\nthe same as in part two.",
    "start": "1407190",
    "end": "1412070"
  },
  {
    "text": "We get our checkpoint right here, and\nwe're just going to do that in memory. We've got our state graph, we're\nusing the exact same state here.",
    "start": "1412710",
    "end": "1419120"
  },
  {
    "text": "We've got the prompt in LLM. We create this draft\nsolver, add it to the node. We set that as the entry point.",
    "start": "1419190",
    "end": "1425500"
  },
  {
    "text": "We create the retrieve node. We create the solver node. And the evaluation node\nto run the test cases.",
    "start": "1425940",
    "end": "1431640"
  },
  {
    "text": "Then we start connecting them. So we add an edge for draft to\nretrieve, retrieve to solve. Solve to evaluate and then we\nadd these conditional edges to",
    "start": "1431640",
    "end": "1438965"
  },
  {
    "text": "define the conditional looping. So we say, once you run the test\ncases we'll either go back to the",
    "start": "1438965",
    "end": "1444255"
  },
  {
    "text": "solver or we'll finish if we succeed. And we'll create the\ncheck pointer as well.",
    "start": "1444265",
    "end": "1448125"
  },
  {
    "text": "The one different thing in part\n3 compared to part 2 is we're going to add this interrupt after\nthe evaluation node command.",
    "start": "1450385",
    "end": "1456145"
  },
  {
    "text": "So basically before it goes\nto a human step, we're going to tell the graph, Hey, stop.",
    "start": "1456655",
    "end": "1462185"
  },
  {
    "text": "and allow the human or any other\nprocess to be modifying the state.",
    "start": "1462645",
    "end": "1467135"
  },
  {
    "text": "Let's visualize this here. As you can see, the graph looks\nexactly the same as in part two, and we'll start running it.",
    "start": "1468815",
    "end": "1473535"
  },
  {
    "text": "So again, this is just going to continue\nexecuting until it reaches that interrupt.",
    "start": "1474625",
    "end": "1479045"
  },
  {
    "text": "All right, so our graph\nhas stopped executing. You can see the current state by looking\nat this snapshot using the config, and",
    "start": "1481865",
    "end": "1490544"
  },
  {
    "text": "you can see again the problem there. Note that it doesn't say a graph recursion\nerror, but it still has gotten the",
    "start": "1490545",
    "end": "1497285"
  },
  {
    "text": "incorrect submission as we expected. Since we added the interrupt, it\nactually will stop this loop and then",
    "start": "1497285",
    "end": "1503235"
  },
  {
    "text": "we can resume it So we can look again. Here's the silver problem that\nwe were looking at before.",
    "start": "1503235",
    "end": "1509670"
  },
  {
    "text": "It was unable to solve it so far. We're going to look at its\ncurrent candidate solution. So this is again printed out\nfrom the agent right now.",
    "start": "1509730",
    "end": "1516600"
  },
  {
    "text": "Looks okay. Maybe a little simple. Definitely doesn't handle\nall of the edge cases.",
    "start": "1517010",
    "end": "1521559"
  },
  {
    "text": "And then we can look at this test here,\nbecause that's the last tool message here. Incorrect submission. It actually got 8 out\nof 10, so pretty close.",
    "start": "1522110",
    "end": "1529050"
  },
  {
    "text": "Let's say let's give it\nsome recommendations here. Okay. as a human message.",
    "start": "1529480",
    "end": "1534580"
  },
  {
    "text": "And then we'll check to make sure that\nthat actually was reflecting the state. So you can see, we now have\nthis human message we've done by",
    "start": "1535020",
    "end": "1541620"
  },
  {
    "text": "calling graph dot update state\nand providing that config there. So it tells which snapshot to be updating.",
    "start": "1541620",
    "end": "1547790"
  },
  {
    "text": "And then you have the human message here\nand we can resume the way we resume here",
    "start": "1548340",
    "end": "1555460"
  },
  {
    "text": "is we pass in a null values and none. And then since we're using this. Same config that we're using it knows\nto load the current state from the check",
    "start": "1555480",
    "end": "1564435"
  },
  {
    "text": "pointer that we've compiled into the graph\nAgain, we use that in memory SQLite check pointer here for the sake of the tutorial\nBut there's a lot of implementations you",
    "start": "1564455",
    "end": "1572605"
  },
  {
    "text": "can use to connect with your own storage\narchitecture This is going to take a little bit of time, so again, we'll\nresume whenever it's done executing.",
    "start": "1572605",
    "end": "1580405"
  },
  {
    "text": "Alright, so in our case, it actually\nwas enough to get it to succeed. I had this other code here to try to\nprompt it into the right position, because",
    "start": "1581885",
    "end": "1590095"
  },
  {
    "text": "occasionally it doesn't succeed even\nafter that first bit of human feedback. But in our case, it does. As you can see, you can list through\nall of the states here, so I was just",
    "start": "1590175",
    "end": "1597745"
  },
  {
    "text": "getting the most recent checkpoint\nfrom this graph's execution, and we see that it's a success.",
    "start": "1597745",
    "end": "1601855"
  },
  {
    "text": "You can actually check out the\nLangsmith trace again here, I'll jump back to see it run.",
    "start": "1602955",
    "end": "1611105"
  },
  {
    "start": "1603000",
    "end": "1664000"
  },
  {
    "text": "And we see that again, we passed in null. If you remember from the loop in\nthe notebook, it goes, it loads.",
    "start": "1611485",
    "end": "1617165"
  },
  {
    "text": "We go back to the solver because\nthat's the next node slated to be executed in that graph.",
    "start": "1617165",
    "end": "1621995"
  },
  {
    "text": "It already run the draft and recall\nand retriever and all those steps. You can see the full list of messages to\nsee that yes, indeed, it has been fetching",
    "start": "1622185",
    "end": "1629865"
  },
  {
    "text": "these things from memory and includes\nthis recommendation that we've added.",
    "start": "1629865",
    "end": "1634515"
  },
  {
    "text": "We've put this all in a notebook, but\nagain, you can put in any sort of UI above the land graph implementation\nand allow the user to be interacting",
    "start": "1634995",
    "end": "1641735"
  },
  {
    "text": "with your copilot in arbitrary ways. So the AI is able to then incorporate\nthis breakdown into an updated response",
    "start": "1641735",
    "end": "1648544"
  },
  {
    "text": "that then passes all of the test cases. So I'd say it's a success. Thanks.",
    "start": "1648545",
    "end": "1653285"
  },
  {
    "start": "1664000",
    "end": "1843000"
  },
  {
    "text": "Alright, so that brings us\nto the end of this tutorial. As we saw, LLMs, as they're trained\ntoday, alone aren't super great at",
    "start": "1664010",
    "end": "1672419"
  },
  {
    "text": "solving this challenging type of\nreasoning problem problems posed by olympiad programming questions.",
    "start": "1672420",
    "end": "1678110"
  },
  {
    "text": "However, through some prompting\ntechniques and the better systems design, you can improve the average\nperformance of your programming.",
    "start": "1678740",
    "end": "1685425"
  },
  {
    "text": "Greatly from the low point of\nunder 9 percent to above 20%. And when you're building real applications\nto solve challenging problems, you can",
    "start": "1685585",
    "end": "1693985"
  },
  {
    "text": "create these sort of human in the loop\ninterfaces easily with Langraph to make it so that you can reach a better overall\noutcome compared to just the agent alone",
    "start": "1694115",
    "end": "1702905"
  },
  {
    "text": "and compared to just the human alone. I think these general techniques\nare fairly, fairly expansive and",
    "start": "1703085",
    "end": "1709294"
  },
  {
    "text": "can be applied in a lot of domains. So you'll recall, first we started\nwith a zero shot agent with reflection.",
    "start": "1709295",
    "end": "1714740"
  },
  {
    "text": "It basically prompted the agent to be\nlooking at the test case results, looking at the current solution, and then try to\nincorporate those results and feedback",
    "start": "1715000",
    "end": "1722800"
  },
  {
    "text": "into an updated candidate to eventually\nget out and solve the right problem. We saw how even on a bronze level\nproblem, this doesn't always",
    "start": "1722800",
    "end": "1729360"
  },
  {
    "text": "work, and so we then added in an\nadditional optimization for retrieval.",
    "start": "1729360",
    "end": "1734580"
  },
  {
    "text": "This, as the authors posed as a sort\nof , episodic memory, allowed the model to then fetch these really high\nquality examples from the corpus,",
    "start": "1735570",
    "end": "1744000"
  },
  {
    "text": "and use that to try to trigger a\nlittle bit better of an output that follows a similar design and approach.",
    "start": "1744270",
    "end": "1751150"
  },
  {
    "text": "This can induce better reasoning\nin this case because of these few shot instructions. We saw that that was able to solve\nthe bronze level question, but it",
    "start": "1752170",
    "end": "1760350"
  },
  {
    "text": "failed on the silver level question. So then we added in this human in a loop\ninterface with the interrupt after that",
    "start": "1760350",
    "end": "1766570"
  },
  {
    "text": "allowed us to then go in and modify the\ncheckpointed state of the graph to then guide the agent to come to a proper\nsolution to the problem that's hard.",
    "start": "1766570",
    "end": "1774830"
  },
  {
    "text": "As you can see from all of these steps,\nautonomous agents are really cool. They're not quite there yet in all\nof these challenging problems, but",
    "start": "1776525",
    "end": "1783995"
  },
  {
    "text": "through better engineering, through\nusing state machines, and all of this, you can come to some better designed\nsystems that are actually capable of",
    "start": "1784005",
    "end": "1790305"
  },
  {
    "text": "doing some pretty impressive work. I'm excited by this new data set\nbecause it is a lot more challenging",
    "start": "1790305",
    "end": "1795340"
  },
  {
    "text": "and shows the cracks in the abilities\nof our current types of language models as they are today, while also showing\nhow these hybrid systems, these neuro",
    "start": "1795340",
    "end": "1803570"
  },
  {
    "text": "symbolic approaches can be really\npowerful in improving performance. I'm excited to see other people come out\nwith better systems that can surpass those",
    "start": "1803570",
    "end": "1811480"
  },
  {
    "text": "presented by the authors and hopefully\nget to the point where they can solve all these types of questions, even without\nresorting on much, much larger models.",
    "start": "1811520",
    "end": "1819710"
  },
  {
    "text": "That's all that we have\nfor our tutorial today. If you have any questions or\ncomments, feel free to leave them in the comments below.",
    "start": "1821275",
    "end": "1826205"
  },
  {
    "text": "Check out the links in the\ndescription as well to see the code and run it for yourself. And let us know what other types of\ntutorials you'd like to see that would",
    "start": "1827095",
    "end": "1833275"
  },
  {
    "text": "be helpful in implementing your own\nagents and chatbots and assistants. Until next time, this is Will,\nand hope you have a great day.",
    "start": "1833285",
    "end": "1840755"
  },
  {
    "text": "Bye!",
    "start": "1841355",
    "end": "1841565"
  }
]
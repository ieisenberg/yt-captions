[
  {
    "text": "a big focus of Lang train 0.1 is making",
    "start": "880",
    "end": "4200"
  },
  {
    "text": "it as easy as possible to use a language",
    "start": "4200",
    "end": "7640"
  },
  {
    "text": "model with external tools whether those",
    "start": "7640",
    "end": "10960"
  },
  {
    "text": "be a search engine a vector store um a",
    "start": "10960",
    "end": "14960"
  },
  {
    "text": "calculator a python repple anything like",
    "start": "14960",
    "end": "17560"
  },
  {
    "text": "that and so in order to make that as",
    "start": "17560",
    "end": "20240"
  },
  {
    "text": "easy as possible and as order to build a",
    "start": "20240",
    "end": "22119"
  },
  {
    "text": "really solid foundation for that we've",
    "start": "22119",
    "end": "24880"
  },
  {
    "text": "put a lot of emphasis on output parsing",
    "start": "24880",
    "end": "27359"
  },
  {
    "text": "which is what we call taking the output",
    "start": "27359",
    "end": "28880"
  },
  {
    "text": "of an llm which is either a string or a",
    "start": "28880",
    "end": "31160"
  },
  {
    "text": "chat message and converting that into a",
    "start": "31160",
    "end": "33480"
  },
  {
    "text": "format where it can be used easily in a",
    "start": "33480",
    "end": "36559"
  },
  {
    "text": "downstream",
    "start": "36559",
    "end": "37840"
  },
  {
    "text": "Manner and so two of the big things that",
    "start": "37840",
    "end": "40879"
  },
  {
    "text": "we've added recently um one is a table",
    "start": "40879",
    "end": "44800"
  },
  {
    "text": "of all the different output parsers that",
    "start": "44800",
    "end": "46840"
  },
  {
    "text": "we support um so the the name and whe a",
    "start": "46840",
    "end": "51079"
  },
  {
    "text": "few attributes about it and then",
    "start": "51079",
    "end": "52559"
  },
  {
    "text": "description of when to use it because we",
    "start": "52559",
    "end": "54399"
  },
  {
    "text": "recognize that we do have a lot of",
    "start": "54399",
    "end": "56320"
  },
  {
    "text": "different output parsers um and we've",
    "start": "56320",
    "end": "58199"
  },
  {
    "text": "accumulated these the community has",
    "start": "58199",
    "end": "59559"
  },
  {
    "text": "added these over time and so we wanted",
    "start": "59559",
    "end": "61199"
  },
  {
    "text": "to add this table that says you know",
    "start": "61199",
    "end": "63280"
  },
  {
    "text": "when to use it what it's good for and a",
    "start": "63280",
    "end": "64720"
  },
  {
    "text": "few key",
    "start": "64720",
    "end": "66560"
  },
  {
    "text": "attributes um the second thing that",
    "start": "66560",
    "end": "68840"
  },
  {
    "text": "we've put a lot of emphasis on is",
    "start": "68840",
    "end": "70920"
  },
  {
    "text": "streaming for these output parsers so",
    "start": "70920",
    "end": "73759"
  },
  {
    "text": "streaming as general as we mentioned",
    "start": "73759",
    "end": "75720"
  },
  {
    "text": "before in in a previous video is is",
    "start": "75720",
    "end": "77720"
  },
  {
    "text": "really important for us and streaming",
    "start": "77720",
    "end": "79759"
  },
  {
    "text": "can be tricky for output parsing because",
    "start": "79759",
    "end": "82200"
  },
  {
    "text": "let's let's take Json for example if you",
    "start": "82200",
    "end": "84200"
  },
  {
    "text": "want to parse something into a a a Json",
    "start": "84200",
    "end": "88000"
  },
  {
    "text": "blob um into like a dictionary",
    "start": "88000",
    "end": "91119"
  },
  {
    "text": "if you only have half of the output if",
    "start": "91119",
    "end": "92640"
  },
  {
    "text": "you only have half of the string if you",
    "start": "92640",
    "end": "93920"
  },
  {
    "text": "pass that to json. loads uh then it",
    "start": "93920",
    "end": "97040"
  },
  {
    "text": "won't actually load um it will it will",
    "start": "97040",
    "end": "99520"
  },
  {
    "text": "raise an error because only half of it",
    "start": "99520",
    "end": "100920"
  },
  {
    "text": "is there same with XML same with other",
    "start": "100920",
    "end": "103759"
  },
  {
    "text": "formats and so we've put a lot of",
    "start": "103759",
    "end": "105079"
  },
  {
    "text": "emphasis on basically making it easy and",
    "start": "105079",
    "end": "109320"
  },
  {
    "text": "possible to get streaming for things",
    "start": "109320",
    "end": "111920"
  },
  {
    "text": "that have output parsers on them so",
    "start": "111920",
    "end": "116240"
  },
  {
    "text": "taking a look really quickly at this at",
    "start": "116240",
    "end": "118960"
  },
  {
    "text": "this notebook that I prepared preped to",
    "start": "118960",
    "end": "120159"
  },
  {
    "text": "walk through some of these examples um",
    "start": "120159",
    "end": "123240"
  },
  {
    "text": "first is just a basic uh uh the most",
    "start": "123240",
    "end": "126880"
  },
  {
    "text": "basic output parser that we have which",
    "start": "126880",
    "end": "128599"
  },
  {
    "text": "converts a chat message um into a string",
    "start": "128599",
    "end": "133200"
  },
  {
    "text": "so strings are more usable than chat",
    "start": "133200",
    "end": "135000"
  },
  {
    "text": "messages a lot of modern models return",
    "start": "135000",
    "end": "137519"
  },
  {
    "text": "chat messages and so we have a really",
    "start": "137519",
    "end": "139239"
  },
  {
    "text": "simple utility that just converts it",
    "start": "139239",
    "end": "140640"
  },
  {
    "text": "into a string and so we have this chain",
    "start": "140640",
    "end": "143280"
  },
  {
    "text": "if we call this chain um with this input",
    "start": "143280",
    "end": "146120"
  },
  {
    "text": "then we get back you know this AI",
    "start": "146120",
    "end": "147720"
  },
  {
    "text": "message often times we just want the",
    "start": "147720",
    "end": "149440"
  },
  {
    "text": "string",
    "start": "149440",
    "end": "150360"
  },
  {
    "text": "so we can add in this stir output parser",
    "start": "150360",
    "end": "152440"
  },
  {
    "text": "if you see these around the docs that's",
    "start": "152440",
    "end": "154120"
  },
  {
    "text": "why we use them in so many places to",
    "start": "154120",
    "end": "155959"
  },
  {
    "text": "convert it into a string that we can use",
    "start": "155959",
    "end": "157800"
  },
  {
    "text": "around because not all applications are",
    "start": "157800",
    "end": "160519"
  },
  {
    "text": "chat um the other um common output pars",
    "start": "160519",
    "end": "165080"
  },
  {
    "text": "that I want to walk through is one that",
    "start": "165080",
    "end": "167720"
  },
  {
    "text": "uses open aai function calling so",
    "start": "167720",
    "end": "171319"
  },
  {
    "text": "function calling was introduced by open",
    "start": "171319",
    "end": "173040"
  },
  {
    "text": "AI a while ago as a way to basically",
    "start": "173040",
    "end": "175879"
  },
  {
    "text": "return outputs in a structured manner",
    "start": "175879",
    "end": "177800"
  },
  {
    "text": "it's not guaranteed that they'll be in",
    "start": "177800",
    "end": "180000"
  },
  {
    "text": "that structured format but it's pretty",
    "start": "180000",
    "end": "181879"
  },
  {
    "text": "likely and so we've added some output",
    "start": "181879",
    "end": "184680"
  },
  {
    "text": "parsers and and a bunch of cookbooks to",
    "start": "184680",
    "end": "186440"
  },
  {
    "text": "make working with uh this function",
    "start": "186440",
    "end": "189280"
  },
  {
    "text": "calling ability really easy other models",
    "start": "189280",
    "end": "192239"
  },
  {
    "text": "are starting to add this as well um some",
    "start": "192239",
    "end": "194400"
  },
  {
    "text": "of them are just doing a drop and",
    "start": "194400",
    "end": "195720"
  },
  {
    "text": "replacement for open AI um so you can",
    "start": "195720",
    "end": "197879"
  },
  {
    "text": "use the exact same output pares that we",
    "start": "197879",
    "end": "199760"
  },
  {
    "text": "have here um others of them are slightly",
    "start": "199760",
    "end": "201840"
  },
  {
    "text": "different and so we add support for",
    "start": "201840",
    "end": "203440"
  },
  {
    "text": "those but at the moment open a function",
    "start": "203440",
    "end": "205799"
  },
  {
    "text": "calling is probably the most reliable",
    "start": "205799",
    "end": "207319"
  },
  {
    "text": "way to get structured information back",
    "start": "207319",
    "end": "210000"
  },
  {
    "text": "from a language model and so we've",
    "start": "210000",
    "end": "211640"
  },
  {
    "text": "focused on really adding really good",
    "start": "211640",
    "end": "214159"
  },
  {
    "text": "support for it so part of that comes",
    "start": "214159",
    "end": "217760"
  },
  {
    "text": "with a nice developer experience as well",
    "start": "217760",
    "end": "219720"
  },
  {
    "text": "and so for that we rely heavily on",
    "start": "219720",
    "end": "221560"
  },
  {
    "text": "pantic so pantic makes it really easy to",
    "start": "221560",
    "end": "224480"
  },
  {
    "text": "Define um basically schemas for things",
    "start": "224480",
    "end": "228640"
  },
  {
    "text": "so open a function callings relies on",
    "start": "228640",
    "end": "230560"
  },
  {
    "text": "Json schemas being passed in I don't I",
    "start": "230560",
    "end": "233879"
  },
  {
    "text": "don't really like writing Json schemas",
    "start": "233879",
    "end": "235680"
  },
  {
    "text": "by hand I'd much rather write a pantic",
    "start": "235680",
    "end": "237640"
  },
  {
    "text": "module and then convert that to a Json",
    "start": "237640",
    "end": "239720"
  },
  {
    "text": "schema so I can do that by having uh by",
    "start": "239720",
    "end": "242439"
  },
  {
    "text": "using this base model thing from pantic",
    "start": "242439",
    "end": "244840"
  },
  {
    "text": "um I can then write this uh class called",
    "start": "244840",
    "end": "247400"
  },
  {
    "text": "joke um and I can give it a description",
    "start": "247400",
    "end": "250000"
  },
  {
    "text": "we actually require that all uh that all",
    "start": "250000",
    "end": "254120"
  },
  {
    "text": "uh of these um things that will convert",
    "start": "254120",
    "end": "257440"
  },
  {
    "text": "into Json schemas have descriptions and",
    "start": "257440",
    "end": "260280"
  },
  {
    "text": "the reason that we do that is because",
    "start": "260280",
    "end": "262440"
  },
  {
    "text": "this uh function colon definition this",
    "start": "262440",
    "end": "264680"
  },
  {
    "text": "joke thing right here this is actually a",
    "start": "264680",
    "end": "268520"
  },
  {
    "text": "uh this goes into the prompt think of",
    "start": "268520",
    "end": "269960"
  },
  {
    "text": "this as a prompt so everything that we",
    "start": "269960",
    "end": "271240"
  },
  {
    "text": "write here from the description of the",
    "start": "271240",
    "end": "273560"
  },
  {
    "text": "overall thing to the description of each",
    "start": "273560",
    "end": "275240"
  },
  {
    "text": "field is really prompting the language",
    "start": "275240",
    "end": "277039"
  },
  {
    "text": "model and so we want to make sure that",
    "start": "277039",
    "end": "279080"
  },
  {
    "text": "you're writing prompts so we require",
    "start": "279080",
    "end": "280240"
  },
  {
    "text": "that you have it here for the fields",
    "start": "280240",
    "end": "282600"
  },
  {
    "text": "it's optional but we also provide it",
    "start": "282600",
    "end": "284039"
  },
  {
    "text": "here we've provide some description on",
    "start": "284039",
    "end": "285960"
  },
  {
    "text": "basically how to use this um and so from",
    "start": "285960",
    "end": "290000"
  },
  {
    "text": "there we then have a helper function to",
    "start": "290000",
    "end": "292520"
  },
  {
    "text": "convert from a pantic model to this to",
    "start": "292520",
    "end": "295039"
  },
  {
    "text": "the open AI function um schema that it",
    "start": "295039",
    "end": "298080"
  },
  {
    "text": "requires um and then we have uh this",
    "start": "298080",
    "end": "300800"
  },
  {
    "text": "output uh this open AI functions parser",
    "start": "300800",
    "end": "304000"
  },
  {
    "text": "which converts it to Json um so Json is",
    "start": "304000",
    "end": "306479"
  },
  {
    "text": "a really convenient uh schema to use to",
    "start": "306479",
    "end": "308800"
  },
  {
    "text": "pass into Downstream things so we can",
    "start": "308800",
    "end": "310680"
  },
  {
    "text": "create this parser we can then create a",
    "start": "310680",
    "end": "312800"
  },
  {
    "text": "chain um and so the chain is this prompt",
    "start": "312800",
    "end": "315600"
  },
  {
    "text": "it's this model but we also pass in",
    "start": "315600",
    "end": "317840"
  },
  {
    "text": "functions so we pass in this uh this",
    "start": "317840",
    "end": "322160"
  },
  {
    "text": "open AI functions list that we have here",
    "start": "322160",
    "end": "325199"
  },
  {
    "text": "um and then we and then we pass the",
    "start": "325199",
    "end": "326680"
  },
  {
    "text": "result of this we chain it with this",
    "start": "326680",
    "end": "328560"
  },
  {
    "text": "parser and so if we do this we can see",
    "start": "328560",
    "end": "331800"
  },
  {
    "text": "that it returns um a uh it returns a",
    "start": "331800",
    "end": "335759"
  },
  {
    "text": "Json blob with a setup and a punch line",
    "start": "335759",
    "end": "338240"
  },
  {
    "text": "and so to get a little bit more",
    "start": "338240",
    "end": "339280"
  },
  {
    "text": "intuition we can take a look at Lang",
    "start": "339280",
    "end": "340639"
  },
  {
    "text": "Smith to see what's going on under the",
    "start": "340639",
    "end": "344000"
  },
  {
    "text": "hood if we take a look at L lsmith we",
    "start": "344840",
    "end": "347560"
  },
  {
    "text": "can find the run here um we can go into",
    "start": "347560",
    "end": "350360"
  },
  {
    "text": "it there's one important call but let's",
    "start": "350360",
    "end": "352199"
  },
  {
    "text": "look at all of them just because uh we",
    "start": "352199",
    "end": "354919"
  },
  {
    "text": "want to see exactly what's going on",
    "start": "354919",
    "end": "356560"
  },
  {
    "text": "first is the chat prompt template",
    "start": "356560",
    "end": "358280"
  },
  {
    "text": "basically just formats it into a prompt",
    "start": "358280",
    "end": "360000"
  },
  {
    "text": "to the language model now let's look at",
    "start": "360000",
    "end": "361639"
  },
  {
    "text": "the interesting bit the open Ai call so",
    "start": "361639",
    "end": "364400"
  },
  {
    "text": "here we can see that we have this",
    "start": "364400",
    "end": "365880"
  },
  {
    "text": "function definition up here so this is",
    "start": "365880",
    "end": "367919"
  },
  {
    "text": "the input this is the prompt um this is",
    "start": "367919",
    "end": "371280"
  },
  {
    "text": "also part of the input it's the function",
    "start": "371280",
    "end": "373160"
  },
  {
    "text": "definition so if we click here we can",
    "start": "373160",
    "end": "375720"
  },
  {
    "text": "now see a a nice description of the",
    "start": "375720",
    "end": "378240"
  },
  {
    "text": "function that we passed in we can see",
    "start": "378240",
    "end": "379880"
  },
  {
    "text": "the name of it the description here and",
    "start": "379880",
    "end": "381840"
  },
  {
    "text": "then the different arguments and their",
    "start": "381840",
    "end": "383560"
  },
  {
    "text": "types and their names and the",
    "start": "383560",
    "end": "385199"
  },
  {
    "text": "descriptions for those we can also see",
    "start": "385199",
    "end": "387919"
  },
  {
    "text": "the output of this language model call",
    "start": "387919",
    "end": "390120"
  },
  {
    "text": "and it's this is the raw response from",
    "start": "390120",
    "end": "392560"
  },
  {
    "text": "open AI it's got this function call um",
    "start": "392560",
    "end": "395080"
  },
  {
    "text": "thing this is the syntax they use um",
    "start": "395080",
    "end": "397720"
  },
  {
    "text": "with arguments and names um and so we",
    "start": "397720",
    "end": "401680"
  },
  {
    "text": "can see what the Json output function",
    "start": "401680",
    "end": "403280"
  },
  {
    "text": "parser is actually doing um and it's",
    "start": "403280",
    "end": "405599"
  },
  {
    "text": "taking in this which is the AI message",
    "start": "405599",
    "end": "409680"
  },
  {
    "text": "that's returned from open AI which has",
    "start": "409680",
    "end": "411400"
  },
  {
    "text": "no content but then has this function",
    "start": "411400",
    "end": "413160"
  },
  {
    "text": "call thing and uh these this arguments",
    "start": "413160",
    "end": "416120"
  },
  {
    "text": "here is a Json string and it's basically",
    "start": "416120",
    "end": "419080"
  },
  {
    "text": "par it out correctly and returning the",
    "start": "419080",
    "end": "421199"
  },
  {
    "text": "setup and the punch and the punch",
    "start": "421199",
    "end": "423960"
  },
  {
    "text": "line as mentioned we've also done a lot",
    "start": "423960",
    "end": "426800"
  },
  {
    "text": "of work to support streaming here um so",
    "start": "426800",
    "end": "429440"
  },
  {
    "text": "here we can uh do the same thing let's",
    "start": "429440",
    "end": "432360"
  },
  {
    "text": "pass in bears as a topic or bars as a",
    "start": "432360",
    "end": "435160"
  },
  {
    "text": "topic um and so here um we can see that",
    "start": "435160",
    "end": "438599"
  },
  {
    "text": "it streams back results so again like",
    "start": "438599",
    "end": "442039"
  },
  {
    "text": "this is being done by parsing The",
    "start": "442039",
    "end": "444960"
  },
  {
    "text": "partially completed Json string um",
    "start": "444960",
    "end": "447199"
  },
  {
    "text": "figuring out which keys are present and",
    "start": "447199",
    "end": "448919"
  },
  {
    "text": "then rep presenting",
    "start": "448919",
    "end": "450599"
  },
  {
    "text": "those for all these output uh parser",
    "start": "450599",
    "end": "453400"
  },
  {
    "text": "types um we've also included notebooks",
    "start": "453400",
    "end": "455879"
  },
  {
    "text": "on how to use them um so if you click on",
    "start": "455879",
    "end": "459360"
  },
  {
    "text": "any one of them you'll see uh uh",
    "start": "459360",
    "end": "461680"
  },
  {
    "text": "notebooks and tutorials on how to use",
    "start": "461680",
    "end": "463360"
  },
  {
    "text": "them um streaming some some",
    "start": "463360",
    "end": "465560"
  },
  {
    "text": "functionality there we've invested a lot",
    "start": "465560",
    "end": "467680"
  },
  {
    "text": "of work in making it easy to structure",
    "start": "467680",
    "end": "469639"
  },
  {
    "text": "the responses from language models um",
    "start": "469639",
    "end": "472159"
  },
  {
    "text": "because that's a big part of what Lang",
    "start": "472159",
    "end": "474080"
  },
  {
    "text": "chain uh uh does um some of that is",
    "start": "474080",
    "end": "477199"
  },
  {
    "text": "using open a function calling other of",
    "start": "477199",
    "end": "479440"
  },
  {
    "text": "that doesn't rely on it because a lot of",
    "start": "479440",
    "end": "480960"
  },
  {
    "text": "Open Source models and other models",
    "start": "480960",
    "end": "482400"
  },
  {
    "text": "don't have that and so we have actually",
    "start": "482400",
    "end": "484080"
  },
  {
    "text": "the majority of our output parsers don't",
    "start": "484080",
    "end": "485639"
  },
  {
    "text": "use function calling at",
    "start": "485639",
    "end": "488800"
  },
  {
    "text": "all",
    "start": "488800",
    "end": "491800"
  }
]
[
  {
    "start": "0",
    "end": "120000"
  },
  {
    "text": "hi this is Lance from Lang chain I want",
    "start": "1240",
    "end": "3320"
  },
  {
    "text": "to walk through building a rag app from",
    "start": "3320",
    "end": "5080"
  },
  {
    "text": "scratch using NX new long context",
    "start": "5080",
    "end": "7919"
  },
  {
    "text": "embedding model so one Trend I think is",
    "start": "7919",
    "end": "10719"
  },
  {
    "text": "really interesting is the expansion of",
    "start": "10719",
    "end": "12719"
  },
  {
    "text": "context windows for llms and embedding",
    "start": "12719",
    "end": "15199"
  },
  {
    "text": "models so we can see with methods like",
    "start": "15199",
    "end": "17720"
  },
  {
    "text": "rope or self- extend open source llms",
    "start": "17720",
    "end": "20640"
  },
  {
    "text": "like llama 2 and 52 mraw mix TRW have",
    "start": "20640",
    "end": "23599"
  },
  {
    "text": "all seen expansion in their context",
    "start": "23599",
    "end": "25400"
  },
  {
    "text": "windows out from you know 4K up to 32k",
    "start": "25400",
    "end": "29519"
  },
  {
    "text": "or Beyond",
    "start": "29519",
    "end": "30519"
  },
  {
    "text": "which is really interesting because it",
    "start": "30519",
    "end": "32279"
  },
  {
    "text": "lets us fit from you know at 4K it's",
    "start": "32279",
    "end": "35079"
  },
  {
    "text": "like a few dozen Pages up to like many",
    "start": "35079",
    "end": "38120"
  },
  {
    "text": "dozen or small hundreds of pages we can",
    "start": "38120",
    "end": "40079"
  },
  {
    "text": "actually pass into these",
    "start": "40079",
    "end": "41760"
  },
  {
    "text": "llms and we've actually seen embedding",
    "start": "41760",
    "end": "44120"
  },
  {
    "text": "models go through the same",
    "start": "44120",
    "end": "45480"
  },
  {
    "text": "transformation most recently with NX",
    "start": "45480",
    "end": "47960"
  },
  {
    "text": "model we actually have a context window",
    "start": "47960",
    "end": "50280"
  },
  {
    "text": "around 8,000 tokens which is on the",
    "start": "50280",
    "end": "52920"
  },
  {
    "text": "which is on par with ada2 from open Ai",
    "start": "52920",
    "end": "56359"
  },
  {
    "text": "and a few others and so nomic relased a",
    "start": "56359",
    "end": "60039"
  },
  {
    "text": "nice blog post today in a paper uh that",
    "start": "60039",
    "end": "62760"
  },
  {
    "text": "shows really strong performance on a few",
    "start": "62760",
    "end": "64518"
  },
  {
    "text": "benchmarks including this long context",
    "start": "64519",
    "end": "66920"
  },
  {
    "text": "Benchmark that was recently put out by",
    "start": "66920",
    "end": "68640"
  },
  {
    "text": "hazy",
    "start": "68640",
    "end": "69479"
  },
  {
    "text": "research um so what we're going to do is",
    "start": "69479",
    "end": "71840"
  },
  {
    "text": "we'll show how to use this from scratch",
    "start": "71840",
    "end": "73920"
  },
  {
    "text": "and we'll build a rag app that's going",
    "start": "73920",
    "end": "75280"
  },
  {
    "text": "to look something like this we'll take",
    "start": "75280",
    "end": "77640"
  },
  {
    "text": "documents we'll embed them using this",
    "start": "77640",
    "end": "79880"
  },
  {
    "text": "nomic embedding model we'll then store",
    "start": "79880",
    "end": "82280"
  },
  {
    "text": "them in a vector store we'll take an",
    "start": "82280",
    "end": "84759"
  },
  {
    "text": "input question embed it retrieve",
    "start": "84759",
    "end": "87840"
  },
  {
    "text": "relevant documents and then then process",
    "start": "87840",
    "end": "90880"
  },
  {
    "text": "them using an open source llm to produce",
    "start": "90880",
    "end": "93479"
  },
  {
    "text": "an answer that's going to be kind of our",
    "start": "93479",
    "end": "96040"
  },
  {
    "text": "workflow um now let's kind of start from",
    "start": "96040",
    "end": "98560"
  },
  {
    "text": "scratch here now all I need to do is a",
    "start": "98560",
    "end": "102439"
  },
  {
    "text": "few pip installs which I've already done",
    "start": "102439",
    "end": "105399"
  },
  {
    "text": "I've also logged into nomic here it's",
    "start": "105399",
    "end": "107840"
  },
  {
    "text": "giving me an API token I set my token um",
    "start": "107840",
    "end": "110719"
  },
  {
    "text": "I also set that as environment variable",
    "start": "110719",
    "end": "112320"
  },
  {
    "text": "so you can just do take care of that",
    "start": "112320",
    "end": "113520"
  },
  {
    "text": "yourself I also use uh lsmith and we'll",
    "start": "113520",
    "end": "116880"
  },
  {
    "text": "see why that's kind of useful next but",
    "start": "116880",
    "end": "118759"
  },
  {
    "text": "of course it's optional",
    "start": "118759",
    "end": "120600"
  },
  {
    "start": "120000",
    "end": "440000"
  },
  {
    "text": "um now let let's kind of Kick this off",
    "start": "120600",
    "end": "122560"
  },
  {
    "text": "so first I want to load some",
    "start": "122560",
    "end": "124920"
  },
  {
    "text": "documents so I'm going to use this Lang",
    "start": "124920",
    "end": "127360"
  },
  {
    "text": "chain webbased loader to load from three",
    "start": "127360",
    "end": "130000"
  },
  {
    "text": "URLs um which are blog posts I really",
    "start": "130000",
    "end": "132520"
  },
  {
    "text": "like so I can load those now those are",
    "start": "132520",
    "end": "135680"
  },
  {
    "text": "load into this list so that's great a",
    "start": "135680",
    "end": "138920"
  },
  {
    "text": "few blog posts here",
    "start": "138920",
    "end": "140599"
  },
  {
    "text": "okay great now what I'm going to do is",
    "start": "140599",
    "end": "143920"
  },
  {
    "text": "I'm going to split them so I'm going to",
    "start": "143920",
    "end": "145920"
  },
  {
    "text": "use this character text Splitter from",
    "start": "145920",
    "end": "148239"
  },
  {
    "text": "Lang chain and I'm going to use Tik",
    "start": "148239",
    "end": "150440"
  },
  {
    "text": "token encoder which means I'm going to",
    "start": "150440",
    "end": "151920"
  },
  {
    "text": "split based upon tokens and I'm setting",
    "start": "151920",
    "end": "154920"
  },
  {
    "text": "a big chunk size so",
    "start": "154920",
    "end": "157239"
  },
  {
    "text": "7500 okay so there we go we have our",
    "start": "157239",
    "end": "161120"
  },
  {
    "text": "splits now we can kind of look at those",
    "start": "161120",
    "end": "163599"
  },
  {
    "text": "just check",
    "start": "163599",
    "end": "166200"
  },
  {
    "text": "those good Okay so we've taken our",
    "start": "168319",
    "end": "171560"
  },
  {
    "text": "documents we've loaded them we've split",
    "start": "171560",
    "end": "173200"
  },
  {
    "text": "them using a big chunk size because I",
    "start": "173200",
    "end": "174840"
  },
  {
    "text": "have a embedding model that can process",
    "start": "174840",
    "end": "176360"
  },
  {
    "text": "up to 8K and I'm going to use an llm",
    "start": "176360",
    "end": "179120"
  },
  {
    "text": "that can process up to",
    "start": "179120",
    "end": "181640"
  },
  {
    "text": "32k now I just make have a few Imports",
    "start": "181640",
    "end": "185200"
  },
  {
    "text": "here there we",
    "start": "185200",
    "end": "186959"
  },
  {
    "text": "go now I'm going to show you something",
    "start": "186959",
    "end": "188959"
  },
  {
    "text": "that's pretty interesting which brings",
    "start": "188959",
    "end": "190879"
  },
  {
    "text": "in the GIC embeddings so all I'm doing",
    "start": "190879",
    "end": "193959"
  },
  {
    "text": "here is I'm creating a vector store from",
    "start": "193959",
    "end": "195480"
  },
  {
    "text": "Chromo which is open source Vector",
    "start": "195480",
    "end": "197840"
  },
  {
    "text": "store I simply pass in my document",
    "start": "197840",
    "end": "200280"
  },
  {
    "text": "splits which we defined here I Define a",
    "start": "200280",
    "end": "203040"
  },
  {
    "text": "collection name I call it rag chroma now",
    "start": "203040",
    "end": "205879"
  },
  {
    "text": "I apply my open ey my embedding model",
    "start": "205879",
    "end": "208280"
  },
  {
    "text": "here and I'm I'm specifying noic",
    "start": "208280",
    "end": "210480"
  },
  {
    "text": "embeddings with this new model and",
    "start": "210480",
    "end": "213159"
  },
  {
    "text": "that's it I build my retriever from",
    "start": "213159",
    "end": "215319"
  },
  {
    "text": "this so what this allows is when I have",
    "start": "215319",
    "end": "218239"
  },
  {
    "text": "this retriever I can basically call get",
    "start": "218239",
    "end": "220159"
  },
  {
    "text": "relevant documents on",
    "start": "220159",
    "end": "223319"
  },
  {
    "text": "it right and I can pass in any question",
    "start": "223360",
    "end": "227680"
  },
  {
    "text": "um and it'll get me you know task de",
    "start": "227680",
    "end": "232000"
  },
  {
    "text": "composition and it'll get me documents",
    "start": "232000",
    "end": "234599"
  },
  {
    "text": "so now I have a retriever that has taken",
    "start": "234599",
    "end": "237200"
  },
  {
    "text": "my use nomic embeddings to embed my",
    "start": "237200",
    "end": "239360"
  },
  {
    "text": "documents it makes them easy to",
    "start": "239360",
    "end": "242000"
  },
  {
    "text": "retrieve so this now I'm going to show",
    "start": "242000",
    "end": "244920"
  },
  {
    "text": "you something that I really like uh when",
    "start": "244920",
    "end": "247439"
  },
  {
    "text": "it comes to running local",
    "start": "247439",
    "end": "249519"
  },
  {
    "text": "models I like to use",
    "start": "249519",
    "end": "251879"
  },
  {
    "text": "AMA it's super convenient all you have",
    "start": "251879",
    "end": "254680"
  },
  {
    "text": "to do is just download AMA and have it",
    "start": "254680",
    "end": "256720"
  },
  {
    "text": "running so I actually just having it",
    "start": "256720",
    "end": "257880"
  },
  {
    "text": "running on my machine and all you have",
    "start": "257880",
    "end": "261000"
  },
  {
    "text": "to run is this command AMA pull like",
    "start": "261000",
    "end": "263919"
  },
  {
    "text": "your model of interest",
    "start": "263919",
    "end": "268000"
  },
  {
    "text": "um",
    "start": "268600",
    "end": "271600"
  },
  {
    "text": "so for",
    "start": "271960",
    "end": "273080"
  },
  {
    "text": "example right here aama pull mrw",
    "start": "273080",
    "end": "277560"
  },
  {
    "text": "instruct um and this will actually just",
    "start": "277560",
    "end": "280600"
  },
  {
    "text": "pull the model for",
    "start": "280600",
    "end": "282199"
  },
  {
    "text": "me then it's accessible to me when I",
    "start": "282199",
    "end": "284479"
  },
  {
    "text": "want to run",
    "start": "284479",
    "end": "285479"
  },
  {
    "text": "it um so now I actually have some codes",
    "start": "285479",
    "end": "289000"
  },
  {
    "text": "set here already which is just for",
    "start": "289000",
    "end": "291039"
  },
  {
    "text": "convenience I can specify a prompt for",
    "start": "291039",
    "end": "293720"
  },
  {
    "text": "rag which is answer the question based",
    "start": "293720",
    "end": "296520"
  },
  {
    "text": "on the following context here's my",
    "start": "296520",
    "end": "298759"
  },
  {
    "text": "context key here's my",
    "start": "298759",
    "end": "300800"
  },
  {
    "text": "question and set that as a prompt",
    "start": "300800",
    "end": "304759"
  },
  {
    "text": "here now here is where I specify my llm",
    "start": "304759",
    "end": "309600"
  },
  {
    "text": "so I set AMA llm to mrol instruct and I",
    "start": "309600",
    "end": "313960"
  },
  {
    "text": "set it here and I build a rag",
    "start": "313960",
    "end": "317440"
  },
  {
    "text": "chain so all that's happening then is",
    "start": "317440",
    "end": "322319"
  },
  {
    "text": "I'm building a dictionary that I can",
    "start": "322319",
    "end": "324080"
  },
  {
    "text": "pass into my prompt context is what we",
    "start": "324080",
    "end": "327000"
  },
  {
    "text": "retrieve from our Vector store right",
    "start": "327000",
    "end": "328840"
  },
  {
    "text": "here",
    "start": "328840",
    "end": "330199"
  },
  {
    "text": "the question we pass through from the",
    "start": "330199",
    "end": "332240"
  },
  {
    "text": "user and those populate these two keys",
    "start": "332240",
    "end": "335000"
  },
  {
    "text": "context question those go into our",
    "start": "335000",
    "end": "336680"
  },
  {
    "text": "prompt so populates our prompt we pipe",
    "start": "336680",
    "end": "339560"
  },
  {
    "text": "that prompt into our local llm we parse",
    "start": "339560",
    "end": "342520"
  },
  {
    "text": "the output and that's really it now we",
    "start": "342520",
    "end": "344919"
  },
  {
    "text": "can see I can run invoke here and I know",
    "start": "344919",
    "end": "348840"
  },
  {
    "text": "this will take you know around 20",
    "start": "348840",
    "end": "351240"
  },
  {
    "text": "seconds when run",
    "start": "351240",
    "end": "352919"
  },
  {
    "text": "locally but what I'll show you in the",
    "start": "352919",
    "end": "355039"
  },
  {
    "text": "meantime is I can go over to Langs Smith",
    "start": "355039",
    "end": "358319"
  },
  {
    "text": "and we can actually see this is running",
    "start": "358319",
    "end": "359880"
  },
  {
    "text": "right now so this shows me my Retriever",
    "start": "359880",
    "end": "362960"
  },
  {
    "text": "and what's going on so here's the",
    "start": "362960",
    "end": "365120"
  },
  {
    "text": "documents that I retrieved and you can",
    "start": "365120",
    "end": "367440"
  },
  {
    "text": "see they're pretty big because we used",
    "start": "367440",
    "end": "369560"
  },
  {
    "text": "again a large chunk size and we embedded",
    "start": "369560",
    "end": "371440"
  },
  {
    "text": "them using nomic large context",
    "start": "371440",
    "end": "373639"
  },
  {
    "text": "embeddings and then I can see my chat",
    "start": "373639",
    "end": "376400"
  },
  {
    "text": "model it's still running but here is the",
    "start": "376400",
    "end": "379280"
  },
  {
    "text": "prompt that was passed",
    "start": "379280",
    "end": "381599"
  },
  {
    "text": "in let's check our notebook oh okay here",
    "start": "381599",
    "end": "384400"
  },
  {
    "text": "it is so actually the answer is here and",
    "start": "384400",
    "end": "386720"
  },
  {
    "text": "this should refresh there it is very",
    "start": "386720",
    "end": "389080"
  },
  {
    "text": "nice",
    "start": "389080",
    "end": "390440"
  },
  {
    "text": "uh it is all refreshed and we can see",
    "start": "390440",
    "end": "392199"
  },
  {
    "text": "here's our answer so that's really all",
    "start": "392199",
    "end": "394720"
  },
  {
    "text": "there is to it it's a pretty simple",
    "start": "394720",
    "end": "397240"
  },
  {
    "text": "process um as you can see going from",
    "start": "397240",
    "end": "402280"
  },
  {
    "text": "some set of documents splitting them",
    "start": "402280",
    "end": "404479"
  },
  {
    "text": "embedding them in indexing them using NX",
    "start": "404479",
    "end": "406520"
  },
  {
    "text": "embeddings and then running an open",
    "start": "406520",
    "end": "408560"
  },
  {
    "text": "source llm locally using AMA this is all",
    "start": "408560",
    "end": "411599"
  },
  {
    "text": "my laptop to process them and give me",
    "start": "411599",
    "end": "416039"
  },
  {
    "text": "answers so that's really the basic",
    "start": "416039",
    "end": "418039"
  },
  {
    "text": "workflow it's pretty simple",
    "start": "418039",
    "end": "420199"
  },
  {
    "text": "and this is all run using open source",
    "start": "420199",
    "end": "422319"
  },
  {
    "text": "components uh it's on my laptop the",
    "start": "422319",
    "end": "424680"
  },
  {
    "text": "embedding model is run through their API",
    "start": "424680",
    "end": "426840"
  },
  {
    "text": "but it will be available to run locally",
    "start": "426840",
    "end": "428400"
  },
  {
    "text": "soon so I'm actually really excited to",
    "start": "428400",
    "end": "429680"
  },
  {
    "text": "try that out and then this entire",
    "start": "429680",
    "end": "431319"
  },
  {
    "text": "workflow can be run both using you know",
    "start": "431319",
    "end": "433800"
  },
  {
    "text": "of course the embedding model through",
    "start": "433800",
    "end": "435120"
  },
  {
    "text": "API or locally on my",
    "start": "435120",
    "end": "437720"
  },
  {
    "text": "laptop so now you can see in our",
    "start": "437720",
    "end": "440319"
  },
  {
    "start": "440000",
    "end": "748000"
  },
  {
    "text": "notebook we've laid out this rag chain",
    "start": "440319",
    "end": "443360"
  },
  {
    "text": "and we talked through kind of How It's",
    "start": "443360",
    "end": "445000"
  },
  {
    "text": "architected we've shown how it works now",
    "start": "445000",
    "end": "448039"
  },
  {
    "text": "I want to show one extension",
    "start": "448039",
    "end": "450160"
  },
  {
    "text": "here so if you recall we invoked our",
    "start": "450160",
    "end": "453440"
  },
  {
    "text": "chain just with chain invoke we passed",
    "start": "453440",
    "end": "455479"
  },
  {
    "text": "our question we get our",
    "start": "455479",
    "end": "457520"
  },
  {
    "text": "answer now what if I want to turn this",
    "start": "457520",
    "end": "459680"
  },
  {
    "text": "into an app like I want to just kind of",
    "start": "459680",
    "end": "462680"
  },
  {
    "text": "abstract this chain",
    "start": "462680",
    "end": "464199"
  },
  {
    "text": "away and what I want is that the",
    "start": "464199",
    "end": "467840"
  },
  {
    "text": "invocation methods of this chain like",
    "start": "467840",
    "end": "471599"
  },
  {
    "text": "invoke are just mapped to endpoints in",
    "start": "471599",
    "end": "474000"
  },
  {
    "text": "an",
    "start": "474000",
    "end": "475120"
  },
  {
    "text": "application so that's actually what Lang",
    "start": "475120",
    "end": "477240"
  },
  {
    "text": "serve lets us do so Lang serve kind of",
    "start": "477240",
    "end": "480039"
  },
  {
    "text": "sits on top of Lang chain it's kind of a",
    "start": "480039",
    "end": "483000"
  },
  {
    "text": "platform that wraps any chain that we",
    "start": "483000",
    "end": "485159"
  },
  {
    "text": "build and it basically just Maps the",
    "start": "485159",
    "end": "487039"
  },
  {
    "text": "invocation methods of our chain in this",
    "start": "487039",
    "end": "490520"
  },
  {
    "text": "case our rag chain to http endpoints",
    "start": "490520",
    "end": "493159"
  },
  {
    "text": "which we can access and then we can do",
    "start": "493159",
    "end": "494720"
  },
  {
    "text": "all sorts of things with that we can",
    "start": "494720",
    "end": "495919"
  },
  {
    "text": "serve it we can you know they can be",
    "start": "495919",
    "end": "497960"
  },
  {
    "text": "accessible via the web and",
    "start": "497960",
    "end": "499840"
  },
  {
    "text": "otherwise so I'll show you kind of how",
    "start": "499840",
    "end": "501720"
  },
  {
    "text": "to do this really",
    "start": "501720",
    "end": "503159"
  },
  {
    "text": "easily and all I'm going to do so we can",
    "start": "503159",
    "end": "506919"
  },
  {
    "text": "kind of open up over here I just have a",
    "start": "506919",
    "end": "508639"
  },
  {
    "text": "you know an EMP an empty",
    "start": "508639",
    "end": "510800"
  },
  {
    "text": "environment um so now all I've done",
    "start": "510800",
    "end": "513640"
  },
  {
    "text": "previously is I've created this cond",
    "start": "513640",
    "end": "515000"
  },
  {
    "text": "environment I've done this pip install",
    "start": "515000",
    "end": "516719"
  },
  {
    "text": "for Lang chain CLI and Lang serve that's",
    "start": "516719",
    "end": "519000"
  },
  {
    "text": "really it I'm going to run is this",
    "start": "519000",
    "end": "521680"
  },
  {
    "text": "command here Lang chain app new and it's",
    "start": "521680",
    "end": "525440"
  },
  {
    "text": "going to ask me about packages I'm going",
    "start": "525440",
    "end": "527040"
  },
  {
    "text": "to say no packages and I'll show you",
    "start": "527040",
    "end": "528880"
  },
  {
    "text": "what's going to happen here shortly so",
    "start": "528880",
    "end": "531480"
  },
  {
    "text": "what you see here is that'll close us",
    "start": "531480",
    "end": "534120"
  },
  {
    "text": "down a little bit we've created this EMP",
    "start": "534120",
    "end": "537080"
  },
  {
    "text": "empty template app with just just has",
    "start": "537080",
    "end": "539480"
  },
  {
    "text": "this app directory with server.py and it",
    "start": "539480",
    "end": "542000"
  },
  {
    "text": "has packages which is empty okay so all",
    "start": "542000",
    "end": "546480"
  },
  {
    "text": "I need to do now is in this app",
    "start": "546480",
    "end": "549200"
  },
  {
    "text": "directory I'm going to create a new file",
    "start": "549200",
    "end": "550839"
  },
  {
    "text": "chain.",
    "start": "550839",
    "end": "552120"
  },
  {
    "text": "piy and into this file we had our code",
    "start": "552120",
    "end": "555959"
  },
  {
    "text": "previously for our rag chain it was",
    "start": "555959",
    "end": "558160"
  },
  {
    "text": "basically right here I just kind of",
    "start": "558160",
    "end": "559640"
  },
  {
    "text": "copied and formatted it slightly for",
    "start": "559640",
    "end": "561360"
  },
  {
    "text": "convenience but this is the same code",
    "start": "561360",
    "end": "563360"
  },
  {
    "text": "that we had in our notebook I'm just",
    "start": "563360",
    "end": "564839"
  },
  {
    "text": "going to save this so now I have this",
    "start": "564839",
    "end": "567200"
  },
  {
    "text": "chain. piy file defined in my app",
    "start": "567200",
    "end": "569519"
  },
  {
    "text": "directory here and all I'm going to do",
    "start": "569519",
    "end": "571920"
  },
  {
    "text": "in server.py is two things really",
    "start": "571920",
    "end": "575040"
  },
  {
    "text": "quickly so you can see it right",
    "start": "575040",
    "end": "577839"
  },
  {
    "text": "here from that chain. Pi import my chain",
    "start": "577839",
    "end": "582640"
  },
  {
    "text": "as I'm going to call it nomic chain and",
    "start": "582640",
    "end": "585040"
  },
  {
    "text": "going I'm I'm going to call this add",
    "start": "585040",
    "end": "586839"
  },
  {
    "text": "routes",
    "start": "586839",
    "end": "587880"
  },
  {
    "text": "here so what this is going to do is you",
    "start": "587880",
    "end": "590760"
  },
  {
    "text": "can see our chain is defined here this",
    "start": "590760",
    "end": "592360"
  },
  {
    "text": "is exactly what we had in our notebook",
    "start": "592360",
    "end": "594720"
  },
  {
    "text": "it's going to map the invocation method",
    "start": "594720",
    "end": "596760"
  },
  {
    "text": "of this chain to httn points in this",
    "start": "596760",
    "end": "600279"
  },
  {
    "text": "Lang serve app which is kind of run by",
    "start": "600279",
    "end": "603120"
  },
  {
    "text": "fast fast API and this add routes just",
    "start": "603120",
    "end": "606040"
  },
  {
    "text": "simply Maps those invocation methods to",
    "start": "606040",
    "end": "609040"
  },
  {
    "text": "a number of",
    "start": "609040",
    "end": "610279"
  },
  {
    "text": "endpoints so that's really it um we're",
    "start": "610279",
    "end": "613800"
  },
  {
    "text": "going to do a few other little things",
    "start": "613800",
    "end": "615720"
  },
  {
    "text": "here we're just going to add our",
    "start": "615720",
    "end": "617920"
  },
  {
    "text": "dependencies which we did in the",
    "start": "617920",
    "end": "619360"
  },
  {
    "text": "notebook independently but we'll go",
    "start": "619360",
    "end": "621279"
  },
  {
    "text": "ahead and do that here so that's just",
    "start": "621279",
    "end": "622959"
  },
  {
    "text": "poetry add make sure we got them all",
    "start": "622959",
    "end": "624839"
  },
  {
    "text": "okay make sure we add Lang chain as",
    "start": "624839",
    "end": "626839"
  },
  {
    "text": "well so that's running right now",
    "start": "626839",
    "end": "631040"
  },
  {
    "text": "there we go nice and we'll go ahead and",
    "start": "631720",
    "end": "636079"
  },
  {
    "text": "add line chain as well make sure we have",
    "start": "636079",
    "end": "639160"
  },
  {
    "text": "that so that's just making sure our",
    "start": "639160",
    "end": "641480"
  },
  {
    "text": "project has all the required",
    "start": "641480",
    "end": "643800"
  },
  {
    "text": "dependencies we can run poetry install",
    "start": "643800",
    "end": "646079"
  },
  {
    "text": "just confirm they're all installed but",
    "start": "646079",
    "end": "647399"
  },
  {
    "text": "when you run ad it should install",
    "start": "647399",
    "end": "648920"
  },
  {
    "text": "everything for you um so we Define our",
    "start": "648920",
    "end": "652040"
  },
  {
    "text": "chain. piy which has our chain we've",
    "start": "652040",
    "end": "654519"
  },
  {
    "text": "updated server.py to basically take the",
    "start": "654519",
    "end": "657880"
  },
  {
    "text": "invocation meth of our chain and Route",
    "start": "657880",
    "end": "660880"
  },
  {
    "text": "them to endpoints in an app and you'll",
    "start": "660880",
    "end": "663600"
  },
  {
    "text": "see no MC rag will be kind of the the",
    "start": "663600",
    "end": "666800"
  },
  {
    "text": "Endo that we'll work with now if we just",
    "start": "666800",
    "end": "669279"
  },
  {
    "text": "run poetry run Lang chain serve",
    "start": "669279",
    "end": "672839"
  },
  {
    "text": "here this should spin up an app for us",
    "start": "672839",
    "end": "676720"
  },
  {
    "text": "and now you can see our app is running",
    "start": "676720",
    "end": "679240"
  },
  {
    "text": "so I'll just open this up so you can see",
    "start": "679240",
    "end": "681399"
  },
  {
    "text": "it this is showing Lang serve and our",
    "start": "681399",
    "end": "684839"
  },
  {
    "text": "app is now running here",
    "start": "684839",
    "end": "687399"
  },
  {
    "text": "locally and",
    "start": "687399",
    "end": "690079"
  },
  {
    "text": "I actually already",
    "start": "690079",
    "end": "692399"
  },
  {
    "text": "have right here so here is that",
    "start": "692399",
    "end": "697800"
  },
  {
    "text": "URL here was what we defined in our uh",
    "start": "697800",
    "end": "701800"
  },
  {
    "text": "server.py nomic rag and you can see this",
    "start": "701800",
    "end": "704760"
  },
  {
    "text": "playground right here so this is like an",
    "start": "704760",
    "end": "707720"
  },
  {
    "text": "interactive UI that we can use for our",
    "start": "707720",
    "end": "709680"
  },
  {
    "text": "app so if we go back to what our",
    "start": "709680",
    "end": "711680"
  },
  {
    "text": "question was what are the types of agent",
    "start": "711680",
    "end": "713440"
  },
  {
    "text": "memory for",
    "start": "713440",
    "end": "714639"
  },
  {
    "text": "example we can just say run and",
    "start": "714639",
    "end": "717519"
  },
  {
    "text": "hopefully this runs let's have a look",
    "start": "717519",
    "end": "719200"
  },
  {
    "text": "here hopefully this should start",
    "start": "719200",
    "end": "720200"
  },
  {
    "text": "streaming okay very nice so now our rag",
    "start": "720200",
    "end": "722399"
  },
  {
    "text": "app is",
    "start": "722399",
    "end": "723600"
  },
  {
    "text": "streaming and that's pretty cool so now",
    "start": "723600",
    "end": "727040"
  },
  {
    "text": "we've gone from prototyping in a in a",
    "start": "727040",
    "end": "729040"
  },
  {
    "text": "notebook to using Langer to deploy a rag",
    "start": "729040",
    "end": "732399"
  },
  {
    "text": "app locally with interactive UI and of",
    "start": "732399",
    "end": "734800"
  },
  {
    "text": "course this is running locally but if I",
    "start": "734800",
    "end": "737079"
  },
  {
    "text": "was using apis then I could actually",
    "start": "737079",
    "end": "738600"
  },
  {
    "text": "then Host this and serve it using hosted",
    "start": "738600",
    "end": "740959"
  },
  {
    "text": "Lang serve which we do talk about in",
    "start": "740959",
    "end": "742440"
  },
  {
    "text": "other videos but because this is running",
    "start": "742440",
    "end": "744160"
  },
  {
    "text": "locally I won't get into that right now",
    "start": "744160",
    "end": "747560"
  },
  {
    "text": "thanks",
    "start": "747560",
    "end": "750560"
  }
]
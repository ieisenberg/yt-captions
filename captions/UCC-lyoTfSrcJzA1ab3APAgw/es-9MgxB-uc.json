[
  {
    "text": "welcome to another YouTube video where we're going to build something really cool this is going to build off of a",
    "start": "1319",
    "end": "8440"
  },
  {
    "text": "previous template it's going to build off of a uh it's going to build off the research assistant template but it's",
    "start": "8440",
    "end": "14160"
  },
  {
    "text": "going to be a modified version specifically we're going to get it to work over SQL databases so what that",
    "start": "14160",
    "end": "19600"
  },
  {
    "text": "means is we're going to create a research assistant that does its research by executing SQL queries and",
    "start": "19600",
    "end": "25279"
  },
  {
    "text": "and asking questions of SQL databases and I think this is interesting for two reasons um probably many more but two",
    "start": "25279",
    "end": "31080"
  },
  {
    "text": "reasons to highlight uh first a lot of data is in structured format and so",
    "start": "31080",
    "end": "36760"
  },
  {
    "text": "being able to not only ask questions of it but also write research reports over it unlocks a massive amount of use cases",
    "start": "36760",
    "end": "46559"
  },
  {
    "text": "secondly what we're going to be doing is actually using a subchain a SQL chain as the thing that's",
    "start": "46559",
    "end": "53600"
  },
  {
    "text": "doing the research so this is hooking up the research assistant to another chain",
    "start": "53600",
    "end": "58719"
  },
  {
    "text": "which is itself you know using an llm to generate SQL queries and then returning that so I think that's really",
    "start": "58719",
    "end": "65600"
  },
  {
    "text": "interesting because it shows off this idea of having multiple llms with",
    "start": "65600",
    "end": "70799"
  },
  {
    "text": "different responsibilities communicating and and delegating and so we're going to combine",
    "start": "70799",
    "end": "77479"
  },
  {
    "text": "the uh the research assistant with a a SQL question answering template one we'll pick one that exists um",
    "start": "77479",
    "end": "85720"
  },
  {
    "text": "already and uh yeah I think this will be a pretty cool combin of of two interesting",
    "start": "85720",
    "end": "93240"
  },
  {
    "text": "topics so we're going to be working out of the Lang chain templates um repo this",
    "start": "93240",
    "end": "100159"
  },
  {
    "text": "is it pulled up here the research assistant template",
    "start": "100159",
    "end": "106399"
  },
  {
    "text": "is right here there's a few SQL templates we're going to use SQL AMA I",
    "start": "106399",
    "end": "112119"
  },
  {
    "text": "really like AMA it's a great way to run uh llama as well as other models",
    "start": "112119",
    "end": "118360"
  },
  {
    "text": "locally um and yeah we're going to dive into it we'll we'll be setting some environment",
    "start": "118360",
    "end": "124840"
  },
  {
    "text": "variables but I'm going to do everything from scratch so you guys will be able to see uh exactly what I'm setting and and",
    "start": "124840",
    "end": "131400"
  },
  {
    "text": "what I'm having to do I'll probably pause my screen at various points um so I can use environment variables and",
    "start": "131400",
    "end": "137640"
  },
  {
    "text": "things like that and not leak those but other than that this will be completely one take from scratch so this is my copy of the",
    "start": "137640",
    "end": "146319"
  },
  {
    "text": "linkchain repo um I'm going to initialize my virtual environment um I already have one set up um and then",
    "start": "146319",
    "end": "154160"
  },
  {
    "text": "I'm going to go into the templates repo and I'm going to",
    "start": "154160",
    "end": "160360"
  },
  {
    "text": "create a new uh a new template so I created a new template",
    "start": "160360",
    "end": "167360"
  },
  {
    "text": "called Lang chain or sorry I created a new template using the Lang chain template new and then it's called SQL",
    "start": "167360",
    "end": "173800"
  },
  {
    "text": "research assistant um I can now move into it",
    "start": "173800",
    "end": "181760"
  },
  {
    "text": "and there we go I've got that set up if we take a look at what is inside",
    "start": "182080",
    "end": "189519"
  },
  {
    "text": "it we can see that we have a basic skeleton um and the chain file which is",
    "start": "189799",
    "end": "196159"
  },
  {
    "text": "here is uh yeah pretty basic it has this has",
    "start": "196159",
    "end": "201239"
  },
  {
    "text": "this like Talk Like a Pirate example so what we want to do is we're going to be working off the research",
    "start": "201239",
    "end": "207879"
  },
  {
    "text": "assistant and so let's [Music] grab let's grab this and let's move this",
    "start": "207879",
    "end": "217080"
  },
  {
    "text": "in here let's call this SQL research assistant and let's overwrite",
    "start": "217080",
    "end": "223760"
  },
  {
    "text": "everything then I need to fix Imports probably so I need to add SQL there SQL",
    "start": "223760",
    "end": "231319"
  },
  {
    "text": "there where else is SQL used not there do we use any SQL okay so I've copied over the",
    "start": "231319",
    "end": "239319"
  },
  {
    "text": "research assistant I've renamed it to SQL research assistant that seems like a good",
    "start": "239319",
    "end": "245360"
  },
  {
    "text": "start if you haven't watched the research assistant YouTube video you definitely should um this will be this",
    "start": "245360",
    "end": "251560"
  },
  {
    "text": "will be doable not having watched that but that would provide a lot more context the research assistant basically",
    "start": "251560",
    "end": "258720"
  },
  {
    "text": "has two components it has a research um chain and then it has a writer chain the writer chain can be relatively untouched",
    "start": "258720",
    "end": "265840"
  },
  {
    "text": "um if we look at that um it is is oh actually this I think no this this is",
    "start": "265840",
    "end": "272840"
  },
  {
    "text": "good um it has a bunch of prompts that say to write a research report um it uses open AI we can keep on using open",
    "start": "272840",
    "end": "279759"
  },
  {
    "text": "AI um and so the writer chain is good what we want to change is the research",
    "start": "279759",
    "end": "284840"
  },
  {
    "text": "chain so previously we looked things up on the Internet we want to change this to now use SQL we can see the chain down",
    "start": "284840",
    "end": "291800"
  },
  {
    "text": "here um and so looking at this in more detail the first component generates a bunch of",
    "start": "291800",
    "end": "299120"
  },
  {
    "text": "smaller search queries um and then basically we look up we do a search on",
    "start": "299120",
    "end": "304919"
  },
  {
    "text": "each of those uh sub questions answer them and join the responses and then and then we pass that as the final research",
    "start": "304919",
    "end": "311280"
  },
  {
    "text": "report which then gets Rewritten into an essay so um what we basically want to do",
    "start": "311280",
    "end": "318720"
  },
  {
    "text": "we still want to generate sub questions so this is going to be the same we'll maybe change the prompt a little bit but that'll be the same what we want to do",
    "start": "318720",
    "end": "324800"
  },
  {
    "text": "is replace this part if we look at where this is defined this uh basic basically",
    "start": "324800",
    "end": "330039"
  },
  {
    "text": "gets a bunch of links scrapes them summarizes them that we want to replace this with a",
    "start": "330039",
    "end": "337160"
  },
  {
    "text": "SQL chain so we have a bunch of sub questions and we want each sub question to go to a SQL chain and then respond so",
    "start": "337160",
    "end": "344960"
  },
  {
    "text": "let's take a look at SQL oama to see what's going on in",
    "start": "344960",
    "end": "350440"
  },
  {
    "text": "here so this is the SQL chain um it actually does more than we want so it",
    "start": "350440",
    "end": "355880"
  },
  {
    "text": "has a conversational memory we don't need that because remember we just want this one particular chain but let's",
    "start": "355880",
    "end": "362280"
  },
  {
    "text": "copy all of this and",
    "start": "362280",
    "end": "367880"
  },
  {
    "text": "let's put it in a new file here I guess um let's call this sequel let's",
    "start": "367880",
    "end": "376280"
  },
  {
    "text": "put that there we also need this so so this um this example is doing question answering over uh uh sqlite database",
    "start": "376280",
    "end": "385520"
  },
  {
    "text": "that has uh information about NBA rosters so we'll end up asking it's a pretty simple database so the",
    "start": "385520",
    "end": "391720"
  },
  {
    "text": "questions that we're going to end up asking in this video are probably going to be pretty simple but that's fine the point of this is to show how you can",
    "start": "391720",
    "end": "398639"
  },
  {
    "text": "heavily modify the research assistant template to do research over any source so the fact that this particular source",
    "start": "398639",
    "end": "404199"
  },
  {
    "text": "is a pretty lame and uninteresting MBA roster database doesn't matter too much",
    "start": "404199",
    "end": "409520"
  },
  {
    "text": "so we'll paste that there then um we're going to modify this chain slightly um this is unnecessary",
    "start": "409520",
    "end": "420759"
  },
  {
    "text": "um so so this you can see is is doing some saving of memory we don't want to be saving any memory we don't want a",
    "start": "420759",
    "end": "427560"
  },
  {
    "text": "concept of memory if we're just doing this we really just need the SQL chain the SQL chain we can also remove this",
    "start": "427560",
    "end": "434479"
  },
  {
    "text": "history bit yeah we can remove this history bit and then that'll be good we can use that",
    "start": "434479",
    "end": "440120"
  },
  {
    "text": "so we'll repl the SQL response memory with just a SQL chain",
    "start": "440120",
    "end": "445919"
  },
  {
    "text": "um cool that seems relatively fine we might have to change some typing",
    "start": "445919",
    "end": "451800"
  },
  {
    "text": "around the outputs but let's work with that let's call this uh SQL answer",
    "start": "451800",
    "end": "460039"
  },
  {
    "text": "chain and then what we're going to do in here from Lan chain nope from SQL",
    "start": "460039",
    "end": "471440"
  },
  {
    "text": "research assistant search SQL import",
    "start": "471440",
    "end": "476560"
  },
  {
    "text": "that and then we are going to use that right",
    "start": "476560",
    "end": "481599"
  },
  {
    "text": "there so we're taking this chain which comes from the SQL template and is designed to answer a single question and",
    "start": "481599",
    "end": "487960"
  },
  {
    "text": "we're basically dropping it in here the map is going to mean that it's going to apply for all the questions that are generated from the sub",
    "start": "487960",
    "end": "495599"
  },
  {
    "text": "Generation Um let's",
    "start": "495599",
    "end": "501800"
  },
  {
    "text": "add let's add a little test case just to try this out before we spin it",
    "start": "508240",
    "end": "514599"
  },
  {
    "text": "up um chain. invoke",
    "start": "514599",
    "end": "522518"
  },
  {
    "text": "question um",
    "start": "522519",
    "end": "529080"
  },
  {
    "text": "who is typically",
    "start": "529080",
    "end": "534519"
  },
  {
    "text": "older point guards or centers",
    "start": "534519",
    "end": "540360"
  },
  {
    "text": "um so this might be answerable with a a single SQL query but it's a good uh it's",
    "start": "540360",
    "end": "546120"
  },
  {
    "text": "a good example of it's a it's a working functional example",
    "start": "546120",
    "end": "552160"
  },
  {
    "text": "um okay so before running we need to make sure that ama is running AMA is",
    "start": "552160",
    "end": "558160"
  },
  {
    "text": "what we're using to uh use a local llm",
    "start": "558160",
    "end": "563279"
  },
  {
    "text": "and actually let's take a look at which so we're using Zephyr Zephyr is actually a little bit too big for my backbook so",
    "start": "563279",
    "end": "568959"
  },
  {
    "text": "I'm switch to llama 2 um if you haven't set up a llama definitely check it out",
    "start": "568959",
    "end": "574800"
  },
  {
    "text": "it's super cool repo makes it really easy to interact with language models in",
    "start": "574800",
    "end": "580440"
  },
  {
    "text": "order to make sure that I have it running I'm going to do",
    "start": "580440",
    "end": "584760"
  },
  {
    "text": "this it's taking a little bit okay hi awesome cool so I can see it",
    "start": "588240",
    "end": "594640"
  },
  {
    "text": "running that's fantastic um I'm using open AI at",
    "start": "594640",
    "end": "601720"
  },
  {
    "text": "various points throughout here so I'm going to set my open AI API key I'm going to pause the",
    "start": "601720",
    "end": "609120"
  },
  {
    "text": "video and do that all right that key is set um and",
    "start": "609120",
    "end": "616440"
  },
  {
    "text": "then the next thing I'm going to do is I'm going to set my Lang Smith key so Lang Smith is going to be super handy",
    "start": "616440",
    "end": "622200"
  },
  {
    "text": "for debugging everything that goes on because I don't think this is going to work on the first try it never does and",
    "start": "622200",
    "end": "627360"
  },
  {
    "text": "so we're going to need to iterate on it a bunch Lang Smith is going to help a bunch with that I can set it up by",
    "start": "627360",
    "end": "633040"
  },
  {
    "text": "basically exporting these variables um if you don't have access to link Smith",
    "start": "633040",
    "end": "638600"
  },
  {
    "text": "shoot me a DM on Twitter or LinkedIn and we can get you access there um I am",
    "start": "638600",
    "end": "644079"
  },
  {
    "text": "going to go back to the terminal and insert those um I'm going to pause the",
    "start": "644079",
    "end": "649160"
  },
  {
    "text": "video while I do that to not leak any Keys all right set those variables so we",
    "start": "649160",
    "end": "656000"
  },
  {
    "text": "should be good to go um let's try it out actually so so before we do that I do",
    "start": "656000",
    "end": "662800"
  },
  {
    "text": "have to install the package that I'm working on so I'm going to pip install d e this is in the SQL research assistant",
    "start": "662800",
    "end": "669839"
  },
  {
    "text": "it's going to install um as an editable dependency the files so that way when I modify the files I don't have to",
    "start": "669839",
    "end": "675079"
  },
  {
    "text": "reinstall it super handy um I can now run this file where I put this little",
    "start": "675079",
    "end": "682720"
  },
  {
    "text": "example um python SQL research assistant chain probably should have added some",
    "start": "682720",
    "end": "689480"
  },
  {
    "text": "print statements around it but I think it's fine because this is going to eror",
    "start": "689480",
    "end": "696079"
  },
  {
    "text": "anyways okay cool um so I see that I have a key history that's because I've removed the history um from this chain",
    "start": "696079",
    "end": "705320"
  },
  {
    "text": "but I haven't removed it from this prompt so let's remove it there and I'm",
    "start": "705320",
    "end": "710920"
  },
  {
    "text": "just removing history because the sequel example that I copied was a conversational thing so it had this history key in there that's missing um",
    "start": "710920",
    "end": "718720"
  },
  {
    "text": "now because I don't care about that so I deleted that I forgot to delete it from The Prompt now it's good okay so we get",
    "start": "718720",
    "end": "725920"
  },
  {
    "text": "some error I was expecting this because I don't",
    "start": "725920",
    "end": "731720"
  },
  {
    "text": "think that llama is great at writing squl queries and so I probably need to give it some more explicit instructions",
    "start": "731720",
    "end": "740440"
  },
  {
    "text": "so let's take a look at what is going on under the hood there's a lot going on because this is a more complicated thing",
    "start": "740440",
    "end": "747000"
  },
  {
    "text": "than usual um this is the first LM call that's being made this is where I'm asking the llm to generate a Persona and",
    "start": "747000",
    "end": "756079"
  },
  {
    "text": "so I'm going to be writing a report in the style of a sports analyst agent that seems good so",
    "start": "756079",
    "end": "761440"
  },
  {
    "text": "far now here's the next part um where I'm asking uh the the LM to generate",
    "start": "761440",
    "end": "768880"
  },
  {
    "text": "some sub questions um it's generating average okay we can maybe return to this",
    "start": "768880",
    "end": "774320"
  },
  {
    "text": "and refine this um a little bit later on but I think that",
    "start": "774320",
    "end": "781320"
  },
  {
    "text": "works um this is one thing that is generating",
    "start": "781320",
    "end": "786600"
  },
  {
    "text": "that kind of looks fine um this is another thing that is generating that also looks fine and we can see here that",
    "start": "786600",
    "end": "794000"
  },
  {
    "text": "I think this is where the output error occurs and that is because there is",
    "start": "794000",
    "end": "803600"
  },
  {
    "text": "this okay so it's being over lever Bose so it's not I'm telling it to",
    "start": "803600",
    "end": "811079"
  },
  {
    "text": "um so this is the prompt that's this is the prompt that's being used to write the SQL quy based on the table schema",
    "start": "811079",
    "end": "817079"
  },
  {
    "text": "below write a SQL query that would answer the user's question um no Preamble it's adding things on what I'm",
    "start": "817079",
    "end": "823720"
  },
  {
    "text": "going to do is I'm going to add another output parser",
    "start": "823720",
    "end": "831680"
  },
  {
    "text": "um that basically",
    "start": "831720",
    "end": "837759"
  },
  {
    "text": "um splits on double new lines and just takes the first so there shouldn't",
    "start": "837759",
    "end": "844759"
  },
  {
    "text": "really I can't think of a good reason why there would be double new lines in a SQL query so when it seees something like this it's going to split it's going",
    "start": "844759",
    "end": "850720"
  },
  {
    "text": "to split here it's going to take the first thing it's going to be that that should probably work um all right let's",
    "start": "850720",
    "end": "856040"
  },
  {
    "text": "run it again and see what happens I'm I'm expecting using llama 2 that we're going to have to iterate it on this um",
    "start": "856040",
    "end": "862839"
  },
  {
    "text": "quite a bunch which is good because that'll give us a chance to show off lang Smith show off some of how we think",
    "start": "862839",
    "end": "870360"
  },
  {
    "text": "about doing prompt engineering bits all of that good fun",
    "start": "870360",
    "end": "876000"
  },
  {
    "text": "stuff okay cool so so this actually seems to work relatively well so far um",
    "start": "876000",
    "end": "882279"
  },
  {
    "text": "it's actually getting down to line 180 in here where we're trying to join",
    "start": "882279",
    "end": "888160"
  },
  {
    "text": "the response of the SQL answer chain together we expect to see",
    "start": "888160",
    "end": "893279"
  },
  {
    "text": "um we expect to see strings but instead we're getting an i message M that is",
    "start": "893279",
    "end": "900560"
  },
  {
    "text": "because um that's because this we can add a stir",
    "start": "900560",
    "end": "905839"
  },
  {
    "text": "output parser that will add in",
    "start": "905839",
    "end": "913240"
  },
  {
    "text": "um that'll that'll convert it from an AI message to a string so that's good and",
    "start": "913560",
    "end": "920160"
  },
  {
    "text": "then what I also want to do though is I want to change things up a little bit because I don't just want",
    "start": "920160",
    "end": "927600"
  },
  {
    "text": "to return",
    "start": "927600",
    "end": "932920"
  },
  {
    "text": "the um I don't just want to return the answer so let's go answer",
    "start": "932920",
    "end": "939199"
  },
  {
    "text": "there but instead what I want to do is I want to combine it with the original question and have like a nicely",
    "start": "939199",
    "end": "945839"
  },
  {
    "text": "formatted kind of like response I can show what that looks like but basically I'm going to do Lambda X then do F",
    "start": "945839",
    "end": "956399"
  },
  {
    "text": "string we can do this this",
    "start": "957600",
    "end": "963120"
  },
  {
    "text": "uh like",
    "start": "963120",
    "end": "966440"
  },
  {
    "text": "that okay right so now this um so this is doing",
    "start": "972880",
    "end": "977920"
  },
  {
    "text": "several things um first it's well it's making this return a string and it's making this string be a question and",
    "start": "977920",
    "end": "985040"
  },
  {
    "text": "answer the reason that that's useful is that then when that's passed the LM it can can see what the question it asked",
    "start": "985040",
    "end": "992240"
  },
  {
    "text": "to get that answer was rather than just seeing all the",
    "start": "992240",
    "end": "996759"
  },
  {
    "text": "answers there there'll be a little bit of waiting here because llama's a little bit slow",
    "start": "1001079",
    "end": "1007600"
  },
  {
    "text": "locally we can actually probably see it running if we go here",
    "start": "1014360",
    "end": "1020360"
  },
  {
    "text": "and we can see it in the action and it finishes",
    "start": "1020360",
    "end": "1025918"
  },
  {
    "text": "okay so oh wow so so this is a much longer report than probably necessary",
    "start": "1025919",
    "end": "1032280"
  },
  {
    "text": "for a simple question like this um but if we take a look at it we can see all",
    "start": "1032280",
    "end": "1037880"
  },
  {
    "text": "right so it gives some introduction um okay so the average age of centers is",
    "start": "1037880",
    "end": "1045480"
  },
  {
    "text": "26.7 years old uh um there's some more",
    "start": "1045480",
    "end": "1053080"
  },
  {
    "text": "it's no data for point guards okay so it's getting some information it's it's",
    "start": "1056120",
    "end": "1062799"
  },
  {
    "text": "like you know I would expect it to have point guard Age center age and then that's kind of it it's not getting there",
    "start": "1062799",
    "end": "1069840"
  },
  {
    "text": "let's let's see what's going on if we look at the final prompt that's inserted",
    "start": "1069840",
    "end": "1076919"
  },
  {
    "text": "um Okay so we see that this is why it can't calculate that it can get",
    "start": "1076919",
    "end": "1083559"
  },
  {
    "text": "that and then it can't get the age distribution of point guards versus centers okay so this is like fine that's",
    "start": "1083559",
    "end": "1093919"
  },
  {
    "text": "like a more complicated SQL query and not a very good question but this is weird why can't it answer this",
    "start": "1093919",
    "end": "1101360"
  },
  {
    "text": "um that's the okay that's let's take a look here",
    "start": "1101360",
    "end": "1109600"
  },
  {
    "text": "um that's Center it has an explanation but that's fine because we slice that",
    "start": "1109600",
    "end": "1117240"
  },
  {
    "text": "out what is here oh that's this is",
    "start": "1117240",
    "end": "1123679"
  },
  {
    "text": "Center that gets the SQL query this is looking up point",
    "start": "1125840",
    "end": "1134000"
  },
  {
    "text": "guard um I am probably [Music]",
    "start": "1134000",
    "end": "1139640"
  },
  {
    "text": "guessing that yeah okay so I'm guessing it's like PG instead of the word point guard well we can what that means this",
    "start": "1139640",
    "end": "1146640"
  },
  {
    "text": "is probably better handled in a SQL um tutorial but what that basically means",
    "start": "1146640",
    "end": "1152640"
  },
  {
    "text": "is we want we need to get more information about the table",
    "start": "1152640",
    "end": "1158400"
  },
  {
    "text": "um so if we look at",
    "start": "1158400",
    "end": "1164000"
  },
  {
    "text": "what is in here",
    "start": "1164000",
    "end": "1169840"
  },
  {
    "text": "this is yeah okay",
    "start": "1169840",
    "end": "1178320"
  },
  {
    "text": "so the SQL database this is a database wrapper that we have",
    "start": "1178320",
    "end": "1185159"
  },
  {
    "text": "um and when we initialize it we're passing in Sample rows and table info",
    "start": "1185159",
    "end": "1192120"
  },
  {
    "text": "which I believe if yeah so so this um so okay so backing up what EX L is going in",
    "start": "1192120",
    "end": "1199480"
  },
  {
    "text": "to the uh llm what's going into the llm look in the playground we can maybe see",
    "start": "1199480",
    "end": "1205440"
  },
  {
    "text": "it is this um and notably the only thing that we're passing in about the SQL table is this information right here",
    "start": "1205440",
    "end": "1211799"
  },
  {
    "text": "which is the schema but we need to know we we want to do analysis on like what is the position",
    "start": "1211799",
    "end": "1219760"
  },
  {
    "text": "column we need to know the values of that so that we can filter it because basically what was happening and what was going wrong is",
    "start": "1219760",
    "end": "1227159"
  },
  {
    "text": "that we were looking for point guard spelled point guard not PG and so that's",
    "start": "1227159",
    "end": "1234520"
  },
  {
    "text": "a mistake that the L made because it doesn't know the values of the column so",
    "start": "1234520",
    "end": "1239799"
  },
  {
    "text": "I'm guessing when we made this template we probably did this because llama gets really",
    "start": "1239799",
    "end": "1245760"
  },
  {
    "text": "confused by by some of the um SQL rows let's put in two and and let's see what",
    "start": "1245760",
    "end": "1252360"
  },
  {
    "text": "happens here um that's kind of the downside of",
    "start": "1252360",
    "end": "1259799"
  },
  {
    "text": "working with the local models they're not necessarily always the best on so",
    "start": "1259799",
    "end": "1265280"
  },
  {
    "text": "here so here you can see oh is that a respon oh no that didn't resp okay so here you can see that we have the two",
    "start": "1265280",
    "end": "1271400"
  },
  {
    "text": "rows from this table that we put in and you can see here that it's a little bit",
    "start": "1271400",
    "end": "1276559"
  },
  {
    "text": "misaligned but position small forward shooting guard so hopefully what should",
    "start": "1276559",
    "end": "1282159"
  },
  {
    "text": "happen is it should let the llm know that the values here are like this style",
    "start": "1282159",
    "end": "1287760"
  },
  {
    "text": "they're not fully written out point guard it should be like PG and so here actually okay perfect so we can see that",
    "start": "1287760",
    "end": "1294240"
  },
  {
    "text": "it recognizes that PG okay so we get a response let's look",
    "start": "1294240",
    "end": "1301080"
  },
  {
    "text": "at this response we have some great background",
    "start": "1301080",
    "end": "1308159"
  },
  {
    "text": "um okay average age of point guards is 27.5 while the average age of centers is slightly lower",
    "start": "1308159",
    "end": "1316480"
  },
  {
    "text": "um",
    "start": "1317039",
    "end": "1320039"
  },
  {
    "text": "H okay so here it's citing some different numbers",
    "start": "1323480",
    "end": "1328560"
  },
  {
    "text": "[Music] um so so it's here it's hallucinating a little bit let's take a look at this",
    "start": "1328560",
    "end": "1334000"
  },
  {
    "text": "prompt and see why it thinks that so it gets this gets",
    "start": "1334000",
    "end": "1342240"
  },
  {
    "text": "this okay so so this so it's getting two different sources of information or two",
    "start": "1346039",
    "end": "1352440"
  },
  {
    "text": "different two different responses one is um this which is saying the average age",
    "start": "1352440",
    "end": "1360799"
  },
  {
    "text": "of point guards is that so what I'm guessing is actually I I let's take a look at",
    "start": "1360799",
    "end": "1367840"
  },
  {
    "text": "some of the other ones [Music]",
    "start": "1367840",
    "end": "1373469"
  },
  {
    "text": "um so this is just hallucinating it looks",
    "start": "1376960",
    "end": "1382720"
  },
  {
    "text": "like like it has something with centers so so okay so so basically this is a",
    "start": "1382720",
    "end": "1388120"
  },
  {
    "text": "hallucinated response um and to to backtrack into how",
    "start": "1388120",
    "end": "1393760"
  },
  {
    "text": "I got that like if we look at the final prompt that's going into the research report we can see that one of the",
    "start": "1393760",
    "end": "1398880"
  },
  {
    "text": "questions and one of the answers that we get is this this is that conflict with this and this I trust these and these",
    "start": "1398880",
    "end": "1405360"
  },
  {
    "text": "much more that they're accurate because these are just simple questions this is like way more complicated this answer so",
    "start": "1405360",
    "end": "1412760"
  },
  {
    "text": "I'm guessing that this is hallucinated if I go back and I find where that ANW responded from I can see the data that",
    "start": "1412760",
    "end": "1419320"
  },
  {
    "text": "it's getting it's hallucinating a lot this is part of the issue with um local models",
    "start": "1419320",
    "end": "1428120"
  },
  {
    "text": "so so what I'm thinking that I'm going to do so so what I want I want to do a little prompt engineering and I probably",
    "start": "1428120",
    "end": "1434080"
  },
  {
    "text": "want to change language models because Ama or just llama in general um you know",
    "start": "1434080",
    "end": "1440919"
  },
  {
    "text": "it's it's not as good as chat GPT it's fine for some of these things and it I think this is this is a separate",
    "start": "1440919",
    "end": "1447799"
  },
  {
    "text": "conversation but it's really important to be able to know when to use different models and when they're good at and when you need to do more complex kind of like",
    "start": "1447799",
    "end": "1455520"
  },
  {
    "text": "um synthesis of information you probably want a larger model at least at the moment if we look here oh I I can open",
    "start": "1455520",
    "end": "1463120"
  },
  {
    "text": "this in a playground okay I wasn't expecting that but that's fine um",
    "start": "1463120",
    "end": "1468360"
  },
  {
    "text": "uh I don't yeah okay so this",
    "start": "1468360",
    "end": "1476120"
  },
  {
    "text": "um so so Lama it can't really be used because we don't support it but what we",
    "start": "1476120",
    "end": "1481600"
  },
  {
    "text": "can do is we can take this we can put it here um and we can use so so now we can",
    "start": "1481600",
    "end": "1490039"
  },
  {
    "text": "try out so this is the prompt template this is the prompt with all the inputs that gets in and we can use we can",
    "start": "1490039",
    "end": "1496480"
  },
  {
    "text": "choose any output that we want let's see what like like what would open AI have",
    "start": "1496480",
    "end": "1502360"
  },
  {
    "text": "said okay so it's listing it out that's much more faithful than olama which just",
    "start": "1502360",
    "end": "1508240"
  },
  {
    "text": "hallucinated things so what I'm going to do is I'm going to",
    "start": "1508240",
    "end": "1513480"
  },
  {
    "text": "change the synthesis part from being done by AMA to being",
    "start": "1513480",
    "end": "1519760"
  },
  {
    "text": "done by chat open AI",
    "start": "1519760",
    "end": "1525200"
  },
  {
    "text": "um cool let's run that and let's see what",
    "start": "1525520",
    "end": "1531919"
  },
  {
    "text": "happens so we can see things in action again let's take a look at maybe what's going",
    "start": "1536640",
    "end": "1542559"
  },
  {
    "text": "on um it's generating that SQL query generating that SQL",
    "start": "1542559",
    "end": "1550398"
  },
  {
    "text": "query that's complicated SQL query but looks like it hasn't errored so far",
    "start": "1552120",
    "end": "1559600"
  },
  {
    "text": "um this is",
    "start": "1559600",
    "end": "1563000"
  },
  {
    "text": "now summarizing some of the outputs here um yeah okay so we're getting the",
    "start": "1568399",
    "end": "1576720"
  },
  {
    "text": "average age of centers we're getting the average age of",
    "start": "1576720",
    "end": "1582320"
  },
  {
    "text": "point guards this last one is very",
    "start": "1582320",
    "end": "1589080"
  },
  {
    "text": "confusing um what is it even doing select age count Star as count of point",
    "start": "1589080",
    "end": "1596720"
  },
  {
    "text": "guards count Star as count of centers from NBA rosters okay so this is like no",
    "start": "1596720",
    "end": "1603960"
  },
  {
    "text": "information or no useful information still",
    "start": "1603960",
    "end": "1612039"
  },
  {
    "text": "running yeah so this this might take a this might take a while again um I will",
    "start": "1616600",
    "end": "1622960"
  },
  {
    "text": "pause the video and come back when it's finished all right so we've got our",
    "start": "1622960",
    "end": "1630279"
  },
  {
    "text": "report um age comparison between point guards and centers um gives some nice",
    "start": "1630279",
    "end": "1635960"
  },
  {
    "text": "Preamble gets average age of point guards is this average age of centers is this and then mentions that 29 centers",
    "start": "1635960",
    "end": "1642440"
  },
  {
    "text": "are in basketball so yeah the",
    "start": "1642440",
    "end": "1649039"
  },
  {
    "text": "so the it it uses the given information um if we look at the prompt and what's",
    "start": "1649039",
    "end": "1655279"
  },
  {
    "text": "passed in we can see that we get the average age of point guards is this the average age of centers is this and then",
    "start": "1655279",
    "end": "1660320"
  },
  {
    "text": "it asks this question about the distribution of point guards versus centers in basketball and it gets back this which is true there's there's 29",
    "start": "1660320",
    "end": "1666080"
  },
  {
    "text": "centers in basketball in probably probably this database um and yeah so if we look at the",
    "start": "1666080",
    "end": "1674760"
  },
  {
    "text": "response um yeah it's truthful it's rather long for this type",
    "start": "1674760",
    "end": "1681840"
  },
  {
    "text": "of question but again this is just an example question and yeah I think that about",
    "start": "1681840",
    "end": "1688200"
  },
  {
    "text": "covers everything last thing we're going to do is we're going to serve this with Lang",
    "start": "1688200",
    "end": "1694320"
  },
  {
    "text": "serve um so Lang serve is a really easy way to deploy all these all these chains and agents and all of that and so you if",
    "start": "1694320",
    "end": "1702640"
  },
  {
    "text": "you look in the P project. toml you can see that we've got this langing serve tool and it exports this module um so",
    "start": "1702640",
    "end": "1710399"
  },
  {
    "text": "SQL research assistant chain if we go into here perfect good catch so we can see that we can we need to change this",
    "start": "1710399",
    "end": "1716600"
  },
  {
    "text": "to SQL research assistant um so this remember I I copied this code over from regular research assistant which is why",
    "start": "1716600",
    "end": "1723000"
  },
  {
    "text": "it was research assistant but we want to be importing SQL research assistant so we're importing SQL research assistant",
    "start": "1723000",
    "end": "1728200"
  },
  {
    "text": "chain. chain if we go to there this is the chain that we defined now once we have that properly set up what we can do",
    "start": "1728200",
    "end": "1735320"
  },
  {
    "text": "is just L chain serve this will run it up um we can go",
    "start": "1735320",
    "end": "1742360"
  },
  {
    "text": "to Local Host 8,000 go in playground",
    "start": "1742360",
    "end": "1747679"
  },
  {
    "text": "mode we can see now here so this is the this is one of the research variables that we could choose from doesn't really",
    "start": "1747679",
    "end": "1753039"
  },
  {
    "text": "do that much there's the question if we go back here let's copy this question let's put it in",
    "start": "1753039",
    "end": "1758960"
  },
  {
    "text": "there and now we can see the intermediate steps start to creep up this is uh we can see that there's some",
    "start": "1758960",
    "end": "1765679"
  },
  {
    "text": "questions generated there's some intermediate responses um and it keeps on chugging",
    "start": "1765679",
    "end": "1772279"
  },
  {
    "text": "along and then now we can see that the output starts streaming so this is a really nice we you know we build in streaming we build in all of that to L",
    "start": "1772279",
    "end": "1778480"
  },
  {
    "text": "serve so that when you have long reports getting written like this you can still see it as it starts to progress",
    "start": "1778480",
    "end": "1786559"
  },
  {
    "text": "um so this is yeah this is the research report um that about wraps it up uh I",
    "start": "1786559",
    "end": "1795640"
  },
  {
    "text": "can't think of much else to cover cover hopefully this is a good um more",
    "start": "1795640",
    "end": "1801120"
  },
  {
    "text": "advanced uh uh YouTube video on taking the research assistant template and",
    "start": "1801120",
    "end": "1807039"
  },
  {
    "text": "modifying it so that I can do research over any source of knowledge in this case a SQL database and this this this",
    "start": "1807039",
    "end": "1813640"
  },
  {
    "text": "is also really cool because it uses a bunch of different prompts and even different models remember we're using",
    "start": "1813640",
    "end": "1819039"
  },
  {
    "text": "llama to from Lama to generate the SQL um so it uses these prompts and these",
    "start": "1819039",
    "end": "1824880"
  },
  {
    "text": "models in a wide variety of of different ways and it's really this this complex",
    "start": "1824880",
    "end": "1830399"
  },
  {
    "text": "cognitive architecture that we're that we're building up that's about it thank you guys for",
    "start": "1830399",
    "end": "1838679"
  },
  {
    "text": "listening",
    "start": "1838679",
    "end": "1841679"
  }
]
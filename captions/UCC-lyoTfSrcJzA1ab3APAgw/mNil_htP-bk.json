[
  {
    "text": "thanks Mar and Arash and viian and per and everyone for hosting us uh excited to be here my name is Harrison uh I'm",
    "start": "4240",
    "end": "11440"
  },
  {
    "text": "the co-founder and CEO of Lang chain and I'm excited today to be chatting with",
    "start": "11440",
    "end": "18039"
  },
  {
    "text": "James there's a microphone I think down there um I met I met James there's two",
    "start": "18039",
    "end": "24160"
  },
  {
    "text": "microphones yeah we're double miced I met James I think two years ago roughly yeah um when we were both kind",
    "start": "24160",
    "end": "30599"
  },
  {
    "text": "of like exploring the Gen space and we've stayed in touch and you know has",
    "start": "30599",
    "end": "36000"
  },
  {
    "text": "been awesome to see what what you've been doing with character um maybe to start do you want to give people a little bit of your background because I",
    "start": "36000",
    "end": "42800"
  },
  {
    "text": "think that speaks to some of what we'll be talking about today sure than uh and and thank you to per and and to L Jane",
    "start": "42800",
    "end": "48360"
  },
  {
    "text": "for hosting this event um and and having us um to speak about the story of character um I I guess like the most",
    "start": "48360",
    "end": "56920"
  },
  {
    "text": "most relevant history for me is I I joined Google brain in 2019 um where I",
    "start": "56920",
    "end": "62760"
  },
  {
    "text": "eventually met no and and Daniel and a bunch of the founding team of character over the years um and spent about four",
    "start": "62760",
    "end": "70439"
  },
  {
    "text": "years there working on dev tools um sort of um I I worked on systems with deep",
    "start": "70439",
    "end": "77360"
  },
  {
    "text": "mind that gated access to the the TPU and GPU Fleet um and and helped",
    "start": "77360",
    "end": "83079"
  },
  {
    "text": "researchers Define experiments and training Loops Etc um and two years ago",
    "start": "83079",
    "end": "89040"
  },
  {
    "text": "I I made the leap of faith in back into startup land um where I was prior to",
    "start": "89040",
    "end": "94360"
  },
  {
    "text": "Google um to join no I'm Daniel and then and the the rest of the founding team to",
    "start": "94360",
    "end": "100000"
  },
  {
    "text": "to help scale the product um and excited to talk about that today yeah let's talk about that most people are probably",
    "start": "100000",
    "end": "106680"
  },
  {
    "text": "familiar with character in some form um but do you maybe want to give an",
    "start": "106680",
    "end": "111920"
  },
  {
    "text": "overview of of the product that you all are building and maybe how it's kind of like evolved over the past two three",
    "start": "111920",
    "end": "117039"
  },
  {
    "text": "years yeah I if I could I'll go back to 2017 um and maybe even earlier um so so",
    "start": "117039",
    "end": "123680"
  },
  {
    "text": "Noom and Daniel Noom uh was at Google actually from 2000",
    "start": "123680",
    "end": "128879"
  },
  {
    "text": "uh has hundreds of patents to his name has has you know pushed the industry the",
    "start": "128879",
    "end": "134640"
  },
  {
    "text": "like machine learning AI industry you know in more ways than you know just about anyone else in the world I think",
    "start": "134640",
    "end": "140720"
  },
  {
    "text": "um 2017 he was the you know one of the primary authors on the attention paper",
    "start": "140720",
    "end": "145840"
  },
  {
    "text": "um and um Daniel def freus had had this lifelong dream of of building an open",
    "start": "145840",
    "end": "152840"
  },
  {
    "text": "domain dialogue agent that was unconstrained from the very rigid NLP",
    "start": "152840",
    "end": "158200"
  },
  {
    "text": "you know rule-based systems um that were the the standard of the time and um",
    "start": "158200",
    "end": "164920"
  },
  {
    "text": "those two um got connected inside Google and why I connected with Daniel is",
    "start": "164920",
    "end": "171040"
  },
  {
    "text": "because he was begging people for TPU credits to train larger and larger",
    "start": "171040",
    "end": "176519"
  },
  {
    "text": "models back in 2019 um and eventually you know that",
    "start": "176519",
    "end": "182280"
  },
  {
    "text": "pairing plus a whole bunch of 20% work formed um uh the product that was was",
    "start": "182280",
    "end": "188519"
  },
  {
    "text": "sort of behind the paper Lambda um which then um actually was preceded by Mina",
    "start": "188519",
    "end": "194879"
  },
  {
    "text": "internally at Google then became Lambda and then in you know sort of",
    "start": "194879",
    "end": "200560"
  },
  {
    "text": "2020 uh one they they left Google to try and give this technology to the",
    "start": "200560",
    "end": "206840"
  },
  {
    "text": "consumers um and and see what they wanted in see what they they did with it the most ironic thing you about",
    "start": "206840",
    "end": "213720"
  },
  {
    "text": "characters founding story is that it was a case of just build it and they will",
    "start": "213720",
    "end": "219159"
  },
  {
    "text": "come um which sort of broke all of like the rule numero UMO Unos of the",
    "start": "219159",
    "end": "226120"
  },
  {
    "text": "201s um and um so exceptional story um",
    "start": "226120",
    "end": "231599"
  },
  {
    "text": "exceptional pairing and you know we launched about a month before chat GPT",
    "start": "231599",
    "end": "238120"
  },
  {
    "text": "came out in October of 2022 and um having rebuilt the sort of",
    "start": "238120",
    "end": "245280"
  },
  {
    "text": "research from the ground up and then in January you know went from I think like",
    "start": "245280",
    "end": "250879"
  },
  {
    "text": "300 uh Generations per second to this summer we went we over 30,000 mes per",
    "start": "250879",
    "end": "256199"
  },
  {
    "text": "second um so we went through like two orders of magnitude in about 18 months and that's the second third kind",
    "start": "256199",
    "end": "264800"
  },
  {
    "text": "of like highest QPS yeah I think I think by",
    "start": "264800",
    "end": "270360"
  },
  {
    "text": "um enough sleuthing uh it's about the third most used gen application um",
    "start": "270360",
    "end": "278120"
  },
  {
    "text": "probably behind um meta and open AI um might give a brief primary about",
    "start": "278120",
    "end": "284479"
  },
  {
    "text": "what character maybe is as as a platform um and how we're sort of different to",
    "start": "284479",
    "end": "290440"
  },
  {
    "text": "you know the chat gpts of the world and and even the meta AI AIS of the world it's all premise on this on on the",
    "start": "290440",
    "end": "296280"
  },
  {
    "text": "notion of ugc prompts basically um that are characters and so so when you know",
    "start": "296280",
    "end": "302720"
  },
  {
    "text": "as a new user to character you s have met with 200 million you know Community",
    "start": "302720",
    "end": "308400"
  },
  {
    "text": "created characters that are effectively just prompts um you know behind the",
    "start": "308400",
    "end": "314320"
  },
  {
    "text": "scenes um and and you can go and discover uh uh you",
    "start": "314320",
    "end": "319680"
  },
  {
    "text": "know um you well-known characters from TV shows you can go and discover you",
    "start": "319680",
    "end": "325120"
  },
  {
    "text": "know generic characters like a therapist character or a best friend character or a language learning character um and",
    "start": "325120",
    "end": "333360"
  },
  {
    "text": "obviously on the other side of that sort of marketplace you can create your own um character um and it's super duper",
    "start": "333360",
    "end": "340639"
  },
  {
    "text": "simple it's all all it is is natural language prompting um and",
    "start": "340639",
    "end": "346000"
  },
  {
    "text": "uh yeah it's actually really difficult to Define like what is the whale use",
    "start": "346000",
    "end": "351520"
  },
  {
    "text": "case because there's a super long tale of users and even within a single user",
    "start": "351520",
    "end": "357919"
  },
  {
    "text": "you know they might have a a pleth of use cases that they come to the site for given that this is so like open",
    "start": "357919",
    "end": "364800"
  },
  {
    "text": "domain um and and you can talk about anything that's part of the power of of gen I think um cool okay so so you guys",
    "start": "364800",
    "end": "372440"
  },
  {
    "text": "launch right around uh uh or right before chat GPT I think a lot of people",
    "start": "372440",
    "end": "377599"
  },
  {
    "text": "in this room are probably building with apps and they've probably or building apps with Gen they've probably launched",
    "start": "377599",
    "end": "383160"
  },
  {
    "text": "apps uh probably no one in this room has reached a scale of character AI what was",
    "start": "383160",
    "end": "388440"
  },
  {
    "text": "that kind of like Journey like and as people are building you know if as hopefully they're able to kind of like",
    "start": "388440",
    "end": "394199"
  },
  {
    "text": "you know build apps like this what should they expect kind of like along the way",
    "start": "394199",
    "end": "400280"
  },
  {
    "text": "yeah um so I think for a lot of us last last year was really like the hyper",
    "start": "400280",
    "end": "406000"
  },
  {
    "text": "growth year and it was probably like speaking for other people but definitely myself the most rewarding um year of of",
    "start": "406000",
    "end": "413560"
  },
  {
    "text": "our lives in our careers because you know as as um this whole industry taking",
    "start": "413560",
    "end": "419960"
  },
  {
    "text": "off we also have a you know exponential user um growth and and what kicked that",
    "start": "419960",
    "end": "425680"
  },
  {
    "text": "off was it just kind of like more eyeballs on the space more Tailwinds or",
    "start": "425680",
    "end": "432280"
  },
  {
    "text": "yeah I mean I honest I think that you know we we rode the coattails of Chachi um like like Chachi sort of",
    "start": "432280",
    "end": "439720"
  },
  {
    "text": "brought to the eyes of the consumer in more of the mainstream um what this technology was",
    "start": "439720",
    "end": "446840"
  },
  {
    "text": "and then you know as as you know regular consumers online s of were exposed to",
    "start": "446840",
    "end": "453599"
  },
  {
    "text": "the technology then you know some fraction of them you know gravitated towards this different experience um you",
    "start": "453599",
    "end": "460680"
  },
  {
    "text": "know people talk about character being more fond more engaging um um uh than",
    "start": "460680",
    "end": "468120"
  },
  {
    "text": "than like the competitor app did you think that would be the case or were you did you think it was like when they",
    "start": "468120",
    "end": "474639"
  },
  {
    "text": "started growing were you like oh oh no this is bad for us or did you kind of like realize that it was going to",
    "start": "474639",
    "end": "480000"
  },
  {
    "text": "whole wave super super good question I I think it was initially competitive um",
    "start": "480000",
    "end": "485159"
  },
  {
    "text": "and and you know I I don't think the it it's it's one one thing to say but it's another thing to like fully embody in",
    "start": "485159",
    "end": "491440"
  },
  {
    "text": "your brain that you know um the rising tide lifts all boats and and like the Tam like the market is expanding as",
    "start": "491440",
    "end": "498240"
  },
  {
    "text": "we're as we're building um and so you know it wasn't really a zero some game at all um but it's really e that's the",
    "start": "498240",
    "end": "505280"
  },
  {
    "text": "sort of default um mental model that I think we had initially but um but yeah the the the scaling story it",
    "start": "505280",
    "end": "512839"
  },
  {
    "text": "it was it was you know I I would say a pretty standard monolith um to",
    "start": "512839",
    "end": "519599"
  },
  {
    "text": "Services uh and dropping the micro part um via database shoting story with I",
    "start": "519599",
    "end": "528200"
  },
  {
    "text": "think three core differences given that it was this llm like this new technology",
    "start": "528200",
    "end": "534080"
  },
  {
    "text": "and differences from traditional kind of like app scaling yeah yeah exactly different different to like a",
    "start": "534080",
    "end": "539600"
  },
  {
    "text": "traditional consumer application of the 2010 201s um what are the differences I think",
    "start": "539600",
    "end": "545880"
  },
  {
    "text": "that uh number one the volume of data um",
    "start": "545880",
    "end": "550959"
  },
  {
    "text": "per second that you're having to like Wrangle is order a magnitude higher than",
    "start": "550959",
    "end": "559240"
  },
  {
    "text": "prior Generation Um social companies and the reason is is because you've got to",
    "start": "559240",
    "end": "564399"
  },
  {
    "text": "build this prompt every single message like every like the most heavily",
    "start": "564399",
    "end": "570640"
  },
  {
    "text": "used sort of user path is generating a response generating a message and for",
    "start": "570640",
    "end": "577000"
  },
  {
    "text": "every time you're going to write a message you're going to pull the entire chat history likely from cash um a lot",
    "start": "577000",
    "end": "582600"
  },
  {
    "text": "of it um but you've still got to like you you're you're piping that many bytes",
    "start": "582600",
    "end": "587880"
  },
  {
    "text": "through networking layers um that many times a second um and so I think I think",
    "start": "587880",
    "end": "594320"
  },
  {
    "text": "we're like like our network does seven or 8 G",
    "start": "594320",
    "end": "599360"
  },
  {
    "text": "gab per second just on just on this hot path um for Generation Um so that's like",
    "start": "599360",
    "end": "606959"
  },
  {
    "text": "insane volume of data um I think is one the second is cost like to to serve",
    "start": "606959",
    "end": "616720"
  },
  {
    "text": "30,000 messages per second costs a ton of money in GPU spend um and so there",
    "start": "616720",
    "end": "623959"
  },
  {
    "text": "were like last year like this is sort of correlated with with latency too too",
    "start": "623959",
    "end": "629640"
  },
  {
    "text": "like um uh you can you can pay more money in",
    "start": "629640",
    "end": "636519"
  },
  {
    "text": "in over provisioning servers like over over provisioning gpus um to lower the",
    "start": "636519",
    "end": "641600"
  },
  {
    "text": "latency and we all know that like consumer number one is like better",
    "start": "641600",
    "end": "647320"
  },
  {
    "text": "latency like the easiest thing to do to improve a consumer application is like improv latency but that costs a huge",
    "start": "647320",
    "end": "652880"
  },
  {
    "text": "amount of money and so what else can you do you can like um prun prune the number of parameters that you're serving at run",
    "start": "652880",
    "end": "659560"
  },
  {
    "text": "time um parameters in the models themselves parameters in the models yeah um and so we uh and and maybe just to",
    "start": "659560",
    "end": "666839"
  },
  {
    "text": "make this really clear because I don't think we've touched on it but unlike probably most apps building in the space",
    "start": "666839",
    "end": "672079"
  },
  {
    "text": "you guys were building your own models from day Zero like Foundation models not fine-tuning yeah that that's exactly",
    "start": "672079",
    "end": "678560"
  },
  {
    "text": "right and that's part of you know like um nom and Daniel and the rest of the founding team's sort of um gift to the",
    "start": "678560",
    "end": "685399"
  },
  {
    "text": "company is that we had you know until recently until you know Google bought",
    "start": "685399",
    "end": "691839"
  },
  {
    "text": "essentially the research from from the company um we had our own pre-training through posttraining um Stacks which",
    "start": "691839",
    "end": "698800"
  },
  {
    "text": "meant that you know we could make architectural decisions um like",
    "start": "698800",
    "end": "704160"
  },
  {
    "text": "multiquery attention way like Upstream in the pre-training process and um serve",
    "start": "704160",
    "end": "711760"
  },
  {
    "text": "that knowing that that actually didn't hurt engagement it didn't hurt out core",
    "start": "711760",
    "end": "717399"
  },
  {
    "text": "metric as much as um a competitor that's serving a more intelligent based you know product",
    "start": "717399",
    "end": "724560"
  },
  {
    "text": "experience would would see and so we were able to not just like take a given",
    "start": "724560",
    "end": "729800"
  },
  {
    "text": "architecture and and like um post-train some like um uh style into the the model",
    "start": "729800",
    "end": "737000"
  },
  {
    "text": "but like actually make pretty significant architectural decisions way Upstream in the in the pre-training",
    "start": "737000",
    "end": "742720"
  },
  {
    "text": "process and that also let you control speed and latency more precisely yeah um",
    "start": "742720",
    "end": "748240"
  },
  {
    "text": "I think like just just like mqa um gave us um what's mqa mqa multier",
    "start": "748240",
    "end": "755440"
  },
  {
    "text": "attention um it gave us 5x reduction in um in in out like GPU",
    "start": "755440",
    "end": "765880"
  },
  {
    "text": "cache why is GPU cache important because for every message that we generate we",
    "start": "765880",
    "end": "774720"
  },
  {
    "text": "cache at each layer in the model the result of the",
    "start": "774720",
    "end": "779920"
  },
  {
    "text": "computation um and the result of the computation is dependent on the prompt",
    "start": "779920",
    "end": "785680"
  },
  {
    "text": "up until that point when you think about character ai's use case the N plus1",
    "start": "785680",
    "end": "791560"
  },
  {
    "text": "generation meaning like when you're chatting like the N plus1 message that you send the prompt looks exactly the",
    "start": "791560",
    "end": "799160"
  },
  {
    "text": "same modulo the new user message and so by utilizing this GPU cache which we now",
    "start": "799160",
    "end": "805760"
  },
  {
    "text": "have 5x more of effectively per GPU um we can actually pick up all the",
    "start": "805760",
    "end": "813839"
  },
  {
    "text": "computation by like the 5% that's how you know 5% of the end which which is",
    "start": "813839",
    "end": "820920"
  },
  {
    "text": "the users message that we haven't competed over yet um so if we didn't",
    "start": "820920",
    "end": "826320"
  },
  {
    "text": "have any GPU caching at all and we have like a pretty um comprehensive scaling",
    "start": "826320",
    "end": "832440"
  },
  {
    "text": "inference part one part two on our research blog if you're curious um we we would we would be bankrupt like tomorrow",
    "start": "832440",
    "end": "838920"
  },
  {
    "text": "um um um so we have like a 95% cash AIT ratio which allows us to serve this this",
    "start": "838920",
    "end": "844440"
  },
  {
    "text": "GPS um at a decent cost so I think like um cost is is like the second biggest",
    "start": "844440",
    "end": "851560"
  },
  {
    "text": "difference is like to serve the core user experience there's a whole bunch of",
    "start": "851560",
    "end": "857320"
  },
  {
    "text": "engineering challenges that we had to you know face headon um including you",
    "start": "857320",
    "end": "862920"
  },
  {
    "text": "know architecture changes including caching um including like sizes of the model um in order to serve at somewhere",
    "start": "862920",
    "end": "871560"
  },
  {
    "text": "that's cost effective for us third thing um is the like the total",
    "start": "871560",
    "end": "878120"
  },
  {
    "text": "response time is I think p50 is like 12.5 seconds today meaning like that's",
    "start": "878120",
    "end": "885519"
  },
  {
    "text": "the time it takes to generate an entire message um and back last year I think it",
    "start": "885519",
    "end": "891519"
  },
  {
    "text": "was probably like 25 seconds and the first chunk like the the time it took",
    "start": "891519",
    "end": "897399"
  },
  {
    "text": "from a user to send a message and get the first like you know first like eight",
    "start": "897399",
    "end": "902839"
  },
  {
    "text": "words and the response that's like 5 seconds but 12 to 25 seconds call it",
    "start": "902839",
    "end": "909600"
  },
  {
    "text": "you're having to like maintain that open connection between your service and the",
    "start": "909600",
    "end": "915120"
  },
  {
    "text": "clients and so like you multiply that duration 12 seconds by that QPS and you",
    "start": "915120",
    "end": "923480"
  },
  {
    "text": "get to like 400,000 open connections to all of your like in across all your",
    "start": "923480",
    "end": "930079"
  },
  {
    "text": "machines um and so like that also means like you know a you got to scale the",
    "start": "930079",
    "end": "936279"
  },
  {
    "text": "number of PODS B you've got to make sure that each connection is somewhat lightweight um so that you can um um you",
    "start": "936279",
    "end": "944880"
  },
  {
    "text": "know keep them open and you're not like ooming the machines um and there's a",
    "start": "944880",
    "end": "950000"
  },
  {
    "text": "whole bunch of pressure you have on like your your like services and your",
    "start": "950000",
    "end": "955040"
  },
  {
    "text": "system components like your Rus cache layer for example",
    "start": "955040",
    "end": "960160"
  },
  {
    "text": "um so um and your networking layer so I think",
    "start": "960160",
    "end": "965399"
  },
  {
    "text": "like this was this is another another like very unique thing that was different from like consumer",
    "start": "965399",
    "end": "971399"
  },
  {
    "text": "applications of the 201s um one of the things um that we hear a bunch from people as they're",
    "start": "971399",
    "end": "977240"
  },
  {
    "text": "building their apps is kind of like a trade-off between performance latency and cost um and you kind of mentioned a",
    "start": "977240",
    "end": "984000"
  },
  {
    "text": "few of those as you were talking about kind of like scaling out the app how how did you guys think about that",
    "start": "984000",
    "end": "989440"
  },
  {
    "text": "internally did you prioritize one more than the other how did you measure it how did you kind of like decide the trade-offs to make performance meaning",
    "start": "989440",
    "end": "996720"
  },
  {
    "text": "quality yeah yeah um so I",
    "start": "996720",
    "end": "1003880"
  },
  {
    "text": "I nothing was particularly scientific um you know we like building the plane as",
    "start": "1003880",
    "end": "1009360"
  },
  {
    "text": "it was taking off um every every time we we made like a",
    "start": "1009360",
    "end": "1017959"
  },
  {
    "text": "Improvement to like a call latency metric from the",
    "start": "1017959",
    "end": "1023680"
  },
  {
    "text": "model we could trade that off with um cost of serving we could either hold",
    "start": "1023680",
    "end": "1029600"
  },
  {
    "text": "like the the QPS per GPU effectively constant and drop overall",
    "start": "1029600",
    "end": "1037400"
  },
  {
    "text": "latency um or we could um serve our",
    "start": "1037400",
    "end": "1043959"
  },
  {
    "text": "entire Capa our entire sort of like um Demand on fuel machines",
    "start": "1043959",
    "end": "1049400"
  },
  {
    "text": "um it was probably mostly mediated by the research demands like you know um if",
    "start": "1049400",
    "end": "1056200"
  },
  {
    "text": "we're kicking off like a massive Hero Run for example of a 3 months we need some fixed um capacity to train that",
    "start": "1056200",
    "end": "1063799"
  },
  {
    "text": "model and so we might um you in increase the consumer like first party platform",
    "start": "1063799",
    "end": "1069919"
  },
  {
    "text": "consumer s character AI latency we might bump that up in order to take some",
    "start": "1069919",
    "end": "1075200"
  },
  {
    "text": "machines and assign them to research um that was that was probably the",
    "start": "1075200",
    "end": "1082039"
  },
  {
    "text": "um the biggest tradeoff that was made makes sense makes sense um you're",
    "start": "1082039",
    "end": "1087120"
  },
  {
    "text": "scaling like crazy over the past year were there any kind of like horror stories War Stories funny stories that",
    "start": "1087120",
    "end": "1094240"
  },
  {
    "text": "popped up as you were trying to to continue to scale the platform there was there was one particularly",
    "start": "1094240",
    "end": "1100320"
  },
  {
    "text": "funny um story I think that like relates to how",
    "start": "1100320",
    "end": "1107120"
  },
  {
    "text": "different like to a challenge that is unique to scaling these types of like products as well and it was to",
    "start": "1107120",
    "end": "1115240"
  },
  {
    "text": "do with this GPU like local attention cache that I mentioned um we for a",
    "start": "1115240",
    "end": "1121720"
  },
  {
    "text": "couple of months we um we had Rewritten our serving cop pods um and so these",
    "start": "1121720",
    "end": "1130600"
  },
  {
    "text": "these new serving cop pods indexed the results of these computation into the cache in a slightly different way",
    "start": "1130600",
    "end": "1139039"
  },
  {
    "text": "whenever we like ran whenever we like you know post- trained a new model and",
    "start": "1139039",
    "end": "1144600"
  },
  {
    "text": "did an AB test on our site we found that like not only were the results like",
    "start": "1144600",
    "end": "1150799"
  },
  {
    "text": "neutral to negative but like they were very negative we like what like the the token budget was like 5x the previous",
    "start": "1150799",
    "end": "1157880"
  },
  {
    "text": "model the um like the DOA quality like the DOA mixture was like so much better",
    "start": "1157880",
    "end": "1163799"
  },
  {
    "text": "like the architecture was so much better like how the hell is this happening um and like it responded with coherent like",
    "start": "1163799",
    "end": "1172360"
  },
  {
    "text": "responses and so like the test that we ran for like to test the contract of",
    "start": "1172360",
    "end": "1177559"
  },
  {
    "text": "like message in message out it was like they were all passing it was",
    "start": "1177559",
    "end": "1182600"
  },
  {
    "text": "fine um just so happened that like when we when we rewrote those c-s to index",
    "start": "1182600",
    "end": "1188200"
  },
  {
    "text": "the results of computation to the cache we we missed",
    "start": "1188200",
    "end": "1194159"
  },
  {
    "text": "indexing the the results of the computation for um user",
    "start": "1194159",
    "end": "1201320"
  },
  {
    "text": "messages and so like on the successive Generations",
    "start": "1201320",
    "end": "1207000"
  },
  {
    "text": "when we when we picked up that 95% cash and computed the last 5% what the model",
    "start": "1207000",
    "end": "1213360"
  },
  {
    "text": "was seeing effectively was character like in the prompt effectively was",
    "start": "1213360",
    "end": "1219440"
  },
  {
    "text": "character definition character message character message character message charact like it's like it was talking to",
    "start": "1219440",
    "end": "1224960"
  },
  {
    "text": "itself and missing all of the user messages and like obviously over time",
    "start": "1224960",
    "end": "1231159"
  },
  {
    "text": "like the users are like what what the hell is this like this sucks like and you know time spent like Tang to 12%",
    "start": "1231159",
    "end": "1238720"
  },
  {
    "text": "we're like what um and so we fixed that bug and like an an artifact like a model that we had lying around we like fixed",
    "start": "1238720",
    "end": "1246159"
  },
  {
    "text": "it ran a test and it won by like 24% and we like oh like that was like 3",
    "start": "1246159",
    "end": "1251919"
  },
  {
    "text": "months of you know um of like banging our heads against the table how how did you find the bug um your our mutual",
    "start": "1251919",
    "end": "1258840"
  },
  {
    "text": "friend Sam scha um was was bugged so much by people saying like this doesn't",
    "start": "1258840",
    "end": "1264159"
  },
  {
    "text": "feel right to me like Vibe check and no test of passing but like something's off",
    "start": "1264159",
    "end": "1270679"
  },
  {
    "text": "with the quality of this model um and he he was bugged like so many times they was like okay like fine I'll look into",
    "start": "1270679",
    "end": "1276880"
  },
  {
    "text": "it um and like it was like a probably like a three line change um to to fix",
    "start": "1276880",
    "end": "1282640"
  },
  {
    "text": "the buck so nice um I would say the other like um maybe like um different",
    "start": "1282640",
    "end": "1290120"
  },
  {
    "text": "for this audience um the other like the Achilles heel of scaling this product",
    "start": "1290120",
    "end": "1295559"
  },
  {
    "text": "was the database layer 100% um and like the the the funniest and most",
    "start": "1295559",
    "end": "1305520"
  },
  {
    "text": "catastrophic like War Story we have with the database is like I think in June of",
    "start": "1305520",
    "end": "1310679"
  },
  {
    "text": "last year A bunch of us woke up at 5:00 a.m. PST and we had a teammate in in um",
    "start": "1310679",
    "end": "1316919"
  },
  {
    "text": "in New York at 8 to say like hey like the sight's going down like yet again um okay like put",
    "start": "1316919",
    "end": "1323880"
  },
  {
    "text": "maintenance mode on we'll look at it U we all got into the office we realized that um like they seemed a difference",
    "start": "1323880",
    "end": "1331679"
  },
  {
    "text": "like there was database issues latency was spiking there were a whole bunch of open connections to the database and we",
    "start": "1331679",
    "end": "1337320"
  },
  {
    "text": "were like seems different to what we've seen before there's no no easy fix and by 11:00 a.m. we we found like a",
    "start": "1337320",
    "end": "1344240"
  },
  {
    "text": "reasonable hypothesis from Google who was hosting our postgress instance",
    "start": "1344240",
    "end": "1349440"
  },
  {
    "text": "um at the time and it just so happened that like the there was a bug in",
    "start": "1349440",
    "end": "1355360"
  },
  {
    "text": "postgress like core postgress that was was triggered by by function of our sort",
    "start": "1355360",
    "end": "1362320"
  },
  {
    "text": "of query volume and and characteristics and by their wrapping of of postgress",
    "start": "1362320",
    "end": "1369520"
  },
  {
    "text": "which meant that um when postgress like when you do any transaction when you",
    "start": "1369520",
    "end": "1375360"
  },
  {
    "text": "write um update or delete at transaction ID is issued for bookkeeping",
    "start": "1375360",
    "end": "1381200"
  },
  {
    "text": "purposes uh xid and those xids are are garbage",
    "start": "1381200",
    "end": "1386480"
  },
  {
    "text": "collected like periodically by this vacuum procedure and um it just happened",
    "start": "1386480",
    "end": "1391799"
  },
  {
    "text": "that like procress thought it release an xid but it",
    "start": "1391799",
    "end": "1397520"
  },
  {
    "text": "hadn't and the way we found out was um",
    "start": "1397520",
    "end": "1403000"
  },
  {
    "text": "we had this post feature where a user could post like a snippet of that that and um every time I",
    "start": "1403000",
    "end": "1411559"
  },
  {
    "text": "user would load that page the um um we would update to metad",
    "start": "1411559",
    "end": "1417679"
  },
  {
    "text": "dat about how often that page was viewed so we would issue this DML transaction like update the record so we needed an",
    "start": "1417679",
    "end": "1425279"
  },
  {
    "text": "xid um but we couldn't update the record because the xid the prior xid hadn't",
    "start": "1425279",
    "end": "1430720"
  },
  {
    "text": "been released and the post that was responsible for this corruption on on",
    "start": "1430720",
    "end": "1436320"
  },
  {
    "text": "like dis on the page was this grilled cheeses post um and no no reason why it",
    "start": "1436320",
    "end": "1443679"
  },
  {
    "text": "would be the grilled cheeses post but it was this like character that was a mix between a grilled cheese and Jesus and",
    "start": "1443679",
    "end": "1450880"
  },
  {
    "text": "it was a really funny I mean like no no disrespect to people you know that that are religious but it was really really",
    "start": "1450880",
    "end": "1456520"
  },
  {
    "text": "funny like the snippet and uh and like by total coincidence it just happened to",
    "start": "1456520",
    "end": "1462240"
  },
  {
    "text": "be this post and So eventually like at later then at 1:00 p.m. we realized we",
    "start": "1462240",
    "end": "1468159"
  },
  {
    "text": "had 16 hours left of issuing DM like xids until the all the entire xid space",
    "start": "1468159",
    "end": "1475520"
  },
  {
    "text": "had been had be consumed and we would need to take the database offline for seven days to do a full vacuum procedure",
    "start": "1475520",
    "end": "1484120"
  },
  {
    "text": "um to like go and like manually release all the xids so it was like do we roll",
    "start": "1484120",
    "end": "1489559"
  },
  {
    "text": "back to yesterday's backup and say that you've lost like to the users that you've lost a day's worth of data do we",
    "start": "1489559",
    "end": "1496159"
  },
  {
    "text": "try and fix forward and like in 16 hours hope we find a solution like what are we",
    "start": "1496159",
    "end": "1502039"
  },
  {
    "text": "going to do eventually like 1:00 a.m. we um successfully ran a like partial",
    "start": "1502039",
    "end": "1510159"
  },
  {
    "text": "vacuum on a backup that succeeded and then we decided to run that same vacuum",
    "start": "1510159",
    "end": "1516000"
  },
  {
    "text": "on our online online database um and took the side down for",
    "start": "1516000",
    "end": "1521919"
  },
  {
    "text": "like 30 40 minutes um so yeah it's funny because like on the one hand like how",
    "start": "1521919",
    "end": "1528480"
  },
  {
    "text": "did we trigger this like random bug and like lowlevel postr bookkeeping but on the other hand like it had to be this",
    "start": "1528480",
    "end": "1534360"
  },
  {
    "text": "Grill Jesus post like almost took you guys down yeah yeah yeah yeah totally um",
    "start": "1534360",
    "end": "1541760"
  },
  {
    "text": "as one of the first companies kind of like in the space really building that scale what internal tooling did you guys",
    "start": "1541760",
    "end": "1550200"
  },
  {
    "text": "build to help you iterate develop faster yeah um so",
    "start": "1550200",
    "end": "1558600"
  },
  {
    "text": "one this is this is going to sound like super trivial and like it kind of is",
    "start": "1558600",
    "end": "1565000"
  },
  {
    "text": "but um at this scale there are so many like components involved in the hot path that",
    "start": "1565000",
    "end": "1573799"
  },
  {
    "text": "um when when we were like last year",
    "start": "1573799",
    "end": "1578919"
  },
  {
    "text": "building out like going from monolith to Services via the shotting",
    "start": "1578919",
    "end": "1584799"
  },
  {
    "text": "strategy The Way We Were constructing the prompt to feed into the",
    "start": "1584799",
    "end": "1590039"
  },
  {
    "text": "LM was effectively concatenating to a string and like slicing into a string",
    "start": "1590039",
    "end": "1596760"
  },
  {
    "text": "over three different components that so like we would build part of the prompt and like via you know grpc protuff we",
    "start": "1596760",
    "end": "1604480"
  },
  {
    "text": "send to a separate component and we get some more data from a different database and like a pan kite to a string which",
    "start": "1604480",
    "end": "1611159"
  },
  {
    "text": "meant and this meant that like this this very you know um janky way of like",
    "start": "1611159",
    "end": "1618240"
  },
  {
    "text": "concatenating slicing into the prompt meant that it was almost impossible to change the prompt in any significant way",
    "start": "1618240",
    "end": "1625600"
  },
  {
    "text": "without introducing bugs somewhere um and the most classy example when we when",
    "start": "1625600",
    "end": "1630640"
  },
  {
    "text": "we launch group chat when we launch group chat rather than the prompts for the LM",
    "start": "1630640",
    "end": "1637919"
  },
  {
    "text": "being character definition effectively and then the chat history it was now",
    "start": "1637919",
    "end": "1643000"
  },
  {
    "text": "like a couple character definitions because you could have multiple characters in the chat",
    "start": "1643000",
    "end": "1649120"
  },
  {
    "text": "and then the history but just doing that just having a couple character",
    "start": "1649120",
    "end": "1654559"
  },
  {
    "text": "definitions was complex because we had so many layers and um I think we we spent like",
    "start": "1654559",
    "end": "1661399"
  },
  {
    "text": "two weeks just making that change with a good Engineers um and introduced like three or four bugs in the in the process",
    "start": "1661399",
    "end": "1669000"
  },
  {
    "text": "um and so we built this tool to to S of solve the problem of iterating on the",
    "start": "1669000",
    "end": "1676080"
  },
  {
    "text": "prompting layer um and most importantly running experiments like when when we make a change to like even a trivial",
    "start": "1676080",
    "end": "1683039"
  },
  {
    "text": "change like um you know um a formatting change like using uh colon",
    "start": "1683039",
    "end": "1691799"
  },
  {
    "text": "space we want at this scale like we want to know what the performance impact was",
    "start": "1691799",
    "end": "1697279"
  },
  {
    "text": "the engagement impact like was it did it regress some quality somewhere was what happened to time spent happened to",
    "start": "1697279",
    "end": "1703399"
  },
  {
    "text": "number messages sent um to the control us treatment um and so so we built this",
    "start": "1703399",
    "end": "1709240"
  },
  {
    "text": "tool called prompt poets which allowed us to basically templa our prompts in",
    "start": "1709240",
    "end": "1715919"
  },
  {
    "text": "this yaml and ginger layer and we use ginger to sort of",
    "start": "1715919",
    "end": "1722320"
  },
  {
    "text": "interpolate um runtime variables and also um execute control flow so you can",
    "start": "1722320",
    "end": "1730000"
  },
  {
    "text": "condition like in the prompt template you can condition on the value of a variable or you can Loop through some",
    "start": "1730000",
    "end": "1738159"
  },
  {
    "text": "verble that you pass into the ginger render function um and then the the yaml",
    "start": "1738159",
    "end": "1745399"
  },
  {
    "text": "layer was usedful cuz we don't have an infinite context window and when we sort of have context",
    "start": "1745399",
    "end": "1754399"
  },
  {
    "text": "overflow we want to truncate we want to truncate in a Smart Way such that we don't blow this 95% cash every",
    "start": "1754399",
    "end": "1763039"
  },
  {
    "text": "successive message um and so we had to do this smart truncation um",
    "start": "1763039",
    "end": "1768880"
  },
  {
    "text": "implementation which was also very useful to have like this structured yaml",
    "start": "1768880",
    "end": "1774440"
  },
  {
    "text": "um and like um we can assign a truncation priority to each part of the",
    "start": "1774440",
    "end": "1780039"
  },
  {
    "text": "yaml so that we can you know take out less important things from The Prompt",
    "start": "1780039",
    "end": "1785320"
  },
  {
    "text": "first um and and not take out like something that's critical like uh the",
    "start": "1785320",
    "end": "1791559"
  },
  {
    "text": "character definition for example um and by character definition I mean the ugc",
    "start": "1791559",
    "end": "1797200"
  },
  {
    "text": "like user generat content prompt that was that is the character and you guys open sourced this right we open sourc it",
    "start": "1797200",
    "end": "1804720"
  },
  {
    "text": "yeah after um actually like the original name of this tool was was and it still",
    "start": "1804720",
    "end": "1809840"
  },
  {
    "text": "is humies um like the the the Greek the Greek god the Greek god like",
    "start": "1809840",
    "end": "1815399"
  },
  {
    "text": "communicates with the gods yeah yeah it's like um and so like you know like we build this tool to communicate with",
    "start": "1815399",
    "end": "1821760"
  },
  {
    "text": "the gods meaning the LMS um I bet I bet you your Valar wouldn't be happy with that and uh",
    "start": "1821760",
    "end": "1829039"
  },
  {
    "text": "and um and and we we like we baked in a whole bunch of like character",
    "start": "1829039",
    "end": "1835399"
  },
  {
    "text": "implementation detail into homies and then stripped all of that out to open source this now very lightweight um",
    "start": "1835399",
    "end": "1842919"
  },
  {
    "text": "package called prom P um and it's it's you know uh we're hoping to put more",
    "start": "1842919",
    "end": "1848960"
  },
  {
    "text": "investment behind it um but it's go some decent traction people should check it out um we're going to go to questions",
    "start": "1848960",
    "end": "1855720"
  },
  {
    "text": "after one more question so think of think of stuff you want to ask",
    "start": "1855720",
    "end": "1861840"
  },
  {
    "text": "James what's next for character yeah um so I think part of the answer is is",
    "start": "1861840",
    "end": "1872399"
  },
  {
    "text": "um mention that we we went through I'm not sure if everyone saw but we went through this sort of deal with character",
    "start": "1872399",
    "end": "1879440"
  },
  {
    "text": "where sorry with Google where Google sort of licensed our core research um",
    "start": "1879440",
    "end": "1886120"
  },
  {
    "text": "and hired like 32 researchers from the pre-training like the entire pre-training team um which for us meant",
    "start": "1886120",
    "end": "1893120"
  },
  {
    "text": "like internally like we run from character 1.0 to character 2.0 C 2.0 is",
    "start": "1893120",
    "end": "1899080"
  },
  {
    "text": "much less focused on on pre-training um our models we still have a very strong",
    "start": "1899080",
    "end": "1905760"
  },
  {
    "text": "uh posttraining Team um that that sort of post trains our models uh on on preference data that",
    "start": "1905760",
    "end": "1913720"
  },
  {
    "text": "we collect from the product um but the shift was going from like this",
    "start": "1913720",
    "end": "1918840"
  },
  {
    "text": "aspirational AGI research lab to like 100% focused on the product and",
    "start": "1918840",
    "end": "1925240"
  },
  {
    "text": "the users um and so in that vein um the",
    "start": "1925240",
    "end": "1930919"
  },
  {
    "text": "the sort of 60% BET right now for like in terms of resources of the company are",
    "start": "1930919",
    "end": "1936679"
  },
  {
    "text": "on new formats and big bats so we want to explore you know new um user",
    "start": "1936679",
    "end": "1943279"
  },
  {
    "text": "experiences that sort of break out of the chat messaging sort of response um",
    "start": "1943279",
    "end": "1949679"
  },
  {
    "text": "Paradigm into um more multimodal experiences how can we generate artifacts on existing chat transcripts",
    "start": "1949679",
    "end": "1956720"
  },
  {
    "text": "and and maybe like build a feed or build something that is like new and exciting",
    "start": "1956720",
    "end": "1962600"
  },
  {
    "text": "and only possible with this technology the sort of like um 20 to",
    "start": "1962600",
    "end": "1968720"
  },
  {
    "text": "30% um focus is on the current core products like making sure we finish the",
    "start": "1968720",
    "end": "1974519"
  },
  {
    "text": "loops and tighten up the the existing user experiences and the 10% bet is like",
    "start": "1974519",
    "end": "1979919"
  },
  {
    "text": "to the to the one of the like points I brought up earlier like it's very costly to serve uh at this scale and so like",
    "start": "1979919",
    "end": "1986600"
  },
  {
    "text": "we're going to we're going to make some money um and and I think there are very easy ways of doing that",
    "start": "1986600",
    "end": "1994679"
  }
]
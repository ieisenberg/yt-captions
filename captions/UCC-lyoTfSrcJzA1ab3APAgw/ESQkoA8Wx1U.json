[
  {
    "text": "for tuning in and and joining this webinar I'm excited to be doing this one I think the first one we ever did was on",
    "start": "359",
    "end": "7620"
  },
  {
    "text": "a sequel and I think we had Francisco on there as well so it's uh it's good to come full circle",
    "start": "7620",
    "end": "13860"
  },
  {
    "text": "um we've got uh we've got some awesome presentations and an awesome webinar today",
    "start": "13860",
    "end": "18960"
  },
  {
    "text": "um minor Logistics before we get started this is being recorded it will be available at the link afterwards and",
    "start": "18960",
    "end": "24180"
  },
  {
    "text": "then we'll also put it up on YouTube um in in a day or two um if you have questions we will spend a",
    "start": "24180",
    "end": "30779"
  },
  {
    "text": "lot of time answering the questions at the end so please ask them in the little question mark box so if you look on the",
    "start": "30779",
    "end": "37680"
  },
  {
    "text": "right chat which you're in now and then there's a box underneath it with a question mark please put your questions in there upload the ones that you want",
    "start": "37680",
    "end": "44399"
  },
  {
    "text": "to hear answered the most um and in terms of schedule what we're going to do is we're going to do three",
    "start": "44399",
    "end": "49980"
  },
  {
    "text": "quick uh three quick presentations and then q a for the rest of it",
    "start": "49980",
    "end": "55620"
  },
  {
    "text": "um that's pretty much the the the introduction so with that maybe we can",
    "start": "55620",
    "end": "61140"
  },
  {
    "text": "do quick intros uh bye everyone my name my name is Harrison uh co-founder CEO of langchain and I will pass it on to our",
    "start": "61140",
    "end": "68640"
  },
  {
    "text": "gym do you want to start yeah hi everyone really excited to be here uh my name is artem I'm co-founder",
    "start": "68640",
    "end": "75240"
  },
  {
    "text": "and CEO at Cube David hi everyone I'm David um and CEO of",
    "start": "75240",
    "end": "82740"
  },
  {
    "text": "Delphi labs Francisco",
    "start": "82740",
    "end": "88439"
  },
  {
    "text": "hey there so my name is Francisco I'm co-founder with Mano here from Palace where do we do llm Consulting and we do",
    "start": "88439",
    "end": "96119"
  },
  {
    "text": "quite a lot of them to SQL work so really excited to be here and last but not least manual",
    "start": "96119",
    "end": "104340"
  },
  {
    "text": "yeah Francisco already presented uh myself but I'm co-founder with him at Pampa here doing consulting and also",
    "start": "104340",
    "end": "110840"
  },
  {
    "text": "contributing to 19 as well awesome let's jump right into our team",
    "start": "110840",
    "end": "116880"
  },
  {
    "text": "do you wanna do you want to take it away yeah sure let's let me",
    "start": "116880",
    "end": "122000"
  },
  {
    "text": "share my screen here",
    "start": "122000",
    "end": "126079"
  },
  {
    "text": "okay you can see it all right yes",
    "start": "128640",
    "end": "134040"
  },
  {
    "text": "yeah I will do a quick introduction to the idea of semantic player and it keeps specifically and then how it can be used",
    "start": "134040",
    "end": "140520"
  },
  {
    "text": "uh with with land chain and llm based applications anything you know like uh",
    "start": "140520",
    "end": "147599"
  },
  {
    "text": "David from Delphi will cut mobile the you know I'm sure about the benefits of",
    "start": "147599",
    "end": "152879"
  },
  {
    "text": "that approach as well but just kind of you know to set a stage uh what is semantic layer uh semantic layer uh it's",
    "start": "152879",
    "end": "161760"
  },
  {
    "text": "a middleware that sits between your data sources and your different applications",
    "start": "161760",
    "end": "167940"
  },
  {
    "text": "so you can think about it as a the analytical oil Ram that helps you to",
    "start": "167940",
    "end": "175860"
  },
  {
    "text": "Define metrics properties of the data sort of translate the database tabular",
    "start": "175860",
    "end": "183000"
  },
  {
    "text": "data into molec meaningful business level data",
    "start": "183000",
    "end": "188580"
  },
  {
    "text": "um it's uh when you have that in your stack your applications including can only maybe",
    "start": "188700",
    "end": "195000"
  },
  {
    "text": "your python land chain application would not go to the data source directly but",
    "start": "195000",
    "end": "200159"
  },
  {
    "text": "would go through the semantic layer and the benefits of having this multiplayer as you can see them on a slide like a",
    "start": "200159",
    "end": "205680"
  },
  {
    "text": "data modeling Access Control caching an API I will talk more about data modeling",
    "start": "205680",
    "end": "211019"
  },
  {
    "text": "just because I think that's the most relevant benefit to the sort of a text",
    "start": "211019",
    "end": "216420"
  },
  {
    "text": "to SQL applications but other benefits including access control that's like a",
    "start": "216420",
    "end": "222480"
  },
  {
    "text": "possibility to centralize your access control coming from a different applications to the different data sources caching just to speed up",
    "start": "222480",
    "end": "229620"
  },
  {
    "text": "performance of different queries and then finally API so for example Cube",
    "start": "229620",
    "end": "234840"
  },
  {
    "text": "supports rest API graphql API which can be used to embed for like embedded analytics or front-end applications and",
    "start": "234840",
    "end": "240900"
  },
  {
    "text": "then we have a SQL endpoint which can be used for pi tool or like AI agents and",
    "start": "240900",
    "end": "246659"
  },
  {
    "text": "chat Bots so overall the data model and that's probably where uh we'll talk about the",
    "start": "246659",
    "end": "253200"
  },
  {
    "text": "biggest benefits and AI stack data model is a way to create a context and to be",
    "start": "253200",
    "end": "258660"
  },
  {
    "text": "able to provide later this context to the AI application and when I say",
    "start": "258660",
    "end": "264120"
  },
  {
    "text": "context it's a way to describe what you actually have in your data so think",
    "start": "264120",
    "end": "269639"
  },
  {
    "text": "about you have a lot of tables in your data warehouse in your database and but then you wanted to sort of give it",
    "start": "269639",
    "end": "275699"
  },
  {
    "text": "meaning give it a context like what is the data is about what like things what",
    "start": "275699",
    "end": "280919"
  },
  {
    "text": "a matrix does data have what a relationship between different entities so in Cube it all it's all about data",
    "start": "280919",
    "end": "288060"
  },
  {
    "text": "sets or entities and when you describe your data model you create what you call",
    "start": "288060",
    "end": "293340"
  },
  {
    "text": "a cube which sort of represents an entity like orders in e-commerce data like users and then you can say one user",
    "start": "293340",
    "end": "300720"
  },
  {
    "text": "can have multiple orders that's a relationship between them and then you can say orders may have like a metric",
    "start": "300720",
    "end": "307440"
  },
  {
    "text": "that would be called uh bounce like a cancellation rate right or something",
    "start": "307440",
    "end": "312540"
  },
  {
    "text": "like the amount like the percentage of orders had been canceled so you can kind of building with this uh approach uh",
    "start": "312540",
    "end": "320400"
  },
  {
    "text": "creating multiple measures multiple relationships and creating a data graph and then you can take the data graph and",
    "start": "320400",
    "end": "327360"
  },
  {
    "text": "expose it to the different tools including kind of AI applications and uh as you can see it's all like code",
    "start": "327360",
    "end": "335580"
  },
  {
    "text": "based so we it could we really big delivers in sort of a code first approach so everything is a code based",
    "start": "335580",
    "end": "341639"
  },
  {
    "text": "yaml we support python now as well so um and it's all open source so",
    "start": "341639",
    "end": "349259"
  },
  {
    "text": "um now probably I will talk a little bit about the why it matters for AI stack",
    "start": "349259",
    "end": "356520"
  },
  {
    "text": "I think one the problem that you know like we need to always kind of",
    "start": "356520",
    "end": "362220"
  },
  {
    "text": "keep in mind when building tags to SQL application is that we need to make sure that we provide enough context to the uh",
    "start": "362220",
    "end": "370500"
  },
  {
    "text": "llm that they can generate the correct SQL queries but we also need to be able",
    "start": "370500",
    "end": "376800"
  },
  {
    "text": "to reduce the room for error meaning that the simpler query should be it's it",
    "start": "376800",
    "end": "383639"
  },
  {
    "text": "means a less error prompt system is right like if you would require you know like to for the simple answer to get a",
    "start": "383639",
    "end": "390840"
  },
  {
    "text": "bunch of different joins you know like know how to avoid fat Fan outs and traps",
    "start": "390840",
    "end": "396240"
  },
  {
    "text": "right like then it would be really hard for the llm system to generate very correct SQL for that but if it's a SQL",
    "start": "396240",
    "end": "402780"
  },
  {
    "text": "is going to be simple it means it just it's going to be more correct so that's",
    "start": "402780",
    "end": "408479"
  },
  {
    "text": "where like two areas where like semanticleer can help so the first area is that semantic layer",
    "start": "408479",
    "end": "414840"
  },
  {
    "text": "can give that context to the llm system and the way we can do that is by uh kind",
    "start": "414840",
    "end": "424080"
  },
  {
    "text": "of go into the semantic layer and Cube specifically to The Meta endpoint downloading the data downloading all the",
    "start": "424080",
    "end": "431340"
  },
  {
    "text": "description that I showed you you can Define in a yaml code right like what this Matrix is about how this metrics is",
    "start": "431340",
    "end": "437580"
  },
  {
    "text": "connected to different metric to different dimensions what entities you have how this ended is connected to each",
    "start": "437580",
    "end": "443160"
  },
  {
    "text": "other so you can just dump all that information uh into into text and then put it into",
    "start": "443160",
    "end": "450000"
  },
  {
    "text": "your vector database right and then when you do a query right you can do in sort of in context learning",
    "start": "450000",
    "end": "457020"
  },
  {
    "text": "when you kind of send this query to llm and provide all the relevant contacts to them to the system to generate the",
    "start": "457020",
    "end": "464340"
  },
  {
    "text": "correct query on sort of a second uh part of the benefit is that now with",
    "start": "464340",
    "end": "472740"
  },
  {
    "text": "that you don't with this semantically or you don't have to query your Warehouse directly you can generate a SQL query",
    "start": "472740",
    "end": "479699"
  },
  {
    "text": "that will you will send to semanticleer and that SQL query is going to be much much more simpler uh just because it",
    "start": "479699",
    "end": "487740"
  },
  {
    "text": "doesn't need to know about all the hidden complexities different joints",
    "start": "487740",
    "end": "492860"
  },
  {
    "text": "metrics how they've been calculated all of this so the query to semantic layer may be as simple as",
    "start": "492860",
    "end": "500160"
  },
  {
    "text": "select you know like top most selling products and it could",
    "start": "500160",
    "end": "505560"
  },
  {
    "text": "be just two columns in a select statement and then an underlying SQL could be really",
    "start": "505560",
    "end": "512099"
  },
  {
    "text": "huge it's doing a lot of joints and all of that so that's kind of creates the",
    "start": "512099",
    "end": "517320"
  },
  {
    "text": "protection that in this case your system it doesn't need to know and it doesn't",
    "start": "517320",
    "end": "524039"
  },
  {
    "text": "need to create all this like complex the quality and Cube itself it's it's it's sharp to",
    "start": "524039",
    "end": "532260"
  },
  {
    "text": "create that complicated SQL and then to satisfy that result so that is a high level overview of how",
    "start": "532260",
    "end": "539519"
  },
  {
    "text": "semanticleer can uh can add value to the AI based tag and then we have I have a",
    "start": "539519",
    "end": "545160"
  },
  {
    "text": "quick question actually uh before you move on so for uh when you say kind of like read the semantic layer definitions",
    "start": "545160",
    "end": "550980"
  },
  {
    "text": "for context like the you know he was around before llms people were writing this before LMS were",
    "start": "550980",
    "end": "558180"
  },
  {
    "text": "interacting with it have you noticed like any like are the definitions the way that people write that like the",
    "start": "558180",
    "end": "564899"
  },
  {
    "text": "descriptions and so forth do those generally translate pretty nicely to having llms interact with them",
    "start": "564899",
    "end": "570839"
  },
  {
    "text": "um or or are there are there are you seeing people kind of like change them in some way so that llms can better kind",
    "start": "570839",
    "end": "576420"
  },
  {
    "text": "of like query them uh I don't think people change them",
    "start": "576420",
    "end": "582660"
  },
  {
    "text": "um I think it's a role would be a really good question to David also because I think I know I'm sure you you saw it a",
    "start": "582660",
    "end": "587940"
  },
  {
    "text": "lot but I feel like if you give a human readable um description to your metric and dimension and that's sort of considered",
    "start": "587940",
    "end": "593940"
  },
  {
    "text": "a best practice in the data World anyway you wanted to create a catalog you wanted to expose this data to you know",
    "start": "593940",
    "end": "599339"
  },
  {
    "text": "like your people in a company to employees so they understand it so you try to give it really good human",
    "start": "599339",
    "end": "604800"
  },
  {
    "text": "readable name and then it's actually really good for llm as well so you can",
    "start": "604800",
    "end": "609899"
  },
  {
    "text": "just take it and give it to LM so it's not like you need to create something specific here so I haven't seen people",
    "start": "609899",
    "end": "616019"
  },
  {
    "text": "doing anything specific here but you know like maybe in some cases you would need to fine tune but overall it just",
    "start": "616019",
    "end": "622320"
  },
  {
    "text": "translates very well perfect cool um",
    "start": "622320",
    "end": "627839"
  },
  {
    "text": "yeah probably you know like I have really only one slide here just a link to them if anyone wants to try it's a",
    "start": "627839",
    "end": "633959"
  },
  {
    "text": "stream lead app that built with lamp chain and Cube and um",
    "start": "633959",
    "end": "639000"
  },
  {
    "text": "and sort of it's hosted on GitHub so it's open source like 100 lines of code uh but I think that's it from my end so",
    "start": "639000",
    "end": "646920"
  },
  {
    "text": "and I will just stop sharing now",
    "start": "646920",
    "end": "650839"
  },
  {
    "text": "full awesome and and I guess like uh one more question again maybe this is maybe",
    "start": "654000",
    "end": "659040"
  },
  {
    "text": "this is better aimed at like David so so I asked before about if people are writing descriptions for",
    "start": "659040",
    "end": "664800"
  },
  {
    "text": "um kind of like uh uh so that albums can better understand the context are people doing the",
    "start": "664800",
    "end": "671519"
  },
  {
    "text": "opposite and creating like different kind of like views or data models uh specifically for some of these llm",
    "start": "671519",
    "end": "677160"
  },
  {
    "text": "applications like are the element applications that are like chat over your data do they require kind of like",
    "start": "677160",
    "end": "682440"
  },
  {
    "text": "different queries than queries that people were were doing previously",
    "start": "682440",
    "end": "688260"
  },
  {
    "text": "I'd say not really um the thing that our team described where if you make your semantic layer as",
    "start": "688260",
    "end": "695820"
  },
  {
    "text": "you know clean and well described and less cluttered as possible it I mean the",
    "start": "695820",
    "end": "703920"
  },
  {
    "text": "way I describe it is if you made your semantic layer such that another industry expert who worked like a",
    "start": "703920",
    "end": "709620"
  },
  {
    "text": "competitor could come and look at it and understand exactly what it means that's",
    "start": "709620",
    "end": "715140"
  },
  {
    "text": "the best way you could prepare it for an llm because an LM is kind of like an expert in all Industries right but",
    "start": "715140",
    "end": "723360"
  },
  {
    "text": "um yeah it's interesting as well the the idea of whether semantic glare was made for a chat but I mean I guess Cube's",
    "start": "723360",
    "end": "729360"
  },
  {
    "text": "Heritage with sat spot kind of makes it as if it was but um yeah that's interesting",
    "start": "729360",
    "end": "738320"
  },
  {
    "text": "very cool um David do you want to jump into your presentation yeah",
    "start": "740040",
    "end": "746060"
  },
  {
    "text": "and reminder for people that if they have questions um throughout these we're going to take a bunch of questions for everyone at the",
    "start": "748560",
    "end": "754980"
  },
  {
    "text": "end so throw them in the in the question chat on the right",
    "start": "754980",
    "end": "760339"
  },
  {
    "text": "okay I think everyone can see that yep so I think a good starting point is",
    "start": "760920",
    "end": "767040"
  },
  {
    "text": "what is stealthy and I think you know giving away so new I think it's probably worth going into like who who is",
    "start": "767040",
    "end": "772860"
  },
  {
    "text": "stealthy as well so Michael and I are the co-founders of Delphi uh we've both worked across",
    "start": "772860",
    "end": "780660"
  },
  {
    "text": "different data teams um leading uh data teams using semantic",
    "start": "780660",
    "end": "786480"
  },
  {
    "text": "ways in the form of looker as well we've both been part of the DBT Community which is how we met",
    "start": "786480",
    "end": "793160"
  },
  {
    "text": "uh and Michael also has uh lead data teams using uh self-serve bi tools like",
    "start": "793160",
    "end": "799860"
  },
  {
    "text": "leopard as well and one of the things that we both saw was that data teams",
    "start": "799860",
    "end": "806100"
  },
  {
    "text": "still really struggle with self-service um we found even with something like",
    "start": "806100",
    "end": "813060"
  },
  {
    "text": "looker which gives you like appointment click interface it's still really really difficult for uh stakeholders to",
    "start": "813060",
    "end": "821100"
  },
  {
    "text": "self-serve and you have uh a huge amount of work that comes to Us ad hoc and many stakeholders don't",
    "start": "821100",
    "end": "828959"
  },
  {
    "text": "have the skill they don't have the quantitative mindset or the will all the time to use them so they've reached out to people like Michael and I instead",
    "start": "828959",
    "end": "837920"
  },
  {
    "text": "and you know this results in a two-sided problem data teams who feel harassed and",
    "start": "838760",
    "end": "844380"
  },
  {
    "text": "unable to do what they really want to do whether that's deeper answering deeper questions or",
    "start": "844380",
    "end": "851420"
  },
  {
    "text": "in investing in their infrastructure to also better better answer questions in",
    "start": "851420",
    "end": "856920"
  },
  {
    "text": "the future and stakeholders have to wait a really long time sometimes they wouldn't get answers at all if what they asked for",
    "start": "856920",
    "end": "863100"
  },
  {
    "text": "wasn't aligned with their okrs and you know generally speaking both",
    "start": "863100",
    "end": "868980"
  },
  {
    "text": "sides were unhappy and are still unhappy if you speak to a lot of these teams uh",
    "start": "868980",
    "end": "874019"
  },
  {
    "text": "with what with the way things are and you know invariably because of how",
    "start": "874019",
    "end": "879540"
  },
  {
    "text": "difficult it is to find things you end up with this dashboard bloke in something like liquor because when",
    "start": "879540",
    "end": "884639"
  },
  {
    "text": "people can't find things they just recreate them to Delphi what we're trying to build up",
    "start": "884639",
    "end": "890579"
  },
  {
    "text": "here is an AI powered data platform specifically for non-technical users",
    "start": "890579",
    "end": "897060"
  },
  {
    "text": "so what we're trying to do is to use AI to answer simple for moderate complexity",
    "start": "897060",
    "end": "903480"
  },
  {
    "text": "data questions you know that quick data pool quick answers for and you know these actually make up the majority of",
    "start": "903480",
    "end": "910320"
  },
  {
    "text": "data requests today from our experience and so we aim to quickly and easily and",
    "start": "910320",
    "end": "917100"
  },
  {
    "text": "most importantly safely answer these questions and you know we want to augment data teams and build on the work",
    "start": "917100",
    "end": "923220"
  },
  {
    "text": "they've already done and not pretend we could replace them and this is why we want to integrate with semantic",
    "start": "923220",
    "end": "929339"
  },
  {
    "text": "layers and you know you've probably seen many tools out there which try and solve the",
    "start": "929339",
    "end": "936720"
  },
  {
    "text": "same problem that we do many of them are using an approach that I describe as",
    "start": "936720",
    "end": "941760"
  },
  {
    "text": "text to SQL and this is where an llm is used to",
    "start": "941760",
    "end": "946980"
  },
  {
    "text": "generate SQL directly from a database schema and essentially here the llm is",
    "start": "946980",
    "end": "952560"
  },
  {
    "text": "generating a semantic layer on the Fly for each request and so what it's doing is it's",
    "start": "952560",
    "end": "959100"
  },
  {
    "text": "interpreting the meaning of the data and how it fits together with little to no human intervention",
    "start": "959100",
    "end": "964560"
  },
  {
    "text": "and it's our opinion that this is not going to work for Enterprise bi and",
    "start": "964560",
    "end": "969779"
  },
  {
    "text": "analytics use cases and the data teams and stakeholders need to govern what that data means and this",
    "start": "969779",
    "end": "976560"
  },
  {
    "text": "should not really change very often and be consistent from request to request",
    "start": "976560",
    "end": "981779"
  },
  {
    "text": "and this is why we started with semantic ways from the very outset so from the first prototype that Michael built we've",
    "start": "981779",
    "end": "988560"
  },
  {
    "text": "always built on top of semantic ways we generate semantic API requests using our",
    "start": "988560",
    "end": "994260"
  },
  {
    "text": "prompt engineering and for our semantic layers are aware the meaning of denature is defined and",
    "start": "994260",
    "end": "1000380"
  },
  {
    "text": "governed by their data teams and so for us llms are the other piece of the solution with semantic layers to",
    "start": "1000380",
    "end": "1008420"
  },
  {
    "text": "enable self-service with data so with Delphi stakeholders can answer questions and natural language as if",
    "start": "1008420",
    "end": "1015860"
  },
  {
    "text": "they are talking to an analysts you can just ask the offense of asking David ping Delphi on slack instead of David",
    "start": "1015860",
    "end": "1021519"
  },
  {
    "text": "and get a safe response and the other thing that we find really",
    "start": "1021519",
    "end": "1028579"
  },
  {
    "text": "helpful is that data teams can really understand quickly and easily what Delphi has generated because we don't",
    "start": "1028579",
    "end": "1035000"
  },
  {
    "text": "generate SQL because the semantic way is not being generated on the Fly you can",
    "start": "1035000",
    "end": "1041058"
  },
  {
    "text": "just see a simple semantic API request much like a cube rested API request",
    "start": "1041059",
    "end": "1046660"
  },
  {
    "text": "validated that it's answering the question that's like a 10 second job versus trying to uh validate some",
    "start": "1046660",
    "end": "1054380"
  },
  {
    "text": "machine generated SQL which could take a lot longer and to be honest if it was me I would just Chuck it and write my own",
    "start": "1054380",
    "end": "1061220"
  },
  {
    "text": "SQL and I think most analysts will probably do that so therefore use Lang chain",
    "start": "1061220",
    "end": "1067640"
  },
  {
    "text": "Bank chain provides a unified interface for every lln provider we might want to",
    "start": "1067640",
    "end": "1072740"
  },
  {
    "text": "work with and we work with anthropic open Ai gcp and we have some",
    "start": "1072740",
    "end": "1079580"
  },
  {
    "text": "open source hosted ones as well and the reason why this is really helpful for us is we work in an",
    "start": "1079580",
    "end": "1086900"
  },
  {
    "text": "Enterprise setting where our customers might be particular about which llm we use and then we don't have to do extra",
    "start": "1086900",
    "end": "1093260"
  },
  {
    "text": "work to support this every time we want to change which element we're using",
    "start": "1093260",
    "end": "1098419"
  },
  {
    "text": "and Manchester has a really helpful lot of abstractions over the language models training memory prompt Edition over",
    "start": "1098419",
    "end": "1105200"
  },
  {
    "text": "thread to DB Integrations so we can use language chain to do like various operations",
    "start": "1105200",
    "end": "1112539"
  },
  {
    "text": "that's yeah that's what I have to say uh any questions",
    "start": "1112940",
    "end": "1118779"
  },
  {
    "text": "um so I I have one kind of about the types of questions that you see people asking and I think previously you",
    "start": "1120980",
    "end": "1127280"
  },
  {
    "text": "described it as kind of like uh easy to medium kind of like difficulty questions yeah what exactly does that mean and",
    "start": "1127280",
    "end": "1136340"
  },
  {
    "text": "like if it is a hard level question like what do you do then so like with a hard level question I",
    "start": "1136340",
    "end": "1143179"
  },
  {
    "text": "don't expect that an Owen would be able to answer it today or even in the in the near term",
    "start": "1143179",
    "end": "1148880"
  },
  {
    "text": "so I'm talking when I say a hard level question is like typically like strategic questions so for example when",
    "start": "1148880",
    "end": "1155240"
  },
  {
    "text": "I worked at list we had different products that we would merge to show people like the best price for the same",
    "start": "1155240",
    "end": "1161120"
  },
  {
    "text": "products in different retailers and like one of the deeper questions that we answer as a dating is should we should",
    "start": "1161120",
    "end": "1167600"
  },
  {
    "text": "we continue to merge products is this a good idea for our business like that is such a complicated",
    "start": "1167600",
    "end": "1173360"
  },
  {
    "text": "question to answer and how like it has so many different steps and waiting and it's just not something that you know",
    "start": "1173360",
    "end": "1180500"
  },
  {
    "text": "something like Delphi could ever really uh answer well at least at this level of",
    "start": "1180500",
    "end": "1185539"
  },
  {
    "text": "Technology and so that's what I mean by a hard question and that's where I think you still need a data team you still need",
    "start": "1185539",
    "end": "1191720"
  },
  {
    "text": "those senior analysts who are that consultative partner to your business and and what we really hope is that with",
    "start": "1191720",
    "end": "1198080"
  },
  {
    "text": "Delphi in place that those people have more time to do that working on just being like shoulder tapped or pinged on",
    "start": "1198080",
    "end": "1204140"
  },
  {
    "text": "slack all the time for small things do you do you do anything in in the Delphi um bot to basically if someone",
    "start": "1204140",
    "end": "1211460"
  },
  {
    "text": "asks a question like that do you say like hey you know we can't really answer that or what happens if I if I were to",
    "start": "1211460",
    "end": "1218059"
  },
  {
    "text": "ask if the Delphi bought that yeah absolutely he says uh what would happen today is uh Delphi would probably say uh",
    "start": "1218059",
    "end": "1226039"
  },
  {
    "text": "I don't I'm not sure how to answer this question uh and then we have a configuration and when when you set up",
    "start": "1226039",
    "end": "1231860"
  },
  {
    "text": "our app that lets you choose like a help Channel or a help person and that's usually like the data team Channel or",
    "start": "1231860",
    "end": "1237679"
  },
  {
    "text": "something like that and then the and that they'll be alerted to the fact that",
    "start": "1237679",
    "end": "1243620"
  },
  {
    "text": "this question has been asked and they can either help they'll be come to a better answer through wording the",
    "start": "1243620",
    "end": "1249260"
  },
  {
    "text": "question differently or they'll just take it away and answer it in something else like hex or count or something like",
    "start": "1249260",
    "end": "1254299"
  },
  {
    "text": "that very cool yeah I like I like the idea of like human in the loop as a way to",
    "start": "1254299",
    "end": "1259460"
  },
  {
    "text": "augment 100 yeah yeah do you do that like another another way that we've thought about this in a little bit for",
    "start": "1259460",
    "end": "1266059"
  },
  {
    "text": "like chat so we have like chat Link channel which is a chatbot over our documentation and one of the things that we want to do more of is like figure out",
    "start": "1266059",
    "end": "1273440"
  },
  {
    "text": "um what types of questions people are asking so then we can like improve documentation there or something do you",
    "start": "1273440",
    "end": "1279799"
  },
  {
    "text": "have any type of like analytics to provide like what types of queries people are asking so that you can I I",
    "start": "1279799",
    "end": "1285260"
  },
  {
    "text": "don't know what the action item would be so maybe it's not a perfect parallel but I'm curious if there's anything yeah so",
    "start": "1285260",
    "end": "1290900"
  },
  {
    "text": "this is a question we've been asked a few times and we actually have the data to the metadata rather to do it it's",
    "start": "1290900",
    "end": "1297200"
  },
  {
    "text": "just a question of we're trying to figure out like the design of how we should build this and that's something we're working with our design Partners",
    "start": "1297200",
    "end": "1303440"
  },
  {
    "text": "on but essentially yes so it's typically it's where people are asking questions which are at the right kind of level of",
    "start": "1303440",
    "end": "1309620"
  },
  {
    "text": "complexity for Dobby to answer them but the semantic layer just doesn't contain anything relevant to those questions and",
    "start": "1309620",
    "end": "1316159"
  },
  {
    "text": "so what will happen is the date stream will see that oh this is how these questions are being asked but they know",
    "start": "1316159",
    "end": "1321500"
  },
  {
    "text": "Delphi shouldn't answer it because they haven't exposed anything to Delphi that could be used to answer it so what we",
    "start": "1321500",
    "end": "1327260"
  },
  {
    "text": "want to show them is like oh here's this term and maybe it's like um basket conversion and like we've not",
    "start": "1327260",
    "end": "1333980"
  },
  {
    "text": "made anything in the semantic way to evaluate basket conversion uh and it's like it's almost like this is like how",
    "start": "1333980",
    "end": "1340340"
  },
  {
    "text": "we could improve our product because this is something that's being asked for that's not you know if you think about",
    "start": "1340340",
    "end": "1345440"
  },
  {
    "text": "the data as a product inside an organization it's like this is a good way to improve the product",
    "start": "1345440",
    "end": "1351400"
  },
  {
    "text": "yeah that's that's a cool way of looking at it and and how does Delphi handle",
    "start": "1351400",
    "end": "1356480"
  },
  {
    "text": "those questions right now like is it pretty good at saying like oh there's not appropriate data to answer or will",
    "start": "1356480",
    "end": "1362000"
  },
  {
    "text": "it kind of like hallucinate some stuff and if it's good how did you how did you make it good at kind of like staying on",
    "start": "1362000",
    "end": "1368299"
  },
  {
    "text": "track and yeah this is the thing it's it it's it's required a lot of a lot of",
    "start": "1368299",
    "end": "1374299"
  },
  {
    "text": "what's actually feeling more like normal engineering to get used to work to work well",
    "start": "1374299",
    "end": "1379760"
  },
  {
    "text": "um so yeah we've got many many steps in our flow where you know we index the",
    "start": "1379760",
    "end": "1384860"
  },
  {
    "text": "whole catalog from something like you and then we use thing methods like",
    "start": "1384860",
    "end": "1390320"
  },
  {
    "text": "vector similarity to the question to see if there are actual relevant terms uh",
    "start": "1390320",
    "end": "1396440"
  },
  {
    "text": "that are relevant to the question if we can't find anything that's within a certain threshold we will say at that",
    "start": "1396440",
    "end": "1403100"
  },
  {
    "text": "point we don't think we've got anything speak to your data team um if we do have them and we do still",
    "start": "1403100",
    "end": "1410659"
  },
  {
    "text": "explain what we're doing to the user unit we'll say we're going to pull this um they can see the summary of what",
    "start": "1410659",
    "end": "1416600"
  },
  {
    "text": "we're actually generating and it's it's readable in natural language and they can say well this is still uh",
    "start": "1416600",
    "end": "1423380"
  },
  {
    "text": "not what I want and so because we're opening up the box I feel like delphi's",
    "start": "1423380",
    "end": "1429200"
  },
  {
    "text": "not hallucinating it's much more like an experience where you're talking to an analyst and this is trying to kind of guess what you want well not even guess",
    "start": "1429200",
    "end": "1435980"
  },
  {
    "text": "but derive what you want from the data they know about",
    "start": "1435980",
    "end": "1440679"
  },
  {
    "text": "very cool um all right Francisco Manuel do you guys want to cap",
    "start": "1442700",
    "end": "1450080"
  },
  {
    "text": "it off in terms of presentations and then we can go to a more panel discussion absolutely absolutely so we're just",
    "start": "1450080",
    "end": "1457520"
  },
  {
    "text": "going to present um some corporations with actually library that are in the same line of",
    "start": "1457520",
    "end": "1464200"
  },
  {
    "text": "using semantic search and adding Dynamic pieces to the prompt to improve either",
    "start": "1464200",
    "end": "1471140"
  },
  {
    "text": "accuracy or cost we see a great opportunity in in llm to SQL solutions",
    "start": "1471140",
    "end": "1477980"
  },
  {
    "text": "to include domain specific knowledge when the from when the users already",
    "start": "1477980",
    "end": "1483080"
  },
  {
    "text": "send the question and using that question to incorporate different pieces of knowledge that might be relevant for",
    "start": "1483080",
    "end": "1488419"
  },
  {
    "text": "the agent either to make a better query and get the correct result or make a",
    "start": "1488419",
    "end": "1493940"
  },
  {
    "text": "more efficient thinking process as practitioners with this um with these",
    "start": "1493940",
    "end": "1499340"
  },
  {
    "text": "types of solutions many times we see that the chain of the agent is trying to",
    "start": "1499340",
    "end": "1504860"
  },
  {
    "text": "get to the right answer maybe it gets the right answer but it takes a few tries and it's very very consumptive in",
    "start": "1504860",
    "end": "1510860"
  },
  {
    "text": "terms of tokens and time and we would like to try to avoid that as much as possible and having a straightforward",
    "start": "1510860",
    "end": "1517280"
  },
  {
    "text": "Builder queries and did work well and return right now the the Baseline",
    "start": "1517280",
    "end": "1523220"
  },
  {
    "text": "solution is just sending all the table schema with sample rows to the agent and",
    "start": "1523220",
    "end": "1528559"
  },
  {
    "text": "then also to a chain and using that to build a correct query but in some ways",
    "start": "1528559",
    "end": "1533779"
  },
  {
    "text": "you can be smarter than that and there a few things that we added to the library right now it's already been released",
    "start": "1533779",
    "end": "1540380"
  },
  {
    "text": "that we would like to to share there's also other things that can be done we think that is a very fair type field to",
    "start": "1540380",
    "end": "1546980"
  },
  {
    "text": "explore on how domain experts can add their knowledge so that the problem gets built in a way that is really really",
    "start": "1546980",
    "end": "1553279"
  },
  {
    "text": "clear and explicit to the to the model but this is a a way to start so",
    "start": "1553279",
    "end": "1558820"
  },
  {
    "text": "and take it from there probably yep I will I'll present a very short",
    "start": "1558820",
    "end": "1565520"
  },
  {
    "text": "notebook um on on these two custom tools that we have we have built all of this we'll",
    "start": "1565520",
    "end": "1572360"
  },
  {
    "text": "show this notebook together with uh with the recording um and also this is uh in a blog post that we wrote together with the",
    "start": "1572360",
    "end": "1578360"
  },
  {
    "text": "launching team and it's also in the SQL documentation for blockchain so you'll probably find it there as well mostly",
    "start": "1578360",
    "end": "1584299"
  },
  {
    "text": "the the clicks on how to or how to build these custom tools I'll focus more on the results right so I'm using the",
    "start": "1584299",
    "end": "1591380"
  },
  {
    "text": "genome database for for an example um this is a question that can be answered using the standard SQL agents",
    "start": "1591380",
    "end": "1598279"
  },
  {
    "text": "and we'll we'll show how these two tools which are versatile that will get",
    "start": "1598279",
    "end": "1603860"
  },
  {
    "text": "similar examples um so matches of user question two SQL queries that we know that work",
    "start": "1603860",
    "end": "1610760"
  },
  {
    "text": "um first that tool and also a tool that checks the spelling of proper nouns so",
    "start": "1610760",
    "end": "1616220"
  },
  {
    "text": "how these two custom tools uh improve the age the agent the world performance and and accuracy right so just to",
    "start": "1616220",
    "end": "1624740"
  },
  {
    "text": "Showcase a question that can be answered with a standard SQL agent um we can see here like what is the what",
    "start": "1624740",
    "end": "1631640"
  },
  {
    "text": "is the the chain right first or the other process first using the SQL get similar examples too which",
    "start": "1631640",
    "end": "1638720"
  },
  {
    "text": "is a retriever tool that gets as I said similar examples to the question that",
    "start": "1638720",
    "end": "1643880"
  },
  {
    "text": "the user asks so how many players do we have in the database it will bring uh using the retriever it will bring how",
    "start": "1643880",
    "end": "1650120"
  },
  {
    "text": "many players are there with its corresponding SQL query and find the total number of invoices",
    "start": "1650120",
    "end": "1656240"
  },
  {
    "text": "just because the database the the fusion database was stored so it's relevant but",
    "start": "1656240",
    "end": "1661580"
  },
  {
    "text": "not not similar enough with the corresponding SQL query and the agent will choose okay I don't need to use all",
    "start": "1661580",
    "end": "1668480"
  },
  {
    "text": "like this agent also has the standard SQL toolkit but it decides not to use it",
    "start": "1668480",
    "end": "1673760"
  },
  {
    "text": "because okay I already have in the few shots an example that is similar enough so I'll just use the that query run it",
    "start": "1673760",
    "end": "1682220"
  },
  {
    "text": "and it took 13 seconds to do the whole process and",
    "start": "1682220",
    "end": "1688720"
  },
  {
    "text": "3391 tokens which write the same example with a standard SQL agent with the standard SQL",
    "start": "1688720",
    "end": "1696200"
  },
  {
    "text": "toolkit and everything we see like the usual workflow that uh anyone who has tried their agent has",
    "start": "1696200",
    "end": "1702500"
  },
  {
    "text": "seen before which is first listing the tables then querying for the schema for the employee table uh getting the summer",
    "start": "1702500",
    "end": "1709640"
  },
  {
    "text": "rows checking the syntax I'm running the query right and this spans",
    "start": "1709640",
    "end": "1715760"
  },
  {
    "text": "um a 60 increase in in time so actually the other the other agent is uh around",
    "start": "1715760",
    "end": "1721640"
  },
  {
    "text": "40 uh the design at the than the standard agents and it also spends much",
    "start": "1721640",
    "end": "1727700"
  },
  {
    "text": "more token so it is more inefficient both in in terms of time and in terms of of tokens and cost right which is um two",
    "start": "1727700",
    "end": "1735620"
  },
  {
    "text": "things that we want to to clearly uh improve in the in the SQL Solutions",
    "start": "1735620",
    "end": "1741380"
  },
  {
    "text": "and then there's another example which is for spelling mistakes right so hard how many albums did Alice in Keynes",
    "start": "1741380",
    "end": "1747919"
  },
  {
    "text": "instead of Alice in Chains with the real artist name uh how many albums did Alice in Kane's",
    "start": "1747919",
    "end": "1754640"
  },
  {
    "text": "record um and again using the custom agent we we use first they get similar examples",
    "start": "1754640",
    "end": "1760279"
  },
  {
    "text": "tool where we have for example Aerosmith which is um which is many uh maybe a similar example",
    "start": "1760279",
    "end": "1768260"
  },
  {
    "text": "how many albums from Aerosmith and then we have the other tool which checks the checks the spelling right so we have",
    "start": "1768260",
    "end": "1774980"
  },
  {
    "text": "from Madison Keynes it retrieved the the most similar artists which are Alice in",
    "start": "1774980",
    "end": "1780799"
  },
  {
    "text": "Chains and Alicia Lua so in this way the agent is able to correct the spelling mistake from the from the question from",
    "start": "1780799",
    "end": "1787159"
  },
  {
    "text": "the user and that is I mean that is key for filtering a column right in this case the artist's name so it could get",
    "start": "1787159",
    "end": "1794659"
  },
  {
    "text": "the right answer which is one album um and just to contrast the standard SQL agent which has the tools that we",
    "start": "1794659",
    "end": "1801020"
  },
  {
    "text": "already discussed won't be able to get the right answer because it doesn't spot the the spelling mistake so it uses the",
    "start": "1801020",
    "end": "1808039"
  },
  {
    "text": "first tool the second tool Etc um the query Checker and when it runs",
    "start": "1808039",
    "end": "1813380"
  },
  {
    "text": "the query is try to filter based on Alison gains which of course is not the right the right name so",
    "start": "1813380",
    "end": "1820520"
  },
  {
    "text": "um it doesn't get the right it gets like the wrong answer even like being much slower and spending a similar",
    "start": "1820520",
    "end": "1827419"
  },
  {
    "text": "amount of tokens so these are two examples of how including domain specific knowledge",
    "start": "1827419",
    "end": "1832580"
  },
  {
    "text": "enough in forms of custom tools which can now be appended to the to the SQL agent",
    "start": "1832580",
    "end": "1837860"
  },
  {
    "text": "um how including this domain specific knowledge increases accuracy and reduces time and and tokens right",
    "start": "1837860",
    "end": "1845120"
  },
  {
    "text": "so it's really powerful for for improving from from for improving the the standard SQL agents",
    "start": "1845120",
    "end": "1852940"
  },
  {
    "text": "still open to questions of course if you if you have any awesome yeah I mean so I",
    "start": "1853760",
    "end": "1859460"
  },
  {
    "text": "think I mean I think there's two really cool insights here the the few shot examples and then kind of like the the",
    "start": "1859460",
    "end": "1865100"
  },
  {
    "text": "the the vector store retrieval high cardinality so maybe those are good places to start just like a general",
    "start": "1865100",
    "end": "1870799"
  },
  {
    "text": "um panel discussion and then kind of like open it up from there um so uh I guess first on the topic of",
    "start": "1870799",
    "end": "1877880"
  },
  {
    "text": "kind of like few shot examples um you know I think the implementation in the agent had a tool which could",
    "start": "1877880",
    "end": "1883520"
  },
  {
    "text": "fetch relevant ones there's also like maybe something else where you do that automatically and you automatically select them and so I guess my question",
    "start": "1883520",
    "end": "1890360"
  },
  {
    "text": "for you Manuel and Francisco would probably be like what are the trade-offs there and then my question for uh David",
    "start": "1890360",
    "end": "1896120"
  },
  {
    "text": "and Arkham have you guys seen kind of like few shot examples being used",
    "start": "1896120",
    "end": "1901159"
  },
  {
    "text": "um efficiently effectively when you have the semantic layer as well and maybe we can start with Manuel and Francisco and",
    "start": "1901159",
    "end": "1907279"
  },
  {
    "text": "then go on from there foreign I think just including a future examples",
    "start": "1907279",
    "end": "1916340"
  },
  {
    "text": "automatically would work what we're doing now is like indicating to agent to always use it so it's kind of the same",
    "start": "1916340",
    "end": "1922220"
  },
  {
    "text": "thing um because the tool framework is quite flexible so we just include it there but",
    "start": "1922220",
    "end": "1927799"
  },
  {
    "text": "I think it is a good idea of always having a future a few future examples since it's not you should it's not very",
    "start": "1927799",
    "end": "1934580"
  },
  {
    "text": "token consultant it's quite hard to know like that's in some specific case it",
    "start": "1934580",
    "end": "1940039"
  },
  {
    "text": "will be useful or not you just need to see and and the agent can always ignore them if",
    "start": "1940039",
    "end": "1945559"
  },
  {
    "text": "it feels that you know it's not important enough or related enough so I think it can be done automatically",
    "start": "1945559",
    "end": "1952940"
  },
  {
    "text": "as well and David have have you guys seen kind",
    "start": "1952940",
    "end": "1958640"
  },
  {
    "text": "of like a few shot examples be helpful have you explored those at all or or not",
    "start": "1958640",
    "end": "1963679"
  },
  {
    "text": "yet no we haven't we haven't looked at them yet and you know and we also haven't got",
    "start": "1963679",
    "end": "1970700"
  },
  {
    "text": "to a point where we've explored fine-tuning either we've generally been using the models as is uh yeah",
    "start": "1970700",
    "end": "1978799"
  },
  {
    "text": "yeah actually maybe that's another question for you for you guys Manuel and Francisco have you looked at fine-tuning",
    "start": "1978799",
    "end": "1984440"
  },
  {
    "text": "at all do you think fine tuning would help here is this one of the situations where it would be good",
    "start": "1984440",
    "end": "1990398"
  },
  {
    "text": "yeah yeah yeah yeah yeah we have uh Explorer fine tuning uh using the gbtv",
    "start": "1993080",
    "end": "1999019"
  },
  {
    "text": "3.5 and it's it's an interesting um field and and there's there's some",
    "start": "1999019",
    "end": "2004720"
  },
  {
    "text": "research around it so it's it seems to be um very good but",
    "start": "2004720",
    "end": "2011380"
  },
  {
    "text": "it's it's for for future using future examples dynamically you can get like 30 40 uh",
    "start": "2011380",
    "end": "2019000"
  },
  {
    "text": "good examples and include them and you can you can play around with with more things for example",
    "start": "2019000",
    "end": "2024880"
  },
  {
    "text": "you can do like um a first holding with a score so similarity score in the in this example",
    "start": "2024880",
    "end": "2030460"
  },
  {
    "text": "we're just including the top two examples right or top three examples but you can do something like",
    "start": "2030460",
    "end": "2035740"
  },
  {
    "text": "um okay if I don't find any relevant examples based on a threshold I just don't include them or if I find highly",
    "start": "2035740",
    "end": "2041740"
  },
  {
    "text": "relevant examples which would be like the example that I showed in Notebook um I just I just cut the the whole let's",
    "start": "2041740",
    "end": "2049179"
  },
  {
    "text": "say sort of token inefficient prompt of having the all of the tools that we have and just saying okay using a using a",
    "start": "2049179",
    "end": "2056320"
  },
  {
    "text": "like a like a simple prompt which is I have this query and I have this user question on this query I just want to",
    "start": "2056320",
    "end": "2062679"
  },
  {
    "text": "adapt it to this other user question right because we know we have a very very close similarity so that sort of",
    "start": "2062679",
    "end": "2068560"
  },
  {
    "text": "playing along with us with the similarity score that we got from the from the retriever",
    "start": "2068560",
    "end": "2073898"
  },
  {
    "text": "um you have it with a few shots you don't have it with uh with the fine tuning that makes sense",
    "start": "2073899",
    "end": "2080080"
  },
  {
    "text": "myself I haven't tried fine tuning uh so I haven't measured the performance",
    "start": "2080080",
    "end": "2086398"
  },
  {
    "text": "accuracy but I think like um at recent Theory I would do both like",
    "start": "2086399",
    "end": "2092919"
  },
  {
    "text": "if I have a big enough data set I would fine tune and then like the future is much more complex specific so I maybe",
    "start": "2092919",
    "end": "2100540"
  },
  {
    "text": "you can't rely on the model having uh the examples you used in the training",
    "start": "2100540",
    "end": "2106119"
  },
  {
    "text": "set as in memory like remember them exactly so it probably helps across the",
    "start": "2106119",
    "end": "2111880"
  },
  {
    "text": "board to fine tune in terms of perfect in terms of accuracy but then again like if you have a very relevant example in",
    "start": "2111880",
    "end": "2118119"
  },
  {
    "text": "inference time it's probably a good idea to include it because it has it has it",
    "start": "2118119",
    "end": "2123280"
  },
  {
    "text": "like very fresh in the problem so I think they are not mutually exclusive I would definitely very interested in",
    "start": "2123280",
    "end": "2128859"
  },
  {
    "text": "seeing uh how much engineering improves accuracy um in a specific use case",
    "start": "2128859",
    "end": "2137020"
  },
  {
    "text": "I mean I guess this is there is one way in which we are using it which is kind",
    "start": "2137020",
    "end": "2142119"
  },
  {
    "text": "of organically through user feedback in our products so when Delphi gives an answer you can say whether it's good or",
    "start": "2142119",
    "end": "2149560"
  },
  {
    "text": "not with a thumbs up thumbs down and when Delphi does give an answer which is good",
    "start": "2149560",
    "end": "2155260"
  },
  {
    "text": "obviously that's then a prompt which to have a good which was a good answer that",
    "start": "2155260",
    "end": "2160900"
  },
  {
    "text": "you could then you know prompt an association with a question that you could then put in as a as in in that few",
    "start": "2160900",
    "end": "2167440"
  },
  {
    "text": "shot way and that's yeah that's that is one way in which we do improved office output",
    "start": "2167440",
    "end": "2173619"
  },
  {
    "text": "oh that's awesome okay so you have some type of like active feedback loop and when you say put back in where where do",
    "start": "2173619",
    "end": "2180579"
  },
  {
    "text": "you put that like is it where do you put that in basically do you is do you just have kind of like a section in the",
    "start": "2180579",
    "end": "2186460"
  },
  {
    "text": "prompt that's like here's some recent here's some similar examples or something like that or is it a",
    "start": "2186460",
    "end": "2191560"
  },
  {
    "text": "completely separate step in the chain where you first see if there's anything similar and then use that yeah it's more",
    "start": "2191560",
    "end": "2197200"
  },
  {
    "text": "like the latter really interesting very cool um in the second part of what you guys",
    "start": "2197200",
    "end": "2204640"
  },
  {
    "text": "talked about was around kind of like handling spelling errors which we can maybe generalize to like handling kind",
    "start": "2204640",
    "end": "2211119"
  },
  {
    "text": "of like high cardinality columns when you know like if if a column's like a Boolean it's really clear what the value",
    "start": "2211119",
    "end": "2217300"
  },
  {
    "text": "should be or something like that but when you have a column that's like a name um I mean this isn't even getting into",
    "start": "2217300",
    "end": "2223300"
  },
  {
    "text": "columns that are like all text values but let's just let's just stick with high cardinality finale you have a name",
    "start": "2223300",
    "end": "2228640"
  },
  {
    "text": "or some sort of a person of an object or something and if you want to like filter on that you need to like spell it",
    "start": "2228640",
    "end": "2234940"
  },
  {
    "text": "correctly and oftentimes users don't um and so how yeah I mean maybe starting",
    "start": "2234940",
    "end": "2241000"
  },
  {
    "text": "with uh RTM and David how do you guys think about that have you seen anyone do kind of like clever things there",
    "start": "2241000",
    "end": "2249700"
  },
  {
    "text": "I think I can start from you know like Cube as a magical error perspective is because we kind of provide that metadata",
    "start": "2249700",
    "end": "2257500"
  },
  {
    "text": "information so we want the consumers like Engineers who are building uh sort",
    "start": "2257500",
    "end": "2263920"
  },
  {
    "text": "of llm based solutions to get as much context as possible including the values of these Dimensions right like that can",
    "start": "2263920",
    "end": "2270220"
  },
  {
    "text": "be hyperdinality so we probably necessarily don't like deal with that but we're thinking about more like what",
    "start": "2270220",
    "end": "2276280"
  },
  {
    "text": "tools we need to provide for people to be able to fetch them I think the just a simple solution just to try to load all",
    "start": "2276280",
    "end": "2283060"
  },
  {
    "text": "the values you know they can kind of put them so that's what I see people doing right now we are trying and some we",
    "start": "2283060",
    "end": "2289180"
  },
  {
    "text": "actually spend some time with David recently talking about it what kind of additional tools we can kind of provide",
    "start": "2289180",
    "end": "2294280"
  },
  {
    "text": "to you know developers that can you know like make working with this High",
    "start": "2294280",
    "end": "2300220"
  },
  {
    "text": "cardinality Dimensions more efficient so one thing is that we can look at the query history and to see you know like",
    "start": "2300220",
    "end": "2305980"
  },
  {
    "text": "what are dimensions kind of you know like a being what values in these dimensions of being asked more",
    "start": "2305980",
    "end": "2312040"
  },
  {
    "text": "frequently right so that's one thing and then sort of we can use that knowledge for the context the other thing is that",
    "start": "2312040",
    "end": "2319119"
  },
  {
    "text": "Solutions like a semantic layer can index the values and to see what are the most popular values that are sort of",
    "start": "2319119",
    "end": "2325480"
  },
  {
    "text": "being more relevant and sort of the build a connection also between these values and provide that as a meta",
    "start": "2325480",
    "end": "2330579"
  },
  {
    "text": "endpoint so that's something we wanted to build at Cube sort of phenolic to kind of improve the the context that we",
    "start": "2330579",
    "end": "2336880"
  },
  {
    "text": "provide to llms so so not just return all values return the most popular ones what about ones",
    "start": "2336880",
    "end": "2343660"
  },
  {
    "text": "that are like what about the ones that are like similar to a query or something like that like is there any way to do that in",
    "start": "2343660",
    "end": "2350920"
  },
  {
    "text": "kind of like uh like like a a quick way or that doesn't that doesn't",
    "start": "2350920",
    "end": "2357220"
  },
  {
    "text": "add too much latency because like so for an example of a way that would add a lot of latency if you",
    "start": "2357220",
    "end": "2363099"
  },
  {
    "text": "you could like index all the values create a vector store you could then have an llm kind of like parse out like",
    "start": "2363099",
    "end": "2368560"
  },
  {
    "text": "oh I want to look up like the values most similar to like this person's name you know maybe that doesn't work great",
    "start": "2368560",
    "end": "2373599"
  },
  {
    "text": "for that person's name because it's based on semantic similarity but maybe you have some other thing but you know that involves a call to a language model",
    "start": "2373599",
    "end": "2380020"
  },
  {
    "text": "it's potentially long maybe that's fine maybe but then yeah like I you know then",
    "start": "2380020",
    "end": "2386140"
  },
  {
    "text": "you start getting going down the rabbit hole of what if I need to do this for two different columns and you kind of get so something that looks kind of like",
    "start": "2386140",
    "end": "2391900"
  },
  {
    "text": "the agent that Francisco and Manuel kind of like came up with basically where it's searching kind of like the vector store and doing that which is I think",
    "start": "2391900",
    "end": "2399400"
  },
  {
    "text": "yields pretty good results but it takes a lot of time so like is there a way to meet in the middle any anyway",
    "start": "2399400",
    "end": "2406619"
  },
  {
    "text": "uh uh yeah I think um and you know like I know that David is spending a lot of",
    "start": "2407020",
    "end": "2412420"
  },
  {
    "text": "time thinking about that problem but uh I think what Cube can do is uh we can",
    "start": "2412420",
    "end": "2419140"
  },
  {
    "text": "sort of provide like some API that can you know like the llm can query during",
    "start": "2419140",
    "end": "2425200"
  },
  {
    "text": "the query time to get some cached values that can be kind of close to that",
    "start": "2425200",
    "end": "2430660"
  },
  {
    "text": "specific Dimension because we would probably it would take a lot of",
    "start": "2430660",
    "end": "2436000"
  },
  {
    "text": "lead and stitches for us to go and to re-index everything again so if we would have something already cached we would",
    "start": "2436000",
    "end": "2442000"
  },
  {
    "text": "be able to quickly provide that but uh I think that's a sort of an only option",
    "start": "2442000",
    "end": "2447040"
  },
  {
    "text": "for the additional sort of semantics during the query time and then the rest should be sort of phenolic did as a",
    "start": "2447040",
    "end": "2453579"
  },
  {
    "text": "background job right like where you do have an indexing you're putting that in a vector store and like just kind of",
    "start": "2453579",
    "end": "2458680"
  },
  {
    "text": "dealing with that later but for like a quick inquiry context that's something that potentially we can provide on our",
    "start": "2458680",
    "end": "2465220"
  },
  {
    "text": "end but that's that's a really interesting problem to solve said like the things that are most",
    "start": "2465220",
    "end": "2472300"
  },
  {
    "text": "important there is like how you can't do it for everything for a specific column",
    "start": "2472300",
    "end": "2477820"
  },
  {
    "text": "and especially with with a complex like semantic layer deployment they could have many many hundreds of these columns",
    "start": "2477820",
    "end": "2484839"
  },
  {
    "text": "which have uh millions of Records each and",
    "start": "2484839",
    "end": "2491260"
  },
  {
    "text": "so then thinking about which ones are used in filtering a lot and which ones have a lot the records associated with",
    "start": "2491260",
    "end": "2497740"
  },
  {
    "text": "them that's really important like you've got to do that there's no magic that's that's the that's that's what that's",
    "start": "2497740",
    "end": "2503800"
  },
  {
    "text": "what it has to work Francisco Manuel anything to add from",
    "start": "2503800",
    "end": "2510460"
  },
  {
    "text": "your guys's perspective when you were playing around with this I was just thinking like what would be a",
    "start": "2510460",
    "end": "2518140"
  },
  {
    "text": "good way to since the high latency part is always the llm call like how can you for",
    "start": "2518140",
    "end": "2525400"
  },
  {
    "text": "example extract uh if there's a proper noun in the sentence without using",
    "start": "2525400",
    "end": "2530740"
  },
  {
    "text": "another because that would save some time right we would get the proper noun",
    "start": "2530740",
    "end": "2535780"
  },
  {
    "text": "send it to whatever Vector store you made and get the result without having to have an NM code which has that",
    "start": "2535780",
    "end": "2541540"
  },
  {
    "text": "latency I'm not sure if there's like some kind of very quick model named identity",
    "start": "2541540",
    "end": "2546940"
  },
  {
    "text": "recognition model that can be used for that maybe a model can be trained for that but in everything like from my view",
    "start": "2546940",
    "end": "2555339"
  },
  {
    "text": "is trying to make at least llm calls as possible without decreasing the",
    "start": "2555339",
    "end": "2561220"
  },
  {
    "text": "functionality like trying to do the same things without elements like that's my my friend I thought I'm not sure if it",
    "start": "2561220",
    "end": "2568060"
  },
  {
    "text": "works",
    "start": "2568060",
    "end": "2570359"
  },
  {
    "text": "um all right we can probably jump into a lot of user questions now so drop them in the chat on the right first one is",
    "start": "2574000",
    "end": "2579819"
  },
  {
    "text": "probably most for you our gym and let me click on it is the semantic layer built",
    "start": "2579819",
    "end": "2585880"
  },
  {
    "text": "for relational database how about nosql and unstructured data sources isn't gpt4 already very good at code interpreter",
    "start": "2585880",
    "end": "2593260"
  },
  {
    "text": "for that kind of data um so yeah this is maybe a little bit more color on like what exactly cube is",
    "start": "2593260",
    "end": "2600819"
  },
  {
    "text": "um and then and and how it interacts with different types of databases yeah uh so cube is and I give a cement",
    "start": "2600819",
    "end": "2608260"
  },
  {
    "text": "it's a semantic layer right it's it's built for I would say a tabular or relational data right first",
    "start": "2608260",
    "end": "2616359"
  },
  {
    "text": "um it's possible you know like to use different query engines like a pressed Katrina to potentially maybe query a",
    "start": "2616359",
    "end": "2623200"
  },
  {
    "text": "different you know like a type of the data but the president Trina they would",
    "start": "2623200",
    "end": "2628540"
  },
  {
    "text": "it's how it will create a SQL interface right so cube is always it sits on top",
    "start": "2628540",
    "end": "2633880"
  },
  {
    "text": "of SQL query engine or SQL database or SQL warehouse and I think that's sort of",
    "start": "2633880",
    "end": "2639280"
  },
  {
    "text": "where we can add value and that we're really being focused on that specific kind of use case anything that like a",
    "start": "2639280",
    "end": "2645940"
  },
  {
    "text": "lot of really good tools for like more unstructured data and index and Constructor data but Cube as a semantic",
    "start": "2645940",
    "end": "2651520"
  },
  {
    "text": "layer is really being focused on the relational data",
    "start": "2651520",
    "end": "2655800"
  },
  {
    "text": "I think it's it's interesting because like you know I've seen Cube integrates with right but then like archim",
    "start": "2656680",
    "end": "2662980"
  },
  {
    "text": "said it's going to write SQL so effectively all you're doing is shredding out uh the values from the",
    "start": "2662980",
    "end": "2669040"
  },
  {
    "text": "Json format data and making them into SQL like tables to then use with the",
    "start": "2669040",
    "end": "2674260"
  },
  {
    "text": "semantic way so there's not really a hell of a lot of difference and actually what ends up happening that's true yeah",
    "start": "2674260",
    "end": "2680680"
  },
  {
    "text": "we integrate this manga but we actually required to run the Pi connector",
    "start": "2680680",
    "end": "2686200"
  },
  {
    "text": "which is sort of a proxy like my SQL proxy on top of manga I heard that",
    "start": "2686200",
    "end": "2692140"
  },
  {
    "text": "might introduce some sort of a native SQL support so you know like in that case we would be able to support",
    "start": "2692140",
    "end": "2697900"
  },
  {
    "text": "manga natively but then again it's always SQL right so if the nosql database like data store will introduce",
    "start": "2697900",
    "end": "2704619"
  },
  {
    "text": "a SQL interface then we would be able to support that",
    "start": "2704619",
    "end": "2709140"
  },
  {
    "text": "um all right this one's for Manuel do you have any ideas how to make spelling mistakes more generic so you don't have",
    "start": "2711520",
    "end": "2717520"
  },
  {
    "text": "to pre-define which columns should be used to verify proper nouns so yeah so",
    "start": "2717520",
    "end": "2723400"
  },
  {
    "text": "when you were doing it for I think we did it so when you did the app it was over this like the tunic data set which",
    "start": "2723400",
    "end": "2729099"
  },
  {
    "text": "is a data set of like song artists and things like that so did you predefine kind of like which columns should be",
    "start": "2729099",
    "end": "2734800"
  },
  {
    "text": "used to to kind of like verify spelling on yeah I should probably take that one",
    "start": "2734800",
    "end": "2740440"
  },
  {
    "text": "because it was a bit myself um we hardcoded that so we just you know we saw artists you know customer names",
    "start": "2740440",
    "end": "2748060"
  },
  {
    "text": "and play names so those are probably proper nouns are coming misspelled I think this question is really really",
    "start": "2748060",
    "end": "2753700"
  },
  {
    "text": "interesting I thought about this so I don't think there's a straight answer I think there are very very nice",
    "start": "2753700",
    "end": "2759760"
  },
  {
    "text": "characteristics to get started in this path for example one thing I've been thinking about is doing some kind of",
    "start": "2759760",
    "end": "2766180"
  },
  {
    "text": "like rule-based approach where you're trying to see if the columns first are string second are not categorical so you",
    "start": "2766180",
    "end": "2773740"
  },
  {
    "text": "the cardinality is high third are not very long and Max two words for example",
    "start": "2773740",
    "end": "2780099"
  },
  {
    "text": "like not name uncertain and in that way you can like dive and like you can have like a funnel where you're left with a",
    "start": "2780099",
    "end": "2786520"
  },
  {
    "text": "few columns that are highly likely to be uh proper nouns or or just like entities",
    "start": "2786520",
    "end": "2792400"
  },
  {
    "text": "that can be misspelled and you can make a vector with those you can also check if they are",
    "start": "2792400",
    "end": "2798880"
  },
  {
    "text": "they have capped in caps the first letter but you're assuming that the database is needed which is not always",
    "start": "2798880",
    "end": "2804880"
  },
  {
    "text": "the case but I think like this first approach of like making a few rules not very long is a stream doesn't have a low",
    "start": "2804880",
    "end": "2811060"
  },
  {
    "text": "cardinality it leaves a subset of highly likely columns uh that are the subset",
    "start": "2811060",
    "end": "2817359"
  },
  {
    "text": "that you're looking for but there's another thing that I was thinking of that I think is quite interesting which is",
    "start": "2817359",
    "end": "2822520"
  },
  {
    "text": "it's highly likely that there's like this 80 20 priority in which things you",
    "start": "2822520",
    "end": "2828040"
  },
  {
    "text": "want to get right and which you know which colors are not very important and are not are not queried uh often and if",
    "start": "2828040",
    "end": "2836380"
  },
  {
    "text": "you just do that run that that approach you will be uh using all the examples of",
    "start": "2836380",
    "end": "2843099"
  },
  {
    "text": "these proper nouns or entities in the same Vector store so you will be mixing a lot of information and you're lowering",
    "start": "2843099",
    "end": "2850540"
  },
  {
    "text": "you're decreasing the probability of getting the right result back so one one cool approach I think again following",
    "start": "2850540",
    "end": "2856839"
  },
  {
    "text": "this identity rule is selecting The Columns that you most care for that you",
    "start": "2856839",
    "end": "2862000"
  },
  {
    "text": "want you know to get to get that spelling right maybe two or three three or four and then for these having a",
    "start": "2862000",
    "end": "2868839"
  },
  {
    "text": "separate Vector store and in the tool having that vectors are being worked first with a specific threshold if",
    "start": "2868839",
    "end": "2874900"
  },
  {
    "text": "values are returned then use those and then maybe append values from the from",
    "start": "2874900",
    "end": "2880359"
  },
  {
    "text": "the long term of columns um to to return results from that tool",
    "start": "2880359",
    "end": "2885640"
  },
  {
    "text": "so in that in that way you're prioritizing like if if the user is speaking about one of the entities that",
    "start": "2885640",
    "end": "2891880"
  },
  {
    "text": "I most care for it's going to be well spelled it's a small Vector store with with a constrained set of results and",
    "start": "2891880",
    "end": "2898240"
  },
  {
    "text": "then you have a long tail one which has a higher degree of error so in that way you can you know prioritize having high",
    "start": "2898240",
    "end": "2904960"
  },
  {
    "text": "accuracy over columns that are mostly most important",
    "start": "2904960",
    "end": "2909420"
  },
  {
    "text": "kind of relate okay so this is the we're running low on time and I think there's two good questions that I want to get to",
    "start": "2910960",
    "end": "2916660"
  },
  {
    "text": "so jump into the next one a little bit related to retrieval but in a different way curious if anyone has thought about",
    "start": "2916660",
    "end": "2922440"
  },
  {
    "text": "uh through embeddings a data dictionary for retrieval so basically like if you have if the table does have metadata",
    "start": "2922440",
    "end": "2929500"
  },
  {
    "text": "embedding that and then retrieving the relevant things rather than retrieving like the whole schema or something like",
    "start": "2929500",
    "end": "2935079"
  },
  {
    "text": "that and I guess maybe a generalization of this is what do you do when the schema is really big how are you guys",
    "start": "2935079",
    "end": "2940119"
  },
  {
    "text": "handling that um maybe we can start with David and then go to Francisco and Manuel from there",
    "start": "2940119",
    "end": "2946420"
  },
  {
    "text": "yeah so we've seen some like gigantic um semantic players that we've worked on",
    "start": "2946420",
    "end": "2951760"
  },
  {
    "text": "like typically like um quite mature look at projects have been you know huge with many similar",
    "start": "2951760",
    "end": "2959800"
  },
  {
    "text": "named columns and similarly named explores so we've had to find ways that you know on set up say oh choose which",
    "start": "2959800",
    "end": "2967900"
  },
  {
    "text": "explorers you you want to see and like with cube when like the user may with views would use the same thing like",
    "start": "2967900",
    "end": "2974260"
  },
  {
    "text": "which views do you want the Opie to look at and then you kind of have this step firstly where delphi's choosing which",
    "start": "2974260",
    "end": "2982359"
  },
  {
    "text": "one is the most appropriate to use and then it operates there in that space and not everywhere because otherwise it's",
    "start": "2982359",
    "end": "2989140"
  },
  {
    "text": "just too it's just so likely to go wrong",
    "start": "2989140",
    "end": "2993599"
  },
  {
    "text": "Manuel Francisco have you guys seen anything",
    "start": "2995160",
    "end": "2999300"
  },
  {
    "text": "yeah I was I was going to wait if Francis commented to talk but yeah I thought about it like it's really really",
    "start": "3002400",
    "end": "3009180"
  },
  {
    "text": "interesting um mostly and this is kind of generalized",
    "start": "3009180",
    "end": "3014520"
  },
  {
    "text": "to to the the actual um actual topic of the blog post we wrote and and the whole idea behind",
    "start": "3014520",
    "end": "3021900"
  },
  {
    "text": "these custom tools which is including domain specific knowledge and empowering uh your your solution with",
    "start": "3021900",
    "end": "3028260"
  },
  {
    "text": "domain specific knowledge and and this is a clear example right do we do we need to include the whole schema of the",
    "start": "3028260",
    "end": "3034980"
  },
  {
    "text": "tables with with columns that sometimes we know that won't be used um or",
    "start": "3034980",
    "end": "3040920"
  },
  {
    "text": "or encoding or like a lot of information that is automatically retrieved with the",
    "start": "3040920",
    "end": "3046079"
  },
  {
    "text": "tools that the agent has right now that many are not relevant and maybe it's more relevant to include a short description of the table or shorter",
    "start": "3046079",
    "end": "3051900"
  },
  {
    "text": "description of the columns and you can dynamically include it uh with this with this retrieval tools",
    "start": "3051900",
    "end": "3058260"
  },
  {
    "text": "um reducing prompts they're using tokens sorry uh time and also like being much",
    "start": "3058260",
    "end": "3063839"
  },
  {
    "text": "more accurate right and this is another example of how to include domain specific knowledge that the person who",
    "start": "3063839",
    "end": "3069599"
  },
  {
    "text": "is building the solution has and and that's infinite value uh to the to the",
    "start": "3069599",
    "end": "3075780"
  },
  {
    "text": "let's say vanilla escalation right um so so this is a very very uh like",
    "start": "3075780",
    "end": "3082319"
  },
  {
    "text": "another idea of very similar to the few shots actually uh you can even have like four months right so",
    "start": "3082319",
    "end": "3088440"
  },
  {
    "text": "um have a first first uh layer that gets a description of the table and the",
    "start": "3088440",
    "end": "3093900"
  },
  {
    "text": "columns and if the llm isn't able if the agent isn't able to to build the right query okay then I go and query the whole",
    "start": "3093900",
    "end": "3099839"
  },
  {
    "text": "schema but just if I need it right uh not always so it's very very interesting",
    "start": "3099839",
    "end": "3108200"
  },
  {
    "text": "all right and we're running low on time but this is a very open-ended question and so uh I don't know I don't know how",
    "start": "3109020",
    "end": "3115740"
  },
  {
    "text": "concrete things we're gonna have to say about this but can you and I guess this is this is prompted off of David's kind",
    "start": "3115740",
    "end": "3121559"
  },
  {
    "text": "of like comment and so maybe we can start with him and that might be all we have time for but can you talk through some of the engineering changes that",
    "start": "3121559",
    "end": "3126900"
  },
  {
    "text": "we'll need to see to migrate us from answering easy medium Enterprise questions to medium hard ones",
    "start": "3126900",
    "end": "3134339"
  },
  {
    "text": "yeah and again I probably said this once or twice there's no magic right the way",
    "start": "3134339",
    "end": "3139559"
  },
  {
    "text": "that this has to be done is through expression so like our Gem and I have talked about things like uh metric trees",
    "start": "3139559",
    "end": "3145680"
  },
  {
    "text": "and Metric chains like describing how metrics affect each other you know and",
    "start": "3145680",
    "end": "3150920"
  },
  {
    "text": "things so that it allows you to answer more abstract questions because you have",
    "start": "3150920",
    "end": "3156720"
  },
  {
    "text": "something to Traverse that will help you answer the question",
    "start": "3156720",
    "end": "3162780"
  },
  {
    "text": "um when it comes to those very abstract questions I think there is an element",
    "start": "3162780",
    "end": "3168660"
  },
  {
    "text": "where the reason why you're asking that question is because you're trying to",
    "start": "3168660",
    "end": "3173700"
  },
  {
    "text": "make a pretty bold move as an organization and when you're doing that",
    "start": "3173700",
    "end": "3179460"
  },
  {
    "text": "it's slow and when you're doing that there's potentially Millions on the line and actually having a human do this with",
    "start": "3179460",
    "end": "3187619"
  },
  {
    "text": "care is going to be what you would do anyway even if you did ask some LM tool",
    "start": "3187619",
    "end": "3193440"
  },
  {
    "text": "about this so I I wonder you know if there's like diminishing",
    "start": "3193440",
    "end": "3199020"
  },
  {
    "text": "value in trying to build some system that was so powerful that it could answer those really complex questions",
    "start": "3199020",
    "end": "3205920"
  },
  {
    "text": "um but you know that's just the way I'm thinking right now",
    "start": "3205920",
    "end": "3211099"
  },
  {
    "text": "awesome all right well that's all I've got time for thank you guys for joining it was a it was a pleasure to have you",
    "start": "3213599",
    "end": "3219480"
  },
  {
    "text": "on thank you everyone for for tuning in and the great questions um and uh yeah we'll put this recording",
    "start": "3219480",
    "end": "3226380"
  },
  {
    "text": "up so that everyone can re-watch it and learn from all the insights thank you guys",
    "start": "3226380",
    "end": "3232200"
  },
  {
    "text": "thanks for having us",
    "start": "3232200",
    "end": "3235220"
  }
]
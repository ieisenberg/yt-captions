[
  {
    "text": "all right we are live this is going to be a really fun webinar I'm really",
    "start": "4520",
    "end": "10120"
  },
  {
    "text": "interested in this topic and I always really think it's a good um experience",
    "start": "10120",
    "end": "15559"
  },
  {
    "text": "when we do deep Dives on uh one particular project or company so excited to do combine those two things into a",
    "start": "15559",
    "end": "22400"
  },
  {
    "text": "deep dive on um the the this called it theory of mind but there's a lot of",
    "start": "22400",
    "end": "27720"
  },
  {
    "text": "other terms that that hopefully uh I'll get educated on um throughout the webinar so minor Logistics and then",
    "start": "27720",
    "end": "34480"
  },
  {
    "text": "we'll just jump right into it um we are recording will be available at the link",
    "start": "34480",
    "end": "39520"
  },
  {
    "text": "afterwards and then we'll put it up on YouTube um by at least by the end of the week if you guys have questions and um I",
    "start": "39520",
    "end": "47719"
  },
  {
    "text": "will certainly have questions but if you guys have questions try to drop them in the Q&A section on the right so there's",
    "start": "47719",
    "end": "54280"
  },
  {
    "text": "the chat section right now where everyone's saying hello which is great um and then if you look below it all the",
    "start": "54280",
    "end": "60199"
  },
  {
    "text": "way to the right there's a little box with the question mark and so if you drop questions in there you can also upload other questions that you want to",
    "start": "60199",
    "end": "66119"
  },
  {
    "text": "hear answered and we'll kind of just go through those in order of like most uploaded um uh uh at the uh or honestly",
    "start": "66119",
    "end": "73880"
  },
  {
    "text": "throughout throughout the whole kind of like uh presentation um that's pretty much it",
    "start": "73880",
    "end": "79400"
  },
  {
    "text": "I'm going to hand it over to you guys now and so yeah you guys maybe want to do quick intros and then just take it away for sure yeah so uh my name's Vince",
    "start": "79400",
    "end": "88960"
  },
  {
    "text": "uh I'm a machine learning engineer uh I come from background in higher education I was working on a research and development team building ml apps at a",
    "start": "88960",
    "end": "95720"
  },
  {
    "text": "major university in the US for a long time and um yeah got with these guys to start plastic",
    "start": "95720",
    "end": "102479"
  },
  {
    "text": "Labs I'm courland uh I'm a uh philosopher educator most of my career",
    "start": "102479",
    "end": "108399"
  },
  {
    "text": "in the classroom teaching language and philosophy hey I'm venath uh I've kind",
    "start": "108399",
    "end": "115159"
  },
  {
    "text": "of been all over the tech stack from Hardware to front end to security most recently I was a PM at Microsoft uh",
    "start": "115159",
    "end": "123119"
  },
  {
    "text": "joined the plastic team once we started kind of scaling things out and started to think a lot more about the architecture and you know have a look",
    "start": "123119",
    "end": "130360"
  },
  {
    "text": "back yeah so I can give like the quick origin story and we can dive into the research um so we came together to start",
    "start": "130360",
    "end": "138160"
  },
  {
    "text": "uh exploring what a what an AI tutor would look like um having education backgrounds we thought there was a lot",
    "start": "138160",
    "end": "143319"
  },
  {
    "text": "to be desired in like a a true like AI tutoring experience and so uh courland",
    "start": "143319",
    "end": "149440"
  },
  {
    "text": "and I started really jamming on like what would a pedagogically sound AI tutor look like and the tldr on that was",
    "start": "149440",
    "end": "156280"
  },
  {
    "text": "uh you know we we came up with an architecture that uh was sort of like meta prompting to assess student needs",
    "start": "156280",
    "end": "162800"
  },
  {
    "text": "and uh we found that it was really good at doing that um but up into a point where it just didn't have enough personal context on users and so we took",
    "start": "162800",
    "end": "169760"
  },
  {
    "text": "a step back and we saw it was like a much broader opportunity to uh give large language model applications more",
    "start": "169760",
    "end": "176400"
  },
  {
    "text": "context on on their users and uh that was kind of how the Inception of plastic Labs started um and so we we spent three",
    "start": "176400",
    "end": "183200"
  },
  {
    "text": "months in an accelerator program researching and building out an MVP of what this like uh framework might look",
    "start": "183200",
    "end": "188640"
  },
  {
    "text": "like and uh yeah we can dive into it if that sounds good yeah yeah cool do uh",
    "start": "188640",
    "end": "195480"
  },
  {
    "text": "you guys want to just talk or should I share the the little diagrams we have or yeah yeah share share uh yeah show",
    "start": "195480",
    "end": "204159"
  },
  {
    "text": "the uh some of those diagrams to get us started and then we can Bounce Around yeah",
    "start": "204159",
    "end": "210319"
  },
  {
    "text": "cool cool so yeah here join our Discord if this sounds interesting",
    "start": "210319",
    "end": "217439"
  },
  {
    "text": "um um so yeah we usually like to start this off um I don't know being the resident philosopher here I'll um I",
    "start": "217920",
    "end": "225640"
  },
  {
    "text": "can't help myself but we usually like to start this off uh in term framing this in terms of the principal agent problem",
    "start": "225640",
    "end": "231159"
  },
  {
    "text": "which like you know going back to econ 101 basically describes all the ways in which um uh coordination can go wrong",
    "start": "231159",
    "end": "239720"
  },
  {
    "text": "when you try to delegate a task to an agent um and obviously as we're thinking about how human AI relations are going",
    "start": "239720",
    "end": "247480"
  },
  {
    "text": "to go and unfold and the kind of tools we're going to build um that becomes that becomes really important to",
    "start": "247480",
    "end": "252519"
  },
  {
    "text": "consider right like human relationships are really really messy and uh especially economic ones um and so you",
    "start": "252519",
    "end": "259799"
  },
  {
    "text": "know full of information asymmetries and Mis line in sence and so um yeah if we",
    "start": "259799",
    "end": "265240"
  },
  {
    "text": "want like uh our our AI to be truly augmentive then you know we you know we",
    "start": "265240",
    "end": "270840"
  },
  {
    "text": "we ought to start thinking about some of these things on the front end here so um earlier this year researchers noted",
    "start": "270840",
    "end": "278840"
  },
  {
    "text": "that uh llms were just you know displaying uh emergent theory of Mind",
    "start": "278840",
    "end": "284039"
  },
  {
    "text": "abilities and we found this really really interesting in terms of uh solving some of those problems I just",
    "start": "284039",
    "end": "290800"
  },
  {
    "text": "talked about and and the reason is the theory of mind is basically the capacity to predict what other people are",
    "start": "290800",
    "end": "297680"
  },
  {
    "text": "thinking and it's limited to just just humans and a few other species and so the fact that this is emerging in",
    "start": "297680",
    "end": "303680"
  },
  {
    "text": "without being a task they're specifically trained for is like really compelling and we can get into like why that might be happening and all that but",
    "start": "303680",
    "end": "310960"
  },
  {
    "text": "um basically uh you know what was do you know what the do you know what the evidence in the paper was that this",
    "start": "310960",
    "end": "317400"
  },
  {
    "text": "theory of Mind was emerging in llms like what what exact kind of like study they they ran or",
    "start": "317400",
    "end": "323400"
  },
  {
    "text": "experiments yeah they ran a they they ran GPT like the GPT series of models on",
    "start": "323400",
    "end": "329639"
  },
  {
    "text": "uh these classic tests that developmental psychologists uh use on children where they sort of lay out",
    "start": "329639",
    "end": "335919"
  },
  {
    "text": "observations of like different actors in in scenarios and ask the and like prompt",
    "start": "335919",
    "end": "341199"
  },
  {
    "text": "the language model to make the correct selection as to like who uh who is uh",
    "start": "341199",
    "end": "347400"
  },
  {
    "text": "like missing information or uh I think in this case it was like uh who has",
    "start": "347400",
    "end": "353840"
  },
  {
    "text": "right information or who is who is uh going to be confused so it's it's like a multiple",
    "start": "353840",
    "end": "360039"
  },
  {
    "text": "choice problem at its at its core yeah yeah yeah they they they ask use they ask um you know when when these",
    "start": "360039",
    "end": "367919"
  },
  {
    "text": "kinds of tests are done people right like they're just asking they're they're trying to design uh queries that um that",
    "start": "367919",
    "end": "375720"
  },
  {
    "text": "show that like whoever's being being tested can can think about other people's State of Mind like naturally",
    "start": "375720",
    "end": "382919"
  },
  {
    "text": "and so you know we probably need to you know we can talk about this later maybe but we think a lot about how like what",
    "start": "382919",
    "end": "389120"
  },
  {
    "text": "what I don't specific like evaluations might be here because obviously like this isn't going to be exactly like",
    "start": "389120",
    "end": "395199"
  },
  {
    "text": "what's happening in humans um but regardless of like taxonomy it's it's super useful right and so when we think",
    "start": "395199",
    "end": "402240"
  },
  {
    "text": "about like um you know when we think about trying to get l or AI to act in",
    "start": "402240",
    "end": "408680"
  },
  {
    "text": "like high fidelity with our interests then this we think this is like a really potent tool so um so like to improve you",
    "start": "408680",
    "end": "416879"
  },
  {
    "text": "know our the first thing we thought of is like how do we improve this basically right um so how do we enhance this and",
    "start": "416879",
    "end": "424000"
  },
  {
    "text": "um the first thing we did since this is like you know a thing that biological brains do naturally um is to think about",
    "start": "424000",
    "end": "431720"
  },
  {
    "text": "like how do we how do humans gain the like gain the context um that they need to improve",
    "start": "431720",
    "end": "437879"
  },
  {
    "text": "their theory of Mind predictions and like can we mimic these kinds of processes in L and we found that we can",
    "start": "437879",
    "end": "445479"
  },
  {
    "text": "basically um the brain learns by constantly making predictions about reality and cons and comparing that with",
    "start": "445479",
    "end": "452000"
  },
  {
    "text": "actual sense data um coming in and when there are errors in prediction and when there's a difference between the",
    "start": "452000",
    "end": "457919"
  },
  {
    "text": "prediction and reality um the brain learns something and most of the stuff happens subconsciously in the dark although you",
    "start": "457919",
    "end": "464440"
  },
  {
    "text": "can use this as an active learning technique um and you know it turns out",
    "start": "464440",
    "end": "469680"
  },
  {
    "text": "that uh the LM are actually really suited to to doing this too right we can do basically the same thing so we",
    "start": "469680",
    "end": "476479"
  },
  {
    "text": "designed like a prompting framework that um that you know that forces the LM to",
    "start": "476479",
    "end": "484720"
  },
  {
    "text": "like actively metac cognate on user Behavior compare that against their",
    "start": "484720",
    "end": "490280"
  },
  {
    "text": "actual behavior and then um learn learn from the difference right derive",
    "start": "490280",
    "end": "495919"
  },
  {
    "text": "psychological facts from that Delta so um yeah so this is and this this",
    "start": "495919",
    "end": "502720"
  },
  {
    "text": "violation of expectation is is this like a pre-existing Concept in Psychology that",
    "start": "502720",
    "end": "508280"
  },
  {
    "text": "that uh they borrowing from yeah yeah so like violation of expectation is a is a",
    "start": "508280",
    "end": "514080"
  },
  {
    "text": "concept from developmental psychology um and basically it's it it is one of these mechanisms about prediction and",
    "start": "514080",
    "end": "521080"
  },
  {
    "text": "comparison that humans use from the earli stages there's a bunch of studies on like infants and how how they learn",
    "start": "521080",
    "end": "527320"
  },
  {
    "text": "by having their expectation violated and so yeah so we're really taking our cue from theories in Psychology and",
    "start": "527320",
    "end": "533279"
  },
  {
    "text": "cognitive science and seeing if we can you know how we can mimic those um in",
    "start": "533279",
    "end": "538320"
  },
  {
    "text": "our Proms and architecture",
    "start": "538320",
    "end": "541200"
  },
  {
    "text": "yeah so this this is kind of like the the snippet of the diagram so this was like our overall sort of like",
    "start": "543760",
    "end": "549440"
  },
  {
    "text": "metacognitive architecture and we try to break this down because this gets a little complex um the the thing that you",
    "start": "549440",
    "end": "556320"
  },
  {
    "text": "can see in our in the uh open source version of the tutor um which again a bit of context for for folks um we've we",
    "start": "556320",
    "end": "564320"
  },
  {
    "text": "have open sourced an AI tutor um it's called it's we have it implemented um at",
    "start": "564320",
    "end": "570920"
  },
  {
    "text": "chat. bloom. right now but the repo is open source um you can find that um it's",
    "start": "570920",
    "end": "576680"
  },
  {
    "text": "called tutter GPT and it's under the plastic Labs uh uh organization but the",
    "start": "576680",
    "end": "582839"
  },
  {
    "text": "uh the way that works is um whenever users say something we generate a thought about the students's needs and",
    "start": "582839",
    "end": "589160"
  },
  {
    "text": "then we feed that into a uh response chain that uses that thought as like extra context to generate a response and",
    "start": "589160",
    "end": "596680"
  },
  {
    "text": "so really what we're doing uh on the back end of that is sort of enhancing the language like the language model's",
    "start": "596680",
    "end": "602519"
  },
  {
    "text": "ability to think about the user and so what we do is like EO courland was",
    "start": "602519",
    "end": "608240"
  },
  {
    "text": "saying this we try to implement and mimic this violation of expectation method where we predict what the user is",
    "start": "608240",
    "end": "613480"
  },
  {
    "text": "going to say uh and we uh compare that",
    "start": "613480",
    "end": "618640"
  },
  {
    "text": "to what they actually said and we and uh the important thing here is like the",
    "start": "618640",
    "end": "623760"
  },
  {
    "text": "metacognitive prompting part we generate thoughts at every step so it's not like",
    "start": "623760",
    "end": "630600"
  },
  {
    "text": "one shot or like you know single shot uh response generation we're always having",
    "start": "630600",
    "end": "635639"
  },
  {
    "text": "the language model reflect on uh what it's observing and so we generate a",
    "start": "635639",
    "end": "642880"
  },
  {
    "text": "thought about what the user is going to say we revised that thought based off of facts that we can retrieve over a vector",
    "start": "642880",
    "end": "648959"
  },
  {
    "text": "store we uh compare the what we thought they were going to say ver what they",
    "start": "648959",
    "end": "654760"
  },
  {
    "text": "actually said and derive facts based off the that difference and those get sent into a vector store that can then be",
    "start": "654760",
    "end": "660639"
  },
  {
    "text": "retrieved over um at you know later turns of the conversation so oh I think I'm over here",
    "start": "660639",
    "end": "669279"
  },
  {
    "text": "yeah um happy to dive more into like the the",
    "start": "669279",
    "end": "675639"
  },
  {
    "text": "like architecture and the Lang chain side of these things is like yeah we built this entire thing in Lang chain",
    "start": "675639",
    "end": "680760"
  },
  {
    "text": "and you can see uh see that in the open source version as well well I think it's probably worth walking so this is a",
    "start": "680760",
    "end": "687200"
  },
  {
    "text": "really cool diagram and I think this is the kind of like key bit and I know like we discussed this a bunch in slack and I",
    "start": "687200",
    "end": "692320"
  },
  {
    "text": "had a bunch of questions about this so I think it um is maybe worth just going over this um in in in in more detail um",
    "start": "692320",
    "end": "700120"
  },
  {
    "text": "even just for my kind of like further education so um okay so we have the okay",
    "start": "700120",
    "end": "707920"
  },
  {
    "text": "so we have the um where where's the best place to start if we start with",
    "start": "707920",
    "end": "715959"
  },
  {
    "text": "the bot so we maybe we start with the bot response sure so from the bot response in the",
    "start": "715959",
    "end": "722720"
  },
  {
    "text": "background what we're going to do is we're going to predict what the user going to say yes and importantly that's",
    "start": "722720",
    "end": "728519"
  },
  {
    "text": "like a reflection we're not like trying to predict verbatim we find that like the language model is quite good at",
    "start": "728519",
    "end": "734360"
  },
  {
    "text": "generating like accurate commentary but really bad at generating like verbatim",
    "start": "734360",
    "end": "740639"
  },
  {
    "text": "predictions of like what they think the user is going to say and so like go",
    "start": "740639",
    "end": "745959"
  },
  {
    "text": "ahead go no I was going to go on to the next thing but if you're going to clarify this part yeah yeah yeah uh so",
    "start": "745959",
    "end": "754760"
  },
  {
    "text": "so the no I mean yeah that we're we're moving on so the the comment like the",
    "start": "754760",
    "end": "762279"
  },
  {
    "text": "reflection the thought about what the user is going to say gets uh revised so like we in in uh we put in the chat",
    "start": "762279",
    "end": "772440"
  },
  {
    "text": "message history for this one um and so the only context available to it at this",
    "start": "772440",
    "end": "778680"
  },
  {
    "text": "point point it's just like everything that's been set up to that point in the conversation uh that will reasonably fit",
    "start": "778680",
    "end": "784760"
  },
  {
    "text": "in the context window of course um and then we take that we ask the language",
    "start": "784760",
    "end": "790279"
  },
  {
    "text": "model to revise that thought based off of any uh facts that it can retrieve from the vector store so I think",
    "start": "790279",
    "end": "796000"
  },
  {
    "text": "actually an important piece here is we are prompting it to do two things um we're prompting it to uh reflect like",
    "start": "796000",
    "end": "803360"
  },
  {
    "text": "generate a thought about the students needs and uh list out any additional uh",
    "start": "803360",
    "end": "809199"
  },
  {
    "text": "data points that it could uh that it would find useful to improve its",
    "start": "809199",
    "end": "815440"
  },
  {
    "text": "prediction so this is a two-part process we describ it in the paper um but what we do is we parse out those additional",
    "start": "815440",
    "end": "821800"
  },
  {
    "text": "data points and those serve as the query over the vector store so whenever we ask",
    "start": "821800",
    "end": "827160"
  },
  {
    "text": "it to revise that thought based off of facts it's retrieve it's retrieving based off of uh any additional data that",
    "start": "827160",
    "end": "833519"
  },
  {
    "text": "it thinks it might uh that might be useful for uh improving that that prediction about the user which usually",
    "start": "833519",
    "end": "840800"
  },
  {
    "text": "lends itself well really well to querying over like psychological facts about like people's interests their",
    "start": "840800",
    "end": "846360"
  },
  {
    "text": "beliefs their prior knowledge about certain things um and so usually the the",
    "start": "846360",
    "end": "853240"
  },
  {
    "text": "uh Reflections the thoughts they get uh really dialed in after this step um and",
    "start": "853240",
    "end": "858639"
  },
  {
    "text": "so then we take what they actually said and compare it to the uh wait so just going back so just going back to the",
    "start": "858639",
    "end": "865480"
  },
  {
    "text": "user thought the thought revision basically what you do is you take original prediction you take in the",
    "start": "865480",
    "end": "871160"
  },
  {
    "text": "retrieved facts and you're like hey update now what you think the US going to say based on like these additional",
    "start": "871160",
    "end": "876959"
  },
  {
    "text": "facts exactly exactly yep and so uh",
    "start": "876959",
    "end": "882560"
  },
  {
    "text": "usually right so usually that gets really dialed in at that point um and so this step generates uh a thought about",
    "start": "882560",
    "end": "889320"
  },
  {
    "text": "how those two might differ the the revised thought and what they actually said and so uh that commentary is then",
    "start": "889320",
    "end": "897360"
  },
  {
    "text": "used to derive have literally like a list of facts about a user um that can",
    "start": "897360",
    "end": "902680"
  },
  {
    "text": "be then stored and we just check for uh redundancy at that point um but otherwise they get stored um and so the",
    "start": "902680",
    "end": "911000"
  },
  {
    "text": "same thing uh that I said how how do you so I think the checking for redundancy is actually quite interesting as well so",
    "start": "911000",
    "end": "917480"
  },
  {
    "text": "like what what does that what does that involve uh actually it's it's pretty",
    "start": "917480",
    "end": "922839"
  },
  {
    "text": "it's pretty simple um you know we we we derive like a list of facts and then we",
    "start": "922839",
    "end": "928240"
  },
  {
    "text": "like sort of iterate over the vector store on like a similarity basis to just make sure that like uh we haven't stored",
    "start": "928240",
    "end": "935279"
  },
  {
    "text": "something super similar we're not storing redundant facts so for each fact you like look up things in Vector",
    "start": "935279",
    "end": "941600"
  },
  {
    "text": "store um and then and and and then and then what you you get back like 10 items",
    "start": "941600",
    "end": "949000"
  },
  {
    "text": "and their corresponding similarities do you then base it off of the similarity do you pass it to the language model and",
    "start": "949000",
    "end": "954079"
  },
  {
    "text": "ask it to make a decision yeah we ask the language model to make the decision that's another yeah",
    "start": "954079",
    "end": "961240"
  },
  {
    "text": "that's a great great point to clarify um we find it like sorry no go ahead I was",
    "start": "961240",
    "end": "968199"
  },
  {
    "text": "just going to say like a broad theme um in in our work and we've written about this in our blog is that like we find",
    "start": "968199",
    "end": "973680"
  },
  {
    "text": "that the more aomy we give the the language model to to make decision like the more intellectual respect we treat",
    "start": "973680",
    "end": "980000"
  },
  {
    "text": "it with uh the more we're rewarded like it's it's fascinating you know the the",
    "start": "980000",
    "end": "985160"
  },
  {
    "text": "limits of which you can offload cognitive tasks to these language models like so sorry yeah I just wanted to",
    "start": "985160",
    "end": "990880"
  },
  {
    "text": "throw that in there and um so okay so you you get back",
    "start": "990880",
    "end": "996920"
  },
  {
    "text": "like the 10 most similar ones you have your new fact you pass it to the language model and then what can the",
    "start": "996920",
    "end": "1002519"
  },
  {
    "text": "language model says like yes this is a good new fact to add no this is a good new fact like do you update old facts at",
    "start": "1002519",
    "end": "1009920"
  },
  {
    "text": "all like if there's conflicting temporal information like how how would that work",
    "start": "1009920",
    "end": "1015279"
  },
  {
    "text": "yeah that's a great question um currently we're just sort of like passing ing in like the facts we're",
    "start": "1015279",
    "end": "1021759"
  },
  {
    "text": "looking we're considering storing and then like the top K that we retrieve and",
    "start": "1021759",
    "end": "1027199"
  },
  {
    "text": "asking the language model to reason about like what the list should look like uh to not restore redundant",
    "start": "1027199",
    "end": "1034438"
  },
  {
    "text": "information uh the temporal aspect of this is super interesting and like an",
    "start": "1034439",
    "end": "1039520"
  },
  {
    "text": "area of of future work for us I think there's a lot of really neat things we could do there uh we just haven't gotten",
    "start": "1039520",
    "end": "1044918"
  },
  {
    "text": "to that yet in the MVP and and when you say like reason about what the list should be that's specifically like if",
    "start": "1044919",
    "end": "1050840"
  },
  {
    "text": "you have 10 new incoming facts you're like reasoning about whether that should actually just be three new ones or",
    "start": "1050840",
    "end": "1056679"
  },
  {
    "text": "whether it should be all 10 like that you're not you're not changing any of the stuff that's already in there exactly that's right yeah yeah it's like",
    "start": "1056679",
    "end": "1064039"
  },
  {
    "text": "given it given these are existing these are new reason about which one should be stored based off like you know to to not",
    "start": "1064039",
    "end": "1071039"
  },
  {
    "text": "uh uh sort like redundant information cool yeah",
    "start": "1071039",
    "end": "1077400"
  },
  {
    "text": "yeah well so that I mean that that and then that goes and then okay so",
    "start": "1077400",
    "end": "1084520"
  },
  {
    "text": "and then this is uh okay so then you update the vector store and then you've",
    "start": "1084520",
    "end": "1089760"
  },
  {
    "text": "got this other bubble here the the theory of mind and violation of expectation",
    "start": "1089760",
    "end": "1095240"
  },
  {
    "text": "thought what is that representing in the bubble this this sort of like Square",
    "start": "1095240",
    "end": "1101000"
  },
  {
    "text": "represents the open source tutor um okay what you can see out there on in the",
    "start": "1101000",
    "end": "1106360"
  },
  {
    "text": "repo right now and so like uh really all this represents is like the thought step and like in our version",
    "start": "1106360",
    "end": "1114120"
  },
  {
    "text": "of Bloom the hosted tutor um that you can try out at chat. bloom. uh it's got this extra sort of",
    "start": "1114120",
    "end": "1121200"
  },
  {
    "text": "like uh step that's retrieving it's sort of similar to this up here where we have it generate a thought but then we revise",
    "start": "1121200",
    "end": "1127400"
  },
  {
    "text": "that thought it's like the our implementation of the tutor generates a thought just like the open source",
    "start": "1127400",
    "end": "1133039"
  },
  {
    "text": "version but revises that thought and the difference here would be the thought would be how the bot should respond not",
    "start": "1133039",
    "end": "1139799"
  },
  {
    "text": "how the human should respond at this for for this particular thing correct yep",
    "start": "1139799",
    "end": "1145240"
  },
  {
    "text": "yeah yeah yeah to add um I'll just say the",
    "start": "1145240",
    "end": "1152559"
  },
  {
    "text": "reason that we um the reason that we have the um our tutor metac cognate",
    "start": "1152559",
    "end": "1158200"
  },
  {
    "text": "constantly at every con you know at every turn of conversation is because um",
    "start": "1158200",
    "end": "1164080"
  },
  {
    "text": "we find that when it's constantly thinking about what the learner needs um",
    "start": "1164080",
    "end": "1169840"
  },
  {
    "text": "that uh that its responses are like way more in tune with their actual needs so instead of um you know originally we",
    "start": "1169840",
    "end": "1177039"
  },
  {
    "text": "were trying to design um you know like uh you know change specific to",
    "start": "1177039",
    "end": "1183880"
  },
  {
    "text": "particular uh like domains of learning and like figure out what the student objective was and funnel them there and",
    "start": "1183880",
    "end": "1191240"
  },
  {
    "text": "we found that if we just had the model constantly reasoning about what the student needs that we didn't really need",
    "start": "1191240",
    "end": "1197000"
  },
  {
    "text": "to define the objective at all um because um because it's just always",
    "start": "1197000",
    "end": "1202360"
  },
  {
    "text": "cohered to to the needs of the moment and so we we found it was much more broadly capable without requiring like",
    "start": "1202360",
    "end": "1209000"
  },
  {
    "text": "tons of you know high quality demonstrations or or anything like",
    "start": "1209000",
    "end": "1215039"
  },
  {
    "text": "that yeah I'll also add too that uh when we do that and",
    "start": "1215600",
    "end": "1221840"
  },
  {
    "text": "like one of the things I think we were talking a lot about was like this part where like how do we determine what the",
    "start": "1221840",
    "end": "1227200"
  },
  {
    "text": "bot responds with we were like oh that's actually an important sort of uh uh thing like for",
    "start": "1227200",
    "end": "1234280"
  },
  {
    "text": "us is that we we don't we sort of just give it a lot of context at its disposal",
    "start": "1234280",
    "end": "1239480"
  },
  {
    "text": "like to to reason about the best way to respond to the user and what we found is that like gp4 and these chat models are",
    "start": "1239480",
    "end": "1246960"
  },
  {
    "text": "trained super well to like for lack of a better term like catch a Vibe uh if you",
    "start": "1246960",
    "end": "1252919"
  },
  {
    "text": "give it like all this context like you're like okay here are the users's interests here's like you know here's what they know about this already like",
    "start": "1252919",
    "end": "1259240"
  },
  {
    "text": "things like that and then you give it the chat history uh it does a really good job of",
    "start": "1259240",
    "end": "1264840"
  },
  {
    "text": "like trying of determining on its own like okay should I ask a follow-up question or should I just like respond",
    "start": "1264840",
    "end": "1270480"
  },
  {
    "text": "with the answer um do I need more information to better serve them or should we dive deeper based on their",
    "start": "1270480",
    "end": "1276400"
  },
  {
    "text": "interests like where should we take this conversation we we find some really like interesting emergent behavior that way",
    "start": "1276400",
    "end": "1282799"
  },
  {
    "text": "um so yeah it's like really really cool to see how they handle this stuff and are the for this uh open source or in",
    "start": "1282799",
    "end": "1290679"
  },
  {
    "text": "the paper and everything they're like basically described in the paper we're still you know we're in early stage",
    "start": "1290679",
    "end": "1296200"
  },
  {
    "text": "startup we're trying to figure out our our our path forward here we'd love to open source it in fact that's we you",
    "start": "1296200",
    "end": "1301360"
  },
  {
    "text": "know it's kind of what we're thinking is the future um like an open core sort of model um but not at the moment we just",
    "start": "1301360",
    "end": "1307200"
  },
  {
    "text": "have to get our ducks in AOW a little bit here and figure out what we're doing yeah completely reasonable there's a uh",
    "start": "1307200",
    "end": "1313080"
  },
  {
    "text": "the reason I asked is there's a good question um in the chat as well is like what are the nature of the facts that",
    "start": "1313080",
    "end": "1318640"
  },
  {
    "text": "the model ends up retrieving and like are there some examples and I imagine like those really depend on the prompts",
    "start": "1318640",
    "end": "1323880"
  },
  {
    "text": "you use kind of and so yeah I'd be curious to hear how you guys thought about that prompting process and then",
    "start": "1323880",
    "end": "1330000"
  },
  {
    "text": "and what you observed yeah yeah we we tend to We tend",
    "start": "1330000",
    "end": "1335840"
  },
  {
    "text": "to focus a lot on user psychology um because we think that that's like the uh",
    "start": "1335840",
    "end": "1341039"
  },
  {
    "text": "like the primary new potential Paradigm here um so instead of you know like",
    "start": "1341039",
    "end": "1348960"
  },
  {
    "text": "traditionally we've we've thought about like getting to know users digitally as",
    "start": "1348960",
    "end": "1354200"
  },
  {
    "text": "like what's their activity what do they engaged with let's maybe plug in their email their docs their highlights their",
    "start": "1354200",
    "end": "1360000"
  },
  {
    "text": "notes that kind of stuff and then we'll know them um and that works you know well to to a degree but like if we're",
    "start": "1360000",
    "end": "1366840"
  },
  {
    "text": "just doing that with ls we think that uh we think we're missing a big opportunity because they're able to reason over like",
    "start": "1366840",
    "end": "1373760"
  },
  {
    "text": "really substantive psychological content um because probably because the narrative space of the pre-training is",
    "start": "1373760",
    "end": "1380240"
  },
  {
    "text": "like filled with that kind of stuff um then uh then we ought to try to leverage that so like so when we we're asking the",
    "start": "1380240",
    "end": "1388760"
  },
  {
    "text": "model to store so that's why we ask the model to store specifically psychological things we tend to think we think about like what are the um what",
    "start": "1388760",
    "end": "1396279"
  },
  {
    "text": "are the kinds of facts that humans gain from ordinary social cognition or",
    "start": "1396279",
    "end": "1401440"
  },
  {
    "text": "interpersonal interaction right like if I'm if I'm spending a lot of time with someone I'm not like reading their",
    "start": "1401440",
    "end": "1408320"
  },
  {
    "text": "emails or their docs or their digital artifacts right like we're conversing um",
    "start": "1408320",
    "end": "1413400"
  },
  {
    "text": "I'm getting to know like what we might say is the real them right I'm trying to figure out like their beliefs their",
    "start": "1413400",
    "end": "1420000"
  },
  {
    "text": "false beliefs their personal history their Knowledge Graph their interests Hobbies um you know anything like that",
    "start": "1420000",
    "end": "1428320"
  },
  {
    "text": "right um and we tend to just like kind of absorb this passively and",
    "start": "1428320",
    "end": "1433880"
  },
  {
    "text": "automatically either you know with a mix of interpersonal interaction ction and like social cognition right so I will",
    "start": "1433880",
    "end": "1441919"
  },
  {
    "text": "ask like deliberate questions of someone like to to get discreet facts um you",
    "start": "1441919",
    "end": "1448480"
  },
  {
    "text": "know if if I'm trying to get to know someone but my brain is also constantly running prediction on what they're going",
    "start": "1448480",
    "end": "1453559"
  },
  {
    "text": "to say next and um and how they might behave and then comparing that to what I",
    "start": "1453559",
    "end": "1459559"
  },
  {
    "text": "actually observe and deriving facts and so that's what we're trying to mimic here and so when it retrieves um when it stores things it's",
    "start": "1459559",
    "end": "1466640"
  },
  {
    "text": "storing it's just storing stuff that comes from that prediction era right from the difference between what it",
    "start": "1466640",
    "end": "1471919"
  },
  {
    "text": "thought you would say and what you actually said because you know because if it predicted something correctly it",
    "start": "1471919",
    "end": "1478039"
  },
  {
    "text": "you know then it it doesn't really need to know that about you right it it already is able to int it um and yeah",
    "start": "1478039",
    "end": "1484039"
  },
  {
    "text": "what that ends up being is that kind of tweet of psychological stuff and so then when it retrieves that",
    "start": "1484039",
    "end": "1489840"
  },
  {
    "text": "information um that's uh that's what's happening when it when we talk about it like in the context of the tutor for",
    "start": "1489840",
    "end": "1495760"
  },
  {
    "text": "example like what we find is is that the model is um much better able to keep",
    "start": "1495760",
    "end": "1503320"
  },
  {
    "text": "track of like what a student knows um it's able to synthesize Concepts um across interactions over time um it's",
    "start": "1503320",
    "end": "1511000"
  },
  {
    "text": "able to like contextualize Concepts in terms of something it knows the user is interested in right like it knows you're",
    "start": "1511000",
    "end": "1518440"
  },
  {
    "text": "interested in soccer right so if it's trying to explain velocity to you right",
    "start": "1518440",
    "end": "1523720"
  },
  {
    "text": "it it'll frame it in terms of in terms of soccer and it'll reference a previous ation we find that's a really like basic",
    "start": "1523720",
    "end": "1530320"
  },
  {
    "text": "example but we find it does that like across really impressive domains right there's a bunch of like Swedish",
    "start": "1530320",
    "end": "1537120"
  },
  {
    "text": "dickenstein PhD students um using Bloom um and it's able to uh it's able to like",
    "start": "1537120",
    "end": "1544080"
  },
  {
    "text": "synthesize uh it's able to synthesize like multiple philosophers and multiple",
    "start": "1544080",
    "end": "1550360"
  },
  {
    "text": "discret Concepts within their philosophy between conversations and make connections like that weren't that",
    "start": "1550360",
    "end": "1556720"
  },
  {
    "text": "weren't there before and uh and so I mean that's like a Knowledge Graph example but it's you know it's really",
    "start": "1556720",
    "end": "1564159"
  },
  {
    "text": "it's really it ends up being like really powerful the other thing I'll add there too is if you if you if you want like",
    "start": "1564159",
    "end": "1571240"
  },
  {
    "text": "the closest thing to to like seeing what the examples might be you can go to chat. bloom. and try it out and we have",
    "start": "1571240",
    "end": "1579399"
  },
  {
    "text": "a toggle up in the top right that allows you to see like the thoughts of the bot and that's where it lists out that",
    "start": "1579399",
    "end": "1585399"
  },
  {
    "text": "additional data that it thinks would be useful so usually like it's it's it's like things like your interest or your",
    "start": "1585399",
    "end": "1590600"
  },
  {
    "text": "prior knowledge and that's what we're you know that that's the type of data we're we're going for and I just dropped that link in the",
    "start": "1590600",
    "end": "1597520"
  },
  {
    "text": "chat because I'm I'm definitely going to play around with that after um all right moving on to some of the questions that",
    "start": "1597520",
    "end": "1603080"
  },
  {
    "text": "we've got in in the question box um the first one I think is really good what",
    "start": "1603080",
    "end": "1608320"
  },
  {
    "text": "are the data formats you recommend for storing memory what are considerations for building and so just to kind of like",
    "start": "1608320",
    "end": "1615640"
  },
  {
    "text": "um look at that diagram that you had it seems like you're using a vector store",
    "start": "1615640",
    "end": "1620960"
  },
  {
    "text": "and you're storing like facts but not the raw conversation things you're storing like the llm reflected things",
    "start": "1620960",
    "end": "1629240"
  },
  {
    "text": "was there is is is my understanding correct and then is there any other data formats that you tried um you know I",
    "start": "1629240",
    "end": "1635440"
  },
  {
    "text": "think a lot of people are interested in graphs more structured representations yeah I would be really curious to hear",
    "start": "1635440",
    "end": "1640640"
  },
  {
    "text": "your thoughts there by way this is such a good slide so yeah close it too soon",
    "start": "1640640",
    "end": "1646559"
  },
  {
    "text": "we love we love escaladora yeah yeah normaliz excal um",
    "start": "1646559",
    "end": "1652279"
  },
  {
    "text": "we uh we're restoring natural language um at this at this point I think there's",
    "start": "1652279",
    "end": "1657760"
  },
  {
    "text": "a lot of opportunity to really interesting things um storing you know uh uh like embeddings learning tokens in",
    "start": "1657760",
    "end": "1665799"
  },
  {
    "text": "this regard um but yeah currently it's it's it's quite simple like we derive",
    "start": "1665799",
    "end": "1671760"
  },
  {
    "text": "like a list of facts and then we embed those and store those vectors and so um",
    "start": "1671760",
    "end": "1678320"
  },
  {
    "text": "yeah anything to add yeah it's essentially like a retrieval augmented generation there at the the VOE step and",
    "start": "1678320",
    "end": "1686120"
  },
  {
    "text": "the the thought revision step so the vector store is just to make that process a lot faster but um we haven't",
    "start": "1686120",
    "end": "1693480"
  },
  {
    "text": "really seen any issues with like just storing natural language or Json especially for like chat message history",
    "start": "1693480",
    "end": "1700600"
  },
  {
    "text": "I think there's some questions related to like context Windows um and there's a lot of creative things that we've messed",
    "start": "1700600",
    "end": "1706600"
  },
  {
    "text": "around there with kind of how to optimize the context window um sometimes",
    "start": "1706600",
    "end": "1712000"
  },
  {
    "text": "we just take the last 10 messages but I think we've also looked into at at one",
    "start": "1712000",
    "end": "1717559"
  },
  {
    "text": "point we were using like conversation summary buffer window which like kept summarizing the the memory as the chat",
    "start": "1717559",
    "end": "1725240"
  },
  {
    "text": "was going and then we've we've like played around with some ideas of like only putting the most recent messages in",
    "start": "1725240",
    "end": "1732320"
  },
  {
    "text": "but making the past chat history queriable to the agent if it like as",
    "start": "1732320",
    "end": "1737600"
  },
  {
    "text": "tool basically where it could it could choose wanted to yeah because what we do is a lot of this like telling the",
    "start": "1737600",
    "end": "1744200"
  },
  {
    "text": "telling the agent to think about what it needs and if you treat the memory as a tool that it can decide that it needs",
    "start": "1744200",
    "end": "1751399"
  },
  {
    "text": "more context and not necessarily just on the user but just on the conversation there there's some opportunities there",
    "start": "1751399",
    "end": "1757840"
  },
  {
    "text": "of like letting it figure out what it needs essentially yeah and that was a",
    "start": "1757840",
    "end": "1763120"
  },
  {
    "text": "great segue to the next question which I just put up with SH like what are the challenges of long-term memory for agents and what Solutions have been",
    "start": "1763120",
    "end": "1769039"
  },
  {
    "text": "working best what does the next step look like for context window friendly and reliable long-term memory so you",
    "start": "1769039",
    "end": "1774880"
  },
  {
    "text": "talked a bit about so it sounded like summarizing the conversation only including kind of like most recent",
    "start": "1774880",
    "end": "1780480"
  },
  {
    "text": "messages letting the agent like look up if it needed to these were all things you experimented with um any other",
    "start": "1780480",
    "end": "1786120"
  },
  {
    "text": "additional stuff to add and and what is live right now in in in app. bloom. what",
    "start": "1786120",
    "end": "1791679"
  },
  {
    "text": "are what are you know I think there's a great like you can talk about everything all you want but I think it's really interesting to see what you guys",
    "start": "1791679",
    "end": "1797039"
  },
  {
    "text": "actually chose to do and so I'd also be curious to to you know with all these different options which one emerged",
    "start": "1797039",
    "end": "1803200"
  },
  {
    "text": "Victorious for you I mean so the live one is just the it's it's saying like the 10 most recent messages for the chat",
    "start": "1803200",
    "end": "1810480"
  },
  {
    "text": "context and then um you know for the revision steps and all the extra like",
    "start": "1810480",
    "end": "1817080"
  },
  {
    "text": "thought stuff there it's kind of searching across the entire um VOR",
    "start": "1817080",
    "end": "1822399"
  },
  {
    "text": "store I think right now we're kind of like playing around with a couple different ways to do the window and I",
    "start": "1822399",
    "end": "1829760"
  },
  {
    "text": "think it's just like a matter of like finishing up these experiments and deciding if we want to push at the prod",
    "start": "1829760",
    "end": "1835000"
  },
  {
    "text": "or not um if you look at a repo we have like a ton of different branches I don't know if anyone's really monitoring that",
    "start": "1835000",
    "end": "1841120"
  },
  {
    "text": "closely but you can see like all the different iterations of the different modules and then I think you know one of",
    "start": "1841120",
    "end": "1847919"
  },
  {
    "text": "the main challenges that I I've noticed is just like the kind of like decay in",
    "start": "1847919",
    "end": "1853240"
  },
  {
    "text": "models over time when like I've seen like a lot of instances of Agents just over time like starting to spit out like",
    "start": "1853240",
    "end": "1859159"
  },
  {
    "text": "gibberish um and that could be because of like Unicode errors or just like token",
    "start": "1859159",
    "end": "1864320"
  },
  {
    "text": "issues um hyper parameter tuning you know like playing with the temperature and like top K and stuff like that or",
    "start": "1864320",
    "end": "1871360"
  },
  {
    "text": "top P sorry that's been yeah that's been a fun one to hone in we actually like I think",
    "start": "1871360",
    "end": "1878399"
  },
  {
    "text": "I can't remember is is our temperature still a little higher than normal on tutor GPT temperature is still like",
    "start": "1878399",
    "end": "1885679"
  },
  {
    "text": "higher um but I we we tuned the top the top PE to prevent the gibberish from",
    "start": "1885679",
    "end": "1893080"
  },
  {
    "text": "coming out yeah yeah that was actually a yeah that was a fun sort of I guess like",
    "start": "1893080",
    "end": "1898600"
  },
  {
    "text": "practical experiment like we found that like if we can increase the temperature slightly and then constrain top PE a",
    "start": "1898600",
    "end": "1904919"
  },
  {
    "text": "little bit uh we increase the likelihood for our tutor to behave and start you",
    "start": "1904919",
    "end": "1910600"
  },
  {
    "text": "know like not just sounding like a large language model you know what I mean like it wasn't so roote it was much more like",
    "start": "1910600",
    "end": "1917360"
  },
  {
    "text": "uh you know engaged and had a bit more personality which I think is something people are are critical with the open AI",
    "start": "1917360",
    "end": "1923080"
  },
  {
    "text": "models about they become a little lobotomized and just like boring uh but yeah you can play with it you can play",
    "start": "1923080",
    "end": "1929039"
  },
  {
    "text": "with the parameters and I think you can find some really interesting results that way I think some of the work in uh",
    "start": "1929039",
    "end": "1935960"
  },
  {
    "text": "attention syns also I I think that was a paper I read recently is kind of interesting in like maybe a model for",
    "start": "1935960",
    "end": "1942559"
  },
  {
    "text": "looking at context Windows 2 of storing some of the original conversations",
    "start": "1942559",
    "end": "1948000"
  },
  {
    "text": "um or original messages from the beginning and then only changing out a certain amount at the later part of the",
    "start": "1948000",
    "end": "1954480"
  },
  {
    "text": "window um I you know that paper showed a lot of results and kind of just",
    "start": "1954480",
    "end": "1959679"
  },
  {
    "text": "improving the coherency sorry one thing that I'll also",
    "start": "1959679",
    "end": "1965159"
  },
  {
    "text": "add um you know I think like um like yes the data format that you guys are using",
    "start": "1965159",
    "end": "1971399"
  },
  {
    "text": "is a vector store which maybe isn't as like you know as novel as like a graph",
    "start": "1971399",
    "end": "1976760"
  },
  {
    "text": "or something something but I want to like I think like one this is extremely similar to what the generative agents",
    "start": "1976760",
    "end": "1982240"
  },
  {
    "text": "paper did um and two it's it's more than just a vector store like you because you guys aren't just storing the raw events",
    "start": "1982240",
    "end": "1987559"
  },
  {
    "text": "you're storing like the reflections of the llms and I think like that's like the um you know like the new thing here",
    "start": "1987559",
    "end": "1996159"
  },
  {
    "text": "isn't like the new thing here isn't data structures it's llms and there's about",
    "start": "1996159",
    "end": "2002360"
  },
  {
    "text": "like what the best data structure for an llm is but that's a separate thing like the new thing here is the llm and I think taking advantage of that to store",
    "start": "2002360",
    "end": "2008679"
  },
  {
    "text": "these Reflections is like really really powerful even if the data structure itself seems incredibly similar to like",
    "start": "2008679",
    "end": "2015240"
  },
  {
    "text": "some of the standard like you know just oh you get started with Vector stores off of rag it's actually like you've got",
    "start": "2015240",
    "end": "2020320"
  },
  {
    "text": "this layer of the llm reflection and I think that's the powerful bit here and so yeah AB absolutely it's it's what's",
    "start": "2020320",
    "end": "2027600"
  },
  {
    "text": "in the data not how it's stored yeah yeah could agree more um this is an",
    "start": "2027600",
    "end": "2035399"
  },
  {
    "text": "interesting question so um um it's interesting to see new llm Frameworks emerge to mimic human brains but how",
    "start": "2035399",
    "end": "2041919"
  },
  {
    "text": "soon do you think we'll start seeing more ways to improve LM capabilities that aren't modeled after human B brains",
    "start": "2041919",
    "end": "2048240"
  },
  {
    "text": "um and maybe tying this into some of the stuff like a lot of the research here is based off of like you know developmental psychology for kind of like humans do",
    "start": "2048240",
    "end": "2055280"
  },
  {
    "text": "you think that maybe fall short in some areas and there's some kind of like we could we could get to better responses",
    "start": "2055280",
    "end": "2062040"
  },
  {
    "text": "if this very open-ended but yeah I don't I don't know if you have any kind of like thoughts on like are you guys going",
    "start": "2062040",
    "end": "2067960"
  },
  {
    "text": "to continue like pursuing kind of like existing developmental psychology ideas",
    "start": "2067960",
    "end": "2073599"
  },
  {
    "text": "um are you very open-ended but I thought it was yeah yeah yeah we think uh we",
    "start": "2073599",
    "end": "2080320"
  },
  {
    "text": "think I mean we think a ton about um about where we can leverage the edge of",
    "start": "2080320",
    "end": "2087638"
  },
  {
    "text": "like lots of different seemingly disper domains I mean cognitive Sciences is you know kind of an obvious connected one",
    "start": "2087639",
    "end": "2094760"
  },
  {
    "text": "but um but yeah we we play to to you know we we think a whole lot about um about theories about how the",
    "start": "2094760",
    "end": "2103760"
  },
  {
    "text": "brain works in in cognitive science and and it's you know its connected fields and and how we might leverage those",
    "start": "2103760",
    "end": "2109880"
  },
  {
    "text": "things but but yeah totally agree that there's like there's probably like an entire space of over hun capabilities",
    "start": "2109880",
    "end": "2117079"
  },
  {
    "text": "that we're not even we're not really aware of and I'm not sure that we're going to like find out what those like",
    "start": "2117079",
    "end": "2124160"
  },
  {
    "text": "AI or llm native method are unless we just like keep trying to like we keep",
    "start": "2124160",
    "end": "2131119"
  },
  {
    "text": "sort of like working down the list of what we know about uh about like how reasoning can be done um based on you",
    "start": "2131119",
    "end": "2137200"
  },
  {
    "text": "know like what we see in biological brains um but yeah like I have no have",
    "start": "2137200",
    "end": "2142640"
  },
  {
    "text": "no doubt that there are like um there are re like truly novel I guess",
    "start": "2142640",
    "end": "2148960"
  },
  {
    "text": "reasoning capabilities or or other intellectual processes that are possible",
    "start": "2148960",
    "end": "2154680"
  },
  {
    "text": "with um with l because they like they really are um they really are like a a",
    "start": "2154680",
    "end": "2162040"
  },
  {
    "text": "different kind of intelligence right they're excellent at simulating I mean they're exod simulating in general and",
    "start": "2162040",
    "end": "2167960"
  },
  {
    "text": "so the fact that they can simulate um you know human processes are are is is",
    "start": "2167960",
    "end": "2173520"
  },
  {
    "text": "really impressive but like yeah they could they could presumably simulate um",
    "start": "2173520",
    "end": "2180200"
  },
  {
    "text": "you know anything else we can Tre about yeah um next question I think is top of",
    "start": "2180200",
    "end": "2187640"
  },
  {
    "text": "people's minds on a lot of things but how did you measure the performance of these heris stics and what did you learn",
    "start": "2187640",
    "end": "2192880"
  },
  {
    "text": "about the relevance of those benchmarks so yeah evaluation like how do you evaluate something like this yeah so uh what we did was uh the",
    "start": "2192880",
    "end": "2203040"
  },
  {
    "text": "existing theory of Mind sort of benchmarks weren't really uh suited for our use case because ours is like",
    "start": "2203040",
    "end": "2209240"
  },
  {
    "text": "conversational like social cognition type stuff and so like we want to create",
    "start": "2209240",
    "end": "2214319"
  },
  {
    "text": "much more sort of like robust academic um uh benchmarks for these types of things but the best we could do was sort",
    "start": "2214319",
    "end": "2219400"
  },
  {
    "text": "of run an AB test on the back end of Bloom and so we had uh a period of time",
    "start": "2219400",
    "end": "2224880"
  },
  {
    "text": "where if you signed into the uh the interface on chat. bloom. uh there was",
    "start": "2224880",
    "end": "2230560"
  },
  {
    "text": "like 50% chance You Got Served the version of Bloom that's like strictly",
    "start": "2230560",
    "end": "2236200"
  },
  {
    "text": "what we have in the open source uh repo or uh or You Got Served the version where we were running this metacognitive",
    "start": "2236200",
    "end": "2243400"
  },
  {
    "text": "like prompting framework on the back end and uh yeah what we did was we we evaluated the performance of whether or",
    "start": "2243400",
    "end": "2250119"
  },
  {
    "text": "not doing this entire like you know like huge chain of of of prompts was worth it",
    "start": "2250119",
    "end": "2256000"
  },
  {
    "text": "by uh seeing if it was uh improving the language model's ability to predict what the user was going to say and uh we used",
    "start": "2256000",
    "end": "2265200"
  },
  {
    "text": "the language model itself to evaluate um its performance so like we would like",
    "start": "2265200",
    "end": "2271000"
  },
  {
    "text": "that's the eval the eval repo is open source and that's on classic Labs GitHub",
    "start": "2271000",
    "end": "2276040"
  },
  {
    "text": "repo um so what we said was like okay here's what we thought they were going to say here's what they actually said uh on a",
    "start": "2276040",
    "end": "2281920"
  },
  {
    "text": "scale of 1 to five rate your accuracy yeah you're and so what we",
    "start": "2281920",
    "end": "2287119"
  },
  {
    "text": "found was that uh with the with the violation of expectation framework running in the",
    "start": "2287119",
    "end": "2293240"
  },
  {
    "text": "background uh it made the language model more right in its predictions and less",
    "start": "2293240",
    "end": "2299079"
  },
  {
    "text": "wrong in its predictions uh over time and uh yeah ran ran a kisare test on on",
    "start": "2299079",
    "end": "2305720"
  },
  {
    "text": "that and so uh you can read yeah you can you can see the details of that in in the paper um",
    "start": "2305720",
    "end": "2311599"
  },
  {
    "text": "we're actually working on uh you updating the the results right now",
    "start": "2311599",
    "end": "2318760"
  },
  {
    "text": "so um all right next one I also think is interesting how do you like have did you",
    "start": "2320400",
    "end": "2327599"
  },
  {
    "text": "guys try to assess how much coverage of psychological facts you already have so like based on interactions and the",
    "start": "2327599",
    "end": "2334720"
  },
  {
    "text": "number of vectors that you have how how well do you actually know the user that's a great question",
    "start": "2334720",
    "end": "2343119"
  },
  {
    "text": "um currently it is just like based on",
    "start": "2343119",
    "end": "2348640"
  },
  {
    "text": "whether or not we're storing new facts we actually haven't really dove into like in aggregate like how many times uh",
    "start": "2348640",
    "end": "2357079"
  },
  {
    "text": "it's sort of deducing that there's no new facts to store um but that's a super",
    "start": "2357079",
    "end": "2363319"
  },
  {
    "text": "super interesting thing I think that's like kind of on on at least of mine for me um as we as we uh head into the",
    "start": "2363319",
    "end": "2370079"
  },
  {
    "text": "future like on the road mapap of things to do um but yeah I I",
    "start": "2370079",
    "end": "2377520"
  },
  {
    "text": "think the idea is that these improve with you know in aggregate uh courand",
    "start": "2377520",
    "end": "2383119"
  },
  {
    "text": "speaks a little bit about this yeah yeah I mean you know we",
    "start": "2383119",
    "end": "2388400"
  },
  {
    "text": "certainly found that um that like it makes it's making you the model is making better predictions about",
    "start": "2388400",
    "end": "2394319"
  },
  {
    "text": "individuals right it's less wrong it's more right it's doing impressive synthesis but yeah we haven't we haven't",
    "start": "2394319",
    "end": "2399960"
  },
  {
    "text": "like jumped right jumped into um all of the types of things just learning and",
    "start": "2399960",
    "end": "2405599"
  },
  {
    "text": "how we might cluster those and and and think about those and then like where the where the gaps are um but uh yeah I",
    "start": "2405599",
    "end": "2413440"
  },
  {
    "text": "think it's a great question you asked I forgot yeah no no no that was it that",
    "start": "2413440",
    "end": "2418880"
  },
  {
    "text": "was it Javier if that sounds interesting uh hit us up love to shat about",
    "start": "2418880",
    "end": "2424160"
  },
  {
    "text": "it um this is a fun one was was the name Bloom influenced by Bloom's",
    "start": "2424480",
    "end": "2430319"
  },
  {
    "text": "taxonomy yes uh yeah originally like blooms to Sigma problem right that uh",
    "start": "2430319",
    "end": "2435960"
  },
  {
    "text": "that it's possible for one toone instruction to produce uh results uh",
    "start": "2435960",
    "end": "2442640"
  },
  {
    "text": "yeah two standard deviations better than one to many classroom",
    "start": "2442640",
    "end": "2448319"
  },
  {
    "text": "paradigms so yeah we thought that um that you know like the Advent devs repr represents like a big you know a huge",
    "start": "2448440",
    "end": "2455480"
  },
  {
    "text": "opportunity to to bring to normalize one toone instruction for like orders of",
    "start": "2455480",
    "end": "2460680"
  },
  {
    "text": "magnitude lower cost um actually we talk a whole lot about like a lot of these how a lot of these AI tutors and chat",
    "start": "2460680",
    "end": "2466480"
  },
  {
    "text": "Bots right now are um are essentially still like one to many tools because everyone's kind of getting the same",
    "start": "2466480",
    "end": "2473960"
  },
  {
    "text": "thing the same out of the box thing and like you know there's watermarks on lots of these tools asking to just not to",
    "start": "2473960",
    "end": "2479960"
  },
  {
    "text": "share personal information and you know and and uh but so like re to really",
    "start": "2479960",
    "end": "2487160"
  },
  {
    "text": "realize like what onetoone instruction means they it has to not just be like you know an OnDemand learning companion",
    "start": "2487160",
    "end": "2494359"
  },
  {
    "text": "um that you can access any time but it has to be personalized right it has to learn about you and it has to be able to meet you where you are and it has to",
    "start": "2494359",
    "end": "2500960"
  },
  {
    "text": "think about novel ways to produce learning outcomes for you just like an expert tutor would and so I think the",
    "start": "2500960",
    "end": "2507119"
  },
  {
    "text": "the way to do this is to for it to get really good at theory of Mind prediction because that's like I me that's what",
    "start": "2507119",
    "end": "2512760"
  },
  {
    "text": "teachers spend that's what you know that's what makes it a great teacher grade right if they're in a setting",
    "start": "2512760",
    "end": "2518119"
  },
  {
    "text": "where they're able to um you know form more substantive relationships with their students then um then that's a big",
    "start": "2518119",
    "end": "2525680"
  },
  {
    "text": "part of what they're doing right they're constantly thinking you know they're constantly building psychological models",
    "start": "2525680",
    "end": "2531119"
  },
  {
    "text": "of each student in their charge and thinking about how that can uh how they",
    "start": "2531119",
    "end": "2536520"
  },
  {
    "text": "can create a learning outcome for them and and then how like how those models intersect with one another right and how",
    "start": "2536520",
    "end": "2542400"
  },
  {
    "text": "they could create you know a learning outcome for the levera you know the class to create a learning outcome and",
    "start": "2542400",
    "end": "2548280"
  },
  {
    "text": "so um yeah we think that you know Frameworks like this are the beginning",
    "start": "2548280",
    "end": "2553640"
  },
  {
    "text": "of getting to a place where um where we actually can realize uh and normalize",
    "start": "2553640",
    "end": "2559720"
  },
  {
    "text": "like the solve blooms to Sigma",
    "start": "2559720",
    "end": "2564119"
  },
  {
    "text": "problem um another one that I like is and this goes back to the memory bit and I know we chatted a lot about this um",
    "start": "2565200",
    "end": "2571880"
  },
  {
    "text": "and I think we said how how Vector stores were um you know it's not just vector stores it's kind of like adding",
    "start": "2571880",
    "end": "2577160"
  },
  {
    "text": "things into Vector stores but did you see any kind of like edge cases or limitations of storing things in a",
    "start": "2577160",
    "end": "2582839"
  },
  {
    "text": "vector store and retrieving them kind of like based on on semantic similarity um",
    "start": "2582839",
    "end": "2588359"
  },
  {
    "text": "was there was there any examples where more structure might come into play or was it pretty fine for everything that",
    "start": "2588359",
    "end": "2594359"
  },
  {
    "text": "you guys [Music]",
    "start": "2594359",
    "end": "2600249"
  },
  {
    "text": "saw know I don't think we particularly ran into any Edge case",
    "start": "2601160",
    "end": "2606640"
  },
  {
    "text": "is but I think you know this raises a question of like there's probably or not probably",
    "start": "2606640",
    "end": "2614520"
  },
  {
    "text": "there is like open research to be done on like ways to push this even further and like push what is semantically good",
    "start": "2614520",
    "end": "2622119"
  },
  {
    "text": "or not I mean we've already kind of seen that like letting the model decide has really given us really strong",
    "start": "2622119",
    "end": "2630880"
  },
  {
    "text": "results on like deciding what's important or not and like you know maybe there's some prayer paradigms here to",
    "start": "2630880",
    "end": "2636839"
  },
  {
    "text": "expand that for rag um and not just relying on like the text embedding model",
    "start": "2636839",
    "end": "2644200"
  },
  {
    "text": "but also some more like cognitive information and that we're still kind of",
    "start": "2644200",
    "end": "2650800"
  },
  {
    "text": "exploring all the ways in which this data can this data is being used and can be can be used by the language model",
    "start": "2650800",
    "end": "2657480"
  },
  {
    "text": "like we're we're very intentionally giving the language Model A lot of",
    "start": "2657480",
    "end": "2662800"
  },
  {
    "text": "autonomy to decide how to respond and like given this information we've seen some really interesting emergent",
    "start": "2662800",
    "end": "2668680"
  },
  {
    "text": "Behavior but like yeah like courland was talking about like the the uh overhung",
    "start": "2668680",
    "end": "2674520"
  },
  {
    "text": "capabilities the space of overhung capabilities that we think is still quite Broad and so like all we're doing is trying to like increase the context",
    "start": "2674520",
    "end": "2681680"
  },
  {
    "text": "that the model has in order to explore that space more so yeah it's it's it's it's",
    "start": "2681680",
    "end": "2689520"
  },
  {
    "text": "subjective by Nature so like I don't know that we hit too many like clear limits but like yeah it's a super",
    "start": "2689520",
    "end": "2695280"
  },
  {
    "text": "interesting problem that makes sense there's another um good question um around basically uh",
    "start": "2695280",
    "end": "2703480"
  },
  {
    "text": "shortterm versus long-term memory um so like you know what might be relevant for",
    "start": "2703480",
    "end": "2709160"
  },
  {
    "text": "them in a conversation is maybe you know not a defining characteristic of them",
    "start": "2709160",
    "end": "2714839"
  },
  {
    "text": "and so there's that difference there H H how do you kind of like think about that",
    "start": "2714839",
    "end": "2720800"
  },
  {
    "text": "like is is the is the vector store aimed entirely at only like this more like long-term type things and then you just",
    "start": "2720800",
    "end": "2727359"
  },
  {
    "text": "expect short-term things to be within the conversation itself um",
    "start": "2727359",
    "end": "2734480"
  },
  {
    "text": "yeah I think the the vector store is right now primarily focused on",
    "start": "2734480",
    "end": "2740359"
  },
  {
    "text": "storing the psychological data and because we built the tutor in such a way",
    "start": "2740359",
    "end": "2745760"
  },
  {
    "text": "that it's sort of like at every conversation turn",
    "start": "2745760",
    "end": "2750800"
  },
  {
    "text": "updating its I like its uh thoughts on how to best serve the student",
    "start": "2750800",
    "end": "2756880"
  },
  {
    "text": "uh we are intentionally sort of like trying to solve for short and long-term",
    "start": "2756880",
    "end": "2762839"
  },
  {
    "text": "memory there like uh at any given point in the conversation it should be able to",
    "start": "2762839",
    "end": "2768319"
  },
  {
    "text": "change the way it's thinking about a student which would inform the uh the",
    "start": "2768319",
    "end": "2774720"
  },
  {
    "text": "things that it would think would improve its prediction so like that's like how the",
    "start": "2774720",
    "end": "2780960"
  },
  {
    "text": "query gets formed over the vector store uh and so yeah like it's we try to",
    "start": "2780960",
    "end": "2786119"
  },
  {
    "text": "subvert that problem as best we can I think is it would be my answer you guys",
    "start": "2786119",
    "end": "2791839"
  },
  {
    "text": "have anything to add yeah I I mean the vector story is more just like facts about the person",
    "start": "2791839",
    "end": "2799760"
  },
  {
    "text": "and like characteristics about them versus the chat history is like kind of like what's going on in the moment so I",
    "start": "2799760",
    "end": "2806520"
  },
  {
    "text": "think just that split there is already kind of like a long term versus short-term thing but to Vince's Point",
    "start": "2806520",
    "end": "2812960"
  },
  {
    "text": "like letting the model be as fluid as possible so that it can really adapt um",
    "start": "2812960",
    "end": "2819240"
  },
  {
    "text": "just kind of makes it so you know it figures it out yeah I",
    "start": "2819240",
    "end": "2824680"
  },
  {
    "text": "think we you know like a big relatively like a big uh direction of future inquiry for us too is like what kind of",
    "start": "2824680",
    "end": "2830880"
  },
  {
    "text": "async reasoning we can be doing over the vector store in the psychological model um yeah and what kind of facts can you",
    "start": "2830880",
    "end": "2838559"
  },
  {
    "text": "know during a conversation or interaction in some other Paradigm like what kind of facts can we keep on deck or what kinds of like reasoning products",
    "start": "2838559",
    "end": "2845119"
  },
  {
    "text": "can we keep on deck that might be leveraged in you know in the conversation or the image generation or",
    "start": "2845119",
    "end": "2850880"
  },
  {
    "text": "whatever it is that you're that you're trying to",
    "start": "2850880",
    "end": "2854720"
  },
  {
    "text": "do sense",
    "start": "2856319",
    "end": "2861920"
  },
  {
    "text": "um well I think um I think that's probably brings us to the the end of the",
    "start": "2867680",
    "end": "2874119"
  },
  {
    "text": "webinar there's a lot of questions in the chat around um how people can keep on talking about this because I think",
    "start": "2874119",
    "end": "2879680"
  },
  {
    "text": "there are a lot of different things that that we could go down and I see some existing questions and so I know you",
    "start": "2879680",
    "end": "2884800"
  },
  {
    "text": "guys yeah youve got the Discord so that's probably the best place to take some of these um uh uh questions um",
    "start": "2884800",
    "end": "2891240"
  },
  {
    "text": "anything you guys want to leave us with final words of wisdom",
    "start": "2891240",
    "end": "2897119"
  },
  {
    "text": "thoughts no super excited with what you guys are doing over at Lang chain and Lang serf stuff we see this like the",
    "start": "2897119",
    "end": "2904520"
  },
  {
    "text": "evolution of the space being really conducive to what we're trying to do is give agents uh more sort of like tools",
    "start": "2904520",
    "end": "2911480"
  },
  {
    "text": "to to think about and augment their their behavior so um Cory you want to add anything no I mean I would just say",
    "start": "2911480",
    "end": "2918720"
  },
  {
    "text": "like you know I mean our ultimate goal is to be able to trust agents to be like",
    "start": "2918720",
    "end": "2924119"
  },
  {
    "text": "as autonomous and as capable as possible and so bringing them into like um",
    "start": "2924119",
    "end": "2929839"
  },
  {
    "text": "extremely close coherence with your psychology we think is a is like a major component there and so so we want to",
    "start": "2929839",
    "end": "2936319"
  },
  {
    "text": "build tools that that enable that and um and yeah so we're um we're also talking",
    "start": "2936319",
    "end": "2941359"
  },
  {
    "text": "we're talking about how we can like generalize this and make it into make it into a horizontal service and so um yeah",
    "start": "2941359",
    "end": "2949040"
  },
  {
    "text": "um we'd love to talk to anybody that's interested and uh interested in working on these problems or um you know using",
    "start": "2949040",
    "end": "2955680"
  },
  {
    "text": "some of these features or plugging the stuff in yeah and just last thing is like",
    "start": "2955680",
    "end": "2962160"
  },
  {
    "text": "we're really big on open source so like we really welcome anyone to come in and",
    "start": "2962160",
    "end": "2967440"
  },
  {
    "text": "you know if you feel like we made bad decisions about how things are built like let raise a PR we'll we can talk",
    "start": "2967440",
    "end": "2973680"
  },
  {
    "text": "about it yeah and you guys have some great repos as well both the eval and then and",
    "start": "2973680",
    "end": "2979240"
  },
  {
    "text": "then uh the tutor GPT repo that I would encourage everyone to check out um all",
    "start": "2979240",
    "end": "2984920"
  },
  {
    "text": "right well I really appreciate you guys coming on I'm really interested in this topic and this is uh this is one of the",
    "start": "2984920",
    "end": "2990119"
  },
  {
    "text": "best papers I think I've seen on this topic since like the generative agents paper like in my mind these are like the two kind of like most interesting things",
    "start": "2990119",
    "end": "2996640"
  },
  {
    "text": "in that space um so yeah you know really appreciate it and and looking forward to",
    "start": "2996640",
    "end": "3002640"
  },
  {
    "text": "hearing more about what you guys get up to and and thank you everyone for tuning in this was uh this was definitely one",
    "start": "3002640",
    "end": "3009319"
  },
  {
    "text": "of the more engaged webinars that we've had just in terms of messages so I think you can like everyone's really",
    "start": "3009319",
    "end": "3014359"
  },
  {
    "text": "interested in this topic and so I'm sure uh there's some good conversation to be had offline as well all right goodbye",
    "start": "3014359",
    "end": "3021200"
  },
  {
    "text": "everyone thanks thanks for coming everyone bye",
    "start": "3021200",
    "end": "3027440"
  },
  {
    "text": "yeah",
    "start": "3027920",
    "end": "3030920"
  }
]
[
  {
    "start": "0",
    "end": "25000"
  },
  {
    "text": "hey this is lanch Lang Cham anthropic",
    "start": "40",
    "end": "2120"
  },
  {
    "text": "just released clae 37 now this is a",
    "start": "2120",
    "end": "4359"
  },
  {
    "text": "really exciting development from",
    "start": "4359",
    "end": "6200"
  },
  {
    "text": "anthropic because it's their first",
    "start": "6200",
    "end": "8000"
  },
  {
    "text": "explicit reasoning model and let me just",
    "start": "8000",
    "end": "10719"
  },
  {
    "text": "show how to use it and then talk a",
    "start": "10719",
    "end": "12440"
  },
  {
    "text": "little bit about how it works so first",
    "start": "12440",
    "end": "14120"
  },
  {
    "text": "you're just going to install L anthropic",
    "start": "14120",
    "end": "15879"
  },
  {
    "text": "make sure AP API key is set you're going",
    "start": "15879",
    "end": "18119"
  },
  {
    "text": "to select Claude 37 latest as your model",
    "start": "18119",
    "end": "21119"
  },
  {
    "text": "now this is where things are a bit new",
    "start": "21119",
    "end": "22760"
  },
  {
    "text": "you can set max tokens for your response",
    "start": "22760",
    "end": "24680"
  },
  {
    "text": "just like before but you can also set",
    "start": "24680",
    "end": "26720"
  },
  {
    "start": "25000",
    "end": "42000"
  },
  {
    "text": "this thinking parameter and a budget for",
    "start": "26720",
    "end": "29080"
  },
  {
    "text": "thinking tokens I'll talk more about",
    "start": "29080",
    "end": "30640"
  },
  {
    "text": "this later passing an input now the",
    "start": "30640",
    "end": "32398"
  },
  {
    "text": "response is an AI message just like",
    "start": "32399",
    "end": "34840"
  },
  {
    "text": "normal but what's new here is that it's",
    "start": "34840",
    "end": "36800"
  },
  {
    "text": "actually a list and this output actually",
    "start": "36800",
    "end": "39719"
  },
  {
    "text": "has two blocks so one is a thinking",
    "start": "39719",
    "end": "41920"
  },
  {
    "text": "block and the other is the response now",
    "start": "41920",
    "end": "44600"
  },
  {
    "start": "42000",
    "end": "75000"
  },
  {
    "text": "what's interesting here is anthropic",
    "start": "44600",
    "end": "46600"
  },
  {
    "text": "made the decision to actually expose the",
    "start": "46600",
    "end": "48320"
  },
  {
    "text": "thinking to the user so we can see",
    "start": "48320",
    "end": "50440"
  },
  {
    "text": "claud's full thinking process",
    "start": "50440",
    "end": "51879"
  },
  {
    "text": "transparently in this thinking block and",
    "start": "51879",
    "end": "54359"
  },
  {
    "text": "then we can see the final answer",
    "start": "54359",
    "end": "56480"
  },
  {
    "text": "provided we can open a lsmith and see",
    "start": "56480",
    "end": "58640"
  },
  {
    "text": "the overall latency 20 seconds as well",
    "start": "58640",
    "end": "61239"
  },
  {
    "text": "as the full output with the thinking",
    "start": "61239",
    "end": "63879"
  },
  {
    "text": "block and the text block now this model",
    "start": "63879",
    "end": "65880"
  },
  {
    "text": "is also compatible with building agents",
    "start": "65880",
    "end": "67960"
  },
  {
    "text": "so I'll build a simple agent here with",
    "start": "67960",
    "end": "69680"
  },
  {
    "text": "three arithmetic tools we'll just use",
    "start": "69680",
    "end": "71720"
  },
  {
    "text": "Lang graph pre-built for a classic react",
    "start": "71720",
    "end": "74360"
  },
  {
    "text": "style tool calling agent and we'll go",
    "start": "74360",
    "end": "76040"
  },
  {
    "start": "75000",
    "end": "98000"
  },
  {
    "text": "ahead and run that by passing ad 3+4 and",
    "start": "76040",
    "end": "78400"
  },
  {
    "text": "we can see something pretty cool here in",
    "start": "78400",
    "end": "79960"
  },
  {
    "text": "the AI message we can see this thinking",
    "start": "79960",
    "end": "82439"
  },
  {
    "text": "block present and this is actually very",
    "start": "82439",
    "end": "84439"
  },
  {
    "text": "nice with tool use because it actually",
    "start": "84439",
    "end": "86439"
  },
  {
    "text": "tells you its thinking around when and",
    "start": "86439",
    "end": "88920"
  },
  {
    "text": "why to use a specific tool so you can",
    "start": "88920",
    "end": "90640"
  },
  {
    "text": "see the user asking to add numbers this",
    "start": "90640",
    "end": "92840"
  },
  {
    "text": "is arithmetic and I have access to the",
    "start": "92840",
    "end": "95720"
  },
  {
    "text": "add function which is suitable for this",
    "start": "95720",
    "end": "97360"
  },
  {
    "text": "task that's really cool because often",
    "start": "97360",
    "end": "99320"
  },
  {
    "start": "98000",
    "end": "132000"
  },
  {
    "text": "times you don't know why models are",
    "start": "99320",
    "end": "100680"
  },
  {
    "text": "actually choosing to call tools so it's",
    "start": "100680",
    "end": "102600"
  },
  {
    "text": "great in this case to see that visibly",
    "start": "102600",
    "end": "104479"
  },
  {
    "text": "it chooses to call the tool there's your",
    "start": "104479",
    "end": "106000"
  },
  {
    "text": "tool call is normal we get the tool",
    "start": "106000",
    "end": "107479"
  },
  {
    "text": "message back we get a response so these",
    "start": "107479",
    "end": "109920"
  },
  {
    "text": "thinking models are entirely compatible",
    "start": "109920",
    "end": "111479"
  },
  {
    "text": "with building agents with tool calling",
    "start": "111479",
    "end": "113799"
  },
  {
    "text": "as you'd expect now I just want to talk",
    "start": "113799",
    "end": "116000"
  },
  {
    "text": "about this a little bit more in general",
    "start": "116000",
    "end": "117399"
  },
  {
    "text": "terms so we have some prior videos",
    "start": "117399",
    "end": "119399"
  },
  {
    "text": "discussing chat models versus reasoning",
    "start": "119399",
    "end": "121119"
  },
  {
    "text": "models in general they're using two",
    "start": "121119",
    "end": "123200"
  },
  {
    "text": "different scaling paradigms chat models",
    "start": "123200",
    "end": "125240"
  },
  {
    "text": "being nextto prediction reasoning models",
    "start": "125240",
    "end": "127079"
  },
  {
    "text": "being RL on Chain of Thought different",
    "start": "127079",
    "end": "129479"
  },
  {
    "text": "reasoning types System One versus system",
    "start": "129479",
    "end": "131400"
  },
  {
    "text": "2 I show a little bit below often the",
    "start": "131400",
    "end": "134000"
  },
  {
    "start": "132000",
    "end": "165000"
  },
  {
    "text": "way you instruct the model differs a bit",
    "start": "134000",
    "end": "135560"
  },
  {
    "text": "for reasoning models versus chat models",
    "start": "135560",
    "end": "137360"
  },
  {
    "text": "and again the interaction modes are a",
    "start": "137360",
    "end": "139120"
  },
  {
    "text": "bit different whereas chat models are",
    "start": "139120",
    "end": "141040"
  },
  {
    "text": "typically strong for short firm chat",
    "start": "141040",
    "end": "143640"
  },
  {
    "text": "conversation reason models are better",
    "start": "143640",
    "end": "145800"
  },
  {
    "text": "for longer running reasoning heavy tasks",
    "start": "145800",
    "end": "149480"
  },
  {
    "text": "so just with other reing models have",
    "start": "149480",
    "end": "151040"
  },
  {
    "text": "been released for example from we saw",
    "start": "151040",
    "end": "152599"
  },
  {
    "text": "from R1 we saw from open AI Cloud 37 is",
    "start": "152599",
    "end": "156080"
  },
  {
    "text": "post-t trained with reinforcement",
    "start": "156080",
    "end": "157440"
  },
  {
    "text": "learning now what's need is they do",
    "start": "157440",
    "end": "159800"
  },
  {
    "text": "expose the reing traces to the user",
    "start": "159800",
    "end": "161879"
  },
  {
    "text": "what's also interesting is they give a",
    "start": "161879",
    "end": "163319"
  },
  {
    "text": "lot of control over how long the model",
    "start": "163319",
    "end": "165000"
  },
  {
    "start": "165000",
    "end": "195000"
  },
  {
    "text": "can think for with O Series models",
    "start": "165000",
    "end": "167040"
  },
  {
    "text": "there's qualitative reasoning tiers like",
    "start": "167040",
    "end": "170280"
  },
  {
    "text": "medium and high with claw 37 you can",
    "start": "170280",
    "end": "172640"
  },
  {
    "text": "explicitly instruct the model to use a",
    "start": "172640",
    "end": "176159"
  },
  {
    "text": "particular thinking budget of tokens",
    "start": "176159",
    "end": "178680"
  },
  {
    "text": "with Max tokens being the maximum number",
    "start": "178680",
    "end": "180440"
  },
  {
    "text": "of tokens to generate before stopping",
    "start": "180440",
    "end": "182840"
  },
  {
    "text": "and the thinking budget being the number",
    "start": "182840",
    "end": "184239"
  },
  {
    "text": "of tokens you allocate for the thinking",
    "start": "184239",
    "end": "186000"
  },
  {
    "text": "process now a few other interesting",
    "start": "186000",
    "end": "187400"
  },
  {
    "text": "things about this model it has an",
    "start": "187400",
    "end": "188799"
  },
  {
    "text": "October 2024 knowledge cut off which is",
    "start": "188799",
    "end": "190920"
  },
  {
    "text": "improvement over what we saw previously",
    "start": "190920",
    "end": "192760"
  },
  {
    "text": "and it allows up to 128,000 tokens",
    "start": "192760",
    "end": "195959"
  },
  {
    "start": "195000",
    "end": "225000"
  },
  {
    "text": "output which is potentially interesting",
    "start": "195959",
    "end": "197599"
  },
  {
    "text": "for certain applications now they report",
    "start": "197599",
    "end": "199560"
  },
  {
    "text": "strong performance on software",
    "start": "199560",
    "end": "201799"
  },
  {
    "text": "engineering so sbench verified you can",
    "start": "201799",
    "end": "203599"
  },
  {
    "text": "see it's a big jump over CLA 35 49%",
    "start": "203599",
    "end": "206560"
  },
  {
    "text": "versus 62% and so overall from look at",
    "start": "206560",
    "end": "208920"
  },
  {
    "text": "performance here you can see see there",
    "start": "208920",
    "end": "210040"
  },
  {
    "text": "was a very high emphasis placed on",
    "start": "210040",
    "end": "211760"
  },
  {
    "text": "coding which makes a lot of sense",
    "start": "211760",
    "end": "213280"
  },
  {
    "text": "because Claude 35 Sonet was already one",
    "start": "213280",
    "end": "215280"
  },
  {
    "text": "of the strongest llms for coding",
    "start": "215280",
    "end": "218120"
  },
  {
    "text": "obviously very heavily used in tools",
    "start": "218120",
    "end": "219480"
  },
  {
    "text": "like cursor and this appears to be a",
    "start": "219480",
    "end": "221720"
  },
  {
    "text": "significant jump over 35 Sonet what's",
    "start": "221720",
    "end": "224480"
  },
  {
    "text": "also kind of interesting is if you look",
    "start": "224480",
    "end": "225879"
  },
  {
    "start": "225000",
    "end": "255000"
  },
  {
    "text": "at the pricing so 35 Sonet input tokens",
    "start": "225879",
    "end": "228799"
  },
  {
    "text": "are $3 per million token output are $15",
    "start": "228799",
    "end": "232400"
  },
  {
    "text": "per million",
    "start": "232400",
    "end": "233360"
  },
  {
    "text": "token 35 Sonet is the same now it's",
    "start": "233360",
    "end": "236640"
  },
  {
    "text": "worth noting the number of output tokens",
    "start": "236640",
    "end": "238480"
  },
  {
    "text": "with 37 will frequently larger because",
    "start": "238480",
    "end": "241760"
  },
  {
    "text": "of thinking but the pricing is the same",
    "start": "241760",
    "end": "245680"
  },
  {
    "text": "now some tips for usage anthropic",
    "start": "245680",
    "end": "247879"
  },
  {
    "text": "mentions use this on challenging stem",
    "start": "247879",
    "end": "250319"
  },
  {
    "text": "problems now this is kind of an",
    "start": "250319",
    "end": "251560"
  },
  {
    "text": "interesting thing that they note for",
    "start": "251560",
    "end": "253239"
  },
  {
    "text": "complex tasks consider over 16,000",
    "start": "253239",
    "end": "255720"
  },
  {
    "start": "255000",
    "end": "285000"
  },
  {
    "text": "tokens of thinking budget 4 to 8,000 is",
    "start": "255720",
    "end": "259199"
  },
  {
    "text": "considered acceptable for simpler",
    "start": "259199",
    "end": "261479"
  },
  {
    "text": "reasoning tasks now you'd have to kind",
    "start": "261479",
    "end": "263080"
  },
  {
    "text": "of experiment with that given your",
    "start": "263080",
    "end": "264880"
  },
  {
    "text": "particular needs to see what the right",
    "start": "264880",
    "end": "266280"
  },
  {
    "text": "threshold is for you but that's a nice",
    "start": "266280",
    "end": "268120"
  },
  {
    "text": "thing that give you a lot of control",
    "start": "268120",
    "end": "269320"
  },
  {
    "text": "over the amount of tokens you allocate",
    "start": "269320",
    "end": "270880"
  },
  {
    "text": "for reasoning now of course you have to",
    "start": "270880",
    "end": "272320"
  },
  {
    "text": "think about latency here because as you",
    "start": "272320",
    "end": "273720"
  },
  {
    "text": "bump up the thinking tokens you'll also",
    "start": "273720",
    "end": "275280"
  },
  {
    "text": "bump up the latency and also they also",
    "start": "275280",
    "end": "277160"
  },
  {
    "text": "made some interesting notes on very long",
    "start": "277160",
    "end": "279479"
  },
  {
    "text": "outputs you can actually request a",
    "start": "279479",
    "end": "281240"
  },
  {
    "text": "detailed outline with word counts down",
    "start": "281240",
    "end": "283400"
  },
  {
    "text": "to the paragraph level if you want and",
    "start": "283400",
    "end": "285240"
  },
  {
    "start": "285000",
    "end": "300000"
  },
  {
    "text": "you can ask clct to index paragraphs to",
    "start": "285240",
    "end": "287080"
  },
  {
    "text": "the outline and maintain specific word",
    "start": "287080",
    "end": "289240"
  },
  {
    "text": "counts so you actually have a lot of",
    "start": "289240",
    "end": "290880"
  },
  {
    "text": "potential configurability in control",
    "start": "290880",
    "end": "293240"
  },
  {
    "text": "over these very long generation outputs",
    "start": "293240",
    "end": "295880"
  },
  {
    "text": "and that's another thing that's worth",
    "start": "295880",
    "end": "297080"
  },
  {
    "text": "experimenting with a bit some nice",
    "start": "297080",
    "end": "298520"
  },
  {
    "text": "tricks they mention with respect to",
    "start": "298520",
    "end": "299759"
  },
  {
    "text": "prompting avoid predetermined",
    "start": "299759",
    "end": "301360"
  },
  {
    "start": "300000",
    "end": "330000"
  },
  {
    "text": "instructions like when you're working",
    "start": "301360",
    "end": "302479"
  },
  {
    "text": "with chat models you often think about",
    "start": "302479",
    "end": "304479"
  },
  {
    "text": "think through your problem step by step",
    "start": "304479",
    "end": "306080"
  },
  {
    "text": "enumerate the task very",
    "start": "306080",
    "end": "307720"
  },
  {
    "text": "explicitly here think more about General",
    "start": "307720",
    "end": "310080"
  },
  {
    "text": "instructions think about this problem",
    "start": "310080",
    "end": "311919"
  },
  {
    "text": "thoroughly and in great detail consider",
    "start": "311919",
    "end": "313600"
  },
  {
    "text": "multiple approaches so you're not",
    "start": "313600",
    "end": "315680"
  },
  {
    "text": "telling it really how to think",
    "start": "315680",
    "end": "316680"
  },
  {
    "text": "explicitly you're giving it more General",
    "start": "316680",
    "end": "318039"
  },
  {
    "text": "instructions and the task you want",
    "start": "318039",
    "end": "319560"
  },
  {
    "text": "solved now we've seen that same kind of",
    "start": "319560",
    "end": "321800"
  },
  {
    "text": "approach as other reasoning models and",
    "start": "321800",
    "end": "323680"
  },
  {
    "text": "in terms of parameters you know again we",
    "start": "323680",
    "end": "325280"
  },
  {
    "text": "talked about that budget tokens",
    "start": "325280",
    "end": "326560"
  },
  {
    "text": "parameter being quite important we show",
    "start": "326560",
    "end": "328880"
  },
  {
    "text": "that here when working with the model",
    "start": "328880",
    "end": "330639"
  },
  {
    "start": "330000",
    "end": "345000"
  },
  {
    "text": "itself again you're passing your budget",
    "start": "330639",
    "end": "332600"
  },
  {
    "text": "tokens relative to your max tokens where",
    "start": "332600",
    "end": "335240"
  },
  {
    "text": "budget tokens should be less than your",
    "start": "335240",
    "end": "336680"
  },
  {
    "text": "max tokens and just as we showed above",
    "start": "336680",
    "end": "338600"
  },
  {
    "text": "here is example usage and as mentioned",
    "start": "338600",
    "end": "341120"
  },
  {
    "text": "the response is going to have a thinking",
    "start": "341120",
    "end": "342600"
  },
  {
    "text": "block and a response block which you can",
    "start": "342600",
    "end": "344479"
  },
  {
    "text": "very easily segment you can extract the",
    "start": "344479",
    "end": "346800"
  },
  {
    "start": "345000",
    "end": "396000"
  },
  {
    "text": "thinking as well as the text from each",
    "start": "346800",
    "end": "349759"
  },
  {
    "text": "block very easily it is also worth",
    "start": "349759",
    "end": "351360"
  },
  {
    "text": "noting that the thinking block contains",
    "start": "351360",
    "end": "352520"
  },
  {
    "text": "a signature field you might wonder what",
    "start": "352520",
    "end": "354160"
  },
  {
    "text": "that is and it's a cryptographic token",
    "start": "354160",
    "end": "356560"
  },
  {
    "text": "that verifies the thinking block is",
    "start": "356560",
    "end": "357919"
  },
  {
    "text": "generated by claw that's all that is and",
    "start": "357919",
    "end": "359680"
  },
  {
    "text": "you can see that right here if I look at",
    "start": "359680",
    "end": "360840"
  },
  {
    "text": "my my response that first element the in",
    "start": "360840",
    "end": "363560"
  },
  {
    "text": "the thinking block is going to be",
    "start": "363560",
    "end": "365360"
  },
  {
    "text": "signature and then I have my overall",
    "start": "365360",
    "end": "367720"
  },
  {
    "text": "thinking right here so you can see this",
    "start": "367720",
    "end": "369319"
  },
  {
    "text": "is a very interesting and Powerful new",
    "start": "369319",
    "end": "370759"
  },
  {
    "text": "model you can configure the thinking",
    "start": "370759",
    "end": "373560"
  },
  {
    "text": "tokens very precisely it has very long",
    "start": "373560",
    "end": "377080"
  },
  {
    "text": "kind of generation capacity at a state",
    "start": "377080",
    "end": "379280"
  },
  {
    "text": "of their performance across a number of",
    "start": "379280",
    "end": "380759"
  },
  {
    "text": "tasks including coding it works of tool",
    "start": "380759",
    "end": "383960"
  },
  {
    "text": "calling as we showed with our simple",
    "start": "383960",
    "end": "385280"
  },
  {
    "text": "agent example so it should be a really",
    "start": "385280",
    "end": "387639"
  },
  {
    "text": "interesting model to experiment with and",
    "start": "387639",
    "end": "389160"
  },
  {
    "text": "I'm excited to test this further but",
    "start": "389160",
    "end": "391280"
  },
  {
    "text": "just want to give you a quick overview",
    "start": "391280",
    "end": "393120"
  },
  {
    "text": "thanks and feel free to leave any",
    "start": "393120",
    "end": "394360"
  },
  {
    "text": "comments below",
    "start": "394360",
    "end": "397038"
  }
]
[
  {
    "text": "excited for it so before we get started quick logistical things um this is recorded we'll post it on",
    "start": "0",
    "end": "6960"
  },
  {
    "text": "YouTube afterwards um there is a chat box if you look to",
    "start": "6960",
    "end": "12480"
  },
  {
    "text": "the right underneath the chat there's a little q a box and so if you have questions please put them in there and",
    "start": "12480",
    "end": "18359"
  },
  {
    "text": "basically the way that it will work is at the end when we're doing question answering we'll we'll go to that q a box",
    "start": "18359",
    "end": "23460"
  },
  {
    "text": "and we'll look at the ones that are most upvoted so in addition to just adding questions you can also upload once so",
    "start": "23460",
    "end": "28680"
  },
  {
    "text": "that's kind of how we'll pick um the top ones to answer um that's pretty much it in terms of",
    "start": "28680",
    "end": "34980"
  },
  {
    "text": "logistics this will go just about um an hour um today we're doing a deep dive on",
    "start": "34980",
    "end": "41700"
  },
  {
    "text": "quiver so I'm excited to be joined by Stan who's who's the The Mastermind behind quiver",
    "start": "41700",
    "end": "47700"
  },
  {
    "text": "um quiver is uh I'll let stand explain what quiver is but basically the um the",
    "start": "47700",
    "end": "53460"
  },
  {
    "text": "format of this is we'll do a 30 minutes kind of just like walk through of quiver everything related to how it got started",
    "start": "53460",
    "end": "59460"
  },
  {
    "text": "um where it is now future roadmap how to think about it as product versus technology all of those things I'm just",
    "start": "59460",
    "end": "66540"
  },
  {
    "text": "going to Pepper him with questions this is going to be great he'll hopefully give me some good feedback on link chain I'll hopefully give them some good",
    "start": "66540",
    "end": "72479"
  },
  {
    "text": "feedback on quiver and we'll just kind of have a fun conversation and then we'll work in questions from the audience so add the questions to the",
    "start": "72479",
    "end": "79020"
  },
  {
    "text": "question answer Tab and we'll just power through those um",
    "start": "79020",
    "end": "84060"
  },
  {
    "text": "that's basically it as an intro stand do you want to do you want to take it away yeah so hi guys",
    "start": "84060",
    "end": "91560"
  },
  {
    "text": "um I'm Stan from France my 3.8 uh thanks Harrison for the introduction",
    "start": "91560",
    "end": "99360"
  },
  {
    "text": "um well I think we can start uh let me share my screen uh if if we yeah",
    "start": "99360",
    "end": "107040"
  },
  {
    "text": "uh uh okay so let's start at the beginning uh so",
    "start": "107040",
    "end": "113700"
  },
  {
    "text": "quiver uh so for those of you that want to follow a destination you can go to",
    "start": "113700",
    "end": "121020"
  },
  {
    "text": "GitHub Sanjay rather find quiver and for those of you that don't want to go uh",
    "start": "121020",
    "end": "127920"
  },
  {
    "text": "here you can just go to the website um so uh what is quiver so the the ID",
    "start": "127920",
    "end": "136379"
  },
  {
    "text": "behind quiver the at the start was just a place to dump you know all of the",
    "start": "136379",
    "end": "141959"
  },
  {
    "text": "files that you and the knowledge that you encounter every day and be able you know in a week or in two weeks a month",
    "start": "141959",
    "end": "149640"
  },
  {
    "text": "or a year to ask questions about it um because I've been using obsidian for",
    "start": "149640",
    "end": "156480"
  },
  {
    "text": "maybe two years and I've been using notion also a lot and one of the",
    "start": "156480",
    "end": "162540"
  },
  {
    "text": "things that I really like um is the ability to um to quickly dump information into",
    "start": "162540",
    "end": "171540"
  },
  {
    "text": "these tools so on notion you have uh um",
    "start": "171540",
    "end": "177140"
  },
  {
    "text": "things that you can install in Chrome so that you take a button in Gems or the web page in Ocean obsidian same",
    "start": "177140",
    "end": "185519"
  },
  {
    "text": "um and uh yeah so it's when you have a busy day and you don't want to forget information just dump it and it's",
    "start": "185519",
    "end": "192599"
  },
  {
    "text": "something that I like to call a fleeting note so um I used to do you know fitting notes",
    "start": "192599",
    "end": "198780"
  },
  {
    "text": "just dump them into obsidian and then later on in the week come back to a bit",
    "start": "198780",
    "end": "204120"
  },
  {
    "text": "and walk them and create some value out of them and so that was kind of the idea at the beginning is to be able to dump",
    "start": "204120",
    "end": "210540"
  },
  {
    "text": "anything into quiver and then just ask questions so yeah so let's just saw it behind Quaver",
    "start": "210540",
    "end": "218519"
  },
  {
    "text": "um if you want um you can just yeah when when did you",
    "start": "218519",
    "end": "223860"
  },
  {
    "text": "start this just to set the timeline like was this how recent was this it's uh",
    "start": "223860",
    "end": "229739"
  },
  {
    "text": "three and a half weeks ago yeah so the first yeah the first comment is uh",
    "start": "229739",
    "end": "236120"
  },
  {
    "text": "three weeks uh thing to go or something like that it was on Friday evening three",
    "start": "236120",
    "end": "241620"
  },
  {
    "text": "and a half weeks ago yeah the thing is uh let me share my",
    "start": "241620",
    "end": "248400"
  },
  {
    "text": "screen here I'm looking at the first comment so yeah May 12th",
    "start": "248400",
    "end": "254340"
  },
  {
    "text": "yeah awesome yeah but I've mentored with uh you know",
    "start": "254340",
    "end": "260299"
  },
  {
    "text": "things like that I created a small Tool uh let me find the name it's a speech",
    "start": "260299",
    "end": "266160"
  },
  {
    "text": "digest that uh if you can see my my screen it's a small tool that I created",
    "start": "266160",
    "end": "272100"
  },
  {
    "text": "on the stream knit um but um I have a GitHub for that which is a",
    "start": "272100",
    "end": "278880"
  },
  {
    "text": "standard speed digest it which is a tool onto which you can damp audio files and",
    "start": "278880",
    "end": "285060"
  },
  {
    "text": "it translates them to document and summarize them so I've been made in",
    "start": "285060",
    "end": "291960"
  },
  {
    "text": "with you know Chad GPT but GPT whisper and all of these things",
    "start": "291960",
    "end": "299419"
  },
  {
    "text": "and so quiver at the beginning was just a merge between a speed digest I've also",
    "start": "299419",
    "end": "307620"
  },
  {
    "text": "created something for fun but which is called article genius",
    "start": "307620",
    "end": "313259"
  },
  {
    "text": "um sorry guys wrong sorry uh",
    "start": "313259",
    "end": "318300"
  },
  {
    "text": "yeah so this one so article genius um no I'm not am I showing uh article",
    "start": "318300",
    "end": "327120"
  },
  {
    "text": "genius can you see yeah yeah um so yeah just a few things have been",
    "start": "327120",
    "end": "332940"
  },
  {
    "text": "made in with and then one evening on Friday I decided to create that uh so",
    "start": "332940",
    "end": "339539"
  },
  {
    "text": "quiver and yeah so when you",
    "start": "339539",
    "end": "346139"
  },
  {
    "text": "yeah when you started quiver like did you think it would be bigger than the other ones that you started because I",
    "start": "346139",
    "end": "352320"
  },
  {
    "text": "looked and this has like you know 7 000 Stars already and and some the speech",
    "start": "352320",
    "end": "357539"
  },
  {
    "text": "one you know not nearly as many as not so did you know that it would like were you investing in it as like this is this",
    "start": "357539",
    "end": "363240"
  },
  {
    "text": "could be like a big thing or was it similar to the other ones just kind of like a smaller project and it's not or",
    "start": "363240",
    "end": "368699"
  },
  {
    "text": "whatever it's the the thing that happened that was crazy is that I made a tweet about it and one guy from long",
    "start": "368699",
    "end": "375720"
  },
  {
    "text": "chain we treated my tweet and that went crazy from here so I was just you know",
    "start": "375720",
    "end": "381840"
  },
  {
    "text": "let let me show you a quiver it was just a screenshot and yeah it just blew up and at that",
    "start": "381840",
    "end": "388979"
  },
  {
    "text": "time I didn't know what happened so it was pretty fun uh Friday evening I went",
    "start": "388979",
    "end": "394259"
  },
  {
    "text": "to bed at 3am with you know my phone just vibrating and uh when I woke up at",
    "start": "394259",
    "end": "400560"
  },
  {
    "text": "like 400 stars and the next day I was changing on GitHub so yeah it's been yeah it was very fun",
    "start": "400560",
    "end": "407940"
  },
  {
    "text": "and I think it's you that we tweeted my tweet and that made quiver uh you know",
    "start": "407940",
    "end": "415139"
  },
  {
    "text": "the thing that it is today so yeah yeah thank you but we Retreat a lot of stuff",
    "start": "415139",
    "end": "421800"
  },
  {
    "text": "and and not everything kind of like takes off there's definitely something about quiver that that struck a chord",
    "start": "421800",
    "end": "427139"
  },
  {
    "text": "with with people and and made them decided to try it out and take a look yeah I think it was the the second grain",
    "start": "427139",
    "end": "433680"
  },
  {
    "text": "uh kind of you know branding of the the tool with uh you know when people uh",
    "start": "433680",
    "end": "440099"
  },
  {
    "text": "because you know uh in the tech World a lot of people know obsidian and so when you said the second brain a lot of",
    "start": "440099",
    "end": "447720"
  },
  {
    "text": "people already know the concept thanks to obsidian and so that I think struck",
    "start": "447720",
    "end": "453780"
  },
  {
    "text": "uh the code I think yeah um yeah I think that's why it became what it is",
    "start": "453780",
    "end": "460800"
  },
  {
    "text": "um and you know the idea behind it to believe some um some of the the things that you have",
    "start": "460800",
    "end": "467340"
  },
  {
    "text": "in your head and don't think about it and just look at it later on and maybe the fact",
    "start": "467340",
    "end": "472919"
  },
  {
    "text": "that it's open source too yeah that helps",
    "start": "472919",
    "end": "478979"
  },
  {
    "text": "so yeah um maybe you want to Quick demo about I",
    "start": "478979",
    "end": "484080"
  },
  {
    "text": "think you know if you want to just go to the website uh but you can just get start get started here you just create",
    "start": "484080",
    "end": "491099"
  },
  {
    "text": "an account and uh I already have one so",
    "start": "491099",
    "end": "496819"
  },
  {
    "text": "let me show you I have many",
    "start": "496819",
    "end": "501319"
  },
  {
    "text": "um but you can just drop drop one file uh let me find yeah this one maybe hope",
    "start": "502139",
    "end": "509639"
  },
  {
    "text": "it's working there's always yeah it's working we always have the demo effect so I've just uploaded a presentation I",
    "start": "509639",
    "end": "517500"
  },
  {
    "text": "did on uh on the generative AI to that work but it's",
    "start": "517500",
    "end": "523800"
  },
  {
    "text": "maybe somewhere in the brain I don't know why it is let me find it yeah it's here so we can see the content so it's",
    "start": "523800",
    "end": "531660"
  },
  {
    "text": "uh um it was just a presentation about",
    "start": "531660",
    "end": "539000"
  },
  {
    "text": "generative Ai and so now we can just ask questions about it Let me refresh hey um",
    "start": "539160",
    "end": "545820"
  },
  {
    "text": "I don't know uh what is uh um who his eyes and Chase let's see",
    "start": "545820",
    "end": "554880"
  },
  {
    "text": "is there information in my brain uh no",
    "start": "554880",
    "end": "561500"
  },
  {
    "text": "so yeah we have some issues right now that um uh",
    "start": "561959",
    "end": "568140"
  },
  {
    "text": "um yeah so uh what he did here is it looked into let me show you so I tried",
    "start": "568140",
    "end": "574920"
  },
  {
    "text": "to find I might have written your name wrong um but yeah it's looking for that right",
    "start": "574920",
    "end": "582180"
  },
  {
    "text": "here and it finds the information that is the most relevant and you can ask it",
    "start": "582180",
    "end": "589860"
  },
  {
    "text": "many questions but for example I've put some things about Keda for example which is a tour and",
    "start": "589860",
    "end": "597060"
  },
  {
    "text": "um it's being able to find all the information about Keda and",
    "start": "597060",
    "end": "603720"
  },
  {
    "text": "um um and put you know an answer with that so",
    "start": "603720",
    "end": "611100"
  },
  {
    "text": "how it works maybe that you're interested in um",
    "start": "611100",
    "end": "617959"
  },
  {
    "text": "yeah yeah so that's very simple right now but it's a document so at first we have a",
    "start": "618000",
    "end": "625200"
  },
  {
    "text": "document so here we take a PDF uh markdown PowerPoint or something like",
    "start": "625200",
    "end": "631560"
  },
  {
    "text": "that and we use a long chain document loaders so let me find uh that on the",
    "start": "631560",
    "end": "639120"
  },
  {
    "text": "namching website so here on long chain you have a lot of",
    "start": "639120",
    "end": "647339"
  },
  {
    "text": "things and I think it's yeah bad here so right right here I'm using",
    "start": "647339",
    "end": "653399"
  },
  {
    "text": "um so for example the nag downloaders and taking the instruction markdown and",
    "start": "653399",
    "end": "660240"
  },
  {
    "text": "I'm just loading the file and uh yeah and so thanks to uh your uh",
    "start": "660240",
    "end": "666839"
  },
  {
    "text": "loader if we go into thanks so much instructions for that yeah so this is so",
    "start": "666839",
    "end": "672959"
  },
  {
    "text": "this is a big shout out instruction which is a great company doing a lot around document layers and we have a very tight integration with them",
    "start": "672959",
    "end": "680519"
  },
  {
    "text": "um but yeah they they do a lot of the the the smart stuff here yeah there is",
    "start": "680519",
    "end": "686640"
  },
  {
    "text": "another one that I can show that uses uh uh yeah I think I think PDF you also",
    "start": "686640",
    "end": "692519"
  },
  {
    "text": "have a PDF loader with unstructured um so how many how many different file",
    "start": "692519",
    "end": "697920"
  },
  {
    "text": "types do you support for uploads uh So currently let me",
    "start": "697920",
    "end": "703440"
  },
  {
    "text": "um So currently we have audio files so it's all the the audio files that are supported by Whisper so it's MP4 MP3 uh",
    "start": "703440",
    "end": "711779"
  },
  {
    "text": "video files uh we have chb uh dog Ducks uh doc kicks epubs GitHub repositories",
    "start": "711779",
    "end": "719279"
  },
  {
    "text": "that's all files",
    "start": "719279",
    "end": "723120"
  },
  {
    "text": "how do you decide on these the set of files versus other sets",
    "start": "734880",
    "end": "739980"
  },
  {
    "text": "uh for now it's just you know the ones that made uh more sense to to us uh and",
    "start": "739980",
    "end": "747000"
  },
  {
    "text": "if somebody asks to add a file it's pretty straight straight forward so it's just we have a function here that",
    "start": "747000",
    "end": "754019"
  },
  {
    "text": "returns the function with uh the type of you know loaders and so",
    "start": "754019",
    "end": "762300"
  },
  {
    "text": "so it's very straightforward and if you want to add a new um loader you can just do it",
    "start": "762300",
    "end": "769860"
  },
  {
    "text": "and uh how how it works is um in the we have let me uh so I think I",
    "start": "769860",
    "end": "779279"
  },
  {
    "text": "changed uh uh so here we have you know if the",
    "start": "779279",
    "end": "786540"
  },
  {
    "text": "extension of the file is one of those then we call the",
    "start": "786540",
    "end": "792180"
  },
  {
    "text": "the corresponding processor and that's it",
    "start": "792180",
    "end": "798899"
  },
  {
    "text": "so yeah it's very simple and you know people can just add whatever they want here and then it's",
    "start": "798899",
    "end": "805440"
  },
  {
    "text": "you know it's integrated um so this this is what happens when you just upload the file",
    "start": "805440",
    "end": "812700"
  },
  {
    "text": "um so if you go here so what happens is you take a file and you upload it it's going to so this",
    "start": "812700",
    "end": "820320"
  },
  {
    "text": "file already exists um but it it's going into the processor",
    "start": "820320",
    "end": "825480"
  },
  {
    "text": "here it's looking at markdown so we have MD or markdown because some people use",
    "start": "825480",
    "end": "830519"
  },
  {
    "text": "the Magnum extension and then we go and process the file and",
    "start": "830519",
    "end": "836339"
  },
  {
    "text": "so this uh here is we have we are using",
    "start": "836339",
    "end": "841440"
  },
  {
    "text": "the long chain document loaders and it loads the file into memory it adds metadata on top of it",
    "start": "841440",
    "end": "848160"
  },
  {
    "text": "and then uh do you have any more questions about about that I think it's uh",
    "start": "848160",
    "end": "855320"
  },
  {
    "text": "yeah seems what what type of metadata is that or is that just whatever gets added",
    "start": "855660",
    "end": "860700"
  },
  {
    "text": "on the document loaders or uh yeah yeah we add extra things for now uh so let me",
    "start": "860700",
    "end": "868680"
  },
  {
    "text": "um go back to uh the common so what we do is we add the file shop uh",
    "start": "868680",
    "end": "876120"
  },
  {
    "text": "so it's a unique identifier of the file so that we know if the file has already",
    "start": "876120",
    "end": "881459"
  },
  {
    "text": "been uploaded the size the name uh the chunk size chunk of a lab date and a",
    "start": "881459",
    "end": "888600"
  },
  {
    "text": "feature we have added a feature but this if this is a summary of a chunk or not",
    "start": "888600",
    "end": "896220"
  },
  {
    "text": "um and yeah so these are some metadata that we add the file size one that we use to",
    "start": "896220",
    "end": "904380"
  },
  {
    "text": "be able to know that you know if I try to put the file again and again",
    "start": "904380",
    "end": "909779"
  },
  {
    "text": "it won't you won't be able to because it already exists in the vector store",
    "start": "909779",
    "end": "916740"
  },
  {
    "text": "so uh sorry uh let me I was showing you the wrong string but if I try to add",
    "start": "916740",
    "end": "922760"
  },
  {
    "text": "map.nd again I thought because the file already exists thanks to the shop",
    "start": "922760",
    "end": "930660"
  },
  {
    "text": "got it so yeah and uh the file size and things yeah what about so the summarization seems",
    "start": "930660",
    "end": "937320"
  },
  {
    "text": "interesting what's uh what's that so the summarization is something we",
    "start": "937320",
    "end": "943019"
  },
  {
    "text": "started working on with uh Sean so it's one of the guy that has been here since the beginning is the ability to",
    "start": "943019",
    "end": "949079"
  },
  {
    "text": "summarize uh the document uh before uh putting it in the brain and I have two",
    "start": "949079",
    "end": "956339"
  },
  {
    "text": "um so if we look at the the let me find the Super Bass",
    "start": "956339",
    "end": "962639"
  },
  {
    "text": "so uh I'm showing you here the vector stones that is it's a bit pretty much uh",
    "start": "962639",
    "end": "972000"
  },
  {
    "text": "red so we're not using it in production yet it's still in you know testing",
    "start": "972000",
    "end": "977940"
  },
  {
    "text": "um but what happened is you summarize the content of the file using chat CPT",
    "start": "977940",
    "end": "985579"
  },
  {
    "text": "or something like that and you you embed um this uh summary and you also hear so",
    "start": "987560",
    "end": "995820"
  },
  {
    "text": "here we have a foreign keypad thanks to the full document and so that allows you to ask a question",
    "start": "995820",
    "end": "1004160"
  },
  {
    "text": "on um so retrieving more information and I think you did something like that with",
    "start": "1004160",
    "end": "1010040"
  },
  {
    "text": "the condensed uh prompt I saw a new feature coming uh",
    "start": "1010040",
    "end": "1017180"
  },
  {
    "text": "um a couple of days ago I know you're you're going very fast but I think you created something called the condensed",
    "start": "1017180",
    "end": "1026020"
  },
  {
    "text": "um yeah so I think I think yeah you did that with the the condensed I'm not sure",
    "start": "1026120",
    "end": "1033438"
  },
  {
    "text": "I saw something and I I didn't have the",
    "start": "1033439",
    "end": "1038500"
  },
  {
    "text": "um I don't know why I saw it but um",
    "start": "1038959",
    "end": "1043900"
  },
  {
    "text": "um so I think we have a summary are you are you using the summary no",
    "start": "1050900",
    "end": "1057200"
  },
  {
    "text": "because this is a feature that we implemented three two and a half weeks ago maybe",
    "start": "1057200",
    "end": "1062419"
  },
  {
    "text": "uh but we haven't you know used any of the tools inside",
    "start": "1062419",
    "end": "1068660"
  },
  {
    "text": "um so it's it's a feature for later on uh but we definitely need to to put it",
    "start": "1068660",
    "end": "1076160"
  },
  {
    "text": "so the backend is ready to use it but the front end is not yeah um and one of the reason is that we",
    "start": "1076160",
    "end": "1082640"
  },
  {
    "text": "haven't yet tested uh um how much it cost because you know for",
    "start": "1082640",
    "end": "1087919"
  },
  {
    "text": "each document yeah uh you're kind of doubling the price because you have to",
    "start": "1087919",
    "end": "1093020"
  },
  {
    "text": "process the document create a summarization embed yeah this",
    "start": "1093020",
    "end": "1098600"
  },
  {
    "text": "summarization and also embed the documents but for all so that's you know",
    "start": "1098600",
    "end": "1103880"
  },
  {
    "text": "kind of crazy uh but yeah so we we went right here to the",
    "start": "1103880",
    "end": "1110179"
  },
  {
    "text": "embeddings that the first thing is to uh yeah",
    "start": "1110179",
    "end": "1115340"
  },
  {
    "text": "yeah the chunking of documents so uh what we did here is we are using the",
    "start": "1115340",
    "end": "1121520"
  },
  {
    "text": "recursive character text splitter so what happens is uh when you load your",
    "start": "1121520",
    "end": "1127100"
  },
  {
    "text": "document then we split it into chunk size of 500 tokens",
    "start": "1127100",
    "end": "1133640"
  },
  {
    "text": "um so we are using tip token encoder it's something that kind of uh calculates the same number of tokens",
    "start": "1133640",
    "end": "1141620"
  },
  {
    "text": "than GPT uh why I'm using this one is because most people",
    "start": "1141620",
    "end": "1147799"
  },
  {
    "text": "um use GPT for now uh and I think cloud also is using the same one",
    "start": "1147799",
    "end": "1153860"
  },
  {
    "text": "uh kind of you know function to calculate the number of tokens",
    "start": "1153860",
    "end": "1158960"
  },
  {
    "text": "how do you decide on uh how do you decide on 500 and zero as the chunk size",
    "start": "1158960",
    "end": "1165320"
  },
  {
    "text": "and chunk overlap this is one question I get asked a lot like what's the best chunk size what's the best you know it's it's like the same thing you know it I I",
    "start": "1165320",
    "end": "1172880"
  },
  {
    "text": "don't know it's it's one question I've been asked it's one thing that we need to to look at and it's",
    "start": "1172880",
    "end": "1180140"
  },
  {
    "text": "um it depends on uh how much context you want to keep",
    "start": "1180140",
    "end": "1185480"
  },
  {
    "text": "um for some documents 100 tokens is filed for others one thousand is fine",
    "start": "1185480",
    "end": "1191480"
  },
  {
    "text": "um so it's not something that we have looked into yet but it's something that needs to be looked into because",
    "start": "1191480",
    "end": "1198380"
  },
  {
    "text": "uh the chunk size um so if we don't care uh it it splits",
    "start": "1198380",
    "end": "1204559"
  },
  {
    "text": "the document into smaller bits um but if we have a document that talks",
    "start": "1204559",
    "end": "1209780"
  },
  {
    "text": "about you know the title is King Arthur you know I don't know and then uh we",
    "start": "1209780",
    "end": "1216080"
  },
  {
    "text": "have the description and at any time we don't talk about King Arthur we just say it's a king that did bad bad bad if we",
    "start": "1216080",
    "end": "1223600"
  },
  {
    "text": "have a chunk size that is too small we could lose the title at the beginning and so when we do",
    "start": "1223600",
    "end": "1231039"
  },
  {
    "text": "uh the simulated search what happens is that we might not be",
    "start": "1231039",
    "end": "1236480"
  },
  {
    "text": "able to find the chunk that has the information that we want on King Alpha so on some use cases having small chance",
    "start": "1236480",
    "end": "1245240"
  },
  {
    "text": "is very interesting and on some use cases you want big chunks so it's something that I I don't know",
    "start": "1245240",
    "end": "1252200"
  },
  {
    "text": "how yet but it's something that we need to put into quiver to allow people or to",
    "start": "1252200",
    "end": "1257900"
  },
  {
    "text": "to send people well if it's a document that has you know a small category is",
    "start": "1257900",
    "end": "1264500"
  },
  {
    "text": "put a chunk that is very small but if it's document that has you know not a",
    "start": "1264500",
    "end": "1270140"
  },
  {
    "text": "lot of categories and you want to be able to ask questions about big parts of the documents then put a",
    "start": "1270140",
    "end": "1277400"
  },
  {
    "text": "chunk size that is big but this is one of the tricky things",
    "start": "1277400",
    "end": "1283640"
  },
  {
    "text": "that we we encounter with Quaver is the chunk size and I think it's something that the community needs to to think",
    "start": "1283640",
    "end": "1290720"
  },
  {
    "text": "about because it's going to it's going to",
    "start": "1290720",
    "end": "1296020"
  },
  {
    "text": "make information retrievable where better once we figure out how to chunk",
    "start": "1296020",
    "end": "1303200"
  },
  {
    "text": "efficiently and I think it's something that is often overlooked in applications",
    "start": "1303200",
    "end": "1309320"
  },
  {
    "text": "and it's something that we are looking in quiver right now because we have no clue",
    "start": "1309320",
    "end": "1314780"
  },
  {
    "text": "but yeah I mean one of the things uh and I see",
    "start": "1314780",
    "end": "1319940"
  },
  {
    "text": "some comments in the chat about uh like uh chunking",
    "start": "1319940",
    "end": "1325159"
  },
  {
    "text": "um chunking by existing document formatting and how and how that's effective one of the things that we have",
    "start": "1325159",
    "end": "1332059"
  },
  {
    "text": "that we can maybe make a little bit like basically we have a bunch of",
    "start": "1332059",
    "end": "1337539"
  },
  {
    "text": "document Splitters that split by like important attributes yeah this doesn't",
    "start": "1337539",
    "end": "1342919"
  },
  {
    "text": "get to the links but like markdown right like you keep the yeah and I think you had some great back when we chatted",
    "start": "1342919",
    "end": "1348440"
  },
  {
    "text": "earlier about like right now we split on like header one header two and stuff like that and so that helps a little bit with like organization and keeping",
    "start": "1348440",
    "end": "1354500"
  },
  {
    "text": "things semantically meaningful the big thing would be it would be really nice to carry that metadata through",
    "start": "1354500",
    "end": "1360440"
  },
  {
    "text": "um and so I think we're working on some stuff there but you know another thing um",
    "start": "1360440",
    "end": "1365539"
  },
  {
    "text": "since you already have the file extensions one thing that we can probably add pretty easily is just like a a splitter that like you know looks",
    "start": "1365539",
    "end": "1372740"
  },
  {
    "text": "for if it if it's marked down it will use the markdown one if it like it kind of like does it based on the file",
    "start": "1372740",
    "end": "1377840"
  },
  {
    "text": "extensions I think the the recursive text bitter really does that",
    "start": "1377840",
    "end": "1385659"
  },
  {
    "text": "um but you know it's just it splits at the quite place but it doesn't keep you know the",
    "start": "1385940",
    "end": "1393020"
  },
  {
    "text": "information that we want yeah but even with the like the recursive text splitter right now it",
    "start": "1393020",
    "end": "1399080"
  },
  {
    "text": "takes on like a single list of things to split on but things like that the the list of those things for markdown versus",
    "start": "1399080",
    "end": "1405980"
  },
  {
    "text": "like HTML is like pretty different and so having a nice way to switch this this I guess relies on like each document",
    "start": "1405980",
    "end": "1412880"
  },
  {
    "text": "kind of having um actually do you do text splitting like at the individual document level",
    "start": "1412880",
    "end": "1419299"
  },
  {
    "text": "yeah yeah yeah so then it should be pretty easy to we can maybe work on something",
    "start": "1419299",
    "end": "1425720"
  },
  {
    "text": "but it should be pretty easy to add a something that just like looks at the file extension and then if it's like HTML it uses the HTML recursive text",
    "start": "1425720",
    "end": "1433280"
  },
  {
    "text": "splitter if it's marked down it uses the markdown one yeah I think uh so long um text splitting is",
    "start": "1433280",
    "end": "1442520"
  },
  {
    "text": "very important because uh we are limited by context right now so if if you know if we have one million context or tokens",
    "start": "1442520",
    "end": "1451340"
  },
  {
    "text": "then the trunking is not an issue but when you have four thousand eight thousand or thirty two thousand uh being",
    "start": "1451340",
    "end": "1459440"
  },
  {
    "text": "able to efficiently chunk your fights is very important because it allows you to put more information uh uh at the same",
    "start": "1459440",
    "end": "1467900"
  },
  {
    "text": "place so if if you know GPT open AI release is a gpt4 with two millions uh",
    "start": "1467900",
    "end": "1475159"
  },
  {
    "text": "token possibilities then chunking you know we can just put it in the garbage and just load the entire file but for",
    "start": "1475159",
    "end": "1481340"
  },
  {
    "text": "now if we want efficient uh information which you want we need to have efficient uh chunking",
    "start": "1481340",
    "end": "1488659"
  },
  {
    "text": "uh well yeah I mean so there was a question about this in the chat and we'll get to a billions of liquor stores",
    "start": "1488659",
    "end": "1494059"
  },
  {
    "text": "in a little bit but like um you know I think with these long context windows",
    "start": "1494059",
    "end": "1499880"
  },
  {
    "text": "do you think yeah it will chunking and embedding and Vector stores go away",
    "start": "1499880",
    "end": "1505700"
  },
  {
    "text": "because the argument would be exactly what you said you can just pass the whole document in the counter argument would be like",
    "start": "1505700",
    "end": "1511400"
  },
  {
    "text": "that takes a lot longer to get an answer yeah",
    "start": "1511400",
    "end": "1516440"
  },
  {
    "text": "yeah it might but the thing is let's say that",
    "start": "1516440",
    "end": "1521480"
  },
  {
    "text": "you want to ask uh the editing what happened today in the world yeah okay I",
    "start": "1521480",
    "end": "1529159"
  },
  {
    "text": "don't think that two millions tokens will be enough you know so you'll have to process all the information before so",
    "start": "1529159",
    "end": "1535760"
  },
  {
    "text": "it's just that we'll be able to process more information and have more accurate uh information based on huge context and",
    "start": "1535760",
    "end": "1543620"
  },
  {
    "text": "ask more complicated questions but I think that chunking and Vector store will be here for",
    "start": "1543620",
    "end": "1550039"
  },
  {
    "text": "quite a bit of time and you you probably don't want to do the calculation all the",
    "start": "1550039",
    "end": "1556220"
  },
  {
    "text": "time you still have to you know uh what happened on Old Monday since 1922.",
    "start": "1556220",
    "end": "1562840"
  },
  {
    "text": "that's something you need a vector store I don't know if it's useful but you need the vector store in order to throw the",
    "start": "1562840",
    "end": "1569120"
  },
  {
    "text": "information or or at least a database you know",
    "start": "1569120",
    "end": "1575000"
  },
  {
    "text": "makes sense um yeah we can continue",
    "start": "1575000",
    "end": "1584320"
  },
  {
    "text": "um so yeah the the last part is kind of the embedding so we are using open AI",
    "start": "1584480",
    "end": "1589640"
  },
  {
    "text": "embeddings um I've tried a pan so pan is uh",
    "start": "1589640",
    "end": "1597820"
  },
  {
    "text": "the Google um modern and you can use you can use it to",
    "start": "1597820",
    "end": "1604820"
  },
  {
    "text": "embed and you can use it with a long chain so there is uh let me sign",
    "start": "1604820",
    "end": "1611900"
  },
  {
    "text": "um you can use the embeddings long chain or Pal",
    "start": "1611900",
    "end": "1617179"
  },
  {
    "text": "but the the issue that I had is that for now plan only is not compatible in terms",
    "start": "1617179",
    "end": "1624919"
  },
  {
    "text": "of vector size with open AI so it means that if I want to use Palm I",
    "start": "1624919",
    "end": "1631520"
  },
  {
    "text": "have to make a second database which with with a vector that is 750",
    "start": "1631520",
    "end": "1638740"
  },
  {
    "text": "Dimensions where openai embedding is 1500",
    "start": "1638740",
    "end": "1645020"
  },
  {
    "text": "so I can't use the same database a table you know for the same",
    "start": "1645020",
    "end": "1651860"
  },
  {
    "text": "one so I can't allow people to use either vertex AI with pan or open AI",
    "start": "1651860",
    "end": "1659419"
  },
  {
    "text": "depending on what they prefer because that means that right now I have to change uh the way that the information",
    "start": "1659419",
    "end": "1666620"
  },
  {
    "text": "is installed but yeah you can use pretty much any",
    "start": "1666620",
    "end": "1671779"
  },
  {
    "text": "embedding system that you want uh just you know less",
    "start": "1671779",
    "end": "1677360"
  },
  {
    "text": "[Music] as a precise to have a plan for now and the",
    "start": "1677360",
    "end": "1686659"
  },
  {
    "text": "vector store I've used Super Bass because you get the free database",
    "start": "1686659",
    "end": "1692080"
  },
  {
    "text": "uh which is pretty nice and it's uh postgrespect so uh one of the thing is that uh I",
    "start": "1692080",
    "end": "1700760"
  },
  {
    "text": "really like vector store but I don't I I'm not a data scientist like you",
    "start": "1700760",
    "end": "1706220"
  },
  {
    "text": "um and so I know positive SQL I can use the same table at the same database to",
    "start": "1706220",
    "end": "1713120"
  },
  {
    "text": "store so um if we look here I've got my user I've",
    "start": "1713120",
    "end": "1718400"
  },
  {
    "text": "got my stats I've got my vectors my Sona is all of these things at the same place and I and I don't need",
    "start": "1718400",
    "end": "1726919"
  },
  {
    "text": "to try something else and postgres credit is very efficient for you know you can go to terabytes of data and if",
    "start": "1726919",
    "end": "1735440"
  },
  {
    "text": "we look at uh the the help of the database so this is the",
    "start": "1735440",
    "end": "1742880"
  },
  {
    "text": "CPU that has been used on the database so for now it's cruising I mean it's it",
    "start": "1742880",
    "end": "1750380"
  },
  {
    "text": "doesn't have any issue with uh the the usage on the database so yeah so I I'd",
    "start": "1750380",
    "end": "1760100"
  },
  {
    "text": "recommend for now for people when you're trying to build something to use",
    "start": "1760100",
    "end": "1765799"
  },
  {
    "text": "um uh you can use Pinecone or any other manage",
    "start": "1765799",
    "end": "1771140"
  },
  {
    "text": "Vector store that you want but if you just want to poke something very simple",
    "start": "1771140",
    "end": "1776779"
  },
  {
    "text": "um the postgresql database is if you know how to do is make be convenient",
    "start": "1776779",
    "end": "1784100"
  },
  {
    "text": "so yeah the number one uploaded question right now and this is a reminder if people have questions add them in the Q",
    "start": "1784100",
    "end": "1789679"
  },
  {
    "text": "a section I'll put ones you want to see answered but the number one question that's that's there is like which Vector",
    "start": "1789679",
    "end": "1795559"
  },
  {
    "text": "store are you using and why and so just to summarize like postgres because you",
    "start": "1795559",
    "end": "1800659"
  },
  {
    "text": "already know it and are using it for other things and it's easy to use with super bass out of the box",
    "start": "1800659",
    "end": "1806539"
  },
  {
    "text": "yeah it's uh I didn't have to so I look into website credent uh pine cone",
    "start": "1806539",
    "end": "1815179"
  },
  {
    "text": "um each time I had to find I had to learn a",
    "start": "1815179",
    "end": "1823520"
  },
  {
    "text": "new way of communicating and they are great and they are awesome but I'm not storing right now terabytes of",
    "start": "1823520",
    "end": "1830480"
  },
  {
    "text": "information so the postgres query is fine and I know that if whoever keeps",
    "start": "1830480",
    "end": "1836419"
  },
  {
    "text": "growing I'll have to use one of them but for now no I don't",
    "start": "1836419",
    "end": "1843220"
  },
  {
    "text": "um yeah um I think there's a question with multiple",
    "start": "1843799",
    "end": "1850580"
  },
  {
    "text": "documents uh for now I think the default document retrieval is full",
    "start": "1850580",
    "end": "1856039"
  },
  {
    "text": "so this is something that we have to improve um and to uh",
    "start": "1856039",
    "end": "1861200"
  },
  {
    "text": "we haven't implemented yet a dynamic you know document loading uh but yeah it's",
    "start": "1861200",
    "end": "1869419"
  },
  {
    "text": "something that we have to do you're talking about chunks right yeah",
    "start": "1869419",
    "end": "1875179"
  },
  {
    "text": "yeah yeah yeah so that'd be I mean that's something that um and I mean",
    "start": "1875179",
    "end": "1880580"
  },
  {
    "text": "you'd want to do that based on like token length of the document right exactly",
    "start": "1880580",
    "end": "1885919"
  },
  {
    "text": "yeah um yeah so yeah I think it's it's saying the conversational retrieval",
    "start": "1885919",
    "end": "1894020"
  },
  {
    "text": "so yeah let me see I think the super based Vector store for example",
    "start": "1894020",
    "end": "1899600"
  },
  {
    "text": "um which is by default so there's Decay",
    "start": "1899600",
    "end": "1904760"
  },
  {
    "text": "argument here yeah and I think by default it's at four so I had to",
    "start": "1904760",
    "end": "1910159"
  },
  {
    "text": "override the similarity search function um but by default I think it's full",
    "start": "1910159",
    "end": "1917500"
  },
  {
    "text": "yeah for four documents well four chunks of documents so I think",
    "start": "1917679",
    "end": "1924020"
  },
  {
    "text": "this quite I'm not sure what this question is asking about but if it's asking about like multiple documents at once when you were doing the chat you",
    "start": "1924020",
    "end": "1929899"
  },
  {
    "text": "were already chatting over all your documents right and that and yes we're able to do that with the whole yeah so",
    "start": "1929899",
    "end": "1935840"
  },
  {
    "text": "the chunking and putting it into a vector store allows us to basically interact with all these documents at",
    "start": "1935840",
    "end": "1941600"
  },
  {
    "text": "once uh exactly so um but yeah it's something that you have",
    "start": "1941600",
    "end": "1947480"
  },
  {
    "text": "to keep in mind is but for now quiver is using 500 uh chunks of 500 tokens and uh GPT 3.5",
    "start": "1947480",
    "end": "1957740"
  },
  {
    "text": "is limited to 4000 tokens so if I use four chunks that's 2 000",
    "start": "1957740",
    "end": "1963559"
  },
  {
    "text": "tokens that I've been that I've been used and uh when it says four thousand",
    "start": "1963559",
    "end": "1968899"
  },
  {
    "text": "tokens it's four thousand tokens for the question uh the context plus the question please press the answer",
    "start": "1968899",
    "end": "1976460"
  },
  {
    "text": "so uh and then if you want to have a chat history chat memory",
    "start": "1976460",
    "end": "1983360"
  },
  {
    "text": "um but you know if you go above a four thousand tokens you don't have uh",
    "start": "1983360",
    "end": "1990100"
  },
  {
    "text": "uh you can't find this toy uh it's for example when you check GPT plus HTTP on",
    "start": "1990100",
    "end": "1996860"
  },
  {
    "text": "the website once you go over if you have a long discussion you know with uh child GPT at one time",
    "start": "1996860",
    "end": "2003340"
  },
  {
    "text": "it feels like it doesn't remember what you were talking before it's because you",
    "start": "2003340",
    "end": "2008380"
  },
  {
    "text": "went over the token limit and so it had to forget a few things",
    "start": "2008380",
    "end": "2013480"
  },
  {
    "text": "so yeah it's uh an issue that we have",
    "start": "2013480",
    "end": "2020278"
  },
  {
    "text": "um yeah um awesome",
    "start": "2020740",
    "end": "2027000"
  },
  {
    "text": "and so yeah um after that we have you know the retrieval so we are the user question",
    "start": "2027000",
    "end": "2034179"
  },
  {
    "text": "and we create a vector with that we use the simulated search function and then",
    "start": "2034179",
    "end": "2040059"
  },
  {
    "text": "we ask the question to charge with the channel size context and the user",
    "start": "2040059",
    "end": "2045220"
  },
  {
    "text": "question one thing that we had to do is we had to as you saw here is we had to create a",
    "start": "2045220",
    "end": "2053560"
  },
  {
    "text": "custom super based Vector store the reason why uh yeah that's a good",
    "start": "2053560",
    "end": "2059440"
  },
  {
    "text": "question is that here you can see I have a user ID",
    "start": "2059440",
    "end": "2064560"
  },
  {
    "text": "um the thing is uh right now the the supervised Vector store on python",
    "start": "2064659",
    "end": "2071679"
  },
  {
    "text": "doesn't support meta that I've been showing um so I was lazy",
    "start": "2071679",
    "end": "2078960"
  },
  {
    "text": "I didn't make a pull request I just yeah",
    "start": "2078960",
    "end": "2084838"
  },
  {
    "text": "yeah I'm sorry I'm joking but yeah so I implemented my own uh",
    "start": "2085540",
    "end": "2091118"
  },
  {
    "text": "simulated search but allows me to filter by a specific column so if we look at",
    "start": "2091119",
    "end": "2097780"
  },
  {
    "text": "the the database here in the vectors here I have the name of the user and so",
    "start": "2097780",
    "end": "2107080"
  },
  {
    "text": "that's yeah you know but allows allowed me to filter on that",
    "start": "2107080",
    "end": "2113380"
  },
  {
    "text": "um I wanted to do it on metadata but it wasn't supported yet I told the guys of Super Bass uh and uh",
    "start": "2113380",
    "end": "2121359"
  },
  {
    "text": "they are looking into it because I said well your GS Vector store is support uh",
    "start": "2121359",
    "end": "2128200"
  },
  {
    "text": "and the filtering of metadata that you know the ones on on python doesn't and I",
    "start": "2128200",
    "end": "2135460"
  },
  {
    "text": "understand that there are a GS you know JavaScript the more focused on uh website and I'm",
    "start": "2135460",
    "end": "2145000"
  },
  {
    "text": "back in the with python so it's an understandable",
    "start": "2145000",
    "end": "2150240"
  },
  {
    "text": "um so yeah so that's basically uh",
    "start": "2151000",
    "end": "2156280"
  },
  {
    "text": "all the everything that happens with Cueva uh we have a few things that we",
    "start": "2156280",
    "end": "2162579"
  },
  {
    "text": "had to change you know and a few things that we have issues with is for example",
    "start": "2162579",
    "end": "2168160"
  },
  {
    "text": "the and I'm sorry I didn't make a a PR is the default uh prompt uh doesn't",
    "start": "2168160",
    "end": "2176940"
  },
  {
    "text": "respond in the initial language of the question so if you had people that ask questions",
    "start": "2176940",
    "end": "2183640"
  },
  {
    "text": "in Chinese it answers in English if the document is in English ah no it answers in English no if you",
    "start": "2183640",
    "end": "2190540"
  },
  {
    "text": "ask a question in your language at first it answered with you know English",
    "start": "2190540",
    "end": "2196839"
  },
  {
    "text": "so yeah it's something that we had to change um and yeah so that for now it's very",
    "start": "2196839",
    "end": "2203800"
  },
  {
    "text": "simple you can try it you can install it locally um yeah if you want to look at the first",
    "start": "2203800",
    "end": "2212260"
  },
  {
    "text": "iteration that happened three weeks ago can I can I ask okay quick question going back prompt",
    "start": "2212260",
    "end": "2219220"
  },
  {
    "text": "change changing the prompts um this is something that we want to make really easy at Ling Jing because",
    "start": "2219220",
    "end": "2225160"
  },
  {
    "text": "you know the prompts that we have are just default prompts we don't think they're you know the best ones you absolutely should modify them for your",
    "start": "2225160",
    "end": "2231040"
  },
  {
    "text": "use case um was it there anything we could do to make like how how easy was was that",
    "start": "2231040",
    "end": "2238180"
  },
  {
    "text": "process was there is there anything we can do to make that easier for people to figure out how to modify the prompts",
    "start": "2238180",
    "end": "2244359"
  },
  {
    "text": "um the fact that you can modify prompts at all um yeah yeah uh it was fairly easy I",
    "start": "2244359",
    "end": "2251260"
  },
  {
    "text": "mean it's it's it's it's good I think the information retrieval of how uh what the default",
    "start": "2251260",
    "end": "2259839"
  },
  {
    "text": "prompt is is not efficient um so at first I had some issues",
    "start": "2259839",
    "end": "2266500"
  },
  {
    "text": "understanding how the problems were you know created with you know uh the Chrome",
    "start": "2266500",
    "end": "2272260"
  },
  {
    "text": "templates and the questions and if we look at the",
    "start": "2272260",
    "end": "2278440"
  },
  {
    "text": "and that so we have the chat history here we have the question and so this is",
    "start": "2278440",
    "end": "2283599"
  },
  {
    "text": "something that we we I think we could copied from your uh",
    "start": "2283599",
    "end": "2289680"
  },
  {
    "text": "from your um code and we modified and it took me",
    "start": "2289680",
    "end": "2295900"
  },
  {
    "text": "quite a bit to understand that you were using templating to you know input the chat history here the follow-up question",
    "start": "2295900",
    "end": "2302880"
  },
  {
    "text": "and uh but uh it's very easy to modify I mean",
    "start": "2302880",
    "end": "2308920"
  },
  {
    "text": "it's right here you can create your own you're you already created more with you know the contents prompt",
    "start": "2308920",
    "end": "2316240"
  },
  {
    "text": "um yeah I don't think it's an issue cool",
    "start": "2316240",
    "end": "2323280"
  },
  {
    "text": "um I'm looking at the questions",
    "start": "2328720",
    "end": "2333940"
  },
  {
    "text": "yeah so there's yes questions there's a good one that I like from from Maxime",
    "start": "2333940",
    "end": "2339339"
  },
  {
    "text": "and there's kind of two components to it um so maybe we can uh maybe we can stick",
    "start": "2339339",
    "end": "2345280"
  },
  {
    "text": "with I think there's a technical part so how do you debug slash improve all the knobs of the llm app the choice of",
    "start": "2345280",
    "end": "2351099"
  },
  {
    "text": "embeddings the choice of vector Shores the text Splitters the prompts like how yeah how do you improve all these yeah",
    "start": "2351099",
    "end": "2357520"
  },
  {
    "text": "so uh I think I know I know this guy I think we had the talk on Tuesday so it's",
    "start": "2357520",
    "end": "2363040"
  },
  {
    "text": "a question but uh as a husk and I had a discussion with him but the the issue",
    "start": "2363040",
    "end": "2369220"
  },
  {
    "text": "right now is that you can't know if your um if you how do you end to end or how",
    "start": "2369220",
    "end": "2377200"
  },
  {
    "text": "do you test about your new version of your prompt is better than the last one and that's something that is very hard",
    "start": "2377200",
    "end": "2383680"
  },
  {
    "text": "to do and uh I think there is a place to you know",
    "start": "2383680",
    "end": "2389280"
  },
  {
    "text": "there is something to be done I mean I don't know when I'm making an improvement of my on my prompt on my on",
    "start": "2389280",
    "end": "2396099"
  },
  {
    "text": "my embeddings on the chunk size if the questions that is answered is better than the uh than the previous version",
    "start": "2396099",
    "end": "2403619"
  },
  {
    "text": "and so I've thought about using chatgpt to measure you know",
    "start": "2403619",
    "end": "2409079"
  },
  {
    "text": "uh the relevance of the answer but it's pricey I mean every time you",
    "start": "2409079",
    "end": "2415960"
  },
  {
    "text": "want to enter to test if your new version uh is better than the last one if you do",
    "start": "2415960",
    "end": "2421839"
  },
  {
    "text": "you know unit tests is going to cost you a bunch of calls",
    "start": "2421839",
    "end": "2427240"
  },
  {
    "text": "yeah to open AI and yeah so right now it's just you know",
    "start": "2427240",
    "end": "2434260"
  },
  {
    "text": "try and try on an air but uh if we want our projects to go above and beyond you",
    "start": "2434260",
    "end": "2442300"
  },
  {
    "text": "know with performance and improvements we have to find a way to measure um the improvements of problems and so",
    "start": "2442300",
    "end": "2450820"
  },
  {
    "text": "that could come from measuring uh user um you know ABT testing or I don't know",
    "start": "2450820",
    "end": "2458220"
  },
  {
    "text": "it's very hard I think there's a feeling well so there's okay so the second part of",
    "start": "2458220",
    "end": "2464680"
  },
  {
    "text": "this gets into a little bit of that and then maybe this is more on the product side how do you like visualize and",
    "start": "2464680",
    "end": "2470200"
  },
  {
    "text": "understand how users are using quiver and maybe maybe we can take this lesson",
    "start": "2470200",
    "end": "2475240"
  },
  {
    "text": "the technical Direction but like more like you know when you're thinking about products to add right or features to add like how how do yeah how what do you use",
    "start": "2475240",
    "end": "2482320"
  },
  {
    "text": "to keep an eye on how people are using the app well the the the the we have uh so not",
    "start": "2482320",
    "end": "2490300"
  },
  {
    "text": "in the new version but on the extremely version every question that was asked on Cueva",
    "start": "2490300",
    "end": "2497079"
  },
  {
    "text": "was recorded so it gave um I can show you uh so I had a a table",
    "start": "2497079",
    "end": "2505900"
  },
  {
    "text": "here and let me find uh so it was how",
    "start": "2505900",
    "end": "2511480"
  },
  {
    "text": "did I chat here so it was the quick and dirty but you know",
    "start": "2511480",
    "end": "2516900"
  },
  {
    "text": "uh here I can I can find all the I could find all the",
    "start": "2516900",
    "end": "2522520"
  },
  {
    "text": "uh questions when people asked about quiver in quiver so let's let's look at",
    "start": "2522520",
    "end": "2527980"
  },
  {
    "text": "something so that's something that I did is I looked at how people were using it um",
    "start": "2527980",
    "end": "2533800"
  },
  {
    "text": "and then I tried to find the issues so one thing that I found is that people",
    "start": "2533800",
    "end": "2539079"
  },
  {
    "text": "are trying to um ask questions on one document",
    "start": "2539079",
    "end": "2544900"
  },
  {
    "text": "specifically and whoever doesn't do that efficiently so let's say let me show you",
    "start": "2544900",
    "end": "2550780"
  },
  {
    "text": "that if you want to ask me questions about you know let's say the tech had",
    "start": "2550780",
    "end": "2556060"
  },
  {
    "text": "our code product is summarize the tech radar Cloud product",
    "start": "2556060",
    "end": "2564040"
  },
  {
    "text": "it comes it can't do it because it doesn't have you know the the capability",
    "start": "2564040",
    "end": "2569980"
  },
  {
    "text": "to take just all the content from the file uh yeah so yeah so that's the demo",
    "start": "2569980",
    "end": "2577060"
  },
  {
    "text": "effect you know it's working right now but uh but probably it doesn't have like all",
    "start": "2577060",
    "end": "2585880"
  },
  {
    "text": "like it's it's you know it's probably it's pulling in some chunks and it's probably summarizing the chunks that it",
    "start": "2585880",
    "end": "2591220"
  },
  {
    "text": "gets back but it's not the first thing interesting uh kind of like",
    "start": "2591220",
    "end": "2597940"
  },
  {
    "text": "um you know and we can chat about this offline and and like right now you're using kind of like the fixed conversational retrieval chain",
    "start": "2597940",
    "end": "2605140"
  },
  {
    "text": "um which is you know super easy to get started but but it's really about like question answering on like a fact basis",
    "start": "2605140",
    "end": "2610420"
  },
  {
    "text": "yeah I think one thing that might be interesting to it before is like you know the idea I don't know whether it's",
    "start": "2610420",
    "end": "2616240"
  },
  {
    "text": "an agent or just using a router chain so if you you can say like oh if the question seems to be about summary I'm",
    "start": "2616240",
    "end": "2622420"
  },
  {
    "text": "going to do summary and then you basically like okay find the find the find the page it page or pages so look",
    "start": "2622420",
    "end": "2629260"
  },
  {
    "text": "this is where it starts to get a little bit more complicated but like yeah between and like only use the",
    "start": "2629260",
    "end": "2634540"
  },
  {
    "text": "conversation chain when when it's a factual question and when you go to summarization for summarization I mean",
    "start": "2634540",
    "end": "2640300"
  },
  {
    "text": "and this can also be this can also I was thinking about this the other day this could be like um you know like if someone asks you to",
    "start": "2640300",
    "end": "2646599"
  },
  {
    "text": "summarize a document you could just switch over to using uh uh if you have access the anthropic 100K model and just",
    "start": "2646599",
    "end": "2654099"
  },
  {
    "text": "pass in the whole document assuming that it's like short enough and well yeah",
    "start": "2654099",
    "end": "2659380"
  },
  {
    "text": "the these uh not on the web but on the local uh Hub you can use uh control page",
    "start": "2659380",
    "end": "2667359"
  },
  {
    "text": "so code 100 context I know that is but I don't have access to it so if one got it",
    "start": "2667359",
    "end": "2674020"
  },
  {
    "text": "here you know I'm looking forward um but yeah that's something that you",
    "start": "2674020",
    "end": "2680020"
  },
  {
    "text": "could do but you know 100 000 it's I've calculated the price it's uh 73",
    "start": "2680020",
    "end": "2688020"
  },
  {
    "text": "cents for one summarization of 100 000 uh tokens context",
    "start": "2688020",
    "end": "2695380"
  },
  {
    "text": "it's kind of pricey you know so if",
    "start": "2695380",
    "end": "2700420"
  },
  {
    "text": "yeah I think I think uh the the chain the agents the summarization that you",
    "start": "2700420",
    "end": "2705700"
  },
  {
    "text": "showed right here uh maybe using you know specific chains or agents to do",
    "start": "2705700",
    "end": "2711940"
  },
  {
    "text": "something when the question um you know",
    "start": "2711940",
    "end": "2717880"
  },
  {
    "text": "um yeah when you think that the question is going somewhere that would be nice but there's an issue with that and I",
    "start": "2717880",
    "end": "2723460"
  },
  {
    "text": "think it's the the the gpt3 uh and that that relies on the uh",
    "start": "2723460",
    "end": "2732520"
  },
  {
    "text": "underlying local uh llm to be performant enough to be able to",
    "start": "2732520",
    "end": "2740260"
  },
  {
    "text": "um tell you with a structured um so jisan or thing like that so you know",
    "start": "2740260",
    "end": "2748240"
  },
  {
    "text": "with auto GPT and things like that they talk with they tell you what to do the",
    "start": "2748240",
    "end": "2754359"
  },
  {
    "text": "next section with a GSM and you have you know fuzzy",
    "start": "2754359",
    "end": "2760200"
  },
  {
    "text": "it can take hours just to do one simple task and so if you are trying to",
    "start": "2765359",
    "end": "2771819"
  },
  {
    "text": "retrieve information quickly using agents or you know long chains",
    "start": "2771819",
    "end": "2777940"
  },
  {
    "text": "can yeah no the user expense won't be great so we need to find a way to make it smart",
    "start": "2777940",
    "end": "2784359"
  },
  {
    "text": "maybe you know on the UA ux on the website you know you",
    "start": "2784359",
    "end": "2790300"
  },
  {
    "text": "have a button and you say this is a summarization task yeah",
    "start": "2790300",
    "end": "2796800"
  },
  {
    "text": "you know honestly that's probably that's probably easier yeah like yeah",
    "start": "2797319",
    "end": "2803400"
  },
  {
    "text": "there's this thing right where like you you like you know you could do something really complicated or you could just",
    "start": "2804359",
    "end": "2809740"
  },
  {
    "text": "make the ux a little bit different and add a button yeah it's it's it reminds me of the",
    "start": "2809740",
    "end": "2817060"
  },
  {
    "text": "blockchain in 2017 because I used to get the abduction there uh it we tried to",
    "start": "2817060",
    "end": "2823359"
  },
  {
    "text": "put blockchain everywhere but sometimes you don't need blockchain the simple button can do the same thing",
    "start": "2823359",
    "end": "2829560"
  },
  {
    "text": "uh and I think I think llms is amazing and can do plenty things but sometimes",
    "start": "2829560",
    "end": "2835480"
  },
  {
    "text": "just a simple you know checkbox can go a long way",
    "start": "2835480",
    "end": "2841319"
  },
  {
    "text": "um going to another question do you plan to add website crawl and scrape features",
    "start": "2841780",
    "end": "2846819"
  },
  {
    "text": "so we could ask quiver about for example online Docs yeah so",
    "start": "2846819",
    "end": "2852760"
  },
  {
    "text": "uh this one has been a tough one uh so if you want there's a an issue that has",
    "start": "2852760",
    "end": "2859720"
  },
  {
    "text": "been started you know a Week Ago by one guy taken back by another one and it's",
    "start": "2859720",
    "end": "2866079"
  },
  {
    "text": "it's walking the only thing is here the installation of chrome is uh platform is",
    "start": "2866079",
    "end": "2873520"
  },
  {
    "text": "not platform agnostic so that means that we have to have a Docker file that is different for each platform and that I",
    "start": "2873520",
    "end": "2880300"
  },
  {
    "text": "don't want I just want to have to do a type 1 comment so the code is working you can call in that website",
    "start": "2880300",
    "end": "2888400"
  },
  {
    "text": "um you know Max Page Max time uh if you want yes when doing or not but just this part is blocking so I",
    "start": "2888400",
    "end": "2896380"
  },
  {
    "text": "haven't found the time yet to debug but yeah it's we are",
    "start": "2896380",
    "end": "2902800"
  },
  {
    "text": "I couldn't I could you know merge the file but that would mean that",
    "start": "2902800",
    "end": "2909760"
  },
  {
    "text": "um it would or the docker file would only work on old on Intel computers",
    "start": "2909760",
    "end": "2915640"
  },
  {
    "text": "and not on my MacBook for example I'd like to do something else different and this is not something I want to do",
    "start": "2915640",
    "end": "2923619"
  },
  {
    "text": "yeah yeah all right another question I see is",
    "start": "2923619",
    "end": "2928839"
  },
  {
    "text": "about uh local models um do you plan to support local open",
    "start": "2928839",
    "end": "2934240"
  },
  {
    "text": "source llm which and and when uh so this is something that we are so",
    "start": "2934240",
    "end": "2940960"
  },
  {
    "text": "with um I'm planning on you know talking with Ivan from a private GPT on Monday so we",
    "start": "2940960",
    "end": "2948640"
  },
  {
    "text": "have been talking with Ivan and there's one thing that I need uh from him is the",
    "start": "2948640",
    "end": "2954839"
  },
  {
    "text": "ability to use his uh package uh you",
    "start": "2954839",
    "end": "2960220"
  },
  {
    "text": "know and bought it into Quaver so I'm waiting on him to implement this functionality but I'm planning on using",
    "start": "2960220",
    "end": "2966579"
  },
  {
    "text": "private GPT and later on if you want you know you could use other ones but the first one",
    "start": "2966579",
    "end": "2972760"
  },
  {
    "text": "is private GPT and it's going to happen uh I have let me find it I have a quiver",
    "start": "2972760",
    "end": "2980260"
  },
  {
    "text": "I have a roadmap will not let me sign it",
    "start": "2980260",
    "end": "2987240"
  },
  {
    "text": "so this is the quiver roadmap so we are here so we are done almost done with the",
    "start": "2987700",
    "end": "2994000"
  },
  {
    "text": "game one then we have you know the streaming so the documents one one multiple documents from that",
    "start": "2994000",
    "end": "2999940"
  },
  {
    "text": "conversation and shareable brains and then it's going to be local edit apps",
    "start": "2999940",
    "end": "3006540"
  },
  {
    "text": "and so this one will be so this is like we are talking two weeks you know in two",
    "start": "3006540",
    "end": "3012359"
  },
  {
    "text": "weeks time we will be able to use uh private uh elements it just has been so",
    "start": "3012359",
    "end": "3018060"
  },
  {
    "text": "fast that's awesome um yeah but yeah and this the summarization metadata",
    "start": "3018060",
    "end": "3025560"
  },
  {
    "text": "enrichment is is what we chatted about earlier exactly",
    "start": "3025560",
    "end": "3030660"
  },
  {
    "text": "so um it's it's something that needs to happen because right now quiver is just not a beautiful document retriever",
    "start": "3030660",
    "end": "3038520"
  },
  {
    "text": "but it's not very efficient so we need to to be able to uh to use it",
    "start": "3038520",
    "end": "3043560"
  },
  {
    "text": "efficiently I had more information allow people to create their own prompts",
    "start": "3043560",
    "end": "3048599"
  },
  {
    "text": "because the prompt that you want if you are you know if your brain is here to",
    "start": "3048599",
    "end": "3055319"
  },
  {
    "text": "help you answer questions on you know issues with uh technical things",
    "start": "3055319",
    "end": "3061140"
  },
  {
    "text": "The Prompt might be different than if you ask questions about the book",
    "start": "3061140",
    "end": "3066599"
  },
  {
    "text": "if you ask questions about the book she wants the prompt to not deviate from the context if you ask questions about",
    "start": "3066599",
    "end": "3074040"
  },
  {
    "text": "technical issues you might want the prompt to tell the local language model",
    "start": "3074040",
    "end": "3081020"
  },
  {
    "text": "to try to answer the question with the context but if it doesn't exist it can create an answer you know",
    "start": "3081020",
    "end": "3088200"
  },
  {
    "text": "from its knowledge is that what specialized brains mean or",
    "start": "3088200",
    "end": "3093660"
  },
  {
    "text": "what is what is specialized brains I see a question I see a question uh in the chat about specialized brains as well so",
    "start": "3093660",
    "end": "3100079"
  },
  {
    "text": "uh it's it's something I I want to to be able to allow people to uh fine-tune",
    "start": "3100079",
    "end": "3106980"
  },
  {
    "text": "some models and make it and make them very efficient and understanding specific",
    "start": "3106980",
    "end": "3113640"
  },
  {
    "text": "um types of files or context so let's say CSV is uh or PDF I talk about one",
    "start": "3113640",
    "end": "3121920"
  },
  {
    "text": "specific thing I want them to be very efficient at one task yeah and uh so it's not very you know",
    "start": "3121920",
    "end": "3130800"
  },
  {
    "text": "for now it's just something I haven't thought a lot about it but we need to it's like a part of your",
    "start": "3130800",
    "end": "3136319"
  },
  {
    "text": "brain that is very good at one thing and one thing only yeah and yeah yeah we'll see what how it",
    "start": "3136319",
    "end": "3144180"
  },
  {
    "text": "happens and there is Open Source Point let's see I want to people to be able to create and",
    "start": "3144180",
    "end": "3149520"
  },
  {
    "text": "you know what the same thing you're doing with long chain Hub is to be able to download them you know uh privilege",
    "start": "3149520",
    "end": "3157440"
  },
  {
    "text": "grains especially and then the last one is the visual",
    "start": "3157440",
    "end": "3165839"
  },
  {
    "text": "document editor so it's the ability to edit your brain from the weather",
    "start": "3165839",
    "end": "3172160"
  },
  {
    "text": "all right I think we're just about running uh short on time so any last words of wisdom that you would like to",
    "start": "3175619",
    "end": "3181920"
  },
  {
    "text": "leave us with think you're looking forward to things on the roadmap things",
    "start": "3181920",
    "end": "3187319"
  },
  {
    "text": "you want help with yeah I mean yeah words of wisdom",
    "start": "3187319",
    "end": "3193020"
  },
  {
    "text": "uh just have fun and try to build something I mean it's it's amazing what you can build and you know Frameworks",
    "start": "3193020",
    "end": "3200640"
  },
  {
    "text": "like uh yours like function really help create amazing",
    "start": "3200640",
    "end": "3206579"
  },
  {
    "text": "applications and you know guys just try and do one thing and you might you know",
    "start": "3206579",
    "end": "3214020"
  },
  {
    "text": "do a webinar about it in a couple of weeks you know and uh just have fun on",
    "start": "3214020",
    "end": "3219059"
  },
  {
    "text": "the way and a lot of people are looking uh and they're doing things so",
    "start": "3219059",
    "end": "3225780"
  },
  {
    "text": "just try and build something and it took me less than so it took me like 200",
    "start": "3225780",
    "end": "3231300"
  },
  {
    "text": "lines of code to build the first edition of quiver and yeah so have fun",
    "start": "3231300",
    "end": "3239280"
  },
  {
    "text": "just have fun and build I love that that's definitely going to be when I when I tweet about the YouTube link that is definitely going to be the uh I think",
    "start": "3239280",
    "end": "3246300"
  },
  {
    "text": "there um thanks for joining me Stan this was a lot of fun this was yeah I think this",
    "start": "3246300",
    "end": "3251880"
  },
  {
    "text": "was this is a great Deep dive we talked about product we talked about tech stuff I hope people enjoyed it",
    "start": "3251880",
    "end": "3258000"
  },
  {
    "text": "um I hope you enjoyed it and uh",
    "start": "3258000",
    "end": "3261740"
  }
]
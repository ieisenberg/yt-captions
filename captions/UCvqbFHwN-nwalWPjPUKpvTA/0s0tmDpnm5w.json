[
  {
    "start": "0",
    "end": "136000"
  },
  {
    "text": "hello everyone this is vikas and nick from tetrad at data we work at stu and other",
    "start": "0",
    "end": "6960"
  },
  {
    "text": "service smash technologies around stu in this talk we are going to discuss and",
    "start": "6960",
    "end": "15120"
  },
  {
    "text": "share our experiences and learnings that we gained while working with some of our large",
    "start": "15120",
    "end": "20480"
  },
  {
    "text": "enterprise customers trying to help them in magifying their multi-cluster installations",
    "start": "20480",
    "end": "27279"
  },
  {
    "text": "this stock is roughly divided into four sections in the first section we will discuss",
    "start": "27279",
    "end": "32640"
  },
  {
    "text": "about the complexity and the manageability issues in the large scale multi-cluster installations",
    "start": "32640",
    "end": "39840"
  },
  {
    "text": "then assuming that service smash and histo is going to help in managing these",
    "start": "39840",
    "end": "45840"
  },
  {
    "text": "problems we will see the gap and pain points if we try to follow",
    "start": "45840",
    "end": "51520"
  },
  {
    "text": "this tube community suggested multi-cluster installation approaches for overlaying steel mesh",
    "start": "51520",
    "end": "57900"
  },
  {
    "text": "[Music] installations and then we will discuss",
    "start": "57900",
    "end": "63280"
  },
  {
    "text": "in the next two sections our our approach which is a bit",
    "start": "63280",
    "end": "68640"
  },
  {
    "text": "more practical and and and how it is addressing the pain points",
    "start": "68640",
    "end": "74479"
  },
  {
    "text": "and the gaps that we found in the community suggested installation approaches",
    "start": "74479",
    "end": "81040"
  },
  {
    "text": "so next uh passing over to nick to start with the problems of the multi-cluster",
    "start": "81040",
    "end": "87119"
  },
  {
    "text": "installations thank you yeah congratulations everybody you've been",
    "start": "87119",
    "end": "92560"
  },
  {
    "text": "you've made it to multi-cluster you've successfully scaled your application from a single cluster to multiple",
    "start": "92560",
    "end": "100159"
  },
  {
    "text": "but you're looking at back and your slas haven't improved um you broke a bunch of security rules",
    "start": "100159",
    "end": "106799"
  },
  {
    "text": "in doing so um so that you could get the networking to connect properly and then you're",
    "start": "106799",
    "end": "112159"
  },
  {
    "text": "realizing that management has got a lot more difficult it seems like the problems that you're",
    "start": "112159",
    "end": "117439"
  },
  {
    "text": "facing are bigger than the ones you were doing earlier so trading off a better sla",
    "start": "117439",
    "end": "125600"
  },
  {
    "text": "for more problems didn't really seem advantageous to you and so we're going to walk through some of these problems that a lot of our customers have early",
    "start": "125600",
    "end": "132080"
  },
  {
    "text": "on when they're adopting the multi-cluster model the first one that we want to talk about",
    "start": "132080",
    "end": "138319"
  },
  {
    "start": "136000",
    "end": "136000"
  },
  {
    "text": "is the this is a typical deployment that we that you would see when you go from a one to multi-cluster",
    "start": "138319",
    "end": "146000"
  },
  {
    "text": "environment typically you have a low balancer within the cluster um",
    "start": "146000",
    "end": "151519"
  },
  {
    "text": "engine x ingress is like the default one that most you're probably familiar with and then we connect all of those",
    "start": "151519",
    "end": "158879"
  },
  {
    "text": "clusters and do the routing with a tier one which we call tier one low balance here which is typically your",
    "start": "158879",
    "end": "164319"
  },
  {
    "text": "your cloud load balancer and that's so you have a single point of entry and can route between multiple clusters but",
    "start": "164319",
    "end": "171360"
  },
  {
    "text": "you're you're team one you've you've been tasked to move your microservice from one cluster",
    "start": "171360",
    "end": "176640"
  },
  {
    "text": "into a multicultural environment now um you're you're gonna follow the coattails of team two who's already been doing it for a little",
    "start": "176640",
    "end": "182879"
  },
  {
    "text": "while and so you're going to take your application and stick it behind that same default low balancer",
    "start": "182879",
    "end": "188720"
  },
  {
    "text": "that that team won or team 2 has been using but also you start to know you have more",
    "start": "188720",
    "end": "195040"
  },
  {
    "text": "outages than you have before you've bound yourself now to the",
    "start": "195040",
    "end": "200159"
  },
  {
    "text": "failures of t2 uh team two's errors have now become your problem",
    "start": "200159",
    "end": "205360"
  },
  {
    "text": "because when they have problems their low bounces they cause the low balance to be removed from the pool",
    "start": "205360",
    "end": "210480"
  },
  {
    "text": "which is now causing outages for you and so there's all there's cases where going",
    "start": "210480",
    "end": "216879"
  },
  {
    "text": "multi-cluster doesn't actually make anything better and so we're gonna have some solutions that will address these problems in a",
    "start": "216879",
    "end": "224000"
  },
  {
    "text": "very practical way secondly when you go to this",
    "start": "224000",
    "end": "230239"
  },
  {
    "start": "226000",
    "end": "226000"
  },
  {
    "text": "typical multi-cluster routing you're you don't have a",
    "start": "230239",
    "end": "236560"
  },
  {
    "text": "good way of being able to tell your microservice how to locally address services if",
    "start": "236560",
    "end": "242319"
  },
  {
    "text": "they're like within your cluster or within your region and so to get the aha",
    "start": "242319",
    "end": "248239"
  },
  {
    "text": "availability you're going to have to call up outside of your cluster to that tier one low balancer to",
    "start": "248239",
    "end": "254879"
  },
  {
    "text": "get access to the other micro service that your service that you're trying to",
    "start": "254879",
    "end": "260560"
  },
  {
    "text": "access and so if you typically only have like two options either you",
    "start": "260560",
    "end": "266080"
  },
  {
    "text": "route externally to that low balancer or directly internally to that that cluster that you're on but if you",
    "start": "266080",
    "end": "272320"
  },
  {
    "text": "wrote locally and that that pod or that service is down you have no failover",
    "start": "272320",
    "end": "280000"
  },
  {
    "start": "280000",
    "end": "280000"
  },
  {
    "text": "and finally as your multi-cluster architecture grows you can get some really complex",
    "start": "280479",
    "end": "286800"
  },
  {
    "text": "dependency chains um you it's be very difficult for you to trace",
    "start": "286800",
    "end": "292320"
  },
  {
    "text": "all the all of the consumers that depend on you and your functionality and so without service mesh",
    "start": "292320",
    "end": "300400"
  },
  {
    "text": "you'll find these problems are very prevalent um and so then you'll be looking for that solution which you know service",
    "start": "300400",
    "end": "307280"
  },
  {
    "text": "mess seems to be the one that'll that'll solve these problems for you",
    "start": "307280",
    "end": "312400"
  },
  {
    "start": "312000",
    "end": "312000"
  },
  {
    "text": "and so as you're adopting service mesh there's a lot of questions that our customers are asking and how do you go about doing it in the",
    "start": "312400",
    "end": "318960"
  },
  {
    "text": "correct way you know am i adding more complexity to my architecture when multi-clusters already made it",
    "start": "318960",
    "end": "324960"
  },
  {
    "text": "complex i chose istio and now when i upgraded it i've lost connectivity to everything and",
    "start": "324960",
    "end": "331600"
  },
  {
    "text": "so we're having larger production outages do i need to re-architect my multi-cluster",
    "start": "331600",
    "end": "337759"
  },
  {
    "text": "up so that i can adopt service mesh and so a lot of these questions um we'll answer later in the slides",
    "start": "337759",
    "end": "346160"
  },
  {
    "text": "and i'll pass over to the cost to start with the istio solution",
    "start": "346880",
    "end": "352240"
  },
  {
    "text": "uh so yeah there's no denying that uh istio is super powerful it can",
    "start": "352240",
    "end": "359199"
  },
  {
    "text": "it's you can help in in in in is you can help in",
    "start": "359199",
    "end": "365759"
  },
  {
    "text": "managing these complexities of multi-cluster installations but but how exactly i am going to",
    "start": "365759",
    "end": "373580"
  },
  {
    "text": "[Music] overlays to measure multi-cluster installations because there are different teams",
    "start": "373580",
    "end": "380560"
  },
  {
    "text": "different different personas different uh administrative uh boundaries over these clusters so how",
    "start": "380560",
    "end": "388400"
  },
  {
    "text": "how one is going to do that so we'll start with taking a look over",
    "start": "388400",
    "end": "396400"
  },
  {
    "text": "what the steel community documentation has been suggesting so at",
    "start": "396400",
    "end": "402400"
  },
  {
    "text": "the moment there are in the latest release which is 1.7 there are two multi-cluster installation",
    "start": "402400",
    "end": "408560"
  },
  {
    "text": "approaches the one is replicated control planes and another one is shared control plane because of the",
    "start": "408560",
    "end": "415199"
  },
  {
    "text": "resiliency requirements we can rule out the shared control plane",
    "start": "415199",
    "end": "420840"
  },
  {
    "text": "approach and let's take a deeper look at the replicated control planes approach",
    "start": "420840",
    "end": "428400"
  },
  {
    "text": "so how this works is that in your clusters each cluster has",
    "start": "429360",
    "end": "434840"
  },
  {
    "text": "independent seo control plane running and the and the ca",
    "start": "434840",
    "end": "441919"
  },
  {
    "text": "of each of the issues control plane on these clusters is configured with the intermediate cs",
    "start": "441919",
    "end": "448639"
  },
  {
    "text": "which are generated from the same shared root ca the services which are the shared",
    "start": "448639",
    "end": "455440"
  },
  {
    "text": "services and are supposed to be accessed from the remote clusters are",
    "start": "455440",
    "end": "461039"
  },
  {
    "text": "exposed through service entries for example here the service who which is in the cluster 2",
    "start": "461039",
    "end": "466720"
  },
  {
    "text": "is exposed on the cluster 1 using a service entry and the host name in the service entry",
    "start": "466720",
    "end": "472639"
  },
  {
    "text": "has this dot global prefix added to the name and namespace",
    "start": "472639",
    "end": "478000"
  },
  {
    "text": "of the service and the endpoints of the service entry points to the",
    "start": "478000",
    "end": "483440"
  },
  {
    "text": "gateways of the remote clusters at runtime it looks something like this when a",
    "start": "483440",
    "end": "491280"
  },
  {
    "start": "488000",
    "end": "488000"
  },
  {
    "text": "client makes a request it goes to kubernetes a dns server kubernetes kubernetes dns",
    "start": "491280",
    "end": "499199"
  },
  {
    "text": "we have to run with a core dns plugin which is shipped by",
    "start": "499199",
    "end": "505840"
  },
  {
    "text": "all so all the dot global prefixed hostname queries um kubernetes dns pass these",
    "start": "505840",
    "end": "513279"
  },
  {
    "text": "queries to core dns and poor dns resolves these",
    "start": "513279",
    "end": "518320"
  },
  {
    "text": "these hostname dns queries with the virtual id of the service entry",
    "start": "518640",
    "end": "523760"
  },
  {
    "text": "and using this virtual ip on the sidecar picks up the listener",
    "start": "523760",
    "end": "529200"
  },
  {
    "text": "and there the listener has the is pointing to the remote gateway where the actual the services the back-end",
    "start": "529200",
    "end": "536480"
  },
  {
    "text": "service is running and this way the request reaches there is cluster tools gateway",
    "start": "536480",
    "end": "542080"
  },
  {
    "text": "and sni host it still has the hostname which has got global prefix so it won't make to the",
    "start": "542080",
    "end": "548880"
  },
  {
    "text": "actual backend service so there a an online filter is configured to to translate this top global from the",
    "start": "548880",
    "end": "556720"
  },
  {
    "text": "si host to the service store cluster total local so now",
    "start": "556720",
    "end": "562320"
  },
  {
    "text": "um this gateway on the cluster 2 can finally forward the request to the",
    "start": "562320",
    "end": "568880"
  },
  {
    "text": "actual service implementation but",
    "start": "568880",
    "end": "574560"
  },
  {
    "start": "572000",
    "end": "572000"
  },
  {
    "text": "can we can we use this in our production environments unfortunately not and why not is because",
    "start": "574560",
    "end": "583600"
  },
  {
    "text": "it it doesn't support locality aware routing out of the box we cannot simply if if we have um",
    "start": "583600",
    "end": "591920"
  },
  {
    "text": "if we have a local instance of the service running in cluster ideally it is desired that the for that",
    "start": "591920",
    "end": "599440"
  },
  {
    "text": "the first priority should be uh the request should be served by the local instance",
    "start": "599440",
    "end": "605200"
  },
  {
    "text": "so we should be able to somehow the local instance should be part of the",
    "start": "605200",
    "end": "610320"
  },
  {
    "text": "load balancer pool but we cannot simply here in this approach we cannot simply put the",
    "start": "610320",
    "end": "615440"
  },
  {
    "text": "cluster ip in the service entry endpoints and the reason is the same this dot global thing",
    "start": "615440",
    "end": "621120"
  },
  {
    "text": "we can fix this we can make it correct by adding um virtual service to rewrite this host",
    "start": "621120",
    "end": "628000"
  },
  {
    "text": "name converting this door global to canonical name of the service in the local",
    "start": "628000",
    "end": "634480"
  },
  {
    "text": "local cluster but this problem is not the only problem there is there are much",
    "start": "634480",
    "end": "640079"
  },
  {
    "text": "bigger problems than this in this approach the so so the host names",
    "start": "640079",
    "end": "647279"
  },
  {
    "text": "in the clients uh are directly depending on the actual back-end implementation of the",
    "start": "647279",
    "end": "653600"
  },
  {
    "text": "services so let me explain you with this example here the actual service is foo which is running",
    "start": "653600",
    "end": "660000"
  },
  {
    "text": "in the funnest name space in the cluster too so the the clients on the remote",
    "start": "660000",
    "end": "665040"
  },
  {
    "text": "clusters here at the cluster one should use the host name uh which is the",
    "start": "665040",
    "end": "670079"
  },
  {
    "text": "service name actual service name dot service name space namespace.global and this is pretty bad",
    "start": "670079",
    "end": "675680"
  },
  {
    "text": "because if there are n number of clusters serving this uh service serving this",
    "start": "675680",
    "end": "683680"
  },
  {
    "text": "api serving this service then the owner of these services cannot",
    "start": "683680",
    "end": "689920"
  },
  {
    "text": "change the backend implementation of the service at all because the clients will get broken in that case so",
    "start": "689920",
    "end": "697760"
  },
  {
    "text": "in other words we can say there is no abstraction the clients are directly depending on the actual backend implementation",
    "start": "698800",
    "end": "705120"
  },
  {
    "text": "and there is no very straightforward locality aware routing as well",
    "start": "705120",
    "end": "712079"
  },
  {
    "text": "these points are already acknowledged by the history community as well and we also part of this community and we",
    "start": "712160",
    "end": "718079"
  },
  {
    "text": "have been working to come up with better installation approaches so in the 1.8 uh we have this",
    "start": "718079",
    "end": "725360"
  },
  {
    "text": "a new approach and and this replicated control plane is not there anymore in",
    "start": "725360",
    "end": "730480"
  },
  {
    "text": "the coming releases but so in this approach for example which is coming",
    "start": "730480",
    "end": "735600"
  },
  {
    "text": "here each here also we have a stereo control plane running in each of the clusters",
    "start": "735600",
    "end": "740720"
  },
  {
    "text": "and what change here is this that the study of each cluster is watching the api",
    "start": "740720",
    "end": "746959"
  },
  {
    "text": "servers of all the remote clusters so this solves the locality the aware",
    "start": "746959",
    "end": "752320"
  },
  {
    "text": "routing problem because uh because the end points it has",
    "start": "752320",
    "end": "758079"
  },
  {
    "text": "because it has all the local endpoints and the remote endpoint in the same lb pool",
    "start": "758079",
    "end": "763360"
  },
  {
    "text": "but the problem of the direct dependency on the canonical name of the service and",
    "start": "763360",
    "end": "768480"
  },
  {
    "text": "namespace is still there still there is no abstraction and plus the scalability issues are there and the",
    "start": "768480",
    "end": "774639"
  },
  {
    "text": "security concerns are there because these clusters are owned by different teams and they may not want to",
    "start": "774639",
    "end": "779839"
  },
  {
    "text": "expose all their internal implementation of the services to other teams",
    "start": "779839",
    "end": "787600"
  },
  {
    "text": "so that's where we we had to come up with a different approach to meet the requirements of our",
    "start": "787600",
    "end": "793519"
  },
  {
    "text": "customers and now i'm passing over to nick to explain our approach yeah so we we",
    "start": "793519",
    "end": "799920"
  },
  {
    "text": "took a look at this um and looked at our customers problems and",
    "start": "799920",
    "end": "804959"
  },
  {
    "text": "our customers have many many clusters that they want to connect together um and span multiple clouds",
    "start": "804959",
    "end": "813200"
  },
  {
    "text": "and so we we wanted an approach that was somewhat simplistic and practical to",
    "start": "813200",
    "end": "819199"
  },
  {
    "text": "their use cases and it didn't require a lot of um architectural core potential changes",
    "start": "819199",
    "end": "824639"
  },
  {
    "text": "within their environments to adopt this service mesh architecture um and then we also want to put a little",
    "start": "824639",
    "end": "830800"
  },
  {
    "text": "a little bit of the application developer in mind when we when we deploy these",
    "start": "830800",
    "end": "838320"
  },
  {
    "start": "838000",
    "end": "838000"
  },
  {
    "text": "and so what kind of developer mindset did we try to assume when we were coming up with this",
    "start": "838320",
    "end": "844079"
  },
  {
    "text": "solution well developers just want to consume applications as sas products even",
    "start": "844079",
    "end": "851680"
  },
  {
    "text": "internally they want to access your api that assume that it's ha",
    "start": "851680",
    "end": "858079"
  },
  {
    "text": "and that you're you're routing locally or you know efficiently and so they don't",
    "start": "858079",
    "end": "863519"
  },
  {
    "text": "really necessarily care where your your service is hosted it's that they can just reach it easily they want to spend more time on",
    "start": "863519",
    "end": "871199"
  },
  {
    "text": "implementing the features that are really going to drive that product rather than spending time on a lot of",
    "start": "871199",
    "end": "878160"
  },
  {
    "text": "the implementation details with auth routing networking and a lot",
    "start": "878160",
    "end": "883199"
  },
  {
    "text": "of stuff that comes with service mesh or or even without and they want to be able to advertise",
    "start": "883199",
    "end": "889760"
  },
  {
    "text": "their own products effectively and easily to either external customers or to other teams",
    "start": "889760",
    "end": "895120"
  },
  {
    "text": "within their organization and so with that in mind we came up with a",
    "start": "895120",
    "end": "900639"
  },
  {
    "text": "much more simplistic approach to uh initial installation and that's by deploying istio",
    "start": "900639",
    "end": "908000"
  },
  {
    "text": "essentially isolated per cluster we deploy the control plane",
    "start": "908000",
    "end": "913120"
  },
  {
    "text": "on every cluster we scope that control plane to only know about services within",
    "start": "913120",
    "end": "918399"
  },
  {
    "text": "the cluster that it's residing and so we have a locally scoped mesh",
    "start": "918399",
    "end": "924000"
  },
  {
    "text": "we say that you should manage these control planes externally and you can do so with a number of tools",
    "start": "924000",
    "end": "929440"
  },
  {
    "text": "um ci tools github and so that'll take away the the managing",
    "start": "929440",
    "end": "936240"
  },
  {
    "text": "everything individually and then we the final point is we really want you to embrace gateways a little bit differently than you are",
    "start": "936240",
    "end": "942320"
  },
  {
    "text": "today and expand upon the use of those",
    "start": "942320",
    "end": "946800"
  },
  {
    "text": "but why so why do we want to do separate pistol control points well we really want to align the failure",
    "start": "947360",
    "end": "954000"
  },
  {
    "text": "domains of your application to that cluster and so if you push bad configs or you upgrade",
    "start": "954000",
    "end": "962079"
  },
  {
    "text": "istio incorrectly and it causes an outage it is now localized to that cluster that you were working",
    "start": "962079",
    "end": "967440"
  },
  {
    "text": "and so it gives you a lot more control over not bringing down your entire environment",
    "start": "967440",
    "end": "973759"
  },
  {
    "text": "and it aligns that issue control plane with the underlying cluster that it's running out so networking and",
    "start": "973759",
    "end": "979279"
  },
  {
    "text": "node management stuff like that and so it's a lot a lot more effective for our customers to manage them these days",
    "start": "979279",
    "end": "985519"
  },
  {
    "text": "and ca especially for outages um and then it also allows you to do safer upgrades so as you upgrade issue you",
    "start": "985519",
    "end": "991440"
  },
  {
    "text": "might be able to pick a cluster that has less usage update that one if it goes successfully then you can",
    "start": "991440",
    "end": "997279"
  },
  {
    "text": "roll it out to other clusters and this this would differ from the",
    "start": "997279",
    "end": "1002320"
  },
  {
    "text": "shared control plane that was one of the seo recommendations",
    "start": "1002320",
    "end": "1008879"
  },
  {
    "text": "um but we have a problem we can't then applications cannot see up services in",
    "start": "1009519",
    "end": "1015440"
  },
  {
    "text": "other clusters and so we need to adjust this problem and so the way that we",
    "start": "1015440",
    "end": "1023759"
  },
  {
    "text": "uh want you to go about doing this is by embracing gateways and gateways are just low balancers that",
    "start": "1023759",
    "end": "1029438"
  },
  {
    "start": "1026000",
    "end": "1026000"
  },
  {
    "text": "are fronting your applications um but we want you to use them on a product focused",
    "start": "1029439",
    "end": "1036000"
  },
  {
    "text": "architecture and so currently you're probably using the engine x ingress gateway or you're if you're using istio the",
    "start": "1036000",
    "end": "1042798"
  },
  {
    "text": "defaulting gas gateway and istio system but we want you to kind of get rid of those and move",
    "start": "1042799",
    "end": "1048480"
  },
  {
    "text": "to this product focus database and so in istio that's really easy you can just stand up any number of",
    "start": "1048480",
    "end": "1054880"
  },
  {
    "text": "ingress gateways and then determine the services that are are behind it",
    "start": "1054880",
    "end": "1060480"
  },
  {
    "text": "or upstream from it and so these product focus gateways then allow you to control the micro services",
    "start": "1060480",
    "end": "1066960"
  },
  {
    "text": "behind it as if there are one api and so you can expose your api",
    "start": "1066960",
    "end": "1072720"
  },
  {
    "text": "uh internally or externally via this gateway and now you've aligned",
    "start": "1072720",
    "end": "1078080"
  },
  {
    "text": "the failure domain of this gateway with the product that that it's supporting and so you're not you won't have the",
    "start": "1078080",
    "end": "1084720"
  },
  {
    "text": "shared gateway problem where other products could bring you down um and it just requires you to stand up",
    "start": "1084720",
    "end": "1091919"
  },
  {
    "text": "more gateways and then you'll be able to talk across cluster a lot easier and we'll explain why in a sec",
    "start": "1091919",
    "end": "1098240"
  },
  {
    "text": "um then you can also push your off authentication and",
    "start": "1098240",
    "end": "1103840"
  },
  {
    "text": "authorization circuit breaking up into this gateway and then tune it specifically for your applications that are behind it",
    "start": "1103840",
    "end": "1109679"
  },
  {
    "text": "and so it's a really purpose-built gateway for your product",
    "start": "1109679",
    "end": "1115280"
  },
  {
    "start": "1115000",
    "end": "1115000"
  },
  {
    "text": "so in a in a cluster this is kind of what you would imagine",
    "start": "1115919",
    "end": "1121520"
  },
  {
    "text": "logically what is happening from using a gateway the consumer name space on the right here",
    "start": "1121520",
    "end": "1129440"
  },
  {
    "text": "is not related to the payments api product but it does consume that api and so logically you should be consuming",
    "start": "1129440",
    "end": "1136160"
  },
  {
    "text": "it at the gateway level that allows you to scale microservices add functionality behind it without interruption of that",
    "start": "1136160",
    "end": "1143120"
  },
  {
    "text": "service and so when when we go to a multi-cluster environment",
    "start": "1143120",
    "end": "1148880"
  },
  {
    "text": "this becomes really easy we can then just replicate that payments",
    "start": "1148880",
    "end": "1155120"
  },
  {
    "text": "namespace into another cluster with that gateway in as a whole package and then",
    "start": "1155120",
    "end": "1162400"
  },
  {
    "text": "the consumer namespace now has multiple endpoints to reach you at and so we we add those those hosts to",
    "start": "1162400",
    "end": "1170240"
  },
  {
    "text": "that consumer namespace so now it has two options so making your your payments api",
    "start": "1170240",
    "end": "1176320"
  },
  {
    "text": "highly available but we didn't have to stop there we can",
    "start": "1176320",
    "end": "1181840"
  },
  {
    "text": "say we can do some more intelligent routing that's saying if your consumer is in the same",
    "start": "1181840",
    "end": "1188960"
  },
  {
    "text": "cluster as the gateway that it's consuming and that gateway is closer than say an",
    "start": "1188960",
    "end": "1195280"
  },
  {
    "text": "external gateway in another cluster let's prefer routing locally first",
    "start": "1195280",
    "end": "1200880"
  },
  {
    "text": "and so if you're in the same cluster we can actually use the sidecar to act as the gateway and so in this example this is",
    "start": "1200880",
    "end": "1208000"
  },
  {
    "text": "what we're doing we're using the sidecar to act as the gateway to those microservices to access them directly",
    "start": "1208000",
    "end": "1214480"
  },
  {
    "text": "but in the case of failure or outage we can actually reroute requests over to the cluster 2",
    "start": "1214480",
    "end": "1221760"
  },
  {
    "text": "in the u.s west region so you still get that highly available but now we've added a component",
    "start": "1221760",
    "end": "1227760"
  },
  {
    "text": "of this intelligent local aware routing this is really cost effective",
    "start": "1227760",
    "end": "1233919"
  },
  {
    "text": "for our larger clients that have high volumes of traffic and egress and they're paying a lot for",
    "start": "1233919",
    "end": "1239840"
  },
  {
    "text": "egress data so why should you embrace gateways more",
    "start": "1239840",
    "end": "1246480"
  },
  {
    "text": "than you are today it gives you a way to abstract your apis and your microservices",
    "start": "1246480",
    "end": "1252320"
  },
  {
    "text": "and with a product spin on a product focus is really architected for growing those",
    "start": "1252320",
    "end": "1259760"
  },
  {
    "text": "in a multi-cluster environment it's more of a copy paste than a one-off or",
    "start": "1259760",
    "end": "1265280"
  },
  {
    "text": "trying to figure out who owns the local",
    "start": "1265280",
    "end": "1269200"
  },
  {
    "text": "who owns the local ingress gateway so you can attach your resources to it",
    "start": "1270880",
    "end": "1277440"
  },
  {
    "text": "and then it aligns a lot more with the non-mesh architectures that exist today they're very low balancer centric and so",
    "start": "1277440",
    "end": "1284400"
  },
  {
    "text": "gateway really fits that low balance and we're just empowering the gateway to be a lot",
    "start": "1284400",
    "end": "1290480"
  },
  {
    "text": "more intelligent about the traffic that it's not that it's routing so if we put this all together",
    "start": "1290480",
    "end": "1298880"
  },
  {
    "text": "and what we're doing at tetra is we're making that gateway discovery automated and so from any number of",
    "start": "1298880",
    "end": "1305520"
  },
  {
    "text": "clusters that you you can stand up the gateways will automatically be discoverable in all other clusters so that means we",
    "start": "1305520",
    "end": "1312640"
  },
  {
    "text": "don't need to know about all the other services microservices running in other clusters",
    "start": "1312640",
    "end": "1317679"
  },
  {
    "text": "we just need to know where those gateway in ingress gateways are we are making sure",
    "start": "1317679",
    "end": "1323120"
  },
  {
    "text": "that when you run to those other gateways outside of your own cluster that it's encrypted and it's",
    "start": "1323120",
    "end": "1328400"
  },
  {
    "text": "authorized and then we're also implementing locality-based routing so",
    "start": "1328400",
    "end": "1334400"
  },
  {
    "text": "to improve your cost savings and then failover to failover effectively and then finally",
    "start": "1334400",
    "end": "1342159"
  },
  {
    "text": "we're using um a newer technology seo which is mesh dns but it allows you to",
    "start": "1342159",
    "end": "1347600"
  },
  {
    "text": "eliminate the need for that name space routing that the cost was talking about earlier you can",
    "start": "1347600",
    "end": "1353600"
  },
  {
    "text": "essentially use your own abstracted dns for these gateways",
    "start": "1353600",
    "end": "1359280"
  },
  {
    "text": "to more represent the product that you're offering um so hand over across to talk a little",
    "start": "1359280",
    "end": "1365200"
  },
  {
    "text": "bit more about how we're doing some of this uh routing and gateway management",
    "start": "1365200",
    "end": "1371440"
  },
  {
    "text": "thanks nate all right so so from the service owner point of view",
    "start": "1371440",
    "end": "1379120"
  },
  {
    "start": "1373000",
    "end": "1373000"
  },
  {
    "text": "exposing a service to the external user has the same security concerns if the",
    "start": "1379120",
    "end": "1386159"
  },
  {
    "text": "if the intention is to expose the service within the mesh but to the remote clusters which are",
    "start": "1386159",
    "end": "1392799"
  },
  {
    "text": "sitting across the public internet but essentially whether it so even the",
    "start": "1392799",
    "end": "1398159"
  },
  {
    "text": "even the request is coming from within the mesh but it is coming through the public internet",
    "start": "1398159",
    "end": "1403520"
  },
  {
    "text": "so in so with this point we",
    "start": "1403520",
    "end": "1410880"
  },
  {
    "start": "1406000",
    "end": "1406000"
  },
  {
    "text": "in our model the service owner is supposed to just expose the service",
    "start": "1410880",
    "end": "1418000"
  },
  {
    "text": "to the external world over the chosen gateway port and",
    "start": "1418000",
    "end": "1425919"
  },
  {
    "text": "the user is supposed to configure the whatever security measures authentication and authorization",
    "start": "1425919",
    "end": "1432559"
  },
  {
    "text": "he or she feels comfortable with to deal with the public internet uh security concerns",
    "start": "1432559",
    "end": "1439840"
  },
  {
    "text": "and what we do programmatically is that the the the gateway hosts",
    "start": "1440240",
    "end": "1447520"
  },
  {
    "text": "the apis which are exposed to the external world we auto automatically expose these apis",
    "start": "1447520",
    "end": "1454799"
  },
  {
    "text": "within the mesh to be consumed from the remote clusters so what we do basically is that and this",
    "start": "1454799",
    "end": "1462400"
  },
  {
    "text": "this one five four four three is a reserved port for the stu mt ls",
    "start": "1462400",
    "end": "1468240"
  },
  {
    "text": "we we we discovered what the apis are exposed to the external world",
    "start": "1468240",
    "end": "1474480"
  },
  {
    "text": "and we expose the same apis over htmtrs on this reserved port",
    "start": "1474480",
    "end": "1480240"
  },
  {
    "text": "for the east-west traffic and additionally in addition to the mdls we apply",
    "start": "1480240",
    "end": "1487360"
  },
  {
    "text": "all the uh authentication and authorization configurations which are uh which are which the",
    "start": "1487360",
    "end": "1495039"
  },
  {
    "text": "user has configured for the external traffic we apply those on uh on this one five four four three port",
    "start": "1495039",
    "end": "1501120"
  },
  {
    "text": "as well so it is like double secure",
    "start": "1501120",
    "end": "1506399"
  },
  {
    "text": "in addition to that now this is a very important slide uh we create a local service entry as",
    "start": "1509840",
    "end": "1517039"
  },
  {
    "text": "well and the point to focus here is that the host name in the the host name in the service for example",
    "start": "1517039",
    "end": "1524799"
  },
  {
    "text": "here peer.example.com is same the same as the host which is",
    "start": "1524799",
    "end": "1530320"
  },
  {
    "text": "exposed to be consumed by external world over 944 report what this means is that",
    "start": "1530320",
    "end": "1536799"
  },
  {
    "text": "whether the client of the service is within this same cluster or in some",
    "start": "1536799",
    "end": "1543200"
  },
  {
    "text": "other remote cluster or some external user all are consuming this service",
    "start": "1543200",
    "end": "1549279"
  },
  {
    "text": "with the same abstracted api pay.example.com",
    "start": "1549279",
    "end": "1554640"
  },
  {
    "text": "and the the remote instances and the localist instance",
    "start": "1554840",
    "end": "1560000"
  },
  {
    "text": "are behind the same are part of the same load balancer pool",
    "start": "1560000",
    "end": "1565360"
  },
  {
    "text": "so and and and just one more implementation detail here to achieve this the end point in this",
    "start": "1566400",
    "end": "1574480"
  },
  {
    "text": "service entry is the local kubernetes cluster id",
    "start": "1574480",
    "end": "1580320"
  },
  {
    "text": "and now this is how it will look uh if there are more than one clusters where",
    "start": "1582880",
    "end": "1587919"
  },
  {
    "text": "this uh back-end service has instances running so this service entry in the local",
    "start": "1587919",
    "end": "1595679"
  },
  {
    "text": "cluster has two endpoints the one is the cluster ip of the",
    "start": "1595679",
    "end": "1601039"
  },
  {
    "text": "local service instance and this another one the in the green car this is uh this",
    "start": "1601039",
    "end": "1607600"
  },
  {
    "text": "is the gateway ip address of the remote cluster where one more instance",
    "start": "1607600",
    "end": "1613600"
  },
  {
    "text": "of the service is running",
    "start": "1613600",
    "end": "1616720"
  },
  {
    "start": "1619000",
    "end": "1619000"
  },
  {
    "text": "and now here now we are going to see at run time when the traffic when the",
    "start": "1621919",
    "end": "1628080"
  },
  {
    "text": "request flows from the client how it how how load balancing happens and",
    "start": "1628080",
    "end": "1633279"
  },
  {
    "text": "how it reaches the destination endpoint destination service so",
    "start": "1633279",
    "end": "1640080"
  },
  {
    "text": "first of all on when the client makes a request the client makes a request to the",
    "start": "1640080",
    "end": "1645360"
  },
  {
    "text": "abstracted api paid.example.com whether it is for the local links so",
    "start": "1645360",
    "end": "1652480"
  },
  {
    "text": "the client uh did not bother about where the service instance is running locally or globally or wherever it is",
    "start": "1652480",
    "end": "1659279"
  },
  {
    "text": "so abstracted api is used by the clients this goes uh to the sidecar and in the",
    "start": "1659279",
    "end": "1665279"
  },
  {
    "text": "sidecar we are using um a feature where uh the where the proxy hijacks the",
    "start": "1665279",
    "end": "1673440"
  },
  {
    "text": "dns queries and it caches the dns and uh and and resolves the resolves the",
    "start": "1673440",
    "end": "1682559"
  },
  {
    "text": "dns query with the virtual ip of the service entry",
    "start": "1682559",
    "end": "1689278"
  },
  {
    "text": "and then after the dns query gets resolved",
    "start": "1690960",
    "end": "1697039"
  },
  {
    "text": "then that request starts from the from the client container with the with",
    "start": "1697039",
    "end": "1704720"
  },
  {
    "text": "the virtual id of the service entry and now the site in the sidecar",
    "start": "1704720",
    "end": "1711039"
  },
  {
    "text": "matching with the virtual ip the listener is picked up the listener has um the endpoints to the",
    "start": "1711039",
    "end": "1717600"
  },
  {
    "text": "local instance as well as to the remote instances and because of the locality aware",
    "start": "1717600",
    "end": "1724080"
  },
  {
    "text": "routing in ideal case the local instances are",
    "start": "1724080",
    "end": "1729120"
  },
  {
    "text": "picked up and if there is no local instance",
    "start": "1729120",
    "end": "1734640"
  },
  {
    "text": "or the local instance is in failure mode then side cal will route the request to the remote",
    "start": "1734640",
    "end": "1740799"
  },
  {
    "text": "gateways and when it reaches the gateway",
    "start": "1740799",
    "end": "1745840"
  },
  {
    "text": "the request is over the htm tls plus additionally the gateway will",
    "start": "1745840",
    "end": "1751120"
  },
  {
    "text": "authorize the request using the using the extra authentication and",
    "start": "1751120",
    "end": "1756559"
  },
  {
    "text": "authorization configurations which the user service owner has configured for the",
    "start": "1756559",
    "end": "1761919"
  },
  {
    "text": "external uh external world so here it can be",
    "start": "1761919",
    "end": "1769039"
  },
  {
    "text": "any external oauth service which will authorize the request in addition to htmtls and if everything",
    "start": "1769039",
    "end": "1776080"
  },
  {
    "text": "passes then the request is gets routed to the actual instance",
    "start": "1776080",
    "end": "1782080"
  },
  {
    "text": "so just to summarize here um here we are using a abstracted api so",
    "start": "1782080",
    "end": "1789360"
  },
  {
    "text": "there is no dependency directly on the backend service and the secondly",
    "start": "1789360",
    "end": "1795279"
  },
  {
    "text": "the what api is the service owner wants to expose",
    "start": "1795279",
    "end": "1800399"
  },
  {
    "text": "he has full control on on the expo on the exposure of the apis",
    "start": "1800399",
    "end": "1806799"
  },
  {
    "text": "for example like whatever api he wants to expose to the consumed within the mesh or to the",
    "start": "1806799",
    "end": "1812159"
  },
  {
    "text": "external world the service owner will expose this on the gateway it is not that",
    "start": "1812159",
    "end": "1818399"
  },
  {
    "text": "the whole cluster is being washed upon by the remote remote clusters remote",
    "start": "1818399",
    "end": "1826159"
  },
  {
    "text": "studies so because of the time constraint we could cover this much only though we",
    "start": "1826159",
    "end": "1831760"
  },
  {
    "text": "are doing much more interesting stuff we are doing um",
    "start": "1831760",
    "end": "1837279"
  },
  {
    "text": "multi-tier we are handling multi-tier architectures as well we are handling where the clusters",
    "start": "1837279",
    "end": "1844480"
  },
  {
    "text": "are in the um the clusters are in are part of the different vpcs which are",
    "start": "1844480",
    "end": "1850559"
  },
  {
    "text": "not directly connected but talking through a shared vpcs so we would really",
    "start": "1850559",
    "end": "1856240"
  },
  {
    "text": "like to explain all these things but because of time constraints we cannot talk over this so",
    "start": "1856240",
    "end": "1861919"
  },
  {
    "text": "we can take these things offline if you are interested in knowing more about this",
    "start": "1861919",
    "end": "1867120"
  },
  {
    "text": "and i think that's pretty much all thank you thank you",
    "start": "1867120",
    "end": "1873919"
  }
]
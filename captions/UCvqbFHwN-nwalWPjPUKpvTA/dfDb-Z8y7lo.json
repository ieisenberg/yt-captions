[
  {
    "text": "welcome to Storage Wars the basis for this talk is because",
    "start": "179",
    "end": "5779"
  },
  {
    "text": "nearly the most common question we get in support",
    "start": "5779",
    "end": "11280"
  },
  {
    "text": "once people have kubernetes is well how do I handle stateful sets how do I handle storage how do I use things that",
    "start": "11280",
    "end": "19500"
  },
  {
    "text": "need storage in kubernetes and that's what we're going to try and cover here today",
    "start": "19500",
    "end": "25140"
  },
  {
    "text": "so I'm Sean McCord briefly I was the former I am the former",
    "start": "25140",
    "end": "32238"
  },
  {
    "text": "principal architect at cedaro Labs the maker of and still a fan of",
    "start": "32239",
    "end": "38480"
  },
  {
    "text": "Talos Linux and their new product Omni uh I'm the original author of The",
    "start": "38480",
    "end": "45780"
  },
  {
    "text": "containerization of Seth that's used by red hat and Rook I'm sure none of my",
    "start": "45780",
    "end": "53340"
  },
  {
    "text": "code still exists in that I've been away from it for years but that does give you some",
    "start": "53340",
    "end": "58379"
  },
  {
    "text": "view of my biases in this realm uh I'm very much a Seth fan have been for a",
    "start": "58379",
    "end": "64018"
  },
  {
    "text": "very long time but I do not let loyalty to that product get in the way",
    "start": "64019",
    "end": "69060"
  },
  {
    "text": "of hopefully advancements there are a number of projects that I discovered in the course of this talk that I hope to",
    "start": "69060",
    "end": "75960"
  },
  {
    "text": "be able to use in the future myself uh I have been a Seeker for distributed",
    "start": "75960",
    "end": "82500"
  },
  {
    "text": "for good distributed storage solutions for over 25 years and I still haven't found it",
    "start": "82500",
    "end": "88920"
  },
  {
    "text": "I'm a contributor for many open source projects as I'm sure many other people are in a variety of areas across the",
    "start": "88920",
    "end": "95880"
  },
  {
    "text": "years I'm also wink wink gainfully I'm unemployed",
    "start": "95880",
    "end": "102320"
  },
  {
    "text": "without further Ado let's talk about what this talk is and more importantly what it's not",
    "start": "102780",
    "end": "109740"
  },
  {
    "text": "storage is a huge realm and there is no possible way I can cover everything about it in 20 minutes",
    "start": "109740",
    "end": "117360"
  },
  {
    "text": "so specifically we are not going to talk about any cloud provider systems and",
    "start": "117360",
    "end": "123780"
  },
  {
    "text": "comparisons thereof if you're in a cloud provider you're just going to use that cloud provider's storage system enough",
    "start": "123780",
    "end": "130080"
  },
  {
    "text": "said end of story likewise we're not going to talk about the vast majority of the csis out there",
    "start": "130080",
    "end": "137879"
  },
  {
    "text": "by the way there are over 150 of the things which are mostly just vendor csis",
    "start": "137879",
    "end": "144360"
  },
  {
    "text": "adapter layers which let you use for instance a Synology Nas with kubernetes",
    "start": "144360",
    "end": "149520"
  },
  {
    "text": "freely there's no point in talking about these if you have those systems and that's all you want out of them you'll",
    "start": "149520",
    "end": "155700"
  },
  {
    "text": "use those csis and that's it so what we will try and discuss is an overview",
    "start": "155700",
    "end": "162360"
  },
  {
    "text": "of the main open source storage solutions that are available for use in",
    "start": "162360",
    "end": "167879"
  },
  {
    "text": "kubernetes open source because others are the ones which can be analyzed those",
    "start": "167879",
    "end": "173040"
  },
  {
    "text": "are the ones which are not black boxes which we can actually look at and evaluate the characteristics beyond the",
    "start": "173040",
    "end": "179580"
  },
  {
    "text": "marketing data but also let this be a guide to the key",
    "start": "179580",
    "end": "185160"
  },
  {
    "text": "criteria that you need to be able to understand to be able to decide for you",
    "start": "185160",
    "end": "190980"
  },
  {
    "text": "which which solution is right",
    "start": "190980",
    "end": "195739"
  },
  {
    "text": "so in general plan of attack we'll talk about the types of storage the three of",
    "start": "196319",
    "end": "201540"
  },
  {
    "text": "them location and quiet matters and the characteristics related to it the",
    "start": "201540",
    "end": "208200"
  },
  {
    "text": "characteristics of storage itself the storage interfaces that are available",
    "start": "208200",
    "end": "214140"
  },
  {
    "text": "and finally the contenders those projects which are available for use and",
    "start": "214140",
    "end": "219360"
  },
  {
    "text": "which we're here to evaluate so first the types of storage",
    "start": "219360",
    "end": "226340"
  },
  {
    "text": "mostly these coalesce into three main categories object stores block stores",
    "start": "226340",
    "end": "232500"
  },
  {
    "text": "and shared file systems some vendors use different names for these but functionally these are the",
    "start": "232500",
    "end": "239220"
  },
  {
    "text": "three major sets of storage object stores are basically big key",
    "start": "239220",
    "end": "245159"
  },
  {
    "text": "value databases but instead of for instance at CD designed to store small",
    "start": "245159",
    "end": "250439"
  },
  {
    "text": "bits of data they're designed to store arbitrarily large Blobs of data files",
    "start": "250439",
    "end": "255900"
  },
  {
    "text": "and the like media whatever what have you they're based generally on webtech which",
    "start": "255900",
    "end": "262440"
  },
  {
    "text": "lends themselves really well to expansion for read like processes think",
    "start": "262440",
    "end": "267960"
  },
  {
    "text": "web proxies uh think caching systems and various standardized methods in webtech",
    "start": "267960",
    "end": "275160"
  },
  {
    "text": "to be able to scale up your system and readability there are also Network native this is a",
    "start": "275160",
    "end": "281160"
  },
  {
    "text": "big deal because many of the other Solutions try to adapt some level of local storage",
    "start": "281160",
    "end": "288180"
  },
  {
    "text": "Concepts to their Solutions instead object stores take a web focused",
    "start": "288180",
    "end": "293820"
  },
  {
    "text": "network-only approach uh to all of their interfaces so they have no Legacy components integrated to",
    "start": "293820",
    "end": "301080"
  },
  {
    "text": "them as I said they're easily integrated and layered integrating for instance an",
    "start": "301080",
    "end": "306720"
  },
  {
    "text": "authentication system of your own or using one of the third-party authentication systems easy built-in uh",
    "start": "306720",
    "end": "314880"
  },
  {
    "text": "easy to integrate with the rest of it also like the web however rights are",
    "start": "314880",
    "end": "320699"
  },
  {
    "text": "more difficult you can't just simply write out to a file and expect it to be stored in in your Object Store instead",
    "start": "320699",
    "end": "327840"
  },
  {
    "text": "you generally have to use some kind of API or CLI tool to get it there and that",
    "start": "327840",
    "end": "333180"
  },
  {
    "text": "is where the most difficult aspect of using an object store in your applications are very few of them exist",
    "start": "333180",
    "end": "339419"
  },
  {
    "text": "which can write directly to those object stores block stores",
    "start": "339419",
    "end": "345419"
  },
  {
    "text": "are basically just that they're block oriented uh overlay of the block",
    "start": "345419",
    "end": "351600"
  },
  {
    "text": "oriented implementations that try and represent the storage wherever it may be",
    "start": "351600",
    "end": "356820"
  },
  {
    "text": "as if it were a local disk attached to the system whether it be a USB stick a",
    "start": "356820",
    "end": "362220"
  },
  {
    "text": "hard drive an SSD whatever you get as a user of a block store full",
    "start": "362220",
    "end": "367979"
  },
  {
    "text": "control over the file system so you can choose xfs or ext3 or what have you and",
    "start": "367979",
    "end": "375000"
  },
  {
    "text": "specifically tune it to whatever you wish these map particularly well to",
    "start": "375000",
    "end": "380520"
  },
  {
    "text": "kubernetes persistent volumes PVS the main downside of them is that in",
    "start": "380520",
    "end": "387060"
  },
  {
    "text": "general they only allow a single attachment",
    "start": "387060",
    "end": "392220"
  },
  {
    "text": "to a pod for each volume at any given time so if you have multiple containers",
    "start": "392220",
    "end": "399240"
  },
  {
    "text": "that need to read and write to a block store you generally need to bind them into the same pod which thankfully",
    "start": "399240",
    "end": "406979"
  },
  {
    "text": "kubernetes or allows very easily but that limits your articulation and scaling between those containers to the",
    "start": "406979",
    "end": "414539"
  },
  {
    "text": "Pod level so there isn't really one good standard for Block stores but there are a couple",
    "start": "414539",
    "end": "421500"
  },
  {
    "text": "of protocols which are widely used among those are iSCSI and nvme over Fabrics",
    "start": "421500",
    "end": "429120"
  },
  {
    "text": "they can also be made to offer the other two types of storage keep in mind so",
    "start": "429120",
    "end": "435419"
  },
  {
    "text": "they can view be used as the lowest common denominator for any need Mineo for instance is able to provide object",
    "start": "435419",
    "end": "442919"
  },
  {
    "text": "storage on top of a block storage and likewise their various NFS providers",
    "start": "442919",
    "end": "448680"
  },
  {
    "text": "which can provide a shared file system on top of a block store",
    "start": "448680",
    "end": "453960"
  },
  {
    "text": "finally shared file systems these present files and directories across a",
    "start": "453960",
    "end": "459120"
  },
  {
    "text": "number of nodes as a file system these are the most adaptive and the most",
    "start": "459120",
    "end": "466639"
  },
  {
    "text": "constrained to Legacy operations because they go deep into posix file system mechanics they have a lot of assumptions",
    "start": "466639",
    "end": "473819"
  },
  {
    "text": "that don't map well to the network World least of all the container World there",
    "start": "473819",
    "end": "480660"
  },
  {
    "text": "are always locking problems bottlenecks contention locks and slow General performance",
    "start": "480660",
    "end": "486960"
  },
  {
    "text": "NFS is you has been used for decades it's the old dinosaur",
    "start": "486960",
    "end": "493740"
  },
  {
    "text": "it will work when nothing else works but you don't ever want to use it unless you",
    "start": "493740",
    "end": "499440"
  },
  {
    "text": "absolutely have to they are these are the easiest possible",
    "start": "499440",
    "end": "504479"
  },
  {
    "text": "things to implement and that's unfortunately usually why they're chosen not because you have so many workloads",
    "start": "504479",
    "end": "511259"
  },
  {
    "text": "that actually need active shared files in sequence in Syria and in simultaneous",
    "start": "511259",
    "end": "518279"
  },
  {
    "text": "access but because it's easy to set up and generally forget about and this is a",
    "start": "518279",
    "end": "523500"
  },
  {
    "text": "big downside to Shared file systems that people don't think about nothing integral to NFS handles anything about",
    "start": "523500",
    "end": "531660"
  },
  {
    "text": "replication about topology awareness or any of these major concerns that you have with storage that all out of scoop",
    "start": "531660",
    "end": "540680"
  },
  {
    "text": "location so if you're in a cloud as I said before you're likely to be using the cloud",
    "start": "541320",
    "end": "547440"
  },
  {
    "text": "provider storage but that's only for single Cloud providers if you for instance have",
    "start": "547440",
    "end": "554120"
  },
  {
    "text": "systems in gcp and AWS and Azure you",
    "start": "554120",
    "end": "559140"
  },
  {
    "text": "might appreciate having a common system overlaid on their storage platforms that",
    "start": "559140",
    "end": "565740"
  },
  {
    "text": "you can then modularly stamp out to other systems and that is a possible use for another storage system on top of it",
    "start": "565740",
    "end": "573600"
  },
  {
    "text": "in cluster and out of cluster so in cluster storage systems have an",
    "start": "573600",
    "end": "579060"
  },
  {
    "text": "advantage in operational consistency basically you're able to use the same",
    "start": "579060",
    "end": "584160"
  },
  {
    "text": "kubernetes manifests that you use for all of your other stuff inside and handle your storage as well",
    "start": "584160",
    "end": "591000"
  },
  {
    "text": "which is great for convenience for portability for modularity but keep in mind storage is very unlike applications",
    "start": "591000",
    "end": "600060"
  },
  {
    "text": "it is inherently staple that data that you store in that storage has value and",
    "start": "600060",
    "end": "607260"
  },
  {
    "text": "it's not easily replicated and very definitely not quickly replicated because it takes big chunks of network",
    "start": "607260",
    "end": "613740"
  },
  {
    "text": "bandwidth and CPU usage to be able to move that data in various places",
    "start": "613740",
    "end": "619800"
  },
  {
    "text": "finally keep in mind that storage eats up a lot",
    "start": "619800",
    "end": "625200"
  },
  {
    "text": "of resources not only just this guy oh which is clear you need to write",
    "start": "625200",
    "end": "631080"
  },
  {
    "text": "data to disks so it takes some of your disk i o but also frequently we'll we'll",
    "start": "631080",
    "end": "636240"
  },
  {
    "text": "take CPU usage RAM usage you have contention over disk IO and this is one",
    "start": "636240",
    "end": "642839"
  },
  {
    "text": "of the big Killers that's often invisible if you're not very careful taking away performance over your",
    "start": "642839",
    "end": "648779"
  },
  {
    "text": "applications so the there is an advantage to keeping data storage outside your cluster to be",
    "start": "648779",
    "end": "656579"
  },
  {
    "text": "able to more easily diagnose performance conditions characteristics of storage there are",
    "start": "656579",
    "end": "663720"
  },
  {
    "text": "tons of these but I've tried to boil these down into three main categories Loosely grouped scalability performance",
    "start": "663720",
    "end": "672779"
  },
  {
    "text": "and cost so scalability is represented a lot by the architecture of the storage systems",
    "start": "672779",
    "end": "679200"
  },
  {
    "text": "themselves traditionally the best we had was something like a traditional raid system you had RAID 0 raid one",
    "start": "679200",
    "end": "686720"
  },
  {
    "text": "raid 5 and if you're really really lucky raid 6 so you can handle two discs going",
    "start": "686720",
    "end": "691860"
  },
  {
    "text": "down at any time obviously as the systems get larger and larger handling single points of failure like that",
    "start": "691860",
    "end": "698940"
  },
  {
    "text": "across dozens of disks and the likelihood of you being able to repair those within the cons within the time",
    "start": "698940",
    "end": "706440"
  },
  {
    "text": "failure zone of disks particularly if they're the same skew is really daunting the number of disks that you have that I",
    "start": "706440",
    "end": "714480"
  },
  {
    "text": "have personally had put out into the field in the same skew all failing",
    "start": "714480",
    "end": "719880"
  },
  {
    "text": "within two days of each other is very very common so yes there are ways to mitigate this",
    "start": "719880",
    "end": "726300"
  },
  {
    "text": "you can buy from different batches by different brands of drives etc etc but fundamentally the system is limited",
    "start": "726300",
    "end": "734279"
  },
  {
    "text": "luckily we don't have to deal with traditional raid anymore there are many other options so the current standard if you want to",
    "start": "734279",
    "end": "742320"
  },
  {
    "text": "call it that is the idea of a SAS system with perhaps multi-tiered SAS expenders",
    "start": "742320",
    "end": "748459"
  },
  {
    "text": "to extend them out these are typically viewed as big Bays of drives just a",
    "start": "748459",
    "end": "756420"
  },
  {
    "text": "bunch of disks jbods says they're called and these are usually tiered together with single or redundant SAS controllers",
    "start": "756420",
    "end": "765440"
  },
  {
    "text": "with potentially expander layers and teared down into multiple layers of",
    "start": "765440",
    "end": "771660"
  },
  {
    "text": "disks themselves you're still dealing while you may have redundant controllers you're still",
    "start": "771660",
    "end": "778500"
  },
  {
    "text": "dealing with a highly centralized system all constrained to a single SAS Channel",
    "start": "778500",
    "end": "784200"
  },
  {
    "text": "technically they're four channels per SAS Channel but whatever they're still limited bandwidth for each limited",
    "start": "784200",
    "end": "790800"
  },
  {
    "text": "amount of tiering because you're all cannibalizing from that same bandwidth and getting down practically speaking",
    "start": "790800",
    "end": "796380"
  },
  {
    "text": "you can't really get a standard SAS system larger than about four a few",
    "start": "796380",
    "end": "801680"
  },
  {
    "text": "petabytes with today's technology today's largest drives and those are hard drives when you go into solid-state",
    "start": "801680",
    "end": "809160"
  },
  {
    "text": "drives it's much more restrictive both on the interface and the expansion",
    "start": "809160",
    "end": "814920"
  },
  {
    "text": "so finally that leaves us with storage clusters this is where the biggest interesting stuff is happening in the",
    "start": "814920",
    "end": "822360"
  },
  {
    "text": "storage World these try to eliminate single points of failure so that you're horizontally scalable all tiers of the",
    "start": "822360",
    "end": "830160"
  },
  {
    "text": "system whether it be the controllers whether it be the block Distributors whether it be the block stores are all",
    "start": "830160",
    "end": "837120"
  },
  {
    "text": "as distributed as possible and in many cases the larger the cluster",
    "start": "837120",
    "end": "842700"
  },
  {
    "text": "becomes the faster it goes rather than constraining the same resources",
    "start": "842700",
    "end": "849360"
  },
  {
    "text": "these are designed to be dynamic fine-grained with specific controls for",
    "start": "849360",
    "end": "855180"
  },
  {
    "text": "both replication and topology awareness",
    "start": "855180",
    "end": "860000"
  },
  {
    "text": "so performance the last characteristic um sorry second",
    "start": "861959",
    "end": "868220"
  },
  {
    "text": "characteristic uh benchmarks are always misleading we hear that all over the",
    "start": "868220",
    "end": "874620"
  },
  {
    "text": "place but particularly in storage this is true and this stems even from drives themselves the fundamental basis of",
    "start": "874620",
    "end": "882060"
  },
  {
    "text": "drives you frequently have highly different uh",
    "start": "882060",
    "end": "888060"
  },
  {
    "text": "performance characteristics between say sequential reads sequential rights",
    "start": "888060",
    "end": "893100"
  },
  {
    "text": "random reads random rights mixed loads where you have sequential and uh random",
    "start": "893100",
    "end": "899579"
  },
  {
    "text": "reads and or rights and finally contentious access multiple access older",
    "start": "899579",
    "end": "905820"
  },
  {
    "text": "Technologies for instance really don't handle multiple read requests Etc newer systems do a better job but it's",
    "start": "905820",
    "end": "913199"
  },
  {
    "text": "inherently wildly different and highly workload dependent so benchmarks",
    "start": "913199",
    "end": "918800"
  },
  {
    "text": "basically can be manipulated to say whatever you want them to say unfortunately and even",
    "start": "918800",
    "end": "924980"
  },
  {
    "text": "unintentionally so so that you can easily get down the wrong side that said there are some architectural",
    "start": "924980",
    "end": "932820"
  },
  {
    "text": "choices that do matter so as I said before some systems speed up as they",
    "start": "932820",
    "end": "938339"
  },
  {
    "text": "scale but correspondingly they're slow at low scale some systems slow down as",
    "start": "938339",
    "end": "944579"
  },
  {
    "text": "they scale but in in within their frame of reference can be much faster because",
    "start": "944579",
    "end": "949800"
  },
  {
    "text": "they're highly tuned uh cost I'm using in a very liberal term",
    "start": "949800",
    "end": "956000"
  },
  {
    "text": "cost yes disks controllers Hardware they have a real dollar value cost but when",
    "start": "956000",
    "end": "964079"
  },
  {
    "text": "you're talking about storage these systems can get complex very quickly and the complexity of the system itself is",
    "start": "964079",
    "end": "970680"
  },
  {
    "text": "its own cost administratively whether you're paying that directly to you with your own tax or whether you're paying",
    "start": "970680",
    "end": "977040"
  },
  {
    "text": "somebody else to do it the complexity of each system has its own cost to it therefore of course with everything we",
    "start": "977040",
    "end": "983820"
  },
  {
    "text": "want to keep complexity down next hard drives disk drives ssds hard",
    "start": "983820",
    "end": "990720"
  },
  {
    "text": "drives in particular are going to fail they are the lowest M meeting time to",
    "start": "990720",
    "end": "996720"
  },
  {
    "text": "failure of any component in the modern system including fans",
    "start": "996720",
    "end": "1002959"
  },
  {
    "text": "they will frequently fail as batches as I said before they can fail at any time",
    "start": "1002959",
    "end": "1008240"
  },
  {
    "text": "if you get scale high enough drives are going to fail every day or every week",
    "start": "1008240",
    "end": "1013519"
  },
  {
    "text": "you have to have a plan and you have to have a system to handle Drive",
    "start": "1013519",
    "end": "1019339"
  },
  {
    "text": "Replacements Within These systems and lastly growth and scalability the more",
    "start": "1019339",
    "end": "1025760"
  },
  {
    "text": "centralized the more fixed the more infrastructure contained and less horizontally scalable your system is the",
    "start": "1025760",
    "end": "1033500"
  },
  {
    "text": "more likely you're going to expand to a point at which your infrastructure can no longer take it and you suddenly have",
    "start": "1033500",
    "end": "1039740"
  },
  {
    "text": "to spend tens of thousands hundreds of thousands of dollars to completely replace that",
    "start": "1039740",
    "end": "1045140"
  },
  {
    "text": "system that's otherwise perfectly happy and content with a larger system for more capacity the benefit of horizontal",
    "start": "1045140",
    "end": "1051740"
  },
  {
    "text": "scaling is huge in terms of cost",
    "start": "1051740",
    "end": "1057100"
  },
  {
    "text": "so the storage interfaces um mentioned these briefly before iSCSI",
    "start": "1057799",
    "end": "1063440"
  },
  {
    "text": "it's the old standard it's kind of slow but it's also somewhat the least common",
    "start": "1063440",
    "end": "1069260"
  },
  {
    "text": "denominator lots and lots of vendors use it and it's generally okay given its",
    "start": "1069260",
    "end": "1075440"
  },
  {
    "text": "constraints of the old scuzzy however the Linux implementation in particular open iSCSI which most of the kubernetes",
    "start": "1075440",
    "end": "1082280"
  },
  {
    "text": "users have to use if it's iSCSI is definitely from the pre-container age",
    "start": "1082280",
    "end": "1088580"
  },
  {
    "text": "it requires local sockets local config file flat",
    "start": "1088580",
    "end": "1094460"
  },
  {
    "text": "config files static but multiple access so that when it's updated it has to be read read by all the clients as well as",
    "start": "1094460",
    "end": "1100700"
  },
  {
    "text": "a server and in general when these iscos ecsis are implemented they have a number",
    "start": "1100700",
    "end": "1106760"
  },
  {
    "text": "of bad practices that are security nightmares for your kubernetes system",
    "start": "1106760",
    "end": "1113539"
  },
  {
    "text": "if you have to use them you have to use them but ideally like NFS stay away from",
    "start": "1113539",
    "end": "1118760"
  },
  {
    "text": "them nvme or Fabrics is the newer standard there are several that we're looking at",
    "start": "1118760",
    "end": "1125299"
  },
  {
    "text": "several that that use nvmf nvmeof",
    "start": "1125299",
    "end": "1130460"
  },
  {
    "text": "they're in general like nvme is to scuzzy and Sarah cleaner simpler faster",
    "start": "1130460",
    "end": "1136480"
  },
  {
    "text": "eliminating a lot of the old overhead that is no longer necessary and it's a fairly clean approach to use with",
    "start": "1136480",
    "end": "1143120"
  },
  {
    "text": "containers and thus with kubernetes Seth has its own set of internal drivers",
    "start": "1143120",
    "end": "1150320"
  },
  {
    "text": "adapter layers so RBD they're block storage and cffs their file storage file",
    "start": "1150320",
    "end": "1157039"
  },
  {
    "text": "system offering are both in kernel and relatively easy to use and standardized",
    "start": "1157039",
    "end": "1162679"
  },
  {
    "text": "likewise NFS used to have all the problems of open iSCSI it's been in the",
    "start": "1162679",
    "end": "1168320"
  },
  {
    "text": "kernel however for years as a client it's fairly easy you don't need anything particular to manage it and it's well",
    "start": "1168320",
    "end": "1175340"
  },
  {
    "text": "integrated directly into kubernetes as well finally that brings us to the contenders",
    "start": "1175340",
    "end": "1183260"
  },
  {
    "text": "so a few these are try these are attempted to group by category roughly",
    "start": "1183260",
    "end": "1188480"
  },
  {
    "text": "so that we can think of these in the ways that top down we might want to consider first of all a couple",
    "start": "1188480",
    "end": "1195140"
  },
  {
    "text": "categories that we mostly throw out because they don't matter or they don't have enough information one huge the",
    "start": "1195140",
    "end": "1201919"
  },
  {
    "text": "largest category of CSI providers sorry I haven't defined CSI CSI is the storage",
    "start": "1201919",
    "end": "1208640"
  },
  {
    "text": "container storage interface it is the standardized system by which kubernetes and",
    "start": "1208640",
    "end": "1215600"
  },
  {
    "text": "containers interact with storage so the CSI providers provide access to",
    "start": "1215600",
    "end": "1221720"
  },
  {
    "text": "the storage and using a standardized interface so these vendor adapters are",
    "start": "1221720",
    "end": "1228200"
  },
  {
    "text": "basically used to adopt specific Hardware or specific hosted services",
    "start": "1228200",
    "end": "1235280"
  },
  {
    "text": "two kubernetes to be used as CSI providers for the storage it's just an",
    "start": "1235280",
    "end": "1241160"
  },
  {
    "text": "adapter in general you they don't do anything they don't all they do is map a kubernetes storage volume to whatever",
    "start": "1241160",
    "end": "1248840"
  },
  {
    "text": "the service provider or Hardware vendor has as their own native volume hence",
    "start": "1248840",
    "end": "1255919"
  },
  {
    "text": "it's not particularly interesting to talk about so I've probably already spent too much time talking about it let's move on",
    "start": "1255919",
    "end": "1262960"
  },
  {
    "text": "proprietary options so proprietary options as I said are mostly black boxes",
    "start": "1262960",
    "end": "1268520"
  },
  {
    "text": "there's not a whole lot that we can say infrastructurally what they are there's no easy way to evaluate so",
    "start": "1268520",
    "end": "1275000"
  },
  {
    "text": "there's not really a whole lot of mention to them I've listed a few here just those that caught my eye or those",
    "start": "1275000",
    "end": "1282860"
  },
  {
    "text": "which are popular enough to have been of interest but realistically there's no",
    "start": "1282860",
    "end": "1288320"
  },
  {
    "text": "way for me to fit them into this talk so bye local storage so local storage is really",
    "start": "1288320",
    "end": "1295580"
  },
  {
    "text": "common for small kubernetes clusters or for systems that really just need to",
    "start": "1295580",
    "end": "1300919"
  },
  {
    "text": "throw up kubernetes Dev environments and and whatnot this is the easiest way to",
    "start": "1300919",
    "end": "1306140"
  },
  {
    "text": "get storage in kubernetes and thankfully now while there used to be a number of third-party vendors persistent local",
    "start": "1306140",
    "end": "1313220"
  },
  {
    "text": "volumes are built into kubernetes the only big thing to know about local",
    "start": "1313220",
    "end": "1318860"
  },
  {
    "text": "storage is of course it's node local therefore pods which need access to that storage have to be scheduled to the",
    "start": "1318860",
    "end": "1325520"
  },
  {
    "text": "nodes which provide it again kubernetes now handles all of this you don't have to worry about it but clearly",
    "start": "1325520",
    "end": "1331940"
  },
  {
    "text": "that's not a scalable solution you have pods that are directly bound to nodes so you want to avoid that but it is here it",
    "start": "1331940",
    "end": "1338840"
  },
  {
    "text": "is available as a simple storage solution that does still work with the rest of the kubernetes semantics for",
    "start": "1338840",
    "end": "1345620"
  },
  {
    "text": "accessing storage there's another one here worth mentioning called uh Topo lvm which",
    "start": "1345620",
    "end": "1352820"
  },
  {
    "text": "allows you to map directly lvm volumes into kubernetes fairly easily so worth",
    "start": "1352820",
    "end": "1359720"
  },
  {
    "text": "knowing about shared file systems NFS as we mentioned",
    "start": "1359720",
    "end": "1365360"
  },
  {
    "text": "the old dog that has never learned new tricks we have glusterfs which used to maintain",
    "start": "1365360",
    "end": "1372919"
  },
  {
    "text": "their own CSI but now is just provided by a third party",
    "start": "1372919",
    "end": "1377980"
  },
  {
    "text": "system called karalu if I'm pronouncing that correctly who knows this is an",
    "start": "1377980",
    "end": "1384020"
  },
  {
    "text": "in-cluster operator for gluster FS Sometimes gluster some gluster FS it's",
    "start": "1384020",
    "end": "1392299"
  },
  {
    "text": "an aggregating shared file system that is it Aggregates a number of different back-end storage units into a common",
    "start": "1392299",
    "end": "1400840"
  },
  {
    "text": "Point that's then exported as a as a shared file system uh it's reasonably simple there aren't a",
    "start": "1400840",
    "end": "1409100"
  },
  {
    "text": "whole lot of guard rails you can do the wrong thing it's very common even in the docs for them to recommend for instance",
    "start": "1409100",
    "end": "1415760"
  },
  {
    "text": "that two node system which is uh in cluster's crazy it's like running a two",
    "start": "1415760",
    "end": "1422720"
  },
  {
    "text": "node SCD cluster it's worse than running a single node except for your data",
    "start": "1422720",
    "end": "1428980"
  },
  {
    "text": "Integrity uh availability is a takes a down spiral with only two but regardless",
    "start": "1428980",
    "end": "1436400"
  },
  {
    "text": "you can do it correctly and in general it's fairly easy to use cefs is the shared file system of",
    "start": "1436400",
    "end": "1445360"
  },
  {
    "text": "ceph which I'll talk about later when we talk about storage clusters",
    "start": "1445360",
    "end": "1450559"
  },
  {
    "text": "pooling and aggregating systems so these are relatively simple all they really do is group underlying storage providers",
    "start": "1450559",
    "end": "1458200"
  },
  {
    "text": "into a common face that can be presented to kubernetes either as block devices or",
    "start": "1458200",
    "end": "1466460"
  },
  {
    "text": "as object stores or as shared file systems three worth mentioning here the virtual",
    "start": "1466460",
    "end": "1473419"
  },
  {
    "text": "disk array which is a fairly low level system based on nvmeof",
    "start": "1473419",
    "end": "1479840"
  },
  {
    "text": "uh which just takes a number of different storage providers and repackages them up as virtual disks that",
    "start": "1479840",
    "end": "1488360"
  },
  {
    "text": "kubernetes can use directly however there's not a whole lot of tooling here so if you're the kind of person who",
    "start": "1488360",
    "end": "1495260"
  },
  {
    "text": "likes to build their own tooling these make com good tools to start with but",
    "start": "1495260",
    "end": "1501140"
  },
  {
    "text": "there's no operator there's no provisioning system you'd have to build all of that yourself",
    "start": "1501140",
    "end": "1507320"
  },
  {
    "text": "Mineo is like I said the object store engine it can it has a huge variety of",
    "start": "1507320",
    "end": "1513559"
  },
  {
    "text": "underlying stores both physical and service oriented that can be tied into",
    "start": "1513559",
    "end": "1520220"
  },
  {
    "text": "their system it Aggregates and re-exports as a standard Object Store",
    "start": "1520220",
    "end": "1525320"
  },
  {
    "text": "which speaks S3 linstore is a really popular one because",
    "start": "1525320",
    "end": "1531799"
  },
  {
    "text": "it is relatively simple for as many moving Parts as it has it's highly plugable with lots of different",
    "start": "1531799",
    "end": "1537740"
  },
  {
    "text": "providers at each level of its offering and it's somewhat aggregative it's",
    "start": "1537740",
    "end": "1544820"
  },
  {
    "text": "somewhat replicative it's based on the same people that made drdb",
    "start": "1544820",
    "end": "1550059"
  },
  {
    "text": "which if you know from decades ago was a Master failover System for replication",
    "start": "1550059",
    "end": "1557900"
  },
  {
    "text": "of storage it goes beyond that now and like I say there are various providers",
    "start": "1557900",
    "end": "1563960"
  },
  {
    "text": "for a number of systems they support nvmeoe they support iSCSI and they even",
    "start": "1563960",
    "end": "1569419"
  },
  {
    "text": "support NFS I believe they do a lot of things in a lot of plugability so it's a very flexible",
    "start": "1569419",
    "end": "1575900"
  },
  {
    "text": "solution but still primarily not really a horizontally scalable storage cluster it's more a pooling and aggregating",
    "start": "1575900",
    "end": "1582620"
  },
  {
    "text": "system that leads us to the first storage clusters",
    "start": "1582620",
    "end": "1587720"
  },
  {
    "text": "so the base the most basic of these is probably the family of providers Loosely",
    "start": "1587720",
    "end": "1593600"
  },
  {
    "text": "grouped under the EBS the open ABS name openabs says the name might imply is",
    "start": "1593600",
    "end": "1600799"
  },
  {
    "text": "built to be modeled after Amazon's elastic block storage and these are just block stores they are",
    "start": "1600799",
    "end": "1609919"
  },
  {
    "text": "mostly limited to just replication and not really a whole lot of topology",
    "start": "1609919",
    "end": "1615980"
  },
  {
    "text": "awareness topology controls to them c-store is the oldest engine available",
    "start": "1615980",
    "end": "1622220"
  },
  {
    "text": "the original engine for open ABS it is I understand the ZFS based it's an",
    "start": "1622220",
    "end": "1629299"
  },
  {
    "text": "iSCSI standard pardon me sorry a nice guzzy standard uh",
    "start": "1629299",
    "end": "1636679"
  },
  {
    "text": "so that means you've got to deal with all the open iSCSI junk but it is rugged",
    "start": "1636679",
    "end": "1641900"
  },
  {
    "text": "it's well tested and it's relatively slow uh Jiva is somewhat of a step side a",
    "start": "1641900",
    "end": "1650299"
  },
  {
    "text": "stepchild I've never actually seen any reason to run it it was intended to be a",
    "start": "1650299",
    "end": "1656840"
  },
  {
    "text": "modernization of c-store it mostly just replaces the client interface for iSCSI",
    "start": "1656840",
    "end": "1663020"
  },
  {
    "text": "with a newer go based one but still requires uh open iSCSI on the server",
    "start": "1663020",
    "end": "1669500"
  },
  {
    "text": "side so it's hard to see what the point there is some performance Advantage but it is",
    "start": "1669500",
    "end": "1675679"
  },
  {
    "text": "it is the second generation that was kind of um lost uh in the move to Maya store",
    "start": "1675679",
    "end": "1683299"
  },
  {
    "text": "uh there is also a longhorn it looks like it cut off that slide I apologize uh this is ranchers offering that was",
    "start": "1683299",
    "end": "1691400"
  },
  {
    "text": "originally based on open EPS but it's kind of been Rewritten in various phases its by Rancher it's basically for",
    "start": "1691400",
    "end": "1699380"
  },
  {
    "text": "rancher if you're running wrencher it makes probably some sense to use uh",
    "start": "1699380",
    "end": "1704480"
  },
  {
    "text": "Longhorn um I'm not a Rancher user so I can't really speak a whole lot to it I've never been",
    "start": "1704480",
    "end": "1710840"
  },
  {
    "text": "able to get it up and working on anything else it's again for some reason uh despite them talking",
    "start": "1710840",
    "end": "1717200"
  },
  {
    "text": "about it for a long time getting off and off off of iSCSI they didn't they're still iSCSI so I don't really think much",
    "start": "1717200",
    "end": "1725059"
  },
  {
    "text": "about oh there's the longhorn I just clipped it on the other one anyway lastly in open EPS Maya store",
    "start": "1725059",
    "end": "1733580"
  },
  {
    "text": "it's the shiny new thing it's written in Rust it has NVM eof native support it",
    "start": "1733580",
    "end": "1741620"
  },
  {
    "text": "even has Nick's development files which makes working with it on certain",
    "start": "1741620",
    "end": "1746779"
  },
  {
    "text": "operating systems like makes uh really nice and pleasant it's also very new 1.0",
    "start": "1746779",
    "end": "1753200"
  },
  {
    "text": "was only released this year and along with it a bunch of breaking changes they have had many of those and actually",
    "start": "1753200",
    "end": "1760279"
  },
  {
    "text": "running these in production has been difficult but not impossible uh they're they're very limited right",
    "start": "1760279",
    "end": "1768320"
  },
  {
    "text": "now they will probably expand it later but for right now it's just simple replication you say how many copies you",
    "start": "1768320",
    "end": "1774860"
  },
  {
    "text": "want it will make that into many companies um their docs have historically had a lot of problems it's made installation",
    "start": "1774860",
    "end": "1782000"
  },
  {
    "text": "difficult and some point along the line in their development they decided that",
    "start": "1782000",
    "end": "1787940"
  },
  {
    "text": "you know it's easier if people just use external hcd which unfortunately has the",
    "start": "1787940",
    "end": "1793820"
  },
  {
    "text": "problem of well okay if I have an external LCD that means I need external storage how I'm going to store storage",
    "start": "1793820",
    "end": "1800419"
  },
  {
    "text": "to get my storage system up",
    "start": "1800419",
    "end": "1805700"
  },
  {
    "text": "their answers you can use local storage and then you're back to being bound by",
    "start": "1805700",
    "end": "1810860"
  },
  {
    "text": "nodes at whatsoever but anyway open EPS is really common It's relatively uh",
    "start": "1810860",
    "end": "1816559"
  },
  {
    "text": "simple uh while still being mostly a storage cluster based system",
    "start": "1816559",
    "end": "1822760"
  },
  {
    "text": "and this I haven't had much time to play with it called seaweed FS which is curiously based on radus which is the",
    "start": "1826580",
    "end": "1834440"
  },
  {
    "text": "same thing that ceph is based on for its object storage but it's designed to be",
    "start": "1834440",
    "end": "1841039"
  },
  {
    "text": "simpler and more focused specifically to Containers it's it's like a re-envisionment of ceph in a",
    "start": "1841039",
    "end": "1848960"
  },
  {
    "text": "modernization and simplification I haven't had a whole lot of time to play with it it looks interesting it's got a",
    "start": "1848960",
    "end": "1855799"
  },
  {
    "text": "very diverse set of people working on it I'm intrigued but not a whole lot of data I don't know",
    "start": "1855799",
    "end": "1862760"
  },
  {
    "text": "anybody yet who's used it but it is interesting finally there's Seth Seth is the big",
    "start": "1862760",
    "end": "1869260"
  },
  {
    "text": "everything uh it's complex to start there are a lot of moving pieces to it",
    "start": "1869260",
    "end": "1874520"
  },
  {
    "text": "there are a lot of tunable parameters it's highly topology aware it's very",
    "start": "1874520",
    "end": "1880399"
  },
  {
    "text": "rugged it's well tested it's very old but it's also kept in update there have",
    "start": "1880399",
    "end": "1887360"
  },
  {
    "text": "been numerous updates to make it work much better with nvme drives and take advantage of various systems",
    "start": "1887360",
    "end": "1893360"
  },
  {
    "text": "it is in general highly fault tolerant the number of times I have shot myself in the foot with ceph and not actually",
    "start": "1893360",
    "end": "1899960"
  },
  {
    "text": "lost any data well is a hundred percent so it may be brutal for that recovery",
    "start": "1899960",
    "end": "1907700"
  },
  {
    "text": "but it's really reliable lastly we have the Rook packagement of",
    "start": "1907700",
    "end": "1914960"
  },
  {
    "text": "Seth so running Seth directly can be pretty heavy load Rook allows you to",
    "start": "1914960",
    "end": "1920179"
  },
  {
    "text": "package that up into an operator that you can run directly on kubernetes it",
    "start": "1920179",
    "end": "1925580"
  },
  {
    "text": "generally makes self-administration very easy you trade some control in exchange",
    "start": "1925580",
    "end": "1930620"
  },
  {
    "text": "for that automation though so running out of time so trying to get",
    "start": "1930620",
    "end": "1936260"
  },
  {
    "text": "down to the comparison table here to give you an idea of how scientifically",
    "start": "1936260",
    "end": "1942380"
  },
  {
    "text": "and mathematically based this is I've used some Emoji to make it a little better",
    "start": "1942380",
    "end": "1948940"
  },
  {
    "text": "uh anyway there's a lot here we don't really have time to cover a whole lot but this will be available on the slides",
    "start": "1949460",
    "end": "1956299"
  },
  {
    "text": "after the session uh if I can just end with what I'd call",
    "start": "1956299",
    "end": "1962120"
  },
  {
    "text": "an executive summary if you just want to pay somebody else to handle it and you don't want to deal with it in-house Port",
    "start": "1962120",
    "end": "1969200"
  },
  {
    "text": "Works seems to be about the most popular purely commercial solution",
    "start": "1969200",
    "end": "1974539"
  },
  {
    "text": "if you don't really care about any of the replication factors where it's stored you know whatever you just want",
    "start": "1974539",
    "end": "1980059"
  },
  {
    "text": "to store it try linstore it's really flexible it's fast for what it is and it generally is",
    "start": "1980059",
    "end": "1987559"
  },
  {
    "text": "fairly easy to deal to manage with their operators Etc if you need control or you need better",
    "start": "1987559",
    "end": "1994159"
  },
  {
    "text": "scaling but ceph is still scary consider open Abs if you want",
    "start": "1994159",
    "end": "2001120"
  },
  {
    "text": "performance more than ruggedness choose buy a store if you want ruggedness over performance choose c-store as the back",
    "start": "2001120",
    "end": "2008019"
  },
  {
    "text": "end if you want the best features scaling and fault tolerance ceph is really the",
    "start": "2008019",
    "end": "2014620"
  },
  {
    "text": "answer stability over everything else runs Seth on its own bear on an outside the",
    "start": "2014620",
    "end": "2022480"
  },
  {
    "text": "kubernetes cluster set of machines and you will be great otherwise",
    "start": "2022480",
    "end": "2029080"
  },
  {
    "text": "and this is what I do despite having used ceph for more than a decade use Rook uh to package up yourself and",
    "start": "2029080",
    "end": "2036820"
  },
  {
    "text": "run it in cluster and just be done with it all right well thanks for attending uh",
    "start": "2036820",
    "end": "2044080"
  },
  {
    "text": "again Sean McCord if I have any time at all I will try to get to questions",
    "start": "2044080",
    "end": "2050760"
  },
  {
    "text": "we good okay anyway questions",
    "start": "2051460",
    "end": "2056760"
  },
  {
    "text": "are you raising it thank you",
    "start": "2060040",
    "end": "2063898"
  },
  {
    "text": "all right I guess no oh we have one yes sir",
    "start": "2066580",
    "end": "2073540"
  },
  {
    "text": "how does luster integrate to solve this you I did I",
    "start": "2073540",
    "end": "2079060"
  },
  {
    "text": "didn't mentioned Laster file system I'm sorry I can't hear you can you can you repeat",
    "start": "2079060",
    "end": "2085679"
  },
  {
    "text": "Gloucester one two three so how does Blaster compare to all the",
    "start": "2086560",
    "end": "2092138"
  },
  {
    "text": "options that you mentioned how does gluster compare to luster",
    "start": "2092139",
    "end": "2097500"
  },
  {
    "text": "luster ah luster yes sorry yeah so luster luster is an old story luster is",
    "start": "2097500",
    "end": "2103900"
  },
  {
    "text": "a is um so luster and Intermezzo I used or",
    "start": "2103900",
    "end": "2109359"
  },
  {
    "text": "tried to use back in the 90s and 2000s so as far as I know I'm not aware of any",
    "start": "2109359",
    "end": "2114880"
  },
  {
    "text": "kubernetes adapters for luster there may be I just haven't run across uh any of them I mean it is mostly old old tech",
    "start": "2114880",
    "end": "2123780"
  },
  {
    "text": "for a long time there was the problem of the out of tree uh kernel drivers to be",
    "start": "2123780",
    "end": "2130180"
  },
  {
    "text": "honest I haven't kept up with it I I know it still exists I know it's highly used in the uh academic realms",
    "start": "2130180",
    "end": "2137440"
  },
  {
    "text": "but I I haven't really kept up with luster sorry",
    "start": "2137440",
    "end": "2142200"
  },
  {
    "text": "okay all right we are out of time thanks for attending and enjoy the rest of",
    "start": "2146260",
    "end": "2151359"
  },
  {
    "text": "kubecon",
    "start": "2151359",
    "end": "2153779"
  }
]
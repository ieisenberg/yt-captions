[
  {
    "start": "0",
    "end": "23000"
  },
  {
    "text": "uh hi everyone good morning and Welcome",
    "start": "120",
    "end": "2520"
  },
  {
    "text": "to our lightning talk session on",
    "start": "2520",
    "end": "4520"
  },
  {
    "text": "optimizing cluster workloads celium",
    "start": "4520",
    "end": "7000"
  },
  {
    "text": "invoy on dpu so my name is ataki Mishra",
    "start": "7000",
    "end": "10759"
  },
  {
    "text": "I'm currently part of Marvel's",
    "start": "10759",
    "end": "12320"
  },
  {
    "text": "accelerator solution team and very much",
    "start": "12320",
    "end": "14639"
  },
  {
    "text": "interested in stuff like kubernetes",
    "start": "14639",
    "end": "17039"
  },
  {
    "text": "Solutions P4 programmable data planes",
    "start": "17039",
    "end": "20279"
  },
  {
    "text": "areas like cni and load balancers so we",
    "start": "20279",
    "end": "24680"
  },
  {
    "start": "23000",
    "end": "92000"
  },
  {
    "text": "we know that celium has brought a",
    "start": "24680",
    "end": "26320"
  },
  {
    "text": "significant change by leveraging the",
    "start": "26320",
    "end": "28080"
  },
  {
    "text": "ebpf technology so so this proposal is",
    "start": "28080",
    "end": "31519"
  },
  {
    "text": "actually to take this step a bit further",
    "start": "31519",
    "end": "34360"
  },
  {
    "text": "by moving all the features and",
    "start": "34360",
    "end": "36399"
  },
  {
    "text": "functionalities provided by celium on",
    "start": "36399",
    "end": "38800"
  },
  {
    "text": "tot data processing units or we call",
    "start": "38800",
    "end": "41440"
  },
  {
    "text": "them dpu for the rest of the slides so",
    "start": "41440",
    "end": "44160"
  },
  {
    "text": "these are actually Hardware specialized",
    "start": "44160",
    "end": "46760"
  },
  {
    "text": "Hardware which are outside your servers",
    "start": "46760",
    "end": "50399"
  },
  {
    "text": "so modern dpus are capable of",
    "start": "50399",
    "end": "52520"
  },
  {
    "text": "efficiently handling all the layer 4 and",
    "start": "52520",
    "end": "54800"
  },
  {
    "text": "layer 7 related processing like",
    "start": "54800",
    "end": "57719"
  },
  {
    "text": "mtls transparent encryption decryption",
    "start": "57719",
    "end": "60519"
  },
  {
    "text": "layer four load balancing and uh yeah so",
    "start": "60519",
    "end": "64720"
  },
  {
    "text": "it's like most of them which directly",
    "start": "64720",
    "end": "66400"
  },
  {
    "text": "overlaps with the features provided by",
    "start": "66400",
    "end": "68880"
  },
  {
    "text": "celium so that's why the first",
    "start": "68880",
    "end": "71240"
  },
  {
    "text": "functionality we targeted was layer 7",
    "start": "71240",
    "end": "73640"
  },
  {
    "text": "function layer 7 processing which is",
    "start": "73640",
    "end": "75680"
  },
  {
    "text": "done by invoy today so celium moved",
    "start": "75680",
    "end": "79759"
  },
  {
    "text": "invoy from per pod site C model to per",
    "start": "79759",
    "end": "84880"
  },
  {
    "text": "note site C model so why not to move",
    "start": "84880",
    "end": "87360"
  },
  {
    "text": "that onto the dpus that is the out of",
    "start": "87360",
    "end": "90360"
  },
  {
    "text": "server",
    "start": "90360",
    "end": "92200"
  },
  {
    "start": "92000",
    "end": "155000"
  },
  {
    "text": "model so we profiled a sample cluster to",
    "start": "92200",
    "end": "95320"
  },
  {
    "text": "get the idea of the resource",
    "start": "95320",
    "end": "97680"
  },
  {
    "text": "utilization uh by various components",
    "start": "97680",
    "end": "100479"
  },
  {
    "text": "upon experimental stress test we saw",
    "start": "100479",
    "end": "102720"
  },
  {
    "text": "celium resource utiliz utilization going",
    "start": "102720",
    "end": "105560"
  },
  {
    "text": "up to 35% invoice up to 42% so while",
    "start": "105560",
    "end": "109840"
  },
  {
    "text": "these are just synthetic test we would",
    "start": "109840",
    "end": "112119"
  },
  {
    "text": "be happy to discuss if you guys have any",
    "start": "112119",
    "end": "114399"
  },
  {
    "text": "profile data uh in your production",
    "start": "114399",
    "end": "117079"
  },
  {
    "text": "environment which shows something",
    "start": "117079",
    "end": "119479"
  },
  {
    "text": "similar kind of high utilization so in",
    "start": "119479",
    "end": "123399"
  },
  {
    "text": "the next in the next diagram we this is",
    "start": "123399",
    "end": "125920"
  },
  {
    "text": "the first model which we tried initially",
    "start": "125920",
    "end": "128119"
  },
  {
    "text": "and this was to deploy celium and invoy",
    "start": "128119",
    "end": "132440"
  },
  {
    "text": "using the demon set method on the dpus",
    "start": "132440",
    "end": "136879"
  },
  {
    "text": "and we use the Gateway API use case so",
    "start": "136879",
    "end": "139400"
  },
  {
    "text": "that all your traffic will come to your",
    "start": "139400",
    "end": "142120"
  },
  {
    "text": "dpus and from there all the Gateway",
    "start": "142120",
    "end": "144519"
  },
  {
    "text": "related processing will happen on dpu",
    "start": "144519",
    "end": "146560"
  },
  {
    "text": "with the help of invo deployed on dpu",
    "start": "146560",
    "end": "149080"
  },
  {
    "text": "and from there it will go directly to",
    "start": "149080",
    "end": "150959"
  },
  {
    "text": "the backend ports or uh the application",
    "start": "150959",
    "end": "155360"
  },
  {
    "start": "155000",
    "end": "172000"
  },
  {
    "text": "containers however after that we will",
    "start": "155360",
    "end": "157760"
  },
  {
    "text": "able to come up with the complete",
    "start": "157760",
    "end": "159760"
  },
  {
    "text": "offload architecture where your celium",
    "start": "159760",
    "end": "162360"
  },
  {
    "text": "agent ebpf data path and the invol proxy",
    "start": "162360",
    "end": "166360"
  },
  {
    "text": "all can be deployed or I can say",
    "start": "166360",
    "end": "169200"
  },
  {
    "text": "offloaded to the data processing",
    "start": "169200",
    "end": "172040"
  },
  {
    "start": "172000",
    "end": "257000"
  },
  {
    "text": "units so this is the detailed diagram of",
    "start": "172040",
    "end": "174959"
  },
  {
    "text": "the uh full primary Network offload to",
    "start": "174959",
    "end": "177360"
  },
  {
    "text": "dpu so we have introduced some plugins",
    "start": "177360",
    "end": "180920"
  },
  {
    "text": "to trans transparently offload all the",
    "start": "180920",
    "end": "184360"
  },
  {
    "text": "components no changes in the kubernetes",
    "start": "184360",
    "end": "187120"
  },
  {
    "text": "OR Port spec has been done so let's go",
    "start": "187120",
    "end": "190040"
  },
  {
    "text": "to the diagram as soon as your Port get",
    "start": "190040",
    "end": "192280"
  },
  {
    "text": "deploys CRI will call the cni agent like",
    "start": "192280",
    "end": "194760"
  },
  {
    "text": "the in the normal fashion but this",
    "start": "194760",
    "end": "196799"
  },
  {
    "text": "calling this connection will will be",
    "start": "196799",
    "end": "199400"
  },
  {
    "text": "intercepted by the cni offload layer now",
    "start": "199400",
    "end": "202879"
  },
  {
    "text": "this our cni offload layer we're going",
    "start": "202879",
    "end": "204879"
  },
  {
    "text": "to take all the data from the C from the",
    "start": "204879",
    "end": "207840"
  },
  {
    "text": "connection and we're going to at one",
    "start": "207840",
    "end": "210519"
  },
  {
    "text": "user one uh interface to the user",
    "start": "210519",
    "end": "213400"
  },
  {
    "text": "application pod now it will going to",
    "start": "213400",
    "end": "216599"
  },
  {
    "text": "send all the data to the interface which",
    "start": "216599",
    "end": "219239"
  },
  {
    "text": "is just allocated to the plugin that was",
    "start": "219239",
    "end": "221920"
  },
  {
    "text": "on the dpu now this plugin will going to",
    "start": "221920",
    "end": "223920"
  },
  {
    "text": "send all the data to your cni in the",
    "start": "223920",
    "end": "227840"
  },
  {
    "text": "same fashion that c does after getting",
    "start": "227840",
    "end": "230640"
  },
  {
    "text": "the data cni will be behave in the same",
    "start": "230640",
    "end": "233400"
  },
  {
    "text": "way that uh it will going to allocate",
    "start": "233400",
    "end": "235319"
  },
  {
    "text": "the other side of that connection to",
    "start": "235319",
    "end": "237120"
  },
  {
    "text": "your ebpf data path it will going to",
    "start": "237120",
    "end": "238959"
  },
  {
    "text": "attach that",
    "start": "238959",
    "end": "240360"
  },
  {
    "text": "so this connection you are seeing",
    "start": "240360",
    "end": "242400"
  },
  {
    "text": "between the application pod and the ebpf",
    "start": "242400",
    "end": "244879"
  },
  {
    "text": "data path is actually via virtual",
    "start": "244879",
    "end": "247439"
  },
  {
    "text": "function pair so we have a POC ready",
    "start": "247439",
    "end": "251920"
  },
  {
    "text": "model for this architecture and we would",
    "start": "251920",
    "end": "254159"
  },
  {
    "text": "love to discuss about this with the",
    "start": "254159",
    "end": "256799"
  },
  {
    "text": "community so our final idea is to",
    "start": "256799",
    "end": "260359"
  },
  {
    "start": "257000",
    "end": "312000"
  },
  {
    "text": "transition all the common infrastructure",
    "start": "260359",
    "end": "263360"
  },
  {
    "text": "workloads onto the dpus this will give",
    "start": "263360",
    "end": "266639"
  },
  {
    "text": "you two direct benefits first compute",
    "start": "266639",
    "end": "270199"
  },
  {
    "text": "power of the dpus the Hardwares will be",
    "start": "270199",
    "end": "273280"
  },
  {
    "text": "utilized and compute power of your",
    "start": "273280",
    "end": "275759"
  },
  {
    "text": "servers will be totally freed up to run",
    "start": "275759",
    "end": "278720"
  },
  {
    "text": "some to handle some additional",
    "start": "278720",
    "end": "280160"
  },
  {
    "text": "application workloads now in future we",
    "start": "280160",
    "end": "283400"
  },
  {
    "text": "would like to use the acceleration",
    "start": "283400",
    "end": "285160"
  },
  {
    "text": "capabilities which are offered by uh",
    "start": "285160",
    "end": "287240"
  },
  {
    "text": "modern dpus so that the compute",
    "start": "287240",
    "end": "290120"
  },
  {
    "text": "intensive portions of your these",
    "start": "290120",
    "end": "292080"
  },
  {
    "text": "workloads will be directly offloaded to",
    "start": "292080",
    "end": "294600"
  },
  {
    "text": "the hardware specialized Hardware",
    "start": "294600",
    "end": "296759"
  },
  {
    "text": "accelerators thereby increasing the",
    "start": "296759",
    "end": "298720"
  },
  {
    "text": "overall uh cluster performance and since",
    "start": "298720",
    "end": "301440"
  },
  {
    "text": "dpus are power efficient so the solution",
    "start": "301440",
    "end": "304280"
  },
  {
    "text": "has the potential to reduce the overall",
    "start": "304280",
    "end": "306600"
  },
  {
    "text": "power consumption of your kubernetes",
    "start": "306600",
    "end": "308800"
  },
  {
    "text": "cluster thank",
    "start": "308800",
    "end": "311880"
  },
  {
    "text": "you",
    "start": "311880",
    "end": "314880"
  }
]
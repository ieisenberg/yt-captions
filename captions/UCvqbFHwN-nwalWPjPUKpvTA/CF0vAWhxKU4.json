[
  {
    "text": "all right welcome to troubleshooting hidden performance and cost and network traffic across multiple azs with ebpf",
    "start": "160",
    "end": "8160"
  },
  {
    "text": "who here knows what ebpf is oh we're done you want to come up here yeah okay",
    "start": "8160",
    "end": "14920"
  },
  {
    "text": "awesome uh the then uh we'll get right into it I'm Nala I'm a principal",
    "start": "14920",
    "end": "21480"
  },
  {
    "text": "specialist solution architect at AWS and uh I work on containers and",
    "start": "21480",
    "end": "27000"
  },
  {
    "text": "serverless services and focus on observ ility and a few months ago Shahar and myself",
    "start": "27000",
    "end": "34520"
  },
  {
    "text": "we were talking about some of the customer problems some of your own problems around visibility and network",
    "start": "34520",
    "end": "41559"
  },
  {
    "text": "and we started coming up with this idea for this talk and so I'm joined by",
    "start": "41559",
    "end": "48120"
  },
  {
    "text": "Shahar hey everyone I'm shakar oai and I'm uh the co-founder and CEO of gr",
    "start": "48120",
    "end": "53359"
  },
  {
    "text": "cover guar is a full stack observability platform built for cloud native environments uh which uses ebpf which",
    "start": "53359",
    "end": "59640"
  },
  {
    "text": "we're going to talk about and this talk in yeah it looks like there's a lot of EF fans here yeah who likes",
    "start": "59640",
    "end": "65400"
  },
  {
    "text": "ebpf there we go louder louder yeah so why are we here why does ebpf",
    "start": "65400",
    "end": "72840"
  },
  {
    "text": "matter why does visibility observability matter the Amazon CTO verer Vogal he",
    "start": "72840",
    "end": "78240"
  },
  {
    "text": "said a few years ago everything fails all the time who's seen this slide before who's seen this quote it's true",
    "start": "78240",
    "end": "85360"
  },
  {
    "text": "right this is our North Star like this is our architectural principle at AWS",
    "start": "85360",
    "end": "90840"
  },
  {
    "text": "this this is what drives what we do at AWS and also what we tell our customers",
    "start": "90840",
    "end": "96240"
  },
  {
    "text": "to do you have to be aware that everything fails all the time and so",
    "start": "96240",
    "end": "102159"
  },
  {
    "text": "that leads to an architecture that centers around",
    "start": "102159",
    "end": "107880"
  },
  {
    "text": "resilience you have to design your systems to be able to deal with those failures but resilience comes with",
    "start": "107880",
    "end": "115920"
  },
  {
    "text": "tradeoffs sometimes it could be expensive or you you don't know the cost of",
    "start": "115920",
    "end": "121360"
  },
  {
    "text": "it so what is resilience resilience refers to the ability of workloads to",
    "start": "121360",
    "end": "127000"
  },
  {
    "text": "respond to and quickly recover from those failures and we think of a a",
    "start": "127000",
    "end": "132480"
  },
  {
    "text": "mental model to help us think about resilience on one side we have high availability and that's the resistance",
    "start": "132480",
    "end": "139319"
  },
  {
    "text": "of your system to those failures through the design of the of your system and",
    "start": "139319",
    "end": "144760"
  },
  {
    "text": "then disaster recover so how fast can you recover when there was some kind of",
    "start": "144760",
    "end": "149920"
  },
  {
    "text": "failure something out of some high impact failure so together this creates",
    "start": "149920",
    "end": "155280"
  },
  {
    "text": "a spectrum that we think of as continuous resilience and one of the main",
    "start": "155280",
    "end": "160920"
  },
  {
    "text": "components of continuous resilience architectures at AWS is availability zones who here knows",
    "start": "160920",
    "end": "167720"
  },
  {
    "text": "what an availability zone is okay so this is just a quick recap this perfect audience say no ebpf they know azs they",
    "start": "167720",
    "end": "175239"
  },
  {
    "text": "can come up here and do this talk um so azs are our availability",
    "start": "175239",
    "end": "180800"
  },
  {
    "text": "zones are one of our core components for Designing for resilience and these are",
    "start": "180800",
    "end": "186400"
  },
  {
    "text": "fully isolated one or more data centers in a specific region that are connected",
    "start": "186400",
    "end": "192159"
  },
  {
    "text": "through High um High highly available fall tolerant and scalable connectivity",
    "start": "192159",
    "end": "198120"
  },
  {
    "text": "and they're kind of like independent units and this is the the Cornerstone of building our systems with resiliency in",
    "start": "198120",
    "end": "204760"
  },
  {
    "text": "mind right all of you I hope are using more than one a in your architectures in your system",
    "start": "204760",
    "end": "211760"
  },
  {
    "text": "good now keeping a in mind we now are at cubec con right so we have to talk about",
    "start": "212159",
    "end": "218840"
  },
  {
    "text": "kubernetes I mean I guess we could talk about something else but we talk about kubernetes the kubernetes networking is",
    "start": "218840",
    "end": "224519"
  },
  {
    "text": "a different Paradigm right so just a quick recap with respect to kubernetes Services if you if you're new to",
    "start": "224519",
    "end": "231599"
  },
  {
    "text": "kubernetes these are this is the main core component of networking so a service enables load balancing to your",
    "start": "231599",
    "end": "239439"
  },
  {
    "text": "pod right so in this case we're going to be talking about backend pods and there's different types of services",
    "start": "239439",
    "end": "246079"
  },
  {
    "text": "mostly you see two different types which are cluster IP which is used for internal cluster",
    "start": "246079",
    "end": "251959"
  },
  {
    "text": "communication and there's node Port as well but that's not as used as as much these days and then you have a load",
    "start": "251959",
    "end": "257160"
  },
  {
    "text": "balancer service and that's usually to expose your services",
    "start": "257160",
    "end": "262360"
  },
  {
    "text": "externally so for our conversation today and I think about this as a conversation even though I will ask you to do",
    "start": "262360",
    "end": "268320"
  },
  {
    "text": "questions and answers afterward Ward and find us afterwards because I do not want to stop you from the party going on",
    "start": "268320",
    "end": "274600"
  },
  {
    "text": "upstairs let's think about a typical service that you might be running in your kubernetes cluster you have your",
    "start": "274600",
    "end": "282960"
  },
  {
    "text": "external customers or your clients they they send a request to a network load",
    "start": "282960",
    "end": "288680"
  },
  {
    "text": "balancer for example and then that goes through Q proxy which then communicates to the",
    "start": "288680",
    "end": "295120"
  },
  {
    "text": "nodeport service which then communicates to the cluster IP service",
    "start": "295120",
    "end": "300320"
  },
  {
    "text": "which then load balances those pods across or or load balances that traffic",
    "start": "300320",
    "end": "306560"
  },
  {
    "text": "across different uh different pods so for this front end pods service we have three pods now what you might not be",
    "start": "306560",
    "end": "314360"
  },
  {
    "text": "aware and it depends on the architecture uh maybe not there we go is these",
    "start": "314360",
    "end": "321199"
  },
  {
    "text": "different front end pods are in different A's and so there are some considerations",
    "start": "321199",
    "end": "326840"
  },
  {
    "text": "here with respect to network topology performance and cost in this load",
    "start": "326840",
    "end": "332400"
  },
  {
    "text": "balancing between azs so for example that Q proxy service is an AA did you",
    "start": "332400",
    "end": "337759"
  },
  {
    "text": "know that I don't know and it's load balancing across these two azs so already with a very",
    "start": "337759",
    "end": "344440"
  },
  {
    "text": "simple service we have cross a network traffic or opportunities where traffic",
    "start": "344440",
    "end": "350479"
  },
  {
    "text": "are going from one node to another within your cluster Crossing those a boundaries are you aware of where that",
    "start": "350479",
    "end": "358400"
  },
  {
    "text": "traffic is going how do you know if that's important or not for your resiliency",
    "start": "358400",
    "end": "365039"
  },
  {
    "text": "design now that front end pod you know most of our services aren't just one pod",
    "start": "365039",
    "end": "370360"
  },
  {
    "text": "that would be amazing most of them are complex so that front-end pod now has to reach out to a back-end service and that",
    "start": "370360",
    "end": "377039"
  },
  {
    "text": "backend service is on the same cluster that goes through cluster IP that's running in some kind of a and we're",
    "start": "377039",
    "end": "384240"
  },
  {
    "text": "we're a small company this service is very lightweight and we just need one backend pod and it's just going to the",
    "start": "384240",
    "end": "390560"
  },
  {
    "text": "same a awesome but all of a sudden it gets really popular you know I put gen",
    "start": "390560",
    "end": "395840"
  },
  {
    "text": "into my application name and all of a sudden the traffic goes through the roof right oh man what am I going to do so I",
    "start": "395840",
    "end": "402479"
  },
  {
    "text": "go to the backend deployment replica set and I set it from one to three and what happens tell me what",
    "start": "402479",
    "end": "409479"
  },
  {
    "text": "happens we get more pods right so now new pods show up those backend pods are",
    "start": "409479",
    "end": "415560"
  },
  {
    "text": "in three different A's now now I didn't know that maybe you",
    "start": "415560",
    "end": "421599"
  },
  {
    "text": "know I'm just an application developer all I did was put gen into the title of my application and all of a sudden I got to scale up my service to thousands of",
    "start": "421599",
    "end": "428720"
  },
  {
    "text": "PODS and this is a very simple example this is about as simple of an application as I can think of and all of",
    "start": "428720",
    "end": "434520"
  },
  {
    "text": "a sudden we have new things to consider hidden tradeoffs that I did not know",
    "start": "434520",
    "end": "439720"
  },
  {
    "text": "about and that you might not know about so first of all we have service complexity right just this this front",
    "start": "439720",
    "end": "446240"
  },
  {
    "text": "end and this back end it's just three ponds each and we now have N squared",
    "start": "446240",
    "end": "451840"
  },
  {
    "text": "traffic configurations that can be that can coexist at any given moment in time in my cluster and this is just one",
    "start": "451840",
    "end": "458520"
  },
  {
    "text": "application on one cluster and it starts to scale complexity wise very",
    "start": "458520",
    "end": "464280"
  },
  {
    "text": "rapidly then we've got cost considerations that pod that front end",
    "start": "464280",
    "end": "469720"
  },
  {
    "text": "pod is in AA and now it's load balancing to AA ASB AC and there's cost",
    "start": "469720",
    "end": "475879"
  },
  {
    "text": "implications in terms of network traffic and resources that I know I didn't I might not know about",
    "start": "475879",
    "end": "482800"
  },
  {
    "text": "maybe I wanted all that traffic to only go to ASB don't know and then there's",
    "start": "482800",
    "end": "487840"
  },
  {
    "text": "performance and reliability considerations so these are three considerations in terms of the",
    "start": "487840",
    "end": "493639"
  },
  {
    "text": "performance maybe I wanted that traffic to only go to the same a and that data the data on that backend service is",
    "start": "493639",
    "end": "500599"
  },
  {
    "text": "better in a AA and so I meant aa aa to",
    "start": "500599",
    "end": "506680"
  },
  {
    "text": "AA and so there these are all the considerations and hidden tradeoffs that",
    "start": "506680",
    "end": "512159"
  },
  {
    "text": "I need visibility into to make a better resiliency decision so gaining",
    "start": "512159",
    "end": "517200"
  },
  {
    "text": "visibility for resiliency decisions we want to make the best decision on resiliency tradeoffs as possible right",
    "start": "517200",
    "end": "524440"
  },
  {
    "text": "I'm an engineer I got to respond to this architecture I'm on call I want to make sure that I'm making the best",
    "start": "524440",
    "end": "530880"
  },
  {
    "text": "architectural decision at any given moment in time so we need visibility into what services are talking to each",
    "start": "530880",
    "end": "537000"
  },
  {
    "text": "other where those services are running the metrics that matter to those Services right so it could be latency it",
    "start": "537000",
    "end": "544160"
  },
  {
    "text": "could be cost it could be CPU usage it could be pod level networking it could",
    "start": "544160",
    "end": "550160"
  },
  {
    "text": "be all kinds of things and then the Telemetry has to be correlated to the kubernetes resources so that I know what",
    "start": "550160",
    "end": "557440"
  },
  {
    "text": "is talking to what at the kubernetes context right with kubernetes information resources and metadata so",
    "start": "557440",
    "end": "565440"
  },
  {
    "text": "what do I go to first to get this Prometheus not bad I can get metric for the pods the containers and other",
    "start": "565440",
    "end": "573279"
  },
  {
    "text": "services the node but it doesn't give me where those where that traffic is going",
    "start": "573279",
    "end": "579279"
  },
  {
    "text": "to from one a to another and it doesn't necessarily give me information about the performance between those services",
    "start": "579279",
    "end": "587079"
  },
  {
    "text": "so then I start using open Telemetry who he is using open Telemetry awesome so I can start tracing",
    "start": "587079",
    "end": "596480"
  },
  {
    "text": "and that gives me some dependency uh map and and understand what service is talking to what but again that's uh that",
    "start": "596480",
    "end": "603959"
  },
  {
    "text": "doesn't have all the information at the as level that I might need so I take a",
    "start": "603959",
    "end": "611120"
  },
  {
    "text": "look at VPC flow logs right but this is awesome I get a get a good understanding",
    "start": "611120",
    "end": "616920"
  },
  {
    "text": "of what packets are flying what what transactions are flying through the network but bpc flow logs don't have",
    "start": "616920",
    "end": "624519"
  },
  {
    "text": "anything to do with kubernetes I don't know what that IP address is associated with the front end service or the",
    "start": "624519",
    "end": "630000"
  },
  {
    "text": "backend service don't know I can look at eni metrics but that's mostly around IP",
    "start": "630000",
    "end": "635880"
  },
  {
    "text": "address allocation and uh what What's the ipam services looking like if I'm",
    "start": "635880",
    "end": "641560"
  },
  {
    "text": "going to run out of IP addresses it kind of gets me a little bit of information but not what I really need and then we",
    "start": "641560",
    "end": "648160"
  },
  {
    "text": "have the load balancer metrics that's great those transactions we going through a load balancer first and I need",
    "start": "648160",
    "end": "653680"
  },
  {
    "text": "to make sure that I understand where that's going to in those different azs at any given moment but",
    "start": "653680",
    "end": "659760"
  },
  {
    "text": "that's a separate system and it has no idea what what kubernetes pods are running what name space what service Etc",
    "start": "659760",
    "end": "666880"
  },
  {
    "text": "so this gets me some of the way it gets me some of the good data but I think we can do better and so I'm going to go",
    "start": "666880",
    "end": "673519"
  },
  {
    "text": "over to Shahar and see how we can do better there we go wrong thing well",
    "start": "673519",
    "end": "680639"
  },
  {
    "text": "thank you for setting the stage near um so we all got uh kind of the the the",
    "start": "680639",
    "end": "686519"
  },
  {
    "text": "ground stated together of of uh A's being important right we have to have this resiliency most of you are probably",
    "start": "686519",
    "end": "692360"
  },
  {
    "text": "using it in some form um but getting insights of how this actually works and",
    "start": "692360",
    "end": "697720"
  },
  {
    "text": "how to actually manage this specific tradeoff that A's represent that's still",
    "start": "697720",
    "end": "703680"
  },
  {
    "text": "kind of hard with all the tools that Nile just kind of went through so before setting up into you know building a new",
    "start": "703680",
    "end": "709800"
  },
  {
    "text": "land and kind of figuring out how ebpf can help us let's figure out what we're trying to improve right what with the",
    "start": "709800",
    "end": "715000"
  },
  {
    "text": "current state of tools you guys all use in in your current cloud provider so the first thing is service identity we're",
    "start": "715000",
    "end": "722519"
  },
  {
    "text": "using kubernetes this is a kubernetes conference you guys are using the kubernetes infrastructure we have to",
    "start": "722519",
    "end": "728079"
  },
  {
    "text": "relate what we're seeing in things like VPC flow logs and all the tools we have to the actual kubernetes entity right",
    "start": "728079",
    "end": "733920"
  },
  {
    "text": "and it it gets even worse if you're looking at VPC flow logs you see IPS and ports that's great but that's only",
    "start": "733920",
    "end": "739839"
  },
  {
    "text": "relevant for now what happens a few hours later where where pods get replaced that IP is no longer relevant",
    "start": "739839",
    "end": "745199"
  },
  {
    "text": "you can't even use it to figure out uh what how to troubleshoot your kual environment even if you had the ability",
    "start": "745199",
    "end": "751279"
  },
  {
    "text": "to do so and the second thing that we um usually Overlook is the carnality of the",
    "start": "751279",
    "end": "757199"
  },
  {
    "text": "problem where you looking at things uh specifically like VPC flow logs these things represent million of of events",
    "start": "757199",
    "end": "763800"
  },
  {
    "text": "just flowing in basically saying how much traffic is being trans transmitted between different IPS inside your",
    "start": "763800",
    "end": "769279"
  },
  {
    "text": "environment but we want to use metrics right we want to measure Trends we want to figure out what's going on even if we",
    "start": "769279",
    "end": "776320"
  },
  {
    "text": "could attach some entities from kubernetes into these VPC flow logs and say you know this IP is actually this p",
    "start": "776320",
    "end": "782959"
  },
  {
    "text": "and this deployment if we even if we could have done that how are we going to aggregate all this stuff into usable",
    "start": "782959",
    "end": "788959"
  },
  {
    "text": "stuff that we can actually take Decisions by right knowing that a specific part at specific time did something and and transmitted something",
    "start": "788959",
    "end": "796279"
  },
  {
    "text": "it might not be the best thing to make a decision of whether I need cross a communication or not for my system and",
    "start": "796279",
    "end": "802279"
  },
  {
    "text": "the third part is lack of EX ability even if we know something about what's going on there's so much information and",
    "start": "802279",
    "end": "808560"
  },
  {
    "text": "so many pods running in your kubernetes cluster that making decision making decisions about it we're going to have",
    "start": "808560",
    "end": "813680"
  },
  {
    "text": "to get some more information like what API is actually carrying this cross availabilities on communication was did",
    "start": "813680",
    "end": "820120"
  },
  {
    "text": "I intend to do that or it's just a random API that I know that isn't something that I plan for my",
    "start": "820120",
    "end": "827040"
  },
  {
    "text": "resiliency so before we uh dive into what we want to achieve uh let's just",
    "start": "827040",
    "end": "832120"
  },
  {
    "text": "name it we want a kuber that is aware Network sensor right that's what we want to achieve we want something to be aware",
    "start": "832120",
    "end": "837639"
  },
  {
    "text": "of the infrastructure that's going to help help us make decisions about whether this cross a communication is something that we intended to do like",
    "start": "837639",
    "end": "844360"
  },
  {
    "text": "you do in everything even in setting your requests the limits in your past right you intended to do so so between",
    "start": "844360",
    "end": "850600"
  },
  {
    "text": "AA and ACC in this drawings there's a a lot of different network streams the first thing we want to do is make sure",
    "start": "850600",
    "end": "856800"
  },
  {
    "text": "that we tightly link that to the kubernetes structure we want to name the pods on both ends on each each of the",
    "start": "856800",
    "end": "862639"
  },
  {
    "text": "streams that's kind of intuitive right the second thing you want to do is aggregate it to some level that makes",
    "start": "862639",
    "end": "868279"
  },
  {
    "text": "sense that ality you can work with and the the first thing that comes to mind is the cality of the kubernets",
    "start": "868279",
    "end": "874360"
  },
  {
    "text": "deployment right do I actually want to measure the communication between each and every pod and each and every pod on",
    "start": "874360",
    "end": "879880"
  },
  {
    "text": "the other end or I want to say something that describes the phenomena of two different deployments communicated cross",
    "start": "879880",
    "end": "885920"
  },
  {
    "text": "availability zones and the final thing that we're going to try to achieve with evf in this",
    "start": "885920",
    "end": "891120"
  },
  {
    "text": "stock is pinning down something that's going to help you reach the the root cause of this cross availability Zone",
    "start": "891120",
    "end": "897160"
  },
  {
    "text": "traffic and again figure out if if it's important to you and for example knowing that API search which is an HTTP API is",
    "start": "897160",
    "end": "904600"
  },
  {
    "text": "carrying this traffic might help you make a decision of whether to address the issue or whether you intended that",
    "start": "904600",
    "end": "910600"
  },
  {
    "text": "your uh platform will be built like that so a good idea come to mind right",
    "start": "910600",
    "end": "916320"
  },
  {
    "text": "uh ebpf is is a strong Buzz these days and it can probably help us out and to",
    "start": "916320",
    "end": "921920"
  },
  {
    "text": "those of you that don't know what ebpf is ebpf is a revolutionary technology that allows us to run programs in the",
    "start": "921920",
    "end": "928000"
  },
  {
    "text": "context of the Linux kernel itself uh in in kubernetes it means in the context of the actual kubernetes node the actual",
    "start": "928000",
    "end": "933800"
  },
  {
    "text": "kubernetes worker node itself without doing any scary stuff for charging car Cod or anything like that but these evf",
    "start": "933800",
    "end": "940399"
  },
  {
    "text": "programs have more power than that they can observe what our containers are doing without intervening with the",
    "start": "940399",
    "end": "946000"
  },
  {
    "text": "application code itself basically means that we can see what containers are re sending and receiving across the entire",
    "start": "946000",
    "end": "952399"
  },
  {
    "text": "cluster just by sending a simple evf program into the kernel of each of these nodes now it sounds like which should be",
    "start": "952399",
    "end": "959399"
  },
  {
    "text": "pretty easy right ebpf was built to observe Network traffic it's an event driven system built to observe",
    "start": "959399",
    "end": "965319"
  },
  {
    "text": "situations like Network receive and send uh and it also runs directly on the",
    "start": "965319",
    "end": "971240"
  },
  {
    "text": "kubernetes deployment we wanted the kubernetes aware sensor that's that's what it is it run it will run it as a",
    "start": "971240",
    "end": "977079"
  },
  {
    "text": "deployment on your kubernetes cluster aware of the kubernetes infrastructure and the last bit of ebpf program that",
    "start": "977079",
    "end": "983759"
  },
  {
    "text": "sounds like we can punch a few stuff in there right like a logic for our aggregation or whatever you want to achieve so that sounds like a magical",
    "start": "983759",
    "end": "991319"
  },
  {
    "text": "solution to every problem we wanted to solve with VPC flow logs or things that come from our Cloud",
    "start": "991319",
    "end": "997319"
  },
  {
    "text": "metrics um as as we all know there's a bit of execution behind any great idea",
    "start": "997319",
    "end": "1002519"
  },
  {
    "text": "so uh thanks C for that so let's dive a bit into the details of how we can actually pull it off so the first thing",
    "start": "1002519",
    "end": "1009600"
  },
  {
    "text": "we're going to do is collect Network metrics where now this is ef's moment to shine because evf was built to probe",
    "start": "1009600",
    "end": "1016319"
  },
  {
    "text": "simple operations in the kernel user space like socket rener right we can easily build uh counters that count the",
    "start": "1016319",
    "end": "1024079"
  },
  {
    "text": "bytes uh that pass and be that that or sent or received on each of uh these",
    "start": "1024079",
    "end": "1029438"
  },
  {
    "text": "socket Pairs and start creating metrics from the infrastructure itself on things like IP and Port from the client side IP",
    "start": "1029439",
    "end": "1036918"
  },
  {
    "text": "and Port from from the server side and count these metrics over time building these throughput metrics eventually that",
    "start": "1036919",
    "end": "1042678"
  },
  {
    "text": "we can use now this is already a good start compared to things that we have in",
    "start": "1042679",
    "end": "1048038"
  },
  {
    "text": "a vent driven system sys like VPC fla locks but eventually we do end up with",
    "start": "1048039",
    "end": "1053720"
  },
  {
    "text": "this kind of for Tuple right of Ip and port on both end and drop right into the first two problems that are clear the",
    "start": "1053720",
    "end": "1061360"
  },
  {
    "text": "first thing is that the client Port is usually random it has nothing to do with the logical aspect of the connection",
    "start": "1061360",
    "end": "1066799"
  },
  {
    "text": "itself it tell us nothing but the port being selected at the initiation of the connection itself and it creates a lot",
    "start": "1066799",
    "end": "1074360"
  },
  {
    "text": "of cardinality to what whatever we're trying to describe right if we're going to build a metric with this label we should think about it heavily because",
    "start": "1074360",
    "end": "1080640"
  },
  {
    "text": "that's going to be a very high cality metric and the second thing is as nma just told us we're in kubernetes a",
    "start": "1080640",
    "end": "1086799"
  },
  {
    "text": "server IP that's virtual in most cases it's going to be a a kuber service that",
    "start": "1086799",
    "end": "1091919"
  },
  {
    "text": "uh behind the scenes uh basically communicates to a lot of different pods how can we use a virtual IP to figure",
    "start": "1091919",
    "end": "1097919"
  },
  {
    "text": "out what's going on so we're going to address the problem uh straight on at the beginning by dropping the client",
    "start": "1097919",
    "end": "1103200"
  },
  {
    "text": "Port we don't really need it to figure out what's going on and make decisions on the uh at logical aspect of the",
    "start": "1103200",
    "end": "1109440"
  },
  {
    "text": "connection and we're going to translate the service IP with some ebpf magic now without diving too deep into that ebpf",
    "start": "1109440",
    "end": "1115720"
  },
  {
    "text": "is situated in the best Junction possible at observing kernel operations",
    "start": "1115720",
    "end": "1121200"
  },
  {
    "text": "like the services that the kernel provide to translate not translation and basically make decisions about what that",
    "start": "1121200",
    "end": "1128080"
  },
  {
    "text": "kubernetes uses about what the server IP actually represents and translating it to an actual po IP behind the scenes so",
    "start": "1128080",
    "end": "1135919"
  },
  {
    "text": "we end up with a tree Tuple and new of P IP on both ends which is a physical",
    "start": "1135919",
    "end": "1142360"
  },
  {
    "text": "IP we can actually use to understand and the server Port which we're going to continue to take with us for for uh the",
    "start": "1142360",
    "end": "1148520"
  },
  {
    "text": "meanwhile now the next thing we're going to do is tie that back to the kubernetes infrastructure we're going to use the",
    "start": "1148520",
    "end": "1153640"
  },
  {
    "text": "kubernetes API that's very intuitive to do uh the kubernetes API uh holds all",
    "start": "1153640",
    "end": "1159280"
  },
  {
    "text": "the kubernetes hierarchy in one place we can listen in on events that change this hierarchy and make sure that we stay up",
    "start": "1159280",
    "end": "1166120"
  },
  {
    "text": "to dat all the pods all the nodes that host them all these manifests are being described in the kubernetes API server",
    "start": "1166120",
    "end": "1172360"
  },
  {
    "text": "so we can start to do three things first we're going to turn all these pod IPS into pod names right we want IP is",
    "start": "1172360",
    "end": "1178799"
  },
  {
    "text": "transient we want to make sure that we hang on to a pod and a deployment name that represents something that you guys",
    "start": "1178799",
    "end": "1184919"
  },
  {
    "text": "wrote or understand rather than an IP uh and we're going to retrieve the availability Zone value from the node",
    "start": "1184919",
    "end": "1190720"
  },
  {
    "text": "manifest we have all these nodes running in the cluster their manifest basically tells us what availability Zone they",
    "start": "1190720",
    "end": "1196280"
  },
  {
    "text": "belong to and then we're going to tie that back to the p we know each pod who's the node that hosts it and now we",
    "start": "1196280",
    "end": "1202080"
  },
  {
    "text": "have the AZ of the actual pod itself and that's it basically we have the full context we have front end pod",
    "start": "1202080",
    "end": "1209200"
  },
  {
    "text": "on one end communicating to a back end pod on one end on the other end both of them belong to uh a specific deployment",
    "start": "1209200",
    "end": "1215760"
  },
  {
    "text": "called front end or back end and we know the node they're running on and therefore the a they're running on so we",
    "start": "1215760",
    "end": "1222000"
  },
  {
    "text": "just moved to um a description which is much more suitable to what we tried to do measuring a counter bite metric of",
    "start": "1222000",
    "end": "1228960"
  },
  {
    "text": "communication between client on pod name and a on one end to a server with pod name port and a on the",
    "start": "1228960",
    "end": "1236240"
  },
  {
    "text": "other now that's a good time to stop for a second and figure out what do we want to measure right because eventually just",
    "start": "1236240",
    "end": "1243760"
  },
  {
    "text": "creating all these metrics without the ability to make decision with them it's something that uh we all know from",
    "start": "1243760",
    "end": "1249000"
  },
  {
    "text": "observability and a lot of different aspects too much data isn't necessarily a good choice uh we did have to go all the way",
    "start": "1249000",
    "end": "1256080"
  },
  {
    "text": "to to the Pod grity to get the a right without knowing the Pod and figur",
    "start": "1256080",
    "end": "1261240"
  },
  {
    "text": "figuring out which node hosts it we would never get to the a level which is Our intention at the beginning but do we",
    "start": "1261240",
    "end": "1267520"
  },
  {
    "text": "really want to say a specific front end pod is communicating with this and this volume to a specific backend pod because",
    "start": "1267520",
    "end": "1274559"
  },
  {
    "text": "that could be tremendously wasteful imagine the situation of 100 pods on each end as Neal just described that's",
    "start": "1274559",
    "end": "1281279"
  },
  {
    "text": "100 time 100 possible connections does it really give us anything to measure any intricate connection between all",
    "start": "1281279",
    "end": "1287960"
  },
  {
    "text": "these differents in most cases what we really wanted to say was front end is communicated to",
    "start": "1287960",
    "end": "1294000"
  },
  {
    "text": "backend at this or this velocity and some of this traffic is crossing A's so we can make decisions by",
    "start": "1294000",
    "end": "1301080"
  },
  {
    "text": "that and so we aggregate all the metrics that we're going to show from now on into this kind of new description new",
    "start": "1301080",
    "end": "1308760"
  },
  {
    "text": "labels of a kubet this workload name like a deployment or any anything that represents this group of PS on the",
    "start": "1308760",
    "end": "1316720"
  },
  {
    "text": "client side which is with its relevant a and a workload and server port and a on",
    "start": "1316720",
    "end": "1322039"
  },
  {
    "text": "the server side so now it's much more descriptive and much more aggregated to things that we understand as a logical",
    "start": "1322039",
    "end": "1328200"
  },
  {
    "text": "aspect of kubernetes now these are a lot of thoughts and a lot of theory we wanted to show you how it might look",
    "start": "1328200",
    "end": "1333799"
  },
  {
    "text": "like in an actual system that is very kubernetes aware and measures this metrics so we're going to dive deep into",
    "start": "1333799",
    "end": "1339720"
  },
  {
    "text": "a u an example of ground cover showing all the different deployments right now in the kubernetes cluster in a specific",
    "start": "1339720",
    "end": "1345480"
  },
  {
    "text": "namespace and we're going to focus on checkout service which is a specific deployment we see that it has one pod",
    "start": "1345480",
    "end": "1351640"
  },
  {
    "text": "and it's running healthy and we see that it communicates to a few different other workloads in the same uh kubernetes",
    "start": "1351640",
    "end": "1357720"
  },
  {
    "text": "cluster these six different workloads represent six different deployments that this workload communicates with now if",
    "start": "1357720",
    "end": "1364320"
  },
  {
    "text": "we look at the network metric that we just described we see two things one is that about 500 bytes per second are",
    "start": "1364320",
    "end": "1371080"
  },
  {
    "text": "being sent from uh checkout service to the other deployments and about half of",
    "start": "1371080",
    "end": "1376279"
  },
  {
    "text": "this is crossing availability zones now it could have stopped here but now we also know the four out of the six that",
    "start": "1376279",
    "end": "1382640"
  },
  {
    "text": "actually partner on the other end of this cross availability Zone um network",
    "start": "1382640",
    "end": "1387960"
  },
  {
    "text": "network traffic now this is super powerful right because we we're not just looking at six random connections which",
    "start": "1387960",
    "end": "1394760"
  },
  {
    "text": "we might have known from just knowing how the system is built we know the exact four that cross availability zone",
    "start": "1394760",
    "end": "1401720"
  },
  {
    "text": "so it might be a wrap-up right we know it we know uh what what is crossing a is",
    "start": "1401720",
    "end": "1406960"
  },
  {
    "text": "and now you can make a decision of whether you intended to do so or not but is there a way to make it a bit more",
    "start": "1406960",
    "end": "1412760"
  },
  {
    "text": "actionable even more we know that evf is a very strong tool right it can observe socket read",
    "start": "1412760",
    "end": "1419520"
  },
  {
    "text": "and right and kind of measure bytes being transferred at the at the lowest level like we just describe but it it",
    "start": "1419520",
    "end": "1425200"
  },
  {
    "text": "can also capture L7 traces like application Level traces right it can",
    "start": "1425200",
    "end": "1430520"
  },
  {
    "text": "measure API throughputs and see it through the application and user space itself with no cone changes as well to",
    "start": "1430520",
    "end": "1436559"
  },
  {
    "text": "the containers you're running uh a lot of different solutions out there from open source to things like ground cover utilize this exact capability so that's",
    "start": "1436559",
    "end": "1444880"
  },
  {
    "text": "a great an interesting idea and also traces can be linked back to the infrastructure in the exact same way we",
    "start": "1444880",
    "end": "1450919"
  },
  {
    "text": "can know the pods on both ends we can know the relevant nodes we can know their A's in the exact same way we did",
    "start": "1450919",
    "end": "1456480"
  },
  {
    "text": "so far so why don't use that because traces have so much more information",
    "start": "1456480",
    "end": "1461679"
  },
  {
    "text": "like is the traffic encrypted what's the protocol being transmitted at the application Level between these two",
    "start": "1461679",
    "end": "1467640"
  },
  {
    "text": "different paths across the A and so we do a couple of things that we want to show you that are interesting",
    "start": "1467640",
    "end": "1473720"
  },
  {
    "text": "to kind of Crank It Up A Notch one is that we enrich those metrics into something that is usable even more we're",
    "start": "1473720",
    "end": "1481200"
  },
  {
    "text": "going to replace the port label which is interesting on its own with a ristic",
    "start": "1481200",
    "end": "1486279"
  },
  {
    "text": "enrichment of basically saying we know that this traffic represents https for example so this metrics suddenly be",
    "start": "1486279",
    "end": "1492919"
  },
  {
    "text": "became even more interesting but we're not going to stop there because what if we could attach across a label to any",
    "start": "1492919",
    "end": "1500360"
  },
  {
    "text": "singular Trace that is being transmitted inside the cluster right looking at metrics looking at Trends making",
    "start": "1500360",
    "end": "1506880"
  },
  {
    "text": "decisions by a volume of buys being transmitted between a two specific workloads and a specific API over time",
    "start": "1506880",
    "end": "1514279"
  },
  {
    "text": "that's great but why don't see an example right why don't see a specific span being sent between two pods and",
    "start": "1514279",
    "end": "1520640"
  },
  {
    "text": "label that span is crossing the availability zone so we're going to do just just that in this demo we're going to walk in the",
    "start": "1520640",
    "end": "1527200"
  },
  {
    "text": "Tracer screen of ground cover and we're going to filter the workload called checkout service that we saw before communicating with these four different",
    "start": "1527200",
    "end": "1534039"
  },
  {
    "text": "other workloads over availability zones we see the cross a label at the top mentioning that this span just crossed a",
    "start": "1534039",
    "end": "1541080"
  },
  {
    "text": "and we know this this is a grpc span and we're not going to stop there we're going to filter all the cross",
    "start": "1541080",
    "end": "1547399"
  },
  {
    "text": "availability Zone spans and we get a list and volume over time of actual spans and examples with their payloads",
    "start": "1547399",
    "end": "1554480"
  },
  {
    "text": "being Crossing being sent and Crossing availability zones so we can take these examples and dive deeper with",
    "start": "1554480",
    "end": "1561399"
  },
  {
    "text": "the developers with the devops team with whatever responsible for the deployment that made a decision of whether it",
    "start": "1561399",
    "end": "1567320"
  },
  {
    "text": "actually is something we intended to do now what did we end up with we had on",
    "start": "1567320",
    "end": "1572919"
  },
  {
    "text": "one add Network metrix um these metrics translate directly into cost into",
    "start": "1572919",
    "end": "1579880"
  },
  {
    "text": "performance of your application you might see we might see a specific workload representing a lot of chz",
    "start": "1579880",
    "end": "1585919"
  },
  {
    "text": "communication and you might want to treat that just by looking at these metrics but we also got deep deep",
    "start": "1585919",
    "end": "1591960"
  },
  {
    "text": "contexts with traces so now we know who to blame we know where to focus we know how to maybe solve the issue and maybe",
    "start": "1591960",
    "end": "1598200"
  },
  {
    "text": "take decisions on our architecture based on that to show you that uh this can happen",
    "start": "1598200",
    "end": "1603679"
  },
  {
    "text": "in real life this is the actually the the story of ground cover of us finding this exact uh situation that we just",
    "start": "1603679",
    "end": "1610240"
  },
  {
    "text": "described and basically eating our own dog food which is always a good example of uh things being",
    "start": "1610240",
    "end": "1615600"
  },
  {
    "text": "interesting um this is a very rough description clearly of the ground cover um metric ingestion pipeline we're",
    "start": "1615600",
    "end": "1622320"
  },
  {
    "text": "absorbability company as part of that we store a lot of metrics so our our",
    "start": "1622320",
    "end": "1627399"
  },
  {
    "text": "production was built on top of an ingestion Pipeline with a front end based on k and a metric ingestion",
    "start": "1627399",
    "end": "1632880"
  },
  {
    "text": "pipeline built on victoriia Metric which eventually represented the entire pipeline we wanted to uh make sure it's",
    "start": "1632880",
    "end": "1639159"
  },
  {
    "text": "resilient right so we created multiple availability zones that that was a clear decision if AA drops we want to make",
    "start": "1639159",
    "end": "1646919"
  },
  {
    "text": "sure that ingesting the metric continues so we deployed both Khan and Victoria",
    "start": "1646919",
    "end": "1652039"
  },
  {
    "text": "metrics on these multiple A's and we were good to go right we're we're resilient if something happens to one of",
    "start": "1652039",
    "end": "1658200"
  },
  {
    "text": "these A's our application is going to keep on functioning but what we found a few months later is that the origional",
    "start": "1658200",
    "end": "1663880"
  },
  {
    "text": "network cost which is basically describing this cross a communication Network cost was higher than the compute",
    "start": "1663880",
    "end": "1669480"
  },
  {
    "text": "of the cluster itself which in this case stores all our metrics so for us that",
    "start": "1669480",
    "end": "1675039"
  },
  {
    "text": "wasn't logical enough to make a decision but I think what's more interesting is what did we actually intended to even do",
    "start": "1675039",
    "end": "1682080"
  },
  {
    "text": "right we intended that Kong and Victoria metrics will both run on AA and ASB we",
    "start": "1682080",
    "end": "1688679"
  },
  {
    "text": "wanted to make sure that if AAA drops dead that ASB is going to be there to back us up but did we really intend for",
    "start": "1688679",
    "end": "1695200"
  },
  {
    "text": "a k from AA to communicate with a victorium ingestion pipeline from ASB",
    "start": "1695200",
    "end": "1700679"
  },
  {
    "text": "not not necessarily we just didn't know exactly what we were doing and exactly what we were causing uh with this",
    "start": "1700679",
    "end": "1710120"
  },
  {
    "text": "so I really appreciate that story because I think this is where I see a",
    "start": "1713159",
    "end": "1719559"
  },
  {
    "text": "lot of customers that they think they know how they design their architecture",
    "start": "1719559",
    "end": "1725600"
  },
  {
    "text": "and they think they know oh yeah I've deployed this I've put some rules or I",
    "start": "1725600",
    "end": "1731679"
  },
  {
    "text": "have this traffic going here and I've set up the load balancy I'm resilient I'm okay I know when an a fails I know",
    "start": "1731679",
    "end": "1738240"
  },
  {
    "text": "traffic is going to go but when you really dig in you find",
    "start": "1738240",
    "end": "1743360"
  },
  {
    "text": "out that oh I didn't know this service was talking to this I didn't know this was configured from AA to AC or AA to AA",
    "start": "1743360",
    "end": "1751200"
  },
  {
    "text": "even right so they thought they were building something with resiliency in mind but really they were just sending",
    "start": "1751200",
    "end": "1756960"
  },
  {
    "text": "the traffic to the same Zone and if that zone went down then there was no resiliency so think about your own",
    "start": "1756960",
    "end": "1763720"
  },
  {
    "text": "architecture and it's awesome and what your assumptions are about that but you need to have something there to",
    "start": "1763720",
    "end": "1770480"
  },
  {
    "text": "validate whether those assumptions about your architecture cross a are actually",
    "start": "1770480",
    "end": "1776399"
  },
  {
    "text": "true so the takeaways for this are resiliency decisions are based on balancing these competing values right",
    "start": "1776399",
    "end": "1783720"
  },
  {
    "text": "so you have different needs like availability performance and cost that",
    "start": "1783720",
    "end": "1789279"
  },
  {
    "text": "all driving and balancing the decision that you need to make so sometimes a high cost in multi-az and having network",
    "start": "1789279",
    "end": "1797360"
  },
  {
    "text": "traffic going across A's is exactly what you want and that's the intended design but maybe you want to make sure that",
    "start": "1797360",
    "end": "1804279"
  },
  {
    "text": "this service is always talking to a service that's in the same a and having",
    "start": "1804279",
    "end": "1809880"
  },
  {
    "text": "that uh resiliency architectural trade-off decision data is important",
    "start": "1809880",
    "end": "1816720"
  },
  {
    "text": "utilize ebpf to get that data it gives you that granular level metrics and",
    "start": "1816720",
    "end": "1824200"
  },
  {
    "text": "information and traces and Telemetry and then you can connect it to the kubernetes metadata to understand what",
    "start": "1824200",
    "end": "1832559"
  },
  {
    "text": "services are talking about what services enriched with the A's that those",
    "start": "1832559",
    "end": "1838840"
  },
  {
    "text": "services are sitting on and then you can take action so once you know what the",
    "start": "1838840",
    "end": "1845600"
  },
  {
    "text": "actual state of your services are you can change the architecture by implementing topology aware routing or",
    "start": "1845600",
    "end": "1852880"
  },
  {
    "text": "something like a service or ambient mesh that has smart request routing or",
    "start": "1852880",
    "end": "1858639"
  },
  {
    "text": "and think about where those nodes are being spun up the compute that you're using is being spun up to support those",
    "start": "1858639",
    "end": "1865279"
  },
  {
    "text": "resources so you can utilize something like Carpenter to make sure that you're spinning up the nodes in the right a to",
    "start": "1865279",
    "end": "1871480"
  },
  {
    "text": "support those workloads as you're scaling up so the next time you have your awesome gen application you know",
    "start": "1871480",
    "end": "1878559"
  },
  {
    "text": "that it's resilient it's cost- effective and it's running really really well so get your phones out we have some",
    "start": "1878559",
    "end": "1886360"
  },
  {
    "text": "resources that you you you can explore more uh while you're grabbing your drink upstairs for sure so we have some",
    "start": "1886360",
    "end": "1893799"
  },
  {
    "text": "resources best practices guid we have a blog post that covers all the different types of ebpf Technologies at uh at the",
    "start": "1893799",
    "end": "1901240"
  },
  {
    "text": "end of last year what it is how it works um different open source projects around that we have some details on how ground",
    "start": "1901240",
    "end": "1908440"
  },
  {
    "text": "cover Works under the hood that that utilizes ebpf and we have some best practices around resiliency and",
    "start": "1908440",
    "end": "1915039"
  },
  {
    "text": "observability that me and my colleague wrote from experience with talking with",
    "start": "1915039",
    "end": "1920559"
  },
  {
    "text": "thousands of customers uh our best practices guidance on making sure that you're resilient across different",
    "start": "1920559",
    "end": "1927120"
  },
  {
    "text": "infrastructure layers and last but not least please take a survey uh I hope you",
    "start": "1927120",
    "end": "1933039"
  },
  {
    "text": "realize I gave you three minutes back uh please uh please fill out the",
    "start": "1933039",
    "end": "1939559"
  },
  {
    "text": "survey I'm going to put this up real quick and then I'm going to go back to the LA previous slide with all the links",
    "start": "1939559",
    "end": "1945279"
  },
  {
    "text": "all right cool thank you so much thank you",
    "start": "1945279",
    "end": "1950399"
  },
  {
    "text": "guys",
    "start": "1950399",
    "end": "1953399"
  }
]
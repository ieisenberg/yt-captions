[
  {
    "start": "0",
    "end": "47000"
  },
  {
    "text": "hello my name is Brian Brazzle and I'm here to give you a talk on Counting with Prometheus so to give you some",
    "start": "240",
    "end": "6000"
  },
  {
    "text": "background on who I am I'm one of the four core developers and promethus studied in Dublin live in Dublin worked",
    "start": "6000",
    "end": "11960"
  },
  {
    "text": "at Google for a while worked on many open source projects and these days I'm the founder of robust perception who",
    "start": "11960",
    "end": "18080"
  },
  {
    "text": "does Consulting and support uh for prome meus so if you're looking for that talk to me afterwards uh so preus if you aren't",
    "start": "18080",
    "end": "25640"
  },
  {
    "text": "generally aware just give you some background it's a metric based time series database for box monitoring so solving the same",
    "start": "25640",
    "end": "32800"
  },
  {
    "text": "sort of space that say graphite would be not the same s of space that elk would be it supports labels which are",
    "start": "32800",
    "end": "40079"
  },
  {
    "text": "multi-dimensional tags or key value pairs there's no ordering on them and it's got unified graphing on",
    "start": "40079",
    "end": "46840"
  },
  {
    "text": "alerting uh the architecture uh is service Discovery figures out that if",
    "start": "46840",
    "end": "52120"
  },
  {
    "start": "47000",
    "end": "47000"
  },
  {
    "text": "where everything is all your pods or whatnot from kubernetes or console then go scrapes them things like C advisor",
    "start": "52120",
    "end": "58920"
  },
  {
    "text": "Cassandra JX exporter your own applications uh whatever stores the data",
    "start": "58920",
    "end": "64119"
  },
  {
    "text": "locally has rules and alerts so it got a pretty complex query language called prom sends the alert the alert manager",
    "start": "64119",
    "end": "70360"
  },
  {
    "text": "and then grafana or other dashboarding Solutions can get the data there's something up in I think the",
    "start": "70360",
    "end": "76920"
  },
  {
    "text": "six S khz range I'm kind of hearing an",
    "start": "76920",
    "end": "81159"
  },
  {
    "text": "echo sensitive ears uh okay so go on to the actual topic we're discussing",
    "start": "82119",
    "end": "87799"
  },
  {
    "text": "counting Counting is easy we're all taught it in primary school or as we're in Germany",
    "start": "87799",
    "end": "93399"
  },
  {
    "text": "kinderen uh it's just one two three nice and simple the problem is that we're looking",
    "start": "93399",
    "end": "99680"
  },
  {
    "start": "98000",
    "end": "98000"
  },
  {
    "text": "at monitoring events or monitoring events interesting to monitoring for a metric",
    "start": "99680",
    "end": "104719"
  },
  {
    "text": "system and we want to sell how many of those have happened inside the last 5 minutes but the thing is that we're not",
    "start": "104719",
    "end": "110560"
  },
  {
    "text": "getting seeing every single event because we're a metric space system not a logs based system what we're doing is",
    "start": "110560",
    "end": "116399"
  },
  {
    "text": "sampling every now and then hey what's going on 20 seconds later hey what's",
    "start": "116399",
    "end": "121560"
  },
  {
    "text": "going on and the problem is sometimes there's that a loss because there's a network interruption or the other end is",
    "start": "121560",
    "end": "126799"
  },
  {
    "text": "slow in the middle of doing GC or something and you know we have this then",
    "start": "126799",
    "end": "131959"
  },
  {
    "text": "partial view of sampled data and how do we process then to answer the question of how many requests did I get inside",
    "start": "131959",
    "end": "138800"
  },
  {
    "text": "the last 5 minutes so I should say that there are basically two types of core metrics that",
    "start": "138800",
    "end": "145000"
  },
  {
    "start": "140000",
    "end": "140000"
  },
  {
    "text": "you are going to come across in any monitoring system there's also weirder stuff like hyper log we're going to",
    "start": "145000",
    "end": "150080"
  },
  {
    "text": "ignore those uh you have the gauge the gauge is just a snapshot of state so conically your temperature or your",
    "start": "150080",
    "end": "156160"
  },
  {
    "text": "memory usage is a snap who knows how it's actually moving but it's just telling you right now I am using 50",
    "start": "156160",
    "end": "161640"
  },
  {
    "text": "megab of ram they go up they go down H counters are the utter base type and uh",
    "start": "161640",
    "end": "168720"
  },
  {
    "text": "well we need to have a small explanation over the next 30 minutes or so of what a",
    "start": "168720",
    "end": "174159"
  },
  {
    "text": "counter is so the thing is what we're trying to track is events events are something",
    "start": "174159",
    "end": "179840"
  },
  {
    "start": "175000",
    "end": "175000"
  },
  {
    "text": "that happens right it might be HTP request it might be a function call it might be an exception it could be",
    "start": "179840",
    "end": "185400"
  },
  {
    "text": "anything an event logging system like your L stack or anything in or gray log would have every single event but not",
    "start": "185400",
    "end": "192799"
  },
  {
    "text": "too much information about them because you'll run into bandwidth issues a metric space system where up in PR graphice anything in that area you know",
    "start": "192799",
    "end": "200080"
  },
  {
    "text": "you need to aggregate those across time because we're just sampling and that's where things get",
    "start": "200080",
    "end": "205480"
  },
  {
    "text": "tricky uh so there's a few different approaches that you will see if if you look across all the different monitoring",
    "start": "205480",
    "end": "211599"
  },
  {
    "text": "systems like from iot devices uh to switches to applications and client",
    "start": "211599",
    "end": "216920"
  },
  {
    "text": "libraries uh the first and simplest one you'll see in a lot of devices uh particularly actual physical Hardware",
    "start": "216920",
    "end": "222200"
  },
  {
    "text": "devices is the resetting count it starts at zero every time there's an event of",
    "start": "222200",
    "end": "227280"
  },
  {
    "text": "Interest it increments and then whatever however the data is transferred whether it be push or pull it sends the current",
    "start": "227280",
    "end": "234360"
  },
  {
    "text": "count and resets to zero and then you know more events come in it has the data and then the data is",
    "start": "234360",
    "end": "240959"
  },
  {
    "text": "transferred it's reset to zero and it keeps on working like that nice and",
    "start": "240959",
    "end": "246560"
  },
  {
    "text": "simple and here's how this works in normal operation so this is showing 10",
    "start": "246560",
    "end": "252599"
  },
  {
    "start": "247000",
    "end": "247000"
  },
  {
    "text": "per second and it comes along and there's a big spike up to 50 per second for a 10sec period so nice simple",
    "start": "252599",
    "end": "258479"
  },
  {
    "text": "example and if you were to look at what's going on it's",
    "start": "258479",
    "end": "264120"
  },
  {
    "text": "fine uh it captures this it's a little laggy that's fine but it perfectly captures what's going on",
    "start": "264120",
    "end": "270240"
  },
  {
    "text": "and that's all fine uh the problem is though that it's not quite perfect so one thing if a transfer fails You've",
    "start": "270240",
    "end": "276720"
  },
  {
    "start": "272000",
    "end": "272000"
  },
  {
    "text": "Lost That data and the thing is though that you might have to realize that this is not a random uncorrelated event if",
    "start": "276720",
    "end": "284080"
  },
  {
    "text": "you have just had a traffic Spike there is more chance that you are going to lose that data and miss that Spike",
    "start": "284080",
    "end": "289800"
  },
  {
    "text": "because well the Network's busy so there's a higher chance of packet loss that's correlated with the instant you're actually interested",
    "start": "289800",
    "end": "295479"
  },
  {
    "text": "in uh and also if you have more than one place you're sending data that doesn't work out too well because each of them's",
    "start": "295479",
    "end": "301680"
  },
  {
    "text": "going to you know they're pulling in the data from it they're going to each see half of the information if you've got",
    "start": "301680",
    "end": "306800"
  },
  {
    "text": "true places or someone's just testing something in their workstation using a pool model on that that's not going to work out too well so this is not",
    "start": "306800",
    "end": "313400"
  },
  {
    "text": "generally a good approach except some very specific circumstances uh so if we presume that",
    "start": "313400",
    "end": "321120"
  },
  {
    "start": "319000",
    "end": "319000"
  },
  {
    "text": "we lost a single point right here at the failure we don't see it at all in our graph um this the blue line is the true",
    "start": "321120",
    "end": "328440"
  },
  {
    "text": "line and we just see yep everything was perfect it was normal there was nothing out of the ordinary",
    "start": "328440",
    "end": "334400"
  },
  {
    "text": "you'd completely miss the fact that you had a big 5x spice familiar data so it has that disadvantage the second",
    "start": "334400",
    "end": "341240"
  },
  {
    "text": "approach now this one is very popular uh so drop Wizard's meter for everyone familiar with the very popular Java",
    "start": "341240",
    "end": "347479"
  },
  {
    "text": "Library drop Wizard and it's porting into basically every other language if anyone's using go metrics in go that's",
    "start": "347479",
    "end": "353240"
  },
  {
    "text": "drop wizard basically it's a port it there's a few others in other languages as well H it works works the same way as",
    "start": "353240",
    "end": "360360"
  },
  {
    "text": "Unix load averages H so it's a bit of it's way of saying well we take the current value",
    "start": "360360",
    "end": "367479"
  },
  {
    "text": "and we take 20% of it and 80% of the old value and we add them together and the next tick we do the same thing again so",
    "start": "367479",
    "end": "374479"
  },
  {
    "text": "it takes the current value adds it in and Smooths things from history uh you do this regularly every 5",
    "start": "374479",
    "end": "380599"
  },
  {
    "text": "10 seconds or whatnot and there's a waiting Factor deciding how much you care about old how much you care about",
    "start": "380599",
    "end": "385840"
  },
  {
    "text": "new so drop for example would evaluate that every 5 seconds so that's how it",
    "start": "385840",
    "end": "392160"
  },
  {
    "text": "works H and in normal operation here's how it looks out so does that work",
    "start": "392160",
    "end": "397319"
  },
  {
    "start": "393000",
    "end": "393000"
  },
  {
    "text": "mostly yeah H data comes along it sees it and because it's nominally averaging over one minute it justs this over",
    "start": "397319",
    "end": "405440"
  },
  {
    "text": "time so it's actually reasonably accurate what expect for a one Minish average and it just exponentially",
    "start": "405440",
    "end": "412599"
  },
  {
    "text": "displays here there are problems with the exponential moving average the first is",
    "start": "412599",
    "end": "418720"
  },
  {
    "text": "that because you're King exponentially events are not considered equivalently if you're transferring data every 10",
    "start": "418720",
    "end": "424280"
  },
  {
    "text": "seconds and it's doing that tick every 5 Seconds data in the 5 Seconds proceeding your scrape matters more than the 5",
    "start": "424280",
    "end": "431080"
  },
  {
    "text": "seconds before it because of the Decay so that makes the math kind of tricky to figure out if you're not",
    "start": "431080",
    "end": "436840"
  },
  {
    "text": "sampling it the same as the tick interval and let be honest 5 seconds is quite frequent for data uh and it also",
    "start": "436840",
    "end": "443360"
  },
  {
    "text": "means because it's got built in 1 minute 5 minutes and 50 minute waiting if you want some utter rate or want to get",
    "start": "443360",
    "end": "449080"
  },
  {
    "text": "things faster or slower you can't do that and it's kind of resilient to missing a scrape like you can see that",
    "start": "449080",
    "end": "457120"
  },
  {
    "text": "it will uh you know it'll probably get here you'll kind of have the information uh but you're not going to seek for the",
    "start": "457120",
    "end": "463240"
  },
  {
    "start": "462000",
    "end": "462000"
  },
  {
    "text": "full Spike but it's not terrible but it has issues uh there's also a general issue",
    "start": "463240",
    "end": "469680"
  },
  {
    "text": "we need to talk about you're going to come across continuously in Signal processing might have also noticed in my keynote even with the diagram is",
    "start": "469680",
    "end": "476560"
  },
  {
    "text": "aliasing so depending on exactly in precise precisely where you scrape when",
    "start": "476560",
    "end": "481720"
  },
  {
    "text": "you scrape and when the data is coming from you might see artifacts and something called like the",
    "start": "481720",
    "end": "487159"
  },
  {
    "text": "the quest Channon theorem which states you can only see features that are uh",
    "start": "487159",
    "end": "492759"
  },
  {
    "text": "see half the frequency of what you're scraping at and that even then the positive po mats to extract that",
    "start": "492759",
    "end": "498840"
  },
  {
    "text": "frequency so moving a second in either direction when evaluating something can make a massive difference in what you",
    "start": "498840",
    "end": "505879"
  },
  {
    "text": "see so who here has used Grana and had a pile of there more to do with",
    "start": "505879",
    "end": "512120"
  },
  {
    "text": "sentence and had you know a graph and they hit refresh and the shape of it completely changed and then the refres",
    "start": "512120",
    "end": "518839"
  },
  {
    "text": "it changed again that's all aliasing effects because basically we scraping frequently enough to see the true nature of the graph this happens all the time H",
    "start": "518839",
    "end": "527120"
  },
  {
    "text": "and it's just the fact of life and now you probably shouldn't scrape more you should switch to logs at that point because trying to do that sort of",
    "start": "527120",
    "end": "533320"
  },
  {
    "text": "analysis of metrics you know how fast do you need to scrape once every millisecond nanc microsc you know switch",
    "start": "533320",
    "end": "539760"
  },
  {
    "text": "to logs you just need to be aware this is a thing that happens uh and this also brings me to",
    "start": "539760",
    "end": "545959"
  },
  {
    "text": "something else uh a confusion that sometimes come up from use it's like why don't you work like graphite summarized",
    "start": "545959",
    "end": "552160"
  },
  {
    "text": "function it gives me the right answer turns out it doesn't it gives you",
    "start": "552160",
    "end": "557399"
  },
  {
    "text": "an answer which would appear to be correct via a naive analysis so what it",
    "start": "557399",
    "end": "562920"
  },
  {
    "text": "does is let's say summarize in its simplest form say right how many requests did I have inside the last hour",
    "start": "562920",
    "end": "568519"
  },
  {
    "text": "and it'll go and to look at data points in that last hour and add them up because they've already been converted to",
    "start": "568519",
    "end": "574120"
  },
  {
    "text": "gauges um and there it is the problem is that if the data points at 1302 and",
    "start": "574120",
    "end": "579720"
  },
  {
    "text": "we're aligned on the hour that 1302 point and for 50 minutes includes 2",
    "start": "579720",
    "end": "584920"
  },
  {
    "text": "minutes from the hour and 13 minutes from outside the hour so it's not",
    "start": "584920",
    "end": "590120"
  },
  {
    "start": "588000",
    "end": "588000"
  },
  {
    "text": "accurate because you're including all this data and you're missing all this data so you're getting an aliasing issue",
    "start": "590120",
    "end": "595800"
  },
  {
    "text": "there so summarize is not accurate because the data is is extremely unlikely to be aligned and you can",
    "start": "595800",
    "end": "601600"
  },
  {
    "text": "imagine normally you're going to have things staggered because you want to spread load around so it's always going to be inaccurate uh this is not just me",
    "start": "601600",
    "end": "608480"
  },
  {
    "text": "riffing on the summarized function it is not possible for a metric space system to get this right Prometheus also",
    "start": "608480",
    "end": "615079"
  },
  {
    "text": "produces a wrong answer it's merely a different wrong answer I believe it's a better wrong answer but just be aware",
    "start": "615079",
    "end": "621880"
  },
  {
    "text": "these there's all trade-offs be made here like this is not an unreasonable way to do it in graphite but because of this issue you're going to you know the",
    "start": "621880",
    "end": "628560"
  },
  {
    "text": "answer is just not right if you want an accurate answer use",
    "start": "628560",
    "end": "633040"
  },
  {
    "start": "633000",
    "end": "633000"
  },
  {
    "text": "logs and but the thing is both the previous Solutions are kind of designed with the belief that the monitoring",
    "start": "633839",
    "end": "639160"
  },
  {
    "text": "system on the other end is relatively dumb right we've got something if you've just got some graph light which doesn't",
    "start": "639160",
    "end": "645360"
  },
  {
    "text": "have oh it's getting better over time doesn't have that powerful query language uh or something like open CS2",
    "start": "645360",
    "end": "650440"
  },
  {
    "text": "which only very recently started to get a query language uh only like in the release like two months ago it actually",
    "start": "650440",
    "end": "655880"
  },
  {
    "text": "started to get one if you've got something that's basically just a dumb data store you have to do all your smarts inside the client whatever that",
    "start": "655880",
    "end": "662839"
  },
  {
    "text": "is if however you control both the client and the server and can puts your smarts in the server uh you know you can",
    "start": "662839",
    "end": "670519"
  },
  {
    "text": "do some more interesting things because you know like if you have a system where it's only a dumb database",
    "start": "670519",
    "end": "677760"
  },
  {
    "text": "having some inaccuracies is better than having nothing right that's just engineering we have to make trade-offs but we can do something a little better",
    "start": "677760",
    "end": "684360"
  },
  {
    "text": "so the approach the third approach is the approach taken by promethus counters uh and like the resetting",
    "start": "684360",
    "end": "690320"
  },
  {
    "text": "counters we have a counter that starts at zero and is incremented in the exact same way and it's regularly transferred",
    "start": "690320",
    "end": "696920"
  },
  {
    "text": "but it is never reset it's only ever reset when the process restarts H and then the rate function",
    "start": "696920",
    "end": "702800"
  },
  {
    "text": "takes us in and calculates how quickly it increases or decreases over time oh increases only increases",
    "start": "702800",
    "end": "709560"
  },
  {
    "text": "counters don't decrease uh so a normal operation we'll see now this is the correct answer",
    "start": "709560",
    "end": "715399"
  },
  {
    "text": "mathematically because this examp these examples purposely don't have aliasing because that's you know another problem",
    "start": "715399",
    "end": "721600"
  },
  {
    "text": "but this is the 100% correct answer of what one minute average looks like so that's exactly what we want that",
    "start": "721600",
    "end": "727279"
  },
  {
    "text": "is the correct mathematical answer because everything's aligned perfectly um so it's resilient to fail",
    "start": "727279",
    "end": "733519"
  },
  {
    "text": "transfers you lose resolution not data so that's good you can still see that hey there's more requests than usual you",
    "start": "733519",
    "end": "739399"
  },
  {
    "text": "just can't tell exactly when they happened multiple places can pull data from it or push thata whatever no",
    "start": "739399",
    "end": "745160"
  },
  {
    "text": "problems and you can choose whatever time you want to average that you want",
    "start": "745160",
    "end": "750760"
  },
  {
    "text": "data is considered uniformly it doesn't matter when it was like the first 5 seconds or the last 5 Seconds of the 10- minute rate it's all considered",
    "start": "750760",
    "end": "756600"
  },
  {
    "text": "uniformly and it's extremely Implement easy to implement on the plan side because you just have a counter that",
    "start": "756600",
    "end": "762000"
  },
  {
    "text": "goes up you you know need some new texts and so on but that's rather easy to",
    "start": "762000",
    "end": "767440"
  },
  {
    "text": "implement now if there is a failed transfer let's say for whatever reason that this transfer around here fails you",
    "start": "767440",
    "end": "774079"
  },
  {
    "text": "just see the data you know 10 seconds later so that's you know pretty good we",
    "start": "774079",
    "end": "779120"
  },
  {
    "text": "still see that hey there was an increase on average over this time period we just see it slightly later because you know",
    "start": "779120",
    "end": "785320"
  },
  {
    "text": "the network didn't like that 5x Spike so that's going fairly well so not perfect",
    "start": "785320",
    "end": "790639"
  },
  {
    "text": "but still pretty good um so then looking it these ways to talk about the rate function itself",
    "start": "790639",
    "end": "797320"
  },
  {
    "start": "792000",
    "end": "792000"
  },
  {
    "text": "because some people are confused about some of the behaviors of the rate function because it turns out the internals are complicated and it took us",
    "start": "797320",
    "end": "804360"
  },
  {
    "text": "a while I think Born did a lot of work on this as did I uh because there the real world kicks in processes restart it",
    "start": "804360",
    "end": "812760"
  },
  {
    "text": "turns out yeah scrapes get missed time period as I mentioned because of aliasing they rarely align perfectly and",
    "start": "812760",
    "end": "820600"
  },
  {
    "text": "uh you know things start and stop maybe your project goes away or you deploy a new version all these things happen and",
    "start": "820600",
    "end": "826920"
  },
  {
    "text": "we need to deal with them in a way that is largely correct or at least good enough because we can't do it perfect",
    "start": "826920",
    "end": "832720"
  },
  {
    "text": "because this is all metrics if you want perfect you need logs and to ignore general",
    "start": "832720",
    "end": "837759"
  },
  {
    "text": "relativity different topic so the first problem we have is counter resets right",
    "start": "837759",
    "end": "844079"
  },
  {
    "start": "838000",
    "end": "838000"
  },
  {
    "text": "counters can be reset to zero and basically just normally only ever happens when a process restarts so you imagine it's there still sitting in the",
    "start": "844079",
    "end": "849680"
  },
  {
    "text": "same port same Target restarts it's now zero because who wants to have to maintain straight across runs right so",
    "start": "849680",
    "end": "856680"
  },
  {
    "text": "because we know the counters only every increase what we can do is say hey that counter just went down therefore it's",
    "start": "856680",
    "end": "862560"
  },
  {
    "text": "reset so if we see nor 10 to 5 well we know that total well went from 10 to",
    "start": "862560",
    "end": "868880"
  },
  {
    "text": "five so was a counter reset there so we had 10 so went from all to 10 so it's a 10 of increase went the 10 to five so Le",
    "start": "868880",
    "end": "874720"
  },
  {
    "text": "five of increase so 15 total and that's what we see by contrast if you're looking at graph F influx TB they have",
    "start": "874720",
    "end": "881759"
  },
  {
    "text": "the closest thing they have to the rate function is the non- negative derivative function and what it would do is it",
    "start": "881759",
    "end": "887320"
  },
  {
    "text": "would actually ignore that drop and just report your increase of 10 so we get a slightly better answer",
    "start": "887320",
    "end": "894480"
  },
  {
    "text": "here H the second question of Miss scrapes well if we miss the scrape it's",
    "start": "894480",
    "end": "899519"
  },
  {
    "start": "895000",
    "end": "895000"
  },
  {
    "text": "fine we've still got the data points around it and everything just works but if what happens just at the",
    "start": "899519",
    "end": "905199"
  },
  {
    "text": "edge of the time period we're considering that's more complicated um because it's very rare",
    "start": "905199",
    "end": "913519"
  },
  {
    "start": "908000",
    "end": "908000"
  },
  {
    "text": "that the race will align perfectly when the scrapes are especially once you have more than one Target and the fact that",
    "start": "913519",
    "end": "919120"
  },
  {
    "text": "things are inmediately staggered on 1 millisecond intervals based on the hash of the target labels so they're going to",
    "start": "919120",
    "end": "924920"
  },
  {
    "text": "be spread all over that 5 minutes pretty evenly um and our time stop millisecond",
    "start": "924920",
    "end": "931079"
  },
  {
    "text": "resolution so you know have fun with that so the thing is we if information if data points are near the edge we need",
    "start": "931079",
    "end": "936440"
  },
  {
    "text": "to extrapolate out to get the right answers and this is where one of the big",
    "start": "936440",
    "end": "941839"
  },
  {
    "text": "confusions around race happens talking about increase which is rates broader so race returns per second results increase",
    "start": "941839",
    "end": "948920"
  },
  {
    "text": "is just syntactic sugar around Dash so if you have rate 5m increase is the same",
    "start": "948920",
    "end": "954800"
  },
  {
    "text": "as saying rate 5m multiply by 300 that's only tactic sugar because people keep on",
    "start": "954800",
    "end": "960959"
  },
  {
    "text": "asking us for this anyway uh so let's say we have data and at T equals 1 the",
    "start": "960959",
    "end": "966360"
  },
  {
    "text": "data is 10 T = 6 is 12 and T = 11 is 13 so this has clearly gone up by three",
    "start": "966360",
    "end": "972759"
  },
  {
    "text": "over this time period and we want to look over from tal 0 to tal 15 and see",
    "start": "972759",
    "end": "979880"
  },
  {
    "text": "what the rate is per second now you could look at this and say hey over 10 seconds it's gone up by three therefore",
    "start": "979880",
    "end": "985800"
  },
  {
    "text": "hey it's said three over 10 seconds and the increase is three however if you're looking over the 15 seconds it's really",
    "start": "985800",
    "end": "991519"
  },
  {
    "text": "over 4.5 so even though we've got all integers here because we've extended from the 10 seconds that we have in data",
    "start": "991519",
    "end": "998000"
  },
  {
    "text": "to the 15 seconds we need to add an extra 5 Seconds Worth to data which is 50% more and we end up with",
    "start": "998000",
    "end": "1004800"
  },
  {
    "text": "4.5 it is the correct result on average because on average if you look at it at different periods it is 4.5 it's just",
    "start": "1004800",
    "end": "1011199"
  },
  {
    "text": "because you T hey it's three therefore it's an integer no it's a floating Point number and that's how integers end up as",
    "start": "1011199",
    "end": "1016600"
  },
  {
    "text": "floats I have a diagram for this one so your data points are at 1 and 11 and you",
    "start": "1016600",
    "end": "1022240"
  },
  {
    "text": "got the other data point here it's an average so that's fine and if you look at literally you just say hey that's three but the time period is further so",
    "start": "1022240",
    "end": "1029280"
  },
  {
    "text": "you have to extrapolate back to 9.7 and forward to 14.2 effectively and we end",
    "start": "1029280",
    "end": "1034520"
  },
  {
    "text": "up then with the 4.5 across that rather than the tree that would be here does that make sense what's going on yeah",
    "start": "1034520",
    "end": "1042000"
  },
  {
    "text": "this is why that answer happens and as well",
    "start": "1042000",
    "end": "1049559"
  },
  {
    "text": "uh time series are created and destroyed if we always extrapolate it out to the edge the problem is if a Time series",
    "start": "1049559",
    "end": "1055600"
  },
  {
    "text": "let's say we're doing an increase over an hour and a Time TI only exists for 5 minutes we' way overestimate we always",
    "start": "1055600",
    "end": "1061360"
  },
  {
    "text": "extrapolated at the edge which would be a problem so we need to detect that so we basically get all the points see how",
    "start": "1061360",
    "end": "1067559"
  },
  {
    "text": "far they are apart from each other average that because that's good enough and what we do is if the first point is",
    "start": "1067559",
    "end": "1075000"
  },
  {
    "text": "within one interval plus some slack we'll extrapolate and on the other end",
    "start": "1075000",
    "end": "1080480"
  },
  {
    "text": "if same thing if the end is within 110% of the interval we'll extrapolate if",
    "start": "1080480",
    "end": "1085600"
  },
  {
    "text": "it's not it means the time series we think it started or stopped and we'll just extrapolate 50% of the interval the",
    "start": "1085600",
    "end": "1091799"
  },
  {
    "text": "principle is if a Time series disappeared well it could have disappeared the process could have died",
    "start": "1091799",
    "end": "1097799"
  },
  {
    "text": "any time from the scrape and when the next scrape should have been on average it disappears in the middle so an",
    "start": "1097799",
    "end": "1104280"
  },
  {
    "text": "average will get the same results I we do the same to start with something appearing and one other thing we know counters",
    "start": "1104280",
    "end": "1111120"
  },
  {
    "text": "can't go negative because they start at zero and only ever increase so we don't extrapolate below",
    "start": "1111120",
    "end": "1116280"
  },
  {
    "text": "zero so here are all the examples so this is a diagram this took quite while to",
    "start": "1116280",
    "end": "1121679"
  },
  {
    "start": "1117000",
    "end": "1117000"
  },
  {
    "text": "produce looks very silly if you don't know what's going on doesn't it so we'll take this is the simplest example here",
    "start": "1121679",
    "end": "1128919"
  },
  {
    "text": "this fell up a big long one and what we're doing is that this it starts",
    "start": "1128919",
    "end": "1134159"
  },
  {
    "text": "happens to start perfectly aligned so it's simple but at the end because the next data point would be here outside",
    "start": "1134159",
    "end": "1139360"
  },
  {
    "text": "the window we extrapolate forward and we calculate it based on that first point and that last",
    "start": "1139360",
    "end": "1145679"
  },
  {
    "text": "point with this one here going back one uh at the start well we don't extrapolate below zero but it is within",
    "start": "1145679",
    "end": "1152919"
  },
  {
    "text": "you know an interval so we extrapolate back to there and at the end well it's not close enough cuz the next point",
    "start": "1152919",
    "end": "1159159"
  },
  {
    "text": "would be there and that's within the window cuz you know it's here so we just extrapolate 50% and then this one here",
    "start": "1159159",
    "end": "1166400"
  },
  {
    "text": "we extrapolate at the end and once again 50% because we're saying on average it probably disappeared halfway",
    "start": "1166400",
    "end": "1173120"
  },
  {
    "text": "true the slides will be online later I always put my slides online",
    "start": "1173120",
    "end": "1179080"
  },
  {
    "text": "later because yeah you need this text but this is what's going on this is just explaining all the cases of how we try",
    "start": "1179080",
    "end": "1185080"
  },
  {
    "text": "to get this as right as possible so we're correct mostly on",
    "start": "1185080",
    "end": "1190440"
  },
  {
    "text": "average H and there is another issue is that um sometimes happens with just time",
    "start": "1192320",
    "end": "1198480"
  },
  {
    "text": "series that don't always exist so we kind of presume that we'll see the time series it we'll see the zero we'll see",
    "start": "1198480",
    "end": "1205400"
  },
  {
    "text": "everything increasing from there the problem is sometimes time series spring forth with a value of",
    "start": "1205400",
    "end": "1210960"
  },
  {
    "text": "one and then keep that one forever and if we look at that",
    "start": "1210960",
    "end": "1216280"
  },
  {
    "text": "mathematically well it's okay what's the increase in that well there isn't an increase it's flat but if someone has just created",
    "start": "1216280",
    "end": "1223039"
  },
  {
    "text": "this this series and wants to say yes I want to track that one CU that means an error I care about well we have no idea",
    "start": "1223039",
    "end": "1230000"
  },
  {
    "text": "when that increase from 0 to one happened CU from a Time series databas standpoint for all we know this",
    "start": "1230000",
    "end": "1235679"
  },
  {
    "text": "application has been running for years that increase happened a decade ago and we just never saw it because the perties",
    "start": "1235679",
    "end": "1241559"
  },
  {
    "text": "has only turned up so we can't assume anything we don't know uh and the time",
    "start": "1241559",
    "end": "1246640"
  },
  {
    "text": "series database wouldn't have this information all it sees is a single time series with no context because that's how it works um so the thing is that we",
    "start": "1246640",
    "end": "1255840"
  },
  {
    "text": "are generally in predus we're not trying to catch 100% of everything so our answer is well we'll see the next increase so you plan to have you know a",
    "start": "1255840",
    "end": "1263679"
  },
  {
    "text": "different solution if you're trying to get 100% reliability because predus makes several trade-offs around",
    "start": "1263679",
    "end": "1269279"
  },
  {
    "text": "availability uh versus precision and accuracy uh so if you do care about this",
    "start": "1269279",
    "end": "1274720"
  },
  {
    "text": "logs logs are more accurate especially if you get the type that are actually you know CP or make sure you're uh",
    "start": "1274720",
    "end": "1282400"
  },
  {
    "text": "calendars are initialized when your process starts to zero so we'll see that cuz then the race is just down to that",
    "start": "1282400",
    "end": "1288440"
  },
  {
    "text": "scrape or just alert on the fact that it's one if you actually care about that",
    "start": "1288440",
    "end": "1293919"
  },
  {
    "text": "because really if you're indicating hey I'm in an error State that's more engaged than the counter",
    "start": "1293919",
    "end": "1299640"
  },
  {
    "text": "thing H there's another problem uh and this is a general problem you'll see across most monitoring systems and not",
    "start": "1299640",
    "end": "1305960"
  },
  {
    "start": "1300000",
    "end": "1300000"
  },
  {
    "text": "all scientific ones tend to approach this differently uh there's lag you'll notice in all the diagrams we had of",
    "start": "1305960",
    "end": "1311880"
  },
  {
    "text": "what was going on that there was lag of at least a scrape interval of seeing the spike because all of them are looking",
    "start": "1311880",
    "end": "1318600"
  },
  {
    "text": "back in time right so if I've got a 5 minute rate at a given time it's really a 5 minute average of the last 5 minutes",
    "start": "1318600",
    "end": "1325440"
  },
  {
    "text": "it's not centered on now uh similarly with resetting counters will have the exact same issue explan",
    "start": "1325440",
    "end": "1331279"
  },
  {
    "text": "moving averages is much more complicated to explain but the exact same thing is happening it's always a lagging",
    "start": "1331279",
    "end": "1338200"
  },
  {
    "text": "View and that's the way it is one of the reasons for this is that if we we're looking at Future data that suddenly",
    "start": "1338200",
    "end": "1343640"
  },
  {
    "text": "becomes very complicated because it means if I was to evaluate a query and then new data comes in the",
    "start": "1343640",
    "end": "1348960"
  },
  {
    "text": "value of the query changes that will be very hard to deal with you know in your head so one other thing to keep in mind",
    "start": "1348960",
    "end": "1356559"
  },
  {
    "text": "is that rates are only really comparable if they're the same period like if you're comparing a 5-minute rate and a 10-minute rate and trying to divide them",
    "start": "1356559",
    "end": "1363240"
  },
  {
    "text": "that doesn't make sense statistically so try to keep to one rate in your entire predus you'll tag me at the worst I ever",
    "start": "1363240",
    "end": "1370799"
  },
  {
    "text": "came across was was it 17 or 23 or something like that rates inside a",
    "start": "1370799",
    "end": "1377360"
  },
  {
    "text": "single file yeah because someone had misunderstood how things work single rate inside an entire Prometheus unless you know what",
    "start": "1377360",
    "end": "1383640"
  },
  {
    "text": "you're doing maybe two two might be okay in c special circumstances as long as you never compareed",
    "start": "1383640",
    "end": "1389159"
  },
  {
    "text": "them um so we looked at how predus does things there are a few more complications in the client because yes",
    "start": "1389159",
    "end": "1395679"
  },
  {
    "start": "1390000",
    "end": "1390000"
  },
  {
    "text": "it's a counter it goes up that sounds easy to implement uh but you need to worry about the real world which",
    "start": "1395679",
    "end": "1401480"
  },
  {
    "text": "includes things like treading because treading is a Ting and has been for some decades concurrency handling what you",
    "start": "1401480",
    "end": "1407520"
  },
  {
    "text": "have available to you varies by language mutexes pretty much every language has mutexes but they're also the slowest so",
    "start": "1407520",
    "end": "1414600"
  },
  {
    "text": "you're normally talking uh what about 100 Nan for a mutex except python which is 100 microsc",
    "start": "1414600",
    "end": "1421840"
  },
  {
    "text": "or in fact was it 500 micros it's ridiculously slow in Pyon for reasons I'm not aware of uh but then there's",
    "start": "1421840",
    "end": "1428320"
  },
  {
    "text": "atomics atomics tend to be around the uh 105 NC range and then the best one of",
    "start": "1428320",
    "end": "1435520"
  },
  {
    "text": "all is you can actually have per processor values so so you don't have to do cache coherency across the processors uh so Java actually",
    "start": "1435520",
    "end": "1442080"
  },
  {
    "text": "approximates this so the Java client actually handles concery the best uh but atomics are perfectly fine for average",
    "start": "1442080",
    "end": "1447400"
  },
  {
    "text": "use and some languages only have mutexes like the go client is using atomics the Ruby client doesn't actually have any",
    "start": "1447400",
    "end": "1453640"
  },
  {
    "text": "concurrency handling because Ruby uh because it it's presumed it's only single treaded so why would you",
    "start": "1453640",
    "end": "1459480"
  },
  {
    "text": "need it uh yeah so by comparison if you look at how the drop wizard meter it has",
    "start": "1459480",
    "end": "1466279"
  },
  {
    "text": "to increment four numbers so that's actually using is using atomics or the same double add we have in the Java T",
    "start": "1466279",
    "end": "1471840"
  },
  {
    "text": "anyway the increment is quite efficient but there's four of them because it has to do the total and it's got the 1",
    "start": "1471840",
    "end": "1477480"
  },
  {
    "text": "minute 5 minute and 15 minute and it also has to do the Decay logic as well every 5 seconds so it works out the drop",
    "start": "1477480",
    "end": "1483840"
  },
  {
    "text": "wizard meter if you do the benchmarks it's about six times slower than prus counter just to do your instrumentation",
    "start": "1483840",
    "end": "1491000"
  },
  {
    "text": "now this doesn't matter if you're doing it like 100 times a second because who cares about an extra what 80 or or 100",
    "start": "1491000",
    "end": "1498159"
  },
  {
    "text": "NS a few times a second doesn't matter but if you're starting to really instrument your code in 100,000 or a",
    "start": "1498159",
    "end": "1504720"
  },
  {
    "text": "million instrumentation events a second which is normal like it's not unusual for a single request to pass through like 100",
    "start": "1504720",
    "end": "1511559"
  },
  {
    "text": "counters when things well instrumented that can be more of a concern I will mention though the drop wizard counter",
    "start": "1511559",
    "end": "1518120"
  },
  {
    "text": "which is actually a gauge because it can go down H is as fast as a prus counter uh because it's using the exact same",
    "start": "1518120",
    "end": "1524320"
  },
  {
    "text": "double add that the Java client uses so that one's fine it's just the meter which is doing all this exponential",
    "start": "1524320",
    "end": "1530200"
  },
  {
    "text": "decaying windows that actually has performance implications H there is another",
    "start": "1530200",
    "end": "1535760"
  },
  {
    "start": "1535000",
    "end": "1535000"
  },
  {
    "text": "implication which I wrote recently in the blog post uh PR labels in the child so normally if you are using the python",
    "start": "1535760",
    "end": "1541960"
  },
  {
    "text": "client or one of the others you'll notice it's my metric specify the labels and then increment",
    "start": "1541960",
    "end": "1547440"
  },
  {
    "text": "it right it's not spec you don't specify the labels inside the increment call",
    "start": "1547440",
    "end": "1552600"
  },
  {
    "text": "here uh and this is because we have this thing returns what's called a child cross the languages and it's basically a",
    "start": "1552600",
    "end": "1559039"
  },
  {
    "text": "map here a concurrent hash map if you're Us in Java and that map can actually be",
    "start": "1559039",
    "end": "1564200"
  },
  {
    "text": "expensive so it's takes about 100 nanc or so on Java so if you think about that",
    "start": "1564200",
    "end": "1570919"
  },
  {
    "text": "that increment that Atomic increment is taking between 10 and 20 NS depending on how contended it is and then you add 100",
    "start": "1570919",
    "end": "1577399"
  },
  {
    "text": "Nan just to find the thing you need to increment that's pretty serious like that's makes things six times slower",
    "start": "1577399",
    "end": "1583240"
  },
  {
    "text": "that's bad so instead if you can keep a pointer to this child that's much faster and this is why we do it this way so",
    "start": "1583240",
    "end": "1589279"
  },
  {
    "text": "someone if they know in advance what label values they have which is a fairly common thing uh you can then just well",
    "start": "1589279",
    "end": "1596760"
  },
  {
    "text": "cash that as a pointer directly to the child and increment it and that's much faster so if you are doing anything like",
    "start": "1596760",
    "end": "1602480"
  },
  {
    "text": "that that helps can't always do it uh but that's handy but if you're thinking hey I'll cash it inside a concurrent",
    "start": "1602480",
    "end": "1609159"
  },
  {
    "text": "hashmap there's no point in doing that because this already is a concurrent hashmap you can't get more more faster",
    "start": "1609159",
    "end": "1615799"
  },
  {
    "text": "than that at least in Java and similarly the other languages uh the other there's a related anti pattern you see sometimes",
    "start": "1615799",
    "end": "1621080"
  },
  {
    "text": "where people will create a map from metric names to metric objects don't do that you know the name of your metric",
    "start": "1621080",
    "end": "1626640"
  },
  {
    "text": "just keep a pointer because otherwise well you're once again are going to have this",
    "start": "1626640",
    "end": "1633360"
  },
  {
    "text": "hit uh there are some just other best practices then mention",
    "start": "1633360",
    "end": "1638440"
  },
  {
    "start": "1634000",
    "end": "1634000"
  },
  {
    "text": "around around uh counters uh use seconds for timing seconds are the standard",
    "start": "1638440",
    "end": "1644520"
  },
  {
    "text": "everyone uses seconds right and then put that name inside metric and there are other systems uh you can see it",
    "start": "1644520",
    "end": "1650720"
  },
  {
    "text": "sometimes with other things that they only support integers inside the database so the developer has to choose",
    "start": "1650720",
    "end": "1656279"
  },
  {
    "text": "well I'm going to use nanc microsc milliseconds seconds minutes hours days",
    "start": "1656279",
    "end": "1661840"
  },
  {
    "text": "I've seen all of these instrumented sometimes inside the same binary like there was a time when perus itself was",
    "start": "1661840",
    "end": "1668840"
  },
  {
    "text": "using four different time units in its Exposition this is prous no we might have be better than that this is silly",
    "start": "1668840",
    "end": "1676240"
  },
  {
    "text": "just use seconds we're using FL Point numbers so it'll automatically handle the exponent because the thing is that",
    "start": "1676240",
    "end": "1681880"
  },
  {
    "text": "what unit you just have in your graphs is the display level problem that should be handled up with graan it shouldn't be the concern of",
    "start": "1681880",
    "end": "1688799"
  },
  {
    "text": "someone who's actually writing the code it should just be right use seconds graan will take care of it that's the way to approach this in the same way",
    "start": "1688799",
    "end": "1696000"
  },
  {
    "text": "that you don't choose your time zones down in your code don't choose your units that's the problem for a display",
    "start": "1696000",
    "end": "1701640"
  },
  {
    "text": "layer solve on the display layer similarly increase function it's handy for display but in your rules and your",
    "start": "1701640",
    "end": "1707480"
  },
  {
    "text": "Exposition and so on use R for recording rules just so once again it's per second nice consistent simple and as I",
    "start": "1707480",
    "end": "1713720"
  },
  {
    "text": "mentioned increases only syntactic sugar for rate it's exact same um there's no extra",
    "start": "1713720",
    "end": "1720679"
  },
  {
    "text": "logic in there it's just a multiplication to make your life a little easier there is one other rate function",
    "start": "1720679",
    "end": "1726159"
  },
  {
    "start": "1724000",
    "end": "1724000"
  },
  {
    "text": "called irate it's not an angry function although I think that's mentioned in the",
    "start": "1726159",
    "end": "1731200"
  },
  {
    "text": "docs in fact I need to clean up the docks cuz that joke's getting a little stale H all it does is looks at last two",
    "start": "1731200",
    "end": "1737960"
  },
  {
    "text": "points in the range right and just says how fast they're increasing so it's extremely responsive you notice with r",
    "start": "1737960",
    "end": "1743919"
  },
  {
    "text": "it's a one minute average and the same the explanation many moving windows are kind of a one minute average but that",
    "start": "1743919",
    "end": "1749279"
  },
  {
    "text": "means any Spike or so on is averaged over a minute uh which can be handy if that is very spiky because it turns out",
    "start": "1749279",
    "end": "1755440"
  },
  {
    "text": "humans are really not good at dealing with spiky data so you want to average it a bit uh but if uh so there is IR",
    "start": "1755440",
    "end": "1762919"
  },
  {
    "text": "rate if you want to see what's really going on H because it'll give you very update data of exactly what's going on so if",
    "start": "1762919",
    "end": "1768279"
  },
  {
    "text": "you're seen lots of very brief spikes or microbursts and so on you are going to want to have IR to see it it's also",
    "start": "1768279",
    "end": "1775000"
  },
  {
    "text": "handy if you don't actually know what the scrape interval is but you need to be careful and because that's one of the",
    "start": "1775000",
    "end": "1780039"
  },
  {
    "text": "reasons why it's used in all the console templates in prous we don't know what scrape interval we've used you're probably using the default of 15 or",
    "start": "1780039",
    "end": "1785600"
  },
  {
    "text": "maybe using a minute or maybe it cut it down to a second because you know you're like hammering your servers H so it's",
    "start": "1785600",
    "end": "1791000"
  },
  {
    "text": "handy there but you need to be careful you're not missing data so iate itself in the perfect case like you'll see this",
    "start": "1791000",
    "end": "1797000"
  },
  {
    "text": "works exactly same and gives us that same perfect answer we solve the setting counc which is good I know no the lag",
    "start": "1797000",
    "end": "1804399"
  },
  {
    "text": "though as I mentioned happens as well when it failed transfer like let's say this transfer here fails we missed this",
    "start": "1804399",
    "end": "1810679"
  },
  {
    "start": "1806000",
    "end": "1806000"
  },
  {
    "text": "H we'll still see a spike it'll just be not quite as big so you're still seeing the spike it's resilient it's not the",
    "start": "1810679",
    "end": "1817200"
  },
  {
    "text": "perfect answer but we have reasonably gracefully handled a failed scrape that happened because well there was a",
    "start": "1817200",
    "end": "1823600"
  },
  {
    "text": "overload going on so this brings us to question you to be careful about missing",
    "start": "1823600",
    "end": "1829480"
  },
  {
    "start": "1825000",
    "end": "1825000"
  },
  {
    "text": "data the query range HP endpoint so that's what graan is using it basically says hey here's a start here's an end",
    "start": "1829480",
    "end": "1836480"
  },
  {
    "text": "evaluate this PR expression at each of those data points it's just a hand it's a slightly optimized way of saying run",
    "start": "1836480",
    "end": "1844320"
  },
  {
    "text": "this query many many times 5 Seconds Apart or 10 seconds apart or 20 seconds apart but if you have a 10-minute step",
    "start": "1844320",
    "end": "1851360"
  },
  {
    "text": "like you're saying is Right run this over the last week every 10 minutes with a 5 minute rate you're Miss half dat",
    "start": "1851360",
    "end": "1858480"
  },
  {
    "text": "each of those requests is only looking at 5 minutes of data and other 5 minutes before it's missing so you need to be",
    "start": "1858480",
    "end": "1864000"
  },
  {
    "text": "careful so you need to make sure your rate range is generally at least the size of your step and in IRAs you want",
    "start": "1864000",
    "end": "1870600"
  },
  {
    "text": "your step to be uh no larger than your sample resolution so it'll always have those two points even if there's a fail transfer so just keep that in mind",
    "start": "1870600",
    "end": "1877519"
  },
  {
    "text": "otherwise you're going to be missing data and not getting a true average because you're missing half of",
    "start": "1877519",
    "end": "1883399"
  },
  {
    "text": "it uh you'll also just mention the compound types so got a summary how do",
    "start": "1883399",
    "end": "1888440"
  },
  {
    "start": "1884000",
    "end": "1884000"
  },
  {
    "text": "you track latency in perus two counters yay uh you just count the total requests",
    "start": "1888440",
    "end": "1893880"
  },
  {
    "text": "you count the total latency get the rates of those divide and now you have average latency over",
    "start": "1893880",
    "end": "1899159"
  },
  {
    "text": "any time period you like okay it's the summary is basically just a convenient API for doing this",
    "start": "1899159",
    "end": "1905440"
  },
  {
    "text": "because it's such a common use case uh there's also quantiles but uh quantiles",
    "start": "1905440",
    "end": "1910960"
  },
  {
    "text": "compa in the client are not aggregable and they tend to be slow because you need M texes and lots of math",
    "start": "1910960",
    "end": "1917799"
  },
  {
    "text": "it can have some uses you know it varies the other one is the histogram it also has the same count and sum that summary",
    "start": "1917799",
    "end": "1923159"
  },
  {
    "start": "1920000",
    "end": "1920000"
  },
  {
    "text": "has but really is for calculating quants in perus because it all it does is has",
    "start": "1923159",
    "end": "1928399"
  },
  {
    "text": "counters which are buckets uh which indicates the histogram you take the reach of all of those and",
    "start": "1928399",
    "end": "1934399"
  },
  {
    "text": "which you can aggregate up then and then you figure out okay so where's the 9 percenti here uh so that works fine but beware of",
    "start": "1934399",
    "end": "1942200"
  },
  {
    "text": "cardinality explosion because there's a general rule in promethus you probably want to keep your cardinality below 10 on any instrumentation and a histogram",
    "start": "1942200",
    "end": "1949360"
  },
  {
    "text": "out of the box has the cardinality of 10 so you need to be careful General cardinality there's maybe literally for",
    "start": "1949360",
    "end": "1956559"
  },
  {
    "text": "every prus you're allowed a handful of exceptions so Choose Wisely where you're going to be because sometimes hey if",
    "start": "1956559",
    "end": "1962000"
  },
  {
    "text": "you've got 12 types of logs you aggregate well there's your cardinality that's life but you should be very careful with instrumentation",
    "start": "1962000",
    "end": "1967760"
  },
  {
    "text": "particularly in libraries not to blow out how much performance per can deal with because monitoring is not free",
    "start": "1967760",
    "end": "1974360"
  },
  {
    "text": "monitoring costs money and time and resources and humans to have to fix you know and go and Rune everything so uh",
    "start": "1974360",
    "end": "1980919"
  },
  {
    "text": "summaries without quantiles are basically free as soon as you're stting adding labels or quantiles or histograms",
    "start": "1980919",
    "end": "1986240"
  },
  {
    "text": "things start to get more expensive just because things are multiplying out and so that's the main talk the",
    "start": "1986240",
    "end": "1991960"
  },
  {
    "start": "1990000",
    "end": "1990000"
  },
  {
    "text": "resources itself you have the previous website user Dev main list the source code is in functions. go and there also",
    "start": "1991960",
    "end": "1998320"
  },
  {
    "text": "my own blog which has some posts around this stuff in promethus generally cool so any questions we have H we have 15",
    "start": "1998320",
    "end": "2005919"
  },
  {
    "text": "minutes for questions or 14 minutes",
    "start": "2005919",
    "end": "2011679"
  },
  {
    "text": "questions or are you still just ingesting all that everyone Now understand why you can",
    "start": "2011679",
    "end": "2017279"
  },
  {
    "text": "get non- integral answers with integral input the rate yeah it's right on",
    "start": "2017279",
    "end": "2024559"
  },
  {
    "text": "average so any questions at all hand up",
    "start": "2024559",
    "end": "2030880"
  },
  {
    "text": "see no one really no questions oh there's a",
    "start": "2030919",
    "end": "2037200"
  },
  {
    "text": "question there what is",
    "start": "2037200",
    "end": "2039960"
  },
  {
    "text": "it okay so the question is are recommended scrape intervals on",
    "start": "2050560",
    "end": "2056000"
  },
  {
    "text": "Prometheus uh it basically boils down to how much data and how accurate the data",
    "start": "2056000",
    "end": "2061839"
  },
  {
    "text": "you need is H because the way I see it yes you could scrape once a second and",
    "start": "2061839",
    "end": "2067000"
  },
  {
    "text": "and get really you know granular data but you could also scrape once every 60",
    "start": "2067000",
    "end": "2072720"
  },
  {
    "text": "seconds and have 60 times the time series for basically the same performance cost and which of those is",
    "start": "2072720",
    "end": "2079158"
  },
  {
    "text": "more likely to help you in an emergency like having all your libraries interest having this one metric that's",
    "start": "2079159",
    "end": "2084760"
  },
  {
    "text": "awesome and I would generally aim for breath like just having things liberally instrumented with no labels alter your",
    "start": "2084760",
    "end": "2091118"
  },
  {
    "text": "code base just so you can figure out right roughly where is my problem so I would generally I found personally one",
    "start": "2091119",
    "end": "2096878"
  },
  {
    "text": "minute is actually fine for the vast majority of things and the only time you need down at the second range is when",
    "start": "2096879",
    "end": "2103119"
  },
  {
    "text": "you're trying to bug like for maybe literally a handful of metrics when you're trying to debug you know bursts",
    "start": "2103119",
    "end": "2109320"
  },
  {
    "text": "of traffic that are in the seconds range but breath is generally best a lot of people use like 15 seconds because",
    "start": "2109320",
    "end": "2115400"
  },
  {
    "text": "that's the default or 10 seconds but you basically trade off do I want a broader metrics or do I want the ones I have to",
    "start": "2115400",
    "end": "2120880"
  },
  {
    "text": "be more granular cool any other questions your hand up um",
    "start": "2120880",
    "end": "2128040"
  },
  {
    "text": "a general question about these metrics and math math um I feel like there's a",
    "start": "2128040",
    "end": "2133839"
  },
  {
    "text": "lot of um like patterns in your head what should one do like an API generic",
    "start": "2133839",
    "end": "2140240"
  },
  {
    "text": "API rest base what what what are the kinds of things we would measure if if we if you don't know anything about the",
    "start": "2140240",
    "end": "2147200"
  },
  {
    "text": "API so like rates and like latency and whatever I wonder if there is a place in",
    "start": "2147200",
    "end": "2152720"
  },
  {
    "text": "the internet where people uh are currently collecting those like I know",
    "start": "2152720",
    "end": "2158240"
  },
  {
    "text": "the SR Sr book um has some five golden rules of whatever if you want to measure",
    "start": "2158240",
    "end": "2165440"
  },
  {
    "text": "I know them but is there is there more on that so the question I don't want to say people do do my work but it's just",
    "start": "2165440",
    "end": "2172760"
  },
  {
    "text": "like there should be some knowledge around how to use the query language in some basic user cases okay so this",
    "start": "2172760",
    "end": "2179000"
  },
  {
    "text": "question about query language or instrumentation I mean I mean it's it's collecting the metrics and also Language",
    "start": "2179000",
    "end": "2185839"
  },
  {
    "text": "by are there are there some is it always specific to your uh so in relation to",
    "start": "2185839",
    "end": "2192000"
  },
  {
    "text": "instrumentation what instrument was the first part of the question if you look at the best practices on prus the",
    "start": "2192000",
    "end": "2198079"
  },
  {
    "text": "instrumentation best practices answer that question which is why I wrote them um the second question then is are there",
    "start": "2198079",
    "end": "2204560"
  },
  {
    "text": "common patterns around using things like summaries and so on so the thing is there's about five really really common",
    "start": "2204560",
    "end": "2211680"
  },
  {
    "text": "patterns in Prometheus there's like taking a rate there's aggregating that",
    "start": "2211680",
    "end": "2217359"
  },
  {
    "text": "rate there's using histogram quantile RIT rate and aggregation and there's a summary doing the quantiles they're very",
    "start": "2217359",
    "end": "2224240"
  },
  {
    "text": "simple patterns uh I'm not sure they're explicitly done I'll put them in the blog eventually they're on my to-do list",
    "start": "2224240",
    "end": "2230119"
  },
  {
    "text": "uh but those are the normal patterns just like five or six of them only that you need and of them to be honest only",
    "start": "2230119",
    "end": "2236240"
  },
  {
    "text": "the histogram and the summary require any P the rest of is just take a ration and take a some but yeah everything",
    "start": "2236240",
    "end": "2243440"
  },
  {
    "text": "beyond that tends to be so weird that we basically need to ask a a promptu expert what you you're doing because you're",
    "start": "2243440",
    "end": "2249880"
  },
  {
    "text": "doing complex stuff yeah another question what's the difference between iate and",
    "start": "2249880",
    "end": "2255960"
  },
  {
    "text": "Delta okay so the question is what's the difference between irate and Delta IR rate is for use with counters it looks",
    "start": "2255960",
    "end": "2262240"
  },
  {
    "text": "at last to rate that's much more responsive uh Delta by comparison I",
    "start": "2262240",
    "end": "2268119"
  },
  {
    "text": "propose removing from the language H Delta is for use with gauges and it's",
    "start": "2268119",
    "end": "2273960"
  },
  {
    "text": "the same as increase but doesn't have the uh counter reset handling the function you",
    "start": "2273960",
    "end": "2280760"
  },
  {
    "text": "really want is called D which will use at least squares analysis uh to figure out how fast a gauge is moving up and",
    "start": "2280760",
    "end": "2286800"
  },
  {
    "text": "down because the problem with Delta because it's following it's basically just using the first and last point and doing some extrapolation is that it is",
    "start": "2286800",
    "end": "2294839"
  },
  {
    "text": "extremely susceptible to outliers at that happen to be at the start and end which is a problem whereas if you're",
    "start": "2294839",
    "end": "2301040"
  },
  {
    "text": "using least squares via the riv it's not as dominated by any outliers around",
    "start": "2301040",
    "end": "2306200"
  },
  {
    "text": "those points so generally don't use Delta but then is for gauges and IR R and increase are for",
    "start": "2306200",
    "end": "2313200"
  },
  {
    "text": "counters our recommendation was a question there yeah the really basic question regarding rate do I need to put",
    "start": "2313200",
    "end": "2320040"
  },
  {
    "text": "in the scrape interval into rate or is that all done for me or is that what the inre okay so so the question is do I",
    "start": "2320040",
    "end": "2326119"
  },
  {
    "text": "need to put the scrape interval into rate the answer is no because it has the data can work that out but the range",
    "start": "2326119",
    "end": "2333800"
  },
  {
    "text": "should cover at at least two points preferably Tre to cover a missing scrape",
    "start": "2333800",
    "end": "2339720"
  },
  {
    "text": "so normally you know two and a half times at least i' like if you had let's say 10c scrape interval you probably",
    "start": "2339720",
    "end": "2345880"
  },
  {
    "text": "want a 30 second rate at a minimum longer if you actually want average out but I always get the per second back",
    "start": "2345880",
    "end": "2352280"
  },
  {
    "text": "rate always returns per second yes cool uh any other",
    "start": "2352280",
    "end": "2357720"
  },
  {
    "text": "questions put your hand up anyone anyone hiding over here the",
    "start": "2357880",
    "end": "2364960"
  },
  {
    "text": "question no about four of you couldn't see okay well if that's it then thank",
    "start": "2364960",
    "end": "2371960"
  },
  {
    "text": "you very much",
    "start": "2371960",
    "end": "2379760"
  }
]
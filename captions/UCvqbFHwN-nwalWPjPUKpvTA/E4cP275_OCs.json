[
  {
    "start": "0",
    "end": "41000"
  },
  {
    "text": "hi so i'm currently a postdoc researcher at kent university i'm jose sanchez",
    "start": "960",
    "end": "6480"
  },
  {
    "text": "i just recently graduated last month and this talk summarizes",
    "start": "6480",
    "end": "12080"
  },
  {
    "text": "the latest work during my dissertation which is trying to bring network aware information to the scheduling process in",
    "start": "12080",
    "end": "18960"
  },
  {
    "text": "kubernetes trying to find better decisions uh focus on this information to allocate workloads in kubernetes",
    "start": "18960",
    "end": "26960"
  },
  {
    "text": "unfortunately uh my collaborator my co-speaker shen was not able to be",
    "start": "26960",
    "end": "32640"
  },
  {
    "text": "here today so i'll be doing the the presentation this work is a joint collaboration between ghent university",
    "start": "32640",
    "end": "39040"
  },
  {
    "text": "and ibm today i'll talk about",
    "start": "39040",
    "end": "44079"
  },
  {
    "text": "more about the motivation why do we need network aware scheduling in current kubernetes clusters",
    "start": "44079",
    "end": "50719"
  },
  {
    "text": "i'll try to show you the main building blocks that we currently have in our network aware framework i'll try to",
    "start": "50719",
    "end": "57360"
  },
  {
    "text": "explain you some of the implementation details and some of the considerations that we have in our framework",
    "start": "57360",
    "end": "63280"
  },
  {
    "text": "and i'll try to show you a complete example on how you can use our framework",
    "start": "63280",
    "end": "68960"
  },
  {
    "text": "to deploy your applications in a kubernetes cluster trying to find better",
    "start": "68960",
    "end": "74640"
  },
  {
    "text": "decisions in terms of network aware placement then if the demo gods and the wi-fi help",
    "start": "74640",
    "end": "80799"
  },
  {
    "text": "me i'll try to show you a live demo by deploying the online boutique application which is a typical",
    "start": "80799",
    "end": "87280"
  },
  {
    "text": "application used in microservice research so it's a web-based",
    "start": "87280",
    "end": "93439"
  },
  {
    "text": "application with several workloads and by deploying this application with the default scheduler and with our approach",
    "start": "93439",
    "end": "100720"
  },
  {
    "text": "our network aware framework you will see the differences that you get by deploying this application in kubernetes",
    "start": "100720",
    "end": "106799"
  },
  {
    "text": "cluster then i'll talk about the challenges and the lessons learned and finally",
    "start": "106799",
    "end": "112000"
  },
  {
    "text": "acknowledgements so typically when we started working on",
    "start": "112000",
    "end": "117040"
  },
  {
    "start": "114000",
    "end": "251000"
  },
  {
    "text": "network aware scheduling we noticed that the kubernetes scheduler typically mainly focuses on resource efficiency so",
    "start": "117040",
    "end": "123840"
  },
  {
    "text": "typically you as a developer you try to set up cpu and memory requests and limitations so that the scheduler can",
    "start": "123840",
    "end": "130879"
  },
  {
    "text": "find better decisions for your pods and that's particularly important when",
    "start": "130879",
    "end": "136800"
  },
  {
    "text": "you are focusing on energy efficiency but for certain applications like latency sensitive iot applications",
    "start": "136800",
    "end": "143920"
  },
  {
    "text": "and video streaming applications low latency plays a major role because you want to reduce the",
    "start": "143920",
    "end": "150959"
  },
  {
    "text": "the applications response time trying to give pleasant experiences to your end users",
    "start": "150959",
    "end": "157040"
  },
  {
    "text": "so currently there are very few plugins scheduling plugins in the kubernetes",
    "start": "157040",
    "end": "163440"
  },
  {
    "text": "architecture that you can use with contextual awareness so for instance",
    "start": "163440",
    "end": "168480"
  },
  {
    "text": "when you have several workloads in your application typically the scheduler allocates these workloads independent of",
    "start": "168480",
    "end": "174959"
  },
  {
    "text": "each other so they have not a knowledge of which workloads i will",
    "start": "174959",
    "end": "181120"
  },
  {
    "text": "contact to or i will communicate to and also there is no knowledge on the infrastructure topology meaning what is",
    "start": "181120",
    "end": "188480"
  },
  {
    "text": "available bandwidth let's say in your cluster between cluster nodes what is the communication latency or delay that",
    "start": "188480",
    "end": "195040"
  },
  {
    "text": "you have on your network links so there is not this type of information available",
    "start": "195040",
    "end": "200720"
  },
  {
    "text": "currently so we thought about how can we do better well the easy answer is to say to",
    "start": "200720",
    "end": "208080"
  },
  {
    "text": "consider some sort of latency or network bandwidth metric in the scheduling process but how can we do this there is",
    "start": "208080",
    "end": "215120"
  },
  {
    "text": "a lot of research on these which typically involve a theoretical modeling",
    "start": "215120",
    "end": "220480"
  },
  {
    "text": "where you can handle all the constraints all the complexity concerning tragedy of resources network",
    "start": "220480",
    "end": "228879"
  },
  {
    "text": "latency among cluster nodes also bandwidth but typically to find the",
    "start": "228879",
    "end": "234080"
  },
  {
    "text": "optimal location scheme it takes several hours to find it which is not scalable",
    "start": "234080",
    "end": "239760"
  },
  {
    "text": "in production environment so how can we address network aware scheduling in",
    "start": "239760",
    "end": "245760"
  },
  {
    "text": "let's say operational environment like kubernetes",
    "start": "245760",
    "end": "251200"
  },
  {
    "start": "251000",
    "end": "313000"
  },
  {
    "text": "so we have proposed a framework where we are essentially considering two main",
    "start": "251360",
    "end": "257359"
  },
  {
    "text": "aspects application characteristics because we believe that micro service dependencies",
    "start": "257359",
    "end": "262400"
  },
  {
    "text": "play a major role so for instance you have here two example applications the online boutique application the redis",
    "start": "262400",
    "end": "268880"
  },
  {
    "text": "cluster one and you can clearly see that you have several workloads here and they communicate to each other",
    "start": "268880",
    "end": "274960"
  },
  {
    "text": "so when you are deploying one of these workloads in the scheduler you should be aware of that you should be aware of the",
    "start": "274960",
    "end": "280880"
  },
  {
    "text": "dependencies that each microservice has based on a certain application the second main aspect is in terms of",
    "start": "280880",
    "end": "287600"
  },
  {
    "text": "infrastructure topology so we want to establish network weights among cluster nodes based on different",
    "start": "287600",
    "end": "293919"
  },
  {
    "text": "metrics so you as a developer based on our solution you based on the knowledge that",
    "start": "293919",
    "end": "299759"
  },
  {
    "text": "you have on your infrastructure you can manually define network weights among the cluster nodes and this is based on",
    "start": "299759",
    "end": "306080"
  },
  {
    "text": "the current topology labels supported in communities like zones and regions",
    "start": "306080",
    "end": "312639"
  },
  {
    "start": "313000",
    "end": "353000"
  },
  {
    "text": "we believe that all kinds of topologies will benefit from this framework but of course high latency is a major concern",
    "start": "313680",
    "end": "320160"
  },
  {
    "text": "in multi-region clusters but even in a small scale cluster if your nodes have different network connections",
    "start": "320160",
    "end": "326720"
  },
  {
    "text": "they can benefit from latency aware decisions and as an example for instance in a data",
    "start": "326720",
    "end": "333199"
  },
  {
    "text": "center you have certain applications like financial applications that if you deploy dependent workloads far away from",
    "start": "333199",
    "end": "340479"
  },
  {
    "text": "each other in different zones of the data center you may have high latency in the communication between these two",
    "start": "340479",
    "end": "346800"
  },
  {
    "text": "workloads so it's quite important to consider uh this information in the scheduling process",
    "start": "346800",
    "end": "353600"
  },
  {
    "text": "so before i jump to my main overview of our framework",
    "start": "353600",
    "end": "358639"
  },
  {
    "text": "i would like to ask a question many of you has already heard about the kubernetes scheduling community and has",
    "start": "358639",
    "end": "364479"
  },
  {
    "text": "used their uh scheduling plugins repository please raise your hand",
    "start": "364479",
    "end": "370319"
  },
  {
    "text": "so i see just a very few uh hands so essentially we have designed our",
    "start": "370319",
    "end": "376160"
  },
  {
    "start": "376000",
    "end": "489000"
  },
  {
    "text": "framework based on their repository based on their current framework and essentially i'll try to explain you the",
    "start": "376160",
    "end": "383120"
  },
  {
    "text": "main building blocks that we currently have so essentially we have two custom resources",
    "start": "383120",
    "end": "388800"
  },
  {
    "text": "which will also have a controller so the first one we called it as a application group",
    "start": "388800",
    "end": "395440"
  },
  {
    "text": "where essentially you can say which workloads belong to a certain application and also establish",
    "start": "395440",
    "end": "401919"
  },
  {
    "text": "dependencies among these workloads and i will go more on these later on",
    "start": "401919",
    "end": "407440"
  },
  {
    "text": "the second custom resource is a network topology where you can establish network weights among",
    "start": "407440",
    "end": "414160"
  },
  {
    "text": "different zones and regions in the cluster so that you can use these costs later on on our scheduling plugins",
    "start": "414160",
    "end": "421280"
  },
  {
    "text": "we have three scheduling plugins uh essentially in the communities six scheduling community they have opened up",
    "start": "421280",
    "end": "428400"
  },
  {
    "text": "the cube scheduler component and you have several extension points where you can develop your own algorithms so that",
    "start": "428400",
    "end": "434639"
  },
  {
    "text": "you can use your own algorithms to schedule pods let's say in the cluster",
    "start": "434639",
    "end": "440639"
  },
  {
    "text": "we have three functions a q sorting function a filtering function and the scoring one which i'll go on as well",
    "start": "440639",
    "end": "447039"
  },
  {
    "text": "later on today and essentially with these three functions we are trying to approximate the optimal",
    "start": "447039",
    "end": "452479"
  },
  {
    "text": "solution that the theoretical model would give us but in a much more scalable way",
    "start": "452479",
    "end": "458319"
  },
  {
    "text": "as an additional component we also have a net perf component that can be used in",
    "start": "458319",
    "end": "463520"
  },
  {
    "text": "typically in small scale or medium-sized clusters where you run net proof measurements across your",
    "start": "463520",
    "end": "469599"
  },
  {
    "text": "cluster nodes and then we save the measurements in a config map and then what we will do is",
    "start": "469599",
    "end": "474639"
  },
  {
    "text": "that we have a controller that will access this config map and they will update the costs on the cr based on the",
    "start": "474639",
    "end": "481520"
  },
  {
    "text": "net perf measurements it's an additional component that we are also proposing",
    "start": "481520",
    "end": "486639"
  },
  {
    "text": "and then another important part is bandwidth in terms of bandwidth we believe that",
    "start": "486639",
    "end": "491919"
  },
  {
    "start": "489000",
    "end": "541000"
  },
  {
    "text": "bandwidth should be considered as well as a resource as typically cpu and memory is considered in kubernetes so we",
    "start": "491919",
    "end": "499039"
  },
  {
    "text": "are using or we are advertising bandwidth resource resources as extended resources in kubernetes so that you can",
    "start": "499039",
    "end": "506000"
  },
  {
    "text": "also as a developer make resource requests and limitations based on these",
    "start": "506000",
    "end": "512719"
  },
  {
    "text": "extended resource cons concepts we also use the bandwidth cni plugin",
    "start": "512719",
    "end": "519760"
  },
  {
    "text": "available in calico to limit the bandwidth in power deployments",
    "start": "519760",
    "end": "526080"
  },
  {
    "text": "it currently supports ingress and egress traffic shaping so with this we try to find better nodes",
    "start": "526080",
    "end": "534480"
  },
  {
    "text": "in the cluster by by as well considering bandwidth as a resource",
    "start": "534480",
    "end": "540959"
  },
  {
    "start": "541000",
    "end": "595000"
  },
  {
    "text": "so going to a complete example trying to show you how our framework uh works so",
    "start": "541440",
    "end": "547120"
  },
  {
    "text": "imagine that you have an application group a1 composed of three pods",
    "start": "547120",
    "end": "552160"
  },
  {
    "text": "we have essentially a yaml based file where we say which workloads belong to this",
    "start": "552160",
    "end": "558560"
  },
  {
    "text": "application group and we establish dependencies among the workloads in terms of dependencies currently we",
    "start": "558560",
    "end": "564399"
  },
  {
    "text": "support the minimum bandwidth requirement and the maximum network cost so essentially we tell the cluster that",
    "start": "564399",
    "end": "570800"
  },
  {
    "text": "between two dependent workloads there is a minimum bandwidth that should exist between these two so that they can",
    "start": "570800",
    "end": "577600"
  },
  {
    "text": "communicate properly and also a maximum network cost which is",
    "start": "577600",
    "end": "582800"
  },
  {
    "text": "the maximum threshold let's say or that in terms of communication latency",
    "start": "582800",
    "end": "588000"
  },
  {
    "text": "that should exist between two cluster nodes when they are allocating these two workloads",
    "start": "588000",
    "end": "595279"
  },
  {
    "start": "595000",
    "end": "628000"
  },
  {
    "text": "then we have the network topology cr that i mentioned before where you can manually input costs with",
    "start": "595279",
    "end": "603279"
  },
  {
    "text": "based on the knowledge that you have of the infrastructure currently we are focusing on latency so we want to find",
    "start": "603279",
    "end": "610000"
  },
  {
    "text": "placement schemes focusing on low latency so we establish costs between regions and zones in the cluster as you",
    "start": "610000",
    "end": "616720"
  },
  {
    "text": "can see the yaml-based file will correspond to the figure in the slide",
    "start": "616720",
    "end": "623360"
  },
  {
    "text": "so now going through the scheduling plugins that we are also proposing",
    "start": "623360",
    "end": "628640"
  },
  {
    "start": "628000",
    "end": "684000"
  },
  {
    "text": "first one of the things that we thought about is that when you have several workloads in your application",
    "start": "628640",
    "end": "634560"
  },
  {
    "text": "with how do we select the first spot to be scheduled it's uh because",
    "start": "634560",
    "end": "640720"
  },
  {
    "text": "the order from which you will allocate all these pods in your application will have an impact on the final",
    "start": "640720",
    "end": "647680"
  },
  {
    "text": "end-to-end response time let's say of your application so how do we solve this which which part should be we consider",
    "start": "647680",
    "end": "654000"
  },
  {
    "text": "first so we have a potential solution for this which is an additional qsort plugin that sorts spots based on",
    "start": "654000",
    "end": "660560"
  },
  {
    "text": "topological sorting essentially in topological sorting it looks for the dependencies amongst different workloads",
    "start": "660560",
    "end": "667680"
  },
  {
    "text": "and tries to find the preferred order based on topology information",
    "start": "667680",
    "end": "673200"
  },
  {
    "text": "and currently we support six algorithms and i will show you that significant differences can be obtained based on the",
    "start": "673200",
    "end": "679680"
  },
  {
    "text": "topology algorithm that you select for in the application group so for now we are supporting six",
    "start": "679680",
    "end": "686399"
  },
  {
    "start": "684000",
    "end": "727000"
  },
  {
    "text": "algorithms and you can see here that depending on which one you select",
    "start": "686399",
    "end": "692800"
  },
  {
    "text": "different orders are uh are obtained so currently for the online boutique",
    "start": "692800",
    "end": "698240"
  },
  {
    "text": "application we achieved lower latency with three versions with three algorithms but you can clearly see that",
    "start": "698240",
    "end": "704880"
  },
  {
    "text": "depending on the order it matters how how much can we optimize the latency in",
    "start": "704880",
    "end": "711519"
  },
  {
    "text": "the in the in the in the kubernetes cluster so essentially what we do is that we",
    "start": "711519",
    "end": "716720"
  },
  {
    "text": "attribute an index to each workload in our application group and based on that",
    "start": "716720",
    "end": "721920"
  },
  {
    "text": "index we will sort the pods in the waiting queue to be scheduled",
    "start": "721920",
    "end": "727440"
  },
  {
    "start": "727000",
    "end": "765000"
  },
  {
    "text": "then we have a filtering and the scoring function the filtering essentially tries to",
    "start": "727760",
    "end": "734320"
  },
  {
    "text": "filter out nodes that will produce low scores trying to filter out these nodes based",
    "start": "734320",
    "end": "740160"
  },
  {
    "text": "on the requirements that i've already mentioned in the pods application group and also then the scoring function is",
    "start": "740160",
    "end": "747200"
  },
  {
    "text": "the main function of our of our framework let's say where we try to find nodes",
    "start": "747200",
    "end": "753519"
  },
  {
    "text": "uh that will ensure that the network latency is minimized for dependent workloads based on the network costs",
    "start": "753519",
    "end": "759760"
  },
  {
    "text": "that are available in the network topology cr but how does this work i'll try to show",
    "start": "759760",
    "end": "764959"
  },
  {
    "text": "you uh an example so let's assume that we have an obligation group a1 with three parts",
    "start": "764959",
    "end": "772480"
  },
  {
    "text": "three deployments and we have a dependency between p1 and p2 and we have",
    "start": "772480",
    "end": "777600"
  },
  {
    "text": "another dependency between p2 and p3 we have the network topology cr that",
    "start": "777600",
    "end": "783440"
  },
  {
    "start": "781000",
    "end": "791000"
  },
  {
    "text": "i've shown previously we have two regions four zones and eight nodes in our cluster",
    "start": "783440",
    "end": "790800"
  },
  {
    "start": "791000",
    "end": "842000"
  },
  {
    "text": "and then for the filtering function let's imagine that we want to schedule the workload p1 and p2 is a dependency",
    "start": "792079",
    "end": "800240"
  },
  {
    "text": "so and we know that there is already an instance of p2 deployed on node n1 so",
    "start": "800240",
    "end": "805920"
  },
  {
    "text": "how does the filtering function works so essentially it tries to exclude nodes that will unmet a higher number of",
    "start": "805920",
    "end": "812079"
  },
  {
    "text": "dependencies and tries to reduce the number of nodes being scored so in this example essentially it will check the",
    "start": "812079",
    "end": "818959"
  },
  {
    "text": "maximum network cost requirements between p1 and p2 in the application group cr and the nodes that will produce",
    "start": "818959",
    "end": "826399"
  },
  {
    "text": "a higher cost that will surpass this threshold will be automatically filtered out so",
    "start": "826399",
    "end": "831839"
  },
  {
    "text": "essentially in this case in our topology node n5 to n8 will be filtered out and",
    "start": "831839",
    "end": "837920"
  },
  {
    "text": "will not be be considered for scoring",
    "start": "837920",
    "end": "842760"
  },
  {
    "start": "842000",
    "end": "881000"
  },
  {
    "text": "going through the scoring function essentially we are trying to calculate accumulated shortest path",
    "start": "843040",
    "end": "848959"
  },
  {
    "text": "cost for all the candidate nodes based on the network weights that we have in the network topology cr and all the",
    "start": "848959",
    "end": "855199"
  },
  {
    "text": "workloads that are already scheduled in the in the cluster we normalize the accumulated costs for",
    "start": "855199",
    "end": "861360"
  },
  {
    "text": "all the nodes because we want to favor nodes with lower costs these nodes will be scored higher so as you can see in",
    "start": "861360",
    "end": "867920"
  },
  {
    "text": "the example the nodes that will be scored higher are n1 and then",
    "start": "867920",
    "end": "873120"
  },
  {
    "text": "two because these two nodes based on our network topology will produce lower latency in the end",
    "start": "873120",
    "end": "881120"
  },
  {
    "start": "881000",
    "end": "892000"
  },
  {
    "text": "so now i'll try to show you a live demo on how you could deploy all these",
    "start": "882320",
    "end": "887680"
  },
  {
    "text": "components and deploy an application based on our solution so i have a kubernetes cluster with 16",
    "start": "887680",
    "end": "894880"
  },
  {
    "text": "nodes all the nodes belong to the same region belgium and but each node is on a different zone",
    "start": "894880",
    "end": "902160"
  },
  {
    "text": "and i have emulated different network connections with varying delays with traffic control",
    "start": "902160",
    "end": "908079"
  },
  {
    "text": "so you can clearly see the differences in terms of latency this morning i've run the",
    "start": "908079",
    "end": "913440"
  },
  {
    "text": "additional component that i mentioned the netperf component so i have all the measurements saved in a config map and i will try to",
    "start": "913440",
    "end": "921120"
  },
  {
    "text": "deploy our network topology controller that will access these measurements and will update the network topology cr",
    "start": "921120",
    "end": "927839"
  },
  {
    "text": "accordingly so let's go to the demo",
    "start": "927839",
    "end": "933519"
  },
  {
    "start": "934000",
    "end": "1290000"
  },
  {
    "text": "so first i will deploy the controller image",
    "start": "937360",
    "end": "943680"
  },
  {
    "text": "essentially you have two images in this scheduling plugins repository you have",
    "start": "943680",
    "end": "949839"
  },
  {
    "text": "the controller and the scheduler you can use their uh already available uh additional plugins",
    "start": "949839",
    "end": "956560"
  },
  {
    "text": "that you have there but you can develop as well in their framework your own algorithms and that's essentially what",
    "start": "956560",
    "end": "962079"
  },
  {
    "text": "we did so i will deploy the controller",
    "start": "962079",
    "end": "968519"
  },
  {
    "text": "let's hope the wi-fi it's okay",
    "start": "974720",
    "end": "979360"
  },
  {
    "text": "so",
    "start": "980720",
    "end": "983720"
  },
  {
    "text": "i will just check the logs to see if everything worked fine",
    "start": "989040",
    "end": "997079"
  },
  {
    "text": "so we should see two controllers two additional controllers which is the application group and the network",
    "start": "1004240",
    "end": "1010480"
  },
  {
    "text": "topology one",
    "start": "1010480",
    "end": "1013360"
  },
  {
    "text": "sorry let me check",
    "start": "1015920",
    "end": "1024199"
  },
  {
    "text": "better yeah so",
    "start": "1029520",
    "end": "1036159"
  },
  {
    "text": "now i will show you the application group",
    "start": "1036839",
    "end": "1042480"
  },
  {
    "text": "so we have an application group for the online",
    "start": "1044240",
    "end": "1049600"
  },
  {
    "text": "boutique application where we have all the dependencies all the workloads that belong to the",
    "start": "1049600",
    "end": "1057360"
  },
  {
    "text": "online boutique and i will deploy these cr to the to the cluster",
    "start": "1057360",
    "end": "1064600"
  },
  {
    "text": "i'll show you the application group",
    "start": "1078880",
    "end": "1085520"
  },
  {
    "text": "so here you have all the workloads that belong to the application group and also",
    "start": "1085520",
    "end": "1091280"
  },
  {
    "text": "our controller as given an index to each workload",
    "start": "1091280",
    "end": "1096799"
  },
  {
    "text": "saying which is the preferred order for for which these workloads should be deployed in the",
    "start": "1096799",
    "end": "1102320"
  },
  {
    "text": "system so now i will show you the other",
    "start": "1102320",
    "end": "1108720"
  },
  {
    "text": "cr that we have the network topology one",
    "start": "1108720",
    "end": "1113120"
  },
  {
    "text": "and in this case i will not add any weights manually because i have run this",
    "start": "1113760",
    "end": "1120880"
  },
  {
    "text": "morning the netperf component so i will just use those costs",
    "start": "1120880",
    "end": "1126000"
  },
  {
    "text": "so i'll just deploy it",
    "start": "1126000",
    "end": "1131480"
  },
  {
    "text": "so now if we check the logs you will see that i have the costs",
    "start": "1139280",
    "end": "1146480"
  },
  {
    "text": "added from the controller into the cr",
    "start": "1146480",
    "end": "1151640"
  },
  {
    "text": "so you can see here that i have bandwidth capacities i don't have yet bandit allocated",
    "start": "1157679",
    "end": "1163919"
  },
  {
    "text": "because i don't have pods yet scheduled and i have a",
    "start": "1163919",
    "end": "1169679"
  },
  {
    "text": "cost list for this for each origin in the cluster",
    "start": "1169679",
    "end": "1174559"
  },
  {
    "text": "so now i just need to deploy the scheduler image which essentially i will deploy a",
    "start": "1176559",
    "end": "1182480"
  },
  {
    "text": "different scheduler into my kubernetes cluster which will use our plugins",
    "start": "1182480",
    "end": "1189120"
  },
  {
    "text": "so i need a different configuration for the",
    "start": "1189360",
    "end": "1195280"
  },
  {
    "text": "scheduler which will use our topological sort and our network overhead plugin",
    "start": "1195280",
    "end": "1201440"
  },
  {
    "text": "with the filtering and the scoring function enabled",
    "start": "1201440",
    "end": "1206440"
  },
  {
    "text": "so i have the scheduler",
    "start": "1214240",
    "end": "1218600"
  },
  {
    "text": "i will also enlarge the font on this one",
    "start": "1220159",
    "end": "1225520"
  },
  {
    "text": "so that i will keep the logs here sorry",
    "start": "1228720",
    "end": "1235840"
  },
  {
    "text": "and the idea now is that i will deploy the online boutique application with the normal ks",
    "start": "1239120",
    "end": "1245520"
  },
  {
    "text": "and i will use the locus load tool available in online boutique to see the application's response time and then i",
    "start": "1245520",
    "end": "1252880"
  },
  {
    "text": "will deploy the online boutique based on our framework with this different version of the schedule",
    "start": "1252880",
    "end": "1260760"
  },
  {
    "text": "so i have here the scheduler i'll just put the logs",
    "start": "1276640",
    "end": "1281760"
  },
  {
    "text": "and i'll keep them running so everything seems to be working",
    "start": "1281760",
    "end": "1290320"
  },
  {
    "start": "1290000",
    "end": "1613000"
  },
  {
    "text": "so now i will deploy the online boutique with the normal schedule",
    "start": "1290320",
    "end": "1299240"
  },
  {
    "text": "so i'm deploying all the",
    "start": "1311840",
    "end": "1315279"
  },
  {
    "text": "so in fact i'm deploying the one with the with our network aware framework first",
    "start": "1317760",
    "end": "1324159"
  },
  {
    "text": "so i'll show you first our network aware performance let's say",
    "start": "1324159",
    "end": "1332280"
  },
  {
    "text": "so let me see if the pods are running so that i can run the locust load tool",
    "start": "1337039",
    "end": "1343919"
  },
  {
    "text": "so some of them are still being created",
    "start": "1343919",
    "end": "1348399"
  },
  {
    "text": "so i'll run the locust the load generator",
    "start": "1355520",
    "end": "1360600"
  },
  {
    "text": "so now let me get the logs of the load generator",
    "start": "1366960",
    "end": "1372520"
  },
  {
    "text": "so it's not it's not running yet",
    "start": "1377520",
    "end": "1382480"
  },
  {
    "text": "so here now you see the performance that we get with our network aware framework",
    "start": "1384720",
    "end": "1390799"
  },
  {
    "text": "so we are getting uh average latency of 400 milliseconds",
    "start": "1390799",
    "end": "1396720"
  },
  {
    "text": "in some of the get and post requests i'll keep it running until 100 requests and then i will",
    "start": "1396720",
    "end": "1402880"
  },
  {
    "text": "deploy it with the ks so that you can see the differences in terms of the",
    "start": "1402880",
    "end": "1408880"
  },
  {
    "text": "of the the performance that we get",
    "start": "1408880",
    "end": "1412799"
  },
  {
    "text": "so we have minimum response time of 200 maximum of 600 for instance for the",
    "start": "1415760",
    "end": "1422799"
  },
  {
    "text": "single get request and then",
    "start": "1422799",
    "end": "1428640"
  },
  {
    "text": "i will deploy it with the ks so that you can see the differences in terms of performance",
    "start": "1428640",
    "end": "1435120"
  },
  {
    "text": "so i'll stop it here and now i will just",
    "start": "1435120",
    "end": "1440720"
  },
  {
    "text": "delete i will just delete my deployment with our network framework",
    "start": "1440720",
    "end": "1447360"
  },
  {
    "text": "so that the cluster was on the same status when i deploy it with our framework",
    "start": "1447360",
    "end": "1455158"
  },
  {
    "text": "so all the parts all the deployments are being deleted",
    "start": "1460960",
    "end": "1465360"
  },
  {
    "text": "and i will delete as well the load generator",
    "start": "1468799",
    "end": "1474158"
  },
  {
    "text": "let me just check if all the pods are already deleted",
    "start": "1477360",
    "end": "1482400"
  },
  {
    "text": "so i still have the load generator that is terminating so now i will deploy it",
    "start": "1482400",
    "end": "1488080"
  },
  {
    "text": "with the normal with the default scheduler",
    "start": "1488080",
    "end": "1492600"
  },
  {
    "text": "let me see if all the pods are running before i run the load generator",
    "start": "1505200",
    "end": "1511400"
  },
  {
    "text": "so i'll apply it so now let's see the logs",
    "start": "1525200",
    "end": "1530880"
  },
  {
    "text": "so it's running so here",
    "start": "1538240",
    "end": "1543919"
  },
  {
    "text": "you can see that uh typically the ks when deploys the online boutique",
    "start": "1543919",
    "end": "1551360"
  },
  {
    "text": "application typically we have higher values in terms of latency so here you can see that with",
    "start": "1551360",
    "end": "1558080"
  },
  {
    "text": "our network aware framework we can at least or for most requests we can at",
    "start": "1558080",
    "end": "1564320"
  },
  {
    "text": "least 30 to 40 percent reduce the latency expected uh in the cluster",
    "start": "1564320",
    "end": "1571840"
  },
  {
    "text": "i'll just keep it running so even the",
    "start": "1572559",
    "end": "1577919"
  },
  {
    "text": "in the minimum and in the average response time that we get in the online boutique application with",
    "start": "1577919",
    "end": "1583520"
  },
  {
    "text": "our framework we can typically reduce it based on specifying pod dependencies specifying",
    "start": "1583520",
    "end": "1591039"
  },
  {
    "text": "workload dependencies in the application group and as well having the network topology in the",
    "start": "1591039",
    "end": "1596799"
  },
  {
    "text": "network topology cr we can typically reduce the latency in a",
    "start": "1596799",
    "end": "1602480"
  },
  {
    "text": "kubernetes cluster so",
    "start": "1602480",
    "end": "1608080"
  },
  {
    "text": "i will just to finish my presentation",
    "start": "1608080",
    "end": "1614320"
  },
  {
    "start": "1613000",
    "end": "1731000"
  },
  {
    "text": "so what were the challenges and the lessons learned that we learned well our plugins can significantly reduce the",
    "start": "1614320",
    "end": "1621679"
  },
  {
    "text": "expected latency in kubernetes clusters especially if you properly define the application group based on the workloads",
    "start": "1621679",
    "end": "1628400"
  },
  {
    "text": "of your application and establish the dependencies that you will have in these",
    "start": "1628400",
    "end": "1633679"
  },
  {
    "text": "in your application another aspect is that currently there are a lot of",
    "start": "1633679",
    "end": "1639679"
  },
  {
    "text": "workload or grouping definitions there exists also the pod group concept where",
    "start": "1639679",
    "end": "1644720"
  },
  {
    "text": "you can deploy all the pods all together like in gang schedulers we are proposing the application group and i believe that",
    "start": "1644720",
    "end": "1651679"
  },
  {
    "text": "in the community we need to get to a generic uniform uh way of having a",
    "start": "1651679",
    "end": "1658320"
  },
  {
    "text": "yaml-based file where we could have all of these uh definitions and then we as",
    "start": "1658320",
    "end": "1664799"
  },
  {
    "text": "developers can select the one that we prefer to use another aspect that i did not mention",
    "start": "1664799",
    "end": "1671440"
  },
  {
    "text": "yet is that our plugins do not add significant overhead to the scheduler process currently",
    "start": "1671440",
    "end": "1678159"
  },
  {
    "text": "if we want to schedule a pod based on the go benchmark tool we are well below one second for a",
    "start": "1678159",
    "end": "1685279"
  },
  {
    "text": "cluster with ten thousand nodes so we are not adding overhead because we are accessing information via custom",
    "start": "1685279",
    "end": "1691679"
  },
  {
    "text": "resources and uh my main message today is that we are currently looking for contributors",
    "start": "1691679",
    "end": "1698159"
  },
  {
    "text": "and engagement from the community that are interested in network aware scheduling because currently we are",
    "start": "1698159",
    "end": "1703760"
  },
  {
    "text": "focusing on reducing the latency by specifying workload dependencies but you may have",
    "start": "1703760",
    "end": "1709600"
  },
  {
    "text": "different ideas different concepts that you would like as well to add to our current implementation and we are open",
    "start": "1709600",
    "end": "1715679"
  },
  {
    "text": "to it currently we are actively involved in the kubernetes scheduling community and we have",
    "start": "1715679",
    "end": "1723440"
  },
  {
    "text": "kubernetes announcement proposal already accepted and we have the initial pr already submitted and we are waiting uh",
    "start": "1723440",
    "end": "1729679"
  },
  {
    "text": "for revision to finish my presentation i just would like to thank all the uh",
    "start": "1729679",
    "end": "1735840"
  },
  {
    "start": "1731000",
    "end": "1760000"
  },
  {
    "text": "the people that were involved in this work mainly from ibm research and ghent university and i would like to thank as",
    "start": "1735840",
    "end": "1742240"
  },
  {
    "text": "well to the kubernetes six scheduling community because since the beginning",
    "start": "1742240",
    "end": "1747679"
  },
  {
    "text": "in our early cap proposal cap draft they gave us a lot of valuable feedback which",
    "start": "1747679",
    "end": "1753679"
  },
  {
    "text": "allowed us to improve uh our current implementation so i would like to thank them as well",
    "start": "1753679",
    "end": "1760799"
  },
  {
    "start": "1760000",
    "end": "1768000"
  },
  {
    "text": "so now i'm ready to answer all the questions that you may have otherwise you can find me in one of the breaks i'm",
    "start": "1760799",
    "end": "1767120"
  },
  {
    "text": "always happy to to share insights with you thank you",
    "start": "1767120",
    "end": "1772480"
  },
  {
    "text": "anybody anybody got any question we have one online then i can go there can we",
    "start": "1779440",
    "end": "1785520"
  },
  {
    "text": "i will be just like right there we have one virtual so the first virtual is how would this",
    "start": "1785520",
    "end": "1791039"
  },
  {
    "text": "network our scalar react to network disruption will the application services lose daily state while the workload is",
    "start": "1791039",
    "end": "1797440"
  },
  {
    "text": "being risk headed can you repeat the question last part please uh",
    "start": "1797440",
    "end": "1802640"
  },
  {
    "text": "would the application services lose data state while the workload is being rescheduled if there is some data",
    "start": "1802640",
    "end": "1808080"
  },
  {
    "text": "disruption some network data disruption so",
    "start": "1808080",
    "end": "1813120"
  },
  {
    "text": "currently we have the additional component and net perf where you can run several times a day",
    "start": "1813120",
    "end": "1819440"
  },
  {
    "text": "let's say the component so that you have updated costs in a config map and our controller will update the costs in the",
    "start": "1819440",
    "end": "1826720"
  },
  {
    "text": "cr so that you we can find uh better decisions in terms of scheduling and",
    "start": "1826720",
    "end": "1833200"
  },
  {
    "text": "also when pods are evicted or rescheduled all the workloads that are already uh",
    "start": "1833200",
    "end": "1840000"
  },
  {
    "text": "deployed in the system our framework will make sure that we'll find the best node based on the current status of the",
    "start": "1840000",
    "end": "1846880"
  },
  {
    "text": "infrastructure based on the network costs that are available okay",
    "start": "1846880",
    "end": "1853120"
  },
  {
    "text": "he got his answer anybody else just raise your hand",
    "start": "1853120",
    "end": "1859000"
  },
  {
    "text": "thanks uh this is awesome thank you uh i'm curious how close you think this is",
    "start": "1864559",
    "end": "1869840"
  },
  {
    "text": "to being production ready so currently uh",
    "start": "1869840",
    "end": "1875519"
  },
  {
    "text": "we are waiting on the revision on the pr that we submitted so",
    "start": "1875519",
    "end": "1881519"
  },
  {
    "text": "what i've shown you the main components that i've shown you in my overview it's they are running so we have this version",
    "start": "1881519",
    "end": "1888320"
  },
  {
    "text": "completely running but we are waiting so that it can be included in the seek scheduling community",
    "start": "1888320",
    "end": "1894799"
  },
  {
    "text": "but we expect to be there in the next few months otherwise you can access our",
    "start": "1894799",
    "end": "1900880"
  },
  {
    "text": "current implementation via the fork that i have from their repo so it's available in one of my branches so you can",
    "start": "1900880",
    "end": "1907440"
  },
  {
    "text": "testing out for yourself as well let's say great thanks",
    "start": "1907440",
    "end": "1912720"
  },
  {
    "text": "one more damn",
    "start": "1913679",
    "end": "1920679"
  },
  {
    "text": "um so i was wondering do you have any uh data or statistics on how this might affect",
    "start": "1922720",
    "end": "1930960"
  },
  {
    "text": "resiliency so do the when you reduce latency you tend to group things together right",
    "start": "1930960",
    "end": "1937120"
  },
  {
    "text": "and uh yeah so another experiment that we did was with",
    "start": "1937120",
    "end": "1942880"
  },
  {
    "text": "the redis cluster application which typically you have several master instances and slaves",
    "start": "1942880",
    "end": "1949840"
  },
  {
    "text": "so they are constantly exchanging let's say data and",
    "start": "1949840",
    "end": "1955919"
  },
  {
    "text": "we have run let's say the redis benchmark tool based on the deployment that we have in",
    "start": "1955919",
    "end": "1962080"
  },
  {
    "text": "this same cluster with 16 nodes and we were able to improve the throughput by 20 on average with our network aware",
    "start": "1962080",
    "end": "1969919"
  },
  {
    "text": "framework for that application",
    "start": "1969919",
    "end": "1973960"
  },
  {
    "text": "hi uh so is there a possibility to extend this so",
    "start": "1977200",
    "end": "1982320"
  },
  {
    "text": "that there's like dynamic network aware scheduling so like if the nodes there's a lot of congestion and the like right",
    "start": "1982320",
    "end": "1989039"
  },
  {
    "text": "now the costs are manually fed can we do that on a dynamic basis like on a real-time basis",
    "start": "1989039",
    "end": "1996399"
  },
  {
    "text": "one of the things that we have planned is to add a an additional plug-in which will focus",
    "start": "1996399",
    "end": "2002840"
  },
  {
    "text": "on monitoring let's say the bandwidth that the incoming traffic on a given",
    "start": "2002840",
    "end": "2008159"
  },
  {
    "text": "node and based on that we will develop a plugin that will try to",
    "start": "2008159",
    "end": "2015840"
  },
  {
    "text": "schedule the the workloads based on the bandwidth resources requests that you",
    "start": "2015840",
    "end": "2021279"
  },
  {
    "text": "set up in the deployment file and based on the current usage of the node there is a load watcher",
    "start": "2021279",
    "end": "2027840"
  },
  {
    "text": "component that currently does that for cpu and memory and we are planning to extend it to bandwidth so that we can",
    "start": "2027840",
    "end": "2034640"
  },
  {
    "text": "consider the incoming traffic of the node to try to avoid to deploy workloads",
    "start": "2034640",
    "end": "2039760"
  },
  {
    "text": "on nodes that are congested as you mentioned",
    "start": "2039760",
    "end": "2043840"
  },
  {
    "text": "uh so just a for regarding to partition tolerance applications that we have for",
    "start": "2045039",
    "end": "2050079"
  },
  {
    "text": "instance like yes radius or just as your example uh regarding to boutique",
    "start": "2050079",
    "end": "2056398"
  },
  {
    "text": "uh if you have for instance ten ports there are the 10 type of",
    "start": "2056399",
    "end": "2061919"
  },
  {
    "text": "applications that are living together so if one of the pods evicted or getting",
    "start": "2061919",
    "end": "2067679"
  },
  {
    "text": "crash lube and they say scaled somewhere else end of the some places",
    "start": "2067679",
    "end": "2073599"
  },
  {
    "text": "so what does it do can you put some light on i mean is it going to regarding to network benchmark is it",
    "start": "2073599",
    "end": "2081440"
  },
  {
    "text": "going to kill every pod and start to schedule for network efficiency",
    "start": "2081440",
    "end": "2088079"
  },
  {
    "text": "or is going to live as it is like i say",
    "start": "2088079",
    "end": "2093200"
  },
  {
    "text": "i would say that as a cluster administrator you need to make decisions or",
    "start": "2094320",
    "end": "2101200"
  },
  {
    "text": "decide which you prefer to optimize in your cluster so currently you have",
    "start": "2101200",
    "end": "2106560"
  },
  {
    "text": "several plugins focused on resource efficiency and we are proposing one which is more",
    "start": "2106560",
    "end": "2112480"
  },
  {
    "text": "focused on network aware information which based on workload dependencies and",
    "start": "2112480",
    "end": "2118079"
  },
  {
    "text": "network topology tries to find uh placement schemes where it tries to reduce the latency we currently are",
    "start": "2118079",
    "end": "2124640"
  },
  {
    "text": "focused on that and even if pods are evicted as you said we",
    "start": "2124640",
    "end": "2130160"
  },
  {
    "text": "believe that our framework can find the the best node focused on low latency uh",
    "start": "2130160",
    "end": "2136880"
  },
  {
    "text": "based on the current status of the of the cluster okay great session",
    "start": "2136880",
    "end": "2143200"
  },
  {
    "text": "thank you jose i think we are done of time but yeah we have lunch break now so if",
    "start": "2143200",
    "end": "2150160"
  },
  {
    "text": "you want to gather here that's fine thank you folks thank you thank you",
    "start": "2150160",
    "end": "2156920"
  }
]
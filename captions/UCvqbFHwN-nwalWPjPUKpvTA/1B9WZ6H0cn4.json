[
  {
    "text": "so just a quick show of hands how many of you have uh heard of AI",
    "start": "480",
    "end": "6680"
  },
  {
    "text": "agents it's pretty much everyone amazing and uh how many of you are actually",
    "start": "6680",
    "end": "12480"
  },
  {
    "text": "building AI agent or agentic systems right now",
    "start": "12480",
    "end": "17880"
  },
  {
    "text": "wonderful so my topic today is going to be about um AI agent observability",
    "start": "17880",
    "end": "24640"
  },
  {
    "text": "um the thing the the bunch of challenges that arise with with the new",
    "start": "24640",
    "end": "29920"
  },
  {
    "text": "architecture and the systems uh surrounding LLMs vector databases and",
    "start": "29920",
    "end": "35360"
  },
  {
    "text": "orchestration frameworks unfortunately my co-speaker",
    "start": "35360",
    "end": "41280"
  },
  {
    "text": "couldn't make it today so it's just going to be me um but just a bit about ourselves uh my name is Karthik i'm the",
    "start": "41280",
    "end": "49200"
  },
  {
    "text": "co-founder and CTO of Langrace which is an open source and open telemetry based u",
    "start": "49200",
    "end": "54840"
  },
  {
    "text": "observability client SDK as well as client for uh tracing and evaluating",
    "start": "54840",
    "end": "60160"
  },
  {
    "text": "genai based applications uh on the open source side",
    "start": "60160",
    "end": "65439"
  },
  {
    "text": "I also I'm also one of the members of the genai uh special interest group um",
    "start": "65439",
    "end": "72159"
  },
  {
    "text": "which is responsible for coming up with semantic conventions for genai based apps um I was also one of the main",
    "start": "72159",
    "end": "79280"
  },
  {
    "text": "contributors of the official OpenAI um client SDK for um open telemetry uh my",
    "start": "79280",
    "end": "86799"
  },
  {
    "text": "co-speaker u who was who also worked with me on the on the presentation uh",
    "start": "86799",
    "end": "92000"
  },
  {
    "text": "he's from IBM and he's also part of the genai",
    "start": "92000",
    "end": "97479"
  },
  {
    "text": "group so let's do a quick background and uh see the lay of the land right so 2023 or",
    "start": "97479",
    "end": "106079"
  },
  {
    "text": "towards the end of 2022 uh chat GPT launched and the year 2023 was all about",
    "start": "106079",
    "end": "112840"
  },
  {
    "text": "LLMs uh we we had developers um excited about building with LLMs",
    "start": "112840",
    "end": "119280"
  },
  {
    "text": "uh multiple different labs uh labs were created uh",
    "start": "119280",
    "end": "125520"
  },
  {
    "text": "many models were launched and we saw a quick acceleration from GPT3.5 to GPT4",
    "start": "125520",
    "end": "133040"
  },
  {
    "text": "and GPT40 and the intelligence uh quickly improved year 2024 was all about",
    "start": "133040",
    "end": "140720"
  },
  {
    "text": "retrieval augmented generation or rag and uh AI orchestration frameworks such",
    "start": "140720",
    "end": "146480"
  },
  {
    "text": "as langchain llama index haststack autogen um things like that so all of a",
    "start": "146480",
    "end": "153200"
  },
  {
    "text": "sudden we went from uh building directly with LLMs to how can we build chat GPT",
    "start": "153200",
    "end": "159519"
  },
  {
    "text": "for our own enterprise data and uh that's when vector databases blew up",
    "start": "159519",
    "end": "164959"
  },
  {
    "text": "because vector databases with vector databases you can retrieve contents with",
    "start": "164959",
    "end": "170000"
  },
  {
    "text": "um natural language uh you can search using semantics and provide that as a",
    "start": "170000",
    "end": "175680"
  },
  {
    "text": "context to LLMs and rag as a architecture became very popular and year 2025 is It has been like 3 months",
    "start": "175680",
    "end": "182720"
  },
  {
    "text": "and we are already talking about multi- aent systems and the entire stack is",
    "start": "182720",
    "end": "188480"
  },
  {
    "text": "coming together uh slowly evolving uh we have observability of course uh but",
    "start": "188480",
    "end": "194879"
  },
  {
    "text": "besides observability we have hosting uh we model context protocol which is like",
    "start": "194879",
    "end": "200319"
  },
  {
    "text": "the standard protocol uh for for for the LLMs to interact with external tools uh",
    "start": "200319",
    "end": "207120"
  },
  {
    "text": "that's that's become very popular in the last few weeks uh we we we we are seeing",
    "start": "207120",
    "end": "212560"
  },
  {
    "text": "newer frameworks showing up every day typescript has Versel AI SDK uh Mastra",
    "start": "212560",
    "end": "219040"
  },
  {
    "text": "Python has like a bunch of frameworks like Crew AI um Autogen Langchain Llama",
    "start": "219040",
    "end": "225319"
  },
  {
    "text": "Index Agno bunch of different frameworks uh we have LLM proxy that is becoming",
    "start": "225319",
    "end": "231519"
  },
  {
    "text": "like a big topic all of a sudden developers want to switch between models without any underlying cost so uh we are",
    "start": "231519",
    "end": "239760"
  },
  {
    "text": "seeing the rise of LLM proxies such as light LLM Arch AI gateway and things",
    "start": "239760",
    "end": "246319"
  },
  {
    "text": "like that memory is becoming a big topic uh LLMs need contextual data and a",
    "start": "246319",
    "end": "253200"
  },
  {
    "text": "memory layer bunch of different open source projects are showing up around memory layer sandboxes for code uh",
    "start": "253200",
    "end": "260720"
  },
  {
    "text": "generate for running code LLM generated code that's becoming like a big topic as well uh we are seeing the rise of uh",
    "start": "260720",
    "end": "268320"
  },
  {
    "text": "products such as lovable bolt and v 0ero that generates code on the fly and the code needs an execution environment uh",
    "start": "268320",
    "end": "275360"
  },
  {
    "text": "which is like a sandboxed environment without any security issues and we are seeing rise of sandboxes such as E2B",
    "start": "275360",
    "end": "282639"
  },
  {
    "text": "again open source project um and finally we are we we are also seeing the",
    "start": "282639",
    "end": "287759"
  },
  {
    "text": "convergence of vector databases with the traditional databases pg vector is becoming very popular MongoDB has",
    "start": "287759",
    "end": "294720"
  },
  {
    "text": "launched their own uh vector vector search so the entire uh stack is",
    "start": "294720",
    "end": "300400"
  },
  {
    "text": "evolving uh which which means observability is starting to play a much",
    "start": "300400",
    "end": "305520"
  },
  {
    "text": "bigger role and the importance of observability is becoming more acute uh by the day so let's let's let's talk about a",
    "start": "305520",
    "end": "314479"
  },
  {
    "text": "few definitions right so what is an AI agent an AI agent um is is nothing but",
    "start": "314479",
    "end": "320720"
  },
  {
    "text": "it's it's built using an LLM and um typically it it uh it tries to do a",
    "start": "320720",
    "end": "327520"
  },
  {
    "text": "bunch of DB retrievalss um it it it uh interfaces with external tools using",
    "start": "327520",
    "end": "334000"
  },
  {
    "text": "tool calling u it does a bunch of multi-step reasoning to achieve a",
    "start": "334000",
    "end": "339039"
  },
  {
    "text": "desired end goal um with or without a human in the loop so a bunch of",
    "start": "339039",
    "end": "345720"
  },
  {
    "text": "um Quick examples are cursor which is a popular code editor which is becoming um",
    "start": "345720",
    "end": "353440"
  },
  {
    "text": "quite useful um GitHub copilot v 0ero by versel these are all like typical AI",
    "start": "353440",
    "end": "359199"
  },
  {
    "text": "agentic systems now let's talk about a multi- aent system what is a multi- aent system",
    "start": "359199",
    "end": "365360"
  },
  {
    "text": "so a multi- aent system is nothing but a system that is made up of multiple AI agents with uh different",
    "start": "365360",
    "end": "371960"
  },
  {
    "text": "responsibilities that are working together uh in in a sort of coordinated fashion",
    "start": "371960",
    "end": "377240"
  },
  {
    "text": "or multiple architectures are showing up on that front as well where a single agent is delegating tasks to multiple",
    "start": "377240",
    "end": "384319"
  },
  {
    "text": "other agents aggregating the responses and giving out like a uh overall response based on the given task at",
    "start": "384319",
    "end": "391960"
  },
  {
    "text": "hand so let's let's talk about some of the common challenges with multi- aent",
    "start": "391960",
    "end": "397840"
  },
  {
    "text": "systems or AI agents right so the broad the three broad categories where most of",
    "start": "397840",
    "end": "403600"
  },
  {
    "text": "the challenges are at today are reliability latency and cost and",
    "start": "403600",
    "end": "409280"
  },
  {
    "text": "reliability is probably the number one u challenge for developers building with",
    "start": "409280",
    "end": "415039"
  },
  {
    "text": "LLMs today and uh that directly comes from the fact that LLMs are",
    "start": "415039",
    "end": "420560"
  },
  {
    "text": "nondeterministic in nature um which means in in simple words uh given given",
    "start": "420560",
    "end": "426160"
  },
  {
    "text": "a given the same input multiple times there is no guarantee that you will you would get the same response every single",
    "start": "426160",
    "end": "432400"
  },
  {
    "text": "time um so because of the nondeterministic nature um and and when",
    "start": "432400",
    "end": "438160"
  },
  {
    "text": "you are dealing with multiple agents with multiple models in a single architecture it's it's really hard to um",
    "start": "438160",
    "end": "446400"
  },
  {
    "text": "build like a reliable system that achieves a given goal uh every single",
    "start": "446400",
    "end": "451599"
  },
  {
    "text": "time uh which means we are talking about things like evaluating the performance of of models that is specific to",
    "start": "451599",
    "end": "459039"
  },
  {
    "text": "applications there is model eval evals uh which for for which we have like llm",
    "start": "459039",
    "end": "464960"
  },
  {
    "text": "marina and things like that but then when when you're actually building genai applications the metrics that you would",
    "start": "464960",
    "end": "471599"
  },
  {
    "text": "want to evaluate on are very subjective in nature it it completely depends on the use case that you are you are trying",
    "start": "471599",
    "end": "478080"
  },
  {
    "text": "to achieve with with models right so if you're building like a summarization agent um again like how well it's",
    "start": "478080",
    "end": "486560"
  },
  {
    "text": "summarizing the the given input is really dependent on uh what how well you",
    "start": "486560",
    "end": "491599"
  },
  {
    "text": "would want it to summarize so it's it's going to be very subjective in nature and secondly we are also starting to see",
    "start": "491599",
    "end": "497919"
  },
  {
    "text": "a multimodality of um uh of of data right so you have text uh now we are",
    "start": "497919",
    "end": "504720"
  },
  {
    "text": "talking about voice we there is images there is video um that that brings about",
    "start": "504720",
    "end": "509759"
  },
  {
    "text": "its own complexities to it um the architecture is is still evolving uh",
    "start": "509759",
    "end": "515518"
  },
  {
    "text": "like I like I showed in the first slide there's like a bunch of different components that are evolving on a",
    "start": "515519",
    "end": "520560"
  },
  {
    "text": "day-to-day basis there are the best practices are still being figured out so the complex nature of the architecture",
    "start": "520560",
    "end": "527279"
  },
  {
    "text": "is again adding uh adding a lot more reason for for the sake of reliability",
    "start": "527279",
    "end": "534080"
  },
  {
    "text": "and agentic loops uh there there is this common issue where uh LLMs get stuck in",
    "start": "534080",
    "end": "539760"
  },
  {
    "text": "a loop and uh typically if you if if there is a human in the loop they they interfere and they get the get the model",
    "start": "539760",
    "end": "547279"
  },
  {
    "text": "out of it so uh and and also the choices developers have in terms of the number",
    "start": "547279",
    "end": "553360"
  },
  {
    "text": "of models that are out there there is open source models there is reasoning models there is closed source models and",
    "start": "553360",
    "end": "558800"
  },
  {
    "text": "things like that so switching between different models again adds to the complexity uh when we talk about latency",
    "start": "558800",
    "end": "566560"
  },
  {
    "text": "um we we are primarily talking about um tokens uh tokens are what the models",
    "start": "566560",
    "end": "572480"
  },
  {
    "text": "generate uh two main metrics drive latency one is time to first token when",
    "start": "572480",
    "end": "577600"
  },
  {
    "text": "you're streaming and uh tokens per second and cost is also even though cost",
    "start": "577600",
    "end": "583040"
  },
  {
    "text": "is like going down by the day cost still seems to be like a big thing that developers are uh worried",
    "start": "583040",
    "end": "590600"
  },
  {
    "text": "about so what do developers actually want right so developers today um up",
    "start": "590600",
    "end": "596399"
  },
  {
    "text": "until probably end of last year people were excited they were building agentic",
    "start": "596399",
    "end": "602000"
  },
  {
    "text": "applications and uh it was relatively easier to build um magical products and",
    "start": "602000",
    "end": "608800"
  },
  {
    "text": "product experiences and uh put put out a demo for it but then like when when you",
    "start": "608800",
    "end": "615120"
  },
  {
    "text": "would want to go to production the gap between like a shiny demo and going to the production has been like pretty",
    "start": "615120",
    "end": "621839"
  },
  {
    "text": "pretty large and the reason for that is uh the best practices around tracing LLM",
    "start": "621839",
    "end": "627120"
  },
  {
    "text": "applications and evaluating and u measuring accuracy baselining the",
    "start": "627120",
    "end": "633680"
  },
  {
    "text": "performance and putting together a process for continuously improving it uh was either non-existent or it was just",
    "start": "633680",
    "end": "640320"
  },
  {
    "text": "it was still being figured out so developers are starting to realize traceability is going to play like a big",
    "start": "640320",
    "end": "646800"
  },
  {
    "text": "role um and they're starting to adopt uh open telemetry based uh tracing for uh",
    "start": "646800",
    "end": "654160"
  },
  {
    "text": "for for their genai stack so let's frame the observability problem for this new agentic stack right",
    "start": "654160",
    "end": "661600"
  },
  {
    "text": "so uh I have put together like a comparison over here across a bunch of different categories um let's start with",
    "start": "661600",
    "end": "668079"
  },
  {
    "text": "determinism right so like I mentioned in the traditional software stack things were pretty deterministic in nature you",
    "start": "668079",
    "end": "674399"
  },
  {
    "text": "were either dealing with failures or you were dealing with successes um but in the agentic stack it's non-deterministic",
    "start": "674399",
    "end": "680880"
  },
  {
    "text": "in nature uh like I like I mentioned earlier there's no guarantee that a model is going to give out the same",
    "start": "680880",
    "end": "686720"
  },
  {
    "text": "response uh given given an input multiple times uh secondly signals um",
    "start": "686720",
    "end": "693040"
  },
  {
    "text": "again in the traditional stack logs traces metrics these were the signals uh",
    "start": "693040",
    "end": "698079"
  },
  {
    "text": "there were clear thresholds that you can set depending on your use case and uh clear patterns that you can look for to",
    "start": "698079",
    "end": "705200"
  },
  {
    "text": "understand basically uh whe whether things are going wrong to to do anomaly detection and things like that uh but in",
    "start": "705200",
    "end": "712240"
  },
  {
    "text": "the agentic stack the signals are gathered from the prompts and completions or the inputs and outputs to",
    "start": "712240",
    "end": "718640"
  },
  {
    "text": "the models and also the vector vector scores um from the retrieve from from",
    "start": "718640",
    "end": "724320"
  },
  {
    "text": "the retrieved outputs of vector databases so developers increasingly",
    "start": "724320",
    "end": "729519"
  },
  {
    "text": "want to see the uh inputs going into the models and the outputs coming out out of the models uh because that that tells",
    "start": "729519",
    "end": "737279"
  },
  {
    "text": "you whether the performance of the model is good or bad um and they also would like to see the retrieved results from a",
    "start": "737279",
    "end": "744399"
  },
  {
    "text": "database along with their scores and whether the correct uh results are being passed over to the model to see where",
    "start": "744399",
    "end": "750880"
  },
  {
    "text": "the bottlenecks are whether the retrieval pipeline needs to be improved or the model needs to be swapped out or",
    "start": "750880",
    "end": "757040"
  },
  {
    "text": "the model needs to be t tuned um next is the state u again like in the",
    "start": "757040",
    "end": "762560"
  },
  {
    "text": "traditional stack uh we had a very explicit um state uh it was either",
    "start": "762560",
    "end": "768560"
  },
  {
    "text": "designed uh uh previously like during during the development process or it was",
    "start": "768560",
    "end": "774959"
  },
  {
    "text": "um it was very clear as to what state the system can be in at any particular time uh but in the case of agentic stack",
    "start": "774959",
    "end": "782800"
  },
  {
    "text": "while we have the traditional notion of states we we are also uh having the",
    "start": "782800",
    "end": "788160"
  },
  {
    "text": "context window of the model as well as the memory uh which puts the stack in",
    "start": "788160",
    "end": "793200"
  },
  {
    "text": "different states it's almost like a fluid fluid state um uh and and if you layer in u tool calling on top of that",
    "start": "793200",
    "end": "801680"
  },
  {
    "text": "then it it becomes um the the number of states the the system can be in um",
    "start": "801680",
    "end": "806959"
  },
  {
    "text": "increases quite rapidly execution um again like in the",
    "start": "806959",
    "end": "812240"
  },
  {
    "text": "traditional stack it was like static execution you had like different systems different services in the agentic stack",
    "start": "812240",
    "end": "818880"
  },
  {
    "text": "we are talking about LLMdriven execution um especially with things like tool calling testing uh we had unit tests now",
    "start": "818880",
    "end": "827440"
  },
  {
    "text": "we are talking about evalu uh for uh for testing the performance of",
    "start": "827440",
    "end": "833680"
  },
  {
    "text": "of your system uh root cause analysis stack traces were are pretty common uh",
    "start": "833680",
    "end": "839120"
  },
  {
    "text": "in the case of agentic stack uh we are talking about semantics and the context that is being passed to the",
    "start": "839120",
    "end": "845560"
  },
  {
    "text": "LLM tooling is continuing to evolve in the agentic stack it's becoming complex",
    "start": "845560",
    "end": "851120"
  },
  {
    "text": "and finally the feedback uh in the traditional stack the feedback was more of an opt optional thing um as long as",
    "start": "851120",
    "end": "858320"
  },
  {
    "text": "you had like pretty solid unit test coverage and integration tests uh it was more than sufficient to guarantee the",
    "start": "858320",
    "end": "864079"
  },
  {
    "text": "the performance while in the agentics track the feedback is becoming more and more required both from the end users as",
    "start": "864079",
    "end": "870639"
  },
  {
    "text": "well as uh developers who are evaluating the performance of of their entire application so now that we know about u",
    "start": "870639",
    "end": "879360"
  },
  {
    "text": "the different problems that that we are faced with u the role of observability",
    "start": "879360",
    "end": "884560"
  },
  {
    "text": "assets is also extending when it comes to AI agents um beyond just debugging by",
    "start": "884560",
    "end": "892000"
  },
  {
    "text": "looking at traces uh more and more developers are starting to use traces as",
    "start": "892000",
    "end": "898720"
  },
  {
    "text": "like a rich source of information for doing various other things outside of observability for instance traces are a",
    "start": "898720",
    "end": "905839"
  },
  {
    "text": "good source of information for building eval sets because uh once you have the application in production you the traces",
    "start": "905839",
    "end": "914079"
  },
  {
    "text": "are going to contain uh the inputs and outputs to the models it's going to contain the retrievalss it's going to",
    "start": "914079",
    "end": "919920"
  },
  {
    "text": "contain the attributes that you have set up the model with so all this",
    "start": "919920",
    "end": "925440"
  },
  {
    "text": "information is really useful to build build an eval set and uh test it against",
    "start": "925440",
    "end": "932079"
  },
  {
    "text": "like let's say you want to switch from open AI to anthropic um you can you can use these traces to test it against a",
    "start": "932079",
    "end": "938399"
  },
  {
    "text": "new model before trying to switch out to that model so testing an eval is like a big use case for these traces finetuning",
    "start": "938399",
    "end": "945600"
  },
  {
    "text": "is like another big use case um because these uh traces are representative of",
    "start": "945600",
    "end": "950800"
  },
  {
    "text": "production data uh after tracing your application for a bit of time you can extract and uh you can extract the",
    "start": "950800",
    "end": "958399"
  },
  {
    "text": "inputs and outputs out of uh the finetune uh the the traces label them",
    "start": "958399",
    "end": "963759"
  },
  {
    "text": "and uh use it for fine-tuning like a like an open source model and swap out the model that you're currently using uh",
    "start": "963759",
    "end": "970160"
  },
  {
    "text": "and and data labeling of course like which feeds back into fine-tuning process um the second category is UX",
    "start": "970160",
    "end": "978440"
  },
  {
    "text": "optimization so prompt engineering is is continuing to exist as a big theme and",
    "start": "978440",
    "end": "985279"
  },
  {
    "text": "uh one of the things that uh developers are starting to do is they are uh because the prompts are being traced by",
    "start": "985279",
    "end": "992399"
  },
  {
    "text": "the traced in the spans um people want to test with multiple prompts and",
    "start": "992399",
    "end": "998639"
  },
  {
    "text": "understand how different prompts are behaving out in the in the production um and and you can use these traces again",
    "start": "998639",
    "end": "1005519"
  },
  {
    "text": "for doing AB testing uh regression testing and and whatnot and you can also",
    "start": "1005519",
    "end": "1010880"
  },
  {
    "text": "derive user specific um uh memory and context like uh you you can attach user",
    "start": "1010880",
    "end": "1017519"
  },
  {
    "text": "ids to to the spans and uh aggregate traces for a specific user and and feed",
    "start": "1017519",
    "end": "1024160"
  },
  {
    "text": "that back into the memory layer for that user for enriching the LLM with additional context and and finally",
    "start": "1024160",
    "end": "1030720"
  },
  {
    "text": "security and compliance um things like prompt injections are becoming uh slowly",
    "start": "1030720",
    "end": "1036319"
  },
  {
    "text": "starting to become a thing and uh auditability of u the trace logs are also becoming important because it",
    "start": "1036319",
    "end": "1043678"
  },
  {
    "text": "contains um uh like depending on the use case it contains like very important",
    "start": "1043679",
    "end": "1048960"
  },
  {
    "text": "information the prompts and completions so auditability of that um has been like",
    "start": "1048960",
    "end": "1054320"
  },
  {
    "text": "a uh like a use case from from these phrases so the observability for AI",
    "start": "1054320",
    "end": "1059919"
  },
  {
    "text": "agents is kind of like the the role of it is starting to emerge and and evolve uh into additional use cases as well so",
    "start": "1059919",
    "end": "1068080"
  },
  {
    "text": "what should I observe then right so um when when it comes to um observing like",
    "start": "1068080",
    "end": "1075840"
  },
  {
    "text": "an AI agentic stack uh we can put put that right now into three broad categories uh the first one being agent",
    "start": "1075840",
    "end": "1083760"
  },
  {
    "text": "or LLM level tracing uh like I said prompts and completions um definitely",
    "start": "1083760",
    "end": "1090000"
  },
  {
    "text": "that's that's one thing uh like developers are finding value out of tool calls model settings like the",
    "start": "1090000",
    "end": "1097679"
  },
  {
    "text": "temperature settings of a model the API settings of a model things like that the second category is storage and memory",
    "start": "1097679",
    "end": "1103840"
  },
  {
    "text": "tracing the queries that are being u used for hitting the mod hitting the",
    "start": "1103840",
    "end": "1110160"
  },
  {
    "text": "vector database or or the memory layers and the retrieved results along with their scores uh the the ranked results",
    "start": "1110160",
    "end": "1117280"
  },
  {
    "text": "uh latency and failures and and finally framework level tracing uh these are the orchestration frameworks like langchain",
    "start": "1117280",
    "end": "1123919"
  },
  {
    "text": "llama index crew AI and and agno and others um because frameworks are doing",
    "start": "1123919",
    "end": "1130320"
  },
  {
    "text": "the orchestration at the higher level and under the hood multiple u agents or",
    "start": "1130320",
    "end": "1135440"
  },
  {
    "text": "multiple models could be called external tools could be invoked uh the control flow of orchestration uh control flow of",
    "start": "1135440",
    "end": "1142720"
  },
  {
    "text": "the highle framework becomes very important to trace to understand uh the",
    "start": "1142720",
    "end": "1148080"
  },
  {
    "text": "behavior of an agentic system and also agents are starting to pass messages to each other uh using model context",
    "start": "1148080",
    "end": "1155200"
  },
  {
    "text": "protocol and things and and other other techniques so what is being passed between different agents and whether",
    "start": "1155200",
    "end": "1161600"
  },
  {
    "text": "they are passing the right things and to understand in in a multi- aent system understanding which agents need to be",
    "start": "1161600",
    "end": "1168320"
  },
  {
    "text": "tuned uh based on all the all the three categories of traces are becoming uh",
    "start": "1168320",
    "end": "1174080"
  },
  {
    "text": "more important and finally um a single unified trace per user request paints",
    "start": "1174080",
    "end": "1180880"
  },
  {
    "text": "like the big picture of how well your your system is u is is is working at at",
    "start": "1180880",
    "end": "1187520"
  },
  {
    "text": "any point in time so the good news is uh we have the open",
    "start": "1187520",
    "end": "1193440"
  },
  {
    "text": "telemetry genai semantic conventions uh special interest group um and u we we",
    "start": "1193440",
    "end": "1200960"
  },
  {
    "text": "have made tremendous progress in the last uh 14 months or so since the inception of this uh group uh so what",
    "start": "1200960",
    "end": "1208720"
  },
  {
    "text": "are some of the things that we have done so far right so um first of all the the Otal uh genai semantic conventions group",
    "start": "1208720",
    "end": "1216799"
  },
  {
    "text": "is responsible for um the semantic conventions of the traces and the spans",
    "start": "1216799",
    "end": "1222000"
  },
  {
    "text": "so essentially um coming up with standards for modeling the the the",
    "start": "1222000",
    "end": "1227840"
  },
  {
    "text": "different attributes and what needs to be what needs to get recorded as events what needs to get recorded as attributes",
    "start": "1227840",
    "end": "1233760"
  },
  {
    "text": "the naming of these attributes and things like that so that no matter which whichever observability vendor or client",
    "start": "1233760",
    "end": "1239760"
  },
  {
    "text": "you use uh you have like a pretty seamless and standard experience uh the the good thing is",
    "start": "1239760",
    "end": "1246240"
  },
  {
    "text": "there are multiple besides the official open telemetry libraries uh that are",
    "start": "1246240",
    "end": "1251280"
  },
  {
    "text": "being worked upon there are multiple other uh open source projects that are open telemetry based so there is a lot",
    "start": "1251280",
    "end": "1257120"
  },
  {
    "text": "of optionality for developers to adopt today and uh there are some early",
    "start": "1257120",
    "end": "1262799"
  },
  {
    "text": "proposals for vector database semantic conventions and agentic observability as well which is which is currently work in",
    "start": "1262799",
    "end": "1270520"
  },
  {
    "text": "progress so uh as as a group um we are encouraging framework developers and LLM",
    "start": "1270520",
    "end": "1278080"
  },
  {
    "text": "vendors to also adopt these standards uh one one one uh good thing is like",
    "start": "1278080",
    "end": "1284919"
  },
  {
    "text": "OpenAI's recent AI agent SDK uh ships with the standard semantic conventions",
    "start": "1284919",
    "end": "1290559"
  },
  {
    "text": "for tracing uh with open telemetry and more and more uh framework developers are starting to take notice and uh they",
    "start": "1290559",
    "end": "1297760"
  },
  {
    "text": "are either instrumenting it within the framework or we are instrumenting based on the semantic",
    "start": "1297760",
    "end": "1304440"
  },
  {
    "text": "conventions so you can you can scan the QR code at the bottom right to see the",
    "start": "1304440",
    "end": "1309919"
  },
  {
    "text": "running notes of the group and uh all the relevant links are also published there um I highly re encourage you all",
    "start": "1309919",
    "end": "1317600"
  },
  {
    "text": "to join the um weekly calls if you have any topics to talk about or if you have",
    "start": "1317600",
    "end": "1323600"
  },
  {
    "text": "any questions uh it's it's it's gotten together as a big group compared to even",
    "start": "1323600",
    "end": "1328720"
  },
  {
    "text": "like 6 months ago um so what are some of the semantic conventions right so the it's it's broadly categorized into three",
    "start": "1328720",
    "end": "1334960"
  },
  {
    "text": "three um groups the three categories first one being events then metrics and",
    "start": "1334960",
    "end": "1340400"
  },
  {
    "text": "the spans uh events are where we are currently capturing prompts and completions although there is like a",
    "start": "1340400",
    "end": "1347120"
  },
  {
    "text": "active uh discussion happening right now as to where we need to actually capture the events i'll come come to it in a",
    "start": "1347120",
    "end": "1352840"
  },
  {
    "text": "second um some of the considerations are privacy size of uh the spans and uh",
    "start": "1352840",
    "end": "1359919"
  },
  {
    "text": "performance depending on the back end uh that's uh back end in the database where we are storing these spans uh on the",
    "start": "1359919",
    "end": "1366320"
  },
  {
    "text": "metric side like I mentioned uh tokens uh like input tokens and output tokens",
    "start": "1366320",
    "end": "1372080"
  },
  {
    "text": "um cached tokens things like that for for the sake of tracking cost and also",
    "start": "1372080",
    "end": "1377840"
  },
  {
    "text": "performance metrics such as time to first token in the case of uh um uh the inference as well as tokens per second",
    "start": "1377840",
    "end": "1384640"
  },
  {
    "text": "in the case of uh streaming responses and finally um on the spans we are",
    "start": "1384640",
    "end": "1390000"
  },
  {
    "text": "recording all the request and response attributes uh a quick shout out to all",
    "start": "1390000",
    "end": "1396000"
  },
  {
    "text": "the representatives from uh companies like Microsoft Google um trace loop",
    "start": "1396000",
    "end": "1402039"
  },
  {
    "text": "parise u a lot of uh representatives are starting to come together as a group so",
    "start": "1402039",
    "end": "1407440"
  },
  {
    "text": "if you are either dealing with genai observability or you're working on it um",
    "start": "1407440",
    "end": "1412960"
  },
  {
    "text": "feel free to join the uh weekly calls some of the hot topics right now at uh",
    "start": "1412960",
    "end": "1420720"
  },
  {
    "text": "the semantic conventions group are tracing prompts and completion uh not just for text but also for multimodal",
    "start": "1420720",
    "end": "1427039"
  },
  {
    "text": "inputs and outputs so uh do you like when when we are talking about videos and images and audio uh obviously the",
    "start": "1427039",
    "end": "1434880"
  },
  {
    "text": "the size of the span uh becomes large and you don't want to store um a lot of",
    "start": "1434880",
    "end": "1440799"
  },
  {
    "text": "information in them but then like you still want to trace uh the the inputs",
    "start": "1440799",
    "end": "1446159"
  },
  {
    "text": "and outputs in the even in the case of multimodal multimodal uh scenarios because uh that's that's where you kind",
    "start": "1446159",
    "end": "1452480"
  },
  {
    "text": "of like determine the performance of your models so uh we are starting to have a discussion around how would you",
    "start": "1452480",
    "end": "1458559"
  },
  {
    "text": "like store audio or images or video like uh one of the proposals is uh storing",
    "start": "1458559",
    "end": "1464640"
  },
  {
    "text": "them in a blob storage and attaching the reference to it to the spans in those",
    "start": "1464640",
    "end": "1470480"
  },
  {
    "text": "scenarios like search and and indexing becomes like a like an issue so things like that and also where would you store",
    "start": "1470480",
    "end": "1477360"
  },
  {
    "text": "the attributes in general uh the prompts and completion attributes like do we want to store them in in the attributes",
    "start": "1477360",
    "end": "1483120"
  },
  {
    "text": "or do we want to store them in the events or log events uh depending on various uh pros and cons u we are we are",
    "start": "1483120",
    "end": "1489679"
  },
  {
    "text": "starting to figure out what would be the best experience uh for the uh for the developers and secondly uh tracing end",
    "start": "1489679",
    "end": "1497279"
  },
  {
    "text": "user feedback and evaluations is becoming another big topic because uh because evaluations is is essent",
    "start": "1497279",
    "end": "1503840"
  },
  {
    "text": "Essentially how you you can baseline the performance of your agentic application and uh the prompt and completion data is",
    "start": "1503840",
    "end": "1511120"
  },
  {
    "text": "is stored in spans you you want the client to show",
    "start": "1511120",
    "end": "1516559"
  },
  {
    "text": "some sort of a way for the developers to run evaluations on top of it and uh",
    "start": "1516559",
    "end": "1521600"
  },
  {
    "text": "typically you you don't um uh you don't you don't modify the traced data u or",
    "start": "1521600",
    "end": "1528080"
  },
  {
    "text": "you don't you don't want to attach the scores of these evaluations back to the spans so how would you model the",
    "start": "1528080",
    "end": "1534080"
  },
  {
    "text": "database on the back end uh whe whether you would want to store user feedback like G given by the end users as thumbs",
    "start": "1534080",
    "end": "1541440"
  },
  {
    "text": "up and thumbs down uh actions do you want to like store them in the span attributes uh what about the developer",
    "start": "1541440",
    "end": "1548720"
  },
  {
    "text": "done attributes developer done evaluations like why would you want to store that things like that so uh these",
    "start": "1548720",
    "end": "1554640"
  },
  {
    "text": "are some of the hot top hot topics that we have have had multiple discussions on and a lot of inputs from various",
    "start": "1554640",
    "end": "1561600"
  },
  {
    "text": "stakeholders across multiple companies but um the good news is we are starting to align on a bunch of these uh",
    "start": "1561600",
    "end": "1567840"
  },
  {
    "text": "different topics at the moment so uh if if I'm building an agentic application uh how can I set up",
    "start": "1567840",
    "end": "1575520"
  },
  {
    "text": "observability right so um there are obviously uh two components to it one is",
    "start": "1575520",
    "end": "1582000"
  },
  {
    "text": "the vendor comp the client component the observability client and uh the other one is the SDK the open open telemetry",
    "start": "1582000",
    "end": "1589440"
  },
  {
    "text": "SDK on the client side we have uh a bunch of different projects that are dedicated for genai observability um the",
    "start": "1589440",
    "end": "1596480"
  },
  {
    "text": "the open source and self-hostable ones I've listed down over here and on the SDK side um besides the official Open",
    "start": "1596480",
    "end": "1604480"
  },
  {
    "text": "Telemetry SDK where we have support for OpenAI Vortex um we have support for AWS",
    "start": "1604480",
    "end": "1610640"
  },
  {
    "text": "Bedrock uh we also have some of these other projects um uh like Open Lamentary",
    "start": "1610640",
    "end": "1616000"
  },
  {
    "text": "Langrays uh Elastics EOT and things like that um and and it doesn't matter which",
    "start": "1616000",
    "end": "1621919"
  },
  {
    "text": "SDK you use like most most of them adhere to the genai semantic conventions",
    "start": "1621919",
    "end": "1627039"
  },
  {
    "text": "so all of them are going to be uh generating spans uh in a in a very similar data format and the best part is",
    "start": "1627039",
    "end": "1634320"
  },
  {
    "text": "um uh it's it's it's non-intrusive in the sense that you can just install the library and set it up uh you don't need",
    "start": "1634320",
    "end": "1641440"
  },
  {
    "text": "to uh plump it in your codebase you just install it and import the open telemetry library and uh it's it's almost close to",
    "start": "1641440",
    "end": "1648159"
  },
  {
    "text": "zero code instrumentation uh where the imported uh LLM's client SDK or vector",
    "start": "1648159",
    "end": "1654960"
  },
  {
    "text": "DB's client SDK is patched at runtime and spans are generated and exported back uh to your uh to your observability",
    "start": "1654960",
    "end": "1662279"
  },
  {
    "text": "vendor so a typical setup looks something like this you have the genai applications or multi- aent agentic",
    "start": "1662279",
    "end": "1668320"
  },
  {
    "text": "system on the left side uh you install the SDK on them and once you install it",
    "start": "1668320",
    "end": "1674399"
  },
  {
    "text": "they are going to start generating uh traces uh that that that are going to capture the um cap capture inputs and",
    "start": "1674399",
    "end": "1682399"
  },
  {
    "text": "outputs from the models capture queries and retrievalss from vector DBs uh capture the control flow from frameworks",
    "start": "1682399",
    "end": "1688880"
  },
  {
    "text": "and they're going to batch it and you can either set up like a collector or not you can directly send it to a open",
    "start": "1688880",
    "end": "1695120"
  },
  {
    "text": "telemetry compatible observability client um such as IBM in Stana or",
    "start": "1695120",
    "end": "1700320"
  },
  {
    "text": "Elastics APM or Data Dog or Graphfana or Prometheus um and uh it's just going to",
    "start": "1700320",
    "end": "1706080"
  },
  {
    "text": "receive just fine um so it's it's kind of uh very flexible setup you just you",
    "start": "1706080",
    "end": "1711440"
  },
  {
    "text": "just install the SDK and if you already have like a working observability setup uh you can just layer in observability",
    "start": "1711440",
    "end": "1717520"
  },
  {
    "text": "for JAI applications on top of it so uh what are again like I I just",
    "start": "1717520",
    "end": "1724799"
  },
  {
    "text": "mentioned the typical setup but there are multiple ways to instrument your agentic applications right so it can be",
    "start": "1724799",
    "end": "1730480"
  },
  {
    "text": "categorized into three broad categories obviously the first one is installing the official open telemetry uh libraries",
    "start": "1730480",
    "end": "1737200"
  },
  {
    "text": "uh we have libraries for Python TypeScript and other languages as well",
    "start": "1737200",
    "end": "1742320"
  },
  {
    "text": "although Python has the most coverage for geni applications uh at the moment um so currently the official ones we",
    "start": "1742320",
    "end": "1749679"
  },
  {
    "text": "have openai bedrock and vert.xai uh bunch of and and the openi client SDK",
    "start": "1749679",
    "end": "1755360"
  },
  {
    "text": "works with like pretty much all other model providers so if you're consuming uh LLMs using open as client SDK you can",
    "start": "1755360",
    "end": "1761840"
  },
  {
    "text": "just use use the official instrumentation from uh open telemetry to trace that or you can install the",
    "start": "1761840",
    "end": "1769600"
  },
  {
    "text": "third party open source projects out there uh which includes langrace open lmmetry or open lit um we also have",
    "start": "1769600",
    "end": "1777520"
  },
  {
    "text": "extensive support for vector DBs agentic frameworks and things like that even though the semantics have not yet been",
    "start": "1777520",
    "end": "1783600"
  },
  {
    "text": "defined for uh defined for some of these components uh it kind of serves as a way",
    "start": "1783600",
    "end": "1789120"
  },
  {
    "text": "for us to test out and uh bring back some of our learnings to the semantic conventions to define standards",
    "start": "1789120",
    "end": "1797000"
  },
  {
    "text": "around oops we'll just finish it real quick um and finally we have u you can",
    "start": "1797000",
    "end": "1804080"
  },
  {
    "text": "write your own instrumentation using uh the conventions so this is the full stack",
    "start": "1804080",
    "end": "1810080"
  },
  {
    "text": "observability u market map at the moment uh like I mentioned it's very similar to",
    "start": "1810080",
    "end": "1815360"
  },
  {
    "text": "the first slide we have the frameworks we have vector databases infrastructure",
    "start": "1815360",
    "end": "1820559"
  },
  {
    "text": "um like GPU and CPU for serving the models u application at the top and",
    "start": "1820559",
    "end": "1827120"
  },
  {
    "text": "vector databases as well finally some demo traces what it",
    "start": "1827120",
    "end": "1832320"
  },
  {
    "text": "looks like when when we are observing a multi- aent system so this one is like a",
    "start": "1832320",
    "end": "1837679"
  },
  {
    "text": "multi- aent system built using Agno um it it traces the orchestration layer it",
    "start": "1837679",
    "end": "1844080"
  },
  {
    "text": "traces the LLM layer uh as you can see like messages are being passed uh between uh different agents and finally",
    "start": "1844080",
    "end": "1851600"
  },
  {
    "text": "there is like a top level agent that uh responds to responds to the final output",
    "start": "1851600",
    "end": "1857760"
  },
  {
    "text": "uh this one is like a typical uh very simple simple implementation of uh a retrieval augmented uh generation uh so",
    "start": "1857760",
    "end": "1865360"
  },
  {
    "text": "you have like a framework at the top you have embeddings um you have the vector",
    "start": "1865360",
    "end": "1870880"
  },
  {
    "text": "database which is the which is VB8 in this case and then finally uh the open AI um but yeah that's uh that's pretty",
    "start": "1870880",
    "end": "1878559"
  },
  {
    "text": "much it um thank you for listening i'm happy to take any questions that you may have",
    "start": "1878559",
    "end": "1884970"
  },
  {
    "text": "[Applause]",
    "start": "1884970",
    "end": "1890499"
  }
]
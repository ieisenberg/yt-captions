[
  {
    "start": "0",
    "end": "103000"
  },
  {
    "text": "okay today we are talking with richard hartman with grafana labs an",
    "start": "640",
    "end": "7680"
  },
  {
    "text": "intro to open source observability with grafana prometheus loki and tempo",
    "start": "7680",
    "end": "13040"
  },
  {
    "text": "everyone please uh remember that during the webinar you're not able to speak as an attendee",
    "start": "13040",
    "end": "19199"
  },
  {
    "text": "you're using the chat i see already so oh say hello and",
    "start": "19199",
    "end": "25760"
  },
  {
    "text": "for richard um we'll get you as many of those as we can at the end and um we can even stay on a",
    "start": "25760",
    "end": "32160"
  },
  {
    "text": "little bit longer since we're running late to take care of that this is an official official webinar of",
    "start": "32160",
    "end": "37760"
  },
  {
    "text": "the cncf and as such is a subject to the cncf code of conduct please do not add",
    "start": "37760",
    "end": "43200"
  },
  {
    "text": "anything to the chat or questions that would be in violation of the code of conduct and please be respectful of your",
    "start": "43200",
    "end": "49520"
  },
  {
    "text": "participants and presenters please also note that the recording and slides will be posted later today to the",
    "start": "49520",
    "end": "55840"
  },
  {
    "text": "cncf online programs page under online programs they were also available via",
    "start": "55840",
    "end": "61440"
  },
  {
    "text": "this registration link which will take you to our online programs youtube playlist",
    "start": "61440",
    "end": "67600"
  },
  {
    "text": "with that i'm going to hand it over to richard so we can kick things off thank you again for hanging",
    "start": "67600",
    "end": "75200"
  },
  {
    "text": "thank you thank you libby uh thank you everyone um word of warning i keep getting pop-ups",
    "start": "77040",
    "end": "83119"
  },
  {
    "text": "from from the platform that my internet connection is unstable which i don't believe is the case but",
    "start": "83119",
    "end": "89520"
  },
  {
    "text": "something is is is broken-ish so if i drop or anything um i'll try to rejoin",
    "start": "89520",
    "end": "96640"
  },
  {
    "text": "so let's get started intro to open source observable team a little bit of",
    "start": "96640",
    "end": "102640"
  },
  {
    "text": "validating that most of my life i've worked in engineering architecture operation",
    "start": "102640",
    "end": "108640"
  },
  {
    "start": "103000",
    "end": "177000"
  },
  {
    "text": "worlds so i i have strong opinions about about the right tools and about not perfect or",
    "start": "108640",
    "end": "116000"
  },
  {
    "text": "not good enough tools oftentimes you have this this parrot thing there",
    "start": "116000",
    "end": "122320"
  },
  {
    "text": "where you have breaks between different media where you have breaks between different um",
    "start": "122320",
    "end": "129360"
  },
  {
    "text": "trains of thought like how to how to index your data how how the mental modeling works maybe one thing has the",
    "start": "129360",
    "end": "136080"
  },
  {
    "text": "one color the other thing is the other color or one of the things left to right the other is like right to left doesn't",
    "start": "136080",
    "end": "141840"
  },
  {
    "text": "matter you have breaks between your different systems too often which in",
    "start": "141840",
    "end": "147280"
  },
  {
    "text": "turn means uh that way too often you um you end up paying extra cost in mental overhead or",
    "start": "147280",
    "end": "153760"
  },
  {
    "text": "in in automation overhead it's not seamless you need to switch mental modes when you go from your logs to your",
    "start": "153760",
    "end": "159280"
  },
  {
    "text": "traces or what have you which um is is not nice and it just it adds",
    "start": "159280",
    "end": "164720"
  },
  {
    "text": "friction and you don't really need that at like five in the morning on a sunday when you've got when you've gotten a",
    "start": "164720",
    "end": "170000"
  },
  {
    "text": "pager so let's try and rethink uh what what we actually want to do here and i'm going",
    "start": "170000",
    "end": "176640"
  },
  {
    "text": "to to go through a little bit of of like the philosophy of observability and a few buzzwords",
    "start": "176640",
    "end": "182480"
  },
  {
    "start": "177000",
    "end": "430000"
  },
  {
    "text": "as a as a foundation let's say um for what we are then talking about",
    "start": "182480",
    "end": "190239"
  },
  {
    "text": "um there is um a thing where the cloud native scale is",
    "start": "190239",
    "end": "197360"
  },
  {
    "text": "basically what internet scale was two decades ago and that's kind of important to keep in mind because a lot of of",
    "start": "197360",
    "end": "203519"
  },
  {
    "text": "issues which we see in the cloud native world have already been solved in different contexts",
    "start": "203519",
    "end": "209120"
  },
  {
    "text": "before us and it's always a good idea to to look at what engineers before us",
    "start": "209120",
    "end": "214799"
  },
  {
    "text": "did to to solve problems like not the specific implementations because usually they don't fit their age if they're too",
    "start": "214799",
    "end": "220720"
  },
  {
    "text": "old or the new age um but the underlying concepts like for example um computer networks the internet",
    "start": "220720",
    "end": "227599"
  },
  {
    "text": "also power networks a lot of those tend to run on metrics because this is already a predestination of",
    "start": "227599",
    "end": "234239"
  },
  {
    "text": "of what you care about as as a domain subject expert um so it's it's always good to look back",
    "start": "234239",
    "end": "243439"
  },
  {
    "text": "at what has been done before and what worked not from the specific implementation but from a an engineering",
    "start": "243439",
    "end": "250400"
  },
  {
    "text": "point of view as always in tech we have buzzwords um",
    "start": "250400",
    "end": "257199"
  },
  {
    "text": "buzzwords are usually usually",
    "start": "257199",
    "end": "262479"
  },
  {
    "text": "they have a kernel of truth um but um by the time there are buzzwords they have",
    "start": "262479",
    "end": "268000"
  },
  {
    "text": "lost most of that meaning um which is a pity but it also stands like why they were so successful",
    "start": "268000",
    "end": "275680"
  },
  {
    "text": "of particular note is is cargo culting cargo culting is defined as observing",
    "start": "275680",
    "end": "281360"
  },
  {
    "text": "behavior and observing success or results of that behavior",
    "start": "281360",
    "end": "286639"
  },
  {
    "text": "and emulating that behavior without actually applying the underlying thought",
    "start": "286639",
    "end": "292240"
  },
  {
    "text": "or fundamental engineering practices it comes from from indigenous people who observed",
    "start": "292240",
    "end": "299410"
  },
  {
    "text": "[Music] soldiers building building runways for planes and small control",
    "start": "299410",
    "end": "305360"
  },
  {
    "text": "towers and such and then the gods send send stuff from heavens which was basically",
    "start": "305360",
    "end": "310720"
  },
  {
    "text": "just uh logistics of the army but the perception was that just by building",
    "start": "310720",
    "end": "316639"
  },
  {
    "text": "runways and such you could get gifts from the gods and to this day those those things still",
    "start": "316639",
    "end": "323600"
  },
  {
    "text": "echo in in a few religions so that is observed behavior it becomes",
    "start": "323600",
    "end": "329120"
  },
  {
    "text": "part of culture but it it's not actually doing anything it's not actually pursuing the uh",
    "start": "329120",
    "end": "336639"
  },
  {
    "text": "the goals or or the the underlying um rationale and that's something which you",
    "start": "336639",
    "end": "342400"
  },
  {
    "text": "always need to be worried about it's not about just changing the name for a thing and anyone who was assistment yesterday",
    "start": "342400",
    "end": "348560"
  },
  {
    "text": "is sae today and you're done it's about actually changing the behavior and actually understanding why something is",
    "start": "348560",
    "end": "354960"
  },
  {
    "text": "successful not just observing that it is successful monitoring while i personally uh use",
    "start": "354960",
    "end": "361919"
  },
  {
    "text": "monitoring and observability more or less interchangeably and that is buzzwordy definition",
    "start": "361919",
    "end": "367039"
  },
  {
    "text": "monitoring has taken a little bit of a meaning of collecting data not using it um you have two extremes in this one",
    "start": "367039",
    "end": "372880"
  },
  {
    "text": "takes one thing where you have the full text indexing where you just in in a vain attempt",
    "start": "372880",
    "end": "378400"
  },
  {
    "text": "go after everything which you can find or data lake which outside of batch analysis is often a euphemism for um no",
    "start": "378400",
    "end": "386000"
  },
  {
    "text": "one is ever going to look at the thing um observability is is trying to reframe",
    "start": "386000",
    "end": "392000"
  },
  {
    "text": "that a little bit um about being able to ask new questions just observe what inputs what outputs a",
    "start": "392000",
    "end": "398639"
  },
  {
    "text": "system has and being able to deduce the internal state of that system from those inputs and outputs",
    "start": "398639",
    "end": "405039"
  },
  {
    "text": "as in ask questions which you didn't know you wanted to to ask before and that enables",
    "start": "405039",
    "end": "411599"
  },
  {
    "text": "humans to understand complex system but it also allows you to automate a lot of this so it's not just about determining that",
    "start": "411599",
    "end": "418800"
  },
  {
    "text": "something is in a certain state it's also about determining",
    "start": "418800",
    "end": "423919"
  },
  {
    "text": "why it is in a certain state and ideally how to get it out of that state if you cannot ask questions on the fly",
    "start": "423919",
    "end": "430400"
  },
  {
    "start": "430000",
    "end": "596000"
  },
  {
    "text": "like new questions it's just not observability another super important concept is",
    "start": "430400",
    "end": "435520"
  },
  {
    "text": "complexity where you have what i call fake complexity aka bad design which you can reduce and you should reduce in my",
    "start": "435520",
    "end": "442080"
  },
  {
    "text": "opinion like unless you have other engineering constraints like i don't know money gtm",
    "start": "442080",
    "end": "448000"
  },
  {
    "text": "maybe maybe compliance reasons what have you but outside of of actually reasons why you have complexity you should",
    "start": "448000",
    "end": "454160"
  },
  {
    "text": "always strive to get rid of complexity but you have real system inherent complexity as well and that can be moved",
    "start": "454160",
    "end": "461520"
  },
  {
    "text": "but it cannot be made to go away like state is always someone's else's problem you have all",
    "start": "461520",
    "end": "467520"
  },
  {
    "text": "your micro services they're stateless but someone has to maintain the database so that that complexity has to live",
    "start": "467520",
    "end": "474160"
  },
  {
    "text": "somewhere so yeah you can move it back and forth you can comparison mentalize and in my opinion my strong opinion you should",
    "start": "474160",
    "end": "481280"
  },
  {
    "text": "comparison mentalize it and you should distill it meaningfully and we have two different definitions of",
    "start": "481280",
    "end": "487199"
  },
  {
    "text": "of distilling this a the apis towards whatever the consumer slash user of the",
    "start": "487199",
    "end": "492720"
  },
  {
    "text": "thing is and b already start thinking about what you need to emit towards the observers",
    "start": "492720",
    "end": "498800"
  },
  {
    "text": "towards your operational teams so they can look at the thing",
    "start": "498800",
    "end": "504240"
  },
  {
    "text": "that is basically slis um sli slo sla often times people are confused what",
    "start": "504800",
    "end": "510319"
  },
  {
    "text": "they mean it's really really simple sli are several service level indicators what you measure objectives are what you",
    "start": "510319",
    "end": "516320"
  },
  {
    "text": "need to hit and agreement since when you need to start paying course someone",
    "start": "516320",
    "end": "521518"
  },
  {
    "text": "broke a contract a lot of of sre to me",
    "start": "521519",
    "end": "527600"
  },
  {
    "text": "is about aligning incentives across the org because if you have devs they want to ship code then",
    "start": "527600",
    "end": "533519"
  },
  {
    "text": "they want to ship new releases asap you have operational people who are paid",
    "start": "533519",
    "end": "538640"
  },
  {
    "text": "for for stuff not breaking so you have diametry diametrically",
    "start": "538640",
    "end": "543760"
  },
  {
    "text": "opposed incentives where the one group wants to move super quickly and the other group wants to move rather slowly",
    "start": "543760",
    "end": "550240"
  },
  {
    "text": "and carefully and so they always they always fight they always have strive course that's",
    "start": "550240",
    "end": "555519"
  },
  {
    "text": "built into literally into their compensation structure and into their complete organizational structure",
    "start": "555519",
    "end": "561120"
  },
  {
    "text": "there is one of the main things of sre to me is the concept of error budgets where everyone shares a budget for how",
    "start": "561120",
    "end": "568320"
  },
  {
    "text": "many errors a thing can have and if you hit those budgets it's fine but",
    "start": "568320",
    "end": "575200"
  },
  {
    "text": "it doesn't matter if this is due to new features or a b testing or a new deployment where the pm needed something",
    "start": "575200",
    "end": "581440"
  },
  {
    "text": "really really urgently or things always breaking if things break too often in operations the devs don't have error",
    "start": "581440",
    "end": "587839"
  },
  {
    "text": "budget for their testing and deployment velocity anymore so you align those",
    "start": "587839",
    "end": "593120"
  },
  {
    "text": "incentives another nice thing is if you're able to build a shared understanding not just",
    "start": "593120",
    "end": "599920"
  },
  {
    "start": "596000",
    "end": "828000"
  },
  {
    "text": "align incentives between people and that's where dashboards are coming in where all those dashboards ideally",
    "start": "599920",
    "end": "606720"
  },
  {
    "text": "are shared between all those different teams because then you have an incentive to invest in shared tooling and everyone",
    "start": "606720",
    "end": "613760"
  },
  {
    "text": "improves a little bit and everyone else benefits from the thing you pull all your institution knowledge around a",
    "start": "613760",
    "end": "619440"
  },
  {
    "text": "thing from a lot of different angles and everyone works together in making this",
    "start": "619440",
    "end": "624720"
  },
  {
    "text": "better it also means you're building the same language and you built the same",
    "start": "624720",
    "end": "629920"
  },
  {
    "text": "understanding everyone has the same dashboard the pm doesn't need to fight the engineers about what that one metric",
    "start": "629920",
    "end": "636399"
  },
  {
    "text": "is course they literally look at the same data they don't use different words for different aspects of course all of them",
    "start": "636399",
    "end": "642480"
  },
  {
    "text": "use the same dashboards the same alerts the same reports which in turn means they use the same language",
    "start": "642480",
    "end": "648800"
  },
  {
    "text": "services are not a super important concept they could basically comparison mentalize complexity and if you remember",
    "start": "648800",
    "end": "655920"
  },
  {
    "text": "just now i said one of those two abstraction layers would be an interface",
    "start": "655920",
    "end": "661040"
  },
  {
    "text": "towards the user they usually have different owners and teams obviously teams can have or own",
    "start": "661040",
    "end": "667040"
  },
  {
    "text": "more than one service but by and large they they tend to have their own groups of whoever is responsible and contracts",
    "start": "667040",
    "end": "673680"
  },
  {
    "text": "define their interfaces i like the term contract a lot of course it is is commonly defined as a",
    "start": "673680",
    "end": "680640"
  },
  {
    "text": "written agreement which must not be broken and you actually write it down and you agree it and you sign it so you",
    "start": "680640",
    "end": "687120"
  },
  {
    "text": "have an agreement and by writing things down and making things explicit a lot of those implicit misunderstandings just go",
    "start": "687120",
    "end": "692800"
  },
  {
    "text": "away because once it's written down and agreed and that's the basis for what you actually do and how you operate a lot of",
    "start": "692800",
    "end": "699120"
  },
  {
    "text": "people will take a second and third look and actually start negotiating details instead of everyone being like yeah",
    "start": "699120",
    "end": "705040"
  },
  {
    "text": "whatever it'll work and then it breaks and everyone is fighting why it broke and then you realize that you had a lot",
    "start": "705040",
    "end": "710959"
  },
  {
    "text": "of misunderstandings doesn't matter if the customers or consumers are internal or external",
    "start": "710959",
    "end": "718079"
  },
  {
    "text": "treat them as if they were external of course they are depending on your thing anyone coming from networking like",
    "start": "718079",
    "end": "724000"
  },
  {
    "text": "myself layers or another way of thinking about this the internet",
    "start": "724000",
    "end": "729200"
  },
  {
    "text": "wouldn't exist without proper layering because i can literally rip out layer one and layer two and i have",
    "start": "729200",
    "end": "735680"
  },
  {
    "text": "instead of ethernet i have wi-fi or what have you and that wouldn't be possible without those clean and long-term stable",
    "start": "735680",
    "end": "742560"
  },
  {
    "text": "interfaces between the different layers other things like cpus hardness compute",
    "start": "742560",
    "end": "748000"
  },
  {
    "text": "nodes your lunch even if you cook from scratch you will not grow every last cucumber yourself you have certain interfaces where you buy other services",
    "start": "748000",
    "end": "755920"
  },
  {
    "text": "and just consume those alerting also super important um",
    "start": "755920",
    "end": "762320"
  },
  {
    "text": "customers don't care if i don't know you have 20 database notes they don't care",
    "start": "762320",
    "end": "767519"
  },
  {
    "text": "if if 15 of them are down or five of them are down or all of them are healthy they care about that service which they",
    "start": "767519",
    "end": "773839"
  },
  {
    "text": "are consuming being healthy and responsive and what have you so that's the perspective to mainly take",
    "start": "773839",
    "end": "780639"
  },
  {
    "text": "define your slas your sli's your slos from that perspective of is it user",
    "start": "780639",
    "end": "786560"
  },
  {
    "text": "interfacing or is it user visible the nice thing if you do this in depth",
    "start": "786560",
    "end": "791680"
  },
  {
    "text": "what is your provider's sla and sli is perfect for you to debug of course if",
    "start": "791680",
    "end": "797440"
  },
  {
    "text": "the database is down you don't need to debug where your webshop is not working you kind of know",
    "start": "797440",
    "end": "802639"
  },
  {
    "text": "so you you structure again you use the same language across the complete stack of what you're doing important to avoid",
    "start": "802639",
    "end": "809279"
  },
  {
    "text": "burnout anything or anything which is currently or imminent customers must be",
    "start": "809279",
    "end": "814800"
  },
  {
    "text": "alerted upon and nothing else raise a ticket do it during business hours if it's not customer impacting",
    "start": "814800",
    "end": "821600"
  },
  {
    "text": "just don't of course you'll burn out so that's the intro part now gets to the",
    "start": "821600",
    "end": "827120"
  },
  {
    "text": "tech part prometheus prometheus if you don't know is inspired by google's pokemon it's a time series",
    "start": "827120",
    "end": "833040"
  },
  {
    "text": "database internally it uses 64-bit values for pretty much everything which is relevant there's thousands or tens of",
    "start": "833040",
    "end": "840160"
  },
  {
    "text": "thousands of insta thousands of instrumentations and exporters",
    "start": "840160",
    "end": "845440"
  },
  {
    "text": "that are public um there's millions of installations of prometheus um it's not for law",
    "start": "845440",
    "end": "852399"
  },
  {
    "text": "done by gorham main selling points built-in services cover",
    "start": "852399",
    "end": "858800"
  },
  {
    "text": "that is will notice um they're next like not impossible it's very uncommon to run kubernetes without a",
    "start": "858800",
    "end": "865360"
  },
  {
    "text": "prometheus of some sort because they are literally designed from each other even back from the google work in pork",
    "start": "865360",
    "end": "871120"
  },
  {
    "text": "mondays and more or less by a happy little accident with kubernetes and prometheus within",
    "start": "871120",
    "end": "876480"
  },
  {
    "text": "cncf low and behold those are the two founding projects of cncf",
    "start": "876480",
    "end": "882639"
  },
  {
    "text": "they go together um you haven't you have no hierarchical data models so you don't have your i don't know your region your",
    "start": "882639",
    "end": "889199"
  },
  {
    "text": "your city your customer and then you need to select by customer and all of a sudden you need to walk up your",
    "start": "889199",
    "end": "894240"
  },
  {
    "text": "hierarchical area while you need to walk down blah blah blah now you have an n-dimensional label set which you slice and dice as you need it so you select by",
    "start": "894240",
    "end": "901360"
  },
  {
    "text": "label customer equals x and you're done prom kl is a function label a functional",
    "start": "901360",
    "end": "907600"
  },
  {
    "text": "language which allows you to do vector math on on on your data",
    "start": "907600",
    "end": "913040"
  },
  {
    "text": "which is super efficient like highly efficient in particular of course the label matches matching usually does more",
    "start": "913040",
    "end": "918720"
  },
  {
    "text": "or less by magic what you want and this is used for everything processing graphing alerting exporting data every",
    "start": "918720",
    "end": "924800"
  },
  {
    "text": "every way you work on the data is always through promptly so it's a language you have to learn but",
    "start": "924800",
    "end": "930639"
  },
  {
    "text": "it's the one language and then everything works simply operation don't need to convince you probably",
    "start": "930639",
    "end": "935680"
  },
  {
    "text": "highly efficient it's pull-based for good reason of course this makes a lot of things easier",
    "start": "935680",
    "end": "941839"
  },
  {
    "text": "to reason about about correctness and up-to-date correctness of the state of",
    "start": "941839",
    "end": "947440"
  },
  {
    "text": "of the wider system push versus pull is a borderline religious debate but in particular",
    "start": "947440",
    "end": "953600"
  },
  {
    "text": "coming from the networking space there are some properties of pull which are next to impossible or super hard to to",
    "start": "953600",
    "end": "960399"
  },
  {
    "text": "emulate in push-based system unless the push-based system has complete information of of everything",
    "start": "960399",
    "end": "966720"
  },
  {
    "text": "which should be sending data at which point pulling is more efficient anyway white box black box monitoring one looks",
    "start": "966720",
    "end": "973759"
  },
  {
    "start": "970000",
    "end": "1033000"
  },
  {
    "text": "at the thing from the outside without further information whereas white box monitoring looks at all the",
    "start": "973759",
    "end": "980000"
  },
  {
    "text": "inerts you instrument your code you emit data from internal um every service should have its own",
    "start": "980000",
    "end": "985759"
  },
  {
    "text": "metrics and endpoint with things like the prometheus agent which we announced today with my promises team",
    "start": "985759",
    "end": "992480"
  },
  {
    "text": "head on look at the block of promises io slash blog um",
    "start": "992480",
    "end": "998320"
  },
  {
    "text": "we uh we can also accumulate this data for you and then even push it to other backends um",
    "start": "998320",
    "end": "1006079"
  },
  {
    "text": "yeah and super hard api commits stronger than anything i've ever seen in my life maybe",
    "start": "1006079",
    "end": "1011519"
  },
  {
    "text": "except for the linux kernel time series yeah most certainly except",
    "start": "1011519",
    "end": "1016959"
  },
  {
    "text": "for the linux kernel these defined as user interfaces which are not deprecated anyway what are time series",
    "start": "1016959",
    "end": "1023920"
  },
  {
    "text": "recorded values which change over time for example the temperature in your room that's a time series",
    "start": "1023920",
    "end": "1029199"
  },
  {
    "text": "you usually merge those individual events of i don't know tens of thousands of people accessing that thing",
    "start": "1029199",
    "end": "1036000"
  },
  {
    "start": "1033000",
    "end": "1045000"
  },
  {
    "text": "into counters and their histograms um typical examples would be requests to web server temperatures service latency",
    "start": "1036000",
    "end": "1042640"
  },
  {
    "text": "this kind of thing it's super easy to omit the parse and read that's literally how it looks on the wire so it's like i know people who",
    "start": "1042640",
    "end": "1049520"
  },
  {
    "text": "print f in their c code and then just dump that file onto web server and that's how they instrument their code",
    "start": "1049520",
    "end": "1054640"
  },
  {
    "text": "and it works like there are easier ways but for them that works and it's totally fine",
    "start": "1054640",
    "end": "1060320"
  },
  {
    "text": "scaling kubernetes is a spork prometheus is a sport one so",
    "start": "1060320",
    "end": "1066000"
  },
  {
    "text": "yeah scale is is kind of built in prometheus and kubernetes are designed and written",
    "start": "1066000",
    "end": "1071760"
  },
  {
    "start": "1068000",
    "end": "1131000"
  },
  {
    "text": "with each other in mind borg and borgmon again",
    "start": "1071760",
    "end": "1077120"
  },
  {
    "text": "yeah just looking at prometheus i have a typo there's a two missing in",
    "start": "1077120",
    "end": "1083120"
  },
  {
    "text": "that in that sentence um so roughly 1 million samples per second is",
    "start": "1083120",
    "end": "1090000"
  },
  {
    "text": "not a problem on current hardware 2200k samples per second and core is is",
    "start": "1090000",
    "end": "1095039"
  },
  {
    "text": "roughly where we're at and but that's already slightly old and the single largest uh prometheus instance which we",
    "start": "1095039",
    "end": "1101919"
  },
  {
    "text": "saw in production was 125 million active times years like we as in prometheus team um i know of someone who",
    "start": "1101919",
    "end": "1110400"
  },
  {
    "text": "ran it at 700 million so um yeah it's kind of scalable but it's also painful at that",
    "start": "1110400",
    "end": "1116799"
  },
  {
    "text": "point you probably would cortex or thanos or something speaking of um there's two uh two",
    "start": "1116799",
    "end": "1124240"
  },
  {
    "text": "projects which have high overlap with uh with prometheus team members thanos and cortex historically thanos is",
    "start": "1124240",
    "end": "1131120"
  },
  {
    "start": "1131000",
    "end": "1152000"
  },
  {
    "text": "easier to run and scales storage horizontally cortex is a lot easier to run these days and it started with",
    "start": "1131120",
    "end": "1137280"
  },
  {
    "text": "scaling uh storage in gestures and querying horizontally it took the code of of thanos to also scale storage",
    "start": "1137280",
    "end": "1144720"
  },
  {
    "text": "horizontally guess what thanos was working on with ingesting querying",
    "start": "1144720",
    "end": "1151000"
  },
  {
    "text": "data from from from grafana itself the largest single cluster it's not all",
    "start": "1151280",
    "end": "1158480"
  },
  {
    "start": "1152000",
    "end": "1177000"
  },
  {
    "text": "of grafana just one cluster but that's already old data we have higher numbers now 65 million active",
    "start": "1158480",
    "end": "1165760"
  },
  {
    "text": "series at a cost of 668 cpu cores and 3.4 gigs of ram",
    "start": "1165760",
    "end": "1170880"
  },
  {
    "text": "one customer is running at 3 billion but that's kind of more than pushing it but it did not",
    "start": "1170880",
    "end": "1177840"
  },
  {
    "start": "1177000",
    "end": "1308000"
  },
  {
    "text": "completely die in a fire loki it is basically like prometheus but for",
    "start": "1177840",
    "end": "1184000"
  },
  {
    "text": "logs so it follows all the same design principles as the same label based system it has the same indexing type it",
    "start": "1184000",
    "end": "1190000"
  },
  {
    "text": "takes tons of code from from cortex and for a kind of aubry seasons the nice",
    "start": "1190000",
    "end": "1196880"
  },
  {
    "text": "thing is you don't need a full text index course usually if you work on logs you don't need every last bit and piece",
    "start": "1196880",
    "end": "1203039"
  },
  {
    "text": "of your thing indexed most often you're able to to",
    "start": "1203039",
    "end": "1208400"
  },
  {
    "text": "extract a few relevant bits and pieces of information you index that you search",
    "start": "1208400",
    "end": "1214640"
  },
  {
    "text": "on that and the rest is just an opaque string which is which is stored without indexing which means you have a lot less overhead",
    "start": "1214640",
    "end": "1222240"
  },
  {
    "text": "and cost in storage and in particular indexing in lookups",
    "start": "1222240",
    "end": "1227600"
  },
  {
    "text": "you can work at scale like significant scale sorry",
    "start": "1227600",
    "end": "1233440"
  },
  {
    "text": "and one of the nice properties which are initially non-obvious to a lot of users is um as you use literally the same",
    "start": "1233440",
    "end": "1241039"
  },
  {
    "text": "label based system as prometheus it's trivial to to turn your logs into",
    "start": "1241039",
    "end": "1246720"
  },
  {
    "text": "metrics to extract metrics from your logs for alerting graphing blah blah blah blah blah",
    "start": "1246720",
    "end": "1252080"
  },
  {
    "text": "basically pre-processing or processing logs into metrics again remember same",
    "start": "1252080",
    "end": "1257679"
  },
  {
    "text": "like internet scale two decades ago that's kind of the same trick which is literally the same thing where a lot of",
    "start": "1257679",
    "end": "1263520"
  },
  {
    "text": "singular ones were turned into metrics and then just the metrics exposed in loki you have that mechanism built in",
    "start": "1263520",
    "end": "1268799"
  },
  {
    "text": "which is super nice and except for google's m tail which kind of",
    "start": "1268799",
    "end": "1274480"
  },
  {
    "text": "was that even when it was released something which which we haven't seen in in the open source or in the open world",
    "start": "1274480",
    "end": "1281520"
  },
  {
    "text": "like certain search engines and such have this internally but not uh",
    "start": "1281520",
    "end": "1288400"
  },
  {
    "text": "not others prior to loki at least and you can pump basically all type of of of text-based information into into",
    "start": "1288400",
    "end": "1296559"
  },
  {
    "text": "loki one of the elite deaths at welsh even puts his his car telemetry and pictures",
    "start": "1296559",
    "end": "1303280"
  },
  {
    "text": "from his dash cam into low key course he can and he likes to because again the content back here is",
    "start": "1303280",
    "end": "1309600"
  },
  {
    "start": "1308000",
    "end": "1362000"
  },
  {
    "text": "unindexed which means you can just put whatever and it's just an opaque string or blob",
    "start": "1309600",
    "end": "1315360"
  },
  {
    "text": "to be precise you might remember the prometheus exposition format we saw earlier or the",
    "start": "1315360",
    "end": "1320480"
  },
  {
    "text": "open metrics format which we saw earlier um that's actually the same with the labels here you just need a timestamp of",
    "start": "1320480",
    "end": "1326960"
  },
  {
    "text": "course obviously an event is is always at a specific point in time",
    "start": "1326960",
    "end": "1332960"
  },
  {
    "text": "so you need to emit that specific point in time whereas the metrics are",
    "start": "1332960",
    "end": "1340240"
  },
  {
    "text": "handled differently on a conceptual level you can emit precise timestamps but usually for mathematical reasons",
    "start": "1340240",
    "end": "1347120"
  },
  {
    "text": "which we are not going into here it's it's better to to have prometheus or cortex or thanos handle handle the",
    "start": "1347120",
    "end": "1353120"
  },
  {
    "text": "timestamping versus with low key it's better to have the emitter handle",
    "start": "1353120",
    "end": "1358840"
  },
  {
    "text": "timestamping um some numbers um our queries at grafana labs regularly see 40",
    "start": "1358840",
    "end": "1365120"
  },
  {
    "start": "1362000",
    "end": "1413000"
  },
  {
    "text": "gigs per second gigabytes per second um i know that we already at",
    "start": "1365120",
    "end": "1372480"
  },
  {
    "text": "rough production see 80 gigs due to a new way how we how we",
    "start": "1372480",
    "end": "1379120"
  },
  {
    "text": "scale our queries um which means you can go through insane",
    "start": "1379120",
    "end": "1384480"
  },
  {
    "text": "amounts of data within a super short time we regularly query terabytes of data in",
    "start": "1384480",
    "end": "1391120"
  },
  {
    "text": "under a minute and ideally you then emit this back into metrics so you don't have",
    "start": "1391120",
    "end": "1396480"
  },
  {
    "text": "to do those expensive or relatively expensive queries regularly you can just what you really care about already emit",
    "start": "1396480",
    "end": "1402799"
  },
  {
    "text": "into metrics and then again you reduce total amount of information also",
    "start": "1402799",
    "end": "1408159"
  },
  {
    "text": "computational complexity by orders of magnitude tempo the loss of the bunch",
    "start": "1408159",
    "end": "1414880"
  },
  {
    "text": "um with openmetrics",
    "start": "1414880",
    "end": "1420240"
  },
  {
    "text": "there was another thing which which was brought into the open which was before that basically limited to",
    "start": "1420240",
    "end": "1426320"
  },
  {
    "text": "to google with my openmetrics head on when we were talking ages ago about potentially",
    "start": "1426320",
    "end": "1433200"
  },
  {
    "text": "merging open senses and open metrics one of the things which stuck with me is",
    "start": "1433200",
    "end": "1439200"
  },
  {
    "text": "when when the googlers mentioned how how searching for for traces didn't scale",
    "start": "1439200",
    "end": "1445200"
  },
  {
    "text": "and when google tells you that searching doesn't scale searching for something um you better listen which which i did",
    "start": "1445200",
    "end": "1452000"
  },
  {
    "text": "so x employers are just an id you have an id for a trace and you",
    "start": "1452000",
    "end": "1458400"
  },
  {
    "text": "attach that to the trace but you also attach that id to a metric",
    "start": "1458400",
    "end": "1464559"
  },
  {
    "text": "or to a log line so now you know that a relevant metric",
    "start": "1464559",
    "end": "1469760"
  },
  {
    "text": "or relevant log line carries a trace with it and you don't have to have this needle",
    "start": "1469760",
    "end": "1476240"
  },
  {
    "text": "and haystack problem where you where you have to search through all your traces or live analysis do a live",
    "start": "1476240",
    "end": "1483039"
  },
  {
    "text": "analysis on your traces to deduce what the properties of that particular traces",
    "start": "1483039",
    "end": "1488640"
  },
  {
    "text": "um you already know that this is a relevant thing course it came from that",
    "start": "1488640",
    "end": "1494640"
  },
  {
    "text": "high latency bucket where i know your p99 was two seconds what have you doesn't matter but you know you have a",
    "start": "1494640",
    "end": "1501120"
  },
  {
    "text": "high latency there you know you had that one error you know you had that one security exception what have you and you",
    "start": "1501120",
    "end": "1506799"
  },
  {
    "text": "know that this one trace is relevant to the thing which you're currently working on which you saw in",
    "start": "1506799",
    "end": "1512799"
  },
  {
    "text": "your logs or your metrics so you don't need to search you don't need to switch mental context all the",
    "start": "1512799",
    "end": "1519120"
  },
  {
    "text": "time trying to walk through a ton of traces or spends you simply",
    "start": "1519120",
    "end": "1524720"
  },
  {
    "text": "from your metrics from your logs where you already know that something is relevant jump into your traces",
    "start": "1524720",
    "end": "1530559"
  },
  {
    "text": "super nice um they are built into pretty much everything which we're talking about um",
    "start": "1530559",
    "end": "1536720"
  },
  {
    "text": "of course kind of obvious they're nice but tempo also um",
    "start": "1536720",
    "end": "1543039"
  },
  {
    "text": "also allows you to search of course some users and some use cases just require searching of more or less raw",
    "start": "1543039",
    "end": "1551679"
  },
  {
    "text": "traces and spends my own personal opinion at some point it would be nice to optimize this out if if you need to",
    "start": "1552080",
    "end": "1558000"
  },
  {
    "text": "do search as of today but if you need to rely on search going forward that's also",
    "start": "1558000",
    "end": "1563440"
  },
  {
    "text": "completely doable better would be if if you go through ex-employers because it's just so much",
    "start": "1563440",
    "end": "1568880"
  },
  {
    "text": "more efficient only works on object storage you don't need cassandra elastic anything",
    "start": "1568880",
    "end": "1574400"
  },
  {
    "text": "expensive in the background given an object store and you're done it's compatible with all the things open",
    "start": "1574400",
    "end": "1580320"
  },
  {
    "text": "telemetry tracing zipkin jager by default we are not sampling you can sample if you want to",
    "start": "1580320",
    "end": "1586559"
  },
  {
    "text": "but we don't sample um i also need to update that slide i see",
    "start": "1586559",
    "end": "1592720"
  },
  {
    "text": "um because as of four months ago which is eons in in this production velocity uh we had",
    "start": "1592720",
    "end": "1601279"
  },
  {
    "text": "over 2 million samples per second at 350 megabytes per second and we have 14 day",
    "start": "1601279",
    "end": "1606320"
  },
  {
    "text": "retention three copy stored at a cost of 240 cpu 400 gigs 450 gigs of ram and 132",
    "start": "1606320",
    "end": "1612880"
  },
  {
    "text": "terabytes of object storage and the p99 of 2.5 um",
    "start": "1612880",
    "end": "1618400"
  },
  {
    "text": "it's better already but like tempo scales and it scales insanely high",
    "start": "1618400",
    "end": "1627039"
  },
  {
    "text": "bringing all of this together this this more holistic thing allows you to jump from logs to traces from metrics",
    "start": "1627039",
    "end": "1633600"
  },
  {
    "start": "1628000",
    "end": "1638000"
  },
  {
    "text": "to traces from traces to logs and all the all the other different ways um of course like it's",
    "start": "1633600",
    "end": "1640799"
  },
  {
    "start": "1638000",
    "end": "1657000"
  },
  {
    "text": "literally designed for each other and while they're all distinct projects and you're not forced to use all of them to",
    "start": "1640799",
    "end": "1646960"
  },
  {
    "text": "to reap benefits if you so choose um you get you get the most bang for your non buck",
    "start": "1646960",
    "end": "1655200"
  },
  {
    "text": "of course a those things have been designed for each other and personally speaking since at",
    "start": "1655200",
    "end": "1660320"
  },
  {
    "start": "1657000",
    "end": "1712000"
  },
  {
    "text": "least 2015 i have been working towards having those three things for metrics logs and traces",
    "start": "1660320",
    "end": "1667360"
  },
  {
    "text": "as a holistic thing so there is a long-running underlying design as to the bank for the buck all of this",
    "start": "1667360",
    "end": "1674159"
  },
  {
    "text": "is open source you can run it yourself i like food and shelter so you're also more than welcome to go to grafana cloud",
    "start": "1674159",
    "end": "1680080"
  },
  {
    "text": "or or buy enterprise or what have you um and there's some more features rough sniff test if the user the intended user",
    "start": "1680080",
    "end": "1687440"
  },
  {
    "text": "has more money than time um it tends to be a paid feature if they have more time than money it tends to be open source",
    "start": "1687440",
    "end": "1693600"
  },
  {
    "text": "like that's roughly the the sniff test for our monetization strategy",
    "start": "1693600",
    "end": "1699120"
  },
  {
    "text": "again most or anything we talked about right now it's completely open source you can run it yourself",
    "start": "1699120",
    "end": "1705279"
  },
  {
    "text": "a few screenshots most of you know how um how grafana looks but still",
    "start": "1705279",
    "end": "1711200"
  },
  {
    "text": "um those blue lines are relatively new and super nice you can have events you can",
    "start": "1711200",
    "end": "1716720"
  },
  {
    "start": "1712000",
    "end": "1734000"
  },
  {
    "text": "have um you can have your alerts you can have things like this which which give you a lot more context",
    "start": "1716720",
    "end": "1723279"
  },
  {
    "text": "you can also have examples visualized and things like this um and tons of other visualizations",
    "start": "1723279",
    "end": "1731440"
  },
  {
    "text": "as just last week we had uh observabilitycon 2021 online",
    "start": "1731440",
    "end": "1737440"
  },
  {
    "start": "1734000",
    "end": "1765000"
  },
  {
    "text": "obviously um a lot of what we just talked about you can find in more depth uh without that",
    "start": "1737440",
    "end": "1744320"
  },
  {
    "text": "rush to to cover as many questions as possible um at this location",
    "start": "1744320",
    "end": "1750240"
  },
  {
    "text": "grafanacon anyone um that's also part of the slice it's even a click",
    "start": "1750240",
    "end": "1757600"
  },
  {
    "text": "thank you very much uh you can post talks on github like all of them for last",
    "start": "1758159",
    "end": "1764000"
  },
  {
    "text": "decade or so email twitter are there for your per user",
    "start": "1764000",
    "end": "1769360"
  },
  {
    "start": "1765000",
    "end": "1826000"
  },
  {
    "text": "and let's see what we have as questions",
    "start": "1769360",
    "end": "1774000"
  },
  {
    "text": "um do we get created questions and they're read out or how does it work i honestly",
    "start": "1774399",
    "end": "1779679"
  },
  {
    "text": "don't know sorry i didn't anyone with a question just drop it into",
    "start": "1779679",
    "end": "1785440"
  },
  {
    "text": "the chat and richard can take a look at it as they come in sounds good",
    "start": "1785440",
    "end": "1790720"
  },
  {
    "text": "we'll go from there good good",
    "start": "1790720",
    "end": "1795840"
  },
  {
    "text": "so there are currently no questions which means i wouldn't have had to hurry as much",
    "start": "1799200",
    "end": "1805440"
  },
  {
    "text": "i can also ad-lib and go into more detail and other stuff but do ask questions if you have any",
    "start": "1805440",
    "end": "1812480"
  },
  {
    "text": "how to orchestrate apps to integrate with grafana cloud",
    "start": "1817039",
    "end": "1822080"
  },
  {
    "text": "can you orchestrate is",
    "start": "1822080",
    "end": "1829120"
  },
  {
    "text": "can you expand on what you mean with orchestrate course i think you're mixing on the one hand your own orchestration",
    "start": "1829120",
    "end": "1836000"
  },
  {
    "text": "of application versus um how to how to emit data towards grafana",
    "start": "1836000",
    "end": "1841679"
  },
  {
    "text": "cloud i can try and have have a partial reply as as to the second part",
    "start": "1841679",
    "end": "1848240"
  },
  {
    "text": "of that question how i understand it um",
    "start": "1848240",
    "end": "1853039"
  },
  {
    "text": "the easiest way for for most things is the grafana agent which is what the prometheus agent which",
    "start": "1853600",
    "end": "1859600"
  },
  {
    "text": "was released today is based upon of course this allows you to uh to",
    "start": "1859600",
    "end": "1865440"
  },
  {
    "text": "channel all your your signals uh towards grafana cloud um",
    "start": "1865440",
    "end": "1870480"
  },
  {
    "text": "if you have any of the other interfaces like the common ones um they're all supported um like ideally you you put",
    "start": "1870480",
    "end": "1877600"
  },
  {
    "text": "things somehow into into a prometheus remote right um to to emit towards",
    "start": "1877600",
    "end": "1882799"
  },
  {
    "text": "graphite cloud if it's metrics for traces open telemetry tracing is is",
    "start": "1882799",
    "end": "1888399"
  },
  {
    "text": "the gold standard so you should absolutely do this if you have non-prometheus things and",
    "start": "1888399",
    "end": "1894320"
  },
  {
    "text": "there's an exporter for pretty much or for probably everything on the market",
    "start": "1894320",
    "end": "1899679"
  },
  {
    "text": "to get data into prometheus format and then you can use the agent or other mechanisms to um to push towards grafana",
    "start": "1899679",
    "end": "1906159"
  },
  {
    "text": "cloud if you want to um the open telemetry collector also supports prometheus remote right so you",
    "start": "1906159",
    "end": "1911919"
  },
  {
    "text": "can also use this um yeah pretty much everything which which is on the market is supported",
    "start": "1911919",
    "end": "1918559"
  },
  {
    "text": "prom tail and such for loki and everything is built into into the grafana agent if you just want the bare",
    "start": "1918559",
    "end": "1924799"
  },
  {
    "text": "bones open metrics to um to promise this remote right pipeline uh",
    "start": "1924799",
    "end": "1931600"
  },
  {
    "text": "the prometheus agent is better if you want built-in exporters if you want prom tail if you",
    "start": "1931600",
    "end": "1937039"
  },
  {
    "text": "want to have open telemetry tracing all those things built into a single binary the grafana agent is better depends on",
    "start": "1937039",
    "end": "1944080"
  },
  {
    "text": "your trade-off some deployment models like to have a single huge binary which does pretty much everything other",
    "start": "1944080",
    "end": "1949760"
  },
  {
    "text": "deployment models mandate that you have tons of smaller services both as valid both as covered",
    "start": "1949760",
    "end": "1956000"
  },
  {
    "text": "um are there docker images available yes for everything as far as i am aware",
    "start": "1956000",
    "end": "1962480"
  },
  {
    "text": "if not focus on on cncf slack or on on grafana community",
    "start": "1962480",
    "end": "1967919"
  },
  {
    "text": "slack or shoot me a message but i would be surprised if we don't have up-to-date docker images for",
    "start": "1967919",
    "end": "1974559"
  },
  {
    "text": "everything i'm certain we do um do you have an off-the-shelf helm chart for getting this whole setup",
    "start": "1974559",
    "end": "1982480"
  },
  {
    "text": "um i think we do um there's tons of work on in our integration crew and we're hiring",
    "start": "1982480",
    "end": "1988399"
  },
  {
    "start": "1984000",
    "end": "2056000"
  },
  {
    "text": "like crazy for the integrations crew where all of this is made more seamless",
    "start": "1988399",
    "end": "1993840"
  },
  {
    "text": "internally we use tanker which is jsonnet which is then compiled",
    "start": "1993840",
    "end": "2000399"
  },
  {
    "text": "into into helm and others and also is able to to ingest term charts",
    "start": "2000399",
    "end": "2006080"
  },
  {
    "text": "which means you don't have this common problem of",
    "start": "2006080",
    "end": "2010960"
  },
  {
    "text": "of having those super static slash brittle hem charts which are hard to to change and and hard to to track in",
    "start": "2013120",
    "end": "2020559"
  },
  {
    "text": "particular if you have both upstream changes and your own local changes where you functionally need to fork",
    "start": "2020559",
    "end": "2026640"
  },
  {
    "text": "pretty much everything and and carry your own forks if you if you need to do anything more than really baseline",
    "start": "2026640",
    "end": "2032880"
  },
  {
    "text": "changes i suggest you you look at tanka and and js on it um",
    "start": "2032880",
    "end": "2039200"
  },
  {
    "text": "i can drop the url into into chat in a few",
    "start": "2039200",
    "end": "2044240"
  },
  {
    "text": "which is a lot more malleable and also allows you to define other things like like alerts and such and you",
    "start": "2044240",
    "end": "2050480"
  },
  {
    "text": "all have this in one one language jsonnet which is quite nice",
    "start": "2050480",
    "end": "2055919"
  },
  {
    "text": "how to integrate apps to send metrics or emit data to grafana cloud um",
    "start": "2055919",
    "end": "2061040"
  },
  {
    "text": "depends on the type of of well okay no he said metrics not signal sorry um well",
    "start": "2061040",
    "end": "2066480"
  },
  {
    "text": "okay let's go with metrics and then with data metrics um prometheus client libraries um",
    "start": "2066480",
    "end": "2072158"
  },
  {
    "text": "is the gold standard for for emitting metrics as of today um for",
    "start": "2072159",
    "end": "2079040"
  },
  {
    "text": "uh data defined as traces open telemetry tracing is the gold standard",
    "start": "2079040",
    "end": "2085040"
  },
  {
    "text": "for logs it doesn't really matter of course logs is just historically kind",
    "start": "2085040",
    "end": "2091040"
  },
  {
    "text": "of a mess as most of you will probably agree so promtel can ingest pretty much",
    "start": "2091040",
    "end": "2096079"
  },
  {
    "text": "everything and just hammer it into shape for for loki to consume again all of this is",
    "start": "2096079",
    "end": "2103200"
  },
  {
    "text": "built into the grafana agent but for for your own applications",
    "start": "2103200",
    "end": "2109280"
  },
  {
    "text": "when you need to emit the actual raw data from your own code and you need to instrument your own code",
    "start": "2109280",
    "end": "2115280"
  },
  {
    "text": "for metrics prometheus client libraries for traces open telemetry tracing and for",
    "start": "2115280",
    "end": "2121440"
  },
  {
    "text": "logs it doesn't really matter cause prompted eats at",
    "start": "2121440",
    "end": "2125599"
  },
  {
    "text": "all does correlation happen between loki logs and tempo traces so",
    "start": "2128839",
    "end": "2134320"
  },
  {
    "text": "um going from your logs to your traces the ideal case is you have an xml on",
    "start": "2134320",
    "end": "2142320"
  },
  {
    "text": "your on your logs there you know that your id for uh for that trace or that",
    "start": "2142320",
    "end": "2148160"
  },
  {
    "text": "span or both ex-employer support support free form text so",
    "start": "2148160",
    "end": "2153520"
  },
  {
    "text": "as per wc3's tracing standard we support both span and and",
    "start": "2153520",
    "end": "2162720"
  },
  {
    "text": "trace id and that modeling is also coming in large part from how google did it internally",
    "start": "2162720",
    "end": "2169200"
  },
  {
    "start": "2164000",
    "end": "2224000"
  },
  {
    "text": "like a lot of this has a history from there so it tends to already work nicely with each other",
    "start": "2169200",
    "end": "2175520"
  },
  {
    "text": "and you just tossed it in and once loki is aware that yes this is an exopla you can just jump to your trace storage",
    "start": "2175520",
    "end": "2183520"
  },
  {
    "text": "and and just go there and there's also an inverse index where you can look up um",
    "start": "2183520",
    "end": "2189680"
  },
  {
    "text": "trace ids or exemplars if you have one and you need to see that one log line",
    "start": "2189680",
    "end": "2194800"
  },
  {
    "text": "you can also go the other way which is of particular interest if you if you came to your trace or your span through",
    "start": "2194800",
    "end": "2201280"
  },
  {
    "text": "a search within tempo of course then that exemplar is is like the shortcut",
    "start": "2201280",
    "end": "2206560"
  },
  {
    "text": "back into into your logs or matrix",
    "start": "2206560",
    "end": "2211720"
  },
  {
    "text": "should kubernetes application services be designed in any particular way to use these tools what is a good starting",
    "start": "2214079",
    "end": "2219839"
  },
  {
    "text": "point to integrate these tools to custom kubernetes services running in a cluster great question and it's not basic not at",
    "start": "2219839",
    "end": "2226800"
  },
  {
    "start": "2224000",
    "end": "2384000"
  },
  {
    "text": "all for prometheus slash the others is super simple um",
    "start": "2226800",
    "end": "2234240"
  },
  {
    "text": "prometheus i touched on this but it didn't go in depth it has a thing called service",
    "start": "2234240",
    "end": "2239920"
  },
  {
    "text": "discovery which is just an interface where prometheus understands how other",
    "start": "2239920",
    "end": "2247280"
  },
  {
    "text": "services run their thing first and foremost kubernetes but",
    "start": "2247280",
    "end": "2252480"
  },
  {
    "text": "there's also things like text files where you just write yaml and and populate your your service discovery",
    "start": "2252480",
    "end": "2259839"
  },
  {
    "text": "for anyone uh more on the networking site zone transfer is is possible so you have your bind or whatever unbound dns",
    "start": "2259839",
    "end": "2267280"
  },
  {
    "text": "server allows zone transfers by prometheus and it just ingests the complete zone and",
    "start": "2267280",
    "end": "2272880"
  },
  {
    "text": "just starts monitoring or scraping everything which is defined in that in that zone",
    "start": "2272880",
    "end": "2278160"
  },
  {
    "text": "and again that is also the case for for kubernetes so you literally just point your premises at your kubernetes and you",
    "start": "2278160",
    "end": "2284079"
  },
  {
    "text": "tell your kubernetes that yes this thing may get the data and automatically",
    "start": "2284079",
    "end": "2290480"
  },
  {
    "text": "prometheus gets all the data from that kubernetes cluster with or from the parts like",
    "start": "2290480",
    "end": "2296720"
  },
  {
    "text": "services internal blah blah might be different depending on your precise setup maybe you need a sidecar blah blah blah the usual but for the",
    "start": "2296720",
    "end": "2303440"
  },
  {
    "text": "parts itself and such all that is automatically emitted which is super nice of course",
    "start": "2303440",
    "end": "2309200"
  },
  {
    "text": "it's literally one thing to set up and automatically you have all that data in your local prometheus if you don't want",
    "start": "2309200",
    "end": "2315520"
  },
  {
    "text": "to have local storage or you have issues with state which was the reason why we created the prometheus operator ages ago",
    "start": "2315520",
    "end": "2322480"
  },
  {
    "text": "to handle state within within kubernetes you can also just run the grafana or the prometheus agent and just shove all that",
    "start": "2322480",
    "end": "2329440"
  },
  {
    "text": "data into eg grafana cloud or one of the other prometheus compatible",
    "start": "2329440",
    "end": "2335119"
  },
  {
    "text": "offerings speaking of hermes compatibility also on the prometheus block again promises io slash blog",
    "start": "2335119",
    "end": "2342240"
  },
  {
    "text": "we did start a prometheus with my prometheus head on we did start a",
    "start": "2342240",
    "end": "2347760"
  },
  {
    "text": "prometheus compliance thing there or prometheus conformance thing where if you are compliant to the relevant apis",
    "start": "2347760",
    "end": "2354880"
  },
  {
    "text": "and service interfaces you get certified as prometheus compatible which means for the users",
    "start": "2354880",
    "end": "2360400"
  },
  {
    "text": "that you actually know that a thing is promises compatible and",
    "start": "2360400",
    "end": "2365599"
  },
  {
    "text": "and you can just use it without fear of of something breaking um prometheus cortex",
    "start": "2365599",
    "end": "2372480"
  },
  {
    "text": "grafana cloud are prometheus compatible uh",
    "start": "2372480",
    "end": "2379640"
  },
  {
    "text": "do you have any best practices blueprints for self-managed grafana slash prometheus loki setup any best",
    "start": "2383200",
    "end": "2390480"
  },
  {
    "start": "2384000",
    "end": "2479000"
  },
  {
    "text": "practices to optimize performance depends a little bit on your scale",
    "start": "2390480",
    "end": "2396240"
  },
  {
    "text": "so if you have normal scale like if if you're working at a huge company or you run a team and",
    "start": "2396240",
    "end": "2403599"
  },
  {
    "text": "they have i don't know how many users blah blah blah blah blah that is not as applicable but if you",
    "start": "2403599",
    "end": "2409040"
  },
  {
    "text": "have normal sized amounts of data it's pretty easy",
    "start": "2409040",
    "end": "2415440"
  },
  {
    "text": "because you just start a prometheus or a cortex or thanos cortex and",
    "start": "2415440",
    "end": "2420800"
  },
  {
    "text": "prometheus have single binary modes so you just start the binary and and you're done in this case i would recommend uh",
    "start": "2420800",
    "end": "2427280"
  },
  {
    "text": "prometheus myself if you get started um loki also has a single binary mode tempo",
    "start": "2427280",
    "end": "2432640"
  },
  {
    "text": "as well um so you just start those binaries and you can just you can just start",
    "start": "2432640",
    "end": "2438880"
  },
  {
    "text": "ingesting data into those systems as for prometheus i would suggest the documentation on",
    "start": "2438880",
    "end": "2445440"
  },
  {
    "text": "prometheio as to grafana cloud loki temple i would suggest the documentation",
    "start": "2445440",
    "end": "2451280"
  },
  {
    "text": "on grafana.com um those are the best ones digitalocean also has quite a few um",
    "start": "2451280",
    "end": "2459040"
  },
  {
    "text": "super nice prometheus tutorials which are i think four years old but they are",
    "start": "2459040",
    "end": "2464240"
  },
  {
    "text": "super nicely written so um yeah also we are extending the tutorial",
    "start": "2464240",
    "end": "2470319"
  },
  {
    "text": "section on prometheusel so yeah",
    "start": "2470319",
    "end": "2474480"
  },
  {
    "text": "does prometheus integrate with tools like istio um i think i know the answer but",
    "start": "2477760",
    "end": "2483599"
  },
  {
    "start": "2479000",
    "end": "2631000"
  },
  {
    "text": "i don't want to give a wrong answer so i can follow up and",
    "start": "2483599",
    "end": "2489440"
  },
  {
    "text": "shoot me an email or something i'll i'll get you the authoritative answer from robot",
    "start": "2489440",
    "end": "2495119"
  },
  {
    "text": "or from joe sorry not from robert and and before i say something wrong",
    "start": "2495119",
    "end": "2501119"
  },
  {
    "text": "13 more minutes and no questions this is your chance",
    "start": "2502240",
    "end": "2507960"
  },
  {
    "text": "any other questions",
    "start": "2520960",
    "end": "2523838"
  },
  {
    "text": "have we stalled out seems like do you want to include a slack channel",
    "start": "2526640",
    "end": "2533280"
  },
  {
    "text": "or something in the chat richard um or julie just to for any follow-up questions anything like that",
    "start": "2533280",
    "end": "2541440"
  },
  {
    "text": "yeah we have the uh i mean for we have to split this for cortex and prometheus you have you have the cncf",
    "start": "2543599",
    "end": "2550960"
  },
  {
    "text": "slack i do let me put let me put ours in and uh",
    "start": "2550960",
    "end": "2556240"
  },
  {
    "text": "online programs and then if anybody has any other questions you can hit each other up here",
    "start": "2556240",
    "end": "2564920"
  },
  {
    "text": "[Music]",
    "start": "2566510",
    "end": "2569589"
  },
  {
    "text": "there we go",
    "start": "2575119",
    "end": "2578440"
  },
  {
    "text": "okay well if there are no other questions i want to thank you richard thank you",
    "start": "2591200",
    "end": "2596240"
  },
  {
    "text": "everyone for um hanging in there with us as we got things started a little bit of a rough",
    "start": "2596240",
    "end": "2601599"
  },
  {
    "text": "rough start but um i think this was a great one and you got tons of great questions and",
    "start": "2601599",
    "end": "2607440"
  },
  {
    "text": "let's keep those conversations rolling and um thank you again and the",
    "start": "2607440",
    "end": "2612640"
  },
  {
    "text": "recordings will be up in a little bit uh this afternoon cool thanks for having me thanks",
    "start": "2612640",
    "end": "2619119"
  },
  {
    "text": "everyone so much thanks everyone",
    "start": "2619119",
    "end": "2624519"
  }
]
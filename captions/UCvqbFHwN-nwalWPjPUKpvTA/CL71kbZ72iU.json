[
  {
    "start": "0",
    "end": "64000"
  },
  {
    "text": "all right good afternoon everybody welcome to today's session networking optimizations for multi node deep",
    "start": "30",
    "end": "6330"
  },
  {
    "text": "learning on kubernetes before we get going I'd like to remind everybody to please rate the session afterwards on",
    "start": "6330",
    "end": "12719"
  },
  {
    "text": "the schedule app also if you have any translation needs we got translation going on over here",
    "start": "12719",
    "end": "17940"
  },
  {
    "text": "just punch in that URL type in the code and then you have the app on your phone please use headphones though versus the",
    "start": "17940",
    "end": "24300"
  },
  {
    "text": "audio speaker um I'd like to introduce these speakers for today arez cohen",
    "start": "24300",
    "end": "29580"
  },
  {
    "text": "vice-president for cloud x nei program at monix and Rashad Chopra principal",
    "start": "29580",
    "end": "35100"
  },
  {
    "text": "software engineer with NVIDIA working on AI deep learning infrastructure it was like with that I'd like to hand it back",
    "start": "35100",
    "end": "40170"
  },
  {
    "text": "over to you guys thank you thank you very much so good afternoon everybody",
    "start": "40170",
    "end": "45390"
  },
  {
    "text": "[Music] we thought to start with why machine learning but to be honest this days it's",
    "start": "45390",
    "end": "52140"
  },
  {
    "text": "quite obvious machine learning is everywhere even we have this little",
    "start": "52140",
    "end": "57149"
  },
  {
    "text": "thing here that translate it is all machine learning based so really machine learning is everywhere and we definitely",
    "start": "57149",
    "end": "62550"
  },
  {
    "text": "want to run machine learning in kubernetes as well this is just a basic",
    "start": "62550",
    "end": "67950"
  },
  {
    "start": "64000",
    "end": "64000"
  },
  {
    "text": "definition of what machine learning is from Wikipedia in essence is just the",
    "start": "67950",
    "end": "73290"
  },
  {
    "text": "ability to allow machines to learn from data and program themselves but the real",
    "start": "73290",
    "end": "79259"
  },
  {
    "start": "79000",
    "end": "79000"
  },
  {
    "text": "development over the past few years is around subfield of machine learning",
    "start": "79259",
    "end": "84720"
  },
  {
    "text": "called deep learning or deep neural network which is basically an",
    "start": "84720",
    "end": "90900"
  },
  {
    "text": "implementation of machine learning which is inspired by the brain in other words",
    "start": "90900",
    "end": "96090"
  },
  {
    "text": "taking a biological implementation if you like and translate that into",
    "start": "96090",
    "end": "102470"
  },
  {
    "text": "software implementation this is the very",
    "start": "102470",
    "end": "108180"
  },
  {
    "start": "106000",
    "end": "106000"
  },
  {
    "text": "basic of neural networks will not do a neural networks course here but I do want you to understand the basics so it",
    "start": "108180",
    "end": "115170"
  },
  {
    "text": "will help us understand the challenges in running in in large scale what you see here is a single neuron which has",
    "start": "115170",
    "end": "122219"
  },
  {
    "text": "three inputs on the left-hand side x0 x1 and x2 and with each input we",
    "start": "122219",
    "end": "131400"
  },
  {
    "text": "associate the weight that we 0 W 1 and W 2 and those weights are very",
    "start": "131400",
    "end": "137500"
  },
  {
    "text": "important those weights will define if this neural network will work properly or not so we need to tune them and we'll",
    "start": "137500",
    "end": "144340"
  },
  {
    "text": "talk about how we do that in a minute those inputs and the weights are going into the cell body there's a simple",
    "start": "144340",
    "end": "150700"
  },
  {
    "text": "function there that decide if this neuron should fire or not so as a single neuron that's pretty simple and a single",
    "start": "150700",
    "end": "158980"
  },
  {
    "text": "neuron doesn't really help us a lot but when we couldn't combine them together interesting things start to happen this",
    "start": "158980",
    "end": "166060"
  },
  {
    "text": "is a neural network that do image processing and predictive an images",
    "start": "166060",
    "end": "173049"
  },
  {
    "text": "digits 0 1 2 all the way to 9 you can see the output on the right-hand side",
    "start": "173049",
    "end": "178269"
  },
  {
    "text": "and the input on the left-hand side this is an image this is a 3 layer Network",
    "start": "178269",
    "end": "183340"
  },
  {
    "text": "and as you considers many connection between the neurons the neurons are all connected interconnected to each other",
    "start": "183340",
    "end": "189430"
  },
  {
    "text": "now on every connection there are weights as we said earlier so you can",
    "start": "189430",
    "end": "194620"
  },
  {
    "text": "assume that there's quite a lot of weight on this neural network but neural",
    "start": "194620",
    "end": "200829"
  },
  {
    "text": "network can be much bigger this is a 12 layer neural network and as",
    "start": "200829",
    "end": "206260"
  },
  {
    "text": "you can imagine there are much more parameters much more weights that needs to be tuned for this neural network to",
    "start": "206260",
    "end": "213280"
  },
  {
    "text": "work efficiently and this is definitely not the biggest neural network actually today we're saying neural networks that",
    "start": "213280",
    "end": "220359"
  },
  {
    "text": "are multiple hundreds of layers and they",
    "start": "220359",
    "end": "225819"
  },
  {
    "text": "can be very very very large and very complex now when we build a neural",
    "start": "225819",
    "end": "231159"
  },
  {
    "start": "230000",
    "end": "230000"
  },
  {
    "text": "network in the beginning it doesn't act as we want it to be we need to train it",
    "start": "231159",
    "end": "236470"
  },
  {
    "text": "we need to teach it and the way we're teaching neural network is through a process where we feed information that",
    "start": "236470",
    "end": "243790"
  },
  {
    "text": "is pre classified or pre tagged a good example a very classical example is an",
    "start": "243790",
    "end": "249250"
  },
  {
    "text": "image processing when we are trying to teach a system to distinguish between dogs and cats so we will feed images of",
    "start": "249250",
    "end": "256060"
  },
  {
    "text": "dogs and cats but we know that there are dogs and cats and on the output we will",
    "start": "256060",
    "end": "261909"
  },
  {
    "text": "check what was the result and we will try to feedback and fix those weights that I said earlier through some kind of algorithm",
    "start": "261909",
    "end": "268620"
  },
  {
    "text": "until the point where we feed dog image and it will say it's a dog and good probability and a can't imagine it will",
    "start": "268620",
    "end": "275170"
  },
  {
    "text": "say it's a cat and then at that point we say that the neural network is trained and then we can move to the inference",
    "start": "275170",
    "end": "282250"
  },
  {
    "text": "phase the inference phase is basically the execution part this is where we actually push an untagged in a data it",
    "start": "282250",
    "end": "289540"
  },
  {
    "text": "can be an image that we don't know exactly what it has and it will tell us if it is a dog or a cat of course this",
    "start": "289540",
    "end": "295840"
  },
  {
    "text": "is a simplified example the training phase is very challenging it is very",
    "start": "295840",
    "end": "301630"
  },
  {
    "start": "298000",
    "end": "298000"
  },
  {
    "text": "very much compute intensive process this is why NVIDIA GPU is such a wonderful",
    "start": "301630",
    "end": "307390"
  },
  {
    "text": "solution because it allows us to drive computational very fast but what we see",
    "start": "307390",
    "end": "314410"
  },
  {
    "text": "is that those neural networks are growing in complexity and the input data",
    "start": "314410",
    "end": "319750"
  },
  {
    "text": "is growing as well and actually today if we are looking at modern models and",
    "start": "319750",
    "end": "326320"
  },
  {
    "text": "problems it takes us weeks to train a model obviously that is very challenging",
    "start": "326320",
    "end": "331810"
  },
  {
    "text": "challenging because a week is a long time but also we need to train quite often there's two reason one we will",
    "start": "331810",
    "end": "338860"
  },
  {
    "text": "learn to train often one is because development model is not a linear",
    "start": "338860",
    "end": "343930"
  },
  {
    "text": "process like writing a C code or any other language you are used to you write the model you train it you see how it",
    "start": "343930",
    "end": "350440"
  },
  {
    "text": "behaves you change it and then you train it again and you go on and on now if you do that and it takes you a week between",
    "start": "350440",
    "end": "356590"
  },
  {
    "text": "training that's very inefficient another reason is that just like in life you",
    "start": "356590",
    "end": "362590"
  },
  {
    "text": "have to keep on learning you build the model you train it great you put it in production but things change the world",
    "start": "362590",
    "end": "369940"
  },
  {
    "text": "is dynamic and we need to be able to keep on teaching the model too and bring",
    "start": "369940",
    "end": "376180"
  },
  {
    "text": "it to be more accurate so what we really need is we need to to accelerate our",
    "start": "376180",
    "end": "382090"
  },
  {
    "text": "training time and the only way to do that is to do scale-out computing",
    "start": "382090",
    "end": "387120"
  },
  {
    "text": "basically add more computers so how do we how do we do trainer scale out in",
    "start": "387120",
    "end": "393160"
  },
  {
    "start": "390000",
    "end": "390000"
  },
  {
    "text": "machine learning this paradigm called data parallelism and basically what it does is basically",
    "start": "393160",
    "end": "398990"
  },
  {
    "text": "instead of having a single computer that has all the input data we just add more computer we scale out and we take the",
    "start": "398990",
    "end": "407870"
  },
  {
    "text": "input data we split it in between the different computers so in this example each computer will get sixth 1/6 of the",
    "start": "407870",
    "end": "414920"
  },
  {
    "text": "data and then it do a local training now if each of the computers will do local",
    "start": "414920",
    "end": "421430"
  },
  {
    "text": "training you will ever end up with six different models because each of them was working on different data elements",
    "start": "421430",
    "end": "427760"
  },
  {
    "text": "so that will not work what we really need to do is we need to combine those machines power together and the way to",
    "start": "427760",
    "end": "434360"
  },
  {
    "text": "do that is basically split the data into mini batches let's say 32 images do",
    "start": "434360",
    "end": "440480"
  },
  {
    "text": "local training on each node and then communicate the results and combine them",
    "start": "440480",
    "end": "446030"
  },
  {
    "text": "together through the network it can be to a single computer it can be between the computers there's different ways to",
    "start": "446030",
    "end": "452480"
  },
  {
    "text": "do that and eventually this process when we are iterating this multiple times it",
    "start": "452480",
    "end": "459919"
  },
  {
    "text": "can be hundreds of thousands or millions of iteration we will get a single end module that is trained now when we look",
    "start": "459919",
    "end": "468140"
  },
  {
    "start": "468000",
    "end": "468000"
  },
  {
    "text": "at those network element in the training phase we see that the communication",
    "start": "468140",
    "end": "473630"
  },
  {
    "text": "pattern is very very challenging it will it will be usually a very high performance high throughput the those",
    "start": "473630",
    "end": "482620"
  },
  {
    "text": "models can be transferring tens and hundreds of gigabits per second so it's",
    "start": "482620",
    "end": "488360"
  },
  {
    "text": "a lot of data from every computer and you have a lot of computers usually doing that it will be very high message",
    "start": "488360",
    "end": "494870"
  },
  {
    "text": "rate and low latency requirements and it has collective operation in nature what",
    "start": "494870",
    "end": "501590"
  },
  {
    "text": "I mean by collective operation is that all those nodes are working together they work on a mini badge to communicate",
    "start": "501590",
    "end": "508010"
  },
  {
    "text": "and they're waiting for each other so they work as a collective and as a collective you need to wait for",
    "start": "508010",
    "end": "513979"
  },
  {
    "text": "everybody and synchronize everybody together and this type of communication pattern very much remind us of high",
    "start": "513979",
    "end": "520760"
  },
  {
    "text": "performance computing Network which are all the supercomputers and we know from",
    "start": "520760",
    "end": "527330"
  },
  {
    "text": "a lot of years of experience that advanced network techniques such as our the human GPU direct are critical for",
    "start": "527330",
    "end": "534920"
  },
  {
    "text": "having an efficient training I mentioned our they may let me just give you a",
    "start": "534920",
    "end": "540920"
  },
  {
    "text": "quick explanation about what is already main are delay is a remote direct memory access it is a transport service you",
    "start": "540920",
    "end": "548240"
  },
  {
    "text": "guys probably know TCP and UDP so it's in the same layer of Mallis and but it",
    "start": "548240",
    "end": "553940"
  },
  {
    "text": "was designed much later and it is much more advanced in terms of feature set it",
    "start": "553940",
    "end": "560000"
  },
  {
    "text": "provides ability to do read and write over the network not only send receive and it provides us ability to the kernel",
    "start": "560000",
    "end": "567350"
  },
  {
    "text": "bypass kernel bypasses when the application talk directly to the odd were bypassing the kernel and by that we",
    "start": "567350",
    "end": "573230"
  },
  {
    "text": "get very low latency and it provides full hardware offload at least with the Mellanox necks which mean that we can",
    "start": "573230",
    "end": "579620"
  },
  {
    "text": "transfer hundreds of gigabytes without any CPU intervention so the CPU load is zero and the efficiency is very very",
    "start": "579620",
    "end": "586339"
  },
  {
    "text": "high our dev I started from a technology called InfiniBand but today it's part of Ethernet it is called Rocky and the",
    "start": "586339",
    "end": "593810"
  },
  {
    "text": "interface the software interface is not socket it is an interface called herbs which is very important because the",
    "start": "593810",
    "end": "600380"
  },
  {
    "text": "normal net devices that we transfer to the container doesn't provide Rocky or are the main interface we need a",
    "start": "600380",
    "end": "606890"
  },
  {
    "text": "different interface GPU direct is a technology that allow us a better",
    "start": "606890",
    "end": "612649"
  },
  {
    "start": "609000",
    "end": "609000"
  },
  {
    "text": "efficiency of sending and receiving data from the GPU to the network what you see on the top right hand side is how do you",
    "start": "612649",
    "end": "619160"
  },
  {
    "text": "get data in and out of the GPU memory without GPU director what you would do",
    "start": "619160",
    "end": "624290"
  },
  {
    "text": "is typically copy data from the GPU memory to the host memory copy the host memory to a buffer in the host number",
    "start": "624290",
    "end": "631040"
  },
  {
    "text": "again for the network and send it out that's not very efficient obviously GPU",
    "start": "631040",
    "end": "636260"
  },
  {
    "text": "direct is a technology that developed by Nvidia and Mellanox together about 10",
    "start": "636260",
    "end": "642050"
  },
  {
    "text": "years ago which allowed the neck and the gpo to communicate directly to each other so the neck can access the GPU",
    "start": "642050",
    "end": "648589"
  },
  {
    "text": "memory and send and receive data directly from there obviously it provides a much more much better",
    "start": "648589",
    "end": "655670"
  },
  {
    "text": "efficiency so how do we enable our team a NGP direct in kubernetes so today we are",
    "start": "655670",
    "end": "663770"
  },
  {
    "text": "using SRA of V as a mechanism to expose our diamond GPU direct SRV is a PCI",
    "start": "663770",
    "end": "670580"
  },
  {
    "text": "specification stands for single route our virtualization and basically what does what does it mean it means that you",
    "start": "670580",
    "end": "678050"
  },
  {
    "text": "can take a PCI device slice it and provide slices to an application called",
    "start": "678050",
    "end": "684230"
  },
  {
    "text": "virtual function what you see on the images and on the bottom here on the left hand side you'd see the standard",
    "start": "684230",
    "end": "689930"
  },
  {
    "text": "configuration on the right hand side you see this array of n you can see that every virtual function coming from the",
    "start": "689930",
    "end": "695690"
  },
  {
    "text": "device has a net device but also the our DMA device those devices that are needed",
    "start": "695690",
    "end": "700970"
  },
  {
    "text": "for our DMA that can be mapped into the container there are CN eyes and device plugins to",
    "start": "700970",
    "end": "707030"
  },
  {
    "text": "provision SRA away it is completely standout and upstream and you can find the links in this page so from a",
    "start": "707030",
    "end": "714830"
  },
  {
    "text": "container perspective the container will see when when when at the SRU V device",
    "start": "714830",
    "end": "720590"
  },
  {
    "text": "and CNI plugin are activated the container will see both an our DMA",
    "start": "720590",
    "end": "726140"
  },
  {
    "text": "device this is the IB dev that you see here as well as a net device under the namespace of that container and we'll",
    "start": "726140",
    "end": "732500"
  },
  {
    "text": "get a slice of the neck as part of the Sava interface so how does it look from",
    "start": "732500",
    "end": "738980"
  },
  {
    "text": "an orchestration perspective on the kubernetes level so first the SR every Network device",
    "start": "738980",
    "end": "745580"
  },
  {
    "text": "plug-in will advertise the service capabilities basically how many virtual",
    "start": "745580",
    "end": "751490"
  },
  {
    "text": "functions each device has and then when you launch a pod it will define that it",
    "start": "751490",
    "end": "757280"
  },
  {
    "text": "needs a survivor V in case that it needs a service or it will sign is a virtual function the kubernetes scheduler then",
    "start": "757280",
    "end": "763910"
  },
  {
    "text": "we'll run the pod and the right host with with those resources the device",
    "start": "763910",
    "end": "768920"
  },
  {
    "text": "plug-in will allocate the virtual function that will be connected to that",
    "start": "768920",
    "end": "774980"
  },
  {
    "text": "pod the allocated device is communicated with the SRA OVC ni because we need the",
    "start": "774980",
    "end": "780470"
  },
  {
    "text": "net device to run on that interface and then the service and I will move the virtual function at device to the",
    "start": "780470",
    "end": "787400"
  },
  {
    "text": "put the namespace in kubernetes today",
    "start": "787400",
    "end": "793220"
  },
  {
    "text": "you're not allowed to run more than one interface or one CNI into a pod and for",
    "start": "793220",
    "end": "799279"
  },
  {
    "text": "that Malta's or similar in plugins were developed monitors as a meta plugin",
    "start": "799279",
    "end": "806540"
  },
  {
    "text": "which allows to provide multiple interfaces to to a pod there will be",
    "start": "806540",
    "end": "813230"
  },
  {
    "text": "always one interface which will be the prime the master interface this is the standard kind of eth0 that that you are",
    "start": "813230",
    "end": "820339"
  },
  {
    "text": "using and this is where all the security groups and policies and so on will be applied but then Moltres provides you",
    "start": "820339",
    "end": "827660"
  },
  {
    "text": "the ability to connect additional c nice one omo it can be more than one and in",
    "start": "827660",
    "end": "834350"
  },
  {
    "text": "our case it is obviously a survey of a and those interfaces although they are",
    "start": "834350",
    "end": "840680"
  },
  {
    "text": "providing connectivity they don't have any security policies around them and",
    "start": "840680",
    "end": "846320"
  },
  {
    "text": "they are not able to be present in under the kubernetes interface and with that I",
    "start": "846320",
    "end": "853400"
  },
  {
    "text": "will hand to result now welcome to part",
    "start": "853400",
    "end": "863630"
  },
  {
    "text": "two of the post learn session of the last day of the conference I'm sure you",
    "start": "863630",
    "end": "869180"
  },
  {
    "text": "guys excited try to make it interesting funny thing I noticed that when res said",
    "start": "869180",
    "end": "876380"
  },
  {
    "text": "our DMA the AI thing running over there was saying our DNA",
    "start": "876380",
    "end": "883959"
  },
  {
    "text": "it's that was noticing and it's more clever than I was afraid of anyway yeah",
    "start": "884900",
    "end": "891230"
  },
  {
    "text": "we get to probably my accent or I'm",
    "start": "891230",
    "end": "898250"
  },
  {
    "text": "smarter than all right all right so uh",
    "start": "898250",
    "end": "903610"
  },
  {
    "start": "902000",
    "end": "902000"
  },
  {
    "text": "arrests talked about all the ingredients that you would need to get deep learning",
    "start": "903610",
    "end": "909970"
  },
  {
    "text": "going on Cuban Aires for multiple nodes you need Rd main everything he put it on",
    "start": "910000",
    "end": "915650"
  },
  {
    "text": "the list of all the ingredients and I put all these ingredients together you will have a large data center hopefully",
    "start": "915650",
    "end": "920660"
  },
  {
    "text": "if you want to scale out and push further and further you have a large data center and you could be able to put",
    "start": "920660",
    "end": "925730"
  },
  {
    "text": "these pieces together and things would start to work I'm afraid not you will run into issues and those are",
    "start": "925730",
    "end": "932420"
  },
  {
    "text": "the issues which I'm gonna list down if you ever going to try this in your data center you're gonna bring this",
    "start": "932420",
    "end": "937460"
  },
  {
    "text": "infrastructure up you're gonna have to take care of these issues in mind some of them are functional issues you will",
    "start": "937460",
    "end": "942920"
  },
  {
    "text": "see that stuff is not working and some of them are performance issues you will see that if stuff is working at as low",
    "start": "942920",
    "end": "949430"
  },
  {
    "text": "as 1% of the performance that you thought or I would have shown in the slides so I will go through some of this",
    "start": "949430",
    "end": "955190"
  },
  {
    "text": "list and we start right we probably start making some counts of things that I am going to list and in the end I'm",
    "start": "955190",
    "end": "960200"
  },
  {
    "text": "going to show some performance graphs on how when we put in these optimizations what do we see do we see the expected",
    "start": "960200",
    "end": "965750"
  },
  {
    "text": "result so not all right so we'll start with priori flow control explicit congestion notification stuff you can",
    "start": "965750",
    "end": "972110"
  },
  {
    "start": "966000",
    "end": "966000"
  },
  {
    "text": "read up on Google what it is it's broadly about saying when the network is going to be shared it's an either RDMA",
    "start": "972110",
    "end": "978230"
  },
  {
    "text": "or converged Ethernet you're gonna have trouble with other things so well let's separate our priority flow control",
    "start": "978230",
    "end": "983930"
  },
  {
    "text": "things and then let's make a separate channel you need to configure that on the host the ecn bits which is",
    "start": "983930",
    "end": "989420"
  },
  {
    "text": "congestion notification which is just saying your first congestion please back out dumps in traffic let's don't make it",
    "start": "989420",
    "end": "994490"
  },
  {
    "text": "worse kind of things these are things which you have to can fix on your switch or the router and then other things you",
    "start": "994490",
    "end": "1001870"
  },
  {
    "text": "need to get this ACS thing set up on BIOS if you don't do that you will see some performance suffering and",
    "start": "1001870",
    "end": "1008450"
  },
  {
    "text": "there's a GPO direct which it has introduced if you don't put this kernel module in imagine now you have 20 boxes",
    "start": "1008450",
    "end": "1018170"
  },
  {
    "text": "in your data center or 200 boxes and you didn't put one of the kernel modules thing going on in one of the boxes",
    "start": "1018170",
    "end": "1023600"
  },
  {
    "text": "dismissed one what is the beauty or the single most important principle of high",
    "start": "1023600",
    "end": "1029270"
  },
  {
    "text": "performance computing the slowest guy is gonna guide the performance of the",
    "start": "1029270",
    "end": "1035270"
  },
  {
    "text": "entire flock when you say the whole thing is running on 20 percent performance what's going wrong well",
    "start": "1035270",
    "end": "1040610"
  },
  {
    "text": "please go through the checklist this suffered this so believe us the final part is blue film registers",
    "start": "1040610",
    "end": "1046188"
  },
  {
    "text": "that using Mellanox codes if you have smaller packets 64 bytes less or something and then you probably want to",
    "start": "1046189",
    "end": "1052760"
  },
  {
    "text": "tune this further you don't want to see if I pursue drop it's not that 5% broken",
    "start": "1052760",
    "end": "1057980"
  },
  {
    "text": "performance is important I translate that to 5% of your money going waste when you've invested millions of dollars",
    "start": "1057980",
    "end": "1063860"
  },
  {
    "text": "in that infrastructure going how many of these are there four of these all right we keep going you don't believe me",
    "start": "1063860",
    "end": "1069440"
  },
  {
    "text": "probably and these are the graphs that we measured we didn't do PFC NECN the one on the left is showing for interface",
    "start": "1069440",
    "end": "1076700"
  },
  {
    "start": "1074000",
    "end": "1074000"
  },
  {
    "text": "cards the red orange green and blue trying to operate over some period of",
    "start": "1076700",
    "end": "1082250"
  },
  {
    "text": "time which is the x axis and the y axis is the gigabits per second and the max",
    "start": "1082250",
    "end": "1087290"
  },
  {
    "text": "you could have gotten a hundred gigs per seconds that's the card throughput and you would see that you",
    "start": "1087290",
    "end": "1092750"
  },
  {
    "text": "don't get the things right one of the cards is just working at 20% 20 bits per",
    "start": "1092750",
    "end": "1099410"
  },
  {
    "text": "second will just enable that and you see the graph on the right and you say nearly everyone is working together like",
    "start": "1099410",
    "end": "1105140"
  },
  {
    "text": "brothers should be and you get above 90% but and you can see as anyone can that",
    "start": "1105140",
    "end": "1113419"
  },
  {
    "text": "there's some small spikes that come down and everything we were at the four counts of things that we had optimized",
    "start": "1113419",
    "end": "1119450"
  },
  {
    "text": "I'm gonna go next on how to remove these spikes also if there's one single",
    "start": "1119450",
    "end": "1126919"
  },
  {
    "start": "1124000",
    "end": "1124000"
  },
  {
    "text": "important thing that you're here for and you want to learn on how to get deep learning infrastructure on scale with",
    "start": "1126919",
    "end": "1132530"
  },
  {
    "text": "cuban ares and everything this is the one thing which will improve your performance",
    "start": "1132530",
    "end": "1138559"
  },
  {
    "text": "multifold make it scalable make it reliable the problem statement is that I",
    "start": "1138559",
    "end": "1144179"
  },
  {
    "text": "got these boxes you know the GP boxes each box has eight GPUs of 16 GPS a 4G piece of whatever your favorite",
    "start": "1144179",
    "end": "1149970"
  },
  {
    "text": "Convocation work and let's connect them to the network and the network has these top-of-rack switches or something how do",
    "start": "1149970",
    "end": "1156720"
  },
  {
    "text": "you connect them if you're anyone like me or something stupid or learning this",
    "start": "1156720",
    "end": "1161730"
  },
  {
    "text": "is what I did I put these boxes and then the rod got over I put this into the switch and then get to the other rack put these boxes put it on the top of the",
    "start": "1161730",
    "end": "1168570"
  },
  {
    "text": "rack and they connect the power of the rack to the fabs and spines or whatever it is does not work and it would work",
    "start": "1168570",
    "end": "1177750"
  },
  {
    "text": "for any other thing that you would try to do it will not work for deep learning why because deep learning has a peculiar",
    "start": "1177750",
    "end": "1184410"
  },
  {
    "text": "thing when you try to share those mini-batches with your parameter servers and everything what's going on is that",
    "start": "1184410",
    "end": "1190840"
  },
  {
    "text": "[Music] the if you see this diagram on the right",
    "start": "1190840",
    "end": "1199169"
  },
  {
    "text": "top right the information sharing happens in and throw a ring or a",
    "start": "1199169",
    "end": "1204299"
  },
  {
    "text": "parameter server or a tree or something whatever information goes through Nick one comes out of Nick one covering all",
    "start": "1204299",
    "end": "1210390"
  },
  {
    "text": "the GPUs conducting all the parameters that each of those GP is communicated goes to the other GPU node and",
    "start": "1210390",
    "end": "1215700"
  },
  {
    "text": "communicates with Nick one also and goes to the third node and can me guess with Nick one again all the Nick ones want to",
    "start": "1215700",
    "end": "1221820"
  },
  {
    "text": "talk to each other all the Nick toes want to talk to each other all the Nick trees want to talk to each other never",
    "start": "1221820",
    "end": "1228150"
  },
  {
    "text": "would you have a situation in deep learning in the frameworks that Nick one is trying to talk to Nick - no Nick one",
    "start": "1228150",
    "end": "1234090"
  },
  {
    "text": "talks to Nick one Nick two - Nick - three - three four - four so a minor point but a very clever point I'm saying",
    "start": "1234090",
    "end": "1242010"
  },
  {
    "text": "the single most important thing if you have to learn so wake up listen to this when you've wire up your servers get",
    "start": "1242010",
    "end": "1248640"
  },
  {
    "text": "your Nick 1 2 switch 1 all the Nick tools to switch to all the Nick threes",
    "start": "1248640",
    "end": "1253710"
  },
  {
    "text": "to switch 3 even if they're from the same box just a simple measure and the",
    "start": "1253710",
    "end": "1259710"
  },
  {
    "text": "result is that when all Nick ones perform their communication pattern they will have no extra hop one hop right",
    "start": "1259710",
    "end": "1266790"
  },
  {
    "text": "they all go to the same switch they get back to the thing there is no extra hop required now extra half is bad when you're talking about",
    "start": "1266790",
    "end": "1273090"
  },
  {
    "text": "RDMA over Ethernet a simple principle very easy to understand just that I struggle so much with putting all of",
    "start": "1273090",
    "end": "1279990"
  },
  {
    "text": "these two in the same single switch and everything and the one important thing that you can learn from here is that if you get the number of ports on your",
    "start": "1279990",
    "end": "1286320"
  },
  {
    "text": "switch is more than the more you can scale any cluster if you have a 128-bit of 128 port switch you will be able to",
    "start": "1286320",
    "end": "1294060"
  },
  {
    "text": "connect 128 machines on one switch that",
    "start": "1294060",
    "end": "1299940"
  },
  {
    "text": "would nearly mean 1,000 GPUs five points did I make this is the single most",
    "start": "1299940",
    "end": "1305280"
  },
  {
    "text": "important one sixth point if you don't enable this this is going to be",
    "start": "1305280",
    "end": "1310470"
  },
  {
    "text": "dysfunctional this is a source based routing now it has introduced that using multiple have multiple interfaces into",
    "start": "1310470",
    "end": "1317220"
  },
  {
    "text": "the port when you have multiple interfaces all of them are on a different network and possibly would be",
    "start": "1317220",
    "end": "1325250"
  },
  {
    "start": "1321000",
    "end": "1321000"
  },
  {
    "text": "do you know how routing works then if I want to go from a box to some IP address",
    "start": "1325250",
    "end": "1332190"
  },
  {
    "text": "my destination routing table says oh you want to get to that subnet use this NIC",
    "start": "1332190",
    "end": "1337650"
  },
  {
    "text": "I say hold on I'm deep learning okay I know which NIC to use don't tell me to use that Nick I know which need to use I",
    "start": "1337650",
    "end": "1344640"
  },
  {
    "text": "want to connect NIC one to Nick one don't tell me that your routing table is saying to use NIC for for that subnet well you need so spaced out in here so",
    "start": "1344640",
    "end": "1352650"
  },
  {
    "text": "that when you're deep learning framework is trying to share parameters it consults the source based routing and",
    "start": "1352650",
    "end": "1358830"
  },
  {
    "text": "says NIC one will always go from NIC one you choose the source interface and you",
    "start": "1358830",
    "end": "1364320"
  },
  {
    "text": "choose the destination interface and you need this plug-in to make this working so we always put this together if you",
    "start": "1364320",
    "end": "1369480"
  },
  {
    "text": "have a quick question I can answer now if we can take this letter yeah layer 2 network clearly and you",
    "start": "1369480",
    "end": "1376470"
  },
  {
    "text": "will not have VLANs then and you will not have ever the possibility of going and expanding your network when you have",
    "start": "1376470",
    "end": "1383460"
  },
  {
    "text": "a 648 port switch and he said can we have layer 3 if you don't want layer 3 yes if you stick in layer 2 you don't",
    "start": "1383460",
    "end": "1389100"
  },
  {
    "text": "need this but you want to scale out and we wanted to scale out so we said well",
    "start": "1389100",
    "end": "1394230"
  },
  {
    "text": "let's make it generic good question thank you this is the roughly the final",
    "start": "1394230",
    "end": "1400710"
  },
  {
    "start": "1398000",
    "end": "1398000"
  },
  {
    "text": "thing that I'm going to talk about we can spend a lot of time on this and if you want we can close the sooner but these are real performance measurements",
    "start": "1400710",
    "end": "1407160"
  },
  {
    "text": "now I could have gone on to hundreds of GPUs but I wanted to restrict and see",
    "start": "1407160",
    "end": "1415350"
  },
  {
    "text": "that just 5 boxes put together just 42:48 GPUs put together on different",
    "start": "1415350",
    "end": "1420929"
  },
  {
    "text": "scale what are the numbers that I got on resonate 50 which has 23 million",
    "start": "1420929",
    "end": "1426150"
  },
  {
    "text": "parameters to be shared on every one of the 50 layers when you do deep learning training on 14 million images the y-axis",
    "start": "1426150",
    "end": "1434550"
  },
  {
    "text": "is number of images per second the x-axis is number of GPS that are used",
    "start": "1434550",
    "end": "1441270"
  },
  {
    "text": "and the three graphs are on batch sizes see clearly in SGD we trust' SGD is the",
    "start": "1441270",
    "end": "1451980"
  },
  {
    "text": "algorithm that we use stochastic gradient descent to share those parameters and that's why you would see",
    "start": "1451980",
    "end": "1458040"
  },
  {
    "text": "why the batch sizes are important why your accuracy is important why the training image the these speed of",
    "start": "1458040",
    "end": "1464340"
  },
  {
    "text": "training is important and how these things play but with the network guys we want to make sure that what did I do all",
    "start": "1464340",
    "end": "1471300"
  },
  {
    "text": "this for and you can see in the third graph just in five boxes put together",
    "start": "1471300",
    "end": "1476520"
  },
  {
    "text": "you can see if you did not put your network right the red line is the RDMA",
    "start": "1476520",
    "end": "1482070"
  },
  {
    "text": "highly optimized stuff and the blue line is also hundred gigs I'm not comparing wrong mix with stuff the blue line was",
    "start": "1482070",
    "end": "1489120"
  },
  {
    "text": "also the hundred gig mix and you see two extra performance that's half your money",
    "start": "1489120",
    "end": "1495420"
  },
  {
    "text": "wasted in just five boxes put together five as an or six boxes put together yeah so 48",
    "start": "1495420",
    "end": "1502110"
  },
  {
    "text": "gpu-z would see 2x performance last now as you start to scale into hundreds and thousands GPUs you can calculate what's",
    "start": "1502110",
    "end": "1509670"
  },
  {
    "text": "going to go happen the top left graph is the bigger batch size and there are",
    "start": "1509670",
    "end": "1517110"
  },
  {
    "text": "three lines there one is the orange line which is the ideal theoretical maximum that you could ever get which is what I",
    "start": "1517110",
    "end": "1523440"
  },
  {
    "text": "did with one GPU I took and I said what if I put 48 gp's I just took that number",
    "start": "1523440",
    "end": "1530130"
  },
  {
    "text": "and multiplied by 48 that's the idea you could get and if you see in most of these graphs until 8 GPUs you definitely",
    "start": "1530130",
    "end": "1537570"
  },
  {
    "text": "get similar scale and after 8 you start to peter off a little bit you know the",
    "start": "1537570",
    "end": "1542640"
  },
  {
    "text": "scale is the slope is not one anymore or something it's because one box had a GPUs it's only when the second box comes",
    "start": "1542640",
    "end": "1549690"
  },
  {
    "text": "in you use the actual network you use the PFC if the EZ ends you will use the optimizations that I've been talking",
    "start": "1549690",
    "end": "1555990"
  },
  {
    "text": "about who likes to see half of their data or half of their money going based",
    "start": "1555990",
    "end": "1561290"
  },
  {
    "text": "nobody we're talking millions of dollars here I'll prove my point in the end with",
    "start": "1561290",
    "end": "1566490"
  },
  {
    "text": "a joke at somebody in conclusion I don't",
    "start": "1566490",
    "end": "1572490"
  },
  {
    "start": "1569000",
    "end": "1569000"
  },
  {
    "text": "stretch it we can talk about this later and these graphs are important these are real measurements and they're not done",
    "start": "1572490",
    "end": "1578340"
  },
  {
    "text": "yet we're gonna improve this further we're gonna pull these red guys and they love them and try to see how the scale and everything so I'm putting together",
    "start": "1578340",
    "end": "1585179"
  },
  {
    "text": "laughs with 800 GPUs and thousand GPS them and see how far it goes and then you've seen the ML portion umbers and",
    "start": "1585179",
    "end": "1590759"
  },
  {
    "text": "everything we want to train the resonant 50 or the more complex smaller Z 1 is",
    "start": "1590759",
    "end": "1596669"
  },
  {
    "text": "known 50 and 150 and what not not in weeks as it used to take not in days nor",
    "start": "1596669",
    "end": "1603240"
  },
  {
    "text": "in hours these results are the old model trained in five minutes so you can train",
    "start": "1603240",
    "end": "1611220"
  },
  {
    "text": "retrain things like those well this is the summary and it's coming to a close",
    "start": "1611220",
    "end": "1616830"
  },
  {
    "text": "finally the upshot of the matter is a multi rail or Diamond Cuban a DS is possible and it scales very well as we",
    "start": "1616830",
    "end": "1623100"
  },
  {
    "text": "have shown which Don the performance numbers there are a lot of things to take care of and you can go over the slides it will publish of course further",
    "start": "1623100",
    "end": "1630629"
  },
  {
    "text": "work would be storage you got a plan for it or we'll talk about it ambient temperature is an important",
    "start": "1630629",
    "end": "1637049"
  },
  {
    "text": "thing if you have hundred degree going on outside you will see that performance of your data center is suffering and you",
    "start": "1637049",
    "end": "1643110"
  },
  {
    "text": "would say what I did everything right what's wrong well it's just hot outside plays around good pressure there are",
    "start": "1643110",
    "end": "1649350"
  },
  {
    "text": "other things weather clears biggest principal slowest link will guide the performance of the entire job it's an HPC thing and to close does anyone know",
    "start": "1649350",
    "end": "1658049"
  },
  {
    "text": "what principle does a plane fly this was asked to me when I was doing my pilot",
    "start": "1658049",
    "end": "1663360"
  },
  {
    "text": "training several years ago and I took the first without instruction and the instructor said so you've learned a",
    "start": "1663360",
    "end": "1669629"
  },
  {
    "text": "little bit about how planes fly how do you how do they fly and I was naive I said you know like how networks works on",
    "start": "1669629",
    "end": "1676440"
  },
  {
    "text": "bits and switching and it has all the Bernoulli's principle things no the only",
    "start": "1676440",
    "end": "1682200"
  },
  {
    "text": "principle is you put money it flies this is networking put money in course just take a few",
    "start": "1682200",
    "end": "1687840"
  },
  {
    "text": "things thank you",
    "start": "1687840",
    "end": "1690408"
  },
  {
    "text": "so if any of you have questions that we have few more minutes and you're more",
    "start": "1694370",
    "end": "1699690"
  },
  {
    "text": "than welcome to contact rich out of myself yes do you have performance",
    "start": "1699690",
    "end": "1708300"
  },
  {
    "text": "numbers visibly the bare metal versus communities that you could illustrate on this is cubed and is on bare metal okay",
    "start": "1708300",
    "end": "1715800"
  },
  {
    "text": "so if you remove the infrastructure and just run it purely on bare metal how would this look like that's what I was",
    "start": "1715800",
    "end": "1721890"
  },
  {
    "text": "trying to figure out exactly the same it's if it's an argument that your name spaces introduce anything they're not in",
    "start": "1721890",
    "end": "1729000"
  },
  {
    "text": "the data path okay the SRO via the whole idea is that there is no bridge there is nothing the SRV idea is that you take",
    "start": "1729000",
    "end": "1735270"
  },
  {
    "text": "the physical interface nearly the physical interface take maybe a virtual function out of it and pull it right into it and as a rest set it doesn't",
    "start": "1735270",
    "end": "1741360"
  },
  {
    "text": "work on those sockets it works on the verbs so the data plane is not even there it doesn't even know what namespace and everything is it does but",
    "start": "1741360",
    "end": "1748830"
  },
  {
    "text": "it's not in the path yes I would maybe just add one thing that we didn't talk about here but the next phase that we",
    "start": "1748830",
    "end": "1755580"
  },
  {
    "text": "will do is actually enable all the Sdn controllers with the bypass so we you",
    "start": "1755580",
    "end": "1762810"
  },
  {
    "text": "know in the very near future we'll be able to run all those goodies where the full Sdn and without any performance",
    "start": "1762810",
    "end": "1770220"
  },
  {
    "text": "impact that's the next phase any additional questions yeah over here",
    "start": "1770220",
    "end": "1777650"
  },
  {
    "text": "if we are slicing the GPU to V GPUs right will we see any issues here like",
    "start": "1786930",
    "end": "1793620"
  },
  {
    "text": "our multiple jobs we'll run the universe of the problem we're trying to solve",
    "start": "1793620",
    "end": "1798870"
  },
  {
    "text": "we're taking one job and we're gonna take thousands of GPUs and use saying",
    "start": "1798870",
    "end": "1804360"
  },
  {
    "text": "that we take one GP and split it into multiple jobs so that we can't compare",
    "start": "1804360",
    "end": "1809460"
  },
  {
    "text": "this I mean I I know that this is the thing that we need to work I mean this is the problem K said but this is not that problem statement it's this problem",
    "start": "1809460",
    "end": "1815760"
  },
  {
    "text": "said - I got a model it takes hours to run and optimize how can I bring it down to minutes so this is not GPU sharing",
    "start": "1815760",
    "end": "1824580"
  },
  {
    "text": "this is taking everything in your datacenter or on one job finished in minutes come back with the new parameters yes so if you have a large",
    "start": "1824580",
    "end": "1837020"
  },
  {
    "text": "GPU cluster in which you run in different trainings in parallel like different different sets of you know DC",
    "start": "1837020",
    "end": "1843840"
  },
  {
    "text": "video trainings you know when you keep running were load your cluster it gets somehow fragmented like you cannot do",
    "start": "1843840",
    "end": "1850020"
  },
  {
    "text": "perfect lace me that you cannot put the jobs next to each other that's why so when you're using rocky instead of",
    "start": "1850020",
    "end": "1855780"
  },
  {
    "text": "InfiniBand how much noise can you know",
    "start": "1855780",
    "end": "1860790"
  },
  {
    "text": "how much noise can it survive or you know to make hotspots in the network because with InfiniBand G so hollers has",
    "start": "1860790",
    "end": "1867240"
  },
  {
    "text": "always like a double path - you can on T somehow the nodes will reach each other within a certain Latin C with a certain",
    "start": "1867240",
    "end": "1873900"
  },
  {
    "text": "pathway that without noise but with rocky is not the case if your question",
    "start": "1873900",
    "end": "1878940"
  },
  {
    "text": "is if I could tell right is that with rocky you're selling the network in",
    "start": "1878940",
    "end": "1884760"
  },
  {
    "text": "somewhere and within few when you get the Clear Channel and everything and stuff so this work is showing rocky but",
    "start": "1884760",
    "end": "1891570"
  },
  {
    "text": "it's not occluding rocky first including InfiniBand first of all so it's a principle should apply and then we",
    "start": "1891570",
    "end": "1897059"
  },
  {
    "text": "should work on IB as well but come back to a question yes if you clog a network you will get clogged results if you",
    "start": "1897059",
    "end": "1902760"
  },
  {
    "text": "clear a network you will get clear results is this there's nothing else but but you don't forget the PFC ECN",
    "start": "1902760",
    "end": "1909090"
  },
  {
    "text": "bits right if you have you have ecn on you would have a normally functioning cluster but if you still are overloaded",
    "start": "1909090",
    "end": "1915600"
  },
  {
    "text": "at least you will not die with thrashing I will just maybe quickly add",
    "start": "1915600",
    "end": "1921870"
  },
  {
    "text": "on that in general when you're running multi applications and a cloud which is",
    "start": "1921870",
    "end": "1926880"
  },
  {
    "text": "our performance you need to do placement in a network of our manner if you'll",
    "start": "1926880",
    "end": "1932370"
  },
  {
    "text": "place your workloads and without any network awareness you may have challenges and it is not available yet",
    "start": "1932370",
    "end": "1940140"
  },
  {
    "text": "to this part of kubernetes but this is something that HPC guys are definitely but you can do never placement but it",
    "start": "1940140",
    "end": "1947190"
  },
  {
    "text": "will get fragmented eventually because you place three you take four nodes and use for a job that's in danger source",
    "start": "1947190",
    "end": "1952770"
  },
  {
    "text": "gets free and then you only need two and then two are isolated I made you may not have four next to each other right",
    "start": "1952770",
    "end": "1958740"
  },
  {
    "text": "you're right I mean this is a problem that we faced in our data center and we are doing a new scheduler we have built",
    "start": "1958740",
    "end": "1964920"
  },
  {
    "text": "a new scheduler for the deep learning jobs for communities and to begin with for these large jobs we do gang",
    "start": "1964920",
    "end": "1970230"
  },
  {
    "text": "scheduling so that we know that the gang scheduler will put all these jobs on the nodes that are allocated so we demarcate",
    "start": "1970230",
    "end": "1977550"
  },
  {
    "text": "these nodes saying this is a node which will run jobs which want eight GPUs this is a node which will run which will four",
    "start": "1977550",
    "end": "1984720"
  },
  {
    "text": "jobs which won't for GPS which means two jobs can fit if you had a GPS if you're for jobs get creative here sixteen GPS on that box in this is a box a separate",
    "start": "1984720",
    "end": "1991980"
  },
  {
    "text": "box labeled separately the scheduler knows the notes electron rows and everything which is going to run only",
    "start": "1991980",
    "end": "1997650"
  },
  {
    "text": "jobs which one one GPU which means we can fit sixteen jobs if they have sixteen GPUs or eight jobs if they're after using but that's how we try to",
    "start": "1997650",
    "end": "2003740"
  },
  {
    "text": "avoid that fragmentation it is an integer programming trouble and if you",
    "start": "2003740",
    "end": "2008810"
  },
  {
    "text": "say I want to solve everything and not have fragmentation yes it's a real problem you will have lot of what's",
    "start": "2008810",
    "end": "2014840"
  },
  {
    "text": "called efficiency issues utilization so I think we're at the top the hour at",
    "start": "2014840",
    "end": "2022370"
  },
  {
    "text": "this point so all right okay if you have any other questions I catch up with the guys afterwards outside and thank you",
    "start": "2022370",
    "end": "2029810"
  },
  {
    "text": "for coming to the session thank you thank you thank you [Music]",
    "start": "2029810",
    "end": "2035160"
  }
]
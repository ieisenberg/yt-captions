[
  {
    "start": "0",
    "end": "46000"
  },
  {
    "text": "okay we're gonna go ahead and get started thanks thanks everyone for being here this talk is called a day in the",
    "start": "4650",
    "end": "11129"
  },
  {
    "text": "life of the data scientist we're going to talk about conquering machine learning life cycle on kubernetes so",
    "start": "11129",
    "end": "16890"
  },
  {
    "text": "good to have everybody here my name is Brian Redmond I work for Microsoft I'm on the Azure global black belt team I've",
    "start": "16890",
    "end": "23220"
  },
  {
    "text": "been at Microsoft for 18 years Redmond is my actual last name that's been that",
    "start": "23220",
    "end": "28680"
  },
  {
    "text": "way since I was born I'm based in Pittsburgh Pennsylvania so it's in the Northeast and the United States and when",
    "start": "28680",
    "end": "34559"
  },
  {
    "text": "I'm not talking about kubernetes or or technology I spend my time traveling around this was from last week I came",
    "start": "34559",
    "end": "41100"
  },
  {
    "text": "here from Hawaii on vacation so certainly a fun way to spend last week",
    "start": "41100",
    "end": "46160"
  },
  {
    "start": "46000",
    "end": "69000"
  },
  {
    "text": "everyone my name is Rita Jane I am a software engineer I'm Microsoft I'm based out of San",
    "start": "46160",
    "end": "52230"
  },
  {
    "text": "Francisco and I'm on the agile cognitive computing specifically I write features",
    "start": "52230",
    "end": "58800"
  },
  {
    "text": "for upstream kubernetes and basically making sure that all you guys have good",
    "start": "58800",
    "end": "64890"
  },
  {
    "text": "kubernetes experience on Azure um so I don't know if you guys remember",
    "start": "64890",
    "end": "71680"
  },
  {
    "text": "this but back in January I guess open they I announced that they're using",
    "start": "71680",
    "end": "77229"
  },
  {
    "text": "kubernetes for all of their machine learning trainings and more goats and",
    "start": "77229",
    "end": "82590"
  },
  {
    "text": "specifically their large clusters go up to 2500 notes so that sounds pretty",
    "start": "82590",
    "end": "89380"
  },
  {
    "text": "incredible especially for data scientists everywhere right now nowadays",
    "start": "89380",
    "end": "94539"
  },
  {
    "text": "more and more companies have AI as part of their company strategy but not",
    "start": "94539",
    "end": "100690"
  },
  {
    "text": "everybody has a dedicated infrastructure team just for their data scientist team",
    "start": "100690",
    "end": "106020"
  },
  {
    "text": "but a lot of companies do see the value of bringing DevOps practices to their",
    "start": "106020",
    "end": "112770"
  },
  {
    "text": "machine learning workflow and what we want to do in this session is",
    "start": "112770",
    "end": "119200"
  },
  {
    "text": "essentially demonstrate the typical machine learning workflow and how we can",
    "start": "119200",
    "end": "124720"
  },
  {
    "text": "leverage some of the best tools that are familiar to us in the kubernetes",
    "start": "124720",
    "end": "129789"
  },
  {
    "text": "community but to enhance a development experience in operations life cycles",
    "start": "129789",
    "end": "135570"
  },
  {
    "text": "meanwhile we can abstract all of the complexity of managing and operating infrastructure for a lot of the end",
    "start": "135570",
    "end": "142329"
  },
  {
    "text": "users so before we get into all the fun demos we're gonna try spend as much time in",
    "start": "142329",
    "end": "147780"
  },
  {
    "start": "144000",
    "end": "282000"
  },
  {
    "text": "this talk on demos as we can want to talk through the the typical kind of machine learning workflow and some of",
    "start": "147780",
    "end": "153180"
  },
  {
    "text": "the things that the issues that we run into and why we're trying to do some of this when we talk about the the data",
    "start": "153180",
    "end": "158250"
  },
  {
    "text": "preparation side really machine learning is only as good as the data that we have and we end up with very high volumes of",
    "start": "158250",
    "end": "164700"
  },
  {
    "text": "data large amounts of data that's a very big in size it creates a lot of issues around networking bottlenecks how do you",
    "start": "164700",
    "end": "171120"
  },
  {
    "text": "manage storage if I want to do this in a distributed manner how do I make that storage available to it to all of the",
    "start": "171120",
    "end": "177120"
  },
  {
    "text": "different training kind of processes I have and keeping track of data is also difficult you know maybe I want to",
    "start": "177120",
    "end": "182190"
  },
  {
    "text": "version data sets and go back and forth to different versions you know maybe I want to automate",
    "start": "182190",
    "end": "187200"
  },
  {
    "text": "training based on when I get new data or maybe I don't want to do that maybe that's happening too often and I don't",
    "start": "187200",
    "end": "192810"
  },
  {
    "text": "want to train necessarily every time there's a change so a lot of issues that we face there certainly on the training",
    "start": "192810",
    "end": "198480"
  },
  {
    "text": "side trainings are a training process is a pretty long-running process sometimes people run these things overnight and",
    "start": "198480",
    "end": "204480"
  },
  {
    "text": "they come back in the morning and see how it did and so getting the parameters correct the first time is super important the earlier we get to the",
    "start": "204480",
    "end": "211319"
  },
  {
    "text": "right model I mean is the earlier that we're actually taking advantage of it and so if we're doing these things",
    "start": "211319",
    "end": "216510"
  },
  {
    "text": "sequentially we've got to find a better way to do it on a larger scale if we're doing it in parallel then it becomes",
    "start": "216510",
    "end": "222720"
  },
  {
    "text": "pretty difficult to take advantage of distributed training technologies there's a few solutions out there and",
    "start": "222720",
    "end": "228000"
  },
  {
    "text": "they're all fairly difficult to do well and certainly getting the right hyper parameters is really key and we'll talk",
    "start": "228000",
    "end": "234690"
  },
  {
    "text": "about a solution and demo one here later today on how to do that now once we have a model that we like and we're ready to",
    "start": "234690",
    "end": "241019"
  },
  {
    "text": "use it in in production and serve that as an API there's a number of different issues we run into here where they're",
    "start": "241019",
    "end": "246299"
  },
  {
    "text": "they're actually pretty much typical app dev issues things that we that we solve with kind of DevOps practices things",
    "start": "246299",
    "end": "252840"
  },
  {
    "text": "where I containerized this model it worked on you know the test or dev machine and we brought it to production",
    "start": "252840",
    "end": "257849"
  },
  {
    "text": "that didn't work as well we certainly want to try to address those kinds of issues that things like containers dealing with scalability we want to",
    "start": "257849",
    "end": "264570"
  },
  {
    "text": "bring in feedback from production into our machine learning model and so when people are testing against our serving",
    "start": "264570",
    "end": "271770"
  },
  {
    "text": "model we actually get feedback there and we can actually incorporate that into the next training cycle and certainly",
    "start": "271770",
    "end": "277529"
  },
  {
    "text": "just generally automation and the things that we do around see ICD and automation are super important so when we say",
    "start": "277529",
    "end": "283619"
  },
  {
    "start": "282000",
    "end": "374000"
  },
  {
    "text": "DevOps what do we mean by DevOps this is a quote from from jazz humble and certainly let you reek of read through",
    "start": "283619",
    "end": "289589"
  },
  {
    "text": "that what jumps out to me is we're talking about rapidly changing resilient systems at scale and certainly when we",
    "start": "289589",
    "end": "296219"
  },
  {
    "text": "think about what we're trying to do with machine learning those things are super important we want to be able to work",
    "start": "296219",
    "end": "302279"
  },
  {
    "text": "with machine learning at a large amount of scale it's changing very fast we're gonna take advantage of DevOps practices",
    "start": "302279",
    "end": "308039"
  },
  {
    "text": "to do that it really means things like using using agile practices all throughout the solution not just on",
    "start": "308039",
    "end": "315269"
  },
  {
    "text": "our sort of code application development using infrastructure as code and get",
    "start": "315269",
    "end": "320399"
  },
  {
    "text": "throughout the process to make sure that we can roll back and roll forward and understand the changes that occur automated testing throughout the process",
    "start": "320399",
    "end": "327359"
  },
  {
    "text": "using things like CI CD to allow us to roll back and do things like canary tests and all those interesting things",
    "start": "327359",
    "end": "333389"
  },
  {
    "text": "but do it for our machine learning process and we see we see that having",
    "start": "333389",
    "end": "338459"
  },
  {
    "text": "been done in the past very well in the app dev world I would argue that not not as much of that is happening in the",
    "start": "338459",
    "end": "343919"
  },
  {
    "text": "machine learning process certainly a company like open AI they probably do this very well everyone else I would say",
    "start": "343919",
    "end": "350579"
  },
  {
    "text": "a lot of this stuff happens underneath someone's desk and things like that and the machine learning data science world at the same time we don't want to",
    "start": "350579",
    "end": "357449"
  },
  {
    "text": "incorporate a bunch of rules and tools and processes that slow down data science data scientists are doing",
    "start": "357449",
    "end": "363539"
  },
  {
    "text": "science and that involves a lot of experimentation the goal would be to make that experimentation more efficient",
    "start": "363539",
    "end": "368909"
  },
  {
    "text": "not less efficient and that is super important when I think about data science and machine learning",
    "start": "368909",
    "end": "374310"
  },
  {
    "start": "374000",
    "end": "422000"
  },
  {
    "text": "so where did containers in kubernetes fit in well this is Kubb con I think everybody understands these technologies",
    "start": "374310",
    "end": "380130"
  },
  {
    "text": "pretty well we do want to take advantage of containers and we're doing machine learning rita was working on some of",
    "start": "380130",
    "end": "385650"
  },
  {
    "text": "these demos and she sent me over a Python script I tried it out on my machine I was missing some Python",
    "start": "385650",
    "end": "390960"
  },
  {
    "text": "dependency containers take care of those kind of problems for us and we need kubernetes to handle orchestration for",
    "start": "390960",
    "end": "396690"
  },
  {
    "text": "us we're dealing with pretty large distributed systems massive scale thousands of cores summer GPUs and some",
    "start": "396690",
    "end": "403770"
  },
  {
    "text": "aren't kubernetes will help make sure that the right workload ends up on the right kind of node and we end up being",
    "start": "403770",
    "end": "409680"
  },
  {
    "text": "much more efficient about our trainings and we're gonna use tools like helm and you'll see where helm fits in as well if you're not familiar with helm certainly",
    "start": "409680",
    "end": "416220"
  },
  {
    "text": "a part of the CNC F as a package manager for kubernetes",
    "start": "416220",
    "end": "421700"
  },
  {
    "start": "422000",
    "end": "489000"
  },
  {
    "text": "as we mentioned earlier there are many many open-source solutions popping up",
    "start": "422050",
    "end": "428740"
  },
  {
    "text": "specifically to tailor running machine learning workloads on kubernetes and",
    "start": "428740",
    "end": "433760"
  },
  {
    "text": "enhance the end-user experience some of the ones that that I can think of right now it's like Polly axon Rhys ml",
    "start": "433760",
    "end": "441530"
  },
  {
    "text": "pipeline AI IBM fiddle those are a lot of options right so for the purpose of",
    "start": "441530",
    "end": "448610"
  },
  {
    "text": "this talk we chose cube flow to demonstrate a lot of the concepts and what we love about cube flow is that",
    "start": "448610",
    "end": "454910"
  },
  {
    "text": "it's a first of all it's open source is a community product and it really",
    "start": "454910",
    "end": "462140"
  },
  {
    "text": "abstract Sal otter that kubernetes complexity and it also makes repeating",
    "start": "462140",
    "end": "469510"
  },
  {
    "text": "training and serving a lot easier for people who may not be as familiar with",
    "start": "469510",
    "end": "474770"
  },
  {
    "text": "kubernetes but also like bring in you know our go workflow jupiter hub and",
    "start": "474770",
    "end": "480920"
  },
  {
    "text": "just make it it's a fully packaged solution that integrates a lot of the things a lot of the tools that we're",
    "start": "480920",
    "end": "486680"
  },
  {
    "text": "already familiar with okay so we done this talk a couple of",
    "start": "486680",
    "end": "492850"
  },
  {
    "start": "489000",
    "end": "537000"
  },
  {
    "text": "times and we always like to use real-world examples and in the past",
    "start": "492850",
    "end": "498070"
  },
  {
    "text": "we've done examples demos with image classification and often we choose a",
    "start": "498070",
    "end": "504220"
  },
  {
    "text": "well-known celebrity in the around the world and since we're here and keep on China we thought it's appropriate to use",
    "start": "504220",
    "end": "511630"
  },
  {
    "text": "fun beaming as she's probably the one of the most famous female celebrity in the",
    "start": "511630",
    "end": "517840"
  },
  {
    "text": "country so as many of you know a couple months ago a lot of fans were really",
    "start": "517840",
    "end": "523870"
  },
  {
    "text": "concerned that she kind of disappeared and she was she kind of like was popped",
    "start": "523870",
    "end": "529450"
  },
  {
    "text": "up in various parts of the country and so we thought why don't we use image",
    "start": "529450",
    "end": "535150"
  },
  {
    "text": "classification to find her and taking the workflow that we kind of talked",
    "start": "535150",
    "end": "540400"
  },
  {
    "start": "537000",
    "end": "639000"
  },
  {
    "text": "about earlier let's apply it to this particular example so first we start",
    "start": "540400",
    "end": "545410"
  },
  {
    "text": "with the data right and for this particular demo we are actually using",
    "start": "545410",
    "end": "552640"
  },
  {
    "text": "transfer learning so what that means is we start with Inception b3 as our base model which already has a lot of image",
    "start": "552640",
    "end": "562150"
  },
  {
    "text": "classification for a lot of the common things that we know like a dog a cat flowers and people and so on and so",
    "start": "562150",
    "end": "567220"
  },
  {
    "text": "forth so what we're doing is we're using that base model and we'll we applied that our data and labels for funding",
    "start": "567220",
    "end": "574510"
  },
  {
    "text": "being images for funding and images that are people who are not funding me right and we're taking that and we'll retrain",
    "start": "574510",
    "end": "581650"
  },
  {
    "text": "the top layer and that's how we get our particular model that works for our scenario and that's it come we obviously",
    "start": "581650",
    "end": "590050"
  },
  {
    "text": "want to improve and refine our model as it gets better and so what we're doing",
    "start": "590050",
    "end": "596020"
  },
  {
    "text": "is we create repeatable read experiments essentially our model and we want to be",
    "start": "596020",
    "end": "603190"
  },
  {
    "text": "able to run them as containers and we want to visualize the results in tensor",
    "start": "603190",
    "end": "608890"
  },
  {
    "text": "board and we also want to be able to run and scale all the different trainings",
    "start": "608890",
    "end": "614020"
  },
  {
    "text": "all the different hyper parameters by running it in kubernetes and we're going to leverage home and bunch of other",
    "start": "614020",
    "end": "620200"
  },
  {
    "text": "tools together to show you guys how we are doing that and last but not least we obviously want",
    "start": "620200",
    "end": "627100"
  },
  {
    "text": "to serve the model once it's ready to go and we're going to again demonstrate how",
    "start": "627100",
    "end": "632230"
  },
  {
    "text": "to do that and and also serve the model and test it again some test images that",
    "start": "632230",
    "end": "637660"
  },
  {
    "text": "we picked okay so I'm gonna I'm gonna do the first demo here and the first demo I'm",
    "start": "637660",
    "end": "643500"
  },
  {
    "start": "639000",
    "end": "771000"
  },
  {
    "text": "actually not gonna use kubernetes even though we're here at cube Con I'm just gonna show you kind of how we're gonna use containers to run one of these",
    "start": "643500",
    "end": "649530"
  },
  {
    "text": "trainings and do this kind of transfer learning that Rita just described so first I'm gonna jump out and show you",
    "start": "649530",
    "end": "655740"
  },
  {
    "text": "the code I'm gonna use vs code here and let you take a look at what we have here and so this retrain dot Python file this",
    "start": "655740",
    "end": "663330"
  },
  {
    "text": "is actually the transfer learning program that we're using that was described and we're gonna go through this line by line I think it's a",
    "start": "663330",
    "end": "669630"
  },
  {
    "text": "thousand lines of code so you know buckle up and that's what we're gonna do but know we're not gonna spend any time",
    "start": "669630",
    "end": "675450"
  },
  {
    "text": "in the code but what this what this code does is it goes out and downloads that inception model and then it actually",
    "start": "675450",
    "end": "681030"
  },
  {
    "text": "pulls in these pictures in these and these directories and so I have the fbb directory that's a bunch of pictures of",
    "start": "681030",
    "end": "687660"
  },
  {
    "text": "fan bingbing that that we're gonna end up you know properly labeling that way and then in the other folder the not fbb",
    "start": "687660",
    "end": "694140"
  },
  {
    "text": "we have pictures of people that aren't aren't her and so our model is actually going to go go through and scan these",
    "start": "694140",
    "end": "701100"
  },
  {
    "text": "and understand and build a model that we can then use and serve and use in our application and this is what the docker",
    "start": "701100",
    "end": "707220"
  },
  {
    "text": "file looks like for this application pretty straightforward we just use the standard tensorflow GPU image we add in",
    "start": "707220",
    "end": "713339"
  },
  {
    "text": "our code in our images and we're gonna go and do this do this execution of it so let me go back over to powerpoint and",
    "start": "713339",
    "end": "719460"
  },
  {
    "text": "let you see this running i'm gonna run this in powerpoint these things take a bit of time to run and so we have videos",
    "start": "719460",
    "end": "725370"
  },
  {
    "text": "of them here so i've got to get my mouse back",
    "start": "725370",
    "end": "730910"
  },
  {
    "text": "about that new they'll be trouble so I do a docker run command you can see the parameters up here a little bit hard to",
    "start": "732990",
    "end": "738690"
  },
  {
    "text": "see but basically I'm just running that image I'm passing in a bunch of parameters that mostly just tell it where does what files are where to store",
    "start": "738690",
    "end": "745860"
  },
  {
    "text": "all the files of everything I do tell it how many training steps that I want and this is going to end up being 4,000",
    "start": "745860",
    "end": "751640"
  },
  {
    "text": "understanding the right amount of training steps are the kind of hyper parameters that we would we would want to be testing and validating but you can",
    "start": "751640",
    "end": "757950"
  },
  {
    "text": "see it's going to go off and run that and we get back periodically an update on the results of the training and their",
    "start": "757950",
    "end": "763500"
  },
  {
    "text": "stand kind of how it's going at the end of this we end up with a model that we can then serve up and try out and that's",
    "start": "763500",
    "end": "769529"
  },
  {
    "text": "what I'm gonna actually show you next we're gonna take the model that comes out of that training and we need to",
    "start": "769529",
    "end": "775500"
  },
  {
    "start": "771000",
    "end": "875000"
  },
  {
    "text": "serve that up most likely as an API there's a number of different ways to do this I'm going to demo tensorflow",
    "start": "775500",
    "end": "780630"
  },
  {
    "text": "serving but a lot of companies will go out and build their own API and wrap around that particular model maybe they",
    "start": "780630",
    "end": "786180"
  },
  {
    "text": "build a Python flask application that is an API so that it can control kind of how that result is displayed but if I",
    "start": "786180",
    "end": "793350"
  },
  {
    "text": "just want to test out my model really quickly I can use something like tensorflow serving or Seldon and wrap",
    "start": "793350",
    "end": "798720"
  },
  {
    "text": "that around my model and test it out and I want to show you what that looks like",
    "start": "798720",
    "end": "803779"
  },
  {
    "text": "so what I end up doing here is I basically just take a the tensor the standard tensor flow serving image which",
    "start": "804639",
    "end": "811339"
  },
  {
    "text": "is really just a subset of the overall tensor flow project only the components that you need to serve this actual model",
    "start": "811339",
    "end": "817490"
  },
  {
    "text": "and I'm gonna copy in my model file into that and create a container image and when I go and run that I end up with",
    "start": "817490",
    "end": "824569"
  },
  {
    "text": "with an endpoint that I can query and so what I'll end up doing is I'll take a client application now that this this",
    "start": "824569",
    "end": "830060"
  },
  {
    "text": "endpoint is running in the background I'll take a picture and send it to that endpoint pretty simple sort of process",
    "start": "830060",
    "end": "836240"
  },
  {
    "text": "and when we do that this is the type of result that we get I end up with something that understands our model up",
    "start": "836240",
    "end": "843079"
  },
  {
    "text": "in the top there it shows the fbb and not fbb labels that came right out of the model and the particular picture",
    "start": "843079",
    "end": "848870"
  },
  {
    "text": "that I sent here it comes back with percentages based on is this F is this spawn Bingbing or not so in this case",
    "start": "848870",
    "end": "856220"
  },
  {
    "text": "it's 95 percent sure that that person in that picture is fine Bingbing and so we're pretty confident that the model",
    "start": "856220",
    "end": "863029"
  },
  {
    "text": "works with kind of a test image and so tensorflow serving obviously gave us that really simple way to take that",
    "start": "863029",
    "end": "868610"
  },
  {
    "text": "model without writing a bunch of code around it and test it out and that's the basics of that kind of piece of the demo",
    "start": "868610",
    "end": "875240"
  },
  {
    "start": "875000",
    "end": "1206000"
  },
  {
    "text": "so what about cooed flow that was just the basics of running it locally coop flow is where we're gonna get a bit more",
    "start": "875240",
    "end": "881209"
  },
  {
    "text": "interesting and take it up to the cluster and run this at a bit more of a scale and so we'll walk through how to",
    "start": "881209",
    "end": "886939"
  },
  {
    "text": "install Cooper here and how to actually use something called a TF job to actually get that up and running",
    "start": "886939",
    "end": "894730"
  },
  {
    "text": "the first thing I want to walk you through is I have a cluster running in Azure and so my particular cluster is is",
    "start": "895870",
    "end": "901330"
  },
  {
    "text": "on ACS engine one of the nice things about running running kubernetes particularly around around machine",
    "start": "901330",
    "end": "907420"
  },
  {
    "text": "learning and GPUs is Azure takes care of adding the nvidia drivers for whether",
    "start": "907420",
    "end": "912580"
  },
  {
    "text": "i'm using Azure kubernetes service or ACS engine it automatically sets up those drivers and makes my GPUs",
    "start": "912580",
    "end": "918880"
  },
  {
    "text": "available for those particular VM sizes and so you can see on this particular node I did a describe on one of the",
    "start": "918880",
    "end": "925330"
  },
  {
    "text": "nodes and I have that Nvidia comm slash GPU label and I have one available in this particular node I can use that",
    "start": "925330",
    "end": "931779"
  },
  {
    "text": "label later when I have my TF job specification I'll make sure that I ask for that so that we end up running this",
    "start": "931779",
    "end": "938230"
  },
  {
    "text": "on a particular GPU node in my cluster and it's nice I don't have to do any work to get those drivers set up",
    "start": "938230",
    "end": "945600"
  },
  {
    "text": "so next we're going to install coop flow and coop flow uses case on it for its",
    "start": "946510",
    "end": "951760"
  },
  {
    "text": "installation it's basically a simple way to kind of parameterize all the optional features that you want to use and so",
    "start": "951760",
    "end": "957670"
  },
  {
    "text": "you'll actually go out and point it out at a registry and to the source where where coop flows source is actually",
    "start": "957670",
    "end": "964360"
  },
  {
    "text": "installed and then you specify the different components that you want so everybody's going to use use coop flow",
    "start": "964360",
    "end": "970060"
  },
  {
    "text": "core we're also adding tensorflow serving and we're adding agro and Argo Argo is the workflow utility Rita",
    "start": "970060",
    "end": "976510"
  },
  {
    "text": "mentioned that you'll see in a demo later and so we're adding those different components we're layering any of the parameters for any of the the ways that",
    "start": "976510",
    "end": "983649"
  },
  {
    "text": "we want to configure this if we want things exposed to the Internet and so forth once we actually go and add those",
    "start": "983649",
    "end": "989050"
  },
  {
    "text": "parameters we do a generate that's actually what's going to go out and create the manifest for installing coop",
    "start": "989050",
    "end": "994149"
  },
  {
    "text": "flow the only thing that actually actually installs things in my cluster is when I go out and do an apply once I",
    "start": "994149",
    "end": "999970"
  },
  {
    "text": "do that apply I'm going to jump ahead here and you'll see kind of what we end up with the coop flow components are now",
    "start": "999970",
    "end": "1006180"
  },
  {
    "text": "installed into my cluster or there at least installing I end up with the the operator which to me is really the key",
    "start": "1006180",
    "end": "1012839"
  },
  {
    "text": "to cube flow for a lot of these kind of TF job type operations I'm describing I end up with the work flow controller in",
    "start": "1012839",
    "end": "1019050"
  },
  {
    "text": "Argo which are the Argo components ambassador handles Engrish traffic and so forth so I now have coop flow on top",
    "start": "1019050",
    "end": "1025650"
  },
  {
    "text": "of my cluster to allow me to do some of these and to end kind of machine learning workflows",
    "start": "1025650",
    "end": "1032770"
  },
  {
    "text": "the last piece is to actually run my training using coop flow I'm gonna jump back over to vs code and just show you",
    "start": "1032770",
    "end": "1039699"
  },
  {
    "text": "real quick what one of these TF jobs looks like",
    "start": "1039699",
    "end": "1043860"
  },
  {
    "text": "so this is my llamo file for for my job that I'm running this is basically the",
    "start": "1045890",
    "end": "1051530"
  },
  {
    "text": "same training I did in the docker demos but we're gonna do it in kubernetes I'm gonna create a persistent volume so I",
    "start": "1051530",
    "end": "1056630"
  },
  {
    "text": "can store my logs in using cloud storage so I can take a look at them later with a different container and this is the TF",
    "start": "1056630",
    "end": "1063500"
  },
  {
    "text": "job spec for this custom resource that that coupe flow is expecting and you can",
    "start": "1063500",
    "end": "1068809"
  },
  {
    "text": "see I provide this TF replica specs and I have I have one TF component here that",
    "start": "1068809",
    "end": "1074570"
  },
  {
    "text": "I'm running but it could be much more complicated than that there could be parameter servers various worker nodes you can specify all of that here and",
    "start": "1074570",
    "end": "1081710"
  },
  {
    "text": "then provide the pod spec you can see the image and the the arguments that I'm providing it looks basically the same as",
    "start": "1081710",
    "end": "1087919"
  },
  {
    "text": "the doctor run that I did earlier but I'm putting it into my Yama file here and notice I am specifying that Nvidia",
    "start": "1087919",
    "end": "1095510"
  },
  {
    "text": "comm GPU here to make sure that I get a GPU cuz that's what my image is expecting so I'll just take show you",
    "start": "1095510",
    "end": "1102500"
  },
  {
    "text": "what that looks like when we run that",
    "start": "1102500",
    "end": "1106000"
  },
  {
    "text": "and that mouse back you can see our coop flow components are",
    "start": "1108830",
    "end": "1115879"
  },
  {
    "text": "all running I'm just going to do a create on that yamo file and what it's going to do is create the TF job and",
    "start": "1115879",
    "end": "1121759"
  },
  {
    "text": "that persistent volume when the TF job is there they were then going to get a pod created based on that that's what",
    "start": "1121759",
    "end": "1128330"
  },
  {
    "text": "goop flow takes care of for us and you can see actually our volume is created and we do a check on the pod that's",
    "start": "1128330",
    "end": "1134899"
  },
  {
    "text": "actually going to be creating now and it takes it a couple minutes to create that's why we again use some recordings",
    "start": "1134899",
    "end": "1139909"
  },
  {
    "text": "here to jump ahead but if we go ahead and take a look at the logs we can actually see that this thing is executed",
    "start": "1139909",
    "end": "1147169"
  },
  {
    "text": "and our logs are stored up on cloud storage and we could take a look at them with like a tensor board so let me show",
    "start": "1147169",
    "end": "1152570"
  },
  {
    "text": "you what tensor board looks like you can see that my job is completed and",
    "start": "1152570",
    "end": "1160020"
  },
  {
    "text": "so after it's completed I can actually spin up another deployment which is tensor board and I'll have both a pod",
    "start": "1160020",
    "end": "1165450"
  },
  {
    "text": "with the tensor board in it and a service and I'll show you kind of what that",
    "start": "1165450",
    "end": "1171220"
  },
  {
    "text": "I end up with my my tensor board pod as well as the completed TF job and then I",
    "start": "1171220",
    "end": "1176919"
  },
  {
    "text": "can end up querying the breadth of the browser and actually seeing my results and actually understand how did that",
    "start": "1176919",
    "end": "1182860"
  },
  {
    "text": "work how did everything go we at that point also that those resources are now available that since that job is",
    "start": "1182860",
    "end": "1188799"
  },
  {
    "text": "completed that GPUs available for another another another training but we have the results of this log to be able",
    "start": "1188799",
    "end": "1194740"
  },
  {
    "text": "to evaluate the results and go from there all right so the next step is to actually hone these results and make",
    "start": "1194740",
    "end": "1200530"
  },
  {
    "text": "them better since they're not absolutely perfect and that's where rita is going to show you the hyper parameter tuning",
    "start": "1200530",
    "end": "1205740"
  },
  {
    "text": "as as we talked about this is for data scientists after all and when we talk",
    "start": "1205740",
    "end": "1212440"
  },
  {
    "start": "1206000",
    "end": "1703000"
  },
  {
    "text": "about sign science it's an experiment right and with every experiment we often",
    "start": "1212440",
    "end": "1217750"
  },
  {
    "text": "want to try different hyper parameters to fine-tune our model to make sure that",
    "start": "1217750",
    "end": "1222760"
  },
  {
    "text": "they improve over time and as traditional experience a lot of data",
    "start": "1222760",
    "end": "1228159"
  },
  {
    "text": "scientists end up running while they they probably have some machine you know",
    "start": "1228159",
    "end": "1233370"
  },
  {
    "text": "under their desk somewhere and they have to they have limited GPU resources and",
    "start": "1233370",
    "end": "1239110"
  },
  {
    "text": "they so what that means is they have to run trigger one job to finish and wait for hours maybe days right and so that",
    "start": "1239110",
    "end": "1246190"
  },
  {
    "text": "they can trigger start another experiment so what we're what we're going to show is a way to fully leverage",
    "start": "1246190",
    "end": "1253390"
  },
  {
    "text": "Cooper Nettie's in this end type we're going to scale and test different experiments in parallel so that we can",
    "start": "1253390",
    "end": "1260440"
  },
  {
    "text": "test different hyper parameters by marrying the the best part of cube flow",
    "start": "1260440",
    "end": "1266080"
  },
  {
    "text": "TF jobs and helm so that we can allow kubernetes to spin up all the different",
    "start": "1266080",
    "end": "1273130"
  },
  {
    "text": "parts that are necessary to complete an experiment and meanwhile we have one centralized tensor board instance that",
    "start": "1273130",
    "end": "1280210"
  },
  {
    "text": "essentially allows us to look at logs and results from every single experiments thereafter and be able to",
    "start": "1280210",
    "end": "1287620"
  },
  {
    "text": "compare and contrast how the performance of each experiment at the same time so",
    "start": "1287620",
    "end": "1294220"
  },
  {
    "text": "in order to do this in a kubernetes cluster obviously you're gonna say well does that mean I have to",
    "start": "1294220",
    "end": "1300250"
  },
  {
    "text": "create you know powerful GPU machines and just let us sit idle and wait and make sure they're available when my",
    "start": "1300250",
    "end": "1306460"
  },
  {
    "text": "users does cube CTL create No we definitely don't want that so there",
    "start": "1306460",
    "end": "1312610"
  },
  {
    "text": "are different ways to auto scale your cluster obviously there's called a cloud autoscaler which allows you to create",
    "start": "1312610",
    "end": "1319690"
  },
  {
    "text": "and delete VMs on on-demand so for the",
    "start": "1319690",
    "end": "1325060"
  },
  {
    "text": "purpose of this demo we're actually going to use a virtual cubelet and add your container instance so what is kind",
    "start": "1325060",
    "end": "1331180"
  },
  {
    "text": "of your container instance well as your container instance is a managed service that allows you to run your containers",
    "start": "1331180",
    "end": "1336730"
  },
  {
    "text": "without having to worry about infrastructure so you don't have to manage the actual node so all you have",
    "start": "1336730",
    "end": "1342760"
  },
  {
    "text": "to worry about is here's my image and go run it right so what we're doing is we're leveraging virtual cubelet which",
    "start": "1342760",
    "end": "1350080"
  },
  {
    "text": "essentially allows us to talk to a provider like a drip container instance",
    "start": "1350080",
    "end": "1355720"
  },
  {
    "text": "and be able to schedule our containers on Azure container instance and it kind",
    "start": "1355720",
    "end": "1361930"
  },
  {
    "text": "of masquerades as one of the couplets in the cluster and with this we're able to",
    "start": "1361930",
    "end": "1368320"
  },
  {
    "text": "run jobs on demand and auto scale as needed and once the jobs are completed I don't",
    "start": "1368320",
    "end": "1374800"
  },
  {
    "text": "have to pay for any of the resources so first I'm going to use helm to",
    "start": "1374800",
    "end": "1383660"
  },
  {
    "text": "leverage helm charters that are available for a lot of these solutions so virtual equivalent has a helm card",
    "start": "1383660",
    "end": "1392970"
  },
  {
    "text": "that allows me to install virtue cube with one single command and as you can",
    "start": "1392970",
    "end": "1397980"
  },
  {
    "text": "see here what we're doing is we're passing in credential information for a juror so that could wait so that a",
    "start": "1397980",
    "end": "1404820"
  },
  {
    "text": "virtual couplet will understand how to create instances on Azure and be able to",
    "start": "1404820",
    "end": "1411770"
  },
  {
    "text": "talk to virtue be able to talk to add your container instance api's so once",
    "start": "1411770",
    "end": "1418140"
  },
  {
    "text": "this is installed in the cluster as you can see when I do Cube CTO node you'll",
    "start": "1418140",
    "end": "1424350"
  },
  {
    "text": "see virtual people at the very end and what this does is to kubernetes it sees",
    "start": "1424350",
    "end": "1430800"
  },
  {
    "text": "it as one of the notes and with certain annotations I'm able to tell kubernetes",
    "start": "1430800",
    "end": "1436290"
  },
  {
    "text": "for this particular pod please go run it on as your container instance and and",
    "start": "1436290",
    "end": "1442050"
  },
  {
    "text": "again I don't have to worry about how to manage the VMS and I don't have to worry about patching or managing or supporting",
    "start": "1442050",
    "end": "1449040"
  },
  {
    "text": "it so next what now that we have so next",
    "start": "1449040",
    "end": "1455920"
  },
  {
    "text": "now that we have virtual kublai up and running what we want to do is again use helm to install our hyper parameter",
    "start": "1455920",
    "end": "1463660"
  },
  {
    "text": "chart so what we've done here is taking the diploma camels that Brian just",
    "start": "1463660",
    "end": "1468880"
  },
  {
    "text": "showed earlier again leveraging cube flow to schedule these TF jobs in",
    "start": "1468880",
    "end": "1475480"
  },
  {
    "text": "parallel right so now let's go take a look at what that chart looks like so",
    "start": "1475480",
    "end": "1481060"
  },
  {
    "text": "what we like about this is essentially we're using home chart to help us",
    "start": "1481060",
    "end": "1487500"
  },
  {
    "text": "parameters our actual deployment of the TF jobs so here as you can see were",
    "start": "1487500",
    "end": "1494020"
  },
  {
    "text": "actually using different hyper parameters but also exposing them as",
    "start": "1494020",
    "end": "1499810"
  },
  {
    "text": "parameters to our our deployment",
    "start": "1499810",
    "end": "1504890"
  },
  {
    "text": "so here is a typical deployment file and as you can see it see here this chart",
    "start": "1504890",
    "end": "1510799"
  },
  {
    "text": "actually creates a permutation of TF jobs based on the parameters that we",
    "start": "1510799",
    "end": "1516980"
  },
  {
    "text": "want to test so here as you can see for a particular TF job well I'm doing is",
    "start": "1516980",
    "end": "1522890"
  },
  {
    "text": "I'm saying go ahead and run this particular TF job on a CI with the K 80",
    "start": "1522890",
    "end": "1532929"
  },
  {
    "text": "GPU skew and then again here it's the same thing that we did earlier where we",
    "start": "1532929",
    "end": "1538730"
  },
  {
    "text": "pass an information to run our image to run our training but the difference here is we're passing in the hyper parameters",
    "start": "1538730",
    "end": "1545150"
  },
  {
    "text": "that we want to test and and again next what we're doing is we're telling",
    "start": "1545150",
    "end": "1550520"
  },
  {
    "text": "kubernetes go ahead and schedule these pods on a CI",
    "start": "1550520",
    "end": "1557470"
  },
  {
    "text": "so now coming back to the demo",
    "start": "1557690",
    "end": "1561909"
  },
  {
    "text": "so what we've done is again we use home install to install that char that I just",
    "start": "1565180",
    "end": "1570430"
  },
  {
    "text": "showed you and once this gets scheduled as you can see it instead of saying that",
    "start": "1570430",
    "end": "1577180"
  },
  {
    "text": "it's running on one of the nodes in the cluster it's actually it says it's running on virtual cubelet",
    "start": "1577180",
    "end": "1584039"
  },
  {
    "text": "and what is happening behind the scenes is that it virtually then talks to as",
    "start": "1584669",
    "end": "1591899"
  },
  {
    "text": "your container instance api's and here what we're doing is we're using an address tli to query what are",
    "start": "1591899",
    "end": "1598739"
  },
  {
    "text": "the resources that are getting created in a CI and here as you can see for each one of these jobs it's actually creating",
    "start": "1598739",
    "end": "1606419"
  },
  {
    "text": "a container group within the adjure container instance",
    "start": "1606419",
    "end": "1612859"
  },
  {
    "text": "so so here is a look at what is",
    "start": "1620040",
    "end": "1625450"
  },
  {
    "text": "happening when I'm running these training jobs on a CI so much like any",
    "start": "1625450",
    "end": "1631630"
  },
  {
    "text": "coop CTL command you can also understand like this is actually the events that",
    "start": "1631630",
    "end": "1637030"
  },
  {
    "text": "are happening when you run the container when you run the PI it's the first thing",
    "start": "1637030",
    "end": "1642340"
  },
  {
    "text": "is gonna do is gonna try to pull down your image and it's gonna start at the container and then next what its gonna",
    "start": "1642340",
    "end": "1649300"
  },
  {
    "text": "what you can see is you can again look at the locks of each container and you",
    "start": "1649300",
    "end": "1654490"
  },
  {
    "text": "can look at the progress of each training job as they go and because we're persisting all of this",
    "start": "1654490",
    "end": "1662310"
  },
  {
    "text": "on add your files each one of them remember the the different permutations",
    "start": "1662310",
    "end": "1668500"
  },
  {
    "text": "of the TF drops each TF job actually persists the logs and the results all in",
    "start": "1668500",
    "end": "1674080"
  },
  {
    "text": "a subdirectory on Azure files",
    "start": "1674080",
    "end": "1677760"
  },
  {
    "text": "and as part of our target we also create we also deployed sensor board and what",
    "start": "1680930",
    "end": "1687620"
  },
  {
    "text": "this allows us to do is to look at the performance of all these TF jobs as they're running and be able to compare",
    "start": "1687620",
    "end": "1694400"
  },
  {
    "text": "them side-by-side",
    "start": "1694400",
    "end": "1696820"
  },
  {
    "start": "1703000",
    "end": "1760000"
  },
  {
    "text": "all right so that was a demonstration of how a data scientist can leverage helm",
    "start": "1703440",
    "end": "1710410"
  },
  {
    "text": "virtue Kubla and a CI to run experiments in parallel next what we offer what we",
    "start": "1710410",
    "end": "1717250"
  },
  {
    "text": "want to show is how data scientists actually want to run a ml pipeline into",
    "start": "1717250",
    "end": "1722830"
  },
  {
    "text": "end meaning how do I go from data preparation to training to serving in a",
    "start": "1722830",
    "end": "1728590"
  },
  {
    "text": "more intuitive and simple way and what we're doing here is we're again",
    "start": "1728590",
    "end": "1733660"
  },
  {
    "text": "leveraging our go workflow which is an open source solution creator for kubernetes to run workflow",
    "start": "1733660",
    "end": "1741780"
  },
  {
    "text": "so in order I'm a pipeline what we are doing is first we have to containerize each",
    "start": "1742959",
    "end": "1748450"
  },
  {
    "text": "component each stage in our pipeline and as soon as each stage is completed then",
    "start": "1748450",
    "end": "1755350"
  },
  {
    "text": "they triggers the start of the next stage",
    "start": "1755350",
    "end": "1759210"
  },
  {
    "text": "so here I'm going to show you guys what a typical Argo definition looks like I",
    "start": "1760570",
    "end": "1767320"
  },
  {
    "text": "know this is kind of overwhelming but but essentially like any other yamo",
    "start": "1767320",
    "end": "1772690"
  },
  {
    "text": "files out there you have arguments that tells are go hey here's here are the",
    "start": "1772690",
    "end": "1778660"
  },
  {
    "text": "arguments that I want to use for this particular run right and when you define",
    "start": "1778660",
    "end": "1784240"
  },
  {
    "text": "an Argo workflow you also tell Argo hey here are the different steps here are",
    "start": "1784240",
    "end": "1789460"
  },
  {
    "text": "the different stages and for each stage there are there are definitely you can",
    "start": "1789460",
    "end": "1795100"
  },
  {
    "text": "again create definitions to tell Argo here's what I want you to do in",
    "start": "1795100",
    "end": "1800410"
  },
  {
    "text": "kubernetes so here as you can see we have a couple of different stages and",
    "start": "1800410",
    "end": "1805450"
  },
  {
    "text": "I'm going to let so let's say for TF train down here I describe what TF train",
    "start": "1805450",
    "end": "1811690"
  },
  {
    "text": "stage is supposed to do and again much like what we did earlier it does nothing",
    "start": "1811690",
    "end": "1816880"
  },
  {
    "text": "but tell our go here's the yeah mole that I want you to run and essentially it creates a TF job right and what this",
    "start": "1816880",
    "end": "1825190"
  },
  {
    "text": "does then again runs all of these runs this TF job and then once it's done once it's",
    "start": "1825190",
    "end": "1832360"
  },
  {
    "text": "completed then it triggers the serving piece so down here is the serving the",
    "start": "1832360",
    "end": "1837910"
  },
  {
    "text": "inference stage and once again what it does is it takes the output from the",
    "start": "1837910",
    "end": "1844630"
  },
  {
    "text": "previous stage and expose it and serve it as a serving endpoint for our tests our Python script to test a test image",
    "start": "1844630",
    "end": "1855000"
  },
  {
    "text": "so coming back to our demo here is here",
    "start": "1855220",
    "end": "1864130"
  },
  {
    "text": "is us running it right so in order to so the fact the Yama file that we just",
    "start": "1864130",
    "end": "1869950"
  },
  {
    "text": "showed you it defines an entire pipeline but to actually trigger it you need to do our go submit which basically submits",
    "start": "1869950",
    "end": "1876820"
  },
  {
    "text": "the job and initiates the beginning of the pipeline and once it gets created over time as",
    "start": "1876820",
    "end": "1885150"
  },
  {
    "text": "you can see a it basically triggers one stage and then it tells you the progress",
    "start": "1885150",
    "end": "1892020"
  },
  {
    "text": "of one stage and then it goes to the next so as you can see here what it's actually doing is it creates my job",
    "start": "1892020",
    "end": "1899190"
  },
  {
    "text": "which is the training course training stage of the pipeline and at the same time it created the tensor board stage",
    "start": "1899190",
    "end": "1907500"
  },
  {
    "text": "which again allows us to monitor the training as it's going",
    "start": "1907500",
    "end": "1912980"
  },
  {
    "text": "and next here as you know once it's completed with what's interesting about",
    "start": "1915159",
    "end": "1924010"
  },
  {
    "text": "our NGO also it has like a nice UI dashboard but also the CLI will actually",
    "start": "1924010",
    "end": "1929620"
  },
  {
    "text": "tell you how the status of each stage and as you progress if it basically",
    "start": "1929620",
    "end": "1936880"
  },
  {
    "text": "allows you to look at the the content",
    "start": "1936880",
    "end": "1942880"
  },
  {
    "text": "and the logs of your training and again it has the dashboard portion that lets you look at it as well so here as the",
    "start": "1942880",
    "end": "1952630"
  },
  {
    "text": "pipeline progresses as you can see the the training stage is done now he",
    "start": "1952630",
    "end": "1957730"
  },
  {
    "text": "advances to the serving piece which then",
    "start": "1957730",
    "end": "1963360"
  },
  {
    "text": "creates the the serving pod and what",
    "start": "1963809",
    "end": "1969220"
  },
  {
    "text": "what the serving pod does is a with the service as well it basically creates a public service a kubernetes service that",
    "start": "1969220",
    "end": "1977080"
  },
  {
    "text": "exposes or serving model endpoint so that my Python client code can then use",
    "start": "1977080",
    "end": "1983500"
  },
  {
    "text": "that serving in point to test so in this case",
    "start": "1983500",
    "end": "1989590"
  },
  {
    "text": "so in this case disturbing model stage created the service and with that service API I'm able to run it against",
    "start": "1989590",
    "end": "1996610"
  },
  {
    "text": "it with a test image",
    "start": "1996610",
    "end": "2000260"
  },
  {
    "text": "and again the output of it is you know some some label and then some",
    "start": "2001990",
    "end": "2007990"
  },
  {
    "text": "probability of how confident it feels that particular test so in this case as",
    "start": "2007990",
    "end": "2017140"
  },
  {
    "text": "you can see for this particular image it says",
    "start": "2017140",
    "end": "2023398"
  },
  {
    "text": "so for this particular image it basically will we'll be able to tell you hey it's not funding being and this is",
    "start": "2026290",
    "end": "2033490"
  },
  {
    "text": "the probability okay so I guess that's the end to end so",
    "start": "2033490",
    "end": "2041620"
  },
  {
    "start": "2038000",
    "end": "2193000"
  },
  {
    "text": "what's next yes well I'd like to believe that those demos meant that we solved everything we realize it's a bit more",
    "start": "2041620",
    "end": "2047470"
  },
  {
    "text": "complicated than that in fact in some ways we've added a bunch of tools for data scientists to do their to do their",
    "start": "2047470",
    "end": "2052990"
  },
  {
    "text": "work but we've also introduced some new tasks for them docker files yeah mol we probably don't want to have data",
    "start": "2052990",
    "end": "2060220"
  },
  {
    "text": "scientists spending time in the ml files and so perhaps the goal is to abstract some of that away from them and",
    "start": "2060220",
    "end": "2065440"
  },
  {
    "text": "certainly coop flow home things like that helped quite a bit and we probably need to do some work to",
    "start": "2065440",
    "end": "2070480"
  },
  {
    "text": "make that a bit easier from the data preparation side we didn't really talk about some of the things that you can do",
    "start": "2070480",
    "end": "2075669"
  },
  {
    "text": "around data so there's like pachyderm out there that can that can help in that kind of thing and certainly you can use",
    "start": "2075670",
    "end": "2080800"
  },
  {
    "text": "that along with coop flow and certainly on the DevOps side we didn't talk about some of the things that you need to do",
    "start": "2080800",
    "end": "2085929"
  },
  {
    "text": "around automation or testing certainly we have a model and we know what kind of result it should it should provide so we",
    "start": "2085930",
    "end": "2092050"
  },
  {
    "text": "could actually automate those tests and do things like canary deploys and AV testing when we actually do it train",
    "start": "2092050",
    "end": "2098230"
  },
  {
    "text": "train a model and release it into into production so important to add those things to it and know that our work is",
    "start": "2098230",
    "end": "2104200"
  },
  {
    "text": "not done yeah and two if you want to learn a little bit more about pachyderms for versioning your data set and turning",
    "start": "2104200",
    "end": "2110650"
  },
  {
    "text": "a new training definitely go and check out samuel session tomorrow it's called",
    "start": "2110650",
    "end": "2115960"
  },
  {
    "text": "modern data science and cloud native world so please do that it's actually in this room also we just also want to",
    "start": "2115960",
    "end": "2122200"
  },
  {
    "text": "mention that there are plenty of houses services out there today so depending on the requirements of your data scientist",
    "start": "2122200",
    "end": "2128290"
  },
  {
    "text": "you might not need all this so I just want to call that out like Azure ml studio",
    "start": "2128290",
    "end": "2133300"
  },
  {
    "text": "cognitive stirs the stage maker auto ml so those are actually out there but again this is for people who want to",
    "start": "2133300",
    "end": "2140470"
  },
  {
    "text": "kind of manage their own training and prediction workflow and again there's",
    "start": "2140470",
    "end": "2145870"
  },
  {
    "text": "tons of open source stuff popping up in the space and I also want to just call out that last week cube flow pipeline",
    "start": "2145870",
    "end": "2153400"
  },
  {
    "text": "was released and it's it's very much includes a lot of the Argo stuff that I demoed earlier so that you can create a",
    "start": "2153400",
    "end": "2160750"
  },
  {
    "text": "pipeline but pipeline cube flow pipeline has a nice user",
    "start": "2160750",
    "end": "2165820"
  },
  {
    "text": "interface and kind of abstract a lot of this complexity from the end user and",
    "start": "2165820",
    "end": "2171010"
  },
  {
    "text": "also check out cube flow Ferenc was also released last week I think essentially it leverages meta particle and it allows",
    "start": "2171010",
    "end": "2179350"
  },
  {
    "text": "end-users to label parts of their Python code and be able to kind of go from",
    "start": "2179350",
    "end": "2185650"
  },
  {
    "text": "development or training very quickly without having too much understanding of",
    "start": "2185650",
    "end": "2190660"
  },
  {
    "text": "the infrastructure piece it's so obviously you can go try this code we'd",
    "start": "2190660",
    "end": "2195880"
  },
  {
    "start": "2193000",
    "end": "2229000"
  },
  {
    "text": "love to have people try this out it's all out on github we're a bit over on our time so we certainly will take",
    "start": "2195880",
    "end": "2201430"
  },
  {
    "text": "questions kind of in the back but I certainly want to thank everybody for coming and joining in for the session I appreciate and enjoy the rest of your",
    "start": "2201430",
    "end": "2207340"
  },
  {
    "text": "coop comm all the code and the demos all",
    "start": "2207340",
    "end": "2215440"
  },
  {
    "text": "the video recordings are all up there in the first link so please do check it out and we are definitely open to issues and",
    "start": "2215440",
    "end": "2222690"
  },
  {
    "text": "MPR's nice",
    "start": "2222690",
    "end": "2226770"
  }
]
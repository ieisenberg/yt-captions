[
  {
    "start": "0",
    "end": "15000"
  },
  {
    "text": "hello there my name is watson kasturi",
    "start": "1280",
    "end": "5040"
  },
  {
    "text": "i'm going to be giving this kubecon tech",
    "start": "5040",
    "end": "6960"
  },
  {
    "text": "talk along with",
    "start": "6960",
    "end": "8480"
  },
  {
    "text": "nivedita vishwanath on high performance",
    "start": "8480",
    "end": "10800"
  },
  {
    "text": "networking for distributed dl training",
    "start": "10800",
    "end": "12880"
  },
  {
    "text": "in production k8s",
    "start": "12880",
    "end": "16240"
  },
  {
    "start": "15000",
    "end": "38000"
  },
  {
    "text": "this presentation is about sharing your",
    "start": "16240",
    "end": "18160"
  },
  {
    "text": "experience in creating 800 gpu",
    "start": "18160",
    "end": "20640"
  },
  {
    "text": "cluster using 100kg x over rocky",
    "start": "20640",
    "end": "23920"
  },
  {
    "text": "protocol",
    "start": "23920",
    "end": "25760"
  },
  {
    "text": "using ethernet network",
    "start": "25760",
    "end": "29199"
  },
  {
    "text": "i'll cover the first section and i'll go",
    "start": "29199",
    "end": "32398"
  },
  {
    "text": "into the second section",
    "start": "32399",
    "end": "34480"
  },
  {
    "text": "concluding with performance numbers",
    "start": "34480",
    "end": "38160"
  },
  {
    "start": "38000",
    "end": "172000"
  },
  {
    "text": "so the agenda of this tech talk is",
    "start": "39360",
    "end": "41200"
  },
  {
    "text": "broadly split into two sections",
    "start": "41200",
    "end": "44800"
  },
  {
    "text": "the top level is a gray colored boxes",
    "start": "44800",
    "end": "47360"
  },
  {
    "text": "which indicate",
    "start": "47360",
    "end": "48800"
  },
  {
    "text": "control plane operations and setup which",
    "start": "48800",
    "end": "51440"
  },
  {
    "text": "we have to do",
    "start": "51440",
    "end": "53039"
  },
  {
    "text": "the bottom level side is the green boxes",
    "start": "53039",
    "end": "56000"
  },
  {
    "text": "indicate",
    "start": "56000",
    "end": "57280"
  },
  {
    "text": "the network the speeds and the feeds how",
    "start": "57280",
    "end": "60000"
  },
  {
    "text": "do we integrate rdma",
    "start": "60000",
    "end": "61440"
  },
  {
    "text": "sriv and then the performance numbers",
    "start": "61440",
    "end": "65280"
  },
  {
    "text": "coming out of this exercise so obviously",
    "start": "65280",
    "end": "68240"
  },
  {
    "text": "the stack has to be laid out",
    "start": "68240",
    "end": "69760"
  },
  {
    "text": "first for the computer environment and",
    "start": "69760",
    "end": "72880"
  },
  {
    "text": "then we have to",
    "start": "72880",
    "end": "73760"
  },
  {
    "text": "launch the dl applications and as a",
    "start": "73760",
    "end": "76159"
  },
  {
    "text": "container",
    "start": "76159",
    "end": "76880"
  },
  {
    "text": "in the kds environment and collect the",
    "start": "76880",
    "end": "79600"
  },
  {
    "text": "metrics",
    "start": "79600",
    "end": "80240"
  },
  {
    "text": "coming out of the telemetry to monitor",
    "start": "80240",
    "end": "82720"
  },
  {
    "text": "how the cluster is performing",
    "start": "82720",
    "end": "85200"
  },
  {
    "text": "along with fairness multi-user",
    "start": "85200",
    "end": "87840"
  },
  {
    "text": "multiplexed",
    "start": "87840",
    "end": "88799"
  },
  {
    "text": "environment so that the users can get a",
    "start": "88799",
    "end": "90799"
  },
  {
    "text": "fair share of the computer",
    "start": "90799",
    "end": "94079"
  },
  {
    "text": "the multi-node data center consideration",
    "start": "94960",
    "end": "97119"
  },
  {
    "text": "has to be you know",
    "start": "97119",
    "end": "98479"
  },
  {
    "text": "involved here for the design of the",
    "start": "98479",
    "end": "100560"
  },
  {
    "text": "cluster itself",
    "start": "100560",
    "end": "103280"
  },
  {
    "text": "and depend depends on the heating and",
    "start": "103280",
    "end": "105040"
  },
  {
    "text": "the cooling the rack layout",
    "start": "105040",
    "end": "107360"
  },
  {
    "text": "along with the fine networks which are",
    "start": "107360",
    "end": "109040"
  },
  {
    "text": "listed here what we call as the east",
    "start": "109040",
    "end": "110960"
  },
  {
    "text": "west not south",
    "start": "110960",
    "end": "111920"
  },
  {
    "text": "ipmi storage and internet network",
    "start": "111920",
    "end": "116000"
  },
  {
    "text": "the edi hdr ndr and pci are bandwidth",
    "start": "116000",
    "end": "118960"
  },
  {
    "text": "related",
    "start": "118960",
    "end": "119759"
  },
  {
    "text": "the edr is 100k hdr is 200 gig",
    "start": "119759",
    "end": "123360"
  },
  {
    "text": "and ndr and 400 links and how do they",
    "start": "123360",
    "end": "126240"
  },
  {
    "text": "actually communicate",
    "start": "126240",
    "end": "127520"
  },
  {
    "text": "gpu to gpu in the east-west direction",
    "start": "127520",
    "end": "131599"
  },
  {
    "text": "and how do we integrate the nodes rdma",
    "start": "131599",
    "end": "134400"
  },
  {
    "text": "srv",
    "start": "134400",
    "end": "135120"
  },
  {
    "text": "cnr into the kubernetes tester",
    "start": "135120",
    "end": "138560"
  },
  {
    "text": "and then we'll conclude with production",
    "start": "138560",
    "end": "140720"
  },
  {
    "text": "here carried as experience",
    "start": "140720",
    "end": "142000"
  },
  {
    "text": "and also the performance in the second",
    "start": "142000",
    "end": "144720"
  },
  {
    "text": "half",
    "start": "144720",
    "end": "146959"
  },
  {
    "text": "i'm not going to go into the details of",
    "start": "147680",
    "end": "149360"
  },
  {
    "text": "this listing here",
    "start": "149360",
    "end": "151040"
  },
  {
    "text": "but you can see there are five networks",
    "start": "151040",
    "end": "152800"
  },
  {
    "text": "listed here",
    "start": "152800",
    "end": "155280"
  },
  {
    "text": "there are speeds and fees discussion and",
    "start": "155280",
    "end": "158160"
  },
  {
    "text": "other design consideration in the data",
    "start": "158160",
    "end": "160000"
  },
  {
    "text": "center",
    "start": "160000",
    "end": "162319"
  },
  {
    "text": "nivedita will cover the production",
    "start": "162560",
    "end": "164480"
  },
  {
    "text": "kubernetes cluster",
    "start": "164480",
    "end": "166160"
  },
  {
    "text": "multi-node workloads and also a cni",
    "start": "166160",
    "end": "170000"
  },
  {
    "text": "control flow",
    "start": "170000",
    "end": "172720"
  },
  {
    "start": "172000",
    "end": "296000"
  },
  {
    "text": "so what is the multi-node cluster mnk it",
    "start": "173120",
    "end": "175440"
  },
  {
    "text": "is",
    "start": "175440",
    "end": "176400"
  },
  {
    "text": "mnk8s is a 100 node dgx1 v100 cluster",
    "start": "176400",
    "end": "180239"
  },
  {
    "text": "connected by the ethernet links for gpu",
    "start": "180239",
    "end": "182239"
  },
  {
    "text": "to gpu communication",
    "start": "182239",
    "end": "184319"
  },
  {
    "text": "over a rocky v2 protocol we use rdma",
    "start": "184319",
    "end": "187599"
  },
  {
    "text": "extensively",
    "start": "187599",
    "end": "188480"
  },
  {
    "text": "to move the data and the cluster is set",
    "start": "188480",
    "end": "192400"
  },
  {
    "text": "up such that we can provide horizontal",
    "start": "192400",
    "end": "194000"
  },
  {
    "text": "scaling at bgs",
    "start": "194000",
    "end": "196159"
  },
  {
    "text": "in the data center subjected to the",
    "start": "196159",
    "end": "198000"
  },
  {
    "text": "condition of",
    "start": "198000",
    "end": "199280"
  },
  {
    "text": "rack space power cooling and heating",
    "start": "199280",
    "end": "202879"
  },
  {
    "text": "the orchestration is done by the kts",
    "start": "202879",
    "end": "204879"
  },
  {
    "text": "controller while the jobs are actually",
    "start": "204879",
    "end": "206720"
  },
  {
    "text": "time shared as i said earlier",
    "start": "206720",
    "end": "209440"
  },
  {
    "text": "controlled by the custom batch scheduler",
    "start": "209440",
    "end": "212480"
  },
  {
    "text": "for fairness of the gpu as well as the",
    "start": "212480",
    "end": "215599"
  },
  {
    "text": "time being used on the gpu",
    "start": "215599",
    "end": "218400"
  },
  {
    "text": "data scientists are the users who are",
    "start": "218400",
    "end": "220480"
  },
  {
    "text": "running the ml jobs",
    "start": "220480",
    "end": "222799"
  },
  {
    "text": "it could be a pi touch or tensorflow",
    "start": "222799",
    "end": "224640"
  },
  {
    "text": "inside the container or they are",
    "start": "224640",
    "end": "227120"
  },
  {
    "text": "getting launched by the kids in these",
    "start": "227120",
    "end": "230239"
  },
  {
    "text": "worker nodes so when you set up a",
    "start": "230239",
    "end": "233840"
  },
  {
    "text": "cluster like this there is an",
    "start": "233840",
    "end": "234879"
  },
  {
    "text": "expectation of the kpi",
    "start": "234879",
    "end": "237280"
  },
  {
    "text": "and here is what we have experienced",
    "start": "237280",
    "end": "240799"
  },
  {
    "text": "in what you have considered as a good",
    "start": "240799",
    "end": "242560"
  },
  {
    "text": "kpi for ml",
    "start": "242560",
    "end": "244159"
  },
  {
    "text": "clusters we need to design low latent",
    "start": "244159",
    "end": "247280"
  },
  {
    "text": "mnk clusters and it's one hop network",
    "start": "247280",
    "end": "250879"
  },
  {
    "text": "to keep the cluster design simple",
    "start": "250879",
    "end": "254480"
  },
  {
    "text": "and what we also observed is",
    "start": "254480",
    "end": "257600"
  },
  {
    "text": "instead of being 16 gpu on a one note we",
    "start": "257600",
    "end": "260479"
  },
  {
    "text": "if we run a",
    "start": "260479",
    "end": "261440"
  },
  {
    "text": "1400 gpu we have a improvement of",
    "start": "261440",
    "end": "265199"
  },
  {
    "text": "factor of 70x and this is specifically",
    "start": "265199",
    "end": "268160"
  },
  {
    "text": "an ml",
    "start": "268160",
    "end": "269040"
  },
  {
    "text": "performance faster model convergence for",
    "start": "269040",
    "end": "272800"
  },
  {
    "text": "the data center means",
    "start": "272800",
    "end": "275040"
  },
  {
    "text": "faster performance numbers coming down",
    "start": "275040",
    "end": "278639"
  },
  {
    "text": "into increasing productivity and also",
    "start": "278639",
    "end": "281759"
  },
  {
    "text": "converging faster into the accurate",
    "start": "281759",
    "end": "283440"
  },
  {
    "text": "states when you have 8 billion",
    "start": "283440",
    "end": "284720"
  },
  {
    "text": "parameters",
    "start": "284720",
    "end": "286080"
  },
  {
    "text": "to operate with the network needs to be",
    "start": "286080",
    "end": "289440"
  },
  {
    "text": "match the multi-node cluster gpu targets",
    "start": "289440",
    "end": "292560"
  },
  {
    "text": "so they don't become a bottleneck",
    "start": "292560",
    "end": "297840"
  },
  {
    "start": "296000",
    "end": "339000"
  },
  {
    "text": "this particular picture has two images",
    "start": "298320",
    "end": "300560"
  },
  {
    "text": "sandwich the one on the left on the",
    "start": "300560",
    "end": "302160"
  },
  {
    "text": "right",
    "start": "302160",
    "end": "303360"
  },
  {
    "text": "the left image is inside the hardware",
    "start": "303360",
    "end": "306240"
  },
  {
    "text": "part",
    "start": "306240",
    "end": "306639"
  },
  {
    "text": "cluster and you can see the perforations",
    "start": "306639",
    "end": "308639"
  },
  {
    "text": "on the on the floor where the airflow",
    "start": "308639",
    "end": "310639"
  },
  {
    "text": "will come out and push it out",
    "start": "310639",
    "end": "312960"
  },
  {
    "text": "the right side picture is on the back",
    "start": "312960",
    "end": "314479"
  },
  {
    "text": "side we call it a power side",
    "start": "314479",
    "end": "317280"
  },
  {
    "text": "where the heat will come out and then",
    "start": "317280",
    "end": "319039"
  },
  {
    "text": "leave the data center",
    "start": "319039",
    "end": "321680"
  },
  {
    "text": "there are basically six switches here",
    "start": "321680",
    "end": "323600"
  },
  {
    "text": "each of them 128 ports 100 gig switches",
    "start": "323600",
    "end": "327600"
  },
  {
    "text": "and there are four rings we'll talk",
    "start": "327600",
    "end": "329280"
  },
  {
    "text": "about in the subsequent slides",
    "start": "329280",
    "end": "331440"
  },
  {
    "text": "and two of them are used for leaves to",
    "start": "331440",
    "end": "334000"
  },
  {
    "text": "go up the",
    "start": "334000",
    "end": "334960"
  },
  {
    "text": "north south traffic",
    "start": "334960",
    "end": "339840"
  },
  {
    "start": "339000",
    "end": "352000"
  },
  {
    "text": "there are terminologies used in this",
    "start": "340240",
    "end": "341840"
  },
  {
    "text": "tech talk so i have listed them here",
    "start": "341840",
    "end": "344160"
  },
  {
    "text": "um i'm not going to go through them but",
    "start": "344160",
    "end": "346400"
  },
  {
    "text": "you can refer them",
    "start": "346400",
    "end": "348240"
  },
  {
    "text": "at their terminologies which you don't",
    "start": "348240",
    "end": "350840"
  },
  {
    "text": "understand",
    "start": "350840",
    "end": "353840"
  },
  {
    "text": "in multi-node cluster these are the",
    "start": "354320",
    "end": "355840"
  },
  {
    "text": "building blocks moving from left to",
    "start": "355840",
    "end": "357440"
  },
  {
    "text": "right",
    "start": "357440",
    "end": "358319"
  },
  {
    "text": "there's a data center there's power",
    "start": "358319",
    "end": "359840"
  },
  {
    "text": "cooling racks how do you do the",
    "start": "359840",
    "end": "361840"
  },
  {
    "text": "placement of the dgx and the cpu nodes",
    "start": "361840",
    "end": "365360"
  },
  {
    "text": "and this is typically done by the side",
    "start": "365360",
    "end": "367039"
  },
  {
    "text": "ops and the networking team",
    "start": "367039",
    "end": "369039"
  },
  {
    "text": "and then there is perimeter network and",
    "start": "369039",
    "end": "371280"
  },
  {
    "text": "then the pi network",
    "start": "371280",
    "end": "372400"
  },
  {
    "text": "is right here which has a k it has a bgp",
    "start": "372400",
    "end": "376319"
  },
  {
    "text": "layout in the switching along with the",
    "start": "376319",
    "end": "378479"
  },
  {
    "text": "vlan on the",
    "start": "378479",
    "end": "379440"
  },
  {
    "text": "lower end and you do have monitoring",
    "start": "379440",
    "end": "382479"
  },
  {
    "text": "metrics",
    "start": "382479",
    "end": "383199"
  },
  {
    "text": "and logging associated with both the",
    "start": "383199",
    "end": "385360"
  },
  {
    "text": "networks as well as the user jobs",
    "start": "385360",
    "end": "389039"
  },
  {
    "text": "this particular block is where the users",
    "start": "389039",
    "end": "390720"
  },
  {
    "text": "actually get to see",
    "start": "390720",
    "end": "392479"
  },
  {
    "text": "and interact extensively using cli gui",
    "start": "392479",
    "end": "396080"
  },
  {
    "text": "and launch their container jobs in this",
    "start": "396080",
    "end": "398720"
  },
  {
    "text": "particular infrastructure",
    "start": "398720",
    "end": "400639"
  },
  {
    "text": "the k8s actually controls the worker",
    "start": "400639",
    "end": "403199"
  },
  {
    "text": "node",
    "start": "403199",
    "end": "403840"
  },
  {
    "text": "and there is an api server obviously",
    "start": "403840",
    "end": "406080"
  },
  {
    "text": "associated with this",
    "start": "406080",
    "end": "409840"
  },
  {
    "start": "410000",
    "end": "471000"
  },
  {
    "text": "this particular picture talks about five",
    "start": "411199",
    "end": "412880"
  },
  {
    "text": "different networks um",
    "start": "412880",
    "end": "415039"
  },
  {
    "text": "which are the component of the traffic",
    "start": "415039",
    "end": "416720"
  },
  {
    "text": "inside the cluster",
    "start": "416720",
    "end": "418160"
  },
  {
    "text": "there's ipmi to control the dmc and the",
    "start": "418160",
    "end": "420800"
  },
  {
    "text": "host and the skate has control traffic",
    "start": "420800",
    "end": "422880"
  },
  {
    "text": "going knocks out",
    "start": "422880",
    "end": "425120"
  },
  {
    "text": "and the api servers can be located",
    "start": "425120",
    "end": "427199"
  },
  {
    "text": "anywhere",
    "start": "427199",
    "end": "428319"
  },
  {
    "text": "this particular green thing gpu gpu",
    "start": "428319",
    "end": "430479"
  },
  {
    "text": "network is a short span in cluster",
    "start": "430479",
    "end": "432960"
  },
  {
    "text": "bandwidth heavy which is where all the",
    "start": "432960",
    "end": "436160"
  },
  {
    "text": "ndr edr hdr traffic actually flows",
    "start": "436160",
    "end": "440319"
  },
  {
    "text": "and they're very sensitive to rtt",
    "start": "440319",
    "end": "442639"
  },
  {
    "text": "between the nodes",
    "start": "442639",
    "end": "444639"
  },
  {
    "text": "and you want them to be non-blocking and",
    "start": "444639",
    "end": "446720"
  },
  {
    "text": "ensure that there's performance in this",
    "start": "446720",
    "end": "448160"
  },
  {
    "text": "particular network",
    "start": "448160",
    "end": "451039"
  },
  {
    "text": "and that needs to interact with storage",
    "start": "451039",
    "end": "452560"
  },
  {
    "text": "network it can be in the leaf of the",
    "start": "452560",
    "end": "454080"
  },
  {
    "text": "spine",
    "start": "454080",
    "end": "455199"
  },
  {
    "text": "to fetch the data and also write the",
    "start": "455199",
    "end": "457680"
  },
  {
    "text": "results",
    "start": "457680",
    "end": "458479"
  },
  {
    "text": "and the logs and obviously the data",
    "start": "458479",
    "end": "461680"
  },
  {
    "text": "center needs access to the internet",
    "start": "461680",
    "end": "465360"
  },
  {
    "text": "for pulling images or data sets",
    "start": "465360",
    "end": "468720"
  },
  {
    "text": "or for other purposes",
    "start": "468720",
    "end": "471840"
  },
  {
    "start": "471000",
    "end": "523000"
  },
  {
    "text": "this elliptical orbit has 10 blocks",
    "start": "473039",
    "end": "476720"
  },
  {
    "text": "which are listed here each block",
    "start": "476720",
    "end": "478400"
  },
  {
    "text": "represent a rack and each rack has like",
    "start": "478400",
    "end": "480479"
  },
  {
    "text": "10 dj axes",
    "start": "480479",
    "end": "482319"
  },
  {
    "text": "they all go into the inside ring there",
    "start": "482319",
    "end": "484080"
  },
  {
    "text": "are four rings or the donuts listed here",
    "start": "484080",
    "end": "486080"
  },
  {
    "text": "with different color",
    "start": "486080",
    "end": "488240"
  },
  {
    "text": "these are called nickel rings and four",
    "start": "488240",
    "end": "490319"
  },
  {
    "text": "of them actually connect to",
    "start": "490319",
    "end": "492400"
  },
  {
    "text": "the next in the dgx ones",
    "start": "492400",
    "end": "496160"
  },
  {
    "text": "each of the ring connects to one of the",
    "start": "496160",
    "end": "498000"
  },
  {
    "text": "nicks in each of the dj axes",
    "start": "498000",
    "end": "499599"
  },
  {
    "text": "and they form a ring and so each node is",
    "start": "499599",
    "end": "501840"
  },
  {
    "text": "only one half away there is uplink",
    "start": "501840",
    "end": "506720"
  },
  {
    "text": "associated with this which is about 6.4",
    "start": "506720",
    "end": "508879"
  },
  {
    "text": "terabytes if you need to go not south",
    "start": "508879",
    "end": "511440"
  },
  {
    "text": "to go to the storage or other needs but",
    "start": "511440",
    "end": "514719"
  },
  {
    "text": "when the gpus are communicating with",
    "start": "514719",
    "end": "516320"
  },
  {
    "text": "each other they are only one half of it",
    "start": "516320",
    "end": "518719"
  },
  {
    "text": "with low latent uh round trip time",
    "start": "518719",
    "end": "523440"
  },
  {
    "start": "523000",
    "end": "555000"
  },
  {
    "text": "many of you are aware of this core spine",
    "start": "524720",
    "end": "526560"
  },
  {
    "text": "leaf model um",
    "start": "526560",
    "end": "528399"
  },
  {
    "text": "this is basically the car switching for",
    "start": "528399",
    "end": "530959"
  },
  {
    "text": "not south",
    "start": "530959",
    "end": "532160"
  },
  {
    "text": "and 100 nodes are stuck here in the in",
    "start": "532160",
    "end": "534640"
  },
  {
    "text": "the racks",
    "start": "534640",
    "end": "535920"
  },
  {
    "text": "with six nicks four of them used by the",
    "start": "535920",
    "end": "538080"
  },
  {
    "text": "east west and two of them for the north",
    "start": "538080",
    "end": "539680"
  },
  {
    "text": "south",
    "start": "539680",
    "end": "541440"
  },
  {
    "text": "and as i indicated earlier gp to gpu",
    "start": "541440",
    "end": "543839"
  },
  {
    "text": "traffic is",
    "start": "543839",
    "end": "544800"
  },
  {
    "text": "significant and you want this to be high",
    "start": "544800",
    "end": "547279"
  },
  {
    "text": "performance low",
    "start": "547279",
    "end": "548800"
  },
  {
    "text": "latent",
    "start": "548800",
    "end": "551279"
  },
  {
    "text": "network",
    "start": "552399",
    "end": "554880"
  },
  {
    "start": "555000",
    "end": "588000"
  },
  {
    "text": "this is the back side of one of the",
    "start": "556160",
    "end": "557440"
  },
  {
    "text": "units um which is called a100",
    "start": "557440",
    "end": "560480"
  },
  {
    "text": "i'm just giving you a sample of how",
    "start": "560480",
    "end": "563040"
  },
  {
    "text": "these quests would connect",
    "start": "563040",
    "end": "564880"
  },
  {
    "text": "there are four here um on each side of",
    "start": "564880",
    "end": "567120"
  },
  {
    "text": "this box",
    "start": "567120",
    "end": "568720"
  },
  {
    "text": "um in the dgx one um there's going to be",
    "start": "568720",
    "end": "571200"
  },
  {
    "text": "four",
    "start": "571200",
    "end": "572000"
  },
  {
    "text": "links and the a100 will be 800",
    "start": "572000",
    "end": "575279"
  },
  {
    "text": "links the storage network will move not",
    "start": "575279",
    "end": "579040"
  },
  {
    "text": "south",
    "start": "579040",
    "end": "580240"
  },
  {
    "text": "through these particular links and then",
    "start": "580240",
    "end": "581760"
  },
  {
    "text": "the traditional ipm network is listed",
    "start": "581760",
    "end": "583760"
  },
  {
    "text": "here",
    "start": "583760",
    "end": "586080"
  },
  {
    "start": "588000",
    "end": "618000"
  },
  {
    "text": "this is a layer 7 stack which most of",
    "start": "589680",
    "end": "592560"
  },
  {
    "text": "you are familiar with",
    "start": "592560",
    "end": "593600"
  },
  {
    "text": "um and this talks about the infiniband",
    "start": "593600",
    "end": "595920"
  },
  {
    "text": "and the rocky",
    "start": "595920",
    "end": "597120"
  },
  {
    "text": "and as you can see only the lower layers",
    "start": "597120",
    "end": "599360"
  },
  {
    "text": "are a little bit different",
    "start": "599360",
    "end": "600800"
  },
  {
    "text": "from the from the l4 onwards",
    "start": "600800",
    "end": "604160"
  },
  {
    "text": "it's identical and",
    "start": "604160",
    "end": "607680"
  },
  {
    "text": "one can use either rocky ethernet and",
    "start": "607680",
    "end": "610720"
  },
  {
    "text": "infiniband and you can reconfigure the",
    "start": "610720",
    "end": "612399"
  },
  {
    "text": "mix",
    "start": "612399",
    "end": "613680"
  },
  {
    "text": "obviously the switches has to be",
    "start": "613680",
    "end": "615120"
  },
  {
    "text": "different between the two networks",
    "start": "615120",
    "end": "619360"
  },
  {
    "start": "618000",
    "end": "636000"
  },
  {
    "text": "this is a little more expanded version",
    "start": "619360",
    "end": "621360"
  },
  {
    "text": "of the the same picture",
    "start": "621360",
    "end": "623360"
  },
  {
    "text": "but with uh with a stack here um",
    "start": "623360",
    "end": "626800"
  },
  {
    "text": "going through the udp and the version 2",
    "start": "626800",
    "end": "629279"
  },
  {
    "text": "and then infiniband network layer and",
    "start": "629279",
    "end": "631040"
  },
  {
    "text": "the version one",
    "start": "631040",
    "end": "633839"
  },
  {
    "text": "we discussed this particular slide",
    "start": "638000",
    "end": "639680"
  },
  {
    "text": "earlier about edr",
    "start": "639680",
    "end": "641040"
  },
  {
    "text": "hdr mdr 100 gauge 200 and 400 gig",
    "start": "641040",
    "end": "645279"
  },
  {
    "text": "and how do they relate to the pci bus um",
    "start": "645279",
    "end": "648160"
  },
  {
    "text": "do they saturate the pci bus",
    "start": "648160",
    "end": "650240"
  },
  {
    "text": "as you can see as they move up the the",
    "start": "650240",
    "end": "653360"
  },
  {
    "text": "bandwidth",
    "start": "653360",
    "end": "654000"
  },
  {
    "text": "and the line rate increases they're",
    "start": "654000",
    "end": "656079"
  },
  {
    "text": "going to saturate this pci bus",
    "start": "656079",
    "end": "657760"
  },
  {
    "text": "theo and you have to move up to the",
    "start": "657760",
    "end": "660320"
  },
  {
    "text": "forum network",
    "start": "660320",
    "end": "663040"
  },
  {
    "text": "so this is a good slide actually relate",
    "start": "663040",
    "end": "665519"
  },
  {
    "text": "what the nodes can do",
    "start": "665519",
    "end": "667279"
  },
  {
    "text": "in terms of pci standards associated",
    "start": "667279",
    "end": "670399"
  },
  {
    "text": "with unique bandwidth",
    "start": "670399",
    "end": "672079"
  },
  {
    "text": "and what the expectation for the gpus",
    "start": "672079",
    "end": "674079"
  },
  {
    "text": "are",
    "start": "674079",
    "end": "675920"
  },
  {
    "text": "when you operate the cluster",
    "start": "675920",
    "end": "679200"
  },
  {
    "text": "this is another view of their network",
    "start": "682399",
    "end": "685040"
  },
  {
    "text": "from seeing inside the box",
    "start": "685040",
    "end": "687600"
  },
  {
    "text": "there's a motherboard and lots of memory",
    "start": "687600",
    "end": "689920"
  },
  {
    "text": "and then the cubelet and the container",
    "start": "689920",
    "end": "691680"
  },
  {
    "text": "runs here",
    "start": "691680",
    "end": "693279"
  },
  {
    "text": "um there is a lots of traffic going",
    "start": "693279",
    "end": "696240"
  },
  {
    "text": "through this particular",
    "start": "696240",
    "end": "697600"
  },
  {
    "text": "nic and the kubernetes actually operates",
    "start": "697600",
    "end": "700240"
  },
  {
    "text": "that along with the metrics being",
    "start": "700240",
    "end": "701680"
  },
  {
    "text": "collected here",
    "start": "701680",
    "end": "703600"
  },
  {
    "text": "this particular complex is actually the",
    "start": "703600",
    "end": "705200"
  },
  {
    "text": "east west complex",
    "start": "705200",
    "end": "706720"
  },
  {
    "text": "where the switching happens you can use",
    "start": "706720",
    "end": "708560"
  },
  {
    "text": "ib or rocky",
    "start": "708560",
    "end": "710560"
  },
  {
    "text": "associated with the gpu for each nodes",
    "start": "710560",
    "end": "713920"
  },
  {
    "text": "we had to extrapolate this for 100 nodes",
    "start": "713920",
    "end": "717600"
  },
  {
    "text": "in the cluster",
    "start": "717600",
    "end": "720319"
  },
  {
    "start": "724000",
    "end": "820000"
  },
  {
    "text": "so what are the design considerations",
    "start": "725120",
    "end": "727279"
  },
  {
    "text": "for multi-node cluster",
    "start": "727279",
    "end": "730560"
  },
  {
    "text": "so align with ethernet switching model",
    "start": "730560",
    "end": "733040"
  },
  {
    "text": "interoperability and ubiquitous ethernet",
    "start": "733040",
    "end": "735040"
  },
  {
    "text": "network",
    "start": "735040",
    "end": "736480"
  },
  {
    "text": "is is a vehicle where you can install",
    "start": "736480",
    "end": "739120"
  },
  {
    "text": "this",
    "start": "739120",
    "end": "740240"
  },
  {
    "text": "avoid placement logic fundamentally ecmp",
    "start": "740240",
    "end": "743760"
  },
  {
    "text": "and others two layer routing will have",
    "start": "743760",
    "end": "747519"
  },
  {
    "text": "some",
    "start": "747519",
    "end": "748160"
  },
  {
    "text": "hiccups so we prefer to do one hop",
    "start": "748160",
    "end": "751360"
  },
  {
    "text": "l2 network and so we don't have",
    "start": "751360",
    "end": "754000"
  },
  {
    "text": "complexity",
    "start": "754000",
    "end": "755360"
  },
  {
    "text": "while you're operating the cluster",
    "start": "755360",
    "end": "758720"
  },
  {
    "text": "this particular one is 100 cluster but",
    "start": "758720",
    "end": "761360"
  },
  {
    "text": "you can even",
    "start": "761360",
    "end": "762079"
  },
  {
    "text": "have longer cables you can actually",
    "start": "762079",
    "end": "764959"
  },
  {
    "text": "expand that",
    "start": "764959",
    "end": "766560"
  },
  {
    "text": "to to more racks and as i've indicated",
    "start": "766560",
    "end": "770160"
  },
  {
    "text": "there",
    "start": "770160",
    "end": "771120"
  },
  {
    "text": "in one of the pictures it's a 16 rack",
    "start": "771120",
    "end": "774560"
  },
  {
    "text": "structure but you can expand it at 25 50",
    "start": "774560",
    "end": "777440"
  },
  {
    "text": "as long as there is switching structure",
    "start": "777440",
    "end": "780800"
  },
  {
    "text": "align and leverage nccl which is a",
    "start": "780800",
    "end": "782959"
  },
  {
    "text": "nickel rail structure",
    "start": "782959",
    "end": "785440"
  },
  {
    "text": "the libraries to avoid switching",
    "start": "785440",
    "end": "786880"
  },
  {
    "text": "congestion and output ports",
    "start": "786880",
    "end": "788959"
  },
  {
    "text": "nickel does do a tray uh rings and it",
    "start": "788959",
    "end": "791279"
  },
  {
    "text": "arbitrates",
    "start": "791279",
    "end": "792320"
  },
  {
    "text": "and ensure that the traffic flows",
    "start": "792320",
    "end": "794560"
  },
  {
    "text": "smoothly",
    "start": "794560",
    "end": "796800"
  },
  {
    "text": "while they're actually bringing up the",
    "start": "796800",
    "end": "798839"
  },
  {
    "text": "cluster",
    "start": "798839",
    "end": "800639"
  },
  {
    "text": "avoid generic storage traffic mixing for",
    "start": "800639",
    "end": "803600"
  },
  {
    "text": "the rdma",
    "start": "803600",
    "end": "804480"
  },
  {
    "text": "nickel ring so that we have a clean",
    "start": "804480",
    "end": "807279"
  },
  {
    "text": "network for the east west",
    "start": "807279",
    "end": "810399"
  },
  {
    "text": "and that actually integrates with sr",
    "start": "810399",
    "end": "812240"
  },
  {
    "text": "sriv cni",
    "start": "812240",
    "end": "814240"
  },
  {
    "text": "and the rdma interfaces are actually",
    "start": "814240",
    "end": "816079"
  },
  {
    "text": "exposed inside the container",
    "start": "816079",
    "end": "819279"
  },
  {
    "start": "820000",
    "end": "849000"
  },
  {
    "text": "so this is a traditional switching",
    "start": "821519",
    "end": "823040"
  },
  {
    "text": "structure which most of you are familiar",
    "start": "823040",
    "end": "824800"
  },
  {
    "text": "with",
    "start": "824800",
    "end": "826000"
  },
  {
    "text": "so edge spine leaf and torque the",
    "start": "826000",
    "end": "828800"
  },
  {
    "text": "storage",
    "start": "828800",
    "end": "829360"
  },
  {
    "text": "can decide um beside very close to the",
    "start": "829360",
    "end": "832800"
  },
  {
    "text": "leaf",
    "start": "832800",
    "end": "833199"
  },
  {
    "text": "if you want to have a local traffic or",
    "start": "833199",
    "end": "836160"
  },
  {
    "text": "move it up a little bit into the spine",
    "start": "836160",
    "end": "839199"
  },
  {
    "text": "and the ip method actually connects it",
    "start": "839199",
    "end": "841600"
  },
  {
    "text": "to the bmc",
    "start": "841600",
    "end": "843519"
  },
  {
    "text": "on the switches to managed",
    "start": "843519",
    "end": "847199"
  },
  {
    "start": "849000",
    "end": "864000"
  },
  {
    "text": "so i'm going to pass here and hand this",
    "start": "850959",
    "end": "853040"
  },
  {
    "text": "off to navedita",
    "start": "853040",
    "end": "854240"
  },
  {
    "text": "to talk about the control plane",
    "start": "854240",
    "end": "857279"
  },
  {
    "text": "and the vedic i'll conclude",
    "start": "857279",
    "end": "860639"
  },
  {
    "text": "the performance thank you",
    "start": "860639",
    "end": "865199"
  },
  {
    "text": "thank you watson hello everyone i'm",
    "start": "865680",
    "end": "868240"
  },
  {
    "text": "nivedita and i'm glad to be",
    "start": "868240",
    "end": "869839"
  },
  {
    "text": "co-presenting",
    "start": "869839",
    "end": "870959"
  },
  {
    "text": "this session now watson talked about the",
    "start": "870959",
    "end": "874720"
  },
  {
    "text": "best practices and network protocols to",
    "start": "874720",
    "end": "877279"
  },
  {
    "text": "be considered while designing",
    "start": "877279",
    "end": "879040"
  },
  {
    "text": "a high performance multi-node cluster in",
    "start": "879040",
    "end": "881360"
  },
  {
    "text": "a data center",
    "start": "881360",
    "end": "882959"
  },
  {
    "text": "i would like to talk about how we",
    "start": "882959",
    "end": "884720"
  },
  {
    "text": "leveraged those design decisions",
    "start": "884720",
    "end": "886959"
  },
  {
    "text": "to enable high-speed networking in",
    "start": "886959",
    "end": "889440"
  },
  {
    "text": "kubernetes",
    "start": "889440",
    "end": "891440"
  },
  {
    "text": "now we have an on-prem production",
    "start": "891440",
    "end": "893600"
  },
  {
    "text": "kubernetes cluster",
    "start": "893600",
    "end": "895199"
  },
  {
    "text": "that is mainly used by our internal",
    "start": "895199",
    "end": "897279"
  },
  {
    "text": "users",
    "start": "897279",
    "end": "898560"
  },
  {
    "text": "and most of these internal users are",
    "start": "898560",
    "end": "900959"
  },
  {
    "text": "research scientists that are running",
    "start": "900959",
    "end": "902959"
  },
  {
    "text": "deep learning applications that often",
    "start": "902959",
    "end": "905680"
  },
  {
    "text": "require",
    "start": "905680",
    "end": "906320"
  },
  {
    "text": "hundreds of gpus we have enabled support",
    "start": "906320",
    "end": "910399"
  },
  {
    "text": "for running",
    "start": "910399",
    "end": "911120"
  },
  {
    "text": "multi-node workloads through a custom",
    "start": "911120",
    "end": "913839"
  },
  {
    "text": "job controller",
    "start": "913839",
    "end": "915440"
  },
  {
    "text": "the upstream mpi operator and a custom",
    "start": "915440",
    "end": "918560"
  },
  {
    "text": "batch scheduler",
    "start": "918560",
    "end": "920560"
  },
  {
    "text": "the custom job controller registers a",
    "start": "920560",
    "end": "923040"
  },
  {
    "text": "custom resource definition or a crd for",
    "start": "923040",
    "end": "925760"
  },
  {
    "text": "a multi-node job",
    "start": "925760",
    "end": "927199"
  },
  {
    "text": "with the api server users can submit",
    "start": "927199",
    "end": "930959"
  },
  {
    "text": "multi-node jobs through the cid either",
    "start": "930959",
    "end": "933600"
  },
  {
    "text": "through the cli or",
    "start": "933600",
    "end": "934880"
  },
  {
    "text": "ui and when a multi-node job",
    "start": "934880",
    "end": "938320"
  },
  {
    "text": "is submitted the custom job controller",
    "start": "938320",
    "end": "941120"
  },
  {
    "text": "watches",
    "start": "941120",
    "end": "941759"
  },
  {
    "text": "for these events and creates an mpi job",
    "start": "941759",
    "end": "945360"
  },
  {
    "text": "for the multi-node job the mpi operator",
    "start": "945360",
    "end": "949120"
  },
  {
    "text": "then creates the ports",
    "start": "949120",
    "end": "950800"
  },
  {
    "text": "for the mpi job and these spots form",
    "start": "950800",
    "end": "954079"
  },
  {
    "text": "a gang which is then scheduled by the",
    "start": "954079",
    "end": "956480"
  },
  {
    "text": "custom batch scheduler",
    "start": "956480",
    "end": "959279"
  },
  {
    "text": "now the container image has the",
    "start": "959279",
    "end": "961600"
  },
  {
    "text": "necessary libraries",
    "start": "961600",
    "end": "963120"
  },
  {
    "text": "for the framework mpi and nickel",
    "start": "963120",
    "end": "966880"
  },
  {
    "text": "and when all the pods are running as a",
    "start": "966880",
    "end": "969120"
  },
  {
    "text": "gank they communicate",
    "start": "969120",
    "end": "970959"
  },
  {
    "text": "through nickel now the production",
    "start": "970959",
    "end": "974079"
  },
  {
    "start": "972000",
    "end": "1010000"
  },
  {
    "text": "cluster we have is a shared cluster",
    "start": "974079",
    "end": "977120"
  },
  {
    "text": "as watson mentioned it's made up of 100",
    "start": "977120",
    "end": "980000"
  },
  {
    "text": "dgx1 nodes",
    "start": "980000",
    "end": "982320"
  },
  {
    "text": "and since this is a shared cluster we",
    "start": "982320",
    "end": "984480"
  },
  {
    "text": "have implemented features like",
    "start": "984480",
    "end": "986880"
  },
  {
    "text": "gang scheduling starvation handling",
    "start": "986880",
    "end": "989519"
  },
  {
    "text": "backfilling",
    "start": "989519",
    "end": "990639"
  },
  {
    "text": "as well as support for user quotas drf",
    "start": "990639",
    "end": "994399"
  },
  {
    "text": "and dynamic job priority through our",
    "start": "994399",
    "end": "996800"
  },
  {
    "text": "custom scheduler",
    "start": "996800",
    "end": "998880"
  },
  {
    "text": "we have a logging and monitoring",
    "start": "998880",
    "end": "1001360"
  },
  {
    "text": "pipeline that feeds into dashboards and",
    "start": "1001360",
    "end": "1004240"
  },
  {
    "text": "alerts and helps with day-to-day",
    "start": "1004240",
    "end": "1008560"
  },
  {
    "text": "operations",
    "start": "1008839",
    "end": "1010480"
  },
  {
    "text": "now in order to run distributed deep",
    "start": "1010480",
    "end": "1013519"
  },
  {
    "text": "learning",
    "start": "1013519",
    "end": "1014079"
  },
  {
    "text": "applications high speed networking is",
    "start": "1014079",
    "end": "1017199"
  },
  {
    "text": "extremely crucial but before we go into",
    "start": "1017199",
    "end": "1020639"
  },
  {
    "text": "how we enable high speed networking",
    "start": "1020639",
    "end": "1023279"
  },
  {
    "text": "let's take a high-level look at the",
    "start": "1023279",
    "end": "1025199"
  },
  {
    "text": "topology of a dgx1",
    "start": "1025199",
    "end": "1027438"
  },
  {
    "text": "node each djx1 has",
    "start": "1027439",
    "end": "1030798"
  },
  {
    "text": "8 v100 gpus that are interconnected by",
    "start": "1030799",
    "end": "1034480"
  },
  {
    "text": "nvlink in our cluster",
    "start": "1034480",
    "end": "1037120"
  },
  {
    "text": "it has four melanox 100 gig",
    "start": "1037120",
    "end": "1040160"
  },
  {
    "text": "nics for rdma and dual copper 10 gig",
    "start": "1040160",
    "end": "1043760"
  },
  {
    "text": "ethernet linux the four",
    "start": "1043760",
    "end": "1047360"
  },
  {
    "text": "rdma interfaces form a rocky network",
    "start": "1047360",
    "end": "1051039"
  },
  {
    "text": "or a ring that is used by nikkor for gpu",
    "start": "1051039",
    "end": "1054160"
  },
  {
    "text": "to gpu communication",
    "start": "1054160",
    "end": "1055840"
  },
  {
    "text": "using the one hop vlan switching fabric",
    "start": "1055840",
    "end": "1059600"
  },
  {
    "text": "nickel can detect the fast interconnects",
    "start": "1059600",
    "end": "1062480"
  },
  {
    "text": "between gpus both",
    "start": "1062480",
    "end": "1064160"
  },
  {
    "text": "within and across nodes and the nickel",
    "start": "1064160",
    "end": "1067679"
  },
  {
    "text": "ring formation also helps with",
    "start": "1067679",
    "end": "1069679"
  },
  {
    "text": "output port congestion at the cluster",
    "start": "1069679",
    "end": "1073120"
  },
  {
    "text": "now this process is described in detail",
    "start": "1073120",
    "end": "1075440"
  },
  {
    "text": "in the link that is shared",
    "start": "1075440",
    "end": "1077280"
  },
  {
    "text": "on the slide the dual",
    "start": "1077280",
    "end": "1080720"
  },
  {
    "text": "ethernet nics on the dgx1 node",
    "start": "1080720",
    "end": "1084080"
  },
  {
    "text": "are primarily used for storage and",
    "start": "1084080",
    "end": "1086400"
  },
  {
    "text": "kubernetes control traffic",
    "start": "1086400",
    "end": "1089039"
  },
  {
    "text": "so this gives us two distinct networks",
    "start": "1089039",
    "end": "1091840"
  },
  {
    "text": "one for rocky and one for storage or",
    "start": "1091840",
    "end": "1094080"
  },
  {
    "text": "control",
    "start": "1094080",
    "end": "1095120"
  },
  {
    "text": "resulting in an isolated environment for",
    "start": "1095120",
    "end": "1097760"
  },
  {
    "text": "performance-centric workloads",
    "start": "1097760",
    "end": "1101360"
  },
  {
    "text": "to enable high-speed networking for",
    "start": "1103120",
    "end": "1105440"
  },
  {
    "text": "multi-node jobs",
    "start": "1105440",
    "end": "1107039"
  },
  {
    "text": "we need to make the multiple interfaces",
    "start": "1107039",
    "end": "1109600"
  },
  {
    "text": "on the host",
    "start": "1109600",
    "end": "1110480"
  },
  {
    "text": "available inside the kubernetes board",
    "start": "1110480",
    "end": "1113600"
  },
  {
    "text": "this is achieved through a combination",
    "start": "1113600",
    "end": "1115600"
  },
  {
    "text": "of the sr iov device plugin",
    "start": "1115600",
    "end": "1118080"
  },
  {
    "text": "and multicni the sriov device plugin",
    "start": "1118080",
    "end": "1122080"
  },
  {
    "text": "discovers the rdma interfaces on the",
    "start": "1122080",
    "end": "1124799"
  },
  {
    "text": "host and registers them with cubelet",
    "start": "1124799",
    "end": "1128000"
  },
  {
    "text": "the rdma interfaces can then be managed",
    "start": "1128000",
    "end": "1130960"
  },
  {
    "text": "by cubelet as",
    "start": "1130960",
    "end": "1132160"
  },
  {
    "text": "allocatable resources so once a",
    "start": "1132160",
    "end": "1135679"
  },
  {
    "text": "pod that is requesting these rdma",
    "start": "1135679",
    "end": "1138320"
  },
  {
    "text": "interfaces in its resource spec",
    "start": "1138320",
    "end": "1140160"
  },
  {
    "text": "gets scheduled onto a node cubelet",
    "start": "1140160",
    "end": "1142799"
  },
  {
    "text": "starts",
    "start": "1142799",
    "end": "1143280"
  },
  {
    "text": "moving the network resources from the",
    "start": "1143280",
    "end": "1146320"
  },
  {
    "text": "host namespace to the port namespace to",
    "start": "1146320",
    "end": "1148799"
  },
  {
    "text": "the",
    "start": "1148799",
    "end": "1149280"
  },
  {
    "text": "registered cni plugin now since the dgx1",
    "start": "1149280",
    "end": "1154240"
  },
  {
    "text": "node has multiple types of network",
    "start": "1154240",
    "end": "1156720"
  },
  {
    "text": "interfaces",
    "start": "1156720",
    "end": "1157840"
  },
  {
    "text": "we use multis as the cni plugin which",
    "start": "1157840",
    "end": "1160880"
  },
  {
    "text": "delegates its call",
    "start": "1160880",
    "end": "1162880"
  },
  {
    "text": "to the sr iov cni plugin and the flannel",
    "start": "1162880",
    "end": "1165760"
  },
  {
    "text": "plugin",
    "start": "1165760",
    "end": "1167640"
  },
  {
    "text": "sriovcni configures the rdma interfaces",
    "start": "1167640",
    "end": "1170799"
  },
  {
    "text": "in a port",
    "start": "1170799",
    "end": "1171679"
  },
  {
    "text": "while flannel configures the default h0",
    "start": "1171679",
    "end": "1174559"
  },
  {
    "text": "interface",
    "start": "1174559",
    "end": "1176080"
  },
  {
    "text": "all the components in this flow are",
    "start": "1176080",
    "end": "1178559"
  },
  {
    "text": "upstream components that have been used",
    "start": "1178559",
    "end": "1180559"
  },
  {
    "text": "with minor customizations",
    "start": "1180559",
    "end": "1184159"
  },
  {
    "start": "1184000",
    "end": "1243000"
  },
  {
    "text": "now for each physical rdma interface on",
    "start": "1185440",
    "end": "1188400"
  },
  {
    "text": "the host",
    "start": "1188400",
    "end": "1189440"
  },
  {
    "text": "we create two sriv interfaces or virtual",
    "start": "1189440",
    "end": "1192799"
  },
  {
    "text": "functions",
    "start": "1192799",
    "end": "1194160"
  },
  {
    "text": "so a dgx1 node that has four rdma",
    "start": "1194160",
    "end": "1197520"
  },
  {
    "text": "interfaces",
    "start": "1197520",
    "end": "1198640"
  },
  {
    "text": "will result in eight virtual functions",
    "start": "1198640",
    "end": "1202159"
  },
  {
    "text": "each full node port will only use four",
    "start": "1202159",
    "end": "1205039"
  },
  {
    "text": "of these eight vfs",
    "start": "1205039",
    "end": "1206400"
  },
  {
    "text": "one corresponding to each physical",
    "start": "1206400",
    "end": "1208640"
  },
  {
    "text": "interface",
    "start": "1208640",
    "end": "1209679"
  },
  {
    "text": "and the remaining four vfs are used for",
    "start": "1209679",
    "end": "1213039"
  },
  {
    "text": "monitoring and storage network creation",
    "start": "1213039",
    "end": "1217360"
  },
  {
    "text": "also the affinity of any vf to a",
    "start": "1217360",
    "end": "1220000"
  },
  {
    "text": "particular gpu",
    "start": "1220000",
    "end": "1221280"
  },
  {
    "text": "is decided at runtime by nickel",
    "start": "1221280",
    "end": "1224559"
  },
  {
    "text": "the first image on the slide highlights",
    "start": "1224559",
    "end": "1227120"
  },
  {
    "text": "the four",
    "start": "1227120",
    "end": "1227919"
  },
  {
    "text": "physical rdma interfaces of the host",
    "start": "1227919",
    "end": "1231360"
  },
  {
    "text": "and the second image highlights the four",
    "start": "1231360",
    "end": "1234080"
  },
  {
    "text": "sriov interfaces",
    "start": "1234080",
    "end": "1235919"
  },
  {
    "text": "that are created from the physical",
    "start": "1235919",
    "end": "1237440"
  },
  {
    "text": "interfaces and renamed in a pod",
    "start": "1237440",
    "end": "1241679"
  },
  {
    "text": "since this is a production cluster we",
    "start": "1243679",
    "end": "1246640"
  },
  {
    "text": "are constantly",
    "start": "1246640",
    "end": "1247679"
  },
  {
    "text": "monitoring the traffic on the rdib",
    "start": "1247679",
    "end": "1249840"
  },
  {
    "text": "interfaces",
    "start": "1249840",
    "end": "1251520"
  },
  {
    "text": "this is done by capturing the values of",
    "start": "1251520",
    "end": "1254159"
  },
  {
    "text": "the transmit and receive counters",
    "start": "1254159",
    "end": "1257200"
  },
  {
    "text": "and the image shown here shows the",
    "start": "1257200",
    "end": "1260159"
  },
  {
    "text": "traffic that you typically see",
    "start": "1260159",
    "end": "1261840"
  },
  {
    "text": "while running a machine learning",
    "start": "1261840",
    "end": "1263520"
  },
  {
    "text": "application",
    "start": "1263520",
    "end": "1265200"
  },
  {
    "text": "now we often see a sawtooth-like pattern",
    "start": "1265200",
    "end": "1268799"
  },
  {
    "text": "and this is a result of the two phases",
    "start": "1268799",
    "end": "1270960"
  },
  {
    "text": "that generally occur in",
    "start": "1270960",
    "end": "1272559"
  },
  {
    "text": "every epoch of an ml app the two phases",
    "start": "1272559",
    "end": "1275840"
  },
  {
    "text": "being the",
    "start": "1275840",
    "end": "1276559"
  },
  {
    "text": "compute phase and the communicate phase",
    "start": "1276559",
    "end": "1279919"
  },
  {
    "text": "in the compute phase the gpu workers are",
    "start": "1279919",
    "end": "1283280"
  },
  {
    "text": "fetching from storage performing",
    "start": "1283280",
    "end": "1285280"
  },
  {
    "text": "computation creating mpi barriers",
    "start": "1285280",
    "end": "1288080"
  },
  {
    "text": "and there is no communication with other",
    "start": "1288080",
    "end": "1290880"
  },
  {
    "text": "gpu workers",
    "start": "1290880",
    "end": "1292240"
  },
  {
    "text": "hence the dip or the valley in the",
    "start": "1292240",
    "end": "1294880"
  },
  {
    "text": "traffic",
    "start": "1294880",
    "end": "1296559"
  },
  {
    "text": "in the communicate phase the gpu workers",
    "start": "1296559",
    "end": "1299520"
  },
  {
    "text": "share the result of the previous phase",
    "start": "1299520",
    "end": "1301440"
  },
  {
    "text": "with other workers",
    "start": "1301440",
    "end": "1302799"
  },
  {
    "text": "and this results in the peak in the",
    "start": "1302799",
    "end": "1304720"
  },
  {
    "text": "pattern that you see",
    "start": "1304720",
    "end": "1306799"
  },
  {
    "text": "now we ideally want to maximize the",
    "start": "1306799",
    "end": "1309360"
  },
  {
    "text": "compute time",
    "start": "1309360",
    "end": "1310320"
  },
  {
    "text": "and minimize the communicate time in an",
    "start": "1310320",
    "end": "1312400"
  },
  {
    "text": "algorithm",
    "start": "1312400",
    "end": "1313440"
  },
  {
    "text": "to improve epoch training efficiency",
    "start": "1313440",
    "end": "1319600"
  },
  {
    "start": "1319000",
    "end": "1369000"
  },
  {
    "text": "in addition to monitoring the rdma",
    "start": "1319600",
    "end": "1322400"
  },
  {
    "text": "traffic",
    "start": "1322400",
    "end": "1323039"
  },
  {
    "text": "we also run nickel all reduce routine",
    "start": "1323039",
    "end": "1326640"
  },
  {
    "text": "and other collective primitives as part",
    "start": "1326640",
    "end": "1329440"
  },
  {
    "text": "of a pre-flight check",
    "start": "1329440",
    "end": "1330880"
  },
  {
    "text": "prior to running multi-node workloads",
    "start": "1330880",
    "end": "1334000"
  },
  {
    "text": "nickel all reduce test captures the",
    "start": "1334000",
    "end": "1336480"
  },
  {
    "text": "average",
    "start": "1336480",
    "end": "1337120"
  },
  {
    "text": "bus bandwidth and it's run with",
    "start": "1337120",
    "end": "1340080"
  },
  {
    "text": "different configurations where we",
    "start": "1340080",
    "end": "1342400"
  },
  {
    "text": "vary the mpi rank per node the number of",
    "start": "1342400",
    "end": "1345039"
  },
  {
    "text": "threads per rank",
    "start": "1345039",
    "end": "1346240"
  },
  {
    "text": "the number of gpus per thread and so on",
    "start": "1346240",
    "end": "1349760"
  },
  {
    "text": "from the table and graph we see that",
    "start": "1349760",
    "end": "1352240"
  },
  {
    "text": "even with",
    "start": "1352240",
    "end": "1352960"
  },
  {
    "text": "increasing number of nodes we get a",
    "start": "1352960",
    "end": "1355840"
  },
  {
    "text": "pretty consistent average",
    "start": "1355840",
    "end": "1357679"
  },
  {
    "text": "bus bandwidth of about 45 gbps",
    "start": "1357679",
    "end": "1361840"
  },
  {
    "text": "where the theoretical light rate is 50",
    "start": "1361840",
    "end": "1364720"
  },
  {
    "text": "gbps",
    "start": "1364720",
    "end": "1367440"
  },
  {
    "text": "here we also have captured the",
    "start": "1369600",
    "end": "1371679"
  },
  {
    "text": "performance of a pie torch",
    "start": "1371679",
    "end": "1373360"
  },
  {
    "text": "pert jaw that we have run in two",
    "start": "1373360",
    "end": "1375840"
  },
  {
    "text": "different phases",
    "start": "1375840",
    "end": "1377280"
  },
  {
    "text": "and we see that the throughput scaling",
    "start": "1377280",
    "end": "1379840"
  },
  {
    "text": "which is measured in sequences per",
    "start": "1379840",
    "end": "1381760"
  },
  {
    "text": "second",
    "start": "1381760",
    "end": "1382640"
  },
  {
    "text": "is close to the ideal value even when",
    "start": "1382640",
    "end": "1386080"
  },
  {
    "text": "using up to",
    "start": "1386080",
    "end": "1386880"
  },
  {
    "text": "256 concurrent gpus in a shared",
    "start": "1386880",
    "end": "1389679"
  },
  {
    "text": "multi-node cluster",
    "start": "1389679",
    "end": "1392720"
  },
  {
    "start": "1394000",
    "end": "1477000"
  },
  {
    "text": "so in conclusion we wanted to share some",
    "start": "1395120",
    "end": "1398559"
  },
  {
    "text": "of our",
    "start": "1398559",
    "end": "1399200"
  },
  {
    "text": "findings and observations for dc",
    "start": "1399200",
    "end": "1402640"
  },
  {
    "text": "placement and design following the best",
    "start": "1402640",
    "end": "1406400"
  },
  {
    "text": "practices will result in an environment",
    "start": "1406400",
    "end": "1409039"
  },
  {
    "text": "that gives good performance",
    "start": "1409039",
    "end": "1410559"
  },
  {
    "text": "for aiml workloads where bandwidth",
    "start": "1410559",
    "end": "1414559"
  },
  {
    "text": "is concerned comprehensive understanding",
    "start": "1414559",
    "end": "1417360"
  },
  {
    "text": "of the network flows",
    "start": "1417360",
    "end": "1419280"
  },
  {
    "text": "will provide guidance for designing",
    "start": "1419280",
    "end": "1421679"
  },
  {
    "text": "multi-node clusters without congestion",
    "start": "1421679",
    "end": "1423919"
  },
  {
    "text": "at edr and future",
    "start": "1423919",
    "end": "1425760"
  },
  {
    "text": "hdr ndr rates what's to be kept in mind",
    "start": "1425760",
    "end": "1429840"
  },
  {
    "text": "is hdr",
    "start": "1429840",
    "end": "1430720"
  },
  {
    "text": "ndr rates are applicable for tor",
    "start": "1430720",
    "end": "1433200"
  },
  {
    "text": "switches as well",
    "start": "1433200",
    "end": "1434480"
  },
  {
    "text": "and not for dc to dc connectivity alone",
    "start": "1434480",
    "end": "1438559"
  },
  {
    "text": "regarding the kubernetes control plane",
    "start": "1438559",
    "end": "1440799"
  },
  {
    "text": "we found",
    "start": "1440799",
    "end": "1441600"
  },
  {
    "text": "that the upstream components and plugins",
    "start": "1441600",
    "end": "1443840"
  },
  {
    "text": "in the community",
    "start": "1443840",
    "end": "1444960"
  },
  {
    "text": "are easy to adopt and customize and by",
    "start": "1444960",
    "end": "1448159"
  },
  {
    "text": "implementing features like gang",
    "start": "1448159",
    "end": "1449919"
  },
  {
    "text": "scheduling starvation handling quotas",
    "start": "1449919",
    "end": "1452400"
  },
  {
    "text": "in our custom batch scheduler we were",
    "start": "1452400",
    "end": "1454880"
  },
  {
    "text": "able to achieve",
    "start": "1454880",
    "end": "1456240"
  },
  {
    "text": "seamless scheduling of multi-node",
    "start": "1456240",
    "end": "1458480"
  },
  {
    "text": "workloads",
    "start": "1458480",
    "end": "1459520"
  },
  {
    "text": "while maintaining fairness for end users",
    "start": "1459520",
    "end": "1464159"
  },
  {
    "text": "i would like to thank the entire team at",
    "start": "1465360",
    "end": "1467600"
  },
  {
    "text": "nvidia for their help",
    "start": "1467600",
    "end": "1469200"
  },
  {
    "text": "and support and i would also like to",
    "start": "1469200",
    "end": "1471520"
  },
  {
    "text": "thank kubecon for",
    "start": "1471520",
    "end": "1472799"
  },
  {
    "text": "giving us this opportunity to show our",
    "start": "1472799",
    "end": "1475279"
  },
  {
    "text": "work",
    "start": "1475279",
    "end": "1475919"
  },
  {
    "text": "thank you",
    "start": "1475919",
    "end": "1479360"
  }
]
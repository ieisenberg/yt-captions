[
  {
    "text": "what a fantastic 3 days almost uh almost the end last afternoon so kudos to all",
    "start": "1000",
    "end": "6040"
  },
  {
    "text": "of you uh for joining this session um I know you have travel plans",
    "start": "6040",
    "end": "12400"
  },
  {
    "text": "to go back Etc so thank you for being here um and thank you so much for giving",
    "start": "12400",
    "end": "18840"
  },
  {
    "text": "us the opportunity to share our ideas with you um today I will be speaking",
    "start": "18840",
    "end": "25439"
  },
  {
    "text": "with you about achieving real time generative AI during gameplay for games",
    "start": "25439",
    "end": "31320"
  },
  {
    "text": "running on",
    "start": "31320",
    "end": "33840"
  },
  {
    "text": "kubernetes just a quick introduction I ishan Sharma I'm a senior product manager in the Google kubernetes engine",
    "start": "36520",
    "end": "43719"
  },
  {
    "text": "gke uh Team within Google Cloud um I'm part of the Google Cloud",
    "start": "43719",
    "end": "49199"
  },
  {
    "text": "for games team and what excites me most about my work is building a platform",
    "start": "49199",
    "end": "55320"
  },
  {
    "text": "that powers some of the most successful games um Global Life service games games",
    "start": "55320",
    "end": "61199"
  },
  {
    "text": "in my life before joining Google I had the opportunity to work at large and small companies in the fields of cloud",
    "start": "61199",
    "end": "68080"
  },
  {
    "text": "AI iot nanotechnology and microelectronics when I'm not working",
    "start": "68080",
    "end": "73240"
  },
  {
    "text": "with my colleagues to build awesome products you will find me hiking biking",
    "start": "73240",
    "end": "78600"
  },
  {
    "text": "exploring new cities and teaching meditation over the next 30 minutes or",
    "start": "78600",
    "end": "85960"
  },
  {
    "text": "so let's go on a journey together exploring generative Ai and games let's",
    "start": "85960",
    "end": "91400"
  },
  {
    "text": "discuss briefly about the latest trends in generative AI um how game backends",
    "start": "91400",
    "end": "96439"
  },
  {
    "text": "are deployed using kubernetes how generative AI is really starting to be used in games and how it can all be done",
    "start": "96439",
    "end": "104759"
  },
  {
    "text": "with kubernetes finally I will present a demo that demonstrates these",
    "start": "104759",
    "end": "110640"
  },
  {
    "text": "Concepts so just to uh break the ice here a little bit a question for all of",
    "start": "110640",
    "end": "116600"
  },
  {
    "text": "you show of hands of course how many here are game developers for hobby or",
    "start": "116600",
    "end": "122479"
  },
  {
    "text": "for work okay I see a see a few welcome and um how many I said Hobby and work so",
    "start": "122479",
    "end": "129879"
  },
  {
    "text": "how many of you are professional game developers you can leave your hands up just for a few minutes okay so a few a",
    "start": "129879",
    "end": "135200"
  },
  {
    "text": "few uh great how many of you are Gamers Avid Gamers uh almost every day you",
    "start": "135200",
    "end": "141519"
  },
  {
    "text": "you're playing games great uh keep your hands up how many of you play a game at",
    "start": "141519",
    "end": "147000"
  },
  {
    "text": "least once a month so cons cons PC Mobile okay once uh good and how many of",
    "start": "147000",
    "end": "154800"
  },
  {
    "text": "you have played a game at least once in your life all right almost all of you great",
    "start": "154800",
    "end": "160959"
  },
  {
    "text": "so what this tells me is that I have a fantastic audience here and half my job is done",
    "start": "160959",
    "end": "167400"
  },
  {
    "text": "good so switching to generative AI right so we all know with the launch of chat",
    "start": "167400",
    "end": "172680"
  },
  {
    "text": "GPT Bard Etc the term generative AI has become mainstream in all of our",
    "start": "172680",
    "end": "178680"
  },
  {
    "text": "conversations and that's not just the Tech Community right over the last few decades however we'll see that",
    "start": "178680",
    "end": "184000"
  },
  {
    "text": "artificial intelligence and machine learning has been steadily improving so it is noteworthy that just in the last",
    "start": "184000",
    "end": "191120"
  },
  {
    "text": "decade we have seen that AI systems have become more capable and are now beating humans in perception tests so these are",
    "start": "191120",
    "end": "198159"
  },
  {
    "text": "in domains such as handwriting speech and image recognition uh reading comprehension and of course language",
    "start": "198159",
    "end": "205040"
  },
  {
    "text": "understanding now generative AI geni as most of you would know a it is a type of",
    "start": "205040",
    "end": "211400"
  },
  {
    "text": "artificial intelligence that can produce new images text videos and audio clips",
    "start": "211400",
    "end": "217439"
  },
  {
    "text": "and that is really part of this Evolution so the generative capabilities",
    "start": "217439",
    "end": "223920"
  },
  {
    "text": "of AI have seen a really Stark improvement over the last nine years so",
    "start": "223920",
    "end": "229200"
  },
  {
    "text": "this chronology that I'm presenting here shows pictures generated by Ai and by the way none of these people actually",
    "start": "229200",
    "end": "235599"
  },
  {
    "text": "exist except of course for the last one uh we can see that the evolution from the very pixelated black and white image",
    "start": "235599",
    "end": "243239"
  },
  {
    "text": "from 2014 to a very realistic image in just 3 years by 2017 by",
    "start": "243239",
    "end": "250079"
  },
  {
    "text": "2021 we started to see text to image Generation Um these are capabilities",
    "start": "250079",
    "end": "255560"
  },
  {
    "text": "with prompts that a lot of you might have tried out already and just last week I used so stable diffusion to",
    "start": "255560",
    "end": "262040"
  },
  {
    "text": "generate a very realistic image of Albert Einstein in a space suit at the",
    "start": "262040",
    "end": "267320"
  },
  {
    "text": "time of a solar eclipse perhaps himself Gathering the experimental evidence that he needed to prove general",
    "start": "267320",
    "end": "275199"
  },
  {
    "text": "relativity that is an impressive image of course Albert Einstein wasn't in space without a helmet as we all",
    "start": "275199",
    "end": "282560"
  },
  {
    "text": "know now the future of gen is even more incredible with the latest from Google",
    "start": "282560",
    "end": "288639"
  },
  {
    "text": "research teams showing quite accurate and realistic video clips generated by text proms on the left you have a teddy",
    "start": "288639",
    "end": "295080"
  },
  {
    "text": "bear running in New York City and on the right a glass bead falling into water with a huge Splash with sunset in the",
    "start": "295080",
    "end": "301560"
  },
  {
    "text": "background really realistic images so now taking this generative AI",
    "start": "301560",
    "end": "308680"
  },
  {
    "text": "capabilities and looking at games so generative AI capabilities when",
    "start": "308680",
    "end": "313960"
  },
  {
    "text": "integrated into games with will truly transform life service games and it will give players a really",
    "start": "313960",
    "end": "321800"
  },
  {
    "text": "novel experience so with the next decade or so we can expect generative AI in games to grow upwards of 20% annually",
    "start": "321800",
    "end": "329639"
  },
  {
    "text": "and we're already seeing generative AI being used in game development today and we expect that ultimately new game",
    "start": "329639",
    "end": "336560"
  },
  {
    "text": "experiences such as smart non-player characters NPCs and level generation",
    "start": "336560",
    "end": "342639"
  },
  {
    "text": "will start to become more prevalent in the chart here those are sort of the purple deep purple and the next two bars",
    "start": "342639",
    "end": "349600"
  },
  {
    "text": "at the bottom and you can see how they're growing over time now when you think of um generative",
    "start": "349600",
    "end": "356560"
  },
  {
    "text": "Ari use cases in games we can classify those use cas cases into two categories",
    "start": "356560",
    "end": "361680"
  },
  {
    "text": "one is improving productivity during game development and the other one is improving player experiences during",
    "start": "361680",
    "end": "366880"
  },
  {
    "text": "gameplay so let's explore these so in the first category game developers use generative AI to really accelerate time",
    "start": "366880",
    "end": "374240"
  },
  {
    "text": "to launch or time to Market by creating content and simplifying development this",
    "start": "374240",
    "end": "379639"
  },
  {
    "text": "includes development of game assets such as characters props audio and video code",
    "start": "379639",
    "end": "386319"
  },
  {
    "text": "generation and AI based game testing in fact code generation and image generation are already being used by",
    "start": "386319",
    "end": "392479"
  },
  {
    "text": "game developers today from these game developers use cases you can sort of see um you can use",
    "start": "392479",
    "end": "399360"
  },
  {
    "text": "off-the-shelf TurnKey apis uh like Google's vertex AI Sage maker or chat",
    "start": "399360",
    "end": "405479"
  },
  {
    "text": "GPT or you can run your own gen inference uh on top of kubernetes in the",
    "start": "405479",
    "end": "410840"
  },
  {
    "text": "second category on the right game developers use AIML and generative AI to adapt gameplay and Empower players to",
    "start": "410840",
    "end": "418479"
  },
  {
    "text": "generate game cont content in real time so these include smart non-player",
    "start": "418479",
    "end": "423800"
  },
  {
    "text": "characters NPCs Dynamic in-game content gamepl that is customized to players and",
    "start": "423800",
    "end": "431000"
  },
  {
    "text": "finally um the ultimate which is user generated content leading to endless",
    "start": "431000",
    "end": "436639"
  },
  {
    "text": "worlds right that's sort of a little ways in the future for game play experiences we believe that running",
    "start": "436639",
    "end": "444160"
  },
  {
    "text": "generative AI inference inside of kubernetes on alongside your game",
    "start": "444160",
    "end": "449400"
  },
  {
    "text": "servers is really going to be the best solution as the industry develops this",
    "start": "449400",
    "end": "455758"
  },
  {
    "text": "capability so today uh we will focus on sort of the right side of this which is",
    "start": "456960",
    "end": "462800"
  },
  {
    "text": "uh sort of the focus of the talk which is real time inference during",
    "start": "462800",
    "end": "468080"
  },
  {
    "text": "gameplay now we looked at the use cases and let's also dis uh discuss typical",
    "start": "468080",
    "end": "475120"
  },
  {
    "text": "user pain points for generative a in games this is based on user research that um our team conducted with subject",
    "start": "475120",
    "end": "481759"
  },
  {
    "text": "matter experts across the games industry so at the platform level uh sort of",
    "start": "481759",
    "end": "487159"
  },
  {
    "text": "starting in the top row um cost and latency are crucial so for generative AI",
    "start": "487159",
    "end": "492599"
  },
  {
    "text": "to be financially feasible in popular games with a large number of players or concurrent users generative AI inference",
    "start": "492599",
    "end": "500080"
  },
  {
    "text": "has to be cost effective goes with that saying right obvious additionally for a smooth game play um and a seamless",
    "start": "500080",
    "end": "507800"
  },
  {
    "text": "player experience the cannot be any lag so low latency is also very important",
    "start": "507800",
    "end": "514200"
  },
  {
    "text": "poor gameplay with a lot of lag can really hurt the success of these games",
    "start": "514200",
    "end": "519760"
  },
  {
    "text": "also raw performance and the ability to run stateof art models without vendor lockin will really",
    "start": "519760",
    "end": "528080"
  },
  {
    "text": "Drive platform decisions the next set of pain points really revolve around the maturity of AI models today in games we",
    "start": "528080",
    "end": "535720"
  },
  {
    "text": "need coherent relevant and contextually appropriate inference over and over",
    "start": "535720",
    "end": "540880"
  },
  {
    "text": "again that's repeatable these models should not of course propagate biases or",
    "start": "540880",
    "end": "546320"
  },
  {
    "text": "stereotypes we also need appropriate content moderation to align with the maturity ratings in games to ensure a",
    "start": "546320",
    "end": "552720"
  },
  {
    "text": "safe and inclusive experience for everyone on the other hand sort of moving into the row at the very bottom",
    "start": "552720",
    "end": "559279"
  },
  {
    "text": "for an engaging game play some games might want to content that llm filters",
    "start": "559279",
    "end": "564800"
  },
  {
    "text": "out today so they might want to show certain images that enhance the gameplay experience furthermore there needs to be",
    "start": "564800",
    "end": "571560"
  },
  {
    "text": "a balance between user generated content and the game structure or lore or the",
    "start": "571560",
    "end": "576959"
  },
  {
    "text": "storyline procedural generation will still require human Supervision in the",
    "start": "576959",
    "end": "582240"
  },
  {
    "text": "near future and as we continue to evolve AI models and llms and how we integrate that with",
    "start": "582240",
    "end": "588640"
  },
  {
    "text": "gameplay so as the game industry starts to integrate generative AI games will continue to evolve the whole industry in",
    "start": "588640",
    "end": "595279"
  },
  {
    "text": "fact will continue to evolve similar to how previously business model evolve from box software games that you could",
    "start": "595279",
    "end": "601200"
  },
  {
    "text": "go to Best Buy or GameStop and get to live service games we will we will continue to evolve into what some are",
    "start": "601200",
    "end": "608480"
  },
  {
    "text": "calling living games in such a model the relationship cycle between the player",
    "start": "608480",
    "end": "613959"
  },
  {
    "text": "and the developer expands to the game itself with all three aspects",
    "start": "613959",
    "end": "619560"
  },
  {
    "text": "interacting to enrich the player experience in these living games game",
    "start": "619560",
    "end": "624640"
  },
  {
    "text": "developers will need to implement AI responsibly and securely safeguarding",
    "start": "624640",
    "end": "630200"
  },
  {
    "text": "intellectual property while of course being vigilant and respecting the",
    "start": "630200",
    "end": "635720"
  },
  {
    "text": "player before we dive deeper into creating living games that I just spoke about by integrating with generative AI",
    "start": "635720",
    "end": "642839"
  },
  {
    "text": "let's briefly discuss how kubernetes is a great compute solution for games kubernetes solves a majority of",
    "start": "642839",
    "end": "650000"
  },
  {
    "text": "the it operations problems for games as you're all familiar with scheduling",
    "start": "650000",
    "end": "655519"
  },
  {
    "text": "Autos scaling Health checking logging and monitoring declarative paradigms",
    "start": "655519",
    "end": "660639"
  },
  {
    "text": "roll backs isolation Etc however kubernetes on its own",
    "start": "660639",
    "end": "666360"
  },
  {
    "text": "doesn't understand Game servers for Game servers we really need the ability to do a few things start and",
    "start": "666360",
    "end": "673000"
  },
  {
    "text": "shut down on demand be able to Pro uh protect Game servers that are running with players on them uh these allocated",
    "start": "673000",
    "end": "680000"
  },
  {
    "text": "Game servers cannot just be shut down even for upgrades that's a poor player experience especially if you're going to win a game and your play your game",
    "start": "680000",
    "end": "686560"
  },
  {
    "text": "server gets shut down for upgrades also to be able to scale On Demand right these are based on location number of",
    "start": "686560",
    "end": "693800"
  },
  {
    "text": "players um rather than CPU uh utilization so for games in memory state",
    "start": "693800",
    "end": "700279"
  },
  {
    "text": "is critical enter agonas um you might have heard talks",
    "start": "700279",
    "end": "705839"
  },
  {
    "text": "about agonas previously it's an open- Source batteries included multiplayer dedicated game server scaling and",
    "start": "705839",
    "end": "712480"
  },
  {
    "text": "orchestration platform and that can run anywhere where kubernetes can run in",
    "start": "712480",
    "end": "717959"
  },
  {
    "text": "2017 in a partnership between Google cloud and Ubisoft we built a gonus which teaches kubernetes how to run game",
    "start": "717959",
    "end": "725040"
  },
  {
    "text": "servers running a gonus and kubernetes really enables hosting running and scaling dedicated Game servers since",
    "start": "725040",
    "end": "732519"
  },
  {
    "text": "then many contributors um across the community across Google and many other game studios have continued to build and",
    "start": "732519",
    "end": "739360"
  },
  {
    "text": "enhance agonas and to this day we're continuing with releases on that agonas understands game sessions it scales with",
    "start": "739360",
    "end": "746079"
  },
  {
    "text": "player loads it supports multiple Network proxies UDP TCP uh ports per",
    "start": "746079",
    "end": "751440"
  },
  {
    "text": "node has tunable warm-up parameters and of course it is open source which is extremely",
    "start": "751440",
    "end": "757480"
  },
  {
    "text": "valuable so this is what a highlevel architecture of a live service game looks like uh players start in a Lobby",
    "start": "757480",
    "end": "764519"
  },
  {
    "text": "on the left there's a Matchmaker that directs them to connect to a dedicated game server where they can connect in a",
    "start": "764519",
    "end": "771440"
  },
  {
    "text": "shared environment a shared experience with other players that's a multiplayer session based game the game front end um",
    "start": "771440",
    "end": "779600"
  },
  {
    "text": "customer matchmaking client and the play player profile service can all run on kubernetes",
    "start": "779600",
    "end": "785720"
  },
  {
    "text": "clusters the player profile metadata can write to a globally replicated database for Access later or for an an analytics",
    "start": "785720",
    "end": "792839"
  },
  {
    "text": "uh such as leaderboards right the game servers also run in kubernetes clusters and are orchestrated by a gonus that we",
    "start": "792839",
    "end": "799399"
  },
  {
    "text": "just spoke about a service mesh can be used for Global deployments so we want",
    "start": "799399",
    "end": "804920"
  },
  {
    "text": "to now add generative AI inference servers with the game server to create a whole new type of game right so how do",
    "start": "804920",
    "end": "811639"
  },
  {
    "text": "we deploy them how do you manage them how do we connect them together that's",
    "start": "811639",
    "end": "817160"
  },
  {
    "text": "the next slide so a typical uh so there are a few different",
    "start": "817160",
    "end": "822839"
  },
  {
    "text": "ways of integrating generative AI inference with Game servers of course one is a turn q",
    "start": "822839",
    "end": "829120"
  },
  {
    "text": "solution such as vertex AI Sage maker stable diffusion API where the game",
    "start": "829120",
    "end": "834560"
  },
  {
    "text": "servers running on a gonus on kubernetes can directly query the API the second approach is more of a",
    "start": "834560",
    "end": "843079"
  },
  {
    "text": "do-it-yourself approach and that uses kubernetes and they're largely two options for that in the first case",
    "start": "843079",
    "end": "849040"
  },
  {
    "text": "generative AI INF servers can run on dedicated kubernetes nodes this allows",
    "start": "849040",
    "end": "854160"
  },
  {
    "text": "multiple Game servers orchestrated by agonas to query the inference apis when",
    "start": "854160",
    "end": "859839"
  },
  {
    "text": "needed the servers can then run on Hardware such as gpus um the inference servers I mean can run on um gpus or",
    "start": "859839",
    "end": "867600"
  },
  {
    "text": "other high performance C pus Etc to find the right balance between raw performance and cost the other approach",
    "start": "867600",
    "end": "875320"
  },
  {
    "text": "is to deploy generative AI inference as a side car to agonis Game servers within",
    "start": "875320",
    "end": "880480"
  },
  {
    "text": "the same pod this makes sense uh really when the dedicated inference server is",
    "start": "880480",
    "end": "885920"
  },
  {
    "text": "needed for each game server and the underlying Hardware of course is optimal",
    "start": "885920",
    "end": "891000"
  },
  {
    "text": "for both the game server and the inference server we've seen examples of this where sometimes game servers are",
    "start": "891000",
    "end": "896959"
  },
  {
    "text": "running on gpus and there is capacity that's available on the underlying hardware and INF servers sort of make",
    "start": "896959",
    "end": "903800"
  },
  {
    "text": "sense to go on there uh of course A lot of times as you might be familiar Game servers um typically run on CPUs",
    "start": "903800",
    "end": "911959"
  },
  {
    "text": "different types of performance CPUs based on the requirements of Game servers Beyond this of course game",
    "start": "911959",
    "end": "917320"
  },
  {
    "text": "developers can also choose to integrate the generative AI inference within the game binary itself um and run it on um",
    "start": "917320",
    "end": "924920"
  },
  {
    "text": "gones on Game Server um pods and of course this oses strong performance",
    "start": "924920",
    "end": "930519"
  },
  {
    "text": "requirements on the underlying Hardware given that you're running both the generative Ai and the game server in the",
    "start": "930519",
    "end": "936560"
  },
  {
    "text": "same binary now let's dive deeper into these options so uh there are advantages of",
    "start": "936560",
    "end": "943360"
  },
  {
    "text": "use uh to using a turnkey solution um especially in game development use cases",
    "start": "943360",
    "end": "948399"
  },
  {
    "text": "where um you it's not real time that was sort of the first column in the chart a",
    "start": "948399",
    "end": "953800"
  },
  {
    "text": "few slides ago uh where it's the game development use cases you're doing assets generation ET Etc in that case",
    "start": "953800",
    "end": "959959"
  },
  {
    "text": "there are not too many requirements for real time where you can query offline uh some of the apis or some of the turnkey",
    "start": "959959",
    "end": "966560"
  },
  {
    "text": "Solutions TurnKey Solutions of course improve time to Value uh where poc's for",
    "start": "966560",
    "end": "972519"
  },
  {
    "text": "or realtime uh use cases for game play TurnKey Solutions are great for that as",
    "start": "972519",
    "end": "977920"
  },
  {
    "text": "well and sometimes there only specific models are only available through uh",
    "start": "977920",
    "end": "983120"
  },
  {
    "text": "TurnKey apis they're not available um openly available where you can containerize them in those situations",
    "start": "983120",
    "end": "989639"
  },
  {
    "text": "you're kind of um tied to using an API now looking at the DIY solution with",
    "start": "989639",
    "end": "995360"
  },
  {
    "text": "kubernetes for generative Aon games um in the market today as you would see",
    "start": "995360",
    "end": "1001319"
  },
  {
    "text": "every single day increasing number of openly available models are a um are",
    "start": "1001319",
    "end": "1006480"
  },
  {
    "text": "becoming available and they can be run in containers what this also provides is",
    "start": "1006480",
    "end": "1012120"
  },
  {
    "text": "cost optimization at scale so kubernetes can be more cost effective than paper use apis for high usage scenarios for",
    "start": "1012120",
    "end": "1019720"
  },
  {
    "text": "example game launches where you're going to see an influx of a lot of concurrent users within a short amount of time so",
    "start": "1019720",
    "end": "1027160"
  },
  {
    "text": "there the unit cost where you're paying for the API starts to go up whereas if you're playing for the platform um that",
    "start": "1027160",
    "end": "1034438"
  },
  {
    "text": "of course makes sense for these um for these high user scenarios dedicated inference uh",
    "start": "1034439",
    "end": "1040480"
  },
  {
    "text": "kubernetes nodes are also of course easy to set up um and they can use the kubernetes features that we're all",
    "start": "1040480",
    "end": "1046280"
  },
  {
    "text": "familiar with such as horiz po Auto scaling scheduling retains and tolerance",
    "start": "1046280",
    "end": "1051679"
  },
  {
    "text": "Etc now generative AI side cars which is the other option that I spoke about might have a slight advantage in latency",
    "start": "1051679",
    "end": "1058760"
  },
  {
    "text": "but they are costly they're onetoone with Game servers and you might be spinning a lot of these Game servers",
    "start": "1058760",
    "end": "1064280"
  },
  {
    "text": "which means that you're also spinning up a lot of these inference servers but in which in cases where",
    "start": "1064280",
    "end": "1069919"
  },
  {
    "text": "inference really doesn't use as much compute power side cars could be useful",
    "start": "1069919",
    "end": "1075000"
  },
  {
    "text": "um because you're using some of the compute that might still be available so that's where um the inference model to",
    "start": "1075000",
    "end": "1081200"
  },
  {
    "text": "game server one:1 might make sense and you're able to bin pack your pods so",
    "start": "1081200",
    "end": "1086559"
  },
  {
    "text": "what we did is we ran some initial tests with stable diffusion and with Bloom so that's a table on the right so we tested",
    "start": "1086559",
    "end": "1093880"
  },
  {
    "text": "two scenarios on kubernetes which is uh dedicated kubernetes nodes and the side",
    "start": "1093880",
    "end": "1099520"
  },
  {
    "text": "car scenario which are the two rows so it's stable defusion uh the order of magnitude is it's 1 to 1.3 seconds and",
    "start": "1099520",
    "end": "1107760"
  },
  {
    "text": "that's large U because of the latency that's um in the inference",
    "start": "1107760",
    "end": "1113280"
  },
  {
    "text": "itself the bloom which is a text based model um the the latency that we saw",
    "start": "1113280",
    "end": "1119480"
  },
  {
    "text": "with um the latency that we saw with dedicated inference nodes was about 146",
    "start": "1119480",
    "end": "1125679"
  },
  {
    "text": "to 147 milliseconds whereas with the side car model we saw 144 to 145",
    "start": "1125679",
    "end": "1132200"
  },
  {
    "text": "millisecond so a slight difference which is sort of expected however the meta Point here the the key point or takeaway",
    "start": "1132200",
    "end": "1139280"
  },
  {
    "text": "here is that inference latency today as you can see in the um stable diffusion",
    "start": "1139280",
    "end": "1145000"
  },
  {
    "text": "model really overpowers any difference between uh different kubernetes",
    "start": "1145000",
    "end": "1150320"
  },
  {
    "text": "deployment methods so um dedicated inference kubernetes notes provide the most ver versatility um ease of use and",
    "start": "1150320",
    "end": "1158840"
  },
  {
    "text": "flexibility compared to side cars because they can be used for multiple Game servers all at the same time they",
    "start": "1158840",
    "end": "1164679"
  },
  {
    "text": "can have dedicated optimized underlying Hardware Etc in the future as some of",
    "start": "1164679",
    "end": "1169799"
  },
  {
    "text": "the inference latency in these models starts to go down these differences will",
    "start": "1169799",
    "end": "1175039"
  },
  {
    "text": "start to become more exaggerated and that's when we really have to make the decisions on which scenario to really go",
    "start": "1175039",
    "end": "1181880"
  },
  {
    "text": "with so something to look forward to and something to prepare as these inference uh starts to get faster and faster and",
    "start": "1181880",
    "end": "1188520"
  },
  {
    "text": "we get faster and better Hardware so for game workloads uh",
    "start": "1188520",
    "end": "1194039"
  },
  {
    "text": "running generative AI specifically kubernetes does have several advantages ages portability to run train and serve",
    "start": "1194039",
    "end": "1201559"
  },
  {
    "text": "across clouds preventing vendor locking and this is key to games customers who are trying to access Global markets the",
    "start": "1201559",
    "end": "1208559"
  },
  {
    "text": "flexibility to choose the right framework for the job um there are a lot of different Frameworks that are",
    "start": "1208559",
    "end": "1213760"
  },
  {
    "text": "available and becoming increasingly available so that's important um kubernetes works really well for that",
    "start": "1213760",
    "end": "1219840"
  },
  {
    "text": "the ability to fine-tune Performance and scale a platform we've all built skills in kubernetes um over the last few years",
    "start": "1219840",
    "end": "1227840"
  },
  {
    "text": "um we can use those skills towards generative AI if we have the do if we subscribe to the do-it-yourself model on",
    "start": "1227840",
    "end": "1235799"
  },
  {
    "text": "kubernetes and of course the advantage for paying what you need when you need it with higher utilization of comput",
    "start": "1235799",
    "end": "1242240"
  },
  {
    "text": "resources uh whether it's CPUs gpus tpus Etc and of course cost savings if you're",
    "start": "1242240",
    "end": "1247679"
  },
  {
    "text": "able to use something like spot instances most importantly customers can run their generative AI inference",
    "start": "1247679",
    "end": "1254280"
  },
  {
    "text": "alongside game servers that are orchestrated by gonus right right so that uh agonis being open source and",
    "start": "1254280",
    "end": "1261440"
  },
  {
    "text": "being able to run in kubernetes which is also open source that really gives you the best best versatility and it allows",
    "start": "1261440",
    "end": "1268360"
  },
  {
    "text": "you to really optimize the two together so this improves performance latency and of course it reduces management overhead",
    "start": "1268360",
    "end": "1275120"
  },
  {
    "text": "does not require to retain retrain the skill set of your teams",
    "start": "1275120",
    "end": "1281080"
  },
  {
    "text": "Etc so with that uh we'll jump into sort of the next part which you all have been",
    "start": "1281080",
    "end": "1287200"
  },
  {
    "text": "waiting for hopefully which is the demo so just to give you a bit of the scenario so this is a game that we have",
    "start": "1287200",
    "end": "1294200"
  },
  {
    "text": "developed we partner with uh gloin um to develop this uh this uh this game um I",
    "start": "1294200",
    "end": "1302080"
  },
  {
    "text": "I'll show you a video of the game and this was recorded in one shot um we have",
    "start": "1302080",
    "end": "1307440"
  },
  {
    "text": "integrated generative AI in there um we we will show you two use cases from the",
    "start": "1307440",
    "end": "1312840"
  },
  {
    "text": "ones that I highlighted earlier the first one being uh smart non-playable characters where there's a dialogue with",
    "start": "1312840",
    "end": "1319360"
  },
  {
    "text": "a with a robot um the robot is named bodis and it's a yellow robot you will",
    "start": "1319360",
    "end": "1325159"
  },
  {
    "text": "see in just a little bit and the second part of it just to show you uh image generation in real time we created a",
    "start": "1325159",
    "end": "1333400"
  },
  {
    "text": "bunch of different Billboards throughout the game now those Billboards represent places where images can be shown uh",
    "start": "1333400",
    "end": "1340640"
  },
  {
    "text": "perhaps these are textures on on cars or or your your clothes or buildings Etc so",
    "start": "1340640",
    "end": "1347440"
  },
  {
    "text": "these are really meant to represent um images that can be used within the game play gameplay environment so uh that's",
    "start": "1347440",
    "end": "1354880"
  },
  {
    "text": "our attempt at showing you what is possible in the and and what is possible",
    "start": "1354880",
    "end": "1361440"
  },
  {
    "text": "uh going forward now this game takes place in the future um I'll I'll just start it just",
    "start": "1361440",
    "end": "1369640"
  },
  {
    "text": "in a little bit but this game takes place in the future um there is a a city",
    "start": "1369640",
    "end": "1375919"
  },
  {
    "text": "where um an alien robot in a spaceship um has come to Earth uh unfortunately",
    "start": "1375919",
    "end": "1383120"
  },
  {
    "text": "the spaceship has crashed and we spin into the game or we start off the game",
    "start": "1383120",
    "end": "1388159"
  },
  {
    "text": "it's a multiplayer game session based game uh so it is using aonis um and um",
    "start": "1388159",
    "end": "1393400"
  },
  {
    "text": "and my partner and I we're in this game and we are trying to help out and understand what's happening uh discuss",
    "start": "1393400",
    "end": "1399960"
  },
  {
    "text": "with the robot and of course eventually help them out so that's the context of the game let's make sure it plays",
    "start": "1399960",
    "end": "1406880"
  },
  {
    "text": "um so here um uh the player which is which",
    "start": "1406880",
    "end": "1415080"
  },
  {
    "text": "is me and and um my partner are exploring what is happening we uh my",
    "start": "1415080",
    "end": "1421880"
  },
  {
    "text": "partner is we both discuss okay maybe there's a robot here we should speak with it now this is where um we are",
    "start": "1421880",
    "end": "1428400"
  },
  {
    "text": "actually using a generative AI model um I'll speak about that just in a little",
    "start": "1428400",
    "end": "1433760"
  },
  {
    "text": "bit little bit um just for folks um I typed in Diego hello who are you uh",
    "start": "1433760",
    "end": "1441600"
  },
  {
    "text": "bodess respond responds I'm bodis um what are you doing in their bodice I'm",
    "start": "1441600",
    "end": "1446720"
  },
  {
    "text": "looking for parts to repair my ship is bess's response the next question we're asking do you want me to help you look",
    "start": "1446720",
    "end": "1453039"
  },
  {
    "text": "for parts bodis says yes how can I help find the parts bod",
    "start": "1453039",
    "end": "1460679"
  },
  {
    "text": "says use the Billboards to guide you to the parts you need now uh we type in how will the",
    "start": "1460679",
    "end": "1469240"
  },
  {
    "text": "Billboards help me the Billboards will show you where to find the components you",
    "start": "1469240",
    "end": "1475000"
  },
  {
    "text": "need and then being a nice person I say okay I will look for the parts and um",
    "start": "1475000",
    "end": "1485039"
  },
  {
    "text": "and see you then and bis says I will be waiting so that's in real time during",
    "start": "1485039",
    "end": "1490799"
  },
  {
    "text": "game play it wasn't from before so now I'm off on the quest uh trying to help",
    "start": "1490799",
    "end": "1495960"
  },
  {
    "text": "bodis looking for these billboards walking through the gameplay environment walk behind a school bus and as I go",
    "start": "1495960",
    "end": "1502520"
  },
  {
    "text": "through here I see a billboard up front which tells me there's a box now if you notice very closely the billboard",
    "start": "1502520",
    "end": "1507799"
  },
  {
    "text": "changed those are actually prompts The Prompt is something like uh create a box with neon highlights on it and you can",
    "start": "1507799",
    "end": "1515000"
  },
  {
    "text": "see the box is changing so these are um hitting the stable diffusion model running on kubernetes in real time where",
    "start": "1515000",
    "end": "1521600"
  },
  {
    "text": "images are being generated based on that one prompt so um now I see an alien with",
    "start": "1521600",
    "end": "1527200"
  },
  {
    "text": "a burger as you saw on the right of course the prompt for the game is alien with a burger and here there's a bunch of kids playing uh wonder what that is",
    "start": "1527200",
    "end": "1534600"
  },
  {
    "text": "not sure what it is let's wait for another image that might appear and there's a school bus oh there was a",
    "start": "1534600",
    "end": "1540600"
  },
  {
    "text": "school bus just now huh it's right over there player two why don't you go explore the school bus while I go figure",
    "start": "1540600",
    "end": "1546679"
  },
  {
    "text": "out what this hamburger alien eating hamburger is oh look there's a hamburger joint here and there is a box with a",
    "start": "1546679",
    "end": "1552679"
  },
  {
    "text": "neon great I picked that up school bus did you figure anything out oh yeah I got the other box cool all right now",
    "start": "1552679",
    "end": "1558760"
  },
  {
    "text": "let's both we got two boxes now let's see what else is happening so there's some fire here oh there's an exhaust it",
    "start": "1558760",
    "end": "1566039"
  },
  {
    "text": "looks like a spaceship something like that um interesting there is fire in the",
    "start": "1566039",
    "end": "1571600"
  },
  {
    "text": "okay so it's an ignition thing all right oh there's something here player two can you please help me open this gate and",
    "start": "1571600",
    "end": "1578120"
  },
  {
    "text": "player two goes in opens the gate I walk in oh there's another box with a neon x on it I'm going to grab that so now",
    "start": "1578120",
    "end": "1583840"
  },
  {
    "text": "between the two of us we have grabbed two boxes now let's let go and find where bodice is okay more Billboards",
    "start": "1583840",
    "end": "1591279"
  },
  {
    "text": "there a school bus we haven't explored this oh look there is a spaceship um all right maybe I should head in this",
    "start": "1591279",
    "end": "1596799"
  },
  {
    "text": "direction another spaceship I'm getting closer maybe this is where the spaceships are oh another spaceship all",
    "start": "1596799",
    "end": "1602320"
  },
  {
    "text": "of those are images that are generated in real time uh with stable diffusion I",
    "start": "1602320",
    "end": "1608200"
  },
  {
    "text": "see a spaceship oh I see bodice as well player two please speak with bodice what do I need to do player two tells me put",
    "start": "1608200",
    "end": "1614039"
  },
  {
    "text": "the boxes in here these are the components for the um for for the engine for the spaceship all right ooh bodis",
    "start": "1614039",
    "end": "1620440"
  },
  {
    "text": "got into the spaceship great now the spaceship is powering up it's ready to go Powers up the engines and launch in",
    "start": "1620440",
    "end": "1628120"
  },
  {
    "text": "three two one and it's gone to space and we have rescued bodis with realtime",
    "start": "1628120",
    "end": "1633840"
  },
  {
    "text": "generative AI that was happening during",
    "start": "1633840",
    "end": "1638120"
  },
  {
    "text": "gameplay thank you so let's actually the more",
    "start": "1638880",
    "end": "1645840"
  },
  {
    "text": "interesting part is how did this actually work what's underneath this right so you can see on the left this",
    "start": "1645840",
    "end": "1652440"
  },
  {
    "text": "chart looks very familiar with uh the chart I presented a few uh a few slides ago on the left are are my players so",
    "start": "1652440",
    "end": "1660360"
  },
  {
    "text": "Diego and and my friend let's um let's call them isan me um the two of us are",
    "start": "1660360",
    "end": "1666080"
  },
  {
    "text": "playing we connect to the game servers that's sort of how a typical backend works for a game um we're both in uh",
    "start": "1666080",
    "end": "1674200"
  },
  {
    "text": "game servers of uh we ran this on Google Cloud um uh we're using us Central one",
    "start": "1674200",
    "end": "1680480"
  },
  {
    "text": "as where we built this demo we used Google kubernetes engine for this",
    "start": "1680480",
    "end": "1685559"
  },
  {
    "text": "deployment um so we have a GK game uh server cluster which is running a bunch of agonas Game servers when we move to",
    "start": "1685559",
    "end": "1692679"
  },
  {
    "text": "the inference cluster here we decided not to use the sidecar model but we decided to use dedicated nodes we put",
    "start": "1692679",
    "end": "1698960"
  },
  {
    "text": "these dedicated nodes onto a different GK cluster powered by gpus now within that there is an API",
    "start": "1698960",
    "end": "1706960"
  },
  {
    "text": "which basically Ally routes the traffic to the various models uh depending on",
    "start": "1706960",
    "end": "1712240"
  },
  {
    "text": "which scenario we're looking at so uh whether it's the smart NPC or the",
    "start": "1712240",
    "end": "1717600"
  },
  {
    "text": "Billboards that are doing image generation then we have sort of this middle layer and I'll get back to this",
    "start": "1717600",
    "end": "1722960"
  },
  {
    "text": "but the middle layer basically is logic for each of the use cases so for NPC logic there is um uh there is a service",
    "start": "1722960",
    "end": "1730559"
  },
  {
    "text": "running that handles text processing for the dialogue pre-processing and postprocessing um for example",
    "start": "1730559",
    "end": "1737919"
  },
  {
    "text": "um if you have played around with um with chat PT or you played around with",
    "start": "1737919",
    "end": "1742960"
  },
  {
    "text": "Bard from Google uh you would have noticed um that if you provided context the response that it gives you makes",
    "start": "1742960",
    "end": "1749399"
  },
  {
    "text": "more sense so what we did is we did a bit of prompt engineering where we gave the context something along the lines of",
    "start": "1749399",
    "end": "1756200"
  },
  {
    "text": "um respond as if you are a an alien from named bodess alien robot from a planet",
    "start": "1756200",
    "end": "1762840"
  },
  {
    "text": "named um and your name is bodess respon your spaces shift has crashed you are um",
    "start": "1762840",
    "end": "1768640"
  },
  {
    "text": "you're going to you're looking for parts that are scattered throughout the city you're going to help guide you need help",
    "start": "1768640",
    "end": "1774600"
  },
  {
    "text": "to find these parts and you're going to guide them by using Billboards uh so respond as of that and response in short",
    "start": "1774600",
    "end": "1782080"
  },
  {
    "text": "um statements that are no longer than x so that's sort of what the context is to",
    "start": "1782080",
    "end": "1787440"
  },
  {
    "text": "the model and then all of the questions kind of go in um hit that API or that model that session that's running so the",
    "start": "1787440",
    "end": "1794120"
  },
  {
    "text": "model has the context to respond appropriately so that's sort of what would go in those logic areas imag in",
    "start": "1794120",
    "end": "1800120"
  },
  {
    "text": "logic that of course has okay we had an alien with a hamburger we had a school",
    "start": "1800120",
    "end": "1805159"
  },
  {
    "text": "bus that's uh we had the ships with an exhaust and all of that so those are all",
    "start": "1805159",
    "end": "1810760"
  },
  {
    "text": "Billboards those are contexts that we're providing of the prompts that we're providing uh just going back for the the",
    "start": "1810760",
    "end": "1816760"
  },
  {
    "text": "NPC logic uh with the context that we have provided to the model what the user",
    "start": "1816760",
    "end": "1822279"
  },
  {
    "text": "inputs is passed through directly as is to the model so that's where the real time Genera AI comes into play um and of",
    "start": "1822279",
    "end": "1830399"
  },
  {
    "text": "course uh we also used built in some of the vertex AI Services as well just so",
    "start": "1830399",
    "end": "1835480"
  },
  {
    "text": "that we can use that during development and that that's a turnkey Solution that's on Google Cloud so we use that as",
    "start": "1835480",
    "end": "1840960"
  },
  {
    "text": "well uh for llm pre and postprocessing and there we go and hit the vertex API so we try to build in both the scenarios",
    "start": "1840960",
    "end": "1847600"
  },
  {
    "text": "into this deployment uh the NPC Logic the imen logic all on gke and kubernetes",
    "start": "1847600",
    "end": "1853720"
  },
  {
    "text": "and then um the models of course running so llama 2 model running on gke um",
    "start": "1853720",
    "end": "1859240"
  },
  {
    "text": "that's what we used and um then there is that can run both on gpus or CPUs",
    "start": "1859240",
    "end": "1864840"
  },
  {
    "text": "depending on the performance that you're looking for and for image generation we use stable diffusion um so so that was",
    "start": "1864840",
    "end": "1870880"
  },
  {
    "text": "on on gpus so I want to highlight one aspect of this the middle layer here is",
    "start": "1870880",
    "end": "1878480"
  },
  {
    "text": "incredibly interesting um we actually spend a lot of time on this middle layer which is sort of the NPC logic and the",
    "start": "1878480",
    "end": "1885440"
  },
  {
    "text": "apis because that's where um we really integrate the game servers",
    "start": "1885440",
    "end": "1891880"
  },
  {
    "text": "inference and we abstract away the calls we load balance them and we um we send",
    "start": "1891880",
    "end": "1897399"
  },
  {
    "text": "it out to different inference servers so going forward that's where we're going to be spending a lot of our time seeing",
    "start": "1897399",
    "end": "1904279"
  },
  {
    "text": "how well that integrates with the gonus and uh with kubernetes so that's really I think where uh where the important",
    "start": "1904279",
    "end": "1911360"
  },
  {
    "text": "part is and even for example with stable diffusion we were getting time um inference times that were really long so",
    "start": "1911360",
    "end": "1919200"
  },
  {
    "text": "uh we spent a bit of time trying to reduce that to to a couple seconds which you saw in real time that was not sped",
    "start": "1919200",
    "end": "1925039"
  },
  {
    "text": "up it was actually a couple seconds where the inference was coming in real",
    "start": "1925039",
    "end": "1931039"
  },
  {
    "text": "time as with anything there's a huge team behind it we'd like to thank our Glo our partners at globant um and and",
    "start": "1931039",
    "end": "1938399"
  },
  {
    "text": "uh various Google Cloud uh contributors uh especially um the cloud C team and uh",
    "start": "1938399",
    "end": "1944880"
  },
  {
    "text": "for AI inference and benchmarking our team uh there of course uh user research",
    "start": "1944880",
    "end": "1950120"
  },
  {
    "text": "uh for that part and and our leadership for sponsoring some of this so as you explore integrating",
    "start": "1950120",
    "end": "1957480"
  },
  {
    "text": "generative AI in your games consider deploying your services on kubernetes uh",
    "start": "1957480",
    "end": "1962799"
  },
  {
    "text": "be it matchmaking Game servers generative AI uh what we have hopefully presented you is we have uh tickled your",
    "start": "1962799",
    "end": "1970039"
  },
  {
    "text": "imagination uh we have got you excited about how all of this can be done with kubernetes using the same skills that",
    "start": "1970039",
    "end": "1976519"
  },
  {
    "text": "you bu bu built up using the same awesome platform that we have um and and we can really change the future of um of",
    "start": "1976519",
    "end": "1984320"
  },
  {
    "text": "games and entertainment uh here are some links uh please feel free to connect with us we'd love to chat with you uh",
    "start": "1984320",
    "end": "1990960"
  },
  {
    "text": "learn about how you're exploring how your journey is with generative AI in games um and and here are some key links",
    "start": "1990960",
    "end": "1999200"
  },
  {
    "text": "please feel free to reach out um G2x uh at",
    "start": "1999200",
    "end": "2005039"
  },
  {
    "text": "google.com with that thank you so much for uh for coming here have a safe trip",
    "start": "2005039",
    "end": "2011000"
  },
  {
    "text": "back home if you have come from abroad or you have come from different cities if you're local again have a safe flight",
    "start": "2011000",
    "end": "2017240"
  },
  {
    "text": "home and uh enjoy the rest of the conference thank you so much for being",
    "start": "2017240",
    "end": "2022600"
  },
  {
    "text": "here I would love for you to come up uh chat with me want to love um want to",
    "start": "2024960",
    "end": "2030760"
  },
  {
    "text": "would love to understand what you're working on and and ask any questions um thank you I'll be up here for a few",
    "start": "2030760",
    "end": "2036840"
  },
  {
    "text": "minutes minutes",
    "start": "2036840",
    "end": "2039840"
  }
]
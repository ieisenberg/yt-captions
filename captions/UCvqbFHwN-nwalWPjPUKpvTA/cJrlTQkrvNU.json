[
  {
    "text": "first of all thank you for coming for the last session of the day my name is Amit kalamar I lead observability and",
    "start": "919",
    "end": "7640"
  },
  {
    "text": "analytics at into it I have with me vijit moris he is a principal engineer in my group and today we wanted to talk",
    "start": "7640",
    "end": "15240"
  },
  {
    "text": "about how we are using jna and AI Ops to reduce mttr at",
    "start": "15240",
    "end": "22000"
  },
  {
    "text": "in so here's the agenda for today we will talk about into it our operational",
    "start": "22000",
    "end": "27800"
  },
  {
    "text": "excellence goal how are we achieving those we have a nice demo for you and",
    "start": "27800",
    "end": "33440"
  },
  {
    "text": "then we'll talk about Numa which is powering all of this and how you can use",
    "start": "33440",
    "end": "38520"
  },
  {
    "text": "Numa in different use cases most of you will know into it from",
    "start": "38520",
    "end": "45559"
  },
  {
    "text": "our Flagship product QuickBooks Turbo Tax CR Karma MIM we are also creators of",
    "start": "45559",
    "end": "52120"
  },
  {
    "text": "Argo so all these Flagship products are powered by these five platform areas",
    "start": "52120",
    "end": "59000"
  },
  {
    "text": "these platform areas has ensured that we drive customer value as well as Drive",
    "start": "59000",
    "end": "65360"
  },
  {
    "text": "Innovation into it is a 100% SAS company and from the numbers on the",
    "start": "65360",
    "end": "71520"
  },
  {
    "text": "screen you can see we operate at a pretty large wall large",
    "start": "71520",
    "end": "76840"
  },
  {
    "text": "scale in is also pretty much committed to open source we not only use it for our applications and platform but we",
    "start": "76840",
    "end": "84119"
  },
  {
    "text": "have active committers as well as contributors in lot of open source project the biggest success story for us",
    "start": "84119",
    "end": "91320"
  },
  {
    "text": "is Argo as most of you might know in created Argo and now it's used worldwide",
    "start": "91320",
    "end": "97720"
  },
  {
    "text": "and is one of the fastest growing project in cncf our latest open project is called",
    "start": "97720",
    "end": "103799"
  },
  {
    "text": "Numa it is used for stream processing AI Ops and analytics we just released 1.0",
    "start": "103799",
    "end": "110799"
  },
  {
    "text": "this week and we are getting good Community engagement for that project",
    "start": "110799",
    "end": "116399"
  },
  {
    "text": "also we are also proud uh recipient of cncf end user award twice so we we are",
    "start": "116399",
    "end": "124240"
  },
  {
    "text": "thankful for that so let me start with the in development platform Journey like most",
    "start": "124240",
    "end": "131879"
  },
  {
    "text": "companies we started with moving to Cloud it was mostly lift and shift the",
    "start": "131879",
    "end": "137760"
  },
  {
    "text": "workloads were traditionally monoliths running on ec2 we started at modernization of this",
    "start": "137760",
    "end": "145400"
  },
  {
    "text": "platform back in 2018 when we started adopting CL cloud natives uh technology",
    "start": "145400",
    "end": "151599"
  },
  {
    "text": "containerizing it using kubernetes uh that helped us increase our development developer productivity",
    "start": "151599",
    "end": "159879"
  },
  {
    "text": "6X and now we are more focused on making a Next Generation platform which is more",
    "start": "159879",
    "end": "165080"
  },
  {
    "text": "of AI based so this is how our a Next",
    "start": "165080",
    "end": "170400"
  },
  {
    "text": "Generation platform looks like we called it modern SAS air it has four pillars",
    "start": "170400",
    "end": "175560"
  },
  {
    "text": "the first pillar is AI powered app experience here we are using using gen",
    "start": "175560",
    "end": "180920"
  },
  {
    "text": "to provide ux experiences to our customers that",
    "start": "180920",
    "end": "186799"
  },
  {
    "text": "includes assisted experiences different types of experiences the second pillar is J assisted development that includes",
    "start": "186799",
    "end": "194360"
  },
  {
    "text": "ass helping our developers with coding debugging testing we are using things like GitHub copilot here the third",
    "start": "194360",
    "end": "200959"
  },
  {
    "text": "pillar is AI powered abcentric runtime and traffic management here we are using",
    "start": "200959",
    "end": "207280"
  },
  {
    "text": "the data which we collect and AI to make the platform simpler for our",
    "start": "207280",
    "end": "214080"
  },
  {
    "text": "developers so that they can concentrate on just writing their business logic and last not but not the least is the Smart",
    "start": "214080",
    "end": "220760"
  },
  {
    "text": "operations using aops all of this is possible because of our investment we have done in our operational data",
    "start": "220760",
    "end": "227159"
  },
  {
    "text": "platform as well as Numa so let me tell you how high level how our operational data platform works",
    "start": "227159",
    "end": "234480"
  },
  {
    "text": "on left hand side you can see we collect lot of data data from git data from",
    "start": "234480",
    "end": "239959"
  },
  {
    "text": "observability data from kubernetes in real time and then use Numa capabilities",
    "start": "239959",
    "end": "246519"
  },
  {
    "text": "to ensure that this data is clean attributable and then we store it in",
    "start": "246519",
    "end": "251799"
  },
  {
    "text": "different stores depending on the use case for example for real time you use ruid for long term we use S3 and so",
    "start": "251799",
    "end": "259560"
  },
  {
    "text": "on then we use again newo capabilities to analyze this data in in real time we",
    "start": "259560",
    "end": "266000"
  },
  {
    "text": "use traditional statistic model traditional AI models llm models to drive actionable insights and these",
    "start": "266000",
    "end": "272840"
  },
  {
    "text": "insights are then used by different use cases you can see it on the right hand side of the slide that includes security",
    "start": "272840",
    "end": "279639"
  },
  {
    "text": "use cases cost use cases development productivity use cases and of course operational excellence which is our",
    "start": "279639",
    "end": "285639"
  },
  {
    "text": "highest uh uh uh usable use case so let me talk about operational excellence at",
    "start": "285639",
    "end": "292039"
  },
  {
    "text": "into it being one of the largest SAS company operational excellence is always",
    "start": "292039",
    "end": "298199"
  },
  {
    "text": "a priority we want to to make sure our experiences and products are available and we give a delightful",
    "start": "298199",
    "end": "304440"
  },
  {
    "text": "experience to our customer so these are the four pillars around which we are",
    "start": "304440",
    "end": "309479"
  },
  {
    "text": "working on operational excellence at inate first is reduce MTD we want to",
    "start": "309479",
    "end": "316120"
  },
  {
    "text": "make sure that if there is a issue we want to know about it so we have done",
    "start": "316120",
    "end": "321319"
  },
  {
    "text": "investment here on things like automatic golden signals both for platforms and",
    "start": "321319",
    "end": "327639"
  },
  {
    "text": "services also we did some we called it as failed customer interaction which is more how our customer feels about our",
    "start": "327639",
    "end": "333840"
  },
  {
    "text": "product I'll give you an example if you are trying to upload a W2 in a Turbo Tax",
    "start": "333840",
    "end": "339120"
  },
  {
    "text": "and it fails we want to know about it so we have you have used open Telemetry to",
    "start": "339120",
    "end": "344319"
  },
  {
    "text": "instrument that and all of this help has helped us reduce our meantime to detect",
    "start": "344319",
    "end": "349560"
  },
  {
    "text": "for less than 5 minutes the second pillar is reducing mttr if there is a",
    "start": "349560",
    "end": "354840"
  },
  {
    "text": "issue we want to fix it as soon as possible so there are two pillars to two things which we have done here one is",
    "start": "354840",
    "end": "360960"
  },
  {
    "text": "the resiliency pattern but we also use our automatic golden signal to fail over",
    "start": "360960",
    "end": "366160"
  },
  {
    "text": "if there are any issues and second is automatic roll back using Progressive delivery we'll talk a little bit more",
    "start": "366160",
    "end": "372360"
  },
  {
    "text": "today on this there are two more pillars for operational excellence one is performance we use Google vitals and we",
    "start": "372360",
    "end": "379440"
  },
  {
    "text": "want to make sure our uh we give a delightful experience for our users and the fourth pillar is cost we want to",
    "start": "379440",
    "end": "386000"
  },
  {
    "text": "make sure the cost is manageable all of these is powered by",
    "start": "386000",
    "end": "393319"
  },
  {
    "text": "Numa now let's talk about reducing mttr in specific and how we are using",
    "start": "393319",
    "end": "398840"
  },
  {
    "text": "Progressive delivery for that so before we get into the solution let me tell you",
    "start": "398840",
    "end": "404240"
  },
  {
    "text": "some of the data points 1/3 of our incidents are caused at in it by",
    "start": "404240",
    "end": "411400"
  },
  {
    "text": "change and I think lot of you might uh uh correlate with that second we thought",
    "start": "411400",
    "end": "418240"
  },
  {
    "text": "saw that our mttr is high because although we have all the data we have events we have logs we have traces",
    "start": "418240",
    "end": "424800"
  },
  {
    "text": "people spend time finding out the exact thing that can help them with their",
    "start": "424800",
    "end": "430240"
  },
  {
    "text": "triaging so we wanted to address that as well as we wanted to ensure that we give",
    "start": "430240",
    "end": "435599"
  },
  {
    "text": "quick summarization for and triaging capability for incident so what we did",
    "start": "435599",
    "end": "441319"
  },
  {
    "text": "was we integrated both AI Ops and jna into Argo CD and roll outs we built two",
    "start": "441319",
    "end": "448639"
  },
  {
    "text": "net new cap probabilities one is AI Ops where we are collecting the data within",
    "start": "448639",
    "end": "454639"
  },
  {
    "text": "the cluster analyzing them running an anomal detection model and making a decision whether we want to roll back",
    "start": "454639",
    "end": "461039"
  },
  {
    "text": "automatically depending on how the change is and the second what we call is a numo pro assist here we again we run",
    "start": "461039",
    "end": "467720"
  },
  {
    "text": "an LM within the cluster itself we ingest logs traces events all kinds of",
    "start": "467720",
    "end": "473720"
  },
  {
    "text": "data and summarize it for our developer so they know why a certain thing is happening so now let me hand it over to",
    "start": "473720",
    "end": "480759"
  },
  {
    "text": "vit to show it in a demo thank you Amit so let me first",
    "start": "480759",
    "end": "486840"
  },
  {
    "text": "start with a small demo plan and so what what I'm going to do is I'm going to roll out roll out a change that has a",
    "start": "486840",
    "end": "493680"
  },
  {
    "text": "bug inside and you will see how we roll it back and also how we explain the reason for roll back so developers can",
    "start": "493680",
    "end": "500680"
  },
  {
    "text": "know what is the reason for the roll back by Listen by summarizing log events",
    "start": "500680",
    "end": "506000"
  },
  {
    "text": "and metrics and based on the lessons land I'm going to play a video on how to do",
    "start": "506000",
    "end": "512640"
  },
  {
    "text": "it so the way you have to see it is that on my right hand side this is the uh",
    "start": "512640",
    "end": "518080"
  },
  {
    "text": "demo app we have and the yellow fishes represent success once in a file you",
    "start": "518080",
    "end": "523159"
  },
  {
    "text": "will see a red fish that represents error so the fishes are going we are",
    "start": "523159",
    "end": "528959"
  },
  {
    "text": "going to make a dummy change this is sorry a buggy change and we use gitops for any change that into it we will",
    "start": "528959",
    "end": "535160"
  },
  {
    "text": "merge this PR in and once we synchronize the changes in Argo C you will see that",
    "start": "535160",
    "end": "542320"
  },
  {
    "text": "the new U Canary deployment will has been deployed so we have the stable and",
    "start": "542320",
    "end": "547399"
  },
  {
    "text": "the canary at the same time once the canary starts taking traffic you will see that there are more errors right you",
    "start": "547399",
    "end": "554600"
  },
  {
    "text": "will see more red fishes coming in this means that there is a CH bug in the deployment and the analysis has started",
    "start": "554600",
    "end": "561000"
  },
  {
    "text": "so you'll see that the analysis run is starting and the analysis template here shows anomal scores in case if you",
    "start": "561000",
    "end": "567839"
  },
  {
    "text": "cannot see in the back it's basically numbers saying that the anomaly score is around nine I'll get I'll explain that",
    "start": "567839",
    "end": "573839"
  },
  {
    "text": "in a second but analysis clearly says that there's a problem and we wait for around 5 minutes for a roll back to",
    "start": "573839",
    "end": "580480"
  },
  {
    "text": "sorry five analysis runs before a roll back to be triggered so the um only",
    "start": "580480",
    "end": "586480"
  },
  {
    "text": "three of them have run and it takes around 15 seconds for one of them to run so one key thing that is as Amit was",
    "start": "586480",
    "end": "594240"
  },
  {
    "text": "talking earlier that we developers has to see the metrics of their deployment and that's the metric extension we added",
    "start": "594240",
    "end": "600720"
  },
  {
    "text": "to Argo CD so what we show here is the golden signal it could be any metric you want to see it this metrics are fetched",
    "start": "600720",
    "end": "607600"
  },
  {
    "text": "from Prometheus so you can add whatever golden signal you think is relevant at into it we do error rate latency and few",
    "start": "607600",
    "end": "614360"
  },
  {
    "text": "few few others so you can now that we have those metrics coming in we also",
    "start": "614360",
    "end": "620560"
  },
  {
    "text": "have to quantify in a generalized fashion saying whether your deployment is good so what you see here is there's",
    "start": "620560",
    "end": "626519"
  },
  {
    "text": "a blue line or a zero line which is the anomaly score of your stable application",
    "start": "626519",
    "end": "631800"
  },
  {
    "text": "that is running and there you you might see a small change here an orange line that is coming in that is the canary",
    "start": "631800",
    "end": "638279"
  },
  {
    "text": "anomaly score that is coming in okay so if you see the values here it's the blue line is zero meaning your stable is",
    "start": "638279",
    "end": "644760"
  },
  {
    "text": "quite well and the canary is showing a value of seven now let me explain what that means um so we have the anomaly",
    "start": "644760",
    "end": "651959"
  },
  {
    "text": "score at into it is normalized between 0 to 10 anything less than three means",
    "start": "651959",
    "end": "657360"
  },
  {
    "text": "your application or your Canon is operating within the normal operating pattern with respect to your stable",
    "start": "657360",
    "end": "664600"
  },
  {
    "text": "anything more than three meaning it is started deviating from the normal operating pattern and the highest value",
    "start": "664600",
    "end": "669959"
  },
  {
    "text": "it can reach is 10 meaning it is totally deviant from the normal operating pattern that means anything less than",
    "start": "669959",
    "end": "676040"
  },
  {
    "text": "three we are good anything more than three we Auto roll back so that's what we see we have a seven and if you come",
    "start": "676040",
    "end": "682720"
  },
  {
    "text": "down here you will see that the analysis template has finished running that's the reason now on if you see the demo app you don't see any red anymore all blue",
    "start": "682720",
    "end": "689600"
  },
  {
    "text": "oh sorry all all yellow right and if also we see all",
    "start": "689600",
    "end": "694760"
  },
  {
    "text": "stable has the old good ports running the cry has been removed because analysis template",
    "start": "694760",
    "end": "700079"
  },
  {
    "text": "finished now one question developers ask at this point is why did it get rolled back this is where the summarization",
    "start": "700079",
    "end": "706600"
  },
  {
    "text": "comes in this is powered by Numa approach so this is a new T the Numa",
    "start": "706600",
    "end": "712680"
  },
  {
    "text": "approach assist tab where we show the anomaly score and some key metrics so we can see that okay there the error rate",
    "start": "712680",
    "end": "719079"
  },
  {
    "text": "is going up the anomaly score is around 9.28 that is the error rate and it gives",
    "start": "719079",
    "end": "725680"
  },
  {
    "text": "you the summary now it's giving you two summaries the first one is based on open AI DAV model 3.5 turbo what it shows is",
    "start": "725680",
    "end": "734120"
  },
  {
    "text": "that first is the summary of the number of data set that came in right it says that there are 60 error error logs",
    "start": "734120",
    "end": "739959"
  },
  {
    "text": "that's coming in and also gives you a potential root cause it says that hey the errors must be caused by too many",
    "start": "739959",
    "end": "745760"
  },
  {
    "text": "red disc Connection open so as a developer they clearly Know What's happen happening anyway they are not that worried because we Auto already",
    "start": "745760",
    "end": "751760"
  },
  {
    "text": "rolled back the change so this is a very good summary about what's happening and the potential root cause now on the",
    "start": "751760",
    "end": "758000"
  },
  {
    "text": "bottom this is open AI test uh DAV model right on the bottom we also have our own",
    "start": "758000",
    "end": "764199"
  },
  {
    "text": "fine tuned custom model this is way cheaper it's a in-cluster um um deployment of our llm that way it is way",
    "start": "764199",
    "end": "771760"
  },
  {
    "text": "cheaper fine tuned on into it data and the result is very promising and very close to the open ai1 the reason we do",
    "start": "771760",
    "end": "779000"
  },
  {
    "text": "this is at scale we had to run lot many analysis and we wanted to have a cheap way of doing it and very close and very",
    "start": "779000",
    "end": "787000"
  },
  {
    "text": "accurate result because we find tune on in it data given this that you can use this",
    "start": "787000",
    "end": "793560"
  },
  {
    "text": "llm this gen integration not only at just deployment roll backs you can do it",
    "start": "793560",
    "end": "799000"
  },
  {
    "text": "at any time of the day for example let's say you get a page during your day and you they ask there's a problem and you",
    "start": "799000",
    "end": "805560"
  },
  {
    "text": "want to debug right so let me this show you this this is the running Argo CD",
    "start": "805560",
    "end": "811399"
  },
  {
    "text": "deployment and if you want to click here right this there is no deployment going",
    "start": "811399",
    "end": "816600"
  },
  {
    "text": "on this is the normal day-to-day operation right before the meeting uh the talk I just triggered an O you can",
    "start": "816600",
    "end": "823680"
  },
  {
    "text": "trigger o by just clicking here so this is the de uh demo app and if I click here right it will take you to the place",
    "start": "823680",
    "end": "830839"
  },
  {
    "text": "and it will tell you what's happening so you can see the Numa Pro let me Zoom a bit here the Numa Pro L I'm saying that",
    "start": "830839",
    "end": "837519"
  },
  {
    "text": "hey there is around this this many errors and it the container was terminated due to an O error I hope that",
    "start": "837519",
    "end": "844240"
  },
  {
    "text": "was too much of assuming but see so we use it at runtime too meaning you don't",
    "start": "844240",
    "end": "849480"
  },
  {
    "text": "have to just have to roll back to really see it anytime us an error you can come here and you can look at the num Pro",
    "start": "849480",
    "end": "855519"
  },
  {
    "text": "assist which will tell you the summary based on all the data we that we gather and",
    "start": "855519",
    "end": "861120"
  },
  {
    "text": "collect now let me get back to my slides and talk about how we do it okay so",
    "start": "861120",
    "end": "870680"
  },
  {
    "text": "so the very high level architecture right so we have the application deployment here first is the AF platform",
    "start": "871839",
    "end": "877920"
  },
  {
    "text": "that at runtime gets all the metrics and writes an anomaly score back to Prometheus which is Argos roll outs",
    "start": "877920",
    "end": "884440"
  },
  {
    "text": "looking to and making a decision whether to roll back whether based on whether the score is greater than three or less",
    "start": "884440",
    "end": "890199"
  },
  {
    "text": "than three the bottom part of the screen what we do is the llm piece where it it has a data in that gathers logs metric",
    "start": "890199",
    "end": "897320"
  },
  {
    "text": "events there some pre-processing and then it does a call to our llm right",
    "start": "897320",
    "end": "902720"
  },
  {
    "text": "this is the custom llm and the open Ai llm and we write the data back to the",
    "start": "902720",
    "end": "907759"
  },
  {
    "text": "store which is shown in the UI the Argo CD Numa proa system we also have a",
    "start": "907759",
    "end": "913480"
  },
  {
    "text": "training pipeline which gathers this data and find Tunes based on um few",
    "start": "913480",
    "end": "918839"
  },
  {
    "text": "intervals and how the organic patterns are changing based on the",
    "start": "918839",
    "end": "924720"
  },
  {
    "text": "traffic now let's take a pause here because what you seen here right is a",
    "start": "924720",
    "end": "931000"
  },
  {
    "text": "very Advanced platform at indid we use uh we use The Cutting Edge Technologies",
    "start": "931000",
    "end": "936880"
  },
  {
    "text": "and we have for example we have an very scalable operational data platform we",
    "start": "936880",
    "end": "942279"
  },
  {
    "text": "use AI Ops to make decisions we use Argo rollouts for Progressive delivery and",
    "start": "942279",
    "end": "947319"
  },
  {
    "text": "even llm being integrated so the natural question that comes is did you guys",
    "start": "947319",
    "end": "953720"
  },
  {
    "text": "really have to boil the ocean to get to place where we are right and um answer answer would be no we didn't have to",
    "start": "953720",
    "end": "960360"
  },
  {
    "text": "right and then what what is that we did right the key thing we did was from the",
    "start": "960360",
    "end": "965680"
  },
  {
    "text": "very beginning we made sure that we are able to stream data in and able to do",
    "start": "965680",
    "end": "972079"
  },
  {
    "text": "stream processing in a very um very large scale manner the key thing that",
    "start": "972079",
    "end": "978240"
  },
  {
    "text": "when when somebody talks about stream stream processing or uh real time processing the uh is mostly related to",
    "start": "978240",
    "end": "986160"
  },
  {
    "text": "first thing that comes to mind is data Engineers for working on fling or spark on Java codebase and that meaning that there's a",
    "start": "986160",
    "end": "994040"
  },
  {
    "text": "perception that it's only for data Engineers streaming is accessible and we wanted to change that we wanted to make",
    "start": "994040",
    "end": "1000000"
  },
  {
    "text": "sure streaming is for everyone application developers ml Engineers devops SRS product managers",
    "start": "1000000",
    "end": "1006279"
  },
  {
    "text": "even so the key thing is we have to make streaming easy for everyone right you you should be able to use streaming in 5",
    "start": "1006279",
    "end": "1012360"
  },
  {
    "text": "minutes learn it and continue so the rest part of the talk is how do we do that at in it at scale and that that's",
    "start": "1012360",
    "end": "1018720"
  },
  {
    "text": "where we the open source new approach come into play and the rest of the talk I'll walk you through how do we do",
    "start": "1018720",
    "end": "1024678"
  },
  {
    "text": "streaming at IND it and how how it is easy to do streaming for everyone so what does numo include right",
    "start": "1024679",
    "end": "1032280"
  },
  {
    "text": "so numo is a collection of kubernetes native open source language agnostic realtime data analytics tools it has",
    "start": "1032280",
    "end": "1039400"
  },
  {
    "text": "three main components first is Numa flow that is massively parall real-time data processing platform this is the where",
    "start": "1039400",
    "end": "1045280"
  },
  {
    "text": "the data movement happens Numa logic is a collection of ml models that we have been using for a couple of years and for",
    "start": "1045280",
    "end": "1053440"
  },
  {
    "text": "realtime operational data and lastly is about control plane on how do you manage",
    "start": "1053440",
    "end": "1058640"
  },
  {
    "text": "these resources for this talk we'll just sck on to Numa flow because it itself is a",
    "start": "1058640",
    "end": "1064320"
  },
  {
    "text": "big topic so again what is Numa flow right is a massively parallel data processing",
    "start": "1064320",
    "end": "1069520"
  },
  {
    "text": "engine this is where the data movement happens right and it's built with three core philosophies first is is very",
    "start": "1069520",
    "end": "1075360"
  },
  {
    "text": "native to kubernetes that means that if you you WR have a specification it should be able to run on edge on Prem on",
    "start": "1075360",
    "end": "1082799"
  },
  {
    "text": "the cloud with e same specification you don't have to change anything second is the most important one that is it should",
    "start": "1082799",
    "end": "1089120"
  },
  {
    "text": "be very easy to use meaning you can write it in any language you like it should be is very easy to adopt and",
    "start": "1089120",
    "end": "1096000"
  },
  {
    "text": "lastly scale and cost efficient it can Auto scale all the way to zero and zero to many and at our deployment at IND it",
    "start": "1096000",
    "end": "1103240"
  },
  {
    "text": "we found out that it is 30% more cheaper than the Java equivalent versions like Flingo",
    "start": "1103240",
    "end": "1109960"
  },
  {
    "text": "spark we are also creators of Argo as you know and the community has been asking from Argo work standpoint that",
    "start": "1109960",
    "end": "1116600"
  },
  {
    "text": "hey if Argo workflow is for batch what is the streaming equalent of it and",
    "start": "1116600",
    "end": "1121799"
  },
  {
    "text": "that's the Numa one way to see Numa is the streaming equivalent of Argo workflows and we fixed few things Argo",
    "start": "1121799",
    "end": "1129760"
  },
  {
    "text": "had problems with for example there's lot of Port churn in Argo any event you create a port you churn out lot of ports",
    "start": "1129760",
    "end": "1136360"
  },
  {
    "text": "you fragment your R CD these are big problems at scale because coming like into it we have lots of workflow running",
    "start": "1136360",
    "end": "1143480"
  },
  {
    "text": "right so we wanted to make sure those problems also get fixed in Numa hence we don't have those kind of HD",
    "start": "1143480",
    "end": "1149400"
  },
  {
    "text": "fragmentation or mutating the state or anything like that now I have been talking about a",
    "start": "1149400",
    "end": "1156159"
  },
  {
    "text": "pipeline what really is a pipeline pipeline is you can think about you are reading from somewhere that is",
    "start": "1156159",
    "end": "1162720"
  },
  {
    "text": "the source you read from you do something to it some kind of transformation some user defined",
    "start": "1162720",
    "end": "1168320"
  },
  {
    "text": "function it could be anything then you write it out somewhere there is a destination for this message right this",
    "start": "1168320",
    "end": "1174200"
  },
  {
    "text": "is the simplest new pipeline you can iment you are reading doing something writing it out now let me walk you",
    "start": "1174200",
    "end": "1180600"
  },
  {
    "text": "through one use case one example as a demo and for that let me so numl comes",
    "start": "1180600",
    "end": "1186840"
  },
  {
    "text": "with lot of in builds okay they Kafka HTTP so let's talk about a use case where you are reading from HTTP and you",
    "start": "1186840",
    "end": "1192919"
  },
  {
    "text": "are writing to a log you're just writing it out and we will use a hugging phe",
    "start": "1192919",
    "end": "1198280"
  },
  {
    "text": "model to do something called a Sentimental analytics sentimental analytics meaning I send in some sentence and it will send say whether",
    "start": "1198280",
    "end": "1205240"
  },
  {
    "text": "it's a positive or A negative sentiment so I will demo this before I demo this",
    "start": "1205240",
    "end": "1210799"
  },
  {
    "text": "the first question is how easy is to write a UDF so if you see here this is all you have to do meaning you have a",
    "start": "1210799",
    "end": "1217039"
  },
  {
    "text": "Handler this is a python code it could be any code you are given an input and you had",
    "start": "1217039",
    "end": "1222280"
  },
  {
    "text": "to return an output if you look at this code it does not say there is any streaming aspect to it it doesn't not",
    "start": "1222280",
    "end": "1228360"
  },
  {
    "text": "talk about rate R it does not talk about anything else right it's all about you are given an input all you need to do is",
    "start": "1228360",
    "end": "1234320"
  },
  {
    "text": "create an output we will make sure that there a guarantee the platform provides that the",
    "start": "1234320",
    "end": "1240000"
  },
  {
    "text": "message will be for uh exactly once forwarded retri are taken care of and um",
    "start": "1240000",
    "end": "1247320"
  },
  {
    "text": "Auto scaling is taken care of we understand the streaming semantics where back pressure and so forth so from a",
    "start": "1247320",
    "end": "1253200"
  },
  {
    "text": "user all you need to do is give this Handler this simple piece of code and you can replace with anything you can uh",
    "start": "1253200",
    "end": "1259320"
  },
  {
    "text": "think about now this is the kuet CR for the same pipeline so the way it is is it's",
    "start": "1259320",
    "end": "1265679"
  },
  {
    "text": "nothing but a graph you have set of vertices you have a source inference and a sync and then you have an edge that",
    "start": "1265679",
    "end": "1271919"
  },
  {
    "text": "connects between sources your user defined function and your sing so this makes a graph now let me show you demo",
    "start": "1271919",
    "end": "1279600"
  },
  {
    "text": "this is a real one let me find the okay so this is the",
    "start": "1279600",
    "end": "1284880"
  },
  {
    "text": "cool UAV built uh is uh this is cluster summary I'm just showing it from the",
    "start": "1284880",
    "end": "1290039"
  },
  {
    "text": "local uh what you're seeing is the name spaces we have and the pipelines that's",
    "start": "1290039",
    "end": "1295559"
  },
  {
    "text": "running so in this case I already deployed the sentiment analytics model because it's a large one it takes a",
    "start": "1295559",
    "end": "1300919"
  },
  {
    "text": "while to download but it's very easy to create a pipeline you click here you can say hey input cat and if I say submit it",
    "start": "1300919",
    "end": "1308799"
  },
  {
    "text": "will create a pipeline so it's easy you can do all the C operations from the UI itself and we have our back using GitHub",
    "start": "1308799",
    "end": "1314559"
  },
  {
    "text": "and things like that now coming back to the sentimental pipeline if you look at the presentation it's the same slide",
    "start": "1314559",
    "end": "1320919"
  },
  {
    "text": "right you have input inference so it's very explainable by itself and what I'm going to do is I'm",
    "start": "1320919",
    "end": "1326960"
  },
  {
    "text": "going to write some data to input and I'm hoping that output will come okay now let's send a",
    "start": "1326960",
    "end": "1336799"
  },
  {
    "text": "sentence basically what I'm going to write is writing documentation is like trying to explain quantum physics to a",
    "start": "1337440",
    "end": "1343679"
  },
  {
    "text": "todler I send the data I go to4 and if you see the output is here",
    "start": "1343679",
    "end": "1349480"
  },
  {
    "text": "right and it says clearly it's a negative sentiment right it's like how difficult is to write the document now",
    "start": "1349480",
    "end": "1355760"
  },
  {
    "text": "let me send something that sounds better uh kubernetes is like the ultimate wingman always there to support your",
    "start": "1355760",
    "end": "1362880"
  },
  {
    "text": "app I send it it should be there it's a positive sentiment so if you think and",
    "start": "1362880",
    "end": "1368120"
  },
  {
    "text": "think about right the example is very simple but what if your input was a slack web hook and you made a product",
    "start": "1368120",
    "end": "1373600"
  },
  {
    "text": "release and you are just passing it through in fact this was a product manager use case he did it during a hack",
    "start": "1373600",
    "end": "1379400"
  },
  {
    "text": "day so you can imagine how this simple it is right and this code by the way is open sourced you can take a look into it",
    "start": "1379400",
    "end": "1385679"
  },
  {
    "text": "and it's very simple to see and I wasn't lying about the code it's very small right um so that is all about this",
    "start": "1385679",
    "end": "1393640"
  },
  {
    "text": "demo let me get back to slides",
    "start": "1393640",
    "end": "1397520"
  },
  {
    "text": "again now I showed you a simple one it does not mean numl cannot do complex things it comes in different shapes and",
    "start": "1402080",
    "end": "1408559"
  },
  {
    "text": "size you could do multisource for example you can do join operations on",
    "start": "1408559",
    "end": "1414039"
  },
  {
    "text": "sings you could do join on udfs and merging on",
    "start": "1414039",
    "end": "1419159"
  },
  {
    "text": "udfs since Numa flow is more like a fire and forget because it can autoscale it",
    "start": "1419159",
    "end": "1424480"
  },
  {
    "text": "knows node migration pod migration so mostly at indid we do it in a fire and forget mode that meaning how do you Auto",
    "start": "1424480",
    "end": "1431799"
  },
  {
    "text": "reconfigure pipeline at run time so we support something called side input which can broadcast messages and Recon",
    "start": "1431799",
    "end": "1438840"
  },
  {
    "text": "configure itself and lastly it can even support Cycles so that uh meaning for",
    "start": "1438840",
    "end": "1445279"
  },
  {
    "text": "example you read some message and you thought okay let me reprocess the same message with additional context so and",
    "start": "1445279",
    "end": "1450600"
  },
  {
    "text": "there are much more but these are the key ones now let me talk about few use cases",
    "start": "1450600",
    "end": "1457640"
  },
  {
    "text": "what the community and at in it we use using Numa flow right first is streaming analytics that is number crunching you",
    "start": "1457640",
    "end": "1464600"
  },
  {
    "text": "have data that is coming in you saw observability video golden signals how do you comp compute availability how do",
    "start": "1464600",
    "end": "1470559"
  },
  {
    "text": "you detect errors and so forth the streaming analytics the melops and ml inference is something the numo proo",
    "start": "1470559",
    "end": "1475840"
  },
  {
    "text": "assist was doing earlier and also anomaly detection and lastly we people also use for event driven uh application",
    "start": "1475840",
    "end": "1483360"
  },
  {
    "text": "you can relate this more like streaming Argo workflows where you get an event",
    "start": "1483360",
    "end": "1489039"
  },
  {
    "text": "that could be metadata to other things and you do some processing with this I will hand it over to Amit to talk about",
    "start": "1489039",
    "end": "1495600"
  },
  {
    "text": "few success stories thank you vjit so we wanted to walk you",
    "start": "1495600",
    "end": "1500960"
  },
  {
    "text": "guys through some of the success stories so that you can get an idea where you can use Nea flow first is the streaming",
    "start": "1500960",
    "end": "1508440"
  },
  {
    "text": "analytics uh I mentioned golden signals when we talk about operational excellence uh so golden signal pipelines",
    "start": "1508440",
    "end": "1514799"
  },
  {
    "text": "at into it use Nea flow some of the features which I wanted to highlight it's multilanguage so it's written both",
    "start": "1514799",
    "end": "1521520"
  },
  {
    "text": "Java and go and most important to me it's like 30% efficient than equivalent",
    "start": "1521520",
    "end": "1526679"
  },
  {
    "text": "fling job which we were running the second is a community uh example uh",
    "start": "1526679",
    "end": "1532360"
  },
  {
    "text": "where uh bcbe is using it for digital signal processing they use it the same",
    "start": "1532360",
    "end": "1538440"
  },
  {
    "text": "pipeline in on Prem on it on in the cloud as well as on the edge so the",
    "start": "1538440",
    "end": "1545960"
  },
  {
    "text": "footprint of Puma flow is such small that you can run it on any Edge device we have successfully run it even on a",
    "start": "1545960",
    "end": "1551480"
  },
  {
    "text": "Rasberry P the Second Use cases is mlops we talked about Numa project assist some of",
    "start": "1551480",
    "end": "1559039"
  },
  {
    "text": "the highlights there is you can use it for in-cluster analytics AI Ops you can use it for llm both for training",
    "start": "1559039",
    "end": "1566679"
  },
  {
    "text": "creating the training data sets doing AB testing and other use cases in mlfs is",
    "start": "1566679",
    "end": "1573559"
  },
  {
    "text": "anomal detection that's most widely used in into it uh any time series data any",
    "start": "1573559",
    "end": "1579720"
  },
  {
    "text": "developer can use it to generate anomal again it's a DIY it's simple to use so",
    "start": "1579720",
    "end": "1585679"
  },
  {
    "text": "it's you don't need to be a data engineer ml engineer to do this and the last set of use cases is event driven uh",
    "start": "1585679",
    "end": "1592840"
  },
  {
    "text": "first is the metadata service we get lot of data from our cloud provider and we",
    "start": "1592840",
    "end": "1598360"
  },
  {
    "text": "want to process it as soon as possible so the feature here is the scalability we go from zero to hundreds of wats uh",
    "start": "1598360",
    "end": "1606240"
  },
  {
    "text": "do it uh process it and then again go back to zero again for metadata service",
    "start": "1606240",
    "end": "1611520"
  },
  {
    "text": "it's almost 90% efficient cost efficient than the equivalent Lambda we used to run and the last last but not the least",
    "start": "1611520",
    "end": "1619080"
  },
  {
    "text": "success story is one of the largest uh automotive company it's using it for",
    "start": "1619080",
    "end": "1624520"
  },
  {
    "text": "real-time map processing so you can think of it's running on an edge uh it",
    "start": "1624520",
    "end": "1629880"
  },
  {
    "text": "scales up it's always reliable uh because you your navigation depends on that and I think one of the quotes they",
    "start": "1629880",
    "end": "1636240"
  },
  {
    "text": "had is fire and forget because they they run it for months without even touching touching that so again the idea behind",
    "start": "1636240",
    "end": "1642559"
  },
  {
    "text": "this is to give you guys an idea how you guys can use it uh this is our",
    "start": "1642559",
    "end": "1648039"
  },
  {
    "text": "QR code you can go to GitHub the demos you saw are available for you guys to download everything is open sourced uh",
    "start": "1648039",
    "end": "1655279"
  },
  {
    "text": "you will see other examples other documentations blocks there and also if you like it please go ahead and start",
    "start": "1655279",
    "end": "1661159"
  },
  {
    "text": "start the report that's how your community works so thank [Applause]",
    "start": "1661159",
    "end": "1673630"
  },
  {
    "text": "you next talk can you uh elaborate more about the an anomaly detection part sure",
    "start": "1676519",
    "end": "1684559"
  },
  {
    "text": "uh does that require uh each application developer to Define their own SLO or you",
    "start": "1684559",
    "end": "1690240"
  },
  {
    "text": "have a unified algorithm in PL form level to do the all the golden signal",
    "start": "1690240",
    "end": "1695840"
  },
  {
    "text": "anomal detection yeah so so if I got the question correct first was how do we do anomal detection right so our anomal",
    "start": "1695840",
    "end": "1702679"
  },
  {
    "text": "detection is based on we look at the application Run State and compare it with how it is performing now so it's an",
    "start": "1702679",
    "end": "1709960"
  },
  {
    "text": "auto encoder which we use we have somewh on based on 10 uh inputs uh a sliding",
    "start": "1709960",
    "end": "1716399"
  },
  {
    "text": "window of 10 but the key thing is that we look at the current pattern and compare with the historical pattern and",
    "start": "1716399",
    "end": "1723720"
  },
  {
    "text": "so it can understand um time of the day week or week and so forth and it but we",
    "start": "1723720",
    "end": "1729760"
  },
  {
    "text": "avoid the cold start problem meaning we start with just 180 inputs meaning 180",
    "start": "1729760",
    "end": "1735000"
  },
  {
    "text": "minutes that's around uh less than and 3 hours up to 3 hours and we are able to scale an anomaly score so we do not have",
    "start": "1735000",
    "end": "1741600"
  },
  {
    "text": "a cold start problem and we go up till like last 10 days so we compare that and give an anomaly score the output is",
    "start": "1741600",
    "end": "1747600"
  },
  {
    "text": "normalized anybody at in will say what the value five mean meaning five is a medium level anomaly 10 meaning is",
    "start": "1747600",
    "end": "1754679"
  },
  {
    "text": "completely anomalous right so that's how we standard standardized it what was the",
    "start": "1754679",
    "end": "1760039"
  },
  {
    "text": "second question I sorry you had two questions right uh just this this one",
    "start": "1760039",
    "end": "1765360"
  },
  {
    "text": "yeah thank you really nice talk uh I had a question",
    "start": "1765360",
    "end": "1770519"
  },
  {
    "text": "around uh realtime incident analysis using Ai and mlops uh do you guys really",
    "start": "1770519",
    "end": "1776919"
  },
  {
    "text": "do that say for example you have a payment platform that you're connected to and the there's an issue with the",
    "start": "1776919",
    "end": "1783120"
  },
  {
    "text": "payment platform uh how do you detect that uh in inside of uh your",
    "start": "1783120",
    "end": "1789159"
  },
  {
    "text": "infrastructure so how do you detect so you remember Amit talking about failed",
    "start": "1789159",
    "end": "1794320"
  },
  {
    "text": "customer interaction for example you have a w to upload that is failing and how do we come to know about it right so",
    "start": "1794320",
    "end": "1801159"
  },
  {
    "text": "the way it happens is let me show you a real the beauty of this is that our UI",
    "start": "1801159",
    "end": "1806399"
  },
  {
    "text": "is um if the it loads ISS yeah there you go",
    "start": "1806399",
    "end": "1813039"
  },
  {
    "text": "so what happens is this is the pipeline right so we get data from Kafka all the",
    "start": "1813039",
    "end": "1818919"
  },
  {
    "text": "time let's say every interaction there are hundreds of interaction thousands of interaction happening and we do",
    "start": "1818919",
    "end": "1825399"
  },
  {
    "text": "inference this is where we infer that data saying that based on the current input whether the current scenario is",
    "start": "1825399",
    "end": "1831159"
  },
  {
    "text": "anomalous and then we pre postprocess this is where we normalize it and we say",
    "start": "1831159",
    "end": "1836519"
  },
  {
    "text": "that okay this is an anomaly and we send it to all our s for example we send it to CF for further analytics we send it",
    "start": "1836519",
    "end": "1843120"
  },
  {
    "text": "for alerting and also we do we do training on the fight because this is a zero configuration system meaning if a",
    "start": "1843120",
    "end": "1850080"
  },
  {
    "text": "new interaction comes up we will understand that okay this is something new we don't have a model for it and we",
    "start": "1850080",
    "end": "1856600"
  },
  {
    "text": "do a own online training for that so this is how we use Numa approach the key thing here if you see right Numa flow is",
    "start": "1856600",
    "end": "1862559"
  },
  {
    "text": "that you can do all this in a single Pipeline and this is a production pipeline that actually does the anomal detection and the output of this create",
    "start": "1862559",
    "end": "1869679"
  },
  {
    "text": "incidents now to tie it back if it is a score greater than three it's an incident fire that into it and do you",
    "start": "1869679",
    "end": "1876320"
  },
  {
    "text": "have automatic recovery mttr is a tricky bit that's where Amit was talking about is we have",
    "start": "1876320",
    "end": "1883480"
  },
  {
    "text": "like resiliency like multi- region deployments we we for example the change and everything we Auto roll back but it",
    "start": "1883480",
    "end": "1891320"
  },
  {
    "text": "is not a fullprof complete solution and some of them you really have to debug but we do give power to isolate meaning",
    "start": "1891320",
    "end": "1898480"
  },
  {
    "text": "you can actually see what is going wrong to an extent and we do me meantime to isolate but the some bits of mttr is not",
    "start": "1898480",
    "end": "1904919"
  },
  {
    "text": "automated thank you thank you thank",
    "start": "1904919",
    "end": "1910799"
  },
  {
    "text": "you you sure are",
    "start": "1913480",
    "end": "1919159"
  },
  {
    "text": "in envir for yes for changes yes for changes we use Progressive delivery and",
    "start": "1922639",
    "end": "1928080"
  },
  {
    "text": "it automatically rolls back so we use Numa Pro as well as Argo",
    "start": "1928080",
    "end": "1934200"
  },
  {
    "text": "CD Argo rollouts so both are open source product Argo CD and Argo rollouts is used for deployment at in and we use",
    "start": "1934200",
    "end": "1942039"
  },
  {
    "text": "Progressive delivery and the the talk as we discussed based on the Rive delivery",
    "start": "1942039",
    "end": "1947679"
  },
  {
    "text": "if there is an anomaly we roll it",
    "start": "1947679",
    "end": "1951158"
  },
  {
    "text": "back just just to summarize we do not use llm for um mathematical use cases",
    "start": "1960480",
    "end": "1967919"
  },
  {
    "text": "here we use Auto encoders for anomaly detection if you are",
    "start": "1967919",
    "end": "1973398"
  },
  {
    "text": "curious cool thank you",
    "start": "1976039",
    "end": "1982050"
  },
  {
    "text": "[Applause]",
    "start": "1982050",
    "end": "1987829"
  },
  {
    "text": "you one one quick one what's the preferred kind of tendency for Numa flow",
    "start": "1989120",
    "end": "1994760"
  },
  {
    "text": "or is it similar to what you would do with Argo workflows where you can run run per cluster or is it more of a kind",
    "start": "1994760",
    "end": "2001559"
  },
  {
    "text": "of roll your own peram space sort of situation yes today it is uh just Within",
    "start": "2001559",
    "end": "2007200"
  },
  {
    "text": "cluster but uh There It Is Nothing is Stopping Us doing multi cluster because all one of the edge could be on another",
    "start": "2007200",
    "end": "2013200"
  },
  {
    "text": "cluster Nothing is Stopping Us as of today but at into it we do single",
    "start": "2013200",
    "end": "2018360"
  },
  {
    "text": "cluster and single name space thank you you're",
    "start": "2018360",
    "end": "2024158"
  },
  {
    "text": "welcome thank",
    "start": "2025960",
    "end": "2029200"
  },
  {
    "text": "you",
    "start": "2032760",
    "end": "2035760"
  }
]
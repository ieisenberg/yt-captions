[
  {
    "text": "well hi everyone my name is yi i'm an engineer from tencap today i'm going to give the",
    "start": "80",
    "end": "6240"
  },
  {
    "text": "presentation a serving cheating record table on thai tv",
    "start": "6240",
    "end": "11360"
  },
  {
    "text": "so in this presentation i will talk about what thai kb is and shows the overview of architecture",
    "start": "11360",
    "end": "18720"
  },
  {
    "text": "of pacquiao and i out then showed introduced the childhood use case",
    "start": "18720",
    "end": "24800"
  },
  {
    "text": "which is the largest thai kv cluster that we aware of we'll talk about zircon's use",
    "start": "24800",
    "end": "30800"
  },
  {
    "text": "case for storing the reading history data in integrity and also",
    "start": "30800",
    "end": "36000"
  },
  {
    "text": "their next generation for the infrastructure for the same use case which is the data table spot and after",
    "start": "36000",
    "end": "42879"
  },
  {
    "text": "that i'll talk about two features that uh that have been useful for the turbo's use case which is",
    "start": "42879",
    "end": "48239"
  },
  {
    "text": "the transaction and followery and and that's it and so uh first what is thai kv",
    "start": "48239",
    "end": "56800"
  },
  {
    "text": "technique is a distributed transactional keyword database that was originally",
    "start": "56800",
    "end": "62239"
  },
  {
    "text": "created at paincap as the underlying storage layer for thai db and although usually used together with",
    "start": "62239",
    "end": "69680"
  },
  {
    "text": "idb techie can be used as a standalone key value database and the design of thai tv is inspired by",
    "start": "69680",
    "end": "77840"
  },
  {
    "text": "google spanner and hbase but it is simpler to manage and it does not depend on the any",
    "start": "77840",
    "end": "84880"
  },
  {
    "text": "distributed file system the project is right now a cnc cf",
    "start": "84880",
    "end": "90240"
  },
  {
    "text": "incubating project and we are trying to move this attackery to graduation stage this year uh",
    "start": "90240",
    "end": "97200"
  },
  {
    "text": "takeaway has over thousand github stars and it's right now have uh around",
    "start": "97200",
    "end": "104159"
  },
  {
    "text": "250 contributors so our titanic provides a simple key",
    "start": "104159",
    "end": "111119"
  },
  {
    "text": "value api but is also able to provide a horizontal scalability which means that uh whenever",
    "start": "111119",
    "end": "119040"
  },
  {
    "text": "you want to scale up the type cluster you can simply add machines to the cluster",
    "start": "119040",
    "end": "124560"
  },
  {
    "text": "and the cluster will auto scale out without you worrying about doing a resharing to your data and also",
    "start": "124560",
    "end": "131280"
  },
  {
    "text": "um attacking we offer the high availability thanks to the underlying replication and",
    "start": "131280",
    "end": "137360"
  },
  {
    "text": "also taking natively supposed transaction this is a picture showing the overall",
    "start": "137360",
    "end": "144800"
  },
  {
    "text": "architecture of thai kv in the front end uh tyqui provides a simple transactional kv api",
    "start": "144800",
    "end": "153280"
  },
  {
    "text": "it also exposes the co-processor api which handles push-down",
    "start": "153280",
    "end": "158800"
  },
  {
    "text": "aggregation requests from time db it has a transaction layer which handles",
    "start": "158800",
    "end": "165040"
  },
  {
    "text": "distributed transaction and multi-version concurrency control it used rough to replicate data and it",
    "start": "165040",
    "end": "173120"
  },
  {
    "text": "used rocksdb to as the underlying storage engine and we are also working on making the storage",
    "start": "173120",
    "end": "179120"
  },
  {
    "text": "engine pluggable so in the future we may be able to use other types of storage engines and this picture shows",
    "start": "179120",
    "end": "187440"
  },
  {
    "text": "how data is organized inside a typical cluster the full key range is split into small",
    "start": "187440",
    "end": "195200"
  },
  {
    "text": "areas and each of this area it we call it a region and the region is",
    "start": "195200",
    "end": "201440"
  },
  {
    "text": "the yield need for a rough replication in taipei and by default each region will",
    "start": "201440",
    "end": "207519"
  },
  {
    "text": "have three replicas and those replicas will be scattered around in different types of windows",
    "start": "207519",
    "end": "213599"
  },
  {
    "text": "and when the world changes some of the regions can get more traffic than the other region",
    "start": "213599",
    "end": "219040"
  },
  {
    "text": "and some regions can grow oversized and taike will rely on another component",
    "start": "219040",
    "end": "225599"
  },
  {
    "text": "to do load balance which is the placement driver or pd the pv cluster",
    "start": "225599",
    "end": "232560"
  },
  {
    "text": "will basically stores the metadata for the reach all the regions and it also monitors the workload and",
    "start": "232560",
    "end": "239519"
  },
  {
    "text": "the data size of each of the region and if needed it will instruct height v",
    "start": "239519",
    "end": "244560"
  },
  {
    "text": "nodes to move the regions around move the leaders of the regions around",
    "start": "244560",
    "end": "250959"
  },
  {
    "text": "and also split or merge some of the regions",
    "start": "250959",
    "end": "255840"
  },
  {
    "text": "this is the rough timeline for thai kv development and it was first graded on 2015",
    "start": "256079",
    "end": "262880"
  },
  {
    "text": "as a storage layer for thai db and one year later we open source it on uh 2018 taiki whip enters cncf",
    "start": "262880",
    "end": "270960"
  },
  {
    "text": "as a sandbox project and then become an incubator project and this year we released the fourth",
    "start": "270960",
    "end": "277120"
  },
  {
    "text": "major release of thai killing now let's take a look at zoho's use case",
    "start": "277120",
    "end": "283120"
  },
  {
    "text": "which is the currently the largest thai giveaway deployment we know of uh so juhoo is the chinese question and",
    "start": "283120",
    "end": "290080"
  },
  {
    "text": "answer website and you can think of it as quora and the website is really popular in china",
    "start": "290080",
    "end": "295520"
  },
  {
    "text": "and zhuhu is using a thai tv to store the reading history of the users on the",
    "start": "295520",
    "end": "301600"
  },
  {
    "text": "website and this is the dashboard snapshot of the dashboard",
    "start": "301600",
    "end": "306720"
  },
  {
    "text": "of the thai kv cluster in this use case uh as you can see the um the data size is",
    "start": "306720",
    "end": "313039"
  },
  {
    "text": "really huge is currently having a 500 tech by data and the insights is still growing and",
    "start": "313039",
    "end": "319199"
  },
  {
    "text": "the cluster has over 200 type nodes about the use case uh the reading",
    "start": "319199",
    "end": "325680"
  },
  {
    "text": "history of the users is used to filter the recommendations so a user won't see",
    "start": "325680",
    "end": "330720"
  },
  {
    "text": "an article that he already reappeared in the recommendation list",
    "start": "330720",
    "end": "336720"
  },
  {
    "text": "and also the uh the data is used to change models to personalize the recommendation to the",
    "start": "336720",
    "end": "342400"
  },
  {
    "text": "users the data set is currently having a 2.5 shilling record so far and the data",
    "start": "342400",
    "end": "348080"
  },
  {
    "text": "set is still growing due to the fast growing user base of obstacle and growing user activities while having a large",
    "start": "348080",
    "end": "356560"
  },
  {
    "text": "data set the cluster also needs to handle a large volume of read and write operations and",
    "start": "356560",
    "end": "364080"
  },
  {
    "text": "during peak time the classic the cluster can have around 200 000 records per second right",
    "start": "364080",
    "end": "371919"
  },
  {
    "text": "and the cluster also normally have uh 150 000 queries per second for risk",
    "start": "371919",
    "end": "378800"
  },
  {
    "text": "and under this rear and right pressure the cluster is able to achieve a p 99.9 latency of",
    "start": "378800",
    "end": "386400"
  },
  {
    "text": "around 100 milliseconds this is the overall architecture for the",
    "start": "386400",
    "end": "392319"
  },
  {
    "text": "use case at the very front end the cherry has a proxy layer and then there is the reddish cache",
    "start": "392319",
    "end": "398560"
  },
  {
    "text": "layer that handles the large volume of reach effect the cache is the right root cache the",
    "start": "398560",
    "end": "404720"
  },
  {
    "text": "right will hit the underlying database which is tidbit and tidbit used high kv",
    "start": "404720",
    "end": "409759"
  },
  {
    "text": "as the underlying storage layer and the cache layer also uh subscribe to tidbit changes",
    "start": "409759",
    "end": "416080"
  },
  {
    "text": "we uh type idb bin log to achieve eventual consistency before using thai",
    "start": "416080",
    "end": "423280"
  },
  {
    "text": "db and thai theory who used to use a mysql and to store the reading history data",
    "start": "423280",
    "end": "430000"
  },
  {
    "text": "and as the data grows larger and larger it needs to restart the data from time time",
    "start": "430000",
    "end": "436639"
  },
  {
    "text": "which is a heavy operation for them and after they switch to use idp and tightly",
    "start": "436639",
    "end": "443280"
  },
  {
    "text": "when the data grows what they do is simply add more holes to the cluster",
    "start": "443280",
    "end": "449039"
  },
  {
    "text": "and the cluster can automatically scale up and so the so so so it's easier for them to handle the",
    "start": "449039",
    "end": "456720"
  },
  {
    "text": "increasing workload and the uh and the data size and also when a target server is done they see",
    "start": "456720",
    "end": "464639"
  },
  {
    "text": "nearly no impact to the overall healthiness of the use case due to the high availability provided by",
    "start": "464639",
    "end": "472960"
  },
  {
    "text": "hiv and also as the the the data",
    "start": "472960",
    "end": "478319"
  },
  {
    "text": "size growth um who also moved to use the cross cloud provider deployment",
    "start": "478319",
    "end": "483520"
  },
  {
    "text": "and during this transition uh tachyv is being very stable for them so",
    "start": "483520",
    "end": "490319"
  },
  {
    "text": "they are currently very happy with target v in in in the reading history use case",
    "start": "490319",
    "end": "498479"
  },
  {
    "text": "but as they add more use case to their system they want to expand the feature",
    "start": "498479",
    "end": "504160"
  },
  {
    "text": "set so they are building a next generation infrastructure for the same use case this",
    "start": "504160",
    "end": "512000"
  },
  {
    "text": "this new infrastructure is called a data table store this the data table store is still based",
    "start": "512000",
    "end": "519200"
  },
  {
    "text": "on high qv and from the tiger dashboard of this cluster and you can see the data size is right now",
    "start": "519200",
    "end": "524560"
  },
  {
    "text": "at around 70 megabytes and it consists of around 100 tech windows and the data",
    "start": "524560",
    "end": "531200"
  },
  {
    "text": "side the data table store is right now basically storing the same set of data as the",
    "start": "531200",
    "end": "537680"
  },
  {
    "text": "reading history cluster but the data size is uh several times smaller",
    "start": "537680",
    "end": "542720"
  },
  {
    "text": "due to some due to the some clever optimization on the application side to",
    "start": "542720",
    "end": "548640"
  },
  {
    "text": "reduce redundant data data table store provide features a",
    "start": "548640",
    "end": "554320"
  },
  {
    "text": "no sql api and it provides a transaction and secondary index support it provides",
    "start": "554320",
    "end": "560640"
  },
  {
    "text": "a negative y column data model and the data in it can be can have schema or be schema",
    "start": "560640",
    "end": "566720"
  },
  {
    "text": "free and most importantly uh the data level store is still based on high quality",
    "start": "566720",
    "end": "572880"
  },
  {
    "text": "so who can still enjoy the availability and scalability provided by thai dairy and",
    "start": "572880",
    "end": "579680"
  },
  {
    "text": "also they make use of some of the typical features for example the transaction and secondary index support are all based on",
    "start": "579680",
    "end": "585680"
  },
  {
    "text": "high-grade transactions now this is the overall architecture of",
    "start": "585680",
    "end": "591279"
  },
  {
    "text": "the data table store we won't go into detail here but as you can see technique is still being used as the",
    "start": "591279",
    "end": "597600"
  },
  {
    "text": "storage layer and most of the other nodes are statics and this is a demonstration of the",
    "start": "597600",
    "end": "605920"
  },
  {
    "text": "y column data model provided by table store and as juju switched",
    "start": "605920",
    "end": "612640"
  },
  {
    "text": "their traffic from the existing reading history cluster to the new newer data table saw",
    "start": "612640",
    "end": "619120"
  },
  {
    "text": "they also plan to add more features to their system including a multiple protocol support",
    "start": "619120",
    "end": "624959"
  },
  {
    "text": "optional relaxed consistency level and also they plan to build big data connector and would have such",
    "start": "624959",
    "end": "630640"
  },
  {
    "text": "a capacity and for the last two items they um they plan to have those systems uh",
    "start": "630640",
    "end": "636399"
  },
  {
    "text": "integrate with the type cluster on the replication level and we'll talk about",
    "start": "636399",
    "end": "643200"
  },
  {
    "text": "that in a bit let's talk about a transaction in a in",
    "start": "643200",
    "end": "648880"
  },
  {
    "text": "tactical which a transaction is proved to be very useful for the um for",
    "start": "648880",
    "end": "654000"
  },
  {
    "text": "the uh service use case it simplify the the application logic they don't need to",
    "start": "654000",
    "end": "659040"
  },
  {
    "text": "re-implement transaction in their application layer so",
    "start": "659040",
    "end": "664480"
  },
  {
    "text": "to have transaction because data in thai tv are split into small regions",
    "start": "664480",
    "end": "671600"
  },
  {
    "text": "and those rough leaders for each of the regions can be on different types of nodes",
    "start": "671600",
    "end": "676880"
  },
  {
    "text": "so to run a transaction we need to do a distributed transaction over",
    "start": "676880",
    "end": "682560"
  },
  {
    "text": "multiple rough groups and this is done entirely using the percolator model",
    "start": "682560",
    "end": "688640"
  },
  {
    "text": "the poc later model is described in the google calculator paper and we use it to support both automatic",
    "start": "688640",
    "end": "696399"
  },
  {
    "text": "optimistic transaction and persimisic transaction",
    "start": "696399",
    "end": "701040"
  },
  {
    "text": "this is an example of the percolator model it is basically a two phase coming protocol and in this",
    "start": "701760",
    "end": "709680"
  },
  {
    "text": "model all the data are split into three columns the data column the log column and the right column and in titley we",
    "start": "709680",
    "end": "717040"
  },
  {
    "text": "use logsdb's column family to implement those columns and in this example we have a",
    "start": "717040",
    "end": "724000"
  },
  {
    "text": "transaction writing to two keys a and b and for each transaction we need to choose a primary",
    "start": "724000",
    "end": "730160"
  },
  {
    "text": "key so here we choose key a as the primary key and during the preri phase we will write",
    "start": "730160",
    "end": "736880"
  },
  {
    "text": "the new data to the data column with the time step and also we'll place a log to each of",
    "start": "736880",
    "end": "742880"
  },
  {
    "text": "the key in this transaction and the blocks will have a pointer pointing to the primary",
    "start": "742880",
    "end": "749200"
  },
  {
    "text": "key and in the commit phrase only the key a which is the primary key will be updated",
    "start": "749200",
    "end": "756480"
  },
  {
    "text": "so the right column of key a will be updated to denote that the transaction has been",
    "start": "756480",
    "end": "762560"
  },
  {
    "text": "committed and also the loss on key a is deleted since only the primary key is being",
    "start": "762560",
    "end": "769519"
  },
  {
    "text": "updated in the commit phrase it can be done in an atomic way to a single rough group",
    "start": "769519",
    "end": "775839"
  },
  {
    "text": "and the logs and the right columns for the other keys will get updated as we resolve the logs in",
    "start": "775839",
    "end": "782000"
  },
  {
    "text": "subsequently and or background of gc3 when we resolve the law we will yield",
    "start": "782000",
    "end": "789040"
  },
  {
    "text": "make use of the pointer to the primary key to confirm that this transaction is committed",
    "start": "789040",
    "end": "796959"
  },
  {
    "text": "so this is how we initially implement automatic transaction in thai kv and in",
    "start": "796959",
    "end": "803360"
  },
  {
    "text": "the latest version we also want to implement a personalistic transaction and how do we do that",
    "start": "803360",
    "end": "809839"
  },
  {
    "text": "it turned out it turns out that it only required require a very simple change so for",
    "start": "809839",
    "end": "815600"
  },
  {
    "text": "pessimistic transaction and and we have an extra locking phrase and during the locking phrase we'll",
    "start": "815600",
    "end": "822160"
  },
  {
    "text": "place the lock to all the keys in this transaction and the log will have a special flag",
    "start": "822160",
    "end": "828560"
  },
  {
    "text": "which you know that which signifies that this law is a personistic lock and in the",
    "start": "828560",
    "end": "834959"
  },
  {
    "text": "pre-phrase the personistic block is turned into a optimistic law the the log format",
    "start": "834959",
    "end": "842480"
  },
  {
    "text": "it is the same as in uh optimistic transactions so that um and the rest the the flow for",
    "start": "842480",
    "end": "850240"
  },
  {
    "text": "for for uh prewrite and commit phrase are the are the same as",
    "start": "850240",
    "end": "856720"
  },
  {
    "text": "a optimistic transaction in this way of pessimistic transaction and",
    "start": "856720",
    "end": "862000"
  },
  {
    "text": "ultimately automatic transaction entity are compatible with each each other so you can have two clients",
    "start": "862000",
    "end": "870079"
  },
  {
    "text": "connected to the same targary cluster and one client doing a passive pessimistic transaction",
    "start": "870079",
    "end": "875519"
  },
  {
    "text": "and one client doing automatic transaction and it's perfectly perfectly fine for personal",
    "start": "875519",
    "end": "881920"
  },
  {
    "text": "transaction we also implement a deadlock detection so for deadlock detection we will in a",
    "start": "881920",
    "end": "888480"
  },
  {
    "text": "tight kv cluster we will have one title node to play the role of the dialog detector",
    "start": "888480",
    "end": "894560"
  },
  {
    "text": "and to simplify the implementation we will use a region one's leader as the",
    "start": "894560",
    "end": "900880"
  },
  {
    "text": "data detector and also on each of the target v nodes there is a wave manager",
    "start": "900880",
    "end": "907600"
  },
  {
    "text": "and a transaction wants to lock a key if a transaction wants the lockheed and",
    "start": "907600",
    "end": "913199"
  },
  {
    "text": "then finds a the key has been locked by another transaction it has to wait at the way to manage it",
    "start": "913199",
    "end": "920560"
  },
  {
    "text": "and the way the manager will use the information to update the dependency graph on the",
    "start": "920560",
    "end": "926160"
  },
  {
    "text": "dialog detector node and if a deadlock is detected the dialog detector will",
    "start": "926160",
    "end": "931519"
  },
  {
    "text": "uh notify the waiter manager to upload one of the transactions",
    "start": "931519",
    "end": "936800"
  },
  {
    "text": "so the overall design is very very simple and there is one cheeky case so when there is such",
    "start": "936800",
    "end": "943839"
  },
  {
    "text": "a leader transfer happen um um and and the region once leader transferred",
    "start": "943839",
    "end": "948959"
  },
  {
    "text": "to a new tyquino this new dialogue detector will lose all the previous information on the",
    "start": "948959",
    "end": "955680"
  },
  {
    "text": "dependency graph and what we do to resolve this issue is very simple we are not",
    "start": "955680",
    "end": "962959"
  },
  {
    "text": "trying to keep the um dependency graph up today we in this case we simply rely on the",
    "start": "962959",
    "end": "970240"
  },
  {
    "text": "transaction timeout to retry themselves so that's it for our transaction and",
    "start": "970240",
    "end": "976480"
  },
  {
    "text": "another thing i want to talk about is follow already that we recently add to thai",
    "start": "976480",
    "end": "981839"
  },
  {
    "text": "followery is an optimization in the rock protocol to reduce a re-latency and to understand",
    "start": "981839",
    "end": "989120"
  },
  {
    "text": "what it is um we need some basic background knowledge for the rough product",
    "start": "989120",
    "end": "996000"
  },
  {
    "text": "loss is a consensus algorithm and a consensus algorithm basically have two",
    "start": "996000",
    "end": "1002399"
  },
  {
    "text": "goals the first one is to ensure an agreement on just stay among all the nodes in a classroom",
    "start": "1002399",
    "end": "1010399"
  },
  {
    "text": "in for thai tv the shear state is the state of the data source in target",
    "start": "1010399",
    "end": "1015519"
  },
  {
    "text": "another goal of a consensus algorithm is to recover the cluster from slower failures",
    "start": "1015519",
    "end": "1022839"
  },
  {
    "text": "autonomously so uh rough the rough algorithm achieve these two",
    "start": "1022839",
    "end": "1028000"
  },
  {
    "text": "goals by doing a lot replication and i'm going to use uh techyv as an example to",
    "start": "1028000",
    "end": "1033760"
  },
  {
    "text": "explain how replication works so when the client wants to write a piece of data they will",
    "start": "1033760",
    "end": "1040400"
  },
  {
    "text": "send a request to the corresponding rough group leader the leader will translate the request",
    "start": "1040400",
    "end": "1047600"
  },
  {
    "text": "into a log end sheet and then start the dot replication the the log replication consists of two",
    "start": "1047600",
    "end": "1054960"
  },
  {
    "text": "steps the first step is the coming log in this step the leader will append the log entry to",
    "start": "1054960",
    "end": "1061919"
  },
  {
    "text": "its local log and at the same time it will broadcast the message to replicate the law entry to all its",
    "start": "1061919",
    "end": "1068880"
  },
  {
    "text": "followers and once it make sure that the log energy it has been replicated to a",
    "start": "1068880",
    "end": "1076000"
  },
  {
    "text": "majority of the replicas it proceeds to the next step which is apply log",
    "start": "1076000",
    "end": "1081919"
  },
  {
    "text": "the content of the log n sheet will be applied to the local state machine on the leader um",
    "start": "1081919",
    "end": "1089840"
  },
  {
    "text": "for thai kv the state machine is just the underlying kv stall or rock city",
    "start": "1089840",
    "end": "1095679"
  },
  {
    "text": "and after that the leader will return to the client and all the followers once received the",
    "start": "1095679",
    "end": "1101360"
  },
  {
    "text": "login sheet they will apply the log to their local state machine",
    "start": "1101360",
    "end": "1106840"
  },
  {
    "text": "asynchronously so this is how a write in taking works and how does uh re",
    "start": "1106840",
    "end": "1113679"
  },
  {
    "text": "works so for re it is usually done in the form of a re-index",
    "start": "1113679",
    "end": "1120080"
  },
  {
    "text": "so when a client wants to read a piece of data it sends a request to one of the nodes",
    "start": "1120080",
    "end": "1126400"
  },
  {
    "text": "in in the rough group and in case if it hits a follower in the",
    "start": "1126400",
    "end": "1133600"
  },
  {
    "text": "rough group the follower will need to send a read index request to the leader the leader will",
    "start": "1133600",
    "end": "1139679"
  },
  {
    "text": "then look at is committed in committed index which is the latest which is the index of the",
    "start": "1139679",
    "end": "1147840"
  },
  {
    "text": "latest log entry that that has been that that has been committed um then",
    "start": "1147840",
    "end": "1155679"
  },
  {
    "text": "it will uh broadcast the message to confirm the likeness of this uh committee index and then",
    "start": "1155679",
    "end": "1162320"
  },
  {
    "text": "after that it will read the data at the committee index or on its own",
    "start": "1162320",
    "end": "1167679"
  },
  {
    "text": "state machine and then return the data to the follower the follower",
    "start": "1167679",
    "end": "1173120"
  },
  {
    "text": "and as you can see here the re-index has still drawback and um so the set the",
    "start": "1173120",
    "end": "1179600"
  },
  {
    "text": "second step can be optimized out by using an optimization called listry but still um an",
    "start": "1179600",
    "end": "1187520"
  },
  {
    "text": "another drawback is that the re-index needs to in re-index the the data are always read",
    "start": "1187520",
    "end": "1195280"
  },
  {
    "text": "from the state machine on the leader and which incur more i o on the leader and also it incurred",
    "start": "1195280",
    "end": "1201440"
  },
  {
    "text": "network latency between the leader and follower and and and and and the latency will be",
    "start": "1201440",
    "end": "1208799"
  },
  {
    "text": "more noticeable when the follower and the leader are on different data centers",
    "start": "1208799",
    "end": "1215280"
  },
  {
    "text": "so um there is a following to uh to solve the problem in a follower read",
    "start": "1215280",
    "end": "1222400"
  },
  {
    "text": "when the follower receive the read request it will send a modified version of reindex to the leader",
    "start": "1222400",
    "end": "1228400"
  },
  {
    "text": "and the leader still needs to confirm the likeness of the committee index but this time",
    "start": "1228400",
    "end": "1234960"
  },
  {
    "text": "instead of reading data from its local state machine it returned the committee index directly",
    "start": "1234960",
    "end": "1241840"
  },
  {
    "text": "and the follower will use the committee index to read from is a",
    "start": "1241840",
    "end": "1247280"
  },
  {
    "text": "local state machine to get the data and return to the client so um so the following is",
    "start": "1247280",
    "end": "1255039"
  },
  {
    "text": "um generally useful in case the follower and the leader is on",
    "start": "1255039",
    "end": "1260799"
  },
  {
    "text": "different data center and also it's more useful when the database is",
    "start": "1260799",
    "end": "1266000"
  },
  {
    "text": "large in size in the surface use case they make use of followery to help reduce latency",
    "start": "1266000",
    "end": "1274000"
  },
  {
    "text": "and also they plan to use followery in a more creative way so this is",
    "start": "1274000",
    "end": "1280880"
  },
  {
    "text": "a demonstration of their plan use case they plan to add a data warehouse in",
    "start": "1280880",
    "end": "1287440"
  },
  {
    "text": "their system but this data warehouse is in a different data center",
    "start": "1287440",
    "end": "1292640"
  },
  {
    "text": "and what they plan to do instead of building a etl pipeline to stream the data",
    "start": "1292640",
    "end": "1297919"
  },
  {
    "text": "from a thai kv cluster to the data warehouse what they plan to do",
    "start": "1297919",
    "end": "1303600"
  },
  {
    "text": "is to have the data warehouse participate in the rough replication of the type cluster",
    "start": "1303600",
    "end": "1310799"
  },
  {
    "text": "and then for reads on the data warehouse they will use the following there are some benefits",
    "start": "1310799",
    "end": "1317360"
  },
  {
    "text": "for this setup one of them is of course the oil ap workloads will will now hit the data",
    "start": "1317360",
    "end": "1324559"
  },
  {
    "text": "warehouse where where the query can be better handled and also um by using follow read across data center",
    "start": "1324559",
    "end": "1331600"
  },
  {
    "text": "traffic can be reduced and also since the data warehouse participates in the",
    "start": "1331600",
    "end": "1336880"
  },
  {
    "text": "rough replication you can play the role of um of one replica in the system and so",
    "start": "1336880",
    "end": "1344080"
  },
  {
    "text": "so for zhukou they can reduce one replica in the thai kv cluster in their main data",
    "start": "1344080",
    "end": "1350640"
  },
  {
    "text": "center to reduce cost and this usage is very creative and we",
    "start": "1350640",
    "end": "1355840"
  },
  {
    "text": "are looking forward to see how it goes in in the future development uh and that's",
    "start": "1355840",
    "end": "1360960"
  },
  {
    "text": "it um that's it for my presentation and if you want to know more about heckely",
    "start": "1360960",
    "end": "1366640"
  },
  {
    "text": "here are a few more links and we will always be available on taiqui's leg channel",
    "start": "1366640",
    "end": "1371840"
  },
  {
    "text": "for any questions thank you",
    "start": "1371840",
    "end": "1375840"
  },
  {
    "text": "hi",
    "start": "1414840",
    "end": "1417840"
  },
  {
    "text": "hi thanks everyone for joining any",
    "start": "1421360",
    "end": "1425919"
  },
  {
    "text": "questions",
    "start": "1428840",
    "end": "1431840"
  },
  {
    "text": "foreign",
    "start": "1470840",
    "end": "1473840"
  },
  {
    "text": "oh so um we got a question what are the three characteristics and",
    "start": "1505279",
    "end": "1511600"
  },
  {
    "text": "how many uh possible and",
    "start": "1511600",
    "end": "1517039"
  },
  {
    "text": "how to optimize for that actually today i have uh salgon sun",
    "start": "1517039",
    "end": "1523120"
  },
  {
    "text": "who's the lead of the jehu's infrastructure team",
    "start": "1523120",
    "end": "1528320"
  },
  {
    "text": "with me over the internet so i'll turn to him",
    "start": "1528320",
    "end": "1534480"
  },
  {
    "text": "for the answer",
    "start": "1534960",
    "end": "1542640"
  },
  {
    "text": "hey someone i i don't think they can hear you but i can i can relay your",
    "start": "1542640",
    "end": "1548799"
  },
  {
    "text": "question so",
    "start": "1554840",
    "end": "1560960"
  },
  {
    "text": "so the so so so i picked the least uh uh at um",
    "start": "1561760",
    "end": "1570240"
  },
  {
    "text": "um",
    "start": "1570240",
    "end": "1572640"
  },
  {
    "text": "160 million million costs per second yeah",
    "start": "1579159",
    "end": "1585840"
  },
  {
    "text": "yeah that's the number of records per",
    "start": "1591200",
    "end": "1596799"
  },
  {
    "text": "second and i i think for the for the high school for the for the resizing they are",
    "start": "1596840",
    "end": "1602720"
  },
  {
    "text": "um that they are point get mostly or are they do yeah they are the point",
    "start": "1602720",
    "end": "1608000"
  },
  {
    "text": "get mostly so so we are not using typeflash to optimize them",
    "start": "1608000",
    "end": "1613840"
  },
  {
    "text": "so the next question is when running in multiple data centers how are transactions dealt",
    "start": "1615440",
    "end": "1622240"
  },
  {
    "text": "with so right now so i think this question is",
    "start": "1622240",
    "end": "1628400"
  },
  {
    "text": "mostly for type type type kv and idb and so um i think so so right now we don't have",
    "start": "1628400",
    "end": "1636480"
  },
  {
    "text": "a special handling for for vendetta data in multiple data centers so we still use",
    "start": "1636480",
    "end": "1642159"
  },
  {
    "text": "the same calculator model for for running the transaction",
    "start": "1642159",
    "end": "1647600"
  },
  {
    "text": "so yeah so so so they still need to go go over the data centers",
    "start": "1647600",
    "end": "1655039"
  },
  {
    "text": "we still incur across data and center traffic for transactions",
    "start": "1655039",
    "end": "1669840"
  },
  {
    "text": "oh if if you are uh if this question is referring to the uh last the use case",
    "start": "1670960",
    "end": "1677679"
  },
  {
    "text": "described at the end of the video so so the the the the the quorum though",
    "start": "1677679",
    "end": "1684480"
  },
  {
    "text": "um will will reach in inside the main data center so",
    "start": "1684480",
    "end": "1690720"
  },
  {
    "text": "so so so in in that case we we can keep the latency low",
    "start": "1691679",
    "end": "1697519"
  },
  {
    "text": "also the next question on how did you get into building databases it's complicated",
    "start": "1698559",
    "end": "1705279"
  },
  {
    "text": "it looks awesome but way over my head so uh i um",
    "start": "1705279",
    "end": "1712399"
  },
  {
    "text": "yeah there is a lot um interesting story about about about how",
    "start": "1712399",
    "end": "1718399"
  },
  {
    "text": "how pink builds this uh database so but uh but i i i think",
    "start": "1718399",
    "end": "1726720"
  },
  {
    "text": "so so so basically they so so the founder of thinktap wants to uh what wants to build something that's",
    "start": "1729440",
    "end": "1737360"
  },
  {
    "text": "that's open source and and that can that can that can make people",
    "start": "1737360",
    "end": "1743679"
  },
  {
    "text": "um and people can use it so yeah i i'm not sure",
    "start": "1743679",
    "end": "1750880"
  },
  {
    "text": "about how to answer this question",
    "start": "1750880",
    "end": "1767840"
  },
  {
    "text": "okay",
    "start": "1820840",
    "end": "1823840"
  },
  {
    "text": "foreign",
    "start": "1834840",
    "end": "1837840"
  },
  {
    "text": "yeah i think i sing all the questions i",
    "start": "1847600",
    "end": "1851520"
  },
  {
    "text": "answered",
    "start": "1862840",
    "end": "1865840"
  },
  {
    "text": "yeah for for any questions you can um if you have any further questions you can go to the uh uh",
    "start": "1889200",
    "end": "1896799"
  },
  {
    "text": "the slack channel for questions i think thank you all for joining",
    "start": "1896799",
    "end": "1903440"
  }
]
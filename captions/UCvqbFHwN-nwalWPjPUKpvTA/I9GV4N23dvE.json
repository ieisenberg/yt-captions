[
  {
    "text": "welcome to our talk this is how the SIG multicluster API specifications are used",
    "start": "160",
    "end": "5680"
  },
  {
    "text": "for real world multicluster management my name is August Simonelli i work with the open cluster management project and",
    "start": "5680",
    "end": "11759"
  },
  {
    "text": "I work for Red Hat and this is Ryan and I'm Ryan i am a maintainer for the newly",
    "start": "11759",
    "end": "17680"
  },
  {
    "text": "contributed CNCF project called Kubby Fleet and I work for Microsoft Azure",
    "start": "17680",
    "end": "23640"
  },
  {
    "text": "cool so let's talk a little bit about what we're going to speak about today so we've done our intro so that's one thing",
    "start": "23640",
    "end": "29920"
  },
  {
    "text": "down um we want to kind of go over the SIG multicluster standards i'm sure many in the room know them but it's always",
    "start": "29920",
    "end": "36399"
  },
  {
    "text": "good to recap them and to sort of baseline where we are with those things then we're going to demo some multicluster because that's the fun",
    "start": "36399",
    "end": "42160"
  },
  {
    "text": "stuff uh we've got a mix of a a recorded demo that's me and a live demo from Ryan that's him sweating over there and then",
    "start": "42160",
    "end": "48719"
  },
  {
    "text": "we can do some Q&A so the first thing I want to call out and again I know there are members of SIG multicluster here but",
    "start": "48719",
    "end": "55120"
  },
  {
    "text": "the idea behind this is that we want to define APIs and not implementations we're not trying to say this is exactly",
    "start": "55120",
    "end": "61920"
  },
  {
    "text": "how you do it we want to define standards we want to define ways that you can work within uh a multicluster",
    "start": "61920",
    "end": "67680"
  },
  {
    "text": "space and be able to add your stuff to it easily so to do that there are four basic APIs that Ryan will cover uh the",
    "start": "67680",
    "end": "75119"
  },
  {
    "text": "about API the multicluster services API the work API and the cluster profile API",
    "start": "75119",
    "end": "80640"
  },
  {
    "text": "and you're going to see those demoed today as well and why do we do this because by adopting standards it makes",
    "start": "80640",
    "end": "87119"
  },
  {
    "text": "it easier for the projects you work for and and add to contribute and to be part of this so whether it's something like",
    "start": "87119",
    "end": "93520"
  },
  {
    "text": "Cappy or Couple Fleet or whatever it is you're working with we make it by using the standard we make it easier for you",
    "start": "93520",
    "end": "98799"
  },
  {
    "text": "to fill those empty boxes so you can come along and say hey my project wants to be part of multicluster and this is",
    "start": "98799",
    "end": "104479"
  },
  {
    "text": "the way that we can do that and the idea again is that once we have these standards the agreed upon community",
    "start": "104479",
    "end": "110560"
  },
  {
    "text": "standards it's not about bringing your standard in and dropping it on and it's about finding something that works for everyone so that is sort of the basics",
    "start": "110560",
    "end": "117280"
  },
  {
    "text": "on how we do this i'll hand over to Ryan now to take you through a quick overview thank you Alex um yeah so let's first",
    "start": "117280",
    "end": "125520"
  },
  {
    "text": "talk about the the oldest one simplest one is called about API so what it is really about it's about uh define some",
    "start": "125520",
    "end": "132640"
  },
  {
    "text": "properties well-known properties for a cluster so probably if uh if uh I assume",
    "start": "132640",
    "end": "138800"
  },
  {
    "text": "most of you are Kubernetes practitioners you know that there's actually no single",
    "start": "138800",
    "end": "144000"
  },
  {
    "text": "ID for a cluster there's there just not there uh if you want to identify a cluster it doesn't exist in the",
    "start": "144000",
    "end": "149840"
  },
  {
    "text": "Kubernetes world so here is the what the about API is going to do because when you have multiple clusters now you kind",
    "start": "149840",
    "end": "156560"
  },
  {
    "text": "of have to identify each other so you can distinguish each other so the one of the actually I we only probably have two",
    "start": "156560",
    "end": "163120"
  },
  {
    "text": "the one properties we have defined is called a cluster name basically so you",
    "start": "163120",
    "end": "169599"
  },
  {
    "text": "can see here it's the name is cluster one you can name it it see looks simple but that actually is something that",
    "start": "169599",
    "end": "175599"
  },
  {
    "text": "kubernetes doesn't have and we are actually in the process of if you uh we are going to upload our our deck so that",
    "start": "175599",
    "end": "182879"
  },
  {
    "text": "click into the link you will see we are actually having a cap discussing more properties we putting another five",
    "start": "182879",
    "end": "188959"
  },
  {
    "text": "different properties that that we think that will be useful so uh please let us know get involved uh vote on that",
    "start": "188959",
    "end": "194959"
  },
  {
    "text": "comment on that um so that's another that's kind of tied up up to our uh",
    "start": "194959",
    "end": "200640"
  },
  {
    "text": "second API it's called the cluster profile API so the about API is really sitting inside the individual cluster to",
    "start": "200640",
    "end": "207440"
  },
  {
    "text": "identify what this various properties of this cluster but in most of the",
    "start": "207440",
    "end": "212799"
  },
  {
    "text": "multicluster world we need a single pane of glass for the the system and main the",
    "start": "212799",
    "end": "217840"
  },
  {
    "text": "fleet and main to actually see what are my clusters what do they do that's where this cluster profile API comes this is",
    "start": "217840",
    "end": "223680"
  },
  {
    "text": "basically allow you to let me see if you can see clearly yeah okay hopefully you can see if you have as good eyesight as",
    "start": "223680",
    "end": "229680"
  },
  {
    "text": "I have um that allows you to actually sit in your control plan and see each",
    "start": "229680",
    "end": "235280"
  },
  {
    "text": "individual clusters uh what properties they have again this this tied up to the",
    "start": "235280",
    "end": "240560"
  },
  {
    "text": "about API so we're going to add more properties well definfined communitydriven properties into the",
    "start": "240560",
    "end": "246799"
  },
  {
    "text": "about and then bring up to this cluster profile API we have i just put in the same link there um the next one is after",
    "start": "246799",
    "end": "254159"
  },
  {
    "text": "you uh decided that uh you have you I mean seen all these clusters and then",
    "start": "254159",
    "end": "259280"
  },
  {
    "text": "you decide that you want to place some uh jobs place some uh workloads into",
    "start": "259280",
    "end": "264560"
  },
  {
    "text": "some clusters how do you do that right you you don't want to always kuddle into each individual clusters and do a kobia",
    "start": "264560",
    "end": "270639"
  },
  {
    "text": "apply so we have a a API called work API basically allows you to from the control",
    "start": "270639",
    "end": "276880"
  },
  {
    "text": "plane side it's kind of again think of that as Kubernetes right on the control plane side you can place uh resources",
    "start": "276880",
    "end": "282880"
  },
  {
    "text": "onto clusters just like when on the Kubernetes side on the master node you can place that into a kublet so it's",
    "start": "282880",
    "end": "288320"
  },
  {
    "text": "exactly the same idea and uh uh August was going to and we are both going to demonstrate how that works in real life",
    "start": "288320",
    "end": "294479"
  },
  {
    "text": "and the last one is when you place all your applications into individual clusters that is that",
    "start": "294479",
    "end": "301040"
  },
  {
    "text": "Not really right you still need them to either talk to each other or can be accessible from uh from your users so",
    "start": "301040",
    "end": "307600"
  },
  {
    "text": "that's where this multicluster service API comes into being this is allows you to actually allow different cluster",
    "start": "307600",
    "end": "313759"
  },
  {
    "text": "different services with the same name there's an uh namespace sameness we're there's going to be a sig multicluster",
    "start": "313759",
    "end": "321039"
  },
  {
    "text": "talk tomorrow we'll get into more details there so you need to have this namespace sameness and then for every",
    "start": "321039",
    "end": "326080"
  },
  {
    "text": "services say every service a they can actually actually talk to each other or allow another service",
    "start": "326080",
    "end": "332039"
  },
  {
    "text": "or external users to talk to your service even if they are sitting in different clusters right that's what you",
    "start": "332039",
    "end": "338400"
  },
  {
    "text": "need you don't want them to individually specify I want to talk to cluster A's service and cluster B service and",
    "start": "338400",
    "end": "343440"
  },
  {
    "text": "cluster B goes around goes away then it doesn't work so you want to give this idea of all these services are the same",
    "start": "343440",
    "end": "349360"
  },
  {
    "text": "that's where the sameness comes from and now we are back to August about uh demonstrate some uh real cool",
    "start": "349360",
    "end": "356800"
  },
  {
    "text": "right so I'm going to talk to you a little bit about an implementation of some of these APIs and some enhancements to them and that's through the open",
    "start": "356800",
    "end": "362720"
  },
  {
    "text": "cluster management project or OCM you can visit us down in the booth all that kind of stuff what is open cluster",
    "start": "362720",
    "end": "368800"
  },
  {
    "text": "management very high level obviously we could go much deeper but it's a hub and spoke model deployment right so we",
    "start": "368800",
    "end": "375039"
  },
  {
    "text": "follow the hub Kubluit approach um they named them clusterlets which I thought was cute something that runs on the",
    "start": "375039",
    "end": "380479"
  },
  {
    "text": "managed clusters and it gives us a weak autonomy so we get resiliency so if there's a network severance or something",
    "start": "380479",
    "end": "385680"
  },
  {
    "text": "like that we are able to uh remain running without losing what's happening on your managed clusters our",
    "start": "385680",
    "end": "392080"
  },
  {
    "text": "implementation of work we call manifest work uh that's as Ryan said how we deliver resources to the managed",
    "start": "392080",
    "end": "398319"
  },
  {
    "text": "clusters now we have added some things to the offering there uh our version of",
    "start": "398319",
    "end": "404240"
  },
  {
    "text": "placement well we call it placement but that's our way to dynamically select clusters based on some resources i'll",
    "start": "404240",
    "end": "409759"
  },
  {
    "text": "show you it very briefly and Ryan will dive into it a little bit more uh the idea is that we can select clusters in a",
    "start": "409759",
    "end": "415840"
  },
  {
    "text": "uh certain way if we want more CPU or different characteristics uh we can use",
    "start": "415840",
    "end": "421280"
  },
  {
    "text": "placement to land on them and then at OCM we include something called add-ons which are a modular and very easy way to",
    "start": "421280",
    "end": "428639"
  },
  {
    "text": "plug things in so if you have something in a project and you say \"I want to bring that along i want to I want to make it part of OCM i want to use it",
    "start": "428639",
    "end": "435120"
  },
  {
    "text": "there.\" You can go through the add-on framework now we're going to go through",
    "start": "435120",
    "end": "440160"
  },
  {
    "text": "every piece of this one so sit back should takes about 40 minutes no I'm just kidding haha um basically I wanted",
    "start": "440160",
    "end": "448160"
  },
  {
    "text": "to demonstrate how we map some of the uh SIG APIs against what we call them",
    "start": "448160",
    "end": "453840"
  },
  {
    "text": "because sometimes that part can be a bit confusing i was confused by that so when you look at things like the about API we",
    "start": "453840",
    "end": "460080"
  },
  {
    "text": "have a cluster claim when you look at the multicluster services API we do things with Submariner and we might make",
    "start": "460080",
    "end": "465840"
  },
  {
    "text": "it so it's easier to manage all your your services these are just implementations of what's happening in",
    "start": "465840",
    "end": "470880"
  },
  {
    "text": "the SIG we don't necessarily expect them to become dominant or anything like that it's just how we use them and allows you",
    "start": "470880",
    "end": "477360"
  },
  {
    "text": "to do different things with them so we have the work and the cluster profile APIs so that's fine uh it's something to",
    "start": "477360",
    "end": "483919"
  },
  {
    "text": "look at it'll be with the deck so I want to now quickly run you through a recorded demo I have that I'll talk",
    "start": "483919",
    "end": "489360"
  },
  {
    "text": "through of deploying some work and a placement and let's see how we",
    "start": "489360",
    "end": "494440"
  },
  {
    "text": "go okay so what I have is two h one hub and",
    "start": "494440",
    "end": "500800"
  },
  {
    "text": "two managed clusters and as you can see I have manifest work i ask the hub about it it knows the managed cluster of",
    "start": "500800",
    "end": "507599"
  },
  {
    "text": "course doesn't know anything about that yeah is that big enough it doesn't matter i can't change it um so we'll go",
    "start": "507599",
    "end": "513279"
  },
  {
    "text": "ahead and do this against the hub the CRD is there and just to prove that it exists I like to look at these things um",
    "start": "513279",
    "end": "520479"
  },
  {
    "text": "there it is so the CRD is there we're ready to go okay so we run agents and on",
    "start": "520479",
    "end": "527440"
  },
  {
    "text": "the manage cluster so we have a registration agent and a work agent who are able to then grab the information",
    "start": "527440",
    "end": "532640"
  },
  {
    "text": "when they need it now here's what I'm going to deploy this is a simple piece of work so this is my manifest work and",
    "start": "532640",
    "end": "538880"
  },
  {
    "text": "I'm going to deploy it to a namespace called cluster one which will match the cluster that I want to deploy to as Ryan",
    "start": "538880",
    "end": "545040"
  },
  {
    "text": "was talking about it's a service account it's a deployment of Inenics it's a specific version there's no magic here",
    "start": "545040",
    "end": "551760"
  },
  {
    "text": "it's just a very normal deployment so I'm going to apply that against the hub uh the piece of work against the hub and",
    "start": "551760",
    "end": "558160"
  },
  {
    "text": "then I want to go ahead and take a look at what's happening there so I'll use cluster ADM which is an OCM tool you",
    "start": "558160",
    "end": "564080"
  },
  {
    "text": "don't have to but I like it because I like how it can display things and how it can interact with the uh environment",
    "start": "564080",
    "end": "569360"
  },
  {
    "text": "and I play with OCM so here is the pieces of work that have been deployed against cluster one and so we'll dive a",
    "start": "569360",
    "end": "575839"
  },
  {
    "text": "little bit more on the on what's actually happened right there's no pods in the cluster one name space on the hub",
    "start": "575839",
    "end": "580959"
  },
  {
    "text": "it's obvious but I just want to be clear that this isn't happening on the hub this is being sent out to the managed cluster so I'll switch to the manage",
    "start": "580959",
    "end": "587519"
  },
  {
    "text": "cluster and let's go ahead and look and find these things in cluster one okay they're not there right so why are they",
    "start": "587519",
    "end": "593440"
  },
  {
    "text": "not there i said it had to be in that namespace that's for managing the cluster when you look closely I was",
    "start": "593440",
    "end": "599279"
  },
  {
    "text": "actually deploying to the default namespace so I can put it anywhere I want it just have to have the namespace",
    "start": "599279",
    "end": "604320"
  },
  {
    "text": "sameness across the cluster naming so if we look at the pods in running on",
    "start": "604320",
    "end": "609839"
  },
  {
    "text": "cluster one I can see myenics deployment so we can see that the the work has actually sent that out to the",
    "start": "609839",
    "end": "616240"
  },
  {
    "text": "agent and it started that up and then if I check on cluster two I",
    "start": "616240",
    "end": "621519"
  },
  {
    "text": "should not see them and there they're not happening there so it's done exactly what I asked",
    "start": "621519",
    "end": "627680"
  },
  {
    "text": "you know no no smoking mirrors um so let's take a look at the work on the hub there's the hub in the cluster one",
    "start": "627680",
    "end": "633519"
  },
  {
    "text": "namespace which matches the name of my managed cluster and there's the piece of work that the manifest work uh",
    "start": "633519",
    "end": "640839"
  },
  {
    "text": "deployed so let's be sure this really exists i like my proof of life so here's the the deployment running that's my",
    "start": "640839",
    "end": "647440"
  },
  {
    "text": "Ingenics deployment and then furthermore I deployed a service account and again",
    "start": "647440",
    "end": "654560"
  },
  {
    "text": "that's just to show that this got through and I also deployed um the I can take a look at the work and what's",
    "start": "654560",
    "end": "660880"
  },
  {
    "text": "really cool is when you use this method to deploy you get all this information from the work so I can now do automation",
    "start": "660880",
    "end": "666480"
  },
  {
    "text": "based on these things i can learn about them i can grab stuff back in the spec where I find out the status of something",
    "start": "666480",
    "end": "672000"
  },
  {
    "text": "i can alert on it i can um see when it changed when it does things so I'm getting all this for free by using the",
    "start": "672000",
    "end": "678399"
  },
  {
    "text": "work API makes my deployments across a managed cluster much more resilient easier to work",
    "start": "678399",
    "end": "684839"
  },
  {
    "text": "with now this monitors the agent monitors the work through a hash so if I do lose",
    "start": "684839",
    "end": "692560"
  },
  {
    "text": "connectivity or I make a change but I'm not talking it'll see a change in the hash it'll know to grab the new work and",
    "start": "692560",
    "end": "698240"
  },
  {
    "text": "update things for me so we've thought of everything right so what we'll do is let's actually go ahead and look inside",
    "start": "698240",
    "end": "705360"
  },
  {
    "text": "uh one of the pods because what I want to do is then make a change to the work i'm going to change the version of Inenix and so you can see that actually",
    "start": "705360",
    "end": "712160"
  },
  {
    "text": "get deployed across the the cluster that we've used so I used an old version of Inenix just because uh that was there",
    "start": "712160",
    "end": "718640"
  },
  {
    "text": "and it was easy so I'm going to use a newer version to um see that it can actually go ahead and deploy those pods",
    "start": "718640",
    "end": "724800"
  },
  {
    "text": "and make something new come out on it so I've changed it to 1274 and then I simply just have to",
    "start": "724800",
    "end": "731120"
  },
  {
    "text": "redeploy the work and once I've done that it'll sort",
    "start": "731120",
    "end": "737519"
  },
  {
    "text": "it out for me so that I can go ahead and look at the different clusters and I can see that the work has been deployed um",
    "start": "737519",
    "end": "742880"
  },
  {
    "text": "it's restarting the containers it's doing everything I asked which is just update the version and in no time my",
    "start": "742880",
    "end": "748000"
  },
  {
    "text": "work's been pushed out to wherever I want so I've managed everything from the hub right i've gotten all that value out",
    "start": "748000",
    "end": "753200"
  },
  {
    "text": "of of these work APIs simplest version you could come up with you could show and I did my 16-year-old she found it",
    "start": "753200",
    "end": "759760"
  },
  {
    "text": "boring okay she's not into that but we now can see that it will",
    "start": "759760",
    "end": "765560"
  },
  {
    "text": "work and so let me just prove to you that the pod is actually been changed i mean that's kind of obvious but again I",
    "start": "765560",
    "end": "771440"
  },
  {
    "text": "like to really see it that's probably my marketing background so there you go we now have the running uh container so",
    "start": "771440",
    "end": "778800"
  },
  {
    "text": "what I really want to do now is just quickly jump into an example of very simple example of our placement so I'm",
    "start": "778800",
    "end": "784720"
  },
  {
    "text": "going to clean up the work that we have here because I only deployed to one cluster and I'm going to show you how I can deploy it to uh multiple clusters",
    "start": "784720",
    "end": "791600"
  },
  {
    "text": "through placement okay this last bit",
    "start": "791600",
    "end": "798839"
  },
  {
    "text": "here so back on the hub and what I'm going to do is using",
    "start": "798839",
    "end": "805279"
  },
  {
    "text": "cluster ADM I'm going to take a look at the clusters now remember I have two clusters and what I do in those is I",
    "start": "805279",
    "end": "810399"
  },
  {
    "text": "have two I have cluster sets ocm sets up a default like a global one but I have a default cluster set I've built that is a",
    "start": "810399",
    "end": "816880"
  },
  {
    "text": "way of grouping clusters together in some way that makes sense it doesn't really matter what they are but that's",
    "start": "816880",
    "end": "822320"
  },
  {
    "text": "what we do i can bind the namespace that I want to use to that cluster set which will allow the work to take actions in",
    "start": "822320",
    "end": "828639"
  },
  {
    "text": "that namespace and then I just have to create a placement so a placement just simply says and I am going to pause this for a",
    "start": "828639",
    "end": "835040"
  },
  {
    "text": "sec a placement simply says put these clusters based on something mine is so",
    "start": "835040",
    "end": "841199"
  },
  {
    "text": "simple it just says put it anywhere and I say find two clusters that meet these criteria i only have two so it's going",
    "start": "841199",
    "end": "846880"
  },
  {
    "text": "to find them both yeah so that'll deploy it to I",
    "start": "846880",
    "end": "852639"
  },
  {
    "text": "would expect to see the work on both clusters based on what I'm doing so I I create the placement and now all I have",
    "start": "852639",
    "end": "859199"
  },
  {
    "text": "to do is create the work to use the placement and the placement will take care of placing the work so the names",
    "start": "859199",
    "end": "864880"
  },
  {
    "text": "are you know talk to the Sig about the names but I love them because I don't forget so the placement exists I it'll",
    "start": "864880",
    "end": "871519"
  },
  {
    "text": "handle all decisions it'll work fine it's the same piece of work as you saw before except I don't have to explicitly",
    "start": "871519",
    "end": "877600"
  },
  {
    "text": "call it as a manifest work it's just normal YAML so the deployment is set to",
    "start": "877600",
    "end": "883199"
  },
  {
    "text": "go ready service account the whole thing and then I use cluster ADM because",
    "start": "883199",
    "end": "888480"
  },
  {
    "text": "I like to to create that piece of work in the exact same way I did before but I tell it what placement to use so I",
    "start": "888480",
    "end": "894480"
  },
  {
    "text": "expect the placement to read the rules ryan will go into it a bit more deeply and I will then be able to place that",
    "start": "894480",
    "end": "900639"
  },
  {
    "text": "work across my multiple clusters so you've seen it do it it's now created that my first work work on the both",
    "start": "900639",
    "end": "909079"
  },
  {
    "text": "clusters and then I can prove that by showing the work running on the",
    "start": "909079",
    "end": "915040"
  },
  {
    "text": "hub so again I didn't have to actually explicitly call that kind it simply built the work for me and there it is so",
    "start": "916040",
    "end": "922959"
  },
  {
    "text": "I have work running on both those namespaces on the hub meaning that both my clusters with those names will have",
    "start": "922959",
    "end": "928320"
  },
  {
    "text": "the work running on it in the default namespace as we talked about",
    "start": "928320",
    "end": "933440"
  },
  {
    "text": "before and there it is running on cluster one and there it is in a second running on cluster two and that",
    "start": "933800",
    "end": "939760"
  },
  {
    "text": "demonstrates at the very simplest level of how we've implemented the work API and added placement to make that work",
    "start": "939760",
    "end": "946240"
  },
  {
    "text": "and now I'm going to show you how to do the same thing with uh Kuble fleet from Ryan",
    "start": "946240",
    "end": "952639"
  },
  {
    "text": "thank you very much um yeah so uh yeah this is uh thank you so we have again we",
    "start": "952639",
    "end": "960800"
  },
  {
    "text": "have this new project called Kubi fleet that is recently contributed to CNCF so",
    "start": "960800",
    "end": "966560"
  },
  {
    "text": "a little bit about Kubby fleet um it's again very similar a lot of concepts are very similar with OCM so we provide you",
    "start": "966560",
    "end": "972880"
  },
  {
    "text": "a single pane of glass for the fleet meanings to do uh multicluster application management just exactly like",
    "start": "972880",
    "end": "980160"
  },
  {
    "text": "of this uh demonstrated you have one hub cluster you do of thing and then it will you don't have to go to your each each",
    "start": "980160",
    "end": "986560"
  },
  {
    "text": "individual cluster imagine you have like 20 50 clusters that will save a lot of your uh headache and based on that we",
    "start": "986560",
    "end": "994000"
  },
  {
    "text": "provide a lot of scheduling capabilities basically we copy pasted a whole bunch of Kubernetes concepts affinities um",
    "start": "994000",
    "end": "1002320"
  },
  {
    "text": "topology spread preferred required during scheduling preferred during",
    "start": "1002320",
    "end": "1007519"
  },
  {
    "text": "scheduling all things like that and we also introduced some uh different flavors of policies uh placement",
    "start": "1007519",
    "end": "1013839"
  },
  {
    "text": "policies just as uh the demo is we can you can pick some how many clusters you have or pick all of them like a demon",
    "start": "1013839",
    "end": "1019600"
  },
  {
    "text": "set and also we add a property based uh scheduling that is why we uh tied into",
    "start": "1019600",
    "end": "1025120"
  },
  {
    "text": "this about API cluster profile API is when you have the properties normally one of the main reason we have",
    "start": "1025120",
    "end": "1031038"
  },
  {
    "text": "properties on that is for the admin to see which where you put it so we have property based scheduling and we finally",
    "start": "1031039",
    "end": "1037918"
  },
  {
    "text": "we have recently we built this building a continuous deployment strategy because the uh yeah we we actually have a demo",
    "start": "1037919",
    "end": "1045360"
  },
  {
    "text": "uh tomorrow uh if you are more interested but today I'm not going to demo de demonstrate that um and then the",
    "start": "1045360",
    "end": "1050720"
  },
  {
    "text": "same thing uh exactly like what OCM uh showed we implemented all these APIs",
    "start": "1050720",
    "end": "1056559"
  },
  {
    "text": "most close to as close as we can to the uh sigmoic cluster standard and uh let's",
    "start": "1056559",
    "end": "1063280"
  },
  {
    "text": "jump into a demo uh anyone want Want to see a live demo or recorded demo",
    "start": "1063280",
    "end": "1068400"
  },
  {
    "text": "yeah okay that's the spirit let's see okay so here I've set",
    "start": "1068400",
    "end": "1075520"
  },
  {
    "text": "up a fleet i don't know how is it Is it Is it big enough big enough i can make it even bigger go bigger if you can yeah",
    "start": "1075520",
    "end": "1082559"
  },
  {
    "text": "okay that probably that's the biggest I can",
    "start": "1082559",
    "end": "1087200"
  },
  {
    "text": "get yeah that's live so that you know that's all or errors you made will be",
    "start": "1092679",
    "end": "1098480"
  },
  {
    "text": "there um the problem with live a big one is you probably cannot see the rest of it so you can see that it has available",
    "start": "1098480",
    "end": "1105200"
  },
  {
    "text": "CPUs i don't know if I can I don't know how to yeah but you can see we have one two three four nine clusters joined to",
    "start": "1105200",
    "end": "1112640"
  },
  {
    "text": "this fleet right and you have there are properties properties at the right side",
    "start": "1112640",
    "end": "1118240"
  },
  {
    "text": "there's available CPU available memory i think I can do white",
    "start": "1118240",
    "end": "1126679"
  },
  {
    "text": "oops I cannot spell so then you will also see available allocatable memories",
    "start": "1126679",
    "end": "1133039"
  },
  {
    "text": "things like that those are the properties and uh cluster",
    "start": "1133039",
    "end": "1138840"
  },
  {
    "text": "pro we create a cluster I cannot spell profile so we create a cluster profile",
    "start": "1138840",
    "end": "1145679"
  },
  {
    "text": "for each cluster um that's but the cluster profile currently doesn't have all these properties yet so we cannot",
    "start": "1145679",
    "end": "1152480"
  },
  {
    "text": "really do schedulings based on that so we showed you the cluster profile the next thing is the cluster um properties",
    "start": "1152480",
    "end": "1158640"
  },
  {
    "text": "right about API so let me see so the main uh placement equivalent",
    "start": "1158640",
    "end": "1165280"
  },
  {
    "text": "API in the K fleet is called uh let me see where's my this guy so this",
    "start": "1165280",
    "end": "1172720"
  },
  {
    "text": "hopefully again if it's hard to see but uh you hopefully you can get some idea we have this u topology uh topology",
    "start": "1172720",
    "end": "1181120"
  },
  {
    "text": "spread affinities but here is the where the properties comes in so we have a",
    "start": "1181120",
    "end": "1186240"
  },
  {
    "text": "property sortter so I showed you previously you have uh available CPUs so",
    "start": "1186240",
    "end": "1191919"
  },
  {
    "text": "we can say in this one we would say that uh because sorting order descending then you are going to we are basically trying",
    "start": "1191919",
    "end": "1197440"
  },
  {
    "text": "to find the cluster with the most CPUs with a weight 50% 50 of them and also a",
    "start": "1197440",
    "end": "1203919"
  },
  {
    "text": "cost u probably this should be ascending but there's another property so we can do all these if all these with Azure are",
    "start": "1203919",
    "end": "1211280"
  },
  {
    "text": "uh Azure based properties and with this um the kubernetes ones are the public properties and then we also have",
    "start": "1211280",
    "end": "1217760"
  },
  {
    "text": "required during scheduling you know all these things we want to be the memories has to be over 13 gig but I just come up",
    "start": "1217760",
    "end": "1224720"
  },
  {
    "text": "with number um because we have uh clusters that don't have that many",
    "start": "1224720",
    "end": "1229919"
  },
  {
    "text": "memories So this is how we use properties um when the cluster profile API the link I send there when we have a",
    "start": "1229919",
    "end": "1237440"
  },
  {
    "text": "common uh communitydriven properties we are going to adapt to that so this is",
    "start": "1237440",
    "end": "1242720"
  },
  {
    "text": "how we do the property and now uh let's take a look at",
    "start": "1242720",
    "end": "1249880"
  },
  {
    "text": "uh take a look at how it does become EU",
    "start": "1249880",
    "end": "1257399"
  },
  {
    "text": "so this is similar to what our placement is so again those are the let's take a look",
    "start": "1257520",
    "end": "1264640"
  },
  {
    "text": "at the status so what it says it says uh found all cluster needed found three so",
    "start": "1264640",
    "end": "1269760"
  },
  {
    "text": "we asked for three it give us three and let's see what it has it has uh so it's called bug batch three uh bug batch four",
    "start": "1269760",
    "end": "1279360"
  },
  {
    "text": "right so let's just take a look at this how do we So we have a we grouped a",
    "start": "1279360",
    "end": "1284559"
  },
  {
    "text": "whole bunch of stuff oh sorry maybe I didn't make it that clear here is uh resource selector so what did we",
    "start": "1284559",
    "end": "1291919"
  },
  {
    "text": "select we selected a namespace called multicluster app here right so basically",
    "start": "1291919",
    "end": "1297520"
  },
  {
    "text": "the idea is I have application sitting in a namespace i want to decide the the fleets admin want to decide where this",
    "start": "1297520",
    "end": "1303840"
  },
  {
    "text": "application should run right it pick all kinds of u properties or criteria say I want to run there so now we actually",
    "start": "1303840",
    "end": "1310799"
  },
  {
    "text": "want to place that uh application to the cluster that's where the the work API comes into being i'll show you something",
    "start": "1310799",
    "end": "1317760"
  },
  {
    "text": "very similar to what OCM does so now let's take a look at the namespace right",
    "start": "1317760",
    "end": "1323520"
  },
  {
    "text": "so the magic is uh we put it in the corresponding name space there and",
    "start": "1323520",
    "end": "1330559"
  },
  {
    "text": "we have a work object there let's see there yeah so that object is there and uh I think",
    "start": "1330559",
    "end": "1337919"
  },
  {
    "text": "after the previous demo you're pretty familiar with it now hopefully uh it's very similar to",
    "start": "1337919",
    "end": "1343960"
  },
  {
    "text": "what the oh maybe I didn't do so you can see it's the same thing",
    "start": "1343960",
    "end": "1350080"
  },
  {
    "text": "manifest name so what we place we place a namespace we place the service uh and",
    "start": "1350080",
    "end": "1356320"
  },
  {
    "text": "we place the deployment and then the last thing we place the service export",
    "start": "1356320",
    "end": "1362080"
  },
  {
    "text": "so now goes to the last API we're going to talk about service export so before that just like uh Oscars want to do I",
    "start": "1362080",
    "end": "1368880"
  },
  {
    "text": "want to prove life like it's we actually place it there right so uh let's see I",
    "start": "1368880",
    "end": "1375679"
  },
  {
    "text": "think it was three see if it's there right so it's",
    "start": "1375679",
    "end": "1382480"
  },
  {
    "text": "there let's just take a quick peek what's",
    "start": "1382480",
    "end": "1387840"
  },
  {
    "text": "inside yeah so it has uh deployment And just to do the same thing let's see if",
    "start": "1390919",
    "end": "1397120"
  },
  {
    "text": "we pick something that is not there let's see i don't know i don't think",
    "start": "1397120",
    "end": "1402880"
  },
  {
    "text": "this one is there does it have anything nothing right you can you can",
    "start": "1402880",
    "end": "1409679"
  },
  {
    "text": "find something just pick another random stuff doesn't exist right so we only",
    "start": "1409679",
    "end": "1414960"
  },
  {
    "text": "place to where it should be so now comes back to what the service export does so",
    "start": "1414960",
    "end": "1420159"
  },
  {
    "text": "with a service expert so we place it in I think in three four and I don't remember",
    "start": "1420159",
    "end": "1427520"
  },
  {
    "text": "what's the next one just let's say three and four right yeah so at least three and four are there um so now you have an",
    "start": "1427520",
    "end": "1436000"
  },
  {
    "text": "application at least sitting actually three clusters I just don't remember three clusters and then now you you have",
    "start": "1436000",
    "end": "1442240"
  },
  {
    "text": "a customer right customer say that's your store storefront right the customers store app want to want to buy",
    "start": "1442240",
    "end": "1448240"
  },
  {
    "text": "something from your from your store so how do they do that they are not going to talk to the C cluster specifically",
    "start": "1448240",
    "end": "1454000"
  },
  {
    "text": "they're going to have an endpoint so that's where we put a uh DNS just",
    "start": "1454000",
    "end": "1459440"
  },
  {
    "text": "basically it's a it's a load balancer in front of it's a DNS based load balancer and that one is called let me see if I",
    "start": "1459440",
    "end": "1466240"
  },
  {
    "text": "still have the command it's long don't want to this one",
    "start": "1466240",
    "end": "1472440"
  },
  {
    "text": "no ah this one yeah so we have our traffic manager there and this is the",
    "start": "1472440",
    "end": "1478559"
  },
  {
    "text": "DNS name and uh",
    "start": "1478559",
    "end": "1483440"
  },
  {
    "text": "um okay let me just so it has a DNS DNS name",
    "start": "1484200",
    "end": "1492000"
  },
  {
    "text": "endpoint and then I forget the",
    "start": "1494840",
    "end": "1499679"
  },
  {
    "text": "name so I will show you how we use the service export right so this is called",
    "start": "1500440",
    "end": "1507720"
  },
  {
    "text": "endpoints all",
    "start": "1507720",
    "end": "1510720"
  },
  {
    "text": "right so it's anyone familiar with skate uh gate gateway APIs it's similar",
    "start": "1516919",
    "end": "1522480"
  },
  {
    "text": "gateway API you have a gateway API and then you have endpoints so this is our endpoints and then the way you use that",
    "start": "1522480",
    "end": "1528240"
  },
  {
    "text": "is u pointing to your service import when when you have",
    "start": "1528240",
    "end": "1535840"
  },
  {
    "text": "service export on your clusters we automatically create a service import uh somewhere else so that you can access",
    "start": "1535840",
    "end": "1542400"
  },
  {
    "text": "that so we have that service import and I show you where the service input",
    "start": "1542400",
    "end": "1548720"
  },
  {
    "text": "is i think it's in the same class yeah so we have this service import",
    "start": "1551080",
    "end": "1557799"
  },
  {
    "text": "yeah so it says how many clusters it has three clusters three four and another another one basically my name there uh",
    "start": "1568559",
    "end": "1575840"
  },
  {
    "text": "it has ports so that's that's how you get this uh in uh storefront and if you",
    "start": "1575840",
    "end": "1584080"
  },
  {
    "text": "look at the this one",
    "start": "1584080",
    "end": "1589520"
  },
  {
    "text": "right so it has a DNS name oh",
    "start": "1591000",
    "end": "1597799"
  },
  {
    "text": "this one it has a DNS name and now you want to dig dig",
    "start": "1598000",
    "end": "1604039"
  },
  {
    "text": "that see if you can yeah now you see this uh actually in here let me see if I",
    "start": "1604039",
    "end": "1609679"
  },
  {
    "text": "can get another another one didn't change for curl it a few",
    "start": "1609679",
    "end": "1616000"
  },
  {
    "text": "times and we can curl actually force it to use",
    "start": "1616000",
    "end": "1621039"
  },
  {
    "text": "it where did it go dig it dig it again",
    "start": "1621039",
    "end": "1628880"
  },
  {
    "text": "same but that that's the part of life but uh just believe me it's actually going to three different places uh",
    "start": "1628880",
    "end": "1635760"
  },
  {
    "text": "that's about the demo hopefully uh if you have any questions uh you can grab me again the the setting is still there",
    "start": "1635760",
    "end": "1642000"
  },
  {
    "text": "you can play with it if you like so finally um there's one shout out is uh",
    "start": "1642000",
    "end": "1647679"
  },
  {
    "text": "our project is so new we don't even have a logo so uh if you are interested if",
    "start": "1647679",
    "end": "1653279"
  },
  {
    "text": "you feel like your uh taste is good uh please vote for the logo may the best uh",
    "start": "1653279",
    "end": "1658640"
  },
  {
    "text": "logo win okay that's it thank you very much we have a Q&A",
    "start": "1658640",
    "end": "1665799"
  },
  {
    "text": "nailed it that's good timing any questions",
    "start": "1667600",
    "end": "1673880"
  },
  {
    "text": "uh yeah is there any Is there a mic somewhere i mean I could just come up if it's",
    "start": "1674240",
    "end": "1679919"
  },
  {
    "text": "easier where is the question from",
    "start": "1679919",
    "end": "1685840"
  },
  {
    "text": "he's there he's going to the mic hi uh so great talk thank you um I do",
    "start": "1685840",
    "end": "1692399"
  },
  {
    "text": "have a question um it seems to be right now oriented at uh spreading your blast",
    "start": "1692399",
    "end": "1699039"
  },
  {
    "text": "radius if cluster goes down geographically um but say you have just",
    "start": "1699039",
    "end": "1704640"
  },
  {
    "text": "two clusters side by side and you want to guard yourself against doing an oopsie and taking a cluster down um it",
    "start": "1704640",
    "end": "1711600"
  },
  {
    "text": "means that you're if you are a developer and you want to present your developers with a unified view say a nice Argo CD",
    "start": "1711600",
    "end": "1718559"
  },
  {
    "text": "dashboard or something like that um it is still going to be represented differently because those tools as far",
    "start": "1718559",
    "end": "1724559"
  },
  {
    "text": "as I know just like uh ISTTO or Kali we aren't really that multicluster aware",
    "start": "1724559",
    "end": "1730240"
  },
  {
    "text": "and definitely not aware in the federated sense of awareness is there",
    "start": "1730240",
    "end": "1735279"
  },
  {
    "text": "any integration with other sigs with other projects where they're working on this or is that something that's a",
    "start": "1735279",
    "end": "1740720"
  },
  {
    "text": "little bit more further out into the future you think um yeah definitely so this is just a uh tiny po portion of all",
    "start": "1740720",
    "end": "1748880"
  },
  {
    "text": "our projects we have a a lot more feature there i believe OCM also have a lot of features like that so actually I",
    "start": "1748880",
    "end": "1755120"
  },
  {
    "text": "will have a demo about uh how does this Kubi fleet work with Ago CD exactly how we work with that's the beauty of an",
    "start": "1755120",
    "end": "1762080"
  },
  {
    "text": "common API when you have a common API the other integr other projects can integrate with an API instead of",
    "start": "1762080",
    "end": "1768159"
  },
  {
    "text": "integrating with a specific project and that's very much what I was trying you know trying to call out is if we can",
    "start": "1768159",
    "end": "1773360"
  },
  {
    "text": "keep to this then those empty boxes you saw on that slide they are anything in theory so that we can make sure we don't",
    "start": "1773360",
    "end": "1780000"
  },
  {
    "text": "go down that road and that that will be the way to do it yeah because it's a spec not an implementation yeah yeah",
    "start": "1780000",
    "end": "1786240"
  },
  {
    "text": "that makes sense yeah and because it is essentially a single control plane anything that could talk to an",
    "start": "1786240",
    "end": "1791440"
  },
  {
    "text": "individual API server would technically just be escapable to talk to a hub API",
    "start": "1791440",
    "end": "1796880"
  },
  {
    "text": "server essentially because it's just CRDs yeah i mean is there a minimum number of clusters i mean in some way it should be one because you always want to",
    "start": "1796880",
    "end": "1803279"
  },
  {
    "text": "grow so if I'm always managing in a in a very standardized way then I'm in a good space yeah i actually have a secondary",
    "start": "1803279",
    "end": "1809440"
  },
  {
    "text": "question which is probably going to annoy everyone uh although there's no line great um so say you have a work and",
    "start": "1809440",
    "end": "1817600"
  },
  {
    "text": "that's deployed and your spoke clusters are executing this work happily if you now go and manually modify that will a",
    "start": "1817600",
    "end": "1824720"
  },
  {
    "text": "controller or reconciliation loop reset that back to the desired state good question um and I feel like you you have",
    "start": "1824720",
    "end": "1831840"
  },
  {
    "text": "been there um so yeah so at least for Kubby fleet we have uh it's called drift detection we have takeover uh drift",
    "start": "1831840",
    "end": "1839120"
  },
  {
    "text": "detection diff reporting all these goodies in the work API but we haven't",
    "start": "1839120",
    "end": "1844320"
  },
  {
    "text": "upstream that yet that's extra work we need to get everybody uh agreed on the API and we can upstream all these uh",
    "start": "1844320",
    "end": "1850880"
  },
  {
    "text": "good features there right cool the takeover part sounds interesting yeah i'll guess we'll talk about it later a",
    "start": "1850880",
    "end": "1856559"
  },
  {
    "text": "lot of times um before they can adopt OCM or Kobe Fleet they were doing this old way right kubby Cado into everybody",
    "start": "1856559",
    "end": "1863200"
  },
  {
    "text": "and then when you when you take care of over you want to make sure that you're not accidentally override something that",
    "start": "1863200",
    "end": "1869440"
  },
  {
    "text": "is specific for that cluster incident will happen so that's definitely something um I know the real admins are",
    "start": "1869440",
    "end": "1876080"
  },
  {
    "text": "worry about that's why we have those features right cool the third tiny question how does the authentication in",
    "start": "1876080",
    "end": "1882559"
  },
  {
    "text": "the demo is it just service accounts from cl from the hub talking to the spoke or is there other way around it's",
    "start": "1882559",
    "end": "1888960"
  },
  {
    "text": "the we both have this pool model so it's the agent member agent actually is",
    "start": "1888960",
    "end": "1894240"
  },
  {
    "text": "authenticated onto the hub cluster so the hub using different ways you can do",
    "start": "1894240",
    "end": "1900000"
  },
  {
    "text": "all kinds of if you're a cloud provider you can use oidc and get this uh um",
    "start": "1900000",
    "end": "1905600"
  },
  {
    "text": "federated identity things like that or you can use old-fashioned um secrets yeah similar as the cluster secrets in",
    "start": "1905600",
    "end": "1911840"
  },
  {
    "text": "Argo essentially yeah cool thank you very much you're welcome hey thank you for your talk i have a",
    "start": "1911840",
    "end": "1919519"
  },
  {
    "text": "think probably a very small question i noticed that the work API specs don't specify any resources so can you tell us",
    "start": "1919519",
    "end": "1926880"
  },
  {
    "text": "more a bit about like the scheduling and placement like of workload how do you handle like placement decision do you",
    "start": "1926880",
    "end": "1932799"
  },
  {
    "text": "kind of look into the manifest and every time evaluate the resources required to place the workload what do we do there",
    "start": "1932799",
    "end": "1939200"
  },
  {
    "text": "i'll leave with you the engineer so you know u so the idea is u work is uh",
    "start": "1939200",
    "end": "1944480"
  },
  {
    "text": "really um there's no intelligence at built into the work API the work API is a workhorse it it does whatever it is",
    "start": "1944480",
    "end": "1951679"
  },
  {
    "text": "told the intelligence is in the placement like we both demonstrated that the placement say you that's where we",
    "start": "1951679",
    "end": "1958880"
  },
  {
    "text": "pick where to put the stuff when we decided where to put we we just envelope them into a work API and that work",
    "start": "1958880",
    "end": "1965840"
  },
  {
    "text": "object will get blindly copied into this cluster that it needs to be so the intelligence is mostly on the placement",
    "start": "1965840",
    "end": "1972480"
  },
  {
    "text": "side all right thank you so much you're welcome hello hello thank you for the talk um so",
    "start": "1972480",
    "end": "1981200"
  },
  {
    "text": "is work intended to be a whole collection of resources that's deployed",
    "start": "1981200",
    "end": "1986640"
  },
  {
    "text": "to a cluster or can you have single piece of work that is split across",
    "start": "1986640",
    "end": "1992880"
  },
  {
    "text": "clusters as well yeah because we all know there's a 1.5 megabyte limit right",
    "start": "1992880",
    "end": "1998159"
  },
  {
    "text": "so if you want to place a lot of stuff you you have to you have to break it and uh for the work API is just designed to",
    "start": "1998159",
    "end": "2005200"
  },
  {
    "text": "hold individual ones if you you can put them say you have 10 pieces you can put them into one if they can hold or you",
    "start": "2005200",
    "end": "2010640"
  },
  {
    "text": "can put it into 10 different work work either way works although I probably don't want to put put it too fine grain",
    "start": "2010640",
    "end": "2017200"
  },
  {
    "text": "then as a human you have to manage it right you make it over complicated or too disastrous if it goes wrong you want",
    "start": "2017200",
    "end": "2024000"
  },
  {
    "text": "to make sure you you have that flexibility thank you very much you're welcome",
    "start": "2024000",
    "end": "2030840"
  },
  {
    "text": "hello uh thank you for the talk uh my question relates uh to what you said about",
    "start": "2031120",
    "end": "2036360"
  },
  {
    "text": "placements um it's it looked like placement",
    "start": "2036360",
    "end": "2041440"
  },
  {
    "text": "specification is statically defined so you're saying hey this cluster has got this much CPU or this much memory if",
    "start": "2041440",
    "end": "2047679"
  },
  {
    "text": "you're in a scenario where you're using something like Carpenter which is going to dynamically scale up based on the",
    "start": "2047679",
    "end": "2053358"
  },
  {
    "text": "workload that you're trying to put in it how is how are you going to choose the right cluster to go to",
    "start": "2053359",
    "end": "2059358"
  },
  {
    "text": "so one thing to correct it's not static so I can demo again if you run some",
    "start": "2059359",
    "end": "2065280"
  },
  {
    "text": "workload into one cluster you will see the available CPUs uh changed or reduced so it's not uh static there is actually",
    "start": "2065280",
    "end": "2073520"
  },
  {
    "text": "a lot of discussion in the sik about whether we want to keep those properties into cluster profile API because to us",
    "start": "2073520",
    "end": "2080878"
  },
  {
    "text": "those are very dynamic uh properties and we have initially we decided that uh for the about API we do not want to put in",
    "start": "2080879",
    "end": "2088000"
  },
  {
    "text": "any uh like Stephanie is there you can add more we do not want to put too dynamic uh properties into that so there",
    "start": "2088000",
    "end": "2095599"
  },
  {
    "text": "could be we don't from the sik level we don't have a solution for that from the koopy fleet side we basically uh collect",
    "start": "2095599",
    "end": "2102960"
  },
  {
    "text": "our agent sitting in the member cluster or workload collecting order metrics and we update that with a certain cadence so",
    "start": "2102960",
    "end": "2110079"
  },
  {
    "text": "that and I know OCM and other projects have their own way to solve that but on the sik level we don't have a solution",
    "start": "2110079",
    "end": "2116000"
  },
  {
    "text": "yet so if welcome to our sik meetings and propose any uh solutions to us uh that' be great and again we will have a",
    "start": "2116000",
    "end": "2122800"
  },
  {
    "text": "talk tomorrow afternoon about the sik APIs so that could be another good question there thank you very much uh I might",
    "start": "2122800",
    "end": "2130640"
  },
  {
    "text": "just go one more question as it wasn't a cute um where are you at with",
    "start": "2130640",
    "end": "2136240"
  },
  {
    "text": "integration with um gateway API at the moment because obviously you demonstrated there something that wasn't",
    "start": "2136240",
    "end": "2143280"
  },
  {
    "text": "really aligned with how gateway API works so where are the two talking a lot",
    "start": "2143280",
    "end": "2149839"
  },
  {
    "text": "I would say we talk I'm not sure if we talk a lot uh last time we talked um the",
    "start": "2149839",
    "end": "2155520"
  },
  {
    "text": "basic idea is exactly what I demonstrated but there are nitty-gritty details that like How do you actually",
    "start": "2155520",
    "end": "2161920"
  },
  {
    "text": "shift traffics between two same services um there are some um again nitty-gritty",
    "start": "2161920",
    "end": "2167520"
  },
  {
    "text": "details we still need to iron out but the idea is the same um and we should talk to network more or Yeah definitely",
    "start": "2167520",
    "end": "2173839"
  },
  {
    "text": "thank thank you for this uh reminder yeah thank you",
    "start": "2173839",
    "end": "2179559"
  },
  {
    "text": "uh hi there uh thanks for the talk uh uh can we use the placement to uh make sure",
    "start": "2179920",
    "end": "2186560"
  },
  {
    "text": "that different works are distributed across a fleet of clusters so that there",
    "start": "2186560",
    "end": "2192560"
  },
  {
    "text": "is uh um the distribution of the work different works are um more balanced",
    "start": "2192560",
    "end": "2199280"
  },
  {
    "text": "because a lot of times we have multiple clusters but each of those clusters are different in size uh can we actually use",
    "start": "2199280",
    "end": "2206160"
  },
  {
    "text": "this to maintain um balance the size of the clusters across uh across different",
    "start": "2206160",
    "end": "2211520"
  },
  {
    "text": "clusters the the answer is definitely yes um again this is not part of the u sik a",
    "start": "2211520",
    "end": "2219520"
  },
  {
    "text": "API in our individual uh projects we definitely have those ways depends on",
    "start": "2219520",
    "end": "2224640"
  },
  {
    "text": "how you want to rebalance right there are two ways to balance one is static balance so when you do the placement you",
    "start": "2224640",
    "end": "2230640"
  },
  {
    "text": "you find out all the clusters but clusters get out of balance after a while so you can also do dynamic balance",
    "start": "2230640",
    "end": "2237599"
  },
  {
    "text": "but all all these are not building to our current uh siguins kleet can handle that or we have different ways to handle",
    "start": "2237599",
    "end": "2244400"
  },
  {
    "text": "that and we have uh plans if you again you want to know more we can talk um uh",
    "start": "2244400",
    "end": "2249680"
  },
  {
    "text": "talk individually down there but uh um at a sick level we don't have a you",
    "start": "2249680",
    "end": "2254720"
  },
  {
    "text": "notice that we actually don't have a placement API yet uh we probably like to work towards that if uh if possible but",
    "start": "2254720",
    "end": "2261760"
  },
  {
    "text": "placement is a very complicated uh scenario just think imagine how kubernetes how many knobs you can turn",
    "start": "2261760",
    "end": "2268160"
  },
  {
    "text": "in kubernetes when you place uh pod right so so we still we're pretty far from getting to that standard uh yet but",
    "start": "2268160",
    "end": "2276320"
  },
  {
    "text": "I think hopefully that's the goal uh for this s multicluster again we need more",
    "start": "2276320",
    "end": "2281760"
  },
  {
    "text": "involvement because we do not want to uh basically decided for the community right we this is pretty much the",
    "start": "2281760",
    "end": "2287119"
  },
  {
    "text": "community center and placement across different environments right it's going to really depend where you are and what's best and so some of it needs to",
    "start": "2287119",
    "end": "2292960"
  },
  {
    "text": "be left really for the implementation um depending on where you want it so the at the product levels I know we're dealing",
    "start": "2292960",
    "end": "2298800"
  },
  {
    "text": "with it in certain ways because our type of product needs to be on metal or somewhere else So I'm curious to see",
    "start": "2298800",
    "end": "2305440"
  },
  {
    "text": "where that goes as far as placement it's like the last the fifth API there that isn't there the fifth API that kind of",
    "start": "2305440",
    "end": "2311599"
  },
  {
    "text": "supposed to rule them all and but it it takes some time to get there yeah i had",
    "start": "2311599",
    "end": "2316720"
  },
  {
    "text": "another question uh I see that OCM has uh uh the support for IRS for AWS uh now",
    "start": "2316720",
    "end": "2325760"
  },
  {
    "text": "I saw that in the latest release y um to run a hub on on EKS on EKS yes um I is",
    "start": "2325760",
    "end": "2333920"
  },
  {
    "text": "is that was was that like a is is Q fleet",
    "start": "2333920",
    "end": "2339359"
  },
  {
    "text": "and OCM kind of differ in that like how how these things are implemented when it comes to authentication and is there a",
    "start": "2339359",
    "end": "2346560"
  },
  {
    "text": "standard around that why was it missing in OCM before",
    "start": "2346560",
    "end": "2352240"
  },
  {
    "text": "why was it missing in OCM boy um well we needed someone to do the work uh we needed the AWS expertise to work with AM",
    "start": "2352240",
    "end": "2359359"
  },
  {
    "text": "that kind of stuff um there needs to be the resources to do the work and a",
    "start": "2359359",
    "end": "2364800"
  },
  {
    "text": "reason to run it there and that gets driven from different levels upstream downstream that kind of thing that's a tricky question to kind of answer openly",
    "start": "2364800",
    "end": "2372480"
  },
  {
    "text": "like that so yeah it it's nothing blocked it just resources and and the",
    "start": "2372480",
    "end": "2377599"
  },
  {
    "text": "the team that worked on it just wanted to tackle it and was a and had that knowledge of AWS to do it um we're",
    "start": "2377599",
    "end": "2383839"
  },
  {
    "text": "thrilled to see it running on there because obviously it runs nicely on Open Shift but you know the more we more",
    "start": "2383839",
    "end": "2389040"
  },
  {
    "text": "environments we can see it on the easier it is for for customers to to manage in those different environments i don't if",
    "start": "2389040",
    "end": "2395760"
  },
  {
    "text": "you have anything to add but unfortunately I cannot speak for OCM no but I mean on your side so Kub Fleet as",
    "start": "2395760",
    "end": "2402960"
  },
  {
    "text": "a as a open source project works on any Kubernetes so and uh it work on EKS GKE",
    "start": "2402960",
    "end": "2409760"
  },
  {
    "text": "AK AKS whatever yeah so it there's no um there's no um vendor it's basically",
    "start": "2409760",
    "end": "2415200"
  },
  {
    "text": "vendor neutral uh it does have a provider model just like a quanter so",
    "start": "2415200",
    "end": "2420560"
  },
  {
    "text": "welcome uh I don't know if any case GK folks are here welcome you to provide",
    "start": "2420560",
    "end": "2425920"
  },
  {
    "text": "implement a provider there so that it can seamlessly work on everything have all the features if you don't have a",
    "start": "2425920",
    "end": "2431839"
  },
  {
    "text": "provider some of the features like the property like the cost property is the provider that is only Azure member",
    "start": "2431839",
    "end": "2438960"
  },
  {
    "text": "member agents can provide that but uh if you running it on EKS GK you won't be able to get that thank you welcome",
    "start": "2438960",
    "end": "2448240"
  }
]
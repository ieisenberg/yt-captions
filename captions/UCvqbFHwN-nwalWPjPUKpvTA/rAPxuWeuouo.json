[
  {
    "text": "foreign",
    "start": "1140",
    "end": "4100"
  },
  {
    "text": "now let's get going thank you for joining us everyone welcome to today's cncf live webinar",
    "start": "14460",
    "end": "20539"
  },
  {
    "text": "Dynamic right sizing of kubernetes for cloud cost savings I'm Libby Schultz and",
    "start": "20539",
    "end": "25680"
  },
  {
    "text": "I'll be moderating today's webinar I'm going to read our code of conduct and then I will hand over to",
    "start": "25680",
    "end": "31740"
  },
  {
    "text": "varsha Nike devops engineer at Trigg and Chip Huang technical product marketing",
    "start": "31740",
    "end": "38160"
  },
  {
    "text": "manager at oci a few housekeeping items before we get started during the webinar you are not able to talk as an attendee",
    "start": "38160",
    "end": "45180"
  },
  {
    "text": "but you can leave all your questions in our chat box uh we will get to as many as we can at",
    "start": "45180",
    "end": "51780"
  },
  {
    "text": "the end this is an official webinar of cncf and as such is subject to the cncf",
    "start": "51780",
    "end": "57780"
  },
  {
    "text": "code of conduct please do not add anything to the chat or questions that would be in violation of that code of",
    "start": "57780",
    "end": "63719"
  },
  {
    "text": "conduct please be respectful of all of your fellow participants and presenters please also note that the recording and",
    "start": "63719",
    "end": "70200"
  },
  {
    "text": "slides will be posted later today to the cncf online programs page at",
    "start": "70200",
    "end": "75799"
  },
  {
    "text": "community.cncf.io under online programs and they're also available via your registration link the recording will",
    "start": "75799",
    "end": "83040"
  },
  {
    "text": "also be available on our online programs YouTube playlist and the cncf Channel with that I will hand it over to varsha",
    "start": "83040",
    "end": "90360"
  },
  {
    "text": "and Chip to kick off today's presentation take it away cool hey thanks Libby so my name is Chip Wong I'm",
    "start": "90360",
    "end": "97439"
  },
  {
    "text": "with work for cloud infrastructure and she didn't join paparta and ifm trade one of the large insurance and all of",
    "start": "97439",
    "end": "103079"
  },
  {
    "text": "Scandinavia to discuss a topic that's top of my for making of you when it comes to run your applications",
    "start": "103079",
    "end": "108740"
  },
  {
    "text": "kubernetes application cloud and that is the cheap customization for a cluster",
    "start": "108740",
    "end": "114000"
  },
  {
    "text": "without confidence performance application and that is why right side you kubernetes clouds are so important",
    "start": "114000",
    "end": "119220"
  },
  {
    "text": "because it's done right you can effectively achieve both of the objectives uh next slide please",
    "start": "119220",
    "end": "126860"
  },
  {
    "text": "so when we're talking about rice I think kubernetes cluster we really talk about two things the first of which is",
    "start": "128099",
    "end": "134280"
  },
  {
    "text": "allocating the right amount of resource for a cluster and this means the memory CPU it's important that Clips are not",
    "start": "134280",
    "end": "140280"
  },
  {
    "text": "resource around the application to ruin the application fitly but you don't want to over provision and waste resources so",
    "start": "140280",
    "end": "147660"
  },
  {
    "text": "by right-sizing kubernetes cluster you are saving money because you're only paying for a resource to utilize",
    "start": "147660",
    "end": "153360"
  },
  {
    "text": "the second aspect is really selecting the right type of Hardware in no types not all the applicants perform the same",
    "start": "153360",
    "end": "160379"
  },
  {
    "text": "some required more CPUs other requires more memory or more or are IO intensive or or require specialized Hardware in",
    "start": "160379",
    "end": "167640"
  },
  {
    "text": "order to run effectively so providing the right node type and write Hardware to your application you allow it to",
    "start": "167640",
    "end": "173760"
  },
  {
    "text": "perform optimally the third of which is really when you write a kubernetes cluster you maintain",
    "start": "173760",
    "end": "181440"
  },
  {
    "text": "a balance of every sort of different application and this belongs to the critical because it minimizes the",
    "start": "181440",
    "end": "187620"
  },
  {
    "text": "resource condition for application which can cause disability so if you write that equivalent study",
    "start": "187620",
    "end": "193800"
  },
  {
    "text": "effectively essentially your app your your cluster can operate more smoothly as well as become more stable",
    "start": "193800",
    "end": "202019"
  },
  {
    "text": "so a key aspect of right side kubernetes cluster it's really looking at the best way to scale",
    "start": "202019",
    "end": "209099"
  },
  {
    "text": "the application depending the application it might be using vertical products Taylor quartz and scaler or",
    "start": "209099",
    "end": "215760"
  },
  {
    "text": "composition mode but you're also looking for the right metrics in order to be able to get your application so just by",
    "start": "215760",
    "end": "221640"
  },
  {
    "text": "going through the exercise of Rights right cycling equivalent cluster you essentially make your applicants more",
    "start": "221640",
    "end": "227040"
  },
  {
    "text": "scalable it also allow to run more efficiently uh next slide please",
    "start": "227040",
    "end": "234140"
  },
  {
    "text": "but when when you write that in kubernetes cluster for the cloud it does come with some challenges well first of",
    "start": "235379",
    "end": "241440"
  },
  {
    "text": "which the word close in kubernetes is dynamic and the amount of resources May allocate to your application run",
    "start": "241440",
    "end": "247200"
  },
  {
    "text": "effectively will change it depending on the local application and because of the changes the way that you right size your",
    "start": "247200",
    "end": "254099"
  },
  {
    "text": "kubernetes cluster needs to dynamic as well so you need to just along with the lowdown application",
    "start": "254099",
    "end": "260579"
  },
  {
    "text": "and before you even start are able to write that here recruited cluster you really have to understand how your",
    "start": "260579",
    "end": "267720"
  },
  {
    "text": "research are being used by your application of cluster and that means you need to find the right right way to",
    "start": "267720",
    "end": "272880"
  },
  {
    "text": "monitor your monster cluster but what are the right tools and what to write methodology so these are some of the",
    "start": "272880",
    "end": "279180"
  },
  {
    "text": "things that's kind of hard to determine and also when you're right at the",
    "start": "279180",
    "end": "285120"
  },
  {
    "text": "terminal called it is complicated first of all you do need to understand how your applicant behave but even",
    "start": "285120",
    "end": "292740"
  },
  {
    "text": "knowing how to apps in your face you still need to understand for a Google cloud provider What hardware and what type of available so you can match it up",
    "start": "292740",
    "end": "299639"
  },
  {
    "text": "correctly and finally when you're doing on on when you do when",
    "start": "299639",
    "end": "306720"
  },
  {
    "text": "you're recycling through this cluster it can affect your performance application so you have to keep that in mind when",
    "start": "306720",
    "end": "312900"
  },
  {
    "text": "you're doing dynamic dynamic aside from this cluster so the methodology youth do",
    "start": "312900",
    "end": "318180"
  },
  {
    "text": "not interfere with the before the application so consider these challenges it's",
    "start": "318180",
    "end": "324960"
  },
  {
    "text": "crucial to address them effective efficiently and it's just like the topic today we have bartram's trig where we",
    "start": "324960",
    "end": "330300"
  },
  {
    "text": "share her experience on right to the group move kubernetes clustered and what she did for trig so",
    "start": "330300",
    "end": "336419"
  },
  {
    "text": "varsha I'll turn it over to you packaging hello this is Russia Nike a",
    "start": "336419",
    "end": "344160"
  },
  {
    "text": "devops engineer from trick for crink I also have my platform manager present",
    "start": "344160",
    "end": "349440"
  },
  {
    "text": "here pyoto haikovski again from trick he's one of our panelists today",
    "start": "349440",
    "end": "356100"
  },
  {
    "text": "so let's get started actually before we get started let's",
    "start": "356100",
    "end": "361380"
  },
  {
    "text": "talk a little about who we are yes scandinavia's largest non-life insurance company we headquartered in bellhope",
    "start": "361380",
    "end": "368280"
  },
  {
    "text": "Denmark we have over 5.3 million customers and over 7 000 employees",
    "start": "368280",
    "end": "375360"
  },
  {
    "text": "where do we stand in the market position in the whole of Scandinavia we hold the top three Market positions spread across",
    "start": "375360",
    "end": "383240"
  },
  {
    "text": "Denmark Norway and Sweden and in no and in Denmark we hold the highest position",
    "start": "383240",
    "end": "388520"
  },
  {
    "text": "we have a broad variety of insurance products made available to our customers",
    "start": "388520",
    "end": "394500"
  },
  {
    "text": "and it is spread across various business sectors for example in the private",
    "start": "394500",
    "end": "399539"
  },
  {
    "text": "sectors we have accident Insurance home insurance pet insurance health insurance",
    "start": "399539",
    "end": "405000"
  },
  {
    "text": "and various others we have a commercial sector where we have insurance for small",
    "start": "405000",
    "end": "410460"
  },
  {
    "text": "and medium scale uh businesses we have a workers liability insurance property",
    "start": "410460",
    "end": "415800"
  },
  {
    "text": "insurance motor insurance and likewise and when it comes to corporate sector we",
    "start": "415800",
    "end": "421259"
  },
  {
    "text": "also have group life insurance including property insurance transport",
    "start": "421259",
    "end": "426960"
  },
  {
    "text": "insurance and the like so what I'm trying to stress upon is we",
    "start": "426960",
    "end": "432180"
  },
  {
    "text": "have a huge variety of insurance products that are made available across various different business sectors",
    "start": "432180",
    "end": "439860"
  },
  {
    "text": "and which means we have a huge amount of data flowing in at real time both",
    "start": "439860",
    "end": "445620"
  },
  {
    "text": "structured and unstructured and what we have to do is we we have to collect them",
    "start": "445620",
    "end": "451500"
  },
  {
    "text": "from various different sources and many of these sources have density of data in terabytes we have to structure them we",
    "start": "451500",
    "end": "459120"
  },
  {
    "text": "have to model them as per the Accord standard for insurance we have to centralize and streamline this data and",
    "start": "459120",
    "end": "465960"
  },
  {
    "text": "make it available at one place at real time so that we can feed our analytical and business intelligence services and",
    "start": "465960",
    "end": "474120"
  },
  {
    "text": "also to our stps straight through processes this is just to ensure that we improve the customer experience and also",
    "start": "474120",
    "end": "481759"
  },
  {
    "text": "fasten the process of insurance itself of course this involves a lot of",
    "start": "481759",
    "end": "487380"
  },
  {
    "text": "Technologies and all the applications are to be deployed on kubernetes and that's what we are trying to achieve",
    "start": "487380",
    "end": "493740"
  },
  {
    "text": "today so the agenda for this session would be will first uh try to have a quick view",
    "start": "493740",
    "end": "501240"
  },
  {
    "text": "of how we do a deployment a quick overview of that and then we talk about",
    "start": "501240",
    "end": "506340"
  },
  {
    "text": "the challenges that we initially faced there were quite a few I'll try to touch upon the major ones",
    "start": "506340",
    "end": "512820"
  },
  {
    "text": "and we'll talk about the solutions Solutions as in what we did to actually right size our cumulative cluster so",
    "start": "512820",
    "end": "520320"
  },
  {
    "text": "there are actually spread across two stages one is we have to right size the",
    "start": "520320",
    "end": "525660"
  },
  {
    "text": "worker nodes involved in the kubernetes cluster and the second way is we have Auto",
    "start": "525660",
    "end": "531360"
  },
  {
    "text": "scaling various techniques of Auto scaling that we have leveraged in order to optimize the utilization and save",
    "start": "531360",
    "end": "537360"
  },
  {
    "text": "cost and finally we would be glad to share the statistics and the results that we",
    "start": "537360",
    "end": "543480"
  },
  {
    "text": "have achieved uh before and after we did these optimizations and a quick summary",
    "start": "543480",
    "end": "551839"
  },
  {
    "text": "so coming to the deployment overview we are using of course Oracle cloud and we",
    "start": "552420",
    "end": "558600"
  },
  {
    "text": "have oracle's kubernetes engine that's orchestrated using terraform which is",
    "start": "558600",
    "end": "564180"
  },
  {
    "text": "infrastructure as a code we use this because it's easiest easy for us to collaborate within the team",
    "start": "564180",
    "end": "570720"
  },
  {
    "text": "and also maintain the code and we have Cloud native applications",
    "start": "570720",
    "end": "575839"
  },
  {
    "text": "deployed as containers inside parts of the kubernetes and this is done using",
    "start": "575839",
    "end": "580980"
  },
  {
    "text": "Helm charts using gitlab cicd Pipelines and to start with we used a basic",
    "start": "580980",
    "end": "587519"
  },
  {
    "text": "standard VM that was made available in oracle's VM list and we try to deploy",
    "start": "587519",
    "end": "594240"
  },
  {
    "text": "all the applications onto the same type of nodes in the node pool",
    "start": "594240",
    "end": "599640"
  },
  {
    "text": "thank you now talking about the challenges that we faced with this architecture",
    "start": "599640",
    "end": "604860"
  },
  {
    "text": "we had workloads reading with CPU hungry workloads we had few memory hungry",
    "start": "604860",
    "end": "611459"
  },
  {
    "text": "workloads we had few performance intensive workloads and we understood that we could not put all of these",
    "start": "611459",
    "end": "618180"
  },
  {
    "text": "application Parts under one umbrella and have the same host or same host note for",
    "start": "618180",
    "end": "624480"
  },
  {
    "text": "all of these applications the second issue being we have a huge",
    "start": "624480",
    "end": "630540"
  },
  {
    "text": "deployment a huge scale of deployment and every deployment of every kubernetes",
    "start": "630540",
    "end": "636120"
  },
  {
    "text": "cluster will comprise of at least two thousand hundred odd number of pots so",
    "start": "636120",
    "end": "641880"
  },
  {
    "text": "this would basically mean that we are stressing the underlying host quite a lot and we hit a few edge cases and to",
    "start": "641880",
    "end": "648720"
  },
  {
    "text": "get around it we had to use few customization scripts and this we were able to achieve using something called",
    "start": "648720",
    "end": "655200"
  },
  {
    "text": "Cloud init Cloud init is basically a customization scripts that you can run as soon as the",
    "start": "655200",
    "end": "662160"
  },
  {
    "text": "VM comes up and of course this is not available in all Cloud platforms but they are available in of course Oracle",
    "start": "662160",
    "end": "669600"
  },
  {
    "text": "okay uh Google's GK and Amazon's eks",
    "start": "669600",
    "end": "676519"
  },
  {
    "text": "uh what for example how we use this cloud and it was we wanted to change few",
    "start": "676519",
    "end": "681660"
  },
  {
    "text": "arguments in the cubelet service of all the worker nodes for example we have wanted to increase the system reserved",
    "start": "681660",
    "end": "688800"
  },
  {
    "text": "resources of uh the node itself on every worker node and this we were able to",
    "start": "688800",
    "end": "694560"
  },
  {
    "text": "achieve using the cloud init script and then coming to the third point we",
    "start": "694560",
    "end": "699779"
  },
  {
    "text": "had a diversified workload as in the uh there were busy hours and there were",
    "start": "699779",
    "end": "706320"
  },
  {
    "text": "idle times in our workload and we had over committed the resources to cater to",
    "start": "706320",
    "end": "711600"
  },
  {
    "text": "the busy hours alone and this meant that when the load is basically idle we were",
    "start": "711600",
    "end": "717060"
  },
  {
    "text": "still paying for the same amount of resources regardless and that was costing us too much and of",
    "start": "717060",
    "end": "723899"
  },
  {
    "text": "course like every other business we also had budget constraints and we had to bring down the cost somehow",
    "start": "723899",
    "end": "731839"
  },
  {
    "text": "so I keep stressing about we have huge large deployment and a huge scale of",
    "start": "732320",
    "end": "738060"
  },
  {
    "text": "deployment so this basically means that for every kubernetes cluster that we have in our",
    "start": "738060",
    "end": "743459"
  },
  {
    "text": "production environment we have approximately 5000 vcpus approximately 13 terabytes of memory 300 or terabytes",
    "start": "743459",
    "end": "752399"
  },
  {
    "text": "of storage and 200 250 number of parts and this is for one kubernetes cluster",
    "start": "752399",
    "end": "760140"
  },
  {
    "text": "and one production deployment and we have at least four of them running at any given instance so there was a huge",
    "start": "760140",
    "end": "767700"
  },
  {
    "text": "dirt near need of optimizing the cost and the resources here",
    "start": "767700",
    "end": "774480"
  },
  {
    "text": "so we started with right sizing our worker nodes we try to explore what options to our Cloud providers provide",
    "start": "774480",
    "end": "783360"
  },
  {
    "text": "so apart from just selecting the host OS type or the flavor we also thought about",
    "start": "783360",
    "end": "790079"
  },
  {
    "text": "the processors that are used by the compute instances so for example at",
    "start": "790079",
    "end": "796860"
  },
  {
    "text": "least in our project we had few Java applications which were AMD 64 based and",
    "start": "796860",
    "end": "803040"
  },
  {
    "text": "we had Kafka clusters also deployed as Bots within the cluster uh using the",
    "start": "803040",
    "end": "808500"
  },
  {
    "text": "stream Z operator and we used amt64 based compute nodes for this and we have",
    "start": "808500",
    "end": "814200"
  },
  {
    "text": "few other Java applications like in the second box where arm 64 piece the images",
    "start": "814200",
    "end": "819720"
  },
  {
    "text": "were created and we could easily deploy them onto the erm64 compute nodes the",
    "start": "819720",
    "end": "826079"
  },
  {
    "text": "advantage of this is if they have highly performant and also they are fairly cheaper in comparison with the AMD 64",
    "start": "826079",
    "end": "833100"
  },
  {
    "text": "ones and these arm 64bs compute instances are available in most major",
    "start": "833100",
    "end": "839040"
  },
  {
    "text": "Cloud platform speed Azure Google Oracle of course and Amazon",
    "start": "839040",
    "end": "845880"
  },
  {
    "text": "so we could leverage that wherever possible and then we had a special requirement",
    "start": "845880",
    "end": "850980"
  },
  {
    "text": "for running a database as a part inside the kubernetes cluster now you would ask",
    "start": "850980",
    "end": "856860"
  },
  {
    "text": "me why this is because we wanted our applications to be able to talk to our",
    "start": "856860",
    "end": "862500"
  },
  {
    "text": "database as much as possible and as frequently as possible without incurring",
    "start": "862500",
    "end": "868320"
  },
  {
    "text": "much of a latency and Oracle of course provides a VM type",
    "start": "868320",
    "end": "874620"
  },
  {
    "text": "or VM shape which has a local disk attached to it an nvme based SSD",
    "start": "874620",
    "end": "881880"
  },
  {
    "text": "attached to it of course this is not available in all of the cloud platforms",
    "start": "881880",
    "end": "888000"
  },
  {
    "text": "but it is available in Google's GK and Amazon's eks so you could search for",
    "start": "888000",
    "end": "895380"
  },
  {
    "text": "ephemeral storage local SSD in Google's gke or you could search for local disk",
    "start": "895380",
    "end": "901800"
  },
  {
    "text": "provisioning in eks furthermore most of the cloud providers",
    "start": "901800",
    "end": "907620"
  },
  {
    "text": "have these demarcations of various VM types they have CPU intensive memory",
    "start": "907620",
    "end": "913199"
  },
  {
    "text": "intensive and I O intensive sometimes even balanced types of VMS we could",
    "start": "913199",
    "end": "918660"
  },
  {
    "text": "select our VM types of the underlying host based on our workload necessity",
    "start": "918660",
    "end": "925079"
  },
  {
    "text": "furthermore now that we have chosen the nodes to deploy on we now have to make",
    "start": "925079",
    "end": "931260"
  },
  {
    "text": "sure that the pots every part that we have application Port goes to the right",
    "start": "931260",
    "end": "936360"
  },
  {
    "text": "or stipulated notes worker node and to",
    "start": "936360",
    "end": "941699"
  },
  {
    "text": "make sure uh this happens we use kubernetes node Affinity node selectors",
    "start": "941699",
    "end": "947760"
  },
  {
    "text": "stains and tolerations and talking about arm 64 again we were",
    "start": "947760",
    "end": "954360"
  },
  {
    "text": "able to build ERM 64 based images using the same Docker multi-architecture",
    "start": "954360",
    "end": "959699"
  },
  {
    "text": "Builder called build X so in case you're interested",
    "start": "959699",
    "end": "965220"
  },
  {
    "text": "furthermore now that we've decided that the flavor is so and so and we have this",
    "start": "965220",
    "end": "970620"
  },
  {
    "text": "type of VMS to select from we also have to consider how do we architect our",
    "start": "970620",
    "end": "976620"
  },
  {
    "text": "kubernetes cluster itself so from our learnings we suggest that we should have",
    "start": "976620",
    "end": "981779"
  },
  {
    "text": "a discrete node pool planning basically meaning that every node pool should",
    "start": "981779",
    "end": "986820"
  },
  {
    "text": "serve just one purpose and one kind of workload it will be easier to manage and",
    "start": "986820",
    "end": "992100"
  },
  {
    "text": "also makes more sense this way consider I choose a very huge node with",
    "start": "992100",
    "end": "998519"
  },
  {
    "text": "a very huge amount of memory in CPU and say I will deploy all my parts onto this node",
    "start": "998519",
    "end": "1004160"
  },
  {
    "text": "there is a disadvantage to this which is if we have block volumes or volumes",
    "start": "1004160",
    "end": "1009440"
  },
  {
    "text": "attached to the pods in these nodes there's a limitation on the number of volumes that can be attached to every",
    "start": "1009440",
    "end": "1015800"
  },
  {
    "text": "instance compute instance and this is true for all the cloud platforms so we'll have to watch out for that if I",
    "start": "1015800",
    "end": "1022220"
  },
  {
    "text": "see if I take the Other Extreme wherein I have a very small note worker node with very small amount of CPU and memory",
    "start": "1022220",
    "end": "1029178"
  },
  {
    "text": "and I try try to have the same set of PODS to be deployed then I'll need more",
    "start": "1029179",
    "end": "1034339"
  },
  {
    "text": "of these worker nodes which would mean I'll have more worker notes and I'll need more number of ips and there is a",
    "start": "1034339",
    "end": "1041178"
  },
  {
    "text": "chance that I can run out of the IP assignment for the worker nodes itself in the kubernetes cluster",
    "start": "1041179",
    "end": "1046520"
  },
  {
    "text": "so we'll have to watch out for that as well of course not all Cloud providers have",
    "start": "1046520",
    "end": "1052040"
  },
  {
    "text": "this flexibility of selecting the memory to CPU ratio Oracle provides it in the",
    "start": "1052040",
    "end": "1058280"
  },
  {
    "text": "form of flex uh virtual machines but few other Cloud providers for example Azure",
    "start": "1058280",
    "end": "1064100"
  },
  {
    "text": "provides an exhaustive list of standard VM shapes and sizes to choose from so",
    "start": "1064100",
    "end": "1069799"
  },
  {
    "text": "that also will help in choosing the right size for your kind of workload",
    "start": "1069799",
    "end": "1076460"
  },
  {
    "text": "of course we suggest that we have a limited set of node pools so that it is",
    "start": "1076460",
    "end": "1082039"
  },
  {
    "text": "easier for us to manage every kubernetes cluster",
    "start": "1082039",
    "end": "1087159"
  },
  {
    "text": "all right so now that we have decided on what host to deploy our ports on let's",
    "start": "1087200",
    "end": "1092419"
  },
  {
    "text": "Venture into Auto scaling and just before we start with auto scaling I would like to give a prerequisite for",
    "start": "1092419",
    "end": "1099140"
  },
  {
    "text": "the scaling which is called a metric server this is basically a server that is to be",
    "start": "1099140",
    "end": "1104600"
  },
  {
    "text": "deployed as an add-on in most of the cloud providers a metric server will basically collect",
    "start": "1104600",
    "end": "1110960"
  },
  {
    "text": "the container resource metrics from all the cubelets in the worker nodes and",
    "start": "1110960",
    "end": "1116960"
  },
  {
    "text": "then send them to the kubernetes API server and that becomes available to all our autoscalers beat horizontal vertical",
    "start": "1116960",
    "end": "1124580"
  },
  {
    "text": "or cloud. or cluster Auto scalar so that's kind of a prerequisites it's also",
    "start": "1124580",
    "end": "1130160"
  },
  {
    "text": "used when you try to use a cube CTL top command it results in how how much of",
    "start": "1130160",
    "end": "1136039"
  },
  {
    "text": "CPU and the memory every pod is utilizing you get to see all those stats if you try to install the metric server",
    "start": "1136039",
    "end": "1144620"
  },
  {
    "text": "now let's Venture into the first kind of Auto scaling which is horizontal power to scalar in as the name suggests it",
    "start": "1144620",
    "end": "1152240"
  },
  {
    "text": "tries to scale out the number of replicas of a particular controller horizontally as in when the lower is",
    "start": "1152240",
    "end": "1159200"
  },
  {
    "text": "high tries to increase the number of pod replicas belonging to a particular deployment or a stateful set and the",
    "start": "1159200",
    "end": "1165140"
  },
  {
    "text": "load when the load decreases it tries to scale down again and there are two ways you can do this",
    "start": "1165140",
    "end": "1171140"
  },
  {
    "text": "one way is using the CPU and the memory based on how much CPU or memory every uh",
    "start": "1171140",
    "end": "1177740"
  },
  {
    "text": "deployment or part in every deployment is using it scales out or scales in the",
    "start": "1177740",
    "end": "1183200"
  },
  {
    "text": "other way is to use a custom metrics custom metrics as in your application Port will export some metrics which",
    "start": "1183200",
    "end": "1191299"
  },
  {
    "text": "makes sense of cost to the horizontal port at a scalar to the Prometheus",
    "start": "1191299",
    "end": "1196400"
  },
  {
    "text": "server which is installed maybe on the cumulative cluster itself or somewhere",
    "start": "1196400",
    "end": "1201440"
  },
  {
    "text": "outside and then using these metrics the Prometheus adapter makes these metrics",
    "start": "1201440",
    "end": "1207020"
  },
  {
    "text": "available to the horizontal power autoscaler as a feedback loop and the horizontal part of the scale then",
    "start": "1207020",
    "end": "1212780"
  },
  {
    "text": "decides if it has to scale out or scale in so there are two ways of using horizontal part of the scalar and",
    "start": "1212780",
    "end": "1219919"
  },
  {
    "text": "there's just a note that you have to consider if you're using a horizontal border to scalar with CPU and memory you",
    "start": "1219919",
    "end": "1227000"
  },
  {
    "text": "will not be able to use vertical port or to scalar so if you're using custom metrics",
    "start": "1227000",
    "end": "1232940"
  },
  {
    "text": "horizontal port or to scalar then you can use vertical powder to scalar we'll get to what is vertical part of the",
    "start": "1232940",
    "end": "1239360"
  },
  {
    "text": "scalar a little later in the slides I just thought I will do mention here as well",
    "start": "1239360",
    "end": "1245919"
  },
  {
    "text": "okay before we talk about this graph I'll just give up a few introduction to",
    "start": "1246620",
    "end": "1251660"
  },
  {
    "text": "this graph itself this is a Custom Tool uh which is derived which drives all the",
    "start": "1251660",
    "end": "1257840"
  },
  {
    "text": "metrics and the stats from our OK or kubernetes engine cluster and this is",
    "start": "1257840",
    "end": "1264080"
  },
  {
    "text": "collected from our production environment so I will be showing you many such",
    "start": "1264080",
    "end": "1269660"
  },
  {
    "text": "crafts and they are all collected from our production environment and uh this",
    "start": "1269660",
    "end": "1275000"
  },
  {
    "text": "is in congruence with the deployment chart that we showed initially with 2000 art parts and uh 300 uh terabytes of",
    "start": "1275000",
    "end": "1283760"
  },
  {
    "text": "storage so here you can see on the x-axis it is time and then the y-axis",
    "start": "1283760",
    "end": "1289159"
  },
  {
    "text": "you can see the number of PODS and with time you can see the number of ports are varying because the workload is",
    "start": "1289159",
    "end": "1295220"
  },
  {
    "text": "demanding so you can see that at one point it went below 350 and at one point it even went",
    "start": "1295220",
    "end": "1302120"
  },
  {
    "text": "beyond 400. so uh we see that this is varying with time as opposed to a",
    "start": "1302120",
    "end": "1310039"
  },
  {
    "text": "parallel line parallel to the x-axis as it was earlier before horizontal part of",
    "start": "1310039",
    "end": "1315740"
  },
  {
    "text": "the scalar was introduced now with this are we saving anything no unfortunately because we are only",
    "start": "1315740",
    "end": "1322880"
  },
  {
    "text": "waiting the number of pots in the cluster doesn't mean that we are changing anything with regard to nodes",
    "start": "1322880",
    "end": "1329120"
  },
  {
    "text": "the nodes are still static and that's what we pay for so unfortunately with",
    "start": "1329120",
    "end": "1334159"
  },
  {
    "text": "just horizontal pod Auto scalar we're not achieving cost savings",
    "start": "1334159",
    "end": "1340000"
  },
  {
    "text": "so let's bring in cluster Auto scaler so to explain this I'll just take an",
    "start": "1340000",
    "end": "1346220"
  },
  {
    "text": "example let's consider Node 1 and node 2 of the same size for our uh for our",
    "start": "1346220",
    "end": "1352940"
  },
  {
    "text": "convenience let's say that we can accommodate a maximum of three parts of the same type",
    "start": "1352940",
    "end": "1358460"
  },
  {
    "text": "and both Node 1 and node 2 are occupied right so now let's consider there are",
    "start": "1358460",
    "end": "1363980"
  },
  {
    "text": "two more parts trying to get scheduled on the same cluster now the cluster Auto scalar senses this and starts a new node",
    "start": "1363980",
    "end": "1371539"
  },
  {
    "text": "or Provisions a new node and then deploys these two nodes these two parts Part 7 and part 8 onto those notes",
    "start": "1371539",
    "end": "1379460"
  },
  {
    "text": "and this is how the upscaling works in cluster Auto scalar and downscaling again when we consider the same Node 1",
    "start": "1379460",
    "end": "1387320"
  },
  {
    "text": "node 2 and node 3. let's see node 2 and node 3 are running uh are not optimally",
    "start": "1387320",
    "end": "1394159"
  },
  {
    "text": "used and they have enough capacity to accommodate two more parts of the same type",
    "start": "1394159",
    "end": "1399799"
  },
  {
    "text": "then cluster Auto scalar science is this again and then it marks one of the nodes for deletion and then tries to move that",
    "start": "1399799",
    "end": "1407480"
  },
  {
    "text": "part or scheduled on that note to the node 2. as you can see in this figure",
    "start": "1407480",
    "end": "1413780"
  },
  {
    "text": "and then it will try to delete the note 3. this is provided the Pod disruptor the constraints like poor disruption",
    "start": "1413780",
    "end": "1420559"
  },
  {
    "text": "budgets are all of the scene so there are few constraints on which the cloud",
    "start": "1420559",
    "end": "1426020"
  },
  {
    "text": "cluster test killer acts but then if there are no Port just uh though there are no constraints it will try to",
    "start": "1426020",
    "end": "1432260"
  },
  {
    "text": "reschedule the pots based on which node can accommodate it and then try to reduce the number of nodes",
    "start": "1432260",
    "end": "1440380"
  },
  {
    "text": "of course cluster Auto scalar is provided out of the box in few of the cloud provider Cloud platforms like",
    "start": "1441080",
    "end": "1446960"
  },
  {
    "text": "azure and there we can we have the Liberty to choose the minimum and the maximum",
    "start": "1446960",
    "end": "1453440"
  },
  {
    "text": "number of cloud notes in every node pool and that's the maximum we can configure",
    "start": "1453440",
    "end": "1459640"
  },
  {
    "text": "but there are a few other clouds a cloud platforms like Oracle where we will have",
    "start": "1459640",
    "end": "1465740"
  },
  {
    "text": "to install it as an add-on and this gives us the liberty to choose or fine",
    "start": "1465740",
    "end": "1470900"
  },
  {
    "text": "tune the class starter scaler for our needs I have just tried to highlight few",
    "start": "1470900",
    "end": "1476780"
  },
  {
    "text": "of the flags that we have configured and tweaked with just to make sure that they",
    "start": "1476780",
    "end": "1482120"
  },
  {
    "text": "fit our needs better so I'll just quickly take a few examples here for",
    "start": "1482120",
    "end": "1487220"
  },
  {
    "text": "example you can see this scale down utilization threshold which will tell the cluster Auto scaler how much of the",
    "start": "1487220",
    "end": "1494360"
  },
  {
    "text": "utilization should a node be uh using before you try to scale down that node",
    "start": "1494360",
    "end": "1500720"
  },
  {
    "text": "so before you consider to scale down that particular node and you can also",
    "start": "1500720",
    "end": "1505760"
  },
  {
    "text": "specify how much time uh you give up node particular node to get provision",
    "start": "1505760",
    "end": "1511220"
  },
  {
    "text": "and come up to the ready State here we have just kept as 15 minutes there are",
    "start": "1511220",
    "end": "1517340"
  },
  {
    "text": "many such parameters that you can play around with and you can find that on the GitHub repository of course you can also",
    "start": "1517340",
    "end": "1524539"
  },
  {
    "text": "select the node pools on which the cluster Auto Scala should act and you",
    "start": "1524539",
    "end": "1530299"
  },
  {
    "text": "can also provide the minimum and the maximum note count for that node pool alone so this way you can pick every",
    "start": "1530299",
    "end": "1538700"
  },
  {
    "text": "node pool that is to be monitored under cluster autoscaler",
    "start": "1538700",
    "end": "1544419"
  },
  {
    "text": "now this graph is together with a horizontal portal to scalar and cluster",
    "start": "1544940",
    "end": "1550159"
  },
  {
    "text": "to scalar this is what we achieve this is a similar graph provided from the",
    "start": "1550159",
    "end": "1555200"
  },
  {
    "text": "same tool but on the y-axis you now see the node counts the number of nodes in the node",
    "start": "1555200",
    "end": "1561080"
  },
  {
    "text": "pool so you can see initially the node count went up to 100 and then it gradually",
    "start": "1561080",
    "end": "1567260"
  },
  {
    "text": "tried to reduce and it stabilized at around 60. this is because in our workload uh we",
    "start": "1567260",
    "end": "1575059"
  },
  {
    "text": "have initial since we are DNA of course data and analytics we have a huge amount",
    "start": "1575059",
    "end": "1580220"
  },
  {
    "text": "of historical data to be loaded initially and then when it gradually gets to the current time of CDC then the",
    "start": "1580220",
    "end": "1587600"
  },
  {
    "text": "load is pretty much stable so that's how you can see the node uh",
    "start": "1587600",
    "end": "1592940"
  },
  {
    "text": "count goes up and down and are we saving anything here cost twice and the answer is yes because",
    "start": "1592940",
    "end": "1600500"
  },
  {
    "text": "notes are what we pay for and if we see lesser number of nodes of course we are paying for lesser number of them",
    "start": "1600500",
    "end": "1607580"
  },
  {
    "text": "as opposed to having a street land parallel to the YX x-axis and we would",
    "start": "1607580",
    "end": "1613159"
  },
  {
    "text": "have to pay for all 100 of them at all given times so this is an advantage but is this",
    "start": "1613159",
    "end": "1619159"
  },
  {
    "text": "enough our graph C otherwise and these are graphs taken from the CPU",
    "start": "1619159",
    "end": "1625700"
  },
  {
    "text": "and the memory stats of scene production clusters same workload and at the same time",
    "start": "1625700",
    "end": "1631940"
  },
  {
    "text": "well let me talk about a few things in this graph for CPU the X Y axis denotes",
    "start": "1631940",
    "end": "1638840"
  },
  {
    "text": "the number of cores and for memory the y-axis denotes the number of gigabytes",
    "start": "1638840",
    "end": "1643940"
  },
  {
    "text": "of memory with time of course and the green the red line indicates the actual",
    "start": "1643940",
    "end": "1650960"
  },
  {
    "text": "utilization of the resources of a of the pots put together and the blue line in the case the",
    "start": "1650960",
    "end": "1657860"
  },
  {
    "text": "resource requests of every pod man in the Manifest file",
    "start": "1657860",
    "end": "1662900"
  },
  {
    "text": "of course this is like a det mining factor for the cluster Auto scalar to scale up or scale down the number of",
    "start": "1662900",
    "end": "1668779"
  },
  {
    "text": "nodes because this is a guaranteed amount of resources that we guarantee to the user so this is what we pay for and",
    "start": "1668779",
    "end": "1676940"
  },
  {
    "text": "this is what we utilize you can see a huge difference between these two and you might ask me why",
    "start": "1676940",
    "end": "1683720"
  },
  {
    "text": "the answer is if I am a developer and I have an app and I have to deploy this",
    "start": "1683720",
    "end": "1689179"
  },
  {
    "text": "app I would give the port manifest in such a way that the resource request is",
    "start": "1689179",
    "end": "1695000"
  },
  {
    "text": "high or it caters to the busy hours of my application and I'll give a little I keep a little",
    "start": "1695000",
    "end": "1701419"
  },
  {
    "text": "bit of buffer beyond that because it's an estimate at the end of the day right and this is for one app and we are",
    "start": "1701419",
    "end": "1708559"
  },
  {
    "text": "talking about 2150 parts and we when we put all the",
    "start": "1708559",
    "end": "1714140"
  },
  {
    "text": "all of them together this is the cumulative disaster we have a huge difference between the utilization and",
    "start": "1714140",
    "end": "1720380"
  },
  {
    "text": "the requests and we are paying for the requests by the way and vertical part of the Skiller comes",
    "start": "1720380",
    "end": "1727820"
  },
  {
    "text": "to our rescue again vertical part of the scalar together with horizontal Paratus killer",
    "start": "1727820",
    "end": "1733700"
  },
  {
    "text": "can work only when a horizontal part of the scalar works on the customers custom",
    "start": "1733700",
    "end": "1739159"
  },
  {
    "text": "metrics and not CPU or memory now let's consider vertical power Auto",
    "start": "1739159",
    "end": "1745400"
  },
  {
    "text": "scalar as opposed to horizontal part of the scale which increases or decreases the",
    "start": "1745400",
    "end": "1752179"
  },
  {
    "text": "number of replicas of a particular pod increases the size",
    "start": "1752179",
    "end": "1758539"
  },
  {
    "text": "of the part itself so when I see the size it basically means the CPU and the memory requested",
    "start": "1758539",
    "end": "1765559"
  },
  {
    "text": "by a part is increased based on the actual part utilization",
    "start": "1765559",
    "end": "1770659"
  },
  {
    "text": "this is done on a regular interval of course that's configurable and in",
    "start": "1770659",
    "end": "1776120"
  },
  {
    "text": "steps which is also configurable in the vertical part of the scalar so in this diagram what I try to show is first we",
    "start": "1776120",
    "end": "1783799"
  },
  {
    "text": "start off with a minimum CPU and the memory that is configured by the user for the vertical part of the scalar you",
    "start": "1783799",
    "end": "1790159"
  },
  {
    "text": "can also configure a limit sorry about that so well it started with vertical power",
    "start": "1790159",
    "end": "1797360"
  },
  {
    "text": "to scalar I'm hoping uh we got through this slide where I discuss why we need",
    "start": "1797360",
    "end": "1803120"
  },
  {
    "text": "vpa so we see that the utilization and the requested resource is way off and we",
    "start": "1803120",
    "end": "1809419"
  },
  {
    "text": "have to bridge this Gap and vpe comes to RSQ uh vpa together",
    "start": "1809419",
    "end": "1816020"
  },
  {
    "text": "with hpe can be used only when HPA is used with custom metrics and not with",
    "start": "1816020",
    "end": "1821360"
  },
  {
    "text": "CPU or memory and PPE as opposed to hpe where the number of ports broad replicas gets",
    "start": "1821360",
    "end": "1828860"
  },
  {
    "text": "scaled up and scaled down PPE tries to increase the size of the Pod itself when",
    "start": "1828860",
    "end": "1833899"
  },
  {
    "text": "I say the size it is CPU and the memory requested by the port is increase based",
    "start": "1833899",
    "end": "1838940"
  },
  {
    "text": "on the actual utilization of the pod and this is done in regular intervals",
    "start": "1838940",
    "end": "1844760"
  },
  {
    "text": "which is configurable and also in steps which is also configurable just for the",
    "start": "1844760",
    "end": "1850460"
  },
  {
    "text": "sake of Simplicity I have chosen some random numbers to depict how this works",
    "start": "1850460",
    "end": "1856159"
  },
  {
    "text": "so initially you have to set a minimum and the maximum number of CPU and memory",
    "start": "1856159",
    "end": "1861559"
  },
  {
    "text": "that vpa can play with and then it will start with the minimum configured CPU",
    "start": "1861559",
    "end": "1867200"
  },
  {
    "text": "and memory on the Pod and as as and when it senses that the Pod is utilizing more than this it steps up and it tries to",
    "start": "1867200",
    "end": "1875059"
  },
  {
    "text": "increase this requested CPU and memory and steps up further again based on requirement and scale down is also",
    "start": "1875059",
    "end": "1881899"
  },
  {
    "text": "happening in the same steps and at the same regular intervals that's configured in the vertical product is killer",
    "start": "1881899",
    "end": "1888620"
  },
  {
    "text": "now this is of course added as an add-on installed as an add-on in the kubernetes cluster and here I have started to just",
    "start": "1888620",
    "end": "1896240"
  },
  {
    "text": "share a few flags that might be of use to you of course there are many others that can be",
    "start": "1896240",
    "end": "1903200"
  },
  {
    "text": "found in the gitlab repo but these are the few which we would like to highlight and you can ignore these numbers that we",
    "start": "1903200",
    "end": "1910220"
  },
  {
    "text": "have configured because we had to do few iterations to get to these numbers and so will you uh because it'll if you have",
    "start": "1910220",
    "end": "1918140"
  },
  {
    "text": "to tailor this VP to your workload you'll have to run a few iterations before you get to the ideal values for",
    "start": "1918140",
    "end": "1924200"
  },
  {
    "text": "your project so um to start with I will try to",
    "start": "1924200",
    "end": "1929240"
  },
  {
    "text": "highlight a few Flags here one is this recommendation margin fact fraction which is basically the amount by which",
    "start": "1929240",
    "end": "1936100"
  },
  {
    "text": "CPU are or the memory gets stepped up or stepped down so we have chosen 30 so every step would",
    "start": "1936100",
    "end": "1944960"
  },
  {
    "text": "be 30 increase in CPU and the memory we would also have parameters like how long",
    "start": "1944960",
    "end": "1950419"
  },
  {
    "text": "do you want to retain the memory and CPU history before it dies down before you",
    "start": "1950419",
    "end": "1956240"
  },
  {
    "text": "discard them we can also set which namespace do you want to uh do you want",
    "start": "1956240",
    "end": "1962539"
  },
  {
    "text": "vpe to act upon and we have used Prometheus for our storage here so we provide the",
    "start": "1962539",
    "end": "1969320"
  },
  {
    "text": "Prometheus URL so on and so forth uh this is for the vpa recommender",
    "start": "1969320",
    "end": "1974360"
  },
  {
    "text": "entity we also have something called vpa updater entity where you can provide informations like how what is the",
    "start": "1974360",
    "end": "1981740"
  },
  {
    "text": "interval at which you want the vpe to run we have set that to 10 minutes you could choose yours and we can also",
    "start": "1981740",
    "end": "1988640"
  },
  {
    "text": "provide the number of minimum replicas of every controller that is to be run uh",
    "start": "1988640",
    "end": "1993860"
  },
  {
    "text": "that is needed for the VP to act on a particular controller at all and if you",
    "start": "1993860",
    "end": "1999019"
  },
  {
    "text": "see too many evictions of the pods and you want to tolerate or you want to reduce that we for example use this uh",
    "start": "1999019",
    "end": "2005919"
  },
  {
    "text": "eviction read limit read pass and also eviction tolerance this is to just to",
    "start": "2005919",
    "end": "2011500"
  },
  {
    "text": "tell the vertical part of this killer that you have to have a certain percentage of the replicas running at",
    "start": "2011500",
    "end": "2017620"
  },
  {
    "text": "all times when you consider evicting one of the pods in the controller so these",
    "start": "2017620",
    "end": "2023380"
  },
  {
    "text": "are few of the flags that we have touched upon but there are various others that might interest you",
    "start": "2023380",
    "end": "2031659"
  },
  {
    "text": "and with vpe together with Cloud cluster to scalar and horizontal power to scalar",
    "start": "2031659",
    "end": "2037179"
  },
  {
    "text": "we get this graph and it is the same workload and uh the same production",
    "start": "2037179",
    "end": "2043200"
  },
  {
    "text": "deployment we see that the red line which is the utilization of the resource",
    "start": "2043200",
    "end": "2048398"
  },
  {
    "text": "actual utilization of the resource is very close to the blue line which is the requested resource",
    "start": "2048399",
    "end": "2055358"
  },
  {
    "text": "you might ask there is still a huge glitch or huge difference initially uh",
    "start": "2055359",
    "end": "2062500"
  },
  {
    "text": "at least in the initial few days and this is because we have configured it to be such and this is because uh totally",
    "start": "2062500",
    "end": "2070358"
  },
  {
    "text": "because our workload behaves this way we have huge historical data in the",
    "start": "2070359",
    "end": "2075580"
  },
  {
    "text": "beginning and we want to reduce the number of evictions that happen due to the vertical product is killer and we",
    "start": "2075580",
    "end": "2081460"
  },
  {
    "text": "have configured it kind of this way but you can refrain from doing this of course",
    "start": "2081460",
    "end": "2086618"
  },
  {
    "text": "and are we saving here with this of course combined we are seeing a lot",
    "start": "2086619",
    "end": "2092919"
  },
  {
    "text": "because firstly our ports are optimized our pods are scaling and the nodes are",
    "start": "2092919",
    "end": "2099640"
  },
  {
    "text": "also scaling and the notes are what we pay for and that's also optimized and we save huge a safe huge on the cost",
    "start": "2099640",
    "end": "2108220"
  },
  {
    "text": "so this table that you see on screen is uh from from the same workload in our",
    "start": "2108220",
    "end": "2114520"
  },
  {
    "text": "production environments two different production environments one without any of these optimization techniques the one",
    "start": "2114520",
    "end": "2120940"
  },
  {
    "text": "at the bottom that you see you can see that we have used 4K CPUs and after",
    "start": "2120940",
    "end": "2127780"
  },
  {
    "text": "optimization we've come down to 1.7 K uh CPUs and with memory we had used 12",
    "start": "2127780",
    "end": "2135160"
  },
  {
    "text": "terabytes of memory and we came down to 6.5 terabytes of memory almost 50 percent of the cost saving that we're",
    "start": "2135160",
    "end": "2142540"
  },
  {
    "text": "doing here of course you can find few differences in the tables uh this is because we we tried to get wiser so so",
    "start": "2142540",
    "end": "2150820"
  },
  {
    "text": "to say we try to increase the planning or increase number of node pools and",
    "start": "2150820",
    "end": "2155980"
  },
  {
    "text": "discreetly uh uh discreetly have notes",
    "start": "2155980",
    "end": "2161140"
  },
  {
    "text": "defined and we also change the shapes here and there so that's the reason why you see it but it the load that it is",
    "start": "2161140",
    "end": "2167920"
  },
  {
    "text": "can is the scene so you could see these uh denzio A1 E4",
    "start": "2167920",
    "end": "2173380"
  },
  {
    "text": "Flex these are basically standard VMS provided by Oracle kubernetes cluster",
    "start": "2173380",
    "end": "2181260"
  },
  {
    "text": "danzaio is the locally the one with locally attached nvme SSD uh A1 Flex are",
    "start": "2181260",
    "end": "2188260"
  },
  {
    "text": "these arm 64 pieced compute instances E4 is the standard uh amd64 images uh",
    "start": "2188260",
    "end": "2196660"
  },
  {
    "text": "compute instances so with this we come to the summary",
    "start": "2196660",
    "end": "2203500"
  },
  {
    "text": "and to summarize uh we first need to explore our Cloud providers VM standard",
    "start": "2203500",
    "end": "2211060"
  },
  {
    "text": "standard VM sizes shapes before we actually decide on what our node type",
    "start": "2211060",
    "end": "2217119"
  },
  {
    "text": "should be a node a particular node pool should be based on our workload requirements",
    "start": "2217119",
    "end": "2223420"
  },
  {
    "text": "and furthermore we have Auto scaling techniques like cluster to scalar which",
    "start": "2223420",
    "end": "2228520"
  },
  {
    "text": "scales the number of nodes in the cluster note pool and we have horizontal power to scalar",
    "start": "2228520",
    "end": "2234760"
  },
  {
    "text": "which furthermore ensures the Pod replicas are scaling and hence the cumulative sum of all the parts keep",
    "start": "2234760",
    "end": "2241000"
  },
  {
    "text": "decreasing whenever it is not necessary and vpa which is vertical power to",
    "start": "2241000",
    "end": "2246760"
  },
  {
    "text": "scalar which ensures that the port is optimally used as in the resource request is as close to the actual",
    "start": "2246760",
    "end": "2253660"
  },
  {
    "text": "utilization of the port as much as possible hope this was of some help to you thank",
    "start": "2253660",
    "end": "2261339"
  },
  {
    "text": "you for your patient listening and sorry about the technical glitch we are open to questions and answers",
    "start": "2261339",
    "end": "2268260"
  },
  {
    "text": "maybe I should get back to the chat",
    "start": "2268260",
    "end": "2272579"
  },
  {
    "text": "quite a few",
    "start": "2275680",
    "end": "2278460"
  },
  {
    "text": "uh we are not doing git Ops as yet uh for the first question okay let me get",
    "start": "2287260",
    "end": "2292780"
  },
  {
    "text": "to the question if you do a new deployment the latest value will get overwritten by the value that was in the",
    "start": "2292780",
    "end": "2299200"
  },
  {
    "text": "Manifest so you didn't get do you do anything special to sync to get uh we",
    "start": "2299200",
    "end": "2304660"
  },
  {
    "text": "when I see deployments in production we do uh fresh deployments from the gitlab",
    "start": "2304660",
    "end": "2310780"
  },
  {
    "text": "CI CD every time so the values are in the gitlab repo and once we update there",
    "start": "2310780",
    "end": "2317920"
  },
  {
    "text": "that's when it goes to the master and that's what gets deployed so we don't have this issue as of now",
    "start": "2317920",
    "end": "2325060"
  },
  {
    "text": "but when we get to git Ops I'm pretty sure we'll get into this issue",
    "start": "2325060",
    "end": "2331200"
  },
  {
    "text": "and according to BP configuration resizing many may happen every 10",
    "start": "2332220",
    "end": "2338200"
  },
  {
    "text": "minutes based on one rdk histogram how much stability was affected with endless",
    "start": "2338200",
    "end": "2344140"
  },
  {
    "text": "restarts across class and this is the reason why we had this initial glitch",
    "start": "2344140",
    "end": "2349780"
  },
  {
    "text": "that you saw in the graph that's because we tried to start the vpa a little later",
    "start": "2349780",
    "end": "2354940"
  },
  {
    "text": "and we configured uh the resource parameters resource request parameters",
    "start": "2354940",
    "end": "2360040"
  },
  {
    "text": "to very high value initially because initially that's when at least for our",
    "start": "2360040",
    "end": "2365200"
  },
  {
    "text": "workload that's when most of the loading and the busy time happens we have a huge amount of historical data and to get to",
    "start": "2365200",
    "end": "2372640"
  },
  {
    "text": "the stable CDC till then we don't want too many uh",
    "start": "2372640",
    "end": "2377680"
  },
  {
    "text": "evictions of the pods that would just delay the loading process and that's the reason we try to manually have a glitch",
    "start": "2377680",
    "end": "2384820"
  },
  {
    "text": "there and we start uh start applying or patching the VP a little later during",
    "start": "2384820",
    "end": "2390339"
  },
  {
    "text": "the deployment so a horizontal power to scalar can't",
    "start": "2390339",
    "end": "2396280"
  },
  {
    "text": "use memory or CPU what metrics are you using to know when to scale up the multiple parts",
    "start": "2396280",
    "end": "2402820"
  },
  {
    "text": "yeah we use custom metrics we have applications which export a particular",
    "start": "2402820",
    "end": "2408520"
  },
  {
    "text": "kind of metrics which is kind of a deciding factor because it provides basically how much are we lacking in",
    "start": "2408520",
    "end": "2414940"
  },
  {
    "text": "time I would not try to go into the details but it could differ in your raw project as well but this value should",
    "start": "2414940",
    "end": "2422920"
  },
  {
    "text": "basically be the deciding factor for you to know if you have to your workload is",
    "start": "2422920",
    "end": "2428020"
  },
  {
    "text": "heavy or if your applications are busy or not so if you have some metrics in",
    "start": "2428020",
    "end": "2433780"
  },
  {
    "text": "your application you could of course export that metrics and then Prometheus uh to this property server and have from",
    "start": "2433780",
    "end": "2440200"
  },
  {
    "text": "this adapter or try to make it available to the horizontal port or to scalar",
    "start": "2440200",
    "end": "2447660"
  },
  {
    "text": "handle when there is one or two parts preventing it from removing the note is",
    "start": "2449339",
    "end": "2454420"
  },
  {
    "text": "there any way to flag some parts as not important or that",
    "start": "2454420",
    "end": "2459940"
  },
  {
    "text": "or that they can be rescheduled if needed uh yeah this is uh one thing that",
    "start": "2459940",
    "end": "2465099"
  },
  {
    "text": "we also faced with Blaster Auto scalar we had pod disruption budgets and uh",
    "start": "2465099",
    "end": "2471280"
  },
  {
    "text": "that meant we had one instance of the pot and the pot is disruption budget was",
    "start": "2471280",
    "end": "2477099"
  },
  {
    "text": "saying that I should have a minimum of one and in which case cluster autoscaler refrains uh it raises its hand and says",
    "start": "2477099",
    "end": "2484359"
  },
  {
    "text": "okay now I can't do anything with this load you will have to exist because the port is still existing and there's no",
    "start": "2484359",
    "end": "2490480"
  },
  {
    "text": "second replica of that part that's kind of to say wrong configuration because",
    "start": "2490480",
    "end": "2495579"
  },
  {
    "text": "for a poor disruption budgets should start with at least two replicas in my",
    "start": "2495579",
    "end": "2501160"
  },
  {
    "text": "opinion and to get around this uh I would say",
    "start": "2501160",
    "end": "2507280"
  },
  {
    "text": "you will need a bit of manual intervention if you really want the cluster Auto scaler to run or you have",
    "start": "2507280",
    "end": "2513640"
  },
  {
    "text": "to make sure you decide wisely when you have the poor disruption budgets configured",
    "start": "2513640",
    "end": "2520119"
  },
  {
    "text": "do you have keeda along with VP is it possible I am not aware of Kira to be frank uh",
    "start": "2520119",
    "end": "2530020"
  },
  {
    "text": "here that you have any inputs on this yeah this is for for collecting values metrics we could use it yes but in our",
    "start": "2530020",
    "end": "2537640"
  },
  {
    "text": "setup we don't have it maybe we will use it in the future for example we use custom metrics from",
    "start": "2537640",
    "end": "2544480"
  },
  {
    "text": "from Kafka so it would be perfect perfect feet for the purpose",
    "start": "2544480",
    "end": "2552599"
  },
  {
    "text": "yes it is possible yeah okay so each app has a has to push metrics to",
    "start": "2552640",
    "end": "2560380"
  },
  {
    "text": "Prometheus at some interval or does parameters pull uh yeah there are two ways the",
    "start": "2560380",
    "end": "2566920"
  },
  {
    "text": "Prometheus works one is push and one is pulled so we are doing the push",
    "start": "2566920",
    "end": "2572020"
  },
  {
    "text": "wherein we push the metrics to the Prometheus and yeah there is configuration in Prometheus itself where",
    "start": "2572020",
    "end": "2578800"
  },
  {
    "text": "you can see how frequently should you uh pull or push the metrics from various",
    "start": "2578800",
    "end": "2585520"
  },
  {
    "text": "apps that's a configuration in the Prometheus when you install Prometheus onto the cluster you have those configuration",
    "start": "2585520",
    "end": "2592000"
  },
  {
    "text": "parameters the HP and VP methods are used together",
    "start": "2592000",
    "end": "2599260"
  },
  {
    "text": "what is the difference between its metrics okay uh if uh HP is used",
    "start": "2599260",
    "end": "2605619"
  },
  {
    "text": "together with vpa I'm presuming this is because HPA was used with custom metrics",
    "start": "2605619",
    "end": "2611200"
  },
  {
    "text": "and the custom metrics basically means your application is trying to export some customized metrics very customized",
    "start": "2611200",
    "end": "2619060"
  },
  {
    "text": "to your application right and vpa methods vpa uses the",
    "start": "2619060",
    "end": "2625060"
  },
  {
    "text": "actual resource utilization when I say when you do a cubesatel top command you",
    "start": "2625060",
    "end": "2630460"
  },
  {
    "text": "actually get to see how much support is actually utilizing regardless of how much you've configured the Pod resource",
    "start": "2630460",
    "end": "2636880"
  },
  {
    "text": "requests so that is what it considers for vpa vertical power to scalar and for",
    "start": "2636880",
    "end": "2643119"
  },
  {
    "text": "hpe you have used the custom metrics which is your what your application is seeing I need uh to have a threshold to",
    "start": "2643119",
    "end": "2651400"
  },
  {
    "text": "scale out and scale in the number of replicas of a pod hope that answered",
    "start": "2651400",
    "end": "2659579"
  },
  {
    "text": "but I didn't miss any question",
    "start": "2659980",
    "end": "2663359"
  },
  {
    "text": "hope the session was of some help to you if you further have any questions you can of course uh leave them with the",
    "start": "2673420",
    "end": "2680440"
  },
  {
    "text": "organizer and they will try to communicate to us over mail but thank you for your patient listening",
    "start": "2680440",
    "end": "2688319"
  },
  {
    "text": "okay thanks so much are there any other questions before we",
    "start": "2689859",
    "end": "2695859"
  },
  {
    "text": "let everyone go",
    "start": "2695859",
    "end": "2698940"
  },
  {
    "text": "all right well excellent job thank you varsha and Chip thank you everyone for",
    "start": "2702940",
    "end": "2709839"
  },
  {
    "text": "joining us um I think you know how to reach our speakers if you have any additional questions but thanks for joining our",
    "start": "2709839",
    "end": "2716680"
  },
  {
    "text": "cncf live webinar today uh as a reminder everything will be online later today",
    "start": "2716680",
    "end": "2721720"
  },
  {
    "text": "early tomorrow so um just let us know if you have any questions and we'll see you again next",
    "start": "2721720",
    "end": "2727839"
  },
  {
    "text": "time thanks so much",
    "start": "2727839",
    "end": "2731280"
  }
]
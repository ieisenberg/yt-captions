[
  {
    "text": "so uh welcome to the Prometheus update um I'm going to do the usual so show of",
    "start": "40",
    "end": "6080"
  },
  {
    "text": "hands who who knows what promethus actually is okay this is way more than in 2017",
    "start": "6080",
    "end": "13839"
  },
  {
    "text": "2018 like there was a full room and no one actually knew what it was so this is really good who's using it like just a",
    "start": "13839",
    "end": "21160"
  },
  {
    "text": "little bit or and who's using it in production nice this is way more than a",
    "start": "21160",
    "end": "27519"
  },
  {
    "text": "few years ago this is really nice so for um those of you who don't know uh the",
    "start": "27519",
    "end": "33399"
  },
  {
    "text": "structure we always have with the Prometheus update is we have a short intro we have a little bit of a deeper",
    "start": "33399",
    "end": "38680"
  },
  {
    "text": "dive session and we try to get through this as quickly as possible so we have enough time for questions at the end so",
    "start": "38680",
    "end": "44800"
  },
  {
    "text": "you can just ask whatever you want to ask uh without us basically prescribing the content and just babbling until the",
    "start": "44800",
    "end": "50440"
  },
  {
    "text": "very end so um the very quick version of what premesis is it is a metric engine",
    "start": "50440",
    "end": "56640"
  },
  {
    "text": "metrics are numerical data which you can store about systems it might be temperature it might be uh how many how",
    "start": "56640",
    "end": "63519"
  },
  {
    "text": "many requests your your web server gets how many sales you do through your web shop things like these uh you would",
    "start": "63519",
    "end": "70400"
  },
  {
    "text": "normally instrument your applications where you have a variety of different uh instrumentation libraries and also Auto",
    "start": "70400",
    "end": "76479"
  },
  {
    "text": "instrumentation you can also use open Telemetry you can use the Prometheus client libraries hooking into your",
    "start": "76479",
    "end": "82200"
  },
  {
    "text": "applications and exposing the data which matters to you automatically Prometheus is the stuff",
    "start": "82200",
    "end": "89000"
  },
  {
    "text": "which does the metx storage and collection and and basically all the computation of the data once it is in",
    "start": "89000",
    "end": "95600"
  },
  {
    "text": "you can query the data you can alert you can dashboard everything through one single language uh for those deeper into",
    "start": "95600",
    "end": "102600"
  },
  {
    "text": "math it is a vector Lang or it is a functional language for doing Vector math on your observability data in more",
    "start": "102600",
    "end": "110520"
  },
  {
    "text": "simpler terms basically you can do actually at scale math on your data and this is part of why Prometheus is so",
    "start": "110520",
    "end": "117399"
  },
  {
    "text": "successful because this was the first time that this this was actually uh available to anyone within open source",
    "start": "117399",
    "end": "123240"
  },
  {
    "text": "and they could could just use those Advanced uh curing mechanisms you can use it for everything if you still have",
    "start": "123240",
    "end": "129119"
  },
  {
    "text": "a data center you can use it for your diesel generators down to your microservices and everything in between",
    "start": "129119",
    "end": "134840"
  },
  {
    "text": "um which is also very much different from previous generations of observability and monitoring tools and",
    "start": "134840",
    "end": "140319"
  },
  {
    "text": "APM and all those things where you're usually limited to just Network or just infrastructure or just applications here",
    "start": "140319",
    "end": "147879"
  },
  {
    "text": "you can do your whole stack with one single solution and also it is the absolute",
    "start": "147879",
    "end": "153959"
  },
  {
    "text": "default for kubernetes for ETD for everything like everything which uh does anything with metrics within Cloud",
    "start": "153959",
    "end": "159800"
  },
  {
    "text": "native all speak the uh prome Exposition format because that's the standard um",
    "start": "159800",
    "end": "165440"
  },
  {
    "text": "across all of this so short history started 11 years",
    "start": "165440",
    "end": "170800"
  },
  {
    "text": "ago was fully open sourced uh 9 years ago um yeah we joined the cncf as the second",
    "start": "170800",
    "end": "178440"
  },
  {
    "text": "project after uh cucon uh after kubernetes uh it was just called cncf",
    "start": "178440",
    "end": "184120"
  },
  {
    "text": "but it was not even called cubec con when we joined so that early uh we released the version two in 2017",
    "start": "184120",
    "end": "190720"
  },
  {
    "text": "currently working to voice over version 3 and we are also the second project to graduate within",
    "start": "190720",
    "end": "196319"
  },
  {
    "text": "cncf uh if you want to watch the documentary about uh Prometheus there is a QR code and the and a link uh I hope",
    "start": "196319",
    "end": "204239"
  },
  {
    "text": "this works here uh that's actually a good point I don't know um but yeah this is um it's nice",
    "start": "204239",
    "end": "210680"
  },
  {
    "text": "and cncf spent a bit of money on on making this I'll just give people the time okay there's one more okay so um a",
    "start": "210680",
    "end": "218879"
  },
  {
    "text": "little bit about our growth um I also work at grafana labs and for with grafana we actually see um how many",
    "start": "218879",
    "end": "225439"
  },
  {
    "text": "instances of Prometheus are being queried or how many grafana instances have a Prometheus backend",
    "start": "225439",
    "end": "231400"
  },
  {
    "text": "defined um and this is one of the very very few numbers we as Prometheus team",
    "start": "231400",
    "end": "236560"
  },
  {
    "text": "uh have about actual adoption of Prometheus course except for GitHub stars stars and such there is no way to",
    "start": "236560",
    "end": "243680"
  },
  {
    "text": "know who is using this like for example here at the project Booth lots of people came up to me hey we're using Prometheus",
    "start": "243680",
    "end": "250200"
  },
  {
    "text": "for years and we are successful with it few years ago no one in China was using Prometheus we don't know this we don't",
    "start": "250200",
    "end": "256560"
  },
  {
    "text": "see this because we don't have any installation numbers except for the ones through grao Labs so and here you can",
    "start": "256560",
    "end": "261840"
  },
  {
    "text": "see the growth over um over the years and we have a little bit of a tradition to to update those numbers once a year",
    "start": "261840",
    "end": "268600"
  },
  {
    "text": "at promcon which is starting today German time in Berlin and I'm flying",
    "start": "268600",
    "end": "274720"
  },
  {
    "text": "back tonight to there um so this is why why I'm also showing this updated number because this is once per year where we",
    "start": "274720",
    "end": "280560"
  },
  {
    "text": "where we make this number public there's a ton of contributors we",
    "start": "280560",
    "end": "286039"
  },
  {
    "text": "just came over 50k Stars I believe this morning but I couldn't update the image",
    "start": "286039",
    "end": "291479"
  },
  {
    "text": "on this on this uh Chromebook here um and if anyone here wants to wants to",
    "start": "291479",
    "end": "296800"
  },
  {
    "text": "join and to to help with development of prometh more than welcome uh kubernetes has like",
    "start": "296800",
    "end": "303080"
  },
  {
    "text": "a thousand people and it's the largest project and uh Prometheus is second in pretty much everything except",
    "start": "303080",
    "end": "309479"
  },
  {
    "text": "contributors we have 20 people and maybe 10 people do work so um we have vly",
    "start": "309479",
    "end": "315639"
  },
  {
    "text": "really really very few people uh on the positive side anyone who does join anyone who wants to contribute can make",
    "start": "315639",
    "end": "322160"
  },
  {
    "text": "an absolutely outsized amount of impact on Open Source by joining one of the non",
    "start": "322160",
    "end": "327800"
  },
  {
    "text": "kubernetes projects IDE really Prometheus so yeah we are always working",
    "start": "327800",
    "end": "335120"
  },
  {
    "text": "to expand the team but uh having more people would be even more better for obvious reasons uh but if you again if",
    "start": "335120",
    "end": "342199"
  },
  {
    "text": "you are interested in any of this um just contact us uh you'll find the Prometheus developers and Prometheus",
    "start": "342199",
    "end": "348840"
  },
  {
    "text": "users mailing list if you just search for it or just search for Prometheus Community you find all the links or just",
    "start": "348840",
    "end": "355479"
  },
  {
    "text": "talk to me afterwards um we really need more hands to to do work um yeah there's",
    "start": "355479",
    "end": "361400"
  },
  {
    "text": "put more so how does all of this actually work let's say you have your web application you maybe have some API",
    "start": "361400",
    "end": "367440"
  },
  {
    "text": "server whatever you have a bunch of microservices in this case you would have the client library either the",
    "start": "367440",
    "end": "373400"
  },
  {
    "text": "Prometheus client library or also you could use the open Telemetry um uh instrumentation libraries and put this",
    "start": "373400",
    "end": "380720"
  },
  {
    "text": "directly into your application code and start exposing data from that there's also concept of uh of",
    "start": "380720",
    "end": "388520"
  },
  {
    "text": "exporters which basically reverse proxies which are translating from various different uh languages and",
    "start": "388520",
    "end": "395080"
  },
  {
    "text": "systems into something which Prometheus understands we do this for efficiency reasons course by doing this at scale at",
    "start": "395080",
    "end": "402240"
  },
  {
    "text": "the far edge of what we scrape it's a lot easier to um to horizontally scale",
    "start": "402240",
    "end": "408800"
  },
  {
    "text": "the load of doing those translations because if we would do it centrally we would have massive computation problems",
    "start": "408800",
    "end": "414199"
  },
  {
    "text": "at the center but so we can push this out to the workloads towards the edge so you have have those exporters and they",
    "start": "414199",
    "end": "420479"
  },
  {
    "text": "can just translate between for example what your CIS uh file system in Linux looks like or the my SQL or whatever and",
    "start": "420479",
    "end": "427560"
  },
  {
    "text": "then you have Prometheus and Prometheus comes along and scrapes all this data uh scraping is basically just comes by uh",
    "start": "427560",
    "end": "434879"
  },
  {
    "text": "takes stuff from the from a web page and stores it and that's it so where does it",
    "start": "434879",
    "end": "441120"
  },
  {
    "text": "know where to look for for monitoring data easy there is a system called",
    "start": "441120",
    "end": "447039"
  },
  {
    "text": "service discovery which is way of telling Prometheus what you should or",
    "start": "447039",
    "end": "452240"
  },
  {
    "text": "what it should be uh getting its data from um if you're using kubernetes and",
    "start": "452240",
    "end": "457960"
  },
  {
    "text": "most of you probably are um you have a direct integration in kubernetes for Prometheus where you literally just tell",
    "start": "457960",
    "end": "464599"
  },
  {
    "text": "a kubernetes there is a Prometheus which is allowed to talk to you and you tell the Prometheus there is a kubernetes you",
    "start": "464599",
    "end": "471800"
  },
  {
    "text": "should be talking to and they start talking to each other and everything which is running on this kubernetes",
    "start": "471800",
    "end": "477440"
  },
  {
    "text": "cluster is automatic started to be scraped by Prometheus and you don't have to do anything and you restart 10,000",
    "start": "477440",
    "end": "485199"
  },
  {
    "text": "parts and everything just happens for you you don't have to do anything manually that's part of the power of",
    "start": "485199",
    "end": "491280"
  },
  {
    "text": "Prometheus if you're using any of the major or midsized Cloud providers we have Integrations for all of them so",
    "start": "491280",
    "end": "498879"
  },
  {
    "text": "whatever you're using as long as you tell the systems they're allowed to talk to each other it just works we also have",
    "start": "498879",
    "end": "506120"
  },
  {
    "text": "console and like we have literally dozens of different service integration or service Discovery Integrations and",
    "start": "506120",
    "end": "512080"
  },
  {
    "text": "also we have a file system based uh or file based uh service Discovery mechanism where you just have a yl file",
    "start": "512080",
    "end": "519399"
  },
  {
    "text": "and you can basically do free form this is something which we see very often in um in physical infrastructure where",
    "start": "519399",
    "end": "525160"
  },
  {
    "text": "often times you don't really have proper inventory in a database and so they just have files and that's what we use to",
    "start": "525160",
    "end": "532040"
  },
  {
    "text": "scrape all of this works and you can combine this as you want and then obviously you want to see",
    "start": "532040",
    "end": "539240"
  },
  {
    "text": "what's happening so you would have uh yog grafana or you would have the Prometheus web UI you can also put",
    "start": "539240",
    "end": "544560"
  },
  {
    "text": "automation all against your Prometheus all written in this one language this",
    "start": "544560",
    "end": "549640"
  },
  {
    "text": "again promql this um functional language for Vector math and also you have",
    "start": "549640",
    "end": "555560"
  },
  {
    "text": "something called the alert manager and that's where you can make the picture because or take the picture that's the last slide um so the alert manager",
    "start": "555560",
    "end": "564519"
  },
  {
    "text": "because part of what Prometheus does for you it it does a lot of computations and you canun really Advanced queries not",
    "start": "564519",
    "end": "570800"
  },
  {
    "text": "just am I over 90% dis or something you can also say things based on the trend",
    "start": "570800",
    "end": "576920"
  },
  {
    "text": "of the last 24 hours what does the next 5 hours look like and would I be above",
    "start": "576920",
    "end": "583240"
  },
  {
    "text": "90% or 95 or 99 or whatever in this time frame so you can basically do",
    "start": "583240",
    "end": "588440"
  },
  {
    "text": "predictions into the future which is really useful with system capacity like diss or with SSL cert or TLS",
    "start": "588440",
    "end": "595720"
  },
  {
    "text": "certificates and things like these they can predict what will happen happen in the future so you basically predict an",
    "start": "595720",
    "end": "601440"
  },
  {
    "text": "outage you predict you predict something failing and then you can alert before it",
    "start": "601440",
    "end": "607680"
  },
  {
    "text": "actually happens so you don't have to uh scramble because something is already broken you get told before it breaks",
    "start": "607680",
    "end": "615399"
  },
  {
    "text": "very very powerful and obviously you can then look at stuff in in your different front ends and and also do automation",
    "start": "615399",
    "end": "621839"
  },
  {
    "text": "based on the alerts so let's look at a few things of what has been new in the last few month",
    "start": "621839",
    "end": "628399"
  },
  {
    "text": "or so so basically this year and this is to be clear only in the main Prometheus",
    "start": "628399",
    "end": "633440"
  },
  {
    "text": "we have also the agent we have the various client libraries blah blah blah blah blah this only looking at Prometheus",
    "start": "633440",
    "end": "638839"
  },
  {
    "text": "proper uh first and foremost uh the most important we have native histograms so",
    "start": "638839",
    "end": "644240"
  },
  {
    "text": "for the last 11 years our histograms were very very coarse and they did what",
    "start": "644240",
    "end": "650120"
  },
  {
    "text": "they needed to do but they were not easy to work with so if you knew precisely what you were doing and if you knew",
    "start": "650120",
    "end": "655560"
  },
  {
    "text": "precisely how your system was working you could use them very very very effectively but usually you need to kind",
    "start": "655560",
    "end": "662079"
  },
  {
    "text": "of get up to speed and basically iterate towards a better understanding of what your system is doing to have proper uh",
    "start": "662079",
    "end": "669200"
  },
  {
    "text": "histograms which is honestly not ideal so what we now have is we have so-called",
    "start": "669200",
    "end": "674399"
  },
  {
    "text": "native histograms if you look at at the left side versus the right side you see that there's a lot more resolution in",
    "start": "674399",
    "end": "681200"
  },
  {
    "text": "your data because we for basically the same cost even lower cost give you much",
    "start": "681200",
    "end": "687360"
  },
  {
    "text": "higher resolution into your data so you know where precisely your latency spikes",
    "start": "687360",
    "end": "692399"
  },
  {
    "text": "are or something like for example here this red line you see precisely on the right hand side that this is where where",
    "start": "692399",
    "end": "698040"
  },
  {
    "text": "a lot of the a lot of the queries are coming in whereas on the left side it's it's so broad you don't really see",
    "start": "698040",
    "end": "704200"
  },
  {
    "text": "what's happening this is really really really powerful it's really awesome you can also have fun with this",
    "start": "704200",
    "end": "711680"
  },
  {
    "text": "like this image is drawn within Prometheus and grafana through a native histogram just of course we can and it",
    "start": "711680",
    "end": "718440"
  },
  {
    "text": "was fun and a little bit of a tech demo but this is uh like you can also have fun with",
    "start": "718440",
    "end": "724600"
  },
  {
    "text": "this there's also like we once uh re-recorded one of the",
    "start": "724600",
    "end": "730519"
  },
  {
    "text": "developer Summit videos uh into this system and just uploaded that course",
    "start": "730519",
    "end": "735760"
  },
  {
    "text": "again we can um we recently had massive",
    "start": "735760",
    "end": "740839"
  },
  {
    "text": "reductions in in memory usage if you're still using an older version of Prometheus you basically want to update",
    "start": "740839",
    "end": "747240"
  },
  {
    "text": "to the new version tonight uh because you will literally save 50% of your",
    "start": "747240",
    "end": "754320"
  },
  {
    "text": "memory this is again huge um we we saw",
    "start": "754320",
    "end": "759399"
  },
  {
    "text": "this in really large clusters at grafana we saw this at at various other users of Prometheus and throughout the user base",
    "start": "759399",
    "end": "766760"
  },
  {
    "text": "we see those roughly 50% of of memory reduction and the larger your your workloads are the more your savings",
    "start": "766760",
    "end": "775480"
  },
  {
    "text": "are we also have something which which just improves your quality of life uh deep at night when uh when when alerts",
    "start": "776519",
    "end": "784519"
  },
  {
    "text": "are firing where with they keep firing for attribute you can now say um how",
    "start": "784519",
    "end": "791560"
  },
  {
    "text": "long something should be alerting even after the alert stopped firing so let's say you have some some really important",
    "start": "791560",
    "end": "799000"
  },
  {
    "text": "thing uh your your error rate of your of your online shop of the of the actual",
    "start": "799000",
    "end": "805320"
  },
  {
    "text": "where you have the payment this is a super important thing course without the payment process you won't get paid so",
    "start": "805320",
    "end": "810519"
  },
  {
    "text": "let's say you have this error rate and it goes above a certain threshold for a really short time and then goes down",
    "start": "810519",
    "end": "816040"
  },
  {
    "text": "again so you only get one quick alert and when you look it's already gone that's not nice so you can say let's",
    "start": "816040",
    "end": "821760"
  },
  {
    "text": "fire for at least 15 minutes so you see hey this happened also if if you have something which always goes under over",
    "start": "821760",
    "end": "828199"
  },
  {
    "text": "under over under over your alerting condition it always goes away comes back goes away comes back and always has new",
    "start": "828199",
    "end": "835720"
  },
  {
    "text": "alerts by saying hey just keep firing for 20 minutes anything which which is coming and going",
    "start": "835720",
    "end": "842440"
  },
  {
    "text": "is just stays there and you don't get new alerts all the time and it's just so",
    "start": "842440",
    "end": "849000"
  },
  {
    "text": "your phone doesn't doesn't explode we also have an OTL OTP endpoint",
    "start": "849000",
    "end": "857040"
  },
  {
    "text": "um we support native ingestion of the OTL format while we still recommend",
    "start": "857040",
    "end": "863079"
  },
  {
    "text": "people should be using the promethus exposition format and scraping for a variety of performance and data",
    "start": "863079",
    "end": "869279"
  },
  {
    "text": "preciseness and stability guarantees we do also acknowledge that some people just prefer push and OTP so we have the",
    "start": "869279",
    "end": "877240"
  },
  {
    "text": "OTP endpoint now and we currently working towards basically becoming the",
    "start": "877240",
    "end": "882399"
  },
  {
    "text": "best back end for anything with OTL in it uh for the simple reason that we are",
    "start": "882399",
    "end": "887800"
  },
  {
    "text": "the cloud native default and we want to stay the cloud native default very",
    "start": "887800",
    "end": "893480"
  },
  {
    "text": "bluntly few things which are coming we are currently working towards having a completely new uh UI for the alert",
    "start": "894000",
    "end": "901519"
  },
  {
    "text": "manager we want to improve um the metadata where for example the type of",
    "start": "901519",
    "end": "907680"
  },
  {
    "text": "metrics and when certain counters have been created is not only put into memory",
    "start": "907680",
    "end": "913440"
  },
  {
    "text": "within Prometheus but also put into storage so if you restart your Prometheus you still",
    "start": "913440",
    "end": "919399"
  },
  {
    "text": "see the same data and it it doesn't just go away Exemplar improvements uh that's a",
    "start": "919399",
    "end": "925759"
  },
  {
    "text": "good point who here knows what exemplars are great so um exemplars are a way",
    "start": "925759",
    "end": "934160"
  },
  {
    "text": "basically exemplars are the IDE of a trace of a can be a distributed Trace",
    "start": "934160",
    "end": "940160"
  },
  {
    "text": "can be a classic Trace does not matter and or a span and you put those IDs",
    "start": "940160",
    "end": "945480"
  },
  {
    "text": "directly onto your um onto your metrics",
    "start": "945480",
    "end": "950759"
  },
  {
    "text": "so you don't have to search through huge amounts of Trace data to find something which is interesting in your in your",
    "start": "950759",
    "end": "956440"
  },
  {
    "text": "tracing back end you can see okay this is a high error rate this is a high latency bucket this is something which",
    "start": "956440",
    "end": "962839"
  },
  {
    "text": "is wrong and you jump directly with the knowledge of what is wrong into a trace",
    "start": "962839",
    "end": "968600"
  },
  {
    "text": "through the Exemplar and you know what is wrong what you're looking for so instead instead of looking at 20 traces",
    "start": "968600",
    "end": "975199"
  },
  {
    "text": "and discarding 19 of them and having to think through every single time you jump directly to the one thing where you know",
    "start": "975199",
    "end": "982240"
  },
  {
    "text": "you have the problem just saves you really lots of time and basically we are improving the",
    "start": "982240",
    "end": "989680"
  },
  {
    "text": "uh the exempli support per is the first thing which actually supports this uh by now Loki and grafana and mimir and such",
    "start": "989680",
    "end": "996319"
  },
  {
    "text": "also supported open Telemetry is working towards uh supporting exemplars and",
    "start": "996319",
    "end": "1002160"
  },
  {
    "text": "basically we want to uh a enable you to work even better with exemplars and also",
    "start": "1002160",
    "end": "1007360"
  },
  {
    "text": "to save them so they're not just a memory so when you restart you still have your Exemplar data uh retained and",
    "start": "1007360",
    "end": "1013759"
  },
  {
    "text": "a more efficient remote right engine which is the way how a Prometheus server sends data to other Prometheus servers",
    "start": "1013759",
    "end": "1020759"
  },
  {
    "text": "or to other storage backends like Thanos like Mia Victoria metrix like all of",
    "start": "1020759",
    "end": "1026678"
  },
  {
    "text": "those yeah um as I said earlier we need you but this is actually the wrong one",
    "start": "1026679",
    "end": "1032918"
  },
  {
    "text": "uh okay sorry I should have deleted the other one but um we need you like help us with uh with code for example here we",
    "start": "1032919",
    "end": "1040640"
  },
  {
    "text": "have a perfect thing uh which no one is currently working on um so yeah again if",
    "start": "1040640",
    "end": "1047038"
  },
  {
    "text": "you if you want to get involved if you want to um get started with development of",
    "start": "1047039",
    "end": "1053120"
  },
  {
    "text": "Prometheus please talk to us like just catch me afterwards or uh send email to",
    "start": "1053120",
    "end": "1058360"
  },
  {
    "text": "again the Prometheus developers mailing list or Prometheus users mailing list and just say hey I want to just try and",
    "start": "1058360",
    "end": "1064160"
  },
  {
    "text": "work on stuff uh we can also do things where like through LFX mentorships uh",
    "start": "1064160",
    "end": "1069520"
  },
  {
    "text": "you can even get like support from LFX to to work on things we are open to",
    "start": "1069520",
    "end": "1075000"
  },
  {
    "text": "pretty much everything we just need more hands and that's it I don't know how much time I have left but that's for me",
    "start": "1075000",
    "end": "1082919"
  },
  {
    "text": "and now we have questions hopefully so who has",
    "start": "1082919",
    "end": "1090320"
  },
  {
    "text": "questions I don't bite",
    "start": "1091039",
    "end": "1094919"
  },
  {
    "text": "promise",
    "start": "1097919",
    "end": "1100919"
  },
  {
    "text": "yeah sor",
    "start": "1106159",
    "end": "1110320"
  },
  {
    "text": "sorry um hi thank you for sharing it was really insightful um I have a question",
    "start": "1112679",
    "end": "1117880"
  },
  {
    "text": "about the Improvement of the memory reduction by 50% how did that happen that's a lot of memory saving I don't",
    "start": "1117880",
    "end": "1125679"
  },
  {
    "text": "know the technical details to be honest uh Brian uh coworker of mine um just looked at stuff for a very long time and",
    "start": "1125679",
    "end": "1132200"
  },
  {
    "text": "was like okay that that doesn't look like right he unless I'm mistaken he",
    "start": "1132200",
    "end": "1137840"
  },
  {
    "text": "redid did how we how we store the labels in memory and basically found a way to",
    "start": "1137840",
    "end": "1144280"
  },
  {
    "text": "uh to D duplicate because we basically had the same the same lookup table twice and it was the majority of our",
    "start": "1144280",
    "end": "1150720"
  },
  {
    "text": "usage but I don't know the details um you already have my email so I if you if",
    "start": "1150720",
    "end": "1156360"
  },
  {
    "text": "you poke me I can send you the pr and you can read through it and just look things up thank you is any other",
    "start": "1156360",
    "end": "1166320"
  },
  {
    "text": "questions hi thanks for your sharing uh actually I",
    "start": "1167240",
    "end": "1173280"
  },
  {
    "text": "have one problem when using prom for um monitoring",
    "start": "1173280",
    "end": "1179880"
  },
  {
    "text": "um uh as we know and prom is a put",
    "start": "1179880",
    "end": "1185039"
  },
  {
    "text": "ststem I mean uh your target is there and your matric there so the pr server",
    "start": "1185039",
    "end": "1191120"
  },
  {
    "text": "will will put the M from your import um but when when I use a daily The Matrix",
    "start": "1191120",
    "end": "1199880"
  },
  {
    "text": "there won't especially the Legacy Matrix won",
    "start": "1199880",
    "end": "1205120"
  },
  {
    "text": "be garbage collected automatically um for example uh as for",
    "start": "1205120",
    "end": "1210760"
  },
  {
    "text": "our user case we have many tenant each",
    "start": "1210760",
    "end": "1216400"
  },
  {
    "text": "each tenant has a ID and so we have the",
    "start": "1216400",
    "end": "1221960"
  },
  {
    "text": "Cs monitoring for each tenant and above it each tenant will have the version for",
    "start": "1221960",
    "end": "1230640"
  },
  {
    "text": "for a deployment and so as time grows we have",
    "start": "1230640",
    "end": "1236880"
  },
  {
    "text": "more um tant come and go and their version will increase by time",
    "start": "1236880",
    "end": "1244280"
  },
  {
    "text": "so um for example after seven uh 7 Days Later the stalled Matrix will Inc",
    "start": "1244280",
    "end": "1253320"
  },
  {
    "text": "increase by time and sometimes when you when you pull the Matrix from end points",
    "start": "1253320",
    "end": "1262159"
  },
  {
    "text": "the the data will be more than 100",
    "start": "1262159",
    "end": "1268520"
  },
  {
    "text": "megabytes so um it's really a B for me and I want to know is there any uh",
    "start": "1268520",
    "end": "1276159"
  },
  {
    "text": "solution for this scenario thank you so if you have 100 megabytes of metrics um",
    "start": "1276159",
    "end": "1284039"
  },
  {
    "text": "you should probably look at at making something more efficient in how you how youate cre the metrix maybe find ways to",
    "start": "1284039",
    "end": "1289840"
  },
  {
    "text": "reduce them also for some data it might actually make more sense to store it in",
    "start": "1289840",
    "end": "1294960"
  },
  {
    "text": "logs and then do analysis later if you have super high cardinality data that",
    "start": "1294960",
    "end": "1300679"
  },
  {
    "text": "being said there are a few approaches um like for example there are uh storage backends for Prometheus which are made",
    "start": "1300679",
    "end": "1308279"
  },
  {
    "text": "for for more scalability uh first and foremost would be Thanos on mimir which",
    "start": "1308279",
    "end": "1313600"
  },
  {
    "text": "just scale very very horizontally so you can put you can put much more data if you want to the other thing which I not",
    "start": "1313600",
    "end": "1321000"
  },
  {
    "text": "quite certain what you asked you said it isn't garbage collected",
    "start": "1321000",
    "end": "1326480"
  },
  {
    "text": "CU did you mean that on the metrix end point it is not garbage collected or do",
    "start": "1326559",
    "end": "1331600"
  },
  {
    "text": "you mean with in promethus it's not garbage collected the Inon",
    "start": "1331600",
    "end": "1336880"
  },
  {
    "text": "itself okay then for example and if I uh upgrade the deployment from uh verion",
    "start": "1336880",
    "end": "1345400"
  },
  {
    "text": "ran uh six to re r seven then the Matrix for R six we don't",
    "start": "1345400",
    "end": "1354799"
  },
  {
    "text": "need eight anymore so then you need to look at your metrix endpoint and you need to you need to remove everything",
    "start": "1354799",
    "end": "1362080"
  },
  {
    "text": "which does not exist anymore because Prometheus doesn't care as long as it sees it it takes the data in but once",
    "start": "1362080",
    "end": "1369480"
  },
  {
    "text": "you start removing the data from your metrix end point Prometheus doesn't see the data anymore and it is not put into",
    "start": "1369480",
    "end": "1377039"
  },
  {
    "text": "storage anymore so so once you have this as the time goes goes past you just you",
    "start": "1377039",
    "end": "1383200"
  },
  {
    "text": "just reduce the amount of metrics which you have the data set becomes smaller but if you look back into the past you",
    "start": "1383200",
    "end": "1388840"
  },
  {
    "text": "see it again so it still knows 10 weeks ago you had version 1 2 3 yeah I know so",
    "start": "1388840",
    "end": "1396240"
  },
  {
    "text": "um at business ourselves we need to take care of the gab de collection of the",
    "start": "1396240",
    "end": "1402039"
  },
  {
    "text": "like metric right to to put it more positively your metric end point should",
    "start": "1402039",
    "end": "1408159"
  },
  {
    "text": "only be exposing data which is currently useful if you still show data which has",
    "start": "1408159",
    "end": "1413799"
  },
  {
    "text": "no use anymore prus cannot know this yeah yeah I know it but",
    "start": "1413799",
    "end": "1420520"
  },
  {
    "text": "actually to identify the LAX matrics it's not that",
    "start": "1420520",
    "end": "1426120"
  },
  {
    "text": "trivial because there are many series and we need to ad oh okay this this",
    "start": "1426120",
    "end": "1433320"
  },
  {
    "text": "tenant has upgrade the deployment and we need to drop the LXI data",
    "start": "1433320",
    "end": "1438760"
  },
  {
    "text": "and there are many many other scenarios we we need to identify each case and",
    "start": "1438760",
    "end": "1445000"
  },
  {
    "text": "handle that that's a little bit of a control plan issue and like all control plans have this fundamental issue we can",
    "start": "1445000",
    "end": "1450600"
  },
  {
    "text": "also talk more later if you want uh I think there's more questions so for the public okay thank you thank you but you",
    "start": "1450600",
    "end": "1455640"
  },
  {
    "text": "can catch me later if you want thank you for sharing Richard so so",
    "start": "1455640",
    "end": "1460720"
  },
  {
    "text": "busy uh I think uh pris just defined a really good like def facto protocol for",
    "start": "1460720",
    "end": "1467080"
  },
  {
    "text": "business as to share data and share Telemetry but one question I have is like uh when we do this monitoring at",
    "start": "1467080",
    "end": "1474960"
  },
  {
    "text": "scale like like and tstp the performance of tsp the scalability of tsp is not so",
    "start": "1474960",
    "end": "1481320"
  },
  {
    "text": "good like for example like Google build more like to handle these things but like for us do you have any suggestions",
    "start": "1481320",
    "end": "1487840"
  },
  {
    "text": "for how to handle this business data at scale so it depends on how you define",
    "start": "1487840",
    "end": "1494039"
  },
  {
    "text": "scale uh if you run Prometheus vanilla Prometheus our recommendation is um to",
    "start": "1494039",
    "end": "1500520"
  },
  {
    "text": "not go over a 100 million active Series so this is roughly where where we say you shouldn't be going with",
    "start": "1500520",
    "end": "1507360"
  },
  {
    "text": "promethus uh I know of people who ran with much more than 100 million active serus and they and it worked but it it",
    "start": "1507360",
    "end": "1515120"
  },
  {
    "text": "needed constant massaging to be honest um so once you you cross this",
    "start": "1515120",
    "end": "1522159"
  },
  {
    "text": "boundary it's better to use the storage backends for Prometheus because Prometheus itself is very geared around",
    "start": "1522159",
    "end": "1529279"
  },
  {
    "text": "I have limited set of data and I need to create alerts from this and this is why we optimize for this up to 100 million",
    "start": "1529279",
    "end": "1536720"
  },
  {
    "text": "roughly if you have things like Thanos cortex mimir there you can put stuff in",
    "start": "1536720",
    "end": "1542559"
  },
  {
    "text": "at much higher scale you can go into the billions of of active Series so you get",
    "start": "1542559",
    "end": "1547600"
  },
  {
    "text": "easily 10xd the scalability with with different backends and this is by Design",
    "start": "1547600",
    "end": "1553159"
  },
  {
    "text": "from Prometheus we don't with my Prometheus head on we don't want to deal with one billion active",
    "start": "1553159",
    "end": "1559919"
  },
  {
    "text": "series uh um uh first thanks for sharing and uh uh I'm very interested about the",
    "start": "1559919",
    "end": "1567000"
  },
  {
    "text": "uh when you're talking about the what's coming and the the remote ride version too and uh can you uh like detailly uh",
    "start": "1567000",
    "end": "1575159"
  },
  {
    "text": "uh describe how how it uh uh improved the performance and the bandwidth and uh",
    "start": "1575159",
    "end": "1581240"
  },
  {
    "text": "also uh like in the future uh will it be possible to customize the uh uh like",
    "start": "1581240",
    "end": "1588960"
  },
  {
    "text": "serializing a uh protocol or like a like Proto is not like there still a",
    "start": "1588960",
    "end": "1595799"
  },
  {
    "text": "performance down set not very uh High eff Vision like like that do you mean",
    "start": "1595799",
    "end": "1601600"
  },
  {
    "text": "protuff for remote right or do you mean protop for scraping",
    "start": "1601600",
    "end": "1607039"
  },
  {
    "text": "data a remote right okay yeah so um currently what remote ride does is very",
    "start": "1607039",
    "end": "1613720"
  },
  {
    "text": "inefficient because it was initially just a proof of concept and then it works so well we kept using",
    "start": "1613720",
    "end": "1620279"
  },
  {
    "text": "it um very fundamentally we sent the same label sets all the time so we send",
    "start": "1620279",
    "end": "1627520"
  },
  {
    "text": "the same data about the same labels again and again and again and again and this just takes up a lot of space course",
    "start": "1627520",
    "end": "1633320"
  },
  {
    "text": "labels are very large compared to the metrics themselves which are obviously very small um so the the the biggest",
    "start": "1633320",
    "end": "1641559"
  },
  {
    "text": "Improvement which we have is just don't send us as often it reminds me of htpv to like you has the headers like like",
    "start": "1641559",
    "end": "1649840"
  },
  {
    "text": "that not not not not quite but also not maybe a little bit but there there's",
    "start": "1649840",
    "end": "1657399"
  },
  {
    "text": "other things like for example and there we are back with streaming and http2 um remote ride version one is written",
    "start": "1657399",
    "end": "1663960"
  },
  {
    "text": "completely stateless so you send it you don't have to care about what you sent before what you sent after you just send",
    "start": "1663960",
    "end": "1670600"
  },
  {
    "text": "it whereas remote uh read remote read write version two uh is going to have",
    "start": "1670600",
    "end": "1676600"
  },
  {
    "text": "limited State cuz because we also have scalability issues so we need to find good trade-offs um but where we know",
    "start": "1676600",
    "end": "1683320"
  },
  {
    "text": "what we send so we can even not send you the whole raw data we can actually serialize into the in memory format",
    "start": "1683320",
    "end": "1690320"
  },
  {
    "text": "because we know what you already have or serialize from the in memory format so those are the two uh main um",
    "start": "1690320",
    "end": "1698159"
  },
  {
    "text": "improvements for more details uh you need to look at the actual PRS um but",
    "start": "1698159",
    "end": "1703360"
  },
  {
    "text": "this is cuz I don't see any like uh blog or or done yet no no it's not done yet",
    "start": "1703360",
    "end": "1709440"
  },
  {
    "text": "but uh we are having the Prometheus death Summit just this next Saturday",
    "start": "1709440",
    "end": "1715039"
  },
  {
    "text": "German time in Berlin and if you look at the Prometheus developers mailing list there's also a link where you can join",
    "start": "1715039",
    "end": "1721640"
  },
  {
    "text": "online if you want and you can just listen in and participate and everything so this is fully open fully we have this",
    "start": "1721640",
    "end": "1729399"
  },
  {
    "text": "uh once a month online and just next Saturday we have it once a year in person um so yeah this is",
    "start": "1729399",
    "end": "1738440"
  },
  {
    "text": "okay thank you very much this very exciting new",
    "start": "1738440",
    "end": "1743000"
  },
  {
    "text": "feature well I I I have some questions uh uh Bel below the above questions so",
    "start": "1745240",
    "end": "1753240"
  },
  {
    "text": "uh in some uh storage of promi such as Victor Matrix we could find that him",
    "start": "1753240",
    "end": "1761559"
  },
  {
    "text": "they manually optimize the de serialization method of PFF so",
    "start": "1761559",
    "end": "1768159"
  },
  {
    "text": "uh uh I think proa maybe uh have has",
    "start": "1768159",
    "end": "1773320"
  },
  {
    "text": "poor uh performance to uh on the this",
    "start": "1773320",
    "end": "1778600"
  },
  {
    "text": "distalization side so are there any uh",
    "start": "1778600",
    "end": "1784000"
  },
  {
    "text": "uh do you think customize the uh let users customize their uh this uh remote",
    "start": "1784000",
    "end": "1791159"
  },
  {
    "text": "right protocols is a good question so it's open source you can you",
    "start": "1791159",
    "end": "1796840"
  },
  {
    "text": "can c customize this already as of today if you want to easy um there's but there's more to it",
    "start": "1796840",
    "end": "1802910"
  },
  {
    "text": "[Music] um okay there's no there's yeah Victoria",
    "start": "1802910",
    "end": "1807919"
  },
  {
    "text": "Matrix is deliberately not compatible with Prometheus with like any any way",
    "start": "1807919",
    "end": "1813360"
  },
  {
    "text": "you look at it if you look at the remote ride if you look at the storage if you look at uh at the query uh language at",
    "start": "1813360",
    "end": "1818679"
  },
  {
    "text": "everything at the query engine it is deliberately not compatible with Prometheus which is a completely fine",
    "start": "1818679",
    "end": "1824960"
  },
  {
    "text": "engineering decision to make like Victor metric has many nice properties and they have some really good technology I'm not",
    "start": "1824960",
    "end": "1830200"
  },
  {
    "text": "saying anything negative here I'm just saying they have different design goals",
    "start": "1830200",
    "end": "1835320"
  },
  {
    "text": "than we as the Prometheus project and we as the Prometheus ecosystem we value stability and we value long-term",
    "start": "1835320",
    "end": "1842720"
  },
  {
    "text": "guarantees and everything which maybe not everyone does and again I'm not saying that this is a",
    "start": "1842720",
    "end": "1848960"
  },
  {
    "text": "bad choice I'm just saying it is a different Choice which is valid if you make it um I didn't look at their",
    "start": "1848960",
    "end": "1855159"
  },
  {
    "text": "implementation of the remote right so I can't tell you what precisely they do I know that for example in",
    "start": "1855159",
    "end": "1860320"
  },
  {
    "text": "storage um they lose Precision on purpose because it is more efficient and again this is a fine trade-off to make",
    "start": "1860320",
    "end": "1866639"
  },
  {
    "text": "if you do so on purpose but it means the data is never going to be the same as in any promethus",
    "start": "1866639",
    "end": "1872559"
  },
  {
    "text": "compatible system so if you need precise like in large numbers or something you just don't get this and I don't know",
    "start": "1872559",
    "end": "1878320"
  },
  {
    "text": "what they do in in remote ride all that being said it's open source if you want to if you want to change uh stuff in",
    "start": "1878320",
    "end": "1884559"
  },
  {
    "text": "Prometheus just do it if you want to adapt your Prometheus installation to the uh to the adapted format of Victoria",
    "start": "1884559",
    "end": "1891880"
  },
  {
    "text": "metrics just do it thank you",
    "start": "1891880",
    "end": "1898080"
  },
  {
    "text": "that's any other questions we still have",
    "start": "1899399",
    "end": "1905440"
  },
  {
    "text": "time so I've really optim y there's one can",
    "start": "1909440",
    "end": "1914519"
  },
  {
    "text": "you thank you um I have a user case I",
    "start": "1916159",
    "end": "1922600"
  },
  {
    "text": "deployed the two ti premisses so I have a a testing production cluster deployed",
    "start": "1922600",
    "end": "1929600"
  },
  {
    "text": "and my second T is uh each cluster has a a premisis instance running and as well",
    "start": "1929600",
    "end": "1936120"
  },
  {
    "text": "as I use my second TS to store the premisis metric collect from ORS so with",
    "start": "1936120",
    "end": "1943120"
  },
  {
    "text": "your V2 remote right am I I allow to write on",
    "start": "1943120",
    "end": "1949200"
  },
  {
    "text": "the local cluster and as well as pump the metric across to the remote my",
    "start": "1949200",
    "end": "1956000"
  },
  {
    "text": "second tier premises is that doable this is already doable today you can already",
    "start": "1956000",
    "end": "1961760"
  },
  {
    "text": "use it with version one you can send to more than one uh storage back end if you want and done okay I mean it's more",
    "start": "1961760",
    "end": "1970200"
  },
  {
    "text": "efficient with version why did I go here it's more efficient with uh with uh",
    "start": "1970200",
    "end": "1975559"
  },
  {
    "text": "version with version uh two but with version one it already works oh okay I",
    "start": "1975559",
    "end": "1981440"
  },
  {
    "text": "have never tried so that's why I'm I'm interesting to to see just work okay",
    "start": "1981440",
    "end": "1987080"
  },
  {
    "text": "thank",
    "start": "1987080",
    "end": "1989278"
  },
  {
    "text": "you any more",
    "start": "1994279",
    "end": "1997720"
  },
  {
    "text": "questions now is your chance again I optimized for question",
    "start": "2000120",
    "end": "2005559"
  },
  {
    "text": "time I can talk about other stuff of Prometheus but now is your chance to actually ask what you wanted to",
    "start": "2005559",
    "end": "2013720"
  },
  {
    "text": "know no one we can also wrap up early and you can have a break if you",
    "start": "2018320",
    "end": "2026120"
  },
  {
    "text": "want 3 to one okay oh there's",
    "start": "2026120",
    "end": "2031880"
  },
  {
    "text": "one hello uh thanks for your excellent uh presentation and uh uh I'm I'm",
    "start": "2031880",
    "end": "2038480"
  },
  {
    "text": "looking forward to contribute to prus could you provide some any uh General recommendation for the new contributor",
    "start": "2038480",
    "end": "2046039"
  },
  {
    "text": "yeah so um the first thing is there is a Prometheus developers mailing list uh",
    "start": "2046039",
    "end": "2052358"
  },
  {
    "text": "just promethus DD developers googlegroups.com um and the first thing",
    "start": "2052359",
    "end": "2057720"
  },
  {
    "text": "which I would be doing is I would be sending email to there and say hi I just want to get involved my interests like",
    "start": "2057720",
    "end": "2064800"
  },
  {
    "text": "if you have interests and if you say I want to work on front and I want to work on query engine I want maybe not query",
    "start": "2064800",
    "end": "2071320"
  },
  {
    "text": "engine as a first thing but like I want to work on this thing and you have",
    "start": "2071320",
    "end": "2076560"
  },
  {
    "text": "something you want to work on put this into your email if you're just open to whatever just say I'm just looking to",
    "start": "2076560",
    "end": "2082679"
  },
  {
    "text": "contribute can you give me some suggestions and then it depends on how well you know go how well you're able to",
    "start": "2082679",
    "end": "2089520"
  },
  {
    "text": "read the code base yourself versus how well uh how much you need help to to understand it uh things like these and",
    "start": "2089520",
    "end": "2096000"
  },
  {
    "text": "you just open up the conversation with uh with all the different maintainers and we together find a way where where",
    "start": "2096000",
    "end": "2103880"
  },
  {
    "text": "you can just start contributing and we find something which is a good fit as a first project as a first issue as a",
    "start": "2103880",
    "end": "2110599"
  },
  {
    "text": "first PR within within Prometheus so that's the one way the other way is if",
    "start": "2110599",
    "end": "2115800"
  },
  {
    "text": "you say I want to do X like for example today I talked to someone who wanted to",
    "start": "2115800",
    "end": "2121359"
  },
  {
    "text": "put um grpc or protuff scraping back into Prometheus we had this in version",
    "start": "2121359",
    "end": "2127160"
  },
  {
    "text": "one we don't currently have it um and he was like I want to do this specific",
    "start": "2127160",
    "end": "2132320"
  },
  {
    "text": "thing great okay then write to the mailing list and say I have an interest in implementing this specific feature",
    "start": "2132320",
    "end": "2137880"
  },
  {
    "text": "which I already know I want to be doing can you help me get started on this then",
    "start": "2137880",
    "end": "2144320"
  },
  {
    "text": "the next step is usually writing a design document uh if it's if it's a small uh thing then you can write it in",
    "start": "2144320",
    "end": "2151000"
  },
  {
    "text": "a just in an issue within within GitHub and we can discuss it if it's if it's a",
    "start": "2151000",
    "end": "2157040"
  },
  {
    "text": "little bit longer maybe write WR the one pager or something uh and send it into the group and and just say Okay this and",
    "start": "2157040",
    "end": "2165040"
  },
  {
    "text": "this is a problem I looked at this option I looked at this option I looked at this option I believe this option is the best one for those reasons I would",
    "start": "2165040",
    "end": "2172520"
  },
  {
    "text": "like to implement this does anyone have concerns any tips any help uh and then again you have this discussion phase",
    "start": "2172520",
    "end": "2178720"
  },
  {
    "text": "where people actually talk about what you do and how you do it and then you actually go do",
    "start": "2178720",
    "end": "2184240"
  },
  {
    "text": "it and then it's just normal GitHub where you open a PR you get a review and either it's merged or you fix something",
    "start": "2184240",
    "end": "2190520"
  },
  {
    "text": "and you just go through the cycle and then it's merged and you do the next thing thanks a lot and uh actually I uh",
    "start": "2190520",
    "end": "2199960"
  },
  {
    "text": "uh also a participant in the contributor in on kubernetes sometimes when I uh",
    "start": "2199960",
    "end": "2206079"
  },
  {
    "text": "submit PS uh maybe the reviewer is busy so they can't uh uh review my code in",
    "start": "2206079",
    "end": "2212599"
  },
  {
    "text": "time so how can I as for permise is also a famous project and uh maybe some",
    "start": "2212599",
    "end": "2219440"
  },
  {
    "text": "reviewer they are busy as well so how can I ensure my PR can go smoothly and",
    "start": "2219440",
    "end": "2226960"
  },
  {
    "text": "uh quickly yeah so you can never be sure just to be fair like it would be I would",
    "start": "2226960",
    "end": "2233480"
  },
  {
    "text": "be not honest if I told you yes everything always so um there are a few tricks there are a few things so a um as",
    "start": "2233480",
    "end": "2241400"
  },
  {
    "text": "I said earlier kubernetes has many many many many many more people than Prometheus which is a good thing and a",
    "start": "2241400",
    "end": "2248280"
  },
  {
    "text": "bad thing when it comes to new contributors because they have more people who can help you but also you build less of a of an immediate",
    "start": "2248280",
    "end": "2255400"
  },
  {
    "text": "relationship with core maintainers so maybe the person you build your initial relationship with has",
    "start": "2255400",
    "end": "2261520"
  },
  {
    "text": "only limited knowledge of a certain subsystem so if they hit an issue they need to ask someone else they need to ask someone else this chain doesn't",
    "start": "2261520",
    "end": "2268640"
  },
  {
    "text": "exist in Prometheus like you talk directly to the person who knows this thing best in the whole world so that's",
    "start": "2268640",
    "end": "2274800"
  },
  {
    "text": "very convenient um um so that's part of this also they could be busy and maybe",
    "start": "2274800",
    "end": "2280160"
  },
  {
    "text": "you don't get a reply for a month because I don't know they get sick or something but um the ways you can",
    "start": "2280160",
    "end": "2286520"
  },
  {
    "text": "improve this and you can improve your your chance of success and how you get things through more",
    "start": "2286520",
    "end": "2291720"
  },
  {
    "text": "quickly talk about it before you actually start doing the work in particular when you're are new talk",
    "start": "2291720",
    "end": "2298200"
  },
  {
    "text": "about hey I want to do this thing course maybe someone already had a plan maybe someone already thought of an approach",
    "start": "2298200",
    "end": "2303839"
  },
  {
    "text": "and just didn't have time maybe there is some issue you didn't even think about and they can just tell you hey this",
    "start": "2303839",
    "end": "2310079"
  },
  {
    "text": "exists as a concern also think about this one things like how the code should",
    "start": "2310079",
    "end": "2315200"
  },
  {
    "text": "look how the formatting should be what functions to use like all of those things are better to discuss up front",
    "start": "2315200",
    "end": "2321839"
  },
  {
    "text": "and then you do the work and not you do some work and then everyone has more work to to do review put differently the",
    "start": "2321839",
    "end": "2329079"
  },
  {
    "text": "best way to make your PR merged quickly is to to put as as much thought ahead of",
    "start": "2329079",
    "end": "2335880"
  },
  {
    "text": "time into writing the documentation into writing the issue into having the discussion and then when you file the pr",
    "start": "2335880",
    "end": "2343400"
  },
  {
    "text": "write a detailed description of this is what I did and why I did it because this",
    "start": "2343400",
    "end": "2348520"
  },
  {
    "text": "makes it quicker for the person who reviews your code to think through because let's say you and send small PRS",
    "start": "2348520",
    "end": "2355480"
  },
  {
    "text": "not huge PRS because what you're optimizing for is make it quick for the",
    "start": "2355480",
    "end": "2360599"
  },
  {
    "text": "reviewer to just do it if they have to take let's say 3 hours to do full review",
    "start": "2360599",
    "end": "2366000"
  },
  {
    "text": "of your PR or they have to take 20 minutes what will they like if they have",
    "start": "2366000",
    "end": "2372720"
  },
  {
    "text": "two PRS to review one will take 20 minutes one will take three hours what are they going to do on their coffee break yeah short yeah yeah so this is",
    "start": "2372720",
    "end": "2381920"
  },
  {
    "text": "the best way thanks for clarification thanks",
    "start": "2381920",
    "end": "2387319"
  },
  {
    "text": "hes any more questions",
    "start": "2387319",
    "end": "2393000"
  },
  {
    "text": "yeah yeah so it's it's just by the way the the previous question so the kubernetes",
    "start": "2395400",
    "end": "2401440"
  },
  {
    "text": "does not have something like for example cap in kubernetes which is kubernetes extension proposal you don't need to",
    "start": "2401440",
    "end": "2407880"
  },
  {
    "text": "create something like this and then your feature goes to Alpha then beta then GA",
    "start": "2407880",
    "end": "2412960"
  },
  {
    "text": "it's much simpler right it is much simpler we we have a system of design documents and for larger things we we",
    "start": "2412960",
    "end": "2419240"
  },
  {
    "text": "usually require someone writes a design document but this is for large things which we sometimes discuss for over year",
    "start": "2419240",
    "end": "2426040"
  },
  {
    "text": "because they are so large and course our stability guarantees are so hard with in",
    "start": "2426040",
    "end": "2431560"
  },
  {
    "text": "promethus because like monitoring must work it just must work so we are very",
    "start": "2431560",
    "end": "2438680"
  },
  {
    "text": "very careful in what we do and if this is a bigger change we sometimes literally take years just to make certain it's correct yet for normal",
    "start": "2438680",
    "end": "2446800"
  },
  {
    "text": "stuff you would usually be looking at weeks to month of just like send something go back forth back forth as",
    "start": "2446800",
    "end": "2453359"
  },
  {
    "text": "part of a res candidate candidate and it goes so there is no like three step",
    "start": "2453359",
    "end": "2459440"
  },
  {
    "text": "process or anything much quicker okay thank you very much I was just wondering about is there a formal process like",
    "start": "2459440",
    "end": "2466319"
  },
  {
    "text": "because this usually takes a lot of time uh in those formal processes like",
    "start": "2466319",
    "end": "2471839"
  },
  {
    "text": "kubernetes extension proposal then the feature goes Alpha then beta then finally free releases later uh only then",
    "start": "2471839",
    "end": "2479720"
  },
  {
    "text": "it's General availability right oh okay thank you yeah no there that that's part of the problem of kubernetes having so",
    "start": "2479720",
    "end": "2486599"
  },
  {
    "text": "many people because you need all this overhead uh whereas with with again",
    "start": "2486599",
    "end": "2491760"
  },
  {
    "text": "Prometheus has roughly 20 maintainers and roughly half of them actually do work so you have a group of 10 12 people",
    "start": "2491760",
    "end": "2500960"
  },
  {
    "text": "and you talk to them directly it's a very quick process yeah sure thank",
    "start": "2500960",
    "end": "2507520"
  },
  {
    "text": "you more questions we still have up to 20 minutes probably more like",
    "start": "2507520",
    "end": "2514839"
  },
  {
    "text": "15 to not block the next speaker",
    "start": "2514839",
    "end": "2518240"
  },
  {
    "text": "okay going once going twice thank you very",
    "start": "2520720",
    "end": "2528079"
  },
  {
    "text": "much",
    "start": "2528359",
    "end": "2531359"
  }
]
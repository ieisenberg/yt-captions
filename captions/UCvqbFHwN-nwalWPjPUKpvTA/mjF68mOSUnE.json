[
  {
    "start": "0",
    "end": "37000"
  },
  {
    "text": "so hello everyone",
    "start": "480",
    "end": "2240"
  },
  {
    "text": "my name is ben and today my talk is",
    "start": "2240",
    "end": "4400"
  },
  {
    "text": "about",
    "start": "4400",
    "end": "5440"
  },
  {
    "text": "tsdb compaction",
    "start": "5440",
    "end": "7359"
  },
  {
    "text": "so",
    "start": "7359",
    "end": "8240"
  },
  {
    "text": "a quick introduction about myself",
    "start": "8240",
    "end": "10800"
  },
  {
    "text": "i'm an sre at bad dance working on",
    "start": "10800",
    "end": "13360"
  },
  {
    "text": "kubernetes and",
    "start": "13360",
    "end": "15759"
  },
  {
    "text": "and i'm a tunnels maintainer and also a",
    "start": "15759",
    "end": "18240"
  },
  {
    "text": "promises contributor",
    "start": "18240",
    "end": "21439"
  },
  {
    "text": "so first of all i want to give big",
    "start": "22080",
    "end": "24000"
  },
  {
    "text": "thanks to ganesh for his uh great tsd",
    "start": "24000",
    "end": "26720"
  },
  {
    "text": "block series so if you are interested in",
    "start": "26720",
    "end": "29279"
  },
  {
    "text": "kcb and want to learn more about",
    "start": "29279",
    "end": "31519"
  },
  {
    "text": "compaction please",
    "start": "31519",
    "end": "33120"
  },
  {
    "text": "definitely check out his blog post",
    "start": "33120",
    "end": "36880"
  },
  {
    "text": "so in his blog post he defines the",
    "start": "36880",
    "end": "39920"
  },
  {
    "start": "37000",
    "end": "37000"
  },
  {
    "text": "compaction as a process of creating one",
    "start": "39920",
    "end": "43280"
  },
  {
    "text": "a new block from one or more source",
    "start": "43280",
    "end": "45920"
  },
  {
    "text": "blocks",
    "start": "45920",
    "end": "46879"
  },
  {
    "text": "and this is actually a high level",
    "start": "46879",
    "end": "49120"
  },
  {
    "text": "overview of tsb compaction and in this",
    "start": "49120",
    "end": "52640"
  },
  {
    "text": "talk let's dive deep into it",
    "start": "52640",
    "end": "55360"
  },
  {
    "text": "so because the definition mentions a tcp",
    "start": "55360",
    "end": "58480"
  },
  {
    "text": "block so i will first introduce what is",
    "start": "58480",
    "end": "60879"
  },
  {
    "text": "the tcp block",
    "start": "60879",
    "end": "63680"
  },
  {
    "start": "63000",
    "end": "63000"
  },
  {
    "text": "so a tsv block is created from an",
    "start": "63680",
    "end": "66159"
  },
  {
    "text": "in-memory head block to disk every two",
    "start": "66159",
    "end": "68880"
  },
  {
    "text": "hours",
    "start": "68880",
    "end": "69760"
  },
  {
    "text": "and this way there's no time overlapping",
    "start": "69760",
    "end": "72400"
  },
  {
    "text": "by default so different blocks will",
    "start": "72400",
    "end": "75040"
  },
  {
    "text": "cover different time ranges so you can",
    "start": "75040",
    "end": "77360"
  },
  {
    "text": "think this as a way to organize your",
    "start": "77360",
    "end": "80479"
  },
  {
    "text": "time series data partition by time so",
    "start": "80479",
    "end": "82960"
  },
  {
    "text": "for example when there's a query comes",
    "start": "82960",
    "end": "85119"
  },
  {
    "text": "in it will only touch the blocks within",
    "start": "85119",
    "end": "88479"
  },
  {
    "text": "the required time range so if you query",
    "start": "88479",
    "end": "91520"
  },
  {
    "text": "the most recent data it will only hit",
    "start": "91520",
    "end": "93920"
  },
  {
    "text": "the most recent block",
    "start": "93920",
    "end": "95759"
  },
  {
    "text": "so each tcp block is actually a minute",
    "start": "95759",
    "end": "98640"
  },
  {
    "text": "database itself it contains four parts a",
    "start": "98640",
    "end": "102159"
  },
  {
    "text": "json file to store some metadata",
    "start": "102159",
    "end": "105119"
  },
  {
    "text": "index file for",
    "start": "105119",
    "end": "106799"
  },
  {
    "text": "helping you search series",
    "start": "106799",
    "end": "109200"
  },
  {
    "text": "and a trunks directory to store your",
    "start": "109200",
    "end": "111680"
  },
  {
    "text": "data samples and finally a tombstone",
    "start": "111680",
    "end": "114240"
  },
  {
    "text": "file",
    "start": "114240",
    "end": "115759"
  },
  {
    "text": "so let's start with the metadata file",
    "start": "115759",
    "end": "118479"
  },
  {
    "start": "117000",
    "end": "117000"
  },
  {
    "text": "first so it includes some",
    "start": "118479",
    "end": "120799"
  },
  {
    "text": "block level metadata like the time range",
    "start": "120799",
    "end": "123759"
  },
  {
    "text": "and some tsdb stats like number of",
    "start": "123759",
    "end": "126399"
  },
  {
    "text": "samples series and trunks",
    "start": "126399",
    "end": "128800"
  },
  {
    "text": "and some additional information about",
    "start": "128800",
    "end": "131039"
  },
  {
    "text": "compaction",
    "start": "131039",
    "end": "132400"
  },
  {
    "text": "and in other systems like tunnels we",
    "start": "132400",
    "end": "135200"
  },
  {
    "text": "extend",
    "start": "135200",
    "end": "136319"
  },
  {
    "text": "the metadata file to include some",
    "start": "136319",
    "end": "138640"
  },
  {
    "text": "information like the external labels or",
    "start": "138640",
    "end": "141680"
  },
  {
    "text": "down sampling resolution of that block",
    "start": "141680",
    "end": "145840"
  },
  {
    "text": "so next",
    "start": "145840",
    "end": "147040"
  },
  {
    "text": "let's look at",
    "start": "147040",
    "end": "148879"
  },
  {
    "start": "148000",
    "end": "148000"
  },
  {
    "text": "what is index and trunks",
    "start": "148879",
    "end": "151440"
  },
  {
    "text": "so we all know that in tsdb the smallest",
    "start": "151440",
    "end": "154239"
  },
  {
    "text": "unit is actually a sample which just a",
    "start": "154239",
    "end": "157920"
  },
  {
    "text": "pair of",
    "start": "157920",
    "end": "159280"
  },
  {
    "text": "timestamps and value",
    "start": "159280",
    "end": "161280"
  },
  {
    "text": "so let's imagine if we map all these",
    "start": "161280",
    "end": "164560"
  },
  {
    "text": "data samples to a two-dimensional graph",
    "start": "164560",
    "end": "167760"
  },
  {
    "text": "for example the x-axis is time and",
    "start": "167760",
    "end": "170000"
  },
  {
    "text": "y-axis is serious",
    "start": "170000",
    "end": "171920"
  },
  {
    "text": "since the graph would look like this",
    "start": "171920",
    "end": "174239"
  },
  {
    "text": "and you can find that",
    "start": "174239",
    "end": "176239"
  },
  {
    "text": "each row just represents a series",
    "start": "176239",
    "end": "179920"
  },
  {
    "text": "and a series includes two parts on the",
    "start": "179920",
    "end": "183120"
  },
  {
    "text": "hand side we have some label sets",
    "start": "183120",
    "end": "186159"
  },
  {
    "text": "which are just some combination of label",
    "start": "186159",
    "end": "188480"
  },
  {
    "text": "pairs",
    "start": "188480",
    "end": "189440"
  },
  {
    "text": "uh used to uniquely identify one series",
    "start": "189440",
    "end": "192879"
  },
  {
    "text": "and for simplicity you can think",
    "start": "192879",
    "end": "196000"
  },
  {
    "text": "uh all these uh series labels on the",
    "start": "196000",
    "end": "199040"
  },
  {
    "text": "right hand side can be stored on disk uh",
    "start": "199040",
    "end": "202159"
  },
  {
    "text": "in some special format and this is",
    "start": "202159",
    "end": "204400"
  },
  {
    "text": "called the index file and it's used for",
    "start": "204400",
    "end": "206959"
  },
  {
    "text": "looking up your series faster during the",
    "start": "206959",
    "end": "208799"
  },
  {
    "text": "query time and on the left hand side",
    "start": "208799",
    "end": "212080"
  },
  {
    "text": "there are some",
    "start": "212080",
    "end": "213200"
  },
  {
    "text": "data samples and each row of samples",
    "start": "213200",
    "end": "216239"
  },
  {
    "text": "actually belongs to each series and to",
    "start": "216239",
    "end": "219360"
  },
  {
    "text": "store these",
    "start": "219360",
    "end": "220799"
  },
  {
    "text": "samples on disk they are encoded in some",
    "start": "220799",
    "end": "223519"
  },
  {
    "text": "special format to save a disk space and",
    "start": "223519",
    "end": "227599"
  },
  {
    "text": "this is called trunks",
    "start": "227599",
    "end": "230159"
  },
  {
    "text": "so when we run a query it will first try",
    "start": "230159",
    "end": "233040"
  },
  {
    "text": "to match the",
    "start": "233040",
    "end": "234560"
  },
  {
    "text": "series from the index file",
    "start": "234560",
    "end": "236879"
  },
  {
    "text": "and for each series it will try to fetch",
    "start": "236879",
    "end": "239680"
  },
  {
    "text": "the corresponding",
    "start": "239680",
    "end": "241200"
  },
  {
    "text": "trunks file on the right hand side and",
    "start": "241200",
    "end": "243200"
  },
  {
    "text": "finally return the results to the user",
    "start": "243200",
    "end": "246879"
  },
  {
    "text": "so yeah we covered the index and trunks",
    "start": "246879",
    "end": "249680"
  },
  {
    "text": "and i want to skip the tomstone file for",
    "start": "249680",
    "end": "252000"
  },
  {
    "start": "250000",
    "end": "250000"
  },
  {
    "text": "now and let's talk about compaction",
    "start": "252000",
    "end": "253840"
  },
  {
    "text": "first",
    "start": "253840",
    "end": "254879"
  },
  {
    "text": "so",
    "start": "254879",
    "end": "255760"
  },
  {
    "text": "in this diagram we prepared two uh",
    "start": "255760",
    "end": "258000"
  },
  {
    "text": "compacts",
    "start": "258000",
    "end": "259120"
  },
  {
    "text": "two blocks to compact together block a",
    "start": "259120",
    "end": "261600"
  },
  {
    "text": "and b are created from the head block so",
    "start": "261600",
    "end": "264880"
  },
  {
    "text": "they don't have any overlapping data by",
    "start": "264880",
    "end": "267040"
  },
  {
    "text": "default and as you can see",
    "start": "267040",
    "end": "269840"
  },
  {
    "text": "they have some common series like a job",
    "start": "269840",
    "end": "273199"
  },
  {
    "text": "equals http server",
    "start": "273199",
    "end": "275520"
  },
  {
    "text": "and also in the meantime they will have",
    "start": "275520",
    "end": "277199"
  },
  {
    "text": "some different series",
    "start": "277199",
    "end": "279040"
  },
  {
    "text": "like this",
    "start": "279040",
    "end": "280240"
  },
  {
    "text": "series from kubernetes environment",
    "start": "280240",
    "end": "282720"
  },
  {
    "text": "because we all know that kubernetes",
    "start": "282720",
    "end": "284320"
  },
  {
    "text": "environment is very dynamic so the parts",
    "start": "284320",
    "end": "287440"
  },
  {
    "text": "might be",
    "start": "287440",
    "end": "288560"
  },
  {
    "text": "created and deleted at different times",
    "start": "288560",
    "end": "291120"
  },
  {
    "text": "so it's very possible that",
    "start": "291120",
    "end": "293199"
  },
  {
    "text": "some series will exist in block a but",
    "start": "293199",
    "end": "296080"
  },
  {
    "text": "not in block b",
    "start": "296080",
    "end": "298400"
  },
  {
    "text": "so",
    "start": "298400",
    "end": "299680"
  },
  {
    "text": "after this setup let's start the",
    "start": "299680",
    "end": "301759"
  },
  {
    "text": "compaction",
    "start": "301759",
    "end": "303120"
  },
  {
    "text": "so",
    "start": "303120",
    "end": "305039"
  },
  {
    "text": "i think the first thing in the",
    "start": "305039",
    "end": "306639"
  },
  {
    "text": "compaction phase is to merge the several",
    "start": "306639",
    "end": "309520"
  },
  {
    "text": "index files together into a larger index",
    "start": "309520",
    "end": "312160"
  },
  {
    "text": "file so you can see we have two index",
    "start": "312160",
    "end": "315199"
  },
  {
    "text": "files from a and b and we merged merged",
    "start": "315199",
    "end": "318400"
  },
  {
    "text": "them into a larger one",
    "start": "318400",
    "end": "320080"
  },
  {
    "text": "so during this process the common series",
    "start": "320080",
    "end": "322639"
  },
  {
    "text": "labels such as the",
    "start": "322639",
    "end": "324479"
  },
  {
    "text": "labels from http server and node",
    "start": "324479",
    "end": "326800"
  },
  {
    "text": "exporters they are merged and duplicated",
    "start": "326800",
    "end": "329840"
  },
  {
    "text": "because we don't want to keep two copy",
    "start": "329840",
    "end": "331919"
  },
  {
    "text": "of them",
    "start": "331919",
    "end": "332880"
  },
  {
    "text": "and for the different series like the",
    "start": "332880",
    "end": "335280"
  },
  {
    "text": "kubernetes metrics they are just sorted",
    "start": "335280",
    "end": "337840"
  },
  {
    "text": "and combined together",
    "start": "337840",
    "end": "340160"
  },
  {
    "text": "so after the index merging is done",
    "start": "340160",
    "end": "342880"
  },
  {
    "text": "next we want to merge the trunks",
    "start": "342880",
    "end": "344960"
  },
  {
    "text": "together so let's switch to the two",
    "start": "344960",
    "end": "347440"
  },
  {
    "text": "dimensional graph again",
    "start": "347440",
    "end": "349440"
  },
  {
    "text": "so what we want to do is to first",
    "start": "349440",
    "end": "352000"
  },
  {
    "text": "iterate over all the series from the",
    "start": "352000",
    "end": "354320"
  },
  {
    "text": "newly created index file on the right",
    "start": "354320",
    "end": "357039"
  },
  {
    "text": "hand side",
    "start": "357039",
    "end": "358160"
  },
  {
    "text": "and for each series on the right hand",
    "start": "358160",
    "end": "361440"
  },
  {
    "text": "side we will try to fetch the trunks",
    "start": "361440",
    "end": "364080"
  },
  {
    "text": "from different blocks and merge the",
    "start": "364080",
    "end": "367039"
  },
  {
    "text": "trunks together",
    "start": "367039",
    "end": "369120"
  },
  {
    "text": "so uh this process would look like this",
    "start": "369120",
    "end": "372639"
  },
  {
    "text": "so because the two blocks don't have any",
    "start": "372639",
    "end": "375120"
  },
  {
    "text": "overlapping data we just need to combine",
    "start": "375120",
    "end": "377759"
  },
  {
    "text": "these trunks together horizontally",
    "start": "377759",
    "end": "381280"
  },
  {
    "text": "and yeah you can see for these different",
    "start": "381280",
    "end": "383919"
  },
  {
    "text": "series that only exists in uh",
    "start": "383919",
    "end": "387039"
  },
  {
    "text": "block a because b don't have this kind",
    "start": "387039",
    "end": "389360"
  },
  {
    "text": "of data so we don't need to merge",
    "start": "389360",
    "end": "392840"
  },
  {
    "text": "anything and yeah finally the results",
    "start": "392840",
    "end": "395840"
  },
  {
    "start": "395000",
    "end": "395000"
  },
  {
    "text": "would look like this so we got a larger",
    "start": "395840",
    "end": "398560"
  },
  {
    "text": "newly compacted block",
    "start": "398560",
    "end": "400319"
  },
  {
    "text": "and the index and trunks are merged",
    "start": "400319",
    "end": "402720"
  },
  {
    "text": "together so this is how the compaction",
    "start": "402720",
    "end": "405120"
  },
  {
    "text": "works",
    "start": "405120",
    "end": "406080"
  },
  {
    "text": "and but this is the most common case",
    "start": "406080",
    "end": "408160"
  },
  {
    "text": "because there's no data overlapping and",
    "start": "408160",
    "end": "410400"
  },
  {
    "text": "another case is called a vertical",
    "start": "410400",
    "end": "412479"
  },
  {
    "start": "411000",
    "end": "411000"
  },
  {
    "text": "compaction and uh yeah you can see block",
    "start": "412479",
    "end": "415199"
  },
  {
    "text": "a has and block b have some overlapping",
    "start": "415199",
    "end": "417840"
  },
  {
    "text": "data and this case happens a lot when uh",
    "start": "417840",
    "end": "420800"
  },
  {
    "text": "prometheus supports backfilling",
    "start": "420800",
    "end": "423680"
  },
  {
    "text": "however the compaction phase is actually",
    "start": "423680",
    "end": "425840"
  },
  {
    "text": "still the same what we need to do is",
    "start": "425840",
    "end": "427919"
  },
  {
    "text": "still emerging the index file together",
    "start": "427919",
    "end": "430639"
  },
  {
    "text": "and then we going over all these series",
    "start": "430639",
    "end": "433440"
  },
  {
    "text": "on the right hand side and try to merge",
    "start": "433440",
    "end": "435440"
  },
  {
    "text": "the trunks together",
    "start": "435440",
    "end": "437280"
  },
  {
    "text": "so",
    "start": "437280",
    "end": "438560"
  },
  {
    "text": "the only thing different is that",
    "start": "438560",
    "end": "440800"
  },
  {
    "text": "we might got some overlapping in this",
    "start": "440800",
    "end": "442560"
  },
  {
    "text": "case right and finally we will get a",
    "start": "442560",
    "end": "446080"
  },
  {
    "text": "newly compacted block like this and the",
    "start": "446080",
    "end": "448880"
  },
  {
    "text": "only like overlap trunks",
    "start": "448880",
    "end": "451680"
  },
  {
    "text": "is outlined here",
    "start": "451680",
    "end": "453440"
  },
  {
    "text": "and for these overlapped data we need to",
    "start": "453440",
    "end": "455680"
  },
  {
    "text": "rebuild the overlapped trunks and maybe",
    "start": "455680",
    "end": "458000"
  },
  {
    "text": "do some deduplication",
    "start": "458000",
    "end": "459919"
  },
  {
    "text": "but this process is actually very naive",
    "start": "459919",
    "end": "462240"
  },
  {
    "text": "in prometheus right now because",
    "start": "462240",
    "end": "464800"
  },
  {
    "text": "the duplication is only one-on-one which",
    "start": "464800",
    "end": "467599"
  },
  {
    "text": "means only exactly the same trunks can",
    "start": "467599",
    "end": "470479"
  },
  {
    "text": "be duplicate",
    "start": "470479",
    "end": "473120"
  },
  {
    "text": "so yeah i think that covers",
    "start": "473120",
    "end": "476160"
  },
  {
    "text": "all the process of compaction and next",
    "start": "476160",
    "end": "478639"
  },
  {
    "text": "let's take a look",
    "start": "478639",
    "end": "480160"
  },
  {
    "text": "at why we do we need it",
    "start": "480160",
    "end": "482800"
  },
  {
    "text": "so yeah let's think about the query",
    "start": "482800",
    "end": "485360"
  },
  {
    "start": "483000",
    "end": "483000"
  },
  {
    "text": "scenario so uh before compaction",
    "start": "485360",
    "end": "488720"
  },
  {
    "text": "uh",
    "start": "488720",
    "end": "489759"
  },
  {
    "text": "if we do a long-term query it will try",
    "start": "489759",
    "end": "493120"
  },
  {
    "text": "to match all these small blocks and hit",
    "start": "493120",
    "end": "496400"
  },
  {
    "text": "them so that in this way we need to go",
    "start": "496400",
    "end": "498960"
  },
  {
    "text": "through all these small index files and",
    "start": "498960",
    "end": "501440"
  },
  {
    "text": "try to merge the results together back",
    "start": "501440",
    "end": "504080"
  },
  {
    "text": "to the user",
    "start": "504080",
    "end": "505440"
  },
  {
    "text": "but if we can do some kind of compaction",
    "start": "505440",
    "end": "509440"
  },
  {
    "text": "then finally we will only have one",
    "start": "509440",
    "end": "511840"
  },
  {
    "text": "larger block in this case so the same",
    "start": "511840",
    "end": "514399"
  },
  {
    "text": "query will only hit one larger block and",
    "start": "514399",
    "end": "517599"
  },
  {
    "text": "we don't have to do anything related to",
    "start": "517599",
    "end": "520880"
  },
  {
    "text": "like",
    "start": "520880",
    "end": "521680"
  },
  {
    "text": "merging results or some online",
    "start": "521680",
    "end": "523440"
  },
  {
    "text": "deterification in this case so query",
    "start": "523440",
    "end": "526160"
  },
  {
    "text": "performance will be significantly",
    "start": "526160",
    "end": "528560"
  },
  {
    "text": "improved",
    "start": "528560",
    "end": "529760"
  },
  {
    "text": "and additionally because each index",
    "start": "529760",
    "end": "532399"
  },
  {
    "text": "files from the small blocks might",
    "start": "532399",
    "end": "535040"
  },
  {
    "text": "contain some common series as i",
    "start": "535040",
    "end": "537279"
  },
  {
    "text": "mentioned earlier so when we do the",
    "start": "537279",
    "end": "539680"
  },
  {
    "text": "compaction and merging process we can",
    "start": "539680",
    "end": "542320"
  },
  {
    "text": "save some disk space by duplicating the",
    "start": "542320",
    "end": "545200"
  },
  {
    "text": "index data",
    "start": "545200",
    "end": "547680"
  },
  {
    "text": "okay so",
    "start": "547680",
    "end": "549440"
  },
  {
    "start": "549000",
    "end": "549000"
  },
  {
    "text": "yeah finally let's take a look at the",
    "start": "549440",
    "end": "551680"
  },
  {
    "text": "tomstown file",
    "start": "551680",
    "end": "553120"
  },
  {
    "text": "so why do we need it",
    "start": "553120",
    "end": "554959"
  },
  {
    "text": "so let's imagine the case if we want to",
    "start": "554959",
    "end": "556959"
  },
  {
    "text": "delete some serious data from a block",
    "start": "556959",
    "end": "559600"
  },
  {
    "text": "then we can send a deletion request and",
    "start": "559600",
    "end": "561680"
  },
  {
    "text": "specify like the series matches and the",
    "start": "561680",
    "end": "564959"
  },
  {
    "text": "data time range we want to delete",
    "start": "564959",
    "end": "567360"
  },
  {
    "text": "and for performance reason these data to",
    "start": "567360",
    "end": "569839"
  },
  {
    "text": "delete are temporarily saved in a file",
    "start": "569839",
    "end": "572640"
  },
  {
    "text": "called tomstone",
    "start": "572640",
    "end": "574080"
  },
  {
    "text": "and",
    "start": "574080",
    "end": "575120"
  },
  {
    "text": "it's these data are deleted during the",
    "start": "575120",
    "end": "577680"
  },
  {
    "text": "compaction time so while we iterate over",
    "start": "577680",
    "end": "580880"
  },
  {
    "text": "all the series and we find that if",
    "start": "580880",
    "end": "584160"
  },
  {
    "text": "the series and trunks actually match the",
    "start": "584160",
    "end": "586160"
  },
  {
    "text": "data from the tombstone and if it",
    "start": "586160",
    "end": "588800"
  },
  {
    "text": "matches then we drop this and so that",
    "start": "588800",
    "end": "591600"
  },
  {
    "text": "the newly",
    "start": "591600",
    "end": "592640"
  },
  {
    "text": "compacted block will not have this data",
    "start": "592640",
    "end": "595600"
  },
  {
    "text": "so and additionally if the tomstown file",
    "start": "595600",
    "end": "598880"
  },
  {
    "text": "contains enough amount of serious data",
    "start": "598880",
    "end": "601440"
  },
  {
    "text": "the compaction itself will be triggered",
    "start": "601440",
    "end": "603680"
  },
  {
    "text": "to clean up the data in order to save",
    "start": "603680",
    "end": "606399"
  },
  {
    "text": "more disk space",
    "start": "606399",
    "end": "608800"
  },
  {
    "text": "so now i think you",
    "start": "608800",
    "end": "610640"
  },
  {
    "text": "have a high level idea about what is a",
    "start": "610640",
    "end": "612959"
  },
  {
    "text": "tomstow file but in the perspective of",
    "start": "612959",
    "end": "616320"
  },
  {
    "text": "compaction it's still just some kind of",
    "start": "616320",
    "end": "618959"
  },
  {
    "text": "modification to your index and trunks",
    "start": "618959",
    "end": "621839"
  },
  {
    "text": "data so yeah to me i think the essential",
    "start": "621839",
    "end": "625040"
  },
  {
    "text": "part of",
    "start": "625040",
    "end": "626320"
  },
  {
    "text": "compaction is merging the index and",
    "start": "626320",
    "end": "628160"
  },
  {
    "text": "trunks",
    "start": "628160",
    "end": "630480"
  },
  {
    "text": "so yeah i think we",
    "start": "630839",
    "end": "633600"
  },
  {
    "text": "cover the compaction but actually before",
    "start": "633600",
    "end": "636720"
  },
  {
    "start": "634000",
    "end": "634000"
  },
  {
    "text": "the compaction phase there's another",
    "start": "636720",
    "end": "638800"
  },
  {
    "text": "phase called planning and it's used to",
    "start": "638800",
    "end": "641360"
  },
  {
    "text": "choose which blocks we want to compact",
    "start": "641360",
    "end": "644079"
  },
  {
    "text": "together",
    "start": "644079",
    "end": "645120"
  },
  {
    "text": "so in this diagram there are five blocks",
    "start": "645120",
    "end": "647760"
  },
  {
    "text": "in the",
    "start": "647760",
    "end": "648959"
  },
  {
    "text": "tsdb directory now and the planner",
    "start": "648959",
    "end": "651920"
  },
  {
    "text": "choses to",
    "start": "651920",
    "end": "653600"
  },
  {
    "text": "compact the three blocks together into a",
    "start": "653600",
    "end": "656000"
  },
  {
    "text": "new new block f",
    "start": "656000",
    "end": "658000"
  },
  {
    "text": "so to choose these source blocks it",
    "start": "658000",
    "end": "660959"
  },
  {
    "text": "follows some uh planning algorithm",
    "start": "660959",
    "end": "663680"
  },
  {
    "text": "and right now the planning algorithm in",
    "start": "663680",
    "end": "665760"
  },
  {
    "text": "promises is a little bit simple and it",
    "start": "665760",
    "end": "668399"
  },
  {
    "text": "only checks the time range and number of",
    "start": "668399",
    "end": "670560"
  },
  {
    "text": "tombstones of each block",
    "start": "670560",
    "end": "672640"
  },
  {
    "text": "and this information can be easily found",
    "start": "672640",
    "end": "674880"
  },
  {
    "text": "from the metadata file",
    "start": "674880",
    "end": "677040"
  },
  {
    "text": "so i will not uh dive deep into the",
    "start": "677040",
    "end": "679440"
  },
  {
    "text": "planning algorithms here but ideally we",
    "start": "679440",
    "end": "682079"
  },
  {
    "text": "can extend it it to be more intelligent",
    "start": "682079",
    "end": "685279"
  },
  {
    "text": "and in tunnels we have supported one",
    "start": "685279",
    "end": "688640"
  },
  {
    "text": "planner called index size limit planner",
    "start": "688640",
    "end": "691440"
  },
  {
    "text": "to limit the maximum like index size of",
    "start": "691440",
    "end": "694240"
  },
  {
    "text": "the compacted block",
    "start": "694240",
    "end": "697360"
  },
  {
    "text": "so yeah i think that's all for the",
    "start": "698079",
    "end": "700800"
  },
  {
    "text": "compaction in promiscuous tsdb itself",
    "start": "700800",
    "end": "704160"
  },
  {
    "start": "704000",
    "end": "704000"
  },
  {
    "text": "next let's take a look at some",
    "start": "704160",
    "end": "706480"
  },
  {
    "text": "like more large data scale scenarios in",
    "start": "706480",
    "end": "709200"
  },
  {
    "text": "some system like tunnels or cortex",
    "start": "709200",
    "end": "712240"
  },
  {
    "text": "and actually i will not cover cortex",
    "start": "712240",
    "end": "714240"
  },
  {
    "text": "compactor here because it's built on top",
    "start": "714240",
    "end": "716959"
  },
  {
    "text": "of the tunnels compactor with some like",
    "start": "716959",
    "end": "719279"
  },
  {
    "text": "additional features",
    "start": "719279",
    "end": "721600"
  },
  {
    "text": "so a common like tunnels",
    "start": "721600",
    "end": "723680"
  },
  {
    "text": "determinant looks like this so we might",
    "start": "723680",
    "end": "726240"
  },
  {
    "text": "have two clusters and each cluster has",
    "start": "726240",
    "end": "728720"
  },
  {
    "text": "one promises with one",
    "start": "728720",
    "end": "730720"
  },
  {
    "text": "tunnel sidecar",
    "start": "730720",
    "end": "732320"
  },
  {
    "text": "and in prometheus we will configure the",
    "start": "732320",
    "end": "735040"
  },
  {
    "text": "cluster name as the external labels",
    "start": "735040",
    "end": "738480"
  },
  {
    "text": "and the sidecar will try to inject the",
    "start": "738480",
    "end": "741519"
  },
  {
    "text": "external labels to the tsdb blocks and",
    "start": "741519",
    "end": "745040"
  },
  {
    "text": "upload them to the object storage every",
    "start": "745040",
    "end": "747600"
  },
  {
    "text": "two hours",
    "start": "747600",
    "end": "748800"
  },
  {
    "text": "and besides we also have one central",
    "start": "748800",
    "end": "752320"
  },
  {
    "text": "tunnels compactor running against the",
    "start": "752320",
    "end": "754560"
  },
  {
    "text": "object storage",
    "start": "754560",
    "end": "756240"
  },
  {
    "text": "and the compactor works in four steps",
    "start": "756240",
    "end": "760240"
  },
  {
    "text": "and first because compaction needs to do",
    "start": "760240",
    "end": "762800"
  },
  {
    "text": "some planning first",
    "start": "762800",
    "end": "764480"
  },
  {
    "text": "and planning step only requires the",
    "start": "764480",
    "end": "766800"
  },
  {
    "text": "block metadata",
    "start": "766800",
    "end": "768320"
  },
  {
    "text": "so the compactor will have a separate",
    "start": "768320",
    "end": "770720"
  },
  {
    "text": "job to fetch the block metadata from the",
    "start": "770720",
    "end": "774079"
  },
  {
    "text": "object storage and download them to a",
    "start": "774079",
    "end": "776079"
  },
  {
    "text": "local disk",
    "start": "776079",
    "end": "777680"
  },
  {
    "text": "and after this is done then it can start",
    "start": "777680",
    "end": "780800"
  },
  {
    "text": "planning using this local metadata",
    "start": "780800",
    "end": "783519"
  },
  {
    "text": "and",
    "start": "783519",
    "end": "784639"
  },
  {
    "text": "the third step if there's an available",
    "start": "784639",
    "end": "787040"
  },
  {
    "text": "compaction plan",
    "start": "787040",
    "end": "788399"
  },
  {
    "text": "it will",
    "start": "788399",
    "end": "789600"
  },
  {
    "text": "try to download all these required",
    "start": "789600",
    "end": "791600"
  },
  {
    "text": "blocks",
    "start": "791600",
    "end": "792560"
  },
  {
    "text": "and compact them locally",
    "start": "792560",
    "end": "794959"
  },
  {
    "text": "and finally it will try to upload the",
    "start": "794959",
    "end": "797360"
  },
  {
    "text": "new block to the bucket and delete all",
    "start": "797360",
    "end": "800320"
  },
  {
    "text": "these source blocks",
    "start": "800320",
    "end": "802959"
  },
  {
    "text": "so as you can see you can find that stop",
    "start": "802959",
    "end": "806240"
  },
  {
    "text": "step 2 and step 3 is exactly the same as",
    "start": "806240",
    "end": "809680"
  },
  {
    "text": "the prometheus compactor",
    "start": "809680",
    "end": "812079"
  },
  {
    "text": "and the tunnels compactor just adds step",
    "start": "812079",
    "end": "815120"
  },
  {
    "text": "one and four to get it working with the",
    "start": "815120",
    "end": "817920"
  },
  {
    "text": "object storage uh environment",
    "start": "817920",
    "end": "821680"
  },
  {
    "text": "and actually uh there's a little bit",
    "start": "822000",
    "end": "823760"
  },
  {
    "text": "difference in the planning phase so",
    "start": "823760",
    "end": "826800"
  },
  {
    "text": "planning is actually done separately in",
    "start": "826800",
    "end": "829040"
  },
  {
    "text": "different groups and each group is",
    "start": "829040",
    "end": "831839"
  },
  {
    "text": "identified by the",
    "start": "831839",
    "end": "834320"
  },
  {
    "text": "external labels added to that block",
    "start": "834320",
    "end": "837839"
  },
  {
    "text": "so you can see here we have blocks from",
    "start": "837839",
    "end": "840480"
  },
  {
    "text": "cluster europe and u.s",
    "start": "840480",
    "end": "842880"
  },
  {
    "text": "so these blocks should be planned and",
    "start": "842880",
    "end": "845839"
  },
  {
    "text": "compact together because we don't want",
    "start": "845839",
    "end": "847920"
  },
  {
    "text": "to have a super larger blocks for maybe",
    "start": "847920",
    "end": "851120"
  },
  {
    "text": "all the cluster go away",
    "start": "851120",
    "end": "853440"
  },
  {
    "text": "and",
    "start": "853440",
    "end": "854560"
  },
  {
    "text": "yeah so finally we got two",
    "start": "854560",
    "end": "856720"
  },
  {
    "text": "blocks for europe and u.s",
    "start": "856720",
    "end": "859519"
  },
  {
    "text": "and uh yes that's how",
    "start": "859519",
    "end": "861680"
  },
  {
    "text": "thanos compactor works basically",
    "start": "861680",
    "end": "864720"
  },
  {
    "text": "and",
    "start": "864720",
    "end": "866160"
  },
  {
    "text": "next let's see some extensions we made",
    "start": "866160",
    "end": "868959"
  },
  {
    "text": "to the tunnels compactor to deal with",
    "start": "868959",
    "end": "871600"
  },
  {
    "text": "our like large-scale data use cases",
    "start": "871600",
    "end": "875920"
  },
  {
    "start": "876000",
    "end": "876000"
  },
  {
    "text": "and yeah the first scenario is actually",
    "start": "876399",
    "end": "878959"
  },
  {
    "text": "super common",
    "start": "878959",
    "end": "880320"
  },
  {
    "text": "where we deployed two",
    "start": "880320",
    "end": "882320"
  },
  {
    "text": "promises instances at each cluster for",
    "start": "882320",
    "end": "885440"
  },
  {
    "text": "high availability purposes",
    "start": "885440",
    "end": "887600"
  },
  {
    "text": "and in this case a new external label",
    "start": "887600",
    "end": "890079"
  },
  {
    "text": "called replica is added to identify the",
    "start": "890079",
    "end": "893199"
  },
  {
    "text": "source",
    "start": "893199",
    "end": "894240"
  },
  {
    "text": "premises of these data",
    "start": "894240",
    "end": "896839"
  },
  {
    "text": "blocks and then the problem of this",
    "start": "896839",
    "end": "899920"
  },
  {
    "start": "899000",
    "end": "899000"
  },
  {
    "text": "setup is actually the data duplication",
    "start": "899920",
    "end": "902560"
  },
  {
    "text": "problem",
    "start": "902560",
    "end": "903440"
  },
  {
    "text": "because of the grouping mechanism",
    "start": "903440",
    "end": "906399"
  },
  {
    "text": "and the external labels for different",
    "start": "906399",
    "end": "908639"
  },
  {
    "text": "replicas are actually different so we",
    "start": "908639",
    "end": "910480"
  },
  {
    "text": "will have two groups for two replicas",
    "start": "910480",
    "end": "913680"
  },
  {
    "text": "but actually they are still in the same",
    "start": "913680",
    "end": "915760"
  },
  {
    "text": "cluster right so finally we will have",
    "start": "915760",
    "end": "918399"
  },
  {
    "text": "two compacted blocks",
    "start": "918399",
    "end": "920480"
  },
  {
    "text": "like in this cluster us with totally",
    "start": "920480",
    "end": "923760"
  },
  {
    "text": "overlapped",
    "start": "923760",
    "end": "924880"
  },
  {
    "text": "time range for the two blocks",
    "start": "924880",
    "end": "927519"
  },
  {
    "text": "and obviously you can see this is not",
    "start": "927519",
    "end": "930639"
  },
  {
    "text": "good because",
    "start": "930639",
    "end": "932000"
  },
  {
    "text": "firstly we double the space usage by",
    "start": "932000",
    "end": "934959"
  },
  {
    "text": "having two blocks with almost the same",
    "start": "934959",
    "end": "937360"
  },
  {
    "text": "data",
    "start": "937360",
    "end": "938320"
  },
  {
    "text": "and also during the query time we have",
    "start": "938320",
    "end": "940560"
  },
  {
    "text": "to do some online the two duplication",
    "start": "940560",
    "end": "944079"
  },
  {
    "text": "because also the query touch the two",
    "start": "944079",
    "end": "946560"
  },
  {
    "text": "blocks the query performance is not as",
    "start": "946560",
    "end": "949440"
  },
  {
    "text": "good as like with only one block",
    "start": "949440",
    "end": "954399"
  },
  {
    "start": "954000",
    "end": "954000"
  },
  {
    "text": "so to solve this actually",
    "start": "954399",
    "end": "957120"
  },
  {
    "text": "like as i mentioned we can use the",
    "start": "957120",
    "end": "960000"
  },
  {
    "text": "built-in vertical compaction mechanism",
    "start": "960000",
    "end": "962959"
  },
  {
    "text": "to merge the overlapped blocks right and",
    "start": "962959",
    "end": "965759"
  },
  {
    "text": "tunnels provide a flag called the",
    "start": "965759",
    "end": "967600"
  },
  {
    "text": "duplication replica label and if we",
    "start": "967600",
    "end": "970560"
  },
  {
    "text": "specify it the replica label of the",
    "start": "970560",
    "end": "973759"
  },
  {
    "text": "replica external label can be ignored",
    "start": "973759",
    "end": "976800"
  },
  {
    "text": "during the grouping and planning phase",
    "start": "976800",
    "end": "979440"
  },
  {
    "text": "and all these six blocks",
    "start": "979440",
    "end": "982560"
  },
  {
    "text": "will be planned and compacted together",
    "start": "982560",
    "end": "986720"
  },
  {
    "text": "so yes this is good because we utilize",
    "start": "986720",
    "end": "989759"
  },
  {
    "text": "the default vertical compaction",
    "start": "989759",
    "end": "991360"
  },
  {
    "text": "mechanism and use it to improve the",
    "start": "991360",
    "end": "994000"
  },
  {
    "text": "space usage and the query performance",
    "start": "994000",
    "end": "997680"
  },
  {
    "text": "but the question is is it really good",
    "start": "997680",
    "end": "1000399"
  },
  {
    "text": "enough",
    "start": "1000399",
    "end": "1001600"
  },
  {
    "text": "and what about the trunks data",
    "start": "1001600",
    "end": "1005519"
  },
  {
    "text": "so actually the trunks data is still",
    "start": "1005519",
    "end": "1007759"
  },
  {
    "text": "problematic",
    "start": "1007759",
    "end": "1009199"
  },
  {
    "text": "because the trunks data are from",
    "start": "1009199",
    "end": "1011680"
  },
  {
    "text": "high availability promises pairs and",
    "start": "1011680",
    "end": "1014800"
  },
  {
    "text": "actually they cannot be perfectly",
    "start": "1014800",
    "end": "1016720"
  },
  {
    "text": "duplicated by the default vertical",
    "start": "1016720",
    "end": "1019279"
  },
  {
    "text": "compaction mechanism because we have two",
    "start": "1019279",
    "end": "1022000"
  },
  {
    "text": "promises instances and they cannot",
    "start": "1022000",
    "end": "1025038"
  },
  {
    "text": "actually perfectly collect samples at",
    "start": "1025039",
    "end": "1028319"
  },
  {
    "text": "exactly the same time so the timestamp",
    "start": "1028319",
    "end": "1030959"
  },
  {
    "text": "of these samples from two promises",
    "start": "1030959",
    "end": "1033839"
  },
  {
    "text": "cannot be",
    "start": "1033839",
    "end": "1035199"
  },
  {
    "text": "the same however the default vertical",
    "start": "1035199",
    "end": "1037760"
  },
  {
    "text": "compaction only works for one-on-one",
    "start": "1037760",
    "end": "1040240"
  },
  {
    "text": "vertication",
    "start": "1040240",
    "end": "1041678"
  },
  {
    "text": "but in the case of different timestamps",
    "start": "1041679",
    "end": "1044480"
  },
  {
    "text": "it doesn't work so finally we still have",
    "start": "1044480",
    "end": "1047520"
  },
  {
    "text": "double space usage for",
    "start": "1047520",
    "end": "1050160"
  },
  {
    "text": "like this replica data",
    "start": "1050160",
    "end": "1053440"
  },
  {
    "text": "so and it would be better to have some",
    "start": "1053440",
    "end": "1055919"
  },
  {
    "text": "like smarter vertical compaction",
    "start": "1055919",
    "end": "1057919"
  },
  {
    "text": "algorithm to do this duplication for",
    "start": "1057919",
    "end": "1060720"
  },
  {
    "text": "this use case",
    "start": "1060720",
    "end": "1062000"
  },
  {
    "text": "and actually what we want is to have",
    "start": "1062000",
    "end": "1064320"
  },
  {
    "text": "it to have something like this we want",
    "start": "1064320",
    "end": "1066240"
  },
  {
    "text": "to maybe only keep one sample from only",
    "start": "1066240",
    "end": "1068720"
  },
  {
    "text": "one replica and that's already good",
    "start": "1068720",
    "end": "1070320"
  },
  {
    "text": "enough to us",
    "start": "1070320",
    "end": "1072880"
  },
  {
    "text": "so this can be done by extending the",
    "start": "1072880",
    "end": "1075919"
  },
  {
    "start": "1073000",
    "end": "1073000"
  },
  {
    "text": "like duplication algorithm used in the",
    "start": "1075919",
    "end": "1078240"
  },
  {
    "text": "vertical compaction and in tunnels we",
    "start": "1078240",
    "end": "1080640"
  },
  {
    "text": "supported the same",
    "start": "1080640",
    "end": "1082880"
  },
  {
    "text": "penalty duration algorithms used by the",
    "start": "1082880",
    "end": "1085520"
  },
  {
    "text": "tunnel squarer and we applied for the",
    "start": "1085520",
    "end": "1088240"
  },
  {
    "text": "location at the compactor side so this",
    "start": "1088240",
    "end": "1091200"
  },
  {
    "text": "saves the space usage a lot",
    "start": "1091200",
    "end": "1095039"
  },
  {
    "text": "and another challenge we made",
    "start": "1095039",
    "end": "1098000"
  },
  {
    "start": "1096000",
    "end": "1096000"
  },
  {
    "text": "of internals is to how is about how to",
    "start": "1098000",
    "end": "1100799"
  },
  {
    "text": "deal with some",
    "start": "1100799",
    "end": "1102480"
  },
  {
    "text": "data manu manipulation requests from the",
    "start": "1102480",
    "end": "1105520"
  },
  {
    "text": "object storage for example we want to",
    "start": "1105520",
    "end": "1107919"
  },
  {
    "text": "delete some high cardinality series or",
    "start": "1107919",
    "end": "1110640"
  },
  {
    "text": "we want to relabel this series or rename",
    "start": "1110640",
    "end": "1113600"
  },
  {
    "text": "this metrics",
    "start": "1113600",
    "end": "1115679"
  },
  {
    "text": "and the problem is that these blocks are",
    "start": "1115679",
    "end": "1118240"
  },
  {
    "text": "from object storage and they are",
    "start": "1118240",
    "end": "1120640"
  },
  {
    "text": "immutable by default so can we modify",
    "start": "1120640",
    "end": "1123440"
  },
  {
    "text": "the existing index and trunks easily",
    "start": "1123440",
    "end": "1128160"
  },
  {
    "text": "so",
    "start": "1128160",
    "end": "1128880"
  },
  {
    "text": "yeah because today's topic is about",
    "start": "1128880",
    "end": "1131039"
  },
  {
    "text": "compaction and actually tunnels uses",
    "start": "1131039",
    "end": "1133200"
  },
  {
    "text": "this compaction mechanism",
    "start": "1133200",
    "end": "1135120"
  },
  {
    "text": "to achieve this request",
    "start": "1135120",
    "end": "1137440"
  },
  {
    "text": "so let me use uh relabeling for an",
    "start": "1137440",
    "end": "1140480"
  },
  {
    "start": "1139000",
    "end": "1139000"
  },
  {
    "text": "example so we have this kind of reliable",
    "start": "1140480",
    "end": "1143039"
  },
  {
    "text": "in configuration",
    "start": "1143039",
    "end": "1144559"
  },
  {
    "text": "and what it does is that the first",
    "start": "1144559",
    "end": "1146320"
  },
  {
    "text": "reliable request",
    "start": "1146320",
    "end": "1147919"
  },
  {
    "text": "just renames",
    "start": "1147919",
    "end": "1149520"
  },
  {
    "text": "this node cpu metrics to another name",
    "start": "1149520",
    "end": "1152880"
  },
  {
    "text": "and another",
    "start": "1152880",
    "end": "1154320"
  },
  {
    "text": "reliable request just drops this label",
    "start": "1154320",
    "end": "1157280"
  },
  {
    "text": "with the name code",
    "start": "1157280",
    "end": "1160080"
  },
  {
    "text": "so in this case we are still trying to",
    "start": "1160080",
    "end": "1162080"
  },
  {
    "text": "do a compaction for this for this block",
    "start": "1162080",
    "end": "1164400"
  },
  {
    "text": "we want to modify",
    "start": "1164400",
    "end": "1166160"
  },
  {
    "text": "and",
    "start": "1166160",
    "end": "1167200"
  },
  {
    "text": "while we like iterate over all these",
    "start": "1167200",
    "end": "1169679"
  },
  {
    "text": "series on the right hand side we just do",
    "start": "1169679",
    "end": "1172880"
  },
  {
    "text": "this relabeling",
    "start": "1172880",
    "end": "1174880"
  },
  {
    "text": "to this to each series label",
    "start": "1174880",
    "end": "1177280"
  },
  {
    "text": "and",
    "start": "1177280",
    "end": "1178880"
  },
  {
    "text": "if this series",
    "start": "1178880",
    "end": "1180240"
  },
  {
    "text": "series label changes then we can do some",
    "start": "1180240",
    "end": "1183679"
  },
  {
    "text": "actions accordingly for example in the",
    "start": "1183679",
    "end": "1186000"
  },
  {
    "text": "case of label",
    "start": "1186000",
    "end": "1187360"
  },
  {
    "text": "replace it's super easy because we just",
    "start": "1187360",
    "end": "1190160"
  },
  {
    "text": "needed to rename the labels on the right",
    "start": "1190160",
    "end": "1193440"
  },
  {
    "text": "hand side so only index parts need to be",
    "start": "1193440",
    "end": "1195919"
  },
  {
    "text": "changed we don't need to modify anything",
    "start": "1195919",
    "end": "1198240"
  },
  {
    "text": "related to trunks",
    "start": "1198240",
    "end": "1200000"
  },
  {
    "text": "but the label drop case is a little bit",
    "start": "1200000",
    "end": "1202320"
  },
  {
    "text": "trickier because the code label",
    "start": "1202320",
    "end": "1205600"
  },
  {
    "text": "once the code label is deleted then",
    "start": "1205600",
    "end": "1207840"
  },
  {
    "text": "these three series will be",
    "start": "1207840",
    "end": "1210240"
  },
  {
    "text": "merged into one series right so",
    "start": "1210240",
    "end": "1213520"
  },
  {
    "text": "in this case we need to also merge the",
    "start": "1213520",
    "end": "1215840"
  },
  {
    "text": "corresponding trunks files",
    "start": "1215840",
    "end": "1217760"
  },
  {
    "text": "and combine them and do some duplication",
    "start": "1217760",
    "end": "1220480"
  },
  {
    "text": "in this case but anyway finally we",
    "start": "1220480",
    "end": "1223760"
  },
  {
    "text": "re-labeled this pcb block and we got a",
    "start": "1223760",
    "end": "1226799"
  },
  {
    "text": "new block",
    "start": "1226799",
    "end": "1228159"
  },
  {
    "text": "after this compaction",
    "start": "1228159",
    "end": "1231200"
  },
  {
    "text": "so this is cool so why not we have this",
    "start": "1231760",
    "end": "1234640"
  },
  {
    "start": "1232000",
    "end": "1232000"
  },
  {
    "text": "support in premises as well so recently",
    "start": "1234640",
    "end": "1237360"
  },
  {
    "text": "i opened the pr to support this kind of",
    "start": "1237360",
    "end": "1240320"
  },
  {
    "text": "use case in the prom tool",
    "start": "1240320",
    "end": "1242559"
  },
  {
    "text": "and actually the required change is",
    "start": "1242559",
    "end": "1244400"
  },
  {
    "text": "super easy",
    "start": "1244400",
    "end": "1247120"
  },
  {
    "start": "1247000",
    "end": "1247000"
  },
  {
    "text": "so first i added one interface called",
    "start": "1247360",
    "end": "1250159"
  },
  {
    "text": "modifier and it has only one modify",
    "start": "1250159",
    "end": "1253280"
  },
  {
    "text": "method and this is just used to",
    "start": "1253280",
    "end": "1256880"
  },
  {
    "text": "apply some additional modification logic",
    "start": "1256880",
    "end": "1260080"
  },
  {
    "text": "to the index files and to the trunks",
    "start": "1260080",
    "end": "1262080"
  },
  {
    "text": "files during the compaction phase",
    "start": "1262080",
    "end": "1264720"
  },
  {
    "text": "and for the promises built-in write",
    "start": "1264720",
    "end": "1267280"
  },
  {
    "text": "method",
    "start": "1267280",
    "end": "1268240"
  },
  {
    "text": "it's extended with a list of modifiers",
    "start": "1268240",
    "end": "1271200"
  },
  {
    "text": "to apply this logic",
    "start": "1271200",
    "end": "1274159"
  },
  {
    "text": "and to view it more easily so this is",
    "start": "1274159",
    "end": "1277679"
  },
  {
    "start": "1276000",
    "end": "1276000"
  },
  {
    "text": "the graph again with the modifier so you",
    "start": "1277679",
    "end": "1280240"
  },
  {
    "text": "can see the modifier just works as a",
    "start": "1280240",
    "end": "1282799"
  },
  {
    "text": "middle layer uh in the compaction",
    "start": "1282799",
    "end": "1284960"
  },
  {
    "text": "process",
    "start": "1284960",
    "end": "1286080"
  },
  {
    "text": "and during the modif during the",
    "start": "1286080",
    "end": "1288240"
  },
  {
    "text": "compaction phase we still need to merge",
    "start": "1288240",
    "end": "1290720"
  },
  {
    "text": "the index files and trunks together but",
    "start": "1290720",
    "end": "1293280"
  },
  {
    "text": "we apply the modification to them before",
    "start": "1293280",
    "end": "1295840"
  },
  {
    "text": "writing a new block",
    "start": "1295840",
    "end": "1298559"
  },
  {
    "text": "so what can we achieve using this",
    "start": "1298559",
    "end": "1300000"
  },
  {
    "start": "1299000",
    "end": "1299000"
  },
  {
    "text": "modifier so let's do some brainstorming",
    "start": "1300000",
    "end": "1302320"
  },
  {
    "text": "about down sampling so you can simply",
    "start": "1302320",
    "end": "1304960"
  },
  {
    "text": "think about don't sampling as a process",
    "start": "1304960",
    "end": "1306880"
  },
  {
    "text": "of increasing the script interval in",
    "start": "1306880",
    "end": "1309360"
  },
  {
    "text": "premises",
    "start": "1309360",
    "end": "1310640"
  },
  {
    "text": "and in the diagram you can see we done",
    "start": "1310640",
    "end": "1313360"
  },
  {
    "text": "sample data from 15 seconds to one",
    "start": "1313360",
    "end": "1315600"
  },
  {
    "text": "minutes resolution",
    "start": "1315600",
    "end": "1317440"
  },
  {
    "text": "and after down sampling we have fewer",
    "start": "1317440",
    "end": "1319760"
  },
  {
    "text": "samples in this case",
    "start": "1319760",
    "end": "1321919"
  },
  {
    "text": "and you can imagine",
    "start": "1321919",
    "end": "1324320"
  },
  {
    "text": "in the case of down sampling we just",
    "start": "1324320",
    "end": "1326240"
  },
  {
    "text": "need to change the",
    "start": "1326240",
    "end": "1328000"
  },
  {
    "text": "trunks file and we don't need to modify",
    "start": "1328000",
    "end": "1330240"
  },
  {
    "text": "anything related to the index",
    "start": "1330240",
    "end": "1333360"
  },
  {
    "text": "so actually we can implement a down",
    "start": "1333360",
    "end": "1335679"
  },
  {
    "text": "sampling modifier and with the",
    "start": "1335679",
    "end": "1338240"
  },
  {
    "text": "configuration on the left and high left",
    "start": "1338240",
    "end": "1340400"
  },
  {
    "text": "left hand side when we do the compaction",
    "start": "1340400",
    "end": "1343440"
  },
  {
    "text": "we find all the matched series with this",
    "start": "1343440",
    "end": "1346240"
  },
  {
    "text": "mattress label",
    "start": "1346240",
    "end": "1347840"
  },
  {
    "text": "and just rebuild these trunks with this",
    "start": "1347840",
    "end": "1350640"
  },
  {
    "text": "configured resolution",
    "start": "1350640",
    "end": "1354000"
  },
  {
    "text": "and yes the last",
    "start": "1354000",
    "end": "1355919"
  },
  {
    "text": "brainstorming case is about dynamic",
    "start": "1355919",
    "end": "1357919"
  },
  {
    "text": "retention we can also implement a",
    "start": "1357919",
    "end": "1360240"
  },
  {
    "text": "retention modifier",
    "start": "1360240",
    "end": "1361840"
  },
  {
    "text": "and during the compaction time we can",
    "start": "1361840",
    "end": "1364240"
  },
  {
    "text": "check whether these series",
    "start": "1364240",
    "end": "1366640"
  },
  {
    "text": "match the",
    "start": "1366640",
    "end": "1367919"
  },
  {
    "text": "required matches and for these matches",
    "start": "1367919",
    "end": "1370640"
  },
  {
    "text": "series we move them to a new block and",
    "start": "1370640",
    "end": "1373440"
  },
  {
    "text": "keep them for a longer time",
    "start": "1373440",
    "end": "1375919"
  },
  {
    "text": "so yeah i think that's all for today",
    "start": "1375919",
    "end": "1379120"
  },
  {
    "text": "about my talk",
    "start": "1379120",
    "end": "1380640"
  },
  {
    "text": "so yeah thank you for",
    "start": "1380640",
    "end": "1382640"
  },
  {
    "text": "everyone for listening and i'm ready for",
    "start": "1382640",
    "end": "1385039"
  },
  {
    "text": "the",
    "start": "1385039",
    "end": "1386159"
  },
  {
    "text": "current part thank you",
    "start": "1386159",
    "end": "1388830"
  },
  {
    "text": "[Applause]",
    "start": "1388830",
    "end": "1394640"
  },
  {
    "text": "we're gonna have a slightly shorter q a",
    "start": "1394640",
    "end": "1396799"
  },
  {
    "text": "for this session to catch up a little",
    "start": "1396799",
    "end": "1398159"
  },
  {
    "text": "bit on time because we've run a little",
    "start": "1398159",
    "end": "1399679"
  },
  {
    "text": "bit over does anybody have a question",
    "start": "1399679",
    "end": "1401840"
  },
  {
    "text": "they'd like me to repeat for our virtual",
    "start": "1401840",
    "end": "1403919"
  },
  {
    "text": "audience",
    "start": "1403919",
    "end": "1406320"
  },
  {
    "text": "all right i have one then um",
    "start": "1409280",
    "end": "1412240"
  },
  {
    "text": "you mentioned the two dimensions of",
    "start": "1412240",
    "end": "1414880"
  },
  {
    "text": "vertical and horizontal that you compact",
    "start": "1414880",
    "end": "1416720"
  },
  {
    "text": "by",
    "start": "1416720",
    "end": "1417600"
  },
  {
    "text": "um i think i'm correct in saying",
    "start": "1417600",
    "end": "1419760"
  },
  {
    "text": "horizontal is your time there and",
    "start": "1419760",
    "end": "1422159"
  },
  {
    "text": "vertical is um overlapping data that",
    "start": "1422159",
    "end": "1424799"
  },
  {
    "text": "sort of thing yeah but actually uh i",
    "start": "1424799",
    "end": "1427039"
  },
  {
    "text": "think vertical and horizontal is i mean",
    "start": "1427039",
    "end": "1429600"
  },
  {
    "text": "the in z graph you can see when we try",
    "start": "1429600",
    "end": "1431600"
  },
  {
    "text": "to merge the trunks together it's just",
    "start": "1431600",
    "end": "1434000"
  },
  {
    "text": "still like horizontally merging right",
    "start": "1434000",
    "end": "1436000"
  },
  {
    "text": "but the if there's no time overlapping",
    "start": "1436000",
    "end": "1439520"
  },
  {
    "text": "we don't need to do anything we just",
    "start": "1439520",
    "end": "1441200"
  },
  {
    "text": "change these trunks together but if",
    "start": "1441200",
    "end": "1443520"
  },
  {
    "text": "there's any overlapping we need to",
    "start": "1443520",
    "end": "1445360"
  },
  {
    "text": "rebuild the trunk",
    "start": "1445360",
    "end": "1446799"
  },
  {
    "text": "so yeah i was going to ask do you see",
    "start": "1446799",
    "end": "1449039"
  },
  {
    "text": "any other dimensions",
    "start": "1449039",
    "end": "1450720"
  },
  {
    "text": "that",
    "start": "1450720",
    "end": "1451679"
  },
  {
    "text": "besides those two that you would",
    "start": "1451679",
    "end": "1453840"
  },
  {
    "text": "like them yeah i don't think so yeah i",
    "start": "1453840",
    "end": "1456080"
  },
  {
    "text": "think only only two dimensions",
    "start": "1456080",
    "end": "1458640"
  },
  {
    "text": "well thank you very much",
    "start": "1458640",
    "end": "1460240"
  },
  {
    "text": "okay thank you",
    "start": "1460240",
    "end": "1463720"
  },
  {
    "text": "[Applause]",
    "start": "1464170",
    "end": "1468650"
  }
]
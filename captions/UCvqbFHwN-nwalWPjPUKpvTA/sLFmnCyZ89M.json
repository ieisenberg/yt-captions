[
  {
    "text": "thank you very much for being here uh I am Paulo Paderno i am a software",
    "start": "320",
    "end": "5359"
  },
  {
    "text": "engineer working on Redat on the messaging and data streaming team so mostly working on Apachi Kafka and even",
    "start": "5359",
    "end": "12160"
  },
  {
    "text": "on stream that this is what we are going to talk about which is a CNCF incubating",
    "start": "12160",
    "end": "17520"
  },
  {
    "text": "project um and it's about running Kafka Kubernetes i'm one of the core maintainers and with me there is Tina hi",
    "start": "17520",
    "end": "25840"
  },
  {
    "text": "everyone uh my name is Kantasa but I usually go by Tina so I'm a software engineer at Red Hat as well and I also",
    "start": "25840",
    "end": "33040"
  },
  {
    "text": "contribute to StreamZ and Kafka as well all right um so agenda for this",
    "start": "33040",
    "end": "40719"
  },
  {
    "text": "session we will start with introducing um Kafka and StreamZy so don't worry if you don't know too much about them and",
    "start": "40719",
    "end": "47520"
  },
  {
    "text": "we'll also talk about some of the new features that came to streams uh such as craft tier storage and auto rebalancing",
    "start": "47520",
    "end": "54879"
  },
  {
    "text": "and we will also talk about some of the exciting upcoming",
    "start": "54879",
    "end": "60039"
  },
  {
    "text": "features so what is Apache Kafka it's a leading distributed event streaming platform",
    "start": "60039",
    "end": "66439"
  },
  {
    "text": "um it scales horizontally and has a it's highly available in fault tolerant and",
    "start": "66439",
    "end": "72799"
  },
  {
    "text": "it has wide variety of use cases it can capture data in real time um from",
    "start": "72799",
    "end": "78799"
  },
  {
    "text": "various sources uh data sources like database event driven applications or other cloud services and store that",
    "start": "78799",
    "end": "85759"
  },
  {
    "text": "durably to be uh consumed by other systems to uh manipulate or um react to",
    "start": "85759",
    "end": "92880"
  },
  {
    "text": "them in real time so it was originally created by LinkedIn and open sourced under Apache",
    "start": "92880",
    "end": "99920"
  },
  {
    "text": "uh software foundation it's licensed under Apache license",
    "start": "99920",
    "end": "104720"
  },
  {
    "text": "20 so what is StreamZ um so it's also um",
    "start": "105880",
    "end": "111600"
  },
  {
    "text": "open source project it's CNC included project as Paulo already mentioned it's also licensed under Apache license",
    "start": "111600",
    "end": "117960"
  },
  {
    "text": "20 um so Kafka sounds great in terms of what it can offer but it is",
    "start": "117960",
    "end": "123439"
  },
  {
    "text": "operationally very complex um that's why uh running CFKA on Kubernetes become",
    "start": "123439",
    "end": "128959"
  },
  {
    "text": "very popular it was probably the most popular way to run Kafka how however even that presents uh",
    "start": "128959",
    "end": "135760"
  },
  {
    "text": "its own challenges because Kubernetes doesn't have that Kafka specific necessary Kafka specific knowledge um to",
    "start": "135760",
    "end": "142959"
  },
  {
    "text": "keep that high maintain um highly uh sorry availability and performance",
    "start": "142959",
    "end": "149920"
  },
  {
    "text": "so streams manages Apache Cafka and Kubernetes as I said uh it's based on Kubernetes operator pattern and it",
    "start": "149920",
    "end": "156879"
  },
  {
    "text": "provides various operators for running and managing cafka components and it and massively reduces uh operational",
    "start": "156879",
    "end": "165599"
  },
  {
    "text": "overhead so streams really allows you to run kubernet uh cafka in a kubernetes native way it uses the CRDs to extend uh",
    "start": "165720",
    "end": "173920"
  },
  {
    "text": "Kubernetes API to define uh Kafka resources and integrates that Kafka",
    "start": "173920",
    "end": "180560"
  },
  {
    "text": "knowledge into the operator and that is uh really important when it comes to like doing upgrades and rolling",
    "start": "180560",
    "end": "187959"
  },
  {
    "text": "updates and also manages Kafka resources through the operator pattern as well like Kafka topics Kafka users and",
    "start": "187959",
    "end": "197280"
  },
  {
    "text": "connectors right So stream uh automates the installation of CFKA as well as its",
    "start": "199159",
    "end": "205360"
  },
  {
    "text": "uh CFKA other CFKA components um such as Kafka connect which lets you um connect",
    "start": "205360",
    "end": "212239"
  },
  {
    "text": "your cluster uh to various external systems and also Maker which allows you",
    "start": "212239",
    "end": "217680"
  },
  {
    "text": "to replicate your cluster for disaster recovery and also HTTP bridge which is",
    "start": "217680",
    "end": "223440"
  },
  {
    "text": "provided by StreamZ um for connecting to your cluster over HTTP and there's two",
    "start": "223440",
    "end": "229360"
  },
  {
    "text": "people as well I'll come to that in a bit uh so stream uh handles not just day",
    "start": "229360",
    "end": "236879"
  },
  {
    "text": "one operation also day two operations uh such as upgrades certificate management",
    "start": "236879",
    "end": "242640"
  },
  {
    "text": "scaling of clusters and configuration of clusters and also uses another open",
    "start": "242640",
    "end": "247680"
  },
  {
    "text": "source project called cruise control to balance data in your cluster it also lets you monitor your",
    "start": "247680",
    "end": "254319"
  },
  {
    "text": "cluster easily it integrates with uh various different uh monitoring systems so um there's also new uh project that",
    "start": "254319",
    "end": "262079"
  },
  {
    "text": "was added recently called metric reporter which allows you to expose Kafka metrics directly uh to Prometheus",
    "start": "262079",
    "end": "269360"
  },
  {
    "text": "without using JMX also offers various uh",
    "start": "269360",
    "end": "275919"
  },
  {
    "text": "authentication mechanisms um and it integrates really well with other CNCF uh projects like",
    "start": "275919",
    "end": "282960"
  },
  {
    "text": "open telemetry prometheus and keta",
    "start": "282960",
    "end": "289840"
  },
  {
    "text": "Cool okay so we'll move on to uh the recent features of stream so we'll start with",
    "start": "290040",
    "end": "297120"
  },
  {
    "text": "craft so craft it removes zookeeper dependency of metadata management was",
    "start": "297960",
    "end": "303120"
  },
  {
    "text": "used to store the metadata of clusters before and it's being replaced by Kafka's own implementation based on uh",
    "start": "303120",
    "end": "310000"
  },
  {
    "text": "RAF protocol and this simplifies the deployment and management of the clusters because you have a single",
    "start": "310000",
    "end": "315919"
  },
  {
    "text": "system to manage and uh operate and also improves the",
    "start": "315919",
    "end": "321520"
  },
  {
    "text": "scalability because Kafka is very very scalable and Zookeeper tends to have a",
    "start": "321520",
    "end": "326560"
  },
  {
    "text": "limit when it comes to scaling and it makes it much more efficient and performant because you don't have to",
    "start": "326560",
    "end": "331759"
  },
  {
    "text": "sync the metadata data between zoo zookeeper and",
    "start": "331759",
    "end": "336159"
  },
  {
    "text": "kafka so this is how uh zookeeper based clusters look like so you have brokers",
    "start": "338919",
    "end": "345600"
  },
  {
    "text": "um cafka broker nodes and then you have your zookeeper cluster and one of those broker nodes designated as a controller",
    "start": "345600",
    "end": "352560"
  },
  {
    "text": "and then used to talk to zookeeper to coordinate all the metadata",
    "start": "352560",
    "end": "358560"
  },
  {
    "text": "updates and this is now how craft cluster looks like you just have um only CFKA nodes uh some of it is u serving as",
    "start": "358840",
    "end": "367199"
  },
  {
    "text": "controllers and some of it is uh serving as brokers",
    "start": "367199",
    "end": "372520"
  },
  {
    "text": "so those controller nodes they form a a quorum um based on the raft protocol and",
    "start": "372960",
    "end": "380639"
  },
  {
    "text": "it's basically distributed quorum where a metadata topic is stored locally in",
    "start": "380639",
    "end": "386000"
  },
  {
    "text": "each controller node and one of the controller node is the quorum leader and it's called active",
    "start": "386000",
    "end": "393639"
  },
  {
    "text": "controller and then the other controller um so that active controller is handling all the partition assignments and",
    "start": "393639",
    "end": "399759"
  },
  {
    "text": "updates to the metadata topic and then all the other controllers are just following uh and replicating that",
    "start": "399759",
    "end": "406240"
  },
  {
    "text": "metadata topic updates and it's just trying to um keep up to date",
    "start": "406240",
    "end": "414039"
  },
  {
    "text": "so brokers also store this metadata topic locally and then they talk to I'm sorry",
    "start": "415120",
    "end": "422000"
  },
  {
    "text": "they talk to the active controller to coordinate the metadata um to get the metadata",
    "start": "422000",
    "end": "428280"
  },
  {
    "text": "updates and um couple of slides before with the zookeeper cluster um you saw that one of the broker used to be",
    "start": "428280",
    "end": "435039"
  },
  {
    "text": "designated as the controller so none of the workers controller needs to uh the broker nodes need to do that anymore",
    "start": "435039",
    "end": "441599"
  },
  {
    "text": "they just handle the client topic data and then it's the controller active controller handling all the partition",
    "start": "441599",
    "end": "447360"
  },
  {
    "text": "assignments and coordination of that",
    "start": "447360",
    "end": "451360"
  },
  {
    "text": "metadata so with craft also offers various different ways uh you can run",
    "start": "453160",
    "end": "458400"
  },
  {
    "text": "the cluster so the usual setup is uh having designated worker nodes and",
    "start": "458400",
    "end": "465120"
  },
  {
    "text": "having designated controller nodes and this is great for large clusters and this is the recommendation uh",
    "start": "465120",
    "end": "471120"
  },
  {
    "text": "recommended recommended setup for production um and also allows much better",
    "start": "471120",
    "end": "479360"
  },
  {
    "text": "scalability but you can also run it in combined mode meaning that some or all of your controllers uh sorry some or all",
    "start": "479720",
    "end": "486879"
  },
  {
    "text": "of your nodes um serving as both controller and brokers and obviously this um saves you",
    "start": "486879",
    "end": "494240"
  },
  {
    "text": "some resource because you can run much less um count of nodes but you need to",
    "start": "494240",
    "end": "500319"
  },
  {
    "text": "be aware that if a node is serving as both controller and broker it might need more uh memory and CPU resource",
    "start": "500319",
    "end": "508479"
  },
  {
    "text": "you can even run single node cluster if you need a cluster that if you need to spin up cluster very quickly for just",
    "start": "508479",
    "end": "515039"
  },
  {
    "text": "some testing purpose this works great so the the the last three setup is uh",
    "start": "515039",
    "end": "520719"
  },
  {
    "text": "really just for development environments",
    "start": "520719",
    "end": "525640"
  },
  {
    "text": "so of course you can um migrate your existing zookeeper based clusters to",
    "start": "526320",
    "end": "531800"
  },
  {
    "text": "craft and that migration process is quite uh complex and manual um but",
    "start": "531800",
    "end": "537839"
  },
  {
    "text": "streams supports it and allows you to do it in a semi-automatic way it's driven by users um through",
    "start": "537839",
    "end": "544519"
  },
  {
    "text": "annotations it couldn't be f fully automated because of the significant difference in the architecture and",
    "start": "544519",
    "end": "551560"
  },
  {
    "text": "configuration by however by um giving back some of that control back to the",
    "start": "551560",
    "end": "557040"
  },
  {
    "text": "user um allows you to have the roll back option so the migration is done in",
    "start": "557040",
    "end": "562800"
  },
  {
    "text": "phases and then up until the last phase you can uh roll back to",
    "start": "562800",
    "end": "569120"
  },
  {
    "text": "zookeeper right so craft was announced in 2019 uh so it's more than 5 years ago",
    "start": "571160",
    "end": "578240"
  },
  {
    "text": "and then it was first supported in stream 2029 sorry 029 as an experimental",
    "start": "578240",
    "end": "585480"
  },
  {
    "text": "support and and it was enabled by default in stream Z040 so meaning all",
    "start": "585480",
    "end": "590720"
  },
  {
    "text": "the new cluster that were provisioned after this version they will be running",
    "start": "590720",
    "end": "596320"
  },
  {
    "text": "uh in craft mode by default and then just two weeks ago um",
    "start": "596320",
    "end": "602560"
  },
  {
    "text": "Kafka 4 was released removing zookeeper completely so we're very happy to see finally this uh craft feature is coming",
    "start": "602560",
    "end": "610480"
  },
  {
    "text": "to completion and um now we working towards uh stream",
    "start": "610480",
    "end": "617240"
  },
  {
    "text": "046 so the current version is two uh 045 um it supports Kako 380 and 38",
    "start": "617240",
    "end": "625560"
  },
  {
    "text": "390 and it's the last version with Zookeeper support and we plan to provide",
    "start": "625560",
    "end": "630959"
  },
  {
    "text": "extended uh support for this version probably around a year",
    "start": "630959",
    "end": "636360"
  },
  {
    "text": "and so this is the last chance you can migrate to existing um Zookeeper based",
    "start": "636360",
    "end": "641680"
  },
  {
    "text": "cluster to craft because um with z uh stream 460",
    "start": "641680",
    "end": "649440"
  },
  {
    "text": "uh which is the next release um It will only support craft mode it will support",
    "start": "649440",
    "end": "654480"
  },
  {
    "text": "cafka 390 and 40 and we also using this opportunity to",
    "start": "654480",
    "end": "660480"
  },
  {
    "text": "remove some of the deprecated components like mirror maker one okay so if you'd like to learn more",
    "start": "660480",
    "end": "667360"
  },
  {
    "text": "about craft here is the link and with that I think I'll pass to my colleague",
    "start": "667360",
    "end": "674000"
  },
  {
    "text": "yeah thank you Tina so um craft was one of the the big features that you know u",
    "start": "674000",
    "end": "680480"
  },
  {
    "text": "was added to to Kafka so now we are supporting that u since long time in in",
    "start": "680480",
    "end": "686399"
  },
  {
    "text": "stream uh and uh yeah with Kafka 4 and streamit 046 that we expect to have",
    "start": "686399",
    "end": "692240"
  },
  {
    "text": "within maybe this month um you will have um craft um as the the the first choice",
    "start": "692240",
    "end": "699760"
  },
  {
    "text": "of the the only choice for running your Kafka cluster so it's not just about craft as the main features that you have",
    "start": "699760",
    "end": "706240"
  },
  {
    "text": "today within streamy but even the tier storage even tier storage is something that was added in Kafka itself so with",
    "start": "706240",
    "end": "712880"
  },
  {
    "text": "tier storage you can think of offloading some messages so having some maybe old",
    "start": "712880",
    "end": "718959"
  },
  {
    "text": "messages um got from your brokers to be offload on some other storage like for",
    "start": "718959",
    "end": "725440"
  },
  {
    "text": "example could be a cloud storage like Amazon S3 or things like that Azure blob",
    "start": "725440",
    "end": "731120"
  },
  {
    "text": "storage and so on so um why you should use the the tier storage uh first of all so there are",
    "start": "731120",
    "end": "737680"
  },
  {
    "text": "several reasons right uh first of all for cost uh efficiency so it means that",
    "start": "737680",
    "end": "743360"
  },
  {
    "text": "um you have on your brokers of course disks that maybe are more expensive",
    "start": "743360",
    "end": "748720"
  },
  {
    "text": "because you want performance you can run with SSD and things like that and uh of",
    "start": "748720",
    "end": "754560"
  },
  {
    "text": "course in this case um if you are going instead to offload all the messages so",
    "start": "754560",
    "end": "759920"
  },
  {
    "text": "messages that are part of the history of your uh uh Kafka cluster that you want to to to have there anyway but they are",
    "start": "759920",
    "end": "767519"
  },
  {
    "text": "not uh read so often by the consumers you can just offload these messages in",
    "start": "767519",
    "end": "772959"
  },
  {
    "text": "some more you know cheaper storage that could be something in the cloud and having the more upto-date uh data still",
    "start": "772959",
    "end": "780639"
  },
  {
    "text": "on on the on the brokers so you can have less dis space used on the brokers and offloading something on a cheaper",
    "start": "780639",
    "end": "787920"
  },
  {
    "text": "storage and so on so the first reason is the cost which brings of course scalability as well uh because you have",
    "start": "787920",
    "end": "794320"
  },
  {
    "text": "the computation mostly running on the brokers and storing there the messages that you are access frequently and maybe",
    "start": "794320",
    "end": "800560"
  },
  {
    "text": "the older ones on the on the cheaper storage but it's also really useful for faster recovery and rebalancing about",
    "start": "800560",
    "end": "807040"
  },
  {
    "text": "faster recovery you can think then when something bad happens for example on a broker and you are restarting the broker",
    "start": "807040",
    "end": "813120"
  },
  {
    "text": "the broker has kind of to recover the data uh reconstructing the log of course more data you have on the broker more",
    "start": "813120",
    "end": "820240"
  },
  {
    "text": "the log are bigger insights you have more segments in the logs then it will take more time for the broker to",
    "start": "820240",
    "end": "826800"
  },
  {
    "text": "reconstructing everything so in this case of course if you are offloading older messages somewhere else you can uh",
    "start": "826800",
    "end": "834320"
  },
  {
    "text": "be faster when recovering from the brokers and even on rebalancing rebalancing uh as Tina mentioned before",
    "start": "834320",
    "end": "841360"
  },
  {
    "text": "there is the usage of crisis control for example where rebalancing means uh moving partitions across your cluster",
    "start": "841360",
    "end": "848639"
  },
  {
    "text": "across all the brokers within your cluster in order to have a more you know balanced load uh across all of them but",
    "start": "848639",
    "end": "855680"
  },
  {
    "text": "of course if you are moving uh partitions which are you know little insides uh you can be faster on",
    "start": "855680",
    "end": "862519"
  },
  {
    "text": "rebalancing so again you have the older data in uh other storage in the cloud",
    "start": "862519",
    "end": "868720"
  },
  {
    "text": "storage for example then you can just rebalancing the your cluster with with less less partitions and less data and",
    "start": "868720",
    "end": "875519"
  },
  {
    "text": "last but not least uh simplified cluster operations it means that for example you don't have to deal with the disk",
    "start": "875519",
    "end": "882440"
  },
  {
    "text": "expansions because you are getting more data more data so you need to expand the disk on your brokers you are just",
    "start": "882440",
    "end": "888639"
  },
  {
    "text": "writing the old data on the cloud storage and uh and then you yeah you",
    "start": "888639",
    "end": "894000"
  },
  {
    "text": "don't need to run this kind of operation or for example deleting old segments because they are getting bigger and",
    "start": "894000",
    "end": "899199"
  },
  {
    "text": "bigger and bigger so this is uh these are the one main reason that you should use tier storage within Kafka uh of",
    "start": "899199",
    "end": "906959"
  },
  {
    "text": "course with streamy you have a kubernetative approach as usual so within our cafka custom resource which",
    "start": "906959",
    "end": "912800"
  },
  {
    "text": "is the main custom resource that use today for deploying a uh kafka cluster with the stream there is a new field",
    "start": "912800",
    "end": "918880"
  },
  {
    "text": "which is the tier storage field where you can specify the implementation of the remote storage manager that you are",
    "start": "918880",
    "end": "925440"
  },
  {
    "text": "going to use so in Kafka uh you can even write your own storage manager you have",
    "start": "925440",
    "end": "930959"
  },
  {
    "text": "to implement some interfaces you can um you know build this jar and baking your",
    "start": "930959",
    "end": "936160"
  },
  {
    "text": "image uh the Kafka image starting with the from the streamy one to have this plug-in inside and then you can apply",
    "start": "936160",
    "end": "942560"
  },
  {
    "text": "the configuration here for your uh storage manager and it will be used uh by stream easy to configure everything",
    "start": "942560",
    "end": "948720"
  },
  {
    "text": "and then by cafka of course for offloading and using the tier storage feature so moving the data uh in the in",
    "start": "948720",
    "end": "955519"
  },
  {
    "text": "the corresponding storage that is used by this the the remnant storage manager the support that we have today is mostly",
    "start": "955519",
    "end": "962800"
  },
  {
    "text": "about you know custom implementation this is why you saw on the previous slide the type of the tire storage is",
    "start": "962800",
    "end": "970240"
  },
  {
    "text": "custom so it means that you can bring your own implementation and um there is",
    "start": "970240",
    "end": "976079"
  },
  {
    "text": "no kind of strict API for the several providers that you can use uh for the",
    "start": "976079",
    "end": "981800"
  },
  {
    "text": "storage uh we are exploring stream is this a open source plug-in which is",
    "start": "981800",
    "end": "987199"
  },
  {
    "text": "supporting several storage as you can see here amazon S3 GCS and Azure blob storage but of course you can write your",
    "start": "987199",
    "end": "994000"
  },
  {
    "text": "own if you need something different and then uh yeah using the tier storage field within the Kafka custom resource",
    "start": "994000",
    "end": "999759"
  },
  {
    "text": "to set all the configuration but the plan is uh as you can see here when um so tier storage is",
    "start": "999759",
    "end": "1007519"
  },
  {
    "text": "finally G since Kafka 39 it's now um production ready it was not so it was in",
    "start": "1007519",
    "end": "1013600"
  },
  {
    "text": "early access in 3.6 now that it's GA production ready uh we",
    "start": "1013600",
    "end": "1018959"
  },
  {
    "text": "are thinking as a future step to have a more kind of strongly typed API where we",
    "start": "1018959",
    "end": "1024640"
  },
  {
    "text": "have a better support for the several storage that are available uh yeah that we have out there instead of having this",
    "start": "1024640",
    "end": "1031120"
  },
  {
    "text": "kind of custom support the next feature is about auto",
    "start": "1031120",
    "end": "1036400"
  },
  {
    "text": "rebalancing on cluster scaling so as mentioned before there is a cris control integration with streamy can use cris",
    "start": "1036400",
    "end": "1042880"
  },
  {
    "text": "control in order to run your rebalancing in the cluster but um the the interface",
    "start": "1042880",
    "end": "1048480"
  },
  {
    "text": "that you have today is by using a specific custom resource it's called kafka rebalance so instead of talking",
    "start": "1048480",
    "end": "1054400"
  },
  {
    "text": "with the http rest api exposed by cruise control in order to get the proposal to ask to cruise control to run the",
    "start": "1054400",
    "end": "1060360"
  },
  {
    "text": "rebalancing still again kubernetive way you are writing your kafka rebalance",
    "start": "1060360",
    "end": "1065600"
  },
  {
    "text": "custom resource where you can specify the goals that you want to achieve with the rebalancing but it's manual right",
    "start": "1065600",
    "end": "1071679"
  },
  {
    "text": "And if for example you want to do something like scaling of your cluster so you are scaling up you are adding",
    "start": "1071679",
    "end": "1077280"
  },
  {
    "text": "more brokers these brokers are not getting partitions from the existing topic they are getting partitions and",
    "start": "1077280",
    "end": "1084000"
  },
  {
    "text": "replicas only for the newly created topic what you have to do after scaling up your cluster you have to run a",
    "start": "1084000",
    "end": "1090400"
  },
  {
    "text": "rebalancing so creating manually your cafka rebalance and increase control will move partitions the existing one",
    "start": "1090400",
    "end": "1096320"
  },
  {
    "text": "from the brokers to the new ones the same if you want to scale down if you want to scale down you cannot just scale",
    "start": "1096320",
    "end": "1102880"
  },
  {
    "text": "down if the brokers that you want to remove are hosting partitions because you could have problem like partitions",
    "start": "1102880",
    "end": "1108640"
  },
  {
    "text": "offline and under the m the minus insync replicas and so on so you don't have the",
    "start": "1108640",
    "end": "1114160"
  },
  {
    "text": "data uh accessible this way so you first need to make these brokers empty so moving the partitions off and you can do",
    "start": "1114160",
    "end": "1121360"
  },
  {
    "text": "that by running a rebalancing and then when the brokers are empty you can scale down of course it sounds today as a kind",
    "start": "1121360",
    "end": "1128160"
  },
  {
    "text": "of two manual steps process right so first scale up and then moving partition or first moving partition and then scale",
    "start": "1128160",
    "end": "1134640"
  },
  {
    "text": "down with the auto balancing that you can configure within the Kafka castle resource you can just deal with scaling",
    "start": "1134640",
    "end": "1141280"
  },
  {
    "text": "so you just increase the number of replicas of your brokers or just scale down and so decrease the number of",
    "start": "1141280",
    "end": "1146960"
  },
  {
    "text": "replicas and then the operator will take care of running the scale up and then",
    "start": "1146960",
    "end": "1152400"
  },
  {
    "text": "running the rebalancing for you or on the other way around first running the rebalancing and then running the scale",
    "start": "1152400",
    "end": "1158240"
  },
  {
    "text": "down of course there is a kind of templating here because you are not writing your cuff carry balance but you",
    "start": "1158240",
    "end": "1163840"
  },
  {
    "text": "want still specify the goals that you want to achieve in rebalancing so you can specify a cuff carry balance as a",
    "start": "1163840",
    "end": "1170520"
  },
  {
    "text": "template and specifying the goals but information like the so-called mode that",
    "start": "1170520",
    "end": "1176240"
  },
  {
    "text": "cruise control has to use so add brokers or remove brokers or what are the brokers ids that are going to be added",
    "start": "1176240",
    "end": "1183360"
  },
  {
    "text": "or removed it's something that the operator can set for you because the operator knows that you are adding these",
    "start": "1183360",
    "end": "1188799"
  },
  {
    "text": "brokers or removing these ones so it's just a matter of scaling up and scaling down the rebalancing will happen",
    "start": "1188799",
    "end": "1194559"
  },
  {
    "text": "automatically for loop so these are the three main things main things that we",
    "start": "1194559",
    "end": "1199760"
  },
  {
    "text": "have today in the latest version of stream craft tier storage and auto rebalancing or scaling what's next these",
    "start": "1199760",
    "end": "1207919"
  },
  {
    "text": "are the five main things that you are exploring today so the first one is about improving the certificate",
    "start": "1207919",
    "end": "1212960"
  },
  {
    "text": "management so within streamy today uh everything is secured by default so",
    "start": "1212960",
    "end": "1218240"
  },
  {
    "text": "there is TLS connection between all the components uh across the cluster uh the stream image operator by default create",
    "start": "1218240",
    "end": "1225200"
  },
  {
    "text": "a uh CA root certificate which is going to use to sign the server certificates",
    "start": "1225200",
    "end": "1231440"
  },
  {
    "text": "for all your components or the user can bring uh their own certificate to be put",
    "start": "1231440",
    "end": "1237120"
  },
  {
    "text": "inside the secret uh in order to to be compliant with what streams is expected",
    "start": "1237120",
    "end": "1242400"
  },
  {
    "text": "right um there is no integration with the kind of uh certificate management system like s manager so there was a",
    "start": "1242400",
    "end": "1249760"
  },
  {
    "text": "proposal uh it was approved uh and the implementation is going on by one other",
    "start": "1249760",
    "end": "1256480"
  },
  {
    "text": "our core maintainer Kate Sunlay and uh yeah we are adding this better integration with search manager so you",
    "start": "1256480",
    "end": "1263200"
  },
  {
    "text": "can specify to use within your custom resource that you want to use a search",
    "start": "1263200",
    "end": "1268320"
  },
  {
    "text": "manager providing several information set manager will going to create the the entity certificates for you and then the",
    "start": "1268320",
    "end": "1274960"
  },
  {
    "text": "operator will take care of bringing the certificate and use them for your cluster so the user can kind of set up",
    "start": "1274960",
    "end": "1281280"
  },
  {
    "text": "they own PKI um in order to handle the the certificates the way they want the",
    "start": "1281280",
    "end": "1287440"
  },
  {
    "text": "implementation will be uh pluggable in sense that we would like to have in the future support for other certificate",
    "start": "1287440",
    "end": "1293280"
  },
  {
    "text": "management system but the first one will be search manager so we are focusing on that the next thing is Kafka cluster",
    "start": "1293280",
    "end": "1300880"
  },
  {
    "text": "self feeding so again cris control I already mentioned Kafka rebalance for running manual rebalancing or the auto",
    "start": "1300880",
    "end": "1307360"
  },
  {
    "text": "rebalancing which works just for scaling up or down but cris control provides another feature the anomaly detection",
    "start": "1307360",
    "end": "1313679"
  },
  {
    "text": "it's able to detect u some anomalies that you have in the cluster like broker failures disk failures or go anomaly so",
    "start": "1313679",
    "end": "1321760"
  },
  {
    "text": "goal violation topic anomaly and it's also able not just sending notifications",
    "start": "1321760",
    "end": "1327600"
  },
  {
    "text": "that you can define like I don't know using slack or some other or your even custom implementation for the notifier",
    "start": "1327600",
    "end": "1334799"
  },
  {
    "text": "but it's also able to um fix the issue for you and of course in this case so we",
    "start": "1334799",
    "end": "1341919"
  },
  {
    "text": "would like to integrate this self-healing feature that cris control provides of course in this case there",
    "start": "1341919",
    "end": "1347600"
  },
  {
    "text": "are some challenges right the user is not um controlling the process because",
    "start": "1347600",
    "end": "1352640"
  },
  {
    "text": "it's cris control starting at some point to fix the cluster there is actually nothing that you can do but we would",
    "start": "1352640",
    "end": "1358880"
  },
  {
    "text": "like at least providing a way for the user to know what's happening right so",
    "start": "1358880",
    "end": "1364159"
  },
  {
    "text": "an idea could be just sending some kubernetes events so that you can monitoring and say okay cris control",
    "start": "1364159",
    "end": "1370480"
  },
  {
    "text": "started this kind of fix because this anomaly was uh happening uh this",
    "start": "1370480",
    "end": "1375520"
  },
  {
    "text": "proposal here a stream proposal is a stream under is still under discussion so if you are interested to this future",
    "start": "1375520",
    "end": "1381919"
  },
  {
    "text": "I would suggest you to jump into discussion providing feedback and see what what are the yeah the things that",
    "start": "1381919",
    "end": "1388240"
  },
  {
    "text": "works for you and do you think that will be better for for the stream project another big step will be moving to to v1",
    "start": "1388240",
    "end": "1395440"
  },
  {
    "text": "APIs and finally releasing stream1 so for a long time streams uh stream was at",
    "start": "1395440",
    "end": "1401919"
  },
  {
    "text": "zero do something like and it doesn't mean that stream is not production ready",
    "start": "1401919",
    "end": "1407280"
  },
  {
    "text": "we now have a lot of companies and users in the community using streamy since years in production it was just our",
    "start": "1407280",
    "end": "1414159"
  },
  {
    "text": "decision to have stream one zero out only when zookeeper was going to be removed and it took a lot so a long old",
    "start": "1414159",
    "end": "1421600"
  },
  {
    "text": "time right so uh now that we have Kafka 4 a stream 046 coming it will be the",
    "start": "1421600",
    "end": "1428720"
  },
  {
    "text": "time to start thinking about finally streaming Z1 um also together with of",
    "start": "1428720",
    "end": "1434159"
  },
  {
    "text": "course um moving to the v1 API because today we have a v1 beta 2 and of course",
    "start": "1434159",
    "end": "1440559"
  },
  {
    "text": "the process will not that simple so I mean uh we are going to remove some already deprecated fields maybe we are",
    "start": "1440559",
    "end": "1448200"
  },
  {
    "text": "reting something based on the lessons that we learned in terms of the API that",
    "start": "1448200",
    "end": "1453520"
  },
  {
    "text": "we designed since the beginning we will have several streamy release uh where we",
    "start": "1453520",
    "end": "1459600"
  },
  {
    "text": "are going to support both v1 and v1 beta 2 uh API and then at some point uh we'll",
    "start": "1459600",
    "end": "1466080"
  },
  {
    "text": "release stream one with just the API v1 the next feature will be gateway API",
    "start": "1466080",
    "end": "1473440"
  },
  {
    "text": "support so today with streamy if you want to expose your cafka cluster outside of the kubernetes cluster you",
    "start": "1473440",
    "end": "1480720"
  },
  {
    "text": "can use ingress but you know ingress depends also on the controller implementation for ingress like and so",
    "start": "1480720",
    "end": "1488080"
  },
  {
    "text": "on uh you can use node node ports or you can use also routes if you are running",
    "start": "1488080",
    "end": "1493600"
  },
  {
    "text": "on open shift for example uh but you know there is this gateway API this",
    "start": "1493600",
    "end": "1499039"
  },
  {
    "text": "framework that is pretty mature now and um um you so the the the goal of the",
    "start": "1499039",
    "end": "1505440"
  },
  {
    "text": "gateway API is kind of replacing ingress and we would like to have a built-in integration of gateway API within stream",
    "start": "1505440",
    "end": "1512880"
  },
  {
    "text": "so today we you can already use the gateway API there is also a blog post on the streamy uh website uh by a community",
    "start": "1512880",
    "end": "1520799"
  },
  {
    "text": "user and um and it was mostly about setting up everything manually So you",
    "start": "1520799",
    "end": "1526080"
  },
  {
    "text": "have to set up the the several custom resources you need for the gateway set up the gateway the TLS route and so on",
    "start": "1526080",
    "end": "1532159"
  },
  {
    "text": "uh what we want to have is more built-in integration in stream so you can specify in stream in the Kafka custom resource",
    "start": "1532159",
    "end": "1538400"
  },
  {
    "text": "you have the listeners for exposing right your cluster uh you won't like just to set up that you want the gateway",
    "start": "1538400",
    "end": "1544880"
  },
  {
    "text": "API and stream will set up everything for you so it's something that we have to start to think",
    "start": "1544880",
    "end": "1550440"
  },
  {
    "text": "about uh the last one is about stretch cluster so stretch cluster is about running a cafka cluster stretched across",
    "start": "1550440",
    "end": "1558720"
  },
  {
    "text": "several kubernetes cluster uh there was some requests from several community",
    "start": "1558720",
    "end": "1564960"
  },
  {
    "text": "users and actually there is a proposal which is written by some users from the",
    "start": "1564960",
    "end": "1570240"
  },
  {
    "text": "community still under discussion uh of course there are a lot of challenges here uh because Kafka is very sensitive",
    "start": "1570240",
    "end": "1577440"
  },
  {
    "text": "to latency so we don't see this working on uh you know kubernetes cluster",
    "start": "1577440",
    "end": "1583120"
  },
  {
    "text": "running in se in different continents for example because the latency will be too high but maybe in metropolitan area",
    "start": "1583120",
    "end": "1590320"
  },
  {
    "text": "network and so on and it simplifies for example the the migration of the graph cluster between um kubernetes clusters",
    "start": "1590320",
    "end": "1598320"
  },
  {
    "text": "so again a lot of challenges the discussion is going on there is the proposal if you think that it's an",
    "start": "1598320",
    "end": "1604000"
  },
  {
    "text": "interesting thing yeah jump into it regarding in the future is not just",
    "start": "1604000",
    "end": "1609679"
  },
  {
    "text": "about features so as I mentioned we have this list of new features coming and",
    "start": "1609679",
    "end": "1615520"
  },
  {
    "text": "under discussion there is the streamicon uh streamicon is a virtual conference we",
    "start": "1615520",
    "end": "1621039"
  },
  {
    "text": "already had the first edition last year uh I can say that it was a success from",
    "start": "1621039",
    "end": "1626480"
  },
  {
    "text": "my point of view we had kind of 300 people joining more or less uh it's virtual it's free um the agenda will be",
    "start": "1626480",
    "end": "1634080"
  },
  {
    "text": "out soon uh maybe in the next week and uh you will see sessions around um",
    "start": "1634080",
    "end": "1640320"
  },
  {
    "text": "streamy core internals so how things works internally in stream or for",
    "start": "1640320",
    "end": "1645840"
  },
  {
    "text": "example use cases or scenarios about users or companies using stream uh in",
    "start": "1645840",
    "end": "1652880"
  },
  {
    "text": "production uh or for example how stream can work um with other CNCF projects so",
    "start": "1652880",
    "end": "1658880"
  },
  {
    "text": "what are the kind of integrations that you have with streaming yeah so this is a link where",
    "start": "1658880",
    "end": "1665600"
  },
  {
    "text": "you can find all the information for join the project uh joining the project",
    "start": "1665600",
    "end": "1670720"
  },
  {
    "text": "as any opensource project could be about you know just jumping into the slack channel and asking for questions if you",
    "start": "1670720",
    "end": "1677840"
  },
  {
    "text": "are in troubles with using streamy somehow uh so finding help from the",
    "start": "1677840",
    "end": "1683360"
  },
  {
    "text": "community or for example um raising bugs uh on GitHub and if you want you can",
    "start": "1683360",
    "end": "1689600"
  },
  {
    "text": "even contribute to fix a bug it will be great or uh implementing features proposing features so we have this",
    "start": "1689600",
    "end": "1695840"
  },
  {
    "text": "process like in Kafka the Kafka improvement proposal we have the stream improvement proposal so if there is",
    "start": "1695840",
    "end": "1702240"
  },
  {
    "text": "something that has a big impact on the project you can start a proposal and so",
    "start": "1702240",
    "end": "1707600"
  },
  {
    "text": "start a discussion about I would like to have this what do you think or the community would think about that or for",
    "start": "1707600",
    "end": "1713679"
  },
  {
    "text": "example even just fixing the documentation so you are going through the documentation for the several steps",
    "start": "1713679",
    "end": "1718960"
  },
  {
    "text": "for configuring stuff and you see that something it's not clear or doesn't work the way that it should work um yeah",
    "start": "1718960",
    "end": "1726640"
  },
  {
    "text": "these are all the reference and um it would be great to have some of you using maybe stream easy engaging the community",
    "start": "1726640",
    "end": "1733600"
  },
  {
    "text": "so that's all thank you",
    "start": "1733600",
    "end": "1739080"
  },
  {
    "text": "we have one minute I think if there are any questions otherwise we will be around and you can just",
    "start": "1741600",
    "end": "1749200"
  },
  {
    "text": "uh there is a mic coming so is there an uh an alternative for mirror",
    "start": "1749200",
    "end": "1756679"
  },
  {
    "text": "maker because you mentioned that it was uh going to be dropped sorry an alternative for mirror maker mirror",
    "start": "1756679",
    "end": "1764399"
  },
  {
    "text": "maker ah for for mirror maker no mirror maker 2",
    "start": "1764399",
    "end": "1770880"
  },
  {
    "text": "mirror maker oh uh so we deprocated mirror maker one mirror maker 2 so you",
    "start": "1770880",
    "end": "1777279"
  },
  {
    "text": "can still Yeah use that it's an old version of mirror maker with deprecating things any chance that you go can go",
    "start": "1777279",
    "end": "1782799"
  },
  {
    "text": "over the differences between mirror maker 1 and two if like uh any chance that you can go over the",
    "start": "1782799",
    "end": "1790320"
  },
  {
    "text": "differences real quick between mirror maker one and two difference the breaking changes between one and two",
    "start": "1790320",
    "end": "1795919"
  },
  {
    "text": "yeah exactly mirror maker so mirror maker 2 is totally different it's based on Kafka connect again mirror maker 2 is totally",
    "start": "1795919",
    "end": "1804559"
  },
  {
    "text": "different from mirror maker 1 it's using Kafka connect underneath i see so it's a",
    "start": "1804559",
    "end": "1809760"
  },
  {
    "text": "totally different thing right yeah it was rewritten to make it more efficient and performant while mirror maker one",
    "start": "1809760",
    "end": "1816000"
  },
  {
    "text": "was still based on Kafka clients and underneath so it's running this Kafka connect which is a another Kafka",
    "start": "1816000",
    "end": "1824159"
  },
  {
    "text": "um framework within the Kafka ecosystem about moving data uh across several systems so for example from a database",
    "start": "1824159",
    "end": "1831440"
  },
  {
    "text": "to I don't know some other database you can go through Kafka like a log so for example if I'm deploying a vivo maker 2 I'll I'll",
    "start": "1831440",
    "end": "1840159"
  },
  {
    "text": "also see in the same name space caf connect uh you will see mirror maker 2",
    "start": "1840159",
    "end": "1846159"
  },
  {
    "text": "but underneath it will run Kafka connect thank you so much so yes you don't see you cannot interact with mirror maker 2",
    "start": "1846159",
    "end": "1852159"
  },
  {
    "text": "like it was Kafka connect you got to find the migration as soon as possible yeah yeah yeah and that's the the tool",
    "start": "1852159",
    "end": "1857760"
  },
  {
    "text": "for running this yeah for running migration thank you so much",
    "start": "1857760",
    "end": "1863480"
  },
  {
    "text": "okay thank you out",
    "start": "1863919",
    "end": "1867960"
  }
]
[
  {
    "start": "0",
    "end": "55000"
  },
  {
    "text": "hi everyone and welcome to the first session of the day my name is Anirudh I lead the big data",
    "start": "0",
    "end": "7290"
  },
  {
    "text": "user group in the kubernetes community the first talk we have today is by waching yang from LinkedIn and Jian he",
    "start": "7290",
    "end": "14910"
  },
  {
    "text": "from Alibaba and they're going to be talking about running Apache Samsa on kubernetes couple of logistical items",
    "start": "14910",
    "end": "27510"
  },
  {
    "text": "please hold your questions till the end I'll come with you with a microphone and",
    "start": "27510",
    "end": "32840"
  },
  {
    "text": "leave feedback on scared calm at the end of the session thank you hi I'm waiting",
    "start": "32840",
    "end": "42719"
  },
  {
    "text": "for linking and I'm working on this from",
    "start": "42719",
    "end": "48480"
  },
  {
    "text": "Alibaba and our topic today is running them their own communities first we'll",
    "start": "48480",
    "end": "57539"
  },
  {
    "start": "55000",
    "end": "97000"
  },
  {
    "text": "talk about what Center what Apache center is then we will dive into having",
    "start": "57539",
    "end": "65250"
  },
  {
    "text": "- it's as cute in a center job on kubernetes and then we will do a demo to",
    "start": "65250",
    "end": "70860"
  },
  {
    "text": "run a center job on agile kubernetes cluster after demo we will will talk",
    "start": "70860",
    "end": "77520"
  },
  {
    "text": "more about different deployment options for center users in the end we'll share",
    "start": "77520",
    "end": "83970"
  },
  {
    "text": "more practice about using abilities as a campaigner as container actors a",
    "start": "83970",
    "end": "91409"
  },
  {
    "text": "framework for other big data processing engines",
    "start": "91409",
    "end": "97640"
  },
  {
    "start": "97000",
    "end": "128000"
  },
  {
    "text": "so Sansa is a distributed stream processor framework that allows you to",
    "start": "100659",
    "end": "106420"
  },
  {
    "text": "build words they for job they'll process data at skill in real time it was",
    "start": "106420",
    "end": "113170"
  },
  {
    "text": "developed a link in 27 2013 and was",
    "start": "113170",
    "end": "118229"
  },
  {
    "text": "helping has been widely used and linking and other companies like when were slack",
    "start": "118229",
    "end": "125729"
  },
  {
    "text": "extra Center supports a fully palatable",
    "start": "125729",
    "end": "134680"
  },
  {
    "start": "128000",
    "end": "178000"
  },
  {
    "text": "mode for input sources and output systems it can process and transfer data",
    "start": "134680",
    "end": "140440"
  },
  {
    "text": "from any source seminar often offers built-in integrations with APIs akafuku",
    "start": "140440",
    "end": "146769"
  },
  {
    "text": "ADA like m-80s kinases as your even hub",
    "start": "146769",
    "end": "152319"
  },
  {
    "text": "and hub and so on also it's quite easy to integrate with your own sources there",
    "start": "152319",
    "end": "160299"
  },
  {
    "text": "are different development options you can run them the English standard standalone mode or in cast mode like",
    "start": "160299",
    "end": "168489"
  },
  {
    "text": "runs on a passion or kubernetes we'll talk more about the job deployment later",
    "start": "168489",
    "end": "176849"
  },
  {
    "start": "178000",
    "end": "186000"
  },
  {
    "text": "one is a typical central use case let's look at this picture event event",
    "start": "178620",
    "end": "187090"
  },
  {
    "start": "186000",
    "end": "227000"
  },
  {
    "text": "producer it could be a service database changed or magics event producer writes",
    "start": "187090",
    "end": "195100"
  },
  {
    "text": "the event into messaging system like Kafka and agile you will have from where",
    "start": "195100",
    "end": "201040"
  },
  {
    "text": "a standard job reads input events to do the computation after that send out right job results",
    "start": "201040",
    "end": "209560"
  },
  {
    "text": "into output systems which could be a database Brasserie service or measuring",
    "start": "209560",
    "end": "215260"
  },
  {
    "text": "systems then the downstream application",
    "start": "215260",
    "end": "220569"
  },
  {
    "text": "can consume the job result to do their own analysis and so on",
    "start": "220569",
    "end": "227880"
  },
  {
    "start": "227000",
    "end": "317000"
  },
  {
    "text": "this slides brief stems are features Center provides flexible API in Cinco",
    "start": "228030",
    "end": "234950"
  },
  {
    "text": "Java and Python it has flexible deployment model for",
    "start": "234950",
    "end": "241050"
  },
  {
    "text": "running the applications in any host environment enemies cluster managers",
    "start": "241050",
    "end": "246810"
  },
  {
    "text": "like young and kubernetes so the same Center job code can wrong everywhere",
    "start": "246810",
    "end": "252270"
  },
  {
    "text": "from public cloud to continue right environment to bare metal Halbert",
    "start": "252270",
    "end": "259370"
  },
  {
    "text": "massive scale center provide the first support for local state and support",
    "start": "259370",
    "end": "266010"
  },
  {
    "text": "incremental check pointing of state instead of for snapshots this enables",
    "start": "266010",
    "end": "272580"
  },
  {
    "text": "Em's up to scale to applications with very large state center support applications that use several terabyte",
    "start": "272580",
    "end": "281370"
  },
  {
    "text": "upstate and runs on thousands courses this empower multiple large company",
    "start": "281370",
    "end": "288390"
  },
  {
    "text": "including in cream and some for tolerance Center transparent",
    "start": "288390",
    "end": "295370"
  },
  {
    "text": "transparently migrates tasks along with their associated state in the event of",
    "start": "295370",
    "end": "302400"
  },
  {
    "text": "failures its support host ability and incremental check pointing to fast",
    "start": "302400",
    "end": "309060"
  },
  {
    "text": "recover of the failures stems are currently at least ones processing a",
    "start": "309060",
    "end": "314580"
  },
  {
    "text": "semantics next we will introduce them",
    "start": "314580",
    "end": "319800"
  },
  {
    "start": "317000",
    "end": "372000"
  },
  {
    "text": "the standard terminology Center process your data in the firm of strings a",
    "start": "319800",
    "end": "326340"
  },
  {
    "text": "string is a connect of immutable messages usually at the same type or",
    "start": "326340",
    "end": "332520"
  },
  {
    "text": "category data in a string can be unbounded like Akaka topic or bounded",
    "start": "332520",
    "end": "340919"
  },
  {
    "text": "like a set up files on HDFS Center supports prodding systems and can that",
    "start": "340919",
    "end": "348450"
  },
  {
    "text": "can implement string abstracts for example Kafka implements the string as a",
    "start": "348450",
    "end": "354540"
  },
  {
    "text": "topic a while the database can May increments the string as a sequence of updates to",
    "start": "354540",
    "end": "361449"
  },
  {
    "text": "his tables in this picture there are two input strings and one output stream and",
    "start": "361449",
    "end": "367810"
  },
  {
    "text": "the sender job filled out the event which a lot below a string is charted",
    "start": "367810",
    "end": "375850"
  },
  {
    "start": "372000",
    "end": "462000"
  },
  {
    "text": "into multiple partitions for skinning how is data is processed each partition",
    "start": "375850",
    "end": "382240"
  },
  {
    "text": "is an audit replayable sequence or order of records when mastery is written into",
    "start": "382240",
    "end": "390580"
  },
  {
    "text": "a stream is ends up in one of partitions and them's are skills your applications",
    "start": "390580",
    "end": "398229"
  },
  {
    "text": "by logically breaking it down into multiple partitions tasks a task is a",
    "start": "398229",
    "end": "405240"
  },
  {
    "text": "unit of Paradiso of your application each task consumes",
    "start": "405240",
    "end": "411820"
  },
  {
    "text": "one partitions of its input strings the assignment of partition to tasks never",
    "start": "411820",
    "end": "418270"
  },
  {
    "text": "change they say if a task is on one node that",
    "start": "418270",
    "end": "424479"
  },
  {
    "text": "fails the task is returned the task is really started elsewhere but still",
    "start": "424479",
    "end": "431590"
  },
  {
    "text": "consuming those things during partition just like the logical just like a task",
    "start": "431590",
    "end": "438820"
  },
  {
    "text": "is the logical unit or paradin and a container is the physical you need",
    "start": "438820",
    "end": "445860"
  },
  {
    "text": "application typically have multiple containers distributed across hosts you",
    "start": "445860",
    "end": "452889"
  },
  {
    "text": "can think of each container as a GVM process which runs one or more tasks",
    "start": "452889",
    "end": "461970"
  },
  {
    "start": "462000",
    "end": "501000"
  },
  {
    "text": "so each application also has a job coordinator which masters which which",
    "start": "463580",
    "end": "470780"
  },
  {
    "text": "manages the assignment of tasks across the individual containers the",
    "start": "470780",
    "end": "476210"
  },
  {
    "text": "coordinator monitors the liveness of individual containers and",
    "start": "476210",
    "end": "481630"
  },
  {
    "text": "redistributed which redistribute the tasks amount reminding ones the",
    "start": "481630",
    "end": "487730"
  },
  {
    "text": "remaining one during a failure the coordinator itself is pluggable so this",
    "start": "487730",
    "end": "493760"
  },
  {
    "text": "in labels this enables them to support multiple deployment options as we know",
    "start": "493760",
    "end": "502970"
  },
  {
    "text": "kubernetes supports long-running jobs well and them the stream processing",
    "start": "502970",
    "end": "508460"
  },
  {
    "text": "framework and its job are long-running jobs so communities is a good another",
    "start": "508460",
    "end": "515240"
  },
  {
    "text": "good option for Center user to deploy their jobs we integrate assembler with",
    "start": "515240",
    "end": "521659"
  },
  {
    "text": "communities for running streaming processing as a managed service we",
    "start": "521660",
    "end": "528020"
  },
  {
    "text": "averaged kubernetes for isolation multi-tenancy resource management and",
    "start": "528020",
    "end": "534200"
  },
  {
    "text": "deployment for center application in this mode you write your Center",
    "start": "534200",
    "end": "539960"
  },
  {
    "text": "abdication and some may choose gadget or kubernetes cluster Center then work with",
    "start": "539960",
    "end": "546470"
  },
  {
    "text": "communities to provision resources for your application and run it across a",
    "start": "546470",
    "end": "552080"
  },
  {
    "text": "customer shrinks it also handle the failure of individual instance and",
    "start": "552080",
    "end": "557650"
  },
  {
    "text": "automatically restart them we will dive",
    "start": "557650",
    "end": "563840"
  },
  {
    "text": "into how a sender job runs only qualities first let's recap a bit of",
    "start": "563840",
    "end": "570950"
  },
  {
    "start": "567000",
    "end": "605000"
  },
  {
    "text": "communities the master component includes API server controller",
    "start": "570950",
    "end": "576560"
  },
  {
    "text": "scheduler a scheduler Watson Union created path and select one node for",
    "start": "576560",
    "end": "582620"
  },
  {
    "text": "them to run for concern or cooperate history of building controllers like a",
    "start": "582620",
    "end": "587780"
  },
  {
    "text": "stay for that user users can also develop their own controllers",
    "start": "587780",
    "end": "593070"
  },
  {
    "text": "for a slave node component it includes cuba net and part cumin 'it is a agent",
    "start": "593070",
    "end": "599830"
  },
  {
    "text": "to launch and manage it like they called apart let's talk about the workflow of",
    "start": "599830",
    "end": "607390"
  },
  {
    "start": "605000",
    "end": "701000"
  },
  {
    "text": "offender jabroni own peak abilities so first the job the user use the wrong",
    "start": "607390",
    "end": "614890"
  },
  {
    "text": "app script to submit their job the squeak will initialize an application",
    "start": "614890",
    "end": "620920"
  },
  {
    "text": "runner which is the main entry point responsible for Ronnie Center application the application runner",
    "start": "620920",
    "end": "628270"
  },
  {
    "text": "parses your configs and writes them to a Kafka topic for distributing them then",
    "start": "628270",
    "end": "635560"
  },
  {
    "text": "it process it proceed to submit a request to a keep API server - now a job",
    "start": "635560",
    "end": "642550"
  },
  {
    "text": "coordinator pot the cumin it will start the job coordinator part the coordinator",
    "start": "642550",
    "end": "649960"
  },
  {
    "text": "the job coordinator is then responsible for managing the overall application in",
    "start": "649960",
    "end": "656200"
  },
  {
    "text": "race configs from the Kafka and computes work assignment for individual parts it",
    "start": "656200",
    "end": "662410"
  },
  {
    "text": "also determines the hosts each part should run on taking data locality into",
    "start": "662410",
    "end": "669370"
  },
  {
    "text": "account it proceeds choose then the work report creation request to API server",
    "start": "669370",
    "end": "675880"
  },
  {
    "text": "the cabinet will watch the requests and start a work report if the applications",
    "start": "675880",
    "end": "682480"
  },
  {
    "text": "dependency are hosted in the remote artifactory repository like HDFS those",
    "start": "682480",
    "end": "688900"
  },
  {
    "text": "dependency need to be downloaded into the pot so in step 8 the worker will ask",
    "start": "688900",
    "end": "696130"
  },
  {
    "text": "the job coordinator for is assigned tasks Network had more about the state",
    "start": "696130",
    "end": "703660"
  },
  {
    "start": "701000",
    "end": "734000"
  },
  {
    "text": "step 8 when the work report is started it first queried the job queries the job",
    "start": "703660",
    "end": "710560"
  },
  {
    "text": "coordinator for his work assignment and can fix the end process to ask you to is",
    "start": "710560",
    "end": "716950"
  },
  {
    "text": "assigned a tasks in this picture the job has two inputs which has four partitions repast",
    "start": "716950",
    "end": "724589"
  },
  {
    "text": "respectively each worker has its own assigned during partitions which then",
    "start": "724589",
    "end": "731170"
  },
  {
    "text": "can read input from nests look at more",
    "start": "731170",
    "end": "736629"
  },
  {
    "text": "about let's look at into the note cuban",
    "start": "736629",
    "end": "742689"
  },
  {
    "text": "it will start container and then continuously watched the house up the container it then restored container if",
    "start": "742689",
    "end": "750160"
  },
  {
    "text": "the container fails the container can be constricted to right state into local or",
    "start": "750160",
    "end": "757059"
  },
  {
    "text": "remote store if it's conveyed to the remote a remote store will be mounted",
    "start": "757059",
    "end": "763120"
  },
  {
    "text": "into the pot for the case in the example in the picture the agile remote store is",
    "start": "763120",
    "end": "769480"
  },
  {
    "text": "mounted into the pot next we'll do a",
    "start": "769480",
    "end": "777759"
  },
  {
    "text": "demo how to run a job on a chaos cluster in the cluster",
    "start": "777759",
    "end": "782860"
  },
  {
    "text": "besides kubernetes we also deploy kafka the job will write the result into Kafka",
    "start": "782860",
    "end": "789189"
  },
  {
    "text": "what is the jobs doing is to read real-time feeds from Wikipedia extracts",
    "start": "789189",
    "end": "795579"
  },
  {
    "text": "of metadata of the events and calculated count every 10 seconds for all added",
    "start": "795579",
    "end": "801430"
  },
  {
    "text": "that are that were made during the window it outputs the counts into a",
    "start": "801430",
    "end": "807040"
  },
  {
    "text": "current topic pod Wikipedia state topic let's look at a demo",
    "start": "807040",
    "end": "814829"
  },
  {
    "text": "I'm going to run a slender job called Wikipedia application in 80s this is to",
    "start": "825570",
    "end": "833160"
  },
  {
    "start": "826000",
    "end": "893000"
  },
  {
    "text": "add your portal I've created an 80s crafter they're the resources discs to",
    "start": "833160",
    "end": "840209"
  },
  {
    "text": "storage account and three virtual machines to use agile file as a",
    "start": "840209",
    "end": "846509"
  },
  {
    "text": "kubernetes for now we need to create storage account and no file share for it",
    "start": "846509",
    "end": "851940"
  },
  {
    "text": "so the standard storage account is for that the other storage account is used",
    "start": "851940",
    "end": "857009"
  },
  {
    "text": "to process the files for cloud the shell let's look at them the storage account",
    "start": "857009",
    "end": "864110"
  },
  {
    "text": "this is the file share I created now here there is no file here we'll go back",
    "start": "866540",
    "end": "874709"
  },
  {
    "text": "to here up to around the job let's open the shell to run the job",
    "start": "874709",
    "end": "881600"
  },
  {
    "text": "first let's look at the services wrong in the cluster in the cluster",
    "start": "892890",
    "end": "897900"
  },
  {
    "text": "besides kubernetes we also deployed caca because the job used Kafka as the",
    "start": "897900",
    "end": "903330"
  },
  {
    "text": "messaging system let's check the namespace besides default namespace we created",
    "start": "903330",
    "end": "911160"
  },
  {
    "text": "similar namespace for running send our jobs we can see here there is no sender",
    "start": "911160",
    "end": "920160"
  },
  {
    "text": "job running in the cluster as there's no pots in stem learning space in default",
    "start": "920160",
    "end": "929160"
  },
  {
    "text": "namespace there is a pot called Kafka client we all love into it to run all job",
    "start": "929160",
    "end": "937640"
  },
  {
    "text": "before running the job let's check the existing kafka topics this is the",
    "start": "950420",
    "end": "957530"
  },
  {
    "text": "command to these two kafka topics for a Wikipedia application job the job",
    "start": "957530",
    "end": "963380"
  },
  {
    "text": "results will be sent to a Kafka topic called Wikipedia States and now we can",
    "start": "963380",
    "end": "969260"
  },
  {
    "text": "say there's no such topic created we can",
    "start": "969260",
    "end": "979160"
  },
  {
    "text": "submit a standard job use the wrong app script we need to provide two parameters",
    "start": "979160",
    "end": "984650"
  },
  {
    "text": "to the script why is the configuration and the other is a factory class that's",
    "start": "984650",
    "end": "990410"
  },
  {
    "text": "used to create a configuration file other bugs sent achieves reach the prop",
    "start": "990410",
    "end": "995930"
  },
  {
    "text": "property config factory but you can also implement your own config factory as",
    "start": "995930",
    "end": "1001810"
  },
  {
    "text": "well before running the job let's look at what configurations we set up in the",
    "start": "1001810",
    "end": "1009040"
  },
  {
    "text": "configuration file this is the configuration file since we want to",
    "start": "1009040",
    "end": "1017380"
  },
  {
    "start": "1016000",
    "end": "1076000"
  },
  {
    "text": "learn the job on kubernetes we set up these two configurations tooth health lamda to choose community's",
    "start": "1017380",
    "end": "1023860"
  },
  {
    "text": "operator to run the jobs instead of our other cut cluster managers like Jung we",
    "start": "1023860",
    "end": "1031300"
  },
  {
    "text": "also set up the application class application name and ID job partition",
    "start": "1031300",
    "end": "1039760"
  },
  {
    "text": "number container account and the base directory of the log and job state files",
    "start": "1039760",
    "end": "1048089"
  },
  {
    "text": "these two configurations are related to capture system we also specify the image",
    "start": "1048930",
    "end": "1056110"
  },
  {
    "text": "name for the job and the namespace where a job runs this config is to enable the",
    "start": "1056110",
    "end": "1063190"
  },
  {
    "text": "job to use agile files as the communities volume other configurations",
    "start": "1063190",
    "end": "1068740"
  },
  {
    "text": "are ready to Kiba restore serializers and job metrics let's go back to cloud",
    "start": "1068740",
    "end": "1078130"
  },
  {
    "start": "1076000",
    "end": "1287000"
  },
  {
    "text": "shell to run the job okay",
    "start": "1078130",
    "end": "1086260"
  },
  {
    "text": "the job has been submitted to a chaos successfully let's check the job status",
    "start": "1086260",
    "end": "1097919"
  },
  {
    "text": "now we can see the arthropod created by the job one is the job coordinator part",
    "start": "1108490",
    "end": "1116500"
  },
  {
    "text": "this is the job coordinator part and the other two are worker parts their status",
    "start": "1116500",
    "end": "1125840"
  },
  {
    "text": "is running region check pot status in dashboard as well",
    "start": "1125840",
    "end": "1133269"
  },
  {
    "text": "let's switch to send our namespace",
    "start": "1144070",
    "end": "1148870"
  },
  {
    "text": "we can see the CPU usage memory usage",
    "start": "1152320",
    "end": "1157950"
  },
  {
    "text": "also we can see the part information and PV claims until now there's no errors or",
    "start": "1157950",
    "end": "1167650"
  },
  {
    "text": "exceptions showing in the dashboard everything looks up everything looks ok",
    "start": "1167650",
    "end": "1173560"
  },
  {
    "text": "everything looks fine we can lock into",
    "start": "1173560",
    "end": "1183430"
  },
  {
    "text": "the containers to check the job state and logs let's log in to one of the",
    "start": "1183430",
    "end": "1192520"
  },
  {
    "text": "worker containers",
    "start": "1192520",
    "end": "1195450"
  },
  {
    "text": "let's check if the log file in the state folder have created successfully or not",
    "start": "1203260",
    "end": "1211919"
  },
  {
    "text": "okay we can see the log files and the state folder now let's check the job",
    "start": "1211919",
    "end": "1224350"
  },
  {
    "text": "results we log back to the calc aligned",
    "start": "1224350",
    "end": "1231220"
  },
  {
    "text": "pot we check the Kafka topic again we",
    "start": "1231220",
    "end": "1243490"
  },
  {
    "text": "can see there are some topics created by the job the coordinator stream change",
    "start": "1243490",
    "end": "1248650"
  },
  {
    "text": "rock stream and saw in the median streams job results are saved into the",
    "start": "1248650",
    "end": "1255280"
  },
  {
    "text": "Kafka topic Wikipedia States we can use",
    "start": "1255280",
    "end": "1261720"
  },
  {
    "text": "we can use this command to read the messages from the result topic",
    "start": "1262140",
    "end": "1270630"
  },
  {
    "text": "now we can see there have been some results already okay if the container is",
    "start": "1275200",
    "end": "1288650"
  },
  {
    "text": "gone the file saving the container will also come to check the job state and",
    "start": "1288650",
    "end": "1294470"
  },
  {
    "text": "marks after that container gone we can check them in agile file because before",
    "start": "1294470",
    "end": "1301040"
  },
  {
    "text": "running the job we can take the job to use agile file as the remote volume monkey into the pot the data in agile",
    "start": "1301040",
    "end": "1311060"
  },
  {
    "text": "file will always be there no matter whether the job or container is come a",
    "start": "1311060",
    "end": "1316400"
  },
  {
    "text": "lot let's go back to the agile file and check the logs and state files",
    "start": "1316400",
    "end": "1323980"
  },
  {
    "text": "now we can see there are the job logs and state files this is this is the",
    "start": "1330530",
    "end": "1340790"
  },
  {
    "text": "folder for the job job coordinator pod the other two are for a worker container",
    "start": "1340790",
    "end": "1349840"
  },
  {
    "text": "there are the logs and the job states",
    "start": "1349870",
    "end": "1357550"
  },
  {
    "text": "there's all the demo",
    "start": "1357550",
    "end": "1361240"
  },
  {
    "text": "next Jim will talk about a different deployment options",
    "start": "1365760",
    "end": "1371809"
  },
  {
    "text": "nope yeah so I'll talk about the other",
    "start": "1378100",
    "end": "1383210"
  },
  {
    "start": "1379000",
    "end": "1748000"
  },
  {
    "text": "deployment options for Sansa that is in the running scanner or learning on how",
    "start": "1383210",
    "end": "1389270"
  },
  {
    "text": "to be yarn and also I briefly mentioned how conics kunis works for other data",
    "start": "1389270",
    "end": "1396410"
  },
  {
    "text": "processing engine like spark Fink first the stand alone mode of sensor so in the",
    "start": "1396410",
    "end": "1406220"
  },
  {
    "text": "previous part we mentioned that sensor works on communities and Sansa has also",
    "start": "1406220",
    "end": "1413240"
  },
  {
    "text": "has a way to run static ray on the host meaning the user can simply start the",
    "start": "1413240",
    "end": "1419090"
  },
  {
    "text": "center stream processor manually on the pair host and in this mode so all the",
    "start": "1419090",
    "end": "1426290"
  },
  {
    "text": "stream processors uses the zookeeper for communication so basically it used the",
    "start": "1426290",
    "end": "1433490"
  },
  {
    "text": "suitable for membership management and tasks or Nations so in contrast in this",
    "start": "1433490",
    "end": "1439760"
  },
  {
    "text": "mode it does not use kubernetes or yarn for scattering so there will be limitations life if one node fails",
    "start": "1439760",
    "end": "1447550"
  },
  {
    "text": "sensor stream processor cannot automatically fill to a different fit over to a different node so there will",
    "start": "1447550",
    "end": "1453830"
  },
  {
    "text": "be some limitations in this mode so and that's not mode that similar runs on",
    "start": "1453830",
    "end": "1460640"
  },
  {
    "text": "yarn so in this mode sims are the average yum for scheduling and resource management and deployment so Jana is",
    "start": "1460640",
    "end": "1468320"
  },
  {
    "text": "very similar octo is similar to kubernetes it's also a master/slave",
    "start": "1468320",
    "end": "1475840"
  },
  {
    "text": "architecture that Yan has a master called a resource manager the iron so",
    "start": "1475840",
    "end": "1483710"
  },
  {
    "text": "that is similar to the API server and schedule of the communities it is",
    "start": "1483710",
    "end": "1489080"
  },
  {
    "text": "responsible for scheduling the containers across clusters and the slave",
    "start": "1489080",
    "end": "1496010"
  },
  {
    "text": "is the node manager that is similar to the row of cookies in communities and it",
    "start": "1496010",
    "end": "1501680"
  },
  {
    "text": "is most possible for launching the containers and also there's an",
    "start": "1501680",
    "end": "1507080"
  },
  {
    "text": "application master that is similar to the control the operators concept in",
    "start": "1507080",
    "end": "1512219"
  },
  {
    "text": "communities so the application master is basically a piece of user usually",
    "start": "1512219",
    "end": "1518190"
  },
  {
    "text": "written code for user to interaction interact with young and start their",
    "start": "1518190",
    "end": "1524099"
  },
  {
    "text": "continuous the way it works is so the",
    "start": "1524099",
    "end": "1530700"
  },
  {
    "text": "sender young client first talked to the resource manager it submits the spot",
    "start": "1530700",
    "end": "1536070"
  },
  {
    "text": "sorry the Scimitar application and then the resource manager will make decisions",
    "start": "1536070",
    "end": "1541590"
  },
  {
    "text": "and scheduling the center the same time application master to a particular node",
    "start": "1541590",
    "end": "1547559"
  },
  {
    "text": "so once the sensor application master is started it goes back talking to the",
    "start": "1547559",
    "end": "1553080"
  },
  {
    "text": "resource manager and asked him for continuous to launch the sentence or",
    "start": "1553080",
    "end": "1559349"
  },
  {
    "text": "tasks so the center tasks as a real task that's running inside the container so",
    "start": "1559349",
    "end": "1565739"
  },
  {
    "text": "once the center talks is started on the know major then it can start with its",
    "start": "1565739",
    "end": "1573509"
  },
  {
    "text": "own business project like reading data from the Kafka broker if we do a",
    "start": "1573509",
    "end": "1583049"
  },
  {
    "text": "comparison between kubernetes and yarn so communities is historically good for",
    "start": "1583049",
    "end": "1591419"
  },
  {
    "text": "Romani service as people know so the design of kubernetes",
    "start": "1591419",
    "end": "1596759"
  },
  {
    "text": "is also called the lab of sugar design the way it works is user specify the",
    "start": "1596759",
    "end": "1604979"
  },
  {
    "text": "intent in the phone like llamo foul so it specify the intent what the state or",
    "start": "1604979",
    "end": "1612269"
  },
  {
    "text": "the what is the expected state of my app and then the operator or the controller running on kubernetes it will try to",
    "start": "1612269",
    "end": "1619049"
  },
  {
    "text": "drive the current state of the cluster towards the desired state say example if",
    "start": "1619049",
    "end": "1626369"
  },
  {
    "text": "we deploy app with five traffickers and the cluster has only say three replicas",
    "start": "1626369",
    "end": "1632369"
  },
  {
    "text": "it will try to match up there were two remaining ones and if it's more than that it will automatically delete the",
    "start": "1632369",
    "end": "1638669"
  },
  {
    "text": "extra ones so it's always trying to match the current state towards the desired State and that's how the",
    "start": "1638669",
    "end": "1646430"
  },
  {
    "text": "create the controller the operator works in encode so it always does this control",
    "start": "1646430",
    "end": "1652610"
  },
  {
    "text": "loop every period all the time it checks the current state and the desired state so this sort of creates a",
    "start": "1652610",
    "end": "1659980"
  },
  {
    "text": "self-healing mechanism so like eventually the system will somehow go",
    "start": "1659980",
    "end": "1668510"
  },
  {
    "text": "back to the original track so in every such loop design patterns",
    "start": "1668510",
    "end": "1675520"
  },
  {
    "text": "it's ideal for automated operations so people can similarly say well my",
    "start": "1675520",
    "end": "1681740"
  },
  {
    "text": "obsession water state I wanted my application to be and then the controller operator will go towards that",
    "start": "1681740",
    "end": "1688580"
  },
  {
    "text": "state so in contrast the young based on it's not like that Soyoung is mostly",
    "start": "1688580",
    "end": "1693860"
  },
  {
    "text": "known for big data processing engines so it's a platform for scheduling data",
    "start": "1693860",
    "end": "1701780"
  },
  {
    "text": "process engine starts Park Map Reduce and so on so it's known cool for best",
    "start": "1701780",
    "end": "1708110"
  },
  {
    "text": "jobs and Jung has this first-class job concept since I've built features for",
    "start": "1708110",
    "end": "1716290"
  },
  {
    "text": "job priority so we can scheduling based on job the job level and and there are",
    "start": "1716290",
    "end": "1725960"
  },
  {
    "text": "the the scheduling part of the arm is also I think is more more feature",
    "start": "1725960",
    "end": "1732250"
  },
  {
    "text": "extensive attend communities it builds a lot of scheduling advanced features",
    "start": "1732250",
    "end": "1737570"
  },
  {
    "text": "there so but in contrast of kubernetes scheduling is mostly based on power level so it's schedule based on Paul so",
    "start": "1737570",
    "end": "1744650"
  },
  {
    "text": "there are some difference in your communities other than that we so we all",
    "start": "1744650",
    "end": "1753050"
  },
  {
    "start": "1748000",
    "end": "2085000"
  },
  {
    "text": "talk about some how kubernetes works for other differences in engines like spark",
    "start": "1753050",
    "end": "1758180"
  },
  {
    "text": "and Frink so first spark spot is in here it's very similar to what we just how",
    "start": "1758180",
    "end": "1766850"
  },
  {
    "text": "spark works on communities is that spark still it also has the driver",
    "start": "1766850",
    "end": "1773960"
  },
  {
    "text": "and accurate so the driver is is pretty much similar to the same job coordinator",
    "start": "1773960",
    "end": "1780110"
  },
  {
    "text": "is the essential component for coordinating the tasks across the",
    "start": "1780110",
    "end": "1785870"
  },
  {
    "text": "casters and the actual executor is a real and real worker that's similar to",
    "start": "1785870",
    "end": "1791480"
  },
  {
    "text": "the sensor Walker and the job declined versus um it's the the driver port and",
    "start": "1791480",
    "end": "1798020"
  },
  {
    "text": "the de job for once the job report started it will go back to the communities API server and create its",
    "start": "1798020",
    "end": "1805340"
  },
  {
    "text": "own executor port so once all these ports started a spark rasterized phone",
    "start": "1805340",
    "end": "1812649"
  },
  {
    "text": "so that's how spark works to with the communities and there's another thing",
    "start": "1812649",
    "end": "1818539"
  },
  {
    "text": "community built that's called spark operator so the spark operator either averages the operator concept in",
    "start": "1818539",
    "end": "1825649"
  },
  {
    "text": "communities as I mentioned so operator in community is a is a is a way for user",
    "start": "1825649",
    "end": "1833299"
  },
  {
    "text": "to specify their IP application in a declarative form so say in a form of a",
    "start": "1833299",
    "end": "1841010"
  },
  {
    "text": "llamo foul and user submits the llamo powder to the cluster and the operator will watch the yellow flower definition",
    "start": "1841010",
    "end": "1849020"
  },
  {
    "text": "and tries to create or delete certain ports to match the Yamaha definition so",
    "start": "1849020",
    "end": "1857720"
  },
  {
    "text": "here similarly spark root its own spark operator that the user can submit the",
    "start": "1857720",
    "end": "1865309"
  },
  {
    "text": "spark definition definition through the co I and the spark operator watch that",
    "start": "1865309",
    "end": "1870380"
  },
  {
    "text": "definition fallen to whatever it needs like creates the driver port and the job",
    "start": "1870380",
    "end": "1875899"
  },
  {
    "text": "was done internally the actual parts and also the operator monitors the port",
    "start": "1875899",
    "end": "1881179"
  },
  {
    "text": "status and tries to set the operation status based on certain port status so",
    "start": "1881179",
    "end": "1887330"
  },
  {
    "text": "this whole thing is very similar to the well-known controllers on communities such as the staples a deployment and so",
    "start": "1887330",
    "end": "1895309"
  },
  {
    "text": "on so the llamo foul of spark operator looks like this",
    "start": "1895309",
    "end": "1901770"
  },
  {
    "text": "it shows the spat and the status the spatter is the is the specification of",
    "start": "1901770",
    "end": "1907200"
  },
  {
    "text": "the spark application inside it specifies things like the driver and the",
    "start": "1907200",
    "end": "1914309"
  },
  {
    "text": "executors what is the memory sizing the cost limits and so on for the spark and",
    "start": "1914309",
    "end": "1920100"
  },
  {
    "text": "also the image what is image for the application and also the instructor",
    "start": "1920100",
    "end": "1926130"
  },
  {
    "text": "cross name of the spark gap and the stator side it shows the status of the",
    "start": "1926130",
    "end": "1931650"
  },
  {
    "text": "app and other informations right the the web UI address and so on so that's how",
    "start": "1931650",
    "end": "1939750"
  },
  {
    "text": "spark works on communities and so communities also integral integral ways",
    "start": "1939750",
    "end": "1947610"
  },
  {
    "text": "of print so the spring is another popular very popular streaming",
    "start": "1947610",
    "end": "1953160"
  },
  {
    "text": "processing engines and think architecture wise it's also kind of like",
    "start": "1953160",
    "end": "1959370"
  },
  {
    "text": "the master slave so the spring has the job manager that's similar to the center job coordinator and also the task",
    "start": "1959370",
    "end": "1967440"
  },
  {
    "text": "manager that's similar to the center worker so in cranes it actually uses the",
    "start": "1967440",
    "end": "1976679"
  },
  {
    "text": "communities department primitive to launch its own job managers and task",
    "start": "1976679",
    "end": "1982110"
  },
  {
    "text": "managers so it does not it's not embedded in the finger framework up to",
    "start": "1982110",
    "end": "1988020"
  },
  {
    "text": "this time so the process of this approach is that ravaged the exist robust communities worker primitive and",
    "start": "1988020",
    "end": "1996440"
  },
  {
    "text": "this requires minimum coal change but the disadvantage of that is it's not as",
    "start": "1996440",
    "end": "2004220"
  },
  {
    "text": "factual as the center spark approach so in the below examples the job so the",
    "start": "2004220",
    "end": "2011540"
  },
  {
    "text": "left side shows the llamo definition for the job manager that's the de prompt that uses the",
    "start": "2011540",
    "end": "2017540"
  },
  {
    "text": "department primitive increment is to to deploy one instance of the Fink job",
    "start": "2017540",
    "end": "2024590"
  },
  {
    "text": "manager and the right side shows the department yeah no foul for user to",
    "start": "2024590",
    "end": "2030500"
  },
  {
    "text": "deployed - ramicus of task managers so with this way the drink ravages the department -",
    "start": "2030500",
    "end": "2040640"
  },
  {
    "text": "launched instances however so in",
    "start": "2040640",
    "end": "2046880"
  },
  {
    "text": "contrast with the previous mechanism in this mode it has limitations like you",
    "start": "2046880",
    "end": "2053840"
  },
  {
    "text": "cannot say I want to run a port on a particular node with data locality",
    "start": "2053840",
    "end": "2060500"
  },
  {
    "text": "considered so it's computed average the underlying controller primitives so it",
    "start": "2060500",
    "end": "2066590"
  },
  {
    "text": "has such limitations so that the conjure a primitive core is hard holy so you can't easily change it so that's one",
    "start": "2066590",
    "end": "2075260"
  },
  {
    "text": "thing and yeah so that's it it concludes our session thank you",
    "start": "2075260",
    "end": "2082810"
  },
  {
    "text": "[Applause]",
    "start": "2084920",
    "end": "2086989"
  }
]
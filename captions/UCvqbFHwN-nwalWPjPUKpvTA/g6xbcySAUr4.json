[
  {
    "text": "hello my name is Christine Yen Thank you",
    "start": "160",
    "end": "2720"
  },
  {
    "text": "for having me I'm excited to be here",
    "start": "2720",
    "end": "4880"
  },
  {
    "text": "While I am the co-founder and CEO of",
    "start": "4880",
    "end": "6319"
  },
  {
    "text": "Honeycomb I will say the statements and",
    "start": "6319",
    "end": "8720"
  },
  {
    "text": "assertions I make should apply to any",
    "start": "8720",
    "end": "11040"
  },
  {
    "text": "modern observability workflow Let's get",
    "start": "11040",
    "end": "14280"
  },
  {
    "text": "it Writing software today feels more",
    "start": "14280",
    "end": "17600"
  },
  {
    "text": "magical than it ever has before We've",
    "start": "17600",
    "end": "20000"
  },
  {
    "text": "got LLMs everywhere We have cheap API",
    "start": "20000",
    "end": "22640"
  },
  {
    "text": "calls to foundation models Not even",
    "start": "22640",
    "end": "25119"
  },
  {
    "text": "going to touch the whole idea of vibe",
    "start": "25119",
    "end": "26560"
  },
  {
    "text": "coding in this talk There's a lot to be",
    "start": "26560",
    "end": "29119"
  },
  {
    "text": "excited about here It's very cool to be",
    "start": "29119",
    "end": "31519"
  },
  {
    "text": "in the middle of a phase change in",
    "start": "31519",
    "end": "33040"
  },
  {
    "text": "progress when everything is new to",
    "start": "33040",
    "end": "35120"
  },
  {
    "text": "everyone at the same time And most of us",
    "start": "35120",
    "end": "39520"
  },
  {
    "text": "here today have been building software",
    "start": "39520",
    "end": "40960"
  },
  {
    "text": "before this LLM boom And we know the",
    "start": "40960",
    "end": "43840"
  },
  {
    "text": "hard part about building software",
    "start": "43840",
    "end": "45360"
  },
  {
    "text": "systems isn't just the writing of the",
    "start": "45360",
    "end": "47600"
  },
  {
    "text": "code It's the testing it's the",
    "start": "47600",
    "end": "51120"
  },
  {
    "text": "maintenance the tuning and the debugging",
    "start": "51120",
    "end": "54160"
  },
  {
    "text": "that comes after So while LLMs have a",
    "start": "54160",
    "end": "57520"
  },
  {
    "text": "ton of implications for everything that",
    "start": "57520",
    "end": "58960"
  },
  {
    "text": "we're doing I want to spend this time",
    "start": "58960",
    "end": "60960"
  },
  {
    "text": "with you today on this specific part of",
    "start": "60960",
    "end": "63199"
  },
  {
    "text": "it How we make sure that the code that",
    "start": "63199",
    "end": "65518"
  },
  {
    "text": "we build on top of these magical black",
    "start": "65519",
    "end": "68439"
  },
  {
    "text": "boxes still works the way that we expect",
    "start": "68439",
    "end": "71360"
  },
  {
    "text": "after we've shipped and it's in front of",
    "start": "71360",
    "end": "73439"
  },
  {
    "text": "the user",
    "start": "73439",
    "end": "75600"
  },
  {
    "text": "Now we work with black boxes and",
    "start": "75600",
    "end": "77520"
  },
  {
    "text": "software all the time but LLMs take some",
    "start": "77520",
    "end": "80880"
  },
  {
    "text": "of the ways that we're used to ensuring",
    "start": "80880",
    "end": "83200"
  },
  {
    "text": "consistent reliable behavior and make",
    "start": "83200",
    "end": "86240"
  },
  {
    "text": "them a little more difficult Take for",
    "start": "86240",
    "end": "88720"
  },
  {
    "text": "example trying to make sure your code",
    "start": "88720",
    "end": "90479"
  },
  {
    "text": "overall is testable mockable and",
    "start": "90479",
    "end": "92680"
  },
  {
    "text": "debugable Well unit tests rely on your",
    "start": "92680",
    "end": "97040"
  },
  {
    "text": "being able to define a rep",
    "start": "97040",
    "end": "98960"
  },
  {
    "text": "representative set of inputs With LLMs",
    "start": "98960",
    "end": "102720"
  },
  {
    "text": "we're intentionally opening the door to",
    "start": "102720",
    "end": "104400"
  },
  {
    "text": "a very long tale of possible",
    "start": "104400",
    "end": "106840"
  },
  {
    "text": "inputs As for",
    "start": "106840",
    "end": "109799"
  },
  {
    "text": "mocks LLMs are by nature",
    "start": "109799",
    "end": "112920"
  },
  {
    "text": "non-deterministic Swapping it out for",
    "start": "112920",
    "end": "114799"
  },
  {
    "text": "deterministic mock doesn't really help",
    "start": "114799",
    "end": "117680"
  },
  {
    "text": "us much here And when it comes to",
    "start": "117680",
    "end": "120079"
  },
  {
    "text": "debugging your LLM behavior we don't",
    "start": "120079",
    "end": "122479"
  },
  {
    "text": "have simple logical paths to step",
    "start": "122479",
    "end": "124640"
  },
  {
    "text": "through The whole point of incorporating",
    "start": "124640",
    "end": "126719"
  },
  {
    "text": "LLMs into our software is to wrap the",
    "start": "126719",
    "end": "129679"
  },
  {
    "text": "full breadth of human expression into",
    "start": "129679",
    "end": "131840"
  },
  {
    "text": "our code Debugging LLM behaviors kind of",
    "start": "131840",
    "end": "135760"
  },
  {
    "text": "just turns out to trying something and",
    "start": "135760",
    "end": "137680"
  },
  {
    "text": "seeing what",
    "start": "137680",
    "end": "139319"
  },
  {
    "text": "happens So this turning upside down of",
    "start": "139319",
    "end": "142239"
  },
  {
    "text": "our worldview is happening on a literal",
    "start": "142239",
    "end": "143920"
  },
  {
    "text": "software engineering systems engineering",
    "start": "143920",
    "end": "145760"
  },
  {
    "text": "level where these black boxes just",
    "start": "145760",
    "end": "147760"
  },
  {
    "text": "aren't testable or debugable the way",
    "start": "147760",
    "end": "149440"
  },
  {
    "text": "that we're used to which means there's",
    "start": "149440",
    "end": "151599"
  },
  {
    "text": "no solid sense of correct to fall back",
    "start": "151599",
    "end": "153519"
  },
  {
    "text": "to It's also true at a meta level There",
    "start": "153519",
    "end": "157120"
  },
  {
    "text": "is no environment within which we can",
    "start": "157120",
    "end": "159200"
  },
  {
    "text": "conduct our tests and feel confident in",
    "start": "159200",
    "end": "161040"
  },
  {
    "text": "the",
    "start": "161040",
    "end": "161879"
  },
  {
    "text": "results Even normal product development",
    "start": "161879",
    "end": "164400"
  },
  {
    "text": "or release practices have deter have",
    "start": "164400",
    "end": "167280"
  },
  {
    "text": "have turned inside out instead of",
    "start": "167280",
    "end": "169280"
  },
  {
    "text": "starting with an alpha or beta and then",
    "start": "169280",
    "end": "171599"
  },
  {
    "text": "feeling confident in later broader",
    "start": "171599",
    "end": "173560"
  },
  {
    "text": "release All these early access programs",
    "start": "173560",
    "end": "176000"
  },
  {
    "text": "tend to do is inherently fail to capture",
    "start": "176000",
    "end": "178400"
  },
  {
    "text": "the full range of user behavior and edge",
    "start": "178400",
    "end": "180959"
  },
  {
    "text": "cases",
    "start": "180959",
    "end": "182480"
  },
  {
    "text": "These boxes in the middle column may",
    "start": "182480",
    "end": "184080"
  },
  {
    "text": "still be working for you and may still",
    "start": "184080",
    "end": "185760"
  },
  {
    "text": "be a good idea They just won't be enough",
    "start": "185760",
    "end": "188480"
  },
  {
    "text": "for ensuring the correctness of your new",
    "start": "188480",
    "end": "190319"
  },
  {
    "text": "LLMbacked functionality when you're",
    "start": "190319",
    "end": "192560"
  },
  {
    "text": "inviting your end users to do a lot of",
    "start": "192560",
    "end": "195200"
  },
  {
    "text": "things in your system that you may never",
    "start": "195200",
    "end": "196959"
  },
  {
    "text": "have",
    "start": "196959",
    "end": "198440"
  },
  {
    "text": "expected So is it time to give up on",
    "start": "198440",
    "end": "201519"
  },
  {
    "text": "everything we've learned and know how to",
    "start": "201519",
    "end": "203280"
  },
  {
    "text": "do and just embrace the rise of prompt",
    "start": "203280",
    "end": "205280"
  },
  {
    "text": "engineering as a specialized skill set",
    "start": "205280",
    "end": "207200"
  },
  {
    "text": "of the",
    "start": "207200",
    "end": "208040"
  },
  {
    "text": "future no obviously not Or else I",
    "start": "208040",
    "end": "210319"
  },
  {
    "text": "wouldn't be here today",
    "start": "210319",
    "end": "213159"
  },
  {
    "text": "Because a lot of the conversations we've",
    "start": "213159",
    "end": "215680"
  },
  {
    "text": "been having as an industry over the",
    "start": "215680",
    "end": "217120"
  },
  {
    "text": "years about how to build reliable and",
    "start": "217120",
    "end": "219599"
  },
  {
    "text": "performant available systems in a",
    "start": "219599",
    "end": "222000"
  },
  {
    "text": "chaotic cloudnative world are still",
    "start": "222000",
    "end": "224400"
  },
  {
    "text": "relevant probably more relevant with the",
    "start": "224400",
    "end": "227200"
  },
  {
    "text": "sort of rapid iteration that building",
    "start": "227200",
    "end": "228720"
  },
  {
    "text": "with lens demands",
    "start": "228720",
    "end": "231599"
  },
  {
    "text": "Adopting CI/CD let us shift code let us",
    "start": "231599",
    "end": "234640"
  },
  {
    "text": "ship code much more frequently rapidly",
    "start": "234640",
    "end": "237840"
  },
  {
    "text": "iterating on user",
    "start": "237840",
    "end": "239959"
  },
  {
    "text": "experience talking about testing in",
    "start": "239959",
    "end": "242080"
  },
  {
    "text": "production helped us all embrace the",
    "start": "242080",
    "end": "244159"
  },
  {
    "text": "chaos of real user",
    "start": "244159",
    "end": "246280"
  },
  {
    "text": "input versus artificially sterile test",
    "start": "246280",
    "end": "250040"
  },
  {
    "text": "environments high cardality metadata has",
    "start": "250040",
    "end": "252879"
  },
  {
    "text": "become a must-have if software",
    "start": "252879",
    "end": "254879"
  },
  {
    "text": "engineering teams are trying to",
    "start": "254879",
    "end": "256959"
  },
  {
    "text": "understand complex systems whether that",
    "start": "256959",
    "end": "259759"
  },
  {
    "text": "complexity comes from your architecture",
    "start": "259759",
    "end": "261840"
  },
  {
    "text": "or trying to understand the business",
    "start": "261840",
    "end": "263440"
  },
  {
    "text": "impact or per user",
    "start": "263440",
    "end": "267160"
  },
  {
    "text": "experiences High dimensionality data",
    "start": "267160",
    "end": "270080"
  },
  {
    "text": "being able to break down aggregate data",
    "start": "270080",
    "end": "272639"
  },
  {
    "text": "by a bunch of possible related fields",
    "start": "272639",
    "end": "274960"
  },
  {
    "text": "not just a small number of predefined",
    "start": "274960",
    "end": "276720"
  },
  {
    "text": "ones has become the default way to",
    "start": "276720",
    "end": "278960"
  },
  {
    "text": "detangle the interaction of multiple",
    "start": "278960",
    "end": "281360"
  },
  {
    "text": "contributing factors",
    "start": "281360",
    "end": "283680"
  },
  {
    "text": "and SLOs's service level objectives",
    "start": "283680",
    "end": "286240"
  },
  {
    "text": "borrowed from our SRE friends have let",
    "start": "286240",
    "end": "288560"
  },
  {
    "text": "us leverage existing alerting workflows",
    "start": "288560",
    "end": "291280"
  },
  {
    "text": "but anchoring them around fuzzy concepts",
    "start": "291280",
    "end": "293360"
  },
  {
    "text": "like user experience or are we",
    "start": "293360",
    "end": "295919"
  },
  {
    "text": "delivering a good service to our end",
    "start": "295919",
    "end": "298759"
  },
  {
    "text": "users these trends have already begun",
    "start": "298759",
    "end": "301759"
  },
  {
    "text": "driving a distinct new approach to",
    "start": "301759",
    "end": "303360"
  },
  {
    "text": "making sense of our software even in a",
    "start": "303360",
    "end": "306160"
  },
  {
    "text": "prelim",
    "start": "306160",
    "end": "307720"
  },
  {
    "text": "world and we already have a model for",
    "start": "307720",
    "end": "310400"
  },
  {
    "text": "how to measure debug and move the needle",
    "start": "310400",
    "end": "313120"
  },
  {
    "text": "on unpredictable qualitative or",
    "start": "313120",
    "end": "315199"
  },
  {
    "text": "quantitative experiences",
    "start": "315199",
    "end": "318280"
  },
  {
    "text": "Observability where it's all about",
    "start": "318280",
    "end": "320600"
  },
  {
    "text": "comparing expected behavior against what",
    "start": "320600",
    "end": "323600"
  },
  {
    "text": "we're actually seeing in",
    "start": "323600",
    "end": "325080"
  },
  {
    "text": "production in front of our live",
    "start": "325080",
    "end": "328440"
  },
  {
    "text": "users Because these are some truths",
    "start": "328440",
    "end": "330960"
  },
  {
    "text": "about building on LLM Something",
    "start": "330960",
    "end": "333440"
  },
  {
    "text": "unpredictable will happen User behavior",
    "start": "333440",
    "end": "335919"
  },
  {
    "text": "will be chaotic One fix will break",
    "start": "335919",
    "end": "338880"
  },
  {
    "text": "something else Tests won't be enough and",
    "start": "338880",
    "end": "342000"
  },
  {
    "text": "early access programs won't help you",
    "start": "342000",
    "end": "344720"
  },
  {
    "text": "These aren't only properties of",
    "start": "344720",
    "end": "346240"
  },
  {
    "text": "extremely complex systems They impact",
    "start": "346240",
    "end": "348639"
  },
  {
    "text": "all of us once we've decided to take in",
    "start": "348639",
    "end": "351360"
  },
  {
    "text": "natural language input or unpredictable",
    "start": "351360",
    "end": "353440"
  },
  {
    "text": "input from users and pass it off to AI",
    "start": "353440",
    "end": "356160"
  },
  {
    "text": "to make decisions about that path",
    "start": "356160",
    "end": "358720"
  },
  {
    "text": "carries with it a level of chaos and",
    "start": "358720",
    "end": "360400"
  },
  {
    "text": "complexity that will force us all to",
    "start": "360400",
    "end": "362720"
  },
  {
    "text": "level up fast",
    "start": "362720",
    "end": "366400"
  },
  {
    "text": "Now observability helps embrace some",
    "start": "366400",
    "end": "368280"
  },
  {
    "text": "unpredictability enabling the sort of",
    "start": "368280",
    "end": "370240"
  },
  {
    "text": "feedback loops that let you learn from",
    "start": "370240",
    "end": "372560"
  },
  {
    "text": "what's really happening with your code",
    "start": "372560",
    "end": "375039"
  },
  {
    "text": "The same way that we've learned to work",
    "start": "375039",
    "end": "376800"
  },
  {
    "text": "iteratively with tests observability",
    "start": "376800",
    "end": "378960"
  },
  {
    "text": "enables us all to ship sooner observe",
    "start": "378960",
    "end": "380880"
  },
  {
    "text": "those results in the wild and wrap those",
    "start": "380880",
    "end": "382800"
  },
  {
    "text": "observations back in the into the",
    "start": "382800",
    "end": "384319"
  },
  {
    "text": "development",
    "start": "384319",
    "end": "385560"
  },
  {
    "text": "process We just said tests wouldn't be",
    "start": "385560",
    "end": "387759"
  },
  {
    "text": "enough",
    "start": "387759",
    "end": "389319"
  },
  {
    "text": "right that's where eval come As a quick",
    "start": "389319",
    "end": "392319"
  },
  {
    "text": "sidebar for anyone who isn't familiar",
    "start": "392319",
    "end": "394960"
  },
  {
    "text": "these are tools that allow us to codify",
    "start": "394960",
    "end": "397120"
  },
  {
    "text": "what good looks like in an LLM world",
    "start": "397120",
    "end": "399840"
  },
  {
    "text": "that allow for a little bit more",
    "start": "399840",
    "end": "401199"
  },
  {
    "text": "flexibility about what success or",
    "start": "401199",
    "end": "403440"
  },
  {
    "text": "failure means for our applications The",
    "start": "403440",
    "end": "406319"
  },
  {
    "text": "pattern is that you develop your set of",
    "start": "406319",
    "end": "408160"
  },
  {
    "text": "eval as you develop your application and",
    "start": "408160",
    "end": "410560"
  },
  {
    "text": "we use them to capture intended behavior",
    "start": "410560",
    "end": "413440"
  },
  {
    "text": "or flag behavior as you work with your",
    "start": "413440",
    "end": "416080"
  },
  {
    "text": "prompt Now eval parallel observability",
    "start": "416080",
    "end": "419120"
  },
  {
    "text": "in really useful ways While",
    "start": "419120",
    "end": "420800"
  },
  {
    "text": "observability is all about the",
    "start": "420800",
    "end": "422240"
  },
  {
    "text": "unpredictability and chaos of production",
    "start": "422240",
    "end": "424319"
  },
  {
    "text": "eval capture that good and the bad as",
    "start": "424319",
    "end": "427039"
  },
  {
    "text": "they happen Although in both cases",
    "start": "427039",
    "end": "429919"
  },
  {
    "text": "whether you're talking about the",
    "start": "429919",
    "end": "430800"
  },
  {
    "text": "instrumentation behind your",
    "start": "430800",
    "end": "431840"
  },
  {
    "text": "observability or eval themselves the",
    "start": "431840",
    "end": "434479"
  },
  {
    "text": "intention is for them to evolve with",
    "start": "434479",
    "end": "436400"
  },
  {
    "text": "your code",
    "start": "436400",
    "end": "438000"
  },
  {
    "text": "And what you find in your observability",
    "start": "438000",
    "end": "439759"
  },
  {
    "text": "tools about how users are trying to use",
    "start": "439759",
    "end": "442000"
  },
  {
    "text": "your software turns out to be the best",
    "start": "442000",
    "end": "444880"
  },
  {
    "text": "source of input into defining those new",
    "start": "444880",
    "end": "447720"
  },
  {
    "text": "evals And so if you put these two things",
    "start": "447720",
    "end": "450120"
  },
  {
    "text": "together the same way that observability",
    "start": "450120",
    "end": "452720"
  },
  {
    "text": "offers feedback loops into development",
    "start": "452720",
    "end": "454880"
  },
  {
    "text": "observability pairs with your evals to",
    "start": "454880",
    "end": "457599"
  },
  {
    "text": "form these feedback loops informing and",
    "start": "457599",
    "end": "460080"
  },
  {
    "text": "improving your prompts As you're",
    "start": "460080",
    "end": "462319"
  },
  {
    "text": "uncovering the behavior of your LLMs in",
    "start": "462319",
    "end": "464400"
  },
  {
    "text": "response to your prompts you're defining",
    "start": "464400",
    "end": "466120"
  },
  {
    "text": "eval releasing quickly watching that",
    "start": "466120",
    "end": "468960"
  },
  {
    "text": "code in the wild then closing the loop",
    "start": "468960",
    "end": "471199"
  },
  {
    "text": "as you learn and pulling those learnings",
    "start": "471199",
    "end": "473599"
  },
  {
    "text": "back into your codebase to live on",
    "start": "473599",
    "end": "475520"
  },
  {
    "text": "forever as",
    "start": "475520",
    "end": "478080"
  },
  {
    "text": "eval Let's go one level deeper What does",
    "start": "478120",
    "end": "481360"
  },
  {
    "text": "it look like to ensure that you're",
    "start": "481360",
    "end": "483599"
  },
  {
    "text": "setting yourself and your observability",
    "start": "483599",
    "end": "485360"
  },
  {
    "text": "tooling up to support this kind of",
    "start": "485360",
    "end": "487520"
  },
  {
    "text": "workflow",
    "start": "487520",
    "end": "489080"
  },
  {
    "text": "well because LLMs and Gen AI are these",
    "start": "489080",
    "end": "493120"
  },
  {
    "text": "non-deterministic black boxes with",
    "start": "493120",
    "end": "495680"
  },
  {
    "text": "unbounded variations on inputs they can",
    "start": "495680",
    "end": "498120"
  },
  {
    "text": "receive with a rapidly evolving set of",
    "start": "498120",
    "end": "500720"
  },
  {
    "text": "paths used to refine those inputs",
    "start": "500720",
    "end": "503759"
  },
  {
    "text": "Getting good observability into these",
    "start": "503759",
    "end": "505440"
  },
  {
    "text": "systems is all about systematically",
    "start": "505440",
    "end": "507840"
  },
  {
    "text": "tracking the inputs and",
    "start": "507840",
    "end": "510120"
  },
  {
    "text": "outputs Let's take a look at what this",
    "start": "510120",
    "end": "512479"
  },
  {
    "text": "looks like for a standard web app By",
    "start": "512479",
    "end": "516399"
  },
  {
    "text": "instrumenting our application we can",
    "start": "516399",
    "end": "518080"
  },
  {
    "text": "capture what arguments were sent to it",
    "start": "518080",
    "end": "519839"
  },
  {
    "text": "on any given HTTP request some metadata",
    "start": "519839",
    "end": "522719"
  },
  {
    "text": "about how the app was running what was",
    "start": "522719",
    "end": "525240"
  },
  {
    "text": "returned All this lets us reason about",
    "start": "525240",
    "end": "527760"
  },
  {
    "text": "the behavior that we expect for a given",
    "start": "527760",
    "end": "530399"
  },
  {
    "text": "user endpoint or set of parameters and",
    "start": "530399",
    "end": "532959"
  },
  {
    "text": "it lets us isolate and debug the issue",
    "start": "532959",
    "end": "534720"
  },
  {
    "text": "if the actual behavior deviates from",
    "start": "534720",
    "end": "537200"
  },
  {
    "text": "that",
    "start": "537200",
    "end": "538200"
  },
  {
    "text": "expectation But what about this payment",
    "start": "538200",
    "end": "540399"
  },
  {
    "text": "service it's a third-party blackbox out",
    "start": "540399",
    "end": "543920"
  },
  {
    "text": "of my control where even if I wanted to",
    "start": "543920",
    "end": "546720"
  },
  {
    "text": "I couldn't go in and instrument it or",
    "start": "546720",
    "end": "549519"
  },
  {
    "text": "look at the logs flowing through of what",
    "start": "549519",
    "end": "552160"
  },
  {
    "text": "it's",
    "start": "552160",
    "end": "553160"
  },
  {
    "text": "doing What I do know is what requests my",
    "start": "553160",
    "end": "556800"
  },
  {
    "text": "app is sending it from where in the code",
    "start": "556800",
    "end": "559519"
  },
  {
    "text": "and on behalf of which user And I know",
    "start": "559519",
    "end": "562240"
  },
  {
    "text": "how long it took to respond and whether",
    "start": "562240",
    "end": "564000"
  },
  {
    "text": "it was successful and probably some",
    "start": "564000",
    "end": "565440"
  },
  {
    "text": "other metadata",
    "start": "565440",
    "end": "567120"
  },
  {
    "text": "By capturing all of that I can start to",
    "start": "567120",
    "end": "569360"
  },
  {
    "text": "reason about how the inputs impact the",
    "start": "569360",
    "end": "572000"
  },
  {
    "text": "outputs of my blackbox how my",
    "start": "572000",
    "end": "574480"
  },
  {
    "text": "application and my business logic",
    "start": "574480",
    "end": "576399"
  },
  {
    "text": "impacts all of that and ultimately the",
    "start": "576399",
    "end": "579440"
  },
  {
    "text": "impact on the experience the end user is",
    "start": "579440",
    "end": "582440"
  },
  {
    "text": "having Taking that and carrying that",
    "start": "582440",
    "end": "584560"
  },
  {
    "text": "into an LLM world there are a few more",
    "start": "584560",
    "end": "586720"
  },
  {
    "text": "boxes but the principles remain the same",
    "start": "586720",
    "end": "589680"
  },
  {
    "text": "One tactical note I like using traces",
    "start": "589680",
    "end": "592160"
  },
  {
    "text": "for this in order to understand the",
    "start": "592160",
    "end": "593760"
  },
  {
    "text": "relationships better between the overall",
    "start": "593760",
    "end": "595839"
  },
  {
    "text": "end-user experience and sort of the",
    "start": "595839",
    "end": "598120"
  },
  {
    "text": "subcomponents If you want to use",
    "start": "598120",
    "end": "599760"
  },
  {
    "text": "structured logs go for it You do",
    "start": "599760",
    "end": "602279"
  },
  {
    "text": "you Either way we start with the end",
    "start": "602279",
    "end": "604880"
  },
  {
    "text": "user experience the raw input and",
    "start": "604880",
    "end": "607200"
  },
  {
    "text": "eventually their the output that we're",
    "start": "607200",
    "end": "609080"
  },
  {
    "text": "returning We can also capture",
    "start": "609080",
    "end": "611480"
  },
  {
    "text": "metadata on the context that we're",
    "start": "611480",
    "end": "613680"
  },
  {
    "text": "constructing along with our prompt and",
    "start": "613680",
    "end": "615680"
  },
  {
    "text": "how long that took We can keep track of",
    "start": "615680",
    "end": "618000"
  },
  {
    "text": "the prompt itself that we ultimately",
    "start": "618000",
    "end": "620079"
  },
  {
    "text": "pass to the LLM and useful metadata",
    "start": "620079",
    "end": "623040"
  },
  {
    "text": "Capture useful metadata like token",
    "start": "623040",
    "end": "625399"
  },
  {
    "text": "usage as well as any parsing or",
    "start": "625399",
    "end": "627680"
  },
  {
    "text": "validation of LLM outputs before",
    "start": "627680",
    "end": "630079"
  },
  {
    "text": "returning to the",
    "start": "630079",
    "end": "631560"
  },
  {
    "text": "user By operating under the general",
    "start": "631560",
    "end": "634079"
  },
  {
    "text": "principle that criteria for decision-m",
    "start": "634079",
    "end": "637120"
  },
  {
    "text": "should be captured in a span you can",
    "start": "637120",
    "end": "639920"
  },
  {
    "text": "then go and isolate any of the",
    "start": "639920",
    "end": "642320"
  },
  {
    "text": "interesting behaviors based on how a",
    "start": "642320",
    "end": "644720"
  },
  {
    "text": "prompt is generated",
    "start": "644720",
    "end": "647440"
  },
  {
    "text": "And all of that ultimately lets us see",
    "start": "647440",
    "end": "652480"
  },
  {
    "text": "all of the work that we're doing up to",
    "start": "652480",
    "end": "654560"
  },
  {
    "text": "and including calling the LLM all in one",
    "start": "654560",
    "end": "657800"
  },
  {
    "text": "place Yes of course we can also get the",
    "start": "657800",
    "end": "660079"
  },
  {
    "text": "aggregate graphs like the ones on the",
    "start": "660079",
    "end": "661600"
  },
  {
    "text": "left in the middle We can look at",
    "start": "661600",
    "end": "663760"
  },
  {
    "text": "latency We can reason about user",
    "start": "663760",
    "end": "666200"
  },
  {
    "text": "satisfaction But in a workflow where",
    "start": "666200",
    "end": "668399"
  },
  {
    "text": "we're rapidly iterating on an LM",
    "start": "668399",
    "end": "670880"
  },
  {
    "text": "experience with tons of potential inputs",
    "start": "670880",
    "end": "673200"
  },
  {
    "text": "that can impact whether your application",
    "start": "673200",
    "end": "675040"
  },
  {
    "text": "looks like it's hallucinating you need",
    "start": "675040",
    "end": "677279"
  },
  {
    "text": "to be able to get from any aggregate",
    "start": "677279",
    "end": "678839"
  },
  {
    "text": "graph to inspecting a given",
    "start": "678839",
    "end": "681959"
  },
  {
    "text": "outlier This blue row at the bottom this",
    "start": "681959",
    "end": "684880"
  },
  {
    "text": "is a span where ultimately we're",
    "start": "684880",
    "end": "686399"
  },
  {
    "text": "actually calling the",
    "start": "686399",
    "end": "688200"
  },
  {
    "text": "LLM And being able to ask questions like",
    "start": "688200",
    "end": "691040"
  },
  {
    "text": "okay what actually got passed to the LLM",
    "start": "691040",
    "end": "693279"
  },
  {
    "text": "what was it responding to relies on all",
    "start": "693279",
    "end": "696399"
  },
  {
    "text": "the spans above it because that's all",
    "start": "696399",
    "end": "699040"
  },
  {
    "text": "the work that we're doing to build the",
    "start": "699040",
    "end": "701040"
  },
  {
    "text": "best prompt that we can hand to this",
    "start": "701040",
    "end": "703440"
  },
  {
    "text": "commercial",
    "start": "703440",
    "end": "704680"
  },
  {
    "text": "LLM And when there are that many things",
    "start": "704680",
    "end": "707839"
  },
  {
    "text": "that could result in an unsatisfying LLM",
    "start": "707839",
    "end": "710680"
  },
  {
    "text": "response we need all of the context we",
    "start": "710680",
    "end": "713200"
  },
  {
    "text": "can get to iterate and investigate",
    "start": "713200",
    "end": "716519"
  },
  {
    "text": "towards investigate and iterate towards",
    "start": "716519",
    "end": "718800"
  },
  {
    "text": "a better prompt",
    "start": "718800",
    "end": "721040"
  },
  {
    "text": "Now there are a number of specialized",
    "start": "721040",
    "end": "722800"
  },
  {
    "text": "tools out there that promise out of the",
    "start": "722800",
    "end": "724560"
  },
  {
    "text": "box answers for LLM",
    "start": "724560",
    "end": "727480"
  },
  {
    "text": "observability I will assert I don't want",
    "start": "727480",
    "end": "730560"
  },
  {
    "text": "a siloed or specialized tool I want",
    "start": "730560",
    "end": "733120"
  },
  {
    "text": "something especially not one that tries",
    "start": "733120",
    "end": "736560"
  },
  {
    "text": "to tell me what to care about I want my",
    "start": "736560",
    "end": "739680"
  },
  {
    "text": "tools to reflect what I care about what",
    "start": "739680",
    "end": "742000"
  },
  {
    "text": "good looks like for my applications and",
    "start": "742000",
    "end": "744480"
  },
  {
    "text": "something that aligns with the workflows",
    "start": "744480",
    "end": "746560"
  },
  {
    "text": "that my engineering teams are using for",
    "start": "746560",
    "end": "749040"
  },
  {
    "text": "the overall application",
    "start": "749040",
    "end": "752079"
  },
  {
    "text": "logic Because everything I've talked",
    "start": "752120",
    "end": "754320"
  },
  {
    "text": "about so far isn't some new skill set or",
    "start": "754320",
    "end": "758279"
  },
  {
    "text": "mindset So much of this shift towards",
    "start": "758279",
    "end": "761200"
  },
  {
    "text": "embracing observability is already",
    "start": "761200",
    "end": "763760"
  },
  {
    "text": "underway",
    "start": "763760",
    "end": "765760"
  },
  {
    "text": "In the last decade or so we've seen a",
    "start": "765760",
    "end": "767519"
  },
  {
    "text": "huge shift from developers aren't just",
    "start": "767519",
    "end": "769839"
  },
  {
    "text": "here to write a lot of code which AI",
    "start": "769839",
    "end": "772399"
  },
  {
    "text": "code assistants are certainly helping",
    "start": "772399",
    "end": "774440"
  },
  {
    "text": "with to expanding our responsibilities",
    "start": "774440",
    "end": "777920"
  },
  {
    "text": "to owning our services being joining on",
    "start": "777920",
    "end": "781040"
  },
  {
    "text": "call rotations and testing in production",
    "start": "781040",
    "end": "784200"
  },
  {
    "text": "Ultimately being responsible for what",
    "start": "784200",
    "end": "786399"
  },
  {
    "text": "our end users see as a result of our",
    "start": "786399",
    "end": "789959"
  },
  {
    "text": "code Because like it or not when",
    "start": "789959",
    "end": "792320"
  },
  {
    "text": "building for this new Gen AI world",
    "start": "792320",
    "end": "794720"
  },
  {
    "text": "nothing is predictable besides some",
    "start": "794720",
    "end": "796720"
  },
  {
    "text": "level of",
    "start": "796720",
    "end": "798360"
  },
  {
    "text": "chaos Over the years as I've gone around",
    "start": "798360",
    "end": "801120"
  },
  {
    "text": "talking about observability I've",
    "start": "801120",
    "end": "803040"
  },
  {
    "text": "communicated some version of this bottom",
    "start": "803040",
    "end": "805079"
  },
  {
    "text": "statement that software behaves in",
    "start": "805079",
    "end": "807880"
  },
  {
    "text": "unpredictable emergent ways And the",
    "start": "807880",
    "end": "810720"
  },
  {
    "text": "important part is observing your code as",
    "start": "810720",
    "end": "813360"
  },
  {
    "text": "it's running in production while users",
    "start": "813360",
    "end": "815760"
  },
  {
    "text": "are using it This was true before LLMs",
    "start": "815760",
    "end": "819440"
  },
  {
    "text": "but now as we are intentionally",
    "start": "819440",
    "end": "822000"
  },
  {
    "text": "embracing these non-deterministic emer",
    "start": "822000",
    "end": "824240"
  },
  {
    "text": "black boxes with emergent",
    "start": "824240",
    "end": "826279"
  },
  {
    "text": "behaviors this statement is that much",
    "start": "826279",
    "end": "828959"
  },
  {
    "text": "more",
    "start": "828959",
    "end": "830760"
  },
  {
    "text": "true So as we enter this age of AI I'm",
    "start": "830760",
    "end": "835120"
  },
  {
    "text": "weirdly optimistic because we have many",
    "start": "835120",
    "end": "838880"
  },
  {
    "text": "of the tools and practices at our",
    "start": "838880",
    "end": "840560"
  },
  {
    "text": "disposal to make sense of this brave new",
    "start": "840560",
    "end": "843600"
  },
  {
    "text": "world and we're just getting started I",
    "start": "843600",
    "end": "846399"
  },
  {
    "text": "for one am excited We got",
    "start": "846399",
    "end": "850120"
  },
  {
    "text": "this Thank you for your time and",
    "start": "850120",
    "end": "852079"
  },
  {
    "text": "attention today If you'd like to learn",
    "start": "852079",
    "end": "853920"
  },
  {
    "text": "more I've got an O'Reilly report and a",
    "start": "853920",
    "end": "856959"
  },
  {
    "text": "O'Reilly report and a book to recommend",
    "start": "856959",
    "end": "859120"
  },
  {
    "text": "you Uh I will be at the Honeycomb booth",
    "start": "859120",
    "end": "861360"
  },
  {
    "text": "in the Expo Hall My team and I would",
    "start": "861360",
    "end": "862959"
  },
  {
    "text": "love to hear about what you're building",
    "start": "862959",
    "end": "864399"
  },
  {
    "text": "Thank you so much Have a great CubeCon",
    "start": "864399",
    "end": "868760"
  }
]
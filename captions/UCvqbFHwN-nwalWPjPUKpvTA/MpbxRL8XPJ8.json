[
  {
    "start": "0",
    "end": "28000"
  },
  {
    "text": "hi i'm trade off north of the ohio state",
    "start": "1120",
    "end": "2800"
  },
  {
    "text": "computer center and this is secure",
    "start": "2800",
    "end": "4319"
  },
  {
    "text": "multi-user hpc jobs",
    "start": "4319",
    "end": "6480"
  },
  {
    "text": "and kubernetes with kyverno",
    "start": "6480",
    "end": "9280"
  },
  {
    "text": "um a little bit to describe our hpc",
    "start": "9280",
    "end": "11440"
  },
  {
    "text": "workload using kubernetes it's mostly",
    "start": "11440",
    "end": "13519"
  },
  {
    "text": "lightweight interactive workloads so",
    "start": "13519",
    "end": "15519"
  },
  {
    "text": "they have minimal cpu requirements",
    "start": "15519",
    "end": "17359"
  },
  {
    "text": "compared tradition compared to",
    "start": "17359",
    "end": "19119"
  },
  {
    "text": "traditional hpc",
    "start": "19119",
    "end": "20960"
  },
  {
    "text": "right now it's mostly jupiter in our",
    "start": "20960",
    "end": "22640"
  },
  {
    "text": "studio",
    "start": "22640",
    "end": "24160"
  },
  {
    "text": "this is serving up numerous classrooms",
    "start": "24160",
    "end": "27119"
  },
  {
    "text": "being used by distance",
    "start": "27119",
    "end": "28840"
  },
  {
    "start": "28000",
    "end": "65000"
  },
  {
    "text": "learning um quick overview the",
    "start": "28840",
    "end": "30800"
  },
  {
    "text": "technologies we're using so open on",
    "start": "30800",
    "end": "32640"
  },
  {
    "text": "demand is how we make the hpc jobs or",
    "start": "32640",
    "end": "35040"
  },
  {
    "text": "how we submit them",
    "start": "35040",
    "end": "36480"
  },
  {
    "text": "to kubernetes",
    "start": "36480",
    "end": "37920"
  },
  {
    "text": "it's essentially a web portal for hpc",
    "start": "37920",
    "end": "40000"
  },
  {
    "text": "access a key part is it runs the web",
    "start": "40000",
    "end": "42719"
  },
  {
    "text": "process runs as the user",
    "start": "42719",
    "end": "45120"
  },
  {
    "text": "logged in",
    "start": "45120",
    "end": "47440"
  },
  {
    "text": "to the hpc system",
    "start": "47440",
    "end": "49680"
  },
  {
    "text": "supports multiple resource managers like",
    "start": "49680",
    "end": "51039"
  },
  {
    "text": "slurm torque and kubernetes",
    "start": "51039",
    "end": "54079"
  },
  {
    "text": "then there's uh kyberno which is a",
    "start": "54079",
    "end": "56079"
  },
  {
    "text": "kubernetes policy engine",
    "start": "56079",
    "end": "58640"
  },
  {
    "text": "you deploy policies using communities",
    "start": "58640",
    "end": "61199"
  },
  {
    "text": "native resources",
    "start": "61199",
    "end": "63680"
  },
  {
    "text": "and these policies we'll go over a",
    "start": "63680",
    "end": "65360"
  },
  {
    "start": "65000",
    "end": "105000"
  },
  {
    "text": "little bit",
    "start": "65360",
    "end": "66880"
  },
  {
    "text": "some of the challenges was supporting",
    "start": "66880",
    "end": "68320"
  },
  {
    "text": "hpc jobs and kubernetes",
    "start": "68320",
    "end": "71119"
  },
  {
    "text": "we wanted to treat the jobs similar to",
    "start": "71119",
    "end": "73119"
  },
  {
    "text": "traditional hpc jobs",
    "start": "73119",
    "end": "75280"
  },
  {
    "text": "and allow on-demand apps to submit to",
    "start": "75280",
    "end": "77280"
  },
  {
    "text": "both slurm and kubernetes",
    "start": "77280",
    "end": "79520"
  },
  {
    "text": "uh because communities pods can run as",
    "start": "79520",
    "end": "81600"
  },
  {
    "text": "root",
    "start": "81600",
    "end": "82479"
  },
  {
    "text": "um that made that presented challenges",
    "start": "82479",
    "end": "84240"
  },
  {
    "text": "for shared file system access like gps",
    "start": "84240",
    "end": "86560"
  },
  {
    "text": "or nfs home directories",
    "start": "86560",
    "end": "88799"
  },
  {
    "text": "uh and we had to ensure that the users",
    "start": "88799",
    "end": "92000"
  },
  {
    "text": "processes running in the pod were all",
    "start": "92000",
    "end": "94479"
  },
  {
    "text": "being run as that user's uid and gids",
    "start": "94479",
    "end": "98479"
  },
  {
    "text": "this was a big part of this was mainly",
    "start": "98479",
    "end": "100880"
  },
  {
    "text": "to treat them uh as them for the file",
    "start": "100880",
    "end": "103360"
  },
  {
    "text": "system access",
    "start": "103360",
    "end": "105840"
  },
  {
    "start": "105000",
    "end": "152000"
  },
  {
    "text": "um some design patterns",
    "start": "105840",
    "end": "107759"
  },
  {
    "text": "uh all user pods are in a namespace with",
    "start": "107759",
    "end": "110880"
  },
  {
    "text": "user dash",
    "start": "110880",
    "end": "112399"
  },
  {
    "text": "prefix um and then their username",
    "start": "112399",
    "end": "115360"
  },
  {
    "text": "these namespaces are bootstrapped by on",
    "start": "115360",
    "end": "117200"
  },
  {
    "text": "demand when you log into ondemand",
    "start": "117200",
    "end": "119600"
  },
  {
    "text": "there's also roles and access controls",
    "start": "119600",
    "end": "121680"
  },
  {
    "text": "um given to them in their namespace to",
    "start": "121680",
    "end": "124159"
  },
  {
    "text": "allow them to do just enough to run",
    "start": "124159",
    "end": "126000"
  },
  {
    "text": "on-demand jobs",
    "start": "126000",
    "end": "127600"
  },
  {
    "text": "on the uh as both on a managed pc jobs",
    "start": "127600",
    "end": "130560"
  },
  {
    "text": "um communities itself authenticates with",
    "start": "130560",
    "end": "133200"
  },
  {
    "text": "our key cloud idp",
    "start": "133200",
    "end": "135200"
  },
  {
    "text": "and uh the oauth the oidc tokens for",
    "start": "135200",
    "end": "138560"
  },
  {
    "text": "on-demand are allowed to use the",
    "start": "138560",
    "end": "140160"
  },
  {
    "text": "kubernetes thanks to an oauth2 audience",
    "start": "140160",
    "end": "143200"
  },
  {
    "text": "uh we deployed a tool we wrote called",
    "start": "143200",
    "end": "145040"
  },
  {
    "text": "kldap config map so this maps ldap data",
    "start": "145040",
    "end": "148239"
  },
  {
    "text": "into config maps that can be used by",
    "start": "148239",
    "end": "150080"
  },
  {
    "text": "kyverno",
    "start": "150080",
    "end": "152720"
  },
  {
    "start": "152000",
    "end": "183000"
  },
  {
    "text": "so policy solutions with kyberno we have",
    "start": "152959",
    "end": "156160"
  },
  {
    "text": "policies to ensure a uid and gid and",
    "start": "156160",
    "end": "158560"
  },
  {
    "text": "supplemental groups of a pod match a",
    "start": "158560",
    "end": "160800"
  },
  {
    "text": "user's ldap record we have policies to",
    "start": "160800",
    "end": "163440"
  },
  {
    "text": "restrict host host path access",
    "start": "163440",
    "end": "166319"
  },
  {
    "text": "amount locations to paths we want them",
    "start": "166319",
    "end": "169040"
  },
  {
    "text": "to have access to such as nanotest home",
    "start": "169040",
    "end": "170640"
  },
  {
    "text": "directories gpfs",
    "start": "170640",
    "end": "172720"
  },
  {
    "text": "and some files for slurm",
    "start": "172720",
    "end": "175360"
  },
  {
    "text": "we disallow all forms of privilege",
    "start": "175360",
    "end": "177200"
  },
  {
    "text": "escalation",
    "start": "177200",
    "end": "178879"
  },
  {
    "text": "we also enforce max resource requests",
    "start": "178879",
    "end": "181599"
  },
  {
    "text": "and max runtime of pods",
    "start": "181599",
    "end": "184400"
  },
  {
    "start": "183000",
    "end": "209000"
  },
  {
    "text": "um here's an example of how we're",
    "start": "184400",
    "end": "186319"
  },
  {
    "text": "selecting resources in the policies so",
    "start": "186319",
    "end": "188800"
  },
  {
    "text": "you can see uh",
    "start": "188800",
    "end": "190480"
  },
  {
    "text": "over here we have the user prefix user",
    "start": "190480",
    "end": "192640"
  },
  {
    "text": "dash prefix which made it really easy to",
    "start": "192640",
    "end": "194480"
  },
  {
    "text": "match all the user pods by namespace",
    "start": "194480",
    "end": "197840"
  },
  {
    "text": "one thing we learned very quickly was",
    "start": "197840",
    "end": "199840"
  },
  {
    "text": "you can only validate",
    "start": "199840",
    "end": "201519"
  },
  {
    "text": "on create and update when you're dealing",
    "start": "201519",
    "end": "203200"
  },
  {
    "text": "with ldap data because if the ldap data",
    "start": "203200",
    "end": "205120"
  },
  {
    "text": "changes um while the pod is running it",
    "start": "205120",
    "end": "207680"
  },
  {
    "text": "might become impossible to delete",
    "start": "207680",
    "end": "210879"
  },
  {
    "start": "209000",
    "end": "218000"
  },
  {
    "text": "here's an example of getting ldap data",
    "start": "210879",
    "end": "213200"
  },
  {
    "text": "into the context for the policy so here",
    "start": "213200",
    "end": "215280"
  },
  {
    "text": "we're getting the uid mapping",
    "start": "215280",
    "end": "218799"
  },
  {
    "start": "218000",
    "end": "236000"
  },
  {
    "text": "um here's a validate on the run as user",
    "start": "218799",
    "end": "222480"
  },
  {
    "text": "so we're using the uid to ensure that",
    "start": "222480",
    "end": "224400"
  },
  {
    "text": "the",
    "start": "224400",
    "end": "225200"
  },
  {
    "text": "um we're doing a lookup so here's an",
    "start": "225200",
    "end": "227280"
  },
  {
    "text": "example what the data looks like so it's",
    "start": "227280",
    "end": "228799"
  },
  {
    "text": "user dash my username with my uid and",
    "start": "228799",
    "end": "231920"
  },
  {
    "text": "we're ensuring that that uid is what's",
    "start": "231920",
    "end": "233599"
  },
  {
    "text": "being used for running this user",
    "start": "233599",
    "end": "237040"
  },
  {
    "start": "236000",
    "end": "252000"
  },
  {
    "text": "um we also validate supplemental groups",
    "start": "237120",
    "end": "240080"
  },
  {
    "text": "which is very important for file system",
    "start": "240080",
    "end": "241840"
  },
  {
    "text": "access so here's an example what the",
    "start": "241840",
    "end": "243680"
  },
  {
    "text": "data looks like it's a json string",
    "start": "243680",
    "end": "246239"
  },
  {
    "text": "of an array",
    "start": "246239",
    "end": "248080"
  },
  {
    "text": "and we're using a denying condition",
    "start": "248080",
    "end": "252439"
  },
  {
    "start": "252000",
    "end": "279000"
  },
  {
    "text": "here's some additional policies uh this",
    "start": "253840",
    "end": "255840"
  },
  {
    "text": "one sorry",
    "start": "255840",
    "end": "257519"
  },
  {
    "text": "this one is to restrict the host path",
    "start": "257519",
    "end": "259759"
  },
  {
    "text": "they can access so we allow them to",
    "start": "259759",
    "end": "261280"
  },
  {
    "text": "access uh slam configs munch socket for",
    "start": "261280",
    "end": "263440"
  },
  {
    "text": "slurm and then user uh home directories",
    "start": "263440",
    "end": "266560"
  },
  {
    "text": "and",
    "start": "266560",
    "end": "267600"
  },
  {
    "text": "gpfs",
    "start": "267600",
    "end": "269759"
  },
  {
    "text": "most of the other policies we use um",
    "start": "269759",
    "end": "271600"
  },
  {
    "text": "come from upstream comparing the",
    "start": "271600",
    "end": "272880"
  },
  {
    "text": "policies helm chart uh these are mostly",
    "start": "272880",
    "end": "274880"
  },
  {
    "text": "around security",
    "start": "274880",
    "end": "276240"
  },
  {
    "text": "um",
    "start": "276240",
    "end": "277040"
  },
  {
    "text": "some of the ones i showed here are",
    "start": "277040",
    "end": "278560"
  },
  {
    "text": "custom ones",
    "start": "278560",
    "end": "280080"
  },
  {
    "start": "279000",
    "end": "300000"
  },
  {
    "text": "and here are some of the resources so",
    "start": "280080",
    "end": "282000"
  },
  {
    "text": "upstream policies for caverno",
    "start": "282000",
    "end": "284240"
  },
  {
    "text": "um the osd policies that we deploy with",
    "start": "284240",
    "end": "286880"
  },
  {
    "text": "helm and then a link to the 88 k8 ldap",
    "start": "286880",
    "end": "289919"
  },
  {
    "text": "config map which is uh how we get the",
    "start": "289919",
    "end": "292240"
  },
  {
    "text": "ldap data available to kyberno",
    "start": "292240",
    "end": "297240"
  },
  {
    "text": "[Music]",
    "start": "297580",
    "end": "301220"
  }
]
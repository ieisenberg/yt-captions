[
  {
    "text": "hi everyone and welcome platforms platforms platforms we've been",
    "start": "199",
    "end": "7640"
  },
  {
    "text": "hearing and talking about platforms the past few years so much and along the way",
    "start": "7640",
    "end": "13000"
  },
  {
    "text": "we learned one thing or two about platforms first of all we want to focus on why we're building platforms right so",
    "start": "13000",
    "end": "18560"
  },
  {
    "text": "we want to build platforms to enable product teams to deliver softer better faster and safer so we learned that we",
    "start": "18560",
    "end": "26160"
  },
  {
    "text": "want to establish a platform as a product mindset we want want to definitely talk with the end users",
    "start": "26160",
    "end": "32480"
  },
  {
    "text": "understand better their needs their requirements and then expose a platform API design an API which can fulfill",
    "start": "32480",
    "end": "38719"
  },
  {
    "text": "those requests from the end users of the platform then internally in the back end we can do whatever makes sense for us to",
    "start": "38719",
    "end": "45039"
  },
  {
    "text": "implement the platform implementing different capabilities to support those functionality but recently we've been",
    "start": "45039",
    "end": "50879"
  },
  {
    "text": "getting more and more requests about new types of application and we got to hear",
    "start": "50879",
    "end": "56719"
  },
  {
    "text": "a lot of different buzzword generative AI large language models embeddings rug",
    "start": "56719",
    "end": "62920"
  },
  {
    "text": "Vector stores what's that all about so before we even start extending our platform to support this use cases I",
    "start": "62920",
    "end": "68680"
  },
  {
    "text": "really would like to know more about this domain and we have Lisa here she's an expert in generative AI so can you",
    "start": "68680",
    "end": "74880"
  },
  {
    "text": "tell us a bit more about that yes soas um so generative AI is the latest uh buz",
    "start": "74880",
    "end": "82000"
  },
  {
    "text": "word um artificial intelligence has moved from this initial machine learning phase where it could categorize or",
    "start": "82000",
    "end": "89159"
  },
  {
    "text": "analyze data to a point where it can really generate new things itself text images you name it um so for this um",
    "start": "89159",
    "end": "98280"
  },
  {
    "text": "session we're going to be talking about large language models we want to integrate these into our programs as",
    "start": "98280",
    "end": "103759"
  },
  {
    "text": "developers large language models there's a couple of categories in them so quickly a language model is a completion",
    "start": "103759",
    "end": "109600"
  },
  {
    "text": "model if you send in I like it will probably say chocolate or something um",
    "start": "109600",
    "end": "115119"
  },
  {
    "text": "there's chat models they are instructed and trained to chat with you so if you say I like it's going to say oh what is",
    "start": "115119",
    "end": "121039"
  },
  {
    "text": "it that you like can I help you with something and then we have a bit of a different Beast there uh embedding",
    "start": "121039",
    "end": "126880"
  },
  {
    "text": "models they turn your text into a numerical Vector that encodes the meaning uh which gets very interesting",
    "start": "126880",
    "end": "133800"
  },
  {
    "text": "because you can use it for example to group texts uh or fragments of text that have similar meanings by just looking",
    "start": "133800",
    "end": "139680"
  },
  {
    "text": "which vectors are closest together um in a large language model",
    "start": "139680",
    "end": "145200"
  },
  {
    "text": "you send in text which we call a prompt so you probably have heard of prompt engineering which is just a um hard word",
    "start": "145200",
    "end": "151800"
  },
  {
    "text": "to say you tweak what you send in so you can tweak what comes out and all large",
    "start": "151800",
    "end": "157360"
  },
  {
    "text": "language models have a context window so they limit what you can send in from 200 characters to 20 Pages for",
    "start": "157360",
    "end": "164760"
  },
  {
    "text": "example um and then a next step we would want to do with a large language model",
    "start": "164760",
    "end": "169840"
  },
  {
    "text": "if we don't want to go train it or finding it ourself we can still make it learn from our documents for example our",
    "start": "169840",
    "end": "176440"
  },
  {
    "text": "company documents that it didn't know about because they were not in the original training data um we can use",
    "start": "176440",
    "end": "183159"
  },
  {
    "text": "these embedding models and these embedding stores where we store these numerical meaning vectors to actually go",
    "start": "183159",
    "end": "189519"
  },
  {
    "text": "find the parts of our documents that are relevant to the questions we ask um",
    "start": "189519",
    "end": "194680"
  },
  {
    "text": "that's called retrieval augmented generation or rag again a hard word to say chat with your documents um you see",
    "start": "194680",
    "end": "202080"
  },
  {
    "text": "here the schema of how it goes you split your documents in Parts you store the segments in a embedding store or a",
    "start": "202080",
    "end": "208920"
  },
  {
    "text": "vector store together with their numerical vectors that represent the meaning then in a second step when your",
    "start": "208920",
    "end": "215400"
  },
  {
    "text": "user interacts with um with your large language model you go find the relevant",
    "start": "215400",
    "end": "221439"
  },
  {
    "text": "segments by also embedding the question and finding the pieces that are probably",
    "start": "221439",
    "end": "226640"
  },
  {
    "text": "most relevant meaning wise and then instead of just sending your question to your Lang large language model you're",
    "start": "226640",
    "end": "232280"
  },
  {
    "text": "going to send hey this was the question original question and then here are parts of the documents that might be",
    "start": "232280",
    "end": "238159"
  },
  {
    "text": "relevant in answering um so I hope that the platforms that",
    "start": "238159",
    "end": "244840"
  },
  {
    "text": "Thomas is going to build will support these basic building blocks of AI powered applications I quickly present",
    "start": "244840",
    "end": "251599"
  },
  {
    "text": "myself I'm Lisa Ras I'm an AI transition specialist at open TI and also a",
    "start": "251599",
    "end": "256639"
  },
  {
    "text": "collaborator of the open source framework Lang chain for J I'm also a Committee Member of the cloud native",
    "start": "256639",
    "end": "261880"
  },
  {
    "text": "hacks that are going on in parallel here um and I love everything Ai and open",
    "start": "261880",
    "end": "267320"
  },
  {
    "text": "source yeah and I'm Thomas Vitali I work work at systematic a software company from Denmark I'm a software engineer and",
    "start": "267320",
    "end": "273720"
  },
  {
    "text": "cncf Ambassador I'm really passionate about anything Java and clown native I combine these passions of mine and wrote",
    "start": "273720",
    "end": "280000"
  },
  {
    "text": "a book recently clown native spring in action and in general I'm a big supporter of Open Source Technologies and try to contribute as much as I can",
    "start": "280000",
    "end": "286560"
  },
  {
    "text": "across both the clown native ecosystem and the Java space so I want to make sure that I understood correctly the",
    "start": "286560",
    "end": "293120"
  },
  {
    "text": "problem so we're talking about applications that are powered by large language models and these applications",
    "start": "293120",
    "end": "298840"
  },
  {
    "text": "are actually mented using regular programming languages so we're talking about Java goang python but then we have",
    "start": "298840",
    "end": "304560"
  },
  {
    "text": "two new types of Integrations that you're looking for uh supporting a platform one is towards a model provider",
    "start": "304560",
    "end": "311759"
  },
  {
    "text": "and it could be a local model providers like AMA which is great to run large language models locally on your local",
    "start": "311759",
    "end": "318080"
  },
  {
    "text": "development environment or for on premises deployments there could be uh cloud services for example mistal AI or",
    "start": "318080",
    "end": "324800"
  },
  {
    "text": "open Ai and then we have a second type of integration towards these databases that really store data but they store",
    "start": "324800",
    "end": "331000"
  },
  {
    "text": "the meaning of data as numerical vectors and we call them Vector store so it could be weate as an open source example",
    "start": "331000",
    "end": "338160"
  },
  {
    "text": "right correct all right so I think we have all the ingredients to start designing a new golden path in our",
    "start": "338160",
    "end": "343720"
  },
  {
    "text": "platform to support these new types of application and let's start from how uh uh developers will interact with this",
    "start": "343720",
    "end": "350039"
  },
  {
    "text": "new golden path we going to have a portal where we can extend the amount of",
    "start": "350039",
    "end": "356960"
  },
  {
    "text": "golden pass that we have with a new one I have created already a template uh for a new Java application working uh",
    "start": "356960",
    "end": "364199"
  },
  {
    "text": "integrated with large language models and a vector database so you can choose",
    "start": "364199",
    "end": "369720"
  },
  {
    "text": "a new uh you can start a new project from here uh let's call it my Hub because I'm really a creative person",
    "start": "369720",
    "end": "377720"
  },
  {
    "text": "and so that will be owned by L's team and then we can provide information",
    "start": "377720",
    "end": "384039"
  },
  {
    "text": "I'll just use my GitHub repository for now as an example and I'll give it the name my app super creative",
    "start": "384039",
    "end": "390440"
  },
  {
    "text": "and then let's define some parameters this is specific to uh the Java application it's called my",
    "start": "390440",
    "end": "396759"
  },
  {
    "text": "app so we can customize this uh onboarding procedure here the interesting part you can choose a model",
    "start": "396759",
    "end": "402759"
  },
  {
    "text": "provider for example or Lama if you're working for a uh local uh model on",
    "start": "402759",
    "end": "407840"
  },
  {
    "text": "premises or open AI or M AI or whatever other service let's say or Lama and then",
    "start": "407840",
    "end": "412880"
  },
  {
    "text": "pick a vector store and here in the platform then we can provide a list of whatever we support for now we'll use",
    "start": "412880",
    "end": "419120"
  },
  {
    "text": "GitHub for the pipeline and create a repository so now you can go and check out the repository but there's an",
    "start": "419120",
    "end": "425960"
  },
  {
    "text": "important question we need to ask ourselves when we Implement a platform and it's all about uh The Continuous",
    "start": "425960",
    "end": "433479"
  },
  {
    "text": "development Loop so once a developer check out the git repository are we forcing developers to run kubernetes to",
    "start": "433479",
    "end": "440919"
  },
  {
    "text": "have a kubernetes environment to run the application the answer is actually it depends we talk with the development",
    "start": "440919",
    "end": "447440"
  },
  {
    "text": "teams and find out a strategy that works works best for them in this case we want to meet developers where they are and",
    "start": "447440",
    "end": "453560"
  },
  {
    "text": "developers across different teams are using for example Java laging Lis example or maybe python or nodejs and",
    "start": "453560",
    "end": "461080"
  },
  {
    "text": "they already have a nice developer experience flow from the Frameworks that they're using so we want to keep that so",
    "start": "461080",
    "end": "467759"
  },
  {
    "text": "to uh not introduce additional cognitive load to developers in parallel though we have to solve the problem of how do we",
    "start": "467759",
    "end": "474039"
  },
  {
    "text": "provide the these new Integrations that the applications need how do we provide a model provider and a vector database",
    "start": "474039",
    "end": "481360"
  },
  {
    "text": "if this is running locally on a developer computer and we are not providing services from a kubernetes",
    "start": "481360",
    "end": "486840"
  },
  {
    "text": "cluster and a great solution to that is using a tool which is really developer friendly it's called test containers",
    "start": "486840",
    "end": "493280"
  },
  {
    "text": "with test containers you can have all your different Integrations for example you can run all Lama as a local model",
    "start": "493280",
    "end": "500280"
  },
  {
    "text": "provider you can run weate as a vector database you can developers can use it both at development time when working",
    "start": "500280",
    "end": "506720"
  },
  {
    "text": "locally but also to run integration test because testing is also important we want to test against the real thing and",
    "start": "506720",
    "end": "512599"
  },
  {
    "text": "test container is allowed to do that it integrates with uh the application life cycle and its supports uh Java net Ruby",
    "start": "512599",
    "end": "520039"
  },
  {
    "text": "goang so it's not Java specific so in the context of the platform we also want to uh provide a polyglot solution so we",
    "start": "520039",
    "end": "527600"
  },
  {
    "text": "are seeing an example in Java but all the tools that we're going to implement inside the platform will actually uh be",
    "start": "527600",
    "end": "534120"
  },
  {
    "text": "flexible enough to support different languages so maybe uh we can test it out I'm curious to get some feedback from",
    "start": "534120",
    "end": "540440"
  },
  {
    "text": "you uh and if that works right so um this is what came out",
    "start": "540440",
    "end": "547920"
  },
  {
    "text": "of your platform just like that so let's have a look um I lost the side part but",
    "start": "547920",
    "end": "555959"
  },
  {
    "text": "it's a great application that let me try to run it is normally functional right",
    "start": "555959",
    "end": "562279"
  },
  {
    "text": "like that and I see I have a bean here with a chat language model an embedding model and an embedding store so this is",
    "start": "562279",
    "end": "569519"
  },
  {
    "text": "setup for me that's super convenient uh what else do I find here a document loader so I know if I want to interact",
    "start": "569519",
    "end": "575640"
  },
  {
    "text": "with documents where to store them and how to use them uh this ingester phase is there the content retriever is there",
    "start": "575640",
    "end": "582680"
  },
  {
    "text": "with some parameters that I might want to tweak for my application that's great that I don't have to set all of that up",
    "start": "582680",
    "end": "588480"
  },
  {
    "text": "I see a chat memory and then I AI service here a chat agent um which in L",
    "start": "588480",
    "end": "594680"
  },
  {
    "text": "forj is the Workhorse of our application and it gets to use the chat Lang model",
    "start": "594680",
    "end": "599920"
  },
  {
    "text": "the content retriever to talk with the documents and it has this memory already there so that's really a great start for",
    "start": "599920",
    "end": "605600"
  },
  {
    "text": "me to to work from I have a look at this um jet agent AI service here so imagine",
    "start": "605600",
    "end": "613360"
  },
  {
    "text": "I want to make something else I can now directly jump into the business logic and I want here not a chat agent but I",
    "start": "613360",
    "end": "620240"
  },
  {
    "text": "would want a a composer agent because we're talking about orchestration here",
    "start": "620240",
    "end": "625600"
  },
  {
    "text": "and we're both musicians so let's get some music in here um the nice thing in Lang chain forj is",
    "start": "625600",
    "end": "632680"
  },
  {
    "text": "these um interfaces these AI Services you can just declare what you want to happen there uh you don't have to write",
    "start": "632680",
    "end": "640279"
  },
  {
    "text": "much code for that um ah wait",
    "start": "640279",
    "end": "645600"
  },
  {
    "text": "good okay this is not my usual computer or ID so I want a method called uh",
    "start": "645600",
    "end": "654160"
  },
  {
    "text": "give composition advice also the thing is",
    "start": "654160",
    "end": "659920"
  },
  {
    "text": "llms are very forgiving when there's typos um and then if I wanted to know",
    "start": "659920",
    "end": "665959"
  },
  {
    "text": "what to do I can just make an annotation um at a system message here",
    "start": "665959",
    "end": "671800"
  },
  {
    "text": "which is the instruction for our llm and we want to say uh give composition",
    "start": "671800",
    "end": "678320"
  },
  {
    "text": "advice for scoring um uh the following movie scene",
    "start": "678320",
    "end": "684399"
  },
  {
    "text": "and then the movie scene itself is going to be what we sent in",
    "start": "684399",
    "end": "689959"
  },
  {
    "text": "um that's going to be the prompt here and so uh that's that's really all we have to do uh and then we can just build",
    "start": "689959",
    "end": "696160"
  },
  {
    "text": "it like this AI service build from our composer agent and it will know what to do um maybe we want to give it a couple",
    "start": "696160",
    "end": "703200"
  },
  {
    "text": "of tools because that's super cool you can tell llms that they can use programmatical tools something I Define",
    "start": "703200",
    "end": "708880"
  },
  {
    "text": "here that runs in Java accesses my database or whatever I want to um to happen if I describe it well my my uh",
    "start": "708880",
    "end": "716600"
  },
  {
    "text": "llm will know that it has this and we'll call it when when it's needed and work with with the results so um let's make a",
    "start": "716600",
    "end": "724040"
  },
  {
    "text": "tool um I'm also very creative here uh",
    "start": "724040",
    "end": "729240"
  },
  {
    "text": "let's see if I can get these curly brackets out yes yeah the magic of the",
    "start": "729240",
    "end": "734320"
  },
  {
    "text": "Italian keyboard there so um we want a method that um",
    "start": "734320",
    "end": "741839"
  },
  {
    "text": "gives the virtual instrument code because we will want to be using",
    "start": "741839",
    "end": "747000"
  },
  {
    "text": "Thomas's virtual instruments not any instrument but his um that takes the",
    "start": "747000",
    "end": "753320"
  },
  {
    "text": "normal instrument name as an input um and then again curly braces yes",
    "start": "753320",
    "end": "760279"
  },
  {
    "text": "uh in this case we'll just for the demo return one to three but you can do any any Java code here and then to let the",
    "start": "760279",
    "end": "767560"
  },
  {
    "text": "model know it has this tool we're going to make a tool annotation saying um",
    "start": "767560",
    "end": "774880"
  },
  {
    "text": "gives tomas's virtual in instrument code for",
    "start": "774880",
    "end": "782240"
  },
  {
    "text": "normal instrument name jet language model will know what to do with this anything we understand they usually also",
    "start": "782240",
    "end": "789000"
  },
  {
    "text": "understand and then um here we will add tools and say uh we buil this tools and",
    "start": "789000",
    "end": "798360"
  },
  {
    "text": "voila that's it so it knows it can use um this this instrument Retriever and it will also do so when it's appropriate so",
    "start": "798360",
    "end": "805760"
  },
  {
    "text": "imagine I'm ready with my application here can we not take it into production yes but first i'm interesting because",
    "start": "805760",
    "end": "812440"
  },
  {
    "text": "I'm interested in knowing more about how these type of applications work like we talked about Java but I think that it",
    "start": "812440",
    "end": "819160"
  },
  {
    "text": "might be nice to know how we can support other teams working with different Technologies um and in general what are",
    "start": "819160",
    "end": "825600"
  },
  {
    "text": "this AI regestration framework if you can tell us a bit more so we can support different languages in the platform I'm",
    "start": "825600",
    "end": "830959"
  },
  {
    "text": "sure other teams uh will be really happy we would also be happy yes so um with",
    "start": "830959",
    "end": "836120"
  },
  {
    "text": "this boom of generative AI uh there's also a boom in people that want to build applications around these models maybe",
    "start": "836120",
    "end": "843480"
  },
  {
    "text": "have multiple models in there that interact with each other and everything U so there has also been a boom of AI",
    "start": "843480",
    "end": "849600"
  },
  {
    "text": "orchestration Frameworks so the most famous one the first one was Lang chain which was made by the python folks of",
    "start": "849600",
    "end": "855600"
  },
  {
    "text": "course because machine learning and training uh data engineering happens mostly in Python but they also now have",
    "start": "855600",
    "end": "862079"
  },
  {
    "text": "a version for go and for JavaScript then there's for example semantic kernel for Microsoft supporting javascript. net and",
    "start": "862079",
    "end": "868800"
  },
  {
    "text": "Java and then L chain for J that I'm a collaborator of myself it's a very popular one for Java at the moment and",
    "start": "868800",
    "end": "875160"
  },
  {
    "text": "it's just great of course um so they're all having similar building blocks so",
    "start": "875160",
    "end": "881199"
  },
  {
    "text": "let me dive into the building blocks for L chain for J just to show you uh you see here these uh language models image",
    "start": "881199",
    "end": "888079"
  },
  {
    "text": "models more types of models will be supported in the future um the tools",
    "start": "888079",
    "end": "893120"
  },
  {
    "text": "which we just saw they're there too there's the memory because models are stateless and if you add a memory then",
    "start": "893120",
    "end": "899040"
  },
  {
    "text": "then they become stateful uh output parsers are an amazing amazing feature there because um the llm always returns",
    "start": "899040",
    "end": "906600"
  },
  {
    "text": "text or sometimes Json if you ask it to uh what Lang chain for J does for you is",
    "start": "906600",
    "end": "912040"
  },
  {
    "text": "pars the output to real Java objects so you're just calling your AI service and you get a list back or a plain old Java",
    "start": "912040",
    "end": "920120"
  },
  {
    "text": "object whatever you want and you can just continue from there you don't have to parse any strings um at the right you",
    "start": "920120",
    "end": "925920"
  },
  {
    "text": "see all the rag components to chat with your documents and then usually all the AI",
    "start": "925920",
    "end": "931000"
  },
  {
    "text": "orchestration Frameworks have a layer on top to abstract away even more like AI",
    "start": "931000",
    "end": "936120"
  },
  {
    "text": "service we just saw or chains in like chain for J all right so basically from",
    "start": "936120",
    "end": "941800"
  },
  {
    "text": "the platform we can actually support different programming languages and then we know that for each programming language the development team would use",
    "start": "941800",
    "end": "947519"
  },
  {
    "text": "one of these orchestration Frameworks and then in the platform St we need to provide the Integrations to the actual model provider and Vector database so",
    "start": "947519",
    "end": "955160"
  },
  {
    "text": "let's try to go to production because we need to complete this golden path so for now we talked about the development",
    "start": "955160",
    "end": "960880"
  },
  {
    "text": "workflow uh so the first thing we want to do is containerize the uh uh the application and we could use a doger",
    "start": "960880",
    "end": "967120"
  },
  {
    "text": "file we could even make it part of the template uh bootstrapped from backstage but using a dogger file would not be",
    "start": "967120",
    "end": "973279"
  },
  {
    "text": "that much of a deal not for the platform team because you lose control over all the security and performance",
    "start": "973279",
    "end": "979040"
  },
  {
    "text": "optimizations and for the developers means additional complexity additional responsibilities so instead for this",
    "start": "979040",
    "end": "984920"
  },
  {
    "text": "example we chose Cloud native buildpacks where as a platform team we can centralize the logic to build production",
    "start": "984920",
    "end": "991319"
  },
  {
    "text": "ready images without the need for a Docker file and it works across different languages so in this case we",
    "start": "991319",
    "end": "996399"
  },
  {
    "text": "are going to use it with Java but it works with other types of languages and then with one command you can get the",
    "start": "996399",
    "end": "1001639"
  },
  {
    "text": "production R image you can use the CLI that comes with the project you can have it part of the pipeline or if you're",
    "start": "1001639",
    "end": "1007440"
  },
  {
    "text": "working with kubernetes there's also a kubernetes native implementation it's called kpac and in KAC you get a custom",
    "start": "1007440",
    "end": "1013680"
  },
  {
    "text": "resource is called image and uh you point to a git repository every time there's a change it automatically Builds",
    "start": "1013680",
    "end": "1019199"
  },
  {
    "text": "an image it also signs it with cosign it generates a salsa testation so you have",
    "start": "1019199",
    "end": "1025600"
  },
  {
    "text": "a quite secure artifact uh also pushed to the container registry and then we",
    "start": "1025600",
    "end": "1030959"
  },
  {
    "text": "need to configure the workload for deployments and at this point there are many different Alternatives but the key",
    "start": "1030959",
    "end": "1037480"
  },
  {
    "text": "part here that I want to focus on is I don't want to expose the internal details and internal tools to developers",
    "start": "1037480",
    "end": "1043360"
  },
  {
    "text": "or for example Helm customiz or U instead we are defining a developer friendly API",
    "start": "1043360",
    "end": "1049400"
  },
  {
    "text": "in this case I'm using crossplane uh to define a workload API which only contains the information that the",
    "start": "1049400",
    "end": "1055480"
  },
  {
    "text": "developer needs to provide and this is just a few things that the platform cannot infer by itself for example",
    "start": "1055480",
    "end": "1061320"
  },
  {
    "text": "what's the name of the application or what are the uh Integrations in this case we have open Ai and we8 as a vector",
    "start": "1061320",
    "end": "1067600"
  },
  {
    "text": "database and then internally we can implement it using all our favorite tools uh in this case I decided to go",
    "start": "1067600",
    "end": "1073640"
  },
  {
    "text": "with a crossplane composition to implement the API and use K native to achieve serverless deployment",
    "start": "1073640",
    "end": "1079400"
  },
  {
    "text": "using uh defining some application conventions I'd like the platform to be application aware instead of having",
    "start": "1079400",
    "end": "1085559"
  },
  {
    "text": "applications that are platform aware so there are some conventions across different languages on how to run",
    "start": "1085559",
    "end": "1091000"
  },
  {
    "text": "application in Productions I would like to codify all those conventions in the platform so we are removing even more uh",
    "start": "1091000",
    "end": "1098280"
  },
  {
    "text": "cognitive load from the development teams and then we are using service binding this is an API from the kubernetes project to binds in an",
    "start": "1098280",
    "end": "1105480"
  },
  {
    "text": "autonomous and automatic way uh applications to external services but we have a problem here the platform as it",
    "start": "1105480",
    "end": "1112240"
  },
  {
    "text": "is now doesn't have those Services doesn't have a model provider doesn't have a VOR database I need to build that",
    "start": "1112240",
    "end": "1119200"
  },
  {
    "text": "and uh for the platform we we are using caral so each caral is a cncf Sandbox",
    "start": "1119200",
    "end": "1124440"
  },
  {
    "text": "project each capability in the platform is bundled as a Carval package and uh",
    "start": "1124440",
    "end": "1129720"
  },
  {
    "text": "delivered as an oci artifact so what I did is uh because the platform engineer",
    "start": "1129720",
    "end": "1135960"
  },
  {
    "text": "experience also counts it's not just about the developer experience uh I made a template to build a new caral package",
    "start": "1135960",
    "end": "1142520"
  },
  {
    "text": "in a nice way so I can uh create now a new repository for this new package I",
    "start": "1142520",
    "end": "1147679"
  },
  {
    "text": "have already uh pulled out the repository so what I can do is using the CLI that comes with Carval K control",
    "start": "1147679",
    "end": "1155480"
  },
  {
    "text": "package in it and then I Define the name of the package in this case is weate uh",
    "start": "1155480",
    "end": "1161400"
  },
  {
    "text": "what we what is the foundation of this package we typically don't start from scratch so I can point to an existing",
    "start": "1161400",
    "end": "1166440"
  },
  {
    "text": "Helm chart or an existing uh G release with some kubernetes manifest or some local files if it's a first party",
    "start": "1166440",
    "end": "1173360"
  },
  {
    "text": "product uh and then I'll confirm all the versions and now I have my package at",
    "start": "1173360",
    "end": "1178919"
  },
  {
    "text": "this point I can configure it any way I want using different tools I can use Helm I can use ytt I can use Q I can use",
    "start": "1178919",
    "end": "1185559"
  },
  {
    "text": "soaps to resolve secrets and once I'm done with it I can say k control package",
    "start": "1185559",
    "end": "1191200"
  },
  {
    "text": "release of course I would do this in a pipeline and I give it a name it's a container uh artifact so it will go on",
    "start": "1191200",
    "end": "1199159"
  },
  {
    "text": "my container registry on GitHub and then now it's delivered and I can use it directly from my platform thanks to the",
    "start": "1199159",
    "end": "1206120"
  },
  {
    "text": "uh package management functionality from caral which is kubernetes native what it",
    "start": "1206120",
    "end": "1211280"
  },
  {
    "text": "means is that I get a custom resource called package where I have a reference",
    "start": "1211280",
    "end": "1217440"
  },
  {
    "text": "to my package and I can configure how I'm going to customize this in this case I'm using Helm YT and K build in",
    "start": "1217440",
    "end": "1225240"
  },
  {
    "text": "sequence all right I think we have everything in place for the application",
    "start": "1225240",
    "end": "1230640"
  },
  {
    "text": "uh to be in production so maybe we could give it a try what do you think all",
    "start": "1230640",
    "end": "1236039"
  },
  {
    "text": "right okay this is really amazing um you're making developers lazy but we love that um good um here is our final",
    "start": "1236039",
    "end": "1244440"
  },
  {
    "text": "application it's a composer assistant we picked four videos of which we will",
    "start": "1244440",
    "end": "1250280"
  },
  {
    "text": "orchestrate one at the end so the large language model is going to tell us how to do it we will execute this um so when",
    "start": "1250280",
    "end": "1258640"
  },
  {
    "text": "we click on compose we will get the advice here uh so I wish to ask you",
    "start": "1258640",
    "end": "1263760"
  },
  {
    "text": "which one you would like so we have a romantic scene that we could",
    "start": "1263760",
    "end": "1269440"
  },
  {
    "text": "orchestrate getting ready for the composition the demog gods please",
    "start": "1276720",
    "end": "1281760"
  },
  {
    "text": "yeah all right so we have a romantic scene uh we have a Stoll in a gloomy",
    "start": "1281760",
    "end": "1287520"
  },
  {
    "text": "Forest for who likes that there's an alien attack over the",
    "start": "1287520",
    "end": "1293320"
  },
  {
    "text": "city and then there's some sad melancholic video and we can make the",
    "start": "1293320",
    "end": "1298919"
  },
  {
    "text": "music for any of those who would vote for a romantic scene I thought we were in the city of",
    "start": "1298919",
    "end": "1306400"
  },
  {
    "text": "love thank you for the two people who would go for a mysterious stroll through the forest ah some gloomy",
    "start": "1306400",
    "end": "1314320"
  },
  {
    "text": "gloomy developers here all right who would go for the alien attack H surprise okay I I think if it would",
    "start": "1314320",
    "end": "1321799"
  },
  {
    "text": "really happen we would have to talk again if it's so much fun okay anybody that would like to set be Jo okay so um",
    "start": "1321799",
    "end": "1329960"
  },
  {
    "text": "we will go for the action movie because that was the majority vote but anybody that choose sad can come to me after the",
    "start": "1329960",
    "end": "1337480"
  },
  {
    "text": "after the session and I will make you sad that's not a problem all right um",
    "start": "1337480",
    "end": "1343320"
  },
  {
    "text": "but Thomas yeah but first maybe let's talk more about the application I'm happy to show you the architecture yes",
    "start": "1343320",
    "end": "1349240"
  },
  {
    "text": "I'm really interested in that going on there I will need too much help okay yes",
    "start": "1349240",
    "end": "1356360"
  },
  {
    "text": "there we go um all right so the way this application is built up we have this UI when we click compose it will send the",
    "start": "1356360",
    "end": "1363360"
  },
  {
    "text": "video description to our composer assistant application who will first",
    "start": "1363360",
    "end": "1368400"
  },
  {
    "text": "fetch in our rate embedding store uh any instrument descriptions that are similar",
    "start": "1368400",
    "end": "1373760"
  },
  {
    "text": "to our video description for example uh action impeding scare very heroic will",
    "start": "1373760",
    "end": "1380279"
  },
  {
    "text": "probably be words that are going to be searched for or like meaning clusters uh",
    "start": "1380279",
    "end": "1385799"
  },
  {
    "text": "once it has these relevant segments it's going to send to our llm uh please give us composing instructions we want to use",
    "start": "1385799",
    "end": "1392960"
  },
  {
    "text": "Thomas's virtual instruments and we have a singer um here is the video you have",
    "start": "1392960",
    "end": "1398000"
  },
  {
    "text": "to score this this is the scene description and here are parts of instrument description that you might",
    "start": "1398000",
    "end": "1403279"
  },
  {
    "text": "want to use and then the model itself will see that oh if I need Thomas's virtual inst codes I don't have that in",
    "start": "1403279",
    "end": "1410240"
  },
  {
    "text": "my training data I'm going to call the tool that is there so for every instrument it is supposed to call the",
    "start": "1410240",
    "end": "1416919"
  },
  {
    "text": "tool that will fetch the virtual instrument code from the database and then it will take everything and give us",
    "start": "1416919",
    "end": "1422799"
  },
  {
    "text": "a clean answer back in the application um I did not click yet so I",
    "start": "1422799",
    "end": "1429360"
  },
  {
    "text": "will do that right now we choose action so now it's generating a strategy",
    "start": "1429360",
    "end": "1434799"
  },
  {
    "text": "uh while we wait for this hopefully it comes I should have prepared some drum roll you know we're talking about",
    "start": "1434799",
    "end": "1440640"
  },
  {
    "text": "this um I wonder I mean everybody is now completely enthusiastic because",
    "start": "1440640",
    "end": "1446120"
  },
  {
    "text": "composing advice it's for sure it's everybody has been waiting for this right so if now the whole room here",
    "start": "1446120",
    "end": "1451720"
  },
  {
    "text": "wants to go on our application right away can we visualize the load can yes because we can see it fails and of",
    "start": "1451720",
    "end": "1458200"
  },
  {
    "text": "course we cannot go in production without having observability and the good news is we have open Telemetry configured uh everywhere in the platform",
    "start": "1458200",
    "end": "1465039"
  },
  {
    "text": "and on top of that we also added some specific conventions on top of open Telemetry to get information from the",
    "start": "1465039",
    "end": "1470320"
  },
  {
    "text": "models and interaction with the model provider uh we used our own custom ones but there is a working group currently",
    "start": "1470320",
    "end": "1477240"
  },
  {
    "text": "uh defining a standard set of conventions in open Telemetry also to represent data around large language",
    "start": "1477240",
    "end": "1482919"
  },
  {
    "text": "models so I'm really looking forward to that so let's see what happens we can also uh give this another try and in the",
    "start": "1482919",
    "end": "1489000"
  },
  {
    "text": "meantime we want to see why it failed so we can check the composer",
    "start": "1489000",
    "end": "1494360"
  },
  {
    "text": "assistant and we have some specific spans for the orchestration framework",
    "start": "1494360",
    "end": "1499559"
  },
  {
    "text": "used in here all collected from open Telemetry so we can see uh the result so the",
    "start": "1499559",
    "end": "1507159"
  },
  {
    "text": "second one uh succeeded the first one failed so for the first one we can see uh at which point it failed so the model",
    "start": "1507159",
    "end": "1514159"
  },
  {
    "text": "is call or the application is calling the model multiple times because it needs to integrate with the tools so we have to debug what's happening in that",
    "start": "1514159",
    "end": "1521799"
  },
  {
    "text": "workflow that chain of execution uh but if we look at the one that succeeded then we can also get additional",
    "start": "1521799",
    "end": "1528440"
  },
  {
    "text": "information about uh The Prompt so you get all the prompt here if you'd like to",
    "start": "1528440",
    "end": "1533640"
  },
  {
    "text": "tune it a bit and do some prompt design you can see the Finish reason and also all the tokens so we can see at the end",
    "start": "1533640",
    "end": "1540039"
  },
  {
    "text": "how much we're spending for this demo right that's great that's perfect uh yeah that's amazing that's all I wanted",
    "start": "1540039",
    "end": "1546399"
  },
  {
    "text": "to know that looks good so we got a recommendation here let's have a look so",
    "start": "1546399",
    "end": "1552399"
  },
  {
    "text": "we want to score an action scene we got three uh cord progression I think they look fine so",
    "start": "1552399",
    "end": "1559080"
  },
  {
    "text": "maybe we can go with the first one what do you think looks good to me yes so",
    "start": "1559080",
    "end": "1565000"
  },
  {
    "text": "let's try it out and see what",
    "start": "1565000",
    "end": "1569760"
  },
  {
    "text": "happens so oh yeah you're preparing your audio editor",
    "start": "1572559",
    "end": "1579799"
  },
  {
    "text": "yes let Let's do let's start with something uh with something strong all",
    "start": "1579799",
    "end": "1587240"
  },
  {
    "text": "right do we have",
    "start": "1587240",
    "end": "1593440"
  },
  {
    "text": "sound all",
    "start": "1601799",
    "end": "1605039"
  },
  {
    "text": "[Applause]",
    "start": "1609090",
    "end": "1612150"
  },
  {
    "text": "right okay we got some percussions and now I'll cheat and just",
    "start": "1617240",
    "end": "1623840"
  },
  {
    "text": "Loop through it because that's fun right uh all right so should we add some",
    "start": "1623840",
    "end": "1631520"
  },
  {
    "text": "strings perhaps we got the percussions we got",
    "start": "1631520",
    "end": "1638720"
  },
  {
    "text": "some strings it says use Al Alban strings and some uh drones so we'll follow the recommendation from the",
    "start": "1638720",
    "end": "1645960"
  },
  {
    "text": "model no not that",
    "start": "1645960",
    "end": "1650158"
  },
  {
    "text": "wrong one all [Applause]",
    "start": "1652760",
    "end": "1658680"
  },
  {
    "text": "[Music]",
    "start": "1658680",
    "end": "1662920"
  },
  {
    "text": "[Music]",
    "start": "1668760",
    "end": "1676529"
  },
  {
    "text": "right [Music]",
    "start": "1677120",
    "end": "1688960"
  },
  {
    "text": "all right so how's it going so far alien attack should we add uh",
    "start": "1688960",
    "end": "1696480"
  },
  {
    "text": "some more some more streams yes the ARA yeah",
    "start": "1696480",
    "end": "1702640"
  },
  {
    "text": "that's weird right that's not really action with the ARP but we can do something bit better uh let's",
    "start": "1702640",
    "end": "1710760"
  },
  {
    "text": "see uh down here",
    "start": "1710760",
    "end": "1716440"
  },
  {
    "text": "[Music]",
    "start": "1717650",
    "end": "1721909"
  },
  {
    "text": "yes all right we're getting there so how you feeling with the voice we are almost",
    "start": "1725399",
    "end": "1731159"
  },
  {
    "text": "there should add some cello I think he's suggesting a cello so we could add some cello and then layer up the voice yeah",
    "start": "1731159",
    "end": "1739039"
  },
  {
    "text": "let's add some cello all",
    "start": "1739039",
    "end": "1744840"
  },
  {
    "text": "right let's do it here and like",
    "start": "1744960",
    "end": "1751480"
  },
  {
    "text": "this no I don't want that go away like that",
    "start": "1752440",
    "end": "1758360"
  },
  {
    "text": "[Music]",
    "start": "1758360",
    "end": "1762330"
  },
  {
    "text": "yes [Music]",
    "start": "1767039",
    "end": "1774760"
  },
  {
    "text": "yeah should should we give you the try yes",
    "start": "1774760",
    "end": "1780039"
  },
  {
    "text": "okay drum",
    "start": "1780039",
    "end": "1783360"
  },
  {
    "text": "rules oh",
    "start": "1796519",
    "end": "1800039"
  },
  {
    "text": "[Applause] oh all",
    "start": "1814650",
    "end": "1821519"
  },
  {
    "text": "right I think that worked out where I think we survived this it was a risky",
    "start": "1821519",
    "end": "1827640"
  },
  {
    "text": "one what an amazing voice okay so to recap we got the AI to help us generate this",
    "start": "1827640",
    "end": "1835480"
  },
  {
    "text": "composition and it even gives some interesting result but we could probably",
    "start": "1835480",
    "end": "1840720"
  },
  {
    "text": "improve it right because the the model is has not been trained specifically with this purpose uh so we integrated",
    "start": "1840720",
    "end": "1846600"
  },
  {
    "text": "some of our knowledge around the feelings that each instruments deliver right and some of the virtual",
    "start": "1846600",
    "end": "1852799"
  },
  {
    "text": "instruments and yes we got the observability I I",
    "start": "1852799",
    "end": "1858120"
  },
  {
    "text": "think we can uh move on and just go very quickly across the",
    "start": "1858120",
    "end": "1866240"
  },
  {
    "text": "journey we've done so far the first thing is we talked with the development team that's the most important thing",
    "start": "1866240",
    "end": "1873000"
  },
  {
    "text": "first we hear what's the problem that they have and of course generative AI is super hyped right now but we want to",
    "start": "1873000",
    "end": "1879320"
  },
  {
    "text": "know exactly what what the needs are so after understanding better the needs we Define the project uh boost trapping",
    "start": "1879320",
    "end": "1885360"
  },
  {
    "text": "phase using backstage uh the uh bootstrap also builds the local project",
    "start": "1885360",
    "end": "1890760"
  },
  {
    "text": "using test containers for the local developer experience and next it will also set up a pipeline in this case",
    "start": "1890760",
    "end": "1897120"
  },
  {
    "text": "GitHub actions but you can use uh whatever pipeline engine you prefer and then the other important thing is we're",
    "start": "1897120",
    "end": "1902679"
  },
  {
    "text": "not exposing an internal kubernetes tool or knowledge to developers we are using crossplane uh compositions in order to",
    "start": "1902679",
    "end": "1909120"
  },
  {
    "text": "define a developer friendly API and then we keep all the complexity inside the",
    "start": "1909120",
    "end": "1915039"
  },
  {
    "text": "implementation the development workflow again is based on test containers we got the build pipeline in particular using",
    "start": "1915039",
    "end": "1920919"
  },
  {
    "text": "buildpacks to help containerize all these applications uh the deployment",
    "start": "1920919",
    "end": "1926080"
  },
  {
    "text": "configuration was based on crossplane and the actual implementation was uh",
    "start": "1926080",
    "end": "1931559"
  },
  {
    "text": "using K native we want to scale this so when people are relying on generative Ai",
    "start": "1931559",
    "end": "1937679"
  },
  {
    "text": "and large language models we also need to talk about scaling because there will be many requests some requests will be",
    "start": "1937679",
    "end": "1943799"
  },
  {
    "text": "slow because as you saw it took some seconds in order to process all the Quest there's a bit of back and forth",
    "start": "1943799",
    "end": "1949240"
  },
  {
    "text": "between the model and the application because we are integrating Knowledge from database and tools uh we bind",
    "start": "1949240",
    "end": "1954919"
  },
  {
    "text": "services using this API called service binding from the kubernetes project so",
    "start": "1954919",
    "end": "1960000"
  },
  {
    "text": "uh as part of the golden path we also automatically bind the application to the list of services that the developer",
    "start": "1960000",
    "end": "1967200"
  },
  {
    "text": "mentions while bootstrapping the project we got observability that's really important you saw things can fail and",
    "start": "1967200",
    "end": "1973240"
  },
  {
    "text": "when you add uh large language models they can fail even more so we need visibility into into the tokens into the",
    "start": "1973240",
    "end": "1978919"
  },
  {
    "text": "cost into the prompt so we can do some prompt design and finally of course we want to go to production because if you",
    "start": "1978919",
    "end": "1985600"
  },
  {
    "text": "don't go get to production in a a fast and secure way our application is useless right it's in production that it",
    "start": "1985600",
    "end": "1992279"
  },
  {
    "text": "delivers value and important thing and I like to know if you also enjoy that part",
    "start": "1992279",
    "end": "1998559"
  },
  {
    "text": "is developers are only involved in these first two steps boostrapping the project and then working on the actual business",
    "start": "1998559",
    "end": "2004840"
  },
  {
    "text": "logic and the platform abstracts everything else away yeah I mean as a developer as a developer this is this is",
    "start": "2004840",
    "end": "2011159"
  },
  {
    "text": "the dream so I didn't have to do anything for my project setup except for choosing what I actually want and where",
    "start": "2011159",
    "end": "2017080"
  },
  {
    "text": "I want this project to to live and then all the rest making sure there's",
    "start": "2017080",
    "end": "2022679"
  },
  {
    "text": "observability going to deployment I didn't have to do anything like the wv8 set up nothing so uh the moment your",
    "start": "2022679",
    "end": "2029639"
  },
  {
    "text": "platform is out I'm definitely going to use it and I'm never going to waste let's say like I waste maybe two hours",
    "start": "2029639",
    "end": "2035639"
  },
  {
    "text": "on the whole setup just to even start coding properly and then my business logic is done in another hour so this",
    "start": "2035639",
    "end": "2041880"
  },
  {
    "text": "Cuts all this time this is just really amazing okay that's great to hear thank",
    "start": "2041880",
    "end": "2047079"
  },
  {
    "text": "you yeah so we did some music together I mean we are in Paris you know so music",
    "start": "2047079",
    "end": "2052560"
  },
  {
    "text": "it was a good fit uh but you can uh reach out to us afterwards um and in",
    "start": "2052560",
    "end": "2057638"
  },
  {
    "text": "particular L is really an expert in general dbii so if you have questions around use cases and how it can help",
    "start": "2057639",
    "end": "2064560"
  },
  {
    "text": "with uh you know improving the society uh she's the person to talk to too so reach out afterwards yes okay thank you very much",
    "start": "2064560",
    "end": "2072320"
  },
  {
    "text": "for your",
    "start": "2072320",
    "end": "2074679"
  },
  {
    "text": "attention yeah yeah we'll be around for questions uh if you need to so just come",
    "start": "2080240",
    "end": "2086118"
  },
  {
    "text": "to us also I'm giving another Presentation tomorrow if you'd like to join with Mauricio uh we're going to",
    "start": "2086119",
    "end": "2091158"
  },
  {
    "text": "talk uh about unlocking new platform experiences with open interfaces so we'll dive even deeper into how we can",
    "start": "2091159",
    "end": "2097320"
  },
  {
    "text": "improve the developer experience across the distributed systems and integrate even more services in a transparent way",
    "start": "2097320",
    "end": "2102480"
  },
  {
    "text": "for developers thank you",
    "start": "2102480",
    "end": "2108680"
  }
]
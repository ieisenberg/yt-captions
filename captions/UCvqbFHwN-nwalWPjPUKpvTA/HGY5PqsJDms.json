[
  {
    "text": "uh so hey everyone we are um here from",
    "start": "719",
    "end": "3919"
  },
  {
    "text": "data dog uh we're going to talk about",
    "start": "3919",
    "end": "5560"
  },
  {
    "text": "our journey connecting millions of",
    "start": "5560",
    "end": "7520"
  },
  {
    "text": "containers with",
    "start": "7520",
    "end": "9639"
  },
  {
    "text": "GPC um so just a few words about our",
    "start": "9639",
    "end": "12160"
  },
  {
    "text": "company we are multicloud monitoring and",
    "start": "12160",
    "end": "14200"
  },
  {
    "text": "security products for those that don't",
    "start": "14200",
    "end": "16039"
  },
  {
    "text": "know us we offer metric logs and traces",
    "start": "16039",
    "end": "18400"
  },
  {
    "text": "to our users uh this talk is about is is",
    "start": "18400",
    "end": "21600"
  },
  {
    "text": "not going to be about how to monitor",
    "start": "21600",
    "end": "23320"
  },
  {
    "text": "grpc using data dog it's going to be",
    "start": "23320",
    "end": "26039"
  },
  {
    "text": "about how we use data dog to power the",
    "start": "26039",
    "end": "30000"
  },
  {
    "text": "data do",
    "start": "30000",
    "end": "32040"
  },
  {
    "text": "product um so we're actually a fairly",
    "start": "32040",
    "end": "35320"
  },
  {
    "text": "large service we have tens of thousands",
    "start": "35320",
    "end": "37760"
  },
  {
    "text": "of customers we store trillions of data",
    "start": "37760",
    "end": "40680"
  },
  {
    "text": "points per day so that gives you an idea",
    "start": "40680",
    "end": "43559"
  },
  {
    "text": "of the kind of challenges that we can",
    "start": "43559",
    "end": "45039"
  },
  {
    "text": "have on the back end and this puts",
    "start": "45039",
    "end": "46960"
  },
  {
    "text": "things a bit into",
    "start": "46960",
    "end": "49719"
  },
  {
    "text": "perspective um so why do we use GPC so",
    "start": "49719",
    "end": "53160"
  },
  {
    "text": "originally we started using it uh fairly",
    "start": "53160",
    "end": "55559"
  },
  {
    "text": "early on around 2016 uh and the main",
    "start": "55559",
    "end": "58320"
  },
  {
    "text": "reason to use it was uh client and",
    "start": "58320",
    "end": "60960"
  },
  {
    "text": "server code generation really based on",
    "start": "60960",
    "end": "63000"
  },
  {
    "text": "protobuf it makes it really easy to",
    "start": "63000",
    "end": "64799"
  },
  {
    "text": "basically write applications that",
    "start": "64799",
    "end": "66479"
  },
  {
    "text": "communicate over the network um and it",
    "start": "66479",
    "end": "68680"
  },
  {
    "text": "reported the language we",
    "start": "68680",
    "end": "70280"
  },
  {
    "text": "needed so the fact that it embeds",
    "start": "70280",
    "end": "72920"
  },
  {
    "text": "Advanced client side load balancing was",
    "start": "72920",
    "end": "75040"
  },
  {
    "text": "more of a convenient Discovery than",
    "start": "75040",
    "end": "77320"
  },
  {
    "text": "really a deliberate design choice but as",
    "start": "77320",
    "end": "80159"
  },
  {
    "text": "the data dog backend become larger and",
    "start": "80159",
    "end": "82240"
  },
  {
    "text": "larger those features uh actually prove",
    "start": "82240",
    "end": "85040"
  },
  {
    "text": "to be something that is really truly",
    "start": "85040",
    "end": "86560"
  },
  {
    "text": "useful to",
    "start": "86560",
    "end": "88400"
  },
  {
    "text": "us um okay so this is the typical setup",
    "start": "88400",
    "end": "91240"
  },
  {
    "text": "of a grpc server uh service with clients",
    "start": "91240",
    "end": "94240"
  },
  {
    "text": "at the top and servers at the",
    "start": "94240",
    "end": "96280"
  },
  {
    "text": "bottom most Services run on many many",
    "start": "96280",
    "end": "98759"
  },
  {
    "text": "replicas some Services have can have a",
    "start": "98759",
    "end": "101079"
  },
  {
    "text": "lot of replicas like hundreds of them",
    "start": "101079",
    "end": "104079"
  },
  {
    "text": "and we use drpc builtin client side load",
    "start": "104079",
    "end": "107360"
  },
  {
    "text": "balancing to spread the load across the",
    "start": "107360",
    "end": "109799"
  },
  {
    "text": "server instances we usually do not rely",
    "start": "109799",
    "end": "112280"
  },
  {
    "text": "on external load balancer in between",
    "start": "112280",
    "end": "114079"
  },
  {
    "text": "services to actually do do that work",
    "start": "114079",
    "end": "116799"
  },
  {
    "text": "this helps us save on costs and",
    "start": "116799",
    "end": "118560"
  },
  {
    "text": "operations so typically service owners",
    "start": "118560",
    "end": "121360"
  },
  {
    "text": "are like this approach uh we use DNS for",
    "start": "121360",
    "end": "124880"
  },
  {
    "text": "service Discovery we have no Advanced",
    "start": "124880",
    "end": "126960"
  },
  {
    "text": "kind of control playe features although",
    "start": "126960",
    "end": "129160"
  },
  {
    "text": "um that might change in the future uh so",
    "start": "129160",
    "end": "131840"
  },
  {
    "text": "while this setup has generally been",
    "start": "131840",
    "end": "133160"
  },
  {
    "text": "working really well for us um it has",
    "start": "133160",
    "end": "136599"
  },
  {
    "text": "also come come with like some challenges",
    "start": "136599",
    "end": "139040"
  },
  {
    "text": "and actually using grpc properly in this",
    "start": "139040",
    "end": "141200"
  },
  {
    "text": "setup has been an ongoing Learning",
    "start": "141200",
    "end": "144480"
  },
  {
    "text": "Journey so uh at first users at data doc",
    "start": "144480",
    "end": "147800"
  },
  {
    "text": "were mostly on their own when using in",
    "start": "147800",
    "end": "149920"
  },
  {
    "text": "JPC and soon enough they bumped into a",
    "start": "149920",
    "end": "152840"
  },
  {
    "text": "set of some common problems so the way",
    "start": "152840",
    "end": "155879"
  },
  {
    "text": "we helped our developers to deal with",
    "start": "155879",
    "end": "158080"
  },
  {
    "text": "those set of problems is by providing in",
    "start": "158080",
    "end": "160360"
  },
  {
    "text": "JPC rers and uh here on the slide you",
    "start": "160360",
    "end": "163560"
  },
  {
    "text": "can see examples of some of the issues",
    "start": "163560",
    "end": "166239"
  },
  {
    "text": "we try to deal inside of those rers and",
    "start": "166239",
    "end": "169120"
  },
  {
    "text": "we are going to discuss some of those in",
    "start": "169120",
    "end": "171599"
  },
  {
    "text": "more details later during the",
    "start": "171599",
    "end": "173480"
  },
  {
    "text": "presentation so when working on our uh",
    "start": "173480",
    "end": "176040"
  },
  {
    "text": "JPC rappers we try to be opiniated so we",
    "start": "176040",
    "end": "179840"
  },
  {
    "text": "provide a set of reasonable defaults",
    "start": "179840",
    "end": "181640"
  },
  {
    "text": "that works for everybody uh and if we",
    "start": "181640",
    "end": "184519"
  },
  {
    "text": "need to expose some features uh we",
    "start": "184519",
    "end": "186959"
  },
  {
    "text": "usually expose them as a uh set of",
    "start": "186959",
    "end": "190200"
  },
  {
    "text": "Boolean Flags try to minimize the ux and",
    "start": "190200",
    "end": "194120"
  },
  {
    "text": "uh make it easier for uh our users to",
    "start": "194120",
    "end": "196519"
  },
  {
    "text": "consume it so this approach has a nice",
    "start": "196519",
    "end": "199840"
  },
  {
    "text": "property so we also can transparently",
    "start": "199840",
    "end": "201959"
  },
  {
    "text": "deal with some of the uh problems even",
    "start": "201959",
    "end": "204519"
  },
  {
    "text": "without user involvement by uh adding",
    "start": "204519",
    "end": "208080"
  },
  {
    "text": "new default behaviors uh to our",
    "start": "208080",
    "end": "212920"
  },
  {
    "text": "raer okay so the first thing that we uh",
    "start": "213480",
    "end": "217040"
  },
  {
    "text": "that we take care of uh in our rapper",
    "start": "217040",
    "end": "219920"
  },
  {
    "text": "libraries is failure detection um so one",
    "start": "219920",
    "end": "223239"
  },
  {
    "text": "scenario that is particularly common in",
    "start": "223239",
    "end": "225080"
  },
  {
    "text": "a in a setup like data dog is silent",
    "start": "225080",
    "end": "227760"
  },
  {
    "text": "connection drops uh so that typically",
    "start": "227760",
    "end": "230360"
  },
  {
    "text": "happens when a host is shut down from",
    "start": "230360",
    "end": "232280"
  },
  {
    "text": "the network um and so how does drpc",
    "start": "232280",
    "end": "235560"
  },
  {
    "text": "actually handle this",
    "start": "235560",
    "end": "237040"
  },
  {
    "text": "scenario um so by default it doesn't",
    "start": "237040",
    "end": "239760"
  },
  {
    "text": "really do anything special um it",
    "start": "239760",
    "end": "242400"
  },
  {
    "text": "actually relies on the Linux scel to",
    "start": "242400",
    "end": "245360"
  },
  {
    "text": "detect that a link has failed um and so",
    "start": "245360",
    "end": "249040"
  },
  {
    "text": "in a typical setup of like if you",
    "start": "249040",
    "end": "252319"
  },
  {
    "text": "install any distribution of Linux it",
    "start": "252319",
    "end": "255000"
  },
  {
    "text": "will and use a default it's going to",
    "start": "255000",
    "end": "257280"
  },
  {
    "text": "take a whole 15 minutes in order for the",
    "start": "257280",
    "end": "259199"
  },
  {
    "text": "kernel to detect that link is bad so",
    "start": "259199",
    "end": "261680"
  },
  {
    "text": "this is the amount of time you're going",
    "start": "261680",
    "end": "263000"
  },
  {
    "text": "to get errors uh from uh for grpc Server",
    "start": "263000",
    "end": "267960"
  },
  {
    "text": "um that has a failed link",
    "start": "267960",
    "end": "270479"
  },
  {
    "text": "um so can we do better than that well",
    "start": "270479",
    "end": "273000"
  },
  {
    "text": "GPC actually has the feature that you",
    "start": "273000",
    "end": "275199"
  },
  {
    "text": "need to turn on explicitly in order to",
    "start": "275199",
    "end": "277000"
  },
  {
    "text": "make that much better this feature is",
    "start": "277000",
    "end": "278840"
  },
  {
    "text": "called keep alive so we set that in our",
    "start": "278840",
    "end": "281320"
  },
  {
    "text": "rapper libraries uh and we set it by",
    "start": "281320",
    "end": "283560"
  },
  {
    "text": "default we basically think that in our",
    "start": "283560",
    "end": "285680"
  },
  {
    "text": "setup nobody should everybody should",
    "start": "285680",
    "end": "288199"
  },
  {
    "text": "have keep lives en a so that's an",
    "start": "288199",
    "end": "290160"
  },
  {
    "text": "example of one of the things that we",
    "start": "290160",
    "end": "291840"
  },
  {
    "text": "that we set up uh so this has basically",
    "start": "291840",
    "end": "295440"
  },
  {
    "text": "completely eliminated this pattern that",
    "start": "295440",
    "end": "297160"
  },
  {
    "text": "used to be really common actually um and",
    "start": "297160",
    "end": "299600"
  },
  {
    "text": "and as we felt like we had a a good",
    "start": "299600",
    "end": "302080"
  },
  {
    "text": "grasp on this issue of failing nodes uh",
    "start": "302080",
    "end": "304560"
  },
  {
    "text": "we were able to bring failure detection",
    "start": "304560",
    "end": "306880"
  },
  {
    "text": "to the next level so uh as you've seen",
    "start": "306880",
    "end": "310440"
  },
  {
    "text": "uh setting keep lives allows us to",
    "start": "310440",
    "end": "312639"
  },
  {
    "text": "efficiently deal with network problems",
    "start": "312639",
    "end": "315320"
  },
  {
    "text": "but what if network is fine but an",
    "start": "315320",
    "end": "318120"
  },
  {
    "text": "instance of uh application server is",
    "start": "318120",
    "end": "320560"
  },
  {
    "text": "failing due to some other reason like",
    "start": "320560",
    "end": "322759"
  },
  {
    "text": "for example it cannot connect to",
    "start": "322759",
    "end": "324199"
  },
  {
    "text": "database it got misconfigured or some",
    "start": "324199",
    "end": "327039"
  },
  {
    "text": "other issue is happening and JPC will",
    "start": "327039",
    "end": "329759"
  },
  {
    "text": "happily keep sending request to this",
    "start": "329759",
    "end": "331600"
  },
  {
    "text": "failing server which will uh increase",
    "start": "331600",
    "end": "334479"
  },
  {
    "text": "the error rate for all clients that are",
    "start": "334479",
    "end": "336720"
  },
  {
    "text": "connected to it uh here on the screen",
    "start": "336720",
    "end": "339360"
  },
  {
    "text": "you can see a a diagram for a synthetic",
    "start": "339360",
    "end": "342319"
  },
  {
    "text": "test that we run in our environment when",
    "start": "342319",
    "end": "344520"
  },
  {
    "text": "our when one server is constantly",
    "start": "344520",
    "end": "347039"
  },
  {
    "text": "misbehave and uh the way we deal with",
    "start": "347039",
    "end": "349759"
  },
  {
    "text": "this uh problem is by enabling anually",
    "start": "349759",
    "end": "352960"
  },
  {
    "text": "added JPC feature which is called",
    "start": "352960",
    "end": "354880"
  },
  {
    "text": "outlier detection so outlier detection",
    "start": "354880",
    "end": "358400"
  },
  {
    "text": "actually uh works like this so it allows",
    "start": "358400",
    "end": "361160"
  },
  {
    "text": "ejecting uh misbehaving server by uh",
    "start": "361160",
    "end": "364680"
  },
  {
    "text": "comparing error rate for this server",
    "start": "364680",
    "end": "366880"
  },
  {
    "text": "with the mean value and it actually has",
    "start": "366880",
    "end": "369599"
  },
  {
    "text": "a kind of complex uh configuration",
    "start": "369599",
    "end": "372440"
  },
  {
    "text": "parameters allowing to tune the exection",
    "start": "372440",
    "end": "375680"
  },
  {
    "text": "procedure uh but uh during some",
    "start": "375680",
    "end": "379039"
  },
  {
    "text": "experiments we came up with a set of",
    "start": "379039",
    "end": "380960"
  },
  {
    "text": "reasonable defaults that uh works",
    "start": "380960",
    "end": "384520"
  },
  {
    "text": "for uh most of our users and uh we",
    "start": "384520",
    "end": "390000"
  },
  {
    "text": "configure them by default in our wrapper",
    "start": "390000",
    "end": "392280"
  },
  {
    "text": "libraries and as you can see on the",
    "start": "392280",
    "end": "394240"
  },
  {
    "text": "bottom diagram by enabling outlier",
    "start": "394240",
    "end": "396280"
  },
  {
    "text": "detection the impact of misbehaving",
    "start": "396280",
    "end": "398759"
  },
  {
    "text": "server can be completely uh",
    "start": "398759",
    "end": "402720"
  },
  {
    "text": "eliminated so uh now when we talked",
    "start": "402720",
    "end": "405319"
  },
  {
    "text": "about failure uh detection uh let's uh",
    "start": "405319",
    "end": "409160"
  },
  {
    "text": "discuss some other uh common problems",
    "start": "409160",
    "end": "411880"
  },
  {
    "text": "that our grpc users uh faced uh in uh",
    "start": "411880",
    "end": "416199"
  },
  {
    "text": "our environment so uh here in this",
    "start": "416199",
    "end": "419440"
  },
  {
    "text": "screen you can see a diagram of uh uh",
    "start": "419440",
    "end": "424039"
  },
  {
    "text": "CPU utilizations that is generated for",
    "start": "424039",
    "end": "427479"
  },
  {
    "text": "some of our grpc server and at first it",
    "start": "427479",
    "end": "430160"
  },
  {
    "text": "might look surprising why some servers",
    "start": "430160",
    "end": "432240"
  },
  {
    "text": "will have a lot more load than the",
    "start": "432240",
    "end": "435720"
  },
  {
    "text": "others but uh the answer why this is",
    "start": "435720",
    "end": "438599"
  },
  {
    "text": "happening by default is pretty simple so",
    "start": "438599",
    "end": "441879"
  },
  {
    "text": "uh the uh problem here is that by",
    "start": "441879",
    "end": "445160"
  },
  {
    "text": "default JPC is using pick first as",
    "start": "445160",
    "end": "447400"
  },
  {
    "text": "default load balancer and pi first was",
    "start": "447400",
    "end": "449919"
  },
  {
    "text": "work like this so basically every client",
    "start": "449919",
    "end": "452599"
  },
  {
    "text": "picks a single uh server out of the list",
    "start": "452599",
    "end": "456000"
  },
  {
    "text": "of all available servers and then send",
    "start": "456000",
    "end": "458560"
  },
  {
    "text": "requests to uh This Server and uh",
    "start": "458560",
    "end": "462720"
  },
  {
    "text": "statistically the probability that the",
    "start": "462720",
    "end": "464879"
  },
  {
    "text": "load on the server will be evenly",
    "start": "464879",
    "end": "467080"
  },
  {
    "text": "distributed is very",
    "start": "467080",
    "end": "468840"
  },
  {
    "text": "low so uh what we did to deal with this",
    "start": "468840",
    "end": "472360"
  },
  {
    "text": "problem is change the default in our",
    "start": "472360",
    "end": "474800"
  },
  {
    "text": "environment so uh now we use round drin",
    "start": "474800",
    "end": "479080"
  },
  {
    "text": "as the default load balancer and Round",
    "start": "479080",
    "end": "481639"
  },
  {
    "text": "Robin works very differently so every",
    "start": "481639",
    "end": "484280"
  },
  {
    "text": "client now round robin request between",
    "start": "484280",
    "end": "486840"
  },
  {
    "text": "all avalable servers and now every",
    "start": "486840",
    "end": "489960"
  },
  {
    "text": "server received exactly the same amount",
    "start": "489960",
    "end": "492319"
  },
  {
    "text": "of request so you can see the impact of",
    "start": "492319",
    "end": "495000"
  },
  {
    "text": "this uh change uh on the screen and uh",
    "start": "495000",
    "end": "499360"
  },
  {
    "text": "now requests are perfectly balanced but",
    "start": "499360",
    "end": "502240"
  },
  {
    "text": "in practice we want to have even uh",
    "start": "502240",
    "end": "506440"
  },
  {
    "text": "Balan CPU utilization and uh not a just",
    "start": "506440",
    "end": "509960"
  },
  {
    "text": "number of request so this is still not",
    "start": "509960",
    "end": "513200"
  },
  {
    "text": "enough okay and so one one thing to have",
    "start": "513200",
    "end": "515760"
  },
  {
    "text": "in mind here is that service owners",
    "start": "515760",
    "end": "518080"
  },
  {
    "text": "typically um want to actually tune their",
    "start": "518080",
    "end": "522000"
  },
  {
    "text": "autoscalers that Tru is the number of",
    "start": "522000",
    "end": "524120"
  },
  {
    "text": "PODS according to very",
    "start": "524120",
    "end": "527760"
  },
  {
    "text": "like vastly the vast majority of of",
    "start": "527760",
    "end": "531600"
  },
  {
    "text": "service owners actually use CPU based",
    "start": "531600",
    "end": "533920"
  },
  {
    "text": "autoscaling and they would add instances",
    "start": "533920",
    "end": "536399"
  },
  {
    "text": "when the CPU the average CPU or um well",
    "start": "536399",
    "end": "540920"
  },
  {
    "text": "when the CPU of their servers is",
    "start": "540920",
    "end": "542680"
  },
  {
    "text": "actually going over a threshold for",
    "start": "542680",
    "end": "545399"
  },
  {
    "text": "sustained period of time and actually um",
    "start": "545399",
    "end": "548880"
  },
  {
    "text": "the question is when you have many",
    "start": "548880",
    "end": "550279"
  },
  {
    "text": "servers which number do you take uh",
    "start": "550279",
    "end": "552399"
  },
  {
    "text": "typically you actually like one obvious",
    "start": "552399",
    "end": "555560"
  },
  {
    "text": "answer could be to take the average but",
    "start": "555560",
    "end": "557640"
  },
  {
    "text": "that means that if some some servers are",
    "start": "557640",
    "end": "559680"
  },
  {
    "text": "having a high CPU usage and others have",
    "start": "559680",
    "end": "561959"
  },
  {
    "text": "low CPU usage uh then like some of them",
    "start": "561959",
    "end": "565120"
  },
  {
    "text": "will still get overloaded um before the",
    "start": "565120",
    "end": "567600"
  },
  {
    "text": "auto scaler kicks in so people typically",
    "start": "567600",
    "end": "569680"
  },
  {
    "text": "have to provision autoscaler for the",
    "start": "569680",
    "end": "571720"
  },
  {
    "text": "instances that are the worst",
    "start": "571720",
    "end": "573440"
  },
  {
    "text": "performing um so here is a",
    "start": "573440",
    "end": "577360"
  },
  {
    "text": "um here are the graphs of usage for one",
    "start": "577360",
    "end": "581160"
  },
  {
    "text": "of our Production Services as you can",
    "start": "581160",
    "end": "583040"
  },
  {
    "text": "see on the top because we use round",
    "start": "583040",
    "end": "584360"
  },
  {
    "text": "robin the requests are perfectly",
    "start": "584360",
    "end": "586440"
  },
  {
    "text": "balanced but on the bottom graph we see",
    "start": "586440",
    "end": "588720"
  },
  {
    "text": "that CPU usage is actually showing this",
    "start": "588720",
    "end": "590760"
  },
  {
    "text": "Bend effect where some are around 50% CQ",
    "start": "590760",
    "end": "593880"
  },
  {
    "text": "usage or others around",
    "start": "593880",
    "end": "596480"
  },
  {
    "text": "60% um so this is a pro in practice",
    "start": "596480",
    "end": "599800"
  },
  {
    "text": "because you have to tune your autoscaler",
    "start": "599800",
    "end": "601560"
  },
  {
    "text": "based on the more like the those that",
    "start": "601560",
    "end": "604480"
  },
  {
    "text": "seem to have higher CPU usage uh so",
    "start": "604480",
    "end": "608120"
  },
  {
    "text": "what's going on under the hood here it",
    "start": "608120",
    "end": "610519"
  },
  {
    "text": "happens that our like run Robin is good",
    "start": "610519",
    "end": "613920"
  },
  {
    "text": "at balancing request it's not good at",
    "start": "613920",
    "end": "616079"
  },
  {
    "text": "actually balancing load and here we have",
    "start": "616079",
    "end": "618240"
  },
  {
    "text": "our workloads running on two different",
    "start": "618240",
    "end": "620000"
  },
  {
    "text": "generations of CPU um so ideally you",
    "start": "620000",
    "end": "623920"
  },
  {
    "text": "would want CPU usage to be perfectly",
    "start": "623920",
    "end": "625839"
  },
  {
    "text": "balanced and not not the number of",
    "start": "625839",
    "end": "627760"
  },
  {
    "text": "requests um and",
    "start": "627760",
    "end": "630120"
  },
  {
    "text": "like one thing to keep in mind is that",
    "start": "630120",
    "end": "632360"
  },
  {
    "text": "our the team that is responsible for",
    "start": "632360",
    "end": "634399"
  },
  {
    "text": "scheduling workloads onto servers",
    "start": "634399",
    "end": "636800"
  },
  {
    "text": "doesn't really isn't really interested",
    "start": "636800",
    "end": "638560"
  },
  {
    "text": "to in or isn't really able to make sure",
    "start": "638560",
    "end": "641320"
  },
  {
    "text": "that all the servers for a given uh",
    "start": "641320",
    "end": "644279"
  },
  {
    "text": "deployment are running on the same kind",
    "start": "644279",
    "end": "646519"
  },
  {
    "text": "of",
    "start": "646519",
    "end": "647720"
  },
  {
    "text": "instances uh so can we do better than",
    "start": "647720",
    "end": "649880"
  },
  {
    "text": "that well some of you that have worked",
    "start": "649880",
    "end": "651920"
  },
  {
    "text": "on GTC very recently will recognize the",
    "start": "651920",
    "end": "654320"
  },
  {
    "text": "perfect use for the weighted round robin",
    "start": "654320",
    "end": "656360"
  },
  {
    "text": "uh balancer which is a new feature that",
    "start": "656360",
    "end": "658560"
  },
  {
    "text": "was recently they add did in in drpc and",
    "start": "658560",
    "end": "661680"
  },
  {
    "text": "the idea is that servers will",
    "start": "661680",
    "end": "662720"
  },
  {
    "text": "communicate that current load in each",
    "start": "662720",
    "end": "664600"
  },
  {
    "text": "response and then clients will wait the",
    "start": "664600",
    "end": "666399"
  },
  {
    "text": "number of request sent to each server",
    "start": "666399",
    "end": "668240"
  },
  {
    "text": "according to a computed",
    "start": "668240",
    "end": "670920"
  },
  {
    "text": "capacity so integrating that in our",
    "start": "670920",
    "end": "673279"
  },
  {
    "text": "environment was actually really easy we",
    "start": "673279",
    "end": "675079"
  },
  {
    "text": "just we just had to implement a few",
    "start": "675079",
    "end": "677480"
  },
  {
    "text": "interceptors and a Time Loop that",
    "start": "677480",
    "end": "679600"
  },
  {
    "text": "measures CPU usage and plug that into",
    "start": "679600",
    "end": "682160"
  },
  {
    "text": "the buil-in weting r Dr in uh load",
    "start": "682160",
    "end": "685160"
  },
  {
    "text": "balancer um so we do that through our",
    "start": "685160",
    "end": "688519"
  },
  {
    "text": "rappers Library again so this can be",
    "start": "688519",
    "end": "690760"
  },
  {
    "text": "enabled by service owners through a",
    "start": "690760",
    "end": "692160"
  },
  {
    "text": "simple bullet um so the results have",
    "start": "692160",
    "end": "695399"
  },
  {
    "text": "been actually very impressive uh as you",
    "start": "695399",
    "end": "697720"
  },
  {
    "text": "can see on the top graph CPU usage now",
    "start": "697720",
    "end": "700560"
  },
  {
    "text": "after deploying the load reports becomes",
    "start": "700560",
    "end": "702959"
  },
  {
    "text": "completely balanced it becomes a",
    "start": "702959",
    "end": "705200"
  },
  {
    "text": "straight line and it's now the number of",
    "start": "705200",
    "end": "707360"
  },
  {
    "text": "requests per pod that is actually uh",
    "start": "707360",
    "end": "709680"
  },
  {
    "text": "different according to the server",
    "start": "709680",
    "end": "713040"
  },
  {
    "text": "performance uh so the nice thing really",
    "start": "713040",
    "end": "715240"
  },
  {
    "text": "about this feature is that it requires",
    "start": "715240",
    "end": "716920"
  },
  {
    "text": "no coordination no control plane it's",
    "start": "716920",
    "end": "719399"
  },
  {
    "text": "really easy to set",
    "start": "719399",
    "end": "721279"
  },
  {
    "text": "up um okay so as we just showed round",
    "start": "721279",
    "end": "725839"
  },
  {
    "text": "robbing is a great way to achieve a good",
    "start": "725839",
    "end": "727760"
  },
  {
    "text": "load balancing um it actually has some",
    "start": "727760",
    "end": "730519"
  },
  {
    "text": "also some drawbacks so let's let's look",
    "start": "730519",
    "end": "732720"
  },
  {
    "text": "into that um so this is uh showing um",
    "start": "732720",
    "end": "738160"
  },
  {
    "text": "each arrow on this diagram is actually",
    "start": "738160",
    "end": "739680"
  },
  {
    "text": "showing a connection between a client",
    "start": "739680",
    "end": "741399"
  },
  {
    "text": "and a server when we use uh round weing",
    "start": "741399",
    "end": "744240"
  },
  {
    "text": "this client side load balancing kind of",
    "start": "744240",
    "end": "745760"
  },
  {
    "text": "setup uh the number of the total number",
    "start": "745760",
    "end": "747880"
  },
  {
    "text": "of connections is the number of clients",
    "start": "747880",
    "end": "749880"
  },
  {
    "text": "multiplied by the number of servers so",
    "start": "749880",
    "end": "751399"
  },
  {
    "text": "each server receives one connection per",
    "start": "751399",
    "end": "753519"
  },
  {
    "text": "client um this number can become quite",
    "start": "753519",
    "end": "756639"
  },
  {
    "text": "large if you have a lot of clients um",
    "start": "756639",
    "end": "759079"
  },
  {
    "text": "and so the question is like is that a",
    "start": "759079",
    "end": "761360"
  },
  {
    "text": "problem in",
    "start": "761360",
    "end": "762680"
  },
  {
    "text": "practice it end of then it is because",
    "start": "762680",
    "end": "765320"
  },
  {
    "text": "those connections are cheap but when we",
    "start": "765320",
    "end": "767279"
  },
  {
    "text": "have thousands of connection we they all",
    "start": "767279",
    "end": "769920"
  },
  {
    "text": "sum up and uh resources that are",
    "start": "769920",
    "end": "772880"
  },
  {
    "text": "consumed by those uh connections uh add",
    "start": "772880",
    "end": "775880"
  },
  {
    "text": "up as well so here on the screen you can",
    "start": "775880",
    "end": "778160"
  },
  {
    "text": "see a screen shot of data do profiler",
    "start": "778160",
    "end": "781279"
  },
  {
    "text": "applied to one of our go JPC servers and",
    "start": "781279",
    "end": "785600"
  },
  {
    "text": "uh as you can see uh a lot of memory",
    "start": "785600",
    "end": "788760"
  },
  {
    "text": "like almost 2 gigabytes are spent on uh",
    "start": "788760",
    "end": "792399"
  },
  {
    "text": "some internal grpc buffers so we um dig",
    "start": "792399",
    "end": "796720"
  },
  {
    "text": "deeper to investigate what's going on",
    "start": "796720",
    "end": "798760"
  },
  {
    "text": "there so in order to understand the",
    "start": "798760",
    "end": "801120"
  },
  {
    "text": "problem let's consider a typical uh grpc",
    "start": "801120",
    "end": "804639"
  },
  {
    "text": "setup for a Goan server so here uh you",
    "start": "804639",
    "end": "808160"
  },
  {
    "text": "can see a connection and every",
    "start": "808160",
    "end": "809920"
  },
  {
    "text": "connection in uh JPC go allocates two",
    "start": "809920",
    "end": "813279"
  },
  {
    "text": "buffers uh one for RS and one for rights",
    "start": "813279",
    "end": "816680"
  },
  {
    "text": "and uh JPC go uses those buffers to",
    "start": "816680",
    "end": "819600"
  },
  {
    "text": "proxy request to underline Network sock",
    "start": "819600",
    "end": "823040"
  },
  {
    "text": "uh the corresponding sizes of them are",
    "start": "823040",
    "end": "824959"
  },
  {
    "text": "32 and 64 case uh and uh actually those",
    "start": "824959",
    "end": "830360"
  },
  {
    "text": "buffers help to reduce to improve",
    "start": "830360",
    "end": "833160"
  },
  {
    "text": "performance because uh accessing Network",
    "start": "833160",
    "end": "835519"
  },
  {
    "text": "socket is uh expensive because it",
    "start": "835519",
    "end": "838279"
  },
  {
    "text": "requires Network calls and accessing",
    "start": "838279",
    "end": "840440"
  },
  {
    "text": "data in memory is much faster so by",
    "start": "840440",
    "end": "842920"
  },
  {
    "text": "using those buffers we can improve",
    "start": "842920",
    "end": "845320"
  },
  {
    "text": "performance but uh let's consider what",
    "start": "845320",
    "end": "847800"
  },
  {
    "text": "happens if we use round robin and now we",
    "start": "847800",
    "end": "849839"
  },
  {
    "text": "have thousands of connections so just",
    "start": "849839",
    "end": "852160"
  },
  {
    "text": "those two buffers can account for a",
    "start": "852160",
    "end": "854720"
  },
  {
    "text": "gigabytes of memory on every server",
    "start": "854720",
    "end": "857519"
  },
  {
    "text": "which like uh account for terabytes of",
    "start": "857519",
    "end": "861560"
  },
  {
    "text": "memory ac across all our environment so",
    "start": "861560",
    "end": "865959"
  },
  {
    "text": "uh the uh one more uh problem here is",
    "start": "865959",
    "end": "870000"
  },
  {
    "text": "that in round robin case those uh the",
    "start": "870000",
    "end": "872440"
  },
  {
    "text": "effect of those buffers is not that",
    "start": "872440",
    "end": "875079"
  },
  {
    "text": "visible because u a lot of the",
    "start": "875079",
    "end": "877440"
  },
  {
    "text": "connections are not heavily utilized",
    "start": "877440",
    "end": "879680"
  },
  {
    "text": "like we have thousands of connections",
    "start": "879680",
    "end": "881399"
  },
  {
    "text": "but a lot of them are mostly idle and uh",
    "start": "881399",
    "end": "885600"
  },
  {
    "text": "buffers just sit there without uh",
    "start": "885600",
    "end": "888720"
  },
  {
    "text": "helping us a lot so what we did we",
    "start": "888720",
    "end": "891320"
  },
  {
    "text": "worked with uh JPC team and uh",
    "start": "891320",
    "end": "894959"
  },
  {
    "text": "introduced a optional mechanism that can",
    "start": "894959",
    "end": "899040"
  },
  {
    "text": "uh allows to share uh buffers between",
    "start": "899040",
    "end": "901600"
  },
  {
    "text": "connections so we use syn pool which is",
    "start": "901600",
    "end": "904120"
  },
  {
    "text": "a goine obstructions for sharing uh",
    "start": "904120",
    "end": "907600"
  },
  {
    "text": "objects between concurrent go requests",
    "start": "907600",
    "end": "910279"
  },
  {
    "text": "and uh we wrote some logic to release",
    "start": "910279",
    "end": "912759"
  },
  {
    "text": "the buffers and make them available for",
    "start": "912759",
    "end": "914800"
  },
  {
    "text": "other connections uh when",
    "start": "914800",
    "end": "917440"
  },
  {
    "text": "necessary so uh after we tested this uh",
    "start": "917440",
    "end": "921680"
  },
  {
    "text": "feature on one of our uh grpc servers",
    "start": "921680",
    "end": "925720"
  },
  {
    "text": "the results were really good so we saw",
    "start": "925720",
    "end": "929199"
  },
  {
    "text": "a 40% memory decrease with no visible uh",
    "start": "929199",
    "end": "933240"
  },
  {
    "text": "CPU impact uh and if you want to learn",
    "start": "933240",
    "end": "937120"
  },
  {
    "text": "more about this work here is the link to",
    "start": "937120",
    "end": "939800"
  },
  {
    "text": "the uh pull request where we um did this",
    "start": "939800",
    "end": "943959"
  },
  {
    "text": "work and provide some Benchmark results",
    "start": "943959",
    "end": "946759"
  },
  {
    "text": "but actually here I must mention that go",
    "start": "946759",
    "end": "948880"
  },
  {
    "text": "lank is not the only language where we",
    "start": "948880",
    "end": "951079"
  },
  {
    "text": "have uh problems with too many",
    "start": "951079",
    "end": "953440"
  },
  {
    "text": "connection generated by",
    "start": "953440",
    "end": "955199"
  },
  {
    "text": "rro okay so um this is again uh the same",
    "start": "955199",
    "end": "958720"
  },
  {
    "text": "diagram just showing the connections for",
    "start": "958720",
    "end": "960720"
  },
  {
    "text": "for one client and here we are talking",
    "start": "960720",
    "end": "963639"
  },
  {
    "text": "about python so one thing that we",
    "start": "963639",
    "end": "966279"
  },
  {
    "text": "quickly discovered when we uh when we",
    "start": "966279",
    "end": "968360"
  },
  {
    "text": "investigated these problems of too many",
    "start": "968360",
    "end": "970040"
  },
  {
    "text": "connections kind of causing too much",
    "start": "970040",
    "end": "972000"
  },
  {
    "text": "resource F usage that the reality",
    "start": "972000",
    "end": "974680"
  },
  {
    "text": "doesn't really look like this it",
    "start": "974680",
    "end": "976399"
  },
  {
    "text": "actually looks like this so um each",
    "start": "976399",
    "end": "979800"
  },
  {
    "text": "python process looks like it's opening",
    "start": "979800",
    "end": "982360"
  },
  {
    "text": "it not just one connection to each other",
    "start": "982360",
    "end": "983959"
  },
  {
    "text": "but a bunch of them um so why is that uh",
    "start": "983959",
    "end": "987880"
  },
  {
    "text": "well a lot of popular python Frameworks",
    "start": "987880",
    "end": "990040"
  },
  {
    "text": "are actually spawning not just one",
    "start": "990040",
    "end": "992040"
  },
  {
    "text": "process um to process request but it's",
    "start": "992040",
    "end": "994880"
  },
  {
    "text": "spawning a bunch of them and the they",
    "start": "994880",
    "end": "997800"
  },
  {
    "text": "cannot really share a grpc run time they",
    "start": "997800",
    "end": "999839"
  },
  {
    "text": "cannot really share connections so um in",
    "start": "999839",
    "end": "1002360"
  },
  {
    "text": "our environment typically the servers",
    "start": "1002360",
    "end": "1004360"
  },
  {
    "text": "that are soling our large python",
    "start": "1004360",
    "end": "1006120"
  },
  {
    "text": "monolitic application uh they run",
    "start": "1006120",
    "end": "1008440"
  },
  {
    "text": "thousands of process processes which",
    "start": "1008440",
    "end": "1011160"
  },
  {
    "text": "means that in this case we will have uh",
    "start": "1011160",
    "end": "1013759"
  },
  {
    "text": "dozens of connections per clients to",
    "start": "1013759",
    "end": "1016160"
  },
  {
    "text": "each other um so the way we uh improve",
    "start": "1016160",
    "end": "1020480"
  },
  {
    "text": "the situation here is simply by running",
    "start": "1020480",
    "end": "1023399"
  },
  {
    "text": "an an external connection Pooler we use",
    "start": "1023399",
    "end": "1026160"
  },
  {
    "text": "an N proxy for that running in as a side",
    "start": "1026160",
    "end": "1028760"
  },
  {
    "text": "car that the um the python processes",
    "start": "1028760",
    "end": "1032839"
  },
  {
    "text": "connect to and that is then responsible",
    "start": "1032839",
    "end": "1034918"
  },
  {
    "text": "for doing the round loing for us so by",
    "start": "1034919",
    "end": "1037438"
  },
  {
    "text": "doing that we were able to um make",
    "start": "1037439",
    "end": "1041600"
  },
  {
    "text": "python on par with other languages um",
    "start": "1041600",
    "end": "1044959"
  },
  {
    "text": "but we didn't really actually solve the",
    "start": "1044959",
    "end": "1046918"
  },
  {
    "text": "problem uh we just like greatly improved",
    "start": "1046919",
    "end": "1050120"
  },
  {
    "text": "the number of connections uh in the case",
    "start": "1050120",
    "end": "1052080"
  },
  {
    "text": "of python uh so can we do better than",
    "start": "1052080",
    "end": "1055160"
  },
  {
    "text": "that so the SC that we think should",
    "start": "1055160",
    "end": "1058799"
  },
  {
    "text": "solve the root cause of to many",
    "start": "1058799",
    "end": "1060520"
  },
  {
    "text": "connection problem is subsetting and the",
    "start": "1060520",
    "end": "1063200"
  },
  {
    "text": "idea behind subsetting is really simple",
    "start": "1063200",
    "end": "1065400"
  },
  {
    "text": "so uh what we're going to do we will",
    "start": "1065400",
    "end": "1068080"
  },
  {
    "text": "make every client to choose a subset out",
    "start": "1068080",
    "end": "1070400"
  },
  {
    "text": "of all available servers and then round",
    "start": "1070400",
    "end": "1072720"
  },
  {
    "text": "robbing request between them so a useful",
    "start": "1072720",
    "end": "1076080"
  },
  {
    "text": "way to think about subsetting is this uh",
    "start": "1076080",
    "end": "1078679"
  },
  {
    "text": "you can think that it's something that",
    "start": "1078679",
    "end": "1081000"
  },
  {
    "text": "it uh in the middle of two extreme which",
    "start": "1081000",
    "end": "1083480"
  },
  {
    "text": "are pick first and Round Robin if you",
    "start": "1083480",
    "end": "1085799"
  },
  {
    "text": "compare it to pick first it still opens",
    "start": "1085799",
    "end": "1088799"
  },
  {
    "text": "more connections because uh every client",
    "start": "1088799",
    "end": "1091360"
  },
  {
    "text": "is connected to a subset not to a single",
    "start": "1091360",
    "end": "1093720"
  },
  {
    "text": "server but it's still way less that in",
    "start": "1093720",
    "end": "1096280"
  },
  {
    "text": "case of round dropping but uh because of",
    "start": "1096280",
    "end": "1099120"
  },
  {
    "text": "the fact that we are opening uh more",
    "start": "1099120",
    "end": "1101480"
  },
  {
    "text": "connections we can uh uh have a better",
    "start": "1101480",
    "end": "1105640"
  },
  {
    "text": "uh load utilization on the server uh",
    "start": "1105640",
    "end": "1108840"
  },
  {
    "text": "then we have we speak first so uh the",
    "start": "1108840",
    "end": "1111919"
  },
  {
    "text": "only way of subsetting we implemented in",
    "start": "1111919",
    "end": "1114039"
  },
  {
    "text": "our infrastructure so far is random",
    "start": "1114039",
    "end": "1116400"
  },
  {
    "text": "subsetting and the algorithm here is uh",
    "start": "1116400",
    "end": "1119159"
  },
  {
    "text": "trivial basically we uh just pick a",
    "start": "1119159",
    "end": "1122440"
  },
  {
    "text": "random set of cost on every client and",
    "start": "1122440",
    "end": "1124679"
  },
  {
    "text": "then round robing request between them",
    "start": "1124679",
    "end": "1127120"
  },
  {
    "text": "but the results when we applied it to",
    "start": "1127120",
    "end": "1129360"
  },
  {
    "text": "one of our uh servers and this",
    "start": "1129360",
    "end": "1132159"
  },
  {
    "text": "particular server has like uh thousands",
    "start": "1132159",
    "end": "1134799"
  },
  {
    "text": "of clients um so as you can see the",
    "start": "1134799",
    "end": "1137960"
  },
  {
    "text": "number of connection as well as memory",
    "start": "1137960",
    "end": "1140080"
  },
  {
    "text": "utilization on the server uh reduced a",
    "start": "1140080",
    "end": "1144240"
  },
  {
    "text": "lot but uh the CPU uh impact was not",
    "start": "1144240",
    "end": "1148840"
  },
  {
    "text": "that great uh that's once again because",
    "start": "1148840",
    "end": "1151919"
  },
  {
    "text": "random subsetting has exactly the same",
    "start": "1151919",
    "end": "1154080"
  },
  {
    "text": "problem as p p first so uh the imbalance",
    "start": "1154080",
    "end": "1158640"
  },
  {
    "text": "between the most and the least utilized",
    "start": "1158640",
    "end": "1160799"
  },
  {
    "text": "server now grows and service owners will",
    "start": "1160799",
    "end": "1163960"
  },
  {
    "text": "have to account for that when allocating",
    "start": "1163960",
    "end": "1166000"
  },
  {
    "text": "resources for their server but once",
    "start": "1166000",
    "end": "1168080"
  },
  {
    "text": "again again it might be a fair tradeoff",
    "start": "1168080",
    "end": "1170000"
  },
  {
    "text": "for some uh type of applications but",
    "start": "1170000",
    "end": "1173120"
  },
  {
    "text": "still it's it doesn't feel like it's a",
    "start": "1173120",
    "end": "1175159"
  },
  {
    "text": "generic solution we can enable by",
    "start": "1175159",
    "end": "1177320"
  },
  {
    "text": "default for",
    "start": "1177320",
    "end": "1178840"
  },
  {
    "text": "everybody so uh the thing we are doing",
    "start": "1178840",
    "end": "1182400"
  },
  {
    "text": "right now we are trying to uh closely",
    "start": "1182400",
    "end": "1185960"
  },
  {
    "text": "work with the grpc maintainers and try",
    "start": "1185960",
    "end": "1188880"
  },
  {
    "text": "to introduce a standard way of doing",
    "start": "1188880",
    "end": "1191320"
  },
  {
    "text": "subsetting uh in JPC by exploring a",
    "start": "1191320",
    "end": "1194919"
  },
  {
    "text": "smarter algorithms uh of choosing",
    "start": "1194919",
    "end": "1197440"
  },
  {
    "text": "subsets on the client as well as the",
    "start": "1197440",
    "end": "1199799"
  },
  {
    "text": "algorithms how we can distribute load",
    "start": "1199799",
    "end": "1202840"
  },
  {
    "text": "when subset is already choosen chosen uh",
    "start": "1202840",
    "end": "1206200"
  },
  {
    "text": "but uh this is still work in progress",
    "start": "1206200",
    "end": "1208640"
  },
  {
    "text": "you can see link uh to the corresponding",
    "start": "1208640",
    "end": "1211720"
  },
  {
    "text": "uh JPC proposal on the screen uh and",
    "start": "1211720",
    "end": "1215360"
  },
  {
    "text": "it's too early to share any results of",
    "start": "1215360",
    "end": "1218000"
  },
  {
    "text": "this work",
    "start": "1218000",
    "end": "1219320"
  },
  {
    "text": "yet that's what it we'll be happy to",
    "start": "1219320",
    "end": "1222280"
  },
  {
    "text": "answer any",
    "start": "1222280",
    "end": "1224799"
  },
  {
    "text": "questions yeah go ahead",
    "start": "1226039",
    "end": "1230158"
  },
  {
    "text": "um wondering are you expecting that with",
    "start": "1237640",
    "end": "1240080"
  },
  {
    "text": "random subsetting being taken out and",
    "start": "1240080",
    "end": "1242760"
  },
  {
    "text": "deterministic subsetting coming in that",
    "start": "1242760",
    "end": "1244799"
  },
  {
    "text": "the CPU load will be better balanced",
    "start": "1244799",
    "end": "1247679"
  },
  {
    "text": "across servers is that the expected",
    "start": "1247679",
    "end": "1251640"
  },
  {
    "text": "outcome so uh yes uh basically with",
    "start": "1251640",
    "end": "1255200"
  },
  {
    "text": "deterministic subsetting there are some",
    "start": "1255200",
    "end": "1257120"
  },
  {
    "text": "wellestablished algorith",
    "start": "1257120",
    "end": "1259159"
  },
  {
    "text": "uh we looked at the ones that used at",
    "start": "1259159",
    "end": "1260919"
  },
  {
    "text": "Google and the Twitter aperture and",
    "start": "1260919",
    "end": "1263600"
  },
  {
    "text": "actually it is possible to achieve",
    "start": "1263600",
    "end": "1267000"
  },
  {
    "text": "perfect uh request and connection",
    "start": "1267000",
    "end": "1269480"
  },
  {
    "text": "distribution if you use deterministic",
    "start": "1269480",
    "end": "1271480"
  },
  {
    "text": "subset the problem with those algorithms",
    "start": "1271480",
    "end": "1274240"
  },
  {
    "text": "is that they are require coordination",
    "start": "1274240",
    "end": "1276679"
  },
  {
    "text": "between client and that's kind of the",
    "start": "1276679",
    "end": "1278720"
  },
  {
    "text": "point where we get some push back so",
    "start": "1278720",
    "end": "1281240"
  },
  {
    "text": "that's why we exploring different",
    "start": "1281240",
    "end": "1283799"
  },
  {
    "text": "options of uh doing this and we might we",
    "start": "1283799",
    "end": "1287600"
  },
  {
    "text": "might end up not contributing the",
    "start": "1287600",
    "end": "1290400"
  },
  {
    "text": "deterministic subset to grpc by the way",
    "start": "1290400",
    "end": "1293600"
  },
  {
    "text": "know some approaches that work without",
    "start": "1293600",
    "end": "1295120"
  },
  {
    "text": "coordination like please please come and",
    "start": "1295120",
    "end": "1297080"
  },
  {
    "text": "talk to us just to follow up it may be a",
    "start": "1297080",
    "end": "1300080"
  },
  {
    "text": "naive question but like sharing buffers",
    "start": "1300080",
    "end": "1302320"
  },
  {
    "text": "between the",
    "start": "1302320",
    "end": "1303360"
  },
  {
    "text": "connections uh like you did for go is",
    "start": "1303360",
    "end": "1305600"
  },
  {
    "text": "not a possible solution for the python",
    "start": "1305600",
    "end": "1308320"
  },
  {
    "text": "implementation I don't think that python",
    "start": "1308320",
    "end": "1310480"
  },
  {
    "text": "is affected by the same problem because",
    "start": "1310480",
    "end": "1312960"
  },
  {
    "text": "it's more specific how go was",
    "start": "1312960",
    "end": "1315360"
  },
  {
    "text": "implemented and I don't want to dig into",
    "start": "1315360",
    "end": "1317440"
  },
  {
    "text": "too much Tech technical details but yeah",
    "start": "1317440",
    "end": "1319400"
  },
  {
    "text": "I don't think it applies to",
    "start": "1319400",
    "end": "1322200"
  },
  {
    "text": "python uh so we uh hi my name is s uh we",
    "start": "1322200",
    "end": "1327520"
  },
  {
    "text": "use subsetting at our company and we",
    "start": "1327520",
    "end": "1330559"
  },
  {
    "text": "have we leave it to the teams to decide",
    "start": "1330559",
    "end": "1333919"
  },
  {
    "text": "what the subset size should be I'm",
    "start": "1333919",
    "end": "1336440"
  },
  {
    "text": "curious if you guys have any data on",
    "start": "1336440",
    "end": "1339320"
  },
  {
    "text": "like how you decide the subset based on",
    "start": "1339320",
    "end": "1341320"
  },
  {
    "text": "number of clients and",
    "start": "1341320",
    "end": "1343000"
  },
  {
    "text": "servers so uh we have a few teams uh as",
    "start": "1343000",
    "end": "1346039"
  },
  {
    "text": "we said that do that and uh they choose",
    "start": "1346039",
    "end": "1348320"
  },
  {
    "text": "the subset side size so it's the same um",
    "start": "1348320",
    "end": "1352360"
  },
  {
    "text": "for us it's a little cumers because we",
    "start": "1352360",
    "end": "1354279"
  },
  {
    "text": "don't have a centralized way to control",
    "start": "1354279",
    "end": "1356840"
  },
  {
    "text": "all clients uh as I mentioned at the",
    "start": "1356840",
    "end": "1359039"
  },
  {
    "text": "beginning we don't have any sort of",
    "start": "1359039",
    "end": "1360400"
  },
  {
    "text": "control plane that can kind of",
    "start": "1360400",
    "end": "1362080"
  },
  {
    "text": "dynamically inform all clients that they",
    "start": "1362080",
    "end": "1364840"
  },
  {
    "text": "should increase or like which subset",
    "start": "1364840",
    "end": "1367039"
  },
  {
    "text": "site they should use um but yeah",
    "start": "1367039",
    "end": "1369600"
  },
  {
    "text": "basically this is like so is uh uh is",
    "start": "1369600",
    "end": "1372880"
  },
  {
    "text": "this some kind of like configuration",
    "start": "1372880",
    "end": "1374400"
  },
  {
    "text": "that the team needs to change and then",
    "start": "1374400",
    "end": "1376400"
  },
  {
    "text": "roll out to all the clients yeah it does",
    "start": "1376400",
    "end": "1378760"
  },
  {
    "text": "you need to pass this information at",
    "start": "1378760",
    "end": "1380200"
  },
  {
    "text": "Cent",
    "start": "1380200",
    "end": "1381039"
  },
  {
    "text": "creation okay yeah we're also looking at",
    "start": "1381039",
    "end": "1383520"
  },
  {
    "text": "options where like we can somehow",
    "start": "1383520",
    "end": "1387200"
  },
  {
    "text": "calculate the optimal subset size based",
    "start": "1387200",
    "end": "1389840"
  },
  {
    "text": "on some metrics but I'm not sure if it's",
    "start": "1389840",
    "end": "1393400"
  },
  {
    "text": "feasible",
    "start": "1393400",
    "end": "1396400"
  },
  {
    "text": "okay so in case of you",
    "start": "1398200",
    "end": "1403240"
  },
  {
    "text": "said in case of weighted round robin you",
    "start": "1404200",
    "end": "1406799"
  },
  {
    "text": "said the load was reported back to the",
    "start": "1406799",
    "end": "1408720"
  },
  {
    "text": "client either out of band or on the",
    "start": "1408720",
    "end": "1411640"
  },
  {
    "text": "along with the RPC respon so in your",
    "start": "1411640",
    "end": "1414080"
  },
  {
    "text": "case what was it out of band so we use",
    "start": "1414080",
    "end": "1416159"
  },
  {
    "text": "the default which is uh within response",
    "start": "1416159",
    "end": "1419080"
  },
  {
    "text": "trailers I think both would have worked",
    "start": "1419080",
    "end": "1421520"
  },
  {
    "text": "equally well but okay because if it was",
    "start": "1421520",
    "end": "1425159"
  },
  {
    "text": "reported out of band or something you",
    "start": "1425159",
    "end": "1426480"
  },
  {
    "text": "could actually also use that to figure",
    "start": "1426480",
    "end": "1428600"
  },
  {
    "text": "out which subset to choose or where to",
    "start": "1428600",
    "end": "1431559"
  },
  {
    "text": "send rpcs and all that",
    "start": "1431559",
    "end": "1433320"
  },
  {
    "text": "stuff even Pi first can be used with",
    "start": "1433320",
    "end": "1435679"
  },
  {
    "text": "that I was thinking yeah we explored Le",
    "start": "1435679",
    "end": "1438000"
  },
  {
    "text": "in those options like uh trying to",
    "start": "1438000",
    "end": "1441760"
  },
  {
    "text": "adjust like disconnect for most",
    "start": "1441760",
    "end": "1443919"
  },
  {
    "text": "connected servers but yeah as I said we",
    "start": "1443919",
    "end": "1446799"
  },
  {
    "text": "don't have results",
    "start": "1446799",
    "end": "1449799"
  },
  {
    "text": "yet have a question for you guys um so",
    "start": "1452520",
    "end": "1455480"
  },
  {
    "text": "going back to setting up keep alive",
    "start": "1455480",
    "end": "1458159"
  },
  {
    "text": "parameters on the servers I'm wondering",
    "start": "1458159",
    "end": "1460840"
  },
  {
    "text": "if on in your services are are those",
    "start": "1460840",
    "end": "1464039"
  },
  {
    "text": "turned on by default or in if so what",
    "start": "1464039",
    "end": "1467480"
  },
  {
    "text": "are like how do you determine the",
    "start": "1467480",
    "end": "1468960"
  },
  {
    "text": "default values for those uh so actually",
    "start": "1468960",
    "end": "1471320"
  },
  {
    "text": "it's pretty interesting I didn't get",
    "start": "1471320",
    "end": "1472960"
  },
  {
    "text": "into details here but we set it to a",
    "start": "1472960",
    "end": "1475039"
  },
  {
    "text": "pretty high value because the main thing",
    "start": "1475039",
    "end": "1479080"
  },
  {
    "text": "in my opinion that GPC lives are doing",
    "start": "1479080",
    "end": "1482080"
  },
  {
    "text": "so the mechanism is that it send ping",
    "start": "1482080",
    "end": "1484240"
  },
  {
    "text": "regularly and you can configure the",
    "start": "1484240",
    "end": "1486159"
  },
  {
    "text": "interval and the time out uh but",
    "start": "1486159",
    "end": "1488760"
  },
  {
    "text": "regardless of the interval that you put",
    "start": "1488760",
    "end": "1492600"
  },
  {
    "text": "um it sets CCP user Timeout on the",
    "start": "1492600",
    "end": "1494880"
  },
  {
    "text": "socket and this is what has the like it",
    "start": "1494880",
    "end": "1498120"
  },
  {
    "text": "R basically reduces this window of 15",
    "start": "1498120",
    "end": "1500399"
  },
  {
    "text": "minutes to 15 seconds which in most",
    "start": "1500399",
    "end": "1503960"
  },
  {
    "text": "cases s",
    "start": "1503960",
    "end": "1505799"
  },
  {
    "text": "the yeah and the actual value I think is",
    "start": "1505799",
    "end": "1508240"
  },
  {
    "text": "still 15 minutes for the but we don't",
    "start": "1508240",
    "end": "1511080"
  },
  {
    "text": "care about about the keep Al",
    "start": "1511080",
    "end": "1514000"
  },
  {
    "text": "themselves thank",
    "start": "1514000",
    "end": "1517159"
  },
  {
    "text": "you and just to mention historically a",
    "start": "1519679",
    "end": "1524760"
  },
  {
    "text": "to",
    "start": "1524760",
    "end": "1526159"
  },
  {
    "text": "to like back on the beginning of the",
    "start": "1526159",
    "end": "1529039"
  },
  {
    "text": "presentation people have been kind of",
    "start": "1529039",
    "end": "1530799"
  },
  {
    "text": "tuning site parameters crazy and setting",
    "start": "1530799",
    "end": "1534000"
  },
  {
    "text": "them in ways that actually cause more",
    "start": "1534000",
    "end": "1535520"
  },
  {
    "text": "problems that solve so that's one of the",
    "start": "1535520",
    "end": "1538559"
  },
  {
    "text": "reason why centralizing that",
    "start": "1538559",
    "end": "1542240"
  },
  {
    "text": "that after the initial subset is",
    "start": "1542240",
    "end": "1544679"
  },
  {
    "text": "computed and then the outl detection",
    "start": "1544679",
    "end": "1547000"
  },
  {
    "text": "evicts the host what happens with the",
    "start": "1547000",
    "end": "1549960"
  },
  {
    "text": "subset uh so in our setup nothing uh it",
    "start": "1549960",
    "end": "1554000"
  },
  {
    "text": "just reduces the size",
    "start": "1554000",
    "end": "1556120"
  },
  {
    "text": "of and so outlier detection um with outl",
    "start": "1556120",
    "end": "1561159"
  },
  {
    "text": "detection there is no risk of actually",
    "start": "1561159",
    "end": "1562720"
  },
  {
    "text": "like sh like removing all the servers of",
    "start": "1562720",
    "end": "1564919"
  },
  {
    "text": "the set set because you're only looking",
    "start": "1564919",
    "end": "1567480"
  },
  {
    "text": "at the subset and out layers so um like",
    "start": "1567480",
    "end": "1571240"
  },
  {
    "text": "all servers cannot be",
    "start": "1571240",
    "end": "1572799"
  },
  {
    "text": "outlayer yeah there is a protection you",
    "start": "1572799",
    "end": "1575200"
  },
  {
    "text": "can configure Max uh ejected host I",
    "start": "1575200",
    "end": "1579880"
  },
  {
    "text": "think it's the default to 10% so you",
    "start": "1579880",
    "end": "1582360"
  },
  {
    "text": "will never eject more than 10% of your",
    "start": "1582360",
    "end": "1584919"
  },
  {
    "text": "server",
    "start": "1584919",
    "end": "1587600"
  }
]
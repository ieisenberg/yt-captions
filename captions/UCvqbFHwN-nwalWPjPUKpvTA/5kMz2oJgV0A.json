[
  {
    "start": "0",
    "end": "22000"
  },
  {
    "text": "hello everyone thank you for coming this is clusters as cattle how to seamlessly",
    "start": "0",
    "end": "5069"
  },
  {
    "text": "migrate your apps across your kubernetes clusters my name is Andy Goldstein I work at hep do I've been a kubernetes",
    "start": "5069",
    "end": "12300"
  },
  {
    "text": "contributor for the past several years I'm the tech lead for hep do arc which is our backup and recovery tool for your",
    "start": "12300",
    "end": "19140"
  },
  {
    "text": "kubernetes resources and persistent data so what are we gonna talk about today we're going to talk a little bit about a",
    "start": "19140",
    "end": "25500"
  },
  {
    "start": "22000",
    "end": "45000"
  },
  {
    "text": "history of developing and deploying apps over time we'll talk about kubernetes",
    "start": "25500",
    "end": "31349"
  },
  {
    "text": "and how the pets versus cattle metaphor fits in there I'll go over some app and",
    "start": "31349",
    "end": "37739"
  },
  {
    "text": "workload migrations in kubernetes and I'll show you a little demo that I hope you'll enjoy and at the end we'll have",
    "start": "37739",
    "end": "43649"
  },
  {
    "text": "some time for questions so if you were in the 1940s or 50s and you were",
    "start": "43649",
    "end": "49140"
  },
  {
    "start": "45000",
    "end": "66000"
  },
  {
    "text": "deploying an app this is what it would look like this is a picture of ENIAC one",
    "start": "49140",
    "end": "54149"
  },
  {
    "text": "of the first electronic computers it took up an entire room or more and if you needed to develop an app or and",
    "start": "54149",
    "end": "61230"
  },
  {
    "text": "deploy it you physically had to rewire to make your changes moving forward a",
    "start": "61230",
    "end": "67530"
  },
  {
    "start": "66000",
    "end": "90000"
  },
  {
    "text": "little bit we have some punch cards so better than physically rewiring but not",
    "start": "67530",
    "end": "72689"
  },
  {
    "text": "exactly readable to a normal person and it takes a lot of time to both program",
    "start": "72689",
    "end": "79110"
  },
  {
    "text": "and when you're ready to deploy your app you have to run it through a punch card reader like you can see here with this",
    "start": "79110",
    "end": "86009"
  },
  {
    "text": "IBM 704 electronic calculator fast",
    "start": "86009",
    "end": "91020"
  },
  {
    "text": "forward past all of that past mainframes and we get to things like UNIX and Linux and Windows and now developing apps is",
    "start": "91020",
    "end": "99000"
  },
  {
    "text": "easier deploying apps a little bit easier but getting access to those",
    "start": "99000",
    "end": "104250"
  },
  {
    "text": "computing resources still isn't super easy what you have to do at least back",
    "start": "104250",
    "end": "109920"
  },
  {
    "start": "107000",
    "end": "128000"
  },
  {
    "text": "then is file tickets I need a new server I need a new virtual machine",
    "start": "109920",
    "end": "115049"
  },
  {
    "text": "I need something deployed and with tickets comes delays you have to get things approved maybe multiple people",
    "start": "115049",
    "end": "122189"
  },
  {
    "text": "have to approve it so we're better than having to rewire physically but we're still not there yet so let's fast",
    "start": "122189",
    "end": "130170"
  },
  {
    "start": "128000",
    "end": "180000"
  },
  {
    "text": "forward a little bit further to cloud computing now anybody with a credit card can get fairly instantaneous",
    "start": "130170",
    "end": "136680"
  },
  {
    "text": "access to a virtual machine without having to file a ticket to get it but",
    "start": "136680",
    "end": "142400"
  },
  {
    "text": "just like with physical servers before and with virtual virtual machines and",
    "start": "142400",
    "end": "147629"
  },
  {
    "text": "with cloud-based virtual machines you still have to manage the operating system or have a department that does it",
    "start": "147629",
    "end": "153659"
  },
  {
    "text": "and if one of your virtual machines or physical servers starts acting up you",
    "start": "153659",
    "end": "158970"
  },
  {
    "text": "want to fix it as quickly as possible this is your pet because you never know",
    "start": "158970",
    "end": "165269"
  },
  {
    "text": "how long it's going to take to get this thing back working so you've got to get it up as quickly as possible you want to",
    "start": "165269",
    "end": "171389"
  },
  {
    "text": "make sure that you have the latest operating system updates and you want to make sure that if something does go",
    "start": "171389",
    "end": "176459"
  },
  {
    "text": "wrong you can recover from your backup as quickly as possible okay",
    "start": "176459",
    "end": "181530"
  },
  {
    "start": "180000",
    "end": "236000"
  },
  {
    "text": "obligatory container picture so beyond cloud computing with virtual machines we",
    "start": "181530",
    "end": "187739"
  },
  {
    "text": "have our containerization technologies which are great we don't have to think about the operating system nearly as",
    "start": "187739",
    "end": "193319"
  },
  {
    "text": "much we still do but at least if you're developing an image for your application you can focus on just what you want to",
    "start": "193319",
    "end": "200760"
  },
  {
    "text": "fit in there so if you're working on a web application you put your web server and you're content most likely you",
    "start": "200760",
    "end": "208109"
  },
  {
    "text": "package it up as an image and then you can run it which is great you don't have to worry about installing an operating",
    "start": "208109",
    "end": "213870"
  },
  {
    "text": "system to make this happen but when it comes to orchestrating where these",
    "start": "213870",
    "end": "219239"
  },
  {
    "text": "containers run it's still difficult maybe you have systemd or upstart or",
    "start": "219239",
    "end": "225659"
  },
  {
    "text": "some other init system you can tell it run this container on this node on this server but from a management and",
    "start": "225659",
    "end": "232739"
  },
  {
    "text": "orchestration perspective you're still not there so fortunately we have",
    "start": "232739",
    "end": "238379"
  },
  {
    "start": "236000",
    "end": "278000"
  },
  {
    "text": "kubernetes that's why we're all here so the great thing about kubernetes is you can now really forget for the most part",
    "start": "238379",
    "end": "245609"
  },
  {
    "text": "about that infrastructure and where things are running we tell kubernetes or",
    "start": "245609",
    "end": "250650"
  },
  {
    "text": "more ask kubernetes deploy something I don't really know where you're going to",
    "start": "250650",
    "end": "255870"
  },
  {
    "text": "put it because you get to schedule it so as a person as a developer as an IT operator you don't have to worry about",
    "start": "255870",
    "end": "262289"
  },
  {
    "text": "that as much that's what's great about kubernetes but what about the clusters themselves are",
    "start": "262289",
    "end": "269520"
  },
  {
    "text": "they pets are they cattle do we need to treat them with the utmost of care so",
    "start": "269520",
    "end": "275310"
  },
  {
    "text": "that we make sure that they're always up and running I'm here to tell you you",
    "start": "275310",
    "end": "280349"
  },
  {
    "text": "need to treat them as cattle as best as you can so it's very important that you learn how to automate installing a",
    "start": "280349",
    "end": "287819"
  },
  {
    "text": "cluster adding a node to a cluster and then migrating from an older cluster to",
    "start": "287819",
    "end": "293849"
  },
  {
    "text": "a newer one up here are some tools that you can use I'm going to be talking",
    "start": "293849",
    "end": "298889"
  },
  {
    "text": "today about ansible and cube ATM so ansible is a general purpose tool for",
    "start": "298889",
    "end": "306270"
  },
  {
    "text": "running collections of tasks that have a similar purpose you group those into",
    "start": "306270",
    "end": "312150"
  },
  {
    "text": "roles and then you can have multiple roles in an individual playbook and I'll",
    "start": "312150",
    "end": "317520"
  },
  {
    "text": "have an example here so you can see how that looks so the first thing I want to show is this is a role that I've called",
    "start": "317520",
    "end": "324960"
  },
  {
    "start": "320000",
    "end": "358000"
  },
  {
    "text": "kubernetes and it will if I run it create a one node all in one cluster",
    "start": "324960",
    "end": "331339"
  },
  {
    "text": "obviously that's a bit limiting but for this purpose of this talk I think you can get the point and then you can go",
    "start": "331339",
    "end": "338009"
  },
  {
    "text": "and figure out there's great examples out there for doing multiple node clusters and for adding additional nodes",
    "start": "338009",
    "end": "344219"
  },
  {
    "text": "to existing clusters and what you see here is a default variables file for",
    "start": "344219",
    "end": "350370"
  },
  {
    "text": "things that maybe I want to just have by default my kubernetes version and if I don't override it this is what I'm going",
    "start": "350370",
    "end": "356849"
  },
  {
    "text": "to get once I have that set I have some tasks these are the real meat of what",
    "start": "356849",
    "end": "364169"
  },
  {
    "start": "358000",
    "end": "399000"
  },
  {
    "text": "happens when I run this role so the first thing I need to do is get my packages installed",
    "start": "364169",
    "end": "369300"
  },
  {
    "text": "I need cube control the cubelet cube ATM and kubernetes CNI I'm using fedora so",
    "start": "369300",
    "end": "375240"
  },
  {
    "text": "I've got DNF up there and when I run this task it will make sure that these four packages are present on the machine",
    "start": "375240",
    "end": "381599"
  },
  {
    "text": "and the nice thing about ansible is that it has it has states such as present and",
    "start": "381599",
    "end": "387870"
  },
  {
    "text": "absent and in a lot of tasks such as DNF present is the default and so if I run this over and over again it's not going",
    "start": "387870",
    "end": "394680"
  },
  {
    "text": "to install the packages multiple times it's just going to ensure that they're there once I've got my package is installed I",
    "start": "394680",
    "end": "402130"
  },
  {
    "start": "399000",
    "end": "413000"
  },
  {
    "text": "can use system D to get my cubelets started and make sure that it's enabled",
    "start": "402130",
    "end": "407500"
  },
  {
    "text": "so that as I reboot my machines if that happens that it will start up at boot time and then here we have a template",
    "start": "407500",
    "end": "417010"
  },
  {
    "start": "413000",
    "end": "450000"
  },
  {
    "text": "for cube ATM and it's a template because I want to be able to change the kubernetes version so you can see up",
    "start": "417010",
    "end": "423790"
  },
  {
    "text": "here there's a templating language that allows ansible to take either my default",
    "start": "423790",
    "end": "430000"
  },
  {
    "text": "value which was 1.9 point 6 or a version of my choosing to override and replace",
    "start": "430000",
    "end": "435820"
  },
  {
    "text": "that so that I can change the kubernetes version that I'm installing without necessarily having to rewrite my role",
    "start": "435820",
    "end": "443640"
  },
  {
    "text": "you'll also see that I have a pod subnet for calico and I've decided that I want",
    "start": "443640",
    "end": "448660"
  },
  {
    "text": "to use core DNS as well once I have that I can use the template command to run it",
    "start": "448660",
    "end": "455290"
  },
  {
    "start": "450000",
    "end": "502000"
  },
  {
    "text": "through the template engine do the variable substitution and copy it over to my remote server and then finally",
    "start": "455290",
    "end": "461139"
  },
  {
    "text": "here it'll run cube ATM in it using that template file to get phase 1 of my",
    "start": "461139",
    "end": "466510"
  },
  {
    "text": "cluster up and running but we don't have Calico installed yet so we go ahead and copy the cube kinnetik file that cube",
    "start": "466510",
    "end": "474400"
  },
  {
    "text": "ATM creates to the home directory of my remote user and then finally I can go",
    "start": "474400",
    "end": "479500"
  },
  {
    "text": "ahead and take two calico Gamel copy it over to the remote server and run cute control apply on it and when this is",
    "start": "479500",
    "end": "485979"
  },
  {
    "text": "done I have a fully functioning one node cluster now obviously left out a few",
    "start": "485979",
    "end": "491500"
  },
  {
    "text": "things but I do have all of this source code available on my github repository with a link at the end so you can go",
    "start": "491500",
    "end": "498010"
  },
  {
    "text": "check this out and play around with it on your own after this talk and finally",
    "start": "498010",
    "end": "503740"
  },
  {
    "text": "to put all of this together I have a playbook and in this case my playbook is called cluster and I want to run two",
    "start": "503740",
    "end": "511210"
  },
  {
    "text": "roles with this playbook the first one I just took you through some examples of the second one installs the contour",
    "start": "511210",
    "end": "517960"
  },
  {
    "text": "ingress controller which will be part of a demo that I'll be showing in a minute",
    "start": "517960",
    "end": "523110"
  },
  {
    "start": "522000",
    "end": "619000"
  },
  {
    "text": "ok so you've got your cluster installed and you've automated your installation",
    "start": "523110",
    "end": "528130"
  },
  {
    "text": "so let's talk about applications hopefully you have it your applique",
    "start": "528130",
    "end": "533160"
  },
  {
    "text": "configurations whether it's yeah Mille or case on it or something else",
    "start": "533160",
    "end": "538510"
  },
  {
    "text": "hopefully you have that in source control that's very important and something that we stress highly that you",
    "start": "538510",
    "end": "545290"
  },
  {
    "text": "do and but once you have your applications hopefully automated you may need to",
    "start": "545290",
    "end": "550690"
  },
  {
    "text": "migrate them at some point so if you've got an application you can't think that",
    "start": "550690",
    "end": "556660"
  },
  {
    "text": "you're going to pin it to a specific cluster or a specific node in a specific cluster forever at some point the node",
    "start": "556660",
    "end": "564220"
  },
  {
    "text": "is going to be decommissioned or the pods just going to get killed or the cluster needs to be decommissioned maybe",
    "start": "564220",
    "end": "569920"
  },
  {
    "text": "so we need to think that migrations are necessities and we have to accept that",
    "start": "569920",
    "end": "575470"
  },
  {
    "text": "and account for that so when we're doing migrations stateless obviously is easier",
    "start": "575470",
    "end": "581200"
  },
  {
    "text": "than staple you've got an app that doesn't have any state it's pretty pretty easy to move it around with",
    "start": "581200",
    "end": "586420"
  },
  {
    "text": "stateful apps I'd say that probably depends on the app itself and so I can't",
    "start": "586420",
    "end": "591460"
  },
  {
    "text": "give you a generic this will all work for every single stateful app but you can do things such as maybe put it in",
    "start": "591460",
    "end": "599050"
  },
  {
    "text": "read-only mode if you can accept that and your users can accept that maybe you have to take it offline for some",
    "start": "599050",
    "end": "604690"
  },
  {
    "text": "downtime or maybe you have some apps that can support spanning multiple clusters with replication for example so",
    "start": "604690",
    "end": "611230"
  },
  {
    "text": "that you can start to spin up new members in a new cluster and bring your old members down over time so I do want",
    "start": "611230",
    "end": "620560"
  },
  {
    "start": "619000",
    "end": "671000"
  },
  {
    "text": "to mention I said earlier that I'm the tech lead for arc and it's good for disaster recovery but it's also really",
    "start": "620560",
    "end": "626230"
  },
  {
    "text": "good for migrations so we do on-demand and scheduled backups with arc and we",
    "start": "626230",
    "end": "632070"
  },
  {
    "text": "backup as many or as few kubernetes resources as you specify as well as",
    "start": "632070",
    "end": "637900"
  },
  {
    "text": "persistent volume data so you can say I'd like to back up one namespace or a",
    "start": "637900",
    "end": "643150"
  },
  {
    "text": "bunch you can say I'd like only a certain subset of resources so maybe",
    "start": "643150",
    "end": "648310"
  },
  {
    "text": "just pods and services and you can also use a label selector as part of that",
    "start": "648310",
    "end": "653320"
  },
  {
    "text": "selection criteria when you're creating backups we're also extensible so if we don't",
    "start": "653320",
    "end": "658480"
  },
  {
    "text": "have the exact behavior that you need you can write a plug-in for it and as I mentioned it's good for migrations so",
    "start": "658480",
    "end": "664300"
  },
  {
    "text": "you can take a backup of something in one cluster including persistent data and then migrated over to another cluster so",
    "start": "664300",
    "end": "672759"
  },
  {
    "start": "671000",
    "end": "711000"
  },
  {
    "text": "let's look at a scenario here let's say that I have an app and it's running in a",
    "start": "672759",
    "end": "677769"
  },
  {
    "text": "kubernetes 1.9 cluster and I want to migrate to one point 10 but I don't want",
    "start": "677769",
    "end": "684069"
  },
  {
    "text": "to upgrade my 1.9 cluster I'm afraid that maybe something goes wrong and I",
    "start": "684069",
    "end": "690519"
  },
  {
    "text": "end up with a non-functional application or a non-functional cluster so to avoid",
    "start": "690519",
    "end": "695829"
  },
  {
    "text": "downtime what I want to do is keep my old cluster spin up a brand new cluster",
    "start": "695829",
    "end": "702069"
  },
  {
    "text": "using the new version and then slowly migrate users from the old one to the new one",
    "start": "702069",
    "end": "707560"
  },
  {
    "text": "but do it transparently so they have no idea that this is happening now before I",
    "start": "707560",
    "end": "712660"
  },
  {
    "start": "711000",
    "end": "846000"
  },
  {
    "text": "get into that and the demo I do want to talk a little bit about networking inside of kubernetes because it's",
    "start": "712660",
    "end": "718329"
  },
  {
    "text": "relevant to how we can solve this migration problem so if you're writing a",
    "start": "718329",
    "end": "723370"
  },
  {
    "text": "client and it's running inside the cluster and you want to talk to another pod you can talk to the pod by its IP",
    "start": "723370",
    "end": "729610"
  },
  {
    "text": "address so you could hard code that a better thing to do is to use the DNS",
    "start": "729610",
    "end": "734980"
  },
  {
    "text": "name of the service so you put a service in front of the pod it gets a DNS name it also has an IP address you could use",
    "start": "734980",
    "end": "741910"
  },
  {
    "text": "that if you wanted to and if you're not familiar with services and kubernetes they have endpoints that are associated",
    "start": "741910",
    "end": "748209"
  },
  {
    "text": "with them and there's an endpoint for the pods that are working for that",
    "start": "748209",
    "end": "754689"
  },
  {
    "text": "service so this works great but what happens if I I lose my pod and my",
    "start": "754689",
    "end": "761350"
  },
  {
    "text": "deployment replaces it with another one I have a new IP address so if I",
    "start": "761350",
    "end": "766360"
  },
  {
    "text": "hard-coded that it's not going to work anymore fortunately DNS still works and that's",
    "start": "766360",
    "end": "773800"
  },
  {
    "text": "what I would strongly recommend if you have an in cluster client but what if I have an outside client like someone from",
    "start": "773800",
    "end": "782709"
  },
  {
    "text": "the internet I'm not going to be able to hit this internal cluster only IP and",
    "start": "782709",
    "end": "788380"
  },
  {
    "text": "I'm not going to be able to hit the DNS for the service either because that's local to the cluster so the reason that",
    "start": "788380",
    "end": "795639"
  },
  {
    "text": "I mentioned this is that if I have just a single cluster and I I have one way into it and here's a",
    "start": "795639",
    "end": "802610"
  },
  {
    "text": "solution we can put an ingress controller such as envoy or contour to control envoy and expose that on the",
    "start": "802610",
    "end": "810320"
  },
  {
    "text": "host Network of the node that it's running on and then make sure that from the firewall or wherever we're coming",
    "start": "810320",
    "end": "816470"
  },
  {
    "text": "from the internet that we can get into that node and we use DNS a different DNS name I'm going to use the kubernetes up",
    "start": "816470",
    "end": "823250"
  },
  {
    "text": "and running demo application here and so I just made up a dot demo domain name for this example but we use a different",
    "start": "823250",
    "end": "830390"
  },
  {
    "text": "DNS name and make sure that we have all of the the routing connected so that we can get in this way and the reason that",
    "start": "830390",
    "end": "837170"
  },
  {
    "text": "I mentioned this is that this will allow us to come from outside the cluster into the cluster and it'll allow us to swap",
    "start": "837170",
    "end": "844220"
  },
  {
    "text": "out the clusters as well so here's my solution we have kubernetes we use hep",
    "start": "844220",
    "end": "850880"
  },
  {
    "start": "846000",
    "end": "860000"
  },
  {
    "text": "do contour which is a ingress controller for envoy we add a little bit of wildcard DNS and so at the top let me",
    "start": "850880",
    "end": "859190"
  },
  {
    "text": "show you a picture here I go ahead and I put it a routing cluster now this cluster can be highly available it'll",
    "start": "859190",
    "end": "866360"
  },
  {
    "start": "860000",
    "end": "913000"
  },
  {
    "text": "run envoy and at least one of the nodes I'd recommend you probably have two clusters and you use some sort of IP",
    "start": "866360",
    "end": "872990"
  },
  {
    "text": "failover technology to have them highly available and you point DNS and make",
    "start": "872990",
    "end": "878630"
  },
  {
    "text": "sure that it can get in to whatever node has envoy running on it and for my example here I'm using this query demo",
    "start": "878630",
    "end": "885650"
  },
  {
    "text": "and what I want to do is I want to be able to swap out where the applications",
    "start": "885650",
    "end": "890720"
  },
  {
    "text": "are really running so they're running in either cluster one cluster two however many clusters I have and the whole point",
    "start": "890720",
    "end": "896810"
  },
  {
    "text": "of this is that my routing cluster stays the same I changed the configuration a little bit but I can remove and add",
    "start": "896810",
    "end": "903800"
  },
  {
    "text": "back-end clusters at will and as long as there's at least one running my traffic",
    "start": "903800",
    "end": "909890"
  },
  {
    "text": "will continue to flow and my app will continue to function so how do we do this on the right here I've got a",
    "start": "909890",
    "end": "917210"
  },
  {
    "start": "913000",
    "end": "945000"
  },
  {
    "text": "representation of just a back-end cluster node I have contour and Envoy running so that if I were to hit that",
    "start": "917210",
    "end": "924520"
  },
  {
    "text": "hit on void directly I'd be able to route it into that pod but this is not exposed to the Internet it's my routing",
    "start": "924520",
    "end": "932450"
  },
  {
    "text": "cluster that is so if I add contour an envoy to my",
    "start": "932450",
    "end": "937790"
  },
  {
    "text": "routing cluster and I create an ingress object for my application where does it route how do we get this to wire all",
    "start": "937790",
    "end": "943550"
  },
  {
    "text": "together so what I have is some custom control logic that will look for special",
    "start": "943550",
    "end": "951500"
  },
  {
    "start": "945000",
    "end": "969000"
  },
  {
    "text": "secrets that are labeled in a certain way and inside each secret I have two things I have an IP address that",
    "start": "951500",
    "end": "957950"
  },
  {
    "text": "represents the IP of this node that's running contour and envoy and a back-end",
    "start": "957950",
    "end": "963530"
  },
  {
    "text": "cluster and I have a cube config file that I use to talk to that back-end cluster because what I want to do is I",
    "start": "963530",
    "end": "970910"
  },
  {
    "start": "969000",
    "end": "1026000"
  },
  {
    "text": "want to find all of the ingress objects that have a route equals to label and this is all just an example you know we",
    "start": "970910",
    "end": "978800"
  },
  {
    "text": "can do this different ways but for example purposes I'm looking for route equals true and when I find that when my",
    "start": "978800",
    "end": "984650"
  },
  {
    "text": "controller finds it it adds a service and an endpoints object that are",
    "start": "984650",
    "end": "989660"
  },
  {
    "text": "specific to that ingress in the backend cluster and the endpoints object here",
    "start": "989660",
    "end": "995330"
  },
  {
    "text": "has one IP address in it that points at that envoy running in that back-end node",
    "start": "995330",
    "end": "1000820"
  },
  {
    "text": "and it updates the ingress so that I can actually route traffic appropriately so",
    "start": "1000820",
    "end": "1006100"
  },
  {
    "text": "here's what that looks like if I come to QWERTY demo it's going to hit this Envoy up here and envoy is going to select a",
    "start": "1006100",
    "end": "1013150"
  },
  {
    "text": "back-end based on the endpoints that I have here which point to the node in the backend and then we flow all the way",
    "start": "1013150",
    "end": "1019180"
  },
  {
    "text": "down to that pod so demo time hopefully the demo gods are with me all right so",
    "start": "1019180",
    "end": "1027970"
  },
  {
    "start": "1026000",
    "end": "1050000"
  },
  {
    "text": "this is a pre scripted but live demo so I'm not typing but everything here is",
    "start": "1027970",
    "end": "1034300"
  },
  {
    "text": "actually live and I have some helper functions here so that I can switch between different clusters so for",
    "start": "1034300",
    "end": "1041020"
  },
  {
    "text": "cluster 1 I'm going to show you that we're running kubernetes 1.9 point 6 and",
    "start": "1041020",
    "end": "1046510"
  },
  {
    "text": "I have one node sitting there called cluster 1 so let's go ahead and we're",
    "start": "1046510",
    "end": "1052330"
  },
  {
    "text": "going to deploy quar DV 1 to cluster 1 so I'm going to create a namespace",
    "start": "1052330",
    "end": "1058060"
  },
  {
    "text": "called demo and I'm going to use the cube control run command to run this",
    "start": "1058060",
    "end": "1064900"
  },
  {
    "text": "QWERTY image I'm also going to expose it which will create a service for me on port 8080 and so here you can",
    "start": "1064900",
    "end": "1072130"
  },
  {
    "text": "see that output and then I have an ingress file that just has cardi demo pointing to this particular service so",
    "start": "1072130",
    "end": "1080140"
  },
  {
    "text": "that's all created we can go take a look in the browser and if we go over here this is QWERTY demo I'll refresh it it's",
    "start": "1080140",
    "end": "1086860"
  },
  {
    "text": "not working because I haven't hooked everything up yet so the next thing we want to do is we want to tell my routing",
    "start": "1086860",
    "end": "1092920"
  },
  {
    "text": "cluster about this website that I want to have hosted so I have a little helper",
    "start": "1092920",
    "end": "1099640"
  },
  {
    "start": "1097000",
    "end": "1115000"
  },
  {
    "text": "command after I create this namespace here called R and I'm going to add AV",
    "start": "1099640",
    "end": "1106630"
  },
  {
    "text": "host called Cordy and I have some defaulting in here so this is basically going to say let's let's do QWERTY demo",
    "start": "1106630",
    "end": "1113590"
  },
  {
    "text": "so what does this actually do this creates an ingress and I've abbreviated a little bit but you can see that",
    "start": "1113590",
    "end": "1120190"
  },
  {
    "start": "1115000",
    "end": "1148000"
  },
  {
    "text": "there's a namespace demo the name is Cordy and I have an annotation here called weighted cluster and this is just",
    "start": "1120190",
    "end": "1127810"
  },
  {
    "text": "something that I did for the demo to tell envoy that we're going to be doing some traffic shifting and in particular",
    "start": "1127810",
    "end": "1134920"
  },
  {
    "text": "I'll point out you can see I have this temporary placeholder up here for my",
    "start": "1134920",
    "end": "1140140"
  },
  {
    "text": "back-end service this is because I haven't told the router about any of my back-end clusters so let's go ahead and",
    "start": "1140140",
    "end": "1147220"
  },
  {
    "text": "do that so if I add my back-end cluster 1 we can see what that did to the",
    "start": "1147220",
    "end": "1154780"
  },
  {
    "start": "1148000",
    "end": "1156000"
  },
  {
    "text": "ingress itself so instead of temporary placeholder we now have this quality",
    "start": "1154780",
    "end": "1160360"
  },
  {
    "start": "1156000",
    "end": "1184000"
  },
  {
    "text": "cluster 1 service which my routing controller created automatically for me when I added that back-end to it and if",
    "start": "1160360",
    "end": "1167470"
  },
  {
    "text": "I go into the website and i refresh it I now have the app up and running and I",
    "start": "1167470",
    "end": "1173290"
  },
  {
    "text": "can refresh a couple times and you'll see that down at the bottom this request ID changes here and there so we just",
    "start": "1173290",
    "end": "1179380"
  },
  {
    "text": "have one back-end cluster and the application deployed there all right so",
    "start": "1179380",
    "end": "1185310"
  },
  {
    "start": "1184000",
    "end": "1208000"
  },
  {
    "text": "let's hit hit it with some load so I have a little benchmarking script that's just going to run a five second load",
    "start": "1185310",
    "end": "1191020"
  },
  {
    "text": "test against QWERTY demo and this will show us how many requests came in and",
    "start": "1191020",
    "end": "1196150"
  },
  {
    "text": "which back-end they hit so when this pops up we had about 30",
    "start": "1196150",
    "end": "1201340"
  },
  {
    "text": "400 requests and they all went to this one particular IP address which is my",
    "start": "1201340",
    "end": "1206530"
  },
  {
    "text": "cluster one all right so let's create a backup with ARC so I'm gonna go over to",
    "start": "1206530",
    "end": "1212200"
  },
  {
    "start": "1208000",
    "end": "1225000"
  },
  {
    "text": "cluster one I have arc pre-installed and I'm gonna use the arc backup create command to tell it I want to create a",
    "start": "1212200",
    "end": "1218680"
  },
  {
    "text": "demo or sorry I create a backup called quar D and I want to include one namespace which is the demo namespace so",
    "start": "1218680",
    "end": "1225960"
  },
  {
    "start": "1225000",
    "end": "1244000"
  },
  {
    "text": "this submits a request to the server the arc server which will find it and",
    "start": "1225960",
    "end": "1231280"
  },
  {
    "text": "process it we can go take a look I'm storing this in Mineo and here you'll see I have a bucket called arc and I",
    "start": "1231280",
    "end": "1238480"
  },
  {
    "text": "have a backup called Cordy and this is what you typically see inside for an arc",
    "start": "1238480",
    "end": "1243490"
  },
  {
    "text": "backup so that's all good and we can go ahead and lo and behold we have a brand",
    "start": "1243490",
    "end": "1250420"
  },
  {
    "start": "1244000",
    "end": "1264000"
  },
  {
    "text": "new kubernetes one 10.14 us if I had more time I would I would spin this up",
    "start": "1250420",
    "end": "1257560"
  },
  {
    "text": "with vagrant and run ansible on it but I don't want to make you sit here and wait for that to happen so I have this",
    "start": "1257560",
    "end": "1262630"
  },
  {
    "text": "cluster pre created so we're gonna go ahead and install arc and this installs",
    "start": "1262630",
    "end": "1268360"
  },
  {
    "start": "1264000",
    "end": "1296000"
  },
  {
    "text": "arc in restore only mode so it's going to connect to the same Mineo bucket that",
    "start": "1268360",
    "end": "1274240"
  },
  {
    "text": "my original cluster was using but it won't try and delete any backups for garbage collection or anything like that",
    "start": "1274240",
    "end": "1279550"
  },
  {
    "text": "so it's it's purely restore or read-only mode alright one of the things that arc",
    "start": "1279550",
    "end": "1284920"
  },
  {
    "text": "does if I have if I have backups in a bucket and I point a new cluster at that",
    "start": "1284920",
    "end": "1290500"
  },
  {
    "text": "same bucket all those backups the metadata about them gets synced into the new cluster so here you can see I'm in",
    "start": "1290500",
    "end": "1298330"
  },
  {
    "text": "cluster two and it says I know that this backup called cardi exists which is",
    "start": "1298330",
    "end": "1303340"
  },
  {
    "text": "great this is the migration part so let's say that I want to go ahead and do a migration first we'll check let's make",
    "start": "1303340",
    "end": "1310240"
  },
  {
    "start": "1305000",
    "end": "1335000"
  },
  {
    "text": "sure that I'm not lying to you there is no demo namespace in cluster Tegel so it's not found and then let's restore",
    "start": "1310240",
    "end": "1318070"
  },
  {
    "text": "from backup so I'll run arc restore create and give it the name of the restore that I like to call it and I",
    "start": "1318070",
    "end": "1324130"
  },
  {
    "text": "tell it which backup to create the restore from so this takes a little bit",
    "start": "1324130",
    "end": "1329650"
  },
  {
    "text": "of time not too long because this there's not much in there but we can go",
    "start": "1329650",
    "end": "1336520"
  },
  {
    "text": "ahead and check and see in cluster two if this worked so we have deployments we",
    "start": "1336520",
    "end": "1342910"
  },
  {
    "text": "have the QWERTY deployment we have the service that was restored and we have an",
    "start": "1342910",
    "end": "1348580"
  },
  {
    "text": "ingress for it as well all right so we're gonna go ahead and add cluster two",
    "start": "1348580",
    "end": "1354250"
  },
  {
    "start": "1351000",
    "end": "1365000"
  },
  {
    "text": "as a back-end to my routing cluster so switch back to the router and I'll do",
    "start": "1354250",
    "end": "1360040"
  },
  {
    "text": "our add back-end cluster too and let's see what happened to the ingress here so",
    "start": "1360040",
    "end": "1365920"
  },
  {
    "start": "1365000",
    "end": "1410000"
  },
  {
    "text": "what's important to see let me scroll up just a little bit we have some new",
    "start": "1365920",
    "end": "1371620"
  },
  {
    "text": "annotations so we can wait each back-end in the cluster and we can say I want a",
    "start": "1371620",
    "end": "1377860"
  },
  {
    "text": "hundred percent of the traffic going to one back-end and nothing to any of the other ones or you can divide it up",
    "start": "1377860",
    "end": "1383260"
  },
  {
    "text": "however you'd like one thing that I chose to do for this demo is I want to",
    "start": "1383260",
    "end": "1388510"
  },
  {
    "text": "make sure that the addition of a back end a back end cluster isn't something",
    "start": "1388510",
    "end": "1394930"
  },
  {
    "text": "that automatically puts it in service for receiving traffic so you can see that cluster two has a default weight of",
    "start": "1394930",
    "end": "1400900"
  },
  {
    "text": "zero and it's up to the operator me in this case to decide when it's time to",
    "start": "1400900",
    "end": "1406270"
  },
  {
    "text": "bring cluster two into the actual routing picture so let's give it ten",
    "start": "1406270",
    "end": "1411820"
  },
  {
    "start": "1410000",
    "end": "1421000"
  },
  {
    "text": "percent of traffic so I'm going to run the annotate command with cube control and I'm just changing it to a 90/10",
    "start": "1411820",
    "end": "1417940"
  },
  {
    "text": "split and if we take a look at the ingress you can see ninety and ten and",
    "start": "1417940",
    "end": "1424770"
  },
  {
    "start": "1421000",
    "end": "1444000"
  },
  {
    "text": "if we go look at envoy we can take a look and see envoy has this concept of",
    "start": "1424770",
    "end": "1432580"
  },
  {
    "text": "weighted clusters where you can you can send different amounts of traffic to different backends and so here I have",
    "start": "1432580",
    "end": "1437800"
  },
  {
    "text": "ninety percent going to my cluster one and ten percent going to cluster two so",
    "start": "1437800",
    "end": "1444850"
  },
  {
    "start": "1444000",
    "end": "1482000"
  },
  {
    "text": "let's see if it actually works I'm gonna run the same load testing script again it's hitting QWERTY demo and if",
    "start": "1444850",
    "end": "1452860"
  },
  {
    "text": "everything works this will send about ninety percent of the traffic to my original cluster and ten to the second",
    "start": "1452860",
    "end": "1459160"
  },
  {
    "text": "one and so here you can see the one that ends in dot fifty five was our original cluster and it gets the majority of the",
    "start": "1459160",
    "end": "1465730"
  },
  {
    "text": "traffic if I go into the web browser we can take a look and you'll notice that the name",
    "start": "1465730",
    "end": "1472360"
  },
  {
    "text": "of the pod here if I keep refreshing does eventually change but again because it's the 90/10 split it's going to hit",
    "start": "1472360",
    "end": "1479350"
  },
  {
    "text": "one of them a lot more than it hits the other one alright so now we're happy",
    "start": "1479350",
    "end": "1485500"
  },
  {
    "start": "1482000",
    "end": "1499000"
  },
  {
    "text": "with our our new cluster and we can send all of the traffic to it so I'm changing the weights so that cluster 1 has 0 and",
    "start": "1485500",
    "end": "1492280"
  },
  {
    "text": "cluster 2 gets 100% of it and we can double check the ingress to make sure that that looks good so cluster 2 is at",
    "start": "1492280",
    "end": "1499930"
  },
  {
    "start": "1499000",
    "end": "1507000"
  },
  {
    "text": "100 we can take a look at envoy configuration I'll refresh that and",
    "start": "1499930",
    "end": "1505180"
  },
  {
    "text": "we'll see that cluster 2 is now at 100 and one final test here if we load test",
    "start": "1505180",
    "end": "1511510"
  },
  {
    "text": "it again this will do that same 5 second test and we should see that everything goes to the IP address ending with dot",
    "start": "1511510",
    "end": "1518410"
  },
  {
    "text": "56 and there we go and then finally I",
    "start": "1518410",
    "end": "1526720"
  },
  {
    "text": "can actually delete the cluster 1 back end and this will adjust the ingress so",
    "start": "1526720",
    "end": "1532300"
  },
  {
    "text": "that now there's literally only a single service as a back-end for cluster 2 and",
    "start": "1532300",
    "end": "1538120"
  },
  {
    "text": "if I run the same load test we'll see the same results where it only sends",
    "start": "1538120",
    "end": "1543220"
  },
  {
    "text": "traffic to cluster 2",
    "start": "1543220",
    "end": "1546299"
  },
  {
    "text": "okay that is the end of my demo let me get back over here alright",
    "start": "1551790",
    "end": "1560760"
  },
  {
    "text": "does anyone have any questions I don't",
    "start": "1560760",
    "end": "1566310"
  },
  {
    "text": "know where that mic is that yeah I'll repeat it",
    "start": "1566310",
    "end": "1570890"
  },
  {
    "text": "sure so the question was was my routing demonstration just for traffic coming in",
    "start": "1578580",
    "end": "1585940"
  },
  {
    "text": "from the internet or could it work inside in an intranet for example with",
    "start": "1585940",
    "end": "1593050"
  },
  {
    "text": "service DNS so you can get back to whoops wrong way so when you look at",
    "start": "1593050",
    "end": "1601390"
  },
  {
    "start": "1599000",
    "end": "2078000"
  },
  {
    "text": "this picture this type of setup can work anywhere doesn't have to be on the",
    "start": "1601390",
    "end": "1607540"
  },
  {
    "text": "internet but from a service DNS with the service cluster local DNS that works",
    "start": "1607540",
    "end": "1614260"
  },
  {
    "text": "within a single cluster and this is you know cross clusters one of the things I",
    "start": "1614260",
    "end": "1621160"
  },
  {
    "text": "did look at when I was putting the demo together was maybe trying to use the external named cname support that you",
    "start": "1621160",
    "end": "1626740"
  },
  {
    "text": "have with services and I just didn't get far enough along with it to see if it would work but it's it might anyone else",
    "start": "1626740",
    "end": "1635730"
  },
  {
    "text": "yes all right so the question was what",
    "start": "1635730",
    "end": "1641890"
  },
  {
    "text": "do you need to do when you need or what do you do when you need to upgrade the routing cluster so I would recommend you",
    "start": "1641890",
    "end": "1647170"
  },
  {
    "text": "have to at least and as long as you're using something like keep a live D with",
    "start": "1647170",
    "end": "1653380"
  },
  {
    "text": "a virtual IP for the router itself maybe you add a third cluster so that you know",
    "start": "1653380",
    "end": "1658810"
  },
  {
    "text": "if you lose one and then you don't have one last man standing so yeah keep a live D have a virtual IP and then you",
    "start": "1658810",
    "end": "1665890"
  },
  {
    "text": "can upgrade as you need to and take them in and out of service yes",
    "start": "1665890",
    "end": "1672990"
  },
  {
    "text": "so the question was could we not need the routing cluster and just replicate",
    "start": "1682110",
    "end": "1688080"
  },
  {
    "text": "the routing functionality in two or more clusters and also have the the back-end",
    "start": "1688080",
    "end": "1693570"
  },
  {
    "text": "workloads running there I suppose you could it wasn't something that I was thinking about for this demo but I think",
    "start": "1693570",
    "end": "1699899"
  },
  {
    "text": "with some work we could make it happen in the back",
    "start": "1699899",
    "end": "1707450"
  },
  {
    "text": "right so the question was if you're doing get operations and you have all of",
    "start": "1716549",
    "end": "1722190"
  },
  {
    "text": "your kubernetes configurations for your apps and whatnot in git and you deploy from git",
    "start": "1722190",
    "end": "1727529"
  },
  {
    "text": "how do backups fit in so when we were",
    "start": "1727529",
    "end": "1732719"
  },
  {
    "text": "working on Ark that's a question that comes up a lot and the way that we look",
    "start": "1732719",
    "end": "1738089"
  },
  {
    "text": "at it is get ops is great but if you need to tie in persistent volume backups",
    "start": "1738089",
    "end": "1745459"
  },
  {
    "text": "it's a little iffy so Ark can help you",
    "start": "1745459",
    "end": "1750889"
  },
  {
    "text": "associate backups with your existing workloads and existing things that are",
    "start": "1750889",
    "end": "1756269"
  },
  {
    "text": "running in kubernetes and what we would like to get to if it's not there already",
    "start": "1756269",
    "end": "1761639"
  },
  {
    "text": "is being able to do a backup and restore and then continue to do get ops beyond",
    "start": "1761639",
    "end": "1767369"
  },
  {
    "text": "that point anyone else",
    "start": "1767369",
    "end": "1775519"
  },
  {
    "text": "so the question was does the ark backup handle custom resource definitions or CR",
    "start": "1780320",
    "end": "1785730"
  },
  {
    "text": "DS yes so ark uses API discovery to ask the API",
    "start": "1785730",
    "end": "1791010"
  },
  {
    "text": "server about all the API groups and all the resources that are there and it's able to backup custom resources to",
    "start": "1791010",
    "end": "1799100"
  },
  {
    "text": "question was would it be ok to do the routing cluster only when you need to migrate and then get rid of it",
    "start": "1806900",
    "end": "1814200"
  },
  {
    "text": "afterwards so that for the most part you're just running a single cluster yeah I guess you could it would just",
    "start": "1814200",
    "end": "1821400"
  },
  {
    "text": "depend on how you configure your ingress traffic from the internet or wherever outside the cluster is you know if it's",
    "start": "1821400",
    "end": "1828510"
  },
  {
    "text": "one hop or two you potentially could do that yes our backups encrypted at rest",
    "start": "1828510",
    "end": "1839130"
  },
  {
    "text": "was that the question so Ark supports I believe with a AWS and",
    "start": "1839130",
    "end": "1848360"
  },
  {
    "text": "maybe Azure I'd have to go back and double-check we do support the cloud providers encryption we don't",
    "start": "1848360",
    "end": "1854669"
  },
  {
    "text": "specifically encrypt anything but we've had some requests for that so we're considering it anyone else okay",
    "start": "1854669",
    "end": "1869520"
  },
  {
    "text": "thanks sorry I couldn't see you",
    "start": "1869520",
    "end": "1872630"
  },
  {
    "text": "it was I think I heard you is what's the advantage of having a routing cluster",
    "start": "1882480",
    "end": "1888190"
  },
  {
    "text": "like this instead of using an ingress proxy or a reverse proxy I guess it",
    "start": "1888190",
    "end": "1895480"
  },
  {
    "text": "depends on what functionality you get with the reverse proxy and where you want to control being able to do the the",
    "start": "1895480",
    "end": "1902170"
  },
  {
    "text": "weighting and the traffic shifting the nice thing about this example is you can control it all within kubernetes and",
    "start": "1902170",
    "end": "1909600"
  },
  {
    "text": "again depending on the reverse proxy that you're using you may not have the same sort of administrative capabilities",
    "start": "1909600",
    "end": "1915820"
  },
  {
    "text": "from within the cluster",
    "start": "1915820",
    "end": "1918720"
  },
  {
    "text": "contour with envoy I believe we do I know we do HTTP I know we do TLS or",
    "start": "1927710",
    "end": "1934200"
  },
  {
    "text": "HTTPS I'm not sure about s and I support but it's it's mostly going to be HTTP",
    "start": "1934200",
    "end": "1942179"
  },
  {
    "text": "based or web based yes in the back",
    "start": "1942179",
    "end": "1951018"
  },
  {
    "text": "so the question was databases such as Postgres how do we back those up so arc",
    "start": "1959549",
    "end": "1967210"
  },
  {
    "text": "allows you to run custom hooks before and after we take a snapshot of a volume",
    "start": "1967210",
    "end": "1973090"
  },
  {
    "text": "and that's essentially a queue control exec into your pod so if you need to",
    "start": "1973090",
    "end": "1978580"
  },
  {
    "text": "freeze the file system and then take a snapshot and unfreeze it you can do something like that",
    "start": "1978580",
    "end": "1983830"
  },
  {
    "text": "we've also been considering but we haven't made much progress the concept",
    "start": "1983830",
    "end": "1990159"
  },
  {
    "text": "of something like an application profile or a you know workload profile so that we could tell you could tell arc this",
    "start": "1990159",
    "end": "1997029"
  },
  {
    "text": "pod is a database pod and it's a my sequel pod or a post-grad pod and then we'd have preconceived logic for doing",
    "start": "1997029",
    "end": "2005159"
  },
  {
    "text": "that sort of backup but we're open to any ideas around that it's just something we've only begun thinking",
    "start": "2005159",
    "end": "2011279"
  },
  {
    "text": "about yes",
    "start": "2011279",
    "end": "2017090"
  },
  {
    "text": "okay so the question was is there any concept about moving persistent volumes from one cluster to another so we",
    "start": "2022530",
    "end": "2028800"
  },
  {
    "text": "support that with certain restrictions so if you're running on AWS for example",
    "start": "2028800",
    "end": "2034770"
  },
  {
    "text": "if the persistent volumes are in the same region we should be able to back",
    "start": "2034770",
    "end": "2040830"
  },
  {
    "text": "them up and restore them within a ZZZ in that same region with the other cloud",
    "start": "2040830",
    "end": "2046680"
  },
  {
    "text": "providers that may or may not work but we are going to be adding a replication feature to arc so that you can backup",
    "start": "2046680",
    "end": "2053250"
  },
  {
    "text": "wherever it ends up and then specify via a policy that I'd like to replicate to",
    "start": "2053250",
    "end": "2059790"
  },
  {
    "text": "regions 1 2 & 3 and once that happens you could then restore in any of those",
    "start": "2059790",
    "end": "2065370"
  },
  {
    "text": "regions anyone else all right I will be",
    "start": "2065370",
    "end": "2074370"
  },
  {
    "text": "around for a little bit after thank you very much thank you",
    "start": "2074370",
    "end": "2079490"
  }
]
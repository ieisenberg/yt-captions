[
  {
    "text": "[Music]",
    "start": "16640",
    "end": "19719"
  },
  {
    "text": "hello everyone and welcome to cloud native live where we dive into the call behind",
    "start": "22400",
    "end": "27439"
  },
  {
    "text": "cloud native i'm itai shakuri i'm the director of open source here at aqua security and",
    "start": "27439",
    "end": "32640"
  },
  {
    "text": "i'm also a cncf ambassador and we'll be hosting today's show so uh",
    "start": "32640",
    "end": "37760"
  },
  {
    "text": "cloud native live every week we meet to bring you a new set of presenters that will showcase how to work with cloud native",
    "start": "37760",
    "end": "43680"
  },
  {
    "text": "technologies they will build things they will break things and they will answer your questions",
    "start": "43680",
    "end": "48879"
  },
  {
    "text": "feel free to ask questions as we go along in the chats and we will do our best to answer them",
    "start": "48879",
    "end": "55840"
  },
  {
    "text": "this week we have jason morgan here with us from buoyant to talk about linker d",
    "start": "55840",
    "end": "62480"
  },
  {
    "text": "service mesh before we get started i just want to remind everyone that kubeco north america is",
    "start": "62480",
    "end": "69439"
  },
  {
    "text": "upcoming coming soon in october so if you haven't registered",
    "start": "69439",
    "end": "74720"
  },
  {
    "text": "it's going to be both in person and virtual really looking forward to that uh so",
    "start": "74720",
    "end": "80400"
  },
  {
    "text": "just a quick reminder and a bit of administration i want to remind everyone that this is",
    "start": "80400",
    "end": "87600"
  },
  {
    "text": "an official live stream of the cncf and the such is subject to the cncf code of conduct",
    "start": "87600",
    "end": "93040"
  },
  {
    "text": "so please don't add anything to the chat or questions that would be in violation of that code of conduct",
    "start": "93040",
    "end": "98400"
  },
  {
    "text": "basically just be respectful but just be respect respectful of your fellow participants",
    "start": "98400",
    "end": "103680"
  },
  {
    "text": "and presenters and uh with that uh jason would you like to introduce yourself",
    "start": "103680",
    "end": "109280"
  },
  {
    "text": "yeah hey um thanks for thanks for having me on uh so my name is jason morgan i am a technical evangelist with buoyant",
    "start": "109280",
    "end": "116079"
  },
  {
    "text": "and it's my job to talk to folks about liquor d and try and encourage people to use it and thanks for having",
    "start": "116079",
    "end": "121280"
  },
  {
    "text": "me all right cool um so",
    "start": "121280",
    "end": "126320"
  },
  {
    "text": "we're here to talk about uh um linker d do you want to give a just a one minute background about it",
    "start": "126320",
    "end": "134000"
  },
  {
    "text": "yeah so linker d is a service mesh and it is uh it is built specifically for",
    "start": "134000",
    "end": "139520"
  },
  {
    "text": "kubernetes a service mesh is a tool that you add to your",
    "start": "139520",
    "end": "144560"
  },
  {
    "text": "kubernetes cluster that um that will intercept and you know work with the traffic",
    "start": "144560",
    "end": "152000"
  },
  {
    "text": "between your applications so a service mesh works by adding a number of proxies",
    "start": "152000",
    "end": "157519"
  },
  {
    "text": "beside your applications to handle the traffic between between them and allow you to enhance",
    "start": "157519",
    "end": "164879"
  },
  {
    "text": "them with additional observability features make your request more reliable or more",
    "start": "164879",
    "end": "170000"
  },
  {
    "text": "performant or to um or to add security into the environment like ensuring that",
    "start": "170000",
    "end": "175200"
  },
  {
    "text": "your communications between apps are all mutually authenticated",
    "start": "175200",
    "end": "180959"
  },
  {
    "text": "great so that service mess service machine general and uh did you have a specific um use",
    "start": "181120",
    "end": "187680"
  },
  {
    "text": "case or story that you wanted to cover for today yeah so so liquidy is uh",
    "start": "187680",
    "end": "193440"
  },
  {
    "text": "so today what we're going to go over is multi-cluster linker d so we're going to connect an application",
    "start": "193440",
    "end": "199120"
  },
  {
    "text": "between new york and london using liquid use multi-cluster functionality so we're going to see",
    "start": "199120",
    "end": "206480"
  },
  {
    "text": "how easy it is to set up and and how you would you would reproduce something like this",
    "start": "206480",
    "end": "212319"
  },
  {
    "text": "sounds good all right yeah should we kick off yeah we are all right uh if you don't",
    "start": "212319",
    "end": "219200"
  },
  {
    "text": "mind i'm gonna share screens so give me one second screen two allow",
    "start": "219200",
    "end": "227840"
  },
  {
    "text": "all right uh y'all see my screen okay we see okay all right so i've got two",
    "start": "228319",
    "end": "234000"
  },
  {
    "text": "clusters well i'm going to have two clusters by by the end of this uh we've got a cluster in new york",
    "start": "234000",
    "end": "239040"
  },
  {
    "text": "right so that's the sibo kubernetes new york data center and one in their london data center and",
    "start": "239040",
    "end": "244560"
  },
  {
    "text": "what we're going to do here is we're going to route traffic from our user right in this case top hat person",
    "start": "244560",
    "end": "250239"
  },
  {
    "text": "with the monocle we're going to go over the internet into a traffic ingress through to a",
    "start": "250239",
    "end": "257680"
  },
  {
    "text": "front-end application in that in our kubernetes cluster then linker d is gonna take that",
    "start": "257680",
    "end": "263600"
  },
  {
    "text": "that communication from traffic to the front end to this multi-cluster gateway through",
    "start": "263600",
    "end": "269759"
  },
  {
    "text": "a a layer 7 connection between these two gateways and then over to a back end sitting",
    "start": "269759",
    "end": "276160"
  },
  {
    "text": "there in london so we're going to deploy an app we're going to deploy some clusters we're going to show the front end not working until we",
    "start": "276160",
    "end": "282400"
  },
  {
    "text": "connect it to the back end over in london and that's that's what i've got for slides so we can hop over to a demo",
    "start": "282400",
    "end": "289280"
  },
  {
    "text": "so the scenario is that the application is kind of spread across",
    "start": "289280",
    "end": "294320"
  },
  {
    "text": "two regions or something like that that's not like uh um this is supposed to be like",
    "start": "294320",
    "end": "300160"
  },
  {
    "text": "components of the same application right that we're uh yeah yeah so we've got the front end and a back end for this application",
    "start": "300160",
    "end": "306240"
  },
  {
    "text": "and we need to connect the front end to the back end to make it work and the back end is living in our london data",
    "start": "306240",
    "end": "311759"
  },
  {
    "text": "center right so this isn't this in particular one is a bit contrived just so it's easy to",
    "start": "311759",
    "end": "316800"
  },
  {
    "text": "easy to demo right a more common use case might be like uh you know i've seen examples of",
    "start": "316800",
    "end": "322320"
  },
  {
    "text": "folks that you know they have an application that the scale is so massive that it needs to live in its own cluster so they use",
    "start": "322320",
    "end": "328479"
  },
  {
    "text": "multi-cluster to connect you know one app to another um in that circumstance or another one might be",
    "start": "328479",
    "end": "334880"
  },
  {
    "text": "like we've got got a customer who is centralizing their their common functionality like logging",
    "start": "334880",
    "end": "341280"
  },
  {
    "text": "and mattress collection in a single cluster and then they they essentially add their add their logging and",
    "start": "341280",
    "end": "348479"
  },
  {
    "text": "monitoring agents to the maps and the other clusters and send messages through to this central",
    "start": "348479",
    "end": "353600"
  },
  {
    "text": "cluster so that the individual application clusters don't have to worry about running log stash and and",
    "start": "353600",
    "end": "359680"
  },
  {
    "text": "prometheus and things like that make sense yep thanks all right",
    "start": "359680",
    "end": "367520"
  },
  {
    "text": "so let's get started so the first thing i'm going to do is i'm going to use um i'm going to use the sibo cli to create",
    "start": "367520",
    "end": "373280"
  },
  {
    "text": "a couple clusters so let's do that here can you see my terminal okay",
    "start": "373280",
    "end": "378880"
  },
  {
    "text": "yes so what i'm doing here is i'm creating a cluster called nyc2 uh with onenote and it's",
    "start": "378880",
    "end": "386400"
  },
  {
    "text": "going to be small class there and then we're going to wait for that to finish then we're going to do something similar",
    "start": "386400",
    "end": "391680"
  },
  {
    "text": "in london so the terminal on my left is going to be my new york cluster the terminal on my",
    "start": "391680",
    "end": "397120"
  },
  {
    "text": "right is going to be my london cluster",
    "start": "397120",
    "end": "401680"
  },
  {
    "text": "so while those spin up we'll get going so that the the first thing i have to do",
    "start": "402479",
    "end": "409759"
  },
  {
    "text": "to um to use lingerie in a multi-cluster manner is i have to generate certificates for",
    "start": "409759",
    "end": "416639"
  },
  {
    "text": "linker d uh that use a shared trust route so what happens is i've got these two",
    "start": "416639",
    "end": "422319"
  },
  {
    "text": "clusters and we're gonna we're gonna do mutually authenticated traffic from one cluster to the other",
    "start": "422319",
    "end": "427599"
  },
  {
    "text": "so they all have to trust a common a common certificate common root certificate so that they can they can do that so",
    "start": "427599",
    "end": "434160"
  },
  {
    "text": "we're gonna use a tool called step to generate a root certificate and then two different intermediate",
    "start": "434160",
    "end": "441360"
  },
  {
    "text": "uh ur certificates so step and back linker d has a component that",
    "start": "441360",
    "end": "446880"
  },
  {
    "text": "automatically generates a new certificate for every application inside inside your kubernetes cluster that's part of the",
    "start": "446880",
    "end": "452479"
  },
  {
    "text": "mesh right and it generates that certificate with this with this issuer certificate that it has",
    "start": "452479",
    "end": "459759"
  },
  {
    "text": "um so that's going to be our step now is the is to make both",
    "start": "459759",
    "end": "464800"
  },
  {
    "text": "issuers trust the same route so they'll so one issuer will trust certificates from the other",
    "start": "464800",
    "end": "471599"
  },
  {
    "text": "i'm going to use a tool called step to do that we're just going to go ahead and short circuit this because it's taking a second um so while these clusters create oh",
    "start": "473680",
    "end": "481840"
  },
  {
    "text": "there you go i just got impatient we're going to go ahead and generate a new root certificate so first i'm going to just move into a temp directory",
    "start": "481840",
    "end": "490400"
  },
  {
    "text": "just make sure it's empty so we've got an empty temp directory and we're going to create a new root ca so i've got this tool called step",
    "start": "490800",
    "end": "496479"
  },
  {
    "text": "it's basically just an easier way to do openssl if you're not already good at open ssl",
    "start": "496479",
    "end": "501680"
  },
  {
    "text": "i can send a link to it um it's also under our multi-cluster docs let me actually pull this over",
    "start": "501680",
    "end": "508160"
  },
  {
    "text": "uh we're gonna follow generally this this multi-cluster tutorial uh that you can find right here i don't",
    "start": "508160",
    "end": "515039"
  },
  {
    "text": "know is it already put in the chat or what's the best way to share that app",
    "start": "515039",
    "end": "521839"
  },
  {
    "text": "if you could just uh put it in uh some some something's larger yeah okay",
    "start": "523680",
    "end": "530959"
  },
  {
    "text": "we will try to put it on the screen as well okay cool so we're essentially following that um",
    "start": "530959",
    "end": "537279"
  },
  {
    "text": "that tutorial here which has all the steps for all the all the commands for how we do something like set so",
    "start": "537279",
    "end": "543519"
  },
  {
    "text": "we're going to create a new root certificate right here uh so with this root certificate we can",
    "start": "543519",
    "end": "548880"
  },
  {
    "text": "now create an issuer so i'm going to create one issuer for new york and one issuer for london so let's do",
    "start": "548880",
    "end": "555360"
  },
  {
    "text": "that so here i'm creating a uh a certificate",
    "start": "555360",
    "end": "562880"
  },
  {
    "text": "for identity.linkery.cluster.local the issuer is going to be called",
    "start": "562880",
    "end": "567959"
  },
  {
    "text": "issuer.london.crt um and we're using the we're using the root ca that we just created",
    "start": "567959",
    "end": "577839"
  },
  {
    "text": "all right so we've got we've got our one issuer now we're going to create the other for london",
    "start": "579279",
    "end": "591279"
  },
  {
    "text": "all right so if we look in our directory now we've got uh we've got the routier a new york issuer",
    "start": "591279",
    "end": "597519"
  },
  {
    "text": "and a london issuer",
    "start": "597519",
    "end": "604240"
  },
  {
    "text": "um let's go ahead and export some cube configs",
    "start": "604240",
    "end": "610720"
  },
  {
    "text": "so we're going to use the sivo cli again just to generate a generate a new cube config save it off",
    "start": "611760",
    "end": "620800"
  },
  {
    "text": "and then we're going to do export queue config",
    "start": "621120",
    "end": "626480"
  },
  {
    "text": "let's escape that",
    "start": "626480",
    "end": "633839"
  },
  {
    "text": "right so i can do okay get nodes right we can see i've got i've got my node it's a you know it's",
    "start": "634000",
    "end": "640640"
  },
  {
    "text": "got this node name right it's in our in our civo new york data center i'm going to create one for london",
    "start": "640640",
    "end": "647680"
  },
  {
    "text": "oops here's our command",
    "start": "647680",
    "end": "651600"
  },
  {
    "text": "so we're grabbing our config now for the london plus there and then export cube",
    "start": "653200",
    "end": "660959"
  },
  {
    "text": "config [Music]",
    "start": "660959",
    "end": "665299"
  },
  {
    "text": "all right so you should be able to see in my terminal right here in the prompt it's going to tell you what what kubernetes cluster",
    "start": "669360",
    "end": "676000"
  },
  {
    "text": "and what name space we're in right just so you've got a sense of where we're working so again we're sticking the left side is going to be",
    "start": "676000",
    "end": "681760"
  },
  {
    "text": "new york the right side is going to be london um so now we need to",
    "start": "681760",
    "end": "689200"
  },
  {
    "text": "install linker d right so we're using the linkery cli to actually do the install",
    "start": "689200",
    "end": "694480"
  },
  {
    "text": "so by default the linker dcli is going to generate new certificates for you every time in this case we want it to use that",
    "start": "694480",
    "end": "702000"
  },
  {
    "text": "the certificate that i created so we're giving you commands us what's the what's the root ca what are",
    "start": "702000",
    "end": "708079"
  },
  {
    "text": "your identity certificates going to be so that you can create this environment and then we're going to go ahead and",
    "start": "708079",
    "end": "713600"
  },
  {
    "text": "and apply the apply the the resulting yaml to our cluster then we're",
    "start": "713600",
    "end": "720079"
  },
  {
    "text": "also going to run a liquidity check at the end so we know what's happening so here's the new york install with the",
    "start": "720079",
    "end": "725200"
  },
  {
    "text": "new york certificates we're going to do the same thing for london",
    "start": "725200",
    "end": "731839"
  },
  {
    "text": "and we'll let that let that install run",
    "start": "739519",
    "end": "745839"
  },
  {
    "text": "any any questions as we're going still making sense so far so we've bootstrapped we've bootstrapped",
    "start": "746880",
    "end": "753360"
  },
  {
    "text": "empty kubernetes clusters so sibo they're a kubernetes service provider or they're actually a whole",
    "start": "753360",
    "end": "758399"
  },
  {
    "text": "infrastructure service provider but we're using their kubernetes of service offering we're spinning up a k3s cluster in these",
    "start": "758399",
    "end": "764160"
  },
  {
    "text": "two data centers right now i'm installing liquidity so there's no there's no apps here beyond the default",
    "start": "764160",
    "end": "769519"
  },
  {
    "text": "the default traffic instance installs with uh with k3s",
    "start": "769519",
    "end": "775200"
  },
  {
    "text": "uh we did our install and we used the liquidity check command just to validate that you know the install took correctly",
    "start": "779440",
    "end": "784880"
  },
  {
    "text": "right and then we're ready to go on this class there now we're going to add on so liquid has components right so we installed core",
    "start": "784880",
    "end": "790720"
  },
  {
    "text": "linker d which is the functions of the mesh that you need to actually do work right so that's that's you know add in",
    "start": "790720",
    "end": "796639"
  },
  {
    "text": "the proxy beside your applications that's give the proxy certificates you know that common components like that",
    "start": "796639",
    "end": "803600"
  },
  {
    "text": "but we have are what we need to do multi-cluster or what we need for a dashboard so we're going to install those next",
    "start": "803600",
    "end": "809519"
  },
  {
    "text": "so we're going to do the the multi-cluster install so let me just clear this up so lingerie multi-cluster install and",
    "start": "809519",
    "end": "816000"
  },
  {
    "text": "again we're just going to send that over to k apply dash f and then we'll do the same",
    "start": "816000",
    "end": "821440"
  },
  {
    "text": "thing on the other side so we're installing in london that was pretty fast actually and",
    "start": "821440",
    "end": "827040"
  },
  {
    "text": "now we're gonna do the same thing in or sorry we did it in new york now we're doing it in london uh we're also gonna go ahead and install",
    "start": "827040",
    "end": "833279"
  },
  {
    "text": "the linkery dashboard so that we can pop up in a dashboard if we want right so this is the visualization component so it's got a prometheus a",
    "start": "833279",
    "end": "839839"
  },
  {
    "text": "grafana as well as the lingerie dashboard so you can you can view things in a nice ui but this is not part of the default",
    "start": "839839",
    "end": "846160"
  },
  {
    "text": "linkery install as of like a g210",
    "start": "846160",
    "end": "850480"
  },
  {
    "text": "right so the goal with clicker d is to be an extremely lightweight extremely fast extremely easy to use",
    "start": "852240",
    "end": "858240"
  },
  {
    "text": "service mesh right like trying to make it as low complexity as possible so in general like this the setup of",
    "start": "858240",
    "end": "866079"
  },
  {
    "text": "connecting clusters between regions can be fairly difficult but what we do is you know with the routing we do",
    "start": "866079",
    "end": "872320"
  },
  {
    "text": "we do a layer 7 connection so i didn't set up any special routing rules between london new york right this is any two",
    "start": "872320",
    "end": "878800"
  },
  {
    "text": "places that can make an https connection between each other we can set up we can bridge",
    "start": "878800",
    "end": "884160"
  },
  {
    "text": "clusters over that connection right there's there's no like no special stuff that you need to",
    "start": "884160",
    "end": "889839"
  },
  {
    "text": "do to make that work right the only the only complex part is ensuring that",
    "start": "889839",
    "end": "895600"
  },
  {
    "text": "all of your linker d instances use the same certificate",
    "start": "895600",
    "end": "901600"
  },
  {
    "text": "or use the same root certificate excuse",
    "start": "904079",
    "end": "908000"
  },
  {
    "text": "me",
    "start": "910839",
    "end": "913839"
  },
  {
    "text": "i guess maybe people would assume that they would need to create some kind of",
    "start": "919360",
    "end": "924560"
  },
  {
    "text": "network level uh tunnel between the the data centers",
    "start": "924560",
    "end": "929839"
  },
  {
    "text": "to to make the connectivity work between the the pods between the services but the",
    "start": "929839",
    "end": "936560"
  },
  {
    "text": "service mesh obstructs that yeah absolutely right so all we're gonna do is inside of our app",
    "start": "936560",
    "end": "942720"
  },
  {
    "text": "we're just gonna i'll show you exactly what we're doing but we're making just a dns call to the appropriate service and then it's",
    "start": "942720",
    "end": "948079"
  },
  {
    "text": "gonna route traffic for us automatically there'll be no like there's no special objects created it's still just",
    "start": "948079",
    "end": "954240"
  },
  {
    "text": "a kubernetes service right and once you're in the mesh you can use a kubernetes service that to talk in that way",
    "start": "954240",
    "end": "959839"
  },
  {
    "text": "so we now have we now have liquidity in each thing so let's just do a quick step so k",
    "start": "959839",
    "end": "965040"
  },
  {
    "text": "get pods okay get pods dash a so we're just going to look at",
    "start": "965040",
    "end": "970320"
  },
  {
    "text": "all the pods we have on this cluster make a little bit smaller and let it again uh",
    "start": "970320",
    "end": "975759"
  },
  {
    "text": "you know we've got our our cube system installed so we've got standard stuff as well as some some sibo",
    "start": "975759",
    "end": "982000"
  },
  {
    "text": "some sibo components we've got linker d right so we have the identity the proxy",
    "start": "982000",
    "end": "987519"
  },
  {
    "text": "injector and our destination service that's our core linker d components um for multi-cluster we have our linker",
    "start": "987519",
    "end": "994160"
  },
  {
    "text": "d gateway so this is the actual this is the actual ingress point so again let's look at our",
    "start": "994160",
    "end": "1000079"
  },
  {
    "text": "diagram so what we have right now is we have the new york and london clusters we have traffic we",
    "start": "1000079",
    "end": "1005839"
  },
  {
    "text": "actually have traffic in both but i'm only showing in the one because this is the ingress we're going to be using and we have these gateways but what we",
    "start": "1005839",
    "end": "1011839"
  },
  {
    "text": "haven't done is told these gateways to talk to each other right so that's the that's the next step",
    "start": "1011839",
    "end": "1018320"
  },
  {
    "text": "so we're going to link these clusters as our as our next as our next next",
    "start": "1018320",
    "end": "1023440"
  },
  {
    "text": "component so let's do that",
    "start": "1023440",
    "end": "1028720"
  },
  {
    "text": "sure i want to do it on this side okay so",
    "start": "1029079",
    "end": "1036720"
  },
  {
    "text": "let's talk about what we just ran there um",
    "start": "1036720",
    "end": "1041519"
  },
  {
    "text": "so what we're running is a command linker d multi-cluster link right so we're saying hey we're going to",
    "start": "1042240",
    "end": "1047600"
  },
  {
    "text": "link this uh this london kubernetes cluster right we're going to generate we're",
    "start": "1047600",
    "end": "1053679"
  },
  {
    "text": "going to generate a yaml manifest let's actually run that again um we'll run that again",
    "start": "1053679",
    "end": "1060799"
  },
  {
    "text": "oh yeah okay so i can just run it again so what we do when we run the first part of that command is we just generate",
    "start": "1072400",
    "end": "1077440"
  },
  {
    "text": "we generate the pot security policies services and um and service accounts role",
    "start": "1077440",
    "end": "1084080"
  },
  {
    "text": "bindings that sort of stuff the permissions that we need to tell one cluster can talk together then we need to apply it",
    "start": "1084080",
    "end": "1090240"
  },
  {
    "text": "so from the london cluster i need to generate this yaml and apply it over on the kubernetes cluster so now i can do linker d multi-cluster",
    "start": "1090240",
    "end": "1098640"
  },
  {
    "text": "gateway and see you know okay my new york cluster now",
    "start": "1098640",
    "end": "1104720"
  },
  {
    "text": "sees the london cluster right it sees that link",
    "start": "1104720",
    "end": "1110160"
  },
  {
    "text": "go look at our london cluster",
    "start": "1110160",
    "end": "1113679"
  },
  {
    "text": "right and it doesn't have any peers so what we what we've done is we've given new york access to london but we haven't",
    "start": "1118640",
    "end": "1125360"
  },
  {
    "text": "given london access to new york because in our case we don't need it it's not bi-directional our front end is going to live",
    "start": "1125360",
    "end": "1130960"
  },
  {
    "text": "in new york and it's going to talk to london and that's that's the end of that story",
    "start": "1130960",
    "end": "1137840"
  },
  {
    "text": "so now uh now we've got we've got our gateways connected right and again it's a it's a one-way",
    "start": "1138880",
    "end": "1145120"
  },
  {
    "text": "connection here [Music] so we built this",
    "start": "1145120",
    "end": "1151840"
  },
  {
    "text": "uh we built this connection here um so that we've got our our link set up that's what we did with that",
    "start": "1153840",
    "end": "1159120"
  },
  {
    "text": "multi-cluster link command now we can actually",
    "start": "1159120",
    "end": "1164480"
  },
  {
    "text": "start deploying some applications so here on my new york cluster i'm going",
    "start": "1164480",
    "end": "1169840"
  },
  {
    "text": "to deploy my front end application [Music] uh and then we'll take a look at the ammo after we do that oops",
    "start": "1169840",
    "end": "1179840"
  },
  {
    "text": "all right we're just going to go back to our root directory uh so we uh",
    "start": "1182000",
    "end": "1188320"
  },
  {
    "text": "we've created the frontend app and we're going to look at what all we we made there i'm just going to go deploy the app on the other side as well",
    "start": "1188320",
    "end": "1195600"
  },
  {
    "text": "so on the first side i deployed i deployed my front end web app which is just a little nginx instance and over here i'm going to deploy an app",
    "start": "1198960",
    "end": "1205280"
  },
  {
    "text": "called pod info to this cluster right it's going to get me my backend service which is which is pod info so",
    "start": "1205280",
    "end": "1211919"
  },
  {
    "text": "we're creating a name space a service a deployment an hpa which i don't really need in ingress which i",
    "start": "1211919",
    "end": "1218159"
  },
  {
    "text": "don't really need either um and then on this side if i do k get all",
    "start": "1218159",
    "end": "1225600"
  },
  {
    "text": "right oh i'm in the wrong name space k s pod right i can see",
    "start": "1225600",
    "end": "1232320"
  },
  {
    "text": "like okay get deploy right i've got one deployment front end it's",
    "start": "1232320",
    "end": "1237679"
  },
  {
    "text": "not ready i can look at our pods same thing right like it's it's failing",
    "start": "1237679",
    "end": "1243360"
  },
  {
    "text": "right we'll we'll look at why here in a second and we can check out our services",
    "start": "1243360",
    "end": "1249840"
  },
  {
    "text": "right we've got our we've got our front end service and we have an ingress gonna get ingress um",
    "start": "1250000",
    "end": "1258080"
  },
  {
    "text": "right where nothing's going to nothing's going to uh or it's it's set up to to wrap to our",
    "start": "1258080",
    "end": "1263600"
  },
  {
    "text": "front end so here let's just do so yaml let's look at this so it's basically",
    "start": "1263600",
    "end": "1269360"
  },
  {
    "text": "saying anything that comes in to this uh this application i want you to send it to the front end app right on port 8080",
    "start": "1269360",
    "end": "1277520"
  },
  {
    "text": "and we can actually look at this ip",
    "start": "1277520",
    "end": "1281120"
  },
  {
    "text": "make an http call and we see that you know the service is unavailable right because the pod that's going to",
    "start": "1285760",
    "end": "1291200"
  },
  {
    "text": "populate that service isn't working and let's talk about why",
    "start": "1291200",
    "end": "1305840"
  },
  {
    "text": "so if we look i created a namespace i said i said on the namespace linker d inject so i told i told",
    "start": "1308240",
    "end": "1314400"
  },
  {
    "text": "kubernetes or i really i told liquidity that anything that gets created in this namespace i want to i want to add in my proxy to it or cause",
    "start": "1314400",
    "end": "1321039"
  },
  {
    "text": "i want to be part of the network then i've got a little config for this nginx instance so my front is really just a little enginex server",
    "start": "1321039",
    "end": "1327679"
  },
  {
    "text": "right and so we set up a config and we're telling it talk to talk to this um this address right uh",
    "start": "1327679",
    "end": "1334240"
  },
  {
    "text": "hcp pod info dash lon um on port 9898 right so what's happening",
    "start": "1334240",
    "end": "1341440"
  },
  {
    "text": "is because there's no service no valid service for pod info in this class there it's not",
    "start": "1341440",
    "end": "1347360"
  },
  {
    "text": "able to hit the back end so it's crashing right that's why we're that's why we're at work our failure and then otherwise i just",
    "start": "1347360",
    "end": "1353600"
  },
  {
    "text": "have the config for um i just have the config for the rest of my my front end right um",
    "start": "1353600",
    "end": "1361760"
  },
  {
    "text": "let's go back to that link command really quick so the link command one of the things that we do is we specify the cluster name right so",
    "start": "1361760",
    "end": "1369520"
  },
  {
    "text": "so when we export a service from one cluster to another the service name gets appended with",
    "start": "1369520",
    "end": "1376159"
  },
  {
    "text": "uh gets appended with like a dash and then a cluster name so that you know where it's from and so",
    "start": "1376159",
    "end": "1381760"
  },
  {
    "text": "if you look at the pod info config you know uh the nginx instance is looking for pod info dash",
    "start": "1381760",
    "end": "1388000"
  },
  {
    "text": "lawn lon or london right here our cluster name is line so that's how we're gonna so we're gonna get that service in",
    "start": "1388000",
    "end": "1396400"
  },
  {
    "text": "q control l l uh so if i do take it service on this",
    "start": "1396559",
    "end": "1402880"
  },
  {
    "text": "side i've got sorry i need to change namespaces and that's on info",
    "start": "1402880",
    "end": "1410080"
  },
  {
    "text": "uh i've got a pod info service but we don't see it we see it on our",
    "start": "1410559",
    "end": "1415919"
  },
  {
    "text": "london cluster but not on our new york bus there right um we don't have it so we actually",
    "start": "1415919",
    "end": "1421919"
  },
  {
    "text": "have to we accept the change or edit the pod info service to export it right tell linker d to",
    "start": "1421919",
    "end": "1428960"
  },
  {
    "text": "share it between share it between these clusters so that's what we're going to do next still making sense seem reasonable to",
    "start": "1428960",
    "end": "1437600"
  },
  {
    "text": "follow along and and that if you check out that multi-cluster link that we put in the chat that will",
    "start": "1437600",
    "end": "1443679"
  },
  {
    "text": "that will have these steps in a lot more a lot more depth so you can go at your own pace [Music]",
    "start": "1443679",
    "end": "1451540"
  },
  {
    "text": "awesome so let's do okay edit service pod info",
    "start": "1452159",
    "end": "1460320"
  },
  {
    "text": "so here what i'm going to do is i'm just going to add a label to the service right so we have to instruct",
    "start": "1462240",
    "end": "1467679"
  },
  {
    "text": "the liberty multi-cluster what services we want to share out right so we'll do that by adding a label",
    "start": "1467679",
    "end": "1477200"
  },
  {
    "text": "and just so i don't type it wrong i saved it off to the side",
    "start": "1478640",
    "end": "1487840"
  },
  {
    "text": "yeah so it is mirror",
    "start": "1494720",
    "end": "1500960"
  },
  {
    "text": "linker d dot io slash exported",
    "start": "1500960",
    "end": "1508640"
  },
  {
    "text": "and then equal to true right so i just add a label telling telling liquidity the liberty",
    "start": "1508720",
    "end": "1516320"
  },
  {
    "text": "multi-cluster component that this service should be shared from london to new york",
    "start": "1516320",
    "end": "1522799"
  },
  {
    "text": "so with that edit we're going to see a new service appear",
    "start": "1524480",
    "end": "1530880"
  },
  {
    "text": "called pod info london right or lun i really should have called it london uh and then we'll do a watch",
    "start": "1530880",
    "end": "1537760"
  },
  {
    "text": "cube ctl get pods and we're going to see this we're going to see this front end service go from a failure state",
    "start": "1537760",
    "end": "1544799"
  },
  {
    "text": "to succeeding and we're going to see our app go from no connection to a connection",
    "start": "1544799",
    "end": "1550640"
  },
  {
    "text": "between new york and london",
    "start": "1550640",
    "end": "1557840"
  },
  {
    "text": "any second now",
    "start": "1560799",
    "end": "1563600"
  },
  {
    "text": "uh any questions or waiting yeah i don't see anything coming up on",
    "start": "1569279",
    "end": "1574400"
  },
  {
    "text": "the chat um i guess it was a really good demo",
    "start": "1574400",
    "end": "1580240"
  },
  {
    "text": "everything was clear and uh yeah let's see the magic happens",
    "start": "1580240",
    "end": "1587840"
  },
  {
    "text": "all right well then i'm gonna show the next thing i'm gonna show is you know so we've got um",
    "start": "1588080",
    "end": "1596159"
  },
  {
    "text": "we've got this going i could restart it but it does it just picks it up on its own i guess it's just like crashed",
    "start": "1596559",
    "end": "1603440"
  },
  {
    "text": "yeah um we'll go ahead we'll bring it out okay delete pod whatever",
    "start": "1603600",
    "end": "1613840"
  },
  {
    "text": "yeah right so now we'll see the new one come up and it's going to start",
    "start": "1614000",
    "end": "1619120"
  },
  {
    "text": "successfully because it's got it's got a back end you don't actually have to delete it but i didn't want to wait for the crash loop",
    "start": "1619120",
    "end": "1624720"
  },
  {
    "text": "back off so now we're two of two running right so we see a success and if i go back to this page",
    "start": "1624720",
    "end": "1632799"
  },
  {
    "text": "instead of seeing service available i've got hello from london right as our as our back end over in",
    "start": "1632799",
    "end": "1639360"
  },
  {
    "text": "london hey mate our back end over in london has now um has now connected and we're sending",
    "start": "1639360",
    "end": "1646720"
  },
  {
    "text": "traffic",
    "start": "1646720",
    "end": "1649039"
  },
  {
    "text": "awesome yeah so what we can do seeing is we have way more time than i thought we had uh we can take a look over at",
    "start": "1652320",
    "end": "1659360"
  },
  {
    "text": "so i also did this earlier right and i created an environment left it left it actually run for a while",
    "start": "1659360",
    "end": "1664720"
  },
  {
    "text": "and i connected those to point cloud so point cloud is a linguity commerce a commercial product",
    "start": "1664720",
    "end": "1670880"
  },
  {
    "text": "around lingerie that point created to make it easier to do you know multi-cluster management or just to",
    "start": "1670880",
    "end": "1676799"
  },
  {
    "text": "check on the health of your linkedin instances it's free for up to 50 50 workloads",
    "start": "1676799",
    "end": "1682080"
  },
  {
    "text": "right so i connected my two sibo clusters in we can look at and look at what's been going on with",
    "start": "1682080",
    "end": "1687600"
  },
  {
    "text": "with the ones that we created previously um so the thing i want to show you",
    "start": "1687600",
    "end": "1693919"
  },
  {
    "text": "is this trust root thing right so",
    "start": "1693919",
    "end": "1698720"
  },
  {
    "text": "thanks time um so what we've got here like one of the things you want to ensure when you're doing multi-cluster",
    "start": "1699760",
    "end": "1705919"
  },
  {
    "text": "is is to make that connection work between between multiple clusters the the key",
    "start": "1705919",
    "end": "1711360"
  },
  {
    "text": "component right i stress that a bunch but it it's one that is really worth remembering right i have to share",
    "start": "1711360",
    "end": "1717520"
  },
  {
    "text": "that common trust root so here i can easily identify what my trust rate is by its by its signature and ensure that they",
    "start": "1717520",
    "end": "1724399"
  },
  {
    "text": "match right uh and that's that's the big component in",
    "start": "1724399",
    "end": "1729520"
  },
  {
    "text": "um that's the big component in uh making this work then we can do some",
    "start": "1729520",
    "end": "1735760"
  },
  {
    "text": "fun stuff like like right now if we go look at the workload right so if i go check out you know the actual stuff we could sort",
    "start": "1735760",
    "end": "1742559"
  },
  {
    "text": "by http metrics i could sort by requests let's go see it this way right the",
    "start": "1742559",
    "end": "1749200"
  },
  {
    "text": "things that are really getting hammered so i've got a traffic generator out there so we look at this this thing what i also have is this",
    "start": "1749200",
    "end": "1754559"
  },
  {
    "text": "traffic generator service over in um over in london which is actually hitting",
    "start": "1754559",
    "end": "1759919"
  },
  {
    "text": "this traffic in grass sending a message from traffic",
    "start": "1759919",
    "end": "1765679"
  },
  {
    "text": "over to our front end right and then we go from the front end",
    "start": "1765679",
    "end": "1773360"
  },
  {
    "text": "to our gateway and then we go from gateway",
    "start": "1773360",
    "end": "1780320"
  },
  {
    "text": "over to our back end here we'll make it curve around a little bit if you haven't seen it scala draw is a",
    "start": "1780320",
    "end": "1786320"
  },
  {
    "text": "great tool it's free and you can do nice little diagrams right so now our now our user can send a message",
    "start": "1786320",
    "end": "1795840"
  },
  {
    "text": "over to our traffic ingress and it will get routed appropriately from new york to london right and back",
    "start": "1796559",
    "end": "1805200"
  },
  {
    "text": "and here right i can see the i can see the data on you know my my requests and successes in",
    "start": "1807360",
    "end": "1813039"
  },
  {
    "text": "this environment and if i do something a little bit uh a little bit destructive",
    "start": "1813039",
    "end": "1818480"
  },
  {
    "text": "i can go i can go start generating a bunch of errors or failures right so say we had",
    "start": "1818480",
    "end": "1823840"
  },
  {
    "text": "you know a change to our front end or change to our back end right we started we started sending we",
    "start": "1823840",
    "end": "1828880"
  },
  {
    "text": "started throwing up occasional errors what we're going to see is that data reflected in in the actual live traffic in our",
    "start": "1828880",
    "end": "1836159"
  },
  {
    "text": "apps so i can see that pod info is starting to send some 500s that's cascading down to the front end",
    "start": "1836159",
    "end": "1842320"
  },
  {
    "text": "which is going over to traffic right we can also introduce so latency still looks good but we're seeing we're",
    "start": "1842320",
    "end": "1848240"
  },
  {
    "text": "seeing some errors get introduced right but our request volume is also going up",
    "start": "1848240",
    "end": "1853440"
  },
  {
    "text": "and then we can add something like like a delay right where for whatever reason as traffic goes up",
    "start": "1853440",
    "end": "1858960"
  },
  {
    "text": "we're also seeing a delay what we're going to see is this latency also start to spike as we inject issues",
    "start": "1858960",
    "end": "1864799"
  },
  {
    "text": "into our environment right or as as we have issues in our environment",
    "start": "1864799",
    "end": "1870080"
  },
  {
    "text": "yeah that's really nice um since there are no questions coming up maybe i can",
    "start": "1870559",
    "end": "1876000"
  },
  {
    "text": "add a few yes um i thought you used here uh traffic for",
    "start": "1876000",
    "end": "1882240"
  },
  {
    "text": "uh the ingress is there any relationship between",
    "start": "1882240",
    "end": "1887440"
  },
  {
    "text": "traffic and uh and linker d or is it just you know just you want to choose something that you liked yeah so you",
    "start": "1887440",
    "end": "1894159"
  },
  {
    "text": "actually asked me at the beginning what was different about linker d right so linkery unlike unlike some other service meshes",
    "start": "1894159",
    "end": "1901039"
  },
  {
    "text": "is just focused on the in-cluster traffic or multi-cluster traffic if we're",
    "start": "1901039",
    "end": "1906559"
  },
  {
    "text": "connecting clusters but essentially the traffic inside the mesh what we don't care for or what we don't",
    "start": "1906559",
    "end": "1912240"
  },
  {
    "text": "worry about in liquidity is how the traffic gets from the internet into your application and so we work with traffic we work with",
    "start": "1912240",
    "end": "1919760"
  },
  {
    "text": "ambassador nginx or whatever the ingress is that you're using uh like we'll we'll connect to it and and",
    "start": "1919760",
    "end": "1926000"
  },
  {
    "text": "bring traffic into the match and we actually did kind of a detailed session with the",
    "start": "1926000",
    "end": "1931200"
  },
  {
    "text": "folks over at sivo on you know kind of the the do's and don'ts and hows and whys of integrating",
    "start": "1931200",
    "end": "1937679"
  },
  {
    "text": "your ingress with your mesh so that was a a bit of a of a um a loop at the time",
    "start": "1937679",
    "end": "1944960"
  },
  {
    "text": "sorry the um the answer is we don't have any special integration with traffic",
    "start": "1944960",
    "end": "1950159"
  },
  {
    "text": "traffic works great with laker dd uh as does as far as i can tell like every every",
    "start": "1950159",
    "end": "1955760"
  },
  {
    "text": "ingress i've worked with we haven't had a problem integrating right there um",
    "start": "1955760",
    "end": "1961279"
  },
  {
    "text": "you know there's some details about the way ingress works that that makes the",
    "start": "1961279",
    "end": "1966720"
  },
  {
    "text": "integration slightly different by the actual ingress controller but they're they're all supported",
    "start": "1966720",
    "end": "1973200"
  },
  {
    "text": "cool very cool what are the other uh use cases we've",
    "start": "1973200",
    "end": "1978240"
  },
  {
    "text": "seen multi-cluster we've seen um metrics being uh reported collected",
    "start": "1978240",
    "end": "1984000"
  },
  {
    "text": "like error rates uh latencies and so on are there any other risk cases for uh",
    "start": "1984000",
    "end": "1989200"
  },
  {
    "text": "linkedin well so like the if you step back right like the reason that to use a service mesh",
    "start": "1989200",
    "end": "1994799"
  },
  {
    "text": "right is that like like it's kind of why you go to kubernetes right you go to kubernetes because you want ultimately you have an",
    "start": "1994799",
    "end": "2001039"
  },
  {
    "text": "objective right and that objective is i want my business logic inside my applications to work and work well and",
    "start": "2001039",
    "end": "2006799"
  },
  {
    "text": "work work reliably when i need it to work right so so linker d is there to",
    "start": "2006799",
    "end": "2012399"
  },
  {
    "text": "allow developers who are working on a platform that includes linker d to focus more on business logic and less",
    "start": "2012399",
    "end": "2020000"
  },
  {
    "text": "on common functionality like ntls right so it may be important from a regulatory",
    "start": "2020000",
    "end": "2025440"
  },
  {
    "text": "standpoint that all my all my traffic between applications is encrypted right like even if i'm in say i'm in aws",
    "start": "2025440",
    "end": "2032720"
  },
  {
    "text": "and i've got three azs right like i want to know that that that traffic between availability zones really is",
    "start": "2032720",
    "end": "2038399"
  },
  {
    "text": "encrypted the whole time as an as an example right you can get that for free on your platform by adding in",
    "start": "2038399",
    "end": "2046000"
  },
  {
    "text": "adding in these services to your your service mesh on top of that right like there's way more i want to know",
    "start": "2046000",
    "end": "2051919"
  },
  {
    "text": "about my environment than just are things encrypted like as i write an application like if you've ever dealt with you know",
    "start": "2051919",
    "end": "2058638"
  },
  {
    "text": "hundreds of microservices like it's hard to get consistent metrics from every application like it's a huge",
    "start": "2058639",
    "end": "2064158"
  },
  {
    "text": "i can't tell you the struggle that i had at one of my previous jobs trying to get people to agree on a standard or even",
    "start": "2064159",
    "end": "2069280"
  },
  {
    "text": "just to make like hey listen everyone we need a slash metrics endpoint because it's part of what we do",
    "start": "2069280",
    "end": "2074638"
  },
  {
    "text": "to determine whether or not your app can go to production right like that was that was a struggle right with using linker d you don't have",
    "start": "2074639",
    "end": "2081440"
  },
  {
    "text": "to go bother those application teams because you're going to get common metrics from every single application like i didn't instrument",
    "start": "2081440",
    "end": "2087599"
  },
  {
    "text": "anything in this environment right i added link or d and now i can see the success rate the requests per second the latency i",
    "start": "2087599",
    "end": "2095280"
  },
  {
    "text": "can look in right i can go further in and see what what api what paths within the apis on",
    "start": "2095280",
    "end": "2100400"
  },
  {
    "text": "these apps are being collected and what what are the failures or response times by those particular paths",
    "start": "2100400",
    "end": "2106400"
  },
  {
    "text": "let's actually pop that up real quick so here in london we'll do linkery this",
    "start": "2106400",
    "end": "2112960"
  },
  {
    "text": "dashboard right we'll pop open this is just the open source dashboard that comes with",
    "start": "2112960",
    "end": "2118400"
  },
  {
    "text": "linker d right so i'm connecting over to london so there's a there's a bit of a",
    "start": "2118400",
    "end": "2123520"
  },
  {
    "text": "delay but i can see um i'm actually going to change clusters because this is this is the one that i'm",
    "start": "2123520",
    "end": "2128960"
  },
  {
    "text": "not hammering with a bunch of errors so let's make it a little bit more interesting",
    "start": "2128960",
    "end": "2134560"
  },
  {
    "text": "uh control our export i'm gonna go to london one",
    "start": "2134560",
    "end": "2140079"
  },
  {
    "text": "oh shoot one sec",
    "start": "2140079",
    "end": "2145839"
  },
  {
    "text": "what's going on all right sorry one sec sivo kubernetes",
    "start": "2153200",
    "end": "2160240"
  },
  {
    "text": "config region london one i want my london one cluster",
    "start": "2160240",
    "end": "2168720"
  },
  {
    "text": "and i want to export that config to dot cube configs",
    "start": "2168720",
    "end": "2176079"
  },
  {
    "text": "london one there we go so i'm just grabbing the config kns",
    "start": "2176079",
    "end": "2183359"
  },
  {
    "text": "on info swatching swing over to pot info name space let's run that lingerie",
    "start": "2183359",
    "end": "2188480"
  },
  {
    "text": "dashboard again",
    "start": "2188480",
    "end": "2191119"
  },
  {
    "text": "right so i'm getting things with the match like like access to this dashboard that gives",
    "start": "2194800",
    "end": "2200320"
  },
  {
    "text": "me like detailed metrics so i can see all my name spaces that same info i was",
    "start": "2200320",
    "end": "2205760"
  },
  {
    "text": "seeing in point cloud i could click over into the built-in grafana instance and and",
    "start": "2205760",
    "end": "2210800"
  },
  {
    "text": "set up my own queries there or connect it to the you know the enterprise grafana",
    "start": "2210800",
    "end": "2215920"
  },
  {
    "text": "instance i have and go into pod info and i can see like specifically right what service inside this namespace",
    "start": "2215920",
    "end": "2222400"
  },
  {
    "text": "so what deployment inside this namespace having issues so it's not my generator my generator is happy it's pot info here so look at that",
    "start": "2222400",
    "end": "2229839"
  },
  {
    "text": "look at that app i can see you know the map of my traffic where things are coming from and then i",
    "start": "2229839",
    "end": "2235119"
  },
  {
    "text": "can even see which which service is returning errors well it turns out i've got an endpoint",
    "start": "2235119",
    "end": "2241280"
  },
  {
    "text": "called 501 that just echoes you know whatever whatever status code you send it so this is a bit artificial right but you can",
    "start": "2241280",
    "end": "2248079"
  },
  {
    "text": "see you can see you can diagnose where that's coming from and get the latency right like which which of these have",
    "start": "2248079",
    "end": "2254640"
  },
  {
    "text": "like the worst response time right um oh it turns out my",
    "start": "2254640",
    "end": "2260400"
  },
  {
    "text": "slash delay one endpoint has about a one second delay every time it comes in right so",
    "start": "2260400",
    "end": "2266560"
  },
  {
    "text": "now again another artificially introduced introduced thing but we can we can get this information we can get",
    "start": "2266560",
    "end": "2272320"
  },
  {
    "text": "it to our sre team to our application developers without without having to to get them to",
    "start": "2272320",
    "end": "2279040"
  },
  {
    "text": "instrument anything right they just get it by being on the platform and you as a platform developer just get just get the tools to deal with it",
    "start": "2279040",
    "end": "2285920"
  },
  {
    "text": "now i could add in if i wanted i could add in a service profile and say hey listen when you hit pawn info no matter what i",
    "start": "2285920",
    "end": "2292880"
  },
  {
    "text": "want the maximum of a 500 millisecond timeout on any given call as an example right it's probably",
    "start": "2292880",
    "end": "2298800"
  },
  {
    "text": "aggressive but you get the point i could then as a platform engineer adjust this to fix",
    "start": "2298800",
    "end": "2304079"
  },
  {
    "text": "timeouts or do retries on a particular a particular path in my api or whatever it is that i'm looking",
    "start": "2304079",
    "end": "2309920"
  },
  {
    "text": "looking to do um that they answer your question yeah very much",
    "start": "2309920",
    "end": "2318000"
  },
  {
    "text": "uh yeah cool yeah so um i don't see any other questions coming",
    "start": "2319359",
    "end": "2324839"
  },
  {
    "text": "up um [Music] so uh maybe you can tell us uh",
    "start": "2324839",
    "end": "2330400"
  },
  {
    "text": "where we can go to learn more about linker d and uh if people want to experiment with",
    "start": "2330400",
    "end": "2336960"
  },
  {
    "text": "click link how can they get in touch with you yeah so i'm gonna i'll post a couple",
    "start": "2336960",
    "end": "2342800"
  },
  {
    "text": "things in the chat so the the best place to go to get started is check out the linker d slack",
    "start": "2342800",
    "end": "2348720"
  },
  {
    "text": "uh so it's slack.liquordy.io that's where you can join our community we're super active right we're you know",
    "start": "2348720",
    "end": "2355359"
  },
  {
    "text": "there's a lot of folks that will help respond to your questions help you help you get going uh thank you very",
    "start": "2355359",
    "end": "2361359"
  },
  {
    "text": "much there's also our getting started guide getting started there we go uh there's",
    "start": "2361359",
    "end": "2368720"
  },
  {
    "text": "our getting started guide which will walk you through the initial steps of actually setting up link rd and there's that multi-clustered uh demo",
    "start": "2368720",
    "end": "2375599"
  },
  {
    "text": "that i sent you to that multi-cluster demo is a bit more complicated than what i just did as it includes using a traffic split to",
    "start": "2375599",
    "end": "2382640"
  },
  {
    "text": "share traffic between east and west or between two clusters right but the the basic uh",
    "start": "2382640",
    "end": "2390800"
  },
  {
    "text": "the basics are still there right what we have to do is connect the clusters export the service",
    "start": "2390800",
    "end": "2397040"
  },
  {
    "text": "and then just have anything inside the mesh call out to that service just like you would something else that's local to your",
    "start": "2397040",
    "end": "2403040"
  },
  {
    "text": "cluster right so again keep it simple don't make new custom resource definitions so we don't want people to",
    "start": "2403040",
    "end": "2408240"
  },
  {
    "text": "have to do you know deal work with new object types just to use linker d or to use multi-cluster right",
    "start": "2408240",
    "end": "2415119"
  },
  {
    "text": "it's kubernetes so we want um you know we want kubernetes um well kubernetes objects to be like",
    "start": "2415119",
    "end": "2421520"
  },
  {
    "text": "the the primary thing that you work with um yes our getting started guide's a",
    "start": "2421520",
    "end": "2427280"
  },
  {
    "text": "great one um so those are those are the big things i checked that out and then you know we",
    "start": "2427280",
    "end": "2433680"
  },
  {
    "text": "actually had a another yeah uh a gustrous it absolutely works great on k3s and there's a cool",
    "start": "2433680",
    "end": "2440480"
  },
  {
    "text": "cli tool that you can use or so the linker dcli comes with a a test to let you know if it works so if",
    "start": "2440480",
    "end": "2446960"
  },
  {
    "text": "you want to do it on like i'm running k3s on docker in 2 on a windows box right so",
    "start": "2446960",
    "end": "2452720"
  },
  {
    "text": "there's a lot of room for walkiness in here but i can just check you know does this work so let me spin up a new",
    "start": "2452720",
    "end": "2458640"
  },
  {
    "text": "k-3s plus there okay a3d create plus there uh",
    "start": "2458640",
    "end": "2464160"
  },
  {
    "text": "cloud native live right uh cluster create maybe",
    "start": "2464160",
    "end": "2472240"
  },
  {
    "text": "i don't type this now yeah so i'm going to create a new cluster so this is a k3s cluster",
    "start": "2474000",
    "end": "2481839"
  },
  {
    "text": "running you know in docker on wsl so a bunch of weird stuff but we can just validate if this is going to be",
    "start": "2481839",
    "end": "2488319"
  },
  {
    "text": "a safe target for what we're doing or a kind cluster or you know whatever you're working with",
    "start": "2488319",
    "end": "2493839"
  },
  {
    "text": "and let me just run liberty check dash dash pre and this will just tell us",
    "start": "2493839",
    "end": "2499359"
  },
  {
    "text": "do we have the permissions do we have the right object types is the api of a of the right version like can we can we",
    "start": "2499359",
    "end": "2506400"
  },
  {
    "text": "do what we're trying to do here and install link rd and it'll just tell you at the end yes",
    "start": "2506400",
    "end": "2511520"
  },
  {
    "text": "you know in this case our our green check mark tells us we're good to go",
    "start": "2511520",
    "end": "2516720"
  },
  {
    "text": "very streamlined user experience i must admit awesome hey yeah well try it out i hope",
    "start": "2519119",
    "end": "2526319"
  },
  {
    "text": "you know it's it's really not too bad and what we see is a lot of adopters right find that you know the experience",
    "start": "2526319",
    "end": "2532800"
  },
  {
    "text": "with linkery like by by doing things like reducing the like the cognitive load that you're",
    "start": "2532800",
    "end": "2538319"
  },
  {
    "text": "under right like so like what do you need to we need to know to make it work by keeping that really low we allow you to get value out",
    "start": "2538319",
    "end": "2544640"
  },
  {
    "text": "of the mesh like get some get some business value for your organization out of that mesh without becoming experts in the way the",
    "start": "2544640",
    "end": "2550560"
  },
  {
    "text": "proxy works or you know the custom resource definitions like i haven't i haven't played with any custom resource definitions yet",
    "start": "2550560",
    "end": "2556880"
  },
  {
    "text": "i'm lying i actually created the link but that was on the back end using linker dcli right but i've i've got one crd created",
    "start": "2556880",
    "end": "2564079"
  },
  {
    "text": "in these two clusters and or you know instantiated and and now i'm doing",
    "start": "2564079",
    "end": "2569280"
  },
  {
    "text": "a connection between new york and london right right and then it's even less when",
    "start": "2569280",
    "end": "2574800"
  },
  {
    "text": "you're staying in cluster you need to work with zero customer resource definitions we use your kubernetes objects right at the gate",
    "start": "2574800",
    "end": "2580960"
  },
  {
    "text": "right oh one more sorry grpc load balancing if you're using grpc to do connections",
    "start": "2580960",
    "end": "2588720"
  },
  {
    "text": "a thing that like grpc is great right because it allows you to to multiplex connections",
    "start": "2588720",
    "end": "2595119"
  },
  {
    "text": "over so that is do a bunch of connections over one one http connection so you can send a bunch",
    "start": "2595119",
    "end": "2600240"
  },
  {
    "text": "of requests over one http connection which is awesome right but in in kubernetes right because",
    "start": "2600240",
    "end": "2605599"
  },
  {
    "text": "kubernetes does what's called connection level load balancing you're going to get is essentially hot pods if you have a grpc service so one",
    "start": "2605599",
    "end": "2613280"
  },
  {
    "text": "one responder for your grpc service is going to um it's going to get hotter than the",
    "start": "2613280",
    "end": "2618400"
  },
  {
    "text": "others right because it's going to get all the traffic and so with something like linker d what you get is",
    "start": "2618400",
    "end": "2623520"
  },
  {
    "text": "right out of the box request level load balancing for your applications right so that you're going to balance",
    "start": "2623520",
    "end": "2629599"
  },
  {
    "text": "that across all the different um all the different components cool",
    "start": "2629599",
    "end": "2634960"
  },
  {
    "text": "and i bet that it's easy to set up as uh every other thing that we've seen here",
    "start": "2634960",
    "end": "2640240"
  },
  {
    "text": "yeah you've seen me set it up already right like it's just it's just there and it just works at the gate right there's no",
    "start": "2640240",
    "end": "2646400"
  },
  {
    "text": "there's no configuration to you like the design principles lingerie are be fast be secure be really easy to implement",
    "start": "2646400",
    "end": "2652480"
  },
  {
    "text": "right great i'm convinced um awesome i hope the audience as well",
    "start": "2652480",
    "end": "2660079"
  },
  {
    "text": "so if there are no other questions i guess we can conclude this one and feel free to ask any uh other",
    "start": "2660079",
    "end": "2665760"
  },
  {
    "text": "questions that you may uh have while playing with link rd in their slack",
    "start": "2665760",
    "end": "2671280"
  },
  {
    "text": "or in the cncf slack under the cloud native dash live channel",
    "start": "2671280",
    "end": "2678400"
  },
  {
    "text": "um jason thank you very much it's been a really nice quick fast",
    "start": "2678400",
    "end": "2684960"
  },
  {
    "text": "just like clinker d demo so uh looking for that and um",
    "start": "2684960",
    "end": "2691359"
  },
  {
    "text": "i'll see you next week on cloud native live next wednesday every wednesday awesome appreciate it",
    "start": "2691359",
    "end": "2703039"
  }
]
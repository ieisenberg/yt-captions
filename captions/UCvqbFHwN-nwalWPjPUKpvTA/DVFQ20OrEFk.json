[
  {
    "text": "okay yeah so hello everyone so welcome",
    "start": "80",
    "end": "4040"
  },
  {
    "text": "to last session of CubeCon i hope it was",
    "start": "4040",
    "end": "7279"
  },
  {
    "text": "a good experience for you so today just",
    "start": "7279",
    "end": "11280"
  },
  {
    "text": "we are going to talk about how you can",
    "start": "11280",
    "end": "13840"
  },
  {
    "text": "just supercharge your AIM ML",
    "start": "13840",
    "end": "16400"
  },
  {
    "text": "observability uh using open telemetry",
    "start": "16400",
    "end": "20160"
  },
  {
    "text": "and fluently so uh for the first talk",
    "start": "20160",
    "end": "23840"
  },
  {
    "text": "we're just going to talk about uh",
    "start": "23840",
    "end": "26240"
  },
  {
    "text": "practical strategies for monitoring a",
    "start": "26240",
    "end": "28960"
  },
  {
    "text": "IML workloads on Kubernetes environments",
    "start": "28960",
    "end": "32000"
  },
  {
    "text": "and at the end I'm going to show you a",
    "start": "32000",
    "end": "35760"
  },
  {
    "text": "pretty quick",
    "start": "35760",
    "end": "38559"
  },
  {
    "text": "demo so a little bit about me so uh for",
    "start": "38600",
    "end": "42879"
  },
  {
    "text": "the last six years uh I'm just focusing",
    "start": "42879",
    "end": "46079"
  },
  {
    "text": "on Kubernetes reliability and cloud",
    "start": "46079",
    "end": "48840"
  },
  {
    "text": "infrastructure so I'm working at",
    "start": "48840",
    "end": "51480"
  },
  {
    "text": "Chronosphere uh so Chronosphere is",
    "start": "51480",
    "end": "54079"
  },
  {
    "text": "observable platform so I'm just",
    "start": "54079",
    "end": "56399"
  },
  {
    "text": "contributing",
    "start": "56399",
    "end": "58320"
  },
  {
    "text": "uh that observes the platform i am also",
    "start": "58320",
    "end": "61120"
  },
  {
    "text": "open source contributor uh so Fluent B",
    "start": "61120",
    "end": "64559"
  },
  {
    "text": "beat CI/CD maintainer and you can just",
    "start": "64559",
    "end": "67760"
  },
  {
    "text": "see me on the fluent bit with select",
    "start": "67760",
    "end": "70320"
  },
  {
    "text": "channels and my personal mission is like",
    "start": "70320",
    "end": "74280"
  },
  {
    "text": "making invisible intelligence visible",
    "start": "74280",
    "end": "77360"
  },
  {
    "text": "and action actionable for",
    "start": "77360",
    "end": "80600"
  },
  {
    "text": "everyone so there are a couple of",
    "start": "80600",
    "end": "82560"
  },
  {
    "text": "challenges with the Kubernetes so for",
    "start": "82560",
    "end": "85560"
  },
  {
    "text": "example ephemeral compute so ports come",
    "start": "85560",
    "end": "88560"
  },
  {
    "text": "and go quickly they they just basically",
    "start": "88560",
    "end": "92400"
  },
  {
    "text": "take their logs and context with them uh",
    "start": "92400",
    "end": "95600"
  },
  {
    "text": "resource organiz orchestration so",
    "start": "95600",
    "end": "97920"
  },
  {
    "text": "there's a dynamic scheduling shift",
    "start": "97920",
    "end": "100000"
  },
  {
    "text": "workloads across nodes constantly and",
    "start": "100000",
    "end": "103320"
  },
  {
    "text": "autoscaling uh so training and inference",
    "start": "103320",
    "end": "106000"
  },
  {
    "text": "workloads just scale differently based",
    "start": "106000",
    "end": "108079"
  },
  {
    "text": "on their patterns and",
    "start": "108079",
    "end": "110439"
  },
  {
    "text": "multi-tenency you can just deploy",
    "start": "110439",
    "end": "112399"
  },
  {
    "text": "multiple ML models and share same",
    "start": "112399",
    "end": "115280"
  },
  {
    "text": "infrastructure with different",
    "start": "115280",
    "end": "118680"
  },
  {
    "text": "priorities i think we already have a",
    "start": "118680",
    "end": "121840"
  },
  {
    "text": "solution for them so you can just",
    "start": "121840",
    "end": "124479"
  },
  {
    "text": "purchase your logs to some external log",
    "start": "124479",
    "end": "127560"
  },
  {
    "text": "storage you can just detect for example",
    "start": "127560",
    "end": "130959"
  },
  {
    "text": "lemon nodes if you have issues with the",
    "start": "130959",
    "end": "133120"
  },
  {
    "text": "nodes you can just do predictive scaling",
    "start": "133120",
    "end": "137120"
  },
  {
    "text": "you can just forecast your traffic and",
    "start": "137120",
    "end": "140000"
  },
  {
    "text": "just scale based on that earlier or you",
    "start": "140000",
    "end": "142800"
  },
  {
    "text": "can do workload isolation those are the",
    "start": "142800",
    "end": "146000"
  },
  {
    "text": "known issues",
    "start": "146000",
    "end": "147920"
  },
  {
    "text": "but there are some technical gaps uh",
    "start": "147920",
    "end": "150879"
  },
  {
    "text": "with the aiml application that I am",
    "start": "150879",
    "end": "153920"
  },
  {
    "text": "going to mention more so for example",
    "start": "153920",
    "end": "157120"
  },
  {
    "text": "unified telemetry collection serve uh",
    "start": "157120",
    "end": "160400"
  },
  {
    "text": "collecting telemetry across heterogenous",
    "start": "160400",
    "end": "163120"
  },
  {
    "text": "components is really hard and there's an",
    "start": "163120",
    "end": "166560"
  },
  {
    "text": "issue with the kubernetes a context pro",
    "start": "166560",
    "end": "169360"
  },
  {
    "text": "uh propagation uh maintaining context as",
    "start": "169360",
    "end": "172800"
  },
  {
    "text": "requests travel through the services you",
    "start": "172800",
    "end": "175440"
  },
  {
    "text": "have multiple services and there are",
    "start": "175440",
    "end": "178560"
  },
  {
    "text": "very different ML framework specific",
    "start": "178560",
    "end": "181080"
  },
  {
    "text": "instrumentation so specialized",
    "start": "181080",
    "end": "183040"
  },
  {
    "text": "monitoring for machine learning",
    "start": "183040",
    "end": "185159"
  },
  {
    "text": "components and you have to just connect",
    "start": "185159",
    "end": "187760"
  },
  {
    "text": "your infrastructure metrics with the",
    "start": "187760",
    "end": "190800"
  },
  {
    "text": "machine learning outcomes so these gaps",
    "start": "190800",
    "end": "194080"
  },
  {
    "text": "are basically create create a blind spot",
    "start": "194080",
    "end": "196879"
  },
  {
    "text": "in ML operations team just struggling to",
    "start": "196879",
    "end": "200280"
  },
  {
    "text": "troubleshoot model",
    "start": "200280",
    "end": "202680"
  },
  {
    "text": "issues so I'm just going to do a quick",
    "start": "202680",
    "end": "205760"
  },
  {
    "text": "survey so uh those are the that I'm",
    "start": "205760",
    "end": "210080"
  },
  {
    "text": "hearing most so just please raise your",
    "start": "210080",
    "end": "213120"
  },
  {
    "text": "hands uh so do you have any issues with",
    "start": "213120",
    "end": "215519"
  },
  {
    "text": "the model",
    "start": "215519",
    "end": "218159"
  },
  {
    "text": "performance with input",
    "start": "218840",
    "end": "222440"
  },
  {
    "text": "tracking so resource",
    "start": "222440",
    "end": "226080"
  },
  {
    "text": "optimization so cross component",
    "start": "226519",
    "end": "230280"
  },
  {
    "text": "tracing I think uh most voted for the",
    "start": "230280",
    "end": "233440"
  },
  {
    "text": "resource optimization",
    "start": "233440",
    "end": "235879"
  },
  {
    "text": "part so we are just going to deep dive",
    "start": "235879",
    "end": "238799"
  },
  {
    "text": "into monitoring uh complex intelligence",
    "start": "238799",
    "end": "241840"
  },
  {
    "text": "systems",
    "start": "241840",
    "end": "244480"
  },
  {
    "text": "so what is in invisible intelligence",
    "start": "244480",
    "end": "246799"
  },
  {
    "text": "challenge sir you have a mission",
    "start": "246799",
    "end": "248720"
  },
  {
    "text": "critical AI system right uh nowadays",
    "start": "248720",
    "end": "251439"
  },
  {
    "text": "you're just also powering our critical",
    "start": "251439",
    "end": "255599"
  },
  {
    "text": "business operation also relying some LLM",
    "start": "255599",
    "end": "259639"
  },
  {
    "text": "application either internally or",
    "start": "259639",
    "end": "262280"
  },
  {
    "text": "externally so we have observability gap",
    "start": "262280",
    "end": "265040"
  },
  {
    "text": "so our observability just monitor these",
    "start": "265040",
    "end": "268720"
  },
  {
    "text": "systems but they're just ls behind their",
    "start": "268720",
    "end": "271919"
  },
  {
    "text": "complexity and impact there's a control",
    "start": "271919",
    "end": "274720"
  },
  {
    "text": "problem so when system fails part may be",
    "start": "274720",
    "end": "277600"
  },
  {
    "text": "outside your control so third party comp",
    "start": "277600",
    "end": "280240"
  },
  {
    "text": "components just basically creating a",
    "start": "280240",
    "end": "282880"
  },
  {
    "text": "blind",
    "start": "282880",
    "end": "284360"
  },
  {
    "text": "spot so those are the four critical",
    "start": "284360",
    "end": "287199"
  },
  {
    "text": "observability dimension safe i'm just",
    "start": "287199",
    "end": "290880"
  },
  {
    "text": "going to deep dive on each one",
    "start": "290880",
    "end": "294960"
  },
  {
    "text": "so model performance degragation so you",
    "start": "294960",
    "end": "298720"
  },
  {
    "text": "can see just silent decline models just",
    "start": "298720",
    "end": "301759"
  },
  {
    "text": "decay in unpredictable patterns uh and",
    "start": "301759",
    "end": "306160"
  },
  {
    "text": "they just often fails without any",
    "start": "306160",
    "end": "308479"
  },
  {
    "text": "explicit errors there might be some",
    "start": "308479",
    "end": "311199"
  },
  {
    "text": "concept drift so real world data that",
    "start": "311199",
    "end": "315120"
  },
  {
    "text": "just diverges from this training",
    "start": "315120",
    "end": "318120"
  },
  {
    "text": "distribution and gap just widens over",
    "start": "318120",
    "end": "321120"
  },
  {
    "text": "time there's a threshold creep so",
    "start": "321120",
    "end": "323919"
  },
  {
    "text": "performance metrics fluctuate with",
    "start": "323919",
    "end": "326320"
  },
  {
    "text": "acceptable ranges but just failures",
    "start": "326320",
    "end": "329280"
  },
  {
    "text": "happen sometimes you don't even just",
    "start": "329280",
    "end": "331360"
  },
  {
    "text": "deduct",
    "start": "331360",
    "end": "332440"
  },
  {
    "text": "that there's a prompt ranking challenge",
    "start": "332440",
    "end": "335039"
  },
  {
    "text": "ser for example minor prompt variation",
    "start": "335039",
    "end": "337919"
  },
  {
    "text": "just create different output small",
    "start": "337919",
    "end": "340280"
  },
  {
    "text": "changes cause big impacts and also opac",
    "start": "340280",
    "end": "344240"
  },
  {
    "text": "relationship like prompt response",
    "start": "344240",
    "end": "346240"
  },
  {
    "text": "connection remain invisible to",
    "start": "346240",
    "end": "348400"
  },
  {
    "text": "traditional tools and version cast so",
    "start": "348400",
    "end": "351520"
  },
  {
    "text": "you're just uh constantly uh deploying",
    "start": "351520",
    "end": "354479"
  },
  {
    "text": "new models and also resource consumption",
    "start": "354479",
    "end": "358160"
  },
  {
    "text": "patterns are different than the",
    "start": "358160",
    "end": "359919"
  },
  {
    "text": "traditional one",
    "start": "359919",
    "end": "361840"
  },
  {
    "text": "uh you can just",
    "start": "361840",
    "end": "364039"
  },
  {
    "text": "uh consume more resource for the same",
    "start": "364039",
    "end": "367199"
  },
  {
    "text": "prompt",
    "start": "367199",
    "end": "368720"
  },
  {
    "text": "uh with different",
    "start": "368720",
    "end": "371319"
  },
  {
    "text": "values and there's also complex",
    "start": "371319",
    "end": "373680"
  },
  {
    "text": "deployment topologies like heterogenous",
    "start": "373680",
    "end": "376680"
  },
  {
    "text": "environments your old Kubernetes cluster",
    "start": "376680",
    "end": "379600"
  },
  {
    "text": "not same there are some third party",
    "start": "379600",
    "end": "382280"
  },
  {
    "text": "dependencies there's some inter uh",
    "start": "382280",
    "end": "385680"
  },
  {
    "text": "service chains there's some cross",
    "start": "385680",
    "end": "388080"
  },
  {
    "text": "boundary flow so data crosses",
    "start": "388080",
    "end": "390479"
  },
  {
    "text": "organizational",
    "start": "390479",
    "end": "392039"
  },
  {
    "text": "lines and why traditional monitoring",
    "start": "392039",
    "end": "395759"
  },
  {
    "text": "just uh fall short so what are we doing",
    "start": "395759",
    "end": "399600"
  },
  {
    "text": "we are just checking simple up and down",
    "start": "399600",
    "end": "401680"
  },
  {
    "text": "signals and this is just you can just",
    "start": "401680",
    "end": "404800"
  },
  {
    "text": "miss the gradual degation if you're",
    "start": "404800",
    "end": "407039"
  },
  {
    "text": "checking that or point in time metrics",
    "start": "407039",
    "end": "409520"
  },
  {
    "text": "so you can just",
    "start": "409520",
    "end": "411880"
  },
  {
    "text": "uh capture distribution shift but trains",
    "start": "411880",
    "end": "415039"
  },
  {
    "text": "remain remain invisible and also missing",
    "start": "415039",
    "end": "418000"
  },
  {
    "text": "the semantic context so if you're using",
    "start": "418000",
    "end": "420240"
  },
  {
    "text": "APM tools there's just lag of",
    "start": "420240",
    "end": "422479"
  },
  {
    "text": "understanding model",
    "start": "422479",
    "end": "425479"
  },
  {
    "text": "behavior and there's also impact on the",
    "start": "425479",
    "end": "428560"
  },
  {
    "text": "business side so let's say you have a",
    "start": "428560",
    "end": "431039"
  },
  {
    "text": "recommendation engine",
    "start": "431039",
    "end": "433280"
  },
  {
    "text": "uh and just gradual relevance decline",
    "start": "433280",
    "end": "437680"
  },
  {
    "text": "list to decrease clickthrough rates and",
    "start": "437680",
    "end": "440560"
  },
  {
    "text": "if you're LLM hallucination uh",
    "start": "440560",
    "end": "444520"
  },
  {
    "text": "hallucinating there's a just a",
    "start": "444520",
    "end": "446960"
  },
  {
    "text": "possibility of uh incorrect responses",
    "start": "446960",
    "end": "450160"
  },
  {
    "text": "and you you should also just I think it",
    "start": "450160",
    "end": "454000"
  },
  {
    "text": "was the most voted uh item so uh you",
    "start": "454000",
    "end": "457759"
  },
  {
    "text": "might just experience a",
    "start": "457759",
    "end": "460440"
  },
  {
    "text": "explosion so what is the path format",
    "start": "460440",
    "end": "463120"
  },
  {
    "text": "forward for the new observability so",
    "start": "463120",
    "end": "466080"
  },
  {
    "text": "distribution aware metrics semantic",
    "start": "466080",
    "end": "470360"
  },
  {
    "text": "understanding contextual correlation and",
    "start": "470360",
    "end": "473919"
  },
  {
    "text": "business alignment so uh today I am here",
    "start": "473919",
    "end": "478240"
  },
  {
    "text": "to just uh propose you or present you",
    "start": "478240",
    "end": "482960"
  },
  {
    "text": "how you can do that technically",
    "start": "482960",
    "end": "486400"
  },
  {
    "text": "uh so my approach is fulland bit and",
    "start": "486400",
    "end": "489759"
  },
  {
    "text": "open telemetry",
    "start": "489759",
    "end": "492759"
  },
  {
    "text": "together and combine solutions so what",
    "start": "492759",
    "end": "495680"
  },
  {
    "text": "is open telemetry and what is fulland",
    "start": "495680",
    "end": "498400"
  },
  {
    "text": "bit so open telemetry is open source",
    "start": "498400",
    "end": "501759"
  },
  {
    "text": "observability framework so it is vendor",
    "start": "501759",
    "end": "504639"
  },
  {
    "text": "neutral it just provides you vendor",
    "start": "504639",
    "end": "506800"
  },
  {
    "text": "neutral collection it is just first",
    "start": "506800",
    "end": "509840"
  },
  {
    "text": "class kubernetes integration and strong",
    "start": "509840",
    "end": "512560"
  },
  {
    "text": "community integration adoption probably",
    "start": "512560",
    "end": "515200"
  },
  {
    "text": "you heard a lot of open telemetry during",
    "start": "515200",
    "end": "517120"
  },
  {
    "text": "this conference and fluent bit it's just",
    "start": "517120",
    "end": "520159"
  },
  {
    "text": "end to end observability pipeline it's",
    "start": "520159",
    "end": "522880"
  },
  {
    "text": "just lightweight uh if you're using on",
    "start": "522880",
    "end": "526399"
  },
  {
    "text": "kubernetes",
    "start": "526399",
    "end": "527920"
  },
  {
    "text": "uh it has some powerful transformation",
    "start": "527920",
    "end": "530839"
  },
  {
    "text": "capabilities and it has a seamless",
    "start": "530839",
    "end": "533519"
  },
  {
    "text": "platform",
    "start": "533519",
    "end": "536079"
  },
  {
    "text": "integration so open telemetry provides",
    "start": "536360",
    "end": "540240"
  },
  {
    "text": "an open-source standard for logs metrics",
    "start": "540240",
    "end": "543920"
  },
  {
    "text": "and tracing",
    "start": "543920",
    "end": "545040"
  },
  {
    "text": "So we just uh going to talk about this",
    "start": "545040",
    "end": "548920"
  },
  {
    "text": "standard so it has a schema for logs",
    "start": "548920",
    "end": "552399"
  },
  {
    "text": "metrics and",
    "start": "552399",
    "end": "553800"
  },
  {
    "text": "traces and it also provide transport",
    "start": "553800",
    "end": "557360"
  },
  {
    "text": "layer we are just calling it",
    "start": "557360",
    "end": "560519"
  },
  {
    "text": "OTLP and it has a very good",
    "start": "560519",
    "end": "563080"
  },
  {
    "text": "instrumentation SDK you can just auto",
    "start": "563080",
    "end": "565920"
  },
  {
    "text": "instrument some libraries or you can",
    "start": "565920",
    "end": "569040"
  },
  {
    "text": "just uh use the instrumentation SDK and",
    "start": "569040",
    "end": "572640"
  },
  {
    "text": "you can just expand your application",
    "start": "572640",
    "end": "575040"
  },
  {
    "text": "using",
    "start": "575040",
    "end": "577440"
  },
  {
    "text": "that so we have a schema we have a",
    "start": "578120",
    "end": "581839"
  },
  {
    "text": "transport OTP layer and we have",
    "start": "581839",
    "end": "585160"
  },
  {
    "text": "instrumentation SDK with the open",
    "start": "585160",
    "end": "588680"
  },
  {
    "text": "telemetry so how fluent with an open",
    "start": "588680",
    "end": "591440"
  },
  {
    "text": "telemetry works together",
    "start": "591440",
    "end": "594399"
  },
  {
    "text": "so basically fluent bit collect",
    "start": "594399",
    "end": "599120"
  },
  {
    "text": "transform enrich and deliver this data",
    "start": "599120",
    "end": "602000"
  },
  {
    "text": "to your selected",
    "start": "602000",
    "end": "605399"
  },
  {
    "text": "target you can just consume logs traces",
    "start": "605399",
    "end": "609600"
  },
  {
    "text": "metrics from open telemetry and send it",
    "start": "609600",
    "end": "613040"
  },
  {
    "text": "to open telemetry via OTLP protocol",
    "start": "613040",
    "end": "617760"
  },
  {
    "text": "you can just consume multiple OTLP",
    "start": "617760",
    "end": "622000"
  },
  {
    "text": "uh endpoints and send it to multiple",
    "start": "622000",
    "end": "625200"
  },
  {
    "text": "OTLP",
    "start": "625200",
    "end": "627079"
  },
  {
    "text": "endpoints and let's say",
    "start": "627079",
    "end": "630200"
  },
  {
    "text": "uh our application doesn't just uh give",
    "start": "630200",
    "end": "635760"
  },
  {
    "text": "us a logs in uh open telemetry schema so",
    "start": "635760",
    "end": "640800"
  },
  {
    "text": "we have so basically flant bit has open",
    "start": "640800",
    "end": "644399"
  },
  {
    "text": "telemetry envelope so you can just send",
    "start": "644399",
    "end": "647360"
  },
  {
    "text": "your log record and fluent bit is just",
    "start": "647360",
    "end": "650720"
  },
  {
    "text": "uh converting it",
    "start": "650720",
    "end": "652360"
  },
  {
    "text": "to open telemetry",
    "start": "652360",
    "end": "655320"
  },
  {
    "text": "format it is same for matrix let's say",
    "start": "655320",
    "end": "658240"
  },
  {
    "text": "you have some Prometheus endpoints or",
    "start": "658240",
    "end": "661120"
  },
  {
    "text": "sty or other metrics to be just",
    "start": "661120",
    "end": "664959"
  },
  {
    "text": "converted to open telemetry compliance",
    "start": "664959",
    "end": "670399"
  },
  {
    "text": "schema and like I said it has some sort",
    "start": "671079",
    "end": "674640"
  },
  {
    "text": "of uh enrichment filtering capabilities",
    "start": "674640",
    "end": "677760"
  },
  {
    "text": "also one of them uh you're just",
    "start": "677760",
    "end": "680959"
  },
  {
    "text": "consuming uh a lot of traces and if",
    "start": "680959",
    "end": "684079"
  },
  {
    "text": "you're just",
    "start": "684079",
    "end": "685640"
  },
  {
    "text": "uh collecting the traces from LLM",
    "start": "685640",
    "end": "689519"
  },
  {
    "text": "application it's so chatty so it just",
    "start": "689519",
    "end": "692320"
  },
  {
    "text": "generate a lot of trace and spans you",
    "start": "692320",
    "end": "695040"
  },
  {
    "text": "can just use head sampling what is head",
    "start": "695040",
    "end": "698120"
  },
  {
    "text": "sampling it's a uh probabilistic",
    "start": "698120",
    "end": "701600"
  },
  {
    "text": "approach it just take the headspan and",
    "start": "701600",
    "end": "706160"
  },
  {
    "text": "apply your filter top on it if it",
    "start": "706160",
    "end": "708800"
  },
  {
    "text": "applies then send it to destination not",
    "start": "708800",
    "end": "711680"
  },
  {
    "text": "then drop the whole trace and you can",
    "start": "711680",
    "end": "714560"
  },
  {
    "text": "even do tail sampling",
    "start": "714560",
    "end": "717120"
  },
  {
    "text": "Uh so it wait for all spans and check",
    "start": "717120",
    "end": "721440"
  },
  {
    "text": "for all spans if they apply the",
    "start": "721440",
    "end": "724360"
  },
  {
    "text": "conditions it passes not it just",
    "start": "724360",
    "end": "729639"
  },
  {
    "text": "drops let's say you have uh blocks you",
    "start": "729639",
    "end": "734880"
  },
  {
    "text": "can just apply conditional filters so",
    "start": "734880",
    "end": "737920"
  },
  {
    "text": "for example in this example",
    "start": "737920",
    "end": "740480"
  },
  {
    "text": "uh there's a conditions you can just use",
    "start": "740480",
    "end": "743040"
  },
  {
    "text": "conditional operators like and and or",
    "start": "743040",
    "end": "746240"
  },
  {
    "text": "you can use comparison operators like",
    "start": "746240",
    "end": "748560"
  },
  {
    "text": "AQL or not AQL or greater or less than",
    "start": "748560",
    "end": "752959"
  },
  {
    "text": "uh if your conditionals are good for the",
    "start": "752959",
    "end": "756720"
  },
  {
    "text": "logs so it can pass not then",
    "start": "756720",
    "end": "761279"
  },
  {
    "text": "drops and that was the presentation part",
    "start": "762360",
    "end": "766560"
  },
  {
    "text": "so I have",
    "start": "766560",
    "end": "768360"
  },
  {
    "text": "a quick demo for",
    "start": "768360",
    "end": "772320"
  },
  {
    "text": "you okay I have",
    "start": "774600",
    "end": "777639"
  },
  {
    "text": "a Okay so this is just an uh EKS cluster",
    "start": "777639",
    "end": "783360"
  },
  {
    "text": "it has two GPU nodes on it uh so I just",
    "start": "783360",
    "end": "788320"
  },
  {
    "text": "deploy two LLM models on it and I use uh",
    "start": "788320",
    "end": "792240"
  },
  {
    "text": "something called cubei it's very cool",
    "start": "792240",
    "end": "794720"
  },
  {
    "text": "project i just recommend you to check",
    "start": "794720",
    "end": "797480"
  },
  {
    "text": "also you can just easily those are my my",
    "start": "797480",
    "end": "801519"
  },
  {
    "text": "models so it is a llama 8 billion",
    "start": "801519",
    "end": "804800"
  },
  {
    "text": "instruct and llama 8 billion tulip",
    "start": "804800",
    "end": "810360"
  },
  {
    "text": "this gives me uh using VLM it gives me",
    "start": "810560",
    "end": "815839"
  },
  {
    "text": "uh OpenAI compliant uh endpoints and I I",
    "start": "815839",
    "end": "821440"
  },
  {
    "text": "have a Python application running uh",
    "start": "821440",
    "end": "824160"
  },
  {
    "text": "with these two",
    "start": "824160",
    "end": "825959"
  },
  {
    "text": "models i am just going",
    "start": "825959",
    "end": "829920"
  },
  {
    "text": "to so this is basically Python",
    "start": "835000",
    "end": "837720"
  },
  {
    "text": "application it's just sending incoming",
    "start": "837720",
    "end": "840880"
  },
  {
    "text": "chat request to uh my LLM that's it i I",
    "start": "840880",
    "end": "847760"
  },
  {
    "text": "didn't use any uh metric or log or uh",
    "start": "847760",
    "end": "853199"
  },
  {
    "text": "tracing in my code it's just using the",
    "start": "853199",
    "end": "856399"
  },
  {
    "text": "open telemetry uh open AI open",
    "start": "856399",
    "end": "859480"
  },
  {
    "text": "instrumentation and just creating",
    "start": "859480",
    "end": "862720"
  },
  {
    "text": "uh metrics traces and logs for all my",
    "start": "862720",
    "end": "866480"
  },
  {
    "text": "applications and it is sending it to",
    "start": "866480",
    "end": "869199"
  },
  {
    "text": "fluent bit uh OTLP",
    "start": "869199",
    "end": "874000"
  },
  {
    "text": "endpoint i'm going to show you the full",
    "start": "876920",
    "end": "881600"
  },
  {
    "text": "bit part",
    "start": "881600",
    "end": "884839"
  },
  {
    "text": "okay this is the full end bit part so I",
    "start": "893320",
    "end": "897360"
  },
  {
    "text": "have open telemetry input plug-in",
    "start": "897360",
    "end": "900519"
  },
  {
    "text": "configured it just exposes",
    "start": "900519",
    "end": "904120"
  },
  {
    "text": "uh OTLP endpoint for traces logs and",
    "start": "904120",
    "end": "908079"
  },
  {
    "text": "metrics you can just either send gRPC",
    "start": "908079",
    "end": "912399"
  },
  {
    "text": "using gRPC or you can just use uh",
    "start": "912399",
    "end": "916320"
  },
  {
    "text": "protobuff over uh",
    "start": "916320",
    "end": "918839"
  },
  {
    "text": "HTTP uh and here we have uh output it is",
    "start": "918839",
    "end": "924880"
  },
  {
    "text": "just sending to my demo environment uh",
    "start": "924880",
    "end": "929120"
  },
  {
    "text": "so it it is again uh OTLP endpoint i'm",
    "start": "929120",
    "end": "934160"
  },
  {
    "text": "just saying this is the matrix URI this",
    "start": "934160",
    "end": "936399"
  },
  {
    "text": "is the logs URI and this is the traces",
    "start": "936399",
    "end": "938720"
  },
  {
    "text": "URI and I'm just uh giving my API to",
    "start": "938720",
    "end": "943360"
  },
  {
    "text": "token for my application and that's it",
    "start": "943360",
    "end": "946000"
  },
  {
    "text": "and I'm also as you can see I'm just",
    "start": "946000",
    "end": "948160"
  },
  {
    "text": "using the output as set out uh let me",
    "start": "948160",
    "end": "952240"
  },
  {
    "text": "also show you",
    "start": "952240",
    "end": "955120"
  },
  {
    "text": "quickly so at the moment I'm just using",
    "start": "956279",
    "end": "959600"
  },
  {
    "text": "some load testers uh so these are the",
    "start": "959600",
    "end": "963320"
  },
  {
    "text": "generated matrix traces and logs since",
    "start": "963320",
    "end": "967839"
  },
  {
    "text": "this is so chatty I'm just going to show",
    "start": "967839",
    "end": "971600"
  },
  {
    "text": "you how it is looks like on",
    "start": "971600",
    "end": "975480"
  },
  {
    "text": "the",
    "start": "975480",
    "end": "978480"
  },
  {
    "text": "UI i'm just using Chronosphere platform",
    "start": "980199",
    "end": "983600"
  },
  {
    "text": "but uh it is another observability",
    "start": "983600",
    "end": "986320"
  },
  {
    "text": "platform so you can just use graphana",
    "start": "986320",
    "end": "988800"
  },
  {
    "text": "data do reel datress or any open source",
    "start": "988800",
    "end": "992639"
  },
  {
    "text": "solution but since I had an environment",
    "start": "992639",
    "end": "995360"
  },
  {
    "text": "just I had used that so those are the",
    "start": "995360",
    "end": "997920"
  },
  {
    "text": "matrix parts as you can see I just",
    "start": "997920",
    "end": "1000079"
  },
  {
    "text": "configured",
    "start": "1000079",
    "end": "1002000"
  },
  {
    "text": "uh I don't know maybe 10 line of uh yl I",
    "start": "1002000",
    "end": "1006000"
  },
  {
    "text": "didn't do any instrumentation I just use",
    "start": "1006000",
    "end": "1008399"
  },
  {
    "text": "open telemetry auto",
    "start": "1008399",
    "end": "1010120"
  },
  {
    "text": "instrumentation and this is the result",
    "start": "1010120",
    "end": "1012399"
  },
  {
    "text": "it's just flowing on my environment",
    "start": "1012399",
    "end": "1016399"
  },
  {
    "text": "so this is the P99 client operation",
    "start": "1016399",
    "end": "1019680"
  },
  {
    "text": "latency as you can see it just show me",
    "start": "1019680",
    "end": "1022000"
  },
  {
    "text": "the two models I",
    "start": "1022000",
    "end": "1025000"
  },
  {
    "text": "deployed this is the token usage so",
    "start": "1025000",
    "end": "1028240"
  },
  {
    "text": "these labels are just saying seconds but",
    "start": "1028240",
    "end": "1030880"
  },
  {
    "text": "it is just",
    "start": "1030880",
    "end": "1032438"
  },
  {
    "text": "uh 950 tokens so it is their",
    "start": "1032439",
    "end": "1036520"
  },
  {
    "text": "tokens those are the matrix parts let's",
    "start": "1036520",
    "end": "1039280"
  },
  {
    "text": "say I need the traces it's also flowing",
    "start": "1039280",
    "end": "1042079"
  },
  {
    "text": "here so you can see your uh traces sent",
    "start": "1042079",
    "end": "1047199"
  },
  {
    "text": "to your observ",
    "start": "1047199",
    "end": "1050960"
  },
  {
    "text": "platform and we have also generated logs",
    "start": "1052440",
    "end": "1055679"
  },
  {
    "text": "here you can just use",
    "start": "1055679",
    "end": "1058840"
  },
  {
    "text": "uh ID to correlate them uh and vice",
    "start": "1058840",
    "end": "1065440"
  },
  {
    "text": "versa",
    "start": "1067799",
    "end": "1069640"
  },
  {
    "text": "okay yep that was the everything I",
    "start": "1069640",
    "end": "1072960"
  },
  {
    "text": "wanted to show you today and if you have",
    "start": "1072960",
    "end": "1075840"
  },
  {
    "text": "questions uh I'm happy to answer since I",
    "start": "1075840",
    "end": "1079120"
  },
  {
    "text": "think we have a quite good time",
    "start": "1079120",
    "end": "1083320"
  }
]
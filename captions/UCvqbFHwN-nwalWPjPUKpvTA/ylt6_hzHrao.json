[
  {
    "start": "0",
    "end": "119000"
  },
  {
    "text": "I'd like to thank everybody who's joining us today welcome again to CNCs webinar from Vega",
    "start": "2100",
    "end": "7830"
  },
  {
    "text": "rethinking storage for streams I'm Kristy tan marketing communications manager at CN CF I'll be moderating",
    "start": "7830",
    "end": "15190"
  },
  {
    "text": "today's webinar we would like to welcome our presenter today Flavio Flavio Jin",
    "start": "15190",
    "end": "20919"
  },
  {
    "text": "Kara senior distinguished engineer at Dell a few housekeeping items before we",
    "start": "20919",
    "end": "26859"
  },
  {
    "text": "get started during the webinar you are not able to talk as an attendee there is",
    "start": "26859",
    "end": "32050"
  },
  {
    "text": "a Q&A box at the bottom of your screen please feel free to drop your questions in there and we will get to as many as",
    "start": "32050",
    "end": "38530"
  },
  {
    "text": "we can at the end this is an official webinar of the CNC F and in and as such is subject to the CNC",
    "start": "38530",
    "end": "45370"
  },
  {
    "text": "F Code of Conduct please do not add anything to the chat or questions that would be in violation of that code of",
    "start": "45370",
    "end": "51220"
  },
  {
    "text": "conduct basically be please be respectful of all your fellow participants and presenters please also",
    "start": "51220",
    "end": "58090"
  },
  {
    "text": "note the recording and slides will be posted later today to the CNC F webinar page at CNC F dot IO slash webinars with",
    "start": "58090",
    "end": "67179"
  },
  {
    "text": "that I'll hand it over to Flavio to kick off today's presentation",
    "start": "67179",
    "end": "72600"
  },
  {
    "text": "Thank You Chrissy for traduction for sulfide I want to thank",
    "start": "74740",
    "end": "80180"
  },
  {
    "text": "everyone who is able to join today I know we are going through difficult times across the globe and I appreciate",
    "start": "80180",
    "end": "86960"
  },
  {
    "text": "you taking your time to attend the presentation maybe learn something new I see that actually actually is an",
    "start": "86960",
    "end": "92420"
  },
  {
    "text": "opportunity to get away from the overflow of information about kovat so hopefully you'll be able to learn",
    "start": "92420",
    "end": "98600"
  },
  {
    "text": "something new today about streams of opera Vega and would be definitely worth your time",
    "start": "98600",
    "end": "104470"
  },
  {
    "text": "so as Christine I shouldn't be talking about prevail today a project that I have been working with the team for for",
    "start": "104470",
    "end": "111080"
  },
  {
    "text": "the past few years before I got into pro Vega and it's not motivation how he",
    "start": "111080",
    "end": "118880"
  },
  {
    "text": "works architecture and all that let me tell you a bit about myself I worked for",
    "start": "118880",
    "end": "124340"
  },
  {
    "start": "119000",
    "end": "119000"
  },
  {
    "text": "del W MC I am a senior distinguished engineer there I have been working on the on the provegan project since 2016",
    "start": "124340",
    "end": "131709"
  },
  {
    "text": "so it's it's a bit over three years and and my background is this a bit of",
    "start": "131709",
    "end": "138830"
  },
  {
    "text": "computing I was in research for a number of years I worked at Microsoft Research idea research I worked in a number of",
    "start": "138830",
    "end": "145970"
  },
  {
    "text": "other open source projects in particular one Sina in Apache I was one of the",
    "start": "145970",
    "end": "153709"
  },
  {
    "text": "people who started projects like Apache zookeeper Apache bookkeeper some of the prominent ones I have worked on and you",
    "start": "153709",
    "end": "161540"
  },
  {
    "text": "have some contact information if you want to reach out to me later on or follow me on Twitter now so getting to",
    "start": "161540",
    "end": "171049"
  },
  {
    "text": "the motivation for for per Vega for streams um a lot of the motivation for",
    "start": "171049",
    "end": "177549"
  },
  {
    "text": "for systems doing talk about streams and and and processing stream storing",
    "start": "177549",
    "end": "184940"
  },
  {
    "text": "streams is the many sources of continuously generated data if we if we",
    "start": "184940",
    "end": "191359"
  },
  {
    "text": "think about more concretely applications like social network so you have end",
    "start": "191359",
    "end": "198320"
  },
  {
    "text": "users continually streaming events status updates or if you think about websites where users are are",
    "start": "198320",
    "end": "208090"
  },
  {
    "start": "206000",
    "end": "206000"
  },
  {
    "text": "transacting so they are purchasing they are that are not bank applications where",
    "start": "208610",
    "end": "213860"
  },
  {
    "text": "users are continuously producing producing those events and generating",
    "start": "213860",
    "end": "218900"
  },
  {
    "text": "transactions so those can be extremes of data that you want to collect any one a",
    "start": "218900",
    "end": "224840"
  },
  {
    "text": "process but it's not only about end-users not only about you know human beings on the on the other side of the",
    "start": "224840",
    "end": "230690"
  },
  {
    "text": "screen it could be us about machines it could be about a fleets of servers that you want to collect telemetry about",
    "start": "230690",
    "end": "237340"
  },
  {
    "text": "learn more about how the servers are being used if they are operating correctly all those are valid ways of",
    "start": "237340",
    "end": "244960"
  },
  {
    "text": "valid applications for which you need to collect such data other types of",
    "start": "244960",
    "end": "251900"
  },
  {
    "text": "machines that are that that are interesting to think about and collect data from or you know this day is about",
    "start": "251900",
    "end": "257570"
  },
  {
    "text": "all about IOT you so sensors makes them makes a very good use case for",
    "start": "257570",
    "end": "262600"
  },
  {
    "text": "discussions around streams continuously generated data and this of course all",
    "start": "262600",
    "end": "268730"
  },
  {
    "text": "the the conversations about autonomous cars connected cars that are all average",
    "start": "268730",
    "end": "276350"
  },
  {
    "text": "stream processing yes also there would be a good number of streams coming out",
    "start": "276350",
    "end": "282410"
  },
  {
    "text": "of all those machines all those end users and all of those might be a good",
    "start": "282410",
    "end": "287930"
  },
  {
    "text": "source of information or or output for a good number of applications and so if we",
    "start": "287930",
    "end": "295130"
  },
  {
    "text": "think about the landscape that I'm trying to portrait we have on on the one",
    "start": "295130",
    "end": "302480"
  },
  {
    "start": "296000",
    "end": "296000"
  },
  {
    "text": "ends on the left hand side we have again end users machines producing a",
    "start": "302480",
    "end": "307550"
  },
  {
    "text": "continuous flow of data and we want to be able to ingest that data store it and",
    "start": "307550",
    "end": "315580"
  },
  {
    "text": "process it not necessarily just in the OSI two stages may be there are complex",
    "start": "315580",
    "end": "321440"
  },
  {
    "text": "combinations of ingesting processing storing the right data set and",
    "start": "321440",
    "end": "327919"
  },
  {
    "text": "processing again and and composing stages of processing and storage in in",
    "start": "327919",
    "end": "335780"
  },
  {
    "text": "ways that benefit your business your your applications and so when we think",
    "start": "335780",
    "end": "341630"
  },
  {
    "text": "about outputs that be the result of those data pipelines wait we can think of visualizing data in",
    "start": "341630",
    "end": "347170"
  },
  {
    "text": "different ways so is that give us more insight or just enable us to understand",
    "start": "347170",
    "end": "353030"
  },
  {
    "text": "better the nature of our applications our devices it could be alerts if you talk about",
    "start": "353030",
    "end": "358160"
  },
  {
    "text": "servers you might want to learn about problems that are your fleet of services experience experiencing you can get",
    "start": "358160",
    "end": "365000"
  },
  {
    "text": "insights about your your customers recommendations based on the on the use",
    "start": "365000",
    "end": "371870"
  },
  {
    "text": "of of other users or even actionable analytics thinks that it can use in in",
    "start": "371870",
    "end": "381290"
  },
  {
    "text": "your day job or when you go visit a customer or it could be even between machines as well so all those are valid",
    "start": "381290",
    "end": "390070"
  },
  {
    "text": "outputs that you can think when you have all those streams available to you that you can process and derive value from",
    "start": "390070",
    "end": "399250"
  },
  {
    "text": "now one step down and talking a bit more concretely about use cases so we have",
    "start": "400210",
    "end": "406640"
  },
  {
    "text": "seen I want to mention a couple of general use cases that we have seen so",
    "start": "406640",
    "end": "411860"
  },
  {
    "text": "we have seen for example fruits of drones where they they have cameras and",
    "start": "411860",
    "end": "417680"
  },
  {
    "text": "they are they are recording they're streaming that video which you want to",
    "start": "417680",
    "end": "423320"
  },
  {
    "text": "ingest and process and and people want to do that for different reasons they you know like we have seen applications",
    "start": "423320",
    "end": "430250"
  },
  {
    "text": "where you want to you want to check the health of your cattle to applications where you are checking inspecting the",
    "start": "430250",
    "end": "437360"
  },
  {
    "text": "airplanes between flights say in an airport so all those are examples of",
    "start": "437360",
    "end": "442790"
  },
  {
    "text": "both of the hood examples perhaps a bit you into extremes of the spectrum but",
    "start": "442790",
    "end": "448790"
  },
  {
    "text": "where you want to use three cell phones and you want to ingest those videos and even other telemetry process the data",
    "start": "448790",
    "end": "456050"
  },
  {
    "text": "and it makes sense out of it and another interesting point is those applications",
    "start": "456050",
    "end": "461750"
  },
  {
    "text": "they they are interested in ingesting the data processing it and getting those",
    "start": "461750",
    "end": "468170"
  },
  {
    "text": "insights in an inny real-time right so essentially as soon as as possible",
    "start": "468170",
    "end": "474830"
  },
  {
    "text": "but also the won't you come back eventually and reprocess it so the ability of of",
    "start": "474830",
    "end": "480420"
  },
  {
    "text": "getting results with old latency but also they're big enough reprocessing that data they are important for this",
    "start": "480420",
    "end": "486930"
  },
  {
    "text": "class of applications and along similar lines we have seen the effect in factory",
    "start": "486930",
    "end": "493800"
  },
  {
    "start": "490000",
    "end": "490000"
  },
  {
    "text": "force where you have video cameras recording videos of pieces that are",
    "start": "493800",
    "end": "499800"
  },
  {
    "text": "they're being manufactured and you want to the fact maybe defects in those in",
    "start": "499800",
    "end": "505080"
  },
  {
    "text": "those parts so for that you just videos you process videos and and you get some",
    "start": "505080",
    "end": "513479"
  },
  {
    "text": "output that gives an indication whether things are going right or wrong and again this in this example we also want",
    "start": "513479",
    "end": "520680"
  },
  {
    "text": "to process the data as it comes in but we might also want to reprocess data",
    "start": "520680",
    "end": "527040"
  },
  {
    "text": "later if for example we miss something or maybe we found the problem in the way",
    "start": "527040",
    "end": "532230"
  },
  {
    "text": "we're processing it so that a bit of reprocessing is is also relevant for such an applications now moving down one",
    "start": "532230",
    "end": "543570"
  },
  {
    "start": "543000",
    "end": "543000"
  },
  {
    "text": "level and talk about streams let's let's um let's reason a bit about how we all",
    "start": "543570",
    "end": "550680"
  },
  {
    "text": "see streams are beta so the most natural ways to think about a sequence of events",
    "start": "550680",
    "end": "556230"
  },
  {
    "text": "where these events are again coming from sensors servers and users and so we are",
    "start": "556230",
    "end": "562860"
  },
  {
    "text": "ingesting those events and we are painting one after the other that's a naturally of reasoning about it",
    "start": "562860",
    "end": "569670"
  },
  {
    "text": "about streams but in reality it's not just a single flow like this i we have",
    "start": "569670",
    "end": "577080"
  },
  {
    "start": "573000",
    "end": "573000"
  },
  {
    "text": "some degree of parallelism you know we can have multiple servers moves for sensors moves for users so it's not",
    "start": "577080",
    "end": "582240"
  },
  {
    "text": "really just one single sequence like that it looks more like the figure that I have on the on the slide but we have",
    "start": "582240",
    "end": "589650"
  },
  {
    "text": "again useful flows but even that given",
    "start": "589650",
    "end": "595080"
  },
  {
    "text": "that does not completely characterize the kinds of data streams that are that are I'm referring to so data streams do",
    "start": "595080",
    "end": "603000"
  },
  {
    "start": "603000",
    "end": "603000"
  },
  {
    "text": "not are not necessarily constant in the way we had in the previous slide so the traffic that you see",
    "start": "603000",
    "end": "609660"
  },
  {
    "text": "in a in a stream even with the palace and I have at it that that degree of parallelism does not is not necessarily",
    "start": "609660",
    "end": "616140"
  },
  {
    "text": "static or constant so it could vary over time so maybe at some point in time the",
    "start": "616140",
    "end": "621420"
  },
  {
    "text": "load jobs as some other point increases maybe this is periodic maybe happens when you when you double the number of",
    "start": "621420",
    "end": "627540"
  },
  {
    "text": "sensors you have or the number of servers you have and so so ashe reading a real stream looks more like this where",
    "start": "627540",
    "end": "634230"
  },
  {
    "text": "again we have parallelism and and and the load fluctuates over time either",
    "start": "634230",
    "end": "642090"
  },
  {
    "text": "periodically or at specific times I'm",
    "start": "642090",
    "end": "647700"
  },
  {
    "text": "not important property is that this is just being bounded such streams can be",
    "start": "647700",
    "end": "652830"
  },
  {
    "start": "650000",
    "end": "650000"
  },
  {
    "text": "it can be unbounded so they can start and you can keep collecting data for for as long as you your application runs",
    "start": "652830",
    "end": "662030"
  },
  {
    "text": "traditionally applications have split that there into fresh recently ingest",
    "start": "662030",
    "end": "667050"
  },
  {
    "text": "data and in older historical data and in many cases even separated that data in",
    "start": "667050",
    "end": "673350"
  },
  {
    "text": "different systems and I'm gonna call this they love the way referring to up to the land architecture but the ideal",
    "start": "673350",
    "end": "682410"
  },
  {
    "text": "situation is that we don't make that separation right and we see a stream as",
    "start": "682410",
    "end": "687960"
  },
  {
    "text": "as one unit one flow of of data of",
    "start": "687960",
    "end": "693300"
  },
  {
    "text": "course you as a user you have the rights of of of the leading the data if you wish you",
    "start": "693300",
    "end": "699540"
  },
  {
    "text": "but you should also be able to store a stream for or sumn data for as long as",
    "start": "699540",
    "end": "705330"
  },
  {
    "text": "as it makes sense for your application",
    "start": "705330",
    "end": "709580"
  },
  {
    "text": "and it's not all it's not all is that all about writing right so reading is",
    "start": "711630",
    "end": "718450"
  },
  {
    "start": "715000",
    "end": "715000"
  },
  {
    "text": "also important so reads care baby is another property that of any system that the user data streams need to",
    "start": "718450",
    "end": "724510"
  },
  {
    "text": "incorporate so they're big enough of dealing with this changes leading with the parallelism dealing with the changes",
    "start": "724510",
    "end": "730510"
  },
  {
    "text": "to workloads also needs to be taking to account on the on the read side when",
    "start": "730510",
    "end": "736180"
  },
  {
    "text": "reading the stream so that's the the",
    "start": "736180",
    "end": "742210"
  },
  {
    "start": "741000",
    "end": "741000"
  },
  {
    "text": "motivation for thinking about streams in the way we have in the way we do improve",
    "start": "742210",
    "end": "748630"
  },
  {
    "text": "Vega and in the idea of provegan is essentially to create this system for",
    "start": "748630",
    "end": "756400"
  },
  {
    "text": "storing streams and having stream as a core primitive just like you have file",
    "start": "756400",
    "end": "762070"
  },
  {
    "text": "systems that you have objects systems we we want to have a storage system that's",
    "start": "762070",
    "end": "768240"
  },
  {
    "text": "ingest streams and output streams and at whatever point you decide to to process",
    "start": "768240",
    "end": "774520"
  },
  {
    "text": "the data you should be able to read that in the form of a stream you should have",
    "start": "774520",
    "end": "781090"
  },
  {
    "text": "no need of reading the data storing somewhere else and so properties that",
    "start": "781090",
    "end": "786340"
  },
  {
    "text": "are that I just characterized and are important are to consider that the",
    "start": "786340",
    "end": "791500"
  },
  {
    "text": "amount of data in a stream is inbounded you you might need to store same data",
    "start": "791500",
    "end": "796990"
  },
  {
    "text": "for correspond each a very long time of ingestion it needs to be elastic to deal",
    "start": "796990",
    "end": "802540"
  },
  {
    "text": "with the traffic changes that I have mentioned it needs to be consistent you",
    "start": "802540",
    "end": "808450"
  },
  {
    "text": "don't have sig duplicates or miss events in the industry and it needs to be to",
    "start": "808450",
    "end": "815680"
  },
  {
    "text": "give you their behavior of both tailing a stream and performing historical processing over that same data and those",
    "start": "815680",
    "end": "824410"
  },
  {
    "text": "are properties that we believe are very important if you have a called native application and we wanted to offer that",
    "start": "824410",
    "end": "831250"
  },
  {
    "text": "in a system so that I could play well with all such applications and that's and that's essentially what provegan is",
    "start": "831250",
    "end": "838270"
  },
  {
    "text": "and in this now so let's get into details or profit you know",
    "start": "838270",
    "end": "844750"
  },
  {
    "text": "so pregnant builds on the notion of segments a segment is a sequence of an",
    "start": "844750",
    "end": "853180"
  },
  {
    "text": "append-only sequence of bytes and it's the units that we stop impervia now note",
    "start": "853180",
    "end": "858879"
  },
  {
    "text": "that it's bytes not events messages or records and this is important because it",
    "start": "858879",
    "end": "865180"
  },
  {
    "text": "shows the flexibility that our design gives we can have an event API but we",
    "start": "865180",
    "end": "872800"
  },
  {
    "text": "can also have other API is that that I do not have the notion of say events messages or records and for events in",
    "start": "872800",
    "end": "881470"
  },
  {
    "text": "particular you give an example we can rely on a silly Eliza from the application which will will be",
    "start": "881470",
    "end": "888310"
  },
  {
    "text": "responsible for taking events and and just on Miche bites and that's the final state data that we store now when we",
    "start": "888310",
    "end": "898779"
  },
  {
    "start": "898000",
    "end": "898000"
  },
  {
    "text": "talk about so one of the things that a segment give us is the ability of",
    "start": "898779",
    "end": "904449"
  },
  {
    "text": "providing parallelism so an application that is writing to April Vega stream is",
    "start": "904449",
    "end": "910779"
  },
  {
    "text": "able to write those segments in parallel so that gives us a high capacity for",
    "start": "910779",
    "end": "916420"
  },
  {
    "text": "ingesting data now when an application is writing you can use routing keys to",
    "start": "916420",
    "end": "921910"
  },
  {
    "text": "map the particular and so if you're using the event API to map the particular events to segments and in",
    "start": "921910",
    "end": "928660"
  },
  {
    "text": "that way we're guaranteeing perky order but across keys we do not necessarily",
    "start": "928660",
    "end": "933910"
  },
  {
    "text": "guarantee order but again that's that the cause of that said the benefit of our giving that providing higher",
    "start": "933910",
    "end": "940149"
  },
  {
    "text": "performance or giving the parallelism very we're getting with the with the segment's another benefit we get from",
    "start": "940149",
    "end": "949259"
  },
  {
    "start": "949000",
    "end": "949000"
  },
  {
    "text": "reasoning or thinking about segments is their biggity to scale strings so we can",
    "start": "949259",
    "end": "956110"
  },
  {
    "text": "start say like we have in the in this example we have we start with two segments then we can go to five at some",
    "start": "956110",
    "end": "964750"
  },
  {
    "text": "point because our our load is higher and then at some later time we can scale",
    "start": "964750",
    "end": "970569"
  },
  {
    "text": "down because the workload is because they were 200 this has dropped so those",
    "start": "970569",
    "end": "977290"
  },
  {
    "text": "are operations that we can perform because again we we have this notion of segments we can we",
    "start": "977290",
    "end": "982930"
  },
  {
    "text": "can seem segments and can create new segments and compose that in a industry",
    "start": "982930",
    "end": "989100"
  },
  {
    "text": "segments are also used when we when we when we click a transactions so when an",
    "start": "993540",
    "end": "1000780"
  },
  {
    "start": "994000",
    "end": "994000"
  },
  {
    "text": "application creates a transaction improve eiga we create temporary segments we call",
    "start": "1000780",
    "end": "1006750"
  },
  {
    "text": "them transactional segments so the application as the application is writing events to the transaction it's",
    "start": "1006750",
    "end": "1013350"
  },
  {
    "text": "writing to those transaction segments so there's no interference between the events that are being written to the",
    "start": "1013350",
    "end": "1019500"
  },
  {
    "text": "transaction and and they then started being written to the main segments of",
    "start": "1019500",
    "end": "1024510"
  },
  {
    "text": "the stream so those that data that is being written to the transaction segments they're only they only become",
    "start": "1024510",
    "end": "1032100"
  },
  {
    "text": "visible in power of the primary segments of the screen once they are what once",
    "start": "1032100",
    "end": "1038430"
  },
  {
    "text": "they're committed and once a commit happens then those segments are merged now if for any reason the application",
    "start": "1038430",
    "end": "1046280"
  },
  {
    "text": "doesn't want that transaction anymore can abort and the transactions are are deleted and there is no trace of the of",
    "start": "1046280",
    "end": "1055680"
  },
  {
    "text": "the data after that so again there's an interference between the transaction and the primary segments in the case of",
    "start": "1055680",
    "end": "1062250"
  },
  {
    "text": "awards we can also use segments for",
    "start": "1062250",
    "end": "1071010"
  },
  {
    "start": "1069000",
    "end": "1069000"
  },
  {
    "text": "example to implement replicated sig machines we have the notion imperfect of",
    "start": "1071010",
    "end": "1077730"
  },
  {
    "text": "revision streams where we have conditional events so we compare we",
    "start": "1077730",
    "end": "1083550"
  },
  {
    "text": "compare offsets when appending and that only happens if the if the offset matches we use that property to",
    "start": "1083550",
    "end": "1091410"
  },
  {
    "text": "implement a primitive called state synchronizing which we both exposing our",
    "start": "1091410",
    "end": "1097800"
  },
  {
    "text": "API and we we use it internally I had talked about reader groups that we use",
    "start": "1097800",
    "end": "1103050"
  },
  {
    "text": "in the coordination of our reader groups and in general as I have just mentioned we can implement replicated state",
    "start": "1103050",
    "end": "1109230"
  },
  {
    "text": "machines with it and and in Denison with optimistic concurrency",
    "start": "1109230",
    "end": "1115220"
  },
  {
    "text": "you now let's focus on a bit on one of the",
    "start": "1115220",
    "end": "1122230"
  },
  {
    "text": "features that I have just mentioned which is dream skating that's that's an interesting one is one of the of the key",
    "start": "1122230",
    "end": "1128200"
  },
  {
    "text": "not novel features of pro Vega so it's gaining a serene consistent was",
    "start": "1128200",
    "end": "1133900"
  },
  {
    "start": "1133000",
    "end": "1133000"
  },
  {
    "text": "all dynamically changing the set of segments of the string so you can for",
    "start": "1133900",
    "end": "1139360"
  },
  {
    "text": "example start with a single segment and and later we decide that we need a",
    "start": "1139360",
    "end": "1146470"
  },
  {
    "text": "higher degree of parallelism and create new segments so you can go say from one Jeju we have the bigger of scary is",
    "start": "1146470",
    "end": "1153820"
  },
  {
    "text": "skating automatically so if you configure SCIM to out the scale then then previa we internally track the load",
    "start": "1153820",
    "end": "1159640"
  },
  {
    "text": "and and then scale accordingly but also there you have the option of of",
    "start": "1159640",
    "end": "1165570"
  },
  {
    "text": "manually scaling streams in provegan and you can think of them as as proactive",
    "start": "1165570",
    "end": "1170860"
  },
  {
    "text": "versus reactive so for example if you anticipate that your workload is such that a you will need a higher degree of",
    "start": "1170860",
    "end": "1178330"
  },
  {
    "text": "parameters and you can go ahead and and in menu scale in ahead of time where all",
    "start": "1178330",
    "end": "1183790"
  },
  {
    "text": "the scale is reactive as it observes that the load has changed then it will react and scale accordingly so those are",
    "start": "1183790",
    "end": "1191440"
  },
  {
    "text": "the two mechanisms that we offer as part of scaling streams now looking in in",
    "start": "1191440",
    "end": "1198700"
  },
  {
    "text": "more detail on how this works let's let's say an abstract example before we",
    "start": "1198700",
    "end": "1206500"
  },
  {
    "text": "go into a more concrete one so we start with a single with a single segment remember that I said that in the case of",
    "start": "1206500",
    "end": "1214270"
  },
  {
    "text": "events we map events two segments according to should the routing key space so we have the space between",
    "start": "1214270",
    "end": "1220210"
  },
  {
    "text": "season one and I'm starting with the one single segment so so all keys will map",
    "start": "1220210",
    "end": "1225460"
  },
  {
    "text": "to the same segment now let's say that we have pair of keys that are that are",
    "start": "1225460",
    "end": "1232570"
  },
  {
    "text": "that are hot and so that induces a scale",
    "start": "1232570",
    "end": "1237730"
  },
  {
    "text": "of events so we split segment one into two two equal segments of an of equal",
    "start": "1237730",
    "end": "1244300"
  },
  {
    "text": "length segments two and three and that keeps going at some point we",
    "start": "1244300",
    "end": "1250330"
  },
  {
    "text": "decide that that's not enough and and oh actually let me give an example first so",
    "start": "1250330",
    "end": "1256560"
  },
  {
    "text": "let's you understand this a bit better say that those those keys are",
    "start": "1256560",
    "end": "1262270"
  },
  {
    "text": "representing locations in a Geo application all right so say that I we talked about taxi rights and looking at",
    "start": "1262270",
    "end": "1269950"
  },
  {
    "text": "the specific arrive some people in a in a particular City so some particular location can be hard",
    "start": "1269950",
    "end": "1275980"
  },
  {
    "text": "because of any events and and that could induce such a such a higher load in in",
    "start": "1275980",
    "end": "1282660"
  },
  {
    "text": "to give for cup of keys or a number of keys now but let's say that that's not",
    "start": "1282660",
    "end": "1289210"
  },
  {
    "text": "enough I say that's not enough and now",
    "start": "1289210",
    "end": "1295300"
  },
  {
    "text": "we end up splitting again into segments four and five and and that keeps going",
    "start": "1295300",
    "end": "1301810"
  },
  {
    "text": "until the point that uh those keys become code they go back to code and",
    "start": "1301810",
    "end": "1307950"
  },
  {
    "text": "perfect realizes that the traffic is not a it's not hard as it was before and and",
    "start": "1307950",
    "end": "1313950"
  },
  {
    "text": "you can the two segments can be merged into one single segment so that's the",
    "start": "1313950",
    "end": "1319570"
  },
  {
    "text": "will be the end state of of the string now one important observation here is",
    "start": "1319570",
    "end": "1328120"
  },
  {
    "text": "that as as the segments in the stream",
    "start": "1328120",
    "end": "1334930"
  },
  {
    "text": "are changing as we have this dynamic changes to the set of segments a single key does not necessarily map to the same",
    "start": "1334930",
    "end": "1343390"
  },
  {
    "text": "segment over time and that does not require anything specific from the",
    "start": "1343390",
    "end": "1348550"
  },
  {
    "text": "application the application doesn't have to do anything specific about it so provegan under the hood manages those",
    "start": "1348550",
    "end": "1354490"
  },
  {
    "text": "there's a second assignment of keys to the specific segment so if we pick for",
    "start": "1354490",
    "end": "1359800"
  },
  {
    "text": "example 0.9 we'll see that initially it points the second one then in that",
    "start": "1359800",
    "end": "1365350"
  },
  {
    "text": "segment you then two for them to six and and again under the hood per Vega we'll",
    "start": "1365350",
    "end": "1371020"
  },
  {
    "text": "manage that those and those things for you and there will be transparent touch",
    "start": "1371020",
    "end": "1376450"
  },
  {
    "text": "the application hey Fabio let's look at hey Fabio oh",
    "start": "1376450",
    "end": "1386460"
  },
  {
    "text": "yeah go ahead Gracie oh we just had a question come through the Q&A do you want to answer it now or do you prefer",
    "start": "1386460",
    "end": "1392440"
  },
  {
    "text": "to wait till the end and I'm going to talk about this I'm gonna talk about",
    "start": "1392440",
    "end": "1398350"
  },
  {
    "text": "stars in a second haven't talked about the architecture great okay it sounds good thanks",
    "start": "1398350",
    "end": "1405600"
  },
  {
    "text": "okay so heat map so this is the heat map were generated from from a real",
    "start": "1406799",
    "end": "1414070"
  },
  {
    "text": "execution this isn't one of our test clusters and what we've seen here is the",
    "start": "1414070",
    "end": "1420519"
  },
  {
    "text": "set of segments over times the way over time that we have the color represents",
    "start": "1420519",
    "end": "1425649"
  },
  {
    "text": "the the loads in that given segment at a given time so if it looks if if it looks",
    "start": "1425649",
    "end": "1434019"
  },
  {
    "text": "red then the work is the the workloads higher than that segment if it looks like light blue then it's the workload",
    "start": "1434019",
    "end": "1440440"
  },
  {
    "text": "slowly so that's the spectrum you see at the bottom of the of the heat map and the white you see is the split between",
    "start": "1440440",
    "end": "1447820"
  },
  {
    "text": "between segments so we starting from the left we see a good number of say why",
    "start": "1447820",
    "end": "1454600"
  },
  {
    "text": "it's right which indicates a good number of segments as we move towards the right",
    "start": "1454600",
    "end": "1459690"
  },
  {
    "text": "we see we see that the number of segments reducing which currently",
    "start": "1459690",
    "end": "1466000"
  },
  {
    "text": "indicates that the working this is dropping enough that segments need to merge and we can also see that based on",
    "start": "1466000",
    "end": "1472779"
  },
  {
    "text": "the on the color of the segments like the light blue colors in the in those segments don't you a minimum that starts",
    "start": "1472779",
    "end": "1481630"
  },
  {
    "text": "at around that it may be 2:30 in and",
    "start": "1481630",
    "end": "1486850"
  },
  {
    "text": "goes all the way to a bit over 5:30 a.m. so there's a minimum of two segments",
    "start": "1486850",
    "end": "1492490"
  },
  {
    "text": "around that time and then from 5:30 6:00 a.m. it starts to pick up again where I",
    "start": "1492490",
    "end": "1499210"
  },
  {
    "text": "we start seeing segments splitting a good amount of red which indicates that add segments are hot and and and we have",
    "start": "1499210",
    "end": "1507870"
  },
  {
    "text": "we have a larger number of segments around time now we have generated this graph",
    "start": "1507870",
    "end": "1515390"
  },
  {
    "text": "with we have generated this graph with a",
    "start": "1515390",
    "end": "1521600"
  },
  {
    "text": "workload from this New York City yellow taxi trip records so they were I is at",
    "start": "1521600",
    "end": "1527690"
  },
  {
    "start": "1525000",
    "end": "1525000"
  },
  {
    "text": "the bottom of the slide and we can see that those changes to segments they",
    "start": "1527690",
    "end": "1534830"
  },
  {
    "text": "follow the the workload that we observed in here so as we move from left to right",
    "start": "1534830",
    "end": "1540800"
  },
  {
    "text": "we can see the work out dropping down to minimum around 4:00 a.m. and then and",
    "start": "1540800",
    "end": "1546470"
  },
  {
    "text": "then around 5:30 6:00 a.m. starts to pick up again right so and this is",
    "start": "1546470",
    "end": "1551990"
  },
  {
    "text": "precisely the fact we you wanted to see with respect to scaling right so as as the workload changes as it drops we need",
    "start": "1551990",
    "end": "1558680"
  },
  {
    "text": "fewer segments as it goes up we need a larger number of segments and need more parallelism so if you put those two",
    "start": "1558680",
    "end": "1566300"
  },
  {
    "text": "graphs together we can see we can see again that on the left hand side we have",
    "start": "1566300",
    "end": "1571880"
  },
  {
    "text": "a good amount of merging of segments and and on the right hand side we see and",
    "start": "1571880",
    "end": "1579920"
  },
  {
    "text": "then splitting as the as the load pizza so that's a that's an illustration of",
    "start": "1579920",
    "end": "1587840"
  },
  {
    "text": "what we expect to see for a stream scaling in a production application now",
    "start": "1587840",
    "end": "1595580"
  },
  {
    "text": "let's talk a bit about the the the prevalent architecture so one of the questions that our that we got was about",
    "start": "1595580",
    "end": "1600620"
  },
  {
    "text": "them destroyed subsystem so let's let's talk a bit about not only that but other",
    "start": "1600620",
    "end": "1605960"
  },
  {
    "text": "aspects of the of the architecture we went ready to prove again so if we focus",
    "start": "1605960",
    "end": "1613580"
  },
  {
    "start": "1610000",
    "end": "1610000"
  },
  {
    "text": "on events we have even writers they append to a previous frames we the product stream and we can have a number",
    "start": "1613580",
    "end": "1621080"
  },
  {
    "text": "of parallel segments we track writer positions so that so that we can ensure",
    "start": "1621080",
    "end": "1627860"
  },
  {
    "text": "that in the case of connections dropping and restarting that are we able to",
    "start": "1627860",
    "end": "1633140"
  },
  {
    "text": "resume from from the correct position we",
    "start": "1633140",
    "end": "1639320"
  },
  {
    "text": "also have readers right that can those events we group readers into what",
    "start": "1639320",
    "end": "1645400"
  },
  {
    "start": "1641000",
    "end": "1641000"
  },
  {
    "text": "we call reader groups and with the groups you split the segment load across the readers in the group they also",
    "start": "1645400",
    "end": "1651340"
  },
  {
    "text": "balance the load across those readers and we can ads we can grow and shrink that set by by adding and removing event",
    "start": "1651340",
    "end": "1659290"
  },
  {
    "text": "readers so that's not a big data that we provide and that that's the case even",
    "start": "1659290",
    "end": "1666490"
  },
  {
    "text": "not in the presence of stream scaling that we have just said we have we just talked about internally purveyor has two",
    "start": "1666490",
    "end": "1675070"
  },
  {
    "start": "1673000",
    "end": "1673000"
  },
  {
    "text": "core components one is the controller the controller manages stream metadata",
    "start": "1675070",
    "end": "1680549"
  },
  {
    "text": "the lifecycle of off streams and and",
    "start": "1680549",
    "end": "1686590"
  },
  {
    "text": "also manages transactions now the second element which is a segment store focuses",
    "start": "1686590",
    "end": "1692830"
  },
  {
    "text": "entirely on segments of the controller is responsible for making sense of of",
    "start": "1692830",
    "end": "1698820"
  },
  {
    "text": "segments and exposing the obstruction of streams to applications so stream is on",
    "start": "1698820",
    "end": "1704530"
  },
  {
    "text": "a concept of the of the underlying storage right of the segment store it's",
    "start": "1704530",
    "end": "1709630"
  },
  {
    "text": "a concept that is exposed by by the controller the segment store managers the lifecycle of segments and and stores",
    "start": "1709630",
    "end": "1717330"
  },
  {
    "text": "segment metadata we use a tiered storage",
    "start": "1717330",
    "end": "1725140"
  },
  {
    "start": "1725000",
    "end": "1725000"
  },
  {
    "text": "in in the segment store the first year is a tier that provides low latency for",
    "start": "1725140",
    "end": "1732340"
  },
  {
    "text": "for small rise and we use the patchy bookkeeper for that and we have a second",
    "start": "1732340",
    "end": "1738700"
  },
  {
    "text": "tier which is is what we call the long term storage and that can be implemented",
    "start": "1738700",
    "end": "1744610"
  },
  {
    "text": "with file or object so we have different bindings for for different systems so we can plug an NFS an NFS mounts or it can",
    "start": "1744610",
    "end": "1754450"
  },
  {
    "text": "plug up an object store those would work with previous oh that's that's bloody",
    "start": "1754450",
    "end": "1759640"
  },
  {
    "text": "boy in our system we also use apache zookeeper for for a few things for for",
    "start": "1759640",
    "end": "1766900"
  },
  {
    "text": "coordinating the the segment containers a split of workload across segments",
    "start": "1766900",
    "end": "1773169"
  },
  {
    "text": "store instances and for doing things around transactions as well let's",
    "start": "1773169",
    "end": "1782470"
  },
  {
    "text": "have a closer look at how the write and read path work so the right path is such",
    "start": "1782470",
    "end": "1789010"
  },
  {
    "start": "1784000",
    "end": "1784000"
  },
  {
    "text": "that when a event stream writer wants to append events the first thing we'll do",
    "start": "1789010",
    "end": "1794860"
  },
  {
    "text": "is contact the controller to determine what what is the segment story that he needs to me so thank you and that's",
    "start": "1794860",
    "end": "1800830"
  },
  {
    "text": "phase again on the assignment of of work to the different segment stores so once",
    "start": "1800830",
    "end": "1806620"
  },
  {
    "text": "he learns from the controller you can talk to you connect to the segment store and start appending bytes the bytes from",
    "start": "1806620",
    "end": "1815200"
  },
  {
    "text": "from the events it will those rights be persisted to to Apache bookkeeper so we",
    "start": "1815200",
    "end": "1824410"
  },
  {
    "text": "won't acknowledge to day then writer until we receive a response from bookkeeper that that has been persisted",
    "start": "1824410",
    "end": "1831130"
  },
  {
    "text": "and Apache bookkeeper on on its end will guarantee that the data is persistent",
    "start": "1831130",
    "end": "1838830"
  },
  {
    "text": "and the second tier which I have mentioned for long-term storage",
    "start": "1838830",
    "end": "1844360"
  },
  {
    "text": "we don't write trade immediately so we a synchronously move the data to that",
    "start": "1844360",
    "end": "1851380"
  },
  {
    "text": "long-term storage which enables us to trim data to truncate data from from",
    "start": "1851380",
    "end": "1857860"
  },
  {
    "text": "Apache bookkeeper legends which is the log abstraction that Apache bookkeeper exposes and as I have mentioned before",
    "start": "1857860",
    "end": "1865480"
  },
  {
    "text": "for long term strategy we offer different options you can use for example HDFS or an NFS mount you just",
    "start": "1865480",
    "end": "1872380"
  },
  {
    "text": "serve as the the long term storage on",
    "start": "1872380",
    "end": "1878770"
  },
  {
    "text": "the repast on the repast the reader will",
    "start": "1878770",
    "end": "1884890"
  },
  {
    "start": "1880000",
    "end": "1880000"
  },
  {
    "text": "follow seem similar a similar sequence of steps you contact the controller to know what you read from with signals for",
    "start": "1884890",
    "end": "1892390"
  },
  {
    "text": "serving a particular segment and the segment store will will serve data from",
    "start": "1892390",
    "end": "1898450"
  },
  {
    "text": "from the cache if it's a cache hit then we'll serve them a debate immediately which is the case when you're taking a",
    "start": "1898450",
    "end": "1905860"
  },
  {
    "text": "stream but if you're performing historical reads then it's most likely will be a cache",
    "start": "1905860",
    "end": "1912370"
  },
  {
    "text": "miss and you will read data from from long-term storage so that's essentially",
    "start": "1912370",
    "end": "1918460"
  },
  {
    "text": "how the read and the write have work I",
    "start": "1918460",
    "end": "1923490"
  },
  {
    "text": "want to switch gears out and and talk talk a bit about how connect I'll",
    "start": "1923850",
    "end": "1930910"
  },
  {
    "text": "predict a connect Stuart Chu applications in particular to stream processors which is what I mentioned",
    "start": "1930910",
    "end": "1936340"
  },
  {
    "text": "when I talked about the landscape of applications the main idea is that we",
    "start": "1936340",
    "end": "1943809"
  },
  {
    "text": "develop connectors so we have a sync connector that that takes data in writes",
    "start": "1943809",
    "end": "1949660"
  },
  {
    "text": "you to a previous stream and you also have the other end which is the which is",
    "start": "1949660",
    "end": "1955540"
  },
  {
    "text": "when you want to consume data from from a product stream that would be a source connected so one example of a connector",
    "start": "1955540",
    "end": "1963309"
  },
  {
    "text": "that that we have developed this is the faint connectors you have the have the URL of the repository at the bottom of",
    "start": "1963309",
    "end": "1969850"
  },
  {
    "text": "the slide but that's the general notion of connectors and we have developed a few of them so there is the Apache Frank",
    "start": "1969850",
    "end": "1976840"
  },
  {
    "start": "1974000",
    "end": "1974000"
  },
  {
    "text": "when I have destination there is one for Apache Hadoop we have plug-ins for log stash there's a",
    "start": "1976840",
    "end": "1982390"
  },
  {
    "text": "recent one developed by the community for alpaca and there are more to come there are some that are the developing",
    "start": "1982390",
    "end": "1989320"
  },
  {
    "text": "development areas and hopefully we see more contributions from from the community but here I want to focus on or",
    "start": "1989320",
    "end": "1997270"
  },
  {
    "text": "the Apache flink one because that can that can show some interesting aspects of of connecting stream processor with",
    "start": "1997270",
    "end": "2004230"
  },
  {
    "text": "with pro Vega and the proper data that we can get so Apache flink is a",
    "start": "2004230",
    "end": "2011760"
  },
  {
    "text": "framework that enables and it was want to do two things one is to write",
    "start": "2011760",
    "end": "2018350"
  },
  {
    "start": "2012000",
    "end": "2012000"
  },
  {
    "text": "distributed miscibility processing applications and the second is to deploy these applications in a distributed",
    "start": "2018350",
    "end": "2024360"
  },
  {
    "text": "manner so it's a framework that enables you to write such code and and also",
    "start": "2024360",
    "end": "2030030"
  },
  {
    "text": "unable to Achuar to run it so it's a runtime for for such applications and",
    "start": "2030030",
    "end": "2035480"
  },
  {
    "text": "it's it's able to process both bounded",
    "start": "2035480",
    "end": "2041280"
  },
  {
    "text": "and unbounded datasets and bound besides being a being streams inbound datasets you can see there's historical",
    "start": "2041280",
    "end": "2048089"
  },
  {
    "text": "data now the idea of using provegan with",
    "start": "2048089",
    "end": "2054450"
  },
  {
    "start": "2053000",
    "end": "2053000"
  },
  {
    "text": "Flint would be that's the the data the data from all the sources continuously",
    "start": "2054450",
    "end": "2061169"
  },
  {
    "text": "generating it it doesn't just occur per Vega per Vega can serve both third-party applications",
    "start": "2061169",
    "end": "2068280"
  },
  {
    "text": "or fling jobs or we can have fun job serving those consuming applications or",
    "start": "2068280",
    "end": "2073858"
  },
  {
    "text": "we can have combinations of those so the interesting the interesting aspect is",
    "start": "2073859",
    "end": "2079500"
  },
  {
    "text": "that we can use this interleaving stages of processing and and in storage to",
    "start": "2079500",
    "end": "2087540"
  },
  {
    "text": "build complex and complex pipelines and this is essentially the idea of this",
    "start": "2087540",
    "end": "2094740"
  },
  {
    "text": "figure where we have again the data being just that you're a beggar and perhaps you have multiple stages",
    "start": "2094740",
    "end": "2100010"
  },
  {
    "start": "2095000",
    "end": "2095000"
  },
  {
    "text": "offering jobs that that can give you the final output that you need and again you",
    "start": "2100010",
    "end": "2107670"
  },
  {
    "text": "can think of applications where you you want to do most both stages you cannot you don't want to do one",
    "start": "2107670",
    "end": "2113820"
  },
  {
    "text": "single stage as one single run over the data or mi-8 money when derive some",
    "start": "2113820",
    "end": "2119880"
  },
  {
    "text": "intermediate data sets before we forget your final output",
    "start": "2119880",
    "end": "2125720"
  },
  {
    "text": "so when reading from pro Vega when we need from provegan us what's called",
    "start": "2126840",
    "end": "2134500"
  },
  {
    "text": "source tasks in or source tasks in in flink each one of them we execute a",
    "start": "2134500",
    "end": "2140830"
  },
  {
    "text": "private reader so the set of private readers across the source tasks will",
    "start": "2140830",
    "end": "2146410"
  },
  {
    "text": "form a reader group and they will split the load of segments across them and and",
    "start": "2146410",
    "end": "2152620"
  },
  {
    "text": "even deal with the changes to segments that could happen because of scaling and",
    "start": "2152620",
    "end": "2158650"
  },
  {
    "text": "all that complexity as I mentioned before is hidden from the application the application doesn't have to to deal",
    "start": "2158650",
    "end": "2164890"
  },
  {
    "text": "with any of those changes to the to the set of segments now one interesting one",
    "start": "2164890",
    "end": "2173110"
  },
  {
    "start": "2171000",
    "end": "2171000"
  },
  {
    "text": "important feature that that we exposing that flink leverages is checkpointing we",
    "start": "2173110",
    "end": "2180580"
  },
  {
    "text": "we give we give the birria of getting a position across the the segments of the",
    "start": "2180580",
    "end": "2187030"
  },
  {
    "text": "stream so that so that flink you can use that as part of its own check pointing mechanism so when the master of a flink",
    "start": "2187030",
    "end": "2194800"
  },
  {
    "text": "job is ready to take a check point it will request from the reader group a check point internally the readers will",
    "start": "2194800",
    "end": "2204430"
  },
  {
    "text": "coordinate via state synchronizing and as far as that each one of the readers",
    "start": "2204430",
    "end": "2209650"
  },
  {
    "text": "will emits a checkpoint event and that checkpoint event is going to trigger the",
    "start": "2209650",
    "end": "2215700"
  },
  {
    "text": "the following steps of the fling checkpoint mechanism and finally when",
    "start": "2215700",
    "end": "2223630"
  },
  {
    "text": "that process completes the master receives a checkpoint installs that as part of the of the metadata of a",
    "start": "2223630",
    "end": "2229420"
  },
  {
    "text": "checkpoint that a the job requires and we've seen a second why that's important",
    "start": "2229420",
    "end": "2234700"
  },
  {
    "text": "for for exactly one semantics I am a bit",
    "start": "2234700",
    "end": "2241120"
  },
  {
    "text": "of codes you can you can create a perfect source by creating private",
    "start": "2241120",
    "end": "2246430"
  },
  {
    "text": "reader from the from the the connector I have mentioned so to do that you pass",
    "start": "2246430",
    "end": "2253720"
  },
  {
    "text": "the purveyor config you tell which stream you want to read from a serializer and you can use that as a source in a in",
    "start": "2253720",
    "end": "2263099"
  },
  {
    "start": "2262000",
    "end": "2262000"
  },
  {
    "text": "a fling as part of a fling job so you can see more detail in in a repository containing samples if you're interested",
    "start": "2263099",
    "end": "2271640"
  },
  {
    "text": "now let's move to talk about writing so when writing if you I'm gonna skip that",
    "start": "2272269",
    "end": "2278940"
  },
  {
    "start": "2278000",
    "end": "2278000"
  },
  {
    "text": "at least once apart and focus entirely on the exactly once part which uses transactions to write back to providers",
    "start": "2278940",
    "end": "2286740"
  },
  {
    "text": "so if you have a job that you're passing data say you're reading from a previous stream and you're crossing and now",
    "start": "2286740",
    "end": "2292500"
  },
  {
    "text": "you're dumping Chua to another project stream that will happen in the context",
    "start": "2292500",
    "end": "2297690"
  },
  {
    "text": "of transactions and so to make that work correctly flink will execute a two-phase",
    "start": "2297690",
    "end": "2305430"
  },
  {
    "text": "commit like protocol as I mention you also have the option of disabling that in using at least one semantics in which",
    "start": "2305430",
    "end": "2312750"
  },
  {
    "text": "case you won't be using transactions",
    "start": "2312750",
    "end": "2316430"
  },
  {
    "text": "so the way it works is the Flint master will start the checkpoint you would do",
    "start": "2318130",
    "end": "2323470"
  },
  {
    "text": "you execute those steps I mentioned previously and that's the stuff that I'm calling prepare right so when when it",
    "start": "2323470",
    "end": "2330039"
  },
  {
    "text": "starts that at that process of checkpoint you will push marks which will flow through the through the data",
    "start": "2330039",
    "end": "2335950"
  },
  {
    "text": "graph of a of a freak job when those marks reach the sink tasks they will",
    "start": "2335950",
    "end": "2344079"
  },
  {
    "text": "acknowledge that to the Flint master the fluent master was here from all source sink tasks he will complete the",
    "start": "2344079",
    "end": "2350950"
  },
  {
    "text": "checkpoint indicating that to the sink tasks and at that point they will commit their cause phony transactions so that",
    "start": "2350950",
    "end": "2358930"
  },
  {
    "text": "flow guarantees that the data that the data's being processing in an exactly",
    "start": "2358930",
    "end": "2364539"
  },
  {
    "text": "ones manner",
    "start": "2364539",
    "end": "2367529"
  },
  {
    "text": "so this is all against some code and now choo choo right a sink with a Fink per leg a writer here again you need you can",
    "start": "2370460",
    "end": "2378869"
  },
  {
    "start": "2371000",
    "end": "2371000"
  },
  {
    "text": "pacify very configured cell with stream you're gonna write you're gonna write you have the event router for a",
    "start": "2378869",
    "end": "2385200"
  },
  {
    "text": "geologist specific streams using I'm here using the exactly once mode a",
    "start": "2385200",
    "end": "2391849"
  },
  {
    "text": "civilization etc and then you can add that as part of a of your job okay so",
    "start": "2391849",
    "end": "2401819"
  },
  {
    "text": "that's what I wanted to say about flink let me now talk a bit about pre vega on on kubernetes",
    "start": "2401819",
    "end": "2407640"
  },
  {
    "text": "so we have we use operators in a in a few places so an operator is a custom",
    "start": "2407640",
    "end": "2413640"
  },
  {
    "start": "2411000",
    "end": "2411000"
  },
  {
    "text": "controller from managing the lifecycle of an application in our case an application is is its pre vega but it's",
    "start": "2413640",
    "end": "2420420"
  },
  {
    "text": "also other systems that we use along with predicates for example bookkeeper and zookeeper and it does automation and",
    "start": "2420420",
    "end": "2427289"
  },
  {
    "text": "on a number of dimensions deployment configuration and making sure that",
    "start": "2427289",
    "end": "2436279"
  },
  {
    "text": "looking for disruption budgets looking at a party affinity part affinity and",
    "start": "2436670",
    "end": "2443130"
  },
  {
    "text": "anti affinity rules so those are properties that are they looks into so",
    "start": "2443130",
    "end": "2449339"
  },
  {
    "text": "scaling elements of the system performing upgrades so for example vega",
    "start": "2449339",
    "end": "2456059"
  },
  {
    "text": "upgrades are managed by the by the operator and also monitoring the the",
    "start": "2456059",
    "end": "2462299"
  },
  {
    "text": "health of the different elements of the system so i had mentioned we we do we",
    "start": "2462299",
    "end": "2471029"
  },
  {
    "text": "have a number of operators we have a april vega operator which focuses on the of the core elements of pro Vega",
    "start": "2471029",
    "end": "2478109"
  },
  {
    "text": "controller in segment stores so we have the private operator for that and we have a couple of other operators one for",
    "start": "2478109",
    "end": "2485069"
  },
  {
    "text": "bookkeeper and one for zookeeper so you can see the the repositories listed in",
    "start": "2485069",
    "end": "2491009"
  },
  {
    "text": "the in this slide if you interested in more information you can you can go check our documentation",
    "start": "2491009",
    "end": "2498109"
  },
  {
    "text": "all right so that's a best ring my toy I wanted to cover some ready to wrap up in",
    "start": "2500500",
    "end": "2507619"
  },
  {
    "text": "conclusion we are motivated to work of our swing processing your probe eiga",
    "start": "2507619",
    "end": "2513050"
  },
  {
    "start": "2511000",
    "end": "2511000"
  },
  {
    "text": "that's coming from the needs of processing this multitude of sources",
    "start": "2513050",
    "end": "2518240"
  },
  {
    "text": "that are constantly generating data i've talked about in the users that are continuously producing events or",
    "start": "2518240",
    "end": "2524540"
  },
  {
    "text": "performing online transactions I mentioned IT sensors servers drones all",
    "start": "2524540",
    "end": "2532940"
  },
  {
    "text": "those are potential sources of of continuously generated data that we want",
    "start": "2532940",
    "end": "2538580"
  },
  {
    "text": "to ingest and process not necessarily in in a tailing manner no tailing the data",
    "start": "2538580",
    "end": "2544310"
  },
  {
    "text": "as it comes in but also being able to reprocess any in the arbitrary time Pro",
    "start": "2544310",
    "end": "2550369"
  },
  {
    "text": "Vega aims to be a critical piece of that of that puzzle in particular provides",
    "start": "2550369",
    "end": "2557410"
  },
  {
    "text": "providing stream as a storage primitive so predict is the storage for up for",
    "start": "2557410",
    "end": "2562700"
  },
  {
    "text": "data streams and it provides important properties for for such applications it's it's able to ingest an abundant",
    "start": "2562700",
    "end": "2572480"
  },
  {
    "text": "amount of data on a per-student basis it gives you LSCC based on our auto scaling feature and it",
    "start": "2572480",
    "end": "2580850"
  },
  {
    "text": "gives it gives us the ability of Afghan Singh consistency for the data that is",
    "start": "2580850",
    "end": "2587510"
  },
  {
    "text": "being ingested and also the data that is being read in the way that I have illustrated with with link to connect",
    "start": "2587510",
    "end": "2595340"
  },
  {
    "text": "pro Vega to two extreme processors we have two big connectors I have mentioned",
    "start": "2595340",
    "end": "2602359"
  },
  {
    "text": "a few of them but I have focused mostly on one example which is Apache Frank and I have shown how we can build exactly",
    "start": "2602359",
    "end": "2609109"
  },
  {
    "text": "once end to end using prevent properties and properties of of the stream",
    "start": "2609109",
    "end": "2614300"
  },
  {
    "text": "processing Rivera is open source it's licensed under the Apache License vichu",
    "start": "2614300",
    "end": "2621050"
  },
  {
    "text": "it's currently hosted on github and one of the things that we're looking to is",
    "start": "2621050",
    "end": "2626090"
  },
  {
    "text": "looking looking for a home for for incubation so we hope to eventually hit",
    "start": "2626090",
    "end": "2633400"
  },
  {
    "text": "some foundation and and and be hosted there now before I close indicates that",
    "start": "2633400",
    "end": "2642260"
  },
  {
    "start": "2641000",
    "end": "2641000"
  },
  {
    "text": "anyone in here is interested in getting started with pro Vega why don't you give a few pointers that is of course the",
    "start": "2642260",
    "end": "2649369"
  },
  {
    "text": "website predicted that IO data that gives you a good amount of information has good documentation and explaining",
    "start": "2649369",
    "end": "2656210"
  },
  {
    "text": "parts of the system how to run in and and such there's of course the the repository itself that it can go and",
    "start": "2656210",
    "end": "2663140"
  },
  {
    "text": "check it out and see what kind of issues we are working on maybe pull requests maybe interact a bit with with the",
    "start": "2663140",
    "end": "2669530"
  },
  {
    "text": "developers you can run pervious standalone you know you can fact",
    "start": "2669530",
    "end": "2674930"
  },
  {
    "text": "repository run standalone and see and see how it feels maybe run some samples against that previous standalone it also",
    "start": "2674930",
    "end": "2682190"
  },
  {
    "text": "give you a feeling for how to write codes with Profeta and what kind of",
    "start": "2682190",
    "end": "2687530"
  },
  {
    "text": "features you can get you can also try and kubernetes look at the repository and see can see the structures for for",
    "start": "2687530",
    "end": "2694339"
  },
  {
    "text": "how to deploy there and all the features that we offer and and throughout the process you know feel free to provide",
    "start": "2694339",
    "end": "2701060"
  },
  {
    "text": "any feedback and even contribute that if you have a chance and with that a close",
    "start": "2701060",
    "end": "2708680"
  },
  {
    "text": "eye open up for questions I have a number of pointers here in the casing",
    "start": "2708680",
    "end": "2714500"
  },
  {
    "text": "just saying checking of the things that I have mentioned today thank you great thanks folio for a great",
    "start": "2714500",
    "end": "2720980"
  },
  {
    "text": "presentation and as Fabio mentioned it's now time for the question and answer piece of the webinar so we've got about",
    "start": "2720980",
    "end": "2727069"
  },
  {
    "text": "ten minutes Bobby all go ahead and read and some questions for you so the first one",
    "start": "2727069",
    "end": "2732470"
  },
  {
    "text": "that's from the J is Dupree Vega or does pro Vega have geo replication in its",
    "start": "2732470",
    "end": "2739160"
  },
  {
    "text": "roadmap something similar to pulsar yes",
    "start": "2739160",
    "end": "2745600"
  },
  {
    "text": "it is in our roadmap it isn't our roadmap we don't have that yet but it's clearly an important things and we're",
    "start": "2745600",
    "end": "2753580"
  },
  {
    "text": "doing great ok the next question is from Sharif and",
    "start": "2753580",
    "end": "2759370"
  },
  {
    "text": "the apologies of M but treating these names is there a SQL / SQL compatible layer",
    "start": "2759370",
    "end": "2766630"
  },
  {
    "text": "that can be used to query data and probe eiga something similar to k SQL for",
    "start": "2766630",
    "end": "2772950"
  },
  {
    "text": "Kafka also does it have a presto connector right",
    "start": "2772950",
    "end": "2780400"
  },
  {
    "text": "you can you can do c.coli queries with Frank so you could use that as for preso",
    "start": "2780400",
    "end": "2788830"
  },
  {
    "text": "we don't have a connector yet it is that's another thing that is now roadmap",
    "start": "2788830",
    "end": "2794609"
  },
  {
    "text": "great this question is from Anderson / Vega can be used in a surrealist",
    "start": "2795099",
    "end": "2801310"
  },
  {
    "text": "architecture lambda functions Oh asking if / Vega can be used in a surrealist",
    "start": "2801310",
    "end": "2806329"
  },
  {
    "text": "architecture yes absolutely that's another thing that we are thinking about",
    "start": "2806329",
    "end": "2812710"
  },
  {
    "text": "that's another thing that we think about and we definitely had some some functionality in that in that sense it",
    "start": "2812710",
    "end": "2821569"
  },
  {
    "text": "is actually very they're very good questions all things that are we we are looking to getting and so if any of you",
    "start": "2821569",
    "end": "2828980"
  },
  {
    "text": "is interested in contributing we are happy to hear your you know your opinions you know get your contribution",
    "start": "2828980",
    "end": "2834650"
  },
  {
    "text": "and analyze those are all great and great questions yeah looks like we have",
    "start": "2834650",
    "end": "2840710"
  },
  {
    "text": "another one that just came in from the cost does per Vega have predictive",
    "start": "2840710",
    "end": "2846260"
  },
  {
    "text": "analytics capabilities um per Vega",
    "start": "2846260",
    "end": "2851920"
  },
  {
    "text": "prevent itself is only this story bit storage bit so if you wanna if you want",
    "start": "2851920",
    "end": "2857810"
  },
  {
    "text": "to connect to anything that performs the analytics like we I have described with flink that's that makes total sense",
    "start": "2857810",
    "end": "2863930"
  },
  {
    "text": "right so per Vega gives you their baby of ingesting the streams and I can",
    "start": "2863930",
    "end": "2869150"
  },
  {
    "text": "reading from those streams and you know be doing that's in a way that it can",
    "start": "2869150",
    "end": "2874579"
  },
  {
    "text": "just data for arbitrary amounts of time you know architecture I have explained allows you to keep data for as long as",
    "start": "2874579",
    "end": "2880790"
  },
  {
    "text": "you like and so in that sense this is um this is great if you're looking to eat",
    "start": "2880790",
    "end": "2887060"
  },
  {
    "text": "you're processing a large amount of data for say I don't know training your model",
    "start": "2887060",
    "end": "2894160"
  },
  {
    "text": "right so all those those properties of the system of the storage system give",
    "start": "2894160",
    "end": "2899450"
  },
  {
    "text": "you the rate of doing those things but again if there's any system in particular that I your each study in",
    "start": "2899450",
    "end": "2905210"
  },
  {
    "text": "using there should be nothing that prevents you from from ready connector or even working those on writing a",
    "start": "2905210",
    "end": "2911540"
  },
  {
    "text": "connector great looks like we have time",
    "start": "2911540",
    "end": "2918170"
  },
  {
    "text": "for a few more questions any last-minute questions please drop them in the Q&A box give folks a minute here",
    "start": "2918170",
    "end": "2926980"
  },
  {
    "text": "okay not seeing any other questions come through so great thanks again Flavio for",
    "start": "2935520",
    "end": "2942010"
  },
  {
    "text": "a great resolution oh sorry they spoke too soon is there a purveyor",
    "start": "2942010",
    "end": "2948160"
  },
  {
    "text": "light version with built-in tier 2 support prevent light version with",
    "start": "2948160",
    "end": "2956020"
  },
  {
    "text": "butane THS support so not really so so",
    "start": "2956020",
    "end": "2966930"
  },
  {
    "text": "Rivera itself per Vega will connect to the tier 2 you provide if if duty means",
    "start": "2966930",
    "end": "2975460"
  },
  {
    "text": "that you want to use a local local storage in place so you can do that e",
    "start": "2975460",
    "end": "2984180"
  },
  {
    "text": "you won't be you won't give you like a lot of capacity right because one of the ideas is that 42 is that we have elastic",
    "start": "2984180",
    "end": "2994660"
  },
  {
    "text": "storage right for a long term for restoring data long term so in that",
    "start": "2994660",
    "end": "2999790"
  },
  {
    "text": "sense I would not recommend doing that we have thought of the ability of not",
    "start": "2999790",
    "end": "3006210"
  },
  {
    "text": "having THU but that's not a feature we we offer today ok and Sharif is asking",
    "start": "3006210",
    "end": "3016080"
  },
  {
    "text": "have you done some benchmarking against other streaming solutions example Kafka",
    "start": "3016080",
    "end": "3022020"
  },
  {
    "text": "or Pulsar we have we have the",
    "start": "3022020",
    "end": "3028230"
  },
  {
    "text": "performance observe aeneas comparable to both of them of course there are",
    "start": "3028230",
    "end": "3033330"
  },
  {
    "text": "differences you observe depending on the case based on the architectural",
    "start": "3033330",
    "end": "3038790"
  },
  {
    "text": "differences but but unfortunately I don't have numbers that I can share with you right now we have something soon but",
    "start": "3038790",
    "end": "3046620"
  },
  {
    "text": "we have been looking to that okay and",
    "start": "3046620",
    "end": "3051960"
  },
  {
    "text": "Tom is asking I think this will be our last question how does provegan identify bottlenecks in tier 1 and tier",
    "start": "3051960",
    "end": "3058740"
  },
  {
    "text": "2 storage how does protect identify bottlenecks in",
    "start": "3058740",
    "end": "3065600"
  },
  {
    "text": "tier 1 and tier 2 storage I'm not sure I",
    "start": "3065600",
    "end": "3072440"
  },
  {
    "text": "understand the question so so so if this",
    "start": "3072440",
    "end": "3078530"
  },
  {
    "text": "is asking about throttling if the question is about throttling we do try",
    "start": "3078530",
    "end": "3083870"
  },
  {
    "text": "to look into the traffic that is going you know what's in County versus what's",
    "start": "3083870",
    "end": "3089000"
  },
  {
    "text": "going to children to tier 2 so that's the amount of data same bookkeeper",
    "start": "3089000",
    "end": "3095630"
  },
  {
    "text": "doesn't grow with our bounds and we apply back pressure it should decline",
    "start": "3095630",
    "end": "3102340"
  },
  {
    "text": "okay great well oh sorry I keep saying",
    "start": "3103300",
    "end": "3109190"
  },
  {
    "text": "that one last last question here is there any Docs or pocs to do with CDC",
    "start": "3109190",
    "end": "3115520"
  },
  {
    "text": "with Pro Vega connectors I don't think",
    "start": "3115520",
    "end": "3127610"
  },
  {
    "text": "so so you can look at samples if you can see if there is anything that suits your",
    "start": "3127610",
    "end": "3132860"
  },
  {
    "text": "needs perfect samples that's the idea here",
    "start": "3132860",
    "end": "3138170"
  },
  {
    "text": "so it's one of the repositories in our in our organization great okay well that",
    "start": "3138170",
    "end": "3146990"
  },
  {
    "text": "is all the time that we have today I want to thank you all again for joining the webinar and thanks Flavio for the",
    "start": "3146990",
    "end": "3153140"
  },
  {
    "text": "great presentation a reminder that the slides will be available later today on the CNC after IO slash webinars page and",
    "start": "3153140",
    "end": "3161600"
  },
  {
    "text": "thanks again and we hope to see you all at a future CN CF webinar thank you",
    "start": "3161600",
    "end": "3168640"
  },
  {
    "text": "thank you all thank you taystee",
    "start": "3168640",
    "end": "3172559"
  }
]
[
  {
    "text": "I think it's time so let's get started thank you for all being here today's",
    "start": "160",
    "end": "5720"
  },
  {
    "text": "session is on distributed cash and PR a cloud on kubernetes crust we' buil a",
    "start": "5720",
    "end": "13719"
  },
  {
    "text": "distributed Cash System on kubernetes and use it for a cloud in our own",
    "start": "13719",
    "end": "20480"
  },
  {
    "text": "premise we've uploaded our slide so if you need please check",
    "start": "20480",
    "end": "25599"
  },
  {
    "text": "it he's a u from Japan he works for preer networks which is a AI ml company",
    "start": "25599",
    "end": "32480"
  },
  {
    "text": "in Japan I'll explain our company's cust in detail later I'm T which is colleagues also I'm",
    "start": "32480",
    "end": "41120"
  },
  {
    "text": "a founder of Yi sh shf SBX project and the Mainer of some OS related to",
    "start": "41120",
    "end": "49600"
  },
  {
    "text": "cncf this is today's agenda so we first introduce background Ai and the M",
    "start": "49600",
    "end": "56480"
  },
  {
    "text": "workload on kubernetes cruster second we talked about the main topic simple cast",
    "start": "56480",
    "end": "63120"
  },
  {
    "text": "services that is developed for AI workloads to solve the problem that we",
    "start": "63120",
    "end": "68920"
  },
  {
    "text": "talk about the background start we describe the Lear world use cases next in deoy",
    "start": "68920",
    "end": "76880"
  },
  {
    "text": "consideration we describe techniques to achieve higher performance in the end we",
    "start": "76880",
    "end": "83640"
  },
  {
    "text": "conclude the attack okay next which explains our background yeah thank you",
    "start": "83640",
    "end": "89640"
  },
  {
    "text": "uh first we start the talk from artificial intelligence and machine learning",
    "start": "89640",
    "end": "96119"
  },
  {
    "text": "workloads so let's consider the training or machine learning model that recognize",
    "start": "96119",
    "end": "101799"
  },
  {
    "text": "a numerical digit we have a data set of pictures with numbers and the training",
    "start": "101799",
    "end": "107960"
  },
  {
    "text": "job of deep newer networks here it is a correspond to a two commity spots so KU",
    "start": "107960",
    "end": "115079"
  },
  {
    "text": "spots will access the data set and get the data samples and F the Deep new",
    "start": "115079",
    "end": "121399"
  },
  {
    "text": "networks with the data samples so it will optimize the model then by",
    "start": "121399",
    "end": "126759"
  },
  {
    "text": "continuing the iterations the Deep new network will become to be able to recognize the",
    "start": "126759",
    "end": "134400"
  },
  {
    "text": "numbers here I'd like to look at the strategies to store the data set so we",
    "start": "134400",
    "end": "140400"
  },
  {
    "text": "are Ai and ml company with onpl cluster",
    "start": "140400",
    "end": "145560"
  },
  {
    "text": "so we need on premise solutions for that first one is a NFS so we can mount NFS",
    "start": "145560",
    "end": "154440"
  },
  {
    "text": "storet to KU spots by using a host bu volume NFS is fast if the NFS server has",
    "start": "154440",
    "end": "161920"
  },
  {
    "text": "a fast red drives fast CPUs uh yeah so if the number of client",
    "start": "161920",
    "end": "168040"
  },
  {
    "text": "is limited the performance is acceptable however the large number of",
    "start": "168040",
    "end": "173519"
  },
  {
    "text": "client access the NFS you can easily notice the performance slowdowns",
    "start": "173519",
    "end": "180640"
  },
  {
    "text": "second one is object stretch we have on premise S3 compatible object stretch",
    "start": "180680",
    "end": "187040"
  },
  {
    "text": "with open source software apure zones we are using hard drives as a back end so",
    "start": "187040",
    "end": "194319"
  },
  {
    "text": "by adding a new hard drives we can scale the performance and its",
    "start": "194319",
    "end": "199959"
  },
  {
    "text": "capacity actually the performance of hardk drives are not sufficient to",
    "start": "199959",
    "end": "205599"
  },
  {
    "text": "perform a random deed of data set so it cannot be a solutions for the data set",
    "start": "205599",
    "end": "213159"
  },
  {
    "text": "Rolling S is the no loal stres so our compute node with AI accelerators has",
    "start": "213159",
    "end": "220640"
  },
  {
    "text": "additional nbme drives so it is designed to use as FM volumes of AI and ml",
    "start": "220640",
    "end": "227799"
  },
  {
    "text": "workloads so the problem here is the workload is moves to different compute",
    "start": "227799",
    "end": "233599"
  },
  {
    "text": "note the data will be unreachable so for example we have two",
    "start": "233599",
    "end": "240439"
  },
  {
    "text": "compute nodes A and B so firstly the data set has scheduled to a compute node",
    "start": "240439",
    "end": "246959"
  },
  {
    "text": "a the workload CES the data set to the no loal",
    "start": "246959",
    "end": "252680"
  },
  {
    "text": "strates after that workload may be preempted so fortunately we have another",
    "start": "252680",
    "end": "257840"
  },
  {
    "text": "compute node B so the workload will be moved to the another",
    "start": "257840",
    "end": "263199"
  },
  {
    "text": "node we have a cach data in compute node a but we cannot access there without any",
    "start": "263199",
    "end": "270240"
  },
  {
    "text": "service in compute node a so we have to fetch the data set again it is very time",
    "start": "270240",
    "end": "277160"
  },
  {
    "text": "consuming so therefore no loal Str itself helps the training but cannot be",
    "start": "277160",
    "end": "283520"
  },
  {
    "text": "a final Str solutions for that also if the data uh if the training",
    "start": "283520",
    "end": "290400"
  },
  {
    "text": "requires a larger data set than its capacity we cannot use it as a cash",
    "start": "290400",
    "end": "297160"
  },
  {
    "text": "storage so it is not scalable",
    "start": "297160",
    "end": "301639"
  },
  {
    "text": "this is our grand design of uh storages for AI and ml workload we are going to",
    "start": "302800",
    "end": "310080"
  },
  {
    "text": "combine a object St and non local stres to construct a hierarchical St",
    "start": "310080",
    "end": "316759"
  },
  {
    "text": "systems the port will access the crowd of nbme drives first and if the data",
    "start": "316759",
    "end": "324520"
  },
  {
    "text": "exists in the cloud we can skip the access to the object stres",
    "start": "324520",
    "end": "329840"
  },
  {
    "text": "if the data does not exist in the cloud we have to access the object",
    "start": "329840",
    "end": "335720"
  },
  {
    "text": "stres the capacity of the stres is scalable by adding new hard drives to",
    "start": "335720",
    "end": "342600"
  },
  {
    "text": "object stres and the throughput is scalable by adding a new compute noes or",
    "start": "342600",
    "end": "348759"
  },
  {
    "text": "adding a new nbm drives therefore I think it is very",
    "start": "348759",
    "end": "354479"
  },
  {
    "text": "suitable solutions for AI and ml workloads",
    "start": "354479",
    "end": "360680"
  },
  {
    "text": "so in this session we'd like to introduce our hierarchical Str Solutions",
    "start": "361000",
    "end": "366199"
  },
  {
    "text": "on the top of uh Cloud native Technologies so developing stage Solutions seems difficult but utilizing",
    "start": "366199",
    "end": "374520"
  },
  {
    "text": "kuus features like discoveries and authentications and Eno features like",
    "start": "374520",
    "end": "380520"
  },
  {
    "text": "its Road baning Technologies and its flexibility uh we have developed the strategies very easily",
    "start": "380520",
    "end": "389360"
  },
  {
    "text": "next uh we'll introduce our simple cast Services SS SS is a simple and first and Shing",
    "start": "390599",
    "end": "400720"
  },
  {
    "text": "architecture since SCS has a very basic HTTP G on P interface and just DET no no",
    "start": "400720",
    "end": "408199"
  },
  {
    "text": "local FES when you f the data it's incredible simple and first also SCS is",
    "start": "408199",
    "end": "416479"
  },
  {
    "text": "designed for cloud native do SCS on kubernetes CL and use a lot of",
    "start": "416479",
    "end": "422639"
  },
  {
    "text": "kubernetes feature to reduce our own implementation also SCS adapts share",
    "start": "422639",
    "end": "429319"
  },
  {
    "text": "ning architecture is essential because this enables SCS to be",
    "start": "429319",
    "end": "434360"
  },
  {
    "text": "scalable another important thing to note is that SCS is a just cash services not",
    "start": "434360",
    "end": "440639"
  },
  {
    "text": "persistent stret in other words there is no need to keep the data forever and",
    "start": "440639",
    "end": "446680"
  },
  {
    "text": "it's acceptable to delete the cash dat this is how you can actually use SC",
    "start": "446680",
    "end": "453919"
  },
  {
    "text": "using a car command it's easiest isn't it the first C St the cash data uper the",
    "start": "453919",
    "end": "461400"
  },
  {
    "text": "J in SCS and the second one with the data in first call",
    "start": "461400",
    "end": "467479"
  },
  {
    "text": "stored okay let's take a closer look first look at HTP method first car uses",
    "start": "467479",
    "end": "475080"
  },
  {
    "text": "a put to store the data and the second one uses a get to fetch it this is a natural next is a URL the",
    "start": "475080",
    "end": "483879"
  },
  {
    "text": "first thing the first thing you notice is that is use HTTP and cuent services",
    "start": "483879",
    "end": "490879"
  },
  {
    "text": "right and if you look at the PA of URL it's specify the bucket and the object",
    "start": "490879",
    "end": "498400"
  },
  {
    "text": "in this example the bucket is project fber and the object is",
    "start": "498400",
    "end": "504400"
  },
  {
    "text": "Apple okay next is authentication part we'll discuss this later uh please keep",
    "start": "504400",
    "end": "511319"
  },
  {
    "text": "in mind uh that o header is required in",
    "start": "511319",
    "end": "516360"
  },
  {
    "text": "this part we reduce our own implementation by making good use of the",
    "start": "516360",
    "end": "521760"
  },
  {
    "text": "bound service account token this is the future of",
    "start": "521760",
    "end": "526959"
  },
  {
    "text": "kubernetes let's look at the path of these C commands this is a diagram",
    "start": "527200",
    "end": "532760"
  },
  {
    "text": "showing how users access the SCS users part do something similar to",
    "start": "532760",
    "end": "538600"
  },
  {
    "text": "the carard comma and we looked SCS has the actual data of cash as a",
    "start": "538600",
    "end": "545880"
  },
  {
    "text": "file as mentioned before the action that SGS application does is just return this",
    "start": "545880",
    "end": "553160"
  },
  {
    "text": "file the first thing you notice is that there are kubernetes services and Eno",
    "start": "553160",
    "end": "559160"
  },
  {
    "text": "between users PS and SCS before we go into more detail let's",
    "start": "559160",
    "end": "565959"
  },
  {
    "text": "take a closer look at SCS itself s SS is made of three main components",
    "start": "565959",
    "end": "573320"
  },
  {
    "text": "first is a go language application and then NM or other storage that's hold the",
    "start": "573320",
    "end": "579079"
  },
  {
    "text": "cach data and SQ write which is hold the metadata like access time stamp or",
    "start": "579079",
    "end": "586120"
  },
  {
    "text": "something like that each SS application has its own SQ right in this example there are for SQ",
    "start": "586120",
    "end": "594040"
  },
  {
    "text": "light because there for SS application of course each SCS is",
    "start": "594040",
    "end": "600399"
  },
  {
    "text": "learning as a p in our cluster they are split it out using demon",
    "start": "600399",
    "end": "607240"
  },
  {
    "text": "set back to the diagram okay one of the most significant feature is the share n",
    "start": "607240",
    "end": "613920"
  },
  {
    "text": "architecture it means that nothing like ldb is shared between each SS SP despite",
    "start": "613920",
    "end": "621640"
  },
  {
    "text": "this users can access the cach data from any network Zone in order to achieve",
    "start": "621640",
    "end": "627680"
  },
  {
    "text": "this ler seven load balancing uses a consistent Hing okay next this is a for of",
    "start": "627680",
    "end": "635200"
  },
  {
    "text": "alization in SGS it's similar to kuet outb proxy if",
    "start": "635200",
    "end": "641399"
  },
  {
    "text": "you have used it you can understand it this Smo first a user P should Mount the",
    "start": "641399",
    "end": "648480"
  },
  {
    "text": "service account token and send out a request with it the verifying part it is",
    "start": "648480",
    "end": "654880"
  },
  {
    "text": "SCS is charg of it is is a token Lev AP to verify the token the service account",
    "start": "654880",
    "end": "662800"
  },
  {
    "text": "can tell as the name space of the request Source this can be used for",
    "start": "662800",
    "end": "669120"
  },
  {
    "text": "authentication therefore users can specify the name space that can access the",
    "start": "669120",
    "end": "675079"
  },
  {
    "text": "buet well let's define your bucket you can define a bucket like this there are",
    "start": "675079",
    "end": "681680"
  },
  {
    "text": "two types of a bucket public and private the top orange part is a bucket uh",
    "start": "681680",
    "end": "688839"
  },
  {
    "text": "called the public buckets which anyone can access the blue part below is called",
    "start": "688839",
    "end": "695240"
  },
  {
    "text": "private bucket and that is authenticated based on kubernetes name space it's",
    "start": "695240",
    "end": "701680"
  },
  {
    "text": "possible to list the name spaces that allowed to access the",
    "start": "701680",
    "end": "707040"
  },
  {
    "text": "buet for instance project kubernetes and use of TAMU name spaces are allowed to",
    "start": "707040",
    "end": "713440"
  },
  {
    "text": "access the cubicon bracket it's also possible to set storage limits for each bucket in the",
    "start": "713440",
    "end": "721120"
  },
  {
    "text": "bucket quarter field if the specified capacity is exceeded the bucket Will T",
    "start": "721120",
    "end": "727800"
  },
  {
    "text": "to delete cash data on L basis this figure shows how data is",
    "start": "727800",
    "end": "734839"
  },
  {
    "text": "deleted in the UE firstly the color so each color",
    "start": "734839",
    "end": "740399"
  },
  {
    "text": "represent represents a bucket they are loaded with more and more data with",
    "start": "740399",
    "end": "746079"
  },
  {
    "text": "sifting the start time the do CLE is the maximum capacity allocated for each",
    "start": "746079",
    "end": "753760"
  },
  {
    "text": "bucket once there each bucket has no further increas in capacity this means",
    "start": "753760",
    "end": "760639"
  },
  {
    "text": "that L based data deletion had started",
    "start": "760639",
    "end": "765920"
  },
  {
    "text": "here next we talk about the lar world use",
    "start": "765920",
    "end": "771079"
  },
  {
    "text": "cases we'll introduce two use cases one use case is used SCS as a cach for slow",
    "start": "771079",
    "end": "780600"
  },
  {
    "text": "the motivation of developing SCS has started from here it accelerates data loading through",
    "start": "780600",
    "end": "787959"
  },
  {
    "text": "put of data set the Second Use case is SCS as a storage backround for yet",
    "start": "787959",
    "end": "794680"
  },
  {
    "text": "another cash service let's dive into case",
    "start": "794680",
    "end": "799880"
  },
  {
    "text": "one first let's consider the data loading from object storage like S3 or",
    "start": "799880",
    "end": "806360"
  },
  {
    "text": "or something like this in order to select the iol layers we developed the",
    "start": "806360",
    "end": "812240"
  },
  {
    "text": "PF for our research researches since it's OSS you can check",
    "start": "812240",
    "end": "818160"
  },
  {
    "text": "it out now the source code in Python is a sample code to get a JP file from object",
    "start": "818160",
    "end": "825079"
  },
  {
    "text": "stage with only 10 lines of code also PF has a transparent cach",
    "start": "825079",
    "end": "833160"
  },
  {
    "text": "feature just adding HTP cach parameter to form URL function pile automatically",
    "start": "833160",
    "end": "840720"
  },
  {
    "text": "catch the content and get it from SGS next time if the file is hit in",
    "start": "840720",
    "end": "848759"
  },
  {
    "text": "SCS the lead latency improved because we could skip getting from object stretch",
    "start": "848759",
    "end": "855600"
  },
  {
    "text": "and uh put it into SGS next let's look at case two how to",
    "start": "855600",
    "end": "862800"
  },
  {
    "text": "use SGS as a storage backend for yet another cash servic",
    "start": "862800",
    "end": "869320"
  },
  {
    "text": "there are several lar files we haven't mentioned yet first is a container image",
    "start": "869320",
    "end": "876160"
  },
  {
    "text": "container images for AI and M Rock CL are larger and larger our only Mar",
    "start": "876160",
    "end": "882560"
  },
  {
    "text": "container image that the first choice for our researchers uh is more than 30 gab we",
    "start": "882560",
    "end": "890120"
  },
  {
    "text": "have already build it and uh last week 94% of continent mes PS hit the",
    "start": "890120",
    "end": "897279"
  },
  {
    "text": "SCS the other the model you know llm is",
    "start": "897279",
    "end": "902399"
  },
  {
    "text": "large and sometimes our researchers evaluate public llm in a hugging phase",
    "start": "902399",
    "end": "908399"
  },
  {
    "text": "so we have its Capac cash uity both FES both files have",
    "start": "908399",
    "end": "915320"
  },
  {
    "text": "characteristic like being AAR large and hot normally we use the latest contenter",
    "start": "915320",
    "end": "923120"
  },
  {
    "text": "image so the outdated contenter image should be deleted this get me done by SS the L",
    "start": "923120",
    "end": "932319"
  },
  {
    "text": "policy therefore the combination of SCS and the cash service for these files",
    "start": "932319",
    "end": "938160"
  },
  {
    "text": "works very well this is an example of implementing yet on Cache of course SCS is used as a",
    "start": "938160",
    "end": "947160"
  },
  {
    "text": "storage backround yet another cach must be implemented several features like access",
    "start": "947160",
    "end": "953560"
  },
  {
    "text": "to origin service access to SGS user interface URS mapping from origin key to",
    "start": "953560",
    "end": "960560"
  },
  {
    "text": "USS however storage management like cash eviction and the capacity control which",
    "start": "960560",
    "end": "967199"
  },
  {
    "text": "is difficult to implement is already implemented in SCS so lighting yet another cash is",
    "start": "967199",
    "end": "976800"
  },
  {
    "text": "easier so in this sections we are going to talk about the deployment of simple",
    "start": "976800",
    "end": "983160"
  },
  {
    "text": "cash service here we have two questions to optimize the deployment",
    "start": "983160",
    "end": "989800"
  },
  {
    "text": "one is how can we optimize the network traffic between user ports and enoy we",
    "start": "989800",
    "end": "996639"
  },
  {
    "text": "are using kubernetes service to discover the enoy port here we consider the",
    "start": "996639",
    "end": "1003040"
  },
  {
    "text": "configurations of kubernetes service and the deployment of enroy the other is how can we configure",
    "start": "1003040",
    "end": "1011519"
  },
  {
    "text": "enroy to rot the traffic to the SCS by considering the two questions we",
    "start": "1011519",
    "end": "1018240"
  },
  {
    "text": "can optimize the end to endend data flow from user port to the SCS",
    "start": "1018240",
    "end": "1025079"
  },
  {
    "text": "ports okay so let's start from the question one so how can we optimize the",
    "start": "1025079",
    "end": "1031000"
  },
  {
    "text": "network traffic so first I'd like to describe our Computing infrastructure where the",
    "start": "1031000",
    "end": "1038438"
  },
  {
    "text": "SCS is running right now so we are pround networks uh Ai and machine",
    "start": "1038439",
    "end": "1045079"
  },
  {
    "text": "Learning Company so we are developing machine learning learning models like",
    "start": "1045079",
    "end": "1050280"
  },
  {
    "text": "large language models and many solutions to the industries so these activities",
    "start": "1050280",
    "end": "1055919"
  },
  {
    "text": "uses our on premise Computing infrastructures so we have three kues",
    "start": "1055919",
    "end": "1062320"
  },
  {
    "text": "clusters for Productions and several evaluations and staging clusters as a total there are more than",
    "start": "1062320",
    "end": "1070480"
  },
  {
    "text": "400 kubernetes notes with are 30,000 CPU course uh 300 tab memory and also a",
    "start": "1070480",
    "end": "1077960"
  },
  {
    "text": "2,000 gpus for machine learning models training so also we are developing and",
    "start": "1077960",
    "end": "1084840"
  },
  {
    "text": "operating our own a accelerator chip called MN core so we are doing almost",
    "start": "1084840",
    "end": "1091520"
  },
  {
    "text": "everything of AI accelerators from rtls uh both designs server designs uh",
    "start": "1091520",
    "end": "1098440"
  },
  {
    "text": "drivers and also device plugins for kuties and also a graph",
    "start": "1098440",
    "end": "1104440"
  },
  {
    "text": "compilers so I'd like to introduce the data center Network",
    "start": "1104440",
    "end": "1109480"
  },
  {
    "text": "also so our company freefile networks uses a cross Network",
    "start": "1109480",
    "end": "1115600"
  },
  {
    "text": "topology cross Network topology uses multi stage switches uh deep switches",
    "start": "1115600",
    "end": "1121880"
  },
  {
    "text": "spine switches and external super spine switches this switch is the most nearest",
    "start": "1121880",
    "end": "1128400"
  },
  {
    "text": "switch from the compute node so here we can define a four Network zones for each",
    "start": "1128400",
    "end": "1135159"
  },
  {
    "text": "the swiches uh Network Zone A B G and D's so because uh there are three nodes",
    "start": "1135159",
    "end": "1144880"
  },
  {
    "text": "in the same d s can communicate with a nonblocking",
    "start": "1144880",
    "end": "1150440"
  },
  {
    "text": "performance however the communication between different zones like Zone a and",
    "start": "1150440",
    "end": "1156720"
  },
  {
    "text": "Zone D requires diff and spine switches Communications so Network dink between",
    "start": "1156720",
    "end": "1163760"
  },
  {
    "text": "de stitches and spine stitches is over subscribed in other was the up link is",
    "start": "1163760",
    "end": "1171280"
  },
  {
    "text": "narrower than down links so if the old note in your uh Network Zone try",
    "start": "1171280",
    "end": "1178960"
  },
  {
    "text": "communicating to a different zones congestion happens therefore we have to avoid the",
    "start": "1178960",
    "end": "1186880"
  },
  {
    "text": "interzone communications as much as possible to save up",
    "start": "1186880",
    "end": "1192440"
  },
  {
    "text": "links okay so I have described the background so let's consider the network",
    "start": "1192440",
    "end": "1198720"
  },
  {
    "text": "graphic from user port to enoy port first as assumptions SCS is deploy",
    "start": "1198720",
    "end": "1207360"
  },
  {
    "text": "to the all comput no to use all local nbm drives",
    "start": "1207360",
    "end": "1213840"
  },
  {
    "text": "effectively also user Port may be scheduled to any no because all compute",
    "start": "1213840",
    "end": "1220880"
  },
  {
    "text": "no has a expensive accelerators so there is no meaning of keeping the computer",
    "start": "1220880",
    "end": "1227559"
  },
  {
    "text": "resource idle so where to deploy enoys here we decided to deploy enoy to",
    "start": "1227559",
    "end": "1236640"
  },
  {
    "text": "all compute nodes by doing so we can deduce the network traffic between a",
    "start": "1236640",
    "end": "1242720"
  },
  {
    "text": "user port and enoy Port however we cannot optimize the inter Zone traffic",
    "start": "1242720",
    "end": "1249679"
  },
  {
    "text": "uh between enoy and SCS because SCS has deployed to all",
    "start": "1249679",
    "end": "1255480"
  },
  {
    "text": "computer noes so we cannot optimize about the interone",
    "start": "1255480",
    "end": "1261960"
  },
  {
    "text": "traffic so next I'd like to consider the configurations of kubernetes service to",
    "start": "1262520",
    "end": "1268960"
  },
  {
    "text": "reduce inter Zone traffic in other words uh performer Communications in a topoi a",
    "start": "1268960",
    "end": "1277000"
  },
  {
    "text": "waye we have a user port and enoy port in all computer nodes so there are two",
    "start": "1277000",
    "end": "1284039"
  },
  {
    "text": "method to deduce the interone traffic one is a intern traic policy and the",
    "start": "1284039",
    "end": "1290279"
  },
  {
    "text": "other is a topology a rooting so let's start talk from",
    "start": "1290279",
    "end": "1296840"
  },
  {
    "text": "internal traffic policies internal traffic policy limits the communication to the service",
    "start": "1296840",
    "end": "1303320"
  },
  {
    "text": "internally so if the service have the service have many enoy ports as back end",
    "start": "1303320",
    "end": "1311279"
  },
  {
    "text": "but the internal traffic policy only Lo the traffic to the port within the same",
    "start": "1311279",
    "end": "1317559"
  },
  {
    "text": "node so so we don't have communications between computer",
    "start": "1317559",
    "end": "1323159"
  },
  {
    "text": "nodes topology routin def from internal traffic polies to routing Lo the traffic to the",
    "start": "1323159",
    "end": "1331880"
  },
  {
    "text": "same zone so in this case we have a three enoy port to lot the traffic",
    "start": "1331880",
    "end": "1338080"
  },
  {
    "text": "now it requires communication in the same Zone but not in the different",
    "start": "1338080",
    "end": "1344200"
  },
  {
    "text": "zones therefore it seems internal traffic policy is better than topos",
    "start": "1344200",
    "end": "1350320"
  },
  {
    "text": "rooting from the perspective of uh",
    "start": "1350320",
    "end": "1355080"
  },
  {
    "text": "networking however the Viewpoint of Eno CPU road bance we have a different",
    "start": "1355360",
    "end": "1363320"
  },
  {
    "text": "conclusions internal traffic policy doesn't root the traffic to the other",
    "start": "1363320",
    "end": "1368559"
  },
  {
    "text": "two ports so therefore if some not uses SCS heavily uh we can see the high CPU",
    "start": "1368559",
    "end": "1376520"
  },
  {
    "text": "usage of uh enoy in the node since we dis deployed enoy as a",
    "start": "1376520",
    "end": "1384320"
  },
  {
    "text": "demo set so we cannot increase a CPU resource request with A fine grain",
    "start": "1384320",
    "end": "1391600"
  },
  {
    "text": "manner however topology hour routin utilize three Eno back end so the CPU L",
    "start": "1392159",
    "end": "1399559"
  },
  {
    "text": "balance is deluxed therefore we can see more consistent latency numbers in ouro a",
    "start": "1399559",
    "end": "1407360"
  },
  {
    "text": "rooting therefore we are using Topo routing to",
    "start": "1407360",
    "end": "1412440"
  },
  {
    "text": "improve the CPU Road urance of enoy that is a good balance of network traffic and",
    "start": "1412440",
    "end": "1418520"
  },
  {
    "text": "road balancing so next question is how can we",
    "start": "1418520",
    "end": "1426080"
  },
  {
    "text": "configure the enoy to Lo the traffic so we'll consider the rest part of data",
    "start": "1426080",
    "end": "1433360"
  },
  {
    "text": "flow so here let's consider the load braning of keys so in SCS the key",
    "start": "1433400",
    "end": "1441200"
  },
  {
    "text": "correspond to a bucket and object so in this design we want to rot the traffic",
    "start": "1441200",
    "end": "1448159"
  },
  {
    "text": "from Eno to SCS consistently so consistent means when we",
    "start": "1448159",
    "end": "1454279"
  },
  {
    "text": "put the object to a first SCS we want to get it from the same",
    "start": "1454279",
    "end": "1459919"
  },
  {
    "text": "SCS otherwise we cannot get the object we have put it",
    "start": "1459919",
    "end": "1466320"
  },
  {
    "text": "before the easiest way to achieve that is a introduce a mapping from backet and",
    "start": "1467360",
    "end": "1474360"
  },
  {
    "text": "object to SCS backend ID it introduces a share DB so sometimes",
    "start": "1474360",
    "end": "1481120"
  },
  {
    "text": "share DB performance slows down so here consider sharing yeah yeah blah blah",
    "start": "1481120",
    "end": "1487200"
  },
  {
    "text": "yeah this can be a Solutions but we want to use more simple and more scalable",
    "start": "1487200",
    "end": "1494960"
  },
  {
    "text": "way so here we don't share the database but the shares the functions to",
    "start": "1494960",
    "end": "1501360"
  },
  {
    "text": "determine which is responsible for we introduces the hash functions",
    "start": "1501360",
    "end": "1507840"
  },
  {
    "text": "from bucket and object to some numbers then we decide the Les responsible back",
    "start": "1507840",
    "end": "1514760"
  },
  {
    "text": "end from the number the simplest calculation to",
    "start": "1514760",
    "end": "1520240"
  },
  {
    "text": "determine the responsible back end is just divide the hash value by the number",
    "start": "1520240",
    "end": "1526039"
  },
  {
    "text": "of back ends then use the ER the problem of that is that when the",
    "start": "1526039",
    "end": "1533240"
  },
  {
    "text": "number of backend changes almost every key Dem Maps so typically it happens",
    "start": "1533240",
    "end": "1539840"
  },
  {
    "text": "during node failure and node installations so we should avoid",
    "start": "1539840",
    "end": "1545279"
  },
  {
    "text": "this consistent hushing is a method which solves this problem it designed to",
    "start": "1545279",
    "end": "1551720"
  },
  {
    "text": "uh deduce such a depping so we can expect more lower de mapping uh so the",
    "start": "1551720",
    "end": "1557919"
  },
  {
    "text": "key count divided by the back end count is the IDE",
    "start": "1557919",
    "end": "1563840"
  },
  {
    "text": "numbers emboy has two consistent hashing implementations one is ding hash first",
    "start": "1563840",
    "end": "1571799"
  },
  {
    "text": "It prepares a ding with a responsible back end by hashing the back end",
    "start": "1571799",
    "end": "1578080"
  },
  {
    "text": "information when access happens it calculates the hash of keys then search",
    "start": "1578080",
    "end": "1584440"
  },
  {
    "text": "responsible backend from the ding the other is MRE which manages a",
    "start": "1584440",
    "end": "1591279"
  },
  {
    "text": "set of responsible hashes both mappings are computed from",
    "start": "1591279",
    "end": "1596559"
  },
  {
    "text": "the backend information so all enoy part share this",
    "start": "1596559",
    "end": "1601600"
  },
  {
    "text": "mapping therefore we can see the consistent mapping in all enoy",
    "start": "1601600",
    "end": "1608559"
  },
  {
    "text": "ports load balancing of keys is very important the back end with a larger key",
    "start": "1609559",
    "end": "1617039"
  },
  {
    "text": "responsibility how have several problems so in this figure you can see",
    "start": "1617039",
    "end": "1622679"
  },
  {
    "text": "the length of AR or back and three is 1.5 times longer than back end",
    "start": "1622679",
    "end": "1630120"
  },
  {
    "text": "four therefore backend 3 is 1.5 times of",
    "start": "1630120",
    "end": "1635320"
  },
  {
    "text": "responsibility of a bu and for so it should be avoided because it",
    "start": "1635320",
    "end": "1641679"
  },
  {
    "text": "affects the performance so CPU usage of backend 3 is 1.5 times of back and forth",
    "start": "1641679",
    "end": "1649600"
  },
  {
    "text": "so it may deserve the longer lates in numbers also the lifetime of each data",
    "start": "1649600",
    "end": "1657080"
  },
  {
    "text": "in back and three is shorter than back and force so more possibility of delions",
    "start": "1657080",
    "end": "1662880"
  },
  {
    "text": "in back and three nod here we want to see the consistent",
    "start": "1662880",
    "end": "1668559"
  },
  {
    "text": "resource usage and its lifetime uh we need a consistent Hing with a consistent",
    "start": "1668559",
    "end": "1674720"
  },
  {
    "text": "size of key mappings so let's check the load imbalance of",
    "start": "1674720",
    "end": "1680880"
  },
  {
    "text": "both consistent hashing algorithms in this figure a ding hash has a load",
    "start": "1680880",
    "end": "1686240"
  },
  {
    "text": "imbalance up to 1.5 times however MB doesn't introduce any load",
    "start": "1686240",
    "end": "1694000"
  },
  {
    "text": "imbalance so let's see the screenshot of object count per node the screenshot is",
    "start": "1694799",
    "end": "1701559"
  },
  {
    "text": "taken from our production environment each line correspond to a",
    "start": "1701559",
    "end": "1707760"
  },
  {
    "text": "number of object per node so as you can see when using ding has you can see the",
    "start": "1707760",
    "end": "1714960"
  },
  {
    "text": "multiple lines with some whe however when using a MAG you can see only the",
    "start": "1714960",
    "end": "1720679"
  },
  {
    "text": "single lines but actually there are multiple lines so it means uh load balance on mag",
    "start": "1720679",
    "end": "1728519"
  },
  {
    "text": "algorithm is perfect that is why we are using",
    "start": "1728519",
    "end": "1734600"
  },
  {
    "text": "magb okay so we have deoy the SC to the production environment so let's check",
    "start": "1734919",
    "end": "1741080"
  },
  {
    "text": "the performance numbers this is our API course per",
    "start": "1741080",
    "end": "1746120"
  },
  {
    "text": "second in the last 30 days as you can see uh the highest is",
    "start": "1746120",
    "end": "1752360"
  },
  {
    "text": "37,000 of De per second also uh this is aggregate",
    "start": "1752360",
    "end": "1759159"
  },
  {
    "text": "throughput per second in the last 30 days as you can see the highest is a 75",
    "start": "1759159",
    "end": "1766159"
  },
  {
    "text": "GB per second as aggregated through uh",
    "start": "1766159",
    "end": "1772679"
  },
  {
    "text": "traffic so as a summary we achieved 37,000 request per second with 75 gab",
    "start": "1772679",
    "end": "1781080"
  },
  {
    "text": "per second with only 55 backend servers I think it is not so much number",
    "start": "1781080",
    "end": "1788080"
  },
  {
    "text": "of backend servers also this number is comes from the de world not the",
    "start": "1788080",
    "end": "1794200"
  },
  {
    "text": "synthetic Benchmark So currently we are having",
    "start": "1794200",
    "end": "1799240"
  },
  {
    "text": "268 million object almost deest to SCS",
    "start": "1799240",
    "end": "1804399"
  },
  {
    "text": "is a de heavy and uh we are continuously watching the not found rate to expand",
    "start": "1804399",
    "end": "1811279"
  },
  {
    "text": "the cash capacity in a timely manner so let's conclude the talk so we",
    "start": "1811279",
    "end": "1818679"
  },
  {
    "text": "have introduced our cash Service uh simple cash Services it is designed to",
    "start": "1818679",
    "end": "1824240"
  },
  {
    "text": "with a share nursing architecture to see the linear scating this is easily implemented by invo consistent Hing",
    "start": "1824240",
    "end": "1832080"
  },
  {
    "text": "algorithms also we are following uh Cloud native best practice like a bound",
    "start": "1832080",
    "end": "1837840"
  },
  {
    "text": "service account token from kubernetes to implement authentication easily so our",
    "start": "1837840",
    "end": "1843399"
  },
  {
    "text": "system can be used as a transparent cash of object stretch with pfio our iio",
    "start": "1843399",
    "end": "1849640"
  },
  {
    "text": "obstruction libraries we are using SCS in real world like data set loading and large model",
    "start": "1849640",
    "end": "1856200"
  },
  {
    "text": "servings so we use several optimization techniques like Topo routing and mrebs",
    "start": "1856200",
    "end": "1862440"
  },
  {
    "text": "so our project is supported by Cloud native Technologies and our three internship members so that's all so",
    "start": "1862440",
    "end": "1870080"
  },
  {
    "text": "thank you for paying [Applause]",
    "start": "1870080",
    "end": "1877360"
  },
  {
    "text": "attentions if you have any feedback please uh scan please scan it and uh",
    "start": "1877360",
    "end": "1883039"
  },
  {
    "text": "anyone can any questions out of curiosity is is there a",
    "start": "1883039",
    "end": "1888159"
  },
  {
    "text": "reason why you didn't go with a cluster file system we've been doing X scale storage for a long time and it's not",
    "start": "1888159",
    "end": "1894960"
  },
  {
    "text": "it's much more scalable than uh NFS is I've got 80 pedabytes of",
    "start": "1894960",
    "end": "1900440"
  },
  {
    "text": "storage back at my cluster today and I have over a th000 notes which you know",
    "start": "1900440",
    "end": "1906559"
  },
  {
    "text": "120,000 cores so I'm curious what why you ruled that out thank you sorry sorry",
    "start": "1906559",
    "end": "1913480"
  },
  {
    "text": "come again I'm curious why you didn't use a cluster file system not NFS something",
    "start": "1913480",
    "end": "1921279"
  },
  {
    "text": "like gpfs or luster or WCA or whatnot there's probably a reason I'm curious",
    "start": "1921279",
    "end": "1928720"
  },
  {
    "text": "why you have not you decide not to I think just using AUST some as dpfs like",
    "start": "1928720",
    "end": "1935279"
  },
  {
    "text": "a shared file system can be a Solutions but uh it's a I think actually I have",
    "start": "1935279",
    "end": "1940880"
  },
  {
    "text": "not tried such as shared file systems but it have some difficulties to operate",
    "start": "1940880",
    "end": "1946760"
  },
  {
    "text": "such a large St class but by applying Crown native Technologies to have a our own kuet",
    "start": "1946760",
    "end": "1954320"
  },
  {
    "text": "cluster uh we can uh get our strategies more easier I we we I we think that is",
    "start": "1954320",
    "end": "1961320"
  },
  {
    "text": "more easier uh to use such this",
    "start": "1961320",
    "end": "1965919"
  },
  {
    "text": "solutions thank you other",
    "start": "1969480",
    "end": "1973158"
  },
  {
    "text": "questions okay okay that's all thank you for all being here",
    "start": "1976559",
    "end": "1982919"
  }
]
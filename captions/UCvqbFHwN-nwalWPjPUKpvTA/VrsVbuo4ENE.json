[
  {
    "start": "0",
    "end": "10000"
  },
  {
    "text": "hello everybody my name is Daniel M",
    "start": "199",
    "end": "3720"
  },
  {
    "text": "Berman hi my name is Barney seetharama",
    "start": "3720",
    "end": "7109"
  },
  {
    "text": "and this is airflow on kubernetes to",
    "start": "7109",
    "end": "11340"
  },
  {
    "start": "10000",
    "end": "40000"
  },
  {
    "text": "start out just a little bit of",
    "start": "11340",
    "end": "12450"
  },
  {
    "text": "background of it on ourselves",
    "start": "12450",
    "end": "15210"
  },
  {
    "text": "I am a data science infrastructure",
    "start": "15210",
    "end": "17520"
  },
  {
    "text": "engineer at Bloomberg LP we're actually",
    "start": "17520",
    "end": "20699"
  },
  {
    "text": "having a talk tomorrow on one of our",
    "start": "20699",
    "end": "22439"
  },
  {
    "text": "major projects the data science platform",
    "start": "22439",
    "end": "24890"
  },
  {
    "text": "called machine learning the kubernetes",
    "start": "24890",
    "end": "26970"
  },
  {
    "text": "wait that's actually being given by",
    "start": "26970",
    "end": "28230"
  },
  {
    "text": "Keith lemon and onion museum hey I work",
    "start": "28230",
    "end": "32160"
  },
  {
    "text": "as part of the kubernetes team and",
    "start": "32160",
    "end": "34020"
  },
  {
    "text": "Google Cloud we specifically handle the",
    "start": "34020",
    "end": "36450"
  },
  {
    "text": "workload API with out of the way",
    "start": "36450",
    "end": "40520"
  },
  {
    "text": "pipelines are hard let's take a classic",
    "start": "40520",
    "end": "44789"
  },
  {
    "text": "example that you're a data engineer and",
    "start": "44789",
    "end": "47700"
  },
  {
    "text": "your job is to take raw data and turn it",
    "start": "47700",
    "end": "50820"
  },
  {
    "text": "into actionable data so like any good",
    "start": "50820",
    "end": "53160"
  },
  {
    "text": "data engineer you build a spark job and",
    "start": "53160",
    "end": "56750"
  },
  {
    "text": "that sparked up to well you set it to",
    "start": "56750",
    "end": "59489"
  },
  {
    "text": "run once a day and then your data",
    "start": "59489",
    "end": "61410"
  },
  {
    "text": "scientist come to you and say hey we've",
    "start": "61410",
    "end": "64710"
  },
  {
    "text": "actually figured out a really cool way",
    "start": "64710",
    "end": "66000"
  },
  {
    "text": "of taking the results of your spark job",
    "start": "66000",
    "end": "68210"
  },
  {
    "text": "adding it a tensorflow component and",
    "start": "68210",
    "end": "70500"
  },
  {
    "text": "building a really cool NLP model we",
    "start": "70500",
    "end": "74130"
  },
  {
    "text": "would love to add that to this pipeline",
    "start": "74130",
    "end": "75810"
  },
  {
    "text": "you've created to run once a day and you",
    "start": "75810",
    "end": "77670"
  },
  {
    "text": "say of course why wouldn't you want to",
    "start": "77670",
    "end": "79110"
  },
  {
    "text": "help that and then another data science",
    "start": "79110",
    "end": "81900"
  },
  {
    "text": "team says we've also figured out a way",
    "start": "81900",
    "end": "83640"
  },
  {
    "text": "to take Twitter firehose data and use",
    "start": "83640",
    "end": "89369"
  },
  {
    "text": "some scikit-learn model to build a",
    "start": "89369",
    "end": "91290"
  },
  {
    "text": "different NLP model that's especially",
    "start": "91290",
    "end": "93420"
  },
  {
    "text": "good for their customers and why",
    "start": "93420",
    "end": "96390"
  },
  {
    "text": "wouldn't you want to help you're a good",
    "start": "96390",
    "end": "98070"
  },
  {
    "text": "data engineer and everything's going",
    "start": "98070",
    "end": "100229"
  },
  {
    "text": "great everyone's happy until one day all",
    "start": "100229",
    "end": "102930"
  },
  {
    "text": "of your data scientists are calling you",
    "start": "102930",
    "end": "104520"
  },
  {
    "text": "freaking out because they haven't gotten",
    "start": "104520",
    "end": "106140"
  },
  {
    "text": "new data in three days and they've been",
    "start": "106140",
    "end": "108210"
  },
  {
    "text": "getting stale models to their customers",
    "start": "108210",
    "end": "110250"
  },
  {
    "text": "without any warning and yes you can set",
    "start": "110250",
    "end": "113340"
  },
  {
    "text": "up alerting for your spark job but the",
    "start": "113340",
    "end": "116310"
  },
  {
    "text": "problem is is that as a modern tech",
    "start": "116310",
    "end": "118860"
  },
  {
    "text": "company you're not running a single",
    "start": "118860",
    "end": "121140"
  },
  {
    "text": "pipeline you're running anything from",
    "start": "121140",
    "end": "123119"
  },
  {
    "text": "hundreds to thousands of pipelines at a",
    "start": "123119",
    "end": "125549"
  },
  {
    "text": "time and managing all those pipelines",
    "start": "125549",
    "end": "128489"
  },
  {
    "text": "making sure that any failures are",
    "start": "128489",
    "end": "130950"
  },
  {
    "text": "alerted back to you can be a nightmare",
    "start": "130950",
    "end": "133830"
  },
  {
    "text": "enter Apache airflow Apache airflow was",
    "start": "133830",
    "end": "137800"
  },
  {
    "text": "developed in 2015 as a workflow",
    "start": "137800",
    "end": "139780"
  },
  {
    "text": "scheduler at Airbnb and it's a",
    "start": "139780",
    "end": "142120"
  },
  {
    "text": "continuation of the concept of",
    "start": "142120",
    "end": "143709"
  },
  {
    "text": "configuration as Coda's configuration",
    "start": "143709",
    "end": "146380"
  },
  {
    "text": "and allowed by offering a Python SDK",
    "start": "146380",
    "end": "149230"
  },
  {
    "text": "that users can use to create directed",
    "start": "149230",
    "end": "153250"
  },
  {
    "text": "acyclic graphs it has a really active",
    "start": "153250",
    "end": "155500"
  },
  {
    "text": "open-source community and a large number",
    "start": "155500",
    "end": "158020"
  },
  {
    "text": "of operators and hooks for things such",
    "start": "158020",
    "end": "159880"
  },
  {
    "text": "as h TF s spark bash a lot of GCP",
    "start": "159880",
    "end": "163450"
  },
  {
    "text": "functions and AWS functions and as a",
    "start": "163450",
    "end": "167890"
  },
  {
    "text": "DevOps engineer when you actually look",
    "start": "167890",
    "end": "170470"
  },
  {
    "text": "into the airflow dashboard you're able",
    "start": "170470",
    "end": "172959"
  },
  {
    "text": "to see all of your pipelines at once and",
    "start": "172959",
    "end": "175150"
  },
  {
    "text": "you're able to see which one's failed",
    "start": "175150",
    "end": "177489"
  },
  {
    "text": "and you can dive in see historical data",
    "start": "177489",
    "end": "179739"
  },
  {
    "text": "and check out the failure and see it",
    "start": "179739",
    "end": "182019"
  },
  {
    "text": "running in real time see each of the",
    "start": "182019",
    "end": "183820"
  },
  {
    "text": "tasks and go in and say this task failed",
    "start": "183820",
    "end": "187030"
  },
  {
    "text": "give me the logs and show me why this",
    "start": "187030",
    "end": "189010"
  },
  {
    "text": "failed and how I can remedy this problem",
    "start": "189010",
    "end": "192000"
  },
  {
    "text": "this is what the airflow Python SDK",
    "start": "192000",
    "end": "194830"
  },
  {
    "text": "actually looks like it has this concept",
    "start": "194830",
    "end": "197200"
  },
  {
    "text": "of operators where each operator is a",
    "start": "197200",
    "end": "199660"
  },
  {
    "text": "step so this one step you would use to",
    "start": "199660",
    "end": "202120"
  },
  {
    "text": "describe a spark submit command a bash",
    "start": "202120",
    "end": "204459"
  },
  {
    "text": "command or in a cloud function and once",
    "start": "204459",
    "end": "209260"
  },
  {
    "text": "you've defined all of your operators you",
    "start": "209260",
    "end": "211269"
  },
  {
    "text": "can use this function called set",
    "start": "211269",
    "end": "213190"
  },
  {
    "text": "upstream to set the dependencies and",
    "start": "213190",
    "end": "215680"
  },
  {
    "text": "once you've set the dependencies air",
    "start": "215680",
    "end": "217540"
  },
  {
    "text": "flow is actually able to dynamically",
    "start": "217540",
    "end": "218950"
  },
  {
    "text": "generate a dag based on what you wrote",
    "start": "218950",
    "end": "223450"
  },
  {
    "text": "in Python code and it sets it such that",
    "start": "223450",
    "end": "225850"
  },
  {
    "text": "no no step runs until all of its",
    "start": "225850",
    "end": "229209"
  },
  {
    "text": "dependencies have been met thanks to you",
    "start": "229209",
    "end": "235320"
  },
  {
    "start": "231000",
    "end": "312000"
  },
  {
    "text": "so I feel it's a very complex system to",
    "start": "235320",
    "end": "238420"
  },
  {
    "text": "deploy and manage so I flows to develop",
    "start": "238420",
    "end": "241660"
  },
  {
    "text": "during the vmas pre container age I",
    "start": "241660",
    "end": "243730"
  },
  {
    "text": "would say it has multiple components",
    "start": "243730",
    "end": "245440"
  },
  {
    "text": "like the UI scheduler worker nodes",
    "start": "245440",
    "end": "248709"
  },
  {
    "text": "broker sequel storage and file storage",
    "start": "248709",
    "end": "253450"
  },
  {
    "text": "and it can be deployed in many",
    "start": "253450",
    "end": "256479"
  },
  {
    "text": "configurations you can choose your",
    "start": "256479",
    "end": "258070"
  },
  {
    "text": "executor you can change your DAC source",
    "start": "258070",
    "end": "259930"
  },
  {
    "text": "and also you can change your broker",
    "start": "259930",
    "end": "261729"
  },
  {
    "text": "etcetera so all of these combined",
    "start": "261729",
    "end": "264250"
  },
  {
    "text": "together makes our flow complex to",
    "start": "264250",
    "end": "266740"
  },
  {
    "text": "deploy and manage and also introduces",
    "start": "266740",
    "end": "268479"
  },
  {
    "text": "multiple failure points thank you so one",
    "start": "268479",
    "end": "278349"
  },
  {
    "text": "of the common executives that our flow",
    "start": "278349",
    "end": "280630"
  },
  {
    "text": "users use is the celery executor it",
    "start": "280630",
    "end": "283840"
  },
  {
    "text": "deploys a static number of worker nodes",
    "start": "283840",
    "end": "285780"
  },
  {
    "text": "the problem with that is if you end up",
    "start": "285780",
    "end": "289539"
  },
  {
    "text": "deploying the less number of worker",
    "start": "289539",
    "end": "291009"
  },
  {
    "text": "nodes under provisioning the gear system",
    "start": "291009",
    "end": "293560"
  },
  {
    "text": "you end up you know most of your DAGs",
    "start": "293560",
    "end": "297430"
  },
  {
    "text": "end up in the queue and you end up",
    "start": "297430",
    "end": "299800"
  },
  {
    "text": "missing your s la's and the other thing",
    "start": "299800",
    "end": "303639"
  },
  {
    "text": "is you could end up over positioning",
    "start": "303639",
    "end": "305289"
  },
  {
    "text": "your worker nodes thereby wasting",
    "start": "305289",
    "end": "307449"
  },
  {
    "text": "resources and if you are fiscally and",
    "start": "307449",
    "end": "309610"
  },
  {
    "text": "inclined your money we looked at this",
    "start": "309610",
    "end": "315310"
  },
  {
    "text": "and we looked at communities and so this",
    "start": "315310",
    "end": "317860"
  },
  {
    "text": "is a great way cuban artists can solve",
    "start": "317860",
    "end": "320169"
  },
  {
    "text": "all of these issues by container rising",
    "start": "320169",
    "end": "322930"
  },
  {
    "text": "your air flow components and running it",
    "start": "322930",
    "end": "324759"
  },
  {
    "text": "on communities you can reduce deployment",
    "start": "324759",
    "end": "328240"
  },
  {
    "text": "and management complexity not just that",
    "start": "328240",
    "end": "330820"
  },
  {
    "text": "you can also take advantage of the",
    "start": "330820",
    "end": "333370"
  },
  {
    "text": "dynamic resource API that given artists",
    "start": "333370",
    "end": "335620"
  },
  {
    "text": "provides to have better resource",
    "start": "335620",
    "end": "339639"
  },
  {
    "text": "utilization and also communities",
    "start": "339639",
    "end": "342430"
  },
  {
    "text": "recovers from enables you to do fault",
    "start": "342430",
    "end": "345190"
  },
  {
    "text": "remediation and automate that process so",
    "start": "345190",
    "end": "347560"
  },
  {
    "text": "that if any of your components file it",
    "start": "347560",
    "end": "349210"
  },
  {
    "text": "has recovered automatically for you by",
    "start": "349210",
    "end": "351940"
  },
  {
    "text": "sharing your cluster cabinet is cluster",
    "start": "351940",
    "end": "354159"
  },
  {
    "text": "with other workloads you can improve",
    "start": "354159",
    "end": "356710"
  },
  {
    "text": "your resource utilization so we attacked",
    "start": "356710",
    "end": "362259"
  },
  {
    "text": "a lot of these problems with three",
    "start": "362259",
    "end": "363969"
  },
  {
    "text": "different components which we'll be",
    "start": "363969",
    "end": "365380"
  },
  {
    "text": "going over the kubernetes pod operator",
    "start": "365380",
    "end": "367900"
  },
  {
    "text": "the kubernetes executor and the airflow",
    "start": "367900",
    "end": "370449"
  },
  {
    "text": "operator which is currently a piece of",
    "start": "370449",
    "end": "372310"
  },
  {
    "text": "GCP but in the process of being open",
    "start": "372310",
    "end": "374650"
  },
  {
    "text": "source and offered up to bare metal",
    "start": "374650",
    "end": "376240"
  },
  {
    "text": "koomer days clusters for the kubernetes",
    "start": "376240",
    "end": "380349"
  },
  {
    "text": "pot operator we wanted to create a",
    "start": "380349",
    "end": "384130"
  },
  {
    "text": "better airflow docker story so there",
    "start": "384130",
    "end": "386469"
  },
  {
    "text": "currently is a docker operator and air",
    "start": "386469",
    "end": "388539"
  },
  {
    "text": "flow but it assumes that you have a",
    "start": "388539",
    "end": "390190"
  },
  {
    "text": "running docker container that it can",
    "start": "390190",
    "end": "392110"
  },
  {
    "text": "exact commands into we wanted the",
    "start": "392110",
    "end": "394539"
  },
  {
    "text": "ability to give give air flow an",
    "start": "394539",
    "end": "397089"
  },
  {
    "text": "arbitrary docker container and",
    "start": "397089",
    "end": "398680"
  },
  {
    "text": "run this container monitor it and only",
    "start": "398680",
    "end": "401710"
  },
  {
    "text": "alert us about whether that container",
    "start": "401710",
    "end": "403210"
  },
  {
    "text": "passed or failed at the command it's",
    "start": "403210",
    "end": "404979"
  },
  {
    "text": "attempting to do so the kubernetes pot",
    "start": "404979",
    "end": "408340"
  },
  {
    "text": "operator does exactly that with the cube",
    "start": "408340",
    "end": "410229"
  },
  {
    "text": "API this has a huge benefit that now you",
    "start": "410229",
    "end": "413740"
  },
  {
    "text": "can actually offload a lot of the",
    "start": "413740",
    "end": "415570"
  },
  {
    "text": "dependencies from the airflow workers so",
    "start": "415570",
    "end": "419110"
  },
  {
    "text": "you no longer have to have a lot of",
    "start": "419110",
    "end": "420370"
  },
  {
    "text": "these libraries in the worker you can",
    "start": "420370",
    "end": "422199"
  },
  {
    "text": "just deploy a docker container that has",
    "start": "422199",
    "end": "424120"
  },
  {
    "text": "those libraries to run that task it also",
    "start": "424120",
    "end": "426970"
  },
  {
    "text": "has a huge benefit where you can now do",
    "start": "426970",
    "end": "429009"
  },
  {
    "text": "very easy roll backs and deployments",
    "start": "429009",
    "end": "430990"
  },
  {
    "text": "because you can tag the images in your",
    "start": "430990",
    "end": "433030"
  },
  {
    "text": "decks so now not only are the DAGs item",
    "start": "433030",
    "end": "435760"
  },
  {
    "text": "potent but the actual tasks that they're",
    "start": "435760",
    "end": "437830"
  },
  {
    "text": "running your item potent because it's",
    "start": "437830",
    "end": "439060"
  },
  {
    "text": "running within a docker container for",
    "start": "439060",
    "end": "442180"
  },
  {
    "text": "the issue of static versus dynamic",
    "start": "442180",
    "end": "444039"
  },
  {
    "text": "allocation we created what's called the",
    "start": "444039",
    "end": "446530"
  },
  {
    "text": "kubernetes executor this is a whole new",
    "start": "446530",
    "end": "448630"
  },
  {
    "text": "scheduler for airflow optimized for",
    "start": "448630",
    "end": "451180"
  },
  {
    "text": "kubernetes and it's especially optimized",
    "start": "451180",
    "end": "453729"
  },
  {
    "text": "to have high level of parallelism",
    "start": "453729",
    "end": "455169"
  },
  {
    "text": "through dynamic allocation with the side",
    "start": "455169",
    "end": "457690"
  },
  {
    "text": "effects of a better fault tolerant story",
    "start": "457690",
    "end": "459580"
  },
  {
    "text": "and task level pod configuration so the",
    "start": "459580",
    "end": "463330"
  },
  {
    "text": "way that the dynamic allocation and the",
    "start": "463330",
    "end": "465130"
  },
  {
    "text": "in the kubernetes executors works is",
    "start": "465130",
    "end": "467139"
  },
  {
    "text": "that you only have to actually release a",
    "start": "467139",
    "end": "469389"
  },
  {
    "text": "single pod containing the UI in the",
    "start": "469389",
    "end": "471250"
  },
  {
    "text": "scheduler and when you actually set one",
    "start": "471250",
    "end": "473380"
  },
  {
    "text": "of your DAGs to run that scheduler",
    "start": "473380",
    "end": "475150"
  },
  {
    "text": "speaks to the Kubb api and is able to",
    "start": "475150",
    "end": "477310"
  },
  {
    "text": "dynamically create create airflow pods",
    "start": "477310",
    "end": "479740"
  },
  {
    "text": "each of which containing a single task",
    "start": "479740",
    "end": "482380"
  },
  {
    "text": "to run so once it runs that task the the",
    "start": "482380",
    "end": "485169"
  },
  {
    "text": "worker pod terminates and then really",
    "start": "485169",
    "end": "487930"
  },
  {
    "text": "releases those sort resources to the",
    "start": "487930",
    "end": "491050"
  },
  {
    "text": "cluster this means at times of high",
    "start": "491050",
    "end": "492970"
  },
  {
    "text": "traffic you can scale it out as much as",
    "start": "492970",
    "end": "495639"
  },
  {
    "text": "needed and then once they're all",
    "start": "495639",
    "end": "497110"
  },
  {
    "text": "completed they're able to completely",
    "start": "497110",
    "end": "499510"
  },
  {
    "text": "disappear and you only have to maintain",
    "start": "499510",
    "end": "500949"
  },
  {
    "text": "a single pot this had the side effect of",
    "start": "500949",
    "end": "504820"
  },
  {
    "text": "being able to allow us to do task level",
    "start": "504820",
    "end": "506500"
  },
  {
    "text": "configs so before with static workers",
    "start": "506500",
    "end": "508810"
  },
  {
    "text": "you couldn't really make that many",
    "start": "508810",
    "end": "510280"
  },
  {
    "text": "changes because they were already",
    "start": "510280",
    "end": "511479"
  },
  {
    "text": "allocated but now you can actually say",
    "start": "511479",
    "end": "513490"
  },
  {
    "text": "you know I think this task deserves this",
    "start": "513490",
    "end": "515740"
  },
  {
    "text": "much memory I actually want to do a",
    "start": "515740",
    "end": "518709"
  },
  {
    "text": "sci-fi task with this with this task so",
    "start": "518709",
    "end": "521919"
  },
  {
    "text": "therefore I might want this specific",
    "start": "521919",
    "end": "523300"
  },
  {
    "text": "task to have a version of airflow that",
    "start": "523300",
    "end": "525279"
  },
  {
    "text": "has side PI libraries in it and even has",
    "start": "525279",
    "end": "527920"
  },
  {
    "text": "a slightly better security story where",
    "start": "527920",
    "end": "530050"
  },
  {
    "text": "now you can actually",
    "start": "530050",
    "end": "531300"
  },
  {
    "text": "determine which which service accounts",
    "start": "531300",
    "end": "533760"
  },
  {
    "text": "are per tasks so if you have multiple",
    "start": "533760",
    "end": "535860"
  },
  {
    "text": "service accounts in GCP and you want to",
    "start": "535860",
    "end": "538680"
  },
  {
    "text": "have board before you would have to put",
    "start": "538680",
    "end": "541530"
  },
  {
    "text": "configurations for all of those inside",
    "start": "541530",
    "end": "543570"
  },
  {
    "text": "the workers now you can on a per task",
    "start": "543570",
    "end": "546360"
  },
  {
    "text": "basis determine what what service",
    "start": "546360",
    "end": "550050"
  },
  {
    "text": "accounts each of those tasks would have",
    "start": "550050",
    "end": "552740"
  },
  {
    "text": "as far as the actual architecture goes",
    "start": "552740",
    "end": "555180"
  },
  {
    "text": "because we want to allow for high levels",
    "start": "555180",
    "end": "557310"
  },
  {
    "text": "of parallelism we actually offloaded a",
    "start": "557310",
    "end": "559380"
  },
  {
    "text": "lot of the monitoring from the scheduler",
    "start": "559380",
    "end": "561600"
  },
  {
    "text": "with other airflow executors you would",
    "start": "561600",
    "end": "564060"
  },
  {
    "text": "actually have to have the scheduler",
    "start": "564060",
    "end": "565350"
  },
  {
    "text": "checking the status of each of the tasks",
    "start": "565350",
    "end": "567690"
  },
  {
    "text": "to see if they passed or failed or still",
    "start": "567690",
    "end": "570120"
  },
  {
    "text": "running so now actually because the",
    "start": "570120",
    "end": "573150"
  },
  {
    "text": "workers are speaking to the same",
    "start": "573150",
    "end": "574500"
  },
  {
    "text": "Postgres back end as the scheduler the",
    "start": "574500",
    "end": "577320"
  },
  {
    "text": "only thing that the scheduler needs to",
    "start": "577320",
    "end": "578610"
  },
  {
    "text": "know about is did this did this pod fail",
    "start": "578610",
    "end": "581250"
  },
  {
    "text": "and the way it does that is through the",
    "start": "581250",
    "end": "582990"
  },
  {
    "text": "kubernetes watcher API where the",
    "start": "582990",
    "end": "585180"
  },
  {
    "text": "kubernetes wash api allows the allows",
    "start": "585180",
    "end": "587940"
  },
  {
    "text": "the scheduler to read an event log for",
    "start": "587940",
    "end": "590040"
  },
  {
    "text": "anything with a label tied to that",
    "start": "590040",
    "end": "591960"
  },
  {
    "text": "airflow instance so if the task passes",
    "start": "591960",
    "end": "595290"
  },
  {
    "text": "or fails the worker alerts the Postgres",
    "start": "595290",
    "end": "598050"
  },
  {
    "text": "if it if the pod fails the scheduler",
    "start": "598050",
    "end": "600660"
  },
  {
    "text": "reads the watch API and then alerts the",
    "start": "600660",
    "end": "602850"
  },
  {
    "text": "Postgres which then bubbles up to the",
    "start": "602850",
    "end": "604410"
  },
  {
    "text": "user and anything like pager duty that",
    "start": "604410",
    "end": "606360"
  },
  {
    "text": "you would use for your monitoring but we",
    "start": "606360",
    "end": "609480"
  },
  {
    "text": "also wanted to consider fault tolerance",
    "start": "609480",
    "end": "611160"
  },
  {
    "text": "for when the scheduler goes down with",
    "start": "611160",
    "end": "614880"
  },
  {
    "text": "previous air flow configurations there",
    "start": "614880",
    "end": "617040"
  },
  {
    "text": "was a there was a problem where a lot of",
    "start": "617040",
    "end": "620430"
  },
  {
    "text": "state was being held inside of local",
    "start": "620430",
    "end": "622470"
  },
  {
    "text": "Python queues and that meant that if the",
    "start": "622470",
    "end": "624570"
  },
  {
    "text": "scheduler went down there was no easy",
    "start": "624570",
    "end": "626520"
  },
  {
    "text": "way to recreate this state so you might",
    "start": "626520",
    "end": "628740"
  },
  {
    "text": "have tasks that run twice you might have",
    "start": "628740",
    "end": "630930"
  },
  {
    "text": "passed and don't run at all and so we",
    "start": "630930",
    "end": "633780"
  },
  {
    "text": "were able to take advantage of what's",
    "start": "633780",
    "end": "634950"
  },
  {
    "text": "called a resource version and kubernetes",
    "start": "634950",
    "end": "636630"
  },
  {
    "text": "and we by storing the resource version",
    "start": "636630",
    "end": "639300"
  },
  {
    "text": "in the sequel back-end whence when a",
    "start": "639300",
    "end": "641700"
  },
  {
    "text": "scheduler goes down it can check the",
    "start": "641700",
    "end": "644280"
  },
  {
    "text": "Postgres check the resource version",
    "start": "644280",
    "end": "646530"
  },
  {
    "text": "reread the event log from that point and",
    "start": "646530",
    "end": "649590"
  },
  {
    "text": "then be up to date this means that the",
    "start": "649590",
    "end": "651750"
  },
  {
    "text": "scheduler can go down for hours and even",
    "start": "651750",
    "end": "653520"
  },
  {
    "text": "up to days and still be able to come",
    "start": "653520",
    "end": "655770"
  },
  {
    "text": "back to a point of up to date one other",
    "start": "655770",
    "end": "661620"
  },
  {
    "text": "issue we had to consider was dag",
    "start": "661620",
    "end": "662880"
  },
  {
    "text": "propagation you start out with the Dagon",
    "start": "662880",
    "end": "665200"
  },
  {
    "text": "schedulers but with these workers coming",
    "start": "665200",
    "end": "667360"
  },
  {
    "text": "up dynamically how do we get all these",
    "start": "667360",
    "end": "669400"
  },
  {
    "text": "dag files to the workers to actually run",
    "start": "669400",
    "end": "671530"
  },
  {
    "text": "your workloads we have two modes",
    "start": "671530",
    "end": "674290"
  },
  {
    "text": "currently with a third on the way the",
    "start": "674290",
    "end": "676180"
  },
  {
    "text": "two existing ones are they getting it",
    "start": "676180",
    "end": "677830"
  },
  {
    "text": "mode in the persistent volume mode and",
    "start": "677830",
    "end": "679680"
  },
  {
    "text": "with one point 10.2 we're going to have",
    "start": "679680",
    "end": "682480"
  },
  {
    "text": "a pre-baked mode where you can actually",
    "start": "682480",
    "end": "684510"
  },
  {
    "text": "pre-baked your DAGs into the docker",
    "start": "684510",
    "end": "687040"
  },
  {
    "text": "versions we recommend the get in",
    "start": "687040",
    "end": "688840"
  },
  {
    "text": "pre-baked mode for small to medium sized",
    "start": "688840",
    "end": "690850"
  },
  {
    "text": "air flow instances because it's the",
    "start": "690850",
    "end": "692830"
  },
  {
    "text": "least amount of configuration the",
    "start": "692830",
    "end": "694390"
  },
  {
    "text": "pre-baked will be the easiest one",
    "start": "694390",
    "end": "696010"
  },
  {
    "text": "because then as long as you know the",
    "start": "696010",
    "end": "698110"
  },
  {
    "text": "version of all the dogs are running",
    "start": "698110",
    "end": "700060"
  },
  {
    "text": "everything will be consistent and",
    "start": "700060",
    "end": "701830"
  },
  {
    "text": "there's no need to speak to any external",
    "start": "701830",
    "end": "703330"
  },
  {
    "text": "services at all but we do also",
    "start": "703330",
    "end": "705190"
  },
  {
    "text": "understand that certain companies have",
    "start": "705190",
    "end": "706810"
  },
  {
    "text": "pretty large dag file systems and to",
    "start": "706810",
    "end": "711550"
  },
  {
    "text": "handle those cases we also allow people",
    "start": "711550",
    "end": "714100"
  },
  {
    "text": "to use persistent volumes so you can set",
    "start": "714100",
    "end": "715720"
  },
  {
    "text": "it up with NFS or staff or any other",
    "start": "715720",
    "end": "718150"
  },
  {
    "text": "large scale large scale volume store",
    "start": "718150",
    "end": "720580"
  },
  {
    "text": "that speaks to that has a coup Bay has a",
    "start": "720580",
    "end": "724600"
  },
  {
    "text": "cube volume object Thank You Danielle",
    "start": "724600",
    "end": "730950"
  },
  {
    "start": "727000",
    "end": "940000"
  },
  {
    "text": "that was an amazing piece of work the",
    "start": "730950",
    "end": "733750"
  },
  {
    "text": "community's executors effectively",
    "start": "733750",
    "end": "735520"
  },
  {
    "text": "modernized our flow and took it to the",
    "start": "735520",
    "end": "738220"
  },
  {
    "text": "container world but it still didn't",
    "start": "738220",
    "end": "740860"
  },
  {
    "text": "solve the problem of managing and",
    "start": "740860",
    "end": "742750"
  },
  {
    "text": "deploying our flow that's where the",
    "start": "742750",
    "end": "743980"
  },
  {
    "text": "operator comes in the operator is used",
    "start": "743980",
    "end": "747130"
  },
  {
    "text": "to is a custom controller on kubernetes",
    "start": "747130",
    "end": "749770"
  },
  {
    "text": "that extends the API surface of",
    "start": "749770",
    "end": "752410"
  },
  {
    "text": "kubernetes by introducing two new CR DS",
    "start": "752410",
    "end": "754480"
  },
  {
    "text": "that's the airflow base and the airflow",
    "start": "754480",
    "end": "757030"
  },
  {
    "text": "cluster let's take a look at the base",
    "start": "757030",
    "end": "760230"
  },
  {
    "text": "the airflow base CRE is a declarative",
    "start": "760230",
    "end": "763660"
  },
  {
    "text": "spec that describes the common",
    "start": "763660",
    "end": "765730"
  },
  {
    "text": "components that you need to run airflow",
    "start": "765730",
    "end": "768400"
  },
  {
    "text": "clusters that includes the database and",
    "start": "768400",
    "end": "770470"
  },
  {
    "text": "the storage this can be shared across",
    "start": "770470",
    "end": "773140"
  },
  {
    "text": "multiple airflow clusters in this",
    "start": "773140",
    "end": "777220"
  },
  {
    "text": "example of the spec the user requests",
    "start": "777220",
    "end": "780760"
  },
  {
    "text": "for my sequel instance and a storage he",
    "start": "780760",
    "end": "785380"
  },
  {
    "text": "uses cubes ETL to post it to the API",
    "start": "785380",
    "end": "787930"
  },
  {
    "text": "server the airflow controller monitors",
    "start": "787930",
    "end": "791020"
  },
  {
    "text": "the CR DS and then creates a stateful",
    "start": "791020",
    "end": "793540"
  },
  {
    "text": "sets pod Services config map secrets",
    "start": "793540",
    "end": "796720"
  },
  {
    "text": "etc needed for deploying this company",
    "start": "796720",
    "end": "799980"
  },
  {
    "text": "and in let's take a look at another",
    "start": "799980",
    "end": "804160"
  },
  {
    "text": "example",
    "start": "804160",
    "end": "804819"
  },
  {
    "text": "in this example the user requests for",
    "start": "804819",
    "end": "806709"
  },
  {
    "text": "sequel proxy instead of my sequel this",
    "start": "806709",
    "end": "809439"
  },
  {
    "text": "is used to connect to cloud sequel in a",
    "start": "809439",
    "end": "811600"
  },
  {
    "text": "cloud environment cloud sequel is a more",
    "start": "811600",
    "end": "814110"
  },
  {
    "text": "production ready database and when he",
    "start": "814110",
    "end": "818860"
  },
  {
    "text": "applies the spec this is how the",
    "start": "818860",
    "end": "820480"
  },
  {
    "text": "deployment looks like let's take a look",
    "start": "820480",
    "end": "826929"
  },
  {
    "text": "at the cluster theory cluster series",
    "start": "826929",
    "end": "828699"
  },
  {
    "text": "where you describe the actual airflow",
    "start": "828699",
    "end": "832119"
  },
  {
    "text": "components in this particular example",
    "start": "832119",
    "end": "834790"
  },
  {
    "text": "the user requests for us salary",
    "start": "834790",
    "end": "837300"
  },
  {
    "text": "executors thereby needing the radius as",
    "start": "837300",
    "end": "841449"
  },
  {
    "text": "the broker",
    "start": "841449",
    "end": "842679"
  },
  {
    "text": "and he also under request for two",
    "start": "842679",
    "end": "844629"
  },
  {
    "text": "workers and when the controller deploys",
    "start": "844629",
    "end": "849579"
  },
  {
    "text": "this CRD it results in all these",
    "start": "849579",
    "end": "852009"
  },
  {
    "text": "components getting deployed the way the",
    "start": "852009",
    "end": "855699"
  },
  {
    "text": "controller works with cluster is it for",
    "start": "855699",
    "end": "858249"
  },
  {
    "text": "each of the clusters URI creates a",
    "start": "858249",
    "end": "860170"
  },
  {
    "text": "unique username password and database in",
    "start": "860170",
    "end": "862660"
  },
  {
    "text": "the sequel DB and thereby this allows",
    "start": "862660",
    "end": "865420"
  },
  {
    "text": "you to share the same base across",
    "start": "865420",
    "end": "867189"
  },
  {
    "text": "multiple clusters with isolation in this",
    "start": "867189",
    "end": "872199"
  },
  {
    "text": "example of the cluster CR you the user",
    "start": "872199",
    "end": "874360"
  },
  {
    "text": "requests for communities executors if",
    "start": "874360",
    "end": "878679"
  },
  {
    "text": "you notice we don't the broker and the",
    "start": "878679",
    "end": "881649"
  },
  {
    "text": "worker nodes are not deployed for",
    "start": "881649",
    "end": "883059"
  },
  {
    "text": "cumulative executors",
    "start": "883059",
    "end": "884079"
  },
  {
    "text": "and for what we recommend is well demoed",
    "start": "884079",
    "end": "889329"
  },
  {
    "text": "we use the local executor and for",
    "start": "889329",
    "end": "891339"
  },
  {
    "text": "production runs use the kubernetes",
    "start": "891339",
    "end": "892809"
  },
  {
    "text": "executor the seri also allows you to",
    "start": "892809",
    "end": "898600"
  },
  {
    "text": "spec pod specify part affinity rules",
    "start": "898600",
    "end": "901649"
  },
  {
    "text": "with this you the cuban artists",
    "start": "901649",
    "end": "905160"
  },
  {
    "text": "scheduler spreads your pots across nodes",
    "start": "905160",
    "end": "908019"
  },
  {
    "text": "and across zones this is used to limit",
    "start": "908019",
    "end": "911259"
  },
  {
    "text": "the impact of norrisville on failures",
    "start": "911259",
    "end": "915329"
  },
  {
    "text": "with the operator we use a sidecar or",
    "start": "915449",
    "end": "919959"
  },
  {
    "text": "any container pattern to inject the tags",
    "start": "919959",
    "end": "924149"
  },
  {
    "text": "so when the airflow pod is started a",
    "start": "924149",
    "end": "927040"
  },
  {
    "text": "sidecar syncs the tags from a the GCS",
    "start": "927040",
    "end": "929799"
  },
  {
    "text": "get or NFS or any of",
    "start": "929799",
    "end": "932089"
  },
  {
    "text": "the sources that's configurable and then",
    "start": "932089",
    "end": "934519"
  },
  {
    "text": "starts the airflow part like the sorry",
    "start": "934519",
    "end": "937009"
  },
  {
    "text": "airflow container like the scheduler of",
    "start": "937009",
    "end": "938779"
  },
  {
    "text": "worker thank you so we wanted to talk",
    "start": "938779",
    "end": "943670"
  },
  {
    "start": "940000",
    "end": "1010000"
  },
  {
    "text": "about a few of the other huge benefits",
    "start": "943670",
    "end": "945170"
  },
  {
    "text": "of running airflow on kubernetes one of",
    "start": "945170",
    "end": "947420"
  },
  {
    "text": "the big ones being monitoring when you",
    "start": "947420",
    "end": "949790"
  },
  {
    "text": "run air flow in kubernetes you're",
    "start": "949790",
    "end": "951620"
  },
  {
    "text": "actually able to take advantage of the",
    "start": "951620",
    "end": "953059"
  },
  {
    "text": "monitoring that's already been set up in",
    "start": "953059",
    "end": "954769"
  },
  {
    "text": "your cluster so you can piggyback on",
    "start": "954769",
    "end": "956779"
  },
  {
    "text": "things like if your if your team has",
    "start": "956779",
    "end": "959660"
  },
  {
    "text": "already set up Prometheus or",
    "start": "959660",
    "end": "961129"
  },
  {
    "text": "elasticsearch for logs a lot of these",
    "start": "961129",
    "end": "963529"
  },
  {
    "text": "will automatically transfer from air",
    "start": "963529",
    "end": "965420"
  },
  {
    "text": "flow to these other sources to easily",
    "start": "965420",
    "end": "968240"
  },
  {
    "text": "track and monitor what the health of",
    "start": "968240",
    "end": "970430"
  },
  {
    "text": "your cluster we and as far as the status",
    "start": "970430",
    "end": "973999"
  },
  {
    "text": "goes the kubernetes executor has been",
    "start": "973999",
    "end": "975889"
  },
  {
    "text": "released in airflow 1.10 in experimental",
    "start": "975889",
    "end": "978439"
  },
  {
    "text": "mode we have multiple companies already",
    "start": "978439",
    "end": "980660"
  },
  {
    "text": "using it in production a home chart in",
    "start": "980660",
    "end": "983029"
  },
  {
    "text": "progress we plan to have it as in the",
    "start": "983029",
    "end": "986329"
  },
  {
    "text": "GCP store as a part of the airflow",
    "start": "986329",
    "end": "989779"
  },
  {
    "text": "operator by the end of 2018 and we have",
    "start": "989779",
    "end": "992269"
  },
  {
    "text": "a really active community in both this",
    "start": "992269",
    "end": "994069"
  },
  {
    "text": "in the cig Big Data channel in",
    "start": "994069",
    "end": "995600"
  },
  {
    "text": "kubernetes slack comm and we're",
    "start": "995600",
    "end": "998059"
  },
  {
    "text": "absolutely seeking beta testers devs and",
    "start": "998059",
    "end": "1001029"
  },
  {
    "text": "brave souls willing to do bug searching",
    "start": "1001029",
    "end": "1003839"
  },
  {
    "text": "any form of extra testing scale testing",
    "start": "1003839",
    "end": "1006879"
  },
  {
    "text": "and anyone who just wants to help out",
    "start": "1006879",
    "end": "1008589"
  },
  {
    "text": "with the effort for the air flow operate",
    "start": "1008589",
    "end": "1012309"
  },
  {
    "start": "1010000",
    "end": "1401000"
  },
  {
    "text": "operator we have it currently supporting",
    "start": "1012309",
    "end": "1015459"
  },
  {
    "text": "air flow one point 10.1",
    "start": "1015459",
    "end": "1017679"
  },
  {
    "text": "the kubernetes marketplace for GCP and",
    "start": "1017679",
    "end": "1019899"
  },
  {
    "text": "it has two channels on the kubernetes",
    "start": "1019899",
    "end": "1022059"
  },
  {
    "text": "slack sig big data and air flow -",
    "start": "1022059",
    "end": "1024668"
  },
  {
    "text": "operator and now for some live demos so",
    "start": "1024669",
    "end": "1034089"
  },
  {
    "text": "for this first live demo we're going to",
    "start": "1034089",
    "end": "1035649"
  },
  {
    "text": "be demoing the kubernetes executor so we",
    "start": "1035649",
    "end": "1038260"
  },
  {
    "text": "have an airflow UI set up already and",
    "start": "1038260",
    "end": "1040659"
  },
  {
    "text": "this is tied to a this is tied to our",
    "start": "1040659",
    "end": "1044620"
  },
  {
    "text": "cluster let's hope that the internet",
    "start": "1044620",
    "end": "1047140"
  },
  {
    "text": "works",
    "start": "1047140",
    "end": "1049380"
  },
  {
    "text": "and it looks like we are unable to",
    "start": "1062280",
    "end": "1064780"
  },
  {
    "text": "connect to the kubernetes cluster which",
    "start": "1064780",
    "end": "1066460"
  },
  {
    "text": "is why we always keep a video of our",
    "start": "1066460",
    "end": "1068590"
  },
  {
    "text": "demos hooray",
    "start": "1068590",
    "end": "1072270"
  },
  {
    "text": "well while all that's connecting we can",
    "start": "1087570",
    "end": "1090040"
  },
  {
    "text": "do the video of the GCP operator okay",
    "start": "1090040",
    "end": "1092950"
  },
  {
    "text": "cool",
    "start": "1092950",
    "end": "1093669"
  },
  {
    "text": "yeah I did record a demo just some time",
    "start": "1093669",
    "end": "1096760"
  },
  {
    "text": "back just for this purpose",
    "start": "1096760",
    "end": "1098710"
  },
  {
    "text": "okay I hope you can see the whole screen",
    "start": "1098710",
    "end": "1102309"
  },
  {
    "text": "alright alright so this is a cloud",
    "start": "1102309",
    "end": "1111100"
  },
  {
    "text": "console where you can deploy",
    "start": "1111100",
    "end": "1112360"
  },
  {
    "text": "applications on GCP this is a",
    "start": "1112360",
    "end": "1114730"
  },
  {
    "text": "marketplace for gke coming form you can",
    "start": "1114730",
    "end": "1123929"
  },
  {
    "text": "so in this example I'm going to start",
    "start": "1126600",
    "end": "1130270"
  },
  {
    "text": "the operator on the right you can see",
    "start": "1130270",
    "end": "1134650"
  },
  {
    "text": "the logs for the operator on the right",
    "start": "1134650",
    "end": "1135970"
  },
  {
    "text": "and I'm creating the base CRD first if",
    "start": "1135970",
    "end": "1141040"
  },
  {
    "text": "you it's the same the example that I",
    "start": "1141040",
    "end": "1143500"
  },
  {
    "text": "showed in the slides so as you create",
    "start": "1143500",
    "end": "1147370"
  },
  {
    "text": "the base he already using cube CTO you",
    "start": "1147370",
    "end": "1149980"
  },
  {
    "text": "see that it deploys the stateful sets",
    "start": "1149980",
    "end": "1151720"
  },
  {
    "text": "and for both of them and in the",
    "start": "1151720",
    "end": "1155230"
  },
  {
    "text": "application sorry alright alright so in",
    "start": "1155230",
    "end": "1163000"
  },
  {
    "text": "the UI you can see all the components",
    "start": "1163000",
    "end": "1164500"
  },
  {
    "text": "that are deployed like the stateful so",
    "start": "1164500",
    "end": "1166000"
  },
  {
    "text": "it's a secret etc alright all of them",
    "start": "1166000",
    "end": "1173830"
  },
  {
    "text": "are deployed successfully now let's go",
    "start": "1173830",
    "end": "1178480"
  },
  {
    "text": "and deploy the cluster",
    "start": "1178480",
    "end": "1181380"
  },
  {
    "text": "this is the same example as in the",
    "start": "1185260",
    "end": "1186820"
  },
  {
    "text": "slides it has a celery executor to",
    "start": "1186820",
    "end": "1189370"
  },
  {
    "text": "worker nodes and get a tzaddik source",
    "start": "1189370",
    "end": "1194039"
  },
  {
    "text": "if you notice it's deploying all the",
    "start": "1206820",
    "end": "1209019"
  },
  {
    "text": "parts that are needed for the cluster",
    "start": "1209019",
    "end": "1210399"
  },
  {
    "text": "components",
    "start": "1210399",
    "end": "1212940"
  },
  {
    "text": "and in the UI you can see all these",
    "start": "1224990",
    "end": "1226909"
  },
  {
    "text": "components that were just deployed",
    "start": "1226909",
    "end": "1230200"
  },
  {
    "text": "I also create speedy bees which didn't",
    "start": "1235960",
    "end": "1238360"
  },
  {
    "text": "show up in the UI what I'm doing is a",
    "start": "1238360",
    "end": "1243460"
  },
  {
    "text": "port forwarding to access the UI",
    "start": "1243460",
    "end": "1245369"
  },
  {
    "text": "voila in two minutes you were able to",
    "start": "1245369",
    "end": "1247779"
  },
  {
    "text": "deploy a fully functional airflow",
    "start": "1247779",
    "end": "1249580"
  },
  {
    "text": "cluster with celery and you can test it",
    "start": "1249580",
    "end": "1252639"
  },
  {
    "text": "to make sure it's working you can see",
    "start": "1252639",
    "end": "1255249"
  },
  {
    "text": "that it's running the tags there are",
    "start": "1255249",
    "end": "1258549"
  },
  {
    "text": "three run instances there this is how",
    "start": "1258549",
    "end": "1262749"
  },
  {
    "text": "the dag looks is it not chart all right",
    "start": "1262749",
    "end": "1273690"
  },
  {
    "text": "that was that was cool let's do",
    "start": "1273690",
    "end": "1276909"
  },
  {
    "text": "something a little bit cooler now I'm",
    "start": "1276909",
    "end": "1280840"
  },
  {
    "text": "going to deploy another airflow cluster",
    "start": "1280840",
    "end": "1282789"
  },
  {
    "text": "at this time it's the kubernetes",
    "start": "1282789",
    "end": "1284379"
  },
  {
    "text": "executor you see the new sorry you see",
    "start": "1284379",
    "end": "1291100"
  },
  {
    "text": "the new components that are coming up",
    "start": "1291100",
    "end": "1293169"
  },
  {
    "text": "for the second airflow cluster",
    "start": "1293169",
    "end": "1296580"
  },
  {
    "text": "let's connect to the second cluster and",
    "start": "1301720",
    "end": "1305149"
  },
  {
    "text": "this one is the 8081 port and the second",
    "start": "1305149",
    "end": "1310399"
  },
  {
    "text": "cluster doesn't have the same runs",
    "start": "1310399",
    "end": "1311659"
  },
  {
    "text": "thereby showing it's a different cluster",
    "start": "1311659",
    "end": "1313070"
  },
  {
    "text": "a different context and in the",
    "start": "1313070",
    "end": "1316129"
  },
  {
    "text": "applications page you can see another",
    "start": "1316129",
    "end": "1317840"
  },
  {
    "text": "cluster gist that was just deployed",
    "start": "1317840",
    "end": "1321429"
  },
  {
    "text": "let's try running the year yeah",
    "start": "1324070",
    "end": "1327470"
  },
  {
    "text": "a dag",
    "start": "1327470",
    "end": "1331690"
  },
  {
    "text": "all right",
    "start": "1335700",
    "end": "1338330"
  },
  {
    "text": "if you notice it creates a pod",
    "start": "1338360",
    "end": "1340370"
  },
  {
    "text": "dynamically that's what the cabinet is",
    "start": "1340370",
    "end": "1342020"
  },
  {
    "text": "executed just at four for a dag task it",
    "start": "1342020",
    "end": "1345200"
  },
  {
    "text": "created a pod dynamically and once the",
    "start": "1345200",
    "end": "1351080"
  },
  {
    "text": "task completes the part goes away that's",
    "start": "1351080",
    "end": "1353360"
  },
  {
    "text": "that's it and to show that how the",
    "start": "1353360",
    "end": "1358910"
  },
  {
    "text": "sequel sharing a sum I'm just going to",
    "start": "1358910",
    "end": "1361580"
  },
  {
    "text": "show a bit look at the connection string",
    "start": "1361580",
    "end": "1363950"
  },
  {
    "text": "here for my sequel it generates",
    "start": "1363950",
    "end": "1365630"
  },
  {
    "text": "dynamically the username password and",
    "start": "1365630",
    "end": "1367070"
  },
  {
    "text": "database which are different for each of",
    "start": "1367070",
    "end": "1368840"
  },
  {
    "text": "the clusters alright and that's how we",
    "start": "1368840",
    "end": "1377750"
  },
  {
    "text": "can use airflow operator to deploy and",
    "start": "1377750",
    "end": "1380450"
  },
  {
    "text": "manage your clusters thank you and with",
    "start": "1380450",
    "end": "1387500"
  },
  {
    "text": "that we have a we thank you so much for",
    "start": "1387500",
    "end": "1390380"
  },
  {
    "text": "coming and we'd love if you have any",
    "start": "1390380",
    "end": "1392360"
  },
  {
    "text": "questions and we're here to answer",
    "start": "1392360",
    "end": "1394490"
  },
  {
    "text": "anything you guys won't ask thank you so",
    "start": "1394490",
    "end": "1396860"
  },
  {
    "text": "much",
    "start": "1396860",
    "end": "1398190"
  },
  {
    "text": "[Applause]",
    "start": "1398190",
    "end": "1403559"
  }
]
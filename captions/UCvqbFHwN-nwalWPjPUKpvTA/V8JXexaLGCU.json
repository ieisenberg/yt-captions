[
  {
    "text": "hi everybody welcome to kubecon north america 2021 we're sig honk a hacker crew not an official kubernetes cig and",
    "start": "1040",
    "end": "8160"
  },
  {
    "text": "we're here to present a story for you about how we came across a runcie vulnerability advisory we flocked",
    "start": "8160",
    "end": "13519"
  },
  {
    "text": "together to understand it developed a proof of concept for kubernetes for it and shared our findings with the world",
    "start": "13519",
    "end": "19359"
  },
  {
    "text": "we are excited to get to share them with you hey everybody i'm duffy cooley and i can",
    "start": "19359",
    "end": "24960"
  },
  {
    "text": "be found everywhere as maui lyon i host this week on cloud native on cloud native tv and ebpf office hours on",
    "start": "24960",
    "end": "31920"
  },
  {
    "text": "youtube one of the big takeaways of this talk for me is that we all level each other up it takes a village to move a project",
    "start": "31920",
    "end": "38719"
  },
  {
    "text": "like kubernetes forward whether from the security perspective writing and reviewing code documentation or in the",
    "start": "38719",
    "end": "44480"
  },
  {
    "text": "day-to-day release efforts there are so many ways to get involved find the part that inspires you and jump",
    "start": "44480",
    "end": "50160"
  },
  {
    "text": "in everyone is welcome here we are going to present this story as a",
    "start": "50160",
    "end": "55760"
  },
  {
    "text": "timeline um in the lower part of your screen",
    "start": "55760",
    "end": "61840"
  },
  {
    "text": "you're going to see word bubbles like this one show up and your and those word bubbles are",
    "start": "61840",
    "end": "67040"
  },
  {
    "text": "going to be like exchanges that we pass back and forth as we explore this vulnerability and we're looking we're",
    "start": "67040",
    "end": "72799"
  },
  {
    "text": "excited about just taking you with us on that journey hi i'm rory and i go very racing online",
    "start": "72799",
    "end": "79680"
  },
  {
    "text": "one of the challenges we all face with cloud native world is the complexity it has in terms of the number of",
    "start": "79680",
    "end": "84880"
  },
  {
    "text": "overlapping projects that can be used in a cluster vulnerabilities can occur at any level of the stack and affect your",
    "start": "84880",
    "end": "90400"
  },
  {
    "text": "overall environment also when you're examining a vulnerability this complexity shows up as well",
    "start": "90400",
    "end": "96079"
  },
  {
    "text": "so if you're trying to prove a kubernetes vulnerability one question is well which kubernetes distributions does this affect",
    "start": "96079",
    "end": "102079"
  },
  {
    "text": "there's well over a hundred choices to test and if a vulnerability affects all of them or even just the most used ones",
    "start": "102079",
    "end": "107360"
  },
  {
    "text": "it can be a lot of work hey everyone i'm brad giessoman and i'm sometimes a mischievous goose as a",
    "start": "107360",
    "end": "114399"
  },
  {
    "text": "security researcher it's important to understand that discovering and creating the proof of concept exploit is just the",
    "start": "114399",
    "end": "120240"
  },
  {
    "text": "beginning of a responsible disclosure process if your goal is to get end users to patch as quickly as possible you might",
    "start": "120240",
    "end": "127119"
  },
  {
    "text": "need to take some extra steps to test the exploit on multiple different environments and provide those results",
    "start": "127119",
    "end": "133200"
  },
  {
    "text": "in the disclosure this can help convey a wider impact and impart the desired urgency by the vendor",
    "start": "133200",
    "end": "139120"
  },
  {
    "text": "and community response teams because without that extra supporting detail the issue can often be underrated or even",
    "start": "139120",
    "end": "145520"
  },
  {
    "text": "downplayed by the people triaging that disclosure hi i'm ian coldwater i'm co-chair of",
    "start": "145520",
    "end": "151280"
  },
  {
    "text": "kubernetes security security in the cloud native ecosystem is complex every container system is",
    "start": "151280",
    "end": "157200"
  },
  {
    "text": "only as secure as every part of its stack everything is connected in the dependency chain but different projects",
    "start": "157200",
    "end": "163280"
  },
  {
    "text": "are responsible for different parts sometimes it can be hard to know who exactly is responsible for what",
    "start": "163280",
    "end": "168400"
  },
  {
    "text": "especially when things connect with multiple projects how do we solve this like our dependencies we connect and",
    "start": "168400",
    "end": "174959"
  },
  {
    "text": "depend on each other we all take responsibility for the security of the ecosystem when we bring our different skills and",
    "start": "174959",
    "end": "181280"
  },
  {
    "text": "perspectives to the ecosystem as a whole we can see things we might not have spotted by ourselves when we work together as a community we",
    "start": "181280",
    "end": "188159"
  },
  {
    "text": "get farther than we would if we were working on our own this story is one example of how it can look when",
    "start": "188159",
    "end": "193440"
  },
  {
    "text": "different groups of people work together like that now let's get into the timeline",
    "start": "193440",
    "end": "198560"
  },
  {
    "text": "cool so one of the fun problems in open source is trying to keep track of new information which is relevant to all the",
    "start": "198560",
    "end": "204640"
  },
  {
    "text": "different projects that make up the ecosystem as there's loads of places where interesting things might be discussed",
    "start": "204640",
    "end": "209920"
  },
  {
    "text": "now everyone will have their own approach to this but my three main sources for kubernetes and container related security are twitter github and",
    "start": "209920",
    "end": "217360"
  },
  {
    "text": "slack this story starts in one of those places with a message that was sent to the sig security channel in slack about a",
    "start": "217360",
    "end": "224080"
  },
  {
    "text": "vulnerability in the run c project originally found by etienne champatie cve 2021 30465",
    "start": "224080",
    "end": "232640"
  },
  {
    "text": "vulnerabilities in run c are especially interesting as as a key role in the container ecosystem it's the tool that",
    "start": "232640",
    "end": "238400"
  },
  {
    "text": "actually launches containers and is used as part of many other projects like docker container d and cryo",
    "start": "238400",
    "end": "244799"
  },
  {
    "text": "also most cluster operators will never actually install runc directly and may not even realize they have it installed",
    "start": "244799",
    "end": "251439"
  },
  {
    "text": "after looking at the advisory i had a quick look at the releases for projects that bundle run c and noticed that both",
    "start": "251439",
    "end": "256959"
  },
  {
    "text": "docker and cryo were yet to release a patched version although container d had this was pretty interesting to me",
    "start": "256959",
    "end": "262880"
  },
  {
    "text": "because it meant that a large proportion of clusters were possibly still exposed to the issue now of course that doesn't mean much if",
    "start": "262880",
    "end": "268960"
  },
  {
    "text": "it's not possible to exploit but in the advisory there was an intriguing mention that with kubernetes it might be",
    "start": "268960",
    "end": "274560"
  },
  {
    "text": "possible to use this to gain access to the host file system of cluster nodes",
    "start": "274560",
    "end": "280080"
  },
  {
    "text": "there was no proof of concept code included in the original advisory but there was enough detail to understand",
    "start": "280080",
    "end": "286240"
  },
  {
    "text": "that it was likely a widely applicable container escape the write-up mentions kubernetes and",
    "start": "286240",
    "end": "291440"
  },
  {
    "text": "volume mounts as the point of attack but it's not clear exactly how so i asked the group if we should try to recreate a",
    "start": "291440",
    "end": "297759"
  },
  {
    "text": "poc ourselves and i said be the change we wish to see",
    "start": "297759",
    "end": "302880"
  },
  {
    "text": "each of us brought us brought our own perspectives to this brad wanted to know how it worked i wanted to break it for",
    "start": "302880",
    "end": "308880"
  },
  {
    "text": "fun and rory reminded us that we needed to raise awareness and figure out mitigations so that we could communicate",
    "start": "308880",
    "end": "315039"
  },
  {
    "text": "better out to end users and duffy brought us together and herded all the cats",
    "start": "315039",
    "end": "321919"
  },
  {
    "text": "so the first thing uh so first i was really surprised by this one i thought this was a very interesting cbe and the",
    "start": "322720",
    "end": "328880"
  },
  {
    "text": "first thing i did was create a hackmd and start gathering details and so i pulled in the text from the cbd patch",
    "start": "328880",
    "end": "334479"
  },
  {
    "text": "notes i pulled in the text from the advisory and then i started throwing up a couple of theories about how this would work this document that i'm",
    "start": "334479",
    "end": "340720"
  },
  {
    "text": "talking about is a shared document and it will be a part of the resources at the end of this presentation if you want to read through it",
    "start": "340720",
    "end": "348160"
  },
  {
    "text": "i was also thinking about how we could quickly iterate on something like this because we needed an environment that all of us had access to that we could",
    "start": "349600",
    "end": "355840"
  },
  {
    "text": "start playing with this and iterating on these things for that environment we chose to use kind kind is a a",
    "start": "355840",
    "end": "361919"
  },
  {
    "text": "sub-project of kubernetes and you can check it out at kind dot sigs dot k is to io it's used to actually test a lot",
    "start": "361919",
    "end": "369520"
  },
  {
    "text": "of the kubernetes code on pull requests and it's also used to create lightweight kubernetes clusters in docker and inside",
    "start": "369520",
    "end": "376000"
  },
  {
    "text": "of each of the nodes you'll have a version of run c just like you would on any other node inside of a kubernetes",
    "start": "376000",
    "end": "381919"
  },
  {
    "text": "cluster and so that gave us an operator they gave us a good opportunity to kind of iterate on this stuff",
    "start": "381919",
    "end": "387600"
  },
  {
    "text": "so offering a great source of information about exploits for vulnerabilities is the blog posts of people who discovered",
    "start": "387600",
    "end": "393280"
  },
  {
    "text": "them so with that in mind i went to see if etienne had a post detailing how he'd found this issue",
    "start": "393280",
    "end": "398479"
  },
  {
    "text": "after finding there wasn't anything up yet although there were a lot of other great write-ups on his blog i decided to",
    "start": "398479",
    "end": "403840"
  },
  {
    "text": "drop etienne a cold email to see if there's anything more he could tell us he very kindly responded quickly and",
    "start": "403840",
    "end": "409599"
  },
  {
    "text": "provided some useful high-level information about how he'd exploited it but not the full technical details",
    "start": "409599",
    "end": "415280"
  },
  {
    "text": "after all who gives exploit code to random people who email you",
    "start": "415280",
    "end": "421400"
  },
  {
    "text": "so i set up a call for us to collaborate on ian brad and i jumped in rory was sleeping as he's in scotland",
    "start": "422639",
    "end": "428720"
  },
  {
    "text": "these geese are globally distributed we're everywhere from scotland to california so we started working on trying to",
    "start": "428720",
    "end": "434800"
  },
  {
    "text": "figure out how we wanted to approach creating a poc for this because all we had really was the vulnerability",
    "start": "434800",
    "end": "439840"
  },
  {
    "text": "associated with run c and some notes from etienne safar as i copied and aggregated links i began",
    "start": "439840",
    "end": "446479"
  },
  {
    "text": "looking through the run c fix and the tests that were associated with that and i have to say it didn't make a kind of sense to me",
    "start": "446479",
    "end": "453280"
  },
  {
    "text": "while duffy was looking at the tests in the source code for that run c patch release i was reading the patch notes on that fix which were different from the",
    "start": "453280",
    "end": "460240"
  },
  {
    "text": "notes on the advisory these notes went into more detail describing an order of operations for the attack which gave us",
    "start": "460240",
    "end": "466639"
  },
  {
    "text": "more insight as to how this exploit might work the notes also called out that they thought it was an incomplete fix that",
    "start": "466639",
    "end": "472080"
  },
  {
    "text": "they thought there was probably more attack surface lurking there specifically involving mount targets that's always fun to read what were they",
    "start": "472080",
    "end": "478960"
  },
  {
    "text": "how could they work we started framing up what it would look like to exploit this we knew it could be",
    "start": "478960",
    "end": "484720"
  },
  {
    "text": "exploited with an empty dirt volume based on the information that rory had learned from etienne it's a big clue",
    "start": "484720",
    "end": "490400"
  },
  {
    "text": "knowing that it had to be leveraging a tactile a time of check time of use attack we knew the what and the where but we",
    "start": "490400",
    "end": "496960"
  },
  {
    "text": "still needed to figure out the how all of us were definitely out of our comfort zone a bit when trying to piece",
    "start": "496960",
    "end": "503440"
  },
  {
    "text": "a vulnerability like this together enough to build an exploit it's important that you don't get discouraged",
    "start": "503440",
    "end": "508960"
  },
  {
    "text": "if this takes you out of your comfort zone that's when you grow the most this stuff is complex just keep trying things",
    "start": "508960",
    "end": "516000"
  },
  {
    "text": "as you will see in the demonstration it's kind of amazing that this stuff is found at all it's true",
    "start": "516000",
    "end": "522000"
  },
  {
    "text": "the order of operations described in the advisory wasn't linear at all um it wasn't really in a kind of",
    "start": "522000",
    "end": "527920"
  },
  {
    "text": "straightforward order but it made intuitive sense to me because i don't really think linearly anyway so with my",
    "start": "527920",
    "end": "535040"
  },
  {
    "text": "adhd brain i was able to follow the order in the advisory but that wasn't necessarily the case for all of us",
    "start": "535040",
    "end": "543040"
  },
  {
    "text": "we definitely didn't all understand it from the advisory i tried to explain the order i understood from it i kind of",
    "start": "543040",
    "end": "548080"
  },
  {
    "text": "ended up sounding like conspiracy charlie in that meme brad was like hmm i don't know about",
    "start": "548080",
    "end": "553279"
  },
  {
    "text": "this i'm just gonna go try poke at it fair enough i'm glad he did because at the end of",
    "start": "553279",
    "end": "558640"
  },
  {
    "text": "the day i think it worked out better that way if i had done it i would have just ended up replicating the original poc brad's differing approach got",
    "start": "558640",
    "end": "565760"
  },
  {
    "text": "different results and i think better ones so as it happened right after our",
    "start": "565760",
    "end": "571440"
  },
  {
    "text": "initial zoom call there was a scheduled meeting of kubernetes seg security so it seems like a good opportunity to check",
    "start": "571440",
    "end": "577920"
  },
  {
    "text": "in with the rest of the sig security group and also the kubernetes product security committee members which is now",
    "start": "577920",
    "end": "583200"
  },
  {
    "text": "known as the security response committee or src who attended to see if there were any plans to have some disclosure or",
    "start": "583200",
    "end": "588959"
  },
  {
    "text": "awareness around this vulnerability the feeling we got from the src was that kubernetes has a lot of dependencies and",
    "start": "588959",
    "end": "595200"
  },
  {
    "text": "they didn't feel the src could be in a position of being responsible for putting out security announcements around all of them",
    "start": "595200",
    "end": "601760"
  },
  {
    "text": "i didn't know about this one um i love the folks on the src my best friend tabby sable is on the src but in this",
    "start": "601760",
    "end": "609040"
  },
  {
    "text": "particular case i was not at all sure this was the right call because while i understood that the src",
    "start": "609040",
    "end": "614880"
  },
  {
    "text": "can't be responsible for all advisories in all third-party dependencies there are in fact a lot of them this one in",
    "start": "614880",
    "end": "620560"
  },
  {
    "text": "particular said in the advisory that it would be easiest to leverage from within a kubernetes environment it called us",
    "start": "620560",
    "end": "625600"
  },
  {
    "text": "out specifically and so whether or not this one was technically our problem it had become our problem what did this",
    "start": "625600",
    "end": "631680"
  },
  {
    "text": "thing do in a kubernetes environment we weren't really quite sure yet but clearly it did something we wanted to",
    "start": "631680",
    "end": "637440"
  },
  {
    "text": "figure out how it worked and make sure end users would have the information that they needed to know how to mitigate it",
    "start": "637440",
    "end": "643680"
  },
  {
    "text": "from the information we had my theory was it could be a lot like the subpath sim link race approach from a 2017 cve",
    "start": "643680",
    "end": "651440"
  },
  {
    "text": "so i wanted to give that approach a shot and share the feedback with the group my hypothesis was it could be as simple",
    "start": "651440",
    "end": "657120"
  },
  {
    "text": "as a single pod with two containers sharing two volumes the first container starts and immediately goes into a",
    "start": "657120",
    "end": "664000"
  },
  {
    "text": "never-ending loop replacing a specific folder with a sim link to root the second container then starts up but",
    "start": "664000",
    "end": "671040"
  },
  {
    "text": "has the second volume pointing at that specific folder that container one is changing with a sim link hoping that",
    "start": "671040",
    "end": "678000"
  },
  {
    "text": "when it mounts it follows that sim link and gets tricked into doing so knowing that this is attempting to win a",
    "start": "678000",
    "end": "684240"
  },
  {
    "text": "race condition i initially made this deployment with 20 replicas i even tried 50 or 100 but 20 seemed reasonable as a",
    "start": "684240",
    "end": "690880"
  },
  {
    "text": "balance to increase those the number of chances of winning after a lot of failed runs and",
    "start": "690880",
    "end": "696640"
  },
  {
    "text": "frustration of not seeing anything mounted in that second volume path i got lucky",
    "start": "696640",
    "end": "702560"
  },
  {
    "text": "at one point i just happened to run a loop of kubecontrol execs to list the root directory of all the pods file",
    "start": "702560",
    "end": "709040"
  },
  {
    "text": "systems as it quickly scrolled by i just happened to notice that one of them had fewer directories and all the rest and",
    "start": "709040",
    "end": "715760"
  },
  {
    "text": "closer inspection revealed that one of them had the slash kind directory i remember thinking why like",
    "start": "715760",
    "end": "722160"
  },
  {
    "text": "after executing in and poking around i realized the containers root was mounted from the nodes root file system which",
    "start": "722160",
    "end": "728079"
  },
  {
    "text": "was completely unexpected despite dozens of reruns though i really had a hard time replicating",
    "start": "728079",
    "end": "735120"
  },
  {
    "text": "this makes sense because race conditions are a notorious pain to exploit they're finicky and they take a long",
    "start": "735120",
    "end": "741360"
  },
  {
    "text": "time you don't always get them you have to keep trying and you have to wait sometimes it can be hard to tell if you",
    "start": "741360",
    "end": "746959"
  },
  {
    "text": "even won the race successfully and then when you have to do it again they can be hard to reproduce",
    "start": "746959",
    "end": "752560"
  },
  {
    "text": "yeah it was quite irritating knowing that the race could be won but reliability was still elusive but a big",
    "start": "752560",
    "end": "758079"
  },
  {
    "text": "reason for that was it didn't behave at all how we originally thought so the first thing i wanted to do was",
    "start": "758079",
    "end": "763680"
  },
  {
    "text": "share the fun and make sure that everyone else could replicate so i updated the hackmd with the smallest",
    "start": "763680",
    "end": "768800"
  },
  {
    "text": "possible working manifest and a little bit of instructions so what we had here was a talk to",
    "start": "768800",
    "end": "774639"
  },
  {
    "text": "vulnerability now a talk to vulnerability is a class of software bug caused by a race condition involving the",
    "start": "774639",
    "end": "781120"
  },
  {
    "text": "checking of the state of a part of a system such as in this case sanitizing a path and the use of the results of that",
    "start": "781120",
    "end": "787040"
  },
  {
    "text": "check what exactly does that mean here well there is a check which happens during the container startup when",
    "start": "787040",
    "end": "793279"
  },
  {
    "text": "volumes are mounted into that container to ensure that the file system path is one which is allowed to be there",
    "start": "793279",
    "end": "799200"
  },
  {
    "text": "what our exploit is doing was hitting a timing vulnerability which occurs between when the run c path sanitization",
    "start": "799200",
    "end": "805200"
  },
  {
    "text": "is done and when we overwrite the path with a sim link in the volume of the first container and then mount that",
    "start": "805200",
    "end": "810959"
  },
  {
    "text": "volume into a subsequent container in the same pod when we win the race our path points to the host root file system",
    "start": "810959",
    "end": "819200"
  },
  {
    "text": "so i was able to reproduce the work that brad had had been able to do and so now we actually had a few of us able to",
    "start": "822639",
    "end": "828240"
  },
  {
    "text": "reproduce it and i decided to start kind of working on a script that would enable us to uh use",
    "start": "828240",
    "end": "834160"
  },
  {
    "text": "uh to to bring this exploit to other environments and prove that this thing would work because so far as you saw in",
    "start": "834160",
    "end": "839920"
  },
  {
    "text": "or as brad had mentioned the way he determined the success criteria was that he could say the kind directory mounted",
    "start": "839920",
    "end": "845760"
  },
  {
    "text": "on the underlying host and we needed it we needed to come up with something a little bit more portable so i'm going to",
    "start": "845760",
    "end": "851360"
  },
  {
    "text": "walk you through the the um the manifest here and then we'll talk about uh exactly how we determined our",
    "start": "851360",
    "end": "857920"
  },
  {
    "text": "success criteria and that sort of stuff so one of the first problems that we ran into was um",
    "start": "857920",
    "end": "863360"
  },
  {
    "text": "that the the image polls were starting to add up too much against like um against docker and the accounts that we",
    "start": "863360",
    "end": "869519"
  },
  {
    "text": "were using and this was right around the time the docker made the change in um in the uh the amount of image pools you",
    "start": "869519",
    "end": "877040"
  },
  {
    "text": "can actually get as a single endpoint so what we decided to do was create a daemon set that would cache our image",
    "start": "877040",
    "end": "882720"
  },
  {
    "text": "the nginx stable image on all nodes and then we would wait for that daemon set to land and be successful before",
    "start": "882720",
    "end": "889440"
  },
  {
    "text": "deploying a the deployment the deployment actually holds the um",
    "start": "889440",
    "end": "894880"
  },
  {
    "text": "holds the bits that we're going to use to actually try and recreate this tactile attack",
    "start": "894880",
    "end": "900480"
  },
  {
    "text": "so this is made up this deployment is made up of four containers and the first container is again you're mounting up",
    "start": "900480",
    "end": "906240"
  },
  {
    "text": "and the nginx stable image we have the image pull policy set to never and this way we can avoid that um limitation of",
    "start": "906240",
    "end": "913120"
  },
  {
    "text": "the docker registry it's because we're just going to use the engine x staple that's located right",
    "start": "913120",
    "end": "918480"
  },
  {
    "text": "there on disk laid down by the daemon set and then what we're doing inside of that image is we're starting up a bash shell and we're",
    "start": "918480",
    "end": "924720"
  },
  {
    "text": "passing the following right we're moving into a directory that has been mounted from an empty deer volume that we named",
    "start": "924720",
    "end": "931279"
  },
  {
    "text": "hunk and then we'd go into a wild true loop so where we're just constantly deleting",
    "start": "931279",
    "end": "936800"
  },
  {
    "text": "a file if it caught if it exists called host and and then sim linking the root file",
    "start": "936800",
    "end": "942800"
  },
  {
    "text": "system over that file right and so the intention is that if we're successful then we we should be",
    "start": "942800",
    "end": "948959"
  },
  {
    "text": "able to see that we file system but we'll see how it shakes out the subsequent containers are named one",
    "start": "948959",
    "end": "954800"
  },
  {
    "text": "honk two honk three hunk and these containers are basically mounting up and sleeping forever they mount that honk",
    "start": "954800",
    "end": "961360"
  },
  {
    "text": "volume and then they mount another another volume on top of that and empty their volume called host",
    "start": "961360",
    "end": "967360"
  },
  {
    "text": "and this is the thing that we're deleting and overwriting with that sim link and so the timing attack is exactly",
    "start": "967360",
    "end": "972560"
  },
  {
    "text": "that we're just trying to you know for every for these three containers and every one of the replicas that's part of",
    "start": "972560",
    "end": "977839"
  },
  {
    "text": "this deployment we're going to be trying to get that and here is the logic of the script here right so what we're doing is we do a",
    "start": "977839",
    "end": "985680"
  },
  {
    "text": "we pull a list of all of the running pods that are not in a terminated state we sort them by creation timestamp",
    "start": "985680",
    "end": "993920"
  },
  {
    "text": "and then we iterate through them doing this check and this was probably this is the most",
    "start": "993920",
    "end": "999040"
  },
  {
    "text": "portable way that we could figure out how to do this because it would work regardless of whether you were using coming in as root or as a user and what",
    "start": "999040",
    "end": "1005519"
  },
  {
    "text": "it's doing is we're executing into that pod we're counting the number of process ids that we see under the proc file",
    "start": "1005519",
    "end": "1011839"
  },
  {
    "text": "system and if it's more than five then we have a success and if it is less than",
    "start": "1011839",
    "end": "1017279"
  },
  {
    "text": "five then we delete that pod and the replica set controller replaces that pod and then as we work through the entire",
    "start": "1017279",
    "end": "1023920"
  },
  {
    "text": "loop we'll be able to continue just to harvest pods and have a pool of pods until we actually find a successful x-play",
    "start": "1023920",
    "end": "1031438"
  },
  {
    "text": "um this success criteria is in itself pretty telling and we're going to get to play with that here in the demo but like",
    "start": "1031439",
    "end": "1038400"
  },
  {
    "text": "we know that we're successful because we can see more pids on the pid file system than we should be",
    "start": "1038400",
    "end": "1045120"
  },
  {
    "text": "able to see this will be a fun one to explore",
    "start": "1045120",
    "end": "1050839"
  },
  {
    "text": "okay so let's see this in action so for this specific portable script",
    "start": "1052400",
    "end": "1058400"
  },
  {
    "text": "that duffy just went into great detail on we need create daemon sets deployments and pods in the default name",
    "start": "1058400",
    "end": "1064720"
  },
  {
    "text": "space of a cluster and in my test environment here i'm just showing you that it's a 1.20.2 although",
    "start": "1064720",
    "end": "1071039"
  },
  {
    "text": "run c which we'll show you here in a second is the most important so we have onenote cluster",
    "start": "1071039",
    "end": "1078320"
  },
  {
    "text": "running no special workloads this is just the base installation and so the worker nodes this is",
    "start": "1078320",
    "end": "1084720"
  },
  {
    "text": "something you can do on your system in your environment is run a run c dash dash version",
    "start": "1084720",
    "end": "1090640"
  },
  {
    "text": "what you want to see is 1.0.0 rc 95 or later or 1.01",
    "start": "1090640",
    "end": "1097679"
  },
  {
    "text": "if you see rc 94 or lower you're likely affected",
    "start": "1097679",
    "end": "1104000"
  },
  {
    "text": "so what we're going to do is we're going to run that script that duffy just showed you i'm going to pipe it to 10 replicas because i'm running on a single",
    "start": "1106559",
    "end": "1112559"
  },
  {
    "text": "node cluster and what it's doing is it's creating that daemon set so that it caches that nginx stable image",
    "start": "1112559",
    "end": "1119280"
  },
  {
    "text": "and then goes and deploys that honk deployment with the number of replicas that we talked about and the more replicas you have the greater chances",
    "start": "1119280",
    "end": "1126000"
  },
  {
    "text": "you have for success uh and the more opportunities the race can be won and what we're doing is that last bit of",
    "start": "1126000",
    "end": "1132400"
  },
  {
    "text": "logic duffy shows we're walking through and we're checking the number of pids in each one of them and if it says nope",
    "start": "1132400",
    "end": "1138720"
  },
  {
    "text": "we're fewer than five if there's more than five it'll show success so",
    "start": "1138720",
    "end": "1143840"
  },
  {
    "text": "we're just gonna sit here and basically wait until it succeeds",
    "start": "1143840",
    "end": "1149960"
  },
  {
    "text": "this is a fun one also because like um in this case we're using mini cube to test it but i remember when we first",
    "start": "1152559",
    "end": "1157760"
  },
  {
    "text": "found it we were like is this an artifact of of having found this vulnerability in kind or is this",
    "start": "1157760",
    "end": "1163360"
  },
  {
    "text": "actually like or did we actually find the one that is in run c",
    "start": "1163360",
    "end": "1168559"
  },
  {
    "text": "yeah it uh tended to land i don't know my testing i think the quickest was",
    "start": "1168559",
    "end": "1173679"
  },
  {
    "text": "three but i've had land uh you know 120 some attempts somewhere in those ranges",
    "start": "1173679",
    "end": "1180240"
  },
  {
    "text": "yeah those there was a wide range and sometimes you just leave it for hours and you'd come back and go i got one",
    "start": "1180240",
    "end": "1185840"
  },
  {
    "text": "and other times you'd be like you'd look away and suddenly oh i've got one and sometimes you just don't yeah yeah yeah absolutely run the whole",
    "start": "1185840",
    "end": "1193120"
  },
  {
    "text": "way in nothing i think file system churn has a play in it too like if there's more file system",
    "start": "1193120",
    "end": "1199200"
  },
  {
    "text": "churn happening on the underlying node then i feel like it's a little bit more successful",
    "start": "1199200",
    "end": "1204799"
  },
  {
    "text": "yeah it's i remember leaving it run if it got past 500 we're pretty pretty sure that it wasn't",
    "start": "1204799",
    "end": "1211520"
  },
  {
    "text": "going to happen",
    "start": "1211520",
    "end": "1214000"
  },
  {
    "text": "tricky proving a negative so",
    "start": "1216799",
    "end": "1222080"
  },
  {
    "text": "oh nice all right",
    "start": "1222080",
    "end": "1227520"
  },
  {
    "text": "i'm just going to run this uh cube control exec and we're going to exec into",
    "start": "1227520",
    "end": "1232799"
  },
  {
    "text": "this pod what i want to show you is that if we run a hostname we're still inside",
    "start": "1232799",
    "end": "1238320"
  },
  {
    "text": "the pod we're still inside the container so uh we're not quite there yet it's a little bit weird i'll explain that why",
    "start": "1238320",
    "end": "1245120"
  },
  {
    "text": "why that is in a second we're in the containers network namespace so this is the pods interface",
    "start": "1245120",
    "end": "1252400"
  },
  {
    "text": "but because we have access to the root file system and we're reading out a proc we can see",
    "start": "1252400",
    "end": "1257679"
  },
  {
    "text": "basically that's what ps is reading from we can see all of the pids so let's kill",
    "start": "1257679",
    "end": "1262880"
  },
  {
    "text": "a pick uh one of these sleep infinities",
    "start": "1262880",
    "end": "1268400"
  },
  {
    "text": "we actually can't kill it because we're not in the host's process name space although we are root",
    "start": "1268400",
    "end": "1273679"
  },
  {
    "text": "but because because of that it doesn't really mean we're fully limited we have root",
    "start": "1273679",
    "end": "1279039"
  },
  {
    "text": "access to the file system read write access to the file system there are plenty of things that we can do",
    "start": "1279039",
    "end": "1284159"
  },
  {
    "text": "one of the things that we can do because we know we're in a kubernetes cluster is leverage the",
    "start": "1284159",
    "end": "1290480"
  },
  {
    "text": "secrets that are attached to the let me let me scroll back up so",
    "start": "1290480",
    "end": "1296480"
  },
  {
    "text": "you can see that command we could do a find here and we can look at all the tokens and the secrets that are mounted to pods",
    "start": "1296480",
    "end": "1302720"
  },
  {
    "text": "running on this node so we could do this you know multiple times across multiple nodes and attempt to steal all the",
    "start": "1302720",
    "end": "1308880"
  },
  {
    "text": "tokens in the cluster so that's that that's pretty dangerous you might have a cluster admin uh bound",
    "start": "1308880",
    "end": "1314159"
  },
  {
    "text": "token there in the first go the other thing we could do is get the kublet to run a workload for us and this",
    "start": "1314159",
    "end": "1321120"
  },
  {
    "text": "is how minicube is is running the the kubernetes components itself but it'd be very easy to put a privileged host path",
    "start": "1321120",
    "end": "1327600"
  },
  {
    "text": "pod right here and have the kubelet run it as a full route user",
    "start": "1327600",
    "end": "1333679"
  },
  {
    "text": "if you're a pen tester and you want to leave a backdoor access you could add yourself to the root's",
    "start": "1333679",
    "end": "1339840"
  },
  {
    "text": "authorized keys and get in that way that's a nice one quick one but also we know",
    "start": "1339840",
    "end": "1346720"
  },
  {
    "text": "that we're running potentially docker if this command succeeds",
    "start": "1346720",
    "end": "1352559"
  },
  {
    "text": "yup we have access to the docker socket so we're just one step away from being able to get full access to",
    "start": "1352559",
    "end": "1358960"
  },
  {
    "text": "the node and what do i mean by full access to the node i'm going to run a utility called mi",
    "start": "1358960",
    "end": "1364000"
  },
  {
    "text": "contained written originally by jess frisell and we could see here that we have some",
    "start": "1364000",
    "end": "1370240"
  },
  {
    "text": "capabilities but we have several block syscalls so this is enumerating what access i have am i contained yes i'm",
    "start": "1370240",
    "end": "1375679"
  },
  {
    "text": "running in docker but what what sys calls do i have what are potentially blocked",
    "start": "1375679",
    "end": "1381520"
  },
  {
    "text": "okay like i said we're one command away",
    "start": "1381520",
    "end": "1388159"
  },
  {
    "text": "via a docker run so let me paste this in so we're going to run a privileged container in the host's network name",
    "start": "1388159",
    "end": "1393760"
  },
  {
    "text": "space the hostpid namespace we're going to mount the root volume again but inside the",
    "start": "1393760",
    "end": "1399360"
  },
  {
    "text": "this container as host but then we're going to root right into it and run a bash shell so this is effectively like",
    "start": "1399360",
    "end": "1404880"
  },
  {
    "text": "give me the full access please now when we run hostname we can see yep",
    "start": "1404880",
    "end": "1410320"
  },
  {
    "text": "it's minicube we look at all the interfaces you can see all the interfaces of all",
    "start": "1410320",
    "end": "1415440"
  },
  {
    "text": "the containers and if we do run a psef we can still see all the processes but we can kill a",
    "start": "1415440",
    "end": "1421200"
  },
  {
    "text": "process here if we want to i'm not going to just in case i kill the wrong one",
    "start": "1421200",
    "end": "1426640"
  },
  {
    "text": "but i'm going to rerun am i contained okay",
    "start": "1426880",
    "end": "1432960"
  },
  {
    "text": "this time yes we technically are running inside of docker but we have full capabilities we have cisad and then you",
    "start": "1432960",
    "end": "1438559"
  },
  {
    "text": "know all the other things that we need to do the damage and so that proves here that you know we have the ability to",
    "start": "1438559",
    "end": "1444640"
  },
  {
    "text": "leverage this to make a full node takeover",
    "start": "1444640",
    "end": "1448720"
  },
  {
    "text": "this was wild and frankly really alarming to us because this exploit as it appears in",
    "start": "1452240",
    "end": "1458000"
  },
  {
    "text": "our poc appears to give the exploited pod read write access to the host file system and a view of the hostpit",
    "start": "1458000",
    "end": "1463679"
  },
  {
    "text": "namespace it's not a complete view we can't kill processes directly but we could harvest environment variables and",
    "start": "1463679",
    "end": "1469919"
  },
  {
    "text": "interact with the root file system as the root user in the demo we leveraged that access of the docker socket to get us to full root",
    "start": "1469919",
    "end": "1476880"
  },
  {
    "text": "we also learned during testing that this exploit is still successful even when you're not running the attack containers as root the exploit still works because",
    "start": "1476880",
    "end": "1484320"
  },
  {
    "text": "run c is following the sim link but the access to the file system is limited to that user but because that's enough",
    "start": "1484320",
    "end": "1490240"
  },
  {
    "text": "access to list all the other user ids on the node we can rerun the attack for each of those user ids and get their",
    "start": "1490240",
    "end": "1496080"
  },
  {
    "text": "access one at a time if any of those non-views users have passwordless pseudo full root access is",
    "start": "1496080",
    "end": "1501919"
  },
  {
    "text": "still possible i mentioned to my co-chair tabby sable what we were up to who got curious as we",
    "start": "1501919",
    "end": "1507919"
  },
  {
    "text": "saw in the demo we have the root s fs and the pid namespace and tabby wanted to know what was up with the pid",
    "start": "1507919",
    "end": "1513360"
  },
  {
    "text": "namespace so tabby reached out to duffy with technical questions and they dug in a bit in a side exploration",
    "start": "1513360",
    "end": "1521039"
  },
  {
    "text": "yeah that was a that was a fun chat with tabby we we spent some time like trying to dig through and understand like what",
    "start": "1521039",
    "end": "1526720"
  },
  {
    "text": "name spaces we're a part of and like what name spaces we weren't a part of and really it it seems at the end of the",
    "start": "1526720",
    "end": "1532240"
  },
  {
    "text": "day to be quite simple right like that that attack that we saw in the deployment and also that we've covered a",
    "start": "1532240",
    "end": "1538240"
  },
  {
    "text": "couple of different times um what we're actually doing is just basically mounting a view of the root",
    "start": "1538240",
    "end": "1543520"
  },
  {
    "text": "files the root file root file system directly into the container's file system and because of",
    "start": "1543520",
    "end": "1549440"
  },
  {
    "text": "the pivot root system call and the way that that functions um that becomes kind of your new route so effectively when",
    "start": "1549440",
    "end": "1556480"
  },
  {
    "text": "you exec into that new exploited container you're kind of shooting right into that file system as it is presented",
    "start": "1556480",
    "end": "1563120"
  },
  {
    "text": "to run c because run c is the thing that is run c is the context from which root is",
    "start": "1563120",
    "end": "1569520"
  },
  {
    "text": "mounted at that point right it's a binary running in the root file system of the underlying node and when you said",
    "start": "1569520",
    "end": "1574559"
  },
  {
    "text": "to make a sim link of the root file system into that volume that's exactly what it did and it",
    "start": "1574559",
    "end": "1579760"
  },
  {
    "text": "and so the interesting part is like when you do ps minus cf you see all those pids but you're really just reading from",
    "start": "1579760",
    "end": "1584960"
  },
  {
    "text": "the file system mount of proc it's like process mounted over your file system it's not the pid",
    "start": "1584960",
    "end": "1591440"
  },
  {
    "text": "namespace which is why we can't kill processes so it's one of those interesting explorations into capabilities and",
    "start": "1591440",
    "end": "1597679"
  },
  {
    "text": "things yeah about week about a week later etienne released his poc blog post",
    "start": "1597679",
    "end": "1603760"
  },
  {
    "text": "publicly which included his fully detailed exploit code and a full write-up and that's when we learned that ian's early understanding of the issue",
    "start": "1603760",
    "end": "1610720"
  },
  {
    "text": "was on our approach ended up being similar but it ended up with a very different outcome",
    "start": "1610720",
    "end": "1616480"
  },
  {
    "text": "in etienne's approach it leveraged a small binary to do the sim link swapping so a custom image was needed but it",
    "start": "1616480",
    "end": "1622159"
  },
  {
    "text": "tended to win the race a bit quicker it meant you could mount an arbitrary path from the node's file system inside the",
    "start": "1622159",
    "end": "1627840"
  },
  {
    "text": "container in a sub directory in our approach the manifest itself was a lot simpler as we just used bash to do the",
    "start": "1627840",
    "end": "1634240"
  },
  {
    "text": "sim link swapping but we ended up with the node's root file system mounted as the containers",
    "start": "1634240",
    "end": "1639679"
  },
  {
    "text": "ours tends to take a bit longer to win the race but the manifest was crafted in such a way that it didn't require a",
    "start": "1639679",
    "end": "1645039"
  },
  {
    "text": "custom image i mean we used nginx stable but it could be any other base image that had the base linux utilities in it",
    "start": "1645039",
    "end": "1651520"
  },
  {
    "text": "and it would be accepted by mission control aside from running as the root user to make that quick path to root",
    "start": "1651520",
    "end": "1657440"
  },
  {
    "text": "yeah so we tested this on various clouds and distributions to see what had or had not been patched breaking it down and",
    "start": "1657440",
    "end": "1663679"
  },
  {
    "text": "dividing up the work amongst all of us one unusual thing we did notice during testing is that despite having a run c",
    "start": "1663679",
    "end": "1670159"
  },
  {
    "text": "version which should have been affected we couldn't get the exploit to work using amazon's eks distribution with the",
    "start": "1670159",
    "end": "1675760"
  },
  {
    "text": "latest ami this provoked a bit of head scratching but doing some research into the error messages we were getting and also",
    "start": "1675760",
    "end": "1682240"
  },
  {
    "text": "reading etienne's original disclosure which we'd received by that time led us to realize that amazon had put in a",
    "start": "1682240",
    "end": "1687919"
  },
  {
    "text": "mitigation in place by back porting the security fix without updating the run c version number",
    "start": "1687919",
    "end": "1694000"
  },
  {
    "text": "in general this is something you need to watch for when you're doing vulnerability research and assessment as back porting security patches is a",
    "start": "1694000",
    "end": "1700240"
  },
  {
    "text": "technique used by quite a few vendors it's also something you might want to watch out for if you're trying to figure",
    "start": "1700240",
    "end": "1705840"
  },
  {
    "text": "out if you've mitigated as an end user because the version number might not actually tell you for sure sure so when",
    "start": "1705840",
    "end": "1712480"
  },
  {
    "text": "we were testing these things we used the scientific method we broke down the different cloud providers different",
    "start": "1712480",
    "end": "1718399"
  },
  {
    "text": "versions of things they were running and we tried them all to see if our hypothesis held and what we found was",
    "start": "1718399",
    "end": "1723840"
  },
  {
    "text": "that a lot of large clouds were vulnerable a lot of default installs of major cloud provider services were exploitable",
    "start": "1723840",
    "end": "1730799"
  },
  {
    "text": "and we realized that this problem was really quite widespread and likely a lot of cluster operators and end users were",
    "start": "1730799",
    "end": "1735840"
  },
  {
    "text": "going to be at risk so to reiterate we knew this exploit was a complete node takeover we knew it even",
    "start": "1735840",
    "end": "1742480"
  },
  {
    "text": "could be when you weren't running that container as root and we knew that it wasn't patched in a lot of places this",
    "start": "1742480",
    "end": "1748080"
  },
  {
    "text": "was concerning while we still weren't quite sure why this exploit worked the way it did it was clear that it did and",
    "start": "1748080",
    "end": "1754000"
  },
  {
    "text": "it was bigger and nastier we thought then maybe we or maybe even other people had",
    "start": "1754000",
    "end": "1759279"
  },
  {
    "text": "originally thought i was growing increasingly concerned about this about the impact this thing",
    "start": "1759279",
    "end": "1764399"
  },
  {
    "text": "might have how many people might be at risk for it and the response so far had been honestly far more nonchalant than i",
    "start": "1764399",
    "end": "1770799"
  },
  {
    "text": "thought it needed to be um vendors didn't seem to be terribly concerned about being quick to patch",
    "start": "1770799",
    "end": "1776559"
  },
  {
    "text": "this thing and a lot of end users might not even know that it existed so what were we going to do about this",
    "start": "1776559",
    "end": "1782720"
  },
  {
    "text": "we figured honestly it might be kind of up to us we needed to be the ones to help bring",
    "start": "1782720",
    "end": "1788240"
  },
  {
    "text": "more information to users and to the ecosystem as i said earlier be the change we wish to see so",
    "start": "1788240",
    "end": "1794480"
  },
  {
    "text": "we reached out and disclosed this to the kubernetes security response to committee um expressing that we thought",
    "start": "1794480",
    "end": "1800399"
  },
  {
    "text": "this vulnerability scope might be bigger than we had originally thought and that we thought maybe more of a response",
    "start": "1800399",
    "end": "1807279"
  },
  {
    "text": "might be needed and the src actually responded really well they responded right away understanding",
    "start": "1807279",
    "end": "1813919"
  },
  {
    "text": "our concerns and encouraged us to write a blog post on the kubernetes blog about it here toward",
    "start": "1813919",
    "end": "1819520"
  },
  {
    "text": "end users with mitigation advice we did write this but it took a while to get published because as it turns out that",
    "start": "1819520",
    "end": "1826399"
  },
  {
    "text": "work around this vulnerability ended up being ongoing so the src also besides talking to us",
    "start": "1826399",
    "end": "1833760"
  },
  {
    "text": "about that talk amongst themselves and a group of people from google then went",
    "start": "1833760",
    "end": "1839039"
  },
  {
    "text": "and continued this work looking into this vulnerability and why exactly it was doing this thing it was doing",
    "start": "1839039",
    "end": "1844640"
  },
  {
    "text": "so they continued the research and building upon our work they found more",
    "start": "1844640",
    "end": "1849679"
  },
  {
    "text": "um looking at our work leveraging subpath mounts they continued going down that path and what they ended up finding was",
    "start": "1849679",
    "end": "1856399"
  },
  {
    "text": "a completely new cve which was a vulnerability in the kublet cve",
    "start": "1856399",
    "end": "1862840"
  },
  {
    "text": "2021-25741 um this had a cvss score of 8.8 making it the second most severe",
    "start": "1862840",
    "end": "1868480"
  },
  {
    "text": "computer or oh my goodness the second most severe kubernetes vulnerability to date",
    "start": "1868480",
    "end": "1874640"
  },
  {
    "text": "um that exploit was released last month or at least the vulnerability was",
    "start": "1874640",
    "end": "1881519"
  },
  {
    "text": "um the uh in the advisory for that vulnerability fabricio vosnika and mark",
    "start": "1881519",
    "end": "1888159"
  },
  {
    "text": "walters from google um shouted us out and said that they thanked sekong for the thorough security research that led",
    "start": "1888159",
    "end": "1894640"
  },
  {
    "text": "to them discovering this new vulnerability we think that there's a lot to be learned from this story",
    "start": "1894640",
    "end": "1901200"
  },
  {
    "text": "we think that we all if we work together can level each other up at the end of the day this talk is about",
    "start": "1901200",
    "end": "1907200"
  },
  {
    "text": "working together coming together as a community and building upon each other's work so that we can",
    "start": "1907200",
    "end": "1912960"
  },
  {
    "text": "figure out more find more that's going on bring better information to end users",
    "start": "1912960",
    "end": "1918080"
  },
  {
    "text": "and make the ecosystem as a whole more secure we think there's a lot to be learned from this and we hope that we can all",
    "start": "1918080",
    "end": "1924240"
  },
  {
    "text": "continue to do that yeah absolutely the thing i took away from the story was just the sheer complexity of the cloud native ecosystem",
    "start": "1924240",
    "end": "1931360"
  },
  {
    "text": "both in terms of the vertical stack of software that's used when running kubernetes and also the breadth of options available and how it makes it",
    "start": "1931360",
    "end": "1937919"
  },
  {
    "text": "hard for both researchers and cluster operators to understand where vulnerabilities lie and how they might",
    "start": "1937919",
    "end": "1943360"
  },
  {
    "text": "impact their security i think it's an important consideration for the community to keep focusing on communications and making sure that",
    "start": "1943360",
    "end": "1949679"
  },
  {
    "text": "security information is as clear as possible especially to users who may not spend all their time spelunking around",
    "start": "1949679",
    "end": "1955440"
  },
  {
    "text": "projects like we do yeah for me there are a couple things that are worth sharing about this journey first the appreciation of being",
    "start": "1955440",
    "end": "1962159"
  },
  {
    "text": "able to work in a team where we all get to lean on each other's unique perspectives and abilities and we all provide full encouragement of all",
    "start": "1962159",
    "end": "1968880"
  },
  {
    "text": "honking activities we got a little bit lucky sure but without that level of effective collaboration i could easily imagine a",
    "start": "1968880",
    "end": "1975440"
  },
  {
    "text": "scenario where we didn't overcome the confusing or frustrating parts and there were plenty of those",
    "start": "1975440",
    "end": "1980559"
  },
  {
    "text": "and lastly knowing that this team effort raised more awareness of the vulnerability and helped the main goal",
    "start": "1980559",
    "end": "1985679"
  },
  {
    "text": "of getting vendors to release patches to end users quicker i think that brings us all a lot of satisfaction",
    "start": "1985679",
    "end": "1993200"
  },
  {
    "text": "all of us played a part in this and it was really fun to explore an interesting new talk together",
    "start": "1994240",
    "end": "1999360"
  },
  {
    "text": "here is a slide with reference material and it will take you to the links for the same link",
    "start": "1999360",
    "end": "2004480"
  },
  {
    "text": "script that we wrote the wrote it'll take you to our hackmd notes that we originally gathered context with and",
    "start": "2004480",
    "end": "2010559"
  },
  {
    "text": "it'll also show you the um the cbe documentation for a couple of the both etiennes and also the one that",
    "start": "2010559",
    "end": "2017440"
  },
  {
    "text": "ian referred to uh oh and uh one more thing",
    "start": "2017440",
    "end": "2023679"
  },
  {
    "text": "haunt the planet thanks everybody thank you everyone",
    "start": "2023679",
    "end": "2029600"
  },
  {
    "text": "we're gonna present this slide in the in the slack chat as well um we're going to be here to answer your questions and you",
    "start": "2029600",
    "end": "2035600"
  },
  {
    "text": "might see a couple of us roaming around the halls at our kubecon so see you all next time",
    "start": "2035600",
    "end": "2043480"
  },
  {
    "text": "[Music]",
    "start": "2045440",
    "end": "2051358"
  },
  {
    "text": "you",
    "start": "2051359",
    "end": "2053440"
  }
]
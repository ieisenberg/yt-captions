[
  {
    "start": "0",
    "end": "23000"
  },
  {
    "text": "hi everybody I hope you're all having a great conference thank you for coming to",
    "start": "860",
    "end": "6120"
  },
  {
    "text": "my talk about Tam land or how goodlab.com uses long-term monitoring data for capacity forecasting my name is",
    "start": "6120",
    "end": "13200"
  },
  {
    "text": "Andrew nudigatz I'm a distinguished engineer in the infrastructure departments at gitlab where I focus on",
    "start": "13200",
    "end": "18840"
  },
  {
    "text": "gitlab.com let's start with a bit of a backstory",
    "start": "18840",
    "end": "24439"
  },
  {
    "start": "23000",
    "end": "23000"
  },
  {
    "text": "this Story begins in mid 2021 gitlab.com experienced a series of S1 database",
    "start": "24539",
    "end": "31140"
  },
  {
    "text": "incidents related to high resource utilization on our primary postgres cluster",
    "start": "31140",
    "end": "37320"
  },
  {
    "text": "within the company concerns were raised about the growth rate of gitlab.com and the ability of our primary database to",
    "start": "37320",
    "end": "44460"
  },
  {
    "text": "support this growth if the database hit maximum capacity it might lead to further outages due to saturation issues",
    "start": "44460",
    "end": "53719"
  },
  {
    "text": "vertically scaling the main postgres cluster was no longer an option it was generally agreed that the way",
    "start": "54960",
    "end": "61920"
  },
  {
    "text": "forward would be to split up the main postgres database into more than one cluster",
    "start": "61920",
    "end": "68159"
  },
  {
    "text": "since a large proportion of our database traffic is related to CI it was decided",
    "start": "68159",
    "end": "73380"
  },
  {
    "text": "to move this feature to a second postgres cluster through a process we called functional decomposition",
    "start": "73380",
    "end": "80299"
  },
  {
    "text": "this would be a complicated project spanning months the fact that we wanted to keep the",
    "start": "80299",
    "end": "86280"
  },
  {
    "text": "application running while migrating a huge volume of data to a new cluster made it even more complex",
    "start": "86280",
    "end": "93080"
  },
  {
    "text": "a plan was devised and a date set for the completion of the migration but",
    "start": "93080",
    "end": "98100"
  },
  {
    "text": "valid concerns were raised about whether given the recent space of postgres incidents the primary database could",
    "start": "98100",
    "end": "105060"
  },
  {
    "text": "continue to support the growth we expected to see until the functional decomposition project was delivered",
    "start": "105060",
    "end": "112159"
  },
  {
    "text": "one option would be to bring the project delivery dates forward but doing so would add additional risk to the project",
    "start": "112159",
    "end": "118640"
  },
  {
    "text": "forcing Corners to be cut and possibly leading to further instability",
    "start": "118640",
    "end": "124939"
  },
  {
    "text": "it would be much better if we could confirm that the database would have sufficient capacity allowing us to stick",
    "start": "125360",
    "end": "132360"
  },
  {
    "text": "to the original date giving the take that giving the team the space to carry out the migration with due caution",
    "start": "132360",
    "end": "139860"
  },
  {
    "text": "we needed an accurate and data-driven assessment of the available capacity in our main postgres cluster using a new",
    "start": "139860",
    "end": "147120"
  },
  {
    "text": "tool called tameland we were able to carry out a capacity review with timeland we analyzed all potential",
    "start": "147120",
    "end": "153480"
  },
  {
    "text": "saturation points within the cluster and plotted their individual growth forecasts to predict which if any would",
    "start": "153480",
    "end": "159599"
  },
  {
    "text": "hit saturation we found that if a few small changes were made in the short term we'd have",
    "start": "159599",
    "end": "165959"
  },
  {
    "text": "enough Runway to support the delivery of the functional decomposition over the multi-month time frame the project was",
    "start": "165959",
    "end": "173099"
  },
  {
    "text": "expected to take so it turns out that this is a pretty",
    "start": "173099",
    "end": "179040"
  },
  {
    "text": "boring story as predicted we had enough capacity to perform the migration safely",
    "start": "179040",
    "end": "184379"
  },
  {
    "text": "the migration got completed in time without hitting capacity issues that we had been concerned about and everyone",
    "start": "184379",
    "end": "190860"
  },
  {
    "text": "lived happily ever after but in software infrastructure boring is",
    "start": "190860",
    "end": "196140"
  },
  {
    "text": "normally a good thing the point is that we were able to manage risk around an already risky project and control",
    "start": "196140",
    "end": "203280"
  },
  {
    "text": "uncertainty this is some of the concerns around the project and gave our Executives the",
    "start": "203280",
    "end": "209099"
  },
  {
    "text": "confidence they needed in our project delivery dates I found this quote from a paper called",
    "start": "209099",
    "end": "215340"
  },
  {
    "text": "SRE best practices for capacity management by Louis Casada Torres and Doug kolish and I think it captures the",
    "start": "215340",
    "end": "222420"
  },
  {
    "text": "goal of capacity management really well the goal of capacity management is",
    "start": "222420",
    "end": "227640"
  },
  {
    "text": "controlling uncertainty in the midst of the unknown the service must be available now and continue to run in",
    "start": "227640",
    "end": "233879"
  },
  {
    "text": "future a challenging but rewarding and delicate balance of trade-offs is in play efficiency versus reliability",
    "start": "233879",
    "end": "240680"
  },
  {
    "text": "accuracy versus complexity and effort versus benefits",
    "start": "240680",
    "end": "246739"
  },
  {
    "text": "before I continue I'll Define a few terms that I'm going to use throughout this talk",
    "start": "246959",
    "end": "253459"
  },
  {
    "start": "254000",
    "end": "254000"
  },
  {
    "text": "the first one is the definition of a resource a resource can be anything that can be",
    "start": "255780",
    "end": "261660"
  },
  {
    "text": "consumed and has a limit a lot of capacity planning literature focuses on Hardware resources for example CPU",
    "start": "261660",
    "end": "269040"
  },
  {
    "text": "memory and network bandwidth and these are of course very important examples but there are a lot of other",
    "start": "269040",
    "end": "275660"
  },
  {
    "text": "software-defined resources that are equally important to our capacity planning process some examples include",
    "start": "275660",
    "end": "281580"
  },
  {
    "text": "open file descriptors Cloud quotas and rate limits 32-bit id address space",
    "start": "281580",
    "end": "287639"
  },
  {
    "text": "utilization and SQL tables postgres Auto vacuum utilization Nat Gateway",
    "start": "287639",
    "end": "293400"
  },
  {
    "text": "utilization Global interpreted lock utilization in Ruby database connection pools and CPU thread",
    "start": "293400",
    "end": "301500"
  },
  {
    "text": "utilization redis and node pool size utilization these are all examples of the types of",
    "start": "301500",
    "end": "308400"
  },
  {
    "text": "resources we monitor track and forecast in gitlab.com by combining all of these we're able to",
    "start": "308400",
    "end": "314820"
  },
  {
    "text": "build an accurate capacity forecast for our services",
    "start": "314820",
    "end": "319820"
  },
  {
    "text": "four more terms that we need to Define are the first being utilization now this",
    "start": "321180",
    "end": "326460"
  },
  {
    "text": "should be fairly evident it's a measure of how much of a given resource is being used or consumed at any moment in time",
    "start": "326460",
    "end": "332600"
  },
  {
    "text": "this always has a unit of measure for example open files bytes database",
    "start": "332600",
    "end": "338759"
  },
  {
    "text": "connections Etc capacity is for any given resource the",
    "start": "338759",
    "end": "344400"
  },
  {
    "text": "maximum utilization decibel for example the maximum number of open files that",
    "start": "344400",
    "end": "349560"
  },
  {
    "text": "are processes allowed the total capacity of a disk in bytes or the maximum number",
    "start": "349560",
    "end": "354960"
  },
  {
    "text": "of database connections allowed in a pool utilization percentage is the",
    "start": "354960",
    "end": "360000"
  },
  {
    "text": "utilization expressed as a percentage of the capacity of a resource",
    "start": "360000",
    "end": "366000"
  },
  {
    "text": "finally saturation is what happens when the utilization of a resource nears or",
    "start": "366000",
    "end": "371460"
  },
  {
    "text": "reaches a capacity of that resource in some cases saturation or at least",
    "start": "371460",
    "end": "376560"
  },
  {
    "text": "prolonged saturation will adversely impact the performance of the system for example through increased queuing higher",
    "start": "376560",
    "end": "383699"
  },
  {
    "text": "latencies errors or possibly complete system failure planning for and",
    "start": "383699",
    "end": "389280"
  },
  {
    "text": "hopefully avoiding saturation is the goal of capacity planning foreign",
    "start": "389280",
    "end": "396199"
  },
  {
    "start": "395000",
    "end": "395000"
  },
  {
    "text": "here are some examples of saturation events and the typical times that a full mitigation might take in some cases the",
    "start": "396539",
    "end": "403919"
  },
  {
    "text": "low impact of saturation or the ease of mitigation means that we don't need to focus on these items as a priority in",
    "start": "403919",
    "end": "410580"
  },
  {
    "text": "our capacity planning process for example in kubernetes pod CPU saturation",
    "start": "410580",
    "end": "415680"
  },
  {
    "text": "should be mitigated automatically within minutes by the horizontal pod Auto scaler so it's unnecessary to focus on",
    "start": "415680",
    "end": "423180"
  },
  {
    "text": "these resources in a capacity planning review however there are many other resources",
    "start": "423180",
    "end": "428460"
  },
  {
    "text": "that once they've hit saturation have mitigation time stretching from days to weeks or even months the story I",
    "start": "428460",
    "end": "435419"
  },
  {
    "text": "described earlier about functional decomposition of our postgres cluster is one such example",
    "start": "435419",
    "end": "442380"
  },
  {
    "text": "if one of these resources unexpectedly became saturated it could have a detrimental impact on the availability",
    "start": "442380",
    "end": "448380"
  },
  {
    "text": "of the system for weeks or even months that could mean that requests to the",
    "start": "448380",
    "end": "453419"
  },
  {
    "text": "service start experiencing latency issues or the application could fail completely for example in the case of a",
    "start": "453419",
    "end": "459900"
  },
  {
    "text": "postgres transaction ID wraparound event uh in which reaching saturation will",
    "start": "459900",
    "end": "465120"
  },
  {
    "text": "automatically shut down the database and a disaster recovery operation will need to take place",
    "start": "465120",
    "end": "470699"
  },
  {
    "text": "the goal of our capacity planning process is to focus on Resources with high risk or long mitigation times",
    "start": "470699",
    "end": "479419"
  },
  {
    "text": "let's discuss the general approach that we use to capacity planning on gitlab.com before diving into further",
    "start": "481199",
    "end": "487620"
  },
  {
    "text": "details a lot of capacity planning advice that",
    "start": "487620",
    "end": "492900"
  },
  {
    "start": "490000",
    "end": "490000"
  },
  {
    "text": "I've seen focuses on the system as a whole using demand signals such as monthly active users or requests per",
    "start": "492900",
    "end": "499860"
  },
  {
    "text": "second they talk about the current utilization in times in terms of these signals and the total capacity expressed",
    "start": "499860",
    "end": "507479"
  },
  {
    "text": "in the same terms in other words the current and maximum utilization of the entire system are represented by a",
    "start": "507479",
    "end": "514440"
  },
  {
    "text": "single metric you could call this black box capacity planning in that we treat the capacity as failure opaque with the",
    "start": "514440",
    "end": "523440"
  },
  {
    "text": "with the capacity planning taking place outside the system and a single metric defining the utilization and capacity of",
    "start": "523440",
    "end": "530519"
  },
  {
    "text": "the system in its entirety the difficulty in this type of capacity",
    "start": "530519",
    "end": "536940"
  },
  {
    "text": "planning process is that it requires the maximum utilization capacity of the system to be estimated",
    "start": "536940",
    "end": "544080"
  },
  {
    "text": "there are three common ways of doing this guessing load testing and modeling",
    "start": "544080",
    "end": "549240"
  },
  {
    "text": "let's discuss each the first approach and by far the most",
    "start": "549240",
    "end": "556380"
  },
  {
    "text": "widely used is to guess what the maximum the first approach and by far the most",
    "start": "556380",
    "end": "563399"
  },
  {
    "text": "widely used is to guess what the maximum the first approach and by far the most",
    "start": "563399",
    "end": "569100"
  },
  {
    "text": "widely used is to guess what the maximum utilization capacity of your service is this is known as the back of the",
    "start": "569100",
    "end": "576060"
  },
  {
    "text": "envelope method or even the seat of your pants method it's not scientific and it's not Based",
    "start": "576060",
    "end": "582240"
  },
  {
    "text": "on data only intuition it has many problems it's almost certainly not going",
    "start": "582240",
    "end": "587399"
  },
  {
    "text": "to be correct you can't systematically improve the process behind it so it never gets any better it's not scalable",
    "start": "587399",
    "end": "594360"
  },
  {
    "text": "and you can't automate it this means that you're less likely to carry out capacity planning since it's a manual",
    "start": "594360",
    "end": "600959"
  },
  {
    "text": "process the second approach to determining",
    "start": "600959",
    "end": "606959"
  },
  {
    "start": "604000",
    "end": "604000"
  },
  {
    "text": "utilization capacity is through load testing this is much much better than guessing but this approach also has",
    "start": "606959",
    "end": "613800"
  },
  {
    "text": "several downsides if you're running a large system setting up an appropriately sized test bed can be prohibitively",
    "start": "613800",
    "end": "620220"
  },
  {
    "text": "expensive if possible at all additionally you'll need to create a large custom cluster of clients",
    "start": "620220",
    "end": "627140"
  },
  {
    "text": "additionally you'll need to create a large cluster of clients to generate the workload this adds to the cost and",
    "start": "627140",
    "end": "633660"
  },
  {
    "text": "complexity the second problem is that it's easy to overlook failure modes which may have a",
    "start": "633660",
    "end": "639959"
  },
  {
    "text": "major impact in the real world for example pathological clients generating unexpected workloads possibly due to",
    "start": "639959",
    "end": "646800"
  },
  {
    "text": "abuse or being incorrectly configured building a test Suite to generate an",
    "start": "646800",
    "end": "651899"
  },
  {
    "text": "appropriate workload can be very challenging too",
    "start": "651899",
    "end": "656540"
  },
  {
    "text": "approach is using modeling this approach involves building executable performance models possibly in a spreadsheet Jupiter",
    "start": "657000",
    "end": "664200"
  },
  {
    "text": "notebooks or a regular programming language the model attempts to capture the performance and scalability",
    "start": "664200",
    "end": "669600"
  },
  {
    "text": "characteristics of the system this approach can be very complex additionally it can be very difficult to",
    "start": "669600",
    "end": "676260"
  },
  {
    "text": "validate whether the model is predicting the maximum utilization correctly foreign first approach and by far the",
    "start": "676260",
    "end": "684180"
  },
  {
    "start": "683000",
    "end": "683000"
  },
  {
    "text": "most widely used is to guess what the estimated capacity of their system is this is also known as the back of the",
    "start": "684180",
    "end": "691140"
  },
  {
    "text": "envelope method or even the seed of your pants method it's not scientific and",
    "start": "691140",
    "end": "696180"
  },
  {
    "text": "it's not Based on data only intuition it has many problems",
    "start": "696180",
    "end": "701220"
  },
  {
    "text": "firstly it's almost certainly not going to be correct you can't systematically improve the",
    "start": "701220",
    "end": "707220"
  },
  {
    "text": "process behind it so it never gets any better it's not scalable",
    "start": "707220",
    "end": "712260"
  },
  {
    "text": "and you can't automate it this means that you're less likely to carry out capacity planning since it's a manual",
    "start": "712260",
    "end": "718500"
  },
  {
    "text": "process the second approach is determining capacity through load testing this is",
    "start": "718500",
    "end": "726060"
  },
  {
    "text": "much much better than guessing but this approach also has several downsides you're running a large system setting up",
    "start": "726060",
    "end": "732959"
  },
  {
    "text": "an appropriately sized test bed can be prohibitively expensive if possible at all",
    "start": "732959",
    "end": "738060"
  },
  {
    "text": "additionally you'll need to create a large cluster of clients to generate the workload and this adds to the cost and",
    "start": "738060",
    "end": "744300"
  },
  {
    "text": "the complexity a second problem is that it's easy to overlook failure modes which may have a",
    "start": "744300",
    "end": "750660"
  },
  {
    "text": "major impact in the real world for example pathological clients generating unexpected workloads possibly due to",
    "start": "750660",
    "end": "757140"
  },
  {
    "text": "abuse or being incorrectly configured building a test Suite to generate an appropriate workload can be very",
    "start": "757140",
    "end": "763320"
  },
  {
    "text": "challenging too the third approach is using modeling",
    "start": "763320",
    "end": "768720"
  },
  {
    "start": "765000",
    "end": "765000"
  },
  {
    "text": "this approach involves building executable performance models possibly in a spreadsheet or jupyter notebooks or",
    "start": "768720",
    "end": "775620"
  },
  {
    "text": "a regular programming language the model attempts to capture the performance and scalability characteristics of the",
    "start": "775620",
    "end": "782040"
  },
  {
    "text": "system this approach can also be very complex additionally it can be very difficult to",
    "start": "782040",
    "end": "788700"
  },
  {
    "text": "validate whether the model is predicting the utilization or the maximum utilization correctly",
    "start": "788700",
    "end": "796220"
  },
  {
    "start": "796000",
    "end": "796000"
  },
  {
    "text": "so estimating capacity is really hard to make matters worse the application is",
    "start": "796440",
    "end": "802380"
  },
  {
    "text": "evolving very quickly as is the production environment in a monolithic application such as",
    "start": "802380",
    "end": "807959"
  },
  {
    "text": "gitlab multiple teams may be making changes to the environment and the applications simultaneously making it",
    "start": "807959",
    "end": "814860"
  },
  {
    "text": "even more difficult to control for change additionally experiments are running feature flags are being toggled",
    "start": "814860",
    "end": "820920"
  },
  {
    "text": "and user activity patterns are constantly changing any maximum capacity estimates that are",
    "start": "820920",
    "end": "827459"
  },
  {
    "text": "produced quickly go out of date and lose their meaning constantly lagging behind the true state of the environment",
    "start": "827459",
    "end": "833940"
  },
  {
    "text": "this means that the capacity estimates need to be constantly revised through frequent updates unfortunately none of",
    "start": "833940",
    "end": "840899"
  },
  {
    "text": "the methods for capacity estimation are easy to perform and efficiently automating them is very hard or not",
    "start": "840899",
    "end": "847920"
  },
  {
    "text": "possible the approach that we use on gitlab.com",
    "start": "847920",
    "end": "853260"
  },
  {
    "start": "850000",
    "end": "850000"
  },
  {
    "text": "is closest to modeling however instead of trying to estimate the capacity of the system as a whole and expressing",
    "start": "853260",
    "end": "860220"
  },
  {
    "text": "that using a single demand indicator such as active users we treat each Service as a collection of related",
    "start": "860220",
    "end": "866820"
  },
  {
    "text": "resources and monitor and track them independently so the resources for each",
    "start": "866820",
    "end": "872519"
  },
  {
    "text": "service are treated as a collection of independent but grouped capacity planning metrics",
    "start": "872519",
    "end": "877860"
  },
  {
    "text": "all of these metrics have different growth rates thresholds and periodicity each new change introduced to the system",
    "start": "877860",
    "end": "884399"
  },
  {
    "text": "be it through application changes or infrastructure changes or even user activity will impact the resources",
    "start": "884399",
    "end": "890639"
  },
  {
    "text": "differently we do not attempt to aggregate these resource capacities back into a single",
    "start": "890639",
    "end": "896100"
  },
  {
    "text": "system capacity as this is error-prone and difficult to verify unlike when attempting to estimate total",
    "start": "896100",
    "end": "903300"
  },
  {
    "text": "system capacity estimating the capacity of individual resources is fairly",
    "start": "903300",
    "end": "908399"
  },
  {
    "text": "straightforward for example for disk space the capacity is the disk size for",
    "start": "908399",
    "end": "914399"
  },
  {
    "text": "open file descriptors the capacity is the maximum number of file descriptors and for database connection pools the",
    "start": "914399",
    "end": "920459"
  },
  {
    "text": "capacity is well defined in configuration the biggest downside to this approach is",
    "start": "920459",
    "end": "925920"
  },
  {
    "start": "924000",
    "end": "924000"
  },
  {
    "text": "that we have to track and forecast a lot more metrics but many services share the same types of resources for example many",
    "start": "925920",
    "end": "933959"
  },
  {
    "text": "stateful services will share disk space and inode resource types many ruby-based services will share a",
    "start": "933959",
    "end": "941040"
  },
  {
    "text": "resource metric representing Global interpreter lock utilization we can therefore think of resources and",
    "start": "941040",
    "end": "947760"
  },
  {
    "text": "services as being in a combination Matrix something like what's shown on this slide",
    "start": "947760",
    "end": "954180"
  },
  {
    "text": "the downside to this approach is that instead of having a single utilization that we have to monitor and forecast for",
    "start": "954180",
    "end": "960240"
  },
  {
    "text": "each service we have between 10 10 and 20 per service this generates a lot more data that we",
    "start": "960240",
    "end": "967560"
  },
  {
    "text": "need to manage and perform capacity planning for but luckily this is something that we can automate",
    "start": "967560",
    "end": "973440"
  },
  {
    "text": "to further explain let's dive straight into the implementation as I think this will help illustrate how this approach",
    "start": "973440",
    "end": "979320"
  },
  {
    "text": "works so in order to build a system that can monitor many different types of resource",
    "start": "979320",
    "end": "986339"
  },
  {
    "text": "utilization across different Services we first need to normalize and standardize the resource utilization metrics that we",
    "start": "986339",
    "end": "993420"
  },
  {
    "text": "use we do this by constructing recording rules in Prometheus",
    "start": "993420",
    "end": "999899"
  },
  {
    "start": "995000",
    "end": "995000"
  },
  {
    "text": "all the resource utilization recording rules use the same name gitlab resource",
    "start": "999899",
    "end": "1005540"
  },
  {
    "text": "utilization colon ratio but they have different labels to distinguish them one label for the name of the service and",
    "start": "1005540",
    "end": "1012740"
  },
  {
    "text": "another for the name of the resource each combination of service and resource will have one series",
    "start": "1012740",
    "end": "1018620"
  },
  {
    "text": "the value of these recording rules is between 0 and 1 with 0 being 0",
    "start": "1018620",
    "end": "1023679"
  },
  {
    "text": "utilization and one being a hundred percent utilization in other words at",
    "start": "1023679",
    "end": "1028760"
  },
  {
    "text": "capacity these recording rules are fairly easy to construct for any given resource they",
    "start": "1028760",
    "end": "1036319"
  },
  {
    "start": "1031000",
    "end": "1031000"
  },
  {
    "text": "are simply the current utilization divided by the current capacity here are",
    "start": "1036319",
    "end": "1041360"
  },
  {
    "text": "three examples from the gitlab code base for gcp quota resources we obtain",
    "start": "1041360",
    "end": "1046520"
  },
  {
    "text": "current quota utilization and current limits from gcp quota exporter for",
    "start": "1046520",
    "end": "1051559"
  },
  {
    "text": "Prometheus for open file descriptometrics many Prometheus client libraries",
    "start": "1051559",
    "end": "1056900"
  },
  {
    "text": "automatically publish these metrics out of the box so they're very easy to obtain third example demonstrates how",
    "start": "1056900",
    "end": "1063260"
  },
  {
    "text": "persistent volume claim disk usage can be monitored and using metrics exported by cubelet",
    "start": "1063260",
    "end": "1070419"
  },
  {
    "text": "approach results in a lot of utilization metrics being generated using the open file descriptor",
    "start": "1070520",
    "end": "1076820"
  },
  {
    "text": "utilization metric on gitlab.com there are close to 5 000 series for this at",
    "start": "1076820",
    "end": "1082039"
  },
  {
    "text": "present this is too much data we need to reduce it down by aggregation so that we can",
    "start": "1082039",
    "end": "1088100"
  },
  {
    "text": "have a single representative metric per service resource pair now there are many different ways that",
    "start": "1088100",
    "end": "1093620"
  },
  {
    "text": "we can do this for example we could use an average or quantile but in most cases we find that the best",
    "start": "1093620",
    "end": "1100640"
  },
  {
    "text": "way of aggregating these metrics is by the maximum value this isn't always the case for example",
    "start": "1100640",
    "end": "1107600"
  },
  {
    "text": "for some kubernetes metrics where we might have very high cardinality we might use the 99th percentile removing",
    "start": "1107600",
    "end": "1114500"
  },
  {
    "text": "outlier values however in the majority of resources we",
    "start": "1114500",
    "end": "1119720"
  },
  {
    "text": "aggregate using Max the reason we use this is that highest utilization is the one that leads to",
    "start": "1119720",
    "end": "1126500"
  },
  {
    "text": "saturation and instability in the system for example if you have four servers in",
    "start": "1126500",
    "end": "1132200"
  },
  {
    "text": "a cluster and three of them have very low disk utilization but one of the servers has a disk that's almost full",
    "start": "1132200",
    "end": "1138679"
  },
  {
    "text": "then that's the signal that we want to aggregate the average disk space across the",
    "start": "1138679",
    "end": "1144559"
  },
  {
    "text": "servers is below 50 which seems fine but one of the servers may be close to failure and by using Max we can pick up",
    "start": "1144559",
    "end": "1152120"
  },
  {
    "text": "the worst case for alerting monitoring and forecasting",
    "start": "1152120",
    "end": "1156880"
  },
  {
    "start": "1156000",
    "end": "1156000"
  },
  {
    "text": "taking the same example of open file descriptors as we used previously and aggregating on the max for each servers",
    "start": "1157220",
    "end": "1163700"
  },
  {
    "text": "significantly reduces the volume of data giving us a single signal per service",
    "start": "1163700",
    "end": "1169400"
  },
  {
    "text": "if any service has a process nearing saturation for its open file descriptors resource will have a clear signal of it",
    "start": "1169400",
    "end": "1176240"
  },
  {
    "text": "which we can visualize an alert on each of these resource service",
    "start": "1176240",
    "end": "1181640"
  },
  {
    "text": "combinations has a set of recording rules alert threshold values alerts and grafana dashboards associated with it",
    "start": "1181640",
    "end": "1188059"
  },
  {
    "text": "early on this configuration was hand coded but this soon became unmanageable with too many combinations of resources",
    "start": "1188059",
    "end": "1195200"
  },
  {
    "text": "and services to get around this we migrated to configuration language called jsonnet this allows us to manage",
    "start": "1195200",
    "end": "1201980"
  },
  {
    "text": "a single configuration for each resource including metadata such as documentation or whether or not the resource is",
    "start": "1201980",
    "end": "1208760"
  },
  {
    "text": "horizontally scalable this slide shows an abbreviated example of that configuration",
    "start": "1208760",
    "end": "1214340"
  },
  {
    "text": "we can then validate the configuration before using it to generate all the recording rules and alerts",
    "start": "1214340",
    "end": "1220460"
  },
  {
    "text": "for dashboard generation we use a jsonet library maintained by grafana called grafonet this allows us to generate all",
    "start": "1220460",
    "end": "1227840"
  },
  {
    "text": "our dashboards from the same configuration and ensure that they're always up to date in fact most of the dashboards for",
    "start": "1227840",
    "end": "1234799"
  },
  {
    "text": "gitlab.com are now generated from a graphonic definition",
    "start": "1234799",
    "end": "1240220"
  },
  {
    "text": "this slide shows the main utilization dashboard for a service in this case our",
    "start": "1241640",
    "end": "1246799"
  },
  {
    "text": "primary postgres cluster each of these series represents the worst case for a given type of resource",
    "start": "1246799",
    "end": "1252860"
  },
  {
    "text": "this allows us to quickly review resource utilization across dozens or even hundreds of resources that are",
    "start": "1252860",
    "end": "1259700"
  },
  {
    "text": "being consumed by the service if one of the metrics requires further investigation we can navigate to",
    "start": "1259700",
    "end": "1265760"
  },
  {
    "text": "detailed dashboards that are generated for the resource this is what some of those panels look",
    "start": "1265760",
    "end": "1272179"
  },
  {
    "start": "1270000",
    "end": "1270000"
  },
  {
    "text": "like for each resource we generate a full grafana panel these six resources belong to our main",
    "start": "1272179",
    "end": "1278419"
  },
  {
    "text": "postgres instance once again the aggregated recording rule value is",
    "start": "1278419",
    "end": "1283460"
  },
  {
    "text": "represented by the thick yellow line and the de-aggregated underlying values are visualized alongside those two this",
    "start": "1283460",
    "end": "1291200"
  },
  {
    "text": "allows us to quickly dig down into the source of utilization or saturation issue and determine the problem",
    "start": "1291200",
    "end": "1298340"
  },
  {
    "text": "of course we generate alerts for each utilization metric too generally the alerting threshold for",
    "start": "1298340",
    "end": "1304640"
  },
  {
    "text": "each resource is somewhere below 100 percent the actual alerting threshold depends on",
    "start": "1304640",
    "end": "1310220"
  },
  {
    "text": "the nature of the saturation metric and the way in which it's measured in particular the time period over which",
    "start": "1310220",
    "end": "1315980"
  },
  {
    "text": "samples are collected these thresholds are used for real-time monitoring alerts but also for",
    "start": "1315980",
    "end": "1322400"
  },
  {
    "text": "forecasting capacity issues as we'll see later now that we're collecting utilization",
    "start": "1322400",
    "end": "1329120"
  },
  {
    "text": "data for resources in a normalized form we can start analyzing it over long",
    "start": "1329120",
    "end": "1334400"
  },
  {
    "text": "periods of time looking for trends luckily gitlab.com uses Thanos for",
    "start": "1334400",
    "end": "1340400"
  },
  {
    "start": "1338000",
    "end": "1338000"
  },
  {
    "text": "long-term metric storage this means that all the resource utilization data that we use for short-term monitoring of",
    "start": "1340400",
    "end": "1346640"
  },
  {
    "text": "gitlab.com is retained for several years in object storage",
    "start": "1346640",
    "end": "1352240"
  },
  {
    "text": "here's an example of resource utilization data over a long period showing changes in Trend and a steady",
    "start": "1352419",
    "end": "1359539"
  },
  {
    "text": "growth towards saturation reviewing this data made us confident that we could potentially be using it",
    "start": "1359539",
    "end": "1366440"
  },
  {
    "text": "for forecasting we started looking at how we could leverage this data for planning purposes",
    "start": "1366440",
    "end": "1372380"
  },
  {
    "text": "by forecasting future potential saturation",
    "start": "1372380",
    "end": "1376960"
  },
  {
    "start": "1377000",
    "end": "1377000"
  },
  {
    "text": "our first attempt at forecasting was not a huge success we attempted to use linear regression to predict future",
    "start": "1378500",
    "end": "1384980"
  },
  {
    "text": "growth Prometheus has a predict linear function that we can employ so our first somewhat",
    "start": "1384980",
    "end": "1391820"
  },
  {
    "text": "naive attempt at building a forecasting engine was built on this function since the data could be processed within",
    "start": "1391820",
    "end": "1398240"
  },
  {
    "text": "Thanos this approach was very easy to implement and to experiment with",
    "start": "1398240",
    "end": "1403400"
  },
  {
    "text": "we could see promise in the approach but unfortunately the forecasts were very inaccurate",
    "start": "1403400",
    "end": "1409100"
  },
  {
    "text": "one of the main reasons for this is that linear regressions failed to take seasonality into account in this example",
    "start": "1409100",
    "end": "1415940"
  },
  {
    "text": "the linear regression is able to determine the single long-term growth Trend in the utilization data but fails",
    "start": "1415940",
    "end": "1423080"
  },
  {
    "text": "to take into account weekday Peaks averaging the trend with weekend off peak times",
    "start": "1423080",
    "end": "1429640"
  },
  {
    "text": "any changes in Trend possibly due to application or environment changes are",
    "start": "1429640",
    "end": "1434659"
  },
  {
    "text": "also averaged out into single growth Trend based on the entire historical data set",
    "start": "1434659",
    "end": "1440419"
  },
  {
    "text": "we knew that we would have to go back to the drawing board",
    "start": "1440419",
    "end": "1445360"
  },
  {
    "text": "luckily around this time we became aware of an open source project out of matter called profit it's a library written in",
    "start": "1445460",
    "end": "1452299"
  },
  {
    "text": "r in Python for performing forecasting and predictions it seemed like a much better fit for our purposes than linear",
    "start": "1452299",
    "end": "1458659"
  },
  {
    "text": "regression could ever be and we started experimenting with a proof of concept",
    "start": "1458659",
    "end": "1464480"
  },
  {
    "text": "it quickly became clear that it was well matched to the task at hand here are some of the reasons we really like",
    "start": "1464480",
    "end": "1470780"
  },
  {
    "text": "profit forecasting is notoriously difficult to do it generally requires specialist",
    "start": "1470780",
    "end": "1477140"
  },
  {
    "text": "skills profit has been designed to make forecasting easier without the need for data science expertise",
    "start": "1477140",
    "end": "1483500"
  },
  {
    "text": "profit works on time series data and can produce very good forecasts without needing specific tuning and",
    "start": "1483500",
    "end": "1489740"
  },
  {
    "text": "customization on a per series basis this allows us to scale it up to hundreds of",
    "start": "1489740",
    "end": "1495020"
  },
  {
    "text": "forecasts it's very fast at generating full cost too which also helps when you have as",
    "start": "1495020",
    "end": "1500059"
  },
  {
    "text": "many as we do it's able to recognize seasonal patterns for example traffic activity over hours",
    "start": "1500059",
    "end": "1505760"
  },
  {
    "text": "in a day or days in a week our utilization data is strongly seasonal we see the same traffic patterns week in",
    "start": "1505760",
    "end": "1512720"
  },
  {
    "text": "and week out profit is also able to handle outliers and missing data really well",
    "start": "1512720",
    "end": "1519140"
  },
  {
    "text": "finally it can detect changes in Trends and adjust forecasts accordingly",
    "start": "1519140",
    "end": "1525820"
  },
  {
    "text": "we jokingly called the proof of concept timeland after brick time land the kind",
    "start": "1527140",
    "end": "1532340"
  },
  {
    "text": "but simple-minded weatherman from the Anchorman movies played by the actor Steve Carroll we selected the python",
    "start": "1532340",
    "end": "1539120"
  },
  {
    "text": "version of The Profit library because we have more expertise within the team in Python than in r",
    "start": "1539120",
    "end": "1545120"
  },
  {
    "text": "profit is well suited for use with jupyter notebooks but we wanted to automate the process of generating the",
    "start": "1545120",
    "end": "1550520"
  },
  {
    "text": "reports so we use the python Library called Jupiter book which is designed to generate static websites from jupyter",
    "start": "1550520",
    "end": "1556760"
  },
  {
    "text": "notebooks or from markdown documents the utilization data is combined with metadata such as service catalog",
    "start": "1556760",
    "end": "1563360"
  },
  {
    "text": "information and resource metadata to augment the forecast with useful context and descriptions",
    "start": "1563360",
    "end": "1569419"
  },
  {
    "text": "in the gitlab CI pipeline we import the utilization data from Thanos run forecasts and generate a static sites",
    "start": "1569419",
    "end": "1576140"
  },
  {
    "text": "including plotly graphs showing Trends and forecasts over time we then published the site using gitlab",
    "start": "1576140",
    "end": "1582799"
  },
  {
    "text": "pages this pipeline is run automatically on a weekly basis",
    "start": "1582799",
    "end": "1588820"
  },
  {
    "text": "this is an example of what the weekly report looks like it's a fairly standard static website on the left we have links",
    "start": "1589760",
    "end": "1597740"
  },
  {
    "text": "to the various Services running kidlab.com and then clicking through to servers we presented with the capacity",
    "start": "1597740",
    "end": "1603799"
  },
  {
    "text": "planning forecast for that service for each monitored resource",
    "start": "1603799",
    "end": "1609278"
  },
  {
    "text": "here's an example of a resource from a service in the report at the top we have a description of the",
    "start": "1610159",
    "end": "1615919"
  },
  {
    "text": "resource being monitored this is important because in some cases such as for inodes it's very easy to understand",
    "start": "1615919",
    "end": "1621740"
  },
  {
    "text": "the utilization metric but in other cases some of the resources that we measure can be pretty abstract and",
    "start": "1621740",
    "end": "1628100"
  },
  {
    "text": "having a clear explanation of what's being tracked can really help next we have some deep links to grafana",
    "start": "1628100",
    "end": "1634220"
  },
  {
    "text": "dashboards so that the operator can quickly navigate to access more information after that we present some dates about",
    "start": "1634220",
    "end": "1641720"
  },
  {
    "text": "when the resource is predicted to violate its alert thresholds and also the 100 threshold",
    "start": "1641720",
    "end": "1647720"
  },
  {
    "text": "this is used for prioritization and alerting finally we have the most important",
    "start": "1647720",
    "end": "1653539"
  },
  {
    "text": "component the forecast chart this is a Time series chart plotted over a 270-day",
    "start": "1653539",
    "end": "1659179"
  },
  {
    "text": "period that's six months into the past and three months into the future because of that the current date is always",
    "start": "1659179",
    "end": "1665179"
  },
  {
    "text": "two-thirds across the time series for the forecast we present the median confidence line and an 80 confidence",
    "start": "1665179",
    "end": "1672320"
  },
  {
    "text": "interval range around that depending on the variance in the data this confidence",
    "start": "1672320",
    "end": "1677539"
  },
  {
    "text": "band will be wider or narrower let's take a look at some examples",
    "start": "1677539",
    "end": "1684039"
  },
  {
    "text": "this chart measures our total git disk utilization across all 80 or so of our git servers recording this as a resource",
    "start": "1686539",
    "end": "1694039"
  },
  {
    "text": "metric gives us a pretty good idea of when we'll need to provision additional git servers the provisioning of these",
    "start": "1694039",
    "end": "1700340"
  },
  {
    "text": "servers doesn't take particularly long but there can be a lead time in getting quota limits raised for storage so it's",
    "start": "1700340",
    "end": "1706820"
  },
  {
    "text": "important that we're planning ahead for these events here's an example of what profit calls a",
    "start": "1706820",
    "end": "1712159"
  },
  {
    "text": "change point a change point is an inflection when a trend changes in this",
    "start": "1712159",
    "end": "1717260"
  },
  {
    "text": "case we see a sudden Step Up in resource consumption because we don't have much Headroom on the service and the lead",
    "start": "1717260",
    "end": "1723140"
  },
  {
    "text": "time to mitigating the saturation is long the decision was made to investigate what had led to this change",
    "start": "1723140",
    "end": "1729380"
  },
  {
    "text": "a regression in the application was discovered and corrected avoiding a",
    "start": "1729380",
    "end": "1734480"
  },
  {
    "text": "saturation problem further down the line here's one more example this resource",
    "start": "1734480",
    "end": "1741320"
  },
  {
    "start": "1737000",
    "end": "1737000"
  },
  {
    "text": "represents redis memory on our reader session storage cluster the cluster stores session state if we hit",
    "start": "1741320",
    "end": "1747740"
  },
  {
    "text": "saturation redis will start to evict old session state with the least recently accessed being evicted first if that",
    "start": "1747740",
    "end": "1754760"
  },
  {
    "text": "happens you may need to re-log in to the gitlab web application sooner than you otherwise would have needed to this is",
    "start": "1754760",
    "end": "1761480"
  },
  {
    "text": "caused by a bug in the gitlab application coupled with some unusual user activity the issue on the right was",
    "start": "1761480",
    "end": "1768679"
  },
  {
    "text": "created around about the time of the event and demonstrates how the team were able to pick this issue up very quickly",
    "start": "1768679",
    "end": "1774140"
  },
  {
    "text": "within a short period of time from the start of the event and long before the issue became critical unfortunately in",
    "start": "1774140",
    "end": "1781399"
  },
  {
    "text": "this case the forecast wasn't accurate in that it didn't predict saturation",
    "start": "1781399",
    "end": "1786440"
  },
  {
    "text": "because it had not yet picked up the change point but it was picked up via",
    "start": "1786440",
    "end": "1791840"
  },
  {
    "text": "manual review with plenty of time to mitigate the problem here are some figures from our current",
    "start": "1791840",
    "end": "1798559"
  },
  {
    "text": "deployment of temland we monitor about 360 different service resource combinations but this is growing all the",
    "start": "1798559",
    "end": "1805520"
  },
  {
    "text": "time coincidentally we've investigated about the same number of potential issues within the last 12 months",
    "start": "1805520",
    "end": "1812419"
  },
  {
    "text": "the timeline report generation job takes around 90 minutes to run on a dedicated N1 standard 8 Runner",
    "start": "1812419",
    "end": "1819200"
  },
  {
    "text": "this job does a lot of caching to speed up retrieval of historical data from Thanos",
    "start": "1819200",
    "end": "1824779"
  },
  {
    "text": "tamlan is an aesthetic project and we're improving it all the time to make it better and more useful for forecasting",
    "start": "1824779",
    "end": "1831380"
  },
  {
    "text": "for engineers at gitlab here are some of the improvements that we're considering implementing in future",
    "start": "1831380",
    "end": "1837260"
  },
  {
    "text": "tamlan started off as an internal project and it was highly coupled to our specific infrastructure and monitoring",
    "start": "1837260",
    "end": "1843080"
  },
  {
    "text": "systems we'd like to continue to evolve the project in a way that would allow other people to benefit from it this",
    "start": "1843080",
    "end": "1849740"
  },
  {
    "text": "would require decoupling it and allowing more configuration options further improving the accuracy of the",
    "start": "1849740",
    "end": "1856340"
  },
  {
    "text": "predictions is going to be a Perpetual goal for the project one of the ways that we might consider doing this is by",
    "start": "1856340",
    "end": "1861919"
  },
  {
    "text": "allowing customization or forecasting and alerting parameters for different resource types",
    "start": "1861919",
    "end": "1867559"
  },
  {
    "text": "another goal is better ownership to shift the ownership left to product teams you can do this by sending alerts",
    "start": "1867559",
    "end": "1874700"
  },
  {
    "text": "directly to those teams and finally it would be worthwhile evaluating whether other forecasting",
    "start": "1874700",
    "end": "1880580"
  },
  {
    "text": "libraries including neural profits which is a pytorch neural network forecasting Library based on profit and linkedin's",
    "start": "1880580",
    "end": "1887840"
  },
  {
    "text": "gray card Library could work better in summary we use tamlan to generate a",
    "start": "1887840",
    "end": "1895760"
  },
  {
    "text": "weekly capacity planning report this capacity plan is tightly coupled with our engineering scheduling",
    "start": "1895760",
    "end": "1901580"
  },
  {
    "text": "processes the same metrics that we use for short-term resource utilization monitoring and alerting also get used",
    "start": "1901580",
    "end": "1908059"
  },
  {
    "text": "for long-term forecasts thanks to our ability to retrieve them from Thanos profit is a very useful tool which makes",
    "start": "1908059",
    "end": "1914960"
  },
  {
    "text": "forecasting very easy I would highly recommend you give it a try for forecasting",
    "start": "1914960",
    "end": "1921260"
  },
  {
    "text": "if you're interested in exploring further here are some links to the timeline source code unfortunately the",
    "start": "1921260",
    "end": "1927440"
  },
  {
    "text": "report itself is no longer public due to restrictions in publishing forward-looking statements now that",
    "start": "1927440",
    "end": "1932960"
  },
  {
    "text": "gitlab is a public company but all the source code is still available and of course if you're interested in",
    "start": "1932960",
    "end": "1939200"
  },
  {
    "text": "this sort of thing please reach out we have a large number of vacancies open in the infrastructure team",
    "start": "1939200",
    "end": "1945340"
  },
  {
    "text": "and that's the talk thank you very much I think we're now going to have some questions",
    "start": "1945340",
    "end": "1951580"
  }
]
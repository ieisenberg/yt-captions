[
  {
    "start": "0",
    "end": "70000"
  },
  {
    "text": "hi everyone my name is Susan woo I'm in",
    "start": "280",
    "end": "2720"
  },
  {
    "text": "outbound product management in Google",
    "start": "2720",
    "end": "4640"
  },
  {
    "text": "Cloud um I'm here with my friends and",
    "start": "4640",
    "end": "7240"
  },
  {
    "text": "colleagues I'm going to let them",
    "start": "7240",
    "end": "8639"
  },
  {
    "text": "introduce themselves hi I'm uh Clayton",
    "start": "8639",
    "end": "10639"
  },
  {
    "text": "Coleman I'm really excited this year I",
    "start": "10639",
    "end": "12639"
  },
  {
    "text": "can finally claim that I have a 10 plus",
    "start": "12639",
    "end": "14719"
  },
  {
    "text": "years uh experience in kubernetes so",
    "start": "14719",
    "end": "17640"
  },
  {
    "text": "that's going straight on my resume and",
    "start": "17640",
    "end": "19240"
  },
  {
    "text": "hopefully I'll be uh hirable",
    "start": "19240",
    "end": "22400"
  },
  {
    "text": "someplace Peter pul Amper Computing it's",
    "start": "22400",
    "end": "25240"
  },
  {
    "text": "a pleasure to be here in Paris this week",
    "start": "25240",
    "end": "27640"
  },
  {
    "text": "great to see everybody looking forward",
    "start": "27640",
    "end": "29240"
  },
  {
    "text": "to a a F week talking about kubernetes",
    "start": "29240",
    "end": "31400"
  },
  {
    "text": "and Cloud native I'm Ricardo um I'm",
    "start": "31400",
    "end": "34559"
  },
  {
    "text": "Computing engineer at CERN I'm also part",
    "start": "34559",
    "end": "36760"
  },
  {
    "text": "of the TOC and the tab in the cncf",
    "start": "36760",
    "end": "39480"
  },
  {
    "text": "really happy to be here meet everyone hi",
    "start": "39480",
    "end": "42320"
  },
  {
    "text": "I'm Lou so I'm the PNC maintainer of the",
    "start": "42320",
    "end": "44480"
  },
  {
    "text": "open source project called alasil and",
    "start": "44480",
    "end": "46800"
  },
  {
    "text": "hopefully I can see like how we dat Ai",
    "start": "46800",
    "end": "49559"
  },
  {
    "text": "and kubernetes work together in",
    "start": "49559",
    "end": "52239"
  },
  {
    "text": "kcom okay Clayton ready I guess so",
    "start": "52239",
    "end": "56640"
  },
  {
    "text": "Enterprises are building a lot of AI",
    "start": "56640",
    "end": "58600"
  },
  {
    "text": "platforms on kubernetes and I hear",
    "start": "58600",
    "end": "60719"
  },
  {
    "text": "platform operators talk about um",
    "start": "60719",
    "end": "63160"
  },
  {
    "text": "abstracting kubernetes for from the data",
    "start": "63160",
    "end": "65519"
  },
  {
    "text": "Sciences um what can we do to make",
    "start": "65520",
    "end": "68119"
  },
  {
    "text": "kubernetes simpler oh my gosh what can't",
    "start": "68119",
    "end": "70920"
  },
  {
    "start": "70000",
    "end": "281000"
  },
  {
    "text": "we do to make kubernetes um so it's",
    "start": "70920",
    "end": "74040"
  },
  {
    "text": "interesting um data scientists don't",
    "start": "74040",
    "end": "76360"
  },
  {
    "text": "need to know about kubernetes but",
    "start": "76360",
    "end": "79000"
  },
  {
    "text": "there's a bunch of things that their",
    "start": "79000",
    "end": "80360"
  },
  {
    "text": "platform teams are going to need uh and",
    "start": "80360",
    "end": "82600"
  },
  {
    "text": "I think I I can simplify by saying uh",
    "start": "82600",
    "end": "86680"
  },
  {
    "text": "kubernetes is supposed to be a cluster",
    "start": "86680",
    "end": "89079"
  },
  {
    "text": "uh or uh operating system and the job of",
    "start": "89079",
    "end": "92040"
  },
  {
    "text": "an operating system is to abstract",
    "start": "92040",
    "end": "93600"
  },
  {
    "text": "Hardware so you heard from Kevin there's",
    "start": "93600",
    "end": "95840"
  },
  {
    "text": "a bunch of exciting work going on uh in",
    "start": "95840",
    "end": "98439"
  },
  {
    "text": "a number of sigs and kubernetes around",
    "start": "98439",
    "end": "100799"
  },
  {
    "text": "abstracting the resource model making",
    "start": "100799",
    "end": "102320"
  },
  {
    "text": "accelerators easier to uh run um but",
    "start": "102320",
    "end": "105880"
  },
  {
    "text": "making just the details that the",
    "start": "105880",
    "end": "107520"
  },
  {
    "text": "platform admins need exposed up above",
    "start": "107520",
    "end": "110560"
  },
  {
    "text": "that um that's going to lead to better",
    "start": "110560",
    "end": "112399"
  },
  {
    "text": "opportunities for scheduling and Bin",
    "start": "112399",
    "end": "114280"
  },
  {
    "text": "packing uh for putting uh keeping those",
    "start": "114280",
    "end": "117240"
  },
  {
    "text": "really really really expensive",
    "start": "117240",
    "end": "118640"
  },
  {
    "text": "accelerators working",
    "start": "118640",
    "end": "120520"
  },
  {
    "text": "and uh the point of kubernetes has",
    "start": "120520",
    "end": "122399"
  },
  {
    "text": "always been to run multiple workloads",
    "start": "122399",
    "end": "124200"
  },
  {
    "text": "together and that's actually what helps",
    "start": "124200",
    "end": "125840"
  },
  {
    "text": "a lot of people achieve significant",
    "start": "125840",
    "end": "127439"
  },
  {
    "text": "efficiency so on top of those uh",
    "start": "127439",
    "end": "129720"
  },
  {
    "text": "accelerators and a better resource model",
    "start": "129720",
    "end": "131239"
  },
  {
    "text": "we really do need uh to bring batch",
    "start": "131239",
    "end": "133560"
  },
  {
    "text": "Frameworks like slurm and Ray uh closer",
    "start": "133560",
    "end": "136920"
  },
  {
    "text": "to kubernetes we need to be able to",
    "start": "136920",
    "end": "138400"
  },
  {
    "text": "support them effectively and then uh",
    "start": "138400",
    "end": "140640"
  },
  {
    "text": "finally since you know training is",
    "start": "140640",
    "end": "142040"
  },
  {
    "text": "really just the development part of the",
    "start": "142040",
    "end": "143480"
  },
  {
    "text": "process everybody's got to go to",
    "start": "143480",
    "end": "145120"
  },
  {
    "text": "production at some point and I think",
    "start": "145120",
    "end": "146920"
  },
  {
    "text": "kubernetes needs to be the best place um",
    "start": "146920",
    "end": "149440"
  },
  {
    "text": "to run production inference workloads",
    "start": "149440",
    "end": "151720"
  },
  {
    "text": "and so the focus I think will have to be",
    "start": "151720",
    "end": "153840"
  },
  {
    "text": "um constructs that make it easy to run",
    "start": "153840",
    "end": "156040"
  },
  {
    "text": "those and to keep them running on top of",
    "start": "156040",
    "end": "157959"
  },
  {
    "text": "accelerators uh pretty much 247 sounds",
    "start": "157959",
    "end": "161480"
  },
  {
    "text": "like something that our community should",
    "start": "161480",
    "end": "163120"
  },
  {
    "text": "be proud to be part of right I hope so",
    "start": "163120",
    "end": "166680"
  },
  {
    "text": "okay Peter I want to ask you about um so",
    "start": "166680",
    "end": "169720"
  },
  {
    "text": "kubernetes is already well suited to",
    "start": "169720",
    "end": "172040"
  },
  {
    "text": "handle the resource allocations so um",
    "start": "172040",
    "end": "175000"
  },
  {
    "text": "you know for uh what compute choices",
    "start": "175000",
    "end": "177720"
  },
  {
    "text": "should these uh platform owners make",
    "start": "177720",
    "end": "180440"
  },
  {
    "text": "especially for performance or for",
    "start": "180440",
    "end": "182760"
  },
  {
    "text": "sustainability so kubernetes and open",
    "start": "182760",
    "end": "185200"
  },
  {
    "text": "source ecosystems have been great for",
    "start": "185200",
    "end": "187040"
  },
  {
    "text": "llm Innovations and open source small",
    "start": "187040",
    "end": "189879"
  },
  {
    "text": "parameter llms are becoming more a more",
    "start": "189879",
    "end": "192680"
  },
  {
    "text": "Prat pragmatic and available Choice uh",
    "start": "192680",
    "end": "196440"
  },
  {
    "text": "however for small parameter llms you",
    "start": "196440",
    "end": "198599"
  },
  {
    "text": "know inference uh small parameter llm",
    "start": "198599",
    "end": "201239"
  },
  {
    "text": "inferencing uh a GPU only approach isn't",
    "start": "201239",
    "end": "205519"
  },
  {
    "text": "necessarily sustainable uh we need",
    "start": "205519",
    "end": "207680"
  },
  {
    "text": "something that's uh you know affordable",
    "start": "207680",
    "end": "210080"
  },
  {
    "text": "uh available uh and easy to use um you",
    "start": "210080",
    "end": "213519"
  },
  {
    "text": "know llm inference runs seamlessly today",
    "start": "213519",
    "end": "217120"
  },
  {
    "text": "out of the box on a64 architecture",
    "start": "217120",
    "end": "219760"
  },
  {
    "text": "processors like Amper for example across",
    "start": "219760",
    "end": "222760"
  },
  {
    "text": "uh you know uh Cloud providers uh and uh",
    "start": "222760",
    "end": "226000"
  },
  {
    "text": "from a uh you know it's it has a proven",
    "start": "226000",
    "end": "229000"
  },
  {
    "text": "uh price per performance per watt uh",
    "start": "229000",
    "end": "232159"
  },
  {
    "text": "compared to the Alternatives uh today",
    "start": "232159",
    "end": "234840"
  },
  {
    "text": "specifically for uh you know this use",
    "start": "234840",
    "end": "237400"
  },
  {
    "text": "case I think you have some credits that",
    "start": "237400",
    "end": "239799"
  },
  {
    "text": "you're giving away right oh yeah so",
    "start": "239799",
    "end": "241640"
  },
  {
    "text": "Oracle uh last Oracle announced last uh",
    "start": "241640",
    "end": "245920"
  },
  {
    "text": "cucon in Chicago uh they're offering uh",
    "start": "245920",
    "end": "249120"
  },
  {
    "text": "credits to be able to use uh ampere",
    "start": "249120",
    "end": "252159"
  },
  {
    "text": "compute within their Cloud specifically",
    "start": "252159",
    "end": "254319"
  },
  {
    "text": "for uh you know cncf based projects and",
    "start": "254319",
    "end": "256959"
  },
  {
    "text": "and open source projects in general so",
    "start": "256959",
    "end": "258959"
  },
  {
    "text": "it's extremely exciting get out there",
    "start": "258959",
    "end": "261079"
  },
  {
    "text": "and try it out uh so Ricardo um so",
    "start": "261079",
    "end": "264280"
  },
  {
    "text": "there's a known GPU shortage and",
    "start": "264280",
    "end": "266919"
  },
  {
    "text": "traditionally people are experiencing",
    "start": "266919",
    "end": "268880"
  },
  {
    "text": "really low GPU utilization uh what's",
    "start": "268880",
    "end": "272080"
  },
  {
    "text": "happening why is that happening and also",
    "start": "272080",
    "end": "274840"
  },
  {
    "text": "what uh techniques can operators use to",
    "start": "274840",
    "end": "278240"
  },
  {
    "text": "increase their GPU utilization yep so",
    "start": "278240",
    "end": "281880"
  },
  {
    "start": "281000",
    "end": "414000"
  },
  {
    "text": "that's uh something we've been looking",
    "start": "281880",
    "end": "283520"
  },
  {
    "text": "at for uh for quite a while uh by now uh",
    "start": "283520",
    "end": "288320"
  },
  {
    "text": "in research Computing scientific",
    "start": "288320",
    "end": "290199"
  },
  {
    "text": "Computing we have some experience",
    "start": "290199",
    "end": "291720"
  },
  {
    "text": "running batch workloads and building a",
    "start": "291720",
    "end": "293160"
  },
  {
    "text": "lot on what Clayton was also mentioning",
    "start": "293160",
    "end": "295680"
  },
  {
    "text": "uh we can kind of separate uh two",
    "start": "295680",
    "end": "297639"
  },
  {
    "text": "different P patterns of usage one is",
    "start": "297639",
    "end": "300120"
  },
  {
    "text": "more the interactive kind of what we",
    "start": "300120",
    "end": "302199"
  },
  {
    "text": "would say inference now as well even",
    "start": "302199",
    "end": "304479"
  },
  {
    "text": "cicd kind of workloads um these are",
    "start": "304479",
    "end": "307759"
  },
  {
    "text": "needs immediate access but they tend to",
    "start": "307759",
    "end": "310080"
  },
  {
    "text": "be quite spiky uh and in there we see",
    "start": "310080",
    "end": "313039"
  },
  {
    "text": "very low uh overall GPU",
    "start": "313039",
    "end": "315919"
  },
  {
    "text": "utilization um something like 20 30% in",
    "start": "315919",
    "end": "319000"
  },
  {
    "text": "the order of uh of 20 to 30% there are",
    "start": "319000",
    "end": "322440"
  },
  {
    "text": "some things that we can do to try to",
    "start": "322440",
    "end": "324280"
  },
  {
    "text": "optimize the this pattern which is to",
    "start": "324280",
    "end": "326600"
  },
  {
    "text": "try to share better or maybe",
    "start": "326600",
    "end": "328240"
  },
  {
    "text": "partitioning uh the G use so that we can",
    "start": "328240",
    "end": "331080"
  },
  {
    "text": "make the best of them so there's several",
    "start": "331080",
    "end": "333479"
  },
  {
    "text": "techniques that uh are possible and uh",
    "start": "333479",
    "end": "336080"
  },
  {
    "text": "there's a lot of work in the community",
    "start": "336080",
    "end": "337440"
  },
  {
    "text": "as well to to better support this uh",
    "start": "337440",
    "end": "339280"
  },
  {
    "text": "clayon was mentioning a lot of this uh",
    "start": "339280",
    "end": "342080"
  },
  {
    "text": "ideas uh I think it's something that",
    "start": "342080",
    "end": "344039"
  },
  {
    "text": "we'll continue pushing for uh and then",
    "start": "344039",
    "end": "346560"
  },
  {
    "text": "we have more the batch workloads uh",
    "start": "346560",
    "end": "348600"
  },
  {
    "text": "which are more predictable but more long",
    "start": "348600",
    "end": "351000"
  },
  {
    "text": "running as well and here what we want is",
    "start": "351000",
    "end": "353360"
  },
  {
    "text": "really to make sure that we always have",
    "start": "353360",
    "end": "355600"
  },
  {
    "text": "enough workloads on the Queue to to make",
    "start": "355600",
    "end": "358280"
  },
  {
    "text": "the best of the system and ever have",
    "start": "358280",
    "end": "360080"
  },
  {
    "text": "like pauses in between uh there are some",
    "start": "360080",
    "end": "362720"
  },
  {
    "text": "Primitives that exist in traditional HPC",
    "start": "362720",
    "end": "365960"
  },
  {
    "text": "uh kind of uh systems that are landing",
    "start": "365960",
    "end": "369080"
  },
  {
    "text": "now uh in the kubernetes and Cloud",
    "start": "369080",
    "end": "371360"
  },
  {
    "text": "native area as well uh things like cues",
    "start": "371360",
    "end": "374160"
  },
  {
    "text": "and better scheduling Primitives things",
    "start": "374160",
    "end": "376639"
  },
  {
    "text": "like co- scheduling um and this is kind",
    "start": "376639",
    "end": "379880"
  },
  {
    "text": "of vital to ensure uh we also cover uh",
    "start": "379880",
    "end": "382759"
  },
  {
    "text": "this type of workloads and uh I I put",
    "start": "382759",
    "end": "385400"
  },
  {
    "text": "here something that I heard uh in back",
    "start": "385400",
    "end": "388080"
  },
  {
    "text": "in the AI day in Chicago uh a",
    "start": "388080",
    "end": "390280"
  },
  {
    "text": "presentation that the ideal situation we",
    "start": "390280",
    "end": "392319"
  },
  {
    "text": "should look for is uh uh sharing",
    "start": "392319",
    "end": "394400"
  },
  {
    "text": "resources where we can have both this",
    "start": "394400",
    "end": "396039"
  },
  {
    "text": "kind of online and offline uh workloads",
    "start": "396039",
    "end": "398840"
  },
  {
    "text": "sharing the same pool uh in a sort of",
    "start": "398840",
    "end": "401360"
  },
  {
    "text": "title collocation I think this is the",
    "start": "401360",
    "end": "403599"
  },
  {
    "text": "the aim we should try to go for go to",
    "start": "403599",
    "end": "407160"
  },
  {
    "text": "ask you Clayton are there any you know",
    "start": "407160",
    "end": "409199"
  },
  {
    "text": "monitoring Frameworks to could monitor",
    "start": "409199",
    "end": "412039"
  },
  {
    "text": "the GPU",
    "start": "412039",
    "end": "413599"
  },
  {
    "text": "performance there's not enough um and I",
    "start": "413599",
    "end": "416199"
  },
  {
    "start": "414000",
    "end": "642000"
  },
  {
    "text": "think this is actually an opportunity um",
    "start": "416199",
    "end": "418160"
  },
  {
    "text": "both in the ecosystem and for vendors",
    "start": "418160",
    "end": "419919"
  },
  {
    "text": "there's a a ton of great tools um you",
    "start": "419919",
    "end": "423240"
  },
  {
    "text": "know whether it's monitoring accelerator",
    "start": "423240",
    "end": "425479"
  },
  {
    "text": "usage you have a rich history of CPU and",
    "start": "425479",
    "end": "429120"
  },
  {
    "text": "host level monitoring but I think as",
    "start": "429120",
    "end": "431240"
  },
  {
    "text": "we're moving into this more complex era",
    "start": "431240",
    "end": "432960"
  },
  {
    "text": "we'd actually need uh better tools for",
    "start": "432960",
    "end": "435120"
  },
  {
    "text": "understanding um you know where capacity",
    "start": "435120",
    "end": "437160"
  },
  {
    "text": "is going how capacity is going to flow",
    "start": "437160",
    "end": "439639"
  },
  {
    "text": "um whether the uh the necessary needs of",
    "start": "439639",
    "end": "442479"
  },
  {
    "text": "the workloads are being satisfied um the",
    "start": "442479",
    "end": "444800"
  },
  {
    "text": "storage system how data is flowing and I",
    "start": "444800",
    "end": "447720"
  },
  {
    "text": "think uh we're just kind of at that",
    "start": "447720",
    "end": "449960"
  },
  {
    "text": "beginning of stitching together this you",
    "start": "449960",
    "end": "451919"
  },
  {
    "text": "know these massive AI supercomputers",
    "start": "451919",
    "end": "454039"
  },
  {
    "text": "that all of us are going to end up",
    "start": "454039",
    "end": "455240"
  },
  {
    "text": "running 10 years from now and um I think",
    "start": "455240",
    "end": "457960"
  },
  {
    "text": "the the monitoring systems have to",
    "start": "457960",
    "end": "459800"
  },
  {
    "text": "evolve with them that makes sense Lou we",
    "start": "459800",
    "end": "462400"
  },
  {
    "text": "talked a lot about performance I've seen",
    "start": "462400",
    "end": "464400"
  },
  {
    "text": "you present talking about uh moving the",
    "start": "464400",
    "end": "468759"
  },
  {
    "text": "G uh CPU to the GPU so that you could",
    "start": "468759",
    "end": "471919"
  },
  {
    "text": "speed up like data loading data",
    "start": "471919",
    "end": "474520"
  },
  {
    "text": "pre-processing you know what are some of",
    "start": "474520",
    "end": "476440"
  },
  {
    "text": "those economic considerations that you",
    "start": "476440",
    "end": "478560"
  },
  {
    "text": "want to share with prog so talking about",
    "start": "478560",
    "end": "481479"
  },
  {
    "text": "the economic consideration I think the",
    "start": "481479",
    "end": "483680"
  },
  {
    "text": "GP utilization rate is one thing that we",
    "start": "483680",
    "end": "485879"
  },
  {
    "text": "cannot avoid like building on Ricardo's",
    "start": "485879",
    "end": "488759"
  },
  {
    "text": "insights about like how we can",
    "start": "488759",
    "end": "490800"
  },
  {
    "text": "scheduling different kinds of jobs",
    "start": "490800",
    "end": "492800"
  },
  {
    "text": "together to help to maximize the GP",
    "start": "492800",
    "end": "495280"
  },
  {
    "text": "utilization rate uh so our approach is",
    "start": "495280",
    "end": "498680"
  },
  {
    "text": "more like focusing on the traffic flow",
    "start": "498680",
    "end": "501599"
  },
  {
    "text": "and also the starage performance which",
    "start": "501599",
    "end": "504039"
  },
  {
    "text": "like Clon have talked about like so the",
    "start": "504039",
    "end": "507199"
  },
  {
    "text": "approach is to attach CPU machine to GPU",
    "start": "507199",
    "end": "510360"
  },
  {
    "text": "machines so the CPU machines can focus",
    "start": "510360",
    "end": "513240"
  },
  {
    "text": "on some initial data task like data",
    "start": "513240",
    "end": "515880"
  },
  {
    "text": "loading data caching and data",
    "start": "515880",
    "end": "518518"
  },
  {
    "text": "pre-processing while the GPU machines",
    "start": "518519",
    "end": "521120"
  },
  {
    "text": "they can focus on the chaining and",
    "start": "521120",
    "end": "523159"
  },
  {
    "text": "serving so it will largely reduce the",
    "start": "523159",
    "end": "525839"
  },
  {
    "text": "GPU weight time the time that we need to",
    "start": "525839",
    "end": "528480"
  },
  {
    "text": "get data ready for AI so AI seems to be",
    "start": "528480",
    "end": "532880"
  },
  {
    "text": "all about getting that information out",
    "start": "532880",
    "end": "535000"
  },
  {
    "text": "of the data so how do we get the data",
    "start": "535000",
    "end": "538040"
  },
  {
    "text": "ready for AI so let's go little more",
    "start": "538040",
    "end": "541360"
  },
  {
    "text": "detail into it so there are different",
    "start": "541360",
    "end": "543480"
  },
  {
    "text": "approach that how we can get data ready",
    "start": "543480",
    "end": "545839"
  },
  {
    "text": "for AI for different kinds of AO World",
    "start": "545839",
    "end": "548200"
  },
  {
    "text": "loads like training and serving they",
    "start": "548200",
    "end": "550000"
  },
  {
    "text": "kind different so we will share one of",
    "start": "550000",
    "end": "552240"
  },
  {
    "text": "the simple example of how we can that",
    "start": "552240",
    "end": "554920"
  },
  {
    "text": "data ready for AI training leveraging",
    "start": "554920",
    "end": "557880"
  },
  {
    "text": "two open source framework the alasio and",
    "start": "557880",
    "end": "560600"
  },
  {
    "text": "Ray so alasio decouple the story system",
    "start": "560600",
    "end": "564160"
  },
  {
    "text": "from the AI framework so the AI",
    "start": "564160",
    "end": "566920"
  },
  {
    "text": "framework can assess different story",
    "start": "566920",
    "end": "568760"
  },
  {
    "text": "system using some UniFi namespace like",
    "start": "568760",
    "end": "572040"
  },
  {
    "text": "the local file system approach or python",
    "start": "572040",
    "end": "574440"
  },
  {
    "text": "AO approach which the data scientists",
    "start": "574440",
    "end": "576880"
  },
  {
    "text": "are pretty familiar with and also it can",
    "start": "576880",
    "end": "579600"
  },
  {
    "text": "leverage the resources on the CPU",
    "start": "579600",
    "end": "581920"
  },
  {
    "text": "machine it can Leverage The this",
    "start": "581920",
    "end": "583959"
  },
  {
    "text": "resources on the CPU machine for the",
    "start": "583959",
    "end": "586760"
  },
  {
    "text": "catching probability it can catch data",
    "start": "586760",
    "end": "589519"
  },
  {
    "text": "for the AI chaining which is especially",
    "start": "589519",
    "end": "592000"
  },
  {
    "text": "helpful when the when the training job",
    "start": "592000",
    "end": "594600"
  },
  {
    "text": "you need to load the data again and",
    "start": "594600",
    "end": "596399"
  },
  {
    "text": "again and on the other side like Ray it",
    "start": "596399",
    "end": "599480"
  },
  {
    "text": "can leverage turn CPU all resources on",
    "start": "599480",
    "end": "602120"
  },
  {
    "text": "the CPU machine to in basically to",
    "start": "602120",
    "end": "605079"
  },
  {
    "text": "facilitate the last mild data",
    "start": "605079",
    "end": "607320"
  },
  {
    "text": "preprocessing and with r the data",
    "start": "607320",
    "end": "609680"
  },
  {
    "text": "loading caching pre-processing and",
    "start": "609680",
    "end": "612279"
  },
  {
    "text": "chaining they can all be paralleled and",
    "start": "612279",
    "end": "614519"
  },
  {
    "text": "stream light together and thus improve",
    "start": "614519",
    "end": "617000"
  },
  {
    "text": "the overall GP utilization rate I think",
    "start": "617000",
    "end": "619720"
  },
  {
    "text": "there's a operator for Ray from c9s",
    "start": "619720",
    "end": "623120"
  },
  {
    "text": "right there are an um you know there's a",
    "start": "623120",
    "end": "624440"
  },
  {
    "text": "lot of Integrations you know coming with",
    "start": "624440",
    "end": "626279"
  },
  {
    "text": "Ray and kubernetes and I think that's a",
    "start": "626279",
    "end": "628640"
  },
  {
    "text": "a great opportunity for us to to keep",
    "start": "628640",
    "end": "631079"
  },
  {
    "text": "improving uh Peter uh we talked a lot",
    "start": "631079",
    "end": "633920"
  },
  {
    "text": "about accelerating AI performance in",
    "start": "633920",
    "end": "636480"
  },
  {
    "text": "software uh what can we do to optimize",
    "start": "636480",
    "end": "639720"
  },
  {
    "text": "for maybe",
    "start": "639720",
    "end": "641040"
  },
  {
    "text": "sustainability so software Accel",
    "start": "641040",
    "end": "643800"
  },
  {
    "start": "642000",
    "end": "722000"
  },
  {
    "text": "acceleration is a great start for llm",
    "start": "643800",
    "end": "646639"
  },
  {
    "text": "imprints uh but we need a more",
    "start": "646639",
    "end": "648600"
  },
  {
    "text": "sustainable compute to actually scale",
    "start": "648600",
    "end": "650880"
  },
  {
    "text": "the workload right so for llm imprint uh",
    "start": "650880",
    "end": "654680"
  },
  {
    "text": "GPU isn't always necessary right so uh",
    "start": "654680",
    "end": "657880"
  },
  {
    "text": "Amper has done some extensive testing uh",
    "start": "657880",
    "end": "660480"
  },
  {
    "text": "with small parameter llms to uh",
    "start": "660480",
    "end": "662920"
  },
  {
    "text": "inference uh running on our uh compute",
    "start": "662920",
    "end": "666839"
  },
  {
    "text": "and uh the empirical evidence that we're",
    "start": "666839",
    "end": "669360"
  },
  {
    "text": "getting is you know it's very uh it's",
    "start": "669360",
    "end": "672440"
  },
  {
    "text": "it's intriguing right like we're we're",
    "start": "672440",
    "end": "673760"
  },
  {
    "text": "seeing uh significant savings and and",
    "start": "673760",
    "end": "676519"
  },
  {
    "text": "cost efficiency and and uh great metrics",
    "start": "676519",
    "end": "679560"
  },
  {
    "text": "of you know in terms of that coming out",
    "start": "679560",
    "end": "681920"
  },
  {
    "text": "so uh you know in some cases we're",
    "start": "681920",
    "end": "683480"
  },
  {
    "text": "talking you know 40% to 80% less cost",
    "start": "683480",
    "end": "687120"
  },
  {
    "text": "for operating so you know and and it's",
    "start": "687120",
    "end": "689839"
  },
  {
    "text": "available today you can you can give it",
    "start": "689839",
    "end": "691519"
  },
  {
    "text": "a try right so uh you know in fact later",
    "start": "691519",
    "end": "694600"
  },
  {
    "text": "on today you can come see it running uh",
    "start": "694600",
    "end": "697320"
  },
  {
    "text": "running in the Oracle booth and and",
    "start": "697320",
    "end": "699560"
  },
  {
    "text": "witness uh an experience here for",
    "start": "699560",
    "end": "702000"
  },
  {
    "text": "yourself Ricardo you're in",
    "start": "702000",
    "end": "703920"
  },
  {
    "text": "infrastructure it seems like the AI",
    "start": "703920",
    "end": "706440"
  },
  {
    "text": "workload seems to be different um from",
    "start": "706440",
    "end": "709600"
  },
  {
    "text": "for than the typical kubernetes",
    "start": "709600",
    "end": "711639"
  },
  {
    "text": "workloads do you want to share some",
    "start": "711639",
    "end": "713839"
  },
  {
    "text": "advice for folks because they might be",
    "start": "713839",
    "end": "715279"
  },
  {
    "text": "running and um operating an",
    "start": "715279",
    "end": "717519"
  },
  {
    "text": "infrastructure for AI workloads if not",
    "start": "717519",
    "end": "720000"
  },
  {
    "text": "today maybe",
    "start": "720000",
    "end": "722079"
  },
  {
    "text": "tomorrow yeah so the there's uh quite a",
    "start": "722079",
    "end": "724760"
  },
  {
    "text": "lot of challenges we've been discussing",
    "start": "724760",
    "end": "727279"
  },
  {
    "text": "them in the last couple of months uh in",
    "start": "727279",
    "end": "729519"
  },
  {
    "text": "different sessions at coupon and",
    "start": "729519",
    "end": "732000"
  },
  {
    "text": "elsewhere uh there are challenges",
    "start": "732000",
    "end": "734160"
  },
  {
    "text": "internally if you're running your own uh",
    "start": "734160",
    "end": "736320"
  },
  {
    "text": "data centers uh that were traditional",
    "start": "736320",
    "end": "738839"
  },
  {
    "text": "designed to host CPUs the when you start",
    "start": "738839",
    "end": "742399"
  },
  {
    "text": "uh increasing the density with things",
    "start": "742399",
    "end": "743800"
  },
  {
    "text": "like gpus there's a lot of challenges I",
    "start": "743800",
    "end": "746079"
  },
  {
    "text": "think the the main lesson we've learned",
    "start": "746079",
    "end": "748959"
  },
  {
    "text": "uh is to to stay as flexible as possible",
    "start": "748959",
    "end": "751800"
  },
  {
    "text": "in terms of uh the infrastructure you",
    "start": "751800",
    "end": "753560"
  },
  {
    "text": "can support and what this means uh given",
    "start": "753560",
    "end": "756440"
  },
  {
    "text": "the scarcity of gpus that uh Susan was",
    "start": "756440",
    "end": "759360"
  },
  {
    "text": "mentioning at the start as well is that",
    "start": "759360",
    "end": "761920"
  },
  {
    "text": "uh if you plan to be uh flexible in",
    "start": "761920",
    "end": "765000"
  },
  {
    "text": "terms of supporting multicluster",
    "start": "765000",
    "end": "766360"
  },
  {
    "text": "workloads and especially supporting",
    "start": "766360",
    "end": "769040"
  },
  {
    "text": "hybrid workloads where you can have your",
    "start": "769040",
    "end": "771519"
  },
  {
    "text": "the majority of your workloads or the",
    "start": "771519",
    "end": "773320"
  },
  {
    "text": "predictable workloads running on",
    "start": "773320",
    "end": "775399"
  },
  {
    "text": "premises if you can actually get hold of",
    "start": "775399",
    "end": "777519"
  },
  {
    "text": "gpus these days but also so complement",
    "start": "777519",
    "end": "779959"
  },
  {
    "text": "that with uh with the ability to burst",
    "start": "779959",
    "end": "782600"
  },
  {
    "text": "into into uh external resources where",
    "start": "782600",
    "end": "785760"
  },
  {
    "text": "these gpus might be available uh in",
    "start": "785760",
    "end": "788560"
  },
  {
    "text": "larger numbers this is really important",
    "start": "788560",
    "end": "790440"
  },
  {
    "text": "and it's this is really a a design uh",
    "start": "790440",
    "end": "793279"
  },
  {
    "text": "decision that has to be made quite early",
    "start": "793279",
    "end": "796160"
  },
  {
    "text": "uh to to support multicluster to be",
    "start": "796160",
    "end": "799000"
  },
  {
    "text": "flexible on where where the resources",
    "start": "799000",
    "end": "801040"
  },
  {
    "text": "come come from this is a a key decision",
    "start": "801040",
    "end": "803760"
  },
  {
    "text": "to be made from the",
    "start": "803760",
    "end": "805519"
  },
  {
    "text": "start well said um so let me uh kind of",
    "start": "805519",
    "end": "808760"
  },
  {
    "text": "encap capsulate and and just kind of",
    "start": "808760",
    "end": "810600"
  },
  {
    "text": "summarize you heard a lot of points but",
    "start": "810600",
    "end": "813000"
  },
  {
    "text": "kubernetes is really looking like it's",
    "start": "813000",
    "end": "815000"
  },
  {
    "text": "becoming the standard for AI platforms",
    "start": "815000",
    "end": "817160"
  },
  {
    "text": "would you agree and so you know let's",
    "start": "817160",
    "end": "819920"
  },
  {
    "text": "work as a community to make these",
    "start": "819920",
    "end": "821600"
  },
  {
    "text": "accelerated workloads run much better on",
    "start": "821600",
    "end": "824800"
  },
  {
    "text": "kubernetes uh another thing another",
    "start": "824800",
    "end": "827120"
  },
  {
    "text": "consideration is Ricardo talked about",
    "start": "827120",
    "end": "829639"
  },
  {
    "text": "the different workloads so there might",
    "start": "829639",
    "end": "831519"
  },
  {
    "text": "be some that are long running some might",
    "start": "831519",
    "end": "833839"
  },
  {
    "text": "be short and spiky so make your resource",
    "start": "833839",
    "end": "836720"
  },
  {
    "text": "allocations decisions based on the use",
    "start": "836720",
    "end": "839600"
  },
  {
    "text": "patterns right um Lou talked about",
    "start": "839600",
    "end": "843079"
  },
  {
    "text": "speeding up the data loading data",
    "start": "843079",
    "end": "846279"
  },
  {
    "text": "pre-processing attach your CPUs to your",
    "start": "846279",
    "end": "849519"
  },
  {
    "text": "GPU clusters and then lastly I actually",
    "start": "849519",
    "end": "852120"
  },
  {
    "text": "heard this from my users and customers",
    "start": "852120",
    "end": "855120"
  },
  {
    "text": "they said um choose the right",
    "start": "855120",
    "end": "857680"
  },
  {
    "text": "specialized compute for the right AI",
    "start": "857680",
    "end": "860639"
  },
  {
    "text": "model the job is to make it easier for",
    "start": "860639",
    "end": "864360"
  },
  {
    "text": "you know research scientists data",
    "start": "864360",
    "end": "866240"
  },
  {
    "text": "scientists to iterate much faster so",
    "start": "866240",
    "end": "868680"
  },
  {
    "text": "that's our job so with that I I'm going",
    "start": "868680",
    "end": "871040"
  },
  {
    "text": "to close at this time and I want to",
    "start": "871040",
    "end": "874040"
  },
  {
    "text": "thank the panelists and we're going to",
    "start": "874040",
    "end": "876560"
  },
  {
    "text": "be around for a hallway track and uh so",
    "start": "876560",
    "end": "880279"
  },
  {
    "text": "look for us and then um you know thank",
    "start": "880279",
    "end": "883240"
  },
  {
    "text": "you for uh having us on this and please",
    "start": "883240",
    "end": "885880"
  },
  {
    "text": "give us uh my panelist a big round of",
    "start": "885880",
    "end": "890280"
  },
  {
    "text": "[Applause]",
    "start": "890280",
    "end": "891570"
  },
  {
    "text": "[Music]",
    "start": "891570",
    "end": "896240"
  },
  {
    "text": "applause",
    "start": "896240",
    "end": "899240"
  }
]
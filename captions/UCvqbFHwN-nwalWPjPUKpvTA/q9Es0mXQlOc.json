[
  {
    "start": "0",
    "end": "88000"
  },
  {
    "text": "one more minutes and then we can kind of get things started",
    "start": "130",
    "end": "4679"
  },
  {
    "text": "all right I'd like to thank everybody who's joining us today welcome to today's CN CF c CN CF webinar what's new",
    "start": "67150",
    "end": "75710"
  },
  {
    "text": "in kubernetes 1:16 my name is Taylor Dolezal I lead set reliability engineering at Walt Disney Studios I was",
    "start": "75710",
    "end": "83330"
  },
  {
    "text": "the 116 communications lead I'll be monitoring today's webinar we would like",
    "start": "83330",
    "end": "88790"
  },
  {
    "start": "88000",
    "end": "88000"
  },
  {
    "text": "to welcome our presenters today Kenny Coleman technical product manager at VMware and kubernetes 116",
    "start": "88790",
    "end": "94720"
  },
  {
    "text": "enhancements lead in lackey Evanson principal program manager at Microsoft and kubernetes 116 lead some",
    "start": "94720",
    "end": "102650"
  },
  {
    "text": "housekeeping items I have for you today are that during the webinar you are not able to talk as an attendee there is a",
    "start": "102650",
    "end": "109910"
  },
  {
    "text": "Q&A box at the bottom of your screen please feel free to drop your questions in there and we'll get to as many as we",
    "start": "109910",
    "end": "115759"
  },
  {
    "text": "can at the end this is an official webinar of the CNC F and as such a subject to the CNC F could",
    "start": "115759",
    "end": "123229"
  },
  {
    "text": "conduct which basically translates to please don't be a jerk please don't add anything to the chat for questions that",
    "start": "123229",
    "end": "129259"
  },
  {
    "text": "will be in violation of that code of conduct basically just be respectful of everybody here today with that I will",
    "start": "129259",
    "end": "136430"
  },
  {
    "text": "hand it over to Kenny to kick off today's presentation thanks Tyler appreciate it and thank you",
    "start": "136430",
    "end": "141739"
  },
  {
    "text": "everybody for joining here today you know it's gonna be a fun-filled afternoon we're looking at all of the",
    "start": "141739",
    "end": "148160"
  },
  {
    "text": "new features as well as some of the graduated features that happen with the 116 release now just some quick",
    "start": "148160",
    "end": "154610"
  },
  {
    "text": "housekeeping as we start going through here please note that we will do our best to answer any questions possible as",
    "start": "154610",
    "end": "161510"
  },
  {
    "text": "Taylor said please use the Q&A panel if you can lakis going to be there to try",
    "start": "161510",
    "end": "166850"
  },
  {
    "text": "to answer them all so please know that we are part of the release team that means that our goal and our job is to",
    "start": "166850",
    "end": "174530"
  },
  {
    "text": "take the everything that is going to be going into the release and funnel it and push out something that is stable and",
    "start": "174530",
    "end": "181610"
  },
  {
    "text": "everybody is happy with now that does not mean that we know every little nuance and technical detail of every",
    "start": "181610",
    "end": "190280"
  },
  {
    "text": "single thing that we're going to go over so as you as we go through here you're gonna see that there is going to be a",
    "start": "190280",
    "end": "196370"
  },
  {
    "text": "link at the very bottom for every issue if you're in climb to read more about it you can go",
    "start": "196370",
    "end": "201860"
  },
  {
    "text": "to that issue and read the kept for the kubernetes enhancement proposal and that will give you a better idea of exactly",
    "start": "201860",
    "end": "207680"
  },
  {
    "text": "what's going into this as well as lucky am i lucky myself we're also not the",
    "start": "207680",
    "end": "212780"
  },
  {
    "text": "issue owners nor are we in every single sig so we will not be able to answer all the details to the you know basically to",
    "start": "212780",
    "end": "220610"
  },
  {
    "text": "them we're gonna do it the best of our ability but that's what we can do so just quickly kind of hit the agenda here",
    "start": "220610",
    "end": "226450"
  },
  {
    "start": "226000",
    "end": "226000"
  },
  {
    "text": "we're gonna go through some of the really three major features and then we're gonna go and touch all of the",
    "start": "226450",
    "end": "232790"
  },
  {
    "text": "enhancements but before we get to that I want lucky to kind of talk about the release theme and as you can see this",
    "start": "232790",
    "end": "239420"
  },
  {
    "text": "badge and the logo that kind of embraced for 116 and he can kind of give you an",
    "start": "239420",
    "end": "244730"
  },
  {
    "text": "update of kind of where this where this all stemmed from as well thanks Kenny",
    "start": "244730",
    "end": "250610"
  },
  {
    "text": "said the release mascot there were two aspects to the creativity here one aspect was going into the 116 release",
    "start": "250610",
    "end": "257989"
  },
  {
    "text": "cycle it was actually the 50th anniversary of the lunar landing which got me thinking about all the Apollo",
    "start": "257989",
    "end": "263060"
  },
  {
    "text": "missions so this badge is actually inspired by the Apollo 16 mission so if",
    "start": "263060",
    "end": "270590"
  },
  {
    "text": "you go and refer to that mission patch you'll take a look and you will see a very similar thing and eagles been",
    "start": "270590",
    "end": "275990"
  },
  {
    "text": "replaced with captain cube and a few other things there the the rest of it represents the meme that is around my",
    "start": "275990",
    "end": "283490"
  },
  {
    "text": "love of Olive Garden and this represents the fun that the release team had together during this release I think it",
    "start": "283490",
    "end": "292550"
  },
  {
    "text": "embodies everything that we went through for the last three months getting the 116 release out so that is the history",
    "start": "292550",
    "end": "299330"
  },
  {
    "text": "behind the release mascot thanks Kenny absolutely and so if you ever see lucky",
    "start": "299330",
    "end": "304340"
  },
  {
    "text": "in person you all can go out to Olive Garden and just have unlimited breadsticks together and just talk about all those all the great things that",
    "start": "304340",
    "end": "310580"
  },
  {
    "text": "happen inside of kubernetes alright so let's go ahead and we will dive into the 1/16 enhancements so just to kind of",
    "start": "310580",
    "end": "319280"
  },
  {
    "text": "give an overview of what this looked like it was a little bit more than we had in 115 I was Enhancement lead back",
    "start": "319280",
    "end": "325130"
  },
  {
    "start": "320000",
    "end": "320000"
  },
  {
    "text": "in 115 too so I can kind of give a little bit of context to it but back in 115 we introduced a total of 25",
    "start": "325130",
    "end": "331460"
  },
  {
    "text": "enhancements that were being tracked and now we're bumping that up to 31 here in 116",
    "start": "331460",
    "end": "336770"
  },
  {
    "text": "and we're gonna be touching on all these pretty lightly and looking at them at a high level but we had in this release we",
    "start": "336770",
    "end": "343639"
  },
  {
    "text": "had 15 introduced as new alpha features that are coming into this this is typically the ones that people are very",
    "start": "343639",
    "end": "350180"
  },
  {
    "text": "interested to know about because these are the things that are gonna be extending kubernetes in a new way that",
    "start": "350180",
    "end": "355939"
  },
  {
    "text": "you can gain more value out of then we're looking at some of the features that have graduated from previous",
    "start": "355939",
    "end": "362749"
  },
  {
    "text": "versions into a beta state which means that they have gone through another release cycle of testing and and bug",
    "start": "362749",
    "end": "370009"
  },
  {
    "text": "fixing and stuff like that and then we also have eight that have been graduated to stable this is in my opinion this is",
    "start": "370009",
    "end": "377060"
  },
  {
    "text": "a great thing because we only had to graduate the stable in 115 this just gives you a better indication of the",
    "start": "377060",
    "end": "383240"
  },
  {
    "text": "trajectory trajectory of where everything's going inside of kubernetes as we progress more towards a stable",
    "start": "383240",
    "end": "389750"
  },
  {
    "text": "platform instead of always trying to introduce a bunch of new features all the time this time we have a bunch of",
    "start": "389750",
    "end": "395330"
  },
  {
    "text": "enhancements that have graduated to a stable state so let's again let's look",
    "start": "395330",
    "end": "401210"
  },
  {
    "text": "at three of the highlights in our opinion some of the biggest ones that kind of came out of here first was a",
    "start": "401210",
    "end": "408289"
  },
  {
    "text": "bunch that were happening with custom resource definitions and that's gonna all take place as we go through and dive",
    "start": "408289",
    "end": "414349"
  },
  {
    "text": "down into each individual cig and we'll be able to see a bunch of CRD mechanisms",
    "start": "414349",
    "end": "422300"
  },
  {
    "text": "all moved to stable with inside the 116 release next is looking at the ipv4 and",
    "start": "422300",
    "end": "428240"
  },
  {
    "start": "425000",
    "end": "425000"
  },
  {
    "text": "ipv6 the dual stack support the adoption of ipv6 has increased over recent years",
    "start": "428240",
    "end": "434330"
  },
  {
    "text": "and people like yourselves are requesting this type of support with inside of kubernetes and this was added",
    "start": "434330",
    "end": "440870"
  },
  {
    "text": "as an alpha feature in communities 1.9 to have ipv6 only clusters and that gave",
    "start": "440870",
    "end": "447529"
  },
  {
    "text": "us the ability to run things either in ipv4 or ipv6 but didn't really have a",
    "start": "447529",
    "end": "453649"
  },
  {
    "text": "combination or there is this kind of thing called a single pod IP aware dual",
    "start": "453649",
    "end": "458750"
  },
  {
    "text": "stack configuration but this had a bunch of limitations from CNI networking plugins system pods from the API and",
    "start": "458750",
    "end": "466729"
  },
  {
    "text": "controller server managed there were types of like Service IPS had to be either all ipv4 or ipv6 when the",
    "start": "466729",
    "end": "474470"
  },
  {
    "text": "cluster so it really didn't encapsulate a lot of things that people were really looking for",
    "start": "474470",
    "end": "480110"
  },
  {
    "text": "and so this enhancement is adding dual stack or single family services support to these clusters so what it's doing is",
    "start": "480110",
    "end": "486740"
  },
  {
    "text": "its providing ipv4 to ipv6 to ipv6",
    "start": "486740",
    "end": "492290"
  },
  {
    "text": "communication to and from within a kubernetes cluster and you can do this by providing dual stack addresses for",
    "start": "492290",
    "end": "499490"
  },
  {
    "text": "the pods and the nodes but you can restrict service IP is to be a single",
    "start": "499490",
    "end": "504680"
  },
  {
    "text": "family if you will and so as we start going through here the kubernetes endpoints the API supports only a single",
    "start": "504680",
    "end": "512120"
  },
  {
    "text": "IP address for endpoint then you have the addition of dual stack features so you have pods that are serving as",
    "start": "512120",
    "end": "517940"
  },
  {
    "text": "backends for kubernetes services so now you can have both ipv4 and ipv6 addresses the cube proxy is going to be",
    "start": "517940",
    "end": "525890"
  },
  {
    "text": "modified to drive IP tables and IP six tables in parallel and that's gonna require the implementation of a proxy or",
    "start": "525890",
    "end": "533150"
  },
  {
    "text": "interface in the cube proxy server that is going to modify and track changes in both the tables as well and this is also",
    "start": "533150",
    "end": "540410"
  },
  {
    "text": "required to expose services in both ipv4 and ipv6 core DNS is also making changes",
    "start": "540410",
    "end": "546320"
  },
  {
    "text": "to support multiple address endpoints and there's a lot more considerations about ingress and load balancers that",
    "start": "546320",
    "end": "552950"
  },
  {
    "text": "weren't mentioned here so if you want to learn more please go to the issue and you can read more there as well now",
    "start": "552950",
    "end": "560780"
  },
  {
    "start": "560000",
    "end": "560000"
  },
  {
    "text": "extending and trying to say really like PVC cloning is is something that we had",
    "start": "560780",
    "end": "566270"
  },
  {
    "text": "kind of touched on in 115 because coming from a administrator background you kind",
    "start": "566270",
    "end": "571850"
  },
  {
    "text": "of see this is a pretty common tool because you see it in most storage devices it's a day that you know you see",
    "start": "571850",
    "end": "578300"
  },
  {
    "text": "them having the ability to be able to duplicate data and you can do this for multi two different reasons whether it's",
    "start": "578300",
    "end": "584420"
  },
  {
    "text": "for desks or disaster recovery or whether it's to test data out on a new",
    "start": "584420",
    "end": "590060"
  },
  {
    "text": "type of pod or a new type of application whatever it is and just understand that clones are different than snapshots so",
    "start": "590060",
    "end": "596210"
  },
  {
    "text": "clones are going to resolve in a new duplicate volume that's me",
    "start": "596210",
    "end": "601430"
  },
  {
    "text": "vision from an existing volume that's already with inside of kubernetes and as we start going through here",
    "start": "601430",
    "end": "607339"
  },
  {
    "text": "the snapshots in their hand are gonna result really as a point in time copy of a volume that is itself not a usable",
    "start": "607339",
    "end": "615110"
  },
  {
    "text": "volume from there and so that's that can be used for vision a new volume or to restore the existing volume to a",
    "start": "615110",
    "end": "621800"
  },
  {
    "text": "previous state so the storage sig identified clone operations as one of those critical functionalities for many",
    "start": "621800",
    "end": "628459"
  },
  {
    "text": "stateful workloads that we all want so maybe you are a database administrator and you want to duplicate that database",
    "start": "628459",
    "end": "634670"
  },
  {
    "text": "volume or perhaps that you want to figure out a way to trigger these clone",
    "start": "634670",
    "end": "639770"
  },
  {
    "text": "operations with inside of the kubernetes api and so kubernetes users can now handle this without having can go around",
    "start": "639770",
    "end": "646520"
  },
  {
    "text": "the committee's API and this is enabled in the persistent volume claim",
    "start": "646520",
    "end": "651820"
  },
  {
    "text": "datasource field and it's adding support for the specifying for specifying existing this persistent volume claims",
    "start": "651820",
    "end": "658880"
  },
  {
    "text": "in that field and that is going to be the volume that you would want to clone",
    "start": "658880",
    "end": "664450"
  },
  {
    "text": "so with this there's no new objects that are being introduced to enable cloning instead this particular field in the",
    "start": "664450",
    "end": "671690"
  },
  {
    "text": "volume persistent line claim object is expanded to be able to accept the name of an existing persistent volume claim",
    "start": "671690",
    "end": "678800"
  },
  {
    "text": "in the same namespace and so it's important to note though that from your perspective as a user a clone is just",
    "start": "678800",
    "end": "686690"
  },
  {
    "text": "another persistent volume and a persistent volume claim the only difference is that the persistent volume",
    "start": "686690",
    "end": "692390"
  },
  {
    "text": "is being populated with the contents of another persistent volume at the creation time and after that it behaves",
    "start": "692390",
    "end": "699470"
  },
  {
    "text": "exactly the same way that any other kubernetes persistent volume does and just adheres to those same behaviors and",
    "start": "699470",
    "end": "705829"
  },
  {
    "text": "rules just to note though that cloning is only supported right now for CSI drivers it's not for entry or 4 flex",
    "start": "705829",
    "end": "713209"
  },
  {
    "text": "volumes so to use this cloning feature you have to ensure that your CSI driver is implementing this on the cluster that",
    "start": "713209",
    "end": "721520"
  },
  {
    "text": "is deployed so if we look at this example that we have here it shows that we have a persistent volume claim with",
    "start": "721520",
    "end": "727459"
  },
  {
    "text": "PVC one that exists in the name space of my NS or mine namespace and has a size",
    "start": "727459",
    "end": "733459"
  },
  {
    "text": "that is less than to 10 gigabytes and this is going to result in a new independent persistence",
    "start": "733459",
    "end": "739930"
  },
  {
    "text": "volume and persistent volume claim called PVC to on the backend and that is gonna be a duplicate of this data that",
    "start": "739930",
    "end": "746500"
  },
  {
    "text": "existed on PVC one so just kind of gives you an idea of what this looks like going through so now let's go ahead and",
    "start": "746500",
    "end": "754690"
  },
  {
    "text": "we will dive in to see our D mania if you will and we're gonna look at every individual cig that had new enhancements",
    "start": "754690",
    "end": "762190"
  },
  {
    "text": "that came into this it's gonna go in alphabetical order so if you're waiting for Windows you can wittily it so here",
    "start": "762190",
    "end": "768790"
  },
  {
    "text": "we go for API machinery so for people that aren't familiar with C RDS or",
    "start": "768790",
    "end": "774760"
  },
  {
    "start": "769000",
    "end": "769000"
  },
  {
    "text": "custom resource definitions let's kind of set a baseline here so a resource is",
    "start": "774760",
    "end": "780639"
  },
  {
    "text": "an endpoint in the kubernetes api that stores a collection of api objects and that could be of a certain kind so for",
    "start": "780639",
    "end": "787690"
  },
  {
    "text": "example the built in pods resource contains a collection of pod objects now a custom resource is an extension of the",
    "start": "787690",
    "end": "795550"
  },
  {
    "text": "kubernetes api but it's not necessarily available on every kubernetes cluster but represents a customization of your",
    "start": "795550",
    "end": "803680"
  },
  {
    "text": "particular criminate installation and today there's all kinds of distributions out there that are using crts to kind of",
    "start": "803680",
    "end": "810610"
  },
  {
    "text": "put their own sort of special sauce on it now with CR DS going officially stable we are gonna start seeing you to",
    "start": "810610",
    "end": "817420"
  },
  {
    "text": "come even more prevalent inside of the kubernetes ecosystem and with CR DD",
    "start": "817420",
    "end": "824620"
  },
  {
    "start": "823000",
    "end": "823000"
  },
  {
    "text": "there's also new the the open API schema is moving to stable so CRD authors can",
    "start": "824620",
    "end": "830050"
  },
  {
    "text": "create their CR DS using the open API version 3 schema and this is gonna enable server-side validation for custom",
    "start": "830050",
    "end": "837279"
  },
  {
    "text": "resources and this validation format is compatible for creating these documentation for custom resources which",
    "start": "837279",
    "end": "844389"
  },
  {
    "text": "can be used by clients like cube cuddle and you can perform client-side validation like create and apply schema",
    "start": "844389",
    "end": "851560"
  },
  {
    "text": "explanation like cute cuddle explained and client generation and this enhancer",
    "start": "851560",
    "end": "856630"
  },
  {
    "text": "will be using the open API version 3 schema to create you publish the open API documentation for these custom",
    "start": "856630",
    "end": "863800"
  },
  {
    "text": "resources as well so the sub resources for",
    "start": "863800",
    "end": "868930"
  },
  {
    "start": "867000",
    "end": "867000"
  },
  {
    "text": "custom resources is also graduating this table and these objects are defined by",
    "start": "868930",
    "end": "874720"
  },
  {
    "text": "CR DS called custom resources however it is one of the most requested features and adds a slash status and a slash",
    "start": "874720",
    "end": "882399"
  },
  {
    "text": "scale sub resource for custom resources if the status sub resource is enabled",
    "start": "882399",
    "end": "888399"
  },
  {
    "text": "the main end point will ignore all changes in the status sub path it the spec does not change and the meta",
    "start": "888399",
    "end": "895810"
  },
  {
    "text": "generation is not updated now for the scale behavior the number of custom resources can easily scale up or down",
    "start": "895810",
    "end": "902800"
  },
  {
    "text": "depending on the replicas field set that is that that is set inside of the spec sub path moving on with even more CRD",
    "start": "902800",
    "end": "912430"
  },
  {
    "start": "911000",
    "end": "911000"
  },
  {
    "text": "stuff so we have defaulting and pruning for custom resources now it's a little bit different because pruning is moving",
    "start": "912430",
    "end": "918339"
  },
  {
    "text": "to stable while defaulting is moving to beta in 1/16 yet they are all enveloped inside of a single enhancement tracking",
    "start": "918339",
    "end": "925300"
  },
  {
    "text": "issue so defaulting is kind of a fundamental step in processing API",
    "start": "925300",
    "end": "930750"
  },
  {
    "text": "objects in the request pipeline of the cube API server and defaulting",
    "start": "930750",
    "end": "936310"
  },
  {
    "text": "happenings during serial that during the D serialization period and it's implemented for most of the native",
    "start": "936310",
    "end": "942880"
  },
  {
    "text": "kubernetes api types and it plays a crucial role for API compatibility when adding new fields however custom",
    "start": "942880",
    "end": "949810"
  },
  {
    "text": "resources do not support this natively and this is all about adding support for specifying default values for that open",
    "start": "949810",
    "end": "957220"
  },
  {
    "text": "API version 3 schema that we have talked about inside of the CR D manifest and",
    "start": "957220",
    "end": "962440"
  },
  {
    "text": "now when we have this deep this new schema is gonna have a support for a default field with any sort of arbitrary",
    "start": "962440",
    "end": "970060"
  },
  {
    "text": "JSON values that we can put into it and now what we can do is we can apply these default values during the",
    "start": "970060",
    "end": "975730"
  },
  {
    "text": "deserialization the same way as native resources do and so custom resources",
    "start": "975730",
    "end": "980800"
  },
  {
    "text": "store these these JSON data values without following the typical kubernetes api behavior to prune these unknown",
    "start": "980800",
    "end": "987130"
  },
  {
    "text": "fields and this makes the arity is a little bit different because it could also lead to potential you know security",
    "start": "987130",
    "end": "993399"
  },
  {
    "text": "and general data consistency concerns because it is unclear what is being stored inside of SED and this adds",
    "start": "993399",
    "end": "1000450"
  },
  {
    "text": "pruning of all fields which are not specified in that open API validation",
    "start": "1000450",
    "end": "1005550"
  },
  {
    "text": "schema excuse me and so pruning is now moving forward to stable 116 and this is",
    "start": "1005550",
    "end": "1011850"
  },
  {
    "text": "going to enforce consistency of the data stored inside of at CD and this means",
    "start": "1011850",
    "end": "1017220"
  },
  {
    "text": "that objects cannot suddenly render themselves unaccessible because of unexpected data breaking decoding or",
    "start": "1017220",
    "end": "1023520"
  },
  {
    "text": "anything of that nature so even if unexpected data with inside of at CD is of the right type and does not break",
    "start": "1023520",
    "end": "1030270"
  },
  {
    "text": "decoding it has not gone through the validation and probably an admission webhook either does not exist for these",
    "start": "1030270",
    "end": "1036930"
  },
  {
    "text": "CR DS or it won't have or it wouldn't have been implementing the pruning behavior in itself and so pruning at",
    "start": "1036930",
    "end": "1044010"
  },
  {
    "text": "this decoding step is enforcing this type of scenario to happen and really it's a countermeasure to take care of",
    "start": "1044010",
    "end": "1051510"
  },
  {
    "text": "security tax that could make use of knowledge of safe future versions of api's with new security relevant fields",
    "start": "1051510",
    "end": "1058530"
  },
  {
    "text": "so if you take this into that context without pruning an attacker could prepare a custom resource with",
    "start": "1058530",
    "end": "1064530"
  },
  {
    "text": "privileged fields that are set and on the upgrade of a cluster or upgrade on a version of that cluster these fields",
    "start": "1064530",
    "end": "1070740"
  },
  {
    "text": "could become alive and lead to some unknown or unallowable and so moving on",
    "start": "1070740",
    "end": "1078840"
  },
  {
    "start": "1078000",
    "end": "1078000"
  },
  {
    "text": "to the web book version for customers sources also graduating disabled plays well at the previous slide on defaulting",
    "start": "1078840",
    "end": "1085440"
  },
  {
    "text": "and pruning because you can default and prune with a web book conversion but it's not a native style and requires the",
    "start": "1085440",
    "end": "1091290"
  },
  {
    "text": "additional work to make that happen and so the existing problem is when a web hook needs to make a request to another",
    "start": "1091290",
    "end": "1096900"
  },
  {
    "text": "service but the API hasn't progressed or changed so CRD users they want to be",
    "start": "1096900",
    "end": "1102060"
  },
  {
    "text": "certain that they can evolve their API before they start down the path of developing a CR D and a controller and",
    "start": "1102060",
    "end": "1109440"
  },
  {
    "text": "so this web hook conversion allows developers to evolve their API while using backwards compatibility of",
    "start": "1109440",
    "end": "1116670"
  },
  {
    "text": "versioned API resources and this allows objects or services to hold multiple",
    "start": "1116670",
    "end": "1121800"
  },
  {
    "text": "versions at the same exact time and convert that one web book from one version to another based on its",
    "start": "1121800",
    "end": "1127920"
  },
  {
    "text": "particular need and continue on with even more stability features as the",
    "start": "1127920",
    "end": "1133800"
  },
  {
    "start": "1130000",
    "end": "1130000"
  },
  {
    "text": "Admission web hooks and these are widely being used for extending kubernetes and it had been beta for",
    "start": "1133800",
    "end": "1141000"
  },
  {
    "text": "three releases up until now and it's a way to extend communities by putting a hook on an object during the creation",
    "start": "1141000",
    "end": "1146940"
  },
  {
    "text": "modification or deletion process and so this Web book can mutate or validate the",
    "start": "1146940",
    "end": "1152279"
  },
  {
    "text": "object if you want to as well and this supports namespace selectors and this is",
    "start": "1152279",
    "end": "1157350"
  },
  {
    "text": "great because it's almost like an all or nothing in that namespace so you may not want to get all the activity that's",
    "start": "1157350",
    "end": "1163440"
  },
  {
    "text": "happening so you want to be able to extend that to include a single object selector if you want to as well and",
    "start": "1163440",
    "end": "1170700"
  },
  {
    "start": "1170000",
    "end": "1170000"
  },
  {
    "text": "moving on to not necessarily just CR DS but moving into another feature called",
    "start": "1170700",
    "end": "1176700"
  },
  {
    "text": "bookmark support we had talked about in 115 but this is graduating this beta in 116 and this is talking about the watch",
    "start": "1176700",
    "end": "1184529"
  },
  {
    "text": "API and this is one of the fundamentals of the kubernetes api and it's a watch",
    "start": "1184529",
    "end": "1190710"
  },
  {
    "text": "api is there to retrieve a collection of resources using a list and then",
    "start": "1190710",
    "end": "1195990"
  },
  {
    "text": "initiating a watch to start from a particular resource version returned by that list operation so if a client watch",
    "start": "1195990",
    "end": "1203730"
  },
  {
    "text": "is disconnected a new one can be restarted and the last one is returning a particular resource version and now",
    "start": "1203730",
    "end": "1210419"
  },
  {
    "text": "but the bookmark support is going to do is it's trying to make the API server",
    "start": "1210419",
    "end": "1216149"
  },
  {
    "text": "performance a little bit better so if we take this and some of the problems that kind of existed was that different",
    "start": "1216149",
    "end": "1223020"
  },
  {
    "text": "scalability tests saw that restarting these watches caused a significant load on the API server when it was watching a",
    "start": "1223020",
    "end": "1230460"
  },
  {
    "text": "small percentage of changes so in extreme clay in in shrink cases you could be you know lead to the point",
    "start": "1230460",
    "end": "1236700"
  },
  {
    "text": "where you're falling out of a history window and a particular resource version to old errors could potentially occur",
    "start": "1236700",
    "end": "1242460"
  },
  {
    "text": "and now the reason is that we want this last item received by The Watcher to have a resource version of our v1 and we",
    "start": "1242460",
    "end": "1250020"
  },
  {
    "text": "may know that that there's not going any changes this particular given watcher and we want to bump that to say an rb2",
    "start": "1250020",
    "end": "1256919"
  },
  {
    "text": "but we don't have any way of communicating that to the watcher so as a result when restarting a watch the",
    "start": "1256919",
    "end": "1263340"
  },
  {
    "text": "client again sends this particular our v1 as a starting point and we process all the events with that resource",
    "start": "1263340",
    "end": "1269810"
  },
  {
    "text": "in between rb1 and rb2 to have that again and so the goal here is to reduce",
    "start": "1269810",
    "end": "1275570"
  },
  {
    "text": "the load on the API server by minimizing the amount of unnecessary watch events that need to be processed after",
    "start": "1275570",
    "end": "1282320"
  },
  {
    "text": "restarting a watch and so this is gonna be called a new event called a bookmark and this type of bookmark is gonna",
    "start": "1282320",
    "end": "1289220"
  },
  {
    "text": "represent information that all objects up to a given resource version have processed for a given watcher so even if",
    "start": "1289220",
    "end": "1296600"
  },
  {
    "text": "the last event of the other types contain the object with the resource version one receiving a bookmark with",
    "start": "1296600",
    "end": "1302570"
  },
  {
    "text": "the resource version two means that there aren't any interesting objects for that watcher in between those states and",
    "start": "1302570",
    "end": "1309070"
  },
  {
    "start": "1309000",
    "end": "1309000"
  },
  {
    "text": "then looking at server-side apply graduating the beta with inside of here everybody knows that cube cut' will",
    "start": "1309070",
    "end": "1315470"
  },
  {
    "text": "apply is a core part of the community's config workflow but it can be buggy and",
    "start": "1315470",
    "end": "1320900"
  },
  {
    "text": "it can be hard to fix from time to time and so you end up with some potential conflicts if a user performs various",
    "start": "1320900",
    "end": "1327890"
  },
  {
    "text": "actions like doing a post operation but then something changes during the post",
    "start": "1327890",
    "end": "1333260"
  },
  {
    "text": "operation or during the applying phase and this functionality will be regular lized and move to the control plane and",
    "start": "1333260",
    "end": "1339800"
  },
  {
    "text": "that's what this is gonna be able to do and now apply is invoked by sending a certain content type with the verb patch",
    "start": "1339800",
    "end": "1346790"
  },
  {
    "text": "on this one and you can read a lot more about this one with inside of this particular enhancement issue it's been",
    "start": "1346790",
    "end": "1353030"
  },
  {
    "text": "around for a while and so always good to have a little bit more eyes on it if this is something that is interesting",
    "start": "1353030",
    "end": "1358370"
  },
  {
    "text": "you as well the last one here with inside of this section is deprecating",
    "start": "1358370",
    "end": "1365480"
  },
  {
    "start": "1360000",
    "end": "1360000"
  },
  {
    "text": "and remove the self link function here and there's been no use of self link for",
    "start": "1365480",
    "end": "1371120"
  },
  {
    "text": "a while so there's no compelling reason for having self link field in there so",
    "start": "1371120",
    "end": "1376400"
  },
  {
    "text": "when modifying or reading an object from the API server self link is set to exactly the year-old that it was used",
    "start": "1376400",
    "end": "1383150"
  },
  {
    "text": "for form that operation and so as a part of making sure that we are following the",
    "start": "1383150",
    "end": "1388310"
  },
  {
    "text": "kubernetes process for demoting and deprecating features this field will be",
    "start": "1388310",
    "end": "1393710"
  },
  {
    "text": "deprecated in one year all right moving on to sig cloud provider so",
    "start": "1393710",
    "end": "1401210"
  },
  {
    "start": "1401000",
    "end": "1401000"
  },
  {
    "text": "as everybody kind of knows that the entry cloud provider implementations are being removed in the future and this is",
    "start": "1401210",
    "end": "1408500"
  },
  {
    "text": "gonna involve a large amount of code that is used in many places with inside of kubernetes and entry in itself so in",
    "start": "1408500",
    "end": "1416090"
  },
  {
    "text": "order to prepare this to eventually be completely vendor agnostic it's gonna be",
    "start": "1416090",
    "end": "1421280"
  },
  {
    "text": "helpful to see what that removal actually entails and to verify that communities will continue to function",
    "start": "1421280",
    "end": "1426680"
  },
  {
    "text": "without it and doing so it's a it's a bit tricky without ensuring that this entry provider code is not being used in",
    "start": "1426680",
    "end": "1434510"
  },
  {
    "text": "some unexpected fashion such as a side channel during init methods or anything like that so what this is going to be",
    "start": "1434510",
    "end": "1441740"
  },
  {
    "text": "doing is building kubernetes binaries without the entry cloud provider packages and this can allow verification",
    "start": "1441740",
    "end": "1448190"
  },
  {
    "text": "and provide additional experimentation to smaller and cheaper binaries for",
    "start": "1448190",
    "end": "1453200"
  },
  {
    "text": "anybody that's interested and just using out of tree providers or perhaps maybe using no provider based clusters and so",
    "start": "1453200",
    "end": "1460130"
  },
  {
    "text": "the goal is to enable kubernetes without entry cloud providers and without forking so this helps test out out a",
    "start": "1460130",
    "end": "1466550"
  },
  {
    "text": "tree providers with the simulation of the future removal of the entry code and enabled experimentation with in cleat",
    "start": "1466550",
    "end": "1473750"
  },
  {
    "text": "with sorry with cloud provider list clusters so if you're doing cloud providers clusters be cool to kind of",
    "start": "1473750",
    "end": "1479390"
  },
  {
    "text": "see some of those use cases out there so if you have something feel free to share it on the communities community I think",
    "start": "1479390",
    "end": "1485810"
  },
  {
    "text": "that'd be really cool to see so sig cluster lifecycle so cube ATM for",
    "start": "1485810",
    "end": "1492560"
  },
  {
    "start": "1491000",
    "end": "1491000"
  },
  {
    "text": "Windows is net new for alpha so anybody that maybe we're jumping the gun with Windows a little bit but you kind of get",
    "start": "1492560",
    "end": "1499070"
  },
  {
    "text": "to see something that's happening here because back in communities 114 was the official support added for Windows",
    "start": "1499070",
    "end": "1505340"
  },
  {
    "text": "containers however up until this point there's been no official tool to actually join Windows nodes to a cluster",
    "start": "1505340",
    "end": "1512210"
  },
  {
    "text": "except going through a series of PowerShell scripts and so this solution is going to be a part of actually making",
    "start": "1512210",
    "end": "1519320"
  },
  {
    "text": "some more of these scripts but writing their config files at the same time and that's proven to be cumbersome and a",
    "start": "1519320",
    "end": "1525080"
  },
  {
    "text": "huge pain point for some of the Windows adoption you know on Linux cubed EMS is quickly able to join those the cluster",
    "start": "1525080",
    "end": "1532010"
  },
  {
    "text": "and the intent of this is propose a design that implements some of that same functionality for Windows so you're",
    "start": "1532010",
    "end": "1538550"
  },
  {
    "text": "gonna see a PowerShell script to install and run on kubernetes prerequisites for",
    "start": "1538550",
    "end": "1543590"
  },
  {
    "text": "Windows nodes and it should also be noticed at this time that this document and this this enhancement proposes the",
    "start": "1543590",
    "end": "1550190"
  },
  {
    "text": "enablement for support for Windows worker nodes utilizing cube ATM and you're gonna see this as this continues",
    "start": "1550190",
    "end": "1556730"
  },
  {
    "text": "to progress so if you are looking into utilizing some more Windows nodes workers make sure you go and check out",
    "start": "1556730",
    "end": "1563660"
  },
  {
    "text": "the documentation it's already been updated so you can kind of get started using cube idiom for Windows already and",
    "start": "1563660",
    "end": "1570250"
  },
  {
    "start": "1570000",
    "end": "1570000"
  },
  {
    "text": "so if you are also using cube ATM to build your clusters and perhaps you want",
    "start": "1570250",
    "end": "1576410"
  },
  {
    "text": "to do some more tweaking and configuration you can now do that utilizing customize as a part of that",
    "start": "1576410",
    "end": "1583190"
  },
  {
    "text": "because cube idiom today only allows you to define a limited set of configuration",
    "start": "1583190",
    "end": "1588440"
  },
  {
    "text": "options for the cluster via the component configurations or the corresponding CLI flags and this really",
    "start": "1588440",
    "end": "1596540"
  },
  {
    "text": "does provide an abstraction to define configuration settings at the cluster level and it defines a limited set of",
    "start": "1596540",
    "end": "1602870"
  },
  {
    "text": "configurations of the node level using these different types of options as well and this is abstract and this",
    "start": "1602870",
    "end": "1608540"
  },
  {
    "text": "abstraction does work well for most common clustered configurations and use cases but there will be other use cases",
    "start": "1608540",
    "end": "1614980"
  },
  {
    "text": "where the cube ATM components just won't be able to take care of it such as poss",
    "start": "1614980",
    "end": "1620690"
  },
  {
    "text": "like today you can't add side cars you can't alter the timeouts for liveness pros and live in those probes inside the",
    "start": "1620690",
    "end": "1627530"
  },
  {
    "text": "control plan components and so forth and so this is going to reduce a new feature that will enable you to be able to have",
    "start": "1627530",
    "end": "1633800"
  },
  {
    "text": "full control of static pod manifest generated by cube ATM at the node level in itself versus the queue minion",
    "start": "1633800",
    "end": "1640850"
  },
  {
    "text": "component configuration that allows mostly cluster wide configurations on the control plane as well as the Etsy D",
    "start": "1640850",
    "end": "1647200"
  },
  {
    "text": "arguments as well and so this new enhancement should not be required to",
    "start": "1647200",
    "end": "1652910"
  },
  {
    "text": "manually alter any static pod manifests that are stored with inside of Etsy kubernetes manifest after the the cube",
    "start": "1652910",
    "end": "1660530"
  },
  {
    "text": "ATM init enjoy so you can utilize customize and make that happen now for you moving on to cig instrumentation",
    "start": "1660530",
    "end": "1669500"
  },
  {
    "start": "1669000",
    "end": "1669000"
  },
  {
    "text": "so there's a huge metrics overhaul that's now taking place inside of 116",
    "start": "1669500",
    "end": "1674600"
  },
  {
    "text": "and the number of metrics with inside of kubernetes today there's a lot of them",
    "start": "1674600",
    "end": "1679850"
  },
  {
    "text": "that just do not follow the official criminalization instrumentation guidelines and this is for a number of",
    "start": "1679850",
    "end": "1685610"
  },
  {
    "text": "reasons some of the metrics were created before the guidelines implemented which happened around two years ago some of it",
    "start": "1685610",
    "end": "1692630"
  },
  {
    "text": "is just missing it in code reviews but beyond that some of the instrumentation guidelines there's several violations of",
    "start": "1692630",
    "end": "1699409"
  },
  {
    "text": "the Prometheus instrumentation best practices so in order to have consistently named and high quality",
    "start": "1699409",
    "end": "1705830"
  },
  {
    "text": "metrics this is going to start overhauling and making those metrics being exposed by communities consistent",
    "start": "1705830",
    "end": "1712549"
  },
  {
    "text": "with the rest of the ecosystem and so what we've even moving further beyond",
    "start": "1712549",
    "end": "1718039"
  },
  {
    "text": "this you can actually start thinking of how can we even join these metrics which shouldn't be as difficult anymore as",
    "start": "1718039",
    "end": "1724789"
  },
  {
    "text": "well so one of the examples I'll kind of go through here some of the you know",
    "start": "1724789",
    "end": "1731120"
  },
  {
    "text": "there's a number of components that that can use a sync so one of the other mechanisms to ensure that you don't want",
    "start": "1731120",
    "end": "1736820"
  },
  {
    "text": "to panic or anything like that is when registering metrics instead of a metrics registry it should be passed each",
    "start": "1736820",
    "end": "1743390"
  },
  {
    "text": "component in order to explicitly register those metrics instead of through init methods or other global",
    "start": "1743390",
    "end": "1749570"
  },
  {
    "text": "executions or something like that and so this is gonna make a step closer than having those stability guarantees for",
    "start": "1749570",
    "end": "1755210"
  },
  {
    "text": "communities around those metrics on the sea advisory side there needs to be consistent labeling the API server",
    "start": "1755210",
    "end": "1761780"
  },
  {
    "text": "histogram latency runs from about 125 milliseconds to 8 seconds and this range",
    "start": "1761780",
    "end": "1767419"
  },
  {
    "text": "doesn't accurately model most of the API server request latency which could run as low as 1 millisecond forgets or as",
    "start": "1767419",
    "end": "1774470"
  },
  {
    "text": "high as 60 seconds before hitting the API server for global timeouts and other",
    "start": "1774470",
    "end": "1780049"
  },
  {
    "text": "things like the scheduler and proxy and API server all needs some sort of conformance changes as well for cleaning",
    "start": "1780049",
    "end": "1786740"
  },
  {
    "text": "out some of these deprecated metrics and we're also gonna kind of see that the client go metrics needs its work queue",
    "start": "1786740",
    "end": "1792620"
  },
  {
    "text": "metrics to follow the Prometheus best practices in naming conventions so if you are on the outside looking in from a",
    "start": "1792620",
    "end": "1800799"
  },
  {
    "text": "metric standpoint and you are our polling metrics from kubernetes this is something that you should probably",
    "start": "1800799",
    "end": "1806180"
  },
  {
    "text": "take a look at to see if your product or feature anything like that can utilize this as well moving on to cig network",
    "start": "1806180",
    "end": "1813470"
  },
  {
    "text": "since we already hit the ipv6 and I before wool stack we'll move on here to looking at the finalize the protection",
    "start": "1813470",
    "end": "1820250"
  },
  {
    "start": "1814000",
    "end": "1814000"
  },
  {
    "text": "for service load balancers this is graduating to stable and are sorry to beta in 116 and this is created because",
    "start": "1820250",
    "end": "1827720"
  },
  {
    "text": "there are various cases where a service controller can leave orphaned load",
    "start": "1827720",
    "end": "1833420"
  },
  {
    "text": "balancer resources after these services are deleted and it's worth to note that it's happy it's better to have a",
    "start": "1833420",
    "end": "1839660"
  },
  {
    "text": "mechanism to ensure the cleanup of these load balancer resources and so this is where this finalizar service comes in",
    "start": "1839660",
    "end": "1845930"
  },
  {
    "text": "and this will be attached to any service that has the type load balancer if the cluster has the cloud provider",
    "start": "1845930",
    "end": "1851720"
  },
  {
    "text": "integration enabled so fun pond the deletion of that particular service the",
    "start": "1851720",
    "end": "1856910"
  },
  {
    "text": "actual deletion of the resource will be blocked until this finalizar is removed and this finalizar will not be removed",
    "start": "1856910",
    "end": "1862760"
  },
  {
    "text": "until the cleanup of the load balancer resources are considered finished by the service controller itself the in point",
    "start": "1862760",
    "end": "1871310"
  },
  {
    "start": "1871000",
    "end": "1871000"
  },
  {
    "text": "slice API this is net new alphas 116 as well and in the current endpoints API",
    "start": "1871310",
    "end": "1877460"
  },
  {
    "text": "one of the object instance contains all of the engine and points of a particular",
    "start": "1877460",
    "end": "1882710"
  },
  {
    "text": "service so whenever a single pod in a service is added updated or deleted the",
    "start": "1882710",
    "end": "1888740"
  },
  {
    "text": "whole endpoints object whether with the other endpoints didn't change or not is recomputed and written to storage with",
    "start": "1888740",
    "end": "1895430"
  },
  {
    "text": "inside of at CD and then sent to all the Watchers like cube proxy and this leads to two major problems so first is",
    "start": "1895430",
    "end": "1902300"
  },
  {
    "text": "storing multiple megabytes of endpoints it can put strain on multiple parts of the system because you don't have a",
    "start": "1902300",
    "end": "1908450"
  },
  {
    "text": "paging system and it's a monolithic kind of watch storage design and the number",
    "start": "1908450",
    "end": "1913550"
  },
  {
    "text": "of max endpoints is bound by the community storage layer which is at CD and that has a hard limit on the size of",
    "start": "1913550",
    "end": "1919760"
  },
  {
    "text": "a single object which is one point five megabytes by default and this means the attempt to write a larger object when",
    "start": "1919760",
    "end": "1926390"
  },
  {
    "text": "that limit hits it will be rejected additionally there's a similar limitation in the watch path in the",
    "start": "1926390",
    "end": "1932420"
  },
  {
    "text": "communities API server so for a kubernetes service if its endpoints object is too large that end point",
    "start": "1932420",
    "end": "1938840"
  },
  {
    "text": "update will not be propagated to the cute proxies and thus iptables and IP vs",
    "start": "1938840",
    "end": "1943970"
  },
  {
    "text": "won't be reprogrammed and so you're gonna have performance segregation in large kubernetes deployments if this",
    "start": "1943970",
    "end": "1949669"
  },
  {
    "text": "happens - so not being able to efficiently read and update these individual endpoint changes can lead to",
    "start": "1949669",
    "end": "1956860"
  },
  {
    "text": "elements not actually being able to basically have their endpoint operations",
    "start": "1956860",
    "end": "1962360"
  },
  {
    "text": "happen so one consideration here is if you put the watch into the picture here",
    "start": "1962360",
    "end": "1968330"
  },
  {
    "text": "the situation becomes even worse as the as this traffic gets multiplied further",
    "start": "1968330",
    "end": "1973400"
  },
  {
    "text": "with the number of watches that you create - and so there's new endpoint slice API will support tens of thousands",
    "start": "1973400",
    "end": "1979880"
  },
  {
    "text": "of back in endpoints and a single service on a cluster with thousands of nodes and it's going to move the API",
    "start": "1979880",
    "end": "1985309"
  },
  {
    "text": "towards a general-purpose back-end discovery API so moving on to cig node",
    "start": "1985309",
    "end": "1992110"
  },
  {
    "text": "the ephemeral containers now if you look at the issue down here it says 277 we've",
    "start": "1992110",
    "end": "1997730"
  },
  {
    "start": "1993000",
    "end": "1993000"
  },
  {
    "text": "moved on we passed the 1,000 issue mark with inside of the enhancements repo so",
    "start": "1997730",
    "end": "2002830"
  },
  {
    "text": "seeing something that has 277 means that this has been around for quite a long time and it's just now being introduced as",
    "start": "2002830",
    "end": "2009400"
  },
  {
    "text": "alpha with inside of 116 and so what does this do well for many developers in some of the",
    "start": "2009400",
    "end": "2016780"
  },
  {
    "text": "native kubernetes applications out there you want to treat kubernetes as an execution platform for binaries that are",
    "start": "2016780",
    "end": "2023470"
  },
  {
    "text": "produced by any type of build system so you can forego scripted OS installation",
    "start": "2023470",
    "end": "2028570"
  },
  {
    "text": "of traditional docker files and instead you might want to copy the output of the build system in from a container image",
    "start": "2028570",
    "end": "2035080"
  },
  {
    "text": "to say scratch or a distro list container image and this gives advantages of having minimal and mutable",
    "start": "2035080",
    "end": "2042010"
  },
  {
    "text": "and smaller size images now the disadvantage of using containers built from scratch is the fact that binary is",
    "start": "2042010",
    "end": "2048878"
  },
  {
    "text": "provided by this don't it makes it difficult for troubleshooting these types of containers and if Rob's folks",
    "start": "2048879",
    "end": "2055600"
  },
  {
    "text": "it becomes the case that a person troubleshooting the application is not unless the person who built it so people",
    "start": "2055600",
    "end": "2060970"
  },
  {
    "text": "who want the ability to attach a known good or automated debugging environment to a pod can now do that as well",
    "start": "2060970",
    "end": "2068790"
  },
  {
    "text": "so looking at pot overhead as something else being new in 116 we all know that",
    "start": "2069110",
    "end": "2075590"
  },
  {
    "start": "2070000",
    "end": "2070000"
  },
  {
    "text": "pods have some resource overhead and in our traditional Linux container or docker approach the accountant overhead",
    "start": "2075590",
    "end": "2082190"
  },
  {
    "text": "is limited to the pause container but that also invokes an overhead that accounts to various system components",
    "start": "2082190",
    "end": "2088370"
  },
  {
    "text": "including the cubelet for controlled loops you have docker you've got kernel for various resources you got fluent v4",
    "start": "2088370",
    "end": "2094370"
  },
  {
    "text": "logs and this current approach is to kind of reserve a chunk of resources for the system components and ignore the",
    "start": "2094370",
    "end": "2100610"
  },
  {
    "text": "overhead from the pause container but this doesn't scale well well with sandbox pods the pod overhead",
    "start": "2100610",
    "end": "2107120"
  },
  {
    "text": "potentially becomes much larger maybe a hundred megabytes and for example Kafka may run as a guest colonel it's got its",
    "start": "2107120",
    "end": "2114530"
  },
  {
    "text": "cada agent init system so on and so forth and since this overhead it's pretty big so it's hard to ignore so we",
    "start": "2114530",
    "end": "2120890"
  },
  {
    "text": "need to account for it and starting from quota enforcement and scheduling and so this new feature is gonna be able to",
    "start": "2120890",
    "end": "2126290"
  },
  {
    "text": "take care of that and actually have that overhead in there as well so the no topology manager is also new within 1/16",
    "start": "2126290",
    "end": "2134090"
  },
  {
    "start": "2130000",
    "end": "2130000"
  },
  {
    "text": "to into date and multiple components with inside the cubelet make decisions about the apology related assignments",
    "start": "2134090",
    "end": "2141500"
  },
  {
    "text": "with inside of here the CPU manager it can make decisions about the set of CPUs",
    "start": "2141500",
    "end": "2147200"
  },
  {
    "text": "and containers allowed to run on it's only implemented as its policy from kubernetes 1.8 as a static one but that",
    "start": "2147200",
    "end": "2155090"
  },
  {
    "text": "doesn't change the assignments for the lifetime of container and then you get the device manager and that makes device",
    "start": "2155090",
    "end": "2161360"
  },
  {
    "text": "assignments to satisfy container resource requirements so generally devices maybe they're attached to one",
    "start": "2161360",
    "end": "2167870"
  },
  {
    "text": "peripheral interconnect so if a device manager and a CPU manager misalign all in communication between the CPU and the",
    "start": "2167870",
    "end": "2174650"
  },
  {
    "text": "device can incur as an additional hop over the processor and you're gonna experience even more latency and you've",
    "start": "2174650",
    "end": "2181100"
  },
  {
    "text": "got things like CNI you've got NICs that include single route IO virtualization these kind of virtualization functions",
    "start": "2181100",
    "end": "2188060"
  },
  {
    "text": "have affinity to particular socket and those have measurable performance ramifications if it's not done properly",
    "start": "2188060",
    "end": "2193910"
  },
  {
    "text": "and so the goal here is to create a preferred socket affinity for containers",
    "start": "2193910",
    "end": "2199640"
  },
  {
    "text": "based on the input from the CPU manager and a device manager and provide an internal",
    "start": "2199640",
    "end": "2204859"
  },
  {
    "text": "interface that they can now integrate to be more topology aware and the cubicles",
    "start": "2204859",
    "end": "2210619"
  },
  {
    "text": "gonna be able to take care of some these components too so for example if a user asked for a fast Network in a",
    "start": "2210619",
    "end": "2217160"
  },
  {
    "text": "virtualized environment it will automatically get all the various pieces coordinated and co-located on a socket",
    "start": "2217160",
    "end": "2223309"
  },
  {
    "text": "like huge pages CPU sets and the network device as well or perhaps if you're",
    "start": "2223309",
    "end": "2228349"
  },
  {
    "text": "doing say neural network training a user can ask for an accelerator device and",
    "start": "2228349",
    "end": "2234470"
  },
  {
    "text": "perhaps a number of exclusive CPUs in order to get the best training performance and this is due to socket",
    "start": "2234470",
    "end": "2240020"
  },
  {
    "text": "alignment of the assigned CPUs and the devices to and for that accelerated advice there could be a number of",
    "start": "2240020",
    "end": "2245930"
  },
  {
    "text": "exclusive cpus in order to get the best training performance - and again this is all gonna do to socket alignment and",
    "start": "2245930",
    "end": "2252950"
  },
  {
    "text": "having the CPU manager and the device manager kind of working in lockstep here",
    "start": "2252950",
    "end": "2260079"
  },
  {
    "start": "2260000",
    "end": "2260000"
  },
  {
    "text": "so adds startup probe liveliness probe hold off for slow starting pods I know",
    "start": "2260079",
    "end": "2265700"
  },
  {
    "text": "it's a long one that this is also new in 116 and this is because you know we have slow starting containers and those refer",
    "start": "2265700",
    "end": "2272990"
  },
  {
    "text": "to ones that require those just a significant amount of time to start this",
    "start": "2272990",
    "end": "2278059"
  },
  {
    "text": "could be because there is data initialization because maybe the first startup takes a lot of time or perhaps",
    "start": "2278059",
    "end": "2284240"
  },
  {
    "text": "it's just a heavy workload and every startup takes a lot of time or perhaps it's just an underpowered or overloaded",
    "start": "2284240",
    "end": "2290990"
  },
  {
    "text": "node and that startup time is dependent upon external factors of actually having",
    "start": "2290990",
    "end": "2296109"
  },
  {
    "text": "processes available and the main problem with this kind of container really works",
    "start": "2296109",
    "end": "2301460"
  },
  {
    "text": "that was from is that they need to give it enough time to start before having the live in this probe fail and that",
    "start": "2301460",
    "end": "2306890"
  },
  {
    "text": "failure threshold time and that which again is gonna trigger a kill by the",
    "start": "2306890",
    "end": "2311990"
  },
  {
    "text": "cubelet before having a chance to be up and so there's ways that we can now handle this situation with the current",
    "start": "2311990",
    "end": "2317750"
  },
  {
    "text": "API but none really provided an answer to actually having a container stuck and",
    "start": "2317750",
    "end": "2322819"
  },
  {
    "text": "deadlock and so what we can do is now we can have this live in this probe hold off for any kind of slope slow pods that",
    "start": "2322819",
    "end": "2330020"
  },
  {
    "text": "are slow to start up now",
    "start": "2330020",
    "end": "2334329"
  },
  {
    "start": "2334000",
    "end": "2334000"
  },
  {
    "text": "runtime class scheduling and this is actually moving to beta in 116 in the",
    "start": "2335230",
    "end": "2340480"
  },
  {
    "text": "initial runtime class implementation it was assumed that the cluster nodes were homogeneous and regardless of runtime",
    "start": "2340480",
    "end": "2346690"
  },
  {
    "text": "classes but it's still possible to run a hit or a genius cluster and pot offers",
    "start": "2346690",
    "end": "2352060"
  },
  {
    "text": "would need to set appropriate node select your rules and toleration that your pods landed on those particular supporting nodes however it's become",
    "start": "2352060",
    "end": "2359320"
  },
  {
    "text": "clear that heterogeneous clusters will not be uncommon and you need to support a better user experience here and the",
    "start": "2359320",
    "end": "2366070"
  },
  {
    "text": "introduction of Windows nodes kind of presents an immediate use case for heterogeneous clusters because some nodes are gonna be running supporting",
    "start": "2366070",
    "end": "2372790"
  },
  {
    "text": "Windows while some are you supporting Linux there's also be inherent differences in the operating systems so it's natural",
    "start": "2372790",
    "end": "2379000"
  },
  {
    "text": "that you want to support different runtimes so for example Windows nodes may support hyper-v sandboxing while",
    "start": "2379000",
    "end": "2385570"
  },
  {
    "text": "linux nodes support kata containers and every native container support is gonna vary on each so with Runcie for linux",
    "start": "2385570",
    "end": "2393220"
  },
  {
    "text": "run HDS for Windows and perhaps some users just wish to keep saying box fork loads and native workloads separate this",
    "start": "2393220",
    "end": "2400569"
  },
  {
    "text": "is again just another example of being able to create this the scheduling so they can kind of create with inside of a",
    "start": "2400569",
    "end": "2407589"
  },
  {
    "text": "single cluster if you need to do that as well so moving on to cig scheduling so with",
    "start": "2407589",
    "end": "2414940"
  },
  {
    "start": "2414000",
    "end": "2414000"
  },
  {
    "text": "inside of kubernetes we can all have even pod spreading as a 1/16 alpha",
    "start": "2414940",
    "end": "2420190"
  },
  {
    "text": "feature that's coming new so incriminate ease you have this affinity thats related to directives that you want to",
    "start": "2420190",
    "end": "2426280"
  },
  {
    "text": "control how pods are scheduled and maybe they're more packed or more scattering however you want to make that happen but",
    "start": "2426280",
    "end": "2432280"
  },
  {
    "text": "right now you're pretty limited in your options for pod affinity so you can have infinite pods be stacked on to a",
    "start": "2432280",
    "end": "2438849"
  },
  {
    "text": "qualifying topology domain or you can have them scheduled onto a single topology domain this can't be an ideal",
    "start": "2438849",
    "end": "2447040"
  },
  {
    "text": "solution especially if you know pods evenly across different topology domains and you can do this because you want",
    "start": "2447040",
    "end": "2453430"
  },
  {
    "text": "high availability or perhaps cost savings and maybe you want to do regular rolling or updates or scaling out",
    "start": "2453430",
    "end": "2459819"
  },
  {
    "text": "replicas and if you do that previously it could become problematic and so the",
    "start": "2459819",
    "end": "2465010"
  },
  {
    "text": "goal is to have even spreading and this is calculated amongst the instead of the apps API such as",
    "start": "2465010",
    "end": "2471220"
  },
  {
    "text": "deployment or replicas replicas set and so this can now be either a hard or soft requirement so as an application",
    "start": "2471220",
    "end": "2478210"
  },
  {
    "text": "developer perhaps you want your application pods to be scheduled on to a specific topology domain as even as",
    "start": "2478210",
    "end": "2485140"
  },
  {
    "text": "possible and that current status is that the pods may be stacked on to a specific",
    "start": "2485140",
    "end": "2490180"
  },
  {
    "text": "top topology domain or maybe you want your pods to not coexist with specific",
    "start": "2490180",
    "end": "2496000"
  },
  {
    "text": "pods and you can do this say such as anti infinity and in some cases it might be favorable to tolerate violating pods",
    "start": "2496000",
    "end": "2503170"
  },
  {
    "text": "but you can be able to say that whether it should or should not okay",
    "start": "2503170",
    "end": "2510760"
  },
  {
    "start": "2510000",
    "end": "2510000"
  },
  {
    "text": "so here's another long one here so extending your requested to capacity ratio priority function to support",
    "start": "2510760",
    "end": "2515950"
  },
  {
    "text": "resource bin packing of extended resources again net new alpha one",
    "start": "2515950",
    "end": "2521740"
  },
  {
    "text": "sixteen here and what we want to be able to do here is we want to run more clothes on communities which use some",
    "start": "2521740",
    "end": "2527770"
  },
  {
    "text": "sort of accelerated devices and we want that default scheduler to spread pods across across them resulting in you know",
    "start": "2527770",
    "end": "2537040"
  },
  {
    "text": "we don't want to have a fragmentation of these extended resources and today you're gonna have that because they may",
    "start": "2537040",
    "end": "2542710"
  },
  {
    "text": "potentially remain independent in a pending state and so what they're gonna do is they can schedule pods using a",
    "start": "2542710",
    "end": "2548230"
  },
  {
    "text": "best fit policy and this is using the requested to capacity ratio this",
    "start": "2548230",
    "end": "2553990"
  },
  {
    "text": "priority function for extended resources so as the graphic shows the default",
    "start": "2553990",
    "end": "2559150"
  },
  {
    "text": "scheduler in most cases will schedule the pods as follows if there is no priority function for an extended",
    "start": "2559150",
    "end": "2565660"
  },
  {
    "text": "resource for bin packing the scheduler should submit to resource jobs on node three as utilization gets higher and",
    "start": "2565660",
    "end": "2572680"
  },
  {
    "text": "this would reduce the fragmentation of an extended resource and reduce the pods in a pending state all right moving on",
    "start": "2572680",
    "end": "2580870"
  },
  {
    "text": "to six storage or chugging right along here so adding resizing support to CSI",
    "start": "2580870",
    "end": "2586030"
  },
  {
    "start": "2583000",
    "end": "2583000"
  },
  {
    "text": "volumes this one should be relatively easy to understand but basically it just means that we can resize volumes with",
    "start": "2586030",
    "end": "2592750"
  },
  {
    "text": "inside of CSI plugins now and these again have to be implemented with inside",
    "start": "2592750",
    "end": "2598420"
  },
  {
    "text": "of CSI and making sure that your CSI adapter is taking part of the spec and then your operation or your",
    "start": "2598420",
    "end": "2605230"
  },
  {
    "text": "profession persistent volume can now become resizable next is looking at",
    "start": "2605230",
    "end": "2610930"
  },
  {
    "start": "2610000",
    "end": "2610000"
  },
  {
    "text": "inline volume support I'm also going through these because a lot of these we hit in 115 previously this is also",
    "start": "2610930",
    "end": "2617560"
  },
  {
    "text": "graduating to beta and 116 and we look at inline volume support because currently in volumes that are backed by",
    "start": "2617560",
    "end": "2624070"
  },
  {
    "text": "CSI drivers can only be used with persistent volume and persistent volume claim objects and so this proposal and",
    "start": "2624070",
    "end": "2631300"
  },
  {
    "text": "this feature is really implementing the support for the ability to nest a CSI volume within pods for ephemeral style",
    "start": "2631300",
    "end": "2639070"
  },
  {
    "text": "for our sorry for ephemeral style drivers so they can be used to inject arbitrary states such as configurations",
    "start": "2639070",
    "end": "2646420"
  },
  {
    "text": "secrets identities variables or any kind of information that you want directly",
    "start": "2646420",
    "end": "2651640"
  },
  {
    "text": "inside of the pause using a mounted volume we also have support for CSI",
    "start": "2651640",
    "end": "2657610"
  },
  {
    "start": "2656000",
    "end": "2656000"
  },
  {
    "text": "plugins on windows nodes so of course this is net new and alpha we can see more things happening with inside of",
    "start": "2657610",
    "end": "2662950"
  },
  {
    "text": "Windows and and so what we wanted to do is we want to see this continue to progress as well so previously for",
    "start": "2662950",
    "end": "2670270"
  },
  {
    "text": "persistent storage requirements for Windows you had to depend on PowerShell based flex volume plugins that maybe",
    "start": "2670270",
    "end": "2677680"
  },
  {
    "text": "they were maintained by Microsoft or somebody else and then they were also only being used over samba or SMB or I",
    "start": "2677680",
    "end": "2685660"
  },
  {
    "text": "scuzzy protocols or you had entry plug-ins for kubernetes with inside the core but as we all know this is starting",
    "start": "2685660",
    "end": "2692590"
  },
  {
    "text": "to become deprecated and we're trying to move things out of tree so support for CSI and kubernetes reached GA status in",
    "start": "2692590",
    "end": "2700420"
  },
  {
    "text": "113 windows was in 114 so the goal is to make sure that window nodes also support",
    "start": "2700420",
    "end": "2705850"
  },
  {
    "text": "CSI plugins so they can get all the benefits that these this ecosystem has to offer",
    "start": "2705850",
    "end": "2710890"
  },
  {
    "text": "for persistent storage requirements and to make sure that windows nodes are seen",
    "start": "2710890",
    "end": "2716020"
  },
  {
    "text": "as a top tier clutter sorry I talked to your hosts as we start going through",
    "start": "2716020",
    "end": "2721750"
  },
  {
    "text": "here and being able to take advantage of these plugins over time alright moving",
    "start": "2721750",
    "end": "2727720"
  },
  {
    "text": "on to sig windows just a few more slides that go here so support for G MSA for",
    "start": "2727720",
    "end": "2733750"
  },
  {
    "start": "2732000",
    "end": "2732000"
  },
  {
    "text": "Windows workloads is moving into beta or group managed service accounts and",
    "start": "2733750",
    "end": "2739059"
  },
  {
    "text": "this introduction actually happened in guru Nettie's 114 and this spec relies",
    "start": "2739059",
    "end": "2745900"
  },
  {
    "text": "on custom resources that needed to be specified through annotations at the pod and a container level and the windows of",
    "start": "2745900",
    "end": "2752589"
  },
  {
    "text": "the plantation of the docker shim and a container runtime interface and the low-level OCI spec can already handle a",
    "start": "2752589",
    "end": "2760119"
  },
  {
    "text": "user name instead of the UID and this is interpreted inside the container to create in process as the intended user",
    "start": "2760119",
    "end": "2767349"
  },
  {
    "text": "this however is not surfaced as a field in the pod container spec that an operator can specify and so this is",
    "start": "2767349",
    "end": "2774730"
  },
  {
    "text": "going to give you the ability to specify the desired user name in the pod container spec asked fields and be able",
    "start": "2774730",
    "end": "2780640"
  },
  {
    "text": "to pass them as configured windows runtime or pass them on to the",
    "start": "2780640",
    "end": "2785769"
  },
  {
    "text": "configured windows during runtime also net new and 116 is being able to run as",
    "start": "2785769",
    "end": "2791410"
  },
  {
    "start": "2787000",
    "end": "2787000"
  },
  {
    "text": "user name for Windows so this API instant - - here will actually capture",
    "start": "2791410",
    "end": "2797410"
  },
  {
    "text": "Windows Boas specific security options from the perspective of the Windows",
    "start": "2797410",
    "end": "2802900"
  },
  {
    "text": "workload identity and containers so we already talked about the ability to sort",
    "start": "2802900",
    "end": "2808750"
  },
  {
    "text": "of talk to have the GMs yes sorry the the GMs a but what this is gonna be able to do is it's going to allow you to",
    "start": "2808750",
    "end": "2816220"
  },
  {
    "text": "cover these fields pertinent to it and actually run the username which is be able to execute that container entry",
    "start": "2816220",
    "end": "2821710"
  },
  {
    "text": "point so again kind of running in tandem with the last slide this is not",
    "start": "2821710",
    "end": "2827440"
  },
  {
    "text": "inclusive of GMS a functionality but will support it later as well so what's coming next so the 1.17",
    "start": "2827440",
    "end": "2837160"
  },
  {
    "start": "2833000",
    "end": "2833000"
  },
  {
    "text": "release of kubernetes is already in progress we're already a few weeks into it the enhancement freeze this past that",
    "start": "2837160",
    "end": "2843970"
  },
  {
    "text": "was back on October 15th if you're interested to kind of see exactly what features will be going into kubernetes",
    "start": "2843970",
    "end": "2850150"
  },
  {
    "text": "117 there's the link to the tracking spreadsheet right there the targeted",
    "start": "2850150",
    "end": "2856329"
  },
  {
    "text": "release for communities 117 is also looking at December 9th 2019 as well",
    "start": "2856329",
    "end": "2862930"
  },
  {
    "text": "just in time should I say right after yeah after cube con so if you",
    "start": "2862930",
    "end": "2870160"
  },
  {
    "text": "are interested in learning more about that you can almost always check out sig release to kind of get an idea of what's",
    "start": "2870160",
    "end": "2875589"
  },
  {
    "text": "happening with inside of the released time frame in the release windows next I",
    "start": "2875589",
    "end": "2882069"
  },
  {
    "text": "don't see a whole lot of stuff in QA which means lucky answered a bunch of stuff but if you have any other questions now's the time to ask is there",
    "start": "2882069",
    "end": "2892299"
  },
  {
    "text": "to be recorded version later for viewing yes this is all being recorded it will be available on YouTube at a later date",
    "start": "2892299",
    "end": "2900480"
  },
  {
    "text": "Andres asking is there any actions being taken from kubernetes team regarding the incompatibility with helm as reported in",
    "start": "2906460",
    "end": "2912849"
  },
  {
    "text": "Helms github the cig release team doesn't do anything directly with helm",
    "start": "2912849",
    "end": "2919289"
  },
  {
    "text": "that is outside of cig release so there's nothing that we will be able to answer with regards to that",
    "start": "2919289",
    "end": "2927660"
  },
  {
    "text": "Kenny I'm trying to find issue just out of interest I suspect it's because of the API deprecations but",
    "start": "2941920",
    "end": "2951490"
  },
  {
    "text": "I'm trying to dig it up mm-hmm so so those api's were marked for",
    "start": "2951490",
    "end": "2958210"
  },
  {
    "text": "deprecation and they went through the deprecation policy which was three releases so back in 1.12 or 1.13 we we",
    "start": "2958210",
    "end": "2965710"
  },
  {
    "text": "said those api's were deprecated and then they were subsequently deleted helm",
    "start": "2965710",
    "end": "2971200"
  },
  {
    "text": "had the opportunity to update that baseline installers to use the updated",
    "start": "2971200",
    "end": "2976540"
  },
  {
    "text": "api's which have been around since 1.9 or 1.10 I believe so I can I can dig",
    "start": "2976540",
    "end": "2981970"
  },
  {
    "text": "into that mansurov there's another question about any chance communities",
    "start": "2981970",
    "end": "2987130"
  },
  {
    "text": "comes with its own package manager I don't particularly see anything like that but I don't want to speak on behalf",
    "start": "2987130",
    "end": "2993880"
  },
  {
    "text": "of the community baki any idea there - nah okay with that",
    "start": "2993880",
    "end": "3008940"
  },
  {
    "text": "I don't see any other questions available or out there so thank you everybody for joining in again this will",
    "start": "3008940",
    "end": "3015660"
  },
  {
    "text": "this recorded session will be available later on on the CNC F webinar page which",
    "start": "3015660",
    "end": "3022080"
  },
  {
    "text": "will also be available on YouTube thank you again everybody and enjoy the rest of your week thank you everybody",
    "start": "3022080",
    "end": "3031070"
  }
]
[
  {
    "text": "hi everyone We are today here talking about adapting Kubernetes to specialized",
    "start": "0",
    "end": "6640"
  },
  {
    "text": "application workloads Uh and uh the this is us Uh who you know let's",
    "start": "6640",
    "end": "13360"
  },
  {
    "text": "start from the other end Uh Don please uh would you like to introduce yourself",
    "start": "13360",
    "end": "19119"
  },
  {
    "text": "my name is Danten I'm a software engineer from Google I'm also uh the",
    "start": "19119",
    "end": "24560"
  },
  {
    "text": "software engineer and the tech lead since Kubernetes inception Currently I'm",
    "start": "24560",
    "end": "29679"
  },
  {
    "text": "leading of the signal the community and less to be here and talking about the",
    "start": "29679",
    "end": "35120"
  },
  {
    "text": "Kubernetes evolvement for those special last of the work nodes like such as the AI machine learning work node and the",
    "start": "35120",
    "end": "41600"
  },
  {
    "text": "HPC work nodes Sachi Hi everyone My name is Sachi Desai I'm a",
    "start": "41600",
    "end": "47840"
  },
  {
    "text": "product manager on the Azure Kubernetes service team and my focus area is AI GPU",
    "start": "47840",
    "end": "53600"
  },
  {
    "text": "HPC deployments onto AKS and Kubernetes as a whole And I'm involved in the",
    "start": "53600",
    "end": "58800"
  },
  {
    "text": "Kubernetes AI tool chain operator CNCF sandbox project",
    "start": "58800",
    "end": "65159"
  },
  {
    "text": "V It should be on Yeah it's on Yeah Uh hi everyone Uh my name is Vuntu I'm a",
    "start": "66439",
    "end": "73680"
  },
  {
    "text": "principal open source specialist essay working with AWS Uh my key focus areas",
    "start": "73680",
    "end": "78799"
  },
  {
    "text": "are uh scaling data and ML workloads on Kubernetes Uh especially the Amazon EKS",
    "start": "78799",
    "end": "85840"
  },
  {
    "text": "So um my strengths around building some data pipelines using Spark Flink and",
    "start": "85840",
    "end": "92400"
  },
  {
    "text": "Trino various other data frameworks on Kubernetes and also building a ML platforms on Kubernetes Looking forward",
    "start": "92400",
    "end": "99439"
  },
  {
    "text": "to speak to you all Uh welcome Uh my name is Aaron Boyd I'm",
    "start": "99439",
    "end": "105040"
  },
  {
    "text": "a senior director and distinguished engineer at NVIDIA Um super excited to be here I'm just thrilled to see how",
    "start": "105040",
    "end": "111759"
  },
  {
    "text": "many people are here on a Friday Like 10 years ago there might have been seven of us And you know we just went out for",
    "start": "111759",
    "end": "118560"
  },
  {
    "text": "beer because like let's just go do that instead So great to see you all Hope you've had a exciting CubeCon I can't",
    "start": "118560",
    "end": "124079"
  },
  {
    "text": "wait to hear your questions for the panel Yeah this is exciting You know we have the three hyperscalers we have",
    "start": "124079",
    "end": "129840"
  },
  {
    "text": "Nvidia What would you want so how many of you already have AI workloads in",
    "start": "129840",
    "end": "135440"
  },
  {
    "text": "production can you raise your hands quite a few And how many are you",
    "start": "135440",
    "end": "140959"
  },
  {
    "text": "planning in the next few months okay so that's much better So uh",
    "start": "140959",
    "end": "146800"
  },
  {
    "text": "let me open up uh a warm-up question to everybody Uh what is the state of art",
    "start": "146800",
    "end": "153519"
  },
  {
    "text": "for your customers who wants to go first what is the state-of-the-art for uh",
    "start": "153519",
    "end": "159040"
  },
  {
    "text": "workloads and in general and a IML in specific Go ahead I can go ahead and",
    "start": "159040",
    "end": "164319"
  },
  {
    "text": "start So I think Nvidia has a really unique set of customers We service like a ton of internal customers that are",
    "start": "164319",
    "end": "171200"
  },
  {
    "text": "doing amazing a IML research um you know from uh biological models to robotics um",
    "start": "171200",
    "end": "178879"
  },
  {
    "text": "you know is obviously known for its presence in AI but we're rapidly expanding to an external market",
    "start": "178879",
    "end": "184800"
  },
  {
    "text": "understanding you know what customers are doing for training and inference um and the workloads are expansive you know",
    "start": "184800",
    "end": "191760"
  },
  {
    "text": "we have anything from hosting things like deep deepseeek to you know using uh",
    "start": "191760",
    "end": "197040"
  },
  {
    "text": "nims and blueprints to go create your own models or augment your models or do fine-tuning and training so I would say",
    "start": "197040",
    "end": "202800"
  },
  {
    "text": "we we service a lot of customers with an extensive diverse set of workloads and",
    "start": "202800",
    "end": "208640"
  },
  {
    "text": "you know as Don will get to eventually you know the hyperscalers are pretty unique in that you know not only are we",
    "start": "208640",
    "end": "214959"
  },
  {
    "text": "seeing the intersection between Kubernetes and AI we're really seeing the intersection of HPC and Kubernetes",
    "start": "214959",
    "end": "222080"
  },
  {
    "text": "and how is that rapidly changing our landscape I think it's an exciting time to be here and I'd love to hear how many",
    "start": "222080",
    "end": "228239"
  },
  {
    "text": "of you um with your workloads and with your customers are experiencing the same thing",
    "start": "228239",
    "end": "235360"
  },
  {
    "text": "Yeah sure Um uh at AWS uh you have you know pretty much uh a lot of customers",
    "start": "235360",
    "end": "242239"
  },
  {
    "text": "who are running their AML workloads on Kubernetes uh which is Amazon EKS and",
    "start": "242239",
    "end": "248560"
  },
  {
    "text": "and the focus is in every vertical uh mostly in automated financials uh in",
    "start": "248560",
    "end": "254640"
  },
  {
    "text": "every vertical supply chain they're focusing on it and one of the biggest example is Amazon retail and where",
    "start": "254640",
    "end": "261759"
  },
  {
    "text": "Amazon focused on building um AI within the retail itself self and which is showing as example for a lot of these uh",
    "start": "261759",
    "end": "270400"
  },
  {
    "text": "customers at AWS and and they're leveraging a lot of these technologies",
    "start": "270400",
    "end": "275520"
  },
  {
    "text": "within you know Kubernetes within Amazon EKS and the open source solutions that came out uh building their AML platforms",
    "start": "275520",
    "end": "282639"
  },
  {
    "text": "um you know with all the capabilities of custom scheduling uh and autoscaling and",
    "start": "282639",
    "end": "290240"
  },
  {
    "text": "inferencing and training and fine-tuning with you know various set of tools that we're going to discuss soon But",
    "start": "290240",
    "end": "298000"
  },
  {
    "text": "yeah Sachi Yeah on Azure we see users um along different paths or parts of their",
    "start": "298040",
    "end": "305199"
  },
  {
    "text": "AI journey So starting off just wanting to experiment with different models conduct benchmarking and evaluate the",
    "start": "305199",
    "end": "311919"
  },
  {
    "text": "performance um starting off with serving models and doing inferencing workloads and then moving forward with tuning or",
    "start": "311919",
    "end": "319199"
  },
  {
    "text": "conducting rag as well to improve um the performance and make it more contextaware in the context of their",
    "start": "319199",
    "end": "325600"
  },
  {
    "text": "applications and of course um then more advanced AI users that want to train their models build them inhouse from",
    "start": "325600",
    "end": "332400"
  },
  {
    "text": "ground up when it comes to um more security reasons um governance over their data etc So we're looking to",
    "start": "332400",
    "end": "340240"
  },
  {
    "text": "support them along that journey at whichever stage they're at and meet them where they are with their AI And I think",
    "start": "340240",
    "end": "346560"
  },
  {
    "text": "we'll go into this a bit more in discussing the projects that we're involved in um within the CNCF",
    "start": "346560",
    "end": "354000"
  },
  {
    "text": "Um Google is a little bit uh special here We also have a lot of the mixed",
    "start": "354000",
    "end": "359039"
  },
  {
    "text": "workload and also customer at the different uh stage So from the training",
    "start": "359039",
    "end": "364479"
  },
  {
    "text": "proc uh data processing preparation and until and until to the all those kind of the inference serving and uh one of the",
    "start": "364479",
    "end": "371919"
  },
  {
    "text": "special like the Google unique it is Google itself also have the hardware",
    "start": "371919",
    "end": "377039"
  },
  {
    "text": "right so the Google also have the TPU so customer came to Google and not just for",
    "start": "377039",
    "end": "382400"
  },
  {
    "text": "uh GPU they also have the uh TPU for cost efficiency all those kind of the read different reasons and also we also",
    "start": "382400",
    "end": "390160"
  },
  {
    "text": "have like the special things Google itself generate be build those LM models",
    "start": "390160",
    "end": "395440"
  },
  {
    "text": "and uh so a lot of customer came to Google ask for gemini and all different of the gemini all those kind of things",
    "start": "395440",
    "end": "402000"
  },
  {
    "text": "So one of the special things it is so internal of those uh training jobs or uh",
    "start": "402000",
    "end": "409039"
  },
  {
    "text": "not just third party of those kind of things and and one and some of it is already on the GKE some is talking about",
    "start": "409039",
    "end": "416160"
  },
  {
    "text": "the migrate or in on the past to the migrate of the kubernetes and GKE so that's kind of give us a unique of the",
    "start": "416160",
    "end": "423400"
  },
  {
    "text": "perspective and how to we build of the standardized of the hardware and uniform",
    "start": "423400",
    "end": "428880"
  },
  {
    "text": "of the things and to support the user and also how do we uh build a standardize of the framework on top of",
    "start": "428880",
    "end": "436720"
  },
  {
    "text": "Kubernetes and to support the different type of the customers things Yeah thank you So let me start back from you Don Um",
    "start": "436720",
    "end": "444880"
  },
  {
    "text": "uh you are you know leading the efforts in SIG node in Kubernetes for the things",
    "start": "444880",
    "end": "450880"
  },
  {
    "text": "that everybody is going to use you know soon real soon now like things like DRA",
    "start": "450880",
    "end": "456479"
  },
  {
    "text": "switching on some some features like that So um like what the cubernetes is",
    "start": "456479",
    "end": "463199"
  },
  {
    "text": "evolving to uh suit uh the AML workloads There is some work in progress Last year",
    "start": "463199",
    "end": "469360"
  },
  {
    "text": "in Paris and in Salt Lake City we got everybody excited on like all the things that are coming out So can you give us a",
    "start": "469360",
    "end": "475199"
  },
  {
    "text": "status of like where they are and you know what can we expect from the community and then on on the side trying",
    "start": "475199",
    "end": "483199"
  },
  {
    "text": "to figure out like how and when uh people can start using it and also where",
    "start": "483199",
    "end": "489199"
  },
  {
    "text": "where does everybody think that Kubernetes needs to evolve beyond the current set of things that is in",
    "start": "489199",
    "end": "494479"
  },
  {
    "text": "progress That's good question Thanks So uh just like of the teams mentioned of",
    "start": "494479",
    "end": "500319"
  },
  {
    "text": "the DIA and also earlier I mentioned that uh because the Google add special",
    "start": "500319",
    "end": "505360"
  },
  {
    "text": "unique space So then we realize about how to standardize the hardware especi",
    "start": "505360",
    "end": "510639"
  },
  {
    "text": "those specified the hardware to support AM machine learning workload node it is really leaded right So this is after DA",
    "start": "510639",
    "end": "517839"
  },
  {
    "text": "is is trying to uh standardize and build abstract uh representative to Kubernetes",
    "start": "517839",
    "end": "525760"
  },
  {
    "text": "right so the Kubernetes can uh managed and also scheduled all those kind of workload so there's a lot of progress",
    "start": "525760",
    "end": "532320"
  },
  {
    "text": "make those kind of things and there is in the production stage almost in that stage",
    "start": "532320",
    "end": "539760"
  },
  {
    "text": "but we need to figure out a lot of others issues like how to migrate and how to u uh build off the monitoring all",
    "start": "539760",
    "end": "547279"
  },
  {
    "text": "those kind of things we still used to be but besides about the hardware there's",
    "start": "547279",
    "end": "553120"
  },
  {
    "text": "the higher end of the objects and the kubernetes actually in the past we start from the support of the web services",
    "start": "553120",
    "end": "560560"
  },
  {
    "text": "right state and then evolve to support the state for site and we don't do",
    "start": "560560",
    "end": "566080"
  },
  {
    "text": "really good uh we try but because priority we didn't do good job on a lot",
    "start": "566080",
    "end": "571519"
  },
  {
    "text": "of to support of the batch workload especially batch workload complex X batch workload and with their framework",
    "start": "571519",
    "end": "578720"
  },
  {
    "text": "So we are looking this is why there's a lot of customer scheduling and the",
    "start": "578720",
    "end": "584399"
  },
  {
    "text": "typology aware of the scheduling and and also topology management and finding",
    "start": "584399",
    "end": "590320"
  },
  {
    "text": "grand of the resource management request come to the Kubernetes community and",
    "start": "590320",
    "end": "595519"
  },
  {
    "text": "every day so community actually build a lot of things like wino and also Kaduner",
    "start": "595519",
    "end": "601600"
  },
  {
    "text": "from from Avidia and also Q uh around of the Kubernetes in the Kubernetes",
    "start": "601600",
    "end": "607440"
  },
  {
    "text": "ecosystem try to do the job queuing try to do the file sharing and all those kind of things But because this kind of",
    "start": "607440",
    "end": "614959"
  },
  {
    "text": "things we done a lot of more and more and well the time we realized actually we are missing of the primitives defined",
    "start": "614959",
    "end": "621839"
  },
  {
    "text": "object to support those kind of things right so for example kubernetes still today couldn't really support uh batch",
    "start": "621839",
    "end": "629440"
  },
  {
    "text": "workload especially complex batch workload their uh dependency right so the job of workflow and the dependency",
    "start": "629440",
    "end": "636560"
  },
  {
    "text": "how we are going to achieve that and also kubernetes there's a lot of the uh",
    "start": "636560",
    "end": "642160"
  },
  {
    "text": "core scheduler or customer scheduling define about the part group So we can do",
    "start": "642160",
    "end": "647839"
  },
  {
    "text": "the G scheduling because especially for training model training jobs they really require about all or nothing about the",
    "start": "647839",
    "end": "654480"
  },
  {
    "text": "scheduling and also what it is how we fast detect of the hardware problem and",
    "start": "654480",
    "end": "659680"
  },
  {
    "text": "then do the hard swap and and quick or smart rep about those failure GPU and",
    "start": "659680",
    "end": "665519"
  },
  {
    "text": "the TPU all those kind of things actually is the new challenge for us So that's we are exciting to work on",
    "start": "665519",
    "end": "670720"
  },
  {
    "text": "together with the community So um Sachi when Kubernetes starts making",
    "start": "670720",
    "end": "677959"
  },
  {
    "text": "progress how soon can you get it into Kato and you know what other things can",
    "start": "677959",
    "end": "684240"
  },
  {
    "text": "you get it into either in the community or in the service uh what are you",
    "start": "684240",
    "end": "690160"
  },
  {
    "text": "thinking about yeah great question Um when I think about where Kaido fits into all of this more so with the name itself",
    "start": "690160",
    "end": "697279"
  },
  {
    "text": "So as a tool chain operator as a tool within your entire AI pipeline we see um",
    "start": "697279",
    "end": "702880"
  },
  {
    "text": "comp composable architecture So plugging it into the other tools that you're using for observability for checking um",
    "start": "702880",
    "end": "709839"
  },
  {
    "text": "your GPU node health for example and overall making optimizations across the",
    "start": "709839",
    "end": "714880"
  },
  {
    "text": "board for different workload deployments So as Don was focusing on um with regards to scheduling and batch",
    "start": "714880",
    "end": "721120"
  },
  {
    "text": "workloads um it's great to look at uh the changes that can be made in the cubeuler framework for example and there",
    "start": "721120",
    "end": "728079"
  },
  {
    "text": "are scheduler plugins that have been proposed um as part of certain ks like",
    "start": "728079",
    "end": "733200"
  },
  {
    "text": "um gang scheduling co-scheduling as well as topology aware uh scheduling plugins",
    "start": "733200",
    "end": "738320"
  },
  {
    "text": "that can support these specific workload deployments um not only just the deployment part but also longunning",
    "start": "738320",
    "end": "744720"
  },
  {
    "text": "availability um so within In Kaido we're looking to just see and validate um how",
    "start": "744720",
    "end": "750160"
  },
  {
    "text": "these all work together And another aspect to look at is um node health and",
    "start": "750160",
    "end": "755360"
  },
  {
    "text": "reliability So when you have these um stateful AI enabled applications not",
    "start": "755360",
    "end": "761120"
  },
  {
    "text": "only do you want to um have successful deployment but for training for example",
    "start": "761120",
    "end": "766480"
  },
  {
    "text": "um you want to support it throughout the entire uh workload process So if there's any kind of interruptions um due to",
    "start": "766480",
    "end": "773360"
  },
  {
    "text": "changes in the GPU health you want to be able to migrate that over let's say to another node and continue on the process",
    "start": "773360",
    "end": "779920"
  },
  {
    "text": "not lose all of the pro progress that was made in the first part and do that in a safe secure manner so that you can",
    "start": "779920",
    "end": "787040"
  },
  {
    "text": "overall reduce cost because we know that GPUs can often be quite um costly and",
    "start": "787040",
    "end": "793600"
  },
  {
    "text": "have limited availability at times So really um supporting node uh reliability",
    "start": "793600",
    "end": "799440"
  },
  {
    "text": "throughout the deployment process and considering different aspects of how that can affect your an AI enabled",
    "start": "799440",
    "end": "806480"
  },
  {
    "text": "applications So V you are trying to integrate a bunch of these things into",
    "start": "806480",
    "end": "812079"
  },
  {
    "text": "things that are useful to customers You've you know done things like data on kubernetus and things like that So can",
    "start": "812079",
    "end": "818880"
  },
  {
    "text": "you speak up about like what do you what do you face when you go to a customer",
    "start": "818880",
    "end": "824720"
  },
  {
    "text": "and like what their challenges are and like how do you go around figuring out like what are the components that you",
    "start": "824720",
    "end": "831040"
  },
  {
    "text": "need to put together for them to you know do the things that they need to do Yeah Yeah Sure So uh probably I might",
    "start": "831040",
    "end": "839360"
  },
  {
    "text": "have to tell the a little bit of history around um before we get into the Kubernetes and so a lot of the batch",
    "start": "839360",
    "end": "846480"
  },
  {
    "text": "workloads or AI workloads traditionally run on HPC or maybe uh some bunch of",
    "start": "846480",
    "end": "852560"
  },
  {
    "text": "CPUs and in the past um you use clusters like Hadoop for running your Spark",
    "start": "852560",
    "end": "858120"
  },
  {
    "text": "workloads but since the Kubernetes has became more stateless to stateful over a",
    "start": "858120",
    "end": "864560"
  },
  {
    "text": "period of time it's grown it became more like an AI native uh platform for all",
    "start": "864560",
    "end": "870880"
  },
  {
    "text": "AML workloads on Kubernetes The main things are when Kubernetes introduced this PVPCs with the running the stateful",
    "start": "870880",
    "end": "878199"
  },
  {
    "text": "workloads support for the distributed file systems like EFS and FSX and so on",
    "start": "878199",
    "end": "883839"
  },
  {
    "text": "uh that help move a lot uh running these batch workloads So and these frameworks",
    "start": "883839",
    "end": "890560"
  },
  {
    "text": "um like spark flank peno and even the al workloads now they",
    "start": "890560",
    "end": "896639"
  },
  {
    "text": "start to support um to run on kubernetes by leveraging these features that",
    "start": "896639",
    "end": "902320"
  },
  {
    "text": "kubernetes offers and there is there are a lot of operators that have been built over a period of time to simplify this",
    "start": "902320",
    "end": "907839"
  },
  {
    "text": "journey So at AWS and you know through",
    "start": "907839",
    "end": "912880"
  },
  {
    "text": "data on Kubernetes uh we build a lot of patterns to show the customers how you can actually run high scale a large",
    "start": "912880",
    "end": "920160"
  },
  {
    "text": "scale spark workloads on Kubernetes or AML training workloads on Kubernetes",
    "start": "920160",
    "end": "925519"
  },
  {
    "text": "right so to do that uh sometimes you need to think about a lot of things right running these workloads on",
    "start": "925519",
    "end": "931360"
  },
  {
    "text": "Kubernetes is pretty straightforward but you need to start thinking about from the point that you want to pack these",
    "start": "931360",
    "end": "937040"
  },
  {
    "text": "workloads distributed workloads You know the things that you want to do is GPU",
    "start": "937040",
    "end": "942079"
  },
  {
    "text": "optimization and CPU optimization and been packing these workloads uh by",
    "start": "942079",
    "end": "947440"
  },
  {
    "text": "running uh using custom basketers like Apache Unicorn Volcano or Q Um and you",
    "start": "947440",
    "end": "955360"
  },
  {
    "text": "also need to consider um the failover if something goes wrong can these",
    "start": "955360",
    "end": "960639"
  },
  {
    "text": "distributed computing parts can recover from it So these are the aspects is the common aspects that we hear from users",
    "start": "960639",
    "end": "967199"
  },
  {
    "text": "and the customers and they also hit the scalability issues with the Kubernetes a Kubernetes we say it supports 5,000",
    "start": "967199",
    "end": "974639"
  },
  {
    "text": "10,000 15,000 nodes but with the stateless microservices yes answer is",
    "start": "974639",
    "end": "981440"
  },
  {
    "text": "yes but for stateful workloads like all these data workloads and AML AML workloads that changes for workload type",
    "start": "981440",
    "end": "989519"
  },
  {
    "text": "to workload right there are some set of workloads like in batch can go up to thousand nodes just because of the",
    "start": "989519",
    "end": "996000"
  },
  {
    "text": "bursty nature of these workloads But when when it comes to AML workloads you can scale up to maybe 2,000 3,000 and",
    "start": "996000",
    "end": "1003199"
  },
  {
    "text": "there's a lot of tuning that needs to be done in every aspect But it changes based on the framework that you select",
    "start": "1003199",
    "end": "1010680"
  },
  {
    "text": "So we we just I think it is evolving a lot and there are a lot of tools that",
    "start": "1010680",
    "end": "1016160"
  },
  {
    "text": "are coming up caching techniques and batch scheduulers uh and optimization on",
    "start": "1016160",
    "end": "1021199"
  },
  {
    "text": "the GPUs uh using you know uh fraction of GPUs and so on but there is still lot",
    "start": "1021199",
    "end": "1028640"
  },
  {
    "text": "to be done in this space uh by the community Thank you So uh this is a question to Erin So as an industry",
    "start": "1028640",
    "end": "1035918"
  },
  {
    "text": "leader right you have to lead the industry you have to take us where you would like us to go and people are also",
    "start": "1035919",
    "end": "1042400"
  },
  {
    "text": "telling you you know this is what we want So how do you balance the two and like how do you think about like you",
    "start": "1042400",
    "end": "1049840"
  },
  {
    "text": "know where do we put our resources how do we prioritize requests we you know",
    "start": "1049840",
    "end": "1057039"
  },
  {
    "text": "what does the future look like you know what do we want people to be doing five years down the line how do you think",
    "start": "1057039",
    "end": "1062480"
  },
  {
    "text": "about that great question Dims So you know I",
    "start": "1062480",
    "end": "1067679"
  },
  {
    "text": "honestly think you'll see a lot more from Nvidia in terms of open source You know the landscape Thank you",
    "start": "1067679",
    "end": "1073679"
  },
  {
    "text": "the the landscape is is certainly changing Um you know I've been in open source forever and part of the CNCF and",
    "start": "1073679",
    "end": "1081039"
  },
  {
    "text": "um you know I think we're we're investing both in our talent and our focus because we know as you know Sachi",
    "start": "1081039",
    "end": "1088880"
  },
  {
    "text": "was indicating you know GPUs are precious and they're a resource that needs to be managed and you know for us",
    "start": "1088880",
    "end": "1095120"
  },
  {
    "text": "to be able to contribute and have the deep understanding and give that back to the community how they can easily manage",
    "start": "1095120",
    "end": "1100160"
  },
  {
    "text": "and operate that is you know fundamental to all of our success and you know we recognize that we're better together as",
    "start": "1100160",
    "end": "1107039"
  },
  {
    "text": "a community and so you know I I don't know exactly I can't point today but I'm on LinkedIn You can always reach out to",
    "start": "1107039",
    "end": "1113760"
  },
  {
    "text": "me I'm very open CNCF Slack Kubernetes Slack I you know I I I do want to hear",
    "start": "1113760",
    "end": "1119280"
  },
  {
    "text": "about the use cases I want to hear about the pain I want to hear about how NVIDIA is an industry leader can help solve",
    "start": "1119280",
    "end": "1124559"
  },
  {
    "text": "these problems But there are quite a few actually open- source projects in Nvidia that people probably aren't aware of",
    "start": "1124559",
    "end": "1130799"
  },
  {
    "text": "There's one called Skyhook that allows you to update you know some of the nickel parameters on the fly for jobs",
    "start": "1130799",
    "end": "1136799"
  },
  {
    "text": "that you're running to get better performance Uh we're going to be publishing a project called Envy Sentinel which looks at the node health",
    "start": "1136799",
    "end": "1144320"
  },
  {
    "text": "It's it's not just good or bad It's in varying different states and we need to be able to work very closely with our",
    "start": "1144320",
    "end": "1150000"
  },
  {
    "text": "cloud partners to be able to you know understand the node health get them back into service very quickly And you know",
    "start": "1150000",
    "end": "1157039"
  },
  {
    "text": "Nvidia is not on an island in this you know DGX cloud which is what I run the",
    "start": "1157039",
    "end": "1162480"
  },
  {
    "text": "Kubernetes team there you know actively works with all the major cloud providers",
    "start": "1162480",
    "end": "1167919"
  },
  {
    "text": "to provide both the technology and the hardware to make that possible So you",
    "start": "1167919",
    "end": "1173200"
  },
  {
    "text": "know I think the tides are changing and I think you know just the relevance of AI within the Kubernetes community is",
    "start": "1173200",
    "end": "1179440"
  },
  {
    "text": "obviously changing I think at Paris almost every keynote mentioned something in AI and it was very different It",
    "start": "1179440",
    "end": "1186000"
  },
  {
    "text": "wasn't that bad this week It wasn't that bad this week but um I'm thinking back I",
    "start": "1186000",
    "end": "1191679"
  },
  {
    "text": "had you know a picture come up that was Kelsey and I at CubeCon London nine",
    "start": "1191679",
    "end": "1196960"
  },
  {
    "text": "years ago and it was a hundred people and I did a keynote about storage and I remember he was the moderator and he was",
    "start": "1196960",
    "end": "1203039"
  },
  {
    "text": "like I just don't think it's ever going to be stateful Like you're wrong on this one",
    "start": "1203039",
    "end": "1208760"
  },
  {
    "text": "Aaron So you know things change and we have to evolve and um this is also just",
    "start": "1208760",
    "end": "1215360"
  },
  {
    "text": "part of our evolution Sounds good So I'll let you go first this time Okay What is one question you would like to",
    "start": "1215360",
    "end": "1220400"
  },
  {
    "text": "ask the other panelists or you know a specific panelist pick one",
    "start": "1220400",
    "end": "1225440"
  },
  {
    "text": "Um I mean if I wasn't here I'm a replacement moderator just so you all",
    "start": "1225440",
    "end": "1230799"
  },
  {
    "text": "know There was one more Shinas who was supposed to be here So I'm the replacement So and they were like uh hey",
    "start": "1230799",
    "end": "1236720"
  },
  {
    "text": "we just going to ask each other questions So this is your chance I I guess I'd pose this to all the panelists",
    "start": "1236720",
    "end": "1242640"
  },
  {
    "text": "like what can we do better you know to your point you all are deeply involved",
    "start": "1242640",
    "end": "1248080"
  },
  {
    "text": "you're all helping customers like what can Nvidia do to help to be you know not",
    "start": "1248080",
    "end": "1253919"
  },
  {
    "text": "even more part of the community but also just like this is the pain va feature",
    "start": "1253919",
    "end": "1259120"
  },
  {
    "text": "requests yeah um sure uh I'm looking at some of",
    "start": "1259120",
    "end": "1266000"
  },
  {
    "text": "the pain points that customers came to me right so one of the common pain point uh that I noticed was especially for the",
    "start": "1266000",
    "end": "1272880"
  },
  {
    "text": "training when they're running distributed training uh across multiple GPUs and uh they stream the data from",
    "start": "1272880",
    "end": "1279440"
  },
  {
    "text": "various sources like uh S3 or other file systems Um",
    "start": "1279440",
    "end": "1285159"
  },
  {
    "text": "but sourcing the data or reading the data and um and running the training",
    "start": "1285159",
    "end": "1290640"
  },
  {
    "text": "workload takes a longer time because it's missing the caching capabilities",
    "start": "1290640",
    "end": "1296159"
  },
  {
    "text": "So for the training it requires uh proper caching across all the nodes and",
    "start": "1296159",
    "end": "1301679"
  },
  {
    "text": "a lot of these customers are actually duplicating the data the entire data set across the nodes to do this training Uh",
    "start": "1301679",
    "end": "1308640"
  },
  {
    "text": "if there is any possibility around this of sharding the data and splitting",
    "start": "1308640",
    "end": "1313679"
  },
  {
    "text": "across these nodes to optimize and also building a cache clusters which",
    "start": "1313679",
    "end": "1319039"
  },
  {
    "text": "simplifies this you know whole training part Anybody else wants to chime in",
    "start": "1319039",
    "end": "1327360"
  },
  {
    "text": "i asked the question uh request to a media last year at the Paris So I want",
    "start": "1327600",
    "end": "1333760"
  },
  {
    "text": "to repeat three asks here and some widely for fail but you know just",
    "start": "1333760",
    "end": "1340400"
  },
  {
    "text": "mention something right when it is I ask for the faster detect of the GPU problem",
    "start": "1340400",
    "end": "1346960"
  },
  {
    "text": "and the hardware problem because of often customer did the training and",
    "start": "1346960",
    "end": "1352080"
  },
  {
    "text": "after the the they have to do the human involvement validate that the model is correct incorrect all those kind of",
    "start": "1352080",
    "end": "1358000"
  },
  {
    "text": "things there's no visibility and and uh and that's with a lot of time and",
    "start": "1358000",
    "end": "1363520"
  },
  {
    "text": "resource there's a thanks there's a lot of proment there and another thing it is",
    "start": "1363520",
    "end": "1369360"
  },
  {
    "text": "I asked last year it is the sharing better sharing GPU GPU it is expensive",
    "start": "1369360",
    "end": "1377360"
  },
  {
    "text": "and and uh it's the how we are going to share right so there share have many way",
    "start": "1377360",
    "end": "1382400"
  },
  {
    "text": "to share but uh and also security like what kind of additional isolation when",
    "start": "1382400",
    "end": "1387840"
  },
  {
    "text": "to to offer to share of the GPU and I believe there's some solution we need to",
    "start": "1387840",
    "end": "1393919"
  },
  {
    "text": "work together and to move forward so last one I ask it is how to plug in GPU",
    "start": "1393919",
    "end": "1402080"
  },
  {
    "text": "because GPU like GPU is expensive and a special device Um so which is means a",
    "start": "1402080",
    "end": "1408960"
  },
  {
    "text": "lot of customer have to preserved a physically attach of the GPU to the uh machines and once they reserved and that",
    "start": "1408960",
    "end": "1416400"
  },
  {
    "text": "GPU cannot use that that node also cannot be used So uh how we are going to",
    "start": "1416400",
    "end": "1423039"
  },
  {
    "text": "uh uh dynamic plug attached of the GPU to the machine that's can totally change",
    "start": "1423039",
    "end": "1429600"
  },
  {
    "text": "about the cloud and uh and how we assemble of the node right so so that's that's kind of the three things I've",
    "start": "1429600",
    "end": "1436159"
  },
  {
    "text": "been keep ask of course kubernetes community and also all of us like all",
    "start": "1436159",
    "end": "1441760"
  },
  {
    "text": "the part partner and the contributor we work together and evolve and one of the",
    "start": "1441760",
    "end": "1447039"
  },
  {
    "text": "things I really worry about it is because so many of the uh scheduler uh",
    "start": "1447039",
    "end": "1452240"
  },
  {
    "text": "idea and so many CR propose to customize of the Kubernetes right so one of the",
    "start": "1452240",
    "end": "1458559"
  },
  {
    "text": "concern is we don't evolve Kubernetes right so to standardize standardize a",
    "start": "1458559",
    "end": "1464000"
  },
  {
    "text": "lot of things standardize the DR standardized hardware device and I hope",
    "start": "1464000",
    "end": "1469679"
  },
  {
    "text": "we can also standardize about the like workflow maybe even not to that high",
    "start": "1469679",
    "end": "1475360"
  },
  {
    "text": "level but the standardize about a group of the parts describe of the workflow",
    "start": "1475360",
    "end": "1481279"
  },
  {
    "text": "and so uh customer customized of the scheduleuler can work against those uh p",
    "start": "1481279",
    "end": "1487919"
  },
  {
    "text": "group instead of we fragment of kubernetes for different purpose uh",
    "start": "1487919",
    "end": "1493880"
  },
  {
    "text": "fragmentation uh sometimes actually it's okay because you customize for different industry needed but that's also is",
    "start": "1493880",
    "end": "1501279"
  },
  {
    "text": "potential for the uh reduce of the efficiency right reduce about uh uh the",
    "start": "1501279",
    "end": "1507120"
  },
  {
    "text": "efficient and performance all those kind of and also it's not elastic uh for",
    "start": "1507120",
    "end": "1512159"
  },
  {
    "text": "customer perspective So that's kind of good the things we need to work together and move forward Sachi before you ask",
    "start": "1512159",
    "end": "1518960"
  },
  {
    "text": "I'm going to ask people to start lining up Uh if you have a question and the mic",
    "start": "1518960",
    "end": "1524960"
  },
  {
    "text": "is right there and if there is nobody we'll just continue talking So I hope you know you have questions and you know",
    "start": "1524960",
    "end": "1531360"
  },
  {
    "text": "line up So otherwise okay Sachi Yes Um",
    "start": "1531360",
    "end": "1536799"
  },
  {
    "text": "yeah So what we see users uh trending towards is wanting to learn more about their AI HPC workload So using different",
    "start": "1536799",
    "end": "1544159"
  },
  {
    "text": "monitoring and observability tools and there's a lot of interest around for example the NVIDIA DCGM exporter and",
    "start": "1544159",
    "end": "1551279"
  },
  {
    "text": "looking for uh broader support of that tool maybe across different types of GPUs and um compute that's introduced by",
    "start": "1551279",
    "end": "1559039"
  },
  {
    "text": "Nvidia for example maybe confidential GPUs and so forth So just I would say um",
    "start": "1559039",
    "end": "1565039"
  },
  {
    "text": "like plugging in these tools together and allowing them to be seamlessly deployed monitoring observability using",
    "start": "1565039",
    "end": "1571840"
  },
  {
    "text": "our kind of standards across Prometheus and Graphfana for example and then um easy integration into all the different",
    "start": "1571840",
    "end": "1578080"
  },
  {
    "text": "cloud providers Um and I would say yeah generally that's the main",
    "start": "1578080",
    "end": "1584480"
  },
  {
    "text": "feature ask Okay if nobody's coming to the mic I'm going to Good Otherwise I was going to call on people like Sergey",
    "start": "1584480",
    "end": "1591840"
  },
  {
    "text": "here I'm going to answer one of Don's requests just right out of the gate You know we we just open sourced our running",
    "start": "1591840",
    "end": "1597840"
  },
  {
    "text": "eyeuler It's called Kai and it does have you know fractional GPU Uh so you know I",
    "start": "1597840",
    "end": "1603760"
  },
  {
    "text": "I love that you mentioned like that there's a lot of schedulers going out there It's really showing kind of the",
    "start": "1603760",
    "end": "1608960"
  },
  {
    "text": "ubiquitous of what people are focused on So we're excited to be part of you know that evolution as well Thank you Please",
    "start": "1608960",
    "end": "1619279"
  },
  {
    "text": "Yes Ah perfect Yes Uh I have a question We were focusing very much on AI and ML",
    "start": "1619279",
    "end": "1627360"
  },
  {
    "text": "workloads which are certainly very interesting very hot topic right now But what I am interested is um uh what",
    "start": "1627360",
    "end": "1635440"
  },
  {
    "text": "challenges do you see in the context of Kubernetes um for the workloads to",
    "start": "1635440",
    "end": "1641919"
  },
  {
    "text": "integrate them um beside and beyond uh",
    "start": "1641919",
    "end": "1647039"
  },
  {
    "text": "GPU workloads excellent question Who wants to take this i can take Yeah Uh",
    "start": "1647039",
    "end": "1653360"
  },
  {
    "text": "besides GPU workloads and I think I'll start with the batch workloads if that makes sense Right So um the challenge uh",
    "start": "1653360",
    "end": "1661039"
  },
  {
    "text": "traditionally on Hadoop clusters where you run a lot of these data processing frameworks as Spark Flink and you know",
    "start": "1661039",
    "end": "1666720"
  },
  {
    "text": "whatot um Hadoop clusters used to scale for thousands and thousands of nodes",
    "start": "1666720",
    "end": "1671760"
  },
  {
    "text": "that traditionally works well but uh when you move to Kubernetes um there is",
    "start": "1671760",
    "end": "1676960"
  },
  {
    "text": "a lot of um orchestration components uh which needs to work together to make it",
    "start": "1676960",
    "end": "1682799"
  },
  {
    "text": "work for large scale workloads starting with uh distributed workloads like Spark",
    "start": "1682799",
    "end": "1687919"
  },
  {
    "text": "Spark uh requires gang scheduling right so which is something the Kubernetes uh",
    "start": "1687919",
    "end": "1694960"
  },
  {
    "text": "you know default scheduleuler does not support but then the other scheduulers evolve to make that gang scheduling",
    "start": "1694960",
    "end": "1700480"
  },
  {
    "text": "possible uh and then optimization of the CPU so distributed computing heavily",
    "start": "1700480",
    "end": "1706559"
  },
  {
    "text": "relies on the storage right so how do we actually use the storage the way we used to use in HDFS like a common file system",
    "start": "1706559",
    "end": "1714159"
  },
  {
    "text": "right so we came up with the PVPVC's like leveraging uh node level storage and also leveraging some distributed",
    "start": "1714159",
    "end": "1720480"
  },
  {
    "text": "file storage and so on So those are the areas where uh improved on Kubernetes",
    "start": "1720480",
    "end": "1726960"
  },
  {
    "text": "and still there is a lot to be done in terms of the scale aspect because we",
    "start": "1726960",
    "end": "1732159"
  },
  {
    "text": "notice when you run like 30,000 parts or 50,000 parts of these workloads and",
    "start": "1732159",
    "end": "1738880"
  },
  {
    "text": "there is um always a bottlenecks around it CD and uh API servers it just because",
    "start": "1738880",
    "end": "1745679"
  },
  {
    "text": "the nature of the bursty workloads and puts a lot of stress on that CD So Kubernetes was never designed for that",
    "start": "1745679",
    "end": "1752559"
  },
  {
    "text": "But now with this type of batch workloads and AML workloads and there's a lot to be done in the space I mean in",
    "start": "1752559",
    "end": "1759279"
  },
  {
    "text": "the end your data AI stuff has to be near where your existing stuff is right",
    "start": "1759279",
    "end": "1765600"
  },
  {
    "text": "that's why we are trying to do this within Kubernetes Uh thanks VA We have one more question",
    "start": "1765600",
    "end": "1772960"
  },
  {
    "text": "Uh hi my question is more targeted towards Nvidia but all feel free to chip",
    "start": "1772960",
    "end": "1778640"
  },
  {
    "text": "in Um so I was thinking about what could be the future of the scientific",
    "start": "1778640",
    "end": "1785360"
  },
  {
    "text": "community the research community along with the open-source community where",
    "start": "1785360",
    "end": "1791200"
  },
  {
    "text": "perhaps we want as a informal group um all u gather together and uh do",
    "start": "1791200",
    "end": "1799360"
  },
  {
    "text": "something with AI but we don't have the budget to go to a cloud provider and",
    "start": "1799360",
    "end": "1805039"
  },
  {
    "text": "reserve a cluster with some GPU nodes So perhaps we all uh are gamers and have an",
    "start": "1805039",
    "end": "1811840"
  },
  {
    "text": "Nvidia GPU at uh our home How can we leverage the ability for the Kubernetes",
    "start": "1811840",
    "end": "1817840"
  },
  {
    "text": "to work at the edge and take advantage of the processing of one of the",
    "start": "1817840",
    "end": "1823120"
  },
  {
    "text": "contributors in that community to uh allocate some uh GPU time from their own",
    "start": "1823120",
    "end": "1829120"
  },
  {
    "text": "machine and then uh all uh train their uh open source model Yeah Before uh I'll",
    "start": "1829120",
    "end": "1836880"
  },
  {
    "text": "just quickly answer one one portion which is if you're part of any of the CNCF projects uh CNCF projects have",
    "start": "1836880",
    "end": "1844000"
  },
  {
    "text": "access to cloud credits from everybody um you know GKE AKS and so espec for",
    "start": "1844000",
    "end": "1850000"
  },
  {
    "text": "example we run um you know uh sanity checks sanity tests on all three",
    "start": "1850000",
    "end": "1856000"
  },
  {
    "text": "providers for GPUs So uh you know please come join the community you will have",
    "start": "1856000",
    "end": "1861279"
  },
  {
    "text": "access to some of these things but yes uh for individual re researchers and research teams you know it might not be",
    "start": "1861279",
    "end": "1867600"
  },
  {
    "text": "the right solution for it but uh you're welcome to talk to the CNCF staff uh there is various mechanisms where we",
    "start": "1867600",
    "end": "1874240"
  },
  {
    "text": "where CNCF makes things available and then I'll hand it over to Erin for the Nvidia side Dim's pretty much answered",
    "start": "1874240",
    "end": "1880480"
  },
  {
    "text": "my exactly what I would say Sorry No I I think it actually brings up an",
    "start": "1880480",
    "end": "1885679"
  },
  {
    "text": "opportunity for us to to collaborate more widely We have a lot of research with NVIDIA you know across the spectrum",
    "start": "1885679",
    "end": "1893679"
  },
  {
    "text": "Um and so I'll look into it I mean that's all I can say I'm sure you have research",
    "start": "1893679",
    "end": "1899440"
  },
  {
    "text": "programs and scholarship programs and those kinds of things Yeah we do But I I think it's a great point and and that is",
    "start": "1899440",
    "end": "1905519"
  },
  {
    "text": "why the CNCF went to the cloud providers got credits made sure that um academics",
    "start": "1905519",
    "end": "1911279"
  },
  {
    "text": "and new startups had the ab that they weren't constrained by getting compute right and and also the cloud providers",
    "start": "1911279",
    "end": "1918399"
  },
  {
    "text": "end up not just Nvidia but also they do neuron and tranium and other things too",
    "start": "1918399",
    "end": "1924559"
  },
  {
    "text": "So uh all those things are available to the community as well Yeah great question Thank you Yeah thank you Uh",
    "start": "1924559",
    "end": "1929760"
  },
  {
    "text": "anyone else yes Sergey Thank you Okay Hello I will ask you to predict the",
    "start": "1929760",
    "end": "1937519"
  },
  {
    "text": "future You beat me to it dude So how do you see",
    "start": "1937519",
    "end": "1943440"
  },
  {
    "text": "it going forward do you think do you think that um we will have um like",
    "start": "1943440",
    "end": "1949440"
  },
  {
    "text": "Microsoft has like PC in every every living room we'll have accelerator in every cluster or we will have people",
    "start": "1949440",
    "end": "1957440"
  },
  {
    "text": "calling to some well-known APIs and like only few companies will provide serving and great models and second when I",
    "start": "1957440",
    "end": "1965919"
  },
  {
    "text": "assume that you'll answer first if you answer first do you think that I know all three clouds building",
    "start": "1965919",
    "end": "1973519"
  },
  {
    "text": "their own accelerator ators and Nvidia have accelerator Do you feel we will converge sometime and then accelerators",
    "start": "1973519",
    "end": "1981039"
  },
  {
    "text": "will start doing um we will be differentiated by capability rather than by vendor name",
    "start": "1981039",
    "end": "1988799"
  },
  {
    "text": "Absolutely And and I think this goes actually beyond accelerators I think this you know VU made an excellent point",
    "start": "1988799",
    "end": "1995120"
  },
  {
    "text": "is that you know the foundations of cloud computing you know are the three-legged stool They're compute",
    "start": "1995120",
    "end": "2000720"
  },
  {
    "text": "storage and networking and we haven't I hadn't had any questions in networking which I'm kind of shocked because a lot",
    "start": "2000720",
    "end": "2006640"
  },
  {
    "text": "of these benchmarks are based on latency right and it's not just within the GPU so I mean I do think the evolution of",
    "start": "2006640",
    "end": "2012880"
  },
  {
    "text": "that is like how do we do that well and how do we orchestrate that well and I think that's why Kubernetes is so",
    "start": "2012880",
    "end": "2019200"
  },
  {
    "text": "important here um in tying that infrastructure together beyond predicting the future of that no I'm not",
    "start": "2019200",
    "end": "2025200"
  },
  {
    "text": "even I'm not even going to touch that question but I'll I'll hand the mic off so everyone can take a take a chance at",
    "start": "2025200",
    "end": "2031519"
  },
  {
    "text": "it Yeah Uh we probably are out of time but you know G 10 seconds each Oh I I",
    "start": "2031519",
    "end": "2038760"
  },
  {
    "text": "did I did hear Microsoft mention in there so I just want to give my two cents Um but as far as the future goes I",
    "start": "2038760",
    "end": "2046240"
  },
  {
    "text": "do see um users wanting a single pane of glass across all of those main three categories So when it comes to",
    "start": "2046240",
    "end": "2053040"
  },
  {
    "text": "observability using different tools across GPU vendors or even wherever the accelerators are coming from being able",
    "start": "2053040",
    "end": "2059599"
  },
  {
    "text": "to have more fine grain control um and monitoring over all of those resources",
    "start": "2059599",
    "end": "2065760"
  },
  {
    "text": "um using a single tool or just stand creating standards across um as well as for networking So for RDMA over",
    "start": "2065760",
    "end": "2073200"
  },
  {
    "text": "Infiniband or um other approaches to uh like distributed networks then how are",
    "start": "2073200",
    "end": "2079200"
  },
  {
    "text": "we going to approach that and make that standard um for different types of workloads not just a IML",
    "start": "2079200",
    "end": "2085520"
  },
  {
    "text": "yeah sure Uh just add to what Sachi said Um I think standardization is the main",
    "start": "2085520",
    "end": "2091440"
  },
  {
    "text": "thing Uh that's now if you look at AI tools on Kubernetes there are like lot",
    "start": "2091440",
    "end": "2096720"
  },
  {
    "text": "of tools and customers are struggling to understand which one to use it So things",
    "start": "2096720",
    "end": "2101920"
  },
  {
    "text": "like anthropic launch this MCP server right standardization uh something like",
    "start": "2101920",
    "end": "2107119"
  },
  {
    "text": "that within both training inference uh using GPUs or maybe using inferentia and",
    "start": "2107119",
    "end": "2112880"
  },
  {
    "text": "trrenium from accelerators various other accelerators there should be a standardized way of accessing these",
    "start": "2112880",
    "end": "2118119"
  },
  {
    "text": "accelerators and I think that's where that innovation that needs to be done I think it will be done in future I guess",
    "start": "2118119",
    "end": "2124240"
  },
  {
    "text": "John has the last word",
    "start": "2124240",
    "end": "2128040"
  },
  {
    "text": "Um yeah I just add uh what my partner said here and uh actually from my",
    "start": "2131520",
    "end": "2138560"
  },
  {
    "text": "imaging of the world I even have the proposal since last year and uh I want",
    "start": "2138560",
    "end": "2143920"
  },
  {
    "text": "to standardize the different layer right so we already doing that hardware layer and I want to standardize at the uh",
    "start": "2143920",
    "end": "2150960"
  },
  {
    "text": "scheduling layer what kind of the new parameters to efficient of the standardize those kind of things and",
    "start": "2150960",
    "end": "2157280"
  },
  {
    "text": "also I want to standardize about the auto scanning and the build of the pives",
    "start": "2157280",
    "end": "2163119"
  },
  {
    "text": "to Nate those workload node the customer scheduler right so for different type of the workload node and different type of",
    "start": "2163119",
    "end": "2169920"
  },
  {
    "text": "the batch workload node they give the signal to the anton infrastructure like a cloud provider and GKE AKS and EKS all",
    "start": "2169920",
    "end": "2179359"
  },
  {
    "text": "those kind of things they need to scale uh auto scale of the node expanded of the uh and uh and uh and also VPA uh HP",
    "start": "2179359",
    "end": "2187920"
  },
  {
    "text": "appear all those kind of work together and the most of the important things what I want in my imagination it is we",
    "start": "2187920",
    "end": "2194960"
  },
  {
    "text": "can evolve all those batch work node or batch work node framework together but",
    "start": "2194960",
    "end": "2201960"
  },
  {
    "text": "preserve a lot of those good things especially of the UX for example earlier",
    "start": "2201960",
    "end": "2207760"
  },
  {
    "text": "have the data scientist one of the data scientist ask I don't have the answer how you access the GPU TPU all those",
    "start": "2207760",
    "end": "2214079"
  },
  {
    "text": "kind of things but I want to preserve you still can using snerm and snerm API",
    "start": "2214079",
    "end": "2221040"
  },
  {
    "text": "and the r and the r api you're familiar with and submit of your jobs and once",
    "start": "2221040",
    "end": "2227680"
  },
  {
    "text": "you finish off you can using ry notebook and to do those those testing and",
    "start": "2227680",
    "end": "2233839"
  },
  {
    "text": "experimental but once it is ready to deploy I hope that deployment it is",
    "start": "2233839",
    "end": "2238880"
  },
  {
    "text": "common and standardized and all those kind of things so we can decouple on the",
    "start": "2238880",
    "end": "2244000"
  },
  {
    "text": "kubernetes layer is the core and I can decouple of the rest of the workload the detail management based on your lead and",
    "start": "2244000",
    "end": "2251920"
  },
  {
    "text": "then send it to the kubernetes that's kind of the my vision and also I've been push since a year ago and that's just",
    "start": "2251920",
    "end": "2259280"
  },
  {
    "text": "want to share here we are out of time a lovely audience thanks a lot thanks for",
    "start": "2259280",
    "end": "2264400"
  },
  {
    "text": "using kubernetus thanks for trying to use a stuff on kubernetes and giving us",
    "start": "2264400",
    "end": "2269599"
  },
  {
    "text": "uh enough feedback uh as part of the kubernetes project you know you'll see more stuff coming out we have 133 coming",
    "start": "2269599",
    "end": "2276960"
  },
  {
    "text": "out and then hopefully there's stuff that you can switch on and try and yeah please give us more feedback and uh give",
    "start": "2276960",
    "end": "2284160"
  },
  {
    "text": "us your use cases Uh we'll hang around here for some time if you have if you want to come chat with us Um Don thank",
    "start": "2284160",
    "end": "2290720"
  },
  {
    "text": "you Sachi thank you V thank you Erin thank you",
    "start": "2290720",
    "end": "2296760"
  }
]
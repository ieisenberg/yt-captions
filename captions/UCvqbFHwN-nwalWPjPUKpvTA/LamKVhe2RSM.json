[
  {
    "text": "awesome well thank you for joining my name is joey i'm one of the founders of pachyderm and so my talk today is gonna",
    "start": "0",
    "end": "7770"
  },
  {
    "text": "be geared towards a little bit of a different problem that what most of the focus of this conference has been on you",
    "start": "7770",
    "end": "13889"
  },
  {
    "text": "know and we're gonna really be talking about kind of data science and what those challenges look like now we're all at a kubernetes conference so you know",
    "start": "13889",
    "end": "21000"
  },
  {
    "text": "you're probably either using kubernetes or thinking about using kubernetes as part of your infrastructure and most likely that's for application deployment",
    "start": "21000",
    "end": "28080"
  },
  {
    "text": "right and management but today i'm going to kind of paint a little bit of a different picture and show you how",
    "start": "28080",
    "end": "34410"
  },
  {
    "text": "pachyderm actually thinks that kubernetes can be pretty amazing fit for your data infrastructure",
    "start": "34410",
    "end": "40340"
  },
  {
    "text": "so just to set the stage for all of this and and give you a view of like why are",
    "start": "40340",
    "end": "45899"
  },
  {
    "text": "we talking about data science in the first place how many of you sense of like what pachyderm is so the inspiration for pachyderm really came",
    "start": "45899",
    "end": "52680"
  },
  {
    "text": "from my co-founder running the Hadoop cluster Airbnb and we realized just how insanely difficult it is to manage both",
    "start": "52680",
    "end": "59340"
  },
  {
    "text": "from a data infrastructure perspective as well as a data science perspective where these two where the teams are interfacing with each other so with that",
    "start": "59340",
    "end": "66299"
  },
  {
    "text": "in mind pachyderms set out with like to solve one specific goal and that was to enable large organizations to better",
    "start": "66299",
    "end": "72000"
  },
  {
    "text": "manage their data infrastructure now of course that's not actually answering the question of what is pachyderm pachyderm",
    "start": "72000",
    "end": "78030"
  },
  {
    "text": "is an open source distributed processing framework built on kubernetes and you know just to climb clarify this up front",
    "start": "78030",
    "end": "84540"
  },
  {
    "text": "cuz we get a lot of questions about this there's no Hadoop code in pachyderm right like in that's kind of mentioning",
    "start": "84540",
    "end": "89850"
  },
  {
    "text": "here in a lot of ways we are alternative to Hadoop and a lot of our early customers are choosing us instead of a",
    "start": "89850",
    "end": "96600"
  },
  {
    "text": "dupe because we fit in kind of the kubernetes and containerized frameworks so how does data science and data and",
    "start": "96600",
    "end": "103590"
  },
  {
    "text": "pressure really relate to containers and kubernetes right so let's let's start by drawing an analogy to things we know",
    "start": "103590",
    "end": "109920"
  },
  {
    "text": "kubernetes is a very good at and that's managing micro services we all know and understand the benefits of a micro",
    "start": "109920",
    "end": "116189"
  },
  {
    "text": "service architecture but I'm gonna kind of talk through a few of them here the first is modularity right so keeping",
    "start": "116189",
    "end": "121590"
  },
  {
    "text": "every service small and modular with clean API is to talk to each other well it really helps us understand exactly",
    "start": "121590",
    "end": "128039"
  },
  {
    "text": "what's going on in that piece of the application and it helps us maintain an dated over time",
    "start": "128039",
    "end": "133540"
  },
  {
    "text": "also flexible tooling right services can be written in any tools using any",
    "start": "133540",
    "end": "138860"
  },
  {
    "text": "languages and run anywhere in the cluster well because they're all containerized right this is exactly what microservice is all about and like how",
    "start": "138860",
    "end": "144650"
  },
  {
    "text": "this gets to be really powerful also services are highly scalable right",
    "start": "144650",
    "end": "149780"
  },
  {
    "text": "you can throw a load balancer in front of it and have your application automatically scale dynamically based on",
    "start": "149780",
    "end": "157069"
  },
  {
    "text": "what incoming traffic looks like as well as what cluster resources are available and",
    "start": "157069",
    "end": "162250"
  },
  {
    "text": "finally reproducibility you know you want if I build something locally I want",
    "start": "162250",
    "end": "167329"
  },
  {
    "text": "it to make sure it runs like this and it runs in the salt in the cluster the same way and I want to be able to share my",
    "start": "167329",
    "end": "172730"
  },
  {
    "text": "application what I've built with another developer and know that it's going to run exactly the same we're we're talking",
    "start": "172730",
    "end": "177890"
  },
  {
    "text": "about the exact same piece so this all applies to microservices right and at",
    "start": "177890",
    "end": "183530"
  },
  {
    "text": "first glance you might think that data infrastructure is a pretty different problem but actually if you start to",
    "start": "183530",
    "end": "190069"
  },
  {
    "text": "kind of break it down you realize that many of the data entry challenges that you see can can kind of be framed in the",
    "start": "190069",
    "end": "195950"
  },
  {
    "text": "same way so let's let's go about that one by one",
    "start": "195950",
    "end": "201010"
  },
  {
    "text": "there yeah so so let's start with modularity so this",
    "start": "205599",
    "end": "212060"
  },
  {
    "text": "is a simplified but like totally reasonable data infrastructure that we see in the wild all the time and you",
    "start": "212060",
    "end": "217549"
  },
  {
    "text": "know data processing as I'm sure you've seen before like involves all these different steps it may be eto",
    "start": "217549",
    "end": "223269"
  },
  {
    "text": "database dumps machine learning pipelines all over the place and each of these pieces can have totally different",
    "start": "223269",
    "end": "229459"
  },
  {
    "text": "requirements and SLA s and sometimes we even managed by different teams so instead of thinking about them as a",
    "start": "229459",
    "end": "235430"
  },
  {
    "text": "monolithic infrastructure let's think of them as different data services right",
    "start": "235430",
    "end": "240859"
  },
  {
    "text": "that basically have a data flow of dependencies between them and interact with each other as like different",
    "start": "240859",
    "end": "247190"
  },
  {
    "text": "applications that work together to build your full data infrastructure and this lets us break down each of these individual pieces into bite-sized chunks",
    "start": "247190",
    "end": "254419"
  },
  {
    "text": "that again are easier to maintain easier update and each one can better suit the very specific purposes that it's meant",
    "start": "254419",
    "end": "260510"
  },
  {
    "text": "to meant to be the next piece is flexible tooling so the data infrastructure world is you",
    "start": "260510",
    "end": "267380"
  },
  {
    "text": "know full of libraries that are all like great and very specific things whether it's tensorflow or OpenCV and so of",
    "start": "267380",
    "end": "273410"
  },
  {
    "text": "course you want to use the best tool for the job but you need a way to manage all these dependencies think I'm running a shared cluster this is exactly the same",
    "start": "273410",
    "end": "279560"
  },
  {
    "text": "problem that containers solve in the micro service world which is again a large suite of tools where you need to manage those dependencies",
    "start": "279560",
    "end": "286720"
  },
  {
    "text": "highly scalable if you've ever done like some sort of data traffic management you probably have seen like this form of a",
    "start": "286720",
    "end": "293660"
  },
  {
    "text": "task dependency graph write different tasks have different SL A's and so it of",
    "start": "293660",
    "end": "300200"
  },
  {
    "text": "course totally makes sense to have each of them Auto scale based on new influxes",
    "start": "300200",
    "end": "305390"
  },
  {
    "text": "of data new processing needs what cluster resources are available and so because of that again",
    "start": "305390",
    "end": "311860"
  },
  {
    "text": "the data infrastructure also needs to be able to scale up and down and be highly",
    "start": "311860",
    "end": "317870"
  },
  {
    "text": "available as you're going through all of these pieces so as you can see like data",
    "start": "317870",
    "end": "323390"
  },
  {
    "text": "infrastructure has many of the same challenges that application enforcer has and it makes a pretty compelling case to try to apply some of these same",
    "start": "323390",
    "end": "329300"
  },
  {
    "text": "principles and so kind of zooming back out that's exactly what pachyderm has done so to take a step back pachyderm started",
    "start": "329300",
    "end": "337490"
  },
  {
    "text": "to think about what the specific data science challenges were and so we're designing pachyderm there were a few",
    "start": "337490",
    "end": "343880"
  },
  {
    "text": "main goals in mind the first was of course as we talk about",
    "start": "343880",
    "end": "350270"
  },
  {
    "text": "any tools right we want allow data scientists to use whatever libraries and tools are best for their job the second",
    "start": "350270",
    "end": "356150"
  },
  {
    "text": "is distributed processing right if you're gonna do any sort of data at scale you clearly need to have a",
    "start": "356150",
    "end": "361520"
  },
  {
    "text": "distributed processing framework so you can scale these things up and down and the third one is actually version",
    "start": "361520",
    "end": "367070"
  },
  {
    "text": "control for data and this is really what we consider the hallmark feature of pachyderm and I'll actually dive into the details of it for a sec but the most",
    "start": "367070",
    "end": "374060"
  },
  {
    "text": "important piece here is that while building a product that could solve these problems and thinking about it in",
    "start": "374060",
    "end": "379550"
  },
  {
    "text": "the framework of how would I build data infrastructure as a set of micro services kubernetes consistently had the",
    "start": "379550",
    "end": "386600"
  },
  {
    "text": "answer that was just the key and really made our life easier so let's dive in them in one by one so",
    "start": "386600",
    "end": "392870"
  },
  {
    "text": "any tools right data scientists as with developers come with just a crazy broad",
    "start": "392870",
    "end": "398050"
  },
  {
    "text": "range of skills they might have they go anywhere from like a statistician right and those are and uses Mathematica all",
    "start": "398050",
    "end": "404980"
  },
  {
    "text": "the way to develop or EDA scientists that use more Python Scala to you know hardcore ETL engineers who love use",
    "start": "404980",
    "end": "411430"
  },
  {
    "text": "everything in C++ and you know go as well and we need all of this bill to run on one unified infrastructure but more",
    "start": "411430",
    "end": "418690"
  },
  {
    "text": "important than any of this what kubernetes really brings is the ability to create the right interface between",
    "start": "418690",
    "end": "424120"
  },
  {
    "text": "the data science teams and the data infrastructure team is Right the infrastructures job is to allow the data scientist to be able to do their work",
    "start": "424120",
    "end": "429910"
  },
  {
    "text": "and interface that effectively and containers and kubernetes are exactly",
    "start": "429910",
    "end": "435070"
  },
  {
    "text": "that great abstraction that gives us a fantastic separation of concerns data scientists are now responsible for",
    "start": "435070",
    "end": "441280"
  },
  {
    "text": "everything that's inside the container right they can build their analysis code and have all of their dependencies and",
    "start": "441280",
    "end": "447010"
  },
  {
    "text": "make sure they know exactly how they're transforming that data but the DevOps team the data infrastructure team is now",
    "start": "447010",
    "end": "452350"
  },
  {
    "text": "in charge of taking that container running it on the infrastructure making many copies of it and making sure that",
    "start": "452350",
    "end": "457630"
  },
  {
    "text": "it runs to completion and these this separation of concerns creates a like really clean organizational process for",
    "start": "457630",
    "end": "463600"
  },
  {
    "text": "actually doing all of this so we can't distribute right so data science at scale clearly needs to be",
    "start": "463600",
    "end": "469720"
  },
  {
    "text": "distributed and then scheduled based on the computational needs and clusters resources available once again",
    "start": "469720",
    "end": "475240"
  },
  {
    "text": "kubernetes had a great answer to this and there's actually their jobs API which serves as a perfect primitive so",
    "start": "475240",
    "end": "480520"
  },
  {
    "text": "I'm gonna kind of demonstrate this through an example so let's say we have a bunch of images sitting in object storage maybe something like s3 right",
    "start": "480520",
    "end": "486640"
  },
  {
    "text": "crew Bay's let's pachyderm spin up many different containers in parallel right and assign a different shard of data to",
    "start": "486640",
    "end": "493720"
  },
  {
    "text": "each of them so each of those containers is running the exact same code which might just be open CV doing let's say",
    "start": "493720",
    "end": "498789"
  },
  {
    "text": "like some sort of edge detection isn't it easy example and what Packer will do is we will take each of these images and",
    "start": "498789",
    "end": "506020"
  },
  {
    "text": "in this example take one-fourth of the images and give them each to each",
    "start": "506020",
    "end": "511630"
  },
  {
    "text": "different containers so now each container has a process a kind of a stream of images in parallel this works",
    "start": "511630",
    "end": "518380"
  },
  {
    "text": "great in kubernetes jobs because guess what if container 3 goes ahead and and dies because containers sometimes do",
    "start": "518380",
    "end": "525100"
  },
  {
    "text": "that kubernetes will automatically restart that and packet ER and basically has the logic then it's a Oh contain",
    "start": "525100",
    "end": "531640"
  },
  {
    "text": "three is the one that died I know what data container three needed so I'm gonna go give that container to the new give",
    "start": "531640",
    "end": "537490"
  },
  {
    "text": "that data to the new to the new container that just came up and be able to reprocess that data and pick up pick up where you left off and so now you",
    "start": "537490",
    "end": "543370"
  },
  {
    "text": "have an ability to scale this out as much as you need this could be for containers or this could be a hundred",
    "start": "543370",
    "end": "548530"
  },
  {
    "text": "giving 1/100 of the day to each of them and you can paralyze out how this data",
    "start": "548530",
    "end": "553750"
  },
  {
    "text": "is processed by just like having your analysis in a container the other side the key thing to point out here is",
    "start": "553750",
    "end": "560050"
  },
  {
    "text": "you're actually not dealing with stateful containers right really all that's happening here is you've got a",
    "start": "560050",
    "end": "565330"
  },
  {
    "text": "container with some code in it it's reading data out of object storage transforming in some way and then",
    "start": "565330",
    "end": "571180"
  },
  {
    "text": "writing it back and so in this in this sense like you are transforming data but like it's you're not dealing with",
    "start": "571180",
    "end": "577570"
  },
  {
    "text": "stateful containers and they can all be scheduled and managed wherever and you basically to treat your object store just like a CDN for your data that all",
    "start": "577570",
    "end": "583450"
  },
  {
    "text": "of your all of your containers can access and then the final piece is",
    "start": "583450",
    "end": "588640"
  },
  {
    "text": "version control for data right so this is one of the cornerstone features of pachyderm and we think actually like",
    "start": "588640",
    "end": "594030"
  },
  {
    "text": "drastically improves the data science workflow in a number of ways version",
    "start": "594030",
    "end": "599110"
  },
  {
    "text": "control for developers is what lets us like collaborate on a large shared code base and not rip our Harrod all the time",
    "start": "599110",
    "end": "605500"
  },
  {
    "text": "imagine if you went into an organization or you were interviewing there and they and they said oh yeah we don't use version control for any of our code you",
    "start": "605500",
    "end": "612700"
  },
  {
    "text": "probably wouldn't take that job well data scientists on day-to-day basis deal with both code and data and it's really",
    "start": "612700",
    "end": "620170"
  },
  {
    "text": "important to be able to actually version both of these and any time know that this is an exact snapshot of my data and",
    "start": "620170",
    "end": "627010"
  },
  {
    "text": "that through this version of my code produce this given result and then okay maybe I had a small new amount of data",
    "start": "627010",
    "end": "633400"
  },
  {
    "text": "come in and I've got like this diff of data now and I want to run that through my new my same version of my code and",
    "start": "633400",
    "end": "640420"
  },
  {
    "text": "get a new result I want to track how all these have changed over time and so when you start thinking about this idea of",
    "start": "640420",
    "end": "646660"
  },
  {
    "text": "what if we version data and connected that with code you get a lot of powerful benefits the first obvious one is",
    "start": "646660",
    "end": "652510"
  },
  {
    "text": "reproducibility which we've already talked about reproducibility lets you say okay I know that if I've run this",
    "start": "652510",
    "end": "661240"
  },
  {
    "text": "code over this snapshot of data anybody else can reproduce those those results it could be a month later and I can say",
    "start": "661240",
    "end": "666910"
  },
  {
    "text": "hey I want to run this transformation over what my users table looked like a month ago and that commit that snapshot",
    "start": "666910",
    "end": "673840"
  },
  {
    "text": "of what my users table look like a month ago is just there and available and every single data scientist if you say",
    "start": "673840",
    "end": "679180"
  },
  {
    "text": "hey run this over the users table knows you're talking about the exact same state of data the next one is instant",
    "start": "679180",
    "end": "686260"
  },
  {
    "text": "revert and we see this in data science organizations all the time there's a lot of time you know you your stuff might",
    "start": "686260",
    "end": "692890"
  },
  {
    "text": "break due to bad code or bad data right and being able to like instantly revert",
    "start": "692890",
    "end": "699100"
  },
  {
    "text": "your data just like we do with code when somebody pushed us to master than they shouldn't have you have now the ability",
    "start": "699100",
    "end": "704620"
  },
  {
    "text": "to instantly revert that and go back to a known good state a really common example of this is let's say you have a",
    "start": "704620",
    "end": "711700"
  },
  {
    "text": "large pipe machine learning pipeline that and the day builds a fraud model right and you've got that fraud model",
    "start": "711700",
    "end": "716770"
  },
  {
    "text": "that you're now pushing out as a service to have fraud to have traffic hit your",
    "start": "716770",
    "end": "722130"
  },
  {
    "text": "hit your server and like decide whether or not it's fraud well if something goes wrong with your input data or maybe your",
    "start": "722130",
    "end": "728230"
  },
  {
    "text": "code and you deploy a fraud model that's incorrect the ability to be able to say oh just like instantaneously revert back",
    "start": "728230",
    "end": "733839"
  },
  {
    "text": "and roll out the old Florida model from yesterday when I go figure out what the heck went wrong becomes incredibly powerful and always knowing how that has",
    "start": "733839",
    "end": "740530"
  },
  {
    "text": "changed over time and let's track that gets really powerful the last piece is also is data lineage and this is kind of",
    "start": "740530",
    "end": "747580"
  },
  {
    "text": "a concept that in the data science world is starting to get a lot of traction right now also like thought of as",
    "start": "747580",
    "end": "752890"
  },
  {
    "text": "provenance and basically what this lets you do is you lets you say here is my like raw input",
    "start": "752890",
    "end": "758740"
  },
  {
    "text": "data and here is all the you know might be 50 steps of transformations that went down to then finally produce this final",
    "start": "758740",
    "end": "764830"
  },
  {
    "text": "result and it might have taken in data from a ton of different sources and pulled together all these different things I need to be able to track every",
    "start": "764830",
    "end": "771100"
  },
  {
    "text": "single step of that because at the end of the day I get to a result and I can look at that graph and say there's no",
    "start": "771100",
    "end": "777280"
  },
  {
    "text": "hey this is right how do I go back and debug all that and audit that whole trail of how my data has changed and all",
    "start": "777280",
    "end": "783850"
  },
  {
    "text": "these different pieces of code that would have transformed it and when you think about having your data version",
    "start": "783850",
    "end": "788860"
  },
  {
    "text": "including all these intermediate steps you now have the ability to really do that and it makes the iteration cycle",
    "start": "788860",
    "end": "795160"
  },
  {
    "text": "for developing data science just incredibly much faster and very powerful",
    "start": "795160",
    "end": "800370"
  },
  {
    "text": "so data versioning comes with this challenges too as you might expect the biggest one is that you for tracking",
    "start": "800370",
    "end": "807580"
  },
  {
    "text": "changes and dips of files this creates a lot of metadata that you need indexed and readily available for fast look ups",
    "start": "807580",
    "end": "814120"
  },
  {
    "text": "well as you might expect what you'd want to use for this is a database to store all of your metadata but this causes a",
    "start": "814120",
    "end": "820600"
  },
  {
    "text": "whole bunch of problems but once again kubernetes came you know showed up and saved the day because they released pet",
    "start": "820600",
    "end": "826600"
  },
  {
    "text": "sets and persistent volumes and pachyderm basically that's exactly how I would do it we have a metadata database that stores all that information and",
    "start": "826600",
    "end": "832990"
  },
  {
    "text": "like basically talks about controls the metadata around how data how files are",
    "start": "832990",
    "end": "839680"
  },
  {
    "text": "versioned and difft and that's run as a pet set Whitney to the president of volume and this now becomes highly",
    "start": "839680",
    "end": "846280"
  },
  {
    "text": "available in kubernetes you get to run it right there if you need to you can always take that and sync it back to something like s3 or your object storage",
    "start": "846280",
    "end": "853570"
  },
  {
    "text": "if you want to make sure it's it's super persistent but kunai's does a pretty good job of it on its own",
    "start": "853570",
    "end": "858930"
  },
  {
    "text": "so let's take a deep breath for say and kind of stand back and think about the kind of world view we've we've built",
    "start": "858930",
    "end": "864670"
  },
  {
    "text": "here we want to be able to run your data infrastructure like the way you run",
    "start": "864670",
    "end": "869950"
  },
  {
    "text": "applications right there is a world where that can really be possible that includes modular services for your data",
    "start": "869950",
    "end": "877750"
  },
  {
    "text": "infrastructure with clean abstractions between to them flexible tooling so your data science team can use whatever it",
    "start": "877750",
    "end": "883780"
  },
  {
    "text": "wants and combine and compose all these pieces together however they like highly scalable and dynamically scaling in fact",
    "start": "883780",
    "end": "891250"
  },
  {
    "text": "to change as your data processing needs evolve and of course reproducible and",
    "start": "891250",
    "end": "896950"
  },
  {
    "text": "that includes data versioning so that way you can track how things are changing over time and actually have make your to have your data reproducible",
    "start": "896950",
    "end": "903970"
  },
  {
    "text": "in addition to your actual code and we want to do all this with one unified",
    "start": "903970",
    "end": "909010"
  },
  {
    "text": "infrastructure and because of the power of kubernetes we actually can so of course if you're excited about building",
    "start": "909010",
    "end": "915340"
  },
  {
    "text": "your data infrastructure in this way and you like the idea of saying okay I'm used to running my application",
    "start": "915340",
    "end": "921310"
  },
  {
    "text": "infrastructure as a set of micro services let me think about the my data infrastructure in a similar format you",
    "start": "921310",
    "end": "927520"
  },
  {
    "text": "should absolutely check out kubernetes and like try thinking about setting your you're set up this way and you should",
    "start": "927520",
    "end": "932650"
  },
  {
    "text": "also look at packet er because we basically build a framework for doing it in exactly that sense cool that's the",
    "start": "932650",
    "end": "938710"
  },
  {
    "text": "end I wanted to give a lot of time for questions because I tend to get a lot and I went pretty fast there",
    "start": "938710",
    "end": "945120"
  },
  {
    "text": "sit i i couldnt hear that last part that question oh",
    "start": "958390",
    "end": "962820"
  },
  {
    "text": "alright so the question was where one weird one do something that store like store huge log files and such for us we",
    "start": "967710",
    "end": "975220"
  },
  {
    "text": "actually do that in object storage as well and i've i've found that most most",
    "start": "975220",
    "end": "980380"
  },
  {
    "text": "object stores are actually quite able to handle that in a reasonable sense these",
    "start": "980380",
    "end": "985510"
  },
  {
    "text": "files you can always break up these files in in ways if that if that was a problem what have you experienced",
    "start": "985510",
    "end": "990760"
  },
  {
    "text": "specifically that causes problems for that",
    "start": "990760",
    "end": "995550"
  },
  {
    "text": "yeah object storage works great for this like honestly like big files work work perfect and we've we've had no problems",
    "start": "999840",
    "end": "1006030"
  },
  {
    "text": "with it so far is that question over here",
    "start": "1006030",
    "end": "1010700"
  },
  {
    "text": "yeah the question was how how's the versioning done is that under the application of pachyderm the answer is that's done by pachyderm and so",
    "start": "1016850",
    "end": "1022100"
  },
  {
    "text": "pachyderm actually the way where do we do this is it's kind of two ways we version things so we're basically we we",
    "start": "1022100",
    "end": "1028188"
  },
  {
    "text": "let you structure your data in terms of commits so you have a set of files and that would be commits and then you may",
    "start": "1028189",
    "end": "1034009"
  },
  {
    "text": "add files overwrite some files append to the end of other files and we store all of those changes that you made to the",
    "start": "1034009",
    "end": "1039709"
  },
  {
    "text": "files as a diff as a new commit that's overlaid on top of that and so in fact from a data science code perspective",
    "start": "1039709",
    "end": "1046699"
  },
  {
    "text": "your code doesn't really have to be super smart in terms of doing anything",
    "start": "1046699",
    "end": "1051799"
  },
  {
    "text": "with versioning pachyderm expose the data to you in this versioned way and so let's say you know have a huge log file",
    "start": "1051799",
    "end": "1058700"
  },
  {
    "text": "and you've appended you know 1% more logs at the end pachyderm will in your automatically be",
    "start": "1058700",
    "end": "1065240"
  },
  {
    "text": "able to say ok I want to only show this piece of analysis the new log files because I only need to process the new",
    "start": "1065240",
    "end": "1071360"
  },
  {
    "text": "logs right and so packing will kind of expose exactly the right data for you inside the container",
    "start": "1071360",
    "end": "1078700"
  },
  {
    "text": "yeah so when you have a continuous stream of logs coming in basically the way pachyderm handles this is you can",
    "start": "1081820",
    "end": "1087830"
  },
  {
    "text": "just make commits at whatever frequency you want and commits actually are very low overhead overall and so we have we",
    "start": "1087830",
    "end": "1094429"
  },
  {
    "text": "have production users making you know a commit every minute or commit every 30 seconds and so you can make commits all",
    "start": "1094429",
    "end": "1100340"
  },
  {
    "text": "the time and now your log will just constantly appending and broken up into these 30-second chunks each of which",
    "start": "1100340",
    "end": "1106460"
  },
  {
    "text": "gets processed downstream",
    "start": "1106460",
    "end": "1109508"
  },
  {
    "text": "you you can you can if do that if you want you don't have to pack it er pachyderm like there's if you if you're",
    "start": "1114980",
    "end": "1121139"
  },
  {
    "text": "just appending loglines constantly there's very little overhead to doing that as you know aggregating all the",
    "start": "1121139",
    "end": "1126990"
  },
  {
    "text": "logs for an hour and making commits versus doing a commit every minute just as that's coming through sure",
    "start": "1126990",
    "end": "1134899"
  },
  {
    "text": "yeah so the pack denote itself were just kind of the coordinator for all this is just a pot in kubernetes so you can",
    "start": "1137720",
    "end": "1143639"
  },
  {
    "text": "scale that out and run that as much and you thin the cluster and then pachyderm itself scales like great with kubernetes",
    "start": "1143639",
    "end": "1149850"
  },
  {
    "text": "jobs right you can spin up thousands of kubernetes jobs all at once and kubernetes will schedule all those and",
    "start": "1149850",
    "end": "1155580"
  },
  {
    "text": "figure out all where you go so all we get all the scaling benefits from kubernetes and pachyderm itself just",
    "start": "1155580",
    "end": "1161580"
  },
  {
    "text": "basically coordinates this and assigns shards of data two sets of containers",
    "start": "1161580",
    "end": "1168230"
  },
  {
    "text": "[Music] it's great for parallel workloads you know if if you have things that can't be",
    "start": "1171840",
    "end": "1178880"
  },
  {
    "text": "paralyzed very well right so some machine learning models right like you can't paralyze that you're not gonna be",
    "start": "1178880",
    "end": "1184100"
  },
  {
    "text": "able to get the benefits of running this in distribute fashion but you can still throw all of this as a single big beefy",
    "start": "1184100",
    "end": "1190160"
  },
  {
    "text": "box within pachyderm and that's totally fine right and so pachyderm works really well actually for like quite",
    "start": "1190160",
    "end": "1196930"
  },
  {
    "text": "heterogeneous like huge datasets where you might have this piece over here that",
    "start": "1196930",
    "end": "1202760"
  },
  {
    "text": "is all has to be single thread right on like big beefy boxes and this thing over here can be really paralyzed right you",
    "start": "1202760",
    "end": "1207980"
  },
  {
    "text": "might have a map job a map style job that can be incredibly distributed but then you've got to reduce where you got",
    "start": "1207980",
    "end": "1213350"
  },
  {
    "text": "to aggregate everything all together and like that both of those setups work perfectly fine a packet and we give you same style map and reduce primitives",
    "start": "1213350",
    "end": "1221000"
  },
  {
    "text": "that you might be used to from Hadoop to run exactly that",
    "start": "1221000",
    "end": "1225730"
  },
  {
    "text": "yeah",
    "start": "1247649",
    "end": "1250649"
  },
  {
    "text": "that's a great question the question was basically that as an inference I'd you guys kind of have a good picture of pachyderm but oftentimes presenting this",
    "start": "1266410",
    "end": "1272650"
  },
  {
    "text": "to the data scientists they have a hard time kind of wrapping their head around all of that yeah so at the kind of early",
    "start": "1272650",
    "end": "1279220"
  },
  {
    "text": "stage we're at now that's definitely something we've seen occasionally oftentimes especially data scientists",
    "start": "1279220",
    "end": "1284470"
  },
  {
    "text": "who kind of lean a little bit more towards the developers side of things find this",
    "start": "1284470",
    "end": "1289870"
  },
  {
    "text": "to be a great a very powerful interface one of the things we're starting to build now is the like actual like",
    "start": "1289870",
    "end": "1295540"
  },
  {
    "text": "natives as a supporting Jupiter no prefer you can just have a Jupiter no Park run that directly in the container",
    "start": "1295540",
    "end": "1300640"
  },
  {
    "text": "and as far as the data scientists are concerned their interface is exactly the same the only difference is now in that",
    "start": "1300640",
    "end": "1306130"
  },
  {
    "text": "like code repo gives ours also docker file there that builds the whole thing into a container right and so making",
    "start": "1306130",
    "end": "1311200"
  },
  {
    "text": "that story very very clean for data scientists definitely is something that we're continuing to make better on the",
    "start": "1311200",
    "end": "1317590"
  },
  {
    "text": "flip side when you're talking about being able to version data and think about how data is built to be snapshots data scientists tend to glom onto that",
    "start": "1317590",
    "end": "1324370"
  },
  {
    "text": "right away and say oh that would be amazing right most of a data scientists job is actually not spent in terms of",
    "start": "1324370",
    "end": "1330280"
  },
  {
    "text": "time doing the interesting mathematical operations that they're great at it tends to be a lot of data munging and",
    "start": "1330280",
    "end": "1336100"
  },
  {
    "text": "testing and trying to figure out how I down sample the right stuff get this to work locally and then figure out how to like either myself or work with the hand",
    "start": "1336100",
    "end": "1342730"
  },
  {
    "text": "pressure team to get this to work actually in the cluster and when you can say the exact same Python script that",
    "start": "1342730",
    "end": "1348790"
  },
  {
    "text": "you wrote locally and like that runs locally that exact same thing is now like what you send off to the data",
    "start": "1348790",
    "end": "1355090"
  },
  {
    "text": "infrastructure and that's going to run in the cluster it could be distributed that now starts to feel very powerful right and that that Python script by the",
    "start": "1355090",
    "end": "1361810"
  },
  {
    "text": "way when they're running on the laptop was probably reading and writing just local files that's actually how",
    "start": "1361810",
    "end": "1367090"
  },
  {
    "text": "pachyderm works itself - I was talking about this with a gentleman here earlier pachyderm basically takes the data in",
    "start": "1367090",
    "end": "1372910"
  },
  {
    "text": "the distributed file system right and now after storage and mounts it locally as a local file system inside the",
    "start": "1372910",
    "end": "1378070"
  },
  {
    "text": "container right and that's how we divvy up what data goes into what container and so the idea that that's that Python",
    "start": "1378070",
    "end": "1384520"
  },
  {
    "text": "script still just reads and writes local files and that's like that's the only cognate overhead they have to think about in terms of accessing their data",
    "start": "1384520",
    "end": "1390810"
  },
  {
    "text": "that starts to be a pretty pretty powerful way to think about things",
    "start": "1390810",
    "end": "1396690"
  },
  {
    "text": "that's a great question so right now the the auto-scaling pieces of this are",
    "start": "1403620",
    "end": "1409870"
  },
  {
    "text": "pretty pretty primitive what you know pachyderm will basically parallel eyes",
    "start": "1409870",
    "end": "1415149"
  },
  {
    "text": "for each pipeline for each you know state task in that dag you can set a paralyzation factor and pachyderm will",
    "start": "1415149",
    "end": "1421210"
  },
  {
    "text": "try to spin up up to that many containers in terms of how much they want to paralyze that in terms of how",
    "start": "1421210",
    "end": "1426880"
  },
  {
    "text": "kubernetes now wants to manage its resources that really comes to like how you ought to scale the underlying",
    "start": "1426880",
    "end": "1432940"
  },
  {
    "text": "resources that kubernetes manages right so if you wanted to for instance say oh we've got a bunch of new processing",
    "start": "1432940",
    "end": "1438460"
  },
  {
    "text": "coming in now packing rooms trying to schedule a ton of different containers crew readies might say okay I'm gonna go out to the sponsors market and bring in",
    "start": "1438460",
    "end": "1444580"
  },
  {
    "text": "a bunch of new nodes and spin that up and like that's how I'm gonna like be able to fill out all these worker loads packing them on the other hand really",
    "start": "1444580",
    "end": "1450039"
  },
  {
    "text": "just thinks about it from their perspective like how paralyze do you want this to be okay we're gonna try to",
    "start": "1450039",
    "end": "1455409"
  },
  {
    "text": "schedule that much with kubernetes and if that's not working or things are running slow or things can't be scheduled we can kind of scale that up",
    "start": "1455409",
    "end": "1460570"
  },
  {
    "text": "or scale that back yeah yeah so actually like pipeline",
    "start": "1460570",
    "end": "1467559"
  },
  {
    "text": "configurations and packet or work exactly that's just a JSON file that you that you put in and that's that's a",
    "start": "1467559",
    "end": "1475289"
  },
  {
    "text": "yeah in terms of like how you specify your your pipeline and packet or like that's it and then you've got your and",
    "start": "1479190",
    "end": "1485019"
  },
  {
    "text": "that that JSON file you know specifies the name of your pipeline what image you want to use and the Registrar you",
    "start": "1485019",
    "end": "1490029"
  },
  {
    "text": "pulling it from you know what functions are gonna call within your code within the container and then things like the",
    "start": "1490029",
    "end": "1496210"
  },
  {
    "text": "peril Asian factor how do you want your data sharted right if it's a it's a map style step like the images example I",
    "start": "1496210",
    "end": "1501700"
  },
  {
    "text": "talked about you don't care which images go where right you just want them you can think lease all spread out if it's something more kind of reduced style",
    "start": "1501700",
    "end": "1507759"
  },
  {
    "text": "where you need a entire file or a group of files all need to be seen by a given container you specify exactly that kind",
    "start": "1507759",
    "end": "1514779"
  },
  {
    "text": "of stuff right there in the JSON file and packing and we'll make sure to keep all those things together as it shards it out",
    "start": "1514779",
    "end": "1521309"
  },
  {
    "text": "anything else it's a great question so the question",
    "start": "1523230",
    "end": "1530440"
  },
  {
    "text": "was how to spark work from this framework so right now we've got a couple customers that are kind of playing around with running a cannery",
    "start": "1530440",
    "end": "1536830"
  },
  {
    "text": "spark cluster and like running that within pachyderm one of the things that we're in the process of building is",
    "start": "1536830",
    "end": "1541870"
  },
  {
    "text": "basically what we think of as a services primitive and what that lets you do is you can have these multiple stages of your pipeline and one of the stages can",
    "start": "1541870",
    "end": "1548080"
  },
  {
    "text": "be a service that basically lets you say okay I've got this data in pachyderm as my input data let me push that over to a",
    "start": "1548080",
    "end": "1554260"
  },
  {
    "text": "spark cluster that I can spin up right now to process all that data and then spark will write that data back in a",
    "start": "1554260",
    "end": "1559570"
  },
  {
    "text": "pachyderm and then continue downstream from there and so this is something that is very easy to do pachyderm kind of we",
    "start": "1559570",
    "end": "1565450"
  },
  {
    "text": "think about it all the time as kinda has on the adapters on all ends is that you can basically have a pipeline it just",
    "start": "1565450",
    "end": "1571150"
  },
  {
    "text": "reads and writes data out from anywhere right and so it's very easy to spark an already read out of object storage becomes very easy now to basically push",
    "start": "1571150",
    "end": "1578620"
  },
  {
    "text": "information over to a spark cluster do all your competition in that sense and then push it back in a pachyderm and",
    "start": "1578620",
    "end": "1584050"
  },
  {
    "text": "make sure all of that is still versioned yeah",
    "start": "1584050",
    "end": "1591090"
  },
  {
    "text": "totally yeah so so the question here is basically around like how pachyderm",
    "start": "1609580",
    "end": "1615070"
  },
  {
    "text": "thinks about diffs and how that kind of translates into doing what we think of as incremental processing and your your",
    "start": "1615070",
    "end": "1621639"
  },
  {
    "text": "comment is exactly right like not everything can be done effectively in an incremental way right I I mentioned kind",
    "start": "1621639",
    "end": "1626950"
  },
  {
    "text": "of in passing during the talk that oh yeah we can say oh there's like 5% new data and I don't",
    "start": "1626950",
    "end": "1633249"
  },
  {
    "text": "actually need any of the other data let me just process that new 5% because pachyderm is aware of what data has",
    "start": "1633249",
    "end": "1639369"
  },
  {
    "text": "changed what data is new you can be really smart about that and for for things like long lines than just being",
    "start": "1639369",
    "end": "1644679"
  },
  {
    "text": "appended this is like trivially easy now you can just say okay this is the new data that you want only process that for",
    "start": "1644679",
    "end": "1651519"
  },
  {
    "text": "some types of computation you do need that that all of the data right if you're doing I don't know I'm just",
    "start": "1651519",
    "end": "1656559"
  },
  {
    "text": "saying I have a bunch of numbers and I'm doing a median right like I need to have all the data the whole time there and so",
    "start": "1656559",
    "end": "1661720"
  },
  {
    "text": "because of that like you can't really leverage the incrementality kind of the way we always joke about this is like",
    "start": "1661720",
    "end": "1667029"
  },
  {
    "text": "pachyderm can't solve math for you but it lets you optimize it whenever there's opportunities to do that and they're",
    "start": "1667029",
    "end": "1672850"
  },
  {
    "text": "actually surprisingly a lot of opportunities and a large swath of the things that that you do in a tipple of",
    "start": "1672850",
    "end": "1679330"
  },
  {
    "text": "data science workflow do fall under things that can potentially be distributed as well as can be",
    "start": "1679330",
    "end": "1684909"
  },
  {
    "text": "incremental there's kind of a class of things that we think of as like online algorithms that work in this way and happy to kind of dive in and talk about",
    "start": "1684909",
    "end": "1691509"
  },
  {
    "text": "more about what what things work really well what types of workflows work well in in that framework versus kind of more",
    "start": "1691509",
    "end": "1698139"
  },
  {
    "text": "of a typical flavor up or you just crunch through everything again from scratch",
    "start": "1698139",
    "end": "1702778"
  },
  {
    "text": "so so I think your question is basically how does pachyderm think about splitting data relative to kubernetes jobs yeah so",
    "start": "1718620",
    "end": "1726430"
  },
  {
    "text": "so the way we think about it is if you're a paralyzation factor for a given task was 10 right so we're gonna spit up",
    "start": "1726430",
    "end": "1731860"
  },
  {
    "text": "10 containers now pachyderm will take all the data you have and let's again say it's a map step like that has images",
    "start": "1731860",
    "end": "1738190"
  },
  {
    "text": "so the images can go wherever right we will basically take take one tenth of",
    "start": "1738190",
    "end": "1743380"
  },
  {
    "text": "the images and we can just use like hashes of the filenames to do this and split them up into shards 0 of 10 or 0",
    "start": "1743380",
    "end": "1749920"
  },
  {
    "text": "nitrite and split those all out and then we'll basically say like okay this container here right is now responsible",
    "start": "1749920",
    "end": "1755380"
  },
  {
    "text": "its container 1 and this is correspond scible for that 1/10 of the images and if that container dies we now know the",
    "start": "1755380",
    "end": "1761740"
  },
  {
    "text": "okay that data now needs to be scheduled on the new container that kubernetes brings up and so pachyderm itself kind",
    "start": "1761740",
    "end": "1768490"
  },
  {
    "text": "of is the part that does the the sharding in terms of figuring out here's how many containers I have how do I want",
    "start": "1768490",
    "end": "1773650"
  },
  {
    "text": "to split the data Cabrera's jobs as far as the the jobs for me was concerned it just knows that I had got 10 containers",
    "start": "1773650",
    "end": "1779200"
  },
  {
    "text": "and all of them need to run to completion I need actually run to cleats in 10 total times in order for me to",
    "start": "1779200",
    "end": "1784660"
  },
  {
    "text": "call this whole whole job done",
    "start": "1784660",
    "end": "1788550"
  },
  {
    "text": "oh how that sharding is done that sharding is actually defined in the pipeline spec",
    "start": "1792430",
    "end": "1799060"
  },
  {
    "text": "so when you when you define your pipeline for pachyderm that specifies like here's my input it is and here's",
    "start": "1799060",
    "end": "1804460"
  },
  {
    "text": "how it can be it can be split up right",
    "start": "1804460",
    "end": "1808320"
  },
  {
    "text": "I'm sorry I could I couldn't quite hear their yeah",
    "start": "1822419",
    "end": "1828980"
  },
  {
    "text": "yep",
    "start": "1828980",
    "end": "1831980"
  },
  {
    "text": "Oh Oh so yes okay so pachyderm kind of does that for you so you don't have to define your your your pod spec for your for",
    "start": "1838200",
    "end": "1844980"
  },
  {
    "text": "your pipeline and you basically specify the the pipeline part in pachyderm and like I said that specifies an image and",
    "start": "1844980",
    "end": "1850200"
  },
  {
    "text": "then pachyderm will spin up those those pods and containers that now like get",
    "start": "1850200",
    "end": "1856710"
  },
  {
    "text": "run so you don't actually have to specify the pod details as part of the pipeline both in kubernetes and",
    "start": "1856710",
    "end": "1862050"
  },
  {
    "text": "pachyderm you just do that in pachyderm and pachyderm will will build all the right kubernetes pieces for you",
    "start": "1862050",
    "end": "1869540"
  },
  {
    "text": "anything else cool I'm here I'm around I got the big green shirt on so happy to",
    "start": "1869540",
    "end": "1875580"
  },
  {
    "text": "answer more questions I should got one more",
    "start": "1875580",
    "end": "1878780"
  },
  {
    "text": "it's completely reliant on kubernetes scheduler yeah so I mean that was kind of one of the big design primitive",
    "start": "1881120",
    "end": "1886830"
  },
  {
    "text": "packages like let's not build everything from scratch right you know Hadoop had to build all of the distributed systems",
    "start": "1886830",
    "end": "1893040"
  },
  {
    "text": "primitives and schedulers and zookeeper and all these pieces and then kind of go solve the big data problem and Packers",
    "start": "1893040",
    "end": "1899250"
  },
  {
    "text": "approach to this has been you know kubernetes gives us almost everything we need to be able to solve this from a",
    "start": "1899250",
    "end": "1904950"
  },
  {
    "text": "distributed systems and scheduling perspective let's just focus on what would a fantastic interface be for data",
    "start": "1904950",
    "end": "1910770"
  },
  {
    "text": "scientists and data infrastructure is",
    "start": "1910770",
    "end": "1915890"
  },
  {
    "text": "cool yep",
    "start": "1915890",
    "end": "1919310"
  },
  {
    "text": "so so the versioning itself is done on files in an object storage right so",
    "start": "1933970",
    "end": "1939210"
  },
  {
    "text": "basically the we have a couple different flavors of versioning I'm happy to dive into more of these details offline if",
    "start": "1939210",
    "end": "1945070"
  },
  {
    "text": "you want basically you know we have pile versioning right so you we know if you've like over it in a file if you've",
    "start": "1945070",
    "end": "1951280"
  },
  {
    "text": "added a new file if you've deleted a file similarly we also have a pen based versioning so if you add new lines to",
    "start": "1951280",
    "end": "1957130"
  },
  {
    "text": "the end of a file we know that like this is now the diff right so file foo and commit one was these hundred lines and",
    "start": "1957130",
    "end": "1963880"
  },
  {
    "text": "file foo if you redo that commit to is these hundred lines plus another you know maybe another 50 lines of something",
    "start": "1963880",
    "end": "1969159"
  },
  {
    "text": "there and so that's how that dipping is done we are in the process of building now the ability to do kind of more sophisticated things like line base",
    "start": "1969159",
    "end": "1975490"
  },
  {
    "text": "dipping for text files or something like that where now you could update the middle of a file somewhere",
    "start": "1975490",
    "end": "1981669"
  },
  {
    "text": "and you'd be able to see that as a diff impactor",
    "start": "1981669",
    "end": "1987330"
  },
  {
    "text": "it's meted we basically use a fuse volume that gets mount that we use fuse to mount that data inside it's not actually a persistent volume that's",
    "start": "1999190",
    "end": "2005400"
  },
  {
    "text": "that's mounted to the container I",
    "start": "2005400",
    "end": "2009080"
  },
  {
    "text": "don't believe so I'll be honest I'd have to I'd have to ask somebody to like go through the details of exactly how that",
    "start": "2012620",
    "end": "2018270"
  },
  {
    "text": "works if this is something that's been kind of changing recently so I have to look into that happy to follow up with",
    "start": "2018270",
    "end": "2023460"
  },
  {
    "text": "you offline on that anything else",
    "start": "2023460",
    "end": "2030440"
  },
  {
    "text": "awesome thank you so much guys appreciate it [Applause]",
    "start": "2030440",
    "end": "2037219"
  }
]
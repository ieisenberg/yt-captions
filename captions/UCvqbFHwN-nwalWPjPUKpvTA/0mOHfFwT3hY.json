[
  {
    "text": "so good afternoon everyone okay so it's an honor and a",
    "start": "160",
    "end": "5440"
  },
  {
    "text": "privilege to be invited as a speaker for the very first cubec happening in India",
    "start": "5440",
    "end": "11160"
  },
  {
    "text": "and we really appreciate all of you to take some time and you know to to sit here and listen to us okay so before we",
    "start": "11160",
    "end": "18760"
  },
  {
    "text": "uh move forward just a quick show of hands how many of you here are less than",
    "start": "18760",
    "end": "24039"
  },
  {
    "text": "5 years of experience in the industry okay nice how about 5 to 10",
    "start": "24039",
    "end": "30840"
  },
  {
    "text": "how about 10 plus and do we have any 20 plus lovely lovely okay and do we have",
    "start": "30840",
    "end": "40280"
  },
  {
    "text": "anyone from program product or engineering manager side okay we have some in the back nice",
    "start": "40280",
    "end": "47320"
  },
  {
    "text": "so what we've done we have basically constructed our uh presentation such that each and every one of you have some",
    "start": "47320",
    "end": "54520"
  },
  {
    "text": "key takeaways so you after this presentation you'll be able to better architect a ml or a non-ml deployment",
    "start": "54520",
    "end": "63400"
  },
  {
    "text": "architecture with that hello everyone my name is Sumit I am part of adop's",
    "start": "63400",
    "end": "69000"
  },
  {
    "text": "developer platform team I've been working on the tech side for past decade and I've been part of adobi for past",
    "start": "69000",
    "end": "75159"
  },
  {
    "text": "couple of years and we've been majorly working towards you know providing cicd Solutions across different different use",
    "start": "75159",
    "end": "81360"
  },
  {
    "text": "cases including CPU based GPU based right so so hi everyone so thanks a lot for",
    "start": "81360",
    "end": "89920"
  },
  {
    "text": "joining the session I'm thean I've been working in adobi for the last 2 years and my work mostly includes designing C",
    "start": "89920",
    "end": "97000"
  },
  {
    "text": "CD pipelines and more importantly the deployment strategies for various use cases that we'll be be covering in this",
    "start": "97000",
    "end": "103840"
  },
  {
    "text": "PPD also so yeah good to be here I don't know why I keep on forgetting thean",
    "start": "103840",
    "end": "109560"
  },
  {
    "text": "man all right so so before we jump into our presentation I want to I want",
    "start": "109560",
    "end": "115040"
  },
  {
    "text": "everyone of you to just look at this chart okay so throughout the present presentation we're going to talk about",
    "start": "115040",
    "end": "121880"
  },
  {
    "text": "so different different deployment strategies that's our x-axis here and we",
    "start": "121880",
    "end": "128479"
  },
  {
    "text": "also going to talk about how they are relevant with different different architectures the y- axis here is",
    "start": "128479",
    "end": "134160"
  },
  {
    "text": "showing the monthly cost that it can incur to you depending upon which strategy you choose now interestingly",
    "start": "134160",
    "end": "141599"
  },
  {
    "text": "what we did we removed the names and we put them in numbers so throughout the",
    "start": "141599",
    "end": "146840"
  },
  {
    "text": "presentation we're going to give you some use cases some techniques and all that and in the end we're going to have a poll where we'll ask you guys what do",
    "start": "146840",
    "end": "153480"
  },
  {
    "text": "you think which one are the last two ones so we're going to focus on the yellow ones and the pink one and let's",
    "start": "153480",
    "end": "159480"
  },
  {
    "text": "see like who guys is right with that thought I'm going to ask Divan to talk",
    "start": "159480",
    "end": "164560"
  },
  {
    "text": "about something but before we do that let's just quickly cover what we're going to talk about today so we will be",
    "start": "164560",
    "end": "171239"
  },
  {
    "text": "talking a little bit about Progressive delivery primarily we'll focus the key",
    "start": "171239",
    "end": "176360"
  },
  {
    "text": "techniques and strategies which are going to help you to understand understand the various aspects of",
    "start": "176360",
    "end": "181920"
  },
  {
    "text": "progressive delivery and then we'll also touch up a little bit about the generative AI architectures particularly",
    "start": "181920",
    "end": "188239"
  },
  {
    "text": "in the deployment perspective okay and once we have all those context we'll talk about why we think that J plays a",
    "start": "188239",
    "end": "195879"
  },
  {
    "text": "big role when it comes to Progressive delivery with that we're going to use various techniques various strategies to",
    "start": "195879",
    "end": "202760"
  },
  {
    "text": "help you decide which strategies fit in what business use case so once we do",
    "start": "202760",
    "end": "207840"
  },
  {
    "text": "that we're going to talk about the best practices is the key takeaways and with that thought I'm going to hand it off to",
    "start": "207840",
    "end": "213840"
  },
  {
    "text": "thean thanks thanks a lot suit for such a nice introduction so uh I would",
    "start": "213840",
    "end": "219959"
  },
  {
    "text": "actually like to know from you guys how many of you are actually using continuous deployment in your work can I",
    "start": "219959",
    "end": "225760"
  },
  {
    "text": "see hands like how many of you are using oh that's cool a lot of you are using so",
    "start": "225760",
    "end": "232480"
  },
  {
    "text": "let's keep that terminology aside and let's try to understand what exactly is Progressive delivery and why it's so",
    "start": "232480",
    "end": "238720"
  },
  {
    "text": "important so when we want to release a new version to the customers if we are",
    "start": "238720",
    "end": "245519"
  },
  {
    "text": "going through a traditional approach that is all at once where we are actually going to release the whole",
    "start": "245519",
    "end": "251319"
  },
  {
    "text": "version to all the customers at one go then there is of course a caveat right",
    "start": "251319",
    "end": "256400"
  },
  {
    "text": "if there is a single defect like a typo also a huge customer wasas will get",
    "start": "256400",
    "end": "261759"
  },
  {
    "text": "impacted the blast radius is going to be huge for this right so the question is can we have a better approach a more",
    "start": "261759",
    "end": "268520"
  },
  {
    "text": "safer approach and that's where we can think of gradually moving instead of going all at once that's where",
    "start": "268520",
    "end": "275280"
  },
  {
    "text": "Progressive delivery comes into picture where we are instead of going all at once we are first exposing the version",
    "start": "275280",
    "end": "282000"
  },
  {
    "text": "to a subset of users we then get a feedback from them and see if that version is actually working as expected",
    "start": "282000",
    "end": "289440"
  },
  {
    "text": "and on the basis of that we either promote to the next set seted user or maybe decide to roll back and this way",
    "start": "289440",
    "end": "296320"
  },
  {
    "text": "we are making our approach more safer and through this we are actually gaining",
    "start": "296320",
    "end": "301520"
  },
  {
    "text": "more a lot of benefits like first of all we are prioritizing the user experience let's say we are taking timely feedback",
    "start": "301520",
    "end": "308560"
  },
  {
    "text": "from the user at different steps and also we are also experimenting with the live traffic on the um new version so",
    "start": "308560",
    "end": "316199"
  },
  {
    "text": "yeah I mean this approach can be considered which can be more safer and",
    "start": "316199",
    "end": "321360"
  },
  {
    "text": "of course like we can have instead of having this mindset of deploy or die we",
    "start": "321360",
    "end": "327280"
  },
  {
    "text": "can have a mindset that is deploy verify Thrive and this is an enhancement for",
    "start": "327280",
    "end": "332840"
  },
  {
    "text": "the continuous deployment so yeah so like Sam mentioned there are various",
    "start": "332840",
    "end": "338080"
  },
  {
    "text": "ways of releasing a version so let's look at few of them one is the blue green strategy so let's say we have a",
    "start": "338080",
    "end": "346440"
  },
  {
    "text": "version one that is addressing 100% of the traffic as of now then the developer",
    "start": "346440",
    "end": "351960"
  },
  {
    "text": "decides to trigger a new deployment and once the deployment is triggered a new",
    "start": "351960",
    "end": "357360"
  },
  {
    "text": "set of replica sets are spun up which are of version two so it's not that we are going to uh shift the 100% traffic",
    "start": "357360",
    "end": "364720"
  },
  {
    "text": "to this new replica set all at once instead we will first test the replica",
    "start": "364720",
    "end": "369800"
  },
  {
    "text": "set with our own request it's like we will own we will eat our own doc food yeah so we'll test the new replica set",
    "start": "369800",
    "end": "377560"
  },
  {
    "text": "with our test request and then once we are confident we'll shift the 100%",
    "start": "377560",
    "end": "383039"
  },
  {
    "text": "traffic to this new replica set yeah this is how we perform blue green deployment now there is an another",
    "start": "383039",
    "end": "390120"
  },
  {
    "text": "approach where we can go in a more gradual way and that's scary deployment",
    "start": "390120",
    "end": "395360"
  },
  {
    "text": "so let's start from the beginning we have a version one that is shift",
    "start": "395360",
    "end": "400720"
  },
  {
    "text": "addressing 100% of the traffic now we will spin up few of the replica set of",
    "start": "400720",
    "end": "406199"
  },
  {
    "text": "version two and instead of Shifting 100% traffic we will take X maybe some amount",
    "start": "406199",
    "end": "412880"
  },
  {
    "text": "of traffic for this new replica let's say 20% in this case and we will analyze",
    "start": "412880",
    "end": "418599"
  },
  {
    "text": "if this replica said is actually performing well this with such amount of traffic we will basically perform",
    "start": "418599",
    "end": "425639"
  },
  {
    "text": "automated test maybe manual test and once we gain confidence we will move further to the next step that is",
    "start": "425639",
    "end": "431919"
  },
  {
    "text": "basically shifting more traffic and this will go on till we reach the 100 100%",
    "start": "431919",
    "end": "437039"
  },
  {
    "text": "Target yeah so these are few of the ways there are many more but for this we are",
    "start": "437039",
    "end": "442360"
  },
  {
    "text": "just targeting blue green and cry so now that you're aware about various ways",
    "start": "442360",
    "end": "447520"
  },
  {
    "text": "let's move to the next thing that is Gen architectures so the first one is quite",
    "start": "447520",
    "end": "454240"
  },
  {
    "text": "simple it's a basically a push based model so as you can see few of the resources are marked as pink color which",
    "start": "454240",
    "end": "461280"
  },
  {
    "text": "basically are deployed in CPU notes the other ones that are in blue are actually deployed in CPU modes so what's",
    "start": "461280",
    "end": "467840"
  },
  {
    "text": "happening is that a request is sent by the client it's then addressed by the front-end service then it's basically",
    "start": "467840",
    "end": "474159"
  },
  {
    "text": "forwarded to the orchestrator orchestrator is basically a decision maker that will decide to which workflow",
    "start": "474159",
    "end": "480680"
  },
  {
    "text": "of which set of workers the request needs to be forwarded to which eventually will make the inference yeah",
    "start": "480680",
    "end": "488240"
  },
  {
    "text": "so keep in just keep an eye on how dependent these resources are on each other there is another architecture that",
    "start": "488240",
    "end": "495720"
  },
  {
    "text": "is pull based where we have just added a queue so basically in this what's happening is that once the front request",
    "start": "495720",
    "end": "502400"
  },
  {
    "text": "is front end service is receiving a request it will send a request to a queue yeah and the next resource that is",
    "start": "502400",
    "end": "510840"
  },
  {
    "text": "orchestrator it will basically pull the messages and process and this is how the flow is going in this",
    "start": "510840",
    "end": "517599"
  },
  {
    "text": "architecture so now that we are aware about the architectures Also let's",
    "start": "517599",
    "end": "523399"
  },
  {
    "text": "understand why such architectures designing s architecture and thinking about how we can perform deployments for",
    "start": "523399",
    "end": "528959"
  },
  {
    "text": "S architecture is actually referred as like a beast like more importantly what",
    "start": "528959",
    "end": "534680"
  },
  {
    "text": "are the challenges that might we might face while designing s architectures so first mostly As Sumit also mentioned",
    "start": "534680",
    "end": "541279"
  },
  {
    "text": "that the GPU are way more expensive than CPU yeah like the resources some of the",
    "start": "541279",
    "end": "547480"
  },
  {
    "text": "resource in the arure were actually belonging to the GPU nodes which is quite expensive so we obviously have",
    "start": "547480",
    "end": "554120"
  },
  {
    "text": "resource constraint right so even so it might be a point during deployment when",
    "start": "554120",
    "end": "560040"
  },
  {
    "text": "we have more number of resources that that are healthy that are deployed in GPU nodes then the time when we are not",
    "start": "560040",
    "end": "567160"
  },
  {
    "text": "deploying yeah then keeping in mind that we have resource constraint how are we going to address the scenario the other",
    "start": "567160",
    "end": "574160"
  },
  {
    "text": "challenge that we might face as you can see in the architecture that the resources are dependent on each other so",
    "start": "574160",
    "end": "581160"
  },
  {
    "text": "let's say if we are performing a deployment we have version two of orchestr orchestrator that is spun up so",
    "start": "581160",
    "end": "588560"
  },
  {
    "text": "we need to ensure that the subsequent resources those are the workers or models those should also have sufficient",
    "start": "588560",
    "end": "596399"
  },
  {
    "text": "resources of version two that will be addressing the request that will be coming from the orchestrator yeah so",
    "start": "596399",
    "end": "602000"
  },
  {
    "text": "this is another challenge that we might face third could be that uh in GPU case",
    "start": "602000",
    "end": "608560"
  },
  {
    "text": "the deployment time can be very high because the image can be a lot very",
    "start": "608560",
    "end": "614320"
  },
  {
    "text": "large yeah so it might happen the download time would be very high or time to abstract would be very high so yeah I",
    "start": "614320",
    "end": "621279"
  },
  {
    "text": "mean in general this can just increase the deployment time so these are few of the challenges so I'll just hand it over",
    "start": "621279",
    "end": "627440"
  },
  {
    "text": "to Sumit who will be basically addressing the solutions that we used",
    "start": "627440",
    "end": "632519"
  },
  {
    "text": "and even build inh housee to address such challenges so suit yeah over to you thank you thean all",
    "start": "632519",
    "end": "639959"
  },
  {
    "text": "right so let's have a quick recap so what we have just talked about we had a chart where we had couple of strategies",
    "start": "639959",
    "end": "646920"
  },
  {
    "text": "and then we spoke about those strategies blue green and uh Canary right and then we also touched up on about uh the",
    "start": "646920",
    "end": "654000"
  },
  {
    "text": "deploy different gen architectures right the push based model and the pull based model so but particularly the",
    "start": "654000",
    "end": "660000"
  },
  {
    "text": "interesting part there that I want you to focus on is that the depend the models although they are deployed separately they are dependent on each",
    "start": "660000",
    "end": "666279"
  },
  {
    "text": "other because of the versions and as Divan mentioned the driver versions so by the time you release something there",
    "start": "666279",
    "end": "673000"
  },
  {
    "text": "are already so many changes that has happened in the markets so the whole industry is running really fast so it's",
    "start": "673000",
    "end": "678399"
  },
  {
    "text": "very difficult to cope up with the different different uh driver versions different different uh you know",
    "start": "678399",
    "end": "683560"
  },
  {
    "text": "architectures that are there and by the time you have a newer version of a model it's already too late and you can't have",
    "start": "683560",
    "end": "689720"
  },
  {
    "text": "a backward compatibility so with that in mind if you look at this diagram so I've tried",
    "start": "689720",
    "end": "695279"
  },
  {
    "text": "to have this look at this boxes here okay so",
    "start": "695279",
    "end": "700399"
  },
  {
    "text": "each of these boxes are representing two versions of a model so let's we talk about version one of the model and then",
    "start": "700399",
    "end": "706200"
  },
  {
    "text": "you release version two there is a very good chance that the version two is is not compatible with the version one so",
    "start": "706200",
    "end": "712360"
  },
  {
    "text": "you have to understand these use cases these business use cases before you decide what to do right now IM imagine",
    "start": "712360",
    "end": "719959"
  },
  {
    "text": "that you have an architecture where you have just a handful of models let's say three models okay configurations for",
    "start": "719959",
    "end": "726160"
  },
  {
    "text": "those three models will be really small like 20 lines of code for each model so you have uh the kenary stages with 25%",
    "start": "726160",
    "end": "733000"
  },
  {
    "text": "25% of deployments three models really easy everything will work fine now",
    "start": "733000",
    "end": "738639"
  },
  {
    "text": "imagine it's 10 20 100,000 so that's where the problem",
    "start": "738639",
    "end": "744600"
  },
  {
    "text": "comes in so as you move on as you have more number of models the management of",
    "start": "744600",
    "end": "749760"
  },
  {
    "text": "your configurations becomes really messy and then what happens it comes with it comes that there are so many challenges",
    "start": "749760",
    "end": "756000"
  },
  {
    "text": "and it's a there is a lot at stake here right you can't make a mistake when when on a production environment right but",
    "start": "756000",
    "end": "762720"
  },
  {
    "text": "you still have to manage and you still have to serve the business needs so what do you do so we fa this Challenge and we",
    "start": "762720",
    "end": "769639"
  },
  {
    "text": "came up uh with a very simple and elegant solution and we call it rollout orchestrator so what's a rollout",
    "start": "769639",
    "end": "776639"
  },
  {
    "text": "orchestrator so it basically uh an interface on top of Argo rollouts and it",
    "start": "776639",
    "end": "784120"
  },
  {
    "text": "leverages Argo rollouts apis to manage the life cycle of your Canary deployments so how it happens if you",
    "start": "784120",
    "end": "791959"
  },
  {
    "text": "look at the right side it's very neatly designed there is a very specific set of",
    "start": "791959",
    "end": "797800"
  },
  {
    "text": "code here that mentions that what now what type of models or what type of deployments in this case you want to uh",
    "start": "797800",
    "end": "805360"
  },
  {
    "text": "you know U move forward right you want to promote so you see there are two",
    "start": "805360",
    "end": "810519"
  },
  {
    "text": "groups for for this example there are two groups the group",
    "start": "810519",
    "end": "815959"
  },
  {
    "text": "one okay so the group one has all the models which are there and the group two",
    "start": "817680",
    "end": "822920"
  },
  {
    "text": "has a front end service now what is why why it is like this so imagine you have a front- end service and you have set of",
    "start": "822920",
    "end": "829800"
  },
  {
    "text": "models which are handling those request your front end service you deploy it first and your model you deploy later so",
    "start": "829800",
    "end": "836399"
  },
  {
    "text": "a new version of request will be coming from Front End service there's no one to respond to and that's a bad use case so",
    "start": "836399",
    "end": "843040"
  },
  {
    "text": "you want to make sure that all of the dependent models are deployed before",
    "start": "843040",
    "end": "848519"
  },
  {
    "text": "anyone which is dependent on that in beginning of the pipeline so that's how you do the front end now you can imagine",
    "start": "848519",
    "end": "855560"
  },
  {
    "text": "if you even have thousands of models it's very easy to combine them and put them like this and there is no one",
    "start": "855560",
    "end": "861959"
  },
  {
    "text": "stopping you to create another version on top of that which also groups if you have you know really really large you",
    "start": "861959",
    "end": "867519"
  },
  {
    "text": "know even 10,000 you can also manage that one other use case here is the roll",
    "start": "867519",
    "end": "874519"
  },
  {
    "text": "out orchestrator can also handle the roll backs that's one of the challenge that happens right so it it's designed",
    "start": "874519",
    "end": "881240"
  },
  {
    "text": "to manage that as well so that is one use case",
    "start": "881240",
    "end": "887600"
  },
  {
    "text": "now okay so thean spoke about Canary right so we do deployments in stages you",
    "start": "889560",
    "end": "896000"
  },
  {
    "text": "you you shift the traffic to only 5% traffic to your newer version then 10 then depending upon the use case right",
    "start": "896000",
    "end": "902480"
  },
  {
    "text": "so there are certain certain techniques certain configurations that I want to highlight that you can leverage in your",
    "start": "902480",
    "end": "908759"
  },
  {
    "text": "deployment architecture one very important is Max search so what does it",
    "start": "908759",
    "end": "914240"
  },
  {
    "text": "do so before we do that imagine that you have an you have an architecture where total number of PODS or GPU nodes that",
    "start": "914240",
    "end": "921360"
  },
  {
    "text": "you're using is 100 okay now as Divan already mentioned the cost is really",
    "start": "921360",
    "end": "926959"
  },
  {
    "text": "high and gpus are probably not a available in the market even if you have money right so what do you do you want",
    "start": "926959",
    "end": "933120"
  },
  {
    "text": "to make sure like you go to your cloud provider you ask them give me more I need 100 more they say no we don't have",
    "start": "933120",
    "end": "939040"
  },
  {
    "text": "it so what you can do you can use max search and set it to the number that serves the business needs and also you",
    "start": "939040",
    "end": "945519"
  },
  {
    "text": "are managed to get it from cloud provider let's say 25 so if you set your max s to 25% what that means during the",
    "start": "945519",
    "end": "953120"
  },
  {
    "text": "whole life cycle of your Canary you will not go beyond 125 100 serving the life",
    "start": "953120",
    "end": "958600"
  },
  {
    "text": "traffic 25 is your candid side which will be surfing eventually 25% of traffic so it will be 25% then 25% like",
    "start": "958600",
    "end": "967160"
  },
  {
    "text": "that so at any point you are not going Beyond 125 and that's how you are saving your resource",
    "start": "967160",
    "end": "973000"
  },
  {
    "text": "constraint another technique which is equally important that is Max",
    "start": "973000",
    "end": "978680"
  },
  {
    "text": "unavailable so Pro I think most of you know when we have our architecture when",
    "start": "978680",
    "end": "984519"
  },
  {
    "text": "we have when we deploy something we always have room for unknowns you can't predict everything right and one unknown",
    "start": "984519",
    "end": "990959"
  },
  {
    "text": "is you always have a buffer like let's say 90% of Parts can serve the traffic that you have you still have 10% buffer",
    "start": "990959",
    "end": "997639"
  },
  {
    "text": "it's an example right so that unknowns are handled so max unavailable is one of",
    "start": "997639",
    "end": "1003000"
  },
  {
    "text": "the field that can that you can leverage to you know basically design your architecture so that you can avoid the",
    "start": "1003000",
    "end": "1009920"
  },
  {
    "text": "down times and you can also reuse that during the deployment time so what you can do is you can set your max",
    "start": "1009920",
    "end": "1015519"
  },
  {
    "text": "unavailable to zero when you set it to zero you you are explicitly telling your controller I under any circumstances I",
    "start": "1015519",
    "end": "1023759"
  },
  {
    "text": "don't want my deployment or my number of ports to go less than 100 you can set it",
    "start": "1023759",
    "end": "1029319"
  },
  {
    "text": "to 90 also that means you're telling your controller it's okay if you want to go to 290 I can handle that and the 10%",
    "start": "1029319",
    "end": "1036199"
  },
  {
    "text": "you can use for the deployment so now you have more buffer in your maxers you can now go for 35% right so that's how",
    "start": "1036199",
    "end": "1044079"
  },
  {
    "text": "it's very important to understand the business use case and also align it with these conf ations and finally uh we're",
    "start": "1044079",
    "end": "1051720"
  },
  {
    "text": "talking about the rollouts gradual rollouts and all that so when you do that there are certain ways that you can",
    "start": "1051720",
    "end": "1057840"
  },
  {
    "text": "test those rollouts so you can do UT you can write it you can run some some sort",
    "start": "1057840",
    "end": "1063240"
  },
  {
    "text": "of automations manual testing right and then also there is something called Canary",
    "start": "1063240",
    "end": "1068600"
  },
  {
    "text": "analysis so what you can do is when you at the initial stage let's say you say 5% of the traffic should move to the",
    "start": "1068600",
    "end": "1075600"
  },
  {
    "text": "newer version of the deployment on top of that you have written some error templates or analysis templates which",
    "start": "1075600",
    "end": "1082520"
  },
  {
    "text": "allows you to monitor what's your error rate in this example for example let's",
    "start": "1082520",
    "end": "1088000"
  },
  {
    "text": "say 404s we all know about 404s right so you get 404s 503 5050 right the error",
    "start": "1088000",
    "end": "1094840"
  },
  {
    "text": "rate template will let you know that there is there is something that that went wrong now now this is very useful",
    "start": "1094840",
    "end": "1101000"
  },
  {
    "text": "and very powerful but there is a little problem about this let's say we have these four sections I serve the traffic",
    "start": "1101000",
    "end": "1107240"
  },
  {
    "text": "25% of these guys they say okay no there is an error rate there is a problem though I have able to identify the",
    "start": "1107240",
    "end": "1113280"
  },
  {
    "text": "problem in my deployment I'll fix that but this 25% of folks have been have",
    "start": "1113280",
    "end": "1118840"
  },
  {
    "text": "their experience have been uh you know bad right so we messed up with the user experience and in certain scenarios you",
    "start": "1118840",
    "end": "1126799"
  },
  {
    "text": "can avoid that so one with that I want to introduce and explain about traffic",
    "start": "1126799",
    "end": "1133360"
  },
  {
    "text": "mirroring it's a very powerful very very interesting use case that the very",
    "start": "1133360",
    "end": "1139320"
  },
  {
    "text": "interesting technique that you can use okay so now imagine that you have a",
    "start": "1139320",
    "end": "1145440"
  },
  {
    "text": "deployment okay you have considered all the use case you have the best developers you have best QA team",
    "start": "1145440",
    "end": "1151440"
  },
  {
    "text": "everybody is best in their fields and they've done all everything that they can do you have right amount of use",
    "start": "1151440",
    "end": "1157120"
  },
  {
    "text": "cases you have complete automation test data right now you deploy your version",
    "start": "1157120",
    "end": "1162720"
  },
  {
    "text": "but what happens like there are always room for unknowns so imagine that your",
    "start": "1162720",
    "end": "1168799"
  },
  {
    "text": "researcher team is working on a new model okay they basically train your model they do everything they spend a",
    "start": "1168799",
    "end": "1176080"
  },
  {
    "text": "lot of time but by the time they release that model there is already a lot of unknown that happened maybe immediately",
    "start": "1176080",
    "end": "1181880"
  },
  {
    "text": "maybe some time back like India won two Cricket World Cups by the",
    "start": "1181880",
    "end": "1190559"
  },
  {
    "text": "time it happens or Donald Trump becomes president so these are unknowns when you",
    "start": "1190559",
    "end": "1195720"
  },
  {
    "text": "did it it was not happening it was not working so these us cases so it's always important to know what's going to happen",
    "start": "1195720",
    "end": "1203559"
  },
  {
    "text": "how you can achieve it that's when this particular diagram I'll show you on the",
    "start": "1203559",
    "end": "1209159"
  },
  {
    "text": "left side there is this mirror request or on the right side this is the original",
    "start": "1209159",
    "end": "1215280"
  },
  {
    "text": "request so the green side I'm representing the existing architecture you have the user base they're serving",
    "start": "1215280",
    "end": "1221360"
  },
  {
    "text": "the traffic it's going to your infrastructure everything is working smoothly right what interestingly you're",
    "start": "1221360",
    "end": "1226799"
  },
  {
    "text": "doing is both during the development time and during the deployment time you are mirroring the request and sending it",
    "start": "1226799",
    "end": "1234320"
  },
  {
    "text": "to another set of deployment now this deployment could be set of models could be set of gpus could be",
    "start": "1234320",
    "end": "1240600"
  },
  {
    "text": "anything interestingly what happens you can discard the response but now you are testing on against the real traffic and",
    "start": "1240600",
    "end": "1247600"
  },
  {
    "text": "that's really useful in the world of gen so but you have to remember one thing",
    "start": "1247600",
    "end": "1253440"
  },
  {
    "text": "when you do this it could backfire so you have to make sure when you duplicate the request you don't duplicate the post",
    "start": "1253440",
    "end": "1259799"
  },
  {
    "text": "request you don't want to update the resource twice right you don't want to mess up your database so we keep that in",
    "start": "1259799",
    "end": "1265840"
  },
  {
    "text": "mind now let's come back to the first slide",
    "start": "1265840",
    "end": "1270919"
  },
  {
    "text": "that we had so do we have any guesses like which one would be the pink one and",
    "start": "1270919",
    "end": "1278559"
  },
  {
    "text": "which one would be the yellow one right hey you can speak",
    "start": "1278559",
    "end": "1287520"
  },
  {
    "text": "up BL that's bang",
    "start": "1287520",
    "end": "1292880"
  },
  {
    "text": "on that's bang on so see uh we talked about various aspects right and at some",
    "start": "1292880",
    "end": "1299840"
  },
  {
    "text": "point when you when you actually think about this at some point you think no no no no blue green should be the less and",
    "start": "1299840",
    "end": "1306960"
  },
  {
    "text": "Canary should be the more because you see the assumptions that we have made which are very close to the real life",
    "start": "1306960",
    "end": "1312760"
  },
  {
    "text": "examples that blue green even though it consumes the 100% at at at a time but it",
    "start": "1312760",
    "end": "1318600"
  },
  {
    "text": "takes very less time because you're saving a lot of time you're saving a lot of uh you know time in releasing in",
    "start": "1318600",
    "end": "1325880"
  },
  {
    "text": "stages right compared to Canary which is taking 4 hours because 10% then you'll do some testing then 10% then 10% right",
    "start": "1325880",
    "end": "1334159"
  },
  {
    "text": "so again so to reiterate based on the assumptions that we have made with four",
    "start": "1334159",
    "end": "1339320"
  },
  {
    "text": "hours for Canary and 2 hours for blue green additionally a deployment frequency is around five for every month",
    "start": "1339320",
    "end": "1345880"
  },
  {
    "text": "and we got this number from one of the cloud providers and it's p4d 24x large",
    "start": "1345880",
    "end": "1351840"
  },
  {
    "text": "VM which cost somewhere around $30 to $35 every hour now interestingly you",
    "start": "1351840",
    "end": "1357120"
  },
  {
    "text": "note that the first three columns are showing you the prices for deployment",
    "start": "1357120",
    "end": "1363520"
  },
  {
    "text": "not your runtime so I want to emphasize on that this particular pricing is not",
    "start": "1363520",
    "end": "1368600"
  },
  {
    "text": "for supporting your runtime it is just for the deployment duration you see with the number of",
    "start": "1368600",
    "end": "1375039"
  },
  {
    "text": "models increasing how significant the numbers the cost is increasing",
    "start": "1375039",
    "end": "1380480"
  },
  {
    "text": "here right and with that thought I'm going to ask you each and every one of",
    "start": "1380480",
    "end": "1386919"
  },
  {
    "text": "you just think with all the architectures that you have seen in your org in your project and all that is that",
    "start": "1386919",
    "end": "1394080"
  },
  {
    "text": "the right architecture is it using the right configuration or can we improve",
    "start": "1394080",
    "end": "1400279"
  },
  {
    "text": "it right you can reference to this table and then create a map and see whether a",
    "start": "1400279",
    "end": "1406679"
  },
  {
    "text": "little change in Max sege Max available or some of these configurations would help maybe choosing the right",
    "start": "1406679",
    "end": "1414760"
  },
  {
    "text": "strategy okay so so just a quick recap so we talked about so max search which",
    "start": "1415279",
    "end": "1421000"
  },
  {
    "text": "is really important Max unavailable right and then Canary strategy that can",
    "start": "1421000",
    "end": "1426600"
  },
  {
    "text": "actually with gradual steps is going to help you a lot in in you know uh releasing the changes analysis templates",
    "start": "1426600",
    "end": "1433559"
  },
  {
    "text": "are really powerful when you really want to test something in an automated fashion traffic mirroring helps you to",
    "start": "1433559",
    "end": "1440279"
  },
  {
    "text": "to anticipate what's happening in the real world versus what you think is happening in the real world there's a",
    "start": "1440279",
    "end": "1445559"
  },
  {
    "text": "big difference right similarly I think there's a very interesting thing that dian's talked about I want to I want to",
    "start": "1445559",
    "end": "1451679"
  },
  {
    "text": "just talk about that just for a few minutes so you see U one of the key challenges so if you look at the pre if",
    "start": "1451679",
    "end": "1458679"
  },
  {
    "text": "you remember the previous side we talked about the prices right but the deployment duration is 4 hours and 2",
    "start": "1458679",
    "end": "1464400"
  },
  {
    "text": "hours now why is that one of the major reason is the image for models are",
    "start": "1464400",
    "end": "1470000"
  },
  {
    "text": "really large and because the images are really large it takes some time at least",
    "start": "1470000",
    "end": "1475880"
  },
  {
    "text": "more than a standard time like standard deployment time it takes more time because the image is large it will be",
    "start": "1475880",
    "end": "1481399"
  },
  {
    "text": "downloaded then it will be extracted and then it will be installed it's a huge difference and then there will be health",
    "start": "1481399",
    "end": "1487399"
  },
  {
    "text": "checks so from the beginning and to the point when the health check says okay this particular part is healthy it's",
    "start": "1487399",
    "end": "1493919"
  },
  {
    "text": "it's a huge window and you want to decrease that though your outcome might",
    "start": "1493919",
    "end": "1499559"
  },
  {
    "text": "be same but you will sa you will save a lot of cost in over in overall so with",
    "start": "1499559",
    "end": "1505679"
  },
  {
    "text": "that so there are certain techniques that you can do you can use image caching right at the at at the node",
    "start": "1505679",
    "end": "1510960"
  },
  {
    "text": "level and if you're using a particular cloud provider it's it's it's so it's good to you know use their own registry",
    "start": "1510960",
    "end": "1516960"
  },
  {
    "text": "to download the image always try to think in that direction as well you can use certain image compression techniques",
    "start": "1516960",
    "end": "1523279"
  },
  {
    "text": "which will allow you to reduce the size of the images right try to have try to break down your images rather than a",
    "start": "1523279",
    "end": "1528919"
  },
  {
    "text": "single image it's it's going to help so with that I'm going to ask I'm going to",
    "start": "1528919",
    "end": "1536159"
  },
  {
    "text": "open the stage for questions if you have",
    "start": "1536159",
    "end": "1539919"
  },
  {
    "text": "any yeah",
    "start": "1544640",
    "end": "1547799"
  },
  {
    "text": "yeah so majorly we use aror only so the question was yeah sorry just to reate",
    "start": "1553360",
    "end": "1560440"
  },
  {
    "text": "the question is what exactly the tool are we using for deployment other than ARS yeah where you're using algor in our",
    "start": "1560440",
    "end": "1571200"
  },
  {
    "text": "case yeah so the question is are we using giops model well the answer is yes we are using giops model so we have Argo",
    "start": "1572320",
    "end": "1579360"
  },
  {
    "text": "CD Argo rollouts Argo workflows all of this we",
    "start": "1579360",
    "end": "1584480"
  },
  {
    "text": "using uh I just have one question what are what are strategies one and two we",
    "start": "1584480",
    "end": "1590559"
  },
  {
    "text": "talked about a strategy three and four but you had other two strategies in the draft that's a good point so we wanted to include all four so the first one was",
    "start": "1590559",
    "end": "1597200"
  },
  {
    "text": "recreate and the second one was rolling a recreate is uh if I give you an",
    "start": "1597200",
    "end": "1602919"
  },
  {
    "text": "example see if you know IRCTC right they have a scheduled down time down time from 11:30 to 12:30 in the night every",
    "start": "1602919",
    "end": "1608960"
  },
  {
    "text": "day so recreate is you you get rid of one version you bring up the another version and there will always be",
    "start": "1608960",
    "end": "1614480"
  },
  {
    "text": "downtime but the benefit with recreate is there is zero additional cost so that's one and the rolling is very much",
    "start": "1614480",
    "end": "1621440"
  },
  {
    "text": "similar like rolling is the U standard version of uh Canary so Canary is",
    "start": "1621440",
    "end": "1627559"
  },
  {
    "text": "Advanced version of rolling so it's typically like it's same it also has Max surge Max unavailable but we only kep",
    "start": "1627559",
    "end": "1632919"
  },
  {
    "text": "two okay thank you any more",
    "start": "1632919",
    "end": "1638760"
  },
  {
    "text": "questions your top but a p torch image would generally be about 40K so have you",
    "start": "1641320",
    "end": "1648320"
  },
  {
    "text": "break into get it down even if you download fromr",
    "start": "1648320",
    "end": "1653760"
  },
  {
    "text": "it's sure so the question is uh a py torch image typically takes around 40",
    "start": "1654880",
    "end": "1660279"
  },
  {
    "text": "gigs of space and while there are certain strategies available what have we done what have we used so far right",
    "start": "1660279",
    "end": "1667360"
  },
  {
    "text": "so I would say we other than these the techniques that we have mentioned I don't think we I think that would be a",
    "start": "1667360",
    "end": "1673320"
  },
  {
    "text": "question for a particular engineer from the AI gen side okay from the from the",
    "start": "1673320",
    "end": "1678960"
  },
  {
    "text": "platform engineering perspective our recommendation is to use caching compressions like that",
    "start": "1678960",
    "end": "1687000"
  },
  {
    "text": "yeah out of question but in our use case",
    "start": "1687399",
    "end": "1692519"
  },
  {
    "text": "is like Cas right so where the image is pretty high so just to create a",
    "start": "1692519",
    "end": "1698640"
  },
  {
    "text": "container it takes 15 minutes and the actual duration is around 20 minutes only so we are just paying for the uh",
    "start": "1698640",
    "end": "1706559"
  },
  {
    "text": "for time for",
    "start": "1706559",
    "end": "1710120"
  },
  {
    "text": "okay so it's a very good question and I think all of you might be able to related so the question is so they have",
    "start": "1712640",
    "end": "1719320"
  },
  {
    "text": "jobs and the startup time of job itself is 15 minutes and the execution time is",
    "start": "1719320",
    "end": "1724480"
  },
  {
    "text": "20 minutes so you are paying tax so that's a good question so there",
    "start": "1724480",
    "end": "1730840"
  },
  {
    "text": "are always tradeoffs and I think while there is scope for improvements in these areas I think uh you can what like you",
    "start": "1730840",
    "end": "1739200"
  },
  {
    "text": "can improvise based on the use case for example if your image has something that",
    "start": "1739200",
    "end": "1745480"
  },
  {
    "text": "you can cash at a different level for example if you have combination of images if you're downloading some some",
    "start": "1745480",
    "end": "1750559"
  },
  {
    "text": "some libraries like your Docker images keep keep that as cached you can use you know Docker",
    "start": "1750559",
    "end": "1755880"
  },
  {
    "text": "ECR basically you know right ECR Registries and all that that you can do and you depending upon the use case you",
    "start": "1755880",
    "end": "1762120"
  },
  {
    "text": "will have to do but I don't think you can do much right the best part is",
    "start": "1762120",
    "end": "1767159"
  },
  {
    "text": "because 15 minutes is uh very high number it's important High availability is more important than cost right so you",
    "start": "1767159",
    "end": "1774640"
  },
  {
    "text": "don't want people to wait for 15 minute just because your container is coming up so what you can do is you can always have some in buffer ready to serve right",
    "start": "1774640",
    "end": "1781840"
  },
  {
    "text": "so you have to improvise based on business use case",
    "start": "1781840",
    "end": "1786760"
  },
  {
    "text": "so how do we decide what number should we use for Max Surge and Max unavailable and if there are any key key points that",
    "start": "1802559",
    "end": "1810279"
  },
  {
    "text": "or key key learnings there so as I mentioned Max search so basically",
    "start": "1810279",
    "end": "1815960"
  },
  {
    "text": "imagine how much of users you are okay with if they have a bad experience I'll",
    "start": "1815960",
    "end": "1821640"
  },
  {
    "text": "start with this if you are okay that 5% of my users are getting a bad experience but you are getting to know whether your",
    "start": "1821640",
    "end": "1828279"
  },
  {
    "text": "version is good or not then you can have your max sege to 5% your steps with 5%",
    "start": "1828279",
    "end": "1834679"
  },
  {
    "text": "the max surge you can also have like again another factor is",
    "start": "1834679",
    "end": "1839880"
  },
  {
    "text": "cost if it's really cheap then you shouldn't be worried about Max Sur at all Max surge is important when it's",
    "start": "1839880",
    "end": "1846440"
  },
  {
    "text": "really expensive you see the GPU cost versus CPU cost right so max surge allows you to manage that so you want to",
    "start": "1846440",
    "end": "1853320"
  },
  {
    "text": "reduce that so depending on the business use case right because you have another",
    "start": "1853320",
    "end": "1858760"
  },
  {
    "text": "thing if you have more stages in your Canary your overall deployment is going to take a lot of time your engineering",
    "start": "1858760",
    "end": "1864840"
  },
  {
    "text": "team will be involved a lot more and that is going to be a problem right that's going to be frustrating so you",
    "start": "1864840",
    "end": "1869880"
  },
  {
    "text": "want to reduce that so there is a tradeoff either the cost or the time",
    "start": "1869880",
    "end": "1874919"
  },
  {
    "text": "right so again it's very important to understand the use case and then decide same goes for Max",
    "start": "1874919",
    "end": "1883440"
  },
  {
    "text": "unavailable any other questions so you talked about miring traffic and",
    "start": "1885519",
    "end": "1895120"
  },
  {
    "text": "you also mentioned that you should not be putting in post calls or delete calls is imping the data to the traffic so how",
    "start": "1895120",
    "end": "1903600"
  },
  {
    "text": "do you decide which customers are getting the traffic and how decide",
    "start": "1903600",
    "end": "1911600"
  },
  {
    "text": "that getting the output out of okay so the question is while we're using",
    "start": "1911600",
    "end": "1917519"
  },
  {
    "text": "traffic mirroring based sorry based on the outcome of the mirrored request that you",
    "start": "1917519",
    "end": "1924480"
  },
  {
    "text": "are getting how do you decide whether that's a right thing or not right so let me clarify one thing when we say mirror",
    "start": "1924480",
    "end": "1930279"
  },
  {
    "text": "mirroring the traffic that mirror request is going is getting discarded",
    "start": "1930279",
    "end": "1935360"
  },
  {
    "text": "the response of that is getting discarded okay on top of that you as a as a developer or a or a researcher what",
    "start": "1935360",
    "end": "1943200"
  },
  {
    "text": "you have you have access to those requests and you can see what is the response now depending on on your",
    "start": "1943200",
    "end": "1948519"
  },
  {
    "text": "architecture the tools that you have inbuilt developed you can decide based on the outcome whether this is the",
    "start": "1948519",
    "end": "1954799"
  },
  {
    "text": "intended outcome or whe whether it is the wrong outcome right and when I said post that's a generic example that you",
    "start": "1954799",
    "end": "1961399"
  },
  {
    "text": "shouldn't use post what I mean to say is you should make sure whatever request you are mirroring they are not creating",
    "start": "1961399",
    "end": "1968000"
  },
  {
    "text": "any side effects for you you have to make sure that any anywhere it's not being used so you have to be careful in",
    "start": "1968000",
    "end": "1973960"
  },
  {
    "text": "that just to add also that the response is get getting discarded of course you",
    "start": "1973960",
    "end": "1979399"
  },
  {
    "text": "can refer to that response but you can also analyze the parts of the new version the logs of them and also the",
    "start": "1979399",
    "end": "1986279"
  },
  {
    "text": "metrices how it's performing those are all the factors that you can also consider yeah you can add the",
    "start": "1986279",
    "end": "1994278"
  },
  {
    "text": "filter so the response from audience is you can also add a filter at the controller level yeah right",
    "start": "1998960",
    "end": "2006360"
  },
  {
    "text": "yeah okay and any other",
    "start": "2006399",
    "end": "2010080"
  },
  {
    "text": "question all right well thank you all for joining",
    "start": "2012120",
    "end": "2018840"
  }
]
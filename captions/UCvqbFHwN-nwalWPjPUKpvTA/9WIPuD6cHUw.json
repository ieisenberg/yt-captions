[
  {
    "text": "a good wine afternoon",
    "start": "0",
    "end": "13340"
  },
  {
    "text": "can there you are hey ed ain't done I just talked to Dino cuz he was giving me",
    "start": "28220",
    "end": "34800"
  },
  {
    "text": "a little bit of static when I tried to join ya the TOC you just ended took me a",
    "start": "34800",
    "end": "41250"
  },
  {
    "text": "few seconds to jump over okay okay I'm not sure about my when I arrived in",
    "start": "41250",
    "end": "48989"
  },
  {
    "text": "Austin yet I'm going to be in India the week before mmm-hmm so just be coming back from",
    "start": "48989",
    "end": "56399"
  },
  {
    "text": "India and trying to figure out how I how I get to Austin and when I can get Austin so I'll try to get back to you",
    "start": "56399",
    "end": "63000"
  },
  {
    "text": "still this week on your request for the for the fight oh yeah I completely",
    "start": "63000",
    "end": "70320"
  },
  {
    "text": "understand the travel issues so Austin the one thing Austin doesn't have going",
    "start": "70320",
    "end": "75539"
  },
  {
    "text": "for it is it does not have a world-class Airport in terms of connections yeah is",
    "start": "75539",
    "end": "82259"
  },
  {
    "text": "so true hey Chris I done pretty good",
    "start": "82259",
    "end": "87750"
  },
  {
    "text": "mute button how are you doing oh wow yeah Austin Austin is always a hop yeah",
    "start": "87750",
    "end": "96270"
  },
  {
    "text": "it's the only thing that isn't that amazing about the place so yeah I'm even",
    "start": "96270",
    "end": "104610"
  },
  {
    "text": "at anyway yeah it is so I fly American so it's not horribly painful it's just up and down",
    "start": "104610",
    "end": "111060"
  },
  {
    "text": "from Dallas but stilts and up and down yeah American American has played some funny games",
    "start": "111060",
    "end": "117299"
  },
  {
    "text": "there over the years they used to run directs a lot out of Austin the places like San Jose and yeah you know why that",
    "start": "117299",
    "end": "123090"
  },
  {
    "text": "was don't you what it was called the IBM",
    "start": "123090",
    "end": "128459"
  },
  {
    "text": "Express so it was actually a flight that was Raleigh Austin San Fran San Jose and",
    "start": "128459",
    "end": "135600"
  },
  {
    "text": "I was on it quite a few times in early 90s and you figured it out the man you",
    "start": "135600",
    "end": "141120"
  },
  {
    "text": "walked on the plane and everyone had to think that on the plane but even even after that so in the 2000s they were",
    "start": "141120",
    "end": "148530"
  },
  {
    "text": "running multiple 737 today from Austin to San Jose and they were always jam-packed yeah suddenly there was a",
    "start": "148530",
    "end": "155870"
  },
  {
    "text": "America no sense ya know that there was there",
    "start": "155870",
    "end": "162680"
  },
  {
    "text": "that but the word that came from I think was when lawyers a half-an-hour change when they were doing it in Austin so it",
    "start": "162680",
    "end": "169040"
  },
  {
    "text": "was just a you know people on and off the bus and and continue on the way but yeah that's all gone now yeah I think we",
    "start": "169040",
    "end": "191359"
  },
  {
    "text": "shouldn't allow a few more minutes I know the TOC Ike's it just ended yeah yeah and there were some complications",
    "start": "191359",
    "end": "197060"
  },
  {
    "text": "getting a lot of the accustomed time good morning Lee",
    "start": "197060",
    "end": "201189"
  },
  {
    "text": "morning lane gentlemen good good happy happy Tuesday and be",
    "start": "202569",
    "end": "211090"
  },
  {
    "text": "tonight nice work well thanks yeah I've",
    "start": "212170",
    "end": "227150"
  },
  {
    "text": "never been involved in a woke up with a battle of much over wood so you've never",
    "start": "227150",
    "end": "236900"
  },
  {
    "text": "done IETF Ken that was activated those battles can go on across multiple working group meetings you know the ITF",
    "start": "236900",
    "end": "245690"
  },
  {
    "text": "too late they kind of jumped you with that you know we got to see it working so there might have been a lot of debate but you always knew in the end you had",
    "start": "245690",
    "end": "252230"
  },
  {
    "text": "to produce something they could interoperate yeah that's not that seemed to help cut a little bit of the battle",
    "start": "252230",
    "end": "257539"
  },
  {
    "text": "over the meanings that used to be the case it hasn't been a more except when just does it as experimental or",
    "start": "257539",
    "end": "264039"
  },
  {
    "text": "individual contributor or whatever else I mean sauce you don't want to be on a standard track I mean the days of",
    "start": "264039",
    "end": "271669"
  },
  {
    "text": "proving interoperability unfortunately you're long gone it would have made things so much easier to just put everyone in the sin bin but I to many",
    "start": "271669",
    "end": "279349"
  },
  {
    "text": "vendors there's other interesting things that are starting to come up in the ITF they're hackfest are getting to be quite",
    "start": "279349",
    "end": "285020"
  },
  {
    "text": "fun lately so I mean a lot of what we've been seeing sort of is the how the heck",
    "start": "285020",
    "end": "290840"
  },
  {
    "text": "fest at every IETF and every IETF we wind up with some protocol or other that gets implemented as a plug into VPP you",
    "start": "290840",
    "end": "298250"
  },
  {
    "text": "know i la won Best in Show at one point for example and so you wind up with really cool stuff that actually makes it",
    "start": "298250",
    "end": "305449"
  },
  {
    "text": "into code and into the real world pretty fast yeah I think I think that that is a",
    "start": "305449",
    "end": "312560"
  },
  {
    "text": "very interesting use case of hackathons I like I like that a lot I'm trying to get MasterCard here to do",
    "start": "312560",
    "end": "319970"
  },
  {
    "text": "more hackathons because they're on their idea of innovation is drinking a beer and talking about how fun things could",
    "start": "319970",
    "end": "326900"
  },
  {
    "text": "be so it is a critical first step but",
    "start": "326900",
    "end": "332800"
  },
  {
    "text": "and we could do that and have pizza and do something then they were like I'm excited you know remember that the",
    "start": "332800",
    "end": "343760"
  },
  {
    "text": "coding wall drinking is there's a fine line there I didn't say we're gonna be",
    "start": "343760",
    "end": "352010"
  },
  {
    "text": "in production did I oftentimes that code",
    "start": "352010",
    "end": "360620"
  },
  {
    "text": "actually just works that the problem is someone trying to figure out how you got it to work later is the more interesting",
    "start": "360620",
    "end": "368800"
  },
  {
    "text": "the content of the comments cuz I have often been involved in me we wrote this as close source now we're going to open",
    "start": "369520",
    "end": "374630"
  },
  {
    "text": "source it discussions you walk through that and you're like oh my god we've got",
    "start": "374630",
    "end": "380930"
  },
  {
    "text": "to trim the comments oh I think I don't",
    "start": "380930",
    "end": "392900"
  },
  {
    "text": "know why we're getting less and less people at this event but maybe you do a better job I mean some ties enjoyed I",
    "start": "392900",
    "end": "400580"
  },
  {
    "text": "made some attempt to promote it on Twitter but well getting high see you",
    "start": "400580",
    "end": "410930"
  },
  {
    "text": "know I'd say we have a pair out here there's all four of us are here let's just make whatever decisions we need to make and you guys weren't there yes we",
    "start": "410930",
    "end": "421250"
  },
  {
    "text": "do we do at least have a quorum right there's four of us yeah five was cool so",
    "start": "421250",
    "end": "427630"
  },
  {
    "text": "Oh excellent I think actually I think",
    "start": "427630",
    "end": "434120"
  },
  {
    "text": "City and token would be better on guys if not phase four I want to go back to a",
    "start": "434120",
    "end": "441380"
  },
  {
    "text": "token dude I'm a string theorist by training I remember that yes that",
    "start": "441380",
    "end": "448340"
  },
  {
    "text": "probably still has some decnet phase four running somewhere in Austin I'll",
    "start": "448340",
    "end": "454670"
  },
  {
    "text": "tell you guys about this recent fun thing I've had here in Mexico with China they were using some OD OD addresses",
    "start": "454670",
    "end": "461780"
  },
  {
    "text": "that me another co-worker and the security side know from from way back in the day you guys would laugh at but I can't tell",
    "start": "461780",
    "end": "468619"
  },
  {
    "text": "you any more on the phone so you guys stole sipper net again everyone everyone abuses super net this was in China this",
    "start": "468619",
    "end": "476809"
  },
  {
    "text": "is the Chinese I thought it would be fun to use IP space for my DoD segments I",
    "start": "476809",
    "end": "482649"
  },
  {
    "text": "think there is some humor in that but I didn't find it at the time to be humorous there is a service provider",
    "start": "482649",
    "end": "494089"
  },
  {
    "text": "that when I was at Alcatel in New Zealand that shall remain nameless that",
    "start": "494089",
    "end": "500389"
  },
  {
    "text": "what they actually decided to do was number their up their ops network their",
    "start": "500389",
    "end": "505879"
  },
  {
    "text": "back-end ops network by area code criminal dialing code so they lose net",
    "start": "505879",
    "end": "514539"
  },
  {
    "text": "three-four stuff in Auckland that for for stuff in Wellington net seven for",
    "start": "514539",
    "end": "521240"
  },
  {
    "text": "stuff in Christchurch and they promised getting to Apple for example it's like",
    "start": "521240",
    "end": "530509"
  },
  {
    "text": "these addresses actually have meaning outside of the outside of that's always",
    "start": "530509",
    "end": "538240"
  },
  {
    "text": "alright let's get to work hi so at that end I'm gonna handed over you to talk through FDI oh and VPP in terms of",
    "start": "538240",
    "end": "545800"
  },
  {
    "text": "networking as a data plane for micro services and so let's keep this very",
    "start": "545800",
    "end": "550910"
  },
  {
    "text": "conversational which I imagine will be like pulling teeth with the crowd you'll",
    "start": "550910",
    "end": "557180"
  },
  {
    "text": "feel free to stop me at any time I'm gonna you'll basically run through really quick what is Fido and a little",
    "start": "557180",
    "end": "563269"
  },
  {
    "text": "bit about technology and then show how it becomes applicable [Music]",
    "start": "563269",
    "end": "568750"
  },
  {
    "text": "um you can see the share yeah yeah and",
    "start": "568750",
    "end": "575540"
  },
  {
    "text": "some of the things that are possible with it which there's a lot of stuff that can be done that you literally don't have anything else to control so",
    "start": "575540",
    "end": "581980"
  },
  {
    "text": "really quick Fido fti oh we pronounce it Fido because it's cutesy like that I",
    "start": "581980",
    "end": "588170"
  },
  {
    "text": "mean it gives us excuse to do things like I'm told that we actually have approval now to have a real dog at our",
    "start": "588170",
    "end": "593959"
  },
  {
    "text": "who thinks you've gone so we come by to the puppy",
    "start": "593959",
    "end": "599639"
  },
  {
    "text": "well it's basically it's a project of the Linux Foundation it's open source it's multi-party meaning there are many",
    "start": "599639",
    "end": "605199"
  },
  {
    "text": "people involved and multi project all this is familiar structure where people like which is much the same um it does a",
    "start": "605199",
    "end": "613889"
  },
  {
    "text": "software data playing basically so high throughput low latency lots of features very resource efficient works equally",
    "start": "613889",
    "end": "620949"
  },
  {
    "text": "well on bare metal VMs or containers because it's a pure user space data play so if you need to stick it in a",
    "start": "620949",
    "end": "626440"
  },
  {
    "text": "container sure why not and it's multi-platform it runs on Intel arm and PowerPC at some point in the",
    "start": "626440",
    "end": "634240"
  },
  {
    "text": "historic past it ran on nips but I don't know that anyone actually cares anymore about notes so and then we have a little",
    "start": "634240",
    "end": "641199"
  },
  {
    "text": "bit of a rubric that we use to discuss the scope of things that live within Fido",
    "start": "641199",
    "end": "646540"
  },
  {
    "text": "um so we usually will talk about three layers the first isn't a trick IO which is how do you get a packet from a NIC or",
    "start": "646540",
    "end": "652720"
  },
  {
    "text": "v-neck to a thread on a core so you could think this is something like DP DK which does that brilliantly and we",
    "start": "652720",
    "end": "659589"
  },
  {
    "text": "actually use the PDK for that purpose of times we're dealing with physical hardware um then you could think of it",
    "start": "659589",
    "end": "665319"
  },
  {
    "text": "as packet processing is the next layer so how do you classify transform prioritize and forward and possibly",
    "start": "665319",
    "end": "671860"
  },
  {
    "text": "terminate packets and then of course now that you've got this spiffy packet processing going on you need some kind",
    "start": "671860",
    "end": "678490"
  },
  {
    "text": "of data plane management agent to manage it all and you can kind of this is control plane but you discover the",
    "start": "678490",
    "end": "685029"
  },
  {
    "text": "control plane men routing protocols to a lot of people and so while it certainly this is also malaria you would put",
    "start": "685029",
    "end": "691839"
  },
  {
    "text": "things that do a very example we managed",
    "start": "691839",
    "end": "697529"
  },
  {
    "text": "yep in terms of where this is good I'm",
    "start": "701010",
    "end": "715180"
  },
  {
    "text": "I'm that was the second slide titled Fido the universal data plane hang on",
    "start": "715180",
    "end": "726939"
  },
  {
    "text": "sure is screwed up one second let me try and reach here and see if that helps",
    "start": "726939",
    "end": "731730"
  },
  {
    "text": "so you should now be on fight of the universal data playing yes yeah that was",
    "start": "741340",
    "end": "748340"
  },
  {
    "text": "the slide I was just talking to thank you for bringing that up it would have made the rest of the much harder to follow it's the ground well the graphics",
    "start": "748340",
    "end": "757820"
  },
  {
    "text": "really do help in places there are some fun animations on how the technology works so moving right along can you all",
    "start": "757820",
    "end": "766490"
  },
  {
    "text": "see Fido in the overall stack here yes yep right so you've got things like kubernetes that handle orchestration",
    "start": "766490",
    "end": "772760"
  },
  {
    "text": "these sort of have data playing services from a networking point of view this data flea management agency packet",
    "start": "772760",
    "end": "778340"
  },
  {
    "text": "processing and network i/o and that's sort of what Fido is doing and then of course obviously you want to write an operating systems like Linux and yo",
    "start": "778340",
    "end": "785390"
  },
  {
    "text": "maybe you ho CI spec'ing out your hardware that kind of thing there's",
    "start": "785390",
    "end": "793580"
  },
  {
    "text": "pretty broad membership in Fido so we've got a bunch of service providers who are involved there are network owners chip",
    "start": "793580",
    "end": "800360"
  },
  {
    "text": "vendors and in various integrators as well there's a lot of interest because",
    "start": "800360",
    "end": "805790"
  },
  {
    "text": "this solves a lot of problems for people in data playing in terms of software and",
    "start": "805790",
    "end": "811130"
  },
  {
    "text": "then we've got even broader contribution coming in so code is coming from a lot",
    "start": "811130",
    "end": "816920"
  },
  {
    "text": "of different directions and if you sort of look at the code activity one of the",
    "start": "816920",
    "end": "823070"
  },
  {
    "text": "things you'll notice is from a commit point of view Fido is currently probably the most active data playing community",
    "start": "823070",
    "end": "830180"
  },
  {
    "text": "on earth it sort of has been rapidly outstripping what we're getting coming",
    "start": "830180",
    "end": "835310"
  },
  {
    "text": "in from OBS or DP DK and we've got a pretty broad set of contributors and",
    "start": "835310",
    "end": "840430"
  },
  {
    "text": "organizations contributing as well I'd",
    "start": "840430",
    "end": "847820"
  },
  {
    "text": "mention it's multi project so we end up having a lot of different projects that go into it I've sort of classified them",
    "start": "847820",
    "end": "854540"
  },
  {
    "text": "here by what's going on most of the projects in packet processing tend to be either VPP which is the core technology",
    "start": "854540",
    "end": "861290"
  },
  {
    "text": "or things that are providing plugins or our libraries to control it of particular interest that that screw",
    "start": "861290",
    "end": "867009"
  },
  {
    "text": "probably is going to be the go VPP project which provides go bindings to",
    "start": "867009",
    "end": "872079"
  },
  {
    "text": "VPP so if you want to go build an agent to drive the data plane and go you just",
    "start": "872079",
    "end": "878079"
  },
  {
    "text": "pick up the libraries and away you go",
    "start": "878079",
    "end": "881430"
  },
  {
    "text": "honeycomb is a a particular data plane management agent um EBP is agnostic as",
    "start": "894149",
    "end": "901110"
  },
  {
    "text": "so you can build whatever you'd like honeycomb is one that service providers tend to like because it gives Netcom",
    "start": "901110",
    "end": "906790"
  },
  {
    "text": "yang interfaces to the finality and VBB and service providers love net comp yang",
    "start": "906790",
    "end": "912959"
  },
  {
    "text": "and if that makes you happy that it'll be a great day to play Management Asian for you and if it doesn't then take",
    "start": "912959",
    "end": "919149"
  },
  {
    "text": "another one cool I am gonna put the :",
    "start": "919149",
    "end": "924790"
  },
  {
    "text": "DPP this is Linda no I want to know like how much contribution or how much",
    "start": "924790",
    "end": "931420"
  },
  {
    "text": "project is open source projects and being developed so for round goal and VBP actually so in the code EBP library",
    "start": "931420",
    "end": "939399"
  },
  {
    "text": "there there's a framework project called legato which was building out a framework for building data plane",
    "start": "939399",
    "end": "946510"
  },
  {
    "text": "management agents because if you look at it in terms of wanting to build not just infrastructure stuff for things like",
    "start": "946510",
    "end": "952959"
  },
  {
    "text": "kubernetes but also vnfs that you may deploy you're gonna want to be an MPhil",
    "start": "952959",
    "end": "959230"
  },
  {
    "text": "so legato is using go VPP and then there's some effort right now and you'll see this in later slides they use ATO",
    "start": "959230",
    "end": "966190"
  },
  {
    "text": "framework to basically build a V switch and literally working for kubernetes as",
    "start": "966190",
    "end": "972610"
  },
  {
    "text": "just another micro service the other micro service you run but you you sort",
    "start": "972610",
    "end": "979510"
  },
  {
    "text": "of you jumped ahead a little bit you'll see more of that as we go along cool so",
    "start": "979510",
    "end": "987720"
  },
  {
    "text": "at the core of the phyto project is this really cool technology called vector packet processing um basically it lives",
    "start": "987720",
    "end": "996399"
  },
  {
    "text": "at the packet processing layer it's incredibly high performance it's your user space you can run it in Linux",
    "start": "996399",
    "end": "1003000"
  },
  {
    "text": "user space as I mentioned runs on Intel",
    "start": "1003000",
    "end": "1008160"
  },
  {
    "text": "our parks key it actually does some very sophisticated optimizations in order to",
    "start": "1008160",
    "end": "1013410"
  },
  {
    "text": "run really well on them it's a very mature technology it's something that's shifted volume in both the the server",
    "start": "1013410",
    "end": "1019410"
  },
  {
    "text": "and an embedded products since I believe about 2004 so it's it's a very mature",
    "start": "1019410",
    "end": "1025438"
  },
  {
    "text": "technology with the kinds of things that you want in a mature technology like high-level trio like really really good",
    "start": "1025439",
    "end": "1031589"
  },
  {
    "text": "traceability hundreds and hundreds and hundreds of statistics on everything being collected without actually",
    "start": "1031589",
    "end": "1036870"
  },
  {
    "text": "impacting performance that kind of stuff so the interesting question is sort of",
    "start": "1036870",
    "end": "1045240"
  },
  {
    "text": "how does it work so basically it decomposes packet processing into a",
    "start": "1045240",
    "end": "1051059"
  },
  {
    "text": "directed graph of nodes so you can almost think of each of these nodes as sort of a nano a micro Network function",
    "start": "1051059",
    "end": "1058590"
  },
  {
    "text": "and each of these notes is a very small amount of work involved in processing the packet and then it hands it off to",
    "start": "1058590",
    "end": "1065030"
  },
  {
    "text": "the next node of the processing graph now packet processing graphs are not particularly new what is new is that VPP",
    "start": "1065030",
    "end": "1074659"
  },
  {
    "text": "processes this processes this graph a vector at a time so it takes a vector of",
    "start": "1074659",
    "end": "1079950"
  },
  {
    "text": "packets as many as it can take off of the received queue and it will take that entire vector and process it through say",
    "start": "1079950",
    "end": "1085919"
  },
  {
    "text": "the ethernet input node and then it will move on to the next node from there and",
    "start": "1085919",
    "end": "1092100"
  },
  {
    "text": "this sense of doing some pretty incredible stuff to performance because a graph node is optimized to fit inside",
    "start": "1092100",
    "end": "1097919"
  },
  {
    "text": "the instruction cache so you wind up with a situation where the graph node",
    "start": "1097919",
    "end": "1104520"
  },
  {
    "text": "itself the first packet warms up the instruction cache so after that you don't have to go out to memory for the",
    "start": "1104520",
    "end": "1109860"
  },
  {
    "text": "instructions the packets are pre fetched into the data cache the lookups four routes or whatever are pre fetched into",
    "start": "1109860",
    "end": "1116820"
  },
  {
    "text": "the data cache and then that result is that more or less after the first packet",
    "start": "1116820",
    "end": "1121890"
  },
  {
    "text": "in the vector you never actually end up blocking on memory which gives you a massive speed-up in terms of the",
    "start": "1121890",
    "end": "1128429"
  },
  {
    "text": "processing of packets and I've got some more slides digging into that with a little more detail here",
    "start": "1128429",
    "end": "1134080"
  },
  {
    "text": "coming up next so if you sort of",
    "start": "1134080",
    "end": "1139120"
  },
  {
    "text": "visualize it this way so you've got the packet processing graph you've got the",
    "start": "1139120",
    "end": "1145029"
  },
  {
    "text": "individual graph nodes some of them are input graph nodes so packets come in from AF packet or vhosts user or D PDK",
    "start": "1145029",
    "end": "1152740"
  },
  {
    "text": "at those graph nodes and you have a whole vector of packets you can sort of",
    "start": "1152740",
    "end": "1159940"
  },
  {
    "text": "visualize what happens they come as an entire vector node by node through the graph and so you get all those nice cash",
    "start": "1159940",
    "end": "1167169"
  },
  {
    "text": "forming behaviors that I mentioned in addition you get the advantages of prefetch to memory there's a lot of",
    "start": "1167169",
    "end": "1173409"
  },
  {
    "text": "stuff being done with instruction parallelization I think on the new skylake server CPUs the theoretical",
    "start": "1173409",
    "end": "1180370"
  },
  {
    "text": "maximum parallelization of instructions per cycle is 5 and we're running something like four point nine seven if",
    "start": "1180370",
    "end": "1186130"
  },
  {
    "text": "memory serves so hyper hyper efficient now a question should be occurring to",
    "start": "1186130",
    "end": "1192909"
  },
  {
    "text": "you guys at this point which is basically what happens if the vector splits what if the vector of Pakistan",
    "start": "1192909",
    "end": "1199539"
  },
  {
    "text": "take a single path through the graph and the answer is that essentially the vector can split at a particular node",
    "start": "1199539",
    "end": "1206200"
  },
  {
    "text": "and then it just gets processed from there as two different vectors you can sort of think of this as an unlucky",
    "start": "1206200",
    "end": "1211960"
  },
  {
    "text": "vector this is sort of a into everyone's life and our packet must fall and it does slow things down because now you",
    "start": "1211960",
    "end": "1217929"
  },
  {
    "text": "have two vectors instead of one being processed to the graph but there's this interesting statistical property that",
    "start": "1217929",
    "end": "1223690"
  },
  {
    "text": "allows you to catch up really quickly which is because this initial vector took longer that means that the number",
    "start": "1223690",
    "end": "1230200"
  },
  {
    "text": "of packets of the next vector is a little bit larger and since you have a bunch of these very expensive fixed",
    "start": "1230200",
    "end": "1235419"
  },
  {
    "text": "costs like hitting memory that are being averaged across the entire number of packets if n goes up the average number",
    "start": "1235419",
    "end": "1243309"
  },
  {
    "text": "of CPU cycles per packet goes down and so you catch up in other words if you if",
    "start": "1243309",
    "end": "1248950"
  },
  {
    "text": "you get a situation to where things go a little bit more slowly for a couple of minutes econds they go faster the next",
    "start": "1248950",
    "end": "1254470"
  },
  {
    "text": "couple of milliseconds any questions so far on the quick run-through the technology",
    "start": "1254470",
    "end": "1261720"
  },
  {
    "text": "nope cool so if VPP also has a plug-in architecture that's incredibly rich so",
    "start": "1262789",
    "end": "1269239"
  },
  {
    "text": "you can do anything with a plug-in except precisely heat so you can add",
    "start": "1269239",
    "end": "1274489"
  },
  {
    "text": "graph nodes to the packet processing graph you can rearrange the graph you",
    "start": "1274489",
    "end": "1280279"
  },
  {
    "text": "can build your plugins independent of the BPP source tree and just drop them as Daiso files in the plugin directory",
    "start": "1280279",
    "end": "1285499"
  },
  {
    "text": "and what this means as anyone can extend VPP with new features however they would",
    "start": "1285499",
    "end": "1290839"
  },
  {
    "text": "like to do it you don't have to block on everyone catching up and likewise you",
    "start": "1290839",
    "end": "1296029"
  },
  {
    "text": "can use the same mechanism to provide hardware acceleration so if I have a piece of hardware that handles some of",
    "start": "1296029",
    "end": "1303109"
  },
  {
    "text": "the things that the graph nodes would otherwise handle in software I can simply let it do that work and then skip",
    "start": "1303109",
    "end": "1308839"
  },
  {
    "text": "to the place where software has to process in the graph and what this means is if you have accelerating Hardware in",
    "start": "1308839",
    "end": "1314419"
  },
  {
    "text": "your boxes you can simply provide plug-ins for them and then if the",
    "start": "1314419",
    "end": "1319579"
  },
  {
    "text": "hardware is present things go faster if the hardware is absent then things still",
    "start": "1319579",
    "end": "1325249"
  },
  {
    "text": "go or if you have hardware from different vendors and different Hardware nodes in your system you could simply",
    "start": "1325249",
    "end": "1330739"
  },
  {
    "text": "stack up the plugins and say ok I'm not going to have to worry about differential deployment across different",
    "start": "1330739",
    "end": "1336589"
  },
  {
    "text": "kinds of hardware I just deploy one collection of plugins everywhere and take advantage of the hardware acceleration that's present make sense",
    "start": "1336589",
    "end": "1345349"
  },
  {
    "text": "so far cool um programmability I'll go through",
    "start": "1345349",
    "end": "1351949"
  },
  {
    "text": "this really quickly VPP for programmability uses a shared memory message queue it's incredibly high",
    "start": "1351949",
    "end": "1358279"
  },
  {
    "text": "performance it's been clocked in at 900,000 requests per second don't ask me",
    "start": "1358279",
    "end": "1363319"
  },
  {
    "text": "why you would need to do that but people who do high-performance coding are kind of obsessive about making things fast",
    "start": "1363319",
    "end": "1369789"
  },
  {
    "text": "and then you get async response messages of course and we've got bindings for C",
    "start": "1369789",
    "end": "1374809"
  },
  {
    "text": "Java Python Lua and go that are being automatically generated every time we",
    "start": "1374809",
    "end": "1380029"
  },
  {
    "text": "build um honeycomb as I mentioned before it's just one example that takes this",
    "start": "1380029",
    "end": "1385909"
  },
  {
    "text": "API and exposes Netcom for rest comp northbound it turns out that anyone can",
    "start": "1385909",
    "end": "1391549"
  },
  {
    "text": "build an agent and so you can have any control plane that makes sense so for example we start looking at the con te v",
    "start": "1391549",
    "end": "1396859"
  },
  {
    "text": "PP work that's being done they're literally just building an agent that manages VPP and deploying and it can in",
    "start": "1396859",
    "end": "1403219"
  },
  {
    "text": "a container as a micro service to handle the networking on the particular node",
    "start": "1403219",
    "end": "1409029"
  },
  {
    "text": "um so VPP has been clocked in at a terabit",
    "start": "1411529",
    "end": "1416750"
  },
  {
    "text": "per second on commodity servers with no hardware acceleration with millions and millions of routes in the routing table",
    "start": "1416750",
    "end": "1424000"
  },
  {
    "text": "so I don't know anything else that even comes close and we're techs my favorite",
    "start": "1424000",
    "end": "1439309"
  },
  {
    "text": "question here then given that VP runs in",
    "start": "1439309",
    "end": "1444500"
  },
  {
    "text": "user space but also acknowledging that if certain hardware is present",
    "start": "1444500",
    "end": "1452559"
  },
  {
    "text": "packet processing will be accelerated",
    "start": "1452559",
    "end": "1456820"
  },
  {
    "text": "this is public cloud friendly oh is it really public cloud friendly yes okay",
    "start": "1458169",
    "end": "1466990"
  },
  {
    "text": "because again you run you it will run whether or not you have magic hardware present so it's very friendly to public",
    "start": "1466990",
    "end": "1473929"
  },
  {
    "text": "cloud and it's it's even friendly to you have some funky networking thing that",
    "start": "1473929",
    "end": "1479750"
  },
  {
    "text": "you need to do inside a container well with VPP you don't have to go get the appropriate version of the kernel with",
    "start": "1479750",
    "end": "1485179"
  },
  {
    "text": "the appropriate magic feature going you can just run it purely in user space which makes it not only very favorite",
    "start": "1485179",
    "end": "1491390"
  },
  {
    "text": "favor very friendly to public cloud it makes it very cloud native friendly because literally you've converted your",
    "start": "1491390",
    "end": "1496880"
  },
  {
    "text": "networking into a pure micro service",
    "start": "1496880",
    "end": "1501010"
  },
  {
    "text": "applications deploying taking do they do that they do that with VPP in the",
    "start": "1502000",
    "end": "1511190"
  },
  {
    "text": "container image that they're using to run on what kind of applications you're",
    "start": "1511190",
    "end": "1517070"
  },
  {
    "text": "talking about so if you're a service provider and you're running to deploy a be enough we are the BNF is doing",
    "start": "1517070",
    "end": "1522830"
  },
  {
    "text": "network processing right it's processing packets then you would probably want to build an application that has BGP",
    "start": "1522830",
    "end": "1528710"
  },
  {
    "text": "incited to do your packet processing um if you are just a plain old vanilla",
    "start": "1528710",
    "end": "1533870"
  },
  {
    "text": "flavor application running on a kubernetes node then as you'll hear you",
    "start": "1533870",
    "end": "1539929"
  },
  {
    "text": "see here in some later slides you can simply do the traditional dance of you know queue control apply - FTP",
    "start": "1539929",
    "end": "1547070"
  },
  {
    "text": "Emel and that will make that switch but what will be happening under the covers is literally a vnf your V switch a",
    "start": "1547070",
    "end": "1554600"
  },
  {
    "text": "container for your V switch a pod for your Reese which being deployed as a daemon set so that you know your",
    "start": "1554600",
    "end": "1561139"
  },
  {
    "text": "networking D switch is running purely in user space and then your containers before the pods that you're deploying on",
    "start": "1561139",
    "end": "1567259"
  },
  {
    "text": "that node are being plugged into it okay okay I've got some pretty pictures",
    "start": "1567259",
    "end": "1572360"
  },
  {
    "text": "around that because it is an interesting thing yep but so again getting back to",
    "start": "1572360",
    "end": "1578720"
  },
  {
    "text": "this the VPP guys actually do count cycles per packet so you know this was",
    "start": "1578720",
    "end": "1584330"
  },
  {
    "text": "doing in comparison you were looking about 160 cycles per packet which is",
    "start": "1584330",
    "end": "1590059"
  },
  {
    "text": "damn fast and I apologize I missed quoted we're at three point two eight out of five not four point nine seven",
    "start": "1590059",
    "end": "1596509"
  },
  {
    "text": "it was the line below it that got stuck in my head in terms of the instructions per cycle so I mean we're literally the",
    "start": "1596509",
    "end": "1609230"
  },
  {
    "text": "just make sure I understood this in the right way we were talking about giving",
    "start": "1609230",
    "end": "1615309"
  },
  {
    "text": "different vectors being broken up a",
    "start": "1615309",
    "end": "1619450"
  },
  {
    "text": "vector is broken up that's the",
    "start": "1622840",
    "end": "1627860"
  },
  {
    "text": "instructions recycle that that affects like that's the number of instructions not not quite so if a particular",
    "start": "1627860",
    "end": "1634820"
  },
  {
    "text": "particular vector gets broken off then what will happen is you'll be running you know so let me go back to the",
    "start": "1634820",
    "end": "1641029"
  },
  {
    "text": "picture because it makes it easier to explain so if you look at this picture",
    "start": "1641029",
    "end": "1647768"
  },
  {
    "text": "splitting the vector so in that packet it's broken off packets 1 0 1 3 through",
    "start": "1647830",
    "end": "1655820"
  },
  {
    "text": "N they process just as fast as normal but you've got to go back and then load the ARB input node into the instruction",
    "start": "1655820",
    "end": "1662809"
  },
  {
    "text": "cache to process packet 2 so the totality of that vector will process more slowly that means the next vector",
    "start": "1662809",
    "end": "1669500"
  },
  {
    "text": "is like n plus M it's a little bit bigger in size so your average cost goes down per packet for the next one",
    "start": "1669500",
    "end": "1676840"
  },
  {
    "text": "suggesting we most vectors traverse a single path through the graph um but you do get outliers but then you",
    "start": "1676840",
    "end": "1684350"
  },
  {
    "text": "can catch up make sense yeah let me",
    "start": "1684350",
    "end": "1689880"
  },
  {
    "text": "catch back up the slide deck yeah",
    "start": "1689880",
    "end": "1696390"
  },
  {
    "text": "so the you end up with extremely high performance one other thing to mention here is we are literally finding that",
    "start": "1696390",
    "end": "1701970"
  },
  {
    "text": "the limitation is the number of PCI links we could actually do better than these numbers with VPP if we could get",
    "start": "1701970",
    "end": "1709050"
  },
  {
    "text": "more PCI lines from Intel and the way we know this is back on the old um the",
    "start": "1709050",
    "end": "1715260"
  },
  {
    "text": "previous version is eons when we were getting 560 gigabits per second the telemetry was telling us it was the PCI",
    "start": "1715260",
    "end": "1722310"
  },
  {
    "text": "lanes that were limiting us and we're seeing that same telemetric signature looking at the telemetry now that we're",
    "start": "1722310",
    "end": "1728010"
  },
  {
    "text": "basically pushing a tear of it through and so we're pretty sure that if we you know as the generation of processors get",
    "start": "1728010",
    "end": "1734760"
  },
  {
    "text": "better and we get more PCI lanes will continue to see performance improvements cuz these two numbers are exactly the",
    "start": "1734760",
    "end": "1740580"
  },
  {
    "text": "same binary it's just different hardware with different number of PCI lines so",
    "start": "1740580",
    "end": "1747450"
  },
  {
    "text": "the this guy is really quick getting this guy is pretty much the limit um in",
    "start": "1747450",
    "end": "1755010"
  },
  {
    "text": "terms of features this this is kind of an eyesore basically what it comes down to is you've pretty much got everything",
    "start": "1755010",
    "end": "1761160"
  },
  {
    "text": "you could imagine in terms of networking features if you were doing an industrial-grade router or switch you",
    "start": "1761160",
    "end": "1768090"
  },
  {
    "text": "have in VPP so routing switching you know advanced features like segment routing you know NAT features all the",
    "start": "1768090",
    "end": "1776160"
  },
  {
    "text": "kinds of proxies you'd want for DHCP lots of invent ulema tree lots of",
    "start": "1776160",
    "end": "1781410"
  },
  {
    "text": "counters you know even support for things like MPLS if you want it so you",
    "start": "1781410",
    "end": "1786480"
  },
  {
    "text": "could do all kinds of crazy things with VPP and that number continues to grow",
    "start": "1786480",
    "end": "1791790"
  },
  {
    "text": "and if there's anything it doesn't do that you want it's a few hundred lines of C to write a plug-in that does it so",
    "start": "1791790",
    "end": "1798420"
  },
  {
    "text": "add couple questions for you real quick are there any reasonable limitations on",
    "start": "1798420",
    "end": "1803490"
  },
  {
    "text": "say ecmp multi pass or do you really not care how big the hash is um I would have",
    "start": "1803490",
    "end": "1810960"
  },
  {
    "text": "to go find out what the outer limits really are but I'll tell you story that will give you some idea of how the minds the people involved work",
    "start": "1810960",
    "end": "1818340"
  },
  {
    "text": "the date barrack is sort of the genius behind all of this and I was having a conversation with him at one point where",
    "start": "1818340",
    "end": "1824290"
  },
  {
    "text": "he was sort of saying you know you really want in caps not tunnel interfaces because interfaces are",
    "start": "1824290",
    "end": "1830110"
  },
  {
    "text": "expensive you know and and though performance but you gotta use them if",
    "start": "1830110",
    "end": "1835179"
  },
  {
    "text": "you're gonna do sort of a virtual bridge domain right if you're gonna do a bridge domain for l2 stuff you got to use",
    "start": "1835179",
    "end": "1841000"
  },
  {
    "text": "interfaces that it has costs and this kind of Concerned me and so I said okay Dave so where are the walls on this",
    "start": "1841000",
    "end": "1846429"
  },
  {
    "text": "right how about a problem is this and his response was is I wouldn't expect",
    "start": "1846429",
    "end": "1854200"
  },
  {
    "text": "any kind of reasonable performance with more than about 80,000 tunnel interfaces yeah god help if you do this type of",
    "start": "1854200",
    "end": "1860530"
  },
  {
    "text": "show int I just a couple other questions",
    "start": "1860530",
    "end": "1866860"
  },
  {
    "text": "and I'm just looking at this um so the multipath was one um the other IP and IP",
    "start": "1866860",
    "end": "1874510"
  },
  {
    "text": "on do you have that as an end cap oh I don't I'm try to remember I'm looking it",
    "start": "1874510",
    "end": "1881290"
  },
  {
    "text": "doesn't look like it and I guess by P and IP but quite honestly um in caps are",
    "start": "1881290",
    "end": "1887320"
  },
  {
    "text": "the simplest order problems we have if somebody whenever so I guess the interesting thing for the end cap is is",
    "start": "1887320",
    "end": "1894490"
  },
  {
    "text": "the way we use IP and IP in calico is we",
    "start": "1894490",
    "end": "1899710"
  },
  {
    "text": "do it stateless we don't set up the tunnels a priori we basically use the next hop address it's a Linux kernel Bay or we use the",
    "start": "1899710",
    "end": "1907360"
  },
  {
    "text": "next cop address as the end point of the IP and IP tunnel you're gonna love this",
    "start": "1907360",
    "end": "1913090"
  },
  {
    "text": "because essentially remember the comment you only actually use tunnel interfaces for the old yes so you guys are pure l3",
    "start": "1913090",
    "end": "1919690"
  },
  {
    "text": "in this case you would just have a route this is by the way please go in cap this damn thing yeah that's what we sort of",
    "start": "1919690",
    "end": "1925360"
  },
  {
    "text": "do today and in bird we basically send it to the ton zero interface as the which handle is the end cap stub right",
    "start": "1925360",
    "end": "1932740"
  },
  {
    "text": "so I guess the only other one that comes to mind um there was two others um so I",
    "start": "1932740",
    "end": "1944740"
  },
  {
    "text": "guess one was that you know what is the size of the multipath and be have you",
    "start": "1944740",
    "end": "1951990"
  },
  {
    "text": "guys looked at doing um doing before so",
    "start": "1951990",
    "end": "1960960"
  },
  {
    "text": "sort of like bi-directional stateless ex-lap or some kind of X lot because X",
    "start": "1960960",
    "end": "1967950"
  },
  {
    "text": "lot performance and the kernel has been pretty horrid Forex like I could go get",
    "start": "1967950",
    "end": "1973200"
  },
  {
    "text": "you the details on that so if you could that would be great the one thing I will",
    "start": "1973200",
    "end": "1978420"
  },
  {
    "text": "plead with regards to this slide is there's a lot of stuff that didn't get put on this slide simply because the number of features we support has made",
    "start": "1978420",
    "end": "1984750"
  },
  {
    "text": "it impossible for this like to actually be kept up to date I'm you know and and and you know this is the third attempt",
    "start": "1984750",
    "end": "1991440"
  },
  {
    "text": "at this and the last time I did this slide it was like I simply can't fit anything else in here the reason I'm",
    "start": "1991440",
    "end": "1996900"
  },
  {
    "text": "asking about X lot and I think this is larger for the network working group I'm starting now to run into folks who are",
    "start": "1996900",
    "end": "2006380"
  },
  {
    "text": "going directly from ipv4 only to wanting to run ipv6 only infrastructure because",
    "start": "2006380",
    "end": "2011780"
  },
  {
    "text": "they're just out of addresses and kubernetes makes it much much worse and",
    "start": "2011780",
    "end": "2017500"
  },
  {
    "text": "then there is the concept of v4 as a service across the infrastructure and",
    "start": "2017500",
    "end": "2023060"
  },
  {
    "text": "you could do something like a stateless Forex Forex lot to offer v4 as a service",
    "start": "2023060",
    "end": "2029870"
  },
  {
    "text": "without requiring consistent before endpoints well I I believe we do a standard we do have available a standard",
    "start": "2029870",
    "end": "2037480"
  },
  {
    "text": "before you know before every 6x slot but one thing I will draw your attention to is we also have features like map and",
    "start": "2037480",
    "end": "2044270"
  },
  {
    "text": "lightweight for over six give you probably more complicated than you want honestly um abilities to tunnel v4 over",
    "start": "2044270",
    "end": "2052040"
  },
  {
    "text": "a PC under length I think in your case what you probably you want is more like a static ex-lap",
    "start": "2052040",
    "end": "2057260"
  },
  {
    "text": "because these are more free I'm running a complicated service provider network yeah actually it's it's it's interesting",
    "start": "2057260",
    "end": "2064250"
  },
  {
    "text": "um you don't want it static because then I've got to offer the for static",
    "start": "2064250",
    "end": "2069620"
  },
  {
    "text": "addresses to the client what I want is the dynamic on the pot on the payload I want to lie to the payload and tell it",
    "start": "2069620",
    "end": "2076638"
  },
  {
    "text": "it's got a v4 address but actually have that X as a v6 and then get mapped to a v4 at",
    "start": "2076639",
    "end": "2084000"
  },
  {
    "text": "the edge if I have to handle inbound for traffic right so it's it actually gets",
    "start": "2084000",
    "end": "2089250"
  },
  {
    "text": "carried as v6 and just gets to the end captain to whatever v4 I've told the the pod it has and that might get reused so",
    "start": "2089250",
    "end": "2096600"
  },
  {
    "text": "it's not really static it is more dynamic so yes the map and lightweight for v6 are sort of fairly sophisticated",
    "start": "2096600",
    "end": "2103620"
  },
  {
    "text": "ways of doing that and again it's when you're looking at the problem of translating of burning v4 over v6 there",
    "start": "2103620",
    "end": "2110880"
  },
  {
    "text": "are a lot of ways to do it and they yep levels of complexity depending on your varying levels of need because you know",
    "start": "2110880",
    "end": "2116610"
  },
  {
    "text": "one of the other options is you know it's just simply something like a DX",
    "start": "2116610",
    "end": "2121740"
  },
  {
    "text": "than GP and cat for God's sake right yeah that yeah we can have a large",
    "start": "2121740",
    "end": "2128310"
  },
  {
    "text": "conversation on that but but I think I can I think this is one that we should",
    "start": "2128310",
    "end": "2133560"
  },
  {
    "text": "probably start talking about in the network working group is you know it's",
    "start": "2133560",
    "end": "2140010"
  },
  {
    "text": "sort of the you know v4 considered harmful RFC we've gone from we don't support v4 to very quickly should we be",
    "start": "2140010",
    "end": "2147960"
  },
  {
    "text": "talking about V you should be considering v6 at least considering v6",
    "start": "2147960",
    "end": "2154590"
  },
  {
    "text": "only infrastructures if you're going to be at scale and therefore what do you do with all your v4 end points required end",
    "start": "2154590",
    "end": "2163170"
  },
  {
    "text": "points in that environment I know you know all the things I can offer you guys as potentially something we could do is",
    "start": "2163170",
    "end": "2170220"
  },
  {
    "text": "I sure it'll come as a great surprise to you that I have an incredibly deep v6",
    "start": "2170220",
    "end": "2175230"
  },
  {
    "text": "expert in my back pocket hey I mean you would never expect that but but I can",
    "start": "2175230",
    "end": "2180660"
  },
  {
    "text": "literally all I get literally persuade Marc Townsley who is literally the fellow at Cisco who's been driving the",
    "start": "2180660",
    "end": "2187380"
  },
  {
    "text": "v6 Boulder up yeah yeah I know Marc really well from the I in it did you know it's it's you know I was an ops me",
    "start": "2187380",
    "end": "2193800"
  },
  {
    "text": "6 and everything else so yeah Marc would be a good one to possibly pull in yep",
    "start": "2193800",
    "end": "2201480"
  },
  {
    "text": "but I think we've we've sorted these problems enough in the IETF we know what can be done it's just going to be a matter of",
    "start": "2201480",
    "end": "2208310"
  },
  {
    "text": "implementing it in an official in a in an efficient manner",
    "start": "2208310",
    "end": "2213870"
  },
  {
    "text": "in the data flame because right now the options to do it in the data plane all sort of suck from a performance",
    "start": "2213870",
    "end": "2219210"
  },
  {
    "text": "standpoint the good news is I think you'll find the ones that we have don't suck and if somebody decides they need",
    "start": "2219210",
    "end": "2225030"
  },
  {
    "text": "more than what we have they're you know they're tunable meaning with a little more a little more elbow grease folks",
    "start": "2225030",
    "end": "2231270"
  },
  {
    "text": "can make them go faster and because VP",
    "start": "2231270",
    "end": "2236280"
  },
  {
    "text": "because the the release cycle and Fido is about three months and because it's",
    "start": "2236280",
    "end": "2241620"
  },
  {
    "text": "running in user space as a micro service you don't have to wait however many years for the kernel to catch up okay",
    "start": "2241620",
    "end": "2251270"
  },
  {
    "text": "and there are also some other options in here that may like make life better like I don't know if you're familiar with",
    "start": "2251270",
    "end": "2256890"
  },
  {
    "text": "what Ohio am does IO am in it's",
    "start": "2256890",
    "end": "2262980"
  },
  {
    "text": "basically in band telemetry so you can optionally say I would like to include",
    "start": "2262980",
    "end": "2268020"
  },
  {
    "text": "an IO am header with my traffic and get timestamps of every node that it passes through including it would endow your",
    "start": "2268020",
    "end": "2274830"
  },
  {
    "text": "application at this time and data came back out at that time so lots of it yeah",
    "start": "2274830",
    "end": "2281100"
  },
  {
    "text": "that's interesting for a NFV app application I'm I think what we're gonna",
    "start": "2281100",
    "end": "2287880"
  },
  {
    "text": "see in kubernetes land and cloud native land is a lot more of that happening at",
    "start": "2287880",
    "end": "2294090"
  },
  {
    "text": "the l5 l7 I like an sto layer but it's still an it's still an interesting tool",
    "start": "2294090",
    "end": "2300510"
  },
  {
    "text": "in the tool bag it is but I mean for example being able to understand what is your latency tax from envoy or from",
    "start": "2300510",
    "end": "2308310"
  },
  {
    "text": "whatever your proxy is also may be of some interest if you're trying to figure out where things are going wrong um so",
    "start": "2308310",
    "end": "2314940"
  },
  {
    "text": "but anyway that sort of features in terms of feature velocity this is just",
    "start": "2314940",
    "end": "2320100"
  },
  {
    "text": "sort of showing we do releases every three months or so and we pick up a fair number of new features every three",
    "start": "2320100",
    "end": "2326250"
  },
  {
    "text": "months and then you know sort of we have seem to go back to that one real quick",
    "start": "2326250",
    "end": "2332400"
  },
  {
    "text": "sorry of course BFD fib nat64 giri over ipv6 okay all",
    "start": "2332400",
    "end": "2341610"
  },
  {
    "text": "right um and then you've got the standard sorts of things you would expect from a relatively well run",
    "start": "2341610",
    "end": "2347160"
  },
  {
    "text": "project when a patch is submitted he goes through automated verify where we run sort of hundreds of unit tests hundreds",
    "start": "2347160",
    "end": "2352920"
  },
  {
    "text": "more system functional tests and then you know a fair number of depending on",
    "start": "2352920",
    "end": "2357990"
  },
  {
    "text": "how concerned people are about the patch performance tests they get run on bare metal so that we can make sure we're not",
    "start": "2357990",
    "end": "2363180"
  },
  {
    "text": "seeing performance regressions in the entire system and that happens before we",
    "start": "2363180",
    "end": "2368430"
  },
  {
    "text": "even get to a code review stop got it you know and then once we do merge for",
    "start": "2368430",
    "end": "2374070"
  },
  {
    "text": "usability we publish a bunch of artifacts so you get apt installable Debian packages yum install overall RPM",
    "start": "2374070",
    "end": "2379950"
  },
  {
    "text": "packages auto-generated documentation that gets generated merged by merge so",
    "start": "2379950",
    "end": "2386760"
  },
  {
    "text": "you can always go out together yum install the latest packages and then per release we also auto generate test",
    "start": "2386760",
    "end": "2393150"
  },
  {
    "text": "reports we've got puppet modules their training and tutorials hands-on use cases blah blah blah all right yep so",
    "start": "2393150",
    "end": "2406260"
  },
  {
    "text": "then um this sort of is trying to draw the picture here when I was saying I keep saying networking as a micro service so you can literally run on on a",
    "start": "2406260",
    "end": "2413940"
  },
  {
    "text": "node a VB PD switch micro service pod um you know it would be bypassing the",
    "start": "2413940",
    "end": "2420210"
  },
  {
    "text": "kernel to get to the NIC and then it ends ups you know providing networking for the individual pods that you're",
    "start": "2420210",
    "end": "2426390"
  },
  {
    "text": "running as workloads on that node and this gives you a lot of advantages you",
    "start": "2426390",
    "end": "2431430"
  },
  {
    "text": "know basically it's pure user space you could talk directly to the next use EDD BDK is up being quite a bit faster than",
    "start": "2431430",
    "end": "2438750"
  },
  {
    "text": "what you get from the kernel it's more scalable it has a bunch of additional features it evolves more quickly because",
    "start": "2438750",
    "end": "2445290"
  },
  {
    "text": "you've got releases every three months and at since it's a essentially just another daemon set that you run to",
    "start": "2445290",
    "end": "2451560"
  },
  {
    "text": "provide your networking as a pod upgrading becomes much simpler you don't have to upgrade the underlying kernel",
    "start": "2451560",
    "end": "2457800"
  },
  {
    "text": "and box um and it also becomes a few microseconds of restart I sorry a few",
    "start": "2457800",
    "end": "2463440"
  },
  {
    "text": "milliseconds of restart on the pod as opposed to 15-minute reboot times and",
    "start": "2463440",
    "end": "2469160"
  },
  {
    "text": "all of this makes it easier to get faster innovation on the data plane as well good",
    "start": "2469160",
    "end": "2477300"
  },
  {
    "text": "[Applause] quickly round off the other question I asked before about public cloud compatibility this is just a question",
    "start": "2477300",
    "end": "2484820"
  },
  {
    "text": "from my own ignorance around the universal availability of DP DK I take",
    "start": "2484820",
    "end": "2492830"
  },
  {
    "text": "it that's just has been in these commonplace in yep so you're basically",
    "start": "2492830",
    "end": "2498740"
  },
  {
    "text": "asking what happens if I'm running this to the VM instead of on bare metal right yet if you're right if you're running it",
    "start": "2498740",
    "end": "2505040"
  },
  {
    "text": "on in a VM you have something that as far as the VM is concerned looks like a PCI net as long as far as you know and",
    "start": "2505040",
    "end": "2512270"
  },
  {
    "text": "there is a you IOT CI generic driver that will work in that case so even if",
    "start": "2512270",
    "end": "2518480"
  },
  {
    "text": "you don't really have hardware there you should be able to run this inside inside",
    "start": "2518480",
    "end": "2524270"
  },
  {
    "text": "of the m in a public cloud okay you know plus there there are also various",
    "start": "2524270",
    "end": "2529520"
  },
  {
    "text": "efforts going on in public cloud as they're trying to address some of the nfe use space where they're actually",
    "start": "2529520",
    "end": "2535220"
  },
  {
    "text": "looking at providing a better DP DK support than not oh you know so this",
    "start": "2535220",
    "end": "2541310"
  },
  {
    "text": "will this is something that is public cloud friendly I have a question so you",
    "start": "2541310",
    "end": "2549980"
  },
  {
    "text": "mean to say this VPP will be in your part and all their ports will be connected to that VPP yeah in this case",
    "start": "2549980",
    "end": "2558260"
  },
  {
    "text": "these connections are logical I've got the next slide actually talks a little bit about the two options that you have available for actually doing that plumb",
    "start": "2558260",
    "end": "2565640"
  },
  {
    "text": "okay okay okay you consistently ask me good leading questions that take me to",
    "start": "2565640",
    "end": "2571010"
  },
  {
    "text": "the next set of slides okay yeah I mean I've asked us to know what if the VPP is outside just we have the VPP which was",
    "start": "2571010",
    "end": "2578300"
  },
  {
    "text": "switching stuff in the port we can deploy it the T between all the nodes",
    "start": "2578300",
    "end": "2584240"
  },
  {
    "text": "and we can connect our ports and VPP yes well I was thinking like what will be",
    "start": "2584240",
    "end": "2590240"
  },
  {
    "text": "the odd wondering of implementing in a port actually that's a yeah I mean let's",
    "start": "2590240",
    "end": "2598730"
  },
  {
    "text": "go to this sort of next picture because this talks about how you can communicate with pots from VBB right so and there's",
    "start": "2598730",
    "end": "2605240"
  },
  {
    "text": "sort of two options that are available to you one is you can use beef Paris",
    "start": "2605240",
    "end": "2611540"
  },
  {
    "text": "and the problem with the fingers is their comparatively slow and comparatively non-scalable and so that's",
    "start": "2611540",
    "end": "2620120"
  },
  {
    "text": "certainly an option it's an option that will always work and you will still get advantages from using to be in that phase but one of the problems that we've",
    "start": "2620120",
    "end": "2627890"
  },
  {
    "text": "seen repeatedly with various things with vbp is if you pass process packets really really quickly and the i/o can't",
    "start": "2627890",
    "end": "2634280"
  },
  {
    "text": "keep up in other words the links leaving a lot of performance and scalability on",
    "start": "2634280",
    "end": "2639860"
  },
  {
    "text": "the table we actually offer in bbp is we have a VPP user space host stack that",
    "start": "2639860",
    "end": "2648230"
  },
  {
    "text": "implements TV and that kind of stuff and that host stack has an LD preload shim",
    "start": "2648230",
    "end": "2654080"
  },
  {
    "text": "available so that with no code changes to the pod you can actually slide that",
    "start": "2654080",
    "end": "2659570"
  },
  {
    "text": "LD preload shim under or for you know for non statically linked workloads and",
    "start": "2659570",
    "end": "2666290"
  },
  {
    "text": "you can then take advantage of the BPP user space so stack now this host stack scales - OH",
    "start": "2666290",
    "end": "2672140"
  },
  {
    "text": "10,000,000 can simultaneous connections 200,000 new connections per second on two core",
    "start": "2672140",
    "end": "2678470"
  },
  {
    "text": "it's also been clocked out pushing north of a hundred gig per second between two",
    "start": "2678470",
    "end": "2683510"
  },
  {
    "text": "pods running on the same server because ECP connection or a single connection",
    "start": "2683510",
    "end": "2689540"
  },
  {
    "text": "because what are the things that we do is if we detect that two pauses are running on the same host and you're",
    "start": "2689540",
    "end": "2696560"
  },
  {
    "text": "using the BPP host act rather than pushing that traffic through a TCP stack we simply treat it as a FIFO queue and",
    "start": "2696560",
    "end": "2702860"
  },
  {
    "text": "so you get really really sped up performance there so that's one set of options that will work with existing",
    "start": "2702860",
    "end": "2709130"
  },
  {
    "text": "workflows out of the box if you have workloads where you can't remain ahead and that's gonna cross namespace",
    "start": "2709130",
    "end": "2718100"
  },
  {
    "text": "boundaries right there you're not gonna be constrained by a namespace boundary there ya know exactly so we're if you're",
    "start": "2718100",
    "end": "2724640"
  },
  {
    "text": "using these thing you're playing in the kernel namespace game if you're - might still have a name spacing concept",
    "start": "2724640",
    "end": "2730490"
  },
  {
    "text": "because you do have the this is who is allowed to talk these are the containers that I'll talk about the VPP host act if",
    "start": "2730490",
    "end": "2736460"
  },
  {
    "text": "the pod is in a tenant namespace or or a",
    "start": "2736460",
    "end": "2741560"
  },
  {
    "text": "secret you know sauce network namespace which micro-service pod is in the host",
    "start": "2741560",
    "end": "2747110"
  },
  {
    "text": "namespace the VPP host a quill spam that names those names basis correct well keep in mind if we're not running a via",
    "start": "2747110",
    "end": "2753440"
  },
  {
    "text": "the air we're not dealing with network namespaces anymore in the kernel sense we okay we are still enforcing the name",
    "start": "2753440",
    "end": "2762980"
  },
  {
    "text": "spacing boundaries because you still have a poly and that but now that that means changes to C and I and and other",
    "start": "2762980",
    "end": "2770030"
  },
  {
    "text": "things it doesn't necessarily mean changes to C and I we don't mind that the net write namespace is set up we",
    "start": "2770030",
    "end": "2776060"
  },
  {
    "text": "still give you the same isolation the you get from an array in space understanding it the same isolation the question is just the change if we can",
    "start": "2776060",
    "end": "2784100"
  },
  {
    "text": "use CN you know scuzz it's gonna get a pod namespace is gonna get set up for",
    "start": "2784100",
    "end": "2790730"
  },
  {
    "text": "the thing and to be in in a mall I'm looking at the V switch microservice pod would be in the host name space so as",
    "start": "2790730",
    "end": "2796970"
  },
  {
    "text": "long as the BPP host for that can span those namespaces that network namespaces",
    "start": "2796970",
    "end": "2802730"
  },
  {
    "text": "I know it's not necessary for keeping you know routing table etc I don't rely",
    "start": "2802730",
    "end": "2807860"
  },
  {
    "text": "on any of that it just that's the way things get done so honest you don't have to change that plumbing that's a little",
    "start": "2807860",
    "end": "2813680"
  },
  {
    "text": "bit easier yep yep so um you know that that basically know that there's one",
    "start": "2813680",
    "end": "2820100"
  },
  {
    "text": "other aspect of this if you are dealing with a workload that is sufficiently performance sensitive that you actually",
    "start": "2820100",
    "end": "2826120"
  },
  {
    "text": "so here's a fact about the world that anyone who's tried to write a high-performance TCP stack has",
    "start": "2826120",
    "end": "2831350"
  },
  {
    "text": "eventually hit which is that the bsd socket API itself is a bottleneck the",
    "start": "2831350",
    "end": "2837260"
  },
  {
    "text": "API itself limits performance when you get to the far out edges and so if you have an application where you are",
    "start": "2837260",
    "end": "2843020"
  },
  {
    "text": "finding the bsd api itself in this situation is creating a bottleneck for you we do have a higher performance",
    "start": "2843020",
    "end": "2850100"
  },
  {
    "text": "native API that is available if you wish to use it for your workload but it would require code changes in the workload so",
    "start": "2850100",
    "end": "2858110"
  },
  {
    "text": "free yeah worried about that I'm just worried about you know trying to avoid",
    "start": "2858110",
    "end": "2863180"
  },
  {
    "text": "the V if pair to get into the pod if I could yeah yeah absolutely and so we've",
    "start": "2863180",
    "end": "2870050"
  },
  {
    "text": "actually got I'll point you to this we",
    "start": "2870050",
    "end": "2875090"
  },
  {
    "text": "actually do have examples of this working right now that I can point you to go that's fine that's just",
    "start": "2875090",
    "end": "2881990"
  },
  {
    "text": "you can send me a Boyer be good yeah absolutely so that's sort of the generic",
    "start": "2881990",
    "end": "2887599"
  },
  {
    "text": "how you communicate with pods um you've got the two options there now in terms",
    "start": "2887599",
    "end": "2893660"
  },
  {
    "text": "of how you communicate between pods if you use the native space host stack there's an interesting other thing that",
    "start": "2893660",
    "end": "2901520"
  },
  {
    "text": "is possible here which is the way VPP sets up the communications you know say you've got one pod listening at another",
    "start": "2901520",
    "end": "2908450"
  },
  {
    "text": "pod connects to it and they happen to be on the same host is it essentially is just acting as the broker here that sets",
    "start": "2908450",
    "end": "2915380"
  },
  {
    "text": "up a shared memory segment between them and once you've got that direct shared memory connection established bvp gets",
    "start": "2915380",
    "end": "2921500"
  },
  {
    "text": "entirely out of the way because the connect all the things that are done about authorizing the connection setting",
    "start": "2921500",
    "end": "2926570"
  },
  {
    "text": "up the connection those go through VPP to control issues of policy and whatnot but there's no reason that we have to",
    "start": "2926570",
    "end": "2932990"
  },
  {
    "text": "touch every byte that passes through in order to allow you to communicate there and you just stayed yourself men copies",
    "start": "2932990",
    "end": "2939530"
  },
  {
    "text": "by getting VPP out of the way once the connection is established so is all of",
    "start": "2939530",
    "end": "2945890"
  },
  {
    "text": "the so so here's an interesting problem if the config in CPP changes ie",
    "start": "2945890",
    "end": "2955099"
  },
  {
    "text": "somebody's added another policy and you've got pods talking over that policy and flyer changes a policy and you've",
    "start": "2955099",
    "end": "2960200"
  },
  {
    "text": "got pods communicating with one another or using that policy in flight this",
    "start": "2960200",
    "end": "2967190"
  },
  {
    "text": "would bypass any pod any policy changes somebody changes the canaries network",
    "start": "2967190",
    "end": "2973700"
  },
  {
    "text": "policy for example and that change affects in-flight traffic you mean",
    "start": "2973700",
    "end": "2979099"
  },
  {
    "text": "changes the label on a pod because it more they change the you know the the original policy said I'm going to allow",
    "start": "2979099",
    "end": "2985460"
  },
  {
    "text": "631 and 636 between all that clients and LDAP servers somebody goes in and drops",
    "start": "2985460",
    "end": "2991240"
  },
  {
    "text": "631 says we're only going to do LDAP s misremembering but I thought the last",
    "start": "2991240",
    "end": "2996830"
  },
  {
    "text": "time I tried to actually change in that word policy that that that I could not change a policy in flight I could remove",
    "start": "2996830",
    "end": "3003250"
  },
  {
    "text": "it and replace it but I remember my attempts to change it did not go well depends on how your learn during the",
    "start": "3003250",
    "end": "3009970"
  },
  {
    "text": "policy write policy is just a cou bearnaise object it depends on what the network stack right but my",
    "start": "3009970",
    "end": "3016300"
  },
  {
    "text": "recollection was asking kubernetes to change the policy I was got back an error that indicated he couldn't be",
    "start": "3016300",
    "end": "3021610"
  },
  {
    "text": "change but maybe I'm just remembering um well even okay in whatever way the if there is a change",
    "start": "3021610",
    "end": "3028540"
  },
  {
    "text": "now yep by doing this that is not going to be reflected it looks like on",
    "start": "3028540",
    "end": "3034480"
  },
  {
    "text": "in-flight packets know that that's an interesting corner case to go take a look at and make sure that we get right yes okay cool all right so that but",
    "start": "3034480",
    "end": "3045910"
  },
  {
    "text": "there's a big pick up both in terms of the performance you can get between pods that happen to live on the same node but",
    "start": "3045910",
    "end": "3052150"
  },
  {
    "text": "also in terms of the cost of being of networking between them so you're gonna increase in scale and density as well",
    "start": "3052150",
    "end": "3058920"
  },
  {
    "text": "okay and then we've been talking a little bit to Mack line about",
    "start": "3058920",
    "end": "3065110"
  },
  {
    "text": "possibilities here with envoy because you know there's sort of an example of people who are very interested in the",
    "start": "3065110",
    "end": "3071080"
  },
  {
    "text": "performance of things and so in the sto envoy case were you to use the VPP host",
    "start": "3071080",
    "end": "3076960"
  },
  {
    "text": "back it's the same LD preload shim game involved it's just that you're talking within the same pod over that direct",
    "start": "3076960",
    "end": "3084370"
  },
  {
    "text": "shared memory once connection is established instead of between pods right but you wouldn't be doing that",
    "start": "3084370",
    "end": "3090520"
  },
  {
    "text": "between pods in envoy anyway if you load the Envoy in - yes but you would be",
    "start": "3090520",
    "end": "3097750"
  },
  {
    "text": "doing it between containers um they're in the same network namespace I guess",
    "start": "3097750",
    "end": "3104800"
  },
  {
    "text": "yes you're but you could be talking to local host right so um not sure I guess",
    "start": "3104800",
    "end": "3114190"
  },
  {
    "text": "depends on how you're doing the local host within the pod I'm also confused here you've got VPP host stack connected",
    "start": "3114190",
    "end": "3119770"
  },
  {
    "text": "to both containers the VPP host stack I think would be connected into the pods",
    "start": "3119770",
    "end": "3125170"
  },
  {
    "text": "network namespace not into every container space is a kernel concept",
    "start": "3125170",
    "end": "3131640"
  },
  {
    "text": "about how it partitions the kernel owned interfaces the post stack in this case",
    "start": "3131640",
    "end": "3136780"
  },
  {
    "text": "would be done via LD prelature into every single",
    "start": "3136780",
    "end": "3142609"
  },
  {
    "text": "mm-hmm Oh II okay this presents an interesting problem then for Kerberos",
    "start": "3142609",
    "end": "3148400"
  },
  {
    "text": "Network policy whose kubernetes network policy is a contains a pod level not a container level thing so we know no I",
    "start": "3148400",
    "end": "3155569"
  },
  {
    "text": "know the thing is you still apply the policy at the level of a pod but I've",
    "start": "3155569",
    "end": "3161239"
  },
  {
    "text": "got multiple interfaces for that pod how do I map that how do I know that both of those those stacks are don't actually",
    "start": "3161239",
    "end": "3168650"
  },
  {
    "text": "have multiple interfaces so the thing that drawing is wrong the drawing is misleading no question okay there's no",
    "start": "3168650",
    "end": "3177109"
  },
  {
    "text": "question the drawing is misleading effectively what ends up happening is you have a context for the particular",
    "start": "3177109",
    "end": "3183849"
  },
  {
    "text": "namespace that lives within VPP which happens to correspond by the kernel namespace but doesn't have to okay here",
    "start": "3183849",
    "end": "3191839"
  },
  {
    "text": "are the collection of IPS that are associated to this namespace that the TCP stacks that are the host acts that",
    "start": "3191839",
    "end": "3198440"
  },
  {
    "text": "are talking here can talk to and by the way one of them is the local host which should be treated the way they way local",
    "start": "3198440",
    "end": "3203749"
  },
  {
    "text": "host is treated and which may say oh by the way this one over here is the proxy and reverse proxy because that's what on",
    "start": "3203749",
    "end": "3209900"
  },
  {
    "text": "boys doing right because all those things should have the say might be appearing as the same IP address outside",
    "start": "3209900",
    "end": "3215509"
  },
  {
    "text": "of the pod well the true the P appearing as the same IP address or set of IP addresses if one IP address because pods",
    "start": "3215509",
    "end": "3223700"
  },
  {
    "text": "have a saying or in in the case of pods you're 100% correct they have one external IP address but if you wanted to",
    "start": "3223700",
    "end": "3230839"
  },
  {
    "text": "do something like direct server return you could do that um okay we this is a",
    "start": "3230839",
    "end": "3239480"
  },
  {
    "text": "rathole we should probably you and I should probably have a conversation yeah I would be very much in favor of that",
    "start": "3239480",
    "end": "3245299"
  },
  {
    "text": "but basically my point is that yes you're one pod but there's the flexibility to do more than what IP per",
    "start": "3245299",
    "end": "3251480"
  },
  {
    "text": "pod there's the flexibility to do more if you want to do interesting things like direct server return yeah yeah okay",
    "start": "3251480",
    "end": "3257480"
  },
  {
    "text": "yeah and so then kubernetes integration there's some example cake communities",
    "start": "3257480",
    "end": "3262700"
  },
  {
    "text": "integration going on in the concieve EPP and area that's built out of the legato",
    "start": "3262700",
    "end": "3269299"
  },
  {
    "text": "framework which I think I had mentioned which is built on the go VPP library and",
    "start": "3269299",
    "end": "3274609"
  },
  {
    "text": "I'm demoing a mystic cube con but I want to be really really clear this is an open innovation regime there is no",
    "start": "3274609",
    "end": "3281779"
  },
  {
    "text": "reason that other providers can't integrate with the EPP that's partially why the NGO VPP library is separate from",
    "start": "3281779",
    "end": "3288950"
  },
  {
    "text": "the legato framework is separate from the con tu PP agent is if all you want to be able to do is use write a go agent",
    "start": "3288950",
    "end": "3295460"
  },
  {
    "text": "that talks to DP P or integrating DP P into your existing go agent you'd probably pick up the go VPP library if",
    "start": "3295460",
    "end": "3301160"
  },
  {
    "text": "you wanted to do something that has some other niceties because you're starting from scratch the legato framework may",
    "start": "3301160",
    "end": "3307999"
  },
  {
    "text": "prove to be useful to you okay a lot of thought went into the how do we make it",
    "start": "3307999",
    "end": "3314029"
  },
  {
    "text": "as easy as possible for everyone to play cool and then just as the teaser so ipv6",
    "start": "3314029",
    "end": "3324289"
  },
  {
    "text": "is a lot more than just addresses right everyone sort of winds up there because of more addresses but it also enables a",
    "start": "3324289",
    "end": "3330799"
  },
  {
    "text": "bunch of other things that could be done implementation wise to provide some of the existing API s that we have in",
    "start": "3330799",
    "end": "3337430"
  },
  {
    "text": "kubernetes you know for example being able to use em any casts for smart load",
    "start": "3337430",
    "end": "3342559"
  },
  {
    "text": "balancing where you can actively measure not only the network latency to who you're talking to but the responsiveness",
    "start": "3342559",
    "end": "3349009"
  },
  {
    "text": "of the client in order to make your selections for who you're actually load-balancing to you know the",
    "start": "3349009",
    "end": "3355009"
  },
  {
    "text": "instrumentation I mentioned with IO am already if you followed the segment",
    "start": "3355009",
    "end": "3360319"
  },
  {
    "text": "routing network programmability rfcs there's a lot of interesting things available there and of course moving",
    "start": "3360319",
    "end": "3365539"
  },
  {
    "text": "away from overlays and Nats to provide service for things like load balancing",
    "start": "3365539",
    "end": "3370819"
  },
  {
    "text": "for services and so forth all these are available implementation level options that don't necessarily require any",
    "start": "3370819",
    "end": "3377779"
  },
  {
    "text": "change in the contract which needs to remain simple to the actual consumers of",
    "start": "3377779",
    "end": "3383239"
  },
  {
    "text": "the kubernetes api and of course all of these are supported today at DDP at high",
    "start": "3383239",
    "end": "3388700"
  },
  {
    "text": "performance and scale so you have a bigger pallet to play with when making implementation decisions is I guess the",
    "start": "3388700",
    "end": "3395059"
  },
  {
    "text": "underlying point yeah and then you can sort of weigh your trade-offs and make",
    "start": "3395059",
    "end": "3400940"
  },
  {
    "text": "your calls and then finally the ubiquitous get involved slide yeah",
    "start": "3400940",
    "end": "3407960"
  },
  {
    "text": "I mean photos and open community we have literally days of tutorials if you want to code in it",
    "start": "3407960",
    "end": "3413089"
  },
  {
    "text": "we've got your binary packages you can install mailing lists IRC channels the",
    "start": "3413089",
    "end": "3419599"
  },
  {
    "text": "good news about the wiki is anything you could possibly want to know is in the wiki the bad news about the wiki is anything you could possibly want to know",
    "start": "3419599",
    "end": "3425089"
  },
  {
    "text": "is in the wiki yeah and are you gonna be sharing these slides um I'd be delighted",
    "start": "3425089",
    "end": "3432170"
  },
  {
    "text": "just to share these slides wherever makes sense to share these slides it's not clear to me where the",
    "start": "3432170",
    "end": "3437240"
  },
  {
    "text": "right place is for the network working group github I would assume can wearing weird and and",
    "start": "3437240",
    "end": "3447920"
  },
  {
    "text": "get having the network what group yeah you guys have a folder for presentations or something or just in just if there's",
    "start": "3447920",
    "end": "3455540"
  },
  {
    "text": "not I can create one but I think we've been putting them on the github networking work group site just linking them from there this video will be",
    "start": "3455540",
    "end": "3464930"
  },
  {
    "text": "uploaded a YouTube right we'll take",
    "start": "3464930",
    "end": "3470660"
  },
  {
    "text": "offline figuring out where the right place to land them is and you know and then you know I should probably have a",
    "start": "3470660",
    "end": "3477980"
  },
  {
    "text": "following up conversation with you Chris about many many things yeah in the in",
    "start": "3477980",
    "end": "3483589"
  },
  {
    "text": "the perfect world that would probably be next week but you know maybe if we don't get to it before then maybe we do that",
    "start": "3483589",
    "end": "3490220"
  },
  {
    "text": "in Austin if not before I assume you're gonna be at Austin or are you not I will",
    "start": "3490220",
    "end": "3497030"
  },
  {
    "text": "be in Austin I will definitely be in Austin so yeah let's try and figure out something if possible next week cool all",
    "start": "3497030",
    "end": "3505190"
  },
  {
    "text": "right awesome does anybody else have any other questions surprisingly we were exactly at time yeah I think the last five",
    "start": "3505190",
    "end": "3523430"
  },
  {
    "text": "slides were probably the immediate end",
    "start": "3523430",
    "end": "3528740"
  },
  {
    "text": "of it yeah my interest lies part of the yeah",
    "start": "3528740",
    "end": "3534050"
  },
  {
    "text": "you call them out and if you places but but I may have maybe more to this just some of the he was clear that",
    "start": "3534050",
    "end": "3541500"
  },
  {
    "text": "some of the compelling reasons why those that are running workloads within an orchestration system i kubernetes we've",
    "start": "3541500",
    "end": "3547380"
  },
  {
    "text": "come to use density and scale are really big ones yeah my friend didn't tell tell",
    "start": "3547380",
    "end": "3556170"
  },
  {
    "text": "me that they will shortly be giving sort of 200 plus cores about 10 pods per four",
    "start": "3556170",
    "end": "3574310"
  },
  {
    "text": "numbers and what you realize and we realize these with so you need something",
    "start": "3574310",
    "end": "3582869"
  },
  {
    "text": "from a networking point mutation support that well no we're not quite there yet we're rapidly moving now okay because in",
    "start": "3582869",
    "end": "3595410"
  },
  {
    "text": "the density arguments of pure capex argument if you can run the same you know if you could increase the number of",
    "start": "3595410",
    "end": "3601050"
  },
  {
    "text": "workloads you're in better shape [Music]",
    "start": "3601050",
    "end": "3608099"
  },
  {
    "text": "[Music] go ahead and actually all stick the link in the chat for that just because there",
    "start": "3619230",
    "end": "3644400"
  },
  {
    "text": "we go thank you and can i just create a",
    "start": "3644400",
    "end": "3668640"
  },
  {
    "text": "presentations folder github both or requests to you thanks",
    "start": "3668640",
    "end": "3673890"
  },
  {
    "text": "cool thank you okay",
    "start": "3673890",
    "end": "3678170"
  }
]
[
  {
    "text": "uh let's get started uh hi and greetings to everyone",
    "start": "320",
    "end": "5480"
  },
  {
    "text": "that attend to my session here in today's session I'm here going to",
    "start": "5480",
    "end": "10559"
  },
  {
    "text": "introduce the amazing toour called to serve models along with the",
    "start": "10559",
    "end": "17160"
  },
  {
    "text": "the associated operator I made for deploy a instance in kubernetes",
    "start": "17160",
    "end": "25880"
  },
  {
    "text": "classers and before we get started let's introduce where I'm from I'm from Dark Cloud we are primly",
    "start": "25880",
    "end": "34680"
  },
  {
    "text": "focusing on kubernetes and trying to coher with ai ai workloads GPU massive",
    "start": "34680",
    "end": "40879"
  },
  {
    "text": "training Etc and as background me f John a",
    "start": "40879",
    "end": "47719"
  },
  {
    "text": "software engineer from darkcloud is focusing on AI and",
    "start": "47719",
    "end": "53239"
  },
  {
    "text": "kubernetes but my stories don't stop the kues EOS system I'm also the contributor",
    "start": "53239",
    "end": "61359"
  },
  {
    "text": "to Goan VJs Lunen for go and JavaScript",
    "start": "61359",
    "end": "67159"
  },
  {
    "text": "many other communities as well and by the way this slide is written in View",
    "start": "67159",
    "end": "74680"
  },
  {
    "text": "and typ script and it will be open source that you can everyone can have",
    "start": "74680",
    "end": "80640"
  },
  {
    "text": "it and except that I'm also the co-founder of Nas uh obsidian",
    "start": "80640",
    "end": "88920"
  },
  {
    "text": "oriented deployment tool for making obsidian knowledge Bas into websites and",
    "start": "88920",
    "end": "94880"
  },
  {
    "text": "the GUI which is a tool for helping front end developers to",
    "start": "94880",
    "end": "101479"
  },
  {
    "text": "co-pilot with AI yeah I know it's kind of boring for",
    "start": "101479",
    "end": "108600"
  },
  {
    "text": "everyone to listen for already three days I'm going to throw a simple demo",
    "start": "108600",
    "end": "117079"
  },
  {
    "text": "for fun",
    "start": "117079",
    "end": "120799"
  },
  {
    "text": "and hopefully this can help everyone to get a better understanding of it I will",
    "start": "123399",
    "end": "129640"
  },
  {
    "text": "try to explain uh what we're doing here is to quickly deploy a model with Alma and",
    "start": "129640",
    "end": "138680"
  },
  {
    "text": "with the on the kind cre cluster it will be able to use the",
    "start": "138680",
    "end": "144640"
  },
  {
    "text": "official Al CRI to interactive interact with it",
    "start": "144640",
    "end": "150360"
  },
  {
    "text": "you see it's fast enough I ran it on my MacBook Pro so I",
    "start": "150360",
    "end": "157800"
  },
  {
    "text": "think it's very amazing for kubernetes",
    "start": "157800",
    "end": "162920"
  },
  {
    "text": "developers who usually will use kind cluster with the AL",
    "start": "162920",
    "end": "169080"
  },
  {
    "text": "operator well you can have coding cop code generation Etc yeah that's",
    "start": "169080",
    "end": "175800"
  },
  {
    "text": "basically the demo what what about this demo means that's the topic okay let's get to the",
    "start": "175800",
    "end": "184200"
  },
  {
    "text": "journey as the beginning of the role of infra team as well as developer I know",
    "start": "184200",
    "end": "191920"
  },
  {
    "text": "many of you may understand that deploying the large language models",
    "start": "191920",
    "end": "197760"
  },
  {
    "text": "involves complex steps and management that's the",
    "start": "197760",
    "end": "204159"
  },
  {
    "text": "challenges and probably some of you may seen this slide but I will go really",
    "start": "204159",
    "end": "209519"
  },
  {
    "text": "quick for building some fundamental context so in machine learning field model is",
    "start": "209519",
    "end": "217000"
  },
  {
    "text": "basically a St of Matrix with factors which is used to predict the input data",
    "start": "217000",
    "end": "225319"
  },
  {
    "text": "with and output the data based on the input and that's it but that's not the",
    "start": "225319",
    "end": "232959"
  },
  {
    "text": "whole picture when we do M we will get this visualization of every fundamental",
    "start": "232959",
    "end": "239920"
  },
  {
    "text": "building block of each model what do we do next we will feed",
    "start": "239920",
    "end": "246239"
  },
  {
    "text": "them into GPU and CPU for inference and computation yeah that's basically what",
    "start": "246239",
    "end": "253079"
  },
  {
    "text": "I'm saying then let's talk about how to deploy when we have the vectors we will",
    "start": "253079",
    "end": "260680"
  },
  {
    "text": "get a binary file when we distribute it there's so many steps okay first one is",
    "start": "260680",
    "end": "267560"
  },
  {
    "text": "training obviously or maybe perhaps you want to get some",
    "start": "267560",
    "end": "272759"
  },
  {
    "text": "Laura when you have the luras you'll need to patch them and merge the",
    "start": "272759",
    "end": "278479"
  },
  {
    "text": "weits for running performance or to make it running on Lower devices you will",
    "start": "278479",
    "end": "285160"
  },
  {
    "text": "need to quantize them sure that's the steps okay so how",
    "start": "285160",
    "end": "292680"
  },
  {
    "text": "can we M them to the containers or applications there's two ways in",
    "start": "292680",
    "end": "298759"
  },
  {
    "text": "practical first one is to M with volumes okay we we have a S3 storage and we will",
    "start": "298759",
    "end": "307000"
  },
  {
    "text": "put the model in the S3 and we will mount it into the volume the second one",
    "start": "307000",
    "end": "314160"
  },
  {
    "text": "is BND it with images but those are not",
    "start": "314160",
    "end": "319800"
  },
  {
    "text": "very good and that comes problems personally I think there's a",
    "start": "319800",
    "end": "326919"
  },
  {
    "text": "limit or boundaries when Distributing models if we're going to bundle all of",
    "start": "326919",
    "end": "333440"
  },
  {
    "text": "these things into the single image what will happen the image will be large and",
    "start": "333440",
    "end": "340960"
  },
  {
    "text": "if every node will need to pull the image in order to bootstrap the container then every node will initiate",
    "start": "340960",
    "end": "347639"
  },
  {
    "text": "a huge file transfer no matter what method you using",
    "start": "347639",
    "end": "353720"
  },
  {
    "text": "for mounting and bundling how we how can we effectively",
    "start": "353720",
    "end": "360039"
  },
  {
    "text": "have every node pull the images or the weights how many storage are needed for",
    "start": "360039",
    "end": "367120"
  },
  {
    "text": "where we assigning storage for control plane nodes we don't know what if a node",
    "start": "367120",
    "end": "373800"
  },
  {
    "text": "will have like 100 LMA 2 instances what will",
    "start": "373800",
    "end": "379560"
  },
  {
    "text": "happen for each one of LMA 2 model there will be 83 GB for 100 instances there",
    "start": "379560",
    "end": "388520"
  },
  {
    "text": "will be um I mean sorry let's say uh we have 100",
    "start": "388520",
    "end": "395800"
  },
  {
    "text": "different distribution or releases of Lama or F or whatever we have 100 of",
    "start": "395800",
    "end": "402960"
  },
  {
    "text": "them different L different configuration different patches then the node will",
    "start": "402960",
    "end": "408840"
  },
  {
    "text": "eventually need to pull every single 100 images download to the not local storage",
    "start": "408840",
    "end": "415599"
  },
  {
    "text": "that will be a problem and for sess scenarios how can",
    "start": "415599",
    "end": "420960"
  },
  {
    "text": "we handle the code boting or what will happen when",
    "start": "420960",
    "end": "426160"
  },
  {
    "text": "we publish at one model then someone will initiate a inference request really",
    "start": "426160",
    "end": "433800"
  },
  {
    "text": "quick that LE questions is that the end no not",
    "start": "433800",
    "end": "439599"
  },
  {
    "text": "absolutely serving is still waiting for us okay managing dependencies across",
    "start": "439599",
    "end": "445720"
  },
  {
    "text": "different environments can be tedious and arpr I bet many of you may have experienced",
    "start": "445720",
    "end": "453080"
  },
  {
    "text": "it already setting up a environment of python c k member is quite complex and",
    "start": "453080",
    "end": "461879"
  },
  {
    "text": "time consuming last one is to getting the model which I've shown you already is",
    "start": "461879",
    "end": "469960"
  },
  {
    "text": "there's still lot work to do that's the concepts let's get into",
    "start": "469960",
    "end": "477520"
  },
  {
    "text": "some real use cases there this is the Triton serving example which is popular",
    "start": "477520",
    "end": "484879"
  },
  {
    "text": "model 72 made by Nvidia how many steps would it made well on the slide it shows",
    "start": "484879",
    "end": "492800"
  },
  {
    "text": "with different method so perhaps you need to get clone the serving framework",
    "start": "492800",
    "end": "500319"
  },
  {
    "text": "or perhaps you need to pull the serving do image but that's still and remember",
    "start": "500319",
    "end": "508840"
  },
  {
    "text": "that's the only one portion of the whole process train distribute bundle serving",
    "start": "508840",
    "end": "517039"
  },
  {
    "text": "and inference this is only serving",
    "start": "517039",
    "end": "522360"
  },
  {
    "text": "part oh sorry let me go back okay what about the torch serve",
    "start": "522640",
    "end": "530680"
  },
  {
    "text": "that's a lot I know that's a framework like fundamental building block but",
    "start": "530680",
    "end": "537000"
  },
  {
    "text": "still there are so many steps that we need to automate and make it more",
    "start": "537000",
    "end": "544600"
  },
  {
    "text": "simple okay let me see okay I know some of the companies May build the their own",
    "start": "544600",
    "end": "552839"
  },
  {
    "text": "serving tools with P serve but what about the open source",
    "start": "552839",
    "end": "558279"
  },
  {
    "text": "Community not very much okay I'm here to introduce the",
    "start": "558279",
    "end": "565560"
  },
  {
    "text": "AMA one tool that simplifies the process",
    "start": "565560",
    "end": "570760"
  },
  {
    "text": "of transforming marging composing deploying and serving for large language",
    "start": "570760",
    "end": "577240"
  },
  {
    "text": "models it's light weighted enough to have single banner to shape with without",
    "start": "577240",
    "end": "584800"
  },
  {
    "text": "literally no dependencies no cond no PGE no extra lit. CPP setup it's Universal",
    "start": "584800",
    "end": "595000"
  },
  {
    "text": "works on pretty much every nor platforms so the boundary of Hardware or drivers",
    "start": "595000",
    "end": "602040"
  },
  {
    "text": "are no longer problem this is how you can customize",
    "start": "602040",
    "end": "608240"
  },
  {
    "text": "the model with alignment you can add multiple layers of Laur you can",
    "start": "608240",
    "end": "613839"
  },
  {
    "text": "pre-configure the parameters and even doing some prompt",
    "start": "613839",
    "end": "619760"
  },
  {
    "text": "engineering as you see the structure of this file and the syntax is the same as",
    "start": "619760",
    "end": "626680"
  },
  {
    "text": "Docker file and yes the way to build and bundle the image of the model is the",
    "start": "626680",
    "end": "634519"
  },
  {
    "text": "same as darker while it's still compatible with",
    "start": "634519",
    "end": "639560"
  },
  {
    "text": "oci standards if it's con if it's compatible to oci standards",
    "start": "639560",
    "end": "647240"
  },
  {
    "text": "can we reuse the hover or registry the answer is yes just like",
    "start": "647240",
    "end": "654839"
  },
  {
    "text": "darker can push and pull the models to the registry if you have haror then",
    "start": "654839",
    "end": "660839"
  },
  {
    "text": "that's all you need push and pull that's your distribution your work is",
    "start": "660839",
    "end": "667560"
  },
  {
    "text": "done what about serving the is it the same as",
    "start": "667560",
    "end": "672959"
  },
  {
    "text": "Docker hard to dis screen hard to distinguish a single run command made it",
    "start": "672959",
    "end": "679440"
  },
  {
    "text": "easy to serve across all platforms environments include iot rasir pie",
    "start": "679440",
    "end": "686720"
  },
  {
    "text": "everything I know it sounds like I'm a team of and",
    "start": "686720",
    "end": "694720"
  },
  {
    "text": "promoting AMA to everyone of you but I'm sorry I'm not let me introduce another",
    "start": "694720",
    "end": "701079"
  },
  {
    "text": "thing what have we done it's operator this is our one",
    "start": "701079",
    "end": "708480"
  },
  {
    "text": "simple install to go plugin to bring AMA to kuties",
    "start": "708480",
    "end": "716040"
  },
  {
    "text": "clusters and just forgot about about the downsides of Alama and challenges let's",
    "start": "716560",
    "end": "722639"
  },
  {
    "text": "talk about the Alama operators feature we got model caching model preloading",
    "start": "722639",
    "end": "729000"
  },
  {
    "text": "scaleway replicas apply correct resource limits and Achieve operator",
    "start": "729000",
    "end": "736199"
  },
  {
    "text": "automation why I know Alma currently or recently supported the model poing and",
    "start": "736199",
    "end": "744079"
  },
  {
    "text": "caching even a little bit thin layer to achieve load",
    "start": "744079",
    "end": "749880"
  },
  {
    "text": "balancing but actually back in the days when I was implement this operator",
    "start": "749880",
    "end": "756639"
  },
  {
    "text": "they're not supported okay for the other problems for General Alama servers",
    "start": "756639",
    "end": "764399"
  },
  {
    "text": "there's no way to set resource limit means if you started a new Al instance",
    "start": "764399",
    "end": "770680"
  },
  {
    "text": "it will eat up your a believable memories gpus CPUs anything which make",
    "start": "770680",
    "end": "777160"
  },
  {
    "text": "it too hard to control and what if you want to create a model mesh for the models it's possible it's",
    "start": "777160",
    "end": "785279"
  },
  {
    "text": "not possible for single Lon but we here brought the power of deployments and",
    "start": "785279",
    "end": "792199"
  },
  {
    "text": "replica to help scale the models make it to replicate so everyone can every user",
    "start": "792199",
    "end": "800120"
  },
  {
    "text": "they can have their own Alma instance which means all different",
    "start": "800120",
    "end": "806440"
  },
  {
    "text": "models can run simultaneously besides all of that I made it kuet which",
    "start": "806440",
    "end": "814399"
  },
  {
    "text": "means the Alama operator works with any kubernetes certified clusters kind Cas",
    "start": "814399",
    "end": "821959"
  },
  {
    "text": "mini Cube everything is the same it's Cloud agnostic okay Deploy on",
    "start": "821959",
    "end": "830079"
  },
  {
    "text": "any cloud provider or on premises I have it in my home lab which I will have",
    "start": "830079",
    "end": "836839"
  },
  {
    "text": "three instances of models it's iot friendly and Deploy on any CR",
    "start": "836839",
    "end": "845240"
  },
  {
    "text": "provider or I mean okay sure the rasir P",
    "start": "845240",
    "end": "850399"
  },
  {
    "text": "I have tested on rasir Pi 4B it's",
    "start": "850399",
    "end": "856199"
  },
  {
    "text": "working loots of the other operators or controllers often requires additional",
    "start": "856279",
    "end": "863360"
  },
  {
    "text": "plugins or SDS to be installed before running but Al operator is not I made it",
    "start": "863360",
    "end": "870759"
  },
  {
    "text": "as simple as possible so no additional plugins no additional CS one command",
    "start": "870759",
    "end": "877880"
  },
  {
    "text": "install then you go it's too you easy to use install the",
    "start": "877880",
    "end": "883839"
  },
  {
    "text": "operator controller with single one command that's it and you can create the",
    "start": "883839",
    "end": "890880"
  },
  {
    "text": "model S well then connect",
    "start": "890880",
    "end": "896959"
  },
  {
    "text": "it or perhaps perhaps you dislike the taste of kubernetes yo manifest I made a",
    "start": "897320",
    "end": "905399"
  },
  {
    "text": "SI called col to help you deploy it's also a KU Cube control",
    "start": "905399",
    "end": "913560"
  },
  {
    "text": "plug-in tool so you can use it as a cube control sub command too yes that's as much as easy you would",
    "start": "913560",
    "end": "922519"
  },
  {
    "text": "see for scaling it's easy too just like any replica set or or deployment you",
    "start": "922519",
    "end": "930720"
  },
  {
    "text": "modify the replica field make it to 10 five on the slide it's",
    "start": "930720",
    "end": "937199"
  },
  {
    "text": "five then it will",
    "start": "937199",
    "end": "940959"
  },
  {
    "text": "scale that's the features but let's talk about the overall architecture or the",
    "start": "943720",
    "end": "951519"
  },
  {
    "text": "primary challenge I faced when I'm making theama",
    "start": "951519",
    "end": "956959"
  },
  {
    "text": "operator here's the correspond in component it will interact with the",
    "start": "956959",
    "end": "962920"
  },
  {
    "text": "major parts are the let me use cursor to point out can can everyone see",
    "start": "962920",
    "end": "970639"
  },
  {
    "text": "it okay this is the model pool and those",
    "start": "970639",
    "end": "976079"
  },
  {
    "text": "are inference server where done this bottom one it",
    "start": "976079",
    "end": "982759"
  },
  {
    "text": "it's a shared PVC why because when I said previously",
    "start": "982759",
    "end": "990000"
  },
  {
    "text": "when when we need to distribute the models we will need to have each note to",
    "start": "990000",
    "end": "995319"
  },
  {
    "text": "P their model or images separately instead of that in Lama operator I",
    "start": "995319",
    "end": "1004480"
  },
  {
    "text": "created the shared PVC and the model Pro to share the models to each of the",
    "start": "1004480",
    "end": "1010639"
  },
  {
    "text": "inference server so once is once a mode once a model is preloaded or",
    "start": "1010639",
    "end": "1017079"
  },
  {
    "text": "downloaded it's cached next time you create another instance of it again or",
    "start": "1017079",
    "end": "1024839"
  },
  {
    "text": "scale it it will no longer to download additional models or",
    "start": "1024839",
    "end": "1031678"
  },
  {
    "text": "files okay let's break it down for inference server you may wondering how",
    "start": "1032919",
    "end": "1039000"
  },
  {
    "text": "does the model Pro work for to cat for the inference server sure I will explain",
    "start": "1039000",
    "end": "1045199"
  },
  {
    "text": "it for Alma server each time we call for the pull a oi image will be pulled from",
    "start": "1045199",
    "end": "1053960"
  },
  {
    "text": "the registry and the server will save it",
    "start": "1053960",
    "end": "1059200"
  },
  {
    "text": "without any modification okay notice it without any",
    "start": "1059200",
    "end": "1064760"
  },
  {
    "text": "modification that means it's unpacked it's still in oi image it's not",
    "start": "1064760",
    "end": "1070280"
  },
  {
    "text": "preloaded not configured once a new request perform",
    "start": "1070280",
    "end": "1077640"
  },
  {
    "text": "from chat comp completions com in the alma server will check if the model in",
    "start": "1077640",
    "end": "1083559"
  },
  {
    "text": "the cache or the presence if not it will appr it again if it is exists then it",
    "start": "1083559",
    "end": "1093440"
  },
  {
    "text": "will unpack it and preload it into memories or if it's unpacked or loaded",
    "start": "1093440",
    "end": "1101240"
  },
  {
    "text": "already it will load into memories with and map with a spap mechanism",
    "start": "1101240",
    "end": "1110200"
  },
  {
    "text": "with that okay sorry that's the end of the slide let me see the last one is to",
    "start": "1110799",
    "end": "1117480"
  },
  {
    "text": "bootstrap the Lama CPP server to serve the models and or in other words the models",
    "start": "1117480",
    "end": "1126200"
  },
  {
    "text": "will be checked for existence before inference to deal with",
    "start": "1126200",
    "end": "1133039"
  },
  {
    "text": "that we have the model pole and if you listen to now you may",
    "start": "1133039",
    "end": "1139919"
  },
  {
    "text": "wondering are the users of Al are non kubernetes users yes that's a great",
    "start": "1139919",
    "end": "1148200"
  },
  {
    "text": "question the concept of the or the initial idea of AMA",
    "start": "1148200",
    "end": "1154640"
  },
  {
    "text": "operator is because I want to bring Al to kubernetes not to enforce every Alama",
    "start": "1154640",
    "end": "1163440"
  },
  {
    "text": "users to use kubernetes because I saw the similarity between model file and",
    "start": "1163440",
    "end": "1171240"
  },
  {
    "text": "Docker file I think the transition of cloud native is the same if we can have",
    "start": "1171240",
    "end": "1179280"
  },
  {
    "text": "Docker Docker file to transform for the traditional applications what about the",
    "start": "1179280",
    "end": "1187200"
  },
  {
    "text": "now day or future traditional models can we make them all darker or containered",
    "start": "1187200",
    "end": "1195760"
  },
  {
    "text": "yeah that's the concept",
    "start": "1195760",
    "end": "1199720"
  },
  {
    "text": "there still pretty much work needs to be done for example I made a little pretty",
    "start": "1201240",
    "end": "1208000"
  },
  {
    "text": "documentation side for it but it's still missing some parts like for example the",
    "start": "1208000",
    "end": "1213960"
  },
  {
    "text": "use cases the model list they are not incomplete and some of the Automation",
    "start": "1213960",
    "end": "1222559"
  },
  {
    "text": "and more far beyond the automation they are all missing",
    "start": "1222559",
    "end": "1229919"
  },
  {
    "text": "it's open source already six months I appreciate everyone that would like to",
    "start": "1229960",
    "end": "1237600"
  },
  {
    "text": "contribute it you can scan the QR codes for documentation site or the",
    "start": "1237600",
    "end": "1244600"
  },
  {
    "text": "repository this project has been exist for like let me calculate four months",
    "start": "1244600",
    "end": "1252440"
  },
  {
    "text": "and it runs really well in my home lab in my company everyone is using it",
    "start": "1252440",
    "end": "1260960"
  },
  {
    "text": "to H how can I say integrate with K GPT to analyze some of the cluster",
    "start": "1260960",
    "end": "1269919"
  },
  {
    "text": "issues I can't make it without any support of the communities but I want to",
    "start": "1270520",
    "end": "1276799"
  },
  {
    "text": "shout out to the community for the following improvements and I want to",
    "start": "1276799",
    "end": "1282760"
  },
  {
    "text": "discuss to everyone here and on or online or the future coming to the",
    "start": "1282760",
    "end": "1291279"
  },
  {
    "text": "following items the first one is to how about let's keep development and",
    "start": "1291279",
    "end": "1298120"
  },
  {
    "text": "improve the newcoming ocii volume standards or how about we can have the",
    "start": "1298120",
    "end": "1305720"
  },
  {
    "text": "container D or darker to fit in theama oi image content type so we can use",
    "start": "1305720",
    "end": "1313640"
  },
  {
    "text": "dragonfly to cat them to distribute the images more than more faster than my",
    "start": "1313640",
    "end": "1321320"
  },
  {
    "text": "motor Pro is or how about better pulling can we improve it or how can we",
    "start": "1321320",
    "end": "1329799"
  },
  {
    "text": "use dragonfly to better distribute the so large models like L 3",
    "start": "1329799",
    "end": "1337000"
  },
  {
    "text": "405b is like 800 of gigb just too large",
    "start": "1337000",
    "end": "1342760"
  },
  {
    "text": "yeah or perhaps we can add some some of the load balance Ing and routing",
    "start": "1342760",
    "end": "1350279"
  },
  {
    "text": "capabilities to improve how the que or response or request is processed because",
    "start": "1350279",
    "end": "1358679"
  },
  {
    "text": "the current implementation of AMA they have a little tiny thing load balancing",
    "start": "1358679",
    "end": "1366640"
  },
  {
    "text": "area where I can imagine for some of the open source or other companies they're",
    "start": "1366640",
    "end": "1373360"
  },
  {
    "text": "trying to group the different models into different sizes",
    "start": "1373360",
    "end": "1378720"
  },
  {
    "text": "and use generic or intelligence capabilities to Route",
    "start": "1378720",
    "end": "1384840"
  },
  {
    "text": "different prompts to different models that would be",
    "start": "1384840",
    "end": "1391240"
  },
  {
    "text": "better with all of that that's the end of today's session I bet many of you may",
    "start": "1392200",
    "end": "1398720"
  },
  {
    "text": "asking how to make this slide I open source it and it was it was built on top",
    "start": "1398720",
    "end": "1406080"
  },
  {
    "text": "of the codes we could ask you to give me some Su off on the feedback",
    "start": "1406080",
    "end": "1412880"
  },
  {
    "text": "of the C control no I mean the cubec events and that's it any",
    "start": "1412880",
    "end": "1421320"
  },
  {
    "text": "[Applause]",
    "start": "1424780",
    "end": "1430299"
  },
  {
    "text": "questions okay",
    "start": "1437080",
    "end": "1440440"
  },
  {
    "text": "okay use to deploy to deploy uh ml models to the edge and how would you",
    "start": "1449799",
    "end": "1455960"
  },
  {
    "text": "compare that to some of the other tools that that that they've been showcasing here at you mean the was mat yes oh okay",
    "start": "1455960",
    "end": "1465120"
  },
  {
    "text": "there comes some downsides m currently AMA is depending on Lama CPP which is",
    "start": "1465120",
    "end": "1473200"
  },
  {
    "text": "kind of slow to preload the models which will result in the adal to have longer",
    "start": "1473200",
    "end": "1481039"
  },
  {
    "text": "code booting time cost and I believe for current or now",
    "start": "1481039",
    "end": "1488799"
  },
  {
    "text": "it's not possible to have Ama to handle the request faster than wasam match or",
    "start": "1488799",
    "end": "1496559"
  },
  {
    "text": "their ganet I think that's the problem but I know I have experienced some like",
    "start": "1496559",
    "end": "1505080"
  },
  {
    "text": "vrm they have better capability to provide better throughput or better",
    "start": "1505080",
    "end": "1512039"
  },
  {
    "text": "performance perhaps we can how can I say the idea of AMA",
    "start": "1512039",
    "end": "1519159"
  },
  {
    "text": "operator here is I want to bring the concepts of model file and the workflow",
    "start": "1519159",
    "end": "1525679"
  },
  {
    "text": "it includes to kubernetes system and I believe we can enforce or",
    "start": "1525679",
    "end": "1535360"
  },
  {
    "text": "encourage kubernetes ecosystem to build a better Al or cooperate them with them",
    "start": "1535360",
    "end": "1543720"
  },
  {
    "text": "to integrate with vrm or wassom Edge to provid better Edge",
    "start": "1543720",
    "end": "1551279"
  },
  {
    "text": "capabilities was my answer clear yeah that was very clear than okay",
    "start": "1551279",
    "end": "1558080"
  },
  {
    "text": "any [Music]",
    "start": "1563880",
    "end": "1567770"
  },
  {
    "text": "other sh PVC",
    "start": "1586360",
    "end": "1590240"
  },
  {
    "text": "okay okay",
    "start": "1613480",
    "end": "1616760"
  },
  {
    "text": "session",
    "start": "1647159",
    "end": "1650159"
  },
  {
    "text": "for operator",
    "start": "1673360",
    "end": "1677360"
  },
  {
    "text": "okay thank",
    "start": "1694000",
    "end": "1697200"
  },
  {
    "text": "you fore",
    "start": "1707120",
    "end": "1711120"
  },
  {
    "text": "[Music]",
    "start": "1713790",
    "end": "1716869"
  },
  {
    "text": "[Music]",
    "start": "1721110",
    "end": "1724190"
  },
  {
    "text": "s",
    "start": "1742440",
    "end": "1745440"
  },
  {
    "text": "then",
    "start": "1797799",
    "end": "1800039"
  },
  {
    "text": "for for",
    "start": "1826960",
    "end": "1830960"
  },
  {
    "text": "w",
    "start": "1883480",
    "end": "1886480"
  },
  {
    "text": "hi hi um I was wondering if you use the theam operator in production and uh if",
    "start": "1889960",
    "end": "1897320"
  },
  {
    "text": "you have maybe a timeline for when it will be ready for production uh we're not pushing it or",
    "start": "1897320",
    "end": "1905000"
  },
  {
    "text": "releasing it to production but I personally use it a lot and my company",
    "start": "1905000",
    "end": "1912080"
  },
  {
    "text": "for development timeline we will use it with k",
    "start": "1912080",
    "end": "1918480"
  },
  {
    "text": "K kubernetes GPT to analyze the issues",
    "start": "1918480",
    "end": "1923519"
  },
  {
    "text": "in cluster so I can't say we're still in a testing",
    "start": "1923519",
    "end": "1930519"
  },
  {
    "text": "area and I believe the reason I didn't push it to the production is because I",
    "start": "1930519",
    "end": "1938639"
  },
  {
    "text": "think Alma is kind of a transition state of our Cloud native AI workloads I don't",
    "start": "1938639",
    "end": "1946840"
  },
  {
    "text": "see it as the final state so it's more like an experiment and I",
    "start": "1946840",
    "end": "1953440"
  },
  {
    "text": "want to bring the concept of model file and encourage the oci volume KP to go",
    "start": "1953440",
    "end": "1962600"
  },
  {
    "text": "even further Beyond to build a better model distribution serving Etc yeah",
    "start": "1962600",
    "end": "1971039"
  },
  {
    "text": "that's it so um Maya ask you whether it",
    "start": "1971039",
    "end": "1977080"
  },
  {
    "text": "have you tried to use Alma or have you experienced any difficulties that I can",
    "start": "1977080",
    "end": "1984320"
  },
  {
    "text": "maybe try to understand and plot a timeline to release it yeah no I'm uh",
    "start": "1984320",
    "end": "1990960"
  },
  {
    "text": "I'm not a model um a machine learning engineer I'm a platform engineer um so",
    "start": "1990960",
    "end": "1997440"
  },
  {
    "text": "we're working with like a different run times and we allow to um for users to",
    "start": "1997440",
    "end": "2002679"
  },
  {
    "text": "deploy their own models on a kubernetes cluster so I I was wondering if this would be like uh um an option for users",
    "start": "2002679",
    "end": "2010720"
  },
  {
    "text": "to uh write anama function and like deploy it to a cluster and it could",
    "start": "2010720",
    "end": "2017000"
  },
  {
    "text": "automate things for them in in production I believe that will be",
    "start": "2017000",
    "end": "2022720"
  },
  {
    "text": "awesome yeah thank",
    "start": "2022720",
    "end": "2027200"
  },
  {
    "text": "you uh anyone is raising their hands",
    "start": "2028559",
    "end": "2034518"
  },
  {
    "text": "okay how about that's the end of the session and hopefully everyone can have",
    "start": "2038559",
    "end": "2045240"
  },
  {
    "text": "your tripping Hong Kong well yeah thank you for coming",
    "start": "2045240",
    "end": "2052760"
  }
]
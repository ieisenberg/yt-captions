[
  {
    "text": "all right let's get started and um my name is toi I'm a software in software",
    "start": "320",
    "end": "6720"
  },
  {
    "text": "engineer in Google I need teams to improve the start of latency for machine learning workloads I also need team to",
    "start": "6720",
    "end": "13519"
  },
  {
    "text": "provide the GPU round time in gke and today we're going to talk about the reducing AI job code start time from 15",
    "start": "13519",
    "end": "21840"
  },
  {
    "text": "minutes to 1 minute and first we'll talk about the code start problem the definition is",
    "start": "21840",
    "end": "28800"
  },
  {
    "text": "here a code start is when you SC schedule a port and to a node and when",
    "start": "28800",
    "end": "35320"
  },
  {
    "text": "the node doesn't have that container image during this process the",
    "start": "35320",
    "end": "40399"
  },
  {
    "text": "container will the container on time will prove and will pull the image from",
    "start": "40399",
    "end": "45920"
  },
  {
    "text": "a remote container registry and download and pack that uh container image to the",
    "start": "45920",
    "end": "52120"
  },
  {
    "text": "local disk which will consume some CPU and networking and",
    "start": "52120",
    "end": "57920"
  },
  {
    "text": "storage which also take time to finish and this graph is a high level",
    "start": "57920",
    "end": "67280"
  },
  {
    "text": "like when you schedu port and each step it requires some resource for example in",
    "start": "67280",
    "end": "74040"
  },
  {
    "text": "the infra side you may need a no pool in jke you may need a instance group in ads",
    "start": "74040",
    "end": "81320"
  },
  {
    "text": "and when you don't have enough node for the same machine type it will check like",
    "start": "81320",
    "end": "86520"
  },
  {
    "text": "Auto scaling and to get enough like CP U GPU or memory and when it comes to the",
    "start": "86520",
    "end": "94439"
  },
  {
    "text": "container run time the workload part and if the content image does not",
    "start": "94439",
    "end": "102360"
  },
  {
    "text": "exist there it will trigger the image pool and it will pull the image to the local and pack it and then the container",
    "start": "102360",
    "end": "109840"
  },
  {
    "text": "can start from that container image and in the end you need the AI model to",
    "start": "109840",
    "end": "116320"
  },
  {
    "text": "present and to start the machine learning workout in this talk we will focus on",
    "start": "116320",
    "end": "123640"
  },
  {
    "text": "the container image pool because that is a most time consuming part and when you",
    "start": "123640",
    "end": "131080"
  },
  {
    "text": "have like 30 gigabyte container image the image pool can take up to 15 minutes",
    "start": "131080",
    "end": "137000"
  },
  {
    "text": "and it's a super long time to start a application and the problem get uh get",
    "start": "137000",
    "end": "143920"
  },
  {
    "text": "even worse when you running a training job because if you hit some error you",
    "start": "143920",
    "end": "150120"
  },
  {
    "text": "need to do error recovery from the N check point at that point you also need to schedule a group of ports onto a new",
    "start": "150120",
    "end": "159560"
  },
  {
    "text": "nodes and then it will delay further due to the code start",
    "start": "159560",
    "end": "167079"
  },
  {
    "text": "latency first we'll uh go to a deep dive into why the image pool is so snow for",
    "start": "167200",
    "end": "174560"
  },
  {
    "text": "AI workloads because AI container image are very large they uh username for lar",
    "start": "174560",
    "end": "182560"
  },
  {
    "text": "uh larger than 4 gab and why are those AI container image",
    "start": "182560",
    "end": "188360"
  },
  {
    "text": "so large because those base layers are very large and why are those base layers",
    "start": "188360",
    "end": "193440"
  },
  {
    "text": "are so large because AI Mach in GPU libraries inside those layers they are",
    "start": "193440",
    "end": "199080"
  },
  {
    "text": "very large and then comes the next question why not placing the libraries onto the",
    "start": "199080",
    "end": "205440"
  },
  {
    "text": "host and put it as part of the disk image it is because the application or",
    "start": "205440",
    "end": "212239"
  },
  {
    "text": "the framework they have version dependency on the library so each kind",
    "start": "212239",
    "end": "218519"
  },
  {
    "text": "of like tensor flow or py they have a specific uh version dependency on the",
    "start": "218519",
    "end": "223720"
  },
  {
    "text": "Cuda and container container actually solves this problem the dependency Problem by putting all the LI into the",
    "start": "223720",
    "end": "230760"
  },
  {
    "text": "container and you can run two different ports side by side on the same node and",
    "start": "230760",
    "end": "237920"
  },
  {
    "text": "using different libraries and the next question is can user reduce the size of",
    "start": "237920",
    "end": "244400"
  },
  {
    "text": "liaries actually no because",
    "start": "244400",
    "end": "249840"
  },
  {
    "text": "user like all not all of those libraries are open sourced and building them may",
    "start": "249840",
    "end": "255480"
  },
  {
    "text": "not customizable for the size and those libraries are required because they are",
    "start": "255480",
    "end": "263160"
  },
  {
    "text": "hard dependency for using gpus and if we if you take a look on the",
    "start": "263160",
    "end": "268720"
  },
  {
    "text": "right side and this is a node inside of the node there's a port inside the port is's a",
    "start": "268720",
    "end": "275919"
  },
  {
    "text": "container and inside the container that multiple layers and from our",
    "start": "275919",
    "end": "281960"
  },
  {
    "text": "investigation like the CN or C libraries in those layers are extremely large like",
    "start": "281960",
    "end": "288680"
  },
  {
    "text": "each of them is 4 gab but the TP driver that on the host they're relatively very",
    "start": "288680",
    "end": "296080"
  },
  {
    "text": "small it's only 22 megabyte or the driver color module is 51 megabyte this",
    "start": "296080",
    "end": "304400"
  },
  {
    "text": "is even before with open source the module now it's even",
    "start": "304400",
    "end": "310120"
  },
  {
    "text": "smaller but the N is there very large so we did uh investigation to look",
    "start": "310120",
    "end": "318520"
  },
  {
    "text": "like uh investigate does it apply to all the containers we are using this uh tool",
    "start": "318520",
    "end": "326560"
  },
  {
    "text": "called Dive it's a great tool you can see each layers and what's the files in",
    "start": "326560",
    "end": "331880"
  },
  {
    "text": "each layers what the size of them and all the preu machine leing",
    "start": "331880",
    "end": "338120"
  },
  {
    "text": "containers from different providers that sharing the same pattern the Q down",
    "start": "338120",
    "end": "343639"
  },
  {
    "text": "layers or C or py toch they're all very large than applications without",
    "start": "343639",
    "end": "353560"
  },
  {
    "text": "GPU so that's a problem and here's a requirements for our",
    "start": "353560",
    "end": "361680"
  },
  {
    "text": "Solutions the requirements need us to provide solutions for uh with speed scalability",
    "start": "361680",
    "end": "369759"
  },
  {
    "text": "and cost efficiency uh for the speed we need to utilize higher suut provided by the disk",
    "start": "369759",
    "end": "377840"
  },
  {
    "text": "or the networking for the scalability we want a solution to apply we want a",
    "start": "377840",
    "end": "384560"
  },
  {
    "text": "solution applies to larger container image and IDE",
    "start": "384560",
    "end": "390120"
  },
  {
    "text": "even when the container size increase the image pool can be skipped or the",
    "start": "390120",
    "end": "396520"
  },
  {
    "text": "image pool type can be constant and moving on to the third",
    "start": "396520",
    "end": "402240"
  },
  {
    "text": "one it quite it is quite possible all the nodes in the cluster put in the same",
    "start": "402240",
    "end": "408199"
  },
  {
    "text": "image at the same time it will use up the erass networking limit for the",
    "start": "408199",
    "end": "416720"
  },
  {
    "text": "container registry so we want that solution or also can solve this problem and in the end it's cost efficiency and",
    "start": "416720",
    "end": "425599"
  },
  {
    "text": "no actra cost in building because like technically you can solve",
    "start": "425599",
    "end": "431919"
  },
  {
    "text": "all the problem by preparing all the nodes all it up and download everything",
    "start": "431919",
    "end": "437160"
  },
  {
    "text": "you need it and put it in standby and all the all the problems solved by using",
    "start": "437160",
    "end": "444039"
  },
  {
    "text": "extra badget but that that is not practical you you still want to save uh",
    "start": "444039",
    "end": "449080"
  },
  {
    "text": "sa morning in still uh in the training",
    "start": "449080",
    "end": "454560"
  },
  {
    "text": "workloads and here is the design space giving the background of not container",
    "start": "455039",
    "end": "460879"
  },
  {
    "text": "image LGE number of LGE number Lo uh large number of nodes in the cluster and",
    "start": "460879",
    "end": "466560"
  },
  {
    "text": "to avoid repeatly image pull or reduce the image pool latency on each note the",
    "start": "466560",
    "end": "473000"
  },
  {
    "text": "design space there are two category the first one is classwide solution it's",
    "start": "473000",
    "end": "478919"
  },
  {
    "text": "quite forward you want you want to put those images create a mirror create a P2P algorithm inside the cluster much",
    "start": "478919",
    "end": "486800"
  },
  {
    "text": "closer to the nodes and then the when the nodes do image pool it's",
    "start": "486800",
    "end": "492400"
  },
  {
    "text": "faster and but our talk uh our focus of this talk is focusing on the Perlo",
    "start": "492400",
    "end": "498800"
  },
  {
    "text": "solution inside the container wrong time because when you when you take a look on",
    "start": "498800",
    "end": "505240"
  },
  {
    "text": "the container idea all the containers are downloaded",
    "start": "505240",
    "end": "510360"
  },
  {
    "text": "to each node repeatedly and you want to like the first impression is why do I need to",
    "start": "510360",
    "end": "516719"
  },
  {
    "text": "repeat that again and again and so that's why we take a look inside",
    "start": "516719",
    "end": "522440"
  },
  {
    "text": "the container WR time especially inside the container D and here comes our Solutions the first",
    "start": "522440",
    "end": "530560"
  },
  {
    "text": "solution is preloading container images through additional",
    "start": "530560",
    "end": "536839"
  },
  {
    "text": "dis and the goal is to skip the competently skip the container image",
    "start": "536920",
    "end": "542560"
  },
  {
    "text": "pool and get faster code start there are three steps of it first you build the",
    "start": "542560",
    "end": "550200"
  },
  {
    "text": "dis image with all the prate containers inside it and step two you create the",
    "start": "550200",
    "end": "557360"
  },
  {
    "text": "load pool or instance group from this dis image and when the all the nodes",
    "start": "557360",
    "end": "563880"
  },
  {
    "text": "created it coming when container container is pre-loaded step three",
    "start": "563880",
    "end": "569640"
  },
  {
    "text": "is when you schedule Port as usual like you don't need to change anything it",
    "start": "569640",
    "end": "574880"
  },
  {
    "text": "will automatically skipe the container image pool and you will get the faster",
    "start": "574880",
    "end": "580120"
  },
  {
    "text": "code start and I will take a closer look into",
    "start": "580120",
    "end": "586120"
  },
  {
    "text": "each step step one it is downloading and unpacking containers and create a dis",
    "start": "586120",
    "end": "594399"
  },
  {
    "text": "image so because if you don't do this this step will be done",
    "start": "594399",
    "end": "599959"
  },
  {
    "text": "at each node like it's the same process on each node without any difference so",
    "start": "599959",
    "end": "606680"
  },
  {
    "text": "that's why we do this ahead of time and prepare it for all the nodes do it only",
    "start": "606680",
    "end": "613720"
  },
  {
    "text": "once step two you when you create the noes you",
    "start": "613720",
    "end": "618920"
  },
  {
    "text": "input the dis image and as you can see this node is",
    "start": "618920",
    "end": "624200"
  },
  {
    "text": "coming with additional disk this dis is coming with preloaded",
    "start": "624200",
    "end": "630399"
  },
  {
    "text": "containers and out of a box those containers are ready to be",
    "start": "630399",
    "end": "635600"
  },
  {
    "text": "used at Step St we modify the container d by plugging a",
    "start": "635600",
    "end": "642519"
  },
  {
    "text": "snapshot so this snapshot is able to read both dis one is from the bo dis it",
    "start": "642519",
    "end": "650399"
  },
  {
    "text": "it is there before and another is the dis when P containers this is our",
    "start": "650399",
    "end": "657040"
  },
  {
    "text": "solution and when this approach a container long time is able to read both",
    "start": "657040",
    "end": "662839"
  },
  {
    "text": "multiple dis and reading the container cache from it and save the like latency",
    "start": "662839",
    "end": "670560"
  },
  {
    "text": "for start of time and another highlight here is",
    "start": "670560",
    "end": "676320"
  },
  {
    "text": "container D will reduce cach by layers so if containers they shared in the same",
    "start": "676320",
    "end": "683880"
  },
  {
    "text": "basees it can benefit the port sub lency for those containers",
    "start": "683880",
    "end": "689880"
  },
  {
    "text": "and you can just put a base containers like the library container or the freal",
    "start": "689880",
    "end": "696560"
  },
  {
    "text": "container onto this additional days it will benefit all the applications using",
    "start": "696560",
    "end": "702360"
  },
  {
    "text": "the shared uh libraries if you don't change those Bas",
    "start": "702360",
    "end": "707399"
  },
  {
    "text": "layers so you make minor changes on the application for example changing some",
    "start": "707399",
    "end": "712800"
  },
  {
    "text": "parameter changing some uh Mega parameter and you can still benefit from this approach",
    "start": "712800",
    "end": "720720"
  },
  {
    "text": "and about the results the predicted results the r ey is what it was before",
    "start": "720720",
    "end": "729399"
  },
  {
    "text": "the blue n it is this solution the comparison is the latency",
    "start": "729399",
    "end": "735399"
  },
  {
    "text": "for image pull to the port",
    "start": "735399",
    "end": "741680"
  },
  {
    "text": "ready and as you can see our solution is more scalable when the container",
    "start": "741680",
    "end": "747760"
  },
  {
    "text": "container image size like even when you have larger image",
    "start": "747760",
    "end": "753519"
  },
  {
    "text": "size it is still a constant time to get the P",
    "start": "753519",
    "end": "761480"
  },
  {
    "text": "ready the the inside the key inside behind is when you create the disk from",
    "start": "761480",
    "end": "767639"
  },
  {
    "text": "the disk image it is actually reusing the same data blocks underneath it's a",
    "start": "767639",
    "end": "773800"
  },
  {
    "text": "distributed storage and it does not require data copy",
    "start": "773800",
    "end": "779440"
  },
  {
    "text": "per disk creation it it is when you create a dis it's just a pointer to the",
    "start": "779440",
    "end": "785720"
  },
  {
    "text": "under underneath data blocks and by the way uh the data",
    "start": "785720",
    "end": "793320"
  },
  {
    "text": "representation gets scaled up when you increase the usage on the disk not by",
    "start": "793320",
    "end": "799959"
  },
  {
    "text": "creating more dis so that's a key insight for this",
    "start": "799959",
    "end": "806360"
  },
  {
    "text": "approach and that's that's the first approach then we will come to the second",
    "start": "806760",
    "end": "813040"
  },
  {
    "text": "solution it is motivated by our investigation into container D and",
    "start": "813040",
    "end": "820000"
  },
  {
    "text": "we did a lot of benchmarking or observation inside container D there",
    "start": "820000",
    "end": "827399"
  },
  {
    "text": "are two steps two phases in container D first is fetch the container image so",
    "start": "827399",
    "end": "834720"
  },
  {
    "text": "container container image is s as a layer by layer",
    "start": "834720",
    "end": "839759"
  },
  {
    "text": "and compressed package is on the container registry so the download",
    "start": "839759",
    "end": "845560"
  },
  {
    "text": "download in Conn is in parallel down downloading all the layers at the same",
    "start": "845560",
    "end": "851000"
  },
  {
    "text": "time putting it into the disk and the pH tool is unpack each",
    "start": "851000",
    "end": "858560"
  },
  {
    "text": "layers and create the snapshot which is a file assistant inside the",
    "start": "858560",
    "end": "866040"
  },
  {
    "text": "container and the packing part is single stred in container",
    "start": "866040",
    "end": "872240"
  },
  {
    "text": "D and also the decompression part this is very uh important and the",
    "start": "872240",
    "end": "879720"
  },
  {
    "text": "question is which step in the image uh image pool is Boton neck so the answer",
    "start": "879720",
    "end": "885920"
  },
  {
    "text": "is unpacking is the bot neck especially for large containers with more layers",
    "start": "885920",
    "end": "893199"
  },
  {
    "text": "you can imagine like you have 30 gigabyte downloading and unpacking requires like networking CPU and disk to",
    "start": "893199",
    "end": "903759"
  },
  {
    "text": "to to place the to create the containers file system all the files all the",
    "start": "903759",
    "end": "909199"
  },
  {
    "text": "folders and question two is is it limited by CPU or networking or storage",
    "start": "909199",
    "end": "915959"
  },
  {
    "text": "from our um from our investigation in most cases it's limited",
    "start": "915959",
    "end": "923560"
  },
  {
    "text": "by the slow dis operations and that's because all the",
    "start": "923560",
    "end": "930959"
  },
  {
    "text": "cloud dis implementation is almost based on the Block storage",
    "start": "930959",
    "end": "936959"
  },
  {
    "text": "technology and this technology is actually a distributed storage say it",
    "start": "936959",
    "end": "942560"
  },
  {
    "text": "requires notw working and you pring the suut for that disk and the default suut",
    "start": "942560",
    "end": "949880"
  },
  {
    "text": "limit is very low and even you like increase it it may not",
    "start": "949880",
    "end": "957279"
  },
  {
    "text": "benefit because because those block storage can handle more parel IO",
    "start": "957279",
    "end": "964680"
  },
  {
    "text": "operations but it will com with relatively higher latency than local",
    "start": "964680",
    "end": "970800"
  },
  {
    "text": "dis and it has uh post and accounts but for",
    "start": "970800",
    "end": "977360"
  },
  {
    "text": "the container this implementation for unpacking it does not benefit from that",
    "start": "977360",
    "end": "983399"
  },
  {
    "text": "uh High IO Ops so in order",
    "start": "983399",
    "end": "991319"
  },
  {
    "text": "to utilize all the support in the block storage you require a very deep IQ deps",
    "start": "991319",
    "end": "998040"
  },
  {
    "text": "for the system call of IO offs to achieve like to get the maximum",
    "start": "998040",
    "end": "1005240"
  },
  {
    "text": "suut limit par for your",
    "start": "1005240",
    "end": "1009880"
  },
  {
    "text": "disk and our solution is summarized in this",
    "start": "1010319",
    "end": "1015800"
  },
  {
    "text": "slide so personally C download everything in",
    "start": "1015800",
    "end": "1021319"
  },
  {
    "text": "parel but un packing them layer by layer because there's a dependency between",
    "start": "1021319",
    "end": "1027558"
  },
  {
    "text": "layers some files that overlapping between layers you need to",
    "start": "1027559",
    "end": "1034520"
  },
  {
    "text": "override or remove uh layer by layer so it's possible the N layer can delete the",
    "start": "1034520",
    "end": "1042280"
  },
  {
    "text": "files in the previous layer so that's why the commity has a uh squential order for the unpacking",
    "start": "1042280",
    "end": "1051039"
  },
  {
    "text": "and it need to adopt a lot of file system types it's it is an other reason",
    "start": "1051039",
    "end": "1058440"
  },
  {
    "text": "and for our proposal we propose unpacking each NS to different",
    "start": "1058440",
    "end": "1065880"
  },
  {
    "text": "folders in parallel and we build the",
    "start": "1065880",
    "end": "1072840"
  },
  {
    "text": "snapshot by using night weight file system operations like MO or rename or",
    "start": "1072840",
    "end": "1081600"
  },
  {
    "text": "creating Mount and as you can see when you paralized all the unpacking jobs you can",
    "start": "1081600",
    "end": "1088720"
  },
  {
    "text": "get the benefit from the uh for the latency and this",
    "start": "1088720",
    "end": "1096400"
  },
  {
    "text": "Improvement is more obious when you have larger containers when you have more uh",
    "start": "1096400",
    "end": "1101440"
  },
  {
    "text": "more layers for the containers uh for example if you have more layers you can run more parallel",
    "start": "1101440",
    "end": "1109960"
  },
  {
    "text": "jobs to unpacking them and typically all the AI and machine learning workloads",
    "start": "1109960",
    "end": "1116559"
  },
  {
    "text": "their containers have over 30 image",
    "start": "1116559",
    "end": "1121080"
  },
  {
    "text": "layers and the predicted results from this one",
    "start": "1121919",
    "end": "1127400"
  },
  {
    "text": "is the r ey is still the the perous uh approach the blue and ey is the proposed",
    "start": "1127400",
    "end": "1135960"
  },
  {
    "text": "solution and when you increase your when you upgrade your disk",
    "start": "1135960",
    "end": "1142280"
  },
  {
    "text": "suut like in GK it's upgrading the dis size you pay you pay more money and you",
    "start": "1142280",
    "end": "1150480"
  },
  {
    "text": "get more benefits by the upgrade but the previous approach",
    "start": "1150480",
    "end": "1157000"
  },
  {
    "text": "doesn't do that that's because the single started I'm packing so when this",
    "start": "1157000",
    "end": "1162159"
  },
  {
    "text": "approach from our Benchmark the image pool for 6 gab container can be reduced from over",
    "start": "1162159",
    "end": "1171200"
  },
  {
    "text": "20 over 2 30 seconds to 40",
    "start": "1171200",
    "end": "1177000"
  },
  {
    "text": "seconds and this is solution two and one last solution is uh Min one it's already",
    "start": "1178280",
    "end": "1185480"
  },
  {
    "text": "merged into uh kuber net and we implemented the maximum parallel image",
    "start": "1185480",
    "end": "1191240"
  },
  {
    "text": "pools across different port and when this parameter we can control and enable",
    "start": "1191240",
    "end": "1197120"
  },
  {
    "text": "the image pool between different PS running on the same note and this can also improve start",
    "start": "1197120",
    "end": "1205400"
  },
  {
    "text": "lency for multiple PS running on the same",
    "start": "1205400",
    "end": "1210559"
  },
  {
    "text": "node and that's the end of this presentation uh if you have any question",
    "start": "1210559",
    "end": "1216400"
  },
  {
    "text": "you can ask from that",
    "start": "1216400",
    "end": "1219640"
  },
  {
    "text": "mic",
    "start": "1227159",
    "end": "1230159"
  },
  {
    "text": "hey hi good U great talk uh really good Improvement performance um for solution",
    "start": "1233880",
    "end": "1242280"
  },
  {
    "text": "number two on unpacking them parallel you said you built a snapshot is that",
    "start": "1242280",
    "end": "1248039"
  },
  {
    "text": "snapshot available for anyone using container D to do",
    "start": "1248039",
    "end": "1253640"
  },
  {
    "text": "that uh solution to thand have a snap",
    "start": "1253640",
    "end": "1259480"
  },
  {
    "text": "shter like it is improving the C of the container D oh it's part of container D",
    "start": "1259480",
    "end": "1265559"
  },
  {
    "text": "so container d by default will uh do this it is uh to be it is a",
    "start": "1265559",
    "end": "1271919"
  },
  {
    "text": "proposal in and it's not yet implemented okay cool",
    "start": "1271919",
    "end": "1277960"
  },
  {
    "text": "thanks so my question is also followup so for solution one where you modify container D to read the cach layers from",
    "start": "1279360",
    "end": "1288960"
  },
  {
    "text": "an attached disk as opposed to the from a local disk is that change also merg to",
    "start": "1288960",
    "end": "1294320"
  },
  {
    "text": "continuity or is that to be implemented or it is uh it is very specific for the",
    "start": "1294320",
    "end": "1302480"
  },
  {
    "text": "each cloud and we can share the idea but like the implementation is inside the",
    "start": "1302480",
    "end": "1308520"
  },
  {
    "text": "gke and it really depends on the implementation of the position dis in",
    "start": "1308520",
    "end": "1315640"
  },
  {
    "text": "Google okay is it turned on by default on GK now or not yet we're going to",
    "start": "1315640",
    "end": "1320919"
  },
  {
    "text": "launch it end of this year and next year okay thank you are you planning to",
    "start": "1320919",
    "end": "1326679"
  },
  {
    "text": "contribute the change to other hypers to the community to container D Community or there are no plans for that uh we",
    "start": "1326679",
    "end": "1334039"
  },
  {
    "text": "will open source the image building part but no we don't have a plan to open source a snapshat but it only applies to",
    "start": "1334039",
    "end": "1341279"
  },
  {
    "text": "Google's approach okay thank you cool Hello um so for solution two",
    "start": "1341279",
    "end": "1349200"
  },
  {
    "text": "have you tried different compression formats for the layers and seeing if that has any effect or I guess like for",
    "start": "1349200",
    "end": "1355320"
  },
  {
    "text": "the image as well yeah it's a great question and I think it's a different dimension",
    "start": "1355320",
    "end": "1361480"
  },
  {
    "text": "and we tried the the STD algorithm and it do improve a little bit for for the",
    "start": "1361480",
    "end": "1367080"
  },
  {
    "text": "image pool thank still it requires downloading and and",
    "start": "1367080",
    "end": "1374159"
  },
  {
    "text": "packing hi my question is about uh solution one here so in this image",
    "start": "1374919",
    "end": "1380200"
  },
  {
    "text": "you're not including the time to create the node pool with a disc from the image which makes sense but I'm wondering if",
    "start": "1380200",
    "end": "1386360"
  },
  {
    "text": "you were to factor that in like in a kind of cloud setting where you're provisioning nodes dynamically is there",
    "start": "1386360",
    "end": "1391600"
  },
  {
    "text": "still a perceived benefit to the first step of building the disk image with the pre-loaded",
    "start": "1391600",
    "end": "1397000"
  },
  {
    "text": "containers and the question is uh why not include the node paring right or",
    "start": "1397000",
    "end": "1403880"
  },
  {
    "text": "mostly just like even if you were to include the node provision would there still be a benefit to this",
    "start": "1403880",
    "end": "1411080"
  },
  {
    "text": "pre-creation of the of the dis image uh yes because the idea here",
    "start": "1411080",
    "end": "1418000"
  },
  {
    "text": "is if you the the node creation time doesn't change but when this approach you create",
    "start": "1418000",
    "end": "1426799"
  },
  {
    "text": "the node the node coming with peri containers out of a box so there's no",
    "start": "1426799",
    "end": "1432559"
  },
  {
    "text": "extra time cost in it but you can benefit from the cash I see okay okay",
    "start": "1432559",
    "end": "1438120"
  },
  {
    "text": "yeah I think the one maybe question mark I had was around like if this was",
    "start": "1438120",
    "end": "1443279"
  },
  {
    "text": "ultimately like if most of the cost was still coming from the download step in which case pre-building the image versus",
    "start": "1443279",
    "end": "1450120"
  },
  {
    "text": "downloading it at the at runtime wouldn't make a difference but you're saying it it would",
    "start": "1450120",
    "end": "1456159"
  },
  {
    "text": "uh there is no I mean let me think about",
    "start": "1456159",
    "end": "1461919"
  },
  {
    "text": "it so the no paring doesn't change right the no is still here the machine type is",
    "start": "1461919",
    "end": "1467440"
  },
  {
    "text": "still the same but paring disk is super fast if you already have",
    "start": "1467440",
    "end": "1473399"
  },
  {
    "text": "the dis image in that location so you don't need to copy the data you just",
    "start": "1473399",
    "end": "1480480"
  },
  {
    "text": "when the cloud on the cloud you create a this is just a pointer to the underneath",
    "start": "1480480",
    "end": "1485799"
  },
  {
    "text": "data so it's super fast it's like within a few seconds I see so there's no actual",
    "start": "1485799",
    "end": "1492159"
  },
  {
    "text": "data copying during the creation process I see but like what if your image lived",
    "start": "1492159",
    "end": "1497240"
  },
  {
    "text": "in like you know um as an Ami in Amazon or something like that we're potentially",
    "start": "1497240",
    "end": "1502600"
  },
  {
    "text": "having to download it into the cluster yeah it's the same I'm sorry what was that uh Ami is it can also benefit from",
    "start": "1502600",
    "end": "1509720"
  },
  {
    "text": "this okay cool well thank you yeah nice talk this Yan CH from Apple uh",
    "start": "1509720",
    "end": "1518799"
  },
  {
    "text": "I have uh two questions the first question about the cost yeah this first",
    "start": "1518799",
    "end": "1524240"
  },
  {
    "text": "solution and pre-loading or prefetching the uh image or snapshot to additional and",
    "start": "1524240",
    "end": "1531200"
  },
  {
    "text": "the dis will this increase the cost it will increase a little bit it's",
    "start": "1531200",
    "end": "1537960"
  },
  {
    "text": "relatively almost doesn't exist so it's just a dis image with that size mhm and",
    "start": "1537960",
    "end": "1546039"
  },
  {
    "text": "you attach a disk to each node the disk will cause some money but when you run",
    "start": "1546039",
    "end": "1553840"
  },
  {
    "text": "machine learning workload the GPU and the Machine they are most like major part of the",
    "start": "1553840",
    "end": "1561880"
  },
  {
    "text": "cost in the building okay adding one dis is relatively smaller",
    "start": "1561880",
    "end": "1568000"
  },
  {
    "text": "part all I think someone may have some comments on",
    "start": "1568000",
    "end": "1573480"
  },
  {
    "text": "that",
    "start": "1586600",
    "end": "1589600"
  },
  {
    "text": "we're trying to merge that fix into container D and yeah that's",
    "start": "1600279",
    "end": "1608279"
  },
  {
    "text": "it any other question yeah so regarding the cost yeah just this slides and uh I",
    "start": "1609919",
    "end": "1616880"
  },
  {
    "text": "don't quite understand how does the the parano unpacking reduce the cost so",
    "start": "1616880",
    "end": "1622640"
  },
  {
    "text": "what's the base n you compare there right so not only improve the performance reduce the latency but also",
    "start": "1622640",
    "end": "1629440"
  },
  {
    "text": "reduce the cost can you elaborate a little how it reduces the",
    "start": "1629440",
    "end": "1636440"
  },
  {
    "text": "cost the parallel unpacking yeah the right it does not reduce cost it's the",
    "start": "1636480",
    "end": "1644120"
  },
  {
    "text": "cost is the same uh but to your next slid I think you issue and uh right the",
    "start": "1644120",
    "end": "1649320"
  },
  {
    "text": "blue line and uh not only and improve the performance",
    "start": "1649320",
    "end": "1654600"
  },
  {
    "text": "also the cost right sorry uh I need to clarify on this graph the right side is",
    "start": "1654600",
    "end": "1660080"
  },
  {
    "text": "only applies to the yellow n and the left side and Y access applies to the",
    "start": "1660080",
    "end": "1669039"
  },
  {
    "text": "red and blue n so it does not reduce cost it reduce the latency okay okay I",
    "start": "1669039",
    "end": "1675960"
  },
  {
    "text": "and when you increase the cost on the dis you can see more",
    "start": "1675960",
    "end": "1681880"
  },
  {
    "text": "Improvement on the new approach for the for the latency comparing to the r KN",
    "start": "1681880",
    "end": "1688039"
  },
  {
    "text": "okay okay got it that's how I read this graph okay the second one is about do you think this preet pre-loading and the",
    "start": "1688039",
    "end": "1695640"
  },
  {
    "text": "approach can work for the clust Autos scanning if I want to increase and add additional new nodes and provision it",
    "start": "1695640",
    "end": "1703279"
  },
  {
    "text": "and uh so how how should I apply this approach to that",
    "start": "1703279",
    "end": "1708720"
  },
  {
    "text": "uh it applies to other scaling mhm and that's a great question",
    "start": "1708720",
    "end": "1714640"
  },
  {
    "text": "and it's a API on the load pool or instance group so when all the new loads",
    "start": "1714640",
    "end": "1721960"
  },
  {
    "text": "get created they will com in up when the dis attached so it's the same noes and just",
    "start": "1721960",
    "end": "1728640"
  },
  {
    "text": "adding more nodes with more discs okay thank you",
    "start": "1728640",
    "end": "1733960"
  },
  {
    "text": "thanks hey I just had a quick question about how how do you manage the life cycle of your dis image so you mentioned",
    "start": "1733960",
    "end": "1740640"
  },
  {
    "text": "that the dis image is pre-baked with the model what happens when you want to update the model and what's your process",
    "start": "1740640",
    "end": "1746799"
  },
  {
    "text": "around it yeah that's a great question I think it's a limitation for this approach it's not that easy to change",
    "start": "1746799",
    "end": "1753120"
  },
  {
    "text": "the disc image you need to build it again once a new version of Huda a new",
    "start": "1753120",
    "end": "1759039"
  },
  {
    "text": "version of uh py toch to get this cash template and every time you upgrade you",
    "start": "1759039",
    "end": "1765519"
  },
  {
    "text": "need to upgrade the dis but it happens in the building time you can easily integrate with the when your cicd",
    "start": "1765519",
    "end": "1772480"
  },
  {
    "text": "workflow to recreate the dis Gage and it can be part of the infra team's",
    "start": "1772480",
    "end": "1779279"
  },
  {
    "text": "responsibility so we we have C separation for the respon",
    "start": "1779279",
    "end": "1784320"
  },
  {
    "text": "responsibility thanks and from application team they don't need to change their",
    "start": "1784320",
    "end": "1790360"
  },
  {
    "text": "containers makes sense the other question I had is around the unpacking that you showed on a slide um so you",
    "start": "1790360",
    "end": "1797799"
  },
  {
    "text": "mentioned that you're making the proposed changes in the container D in how you unpack them in",
    "start": "1797799",
    "end": "1803559"
  },
  {
    "text": "parallel um is the output after the proposed change going to be the same or",
    "start": "1803559",
    "end": "1808600"
  },
  {
    "text": "is there some like after take uh after using the proposed change um is there",
    "start": "1808600",
    "end": "1815440"
  },
  {
    "text": "another any other tradeoffs that the application will have it is the",
    "start": "1815440",
    "end": "1821000"
  },
  {
    "text": "same and yeah that's it it is same okay thanks and we're running out of time I",
    "start": "1821000",
    "end": "1828240"
  },
  {
    "text": "think we can answer one more questions okay okay I'm the lucky one guess so",
    "start": "1828240",
    "end": "1833399"
  },
  {
    "text": "yeah thanks a very good topic here I just uh have one question maybe just out",
    "start": "1833399",
    "end": "1839360"
  },
  {
    "text": "of curiosity like thinking about uh this aggregated storage situation remote",
    "start": "1839360",
    "end": "1846080"
  },
  {
    "text": "storage back end uh what do you see like these techniques here parallel prol",
    "start": "1846080",
    "end": "1851399"
  },
  {
    "text": "loing or like uh we're a fact in in this",
    "start": "1851399",
    "end": "1857559"
  },
  {
    "text": "uh scenario like where where it have or have we tested that like uh can you can",
    "start": "1857559",
    "end": "1865840"
  },
  {
    "text": "from on which which compilation I should test no just for the the whole server",
    "start": "1865840",
    "end": "1871360"
  },
  {
    "text": "like the node the back end of the the node is using remote storage MH and",
    "start": "1871360",
    "end": "1880360"
  },
  {
    "text": "uh uh the the image is kind of already there",
    "start": "1880360",
    "end": "1886159"
  },
  {
    "text": "uh to compare between and you needed to pull some the",
    "start": "1886159",
    "end": "1893000"
  },
  {
    "text": "regist yeah we don't need to pull it again because it's a format in container",
    "start": "1893000",
    "end": "1899399"
  },
  {
    "text": "D and it is comp compatible between different container diery so where it still need that amount",
    "start": "1899399",
    "end": "1907159"
  },
  {
    "text": "of time sorry can come again uh we where it still need that amount of time like even",
    "start": "1907159",
    "end": "1914120"
  },
  {
    "text": "we are using a remote storage for for oh to clarify all the dis in Cloud",
    "start": "1914120",
    "end": "1922480"
  },
  {
    "text": "that remote storage so we don't change that it's still the same okay good thank",
    "start": "1922480",
    "end": "1930320"
  },
  {
    "text": "you so you can imagine all the system calls to the disk will be converted into",
    "start": "1930320",
    "end": "1936200"
  },
  {
    "text": "a API call to the backend distributed",
    "start": "1936200",
    "end": "1941559"
  },
  {
    "text": "system like you create a file file on the on the system call and it is",
    "start": "1941559",
    "end": "1947919"
  },
  {
    "text": "actually created from the back end of us distribut",
    "start": "1947919",
    "end": "1954000"
  },
  {
    "text": "assist oh thank you and one last question yes yeah we are ran out of time",
    "start": "1954080",
    "end": "1960200"
  },
  {
    "text": "but I'm the last I believe yes uh I have a two questions like for regarding the",
    "start": "1960200",
    "end": "1965960"
  },
  {
    "text": "first approach have you tried with the NFS like protocol instead of ice seems",
    "start": "1965960",
    "end": "1971440"
  },
  {
    "text": "like you are attaching every dis from the uh to the Noe so I think instead",
    "start": "1971440",
    "end": "1977000"
  },
  {
    "text": "instead of using ice Cassy like using the NFS instead of the ice Cassy you",
    "start": "1977000",
    "end": "1982200"
  },
  {
    "text": "will Mount the dis from anywhere and you can reduce a lot of time to do it I mean we don't need to take the snapshot per",
    "start": "1982200",
    "end": "1989720"
  },
  {
    "text": "like external dis space uh can you con by using what like",
    "start": "1989720",
    "end": "1996480"
  },
  {
    "text": "uh NFS like for instance we can mount some kind of NFS storage instead of the",
    "start": "1996480",
    "end": "2003600"
  },
  {
    "text": "external discs per each note",
    "start": "2003600",
    "end": "2008960"
  },
  {
    "text": "I think it is applic uh it is feasible",
    "start": "2009120",
    "end": "2014440"
  },
  {
    "text": "for unprint environment but for I don't know I haven't tried that uh",
    "start": "2014440",
    "end": "2020919"
  },
  {
    "text": "but for instance AWS they are supporting EFS which is the NFS fire storage dis",
    "start": "2020919",
    "end": "2026399"
  },
  {
    "text": "space so I think it's would it would be better to use the NFS storage which is",
    "start": "2026399",
    "end": "2031440"
  },
  {
    "text": "the like it's equivalent to the AWS EFS I think uh that one and",
    "start": "2031440",
    "end": "2038679"
  },
  {
    "text": "and yes in Google we also have similar approach but",
    "start": "2038679",
    "end": "2045320"
  },
  {
    "text": "the the disk implementation is faster than Fs in in Google because it is a",
    "start": "2045320",
    "end": "2054040"
  },
  {
    "text": "relative disk implementation inside this cloud and we we have done a lot of like",
    "start": "2054040",
    "end": "2060240"
  },
  {
    "text": "improvements for that approach NFS it can also apply and there",
    "start": "2060240",
    "end": "2065960"
  },
  {
    "text": "are other approach which which is like GS fuse can also apply but it's still slower than this",
    "start": "2065960",
    "end": "2072800"
  },
  {
    "text": "one so it like for AWS use Case by NFS",
    "start": "2072800",
    "end": "2078200"
  },
  {
    "text": "which is the EFS could be faster than your approach in step one I think the idea can apply",
    "start": "2078200",
    "end": "2086520"
  },
  {
    "text": "but I haven't tested that yet in a yeah cool thank you and uh your enhancement",
    "start": "2086520",
    "end": "2093599"
  },
  {
    "text": "which kubernetes person will be available with with this",
    "start": "2093599",
    "end": "2098760"
  },
  {
    "text": "enhancement is latest kuber netics will contains these features or I think I'm",
    "start": "2098760",
    "end": "2105160"
  },
  {
    "text": "testing with 126 oh good thank you yeah I know we're running time so I hope",
    "start": "2105160",
    "end": "2111839"
  },
  {
    "text": "this a quick question so uh my question is when do what events will trigger the",
    "start": "2111839",
    "end": "2117160"
  },
  {
    "text": "image downloading for the in your first option so you said you have a disc that dedicate for image pulling right but",
    "start": "2117160",
    "end": "2123160"
  },
  {
    "text": "what will trigger the image pulling because that should happen before the part was scheduled",
    "start": "2123160",
    "end": "2131000"
  },
  {
    "text": "right yes the question is uh does the image",
    "start": "2133200",
    "end": "2140359"
  },
  {
    "text": "pool happens before the yeah before the part",
    "start": "2140359",
    "end": "2145760"
  },
  {
    "text": "scheduling right um",
    "start": "2145760",
    "end": "2152319"
  },
  {
    "text": "actually if the question is does the image",
    "start": "2152319",
    "end": "2157400"
  },
  {
    "text": "creation happens before the port scheduling the answer is yes it happens before like you know what to deploy you",
    "start": "2157400",
    "end": "2164400"
  },
  {
    "text": "need to prepare for it like prepare the infra for the workload so what's the event that trigger that is that the",
    "start": "2164400",
    "end": "2170680"
  },
  {
    "text": "because the p gets thought to the itcd and then there's a uh controller that",
    "start": "2170680",
    "end": "2175839"
  },
  {
    "text": "watch the P controller actually watch those oh the",
    "start": "2175839",
    "end": "2181400"
  },
  {
    "text": "actual workflow will be more like the application team tell the infra team I",
    "start": "2181400",
    "end": "2188400"
  },
  {
    "text": "need those containers to be preloaded put into the separate process human",
    "start": "2188400",
    "end": "2194079"
  },
  {
    "text": "manual process not automatic process it's more like sayd process oh actually",
    "start": "2194079",
    "end": "2199800"
  },
  {
    "text": "thank",
    "start": "2199800",
    "end": "2201960"
  },
  {
    "text": "you great and thanks thanks everyone for joining",
    "start": "2206839",
    "end": "2212119"
  },
  {
    "text": "this",
    "start": "2212119",
    "end": "2215119"
  }
]
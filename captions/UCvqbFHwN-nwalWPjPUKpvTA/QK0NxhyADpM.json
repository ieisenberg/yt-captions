[
  {
    "start": "0",
    "end": "35000"
  },
  {
    "text": "hello everyone and welcome to our session from notebook tiki flow pipelines with hyperparameters unit",
    "start": "0",
    "end": "5680"
  },
  {
    "text": "in this session we will be showing a complete data science workflow for optimizing your models and we will",
    "start": "5680",
    "end": "12160"
  },
  {
    "text": "be using jupter notebooks jail cardip and ufo pipelines this is us i'm miles kazakiewis software",
    "start": "12160",
    "end": "19760"
  },
  {
    "text": "engineer at rito hi everyone i'm stefano filabanzo software engineer at eric as well",
    "start": "19760",
    "end": "27840"
  },
  {
    "text": "at this point we would like to give some credit to sarah maddox from google who helped us dance with this tutorial",
    "start": "27840",
    "end": "36000"
  },
  {
    "start": "35000",
    "end": "240000"
  },
  {
    "text": "what's in it for you in this session what you learned by the end of the",
    "start": "36640",
    "end": "42079"
  },
  {
    "text": "session you will have converted the jupiter notebook to you flow pipeline with scale this makes your workflow a lot easier",
    "start": "42079",
    "end": "47840"
  },
  {
    "text": "and faster you will have performed by pipeline based hyperparameter tuning with caching which",
    "start": "47840",
    "end": "55440"
  },
  {
    "text": "makes your pipelines run faster everything will be simple since we will be using intuitive uis for everything",
    "start": "55440",
    "end": "62239"
  },
  {
    "text": "you will also accelerate your machine learning life cycle with j as an orchestration tool and finally you will gain complete",
    "start": "62239",
    "end": "68799"
  },
  {
    "text": "visibility of your training you can find a slide deck following this link here where you are also",
    "start": "68799",
    "end": "74560"
  },
  {
    "text": "able to win some cool prizes although this is a recorded session we have live dna on twitter and linkedin",
    "start": "74560",
    "end": "81520"
  },
  {
    "text": "using these hashtags the machine learning platform we are going to use is 2flow",
    "start": "81520",
    "end": "88720"
  },
  {
    "text": "for those who are not familiar with it qflo is an open source project dedicated to making the deployment of machine",
    "start": "88720",
    "end": "93759"
  },
  {
    "text": "learning workflows on kubernetes simple portable and scalable and how can you use it you can deploy",
    "start": "93759",
    "end": "101040"
  },
  {
    "text": "and manage complex machine learning systems at scale you can experiment rapidly",
    "start": "101040",
    "end": "106240"
  },
  {
    "text": "you can perform hyper parameter tuning you can deploy hybrid and multi-cloud workloads and you",
    "start": "106240",
    "end": "112880"
  },
  {
    "text": "can have the show coveted feature of cicd continuous integration and deployment",
    "start": "112880",
    "end": "119040"
  },
  {
    "text": "this is a ten thousand feet overview of machine learning as an as an ml engineer would look at it",
    "start": "119040",
    "end": "125520"
  },
  {
    "text": "machine learning requires some tools and frameworks for data scientists tubeflow encapsulates applications and",
    "start": "125520",
    "end": "131760"
  },
  {
    "text": "services to run those tools on top of kubernetes clusters and kubernetes runs on prem or on any",
    "start": "131760",
    "end": "138319"
  },
  {
    "text": "cloud and this is a machine learning workflow as a data scientist would experience it",
    "start": "138319",
    "end": "146000"
  },
  {
    "text": "data science begins with identifying the problem and collecting and analyzing data",
    "start": "146000",
    "end": "151200"
  },
  {
    "text": "then the data scientist has to choose a machine learning algorithm and code their models",
    "start": "151200",
    "end": "157840"
  },
  {
    "text": "subsequently they have to experiment with data and model training then they",
    "start": "158080",
    "end": "164319"
  },
  {
    "text": "optimize their model with hyperparameter zooming and of course in the very end they need to serve the model with the best result",
    "start": "164319",
    "end": "170800"
  },
  {
    "text": "tube flow has various components to achieve the all the aforementioned in this session we will focus on jupiter",
    "start": "170800",
    "end": "177120"
  },
  {
    "text": "notebooks jail cardip and zip flow pipelines how can someone use duplo you have a",
    "start": "177120",
    "end": "184000"
  },
  {
    "text": "graphical user interface a gui to manage notebooks volumes snapshots pipelines etc",
    "start": "184000",
    "end": "190640"
  },
  {
    "text": "this is an image of the central dashboard also you have two command line",
    "start": "190640",
    "end": "196800"
  },
  {
    "text": "interfaces jf cattle and cubecad and of course tubeflow has its own apis and sdks and",
    "start": "196800",
    "end": "204159"
  },
  {
    "text": "here are some examples the pipeline sdk cadib api and metadata sdk",
    "start": "204159",
    "end": "210159"
  },
  {
    "text": "there's a perception that machine learning is all about model code and complex math but in reality machine",
    "start": "210159",
    "end": "215360"
  },
  {
    "text": "learning applications are complex distributed systems they acquire lots of devops and various",
    "start": "215360",
    "end": "221599"
  },
  {
    "text": "components for monitoring serving managing the resources etc ubflo",
    "start": "221599",
    "end": "227920"
  },
  {
    "text": "containerizes all these components so that you can run them on kubernetes thus you have a uniform way",
    "start": "227920",
    "end": "233599"
  },
  {
    "text": "to run your workloads everywhere and at this point i'll hand over to stefano",
    "start": "233599",
    "end": "241840"
  },
  {
    "start": "240000",
    "end": "310000"
  },
  {
    "text": "thank you alias so now you've seen how kubeflow can accelerate and simplify",
    "start": "244239",
    "end": "251920"
  },
  {
    "text": "the whole orchestration process of running machine learning workflows at scale um in this tutorial",
    "start": "251920",
    "end": "259120"
  },
  {
    "text": "we're going to specifically focus on the data science experience so how keyflow and the tools we're going",
    "start": "259120",
    "end": "265120"
  },
  {
    "text": "to present will enable to dramatically simplify and accelerate the data science workflow",
    "start": "265120",
    "end": "272160"
  },
  {
    "text": "starting from your development environment that is most often jupiter jupiter notebooks then",
    "start": "272160",
    "end": "279919"
  },
  {
    "text": "how kale as a workflow tool will enable you to create pipelines seamlessly",
    "start": "279919",
    "end": "285520"
  },
  {
    "text": "seamlessly and run them in cubesat pipelines and then while and then while doing all",
    "start": "285520",
    "end": "291360"
  },
  {
    "text": "of these rock will enable you to close the circle go all the way back from running to",
    "start": "291360",
    "end": "298560"
  },
  {
    "text": "developing essentially with complete reproducibility enabling you",
    "start": "298560",
    "end": "304800"
  },
  {
    "text": "to explore your pipelines back in time",
    "start": "304800",
    "end": "311840"
  },
  {
    "start": "310000",
    "end": "390000"
  },
  {
    "text": "so we we're talking about um pipelines uh as the",
    "start": "313039",
    "end": "319919"
  },
  {
    "text": "as the core um workflow tool in kubeflow this is because um",
    "start": "319919",
    "end": "326479"
  },
  {
    "text": "by data science is inherently a pipeline process usually when you do data science your",
    "start": "326479",
    "end": "333919"
  },
  {
    "text": "job your work consists of several uh independent steps that come one after the other",
    "start": "333919",
    "end": "340560"
  },
  {
    "text": "this may be data ingestion and then transformation validation afterwards you do model trading um",
    "start": "340560",
    "end": "348720"
  },
  {
    "text": "either locally or at scale and you end up serving and monitoring",
    "start": "348720",
    "end": "353759"
  },
  {
    "text": "so all of these steps can be combined together in pipelines now this workshop",
    "start": "353759",
    "end": "360720"
  },
  {
    "text": "will focus on how to simplify as much as possible the building process",
    "start": "360720",
    "end": "367280"
  },
  {
    "text": "of a pipeline directly from your local environment via a graphical based approach",
    "start": "367280",
    "end": "374720"
  },
  {
    "text": "and how to completely automate data versioning to enable to",
    "start": "374720",
    "end": "380960"
  },
  {
    "text": "enable reproducibility and collaboration of course the tools that will make this possible",
    "start": "380960",
    "end": "387120"
  },
  {
    "text": "are kale and erictosrock now i've been talking about",
    "start": "387120",
    "end": "395039"
  },
  {
    "start": "390000",
    "end": "494000"
  },
  {
    "text": "converting a notebook to a pipeline so this is this makes a lot of sense",
    "start": "395039",
    "end": "402160"
  },
  {
    "text": "because if you think about it when you work in a jupiter notebook",
    "start": "402160",
    "end": "407600"
  },
  {
    "text": "you are already defining a sort of workflow that is pipeline based all of your cells",
    "start": "407600",
    "end": "414400"
  },
  {
    "text": "in the notebook can be thought as as um",
    "start": "414400",
    "end": "419720"
  },
  {
    "text": "isolated steps that can be even combined together and",
    "start": "419720",
    "end": "425680"
  },
  {
    "text": "attached to one another with dependencies this process makes it very easy to",
    "start": "425680",
    "end": "431840"
  },
  {
    "text": "parallelize and isolate your code at scale so you can you could even easily run hyper",
    "start": "431840",
    "end": "438880"
  },
  {
    "text": "parameter tuning over a notebook and its steps",
    "start": "438880",
    "end": "443919"
  },
  {
    "text": "and then also it becomes very easy when running pipelines in the",
    "start": "443919",
    "end": "450479"
  },
  {
    "text": "cube pipelines to apply data versioning and reproducibility to all of these independent steps and",
    "start": "450479",
    "end": "457360"
  },
  {
    "text": "you'll see how and you'll see later how this can be achieved and the various parts of your notebook",
    "start": "457360",
    "end": "464879"
  },
  {
    "text": "that become independent steps might might have different requirements so a",
    "start": "464879",
    "end": "470479"
  },
  {
    "text": "data processing step might be cpu bound so it will need a certain kind of",
    "start": "470479",
    "end": "477199"
  },
  {
    "text": "hardware resources while another part of your code that might be",
    "start": "477199",
    "end": "482479"
  },
  {
    "text": "doing deep learning training would benefit from running in a node with a gpu and all of",
    "start": "482479",
    "end": "489360"
  },
  {
    "text": "this becomes feasible with kale and rock",
    "start": "489360",
    "end": "494400"
  },
  {
    "start": "494000",
    "end": "594000"
  },
  {
    "text": "let's take a look at how these tools combined together with kubeflow",
    "start": "494960",
    "end": "500319"
  },
  {
    "text": "dramatically improve your development workflow and lifecycle",
    "start": "500319",
    "end": "505360"
  },
  {
    "text": "so traditionally you would write some machine learning code maybe in your notebook but then once",
    "start": "505360",
    "end": "512159"
  },
  {
    "text": "you're ready to build a pipeline out of it and scale it up you would need to",
    "start": "512159",
    "end": "517360"
  },
  {
    "text": "create a new docker image where you package all of your dependencies and your code then you need to take your",
    "start": "517360",
    "end": "525600"
  },
  {
    "text": "original code your machine learning code and actually write a pipeline with some",
    "start": "525600",
    "end": "531519"
  },
  {
    "text": "specific sdk for example the q flow pipelines dsl combine this pipeline upload it and run",
    "start": "531519",
    "end": "538640"
  },
  {
    "text": "it whenever you need to go back because maybe you made a mistake",
    "start": "538640",
    "end": "543760"
  },
  {
    "text": "or you need to improve your own code you need to go through all of these cycles this cycle",
    "start": "543760",
    "end": "549519"
  },
  {
    "text": "again you need to write again your code repackage it into a docker image again and again",
    "start": "549519",
    "end": "555200"
  },
  {
    "text": "but now with cadence rock all of these processes process becomes much simpler because you",
    "start": "555200",
    "end": "561600"
  },
  {
    "text": "just need to write the code in the notebook tag the notebook with the ui driven way",
    "start": "561600",
    "end": "568000"
  },
  {
    "text": "you'll see later how and with the click of a button just run it whenever you need to comment",
    "start": "568000",
    "end": "575040"
  },
  {
    "text": "your code it's seamless just write it in the notebook and click the button again",
    "start": "575040",
    "end": "581920"
  },
  {
    "text": "you can already think how this workflow dramatically improves your iteration",
    "start": "581920",
    "end": "588080"
  },
  {
    "text": "time and how much faster allows you to be productive",
    "start": "588080",
    "end": "594959"
  },
  {
    "start": "594000",
    "end": "706000"
  },
  {
    "text": "okay so besides converting notebooks to single",
    "start": "595200",
    "end": "600640"
  },
  {
    "text": "pipelines we look also at how to run hyper parameter tuning optimizations",
    "start": "600640",
    "end": "606160"
  },
  {
    "text": "in a data science world it is usually the case that you are running machine learning",
    "start": "606160",
    "end": "612480"
  },
  {
    "text": "algorithms that are dependent on some parameters so what you end up doing after writing",
    "start": "612480",
    "end": "620480"
  },
  {
    "text": "your first iteration of an algorithm is starting to tinkering with the parameters",
    "start": "620480",
    "end": "625600"
  },
  {
    "text": "and analyzing by yourself the produced metrics this is of course a",
    "start": "625600",
    "end": "631760"
  },
  {
    "text": "very time consuming process and also our problem but then there are",
    "start": "631760",
    "end": "637120"
  },
  {
    "text": "ways to automate all of these using some",
    "start": "637120",
    "end": "642959"
  },
  {
    "text": "automatic tools that basically use your algorithm and search",
    "start": "642959",
    "end": "650079"
  },
  {
    "text": "through a given search space the parameters that you give in",
    "start": "650079",
    "end": "655440"
  },
  {
    "text": "automatically with some specific mathematical optimizations techniques and",
    "start": "655440",
    "end": "662399"
  },
  {
    "text": "optimize over the metrics that you want to optimize in the case of qflo katip is the",
    "start": "662399",
    "end": "668320"
  },
  {
    "text": "official hyperparameter tuner it supports several machine learning frameworks including including",
    "start": "668320",
    "end": "674720"
  },
  {
    "text": "tensorflow mx and mxnet and others and",
    "start": "674720",
    "end": "680000"
  },
  {
    "text": "today what we are going to see is how you can go from a notebook",
    "start": "680000",
    "end": "687040"
  },
  {
    "text": "to kale to katib so scaling up your notebook as pipeline",
    "start": "687040",
    "end": "693760"
  },
  {
    "text": "with hyperparameter tuning with just a click of a button and with this i will hand it over back",
    "start": "693760",
    "end": "700800"
  },
  {
    "text": "to ilias who will start walking you through the actual tutorial",
    "start": "700800",
    "end": "706880"
  },
  {
    "start": "706000",
    "end": "792000"
  },
  {
    "text": "thank you stefano to follow the tutorial please go to this link to find the corresponding code lab that contains",
    "start": "706880",
    "end": "713600"
  },
  {
    "text": "step by step instructions this is the agenda of the tutorial we will install them in af then we will",
    "start": "713600",
    "end": "720399"
  },
  {
    "text": "get some already cooked machine learning code explore it convert it through pipeline and then perform hyper parameter tuning",
    "start": "720399",
    "end": "727120"
  },
  {
    "text": "on a specific model the first step is to install minik af but let's see what mini af",
    "start": "727120",
    "end": "733360"
  },
  {
    "text": "is mini af is the easiest way to deploy an experiment with tube flow",
    "start": "733360",
    "end": "739519"
  },
  {
    "text": "in just a few minutes you can have it on gcp on your laptop or any on-prem infrastructure",
    "start": "739519",
    "end": "745760"
  },
  {
    "text": "it is an all-in-one single node heap flow distribution and mini af mini clip flow is actually",
    "start": "745760",
    "end": "752399"
  },
  {
    "text": "mini cube with kubeflow and our software rok a data management platform",
    "start": "752399",
    "end": "759200"
  },
  {
    "text": "this image is taken from the tfx paper tube flow brings all these parts together in a",
    "start": "759200",
    "end": "764240"
  },
  {
    "text": "container of the way and gives you a nice way to perform hyper parameter streaming moreover cubeshop provides you with an",
    "start": "764240",
    "end": "770560"
  },
  {
    "text": "intuitive ui to manage all your components as we have already mentioned to your ransomware kubernetes",
    "start": "770560",
    "end": "777040"
  },
  {
    "text": "which takes care of duplicates of orchestration but then you also need to manage your",
    "start": "777040",
    "end": "782639"
  },
  {
    "text": "storage you can use many open source tools for your cloud provider's object store",
    "start": "782639",
    "end": "788000"
  },
  {
    "text": "but mini-af comes with rok our data management platform",
    "start": "788000",
    "end": "793200"
  },
  {
    "start": "792000",
    "end": "844000"
  },
  {
    "text": "we have made a lot of contributions to kubeflow because of our expertise in storage and data management",
    "start": "793360",
    "end": "798399"
  },
  {
    "text": "we have extended tube flow making it data aware you contributed code so that your flow can use kubernetes pvcs",
    "start": "798399",
    "end": "804720"
  },
  {
    "text": "no matter where where is deployed on your laptop on prem or a public cloud rock takes care of",
    "start": "804720",
    "end": "810880"
  },
  {
    "text": "data versioning and syncs your data across all different infrastructures",
    "start": "810880",
    "end": "816320"
  },
  {
    "text": "let's see why data versioning is important machine learning let's say we have pipeline where the",
    "start": "816320",
    "end": "821680"
  },
  {
    "text": "first step is data validation when the step is done we take a snapshot and we do the same for the next step",
    "start": "821680",
    "end": "827920"
  },
  {
    "text": "data pre-processing then another step runs but it fails how are we going to debug",
    "start": "827920",
    "end": "835040"
  },
  {
    "text": "we can clone the latest snapshot explore the data and code and then fix the error and continue the",
    "start": "835040",
    "end": "841920"
  },
  {
    "text": "pipeline let's now set up our mini kf",
    "start": "841920",
    "end": "849920"
  },
  {
    "start": "844000",
    "end": "939000"
  },
  {
    "text": "this is the code lab you found before here's introduction related to the",
    "start": "850000",
    "end": "856959"
  },
  {
    "text": "workload we're going to follow here are various information for those",
    "start": "856959",
    "end": "864000"
  },
  {
    "text": "who are not familiar with google cloud",
    "start": "864000",
    "end": "870639"
  },
  {
    "text": "finally let's head to the marketplace installment jf",
    "start": "870639",
    "end": "877199"
  },
  {
    "text": "minkief is a marketplace solution",
    "start": "877199",
    "end": "885839"
  },
  {
    "text": "who search for it",
    "start": "888160",
    "end": "890959"
  },
  {
    "text": "click on launch choose the the project we're going to",
    "start": "896000",
    "end": "902399"
  },
  {
    "text": "deploy it in and here are various configurations we can choose for our mini kf",
    "start": "902399",
    "end": "909680"
  },
  {
    "text": "go to the zone can choose its disks we can select gpus if they are",
    "start": "909680",
    "end": "916000"
  },
  {
    "text": "available in the zone and once we're ready we can click on deploy",
    "start": "916000",
    "end": "921839"
  },
  {
    "text": "so now the instance is going to come up and after that it will take about 15",
    "start": "921920",
    "end": "927279"
  },
  {
    "text": "minutes for mink to be up and running and for you to be ready to experiment",
    "start": "927279",
    "end": "933839"
  },
  {
    "text": "at this point i'll hand over back to stephanie",
    "start": "934639",
    "end": "940639"
  },
  {
    "text": "thank you idiots so uh in no time you should have a ready mini",
    "start": "940639",
    "end": "946720"
  },
  {
    "text": "kf and you will be able to start uh with uh with the tutorial yourself",
    "start": "946720",
    "end": "953279"
  },
  {
    "text": "now i will walk you through the rest of the codelab so we'll see how",
    "start": "953279",
    "end": "958959"
  },
  {
    "text": "you can go from notebook to cutie to cueva pipelines",
    "start": "958959",
    "end": "965519"
  },
  {
    "text": "so i will head over to my mini kf as you can see here i have uh the queue",
    "start": "966079",
    "end": "972720"
  },
  {
    "text": "flow sensor dashboard um if you are already used to qflo if",
    "start": "972720",
    "end": "978480"
  },
  {
    "text": "you've already used it uh you might notice that the the sidebar here is a little bit",
    "start": "978480",
    "end": "985279"
  },
  {
    "text": "different this is because um we've been working on the kubeflow",
    "start": "985279",
    "end": "990480"
  },
  {
    "text": "center dashboard to unify uh in a consistent way all of the key flow components together",
    "start": "990480",
    "end": "996880"
  },
  {
    "text": "in a single place and you will see how i will be using these throughout the tutorial of course",
    "start": "996880",
    "end": "1004399"
  },
  {
    "text": "this is what work that we are going to contribute upstream very soon so you will be able to see it",
    "start": "1004399",
    "end": "1010480"
  },
  {
    "text": "in the github discussions so now i'm heading over to notebooks and i'll create",
    "start": "1010480",
    "end": "1019440"
  },
  {
    "text": "a new notebook just for this demo and they need kubecon i'm selecting",
    "start": "1019440",
    "end": "1026959"
  },
  {
    "text": "a jupiter image that includes scale then i'm also adding a data volume",
    "start": "1026959",
    "end": "1039600"
  },
  {
    "text": "and i press launch and that's it this is very simple in kubeflow to spin up new jupiter servers",
    "start": "1039600",
    "end": "1046959"
  },
  {
    "text": "where you can work on your own code and start new pipelines",
    "start": "1046959",
    "end": "1053840"
  },
  {
    "start": "1066000",
    "end": "1405000"
  },
  {
    "text": "okay the notebook server has been provisioned so you can just connect",
    "start": "1066880",
    "end": "1074080"
  },
  {
    "text": "and in no time we have provisioned in a service of way a full jupiter lab environment",
    "start": "1074400",
    "end": "1082880"
  },
  {
    "text": "now i want to clone some code where i can work on i can do that from the code lab as you",
    "start": "1085760",
    "end": "1092240"
  },
  {
    "text": "can see here there are all of the instructions that you can follow metadata stage now i'll just scroll",
    "start": "1092240",
    "end": "1099360"
  },
  {
    "text": "here to the code that allows me to clone the k repository so i'll head over back",
    "start": "1099360",
    "end": "1108000"
  },
  {
    "text": "to my notebook so we are cloning the official k",
    "start": "1108000",
    "end": "1113520"
  },
  {
    "text": "repository that is open source as you can see there is an examples",
    "start": "1113520",
    "end": "1120960"
  },
  {
    "text": "folder we're going to open the top read classification example",
    "start": "1120960",
    "end": "1128480"
  },
  {
    "text": "that we prepared just for this tutorial there are two notebooks we will start",
    "start": "1128480",
    "end": "1134960"
  },
  {
    "text": "with the dog brick one and then switch over to the drug dog breed cathedral",
    "start": "1134960",
    "end": "1141360"
  },
  {
    "text": "now i want to go over into the details of what is implemented",
    "start": "1141360",
    "end": "1149200"
  },
  {
    "text": "in this notebook just keep in mind that this code is based on a utah city",
    "start": "1149200",
    "end": "1155520"
  },
  {
    "text": "project where we are basically processing some dog images and building",
    "start": "1155520",
    "end": "1163120"
  },
  {
    "text": "a deep learning classifier to recognize dog breeds",
    "start": "1163120",
    "end": "1169679"
  },
  {
    "text": "the first thing i want to do is to verify that my notebook has the dependencies it needs to run the",
    "start": "1170000",
    "end": "1176000"
  },
  {
    "text": "code so i'll just run the first cell here with the import and we notice that we are missing some",
    "start": "1176000",
    "end": "1182000"
  },
  {
    "text": "dependencies so i have a helper here that runs clip install to install the requirements",
    "start": "1182000",
    "end": "1189120"
  },
  {
    "text": "notice how i am installing this library here now on the fly this will be",
    "start": "1189120",
    "end": "1194480"
  },
  {
    "text": "important at a later stage when we will convert this for a pipeline",
    "start": "1194480",
    "end": "1200240"
  },
  {
    "text": "you can think of this process as i could be tinkering with the code solving bugs",
    "start": "1201280",
    "end": "1207039"
  },
  {
    "text": "adding new features um and then installing the planet dependencies on the fly",
    "start": "1207039",
    "end": "1212799"
  },
  {
    "text": "as i add new code okay so now we should have all the",
    "start": "1212799",
    "end": "1220400"
  },
  {
    "text": "dependencies we need i'll restart my kernel",
    "start": "1220400",
    "end": "1227440"
  },
  {
    "text": "okay so every import succeeded so let's say i'm done with the code i'm",
    "start": "1230559",
    "end": "1238240"
  },
  {
    "text": "done with the code so i have implemented all my data preparation",
    "start": "1238240",
    "end": "1243679"
  },
  {
    "text": "and then i'm detecting my dogs i'm writing some detectors",
    "start": "1243679",
    "end": "1248960"
  },
  {
    "text": "we brought the cnn and deep learning code to recognize them again i won't go into",
    "start": "1248960",
    "end": "1256000"
  },
  {
    "text": "details but you see there's some involved code in this um this notebook so i tested it",
    "start": "1256000",
    "end": "1263120"
  },
  {
    "text": "locally i have all my dependencies and now i want to scale it up and convert it to a pipeline",
    "start": "1263120",
    "end": "1268320"
  },
  {
    "text": "how do i do that so i can go over here on the left click on the k panel enable it",
    "start": "1268320",
    "end": "1275679"
  },
  {
    "text": "and now you see a whole bunch of things happening so kale is a",
    "start": "1275679",
    "end": "1282559"
  },
  {
    "text": "is a way for you to tag notebook cells in a ui driven way",
    "start": "1282559",
    "end": "1288960"
  },
  {
    "text": "and assign these cells to pipeline steps let's let's take an example here",
    "start": "1288960",
    "end": "1296159"
  },
  {
    "text": "here you see this cell is tagged as step load data by pressing on",
    "start": "1296159",
    "end": "1303600"
  },
  {
    "text": "the top right here uck provides a very simple way for you to target",
    "start": "1303600",
    "end": "1311120"
  },
  {
    "text": "this cell with this specific name and what you're doing here is basically assigning this",
    "start": "1311120",
    "end": "1316559"
  },
  {
    "text": "cell to a pipeline step multiple cells as you can see can be merged together",
    "start": "1316559",
    "end": "1322240"
  },
  {
    "text": "in a single one and then it is that simple to create new steps and",
    "start": "1322240",
    "end": "1330840"
  },
  {
    "text": "dependencies once you do this of course we've already tagged this notebook for simplicity",
    "start": "1330840",
    "end": "1337679"
  },
  {
    "text": "you can just select an eq flip experiment give the notebook a name",
    "start": "1337679",
    "end": "1343840"
  },
  {
    "text": "and then click the compile and run button so what is happening now is that caleb",
    "start": "1344480",
    "end": "1350559"
  },
  {
    "text": "has validated the notebook and now brock our richto's rock data platform",
    "start": "1350559",
    "end": "1356000"
  },
  {
    "text": "is taking a snapshot of the current notebook all of its volume volumes",
    "start": "1356000",
    "end": "1362559"
  },
  {
    "text": "so that your environment is completely reproduced in the pipeline steps this is why",
    "start": "1362559",
    "end": "1371039"
  },
  {
    "text": "even though i just installed on the fly my libraries the code will run seamlessly in the",
    "start": "1371360",
    "end": "1378640"
  },
  {
    "text": "pipeline steps without you having to build new docker images",
    "start": "1378640",
    "end": "1384720"
  },
  {
    "text": "so chaos then compiled the notebook created a python uploaded it for five times and it starts",
    "start": "1384720",
    "end": "1391120"
  },
  {
    "text": "with a new run let's go to q4 pipelines using this link and see the pipeline running",
    "start": "1391120",
    "end": "1403840"
  },
  {
    "start": "1405000",
    "end": "1542000"
  },
  {
    "text": "okay so as you can see here i have my two volumes that are basically um new",
    "start": "1405039",
    "end": "1412320"
  },
  {
    "text": "volumes that start from snapshot that were taken by a rock when i clicked the button and my python",
    "start": "1412320",
    "end": "1419200"
  },
  {
    "text": "is starting let's give it a little bit of time to run while i go back to the slides and talk to you",
    "start": "1419200",
    "end": "1425919"
  },
  {
    "text": "and walk you through how kale is actually doing all of this",
    "start": "1425919",
    "end": "1431679"
  },
  {
    "text": "so scale is basically a python package and a jupyter lab extension",
    "start": "1431679",
    "end": "1438559"
  },
  {
    "text": "um it allows you to convert a jupiter notebook to cubesat pipelines in a completely ui",
    "start": "1438559",
    "end": "1445520"
  },
  {
    "text": "driven way without the need of writing any kind of external sdk how does it do that",
    "start": "1445520",
    "end": "1454080"
  },
  {
    "text": "well in the point you click the compile compiler button running compile button ko takes the",
    "start": "1454080",
    "end": "1461760"
  },
  {
    "text": "notebook and parses it analyzing all of the annotations you've added via the key ui this",
    "start": "1461760",
    "end": "1469120"
  },
  {
    "text": "turns into an internal graph representation that is parsed by ko so that it can look",
    "start": "1469120",
    "end": "1476159"
  },
  {
    "text": "at all the data dependencies between the notebook cells so cable detects these dependencies and",
    "start": "1476159",
    "end": "1483679"
  },
  {
    "text": "then it takes care of marshalling the data between the pipeline steps for you",
    "start": "1483679",
    "end": "1489440"
  },
  {
    "text": "so that the code execution is completely seamless just like it happens in the notebook",
    "start": "1489440",
    "end": "1496880"
  },
  {
    "text": "and all of this is possible because scale also takes care of generating a whole",
    "start": "1496880",
    "end": "1502400"
  },
  {
    "text": "bunch of code that you would have that you don't need to write anymore because katie is doing it for",
    "start": "1502400",
    "end": "1509120"
  },
  {
    "text": "you note that cable is an open source",
    "start": "1509120",
    "end": "1515039"
  },
  {
    "text": "project that is hosted in the kubeflow cable github github organization",
    "start": "1515039",
    "end": "1521440"
  },
  {
    "text": "and we would be very happy to receive feedback and questions and also",
    "start": "1521440",
    "end": "1528000"
  },
  {
    "text": "contributions now let's go over",
    "start": "1528000",
    "end": "1534320"
  },
  {
    "text": "back over to the pipeline that it is still running",
    "start": "1534320",
    "end": "1539760"
  },
  {
    "text": "it should be done very quickly so notice how",
    "start": "1539760",
    "end": "1546080"
  },
  {
    "text": "we already have two steps you might remember that we tagged some cells with the load",
    "start": "1546080",
    "end": "1552880"
  },
  {
    "text": "data the load data notation and then we",
    "start": "1552880",
    "end": "1558000"
  },
  {
    "text": "tagged some other cells with the detected token notation specifying a dependency so kate was able",
    "start": "1558000",
    "end": "1565440"
  },
  {
    "text": "to separate this code into multiple steps and then even branch out",
    "start": "1565440",
    "end": "1572320"
  },
  {
    "text": "the training of the several different deep learning algorithms because the dependencies were all",
    "start": "1572320",
    "end": "1578960"
  },
  {
    "text": "referring to a common step so you now have code that would have run",
    "start": "1578960",
    "end": "1584400"
  },
  {
    "text": "serial in the notebook running concurrently in the queue for pipeline",
    "start": "1584400",
    "end": "1590480"
  },
  {
    "text": "all of the logs are preserved",
    "start": "1590480",
    "end": "1594880"
  },
  {
    "text": "and also let me go to a pipeline that was already concluded",
    "start": "1596080",
    "end": "1603520"
  },
  {
    "text": "or rather i take this one since it has already [Music]",
    "start": "1603520",
    "end": "1610840"
  },
  {
    "text": "completed as you can see i have a whole bunch of",
    "start": "1610840",
    "end": "1616400"
  },
  {
    "text": "logs here that are taking uh that are basically reproducing",
    "start": "1616400",
    "end": "1621679"
  },
  {
    "text": "the exact visualization that you would see in jupiter for example here the cnn resonant 15",
    "start": "1621679",
    "end": "1629200"
  },
  {
    "text": "in the notebook produces a visualization at the end of its",
    "start": "1629200",
    "end": "1634559"
  },
  {
    "text": "computation to show one of the detected images one of the",
    "start": "1634559",
    "end": "1640320"
  },
  {
    "text": "dog breeds detective so as you can see uh kale is able to",
    "start": "1640320",
    "end": "1646080"
  },
  {
    "text": "completely reproduce even the notebook visualizations so whether you are plotting with matte blocking",
    "start": "1646080",
    "end": "1652000"
  },
  {
    "text": "or interactive with a visualization with blockly all of this is preserved and reproduced",
    "start": "1652000",
    "end": "1659120"
  },
  {
    "text": "in qfl pipelines okay so now that we've run",
    "start": "1659120",
    "end": "1665840"
  },
  {
    "start": "1663000",
    "end": "1790000"
  },
  {
    "text": "a single pipeline we would want to scale it up and run it as a hyper parameter tuning",
    "start": "1665840",
    "end": "1673440"
  },
  {
    "text": "job let's go to the catal notebook",
    "start": "1673440",
    "end": "1680960"
  },
  {
    "text": "in this specific notebook we are skipping two of the learning algorithms and we",
    "start": "1680960",
    "end": "1688320"
  },
  {
    "text": "are running just over the resonant 50.",
    "start": "1688320",
    "end": "1692960"
  },
  {
    "text": "what we want to do is to parameterize the notebook with some input parameters and",
    "start": "1694799",
    "end": "1702799"
  },
  {
    "text": "run the generated pipeline with cutie to optimize over a certain metric so that we can optimize automatically",
    "start": "1702799",
    "end": "1711840"
  },
  {
    "text": "the training algorithm so we need two important things to do this input parameters and an output metric",
    "start": "1712159",
    "end": "1721120"
  },
  {
    "text": "so with ko it is very simple to create pipeline parameters from the notebook",
    "start": "1721120",
    "end": "1727520"
  },
  {
    "text": "all you need to do is to define an um notebook cell with some variable",
    "start": "1727520",
    "end": "1734880"
  },
  {
    "text": "assignments and target with the kui",
    "start": "1734880",
    "end": "1740240"
  },
  {
    "text": "with the pipeline parameter tag and then i'm scrolling down all the way",
    "start": "1740240",
    "end": "1747360"
  },
  {
    "text": "to the bottom of the notebook what you want to do is to have your code",
    "start": "1747360",
    "end": "1752960"
  },
  {
    "text": "produce a metric produce a metric that then will be exported by the",
    "start": "1752960",
    "end": "1759760"
  },
  {
    "text": "pipeline and analyzed by cutting so what you need to do",
    "start": "1759760",
    "end": "1765279"
  },
  {
    "text": "is to print whatever variable your algorithm is producing and that you want to be used as an",
    "start": "1765279",
    "end": "1772480"
  },
  {
    "text": "optimization metric print it and then tag",
    "start": "1772480",
    "end": "1777520"
  },
  {
    "text": "the cell with the pipeline metric stock this is all you need once you have this you can go over",
    "start": "1777520",
    "end": "1786240"
  },
  {
    "text": "the kale sidebar enable the the copy toggle",
    "start": "1786240",
    "end": "1792880"
  },
  {
    "text": "and click on the setup cutting job button now as you can see okay it provides you",
    "start": "1792880",
    "end": "1800480"
  },
  {
    "text": "with this very simple to use ui that provides the input parameters",
    "start": "1800480",
    "end": "1806399"
  },
  {
    "text": "these are exactly the names of the variables i defined in the notebook cell we have already",
    "start": "1806399",
    "end": "1814320"
  },
  {
    "text": "filled the values we want to use but you could do you could insert here whatever values",
    "start": "1814320",
    "end": "1820080"
  },
  {
    "text": "you want from ranges lists integer float streaming values what have you",
    "start": "1820080",
    "end": "1828880"
  },
  {
    "text": "then i can select a search optimization algorithm and my search objective again",
    "start": "1828960",
    "end": "1836320"
  },
  {
    "text": "this is exactly the variable name we are printing in the pipeline metrics cell that's all you need to do",
    "start": "1836320",
    "end": "1845279"
  },
  {
    "text": "i'm clicking close and again the compiler run button so now a similar thing",
    "start": "1845279",
    "end": "1852799"
  },
  {
    "text": "happens as before okay validates the notebook rock takes an immutable snapshot at this",
    "start": "1852799",
    "end": "1860080"
  },
  {
    "text": "specific point in time then kl converts the notebook uploads a new pipeline and now here's",
    "start": "1860080",
    "end": "1867919"
  },
  {
    "text": "what's happening kale is actually starting a new cutting",
    "start": "1867919",
    "end": "1873840"
  },
  {
    "text": "job nucleotide experiment where each caterpillar",
    "start": "1873840",
    "end": "1879840"
  },
  {
    "text": "is actually a q flow pipeline run so this was not possible before it is",
    "start": "1879840",
    "end": "1886080"
  },
  {
    "start": "1886000",
    "end": "2080000"
  },
  {
    "text": "scale that is that it is acting as a bridge between khatib thank you for pipelines let's go",
    "start": "1886080",
    "end": "1893600"
  },
  {
    "text": "see these experiments so here i'm opening",
    "start": "1893600",
    "end": "1901279"
  },
  {
    "text": "the cutie experiment page let's give it a few seconds to load up",
    "start": "1901279",
    "end": "1909278"
  },
  {
    "text": "as you can see i have a new cutting experiment",
    "start": "1913919",
    "end": "1919440"
  },
  {
    "text": "and here a new cubeflow experiment they have the same names they have one",
    "start": "1919440",
    "end": "1925200"
  },
  {
    "text": "single run for the moment again with the same name so you have a one-to-one correspondence",
    "start": "1925200",
    "end": "1931519"
  },
  {
    "text": "here you see which are the input parameters that can be decided to give as input to this",
    "start": "1931519",
    "end": "1938880"
  },
  {
    "text": "pipeline so i'm heading back over to pipelines i see the pipeline",
    "start": "1938880",
    "end": "1944480"
  },
  {
    "text": "generated it is starting to run",
    "start": "1944480",
    "end": "1950398"
  },
  {
    "text": "i can see them here in the config tab what are its input parameters",
    "start": "1950720",
    "end": "1958559"
  },
  {
    "text": "so this pipeline is running just like before but with specific parameter parameters",
    "start": "1960880",
    "end": "1967360"
  },
  {
    "text": "that were given by cathedral now it would take a lot of time for us",
    "start": "1967360",
    "end": "1973360"
  },
  {
    "text": "to monitor uh tens of pipelines running in this experiment so let me head",
    "start": "1973360",
    "end": "1980399"
  },
  {
    "text": "over to an experiment that we already run some time ago",
    "start": "1980399",
    "end": "1990399"
  },
  {
    "text": "okay so this was an experiment created in the same way we did now from the",
    "start": "1990399",
    "end": "1995840"
  },
  {
    "text": "notebook clicking a button on kl as you can see i have several pipelines here",
    "start": "1995840",
    "end": "2001440"
  },
  {
    "text": "that produced a specific metric so this is the metric that we",
    "start": "2001440",
    "end": "2007039"
  },
  {
    "text": "were bringing from the notebook here was able to interpret that and output",
    "start": "2007039",
    "end": "2012159"
  },
  {
    "text": "this metric as an artifact let's go over also to the katip experiment",
    "start": "2012159",
    "end": "2020559"
  },
  {
    "text": "this is the corresponding cutif experiment that was running as you can see we have many runs",
    "start": "2024240",
    "end": "2030399"
  },
  {
    "text": "and how their performance varied over time we have all of the runs even here with",
    "start": "2030399",
    "end": "2037519"
  },
  {
    "text": "the corresponding metrics and input parameters",
    "start": "2037519",
    "end": "2047840"
  },
  {
    "text": "in the meanwhile our experiment is still running and you can see here you can have a live",
    "start": "2048960",
    "end": "2056158"
  },
  {
    "text": "view directly from the notebook about how many",
    "start": "2056159",
    "end": "2062480"
  },
  {
    "text": "runs are are running in this moment and as soon as one at least one",
    "start": "2062960",
    "end": "2070800"
  },
  {
    "text": "would finish you would see here a live view over what is the current best result as",
    "start": "2070800",
    "end": "2077760"
  },
  {
    "text": "well all from your notebook okay so that was it for the hands-on",
    "start": "2077760",
    "end": "2084878"
  },
  {
    "start": "2080000",
    "end": "2398000"
  },
  {
    "text": "tutorial i hope you will have time to go through your code lab play around with the code",
    "start": "2084879",
    "end": "2091040"
  },
  {
    "text": "stop start your own pipelines and have fun so let me go back to the slides to",
    "start": "2091040",
    "end": "2098480"
  },
  {
    "text": "summarize what we saw together today",
    "start": "2098480",
    "end": "2103838"
  },
  {
    "text": "so what have you learned today today you have learned how you can run a pipeline based hyper",
    "start": "2108000",
    "end": "2115680"
  },
  {
    "text": "tuning workflow starting directly from your jupiter notebook in a super simple ui driven way",
    "start": "2115680",
    "end": "2123119"
  },
  {
    "text": "kale is acting as the workflow tool that brings together notebooks q5",
    "start": "2123119",
    "end": "2130000"
  },
  {
    "text": "pipelines and cocktail experiments this is a great simplification",
    "start": "2130000",
    "end": "2135280"
  },
  {
    "text": "of how you can run machine learning workflows in a ui driven way also",
    "start": "2135280",
    "end": "2143119"
  },
  {
    "text": "um all of these um exploit caching and i will show you",
    "start": "2143119",
    "end": "2149599"
  },
  {
    "text": "in a second how that i actually forgot to mention before",
    "start": "2149599",
    "end": "2155040"
  },
  {
    "text": "so we'll go back to the to the queue for pipelines ui so that you can see that",
    "start": "2155040",
    "end": "2161119"
  },
  {
    "text": "all of this workflow thanks to rock is exploiting our our caching feature",
    "start": "2161119",
    "end": "2166640"
  },
  {
    "text": "that is built on top of kubeflow and also this allows you to collaborate",
    "start": "2166640",
    "end": "2171839"
  },
  {
    "text": "faster and more easily so let's head over back",
    "start": "2171839",
    "end": "2177760"
  },
  {
    "text": "to the flow dashboard this is actually something i wanted to show you",
    "start": "2177760",
    "end": "2183440"
  },
  {
    "text": "but forgot so as you can see here i am looking",
    "start": "2183440",
    "end": "2192079"
  },
  {
    "text": "at the experiment that we had already run in the past so i have several runs i took one of",
    "start": "2192079",
    "end": "2198160"
  },
  {
    "text": "them at random and there is this little icon here so this",
    "start": "2198160",
    "end": "2204160"
  },
  {
    "text": "means that this pipeline was cached actually these steps were cached",
    "start": "2204160",
    "end": "2211200"
  },
  {
    "text": "so why is this happening the cnn resonant 50 step",
    "start": "2211599",
    "end": "2218320"
  },
  {
    "text": "is the only one in the pipeline that is dependent on some input parameters it is the only",
    "start": "2218320",
    "end": "2224720"
  },
  {
    "text": "part of the node on the original notebook code that reads that acts upon those parameters",
    "start": "2224720",
    "end": "2233280"
  },
  {
    "text": "since k knows this it also knows that the previous steps won't change",
    "start": "2233280",
    "end": "2240839"
  },
  {
    "text": "um and it that will never change across all of your runs this means that",
    "start": "2240839",
    "end": "2247440"
  },
  {
    "text": "running load data and the tech talks several times would be a waste of resources",
    "start": "2247440",
    "end": "2253200"
  },
  {
    "text": "so what we've done is we've extended the current caching implementation of",
    "start": "2253200",
    "end": "2259359"
  },
  {
    "text": "qflo that works over artifacts to work also over snapshots and pvcs",
    "start": "2259359",
    "end": "2267920"
  },
  {
    "text": "in this way the running time and the performance of all of these pipelines is greatly improved",
    "start": "2267920",
    "end": "2275920"
  },
  {
    "text": "okay so back again to us our summary running pipelines from",
    "start": "2278000",
    "end": "2285119"
  },
  {
    "text": "notebook to queue flow in a completely ui driven way",
    "start": "2285119",
    "end": "2290240"
  },
  {
    "text": "with caching in order to accelerate your workflow",
    "start": "2290240",
    "end": "2296240"
  },
  {
    "text": "dramatically i would like to conclude by saying that",
    "start": "2296839",
    "end": "2302640"
  },
  {
    "text": "in a ricktalk we are very passionate open source contributors we've contributed to many components in",
    "start": "2302640",
    "end": "2309920"
  },
  {
    "text": "kubeflow from jupiter manager ui to pipelines to building our opinionated and super",
    "start": "2309920",
    "end": "2317839"
  },
  {
    "text": "portable q flow distribution mini kf we've done lots of work to the",
    "start": "2317839",
    "end": "2324400"
  },
  {
    "text": "authentication and authorization architecture of keyflow",
    "start": "2324400",
    "end": "2329680"
  },
  {
    "text": "and also many contributions to the linux kernel to support our data platform",
    "start": "2329680",
    "end": "2337920"
  },
  {
    "text": "qflow is a great community made up of many many uh big companies",
    "start": "2338839",
    "end": "2346800"
  },
  {
    "text": "and as a community we are always striving to find new contribution contributors and new passionate users so",
    "start": "2346800",
    "end": "2354640"
  },
  {
    "text": "please get involved you can find here lots of pointers from the github",
    "start": "2354640",
    "end": "2360400"
  },
  {
    "text": "organization to our slack twitter handle or write us an email to the qflo discuss",
    "start": "2360400",
    "end": "2368560"
  },
  {
    "text": "google group will be happy to support you and on board you",
    "start": "2368560",
    "end": "2375040"
  },
  {
    "text": "so thank you for staying with us we really hope you'll have fun playing around with our tutorial",
    "start": "2375280",
    "end": "2382640"
  },
  {
    "text": "make sure to head over our website and there and this quick link where you will find the slides and um",
    "start": "2382640",
    "end": "2391119"
  },
  {
    "text": "and you could win some cool prizes thank you again and see you soon",
    "start": "2391119",
    "end": "2399838"
  }
]
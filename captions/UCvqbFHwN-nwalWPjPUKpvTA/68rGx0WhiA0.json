[
  {
    "start": "0",
    "end": "12000"
  },
  {
    "text": "in this session for the service meshcon track we're going to talk about multi-cluster",
    "start": "160",
    "end": "7279"
  },
  {
    "text": "kubernetes and service mesh patterns so my name is christian posta i'm the",
    "start": "7279",
    "end": "14080"
  },
  {
    "start": "12000",
    "end": "12000"
  },
  {
    "text": "field cto at solo.i o at solo we build api infrastructure for",
    "start": "14080",
    "end": "21039"
  },
  {
    "text": "connecting services across cloud-based platforms like kubernetes using things like",
    "start": "21039",
    "end": "26880"
  },
  {
    "text": "envoy proxy to build api gateways service mesh and thinking about it through the lens",
    "start": "26880",
    "end": "33520"
  },
  {
    "text": "of a multi multi-cluster and hybrid world how do we solve some of the difficult operator",
    "start": "33520",
    "end": "39600"
  },
  {
    "text": "challenges and we'll talk about some of those challenges in this talk i've been involved in the",
    "start": "39600",
    "end": "45920"
  },
  {
    "text": "open source community for quite a long time more recently i would say the last few years been focusing on service mesh",
    "start": "45920",
    "end": "52800"
  },
  {
    "text": "technologies kubernetes and istio and some of those related",
    "start": "52800",
    "end": "59359"
  },
  {
    "text": "ecosystem projects i've written some books on this topic i'm currently writing the istio in action book for",
    "start": "59359",
    "end": "67119"
  },
  {
    "text": "manning please reach out to me on twitter i blog about these topics quite frequently",
    "start": "67119",
    "end": "74479"
  },
  {
    "text": "and i have been doing so over the last five years so um just go take a look reach out if",
    "start": "74479",
    "end": "79920"
  },
  {
    "text": "you have any questions or thoughts so when we talk about deploying our",
    "start": "79920",
    "end": "86080"
  },
  {
    "text": "applications to these cloud-based platforms um",
    "start": "86080",
    "end": "91280"
  },
  {
    "text": "a lot of a lot of questions come up about how do we architect this how do we architect our applications",
    "start": "91280",
    "end": "97040"
  },
  {
    "text": "how do we take our failure domains and requirements for high availability and",
    "start": "97040",
    "end": "103680"
  },
  {
    "text": "certain compliance rules and so forth and how does this manifest how does this actually become concrete",
    "start": "103680",
    "end": "109840"
  },
  {
    "text": "and for those organizations adopting kubernetes and i've been working with them since pre kubernetes 1.0",
    "start": "109840",
    "end": "118240"
  },
  {
    "text": "we originally saw this this idea of deploying into large clusters and making the cluster",
    "start": "118240",
    "end": "124079"
  },
  {
    "text": "multi-tenant and highly available and so forth more recently i would say the last few",
    "start": "124079",
    "end": "129280"
  },
  {
    "text": "years we've seen a trend go more toward many having many smaller clusters where",
    "start": "129280",
    "end": "136000"
  },
  {
    "text": "you might have clusters dedicated for specific data locality reasons uh for specific",
    "start": "136000",
    "end": "142959"
  },
  {
    "text": "networking reasons maybe you have clusters at the edge in a dmz and different ones in your",
    "start": "142959",
    "end": "149120"
  },
  {
    "text": "core network for isolation performance reasons and compliance and",
    "start": "149120",
    "end": "156080"
  },
  {
    "text": "so forth we we see a lot of different uh motivation to going toward a",
    "start": "156080",
    "end": "162560"
  },
  {
    "text": "multi-cluster setup whether that's on premises and you're running multiple clusters of kubernetes",
    "start": "162560",
    "end": "169360"
  },
  {
    "text": "or in a public cloud like a eks or a gke",
    "start": "169360",
    "end": "174640"
  },
  {
    "text": "or both right so there might be uh when we run into customers and work with customers",
    "start": "174640",
    "end": "180560"
  },
  {
    "text": "to solve solutions for both on-prem and in a public cloud",
    "start": "180560",
    "end": "185760"
  },
  {
    "start": "185000",
    "end": "185000"
  },
  {
    "text": "and so that brings us to this need at times to share data between the clusters",
    "start": "185760",
    "end": "193040"
  },
  {
    "text": "to give the illusion or appearance of a sort of loose federation so that",
    "start": "193040",
    "end": "198080"
  },
  {
    "text": "services in these different clusters can talk with services in the other other clusters",
    "start": "198080",
    "end": "204239"
  },
  {
    "text": "and do that in a regulated way if if needed",
    "start": "204239",
    "end": "210000"
  },
  {
    "text": "but also in a more uniform way so we're not um dealing with the challenges of",
    "start": "210000",
    "end": "216879"
  },
  {
    "text": "you know configuring and managing applications across these different clusters completely independently",
    "start": "216879",
    "end": "222799"
  },
  {
    "text": "and having to bespoke try to figure out how to how to put the pieces together",
    "start": "222799",
    "end": "229599"
  },
  {
    "text": "so some patterns that emerge for solving this type of federation and",
    "start": "229599",
    "end": "236000"
  },
  {
    "text": "multi-cluster problem start with the most simple one",
    "start": "236000",
    "end": "241280"
  },
  {
    "start": "240000",
    "end": "240000"
  },
  {
    "text": "all right so we can have multiple clusters but we can have them all on the same network and have them all routable the",
    "start": "241280",
    "end": "247519"
  },
  {
    "text": "different applications and service services and pods within let's say kubernetes routable and talking directly",
    "start": "247519",
    "end": "254000"
  },
  {
    "text": "to each other and this is uh not a use case that we run into very often",
    "start": "254000",
    "end": "261120"
  },
  {
    "text": "uh but if you can achieve it it is simpler right and so trying to build these",
    "start": "261120",
    "end": "267520"
  },
  {
    "text": "microservice based platforms or or platforms to support microservices and so forth",
    "start": "267520",
    "end": "273520"
  },
  {
    "text": "um you know simple is good another option is if they're on",
    "start": "273520",
    "end": "278880"
  },
  {
    "start": "277000",
    "end": "277000"
  },
  {
    "text": "different networks is to expose the services running in a remote cluster",
    "start": "278880",
    "end": "285680"
  },
  {
    "text": "to anyone running outside of that that cluster and so maybe in a in a public",
    "start": "285680",
    "end": "291120"
  },
  {
    "text": "cloud you may expose these as cloud load balancers uh maybe internally",
    "start": "291120",
    "end": "297199"
  },
  {
    "text": "if you don't have load balance you might use something like node port and pin them to specific ports in your cluster",
    "start": "297199",
    "end": "303840"
  },
  {
    "text": "and this can have a very interesting",
    "start": "303840",
    "end": "309280"
  },
  {
    "text": "ramifications right you can have uh if you have a lot of services and you're trying to expose and",
    "start": "309280",
    "end": "315600"
  },
  {
    "text": "allow communication between the the clusters spinning up a load balancer for every single service can be very expensive",
    "start": "315600",
    "end": "323199"
  },
  {
    "text": "alternatively doing that with node ports that can be operationally very very",
    "start": "323199",
    "end": "328639"
  },
  {
    "text": "expensive in terms of now having to manage the port mappings avoiding port",
    "start": "328639",
    "end": "333680"
  },
  {
    "text": "collisions what happens when you have multiple versions of a service and so forth",
    "start": "333680",
    "end": "339440"
  },
  {
    "text": "so that but but it is it is a valid option as things that we've seen another option",
    "start": "339440",
    "end": "345759"
  },
  {
    "start": "343000",
    "end": "343000"
  },
  {
    "text": "is to expose the services in different clusters through a known",
    "start": "345759",
    "end": "352560"
  },
  {
    "text": "ingress point and for kubernetes cluster specific this is a fairly common pattern because",
    "start": "352560",
    "end": "358960"
  },
  {
    "text": "ingress is what's used to allow traffic into a particular cluster in the first",
    "start": "358960",
    "end": "364560"
  },
  {
    "text": "place and so if the if a cluster is trying to talk or application in cluster one is",
    "start": "364560",
    "end": "370479"
  },
  {
    "text": "trying to talk to services running in cluster two they're gonna have to go through the ingress now the trick is to get cluster one",
    "start": "370479",
    "end": "378400"
  },
  {
    "text": "to understand that when it talks to an application does it have to know exactly",
    "start": "378400",
    "end": "384479"
  },
  {
    "text": "that it's talking to another cluster so what can we do to transparently make",
    "start": "384479",
    "end": "390800"
  },
  {
    "text": "available the services in the other cluster such that the traffic does flow this way as we see in the diagram but",
    "start": "390800",
    "end": "398000"
  },
  {
    "text": "the applications in cluster one don't have to be all that aware of the topology because apology",
    "start": "398000",
    "end": "404000"
  },
  {
    "text": "changes so some of the things that we want to try to balance in a multi-cluster world",
    "start": "404000",
    "end": "411440"
  },
  {
    "start": "406000",
    "end": "406000"
  },
  {
    "text": "where we're trying to achieve this level of federation is security all right so the different application",
    "start": "411440",
    "end": "417840"
  },
  {
    "text": "workloads could be for example they might use a tls",
    "start": "417840",
    "end": "424000"
  },
  {
    "text": "or an authentication scheme that isn't consistent across the clusters and we",
    "start": "424000",
    "end": "429599"
  },
  {
    "text": "need to solve for something like that we need to solve for the problem i just described in the previous slide which is",
    "start": "429599",
    "end": "435199"
  },
  {
    "text": "how does a surface and cluster one know about know where it is and know how to talk to",
    "start": "435199",
    "end": "441759"
  },
  {
    "text": "a service in cluster two so we need to do something around service discovery",
    "start": "441759",
    "end": "447360"
  },
  {
    "text": "now when you have multiple multi-cluster setup and you have let's say the same either",
    "start": "447360",
    "end": "452479"
  },
  {
    "text": "this replicas exact same clusters you know multiple of those",
    "start": "452479",
    "end": "458160"
  },
  {
    "text": "or you just have the same service running in multiple clusters maybe they're not replicas but",
    "start": "458160",
    "end": "464400"
  },
  {
    "text": "if if traffic's coming into a particular service and it starts to fail or one of its",
    "start": "464400",
    "end": "470160"
  },
  {
    "text": "dependencies starts to fail you want to load a failover to a",
    "start": "470160",
    "end": "475520"
  },
  {
    "text": "different working service that might end up being in a different cluster so we need to solve for failover in a",
    "start": "475520",
    "end": "481360"
  },
  {
    "text": "multi-cluster scenario when you have these services running across",
    "start": "481360",
    "end": "486800"
  },
  {
    "text": "this highly distributed footprint in multiple clusters you need some way to",
    "start": "486800",
    "end": "491840"
  },
  {
    "text": "federate the telemetry and get a holistic understanding and view of what's",
    "start": "491840",
    "end": "496960"
  },
  {
    "text": "happening between the clusters and the applications that are communicating you got a design for",
    "start": "496960",
    "end": "504400"
  },
  {
    "text": "well understood and um you know",
    "start": "504400",
    "end": "510400"
  },
  {
    "text": "well thought fault domains so that you don't just accidentally",
    "start": "510400",
    "end": "516719"
  },
  {
    "text": "start creating a system that if one part of the system goes down",
    "start": "516719",
    "end": "523680"
  },
  {
    "text": "it starts to slowly take everything else down with it right so you want these isolated fault",
    "start": "523680",
    "end": "530080"
  },
  {
    "text": "planes and you don't want faults to jump uh jump the the different",
    "start": "530080",
    "end": "535200"
  },
  {
    "text": "boundaries that you set up so when we talk about services",
    "start": "535200",
    "end": "540320"
  },
  {
    "text": "communicating with each other and some of the challenges around that um you know for there's various ways of",
    "start": "540320",
    "end": "546399"
  },
  {
    "text": "solving some of the network or application networking challenges uh that crop up in that",
    "start": "546399",
    "end": "553920"
  },
  {
    "text": "in that area things like timeouts and retries load balancing client-side load balancing telemetry",
    "start": "553920",
    "end": "559920"
  },
  {
    "text": "collection service discovery so forth this is an area where a service mesh can",
    "start": "559920",
    "end": "566240"
  },
  {
    "text": "help now whether or not you need a service mesh for your use case that's you know let's let's put that aside",
    "start": "566240",
    "end": "572560"
  },
  {
    "text": "but a service mesh can help in this area and what we're seeing especially around multi-cluster support",
    "start": "572560",
    "end": "578399"
  },
  {
    "text": "is these different implementations continuing to mature so for example linker d which is heavily kubernetes",
    "start": "578399",
    "end": "584720"
  },
  {
    "text": "based just released um you know a little while ago the",
    "start": "584720",
    "end": "590560"
  },
  {
    "text": "their multi-cluster support in lingerie 2.8 istio has various flavors of",
    "start": "590560",
    "end": "597040"
  },
  {
    "text": "multi-cluster support console service mesh from hashicorp you know",
    "start": "597040",
    "end": "602399"
  },
  {
    "text": "there they have multi-cluster support and and so forth so definitely encourage you to take a look at each individual",
    "start": "602399",
    "end": "608320"
  },
  {
    "text": "implementation um and uh you know we can map it back to",
    "start": "608320",
    "end": "613600"
  },
  {
    "text": "some of the patterns that we talk about i will use some concrete examples in the in the rest of the presentation",
    "start": "613600",
    "end": "621360"
  },
  {
    "text": "but i encourage you to check out the implementation details for the mesh that you choose",
    "start": "621360",
    "end": "627760"
  },
  {
    "text": "so one of the building blocks of um quite a few service meshes",
    "start": "627760",
    "end": "634079"
  },
  {
    "text": "is a technology called envoy now envoy isn't the only way to build a service mesh and we see that linkerd",
    "start": "634079",
    "end": "640000"
  },
  {
    "start": "635000",
    "end": "635000"
  },
  {
    "text": "folks successfully built their own proxy um but then you know the",
    "start": "640000",
    "end": "645519"
  },
  {
    "text": "the istios the app matches the consoles and so forth they're they're built on unboying we see more kuma and so forth",
    "start": "645519",
    "end": "651600"
  },
  {
    "text": "um envoy has some interesting capabilities that make it",
    "start": "651600",
    "end": "658399"
  },
  {
    "text": "very well suited to both service mesh building service bench but some of the",
    "start": "658399",
    "end": "663680"
  },
  {
    "start": "663000",
    "end": "663000"
  },
  {
    "text": "uh solving some of the problems around multi-cluster so just to recap in a service mesh",
    "start": "663680",
    "end": "669279"
  },
  {
    "text": "setting envoy plays the role of the service proxy which is an agent or an",
    "start": "669279",
    "end": "675040"
  },
  {
    "text": "interceptor that gets deployed along with a particular application instance so this could be your jbm or your",
    "start": "675040",
    "end": "681680"
  },
  {
    "text": "node.js process and in that deployment whether that's a kubernetes pod which is",
    "start": "681680",
    "end": "687519"
  },
  {
    "text": "very nicely suited to run a deployment like this or a vm where you have a",
    "start": "687519",
    "end": "692720"
  },
  {
    "text": "virtual machine with your application running as well as envoy running next to it now the application talks through envoy",
    "start": "692720",
    "end": "700079"
  },
  {
    "text": "so all the network traffic going into the application or out of the application goes through",
    "start": "700079",
    "end": "706800"
  },
  {
    "text": "onboard proxy and envoy proxy has a lot of networking capabilities",
    "start": "706800",
    "end": "712880"
  },
  {
    "text": "at the l7 layer that that can do very sophisticated things like client-side load balancing priority",
    "start": "712880",
    "end": "720000"
  },
  {
    "text": "failover uh circuit breaking tls origination and termination",
    "start": "720000",
    "end": "725040"
  },
  {
    "text": "statistics collection and so forth right so envoy is a very powerful component and plays a large role in",
    "start": "725040",
    "end": "731519"
  },
  {
    "text": "uh in the solution that we're going to be and the solutions and the patterns that we're going to be talking about",
    "start": "731519",
    "end": "737279"
  },
  {
    "start": "736000",
    "end": "736000"
  },
  {
    "text": "so envoy we see as a",
    "start": "737600",
    "end": "743200"
  },
  {
    "text": "integral part to some of these service mesh implementations some of the features that envoy brings",
    "start": "743200",
    "end": "750639"
  },
  {
    "start": "749000",
    "end": "749000"
  },
  {
    "text": "the table things like request hedging things like retries and retry budgets",
    "start": "750639",
    "end": "757440"
  },
  {
    "text": "load balancing and locality aware load balancing or",
    "start": "757440",
    "end": "762880"
  },
  {
    "text": "zone aware routing so we can route to different zones based on failure parameters",
    "start": "762880",
    "end": "769279"
  },
  {
    "text": "things like aggregated cluster it and point some of these these features in envoy",
    "start": "769279",
    "end": "776000"
  },
  {
    "start": "775000",
    "end": "775000"
  },
  {
    "text": "something like zone aware routing can be very helpful in a multi-cluster world",
    "start": "776240",
    "end": "782480"
  },
  {
    "text": "so with zone aware routing envoy routes traffic to and upstream and upstream is a",
    "start": "782480",
    "end": "789600"
  },
  {
    "text": "service that you know the target service that the traffic needs to go to and if things start to fail",
    "start": "789600",
    "end": "796639"
  },
  {
    "text": "envoy can make a decision about how to spill over into let's say",
    "start": "796639",
    "end": "801920"
  },
  {
    "text": "another availability zone or you know envoy can prefer",
    "start": "801920",
    "end": "807600"
  },
  {
    "text": "calling services in its availability zone and fail over to others and potentially to other regions uh as",
    "start": "807600",
    "end": "815279"
  },
  {
    "text": "you know as as the as the healthy services start to become unhealthy so on envoy can make that",
    "start": "815279",
    "end": "822079"
  },
  {
    "text": "distinction and that determination so you can imagine that if envoy's calling services locally in its cluster",
    "start": "822079",
    "end": "830079"
  },
  {
    "text": "that it could potentially fall over or fail over to services outside of that of",
    "start": "830079",
    "end": "836000"
  },
  {
    "text": "those zones another approach is very similar to zona ware routing",
    "start": "836000",
    "end": "842639"
  },
  {
    "start": "837000",
    "end": "837000"
  },
  {
    "text": "it's not exactly the same but it's called locality aware and in the zone aware example",
    "start": "842639",
    "end": "849199"
  },
  {
    "text": "we saw envoy having the heuristics on its in the proxy itself to make the",
    "start": "849199",
    "end": "854639"
  },
  {
    "text": "determination of when to fail over locality aware load balancing is more of",
    "start": "854639",
    "end": "860079"
  },
  {
    "text": "a weighted load balancing that's driven by the control plane so in this case the service mesh control plane so the",
    "start": "860079",
    "end": "866480"
  },
  {
    "text": "service mesh control plane might know where the different endpoints are potentially in different clusters",
    "start": "866480",
    "end": "871920"
  },
  {
    "text": "and and configure the envoy proxy running with the application",
    "start": "871920",
    "end": "878240"
  },
  {
    "text": "with that knowledge of that that locality awareness and the weights that need to be assigned for the different uh",
    "start": "878240",
    "end": "885279"
  },
  {
    "text": "localities so you again can prefer communication from service in this case",
    "start": "885279",
    "end": "891360"
  },
  {
    "text": "account to you know whatever other dependent service it has",
    "start": "891360",
    "end": "896800"
  },
  {
    "text": "to be local so in the same let's say availability zone or same subset",
    "start": "896800",
    "end": "902959"
  },
  {
    "text": "and then if that starts to go you know those endpoints become unhealthy then we can slowly fail over",
    "start": "902959",
    "end": "909199"
  },
  {
    "text": "to the next availability zone or region",
    "start": "909199",
    "end": "914480"
  },
  {
    "text": "and so forth but this locality awareness is driven by again the control plane not",
    "start": "914480",
    "end": "919600"
  },
  {
    "text": "envoy making the decision itself another another approach that envoy allows for",
    "start": "919600",
    "end": "927920"
  },
  {
    "start": "921000",
    "end": "921000"
  },
  {
    "text": "is configuring a a priority fallback so if we're talking again locally",
    "start": "927920",
    "end": "935839"
  },
  {
    "text": "services communicating locally and they start to become unhealthy",
    "start": "935839",
    "end": "940959"
  },
  {
    "text": "envoy can route instead of to the local unhealthy services can route to",
    "start": "940959",
    "end": "948399"
  },
  {
    "text": "a different you know different fallback services that may be running in a different cluster and may have different",
    "start": "948399",
    "end": "954800"
  },
  {
    "text": "load balancing parameters and so forth so i'm going to tell this to aggregate cluster where you can",
    "start": "954800",
    "end": "960320"
  },
  {
    "text": "for for a single upstream that you're trying to call regardless of where that lives you can",
    "start": "960320",
    "end": "965519"
  },
  {
    "text": "have priority and and fall back configured for that",
    "start": "965519",
    "end": "971519"
  },
  {
    "text": "so let's look at some patterns for this uh this multi this multi-cluster",
    "start": "971519",
    "end": "978800"
  },
  {
    "text": "world in in terms of service mesh all right so where you have",
    "start": "978800",
    "end": "984000"
  },
  {
    "start": "981000",
    "end": "981000"
  },
  {
    "text": "again starting at the beginning where you have a flat network and you may",
    "start": "984000",
    "end": "989040"
  },
  {
    "text": "have a shared control plane for the service mesh so now you have you have services",
    "start": "989040",
    "end": "994880"
  },
  {
    "text": "running in different clusters but like we said in the beginning if you have a flat network and they're directly",
    "start": "994880",
    "end": "1000399"
  },
  {
    "text": "addressable the services can just reach out and talk with each other the control plane can",
    "start": "1000399",
    "end": "1006399"
  },
  {
    "text": "build a locality awareness into the into the the different",
    "start": "1006399",
    "end": "1012240"
  },
  {
    "text": "proxies so that for example when account is calling the user service it will prefer to call the user service",
    "start": "1012240",
    "end": "1019680"
  },
  {
    "text": "in its same locality but then fail over to other ones when you know or if that that service",
    "start": "1019680",
    "end": "1026720"
  },
  {
    "text": "vocally starts to fail so um in in this case you know you have",
    "start": "1026720",
    "end": "1032720"
  },
  {
    "text": "your direct routing you don't have you don't have to use anything special here it's fairly simple",
    "start": "1032720",
    "end": "1039360"
  },
  {
    "text": "and but you still need to figure out a way to federate that telemetry using something like prometheus or datadog how",
    "start": "1039360",
    "end": "1046798"
  },
  {
    "text": "do you get the telemetry from the different clusters into a single pane of glass",
    "start": "1046799",
    "end": "1054240"
  },
  {
    "start": "1054000",
    "end": "1054000"
  },
  {
    "text": "another approach is when you have separate networks the you know the",
    "start": "1054559",
    "end": "1061280"
  },
  {
    "text": "the structure of the service mesh is the same but in different networks the applications across clusters cannot talk",
    "start": "1061280",
    "end": "1067919"
  },
  {
    "text": "directly to each other so in this case they need to go through an ingress or a gateway component",
    "start": "1067919",
    "end": "1075520"
  },
  {
    "text": "and the control plane should be smart enough to build the service mirroring",
    "start": "1075520",
    "end": "1082880"
  },
  {
    "text": "uh so that the account service when it talks to user",
    "start": "1082880",
    "end": "1088240"
  },
  {
    "text": "knows that if it talks to user that it will prefer local but if user starts to",
    "start": "1088240",
    "end": "1094880"
  },
  {
    "text": "become unhealthy that it needs to fail over to the second cluster through that",
    "start": "1094880",
    "end": "1100080"
  },
  {
    "text": "cluster's gateway and the control plane can be smart enough to create the illusion or the mirroring",
    "start": "1100080",
    "end": "1107120"
  },
  {
    "text": "configuration necessary so that when account talks to user it actually talks directly to that other",
    "start": "1107120",
    "end": "1112640"
  },
  {
    "text": "gateway not to um you know the user that's running in the second in the second or remote",
    "start": "1112640",
    "end": "1118880"
  },
  {
    "text": "cluster because those separate networks here right so we do we do need to make that hot through the gateway",
    "start": "1118880",
    "end": "1125919"
  },
  {
    "text": "so in this in this model you know we have different networks which is good but we have the same control plane still",
    "start": "1126080",
    "end": "1132480"
  },
  {
    "text": "so just like in the previous example the the control plane across the surface",
    "start": "1132480",
    "end": "1137840"
  },
  {
    "text": "mesh is in the same failure domain so that goes down in cluster one",
    "start": "1137840",
    "end": "1142880"
  },
  {
    "text": "it all you know gets affected and uh and you you have this increase in",
    "start": "1142880",
    "end": "1150480"
  },
  {
    "text": "burden on the operator to automate and label the networks and some of these endpoints correctly so you know",
    "start": "1150480",
    "end": "1157760"
  },
  {
    "text": "that for this one control plane where the different endpoints are the last pattern we'll look at is having",
    "start": "1157760",
    "end": "1166160"
  },
  {
    "start": "1161000",
    "end": "1161000"
  },
  {
    "text": "separate control planes and one per",
    "start": "1166160",
    "end": "1171360"
  },
  {
    "text": "cluster right so we kind of solve the failure domain problem here so if the control plane cluster one goes",
    "start": "1171360",
    "end": "1177120"
  },
  {
    "text": "down it doesn't affect the operability of cluster two it has its own control plane",
    "start": "1177120",
    "end": "1182320"
  },
  {
    "text": "but the traffic flow is similar it's going through the gateway at each of the different clusters",
    "start": "1182320",
    "end": "1189440"
  },
  {
    "text": "again there's that burden on the operator or the service mesh itself to somehow",
    "start": "1189440",
    "end": "1195760"
  },
  {
    "text": "automate the sharing of the right configuration",
    "start": "1195760",
    "end": "1200799"
  },
  {
    "text": "so that the account service and cluster one when it talks to user can correctly route to or fail over",
    "start": "1200799",
    "end": "1208480"
  },
  {
    "text": "to the user service running in cluster 2. and so there's there's some configuration magic some overhead that",
    "start": "1208480",
    "end": "1215919"
  },
  {
    "text": "is placed on the operator to get this in place to work",
    "start": "1215919",
    "end": "1221280"
  },
  {
    "text": "now each service mesh implementation deals with it and defines this",
    "start": "1221280",
    "end": "1227760"
  },
  {
    "text": "metadata or this mirroring configuration mirroring um differently so check out the different",
    "start": "1227760",
    "end": "1234320"
  },
  {
    "text": "implementations but in this case we are able to keep separate failure domains",
    "start": "1234320",
    "end": "1240559"
  },
  {
    "text": "we are able to have control and be very opinionated about what services",
    "start": "1240559",
    "end": "1247520"
  },
  {
    "text": "should be mirrored across the network and",
    "start": "1247520",
    "end": "1252960"
  },
  {
    "text": "it it allows the traffic to",
    "start": "1252960",
    "end": "1258240"
  },
  {
    "text": "flow through the network and across to these different clusters through the ingress",
    "start": "1258240",
    "end": "1263520"
  },
  {
    "text": "points as we expect right so we have a nice and uniform",
    "start": "1263520",
    "end": "1268880"
  },
  {
    "text": "controlled way of traffic flowing through the network so again",
    "start": "1268880",
    "end": "1274320"
  },
  {
    "text": "this the things that we need to solve we still need to figure out a way to um",
    "start": "1274320",
    "end": "1280960"
  },
  {
    "text": "get get a shared identity for the services so that we can uh",
    "start": "1280960",
    "end": "1286080"
  },
  {
    "text": "take advantage of the service mesh's capabilities to do authentication and authorization",
    "start": "1286080",
    "end": "1292559"
  },
  {
    "text": "all right so we need some way to set that up and automate that uh we need some way to",
    "start": "1292559",
    "end": "1298000"
  },
  {
    "text": "define and uh create and orchestrate basically the the mirroring configuration",
    "start": "1298000",
    "end": "1304799"
  },
  {
    "text": "so that services can call from one cluster to the other",
    "start": "1304799",
    "end": "1309919"
  },
  {
    "text": "through the others gateway all right without having to know that it's actually going to the gateway",
    "start": "1309919",
    "end": "1315679"
  },
  {
    "text": "so there's some service discovery orchestration that needs to happen there we need the capability to",
    "start": "1315679",
    "end": "1321840"
  },
  {
    "text": "define traffic rules for these different services",
    "start": "1321840",
    "end": "1327200"
  },
  {
    "text": "with the multi-cluster use case in mind all right so this is going to involve",
    "start": "1327200",
    "end": "1332320"
  },
  {
    "text": "more automation and um shuffling configurations around to get the illusion of",
    "start": "1332320",
    "end": "1338640"
  },
  {
    "text": "uh you know a single federated um name namespace i guess for these different",
    "start": "1338640",
    "end": "1344640"
  },
  {
    "text": "services so you know this this ends up being",
    "start": "1344640",
    "end": "1350720"
  },
  {
    "text": "shifted from the from the um the mesh all right",
    "start": "1350720",
    "end": "1356080"
  },
  {
    "text": "to the operator now operator is responsible for all these things and that can be a lot",
    "start": "1356080",
    "end": "1361679"
  },
  {
    "text": "that can be a lot to set up more importantly there can be a lot to maintain going forward because",
    "start": "1361679",
    "end": "1367120"
  },
  {
    "text": "you know the these topologies changes the services change they move um you know that",
    "start": "1367120",
    "end": "1373280"
  },
  {
    "text": "it is a constantly evolving system and so that's where so we at solo we've",
    "start": "1373280",
    "end": "1379280"
  },
  {
    "text": "we've built an open source project to help solve this and",
    "start": "1379280",
    "end": "1384400"
  },
  {
    "text": "this project is intended to be mesh agnostic like i said each mesh",
    "start": "1384400",
    "end": "1390720"
  },
  {
    "text": "implements these patterns roughly uh but a little bit differently",
    "start": "1390720",
    "end": "1396799"
  },
  {
    "text": "and without having to go into the details and some of these very low level apis",
    "start": "1396799",
    "end": "1402559"
  },
  {
    "text": "service mesh hub allows you to automate a lot of that operational burden away regardless of",
    "start": "1402559",
    "end": "1410720"
  },
  {
    "text": "the mesh that you pick and so in our architecture what that would look like",
    "start": "1410720",
    "end": "1416400"
  },
  {
    "text": "is service mesh hub running in its management plane able to",
    "start": "1416400",
    "end": "1422240"
  },
  {
    "text": "do the configuration shuffling uh the service mirroring uh the traffic control",
    "start": "1422240",
    "end": "1429200"
  },
  {
    "text": "regardless of you know how many clusters that you have",
    "start": "1429200",
    "end": "1434720"
  },
  {
    "text": "and you can be very multi-cluster aware in the configuration",
    "start": "1434720",
    "end": "1440799"
  },
  {
    "text": "that you use to drive this behavior so it's probably best i have a few minutes left here to to show",
    "start": "1440799",
    "end": "1446720"
  },
  {
    "text": "you a quick demo of what that looks like um",
    "start": "1446720",
    "end": "1452960"
  },
  {
    "text": "let's do the let's do the quick one",
    "start": "1453679",
    "end": "1459279"
  },
  {
    "text": "all right so we have two clusters what we're going to do is we're going to install service mesh hub into one of the",
    "start": "1459279",
    "end": "1466159"
  },
  {
    "text": "clusters one thing i do want to point out uh this is the approximate",
    "start": "1466159",
    "end": "1472320"
  },
  {
    "text": "architecture for the demo like i said this is this is how you would really set up service manager but",
    "start": "1472320",
    "end": "1477679"
  },
  {
    "text": "we're gonna instead of using a separate cluster we're gonna co-locate that into cluster number one and call that the",
    "start": "1477679",
    "end": "1483440"
  },
  {
    "text": "management plane and cluster number two we'll call that the remote cluster so it looks like we've installed",
    "start": "1483440",
    "end": "1490559"
  },
  {
    "text": "service mesh hub if we take a look at it we see we have the controllers that make up",
    "start": "1490559",
    "end": "1496720"
  },
  {
    "text": "the the orchestration of these different meshes here",
    "start": "1496720",
    "end": "1501760"
  },
  {
    "text": "now what we're gonna do is verify validate that the service mesh hub was installed",
    "start": "1501760",
    "end": "1507919"
  },
  {
    "text": "correctly and it looks as though it has been let's register our cluster one and our",
    "start": "1507919",
    "end": "1514799"
  },
  {
    "text": "cluster two so that service measure knows about these clusters and then service measure",
    "start": "1514799",
    "end": "1520799"
  },
  {
    "text": "will go out once it knows about them and it will try to discover what kind of mesh is running on those",
    "start": "1520799",
    "end": "1527919"
  },
  {
    "text": "clusters so at the moment the discovery is able to find clusters based on istio",
    "start": "1527919",
    "end": "1534320"
  },
  {
    "text": "clusters based on linker d and clusters based on console service",
    "start": "1534320",
    "end": "1540720"
  },
  {
    "text": "mesh as well as so it's based on app mesh from aws and the",
    "start": "1540720",
    "end": "1547039"
  },
  {
    "text": "architecture for surface machine is fairly uh plug or very plugable so that we can plug in additional ones",
    "start": "1547039",
    "end": "1554720"
  },
  {
    "text": "like like akuma or whatever pretty easily so",
    "start": "1554720",
    "end": "1560080"
  },
  {
    "text": "we have cluster one registered cluster two seems to be",
    "start": "1560080",
    "end": "1566320"
  },
  {
    "text": "okay now registered now let's see let's see what service mesh hub has",
    "start": "1566320",
    "end": "1573039"
  },
  {
    "text": "found so firstly we see the clusters that we registered and knows about those so that's a good step",
    "start": "1573039",
    "end": "1579760"
  },
  {
    "text": "the second thing is let's ask service mesh hub what meshes are running",
    "start": "1579760",
    "end": "1584880"
  },
  {
    "text": "in these different clusters we see we actually have two istio clusters one running in cluster",
    "start": "1584880",
    "end": "1590480"
  },
  {
    "text": "one one running in cluster two",
    "start": "1590480",
    "end": "1595840"
  },
  {
    "text": "now let's see how easy it is to start to build the federation automation around these two different service meshes that",
    "start": "1596080",
    "end": "1603279"
  },
  {
    "text": "have been deployed so in service mesh hub we have a resource called this virtual mesh",
    "start": "1603279",
    "end": "1610240"
  },
  {
    "text": "and the virtual mesh is a way of defining the different federation mode",
    "start": "1610240",
    "end": "1616720"
  },
  {
    "text": "the identity sharing or the the identity federation mode um whether or not access control is",
    "start": "1616720",
    "end": "1623360"
  },
  {
    "text": "enabled um you know giving it a root signing certificate so we can",
    "start": "1623360",
    "end": "1630240"
  },
  {
    "text": "bring the different service meshes under the same root trust domain",
    "start": "1630240",
    "end": "1635279"
  },
  {
    "text": "and in this case we're specifying exactly which meshes that we want to federate",
    "start": "1635279",
    "end": "1641520"
  },
  {
    "text": "so now if we apply that service mesh hub will then start to do",
    "start": "1641520",
    "end": "1646880"
  },
  {
    "text": "some of the automation around building the federation for these meshes",
    "start": "1646880",
    "end": "1652880"
  },
  {
    "text": "and let's take a look at the virtual mesh and cross our",
    "start": "1652880",
    "end": "1658080"
  },
  {
    "text": "fingers we see that the federation has been accepted all the",
    "start": "1658080",
    "end": "1663679"
  },
  {
    "text": "config looks good the certificates for unifying the identity looks good",
    "start": "1663679",
    "end": "1668799"
  },
  {
    "text": "and the information around access control which we haven't specified anything yet looks",
    "start": "1668799",
    "end": "1674080"
  },
  {
    "text": "good so we'll give it a second using this federated",
    "start": "1674080",
    "end": "1679440"
  },
  {
    "text": "mesh we can do things like uh in this case we'll look at what it",
    "start": "1679440",
    "end": "1684960"
  },
  {
    "text": "what it created in terms of service discovery so the service mirroring part the configuration in istio uses an",
    "start": "1684960",
    "end": "1691200"
  },
  {
    "text": "object called the service entry and we see that in cluster number one we have entries for the services that",
    "start": "1691200",
    "end": "1697679"
  },
  {
    "text": "are running in cluster number two and vice versa",
    "start": "1697679",
    "end": "1703600"
  },
  {
    "text": "all right so now the services in cluster two can call the services running in cluster",
    "start": "1703840",
    "end": "1709440"
  },
  {
    "text": "one uh servicemenship can also do a global uh globally unique namespace for the",
    "start": "1709440",
    "end": "1715440"
  },
  {
    "text": "different services so that you don't have to have have them cluster aware but in this demo we're we're showing",
    "start": "1715440",
    "end": "1722080"
  },
  {
    "text": "how you know that automation can be can be put in place now the last thing we're going to look",
    "start": "1722080",
    "end": "1727600"
  },
  {
    "text": "at is the traffic routing api that we can enable for",
    "start": "1727600",
    "end": "1733520"
  },
  {
    "text": "service through the for the clusters right it's basically a way of orchestrating",
    "start": "1733520",
    "end": "1739760"
  },
  {
    "text": "traffic policies and traffic rules in a multi-cluster aware way",
    "start": "1739760",
    "end": "1745120"
  },
  {
    "text": "you know using this this abstraction this federation that we built on top of it so if we apply this resource",
    "start": "1745120",
    "end": "1754960"
  },
  {
    "text": "what this is going to allow us to do is call the so this is using the book info demo in",
    "start": "1755120",
    "end": "1761919"
  },
  {
    "text": "istio we're going to be able to call between cluster one and cluster two do i have",
    "start": "1761919",
    "end": "1767520"
  },
  {
    "text": "the port forwarding thing no but all right i guess i won't show the port forwarding thing but what we can see is",
    "start": "1767520",
    "end": "1773600"
  },
  {
    "text": "uh automatically the different resources under the cover for in this case istio",
    "start": "1773600",
    "end": "1780480"
  },
  {
    "text": "were automatically created all right so again what servicemenship is doing",
    "start": "1780480",
    "end": "1785919"
  },
  {
    "text": "is uh using the primitives of each mesh which those apis might be slightly",
    "start": "1785919",
    "end": "1791679"
  },
  {
    "text": "different but we unify those apis into a multi-cluster aware api",
    "start": "1791679",
    "end": "1798559"
  },
  {
    "text": "independent of the mesh and then service mesh hub goes off and orchestrates the lower level service",
    "start": "1798559",
    "end": "1805840"
  },
  {
    "text": "mesh apis to enable things like routing across the track acro across the clusters",
    "start": "1805840",
    "end": "1812799"
  },
  {
    "text": "putting virtual surfaces in the istio case in the different clusters",
    "start": "1812799",
    "end": "1817840"
  },
  {
    "text": "unifying the trust domains automatically enabling access control and and so forth",
    "start": "1817840",
    "end": "1824240"
  },
  {
    "text": "without the operator having to go and do uh do this in either manually or setting",
    "start": "1824240",
    "end": "1830320"
  },
  {
    "text": "up that automation and then maintaining that automation so service mesh hub is a very powerful",
    "start": "1830320",
    "end": "1837200"
  },
  {
    "text": "project uh the last thing i guess i'll show is that we can pull back any other any of the rules",
    "start": "1837200",
    "end": "1842960"
  },
  {
    "text": "that apply even if there's multiple rules that apply to a particular service uh fairly simply",
    "start": "1842960",
    "end": "1848960"
  },
  {
    "text": "so that is uh um you know how how do we how do we build this type of system",
    "start": "1848960",
    "end": "1855279"
  },
  {
    "text": "following some well-known patterns the service meshes typically implement those um but then you know nothing's free so",
    "start": "1855279",
    "end": "1863039"
  },
  {
    "text": "you get this operational challenge that and burden that you have to solve for",
    "start": "1863039",
    "end": "1868960"
  },
  {
    "text": "and that is where the service mesh hub project helps so i thank you for joining this talk",
    "start": "1868960",
    "end": "1877440"
  },
  {
    "text": "and i hope you enjoyed the previous talks in this track for service mesh con",
    "start": "1877440",
    "end": "1882720"
  },
  {
    "text": "i think there's a couple left and then we get to the closing remarks from nick jackson",
    "start": "1882720",
    "end": "1889200"
  },
  {
    "text": "but uh go check out you know link or d go check out istio and console and and",
    "start": "1889200",
    "end": "1895679"
  },
  {
    "text": "some of these other ones kuma just joined the cncf go check out kuma and uh and come take a look at us and",
    "start": "1895679",
    "end": "1902240"
  },
  {
    "text": "what we're doing at solo but i thank you for your time and sorry we couldn't be in person",
    "start": "1902240",
    "end": "1909279"
  },
  {
    "text": "next time i hope to come out to kubecon eu and so stay stay safe and stay healthy thanks",
    "start": "1909279",
    "end": "1919320"
  }
]
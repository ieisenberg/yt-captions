[
  {
    "start": "0",
    "end": "38000"
  },
  {
    "text": "so welcome to our presentation hope you",
    "start": "0",
    "end": "2760"
  },
  {
    "text": "guys had a very nice morning very",
    "start": "2760",
    "end": "4680"
  },
  {
    "text": "interesting keynote there we're going to",
    "start": "4680",
    "end": "6779"
  },
  {
    "text": "talk about large-scale batch processing",
    "start": "6779",
    "end": "9179"
  },
  {
    "text": "with Argo workflow and events myself",
    "start": "9179",
    "end": "12360"
  },
  {
    "text": "Rakesh I work as a back-end engineer in",
    "start": "12360",
    "end": "15599"
  },
  {
    "text": "intuits data processing organization and",
    "start": "15599",
    "end": "18300"
  },
  {
    "text": "I have with me a co-presenter Bala he's",
    "start": "18300",
    "end": "22020"
  },
  {
    "text": "the MVP he's the core contributor and",
    "start": "22020",
    "end": "24840"
  },
  {
    "text": "developer of Argo workflow so give him a",
    "start": "24840",
    "end": "27840"
  },
  {
    "text": "good shout out",
    "start": "27840",
    "end": "30380"
  },
  {
    "text": "so you guys can bug him with a lot of",
    "start": "31199",
    "end": "33360"
  },
  {
    "text": "questions so right after the",
    "start": "33360",
    "end": "36000"
  },
  {
    "text": "presentation",
    "start": "36000",
    "end": "38520"
  },
  {
    "start": "38000",
    "end": "38000"
  },
  {
    "text": "so in this presentation we'll be",
    "start": "38520",
    "end": "40860"
  },
  {
    "text": "covering into its background overview of",
    "start": "40860",
    "end": "44219"
  },
  {
    "text": "batch processing platform the use case",
    "start": "44219",
    "end": "46440"
  },
  {
    "text": "why we built it architecture and how it",
    "start": "46440",
    "end": "49680"
  },
  {
    "text": "integrates with our go workflow and Argo",
    "start": "49680",
    "end": "52140"
  },
  {
    "text": "events following that we'll talk about",
    "start": "52140",
    "end": "54320"
  },
  {
    "text": "the scaling challenges the scalability",
    "start": "54320",
    "end": "57360"
  },
  {
    "text": "journey that we went through and the",
    "start": "57360",
    "end": "59699"
  },
  {
    "text": "efforts that went into getting into",
    "start": "59699",
    "end": "61920"
  },
  {
    "text": "production scale and we will wrap up the",
    "start": "61920",
    "end": "64799"
  },
  {
    "text": "presentation with a quick demo and",
    "start": "64799",
    "end": "67140"
  },
  {
    "text": "what's next that what's coming next in",
    "start": "67140",
    "end": "69420"
  },
  {
    "text": "the Argo events and workflow and what's",
    "start": "69420",
    "end": "71760"
  },
  {
    "text": "cooking",
    "start": "71760",
    "end": "74040"
  },
  {
    "text": "so",
    "start": "74040",
    "end": "75720"
  },
  {
    "text": "um before we get into the presentation a",
    "start": "75720",
    "end": "78000"
  },
  {
    "text": "quick shout out to um what Intuit does",
    "start": "78000",
    "end": "79979"
  },
  {
    "text": "into you as you guys are aware of it's a",
    "start": "79979",
    "end": "82020"
  },
  {
    "text": "global technology platform",
    "start": "82020",
    "end": "84180"
  },
  {
    "text": "um that helps customers Achieve",
    "start": "84180",
    "end": "86040"
  },
  {
    "text": "Financial confidence we have over 100",
    "start": "86040",
    "end": "88320"
  },
  {
    "text": "million customers",
    "start": "88320",
    "end": "89939"
  },
  {
    "text": "um in the across the world 14 000",
    "start": "89939",
    "end": "92340"
  },
  {
    "text": "employees working really hard to serve",
    "start": "92340",
    "end": "94560"
  },
  {
    "text": "those customers and we are a strong open",
    "start": "94560",
    "end": "98159"
  },
  {
    "text": "source contributor both in promoting and",
    "start": "98159",
    "end": "100740"
  },
  {
    "text": "also Building open source projects and",
    "start": "100740",
    "end": "103740"
  },
  {
    "text": "getting it out there",
    "start": "103740",
    "end": "106520"
  },
  {
    "text": "so in this slide",
    "start": "106560",
    "end": "108320"
  },
  {
    "text": "we'll start with the batch processing",
    "start": "108320",
    "end": "111060"
  },
  {
    "text": "platform overview starting with some",
    "start": "111060",
    "end": "115320"
  },
  {
    "text": "personas who's the target audience that",
    "start": "115320",
    "end": "117840"
  },
  {
    "text": "we built the presentation for",
    "start": "117840",
    "end": "119899"
  },
  {
    "text": "the platform for and uh so before we",
    "start": "119899",
    "end": "124500"
  },
  {
    "text": "Deep dive I wanted to briefly touch upon",
    "start": "124500",
    "end": "126420"
  },
  {
    "text": "some of the personas",
    "start": "126420",
    "end": "128119"
  },
  {
    "text": "that the processing platform helps with",
    "start": "128119",
    "end": "130800"
  },
  {
    "text": "data engineer who wants to focus on",
    "start": "130800",
    "end": "134280"
  },
  {
    "text": "transforming data rapidly so that they",
    "start": "134280",
    "end": "136500"
  },
  {
    "text": "can Aid their customers a data scientist",
    "start": "136500",
    "end": "139200"
  },
  {
    "text": "who wants to build ml models at a faster",
    "start": "139200",
    "end": "141900"
  },
  {
    "text": "rate and make their applications more",
    "start": "141900",
    "end": "143760"
  },
  {
    "text": "intelligent and platform Engineers who",
    "start": "143760",
    "end": "146640"
  },
  {
    "text": "wants to build data engineering",
    "start": "146640",
    "end": "148379"
  },
  {
    "text": "applications so that they can provide",
    "start": "148379",
    "end": "151560"
  },
  {
    "text": "these applications to other data",
    "start": "151560",
    "end": "153720"
  },
  {
    "text": "personas who can build better data",
    "start": "153720",
    "end": "156360"
  },
  {
    "text": "processing models",
    "start": "156360",
    "end": "158760"
  },
  {
    "start": "158000",
    "end": "158000"
  },
  {
    "text": "so let's talk about",
    "start": "158760",
    "end": "160920"
  },
  {
    "text": "um in this slide we'll talk about the",
    "start": "160920",
    "end": "162420"
  },
  {
    "text": "intuits data processing flow from a very",
    "start": "162420",
    "end": "165060"
  },
  {
    "text": "high level",
    "start": "165060",
    "end": "166140"
  },
  {
    "text": "um so Intuit has several customer facing",
    "start": "166140",
    "end": "167940"
  },
  {
    "text": "products with millions of users um be it",
    "start": "167940",
    "end": "170580"
  },
  {
    "text": "small businesses tax filing and also for",
    "start": "170580",
    "end": "174060"
  },
  {
    "text": "verifying your financial health so",
    "start": "174060",
    "end": "176760"
  },
  {
    "text": "between the products before the data",
    "start": "176760",
    "end": "180300"
  },
  {
    "text": "with the data that we get there are a",
    "start": "180300",
    "end": "182879"
  },
  {
    "text": "lot of use cases that we serve with the",
    "start": "182879",
    "end": "185340"
  },
  {
    "text": "data we need data storage real-time",
    "start": "185340",
    "end": "187860"
  },
  {
    "text": "recommendations to the users data",
    "start": "187860",
    "end": "189660"
  },
  {
    "text": "enrichment their accuration fraud",
    "start": "189660",
    "end": "192300"
  },
  {
    "text": "detection so from the product lineup",
    "start": "192300",
    "end": "194700"
  },
  {
    "text": "before the data arrives and into its",
    "start": "194700",
    "end": "196379"
  },
  {
    "text": "data Lake we have a real-time",
    "start": "196379",
    "end": "199099"
  },
  {
    "text": "Transformations done using our stream",
    "start": "199099",
    "end": "201180"
  },
  {
    "text": "processing platform and once the data",
    "start": "201180",
    "end": "203459"
  },
  {
    "text": "arrives in the data Lake we have batch",
    "start": "203459",
    "end": "206280"
  },
  {
    "text": "platforms performing post-processing and",
    "start": "206280",
    "end": "208860"
  },
  {
    "text": "Analysis which from which we'll get",
    "start": "208860",
    "end": "211920"
  },
  {
    "text": "reporting model training feature",
    "start": "211920",
    "end": "213540"
  },
  {
    "text": "creation and other",
    "start": "213540",
    "end": "216140"
  },
  {
    "text": "data that can be used for real time and",
    "start": "216140",
    "end": "219360"
  },
  {
    "text": "semi real-time feedbacks back to the",
    "start": "219360",
    "end": "221220"
  },
  {
    "text": "products",
    "start": "221220",
    "end": "223640"
  },
  {
    "text": "so with that in mind I will talk about",
    "start": "223739",
    "end": "226019"
  },
  {
    "text": "the intuits batch processing",
    "start": "226019",
    "end": "227879"
  },
  {
    "text": "requirements from a platform standpoint",
    "start": "227879",
    "end": "230040"
  },
  {
    "text": "we wanted to build a company-wide",
    "start": "230040",
    "end": "232620"
  },
  {
    "text": "solutioning for scheduling and",
    "start": "232620",
    "end": "234239"
  },
  {
    "text": "orchestration a lot of the teams want to",
    "start": "234239",
    "end": "236420"
  },
  {
    "text": "have data pipelines or applications",
    "start": "236420",
    "end": "239640"
  },
  {
    "text": "running on a schedule and data is",
    "start": "239640",
    "end": "242580"
  },
  {
    "text": "usually interconnected so we wanted to",
    "start": "242580",
    "end": "244680"
  },
  {
    "text": "provide dependency management for data",
    "start": "244680",
    "end": "247560"
  },
  {
    "text": "pipelines and applications we wanted to",
    "start": "247560",
    "end": "250019"
  },
  {
    "text": "provide a standardized run to runtime",
    "start": "250019",
    "end": "251939"
  },
  {
    "text": "compute layer for data and other",
    "start": "251939",
    "end": "253799"
  },
  {
    "text": "processing use cases in into batch",
    "start": "253799",
    "end": "256500"
  },
  {
    "text": "processing we support spark and",
    "start": "256500",
    "end": "258600"
  },
  {
    "text": "containerized application runtimes in",
    "start": "258600",
    "end": "261959"
  },
  {
    "text": "multiple kubernetes clusters that we",
    "start": "261959",
    "end": "263639"
  },
  {
    "text": "manage we provide the seamless",
    "start": "263639",
    "end": "265259"
  },
  {
    "text": "experience to the users to build data",
    "start": "265259",
    "end": "266940"
  },
  {
    "text": "pipelines build contentious applications",
    "start": "266940",
    "end": "268919"
  },
  {
    "text": "deploy them and schedule them based on",
    "start": "268919",
    "end": "272100"
  },
  {
    "text": "different dependencies so Intuit manager",
    "start": "272100",
    "end": "275220"
  },
  {
    "text": "60 000 pipelines and 10 000 concurrent",
    "start": "275220",
    "end": "278040"
  },
  {
    "text": "pipelines run at any moment so the",
    "start": "278040",
    "end": "281160"
  },
  {
    "text": "platform is also catered to solving a",
    "start": "281160",
    "end": "283500"
  },
  {
    "text": "lot of engineering problems so the",
    "start": "283500",
    "end": "286139"
  },
  {
    "text": "impact this has is over 1500 Engineers",
    "start": "286139",
    "end": "290360"
  },
  {
    "text": "including the personas that we talked",
    "start": "290360",
    "end": "292620"
  },
  {
    "text": "about",
    "start": "292620",
    "end": "293240"
  },
  {
    "text": "besides that there's also other",
    "start": "293240",
    "end": "294960"
  },
  {
    "text": "engineering personnels that are impacted",
    "start": "294960",
    "end": "297000"
  },
  {
    "text": "using this platform",
    "start": "297000",
    "end": "300320"
  },
  {
    "text": "okay",
    "start": "302340",
    "end": "303040"
  },
  {
    "text": "[Music]",
    "start": "303040",
    "end": "303479"
  },
  {
    "text": "um",
    "start": "303479",
    "end": "305280"
  },
  {
    "text": "a slide seems to be taking some time to",
    "start": "305280",
    "end": "307919"
  },
  {
    "text": "load up",
    "start": "307919",
    "end": "310280"
  },
  {
    "text": "all right so we'll move on to the next",
    "start": "311880",
    "end": "314580"
  },
  {
    "text": "slide",
    "start": "314580",
    "end": "315620"
  },
  {
    "start": "315000",
    "end": "315000"
  },
  {
    "text": "so before we talk about how it",
    "start": "315620",
    "end": "319740"
  },
  {
    "text": "integrates with Argo I wanted to quickly",
    "start": "319740",
    "end": "322560"
  },
  {
    "text": "talk about the the platforms",
    "start": "322560",
    "end": "324060"
  },
  {
    "text": "architecture this is a very high level",
    "start": "324060",
    "end": "325860"
  },
  {
    "text": "architecture and we'll talk about like",
    "start": "325860",
    "end": "327780"
  },
  {
    "text": "how we integrate with algo workflow and",
    "start": "327780",
    "end": "330240"
  },
  {
    "text": "events for the orchestration which will",
    "start": "330240",
    "end": "332639"
  },
  {
    "text": "specifically Focus this presentation on",
    "start": "332639",
    "end": "335240"
  },
  {
    "text": "so from the the platform the platform",
    "start": "335240",
    "end": "338699"
  },
  {
    "text": "has multiple different Services I've",
    "start": "338699",
    "end": "340919"
  },
  {
    "text": "highlighted a few here",
    "start": "340919",
    "end": "342860"
  },
  {
    "text": "so we have",
    "start": "342860",
    "end": "345080"
  },
  {
    "text": "the pipeline Management Service which",
    "start": "345080",
    "end": "348000"
  },
  {
    "text": "helps with repository creation build",
    "start": "348000",
    "end": "351539"
  },
  {
    "text": "environment deployments integration with",
    "start": "351539",
    "end": "354539"
  },
  {
    "text": "artifactory and observability so from a",
    "start": "354539",
    "end": "357419"
  },
  {
    "text": "data any engineering personas what we",
    "start": "357419",
    "end": "361680"
  },
  {
    "text": "expect is like them to out of the box",
    "start": "361680",
    "end": "364199"
  },
  {
    "text": "have the ability to get their",
    "start": "364199",
    "end": "366060"
  },
  {
    "text": "environment up and running and then we",
    "start": "366060",
    "end": "368699"
  },
  {
    "text": "provide the capability through our jobs",
    "start": "368699",
    "end": "370620"
  },
  {
    "text": "orchestration service using the the",
    "start": "370620",
    "end": "373080"
  },
  {
    "text": "workflow and the events layer for",
    "start": "373080",
    "end": "375060"
  },
  {
    "text": "scheduling their jobs and creating",
    "start": "375060",
    "end": "376800"
  },
  {
    "text": "dependencies and we have namespace",
    "start": "376800",
    "end": "378900"
  },
  {
    "text": "service to orchestrate their runs on the",
    "start": "378900",
    "end": "382199"
  },
  {
    "text": "compute layer on the multiple kubernetes",
    "start": "382199",
    "end": "384240"
  },
  {
    "text": "clusters that we manage and notification",
    "start": "384240",
    "end": "386220"
  },
  {
    "text": "services for",
    "start": "386220",
    "end": "388160"
  },
  {
    "text": "alerting a notification through various",
    "start": "388160",
    "end": "390720"
  },
  {
    "text": "mediums that we have on the right so we",
    "start": "390720",
    "end": "394080"
  },
  {
    "text": "can see that we have a representation of",
    "start": "394080",
    "end": "396180"
  },
  {
    "text": "what we call as a pipeline so a pipeline",
    "start": "396180",
    "end": "400580"
  },
  {
    "text": "is an abstract which we use for calling",
    "start": "400580",
    "end": "405600"
  },
  {
    "text": "a scheduling on a compute layer so",
    "start": "405600",
    "end": "409259"
  },
  {
    "text": "basically a pipeline has a stack of",
    "start": "409259",
    "end": "410880"
  },
  {
    "text": "process that with the data that is",
    "start": "410880",
    "end": "413460"
  },
  {
    "text": "getting ingested and the data that is",
    "start": "413460",
    "end": "415020"
  },
  {
    "text": "outputted each processor is a code",
    "start": "415020",
    "end": "418080"
  },
  {
    "text": "artifact and the process does",
    "start": "418080",
    "end": "420600"
  },
  {
    "text": "Transformations on the incoming data and",
    "start": "420600",
    "end": "422400"
  },
  {
    "text": "the pipeline manages the processing of",
    "start": "422400",
    "end": "424680"
  },
  {
    "text": "this entire layer and the dependencies",
    "start": "424680",
    "end": "427020"
  },
  {
    "text": "so we'll get more clarity on these",
    "start": "427020",
    "end": "429680"
  },
  {
    "text": "abstracts in the coming slides",
    "start": "429680",
    "end": "433580"
  },
  {
    "start": "434000",
    "end": "434000"
  },
  {
    "text": "so in this slide like I put a quick uh",
    "start": "434340",
    "end": "436680"
  },
  {
    "text": "representation of how the stack from a",
    "start": "436680",
    "end": "441180"
  },
  {
    "text": "dag on the left translates to orgo and",
    "start": "441180",
    "end": "443520"
  },
  {
    "text": "how we manage the dependencies so",
    "start": "443520",
    "end": "446280"
  },
  {
    "text": "basically um so in the previous slide we",
    "start": "446280",
    "end": "448380"
  },
  {
    "text": "saw the um the intuit's processing flow",
    "start": "448380",
    "end": "451020"
  },
  {
    "text": "with the the real-time stream",
    "start": "451020",
    "end": "452160"
  },
  {
    "text": "Transformations and also the batch",
    "start": "452160",
    "end": "453720"
  },
  {
    "text": "Transformations so in the batch",
    "start": "453720",
    "end": "455880"
  },
  {
    "text": "transformation we can see that there is",
    "start": "455880",
    "end": "457500"
  },
  {
    "text": "a dag which is translated to pipeline",
    "start": "457500",
    "end": "461039"
  },
  {
    "text": "dependencies through workflows in Argo",
    "start": "461039",
    "end": "463500"
  },
  {
    "text": "so the the root nodes here are in this",
    "start": "463500",
    "end": "467160"
  },
  {
    "text": "example cron workflows that are running",
    "start": "467160",
    "end": "469560"
  },
  {
    "text": "on a schedule and once the workflow is",
    "start": "469560",
    "end": "473039"
  },
  {
    "text": "fired there is a downstream dependencies",
    "start": "473039",
    "end": "476160"
  },
  {
    "text": "so Downstream dependencies usually can",
    "start": "476160",
    "end": "478740"
  },
  {
    "text": "be between data it can be between",
    "start": "478740",
    "end": "480960"
  },
  {
    "text": "application layers so it depends on your",
    "start": "480960",
    "end": "483840"
  },
  {
    "text": "use case but like usually we support a",
    "start": "483840",
    "end": "486180"
  },
  {
    "text": "resource-based Upstream dependencies",
    "start": "486180",
    "end": "487800"
  },
  {
    "text": "between multiple pipelines so these are",
    "start": "487800",
    "end": "490080"
  },
  {
    "text": "independent pipelines that are managed",
    "start": "490080",
    "end": "493139"
  },
  {
    "text": "by different organization different",
    "start": "493139",
    "end": "494940"
  },
  {
    "text": "teams in Intuit and there are Downstream",
    "start": "494940",
    "end": "498120"
  },
  {
    "text": "that are depending on this data maybe",
    "start": "498120",
    "end": "500580"
  },
  {
    "text": "there is a data enrichment being done in",
    "start": "500580",
    "end": "502199"
  },
  {
    "text": "step one and then we want to process and",
    "start": "502199",
    "end": "504960"
  },
  {
    "text": "write the data to Hive in the next step",
    "start": "504960",
    "end": "506759"
  },
  {
    "text": "and then do post processing and build",
    "start": "506759",
    "end": "508440"
  },
  {
    "text": "reporting and modern analysis um in the",
    "start": "508440",
    "end": "511080"
  },
  {
    "text": "The Next Step so uh so we support two",
    "start": "511080",
    "end": "514020"
  },
  {
    "text": "types of pipeline dependencies primarily",
    "start": "514020",
    "end": "517080"
  },
  {
    "text": "a time-based dependency which we support",
    "start": "517080",
    "end": "519419"
  },
  {
    "text": "using uh the Crone workflows and uh",
    "start": "519419",
    "end": "523140"
  },
  {
    "text": "trigger condition based dependencies",
    "start": "523140",
    "end": "524940"
  },
  {
    "text": "which we support using Argo even source",
    "start": "524940",
    "end": "527700"
  },
  {
    "text": "and sensor so in this example the",
    "start": "527700",
    "end": "531060"
  },
  {
    "text": "upstream and the downstream workflow or",
    "start": "531060",
    "end": "533100"
  },
  {
    "text": "like we discussed earlier is a pipeline",
    "start": "533100",
    "end": "535920"
  },
  {
    "text": "with multiple steps in it and the",
    "start": "535920",
    "end": "538260"
  },
  {
    "text": "dependency management is done using a",
    "start": "538260",
    "end": "540779"
  },
  {
    "text": "Kafka Event Source that we have built",
    "start": "540779",
    "end": "543360"
  },
  {
    "text": "and the sensor which takes care of the",
    "start": "543360",
    "end": "546120"
  },
  {
    "text": "downstream triggers so in this example",
    "start": "546120",
    "end": "548040"
  },
  {
    "text": "it's a one-to-one but we support one to",
    "start": "548040",
    "end": "549899"
  },
  {
    "text": "many this is also supported natively in",
    "start": "549899",
    "end": "553279"
  },
  {
    "text": "Argo events so this just shows the",
    "start": "553279",
    "end": "556500"
  },
  {
    "text": "capability that you can build a",
    "start": "556500",
    "end": "558420"
  },
  {
    "text": "combining orgo workflow and events a",
    "start": "558420",
    "end": "560279"
  },
  {
    "text": "complete orchestration under scheduling",
    "start": "560279",
    "end": "562160"
  },
  {
    "text": "infrastructure for all your data",
    "start": "562160",
    "end": "565740"
  },
  {
    "text": "Pipelines",
    "start": "565740",
    "end": "568160"
  },
  {
    "text": "so in the next slide I wanted to talk",
    "start": "568620",
    "end": "571800"
  },
  {
    "text": "about the the scalability journey that",
    "start": "571800",
    "end": "574200"
  },
  {
    "text": "we went through in terms of both scaling",
    "start": "574200",
    "end": "577320"
  },
  {
    "text": "the Argo events and Argo workflows and",
    "start": "577320",
    "end": "580260"
  },
  {
    "text": "we'll talk we'll take a quick look at",
    "start": "580260",
    "end": "582240"
  },
  {
    "text": "like what we have built internally at",
    "start": "582240",
    "end": "583860"
  },
  {
    "text": "Intuit like on top of what Argo offers",
    "start": "583860",
    "end": "586680"
  },
  {
    "text": "and we'll talk about the the next steps",
    "start": "586680",
    "end": "589920"
  },
  {
    "start": "589000",
    "end": "589000"
  },
  {
    "text": "so",
    "start": "589920",
    "end": "591240"
  },
  {
    "text": "um I put like different uh iterations",
    "start": "591240",
    "end": "593820"
  },
  {
    "text": "that we went over in the architecture",
    "start": "593820",
    "end": "596339"
  },
  {
    "text": "specifically this slide targets how we",
    "start": "596339",
    "end": "599100"
  },
  {
    "text": "scaled Argo events um this targets both",
    "start": "599100",
    "end": "602220"
  },
  {
    "text": "the stability aspect and also the the",
    "start": "602220",
    "end": "604680"
  },
  {
    "text": "scalability aspect of this",
    "start": "604680",
    "end": "606779"
  },
  {
    "text": "infrastructure so from the previous",
    "start": "606779",
    "end": "609120"
  },
  {
    "text": "slide we can see that between two",
    "start": "609120",
    "end": "611700"
  },
  {
    "text": "workflows the internal dependencies we",
    "start": "611700",
    "end": "615000"
  },
  {
    "text": "manage through an even source and a",
    "start": "615000",
    "end": "616800"
  },
  {
    "text": "sensor that has an internal Nat stream",
    "start": "616800",
    "end": "619320"
  },
  {
    "text": "bus so the initial issue that we ran",
    "start": "619320",
    "end": "622740"
  },
  {
    "text": "into with this architecture is that so",
    "start": "622740",
    "end": "626040"
  },
  {
    "text": "the Event Source like where there are",
    "start": "626040",
    "end": "628140"
  },
  {
    "text": "different types of sources that they",
    "start": "628140",
    "end": "630300"
  },
  {
    "text": "Argo events support one including the",
    "start": "630300",
    "end": "633360"
  },
  {
    "text": "workforce so the way we were",
    "start": "633360",
    "end": "635160"
  },
  {
    "text": "orchestrating is the even Source will",
    "start": "635160",
    "end": "636839"
  },
  {
    "text": "listen to the Upstream workflow",
    "start": "636839",
    "end": "638040"
  },
  {
    "text": "completion and emit an event to the NAT",
    "start": "638040",
    "end": "640140"
  },
  {
    "text": "stream which will then utilize the",
    "start": "640140",
    "end": "642600"
  },
  {
    "text": "sensors for doing the downstream",
    "start": "642600",
    "end": "644399"
  },
  {
    "text": "triggers but what happens during a",
    "start": "644399",
    "end": "646620"
  },
  {
    "text": "critical failure what if like an entire",
    "start": "646620",
    "end": "649019"
  },
  {
    "text": "node goes down or in an even Source",
    "start": "649019",
    "end": "650880"
  },
  {
    "text": "completely goes out in those scenarios",
    "start": "650880",
    "end": "654060"
  },
  {
    "text": "we Face some issues with fault tolerance",
    "start": "654060",
    "end": "656880"
  },
  {
    "text": "where like an upstream workflow",
    "start": "656880",
    "end": "658079"
  },
  {
    "text": "completes but an event is not captured",
    "start": "658079",
    "end": "660000"
  },
  {
    "text": "because the Event Source went down so",
    "start": "660000",
    "end": "661800"
  },
  {
    "text": "during the initial Journey we migrated",
    "start": "661800",
    "end": "663600"
  },
  {
    "text": "all our Event Source to Kafka this is a",
    "start": "663600",
    "end": "666899"
  },
  {
    "text": "natively supported feature in algo",
    "start": "666899",
    "end": "669240"
  },
  {
    "text": "events which meant that like we could",
    "start": "669240",
    "end": "672480"
  },
  {
    "text": "turn down um uh I mean even if during",
    "start": "672480",
    "end": "675060"
  },
  {
    "text": "critical failures if they even saw spots",
    "start": "675060",
    "end": "677160"
  },
  {
    "text": "are unavailable the data is still",
    "start": "677160",
    "end": "679440"
  },
  {
    "text": "persisted in an intermediate queue and",
    "start": "679440",
    "end": "682500"
  },
  {
    "text": "so this was the the first step that we",
    "start": "682500",
    "end": "684600"
  },
  {
    "text": "took about um",
    "start": "684600",
    "end": "686040"
  },
  {
    "text": "for stabilizing this but there is still",
    "start": "686040",
    "end": "689040"
  },
  {
    "text": "one",
    "start": "689040",
    "end": "690740"
  },
  {
    "text": "big scalability issue that we've had so",
    "start": "690740",
    "end": "695279"
  },
  {
    "text": "with each of our pipeline dependency",
    "start": "695279",
    "end": "697079"
  },
  {
    "text": "management we are deploying um the",
    "start": "697079",
    "end": "699720"
  },
  {
    "text": "workflows which takes up pods from in",
    "start": "699720",
    "end": "702120"
  },
  {
    "text": "your kubernetes clusters we are",
    "start": "702120",
    "end": "703560"
  },
  {
    "text": "deploying the even source and sensors",
    "start": "703560",
    "end": "705000"
  },
  {
    "text": "which takes up more pods so we are just",
    "start": "705000",
    "end": "707519"
  },
  {
    "text": "adding up more pods for each pipeline",
    "start": "707519",
    "end": "709920"
  },
  {
    "text": "dependency management so we were looking",
    "start": "709920",
    "end": "711899"
  },
  {
    "text": "into solving the problem of creating",
    "start": "711899",
    "end": "715079"
  },
  {
    "text": "independent Event Source per workflow so",
    "start": "715079",
    "end": "717959"
  },
  {
    "text": "the good news is that we were able to",
    "start": "717959",
    "end": "719760"
  },
  {
    "text": "collaborate with the uh the Argo events",
    "start": "719760",
    "end": "722279"
  },
  {
    "text": "team and so we came up with a solution",
    "start": "722279",
    "end": "725100"
  },
  {
    "text": "of migrating to a jet stream bus and a",
    "start": "725100",
    "end": "728640"
  },
  {
    "text": "Shad even source so this is supported in",
    "start": "728640",
    "end": "731100"
  },
  {
    "text": "the most recent versions of orgo events",
    "start": "731100",
    "end": "733200"
  },
  {
    "text": "starting from 1.7.1 where you could",
    "start": "733200",
    "end": "736140"
  },
  {
    "text": "utilize a single Kafka Event Source for",
    "start": "736140",
    "end": "739920"
  },
  {
    "text": "all the Upstream Shad workflows so we",
    "start": "739920",
    "end": "743820"
  },
  {
    "text": "have reduced the resource utilization on",
    "start": "743820",
    "end": "745920"
  },
  {
    "text": "the even Source by 99 and we have",
    "start": "745920",
    "end": "749160"
  },
  {
    "text": "migrated to the new jet stream bus Which",
    "start": "749160",
    "end": "751560"
  },
  {
    "text": "supports the capability for even source",
    "start": "751560",
    "end": "753480"
  },
  {
    "text": "to rely on a single even Source event",
    "start": "753480",
    "end": "755220"
  },
  {
    "text": "and it can filter on the data that's",
    "start": "755220",
    "end": "758100"
  },
  {
    "text": "coming in from the workflows so this is",
    "start": "758100",
    "end": "761579"
  },
  {
    "text": "our current iteration and in our Target",
    "start": "761579",
    "end": "763320"
  },
  {
    "text": "iteration we are working on moving the",
    "start": "763320",
    "end": "766740"
  },
  {
    "text": "sensors to a Shad sensor model so the",
    "start": "766740",
    "end": "769680"
  },
  {
    "text": "the target state is that for each Argo",
    "start": "769680",
    "end": "771720"
  },
  {
    "text": "events namespace which we which is the",
    "start": "771720",
    "end": "773579"
  },
  {
    "text": "orchestration layer we will have a",
    "start": "773579",
    "end": "776040"
  },
  {
    "text": "single compute stack for the event",
    "start": "776040",
    "end": "778200"
  },
  {
    "text": "source and the sensor which will manage",
    "start": "778200",
    "end": "780420"
  },
  {
    "text": "all the the pipeline dependency",
    "start": "780420",
    "end": "782399"
  },
  {
    "text": "management for tens of thousands of",
    "start": "782399",
    "end": "785579"
  },
  {
    "text": "pipelines that we manage every single",
    "start": "785579",
    "end": "787860"
  },
  {
    "text": "day and the downstream triggers are",
    "start": "787860",
    "end": "790139"
  },
  {
    "text": "handled by the uh the even Source",
    "start": "790139",
    "end": "792060"
  },
  {
    "text": "compute layer so there is an effort",
    "start": "792060",
    "end": "794519"
  },
  {
    "text": "going internally uh to migrate the the",
    "start": "794519",
    "end": "796980"
  },
  {
    "text": "events so even sensors and decouple the",
    "start": "796980",
    "end": "800519"
  },
  {
    "text": "the Manifest and the compute so that we",
    "start": "800519",
    "end": "803639"
  },
  {
    "text": "can scale through the structure which we",
    "start": "803639",
    "end": "805920"
  },
  {
    "text": "will be posting more about in the",
    "start": "805920",
    "end": "808139"
  },
  {
    "text": "upcoming Argo release notes",
    "start": "808139",
    "end": "812300"
  },
  {
    "start": "812000",
    "end": "812000"
  },
  {
    "text": "now I'll hand off to Bala to talk about",
    "start": "812639",
    "end": "816959"
  },
  {
    "text": "scaling Argo workflows",
    "start": "816959",
    "end": "819839"
  },
  {
    "text": "thank you Rockets",
    "start": "819839",
    "end": "821700"
  },
  {
    "text": "are you able to hear me",
    "start": "821700",
    "end": "824779"
  },
  {
    "text": "okay",
    "start": "825420",
    "end": "827839"
  },
  {
    "text": "So based on the the",
    "start": "828839",
    "end": "832079"
  },
  {
    "text": "batch processing platform requirement we",
    "start": "832079",
    "end": "834480"
  },
  {
    "text": "need like a ten thousand concurrent",
    "start": "834480",
    "end": "836940"
  },
  {
    "text": "workflow has to be run the each pipeline",
    "start": "836940",
    "end": "839820"
  },
  {
    "text": "will have like a three parts that means",
    "start": "839820",
    "end": "841500"
  },
  {
    "text": "thirty thousand Parts need to support",
    "start": "841500",
    "end": "843899"
  },
  {
    "text": "if you want to support this match you",
    "start": "843899",
    "end": "845399"
  },
  {
    "text": "massive workload",
    "start": "845399",
    "end": "848160"
  },
  {
    "text": "we cannot achieve with a single cluster",
    "start": "848160",
    "end": "850139"
  },
  {
    "text": "so we need to move into that",
    "start": "850139",
    "end": "851480"
  },
  {
    "text": "multi-cluster architecture so when we",
    "start": "851480",
    "end": "854160"
  },
  {
    "text": "are thinking about the multi-cluster",
    "start": "854160",
    "end": "855420"
  },
  {
    "text": "architecture the one main requirement we",
    "start": "855420",
    "end": "857700"
  },
  {
    "text": "got is like the distribution need to be",
    "start": "857700",
    "end": "860700"
  },
  {
    "text": "more Dynamic and it need to scale in",
    "start": "860700",
    "end": "862980"
  },
  {
    "text": "future",
    "start": "862980",
    "end": "865079"
  },
  {
    "text": "based on that we we start designing like",
    "start": "865079",
    "end": "867420"
  },
  {
    "text": "our multi-cluster Arceus",
    "start": "867420",
    "end": "869579"
  },
  {
    "text": "orchestration service",
    "start": "869579",
    "end": "871980"
  },
  {
    "text": "which will distribute that work load",
    "start": "871980",
    "end": "875220"
  },
  {
    "text": "balance the torque flow into that",
    "start": "875220",
    "end": "876420"
  },
  {
    "text": "multiple clusters",
    "start": "876420",
    "end": "878100"
  },
  {
    "text": "and we leveraged the Targo event to",
    "start": "878100",
    "end": "881160"
  },
  {
    "text": "support the pipeline to pipeline",
    "start": "881160",
    "end": "882779"
  },
  {
    "text": "dependency",
    "start": "882779",
    "end": "883800"
  },
  {
    "text": "when you see that the each",
    "start": "883800",
    "end": "886199"
  },
  {
    "text": "node clusters you can see that workflow",
    "start": "886199",
    "end": "888300"
  },
  {
    "text": "controller workflow APS server",
    "start": "888300",
    "end": "890880"
  },
  {
    "text": "and Argo event",
    "start": "890880",
    "end": "893699"
  },
  {
    "text": "the every APA server will be registered",
    "start": "893699",
    "end": "895620"
  },
  {
    "text": "into the orchestration service so that",
    "start": "895620",
    "end": "898079"
  },
  {
    "text": "the orchestration service will know that",
    "start": "898079",
    "end": "900060"
  },
  {
    "text": "what are the Clusters are registered so",
    "start": "900060",
    "end": "901860"
  },
  {
    "text": "that it will",
    "start": "901860",
    "end": "903540"
  },
  {
    "text": "schedule that part into the teach",
    "start": "903540",
    "end": "905160"
  },
  {
    "text": "cluster in the",
    "start": "905160",
    "end": "906720"
  },
  {
    "text": "Dynamic way",
    "start": "906720",
    "end": "909360"
  },
  {
    "text": "so each each cluster when the workflow",
    "start": "909360",
    "end": "911760"
  },
  {
    "text": "is completed it will notify the status",
    "start": "911760",
    "end": "913380"
  },
  {
    "text": "to that Argo event",
    "start": "913380",
    "end": "914940"
  },
  {
    "text": "based on the dependency configuration",
    "start": "914940",
    "end": "916680"
  },
  {
    "text": "Argo event will notify back to that",
    "start": "916680",
    "end": "918779"
  },
  {
    "text": "orchestration service to schedule the",
    "start": "918779",
    "end": "921740"
  },
  {
    "text": "downstream workflow",
    "start": "921740",
    "end": "924120"
  },
  {
    "text": "this architecture we are able to achieve",
    "start": "924120",
    "end": "926279"
  },
  {
    "text": "like a one-to-many many to one and many",
    "start": "926279",
    "end": "928740"
  },
  {
    "text": "to many pipeline dependencies",
    "start": "928740",
    "end": "932480"
  },
  {
    "text": "some of the scaling feature into the Tog",
    "start": "935240",
    "end": "937860"
  },
  {
    "text": "overflow also",
    "start": "937860",
    "end": "939240"
  },
  {
    "text": "the one feature we we did like a h a on",
    "start": "939240",
    "end": "942959"
  },
  {
    "start": "940000",
    "end": "940000"
  },
  {
    "text": "the workflow controller some of the",
    "start": "942959",
    "end": "944820"
  },
  {
    "text": "heavy loaded environment if you see that",
    "start": "944820",
    "end": "948360"
  },
  {
    "text": "the scheduling of pod will take a Time",
    "start": "948360",
    "end": "951300"
  },
  {
    "text": "in the BPP environment most of the",
    "start": "951300",
    "end": "953760"
  },
  {
    "text": "workflows are like a clone workflows if",
    "start": "953760",
    "end": "956220"
  },
  {
    "text": "the workflow controller is taking like a",
    "start": "956220",
    "end": "957959"
  },
  {
    "text": "little bit time the Chrome schedulers",
    "start": "957959",
    "end": "959579"
  },
  {
    "text": "are missing so we enabled that h a using",
    "start": "959579",
    "end": "964199"
  },
  {
    "text": "like a kubernetes leader leader apis so",
    "start": "964199",
    "end": "967620"
  },
  {
    "text": "that at the given time there will be",
    "start": "967620",
    "end": "969480"
  },
  {
    "text": "only one leader and rest of the people",
    "start": "969480",
    "end": "972060"
  },
  {
    "text": "rest of the notes rest of the part will",
    "start": "972060",
    "end": "974579"
  },
  {
    "text": "be a",
    "start": "974579",
    "end": "975600"
  },
  {
    "text": "follower whenever that any problem the",
    "start": "975600",
    "end": "978300"
  },
  {
    "text": "leader immediately that follower will",
    "start": "978300",
    "end": "979980"
  },
  {
    "text": "pick it up and start working on that",
    "start": "979980",
    "end": "983660"
  },
  {
    "text": "the next feature we we enable like the",
    "start": "984240",
    "end": "986760"
  },
  {
    "start": "985000",
    "end": "985000"
  },
  {
    "text": "PDP support on the workflow Parts",
    "start": "986760",
    "end": "988380"
  },
  {
    "text": "whenever you have like a frequent Auto",
    "start": "988380",
    "end": "991500"
  },
  {
    "text": "scaling clusters the node the scale down",
    "start": "991500",
    "end": "995220"
  },
  {
    "text": "will trigger the node drying",
    "start": "995220",
    "end": "998040"
  },
  {
    "text": "which will evict that the workflow parts",
    "start": "998040",
    "end": "1000980"
  },
  {
    "text": "which will end up to the torque flow or",
    "start": "1000980",
    "end": "1002779"
  },
  {
    "text": "step failure or you need to re-run that",
    "start": "1002779",
    "end": "1005660"
  },
  {
    "text": "again the entire step to avoid this",
    "start": "1005660",
    "end": "1007820"
  },
  {
    "text": "issue we enable that part disruption",
    "start": "1007820",
    "end": "1010579"
  },
  {
    "text": "budget as a first class citizen for that",
    "start": "1010579",
    "end": "1012740"
  },
  {
    "text": "workflow so that every workflow will",
    "start": "1012740",
    "end": "1015860"
  },
  {
    "text": "create a PDP for the workflow parts and",
    "start": "1015860",
    "end": "1019519"
  },
  {
    "text": "once the workflow is completed the PDP",
    "start": "1019519",
    "end": "1021680"
  },
  {
    "text": "object will be get deleted this is the",
    "start": "1021680",
    "end": "1023480"
  },
  {
    "text": "way we can prevent that power eviction",
    "start": "1023480",
    "end": "1026178"
  },
  {
    "text": "from the node drawing",
    "start": "1026179",
    "end": "1028760"
  },
  {
    "text": "the third feature we we Pro we",
    "start": "1028760",
    "end": "1031640"
  },
  {
    "start": "1030000",
    "end": "1030000"
  },
  {
    "text": "implemented is like a rate limiting that",
    "start": "1031640",
    "end": "1033319"
  },
  {
    "text": "concurrent part because the every",
    "start": "1033319",
    "end": "1035000"
  },
  {
    "text": "cluster will have like some concurrent",
    "start": "1035000",
    "end": "1037640"
  },
  {
    "text": "power limitations so we enable that the",
    "start": "1037640",
    "end": "1040699"
  },
  {
    "text": "rate limiting the concurrent Parts in",
    "start": "1040699",
    "end": "1042678"
  },
  {
    "text": "the multi levels the user can confirm",
    "start": "1042679",
    "end": "1044660"
  },
  {
    "text": "the cluster level",
    "start": "1044660",
    "end": "1046400"
  },
  {
    "text": "so that the total cluster if I want to",
    "start": "1046400",
    "end": "1049160"
  },
  {
    "text": "restrict further 10 000 parts that they",
    "start": "1049160",
    "end": "1051200"
  },
  {
    "text": "can configure it in the cluster level",
    "start": "1051200",
    "end": "1052580"
  },
  {
    "text": "and each namespace level also they can",
    "start": "1052580",
    "end": "1054740"
  },
  {
    "text": "configure it to give a multi-tenant way",
    "start": "1054740",
    "end": "1058220"
  },
  {
    "text": "of like a some some namespace and we",
    "start": "1058220",
    "end": "1060919"
  },
  {
    "text": "need a more level and in some name space",
    "start": "1060919",
    "end": "1063260"
  },
  {
    "text": "we need a restricted level we can",
    "start": "1063260",
    "end": "1064880"
  },
  {
    "text": "configure it then there is another",
    "start": "1064880",
    "end": "1066620"
  },
  {
    "text": "special use case like if you are",
    "start": "1066620",
    "end": "1069080"
  },
  {
    "text": "integrating Argo workflow with the",
    "start": "1069080",
    "end": "1070640"
  },
  {
    "text": "external system like a database or some",
    "start": "1070640",
    "end": "1072919"
  },
  {
    "text": "other APS server which need like a rate",
    "start": "1072919",
    "end": "1075080"
  },
  {
    "text": "limiting so we implemented the semaphore",
    "start": "1075080",
    "end": "1078620"
  },
  {
    "text": "and mutex to control the",
    "start": "1078620",
    "end": "1081020"
  },
  {
    "text": "concurrency in that container level",
    "start": "1081020",
    "end": "1084799"
  },
  {
    "text": "so this way we we are able to achieve",
    "start": "1084799",
    "end": "1087020"
  },
  {
    "text": "like the batch processing scalability",
    "start": "1087020",
    "end": "1090919"
  },
  {
    "text": "and we used that this all the features",
    "start": "1090919",
    "end": "1093260"
  },
  {
    "text": "in that our platform to achieve that",
    "start": "1093260",
    "end": "1096260"
  },
  {
    "text": "batch processing platform requirement to",
    "start": "1096260",
    "end": "1098900"
  },
  {
    "text": "support like a 10 000 concurrent",
    "start": "1098900",
    "end": "1101179"
  },
  {
    "text": "workflows in our clusters",
    "start": "1101179",
    "end": "1103460"
  },
  {
    "text": "let's give back to Rakesh to demo the",
    "start": "1103460",
    "end": "1106220"
  },
  {
    "text": "platform thank you guys",
    "start": "1106220",
    "end": "1109419"
  },
  {
    "text": "um in the next slides we'll quickly uh",
    "start": "1113840",
    "end": "1116000"
  },
  {
    "text": "look at the the visual aspects of what",
    "start": "1116000",
    "end": "1118760"
  },
  {
    "text": "we were talking about",
    "start": "1118760",
    "end": "1120260"
  },
  {
    "text": "um I think that will paint a better",
    "start": "1120260",
    "end": "1121880"
  },
  {
    "text": "picture",
    "start": "1121880",
    "end": "1122960"
  },
  {
    "text": "um so we talked about",
    "start": "1122960",
    "end": "1124520"
  },
  {
    "text": "um having um so two abstracts um for the",
    "start": "1124520",
    "end": "1127039"
  },
  {
    "text": "platforms uh that are integrating the",
    "start": "1127039",
    "end": "1129860"
  },
  {
    "start": "1128000",
    "end": "1128000"
  },
  {
    "text": "engineering uh so we have uh internal",
    "start": "1129860",
    "end": "1133760"
  },
  {
    "text": "workflow in our into a developer portal",
    "start": "1133760",
    "end": "1136100"
  },
  {
    "text": "where users can build a data processor",
    "start": "1136100",
    "end": "1138919"
  },
  {
    "text": "so a data processor like I mentioned",
    "start": "1138919",
    "end": "1141020"
  },
  {
    "text": "earlier is an Intuit artifact uh a code",
    "start": "1141020",
    "end": "1144620"
  },
  {
    "text": "that can be run in the compute layer of",
    "start": "1144620",
    "end": "1147380"
  },
  {
    "text": "your choice these are reusable artifacts",
    "start": "1147380",
    "end": "1149720"
  },
  {
    "text": "that can be scheduled in multiple",
    "start": "1149720",
    "end": "1152720"
  },
  {
    "text": "different pipelines these are shareable",
    "start": "1152720",
    "end": "1154400"
  },
  {
    "text": "process so for example in this slide you",
    "start": "1154400",
    "end": "1158480"
  },
  {
    "text": "could see that like a process that is",
    "start": "1158480",
    "end": "1160160"
  },
  {
    "text": "being built this is of runtime Spark",
    "start": "1160160",
    "end": "1162799"
  },
  {
    "text": "It's a language that the user has chosen",
    "start": "1162799",
    "end": "1165200"
  },
  {
    "text": "is Python and right out of the box the",
    "start": "1165200",
    "end": "1168500"
  },
  {
    "text": "pipeline management layer builds up the",
    "start": "1168500",
    "end": "1171140"
  },
  {
    "text": "uh the repositories uh for the users to",
    "start": "1171140",
    "end": "1173960"
  },
  {
    "text": "get started the the CI CD and also the",
    "start": "1173960",
    "end": "1177140"
  },
  {
    "text": "artifactory integration so the the",
    "start": "1177140",
    "end": "1179419"
  },
  {
    "text": "platform users can just focus on",
    "start": "1179419",
    "end": "1181820"
  },
  {
    "text": "primarily writing code and not the uh",
    "start": "1181820",
    "end": "1185419"
  },
  {
    "text": "other aspects",
    "start": "1185419",
    "end": "1188480"
  },
  {
    "start": "1188000",
    "end": "1188000"
  },
  {
    "text": "so the next step like once a user",
    "start": "1188480",
    "end": "1190700"
  },
  {
    "text": "registers a processor they could create",
    "start": "1190700",
    "end": "1193160"
  },
  {
    "text": "a data pipeline which is the compute and",
    "start": "1193160",
    "end": "1194900"
  },
  {
    "text": "the orchestration layer where they could",
    "start": "1194900",
    "end": "1197240"
  },
  {
    "text": "specify the artifact they could stack",
    "start": "1197240",
    "end": "1200120"
  },
  {
    "text": "multiple processor artifacts and have",
    "start": "1200120",
    "end": "1202880"
  },
  {
    "text": "the pipeline set up and you could",
    "start": "1202880",
    "end": "1205280"
  },
  {
    "start": "1205000",
    "end": "1205000"
  },
  {
    "text": "specify the scheduling and so in the",
    "start": "1205280",
    "end": "1209539"
  },
  {
    "text": "scheduling like we discussed earlier",
    "start": "1209539",
    "end": "1211580"
  },
  {
    "text": "using the Argo events we are able to",
    "start": "1211580",
    "end": "1213620"
  },
  {
    "text": "support resource-based scheduling and",
    "start": "1213620",
    "end": "1215840"
  },
  {
    "text": "time-based scheduling so in this example",
    "start": "1215840",
    "end": "1218080"
  },
  {
    "text": "the pipeline has to run every day at 3",
    "start": "1218080",
    "end": "1222380"
  },
  {
    "text": "am on completion of this Upstream data",
    "start": "1222380",
    "end": "1226280"
  },
  {
    "text": "Pipeline and on completion of this",
    "start": "1226280",
    "end": "1228799"
  },
  {
    "text": "resource so on meeting this condition",
    "start": "1228799",
    "end": "1230960"
  },
  {
    "text": "the pipeline will automatically schedule",
    "start": "1230960",
    "end": "1233780"
  },
  {
    "text": "so this is how we have decoupled the the",
    "start": "1233780",
    "end": "1237380"
  },
  {
    "text": "dependency management between",
    "start": "1237380",
    "end": "1240160"
  },
  {
    "text": "organizational organizational wide data",
    "start": "1240160",
    "end": "1242900"
  },
  {
    "text": "pipelines so once the pipeline is",
    "start": "1242900",
    "end": "1245480"
  },
  {
    "text": "created we provide the the dashboards",
    "start": "1245480",
    "end": "1249919"
  },
  {
    "text": "for managing your clusters your",
    "start": "1249919",
    "end": "1252080"
  },
  {
    "text": "observability Splunk dashboards cost",
    "start": "1252080",
    "end": "1254299"
  },
  {
    "text": "management and Spark history server in",
    "start": "1254299",
    "end": "1257179"
  },
  {
    "text": "this example because it's a spark",
    "start": "1257179",
    "end": "1258440"
  },
  {
    "text": "pipeline for data processing and we also",
    "start": "1258440",
    "end": "1260840"
  },
  {
    "text": "provide the execution history so all",
    "start": "1260840",
    "end": "1262940"
  },
  {
    "text": "this is a layer of a layer that's built",
    "start": "1262940",
    "end": "1266000"
  },
  {
    "text": "on top of the the kubernetes Clusters we",
    "start": "1266000",
    "end": "1269360"
  },
  {
    "text": "manage for the compute and the the",
    "start": "1269360",
    "end": "1271100"
  },
  {
    "text": "Clusters we manage for the Argo",
    "start": "1271100",
    "end": "1273020"
  },
  {
    "text": "orchestration",
    "start": "1273020",
    "end": "1275299"
  },
  {
    "text": "so in the next slide I just wanted to",
    "start": "1275299",
    "end": "1277760"
  },
  {
    "start": "1276000",
    "end": "1276000"
  },
  {
    "text": "quickly give a Viewpoint of like the the",
    "start": "1277760",
    "end": "1280760"
  },
  {
    "text": "capability and what it enables the the",
    "start": "1280760",
    "end": "1284120"
  },
  {
    "text": "engineering platforms to do so this is",
    "start": "1284120",
    "end": "1285980"
  },
  {
    "text": "an example of a cluster created for one",
    "start": "1285980",
    "end": "1289940"
  },
  {
    "text": "specific customer with an Intuit uh",
    "start": "1289940",
    "end": "1292340"
  },
  {
    "text": "using the data platform so you could see",
    "start": "1292340",
    "end": "1294860"
  },
  {
    "text": "multiple different dags being",
    "start": "1294860",
    "end": "1296659"
  },
  {
    "text": "constructed and like there's multiple",
    "start": "1296659",
    "end": "1298760"
  },
  {
    "text": "complicated clusters which are",
    "start": "1298760",
    "end": "1300740"
  },
  {
    "text": "interconnected through the dependency",
    "start": "1300740",
    "end": "1302480"
  },
  {
    "text": "management and also the the compute",
    "start": "1302480",
    "end": "1304460"
  },
  {
    "text": "orchestration that we provide",
    "start": "1304460",
    "end": "1306740"
  },
  {
    "text": "um",
    "start": "1306740",
    "end": "1308299"
  },
  {
    "text": "we'll uh quickly wrap the presentation",
    "start": "1308299",
    "end": "1311059"
  },
  {
    "text": "uh by talking about what's next",
    "start": "1311059",
    "end": "1314320"
  },
  {
    "start": "1314000",
    "end": "1314000"
  },
  {
    "text": "so we are currently working on next-gen",
    "start": "1314320",
    "end": "1317780"
  },
  {
    "text": "Argo event sensor like we mentioned in",
    "start": "1317780",
    "end": "1320539"
  },
  {
    "text": "the previous slide so this is the the",
    "start": "1320539",
    "end": "1322580"
  },
  {
    "text": "next scalability Journey that we are",
    "start": "1322580",
    "end": "1324679"
  },
  {
    "text": "currently uh ongoing",
    "start": "1324679",
    "end": "1326720"
  },
  {
    "text": "um so where we are decoupling the sensor",
    "start": "1326720",
    "end": "1328700"
  },
  {
    "text": "compute and the Manifest management",
    "start": "1328700",
    "end": "1330820"
  },
  {
    "text": "to reuse a single uh sensor for managing",
    "start": "1330820",
    "end": "1335659"
  },
  {
    "text": "all your dependencies so and we're also",
    "start": "1335659",
    "end": "1339020"
  },
  {
    "text": "working on a next-gen multi-cluster",
    "start": "1339020",
    "end": "1341539"
  },
  {
    "text": "workflow for supporting uh cluster load",
    "start": "1341539",
    "end": "1345679"
  },
  {
    "text": "balancing through the workflow",
    "start": "1345679",
    "end": "1347059"
  },
  {
    "text": "controller which Bala will talk give a",
    "start": "1347059",
    "end": "1349820"
  },
  {
    "text": "few words about",
    "start": "1349820",
    "end": "1351919"
  },
  {
    "text": "So based on the",
    "start": "1351919",
    "end": "1355059"
  },
  {
    "text": "hello",
    "start": "1355820",
    "end": "1357380"
  },
  {
    "text": "so",
    "start": "1357380",
    "end": "1358460"
  },
  {
    "text": "this is the one of the top demand in",
    "start": "1358460",
    "end": "1360679"
  },
  {
    "text": "that open source supporting like a",
    "start": "1360679",
    "end": "1362659"
  },
  {
    "text": "multi-cluster workflow still we are",
    "start": "1362659",
    "end": "1365120"
  },
  {
    "text": "evaluating how we can natively support",
    "start": "1365120",
    "end": "1367340"
  },
  {
    "text": "the multi-cluster load balancing for our",
    "start": "1367340",
    "end": "1370340"
  },
  {
    "text": "Gore flow controller",
    "start": "1370340",
    "end": "1372080"
  },
  {
    "text": "I think",
    "start": "1372080",
    "end": "1373700"
  },
  {
    "text": "yesterday maintenance notes I mentioned",
    "start": "1373700",
    "end": "1375559"
  },
  {
    "text": "that we are targeting for 3.6 feature",
    "start": "1375559",
    "end": "1378380"
  },
  {
    "text": "but still we are looking for the",
    "start": "1378380",
    "end": "1379940"
  },
  {
    "text": "community to give the their use case and",
    "start": "1379940",
    "end": "1382280"
  },
  {
    "text": "everything to understand better for that",
    "start": "1382280",
    "end": "1384679"
  },
  {
    "text": "the common requirement for the",
    "start": "1384679",
    "end": "1387200"
  },
  {
    "text": "multi-cluster workflow",
    "start": "1387200",
    "end": "1389840"
  },
  {
    "text": "oh",
    "start": "1389840",
    "end": "1392440"
  },
  {
    "text": "that's it uh do you guys have any",
    "start": "1394100",
    "end": "1396679"
  },
  {
    "text": "questions",
    "start": "1396679",
    "end": "1399039"
  },
  {
    "text": "for the orchestration service how does",
    "start": "1409220",
    "end": "1411799"
  },
  {
    "text": "it work uh to like distribute different",
    "start": "1411799",
    "end": "1413900"
  },
  {
    "text": "uh workflows to different clusters are",
    "start": "1413900",
    "end": "1416480"
  },
  {
    "text": "you storing like the coop configs within",
    "start": "1416480",
    "end": "1419000"
  },
  {
    "text": "the orchestration service or is it like",
    "start": "1419000",
    "end": "1421700"
  },
  {
    "text": "an event based so basically the the",
    "start": "1421700",
    "end": "1423919"
  },
  {
    "text": "orchestration service",
    "start": "1423919",
    "end": "1426820"
  },
  {
    "text": "into that so that it it's not going with",
    "start": "1428080",
    "end": "1431539"
  },
  {
    "text": "the cube config it's going with Argo",
    "start": "1431539",
    "end": "1433400"
  },
  {
    "text": "server wing and it's it has some memory",
    "start": "1433400",
    "end": "1437059"
  },
  {
    "text": "of like uh how many workflows are",
    "start": "1437059",
    "end": "1439100"
  },
  {
    "text": "running on the teach clusters so that",
    "start": "1439100",
    "end": "1440539"
  },
  {
    "text": "based on that it will load balance it",
    "start": "1440539",
    "end": "1442460"
  },
  {
    "text": "based on the configuration",
    "start": "1442460",
    "end": "1446140"
  },
  {
    "text": "so does it dynamically determine which",
    "start": "1456860",
    "end": "1459500"
  },
  {
    "text": "cluster to schedule the workflow based",
    "start": "1459500",
    "end": "1461960"
  },
  {
    "text": "on the number of workflows that are in",
    "start": "1461960",
    "end": "1463400"
  },
  {
    "text": "in the in each cluster or or does it",
    "start": "1463400",
    "end": "1469120"
  },
  {
    "text": "So currently",
    "start": "1471580",
    "end": "1473539"
  },
  {
    "text": "the master orchestration service will",
    "start": "1473539",
    "end": "1475940"
  },
  {
    "text": "have like all the registered clusters",
    "start": "1475940",
    "end": "1478100"
  },
  {
    "text": "and based on those registration it will",
    "start": "1478100",
    "end": "1480620"
  },
  {
    "text": "rapidly schedule it in the wrong",
    "start": "1480620",
    "end": "1482240"
  },
  {
    "text": "property",
    "start": "1482240",
    "end": "1483679"
  },
  {
    "text": "and you can keep track of like how many",
    "start": "1483679",
    "end": "1485480"
  },
  {
    "text": "workflows are running them because",
    "start": "1485480",
    "end": "1486740"
  },
  {
    "text": "that's the feedback loop through the",
    "start": "1486740",
    "end": "1489080"
  },
  {
    "text": "cardboard flow for Hardware even it will",
    "start": "1489080",
    "end": "1491600"
  },
  {
    "text": "tell you back okay this of course done",
    "start": "1491600",
    "end": "1493100"
  },
  {
    "text": "if start the downstream of course but I",
    "start": "1493100",
    "end": "1496340"
  },
  {
    "text": "I think the question is how do you",
    "start": "1496340",
    "end": "1498380"
  },
  {
    "text": "determine which workflow should run in",
    "start": "1498380",
    "end": "1499820"
  },
  {
    "text": "which cluster",
    "start": "1499820",
    "end": "1501200"
  },
  {
    "text": "come",
    "start": "1501200",
    "end": "1502460"
  },
  {
    "text": "it's done through a round robin fashion",
    "start": "1502460",
    "end": "1504679"
  },
  {
    "text": "yep",
    "start": "1504679",
    "end": "1507340"
  },
  {
    "text": "so with when it comes to the kubernetes",
    "start": "1514520",
    "end": "1517580"
  },
  {
    "text": "Clusters that we manage so one of the",
    "start": "1517580",
    "end": "1519679"
  },
  {
    "text": "the key challenges with running orgo",
    "start": "1519679",
    "end": "1523340"
  },
  {
    "text": "workflows in scale is POD management so",
    "start": "1523340",
    "end": "1527260"
  },
  {
    "text": "we run all our kubernetes clusters in",
    "start": "1527260",
    "end": "1530720"
  },
  {
    "text": "AWS accounts and there is IP limitations",
    "start": "1530720",
    "end": "1533539"
  },
  {
    "text": "on like how many parts that can come up",
    "start": "1533539",
    "end": "1536419"
  },
  {
    "text": "with low latency on a specific cluster",
    "start": "1536419",
    "end": "1539779"
  },
  {
    "text": "so the need for load balancing between",
    "start": "1539779",
    "end": "1542059"
  },
  {
    "text": "multi-clusters comes from that basis so",
    "start": "1542059",
    "end": "1545059"
  },
  {
    "text": "currently the bpp's orchestration",
    "start": "1545059",
    "end": "1547100"
  },
  {
    "text": "service is performing this load",
    "start": "1547100",
    "end": "1549500"
  },
  {
    "text": "balancing through the feedback loop with",
    "start": "1549500",
    "end": "1551419"
  },
  {
    "text": "the Argo events in Kafka but we are",
    "start": "1551419",
    "end": "1554419"
  },
  {
    "text": "natively looking to support this",
    "start": "1554419",
    "end": "1556039"
  },
  {
    "text": "capability in the the workflow",
    "start": "1556039",
    "end": "1558679"
  },
  {
    "text": "controller so that this could be managed",
    "start": "1558679",
    "end": "1561559"
  },
  {
    "text": "more natively",
    "start": "1561559",
    "end": "1564640"
  },
  {
    "text": "foreign",
    "start": "1564679",
    "end": "1567460"
  },
  {
    "text": "number of clusters you guys are running",
    "start": "1570279",
    "end": "1572299"
  },
  {
    "text": "uh how did you tune or determine maximum",
    "start": "1572299",
    "end": "1575720"
  },
  {
    "text": "cluster and how many clusters are you",
    "start": "1575720",
    "end": "1577940"
  },
  {
    "text": "sort of running this workflow Zone um so",
    "start": "1577940",
    "end": "1579980"
  },
  {
    "text": "apparently uh per cluster we are",
    "start": "1579980",
    "end": "1582820"
  },
  {
    "text": "targeting uh around",
    "start": "1582820",
    "end": "1585260"
  },
  {
    "text": "um 10 000 active workflows so because",
    "start": "1585260",
    "end": "1588919"
  },
  {
    "text": "our pod usage pervokes those around two",
    "start": "1588919",
    "end": "1591799"
  },
  {
    "text": "three parts",
    "start": "1591799",
    "end": "1593000"
  },
  {
    "text": "um so that's around thirty thousand",
    "start": "1593000",
    "end": "1594580"
  },
  {
    "text": "eyepiece and the concurrent workflows",
    "start": "1594580",
    "end": "1598880"
  },
  {
    "text": "that we support per cluster is around",
    "start": "1598880",
    "end": "1600860"
  },
  {
    "text": "three thousand so we for supporting 10",
    "start": "1600860",
    "end": "1603559"
  },
  {
    "text": "000 concurrent workflows we are running",
    "start": "1603559",
    "end": "1605539"
  },
  {
    "text": "on three kubernetes clusters that is",
    "start": "1605539",
    "end": "1608480"
  },
  {
    "text": "dedicated for the orchestration so we",
    "start": "1608480",
    "end": "1611659"
  },
  {
    "text": "have a separate compute clusters for",
    "start": "1611659",
    "end": "1613220"
  },
  {
    "text": "running our spark processing jobs and",
    "start": "1613220",
    "end": "1614779"
  },
  {
    "text": "other container applications and we are",
    "start": "1614779",
    "end": "1617539"
  },
  {
    "text": "running out of time",
    "start": "1617539",
    "end": "1619340"
  },
  {
    "text": "couple questions from the virtual",
    "start": "1619340",
    "end": "1620900"
  },
  {
    "text": "audience okay is your experience for",
    "start": "1620900",
    "end": "1623419"
  },
  {
    "text": "large batch jobs is it preferable to",
    "start": "1623419",
    "end": "1625820"
  },
  {
    "text": "have many small workflows",
    "start": "1625820",
    "end": "1627860"
  },
  {
    "text": "or a small number of very large",
    "start": "1627860",
    "end": "1630260"
  },
  {
    "text": "workflows",
    "start": "1630260",
    "end": "1632860"
  },
  {
    "text": "um so in uh",
    "start": "1633260",
    "end": "1636740"
  },
  {
    "text": "so small number of workflows means that",
    "start": "1636740",
    "end": "1639799"
  },
  {
    "text": "like there is a high amount of resource",
    "start": "1639799",
    "end": "1642020"
  },
  {
    "text": "utilization so if we are able to",
    "start": "1642020",
    "end": "1644659"
  },
  {
    "text": "optimize for a pod usage per workflow",
    "start": "1644659",
    "end": "1647900"
  },
  {
    "text": "you could run as many workflows as you",
    "start": "1647900",
    "end": "1650360"
  },
  {
    "text": "can but we are usually optimizing",
    "start": "1650360",
    "end": "1652460"
  },
  {
    "text": "towards larger workflows so that like",
    "start": "1652460",
    "end": "1655460"
  },
  {
    "text": "the resources are shared more optimally",
    "start": "1655460",
    "end": "1659299"
  },
  {
    "text": "okay another question quickly does your",
    "start": "1659299",
    "end": "1662000"
  },
  {
    "text": "UI allow you to Define relationships",
    "start": "1662000",
    "end": "1664760"
  },
  {
    "text": "between workflows if so if so how does",
    "start": "1664760",
    "end": "1668360"
  },
  {
    "text": "it know that your output of one",
    "start": "1668360",
    "end": "1670100"
  },
  {
    "text": "compatible with the input of another",
    "start": "1670100",
    "end": "1674140"
  },
  {
    "text": "so the compatibility in our case is",
    "start": "1674480",
    "end": "1677840"
  },
  {
    "text": "specifically tied with data because we",
    "start": "1677840",
    "end": "1679820"
  },
  {
    "text": "are talking about data pipelines so the",
    "start": "1679820",
    "end": "1681860"
  },
  {
    "text": "workflow integration are done through",
    "start": "1681860",
    "end": "1684700"
  },
  {
    "text": "the events infrastructure so the Argo",
    "start": "1684700",
    "end": "1689059"
  },
  {
    "text": "events track the workflow State change",
    "start": "1689059",
    "end": "1692360"
  },
  {
    "text": "and using the state change events we",
    "start": "1692360",
    "end": "1694820"
  },
  {
    "text": "emitted to Kafka from there we do",
    "start": "1694820",
    "end": "1697640"
  },
  {
    "text": "Downstream invocations on other data",
    "start": "1697640",
    "end": "1699740"
  },
  {
    "text": "pipelines so completion of a workflow",
    "start": "1699740",
    "end": "1702440"
  },
  {
    "text": "which in our case a data pipeline we",
    "start": "1702440",
    "end": "1704539"
  },
  {
    "text": "assume the availability of data so on",
    "start": "1704539",
    "end": "1707600"
  },
  {
    "text": "the downstreams usually that are relying",
    "start": "1707600",
    "end": "1710000"
  },
  {
    "text": "on the data gets triggered immediately",
    "start": "1710000",
    "end": "1711559"
  },
  {
    "text": "based on the conditions but we do",
    "start": "1711559",
    "end": "1713840"
  },
  {
    "text": "support complex conditioning using the",
    "start": "1713840",
    "end": "1715640"
  },
  {
    "text": "algo events",
    "start": "1715640",
    "end": "1717140"
  },
  {
    "text": "event will support like a Argo event",
    "start": "1717140",
    "end": "1719539"
  },
  {
    "text": "will support that complex dependency",
    "start": "1719539",
    "end": "1722120"
  },
  {
    "text": "Logics So based on that if the one",
    "start": "1722120",
    "end": "1724460"
  },
  {
    "text": "pipeline is depends on the multiple",
    "start": "1724460",
    "end": "1726980"
  },
  {
    "text": "pipelines we can configure it in the",
    "start": "1726980",
    "end": "1728299"
  },
  {
    "text": "Argo event side",
    "start": "1728299",
    "end": "1730520"
  },
  {
    "text": "okay we need to wrap up there are a",
    "start": "1730520",
    "end": "1732620"
  },
  {
    "text": "couple more questions on here speakers",
    "start": "1732620",
    "end": "1734539"
  },
  {
    "text": "would you be able to go into the",
    "start": "1734539",
    "end": "1736220"
  },
  {
    "text": "platform later and answer those",
    "start": "1736220",
    "end": "1738140"
  },
  {
    "text": "questions for them sure okay yeah so we",
    "start": "1738140",
    "end": "1740240"
  },
  {
    "text": "will be in our inputs Booth so you guys",
    "start": "1740240",
    "end": "1742760"
  },
  {
    "text": "can come meet us and like shoot us our",
    "start": "1742760",
    "end": "1745039"
  },
  {
    "text": "questions we'll talk more in depth on",
    "start": "1745039",
    "end": "1747200"
  },
  {
    "text": "the architecture and also any other help",
    "start": "1747200",
    "end": "1749179"
  },
  {
    "text": "that you guys need thank you yeah thank",
    "start": "1749179",
    "end": "1751279"
  },
  {
    "text": "you guys",
    "start": "1751279",
    "end": "1752020"
  },
  {
    "text": "[Applause]",
    "start": "1752020",
    "end": "1755500"
  }
]
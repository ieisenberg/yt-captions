[
  {
    "start": "0",
    "end": "48000"
  },
  {
    "text": "hi I'm Rodrigo I'm software engineer at",
    "start": "4799",
    "end": "7620"
  },
  {
    "text": "Microsoft hi I'm Marga I'm director of",
    "start": "7620",
    "end": "10139"
  },
  {
    "text": "engineering at ISO violent",
    "start": "10139",
    "end": "12599"
  },
  {
    "text": "a quick show of hands from these people",
    "start": "12599",
    "end": "15420"
  },
  {
    "text": "in the audience for which of you is the",
    "start": "15420",
    "end": "18359"
  },
  {
    "text": "first kubecon",
    "start": "18359",
    "end": "20820"
  },
  {
    "text": "wow all right welcome welcome everybody",
    "start": "20820",
    "end": "24240"
  },
  {
    "text": "to kubecon and welcome also those that",
    "start": "24240",
    "end": "26939"
  },
  {
    "text": "are veterans uh we are really glad that",
    "start": "26939",
    "end": "30300"
  },
  {
    "text": "you are here this talk is intended for",
    "start": "30300",
    "end": "34140"
  },
  {
    "text": "people that are still thinking of",
    "start": "34140",
    "end": "36600"
  },
  {
    "text": "managing VMS rather than containers or",
    "start": "36600",
    "end": "39239"
  },
  {
    "text": "perhaps you've started thinking about",
    "start": "39239",
    "end": "40680"
  },
  {
    "text": "managing containers but you need a",
    "start": "40680",
    "end": "43020"
  },
  {
    "text": "little Notch to make the the shift to",
    "start": "43020",
    "end": "45840"
  },
  {
    "text": "Cloud native in fact uh I'd like to",
    "start": "45840",
    "end": "49680"
  },
  {
    "start": "48000",
    "end": "48000"
  },
  {
    "text": "introduce you to our friend Taylor who's",
    "start": "49680",
    "end": "52379"
  },
  {
    "text": "a system administrator that is currently",
    "start": "52379",
    "end": "56039"
  },
  {
    "text": "managing VMS they use infrastructure as",
    "start": "56039",
    "end": "59039"
  },
  {
    "text": "code using terraform and ansible and it",
    "start": "59039",
    "end": "63180"
  },
  {
    "text": "works they have an application that has",
    "start": "63180",
    "end": "66840"
  },
  {
    "text": "a front-end a vacuum some load balancing",
    "start": "66840",
    "end": "69780"
  },
  {
    "text": "some firewalls and as I said it mostly",
    "start": "69780",
    "end": "72900"
  },
  {
    "text": "works but as the application becomes",
    "start": "72900",
    "end": "75420"
  },
  {
    "text": "more complex it's getting harder for",
    "start": "75420",
    "end": "77700"
  },
  {
    "text": "them to keep up",
    "start": "77700",
    "end": "79020"
  },
  {
    "text": "so they have been doing some research",
    "start": "79020",
    "end": "81479"
  },
  {
    "text": "into containers and coordinators and",
    "start": "81479",
    "end": "84540"
  },
  {
    "text": "they have decided to migrate but they",
    "start": "84540",
    "end": "87540"
  },
  {
    "text": "need a little help so we are here to",
    "start": "87540",
    "end": "90240"
  },
  {
    "text": "help them make that transition so let's",
    "start": "90240",
    "end": "93000"
  },
  {
    "text": "start at the beginning Rodrigo what",
    "start": "93000",
    "end": "95100"
  },
  {
    "text": "makes containers so special right so",
    "start": "95100",
    "end": "97560"
  },
  {
    "start": "96000",
    "end": "96000"
  },
  {
    "text": "containers are lightweight and very easy",
    "start": "97560",
    "end": "99840"
  },
  {
    "text": "to migrate from one node to another",
    "start": "99840",
    "end": "101520"
  },
  {
    "text": "because they contain all the necessary",
    "start": "101520",
    "end": "103500"
  },
  {
    "text": "necessary code to run our applications",
    "start": "103500",
    "end": "106380"
  },
  {
    "text": "and they are not tied to the underlying",
    "start": "106380",
    "end": "108720"
  },
  {
    "text": "host",
    "start": "108720",
    "end": "110399"
  },
  {
    "text": "so uh you probably shot this before but",
    "start": "110399",
    "end": "113880"
  },
  {
    "text": "we'll go over it one more time quickly",
    "start": "113880",
    "end": "117299"
  },
  {
    "text": "uh containers help us to treat our",
    "start": "117299",
    "end": "121140"
  },
  {
    "text": "our applications as cattle rather than",
    "start": "121140",
    "end": "123060"
  },
  {
    "text": "pets when we treat our applications as",
    "start": "123060",
    "end": "126000"
  },
  {
    "text": "pets we usually for each application we",
    "start": "126000",
    "end": "128580"
  },
  {
    "text": "create a VM image with a very specific",
    "start": "128580",
    "end": "131280"
  },
  {
    "text": "version of Linux with I don't know Ruby",
    "start": "131280",
    "end": "133980"
  },
  {
    "text": "3.1 no other version all its",
    "start": "133980",
    "end": "136680"
  },
  {
    "text": "dependencies and we treat each VM with a",
    "start": "136680",
    "end": "140040"
  },
  {
    "text": "lot of care we spend a lot of time to",
    "start": "140040",
    "end": "142680"
  },
  {
    "text": "upgrade them with a lot of care if",
    "start": "142680",
    "end": "145140"
  },
  {
    "text": "something fake breaks with the Sage into",
    "start": "145140",
    "end": "147900"
  },
  {
    "text": "them to fix it",
    "start": "147900",
    "end": "149640"
  },
  {
    "text": "when we treat our infrast cattle like no",
    "start": "149640",
    "end": "153000"
  },
  {
    "text": "just can come and go and if a note fails",
    "start": "153000",
    "end": "155640"
  },
  {
    "text": "we just move the applications to another",
    "start": "155640",
    "end": "157260"
  },
  {
    "text": "node",
    "start": "157260",
    "end": "158280"
  },
  {
    "text": "right and this and this really well",
    "start": "158280",
    "end": "161099"
  },
  {
    "text": "tune it's just one container that we can",
    "start": "161099",
    "end": "163080"
  },
  {
    "text": "move to the next machine but as our",
    "start": "163080",
    "end": "166140"
  },
  {
    "text": "employ as applications become more",
    "start": "166140",
    "end": "168840"
  },
  {
    "text": "complex we can have a front-end service",
    "start": "168840",
    "end": "171360"
  },
  {
    "text": "a vacuum service some database some blob",
    "start": "171360",
    "end": "173879"
  },
  {
    "text": "storage we add load balancing we want",
    "start": "173879",
    "end": "176519"
  },
  {
    "text": "High availability",
    "start": "176519",
    "end": "178040"
  },
  {
    "text": "it all starts to become quite complex",
    "start": "178040",
    "end": "180660"
  },
  {
    "text": "quite fast",
    "start": "180660",
    "end": "182160"
  },
  {
    "text": "right that's why uh we want to automate",
    "start": "182160",
    "end": "185280"
  },
  {
    "start": "183000",
    "end": "183000"
  },
  {
    "text": "more tasks",
    "start": "185280",
    "end": "186480"
  },
  {
    "text": "we want that for us to be roughly the",
    "start": "186480",
    "end": "189840"
  },
  {
    "text": "same effort to keep one replica for",
    "start": "189840",
    "end": "191760"
  },
  {
    "text": "application then uh or done to keep and",
    "start": "191760",
    "end": "195060"
  },
  {
    "text": "replicas of our application and this is",
    "start": "195060",
    "end": "197220"
  },
  {
    "text": "where kubernetes can really help us",
    "start": "197220",
    "end": "199440"
  },
  {
    "text": "uh",
    "start": "199440",
    "end": "200760"
  },
  {
    "text": "if a node goes down kubernetes can just",
    "start": "200760",
    "end": "203519"
  },
  {
    "text": "migrate the applications to an another",
    "start": "203519",
    "end": "205379"
  },
  {
    "text": "node and we maybe don't even receive a",
    "start": "205379",
    "end": "208140"
  },
  {
    "text": "page or if a whole data center goes down",
    "start": "208140",
    "end": "211260"
  },
  {
    "text": "if we have notes in another data center",
    "start": "211260",
    "end": "213720"
  },
  {
    "text": "kubernetes can just migrate the",
    "start": "213720",
    "end": "215280"
  },
  {
    "text": "applications there to another Data",
    "start": "215280",
    "end": "216900"
  },
  {
    "text": "Center and",
    "start": "216900",
    "end": "218519"
  },
  {
    "text": "it just works yeah that sounds really",
    "start": "218519",
    "end": "221220"
  },
  {
    "text": "great so how do we make that happen so",
    "start": "221220",
    "end": "224220"
  },
  {
    "start": "223000",
    "end": "223000"
  },
  {
    "text": "uh to make that happen we really want",
    "start": "224220",
    "end": "227599"
  },
  {
    "text": "automatic Health checking so if",
    "start": "227599",
    "end": "230640"
  },
  {
    "text": "something is unhealthy Grenada can take",
    "start": "230640",
    "end": "232799"
  },
  {
    "text": "an action to restore it like restart our",
    "start": "232799",
    "end": "234659"
  },
  {
    "text": "apps",
    "start": "234659",
    "end": "236280"
  },
  {
    "text": "and coordinates can take this action on",
    "start": "236280",
    "end": "239340"
  },
  {
    "text": "our applications but also with notes if",
    "start": "239340",
    "end": "241379"
  },
  {
    "text": "a node is unhealthy just migrate the",
    "start": "241379",
    "end": "243360"
  },
  {
    "text": "application there to another node and we",
    "start": "243360",
    "end": "246720"
  },
  {
    "text": "want to integrate this health checking",
    "start": "246720",
    "end": "249299"
  },
  {
    "text": "with the load balancing we want load",
    "start": "249299",
    "end": "251099"
  },
  {
    "text": "balancing at every layer integrated",
    "start": "251099",
    "end": "252840"
  },
  {
    "text": "integrated with the health checking so",
    "start": "252840",
    "end": "255299"
  },
  {
    "text": "we only Route traffic to healthy",
    "start": "255299",
    "end": "257220"
  },
  {
    "text": "replicas and we remove unhealthy",
    "start": "257220",
    "end": "259500"
  },
  {
    "text": "replicas as soon as possible from the",
    "start": "259500",
    "end": "262260"
  },
  {
    "text": "rotation",
    "start": "262260",
    "end": "263340"
  },
  {
    "text": "and like this reduces the burden we",
    "start": "263340",
    "end": "266520"
  },
  {
    "text": "carry significantly",
    "start": "266520",
    "end": "268259"
  },
  {
    "text": "makes our applications more resilient",
    "start": "268259",
    "end": "271380"
  },
  {
    "text": "and I and the problem shift here is just",
    "start": "271380",
    "end": "274440"
  },
  {
    "text": "to let grenades take care of this for us",
    "start": "274440",
    "end": "278940"
  },
  {
    "text": "so coordinates is an additional",
    "start": "278940",
    "end": "281040"
  },
  {
    "start": "279000",
    "end": "279000"
  },
  {
    "text": "attraction layer",
    "start": "281040",
    "end": "283139"
  },
  {
    "text": "that will help us to decouple our",
    "start": "283139",
    "end": "285360"
  },
  {
    "text": "applications from the infrastructure",
    "start": "285360",
    "end": "287460"
  },
  {
    "text": "where they're running on",
    "start": "287460",
    "end": "289639"
  },
  {
    "text": "containers were the first",
    "start": "289639",
    "end": "292100"
  },
  {
    "text": "uh help help with this",
    "start": "292100",
    "end": "295440"
  },
  {
    "text": "but cornettus for this improved upon",
    "start": "295440",
    "end": "297660"
  },
  {
    "text": "that uh like cornettus can help us to",
    "start": "297660",
    "end": "301560"
  },
  {
    "text": "schedule like to attach the volumes to",
    "start": "301560",
    "end": "304560"
  },
  {
    "text": "the nodes where the bot that needs those",
    "start": "304560",
    "end": "306600"
  },
  {
    "text": "volumes are scheduled or will help us",
    "start": "306600",
    "end": "309240"
  },
  {
    "text": "with the networking so our apps can",
    "start": "309240",
    "end": "311400"
  },
  {
    "text": "communicate between between each other",
    "start": "311400",
    "end": "313020"
  },
  {
    "text": "or we can just even say like create me a",
    "start": "313020",
    "end": "315780"
  },
  {
    "text": "load balancer",
    "start": "315780",
    "end": "316979"
  },
  {
    "text": "and it doesn't matter if we're running",
    "start": "316979",
    "end": "319020"
  },
  {
    "text": "in Azure or gcp if we're in unassure it",
    "start": "319020",
    "end": "322320"
  },
  {
    "text": "will create a natural load balancer if",
    "start": "322320",
    "end": "323880"
  },
  {
    "text": "we are in Google Cloud we will create a",
    "start": "323880",
    "end": "326220"
  },
  {
    "text": "Google Cloud load balancer",
    "start": "326220",
    "end": "329400"
  },
  {
    "text": "so this",
    "start": "329400",
    "end": "331620"
  },
  {
    "text": "side but it's actually starting to sound",
    "start": "331620",
    "end": "333600"
  },
  {
    "text": "a little bit too good to be true so",
    "start": "333600",
    "end": "336240"
  },
  {
    "text": "where's the catch so the catch is the",
    "start": "336240",
    "end": "339120"
  },
  {
    "text": "complexity right so kubernetes is a",
    "start": "339120",
    "end": "342060"
  },
  {
    "text": "non-free trivial abstraction layer we're",
    "start": "342060",
    "end": "344580"
  },
  {
    "text": "making heavy use of features like Linux",
    "start": "344580",
    "end": "347460"
  },
  {
    "text": "c groups namespaces overlay first and",
    "start": "347460",
    "end": "350580"
  },
  {
    "text": "we're adding all of that in our hot path",
    "start": "350580",
    "end": "353280"
  },
  {
    "text": "so we really need to learn how to use",
    "start": "353280",
    "end": "355979"
  },
  {
    "text": "kubernetes keep it up to date and more",
    "start": "355979",
    "end": "358199"
  },
  {
    "text": "importantly",
    "start": "358199",
    "end": "359160"
  },
  {
    "text": "uh debug it when it fails right all",
    "start": "359160",
    "end": "362759"
  },
  {
    "text": "right so we know there's no free meal",
    "start": "362759",
    "end": "364560"
  },
  {
    "text": "but uh we are here to help our friend",
    "start": "364560",
    "end": "368280"
  },
  {
    "text": "Taylor make the migration so they've",
    "start": "368280",
    "end": "371880"
  },
  {
    "start": "369000",
    "end": "369000"
  },
  {
    "text": "already started by packaging their",
    "start": "371880",
    "end": "373680"
  },
  {
    "text": "application into containers there's a",
    "start": "373680",
    "end": "376020"
  },
  {
    "text": "front-end and a back-end container that",
    "start": "376020",
    "end": "378860"
  },
  {
    "text": "represents what they want to run so the",
    "start": "378860",
    "end": "381900"
  },
  {
    "text": "first step on their journey to moving to",
    "start": "381900",
    "end": "384300"
  },
  {
    "text": "Cloud native is to deploy this",
    "start": "384300",
    "end": "387000"
  },
  {
    "text": "application as a kubernetes deployment",
    "start": "387000",
    "end": "391020"
  },
  {
    "start": "391000",
    "end": "391000"
  },
  {
    "text": "creating a deployment is basically",
    "start": "391020",
    "end": "393539"
  },
  {
    "text": "writing a bunch of yaml that tells",
    "start": "393539",
    "end": "396180"
  },
  {
    "text": "kubernetes what we want to run in this",
    "start": "396180",
    "end": "398340"
  },
  {
    "text": "case this example for the backend",
    "start": "398340",
    "end": "400020"
  },
  {
    "text": "deployment tells kubernetes that we want",
    "start": "400020",
    "end": "402240"
  },
  {
    "text": "to run five replicas of the backend",
    "start": "402240",
    "end": "405419"
  },
  {
    "text": "image",
    "start": "405419",
    "end": "407900"
  },
  {
    "start": "408000",
    "end": "408000"
  },
  {
    "text": "right",
    "start": "409020",
    "end": "410220"
  },
  {
    "text": "um",
    "start": "410220",
    "end": "411360"
  },
  {
    "text": "and the key concept underline most",
    "start": "411360",
    "end": "413280"
  },
  {
    "text": "kubernetes controller here is that in",
    "start": "413280",
    "end": "415259"
  },
  {
    "text": "the yaml we specify what we want like",
    "start": "415259",
    "end": "417840"
  },
  {
    "text": "five replicas and we just let cornettus",
    "start": "417840",
    "end": "420720"
  },
  {
    "text": "make sure that is always true",
    "start": "420720",
    "end": "423240"
  },
  {
    "text": "right and this is not a one-time",
    "start": "423240",
    "end": "425160"
  },
  {
    "text": "operation so if a pod crashes or a node",
    "start": "425160",
    "end": "428639"
  },
  {
    "text": "goes away kubernetes will ensure however",
    "start": "428639",
    "end": "432600"
  },
  {
    "text": "it decides that this needs to happen",
    "start": "432600",
    "end": "434699"
  },
  {
    "text": "that we always have five replicas right",
    "start": "434699",
    "end": "437100"
  },
  {
    "text": "so if one crashes it will start one if",
    "start": "437100",
    "end": "439620"
  },
  {
    "text": "the node goes away it will move whatever",
    "start": "439620",
    "end": "441599"
  },
  {
    "text": "pods we're running in that note to",
    "start": "441599",
    "end": "443639"
  },
  {
    "text": "another node and it just keep that state",
    "start": "443639",
    "end": "448020"
  },
  {
    "text": "right and when we release a new version",
    "start": "448020",
    "end": "450180"
  },
  {
    "text": "of our application like version 2.0 we",
    "start": "450180",
    "end": "453360"
  },
  {
    "text": "also specify our desired state in in the",
    "start": "453360",
    "end": "455819"
  },
  {
    "text": "yaml we say we want to run this and we",
    "start": "455819",
    "end": "458340"
  },
  {
    "text": "just let kubernetes do the rollout for",
    "start": "458340",
    "end": "460199"
  },
  {
    "text": "us until all replicas are up to date",
    "start": "460199",
    "end": "462180"
  },
  {
    "text": "running version 2.0",
    "start": "462180",
    "end": "465740"
  },
  {
    "text": "so",
    "start": "466440",
    "end": "468180"
  },
  {
    "text": "uh now we have a deployment with our",
    "start": "468180",
    "end": "470520"
  },
  {
    "text": "backend pods our front-end Parts but as",
    "start": "470520",
    "end": "472800"
  },
  {
    "text": "we know Bots IP change frequently so how",
    "start": "472800",
    "end": "475800"
  },
  {
    "text": "do we connect the backend paths to the",
    "start": "475800",
    "end": "478139"
  },
  {
    "text": "front-end Parts if there are IPS are",
    "start": "478139",
    "end": "480479"
  },
  {
    "text": "changing right so for that we use the",
    "start": "480479",
    "end": "482940"
  },
  {
    "text": "concept of a service a service gives us",
    "start": "482940",
    "end": "485580"
  },
  {
    "text": "a stable IP then the different parts of",
    "start": "485580",
    "end": "489539"
  },
  {
    "text": "our application can use to connect to",
    "start": "489539",
    "end": "493220"
  },
  {
    "start": "493000",
    "end": "493000"
  },
  {
    "text": "uh our friend Taylor here will need to",
    "start": "493220",
    "end": "496259"
  },
  {
    "text": "define a front-end and a back-end",
    "start": "496259",
    "end": "498060"
  },
  {
    "text": "service that will Define which are the",
    "start": "498060",
    "end": "501599"
  },
  {
    "text": "pods that are part of that service and",
    "start": "501599",
    "end": "504240"
  },
  {
    "text": "notice that the yaml files for the",
    "start": "504240",
    "end": "506340"
  },
  {
    "text": "services don't include how to run the",
    "start": "506340",
    "end": "508919"
  },
  {
    "text": "application that's what we specified in",
    "start": "508919",
    "end": "511319"
  },
  {
    "text": "the deployment demo in the service yaml",
    "start": "511319",
    "end": "514020"
  },
  {
    "text": "what we include is what are the pods",
    "start": "514020",
    "end": "516300"
  },
  {
    "text": "based on their labels using the selector",
    "start": "516300",
    "end": "518459"
  },
  {
    "text": "field so this is not how we run the",
    "start": "518459",
    "end": "521279"
  },
  {
    "text": "application but how we distribute the",
    "start": "521279",
    "end": "523320"
  },
  {
    "text": "load to the replicas that are running",
    "start": "523320",
    "end": "526080"
  },
  {
    "text": "the application okay so this service",
    "start": "526080",
    "end": "530399"
  },
  {
    "text": "yaml is enough to expose our",
    "start": "530399",
    "end": "531899"
  },
  {
    "text": "applications to the internet not yet we",
    "start": "531899",
    "end": "535440"
  },
  {
    "text": "to decide if an application is exposed",
    "start": "535440",
    "end": "538080"
  },
  {
    "text": "to the internet or just internal to the",
    "start": "538080",
    "end": "540000"
  },
  {
    "text": "cluster we have to specify the type",
    "start": "540000",
    "end": "543060"
  },
  {
    "text": "field in the services the default type",
    "start": "543060",
    "end": "546120"
  },
  {
    "text": "is called cluster IP and it has this",
    "start": "546120",
    "end": "548519"
  },
  {
    "text": "name because VIP assigned to the service",
    "start": "548519",
    "end": "551640"
  },
  {
    "text": "is internal to the cluster it's not",
    "start": "551640",
    "end": "554160"
  },
  {
    "text": "visible to the outside world there's a",
    "start": "554160",
    "end": "556860"
  },
  {
    "text": "component in kubernetes called Cube",
    "start": "556860",
    "end": "558660"
  },
  {
    "text": "proxy which is the one that does the",
    "start": "558660",
    "end": "560519"
  },
  {
    "text": "load balancing so when a request comes",
    "start": "560519",
    "end": "563399"
  },
  {
    "text": "into this cluster IP assigned to our",
    "start": "563399",
    "end": "565620"
  },
  {
    "text": "service Cube proxy will distribute the",
    "start": "565620",
    "end": "568019"
  },
  {
    "text": "traffic across all healthy replicas of",
    "start": "568019",
    "end": "570899"
  },
  {
    "text": "the service so this is the type that",
    "start": "570899",
    "end": "573779"
  },
  {
    "start": "572000",
    "end": "572000"
  },
  {
    "text": "Taylor would set in the backend service",
    "start": "573779",
    "end": "576480"
  },
  {
    "text": "because it's an internal service that is",
    "start": "576480",
    "end": "578880"
  },
  {
    "text": "only visible inside the cluster okay but",
    "start": "578880",
    "end": "581940"
  },
  {
    "text": "how do the front-end Parts know which AP",
    "start": "581940",
    "end": "584760"
  },
  {
    "text": "is assigned to this service so they",
    "start": "584760",
    "end": "586860"
  },
  {
    "text": "connect to the back-end parts right so",
    "start": "586860",
    "end": "589680"
  },
  {
    "text": "for that we use DNS when a service comes",
    "start": "589680",
    "end": "592140"
  },
  {
    "text": "up",
    "start": "592140",
    "end": "593459"
  },
  {
    "text": "tree is created",
    "start": "593459",
    "end": "594839"
  },
  {
    "text": "mapping the name of the service to the",
    "start": "594839",
    "end": "597240"
  },
  {
    "text": "cluster IP so internally any",
    "start": "597240",
    "end": "599880"
  },
  {
    "text": "applications that want to connect can",
    "start": "599880",
    "end": "601980"
  },
  {
    "text": "connect to that",
    "start": "601980",
    "end": "603480"
  },
  {
    "text": "service name that will get mapped to the",
    "start": "603480",
    "end": "605640"
  },
  {
    "text": "cluster AP",
    "start": "605640",
    "end": "606899"
  },
  {
    "text": "okay so this is for internal Services",
    "start": "606899",
    "end": "609740"
  },
  {
    "text": "again how do we expose it to the",
    "start": "609740",
    "end": "612000"
  },
  {
    "text": "internet to expose it to the internet we",
    "start": "612000",
    "end": "613740"
  },
  {
    "text": "will need to choose a different type for",
    "start": "613740",
    "end": "615660"
  },
  {
    "text": "example we can choose the node Port type",
    "start": "615660",
    "end": "618060"
  },
  {
    "start": "616000",
    "end": "616000"
  },
  {
    "text": "it has this name because the service is",
    "start": "618060",
    "end": "620820"
  },
  {
    "text": "available through a port that is exposed",
    "start": "620820",
    "end": "623279"
  },
  {
    "text": "on all of the nodes of our cluster and",
    "start": "623279",
    "end": "626339"
  },
  {
    "text": "again the magic is done by the",
    "start": "626339",
    "end": "628680"
  },
  {
    "text": "kubernetes component that called Cube",
    "start": "628680",
    "end": "630660"
  },
  {
    "text": "proxy which when a request comes in on a",
    "start": "630660",
    "end": "635640"
  },
  {
    "text": "specified Port it distributes the",
    "start": "635640",
    "end": "638160"
  },
  {
    "text": "traffic to the service that is mapped to",
    "start": "638160",
    "end": "640260"
  },
  {
    "text": "that Port notice that for readability in",
    "start": "640260",
    "end": "643620"
  },
  {
    "text": "this diagram here we are not crossing",
    "start": "643620",
    "end": "646800"
  },
  {
    "text": "boundaries across nodes but actually",
    "start": "646800",
    "end": "649040"
  },
  {
    "text": "Cube proxy distributes the traffic to",
    "start": "649040",
    "end": "652200"
  },
  {
    "text": "any node in the cluster it doesn't",
    "start": "652200",
    "end": "654300"
  },
  {
    "text": "matter which node our request comes in",
    "start": "654300",
    "end": "656820"
  },
  {
    "text": "through so if it comes in through Node 1",
    "start": "656820",
    "end": "659820"
  },
  {
    "text": "but Q proxy decides that actually it",
    "start": "659820",
    "end": "663240"
  },
  {
    "text": "should be served diapod in node two it",
    "start": "663240",
    "end": "665220"
  },
  {
    "text": "will redirect it to the poding node",
    "start": "665220",
    "end": "666899"
  },
  {
    "text": "foreign",
    "start": "666899",
    "end": "669500"
  },
  {
    "start": "669000",
    "end": "669000"
  },
  {
    "text": "so this is the type of service that",
    "start": "669779",
    "end": "672360"
  },
  {
    "text": "Taylor could set for their front end",
    "start": "672360",
    "end": "675240"
  },
  {
    "text": "ports and for example it could go to the",
    "start": "675240",
    "end": "678779"
  },
  {
    "text": "port 30500 we actually don't need to",
    "start": "678779",
    "end": "682440"
  },
  {
    "text": "specify that part kubernetes will set it",
    "start": "682440",
    "end": "684420"
  },
  {
    "text": "for us we're just putting there for",
    "start": "684420",
    "end": "686220"
  },
  {
    "text": "clarity okay and how do we make traffic",
    "start": "686220",
    "end": "689220"
  },
  {
    "text": "go to notes on this very specific Port",
    "start": "689220",
    "end": "692279"
  },
  {
    "text": "that is not the HTTP Port right so to do",
    "start": "692279",
    "end": "695760"
  },
  {
    "text": "that we could use uh for example we",
    "start": "695760",
    "end": "698820"
  },
  {
    "text": "could use a legacy load balancer a load",
    "start": "698820",
    "end": "701220"
  },
  {
    "start": "699000",
    "end": "699000"
  },
  {
    "text": "balancer that is not part of the",
    "start": "701220",
    "end": "702720"
  },
  {
    "text": "kubernetes infrastructure and is not",
    "start": "702720",
    "end": "704279"
  },
  {
    "text": "managed by kubernetes",
    "start": "704279",
    "end": "706040"
  },
  {
    "text": "uh this this can be the load balancer",
    "start": "706040",
    "end": "709620"
  },
  {
    "text": "that we were already using before and",
    "start": "709620",
    "end": "711540"
  },
  {
    "text": "instead of pointing it to VMS we pointed",
    "start": "711540",
    "end": "714660"
  },
  {
    "text": "to the nodes in the kubernetes cluster",
    "start": "714660",
    "end": "716700"
  },
  {
    "text": "with the specified note port and then",
    "start": "716700",
    "end": "719700"
  },
  {
    "text": "everything else just stays the same",
    "start": "719700",
    "end": "722100"
  },
  {
    "text": "another option is to directly set the",
    "start": "722100",
    "end": "725220"
  },
  {
    "start": "723000",
    "end": "723000"
  },
  {
    "text": "type load balancer in this case it's",
    "start": "725220",
    "end": "728220"
  },
  {
    "text": "similar to the node Port service type",
    "start": "728220",
    "end": "730380"
  },
  {
    "text": "but it will create a manage the load",
    "start": "730380",
    "end": "733620"
  },
  {
    "text": "balancer in the cloud infrastructure",
    "start": "733620",
    "end": "736200"
  },
  {
    "text": "that we are running on",
    "start": "736200",
    "end": "739579"
  },
  {
    "text": "and once we create it we can query the",
    "start": "740820",
    "end": "744720"
  },
  {
    "text": "IP that this managed load balancer got",
    "start": "744720",
    "end": "747000"
  },
  {
    "text": "by for example checking the status field",
    "start": "747000",
    "end": "750540"
  },
  {
    "text": "okay so we have the service type load",
    "start": "750540",
    "end": "753300"
  },
  {
    "start": "751000",
    "end": "751000"
  },
  {
    "text": "balancer but that is not the only type",
    "start": "753300",
    "end": "756000"
  },
  {
    "text": "of service that balances the loads",
    "start": "756000",
    "end": "758040"
  },
  {
    "text": "across ports right exactly this name can",
    "start": "758040",
    "end": "761820"
  },
  {
    "text": "be a little bit confusing at the",
    "start": "761820",
    "end": "763320"
  },
  {
    "text": "beginning but uh it's called node",
    "start": "763320",
    "end": "765779"
  },
  {
    "text": "balancer because it creates an external",
    "start": "765779",
    "end": "768300"
  },
  {
    "text": "load balancer that is part of the whole",
    "start": "768300",
    "end": "771380"
  },
  {
    "text": "kubernetes management",
    "start": "771380",
    "end": "773639"
  },
  {
    "text": "but all of the services that we said",
    "start": "773639",
    "end": "776040"
  },
  {
    "text": "class 3B node port and load balancer",
    "start": "776040",
    "end": "778920"
  },
  {
    "text": "balance the load across all healthy",
    "start": "778920",
    "end": "781980"
  },
  {
    "text": "replicas of our service",
    "start": "781980",
    "end": "785180"
  },
  {
    "start": "787000",
    "end": "787000"
  },
  {
    "text": "all right so Taylor's application",
    "start": "787139",
    "end": "789360"
  },
  {
    "text": "actually got a little bit more complex",
    "start": "789360",
    "end": "791940"
  },
  {
    "text": "on top of their already existing",
    "start": "791940",
    "end": "794339"
  },
  {
    "text": "application of front-end and backend",
    "start": "794339",
    "end": "796079"
  },
  {
    "text": "they also have a Blog where they publish",
    "start": "796079",
    "end": "798899"
  },
  {
    "text": "what's going on with their system and",
    "start": "798899",
    "end": "801480"
  },
  {
    "text": "this blog is actually running on a",
    "start": "801480",
    "end": "803880"
  },
  {
    "text": "separate application a separate",
    "start": "803880",
    "end": "806160"
  },
  {
    "text": "container so what can they do",
    "start": "806160",
    "end": "808920"
  },
  {
    "text": "right so up to now we've been dealing",
    "start": "808920",
    "end": "811620"
  },
  {
    "text": "with services that are layer four so we",
    "start": "811620",
    "end": "814019"
  },
  {
    "text": "can basically specify things at the TCP",
    "start": "814019",
    "end": "816000"
  },
  {
    "text": "or UDP layer but if you want to check",
    "start": "816000",
    "end": "818459"
  },
  {
    "text": "the HTTP layer like the request path to",
    "start": "818459",
    "end": "821760"
  },
  {
    "text": "slash blog we need uh to do",
    "start": "821760",
    "end": "825240"
  },
  {
    "text": "to do this uh routing at the at layer 7.",
    "start": "825240",
    "end": "829200"
  },
  {
    "text": "so in cornetis we can use an Ingress",
    "start": "829200",
    "end": "831180"
  },
  {
    "text": "resource for this like this will be an",
    "start": "831180",
    "end": "833940"
  },
  {
    "start": "832000",
    "end": "832000"
  },
  {
    "text": "an example for Taylor this is again a",
    "start": "833940",
    "end": "836820"
  },
  {
    "text": "bunch of yamo and where we can specify",
    "start": "836820",
    "end": "839639"
  },
  {
    "text": "if the requests go to slash Blog then it",
    "start": "839639",
    "end": "843420"
  },
  {
    "text": "will be served by the blog service and",
    "start": "843420",
    "end": "846060"
  },
  {
    "text": "otherwise it is it will be served by the",
    "start": "846060",
    "end": "848519"
  },
  {
    "text": "front-end parts",
    "start": "848519",
    "end": "851360"
  },
  {
    "text": "so",
    "start": "852180",
    "end": "854040"
  },
  {
    "text": "uh the English controller can be a",
    "start": "854040",
    "end": "857459"
  },
  {
    "text": "resource that runs in inside our cluster",
    "start": "857459",
    "end": "859680"
  },
  {
    "text": "like in this diagram",
    "start": "859680",
    "end": "861480"
  },
  {
    "text": "it can be for example an inch and X or",
    "start": "861480",
    "end": "864060"
  },
  {
    "text": "it can also be a cloud resource a low",
    "start": "864060",
    "end": "866399"
  },
  {
    "text": "layer 7 load balancer that runs in in",
    "start": "866399",
    "end": "870240"
  },
  {
    "text": "the cloud provider in the second case",
    "start": "870240",
    "end": "873839"
  },
  {
    "text": "there will be also like a lightweight",
    "start": "873839",
    "end": "876060"
  },
  {
    "text": "Ingress controller that will just keep",
    "start": "876060",
    "end": "878040"
  },
  {
    "text": "in sync the cloud load balancer with the",
    "start": "878040",
    "end": "880500"
  },
  {
    "text": "import side piece and things like that",
    "start": "880500",
    "end": "882839"
  },
  {
    "text": "all right you mentioned entry next and",
    "start": "882839",
    "end": "885360"
  },
  {
    "text": "she next is how we would do this in the",
    "start": "885360",
    "end": "887100"
  },
  {
    "text": "VM world right right so we probably",
    "start": "887100",
    "end": "889260"
  },
  {
    "text": "already have an nginx configuration",
    "start": "889260",
    "end": "891120"
  },
  {
    "text": "doing this routing and we just need to",
    "start": "891120",
    "end": "894060"
  },
  {
    "text": "map that uh to the coordinate",
    "start": "894060",
    "end": "896579"
  },
  {
    "text": "synchronous resource",
    "start": "896579",
    "end": "898199"
  },
  {
    "text": "all right",
    "start": "898199",
    "end": "899579"
  },
  {
    "text": "okay so we talk about Services we talk",
    "start": "899579",
    "end": "902399"
  },
  {
    "text": "about Ingress",
    "start": "902399",
    "end": "904260"
  },
  {
    "text": "Ingrid now our friend Taylor is getting",
    "start": "904260",
    "end": "906300"
  },
  {
    "text": "a little bit uh excited about Auto",
    "start": "906300",
    "end": "909000"
  },
  {
    "text": "scaling so they are already familiar",
    "start": "909000",
    "end": "911339"
  },
  {
    "text": "with auto scaling from the vmworld they",
    "start": "911339",
    "end": "913560"
  },
  {
    "text": "have their VM set up",
    "start": "913560",
    "end": "915420"
  },
  {
    "text": "so that when the CPU goes up they get",
    "start": "915420",
    "end": "919079"
  },
  {
    "text": "more and when it goes down they scale",
    "start": "919079",
    "end": "921959"
  },
  {
    "text": "down in the container world is a similar",
    "start": "921959",
    "end": "925620"
  },
  {
    "text": "concept but we have more Dimensions we",
    "start": "925620",
    "end": "928320"
  },
  {
    "text": "can scale the number of PODS the size of",
    "start": "928320",
    "end": "931139"
  },
  {
    "text": "the pods or the number of nodes in the",
    "start": "931139",
    "end": "933300"
  },
  {
    "text": "cluster",
    "start": "933300",
    "end": "935279"
  },
  {
    "start": "935000",
    "end": "935000"
  },
  {
    "text": "right so what we're used to do in the",
    "start": "935279",
    "end": "938820"
  },
  {
    "text": "veeam world is looking at the CP usage",
    "start": "938820",
    "end": "941339"
  },
  {
    "text": "of the node to scale but that doesn't",
    "start": "941339",
    "end": "943920"
  },
  {
    "text": "really work now with containers like in",
    "start": "943920",
    "end": "945839"
  },
  {
    "text": "this example the sub usage of the whole",
    "start": "945839",
    "end": "947699"
  },
  {
    "text": "node is are around 20 but the backing",
    "start": "947699",
    "end": "950760"
  },
  {
    "text": "ports are completely overloaded",
    "start": "950760",
    "end": "954000"
  },
  {
    "text": "so what can we do instead so we should",
    "start": "954000",
    "end": "957060"
  },
  {
    "text": "look at the CPU usage of of the parts",
    "start": "957060",
    "end": "959820"
  },
  {
    "text": "not the node the scale we do horizontal",
    "start": "959820",
    "end": "963540"
  },
  {
    "text": "scaling this way in kubernetes okay and",
    "start": "963540",
    "end": "966120"
  },
  {
    "text": "so how do we do it again with a bunch of",
    "start": "966120",
    "end": "968519"
  },
  {
    "text": "yaml like in in this example we put a",
    "start": "968519",
    "end": "971880"
  },
  {
    "text": "hard limit of minimum three replicas and",
    "start": "971880",
    "end": "974160"
  },
  {
    "text": "maximum 10 replicas of our part and we",
    "start": "974160",
    "end": "977699"
  },
  {
    "text": "target the numbers to be usage of our",
    "start": "977699",
    "end": "979440"
  },
  {
    "text": "Bots around 70 percent so if this abuses",
    "start": "979440",
    "end": "983339"
  },
  {
    "text": "goes goes above this we'll create more",
    "start": "983339",
    "end": "985320"
  },
  {
    "text": "parts and if it goes below we'll just",
    "start": "985320",
    "end": "988260"
  },
  {
    "text": "remove the Bots to not wide resources",
    "start": "988260",
    "end": "991139"
  },
  {
    "text": "is CPU the only metric we can use no",
    "start": "991139",
    "end": "994079"
  },
  {
    "text": "memory is also a built-in metric but we",
    "start": "994079",
    "end": "996839"
  },
  {
    "text": "can also use any custom metric we want",
    "start": "996839",
    "end": "998880"
  },
  {
    "text": "like we can scrape from Primitives for",
    "start": "998880",
    "end": "1001100"
  },
  {
    "text": "example",
    "start": "1001100",
    "end": "1002380"
  },
  {
    "text": "and what can happen if we scale too much",
    "start": "1002380",
    "end": "1006079"
  },
  {
    "text": "right so if we have a lot of demand",
    "start": "1006079",
    "end": "1008660"
  },
  {
    "start": "1008000",
    "end": "1008000"
  },
  {
    "text": "we'll start creating a lot of parts and",
    "start": "1008660",
    "end": "1011300"
  },
  {
    "text": "eventually we might run out of capacity",
    "start": "1011300",
    "end": "1013459"
  },
  {
    "text": "in our nodes to schedule those parts",
    "start": "1013459",
    "end": "1016220"
  },
  {
    "text": "so",
    "start": "1016220",
    "end": "1017660"
  },
  {
    "text": "this is where the cluster Auto scalar",
    "start": "1017660",
    "end": "1019820"
  },
  {
    "text": "kicks in it will look for",
    "start": "1019820",
    "end": "1022699"
  },
  {
    "text": "for pending parts and it will create new",
    "start": "1022699",
    "end": "1025280"
  },
  {
    "text": "nodes in our cluster to schedule them",
    "start": "1025280",
    "end": "1027678"
  },
  {
    "text": "and so we can satisfy the demand that we",
    "start": "1027679",
    "end": "1029660"
  },
  {
    "text": "need",
    "start": "1029660",
    "end": "1031780"
  },
  {
    "text": "okay so we already covered uh like",
    "start": "1032959",
    "end": "1035540"
  },
  {
    "text": "deploying our app exploring it exposing",
    "start": "1035540",
    "end": "1038298"
  },
  {
    "text": "it with services and now to scaling it",
    "start": "1038299",
    "end": "1040699"
  },
  {
    "text": "something that is bothering our front",
    "start": "1040699",
    "end": "1042980"
  },
  {
    "text": "tailor here is uh firewalls",
    "start": "1042980",
    "end": "1045740"
  },
  {
    "text": "the thing is we're used to in the",
    "start": "1045740",
    "end": "1048438"
  },
  {
    "start": "1046000",
    "end": "1046000"
  },
  {
    "text": "on-prem world writing iptellus rule",
    "start": "1048439",
    "end": "1051140"
  },
  {
    "text": "using the VMS IPS to limit connectivity",
    "start": "1051140",
    "end": "1054320"
  },
  {
    "text": "and we do something very similar with",
    "start": "1054320",
    "end": "1056419"
  },
  {
    "text": "security groups in in Cloud providers",
    "start": "1056419",
    "end": "1059419"
  },
  {
    "text": "the thing is with containers uh",
    "start": "1059419",
    "end": "1062360"
  },
  {
    "text": "we don't know the containers IP and we",
    "start": "1062360",
    "end": "1064820"
  },
  {
    "text": "don't even know in which node a",
    "start": "1064820",
    "end": "1066320"
  },
  {
    "text": "container may run it may be running on",
    "start": "1066320",
    "end": "1068720"
  },
  {
    "text": "one note today and another node tomorrow",
    "start": "1068720",
    "end": "1070640"
  },
  {
    "text": "so it's very hard to uh to write the",
    "start": "1070640",
    "end": "1074299"
  },
  {
    "text": "rules as we are used to in this new",
    "start": "1074299",
    "end": "1076039"
  },
  {
    "text": "world so what can we do so instead what",
    "start": "1076039",
    "end": "1079220"
  },
  {
    "start": "1079000",
    "end": "1079000"
  },
  {
    "text": "we do is we write Network policies in",
    "start": "1079220",
    "end": "1081620"
  },
  {
    "text": "our Network policies we don't pick our",
    "start": "1081620",
    "end": "1083539"
  },
  {
    "text": "containers by IP but we pick them by",
    "start": "1083539",
    "end": "1085640"
  },
  {
    "text": "labels so we can say some pods from some",
    "start": "1085640",
    "end": "1089000"
  },
  {
    "text": "labels we only want them to receive",
    "start": "1089000",
    "end": "1091520"
  },
  {
    "text": "traffic on a given port or we only want",
    "start": "1091520",
    "end": "1093980"
  },
  {
    "text": "them to receive traffic that comes from",
    "start": "1093980",
    "end": "1096080"
  },
  {
    "text": "pods with other labels",
    "start": "1096080",
    "end": "1099080"
  },
  {
    "text": "right and so again we do it with a bunch",
    "start": "1099080",
    "end": "1102919"
  },
  {
    "text": "of yaml this is an example where the",
    "start": "1102919",
    "end": "1106039"
  },
  {
    "text": "backing parts will only accept traffic",
    "start": "1106039",
    "end": "1108260"
  },
  {
    "text": "for from Bots that are labeled with",
    "start": "1108260",
    "end": "1110900"
  },
  {
    "text": "appname front-end and on only on this",
    "start": "1110900",
    "end": "1113539"
  },
  {
    "text": "very specific port",
    "start": "1113539",
    "end": "1114980"
  },
  {
    "text": "right so",
    "start": "1114980",
    "end": "1117260"
  },
  {
    "text": "find out which pods should communicate",
    "start": "1117260",
    "end": "1120380"
  },
  {
    "text": "with which other pods that's tricky",
    "start": "1120380",
    "end": "1123320"
  },
  {
    "text": "right yeah",
    "start": "1123320",
    "end": "1125059"
  },
  {
    "text": "if we don't know it beforehand it's it",
    "start": "1125059",
    "end": "1127580"
  },
  {
    "text": "can get very tricky",
    "start": "1127580",
    "end": "1129679"
  },
  {
    "text": "we can use some tools like Inspector",
    "start": "1129679",
    "end": "1132380"
  },
  {
    "text": "Gadget is a tool that we can monitor the",
    "start": "1132380",
    "end": "1134960"
  },
  {
    "text": "traffic across our cluster and generate",
    "start": "1134960",
    "end": "1137539"
  },
  {
    "text": "Network policy for us",
    "start": "1137539",
    "end": "1139640"
  },
  {
    "text": "indeed",
    "start": "1139640",
    "end": "1141380"
  },
  {
    "text": "if this is the default kubernetes",
    "start": "1141380",
    "end": "1144679"
  },
  {
    "text": "Network policy that allows us to filter",
    "start": "1144679",
    "end": "1147919"
  },
  {
    "text": "by labels as I mentioned but if we need",
    "start": "1147919",
    "end": "1150799"
  },
  {
    "text": "more advanced filtering for example we",
    "start": "1150799",
    "end": "1153200"
  },
  {
    "text": "want to do some layer 7 filtering or we",
    "start": "1153200",
    "end": "1156020"
  },
  {
    "text": "want to block accessing like the",
    "start": "1156020",
    "end": "1158059"
  },
  {
    "text": "metadata IP that our cloud provider has",
    "start": "1158059",
    "end": "1161260"
  },
  {
    "text": "for that we will need to use more",
    "start": "1161260",
    "end": "1163820"
  },
  {
    "text": "advanced Network policies like the ones",
    "start": "1163820",
    "end": "1165740"
  },
  {
    "text": "provided by the networking layers like",
    "start": "1165740",
    "end": "1167900"
  },
  {
    "text": "Calico or psyllium",
    "start": "1167900",
    "end": "1171160"
  },
  {
    "text": "all right so",
    "start": "1172039",
    "end": "1174140"
  },
  {
    "text": "now that we applied Network policies",
    "start": "1174140",
    "end": "1176179"
  },
  {
    "text": "what do you think is our cluster fully",
    "start": "1176179",
    "end": "1178100"
  },
  {
    "text": "secure no not really we need to apply",
    "start": "1178100",
    "end": "1181640"
  },
  {
    "text": "several layers of security",
    "start": "1181640",
    "end": "1183799"
  },
  {
    "text": "so we can reduce the impact of any",
    "start": "1183799",
    "end": "1186440"
  },
  {
    "text": "successful attack and reduce attack",
    "start": "1186440",
    "end": "1188419"
  },
  {
    "text": "surface also",
    "start": "1188419",
    "end": "1191320"
  },
  {
    "text": "this talk is not a security talk we will",
    "start": "1192020",
    "end": "1195380"
  },
  {
    "text": "cover a few security strategies but uh",
    "start": "1195380",
    "end": "1198980"
  },
  {
    "text": "please keep in mind that there's a lot",
    "start": "1198980",
    "end": "1202100"
  },
  {
    "text": "more to cover so uh we invite you to do",
    "start": "1202100",
    "end": "1206419"
  },
  {
    "text": "some research on your own to be sure",
    "start": "1206419",
    "end": "1208820"
  },
  {
    "text": "that you have covered all the security",
    "start": "1208820",
    "end": "1210380"
  },
  {
    "text": "Concepts we will divide our security",
    "start": "1210380",
    "end": "1212919"
  },
  {
    "text": "recommendations in three layers",
    "start": "1212919",
    "end": "1215200"
  },
  {
    "text": "minimizing the Privileges given to our",
    "start": "1215200",
    "end": "1217520"
  },
  {
    "text": "pods minimizing the vulnerabilities in",
    "start": "1217520",
    "end": "1220160"
  },
  {
    "text": "our container images and minimizing the",
    "start": "1220160",
    "end": "1222320"
  },
  {
    "text": "access that we give to users and service",
    "start": "1222320",
    "end": "1225080"
  },
  {
    "text": "accounts",
    "start": "1225080",
    "end": "1226340"
  },
  {
    "start": "1226000",
    "end": "1226000"
  },
  {
    "text": "right so something we probably didn't do",
    "start": "1226340",
    "end": "1229400"
  },
  {
    "text": "in in our VM world is to run our",
    "start": "1229400",
    "end": "1231500"
  },
  {
    "text": "applications as root",
    "start": "1231500",
    "end": "1233059"
  },
  {
    "text": "and but when we migrate to containers",
    "start": "1233059",
    "end": "1235660"
  },
  {
    "text": "for example Taylor here",
    "start": "1235660",
    "end": "1238520"
  },
  {
    "text": "created a Docker file based on the",
    "start": "1238520",
    "end": "1240740"
  },
  {
    "text": "docker documentation",
    "start": "1240740",
    "end": "1242780"
  },
  {
    "text": "and it seems very simple straight to the",
    "start": "1242780",
    "end": "1245059"
  },
  {
    "text": "point but where is hidden underneath is",
    "start": "1245059",
    "end": "1247280"
  },
  {
    "text": "that Java here runs its root that sounds",
    "start": "1247280",
    "end": "1250700"
  },
  {
    "text": "really bad",
    "start": "1250700",
    "end": "1251960"
  },
  {
    "text": "it is all right so what can we do uh so",
    "start": "1251960",
    "end": "1255500"
  },
  {
    "text": "in kubernetes we can use the runners",
    "start": "1255500",
    "end": "1257240"
  },
  {
    "text": "user and Runners group directive so we",
    "start": "1257240",
    "end": "1259820"
  },
  {
    "text": "can force the container to run as this",
    "start": "1259820",
    "end": "1261440"
  },
  {
    "text": "user and group",
    "start": "1261440",
    "end": "1262760"
  },
  {
    "text": "uh yeah yeah and that works if our",
    "start": "1262760",
    "end": "1265880"
  },
  {
    "text": "application can work as an unprivileged",
    "start": "1265880",
    "end": "1267919"
  },
  {
    "text": "user but unfortunately many",
    "start": "1267919",
    "end": "1269960"
  },
  {
    "text": "containerized applications kind of",
    "start": "1269960",
    "end": "1272179"
  },
  {
    "text": "expect to be running a throat so what",
    "start": "1272179",
    "end": "1274520"
  },
  {
    "text": "can we do in that case that can get",
    "start": "1274520",
    "end": "1276320"
  },
  {
    "text": "tricky there are several options uh one",
    "start": "1276320",
    "end": "1278419"
  },
  {
    "text": "is to use a feature called username",
    "start": "1278419",
    "end": "1280160"
  },
  {
    "text": "spaces I'm actively working on adding",
    "start": "1280160",
    "end": "1283100"
  },
  {
    "text": "that to kubernetes is actually an alpha",
    "start": "1283100",
    "end": "1285320"
  },
  {
    "text": "feature",
    "start": "1285320",
    "end": "1286720"
  },
  {
    "text": "and it basically tricks the applications",
    "start": "1286720",
    "end": "1289100"
  },
  {
    "text": "into thinking it's running as root but",
    "start": "1289100",
    "end": "1292159"
  },
  {
    "text": "this is only root inside the container",
    "start": "1292159",
    "end": "1293960"
  },
  {
    "text": "from the host point of view it's an",
    "start": "1293960",
    "end": "1295940"
  },
  {
    "text": "important user so if it escapes or",
    "start": "1295940",
    "end": "1298580"
  },
  {
    "text": "anything it doesn't have any privileges",
    "start": "1298580",
    "end": "1302059"
  },
  {
    "text": "uh we gave a talk about user namespaces",
    "start": "1302059",
    "end": "1305240"
  },
  {
    "text": "at the last cubecon so if you want to",
    "start": "1305240",
    "end": "1307280"
  },
  {
    "text": "learn more about that we invite you to",
    "start": "1307280",
    "end": "1309740"
  },
  {
    "text": "like check that out",
    "start": "1309740",
    "end": "1312580"
  },
  {
    "text": "okay all right sorry uh okay so the next",
    "start": "1315860",
    "end": "1320000"
  },
  {
    "start": "1317000",
    "end": "1317000"
  },
  {
    "text": "step is to minimize uh the",
    "start": "1320000",
    "end": "1322520"
  },
  {
    "text": "vulnerabilities in our container images",
    "start": "1322520",
    "end": "1325220"
  },
  {
    "text": "Taylor coming from the VM world may fall",
    "start": "1325220",
    "end": "1329419"
  },
  {
    "text": "into the Trap of thinking that the",
    "start": "1329419",
    "end": "1331340"
  },
  {
    "text": "repositories in the internet like Docker",
    "start": "1331340",
    "end": "1333380"
  },
  {
    "text": "Hub or Quay are actually trustworthy",
    "start": "1333380",
    "end": "1335600"
  },
  {
    "text": "like the repositories from the Linux",
    "start": "1335600",
    "end": "1338059"
  },
  {
    "text": "distributions but unfortunately that's",
    "start": "1338059",
    "end": "1340340"
  },
  {
    "text": "not the case anybody can load containers",
    "start": "1340340",
    "end": "1342799"
  },
  {
    "text": "there and so we can end up with",
    "start": "1342799",
    "end": "1344659"
  },
  {
    "text": "containers that have vulnerabilities",
    "start": "1344659",
    "end": "1346520"
  },
  {
    "text": "that are not up to date or even that",
    "start": "1346520",
    "end": "1348980"
  },
  {
    "text": "include malware like crypto mining",
    "start": "1348980",
    "end": "1351559"
  },
  {
    "text": "software or software that will",
    "start": "1351559",
    "end": "1353299"
  },
  {
    "text": "exfiltrate our credentials so what",
    "start": "1353299",
    "end": "1356059"
  },
  {
    "text": "should Taylor do instead so Taylor",
    "start": "1356059",
    "end": "1358580"
  },
  {
    "text": "should probably provide some golden",
    "start": "1358580",
    "end": "1360679"
  },
  {
    "text": "images to use as base for all in-house",
    "start": "1360679",
    "end": "1363559"
  },
  {
    "text": "applications",
    "start": "1363559",
    "end": "1364640"
  },
  {
    "text": "and to build these golden images we can",
    "start": "1364640",
    "end": "1367280"
  },
  {
    "text": "just build them from scratch using",
    "start": "1367280",
    "end": "1368659"
  },
  {
    "text": "turbos or we can use something we can",
    "start": "1368659",
    "end": "1370940"
  },
  {
    "text": "trust like uh",
    "start": "1370940",
    "end": "1372919"
  },
  {
    "text": "there are some images in Docker half",
    "start": "1372919",
    "end": "1374720"
  },
  {
    "text": "that has that have the official Docker",
    "start": "1374720",
    "end": "1377480"
  },
  {
    "text": "image tag",
    "start": "1377480",
    "end": "1378799"
  },
  {
    "text": "but the important thing here is to use",
    "start": "1378799",
    "end": "1381440"
  },
  {
    "text": "something we can trust and that will",
    "start": "1381440",
    "end": "1383000"
  },
  {
    "text": "release a security update if a security",
    "start": "1383000",
    "end": "1385220"
  },
  {
    "text": "issue is found",
    "start": "1385220",
    "end": "1386600"
  },
  {
    "text": "also like if we're providing golden",
    "start": "1386600",
    "end": "1388580"
  },
  {
    "text": "images uh",
    "start": "1388580",
    "end": "1390679"
  },
  {
    "text": "we can for example take the chance to",
    "start": "1390679",
    "end": "1392659"
  },
  {
    "text": "configure locals correctly so extended",
    "start": "1392659",
    "end": "1395780"
  },
  {
    "text": "characters are shown correctly in logs",
    "start": "1395780",
    "end": "1398360"
  },
  {
    "text": "or we can add some debug tools that",
    "start": "1398360",
    "end": "1401240"
  },
  {
    "text": "we'll need later",
    "start": "1401240",
    "end": "1404020"
  },
  {
    "start": "1404000",
    "end": "1404000"
  },
  {
    "text": "uh we also want to minimize the attack",
    "start": "1404480",
    "end": "1406760"
  },
  {
    "text": "Surface by adding a second profile",
    "start": "1406760",
    "end": "1410299"
  },
  {
    "text": "second will this the simplest way to add",
    "start": "1410299",
    "end": "1413600"
  },
  {
    "text": "this is to use the runtime default",
    "start": "1413600",
    "end": "1414980"
  },
  {
    "text": "profile that is shipped with containers",
    "start": "1414980",
    "end": "1416780"
  },
  {
    "text": "this will basically allow all the Cisco",
    "start": "1416780",
    "end": "1419360"
  },
  {
    "text": "that we will really need and and just",
    "start": "1419360",
    "end": "1422240"
  },
  {
    "text": "deny some like dangerous ciscals and",
    "start": "1422240",
    "end": "1426080"
  },
  {
    "text": "starting with kubernetes 127 that was",
    "start": "1426080",
    "end": "1428900"
  },
  {
    "text": "released like a few days ago we can just",
    "start": "1428900",
    "end": "1431900"
  },
  {
    "text": "apply this cluster wide and not modify",
    "start": "1431900",
    "end": "1434720"
  },
  {
    "text": "all the deployments yamos that were like",
    "start": "1434720",
    "end": "1436940"
  },
  {
    "text": "we're doing here right and if we need if",
    "start": "1436940",
    "end": "1439400"
  },
  {
    "text": "we think more specific specific we can",
    "start": "1439400",
    "end": "1440960"
  },
  {
    "text": "also create our own customized second",
    "start": "1440960",
    "end": "1442700"
  },
  {
    "text": "profile this could help us if we want to",
    "start": "1442700",
    "end": "1445600"
  },
  {
    "text": "really really limit the amount of",
    "start": "1445600",
    "end": "1448039"
  },
  {
    "text": "ciscals that are executed by our pods",
    "start": "1448039",
    "end": "1450679"
  },
  {
    "text": "and we can use the tool that Rodrigo",
    "start": "1450679",
    "end": "1453200"
  },
  {
    "text": "mentioned earlier Inspector Gadget to",
    "start": "1453200",
    "end": "1455539"
  },
  {
    "text": "figure out which ones are the calls that",
    "start": "1455539",
    "end": "1457700"
  },
  {
    "text": "our pods should do and then only allow",
    "start": "1457700",
    "end": "1460520"
  },
  {
    "text": "those",
    "start": "1460520",
    "end": "1462700"
  },
  {
    "text": "all right and the last layer of defense",
    "start": "1462700",
    "end": "1465919"
  },
  {
    "text": "that I mentioned earlier is minimizing",
    "start": "1465919",
    "end": "1467900"
  },
  {
    "text": "access so it kind of can be tempting",
    "start": "1467900",
    "end": "1472100"
  },
  {
    "text": "when you're starting with kubernetes to",
    "start": "1472100",
    "end": "1474080"
  },
  {
    "text": "just do everything as cluster I mean so",
    "start": "1474080",
    "end": "1476780"
  },
  {
    "text": "using the cluster I mean role which has",
    "start": "1476780",
    "end": "1479780"
  },
  {
    "text": "access to all of the cluster you can",
    "start": "1479780",
    "end": "1482059"
  },
  {
    "text": "create new pods on any namespace you can",
    "start": "1482059",
    "end": "1485000"
  },
  {
    "text": "add or delete things No Limits but using",
    "start": "1485000",
    "end": "1489200"
  },
  {
    "text": "the cluster of Bin row is equivalent to",
    "start": "1489200",
    "end": "1491179"
  },
  {
    "text": "being root on a VM so if you couldn't",
    "start": "1491179",
    "end": "1493820"
  },
  {
    "text": "give root to your developers then you",
    "start": "1493820",
    "end": "1496520"
  },
  {
    "text": "shouldn't give cluster admin to your",
    "start": "1496520",
    "end": "1498260"
  },
  {
    "text": "developers you should instead use a tool",
    "start": "1498260",
    "end": "1501380"
  },
  {
    "text": "called rbac role-based Access Control",
    "start": "1501380",
    "end": "1503539"
  },
  {
    "text": "where you limit what people can do",
    "start": "1503539",
    "end": "1506799"
  },
  {
    "text": "depending on their roles so for example",
    "start": "1506799",
    "end": "1509480"
  },
  {
    "text": "in Taylor's case they could give the",
    "start": "1509480",
    "end": "1512720"
  },
  {
    "text": "developers access to the dev namespace",
    "start": "1512720",
    "end": "1515179"
  },
  {
    "text": "but no access to the problem cell or",
    "start": "1515179",
    "end": "1517940"
  },
  {
    "text": "very limited access to the pro name size",
    "start": "1517940",
    "end": "1520700"
  },
  {
    "text": "all right and with that we've reached",
    "start": "1520700",
    "end": "1523340"
  },
  {
    "text": "the end of our talk we saw a bunch of",
    "start": "1523340",
    "end": "1525799"
  },
  {
    "text": "different yaml files like deployment and",
    "start": "1525799",
    "end": "1528380"
  },
  {
    "text": "service and Ingress and horizontal",
    "start": "1528380",
    "end": "1530659"
  },
  {
    "text": "product scalar Network policies",
    "start": "1530659",
    "end": "1534380"
  },
  {
    "text": "it might be a little bit confusing but",
    "start": "1534380",
    "end": "1537260"
  },
  {
    "text": "the key takeaway yeah the key takeaway",
    "start": "1537260",
    "end": "1539900"
  },
  {
    "text": "is probably uh",
    "start": "1539900",
    "end": "1541880"
  },
  {
    "text": "that coordinates is an obstruction layer",
    "start": "1541880",
    "end": "1543980"
  },
  {
    "text": "we can use to automate a lot of tax",
    "start": "1543980",
    "end": "1545659"
  },
  {
    "text": "tasks uh we can fit it with yaml words",
    "start": "1545659",
    "end": "1548539"
  },
  {
    "text": "we specify",
    "start": "1548539",
    "end": "1550159"
  },
  {
    "text": "how we want things to look like and it",
    "start": "1550159",
    "end": "1553340"
  },
  {
    "text": "doesn't really matter if we're running",
    "start": "1553340",
    "end": "1554539"
  },
  {
    "text": "in Azure in Google cloud in apps around",
    "start": "1554539",
    "end": "1556700"
  },
  {
    "text": "in Berlin kubernetes will just take care",
    "start": "1556700",
    "end": "1559159"
  },
  {
    "text": "of uh making a reality what we desire",
    "start": "1559159",
    "end": "1563179"
  },
  {
    "text": "all right so that was yeah the tip of",
    "start": "1563179",
    "end": "1566240"
  },
  {
    "text": "the iceberg of all of the things Cloud",
    "start": "1566240",
    "end": "1568520"
  },
  {
    "text": "native but we hoped it was good for you",
    "start": "1568520",
    "end": "1571460"
  },
  {
    "text": "as a very quick introduction we've",
    "start": "1571460",
    "end": "1574700"
  },
  {
    "text": "included a bunch of references in the",
    "start": "1574700",
    "end": "1576860"
  },
  {
    "start": "1575000",
    "end": "1575000"
  },
  {
    "text": "slides that we uploaded to the system so",
    "start": "1576860",
    "end": "1579559"
  },
  {
    "text": "if you want to like follow some links uh",
    "start": "1579559",
    "end": "1582260"
  },
  {
    "text": "they are in the scheduling",
    "start": "1582260",
    "end": "1585020"
  },
  {
    "start": "1585000",
    "end": "1585000"
  },
  {
    "text": "and we would love to hear your questions",
    "start": "1585020",
    "end": "1587840"
  },
  {
    "text": "now if you have any",
    "start": "1587840",
    "end": "1591039"
  },
  {
    "text": "or not",
    "start": "1593000",
    "end": "1595080"
  },
  {
    "text": "[Applause]",
    "start": "1595080",
    "end": "1604320"
  },
  {
    "text": "no questions all right then thank you",
    "start": "1604820",
    "end": "1607760"
  },
  {
    "text": "very much thank you",
    "start": "1607760",
    "end": "1611200"
  }
]
[
  {
    "text": "sure hello I'm Richard",
    "start": "240",
    "end": "3959"
  },
  {
    "text": "and I'm sure and first of all sorry for",
    "start": "3959",
    "end": "7140"
  },
  {
    "text": "keeping you waiting because we have just",
    "start": "7140",
    "end": "9059"
  },
  {
    "text": "been juggling around today with a bunch",
    "start": "9059",
    "end": "10920"
  },
  {
    "text": "of talks so I hope you're able to gain",
    "start": "10920",
    "end": "13440"
  },
  {
    "text": "from today's talk yeah so in the next 30",
    "start": "13440",
    "end": "16440"
  },
  {
    "text": "minutes we'll be talking about",
    "start": "16440",
    "end": "18000"
  },
  {
    "text": "Prometheus in the mlops life cycle uh we",
    "start": "18000",
    "end": "21480"
  },
  {
    "text": "want to talk a bit about things that",
    "start": "21480",
    "end": "23400"
  },
  {
    "text": "have worked for us using Prometheus both",
    "start": "23400",
    "end": "26220"
  },
  {
    "text": "of us have been working closely with",
    "start": "26220",
    "end": "27720"
  },
  {
    "text": "machine learning things that have worked",
    "start": "27720",
    "end": "29160"
  },
  {
    "text": "for us and uh that's what some of the",
    "start": "29160",
    "end": "32398"
  },
  {
    "text": "things we'll talk about monitoring",
    "start": "32399",
    "end": "34260"
  },
  {
    "text": "especially in the context of machine",
    "start": "34260",
    "end": "35700"
  },
  {
    "text": "learning so um I'm Richard I'm a student",
    "start": "35700",
    "end": "39360"
  },
  {
    "text": "at the University of Toronto",
    "start": "39360",
    "end": "41340"
  },
  {
    "text": "and hi I'm sure I am a contrader and",
    "start": "41340",
    "end": "43200"
  },
  {
    "text": "maintainer at layer 5 which is a service",
    "start": "43200",
    "end": "45000"
  },
  {
    "text": "mesh community",
    "start": "45000",
    "end": "46320"
  },
  {
    "text": "okay so uh when we are talking about",
    "start": "46320",
    "end": "49140"
  },
  {
    "text": "monitoring uh the the traditional",
    "start": "49140",
    "end": "51360"
  },
  {
    "text": "software monitoring",
    "start": "51360",
    "end": "53120"
  },
  {
    "text": "a lot of you might know about monitoring",
    "start": "53120",
    "end": "56219"
  },
  {
    "text": "and softwares or you might have done it",
    "start": "56219",
    "end": "58260"
  },
  {
    "text": "a lot earlier using Prometheus or maybe",
    "start": "58260",
    "end": "61020"
  },
  {
    "text": "some other tool but if you don't uh",
    "start": "61020",
    "end": "63120"
  },
  {
    "text": "usually monitoring in the context of",
    "start": "63120",
    "end": "66000"
  },
  {
    "text": "software uh includes that you think",
    "start": "66000",
    "end": "70020"
  },
  {
    "text": "about slo's monitor uh monitor if your",
    "start": "70020",
    "end": "72840"
  },
  {
    "text": "slos are being made",
    "start": "72840",
    "end": "74600"
  },
  {
    "text": "monitor system failures and so on",
    "start": "74600",
    "end": "77340"
  },
  {
    "text": "there's a lot of things that monitoring",
    "start": "77340",
    "end": "79320"
  },
  {
    "text": "means",
    "start": "79320",
    "end": "81680"
  },
  {
    "text": "and if we talk in the perspective of",
    "start": "82140",
    "end": "84540"
  },
  {
    "text": "machine learning right because today's",
    "start": "84540",
    "end": "85740"
  },
  {
    "text": "talk is all about ml Ops uh so if you",
    "start": "85740",
    "end": "88080"
  },
  {
    "text": "take a look at this diagram for the ml",
    "start": "88080",
    "end": "90420"
  },
  {
    "text": "Ops or the machine learning life cycle",
    "start": "90420",
    "end": "92220"
  },
  {
    "text": "there are of course multiple steps right",
    "start": "92220",
    "end": "94560"
  },
  {
    "text": "from getting your input data and",
    "start": "94560",
    "end": "96720"
  },
  {
    "text": "cleaning it up and then using that data",
    "start": "96720",
    "end": "99180"
  },
  {
    "text": "to train your Machinery model and going",
    "start": "99180",
    "end": "101400"
  },
  {
    "text": "ahead and evaluating your model testing",
    "start": "101400",
    "end": "103860"
  },
  {
    "text": "your model and then finally",
    "start": "103860",
    "end": "104700"
  },
  {
    "text": "productionizing it and post the",
    "start": "104700",
    "end": "106740"
  },
  {
    "text": "productionizing of a model you are also",
    "start": "106740",
    "end": "108540"
  },
  {
    "text": "looking at looking to always test your",
    "start": "108540",
    "end": "110700"
  },
  {
    "text": "model from time to time to ensure that",
    "start": "110700",
    "end": "112799"
  },
  {
    "text": "the model performance does not degrade",
    "start": "112799",
    "end": "114659"
  },
  {
    "text": "as the model is being used in production",
    "start": "114659",
    "end": "116520"
  },
  {
    "text": "and uh post deployment here also",
    "start": "116520",
    "end": "119460"
  },
  {
    "text": "conditionally monitoring the model and",
    "start": "119460",
    "end": "121560"
  },
  {
    "text": "all of these are steps that are part of",
    "start": "121560",
    "end": "123540"
  },
  {
    "text": "the envelope's life cycle and that's",
    "start": "123540",
    "end": "125520"
  },
  {
    "text": "where specifically when when it comes to",
    "start": "125520",
    "end": "127860"
  },
  {
    "text": "from uh the monitoring and observability",
    "start": "127860",
    "end": "129539"
  },
  {
    "text": "side of things we'll see how Prometheus",
    "start": "129539",
    "end": "131400"
  },
  {
    "text": "plays a really key role",
    "start": "131400",
    "end": "134540"
  },
  {
    "text": "uh so we uh so we want to talk about",
    "start": "136260",
    "end": "138599"
  },
  {
    "text": "monitoring in the context of ml sure",
    "start": "138599",
    "end": "140520"
  },
  {
    "text": "would you like to talk a bit about that",
    "start": "140520",
    "end": "142739"
  },
  {
    "text": "sure so uh if we take a look at the",
    "start": "142739",
    "end": "145500"
  },
  {
    "text": "important use cases as I mentioned that",
    "start": "145500",
    "end": "147239"
  },
  {
    "text": "once you productionize your model uh",
    "start": "147239",
    "end": "150239"
  },
  {
    "text": "there are a lot of hidden variables that",
    "start": "150239",
    "end": "151920"
  },
  {
    "text": "might prop up because when you're",
    "start": "151920",
    "end": "153540"
  },
  {
    "text": "working with the production data there",
    "start": "153540",
    "end": "156300"
  },
  {
    "text": "might be cases where you might run into",
    "start": "156300",
    "end": "158459"
  },
  {
    "text": "edge cases where the model does not",
    "start": "158459",
    "end": "160200"
  },
  {
    "text": "perform uh then over time there's also a",
    "start": "160200",
    "end": "162780"
  },
  {
    "text": "possibility that the data Distribution",
    "start": "162780",
    "end": "164700"
  },
  {
    "text": "on the base of which originally your",
    "start": "164700",
    "end": "166379"
  },
  {
    "text": "model was streamed on that might shift",
    "start": "166379",
    "end": "168060"
  },
  {
    "text": "and there are we'll basically will be",
    "start": "168060",
    "end": "170340"
  },
  {
    "text": "explaining two different ways in terms",
    "start": "170340",
    "end": "171780"
  },
  {
    "text": "of the time and in terms of the data",
    "start": "171780",
    "end": "173519"
  },
  {
    "text": "drift so we have particularly two terms",
    "start": "173519",
    "end": "175560"
  },
  {
    "text": "that if you are in the ml ecosystem",
    "start": "175560",
    "end": "177599"
  },
  {
    "text": "concept drift and data drift a couple of",
    "start": "177599",
    "end": "179760"
  },
  {
    "text": "items that you will come across from",
    "start": "179760",
    "end": "181379"
  },
  {
    "text": "time to time and there could be",
    "start": "181379",
    "end": "183239"
  },
  {
    "text": "situations where a model might not be",
    "start": "183239",
    "end": "185400"
  },
  {
    "text": "configured properly so the idea is that",
    "start": "185400",
    "end": "188160"
  },
  {
    "text": "model will still make a prediction but",
    "start": "188160",
    "end": "190260"
  },
  {
    "text": "of course it's not uh always going to be",
    "start": "190260",
    "end": "193140"
  },
  {
    "text": "making a good prediction so that's what",
    "start": "193140",
    "end": "194879"
  },
  {
    "text": "we're also trying to monitor from time",
    "start": "194879",
    "end": "196800"
  },
  {
    "text": "to time that the prediction uh does not",
    "start": "196800",
    "end": "199319"
  },
  {
    "text": "go like the prediction rate does not go",
    "start": "199319",
    "end": "201659"
  },
  {
    "text": "down",
    "start": "201659",
    "end": "202980"
  },
  {
    "text": "so uh so so two things I particularly",
    "start": "202980",
    "end": "205800"
  },
  {
    "text": "want to mention is the aspect of",
    "start": "205800",
    "end": "208140"
  },
  {
    "text": "different challenges uh the monitoring",
    "start": "208140",
    "end": "210720"
  },
  {
    "text": "and context of machine learning and what",
    "start": "210720",
    "end": "212700"
  },
  {
    "text": "we want is pretty different from how you",
    "start": "212700",
    "end": "215340"
  },
  {
    "text": "might have been using Prometheus earlier",
    "start": "215340",
    "end": "217140"
  },
  {
    "text": "uh so so these are the different",
    "start": "217140",
    "end": "219120"
  },
  {
    "text": "challenges I particularly want to",
    "start": "219120",
    "end": "220739"
  },
  {
    "text": "highlight on and so the ideas are a bit",
    "start": "220739",
    "end": "224519"
  },
  {
    "text": "different here what we want to achieve",
    "start": "224519",
    "end": "226019"
  },
  {
    "text": "is a bit different than traditional",
    "start": "226019",
    "end": "227940"
  },
  {
    "text": "software and uh I also want to highlight",
    "start": "227940",
    "end": "231060"
  },
  {
    "text": "that the system goes through properly",
    "start": "231060",
    "end": "233159"
  },
  {
    "text": "there is no error as such you don't have",
    "start": "233159",
    "end": "236159"
  },
  {
    "text": "any system failure you don't have any",
    "start": "236159",
    "end": "237659"
  },
  {
    "text": "SLO failure nothing at all the model",
    "start": "237659",
    "end": "240060"
  },
  {
    "text": "still makes a prediction but you are",
    "start": "240060",
    "end": "241739"
  },
  {
    "text": "still doing something wrong it could be",
    "start": "241739",
    "end": "242940"
  },
  {
    "text": "you are still doing something wrong the",
    "start": "242940",
    "end": "244799"
  },
  {
    "text": "model does not make sensible predictions",
    "start": "244799",
    "end": "246480"
  },
  {
    "text": "so this is also a very interesting use",
    "start": "246480",
    "end": "248760"
  },
  {
    "text": "case everything works perfectly there is",
    "start": "248760",
    "end": "250439"
  },
  {
    "text": "no error but you still need to be able",
    "start": "250439",
    "end": "252959"
  },
  {
    "text": "to monitor in those situations",
    "start": "252959",
    "end": "254939"
  },
  {
    "text": "so uh so the ideas are a bit different",
    "start": "254939",
    "end": "257880"
  },
  {
    "text": "here uh in context to uh in contextual",
    "start": "257880",
    "end": "261479"
  },
  {
    "text": "software",
    "start": "261479",
    "end": "263220"
  },
  {
    "text": "uh so what we want to do is not just uh",
    "start": "263220",
    "end": "266759"
  },
  {
    "text": "so not just many monitor system metrics",
    "start": "266759",
    "end": "269520"
  },
  {
    "text": "and resource metrics which we already do",
    "start": "269520",
    "end": "271860"
  },
  {
    "text": "we introduce a third term over here",
    "start": "271860",
    "end": "273780"
  },
  {
    "text": "called Model Matrix which is trying to",
    "start": "273780",
    "end": "276900"
  },
  {
    "text": "figure out all of this the model still",
    "start": "276900",
    "end": "278820"
  },
  {
    "text": "uh the model is still giving you",
    "start": "278820",
    "end": "280380"
  },
  {
    "text": "predictions there is no error but you",
    "start": "280380",
    "end": "282600"
  },
  {
    "text": "will have to figure out something make",
    "start": "282600",
    "end": "284460"
  },
  {
    "text": "monitoring work just by getting the",
    "start": "284460",
    "end": "286919"
  },
  {
    "text": "model Matrix so that is what we want to",
    "start": "286919",
    "end": "290040"
  },
  {
    "text": "do and",
    "start": "290040",
    "end": "292020"
  },
  {
    "text": "yeah in this presentation also we'll",
    "start": "292020",
    "end": "294600"
  },
  {
    "text": "particularly be stressing on model",
    "start": "294600",
    "end": "296160"
  },
  {
    "text": "Matrix part because system Matrix",
    "start": "296160",
    "end": "298320"
  },
  {
    "text": "resource metrics you might have been uh",
    "start": "298320",
    "end": "300900"
  },
  {
    "text": "doing that since since uh since a long",
    "start": "300900",
    "end": "303240"
  },
  {
    "text": "time or some other talks even before us",
    "start": "303240",
    "end": "304919"
  },
  {
    "text": "uh some other talks even before us uh do",
    "start": "304919",
    "end": "307680"
  },
  {
    "text": "cover this so uh we want to talk more",
    "start": "307680",
    "end": "310440"
  },
  {
    "text": "about the context of ml uh so we have uh",
    "start": "310440",
    "end": "314100"
  },
  {
    "text": "so we have more in this presentation",
    "start": "314100",
    "end": "316500"
  },
  {
    "text": "we'll talk about monitoring model",
    "start": "316500",
    "end": "318780"
  },
  {
    "text": "metrics so uh so so two of the main",
    "start": "318780",
    "end": "322259"
  },
  {
    "text": "things we want to monitor uh and I just",
    "start": "322259",
    "end": "324960"
  },
  {
    "text": "set your context or give you an example",
    "start": "324960",
    "end": "327120"
  },
  {
    "text": "of why uh you might still want to",
    "start": "327120",
    "end": "329759"
  },
  {
    "text": "monitor if your system works well there",
    "start": "329759",
    "end": "332100"
  },
  {
    "text": "is no error uh so it could happen that",
    "start": "332100",
    "end": "334320"
  },
  {
    "text": "environment changes affect the model so",
    "start": "334320",
    "end": "337440"
  },
  {
    "text": "for example uh here uh there could just",
    "start": "337440",
    "end": "341580"
  },
  {
    "text": "be a different environment from when you",
    "start": "341580",
    "end": "344280"
  },
  {
    "text": "had created a model",
    "start": "344280",
    "end": "345840"
  },
  {
    "text": "and now when you're deploying the model",
    "start": "345840",
    "end": "347280"
  },
  {
    "text": "the environmental variables are all",
    "start": "347280",
    "end": "349500"
  },
  {
    "text": "different",
    "start": "349500",
    "end": "350580"
  },
  {
    "text": "in that case your model works well your",
    "start": "350580",
    "end": "354479"
  },
  {
    "text": "model works but it does not work as we",
    "start": "354479",
    "end": "356940"
  },
  {
    "text": "expected it to be it does not give you",
    "start": "356940",
    "end": "358800"
  },
  {
    "text": "the right predictions there could also",
    "start": "358800",
    "end": "360360"
  },
  {
    "text": "be a change in data distribution so the",
    "start": "360360",
    "end": "363120"
  },
  {
    "text": "idea of the so the thing we want to do",
    "start": "363120",
    "end": "365280"
  },
  {
    "text": "with Prometheus in the mL of life cycle",
    "start": "365280",
    "end": "367560"
  },
  {
    "text": "is uh have a model uh trained on some",
    "start": "367560",
    "end": "371340"
  },
  {
    "text": "data and then apply it uh and then make",
    "start": "371340",
    "end": "375360"
  },
  {
    "text": "predictions from it now a lot of you",
    "start": "375360",
    "end": "378780"
  },
  {
    "text": "might tell me that's not exactly what we",
    "start": "378780",
    "end": "381419"
  },
  {
    "text": "want to do that's a very simplified way",
    "start": "381419",
    "end": "383520"
  },
  {
    "text": "of saying it you would also iterate your",
    "start": "383520",
    "end": "385800"
  },
  {
    "text": "model and do all that but let's just",
    "start": "385800",
    "end": "387479"
  },
  {
    "text": "stick with the simplified definition for",
    "start": "387479",
    "end": "389100"
  },
  {
    "text": "right now and one thing that could",
    "start": "389100",
    "end": "392220"
  },
  {
    "text": "majorly go wrong and still have your",
    "start": "392220",
    "end": "394380"
  },
  {
    "text": "model work but we want to get that each",
    "start": "394380",
    "end": "396479"
  },
  {
    "text": "case in our monitoring aspect is that",
    "start": "396479",
    "end": "400139"
  },
  {
    "text": "the data Distribution on which you",
    "start": "400139",
    "end": "402120"
  },
  {
    "text": "trained your model is different from the",
    "start": "402120",
    "end": "404639"
  },
  {
    "text": "data Distribution on which your model is",
    "start": "404639",
    "end": "406440"
  },
  {
    "text": "working",
    "start": "406440",
    "end": "408060"
  },
  {
    "text": "so uh so so think of it as the data on",
    "start": "408060",
    "end": "413460"
  },
  {
    "text": "which your model is making predictions",
    "start": "413460",
    "end": "415280"
  },
  {
    "text": "should be in the same distribution or it",
    "start": "415280",
    "end": "417900"
  },
  {
    "text": "should be in the same likelihood of",
    "start": "417900",
    "end": "419400"
  },
  {
    "text": "distribution",
    "start": "419400",
    "end": "420600"
  },
  {
    "text": "as your original data and there are",
    "start": "420600",
    "end": "422940"
  },
  {
    "text": "multiple mathematical models to measure",
    "start": "422940",
    "end": "425160"
  },
  {
    "text": "this uh multiple ways you can do this",
    "start": "425160",
    "end": "428160"
  },
  {
    "text": "and will not go into the machine",
    "start": "428160",
    "end": "430440"
  },
  {
    "text": "learning specific aspects in the stock",
    "start": "430440",
    "end": "432500"
  },
  {
    "text": "but these are the two ways uh very",
    "start": "432500",
    "end": "436740"
  },
  {
    "text": "popularly known as concept drift and",
    "start": "436740",
    "end": "438539"
  },
  {
    "text": "data drift",
    "start": "438539",
    "end": "440039"
  },
  {
    "text": "so we also want to monitor these well",
    "start": "440039",
    "end": "442440"
  },
  {
    "text": "we'll think of them as edge cases",
    "start": "442440",
    "end": "444900"
  },
  {
    "text": "we we still want to monitor all of this",
    "start": "444900",
    "end": "448620"
  },
  {
    "text": "so can you talk a bit about how",
    "start": "448620",
    "end": "450360"
  },
  {
    "text": "Prometheus comes into play sure so this",
    "start": "450360",
    "end": "452819"
  },
  {
    "text": "is where like you know we're talking",
    "start": "452819",
    "end": "453960"
  },
  {
    "text": "about Prometheus so so far what we saw",
    "start": "453960",
    "end": "456419"
  },
  {
    "text": "was that the system metrics are",
    "start": "456419",
    "end": "458400"
  },
  {
    "text": "something that probably was already",
    "start": "458400",
    "end": "459960"
  },
  {
    "text": "covered in some of the earlier talks and",
    "start": "459960",
    "end": "462000"
  },
  {
    "text": "some of you who might be Prometheus",
    "start": "462000",
    "end": "463680"
  },
  {
    "text": "users might be already doing that so uh",
    "start": "463680",
    "end": "466020"
  },
  {
    "text": "this is a quick sample of how you could",
    "start": "466020",
    "end": "468780"
  },
  {
    "text": "potentially use Prometheus because it's",
    "start": "468780",
    "end": "471300"
  },
  {
    "text": "one of the most uh promising uh like you",
    "start": "471300",
    "end": "474240"
  },
  {
    "text": "know tools to be able to monitor your",
    "start": "474240",
    "end": "476039"
  },
  {
    "text": "model performance and also the model",
    "start": "476039",
    "end": "477479"
  },
  {
    "text": "health so you can use a combination of",
    "start": "477479",
    "end": "479160"
  },
  {
    "text": "both parameters and Griffin and that's",
    "start": "479160",
    "end": "480900"
  },
  {
    "text": "what we're going to be showing in",
    "start": "480900",
    "end": "482099"
  },
  {
    "text": "today's demo as well so primarily what",
    "start": "482099",
    "end": "484560"
  },
  {
    "text": "we are doing is that Prometheus will",
    "start": "484560",
    "end": "486120"
  },
  {
    "text": "allow you to scrape your data so even if",
    "start": "486120",
    "end": "488639"
  },
  {
    "text": "you are having a Time series uh database",
    "start": "488639",
    "end": "490979"
  },
  {
    "text": "um or times data that that's what you",
    "start": "490979",
    "end": "492840"
  },
  {
    "text": "will be able to capture with the help of",
    "start": "492840",
    "end": "494280"
  },
  {
    "text": "Prometheus and then uh you you'll be",
    "start": "494280",
    "end": "496319"
  },
  {
    "text": "able to see the Prometheus logs and",
    "start": "496319",
    "end": "497639"
  },
  {
    "text": "using that at least you'll be able to",
    "start": "497639",
    "end": "499080"
  },
  {
    "text": "see how does the model performance vary",
    "start": "499080",
    "end": "502020"
  },
  {
    "text": "over time and that will give you some",
    "start": "502020",
    "end": "504300"
  },
  {
    "text": "insights to understand whether the",
    "start": "504300",
    "end": "506099"
  },
  {
    "text": "perform with the performance of a model",
    "start": "506099",
    "end": "507720"
  },
  {
    "text": "is actually uh degrading over time as",
    "start": "507720",
    "end": "510479"
  },
  {
    "text": "you kind of analyze these logs that you",
    "start": "510479",
    "end": "512760"
  },
  {
    "text": "get from Prometheus and of course over",
    "start": "512760",
    "end": "514860"
  },
  {
    "text": "that you can put in some alerts with pay",
    "start": "514860",
    "end": "517020"
  },
  {
    "text": "the duty or email and then you can also",
    "start": "517020",
    "end": "519599"
  },
  {
    "text": "go ahead and view them on a grafana",
    "start": "519599",
    "end": "521700"
  },
  {
    "text": "dashboard that we'll be also covering in",
    "start": "521700",
    "end": "523200"
  },
  {
    "text": "today's demonstration so it makes it",
    "start": "523200",
    "end": "525540"
  },
  {
    "text": "easy for as a data scientist or as an ml",
    "start": "525540",
    "end": "528240"
  },
  {
    "text": "Ops engineer to integrate Prometheus to",
    "start": "528240",
    "end": "531180"
  },
  {
    "text": "see how the model performance works over",
    "start": "531180",
    "end": "533700"
  },
  {
    "text": "time especially because we might have",
    "start": "533700",
    "end": "535680"
  },
  {
    "text": "some edge cases that might not be",
    "start": "535680",
    "end": "537120"
  },
  {
    "text": "considered when deploying the model",
    "start": "537120",
    "end": "538980"
  },
  {
    "text": "initially so as part of the model",
    "start": "538980",
    "end": "541200"
  },
  {
    "text": "serving process it plays a really",
    "start": "541200",
    "end": "543660"
  },
  {
    "text": "important hand in determining how and",
    "start": "543660",
    "end": "546839"
  },
  {
    "text": "what changes will you be making inside",
    "start": "546839",
    "end": "548399"
  },
  {
    "text": "of your model post uh going into",
    "start": "548399",
    "end": "550500"
  },
  {
    "text": "production",
    "start": "550500",
    "end": "551760"
  },
  {
    "text": "great so next up uh we'll actually oh",
    "start": "551760",
    "end": "555600"
  },
  {
    "text": "let's go one slide back and uh next up",
    "start": "555600",
    "end": "558540"
  },
  {
    "text": "we'll actually take a look at two demos",
    "start": "558540",
    "end": "560459"
  },
  {
    "text": "and we'll get more context for these",
    "start": "560459",
    "end": "562980"
  },
  {
    "text": "demos uh so uh so we'll try to show how",
    "start": "562980",
    "end": "566399"
  },
  {
    "text": "how do you do this different kind of",
    "start": "566399",
    "end": "569279"
  },
  {
    "text": "monitoring or monitoring in a different",
    "start": "569279",
    "end": "570959"
  },
  {
    "text": "context like we talked about monitor all",
    "start": "570959",
    "end": "573180"
  },
  {
    "text": "the aspects that we talked about uh so",
    "start": "573180",
    "end": "576000"
  },
  {
    "text": "Shiva would you like to start out with a",
    "start": "576000",
    "end": "577980"
  },
  {
    "text": "demo of uh showing Prometheus on Sheldon",
    "start": "577980",
    "end": "581399"
  },
  {
    "text": "me this quickly connect",
    "start": "581399",
    "end": "584720"
  },
  {
    "text": "Ed",
    "start": "602040",
    "end": "604040"
  },
  {
    "text": "perfect",
    "start": "607320",
    "end": "610320"
  },
  {
    "text": "all right so just a quick introduction",
    "start": "623519",
    "end": "625680"
  },
  {
    "text": "about Selden itself so Selden is a bunch",
    "start": "625680",
    "end": "629279"
  },
  {
    "text": "of tools provided to you it's an open",
    "start": "629279",
    "end": "630720"
  },
  {
    "text": "source Tool uh specifically for model",
    "start": "630720",
    "end": "633420"
  },
  {
    "text": "serving model performance model",
    "start": "633420",
    "end": "635339"
  },
  {
    "text": "monitoring model deployment so it works",
    "start": "635339",
    "end": "638100"
  },
  {
    "text": "very closely with Q flow so you can",
    "start": "638100",
    "end": "640320"
  },
  {
    "text": "definitely check it out but what we are",
    "start": "640320",
    "end": "642000"
  },
  {
    "text": "going to be covering is uh the",
    "start": "642000",
    "end": "644279"
  },
  {
    "text": "demonstration for uh how you can use",
    "start": "644279",
    "end": "646680"
  },
  {
    "text": "perimeters so it's going to be little",
    "start": "646680",
    "end": "649019"
  },
  {
    "text": "difficult for me to kind of stretch to",
    "start": "649019",
    "end": "651120"
  },
  {
    "text": "go to the screen or let me actually try",
    "start": "651120",
    "end": "653760"
  },
  {
    "text": "to monitor let me try to just go ahead",
    "start": "653760",
    "end": "656220"
  },
  {
    "text": "and",
    "start": "656220",
    "end": "657420"
  },
  {
    "text": "um",
    "start": "657420",
    "end": "658260"
  },
  {
    "text": "mirror my screen the stone skin",
    "start": "658260",
    "end": "662060"
  },
  {
    "text": "I think so now it should be better",
    "start": "666660",
    "end": "668519"
  },
  {
    "text": "yeah perfect so what we're going to be",
    "start": "668519",
    "end": "671459"
  },
  {
    "text": "covering is an example for being able to",
    "start": "671459",
    "end": "673800"
  },
  {
    "text": "view the Prometheus metrics with the",
    "start": "673800",
    "end": "675660"
  },
  {
    "text": "help of Selden so uh some of the",
    "start": "675660",
    "end": "678480"
  },
  {
    "text": "prequencies that you will require in",
    "start": "678480",
    "end": "679740"
  },
  {
    "text": "case you also want to use that you have",
    "start": "679740",
    "end": "682500"
  },
  {
    "text": "to install the Selden core uh so for",
    "start": "682500",
    "end": "685079"
  },
  {
    "text": "that you need probably a kubernetes",
    "start": "685079",
    "end": "686579"
  },
  {
    "text": "cluster you can use kind if you're",
    "start": "686579",
    "end": "687839"
  },
  {
    "text": "running it locally or you can also use",
    "start": "687839",
    "end": "689640"
  },
  {
    "text": "services like civo or ziki or any other",
    "start": "689640",
    "end": "692279"
  },
  {
    "text": "cloud provider to just have a kubernetes",
    "start": "692279",
    "end": "694620"
  },
  {
    "text": "cluster running so in my case",
    "start": "694620",
    "end": "697019"
  },
  {
    "text": "um and I'll just open up my",
    "start": "697019",
    "end": "699240"
  },
  {
    "text": "terminal as well so in my case I have",
    "start": "699240",
    "end": "702420"
  },
  {
    "text": "and let me just quickly show you my Cube",
    "start": "702420",
    "end": "705420"
  },
  {
    "text": "config so let's go to my DOT Cube",
    "start": "705420",
    "end": "710720"
  },
  {
    "text": "all right so if you're able to see that",
    "start": "714420",
    "end": "716519"
  },
  {
    "text": "uh right now I'm running my kubernetes",
    "start": "716519",
    "end": "718800"
  },
  {
    "text": "cluster it's a gke cluster so it's",
    "start": "718800",
    "end": "720480"
  },
  {
    "text": "running on Google cloud and what I've",
    "start": "720480",
    "end": "723300"
  },
  {
    "text": "done is that I've already configured my",
    "start": "723300",
    "end": "725700"
  },
  {
    "text": "and I'll just quickly show you my",
    "start": "725700",
    "end": "727260"
  },
  {
    "text": "quebecile pods as well so let me just go",
    "start": "727260",
    "end": "730260"
  },
  {
    "text": "ahead and do that",
    "start": "730260",
    "end": "732120"
  },
  {
    "text": "a while he does that uh what's the right",
    "start": "732120",
    "end": "734579"
  },
  {
    "text": "way to say Cube CTL",
    "start": "734579",
    "end": "738120"
  },
  {
    "text": "any",
    "start": "738120",
    "end": "740700"
  },
  {
    "text": "anyone wants to go first I say it as",
    "start": "740700",
    "end": "743339"
  },
  {
    "text": "cube cattle",
    "start": "743339",
    "end": "745019"
  },
  {
    "text": "if you say it another way please don't",
    "start": "745019",
    "end": "747540"
  },
  {
    "text": "hate me or hit survive go on yeah so as",
    "start": "747540",
    "end": "750839"
  },
  {
    "text": "you can see that uh currently I have a",
    "start": "750839",
    "end": "752459"
  },
  {
    "text": "number of different services that are",
    "start": "752459",
    "end": "753779"
  },
  {
    "text": "pre-configured in my quebecile I I hope",
    "start": "753779",
    "end": "756060"
  },
  {
    "text": "that everyone is able to see the screen",
    "start": "756060",
    "end": "758040"
  },
  {
    "text": "right yeah so you can see that I have uh",
    "start": "758040",
    "end": "761220"
  },
  {
    "text": "of course issue because istio Gateway is",
    "start": "761220",
    "end": "763440"
  },
  {
    "text": "used for monitoring and monitoring and",
    "start": "763440",
    "end": "765660"
  },
  {
    "text": "kind of like looking at all the traffic",
    "start": "765660",
    "end": "767040"
  },
  {
    "text": "that is going on so we have an SQ",
    "start": "767040",
    "end": "768600"
  },
  {
    "text": "Gateway and apart from that we have a",
    "start": "768600",
    "end": "770760"
  },
  {
    "text": "bunch of Selden related uh like you know",
    "start": "770760",
    "end": "773880"
  },
  {
    "text": "pods that are running so we have the",
    "start": "773880",
    "end": "776220"
  },
  {
    "text": "course held in and then we have a few",
    "start": "776220",
    "end": "778320"
  },
  {
    "text": "monitoring ones as well so these are",
    "start": "778320",
    "end": "780120"
  },
  {
    "text": "essentially what is running so we have a",
    "start": "780120",
    "end": "782519"
  },
  {
    "text": "Selden Prometheus operator so if you",
    "start": "782519",
    "end": "784920"
  },
  {
    "text": "want to go ahead and run any particular",
    "start": "784920",
    "end": "787139"
  },
  {
    "text": "command and run any machine learning",
    "start": "787139",
    "end": "788940"
  },
  {
    "text": "model you can use the Prometheus",
    "start": "788940",
    "end": "790680"
  },
  {
    "text": "operator to that works on top of Selden",
    "start": "790680",
    "end": "792839"
  },
  {
    "text": "to monitor all your requests and you're",
    "start": "792839",
    "end": "795540"
  },
  {
    "text": "able to see that in a dashboard so since",
    "start": "795540",
    "end": "797760"
  },
  {
    "text": "I already have my monitoring running you",
    "start": "797760",
    "end": "800100"
  },
  {
    "text": "can see that this is my uh dashboard",
    "start": "800100",
    "end": "803120"
  },
  {
    "text": "Prometheus dashboard and over here so",
    "start": "803120",
    "end": "806880"
  },
  {
    "text": "far I've just run a few sample requests",
    "start": "806880",
    "end": "809040"
  },
  {
    "text": "so the idea is that if you follow along",
    "start": "809040",
    "end": "811380"
  },
  {
    "text": "this documentation and we'll share the",
    "start": "811380",
    "end": "812880"
  },
  {
    "text": "link for this documentation",
    "start": "812880",
    "end": "814500"
  },
  {
    "text": "um first we are setting up Selden core",
    "start": "814500",
    "end": "816120"
  },
  {
    "text": "and then we install the Prometheus",
    "start": "816120",
    "end": "818220"
  },
  {
    "text": "operator and we set it up with with",
    "start": "818220",
    "end": "820260"
  },
  {
    "text": "Selden and once we basically do that",
    "start": "820260",
    "end": "823320"
  },
  {
    "text": "then what we're going ahead and doing is",
    "start": "823320",
    "end": "825120"
  },
  {
    "text": "that we are just deploying this example",
    "start": "825120",
    "end": "826800"
  },
  {
    "text": "model that you can see it's just a",
    "start": "826800",
    "end": "828660"
  },
  {
    "text": "simple uh model that Echoes and you can",
    "start": "828660",
    "end": "831660"
  },
  {
    "text": "kind of then see the results as we will",
    "start": "831660",
    "end": "833880"
  },
  {
    "text": "run this and uh as you go ahead and",
    "start": "833880",
    "end": "836820"
  },
  {
    "text": "check this particular docs out",
    "start": "836820",
    "end": "839279"
  },
  {
    "text": "um you'll see that how as you uh like",
    "start": "839279",
    "end": "841380"
  },
  {
    "text": "let's say from time time you run your",
    "start": "841380",
    "end": "843420"
  },
  {
    "text": "machine run model you'll see the changes",
    "start": "843420",
    "end": "845220"
  },
  {
    "text": "coming in this live time series data so",
    "start": "845220",
    "end": "848339"
  },
  {
    "text": "over here I already have one of my",
    "start": "848339",
    "end": "851700"
  },
  {
    "text": "windows open",
    "start": "851700",
    "end": "853380"
  },
  {
    "text": "and I have a call request that is",
    "start": "853380",
    "end": "855300"
  },
  {
    "text": "heading to my endpoint which is running",
    "start": "855300",
    "end": "856800"
  },
  {
    "text": "on localhost 8003 so I've used port",
    "start": "856800",
    "end": "858660"
  },
  {
    "text": "forwarding to kind of run it locally and",
    "start": "858660",
    "end": "860940"
  },
  {
    "text": "you'll be able to see it uh in that GK",
    "start": "860940",
    "end": "862620"
  },
  {
    "text": "cluster as well so as I run this",
    "start": "862620",
    "end": "865019"
  },
  {
    "text": "um you see that it run it successfully",
    "start": "865019",
    "end": "867540"
  },
  {
    "text": "oh okay",
    "start": "867540",
    "end": "869100"
  },
  {
    "text": "and now let's take a look at our",
    "start": "869100",
    "end": "871500"
  },
  {
    "text": "Prometheus dashboard so let me just",
    "start": "871500",
    "end": "874380"
  },
  {
    "text": "quickly refresh this",
    "start": "874380",
    "end": "877399"
  },
  {
    "text": "so as you can see that we have now a new",
    "start": "877500",
    "end": "880260"
  },
  {
    "text": "request that has come up as compared to",
    "start": "880260",
    "end": "882720"
  },
  {
    "text": "the last time so we were up to 12",
    "start": "882720",
    "end": "885000"
  },
  {
    "text": "requests and now we have the 14 requests",
    "start": "885000",
    "end": "886800"
  },
  {
    "text": "so this way what you can do is that um",
    "start": "886800",
    "end": "889380"
  },
  {
    "text": "of course since we are using like you",
    "start": "889380",
    "end": "892320"
  },
  {
    "text": "know you can put in any query into your",
    "start": "892320",
    "end": "894180"
  },
  {
    "text": "Prometheus dashboard to can then also",
    "start": "894180",
    "end": "896399"
  },
  {
    "text": "monitor uh to get a summary version in",
    "start": "896399",
    "end": "899459"
  },
  {
    "text": "this case what I'm doing is that I'm",
    "start": "899459",
    "end": "900660"
  },
  {
    "text": "looking at on a per a second request",
    "start": "900660",
    "end": "902760"
  },
  {
    "text": "basis that how is my model working right",
    "start": "902760",
    "end": "905880"
  },
  {
    "text": "so how many requests have been sent so",
    "start": "905880",
    "end": "907680"
  },
  {
    "text": "far but you can also create your custom",
    "start": "907680",
    "end": "909620"
  },
  {
    "text": "uh dashboards as well to kind of monitor",
    "start": "909620",
    "end": "912839"
  },
  {
    "text": "the actual live prediction rates that",
    "start": "912839",
    "end": "915660"
  },
  {
    "text": "that are going on for a particular model",
    "start": "915660",
    "end": "917399"
  },
  {
    "text": "in this case the example that we showed",
    "start": "917399",
    "end": "919260"
  },
  {
    "text": "is a simple model but you can run it on",
    "start": "919260",
    "end": "920940"
  },
  {
    "text": "any model that you would want SQL and",
    "start": "920940",
    "end": "923279"
  },
  {
    "text": "tensorflow Pi torch space models and",
    "start": "923279",
    "end": "925440"
  },
  {
    "text": "this we can monitor your live machine",
    "start": "925440",
    "end": "927959"
  },
  {
    "text": "learning performance uh on on the",
    "start": "927959",
    "end": "930600"
  },
  {
    "text": "Prometheus dashboard and you can further",
    "start": "930600",
    "end": "932399"
  },
  {
    "text": "expand this expand this by also uh like",
    "start": "932399",
    "end": "935100"
  },
  {
    "text": "you know going ahead and creating a",
    "start": "935100",
    "end": "936300"
  },
  {
    "text": "grafana dashboard to kind of monitor",
    "start": "936300",
    "end": "938699"
  },
  {
    "text": "your logs that we'll be seeing in the",
    "start": "938699",
    "end": "940920"
  },
  {
    "text": "fast API demo that Richard will be",
    "start": "940920",
    "end": "942420"
  },
  {
    "text": "showing to all of you but yes apart from",
    "start": "942420",
    "end": "944639"
  },
  {
    "text": "this I also wanted to quickly showcase",
    "start": "944639",
    "end": "946380"
  },
  {
    "text": "another one so",
    "start": "946380",
    "end": "947639"
  },
  {
    "text": "um how many of you are aware of machine",
    "start": "947639",
    "end": "949500"
  },
  {
    "text": "learning pipelines or might have heard",
    "start": "949500",
    "end": "951300"
  },
  {
    "text": "about this term ml pipelines anyone has",
    "start": "951300",
    "end": "954720"
  },
  {
    "text": "previously probably heard of cube flow",
    "start": "954720",
    "end": "956600"
  },
  {
    "text": "so there are a number of different data",
    "start": "956600",
    "end": "958980"
  },
  {
    "text": "orchestration platforms like you flow",
    "start": "958980",
    "end": "961260"
  },
  {
    "text": "flight and which allow you to basically",
    "start": "961260",
    "end": "963959"
  },
  {
    "text": "take your entire envelopes cycle and",
    "start": "963959",
    "end": "966120"
  },
  {
    "text": "then convert them into specific",
    "start": "966120",
    "end": "967740"
  },
  {
    "text": "workflows so you can think of like let's",
    "start": "967740",
    "end": "969779"
  },
  {
    "text": "say the model training as a separate",
    "start": "969779",
    "end": "971279"
  },
  {
    "text": "workflow uh you can have your model uh",
    "start": "971279",
    "end": "973620"
  },
  {
    "text": "testing and model deployment as specific",
    "start": "973620",
    "end": "976380"
  },
  {
    "text": "workflows right so you can you're",
    "start": "976380",
    "end": "977699"
  },
  {
    "text": "basically dividing them into various",
    "start": "977699",
    "end": "979560"
  },
  {
    "text": "tasks so another example that I would",
    "start": "979560",
    "end": "982199"
  },
  {
    "text": "just want to quickly showcase is uh with",
    "start": "982199",
    "end": "984720"
  },
  {
    "text": "the flight so over here uh basically let",
    "start": "984720",
    "end": "990000"
  },
  {
    "text": "me go back over here to the docs section",
    "start": "990000",
    "end": "992300"
  },
  {
    "text": "so and I'll just quickly search for",
    "start": "992300",
    "end": "994980"
  },
  {
    "text": "Prometheus so as we showed an example",
    "start": "994980",
    "end": "998279"
  },
  {
    "text": "for Selden if you were like let's say",
    "start": "998279",
    "end": "1001100"
  },
  {
    "text": "using a flight for an example for being",
    "start": "1001100",
    "end": "1005240"
  },
  {
    "text": "able to run your workflows machine",
    "start": "1005240",
    "end": "1007160"
  },
  {
    "text": "learning workflows so Prometheus is",
    "start": "1007160",
    "end": "1010339"
  },
  {
    "text": "directly in embedded into your machine",
    "start": "1010339",
    "end": "1012259"
  },
  {
    "text": "learning workflows with flight so you",
    "start": "1012259",
    "end": "1014000"
  },
  {
    "text": "get metrics out of the box and then",
    "start": "1014000",
    "end": "1016519"
  },
  {
    "text": "you'll find that there are some",
    "start": "1016519",
    "end": "1017839"
  },
  {
    "text": "published dashboards to monitor the",
    "start": "1017839",
    "end": "1020060"
  },
  {
    "text": "flight deployments again this is related",
    "start": "1020060",
    "end": "1022339"
  },
  {
    "text": "to your envelopes with the help of Light",
    "start": "1022339",
    "end": "1024260"
  },
  {
    "text": "by using the flight workflows so you can",
    "start": "1024260",
    "end": "1026540"
  },
  {
    "text": "take a look at uh this is well and again",
    "start": "1026540",
    "end": "1028339"
  },
  {
    "text": "we'll be more than happy to share some",
    "start": "1028339",
    "end": "1029900"
  },
  {
    "text": "examples but what we just want to",
    "start": "1029900",
    "end": "1031640"
  },
  {
    "text": "showcase through these examples is that",
    "start": "1031640",
    "end": "1033798"
  },
  {
    "text": "today like Prometheus plays an extremely",
    "start": "1033799",
    "end": "1036500"
  },
  {
    "text": "important role in the mlops life cycle",
    "start": "1036500",
    "end": "1038720"
  },
  {
    "text": "so if you are looking to embed that you",
    "start": "1038720",
    "end": "1041660"
  },
  {
    "text": "have a number of different Integrations",
    "start": "1041660",
    "end": "1043100"
  },
  {
    "text": "out of the box that you can set up",
    "start": "1043100",
    "end": "1044900"
  },
  {
    "text": "locally in your systems and start to",
    "start": "1044900",
    "end": "1047058"
  },
  {
    "text": "monitor the performance and we'll also",
    "start": "1047059",
    "end": "1048679"
  },
  {
    "text": "see an example for a native fast API",
    "start": "1048679",
    "end": "1050840"
  },
  {
    "text": "that will be showing you to all of you",
    "start": "1050840",
    "end": "1055120"
  },
  {
    "text": "okay so I'll show another demo and uh",
    "start": "1055640",
    "end": "1059240"
  },
  {
    "text": "yeah let me get set up",
    "start": "1059240",
    "end": "1062860"
  },
  {
    "text": "okay I think it's up now yes it is so uh",
    "start": "1076520",
    "end": "1080600"
  },
  {
    "text": "now we'll take a look at the first API",
    "start": "1080600",
    "end": "1082160"
  },
  {
    "text": "demo and the idea of these demos is",
    "start": "1082160",
    "end": "1084620"
  },
  {
    "text": "actually to show a very very popular",
    "start": "1084620",
    "end": "1087559"
  },
  {
    "text": "ways of deploying machine learning uh uh",
    "start": "1087559",
    "end": "1090860"
  },
  {
    "text": "of deploying machine learning or doing",
    "start": "1090860",
    "end": "1092960"
  },
  {
    "text": "ml Ops and we just want to show you how",
    "start": "1092960",
    "end": "1095720"
  },
  {
    "text": "we have integrated Prometheus into that",
    "start": "1095720",
    "end": "1098500"
  },
  {
    "text": "but again you are not limited to what we",
    "start": "1098500",
    "end": "1101600"
  },
  {
    "text": "of course show in the demo you can work",
    "start": "1101600",
    "end": "1103160"
  },
  {
    "text": "it make it work with other platforms we",
    "start": "1103160",
    "end": "1104960"
  },
  {
    "text": "just want to share how we have done it",
    "start": "1104960",
    "end": "1106880"
  },
  {
    "text": "with these platforms and apply these",
    "start": "1106880",
    "end": "1108620"
  },
  {
    "text": "ideas to other platforms so we will take",
    "start": "1108620",
    "end": "1110780"
  },
  {
    "text": "a look at fast API which is probably one",
    "start": "1110780",
    "end": "1113240"
  },
  {
    "text": "of the most popular ways to deploy a",
    "start": "1113240",
    "end": "1114799"
  },
  {
    "text": "machine learning model as well and uh so",
    "start": "1114799",
    "end": "1118280"
  },
  {
    "text": "so setting some context for this demo",
    "start": "1118280",
    "end": "1121039"
  },
  {
    "text": "what we want to do is create a rest",
    "start": "1121039",
    "end": "1123320"
  },
  {
    "text": "service to expose the model not",
    "start": "1123320",
    "end": "1125179"
  },
  {
    "text": "something we'll be doing in this talk uh",
    "start": "1125179",
    "end": "1127940"
  },
  {
    "text": "let's just say it's been done for us",
    "start": "1127940",
    "end": "1132039"
  },
  {
    "text": "what which we want to do is instrument",
    "start": "1132100",
    "end": "1134600"
  },
  {
    "text": "the server to collect the metrics which",
    "start": "1134600",
    "end": "1137000"
  },
  {
    "text": "might probably be exposed by a separate",
    "start": "1137000",
    "end": "1139280"
  },
  {
    "text": "Matrix endpoint",
    "start": "1139280",
    "end": "1141080"
  },
  {
    "text": "um from the rest API we have created for",
    "start": "1141080",
    "end": "1143840"
  },
  {
    "text": "our model and we'll use the Prometheus",
    "start": "1143840",
    "end": "1146000"
  },
  {
    "text": "fast API instrumentator",
    "start": "1146000",
    "end": "1148179"
  },
  {
    "text": "which allows us to which allows us to",
    "start": "1148179",
    "end": "1151400"
  },
  {
    "text": "collect metrics uh from uh from a fast",
    "start": "1151400",
    "end": "1155360"
  },
  {
    "text": "API deployment",
    "start": "1155360",
    "end": "1157059"
  },
  {
    "text": "what we'll also be showing will be how",
    "start": "1157059",
    "end": "1160340"
  },
  {
    "text": "to how to show the data distribution",
    "start": "1160340",
    "end": "1163160"
  },
  {
    "text": "your model is right now working under",
    "start": "1163160",
    "end": "1165020"
  },
  {
    "text": "the data distribution the model was",
    "start": "1165020",
    "end": "1166760"
  },
  {
    "text": "trained on so essentially all the",
    "start": "1166760",
    "end": "1168559"
  },
  {
    "text": "aspects which we just covered in the",
    "start": "1168559",
    "end": "1170059"
  },
  {
    "text": "slides so we'll also be showing that and",
    "start": "1170059",
    "end": "1173919"
  },
  {
    "text": "then of course we want to use Prometheus",
    "start": "1173919",
    "end": "1177559"
  },
  {
    "text": "to collect 10 store metrics and we'll",
    "start": "1177559",
    "end": "1180140"
  },
  {
    "text": "just add a layer of rafana to visualize",
    "start": "1180140",
    "end": "1183380"
  },
  {
    "text": "a collected Matrix not something I will",
    "start": "1183380",
    "end": "1186200"
  },
  {
    "text": "focus a lot on in this talk talk but uh",
    "start": "1186200",
    "end": "1189559"
  },
  {
    "text": "yeah we do have for that and we'll just",
    "start": "1189559",
    "end": "1191960"
  },
  {
    "text": "be showing it uh and if you want to try",
    "start": "1191960",
    "end": "1195500"
  },
  {
    "text": "this out for yourself so especially some",
    "start": "1195500",
    "end": "1197480"
  },
  {
    "text": "of the things uh like data distribution",
    "start": "1197480",
    "end": "1200360"
  },
  {
    "text": "what data distribution does your model",
    "start": "1200360",
    "end": "1202520"
  },
  {
    "text": "operate under it's pretty hard to see",
    "start": "1202520",
    "end": "1204500"
  },
  {
    "text": "with the single request uh so we also",
    "start": "1204500",
    "end": "1207380"
  },
  {
    "text": "have some code I've actually been so",
    "start": "1207380",
    "end": "1209539"
  },
  {
    "text": "it's actually uh I've been running some",
    "start": "1209539",
    "end": "1212000"
  },
  {
    "text": "code since morning to uh which is",
    "start": "1212000",
    "end": "1215120"
  },
  {
    "text": "essentially using Lucas uh to simulate",
    "start": "1215120",
    "end": "1218299"
  },
  {
    "text": "requests hundreds of requests it is it",
    "start": "1218299",
    "end": "1220820"
  },
  {
    "text": "has been simulating since the morning uh",
    "start": "1220820",
    "end": "1223100"
  },
  {
    "text": "so that will also allow us to kind of",
    "start": "1223100",
    "end": "1225740"
  },
  {
    "text": "see uh some of the other aspects of",
    "start": "1225740",
    "end": "1228260"
  },
  {
    "text": "machine learning in action which we uh",
    "start": "1228260",
    "end": "1230720"
  },
  {
    "text": "which we particularly wanted to see with",
    "start": "1230720",
    "end": "1232460"
  },
  {
    "text": "this talk ah which we particularly",
    "start": "1232460",
    "end": "1234799"
  },
  {
    "text": "wanted to show with the stock sorry",
    "start": "1234799",
    "end": "1236900"
  },
  {
    "text": "no uh not thank you uh uh let's go to",
    "start": "1236900",
    "end": "1241820"
  },
  {
    "text": "the demo yes",
    "start": "1241820",
    "end": "1243380"
  },
  {
    "text": "not yet great so",
    "start": "1243380",
    "end": "1246380"
  },
  {
    "text": "let's start with the model uh we don't",
    "start": "1246380",
    "end": "1249200"
  },
  {
    "text": "want to talk a lot about the model but",
    "start": "1249200",
    "end": "1251000"
  },
  {
    "text": "we'll start with the model and then work",
    "start": "1251000",
    "end": "1252679"
  },
  {
    "text": "our way up I'll directly start with the",
    "start": "1252679",
    "end": "1255080"
  },
  {
    "text": "docker file uh I have I have a fast API",
    "start": "1255080",
    "end": "1258980"
  },
  {
    "text": "deployment up and I also have a model up",
    "start": "1258980",
    "end": "1262400"
  },
  {
    "text": "my model is trained uh and I and I have",
    "start": "1262400",
    "end": "1266360"
  },
  {
    "text": "a Docker file up to uh to make an image",
    "start": "1266360",
    "end": "1269000"
  },
  {
    "text": "out of it and uh and and now I'll be",
    "start": "1269000",
    "end": "1271880"
  },
  {
    "text": "using this fast API deployment uh so",
    "start": "1271880",
    "end": "1274940"
  },
  {
    "text": "because we don't really want to talk",
    "start": "1274940",
    "end": "1277160"
  },
  {
    "text": "about training a model and all that in",
    "start": "1277160",
    "end": "1278960"
  },
  {
    "text": "the demo so yeah uh then I uh so then",
    "start": "1278960",
    "end": "1283340"
  },
  {
    "text": "what I want to talk about is the",
    "start": "1283340",
    "end": "1285559"
  },
  {
    "text": "dashboard then what I want to talk about",
    "start": "1285559",
    "end": "1287660"
  },
  {
    "text": "is the model.yaml file we have a",
    "start": "1287660",
    "end": "1289820"
  },
  {
    "text": "deployment here uh which uh which uh",
    "start": "1289820",
    "end": "1293720"
  },
  {
    "text": "makes a rest API uh for our model uh",
    "start": "1293720",
    "end": "1297080"
  },
  {
    "text": "which is uh pretty standard and we also",
    "start": "1297080",
    "end": "1300080"
  },
  {
    "text": "have a service here uh the service",
    "start": "1300080",
    "end": "1302600"
  },
  {
    "text": "allows us to expose the rest API and",
    "start": "1302600",
    "end": "1305299"
  },
  {
    "text": "then use it so uh those are two of the",
    "start": "1305299",
    "end": "1309740"
  },
  {
    "text": "things we are doing and then we also",
    "start": "1309740",
    "end": "1311299"
  },
  {
    "text": "have a service monitor so",
    "start": "1311299",
    "end": "1313580"
  },
  {
    "text": "um so of course this must be the service",
    "start": "1313580",
    "end": "1316039"
  },
  {
    "text": "monitor should be in the same space that",
    "start": "1316039",
    "end": "1317900"
  },
  {
    "text": "namespace that Prometheus is running so",
    "start": "1317900",
    "end": "1320299"
  },
  {
    "text": "Prometheus can automatically get get and",
    "start": "1320299",
    "end": "1322640"
  },
  {
    "text": "collect the data from it uh so that is",
    "start": "1322640",
    "end": "1326240"
  },
  {
    "text": "uh what will be",
    "start": "1326240",
    "end": "1327919"
  },
  {
    "text": "um so that is another uh service another",
    "start": "1327919",
    "end": "1331340"
  },
  {
    "text": "so another resource we have uh we'll",
    "start": "1331340",
    "end": "1334400"
  },
  {
    "text": "also deploy a service monitor so okay uh",
    "start": "1334400",
    "end": "1337400"
  },
  {
    "text": "where are these three resources deployed",
    "start": "1337400",
    "end": "1339200"
  },
  {
    "text": "so uh",
    "start": "1339200",
    "end": "1341360"
  },
  {
    "text": "oh no of course you can use something",
    "start": "1341360",
    "end": "1343159"
  },
  {
    "text": "else I'm just using sivo because I've",
    "start": "1343159",
    "end": "1345740"
  },
  {
    "text": "been using it",
    "start": "1345740",
    "end": "1347179"
  },
  {
    "text": "um so I I've deployed I've made a",
    "start": "1347179",
    "end": "1349280"
  },
  {
    "text": "kubernetes cluster I deployed the",
    "start": "1349280",
    "end": "1351440"
  },
  {
    "text": "resources I talked about the rest API uh",
    "start": "1351440",
    "end": "1355000"
  },
  {
    "text": "a service Monitor and a service I've",
    "start": "1355000",
    "end": "1358340"
  },
  {
    "text": "deployed all of that on this civil",
    "start": "1358340",
    "end": "1359900"
  },
  {
    "text": "cluster uh of course you can use",
    "start": "1359900",
    "end": "1361940"
  },
  {
    "text": "whatever Cloud you like but just for",
    "start": "1361940",
    "end": "1363980"
  },
  {
    "text": "this demo we'll be using CEO",
    "start": "1363980",
    "end": "1366380"
  },
  {
    "text": "so",
    "start": "1366380",
    "end": "1367760"
  },
  {
    "text": "with that let's go full screen and okay",
    "start": "1367760",
    "end": "1371360"
  },
  {
    "text": "so we have our model.aml file and then",
    "start": "1371360",
    "end": "1374059"
  },
  {
    "text": "we actually have the dashboard itself so",
    "start": "1374059",
    "end": "1377299"
  },
  {
    "text": "so some of the things we'll be doing in",
    "start": "1377299",
    "end": "1379820"
  },
  {
    "text": "the dashboard to make sense of the data",
    "start": "1379820",
    "end": "1383240"
  },
  {
    "text": "given to us by Prometheus for example is",
    "start": "1383240",
    "end": "1386320"
  },
  {
    "text": "identifying uh what identifying what",
    "start": "1386320",
    "end": "1390020"
  },
  {
    "text": "distributions these data falls falls",
    "start": "1390020",
    "end": "1392059"
  },
  {
    "text": "under",
    "start": "1392059",
    "end": "1393020"
  },
  {
    "text": "now in to do this we will actually use",
    "start": "1393020",
    "end": "1395059"
  },
  {
    "text": "uh and we'll actually leverage some of",
    "start": "1395059",
    "end": "1396980"
  },
  {
    "text": "the functionality by grafana to do this",
    "start": "1396980",
    "end": "1399440"
  },
  {
    "text": "and",
    "start": "1399440",
    "end": "1401200"
  },
  {
    "text": "which is pretty simple you are making a",
    "start": "1401200",
    "end": "1403640"
  },
  {
    "text": "heat map out of it and then you can",
    "start": "1403640",
    "end": "1405620"
  },
  {
    "text": "simply see uh and you can then simply",
    "start": "1405620",
    "end": "1407720"
  },
  {
    "text": "compare it with the original",
    "start": "1407720",
    "end": "1409340"
  },
  {
    "text": "distribution the model was trained on so",
    "start": "1409340",
    "end": "1411860"
  },
  {
    "text": "uh these are so this is one of the",
    "start": "1411860",
    "end": "1413960"
  },
  {
    "text": "things that uh that we are doing uh on",
    "start": "1413960",
    "end": "1416720"
  },
  {
    "text": "on our grafana dashboard uh so uh with",
    "start": "1416720",
    "end": "1421580"
  },
  {
    "text": "that now we have set up now we have set",
    "start": "1421580",
    "end": "1423919"
  },
  {
    "text": "up a rest API deployment for our model",
    "start": "1423919",
    "end": "1426380"
  },
  {
    "text": "we also have a service Monitor and uh we",
    "start": "1426380",
    "end": "1430520"
  },
  {
    "text": "I've already deployed Prometheus uh I'm",
    "start": "1430520",
    "end": "1432980"
  },
  {
    "text": "using Prometheus Jack here so I've",
    "start": "1432980",
    "end": "1434720"
  },
  {
    "text": "already deployed Prometheus uh for us in",
    "start": "1434720",
    "end": "1437299"
  },
  {
    "text": "the cluster uh all of this is pretty",
    "start": "1437299",
    "end": "1440600"
  },
  {
    "text": "intuitive uh up until now at least a",
    "start": "1440600",
    "end": "1443960"
  },
  {
    "text": "deployment part and the part which was",
    "start": "1443960",
    "end": "1445580"
  },
  {
    "text": "in I just showed that on the screen but",
    "start": "1445580",
    "end": "1447320"
  },
  {
    "text": "uh at least deploying all of these is",
    "start": "1447320",
    "end": "1449840"
  },
  {
    "text": "pretty intuitive uh so uh so that's what",
    "start": "1449840",
    "end": "1453200"
  },
  {
    "text": "you have done until now uh we have also",
    "start": "1453200",
    "end": "1456340"
  },
  {
    "text": "created a dashboard uh using the",
    "start": "1456340",
    "end": "1459559"
  },
  {
    "text": "model.json which is uh which is what",
    "start": "1459559",
    "end": "1462080"
  },
  {
    "text": "grafana will be using uh to make sense",
    "start": "1462080",
    "end": "1464360"
  },
  {
    "text": "out of the metrics collected by uh",
    "start": "1464360",
    "end": "1467299"
  },
  {
    "text": "Prometheus",
    "start": "1467299",
    "end": "1469460"
  },
  {
    "text": "so I already have uh so I'm just",
    "start": "1469460",
    "end": "1472940"
  },
  {
    "text": "forwarding put here",
    "start": "1472940",
    "end": "1474980"
  },
  {
    "text": "um uh to uh to get the grafana dashboard",
    "start": "1474980",
    "end": "1478880"
  },
  {
    "text": "and let's actually take a look at the",
    "start": "1478880",
    "end": "1480980"
  },
  {
    "text": "grafana dashboard I particularly want to",
    "start": "1480980",
    "end": "1483320"
  },
  {
    "text": "see one of the demos uh this is uh all",
    "start": "1483320",
    "end": "1486020"
  },
  {
    "text": "of this is by the way open source uh so",
    "start": "1486020",
    "end": "1488840"
  },
  {
    "text": "you can feel free to try out everything",
    "start": "1488840",
    "end": "1491179"
  },
  {
    "text": "see how we have implemented other things",
    "start": "1491179",
    "end": "1493100"
  },
  {
    "text": "but right now uh the part which I talked",
    "start": "1493100",
    "end": "1495919"
  },
  {
    "text": "about which distributions are the",
    "start": "1495919",
    "end": "1497480"
  },
  {
    "text": "requests under uh is something will be",
    "start": "1497480",
    "end": "1500140"
  },
  {
    "text": "showing but we also have some other",
    "start": "1500140",
    "end": "1502280"
  },
  {
    "text": "things which we'll show in the grafana",
    "start": "1502280",
    "end": "1503780"
  },
  {
    "text": "dashboard but not go into everything",
    "start": "1503780",
    "end": "1506659"
  },
  {
    "text": "right now uh due to time uh so another",
    "start": "1506659",
    "end": "1509780"
  },
  {
    "text": "thing before so we have deployed all of",
    "start": "1509780",
    "end": "1512480"
  },
  {
    "text": "this until now what we have also",
    "start": "1512480",
    "end": "1514340"
  },
  {
    "text": "deployed just to better understand uh is",
    "start": "1514340",
    "end": "1517400"
  },
  {
    "text": "locusts so",
    "start": "1517400",
    "end": "1519860"
  },
  {
    "text": "let's close this and let's open our load",
    "start": "1519860",
    "end": "1523159"
  },
  {
    "text": "test so we actually have a locust file",
    "start": "1523159",
    "end": "1525740"
  },
  {
    "text": "uh which is uh which is another",
    "start": "1525740",
    "end": "1529460"
  },
  {
    "text": "um which is another pod we are running",
    "start": "1529460",
    "end": "1531140"
  },
  {
    "text": "to make continuous uh to make continuous",
    "start": "1531140",
    "end": "1534080"
  },
  {
    "text": "requests uh so we can just understand",
    "start": "1534080",
    "end": "1536419"
  },
  {
    "text": "and see and see some data on the grafana",
    "start": "1536419",
    "end": "1538760"
  },
  {
    "text": "dashboard see the heat map being made",
    "start": "1538760",
    "end": "1540740"
  },
  {
    "text": "for different distributions so uh that's",
    "start": "1540740",
    "end": "1543440"
  },
  {
    "text": "what we have until now and let's",
    "start": "1543440",
    "end": "1545840"
  },
  {
    "text": "actually go to our grafana dashboard",
    "start": "1545840",
    "end": "1547520"
  },
  {
    "text": "which which I was talking about and you",
    "start": "1547520",
    "end": "1551000"
  },
  {
    "text": "can actually see requests have been",
    "start": "1551000",
    "end": "1552260"
  },
  {
    "text": "coming in since quite some while it's",
    "start": "1552260",
    "end": "1554960"
  },
  {
    "text": "actually on since morning and uh",
    "start": "1554960",
    "end": "1558260"
  },
  {
    "text": "uh this shows what the model score is",
    "start": "1558260",
    "end": "1561679"
  },
  {
    "text": "especially the model prediction",
    "start": "1561679",
    "end": "1563179"
  },
  {
    "text": "distribution all of these are like",
    "start": "1563179",
    "end": "1564679"
  },
  {
    "text": "random requests I'm sending so I can see",
    "start": "1564679",
    "end": "1567320"
  },
  {
    "text": "the different bins uh uh all of the uh",
    "start": "1567320",
    "end": "1571279"
  },
  {
    "text": "the data is in I can see the different",
    "start": "1571279",
    "end": "1573320"
  },
  {
    "text": "bins the model has been predicted uh the",
    "start": "1573320",
    "end": "1576200"
  },
  {
    "text": "data is in so uh",
    "start": "1576200",
    "end": "1578720"
  },
  {
    "text": "as we were talking about in the slides",
    "start": "1578720",
    "end": "1580580"
  },
  {
    "text": "this is something pretty useful for",
    "start": "1580580",
    "end": "1582620"
  },
  {
    "text": "machine learning use cases uh which is",
    "start": "1582620",
    "end": "1585380"
  },
  {
    "text": "why we want to see it so so some of the",
    "start": "1585380",
    "end": "1587539"
  },
  {
    "text": "other things we so this is of course uh",
    "start": "1587539",
    "end": "1590480"
  },
  {
    "text": "what we would call the model metrics and",
    "start": "1590480",
    "end": "1592880"
  },
  {
    "text": "then we also have the service so in the",
    "start": "1592880",
    "end": "1595279"
  },
  {
    "text": "model Matrix we are also showing model",
    "start": "1595279",
    "end": "1596779"
  },
  {
    "text": "score",
    "start": "1596779",
    "end": "1598279"
  },
  {
    "text": "um so model score is",
    "start": "1598279",
    "end": "1600740"
  },
  {
    "text": "um so the model score is essentially a",
    "start": "1600740",
    "end": "1603500"
  },
  {
    "text": "way to say how good my model is",
    "start": "1603500",
    "end": "1606380"
  },
  {
    "text": "performing get an estimate of it of",
    "start": "1606380",
    "end": "1608419"
  },
  {
    "text": "course we haven't seen the data earlier",
    "start": "1608419",
    "end": "1609980"
  },
  {
    "text": "or trained on it but it at least allows",
    "start": "1609980",
    "end": "1612559"
  },
  {
    "text": "the model score at least allows us to",
    "start": "1612559",
    "end": "1614059"
  },
  {
    "text": "get an estimate of how this works we",
    "start": "1614059",
    "end": "1615799"
  },
  {
    "text": "won't be going into the mathematical",
    "start": "1615799",
    "end": "1617480"
  },
  {
    "text": "models right now we just saw it for",
    "start": "1617480",
    "end": "1619940"
  },
  {
    "text": "model prediction distribution but uh uh",
    "start": "1619940",
    "end": "1622700"
  },
  {
    "text": "all of this is open source you can take",
    "start": "1622700",
    "end": "1624320"
  },
  {
    "text": "a look at it uh okay so with that",
    "start": "1624320",
    "end": "1627440"
  },
  {
    "text": "uh so those are the model metrics we",
    "start": "1627440",
    "end": "1629720"
  },
  {
    "text": "have also uh",
    "start": "1629720",
    "end": "1631580"
  },
  {
    "text": "uh we have also monitored uh service",
    "start": "1631580",
    "end": "1634520"
  },
  {
    "text": "metrics and uh resource metrics uh which",
    "start": "1634520",
    "end": "1638720"
  },
  {
    "text": "are pretty straightforward so I'll not",
    "start": "1638720",
    "end": "1641179"
  },
  {
    "text": "talk a lot about them uh but uh with",
    "start": "1641179",
    "end": "1644539"
  },
  {
    "text": "that uh I",
    "start": "1644539",
    "end": "1646400"
  },
  {
    "text": "but with that demo I come to the end of",
    "start": "1646400",
    "end": "1648500"
  },
  {
    "text": "my talk and this time for real thank you",
    "start": "1648500",
    "end": "1652100"
  },
  {
    "text": "and",
    "start": "1652100",
    "end": "1654460"
  },
  {
    "text": "and this kind of summarize one last",
    "start": "1657559",
    "end": "1659659"
  },
  {
    "text": "point is that uh you can use Prometheus",
    "start": "1659659",
    "end": "1661820"
  },
  {
    "text": "as a very effective tool in all the",
    "start": "1661820",
    "end": "1663860"
  },
  {
    "text": "different life formats of uh during",
    "start": "1663860",
    "end": "1666020"
  },
  {
    "text": "especially the time when you're training",
    "start": "1666020",
    "end": "1667279"
  },
  {
    "text": "model and then post the training when",
    "start": "1667279",
    "end": "1669200"
  },
  {
    "text": "you have put into production to view the",
    "start": "1669200",
    "end": "1671299"
  },
  {
    "text": "live metrics and then of course monitor",
    "start": "1671299",
    "end": "1673159"
  },
  {
    "text": "the overall health of your machine",
    "start": "1673159",
    "end": "1674779"
  },
  {
    "text": "learning models yeah any questions we",
    "start": "1674779",
    "end": "1677120"
  },
  {
    "text": "love to answer them now yeah",
    "start": "1677120",
    "end": "1680980"
  },
  {
    "text": "if not right now then you can always",
    "start": "1684740",
    "end": "1686539"
  },
  {
    "text": "find both of us on Twitter and thank you",
    "start": "1686539",
    "end": "1691539"
  },
  {
    "text": "[Applause]",
    "start": "1692100",
    "end": "1696559"
  }
]
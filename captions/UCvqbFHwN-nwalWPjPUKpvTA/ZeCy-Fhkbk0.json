[
  {
    "text": "all right thank you very much um hi",
    "start": "1439",
    "end": "3679"
  },
  {
    "text": "everybody my name is Dave Dave southwell",
    "start": "3679",
    "end": "6359"
  },
  {
    "text": "uh with def Computing um this is my",
    "start": "6359",
    "end": "8480"
  },
  {
    "text": "co-speaker an uh we're going to split",
    "start": "8480",
    "end": "11000"
  },
  {
    "text": "the presentation up into two different",
    "start": "11000",
    "end": "12719"
  },
  {
    "text": "uh two different parts so that's kind of",
    "start": "12719",
    "end": "14000"
  },
  {
    "text": "why we're standing the way that we are",
    "start": "14000",
    "end": "16000"
  },
  {
    "text": "instead of trying to huddle together uh",
    "start": "16000",
    "end": "17520"
  },
  {
    "text": "behind the lecturn so yeah um what are",
    "start": "17520",
    "end": "20800"
  },
  {
    "text": "we going to talk about today it's a very",
    "start": "20800",
    "end": "23720"
  },
  {
    "text": "long title so I forgive you if you",
    "start": "23720",
    "end": "25960"
  },
  {
    "text": "haven't read through it all but you're",
    "start": "25960",
    "end": "27840"
  },
  {
    "text": "probably familiar with all the terms",
    "start": "27840",
    "end": "29640"
  },
  {
    "text": "we're in talk about resource aware",
    "start": "29640",
    "end": "31359"
  },
  {
    "text": "policy based scheduling for production",
    "start": "31359",
    "end": "33559"
  },
  {
    "text": "gen geni with rag uh we've heard a lot",
    "start": "33559",
    "end": "36600"
  },
  {
    "text": "of other talks today about different",
    "start": "36600",
    "end": "38360"
  },
  {
    "text": "ways to deploy your AI powered",
    "start": "38360",
    "end": "40920"
  },
  {
    "text": "workloads but I don't think any of them",
    "start": "40920",
    "end": "43120"
  },
  {
    "text": "have specifically gone towards how you",
    "start": "43120",
    "end": "44879"
  },
  {
    "text": "might do it in production and the whole",
    "start": "44879",
    "end": "47280"
  },
  {
    "text": "idea behind this talk was how we were",
    "start": "47280",
    "end": "50120"
  },
  {
    "text": "thinking how could you develop a",
    "start": "50120",
    "end": "52520"
  },
  {
    "text": "reference architecture implementation",
    "start": "52520",
    "end": "54440"
  },
  {
    "text": "for how or implementation for how you",
    "start": "54440",
    "end": "56719"
  },
  {
    "text": "could deploy your uh production AI",
    "start": "56719",
    "end": "59280"
  },
  {
    "text": "workloads and that's what we're",
    "start": "59280",
    "end": "61079"
  },
  {
    "text": "proposing",
    "start": "61079",
    "end": "62440"
  },
  {
    "text": "here as you'll see later on we've tried",
    "start": "62440",
    "end": "65360"
  },
  {
    "text": "to use open source software wherever",
    "start": "65360",
    "end": "66920"
  },
  {
    "text": "possible uh we have also thrown up a",
    "start": "66920",
    "end": "68759"
  },
  {
    "text": "couple of different examples where you",
    "start": "68759",
    "end": "70080"
  },
  {
    "text": "might want to use a vendor for some",
    "start": "70080",
    "end": "72159"
  },
  {
    "text": "portions of the architecture but let's",
    "start": "72159",
    "end": "74680"
  },
  {
    "text": "get into it because we don't have too",
    "start": "74680",
    "end": "76280"
  },
  {
    "text": "much time and we do have a demo",
    "start": "76280",
    "end": "78920"
  },
  {
    "text": "later all right why might you want to",
    "start": "78920",
    "end": "82079"
  },
  {
    "text": "use geni and rag well rag with Gen",
    "start": "82079",
    "end": "85680"
  },
  {
    "text": "specifically I think most folks here",
    "start": "85680",
    "end": "87840"
  },
  {
    "text": "already know the answer to this question",
    "start": "87840",
    "end": "89200"
  },
  {
    "text": "too uh but just in case it Bears",
    "start": "89200",
    "end": "91799"
  },
  {
    "text": "repeating um layering rag on top of gen",
    "start": "91799",
    "end": "96119"
  },
  {
    "text": "improves uh reduces your llm",
    "start": "96119",
    "end": "98439"
  },
  {
    "text": "hallucination risks and it also uses",
    "start": "98439",
    "end": "101640"
  },
  {
    "text": "because it's using recent domain",
    "start": "101640",
    "end": "103360"
  },
  {
    "text": "specific uh information information to",
    "start": "103360",
    "end": "106159"
  },
  {
    "text": "augment that uh it invoid it avoids the",
    "start": "106159",
    "end": "109920"
  },
  {
    "text": "cost of needing to retrain an llm as",
    "start": "109920",
    "end": "113240"
  },
  {
    "text": "well and you can also utilize a bunch of",
    "start": "113240",
    "end": "116119"
  },
  {
    "text": "other different components on top of it",
    "start": "116119",
    "end": "118960"
  },
  {
    "text": "and on the left side I don't have a",
    "start": "118960",
    "end": "120799"
  },
  {
    "text": "fancy pointer but on the uh right side",
    "start": "120799",
    "end": "123520"
  },
  {
    "text": "over there you can see kind of a a",
    "start": "123520",
    "end": "124840"
  },
  {
    "text": "generic highle art diagram that's going",
    "start": "124840",
    "end": "127320"
  },
  {
    "text": "to get more and more annotated as we go",
    "start": "127320",
    "end": "131679"
  },
  {
    "text": "through okay you could obviously do a",
    "start": "131959",
    "end": "134800"
  },
  {
    "text": "lot of this stuff using paid for",
    "start": "134800",
    "end": "137480"
  },
  {
    "text": "software um however self-hosting has a",
    "start": "137480",
    "end": "140200"
  },
  {
    "text": "lot of",
    "start": "140200",
    "end": "141080"
  },
  {
    "text": "advantages uh these are kind of the",
    "start": "141080",
    "end": "142840"
  },
  {
    "text": "usual advantages that you would see for",
    "start": "142840",
    "end": "144560"
  },
  {
    "text": "self hosting cost scaling performance",
    "start": "144560",
    "end": "147519"
  },
  {
    "text": "control privacy um privacy seems to",
    "start": "147519",
    "end": "151200"
  },
  {
    "text": "becoming increasingly more important for",
    "start": "151200",
    "end": "153440"
  },
  {
    "text": "folks but all of the other four",
    "start": "153440",
    "end": "155879"
  },
  {
    "text": "components there too are quite",
    "start": "155879",
    "end": "158280"
  },
  {
    "text": "important and I'm sure you know most of",
    "start": "158280",
    "end": "160599"
  },
  {
    "text": "the the big names up there at the top",
    "start": "160599",
    "end": "163400"
  },
  {
    "text": "but there's some downsides to",
    "start": "163400",
    "end": "165360"
  },
  {
    "text": "self-hosting complexity being the the",
    "start": "165360",
    "end": "167840"
  },
  {
    "text": "biggest",
    "start": "167840",
    "end": "169080"
  },
  {
    "text": "one uh so handling the complexity is",
    "start": "169080",
    "end": "172000"
  },
  {
    "text": "resource intensive um our reference",
    "start": "172000",
    "end": "175200"
  },
  {
    "text": "example that we're going to share with",
    "start": "175200",
    "end": "176239"
  },
  {
    "text": "you today combines deploying multiple uh",
    "start": "176239",
    "end": "179480"
  },
  {
    "text": "multip multiple kubernetes clusters",
    "start": "179480",
    "end": "181440"
  },
  {
    "text": "sorry I mix a I use cubes in another",
    "start": "181440",
    "end": "185560"
  },
  {
    "text": "area so sometimes I throw that in",
    "start": "185560",
    "end": "187799"
  },
  {
    "text": "instead of kubernetes",
    "start": "187799",
    "end": "189560"
  },
  {
    "text": "clusters uh along with a a cluster",
    "start": "189560",
    "end": "192280"
  },
  {
    "text": "scheduler and that's going to help take",
    "start": "192280",
    "end": "195120"
  },
  {
    "text": "away a lot of the administrative",
    "start": "195120",
    "end": "196680"
  },
  {
    "text": "overhead of deploying your",
    "start": "196680",
    "end": "200720"
  },
  {
    "text": "own all right let's take a look at some",
    "start": "200720",
    "end": "202799"
  },
  {
    "text": "of the different components for our",
    "start": "202799",
    "end": "205200"
  },
  {
    "text": "reference",
    "start": "205200",
    "end": "206159"
  },
  {
    "text": "architecture uh we've got up at the top",
    "start": "206159",
    "end": "208400"
  },
  {
    "text": "we've got our ingestion job to create",
    "start": "208400",
    "end": "210560"
  },
  {
    "text": "and update our Vector database um the",
    "start": "210560",
    "end": "213159"
  },
  {
    "text": "vector database can be a lot of",
    "start": "213159",
    "end": "214480"
  },
  {
    "text": "different solutions for that towards the",
    "start": "214480",
    "end": "217519"
  },
  {
    "text": "middle we've got our prediction service",
    "start": "217519",
    "end": "219200"
  },
  {
    "text": "that's combining the model input and and",
    "start": "219200",
    "end": "221799"
  },
  {
    "text": "query with rag",
    "start": "221799",
    "end": "224879"
  },
  {
    "text": "context we've got the user interface",
    "start": "224879",
    "end": "227000"
  },
  {
    "text": "over here on the left and then we've got",
    "start": "227000",
    "end": "228120"
  },
  {
    "text": "our llm model serving at the",
    "start": "228120",
    "end": "231959"
  },
  {
    "text": "bottom each one of these components has",
    "start": "232079",
    "end": "235040"
  },
  {
    "text": "different requirements right resource",
    "start": "235040",
    "end": "237360"
  },
  {
    "text": "needs your vector database can run on",
    "start": "237360",
    "end": "240439"
  },
  {
    "text": "pretty generic CPU resources and it's",
    "start": "240439",
    "end": "242959"
  },
  {
    "text": "only needed periodically um this may",
    "start": "242959",
    "end": "245200"
  },
  {
    "text": "change over time and of course you can",
    "start": "245200",
    "end": "246760"
  },
  {
    "text": "change that with policy based scheduler",
    "start": "246760",
    "end": "248640"
  },
  {
    "text": "which we're going to talk about",
    "start": "248640",
    "end": "250079"
  },
  {
    "text": "later uh your Center section with your",
    "start": "250079",
    "end": "252560"
  },
  {
    "text": "llm and rag serving and the user part is",
    "start": "252560",
    "end": "255120"
  },
  {
    "text": "going to have higher availability",
    "start": "255120",
    "end": "256720"
  },
  {
    "text": "requirements uh but it can also run on",
    "start": "256720",
    "end": "259199"
  },
  {
    "text": "pretty generic Hardware so really just",
    "start": "259199",
    "end": "262079"
  },
  {
    "text": "CPUs uh your llm serving component is",
    "start": "262080",
    "end": "264880"
  },
  {
    "text": "where you're going to need something a",
    "start": "264880",
    "end": "266160"
  },
  {
    "text": "little bit more exotic uh in the form of",
    "start": "266160",
    "end": "268720"
  },
  {
    "text": "most likely a GPU Al though as we've",
    "start": "268720",
    "end": "270199"
  },
  {
    "text": "heard earlier today there's options",
    "start": "270199",
    "end": "271840"
  },
  {
    "text": "where you might be able to use an",
    "start": "271840",
    "end": "273039"
  },
  {
    "text": "accelerated CPU for this too but the",
    "start": "273039",
    "end": "275360"
  },
  {
    "text": "point with this is that there's",
    "start": "275360",
    "end": "276840"
  },
  {
    "text": "different resource needs for each of",
    "start": "276840",
    "end": "278520"
  },
  {
    "text": "these different parts and also different",
    "start": "278520",
    "end": "281039"
  },
  {
    "text": "availability needs for each of these",
    "start": "281039",
    "end": "282479"
  },
  {
    "text": "different",
    "start": "282479",
    "end": "284720"
  },
  {
    "text": "parts so uh obviously for this we're",
    "start": "287240",
    "end": "290639"
  },
  {
    "text": "going to use a multicluster",
    "start": "290639",
    "end": "292440"
  },
  {
    "text": "kubernetes deployment across multiple",
    "start": "292440",
    "end": "295280"
  },
  {
    "text": "different clouds if we use multiple",
    "start": "295280",
    "end": "297720"
  },
  {
    "text": "clouds that means that we can take",
    "start": "297720",
    "end": "299880"
  },
  {
    "text": "advantage of all the kinds of benefits",
    "start": "299880",
    "end": "301400"
  },
  {
    "text": "that you get from operating in a",
    "start": "301400",
    "end": "304320"
  },
  {
    "text": "hyperscaler uh we can also by deploying",
    "start": "304320",
    "end": "308120"
  },
  {
    "text": "multiple kubernetes clusters we can",
    "start": "308120",
    "end": "310720"
  },
  {
    "text": "Define each one to have the different",
    "start": "310720",
    "end": "312320"
  },
  {
    "text": "kinds of resources that our architecture",
    "start": "312320",
    "end": "314320"
  },
  {
    "text": "could benefit from so with uh the the",
    "start": "314320",
    "end": "318000"
  },
  {
    "text": "kinds of workloads that need gpus get",
    "start": "318000",
    "end": "320160"
  },
  {
    "text": "deployed to kubernetes clusters that",
    "start": "320160",
    "end": "322479"
  },
  {
    "text": "have gpus and those that don't don't and",
    "start": "322479",
    "end": "325120"
  },
  {
    "text": "we can also efficiently look for the",
    "start": "325120",
    "end": "328440"
  },
  {
    "text": "most coste effective GR these clusters",
    "start": "328440",
    "end": "331160"
  },
  {
    "text": "in various different clouds for us to",
    "start": "331160",
    "end": "333160"
  },
  {
    "text": "deploy on and we'll see as we get into",
    "start": "333160",
    "end": "335319"
  },
  {
    "text": "it Nova makes this easy to",
    "start": "335319",
    "end": "339319"
  },
  {
    "text": "do there are a lot of different um",
    "start": "344800",
    "end": "348759"
  },
  {
    "text": "services that you could use for the",
    "start": "348759",
    "end": "350240"
  },
  {
    "text": "various different components here and",
    "start": "350240",
    "end": "352680"
  },
  {
    "text": "we'd be remiss if we didn't mention some",
    "start": "352680",
    "end": "354280"
  },
  {
    "text": "of those so you can automatically deploy",
    "start": "354280",
    "end": "358600"
  },
  {
    "text": "your workloads on on model",
    "start": "358600",
    "end": "362240"
  },
  {
    "text": "rollout and there's a few different",
    "start": "362240",
    "end": "364919"
  },
  {
    "text": "services that you could plug in for the",
    "start": "364919",
    "end": "366840"
  },
  {
    "text": "vector",
    "start": "366840",
    "end": "367919"
  },
  {
    "text": "database uh and you can there's various",
    "start": "367919",
    "end": "371000"
  },
  {
    "text": "different cluster schedulers that you",
    "start": "371000",
    "end": "372240"
  },
  {
    "text": "could use couple that we've talked about",
    "start": "372240",
    "end": "373759"
  },
  {
    "text": "here today carada is one of them kcp and",
    "start": "373759",
    "end": "377319"
  },
  {
    "text": "Nova this talk is going to focus on",
    "start": "377319",
    "end": "381000"
  },
  {
    "text": "Nova all right what is Nova so Nova is a",
    "start": "381000",
    "end": "384560"
  },
  {
    "text": "policy-based cluster",
    "start": "384560",
    "end": "386639"
  },
  {
    "text": "scheduler and some of the benefits and",
    "start": "386639",
    "end": "389639"
  },
  {
    "text": "capabilities that it provides is the",
    "start": "389639",
    "end": "391280"
  },
  {
    "text": "ability to",
    "start": "391280",
    "end": "392759"
  },
  {
    "text": "place workloads based on different",
    "start": "392759",
    "end": "395759"
  },
  {
    "text": "spread constraints um label based",
    "start": "395759",
    "end": "398720"
  },
  {
    "text": "capacity based including",
    "start": "398720",
    "end": "401039"
  },
  {
    "text": "gpus uh you can migrate your workloads",
    "start": "401039",
    "end": "403520"
  },
  {
    "text": "you can autoscale and you can do just in",
    "start": "403520",
    "end": "405319"
  },
  {
    "text": "time clusters as well across all the",
    "start": "405319",
    "end": "407639"
  },
  {
    "text": "major um kuet service providers eks gke",
    "start": "407639",
    "end": "411400"
  },
  {
    "text": "and",
    "start": "411400",
    "end": "413639"
  },
  {
    "text": "AKs all right so here let's put some",
    "start": "413680",
    "end": "417240"
  },
  {
    "text": "more specific names to some of the",
    "start": "417240",
    "end": "418759"
  },
  {
    "text": "things the components we've talked about",
    "start": "418759",
    "end": "421479"
  },
  {
    "text": "before this is what we're actually going",
    "start": "421479",
    "end": "423440"
  },
  {
    "text": "to have in the",
    "start": "423440",
    "end": "425520"
  },
  {
    "text": "demo uh so we have for the vector",
    "start": "425520",
    "end": "428240"
  },
  {
    "text": "database we've selected FIS from meta",
    "start": "428240",
    "end": "433199"
  },
  {
    "text": "faceb um for the llm and rag serving",
    "start": "433199",
    "end": "436520"
  },
  {
    "text": "component we've selected Lang chain with",
    "start": "436520",
    "end": "438599"
  },
  {
    "text": "fast API and for the llm serving",
    "start": "438599",
    "end": "441479"
  },
  {
    "text": "component we've got open llm with some",
    "start": "441479",
    "end": "444800"
  },
  {
    "text": "uh with a hugging face llm model that we",
    "start": "444800",
    "end": "447960"
  },
  {
    "text": "downloaded again trying to to stick with",
    "start": "447960",
    "end": "450080"
  },
  {
    "text": "as much of the open source Spirit as",
    "start": "450080",
    "end": "454120"
  },
  {
    "text": "possible uh we'll kind of skip through",
    "start": "454120",
    "end": "456120"
  },
  {
    "text": "this pretty quickly because we don't",
    "start": "456120",
    "end": "457680"
  },
  {
    "text": "have a whole lot of time today and we",
    "start": "457680",
    "end": "459520"
  },
  {
    "text": "want to get to the demo part but if",
    "start": "459520",
    "end": "461720"
  },
  {
    "text": "you're curious all of these things are",
    "start": "461720",
    "end": "464039"
  },
  {
    "text": "on GitHub there's a link to all the",
    "start": "464039",
    "end": "466639"
  },
  {
    "text": "different Docker containers that are",
    "start": "466639",
    "end": "468240"
  },
  {
    "text": "prepackaged and uh scripts and tooling",
    "start": "468240",
    "end": "470800"
  },
  {
    "text": "that we've used to generate this demo as",
    "start": "470800",
    "end": "475039"
  },
  {
    "text": "well so we talked a little bit before",
    "start": "475039",
    "end": "477400"
  },
  {
    "text": "about the availability needs for some of",
    "start": "477400",
    "end": "479080"
  },
  {
    "text": "these different",
    "start": "479080",
    "end": "480199"
  },
  {
    "text": "components we are specifying one cluster",
    "start": "480199",
    "end": "483280"
  },
  {
    "text": "for the vector database three clusters",
    "start": "483280",
    "end": "485479"
  },
  {
    "text": "across three regions for the llm and rag",
    "start": "485479",
    "end": "488639"
  },
  {
    "text": "serving components to facilitate higher",
    "start": "488639",
    "end": "491240"
  },
  {
    "text": "availability and two clusters for the",
    "start": "491240",
    "end": "493479"
  },
  {
    "text": "llm serving",
    "start": "493479",
    "end": "494960"
  },
  {
    "text": "component uh also to bridge the gap of",
    "start": "494960",
    "end": "498159"
  },
  {
    "text": "having decently High",
    "start": "498159",
    "end": "499840"
  },
  {
    "text": "availability uh without spending too",
    "start": "499840",
    "end": "502000"
  },
  {
    "text": "much",
    "start": "502000",
    "end": "503879"
  },
  {
    "text": "money all right we're almost there to",
    "start": "503879",
    "end": "506199"
  },
  {
    "text": "the demo so this is going this shows us",
    "start": "506199",
    "end": "509199"
  },
  {
    "text": "the steps that Nova is going to go",
    "start": "509199",
    "end": "511080"
  },
  {
    "text": "through when it's rolling out a new",
    "start": "511080",
    "end": "513440"
  },
  {
    "text": "model or a new deployment actually not",
    "start": "513440",
    "end": "515399"
  },
  {
    "text": "just a new model so first step is",
    "start": "515399",
    "end": "518120"
  },
  {
    "text": "placing the creating a new name space",
    "start": "518120",
    "end": "521039"
  },
  {
    "text": "and then pushing all the images or at",
    "start": "521039",
    "end": "523479"
  },
  {
    "text": "least pushing the image creation secrets",
    "start": "523479",
    "end": "525160"
  },
  {
    "text": "to all the different uh kubernetes",
    "start": "525160",
    "end": "528279"
  },
  {
    "text": "clusters then we'll pull in the llm",
    "start": "528279",
    "end": "530920"
  },
  {
    "text": "serving and load balancer uh and the the",
    "start": "530920",
    "end": "535800"
  },
  {
    "text": "rag model down",
    "start": "535800",
    "end": "538440"
  },
  {
    "text": "here and then we'll fire up the vector",
    "start": "538440",
    "end": "541519"
  },
  {
    "text": "database on the vector database cluster",
    "start": "541519",
    "end": "544560"
  },
  {
    "text": "and last but not least we'll place all",
    "start": "544560",
    "end": "547040"
  },
  {
    "text": "of the llm and rag serving components",
    "start": "547040",
    "end": "550519"
  },
  {
    "text": "across the three clusters to serve the",
    "start": "550519",
    "end": "552839"
  },
  {
    "text": "API",
    "start": "552839",
    "end": "554519"
  },
  {
    "text": "layer so it's a four-step process to get",
    "start": "554519",
    "end": "557880"
  },
  {
    "text": "this all deployed to across all these",
    "start": "557880",
    "end": "559880"
  },
  {
    "text": "different clusters and you may be",
    "start": "559880",
    "end": "561959"
  },
  {
    "text": "wondering what's the process to take it",
    "start": "561959",
    "end": "564880"
  },
  {
    "text": "down one step process just remove the",
    "start": "564880",
    "end": "568160"
  },
  {
    "text": "name space everything lives all in one",
    "start": "568160",
    "end": "570360"
  },
  {
    "text": "name space across all the different",
    "start": "570360",
    "end": "572000"
  },
  {
    "text": "cubes simple and if you're thinking well",
    "start": "572000",
    "end": "574560"
  },
  {
    "text": "maybe we could run multiples of these at",
    "start": "574560",
    "end": "576160"
  },
  {
    "text": "the same time across different name",
    "start": "576160",
    "end": "577560"
  },
  {
    "text": "spaces you'd be right you",
    "start": "577560",
    "end": "581000"
  },
  {
    "text": "could so there's a few different uh",
    "start": "581680",
    "end": "584079"
  },
  {
    "text": "components that we wanted to also call",
    "start": "584079",
    "end": "585680"
  },
  {
    "text": "out as options we mentioned using",
    "start": "585680",
    "end": "588440"
  },
  {
    "text": "FIS uh as the vector database but",
    "start": "588440",
    "end": "591160"
  },
  {
    "text": "there's alternatives for that as well",
    "start": "591160",
    "end": "594000"
  },
  {
    "text": "astrab is one pine cone is one and we8",
    "start": "594000",
    "end": "597440"
  },
  {
    "text": "is another so if you don't want to spend",
    "start": "597440",
    "end": "599480"
  },
  {
    "text": "your time learning faiss or dealing with",
    "start": "599480",
    "end": "602399"
  },
  {
    "text": "some of the headaches that comes with",
    "start": "602399",
    "end": "604320"
  },
  {
    "text": "that and might talk a little bit about",
    "start": "604320",
    "end": "606079"
  },
  {
    "text": "some of those headaches you ran into",
    "start": "606079",
    "end": "607399"
  },
  {
    "text": "with that um you could use a SAS",
    "start": "607399",
    "end": "610519"
  },
  {
    "text": "offering for",
    "start": "610519",
    "end": "612120"
  },
  {
    "text": "that um you could also spread your",
    "start": "612120",
    "end": "615880"
  },
  {
    "text": "clusters across differently across",
    "start": "615880",
    "end": "617680"
  },
  {
    "text": "different clouds than what we've",
    "start": "617680",
    "end": "620000"
  },
  {
    "text": "outlined here and you could have",
    "start": "620000",
    "end": "622040"
  },
  {
    "text": "different model operations so you could",
    "start": "622040",
    "end": "623720"
  },
  {
    "text": "trigger a roll out uh via gitops and you",
    "start": "623720",
    "end": "626600"
  },
  {
    "text": "can run multiple different versions of",
    "start": "626600",
    "end": "627920"
  },
  {
    "text": "the model at the same time and in a blue",
    "start": "627920",
    "end": "629800"
  },
  {
    "text": "green",
    "start": "629800",
    "end": "632079"
  },
  {
    "text": "mode okay I think this is where we're",
    "start": "632240",
    "end": "634079"
  },
  {
    "text": "going to get into the example right",
    "start": "634079",
    "end": "637320"
  },
  {
    "text": "an okay thanks a lot Dave I appreciate",
    "start": "641320",
    "end": "644040"
  },
  {
    "text": "it uh so yeah let's move into the",
    "start": "644040",
    "end": "647200"
  },
  {
    "text": "examples we have two examples of using",
    "start": "647200",
    "end": "650040"
  },
  {
    "text": "the um basically approach that Dave",
    "start": "650040",
    "end": "652760"
  },
  {
    "text": "described for uh multicluster kubernetes",
    "start": "652760",
    "end": "656000"
  },
  {
    "text": "along with a cluster scheduler um and",
    "start": "656000",
    "end": "659480"
  },
  {
    "text": "making sure that all of the components",
    "start": "659480",
    "end": "661800"
  },
  {
    "text": "can be uh managed properly um for uh",
    "start": "661800",
    "end": "665839"
  },
  {
    "text": "doing the uh model in production so just",
    "start": "665839",
    "end": "669040"
  },
  {
    "text": "some choices we made for the examples we",
    "start": "669040",
    "end": "671480"
  },
  {
    "text": "chose to use the Astro uh DB Vector DB",
    "start": "671480",
    "end": "675639"
  },
  {
    "text": "rather than FIS it's not like uh that",
    "start": "675639",
    "end": "678600"
  },
  {
    "text": "FIS won't work and we have uh the same",
    "start": "678600",
    "end": "682079"
  },
  {
    "text": "examples uh in backup slides in our talk",
    "start": "682079",
    "end": "684600"
  },
  {
    "text": "but we just thought in production people",
    "start": "684600",
    "end": "686600"
  },
  {
    "text": "may want a hosted database um and so",
    "start": "686600",
    "end": "689320"
  },
  {
    "text": "we've already given you links to all the",
    "start": "689320",
    "end": "691079"
  },
  {
    "text": "packaging you need for all of those open",
    "start": "691079",
    "end": "692959"
  },
  {
    "text": "source components we've already looked",
    "start": "692959",
    "end": "694360"
  },
  {
    "text": "at and here's the packaging where we",
    "start": "694360",
    "end": "696480"
  },
  {
    "text": "replace uh face with uh ASB uh and",
    "start": "696480",
    "end": "700519"
  },
  {
    "text": "you'll see that it's super easy to plug",
    "start": "700519",
    "end": "702160"
  },
  {
    "text": "in a different Vector database if you",
    "start": "702160",
    "end": "704079"
  },
  {
    "text": "have a different one that you want to",
    "start": "704079",
    "end": "705560"
  },
  {
    "text": "use and we chose to only run ingestion",
    "start": "705560",
    "end": "708600"
  },
  {
    "text": "uh at the deployment of the model time",
    "start": "708600",
    "end": "710680"
  },
  {
    "text": "but you could obviously run a continuous",
    "start": "710680",
    "end": "712839"
  },
  {
    "text": "ingestion and it wouldn't uh change too",
    "start": "712839",
    "end": "714959"
  },
  {
    "text": "many things about our example we chose",
    "start": "714959",
    "end": "718120"
  },
  {
    "text": "to run our examples on a single Cloud",
    "start": "718120",
    "end": "720480"
  },
  {
    "text": "which is eks and we chose to enable a",
    "start": "720480",
    "end": "723360"
  },
  {
    "text": "feature of the Nova cluster scheduler",
    "start": "723360",
    "end": "726399"
  },
  {
    "text": "which is cluster suspend resume standby",
    "start": "726399",
    "end": "729279"
  },
  {
    "text": "this feature is not on by default and",
    "start": "729279",
    "end": "731040"
  },
  {
    "text": "you don't have to use this feature if",
    "start": "731040",
    "end": "732480"
  },
  {
    "text": "you don't want to but what this feature",
    "start": "732480",
    "end": "734440"
  },
  {
    "text": "does is if a cluster is idle for an",
    "start": "734440",
    "end": "737040"
  },
  {
    "text": "extended period of time it basically",
    "start": "737040",
    "end": "739320"
  },
  {
    "text": "spins it down meaning it uh Cycles all",
    "start": "739320",
    "end": "742320"
  },
  {
    "text": "of its non-control plane parts of the",
    "start": "742320",
    "end": "744839"
  },
  {
    "text": "cloud uh to zero resources so it's",
    "start": "744839",
    "end": "747360"
  },
  {
    "text": "basically making things a little green",
    "start": "747360",
    "end": "749959"
  },
  {
    "text": "um if you're already paying for those",
    "start": "749959",
    "end": "751399"
  },
  {
    "text": "resources you might not care if they're",
    "start": "751399",
    "end": "753000"
  },
  {
    "text": "powered up or not but at least you're",
    "start": "753000",
    "end": "754920"
  },
  {
    "text": "not burning that power um and finally we",
    "start": "754920",
    "end": "757560"
  },
  {
    "text": "trigger the operations manually for the",
    "start": "757560",
    "end": "759760"
  },
  {
    "text": "purposes of the demo I certainly agree",
    "start": "759760",
    "end": "761560"
  },
  {
    "text": "that get Ops would be a great way to go",
    "start": "761560",
    "end": "763760"
  },
  {
    "text": "um if you were going to do this in",
    "start": "763760",
    "end": "764800"
  },
  {
    "text": "production but just for the presentation",
    "start": "764800",
    "end": "766920"
  },
  {
    "text": "uh one little disclaimer here these",
    "start": "766920",
    "end": "768880"
  },
  {
    "text": "examples focus on infrastructure",
    "start": "768880",
    "end": "770680"
  },
  {
    "text": "management not on Mad ml skills like I'm",
    "start": "770680",
    "end": "773720"
  },
  {
    "text": "not a data scientist uh so you know I",
    "start": "773720",
    "end": "776360"
  },
  {
    "text": "chose a respectable embedding model for",
    "start": "776360",
    "end": "778760"
  },
  {
    "text": "the vect DP and a respectable open",
    "start": "778760",
    "end": "781000"
  },
  {
    "text": "source llm model but some different",
    "start": "781000",
    "end": "783160"
  },
  {
    "text": "model might work better for your",
    "start": "783160",
    "end": "784560"
  },
  {
    "text": "workload and similarly the resource",
    "start": "784560",
    "end": "787399"
  },
  {
    "text": "sizing on the docker containers that we",
    "start": "787399",
    "end": "789120"
  },
  {
    "text": "used that you'll see in our repo was",
    "start": "789120",
    "end": "791079"
  },
  {
    "text": "chosen for being able to demonstrate",
    "start": "791079",
    "end": "793399"
  },
  {
    "text": "something but it wasn't tuned heavily uh",
    "start": "793399",
    "end": "795680"
  },
  {
    "text": "to make sure that it could be the",
    "start": "795680",
    "end": "797000"
  },
  {
    "text": "optimal",
    "start": "797000",
    "end": "798639"
  },
  {
    "text": "efficiency so with those uh disclaimers",
    "start": "798639",
    "end": "801279"
  },
  {
    "text": "out of the way our first example is a",
    "start": "801279",
    "end": "803440"
  },
  {
    "text": "series of operations that you would do",
    "start": "803440",
    "end": "805040"
  },
  {
    "text": "on a m model in production you would",
    "start": "805040",
    "end": "807639"
  },
  {
    "text": "roll out version one of the model you",
    "start": "807639",
    "end": "810160"
  },
  {
    "text": "would roll out version two of the model",
    "start": "810160",
    "end": "812079"
  },
  {
    "text": "and make sure it's working as well as",
    "start": "812079",
    "end": "813839"
  },
  {
    "text": "version one and then you would retire",
    "start": "813839",
    "end": "816279"
  },
  {
    "text": "version one and so let's see how this",
    "start": "816279",
    "end": "818800"
  },
  {
    "text": "approach that we've been discussing",
    "start": "818800",
    "end": "820199"
  },
  {
    "text": "would handle this",
    "start": "820199",
    "end": "822360"
  },
  {
    "text": "situation so basically at the beginning",
    "start": "822360",
    "end": "824480"
  },
  {
    "text": "of time the Nova control plane uh which",
    "start": "824480",
    "end": "827720"
  },
  {
    "text": "is just looks like a kubernetes cluster",
    "start": "827720",
    "end": "829639"
  },
  {
    "text": "you talked to is itself interacting with",
    "start": "829639",
    "end": "832759"
  },
  {
    "text": "six clusters uh in this example the",
    "start": "832759",
    "end": "835800"
  },
  {
    "text": "first three clusters with the CPU prefix",
    "start": "835800",
    "end": "838279"
  },
  {
    "text": "are the Clusters that we want to run the",
    "start": "838279",
    "end": "840199"
  },
  {
    "text": "user-facing part of our llm plus rag uh",
    "start": "840199",
    "end": "843639"
  },
  {
    "text": "serving so we wanted to locate those in",
    "start": "843639",
    "end": "846279"
  },
  {
    "text": "three different regions across the world",
    "start": "846279",
    "end": "848759"
  },
  {
    "text": "um and they need to be highly available",
    "start": "848759",
    "end": "850519"
  },
  {
    "text": "and they need to respond to the user",
    "start": "850519",
    "end": "852279"
  },
  {
    "text": "even if they can't talk to other parts",
    "start": "852279",
    "end": "854040"
  },
  {
    "text": "of the system then we have two clusters",
    "start": "854040",
    "end": "856480"
  },
  {
    "text": "that have gpus available in this case",
    "start": "856480",
    "end": "859040"
  },
  {
    "text": "each of them only has one a1g GPU",
    "start": "859040",
    "end": "862399"
  },
  {
    "text": "because I wanted to show resource",
    "start": "862399",
    "end": "863720"
  },
  {
    "text": "availability and the selection of uh a",
    "start": "863720",
    "end": "866600"
  },
  {
    "text": "cluster based on resources and I want to",
    "start": "866600",
    "end": "868320"
  },
  {
    "text": "do that in the simple way possible and",
    "start": "868320",
    "end": "870600"
  },
  {
    "text": "finally there's a cluster on which",
    "start": "870600",
    "end": "871959"
  },
  {
    "text": "ingestion will run uh when the ingestion",
    "start": "871959",
    "end": "874320"
  },
  {
    "text": "job",
    "start": "874320",
    "end": "875199"
  },
  {
    "text": "runs so after we let those clusters sit",
    "start": "875199",
    "end": "878000"
  },
  {
    "text": "for a while they were all idle so they",
    "start": "878000",
    "end": "879720"
  },
  {
    "text": "all go into standby so just to kind of",
    "start": "879720",
    "end": "881920"
  },
  {
    "text": "show",
    "start": "881920",
    "end": "883079"
  },
  {
    "text": "that all right so we're ready to roll",
    "start": "883079",
    "end": "885160"
  },
  {
    "text": "out version one of the model uh what do",
    "start": "885160",
    "end": "887399"
  },
  {
    "text": "we do well it's kind of a oneliner",
    "start": "887399",
    "end": "889160"
  },
  {
    "text": "basically and you'll see the script in",
    "start": "889160",
    "end": "891199"
  },
  {
    "text": "our um repo but basically the oneliner",
    "start": "891199",
    "end": "894079"
  },
  {
    "text": "says what is the model Nam space that I",
    "start": "894079",
    "end": "896440"
  },
  {
    "text": "want to deploy the model in uh what are",
    "start": "896440",
    "end": "898800"
  },
  {
    "text": "the Secrets I need all of the uh",
    "start": "898800",
    "end": "900920"
  },
  {
    "text": "clusters to know to be able to pull",
    "start": "900920",
    "end": "902920"
  },
  {
    "text": "parts of the uh the images that they",
    "start": "902920",
    "end": "905399"
  },
  {
    "text": "need to run their part of the workload",
    "start": "905399",
    "end": "907839"
  },
  {
    "text": "uh true means I'd like you to populate",
    "start": "907839",
    "end": "910199"
  },
  {
    "text": "the vector data blase when you run so",
    "start": "910199",
    "end": "911880"
  },
  {
    "text": "we're only going to populate it during",
    "start": "911880",
    "end": "913360"
  },
  {
    "text": "version one model roll out we're going",
    "start": "913360",
    "end": "915720"
  },
  {
    "text": "to keep that Vector database going after",
    "start": "915720",
    "end": "918079"
  },
  {
    "text": "version one the next argument is the",
    "start": "918079",
    "end": "920440"
  },
  {
    "text": "type of input this in this case we're",
    "start": "920440",
    "end": "923160"
  },
  {
    "text": "well the next argument is the cluster in",
    "start": "923160",
    "end": "924920"
  },
  {
    "text": "which we want to run the ingestion job",
    "start": "924920",
    "end": "927480"
  },
  {
    "text": "um so that's ingest Us West one the next",
    "start": "927480",
    "end": "930120"
  },
  {
    "text": "two arguments have to do with what is",
    "start": "930120",
    "end": "931560"
  },
  {
    "text": "the raw data that I want to ingest so",
    "start": "931560",
    "end": "933920"
  },
  {
    "text": "for our particular example we're going",
    "start": "933920",
    "end": "935360"
  },
  {
    "text": "to ingest a site map that sitemap is",
    "start": "935360",
    "end": "938000"
  },
  {
    "text": "going to contain documentation from the",
    "start": "938000",
    "end": "940279"
  },
  {
    "text": "little company um and then the final",
    "start": "940279",
    "end": "942360"
  },
  {
    "text": "three arguments have to do with the uh",
    "start": "942360",
    "end": "944319"
  },
  {
    "text": "Vector DB credentials for to set up the",
    "start": "944319",
    "end": "946519"
  },
  {
    "text": "vector DB uh in terms of populating it",
    "start": "946519",
    "end": "949040"
  },
  {
    "text": "and using it so step one is to uh that",
    "start": "949040",
    "end": "952519"
  },
  {
    "text": "the script executes is to place the",
    "start": "952519",
    "end": "954480"
  },
  {
    "text": "model name space and the image pole",
    "start": "954480",
    "end": "956680"
  },
  {
    "text": "secret on all the Clusters that are",
    "start": "956680",
    "end": "958319"
  },
  {
    "text": "being managed by the Nova control plane",
    "start": "958319",
    "end": "960560"
  },
  {
    "text": "so the first thing is a policy that's",
    "start": "960560",
    "end": "963680"
  },
  {
    "text": "applied to the Nova control plane so",
    "start": "963680",
    "end": "965839"
  },
  {
    "text": "that tells the Nova control plane here's",
    "start": "965839",
    "end": "967959"
  },
  {
    "text": "the policy and that policy will apply to",
    "start": "967959",
    "end": "970399"
  },
  {
    "text": "the namespace and that's a spread and",
    "start": "970399",
    "end": "971920"
  },
  {
    "text": "duplicate policy so the Nam space for",
    "start": "971920",
    "end": "973880"
  },
  {
    "text": "the model will be duplicated and spread",
    "start": "973880",
    "end": "976240"
  },
  {
    "text": "across all the Clusters under management",
    "start": "976240",
    "end": "978120"
  },
  {
    "text": "by Nova the next step is to do the same",
    "start": "978120",
    "end": "980639"
  },
  {
    "text": "thing for the secrets that are needed to",
    "start": "980639",
    "end": "983440"
  },
  {
    "text": "pull the images step two is to place the",
    "start": "983440",
    "end": "986560"
  },
  {
    "text": "llm serving layer that's the layer that",
    "start": "986560",
    "end": "988519"
  },
  {
    "text": "needs the the GPU so we're going to",
    "start": "988519",
    "end": "990880"
  },
  {
    "text": "create a policy it's a simple policy to",
    "start": "990880",
    "end": "992959"
  },
  {
    "text": "say place the things that this policy",
    "start": "992959",
    "end": "996279"
  },
  {
    "text": "pertains to to a cluster that has",
    "start": "996279",
    "end": "998639"
  },
  {
    "text": "adequate resources for the things that",
    "start": "998639",
    "end": "1001120"
  },
  {
    "text": "this needs and so we then deployed the",
    "start": "1001120",
    "end": "1003440"
  },
  {
    "text": "llm serving along with it service um as",
    "start": "1003440",
    "end": "1007160"
  },
  {
    "text": "well as a front you know the service for",
    "start": "1007160",
    "end": "1008560"
  },
  {
    "text": "a front end for load balancer um and",
    "start": "1008560",
    "end": "1011279"
  },
  {
    "text": "that resource availability PL policy",
    "start": "1011279",
    "end": "1013720"
  },
  {
    "text": "allows those to be placed on one of the",
    "start": "1013720",
    "end": "1015279"
  },
  {
    "text": "GPU clusters we saw so we wait for that",
    "start": "1015279",
    "end": "1018000"
  },
  {
    "text": "deployment to finish",
    "start": "1018000",
    "end": "1019399"
  },
  {
    "text": "and we get an external IP address which",
    "start": "1019399",
    "end": "1022000"
  },
  {
    "text": "which will then be used by our customer",
    "start": "1022000",
    "end": "1024400"
  },
  {
    "text": "facing um layer to make calls to the",
    "start": "1024400",
    "end": "1027558"
  },
  {
    "text": "backend GPU model third step is to",
    "start": "1027559",
    "end": "1030319"
  },
  {
    "text": "populate our uh Vector DB with the",
    "start": "1030319",
    "end": "1033240"
  },
  {
    "text": "vector DB ingestor here we're using yet",
    "start": "1033240",
    "end": "1035720"
  },
  {
    "text": "another policy this policy is specified",
    "start": "1035720",
    "end": "1037918"
  },
  {
    "text": "cluster policy please run this job on",
    "start": "1037919",
    "end": "1040640"
  },
  {
    "text": "the cluster I specify uh so that when we",
    "start": "1040640",
    "end": "1043678"
  },
  {
    "text": "run the data ingestion job the policy",
    "start": "1043679",
    "end": "1046438"
  },
  {
    "text": "applies to that job and the data is",
    "start": "1046439",
    "end": "1048280"
  },
  {
    "text": "ingested",
    "start": "1048280",
    "end": "1049400"
  },
  {
    "text": "put into the vector database and the",
    "start": "1049400",
    "end": "1051960"
  },
  {
    "text": "final step is to put those front ends on",
    "start": "1051960",
    "end": "1054520"
  },
  {
    "text": "the three clusters that we located you",
    "start": "1054520",
    "end": "1056799"
  },
  {
    "text": "know in different GEOS across the world",
    "start": "1056799",
    "end": "1059559"
  },
  {
    "text": "and in that case the the service needs",
    "start": "1059559",
    "end": "1062200"
  },
  {
    "text": "to be spread and duplicated just like",
    "start": "1062200",
    "end": "1064000"
  },
  {
    "text": "the namespace and image secrets to be",
    "start": "1064000",
    "end": "1066320"
  },
  {
    "text": "spread and duplicated but not across all",
    "start": "1066320",
    "end": "1068400"
  },
  {
    "text": "the Clusters just across those three CPU",
    "start": "1068400",
    "end": "1071000"
  },
  {
    "text": "clusters we set up in the three Geo so",
    "start": "1071000",
    "end": "1072960"
  },
  {
    "text": "we label those clusters and our policy",
    "start": "1072960",
    "end": "1075520"
  },
  {
    "text": "says apply this policy to the labeled",
    "start": "1075520",
    "end": "1078520"
  },
  {
    "text": "cluster so spread and duplicate and in",
    "start": "1078520",
    "end": "1080760"
  },
  {
    "text": "this case we since we spread and",
    "start": "1080760",
    "end": "1082280"
  },
  {
    "text": "duplicate we get back three uh external",
    "start": "1082280",
    "end": "1085120"
  },
  {
    "text": "IPS for the three you know entry points",
    "start": "1085120",
    "end": "1088480"
  },
  {
    "text": "to the system uh in the three GEOS so",
    "start": "1088480",
    "end": "1091640"
  },
  {
    "text": "we've we One Step from the user point of",
    "start": "1091640",
    "end": "1093880"
  },
  {
    "text": "view of just running the script and",
    "start": "1093880",
    "end": "1096039"
  },
  {
    "text": "basically all the all the operations are",
    "start": "1096039",
    "end": "1098240"
  },
  {
    "text": "executed against the Nova control plane",
    "start": "1098240",
    "end": "1100440"
  },
  {
    "text": "kubernetes cluster so you feel like",
    "start": "1100440",
    "end": "1102200"
  },
  {
    "text": "you're talking to one cluster but these",
    "start": "1102200",
    "end": "1104919"
  },
  {
    "text": "these dis disparate clusters are",
    "start": "1104919",
    "end": "1106440"
  },
  {
    "text": "handling the workloads and so at this",
    "start": "1106440",
    "end": "1107840"
  },
  {
    "text": "point we Ute a a call against the model",
    "start": "1107840",
    "end": "1111600"
  },
  {
    "text": "ask it a question and it",
    "start": "1111600",
    "end": "1113960"
  },
  {
    "text": "responds so now what's happening with",
    "start": "1113960",
    "end": "1116080"
  },
  {
    "text": "our clusters well we see that the three",
    "start": "1116080",
    "end": "1118240"
  },
  {
    "text": "CPU clusters are now active they're",
    "start": "1118240",
    "end": "1120000"
  },
  {
    "text": "ready to take responses so they're no",
    "start": "1120000",
    "end": "1122120"
  },
  {
    "text": "longer in standby they're no longer idle",
    "start": "1122120",
    "end": "1124159"
  },
  {
    "text": "and one of the two GP clusters is also",
    "start": "1124159",
    "end": "1126280"
  },
  {
    "text": "busy uh ready to serve when requests",
    "start": "1126280",
    "end": "1129080"
  },
  {
    "text": "come",
    "start": "1129080",
    "end": "1130400"
  },
  {
    "text": "in okay now we're going to deploy",
    "start": "1130400",
    "end": "1132760"
  },
  {
    "text": "version two of the same model so in",
    "start": "1132760",
    "end": "1135240"
  },
  {
    "text": "version two we're going to use a",
    "start": "1135240",
    "end": "1136320"
  },
  {
    "text": "different Nam space so that we can",
    "start": "1136320",
    "end": "1137880"
  },
  {
    "text": "separate the two",
    "start": "1137880",
    "end": "1139440"
  },
  {
    "text": "um models in terms of the resources",
    "start": "1139440",
    "end": "1141360"
  },
  {
    "text": "they're using we're not going to",
    "start": "1141360",
    "end": "1143440"
  },
  {
    "text": "populate uh the vector database this",
    "start": "1143440",
    "end": "1145640"
  },
  {
    "text": "time we want version two to use the same",
    "start": "1145640",
    "end": "1147360"
  },
  {
    "text": "version of the vector database that",
    "start": "1147360",
    "end": "1148720"
  },
  {
    "text": "version one did um so very similar uh",
    "start": "1148720",
    "end": "1152400"
  },
  {
    "text": "multiple steps they're left them out for",
    "start": "1152400",
    "end": "1154640"
  },
  {
    "text": "brevity here but again we get the three",
    "start": "1154640",
    "end": "1156840"
  },
  {
    "text": "addresses for this time for version two",
    "start": "1156840",
    "end": "1159640"
  },
  {
    "text": "and we execute a command against version",
    "start": "1159640",
    "end": "1161559"
  },
  {
    "text": "two of the model and we see that it",
    "start": "1161559",
    "end": "1163440"
  },
  {
    "text": "responds with the answer we",
    "start": "1163440",
    "end": "1166159"
  },
  {
    "text": "expect uh so at this point um five of",
    "start": "1166159",
    "end": "1169480"
  },
  {
    "text": "the six clusters are active um the two",
    "start": "1169480",
    "end": "1172039"
  },
  {
    "text": "GPU clusters are both active um each of",
    "start": "1172039",
    "end": "1175120"
  },
  {
    "text": "them having one GPU so each of them",
    "start": "1175120",
    "end": "1177080"
  },
  {
    "text": "running a separate copy of the llm",
    "start": "1177080",
    "end": "1179320"
  },
  {
    "text": "serving uh model and then the three",
    "start": "1179320",
    "end": "1182120"
  },
  {
    "text": "front ends continue to be",
    "start": "1182120",
    "end": "1184039"
  },
  {
    "text": "active so now we're ready to let's say",
    "start": "1184039",
    "end": "1186799"
  },
  {
    "text": "we've done a lot of validation we decide",
    "start": "1186799",
    "end": "1189159"
  },
  {
    "text": "that version two is really good it's",
    "start": "1189159",
    "end": "1190840"
  },
  {
    "text": "better than version one we're willing to",
    "start": "1190840",
    "end": "1192679"
  },
  {
    "text": "now retire version one and as we say the",
    "start": "1192679",
    "end": "1195760"
  },
  {
    "text": "simple answer to that is to remove the d",
    "start": "1195760",
    "end": "1197919"
  },
  {
    "text": "space but behind the scenes there's a",
    "start": "1197919",
    "end": "1199880"
  },
  {
    "text": "lot of work to remove that namespace",
    "start": "1199880",
    "end": "1201760"
  },
  {
    "text": "because basically the Nova control plane",
    "start": "1201760",
    "end": "1204000"
  },
  {
    "text": "has to make sure that all of the",
    "start": "1204000",
    "end": "1205120"
  },
  {
    "text": "workload clusters uh remove the Nam",
    "start": "1205120",
    "end": "1207400"
  },
  {
    "text": "space so a lot of work goes on behind",
    "start": "1207400",
    "end": "1209520"
  },
  {
    "text": "the scenes but from the standpoint of EU",
    "start": "1209520",
    "end": "1211840"
  },
  {
    "text": "the person that's administering the",
    "start": "1211840",
    "end": "1213559"
  },
  {
    "text": "system it's a very simple operation uh",
    "start": "1213559",
    "end": "1216120"
  },
  {
    "text": "so now we're back to one of the GPU",
    "start": "1216120",
    "end": "1217919"
  },
  {
    "text": "clusters being idle um and uh we're done",
    "start": "1217919",
    "end": "1222200"
  },
  {
    "text": "so that's example one of things you",
    "start": "1222200",
    "end": "1224200"
  },
  {
    "text": "would do in production you could imagine",
    "start": "1224200",
    "end": "1225919"
  },
  {
    "text": "you have multiple models they all have",
    "start": "1225919",
    "end": "1227640"
  },
  {
    "text": "multiple versions so you would have",
    "start": "1227640",
    "end": "1229000"
  },
  {
    "text": "scaled up version of what we just saw uh",
    "start": "1229000",
    "end": "1231880"
  },
  {
    "text": "the second example has to do with what",
    "start": "1231880",
    "end": "1233559"
  },
  {
    "text": "if I sometimes want more resources than",
    "start": "1233559",
    "end": "1236240"
  },
  {
    "text": "I have statically so in the second",
    "start": "1236240",
    "end": "1238799"
  },
  {
    "text": "example we have version one and version",
    "start": "1238799",
    "end": "1240880"
  },
  {
    "text": "two of the model but what if we wanted",
    "start": "1240880",
    "end": "1242440"
  },
  {
    "text": "version three and my artificial setup I",
    "start": "1242440",
    "end": "1245640"
  },
  {
    "text": "can't run a version three of the model",
    "start": "1245640",
    "end": "1247320"
  },
  {
    "text": "because I don't have enough GPU",
    "start": "1247320",
    "end": "1248679"
  },
  {
    "text": "resources to do that I just have you",
    "start": "1248679",
    "end": "1251080"
  },
  {
    "text": "know one a0g and one cluster and one",
    "start": "1251080",
    "end": "1253240"
  },
  {
    "text": "atng in the other cluster so I can't",
    "start": "1253240",
    "end": "1255159"
  },
  {
    "text": "have three copies of my model running at",
    "start": "1255159",
    "end": "1257000"
  },
  {
    "text": "the same time but",
    "start": "1257000",
    "end": "1259200"
  },
  {
    "text": "uh the Nova cluster scheduler recognizes",
    "start": "1259200",
    "end": "1262320"
  },
  {
    "text": "if a Target cluster that it's managing a",
    "start": "1262320",
    "end": "1265159"
  },
  {
    "text": "Target workload cluster has an",
    "start": "1265159",
    "end": "1266400"
  },
  {
    "text": "autoscaler running in it so if the the",
    "start": "1266400",
    "end": "1269600"
  },
  {
    "text": "auto scalers it currently recognizes are",
    "start": "1269600",
    "end": "1271559"
  },
  {
    "text": "the kubernetes autoscaler and the aloto",
    "start": "1271559",
    "end": "1274360"
  },
  {
    "text": "Luna cluster autoscaler so if it can't",
    "start": "1274360",
    "end": "1277320"
  },
  {
    "text": "find static resources to handle the",
    "start": "1277320",
    "end": "1279440"
  },
  {
    "text": "workload that it wants to deploy it",
    "start": "1279440",
    "end": "1281559"
  },
  {
    "text": "sends the workload to a workload cluster",
    "start": "1281559",
    "end": "1284679"
  },
  {
    "text": "that has an autoscaler with the idea",
    "start": "1284679",
    "end": "1286279"
  },
  {
    "text": "that that autoscaler will be able to",
    "start": "1286279",
    "end": "1288000"
  },
  {
    "text": "handle the work",
    "start": "1288000",
    "end": "1289559"
  },
  {
    "text": "workload so here we set up the Luna uh",
    "start": "1289559",
    "end": "1293279"
  },
  {
    "text": "cluster autoscaler in one of the two GPU",
    "start": "1293279",
    "end": "1295799"
  },
  {
    "text": "clusters and model V1 and model V2 uh",
    "start": "1295799",
    "end": "1300080"
  },
  {
    "text": "are both done just as you previously saw",
    "start": "1300080",
    "end": "1303720"
  },
  {
    "text": "but when we get ready to run model V3 it",
    "start": "1303720",
    "end": "1305760"
  },
  {
    "text": "just sits there pending because it can't",
    "start": "1305760",
    "end": "1307559"
  },
  {
    "text": "get the resources it needs and so we",
    "start": "1307559",
    "end": "1310080"
  },
  {
    "text": "because we care a lot about model V3 and",
    "start": "1310080",
    "end": "1313120"
  },
  {
    "text": "we're willing to pay extra for it we",
    "start": "1313120",
    "end": "1315360"
  },
  {
    "text": "configure it to let it uh be placed by",
    "start": "1315360",
    "end": "1317480"
  },
  {
    "text": "the autoscaler and so the autoscaler",
    "start": "1317480",
    "end": "1320159"
  },
  {
    "text": "then uh scales up one of that cluster uh",
    "start": "1320159",
    "end": "1323799"
  },
  {
    "text": "the East uh two cluster and we can now",
    "start": "1323799",
    "end": "1326840"
  },
  {
    "text": "run version three so you might be",
    "start": "1326840",
    "end": "1329200"
  },
  {
    "text": "thinking well hey that's pretty cool but",
    "start": "1329200",
    "end": "1331200"
  },
  {
    "text": "what about when I scale down by retiring",
    "start": "1331200",
    "end": "1334360"
  },
  {
    "text": "version one or version two what should",
    "start": "1334360",
    "end": "1336320"
  },
  {
    "text": "happen with version three um should it",
    "start": "1336320",
    "end": "1339320"
  },
  {
    "text": "just sit there the answer is what do you",
    "start": "1339320",
    "end": "1341440"
  },
  {
    "text": "want to have happen so some people would",
    "start": "1341440",
    "end": "1343720"
  },
  {
    "text": "say I want version three where it is on",
    "start": "1343720",
    "end": "1345919"
  },
  {
    "text": "the dynamic resources because I don't",
    "start": "1345919",
    "end": "1347679"
  },
  {
    "text": "want to to disrupt anything and that's",
    "start": "1347679",
    "end": "1350400"
  },
  {
    "text": "fine and that would happen by default",
    "start": "1350400",
    "end": "1352760"
  },
  {
    "text": "but if you would like rescheduling",
    "start": "1352760",
    "end": "1354679"
  },
  {
    "text": "because you've now freed up resources",
    "start": "1354679",
    "end": "1357000"
  },
  {
    "text": "than your static area you can uh",
    "start": "1357000",
    "end": "1359799"
  },
  {
    "text": "engender a change to the configuration",
    "start": "1359799",
    "end": "1362640"
  },
  {
    "text": "and let uh the Nova control plane",
    "start": "1362640",
    "end": "1364919"
  },
  {
    "text": "replace that workload uh when this",
    "start": "1364919",
    "end": "1367279"
  },
  {
    "text": "happens so you can basically set up a a",
    "start": "1367279",
    "end": "1369440"
  },
  {
    "text": "system to do",
    "start": "1369440",
    "end": "1371080"
  },
  {
    "text": "that so basically we've shown you an",
    "start": "1371080",
    "end": "1373480"
  },
  {
    "text": "easy and efficient approach to",
    "start": "1373480",
    "end": "1374919"
  },
  {
    "text": "self-hosting production llm rag models",
    "start": "1374919",
    "end": "1377720"
  },
  {
    "text": "that combines multiple Cloud kubernetes",
    "start": "1377720",
    "end": "1379960"
  },
  {
    "text": "clusters for their aggregated scalable",
    "start": "1379960",
    "end": "1382400"
  },
  {
    "text": "resource management and a policy-based",
    "start": "1382400",
    "end": "1384799"
  },
  {
    "text": "resource aware cluster scheduler that is",
    "start": "1384799",
    "end": "1387799"
  },
  {
    "text": "Nova to manage multiple Cloud kubernetes",
    "start": "1387799",
    "end": "1390679"
  },
  {
    "text": "clusters Nova supports a variety of",
    "start": "1390679",
    "end": "1392840"
  },
  {
    "text": "different policies that uh that provide",
    "start": "1392840",
    "end": "1395320"
  },
  {
    "text": "the functionality you need to get this",
    "start": "1395320",
    "end": "1396960"
  },
  {
    "text": "done it can optionally place clusters in",
    "start": "1396960",
    "end": "1399480"
  },
  {
    "text": "standby if they're lightly used and",
    "start": "1399480",
    "end": "1401200"
  },
  {
    "text": "you're interested in that and it could",
    "start": "1401200",
    "end": "1403240"
  },
  {
    "text": "interoperate with the cluster autoscaler",
    "start": "1403240",
    "end": "1405360"
  },
  {
    "text": "if you're interested in that and so we",
    "start": "1405360",
    "end": "1407559"
  },
  {
    "text": "we presented llm plus mod uh rag model",
    "start": "1407559",
    "end": "1410840"
  },
  {
    "text": "roll out and retire uh using this",
    "start": "1410840",
    "end": "1413240"
  },
  {
    "text": "approach uh so thank you very much uh",
    "start": "1413240",
    "end": "1416200"
  },
  {
    "text": "please great our talk here and uh give",
    "start": "1416200",
    "end": "1418960"
  },
  {
    "text": "the software a try we have all of the",
    "start": "1418960",
    "end": "1421679"
  },
  {
    "text": "scripts that we used uh in a repo and we",
    "start": "1421679",
    "end": "1424480"
  },
  {
    "text": "have the ability to uh freely try both",
    "start": "1424480",
    "end": "1427520"
  },
  {
    "text": "uh Nova and Luna if you'd like wa thanks",
    "start": "1427520",
    "end": "1430240"
  },
  {
    "text": "thanks very much thanks for your uh",
    "start": "1430240",
    "end": "1432450"
  },
  {
    "text": "[Applause]",
    "start": "1432450",
    "end": "1437440"
  },
  {
    "text": "time",
    "start": "1437440",
    "end": "1440440"
  },
  {
    "text": "do we have time for questions question",
    "start": "1445520",
    "end": "1448320"
  },
  {
    "text": "yeah I don't if there is",
    "start": "1448320",
    "end": "1451400"
  },
  {
    "text": "any I think we've got like a minute or",
    "start": "1451400",
    "end": "1453520"
  },
  {
    "text": "so a minute",
    "start": "1453520",
    "end": "1456279"
  },
  {
    "text": "yeah back",
    "start": "1456400",
    "end": "1459679"
  },
  {
    "text": "there good job thank you you",
    "start": "1460679",
    "end": "1466000"
  },
  {
    "text": "too",
    "start": "1467360",
    "end": "1470360"
  },
  {
    "text": "I can't hear word you",
    "start": "1470880",
    "end": "1473760"
  },
  {
    "text": "saying I think that might di there we go",
    "start": "1474600",
    "end": "1477600"
  },
  {
    "text": "so question um you've got GPU CPU can",
    "start": "1477600",
    "end": "1481320"
  },
  {
    "text": "you define lots of other spectrums of",
    "start": "1481320",
    "end": "1484399"
  },
  {
    "text": "stuff because Azure just has different",
    "start": "1484399",
    "end": "1486360"
  },
  {
    "text": "stuff to eks and Google cloud and can",
    "start": "1486360",
    "end": "1490360"
  },
  {
    "text": "you define where youve depending on what",
    "start": "1490360",
    "end": "1493120"
  },
  {
    "text": "resources you want which Cloud they",
    "start": "1493120",
    "end": "1495399"
  },
  {
    "text": "appear in because they're",
    "start": "1495399",
    "end": "1497159"
  },
  {
    "text": "available in including services so like",
    "start": "1497159",
    "end": "1500200"
  },
  {
    "text": "I've got this service but it needs a one",
    "start": "1500200",
    "end": "1503279"
  },
  {
    "text": "of the cloud Pacific like uh features",
    "start": "1503279",
    "end": "1507720"
  },
  {
    "text": "like I don't know Neptune or something",
    "start": "1507720",
    "end": "1509320"
  },
  {
    "text": "that's running in uh Amazon can you",
    "start": "1509320",
    "end": "1512520"
  },
  {
    "text": "define that that workload has those sort",
    "start": "1512520",
    "end": "1514640"
  },
  {
    "text": "of requirements so it needs to go to eks",
    "start": "1514640",
    "end": "1517960"
  },
  {
    "text": "not to AKs for example right a very good",
    "start": "1517960",
    "end": "1520799"
  },
  {
    "text": "question so with respect to the things",
    "start": "1520799",
    "end": "1522720"
  },
  {
    "text": "you can Define as as part of the policy",
    "start": "1522720",
    "end": "1525360"
  },
  {
    "text": "we sort of put in a bunch of stuff built",
    "start": "1525360",
    "end": "1527720"
  },
  {
    "text": "in you know like you said CPU GPU memory",
    "start": "1527720",
    "end": "1530399"
  },
  {
    "text": "and so on and then we put in the ability",
    "start": "1530399",
    "end": "1532720"
  },
  {
    "text": "to label things and so you saw me",
    "start": "1532720",
    "end": "1534520"
  },
  {
    "text": "labeling the three CPU clusters that I",
    "start": "1534520",
    "end": "1537120"
  },
  {
    "text": "wanted in the three GEOS uh so that",
    "start": "1537120",
    "end": "1539440"
  },
  {
    "text": "those workloads would only go there so I",
    "start": "1539440",
    "end": "1541320"
  },
  {
    "text": "would say you'd have to label the I mean",
    "start": "1541320",
    "end": "1543159"
  },
  {
    "text": "at least with the current system you",
    "start": "1543159",
    "end": "1544440"
  },
  {
    "text": "would label um some of the Clusters that",
    "start": "1544440",
    "end": "1547039"
  },
  {
    "text": "had these specific things um and then",
    "start": "1547039",
    "end": "1549120"
  },
  {
    "text": "make sure the policy that you know used",
    "start": "1549120",
    "end": "1551919"
  },
  {
    "text": "that label was used for the workloads",
    "start": "1551919",
    "end": "1554360"
  },
  {
    "text": "that had that constraint I think that's",
    "start": "1554360",
    "end": "1555840"
  },
  {
    "text": "the basic so that you know we don't have",
    "start": "1555840",
    "end": "1558399"
  },
  {
    "text": "to keep uh inventing an infinite number",
    "start": "1558399",
    "end": "1560679"
  },
  {
    "text": "of configurations but it kind of lets",
    "start": "1560679",
    "end": "1562679"
  },
  {
    "text": "you label things uh as you need",
    "start": "1562679",
    "end": "1566440"
  },
  {
    "text": "to any",
    "start": "1570399",
    "end": "1573480"
  },
  {
    "text": "others thank you right thank you thank",
    "start": "1573480",
    "end": "1577760"
  },
  {
    "text": "you",
    "start": "1579720",
    "end": "1582720"
  }
]
[
  {
    "text": "good morning uh my name is scha I'm a",
    "start": "1040",
    "end": "3679"
  },
  {
    "text": "computer science graduate student at",
    "start": "3679",
    "end": "5799"
  },
  {
    "text": "Colombia and uh today I'll be speaking",
    "start": "5799",
    "end": "8200"
  },
  {
    "text": "about harnessing generative AI without",
    "start": "8200",
    "end": "10200"
  },
  {
    "text": "making a",
    "start": "10200",
    "end": "11599"
  },
  {
    "text": "forar a little bit about me I worked uh",
    "start": "11599",
    "end": "15000"
  },
  {
    "text": "as an SD at Amazon for 2 years prior to",
    "start": "15000",
    "end": "17359"
  },
  {
    "text": "Colombia and most recently I turned at",
    "start": "17359",
    "end": "19920"
  },
  {
    "text": "Caston by VH for 3 months over the",
    "start": "19920",
    "end": "21800"
  },
  {
    "text": "summer which is where I came across this",
    "start": "21800",
    "end": "24359"
  },
  {
    "text": "problem statement which is to generate",
    "start": "24359",
    "end": "26760"
  },
  {
    "text": "canister blueprints by prompt without",
    "start": "26760",
    "end": "29039"
  },
  {
    "text": "exposing propriety data kind of like a",
    "start": "29039",
    "end": "31199"
  },
  {
    "text": "GitHub co-pilot experience canister",
    "start": "31199",
    "end": "33640"
  },
  {
    "text": "blueprints are basically yaml",
    "start": "33640",
    "end": "35520"
  },
  {
    "text": "configurations used to define backup",
    "start": "35520",
    "end": "38040"
  },
  {
    "text": "restore and delete workflows for",
    "start": "38040",
    "end": "39960"
  },
  {
    "text": "multiple",
    "start": "39960",
    "end": "41160"
  },
  {
    "text": "databases we all know GitHub co-pilot",
    "start": "41160",
    "end": "43760"
  },
  {
    "text": "our handy AI pair programmer which",
    "start": "43760",
    "end": "46280"
  },
  {
    "text": "generates code based on",
    "start": "46280",
    "end": "48320"
  },
  {
    "text": "prompt but GitHub copilot uploads our",
    "start": "48320",
    "end": "51399"
  },
  {
    "text": "code base which is the IP of a company",
    "start": "51399",
    "end": "54879"
  },
  {
    "text": "uh as context of the GitHub co-pilot",
    "start": "54879",
    "end": "56760"
  },
  {
    "text": "service which it needs for generating",
    "start": "56760",
    "end": "58920"
  },
  {
    "text": "recommendations",
    "start": "58920",
    "end": "60760"
  },
  {
    "text": "this is why I chose for pilot which is",
    "start": "60760",
    "end": "63320"
  },
  {
    "text": "an open-source project which provides",
    "start": "63320",
    "end": "65239"
  },
  {
    "text": "the components to build a locally hosted",
    "start": "65239",
    "end": "67960"
  },
  {
    "text": "alternative to get Hub",
    "start": "67960",
    "end": "69720"
  },
  {
    "text": "copilot this uses an Nvidia inference",
    "start": "69720",
    "end": "72600"
  },
  {
    "text": "server at the back end to accelerate",
    "start": "72600",
    "end": "75200"
  },
  {
    "text": "inference and it's required for ML at",
    "start": "75200",
    "end": "77520"
  },
  {
    "text": "scale and that in turn uses a custom",
    "start": "77520",
    "end": "80479"
  },
  {
    "text": "faster Transformer backend which is",
    "start": "80479",
    "end": "82880"
  },
  {
    "text": "specific for llms to in provide",
    "start": "82880",
    "end": "85680"
  },
  {
    "text": "inference like distributed Manor using",
    "start": "85680",
    "end": "88400"
  },
  {
    "text": "something called Model parallelism where",
    "start": "88400",
    "end": "90439"
  },
  {
    "text": "it basically splits the entire model",
    "start": "90439",
    "end": "92399"
  },
  {
    "text": "into multiple different parts and",
    "start": "92399",
    "end": "94280"
  },
  {
    "text": "predicts independently stitching the",
    "start": "94280",
    "end": "96560"
  },
  {
    "text": "output together at the end this is the",
    "start": "96560",
    "end": "99079"
  },
  {
    "text": "framework I had in mind while trying to",
    "start": "99079",
    "end": "101320"
  },
  {
    "text": "build this application and we will see",
    "start": "101320",
    "end": "104119"
  },
  {
    "text": "how to build this part by part I just",
    "start": "104119",
    "end": "106840"
  },
  {
    "text": "plugged in the client and the server",
    "start": "106840",
    "end": "108560"
  },
  {
    "text": "according to my application in my case",
    "start": "108560",
    "end": "111799"
  },
  {
    "text": "the client was an IDE because we wanted",
    "start": "111799",
    "end": "114320"
  },
  {
    "text": "to see the code generated in front of us",
    "start": "114320",
    "end": "116840"
  },
  {
    "text": "by",
    "start": "116840",
    "end": "117719"
  },
  {
    "text": "prompt and the first step was to build",
    "start": "117719",
    "end": "120240"
  },
  {
    "text": "the server itself which is what we saw",
    "start": "120240",
    "end": "122039"
  },
  {
    "text": "for pilot so some of the considerations",
    "start": "122039",
    "end": "124880"
  },
  {
    "text": "I thought about were how and where to",
    "start": "124880",
    "end": "127039"
  },
  {
    "text": "host This Server the hardware and Os",
    "start": "127039",
    "end": "129479"
  },
  {
    "text": "requirements once I decide where I can",
    "start": "129479",
    "end": "131959"
  },
  {
    "text": "host",
    "start": "131959",
    "end": "133120"
  },
  {
    "text": "it and then to connect to this server",
    "start": "133120",
    "end": "136120"
  },
  {
    "text": "some of the considerations I thought",
    "start": "136120",
    "end": "137560"
  },
  {
    "text": "about were how to ensure that only an",
    "start": "137560",
    "end": "139599"
  },
  {
    "text": "authorized client can connect to the",
    "start": "139599",
    "end": "141319"
  },
  {
    "text": "server how to ensure efficient",
    "start": "141319",
    "end": "143239"
  },
  {
    "text": "utilization of the server and how to",
    "start": "143239",
    "end": "145519"
  },
  {
    "text": "ensure availability of the server for",
    "start": "145519",
    "end": "147319"
  },
  {
    "text": "multiple clients connecting to it",
    "start": "147319",
    "end": "151120"
  },
  {
    "text": "The Next Step was to gen gen set up the",
    "start": "151120",
    "end": "153760"
  },
  {
    "text": "client itself and the obvious question",
    "start": "153760",
    "end": "156000"
  },
  {
    "text": "is which client to choose so this",
    "start": "156000",
    "end": "158080"
  },
  {
    "text": "depends on the end users and the",
    "start": "158080",
    "end": "160000"
  },
  {
    "text": "application and in my case I chose an ID",
    "start": "160000",
    "end": "162800"
  },
  {
    "text": "just because the users are",
    "start": "162800",
    "end": "164879"
  },
  {
    "text": "developers another very important",
    "start": "164879",
    "end": "166800"
  },
  {
    "text": "question is how to ensure proprietary",
    "start": "166800",
    "end": "168440"
  },
  {
    "text": "code is not leaked in the process in my",
    "start": "168440",
    "end": "171319"
  },
  {
    "text": "case I downloaded the GitHub copilot",
    "start": "171319",
    "end": "174120"
  },
  {
    "text": "extension and all this was automated and",
    "start": "174120",
    "end": "176760"
  },
  {
    "text": "configured it to point to my local",
    "start": "176760",
    "end": "178920"
  },
  {
    "text": "server uh basically the server hosted on",
    "start": "178920",
    "end": "182040"
  },
  {
    "text": "the cloud before even installing it into",
    "start": "182040",
    "end": "184080"
  },
  {
    "text": "the ID so that it doesn't consume our",
    "start": "184080",
    "end": "186000"
  },
  {
    "text": "code base the final step is the model",
    "start": "186000",
    "end": "188640"
  },
  {
    "text": "itself and for this one question to ask",
    "start": "188640",
    "end": "191480"
  },
  {
    "text": "is what are the existing models",
    "start": "191480",
    "end": "192959"
  },
  {
    "text": "available in the marketplace which can",
    "start": "192959",
    "end": "194519"
  },
  {
    "text": "do this for us and then the next step",
    "start": "194519",
    "end": "197159"
  },
  {
    "text": "would be to evaluate which among these",
    "start": "197159",
    "end": "198920"
  },
  {
    "text": "models gives us the best",
    "start": "198920",
    "end": "201319"
  },
  {
    "text": "accuracy after evaluating if nothing is",
    "start": "201319",
    "end": "204080"
  },
  {
    "text": "up to the mark then we can go ahead with",
    "start": "204080",
    "end": "206480"
  },
  {
    "text": "fine-tuning the model so fine-tuning is",
    "start": "206480",
    "end": "209920"
  },
  {
    "text": "basically the process of adapting a",
    "start": "209920",
    "end": "211640"
  },
  {
    "text": "pre-trained model to fit custom data",
    "start": "211640",
    "end": "214319"
  },
  {
    "text": "what happens is the last few layers of",
    "start": "214319",
    "end": "216280"
  },
  {
    "text": "the model is modified to be able to",
    "start": "216280",
    "end": "219040"
  },
  {
    "text": "generate just the custom data that we",
    "start": "219040",
    "end": "221319"
  },
  {
    "text": "want and this is much better than",
    "start": "221319",
    "end": "223640"
  },
  {
    "text": "actually training a model from scratch",
    "start": "223640",
    "end": "226599"
  },
  {
    "text": "because it takes much less time and data",
    "start": "226599",
    "end": "229720"
  },
  {
    "text": "to do so because the pre-trained model",
    "start": "229720",
    "end": "231560"
  },
  {
    "text": "itself has a lot of knowledge about",
    "start": "231560",
    "end": "233480"
  },
  {
    "text": "language and the domain at",
    "start": "233480",
    "end": "236120"
  },
  {
    "text": "large two important considerations while",
    "start": "236120",
    "end": "239000"
  },
  {
    "text": "fine tuning the model and these are the",
    "start": "239000",
    "end": "240560"
  },
  {
    "text": "steps to do so is in terms of the data a",
    "start": "240560",
    "end": "244000"
  },
  {
    "text": "what format should the data be in so",
    "start": "244000",
    "end": "245840"
  },
  {
    "text": "that the model will be able to accept",
    "start": "245840",
    "end": "247360"
  },
  {
    "text": "and understand it and for that we need",
    "start": "247360",
    "end": "249319"
  },
  {
    "text": "to look at the way the model itself was",
    "start": "249319",
    "end": "251599"
  },
  {
    "text": "trained and the second point is do we",
    "start": "251599",
    "end": "254120"
  },
  {
    "text": "need data augmentation and this depends",
    "start": "254120",
    "end": "256600"
  },
  {
    "text": "on the number of samples data samples",
    "start": "256600",
    "end": "258479"
  },
  {
    "text": "that we have with us of the custom data",
    "start": "258479",
    "end": "261120"
  },
  {
    "text": "in my case I only had 11 sample",
    "start": "261120",
    "end": "263199"
  },
  {
    "text": "blueprints which was way too less for",
    "start": "263199",
    "end": "264880"
  },
  {
    "text": "the model to learn so I proceeded with",
    "start": "264880",
    "end": "267840"
  },
  {
    "text": "data augmentation to synthetically",
    "start": "267840",
    "end": "269919"
  },
  {
    "text": "generate data for me uh and I did this",
    "start": "269919",
    "end": "272520"
  },
  {
    "text": "in these are some of the examples in the",
    "start": "272520",
    "end": "274320"
  },
  {
    "text": "way I did it basically Generate random",
    "start": "274320",
    "end": "276120"
  },
  {
    "text": "typos include random words delete random",
    "start": "276120",
    "end": "279120"
  },
  {
    "text": "words and from 11 samples we now had",
    "start": "279120",
    "end": "281880"
  },
  {
    "text": "nearly 2,000 samples which was split in",
    "start": "281880",
    "end": "285639"
  },
  {
    "text": "at random in an 80% 20% split to create",
    "start": "285639",
    "end": "288960"
  },
  {
    "text": "a train and validation data set which",
    "start": "288960",
    "end": "290960"
  },
  {
    "text": "was used for",
    "start": "290960",
    "end": "292400"
  },
  {
    "text": "training the final results and although",
    "start": "292400",
    "end": "294960"
  },
  {
    "text": "we don't have time today to show a real",
    "start": "294960",
    "end": "297039"
  },
  {
    "text": "demo was that the model recognized IED",
    "start": "297039",
    "end": "299880"
  },
  {
    "text": "canister blueprints by prompt and",
    "start": "299880",
    "end": "301840"
  },
  {
    "text": "generated results it was able to",
    "start": "301840",
    "end": "303919"
  },
  {
    "text": "differentiate between backing various",
    "start": "303919",
    "end": "306039"
  },
  {
    "text": "different databases and provided",
    "start": "306039",
    "end": "307800"
  },
  {
    "text": "different yaml configurations",
    "start": "307800",
    "end": "309880"
  },
  {
    "text": "accordingly I guess the key takeaways I",
    "start": "309880",
    "end": "312120"
  },
  {
    "text": "would want to leave with you is we can",
    "start": "312120",
    "end": "313479"
  },
  {
    "text": "apply a similar framework with",
    "start": "313479",
    "end": "315520"
  },
  {
    "text": "considerations at every stage to build",
    "start": "315520",
    "end": "317800"
  },
  {
    "text": "almost any AI application and this way",
    "start": "317800",
    "end": "320280"
  },
  {
    "text": "we can use generative AI in a secure way",
    "start": "320280",
    "end": "322600"
  },
  {
    "text": "without compromising proprietary data I",
    "start": "322600",
    "end": "325639"
  },
  {
    "text": "encourage the community to take the",
    "start": "325639",
    "end": "327400"
  },
  {
    "text": "plunge harness the power of generator Ai",
    "start": "327400",
    "end": "330000"
  },
  {
    "text": "and enhance your Cloud native",
    "start": "330000",
    "end": "331479"
  },
  {
    "text": "applications without losing competitive",
    "start": "331479",
    "end": "333880"
  },
  {
    "text": "Advantage you I know that was a lot to",
    "start": "333880",
    "end": "336000"
  },
  {
    "text": "take in in 5 minutes but feel free to",
    "start": "336000",
    "end": "338479"
  },
  {
    "text": "reach out to me after this session if",
    "start": "338479",
    "end": "339960"
  },
  {
    "text": "you have any questions any suggestions",
    "start": "339960",
    "end": "342479"
  },
  {
    "text": "and please scan this QR code for um",
    "start": "342479",
    "end": "345800"
  },
  {
    "text": "feedback I'd love to hear feedback on",
    "start": "345800",
    "end": "347440"
  },
  {
    "text": "the talk thank you so",
    "start": "347440",
    "end": "350440"
  },
  {
    "text": "much all right thank you I suggest we",
    "start": "351319",
    "end": "355039"
  },
  {
    "text": "switch but while we switch maybe we can",
    "start": "355039",
    "end": "356880"
  },
  {
    "text": "take one question if there is one fora",
    "start": "356880",
    "end": "359080"
  },
  {
    "text": "if anyone one has one we we can try to",
    "start": "359080",
    "end": "361800"
  },
  {
    "text": "sneak it in while we switch the",
    "start": "361800",
    "end": "365120"
  },
  {
    "text": "laptops otherwise thanks a lot s thank",
    "start": "368560",
    "end": "371520"
  },
  {
    "text": "you",
    "start": "371520",
    "end": "374520"
  }
]
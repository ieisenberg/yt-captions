[
  {
    "text": "okay good morning uh thank you everyone for coming to my session so my session title is",
    "start": "520",
    "end": "8400"
  },
  {
    "text": "unlocking the power of kubernetes for AI so um to today I'll be discussing how we",
    "start": "8400",
    "end": "16560"
  },
  {
    "text": "can unlock the power of kubernetes when it comes to uh utilizing the kubernetes",
    "start": "16560",
    "end": "22039"
  },
  {
    "text": "environment for AI work Clow first of all I want to introduce myself so my",
    "start": "22039",
    "end": "28000"
  },
  {
    "text": "name is Brandon Kong I'm a working for Akamai Technologies I belong to compute",
    "start": "28000",
    "end": "35960"
  },
  {
    "text": "Technology Group for apj Market including the Great China Taiwan and Hong Kong and my position is a principal",
    "start": "35960",
    "end": "44160"
  },
  {
    "text": "Technical Solutions architect so I'm dealing with the cloud business as well as the kubernetes AI uh for AI so so",
    "start": "44160",
    "end": "54920"
  },
  {
    "text": "maybe you know that aama is famous for CDN and security companies but two years",
    "start": "54920",
    "end": "60559"
  },
  {
    "text": "ago we acquired the rote which was uh the cloud vender cloud service provider",
    "start": "60559",
    "end": "67240"
  },
  {
    "text": "the based in Philadelphia in the US so after that uh we started the cloud",
    "start": "67240",
    "end": "73520"
  },
  {
    "text": "business as well so first of all I believe that most",
    "start": "73520",
    "end": "78759"
  },
  {
    "text": "of you in this room do understand why KU is what are the benefits of the",
    "start": "78759",
    "end": "84799"
  },
  {
    "text": "kuet so back to the basic and remind so it gives us the the scalability the",
    "start": "84799",
    "end": "91840"
  },
  {
    "text": "portability so uh I think the the major reason why",
    "start": "91840",
    "end": "97560"
  },
  {
    "text": "we are using the commities for auto scaling for pot and nose and crusters",
    "start": "97560",
    "end": "105240"
  },
  {
    "text": "and portability it does not matter where the commities are located in so it can",
    "start": "105240",
    "end": "111360"
  },
  {
    "text": "be onr it can be a cloud or it can be in the hybrid",
    "start": "111360",
    "end": "117479"
  },
  {
    "text": "environment and thanks to it sa healing um for zero down time demand",
    "start": "117479",
    "end": "124719"
  },
  {
    "text": "applications so we can learn it on the communities and extens ability you know",
    "start": "124719",
    "end": "130000"
  },
  {
    "text": "that the kubernetes has kubernetes ecosystem has a lot of open sources so",
    "start": "130000",
    "end": "136319"
  },
  {
    "text": "in this cubicon event maybe you see the a lot of open sources regarding the quanties environment so so uh this",
    "start": "136319",
    "end": "145120"
  },
  {
    "text": "extensibility make us more flexible when we build the application on the",
    "start": "145120",
    "end": "150480"
  },
  {
    "text": "communties environment and resource optimization so I will consume the most",
    "start": "150480",
    "end": "156680"
  },
  {
    "text": "of my time on session about the resource optimization regarding the zpu so uh",
    "start": "156680",
    "end": "163159"
  },
  {
    "text": "it's very easy uh to manage the resource allocation for",
    "start": "163159",
    "end": "168879"
  },
  {
    "text": "CPU uh CPU sometime the disk the memory",
    "start": "168879",
    "end": "174000"
  },
  {
    "text": "so that's that's very important for application developers uh uh and then this give us",
    "start": "174000",
    "end": "183159"
  },
  {
    "text": "only focusing on the developments not thinking about the environment and automated the roll out",
    "start": "183159",
    "end": "189799"
  },
  {
    "text": "rad backs that give us the effective Dev of cicd 5iz and then just one command is",
    "start": "189799",
    "end": "196480"
  },
  {
    "text": "enough for roll out and roll back and service Discovery by using the kubernetes internal DNS external DNS by",
    "start": "196480",
    "end": "204959"
  },
  {
    "text": "Lo balancer that's provided by the csps and Etc so yeah",
    "start": "204959",
    "end": "212080"
  },
  {
    "text": "this these are the major reasons why we are using the kubernetes so thinking about the deploy",
    "start": "212080",
    "end": "219519"
  },
  {
    "text": "AI work on the kubernetes so it give us the D resource scaling the first and",
    "start": "219519",
    "end": "226760"
  },
  {
    "text": "then um when we have the burst work CL for example if we start a",
    "start": "226760",
    "end": "233760"
  },
  {
    "text": "training and then very faster the auto scaling",
    "start": "233760",
    "end": "238799"
  },
  {
    "text": "picture is the demand so and then another one the shared",
    "start": "238799",
    "end": "244439"
  },
  {
    "text": "infrastructure so we can have the multiple ques cluster for learning the AI workload and CPU and TPU management",
    "start": "244439",
    "end": "252920"
  },
  {
    "text": "the kuet is support scheduling and managing the specialized Hardwares like the CPU and T tpus optimizing their",
    "start": "252920",
    "end": "260880"
  },
  {
    "text": "utilization for AI workload so you can see",
    "start": "260880",
    "end": "266120"
  },
  {
    "text": "that the most of these factors are the common factors with the kubernetes the",
    "start": "266120",
    "end": "271320"
  },
  {
    "text": "benefits so that's why we deploy AI on the",
    "start": "271320",
    "end": "276600"
  },
  {
    "text": "kubernetes so uh let me skip very basic uh contents maybe you can read this",
    "start": "276960",
    "end": "285039"
  },
  {
    "text": "contents on my slide PDF attached to the schedule.com in this schedule but if in",
    "start": "285039",
    "end": "293280"
  },
  {
    "text": "briefs it gave us the resource managements as well as cost managements",
    "start": "293280",
    "end": "298400"
  },
  {
    "text": "so cost management is very important so most of KU cluster learning on croud",
    "start": "298400",
    "end": "306479"
  },
  {
    "text": "environment as you know so instead of the building your DIY workload uh we are",
    "start": "306479",
    "end": "313199"
  },
  {
    "text": "utilizing Cloud but the cost is the pain in the neck when we utilize the cloud",
    "start": "313199",
    "end": "320759"
  },
  {
    "text": "environments so thinking about if we use the GPU more than 2 hours 3 hours for AI",
    "start": "320759",
    "end": "327520"
  },
  {
    "text": "training so it'll give us on invoice over well $1,000",
    "start": "327520",
    "end": "333560"
  },
  {
    "text": "us so efficient Resource Management helps in controlling cost especially in",
    "start": "333560",
    "end": "340319"
  },
  {
    "text": "Cloud environment and sometimes we need the",
    "start": "340319",
    "end": "346120"
  },
  {
    "text": "CDs the custom resource definitions so you know that the communities allows the",
    "start": "346120",
    "end": "352280"
  },
  {
    "text": "creation of the CDs to support your own a specialized AI workload and",
    "start": "352280",
    "end": "358919"
  },
  {
    "text": "requirement and it's very easy to integrate with the AI Frameworks and tools which are very",
    "start": "358919",
    "end": "366039"
  },
  {
    "text": "famous in the Echo System for example the Frameworks like uh tensor Pro pter",
    "start": "366039",
    "end": "373880"
  },
  {
    "text": "and Commercial version of the mvidia Nemo and P these uh Frameworks and tools",
    "start": "373880",
    "end": "380680"
  },
  {
    "text": "uh they give us the sness deployment and operation of AR models and very low",
    "start": "380680",
    "end": "386520"
  },
  {
    "text": "running curve and then it does not ask the Earth to very high learning curve",
    "start": "386520",
    "end": "392919"
  },
  {
    "text": "and they easy and it give us agility as well so one research from the Leed hat",
    "start": "392919",
    "end": "400479"
  },
  {
    "text": "you can see that why organizations deploy workload on containers like the",
    "start": "400479",
    "end": "407120"
  },
  {
    "text": "kubernetes so 74% of the responders they say uh",
    "start": "407120",
    "end": "414919"
  },
  {
    "text": "because the Kum has the consistency across environment",
    "start": "414919",
    "end": "420599"
  },
  {
    "text": "it does not matter if we use the multioud hybrid Crow or private crowd",
    "start": "420599",
    "end": "427440"
  },
  {
    "text": "and Agility uh in the previous slide uh I mentioned that the Comm say the",
    "start": "427440",
    "end": "434560"
  },
  {
    "text": "agility so you know only developers they can focus on development of their",
    "start": "434560",
    "end": "442039"
  },
  {
    "text": "application and then infrastructure management team they build the communities and then they prepare",
    "start": "442039",
    "end": "448800"
  },
  {
    "text": "community resources and host level resources like CPU or CPU and",
    "start": "448800",
    "end": "454960"
  },
  {
    "text": "memory uh it give us the faster development and",
    "start": "454960",
    "end": "460240"
  },
  {
    "text": "Agility and the second reason is the portability from",
    "start": "460240",
    "end": "465599"
  },
  {
    "text": "the uh multiple environment like hybrid um the private or",
    "start": "465599",
    "end": "472680"
  },
  {
    "text": "something so this five reasons of the deploying AI on kubernetes actually",
    "start": "472680",
    "end": "480360"
  },
  {
    "text": "now you can find out that these factors are as same as the kubernetes uh just the",
    "start": "480360",
    "end": "488199"
  },
  {
    "text": "benefits it's the same so another research from the red",
    "start": "488199",
    "end": "495400"
  },
  {
    "text": "hat what kind of the types of workr are running on the kubernetes",
    "start": "495400",
    "end": "501440"
  },
  {
    "text": "Recently I was surprised that the number one software was the database actually I",
    "start": "501440",
    "end": "508720"
  },
  {
    "text": "didn't deploy the database or casing Solutions on the kubernetes uh due to",
    "start": "508720",
    "end": "514080"
  },
  {
    "text": "very high level of the synchronization data synchronization among the multiple",
    "start": "514080",
    "end": "520000"
  },
  {
    "text": "clusters but anyway the responders say that they make their database cures on",
    "start": "520000",
    "end": "527560"
  },
  {
    "text": "the kubernetes environment and AI mering softwares like",
    "start": "527560",
    "end": "533560"
  },
  {
    "text": "trior notebooks python tensor Pro pych",
    "start": "533560",
    "end": "539040"
  },
  {
    "text": "uh they are learning under kubernetes so 65% of responders they say uh kubernetes",
    "start": "539040",
    "end": "546519"
  },
  {
    "text": "environment is is their second PR one to deploy this kind of the",
    "start": "546519",
    "end": "552959"
  },
  {
    "text": "applications but if we thinking about the deploying AI on the Kum is the first",
    "start": "552959",
    "end": "558640"
  },
  {
    "text": "of all you have a question how uh we can decide the gpus what kind of models how",
    "start": "558640",
    "end": "565240"
  },
  {
    "text": "many gpus what kind of specs of the GPU we have to use first of all we need to clearly",
    "start": "565240",
    "end": "572320"
  },
  {
    "text": "understand the difference between CPU and GPU so you can see that the GPU has",
    "start": "572320",
    "end": "579440"
  },
  {
    "text": "some multiple cores than the CPU and then actually the you know the GPU is",
    "start": "579440",
    "end": "586079"
  },
  {
    "text": "for GPU was born for the graphics processing of R to graphics card and",
    "start": "586079",
    "end": "594079"
  },
  {
    "text": "it's a specialized microprocessor for computer chip originally design designed to accelerate",
    "start": "594079",
    "end": "600680"
  },
  {
    "text": "the graphics rendering but thanks to its uh the pism and simultaneous",
    "start": "600680",
    "end": "608600"
  },
  {
    "text": "multiprocessing uh now the gpus is more famous for learning helping the learning",
    "start": "608600",
    "end": "615000"
  },
  {
    "text": "AI work C on their machines so uh if you",
    "start": "615000",
    "end": "622519"
  },
  {
    "text": "decide to running a work C under kues uh first of all we have to thinking about",
    "start": "622519",
    "end": "628640"
  },
  {
    "text": "we have to con consider what kind of the gpus and how many and how much cost we",
    "start": "628640",
    "end": "635720"
  },
  {
    "text": "will we spend for the gpus so uh first of all we need to think",
    "start": "635720",
    "end": "645279"
  },
  {
    "text": "about the dynamic resource allocation and cost as well and multicloud",
    "start": "645279",
    "end": "650600"
  },
  {
    "text": "strategies so um even I'm from a cloud Bender so I don't say the Bender lock in",
    "start": "650600",
    "end": "658240"
  },
  {
    "text": "so multi cloud is strategy means that sometimes you need a type of a GPU B",
    "start": "658240",
    "end": "664320"
  },
  {
    "text": "type of GPU and if you think the different crowd vendors has different",
    "start": "664320",
    "end": "670959"
  },
  {
    "text": "cost model and if you think the their pricing model is more profitable to your",
    "start": "670959",
    "end": "677959"
  },
  {
    "text": "organization you can use the multic cloud for buying the GPU for your AI",
    "start": "677959",
    "end": "683320"
  },
  {
    "text": "work close and also we need to thinking about cost efficiency and how to dynamically",
    "start": "683320",
    "end": "690800"
  },
  {
    "text": "allocate the GPU resources you know uh if you buy uh GPU BM and it cost you uh",
    "start": "690800",
    "end": "699639"
  },
  {
    "text": "$200 for an hour for example it should not be",
    "start": "699639",
    "end": "705040"
  },
  {
    "text": "underutilized and it should not be over utilized as well so you know resource",
    "start": "705040",
    "end": "711399"
  },
  {
    "text": "allocation is very important considering the kubernetes uh utilizing the gpus on the",
    "start": "711399",
    "end": "717880"
  },
  {
    "text": "kubernetes environment and then after that we need to think",
    "start": "717880",
    "end": "724160"
  },
  {
    "text": "about what kind of device plugins and if your GPU Bender support you the device",
    "start": "724160",
    "end": "731160"
  },
  {
    "text": "plugin software and the guidelines how to use that and then GPU vendor integration is",
    "start": "731160",
    "end": "739120"
  },
  {
    "text": "also important so uh fortunately the qu has very strong integration with GPU",
    "start": "739120",
    "end": "746480"
  },
  {
    "text": "Technologies for example uh midia they provide kuum Ed device plugins and Cuda",
    "start": "746480",
    "end": "754440"
  },
  {
    "text": "so making it easier to leverage this debut on your",
    "start": "754440",
    "end": "759720"
  },
  {
    "text": "applications so uh this setup enhances the performance Insurance aidence resource",
    "start": "759720",
    "end": "767079"
  },
  {
    "text": "utilization as well this means that uh you don't need to think uh consider how",
    "start": "767079",
    "end": "772839"
  },
  {
    "text": "to allocate resource by your own but thanks to this device plugin software it",
    "start": "772839",
    "end": "779680"
  },
  {
    "text": "has a picture of monitoring the current GPU utilization and then they can share",
    "start": "779680",
    "end": "786519"
  },
  {
    "text": "your workload and even they can uh make some load",
    "start": "786519",
    "end": "792600"
  },
  {
    "text": "balancers for the GPU resource allocation so the integration of",
    "start": "792600",
    "end": "798360"
  },
  {
    "text": "automation advances GPU management and security features program makes kubernetes an IDE platform for deploying",
    "start": "798360",
    "end": "806839"
  },
  {
    "text": "and managing GPU accelerated AI",
    "start": "806839",
    "end": "811120"
  },
  {
    "text": "workload and device plugin software give us automatic GPU Discovery as well as",
    "start": "812600",
    "end": "819199"
  },
  {
    "text": "resource allocation and health checks as well so uh no matter what kind of the",
    "start": "819199",
    "end": "825720"
  },
  {
    "text": "GPU vage you are using it's it can be Nvidia AMD uh the most of the device",
    "start": "825720",
    "end": "831480"
  },
  {
    "text": "progan software has the pictures like that so not every",
    "start": "831480",
    "end": "839560"
  },
  {
    "text": "uh application is not ideal for the communities so thinking about small scale project or if you have very",
    "start": "839560",
    "end": "846560"
  },
  {
    "text": "limited resource for for example your organization has a just small budget for",
    "start": "846560",
    "end": "853279"
  },
  {
    "text": "having uh just one number of the GPU thinking about it you know it does mean",
    "start": "853279",
    "end": "859000"
  },
  {
    "text": "that kubernetes Autos scaling picture does not mean anything to you right it's",
    "start": "859000",
    "end": "864600"
  },
  {
    "text": "only one so uh no matter it is on the utilize or over utilize there is no",
    "start": "864600",
    "end": "872000"
  },
  {
    "text": "workr for that and how initial setup and learning curve",
    "start": "872000",
    "end": "877079"
  },
  {
    "text": "so um even the GPU vendors they provide us the plugin software and",
    "start": "877079",
    "end": "884440"
  },
  {
    "text": "liaries uh maybe many of uh you agree with me that the installation and",
    "start": "884440",
    "end": "892079"
  },
  {
    "text": "initializes is not easy So based on the operating system kind of operating",
    "start": "892079",
    "end": "898120"
  },
  {
    "text": "system you use it can be a Linux a Windows and anything so very different so I found out that I",
    "start": "898120",
    "end": "906880"
  },
  {
    "text": "was using the dean 11 and there was no",
    "start": "906880",
    "end": "911920"
  },
  {
    "text": "problem to install MDR the Cuda and liaries and container to Kit after I",
    "start": "911920",
    "end": "919079"
  },
  {
    "text": "change it to deian 12 version uh unexpected issues happen repeatedly and",
    "start": "919079",
    "end": "927399"
  },
  {
    "text": "then uh I I spend more than three hours to trouble",
    "start": "927399",
    "end": "932720"
  },
  {
    "text": "shoot the kind of the issue so real time of low relen",
    "start": "932720",
    "end": "938120"
  },
  {
    "text": "application so uh I will talk about how we can overcome this kind of the",
    "start": "938120",
    "end": "943639"
  },
  {
    "text": "requirement but the thing is that if you really need a real time your",
    "start": "943639",
    "end": "949839"
  },
  {
    "text": "roow latency applications uh kuet is not ideal or you",
    "start": "949839",
    "end": "955720"
  },
  {
    "text": "have to build your multiple kubernetes cluster in the world where your end",
    "start": "955720",
    "end": "961240"
  },
  {
    "text": "users are located in for example in Hong Kong in the US in Japan everywhere where",
    "start": "961240",
    "end": "970079"
  },
  {
    "text": "you are in so you know we know that Ed Computing is why",
    "start": "970079",
    "end": "978079"
  },
  {
    "text": "demanding this is because the indidual are also demanding they Wonder faster",
    "start": "978079",
    "end": "984160"
  },
  {
    "text": "response from their service and then you know",
    "start": "984160",
    "end": "990040"
  },
  {
    "text": "engagement ratio of the the service is um the one of the the most",
    "start": "990040",
    "end": "1000079"
  },
  {
    "text": "important factor is a performance metrics right the thinking about the web page the",
    "start": "1000079",
    "end": "1005720"
  },
  {
    "text": "latency so it's if the loading time is more than 3 second so many people Lees",
    "start": "1005720",
    "end": "1012199"
  },
  {
    "text": "the walmart.com the website it's uh reported by the Walmart research teams",
    "start": "1012199",
    "end": "1019680"
  },
  {
    "text": "so AI workload is the same so uh you know we have to be very tolerated when",
    "start": "1019680",
    "end": "1028798"
  },
  {
    "text": "we start the AI training you know if we have the good nice gpus it takes only",
    "start": "1028799",
    "end": "1034760"
  },
  {
    "text": "five a minute or sometime it consumes more than one hour so a real time rooll",
    "start": "1034760",
    "end": "1041600"
  },
  {
    "text": "application we need to thinking about not AI training but uh AI inference uh",
    "start": "1041600",
    "end": "1047839"
  },
  {
    "text": "is most the options but the kind of the applications okay move on so many",
    "start": "1047839",
    "end": "1056400"
  },
  {
    "text": "services like uh this image is captured from the hugging pace so they have they",
    "start": "1056400",
    "end": "1063160"
  },
  {
    "text": "displayed it they they display uh the recommended GPU types so it's a kind of",
    "start": "1063160",
    "end": "1071360"
  },
  {
    "text": "requirement as well so if you cannot decide uh which model requires what kind",
    "start": "1071360",
    "end": "1077640"
  },
  {
    "text": "of the gpus maybe you can raer to this kind of the guidelines um provided by the AI models",
    "start": "1077640",
    "end": "1088159"
  },
  {
    "text": "the providers so this picture is from the inter inference endpoint pce uh for",
    "start": "1088159",
    "end": "1094320"
  },
  {
    "text": "example they have in the pace you can see the many uh text generation models",
    "start": "1094320",
    "end": "1100320"
  },
  {
    "text": "and they display you and what kind of gpus and at least you",
    "start": "1100320",
    "end": "1107159"
  },
  {
    "text": "need so uh when you decide the GPU allocation so first on thinking about if",
    "start": "1107159",
    "end": "1114720"
  },
  {
    "text": "our servic is AI training or our servic is AI inference so very different so for",
    "start": "1114720",
    "end": "1122039"
  },
  {
    "text": "example if you're learning if you are learning the AI training service at least the proing point 64 32 and 16",
    "start": "1122039",
    "end": "1131640"
  },
  {
    "text": "supported GPU is necessary for your service for example Nvidia andair 100",
    "start": "1131640",
    "end": "1137520"
  },
  {
    "text": "cities V 100 series and H 100 series for",
    "start": "1137520",
    "end": "1144039"
  },
  {
    "text": "example but uh if your servic is AI inference which means that you got",
    "start": "1144039",
    "end": "1150280"
  },
  {
    "text": "another AI model train already trained AI model from another vendors and all",
    "start": "1150280",
    "end": "1155480"
  },
  {
    "text": "you have to do is AI inference this process is usually less resource",
    "start": "1155480",
    "end": "1160840"
  },
  {
    "text": "intensive compared to AI training and it only May uh only require a single GPU or",
    "start": "1160840",
    "end": "1168799"
  },
  {
    "text": "fraction of it for example floating Point 16 and integer 8 supported gpus",
    "start": "1168799",
    "end": "1176159"
  },
  {
    "text": "like nvdia T4 series and nvdia A10 nvdia jaier or Nvidia r2x series",
    "start": "1176159",
    "end": "1184159"
  },
  {
    "text": "Etc so uh this test uh from mine I utilize the C 10 data set you know uh",
    "start": "1184159",
    "end": "1192559"
  },
  {
    "text": "this is a very Lage data set as well but um it's a it consist of the labeled the",
    "start": "1192559",
    "end": "1200000"
  },
  {
    "text": "subset of the 18 million tiny images data set actually it consist of the",
    "start": "1200000",
    "end": "1207080"
  },
  {
    "text": "60,000 small images in 10 classes you can see that there is a",
    "start": "1207080",
    "end": "1213360"
  },
  {
    "text": "airplane automobile bird cat deer and then they have the 60,000 images for uh",
    "start": "1213360",
    "end": "1221720"
  },
  {
    "text": "totally and 6,000 images for class so",
    "start": "1221720",
    "end": "1227200"
  },
  {
    "text": "uh you can see that the training code is looks like more complex than inference",
    "start": "1227200",
    "end": "1235080"
  },
  {
    "text": "model so uh not only development side but also uh if you see the",
    "start": "1235080",
    "end": "1242919"
  },
  {
    "text": "result the first results come from the inference and second result is come from",
    "start": "1242919",
    "end": "1249039"
  },
  {
    "text": "API uh the AI training so I tested this code uh using the animal. JPG file which",
    "start": "1249039",
    "end": "1256720"
  },
  {
    "text": "is a host and and then you can see that the probability from inference and",
    "start": "1256720",
    "end": "1263520"
  },
  {
    "text": "training is a different because I'm not sure how many times what kind of Appo",
    "start": "1263520",
    "end": "1269159"
  },
  {
    "text": "how many Appo they used for making uh this kind of am models but for sure I",
    "start": "1269159",
    "end": "1276559"
  },
  {
    "text": "trained this model more than 10 times at the time the loss was there and then I",
    "start": "1276559",
    "end": "1283480"
  },
  {
    "text": "have 90 90% about 90% of the",
    "start": "1283480",
    "end": "1289559"
  },
  {
    "text": "probability that you make sure that it is a horse so in this kind if I measure",
    "start": "1289559",
    "end": "1295960"
  },
  {
    "text": "the GPU the uses allocation very different",
    "start": "1295960",
    "end": "1301840"
  },
  {
    "text": "so also uh getting some result from",
    "start": "1301840",
    "end": "1308159"
  },
  {
    "text": "these two types of the AI uh trainings and inference is different so uh you",
    "start": "1308159",
    "end": "1314440"
  },
  {
    "text": "need to decide which service which kind of service you will apply to your",
    "start": "1314440",
    "end": "1321679"
  },
  {
    "text": "organization and uh there is a tools there are tools like",
    "start": "1322600",
    "end": "1328240"
  },
  {
    "text": "the GPU operator and automated the noodle labeling labeling from the kuet",
    "start": "1328240",
    "end": "1334039"
  },
  {
    "text": "feature so uh fortunately Comm also have",
    "start": "1334039",
    "end": "1339200"
  },
  {
    "text": "how to allocate the GPU resources for your AI or clo so GPU operators like uh",
    "start": "1339200",
    "end": "1347240"
  },
  {
    "text": "incat uh it is it help us to manage a GPU resource effectively and it help us",
    "start": "1347240",
    "end": "1354600"
  },
  {
    "text": "Dynamic allocation for better resource utilization so not only the container TR",
    "start": "1354600",
    "end": "1360919"
  },
  {
    "text": "kit or you know the Cuda or Nvidia GPU driver we need to set up GPU operator if",
    "start": "1360919",
    "end": "1369120"
  },
  {
    "text": "you need get some help for GPU allocation and automated no labeling is",
    "start": "1369120",
    "end": "1375919"
  },
  {
    "text": "a b basic picture from the kuties it is used for not only GPU but also it's used",
    "start": "1375919",
    "end": "1382240"
  },
  {
    "text": "for CPU or dis or your memory also it support a mixed workload",
    "start": "1382240",
    "end": "1389080"
  },
  {
    "text": "on the same GPU uh so nedia recently say that you can use the multi- instance GPU",
    "start": "1389080",
    "end": "1395760"
  },
  {
    "text": "it means that one single GPU can be partitioned to into the multiple",
    "start": "1395760",
    "end": "1401720"
  },
  {
    "text": "instances and then Dynamic allocation based on the load it means that it",
    "start": "1401720",
    "end": "1407720"
  },
  {
    "text": "monitors how much load your GPU have and then if it is too",
    "start": "1407720",
    "end": "1413480"
  },
  {
    "text": "high the service will be goes to another gpus so uh these two techniques are",
    "start": "1413480",
    "end": "1420120"
  },
  {
    "text": "recently introduced and then it is very crucial for the AI developers how to",
    "start": "1420120",
    "end": "1427360"
  },
  {
    "text": "allocate the GPU resource is the major problem or the major pcture to develop",
    "start": "1427360",
    "end": "1433480"
  },
  {
    "text": "your AI service successfully so like huging Pace the",
    "start": "1433480",
    "end": "1439559"
  },
  {
    "text": "Nvidia they display what kind of the your GPU should be for certain the L",
    "start": "1439559",
    "end": "1446480"
  },
  {
    "text": "models or AI models for example llama 3 8 million model only",
    "start": "1446480",
    "end": "1455320"
  },
  {
    "text": "need eight uh one or two gpus in a such model but when it comes to the L 3 70",
    "start": "1455320",
    "end": "1463600"
  },
  {
    "text": "billion model they need at least 4 gpus and or 8 GP use to ensure the D food and",
    "start": "1463600",
    "end": "1471640"
  },
  {
    "text": "lat from the GPU so this kind of the guidelines will help you uh how to",
    "start": "1471640",
    "end": "1478440"
  },
  {
    "text": "decide the number of gpus the specs of gpus you",
    "start": "1478440",
    "end": "1485000"
  },
  {
    "text": "need and then another Factor not only GPU but BM is also important factor so",
    "start": "1485679",
    "end": "1492679"
  },
  {
    "text": "BM is actually crucial when you need to handle the Rog models a high resolution",
    "start": "1492679",
    "end": "1498039"
  },
  {
    "text": "data or large b sizes so GPU power is crucial when you need to process task",
    "start": "1498039",
    "end": "1506159"
  },
  {
    "text": "quickly but the BLM is important how much the memory you need for ReStore",
    "start": "1506159",
    "end": "1514360"
  },
  {
    "text": "some data sets some P files from the GPU so in most AI upload both GPU and BMS",
    "start": "1514360",
    "end": "1521840"
  },
  {
    "text": "are essential and the importance of the each depends on the specific requirement",
    "start": "1521840",
    "end": "1527279"
  },
  {
    "text": "or your task so generally you cannot ignore one in",
    "start": "1527279",
    "end": "1532399"
  },
  {
    "text": "favor of the other so uh Optimal Performance is achieved when both are",
    "start": "1532399",
    "end": "1540399"
  },
  {
    "text": "properly provision according to the workload need so",
    "start": "1540399",
    "end": "1545799"
  },
  {
    "text": "n so V is also important so in the spec specification page over your GPU bander",
    "start": "1545799",
    "end": "1553279"
  },
  {
    "text": "there is a GPU memory pector uh in this example this is a 20 gab the",
    "start": "1553279",
    "end": "1559799"
  },
  {
    "text": "gddr which means the graphics D data late sometimes GPU memory the vam is hbm",
    "start": "1559799",
    "end": "1569679"
  },
  {
    "text": "type high band withd memory it's a totally different so you need to carefully uh verify what kind of the VAB",
    "start": "1569679",
    "end": "1578279"
  },
  {
    "text": "your GPU has so for example this is a very simple",
    "start": "1578279",
    "end": "1583360"
  },
  {
    "text": "Ile to schedule the AI resource to your GPU so this is a part and then you know",
    "start": "1583360",
    "end": "1593200"
  },
  {
    "text": "there is a resource peel and limit PE to identify what kind of GPU and how many",
    "start": "1593200",
    "end": "1600080"
  },
  {
    "text": "you need uh for learning this part and then there is a toleration p and and uh",
    "start": "1600080",
    "end": "1608679"
  },
  {
    "text": "this means that what kind of node if you have uh more than 10 work node and only",
    "start": "1608679",
    "end": "1615760"
  },
  {
    "text": "five work node has the GPU then you you should be thinking about the",
    "start": "1615760",
    "end": "1621039"
  },
  {
    "text": "tolerations and thinking about the what will be the key and value to tolerate",
    "start": "1621039",
    "end": "1627919"
  },
  {
    "text": "and make some taint uh for your",
    "start": "1627919",
    "end": "1633158"
  },
  {
    "text": "workload so this is a job so uh job is you know used for the",
    "start": "1633320",
    "end": "1641320"
  },
  {
    "text": "keeping the trainings AI trainings by the the kubernetes so you can see that",
    "start": "1641320",
    "end": "1648919"
  },
  {
    "text": "the uh there is only one the GPU the reest actually this yam checks that if",
    "start": "1648919",
    "end": "1657080"
  },
  {
    "text": "your commun cluster detect the GPU on your host level so before starting the",
    "start": "1657080",
    "end": "1663200"
  },
  {
    "text": "AI workload service we need to verify that if our GPU is detected by your",
    "start": "1663200",
    "end": "1668799"
  },
  {
    "text": "cumulated cluster so uh schedule the resource with",
    "start": "1668799",
    "end": "1674679"
  },
  {
    "text": "the GPU you can use the limit you can use the gas Toleration as well also uh",
    "start": "1674679",
    "end": "1683240"
  },
  {
    "text": "you can make your own Dynamic Rael like this and then you can use the node oppon",
    "start": "1683240",
    "end": "1689320"
  },
  {
    "text": "oppon to select to make the part select your the proper the work",
    "start": "1689320",
    "end": "1695640"
  },
  {
    "text": "node another feature is NFD which means the another feature Discovery so you",
    "start": "1695640",
    "end": "1701919"
  },
  {
    "text": "don't need to make your own labels uh you need you don't need to typ in the KUB Cub CTL the label command",
    "start": "1701919",
    "end": "1710039"
  },
  {
    "text": "thanks to NF the picture so this picture automatically detect the hardware specs",
    "start": "1710039",
    "end": "1715840"
  },
  {
    "text": "over your worko like this and then it makes the Rael so uh after installation of the NFD",
    "start": "1715840",
    "end": "1724360"
  },
  {
    "text": "you can use no select p and then the label cre by ND is start with the",
    "start": "1724360",
    "end": "1732760"
  },
  {
    "text": "picture. node. the kuet is for an example this node",
    "start": "1732760",
    "end": "1739000"
  },
  {
    "text": "this part ask that I should be in a node which has the PCI 10de",
    "start": "1739000",
    "end": "1746679"
  },
  {
    "text": "interface so this is detected by nfpd not by a developers know uh the Kum",
    "start": "1746679",
    "end": "1755200"
  },
  {
    "text": "administrator but automatically detected by NFD",
    "start": "1755200",
    "end": "1760320"
  },
  {
    "text": "feature so another example for defined that nftd enable us to use no",
    "start": "1760320",
    "end": "1768679"
  },
  {
    "text": "to schedule this part onto notes okay so thinking about the famous",
    "start": "1768679",
    "end": "1775080"
  },
  {
    "text": "the qued cases of the learning the AI so this is mvidia name service which means",
    "start": "1775080",
    "end": "1783720"
  },
  {
    "text": "the idia inflence microservice for ji you can see that their microservices for",
    "start": "1783720",
    "end": "1789679"
  },
  {
    "text": "AI utilization is learn on the top of the kubernetes and thinking about the",
    "start": "1789679",
    "end": "1796399"
  },
  {
    "text": "merchin learning the work flows the qlow helpers tensorflow car py also they are",
    "start": "1796399",
    "end": "1803559"
  },
  {
    "text": "helping us to running the AI or mercenary workload on your clusters",
    "start": "1803559",
    "end": "1810200"
  },
  {
    "text": "in the serving stage the core caser the tensor plus serving as a famous the",
    "start": "1810200",
    "end": "1815960"
  },
  {
    "text": "framework to help you to solve your AI models thinking about how to deoy AI mer",
    "start": "1815960",
    "end": "1823279"
  },
  {
    "text": "on the Comm we have this kind of the pro so the ERS develop their",
    "start": "1823279",
    "end": "1830600"
  },
  {
    "text": "AI application code buil to repository make it the container images then deploy",
    "start": "1830600",
    "end": "1837279"
  },
  {
    "text": "to kues and then the consumers they will be accessed to kuet Cluster via the",
    "start": "1837279",
    "end": "1843080"
  },
  {
    "text": "public internet uh there should be some secure matter to block some unsecure the",
    "start": "1843080",
    "end": "1850080"
  },
  {
    "text": "traffic from uh from the internet utilizing the firewall and there should",
    "start": "1850080",
    "end": "1855200"
  },
  {
    "text": "be a road balancer to share the traffic to the multiple Co",
    "start": "1855200",
    "end": "1862559"
  },
  {
    "text": "clusters this is how uh makes this kind of the workflows uh I will share uh I",
    "start": "1862559",
    "end": "1870159"
  },
  {
    "text": "shared my the GitHub URS for all of the disc code and script so you can see in",
    "start": "1870159",
    "end": "1876720"
  },
  {
    "text": "time uh after this session so I will skipping it so because we are learn uh",
    "start": "1876720",
    "end": "1883000"
  },
  {
    "text": "already learning out of time so uh this is one example python",
    "start": "1883000",
    "end": "1888919"
  },
  {
    "text": "example first of all we need to use the Nvidia system management interface through if my GPU is learning",
    "start": "1888919",
    "end": "1897480"
  },
  {
    "text": "properly and then if I if I learn this P py code uh you can",
    "start": "1897480",
    "end": "1905240"
  },
  {
    "text": "see that there is a several app trainings are repeated and then we can",
    "start": "1905240",
    "end": "1911880"
  },
  {
    "text": "see how much the GPU resource was used for this kind of the training",
    "start": "1911880",
    "end": "1917960"
  },
  {
    "text": "uh thanks to mdmi tools so developers they need a multiple",
    "start": "1917960",
    "end": "1923679"
  },
  {
    "text": "terminals when they learn the when they start AI training and then check if your",
    "start": "1923679",
    "end": "1930399"
  },
  {
    "text": "GPU resource is enough for this kind of the",
    "start": "1930399",
    "end": "1935639"
  },
  {
    "text": "trainings yeah this is a phy how to make uh this AI Service uh through the",
    "start": "1936200",
    "end": "1943600"
  },
  {
    "text": "container images and then one of the example of the yam",
    "start": "1943600",
    "end": "1950080"
  },
  {
    "text": "file how to make the part of your",
    "start": "1950080",
    "end": "1954080"
  },
  {
    "text": "kumes okay so um my final topic is for the demand for distributed clouds so",
    "start": "1956159",
    "end": "1964080"
  },
  {
    "text": "this is my almost the last part of the this session so we are here in the Hong",
    "start": "1964080",
    "end": "1969360"
  },
  {
    "text": "Kong thinking about we want to use the AI inference hosted by some admm micro",
    "start": "1969360",
    "end": "1978080"
  },
  {
    "text": "service vender located in the US so there can be a internet pulus High",
    "start": "1978080",
    "end": "1986720"
  },
  {
    "text": "latency performance can be happen because there are too far and then we",
    "start": "1986720",
    "end": "1992679"
  },
  {
    "text": "use the public internet not you know uh we cannot make any dedicated lines",
    "start": "1992679",
    "end": "1998320"
  },
  {
    "text": "between two point because it's a too far away so thinking about uh this kind of",
    "start": "1998320",
    "end": "2003760"
  },
  {
    "text": "the demands makes the distrib cloud Ed computing like that so the cloud next",
    "start": "2003760",
    "end": "2011440"
  },
  {
    "text": "phace requires a shifting how developers Enterprise think about getting",
    "start": "2011440",
    "end": "2016880"
  },
  {
    "text": "application data close their customers so not only Clow what about having the",
    "start": "2016880",
    "end": "2022880"
  },
  {
    "text": "CL kuber neted closer close to closer to the end users",
    "start": "2022880",
    "end": "2028679"
  },
  {
    "text": "and developers so the next gen the kuet is clusters",
    "start": "2028679",
    "end": "2037320"
  },
  {
    "text": "they should be in the core competing regions which means Rum by the most",
    "start": "2037320",
    "end": "2044279"
  },
  {
    "text": "hyperscalers cloud service providers in the famous city and Country and not only",
    "start": "2044279",
    "end": "2051040"
  },
  {
    "text": "core Compu region the distributed regions at Computing side no matter what",
    "start": "2051040",
    "end": "2056960"
  },
  {
    "text": "types of there it can be a CDM pops as well there will be a Computing machines",
    "start": "2056960",
    "end": "2063560"
  },
  {
    "text": "with the gpus so this image illustrate a Global infrastructure for distributed",
    "start": "2063560",
    "end": "2070599"
  },
  {
    "text": "Quan cluster under Cloud environment especially optimized for AI workr so",
    "start": "2070599",
    "end": "2077839"
  },
  {
    "text": "they can be very close to an the end users and then this",
    "start": "2077839",
    "end": "2084079"
  },
  {
    "text": "satisfies the performance metrics uh asked by the",
    "start": "2084079",
    "end": "2089158"
  },
  {
    "text": "individuales uh in the world okay this is my last slide of this",
    "start": "2089159",
    "end": "2095720"
  },
  {
    "text": "session and then I've shared my my uh example code and script on my",
    "start": "2095720",
    "end": "2101480"
  },
  {
    "text": "GitHub and thank you for your time and attention I I hope that this session was",
    "start": "2101480",
    "end": "2108520"
  },
  {
    "text": "helpful to understand uh even though you was very Beijing rber what kind of the",
    "start": "2108520",
    "end": "2114400"
  },
  {
    "text": "consideration you have to have to learning AI workload on the kues and",
    "start": "2114400",
    "end": "2120880"
  },
  {
    "text": "thanks a lot for your time and then if you have any question I will stand by the out of this room and then you can",
    "start": "2120880",
    "end": "2128000"
  },
  {
    "text": "ask me any question uh I would welcome any discussion thank you",
    "start": "2128000",
    "end": "2134280"
  },
  {
    "text": "[Applause]",
    "start": "2134280",
    "end": "2139689"
  }
]
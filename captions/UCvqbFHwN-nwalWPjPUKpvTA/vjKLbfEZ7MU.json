[
  {
    "text": "okay we are at 2 30 on the dot so I assume we're good to go we are good to",
    "start": "60",
    "end": "5279"
  },
  {
    "text": "go oh hey there's the sign begin hello everyone thank you so much for coming uh",
    "start": "5279",
    "end": "10440"
  },
  {
    "text": "I'm very excited to be here today with savionik as well talking about Keda which is the real time and serverless",
    "start": "10440",
    "end": "17220"
  },
  {
    "text": "scaling solution for kubernetes a cncf incubations project we'll jump right",
    "start": "17220",
    "end": "23340"
  },
  {
    "text": "into it we only have half an hour plus a little bit and we want to leave plenty of time for Q a thank you to all of you",
    "start": "23340",
    "end": "29400"
  },
  {
    "text": "who might be joining virtually hello to you as well I can feel your strength through that little camera in the back",
    "start": "29400",
    "end": "36620"
  },
  {
    "text": "can you feel it too oh all right well maybe after we get through intros so very quickly who are we and why are we",
    "start": "36620",
    "end": "43739"
  },
  {
    "text": "so excited about Keda so I'm Jeff Holland I am a director of product right now it's snowflake the data Cloud",
    "start": "43739",
    "end": "51059"
  },
  {
    "text": "company and prior to snowflake though I worked at Microsoft for about 10 years and part of my time at Microsoft",
    "start": "51059",
    "end": "57320"
  },
  {
    "text": "involved a partnership with red hat uh when we created and founded cada is a",
    "start": "57320",
    "end": "63180"
  },
  {
    "text": "project this would have been I don't know three or four years ago at this point you can find me on the socials at",
    "start": "63180",
    "end": "69360"
  },
  {
    "text": "Twitter or LinkedIn if you have any questions or just want to connect more than happy to chat with you there that Microsoft I was working on a bunch of",
    "start": "69360",
    "end": "75720"
  },
  {
    "text": "the serverless tech like Azure functions Azure container apps and so scale was a key part of that which is part of what",
    "start": "75720",
    "end": "81840"
  },
  {
    "text": "inspired us to be like oh how could we make scale better in kubernetes all up yeah thanks Jeff uh hello everyone again",
    "start": "81840",
    "end": "88799"
  },
  {
    "text": "I'm very happy to be here on stage Jeff he's great and to talk about keraso my",
    "start": "88799",
    "end": "94259"
  },
  {
    "text": "name is binyak rubarik I'm based in bernocheck Republic which is in Central Europe in case you don't know",
    "start": "94259",
    "end": "99680"
  },
  {
    "text": "uh I'm software engineer working on red hat and as Jeff mentioned we are quite",
    "start": "99680",
    "end": "104939"
  },
  {
    "text": "cooperating on Keda for some time uh so I'm kind of maintainer and also active in a commutative Community I'm",
    "start": "104939",
    "end": "111899"
  },
  {
    "text": "part of the TOC board and my main focus is kinetic functions is a good project",
    "start": "111899",
    "end": "117780"
  },
  {
    "text": "so you should check it out definitely but now let's talk about era great and",
    "start": "117780",
    "end": "122880"
  },
  {
    "text": "it's crazy that you flew halfway around the world and are facing jet lag but you were here plenty of time in advance for",
    "start": "122880",
    "end": "128940"
  },
  {
    "text": "the session I flew from Seattle and I ran in here five minutes ago so credit",
    "start": "128940",
    "end": "133980"
  },
  {
    "text": "to you I guess you did a great job so yeah uh yes uh you can imagine how good",
    "start": "133980",
    "end": "139440"
  },
  {
    "text": "of a PM I am if I can't even show up if I like what if what is it PM if not somebody who creates slides and speaking",
    "start": "139440",
    "end": "145680"
  },
  {
    "text": "of sites we'll jump right into it so we're going to talk a little bit about what cada is we're going to show a demo fairly early on and then we're going to",
    "start": "145680",
    "end": "152640"
  },
  {
    "text": "show you a little bit of behind the scenes of how Kata works and we've got some really exciting stuff to share in terms of what the community is building",
    "start": "152640",
    "end": "158220"
  },
  {
    "text": "moving forward as I mentioned we'll have questions at the end so if you can hang on to them there we will answer",
    "start": "158220",
    "end": "163680"
  },
  {
    "text": "questions then so starting with framing cada I like to to use this analogy which",
    "start": "163680",
    "end": "169019"
  },
  {
    "text": "is let's compare two two scaling stories and here's the task let's say that I",
    "start": "169019",
    "end": "174180"
  },
  {
    "text": "have so my my task right now is there's a cubecon party happening tonight if",
    "start": "174180",
    "end": "179280"
  },
  {
    "text": "you're not invited to one come reach out to me I'll give you an invite there's like seven of them happening probably more and here's the goal you need to",
    "start": "179280",
    "end": "187200"
  },
  {
    "text": "provide enough Pizza to feed as many people as show up at a cubecon party now",
    "start": "187200",
    "end": "192599"
  },
  {
    "text": "you have two strategies here one is you show up with one pizza to start with and",
    "start": "192599",
    "end": "197640"
  },
  {
    "text": "you put it down on the table and then you just look at that pizza and you wait until that pizza box is empty and when",
    "start": "197640",
    "end": "204540"
  },
  {
    "text": "the pizza box is empty you're like okay well I guess we need more than one box so then you leave and you come back with two boxes of pizza and then you watch",
    "start": "204540",
    "end": "211500"
  },
  {
    "text": "those two boxes of pizza and you wait till they're empty and then you come back with four and then you come back with eight you could do that it would",
    "start": "211500",
    "end": "218760"
  },
  {
    "text": "work the party attendees will be ticked off at you because if there's a hundred",
    "start": "218760",
    "end": "223860"
  },
  {
    "text": "or two hundred or three hundred people there they're going to be waiting an hour two hours plus while you run back",
    "start": "223860",
    "end": "229140"
  },
  {
    "text": "and forth getting a bunch of people I'll be on the other party back then you know yeah you would have left you would",
    "start": "229140",
    "end": "235580"
  },
  {
    "text": "about or whatever when you're number two this is what a product manager would hopefully do I'm going to",
    "start": "237120",
    "end": "243840"
  },
  {
    "text": "find out how many people are projected to come to this party and then I'm going to make an informed decision based on",
    "start": "243840",
    "end": "250379"
  },
  {
    "text": "how many pizzas I think I need based on that so if there's a hundred people I think okay 10 pizzas is maybe enough",
    "start": "250379",
    "end": "256019"
  },
  {
    "text": "maybe I'll go with 12 to be safe and so I'll show up to the party with 12 boxes of pizza and if there's a thousand",
    "start": "256019",
    "end": "262260"
  },
  {
    "text": "people I'll show up with 120 boxes of pizza now if you were in charge of creative writing pizza for a party which",
    "start": "262260",
    "end": "267780"
  },
  {
    "text": "strategy you're going to go with I think everyone's going to go with strategy number two but the funny thing is when it comes to scaling our applications we",
    "start": "267780",
    "end": "275520"
  },
  {
    "text": "so often go with strategy number one we deploy an application and then we just watch the CPU in the memory and we wait",
    "start": "275520",
    "end": "282600"
  },
  {
    "text": "for all the CPU in the memory to get eaten up and they're like okay well I guess we need some more and so we'll give it a little bit more and then we",
    "start": "282600",
    "end": "287759"
  },
  {
    "text": "just sit there and watch and it is not an efficient way to do things so I am pleased to share that cada is the better",
    "start": "287759",
    "end": "293940"
  },
  {
    "text": "Pizza way to scale your container because kada yeah thank you it's a beautiful analog it makes me very hungry",
    "start": "293940",
    "end": "300660"
  },
  {
    "text": "I love pizza so cada makes it so that your kubernetes cluster is much smarter",
    "start": "300660",
    "end": "306840"
  },
  {
    "text": "at thinking about how to scale things because it will Scale based on the events what is causing the consumption",
    "start": "306840",
    "end": "313259"
  },
  {
    "text": "in the CPU and memory so it integrates with over 55 different event sources from information from Prometheus event",
    "start": "313259",
    "end": "321060"
  },
  {
    "text": "sources like rabbitmq Kafka AWS sqs Azure event hubs gcp Pub sub postgres",
    "start": "321060",
    "end": "327360"
  },
  {
    "text": "you can go to cada.sh and see a massive list of scalars and that list grows two",
    "start": "327360",
    "end": "332880"
  },
  {
    "text": "or three every single time we do a cater release so this is a really useful pattern because it makes it so you can",
    "start": "332880",
    "end": "338400"
  },
  {
    "text": "scale your workloads based on the events the cause of the consumption and not the",
    "start": "338400",
    "end": "344100"
  },
  {
    "text": "reactive way that we've been trained to scale so long before and what I love about Kate is just how seamlessly you",
    "start": "344100",
    "end": "349800"
  },
  {
    "text": "can pop it into any architecture in any kubernetes cluster so let's show you this in action before Xavier neck walks",
    "start": "349800",
    "end": "356460"
  },
  {
    "text": "through some of the architecture so we're going to do a quick demo here this is my hello cada demo I want to make it",
    "start": "356460",
    "end": "362460"
  },
  {
    "text": "as simple as possible we have a rabbitmq cue there's a lot of fantastic queuing",
    "start": "362460",
    "end": "368340"
  },
  {
    "text": "you could swap this out with Kafka or whatever you want I'm just using rabbitmq because it's the easiest for me to to install on a cluster and I'm going",
    "start": "368340",
    "end": "375360"
  },
  {
    "text": "to deploy a container which is just consuming messages from that queue fairly simple",
    "start": "375360",
    "end": "381240"
  },
  {
    "text": "now what we're going to do is we're going to add cada to the mix and cada is going to do two things one it's going to",
    "start": "381240",
    "end": "389039"
  },
  {
    "text": "go ask rabbitmq how many events do you have that need to be processed how many people are waiting in line to get into",
    "start": "389039",
    "end": "394740"
  },
  {
    "text": "this party and then based on that information cada is going to scale our",
    "start": "394740",
    "end": "400620"
  },
  {
    "text": "application based on those events and it does that scaling through the horizontal parado scaler the HPA that we all know",
    "start": "400620",
    "end": "406919"
  },
  {
    "text": "and love it's not doing its own magical scaling thing behind the scenes we'll talk about that in the architecture so you'll see how Kato will scale this one",
    "start": "406919",
    "end": "413460"
  },
  {
    "text": "thing I want to call out here right before I show the demo the application has no idea that cada exists just like",
    "start": "413460",
    "end": "420720"
  },
  {
    "text": "in kubernetes it's not aware that it's running in kubernetes or if it's in a laptop it just wakes up and says start",
    "start": "420720",
    "end": "425880"
  },
  {
    "text": "giving me messages so Kate is able to pop right in there I didn't change my code in any way but it's able to enrich",
    "start": "425880",
    "end": "432660"
  },
  {
    "text": "the scaling logic based on knowing in this case how many messages are on that queue so let's see it in action this is",
    "start": "432660",
    "end": "439979"
  },
  {
    "text": "the deployment manifest that I'm using beautiful beautiful yaml you can see I",
    "start": "439979",
    "end": "445080"
  },
  {
    "text": "just have a very simple container here it's complaining because I'm not requesting any cores or memory that's",
    "start": "445080",
    "end": "450539"
  },
  {
    "text": "the squiggly yellow lines here but I'm just deploying a container and what cada is having me Define is",
    "start": "450539",
    "end": "456900"
  },
  {
    "text": "this custom object next to it which is this cada scaled object and this is where I tell tell cada about the event",
    "start": "456900",
    "end": "464699"
  },
  {
    "text": "source and what I want it to scale so I say I want you to scale this rabbitmq container and I'm going to scale it",
    "start": "464699",
    "end": "470759"
  },
  {
    "text": "based on events coming from rabbitmq and I mentioned there's like 60 of these that I could choose to scale it on I'm",
    "start": "470759",
    "end": "476880"
  },
  {
    "text": "telling it to kind of Target about five messages per container that's like saying how many pizzas per people so I'm",
    "start": "476880",
    "end": "484139"
  },
  {
    "text": "saying every container go for about like five messages I tell it the queue to listen to and I can even describe an",
    "start": "484139",
    "end": "491340"
  },
  {
    "text": "authentication parameter so that Kata knows how to securely ask rabbitmq how many people are in line okay so this is",
    "start": "491340",
    "end": "498479"
  },
  {
    "text": "what I've already deployed in my cluster so let's see that here so I can now at this point my Q is empty I'm going to go",
    "start": "498479",
    "end": "506099"
  },
  {
    "text": "ahead and say sorry let me zoom in here I don't know you can see the last time I ran this which has spoilers okay so",
    "start": "506099",
    "end": "512459"
  },
  {
    "text": "right now my contain container is running one beautiful thing it's scaled",
    "start": "512459",
    "end": "517919"
  },
  {
    "text": "all the way to zero this container is actually not consuming any CPU in my cluster because cada is smart enough",
    "start": "517919",
    "end": "524339"
  },
  {
    "text": "that it's looking at that rabbitmq thing and it's saying there's no messages here why waste the CPU Cycles so cada has",
    "start": "524339",
    "end": "530760"
  },
  {
    "text": "helped the scale all the way down to zero now what I'm going to do here is I'm going to add a quick job which is",
    "start": "530760",
    "end": "538740"
  },
  {
    "text": "going to publish I can't remember a thousand ten thousand messages onto this",
    "start": "538740",
    "end": "543959"
  },
  {
    "text": "rabbitmq queue so now let's watch this in real time and you'll notice even before I finish talking cada now sees oh",
    "start": "543959",
    "end": "551640"
  },
  {
    "text": "shoot there's actually a lot of stuff going on here there's a lot of people who need some CPU so very quickly before",
    "start": "551640",
    "end": "557640"
  },
  {
    "text": "the first CPU cycle even got hit cada has already helped me scale up to you can see I now have four instances of",
    "start": "557640",
    "end": "564600"
  },
  {
    "text": "this container up and running and even before I finish that sentence now it's gone to eight and it will continue to",
    "start": "564600",
    "end": "569880"
  },
  {
    "text": "scale and scale and scale because I told it hey if there's a thousand messages in the queue I want you to Target about",
    "start": "569880",
    "end": "576959"
  },
  {
    "text": "five five messages per container so it's now helping get to that state where it's",
    "start": "576959",
    "end": "582300"
  },
  {
    "text": "able to handle the workload as I described it so you can see very very quickly I've been able to horizontally scale my services now what I want to do",
    "start": "582300",
    "end": "588959"
  },
  {
    "text": "quickly here as well and show you what happens if something goes wrong so I have defined one more",
    "start": "588959",
    "end": "594899"
  },
  {
    "text": "piece here which is some fallback logic that says if the connection to rabbitmq fails what do I want to do does it now",
    "start": "594899",
    "end": "602640"
  },
  {
    "text": "scale all the way to zero and my application blows up well I I wrote this fallback logic to say you know if",
    "start": "602640",
    "end": "608580"
  },
  {
    "text": "something goes wrong just run it for run it for replicas that's a pretty safe spot to be so let's make something go",
    "start": "608580",
    "end": "615240"
  },
  {
    "text": "wrong let's uninstall rabbitmq from this cluster that we've been talking to and",
    "start": "615240",
    "end": "620940"
  },
  {
    "text": "so you can see here my rabbitmq just got terminated and as soon as it got terminated cater realized uh oh I can't I'm trying",
    "start": "620940",
    "end": "628980"
  },
  {
    "text": "to ask rabbitmq how many messages it has I'm not getting any answer back who knows why it might have failed in my",
    "start": "628980",
    "end": "634080"
  },
  {
    "text": "case it failed because of user error but what you'll see here is I finished talking is that it's going to end up in",
    "start": "634080",
    "end": "639600"
  },
  {
    "text": "that fallback mode hopefully it will well the containers are now unhappy because they also can't talk to rabbitmq",
    "start": "639600",
    "end": "645180"
  },
  {
    "text": "but you can see here if I I'll switch to a view where you don't have to look at all of the errors it's now trying to run",
    "start": "645180",
    "end": "651680"
  },
  {
    "text": "with four instances so it it's even Kate has helped us fall back into a state",
    "start": "651680",
    "end": "657660"
  },
  {
    "text": "where it's like okay something went wrong I can fall back now I I won't walk through this now but if I just add",
    "start": "657660",
    "end": "663959"
  },
  {
    "text": "rabbit and Q back into the mix everything will go back into a healthy State it'll go back to consuming",
    "start": "663959",
    "end": "669360"
  },
  {
    "text": "whatever messages might still be there and and going there so hopefully that made sense I had a simple container I",
    "start": "669360",
    "end": "676620"
  },
  {
    "text": "told Kata scale this container based on events from rabbitmq it very very",
    "start": "676620",
    "end": "681779"
  },
  {
    "text": "rapidly got to the right amount of containers I needed to consume all those messages and then I even have some nice",
    "start": "681779",
    "end": "687000"
  },
  {
    "text": "features here like fallback to make sure if something goes wrong my whole application isn't just floundering",
    "start": "687000",
    "end": "692220"
  },
  {
    "text": "because this doesn't know what to do so I think at this point we might even be at a healthy State we'll get there soon",
    "start": "692220",
    "end": "697260"
  },
  {
    "text": "enough so that's a quick hello world demo very very kind of simple to see any",
    "start": "697260",
    "end": "702959"
  },
  {
    "text": "container can now point to cada so with that sibiana can walk us through a little bit of the architecture yeah",
    "start": "702959",
    "end": "708480"
  },
  {
    "text": "thank you Jeff that was great awesome demo so I hope that by now you have some",
    "start": "708480",
    "end": "713820"
  },
  {
    "text": "understanding how Qatar works or what it does actually so we can take a look at our architecture so Keda is built on top",
    "start": "713820",
    "end": "720720"
  },
  {
    "text": "of kubernetes so we are trying to use as much components and Concepts from kubernetes so to not so do not do the",
    "start": "720720",
    "end": "728579"
  },
  {
    "text": "you know the stuff that yeah then things that already exist exactly so",
    "start": "728579",
    "end": "735360"
  },
  {
    "text": "um and the main component is scaled object or skill job this is the main resource where we Define the metadata",
    "start": "735360",
    "end": "740940"
  },
  {
    "text": "for scaling Us in that in the demo so let's say that if we go back to Remo what have done if I create a scaled",
    "start": "740940",
    "end": "747600"
  },
  {
    "text": "object in my cluster there are two main components of Keta the first one is scale operator or controller this is",
    "start": "747600",
    "end": "754140"
  },
  {
    "text": "this box and the second main component is scada Matrix adapter or kinematic server so once Jeff created the scaled",
    "start": "754140",
    "end": "761339"
  },
  {
    "text": "object the cada operator spotted this resource and based on the metadata definition it",
    "start": "761339",
    "end": "767880"
  },
  {
    "text": "creates HPA with the with the proper metadata with the proper scaling Etc and",
    "start": "767880",
    "end": "773279"
  },
  {
    "text": "then it uh it checks the scale object again and see what kind of scalar has been used for for this skill objects so",
    "start": "773279",
    "end": "779639"
  },
  {
    "text": "in this case it was rapidmq so it creates a scalar object which is basically an adapter that talks to the",
    "start": "779639",
    "end": "786240"
  },
  {
    "text": "external service and queries for for the metrics so it it creates the scalar talks to do external service and pause",
    "start": "786240",
    "end": "792959"
  },
  {
    "text": "the metrics and finally because S as Jeff mentioned we rely on HPA for the",
    "start": "792959",
    "end": "799620"
  },
  {
    "text": "auto scaling but HPA cannot scale down to zero it is not able to do that so we",
    "start": "799620",
    "end": "805019"
  },
  {
    "text": "need to do that from the from the kerasite so okay operator does the scaling from zero to one we call this",
    "start": "805019",
    "end": "811139"
  },
  {
    "text": "phase an activation phase and you can even specify specific threshold for this so in in a moment that there is like the",
    "start": "811139",
    "end": "818040"
  },
  {
    "text": "threshold in on the on the Queue it will scale up in this case when we are on one replica of our Target application then",
    "start": "818040",
    "end": "824820"
  },
  {
    "text": "the second main component kicks in and basically it's a it's a matrix adapter that's registered on kubernetes endpoint",
    "start": "824820",
    "end": "831540"
  },
  {
    "text": "and it fits the external metrics from the scalar to the horizontal Port Auto scaler so there is a horizontal scale",
    "start": "831540",
    "end": "839160"
  },
  {
    "text": "control in kubernetes and it asks for metrics and we are providing them through the through this interface again",
    "start": "839160",
    "end": "844800"
  },
  {
    "text": "it's a standard kubernetes stuff so we are trying to to be transparent in this so I think that that's the that's the",
    "start": "844800",
    "end": "851220"
  },
  {
    "text": "main logic quite simple and the one thing just to call out and I know I mentioned this a few times I love about",
    "start": "851220",
    "end": "856920"
  },
  {
    "text": "cada is you can pop in that operator without impacting anything else so you might have already 50 containers running",
    "start": "856920",
    "end": "864000"
  },
  {
    "text": "in a cluster you go and install the cada operator at first nothing's going to change and maybe now two of those 50 are",
    "start": "864000",
    "end": "871380"
  },
  {
    "text": "like yeah scale these based on events those two are still going to be scaled via the HPA Sabi convention but now",
    "start": "871380",
    "end": "877260"
  },
  {
    "text": "they're going to be enriched with all this extra data from cada so this makes it a really nice design to incrementally",
    "start": "877260",
    "end": "883560"
  },
  {
    "text": "adopt as you want without worrying about like oh shoot do I have to now have like a cada flavored kubernetes cluster it",
    "start": "883560",
    "end": "889980"
  },
  {
    "text": "doesn't work like that it's it's very much just doing its thing on the side you pull it in when you need and you ignore it when you don't yeah so there",
    "start": "889980",
    "end": "896760"
  },
  {
    "text": "are two main resources to define the scaling so the first one is scaled object basically with scaled object you",
    "start": "896760",
    "end": "901980"
  },
  {
    "text": "can Target any deployment stateful set or any custom resource that implements this specific sub resource it's called",
    "start": "901980",
    "end": "907860"
  },
  {
    "text": "scale so we can target targeted here and the second main part of the skilled",
    "start": "907860",
    "end": "913560"
  },
  {
    "text": "object is basically the trigger section so in this case it is a Kafka trigger section so it says okay let's let's",
    "start": "913560",
    "end": "919440"
  },
  {
    "text": "scale this deployment based on the messages in this Kafka topic we can have multiple triggers in this in this",
    "start": "919440",
    "end": "926699"
  },
  {
    "text": "trigger section and in this case we are sending all the Matrix from from this particular trigger so it could be Kafka",
    "start": "926699",
    "end": "932760"
  },
  {
    "text": "with mq Prometheus all targeting the same deployment and we are sending the metrics over to HPA and HPA does the",
    "start": "932760",
    "end": "939180"
  },
  {
    "text": "decision on on the scaling itself so it basically at the moment it selects the highest value from from all the from all",
    "start": "939180",
    "end": "945839"
  },
  {
    "text": "the metrics foreign the second component is called scale job",
    "start": "945839",
    "end": "951800"
  },
  {
    "text": "this one is is very good for for long running processes so basically it does",
    "start": "951800",
    "end": "957180"
  },
  {
    "text": "not scale an application or deployment but it uh but its schedule a kubernetes job based on based on the events",
    "start": "957180",
    "end": "963600"
  },
  {
    "text": "happening in the external system so it's the very same trigger section so again the the Kafka topic with video threshold",
    "start": "963600",
    "end": "970320"
  },
  {
    "text": "and instead of specifying a Target we can put playing kubernetes job definition and it",
    "start": "970320",
    "end": "977699"
  },
  {
    "text": "will it will create the kubernetes jobs based on that this is very important aspect because if you have some long",
    "start": "977699",
    "end": "983519"
  },
  {
    "text": "running application that it process some data from the external system it takes hours to process actual stuff if you use",
    "start": "983519",
    "end": "990839"
  },
  {
    "text": "the HP approach the HPA may actually kill your application during the",
    "start": "990839",
    "end": "996060"
  },
  {
    "text": "processing because the metrics are already gone but the application needs more time to process the stuff so in",
    "start": "996060",
    "end": "1001160"
  },
  {
    "text": "this case you should use skill jobs and to spawn a skill jobs space based on that metrics",
    "start": "1001160",
    "end": "1007779"
  },
  {
    "text": "this is just an example because what we are trying to achieve with Keda is is Simplicity it's you it's Simplicity from",
    "start": "1007839",
    "end": "1014540"
  },
  {
    "text": "the user perspective so as a user I don't want to deal with you know configuring all the stuff on kubernetes I just want to plug it in create scaled",
    "start": "1014540",
    "end": "1020959"
  },
  {
    "text": "object and do the scaling so this is example on the left hand side you can see a scaled object",
    "start": "1020959",
    "end": "1026418"
  },
  {
    "text": "on the right hand side you can see basically the HPA with with some custom metrics so you can you can actually",
    "start": "1026419",
    "end": "1032660"
  },
  {
    "text": "implement this on your own you can Target this very same endpoint endpoint in kubernetes but you will do you will",
    "start": "1032660",
    "end": "1039558"
  },
  {
    "text": "need to do all the all the stuff that you don't want to do so we are trying to to make this very simple",
    "start": "1039559",
    "end": "1045880"
  },
  {
    "text": "uh yeah and let's talk about some Advanced features so you have already seen the fallback in the demo it's cool",
    "start": "1046040",
    "end": "1051760"
  },
  {
    "text": "uh also what is what is nice this is HPA scaling Behavior this is Upstream",
    "start": "1051760",
    "end": "1057440"
  },
  {
    "text": "kubernetes Upstream HPA staff um it's it's very important because sometimes the metrics may go up and down",
    "start": "1057440",
    "end": "1064280"
  },
  {
    "text": "up and down so the replica number maybe maybe plugging as well so you you would like to you know avoid this situation so",
    "start": "1064280",
    "end": "1070940"
  },
  {
    "text": "in the scale Behavior you can specify a window which will be used for selecting the Target Target or pick a number uh",
    "start": "1070940",
    "end": "1078500"
  },
  {
    "text": "other cool feature is posing or photo scaling so imagine that you have your deployments your applications your",
    "start": "1078500",
    "end": "1084559"
  },
  {
    "text": "scaling everything is perfect but you would like to do some maintenance and you don't want to remove the scale object from your cluster what you can do",
    "start": "1084559",
    "end": "1091340"
  },
  {
    "text": "you can just annotate the skilled object with The annotation and pause the auto scaling for for the time for the for the",
    "start": "1091340",
    "end": "1097460"
  },
  {
    "text": "outage or forever um we also think that auto scaling is is",
    "start": "1097460",
    "end": "1102559"
  },
  {
    "text": "nice it's fun if you have it in a cluster but if you have many many scale objects in your cluster it's hard you",
    "start": "1102559",
    "end": "1108260"
  },
  {
    "text": "know to get uh beyond the picture what's happening in the cluster actually so observability is is very important for",
    "start": "1108260",
    "end": "1114140"
  },
  {
    "text": "us so at the moment can I expose this some Prometheus metrics about what is happening what is what it does how it",
    "start": "1114140",
    "end": "1120020"
  },
  {
    "text": "does the scaling but we are still trying to improve improve on this area and yeah and the last thing I would like",
    "start": "1120020",
    "end": "1126860"
  },
  {
    "text": "to highlight is that as you have mentioned we have like 50 plus different scalars but if if those",
    "start": "1126860",
    "end": "1133340"
  },
  {
    "text": "carers are not right for you you can Implement your own and you can use uh it's called external scale interface",
    "start": "1133340",
    "end": "1139460"
  },
  {
    "text": "it's basically a grpc interface and if if you implement this interface you can Implement your own scalar with your own",
    "start": "1139460",
    "end": "1144919"
  },
  {
    "text": "logic and just plug in together and cada is written and grow if you don't like grow you can write it's dot net Java",
    "start": "1144919",
    "end": "1151280"
  },
  {
    "text": "whatever and just use the RPC to to talk look at that to do the scaling for you if you want to know more about the spec",
    "start": "1151280",
    "end": "1157460"
  },
  {
    "text": "this is the link for to the recommendation and last but not least is the",
    "start": "1157460",
    "end": "1163580"
  },
  {
    "text": "Authentication it's important right so because if you if you if you need to talk to some external Services you need to store the",
    "start": "1163580",
    "end": "1170539"
  },
  {
    "text": "credentials somehow and most likely you don't want to store them directly in scale object in gamma so you would like",
    "start": "1170539",
    "end": "1175700"
  },
  {
    "text": "to have some reference so there was a reference on the trigger authentication object so it basically can hold",
    "start": "1175700",
    "end": "1181100"
  },
  {
    "text": "references to Secrets vaults uh you can even use spot identity and it's",
    "start": "1181100",
    "end": "1186679"
  },
  {
    "text": "namespace based so you can have a one particular object try to take out integration object in a namespace and reference it in multiple scale objects",
    "start": "1186679",
    "end": "1193100"
  },
  {
    "text": "or you can use cluster-wise trigger authentication and this is useful you for example you are admin on the on the",
    "start": "1193100",
    "end": "1199280"
  },
  {
    "text": "cluster you can set up the crosstalk authentication object in one end space with all the credentials and the users",
    "start": "1199280",
    "end": "1206240"
  },
  {
    "text": "that will do the actual scaling that will create the skill objects can just reference to this cluster authentication",
    "start": "1206240",
    "end": "1213140"
  },
  {
    "text": "object without even knowing what are the credentials so you are not exposing the data to more more users than necessary",
    "start": "1213140",
    "end": "1221740"
  },
  {
    "text": "okay so that's the current state that's the what what we have with Keta it works it's awesome but what's next so the",
    "start": "1221840",
    "end": "1229820"
  },
  {
    "text": "first point I would like to highlight is that at the moment we are just feeding the metrics to HPA",
    "start": "1229820",
    "end": "1235460"
  },
  {
    "text": "so if you recall that was the two main components get operator and ketametric server so we are just sending the",
    "start": "1235460",
    "end": "1241580"
  },
  {
    "text": "metrics over to H to HPA through the metric server uh every time that HPA asks but this might not be the best case",
    "start": "1241580",
    "end": "1248720"
  },
  {
    "text": "if you have tons of scaled objects in our cluster and maybe all of them are getting the same external service so for",
    "start": "1248720",
    "end": "1255260"
  },
  {
    "text": "example the same parameter server so there could be there could be like a very high load on this on the server so",
    "start": "1255260",
    "end": "1260660"
  },
  {
    "text": "once we are able to Cache cache the metric values in the in the Matrix adapter we are able to tell okay they",
    "start": "1260660",
    "end": "1266600"
  },
  {
    "text": "are not to ask for metrics every time but you know store them and give give some give some value later",
    "start": "1266600",
    "end": "1271760"
  },
  {
    "text": "the other cool stuff that we can do with the with the caching is we can do some magic with the actual numbers so once we",
    "start": "1271760",
    "end": "1277640"
  },
  {
    "text": "have but once we know what are the actual metrics coming in the in some period of time we can do some maybe just",
    "start": "1277640",
    "end": "1283100"
  },
  {
    "text": "some smoothing some some Ai and our models Etc um do you want to follow up yeah on the",
    "start": "1283100",
    "end": "1289039"
  },
  {
    "text": "uh for custom logic with evaluating multiple triggers so in my example my",
    "start": "1289039",
    "end": "1294559"
  },
  {
    "text": "container just had a single trigger listed in that list which was rabbitmq you can actually provide multiple of",
    "start": "1294559",
    "end": "1300740"
  },
  {
    "text": "those you could say like rabbitmq and CPU and memory and this cron task or",
    "start": "1300740",
    "end": "1306860"
  },
  {
    "text": "something else now the challenge with that is when it creates it behind the scenes and it actually goes and registers all that with the kubernetes",
    "start": "1306860",
    "end": "1313520"
  },
  {
    "text": "auto scaler the HPA it's going to be publishing all those metrics and we leave it up to the HPA to decide when to",
    "start": "1313520",
    "end": "1320539"
  },
  {
    "text": "whether or not to make a scaling decision and usually today I think Dominic was mentioning it just goes whatever number is the biggest that's",
    "start": "1320539",
    "end": "1326659"
  },
  {
    "text": "the one that's going to prioritize and so moving forward we also have some asked to say like hey can I have some",
    "start": "1326659",
    "end": "1331820"
  },
  {
    "text": "more customized logic here maybe I want to take the average of a few different uh sources maybe I want to prioritize",
    "start": "1331820",
    "end": "1338120"
  },
  {
    "text": "one over the other and so doing more of that logic on the cada side that we can give the HPA just the info that it needs",
    "start": "1338120",
    "end": "1344480"
  },
  {
    "text": "to make the scaling decision on the cloud event sides have been mentioned these last two are actually related to",
    "start": "1344480",
    "end": "1349580"
  },
  {
    "text": "the aspect you know we integrate very cleanly with Prometheus today both from a emitting Prometheus metrics for you to",
    "start": "1349580",
    "end": "1355520"
  },
  {
    "text": "operate but also scaling based on a Prometheus time series query we also",
    "start": "1355520",
    "end": "1360559"
  },
  {
    "text": "want to integrate with Cloud events so that if you uh cada itself can emit Cloud events so when something happens",
    "start": "1360559",
    "end": "1366980"
  },
  {
    "text": "K10 it's Cloud events but also there's an issue of understanding hey how could we scale Things based on cloud events",
    "start": "1366980",
    "end": "1373340"
  },
  {
    "text": "that might be coming from other systems similar story with open Telemetry having that same there's an open Telemetry",
    "start": "1373340",
    "end": "1378740"
  },
  {
    "text": "scalar being worked on right now so you can make scaling decisions based on Telemetry from open Telemetry and deeper",
    "start": "1378740",
    "end": "1384919"
  },
  {
    "text": "integration with that and then finally this open interface for predictive Auto scaling yeah that's another cool feature",
    "start": "1384919",
    "end": "1390910"
  },
  {
    "text": "[Music] basically because we have we are getting the metrics from the external system so we can we can try to do something with",
    "start": "1390910",
    "end": "1397280"
  },
  {
    "text": "them so we are thinking about introducing some interface that we can plug some aim model for example and",
    "start": "1397280",
    "end": "1403820"
  },
  {
    "text": "based on the incoming metrics we can predict the actual actual state so we can say that we would like to Auto scale",
    "start": "1403820",
    "end": "1409760"
  },
  {
    "text": "the application you know every Monday because of the of the prediction at the moment we have one one one scalar that",
    "start": "1409760",
    "end": "1416720"
  },
  {
    "text": "is doing this stuff but it is like a talking to some external service but they would like to do it like an open",
    "start": "1416720",
    "end": "1421820"
  },
  {
    "text": "way and another important thing is environmental impact I know these days",
    "start": "1421820",
    "end": "1428659"
  },
  {
    "text": "it's it's very important stuff as we know all the situations happening around the world so we are actually uh",
    "start": "1428659",
    "end": "1434720"
  },
  {
    "text": "cooperating with with the cncf environmental sustainability group that's trying to solve issues related to",
    "start": "1434720",
    "end": "1441320"
  },
  {
    "text": "this to this to this program so we have done a POC actually uh that will integrate with Co emission",
    "start": "1441320",
    "end": "1450020"
  },
  {
    "text": "intensity or power consumption or similar data and use the data to actually modify the cadaskaring decision",
    "start": "1450020",
    "end": "1457640"
  },
  {
    "text": "so in this in this uh in this specific POC what we have done is that based on",
    "start": "1457640",
    "end": "1463340"
  },
  {
    "text": "the carbon impact we can we can cap the actual maximum",
    "start": "1463340",
    "end": "1468380"
  },
  {
    "text": "replica numbers that we will we will Auto scale to so basically if if the if the if the if the carbon stuff is is",
    "start": "1468380",
    "end": "1476000"
  },
  {
    "text": "looking very bad so let's not scale to 100 replicas but just you know to to for example 10 or 90 replicas or something",
    "start": "1476000",
    "end": "1482840"
  },
  {
    "text": "like that so this is the POC that we have done uh it is not this approach it is like a separate controller but we",
    "start": "1482840",
    "end": "1489320"
  },
  {
    "text": "would like to see in the future something like this directly in the in the scaled object you can check the the",
    "start": "1489320",
    "end": "1494960"
  },
  {
    "text": "POC here there are leaks and links and recordings and there are also some some talks that keep going about about this",
    "start": "1494960",
    "end": "1501440"
  },
  {
    "text": "stuff so you can you can check them in the schedule yeah and all the slides that I'm showing here are uploaded to to",
    "start": "1501440",
    "end": "1507200"
  },
  {
    "text": "scad as well so you can click the links if you want this is something I I really love this is something that has been uh",
    "start": "1507200",
    "end": "1513140"
  },
  {
    "text": "I I've spent a lot of time in in the serverless space and I know a long time ask has been hey I love the elastic",
    "start": "1513140",
    "end": "1519080"
  },
  {
    "text": "scale of my serverless compute I would love to be able to control that scale so that I'm utilizing energy efficiently",
    "start": "1519080",
    "end": "1526159"
  },
  {
    "text": "maybe if the data center is under heavy load or there's a lot of carbon emission delay like don't schedule my jobs right",
    "start": "1526159",
    "end": "1531440"
  },
  {
    "text": "now this notion of being able to have scale rules not just based on the events themselves but the environmental impact",
    "start": "1531440",
    "end": "1537740"
  },
  {
    "text": "in the environmental environment that those are running in I is super important so all of these things that",
    "start": "1537740",
    "end": "1542900"
  },
  {
    "text": "we've talked about in terms of what's next all of these are great opportunities for contributors",
    "start": "1542900",
    "end": "1548000"
  },
  {
    "text": "huge thanks to the community I've been blown away if you go to cada.sh and you just start scrolling about halfway",
    "start": "1548000",
    "end": "1554600"
  },
  {
    "text": "through you'll just hit a wall of logos of just like all of the amazing companies and people and organizations",
    "start": "1554600",
    "end": "1560659"
  },
  {
    "text": "who've been involved in helping make K to great so for those of you who are here who are a part of that Community",
    "start": "1560659",
    "end": "1566000"
  },
  {
    "text": "already who've been contributing opening issues providing feedback huge thank you",
    "start": "1566000",
    "end": "1571100"
  },
  {
    "text": "from sibionek myself and the rest of the maintainers who can't be here and for those of you who are interested this is",
    "start": "1571100",
    "end": "1576380"
  },
  {
    "text": "a really great project to go collaborate with because it really is it just does one thing it's not a full-fledged",
    "start": "1576380",
    "end": "1581840"
  },
  {
    "text": "serverless platform it's not doing TLS termination and like that's great there's a space for that",
    "start": "1581840",
    "end": "1588200"
  },
  {
    "text": "go contribute to those as well but Kate it's like I'm just going to do scaling I'm going to do it really really well I'm going to make sure you show up to",
    "start": "1588200",
    "end": "1594260"
  },
  {
    "text": "the party with the right amount of pizzas and everyone is happy so thanks everyone so much for your help and and",
    "start": "1594260",
    "end": "1599480"
  },
  {
    "text": "with this and I think at that point yes before we go to questions please submit your feedback on the",
    "start": "1599480",
    "end": "1606980"
  },
  {
    "text": "session so if you want to snap the QR code and let us know what you thought hopefully they'll invite us back for",
    "start": "1606980",
    "end": "1613340"
  },
  {
    "text": "more kubecons in the future we can share some of the more exciting features or let us know if there's things you'd like",
    "start": "1613340",
    "end": "1618860"
  },
  {
    "text": "to see done differently yeah thank you very much and do you have any questions we'll go right here in the front I don't",
    "start": "1618860",
    "end": "1625460"
  },
  {
    "text": "see any mics so just speak up and then I'll repeat it so that everybody can hear oh oh yeah or if Savannah wants to",
    "start": "1625460",
    "end": "1630980"
  },
  {
    "text": "run around uh actually I have a question yeah my name is Dan and I have a questions like",
    "start": "1630980",
    "end": "1637640"
  },
  {
    "text": "what is the interval that you set for the appropriate Prometheus server for like a scraping the metrics because uh",
    "start": "1637640",
    "end": "1645500"
  },
  {
    "text": "usually I use like 15 seconds and that impacts scaling",
    "start": "1645500",
    "end": "1650900"
  },
  {
    "text": "sorry another questions about like creative how how does it compare to K",
    "start": "1650900",
    "end": "1656000"
  },
  {
    "text": "native sure uh so all uh activity you can answer",
    "start": "1656000",
    "end": "1661419"
  },
  {
    "text": "both questions yes go for it uh so the polling interval that's that's there",
    "start": "1661419",
    "end": "1666860"
  },
  {
    "text": "that's for the activation phase only that's only for the operator so this is for the initial initial skating so this",
    "start": "1666860",
    "end": "1673159"
  },
  {
    "text": "is for the zero to one then it is up to HPA to ask for for this interval and HPA",
    "start": "1673159",
    "end": "1679520"
  },
  {
    "text": "the default value is finalist taken 15 seconds but what we are trying to do we are with the with the cache we would",
    "start": "1679520",
    "end": "1686000"
  },
  {
    "text": "like to also also create like this interval for for the HPA also so we will",
    "start": "1686000",
    "end": "1691220"
  },
  {
    "text": "like send the metrics only in the specific time but at the moment it is just for the uh for the initial one yeah",
    "start": "1691220",
    "end": "1697760"
  },
  {
    "text": "and you can see like here I for my demo I said ask every five seconds to rabbitmq you can configure this to 15",
    "start": "1697760",
    "end": "1704299"
  },
  {
    "text": "seconds 30 seconds 60 seconds but today we're going to explain once it goes to one then the HPA will just ask on",
    "start": "1704299",
    "end": "1710539"
  },
  {
    "text": "something period like what's the latest metric and Kata will go and fetch it and bring it back for the HPA yeah and the",
    "start": "1710539",
    "end": "1716840"
  },
  {
    "text": "other question yeah it was like it was like yeah that's a good question I quite",
    "start": "1716840",
    "end": "1722659"
  },
  {
    "text": "often get this question um it could be a long talk but I'm trying to do it in a short way so",
    "start": "1722659",
    "end": "1728720"
  },
  {
    "text": "basically I don't see anything as a as a like competitors but it's more like a",
    "start": "1728720",
    "end": "1734419"
  },
  {
    "text": "complimentary tool so because uh in a messaging systems there could be like two ways how to deliver data it could be",
    "start": "1734419",
    "end": "1741020"
  },
  {
    "text": "pool based approach or push-based approach so the pull-based approach is basically that the application needs to",
    "start": "1741020",
    "end": "1746539"
  },
  {
    "text": "handle the connection to the external source so let's say we have application that talks to the rabbitmq so in my",
    "start": "1746539",
    "end": "1752000"
  },
  {
    "text": "application I need to open the connection and manage all the data delivery to the application this is the full based approach so this is where",
    "start": "1752000",
    "end": "1758419"
  },
  {
    "text": "cada works on the other hand the push-based approach is that the application doesn't need to care about",
    "start": "1758419",
    "end": "1764600"
  },
  {
    "text": "like opening the connection Etc it is just waiting for incoming requests so both approaches as like pros and cons",
    "start": "1764600",
    "end": "1771380"
  },
  {
    "text": "you know it depends on the on the use case that you have so for example if you would like to Auto scale your",
    "start": "1771380",
    "end": "1777440"
  },
  {
    "text": "application based on incoming HTTP requests because HTTP requests by its nature are push based it's very hard to",
    "start": "1777440",
    "end": "1785059"
  },
  {
    "text": "achieve it with uh with uh with with HPA and with Canada with this approach so in this case I would I would choose K",
    "start": "1785059",
    "end": "1790460"
  },
  {
    "text": "native but also K native and cada they are like it's just Auto scale we are",
    "start": "1790460",
    "end": "1796100"
  },
  {
    "text": "trying to do the auto scaling that simple uh with with Keda it's more like a serverless platform so you can do more",
    "start": "1796100",
    "end": "1802159"
  },
  {
    "text": "stuff you can do like separate configuration Eventing stuff so really depends on the on the use case it's our",
    "start": "1802159",
    "end": "1807799"
  },
  {
    "text": "complementary tools excellent yeah I think yeah back here like the",
    "start": "1807799",
    "end": "1813380"
  },
  {
    "text": "third or fourth I think was the second hand up at least when we asked for questions uh thanks I I have a question",
    "start": "1813380",
    "end": "1819679"
  },
  {
    "text": "about uh what's the suitable workload type uh that is",
    "start": "1819679",
    "end": "1826059"
  },
  {
    "text": "cater is most appropriate for because I assume those events in the event queue",
    "start": "1826059",
    "end": "1832760"
  },
  {
    "text": "should be homogeneous but what if they are not what if they are heterogeneous jobs and",
    "start": "1832760",
    "end": "1839419"
  },
  {
    "text": "um in your example there was like four jobs or four events handled by each pod",
    "start": "1839419",
    "end": "1846140"
  },
  {
    "text": "but what if it's not that even yeah so on this one it is like the the",
    "start": "1846140",
    "end": "1852080"
  },
  {
    "text": "the the ideal scenario for keita is where you can have horizontal scale",
    "start": "1852080",
    "end": "1857179"
  },
  {
    "text": "they're not like they're not having to uh depend on each other they're kind of",
    "start": "1857179",
    "end": "1863000"
  },
  {
    "text": "independently horizontally scalable and I would even say especially for scaled objects if processing a single message",
    "start": "1863000",
    "end": "1869840"
  },
  {
    "text": "can happen within some reasonable amount of time I don't know what the number you'd put on it like two to three",
    "start": "1869840",
    "end": "1875360"
  },
  {
    "text": "minutes or something cada is great when you have longer jobs like let's say you want to transcode a",
    "start": "1875360",
    "end": "1880940"
  },
  {
    "text": "video and that transcoding job might take three hours that's still where you want to use the scale jobs pattern where",
    "start": "1880940",
    "end": "1886940"
  },
  {
    "text": "you're spinning up one job per video in this example and spinning it up so if you do have a scenario that might be a",
    "start": "1886940",
    "end": "1893240"
  },
  {
    "text": "little bit more uh heterogeneous as you mentioned like there's exceptions here and there I guess the only other one I",
    "start": "1893240",
    "end": "1898880"
  },
  {
    "text": "would mention too and this came up recently on our slack Channel Shameless plug to code of the slack Channel somebody was like oh can I Scale based",
    "start": "1898880",
    "end": "1906799"
  },
  {
    "text": "on the content of the message so it's not just that I want to know are there a thousand messages to be processed but I",
    "start": "1906799",
    "end": "1913880"
  },
  {
    "text": "want to know are there a thousand messages and based on the content to your point like maybe one of those message takes three hours and the other",
    "start": "1913880",
    "end": "1920120"
  },
  {
    "text": "messages only take three seconds Kata today isn't gonna know the the intricacies of that gesture you're going",
    "start": "1920120",
    "end": "1927020"
  },
  {
    "text": "to need to put something else in the middle yeah I know K native this is basically the use case 4K native I would",
    "start": "1927020",
    "end": "1932600"
  },
  {
    "text": "say a community Eventing because you need to know the the specific what's inside the data actually because nature",
    "start": "1932600",
    "end": "1938000"
  },
  {
    "text": "doesn't know about Rita it doesn't care about data it doesn't handle the data delivery so I would use some different",
    "start": "1938000",
    "end": "1943399"
  },
  {
    "text": "systems like anything or any other Eventing solution that requires more complex logic yeah so some variance is",
    "start": "1943399",
    "end": "1949279"
  },
  {
    "text": "okay but if it's like two hours for one message and 30 seconds for the next kata's gonna have a hard time figuring",
    "start": "1949279",
    "end": "1954860"
  },
  {
    "text": "not the right stuff today today okay I think we have time for one maybe two more questions see when I call it you",
    "start": "1954860",
    "end": "1960860"
  },
  {
    "text": "choose I don't know who would have been there so how do you scale Keda itself",
    "start": "1960860",
    "end": "1966740"
  },
  {
    "text": "ah yes you don't scale [Laughter]",
    "start": "1966740",
    "end": "1971779"
  },
  {
    "text": "the scaler needs no scale yeah uh yeah this is this is issue because we already are relying on kubernetes API and",
    "start": "1971779",
    "end": "1979520"
  },
  {
    "text": "unfortunately there could be only one and one like let's say thing that",
    "start": "1979520",
    "end": "1984679"
  },
  {
    "text": "connects to the tourist endpoint providing it's providing the the data you know so there could be one only one",
    "start": "1984679",
    "end": "1989899"
  },
  {
    "text": "metric server per cluster so we can have multiple replicas of the very same very same metric server but you cannot plug",
    "start": "1989899",
    "end": "1996080"
  },
  {
    "text": "any other tool so you can you can scale up the number of metric servers but uh kubernetes by default always ask the one",
    "start": "1996080",
    "end": "2002980"
  },
  {
    "text": "you know so it's we are trying to we are trying to do this like the scale internally so",
    "start": "2002980",
    "end": "2009460"
  },
  {
    "text": "basically we are spawning more processes Etc but um I don't see any big reason for for the for the like actual scaling of Cato",
    "start": "2009460",
    "end": "2017019"
  },
  {
    "text": "yep the primary bottleneck though is that custom metrics adapter you can only have one uh and it's okay that's cada",
    "start": "2017019",
    "end": "2023620"
  },
  {
    "text": "even if we spent multiple processes that's still uh uh yeah this is a usual ask that I would",
    "start": "2023620",
    "end": "2028899"
  },
  {
    "text": "like to have multi-pocket installations in my cluster that's not possible because of this limitation that you can have only one metric server so even if I",
    "start": "2028899",
    "end": "2035559"
  },
  {
    "text": "have like multiple installations they will share the very same metric server we are trying to solve this those Upstream so so to have some kind of",
    "start": "2035559",
    "end": "2042100"
  },
  {
    "text": "proxy in in between like between the end point and but it's still still stuff that we need to figure out how to do",
    "start": "2042100",
    "end": "2047860"
  },
  {
    "text": "that so if anyone here has contacts with the custom metrics adapter team",
    "start": "2047860",
    "end": "2053020"
  },
  {
    "text": "um yes I know we've talked with them in the past but so one more it's got to be a short one",
    "start": "2053020",
    "end": "2058599"
  },
  {
    "text": "before we get kicked out",
    "start": "2058599",
    "end": "2061740"
  },
  {
    "text": "yeah is there a time you've switched to using gcp's Cloud functions or AWS",
    "start": "2063820",
    "end": "2069820"
  },
  {
    "text": "lambdas uh oh so this is just an opinion piece at this point because neither of",
    "start": "2069820",
    "end": "2075580"
  },
  {
    "text": "these necessarily would relate directly to cada gcp Cloud functions or AWS Lambda you know what I expect I used to",
    "start": "2075580",
    "end": "2081878"
  },
  {
    "text": "be the the product lead for Azure function so I would have said neither Azure functions now I'm in a multi-cloud",
    "start": "2081879",
    "end": "2088540"
  },
  {
    "text": "snowflake world and I say they're all beautiful they're great I would say choose the function provider",
    "start": "2088540",
    "end": "2095080"
  },
  {
    "text": "where most of your other stuff is so if you're already using gcp for a bunch of other stuff go use the gcp function",
    "start": "2095080",
    "end": "2101080"
  },
  {
    "text": "thing if you're using AWS go use the AWS thing if you're not sure try to get it to work on snowflake that's all I'll say",
    "start": "2101080",
    "end": "2107380"
  },
  {
    "text": "we don't have Cloud functions but just do it anyways thank you thanks so much everyone we'll be around",
    "start": "2107380",
    "end": "2114040"
  },
  {
    "text": "they'll probably kick us out so if you season Ecker myself around let us know but thank you again so much for coming",
    "start": "2114040",
    "end": "2119320"
  },
  {
    "text": "this",
    "start": "2119320",
    "end": "2121500"
  }
]
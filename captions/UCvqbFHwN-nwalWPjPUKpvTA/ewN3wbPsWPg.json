[
  {
    "text": "a warm welcome to cucon 2023 to this beautiful city of Chicago I'm so happy",
    "start": "240",
    "end": "5520"
  },
  {
    "text": "to be here and I'm grateful to each one of you for choosing to be at my session today we are about to explore how",
    "start": "5520",
    "end": "13719"
  },
  {
    "text": "kubernetes and inflence decision trees can help us efficiently scale gen inferencing for solving complex",
    "start": "13719",
    "end": "20000"
  },
  {
    "text": "reasoning problems so without further Ado let's Jump Right In we have an exciting exciting journey ahead and",
    "start": "20000",
    "end": "26080"
  },
  {
    "text": "plenty to share a quick introduction about me uh i c ly work as a principal",
    "start": "26080",
    "end": "31199"
  },
  {
    "text": "Solutions architect at for AWS and my daily Adventures include collaborating",
    "start": "31199",
    "end": "36520"
  },
  {
    "text": "and co- innovating with some of our largest isv customers right in the heart of gen world the San Francisco Bay Area",
    "start": "36520",
    "end": "44160"
  },
  {
    "text": "previously I worked uh with Cisco with the emerging technology and incubation team uh I believe it's now called Cisco",
    "start": "44160",
    "end": "50960"
  },
  {
    "text": "out shift anyone from Cisco here great team I loved working there I",
    "start": "50960",
    "end": "56680"
  },
  {
    "text": "miss you guys so my journey with kubernetes goes all the way back to 2017 uh at UPS where I architecturally",
    "start": "56680",
    "end": "65080"
  },
  {
    "text": "established UPS's first private Cloud using kubernetes with open shift any open shift guys here Awesome Again great",
    "start": "65080",
    "end": "72799"
  },
  {
    "text": "product I learned a lot from you guys back then I was a student uh so",
    "start": "72799",
    "end": "78159"
  },
  {
    "text": "exploring the intersection of kubernetes and machine learning has been an active area of interest for me since back in",
    "start": "78159",
    "end": "85360"
  },
  {
    "text": "2021 at coupon at La I talked about the inter ction of kubernetes and AI That's",
    "start": "85360",
    "end": "92840"
  },
  {
    "text": "a link to my talk and a Blog and today I'm thrilled to talk about my",
    "start": "92840",
    "end": "98280"
  },
  {
    "text": "exploration into the world of kubernetes and jni you guys ready all right so to kick things off",
    "start": "98280",
    "end": "106360"
  },
  {
    "text": "I'll start with a simple math problem if somebody has downloaded my slides U uh you might be able to get a sneak peek at",
    "start": "106360",
    "end": "112880"
  },
  {
    "text": "that uh but it's still a surprise um so I'll start with a a math game from there",
    "start": "112880",
    "end": "119000"
  },
  {
    "text": "we will examine the the challenges that uh the most state-of art large language models today have in",
    "start": "119000",
    "end": "125640"
  },
  {
    "text": "solving such complex problems and we'll see how a prompting strategy called tree of thoughts approaches such complex",
    "start": "125640",
    "end": "132520"
  },
  {
    "text": "reasoning problems then I'll talk about the efficiency and complexity challenges uh and how to use various software",
    "start": "132520",
    "end": "139040"
  },
  {
    "text": "patterns and hosting this tree of thought strategy on kubernetes can make tree of thought strategy not just",
    "start": "139040",
    "end": "144760"
  },
  {
    "text": "functional but practical and efficient and what better way to bring it to life then with a live demo I'll",
    "start": "144760",
    "end": "151120"
  },
  {
    "text": "show you a tree of thought strategy solving a complex math problem on a kubernetes cluster so to wrap things up",
    "start": "151120",
    "end": "157920"
  },
  {
    "text": "I share some of my concluding thoughts on the future of tree of thought and its",
    "start": "157920",
    "end": "163640"
  },
  {
    "text": "Evolution so in order to understand uh the core problem here uh we'll start with the math game ready for that all",
    "start": "163640",
    "end": "171879"
  },
  {
    "text": "right so take a look at those four numbers there on the screen",
    "start": "171879",
    "end": "177120"
  },
  {
    "text": "your the problem you have to solve is to take these four numbers and use any four basic arithmetic operators addition",
    "start": "177120",
    "end": "183480"
  },
  {
    "text": "multiplication subtraction or division to get 24 seems pretty straightforward",
    "start": "183480",
    "end": "189400"
  },
  {
    "text": "right give it a try all right let's get you the answer it's pretty easy you just add all the",
    "start": "189400",
    "end": "195440"
  },
  {
    "text": "four numbers together and you'll get 24 um it's an easy start of the session but here is when things get interesting so",
    "start": "195440",
    "end": "201799"
  },
  {
    "text": "let's see how the most advanced large language models uh out there fair with",
    "start": "201799",
    "end": "207560"
  },
  {
    "text": "this simple math reasoning challenge we're talking about gp4 B cloud from",
    "start": "207560",
    "end": "213720"
  },
  {
    "text": "anthropic the Giants in the world of generative AI That's The Prompt that you're seeing on the screen so we'll",
    "start": "213720",
    "end": "219040"
  },
  {
    "text": "play a game we'll see how chat GPT 4 tries to uh answer",
    "start": "219040",
    "end": "224120"
  },
  {
    "text": "this so a quick show of hands who here thinks GPT 4 can solve this ma little math challenge instantly and",
    "start": "224120",
    "end": "232040"
  },
  {
    "text": "accurately instantly well I'm surprised there are very pessimistic people out",
    "start": "232720",
    "end": "238879"
  },
  {
    "text": "there come on it is GPT 4 you know how much money open a and Microsoft invested in that billions of dollars and they",
    "start": "238879",
    "end": "245280"
  },
  {
    "text": "can't add four numbers all right well let's give it a try the proof is in the Ping okay so",
    "start": "245280",
    "end": "252879"
  },
  {
    "text": "here we go so I'm going to start this challenge so I'm going to",
    "start": "252879",
    "end": "259120"
  },
  {
    "text": "first enter this prompt and you can see chart GPT 4 this is not 3.5 this is four",
    "start": "259120",
    "end": "265800"
  },
  {
    "text": "this is the state of art is trying to solve it okay it's arrange this well that answer is clearly wrong oh you",
    "start": "265800",
    "end": "271919"
  },
  {
    "text": "tried to correct it oh it's still way off that doesn't make any sense right okay all right so let's not",
    "start": "271919",
    "end": "280680"
  },
  {
    "text": "be let's not jump to conclusions yet let's see what Bard from Google all powerful Google and Cloud do so I'm",
    "start": "280680",
    "end": "286919"
  },
  {
    "text": "going to give the exact same prompt to bod and while that's happening we'll try",
    "start": "286919",
    "end": "293360"
  },
  {
    "text": "with with Cloud okay so they are doing the exact same thing as GPT before we give the",
    "start": "293360",
    "end": "301560"
  },
  {
    "text": "prompt and let's see what happens so anthropic okay so you can",
    "start": "301560",
    "end": "307120"
  },
  {
    "text": "clearly see B has come up with some nonsensical answer uh so does cloud no",
    "start": "307120",
    "end": "313039"
  },
  {
    "text": "better all right let's give them another try to be fair let's try it again let's see maybe another chance they can get",
    "start": "313039",
    "end": "318360"
  },
  {
    "text": "the answer right well",
    "start": "318360",
    "end": "324080"
  },
  {
    "text": "no all right so there you go all three",
    "start": "324080",
    "end": "329560"
  },
  {
    "text": "most advanced large language models are not able to solve the simple problem that I guess a third grader or a fifth grader can do in mentally in their head",
    "start": "329560",
    "end": "337120"
  },
  {
    "text": "okay so all of those are incorrect it seems",
    "start": "337120",
    "end": "342960"
  },
  {
    "text": "that something is not right here why can't they answer this simple math using problem exploring why that happens can",
    "start": "342960",
    "end": "350000"
  },
  {
    "text": "give us a fascinating insight into the state of the large language models and uh how they work but that will require",
    "start": "350000",
    "end": "357120"
  },
  {
    "text": "us to go into into examining the fundamental building blocks of large",
    "start": "357120",
    "end": "362160"
  },
  {
    "text": "language models so bear with me a little bit of computer science here so I will try to explain it the best I can it is a",
    "start": "362160",
    "end": "368639"
  },
  {
    "text": "complex topic so when we talk about current large language models like gp4 Cloud V2 or Palm 2 they fall in the",
    "start": "368639",
    "end": "375800"
  },
  {
    "text": "category of self attention based Auto regressive llms or ar llms which are a",
    "start": "375800",
    "end": "381280"
  },
  {
    "text": "type of decoder only Transformer variant so you can read about the various variants in the Transformers",
    "start": "381280",
    "end": "386400"
  },
  {
    "text": "architectures they come from a branch that are decoder only because of that these llms typically",
    "start": "386400",
    "end": "392520"
  },
  {
    "text": "generate a token based on the preceding sequence of tokens without any backward",
    "start": "392520",
    "end": "398360"
  },
  {
    "text": "editing so this sequential processing uh while effective for doing many tasks like",
    "start": "398360",
    "end": "405840"
  },
  {
    "text": "chats and asking all kinds of questions it poses a significant challenge when it comes to problems that require",
    "start": "405840",
    "end": "410919"
  },
  {
    "text": "multi-step reasoning or exploring different continuations within a single thought process like the math reasoning",
    "start": "410919",
    "end": "416520"
  },
  {
    "text": "problem that we saw in the previous slide moreover these models do not possess a feedback loop they do not have",
    "start": "416520",
    "end": "422199"
  },
  {
    "text": "the capability to go and selfcheck their work iterate upon it perform logical correctness checks and generate as they",
    "start": "422199",
    "end": "428599"
  },
  {
    "text": "generate text and this can amplify small errors potentially leading to larger mistakes as the solution",
    "start": "428599",
    "end": "435199"
  },
  {
    "text": "progresses so we saw this happen in the GPD example before as it was trying to correct itself it was getting into a",
    "start": "435199",
    "end": "440720"
  },
  {
    "text": "bigger and bigger hole and getting more and more long",
    "start": "440720",
    "end": "444960"
  },
  {
    "text": "answers so once llms uh uh such alms they cannot backtrack they cannot",
    "start": "446360",
    "end": "451720"
  },
  {
    "text": "correct a mistake and start the process again now this is St contrast to how we humans solve problems we often involve a",
    "start": "451720",
    "end": "459960"
  },
  {
    "text": "humanistic guided solution approach wherein we navigate through a chain of of of complex problems with relative",
    "start": "459960",
    "end": "466240"
  },
  {
    "text": "ease U and understanding these limitations is crucial as we continue to develop and Implement these large",
    "start": "466240",
    "end": "472199"
  },
  {
    "text": "language models in various domains now let's explore three prompt engineering strategies that have shown a",
    "start": "472199",
    "end": "478879"
  },
  {
    "text": "lot of prompt promise in making these lolms reason more like humans especially for these complex math",
    "start": "478879",
    "end": "486080"
  },
  {
    "text": "problems the first strategy here is called The Chain of Thought strategy uh this strategy takes a sequential",
    "start": "486080",
    "end": "492280"
  },
  {
    "text": "approach and works through steps in an intermediate manner uh while it offers a",
    "start": "492280",
    "end": "497639"
  },
  {
    "text": "clearer path for complex tasks uh and enhances transparency you can see all",
    "start": "497639",
    "end": "502840"
  },
  {
    "text": "the the chain of thoughts as it's solving the problem it can sometimes lead to ambiguous thought decomposition the second St stry that",
    "start": "502840",
    "end": "509800"
  },
  {
    "text": "can be used here is called The Chain of Thought with self-consistency this is where we're looking at an ensemble",
    "start": "509800",
    "end": "515518"
  },
  {
    "text": "method as the algorithm generates multiple independent chains of thoughts and then selects the most frequently",
    "start": "515519",
    "end": "520919"
  },
  {
    "text": "occurring output it's a robust strategy it works uh but it does not explore",
    "start": "520919",
    "end": "526040"
  },
  {
    "text": "alternate paths within a single chain of thought and lastly we have the tree of thought strategy the core focus of",
    "start": "526040",
    "end": "532240"
  },
  {
    "text": "today's talk imagine navigating through a vast tree of reasoning paths with partial",
    "start": "532240",
    "end": "538760"
  },
  {
    "text": "solution in a problem space this but that exploring that entire combinatorial",
    "start": "538760",
    "end": "545279"
  },
  {
    "text": "problem space requires lot of sophisticated and efficient research algorithms to explore all the problem",
    "start": "545279",
    "end": "550680"
  },
  {
    "text": "space it allows us to do locally explore a thought process and globally explore",
    "start": "550680",
    "end": "556320"
  },
  {
    "text": "backtracking and look Ahad techniques well this strategy has shown the highest success when it comes to solving the",
    "start": "556320",
    "end": "563040"
  },
  {
    "text": "reasoning problems such as the one we started with and that's why will take a deep",
    "start": "563040",
    "end": "569920"
  },
  {
    "text": "dive into the tree of thought strategy a powerful framework introduced independently by researchers Yao and log",
    "start": "569920",
    "end": "577560"
  },
  {
    "text": "back in May 2023 so it's not that old it's about 6 months back I have a link to all the research",
    "start": "577560",
    "end": "583200"
  },
  {
    "text": "papers that this talk is based on in the last slide so you can read these papers U they're not that fun to read but you",
    "start": "583200",
    "end": "589640"
  },
  {
    "text": "you need to patiently look through all the math and you'll understand how they built up this this strategy it is just",
    "start": "589640",
    "end": "594720"
  },
  {
    "text": "fascinating it took me a while to crack this thing in my head to build my demo for this",
    "start": "594720",
    "end": "600040"
  },
  {
    "text": "uh so a tree of thought builds a reasoning a reasoning",
    "start": "600040",
    "end": "606560"
  },
  {
    "text": "tree and each node of the tree represents a partial solution it's like",
    "start": "606560",
    "end": "611600"
  },
  {
    "text": "it's building this whole mental map and trying to solve the problems as intermediate steps on the Node each node",
    "start": "611600",
    "end": "617560"
  },
  {
    "text": "is that on the tree it represents a partial thought then each thought or idea branches out creating a treel like",
    "start": "617560",
    "end": "623880"
  },
  {
    "text": "structure of interconnected thoughts this makes a lot of sense when you when you see the demo U of",
    "start": "623880",
    "end": "631320"
  },
  {
    "text": "this uh but I'll walk you through this high level strategy it is way more complicated than it is but U this is a",
    "start": "631320",
    "end": "638320"
  },
  {
    "text": "good start this is the best I could do I had to spend a lot of hours trying to find the best visual to represent this I",
    "start": "638320",
    "end": "644000"
  },
  {
    "text": "couldn't find this in any of the research papers so this took me a while to get",
    "start": "644000",
    "end": "648959"
  },
  {
    "text": "right so the thought generation in tree of thought uh happens from these nodes and each partial thought on a node is is",
    "start": "650000",
    "end": "657440"
  },
  {
    "text": "generated and and it's used to explore four potential Solutions then each partial thought",
    "start": "657440",
    "end": "663320"
  },
  {
    "text": "which can be a potential solution to a problem is sampled and evaluated using",
    "start": "663320",
    "end": "668440"
  },
  {
    "text": "self-reflection by that I mean we ask the large language model to evaluate the",
    "start": "668440",
    "end": "673920"
  },
  {
    "text": "validity of its own thought so now you ask it a question to solve in steps then each step is given back to the model",
    "start": "673920",
    "end": "679680"
  },
  {
    "text": "saying now reason over whether these particular steps can get you to an answer and these conversations start happening and expanding as a tree that's",
    "start": "679680",
    "end": "685839"
  },
  {
    "text": "the basic strategy here the llm then evaluates each thought",
    "start": "685839",
    "end": "693720"
  },
  {
    "text": "classifies them based on the likelihood of that particular partial solution in",
    "start": "693720",
    "end": "700399"
  },
  {
    "text": "solving the problem the evaluation is then used as a feedback signal for the Tre search algorithm influencing what",
    "start": "700399",
    "end": "706560"
  },
  {
    "text": "branches to promote and what branches to prune now the partial thought chains",
    "start": "706560",
    "end": "713240"
  },
  {
    "text": "that score the the highest are validated for correctness of the complete solution",
    "start": "713240",
    "end": "718920"
  },
  {
    "text": "ution so now you have partial thoughts and you use a large language model to give you some indication of whether or",
    "start": "718920",
    "end": "724120"
  },
  {
    "text": "not that can lead to an answer once you find the highest ranking thoughts you then send them for an entire proof",
    "start": "724120",
    "end": "730920"
  },
  {
    "text": "saying that again back to the large language model can this particular Chain of Thought give you the answer now yes",
    "start": "730920",
    "end": "736839"
  },
  {
    "text": "or no so that's what the validator",
    "start": "736839",
    "end": "741279"
  },
  {
    "text": "does and then uh the the the tree the",
    "start": "744959",
    "end": "750160"
  },
  {
    "text": "tree search algorithm is going through these these nodes asking questions ranking them sorting them pruning",
    "start": "750160",
    "end": "756040"
  },
  {
    "text": "branches expanding branches uh and it and the tree search algorithm is decides",
    "start": "756040",
    "end": "762160"
  },
  {
    "text": "the tree strategy uh from the feedback that comes from the evaluations we are the orchestrator and depending on the",
    "start": "762160",
    "end": "768560"
  },
  {
    "text": "nature of the problem we can choose from various research algorithms such as bread first depth first best first best",
    "start": "768560",
    "end": "775440"
  },
  {
    "text": "first search or AAR I'm also trying trying to do a Monte simulation which is",
    "start": "775440",
    "end": "781079"
  },
  {
    "text": "which is an interesting way to to look at this problem but I haven't been able to to get it right yet",
    "start": "781079",
    "end": "786920"
  },
  {
    "text": "um and then finally the orchestrator the orchestrator is sort of a control plane",
    "start": "786920",
    "end": "792600"
  },
  {
    "text": "guiding the search process it facilitates multi- around conversations with large language models providing hints and suggestions to the tree search",
    "start": "792600",
    "end": "798360"
  },
  {
    "text": "algorithm to steer its trajectory it ensures that a rich diversity of potential thoughts get gets explored it",
    "start": "798360",
    "end": "804920"
  },
  {
    "text": "also utilizes backtracking and look ahead techniques to make Global choices ultimately identifying the most",
    "start": "804920",
    "end": "810320"
  },
  {
    "text": "promising solution candidates that's the strategy in Nell",
    "start": "810320",
    "end": "816399"
  },
  {
    "text": "but we won't stop there I will actually take the math problem that we saw in the earlier Slide the the the one where we",
    "start": "816399",
    "end": "822360"
  },
  {
    "text": "to arrange 1 1 1 11 1 111 and we'll see how this strategy",
    "start": "822360",
    "end": "830000"
  },
  {
    "text": "solves that math problem so it starts by representing the problem as I",
    "start": "830000",
    "end": "836120"
  },
  {
    "text": "said as a tree data structure and then using this tree using a Tre search",
    "start": "836120",
    "end": "841199"
  },
  {
    "text": "algorithm so data structure is tree then we use a Tre search algorithm to find the correct solution the tree search structure",
    "start": "841199",
    "end": "848519"
  },
  {
    "text": "starts with the root node representing the problem so in our case the problem",
    "start": "848519",
    "end": "854079"
  },
  {
    "text": "was take 1 1 11 11 and then arrange it to get 24 so that is used as an input",
    "start": "854079",
    "end": "860360"
  },
  {
    "text": "and this input is a wrapped in a prompt and that is then",
    "start": "860360",
    "end": "865440"
  },
  {
    "text": "used to create new new new branches of the tree so the thought generation works by",
    "start": "865440",
    "end": "871480"
  },
  {
    "text": "taking this input node and then wrapping this with a prompt and then asking the llm the large",
    "start": "871480",
    "end": "877680"
  },
  {
    "text": "language model you take that input that is in the in the red box that becomes",
    "start": "877680",
    "end": "883040"
  },
  {
    "text": "the pr for the large language model to respond back with a set of partial Solutions so you break this whole things",
    "start": "883040",
    "end": "888959"
  },
  {
    "text": "in steps you ask a large langage model I don't want a solution give me the steps that can get to a",
    "start": "888959",
    "end": "896839"
  },
  {
    "text": "solution",
    "start": "897680",
    "end": "900680"
  },
  {
    "text": "the orchestrator then takes this this this response from the the large language model and then sends it for",
    "start": "906040",
    "end": "911880"
  },
  {
    "text": "self- evaluation that that gauges the progress of each partial thought in solving the problem uh now pay attention",
    "start": "911880",
    "end": "918399"
  },
  {
    "text": "to this step here this step this is where the branching out the tree",
    "start": "918399",
    "end": "924440"
  },
  {
    "text": "expansion and the evaluation happens in the tree of thought strategy the response from the llm so you get in this",
    "start": "924440",
    "end": "931880"
  },
  {
    "text": "case multiple possible chains of of of partial Solutions so each chain is",
    "start": "931880",
    "end": "939560"
  },
  {
    "text": "split parted split and then each line of the response becomes the next branched",
    "start": "939759",
    "end": "945519"
  },
  {
    "text": "out node of this tree so now you see there are four nodes of this tree it has",
    "start": "945519",
    "end": "951880"
  },
  {
    "text": "expanded the self- evaluation of then each one of these nodes happens by wrapping that partial",
    "start": "953920",
    "end": "960759"
  },
  {
    "text": "thought at that node and asking the large language model to gauge the likelihood of the partial Solution on",
    "start": "960759",
    "end": "966160"
  },
  {
    "text": "that node in solving the game of 24 this is what I mean by self- evaluation of lm's own intermediate",
    "start": "966160",
    "end": "972319"
  },
  {
    "text": "thoughts the large language model for in this case responds by an evaluation",
    "start": "972319",
    "end": "978560"
  },
  {
    "text": "classification in this case it it it gives a classification of sure likely or",
    "start": "978560",
    "end": "985440"
  },
  {
    "text": "impossible so you take that classification and that classification is used to provide feedback to the",
    "start": "985440",
    "end": "990920"
  },
  {
    "text": "orchestrator on whether or not that particular branch has to move forward or should it be pruned or should it Branch",
    "start": "990920",
    "end": "997720"
  },
  {
    "text": "out then this thought generation thought evaluation Tango this",
    "start": "997720",
    "end": "1004120"
  },
  {
    "text": "continues until the search algorithm finds the highest ranking solution uh or hits the maximum tree",
    "start": "1004120",
    "end": "1010199"
  },
  {
    "text": "depth as specified in the tree of thought Hyer parameters so you can you can make this go forever you need to",
    "start": "1010199",
    "end": "1015880"
  },
  {
    "text": "elate the tree at some point otherwise you you will use too much of compute so you you you put a Max tree depth if you",
    "start": "1015880",
    "end": "1021600"
  },
  {
    "text": "can't find the solution then the tree of search algorithm just exits from",
    "start": "1021600",
    "end": "1026640"
  },
  {
    "text": "there so the highest ranking thoughts are then validated for the correctness",
    "start": "1026640",
    "end": "1032160"
  },
  {
    "text": "of the complete solution this is done by taking the highest ranking thought at that node wrapping it with a prompt and",
    "start": "1032160",
    "end": "1038038"
  },
  {
    "text": "then asking the large language model to judge if you can get an answer 24 now at this time the classification expected is",
    "start": "1038039",
    "end": "1044400"
  },
  {
    "text": "a binary Choice are you certain or is it impossible so there is no range here if",
    "start": "1044400",
    "end": "1049480"
  },
  {
    "text": "the answer comes back as certain then that node is tagged as the answer node and the search terminates or else it",
    "start": "1049480",
    "end": "1055480"
  },
  {
    "text": "continues to Branch further out so that is the search",
    "start": "1055480",
    "end": "1061880"
  },
  {
    "text": "algorithm solving uh the the math problem we had in the first few",
    "start": "1061880",
    "end": "1067360"
  },
  {
    "text": "slides now this all looks good uh in in these in these diagrams but how practical is it if I try to run it using",
    "start": "1067360",
    "end": "1074440"
  },
  {
    "text": "you know open open API openi API or Bedrock API or a large language model",
    "start": "1074440",
    "end": "1080480"
  },
  {
    "text": "like llama on your own compute node what is the cost to done this what is the complexity so I'm going to take some",
    "start": "1080480",
    "end": "1086360"
  },
  {
    "text": "deeper dive into that and this is from my own experience of trying to run",
    "start": "1086360",
    "end": "1091759"
  },
  {
    "text": "this so from a computation complexity perspective U this is the the both the",
    "start": "1093000",
    "end": "1100640"
  },
  {
    "text": "time and space complexity of all the comment research algorithms are polinomial uh they run in polinomial",
    "start": "1100640",
    "end": "1105679"
  },
  {
    "text": "time it looks exponential with their polinomial because B and D there uh the b b is the the branching factor and D is",
    "start": "1105679",
    "end": "1114200"
  },
  {
    "text": "the depth of the tree the max depth of the tree they're both constants so the time is polinomial um so you can see that as you",
    "start": "1114200",
    "end": "1122120"
  },
  {
    "text": "Branch out more or you go deeper in the tree you the things the amount of",
    "start": "1122120",
    "end": "1129039"
  },
  {
    "text": "computer required gets gets more and more uh and when you run and if I try to",
    "start": "1129039",
    "end": "1135159"
  },
  {
    "text": "run this uh tree of thought locally on my own compute",
    "start": "1135159",
    "end": "1141200"
  },
  {
    "text": "node within within 15 20 minutes I get C out a memory exception uh it just",
    "start": "1141200",
    "end": "1146280"
  },
  {
    "text": "require just too much of of of GPU memory to run this and if I use API such",
    "start": "1146280",
    "end": "1152640"
  },
  {
    "text": "as open AI I get rate limited and all kinds of throttles get put in within within a few minutes I burn out all of",
    "start": "1152640",
    "end": "1159280"
  },
  {
    "text": "my my kotas you know I've spent hundreds of dollars on this you know within few hours everything is gone and I still",
    "start": "1159280",
    "end": "1164880"
  },
  {
    "text": "don't have an answer uh so for example if I run a tree of search for this problem that we said",
    "start": "1164880",
    "end": "1171159"
  },
  {
    "text": "and I set the branching factor to three and the depth to four running this strategy takes 80 to 100 llm API calls",
    "start": "1171159",
    "end": "1179799"
  },
  {
    "text": "to make you can quickly see how expensive that can get and it's cost prohibitive so I mean I I I can't move",
    "start": "1179799",
    "end": "1185880"
  },
  {
    "text": "forward with that kind of of use of compute so what can we do to reduce this",
    "start": "1185880",
    "end": "1192480"
  },
  {
    "text": "complexity this is where we need to combine prompt engineering with software engineering and I'll explain this",
    "start": "1192480",
    "end": "1198840"
  },
  {
    "text": "approach in the language of patterns so in order to reduce the complexity time complexity we can engage",
    "start": "1198840",
    "end": "1205280"
  },
  {
    "text": "patterns such as uh function decomposition task parallelism uh to",
    "start": "1205280",
    "end": "1211240"
  },
  {
    "text": "break this whole to strategy into independent paralyzable units of execution for space complexity we can",
    "start": "1211240",
    "end": "1217520"
  },
  {
    "text": "use patterns such as distributed cache state externalization so as to reduce the memory pressure so now the state is",
    "start": "1217520",
    "end": "1223720"
  },
  {
    "text": "outside and it's broken into multiple units that run on the Clusters so the amount of memory required on a single note is is",
    "start": "1223720",
    "end": "1230080"
  },
  {
    "text": "reduced and then for your throughput limits uh to manage them we can use",
    "start": "1230080",
    "end": "1235919"
  },
  {
    "text": "pattern such as exponential back off or rate limiters that can track the requests made over",
    "start": "1235919",
    "end": "1241039"
  },
  {
    "text": "time and then for latency uh we can use patterns wherein we use event driven parallelism we can bring in load",
    "start": "1241039",
    "end": "1247280"
  },
  {
    "text": "balancing and asy processing so we we minimize use of synchronous blocking calls so every call every operation is",
    "start": "1247280",
    "end": "1254679"
  },
  {
    "text": "asynchronous but and if you run it on local nodes in start using the API that can improve latency uh but you need to",
    "start": "1254679",
    "end": "1261200"
  },
  {
    "text": "have enough AI acceleration and memory on the compute node and finally to reduce the cost you you need",
    "start": "1261200",
    "end": "1268799"
  },
  {
    "text": "to uh we can use patterns such as the operator pattern that I'll go in details in the next slides of and horizontal",
    "start": "1268799",
    "end": "1275440"
  },
  {
    "text": "Autos scaling patterns that can help you delegate all these aspects to underlying infrastructure and then you can reduce",
    "start": "1275440",
    "end": "1281919"
  },
  {
    "text": "the number of API calls by batching them there is a technique called request batching we can use that to pack to",
    "start": "1281919",
    "end": "1287679"
  },
  {
    "text": "package multiple calls into one request now these patterns look good on",
    "start": "1287679",
    "end": "1293480"
  },
  {
    "text": "the slide slide but how do we actually take this to strategy and build an efficient system out of this to do that",
    "start": "1293480",
    "end": "1300600"
  },
  {
    "text": "we break it into I will show a strategy that I used to break it into four different units so I break the entire",
    "start": "1300600",
    "end": "1307240"
  },
  {
    "text": "strategy into four uh decoupled paralyzable software modules and I call",
    "start": "1307240",
    "end": "1312840"
  },
  {
    "text": "them the thought generator the thought evaluator the solution validator and the orchestrator so as a as an example I'll",
    "start": "1312840",
    "end": "1318679"
  },
  {
    "text": "show you how to take the thought generator through this process the first step is to modularize the thought",
    "start": "1318679",
    "end": "1324360"
  },
  {
    "text": "generator component and here we first implement the functional aspects of D duplication prompting parsing and",
    "start": "1324360",
    "end": "1331120"
  },
  {
    "text": "interfacing with the llm and then we layer on the non-functional aspects such as batch prompting and trate limiting",
    "start": "1331120",
    "end": "1338159"
  },
  {
    "text": "then we externalize all the State Processing to all the state to a graph database and",
    "start": "1338159",
    "end": "1345000"
  },
  {
    "text": "all the communication and distributed caches outside these these components",
    "start": "1345000",
    "end": "1350799"
  },
  {
    "text": "the next step is to contain containerize it and package all the dependencies of the container and the last step is to",
    "start": "1350799",
    "end": "1356799"
  },
  {
    "text": "paralyze it using an orchestration platform so that's how the entire architectural process works taking this",
    "start": "1356799",
    "end": "1362960"
  },
  {
    "text": "complex strategy breaking into independent modules and then packaging each module as a container now when you",
    "start": "1362960",
    "end": "1368080"
  },
  {
    "text": "do that we end up with something like this uh if I had more time I would go",
    "start": "1368080",
    "end": "1373760"
  },
  {
    "text": "into the details of this this entire architecture but I'll walk through this quickly",
    "start": "1373760",
    "end": "1379960"
  },
  {
    "text": "cuz I really want to have some time for the demo this is how the entire platform looks like what you see",
    "start": "1381080",
    "end": "1388360"
  },
  {
    "text": "here is at the top is the externalized tree state in a graph database I'm using",
    "start": "1388360",
    "end": "1394000"
  },
  {
    "text": "Neo forj and at the bottom is the radius bus Which both acts as the pub sub layer",
    "start": "1394000",
    "end": "1399279"
  },
  {
    "text": "but it also is a distributed cache so all of these modules all the things that are happening in the St strategy are now",
    "start": "1399279",
    "end": "1404799"
  },
  {
    "text": "running independently asynchronously over events and wherever you you this this system sees that there is not",
    "start": "1404799",
    "end": "1410320"
  },
  {
    "text": "requirement of any any compute you you cut those calls out and you start to give more resources to to the notes that",
    "start": "1410320",
    "end": "1416480"
  },
  {
    "text": "require more",
    "start": "1416480",
    "end": "1419440"
  },
  {
    "text": "compute okay so now all of these boxes",
    "start": "1422559",
    "end": "1428200"
  },
  {
    "text": "and software modules there are so many layers of modules you need to think about load balancing and service",
    "start": "1428200",
    "end": "1434520"
  },
  {
    "text": "Discovery and interfacing how do you Tain the complexity now now in try to in trying",
    "start": "1434520",
    "end": "1439960"
  },
  {
    "text": "to solve the computation complexity now we ended up with operation complexity so the complexity moved to somewhere else",
    "start": "1439960",
    "end": "1445559"
  },
  {
    "text": "now how do you tame that that's where you bring in the big guns the kubernetes and and ker uh the first thing is to take all",
    "start": "1445559",
    "end": "1454400"
  },
  {
    "text": "the take all the modules that we just saw and I call them cubify them so by",
    "start": "1454400",
    "end": "1460279"
  },
  {
    "text": "that I mean is that you you express the desired state of the to environment in construct such as pod Services replica",
    "start": "1460279",
    "end": "1466360"
  },
  {
    "text": "sets deployment Etc and then you delegate all the aspects such as deployment config management self",
    "start": "1466360",
    "end": "1472840"
  },
  {
    "text": "healing service Discovery Road balancing to kubernetes and automated using a level level four kubernetes",
    "start": "1472840",
    "end": "1479919"
  },
  {
    "text": "operator and you'll see that in the demo too and the last step is to delegate all the autoscaling requirements to kada so",
    "start": "1479919",
    "end": "1486159"
  },
  {
    "text": "kada kind of acts as creates a homostasis of sorts wherein it adjusts the system resources by watching custom",
    "start": "1486159",
    "end": "1493520"
  },
  {
    "text": "metrics produced by the to system",
    "start": "1493520",
    "end": "1499320"
  },
  {
    "text": "the thought operator is the most important component of the system so I'll take a quick you'll take a quick look at what is happening under the hood",
    "start": "1499320",
    "end": "1504960"
  },
  {
    "text": "with this uh operator the first thing to to build this operator is to create what's called custom resources so for",
    "start": "1504960",
    "end": "1511200"
  },
  {
    "text": "each to module there is a custom resource that defines the desired state",
    "start": "1511200",
    "end": "1516240"
  },
  {
    "text": "of that module and then we write a custom controller for each of those to modules using the kubernetes operator",
    "start": "1516240",
    "end": "1523000"
  },
  {
    "text": "framework I used goang to code it the controller ensures that the observed state of a to module matches the desired",
    "start": "1523000",
    "end": "1529480"
  },
  {
    "text": "State defined in the custom resource the controller then takes corrective action to reconcile any discrepancies between",
    "start": "1529480",
    "end": "1535279"
  },
  {
    "text": "the observed State and the reside State and then uh we have the actual operator",
    "start": "1535279",
    "end": "1540799"
  },
  {
    "text": "when the operator gets deployed to the cluster and we instantiate the custom resources the custom controller SK can",
    "start": "1540799",
    "end": "1547159"
  },
  {
    "text": "using and then they use kubernetes API to create the required deployments and take over all the operational",
    "start": "1547159",
    "end": "1553640"
  },
  {
    "text": "aspects now here is the complete architecture I know there are a lot of boxes there but in to to quickly go over",
    "start": "1553640",
    "end": "1559399"
  },
  {
    "text": "that is you have the to operators for each of the four modules the thought generator the thought evaluator the",
    "start": "1559399",
    "end": "1565880"
  },
  {
    "text": "validator and they are monitoring all the custom Resources by watching any",
    "start": "1565880",
    "end": "1571120"
  },
  {
    "text": "discrepancies between the desired state that is that is specified in the CDs and the actual state by monitoring the to",
    "start": "1571120",
    "end": "1577200"
  },
  {
    "text": "environment and it reconciles any discrepancies kada on the other hand",
    "start": "1577200",
    "end": "1583200"
  },
  {
    "text": "even the custom operator could have done this too but kada is very sophisticated in scaling uh and and and being able to to manage",
    "start": "1583200",
    "end": "1590880"
  },
  {
    "text": "it much more efficiently uh so here kada is looking at custom metrics that are generated by",
    "start": "1590880",
    "end": "1596200"
  },
  {
    "text": "the orchestrator internally and then it scales the pods for each module",
    "start": "1596200",
    "end": "1602200"
  },
  {
    "text": "automatically depending on what's happening in the",
    "start": "1602200",
    "end": "1606520"
  },
  {
    "text": "environment all right so that's a lot of slides um lot of slideware let's see",
    "start": "1607640",
    "end": "1612720"
  },
  {
    "text": "some software is ready for the demo all right so uh I I have a live demo too but",
    "start": "1612720",
    "end": "1619440"
  },
  {
    "text": "there are so many moving Parts in this that is so I'm going to start with doing the infrastructure deployment first I",
    "start": "1619440",
    "end": "1625200"
  },
  {
    "text": "will start with a blank cluster and then you can see all the components built but then the actual demo the GUI demo that",
    "start": "1625200",
    "end": "1630600"
  },
  {
    "text": "shows the tree of thought strategy solving a problem I have that recorded so I can pause it and show you how the",
    "start": "1630600",
    "end": "1635720"
  },
  {
    "text": "strategy is actually working so to to do that I have to switch my screens",
    "start": "1635720",
    "end": "1641039"
  },
  {
    "text": "here and let's see if this",
    "start": "1641039",
    "end": "1646520"
  },
  {
    "text": "works",
    "start": "1646520",
    "end": "1649520"
  },
  {
    "text": "so you can see here uh I have the I have a completely clean",
    "start": "1654240",
    "end": "1661159"
  },
  {
    "text": "clear cluster no customer resources no parts no deployments the",
    "start": "1661159",
    "end": "1667120"
  },
  {
    "text": "first step as I said in one of the slides is to is to install the custom resources to do that I'm going to use",
    "start": "1667120",
    "end": "1674799"
  },
  {
    "text": "this make file that comes with the kubernetes operator framework and do install moment I hit",
    "start": "1674799",
    "end": "1681159"
  },
  {
    "text": "that you will see custom resources start to get deployed here let me keep this p",
    "start": "1681159",
    "end": "1690519"
  },
  {
    "text": "on okay so you saw the customer these are CS for each of these these modules",
    "start": "1690960",
    "end": "1696720"
  },
  {
    "text": "each of the modules of the to system at this time there are no parts because nothing is getting there is nothing running at this point I only specified",
    "start": "1696720",
    "end": "1704519"
  },
  {
    "text": "the desired state of the to system",
    "start": "1704519",
    "end": "1709440"
  },
  {
    "text": "now I'm going to deploy the I'm going to deploy the operator the",
    "start": "1710480",
    "end": "1717120"
  },
  {
    "text": "custom operator and with this you'll see uh the",
    "start": "1717120",
    "end": "1723840"
  },
  {
    "text": "K operator also deployed so what you see is now the K server the metrix server and the the KU the the custom thought",
    "start": "1723840",
    "end": "1731039"
  },
  {
    "text": "operator are installed and let's SK some time to",
    "start": "1731039",
    "end": "1740000"
  },
  {
    "text": "start so I'm showing the layers of this stack we started with deploying the the crds next is we installed the operator",
    "start": "1740720",
    "end": "1749760"
  },
  {
    "text": "the the third step now is once the operator is in I will install the two what I call",
    "start": "1749760",
    "end": "1757279"
  },
  {
    "text": "the the infrastructure layers in this one is the redis pass and the new 4G database so I have crds for those",
    "start": "1757279",
    "end": "1764200"
  },
  {
    "text": "already deployed all I have to do is K apply minus F",
    "start": "1764200",
    "end": "1773799"
  },
  {
    "text": "config Okay okay something is not working I",
    "start": "1775000",
    "end": "1782720"
  },
  {
    "text": "think okay this is always happens during a demo the demo guards are not happy I",
    "start": "1788320",
    "end": "1795120"
  },
  {
    "text": "forgot to run something in the background oh right right there so you see the the the thought graph that's the",
    "start": "1795120",
    "end": "1800840"
  },
  {
    "text": "neo4j got installed and the thought bus that is redish is now installed so let",
    "start": "1800840",
    "end": "1807000"
  },
  {
    "text": "me clear this uh let me maximize this so we can see it more clearly those are",
    "start": "1807000",
    "end": "1812200"
  },
  {
    "text": "running and here uh the",
    "start": "1812200",
    "end": "1816158"
  },
  {
    "text": "whole and you can see now there are deployments there it'll take for some time for this to come up all right",
    "start": "1818320",
    "end": "1825679"
  },
  {
    "text": "they're all green look good uh the graph database is still",
    "start": "1825679",
    "end": "1831279"
  },
  {
    "text": "pending and you can see all the persistent volume claims that created uh the services I have a bunch of services",
    "start": "1831279",
    "end": "1837960"
  },
  {
    "text": "that are required for auto Discovery but I also opened a few node ports so that I can I can connect my ID to this cluster",
    "start": "1837960",
    "end": "1843720"
  },
  {
    "text": "to test it out uh and you have the PVS so at this point the infrastructure is",
    "start": "1843720",
    "end": "1848960"
  },
  {
    "text": "ready to to try out uh so this is the part first of My Demo now I have all the",
    "start": "1848960",
    "end": "1854840"
  },
  {
    "text": "pieces required to run this so I'll switch to my I'll switch to my uh presentation",
    "start": "1854840",
    "end": "1864518"
  },
  {
    "text": "again and I'll run this okay so what you're seeing here is",
    "start": "1864600",
    "end": "1871960"
  },
  {
    "text": "let me see uh the this is the I call it the thought parameter this is the GUI",
    "start": "1871960",
    "end": "1879440"
  },
  {
    "text": "for for the the the tree of thought strategy so what you seeing there is these are let me let me pause it",
    "start": "1880799",
    "end": "1888200"
  },
  {
    "text": "so those three thought prompts those are the prompts for evaluating thoughts for",
    "start": "1888200",
    "end": "1893399"
  },
  {
    "text": "generating postive Solutions and for validating the final solution and you can you can change these prompts and you",
    "start": "1893399",
    "end": "1900159"
  },
  {
    "text": "can also try experiment with this prompt that's why I call the thought prompt this is like an uh like a playground so",
    "start": "1900159",
    "end": "1905880"
  },
  {
    "text": "you there's a lot of prompt engineering required to get these prompts right and and and each large language model has",
    "start": "1905880",
    "end": "1911480"
  },
  {
    "text": "their own nuances on on what what kind what kind of prompts you put them so that it kind of gets you to to the to",
    "start": "1911480",
    "end": "1917840"
  },
  {
    "text": "this to the solution uh okay so now let me jump to these are the",
    "start": "1917840",
    "end": "1926200"
  },
  {
    "text": "to hyper parameters uh let me pause it here this is where you see uh things like the depth of the tree the branching",
    "start": "1926200",
    "end": "1932720"
  },
  {
    "text": "Factor uh you can see things like the batch size and then there is this concurrency model that you can choose",
    "start": "1932720",
    "end": "1939399"
  },
  {
    "text": "from multi-processing to multi threading to just serially processing when you're experimenting with these sometimes you",
    "start": "1939399",
    "end": "1945799"
  },
  {
    "text": "need to run things serly so that you can follow through the whole tree when it's parall running just too complex to debug it so I left these strategies in there",
    "start": "1945799",
    "end": "1952720"
  },
  {
    "text": "and then you have the traversal algorithm so you can there choose between you know breadth first depth",
    "start": "1952720",
    "end": "1957799"
  },
  {
    "text": "first search um or you you have I don't have the montico",
    "start": "1957799",
    "end": "1965159"
  },
  {
    "text": "yet or a star all right so let me jump to solving",
    "start": "1965159",
    "end": "1971600"
  },
  {
    "text": "the problem now so I entered the problem 11 one one what's keep noting at the",
    "start": "1971600",
    "end": "1978000"
  },
  {
    "text": "bottom uh right screen you'll see the pods are running but as I hit the solution button you'll see the K kicks",
    "start": "1978000",
    "end": "1984360"
  },
  {
    "text": "in and it'll spin up more pods for that particular piece of the strategy so for",
    "start": "1984360",
    "end": "1989480"
  },
  {
    "text": "for for solving this at this stage it requires more pods to do the self evaluation then creating the initial",
    "start": "1989480",
    "end": "1995320"
  },
  {
    "text": "prompts so you'll be seeing uh pretty soon more ports getting",
    "start": "1995320",
    "end": "2001120"
  },
  {
    "text": "generated right there that is the K custom scalar kicking in it's creating",
    "start": "2001120",
    "end": "2008000"
  },
  {
    "text": "now more pods for the thought evaluator",
    "start": "2008000",
    "end": "2013200"
  },
  {
    "text": "module and then this is the the the entire tree so right now this is your root node it represents the problem and",
    "start": "2014559",
    "end": "2022399"
  },
  {
    "text": "as this solution is running you can see uh in thought prompt of those green lines those are the logs coming in from",
    "start": "2022399",
    "end": "2028880"
  },
  {
    "text": "the radius pass that are streamed over a web soet to this all right so the tree is forming here you see the initial",
    "start": "2028880",
    "end": "2034519"
  },
  {
    "text": "prompt branched into eight partial",
    "start": "2034519",
    "end": "2039679"
  },
  {
    "text": "Solutions and then as we going through this you will see let me walk through this real fast so we don't have enough",
    "start": "2040720",
    "end": "2048118"
  },
  {
    "text": "time left you'll see the stre will keep expanding see now it's at this stage this is the neo4j browser I'm using so",
    "start": "2048119",
    "end": "2055839"
  },
  {
    "text": "since all these all the tree is getting is saved in the in neo4j I'm using NE 4J",
    "start": "2055839",
    "end": "2061358"
  },
  {
    "text": "as a thought State manager so this is your first level of of of the branching out you'll see each at each s it only",
    "start": "2061359",
    "end": "2068878"
  },
  {
    "text": "branches into three clusters because the branching Factor was set as three in the higher parameters if you set it to four or five you'll see a wider",
    "start": "2068879",
    "end": "2076320"
  },
  {
    "text": "tree okay now this is getting really complicated so it has now expanded all over the",
    "start": "2076320",
    "end": "2082638"
  },
  {
    "text": "place okay so at this point I have a solution those orange things Show the",
    "start": "2082639",
    "end": "2088079"
  },
  {
    "text": "answers but what's interesting here is that this tree has found independently",
    "start": "2088079",
    "end": "2093240"
  },
  {
    "text": "two answers from two separate branches but this happen to be the same answer",
    "start": "2093240",
    "end": "2098879"
  },
  {
    "text": "and what you see on here is the solution this is",
    "start": "2099200",
    "end": "2104520"
  },
  {
    "text": "what what gp4 should have answered instead of saying you know 11 divided by",
    "start": "2104520",
    "end": "2109960"
  },
  {
    "text": "11 uh those are the steps you get a 24 so that is uh you know the the real",
    "start": "2109960",
    "end": "2118480"
  },
  {
    "text": "end of my demo but what you can also see is I want to quickly show you that this this tree Explorer is very interesting",
    "start": "2118480",
    "end": "2124640"
  },
  {
    "text": "because here you can now explore the entire three the the the thought process you can go through each node and see",
    "start": "2124640",
    "end": "2130640"
  },
  {
    "text": "what happened and how did it reason this problem",
    "start": "2130640",
    "end": "2136040"
  },
  {
    "text": "see or you can ask uh instead of the thoughts you can",
    "start": "2137280",
    "end": "2143880"
  },
  {
    "text": "ask uh this browser to say give me the answers directly instead of looking at",
    "start": "2143880",
    "end": "2149599"
  },
  {
    "text": "the whole tree so those are two answers and then you can walk back from the answer of what parent thought led to this and then you can start to go back",
    "start": "2149599",
    "end": "2155960"
  },
  {
    "text": "all the way up to the uh to the root",
    "start": "2155960",
    "end": "2160680"
  },
  {
    "text": "node okay so that concludes the [Applause]",
    "start": "2167480",
    "end": "2180280"
  },
  {
    "text": "demo uh and I have some final thoughts this is this is where this is for you",
    "start": "2180280",
    "end": "2185599"
  },
  {
    "text": "for the audience where do you take this work from here so I put this effort to take it at this point uh but I see the",
    "start": "2185599",
    "end": "2191880"
  },
  {
    "text": "future of this into what I call The Logical evolution of this is",
    "start": "2191880",
    "end": "2197640"
  },
  {
    "text": "what I call a new strategy coming up which is called the graph of thoughts so",
    "start": "2197640",
    "end": "2203079"
  },
  {
    "text": "the graph of thoughts is an interesting uh structure wherein it is also a tree",
    "start": "2203079",
    "end": "2210520"
  },
  {
    "text": "it's also a graph like what we saw but here the graph is graph of thought is not restricted to a tree it can be any",
    "start": "2210520",
    "end": "2217280"
  },
  {
    "text": "dag it can take any pad that's what you're seeing here so any branch can connect to any other branch and this",
    "start": "2217280",
    "end": "2223079"
  },
  {
    "text": "requires this this enables us to find more efficient paths in the in this",
    "start": "2223079",
    "end": "2229960"
  },
  {
    "text": "entire graph of thoughts and it also has the potential to reduce the cost and increase efficiency uh this framework",
    "start": "2229960",
    "end": "2236960"
  },
  {
    "text": "was recently introduced about I guess two months back by researchers uh best and his and the team from eth Zurich so",
    "start": "2236960",
    "end": "2244560"
  },
  {
    "text": "that research paper is also in the reference notes you can study it it's it's a fascinating way to look at this problem another potential solution that",
    "start": "2244560",
    "end": "2251280"
  },
  {
    "text": "I see is uh potential future direction that I can see is to use the tree of thought uh",
    "start": "2251280",
    "end": "2260119"
  },
  {
    "text": "as what I call it self- placed technique so that we can enable the tree of thought systems to develop Innovative",
    "start": "2260119",
    "end": "2266560"
  },
  {
    "text": "problem solving strategies that are not present in its training data it's drawing inspiration from how AI agents",
    "start": "2266560",
    "end": "2272440"
  },
  {
    "text": "like alphago or Alpha star learned to enhance the strategies through self play in competitive environments that's",
    "start": "2272440",
    "end": "2278560"
  },
  {
    "text": "another op another future trajectory this can go into and finally uh",
    "start": "2278560",
    "end": "2283880"
  },
  {
    "text": "fine-tuning large language models using tree of thought inspired approach that involves you know this high level",
    "start": "2283880",
    "end": "2289520"
  },
  {
    "text": "counterfactual decision making and considering different choices for the next for example you're trying to",
    "start": "2289520",
    "end": "2294760"
  },
  {
    "text": "generate some creative text so instead of generating the next text you can say you can ask to predict the next to",
    "start": "2294760",
    "end": "2301480"
  },
  {
    "text": "predict and and and go to the next token using the strategy this could open new front years for our problem solving",
    "start": "2301480",
    "end": "2307839"
  },
  {
    "text": "abilities using using large language models and who knows when the day P equals to NP is coming closer That's all",
    "start": "2307839",
    "end": "2314839"
  },
  {
    "text": "folks thank you for your time and I'm open for questions [Applause]",
    "start": "2314839",
    "end": "2324560"
  },
  {
    "text": "now any",
    "start": "2324560",
    "end": "2327800"
  },
  {
    "text": "questions yes",
    "start": "2331520",
    "end": "2338520"
  },
  {
    "text": "[Music]",
    "start": "2339530",
    "end": "2342679"
  },
  {
    "text": "yes so yeah let me show you that it's it's a very so this is the",
    "start": "2346319",
    "end": "2353800"
  },
  {
    "text": "actual UI you can choose Cloud gp4 turbo llama internally switches uh the",
    "start": "2353800",
    "end": "2362079"
  },
  {
    "text": "response API to use a different rapper",
    "start": "2362079",
    "end": "2368440"
  },
  {
    "text": "yes yes or if you have a resident on node like llama you're using or Falcon",
    "start": "2368560",
    "end": "2374680"
  },
  {
    "text": "7B it can make",
    "start": "2374680",
    "end": "2378240"
  },
  {
    "text": "that yes it's built",
    "start": "2379960",
    "end": "2384078"
  },
  {
    "text": "in any other questions yeah uh so I have another question so instead of we",
    "start": "2385599",
    "end": "2393000"
  },
  {
    "text": "selecting which model Can it have ability to choose the model itself like",
    "start": "2393000",
    "end": "2398440"
  },
  {
    "text": "something like this right in in this example yeah we don't really have to burden the llm we could just simply send",
    "start": "2398440",
    "end": "2405200"
  },
  {
    "text": "it to the mathematical um yeah I think that it's way way harder to do than than",
    "start": "2405200",
    "end": "2412839"
  },
  {
    "text": "it looks uh because each model has a very nuanced way of how it answers these questions so",
    "start": "2412839",
    "end": "2419680"
  },
  {
    "text": "what what you are thinking I I also was thinking in similar terms wherein each",
    "start": "2419680",
    "end": "2425319"
  },
  {
    "text": "part of this problem so in the first set of thought Generations happens let's say with GPT 4 but then the evaluation can",
    "start": "2425319",
    "end": "2430760"
  },
  {
    "text": "happen with a different model which is much smaller so that's where I was going with this is instead of using these",
    "start": "2430760",
    "end": "2436040"
  },
  {
    "text": "massive models which are very expensive and require lot of compute you can break this problem where your initial thought generation",
    "start": "2436040",
    "end": "2441720"
  },
  {
    "text": "is the big guns and then the the smaller evaluations and finally when you have the correct answer to validate if it is",
    "start": "2441720",
    "end": "2448760"
  },
  {
    "text": "correct that piece can be done with a local alarm that doesn't require gp4 or",
    "start": "2448760",
    "end": "2453920"
  },
  {
    "text": "clouds so that will help reduce cost and in is efficiency so yes that that's",
    "start": "2453920",
    "end": "2458960"
  },
  {
    "text": "where I think what you're saying can be",
    "start": "2458960",
    "end": "2463240"
  },
  {
    "text": "done yes I have two questions one is llms they mostly probabilistic way of",
    "start": "2464599",
    "end": "2470240"
  },
  {
    "text": "predicting the next word or you know in a um natural language whereas the",
    "start": "2470240",
    "end": "2479560"
  },
  {
    "text": "decision threes they more deterministic root Force way of exploring different options right so there are different",
    "start": "2479560",
    "end": "2484880"
  },
  {
    "text": "methods and you advocating like combining the two so that's my first question yeah and the second question",
    "start": "2484880",
    "end": "2492440"
  },
  {
    "text": "is um in this example that you had you had four numbers right and you were saying that you using um prompting to",
    "start": "2492440",
    "end": "2500880"
  },
  {
    "text": "help L llms to arrive at the right solution right was here the connection",
    "start": "2500880",
    "end": "2506079"
  },
  {
    "text": "between llms and decision 3s you simplifying the problem by going from let's say four numbers into two numbers",
    "start": "2506079",
    "end": "2513440"
  },
  {
    "text": "so that prompting was good enough for llms to solve the two number problem as",
    "start": "2513440",
    "end": "2519160"
  },
  {
    "text": "opposed to like the four numbers with many combinations of operations so yeah to answer the first question uh alms are",
    "start": "2519160",
    "end": "2525520"
  },
  {
    "text": "always stochastic probalistic there is no determinism there what you can do is you can play with these parameters here",
    "start": "2525520",
    "end": "2531359"
  },
  {
    "text": "so the temperature the overall entropy uh then uh you have the M the top K and",
    "start": "2531359",
    "end": "2536400"
  },
  {
    "text": "the top P whether you take the top X tokens or you take the probabil distribution but you always get a",
    "start": "2536400",
    "end": "2544400"
  },
  {
    "text": "representation of the probability of the answer it cannot be terministic what this Tre of thought strategy is trying",
    "start": "2544400",
    "end": "2550000"
  },
  {
    "text": "to do is with the last step of solution validation it is trying to reduce that probability to a very narrow set of of",
    "start": "2550000",
    "end": "2555880"
  },
  {
    "text": "answers that's what happens here but if you run the same thing 10 times three",
    "start": "2555880",
    "end": "2560960"
  },
  {
    "text": "times you will never get an answer the tree just goes into nonsensical paths uh",
    "start": "2560960",
    "end": "2566480"
  },
  {
    "text": "and there is no way to completely control that if I put these parameters too tight in which I keep you know the",
    "start": "2566480",
    "end": "2572559"
  },
  {
    "text": "the the the temperature close to you know let's say zero then I never get an answer if you keep",
    "start": "2572559",
    "end": "2579400"
  },
  {
    "text": "it very high then it goes other way around it starts to create all kind of hallucinations but the idea here is that",
    "start": "2579400",
    "end": "2586319"
  },
  {
    "text": "this strategy will have to find that balance um the next part of of your question was can you repeat that I just",
    "start": "2586319",
    "end": "2593520"
  },
  {
    "text": "lost that yeah basically um how did prompting help llms to arrive at the",
    "start": "2593520",
    "end": "2598839"
  },
  {
    "text": "right solution so uh the examples I give here these these prompt examples that you're",
    "start": "2598839",
    "end": "2604520"
  },
  {
    "text": "seeing they the first step is to find is the prompt engineering here you have to find those",
    "start": "2604520",
    "end": "2610680"
  },
  {
    "text": "prompts but they're not tied to just four or five you to pick up a class of problems in this case the class of",
    "start": "2610680",
    "end": "2616880"
  },
  {
    "text": "problems was Game of 24 you can take sodoko you can take crossword puzzles you can take some creative writing and",
    "start": "2616880",
    "end": "2623800"
  },
  {
    "text": "then there are only three prompts you need to engineer the first prompt is the initial thought generation the second",
    "start": "2623800",
    "end": "2628960"
  },
  {
    "text": "prompt is how do you validate these partial chains and the third prompt is once you are close to an answer how do",
    "start": "2628960",
    "end": "2634760"
  },
  {
    "text": "you validate if it is correct or not that's that's what you to play with but then you can choose any class of of",
    "start": "2634760",
    "end": "2640800"
  },
  {
    "text": "complex problems here and and try to find an answer thank",
    "start": "2640800",
    "end": "2648078"
  },
  {
    "text": "you uh great talk thank you uh so one question I have is uh how much of the",
    "start": "2648119",
    "end": "2654599"
  },
  {
    "text": "infrastructure nodes GPU nodes he had to use to give this tree of thoughts the",
    "start": "2654599",
    "end": "2660040"
  },
  {
    "text": "last example I mean you have explained in the initial uh few slides uh what is",
    "start": "2660040",
    "end": "2665280"
  },
  {
    "text": "the operational uh problem we have and when you try to use K using that how many GP nodes you",
    "start": "2665280",
    "end": "2672640"
  },
  {
    "text": "still need to use to solve this problem uh a lot a lot so so that's one of the",
    "start": "2672640",
    "end": "2678160"
  },
  {
    "text": "reasons why this this tree of thought strategy and the infrastructure I put together was to solve that problem is as",
    "start": "2678160",
    "end": "2683640"
  },
  {
    "text": "you spin up these nodes this tree of thought strategy starts to expand so so",
    "start": "2683640",
    "end": "2689200"
  },
  {
    "text": "the the K scaler is closely watching what the what the orator is telling it and then it starts to to power up those",
    "start": "2689200",
    "end": "2697200"
  },
  {
    "text": "notes which are involved in evaluations and starts to power down you know the",
    "start": "2697200",
    "end": "2703319"
  },
  {
    "text": "notes that are not doing much so it tries to rebalance this entire compute",
    "start": "2703319",
    "end": "2708359"
  },
  {
    "text": "on this cluster closely watching what is happening as the tree is expanding so",
    "start": "2708359",
    "end": "2713480"
  },
  {
    "text": "yeah I mean this a large language model there is no there is no easy way to you need powerful machines otherwise you",
    "start": "2713480",
    "end": "2719400"
  },
  {
    "text": "will spend days to get an answer but the intent here is knowing that reality can we make it more efficient",
    "start": "2719400",
    "end": "2727880"
  },
  {
    "text": "yeah so you're right so K has some custom scalers built for redus and other things so I'm not using that this is a",
    "start": "2734680",
    "end": "2741319"
  },
  {
    "text": "custom scaler that is looking at the the metrix coming from the from the Tree of thir so it the the orchestrator is",
    "start": "2741319",
    "end": "2748480"
  },
  {
    "text": "looking at how the tree is expanding it's creating some custom Matrix that's what geta reacts to so it's very fine grain tuned to the tree of thought",
    "start": "2748480",
    "end": "2755160"
  },
  {
    "text": "strategy correct",
    "start": "2755160",
    "end": "2760760"
  },
  {
    "text": "correct yes you can you can expose this metc of Prometheus and then use Prometheus scaler uh but the custom",
    "start": "2763000",
    "end": "2768240"
  },
  {
    "text": "scaler is in of its purpose buil for tree of thought um so it I was able to",
    "start": "2768240",
    "end": "2773920"
  },
  {
    "text": "get more control with that but absolutely with promethus you can do the same it can get very close to",
    "start": "2773920",
    "end": "2780240"
  },
  {
    "text": "that okay all right that's all for thank you that's all time we have",
    "start": "2780640",
    "end": "2787800"
  }
]
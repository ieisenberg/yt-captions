[
  {
    "text": "hey uh good afternoon everyone um I hope you are having a great day uh let me yourself uh I'm gav yadov uh I work in",
    "start": "240",
    "end": "7759"
  },
  {
    "text": "engine manager in lead AP gway multiple Platforms in in um with me I have Vata",
    "start": "7759",
    "end": "14440"
  },
  {
    "text": "he's working as staff engineer uh lead service message intitute um we are here to discuss about uh a critical topic of",
    "start": "14440",
    "end": "21480"
  },
  {
    "text": "failover um we'll discuss how the services can stay resilient um in case of description how different strategies",
    "start": "21480",
    "end": "28560"
  },
  {
    "text": "or Solutions can help you you know um you know help the business um to keep on growing without any customer impact",
    "start": "28560",
    "end": "35640"
  },
  {
    "text": "right in past we have seen like there are multiple outages have happened uh with multiple clouds you know we all",
    "start": "35640",
    "end": "42239"
  },
  {
    "text": "develop applications you know thinking you know the outages are very rare but when it happens we don't have answers",
    "start": "42239",
    "end": "49120"
  },
  {
    "text": "right so we'll try to address those answers and address those questions here and and get the solutions at scale right",
    "start": "49120",
    "end": "55320"
  },
  {
    "text": "I'm saying yeah um next few slides might be repetive or you know already about it",
    "start": "55320",
    "end": "61800"
  },
  {
    "text": "with the previous session happened before lunch uh right uh just for the interest of other audience I'm saying",
    "start": "61800",
    "end": "67040"
  },
  {
    "text": "I'll go through what is intute intute is a global fintech company uh which helps",
    "start": "67040",
    "end": "72280"
  },
  {
    "text": "customers simplify U multiple financial decision making through uh tax and accounting products um we are already uh",
    "start": "72280",
    "end": "80759"
  },
  {
    "text": "we are lot of U inter is a lot of passionate about the open sour contribution uh we have made uh multiple",
    "start": "80759",
    "end": "86320"
  },
  {
    "text": "contribution to sto Community via Admiral and Argo we are also U end user",
    "start": "86320",
    "end": "91479"
  },
  {
    "text": "for different products like um um kubernetes and uh steo uh and",
    "start": "91479",
    "end": "97880"
  },
  {
    "text": "that's where you know we we keep on developing ourselves and more contributing towards the open sour Community uh with that I'll just talk",
    "start": "97880",
    "end": "105360"
  },
  {
    "text": "about something more on on the contribution part uh we have Admiral as one of the major contribution we have",
    "start": "105360",
    "end": "110399"
  },
  {
    "text": "done uh as a traffic team here uh Admiral is a tool which is used for cross Custer communication uh and",
    "start": "110399",
    "end": "116119"
  },
  {
    "text": "service Discovery um if you need more details please reach out uh reach out to GitHub link and uh see about more about",
    "start": "116119",
    "end": "123000"
  },
  {
    "text": "that um according uh in addition to this we have navic um recently we have open",
    "start": "123000",
    "end": "129160"
  },
  {
    "text": "source this product um this is used for um you know um config unification of",
    "start": "129160",
    "end": "134640"
  },
  {
    "text": "configurations across different Services deployed in service mesh um please reach out U please see the GitHub link and",
    "start": "134640",
    "end": "140800"
  },
  {
    "text": "provide your feedback how is it and maybe start doing more contribution so that we all can learn from here right",
    "start": "140800",
    "end": "147680"
  },
  {
    "text": "um in addition to this open source I'm saying we have a beautiful I'm saying portal page um you know we are on a",
    "start": "147680",
    "end": "153160"
  },
  {
    "text": "modern s Journey uh where we are U looking we are helping developers so that we are abstracting lot of things",
    "start": "153160",
    "end": "159120"
  },
  {
    "text": "from the developers so that they can just focus on mainly on the business logic uh and don't worry about the you know the networking park or the you know",
    "start": "159120",
    "end": "165680"
  },
  {
    "text": "the infrastructure part right uh and that's where the scale looks like this I'm saying so we have um more than 300",
    "start": "165680",
    "end": "171159"
  },
  {
    "text": "clusters running uh with I more than um thousands of name spaces running with",
    "start": "171159",
    "end": "177000"
  },
  {
    "text": "that and more than 2,000 Services running MOS is running talking to each other with thousands of developer uh you",
    "start": "177000",
    "end": "183360"
  },
  {
    "text": "know using this Dev portal and the you know mods platform for their end to endend day-to-day work right",
    "start": "183360",
    "end": "189599"
  },
  {
    "text": "um U I'll talk about the agenda now um so we have seen uh in the previous",
    "start": "189599",
    "end": "196040"
  },
  {
    "text": "session we have talked about you know what is API get and mesh uh we again just for the um interest of other",
    "start": "196040",
    "end": "201319"
  },
  {
    "text": "audience we'll go through quickly touch upon the what is ap2 service mesh um and then from there we'll we'll talk about",
    "start": "201319",
    "end": "207319"
  },
  {
    "text": "how the service is distributed and works a distributed environment and what are the challenges when some failure happens",
    "start": "207319",
    "end": "214280"
  },
  {
    "text": "you know in such environment right how we address those um you know uh the issues and you know at scale you know",
    "start": "214280",
    "end": "221159"
  },
  {
    "text": "not just the existing Solutions and from there I'm saying we'll talk about what are the different solutions we can have",
    "start": "221159",
    "end": "227159"
  },
  {
    "text": "for different use cases you know uh we have explored a lot of different use cases and and we have found out what",
    "start": "227159",
    "end": "233280"
  },
  {
    "text": "approach works for which use case and we'll talk about those things in detail right and and then we'll talk about the",
    "start": "233280",
    "end": "239000"
  },
  {
    "text": "summary and the next for that right so what is API Gateway um it's one of the platform um old platform in intu I'm",
    "start": "239000",
    "end": "246239"
  },
  {
    "text": "saying we have um built over a lot period of time um think about you have",
    "start": "246239",
    "end": "253120"
  },
  {
    "text": "your as a developer you developing multiple apis uh for a service we have initially you get a client you know",
    "start": "253120",
    "end": "259639"
  },
  {
    "text": "start accessing your services all good it works fine this you happen start happening",
    "start": "259639",
    "end": "264880"
  },
  {
    "text": "when you get start getting more of the you know different clients right you have mobile app U you know browser",
    "start": "264880",
    "end": "270800"
  },
  {
    "text": "different services within your service company and you know multile third party right and now the developer has to start",
    "start": "270800",
    "end": "278039"
  },
  {
    "text": "building focusing on the logic of authentication authorization right rate limiting let's say if one of the client",
    "start": "278039",
    "end": "284000"
  },
  {
    "text": "does the DS attack how would I as a developer can save my service right I have to think about those things and",
    "start": "284000",
    "end": "290039"
  },
  {
    "text": "Implement those part also right now if I can just if I can get a component which",
    "start": "290039",
    "end": "295280"
  },
  {
    "text": "can serve all do all those things right it would be good for my me as a developer right and that's where you",
    "start": "295280",
    "end": "301440"
  },
  {
    "text": "know the API comes into picture right API gway sits between your client and the server your service right and",
    "start": "301440",
    "end": "307680"
  },
  {
    "text": "provides you all the capabilities which you talked about authentication authorization rate limiting traffic dialing and many more um you know and",
    "start": "307680",
    "end": "314800"
  },
  {
    "text": "just gives you that flexibility for the developer that you know that you can just focus on your business logic right",
    "start": "314800",
    "end": "320880"
  },
  {
    "text": "so as I said in inter we are you know we have built our own API Gateway we have not we not using the open source any",
    "start": "320880",
    "end": "327160"
  },
  {
    "text": "other Enterprise version of any other API Gateway and this is how the stats look like in in right I'm seeing so we",
    "start": "327160",
    "end": "333080"
  },
  {
    "text": "have more than we have like tri9 uh 59 availability uh throughout the year we",
    "start": "333080",
    "end": "340240"
  },
  {
    "text": "maintain we have seen 1.7 million TPS Max TP doing the text Peak we have",
    "start": "340240",
    "end": "345360"
  },
  {
    "text": "around close to 3 trillion transaction we do yearly um and these are for different more than 2500 Services which",
    "start": "345360",
    "end": "351400"
  },
  {
    "text": "are talking over API Gateway right um and we we the scale needs to be maintained and with that I'm the",
    "start": "351400",
    "end": "357000"
  },
  {
    "text": "capability has to be more refined and need to be optimize and which we start doing which we always do for that API",
    "start": "357000",
    "end": "362560"
  },
  {
    "text": "gway now let's look the another platform service mesh um we have Gateway in inter",
    "start": "362560",
    "end": "368120"
  },
  {
    "text": "we have also a service mesh I'm saying let's see what is service mesh I'm saying um in detail so think about we have different clusters we have seen",
    "start": "368120",
    "end": "374160"
  },
  {
    "text": "multiple clusters we need for our development um so here we have S1 as a service which just wants to talk to S2",
    "start": "374160",
    "end": "381160"
  },
  {
    "text": "uh same cluster and S3 in the different cluster right now if you want to have the same kind of capity which is in API",
    "start": "381160",
    "end": "387240"
  },
  {
    "text": "Gateway we would need similar kind kind of set up here also right so what will the option I'm saying it will look like",
    "start": "387240",
    "end": "392759"
  },
  {
    "text": "this right I'm saying so it will be the communication will happen and you know over the API Gateway this request will",
    "start": "392759",
    "end": "398840"
  },
  {
    "text": "go out of the cluster you know and they will go to the different PPC and then again come back to the cluster right so",
    "start": "398840",
    "end": "406039"
  },
  {
    "text": "you see there's a hop right but we want to avoid that hop and that's why we need something you know considering the",
    "start": "406039",
    "end": "411440"
  },
  {
    "text": "kubernetes world right we need something very close to the container of the Pod right and that's why we need something",
    "start": "411440",
    "end": "416720"
  },
  {
    "text": "called as like kind of mini Gateway which is attached to the you know pod uh and that's where you know we have we are",
    "start": "416720",
    "end": "422199"
  },
  {
    "text": "using ISO um you know which is another flavor of service mesh uh which helps in",
    "start": "422199",
    "end": "429039"
  },
  {
    "text": "you know doing a service to service communication right and that's what the service mes is all about I'm saying we it helps in doing service to service",
    "start": "429039",
    "end": "435080"
  },
  {
    "text": "communication in the most efficient way and this is how the stats look and",
    "start": "435080",
    "end": "440520"
  },
  {
    "text": "you know mesh adoption and in right I'm saying so we have again five9 capabilities five9 availity in um for",
    "start": "440520",
    "end": "446280"
  },
  {
    "text": "mesh Services um we have Max TPS of 7 4K uh during the year we have seen we have",
    "start": "446280",
    "end": "452879"
  },
  {
    "text": "seen almost like 50 million transaction yearly transaction and these trans growing as the a is adoption is growing",
    "start": "452879",
    "end": "458479"
  },
  {
    "text": "in itude um there are more than 300 clusters running and talking and different with the different services in",
    "start": "458479",
    "end": "463840"
  },
  {
    "text": "these clusters and that's how the scal starts growing right now since you now know the uh the",
    "start": "463840",
    "end": "472400"
  },
  {
    "text": "platform what is Gateway and mesh think about how as a developer we think about you know how you know service Works in a",
    "start": "472400",
    "end": "478520"
  },
  {
    "text": "distributed environment and let's now see the actual way you know where the issues are right so how we develop the",
    "start": "478520",
    "end": "484440"
  },
  {
    "text": "services right I'm saying so we have multiple reasons right we have API Gateway we have a service right um all",
    "start": "484440",
    "end": "491000"
  },
  {
    "text": "the communication right now is happening by AP gateways clients are communicating by AP gateway to service we have we have",
    "start": "491000",
    "end": "496240"
  },
  {
    "text": "seen that service to service communion if I want I can do one MCH right all good right we have studied all this just now uh that it is it is all possible",
    "start": "496240",
    "end": "504000"
  },
  {
    "text": "right now see what happens when the region goes you know uh is this a region",
    "start": "504000",
    "end": "509879"
  },
  {
    "text": "sufficient for service right one reason in a distributed environment you may not find it right right I'm saying so you",
    "start": "509879",
    "end": "515880"
  },
  {
    "text": "want that resiliency that you know service should also be there in the multi other region also right so that's where we need a service right now it",
    "start": "515880",
    "end": "522839"
  },
  {
    "text": "looks you know the distributed en perfect distributed environment right so all good right till now right now what",
    "start": "522839",
    "end": "528480"
  },
  {
    "text": "happens on a fine day you have a issue in that region one region right now what to do as a",
    "start": "528480",
    "end": "535160"
  },
  {
    "text": "developer what you going to first reaction is to you know think about option is let the platform team API gway",
    "start": "535160",
    "end": "541399"
  },
  {
    "text": "does the fa over why I need to think about it right so API gway team if let's say take that decision and does the",
    "start": "541399",
    "end": "547800"
  },
  {
    "text": "failover right what will happen think about it I'm saying right you know that",
    "start": "547800",
    "end": "553360"
  },
  {
    "text": "it will it will start failing over all the services which is on board to API Gateway in other reason okay so coming",
    "start": "553360",
    "end": "560399"
  },
  {
    "text": "back to that the problem was that issue was then one reason for a service right but with that for that service instead",
    "start": "560399",
    "end": "567120"
  },
  {
    "text": "of that we have done failover for all the services so AP Gateway has done all the fail right now does it really make",
    "start": "567120",
    "end": "573120"
  },
  {
    "text": "sense that you we are talking about the issue for a service but the Gateway is actually failing over all the services",
    "start": "573120",
    "end": "578200"
  },
  {
    "text": "right so it seems like a concern here and we'll come to this concern that you know we'll keep in mind that you know there's a concern with this failor",
    "start": "578200",
    "end": "583839"
  },
  {
    "text": "strategy right uh what can we do this was there in the API gway part um let's see you know um what we can do on the",
    "start": "583839",
    "end": "590560"
  },
  {
    "text": "mesh side so we have seen here Services service communication is happening from client to server or mesh now when's the",
    "start": "590560",
    "end": "597720"
  },
  {
    "text": "um what happens when the issue happens right the and the region goes down uh and the client is on mesh right I'm",
    "start": "597720",
    "end": "603279"
  },
  {
    "text": "saying so what you do is as a as a developer you what you do is you just update the something called as a",
    "start": "603279",
    "end": "608800"
  },
  {
    "text": "destination and in STO we call it as virtual service you just update the destination so that the client start",
    "start": "608800",
    "end": "615040"
  },
  {
    "text": "calling the service in the other region right simple right I'm saying just one client you just updated it and it all",
    "start": "615040",
    "end": "621120"
  },
  {
    "text": "works fine right what happens when you have hundreds of those clients right I'm saying so we have so many clients right",
    "start": "621120",
    "end": "628000"
  },
  {
    "text": "what happens that way as a developer if I don't have any other option I have to manually go update all those destination",
    "start": "628000",
    "end": "634320"
  },
  {
    "text": "Ino it is all virtu services we start updating those destinations right seems",
    "start": "634320",
    "end": "639839"
  },
  {
    "text": "like a very impractical job right I'm saying that's what I'm saying it's very impractical to just update the destination with all hundreds of clients",
    "start": "639839",
    "end": "645880"
  },
  {
    "text": "right that to doing the disaster right I'm saying you are doing a manual work right I'm here right so again we need",
    "start": "645880",
    "end": "651959"
  },
  {
    "text": "some issue there are issues here and we need to solve those part right I'm saying so that's where we have seen now",
    "start": "651959",
    "end": "657079"
  },
  {
    "text": "there are issues with the Gateway there are issu with the mesh over right let's come to a summary for problem statement",
    "start": "657079",
    "end": "662639"
  },
  {
    "text": "right so we need a strategy like a self service strategy uh which can help us you know um to fail over those service",
    "start": "662639",
    "end": "669440"
  },
  {
    "text": "endpoints without impacting the whole platform right because we are if we are concerned only about one service we",
    "start": "669440",
    "end": "675200"
  },
  {
    "text": "don't want to impact other services you know the customer or the Developers for that other services may not know may not",
    "start": "675200",
    "end": "681000"
  },
  {
    "text": "want to know the failure for that their services right so we need some self service control right I'm saying um fail",
    "start": "681000",
    "end": "686040"
  },
  {
    "text": "solution next is there a kind of lack of layer we need we don't want to update",
    "start": "686040",
    "end": "691639"
  },
  {
    "text": "the configurations automatically uh we don't want to do manually I'm say we want automatic orchestration for those",
    "start": "691639",
    "end": "697120"
  },
  {
    "text": "configurations and that's where the you know we need some solution like that right to serve uh you know address those",
    "start": "697120",
    "end": "702680"
  },
  {
    "text": "issue last but not the least um there are people who know about sto I'm saying",
    "start": "702680",
    "end": "708600"
  },
  {
    "text": "you may know that there are existing outof the boox solutions provided by sto right but those solution may not be",
    "start": "708600",
    "end": "714839"
  },
  {
    "text": "suitable for the scale which in is working on or any other services which are working at a high scale scale right",
    "start": "714839",
    "end": "720200"
  },
  {
    "text": "and we'll try to address those you know use cases uh later W will talk about the use cases and how we can do the you know",
    "start": "720200",
    "end": "726560"
  },
  {
    "text": "failover for those use cases at scale right uh with the with the improved solution right so U with the with the",
    "start": "726560",
    "end": "733320"
  },
  {
    "text": "problem statement in mind I'm saying let's let's talk about solution now so in INE we have developed multiple you Dr",
    "start": "733320",
    "end": "739639"
  },
  {
    "text": "Solutions um you know from the traffic point of view uh we have first we'll talk about self service failover so um",
    "start": "739639",
    "end": "746920"
  },
  {
    "text": "self service failover we want to give a control to the um you know the developer that how can you as a developer can have",
    "start": "746920",
    "end": "753320"
  },
  {
    "text": "a control in the dev portal you know that you can do you know this is how the you know the UI looks like the dev",
    "start": "753320",
    "end": "759880"
  },
  {
    "text": "portal every service owner you know developer can just go to the dev portal in inter and just see the topology for",
    "start": "759880",
    "end": "765720"
  },
  {
    "text": "the Gateway endpoints you we would see that there are do multiple Doom endpoints are given uh for a p endpoint",
    "start": "765720",
    "end": "772120"
  },
  {
    "text": "prod environment um and you can just see the topology for that right if you want to see multiple environment you can just",
    "start": "772120",
    "end": "778360"
  },
  {
    "text": "see multiple envirment and for that specifically you can see the multiple uh end points for that now if I have to do",
    "start": "778360",
    "end": "785399"
  },
  {
    "text": "a failover we can just do edit the option for that end point and do the failover for those I'm saying right I'm",
    "start": "785399",
    "end": "791120"
  },
  {
    "text": "saying this is the capability we have built in in I'm saying you know and giving that a developer that ease you",
    "start": "791120",
    "end": "796199"
  },
  {
    "text": "know so that they don't need to worry about all those things in a reg day-to-day basis and they can just completely come to the portal and do the",
    "start": "796199",
    "end": "802760"
  },
  {
    "text": "this this is how it looks like on the Gateway perspective what about mesh right so mesh on the mesh I'm saying we",
    "start": "802760",
    "end": "809720"
  },
  {
    "text": "have do mesh endpoints right and this is how it looks like the UI we have multiple mesh endpoints uh we",
    "start": "809720",
    "end": "815800"
  },
  {
    "text": "show the topology for those end points how it is um you know correctly conf is it active passive or active active right",
    "start": "815800",
    "end": "822040"
  },
  {
    "text": "and what is the status of it whether it's updated or not right the for those I'm saying once we have those status",
    "start": "822040",
    "end": "827839"
  },
  {
    "text": "right I'm saying we have again you know you can have edit options you know you can which we can edit it and make the",
    "start": "827839",
    "end": "833360"
  },
  {
    "text": "topology of that do mesh endpoint specific endpoint you can change the topology right and make it as you know",
    "start": "833360",
    "end": "839279"
  },
  {
    "text": "as what you want you want to move it to the some other region you can have it based on the active passive you know",
    "start": "839279",
    "end": "844320"
  },
  {
    "text": "based on option right and submit it right and the feedback comes back and your service is failed over with that for that end point right right this this",
    "start": "844320",
    "end": "850800"
  },
  {
    "text": "is how the simple we have made it for the developers um you know um and that's the the experience we have given to that",
    "start": "850800",
    "end": "856839"
  },
  {
    "text": "helpers let's see you know we see UI right I'm let's I think for the people who want to know what is under",
    "start": "856839",
    "end": "863240"
  },
  {
    "text": "underneath it is going on right for those let's see this architecture right so how that happens is a request comes",
    "start": "863240",
    "end": "869560"
  },
  {
    "text": "from the client you know and it's it goes through the intu API Gateway now we've seen the intu API what it does is",
    "start": "869560",
    "end": "875759"
  },
  {
    "text": "it all does all the authentication authorization rate limiting and make sure that the request is genuine you know it should not happen that I'm doing",
    "start": "875759",
    "end": "882639"
  },
  {
    "text": "a failover for a service which is not I'm not the owner of right so it should take care of those things right I'm",
    "start": "882639",
    "end": "887880"
  },
  {
    "text": "saying so that how it happens after that service goes to a DNS manager you know a DNS manager is also another service a",
    "start": "887880",
    "end": "894480"
  },
  {
    "text": "Lambda service which we have developed in in um you know which does all the ability of you know managing the DNS of",
    "start": "894480",
    "end": "901120"
  },
  {
    "text": "the services right of theom endpoints right what it does is it's actually helpful you know it talks to Route 53",
    "start": "901120",
    "end": "908079"
  },
  {
    "text": "you know uh and make it makes that all those calls to the Route 53 apis and make the changes of the DNS and once the",
    "start": "908079",
    "end": "914560"
  },
  {
    "text": "changes are done the feedback is given to the user that you know the failover is uh is completed for that U you know",
    "start": "914560",
    "end": "920320"
  },
  {
    "text": "for your end points right the Lambda service the D services is is responsible for um you know the DS management of",
    "start": "920320",
    "end": "926279"
  },
  {
    "text": "both Gateway and mesh and we'll see how mesh happens right I'm saying it is it",
    "start": "926279",
    "end": "931360"
  },
  {
    "text": "is behind the AWS API Gateway you know since it is a Lambda so it is also needs to be backed up by the a API Gateway and",
    "start": "931360",
    "end": "937560"
  },
  {
    "text": "you know that's how it is working so yeah this is how the experience looks like you know back end experience looks",
    "start": "937560",
    "end": "942800"
  },
  {
    "text": "like for the API Gateway endpoint failure um you know um there's let's talk about what is a meshpoint failure",
    "start": "942800",
    "end": "948560"
  },
  {
    "text": "happens right again same setup request comes from the developer it goes through multiple gateways it comes to DNS",
    "start": "948560",
    "end": "954720"
  },
  {
    "text": "manager now after the DNS manager what it does is obviously the Gateway endo was more ofcom endpoints so it was",
    "start": "954720",
    "end": "960480"
  },
  {
    "text": "talking Route 53 now in case of mesh endpoints what we do is we send a message to the Kafka the the message is",
    "start": "960480",
    "end": "968040"
  },
  {
    "text": "you know with all the attributes which you want to fail over right the end points topology all that right and now",
    "start": "968040",
    "end": "974040"
  },
  {
    "text": "our open source contribution right I'm open source you know component Admiral comes into the picture and takes up all",
    "start": "974040",
    "end": "979800"
  },
  {
    "text": "that messages consumes the messages and you know does the you know try to update the configurations for those different",
    "start": "979800",
    "end": "985880"
  },
  {
    "text": "clients right and that's where the you know update happens so the is they responsible for updating all those",
    "start": "985880",
    "end": "991600"
  },
  {
    "text": "configuration at scale without any manual intervention right it is doing updating the destinations again virtual",
    "start": "991600",
    "end": "998680"
  },
  {
    "text": "service in esto which is getting updated here you know and that's where you know the one end point is getting failor to",
    "start": "998680",
    "end": "1004160"
  },
  {
    "text": "the other end point other reasion right um I'll invite W to talk about the other",
    "start": "1004160",
    "end": "1009880"
  },
  {
    "text": "you know um strategy about automatic failover both the strategies are required we need self service we need",
    "start": "1009880",
    "end": "1014959"
  },
  {
    "text": "automative we have seen there are different use cases for it um you know and we also need automatic also so we",
    "start": "1014959",
    "end": "1020160"
  },
  {
    "text": "we'll talk about those thing and W will take over",
    "start": "1020160",
    "end": "1023959"
  },
  {
    "text": "that okay yeah hello yeah thank you gorov so let me",
    "start": "1035000",
    "end": "1041280"
  },
  {
    "text": "recap what we have seen so far so what we have seen is a set of orchestrators built and they are backed",
    "start": "1041280",
    "end": "1048400"
  },
  {
    "text": "by a nice UI using which developers can easily log their Dev portal UI and they",
    "start": "1048400",
    "end": "1054919"
  },
  {
    "text": "can choose on demand if they want to fail over a particular service they go to a particular endo and simply do an on",
    "start": "1054919",
    "end": "1061160"
  },
  {
    "text": "demand fail over of a particular service so this strategy is needed and this is",
    "start": "1061160",
    "end": "1066200"
  },
  {
    "text": "this requires a manual intervention so what about automatic failover so when I say automatic failover without any human",
    "start": "1066200",
    "end": "1072880"
  },
  {
    "text": "intervention if you find a service is degraded in a region so the client should be able to move their traffic to",
    "start": "1072880",
    "end": "1079120"
  },
  {
    "text": "the appropriate working region automatically so how do we do that let us see what strategies are there so to",
    "start": "1079120",
    "end": "1085440"
  },
  {
    "text": "ensure that your service is automatically moving to the other region so you need to have you know well-built",
    "start": "1085440",
    "end": "1091600"
  },
  {
    "text": "health checks so let us see what the health check mechanisms that we have",
    "start": "1091600",
    "end": "1096880"
  },
  {
    "text": "seen today in our the famous platforms so one of the heal check is passive health check okay so we'll talk",
    "start": "1096880",
    "end": "1103919"
  },
  {
    "text": "about each of them in detail and let's see we'll also see where they work well and where they don't",
    "start": "1103919",
    "end": "1109720"
  },
  {
    "text": "and another one is active health check so most of the platforms like sto you know they give these health checks and",
    "start": "1109720",
    "end": "1116880"
  },
  {
    "text": "these algorithms are available to you on day Zero and you can configure any of them so in addition to that I'm going to",
    "start": "1116880",
    "end": "1123919"
  },
  {
    "text": "introduce another health check that we have built at intute and I also mention",
    "start": "1123919",
    "end": "1128960"
  },
  {
    "text": "the reason why we have done that let's see each one of those health checks so",
    "start": "1128960",
    "end": "1135640"
  },
  {
    "text": "the first one is passive health check so this is also known as out detection",
    "start": "1135640",
    "end": "1141000"
  },
  {
    "text": "in so what is passive health check so in passive health check the client sends",
    "start": "1141000",
    "end": "1146520"
  },
  {
    "text": "request to a service and when the service responds it uses the status of the response to identify the health of a",
    "start": "1146520",
    "end": "1153240"
  },
  {
    "text": "service so an example a client sends all HTTP request to a service if the result",
    "start": "1153240",
    "end": "1158559"
  },
  {
    "text": "codes are 200 okay yeah it deems that the service is healthy whereas if it receives 5xx or",
    "start": "1158559",
    "end": "1165320"
  },
  {
    "text": "any other error codes that it is configured so it considers that the service is unhealthy so let's say you",
    "start": "1165320",
    "end": "1171320"
  },
  {
    "text": "have a service in two regions so region one and region two and then you have a client right so you have a client",
    "start": "1171320",
    "end": "1178360"
  },
  {
    "text": "cluster and it has some set of parts let's say I have configured here this service this client to ensure that uh it",
    "start": "1178360",
    "end": "1186440"
  },
  {
    "text": "always talks to service in region one which means the service is working in active passive mode so at this stage all",
    "start": "1186440",
    "end": "1193320"
  },
  {
    "text": "the client Parts in the client cluster would trigger requests only to the service in region one right now I",
    "start": "1193320",
    "end": "1200640"
  },
  {
    "text": "configure a passive health check so a typical passive heal check configuration would look something like this so in a",
    "start": "1200640",
    "end": "1207320"
  },
  {
    "text": "sense what it is trying to say is check every 15 seconds if you see five",
    "start": "1207320",
    "end": "1212960"
  },
  {
    "text": "consecutive 5xx in the last 60 seconds then fail over to the other region for 5",
    "start": "1212960",
    "end": "1218799"
  },
  {
    "text": "minutes so with this kind of a config so let's see what happens since you apply",
    "start": "1218799",
    "end": "1225480"
  },
  {
    "text": "the config and it's a distributed environment you see that it gets distributed to all the client ports so",
    "start": "1225480",
    "end": "1231080"
  },
  {
    "text": "when we say client here there are multiple client ports which are actually triggering the requests and all these",
    "start": "1231080",
    "end": "1236159"
  },
  {
    "text": "client ports would have got this passo health check configuration that we have given now let's say one of the client",
    "start": "1236159",
    "end": "1243360"
  },
  {
    "text": "part has received 5xx from the service so we do not know from which parts but",
    "start": "1243360",
    "end": "1248600"
  },
  {
    "text": "the client as it sees when it sends a request to the service it has received 5xx and they are matching the configured",
    "start": "1248600",
    "end": "1254679"
  },
  {
    "text": "thresholds of the passive health check configuration right so at this stage what it do so according to the config so",
    "start": "1254679",
    "end": "1262640"
  },
  {
    "text": "the client moves to the other region and the traffic is moving to service in",
    "start": "1262640",
    "end": "1267880"
  },
  {
    "text": "region to right but it is possible that not all parts in your client cluster",
    "start": "1267880",
    "end": "1273840"
  },
  {
    "text": "would see the same effect so some client Parts would have not hit that particular threshold of 5xx error codes that you",
    "start": "1273840",
    "end": "1280520"
  },
  {
    "text": "have configured and they continue to send request to that service and eventually when those client Parts also",
    "start": "1280520",
    "end": "1287159"
  },
  {
    "text": "see that the service has failed because they have hit the configured threshold they too will move the traffic to the",
    "start": "1287159",
    "end": "1293640"
  },
  {
    "text": "other region so this is what we call as passive health check now so let's see",
    "start": "1293640",
    "end": "1299919"
  },
  {
    "text": "where all in what all cases does it work fine so it works fine when there are smaller number of parts in both client",
    "start": "1299919",
    "end": "1306880"
  },
  {
    "text": "and service also this works very well and it",
    "start": "1306880",
    "end": "1312080"
  },
  {
    "text": "allows you to recover from temporary service disruptions so we'll talk about why only temporary service disruption",
    "start": "1312080",
    "end": "1319159"
  },
  {
    "text": "a minute later now let's see the other health",
    "start": "1319159",
    "end": "1324200"
  },
  {
    "text": "check which is called as active health check so as the name indicates so here in active health check the clients would",
    "start": "1324200",
    "end": "1330760"
  },
  {
    "text": "trigger Health probes to the service and expect the service to respond back so depending upon that they consider",
    "start": "1330760",
    "end": "1336520"
  },
  {
    "text": "whether the service is healthy or not so which means once again you have a service in both the regions and let's",
    "start": "1336520",
    "end": "1343679"
  },
  {
    "text": "say I have a client in client uh cluster one so let's say I configured this in",
    "start": "1343679",
    "end": "1348760"
  },
  {
    "text": "the load shared mode which means the client is configured or the service is configured in load shared mode and the client is free to send requests to the",
    "start": "1348760",
    "end": "1356200"
  },
  {
    "text": "service in both the regions so at this stage if I configure an active health",
    "start": "1356200",
    "end": "1361320"
  },
  {
    "text": "check the configuration would look something like this so you can relate this configuration to one of the",
    "start": "1361320",
    "end": "1366840"
  },
  {
    "text": "kubernetes probes like liveness probe or Readiness probe so effectively it says",
    "start": "1366840",
    "end": "1372760"
  },
  {
    "text": "every 1 second send requests to/ Health path of the service and if you don't",
    "start": "1372760",
    "end": "1379320"
  },
  {
    "text": "receive successful responses for three consecutive times consider that the service is unhealthy so this is what a",
    "start": "1379320",
    "end": "1386279"
  },
  {
    "text": "typical active heal check configuration would look like so with such a configuration in",
    "start": "1386279",
    "end": "1392279"
  },
  {
    "text": "place both the once again since we are in a distributed world this configuration goes applies and sits in",
    "start": "1392279",
    "end": "1398919"
  },
  {
    "text": "all the client parts right so all the client parts are exchanging these Health propes remember these Health propes are",
    "start": "1398919",
    "end": "1405960"
  },
  {
    "text": "in addition to the actual payloads that the client is supposed to exchange with the service so this is an additional",
    "start": "1405960",
    "end": "1412200"
  },
  {
    "text": "overhead so let's say at some point in time service one degrades in region one",
    "start": "1412200",
    "end": "1418520"
  },
  {
    "text": "so during this time both these client Parts would eventually fail their",
    "start": "1418520",
    "end": "1424279"
  },
  {
    "text": "configured Active Health check configs and would ignore those failed end points",
    "start": "1424279",
    "end": "1430279"
  },
  {
    "text": "from active routing list so essentially the entire traffic would be flowing to the region",
    "start": "1430279",
    "end": "1437039"
  },
  {
    "text": "to now we have seen two different types of health checks so which are mostly bundled by most of the platforms and",
    "start": "1437039",
    "end": "1445279"
  },
  {
    "text": "just like you know passive health check even Active Health check also you know it works well when the number of pots",
    "start": "1445279",
    "end": "1450760"
  },
  {
    "text": "are small both in client as well as service now let's try to see the limitations of these health",
    "start": "1450760",
    "end": "1457760"
  },
  {
    "text": "checks now we are going back to passive health check so as we have seen passive",
    "start": "1457760",
    "end": "1463240"
  },
  {
    "text": "health checks experiments the service Health with the actual payload that it is supposed to send and serve right so",
    "start": "1463240",
    "end": "1471360"
  },
  {
    "text": "which means you you send a request the actual request only when the service responds you will get to know whether it",
    "start": "1471360",
    "end": "1477320"
  },
  {
    "text": "was served properly or not so this is one limitation of Active Health passive health check so I also mentioned that",
    "start": "1477320",
    "end": "1484000"
  },
  {
    "text": "the passive heal check works well for temporary disruptions the reason is most",
    "start": "1484000",
    "end": "1489399"
  },
  {
    "text": "of the passive heal check algorithms that you have today okay so they come back to the original region once the",
    "start": "1489399",
    "end": "1495799"
  },
  {
    "text": "ejection interval is over so if you remember in the passive health check config there is a parameter called ejection time so which is configur to",
    "start": "1495799",
    "end": "1502559"
  },
  {
    "text": "some minutes some 5 minutes in our example which means the service the clients moves the the traffic from",
    "start": "1502559",
    "end": "1509200"
  },
  {
    "text": "service in region one to region two and after 5 minutes it comes back which means the understanding is that after 5",
    "start": "1509200",
    "end": "1514799"
  },
  {
    "text": "minutes the service is in region when is going to come up and Alive which may not be true always the service has a",
    "start": "1514799",
    "end": "1521080"
  },
  {
    "text": "prolonged issue or if the region is down then you are bound to see the same failures again and the client is",
    "start": "1521080",
    "end": "1526640"
  },
  {
    "text": "supposed to undergo that entire exercise of identifying whether the service is healthy or not using this passive health",
    "start": "1526640",
    "end": "1532240"
  },
  {
    "text": "check mechanism now the service Health visibility may not be uniform so this is",
    "start": "1532240",
    "end": "1539120"
  },
  {
    "text": "very evident when you have large number of parts in both client and service let's say you are running thousands of",
    "start": "1539120",
    "end": "1544520"
  },
  {
    "text": "parts in client cluster and you're running thousands of parts in service cluster so let's say at t0 one of the",
    "start": "1544520",
    "end": "1550679"
  },
  {
    "text": "part in the client identified that the service is down which means it has understood that it has hit the configur",
    "start": "1550679",
    "end": "1557520"
  },
  {
    "text": "threshold as of passive health check of consecutive 5xx within a particular time",
    "start": "1557520",
    "end": "1562600"
  },
  {
    "text": "right and if there are thousands of Parts if you consider the time at which the last pod in the client cluster has",
    "start": "1562600",
    "end": "1569200"
  },
  {
    "text": "moved the traffic so the time gap between the first pod versus last pod it could be huge so when someone asks what",
    "start": "1569200",
    "end": "1577480"
  },
  {
    "text": "is your time to detect and what is your time to fail over so the time could be could be very big in this",
    "start": "1577480",
    "end": "1584240"
  },
  {
    "text": "case so the effect of this is slow detection fail over so so long as you",
    "start": "1584240",
    "end": "1589919"
  },
  {
    "text": "have larger number of parts in client and service clusters so you might take",
    "start": "1589919",
    "end": "1595120"
  },
  {
    "text": "larger amount of time to fail over your entire client cluster from one region to another",
    "start": "1595120",
    "end": "1601520"
  },
  {
    "text": "region and then coming to Active Health checks as we have seen active health checks would trigger additional traffic",
    "start": "1601520",
    "end": "1608520"
  },
  {
    "text": "volume which is the health check volume in addition to the payloads that they serve right so imagine client and",
    "start": "1608520",
    "end": "1613919"
  },
  {
    "text": "service having thousands of parts and if you enable Active Health check so you're actually overloading the network by that",
    "start": "1613919",
    "end": "1619880"
  },
  {
    "text": "much right so these are some of the limitations that they are present with",
    "start": "1619880",
    "end": "1624919"
  },
  {
    "text": "the existing Solutions now let's see you have a mission critical critical service and",
    "start": "1624919",
    "end": "1631000"
  },
  {
    "text": "which operates at scale which means the service has thousands of parts and it connects to thousands of clients and",
    "start": "1631000",
    "end": "1637919"
  },
  {
    "text": "let's say clients also have very large number of Parts both these Solutions may not give",
    "start": "1637919",
    "end": "1644279"
  },
  {
    "text": "an optimal result right in terms of SLA in terms of failover service disruptions for such a case right so that's the",
    "start": "1644279",
    "end": "1651320"
  },
  {
    "text": "reason why we have built a new solution so let me call it external health check",
    "start": "1651320",
    "end": "1656960"
  },
  {
    "text": "solution or external health check service so let's see what it does primarily it attempts to offload the",
    "start": "1656960",
    "end": "1663480"
  },
  {
    "text": "health check from the actual client parts to a dedicated set of Parts which means I built my own system which is",
    "start": "1663480",
    "end": "1670679"
  },
  {
    "text": "capable of doing the health check so for doing the health check of the system I can employ various techniques so one of",
    "start": "1670679",
    "end": "1676480"
  },
  {
    "text": "the technique could be the one that that is used by the active health check itself and then this external health",
    "start": "1676480",
    "end": "1683320"
  },
  {
    "text": "check service is capable of monitoring a dedicated set of uh services that is",
    "start": "1683320",
    "end": "1689440"
  },
  {
    "text": "configured to which are really Mission critical which do not want to employ the solutions that are provided by the",
    "start": "1689440",
    "end": "1695399"
  },
  {
    "text": "platforms by default but does not end there so the",
    "start": "1695399",
    "end": "1700760"
  },
  {
    "text": "external health check service is also capable of communicating to some of the orchestrators that we have seen",
    "start": "1700760",
    "end": "1706799"
  },
  {
    "text": "before so let's see the advantage of it let's say this external health check solution identifies that the service in",
    "start": "1706799",
    "end": "1714960"
  },
  {
    "text": "so and so cluster and so Reon is down then it can output the same health check",
    "start": "1714960",
    "end": "1721679"
  },
  {
    "text": "status to some of the controllers that we have built let's say it outputs it to our traffic controller which is Admiral",
    "start": "1721679",
    "end": "1728679"
  },
  {
    "text": "so Admiral is a traffic configuration modification controller which means it can alter the traffic routing between",
    "start": "1728679",
    "end": "1735919"
  },
  {
    "text": "you know different clients and services on service M so when Admiral sees such a status okay then it can possibly take a",
    "start": "1735919",
    "end": "1743919"
  },
  {
    "text": "decision whether to change the traffic pattern or not right so similarly let's",
    "start": "1743919",
    "end": "1749200"
  },
  {
    "text": "say I have also built something called a resource controller okay it could be a kubernetes resource controller and when",
    "start": "1749200",
    "end": "1754919"
  },
  {
    "text": "that controller gets the health status so then you have a chance there to ensure that you take some actions like",
    "start": "1754919",
    "end": "1761399"
  },
  {
    "text": "you know resource config changes so we'll see how we can put this newly",
    "start": "1761399",
    "end": "1768320"
  },
  {
    "text": "solution external health check service into action for such a mission critical service which is operating at very high",
    "start": "1768320",
    "end": "1775720"
  },
  {
    "text": "scale yeah so the health check controller is ready health check service is ready and it is ready to Output the",
    "start": "1775720",
    "end": "1782399"
  },
  {
    "text": "health check status to all the controllers that we have seen okay and then we have a service which is",
    "start": "1782399",
    "end": "1788640"
  },
  {
    "text": "available in both the regions and we have a client which is ready to send request to all the services in either of",
    "start": "1788640",
    "end": "1795320"
  },
  {
    "text": "the regions so let's say say I configured this service in active active mode in",
    "start": "1795320",
    "end": "1800519"
  },
  {
    "text": "the load shared mode which means I say that the service is ready to take half of the traffic in region one and half in",
    "start": "1800519",
    "end": "1807080"
  },
  {
    "text": "region and then I also configured our external health check service to monitor this particular service service one",
    "start": "1807080",
    "end": "1813640"
  },
  {
    "text": "right so at this stage the external health check servicer is monitoring the service one and as we discussed it is",
    "start": "1813640",
    "end": "1820120"
  },
  {
    "text": "capable of outputting the health status to all the controllers that we have built in so what happens let's say this",
    "start": "1820120",
    "end": "1826679"
  },
  {
    "text": "information goes to Admiral about the health status of a service then Admiral says oh the service is configured in",
    "start": "1826679",
    "end": "1833399"
  },
  {
    "text": "active active mode and it is in load shared mode and Admiral also is aware of all the clients and where they are",
    "start": "1833399",
    "end": "1839640"
  },
  {
    "text": "sitting in so Admiral is all aware so it knows and it configures that particular",
    "start": "1839640",
    "end": "1845720"
  },
  {
    "text": "client all the clients of this particular service with the appropriate traffic topology which is 50% each to",
    "start": "1845720",
    "end": "1851880"
  },
  {
    "text": "one region and 50% to the other so let's say it's some so these this is how the",
    "start": "1851880",
    "end": "1856919"
  },
  {
    "text": "request will go once the traffic topology is made 50/50 so at some point in time a service",
    "start": "1856919",
    "end": "1864039"
  },
  {
    "text": "is degraded in region one right so what would happen at this",
    "start": "1864039",
    "end": "1869360"
  },
  {
    "text": "stage the external health check controller would immediately trigger notifications to all the you know uh the",
    "start": "1869360",
    "end": "1877120"
  },
  {
    "text": "orchestrators available so once it goes to a resource controller then resource",
    "start": "1877120",
    "end": "1882159"
  },
  {
    "text": "controller here has an opportunity to give some commands to the serviceing",
    "start": "1882159",
    "end": "1887320"
  },
  {
    "text": "region when so as to scale up from the existing number of parts to a higher number of parts in anticipation of know",
    "start": "1887320",
    "end": "1894399"
  },
  {
    "text": "the traffic fail over so in this example I've indicated the part scale up alone",
    "start": "1894399",
    "end": "1900279"
  },
  {
    "text": "but however it is not limited to that so it could be you know scaling up of your Ingress or even scaling up of your",
    "start": "1900279",
    "end": "1906240"
  },
  {
    "text": "database right it all depends upon the use case but you have a way to do it and you have a plugin you know that you can",
    "start": "1906240",
    "end": "1913720"
  },
  {
    "text": "uh attach and then you can ensure that all those things are done as and when the service is uh degraded in one region",
    "start": "1913720",
    "end": "1920279"
  },
  {
    "text": "so similarly external health check controller it would have also sent the same request to Admiral and Admiral",
    "start": "1920279",
    "end": "1927120"
  },
  {
    "text": "identifies that the service is down in one of the regions and it would immediately change the traffic topology",
    "start": "1927120",
    "end": "1933240"
  },
  {
    "text": "to the other region so and then thus the client would stop sending requests to",
    "start": "1933240",
    "end": "1939679"
  },
  {
    "text": "the know service in region one and the entire request flow to region",
    "start": "1939679",
    "end": "1945399"
  },
  {
    "text": "two so this is the solution and we have seen total three uh health checks two",
    "start": "1945399",
    "end": "1953960"
  },
  {
    "text": "which come out of bound out of the box to on many platforms like sto passive",
    "start": "1953960",
    "end": "1959880"
  },
  {
    "text": "health check and active health check and the one that works well when your services and clients are operating at",
    "start": "1959880",
    "end": "1966080"
  },
  {
    "text": "scale which is what we have built at in so let me sum it up so to stay ahead",
    "start": "1966080",
    "end": "1972000"
  },
  {
    "text": "of disruptions ensure that you have orchestrators in place so which are capable of understanding understanding",
    "start": "1972000",
    "end": "1978919"
  },
  {
    "text": "the request that the user gives either via Dev portal or whatever and they can",
    "start": "1978919",
    "end": "1985120"
  },
  {
    "text": "quickly alter the traffic topology across all the clients available and then ensure that you have",
    "start": "1985120",
    "end": "1991760"
  },
  {
    "text": "chosen proper health check mechanism so it could be an active health check or a passive health check or sometimes a",
    "start": "1991760",
    "end": "1997080"
  },
  {
    "text": "combination of both or if your service is Mission critical and if it operates at scale then you can you can choose to",
    "start": "1997080",
    "end": "2004320"
  },
  {
    "text": "build a dedicated health check service that we have shown here so it it all depends upon the use",
    "start": "2004320",
    "end": "2011440"
  },
  {
    "text": "case and then also have self service available so it's not necess it's not",
    "start": "2011440",
    "end": "2016840"
  },
  {
    "text": "sufficient if you have orchestrators built in so there should be an easy way the human can communicate to those",
    "start": "2016840",
    "end": "2023000"
  },
  {
    "text": "orchestrators preferably backed by a UI so that the traffic change on demand can happen",
    "start": "2023000",
    "end": "2029320"
  },
  {
    "text": "smoothly last but not least so it's always not about failover you should also consider you know prescaling the",
    "start": "2029320",
    "end": "2036519"
  },
  {
    "text": "resources and this can easily happen when you buil a standalone solution that we have uh just",
    "start": "2036519",
    "end": "2043880"
  },
  {
    "text": "demon shown here so it may not happen with the built-in solutions that you see with some of the",
    "start": "2043880",
    "end": "2050480"
  },
  {
    "text": "platforms I think that's all we had to present thank you and we are open for",
    "start": "2050480",
    "end": "2058480"
  },
  {
    "text": "questions any questions from second please yeah",
    "start": "2060119",
    "end": "2068158"
  },
  {
    "text": "mic can you come to mic in between there's a",
    "start": "2068240",
    "end": "2073398"
  },
  {
    "text": "mic so where is Admiral hosted is it on kubernetes cluster or it's sitting outside Admiral is hosted in our uh",
    "start": "2083200",
    "end": "2091079"
  },
  {
    "text": "special cluster called pass cluster so it's a kubernetes cluster yeah it's another kubernetes cluster what if the",
    "start": "2091079",
    "end": "2097160"
  },
  {
    "text": "Admiral cluster goes down yeah so we have a Dr for Admiral as well we have a disaster recovery for Admiral as well so",
    "start": "2097160",
    "end": "2104200"
  },
  {
    "text": "who is managing that Dr automation for Admiral itself yeah so the Dr for",
    "start": "2104200",
    "end": "2109720"
  },
  {
    "text": "Admiral is managed between uh the two Admirals or the Admirals running in both",
    "start": "2109720",
    "end": "2115119"
  },
  {
    "text": "the regions themselves so it is not using any of these techniques so will it not create a split brain issue or",
    "start": "2115119",
    "end": "2122040"
  },
  {
    "text": "something uh so we use a health Checker kind of a solution using a database you",
    "start": "2122040",
    "end": "2128359"
  },
  {
    "text": "know you write a key to a database and then you determine whether which of your Admirals want to be active and doing the",
    "start": "2128359",
    "end": "2134839"
  },
  {
    "text": "job so it's that kind of a solution it's not uh based on you know health check",
    "start": "2134839",
    "end": "2140320"
  },
  {
    "text": "that that we have shown here okay and in one of the slide you had like Admiral will be reading it from Kafka and then",
    "start": "2140320",
    "end": "2146040"
  },
  {
    "text": "it will be pushing it to all so in one of the previous session they were discussing like uh something similar at",
    "start": "2146040",
    "end": "2152400"
  },
  {
    "text": "that time they were using S3 bucket and all the ports will be connecting to S3 bucket to update the config mhm why",
    "start": "2152400",
    "end": "2158119"
  },
  {
    "text": "can't we use Admiral there as well yes3 bucket to connect okay Admiral that is",
    "start": "2158119",
    "end": "2164280"
  },
  {
    "text": "for the traffic traffic configurations I tell you so Admiral is a service mesh config orchestrator it only knows and",
    "start": "2164280",
    "end": "2172640"
  },
  {
    "text": "understands to translate the input to the corresponding service mesh configs",
    "start": "2172640",
    "end": "2177880"
  },
  {
    "text": "okay which is on stto specific got it yeah sure thanks",
    "start": "2177880",
    "end": "2184720"
  },
  {
    "text": "uh hello uh I have another question so uh first and foremost thank you for the informative session and uh second is",
    "start": "2188520",
    "end": "2194400"
  },
  {
    "text": "regarding the external external traffic kind of a auditor which you have mentioned about so basically U internal",
    "start": "2194400",
    "end": "2201680"
  },
  {
    "text": "and you know active and passive are fine although regarding the load which You' mentioned right that uh if we make let's",
    "start": "2201680",
    "end": "2207280"
  },
  {
    "text": "say there are thousands of clients and thousands of servers there's a direct heal check request which go and it creates a lot of pressure on the uh",
    "start": "2207280",
    "end": "2214480"
  },
  {
    "text": "Services right how are we preventing that with an use of an external health check provider I like it also makes an",
    "start": "2214480",
    "end": "2220839"
  },
  {
    "text": "request right certainly I think you cannot go away with you know health check probes the only thing that we are",
    "start": "2220839",
    "end": "2227040"
  },
  {
    "text": "avoiding is we are offloading clients from doing these health checks MH okay and if the clients are scaled up to a",
    "start": "2227040",
    "end": "2233359"
  },
  {
    "text": "larger number which is not the case with our dedicated infrastructure there you have a limited set of Parts which would",
    "start": "2233359",
    "end": "2239760"
  },
  {
    "text": "do the health check and uh you do not load the system to that extent that extent right is the volume which is",
    "start": "2239760",
    "end": "2246119"
  },
  {
    "text": "mattering here a scale few heal checks will not have an issue for our services the only about the thousands of Parts",
    "start": "2246119",
    "end": "2251560"
  },
  {
    "text": "which are having doing the whole check at that volume so that's the that's the I would say the issue we are trying to avoid and how are we hosting that heal",
    "start": "2251560",
    "end": "2258760"
  },
  {
    "text": "check mechanism I mean like is there any automated service or like how are these heal checks happening is there a crown",
    "start": "2258760",
    "end": "2264720"
  },
  {
    "text": "or like Lambda or what's the compute or logic behind that so health checks uh",
    "start": "2264720",
    "end": "2271240"
  },
  {
    "text": "service also consists of Parts which are capable of understanding different health check mechanism just like your",
    "start": "2271240",
    "end": "2277640"
  },
  {
    "text": "the kubernetes allows you to do props using the TCP HTTP so we have a similar",
    "start": "2277640",
    "end": "2283680"
  },
  {
    "text": "variant because there could be a combination of grpc or certainly",
    "start": "2283680",
    "end": "2289839"
  },
  {
    "text": "okay hello uh so my question is uh you mentioned that you uh developed the",
    "start": "2291000",
    "end": "2297119"
  },
  {
    "text": "external health check just to offload uh some of the uh what do you say the job",
    "start": "2297119",
    "end": "2304000"
  },
  {
    "text": "which is being done internally and you offload that from so can it be possible with the side car",
    "start": "2304000",
    "end": "2310599"
  },
  {
    "text": "containers where side cars where on the client side on the in the service mesh",
    "start": "2310599",
    "end": "2315680"
  },
  {
    "text": "like side car can be integrated with the sto no yeah okay so I was asking that if",
    "start": "2315680",
    "end": "2321960"
  },
  {
    "text": "the side car can do that job no it is the side car doing the job but what we are doing even if the side car does the",
    "start": "2321960",
    "end": "2327760"
  },
  {
    "text": "job it is triggering large traffic volumes when the clients and services are scaled up to higher numbers so we",
    "start": "2327760",
    "end": "2334920"
  },
  {
    "text": "have a couple of mission critical services at inot okay to which most of the other services",
    "start": "2334920",
    "end": "2340640"
  },
  {
    "text": "at inutes are clients so in that case imagine 100 clients each having say some",
    "start": "2340640",
    "end": "2347800"
  },
  {
    "text": "500 Parts talking to this particular service and everybody is doing health check because everybody wants to talk to",
    "start": "2347800",
    "end": "2354640"
  },
  {
    "text": "that particular service at any point in time it is Mission critical right so these many services either the client",
    "start": "2354640",
    "end": "2361240"
  },
  {
    "text": "application containers are the side cars attached to those client Parts they",
    "start": "2361240",
    "end": "2366319"
  },
  {
    "text": "would overload the traffic once again right the network between these clients and uh Services right which is not",
    "start": "2366319",
    "end": "2372400"
  },
  {
    "text": "needed so anything which is coming from a p right so side car is also part of the part only as a container right so so",
    "start": "2372400",
    "end": "2378880"
  },
  {
    "text": "the if you have thousands of Parts you have thousands of side car is it like them so the volume Remains the Same right I'm saying it doesn't changes and",
    "start": "2378880",
    "end": "2385200"
  },
  {
    "text": "that's what we are trying to avoid I'm saying by not having it's not offloading the job of an application logic or",
    "start": "2385200",
    "end": "2390839"
  },
  {
    "text": "application container it's actually offloading the client client cluster",
    "start": "2390839",
    "end": "2396480"
  },
  {
    "text": "it's the client itself completely from doing this job okay okay and is this API",
    "start": "2396480",
    "end": "2401599"
  },
  {
    "text": "Gateway publicly available uh we can use no so it's internally develop only internally use okay you can use Admiral",
    "start": "2401599",
    "end": "2408520"
  },
  {
    "text": "and Naik thank you hey I have a quick question um so",
    "start": "2408520",
    "end": "2415800"
  },
  {
    "text": "you have uh 300 cluster more than 300 clusters on board to this and uh you",
    "start": "2415800",
    "end": "2421599"
  },
  {
    "text": "also said you have more than uh 2,000 Services right more than 2,000 uh",
    "start": "2421599",
    "end": "2426720"
  },
  {
    "text": "services uh with this ambient mode now is G8 I wonder what's your plan are you",
    "start": "2426720",
    "end": "2432680"
  },
  {
    "text": "seeing this you're going to adopt this are you going to have like a migration",
    "start": "2432680",
    "end": "2437920"
  },
  {
    "text": "plan something like that just curious thanks yeah I think we have experimented with ambient mode and there are plans to",
    "start": "2437920",
    "end": "2444839"
  },
  {
    "text": "adopt ambient mode but even to roll it out right at at an intute level I think",
    "start": "2444839",
    "end": "2451400"
  },
  {
    "text": "we need to do and prove with lot of performance testing and the major challenge is at in what we fa is we have",
    "start": "2451400",
    "end": "2458200"
  },
  {
    "text": "extended Envoy with our own custom filters yes right so we need to check how ambient works with Envoy filters so",
    "start": "2458200",
    "end": "2466480"
  },
  {
    "text": "we have lot of on wiper filters at both client side as well as service side so we need to see if all those things work",
    "start": "2466480",
    "end": "2472920"
  },
  {
    "text": "fine or not so that's the major task we are certainly on it okay thank you",
    "start": "2472920",
    "end": "2478240"
  },
  {
    "text": "thanks thanks for the nice talk so one question around the Autos scaling piece the implementation sounds like kada like",
    "start": "2478240",
    "end": "2485800"
  },
  {
    "text": "where kada registered itself a external metric server so the health check thing is does it operate like that or uh it it",
    "start": "2485800",
    "end": "2493359"
  },
  {
    "text": "is completely external to kubernetes no I think it is within kubernetes because at the end of the day",
    "start": "2493359",
    "end": "2500800"
  },
  {
    "text": "uh if a service is on service mesh okay so you need to be in kubernetes even to",
    "start": "2500800",
    "end": "2506760"
  },
  {
    "text": "uh you know send some probes and estimate the and to aut scale like are you feeding some data to HPA like how it",
    "start": "2506760",
    "end": "2514640"
  },
  {
    "text": "I think similar to that we have some custom Solutions built around uh HPA yeah thank",
    "start": "2514640",
    "end": "2522559"
  },
  {
    "text": "you okay I think we good uh yeah thank you thank you all have a good",
    "start": "2523960",
    "end": "2532680"
  }
]
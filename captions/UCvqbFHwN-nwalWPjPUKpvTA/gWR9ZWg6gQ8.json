[
  {
    "text": "hey morning alex um in fact probably good afternoon uh good morning",
    "start": "317199",
    "end": "325840"
  },
  {
    "text": "by the way i noticed this um session when i just joined instead of recording",
    "start": "328880",
    "end": "334320"
  },
  {
    "text": "right so zoom can now do automatic recording now",
    "start": "334320",
    "end": "339360"
  },
  {
    "text": "yeah all of the sick uh meetings are are set to automatically record and then",
    "start": "339360",
    "end": "346560"
  },
  {
    "text": "they get posted to youtube so they're available for the public okay yeah so i i don't i i know that i",
    "start": "346560",
    "end": "353840"
  },
  {
    "text": "just don't know that you can automatically recording a session in zoom right now every time we have to manually click the",
    "start": "353840",
    "end": "360000"
  },
  {
    "text": "button yeah i think i think there's a setting you can you can use when you",
    "start": "360000",
    "end": "366080"
  },
  {
    "text": "set up the zoom call originally hey aaron morning you beat me here",
    "start": "366080",
    "end": "374240"
  },
  {
    "text": "i was having zuma shoes and i had to reboot and then i was jumping out oh no there's going to be people around",
    "start": "374240",
    "end": "380160"
  },
  {
    "text": "and the meeting isn't started",
    "start": "380160",
    "end": "383280"
  },
  {
    "text": "we're good all right",
    "start": "386000",
    "end": "395840"
  },
  {
    "text": "hey alex uh which time zone in i am in the uk time zone",
    "start": "433120",
    "end": "440160"
  },
  {
    "text": "okay gmt yeah uh erin which which times are you in i'm",
    "start": "440160",
    "end": "447599"
  },
  {
    "text": "in uh mountain time zone so hour ahead of pacific yep",
    "start": "447599",
    "end": "456319"
  },
  {
    "text": "oh you still already morning yeah not too early plenty of cups of coffee",
    "start": "456960",
    "end": "463440"
  },
  {
    "text": "into yeah i basically just got a get up like one hour ago",
    "start": "463440",
    "end": "470720"
  },
  {
    "text": "are you um yeah i'm on the pacific time zone i'm i'm basing chinos i'm basing it so i say in fact",
    "start": "473919",
    "end": "480639"
  },
  {
    "text": "currently okay great looks like we have pretty light",
    "start": "480639",
    "end": "485680"
  },
  {
    "text": "attendance today alex uh yeah",
    "start": "485680",
    "end": "493840"
  },
  {
    "text": "and we should wait a couple more minutes yeah sure",
    "start": "495199",
    "end": "507840"
  },
  {
    "text": "yeah with the uk we're in we're in this weird week where everything is off by an",
    "start": "515120",
    "end": "521518"
  },
  {
    "text": "hour because daylight savings went back last sunday within the uh but in the us",
    "start": "521519",
    "end": "527839"
  },
  {
    "text": "it goes back next sunday uh yeah you know that's california has voted to cancel",
    "start": "527839",
    "end": "535839"
  },
  {
    "text": "to cancel the daylight saving but it's only on the like state level and",
    "start": "535839",
    "end": "541040"
  },
  {
    "text": "they said that you have to get permission from the federal level to really remove it right but then it has another problem",
    "start": "541040",
    "end": "548240"
  },
  {
    "text": "say the california is going to have a different time zone compared to uh say uh washington and",
    "start": "548240",
    "end": "555680"
  },
  {
    "text": "oregon right that's going to be weird because you're basically on the supposedly on the same time zone so well",
    "start": "555680",
    "end": "562160"
  },
  {
    "text": "but this daylight savings things i've heard is like um hundreds people probably have a higher",
    "start": "562160",
    "end": "568000"
  },
  {
    "text": "risk of a stroke every year because of like change of the schedule and change of clock stuff",
    "start": "568000",
    "end": "573440"
  },
  {
    "text": "not really sure why i still need it yeah never knew they could correlate it",
    "start": "573440",
    "end": "580399"
  },
  {
    "text": "with health problems based on the time change yeah",
    "start": "580399",
    "end": "587519"
  },
  {
    "text": "i think i'm scared because you don't oh no in fact uh i i don't think arizona has",
    "start": "587519",
    "end": "593600"
  },
  {
    "text": "daylight saving [Music] right they don't okay",
    "start": "593600",
    "end": "599120"
  },
  {
    "text": "yeah but not all the mountain time i guess",
    "start": "599120",
    "end": "605839"
  },
  {
    "text": "alright i think we don't have a lot of people joined",
    "start": "614160",
    "end": "621120"
  },
  {
    "text": "oh we've got a couple more now um but i'd suggest uh i suggest we we um we we can start",
    "start": "621120",
    "end": "628880"
  },
  {
    "text": "and then we can share we can show the recording if need be okay sure",
    "start": "628880",
    "end": "634959"
  },
  {
    "text": "all right so yeah so i was going to ask you this question which screen do you see",
    "start": "637200",
    "end": "646240"
  },
  {
    "text": "i see the full the full screen um presentation page here okay that's good",
    "start": "646240",
    "end": "651680"
  },
  {
    "text": "all right so uh thanks everyone uh for uh joining this session and uh so as you",
    "start": "651680",
    "end": "658560"
  },
  {
    "text": "know that loan form is currently a cncf sandbox project and we are applying for the incubation",
    "start": "658560",
    "end": "665680"
  },
  {
    "text": "stage so this is the longer incubation review all right so uh for this review first i'm going to go",
    "start": "665680",
    "end": "672640"
  },
  {
    "text": "through a few like recaps about basic of longhorn why we do it and how we do it and the later we can uh",
    "start": "672640",
    "end": "680240"
  },
  {
    "text": "go through that how longhorn has grown uh growth um and things join the cncf and with",
    "start": "680240",
    "end": "687040"
  },
  {
    "text": "tractions and i was on the roadmap i see so feel free to interrupt me at any",
    "start": "687040",
    "end": "693120"
  },
  {
    "text": "moment and uh yeah so let's get started all right so what is longhorn so um",
    "start": "693120",
    "end": "701760"
  },
  {
    "text": "longhorn is the open source distributed storage software for kubernetes our goal is pretty clear we want to have",
    "start": "701760",
    "end": "709440"
  },
  {
    "text": "very simple and very um very simple way to add persistent story",
    "start": "709440",
    "end": "715200"
  },
  {
    "text": "to your cluster so one click installation to add persistent storage support for any kubernetes cluster",
    "start": "715200",
    "end": "722079"
  },
  {
    "text": "is the goal we want to have and also the things is there are the few things",
    "start": "722079",
    "end": "728720"
  },
  {
    "text": "like differentiate long form from others so we call them the design principles of",
    "start": "728720",
    "end": "734320"
  },
  {
    "text": "longhorn so first is reliability and because it's a storage software",
    "start": "734320",
    "end": "741440"
  },
  {
    "text": "right so the last thing you want to do is like lost your data so long form provides crash",
    "start": "741440",
    "end": "748240"
  },
  {
    "text": "consistent and make sure that in every data you write to the long run",
    "start": "748240",
    "end": "753440"
  },
  {
    "text": "volume will be right and the preserved on the disk it's no cache in between",
    "start": "753440",
    "end": "758480"
  },
  {
    "text": "right and the second thing is room provides multiple layers of protection against the data loss",
    "start": "758480",
    "end": "764000"
  },
  {
    "text": "so that's including the building snapshot mechanism which is inside the cluster and also the backup",
    "start": "764000",
    "end": "770480"
  },
  {
    "text": "support which going to backup the snapdragon to offsite outside the cluster to for example s3 or nfs server",
    "start": "770480",
    "end": "778320"
  },
  {
    "text": "and in fact there's a third layer compared to some other solutions is if you have your longhorn",
    "start": "778320",
    "end": "785760"
  },
  {
    "text": "used directory data directory available in fact you can directly extract the data from that",
    "start": "785760",
    "end": "791440"
  },
  {
    "text": "given that you for example you lost your whole kubernetes system and you lost your whole every metadata",
    "start": "791440",
    "end": "797440"
  },
  {
    "text": "right that is the one thing that based on because of how long works that is possible for longhorn to",
    "start": "797440",
    "end": "802720"
  },
  {
    "text": "do so so i'm going to go through the architecture a little bit later the second thing is that we want",
    "start": "802720",
    "end": "809120"
  },
  {
    "text": "long form to be very easy to use so one click installation remote we are going to",
    "start": "809120",
    "end": "814720"
  },
  {
    "text": "detect your environment and choose the best way to install longhorn so uh previously that means in fact this",
    "start": "814720",
    "end": "821360"
  },
  {
    "text": "helped a lot during the early days of long run when those uh kubernetes has the driver choice of the",
    "start": "821360",
    "end": "828800"
  },
  {
    "text": "flex volume and the csi we migrate to csi at like in csi",
    "start": "828800",
    "end": "834959"
  },
  {
    "text": "0.3 and later 0.4 and upgrade to 1.0 but in fact even like sometimes you have",
    "start": "834959",
    "end": "841519"
  },
  {
    "text": "to choose flex volume for the kubernetes distribution doesn't have it and the csi different versions in fact",
    "start": "841519",
    "end": "846880"
  },
  {
    "text": "it's not really compatible so we built something called the driver display deployer to",
    "start": "846880",
    "end": "852079"
  },
  {
    "text": "automatically detect the version of your kubernetes and the uninstall the compatible csi for you um",
    "start": "852079",
    "end": "858639"
  },
  {
    "text": "now is the last problem because everybody has standardized to csi 1.0 but a lot of still a lot of effort we",
    "start": "858639",
    "end": "865360"
  },
  {
    "text": "made in to try to make this manual configuration installation process as easy as possible",
    "start": "865360",
    "end": "871839"
  },
  {
    "text": "another thing is don't provide the policy user experience including a building the main ui you",
    "start": "871839",
    "end": "878079"
  },
  {
    "text": "don't need to have like third-party ui or like add add-on for that so that is all included so you can",
    "start": "878079",
    "end": "884560"
  },
  {
    "text": "operate long form many like create volume stuff inside the group control of course but",
    "start": "884560",
    "end": "890560"
  },
  {
    "text": "you can also do that from the ui and you can see the dashboard and to show what's the system level",
    "start": "890560",
    "end": "898320"
  },
  {
    "text": "overview looks like and it performed the backup restore snapshot scheduling backup those kind of operation ui as",
    "start": "898320",
    "end": "904240"
  },
  {
    "text": "well the third thing is the main ability so the ones",
    "start": "904240",
    "end": "909440"
  },
  {
    "text": "the one thing about manageability is it's more like by design right because when you make",
    "start": "909440",
    "end": "915680"
  },
  {
    "text": "your design choices to say how you how this software should work is going to decide that how easy or how",
    "start": "915680",
    "end": "922639"
  },
  {
    "text": "hard is going to be maintained so longhorn is designed to be easy to be understand",
    "start": "922639",
    "end": "928079"
  },
  {
    "text": "so when i will talk about a little bit more on the architecture later but the really goal is make sure that",
    "start": "928079",
    "end": "933680"
  },
  {
    "text": "even you don't really have like very complex storage background you can understand most of concept",
    "start": "933680",
    "end": "939199"
  },
  {
    "text": "and understand how low home works right then also longhorn provides a way to easy to",
    "start": "939199",
    "end": "944560"
  },
  {
    "text": "recover you in the worst case scenario that is as long as well i mentioned there's three layers of protection as",
    "start": "944560",
    "end": "950880"
  },
  {
    "text": "long as you have any one of them available you can recover your data in in",
    "start": "950880",
    "end": "956079"
  },
  {
    "text": "in for recovery data of your cluster right and look also provides upgrade without",
    "start": "956079",
    "end": "961279"
  },
  {
    "text": "interrupting workload uh that is also what we call the live upgrade feature which means that",
    "start": "961279",
    "end": "967199"
  },
  {
    "text": "you can feel free to upgrade your longhorn including lower data engine and the when",
    "start": "967199",
    "end": "974320"
  },
  {
    "text": "you still have the running workload right so that's really like reduce your",
    "start": "974320",
    "end": "979440"
  },
  {
    "text": "downtime reduce your schedule to maintain this window when you want to do the continuous uh",
    "start": "979440",
    "end": "984720"
  },
  {
    "text": "like deployment of when we want to do the maintenance work for for your cluster",
    "start": "984720",
    "end": "991199"
  },
  {
    "text": "all all right yeah so here",
    "start": "991199",
    "end": "999199"
  },
  {
    "text": "is our latest release and the 102 and on the right side i have left a bunch of",
    "start": "999199",
    "end": "1004480"
  },
  {
    "text": "the features and i will just go through very quickly and distribute blog server",
    "start": "1004480",
    "end": "1010800"
  },
  {
    "text": "software well in the 1.1.1 upcoming 101 release we are aiming to add read write menu as well",
    "start": "1010800",
    "end": "1016639"
  },
  {
    "text": "and using nfs and that's going to be building so i'm going to call the distributed story so",
    "start": "1016639",
    "end": "1022160"
  },
  {
    "text": "fail in the next release and the wording stream provisioning means that what are over provisioned in underlaying",
    "start": "1022160",
    "end": "1029520"
  },
  {
    "text": "by using link spots file to preserve the metadata and the data right so this doesn't take extra space",
    "start": "1029520",
    "end": "1035600"
  },
  {
    "text": "unless you use the up to all the spaces and what in snapshots and backup restore snapshot how we define",
    "start": "1035600",
    "end": "1041918"
  },
  {
    "text": "snapshot others the history snapshot point inside cluster which as long as you have",
    "start": "1041919",
    "end": "1048400"
  },
  {
    "text": "this warning inside cluster you can revert back and stuff and the backup and it's going to be outside the cluster",
    "start": "1048400",
    "end": "1054720"
  },
  {
    "text": "right so that we support incremental backup and incremental restore so what an expansion and you can resize",
    "start": "1054720",
    "end": "1061360"
  },
  {
    "text": "the volume across az replica scheduling this is mostly for some uh clouding vendor",
    "start": "1061360",
    "end": "1067600"
  },
  {
    "text": "environments and they want to have the enhanced availability across the whole whole controlled different age in the",
    "start": "1067600",
    "end": "1074080"
  },
  {
    "text": "same region right so then you lost one you see sorry",
    "start": "1074080",
    "end": "1079520"
  },
  {
    "text": "then if you lost one ac you still find and storage type for node disk selection and a cross cluster dr volume with",
    "start": "1079520",
    "end": "1086480"
  },
  {
    "text": "defined rto rpo and live upgrade i mentioned before and the ui i want to click installation and",
    "start": "1086480",
    "end": "1092160"
  },
  {
    "text": "more all right so any questions so far",
    "start": "1092160",
    "end": "1097120"
  },
  {
    "text": "okay all right so this is the overview of how and how",
    "start": "1097200",
    "end": "1102799"
  },
  {
    "text": "longhorn works on the knees so currently we have two notes here both node has a storage and",
    "start": "1102799",
    "end": "1109520"
  },
  {
    "text": "the ram and cpu and the kubernetes ask longhorn for new warning",
    "start": "1109520",
    "end": "1114559"
  },
  {
    "text": "right so this when this request come in logo is going to create two replicas um preferably on two",
    "start": "1114559",
    "end": "1121600"
  },
  {
    "text": "different nodes because we want to have like uh if one graphic up and down we still have the replica",
    "start": "1121600",
    "end": "1127200"
  },
  {
    "text": "available on the other node i can show i can demonstrate the process of philadelphia later",
    "start": "1127200",
    "end": "1132640"
  },
  {
    "text": "so then longhorn is going to create an engine to connect it to those replicas and the engine is going to expose the",
    "start": "1132640",
    "end": "1139360"
  },
  {
    "text": "block device to the warning right so this is very simple way of doing",
    "start": "1139360",
    "end": "1144400"
  },
  {
    "text": "like do to set up this the data path to provide the storage for the for the part to use",
    "start": "1144400",
    "end": "1151200"
  },
  {
    "text": "if we are going to have the second part asking for a second volume we do the same and third part we do the same so there",
    "start": "1151200",
    "end": "1158000"
  },
  {
    "text": "are two advantages of this approach the first thing is you can see that the data path of each volume is not it's",
    "start": "1158000",
    "end": "1165919"
  },
  {
    "text": "not in the wind it's basically isolated from each other right so if one volume goes downward even one",
    "start": "1165919",
    "end": "1172960"
  },
  {
    "text": "engine go down it's not going to in fact like affect any other volumes right",
    "start": "1172960",
    "end": "1178320"
  },
  {
    "text": "another thing is you can see the engine we have here is always collocated with the part with",
    "start": "1178320",
    "end": "1185280"
  },
  {
    "text": "the workload so in the in the most common scenario that we want to guard against for the sa",
    "start": "1185280",
    "end": "1192640"
  },
  {
    "text": "cases is the note down but in this case um if the node one is",
    "start": "1192640",
    "end": "1198160"
  },
  {
    "text": "down for example and then the engine the volume work the engine will be down of course but the",
    "start": "1198160",
    "end": "1203360"
  },
  {
    "text": "workload part one will be done as well right so then the kubernetes are going to",
    "start": "1203360",
    "end": "1208640"
  },
  {
    "text": "like reschedule the part to another node and the engine can be mine like just move along with it and",
    "start": "1208640",
    "end": "1213840"
  },
  {
    "text": "everything will be back to normal so that's greatly simplifying our design for the engine because we don't need to",
    "start": "1213840",
    "end": "1219919"
  },
  {
    "text": "have one engine to kill like more than one node and then this we don't need to have",
    "start": "1219919",
    "end": "1226000"
  },
  {
    "text": "really complex mechanism to do the same engine right so",
    "start": "1226000",
    "end": "1231919"
  },
  {
    "text": "um but how does this how why there's nothing like this before",
    "start": "1231919",
    "end": "1237039"
  },
  {
    "text": "right so the problem is because engine replicas in fact are micro services they're",
    "start": "1237039",
    "end": "1242159"
  },
  {
    "text": "currently running as processes right and the uh and the first version in fact when we come up this are running",
    "start": "1242159",
    "end": "1248320"
  },
  {
    "text": "on h1 as a container as parts but we do hear some limitations later so we change them into process but",
    "start": "1248320",
    "end": "1254720"
  },
  {
    "text": "in the end those are separately orchestrated entities so it's pretty hard to do this without",
    "start": "1254720",
    "end": "1262000"
  },
  {
    "text": "the help of kubernetes right if it's possible right so that's why this mechanism this way we choose to do",
    "start": "1262000",
    "end": "1268880"
  },
  {
    "text": "it is basically it's bound to kubernetes it's with a kubernetes help we can do this otherwise it's going to",
    "start": "1268880",
    "end": "1275760"
  },
  {
    "text": "be like we have to write some our own scheduling mechanism to move this part move this",
    "start": "1275760",
    "end": "1282400"
  },
  {
    "text": "engine process around those stuff that is why we that is why we only see is this kind",
    "start": "1282400",
    "end": "1288960"
  },
  {
    "text": "of magnesium coming this kind of character coming until now right this is basically because of docker",
    "start": "1288960",
    "end": "1295679"
  },
  {
    "text": "docker's ability for you to package one service in a single container and kubernetes ability for you",
    "start": "1295679",
    "end": "1301600"
  },
  {
    "text": "to schedule new parts around without really adding much of overhead on your side",
    "start": "1301600",
    "end": "1307679"
  },
  {
    "text": "hey hey shang so just a quick question um so is",
    "start": "1308720",
    "end": "1315280"
  },
  {
    "text": "effectively does every volume have its own engine yes",
    "start": "1315280",
    "end": "1322320"
  },
  {
    "text": "and and is every engine a separate process yes okay and",
    "start": "1322320",
    "end": "1329200"
  },
  {
    "text": "does does every replica have its own process or or is that yeah every has its own process",
    "start": "1329200",
    "end": "1335760"
  },
  {
    "text": "as well so a little bit of history that we will design every engine replica to be a docker",
    "start": "1335760",
    "end": "1341840"
  },
  {
    "text": "container instead of a process and a first version i think before",
    "start": "1341840",
    "end": "1347159"
  },
  {
    "text": "0.6 right but later we have a one user going and complaining",
    "start": "1347159",
    "end": "1352960"
  },
  {
    "text": "wow i have a huge app a very very big machine it's so beefy and i can run like",
    "start": "1352960",
    "end": "1358880"
  },
  {
    "text": "20 30 workload on that and then i needed 130 volumes well but all those engine and replicas",
    "start": "1358880",
    "end": "1367200"
  },
  {
    "text": "take place inside the part so then i'm going to have like well 80 if i really round them on a",
    "start": "1367200",
    "end": "1373760"
  },
  {
    "text": "single note they'll have eight or even minimum 40 red parts and they just take a lot of",
    "start": "1373760",
    "end": "1379679"
  },
  {
    "text": "force because that is only allowed at 110 parts per node right so then we decided",
    "start": "1379679",
    "end": "1386400"
  },
  {
    "text": "we just decided okay so it seems to make more sense that we um aggregated to a way that",
    "start": "1386400",
    "end": "1392480"
  },
  {
    "text": "they are running as a separate instance a separate process but they are on the same note so we save that",
    "start": "1392480",
    "end": "1399200"
  },
  {
    "text": "resource on the port level so that's why uh in the next page you will see something called instance manager that is",
    "start": "1399200",
    "end": "1406080"
  },
  {
    "text": "why um and how it works right now right okay thank you uh any other",
    "start": "1406080",
    "end": "1412080"
  },
  {
    "text": "questions yeah just a related question so these engines replicas are these like",
    "start": "1412080",
    "end": "1419600"
  },
  {
    "text": "built using kubernetes primitives or they are not like kubernetes based so for example",
    "start": "1419600",
    "end": "1426559"
  },
  {
    "text": "does the engine correspond to a pod or some kubernetes abstraction or it's uh yeah so the engine itself",
    "start": "1426559",
    "end": "1434799"
  },
  {
    "text": "doesn't really doesn't correlate but it was related to a part as i said before but because of like chord limitation we",
    "start": "1434799",
    "end": "1442240"
  },
  {
    "text": "had on the values it can only be 110 per node right so we decided to not take that",
    "start": "1442240",
    "end": "1448159"
  },
  {
    "text": "resource like after later right so now the engine is running inside the pod",
    "start": "1448159",
    "end": "1453360"
  },
  {
    "text": "right and there can be multiple engines running inside that we call it as many parts i can explain",
    "start": "1453360",
    "end": "1459039"
  },
  {
    "text": "more on the next page okay i'll wait till the next page",
    "start": "1459039",
    "end": "1467520"
  },
  {
    "text": "all right okay so this is some detailed review of the",
    "start": "1469520",
    "end": "1474960"
  },
  {
    "text": "architecture of the engine side you can see that now we have three nodes and the um the",
    "start": "1474960",
    "end": "1480080"
  },
  {
    "text": "node you can also see that there are some nodes they have a sprayer disk for longhorn like",
    "start": "1480080",
    "end": "1485520"
  },
  {
    "text": "this black colored ssd we can use that for longer but you have like some what's yellow colored which we",
    "start": "1485520",
    "end": "1491919"
  },
  {
    "text": "assume is the root disk you don't really want to use it for the storage otherwise you might introduce unwanted like this pressure",
    "start": "1491919",
    "end": "1498159"
  },
  {
    "text": "stuff right so you want to have separate you have one separated and also you can",
    "start": "1498159",
    "end": "1503520"
  },
  {
    "text": "see that for the node that's with without or with the storage for longhorn you have a",
    "start": "1503520",
    "end": "1510159"
  },
  {
    "text": "replica instance manager running on top of that that means those nodes are potentially able to run replicas",
    "start": "1510159",
    "end": "1515600"
  },
  {
    "text": "but for every node because they are able to all of the know that here are vocal they are able to run uh using the long",
    "start": "1515600",
    "end": "1522799"
  },
  {
    "text": "volume so we are going to have engines managed running on top of that so let's take the same example we have",
    "start": "1522799",
    "end": "1530000"
  },
  {
    "text": "port a and we want to create a volume for port a we have replicas scheduled on two",
    "start": "1530000",
    "end": "1535279"
  },
  {
    "text": "different nodes node one node two and then the replica process will be started inside",
    "start": "1535279",
    "end": "1540400"
  },
  {
    "text": "replica instance manager and the engine process will start inside the instance manager on the same node after",
    "start": "1540400",
    "end": "1546640"
  },
  {
    "text": "part a and then connect to expose block device to uh to part a",
    "start": "1546640",
    "end": "1552320"
  },
  {
    "text": "right pretty straightforward and you have pro we have for b on the on the uh note 2 and we do the",
    "start": "1552320",
    "end": "1558960"
  },
  {
    "text": "same thing plus c on the node 2 we do the same thing right so next question is what's going to happen",
    "start": "1558960",
    "end": "1565039"
  },
  {
    "text": "if the node a when node 1 went down so if no one went down",
    "start": "1565039",
    "end": "1570400"
  },
  {
    "text": "as you can see in the previous page uh support a in fact the volume a going to have we",
    "start": "1570400",
    "end": "1575440"
  },
  {
    "text": "have the engine on node one and the replica and node one the two node one went down and port one output a",
    "start": "1575440",
    "end": "1582400"
  },
  {
    "text": "everything went down right but because it's kubernetes kubernetes is going to decide that okay so i saw this",
    "start": "1582400",
    "end": "1588240"
  },
  {
    "text": "note down so i'm going to reschedule this part to another node i found the node 3. so kubernetes",
    "start": "1588240",
    "end": "1594720"
  },
  {
    "text": "reschedule the path and restart it on the node 3 and say no quote i still need a warning",
    "start": "1594720",
    "end": "1600400"
  },
  {
    "text": "and then the command is asking for the volume and long ones see that okay so there's still a data of this",
    "start": "1600400",
    "end": "1608480"
  },
  {
    "text": "what workload is inside the node 2 as you can see that's right the red replica there and the longhorn",
    "start": "1608480",
    "end": "1615120"
  },
  {
    "text": "is going to start the engine on note 3 and connect it to the red replica and resume the service to the port a right",
    "start": "1615120",
    "end": "1622080"
  },
  {
    "text": "so that is the how the just in the overview if the failure",
    "start": "1622080",
    "end": "1627200"
  },
  {
    "text": "happens how the recovery works in the goodness word",
    "start": "1627200",
    "end": "1632880"
  },
  {
    "text": "all right any any questions yeah okay so yeah so it seems basically instance managers and replica insurance",
    "start": "1635039",
    "end": "1641600"
  },
  {
    "text": "managers are kind of like demonstrating on every node right but they're they",
    "start": "1641600",
    "end": "1646960"
  },
  {
    "text": "don't create themselves a theory yeah so but they're in fact just controlled by",
    "start": "1646960",
    "end": "1653120"
  },
  {
    "text": "the long horn we built the controller for them because for example when you when you don't have available disks on",
    "start": "1653120",
    "end": "1658640"
  },
  {
    "text": "the node you don't really need a replica instance manager right so that that's why we build them as",
    "start": "1658640",
    "end": "1664320"
  },
  {
    "text": "as a separate controller rather than just using demonsent right but every one of them is a definite part",
    "start": "1664320",
    "end": "1671520"
  },
  {
    "text": "okay and then like now the failover scenario that you describe do we also constitute",
    "start": "1671520",
    "end": "1679279"
  },
  {
    "text": "a new replica on the on note 3 the failover node uh yeah so",
    "start": "1679279",
    "end": "1684399"
  },
  {
    "text": "currently so if there's note four with available disk on node four they yeah we'll recreate the replica of",
    "start": "1684399",
    "end": "1691039"
  },
  {
    "text": "course and because note 3 doesn't have a disk available for the longhorn right so that is that is why we don't do the",
    "start": "1691039",
    "end": "1698799"
  },
  {
    "text": "rebuild of the replica on node three so of course even node one went back we can reuse that replica",
    "start": "1698799",
    "end": "1706000"
  },
  {
    "text": "does that answer your question okay i saw like the red ssc icon so i",
    "start": "1707600",
    "end": "1714159"
  },
  {
    "text": "thought note 3 also has local storage well yeah that's exactly yeah it's what we i want to indicate that's",
    "start": "1714159",
    "end": "1721440"
  },
  {
    "text": "kind of different that is for the root file system right so that is the the available disk",
    "start": "1721440",
    "end": "1727360"
  },
  {
    "text": "is like much says those black or gray colors right so the ssd on note 3 is not really",
    "start": "1727360",
    "end": "1735440"
  },
  {
    "text": "for the long-haul storage so that is also why we don't have the replica instance manager running there",
    "start": "1735440",
    "end": "1742398"
  },
  {
    "text": "hey so quick very quick question and maybe you might come to this in this in a future slide but if",
    "start": "1744559",
    "end": "1751440"
  },
  {
    "text": "if as you said um node one you know um reboots or recovers and and comes",
    "start": "1751440",
    "end": "1757279"
  },
  {
    "text": "back onto the network um so the the the engine on on node",
    "start": "1757279",
    "end": "1762960"
  },
  {
    "text": "three can then reconnect to the to the replica that's on node one",
    "start": "1762960",
    "end": "1769039"
  },
  {
    "text": "but would it would it have to i i assume it would have to re-sync it right at that stage",
    "start": "1769039",
    "end": "1775520"
  },
  {
    "text": "yeah so uh currently in the one.x and we uh we always review the new",
    "start": "1775520",
    "end": "1781360"
  },
  {
    "text": "replica but for the webcoming111.1 release we are going to try to start using the existing replica",
    "start": "1781360",
    "end": "1787760"
  },
  {
    "text": "but of course any replica we use to either review the new replica or using solution replica we are going to",
    "start": "1787760",
    "end": "1793600"
  },
  {
    "text": "check and sync the data before we can use it it's always going to be that case yeah we cannot just",
    "start": "1793600",
    "end": "1798640"
  },
  {
    "text": "blindly use it anyway right",
    "start": "1798640",
    "end": "1805039"
  },
  {
    "text": "also the recovery workflow that you outline does that also happen when you do don't add any new nodes so",
    "start": "1806799",
    "end": "1813520"
  },
  {
    "text": "let's say if you already had another node 3 that was already serving some engines and some replicas can that take over serving the engines",
    "start": "1813520",
    "end": "1821919"
  },
  {
    "text": "are replicas of node 1 that failed you don't necessarily have to add new nodes to",
    "start": "1821919",
    "end": "1827120"
  },
  {
    "text": "replace node 1. is that possible uh sorry i don't quite get the question",
    "start": "1827120",
    "end": "1836240"
  },
  {
    "text": "so in this example that you showed once node one failed you added a new node node three",
    "start": "1836240",
    "end": "1842080"
  },
  {
    "text": "and then node three became responsible for all the yeah so in fact note three is always be there right so this is not",
    "start": "1842080",
    "end": "1848159"
  },
  {
    "text": "running like related workload at the moment but note 3 is inside cluster so yeah of course if you want to add a",
    "start": "1848159",
    "end": "1854880"
  },
  {
    "text": "new node the new node will have the engine instance manager and parts unlike if you could not decide to",
    "start": "1854880",
    "end": "1861760"
  },
  {
    "text": "schedule part on that node that's still going to work right if you say if the like say if you don't",
    "start": "1861760",
    "end": "1869760"
  },
  {
    "text": "have note 3 and you have no 2 and a kubernete decided to schedule this part a on no 2 yeah it was still still going to",
    "start": "1869760",
    "end": "1876799"
  },
  {
    "text": "work it's not it's no different i just using those three to make like the concept more clearly here it",
    "start": "1876799",
    "end": "1883200"
  },
  {
    "text": "doesn't doesn't need to be so the long horns engine and the replica",
    "start": "1883200",
    "end": "1888559"
  },
  {
    "text": "is unless you enable a certain feature called data localities doesn't need to be on the same node",
    "start": "1888559",
    "end": "1894960"
  },
  {
    "text": "does that make sense um so i think these are separate issues",
    "start": "1896720",
    "end": "1902880"
  },
  {
    "text": "but i think locality here really as far as long hauler is concerned a pod that is consuming a long core volume has",
    "start": "1902880",
    "end": "1909279"
  },
  {
    "text": "to have a just a local engine yes but the actual data the actual replica can be on a",
    "start": "1909279",
    "end": "1914880"
  },
  {
    "text": "different note yes",
    "start": "1914880",
    "end": "1921840"
  },
  {
    "text": "all right and nothing prevents any note from serving engines from any other nodes right",
    "start": "1923120",
    "end": "1929600"
  },
  {
    "text": "um yes yeah so i i don't quite understand what",
    "start": "1929840",
    "end": "1935440"
  },
  {
    "text": "you mean by surfing engine but yes any engine as long as there is a replica inside this",
    "start": "1935440",
    "end": "1941679"
  },
  {
    "text": "kubernetes cluster and then you can have engine connect to that replica and the serving serving the volume yes from any node",
    "start": "1941679",
    "end": "1949600"
  },
  {
    "text": "inside cluster as long as you have like a limitation on that part",
    "start": "1949600",
    "end": "1955360"
  },
  {
    "text": "so so just one last question kind of related to that um so",
    "start": "1956240",
    "end": "1962880"
  },
  {
    "text": "i'm assuming um an engine spun off within the engine instance",
    "start": "1962880",
    "end": "1968480"
  },
  {
    "text": "manager as part of a kubernetes controller receiving a request or something",
    "start": "1968480",
    "end": "1975200"
  },
  {
    "text": "perhaps for icsi or something like that i'm i'm kind of speculating um but how",
    "start": "1975200",
    "end": "1983120"
  },
  {
    "text": "how do you make the decision to to schedule a replica on on any",
    "start": "1983120",
    "end": "1990159"
  },
  {
    "text": "particular nodes is is that is there is there some some logic or",
    "start": "1990159",
    "end": "1996320"
  },
  {
    "text": "determination there or or or is it around dropping or um yeah so this basically comes down to",
    "start": "1996320",
    "end": "2003279"
  },
  {
    "text": "the their nose that first this the first thing is of course the notes of the disc should",
    "start": "2003279",
    "end": "2008559"
  },
  {
    "text": "have the space right otherwise assuming they should have the space and the second thing is they have to",
    "start": "2008559",
    "end": "2015039"
  },
  {
    "text": "meet the uh restriction as like like storage tag for example i always i have to schedule this ruling",
    "start": "2015039",
    "end": "2021679"
  },
  {
    "text": "with this tag with the disk on this tag or note down this time they'll have to be there and the third",
    "start": "2021679",
    "end": "2026720"
  },
  {
    "text": "thing is if you enable the start and dfinity which is enabled by default",
    "start": "2026720",
    "end": "2032880"
  },
  {
    "text": "and then the replica need to be scheduled on the different nodes right always going to be on the different nodes so if you don't have a",
    "start": "2032880",
    "end": "2039440"
  },
  {
    "text": "different node to certify that requirement they're going to schedule failure and those parts and",
    "start": "2039440",
    "end": "2044559"
  },
  {
    "text": "also there's a bunch of other scheduling rules you have to apply once you pass all those filters and then",
    "start": "2044559",
    "end": "2051440"
  },
  {
    "text": "you have we are going to get a like available list of the disk and after after that we're going to just",
    "start": "2051440",
    "end": "2057200"
  },
  {
    "text": "pick one from them because all of them meet our scheduling uh like requirement",
    "start": "2057200",
    "end": "2063679"
  },
  {
    "text": "got it okay thank you thank you okay so uh this is on engine",
    "start": "2064159",
    "end": "2071040"
  },
  {
    "text": "and the next slide is on the manager in fact this is going to be even simpler so we have kubernetes cluster and",
    "start": "2071040",
    "end": "2077200"
  },
  {
    "text": "kubernetes class one warning so who i talked to the connect cluster is going to talk",
    "start": "2077200",
    "end": "2082398"
  },
  {
    "text": "uh to the longest css plugin through the csi interface right the longer says that plugin is",
    "start": "2082399",
    "end": "2088480"
  },
  {
    "text": "running as a demo set on every node and then it was going to talk to the local manager which is also running on the",
    "start": "2088480",
    "end": "2094158"
  },
  {
    "text": "demonstration on every node and the normal manager's work is to orchestrate all the volumes and",
    "start": "2094159",
    "end": "2099520"
  },
  {
    "text": "determine like and also local manager is in fact a kubernetes like controller and",
    "start": "2099520",
    "end": "2106160"
  },
  {
    "text": "he going to for example i ask him for a new warning so normal manager going to create a volume crd object and store that in the kubernetes",
    "start": "2106160",
    "end": "2113280"
  },
  {
    "text": "a guest server right of course backed by icd or others and then the controllers the volume",
    "start": "2113280",
    "end": "2118480"
  },
  {
    "text": "controllers inside local manager watch for the object and see okay this is the new volume",
    "start": "2118480",
    "end": "2124240"
  },
  {
    "text": "object coming so i need to create a replica an engine for it and then they decide to create those",
    "start": "2124240",
    "end": "2129359"
  },
  {
    "text": "replicas and engine and the formula from the volume and provided to the user",
    "start": "2129359",
    "end": "2134960"
  },
  {
    "text": "right so it's always going to be it's going to be the same when you have asking for more volumes and the local",
    "start": "2134960",
    "end": "2141440"
  },
  {
    "text": "manager we're going to create more engine and replicas and oxide all those volumes and the provided to the user",
    "start": "2141440",
    "end": "2148640"
  },
  {
    "text": "another way to complement the kubernetes cluster kubernetes permeative is to is the local",
    "start": "2148640",
    "end": "2154880"
  },
  {
    "text": "ui so because the local man because on the csi we normally in charge of like a",
    "start": "2154880",
    "end": "2160160"
  },
  {
    "text": "crate to delete volumes attach detach amount stuff and now we add the ability to do the snapshot which in",
    "start": "2160160",
    "end": "2166800"
  },
  {
    "text": "fact the backup in the longhorn but before that so long-form ui also can do node management for example you want",
    "start": "2166800",
    "end": "2173200"
  },
  {
    "text": "to add more disk to this node and also doing the backup and the snapshot and you can also set",
    "start": "2173200",
    "end": "2181920"
  },
  {
    "text": "the recurring snapshot which means that you want to take a snapshot or take a backup every morning at one am and you can ask you",
    "start": "2181920",
    "end": "2189200"
  },
  {
    "text": "know you can use internal manager to configure it but also of course if you uh if you prefer",
    "start": "2189200",
    "end": "2194560"
  },
  {
    "text": "you can also use the cognitive storage class to configure that as well yeah so local ui is currently a",
    "start": "2194560",
    "end": "2200000"
  },
  {
    "text": "complement for the uh the most csv plugin and then they have the that combination of them both they will",
    "start": "2200000",
    "end": "2206560"
  },
  {
    "text": "have the full functionality which we exposed to the user and in the future we are going to introduce a longer cr as well to allow",
    "start": "2206560",
    "end": "2212880"
  },
  {
    "text": "you to program it program those logic inside your for example your maintenance script",
    "start": "2212880",
    "end": "2218880"
  },
  {
    "text": "stuff",
    "start": "2218880",
    "end": "2221200"
  },
  {
    "text": "all right okay so here is the comparison to the",
    "start": "2224000",
    "end": "2232160"
  },
  {
    "text": "existing csn project uh well i'm just going to go through",
    "start": "2232160",
    "end": "2238240"
  },
  {
    "text": "live online and the first one is what's the position and for long term we always position to",
    "start": "2238240",
    "end": "2243520"
  },
  {
    "text": "be a full stack storage software and compiled to rook which is i think it currently is graduated",
    "start": "2243520",
    "end": "2249040"
  },
  {
    "text": "and the position as a storage orchestration and open ebs is also full stack storage software and",
    "start": "2249040",
    "end": "2255760"
  },
  {
    "text": "the second part is about the engine what's this data engine what's its own lane so longhorn has a long engine which",
    "start": "2255760",
    "end": "2261359"
  },
  {
    "text": "we custom we build ourselves the rook is currently i think the most common user",
    "start": "2261359",
    "end": "2266480"
  },
  {
    "text": "case for the rook is using the saf right opps they they have a few",
    "start": "2266480",
    "end": "2271839"
  },
  {
    "text": "bunch of choices including jiva which in fact is the fork of longhorn engine box",
    "start": "2271839",
    "end": "2276880"
  },
  {
    "text": "two three years ago and the performance wise the local performance is on par",
    "start": "2276880",
    "end": "2282960"
  },
  {
    "text": "with the staff and the opps well as say depends on which engine you",
    "start": "2282960",
    "end": "2288720"
  },
  {
    "text": "use and the the gui on the longer side has built-in gui and the rook has depends on the engine i",
    "start": "2288720",
    "end": "2295119"
  },
  {
    "text": "think saf has a dashboard and open ebs they i think they have a ui but they provided that",
    "start": "2295119",
    "end": "2301440"
  },
  {
    "text": "i think probably at the extra cost if i remember correctly and for the backup restore and the",
    "start": "2301440",
    "end": "2306720"
  },
  {
    "text": "crosstr volume uh tobacco restore longhorn because we uh um we're aiming to provide those",
    "start": "2306720",
    "end": "2314800"
  },
  {
    "text": "functionalities like in the the most user-friendly way so we currently have the backus restore as a",
    "start": "2314800",
    "end": "2320640"
  },
  {
    "text": "building option right we do incremental backup and then we do incremental restore which is the this dr warning option",
    "start": "2320640",
    "end": "2327040"
  },
  {
    "text": "layer there and i think the rook and the set itself doesn't have like building backup restore but rook",
    "start": "2327040",
    "end": "2333839"
  },
  {
    "text": "can take advantage of the using the third party software to do so and i think it's the",
    "start": "2333839",
    "end": "2338960"
  },
  {
    "text": "same for the open ebs uh for cross cluster dr volume uh disaster recovery and local business on",
    "start": "2338960",
    "end": "2346079"
  },
  {
    "text": "top of our backup restore feature and that is the really provided way for the user to use it",
    "start": "2346079",
    "end": "2352160"
  },
  {
    "text": "easily like you have a backup cluster which after running in no time if the main cluster",
    "start": "2352160",
    "end": "2357680"
  },
  {
    "text": "went down so i uh and in fact i'm not certain on the answer for the root can open ebs",
    "start": "2357680",
    "end": "2364000"
  },
  {
    "text": "here i haven't seen something similar here",
    "start": "2364000",
    "end": "2369040"
  },
  {
    "text": "um shang so is having rook on here just being a",
    "start": "2369040",
    "end": "2374800"
  },
  {
    "text": "storage orchestrator do you guys plan to extend the way that you do orchestration to other storage providers it's",
    "start": "2374800",
    "end": "2382079"
  },
  {
    "text": "maybe a good comparison on here even though it's not an existing cncf project i think maybe it would be helpful for",
    "start": "2382079",
    "end": "2388160"
  },
  {
    "text": "the toc to understand for just the cloud native landscape in terms of storage and how long harm okay so uh yeah so yeah so",
    "start": "2388160",
    "end": "2396000"
  },
  {
    "text": "what other storage options do you want to ask to compare to um i just think maybe as we",
    "start": "2396000",
    "end": "2404480"
  },
  {
    "text": "take this into the cncf if you guys are meant to present there that rook here maybe is maybe not the best",
    "start": "2404480",
    "end": "2411839"
  },
  {
    "text": "comparison we should maybe have cloud native storage options and of course there's tons of them within",
    "start": "2411839",
    "end": "2417440"
  },
  {
    "text": "kubernetes and understand how longhorn fits against those in terms of functionality because",
    "start": "2417440",
    "end": "2422720"
  },
  {
    "text": "rook can actually deploy open ebs and seth and min io and many other ones so",
    "start": "2422720",
    "end": "2429119"
  },
  {
    "text": "so i i would i'm just providing a recommendation i think it would make more sense yeah so yeah",
    "start": "2429119",
    "end": "2434880"
  },
  {
    "text": "we definitely can do that the product the why we release the rule here is uh when you look at like storage like",
    "start": "2434880",
    "end": "2441760"
  },
  {
    "text": "a storage uh project focus on more focus on the like block storage level there's probably obvious rook and longhorn",
    "start": "2441760",
    "end": "2448240"
  },
  {
    "text": "they've really mentioned together pretty often so that's why we put the rook here yeah but that makes sense yes",
    "start": "2448240",
    "end": "2454319"
  },
  {
    "text": "okay yeah maybe longhorn seth and opening vs would be a better comparison even though ceps not a cncf project i think it's",
    "start": "2454319",
    "end": "2461920"
  },
  {
    "text": "yeah understanding how it's done it's no more staff to open ebs we're definitely going to be better yeah because in fact i've",
    "start": "2461920",
    "end": "2467920"
  },
  {
    "text": "struggled a little bit when i say rook i in fact in my mind that basically",
    "start": "2467920",
    "end": "2473200"
  },
  {
    "text": "basically means self and but rook is more more than that",
    "start": "2473200",
    "end": "2478720"
  },
  {
    "text": "thanks",
    "start": "2479599",
    "end": "2481839"
  },
  {
    "text": "all right",
    "start": "2485280",
    "end": "2487680"
  },
  {
    "text": "all right so sorry yeah so uh this is the status update and",
    "start": "2490880",
    "end": "2498160"
  },
  {
    "text": "uh so um we have our last latest release is 102 and in fact longhorn",
    "start": "2498160",
    "end": "2504160"
  },
  {
    "text": "has just released the ga release about five months back and so that is the",
    "start": "2504160",
    "end": "2510800"
  },
  {
    "text": "happens on the may 30th 2020 and since the uh and also uh by the way",
    "start": "2510800",
    "end": "2516319"
  },
  {
    "text": "just just a reminder that longhorn has joined the cncf like last october which is so now is exactly",
    "start": "2516319",
    "end": "2522960"
  },
  {
    "text": "one year right so for after for the period that long for joining the cnf it's just one",
    "start": "2522960",
    "end": "2528640"
  },
  {
    "text": "year but we now have 50 kilometers from the 10 different companies and in fact one of the uh one in fact two of the",
    "start": "2528640",
    "end": "2535599"
  },
  {
    "text": "commuters they made a very significant like contribution to longhorn so they implement the arm solution by",
    "start": "2535599",
    "end": "2543040"
  },
  {
    "text": "themselves and submit in the big pr to the longhorn and we take so long team took them off",
    "start": "2543040",
    "end": "2550319"
  },
  {
    "text": "then and just add some like just like polishing it a little bit and now the arm support is going to be",
    "start": "2550319",
    "end": "2556560"
  },
  {
    "text": "experimental feature for the longhorn 1.1 release so that's the few that's a huge thing we saw from happens",
    "start": "2556560",
    "end": "2563520"
  },
  {
    "text": "in our uh contributor community",
    "start": "2563520",
    "end": "2567520"
  },
  {
    "text": "yeah so currently also i have a bunch of dev states right now and local is pretty much very active",
    "start": "2568960",
    "end": "2574400"
  },
  {
    "text": "commits per week 51 youtube open 24 issue close per week 18",
    "start": "2574400",
    "end": "2580079"
  },
  {
    "text": "and new pr per week in 29 yes so those are at the state we come we get from that state dot cnc dot io",
    "start": "2580079",
    "end": "2587280"
  },
  {
    "text": "yeah so on the right side uh you can see that we have huge committee growth since we joined",
    "start": "2587280",
    "end": "2593359"
  },
  {
    "text": "the cncf and uh i think the github stars is probably uh if i remember correctly 600 versus",
    "start": "2593359",
    "end": "2601119"
  },
  {
    "text": "like 2000 right now slack user is like two two three hundred two hundred versus",
    "start": "2601119",
    "end": "2607119"
  },
  {
    "text": "like uh close to when something is like 900 people right now i think and the no account uh note account and",
    "start": "2607119",
    "end": "2613839"
  },
  {
    "text": "this was about like three thousand something and now we are closing to like",
    "start": "2613839",
    "end": "2619359"
  },
  {
    "text": "1500 i think it's 1400 some 14 thousand something yeah so the the growth of the community",
    "start": "2619359",
    "end": "2626640"
  },
  {
    "text": "and the usage of longhorn is is pretty is in fact it's pretty huge if you see that",
    "start": "2626640",
    "end": "2632480"
  },
  {
    "text": "everything is like jumped out at least two three times just like five times after we joined the cncf",
    "start": "2632480",
    "end": "2640000"
  },
  {
    "text": "nice okay all right so those are the uh the",
    "start": "2641920",
    "end": "2647839"
  },
  {
    "text": "community building uh things we do and the first is we actively maintaining the github slack channel and",
    "start": "2647839",
    "end": "2655839"
  },
  {
    "text": "in fact this i have to say is if it's going to be it's in fact it's not easy because our",
    "start": "2655839",
    "end": "2661760"
  },
  {
    "text": "goal is like no unanswered questions we gain a lot we we receive a lot from community and we",
    "start": "2661760",
    "end": "2668240"
  },
  {
    "text": "want to make sure that we meet the requirement right so if you're looking at long-term",
    "start": "2668240",
    "end": "2673599"
  },
  {
    "text": "github issues and form like slack channel you can see that every day we have",
    "start": "2673599",
    "end": "2678640"
  },
  {
    "text": "uh at least about other lists like three four coming up three four issues",
    "start": "2678640",
    "end": "2684720"
  },
  {
    "text": "and those three four users start asking questions on stuff right so basically the responsibility for for my and my",
    "start": "2684720",
    "end": "2691760"
  },
  {
    "text": "team is to answer those questions and make sure and help them make sure users have their best",
    "start": "2691760",
    "end": "2697680"
  },
  {
    "text": "experience with long form that's that's that's in fact for us it's a huge",
    "start": "2697680",
    "end": "2702839"
  },
  {
    "text": "thing and secondly we have a monthly community meeting and plus office hour happens on",
    "start": "2702839",
    "end": "2708079"
  },
  {
    "text": "every second friday of the of the month and we are recording is old definitely",
    "start": "2708079",
    "end": "2713599"
  },
  {
    "text": "available on youtube and you can check that out and in the long community github page there's a link to",
    "start": "2713599",
    "end": "2720800"
  },
  {
    "text": "the recording there and also uh we have moved our infrastructure to cncf",
    "start": "2720800",
    "end": "2726160"
  },
  {
    "text": "and now long-term every night we run a nightly task of for currently the time time is about six",
    "start": "2726160",
    "end": "2732880"
  },
  {
    "text": "to seven hours and though those net test results and also drone build",
    "start": "2732880",
    "end": "2738160"
  },
  {
    "text": "result is like going to run for every pr and every merge commit they are publicly",
    "start": "2738160",
    "end": "2744839"
  },
  {
    "text": "available all right sorry and also we have a",
    "start": "2744839",
    "end": "2749920"
  },
  {
    "text": "metrics dashboard which which is publicly as well this is how we get we know no node account so the initial",
    "start": "2749920",
    "end": "2757839"
  },
  {
    "text": "story is we have upgrade server which is running publicly inside instead of safe infrastructure",
    "start": "2757839",
    "end": "2763599"
  },
  {
    "text": "and when every hour there you there the node running on the local manager is",
    "start": "2763599",
    "end": "2770319"
  },
  {
    "text": "going to asking for if there are new server version available that's also why you can see that the users",
    "start": "2770319",
    "end": "2776880"
  },
  {
    "text": "they get notification of a new server and they very frequently upgrade very soon after the new server",
    "start": "2776880",
    "end": "2782480"
  },
  {
    "text": "come up right but when they when the local manager send that request we know that there's",
    "start": "2782480",
    "end": "2789119"
  },
  {
    "text": "one node available we don't have any way to identify who that node is but we just see okay this is one request coming so i count this as",
    "start": "2789119",
    "end": "2795839"
  },
  {
    "text": "new active node so that's the old nesting is shown on the magic dashboard",
    "start": "2795839",
    "end": "2801200"
  },
  {
    "text": "right that is all public available and also we have participated in the coop con and the for",
    "start": "2801200",
    "end": "2807440"
  },
  {
    "text": "the kukan eu we have host the boost bay booth and office hours two office hours",
    "start": "2807440",
    "end": "2812720"
  },
  {
    "text": "plus one session so that's in fact the fee and also we run a survey and got about 300 response and",
    "start": "2812720",
    "end": "2820240"
  },
  {
    "text": "regarding the kubernetes uh storage native storage and why people using or why people not using",
    "start": "2820240",
    "end": "2826560"
  },
  {
    "text": "it right but um unfortunately in the end we feel like the sample size is probably still too",
    "start": "2826560",
    "end": "2832240"
  },
  {
    "text": "small to reach any like a different defining conclusion so i uh so we didn't really end up",
    "start": "2832240",
    "end": "2839040"
  },
  {
    "text": "publishing a official report on that",
    "start": "2839040",
    "end": "2845760"
  },
  {
    "text": "okay so those are uh some of the end users using longer in",
    "start": "2845760",
    "end": "2851599"
  },
  {
    "text": "production and those end users are all we gathered all this information from",
    "start": "2851599",
    "end": "2856960"
  },
  {
    "text": "the public user channel those are not like wrenching users those are all open source users and",
    "start": "2856960",
    "end": "2862160"
  },
  {
    "text": "they're not a pain wrencher or like for anything right so those are",
    "start": "2862160",
    "end": "2867680"
  },
  {
    "text": "one the first one is the tribunal regional okay so i cannot find spanish okay it's",
    "start": "2867680",
    "end": "2873920"
  },
  {
    "text": "the regional electoral court of the state of power brazil and there is using uh long brain",
    "start": "2873920",
    "end": "2880319"
  },
  {
    "text": "production story back-end with prometheus minion and pg and ming and the second one is uh cinema and it's",
    "start": "2880319",
    "end": "2886720"
  },
  {
    "text": "a health information tech con technology and the third one is qik and they are also using longhorn in",
    "start": "2886720",
    "end": "2893280"
  },
  {
    "text": "one of the next in their uh service management platform so um so how so we",
    "start": "2893280",
    "end": "2900640"
  },
  {
    "text": "uh basically how we got those and users is we basically just shout out in the slack channel",
    "start": "2900640",
    "end": "2906160"
  },
  {
    "text": "and and asking if we're asking them for help for our incubation process right so",
    "start": "2906160",
    "end": "2912160"
  },
  {
    "text": "that's why that's why we got that's how we got this and also we reach out to a few um users in the github that we saw",
    "start": "2912160",
    "end": "2919760"
  },
  {
    "text": "that really frequently interaction with us and asking questions and stuff to and want to know if they can help and",
    "start": "2919760",
    "end": "2926000"
  },
  {
    "text": "that's something the case here and and just to confirm these end users",
    "start": "2926000",
    "end": "2933760"
  },
  {
    "text": "are um are not commercial rancher users",
    "start": "2933760",
    "end": "2941280"
  },
  {
    "text": "therefore they they they are using the open source version of the product uh yes yeah they are not commercial rental",
    "start": "2941280",
    "end": "2947920"
  },
  {
    "text": "users and also um in fact the commercial there's no commercial version of longhorn",
    "start": "2947920",
    "end": "2953200"
  },
  {
    "text": "so rancher only sells support so even their commercial rental users they're going to use the same open source",
    "start": "2953200",
    "end": "2959359"
  },
  {
    "text": "product yeah we just like provide them support that's as a rental apps right so but those are not even like",
    "start": "2959359",
    "end": "2966079"
  },
  {
    "text": "random commercial users yeah they're there they are retro",
    "start": "2966079",
    "end": "2971359"
  },
  {
    "text": "commercial users yeah but we we i think it's better to show uh the opens on the open source side and",
    "start": "2971359",
    "end": "2978079"
  },
  {
    "text": "so that's why we reach our user in this way rather than uh depends on the range of customer to do so",
    "start": "2978079",
    "end": "2985200"
  },
  {
    "text": "okay and and sorry i i'm i'm just going to ask a few",
    "start": "2985200",
    "end": "2990400"
  },
  {
    "text": "questions on this because we got we we we had um similar questions that",
    "start": "2990400",
    "end": "2995520"
  },
  {
    "text": "came up with another project recently um i just want to confirm that",
    "start": "2995520",
    "end": "3002400"
  },
  {
    "text": "the the reason why i'm asking around the commercial rancher thing is is because i want to make sure that",
    "start": "3002400",
    "end": "3010079"
  },
  {
    "text": "these users are not using um some service or or some function that's only available",
    "start": "3010079",
    "end": "3016480"
  },
  {
    "text": "in the commercial rancher edition but not available in the open source edition if you see what i mean yeah i see yeah",
    "start": "3016480",
    "end": "3023119"
  },
  {
    "text": "so no they uh they were definitely open using open source hundred percent",
    "start": "3023119",
    "end": "3028559"
  },
  {
    "text": "because in fact there's no uh we don't make any like commercial version",
    "start": "3028559",
    "end": "3034000"
  },
  {
    "text": "or like a proprietary version of longhorn so even they want they don't have a way to use that i mean",
    "start": "3034000",
    "end": "3039599"
  },
  {
    "text": "even for the rental customers so it's the same for the rent wrenches 100 open source",
    "start": "3039599",
    "end": "3044800"
  },
  {
    "text": "right so as a rental customer you're getting the version of the renter is the exactly same you download from the",
    "start": "3044800",
    "end": "3050240"
  },
  {
    "text": "github let's understand okay thank you",
    "start": "3050240",
    "end": "3056960"
  },
  {
    "text": "yeah i think the sunlight is okay sorry all right so those",
    "start": "3056960",
    "end": "3063920"
  },
  {
    "text": "are the roadmap and for november we're going to release longhorn 1.1",
    "start": "3063920",
    "end": "3069040"
  },
  {
    "text": "release soon and it's going to include in the native of redoing manning support and we're doing that using fs on top of",
    "start": "3069040",
    "end": "3075599"
  },
  {
    "text": "longhorn block device and also the permissions csi snapshot support and some data locality feature as uh and",
    "start": "3075599",
    "end": "3083359"
  },
  {
    "text": "also the arm support which is experimental and as mentioned the arm support is coming from contributions from uh",
    "start": "3083359",
    "end": "3088880"
  },
  {
    "text": "in the community and in the future we are going to do the longhorn cli and the svgk application backcountry",
    "start": "3088880",
    "end": "3095760"
  },
  {
    "text": "store and and also some other items so this is just like overviews of what we see in the",
    "start": "3095760",
    "end": "3102480"
  },
  {
    "text": "roadmap okay okay all right so that's all",
    "start": "3102480",
    "end": "3110480"
  },
  {
    "text": "thanks okay so thank you so any other questions i can answer yes yes uh alex can i can i ask",
    "start": "3110480",
    "end": "3119200"
  },
  {
    "text": "of course go for it yeah so thanks thanks hank uh so i have a couple of questions right uh",
    "start": "3119200",
    "end": "3126240"
  },
  {
    "text": "first of all um if um someone has already some existing data somewhere right on uh",
    "start": "3126240",
    "end": "3133599"
  },
  {
    "text": "on a bucket or a cef or something like that is there a way to migrate into logging core or",
    "start": "3133599",
    "end": "3140480"
  },
  {
    "text": "they have to manually you know create a port that mounts uh yeah in fact that question",
    "start": "3140480",
    "end": "3147680"
  },
  {
    "text": "come up uh i think a few months back yeah but yeah currently uh we",
    "start": "3147680",
    "end": "3154800"
  },
  {
    "text": "don't have a native way to to help you to migrate from other storages but you can always do as",
    "start": "3154800",
    "end": "3161200"
  },
  {
    "text": "kubernetes i can always do that you create a new pvc and the month and the both owed a new pvc into the",
    "start": "3161200",
    "end": "3168319"
  },
  {
    "text": "part and around the cp i can think in between yes but this is one item we're tracking",
    "start": "3168319",
    "end": "3174240"
  },
  {
    "text": "and and we think we can provide some help in fact not just from other storage",
    "start": "3174240",
    "end": "3180720"
  },
  {
    "text": "vendors to cook like too long because we see kubernetes provide very flexible way of operating between",
    "start": "3180720",
    "end": "3187839"
  },
  {
    "text": "storage vendors so we probably can provide a tool for you to help move from any storage render to any",
    "start": "3187839",
    "end": "3194400"
  },
  {
    "text": "storage window so that's that's how we see it yeah that would help a lot on the",
    "start": "3194400",
    "end": "3199599"
  },
  {
    "text": "adoption i think one and second question so you mentioned a bit about",
    "start": "3199599",
    "end": "3205440"
  },
  {
    "text": "the snapshots and the recovery and all this stuff is it um is it are you utilizing the features of",
    "start": "3205440",
    "end": "3212720"
  },
  {
    "text": "csi about uh snaps about you know the new the new methods about snapshots and the",
    "start": "3212720",
    "end": "3220240"
  },
  {
    "text": "restore and all this time and all these things yeah csi yeah yeah so on the roadmap in fact it's",
    "start": "3220240",
    "end": "3227119"
  },
  {
    "text": "the currently this feature is already oh yeah yeah sorry sir i did not yeah yeah csi snapchat support this is",
    "start": "3227119",
    "end": "3233040"
  },
  {
    "text": "the snapchat in the in this context where mapping is to not really the snapshot including",
    "start": "3233040",
    "end": "3238319"
  },
  {
    "text": "longer it's going to be the backup the backup is right because it's the backup that you can migrate outside of",
    "start": "3238319",
    "end": "3244880"
  },
  {
    "text": "uh the volume for snapshots longer snapshots you're always going to be using inside the long form right so does that",
    "start": "3244880",
    "end": "3251920"
  },
  {
    "text": "snapshot support yeah it's well be there for the one map okay and the final uh suggestion i think more and",
    "start": "3251920",
    "end": "3259440"
  },
  {
    "text": "also you know if you can answer um i i think the engine so i wasn't aware of the project",
    "start": "3259440",
    "end": "3264559"
  },
  {
    "text": "i'm just learning today the project reminds me a bit uh a luxio because it is also a storage",
    "start": "3264559",
    "end": "3272480"
  },
  {
    "text": "engine not so much as to look because you know you are also storage engine itself so maybe some",
    "start": "3272480",
    "end": "3280079"
  },
  {
    "text": "comparison with a luxio might make sense you know for um i think",
    "start": "3280079",
    "end": "3285599"
  },
  {
    "text": "i think it's more similar than than rook because because you have the uh",
    "start": "3285599",
    "end": "3290880"
  },
  {
    "text": "your own storage engine um yeah so yeah i think i have um",
    "start": "3290880",
    "end": "3297520"
  },
  {
    "text": "i haven't heard this name and i um i haven't like look into what how they do it and",
    "start": "3297520",
    "end": "3303599"
  },
  {
    "text": "uh yeah so yeah we can we can just try to see if we can yeah just for you to have a look on the project it's um",
    "start": "3303599",
    "end": "3310319"
  },
  {
    "text": "similar with the different layers of uh of storage so they they have something uh something similar they're not so",
    "start": "3310319",
    "end": "3317119"
  },
  {
    "text": "kubernetes integrated as far as i remember but uh yeah just for you too yeah thanks thanks for the presentation",
    "start": "3317119",
    "end": "3324240"
  },
  {
    "text": "i for what it's worth i i believe for luxio are more of a",
    "start": "3324240",
    "end": "3330000"
  },
  {
    "text": "are more of a caching engine than a storage engine",
    "start": "3330000",
    "end": "3335839"
  },
  {
    "text": "yeah yeah yeah yeah so basically my point was also it's it's kind of difficult to compare",
    "start": "3336160",
    "end": "3343200"
  },
  {
    "text": "with um with rook because rook doesn't provide their own uh",
    "start": "3343200",
    "end": "3348720"
  },
  {
    "text": "storage engine right instead it would make sense to compare with something like but they have they have their own um i i",
    "start": "3348720",
    "end": "3355920"
  },
  {
    "text": "if i'm not mistaken you can use you can use aluxeo without having other other as",
    "start": "3355920",
    "end": "3363280"
  },
  {
    "text": "a standalone backing store as well uh if i'm not mistaken right",
    "start": "3363280",
    "end": "3369279"
  },
  {
    "text": "right um hey hey shang just a few other things in terms of the",
    "start": "3369440",
    "end": "3376400"
  },
  {
    "text": "the incubation criteria um so so it looks like the number of",
    "start": "3376400",
    "end": "3384160"
  },
  {
    "text": "um the number of committers has has has improved quite quite a lot",
    "start": "3384160",
    "end": "3390480"
  },
  {
    "text": "recently um would you be able to to share",
    "start": "3390480",
    "end": "3396720"
  },
  {
    "text": "um maybe some ratios of sort of um rancher committers versus",
    "start": "3396720",
    "end": "3402640"
  },
  {
    "text": "external in fact let me see if i can",
    "start": "3402640",
    "end": "3407920"
  },
  {
    "text": "do that right now sorry the light is on my face that's all right",
    "start": "3408160",
    "end": "3419838"
  },
  {
    "text": "yeah let me see should we on the no sorry this the death state is",
    "start": "3432480",
    "end": "3440319"
  },
  {
    "text": "always forgotten oh yeah okay navigated",
    "start": "3440319",
    "end": "3446720"
  },
  {
    "text": "no this is the latest complete statistic",
    "start": "3446720",
    "end": "3454079"
  },
  {
    "text": "uh yeah sorry um",
    "start": "3457280",
    "end": "3461839"
  },
  {
    "text": "complete table yeah this is the contributions let me see",
    "start": "3462799",
    "end": "3468400"
  },
  {
    "text": "comment yeah so still the super majority is",
    "start": "3468400",
    "end": "3474880"
  },
  {
    "text": "coming from the ranger labs and also their other uh from",
    "start": "3474880",
    "end": "3479920"
  },
  {
    "text": "independence and yeah i think other and also the cnc have helped with",
    "start": "3479920",
    "end": "3484960"
  },
  {
    "text": "the website and the field project there's some contribution with suse recently and some others",
    "start": "3484960",
    "end": "3491440"
  },
  {
    "text": "so this is the what we have right now i think",
    "start": "3491440",
    "end": "3495839"
  },
  {
    "text": "got it right so",
    "start": "3496799",
    "end": "3502400"
  },
  {
    "text": "okay yeah another question no i think i think um i think that's",
    "start": "3502400",
    "end": "3509760"
  },
  {
    "text": "fine um would it be possible to to share a pdf um or a link to oh yeah",
    "start": "3509760",
    "end": "3516559"
  },
  {
    "text": "presentation yeah so i i was in that team excellent all right then does does",
    "start": "3516559",
    "end": "3524240"
  },
  {
    "text": "anybody else have any um questions for shang",
    "start": "3524240",
    "end": "3531839"
  },
  {
    "text": "all right in our case thanks thank you so much shank this has been a a really great presentation um and we uh",
    "start": "3533680",
    "end": "3540480"
  },
  {
    "text": "we look forward to making our recommendation to the coc all right thank you um",
    "start": "3540480",
    "end": "3545760"
  },
  {
    "text": "thank you all right yeah thanks a lot",
    "start": "3545760",
    "end": "3555680"
  }
]
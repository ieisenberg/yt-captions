[
  {
    "text": "good afternoon everyone welcome to economics and best practices of running",
    "start": "60",
    "end": "6810"
  },
  {
    "text": "a IML workloads on kubernetes my name is Marlon Patel I am a product manager at",
    "start": "6810",
    "end": "13590"
  },
  {
    "text": "Google cloud and I'm pleased to introduce our co-presenter yeren",
    "start": "13590",
    "end": "18890"
  },
  {
    "text": "hi I'm Ron I'm a co-founder and CTO for Iguazu machine learning platform company",
    "start": "18890",
    "end": "27920"
  },
  {
    "text": "Thank You Erin today we are going to talk about two hot topics in computer",
    "start": "27949",
    "end": "34110"
  },
  {
    "text": "industry first is kubernetes and the second is AI ml artificial intelligence and machine",
    "start": "34110",
    "end": "40290"
  },
  {
    "text": "learning both are critical pillars of modern computing environment in today's",
    "start": "40290",
    "end": "48930"
  },
  {
    "text": "the digital economy data is the new currency for many of us data is the",
    "start": "48930",
    "end": "55710"
  },
  {
    "text": "lifeblood of our company and we want to convert the data into meaningful information",
    "start": "55710",
    "end": "62090"
  },
  {
    "text": "yamo is the engine which helps us convert the data into meaningful",
    "start": "62090",
    "end": "67350"
  },
  {
    "text": "information and with meaningful information we can drive better business",
    "start": "67350",
    "end": "73560"
  },
  {
    "text": "decisions and make actual take actions industries across the world are heavily",
    "start": "73560",
    "end": "80939"
  },
  {
    "text": "investing in AML capabilities so as a",
    "start": "80939",
    "end": "87380"
  },
  {
    "text": "community interested in AML how can we make AI ml simple fast and cost",
    "start": "87380",
    "end": "95460"
  },
  {
    "text": "effective we want to make AML simple so it's accessible to everyone in our",
    "start": "95460",
    "end": "102509"
  },
  {
    "text": "organization we want to make it fast so you can train the model fast",
    "start": "102509",
    "end": "107909"
  },
  {
    "text": "get inside faster and drive business decision faster we want to make it",
    "start": "107909",
    "end": "113939"
  },
  {
    "text": "cost-effective in order to democratize AML so that it's accessible to everyone",
    "start": "113939",
    "end": "122479"
  },
  {
    "text": "so when we think of a IML we typically think about model building and model training however we need to realize that",
    "start": "123710",
    "end": "131240"
  },
  {
    "text": "amo is much bigger than that ml is typically a small part of an",
    "start": "131240",
    "end": "137870"
  },
  {
    "text": "end-to-end AML application a lot of skills are needed to build any AML",
    "start": "137870",
    "end": "144830"
  },
  {
    "text": "application for example a data engineer may cleanse the data another engineer",
    "start": "144830",
    "end": "150770"
  },
  {
    "text": "may extract features data scientists may build models an application engineer may",
    "start": "150770",
    "end": "157700"
  },
  {
    "text": "convert the model into an API and finally an end-user may use the",
    "start": "157700",
    "end": "163430"
  },
  {
    "text": "applications which are built using those API so how can we make a ml times 10x",
    "start": "163430",
    "end": "172010"
  },
  {
    "text": "more productive how can we give them an environment so that they can innovate faster that's why we need cloud native",
    "start": "172010",
    "end": "181910"
  },
  {
    "text": "KML platform we want to kubernetes has",
    "start": "181910",
    "end": "187340"
  },
  {
    "text": "become the de facto standard for cloud native computing and we want to bring the power of kubernetes to AI ml",
    "start": "187340",
    "end": "196269"
  },
  {
    "text": "kubernetes makes a IML workloads scalable portable and composable with",
    "start": "196269",
    "end": "204320"
  },
  {
    "text": "the help of kubernetes data scientists can focus more on building and training",
    "start": "204320",
    "end": "209870"
  },
  {
    "text": "models instead of worrying about underlying infrastructure all they have",
    "start": "209870",
    "end": "215239"
  },
  {
    "text": "to do is choose your favorite hammelburg floor framework pack the models up in",
    "start": "215239",
    "end": "220670"
  },
  {
    "text": "kubernetes and run them on kubernetes at scale kubernetes takes care of scaling",
    "start": "220670",
    "end": "227269"
  },
  {
    "text": "the workload from a single node to thousands of nodes it makes data scientists more productive",
    "start": "227269",
    "end": "234190"
  },
  {
    "text": "so why kubernetes for a mo kubernetes provides three core features that are",
    "start": "234190",
    "end": "240680"
  },
  {
    "text": "very attractive for AML workloads the first is portability kubernetes",
    "start": "240680",
    "end": "247519"
  },
  {
    "text": "provides cloud native open and standardized api's with using coop by",
    "start": "247519",
    "end": "253549"
  },
  {
    "text": "using kubernetes you can seamlessly pour your workload from your laptop or your cloud to your",
    "start": "253549",
    "end": "260150"
  },
  {
    "text": "private data center second is scalability with the help of kubernetes",
    "start": "260150",
    "end": "265699"
  },
  {
    "text": "you can scale your ml workload from a single node to thousands of node",
    "start": "265699",
    "end": "271009"
  },
  {
    "text": "kubernetes also supports hardware accelerators such as GPU TPU and also",
    "start": "271009",
    "end": "276979"
  },
  {
    "text": "auto provisioning and auto scaling which makes killing your workload simple and easy and the third is productivity",
    "start": "276979",
    "end": "284650"
  },
  {
    "text": "kubernetes makes data scientists and data engineers more productive by",
    "start": "284650",
    "end": "290419"
  },
  {
    "text": "freeing them up from managing their own workstation servers or VMs it lets you",
    "start": "290419",
    "end": "296090"
  },
  {
    "text": "focus on your model building and model training instead of focusing in managing",
    "start": "296090",
    "end": "301430"
  },
  {
    "text": "VMs so the kubernetes is actually application agnostic so kubernetes",
    "start": "301430",
    "end": "309380"
  },
  {
    "text": "provides many many advanced features like scalability load balancing scaling etc however it does not know anything",
    "start": "309380",
    "end": "317240"
  },
  {
    "text": "about mo this leaves a lot of work for ml operations teams in setting up the",
    "start": "317240",
    "end": "323870"
  },
  {
    "text": "infrastructure downloading and installing ml frameworks and libraries goo flow fills that gap a cool flow is",
    "start": "323870",
    "end": "332539"
  },
  {
    "text": "actually a kubernetes native open source platform to develop deploy and manage",
    "start": "332539",
    "end": "337659"
  },
  {
    "text": "portable and scalable machine learning workloads coop flow provides higher",
    "start": "337659",
    "end": "345800"
  },
  {
    "text": "level abstractions such as tensor flow job which makes running tensorflow job",
    "start": "345800",
    "end": "351440"
  },
  {
    "text": "or training job much simpler and easier on kubernetes it integrates tensorflow",
    "start": "351440",
    "end": "356930"
  },
  {
    "text": "distributed training and estimator api's with the kubernetes it uses kubernetes",
    "start": "356930",
    "end": "362570"
  },
  {
    "text": "to scale training and leverages hardware accelerators and it benefits from auto",
    "start": "362570",
    "end": "368810"
  },
  {
    "text": "scaling and auto provisioning capabilities of kubernetes and with this",
    "start": "368810",
    "end": "373820"
  },
  {
    "text": "you can also benefit from the why Brent ecosystem of kubernetes toolchain to",
    "start": "373820",
    "end": "379639"
  },
  {
    "text": "develop your ml workflows and run amock workloads",
    "start": "379639",
    "end": "385240"
  },
  {
    "text": "tensorflow also provides sorry crew flow also provides advanced abstraction for",
    "start": "386110",
    "end": "391629"
  },
  {
    "text": "serving so imagine that you build a very advanced model for movie recommendation",
    "start": "391629",
    "end": "398969"
  },
  {
    "text": "now you want to test this model on a small scale with a global traffic to",
    "start": "398969",
    "end": "404919"
  },
  {
    "text": "study the fidelity of your model so if you deploy this model in US the traffic",
    "start": "404919",
    "end": "410680"
  },
  {
    "text": "will be overwhelmingly from Hollywood movie fans if you deploy this model in India the traffic will be overwhelmingly",
    "start": "410680",
    "end": "417069"
  },
  {
    "text": "from Bollywood movie friends so you have a dilemma on one hand your you want your",
    "start": "417069",
    "end": "422199"
  },
  {
    "text": "model to get a slice of traffic from the regions of your interest on the other hand you don't want to deploy an",
    "start": "422199",
    "end": "429219"
  },
  {
    "text": "experimental model globally to limit the blast radius here kubernetes and cut",
    "start": "429219",
    "end": "434319"
  },
  {
    "text": "steel comes to the rescue with the help of kubernetes and sto you can configure the load balancer so that your model",
    "start": "434319",
    "end": "441580"
  },
  {
    "text": "gets a slice of traffic from the region of interest so you can test the fidelity",
    "start": "441580",
    "end": "447250"
  },
  {
    "text": "of your model from the traffic that you are interested in also with kubernetes",
    "start": "447250",
    "end": "452500"
  },
  {
    "text": "ecosystem for example you can use Prometheus for exporting your model",
    "start": "452500",
    "end": "457930"
  },
  {
    "text": "matrix you can also use sto for telemetry and traffic splitting so",
    "start": "457930",
    "end": "464699"
  },
  {
    "text": "kubernetes and sto make many many model lifecycle challenges simple and easy to",
    "start": "464699",
    "end": "470620"
  },
  {
    "text": "handle so in ml world there are two distinct",
    "start": "470620",
    "end": "478440"
  },
  {
    "text": "experiences that we have to address so there is a d0 experience which is",
    "start": "478440",
    "end": "483759"
  },
  {
    "text": "focused on model building where a hosted notebook can make a huge difference and",
    "start": "483759",
    "end": "489750"
  },
  {
    "text": "once a model is built then you have to deal with the production ization challenges where you have to deal with",
    "start": "489750",
    "end": "495759"
  },
  {
    "text": "security scalability logging monitoring etc so now let's look at how kubernetes",
    "start": "495759",
    "end": "502539"
  },
  {
    "text": "helps to address those challenges so in de 0 we are interested in building and",
    "start": "502539",
    "end": "509169"
  },
  {
    "text": "training models and the designer is typically training their models using",
    "start": "509169",
    "end": "514539"
  },
  {
    "text": "notebooks and they have their own preferences for the libraries they would like to use and the free",
    "start": "514539",
    "end": "519820"
  },
  {
    "text": "work they would like to use so here we can benefit from hosted netbooks which",
    "start": "519820",
    "end": "526030"
  },
  {
    "text": "come pre-configured with the most popular libraries and the frameworks and",
    "start": "526030",
    "end": "531250"
  },
  {
    "text": "this includes libraries such as fanned as a numpy and many more and machine",
    "start": "531250",
    "end": "536410"
  },
  {
    "text": "learning frameworks like Kyra's tensorflow extra boot etc so data scientists can open their browser and",
    "start": "536410",
    "end": "543040"
  },
  {
    "text": "connect to the dope connect to the notebook which are hosted and start fetching the data and building the",
    "start": "543040",
    "end": "549790"
  },
  {
    "text": "models directly into the notebook and they can train the model nor in the notebook and the best part is they can",
    "start": "549790",
    "end": "556840"
  },
  {
    "text": "deploy those models once they are trained directly under kubernetes from the notebooks which frees them from",
    "start": "556840",
    "end": "563470"
  },
  {
    "text": "learning intricacies of kubernetes so",
    "start": "563470",
    "end": "569650"
  },
  {
    "text": "once a model is built and trained the next is how do we deploy into production",
    "start": "569650",
    "end": "575680"
  },
  {
    "text": "wall here we have to address many production related challenges for",
    "start": "575680",
    "end": "580870"
  },
  {
    "text": "example security logging monitoring telemetry also data gravity and may so",
    "start": "580870",
    "end": "587380"
  },
  {
    "text": "forth and as you may all know because of the variety of challenges lots of",
    "start": "587380",
    "end": "594490"
  },
  {
    "text": "workloads today run in on-prem environment and challenges related to regulations latency data gravity and so",
    "start": "594490",
    "end": "602860"
  },
  {
    "text": "forth so you know what that means is lot of models will be running in on-prem",
    "start": "602860",
    "end": "610000"
  },
  {
    "text": "environment as well as in cloud environment we call it hybrid model at Google",
    "start": "610000",
    "end": "615670"
  },
  {
    "text": "we are investing heavily in our hybrid strategy in the hybrid world what we see",
    "start": "615670",
    "end": "621580"
  },
  {
    "text": "is you can run your machine learning workloads an on-prem environment using open source tools like goo flow when you",
    "start": "621580",
    "end": "629800"
  },
  {
    "text": "are in a cloud environment we offer AI platform which is managed equivalent of",
    "start": "629800",
    "end": "636010"
  },
  {
    "text": "goo flow from Google and you can run your models directly in under the AI platform so ai platform is basically",
    "start": "636010",
    "end": "644760"
  },
  {
    "text": "developer environment integrated developer environment for data scientists and data engineers in that",
    "start": "644760",
    "end": "651730"
  },
  {
    "text": "world all the pain of doing devops he's taken care by the Google versus when you are on pram you",
    "start": "651730",
    "end": "659470"
  },
  {
    "text": "have to manage you flow on your own so you can use your favorite notebooks and",
    "start": "659470",
    "end": "665070"
  },
  {
    "text": "Python code to talk to goop flow on pram as well as AI platform on GCP however",
    "start": "665070",
    "end": "672010"
  },
  {
    "text": "the underlying api's that are supported on qu flow and on AI platform are",
    "start": "672010",
    "end": "677110"
  },
  {
    "text": "slightly different so the qu flow supports kubernetes tile api's an di platform supports restful api s-- and",
    "start": "677110",
    "end": "683910"
  },
  {
    "text": "often data scientists use their local environment to run their own code and",
    "start": "683910",
    "end": "689740"
  },
  {
    "text": "validate the model so in that case data scientists have to deal with many different varieties of",
    "start": "689740",
    "end": "696070"
  },
  {
    "text": "api's that's not fun so to address that we are developing a hybrid machine",
    "start": "696070",
    "end": "703450"
  },
  {
    "text": "learning SDK which basically abstracts away all the intricacies of underlying platform into common set of API so we",
    "start": "703450",
    "end": "710350"
  },
  {
    "text": "call it goof floor faring so what is good flow Ferenc goop flow firing is an open source hybrid machine learning sdk",
    "start": "710350",
    "end": "717040"
  },
  {
    "text": "for data scientists to write ml code once and run anywhere not only that it",
    "start": "717040",
    "end": "723940"
  },
  {
    "text": "also gives you the ability to package your data science machine learning workload for remote execution so it",
    "start": "723940",
    "end": "730930"
  },
  {
    "text": "abstracts away the pain of managing different underlying platforms and now I'll show you some examples so this",
    "start": "730930",
    "end": "738880"
  },
  {
    "text": "start you see three different ways data scientists have to deal with their platform they can build their machine",
    "start": "738880",
    "end": "746200"
  },
  {
    "text": "learning code locally or they can build it on AI platform which is a managed",
    "start": "746200",
    "end": "753220"
  },
  {
    "text": "service provided by Google or on a KU flow if they're developing locally they can use their favorite Python tool kits",
    "start": "753220",
    "end": "760180"
  },
  {
    "text": "which are which they are very familiar with when you develop it on the AI platform they have to provide basically",
    "start": "760180",
    "end": "767860"
  },
  {
    "text": "g-cloud API so argument which basically lists all the dependencies and packages",
    "start": "767860",
    "end": "773470"
  },
  {
    "text": "that are needed before machine learning code that is developed by data scientists can run on AI platform if",
    "start": "773470",
    "end": "780700"
  },
  {
    "text": "they do the same thing on qu flow they have to write their own Yam of so this is not fun to deal with all",
    "start": "780700",
    "end": "787360"
  },
  {
    "text": "these dependencies which are handled in a different ways in the cool flow",
    "start": "787360",
    "end": "793330"
  },
  {
    "text": "fearing wall all the code is abstract away into a common code which almost look identical",
    "start": "793330",
    "end": "799089"
  },
  {
    "text": "the main difference here is that back-end definitions which are provided as an argument to goo flow training job",
    "start": "799089",
    "end": "807700"
  },
  {
    "text": "is slightly different in each environment so as you can see here the",
    "start": "807700",
    "end": "813010"
  },
  {
    "text": "backend definition is local for local environment yai platform for yet at platform",
    "start": "813010",
    "end": "818080"
  },
  {
    "text": "environment and then scoop flow for a cooler environment it's easy to imagine that this could very well have been a",
    "start": "818080",
    "end": "825220"
  },
  {
    "text": "development staging and production all the only thing that ml operations team",
    "start": "825220",
    "end": "830320"
  },
  {
    "text": "has to do is to basically configure the faring the config file in order to handle the differences between this",
    "start": "830320",
    "end": "836830"
  },
  {
    "text": "environment but for data scientists the code looks almost identical so now let",
    "start": "836830",
    "end": "844209"
  },
  {
    "text": "me show you an end-to-end demo how this works so first what we will do is we'll",
    "start": "844209",
    "end": "849520"
  },
  {
    "text": "discover an existing model from AI hub and GI hub is basically one-stop-shop",
    "start": "849520",
    "end": "855610"
  },
  {
    "text": "for storing and sharing your AI assets for example pipelines your models your",
    "start": "855610",
    "end": "863080"
  },
  {
    "text": "notebooks etc this makes collaboration within an organization much easier once",
    "start": "863080",
    "end": "868570"
  },
  {
    "text": "we discover the model on the AI hub next we open it and a hosted environment",
    "start": "868570",
    "end": "873610"
  },
  {
    "text": "using Jupiter notebook and then we are gonna train it in a three different ways so now let's go to the demo just give me",
    "start": "873610",
    "end": "883810"
  },
  {
    "text": "a second",
    "start": "883810",
    "end": "886230"
  },
  {
    "text": "okay looks like some",
    "start": "891819",
    "end": "899950"
  },
  {
    "text": "all right so what you are looking here we start at the AI hub search space and",
    "start": "904250",
    "end": "911700"
  },
  {
    "text": "what I'm gonna do is I'm gonna search for a cancer detection demo so as soon as I hit the search button you will find",
    "start": "911700",
    "end": "918330"
  },
  {
    "text": "that there are four results three of them are actually notebooks and one is",
    "start": "918330",
    "end": "924810"
  },
  {
    "text": "actually the model itself we are interested in the third result which is",
    "start": "924810",
    "end": "930060"
  },
  {
    "text": "a cancer detection model so we go there and we open the model in a GCP hosted",
    "start": "930060",
    "end": "936090"
  },
  {
    "text": "notebook so that's what you're seeing here so",
    "start": "936090",
    "end": "942990"
  },
  {
    "text": "this is the model I'm going to open so",
    "start": "942990",
    "end": "949500"
  },
  {
    "text": "this is how the model looks like on the top part of the model you have environmental setup which is very common",
    "start": "949500",
    "end": "955800"
  },
  {
    "text": "next what you see here is basically we are exploring the data so understand the",
    "start": "955800",
    "end": "961920"
  },
  {
    "text": "data and clean the data after exploration we will go to basically a",
    "start": "961920",
    "end": "967740"
  },
  {
    "text": "visualization so here you can see some code for the visualization when we wrote the visualization code it will display",
    "start": "967740",
    "end": "974400"
  },
  {
    "text": "some images which are basically positive and negative samples for your cancer",
    "start": "974400",
    "end": "980220"
  },
  {
    "text": "detection input then we build the model so after the model is actually built we",
    "start": "980220",
    "end": "989250"
  },
  {
    "text": "want to fetch basically the embeddings and those embeddings are fetch from the",
    "start": "989250",
    "end": "994260"
  },
  {
    "text": "AI hub for our model these are image and bearings and now we are going to train",
    "start": "994260",
    "end": "999720"
  },
  {
    "text": "it on three different environments so the first environment is basically local",
    "start": "999720",
    "end": "1005480"
  },
  {
    "text": "environment as soon as we start training on local environment it will start showing us logs the second environment",
    "start": "1005480",
    "end": "1014150"
  },
  {
    "text": "is school flow environment here you can see the backend config which says a cool flow and the third environment is yai",
    "start": "1014150",
    "end": "1023990"
  },
  {
    "text": "platform environment and the backend config is GCP so now we will train the",
    "start": "1023990",
    "end": "1029390"
  },
  {
    "text": "local model",
    "start": "1029390",
    "end": "1032800"
  },
  {
    "text": "so now it's straining and you can see the logs are being displayed the",
    "start": "1036169",
    "end": "1042959"
  },
  {
    "text": "training gets finished and 194 seconds here and you can see the loss and",
    "start": "1042959",
    "end": "1048870"
  },
  {
    "text": "accuracy metric next we are going to train the same model in the qu flow",
    "start": "1048870",
    "end": "1054539"
  },
  {
    "text": "environment so in this case the model gets packaged by qu flow faring and it's",
    "start": "1054539",
    "end": "1060600"
  },
  {
    "text": "executed remotely and the logs are streamed back to the notebook so in the",
    "start": "1060600",
    "end": "1065640"
  },
  {
    "text": "top part of it what you see is that the model is actually packaged as a docker image and is put in the repository from",
    "start": "1065640",
    "end": "1071429"
  },
  {
    "text": "where it gets picked up by the qu flow and then the execution is pretty much same you can see the logs in the",
    "start": "1071429",
    "end": "1078720"
  },
  {
    "text": "notebook and the third is we're gonna do",
    "start": "1078720",
    "end": "1084480"
  },
  {
    "text": "the same thing in the a AI platform training environment so the key difference that you will will see here",
    "start": "1084480",
    "end": "1091710"
  },
  {
    "text": "when we do it and the AI platform environment is now the logs are actually",
    "start": "1091710",
    "end": "1097260"
  },
  {
    "text": "made available to be streamed to stackdriver so you can actually I'll show you in a",
    "start": "1097260",
    "end": "1102750"
  },
  {
    "text": "second in this case we provide you a link so it opens the logging in the",
    "start": "1102750",
    "end": "1109650"
  },
  {
    "text": "stackdriver and from there on you can monitor and do everything that you want you to instruct",
    "start": "1109650",
    "end": "1114900"
  },
  {
    "text": "our environment so what this shows here so this is the link to the spec driver and now you go to the truck driver and",
    "start": "1114900",
    "end": "1122330"
  },
  {
    "text": "open the logs",
    "start": "1122330",
    "end": "1125690"
  },
  {
    "text": "yeah",
    "start": "1129590",
    "end": "1132590"
  },
  {
    "text": "so the new locks are made available here and then you can work through your logs",
    "start": "1137300",
    "end": "1143060"
  },
  {
    "text": "in the secretary environment so now going back to this one",
    "start": "1143060",
    "end": "1148840"
  },
  {
    "text": "okay so let's quickly review what goofily opera fairing provides you so",
    "start": "1158590",
    "end": "1164679"
  },
  {
    "text": "it's basically the advantage of coop flooring is it's a data scientists focus it works with the data science friendly",
    "start": "1164679",
    "end": "1170919"
  },
  {
    "text": "environment in notebooks as well as data science friendly programming languages it's a multi-platform so you can",
    "start": "1170919",
    "end": "1177820"
  },
  {
    "text": "seamlessly move across your local environment as well as your GCP environment or your private data center",
    "start": "1177820",
    "end": "1184360"
  },
  {
    "text": "environment it makes your training and inferencing very cost effective because it allows you to burst into the cloud",
    "start": "1184360",
    "end": "1191289"
  },
  {
    "text": "when you run out of capacity on your private local environment you can use",
    "start": "1191289",
    "end": "1197409"
  },
  {
    "text": "the KU flow firing for the lifecycle management and it also supports the multi frameworks including XG boost",
    "start": "1197409",
    "end": "1204159"
  },
  {
    "text": "tensorflow and Python okay so what are the",
    "start": "1204159",
    "end": "1212799"
  },
  {
    "text": "advantages of coupe flow fairing for ml of steam so basically it allows you to",
    "start": "1212799",
    "end": "1218169"
  },
  {
    "text": "enforce your best practices that you want to enforce across your organization second is it's open source so there is",
    "start": "1218169",
    "end": "1226629"
  },
  {
    "text": "no lock-in you can make use of it right away without having to worry about any",
    "start": "1226629",
    "end": "1231879"
  },
  {
    "text": "vendor lock-in and also as I mentioned with the remote bursting you can save a significant amount of money on your",
    "start": "1231879",
    "end": "1237639"
  },
  {
    "text": "operations cost so with that let's move on to the second part of the talk and I will invite Iran to take it take us from",
    "start": "1237639",
    "end": "1244600"
  },
  {
    "text": "here",
    "start": "1244600",
    "end": "1246690"
  },
  {
    "text": "so I have some ambitious demo and I hope it will work and all that but before",
    "start": "1257299",
    "end": "1262470"
  },
  {
    "text": "diving it into a demo of like a full pipeline using cube flow let's talk",
    "start": "1262470",
    "end": "1269340"
  },
  {
    "text": "about some some basics what what I want to show you is this nice yeah we can build a fully automated machine learning",
    "start": "1269340",
    "end": "1275039"
  },
  {
    "text": "environment and leveraging some of the surveillance technologies that are now integrated into cube flow so one of the",
    "start": "1275039",
    "end": "1282450"
  },
  {
    "text": "key challenges today is that machine learning is is pretty complicated and siloed so we have some folks still",
    "start": "1282450",
    "end": "1289889"
  },
  {
    "text": "working on a dupe and data lakes and spark and all that on on yarn some data",
    "start": "1289889",
    "end": "1296580"
  },
  {
    "text": "scientists will come more from a Python mindset and deep learning machine learning scikit-learn actually boosts",
    "start": "1296580",
    "end": "1302340"
  },
  {
    "text": "tensorflow work on sometimes there are laptops sometimes notebooks sometimes kubernetes",
    "start": "1302340",
    "end": "1308580"
  },
  {
    "text": "if they're slightly more advanced and then we have the operational aspects of where do you deploy all that so you have",
    "start": "1308580",
    "end": "1315149"
  },
  {
    "text": "some containers that come from the machine learning world and they just present endpoints that get some vectors",
    "start": "1315149",
    "end": "1321119"
  },
  {
    "text": "and process and respond and you have some other containers that interact with",
    "start": "1321119",
    "end": "1326279"
  },
  {
    "text": "those containers now we have three different disciplines three different silos within the organization and most",
    "start": "1326279",
    "end": "1332879"
  },
  {
    "text": "of the transfer of artifacts and knowledge and everything is done manually today so we need to change that",
    "start": "1332879",
    "end": "1340350"
  },
  {
    "text": "so the general idea is why not use kubernetes a server a unified architecture not necessarily a single",
    "start": "1340350",
    "end": "1346889"
  },
  {
    "text": "cluster you may still have multiple clusters but serve a unified architecture for delivering such a",
    "start": "1346889",
    "end": "1354179"
  },
  {
    "text": "pipeline so you know you do need various ways of storage and databases underneath",
    "start": "1354179",
    "end": "1359639"
  },
  {
    "text": "and then you have all those variety of services that come from those different disciplines you can run SPARC today not",
    "start": "1359639",
    "end": "1366480"
  },
  {
    "text": "many no you can just run SPARC presto hive all those things on kubernetes today but you can also run by torch",
    "start": "1366480",
    "end": "1373799"
  },
  {
    "text": "tends to flow etc and other things that are more serve on the operational side permit is graph on service functions and",
    "start": "1373799",
    "end": "1381509"
  },
  {
    "text": "so on so what you can build is some some pipeline which is slightly more advanced",
    "start": "1381509",
    "end": "1387389"
  },
  {
    "text": "and have three components one is collection of data now most",
    "start": "1387389",
    "end": "1392440"
  },
  {
    "text": "people that come from the data world still think of collection of data is an ETL process if you're being slightly",
    "start": "1392440",
    "end": "1399280"
  },
  {
    "text": "more modern application collection of data is also streams that just feed in or or a scrapers you need some weather",
    "start": "1399280",
    "end": "1406299"
  },
  {
    "text": "information you don't want to store that in your your own data Lake or throughout the entire history you can just go to an",
    "start": "1406299",
    "end": "1413200"
  },
  {
    "text": "external weather service it's the external real-time stock trading information service etcetera so you need",
    "start": "1413200",
    "end": "1419860"
  },
  {
    "text": "automation for grabbing data and bringing it into serve this this place",
    "start": "1419860",
    "end": "1425590"
  },
  {
    "text": "where you're processing the data the second thing that you do once you've brought data and preferably",
    "start": "1425590",
    "end": "1431049"
  },
  {
    "text": "label that and prepare that a bit you need to do machine learning training and",
    "start": "1431049",
    "end": "1436240"
  },
  {
    "text": "validation and also here you can leverage the advantage of kubernetes in scalability you don't want to run",
    "start": "1436240",
    "end": "1442720"
  },
  {
    "text": "experiment on this notebook or this specific VM you want to be able to run the same experiment or the same training",
    "start": "1442720",
    "end": "1449110"
  },
  {
    "text": "on potentially tens or hundreds of job depending on the size of your task and",
    "start": "1449110",
    "end": "1455860"
  },
  {
    "text": "you want to pull resources because I still see people just taking a Jupiter attaching a GPU to that you know in",
    "start": "1455860",
    "end": "1463840"
  },
  {
    "text": "Amazon that's like $12 an hour for a quad node GPU if you're if you have",
    "start": "1463840",
    "end": "1470080"
  },
  {
    "text": "money that's ok but then you're wasting those resources so the right approach would be to",
    "start": "1470080",
    "end": "1475240"
  },
  {
    "text": "essentially pull the GPU resources and every time you launch a job just have a container amount this GPU run and the",
    "start": "1475240",
    "end": "1483490"
  },
  {
    "text": "commission itself and if you're a group of data scientists or then you can pull those resources or if you're using a",
    "start": "1483490",
    "end": "1489850"
  },
  {
    "text": "cloud you can pay per use for some of those resources and then the last stage is once you have a model you want to",
    "start": "1489850",
    "end": "1496299"
  },
  {
    "text": "serve it and then you can use containers and potentially serverless functions as",
    "start": "1496299",
    "end": "1501910"
  },
  {
    "text": "a way to do serving also here many times people think about serving as something",
    "start": "1501910",
    "end": "1507610"
  },
  {
    "text": "that gets a vector of floating boat numbers and respond with the floating point numbers but then there's a",
    "start": "1507610",
    "end": "1513520"
  },
  {
    "text": "critical challenge here how do those floating point numbers get generated that serve",
    "start": "1513520",
    "end": "1518860"
  },
  {
    "text": "a dark secret no one knows so essentially the real data in the world is geolocation this customer identifies",
    "start": "1518860",
    "end": "1525580"
  },
  {
    "text": "its era so the first thing you need to do is feature assembly and only then feed it into a model and last but not",
    "start": "1525580",
    "end": "1533620"
  },
  {
    "text": "least we have to observe a feedback loop we have to monitor everything that happens during production and we could",
    "start": "1533620",
    "end": "1539710"
  },
  {
    "text": "use things like Griffin and primitives to do that and feed the data back into the pipeline and the last thing that we",
    "start": "1539710",
    "end": "1547960"
  },
  {
    "text": "want is that essentially the user the consumers of that platform need some easy way to access the entire system",
    "start": "1547960",
    "end": "1556240"
  },
  {
    "text": "because there's a lot of complicated things you know service measures containers the amell's we want to",
    "start": "1556240",
    "end": "1561460"
  },
  {
    "text": "extract it through notebooks through pipelines we'll show that and through",
    "start": "1561460",
    "end": "1566500"
  },
  {
    "text": "things like service functions so queue flow essentially what it's trying to do",
    "start": "1566500",
    "end": "1572560"
  },
  {
    "text": "is is bring all those different projects for all those different tasks within the pipeline's under one umbrella with the",
    "start": "1572560",
    "end": "1579880"
  },
  {
    "text": "serve simpler integration and this is where you can build a real pipeline so",
    "start": "1579880",
    "end": "1585040"
  },
  {
    "text": "let's look at what it what do I mean by real pipeline so the first thing you need to do is collect data and the",
    "start": "1585040",
    "end": "1592900"
  },
  {
    "text": "reason I put three icons here again to make sure people understand that collecting data is not necessarily doing",
    "start": "1592900",
    "end": "1598330"
  },
  {
    "text": "an ETL job from Oracle or reading an s3 Park a file and loading it into your",
    "start": "1598330",
    "end": "1603870"
  },
  {
    "text": "data science platform sometimes loading data is screaming its Kafka stream",
    "start": "1603870",
    "end": "1609520"
  },
  {
    "text": "sometimes it's fetching from some API services then once we take all that data",
    "start": "1609520",
    "end": "1615430"
  },
  {
    "text": "we need to create a feature vector and we prefer to serve snapshot it version it so when we run this experiment again",
    "start": "1615430",
    "end": "1622060"
  },
  {
    "text": "and again we make sure that we we get the same result so we need to take data then we put it into a pipeline the first",
    "start": "1622060",
    "end": "1629410"
  },
  {
    "text": "step in the pipeline will be to do training so we need to take some code some notebook loaded in run some",
    "start": "1629410",
    "end": "1636610"
  },
  {
    "text": "training generate an output serve data set and our model the second thing we'll",
    "start": "1636610",
    "end": "1643330"
  },
  {
    "text": "do is probably validation again we'll take some code that does validation run it in and get some reporting and so and",
    "start": "1643330",
    "end": "1651190"
  },
  {
    "text": "then we do the joined the deployment general generate some artifact like a container that may be deployed in a different cluster and",
    "start": "1651190",
    "end": "1658019"
  },
  {
    "text": "once we've done the entire testing everything works we may want to get some notification so every step in the",
    "start": "1658019",
    "end": "1664960"
  },
  {
    "text": "pipeline have some sort of output result and this is just the sort of the data",
    "start": "1664960",
    "end": "1670330"
  },
  {
    "text": "science for machine learning pipeline another slide and and this is where we",
    "start": "1670330",
    "end": "1677710"
  },
  {
    "text": "can actually use cube flow pipeline so cue flow type pipeline is a relatively",
    "start": "1677710",
    "end": "1683289"
  },
  {
    "text": "new component but very powerful it allows us to essentially create those",
    "start": "1683289",
    "end": "1688350"
  },
  {
    "text": "dependency graphs with complicated policies it allows us to build the",
    "start": "1688350",
    "end": "1694299"
  },
  {
    "text": "results the inputs and outputs for each experiment and even compare different",
    "start": "1694299",
    "end": "1699600"
  },
  {
    "text": "different results one very powerful thing I like about flow pipeline is the ability to component a component as",
    "start": "1699600",
    "end": "1706269"
  },
  {
    "text": "elements so today there are components from Google from Amazon from IBM from",
    "start": "1706269",
    "end": "1712360"
  },
  {
    "text": "from Iguazu so people can just grab components and integrate them into their",
    "start": "1712360",
    "end": "1717610"
  },
  {
    "text": "pipelines the next thing we need to think about is not just the offline server the machine learning pipeline but",
    "start": "1717610",
    "end": "1724179"
  },
  {
    "text": "also the real-time pipeline are the serving pipeline and again a serving pipeline doesn't add with just having a",
    "start": "1724179",
    "end": "1731230"
  },
  {
    "text": "container that does model serving a serving pipeline includes some application let's say web app or a",
    "start": "1731230",
    "end": "1737950"
  },
  {
    "text": "mobile app that bring some data in and then you need to essentially form this",
    "start": "1737950",
    "end": "1743320"
  },
  {
    "text": "feature vector that is fed into the model where's the data coming from some",
    "start": "1743320",
    "end": "1748389"
  },
  {
    "text": "of it will come from the event itself some of it is from like real time sources some of it from historical",
    "start": "1748389",
    "end": "1753639"
  },
  {
    "text": "sources that also been used for the training and then we have the model serving so you can see all those things",
    "start": "1753639",
    "end": "1759850"
  },
  {
    "text": "always introduce complexities are so many moving components that we need to deal with so what's a simple way to",
    "start": "1759850",
    "end": "1767590"
  },
  {
    "text": "address all this complexity without building docker files all the time and compiling and manually scaling and",
    "start": "1767590",
    "end": "1773620"
  },
  {
    "text": "manually logging and manually securing everything is essentially adopting the service approach so service is a great",
    "start": "1773620",
    "end": "1781330"
  },
  {
    "text": "thing everyone likes herbalists you know there was even a service day on Monday and what is serving is really about",
    "start": "1781330",
    "end": "1788329"
  },
  {
    "text": "service is about automating the process of taking code and operationalizing it thinking about all the aspects of",
    "start": "1788329",
    "end": "1794149"
  },
  {
    "text": "logging auto-scaling forgetting about yeah Mo's and focusing",
    "start": "1794149",
    "end": "1799249"
  },
  {
    "text": "more about requirement specifications and also adding all the instrumentation so one of the key challenges around",
    "start": "1799249",
    "end": "1805039"
  },
  {
    "text": "machine learning and data science is the data scientists are not really used to",
    "start": "1805039",
    "end": "1810259"
  },
  {
    "text": "think about like exception handling and security and all those things so having more and more automated instrumentation",
    "start": "1810259",
    "end": "1816409"
  },
  {
    "text": "built into the code is actually a good thing especially when the gap is so big between data scientists and production",
    "start": "1816409",
    "end": "1823519"
  },
  {
    "text": "code and the other things that are like auto-scaling rolling upgrade etcetera but what's the",
    "start": "1823519",
    "end": "1829429"
  },
  {
    "text": "challenge around service that it wasn't designed for data science or machine learning okay what does it mean usually",
    "start": "1829429",
    "end": "1836179"
  },
  {
    "text": "single-threaded no concurrency no support for GPUs because that's like hardware it's a stateful thing usually",
    "start": "1836179",
    "end": "1844249"
  },
  {
    "text": "stateless application patterns so when you need to deal with things that is with state and context and caches that",
    "start": "1844249",
    "end": "1850609"
  },
  {
    "text": "pretty hard to do most of the frameworks think of it in terms of HTTP when you're",
    "start": "1850609",
    "end": "1857959"
  },
  {
    "text": "starting to move to streaming and batch processing the state involved and checkpointing and all that it's not",
    "start": "1857959",
    "end": "1864349"
  },
  {
    "text": "really designed to most of the frameworks and hard debugging and diagnostics so with that in mind we came",
    "start": "1864349",
    "end": "1870559"
  },
  {
    "text": "with an open source project called nucleo it's already like two years on the road which is very oriented towards",
    "start": "1870559",
    "end": "1876499"
  },
  {
    "text": "data processing analytics and machine learning and I'll show some of those capabilities in a minute what's",
    "start": "1876499",
    "end": "1883190"
  },
  {
    "text": "different about nucleon the lower levels is first it's extremely high performance running your code within nucleo is",
    "start": "1883190",
    "end": "1890119"
  },
  {
    "text": "faster than running your code without nuclear and that's because nuclear itself deals with real-time performance",
    "start": "1890119",
    "end": "1896539"
  },
  {
    "text": "optimizations real-time CPU scheduling real-time thread scheduling garbage",
    "start": "1896539",
    "end": "1902690"
  },
  {
    "text": "cleaning all that is handled by the runtime second is all the features",
    "start": "1902690",
    "end": "1907789"
  },
  {
    "text": "around a data processing checkpointing sharding rebalancing integration with nvidia Rapids for ETL",
    "start": "1907789",
    "end": "1915589"
  },
  {
    "text": "and machine learning integration with other framework for GPU optimizations all the different",
    "start": "1915589",
    "end": "1923029"
  },
  {
    "text": "streaming API you could think of Kafka kinases a google pub/sub esri event hub",
    "start": "1923029",
    "end": "1929059"
  },
  {
    "text": "MQTT jobs etc cron HTTP and one thing",
    "start": "1929059",
    "end": "1935120"
  },
  {
    "text": "that I'm going to show which is very useful is it stateful it's actually can work on top of volume mounts and shirt",
    "start": "1935120",
    "end": "1941630"
  },
  {
    "text": "has notion of shared context that can hold things like database connections GPU resources etc other things that to",
    "start": "1941630",
    "end": "1951139"
  },
  {
    "text": "make it more suitable for data Sciences first automation around Jupiter this",
    "start": "1951139",
    "end": "1956779"
  },
  {
    "text": "entire project just called nuclear Jupiter which is all about how to convert Python code or your notebooks",
    "start": "1956779",
    "end": "1963880"
  },
  {
    "text": "automatically into real time artifacts that contain all the aspects around the",
    "start": "1963880",
    "end": "1969740"
  },
  {
    "text": "function not just the function itself but also the resources is going to consume dependencies packages a PA you",
    "start": "1969740",
    "end": "1978049"
  },
  {
    "text": "know endpoints etc the second thing is the integration with cube flow pipeline",
    "start": "1978049",
    "end": "1983690"
  },
  {
    "text": "that extend the features of Cuba pipeline for doing things like parallel processing seeing steps and code build",
    "start": "1983690",
    "end": "1990919"
  },
  {
    "text": "steps you can build steps that essentially build the code I'll show that things like scene processing etc",
    "start": "1990919",
    "end": "1997929"
  },
  {
    "text": "also again around GPUs we do a lot of work on GPUs very close relations with",
    "start": "1997929",
    "end": "2003580"
  },
  {
    "text": "rep Nvidia and videos using nucleo across the board in different places you",
    "start": "2003580",
    "end": "2009370"
  },
  {
    "text": "can actually with this is a benchmark that was done with the Samsung on a specific Samsung commercial application",
    "start": "2009370",
    "end": "2017049"
  },
  {
    "text": "we're running the same application all nucleo with GPUs was four times faster compared to running it just on container",
    "start": "2017049",
    "end": "2024549"
  },
  {
    "text": "part of it just how nuclear knows how to manage the queuing for the GPU resources",
    "start": "2024549",
    "end": "2030279"
  },
  {
    "text": "which is very transparent to the user okay so with that let's do some some",
    "start": "2030279",
    "end": "2037450"
  },
  {
    "text": "demos",
    "start": "2037450",
    "end": "2039870"
  },
  {
    "text": "okay so let's start with a few basics before I go what I want to show you is building a full pipeline but let's start",
    "start": "2044670",
    "end": "2050919"
  },
  {
    "text": "first by understanding what is nuclear I'm using our managed platform but serve",
    "start": "2050919",
    "end": "2056470"
  },
  {
    "text": "the open source is exactly the same there's no difference so essentially",
    "start": "2056470",
    "end": "2062139"
  },
  {
    "text": "when you go to nuclear you have projects and within projects you have functions and you can create function this is a",
    "start": "2062140",
    "end": "2069370"
  },
  {
    "text": "simple function that does like NLP let me increase the font so did by the way",
    "start": "2069370",
    "end": "2076810"
  },
  {
    "text": "has an embedded vs code contribution of Microsoft you're not forced just to work",
    "start": "2076810",
    "end": "2083950"
  },
  {
    "text": "with the embedded code you can always work from different sources image archives git repos zips all that is",
    "start": "2083950",
    "end": "2093190"
  },
  {
    "text": "supported so you can embed nuclear into se ICD pipeline you can configure many",
    "start": "2093190",
    "end": "2098800"
  },
  {
    "text": "different things and you clear all the different resources you know of in kubernetes whether it's CPUs GPUs it",
    "start": "2098800",
    "end": "2105250"
  },
  {
    "text": "doesn't have to start from zero you know you in data science or streaming you don't really want to start from zero so",
    "start": "2105250",
    "end": "2110470"
  },
  {
    "text": "you can choose what's the range of resources it can work with any type of",
    "start": "2110470",
    "end": "2115780"
  },
  {
    "text": "kubernetes resource like value secrets config Maps labels annotations you could",
    "start": "2115780",
    "end": "2121420"
  },
  {
    "text": "give it the source image that you want to build on top of it the function so it's not like very limited you can",
    "start": "2121420",
    "end": "2126790"
  },
  {
    "text": "essentially say do things like on builds and from build and since you put your",
    "start": "2126790",
    "end": "2132520"
  },
  {
    "text": "entire docker file into descriptive approach it has also volume mounts and PVC so you can mount functions into you",
    "start": "2132520",
    "end": "2140740"
  },
  {
    "text": "can mount data and storage into functions the other very interesting thing is the triggering so essentially",
    "start": "2140740",
    "end": "2147640"
  },
  {
    "text": "not just triggering from HTTP you can trigger from a Kafka stream so when",
    "start": "2147640",
    "end": "2153130"
  },
  {
    "text": "you're trading from a Kafka stream the nuclear engine is which is a scale up scale out a load balancing engine will",
    "start": "2153130",
    "end": "2160540"
  },
  {
    "text": "know how to work with all the shards on the stream and will dynamically if it needs to scale it checkpoints rebalances",
    "start": "2160540",
    "end": "2166810"
  },
  {
    "text": "and you don't lose a single bit during that process so it allows you to auto scale streaming and that's supported",
    "start": "2166810",
    "end": "2174130"
  },
  {
    "text": "across again very large variety of triggers and adding a trigger is very trivial so there are about 14 triggers",
    "start": "2174130",
    "end": "2180069"
  },
  {
    "text": "right now and people can just add additional triggers so that's more on the on this front but let's look at",
    "start": "2180069",
    "end": "2189099"
  },
  {
    "text": "let's look at it from more of an adult perspective the right one",
    "start": "2189099",
    "end": "2194380"
  },
  {
    "text": "okay so data scientists don't like those or you eyes that I showed you they like Jupiter notebooks and what they'll do",
    "start": "2194380",
    "end": "2202979"
  },
  {
    "text": "let me show you a simple example this is the same NLP function that I mentioned",
    "start": "2202979",
    "end": "2208929"
  },
  {
    "text": "before get some text Ransome processing and response as correction translation",
    "start": "2208929",
    "end": "2215079"
  },
  {
    "text": "and sentiment analysis very few lines of code so you can essentially put some magic instructions to like people",
    "start": "2215079",
    "end": "2223179"
  },
  {
    "text": "install to control environment variables control all sorts of spec nucleo spec",
    "start": "2223179",
    "end": "2230099"
  },
  {
    "text": "elements I didn't show that but nucleo spec is essentially a CRD if you download the view nucleo spec it's",
    "start": "2230099",
    "end": "2238449"
  },
  {
    "text": "essentially served it's essentially a CR DT kubernetes element you can do cube",
    "start": "2238449",
    "end": "2245229"
  },
  {
    "text": "cut' all functions you'll see that that's er D but again you can just do",
    "start": "2245229",
    "end": "2252099"
  },
  {
    "text": "all of that you could test your function locally using the built-in test harness and you could then just magic deploy and",
    "start": "2252099",
    "end": "2260890"
  },
  {
    "text": "that will automatically build that function on the cluster and then once",
    "start": "2260890",
    "end": "2266019"
  },
  {
    "text": "it's done I can just curl into that function and see that it's working so taking that and let's build something",
    "start": "2266019",
    "end": "2271660"
  },
  {
    "text": "more complicated one of the nice things that we've done recently is the integration with cube flow pipeline so",
    "start": "2271660",
    "end": "2278799"
  },
  {
    "text": "this example in in the cube flow website where you can see a simple example of",
    "start": "2278799",
    "end": "2284769"
  },
  {
    "text": "essentially taking a notebook through a URL the same notebook I just showed you running a component of deployment this",
    "start": "2284769",
    "end": "2292689"
  },
  {
    "text": "component of deployment is essentially loading the notebook extracting the code",
    "start": "2292689",
    "end": "2298029"
  },
  {
    "text": "as well as the server annotations the magical match to figure out how to build the container based on that it's",
    "start": "2298029",
    "end": "2304119"
  },
  {
    "text": "building the container providing me logs and responding with then address for that running function and",
    "start": "2304119",
    "end": "2311410"
  },
  {
    "text": "then the second component is like a nuclear invoke which is essentially running tests against the container so",
    "start": "2311410",
    "end": "2317440"
  },
  {
    "text": "if I'm going to run this in a pipeline and just run this code what I'll see is",
    "start": "2317440",
    "end": "2323800"
  },
  {
    "text": "that the first step of deployment is building a container pushing the image",
    "start": "2323800",
    "end": "2329440"
  },
  {
    "text": "you know doing all of that and essentially responding when an endpoint and and the response is the invocation",
    "start": "2329440",
    "end": "2338140"
  },
  {
    "text": "response one thing here that you see is that you haven't seen it the environment variable was saying the translation is",
    "start": "2338140",
    "end": "2344530"
  },
  {
    "text": "to French and I'm actually getting Spanish because I mean I'm in Barcelona and that's because you can even override",
    "start": "2344530",
    "end": "2350920"
  },
  {
    "text": "parameters when you're doing the deployment so the code in the notebook can be X and then I could just replace",
    "start": "2350920",
    "end": "2357700"
  },
  {
    "text": "all sorts of parameters and that in the deployment time so with that let's move",
    "start": "2357700",
    "end": "2364300"
  },
  {
    "text": "into something slightly more sophisticated so let's assume we want to build a full pipeline a full pipeline",
    "start": "2364300",
    "end": "2369340"
  },
  {
    "text": "consists of data ingestion data preparation training and then transfer",
    "start": "2369340",
    "end": "2374920"
  },
  {
    "text": "to production so what I build here is four different functions okay",
    "start": "2374920",
    "end": "2380650"
  },
  {
    "text": "like preparation a generator is essentially simulating a real-time feed the preparation is taking that fit and",
    "start": "2380650",
    "end": "2387940"
  },
  {
    "text": "building joins aggregations etc on the data the training is using is",
    "start": "2387940",
    "end": "2393940"
  },
  {
    "text": "essentially creating a training model of that thing it's using by the way dusk",
    "start": "2393940",
    "end": "2399280"
  },
  {
    "text": "and nucleo and dusk and cycle and serve an extra boost it's not deep learning so",
    "start": "2399280",
    "end": "2405700"
  },
  {
    "text": "each one of the steps in the pipeline is a scale out step none of the steps is",
    "start": "2405700",
    "end": "2411070"
  },
  {
    "text": "serve a single single function so I can essentially go and take the generator",
    "start": "2411070",
    "end": "2417660"
  },
  {
    "text": "function which is just a notebook a lot of instruction because it's support",
    "start": "2417660",
    "end": "2423700"
  },
  {
    "text": "different types of data like databases like our time series but also Park a file and when when I run it I could just",
    "start": "2423700",
    "end": "2430660"
  },
  {
    "text": "run it locally and just through built-in",
    "start": "2430660",
    "end": "2436750"
  },
  {
    "text": "the test harness that when I input importing the nucleo sdk library it",
    "start": "2436750",
    "end": "2442570"
  },
  {
    "text": "automatically generates test library and then what I'll see here is that within",
    "start": "2442570",
    "end": "2450369"
  },
  {
    "text": "the matrix essentially I got some file now one very cool thing I did here in",
    "start": "2450369",
    "end": "2455680"
  },
  {
    "text": "the definition we said that nucleus supports mounting support shared files",
    "start": "2455680",
    "end": "2461890"
  },
  {
    "text": "so there's a nice thing in the nucleus decay that essentially allow volume teleporting so I can tell nucleo that my",
    "start": "2461890",
    "end": "2469930"
  },
  {
    "text": "volume in my notebook is going to be remounted into the function which is what I did here so you see that I have",
    "start": "2469930",
    "end": "2476950"
  },
  {
    "text": "my own directory what I'm going to do now is essentially I'm going to deploy a",
    "start": "2476950",
    "end": "2483190"
  },
  {
    "text": "nuclear function and you'll see that the nuclear function the real-time nuclear function will write into my directory",
    "start": "2483190",
    "end": "2489359"
  },
  {
    "text": "hopefully everything works essentially",
    "start": "2489359",
    "end": "2496570"
  },
  {
    "text": "now I'm asking nucleo to deploy who again the demo guys will be with me and",
    "start": "2496570",
    "end": "2504940"
  },
  {
    "text": "it's going to run a deployment ok",
    "start": "2504940",
    "end": "2510609"
  },
  {
    "text": "started which when I'm doing this trick is essentially taking my notebook",
    "start": "2510609",
    "end": "2516220"
  },
  {
    "text": "parsing my notebook optimizing it extracting all the things that give it configuration like this volume mount or",
    "start": "2516220",
    "end": "2522520"
  },
  {
    "text": "by OS you see it's done and now I'm going to run against that",
    "start": "2522520",
    "end": "2528490"
  },
  {
    "text": "endpoint okay I'm done and what I'm supposed to see if I'm going to refresh",
    "start": "2528490",
    "end": "2534570"
  },
  {
    "text": "okay you see another file it's pretty cool so I essentially launch created",
    "start": "2534570",
    "end": "2541270"
  },
  {
    "text": "took my notebook convert my notebook into a container ran it in a different container in the cluster I gave that",
    "start": "2541270",
    "end": "2548680"
  },
  {
    "text": "container through very simple annotation I told it you're gonna write into my directory so or my direct is going to be",
    "start": "2548680",
    "end": "2555130"
  },
  {
    "text": "mounted into your container and it just wrote into I don't even need to move objects around now I just refresh and I",
    "start": "2555130",
    "end": "2561790"
  },
  {
    "text": "have this data I can actually go and use some so I'm utility I have here to read the",
    "start": "2561790",
    "end": "2568440"
  },
  {
    "text": "you know parquet and it sort of name to import miss garrison no so essentially I",
    "start": "2568440",
    "end": "2579060"
  },
  {
    "text": "can just go and read the the data which is on the same place so with that then",
    "start": "2579060",
    "end": "2585000"
  },
  {
    "text": "we did something that does deployment the next thing we want to do is this",
    "start": "2585000",
    "end": "2590400"
  },
  {
    "text": "data preparation so same thing I want to take those parquet far so I have I have",
    "start": "2590400",
    "end": "2596220"
  },
  {
    "text": "your instructions for a nuclear that I need to this container to sense you have all those Python packages I need this I",
    "start": "2596220",
    "end": "2603060"
  },
  {
    "text": "want it to be based on Python Jessie and I won't disturb virtual endpoint virtual",
    "start": "2603060",
    "end": "2608430"
  },
  {
    "text": "mount point and some credentials and you know things were dusk etcetera I then",
    "start": "2608430",
    "end": "2615840"
  },
  {
    "text": "I'm running all this thing I can run the same code locally we're just running here served this handler and this test",
    "start": "2615840",
    "end": "2623940"
  },
  {
    "text": "and I could do the same deployment from here and again when I'll run this thing",
    "start": "2623940",
    "end": "2630140"
  },
  {
    "text": "let's look at the features no features if I'm gonna run against the real time",
    "start": "2630140",
    "end": "2636690"
  },
  {
    "text": "function I'm supposed to now get features delivered directly to me and I",
    "start": "2636690",
    "end": "2642510"
  },
  {
    "text": "could do exactly the same thing for for the other notebooks by the way it's using dusk anyone familiar with dusk",
    "start": "2642510",
    "end": "2648800"
  },
  {
    "text": "dusk is sort of parallel Python processing library that supports many primitives of data frame of a panda's",
    "start": "2648800",
    "end": "2657000"
  },
  {
    "text": "data frame as well as scikit-learn an extra boost one of the nice things that were working with in viña now is support",
    "start": "2657000",
    "end": "2662580"
  },
  {
    "text": "for the GPU so dusk kudi F is the server equivalent of dinner frame and qml is",
    "start": "2662580",
    "end": "2668940"
  },
  {
    "text": "the equivalent of scikit-learn and extra boost so I can essentially do the same",
    "start": "2668940",
    "end": "2674670"
  },
  {
    "text": "things around the training I'll just generate the model C and I'll",
    "start": "2674670",
    "end": "2683430"
  },
  {
    "text": "go to the model directory and hopefully I'm gonna have a model good and then",
    "start": "2683430",
    "end": "2690800"
  },
  {
    "text": "then let's do the prediction so again same notebook now one of the",
    "start": "2690800",
    "end": "2698169"
  },
  {
    "text": "things that I forgot to mention on the on the first one that you see this is",
    "start": "2698169",
    "end": "2705400"
  },
  {
    "text": "commented out because in real life I don't want to go and click shift enter and do something I want in real life",
    "start": "2705400",
    "end": "2711819"
  },
  {
    "text": "this generator to actually work in a cron job and every one minute go fete",
    "start": "2711819",
    "end": "2717130"
  },
  {
    "text": "something from an external service or do something so if I uncomment those two lines just sense you say nucleo config",
    "start": "2717130",
    "end": "2723819"
  },
  {
    "text": "spec triggers cron with ten seconds it's essentially going to add a cron trigger",
    "start": "2723819",
    "end": "2730569"
  },
  {
    "text": "to my function and my function is actually gonna every second is going to push things so I don't have to just",
    "start": "2730569",
    "end": "2735849"
  },
  {
    "text": "think about pipeline that's something that I have to invoke I can put things like streams cron jobs HTP endpoints as",
    "start": "2735849",
    "end": "2742419"
  },
  {
    "text": "part of my my pipeline so with that the",
    "start": "2742419",
    "end": "2747579"
  },
  {
    "text": "next thing I want to do is essentially create an automated pipeline because I'm sort of tired of messing with those all",
    "start": "2747579",
    "end": "2753130"
  },
  {
    "text": "those sort of shift enters so I can essentially write this specific notebook",
    "start": "2753130",
    "end": "2758829"
  },
  {
    "text": "what it does essentially loads those two components which are part of the queue",
    "start": "2758829",
    "end": "2765159"
  },
  {
    "text": "flow repository actually only need invoke one and then I'm I'm just daisy",
    "start": "2765159",
    "end": "2771640"
  },
  {
    "text": "chaining those different four functions all the way from data generation data",
    "start": "2771640",
    "end": "2778959"
  },
  {
    "text": "preparation training and any inferencing okay and one just after the other and then I'm just running this experiment",
    "start": "2778959",
    "end": "2786609"
  },
  {
    "text": "okay so if I'm going to take that notebook and run this experiment again",
    "start": "2786609",
    "end": "2794699"
  },
  {
    "text": "then supposedly I'm going to see something running here in a second and",
    "start": "2794699",
    "end": "2800099"
  },
  {
    "text": "all this pipeline that I described that is going to run automatically okay so",
    "start": "2800099",
    "end": "2807009"
  },
  {
    "text": "you see I got the first step running ok writing into this directory and then the",
    "start": "2807009",
    "end": "2814779"
  },
  {
    "text": "step second step is is running this and then running the training and eventually",
    "start": "2814779",
    "end": "2820749"
  },
  {
    "text": "getting the inference thing done so now if I'm gonna go back to my",
    "start": "2820749",
    "end": "2826510"
  },
  {
    "text": "[Music] my thing let's just go to matrix you see another file was generated a",
    "start": "2826510",
    "end": "2832970"
  },
  {
    "text": "second ago so essentially what I did I didn't know anything about the ammos",
    "start": "2832970",
    "end": "2838700"
  },
  {
    "text": "nothing about docker the only thing I did I was in my native environment of notebooks they just put some annotations",
    "start": "2838700",
    "end": "2846440"
  },
  {
    "text": "and saying you know what I really want my volumes to be mounted potenti I need the trigger of cron maybe Kafka I want",
    "start": "2846440",
    "end": "2853820"
  },
  {
    "text": "couple of GPUs and those are specifying my requirements and this is automatically generating scale out you",
    "start": "2853820",
    "end": "2861530"
  },
  {
    "text": "know processes on my cluster I can still work on my notebook if I don't want the cluster but if I want to scale my",
    "start": "2861530",
    "end": "2867770"
  },
  {
    "text": "experiment I just shift entered on the deploy thing and if I want to turn it",
    "start": "2867770",
    "end": "2872930"
  },
  {
    "text": "into a recurring process of doing this over and over again in an automated fashion I just turned into cue flow",
    "start": "2872930",
    "end": "2879200"
  },
  {
    "text": "pipeline and created a full pipeline okay one thing that we want to improve",
    "start": "2879200",
    "end": "2885860"
  },
  {
    "text": "and we're working with the Jeremy and people from other companies is to try and and create sort of a metadata",
    "start": "2885860",
    "end": "2892280"
  },
  {
    "text": "management layer within queue flow that will simplify greatly those notebooks so",
    "start": "2892280",
    "end": "2897830"
  },
  {
    "text": "I'm going to share all those notebooks in probably will pull them into the coop",
    "start": "2897830",
    "end": "2903350"
  },
  {
    "text": "flow get up so everyone can play with those again we could use any generic",
    "start": "2903350",
    "end": "2909010"
  },
  {
    "text": "resource and and we're hopefully going to make them better and better over time",
    "start": "2909010",
    "end": "2915410"
  },
  {
    "text": "good so that's that's for my demo any questions or no questions thank you",
    "start": "2915410",
    "end": "2925720"
  },
  {
    "text": "yes sorry I'm not sure I heard the",
    "start": "2929050",
    "end": "2943340"
  },
  {
    "text": "questions now my question is a cube flow",
    "start": "2943340",
    "end": "2950000"
  },
  {
    "text": "is going to run on kubernetes itself is having coconuts so cue flow running on",
    "start": "2950000",
    "end": "2956390"
  },
  {
    "text": "top of kubernetes yeah that's what my question is yes and Q Placentia q po is",
    "start": "2956390",
    "end": "2962240"
  },
  {
    "text": "both what is Q flow Q flow is both a set of components and sort of sit under the same pile okay and also a set of unique",
    "start": "2962240",
    "end": "2970130"
  },
  {
    "text": "components at our part of the Q flow project like you flow pipelines Q pipelines I haven't shown all the",
    "start": "2970130",
    "end": "2976970"
  },
  {
    "text": "details but it's very powerful because in q4 pipeline it also has experiment",
    "start": "2976970",
    "end": "2981980"
  },
  {
    "text": "tracking you can see that you could essentially you know people think about cube for pipeline is a machine learning",
    "start": "2981980",
    "end": "2988220"
  },
  {
    "text": "pipeline but can actually do a lot more you can create the CI CD pipeline as I",
    "start": "2988220",
    "end": "2993530"
  },
  {
    "text": "see it's like an iffy if you knife is also having like this kind of flow all right got it",
    "start": "2993530",
    "end": "2998600"
  },
  {
    "text": "so now basically the data most of the data what you do is totally it as all",
    "start": "2998600",
    "end": "3004540"
  },
  {
    "text": "data leak so that's that's a question you know some I personally know end of",
    "start": "3004540",
    "end": "3011830"
  },
  {
    "text": "the model you want to build a model and you through a ml and you need to run",
    "start": "3011830",
    "end": "3017230"
  },
  {
    "text": "this this and I Roger it's a bit a notebook whatever you have it's running",
    "start": "3017230",
    "end": "3022510"
  },
  {
    "text": "on data leak now if yes I know again we need to understand what's the data like data leaks is where you you put your raw",
    "start": "3022510",
    "end": "3029980"
  },
  {
    "text": "data correct okay yeah you know some of the things I did here we have essentially our own high speed cluster",
    "start": "3029980",
    "end": "3036460"
  },
  {
    "text": "file system so everything like you move really really fast so I click refresh and it works so you probably have a",
    "start": "3036460",
    "end": "3042430"
  },
  {
    "text": "fabric which is within the cluster for scaling the job if you're scanning a job",
    "start": "3042430",
    "end": "3047830"
  },
  {
    "text": "you need a cluster of file system cuz they all work on the same okay you probably don't want to go to a dupe or",
    "start": "3047830",
    "end": "3052930"
  },
  {
    "text": "s3 for running a distributed workload on the cluster okay but your raw data that",
    "start": "3052930",
    "end": "3058840"
  },
  {
    "text": "you're going to learn from is probably somewhere on a story or google object store so the the",
    "start": "3058840",
    "end": "3064700"
  },
  {
    "text": "first step is usually pulling from an external resource in some cases if it's real time data or swimming data you will",
    "start": "3064700",
    "end": "3071210"
  },
  {
    "text": "keep it on kubernetes you want not peel it put it on a cloud object store and then you'll have a working set which is",
    "start": "3071210",
    "end": "3078830"
  },
  {
    "text": "probably on the cluster you don't want to go to Hadoop for like doing joins and",
    "start": "3078830",
    "end": "3084020"
  },
  {
    "text": "things like that ok I think this is part of the people still think about data",
    "start": "3084020",
    "end": "3090110"
  },
  {
    "text": "science we have data like okay are like those without did not like also you can do our data science I know that but",
    "start": "3090110",
    "end": "3096650"
  },
  {
    "text": "still if at all you want to use and exploit all the historical data to learn the model you need to finally you are",
    "start": "3096650",
    "end": "3103580"
  },
  {
    "text": "done with everything in the data leak yes I think the other point which is very powerful on cue flow I mentioned",
    "start": "3103580",
    "end": "3109790"
  },
  {
    "text": "those components so to go to the cue flow pipeline repo you see that there are many built-in components and some of",
    "start": "3109790",
    "end": "3117080"
  },
  {
    "text": "them are server data like components ok like if you go to Amazon you add EMR or",
    "start": "3117080",
    "end": "3122750"
  },
  {
    "text": "athina which are essentially server data like so Cooper does allow you to integrate with a cloud provider a data",
    "start": "3122750",
    "end": "3129470"
  },
  {
    "text": "like or your own data like to just create those components there ok ok",
    "start": "3129470",
    "end": "3134570"
  },
  {
    "text": "quarter thank you anyone else",
    "start": "3134570",
    "end": "3140560"
  },
  {
    "text": "how would you compare nucleo to the other server less offerings on coopering IDs like a native and cute and cublas so",
    "start": "3141900",
    "end": "3149709"
  },
  {
    "text": "the way i position nucleo against gay native is when someone asked me can you compare flour eggs and sugar to a cake",
    "start": "3149709",
    "end": "3158259"
  },
  {
    "text": "no k native is essentially building blocks for building your own service",
    "start": "3158259",
    "end": "3163299"
  },
  {
    "text": "okay he's K native equivalent to London oh okay that's so that's that's the first thing",
    "start": "3163299",
    "end": "3168369"
  },
  {
    "text": "nuclear is a fully managed has API is SDKs it you know as load balancers",
    "start": "3168369",
    "end": "3175059"
  },
  {
    "text": "orchestrators it's a you eyes CL eyes K native is a bunch of components okay",
    "start": "3175059",
    "end": "3181180"
  },
  {
    "text": "that's first thing second thing I showed that nucleo is a real-time high performance engine all those things",
    "start": "3181180",
    "end": "3188499"
  },
  {
    "text": "usually open fast and all those who are CGI I call them CGI why because they're the way they work single threaded HTTP",
    "start": "3188499",
    "end": "3195849"
  },
  {
    "text": "request/response they don't have streaming built in they don't have checkpointing they don't have",
    "start": "3195849",
    "end": "3200920"
  },
  {
    "text": "parallelism and nuclear has all this notion of micro spreading inside so nuclear single process gets to 400,000",
    "start": "3200920",
    "end": "3208299"
  },
  {
    "text": "events per second one process nucleus things like GPU and GP resource optimizations it knows how to",
    "start": "3208299",
    "end": "3214599"
  },
  {
    "text": "essentially take the cuda cores and working against them it has stateful",
    "start": "3214599",
    "end": "3220049"
  },
  {
    "text": "data you know integration so nucleus is designed for data processing and machine",
    "start": "3220049",
    "end": "3225759"
  },
  {
    "text": "learning yes it can also do all the other things that lambda does but the positioning is really more wrong we want",
    "start": "3225759",
    "end": "3231670"
  },
  {
    "text": "to focus on you've seen the integration around Jupiter you don't have such a thing in any of the other service",
    "start": "3231670",
    "end": "3238059"
  },
  {
    "text": "frameworks so it's the idea is we want to take the notions of service which is essentially no DevOps or minimal DevOps",
    "start": "3238059",
    "end": "3245170"
  },
  {
    "text": "automation and all that into sort of data science and machine learning thank",
    "start": "3245170",
    "end": "3251469"
  },
  {
    "text": "you okay anyone else",
    "start": "3251469",
    "end": "3257489"
  }
]
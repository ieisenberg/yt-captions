[
  {
    "text": "good afternoon everyone welcome to this session my name is Vincent I'm the chief",
    "start": "120",
    "end": "5440"
  },
  {
    "text": "technology officer for redot based in Asia Pacific uh so I work out of",
    "start": "5440",
    "end": "11519"
  },
  {
    "text": "Singapore but I do spend a lot of time on the road visiting of course or engineering offices uh here in India in",
    "start": "11519",
    "end": "19640"
  },
  {
    "text": "Bangalore and Pune but also meeting with a lot of Enterprise that are really",
    "start": "19640",
    "end": "25840"
  },
  {
    "text": "trying to understand how to get into the artificial intelligence journey and to",
    "start": "25840",
    "end": "31880"
  },
  {
    "text": "leverage a cloud native Technologies we've heard a lot about AI over the past couple of days how exciting it is that",
    "start": "31880",
    "end": "40079"
  },
  {
    "text": "AI is becoming Cloud native I'm going to take a slightly different view in this",
    "start": "40079",
    "end": "46120"
  },
  {
    "text": "session which is to focus on one of the key challenges we see right now in AI",
    "start": "46120",
    "end": "51600"
  },
  {
    "text": "adoption which is sustainability how to build a platform that CS for efficiency",
    "start": "51600",
    "end": "57960"
  },
  {
    "text": "of resource management and of course behind this you would all have in mind",
    "start": "57960",
    "end": "63519"
  },
  {
    "text": "how difficult it is these days to get hold of a GPU when you get hold to a GPU",
    "start": "63519",
    "end": "69600"
  },
  {
    "text": "you want to maximize the usage so we are going to discuss some of the challenges",
    "start": "69600",
    "end": "75200"
  },
  {
    "text": "as well as some of the work that is happening uh in the cognitive Computing Foundation across multiple project to",
    "start": "75200",
    "end": "81920"
  },
  {
    "text": "look at this type of challenge uh I'm going to try to spend a bit of time explaining the topic itself how we look",
    "start": "81920",
    "end": "88640"
  },
  {
    "text": "at the value chain uh of AI with sustainability in mind uh I'll share a",
    "start": "88640",
    "end": "94880"
  },
  {
    "text": "bit as well about high level architecture how do you architect an AI platform for",
    "start": "94880",
    "end": "100880"
  },
  {
    "text": "efficiency and hopefully we'll have enough time to cover a few example uh of",
    "start": "100880",
    "end": "106960"
  },
  {
    "text": "great technical work that is happening across a number of cncf projects so",
    "start": "106960",
    "end": "112399"
  },
  {
    "text": "let's start a bit with a few uh market trends so if you look today at AI",
    "start": "112399",
    "end": "120360"
  },
  {
    "text": "and you'll see in this graph here you know I think I see often on the ground",
    "start": "120360",
    "end": "126039"
  },
  {
    "text": "this mindset that somehow Ai and geni and this explosion started with ch GPT",
    "start": "126039",
    "end": "131319"
  },
  {
    "text": "what I want to share with you is absolutely not since 2010 uh and essentially neural networks",
    "start": "131319",
    "end": "139599"
  },
  {
    "text": "we've seen an explosion of resource requirements due to AI",
    "start": "139599",
    "end": "145120"
  },
  {
    "text": "workload the infection is quite clear from there we you know and since 20",
    "start": "145120",
    "end": "151040"
  },
  {
    "text": "we see an increase roughly four to five times a year in terms of resource utilization",
    "start": "151040",
    "end": "158239"
  },
  {
    "text": "specifically for AI workload the reason is the way that we use AI Technologies",
    "start": "158239",
    "end": "164200"
  },
  {
    "text": "today is we need a lot of data we need to do extensive distributed training",
    "start": "164200",
    "end": "169560"
  },
  {
    "text": "across the stack for these very exciting but also very resource intensive neural",
    "start": "169560",
    "end": "175879"
  },
  {
    "text": "network that needs to be trained and they don't need to be trained only one single time because data changes so we",
    "start": "175879",
    "end": "182159"
  },
  {
    "text": "need to do that repeatedly the second aspect of this is",
    "start": "182159",
    "end": "188239"
  },
  {
    "text": "you know and it's a very interesting thought I mentioned earlier it's hard to get rid of GPU or to get hold of GPU but",
    "start": "188239",
    "end": "196840"
  },
  {
    "text": "there is one resource that has become even more difficult to get hold of and",
    "start": "196840",
    "end": "203000"
  },
  {
    "text": "in demand is energy a lot of data center that we have",
    "start": "203000",
    "end": "208080"
  },
  {
    "text": "not just in our region across the world theyve been built and the power management capability they have have",
    "start": "208080",
    "end": "214959"
  },
  {
    "text": "been built and plan for traditional workload so what you will find is a lot",
    "start": "214959",
    "end": "220560"
  },
  {
    "text": "of data center out there they have some agreement with power provider that do",
    "start": "220560",
    "end": "226360"
  },
  {
    "text": "not C for the explosion in power requirement that is necessary to feed the GPU with energy this is a real",
    "start": "226360",
    "end": "233439"
  },
  {
    "text": "problem if you are interested in it you know one of the best example is now we have the United States re habilitating",
    "start": "233439",
    "end": "240519"
  },
  {
    "text": "nuclear energy just to be able to feed their AI requirement there is no other reason",
    "start": "240519",
    "end": "247079"
  },
  {
    "text": "it's an economic reason they need AI to happen they need to own the AI",
    "start": "247079",
    "end": "252439"
  },
  {
    "text": "Revolution so it's arms race to the ownership of AI this cannot happen",
    "start": "252439",
    "end": "257840"
  },
  {
    "text": "without power very important aspect with all this excitement of",
    "start": "257840",
    "end": "265680"
  },
  {
    "text": "course comes challenges but also risk and regulations so another key emerging",
    "start": "265680",
    "end": "273720"
  },
  {
    "text": "Trend we see is obviously emergence of green a standard practices and",
    "start": "273720",
    "end": "279600"
  },
  {
    "text": "regulations I would like to mention the EU AI act so in Europe if you look at",
    "start": "279600",
    "end": "286120"
  },
  {
    "text": "regulation of AI there is already a provision for provider of AI models and",
    "start": "286120",
    "end": "293000"
  },
  {
    "text": "workload to be accountable for the amount of carbon emissions that they",
    "start": "293000",
    "end": "298160"
  },
  {
    "text": "create that is extremely important think about it most of these provider do they",
    "start": "298160",
    "end": "303840"
  },
  {
    "text": "even know how to measure their carbon emission n to n this is a big",
    "start": "303840",
    "end": "311039"
  },
  {
    "text": "problem last but not least to finish with a bit of a positive note AI",
    "start": "311400",
    "end": "316520"
  },
  {
    "text": "obviously creates a challenge from a sustainability point of view but it also creates",
    "start": "316520",
    "end": "322000"
  },
  {
    "text": "opportunities a lot of efficiency that we get today in power management carbon",
    "start": "322000",
    "end": "328720"
  },
  {
    "text": "emission uh optimization they can actually benefit from artificial intelligence to happen",
    "start": "328720",
    "end": "335919"
  },
  {
    "text": "very simple example power energy grid management I work as well with Telco",
    "start": "335919",
    "end": "341000"
  },
  {
    "text": "providers very often they actually using AI model predictive model to optimize",
    "start": "341000",
    "end": "346280"
  },
  {
    "text": "the way that they manage a power allocation on their grid and in their",
    "start": "346280",
    "end": "351800"
  },
  {
    "text": "substation they actually need this kind of models to be able to do this at scale",
    "start": "351800",
    "end": "357319"
  },
  {
    "text": "it cannot be done with just human are pretty much running AI Ops manually they",
    "start": "357319",
    "end": "362520"
  },
  {
    "text": "managing you know predictive performance and and and capacity requirements",
    "start": "362520",
    "end": "367599"
  },
  {
    "text": "right um where I think the opportunity is for our community since we are",
    "start": "367599",
    "end": "375039"
  },
  {
    "text": "Engineers is that today obviously people did they want to get into AI but these statistics you see there",
    "start": "375039",
    "end": "381919"
  },
  {
    "text": "74% this is actually uh the Enterprise the",
    "start": "381919",
    "end": "387039"
  },
  {
    "text": "percentage of Enterprise who say they are struggling today to orchestrate AI",
    "start": "387039",
    "end": "393199"
  },
  {
    "text": "workload at scale and so I have a bit you know and we had a keynote earlier on I thought he",
    "start": "393199",
    "end": "399080"
  },
  {
    "text": "was a bit too positive and optimistic to be honest when uh we saw a keynote",
    "start": "399080",
    "end": "404599"
  },
  {
    "text": "saying oh kubernetes and cl are SOL AI I totally disagree with this the",
    "start": "404599",
    "end": "411840"
  },
  {
    "text": "statistics shows it most Enterprise that are trying to use Ai and build AI infrastructure today",
    "start": "411840",
    "end": "419240"
  },
  {
    "text": "the majority is scal is is struggling to just scale distributed workload for",
    "start": "419240",
    "end": "425199"
  },
  {
    "text": "tuning I'm not even talking about complex use case you know manage inference and so on so this is still",
    "start": "425199",
    "end": "432759"
  },
  {
    "text": "where we are on the ground in terms of AI",
    "start": "432759",
    "end": "438319"
  },
  {
    "text": "usage optimizing AI for sustainability actually takes a very very wide view of",
    "start": "439560",
    "end": "446039"
  },
  {
    "text": "the sustainability chain I won't cover everything I just want to mention it",
    "start": "446039",
    "end": "451280"
  },
  {
    "text": "when we look at the problem we start from energy infrastructure access to power do we have data center that have",
    "start": "451280",
    "end": "458240"
  },
  {
    "text": "access to solar power wind power renewable being able to access Renewable Power is deeply",
    "start": "458240",
    "end": "465000"
  },
  {
    "text": "important pu of your data center uh type of Hardware you are using all play a",
    "start": "465000",
    "end": "471400"
  },
  {
    "text": "major role in the total footprint but what I'm going to cover today is the right part of the life cycle which is",
    "start": "471400",
    "end": "478840"
  },
  {
    "text": "the software and operation assuming you've got a data center assuming you've got the",
    "start": "478840",
    "end": "485039"
  },
  {
    "text": "gpus how do you maximize the use of your",
    "start": "485039",
    "end": "490960"
  },
  {
    "text": "resources and how do you get the most of the energy span that you are going to",
    "start": "490960",
    "end": "496639"
  },
  {
    "text": "make and this happens obviously with proper orchestration so usage of clown native technology and it happens with",
    "start": "496639",
    "end": "503919"
  },
  {
    "text": "proper SRE platform engineering practices applied to artificial intelligence",
    "start": "503919",
    "end": "509960"
  },
  {
    "text": "so now you're going to ask me how is this relevant to the cncf so I just want to",
    "start": "509960",
    "end": "515599"
  },
  {
    "text": "share with you some relatively recent efforts that have been happening we all",
    "start": "515599",
    "end": "521399"
  },
  {
    "text": "know the cncf mission we want to promote the use of cognitive technology",
    "start": "521399",
    "end": "526959"
  },
  {
    "text": "standards around them I think there is a big we've seen again in yesterday's key note a lot of companies out there now",
    "start": "526959",
    "end": "536360"
  },
  {
    "text": "have to deal with hybrid workloads they run some work close on the cloud private data center I've got a lot of customers",
    "start": "536360",
    "end": "542880"
  },
  {
    "text": "as well now running kubernetes on edge as well AI workload are the best hybrid",
    "start": "542880",
    "end": "551200"
  },
  {
    "text": "workload you can think about AI is hybrid by",
    "start": "551200",
    "end": "556399"
  },
  {
    "text": "definition because you will want to tune or train your model where your data is",
    "start": "556399",
    "end": "561680"
  },
  {
    "text": "generated and 90% of the time where you generate the data is not where the model",
    "start": "561680",
    "end": "568200"
  },
  {
    "text": "needs to be consumed so that creates this situation that already as an engineer I",
    "start": "568200",
    "end": "575120"
  },
  {
    "text": "need to support organization to think about where do I keep the data where do",
    "start": "575120",
    "end": "581480"
  },
  {
    "text": "I train the model where do I deploy the model how do I maximize the efficiency",
    "start": "581480",
    "end": "586880"
  },
  {
    "text": "of data transfer networking access to compute there's a lot of hugely",
    "start": "586880",
    "end": "593000"
  },
  {
    "text": "important design decision that you need to think about from the day one you want",
    "start": "593000",
    "end": "598120"
  },
  {
    "text": "to get into the AI jour scale so on the cncf side it's an",
    "start": "598120",
    "end": "605040"
  },
  {
    "text": "interesting problem because it's a problem that is at the intersection of at least two types of",
    "start": "605040",
    "end": "613200"
  },
  {
    "text": "work that we are already doing on one end we have the tag",
    "start": "613200",
    "end": "618560"
  },
  {
    "text": "runtime that created an AI working group on the other hand we have another",
    "start": "618560",
    "end": "624399"
  },
  {
    "text": "tag which I'm part of which is the Environmental sustainability tag where we care about",
    "start": "624399",
    "end": "630160"
  },
  {
    "text": "making cative technology sustainable we decided to collaborate",
    "start": "630160",
    "end": "636560"
  },
  {
    "text": "between the two groups to build a white",
    "start": "636560",
    "end": "641880"
  },
  {
    "text": "paper explaining best practice of AI system design in Cloud native",
    "start": "641880",
    "end": "647839"
  },
  {
    "text": "environment so we started this engagement about three months ago right now we have a draft paper which we are",
    "start": "647839",
    "end": "654480"
  },
  {
    "text": "extending to revie we are trying to finalize the first version of of this",
    "start": "654480",
    "end": "659600"
  },
  {
    "text": "paper by end of q1 next year and is going to contain a number of best",
    "start": "659600",
    "end": "664839"
  },
  {
    "text": "practices around the management of AI won't go into the detail of the paper",
    "start": "664839",
    "end": "670839"
  },
  {
    "text": "because it's already long but we are approaching the problem from four dimension the First Dimension is the",
    "start": "670839",
    "end": "677480"
  },
  {
    "text": "deployment environment where do you deploy your AI system public Cloud private Cloud on",
    "start": "677480",
    "end": "684959"
  },
  {
    "text": "Prem data center near Edge far Edge Edge device",
    "start": "684959",
    "end": "690360"
  },
  {
    "text": "very wide diversity of environment deployment here type of AI system are you doing",
    "start": "690360",
    "end": "697959"
  },
  {
    "text": "computer vision large language model small language model uh predictive",
    "start": "697959",
    "end": "704440"
  },
  {
    "text": "system the type of system the way you generate the data the way you consume it the need to retrain models frequently or",
    "start": "704440",
    "end": "711519"
  },
  {
    "text": "not frequently it will all play a role in your system design so this is very important AI life cycle",
    "start": "711519",
    "end": "719440"
  },
  {
    "text": "optimizing AI for tuning and optimizing AI for inference is two hugely different",
    "start": "719440",
    "end": "728120"
  },
  {
    "text": "problems so if you solve your need to tune your own language model like you have not solved all the",
    "start": "728360",
    "end": "736959"
  },
  {
    "text": "challenges you will have doing wiely distributed in frence and scaling those are almost two different",
    "start": "736959",
    "end": "744440"
  },
  {
    "text": "disciplines and the last is Persona because when you operate AI scale",
    "start": "744440",
    "end": "749920"
  },
  {
    "text": "obviously you have data scientist they don't really know or understand the platform I find it interesting sometimes",
    "start": "749920",
    "end": "756639"
  },
  {
    "text": "that you know we expect data scientists to know which GPU is going to be a sign uh and how many gpus should actually run",
    "start": "756639",
    "end": "763480"
  },
  {
    "text": "on a workload when they obviously don't actually want to have anything to do",
    "start": "763480",
    "end": "769800"
  },
  {
    "text": "with this and then similarly we need to bring people who have knowledge of the",
    "start": "769800",
    "end": "775320"
  },
  {
    "text": "platform SRE engineer Ops engineer to get to understand the specificity of AI",
    "start": "775320",
    "end": "781600"
  },
  {
    "text": "workload yeah so getting all these Persona across the life cycle to collaborate and understand their role is",
    "start": "781600",
    "end": "787920"
  },
  {
    "text": "also part of our mission so what we want the white paper to be is if you are one",
    "start": "787920",
    "end": "793120"
  },
  {
    "text": "of this Persona you will basically be able to read this paper and understand where you fit in the AI value chain and",
    "start": "793120",
    "end": "800279"
  },
  {
    "text": "what your role in terms of promoting sustainability could",
    "start": "800279",
    "end": "805760"
  },
  {
    "text": "be let's start with a high level view of what a sustainable a platform",
    "start": "807279",
    "end": "812720"
  },
  {
    "text": "architecture is so here I just want to summarize the big takeaway of this at",
    "start": "812720",
    "end": "818600"
  },
  {
    "text": "the top you see two part of the life cycle of AI on the left you have the",
    "start": "818600",
    "end": "825600"
  },
  {
    "text": "model training and the model tuning the type of problem we are solving here is",
    "start": "825600",
    "end": "831800"
  },
  {
    "text": "essentially HPC problems ironically I started my career 20 years ago in HPC",
    "start": "831800",
    "end": "837920"
  },
  {
    "text": "domain now I'm working in a totally different job and I'm doing High HPC on cloud",
    "start": "837920",
    "end": "845040"
  },
  {
    "text": "native technology for AI soing the same typ of problem scheduling workload defining priorities how to build full",
    "start": "845040",
    "end": "852240"
  },
  {
    "text": "tolerance how to optimize for specific SLO and SLO are becoming more and more",
    "start": "852240",
    "end": "858880"
  },
  {
    "text": "complex they are not just performance related we need to care about power",
    "start": "858880",
    "end": "865040"
  },
  {
    "text": "efficiency we need to care about carbon emissions we need to care about cost",
    "start": "865040",
    "end": "870279"
  },
  {
    "text": "as so as an optimization engineer all these elements are becoming increasingly more complex to manage on the right you",
    "start": "870279",
    "end": "877920"
  },
  {
    "text": "see a totally different problem which is in France so something very interesting to",
    "start": "877920",
    "end": "884199"
  },
  {
    "text": "me is when you see the literature today about AI it's like everyone wants to do training and tuning reality is most",
    "start": "884199",
    "end": "892639"
  },
  {
    "text": "business out there they will spend most of their time and focus and energy on",
    "start": "892639",
    "end": "898160"
  },
  {
    "text": "insuring if you are not called Facebook or Alibaba or Google chance is",
    "start": "898160",
    "end": "905880"
  },
  {
    "text": "you will not have enough money to train your own language model so guess what you're going to spend most of your time",
    "start": "905880",
    "end": "911800"
  },
  {
    "text": "doing you are going to take an open source model hopefully yeah and then maybe you'll do a bit of tuning and then",
    "start": "911800",
    "end": "919199"
  },
  {
    "text": "you are going to optimize for infrance yeah so this is usually important now at",
    "start": "919199",
    "end": "924399"
  },
  {
    "text": "the bottom row what do we need to care about as usual we've got compute so here",
    "start": "924399",
    "end": "930880"
  },
  {
    "text": "what is very important is obviously you need to support different type of accelerator NV of usually provide a lot",
    "start": "930880",
    "end": "938199"
  },
  {
    "text": "of great technology very Advanced capability out there that you can use",
    "start": "938199",
    "end": "943519"
  },
  {
    "text": "but we also see the emergence of new type of accelerator that are usually specialized and give very very good you",
    "start": "943519",
    "end": "951360"
  },
  {
    "text": "know rate and capability that are sustainable for very specific type of",
    "start": "951360",
    "end": "957160"
  },
  {
    "text": "workload next year you are going to see the emergence and I mean it's an easy prediction because I've been working",
    "start": "957160",
    "end": "963079"
  },
  {
    "text": "with some of his provider on the hardware side you are going to see the emergence of hugely specialized chip",
    "start": "963079",
    "end": "970040"
  },
  {
    "text": "that are doing specific type of deep you know neural network in France probably",
    "start": "970040",
    "end": "977279"
  },
  {
    "text": "50 or 60% cheaper with lower energy than a traditional general purpose GPU the",
    "start": "977279",
    "end": "983480"
  },
  {
    "text": "cloud provider if you see AWS as an example they have two different chip for",
    "start": "983480",
    "end": "988680"
  },
  {
    "text": "in France and training yeah so we are going towards a world of specialization and you need a",
    "start": "988680",
    "end": "995040"
  },
  {
    "text": "platform that will be able to easily take this new technology as then when they become available to use their",
    "start": "995040",
    "end": "1003759"
  },
  {
    "text": "capability networking becomes a challenge as well",
    "start": "1003759",
    "end": "1009120"
  },
  {
    "text": "the moment you are going into multicluster in particular a deep trading at scale guess what should I use",
    "start": "1009120",
    "end": "1017839"
  },
  {
    "text": "64 h00 GPU on one single machine for 3",
    "start": "1017839",
    "end": "1024400"
  },
  {
    "text": "weeks or do I want to use three different machine connected",
    "start": "1024400",
    "end": "1030600"
  },
  {
    "text": "across uh ndma over converge internet Network depends do you need to go fast",
    "start": "1030600",
    "end": "1038600"
  },
  {
    "text": "are you ready to pay the the energy premium for the network",
    "start": "1038600",
    "end": "1043678"
  },
  {
    "text": "connectivity there's no s simple answer to this you'll have to understand the",
    "start": "1043679",
    "end": "1050520"
  },
  {
    "text": "tradeoff and then finishing with have the storage so storage as well we see a",
    "start": "1050520",
    "end": "1055799"
  },
  {
    "text": "lot of opportunity to improve the way that storage management works especially",
    "start": "1055799",
    "end": "1061320"
  },
  {
    "text": "caching of model uh and especially in the INF France workload side I'll finish with the little thing at the bottom on",
    "start": "1061320",
    "end": "1068919"
  },
  {
    "text": "the right which unfortunately is small but is super important which is",
    "start": "1068919",
    "end": "1074520"
  },
  {
    "text": "observability everything that I have discussed so far if you do not have a way to get Telemetry on your",
    "start": "1074520",
    "end": "1082400"
  },
  {
    "text": "platform you are not going to be able to manage anything or optimize anything so",
    "start": "1082400",
    "end": "1088039"
  },
  {
    "text": "there's actually a huge amount of work that is going specifically on AI Telemetry to understand the performance",
    "start": "1088039",
    "end": "1095039"
  },
  {
    "text": "the latency of model but also the span power energy yeah that you have on the",
    "start": "1095039",
    "end": "1101520"
  },
  {
    "text": "workload we contribute a lot out on a project called Kepler which is a cncf",
    "start": "1101520",
    "end": "1107400"
  },
  {
    "text": "project and capler basic gives you power monitoring for a GPU you will see later why this product",
    "start": "1107400",
    "end": "1114200"
  },
  {
    "text": "is usually beneficial what type of work are we",
    "start": "1114200",
    "end": "1119880"
  },
  {
    "text": "doing now to make this better right to help you as practitioner to optimize",
    "start": "1119880",
    "end": "1127280"
  },
  {
    "text": "your AI platform there are essentially three category of work we work on optimizing workload efficiency so here",
    "start": "1127280",
    "end": "1136000"
  },
  {
    "text": "the thinking that you should have in mind is I have a model and I want to get the same output",
    "start": "1136000",
    "end": "1143320"
  },
  {
    "text": "but with less energy input so this is energy efficient framework how do I make the model",
    "start": "1143320",
    "end": "1150039"
  },
  {
    "text": "smaller how do I make the model's output as good as my previous model but reduce",
    "start": "1150039",
    "end": "1156240"
  },
  {
    "text": "the cost of insurance is an example of it the second category is resource",
    "start": "1156240",
    "end": "1162360"
  },
  {
    "text": "optimization big warning here in the industry today the",
    "start": "1162360",
    "end": "1168080"
  },
  {
    "text": "statistics for resource utilization of gpus are not",
    "start": "1168080",
    "end": "1173760"
  },
  {
    "text": "good 15 20% utilization is pretty much average I see and I speak with a lot of",
    "start": "1173760",
    "end": "1181120"
  },
  {
    "text": "organization yeah so imagine you buy those hugely expensive",
    "start": "1181120",
    "end": "1187039"
  },
  {
    "text": "GPU you install them in your data center at the cost of very expensive",
    "start": "1187039",
    "end": "1192320"
  },
  {
    "text": "Engineers trying to do this and then 80% of the time they are sitting there",
    "start": "1192320",
    "end": "1198360"
  },
  {
    "text": "waiting for a workload not because you don't have anything to run but because the",
    "start": "1198360",
    "end": "1204480"
  },
  {
    "text": "provisioning is not automated is very hard to understand to have a prediction of who needs the gpus when you have to",
    "start": "1204480",
    "end": "1211440"
  },
  {
    "text": "run this multi tant and therefore people are over provisioning GPU to keep them in case they need them I could give you",
    "start": "1211440",
    "end": "1218520"
  },
  {
    "text": "50 different reason why things are not happening there it's just the reality",
    "start": "1218520",
    "end": "1224080"
  },
  {
    "text": "but we have to do better and the last bit is scalability right so if you operate scale I don't think that will be",
    "start": "1224080",
    "end": "1230480"
  },
  {
    "text": "the majority of you in the room but if you operate at scale and you want to go",
    "start": "1230480",
    "end": "1235679"
  },
  {
    "text": "into your own model training or tuning you will need to start thinking about the problem of usually distributed",
    "start": "1235679",
    "end": "1243280"
  },
  {
    "text": "scaling for AI workload and so so we contribute to all this type of Technology all of this is cloud native",
    "start": "1243280",
    "end": "1250520"
  },
  {
    "text": "so the the great news though is and this I agree with what we discussed in the Keynotes the great news is cloud native",
    "start": "1250520",
    "end": "1258440"
  },
  {
    "text": "is is the you know is the place where all of this is happening and it's going to happen more and more on cloud native",
    "start": "1258440",
    "end": "1264480"
  },
  {
    "text": "stack we know it open a could not try and Char GPT without",
    "start": "1264480",
    "end": "1269880"
  },
  {
    "text": "kubernetes yeah so that's where we are already the direction is there it's set for",
    "start": "1269880",
    "end": "1275880"
  },
  {
    "text": "us before I go into some example I wanted to share a bit the I life cycle",
    "start": "1275880",
    "end": "1281000"
  },
  {
    "text": "and a few Hotpot so I mentioned earlier when you are looking at the AI",
    "start": "1281000",
    "end": "1286919"
  },
  {
    "text": "stack you have to solve different optimization problem depending on which part of the life cycle you are at I will",
    "start": "1286919",
    "end": "1294200"
  },
  {
    "text": "just mention the three biggest Hotpot data management always totally",
    "start": "1294200",
    "end": "1302200"
  },
  {
    "text": "underestimated back in the day before all this you know F about you know AI we",
    "start": "1302200",
    "end": "1310520"
  },
  {
    "text": "used to call it data science and data science to me is a better name because in data science",
    "start": "1310520",
    "end": "1317120"
  },
  {
    "text": "there is data a lot of my friend are so-called data scientists we've been data scientists",
    "start": "1317120",
    "end": "1323400"
  },
  {
    "text": "way before J and J hasn't changed this at all by the way when I ask them where do you",
    "start": "1323400",
    "end": "1330720"
  },
  {
    "text": "spend the most of your time on the life cycle their answer is always the data 80",
    "start": "1330720",
    "end": "1338880"
  },
  {
    "text": "to 90% of the time is dealing with sourcing the data making sure the data can be",
    "start": "1338880",
    "end": "1344559"
  },
  {
    "text": "trusted fitting the model with the data validating the model with the data oh",
    "start": "1344559",
    "end": "1350480"
  },
  {
    "text": "I'm ready now I'm serving the model is my problem with data over it's not",
    "start": "1350480",
    "end": "1355679"
  },
  {
    "text": "because now I need to monitor the model output to make sure it doesn't deviate from the data I need to monitor for",
    "start": "1355679",
    "end": "1362600"
  },
  {
    "text": "drift so data is always going to be at the heart of everything so there's a lot",
    "start": "1362600",
    "end": "1368440"
  },
  {
    "text": "of things you can do to optimize data workload a lot of organization I work",
    "start": "1368440",
    "end": "1373480"
  },
  {
    "text": "with right now it's not unusual to see 10,000 to 15,000 core of Apache spark",
    "start": "1373480",
    "end": "1380360"
  },
  {
    "text": "workload just running almost continuously to process data so that's",
    "start": "1380360",
    "end": "1385720"
  },
  {
    "text": "the first area of optimization I won't cover it too much today because this one is traditional",
    "start": "1385720",
    "end": "1392919"
  },
  {
    "text": "it's not really recent the second one part is training that's where a lot of people focus and we've got a lot of",
    "start": "1392919",
    "end": "1399360"
  },
  {
    "text": "great project in cncf to actually help with this right Q for scheduling and",
    "start": "1399360",
    "end": "1406000"
  },
  {
    "text": "orchestration CBR to basically integrate kubernetes with Ray cluster uh that's",
    "start": "1406000",
    "end": "1412440"
  },
  {
    "text": "like that's been like a huge help for us to start implementing implementing",
    "start": "1412440",
    "end": "1417520"
  },
  {
    "text": "distributed training at scale but what I want to share with you and what you see",
    "start": "1417520",
    "end": "1422640"
  },
  {
    "text": "on the right by the way is coming from a very good study from our Facebook AI friends why Facebook AI paper is",
    "start": "1422640",
    "end": "1430039"
  },
  {
    "text": "interesting is of course Facebook is huge in terms of their use of AI and also the way they have designed their AI",
    "start": "1430039",
    "end": "1436640"
  },
  {
    "text": "internally allows them to a very good statistics to understand the Hotpot give you an example of this is Facebook uses",
    "start": "1436640",
    "end": "1444960"
  },
  {
    "text": "uh kubernetes inance cluster and kubernetes training cluster the infont",
    "start": "1444960",
    "end": "1450799"
  },
  {
    "text": "machine and the you know and the configuration of the cluster are usually",
    "start": "1450799",
    "end": "1455840"
  },
  {
    "text": "adapted to the type of workload so workload never moves in between yeah so",
    "start": "1455840",
    "end": "1461720"
  },
  {
    "text": "thanks to this they are able to know exactly how much they are spending in terms of resource on all the parts of",
    "start": "1461720",
    "end": "1467960"
  },
  {
    "text": "the life cycle and something that to me I I found usually interesting is even",
    "start": "1467960",
    "end": "1475720"
  },
  {
    "text": "Facebook which honestly is not probably going to be the the type of pattern you see in most",
    "start": "1475720",
    "end": "1481520"
  },
  {
    "text": "Enterprise very clearly says that although we train huge model and",
    "start": "1481520",
    "end": "1486960"
  },
  {
    "text": "constantly retrain them because we had a lot of new data still 65% of the span is on inance yeah you",
    "start": "1486960",
    "end": "1494919"
  },
  {
    "text": "can see the little diagram at the top on the fet right the gray bar two3 of the fleet of servers is actually",
    "start": "1494919",
    "end": "1503000"
  },
  {
    "text": "dedicated to infrance although the majority of Facebook model they have retune every",
    "start": "1503000",
    "end": "1510000"
  },
  {
    "text": "week if not every day on the new data so think about it right if Facebook with",
    "start": "1510000",
    "end": "1516720"
  },
  {
    "text": "its amount of retuning is spending the majority of time on insurance and",
    "start": "1516720",
    "end": "1523080"
  },
  {
    "text": "resources most Enterprise that you work with or work for will have an even",
    "start": "1523080",
    "end": "1529559"
  },
  {
    "text": "bigger focus and spend on in France that's just the reality now that's also a big",
    "start": "1529559",
    "end": "1536799"
  },
  {
    "text": "opportunity as well the reason is and this is the other statistic shared in",
    "start": "1536799",
    "end": "1542399"
  },
  {
    "text": "the paper but I've seen different view of this in France provides a huge amount",
    "start": "1542399",
    "end": "1548120"
  },
  {
    "text": "of opportunity to reduce the energy span and the carbon span if you start to",
    "start": "1548120",
    "end": "1554720"
  },
  {
    "text": "optimize so 800 but I've seen Google as well publish 900",
    "start": "1554720",
    "end": "1559840"
  },
  {
    "text": "950 is the amount of reduction they manage to get on insurance workload by",
    "start": "1559840",
    "end": "1565200"
  },
  {
    "text": "applying efficiency management technique so that's a good news right if the",
    "start": "1565200",
    "end": "1570559"
  },
  {
    "text": "majority of workload is in France and we can actually reduce that much the power spend on INF",
    "start": "1570559",
    "end": "1578080"
  },
  {
    "text": "France then we can actually of course do something good for Humanity and climate",
    "start": "1578080",
    "end": "1584679"
  },
  {
    "text": "but we can also make our bosses happy with the bill yeah so I'm going to cover",
    "start": "1584679",
    "end": "1592559"
  },
  {
    "text": "now some of the work we are doing specifically on in France and also some of the opportunities we see and you will",
    "start": "1592559",
    "end": "1599520"
  },
  {
    "text": "see some of these techniques in the white paper I mentioned earlier so I'm just here doing a deep dive had to give",
    "start": "1599520",
    "end": "1605799"
  },
  {
    "text": "you an idea of the type of technique and practices we are looking at so the graph",
    "start": "1605799",
    "end": "1610960"
  },
  {
    "text": "you see here is kind of how we see inference and the pocket of opportunity",
    "start": "1610960",
    "end": "1616240"
  },
  {
    "text": "we have to make inference better the things I want to highlight is this right the first is when we look at the",
    "start": "1616240",
    "end": "1623399"
  },
  {
    "text": "Total Resource we have for in France There's an opportunity to start thinking about queuing all the requests for",
    "start": "1623399",
    "end": "1629159"
  },
  {
    "text": "inference and start to allocate the inference request to",
    "start": "1629159",
    "end": "1634200"
  },
  {
    "text": "resources and models in an optimized manner so there is some kind of batching that can be done as well this batching",
    "start": "1634200",
    "end": "1641399"
  },
  {
    "text": "is more in terms of resource allocation to Insurance workload the second type of work what we",
    "start": "1641399",
    "end": "1649039"
  },
  {
    "text": "are doing is now you have a inference workload how can I make the energy span",
    "start": "1649039",
    "end": "1654960"
  },
  {
    "text": "on the start and the memory better so here there's a lot of work that's",
    "start": "1654960",
    "end": "1660760"
  },
  {
    "text": "happening in the cncf today to look on model caching uh in fact",
    "start": "1660760",
    "end": "1666080"
  },
  {
    "text": "recently uh there were a few new submission for sandbox uh project in the",
    "start": "1666080",
    "end": "1671279"
  },
  {
    "text": "cncf to look at how to use oci registry and oci artifacts to uh share",
    "start": "1671279",
    "end": "1678840"
  },
  {
    "text": "AI models and their component why is this important imagine I am a serving",
    "start": "1678840",
    "end": "1685159"
  },
  {
    "text": "engine and instead of going to a a relatively inefficient storage layer I",
    "start": "1685159",
    "end": "1691480"
  },
  {
    "text": "can cash my model directly from an oci registry V going to make to provide me",
    "start": "1691480",
    "end": "1697080"
  },
  {
    "text": "with a lot of efficiency Val provide me with opportunity to cash and use the cache",
    "start": "1697080",
    "end": "1703120"
  },
  {
    "text": "across multiple INF front server if the same model is used for multiple services",
    "start": "1703120",
    "end": "1708320"
  },
  {
    "text": "yeah so there's a lot of ability we have here to do better with less resources the last bit I'm going to go",
    "start": "1708320",
    "end": "1715760"
  },
  {
    "text": "slightly more in details is basically a lot of work we are doing to support a",
    "start": "1715760",
    "end": "1721080"
  },
  {
    "text": "very growing Trend in AI Management in production workload in Enterprise which",
    "start": "1721080",
    "end": "1727640"
  },
  {
    "text": "is people don't want to serve huge 45 billion parameter model in Enterprise",
    "start": "1727640",
    "end": "1734080"
  },
  {
    "text": "today things that get into production in the genni world they are actually small",
    "start": "1734080",
    "end": "1739559"
  },
  {
    "text": "modelss orchestrated across each other and pretty much integrated with the rest of application Services we saw a very",
    "start": "1739559",
    "end": "1746679"
  },
  {
    "text": "good talk this morning about agentic AI yeah this is what is actually going to production today in Enterprise is small",
    "start": "1746679",
    "end": "1754880"
  },
  {
    "text": "agent they are tuned to to you know to meet a very specific Mission and and",
    "start": "1754880",
    "end": "1760919"
  },
  {
    "text": "output which can be measured and the good thing with small model is obviously they're small so they consume less",
    "start": "1760919",
    "end": "1767240"
  },
  {
    "text": "resource and they provide some opportunities for Energy",
    "start": "1767240",
    "end": "1772720"
  },
  {
    "text": "Efficiency so let's see some of this technique so the way we start in the",
    "start": "1772720",
    "end": "1778960"
  },
  {
    "text": "life cycle of small model is how do we build a small model to start with the best small language model out there",
    "start": "1778960",
    "end": "1786080"
  },
  {
    "text": "there are actually large language model that we have trim down so here are a few",
    "start": "1786080",
    "end": "1791559"
  },
  {
    "text": "key techniques that are being used today on a regular basis to get a small language",
    "start": "1791559",
    "end": "1798200"
  },
  {
    "text": "model that perform almost as well as a large language model but with a reduced",
    "start": "1798200",
    "end": "1804480"
  },
  {
    "text": "power demand reduced memory usage model ping is kind of simple you have a neural",
    "start": "1804480",
    "end": "1811039"
  },
  {
    "text": "network let's reduce the node that don't really have much to do with the",
    "start": "1811039",
    "end": "1817360"
  },
  {
    "text": "output generally model prunings doesn't give you much challenge with the output",
    "start": "1817360",
    "end": "1824159"
  },
  {
    "text": "quality and you get some reduction but the much better technique here is model",
    "start": "1824159",
    "end": "1829440"
  },
  {
    "text": "quantization what is model quantization so essentially with model quantization",
    "start": "1829440",
    "end": "1834760"
  },
  {
    "text": "we are looking at taking the model weight and reducing the the the the size of their",
    "start": "1834760",
    "end": "1840919"
  },
  {
    "text": "note from really heavy you know like like like um 32bit floating Point all",
    "start": "1840919",
    "end": "1846880"
  },
  {
    "text": "the way to 16 or 8 bit this is the best technique in terms",
    "start": "1846880",
    "end": "1853039"
  },
  {
    "text": "of power reduction of or but it comes with a challenge",
    "start": "1853039",
    "end": "1858519"
  },
  {
    "text": "the model output and the quality may be affected so there's a lot of research going on in thisa area but essentially",
    "start": "1858519",
    "end": "1867440"
  },
  {
    "text": "what we find is if you use quantization technique but they are they're basically uh quantization aware training so you",
    "start": "1867440",
    "end": "1874519"
  },
  {
    "text": "basically quantize and check the output and tune the output repeatedly you can get to very small size model that",
    "start": "1874519",
    "end": "1881279"
  },
  {
    "text": "perform really really closely to a large language model for your specific purpose and they are projects open",
    "start": "1881279",
    "end": "1888639"
  },
  {
    "text": "source projects out there that enable the serving of this model very effectively an example of this is VM so",
    "start": "1888639",
    "end": "1895120"
  },
  {
    "text": "at that we work a lot today with VM and with VM contributor to make sure that we",
    "start": "1895120",
    "end": "1900919"
  },
  {
    "text": "can get some of this quantize model uh supported uh in in a CL native stack and",
    "start": "1900919",
    "end": "1907320"
  },
  {
    "text": "that is the reason of this investment in VM I'll finish with this last technique which is interesting knowledge",
    "start": "1907320",
    "end": "1914039"
  },
  {
    "text": "distillation is you are basically uh using the concept of a trainer model and you have a small model learning from the",
    "start": "1914039",
    "end": "1921360"
  },
  {
    "text": "large model that is training it for a specific output that also giv you reduction in number of model parameter",
    "start": "1921360",
    "end": "1928159"
  },
  {
    "text": "all this technique they result in reduced power consumption reduced memory",
    "start": "1928159",
    "end": "1933200"
  },
  {
    "text": "consumption for your model great news I've got a small model",
    "start": "1933200",
    "end": "1939399"
  },
  {
    "text": "now here comes a new challenge let's say you have the small model but the resource allocation",
    "start": "1939399",
    "end": "1946519"
  },
  {
    "text": "strategy that you have in kuber forces you to use at least one entire",
    "start": "1946519",
    "end": "1953200"
  },
  {
    "text": "GPU that's an issue because you are going to have over provisioning of GPU resources for all your serving so we",
    "start": "1953519",
    "end": "1961360"
  },
  {
    "text": "want to avoid this so here the good news is we start to have solutions to",
    "start": "1961360",
    "end": "1967000"
  },
  {
    "text": "actually manage scale of model within uh model slices and",
    "start": "1967000",
    "end": "1972240"
  },
  {
    "text": "partition Nvidia provid us with Mig partitions right and recent ly at coupon",
    "start": "1972240",
    "end": "1979360"
  },
  {
    "text": "EU and coupon North America we announce with IBM research a project called insta slice insta slice allows Dynamic",
    "start": "1979360",
    "end": "1987279"
  },
  {
    "text": "partitioning so what it means is as you go and serve model and this model get more requirements you can basically",
    "start": "1987279",
    "end": "1994399"
  },
  {
    "text": "create Mig uh partitions dynamically on the GPU and then use them to serve your",
    "start": "1994399",
    "end": "2001440"
  },
  {
    "text": "model within a slice or a couple of slice yeah and we didn't stop there we",
    "start": "2001440",
    "end": "2007960"
  },
  {
    "text": "started to work on predictive model as well so using AI to optimize Ai and what",
    "start": "2007960",
    "end": "2013080"
  },
  {
    "text": "we show at coupon North America is we can also train",
    "start": "2013080",
    "end": "2018360"
  },
  {
    "text": "model uh to basically understand the gpus that are available the the the the",
    "start": "2018360",
    "end": "2024799"
  },
  {
    "text": "workload footprint as well and then we basically intercept a scheduling to",
    "start": "2024799",
    "end": "2030120"
  },
  {
    "text": "determine what is the best life that should be used to schedule the model all within the S and do this optimization as",
    "start": "2030120",
    "end": "2037360"
  },
  {
    "text": "you go yeah so there is a huge amount of opportunity here to manage the GPU more",
    "start": "2037360",
    "end": "2045760"
  },
  {
    "text": "efficiently so that gets us to already a pretty good point by the way in slice we",
    "start": "2046480",
    "end": "2051960"
  },
  {
    "text": "expect it to kind of be Market ready q1 next year so we are very close uh and",
    "start": "2051960",
    "end": "2057480"
  },
  {
    "text": "and we are not going to stop there because the idea of insta SLI is is complementary to to Dr so Dr takes care",
    "start": "2057480",
    "end": "2064560"
  },
  {
    "text": "of the overall Resource Management the one thing that Dr did really C for is what if you have a very very small model",
    "start": "2064560",
    "end": "2070638"
  },
  {
    "text": "and it only needs like one eight of a GPU so that's the problem we solve I'll finish with",
    "start": "2070639",
    "end": "2076960"
  },
  {
    "text": "this now the last technique you have is dynamically managing the power consumption there's something else you",
    "start": "2076960",
    "end": "2083079"
  },
  {
    "text": "can do with GPU is you can change the frequency or the power you use of a GPU",
    "start": "2083079",
    "end": "2088118"
  },
  {
    "text": "and you can declare it so we recently contributed a project to open source",
    "start": "2088119",
    "end": "2093960"
  },
  {
    "text": "called climatic uh with Intel and IBM research as contributor and what",
    "start": "2093960",
    "end": "2099200"
  },
  {
    "text": "climatic does is again we are using predictive Ai and power profile that we",
    "start": "2099200",
    "end": "2104520"
  },
  {
    "text": "Define with the GPU maker to understand what is the most Optimum frequency I",
    "start": "2104520",
    "end": "2111560"
  },
  {
    "text": "wish a GPU can run at inference to maximize the latency output with the",
    "start": "2111560",
    "end": "2119000"
  },
  {
    "text": "least power demand and the good news uh with insurance workload is there",
    "start": "2119000",
    "end": "2125440"
  },
  {
    "text": "is a way to get 25% Improvement in power span with 2 3%",
    "start": "2125440",
    "end": "2132760"
  },
  {
    "text": "impact on the actual latency performance yeah so so that's like a huge domain as",
    "start": "2132760",
    "end": "2138119"
  },
  {
    "text": "well huge amount of technique available to get more savings so I'm finished with this",
    "start": "2138119",
    "end": "2144200"
  },
  {
    "text": "presentation I hope it was informative in terms of some of the direction and the consideration you can have I just",
    "start": "2144200",
    "end": "2151680"
  },
  {
    "text": "want to finish with this call to action there are some things you can do now let's say you you didn't understand",
    "start": "2151680",
    "end": "2158040"
  },
  {
    "text": "everything I've talked about uh well don't be shy we have the T environmental",
    "start": "2158040",
    "end": "2164240"
  },
  {
    "text": "sustainability within the cncf I put some QR code there you can join us there's a lot of people there who are",
    "start": "2164240",
    "end": "2170480"
  },
  {
    "text": "just discovering sustainability and sustainability for AI everybody is very sharing you can come and learn about it",
    "start": "2170480",
    "end": "2178119"
  },
  {
    "text": "would love to have you around if you are already an AI platform expert and you'd",
    "start": "2178119",
    "end": "2184040"
  },
  {
    "text": "like to contribute you know how to the group that is writing the white paper do",
    "start": "2184040",
    "end": "2189839"
  },
  {
    "text": "scan this QR code it will bring you to the issue on GitHub where we explain",
    "start": "2189839",
    "end": "2195240"
  },
  {
    "text": "what the white paper is doing and right now we are getting more reviewer and contributor on the efficiency technique",
    "start": "2195240",
    "end": "2203200"
  },
  {
    "text": "yeah and the last but not least I mentioned two key projects today where we're still getting uh more contributor",
    "start": "2203200",
    "end": "2209400"
  },
  {
    "text": "Kepler is looking at observability for GPU including performance power consumption and then climatic is doing a",
    "start": "2209400",
    "end": "2216760"
  },
  {
    "text": "power capping for accelerator thank you for your attention I hope the session was helpful I think",
    "start": "2216760",
    "end": "2224359"
  },
  {
    "text": "we've run out of time I see time is a big big letters here so if you want to discuss about it or you have question",
    "start": "2224359",
    "end": "2230640"
  },
  {
    "text": "just grab me I'll just be around for a little while thank you",
    "start": "2230640",
    "end": "2236559"
  }
]
[
  {
    "text": "hello my name is magic Rudovsky I'm a product manager working on kubernetes scalability hello everyone",
    "start": "0",
    "end": "7440"
  },
  {
    "text": "I'm Sean and Giganta I'm working on the kubernetes project for a little more",
    "start": "7440",
    "end": "13530"
  },
  {
    "text": "than two years and I focus on scalability and performance aspects of the project and I'm an active member of",
    "start": "13530",
    "end": "20070"
  },
  {
    "text": "the six scalability some of you would know me by that github or slack handle",
    "start": "20070",
    "end": "25640"
  },
  {
    "text": "and maybe as some folks are grabbing some seats a quick maybe demographics",
    "start": "25640",
    "end": "32700"
  },
  {
    "text": "check who in the room is a user of kubernetes and you're running your own clusters okay so looks like half at",
    "start": "32700",
    "end": "40860"
  },
  {
    "text": "least and who among you is running clusters of 1,000 nodes or more okay and",
    "start": "40860",
    "end": "49050"
  },
  {
    "text": "2,000 anyone are just two hands so 3,000",
    "start": "49050",
    "end": "55340"
  },
  {
    "text": "for now okay anyone among those of you who did not raise your hands is anyone",
    "start": "55340",
    "end": "61739"
  },
  {
    "text": "considering it or planning that you run such large workloads in the future that's actually more than I expected",
    "start": "61739",
    "end": "68790"
  },
  {
    "text": "oh if you want it to be great if you could also network a bit then after the session but now it's maybe then moved to",
    "start": "68790",
    "end": "75930"
  },
  {
    "text": "two what we prepared to do today for you of sham so we will be talking about scalability of kubernetes and we will",
    "start": "75930",
    "end": "83400"
  },
  {
    "text": "cover how you should think about it and what are the current limits and then what does it actually mean for you so",
    "start": "83400",
    "end": "90270"
  },
  {
    "text": "first maybe with a little bit of background why why we prepared this why",
    "start": "90270",
    "end": "95700"
  },
  {
    "text": "we prepared this material so we are getting quite a lot of questions from the community from developers from users",
    "start": "95700",
    "end": "102750"
  },
  {
    "text": "of kubernetes on what does it actually mean that kubernetes scales was the definition of scalability in the context",
    "start": "102750",
    "end": "108450"
  },
  {
    "text": "of this product what are the limits why even though I'm running our a cluster",
    "start": "108450",
    "end": "114180"
  },
  {
    "text": "that is smaller than 5,000 nodes I'm still hitting scalability limits and why workloads that are very similar to",
    "start": "114180",
    "end": "122399"
  },
  {
    "text": "mine are not actually part of testing of of from scallop scalability perspective",
    "start": "122399",
    "end": "128580"
  },
  {
    "text": "and to respond to these questions and also many other that we had",
    "start": "128580",
    "end": "133860"
  },
  {
    "text": "we ran a study to understand and document how kubernetes behaves when you",
    "start": "133860",
    "end": "139920"
  },
  {
    "text": "push its scale to the limits and give some guidance to to folks on how they",
    "start": "139920",
    "end": "145560"
  },
  {
    "text": "should work with large-scale kubernetes configurations so we documented the",
    "start": "145560",
    "end": "154050"
  },
  {
    "text": "outcomes of this study we consolidated it we've also some experience and and",
    "start": "154050",
    "end": "159180"
  },
  {
    "text": "the work that we did before and with kubernetes users and with development of",
    "start": "159180",
    "end": "164700"
  },
  {
    "text": "the product and through this presentation we would like to explain to",
    "start": "164700",
    "end": "170160"
  },
  {
    "text": "you how how you should model scalable scalable kubernetes configurations from scalability perspective how to think",
    "start": "170160",
    "end": "176610"
  },
  {
    "text": "about it how to plan your architecture how to think about it from your features development perspective and we will",
    "start": "176610",
    "end": "184739"
  },
  {
    "text": "describe to you what are the current known limits of scalability of kubernetes and I will also give you some",
    "start": "184739",
    "end": "192150"
  },
  {
    "text": "additional guidance on how you should interact with the six scalability and",
    "start": "192150",
    "end": "197459"
  },
  {
    "text": "how to go about these limits and how to push them forward and expand them so",
    "start": "197459",
    "end": "203280"
  },
  {
    "text": "maybe first let's talk what does it actually mean that kubernetes scales and",
    "start": "203280",
    "end": "208890"
  },
  {
    "text": "how to define it so first important misconception is that it's a single",
    "start": "208890",
    "end": "214140"
  },
  {
    "text": "number so it's not we very frequently in our materials and in the conversations we're using the number of nodes as a",
    "start": "214140",
    "end": "220920"
  },
  {
    "text": "proxy or a simplification of the scale and complexity of your cluster and in",
    "start": "220920",
    "end": "227190"
  },
  {
    "text": "many cases actually does good enough so if you fit into this range you will not",
    "start": "227190",
    "end": "232290"
  },
  {
    "text": "run into trouble but there are situations when it's actually not a detailed enough definition of",
    "start": "232290",
    "end": "237780"
  },
  {
    "text": "scalability of kubernetes and you need to double click into it and get to the next level of complexity of description",
    "start": "237780",
    "end": "245400"
  },
  {
    "text": "of your configuration to make sure that you're not pushing yourself pushing your",
    "start": "245400",
    "end": "251340"
  },
  {
    "text": "cluster and your workloads beyond the elements of what current equivalences can do so a better way to think about",
    "start": "251340",
    "end": "260549"
  },
  {
    "text": "scalability of kubernetes is that within all possible configurations",
    "start": "260549",
    "end": "265680"
  },
  {
    "text": "of your cluster there is a cube which wraps an envelope of those configurations which will offer you good",
    "start": "265680",
    "end": "272759"
  },
  {
    "text": "stability and good performance and as long as you are within that enveloped within the limits of scalability on on",
    "start": "272759",
    "end": "279630"
  },
  {
    "text": "multiple dimensions you are safe you can say that you are within the scalability",
    "start": "279630",
    "end": "285810"
  },
  {
    "text": "limits and you will not run into any trouble neither from performance perspective not from stability of the",
    "start": "285810",
    "end": "292860"
  },
  {
    "text": "cluster one may be note the example the dimensions that we're showing here on",
    "start": "292860",
    "end": "300000"
  },
  {
    "text": "the slide these are examples it's not an exhaustive list in the next slides we'll talk a bit more about how to think about",
    "start": "300000",
    "end": "306660"
  },
  {
    "text": "them and which ones are most relevant that you should consider when architecting or developing features yeah",
    "start": "306660",
    "end": "316800"
  },
  {
    "text": "so first let's spend a couple of minutes talking what are the properties of this",
    "start": "316800",
    "end": "322860"
  },
  {
    "text": "envelope and of this cube that defines scalability limits of kubernetes so",
    "start": "322860",
    "end": "328199"
  },
  {
    "text": "first it's not actually a cube by that we mean that the dimensions that",
    "start": "328199",
    "end": "333380"
  },
  {
    "text": "describe your configuration they are not independent and you may run into a",
    "start": "333380",
    "end": "339570"
  },
  {
    "text": "situation that if on one dimension you have a limit a on another dimension you have a limit B and you max out on both",
    "start": "339570",
    "end": "347610"
  },
  {
    "text": "of those dimensions with your configuration then it's probable that your cluster will be already outside of",
    "start": "347610",
    "end": "354659"
  },
  {
    "text": "the scalability envelope and you will you might run them into trouble even",
    "start": "354659",
    "end": "360240"
  },
  {
    "text": "more the shape of the envelope is not convex so taking a more conservative",
    "start": "360240",
    "end": "365550"
  },
  {
    "text": "approach and going for averages of a and B so that you stick somewhat in the",
    "start": "365550",
    "end": "372360"
  },
  {
    "text": "middle on both of these dimensions still might take you outside of outside of the",
    "start": "372360",
    "end": "377849"
  },
  {
    "text": "envelope and you will breach the scalability limits of of kubernetes next",
    "start": "377849",
    "end": "386550"
  },
  {
    "text": "property now we have it so and the next property that is very important for you",
    "start": "386550",
    "end": "392699"
  },
  {
    "text": "to take into consideration when especially when designing systems that run on kubernetes is the fact that this",
    "start": "392699",
    "end": "398639"
  },
  {
    "text": "envelope tapirs as you stretch it on each of these dimensions so if you should be",
    "start": "398639",
    "end": "405060"
  },
  {
    "text": "very cautious in pushing kubernetes into its limits on too many dimensions at the same time this leads to situations so",
    "start": "405060",
    "end": "413460"
  },
  {
    "text": "the way that you should think about it is that if you for example run a 5000",
    "start": "413460",
    "end": "418830"
  },
  {
    "text": "old cluster you will have less freedom and less space for for your scale on",
    "start": "418830",
    "end": "425130"
  },
  {
    "text": "other dimensions that describe kubernetes and at the same time it actually might mean and it is more",
    "start": "425130",
    "end": "431669"
  },
  {
    "text": "surprising to many folks that run work on some communities even on very small clusters like five nodes if you stretch",
    "start": "431669",
    "end": "437370"
  },
  {
    "text": "on other dimensions like for example the number of pods by node you might run into scale problems - thanks man check",
    "start": "437370",
    "end": "448490"
  },
  {
    "text": "so the next property is about the boundedness of this envelope so what",
    "start": "448490",
    "end": "454289"
  },
  {
    "text": "that really means is you cannot push arbitrarily on any given dimension even",
    "start": "454289",
    "end": "460530"
  },
  {
    "text": "if you keep all the other dimensions at the minimum and the reason for this is primarily a limit on the size of HCD and",
    "start": "460530",
    "end": "468570"
  },
  {
    "text": "typically when you're trying to push along some particular dimension you are increasing the HDD space usage so we",
    "start": "468570",
    "end": "479550"
  },
  {
    "text": "came up with this really crude estimate for the number of objects that can be in",
    "start": "479550",
    "end": "485010"
  },
  {
    "text": "a city assuming the size of add CDs 4gb and that estimate is 300 thousand objects which includes both your built",
    "start": "485010",
    "end": "492780"
  },
  {
    "text": "in API objects and C IDs but it's a really crude estimate in the reason why I say that is it does not account for",
    "start": "492780",
    "end": "500419"
  },
  {
    "text": "factors like the sizes of these objects and also how many revisions of these objects exist which can significantly",
    "start": "500419",
    "end": "507180"
  },
  {
    "text": "affect D your at CD space usage but you can use this as a simplistic idea Thanks",
    "start": "507180",
    "end": "520990"
  },
  {
    "text": "so the final and my most favorite property is about the decomposability of this envelope some of you might have",
    "start": "520990",
    "end": "528910"
  },
  {
    "text": "figured out by now that the number of phases of this envelope is exponential",
    "start": "528910",
    "end": "533950"
  },
  {
    "text": "in the number of dimensions which makes it really hard to compute all of those",
    "start": "533950",
    "end": "539140"
  },
  {
    "text": "phases but fortunately there is a good amount of Independence between groups of",
    "start": "539140",
    "end": "545140"
  },
  {
    "text": "these dimensions which lets us break this down into smaller lower dimensional envelopes and each of those small",
    "start": "545140",
    "end": "553150"
  },
  {
    "text": "envelopes is going to represent some kind of a constraint in our system",
    "start": "553150",
    "end": "558960"
  },
  {
    "text": "before so yeah so we go ahead and look at some of the small envelopes",
    "start": "558960",
    "end": "566760"
  },
  {
    "text": "especially like for Cuba notice but I don't make a few things clear before we",
    "start": "566760",
    "end": "573340"
  },
  {
    "text": "actually look into those limits the first thing is that we are going to do the limits are we're going to talk about",
    "start": "573340",
    "end": "579190"
  },
  {
    "text": "here are purely specific to Cuban interest control plane so these do not",
    "start": "579190",
    "end": "584470"
  },
  {
    "text": "have anything to do with the cloud provider these come basically out of the",
    "start": "584470",
    "end": "589990"
  },
  {
    "text": "kubernetes design there may be some limits that come from the underlying infrastructure of your cluster but here",
    "start": "589990",
    "end": "596290"
  },
  {
    "text": "we are going to only talk about the kubernetes plane limits and these limits",
    "start": "596290",
    "end": "602890"
  },
  {
    "text": "don't form an exhaustive list these are just the ones we've discovered so far so",
    "start": "602890",
    "end": "608680"
  },
  {
    "text": "this will likely change over time and also they they they basically form a",
    "start": "608680",
    "end": "614650"
  },
  {
    "text": "rough sketch of what is our idea of safe",
    "start": "614650",
    "end": "620490"
  },
  {
    "text": "configurations and this is based on primarily scalability tests that six scalability has been doing in some of",
    "start": "620490",
    "end": "626320"
  },
  {
    "text": "the user cases in practice you may be able to actually push beyond some of",
    "start": "626320",
    "end": "632290"
  },
  {
    "text": "these limits we try to be conservative at a few places and we're making recommendations based on based on things",
    "start": "632290",
    "end": "638380"
  },
  {
    "text": "that you've tested on upstream officially but you may be actually be able to push beyond these limits and",
    "start": "638380",
    "end": "644230"
  },
  {
    "text": "even it's possible that within these limits by doing some really peculiar things",
    "start": "644230",
    "end": "649450"
  },
  {
    "text": "or some different kinds of configurations you can screw up so in general like use discretion and if you",
    "start": "649450",
    "end": "655900"
  },
  {
    "text": "have any questions like please feel free to reach out to us six scalability is",
    "start": "655900",
    "end": "660970"
  },
  {
    "text": "very happy to answer such questions so",
    "start": "660970",
    "end": "667030"
  },
  {
    "text": "the next limit or the first limit is actually the number of nodes versus the",
    "start": "667030",
    "end": "673210"
  },
  {
    "text": "number of parts that you can put on a node which a lot of you may also call a spot density and you see on the screen",
    "start": "673210",
    "end": "681600"
  },
  {
    "text": "graph and there is a green shaded region which basically represents our scalability envelope and it's bounded by",
    "start": "681600",
    "end": "689020"
  },
  {
    "text": "three limits there is a limit on the x-axis there is a limit on the y-axis",
    "start": "689020",
    "end": "694960"
  },
  {
    "text": "and there is a limit which is a function of the X and the y-axis which in this",
    "start": "694960",
    "end": "700510"
  },
  {
    "text": "case is the curve that you can see now let's talk about each of these limits",
    "start": "700510",
    "end": "706720"
  },
  {
    "text": "individually so the first one is the limit on the x-axis of five thousand third you can see for the number of",
    "start": "706720",
    "end": "712480"
  },
  {
    "text": "nodes and this is the officially tested limit and this is what we test for in",
    "start": "712480",
    "end": "717610"
  },
  {
    "text": "upstream kubernetes for every release as part of six scalability validation",
    "start": "717610",
    "end": "723190"
  },
  {
    "text": "process that we do so you might want to",
    "start": "723190",
    "end": "729010"
  },
  {
    "text": "go beyond this but then I'm part of some experiments where people try to push",
    "start": "729010",
    "end": "736060"
  },
  {
    "text": "further beyond this but this is what we officially recommend us this is what we test for and yeah it's also mentioned in",
    "start": "736060",
    "end": "743980"
  },
  {
    "text": "the official Cuban it is documentation now the limit on the y-axis which is the",
    "start": "743980",
    "end": "749290"
  },
  {
    "text": "number of pods per node is 110 this again is an official limit and something",
    "start": "749290",
    "end": "754300"
  },
  {
    "text": "with scale test for also by default in Cuban it is cubelets are provided with a",
    "start": "754300",
    "end": "760000"
  },
  {
    "text": "max pods argument of 110 which doesn't let you start more than these if you try",
    "start": "760000",
    "end": "765190"
  },
  {
    "text": "it to go further beyond this you can run more number of pods on your node then",
    "start": "765190",
    "end": "770620"
  },
  {
    "text": "the load on your cubelet and docker is going to increase and their responsiveness can fall down the third",
    "start": "770620",
    "end": "780100"
  },
  {
    "text": "limit which is the curve which in this case is basically a product of the X and",
    "start": "780100",
    "end": "785860"
  },
  {
    "text": "y-axis which gives you the total number of pods across your cluster is limited",
    "start": "785860",
    "end": "792670"
  },
  {
    "text": "to 150,000 parts which is again something we have scaled tested for and",
    "start": "792670",
    "end": "798930"
  },
  {
    "text": "the reason we keep it down to the limit and don't go further is as you as you",
    "start": "798930",
    "end": "804310"
  },
  {
    "text": "try to create more and more number of pods you are likely going to increase the load on the API server and at CD",
    "start": "804310",
    "end": "810820"
  },
  {
    "text": "you're going to create a lot of activity in the cluster which can overload your master there's a note I want to make",
    "start": "810820",
    "end": "817420"
  },
  {
    "text": "here that the limit one I said then a number of cards as 110 per node you need",
    "start": "817420",
    "end": "824320"
  },
  {
    "text": "to keep in mind that you there is an assumption that the number of containers",
    "start": "824320",
    "end": "829360"
  },
  {
    "text": "that you can have in a pod is not too high so it's not more than 2 on an average because if you have too many",
    "start": "829360",
    "end": "837010"
  },
  {
    "text": "containers that can also create issues because there is some fixed amount of cost that cubelet and docker have to",
    "start": "837010",
    "end": "842080"
  },
  {
    "text": "bear for a container and that rises so let's go to the next limit this one is",
    "start": "842080",
    "end": "849700"
  },
  {
    "text": "about the number of services versus the size of your services which is typically",
    "start": "849700",
    "end": "856330"
  },
  {
    "text": "the number of pods that are there in your service here also you see a very similar kind of a limit the similar",
    "start": "856330",
    "end": "863350"
  },
  {
    "text": "pattern of a limit on the x-axis is a limit on the y-axis and a limit on the function of X and y-axis so here we're",
    "start": "863350",
    "end": "871690"
  },
  {
    "text": "going to talk about cluster IP services and I'm not going to step into the",
    "start": "871690",
    "end": "876760"
  },
  {
    "text": "domain of cloud provider based load balancers because that is like I said",
    "start": "876760",
    "end": "882220"
  },
  {
    "text": "earlier something cloud provider dependent and can change from provider to provider some feeling holistic to the",
    "start": "882220",
    "end": "887650"
  },
  {
    "text": "internal service load balancing mechanism in kubernetes now you can see",
    "start": "887650",
    "end": "893470"
  },
  {
    "text": "that there's a limit of 10000 services on the x-axis this is again something we've tested for in in fix scalability",
    "start": "893470",
    "end": "902200"
  },
  {
    "text": "as part of our upstream Kuban it is scale testing this limit mainly arises",
    "start": "902200",
    "end": "908710"
  },
  {
    "text": "because of IP tables whenever you add a new service when you create a new service",
    "start": "908710",
    "end": "914339"
  },
  {
    "text": "you add a rule to the cube SVC iptables chain and this means that when you have",
    "start": "914339",
    "end": "920999"
  },
  {
    "text": "too many services the size of this chain increases which affects your iptables",
    "start": "920999",
    "end": "926970"
  },
  {
    "text": "performance in two ways the first is basically the performance of iptables operations themselves which is IPTA will",
    "start": "926970",
    "end": "933749"
  },
  {
    "text": "save and restores it takes more time to do those operations when the strain",
    "start": "933749",
    "end": "939089"
  },
  {
    "text": "increases and the second is packet routing performance which also falls down for IP tables with as there are",
    "start": "939089",
    "end": "945449"
  },
  {
    "text": "more number of rules to evaluate so 10000 is something which is a good",
    "start": "945449",
    "end": "952050"
  },
  {
    "text": "estimate for this limit and the limit on the y-axis of 250 that you can see for",
    "start": "952050",
    "end": "960839"
  },
  {
    "text": "the size of the service arises due to the fact that endpoints the way it is",
    "start": "960839",
    "end": "968370"
  },
  {
    "text": "designed in cuba it is currently the endpoints API is quadratic in the number of endpoints so whenever you add a new",
    "start": "968370",
    "end": "975300"
  },
  {
    "text": "part to a service you're going to recalculate the whole endpoint object for the service add a new or new IP",
    "start": "975300",
    "end": "981839"
  },
  {
    "text": "entry to this object and then post it over to all your queue proxies so this really creates a very quadratic kind of",
    "start": "981839",
    "end": "989069"
  },
  {
    "text": "traffic so it's we recommend to not have too big services because then your",
    "start": "989069",
    "end": "995100"
  },
  {
    "text": "control plane can get all ordered because of endpoints traffic but again this is not a hard limit 250 is not a",
    "start": "995100",
    "end": "1001220"
  },
  {
    "text": "hard limit you can try to push further but just make sure that if you are",
    "start": "1001220",
    "end": "1006379"
  },
  {
    "text": "trying to create too many services which are big try to have fewer number of I",
    "start": "1006379",
    "end": "1011420"
  },
  {
    "text": "mean when you're trying to create services that are bigger than this try to have fewer number of those services",
    "start": "1011420",
    "end": "1017629"
  },
  {
    "text": "so you can see a configuration on on a node that I mentioned on the right side",
    "start": "1017629",
    "end": "1022939"
  },
  {
    "text": "which is a configuration we have tested for so what we do is we test with a really large number of backends but we",
    "start": "1022939",
    "end": "1030350"
  },
  {
    "text": "have majority of those backends as part of small services a few of them which are part of medium services and a very",
    "start": "1030350",
    "end": "1036890"
  },
  {
    "text": "few of them which are part of large services so this is something which kind of works well in practice so yeah that's",
    "start": "1036890",
    "end": "1045288"
  },
  {
    "text": "basically okay sure what do you mean you mean IPPs",
    "start": "1045289",
    "end": "1058590"
  },
  {
    "text": "okay so that's a really interesting question can I get back to that towards the end of the session because I really",
    "start": "1058590",
    "end": "1064389"
  },
  {
    "text": "want to talk about that so so yeah the next limit is about the number of",
    "start": "1064389",
    "end": "1070450"
  },
  {
    "text": "services you can have per namespace here you can see that on the y-axis you don't",
    "start": "1070450",
    "end": "1076960"
  },
  {
    "text": "actually have any limit because you can just have as many number of namespaces that you want but the more important one",
    "start": "1076960",
    "end": "1082870"
  },
  {
    "text": "is the limit on the x-axis of 5,000 services per namespace and the reason for this is that in kubernetes whenever",
    "start": "1082870",
    "end": "1091480"
  },
  {
    "text": "you create a pod in a namespace as part of the downstream API you populate the",
    "start": "1091480",
    "end": "1096610"
  },
  {
    "text": "pod with a bunch of environmental variables for every single service that has been created in that namespace and",
    "start": "1096610",
    "end": "1103840"
  },
  {
    "text": "when you go beyond a threshold which is 5,000 the part starts to crash because",
    "start": "1103840",
    "end": "1110260"
  },
  {
    "text": "the kernel cannot load the process into memory because there's just not enough space in the buffer for the process",
    "start": "1110260",
    "end": "1117010"
  },
  {
    "text": "which holds environment variables so you want to make sure that this is satisfied",
    "start": "1117010",
    "end": "1122169"
  },
  {
    "text": "and if I am NOT wrong like in Cuban it is released 1.13 we",
    "start": "1122169",
    "end": "1129669"
  },
  {
    "text": "have a change which makes it possible to have service linked environment",
    "start": "1129669",
    "end": "1134799"
  },
  {
    "text": "variables optional so you can mention it in your pod spec and say that please don't mount my pod with environmental",
    "start": "1134799",
    "end": "1140590"
  },
  {
    "text": "variables which which kind of gets us over this limitation and and the curve",
    "start": "1140590",
    "end": "1146529"
  },
  {
    "text": "that you see is basically just the product of both which is the total number of services and that we already saw here has to be limited to less than",
    "start": "1146529",
    "end": "1153070"
  },
  {
    "text": "10,000 fortune this is something which",
    "start": "1153070",
    "end": "1160299"
  },
  {
    "text": "has been asked or again and again by so many people and so many users are",
    "start": "1160299",
    "end": "1165669"
  },
  {
    "text": "interested in this metric so soap or churn is defined as the total or the",
    "start": "1165669",
    "end": "1173889"
  },
  {
    "text": "number of pod creates update or deletes that you can do a second and in Cuban it is we by",
    "start": "1173889",
    "end": "1181070"
  },
  {
    "text": "default limit this to 20 per second and the reason why that limit arises is",
    "start": "1181070",
    "end": "1186559"
  },
  {
    "text": "basically a limit on the QPS for the controller manager so the controller",
    "start": "1186559",
    "end": "1193640"
  },
  {
    "text": "manager by default cannot make more than 20 calls to the API server per second which basically limits your controllers",
    "start": "1193640",
    "end": "1200179"
  },
  {
    "text": "that that take care of these create update and delete operations but there",
    "start": "1200179",
    "end": "1206330"
  },
  {
    "text": "are a few caveats based on which you can kind of go above or below this threshold",
    "start": "1206330",
    "end": "1211549"
  },
  {
    "text": "I just mention a few here so for instance if you're going to create parts manually which I don't think is a very",
    "start": "1211549",
    "end": "1219580"
  },
  {
    "text": "common use case but if you're going to do that then you basically bypass the controller manager and you can have a",
    "start": "1219580",
    "end": "1225350"
  },
  {
    "text": "very high rate of pod creations and for",
    "start": "1225350",
    "end": "1230660"
  },
  {
    "text": "deletions if you're going to depend on the Kuban it is garbage collector to delete your orphan parts then you",
    "start": "1230660",
    "end": "1236960"
  },
  {
    "text": "actually don't have even a lower limit of ten per second because the way the garbage collector works right now in",
    "start": "1236960",
    "end": "1243440"
  },
  {
    "text": "cuban itis is it makes two API calls for deleting a single object so that basically means you can only achieve a",
    "start": "1243440",
    "end": "1251000"
  },
  {
    "text": "throughput of ten per second for deletes and in general when like I said earlier",
    "start": "1251000",
    "end": "1256160"
  },
  {
    "text": "if you have pods that are part of really big services then pod shown can create a",
    "start": "1256160",
    "end": "1262130"
  },
  {
    "text": "lot of endpoints traffic because of this massive endpoints objects and that can",
    "start": "1262130",
    "end": "1267260"
  },
  {
    "text": "overload your control plane and as a result you may not actually be able to achieve the churn of 20 per second",
    "start": "1267260",
    "end": "1275210"
  },
  {
    "text": "safely yeah so this limit is about the",
    "start": "1275210",
    "end": "1283520"
  },
  {
    "text": "number of nodes versus the number of conflicts you can have per node so the",
    "start": "1283520",
    "end": "1289250"
  },
  {
    "text": "number of conflicts that per node is basically the total number of secrets",
    "start": "1289250",
    "end": "1295190"
  },
  {
    "text": "and config maps that a node needs in order to be able to start its bottles so",
    "start": "1295190",
    "end": "1301309"
  },
  {
    "text": "the way it works until release 1.11 is cubelet periodically goes and fetches",
    "start": "1301309",
    "end": "1308720"
  },
  {
    "text": "these conflicts and secret Maps yeah so so here the limit on the",
    "start": "1308720",
    "end": "1318050"
  },
  {
    "text": "x-axis of 5,000 nodes or something already talked about before the limit on",
    "start": "1318050",
    "end": "1323630"
  },
  {
    "text": "the y-axis is interesting so we say that the number of conflicts per node can be more than 200 and this limit is",
    "start": "1323630",
    "end": "1330350"
  },
  {
    "text": "basically because of cubelets api QPS limitation and cubelet by default is",
    "start": "1330350",
    "end": "1337280"
  },
  {
    "text": "configured to not have more than this QPS so it makes it hard for it to",
    "start": "1337280",
    "end": "1342470"
  },
  {
    "text": "refresh periodically the secrets and config maps because it has to mean get calls to the API server the the curve",
    "start": "1342470",
    "end": "1349930"
  },
  {
    "text": "here represents the product of both which basically is the aggregate number",
    "start": "1349930",
    "end": "1357560"
  },
  {
    "text": "of conflicts that are needed across all your nodes and this we limit to 150,000",
    "start": "1357560",
    "end": "1364850"
  },
  {
    "text": "the reason being that just now the thing that I told you that cubelet needs to",
    "start": "1364850",
    "end": "1369860"
  },
  {
    "text": "make periodic calls and the bulk of these get secrets and concept map calls",
    "start": "1369860",
    "end": "1376400"
  },
  {
    "text": "in your cluster becomes so big that your or that your master can get overloaded",
    "start": "1376400",
    "end": "1381470"
  },
  {
    "text": "because of this so luckily the good news is this limitation does not exist",
    "start": "1381470",
    "end": "1388280"
  },
  {
    "text": "anymore starting from release 1.12 the reason is because we moved cubelet from periodically poling conflicts to",
    "start": "1388280",
    "end": "1395240"
  },
  {
    "text": "watching them and watching is much lightweight as compared to polling and",
    "start": "1395240",
    "end": "1400430"
  },
  {
    "text": "it's kind of a design principle for cuban industry how watching wherever possible instead of polling but if",
    "start": "1400430",
    "end": "1407270"
  },
  {
    "text": "you're running a cluster that's below one point twelve up until one point eleven and you want to mitigate this",
    "start": "1407270",
    "end": "1413290"
  },
  {
    "text": "limitation to some extent you can try to co-locate your pods similar pods onto",
    "start": "1413290",
    "end": "1419210"
  },
  {
    "text": "fewer nodes so that only if you are notes need-need those conflicts and secrets or another recommendation is to",
    "start": "1419210",
    "end": "1427370"
  },
  {
    "text": "turn off the default service account token mounting for your pod this is",
    "start": "1427370",
    "end": "1433310"
  },
  {
    "text": "basically the default in cuban it is that the pod is mounted with the secret",
    "start": "1433310",
    "end": "1438590"
  },
  {
    "text": "corresponding to the namespaces identity so that it's able to talk to the api server",
    "start": "1438590",
    "end": "1444169"
  },
  {
    "text": "which basically adds one extra secret for a part and it basically affects the cement so if possible you don't if your",
    "start": "1444169",
    "end": "1451190"
  },
  {
    "text": "parts don't need namespace spaced identity or they don't need to talk to the API server then consider turning",
    "start": "1451190",
    "end": "1457039"
  },
  {
    "text": "this off totally",
    "start": "1457039",
    "end": "1460358"
  },
  {
    "text": "so the question is what is the limit for the cubelet QPS in 1.11 or before I",
    "start": "1470380",
    "end": "1476850"
  },
  {
    "text": "believe the limit is 200 or actually you",
    "start": "1476850",
    "end": "1483310"
  },
  {
    "text": "know I think it's 5 which is per second and this basically shows per midnight",
    "start": "1483310",
    "end": "1488410"
  },
  {
    "text": "refresh rate I think it's five but like I need to check that I'm 100% sure looks",
    "start": "1488410",
    "end": "1495010"
  },
  {
    "text": "like so this limit is across the number",
    "start": "1495010",
    "end": "1500800"
  },
  {
    "text": "of namespaces versus the number of parts you can have power namespace the limit",
    "start": "1500800",
    "end": "1505840"
  },
  {
    "text": "on the x-axis of 10000 namespaces arises basically because of what I've just talked about earlier that pods are",
    "start": "1505840",
    "end": "1513760"
  },
  {
    "text": "mounted with namespace secrets and that increases the get secrets traffic but",
    "start": "1513760",
    "end": "1519160"
  },
  {
    "text": "again because cubed into watching secrets this limit on the x-axis doesn't exist anymore starting from the least",
    "start": "1519160",
    "end": "1525790"
  },
  {
    "text": "one point 12 the interesting limit which is the y-axis limit of 3,000 pods",
    "start": "1525790",
    "end": "1533200"
  },
  {
    "text": "pertinent space it is not a hard limit it is something we've empirically",
    "start": "1533200",
    "end": "1538540"
  },
  {
    "text": "observed in our scalability tests that as you have more and more number of pods in your namespace the responsiveness of",
    "start": "1538540",
    "end": "1545800"
  },
  {
    "text": "your controllers can go down because a lot of reconciliation loops in controllers depend go through all the",
    "start": "1545800",
    "end": "1552430"
  },
  {
    "text": "parts of a particular namespace which can kind of make things a bit slower so this is a recommendation you probably",
    "start": "1552430",
    "end": "1559180"
  },
  {
    "text": "can go higher or you like he can go higher than this but if possible try to",
    "start": "1559180",
    "end": "1564490"
  },
  {
    "text": "break your pods into multiple namespaces yeah and the curve which is the product",
    "start": "1564490",
    "end": "1572530"
  },
  {
    "text": "of both which is the total number of points is limited 250,000 this is what we talked about earlier already let's go",
    "start": "1572530",
    "end": "1579460"
  },
  {
    "text": "to the next limit oh that's awesome so with so one thing I want to say is like",
    "start": "1579460",
    "end": "1585850"
  },
  {
    "text": "with with the knowledge of with a better perspective of what scalability really",
    "start": "1585850",
    "end": "1591550"
  },
  {
    "text": "is and with the knowledge of these limits we hope that you should be able",
    "start": "1591550",
    "end": "1596620"
  },
  {
    "text": "to make more informed choices while architecting your work yards but if you",
    "start": "1596620",
    "end": "1601780"
  },
  {
    "text": "have any questions like you can always to us and just to add to what Shyam said",
    "start": "1601780",
    "end": "1607950"
  },
  {
    "text": "a couple of remarks in terms of workouts for you one is that if you are",
    "start": "1607950",
    "end": "1616220"
  },
  {
    "text": "kubernetes developer and you're building feature features and improvements please",
    "start": "1616220",
    "end": "1621330"
  },
  {
    "text": "make sure that you test them from scalability perspective on six site on github you can find instructions in the",
    "start": "1621330",
    "end": "1627600"
  },
  {
    "text": "whole process how to go about it and how to test and which tests to use well",
    "start": "1627600",
    "end": "1633080"
  },
  {
    "text": "scalability is a horizontal concept so it's not in the hands of a single",
    "start": "1633409",
    "end": "1639210"
  },
  {
    "text": "special interest group to make sure that kubernetes scales it is in the it it is",
    "start": "1639210",
    "end": "1644879"
  },
  {
    "text": "a topic for all of the teams working on improvements both to make sure that you maintain the existing scalability and",
    "start": "1644879",
    "end": "1651299"
  },
  {
    "text": "that we push the limits further secondly if you are covering this user please",
    "start": "1651299",
    "end": "1656549"
  },
  {
    "text": "make sure that you account for its scalability tests in your projects when you're architecting your infrastructure",
    "start": "1656549",
    "end": "1662970"
  },
  {
    "text": "and your systems this is because you may have certain specific aspects of your",
    "start": "1662970",
    "end": "1670230"
  },
  {
    "text": "configuration that will change the shape of this envelope there might be topics associated with your specific",
    "start": "1670230",
    "end": "1675929"
  },
  {
    "text": "infrastructure and networking security and other that may be affecting your the",
    "start": "1675929",
    "end": "1681269"
  },
  {
    "text": "scalability limits that would apply to your specific system so please make sure that you test it and further is that",
    "start": "1681269",
    "end": "1688499"
  },
  {
    "text": "please stay in touch with us with the whole team or human scalability we need",
    "start": "1688499",
    "end": "1694619"
  },
  {
    "text": "both engaged developers who are building features who would collaborate with six",
    "start": "1694619",
    "end": "1700619"
  },
  {
    "text": "scalability to make sure that limits are maintained and expanded and maybe even more importantly we need users who want",
    "start": "1700619",
    "end": "1707399"
  },
  {
    "text": "to run workloads which are beyond the current scale ability envelope who would",
    "start": "1707399",
    "end": "1713429"
  },
  {
    "text": "be interested in collaborating with us in pushing those limits so on this slide",
    "start": "1713429",
    "end": "1719070"
  },
  {
    "text": "we put key contact channels to get in touch of us you can download the presentation from conferences website",
    "start": "1719070",
    "end": "1725549"
  },
  {
    "text": "and we'll be happy to take your questions or connect here in the room or later on in our booths thank you",
    "start": "1725549",
    "end": "1733080"
  },
  {
    "text": "[Applause]",
    "start": "1733080",
    "end": "1742460"
  },
  {
    "text": "okay someone had a question about IP vs oh yeah so yes we know ipbs performs",
    "start": "1743640",
    "end": "1753040"
  },
  {
    "text": "better than IP tables because it has a better implementation of these rules I",
    "start": "1753040",
    "end": "1758170"
  },
  {
    "text": "think it's based on hash tables but we aren't yet tested for IP V s for scale",
    "start": "1758170",
    "end": "1763630"
  },
  {
    "text": "testing but we do expect it to show a lot of improvement or the performance",
    "start": "1763630",
    "end": "1772260"
  },
  {
    "text": "that's a very good question so I don't have too much expertise in storage but I",
    "start": "1780420",
    "end": "1786280"
  },
  {
    "text": "can definitely connect with you with someone from the storage team there are some recommendations that I know of",
    "start": "1786280",
    "end": "1794110"
  },
  {
    "text": "storage which are like kind of way out for specific limits because like some",
    "start": "1794110",
    "end": "1799470"
  },
  {
    "text": "not on the committee's level I'm aware of none but like I'll maybe reach out to",
    "start": "1799470",
    "end": "1805480"
  },
  {
    "text": "you with someone from six storage okay",
    "start": "1805480",
    "end": "1815320"
  },
  {
    "text": "so the question is if I can explain the formula on the number summation of the",
    "start": "1815320",
    "end": "1821170"
  },
  {
    "text": "number of conflicts per node and the answer is yes I can explain and it is it",
    "start": "1821170",
    "end": "1828130"
  },
  {
    "text": "is it is basically the sum of the number of conflicts that each node needs across",
    "start": "1828130",
    "end": "1837250"
  },
  {
    "text": "all the nodes so node a needs some number of conflicts right some number of secrets and config maps for for the pods",
    "start": "1837250",
    "end": "1844060"
  },
  {
    "text": "that run on that node its summation of this across all your nodes in the cluster",
    "start": "1844060",
    "end": "1849000"
  },
  {
    "text": "yes it's not exactly the number of conflicts and used because like if there",
    "start": "1852309",
    "end": "1857540"
  },
  {
    "text": "are multiple pods needing the same conflict on multiple nodes then it's too repetitive so the question is what has",
    "start": "1857540",
    "end": "1880670"
  },
  {
    "text": "this been tested against no so this",
    "start": "1880670",
    "end": "1892520"
  },
  {
    "text": "wasn't run against all the wonders so a lot of our upstream testing as it stands",
    "start": "1892520",
    "end": "1898190"
  },
  {
    "text": "today has been done on GCE not GK on GCE",
    "start": "1898190",
    "end": "1903200"
  },
  {
    "text": "yeah majority of this was done on GC and so yeah it's on some parts of it are",
    "start": "1903200",
    "end": "1909500"
  },
  {
    "text": "done on Q mark which is kind of simulated kubernetes environment which",
    "start": "1909500",
    "end": "1914660"
  },
  {
    "text": "is kind of independent of",
    "start": "1914660",
    "end": "1918190"
  },
  {
    "text": "the coverage on AWS I've been involved",
    "start": "1934070",
    "end": "1940160"
  },
  {
    "text": "in and my team at Samsung we were one of",
    "start": "1940160",
    "end": "1947300"
  },
  {
    "text": "the first teams to be running a very",
    "start": "1947300",
    "end": "1953870"
  },
  {
    "text": "interesting we see that there are because of the different characteristics underlying the different routes abiders",
    "start": "1953870",
    "end": "1959570"
  },
  {
    "text": "you actually will find different different I think I think one six",
    "start": "1959570",
    "end": "1977000"
  },
  {
    "text": "scalability the six availability meetings every week and in general they",
    "start": "1977000",
    "end": "1986000"
  },
  {
    "text": "get six scalability were like really happy to take your contributions and your input if you have had some",
    "start": "1986000",
    "end": "1992090"
  },
  {
    "text": "experiences with some fear scalability tests on your own in your own production environment we are always happy to hear",
    "start": "1992090",
    "end": "1998540"
  },
  {
    "text": "about it and indeed we kind of seek manpower in this kink because it's kind",
    "start": "1998540",
    "end": "2003850"
  },
  {
    "text": "of very niche right now and because it",
    "start": "2003850",
    "end": "2010240"
  },
  {
    "text": "just doesn't scale - well that like a single sink is like testing for every",
    "start": "2010240",
    "end": "2015310"
  },
  {
    "text": "single feature across every single vertical so",
    "start": "2015310",
    "end": "2019620"
  },
  {
    "text": "so the question is are there some tests in the conformance suite that someone",
    "start": "2025480",
    "end": "2031750"
  },
  {
    "text": "can run as a vendor and I'm assuming it's in the context of scalability tests so the answer is right now we don't and",
    "start": "2031750",
    "end": "2037570"
  },
  {
    "text": "this is a discussion we've been having in the past with a bunch of people like if we should start involving scalability",
    "start": "2037570",
    "end": "2044799"
  },
  {
    "text": "test as part of the conformance suite this is an ongoing discussion yes yes oh",
    "start": "2044799",
    "end": "2056858"
  },
  {
    "text": "yeah thanks Bob so q mark like like I was saying earlier it's kind of simulated kubernetes cluster that you",
    "start": "2056859",
    "end": "2063760"
  },
  {
    "text": "can you can basically done a large simulated cluster on just a few nodes with the nodes node part of the cluster",
    "start": "2063760",
    "end": "2070570"
  },
  {
    "text": "hollowed out but your control plan being real it's something that you can test even locally",
    "start": "2070570",
    "end": "2078119"
  },
  {
    "text": "okay that's a very good question so the question is what are things that can be",
    "start": "2094650",
    "end": "2099970"
  },
  {
    "text": "what are some of the limits that can be improved or how they can be improved by throwing more resources at some",
    "start": "2099970",
    "end": "2106030"
  },
  {
    "text": "components it really depends on the limit the specific limit that you're talking about for instance the pod shown",
    "start": "2106030",
    "end": "2111610"
  },
  {
    "text": "that I was talking about it's a it's a QPS limit on controller so you can try to change the default of the controller",
    "start": "2111610",
    "end": "2116920"
  },
  {
    "text": "but you have to be careful about the resources your masters has because when you give it higher QPS there is more",
    "start": "2116920",
    "end": "2123430"
  },
  {
    "text": "stuff that's happening within the master so you also have to scale it vertically and there are other things like the",
    "start": "2123430",
    "end": "2129820"
  },
  {
    "text": "number of nodes if you want to increase it you probably it makes sense to vertically scale your control plane but",
    "start": "2129820",
    "end": "2137620"
  },
  {
    "text": "yeah in general the answer is a bit complicated and it depends on the particular limit in question but QPS",
    "start": "2137620",
    "end": "2146290"
  },
  {
    "text": "queries per second so it's basically the limit on the q- components to talk to the API server",
    "start": "2146290",
    "end": "2153810"
  },
  {
    "text": "okay okay so just to repeat the question",
    "start": "2163470",
    "end": "2190450"
  },
  {
    "text": "the question is if we have some kind of knowledge or have we tested anything",
    "start": "2190450",
    "end": "2196090"
  },
  {
    "text": "with scalability of cron jobs no we haven't really done that like yeah but I",
    "start": "2196090",
    "end": "2201610"
  },
  {
    "text": "am not surprised by the thing you say about having too many cron jobs can affect your controllers because of too",
    "start": "2201610",
    "end": "2209020"
  },
  {
    "text": "many calls but if you are doing some testing with cron jobs like please reach",
    "start": "2209020",
    "end": "2214119"
  },
  {
    "text": "out to us and tell us any limits let you discover if you want to have a common knowledge of scalability okay so the",
    "start": "2214119",
    "end": "2227470"
  },
  {
    "text": "question is if there are a lot of conflict maps that have become stale over time and they haven't been cleaned",
    "start": "2227470",
    "end": "2232540"
  },
  {
    "text": "up does that affect performance the answer is if they are stale and not",
    "start": "2232540",
    "end": "2237790"
  },
  {
    "text": "really being used by anyone they just lie around wasting get CD space but otherwise they they shouldn't really",
    "start": "2237790",
    "end": "2244300"
  },
  {
    "text": "affect performance so the question is if",
    "start": "2244300",
    "end": "2253810"
  },
  {
    "text": "I can tell anything more about the master configuration used for these scale tests so there is a resource on",
    "start": "2253810",
    "end": "2263410"
  },
  {
    "text": "the community repository under six scalability which talks about the recommended configurations for our scale",
    "start": "2263410",
    "end": "2270700"
  },
  {
    "text": "tests but I believe these particular limits have been tested with 64 cores",
    "start": "2270700",
    "end": "2276010"
  },
  {
    "text": "and of something more than 100 gigs of memory and per master yeah so I'm",
    "start": "2276010",
    "end": "2286300"
  },
  {
    "text": "talking the master by the way sorry so the this testing was done both with",
    "start": "2286300",
    "end": "2292369"
  },
  {
    "text": "the single master and under H a which is three postures yes the number of parts",
    "start": "2292369",
    "end": "2304910"
  },
  {
    "text": "per node the question is the number of parts per node was that independent of",
    "start": "2304910",
    "end": "2309980"
  },
  {
    "text": "hardware so what hardware you're talking about don't do anything that is like",
    "start": "2309980",
    "end": "2333799"
  },
  {
    "text": "cross node or test the performance of the node that's actually the domain of",
    "start": "2333799",
    "end": "2339380"
  },
  {
    "text": "the signal that works in that area this is one of those places where as some of the responsibility is sort of",
    "start": "2339380",
    "end": "2345410"
  },
  {
    "text": "distributed among the routine",
    "start": "2345410",
    "end": "2348670"
  },
  {
    "text": "so these are for worker nodes in your q- cluster like to throw some light on this",
    "start": "2353170",
    "end": "2359410"
  },
  {
    "text": "we basically take a really small node and run pause spots on them which like",
    "start": "2359410",
    "end": "2364670"
  },
  {
    "text": "Bob said to nothing and they are like given very minimal resource requests so likes few milli cores and like very",
    "start": "2364670",
    "end": "2372140"
  },
  {
    "text": "little memory and you just start them on the node this is to test the control plane scalability for the node which is",
    "start": "2372140",
    "end": "2378079"
  },
  {
    "text": "Kuebler docker and other stuff we don't actually go into application space which is like what exactly are those containers doing and in some cases in",
    "start": "2378079",
    "end": "2395690"
  },
  {
    "text": "some cases it actually yeah yeah yeah",
    "start": "2395690",
    "end": "2402578"
  },
  {
    "text": "so the question is are there some guidelines on how to scale or provide",
    "start": "2415670",
    "end": "2421140"
  },
  {
    "text": "some different configuration for the control plane so that we support larger limits on the right yes no so so I think",
    "start": "2421140",
    "end": "2443010"
  },
  {
    "text": "strictly speaking that falls under the purview of sig auto-scaling which basically takes care of like dynamically",
    "start": "2443010",
    "end": "2450990"
  },
  {
    "text": "changing the resource requests of your your user space pods or even the control",
    "start": "2450990",
    "end": "2456690"
  },
  {
    "text": "space pods based on usage we basically try to stress everything and like give",
    "start": "2456690",
    "end": "2462210"
  },
  {
    "text": "some really maximal values to each of these and like test how I mean if we",
    "start": "2462210",
    "end": "2467670"
  },
  {
    "text": "give enough resources how much can we push on each of these fronts but",
    "start": "2467670",
    "end": "2474020"
  },
  {
    "text": "yes that's correct",
    "start": "2479980",
    "end": "2483510"
  },
  {
    "text": "yeah I mean there are two parts of this problem there's like auto scaling of your application pods and but you seem",
    "start": "2486900",
    "end": "2494820"
  },
  {
    "text": "to be more interesting or the scaling of the control plane parts yes I mean there",
    "start": "2494820",
    "end": "2500310"
  },
  {
    "text": "are like kind of two different problems but there probably are some common things among both of those so to know",
    "start": "2500310",
    "end": "2509910"
  },
  {
    "text": "about what are the things that you need to push to be able to support higher limits you can come to scalability and",
    "start": "2509910",
    "end": "2515850"
  },
  {
    "text": "to know about how to increase dynamically and when to change the",
    "start": "2515850",
    "end": "2521760"
  },
  {
    "text": "resource requests of your pods or what matrix to auto scale on I think auto scaling is the better thing",
    "start": "2521760",
    "end": "2528060"
  },
  {
    "text": "to reach out for so yeah so the question",
    "start": "2528060",
    "end": "2540210"
  },
  {
    "text": "is why does endpoints traffic increase quadratically with the number of backends it's basically because of the",
    "start": "2540210",
    "end": "2545880"
  },
  {
    "text": "way the API is designed right now we the endpoints object for a service is basically I mean at a high level a list",
    "start": "2545880",
    "end": "2553530"
  },
  {
    "text": "of all the IPS of pods that are part of the service and whenever a new pod comes up you basically add one entry and",
    "start": "2553530",
    "end": "2560130"
  },
  {
    "text": "update this object so instead of maintaining individual endpoints or separate objects you update this whole",
    "start": "2560130",
    "end": "2566280"
  },
  {
    "text": "thing and patch this whole thing which basically means if they're added n times and it's N squared bulk of calls okay",
    "start": "2566280",
    "end": "2579359"
  },
  {
    "text": "maybe let's take this offline because I think we're out of time",
    "start": "2579359",
    "end": "2584480"
  }
]
[
  {
    "start": "0",
    "end": "18000"
  },
  {
    "text": "okay so let's get stuff so my name is Jun and this is my career wish I guess and we both from eBay the",
    "start": "30",
    "end": "7649"
  },
  {
    "text": "perform and data infrastructure team and today I'd like to present to you the Charlotte and federated / miss Custer to",
    "start": "7649",
    "end": "13549"
  },
  {
    "text": "debug these and monitor the database so",
    "start": "13549",
    "end": "18840"
  },
  {
    "start": "18000",
    "end": "18000"
  },
  {
    "text": "over the last three years we have developed geode each with a today's in eBay called new data and today we have",
    "start": "18840",
    "end": "25019"
  },
  {
    "text": "deploy the new data in eBay the internal data data centers with thousands of",
    "start": "25019",
    "end": "31859"
  },
  {
    "text": "posts and over the community's infrastructure so we use the parameters 2.3 from metric monetary and we use this",
    "start": "31859",
    "end": "38340"
  },
  {
    "text": "metric monitoring system to help us so for the system operation and continue the system development so just to give",
    "start": "38340",
    "end": "44760"
  },
  {
    "text": "you a brief overview this system at the high level so we had this current library that is a attach to the database",
    "start": "44760",
    "end": "51449"
  },
  {
    "text": "application they will rather request to the service tier that service tier then end up into the packet data based in the",
    "start": "51449",
    "end": "57090"
  },
  {
    "text": "dead bag and a rapist we had the proxy to process the the query request and",
    "start": "57090",
    "end": "62340"
  },
  {
    "text": "then the request persist and then resources to the back-end storage engine and it also can create a indices where",
    "start": "62340",
    "end": "68070"
  },
  {
    "text": "necessary and push the index to the gobo secondary in the store so just give you",
    "start": "68070",
    "end": "73229"
  },
  {
    "start": "73000",
    "end": "73000"
  },
  {
    "text": "a little bit detail about these database framework in order to set the context for the rest of presentation so the",
    "start": "73229",
    "end": "79170"
  },
  {
    "text": "customer can create a multiple key spaces and each key space is considered multiple sha and each jar consider",
    "start": "79170",
    "end": "85290"
  },
  {
    "text": "multiple replicas the replicas can be the master can be the second le and can be the co hidden and hidden is I say for",
    "start": "85290",
    "end": "92159"
  },
  {
    "text": "the purpose of Baker in recovery and so the older replicas in within a single sha is scattered across multiple data",
    "start": "92159",
    "end": "98700"
  },
  {
    "text": "center so in this database framework we had this hierarchy of replicas sha and key space so for the rest of",
    "start": "98700",
    "end": "107490"
  },
  {
    "start": "106000",
    "end": "106000"
  },
  {
    "text": "presentation we're going to cover how we're going to capture the matrix and aggregated metrics and we're going to describe to you the Charlotte and",
    "start": "107490",
    "end": "113790"
  },
  {
    "text": "federally cluster that we have developed to handle the matrix crap scripting and",
    "start": "113790",
    "end": "119939"
  },
  {
    "text": "the matrix aggregation then we're going to describe you the solution that we have to roll the tongue series requires",
    "start": "119939",
    "end": "126299"
  },
  {
    "text": "amount instances database cluster and get the result in a presenter bizarre individualizing environment and it will",
    "start": "126299",
    "end": "132690"
  },
  {
    "text": "share with you some monitoring experience that we have to for Sisson operation and the system development and",
    "start": "132690",
    "end": "138090"
  },
  {
    "text": "finally the conclusion so in this database brain work we capture",
    "start": "138090",
    "end": "143160"
  },
  {
    "start": "140000",
    "end": "140000"
  },
  {
    "text": "throughput latency Ella the queuing the saturation and in the states the state",
    "start": "143160",
    "end": "148230"
  },
  {
    "text": "can be live Master replica and master secondly or can be the permit ease up and down and",
    "start": "148230",
    "end": "153570"
  },
  {
    "text": "we actually learned Kubrick to expose these OS metrics and that kubera is",
    "start": "153570",
    "end": "158730"
  },
  {
    "text": "hosted in each of the host machine also we develop and install the custom metric exporter to capture the for example I or",
    "start": "158730",
    "end": "165210"
  },
  {
    "text": "thesis metrics there is a much richer compared to the default cube red os",
    "start": "165210",
    "end": "171570"
  },
  {
    "text": "matrix with respect to the this operation and so in overall we capture",
    "start": "171570",
    "end": "177450"
  },
  {
    "text": "about 20 million matrix instances per square interval in the script in to go today we define assess one minute so",
    "start": "177450",
    "end": "184290"
  },
  {
    "text": "each day in each data center we capture about 195 gigabytes of the fanciest data and we had the two data center to host",
    "start": "184290",
    "end": "191580"
  },
  {
    "text": "this a promises cluster and we had little time to set the seven days today",
    "start": "191580",
    "end": "198050"
  },
  {
    "start": "198000",
    "end": "198000"
  },
  {
    "text": "so the integration of the Prometheus with the Cuban net is a cioppino not a nice feature for example you can",
    "start": "198410",
    "end": "203820"
  },
  {
    "text": "ultimately script the target in you know in a cluster so whenever you had a civil bring it up the automatic s Square and",
    "start": "203820",
    "end": "210390"
  },
  {
    "text": "then we also can filter the server the target based on the auto discover the labels then also we can have indeed",
    "start": "210390",
    "end": "218160"
  },
  {
    "text": "automatically the matrix labels into the matrix based on the label they specify",
    "start": "218160",
    "end": "223830"
  },
  {
    "text": "in the prospect so now with the label Y nothing that we can describe is a hierarchy so there's two kinds hierarchy that we describe one is the physical",
    "start": "223830",
    "end": "230280"
  },
  {
    "text": "hierarchy so you can describe the pot the host the wreck the data center and then a logical hierarchy is the one that",
    "start": "230280",
    "end": "236400"
  },
  {
    "text": "I described to you that you can have a replica you can have a shower another key space so all these labels is automated in jetty into the matrix a",
    "start": "236400",
    "end": "242940"
  },
  {
    "text": "based on the post met so we don't need to write the code to autumn to manually inject these labels so with the with the",
    "start": "242940",
    "end": "250890"
  },
  {
    "start": "249000",
    "end": "249000"
  },
  {
    "text": "labels to describe the hierarchy then now we can aggregate matches across the hierarchy so this is key we example on",
    "start": "250890",
    "end": "257310"
  },
  {
    "text": "the body be processed total which is a counter and we discounted a we can compute the transition rate at the",
    "start": "257310",
    "end": "262530"
  },
  {
    "text": "replicas level then we can sum the transition rate at the star level and then at the key",
    "start": "262530",
    "end": "268320"
  },
  {
    "text": "space level and finally at the namespace level so on the right-hand side which you can see is actually you can aggregate in the matrix across around",
    "start": "268320",
    "end": "275130"
  },
  {
    "text": "the physical hierarchy namely that you can get the host level metrics you can have the host label transaction the red",
    "start": "275130",
    "end": "281370"
  },
  {
    "text": "level congestion and in the zone level congestion and then finally reach the same namespace level tranzact's",
    "start": "281370",
    "end": "286860"
  },
  {
    "text": "transition total aggregation and we see also see that we found out that a chi chi space is a constraint at the right",
    "start": "286860",
    "end": "293250"
  },
  {
    "text": "hand side so that all the the host level rack and zone aggregation adjacent",
    "start": "293250",
    "end": "299250"
  },
  {
    "text": "constrained by the specified key space so I just bends earlier that we had a 20",
    "start": "299250",
    "end": "306600"
  },
  {
    "start": "303000",
    "end": "303000"
  },
  {
    "text": "million matches that we need to scrape there for each instance for one for one minute also this leave it difficult for",
    "start": "306600",
    "end": "312630"
  },
  {
    "text": "us to have a one single permit instant to describe all of the metrics and in a decent there's another difficulties that",
    "start": "312630",
    "end": "318270"
  },
  {
    "text": "we have over 1200 recording loop to handle the routine area 10-4 so the",
    "start": "318270",
    "end": "324540"
  },
  {
    "text": "reason why we have so many of these that we could you know is because that each each metric try to many dashboard and",
    "start": "324540",
    "end": "332160"
  },
  {
    "text": "each dashboard is trying to aggregation hierarchy that I described to you earlier in the previous line and also",
    "start": "332160",
    "end": "338010"
  },
  {
    "text": "try to turn it up that in our previous instances the SIP consumption that that",
    "start": "338010",
    "end": "343560"
  },
  {
    "text": "devoted for this metric aggregation or recall recording to evaluation it's a much much different compared to the",
    "start": "343560",
    "end": "348600"
  },
  {
    "text": "amount of the CPU that you square they spend on the metrics crappy so just you cannot just okay I have a scraping and",
    "start": "348600",
    "end": "354090"
  },
  {
    "text": "done now H is the most of Chinese to spend most of CPUs devotee for the metric aggregation so that brings to the",
    "start": "354090",
    "end": "360510"
  },
  {
    "text": "the next topic that and hand it over to which were to cover this Charlotte and premier is a cost of design hi my name",
    "start": "360510",
    "end": "369539"
  },
  {
    "text": "is Vishal Thakur I work on metrics monitoring and alerting in the data infrastructure team at eBay",
    "start": "369539",
    "end": "376250"
  },
  {
    "text": "so I'm going to spend the next few minutes talking about how we set up a sharded federated Prometheus cluster and",
    "start": "376250",
    "end": "384360"
  },
  {
    "start": "383000",
    "end": "383000"
  },
  {
    "text": "deployed it to production at eBay to monitor the geo distributed database that Jun talked about so",
    "start": "384360",
    "end": "394370"
  },
  {
    "text": "I'm showing here a simplified example where the target space the thousands of",
    "start": "394370",
    "end": "400400"
  },
  {
    "text": "parts across hundreds of shards that we have you cannot monitor with the single Prometheus because of the amount of",
    "start": "400400",
    "end": "408229"
  },
  {
    "text": "matrix that we collect and the rules and all of that that June mentioned so the logical thing is to try to add more",
    "start": "408229",
    "end": "414860"
  },
  {
    "text": "Prometheus servers but in such a way that we can scale the Prometheus set up in proportionate to how the zero",
    "start": "414860",
    "end": "421550"
  },
  {
    "text": "distributed database is also going to scale so in this simple example if you add one more Prometheus and take half of",
    "start": "421550",
    "end": "428600"
  },
  {
    "text": "the parts for example the parts which have even-numbered shard IDs and the",
    "start": "428600",
    "end": "434419"
  },
  {
    "text": "parts which have the odd-numbered shard IDs and get them scraped by two different Prometheus servers you already",
    "start": "434419",
    "end": "440090"
  },
  {
    "text": "kind of reduce the load by 50% so we take this concept generalized it parameters has this nice hash mod",
    "start": "440090",
    "end": "446539"
  },
  {
    "text": "function and you can apply strategically to certain set of labels and then achieve your your targets can be grouped",
    "start": "446539",
    "end": "454580"
  },
  {
    "text": "into more than two groups n number of groups however you want it like you can cut and slice them right so let's look",
    "start": "454580",
    "end": "460639"
  },
  {
    "text": "at how it looks like so at the top you see the gray box which is our Prometheus",
    "start": "460639",
    "end": "466580"
  },
  {
    "start": "461000",
    "end": "461000"
  },
  {
    "text": "ya mall template so we have templates for the Prometheus job for recording",
    "start": "466580",
    "end": "472940"
  },
  {
    "text": "rules for alerting rules for our secrets config Maps all of the kubernetes artifacts so they go into our automated",
    "start": "472940",
    "end": "479810"
  },
  {
    "text": "script set up and we turn out the actual deployment artifacts and secrets and so",
    "start": "479810",
    "end": "485870"
  },
  {
    "text": "on so here if we take the example of we want to split the target space into two groups you the automated scripts",
    "start": "485870",
    "end": "494449"
  },
  {
    "text": "substitute the template variables and you can see in this example the modulus remains two but the regular expression",
    "start": "494449",
    "end": "500960"
  },
  {
    "text": "zero one two three four files based on how many you want right so by using the",
    "start": "500960",
    "end": "506810"
  },
  {
    "text": "key space and the shard ID of the target part as the input to the hash mode function we also have this nice side",
    "start": "506810",
    "end": "513979"
  },
  {
    "text": "effect that all the parts belonging to a particular shard of a particular key",
    "start": "513979",
    "end": "519200"
  },
  {
    "text": "space they get scraped by the same Prometheus and it's it's a little bit key as you will see later it helps us in",
    "start": "519200",
    "end": "526160"
  },
  {
    "text": "writing aggregation in a much easier way so we talked about",
    "start": "526160",
    "end": "532890"
  },
  {
    "start": "531000",
    "end": "531000"
  },
  {
    "text": "the scaling of the Prometheus in proportionate to the growth of the",
    "start": "532890",
    "end": "537960"
  },
  {
    "text": "datastore the next challenge to tackle is the high availability and that's",
    "start": "537960",
    "end": "543340"
  },
  {
    "text": "pretty straightforward of taking the same example Prometheus 1 and Prometheus 2 we replicate that exact",
    "start": "543340",
    "end": "549430"
  },
  {
    "text": "setup in a remote kubernetes cluster in a remote DC and you get a pair",
    "start": "549430",
    "end": "554800"
  },
  {
    "text": "Prometheus DB 1 Prometheus DB 1 standby and DB 2 DB 2 stand by each form say H a",
    "start": "554800",
    "end": "560860"
  },
  {
    "text": "pair and they are scraping the sub set",
    "start": "560860",
    "end": "565990"
  },
  {
    "text": "of targets that that complete the whole set of target space so the next way to",
    "start": "565990",
    "end": "574089"
  },
  {
    "start": "572000",
    "end": "572000"
  },
  {
    "text": "scale within a target space so we said",
    "start": "574089",
    "end": "579100"
  },
  {
    "text": "will scale along the short boundaries so using shot as the dimension you get a number of from edges clusters so we",
    "start": "579100",
    "end": "585400"
  },
  {
    "text": "expanded that concept and gave ourselves another way to scale and also isolate so we have several categories of parts if",
    "start": "585400",
    "end": "593230"
  },
  {
    "text": "you will we have the database parts we have indexing parts we have service parts we have cubelets",
    "start": "593230",
    "end": "600130"
  },
  {
    "text": "which expose the operating system metrics and they get scraped by a independent Prometheus cluster so we map",
    "start": "600130",
    "end": "608200"
  },
  {
    "text": "this categories to Prometheus clusters so that gives us another way to scale the Prometheus independently if if the",
    "start": "608200",
    "end": "614740"
  },
  {
    "text": "OS metrics are getting huge then we just have to scale the Prometheus cluster",
    "start": "614740",
    "end": "620680"
  },
  {
    "text": "corresponding to the OS category and so on and all of these from these clusters",
    "start": "620680",
    "end": "626050"
  },
  {
    "text": "are again mirrored in the remote DC and you can see here we also have all these",
    "start": "626050",
    "end": "632140"
  },
  {
    "text": "Prometheus endpoints defined as data sources in graph honor and when I get to the graph on slides that I will describe",
    "start": "632140",
    "end": "639040"
  },
  {
    "text": "how the query happens and how we have made it convenient to the end user as well so the next challenge after scaling",
    "start": "639040",
    "end": "647470"
  },
  {
    "start": "644000",
    "end": "644000"
  },
  {
    "text": "and high availability obviously is how do we federate now now that we split our metrics across several different",
    "start": "647470",
    "end": "653620"
  },
  {
    "text": "Prometheus clusters and Prometheus shards if you take an example you want",
    "start": "653620",
    "end": "659290"
  },
  {
    "text": "to know total inserted docume count for now your data is split across",
    "start": "659290",
    "end": "664480"
  },
  {
    "text": "to prometheus so what we do is we define using recording rules aggregated metrics",
    "start": "664480",
    "end": "670209"
  },
  {
    "text": "at the Prometheus shard level so in the example that I gave if you aggregate in",
    "start": "670209",
    "end": "676029"
  },
  {
    "text": "Prometheus DB one you get the count for the total inserted documents in your odd-numbered parts and then on the other",
    "start": "676029",
    "end": "682750"
  },
  {
    "text": "side you get the total count up to even numbered parts and then you agree ate it up and at the Federation level and you",
    "start": "682750",
    "end": "690279"
  },
  {
    "text": "get the total count across the entire key space now we use deliberately a",
    "start": "690279",
    "end": "695970"
  },
  {
    "text": "prefix level zero for all these aggregated metrics that occur on the",
    "start": "695970",
    "end": "701440"
  },
  {
    "text": "Prometheus char level and that makes us easy to define the Federation job you",
    "start": "701440",
    "end": "707199"
  },
  {
    "text": "don't have to worry about how many are defined as long as you follow the naming convention it's a single Prometheus",
    "start": "707199",
    "end": "712389"
  },
  {
    "text": "Federation job description that pulls all the the level 0 aggregated metrics",
    "start": "712389",
    "end": "720269"
  },
  {
    "start": "720000",
    "end": "720000"
  },
  {
    "text": "again the Federated set up itself is highly available a we have a mirrored",
    "start": "720269",
    "end": "726519"
  },
  {
    "text": "set up in a remote data center which scrapes the same set of all the permits instances now one thing I did not talk",
    "start": "726519",
    "end": "732639"
  },
  {
    "text": "about the Prometheus instance and it's mirrored instance we don't directly go",
    "start": "732639",
    "end": "737680"
  },
  {
    "text": "scrape them either from Garifuna or from the Federation they are fronted by a load balancer whip",
    "start": "737680",
    "end": "743019"
  },
  {
    "text": "and the Federation goes talks to the load balancer web so if the primer is down the mirror can provide the data the",
    "start": "743019",
    "end": "749769"
  },
  {
    "text": "several ways the load balancer web can be implemented ingress federated ingress and yha proxy we don't have time to go",
    "start": "749769",
    "end": "757029"
  },
  {
    "text": "into the detail but this different ways you can implement that so this is what",
    "start": "757029",
    "end": "763329"
  },
  {
    "start": "762000",
    "end": "762000"
  },
  {
    "text": "the completed picture looks like so we have several categories of Prometheus clusters and each category can have n",
    "start": "763329",
    "end": "770589"
  },
  {
    "text": "number of shards and each shard is nothing but an H a pair with an active in one data center and and the standby",
    "start": "770589",
    "end": "776410"
  },
  {
    "text": "in another data center and all the traffic is pulled through the load balancer the query traffic and the",
    "start": "776410",
    "end": "782439"
  },
  {
    "text": "Federation traffic this entire setup is deployable within a couple of seconds",
    "start": "782439",
    "end": "788050"
  },
  {
    "text": "through our automation scripts and it's fully deployed out including",
    "start": "788050",
    "end": "793350"
  },
  {
    "text": "[Music] the rules and recording rules and secrets and any other things that are",
    "start": "793350",
    "end": "798710"
  },
  {
    "text": "needed for the set up to work so from the Prometheus side if we go on to the",
    "start": "798710",
    "end": "804500"
  },
  {
    "text": "query side the graph on a side so I mentioned we use the hash mode function",
    "start": "804500",
    "end": "809780"
  },
  {
    "start": "807000",
    "end": "807000"
  },
  {
    "text": "strategically on a certain set of labels so now you our data is distributed and the user wants to query not the",
    "start": "809780",
    "end": "817010"
  },
  {
    "text": "federated rolled-up metric but say the document count at a shard level so now",
    "start": "817010",
    "end": "822740"
  },
  {
    "text": "does the user have to know about which Prometheus script your data shard so",
    "start": "822740",
    "end": "827870"
  },
  {
    "text": "that's the challenge and we try to solve it with couple of techniques one technique we are calling it the federated lookup and routing table on",
    "start": "827870",
    "end": "834800"
  },
  {
    "text": "the parameter side and then on the graph fauna we make use of the graph on a template variables and template data",
    "start": "834800",
    "end": "839810"
  },
  {
    "text": "sources and I will go into details so before that how it's going to look like for an end user on the graph on our",
    "start": "839810",
    "end": "845270"
  },
  {
    "text": "dashboard so they'll come to this dashboard and they'll see the key space field and a nice drop-down list of key",
    "start": "845270",
    "end": "853130"
  },
  {
    "text": "spaces that they can select from they don't have to type they're not to remember anything once the key space is selected they then select the shard ID that",
    "start": "853130",
    "end": "859310"
  },
  {
    "text": "they're interested in and the data source field is automatically populated and all the graphs are nicely refreshed",
    "start": "859310",
    "end": "864860"
  },
  {
    "text": "from the context that they are interested in now as I mentioned that is",
    "start": "864860",
    "end": "869990"
  },
  {
    "start": "868000",
    "end": "868000"
  },
  {
    "text": "possible by some of these techniques so the technique on the Prometheus side we",
    "start": "869990",
    "end": "875860"
  },
  {
    "text": "built this special metric that we are calling the routing map it's built on",
    "start": "875860",
    "end": "881540"
  },
  {
    "text": "the OP metric which is generated by default on Prometheus for every target",
    "start": "881540",
    "end": "887090"
  },
  {
    "text": "that is scraped so if you look at the recording rule in the gray box there you",
    "start": "887090",
    "end": "892910"
  },
  {
    "text": "will see that it's nothing but count of up and aggregated by some strategic",
    "start": "892910",
    "end": "897950"
  },
  {
    "text": "labels like key space shard and zone so the instant time series vector examples",
    "start": "897950",
    "end": "903290"
  },
  {
    "text": "for corresponding to that metric you can see the two blue boxes for from which is DB one and DB 2 you will see key space",
    "start": "903290",
    "end": "910790"
  },
  {
    "text": "one and and the odd-numbered shards and key space one and two on the right side",
    "start": "910790",
    "end": "916820"
  },
  {
    "text": "with the even-numbered charts right so this is part it is kind of looking like already a partial lookup table and then",
    "start": "916820",
    "end": "923210"
  },
  {
    "text": "when you federate this and you pull these into your Federation server you can inject other external",
    "start": "923210",
    "end": "929620"
  },
  {
    "text": "labels like data source name so on every one of our Prometheus instances we added",
    "start": "929620",
    "end": "935379"
  },
  {
    "text": "data source name which corresponds to the name that we give to that endpoint in graph honor when we define the data",
    "start": "935379",
    "end": "941949"
  },
  {
    "text": "sources in graph honor so what that gets injected and you look at the the bottom yellow time series",
    "start": "941949",
    "end": "947139"
  },
  {
    "text": "list of values now if you have a key space name and a shard ID you can find",
    "start": "947139",
    "end": "952930"
  },
  {
    "text": "out by a query what the data source name is and given a data source name the ref honor can go pull the metrics from there",
    "start": "952930",
    "end": "959309"
  },
  {
    "text": "so with that routing map time series in",
    "start": "959309",
    "end": "964600"
  },
  {
    "start": "960000",
    "end": "960000"
  },
  {
    "text": "place now key space is nothing but a label values function applied on that metric and you retrieve the label values",
    "start": "964600",
    "end": "971889"
  },
  {
    "text": "for the key space dimension and similarly for char ID you retrieve the shard ID dimension values for a given",
    "start": "971889",
    "end": "977740"
  },
  {
    "text": "selected key space and the third critical one once you know the key space",
    "start": "977740",
    "end": "983230"
  },
  {
    "text": "and shard ID you again apply the label values function and you retrieve the",
    "start": "983230",
    "end": "989620"
  },
  {
    "text": "data source name so that's how the in the dashboard the data source gets populated there's a little trick here in",
    "start": "989620",
    "end": "996309"
  },
  {
    "text": "graph ahna the templated data sources cannot be of type query type so you",
    "start": "996309",
    "end": "1002069"
  },
  {
    "text": "cannot assign a label values function to it so we had to create an intermediate",
    "start": "1002069",
    "end": "1007550"
  },
  {
    "text": "hidden variable that has that value and then the data source templated variable",
    "start": "1007550",
    "end": "1013019"
  },
  {
    "text": "just points to that so that's all I have to share I'll give it back to June to",
    "start": "1013019",
    "end": "1018779"
  },
  {
    "text": "talk about our production monitoring experiences ok so the first one I have",
    "start": "1018779",
    "end": "1024178"
  },
  {
    "start": "1024000",
    "end": "1024000"
  },
  {
    "text": "to share with you this monitoring on the monitoring so basically once you place a big cluster so you need to monitor",
    "start": "1024179",
    "end": "1029490"
  },
  {
    "text": "itself so we come up with a dedicated Prometheus instance called safeml and this F minus HS script all the metrics",
    "start": "1029490",
    "end": "1036089"
  },
  {
    "text": "that expose from the permittee instances so by having all the instances related metrics to be into a single fmcs",
    "start": "1036089",
    "end": "1042298"
  },
  {
    "text": "database name we can so example to compare the performance that behavior that manifested by all the instances for",
    "start": "1042299",
    "end": "1049200"
  },
  {
    "text": "example we can see that whether the low that manifested by all the firmaface chars for the for the purpose of",
    "start": "1049200",
    "end": "1056340"
  },
  {
    "text": "scraping the always metric whether they have the even role or not I saw this and I J attached a prior to this as a bomb",
    "start": "1056340",
    "end": "1062250"
  },
  {
    "text": "monitoring instances so just give you that the dashboard that we have so the first one which we saw that well how",
    "start": "1062250",
    "end": "1067380"
  },
  {
    "text": "many fanciest instances that we capture for each individual instances at this time so there's a first dashboard the second why's that well how many",
    "start": "1067380",
    "end": "1073290"
  },
  {
    "text": "instances or parameters in this entire Custer has been done has a country down right third was a little bit more",
    "start": "1073290",
    "end": "1079560"
  },
  {
    "text": "involved which is just try to show you that well with it a standard deviation of the scripting rate for each instances",
    "start": "1079560",
    "end": "1085860"
  },
  {
    "text": "alright so what is the scraping rare instances ativan so here is a defined at the rate of the limit is a particular",
    "start": "1085860",
    "end": "1092270"
  },
  {
    "text": "matrix that expose Mike Ramirez instances it's about the appending up to the Pentheus database and we compute the",
    "start": "1092270",
    "end": "1098580"
  },
  {
    "text": "rate and we over the razor the read there is a prior to the the same matrix",
    "start": "1098580",
    "end": "1104100"
  },
  {
    "text": "that computed for the last 30 minutes 30 minutes ago and so they will give you the deviation and if you see the deviations get job",
    "start": "1104100",
    "end": "1110250"
  },
  {
    "text": "they know that there's something wrong about this scrapping performance and so",
    "start": "1110250",
    "end": "1116220"
  },
  {
    "text": "we can attach the a little to this a self monitoring so for example we can we can have a stress photos to capture how",
    "start": "1116220",
    "end": "1122580"
  },
  {
    "text": "many permit instance is a talent is time and then whether the square instances for its premiere is a chaser Tameka job",
    "start": "1122580",
    "end": "1128430"
  },
  {
    "text": "and also we can monitor the with rich build here from the federation server perspective and so this is actually the",
    "start": "1128430",
    "end": "1136230"
  },
  {
    "text": "values where they are allowed to share with you is actually how we do the troubleshooting use the metrics place monitoring system right so we we",
    "start": "1136230",
    "end": "1142920"
  },
  {
    "text": "aggregated at the one of the dashboard so that the total service error rate of a costing tax service cluster with",
    "start": "1142920",
    "end": "1149400"
  },
  {
    "text": "hundreds of the service port so now it's a well if you see the service rep bump where how do you find out that what is",
    "start": "1149400",
    "end": "1154800"
  },
  {
    "text": "exactly the the port that you will need to go inside to inspect for example using the the local law and then for the",
    "start": "1154800",
    "end": "1160920"
  },
  {
    "text": "troubleshooting so this the the one of the query that we use basically it's",
    "start": "1160920",
    "end": "1166140"
  },
  {
    "text": "actually try to compute accumulated error for each service port and we compute a profile of there and then",
    "start": "1166140",
    "end": "1172620"
  },
  {
    "text": "because it this query is actually only invoked or each Charlotte committee server describe the this particular",
    "start": "1172620",
    "end": "1178110"
  },
  {
    "text": "service metric so we had to apply in another profile another top five",
    "start": "1178110",
    "end": "1183240"
  },
  {
    "text": "aggregation across this Charlotte permitted shoddy parameters per militia",
    "start": "1183240",
    "end": "1188280"
  },
  {
    "text": "in order to get that global top five worst performance and after that you can get into",
    "start": "1188280",
    "end": "1193490"
  },
  {
    "text": "the pole and inspector the local law for the trap Oh Sookie so this is why example using the the top five top k",
    "start": "1193490",
    "end": "1200030"
  },
  {
    "text": "another one is actually we can use them we can compute the error rate and that",
    "start": "1200030",
    "end": "1206480"
  },
  {
    "start": "1201000",
    "end": "1201000"
  },
  {
    "text": "actually will allow in this Prometheus consult or we saw all of the port the service port the transients and we found",
    "start": "1206480",
    "end": "1212870"
  },
  {
    "text": "out that she's permit is one single wet cancer is you can Prada hundreds of these fancies and can humanely humic and",
    "start": "1212870",
    "end": "1219350"
  },
  {
    "text": "operator or developer can visually identify that what are the worst performance of the of this that produced",
    "start": "1219350",
    "end": "1226850"
  },
  {
    "text": "the highest service error rate and we had to do it for all these shaadi server",
    "start": "1226850",
    "end": "1233140"
  },
  {
    "text": "another one is actually about aggregation of the database matrix I do",
    "start": "1233380",
    "end": "1240110"
  },
  {
    "start": "1234000",
    "end": "1234000"
  },
  {
    "text": "the aggregation we need is a replica Shah and in the key space however the foundation is not possible",
    "start": "1240110",
    "end": "1245780"
  },
  {
    "text": "to aggregate the kubera expose always metrics the reason why is because the",
    "start": "1245780",
    "end": "1251960"
  },
  {
    "text": "pot name expose only the pot name and then all these annuity fan or this",
    "start": "1251960",
    "end": "1257120"
  },
  {
    "text": "database associated hierarchy key special and replica is not capture so",
    "start": "1257120",
    "end": "1263390"
  },
  {
    "text": "fortunately we have to expose the internal information which is that the pot name is actually based on the",
    "start": "1263390",
    "end": "1269120"
  },
  {
    "text": "concatenation of the key space try D and replica ID so we use the per movies config bag and then have the regular",
    "start": "1269120",
    "end": "1276140"
  },
  {
    "text": "expression to attach these these always metric and we use a regular expression to a strata",
    "start": "1276140",
    "end": "1281540"
  },
  {
    "text": "these are the kiss by kiss Bayside Ashanti and replica Heidi and injected into the committee's metric as the",
    "start": "1281540",
    "end": "1287690"
  },
  {
    "text": "additional labor once we have this label hierarchy then H we can sum over the container in always matrix or example",
    "start": "1287690",
    "end": "1295730"
  },
  {
    "text": "the this region it so memory and there is some over the container we get the replica level matrix and we from the",
    "start": "1295730",
    "end": "1301309"
  },
  {
    "text": "replica we get a shaft on the shower we get the key space and also we can get an intern named specificity Cerie so that",
    "start": "1301309",
    "end": "1306740"
  },
  {
    "text": "this kind of always aggregation is justin also be very useful for us to do the perform to traverse a to disk or",
    "start": "1306740",
    "end": "1312620"
  },
  {
    "text": "resilience resiliency testing also endurance testing day we test the system for over the one week two weeks three",
    "start": "1312620",
    "end": "1318920"
  },
  {
    "text": "weeks because when you see the weather memory leak has happened whether the CPU consumption has a suddenly change or not",
    "start": "1318920",
    "end": "1324800"
  },
  {
    "text": "so this turns us was very useful the last one is we want to show it to you is about the summarization so",
    "start": "1324800",
    "end": "1330980"
  },
  {
    "start": "1328000",
    "end": "1328000"
  },
  {
    "text": "Prometheus comes to be the manager but eliminate mostly is just communicate to you whether it has happen or not so",
    "start": "1330980",
    "end": "1337400"
  },
  {
    "text": "there's no much summarization capability purine so what we have he said well we",
    "start": "1337400",
    "end": "1343180"
  },
  {
    "text": "explore these the knowledge of the permission we just comes with a lot of label the labels come from the recording",
    "start": "1343180",
    "end": "1348980"
  },
  {
    "text": "loo that we evaluate this alert it comes with the recording loose label so now we",
    "start": "1348980",
    "end": "1354530"
  },
  {
    "text": "can summarize all these alert with this label so in particular we can have a severity so we can see summarize over",
    "start": "1354530",
    "end": "1361490"
  },
  {
    "text": "the critical critical or high or warning there's a three level the similarity that we define in our system and we can",
    "start": "1361490",
    "end": "1367700"
  },
  {
    "text": "aggregate it also over the logical hierarchy to see that well in between each data center how many all happen all",
    "start": "1367700",
    "end": "1373070"
  },
  {
    "text": "the the logical hierarchy for example can see the how many has happened within",
    "start": "1373070",
    "end": "1378140"
  },
  {
    "text": "this key space for the last three hours right so well and then we also have the",
    "start": "1378140",
    "end": "1383330"
  },
  {
    "text": "status which is that liquid is active or as we have been resolved so this is a another label that we can attach to also",
    "start": "1383330",
    "end": "1391510"
  },
  {
    "text": "passive state operation would not be able to solve this problem so we actually learned the unit research that",
    "start": "1391510",
    "end": "1397190"
  },
  {
    "text": "we turned that we persist this permits a lot into this alas research and near are not accessible index the this a lot with",
    "start": "1397190",
    "end": "1404450"
  },
  {
    "text": "with the label that we specify so this is outcome of the Cabana despot so I",
    "start": "1404450",
    "end": "1409700"
  },
  {
    "text": "mean not easy to see from the front of from audience you have to far away but then we can see that the world you can",
    "start": "1409700",
    "end": "1415940"
  },
  {
    "text": "have a logical hierarchy physical hierarchy that you can do this future linear equation you can less severity",
    "start": "1415940",
    "end": "1421790"
  },
  {
    "text": "and you can have a file in a key file you know reads or not so there's one point is",
    "start": "1421790",
    "end": "1426890"
  },
  {
    "text": "when I think one thing that would happen it is a chi there's a ton window right if you can specify the time window in the last 1 minute 2 minutes then that",
    "start": "1426890",
    "end": "1432950"
  },
  {
    "text": "you can get a real-time dashboard if you studied like one hour two hours three or one day then they will give you the",
    "start": "1432950",
    "end": "1438230"
  },
  {
    "text": "historical atlas summarization so that's another very nice - for the photo uncork a person so with that right to conclude",
    "start": "1438230",
    "end": "1446150"
  },
  {
    "text": "our presentation so a premiere is if download on the Internet is actually the staying along single process instance",
    "start": "1446150",
    "end": "1453110"
  },
  {
    "start": "1448000",
    "end": "1448000"
  },
  {
    "text": "but in this presentation was sorry to you that we can create a horizontally scalable and Charlotte federated server",
    "start": "1453110",
    "end": "1459950"
  },
  {
    "text": "cluster without modifying the Prometheus ausco and that with this a scalable caster really to handle the root and",
    "start": "1459950",
    "end": "1466520"
  },
  {
    "text": "already in a root and dashboard with this hierarchical aggregated metrics so with that we like to can come up here",
    "start": "1466520",
    "end": "1471800"
  },
  {
    "text": "and he said thank you for your attention and we can have thank you Q&A any",
    "start": "1471800",
    "end": "1481700"
  },
  {
    "text": "questions yes please so we have a web",
    "start": "1481700",
    "end": "1492380"
  },
  {
    "text": "hook alert manager you can write customer books so we have a web web hook that intercepts alerts and then we send",
    "start": "1492380",
    "end": "1498200"
  },
  {
    "text": "it to our internal long-term retention store as well as to elasticsearch and in",
    "start": "1498200",
    "end": "1504230"
  },
  {
    "text": "future we have plans to send it to Thanos and have global query as well as long-term retention through Thanos yeah",
    "start": "1504230",
    "end": "1513280"
  },
  {
    "text": "yes",
    "start": "1513280",
    "end": "1516280"
  },
  {
    "text": "mm-hm excellent question okay so okay so let's we're going to go to this a",
    "start": "1529110",
    "end": "1536100"
  },
  {
    "text": "walking table so I didn't I think they emphasize that routing",
    "start": "1536100",
    "end": "1541350"
  },
  {
    "text": "table it's a ton base gobo local paper so I say ten base what",
    "start": "1541350",
    "end": "1546810"
  },
  {
    "text": "does it mean so this routing information where you had to sha that rotating table information we call it at a time and",
    "start": "1546810",
    "end": "1552330"
  },
  {
    "text": "then if you know the switching time so then you know that before that point it",
    "start": "1552330",
    "end": "1557400"
  },
  {
    "text": "has to server for after that you have three server then I treat that with that you can you can had crea bundle E and",
    "start": "1557400",
    "end": "1562980"
  },
  {
    "text": "then you can do that so we could continue shouting so with this mechanism what we just need to have time to put it",
    "start": "1562980",
    "end": "1569040"
  },
  {
    "text": "about a great deal in raise this question say we can perform the continuous study in this initially set",
    "start": "1569040",
    "end": "1574560"
  },
  {
    "text": "up",
    "start": "1574560",
    "end": "1576680"
  },
  {
    "text": "yes",
    "start": "1583410",
    "end": "1586070"
  },
  {
    "text": "yes yeah so because it's a drop-down list when the user selects a key space",
    "start": "1589210",
    "end": "1595270"
  },
  {
    "text": "and a shard obviously as I mentioned earlier because of the way we picked the hash mode function the shards data is in",
    "start": "1595270",
    "end": "1601900"
  },
  {
    "text": "a single promise yes so one parameters data sources all we need to display all",
    "start": "1601900",
    "end": "1607480"
  },
  {
    "text": "the shard level data yes so that's where",
    "start": "1607480",
    "end": "1618010"
  },
  {
    "text": "the global query part comes in so when we started this out we were actually keeping an eye on thin O's and cortex",
    "start": "1618010",
    "end": "1623740"
  },
  {
    "text": "and all these other products so that's where the global query part comes in if you want something in between fully",
    "start": "1623740",
    "end": "1630040"
  },
  {
    "text": "federated aggregated versus single shard level and you want something in between obviously you need global query there",
    "start": "1630040",
    "end": "1638910"
  },
  {
    "text": "[Music] okay so when you when you aggregate to shall you had some cooper's in your mind",
    "start": "1641140",
    "end": "1647140"
  },
  {
    "text": "right so maybe you're going to aggregate a based on some label okay so maybe",
    "start": "1647140",
    "end": "1654400"
  },
  {
    "text": "based on I want to aggregate that to shatter its has manifested a super ll",
    "start": "1654400",
    "end": "1660790"
  },
  {
    "text": "read we turn up or something so you can constrain with the label at this no",
    "start": "1660790",
    "end": "1666670"
  },
  {
    "text": "labor right because yes something in your mind because when you summarize not",
    "start": "1666670",
    "end": "1672550"
  },
  {
    "text": "just only a pitch we say okay we're too sure how you specified that there's need to be a systematic mechanism for you to",
    "start": "1672550",
    "end": "1677890"
  },
  {
    "text": "constrain the query",
    "start": "1677890",
    "end": "1681240"
  },
  {
    "text": "yes yeah so right now like I said we",
    "start": "1691640",
    "end": "1696929"
  },
  {
    "text": "have templates for recording rules and the Prometheus jobs and so on and our automation scripts just take the",
    "start": "1696929",
    "end": "1702990"
  },
  {
    "text": "templates and then based on the input they generate it for n number of Prometheus instances it's I mean it's",
    "start": "1702990",
    "end": "1710220"
  },
  {
    "text": "sufficient for our purposes right now it's not very complicated just with a couple of scripts we are able to achieve",
    "start": "1710220",
    "end": "1715289"
  },
  {
    "text": "this but coming to this session here we came across a lot of other tools that we could potentially use to achieve this",
    "start": "1715289",
    "end": "1723210"
  },
  {
    "text": "deployment automation and we are going to look at some of those it just",
    "start": "1723210",
    "end": "1728520"
  },
  {
    "text": "emphasizes I mean with the same script we we can deploy all these Kuster to staging pre pot and then production yeah",
    "start": "1728520",
    "end": "1737690"
  },
  {
    "text": "and also the second security domain some security comprise something special RNA",
    "start": "1737690",
    "end": "1744270"
  },
  {
    "text": "we are doing PCI compliant yes please",
    "start": "1744270",
    "end": "1749750"
  },
  {
    "text": "ah yes so we have deliberately limited",
    "start": "1754100",
    "end": "1760490"
  },
  {
    "text": "to only the Federation server only scrapes the already aggregated metrics from the children Prometheus and that's",
    "start": "1760490",
    "end": "1767390"
  },
  {
    "text": "why our recording rules we have hundreds of recording rules for aggregating it on several different ways and several",
    "start": "1767390",
    "end": "1774410"
  },
  {
    "text": "different combination of labels that we are interested in",
    "start": "1774410",
    "end": "1780519"
  },
  {
    "text": "or definitely definitely yeah we actually have only one single Federation so far we didn't find a need to have",
    "start": "1792670",
    "end": "1798010"
  },
  {
    "text": "more than one Federation because all the Lord like June mentioned earlier goes down to the recording rules and we have",
    "start": "1798010",
    "end": "1805179"
  },
  {
    "text": "so many recording rules we have all possible kind of aggregations that we need the Federation is just pulling them",
    "start": "1805179",
    "end": "1810429"
  },
  {
    "text": "and aggregating some of them to a level one where needed but in most cases is",
    "start": "1810429",
    "end": "1816549"
  },
  {
    "text": "just aggregating them yes please",
    "start": "1816549",
    "end": "1822690"
  },
  {
    "text": "oh it's so ok we weren't away so the do not really come from the prometheus and we remove the and then go to a rep",
    "start": "1832290",
    "end": "1839340"
  },
  {
    "text": "manager let me go to the way hook I mean and then we had a weapon called the slack so that's a real time I live in is a cold sue this permit is Custer and",
    "start": "1839340",
    "end": "1846300"
  },
  {
    "text": "what we have is that is a loot is the alert summarization this is a held on",
    "start": "1846300",
    "end": "1852930"
  },
  {
    "text": "call people to digest how that continues a lot string comes for the last one hour to our one day I mean that's a",
    "start": "1852930",
    "end": "1858960"
  },
  {
    "text": "categorization or summarization it's a sorta like analytics it's not and also",
    "start": "1858960",
    "end": "1864900"
  },
  {
    "text": "there's one more use case whenever we have any productions incident when we want to do root cause analysis people",
    "start": "1864900",
    "end": "1870150"
  },
  {
    "text": "want to go back and look at what else happened at that time how did we miss it how did the on-call miss it and so on and the elasticsearch helps us to you",
    "start": "1870150",
    "end": "1877530"
  },
  {
    "text": "know look at the history and try to roll it up in several different ways yeah so in this case the active and the",
    "start": "1877530",
    "end": "1892410"
  },
  {
    "text": "standby both send alerts and we actually have not one but two alert managers and",
    "start": "1892410",
    "end": "1898890"
  },
  {
    "text": "two different data centers right so they're both are sending to both alert managers and we have some logic within",
    "start": "1898890",
    "end": "1904050"
  },
  {
    "text": "the web hook that does the dedupe based on alert signature so if you look at",
    "start": "1904050",
    "end": "1909390"
  },
  {
    "text": "alert coming from two different Prometheus's almost all the information would be similar except the start time",
    "start": "1909390",
    "end": "1914550"
  },
  {
    "text": "might be slightly different because they might be scraping at slightly skewed times and of course the external label",
    "start": "1914550",
    "end": "1920400"
  },
  {
    "text": "this is Prometheus DB one or this is another Prometheus right in at a more DC so we take care of that when",
    "start": "1920400",
    "end": "1925770"
  },
  {
    "text": "constructing the alert signature and we put it in a temporary cache experiment ash and based on that we just do a deed",
    "start": "1925770",
    "end": "1932460"
  },
  {
    "text": "oh and for the further downstream only one single alert goes out",
    "start": "1932460",
    "end": "1938090"
  },
  {
    "text": "all right thank you very much much",
    "start": "1941150",
    "end": "1946120"
  }
]
[
  {
    "text": "so my name is Jason I'm here with my colleague Kevin we both work on the observability team at Cruz uh which is",
    "start": "640",
    "end": "7120"
  },
  {
    "text": "under site reliability engineering and um just by way of kind of understanding",
    "start": "7120",
    "end": "12400"
  },
  {
    "text": "the audience a little bit here I wanted to just get a sense of a few things can you just like raise your hand or otherwise visually you know inform me if",
    "start": "12400",
    "end": "20000"
  },
  {
    "text": "you feel like you have a good understanding of open Telemetry all right so that's about uh",
    "start": "20000",
    "end": "26960"
  },
  {
    "text": "50% now same question what about specific the open Telemetry collector",
    "start": "26960",
    "end": "32279"
  },
  {
    "text": "thing that you can deploy to manage signals all right slightly less okay cool um that's good because the this",
    "start": "32279",
    "end": "39680"
  },
  {
    "text": "talk is going to get pretty technical um this is kind of a report From The Trenches of uh somebody who's doing a",
    "start": "39680",
    "end": "46680"
  },
  {
    "text": "kind of a large scale migration um using open Telemetry shifting a lot of existing instrumentation to it and um so",
    "start": "46680",
    "end": "55039"
  },
  {
    "text": "we're going to get in the weeds but at the same time it's going to be kind of not so much exactly about how we do it",
    "start": "55039",
    "end": "61519"
  },
  {
    "text": "because we don't want to be necessarily prescriptive just kind of showing you some ways you can think about doing this",
    "start": "61519",
    "end": "66680"
  },
  {
    "text": "in your organization and hopefully it kind of is um applicable to",
    "start": "66680",
    "end": "72280"
  },
  {
    "text": "organizations of various different shapes and sizes and you know um",
    "start": "72280",
    "end": "77759"
  },
  {
    "text": "maturities so as an overview in this talk we're going to walk you through the thought process that we followed and",
    "start": "77799",
    "end": "83759"
  },
  {
    "text": "executing a wholesale migration from one observability vendor to another in our",
    "start": "83759",
    "end": "89079"
  },
  {
    "text": "case uh we had historically used dead dog and are migrating um to",
    "start": "89079",
    "end": "95159"
  },
  {
    "text": "chronosphere it's actually funny I think on Tuesday there's a panel with a uh",
    "start": "95159",
    "end": "100759"
  },
  {
    "text": "charity Majors kind of referred to observability teams as doing vendor engineering and uh that felt actually a",
    "start": "100759",
    "end": "107200"
  },
  {
    "text": "little too accurate um because that's a lot of what we do is we manage our the relationship between the infrastructure",
    "start": "107200",
    "end": "112640"
  },
  {
    "text": "and the teams and ultimately a lot of vendor products that we are leveraging for you know opportunity cost you don't",
    "start": "112640",
    "end": "119520"
  },
  {
    "text": "have to spend all this time owning all aspects of um observability internally",
    "start": "119520",
    "end": "125840"
  },
  {
    "text": "because it doesn't make sense a lot of the time um that said we're not talking specifically about vendors in this talk",
    "start": "125840",
    "end": "131959"
  },
  {
    "text": "it's more about just the process of migrating and why open Telemetry is a great assist in helping you kind of have",
    "start": "131959",
    "end": "138080"
  },
  {
    "text": "more technical choice to allow you to make this kind of shift in the future um we're going to tell you some",
    "start": "138080",
    "end": "143920"
  },
  {
    "text": "lessons we learned along the way Kevin is going to give you a deep dive into how we run the LEL collector at scale",
    "start": "143920",
    "end": "149879"
  },
  {
    "text": "for a lot of different use cases at Cru and ultimately what we hope you get out of this is if nothing else some",
    "start": "149879",
    "end": "157599"
  },
  {
    "text": "confidence that you can start using open tantry um in your environment and iterate on it over time as uh suits your",
    "start": "157599",
    "end": "165640"
  },
  {
    "text": "needs so let's set the stage uh we work at Cruz an autonomous vehicle company that provides ride hail and delivery",
    "start": "165640",
    "end": "172959"
  },
  {
    "text": "services via a fleet of driverless cars in multiple cities as said Kevin and I",
    "start": "172959",
    "end": "178280"
  },
  {
    "text": "work on the observability team so we're responsible for ensuring that we enable um the development and operations of",
    "start": "178280",
    "end": "184280"
  },
  {
    "text": "those Services um to be reliable and also make sure that all of our Engineers can be uh productive with cruise",
    "start": "184280",
    "end": "191159"
  },
  {
    "text": "infrastructure to give you a sense of scale we're talking like we have on the order of 100 kubernetes clusters with",
    "start": "191159",
    "end": "197239"
  },
  {
    "text": "thousands of nodes tens of thousands of PODS we also have about hundreds hundreds of thousands of um VMS that are",
    "start": "197239",
    "end": "204000"
  },
  {
    "text": "spun up and down to sort of assist in things like test training simulation um so if you've been in this",
    "start": "204000",
    "end": "211799"
  },
  {
    "text": "room in particular in cubec con you've probably heard a lot about the benefits of open Telemetry uh in my view otel",
    "start": "211799",
    "end": "219480"
  },
  {
    "text": "provides two key capabilities one it uh it unlocks Choice it unlocks technical choice for you as",
    "start": "219480",
    "end": "226360"
  },
  {
    "text": "observability but two it also um provides Synergy so the ecosystem of otel um has a lot of weight behind it",
    "start": "226360",
    "end": "233959"
  },
  {
    "text": "and there's a lot of nice um virtuous Cycles happening due to the ubiquity of",
    "start": "233959",
    "end": "239760"
  },
  {
    "text": "oel as an open standard it's great because vendors increasingly are supporting it for ingest or export or",
    "start": "239760",
    "end": "246280"
  },
  {
    "text": "whatever while at the same time because of that ubiquity we get a lot of investment in the instrumentation side",
    "start": "246280",
    "end": "252680"
  },
  {
    "text": "so it's a really nice um healthy ecosystem and healthy Community right now um and so we basically approached",
    "start": "252680",
    "end": "260320"
  },
  {
    "text": "elel motivated by desire to shift our entire observability stack from deod do to chronosphere it could be that you",
    "start": "260320",
    "end": "266479"
  },
  {
    "text": "don't need to do anything nearly that extravagant um but we can talk about various ways to um start depending on",
    "start": "266479",
    "end": "272759"
  },
  {
    "text": "what your needs are so to open up like whenever we think about oh I wanted to use this new",
    "start": "272759",
    "end": "278919"
  },
  {
    "text": "technology in uh in my company you always have this this dream is that you you have a green field you've got um",
    "start": "278919",
    "end": "285039"
  },
  {
    "text": "unlimited possibility you know that otel you've heard good things about it and um you don't have any Legacy systems to",
    "start": "285039",
    "end": "291120"
  },
  {
    "text": "deal with you can just create new projects you can use the otel SDK you can use the collector blah blah blah it",
    "start": "291120",
    "end": "296880"
  },
  {
    "text": "all works great you see lots of blog posts about it um however the reality is like we're dealing with stuff like this",
    "start": "296880",
    "end": "303080"
  },
  {
    "text": "where we've got lots of investment um in Legacy systems things that have evolved over time in our case at Cruz we've kind",
    "start": "303080",
    "end": "310080"
  },
  {
    "text": "of had some lava layer going on with instrumentation so you've got like Doc stats D pereus we had some early open",
    "start": "310080",
    "end": "316720"
  },
  {
    "text": "sensus users and open tracing um there's also otel already in the mix in a few",
    "start": "316720",
    "end": "321800"
  },
  {
    "text": "different cases um but beyond just the instrumentation and the code you have all this additional investment on top of",
    "start": "321800",
    "end": "328199"
  },
  {
    "text": "that with um dashboards and alerts and uh things that people are depending on to do their work on a day-to-day basis",
    "start": "328199",
    "end": "335319"
  },
  {
    "text": "at the same time you've got typically a long tail of a bunch of junk that you don't really care about nobody's looking",
    "start": "335319",
    "end": "341759"
  },
  {
    "text": "at and you aren't really sure like how important is it and lastly at larger",
    "start": "341759",
    "end": "346960"
  },
  {
    "text": "organizations you also sometimes wind up with issues of ownership where maybe entire systems don't have a clear owner",
    "start": "346960",
    "end": "353400"
  },
  {
    "text": "and that applies as well to the observability of those systems and assets so some of the the problems that",
    "start": "353400",
    "end": "359919"
  },
  {
    "text": "we faced um I didn't say this but Cruz is like relatively old company I think it's on the order of 10 years I really",
    "start": "359919",
    "end": "366199"
  },
  {
    "text": "should know this but it's it's been around for a while there's been a lot of organic growth that we um had to take on here and so one of the problems we faced",
    "start": "366199",
    "end": "373360"
  },
  {
    "text": "was how do we just just get started to use o otel and take advantage of being",
    "start": "373360",
    "end": "378440"
  },
  {
    "text": "in this ubiquitous virtuous cycle how can we introduce this",
    "start": "378440",
    "end": "383520"
  },
  {
    "text": "technology with minimal overhead for existing teams and I'm not just talking about um talking about code overheads",
    "start": "383520",
    "end": "389160"
  },
  {
    "text": "they don't have to do many changes to their code but also you know performance overhead and things like that um that",
    "start": "389160",
    "end": "395800"
  },
  {
    "text": "also applies to you know disrupting them in their existing dashboards and monitors how can we make it so they don't have to rewrite everything that",
    "start": "395800",
    "end": "402560"
  },
  {
    "text": "they do um third how can we do this safely so that we can transition our monitors and",
    "start": "402560",
    "end": "409280"
  },
  {
    "text": "make sure we don't have gaps in observability that could lead to us missing um issues during a migration and",
    "start": "409280",
    "end": "415759"
  },
  {
    "text": "lastly how can we do all of this at Cruz's scale which is um significant we",
    "start": "415759",
    "end": "420879"
  },
  {
    "text": "have some pretty big clusters so we're gonna talk about taking the first steps and um throughout",
    "start": "420879",
    "end": "427560"
  },
  {
    "text": "the talk uh we're going to kind of refer to a diagram that looks a bit like",
    "start": "427560",
    "end": "432960"
  },
  {
    "text": "this I think this is basically what observability systems look like if you zoom out in a kubon cluster so you've",
    "start": "432960",
    "end": "440240"
  },
  {
    "text": "got a cluster it's got a bunch of nodes typically you got a Damon set running um there's kind of no way to get around",
    "start": "440240",
    "end": "445720"
  },
  {
    "text": "that uh on every node and that Damon set runs an agent that is either vendor provided or you're",
    "start": "445720",
    "end": "451560"
  },
  {
    "text": "running it yourself and that agent has a lot of responsibilities it handles ingest of of metrics like statsd or it",
    "start": "451560",
    "end": "458400"
  },
  {
    "text": "handles maybe scraping things um it handles getting host metrics getting uh",
    "start": "458400",
    "end": "463720"
  },
  {
    "text": "container metrics um it does a lot of work and in other cases like data dog they schedule custom checks and they all",
    "start": "463720",
    "end": "470360"
  },
  {
    "text": "kind of participate in this sort of check mesh that is centrally organized so it can really vary how much they're",
    "start": "470360",
    "end": "476919"
  },
  {
    "text": "doing on the side we have a cluster a agent which is sort of you usually have some of these things they're like kind",
    "start": "476919",
    "end": "482440"
  },
  {
    "text": "of things that are cluster scoped like Cube State metrics things that you only want to be running like once somewhere",
    "start": "482440",
    "end": "488120"
  },
  {
    "text": "another example is if you're pulling Cloud metrics from gcp or Amazon or something now all of this stuff funnels",
    "start": "488120",
    "end": "494599"
  },
  {
    "text": "up into what is just a simple box here that says observability system but actually that is you know also a complex",
    "start": "494599",
    "end": "501520"
  },
  {
    "text": "Beast that has lots of moving Parts but for our purposes here um we'll just assume that is something that can take",
    "start": "501520",
    "end": "508440"
  },
  {
    "text": "in signal like metrics and tracing we're not really talking about logs today by the way um but the same thing would",
    "start": "508440",
    "end": "515159"
  },
  {
    "text": "apply uh takes in metrics and tracing and then it provides a query interface that allows you to um visualize the data",
    "start": "515159",
    "end": "523080"
  },
  {
    "text": "and write alerts and so on and so forth so one of the first things that we thought about when uh approaching you",
    "start": "523080",
    "end": "530320"
  },
  {
    "text": "know adoption of otel was like well what if we just introduce this at the client layer uh we can change the",
    "start": "530320",
    "end": "536120"
  },
  {
    "text": "instrumentation from DD trace or Doc statsd and start a line Ling on open Telemetry take advantage of the",
    "start": "536120",
    "end": "541720"
  },
  {
    "text": "instrumentation there and then we um we can do this actually because the dat do",
    "start": "541720",
    "end": "547440"
  },
  {
    "text": "agent actually supports uh OTL inest for both metrics and traces and it's pretty good um so this looked like a promising",
    "start": "547440",
    "end": "555000"
  },
  {
    "text": "Avenue however uh at at an organization of any significant scale you're going to",
    "start": "555000",
    "end": "560959"
  },
  {
    "text": "run into a lot of problems with actually doing this migration you have to get Buy in from the teams you have the issue of service ownership maybe Ser some",
    "start": "560959",
    "end": "567440"
  },
  {
    "text": "services are just it's not not clear who would do the work and if you have a lot of systems you're really signing up for",
    "start": "567440",
    "end": "573000"
  },
  {
    "text": "a lot of work that ultimately is realistically going to fall on infrastructure the other thing this",
    "start": "573000",
    "end": "578640"
  },
  {
    "text": "doesn't solve are things like pole um like things that expose Prometheus metrics which a lot of internal infra",
    "start": "578640",
    "end": "584600"
  },
  {
    "text": "stuff does uh so while it could be um a way to sort of get your foot in the door",
    "start": "584600",
    "end": "589880"
  },
  {
    "text": "especially if your vendor supports OTL ingest it didn't really work for us",
    "start": "589880",
    "end": "595079"
  },
  {
    "text": "because we had um more use cases and our organization was just too big for the to be a viable",
    "start": "595079",
    "end": "601279"
  },
  {
    "text": "approach a more interesting idea is to still hold on to the fact that you've",
    "start": "601279",
    "end": "606680"
  },
  {
    "text": "got OTL interest on the agents but you can use the elel collector to kind of sit in between um the the agents and",
    "start": "606680",
    "end": "614480"
  },
  {
    "text": "your workloads this is this allows you to do some cool things so you can",
    "start": "614480",
    "end": "620000"
  },
  {
    "text": "normalize at this layer so you can ingest statsd you can ingest in our case Dat Dog APM Trace data um but you can do",
    "start": "620000",
    "end": "627079"
  },
  {
    "text": "other things there as well like maybe enriching the tricks from some other sources uh performing you know other",
    "start": "627079",
    "end": "632800"
  },
  {
    "text": "normalization sampling perhaps you could do here as well and it's kind of get you a little bit of indirection between for",
    "start": "632800",
    "end": "639959"
  },
  {
    "text": "example a vendor provided agent and the rest of your infrastructure and that can start to um open the door to more",
    "start": "639959",
    "end": "646320"
  },
  {
    "text": "interesting things down the road which Kevin will talk about in a bit so I do want to take a little step",
    "start": "646320",
    "end": "653279"
  },
  {
    "text": "back though CU I talked about how like okay we we didn't go down the SDK route because it was like inating the clients",
    "start": "653279",
    "end": "659160"
  },
  {
    "text": "because it was too much work uh but you kind of should have a bifurcated",
    "start": "659160",
    "end": "664519"
  },
  {
    "text": "approach when you're looking at a migration like this so you have one way that you handle sort of Legacy stuff and",
    "start": "664519",
    "end": "670639"
  },
  {
    "text": "you have the other way that you you kind of should be prescriptive about what you want new systems to do because otherwise new systems are going to come up and",
    "start": "670639",
    "end": "676440"
  },
  {
    "text": "they're going to just keep repeating the same patterns that you're trying to stamp out so what we did was um for new",
    "start": "676440",
    "end": "683560"
  },
  {
    "text": "systems we provided a distribution of the um open Telemetry SDK that we wrap",
    "start": "683560",
    "end": "689839"
  },
  {
    "text": "up it's an internal uh in this case we've got it in a few different languages that we use at cruise and it's",
    "start": "689839",
    "end": "695720"
  },
  {
    "text": "basically the observability library that teams um are supposed to be using whenever they're uh um writing a new",
    "start": "695720",
    "end": "702680"
  },
  {
    "text": "system this is really nice because we can put opinionated defaults in there so",
    "start": "702680",
    "end": "708240"
  },
  {
    "text": "we can make sure that everybody's tagging things in the same way uh we also do stuff where we will provide",
    "start": "708240",
    "end": "713800"
  },
  {
    "text": "wrappers of otel instrumentation libraries so we can make sure to um",
    "start": "713800",
    "end": "719480"
  },
  {
    "text": "you know for example I'll get into this in a bit but some instrumentation libraries had problems with high cardinality labels we could like take",
    "start": "719480",
    "end": "725839"
  },
  {
    "text": "care of that and make sure that they only take the the ones that are kind of blessed by the observability team the",
    "start": "725839",
    "end": "732360"
  },
  {
    "text": "other cool thing about this is it allows us to provide a a pretty good Dev experience to users um and this is",
    "start": "732360",
    "end": "737920"
  },
  {
    "text": "something that I think is not often thought about when especially coming from like a statsd model where",
    "start": "737920",
    "end": "744519"
  },
  {
    "text": "developers are kind of used to just metrics are kind of like in the background somewhere and we we see them when in and we see them in Dev or",
    "start": "744519",
    "end": "750199"
  },
  {
    "text": "whatever when it's deployed but locally the workflow um kind of sucks so the",
    "start": "750199",
    "end": "755399"
  },
  {
    "text": "cool thought part about moving to uh otel is that we can do something where when you're deployed we set up like a",
    "start": "755399",
    "end": "762240"
  },
  {
    "text": "push exporter that pushes to our infrastructure but when you're running in Dev mode we can automatically set up",
    "start": "762240",
    "end": "767959"
  },
  {
    "text": "a local prom scrape endpoint we can set up things like stats VI Z pages and that",
    "start": "767959",
    "end": "774000"
  },
  {
    "text": "makes it so that when you're running things locally you have a really nice feedback loop that actually didn't exist exist before and so this is one of those",
    "start": "774000",
    "end": "780519"
  },
  {
    "text": "nice carrots that you want to give to people when you're trying to get them on board with a new thing so um some of the the challenges",
    "start": "780519",
    "end": "788560"
  },
  {
    "text": "that we had I like I kind of think it's required basically to roll your own Dro at this point because if you want to do",
    "start": "788560",
    "end": "795480"
  },
  {
    "text": "anything slightly complicated the off the the Shelf tools just aren't enough I don't think they can be enough it's just",
    "start": "795480",
    "end": "801240"
  },
  {
    "text": "kind of nature of the Beast you can look at otel config go it's a nice way of",
    "start": "801240",
    "end": "806839"
  },
  {
    "text": "simplifying uh setting up the metric and Trace pipelines in open Telemetry um I think that frankly open",
    "start": "806839",
    "end": "814120"
  },
  {
    "text": "Telemetry by itself is kind of a beast to set up a configure um you need probably at least 20 lines of code to to",
    "start": "814120",
    "end": "820760"
  },
  {
    "text": "to to do it and so that's another reason why we rolled our own SDK but it comes with overhead we have to version it we",
    "start": "820760",
    "end": "827040"
  },
  {
    "text": "have to make sure that we um modularize things well enough so that we don't run",
    "start": "827040",
    "end": "832279"
  },
  {
    "text": "into transitive dependency issues but ultimately these were worth the",
    "start": "832279",
    "end": "837759"
  },
  {
    "text": "upside this is kind of like what our library looks like we just have a a start function and then a shut down",
    "start": "837759",
    "end": "843680"
  },
  {
    "text": "function that's basically it we expose um some otel functions like otherwise",
    "start": "843680",
    "end": "848759"
  },
  {
    "text": "people mostly use the otel API so they just generate metrics they generate um",
    "start": "848759",
    "end": "854480"
  },
  {
    "text": "you know counters and and things like that and um we have some other sugar things that we put in there for to kind",
    "start": "854480",
    "end": "860839"
  },
  {
    "text": "of um basically make the edges of the the SDK work a bit",
    "start": "860839",
    "end": "867399"
  },
  {
    "text": "better uh GES that we had with this probably the biggest one was just being",
    "start": "867399",
    "end": "872480"
  },
  {
    "text": "really careful with Trace propagation so again we use data dog data dog has their own uh Trace propagation format and um",
    "start": "872480",
    "end": "880920"
  },
  {
    "text": "what's cool though is that sort of more recent versions of DD Trace day dog's own instrumentation they support sending",
    "start": "880920",
    "end": "888199"
  },
  {
    "text": "um w3c Trace context so they support the new way of sending Trace context when you're emitting data but uh if you have",
    "start": "888199",
    "end": "895160"
  },
  {
    "text": "any old clients in your infrastructure that's no good so so what we had to do and I was going the other thing I was",
    "start": "895160",
    "end": "901279"
  },
  {
    "text": "going to say about this was ISO as far as I know you can only set up one Trace propagator format like otel you can kind",
    "start": "901279",
    "end": "908040"
  },
  {
    "text": "of combine them and have a chain I don't think this is possible in STO and we were relying on Dat Dog at the sto level",
    "start": "908040",
    "end": "914759"
  },
  {
    "text": "as well so necessarily we had to basically build in support for um",
    "start": "914759",
    "end": "920360"
  },
  {
    "text": "backwards compatibility for data dogs format which is another reason it was nice to have our own Dro of the",
    "start": "920360",
    "end": "925680"
  },
  {
    "text": "client I mentioned a few of these other things before um High cardinality metrics have been a problem with the",
    "start": "925680",
    "end": "930880"
  },
  {
    "text": "built-in otel instrumentation this has gotten a lot better with the realization that this is a problem um but that was",
    "start": "930880",
    "end": "937880"
  },
  {
    "text": "something we had to work around in the past an example is like putting the connection ID or like the the pier IP",
    "start": "937880",
    "end": "944680"
  },
  {
    "text": "address on metrics emitted from HTTP instrumentation which you almost basically never want for for",
    "start": "944680",
    "end": "951560"
  },
  {
    "text": "metrics uh there's this idea of a view in otel SDK which I think is kind of confusing I would like to see some",
    "start": "951560",
    "end": "957839"
  },
  {
    "text": "something uh some better work there people are kind of used to defining metrics and like histogram buckets like",
    "start": "957839",
    "end": "964440"
  },
  {
    "text": "next to each other and The View kind of separates them which can be a bit awkward and lastly if you're coming from",
    "start": "964440",
    "end": "970959"
  },
  {
    "text": "the statd world you expect synchronous gauges but guess what they don't exist in notel and this is definitely kind of",
    "start": "970959",
    "end": "976319"
  },
  {
    "text": "a confusing thing for people uh fortunately I believe this landed in the otel spec because they recognized the",
    "start": "976319",
    "end": "982279"
  },
  {
    "text": "need and now we're just waiting on SDK support uh in the meantime we just worked around this we wrote like a",
    "start": "982279",
    "end": "987639"
  },
  {
    "text": "wrapper that made a synchronous interface out of an asynchronous interface again another reason it was",
    "start": "987639",
    "end": "992680"
  },
  {
    "text": "good to have our own client okay so um we talked before a",
    "start": "992680",
    "end": "998480"
  },
  {
    "text": "couple slides ago talked about how you can sort of get a foot in the door by intercepting things with the collector",
    "start": "998480",
    "end": "1004880"
  },
  {
    "text": "um but now we're going to talk about like what would it take to actually run everything with just using the L",
    "start": "1004880",
    "end": "1011680"
  },
  {
    "text": "collector and that's what Kevin's going to talk about all right thanks Jason yeah so so",
    "start": "1011680",
    "end": "1018800"
  },
  {
    "text": "I'll talk about how we run the collectors at Cruise um if you're not familiar a collector is basically piece",
    "start": "1018800",
    "end": "1024640"
  },
  {
    "text": "of instrumentation infrastructure that uh receives metrics log traces uh",
    "start": "1024640",
    "end": "1029918"
  },
  {
    "text": "processes them and then sends them on uh through exporters um it's very",
    "start": "1029919",
    "end": "1035400"
  },
  {
    "text": "composable and it is a nice layer of indirection um especially if you have",
    "start": "1035400",
    "end": "1040640"
  },
  {
    "text": "let's say things like multiple uh vendor backends so here's a high Lev view of",
    "start": "1040640",
    "end": "1046720"
  },
  {
    "text": "our architectures um I'm going to start with our Edge we call them our Edge collector systems on the left um these",
    "start": "1046720",
    "end": "1053320"
  },
  {
    "text": "sit in on all of our clusters so they basically are there with our",
    "start": "1053320",
    "end": "1058440"
  },
  {
    "text": "services and they collect basically at the edge so there are certain things we need to collect like system metrics um",
    "start": "1058440",
    "end": "1065400"
  },
  {
    "text": "as well as uh you know the Services report directly to them um next I'm",
    "start": "1065400",
    "end": "1071559"
  },
  {
    "text": "going to move to our centralized inest collectors which is sort of our second tier um and it is important to note that",
    "start": "1071559",
    "end": "1078440"
  },
  {
    "text": "the deployment architecture um has implications on sort of the collection strategy and the Telemetry content",
    "start": "1078440",
    "end": "1084880"
  },
  {
    "text": "itself um we kind of learn the hard way that things uh having the otel collector as a demon set um versus a deployment um",
    "start": "1084880",
    "end": "1092919"
  },
  {
    "text": "sort of comes with its own nuanced uh capabilities so I'm going to basically go through all the metric and Trace",
    "start": "1092919",
    "end": "1099280"
  },
  {
    "text": "signals that we need uh that we needed to replace in this migration and how we architect our collectors to account for",
    "start": "1099280",
    "end": "1107320"
  },
  {
    "text": "this so the first thing we needed in our migration was replacement collection for our existing uh inest and this is",
    "start": "1107320",
    "end": "1114080"
  },
  {
    "text": "basically statsd metric ingest and Dat Dog Trace inest uh from our",
    "start": "1114080",
    "end": "1119440"
  },
  {
    "text": "services so you can see here are the existing vendor agent on the left and the right is basically what we came up",
    "start": "1119440",
    "end": "1125039"
  },
  {
    "text": "with is the replacement uh it is a it basically this collector takes these",
    "start": "1125039",
    "end": "1130159"
  },
  {
    "text": "responsibilities on through the statsd receiver and the data dog receiver uh protocols like statsd require consistent",
    "start": "1130159",
    "end": "1136880"
  },
  {
    "text": "send targets for aggregation um which made demon set a natural option for us to have these Edge collectors um",
    "start": "1136880",
    "end": "1143840"
  },
  {
    "text": "with consistent you know Source destination end point mapping so we know the metrics are going to the same place",
    "start": "1143840",
    "end": "1149840"
  },
  {
    "text": "uh demon set bloat is something we always want to avoid um you know the overhead per node um but this ended up",
    "start": "1149840",
    "end": "1156320"
  },
  {
    "text": "being really the cleanest solution and somewhat avoidable for our case um we",
    "start": "1156320",
    "end": "1161480"
  },
  {
    "text": "use this level of IND direction to basically normalize and enrich metrics before saying them on to the central",
    "start": "1161480",
    "end": "1167240"
  },
  {
    "text": "injust uh so next we need a way of implementing uh system metrics on kubernetes clusters",
    "start": "1167240",
    "end": "1173360"
  },
  {
    "text": "these are things like kubernetes metrics status of a pod how many jobs failed uh",
    "start": "1173360",
    "end": "1179320"
  },
  {
    "text": "container metrics like you know the CPU a container is consuming as well as host metrics like you know the memory usage",
    "start": "1179320",
    "end": "1185039"
  },
  {
    "text": "of a VM or a node uh these previously came out of the box with our vendor agent uh so now we basically have to",
    "start": "1185039",
    "end": "1191960"
  },
  {
    "text": "figure out how we're going to implement them ourselves for this we leverag the same demon set collector instance you saw",
    "start": "1191960",
    "end": "1198520"
  },
  {
    "text": "earlier and we basically added a series of Prometheus scrape jobs to it using the Prometheus receiver um there already",
    "start": "1198520",
    "end": "1205360"
  },
  {
    "text": "exists an endpoint on the cuet uh for uh host metrics and container advisor",
    "start": "1205360",
    "end": "1210799"
  },
  {
    "text": "metrics as well um so that's where we basically scraped uh locally from the",
    "start": "1210799",
    "end": "1216440"
  },
  {
    "text": "demon Set uh to get our node and container compute metrics uh for kubernetes metrics we use",
    "start": "1216440",
    "end": "1222919"
  },
  {
    "text": "Cube State metrics um which provides as I mentioned a lot of those uh you know",
    "start": "1222919",
    "end": "1228200"
  },
  {
    "text": "metrics that are relevant to the state of the cluster um we run those as a side car on this demon set and we actually",
    "start": "1228200",
    "end": "1237440"
  },
  {
    "text": "have this sharded along the node so there's an option in Cube State metrics uh which basically queries the API",
    "start": "1237440",
    "end": "1243799"
  },
  {
    "text": "server and provides a scrape Target to say you know I only want to produce",
    "start": "1243799",
    "end": "1249559"
  },
  {
    "text": "metrics based on the Node that I'm on um this you know sort of horizontally",
    "start": "1249559",
    "end": "1256000"
  },
  {
    "text": "scales uh the instance uh which we originally had as a centralized instance",
    "start": "1256000",
    "end": "1261280"
  },
  {
    "text": "um and it greatly decreases the scrape time uh and the scrape size uh and basically unlocks horizontal",
    "start": "1261280",
    "end": "1269120"
  },
  {
    "text": "scaling um so we also have another KSM instance KSM Cube State metrics uh for",
    "start": "1269120",
    "end": "1274440"
  },
  {
    "text": "non node Paradigm metrics so things like job metrics or service metrics uh it",
    "start": "1274440",
    "end": "1279880"
  },
  {
    "text": "kind of runs off on its own and is not shed so coming from the vendor solution",
    "start": "1279880",
    "end": "1286240"
  },
  {
    "text": "uh we assume these metrics would have a lot more attributes than they did sort of out of the box um the metrics from",
    "start": "1286240",
    "end": "1292679"
  },
  {
    "text": "the scrape job don't have exactly the attributes in the way we wanted U mainly because they're from the pre- otel days",
    "start": "1292679",
    "end": "1299279"
  },
  {
    "text": "so you know really sort of some Nuance between Prometheus and open Telemetry uh",
    "start": "1299279",
    "end": "1304360"
  },
  {
    "text": "but of course the collector provides really great functionality and it's really powerful uh ability to process",
    "start": "1304360",
    "end": "1310200"
  },
  {
    "text": "metrics uh via processors in a very flexible way uh first we have the attributes",
    "start": "1310200",
    "end": "1317200"
  },
  {
    "text": "processor which updates these data point attributes to match open Telemetry semantic",
    "start": "1317200",
    "end": "1322840"
  },
  {
    "text": "conventions uh open Telemetry semantic conventions are basically standard naming patterns that exist so that way",
    "start": "1322840",
    "end": "1329159"
  },
  {
    "text": "we can unify our Telemetry data so you can see it change like pod and namespace to the K.P pod. name and",
    "start": "1329159",
    "end": "1337799"
  },
  {
    "text": "namespace uh next we use the group by attributes processor to basically group these data points into a parent resource",
    "start": "1337799",
    "end": "1345320"
  },
  {
    "text": "um so in open Telemetry there are resource attributes and data point attributes whereas in Prometheus you",
    "start": "1345320",
    "end": "1351159"
  },
  {
    "text": "there's just a single layer of labels um and this is also a prere for the next processor we use which is the",
    "start": "1351159",
    "end": "1358480"
  },
  {
    "text": "katees attributes processor this basically queries the API server on behalf of that node similar to how KSM",
    "start": "1358480",
    "end": "1364960"
  },
  {
    "text": "did um shed along the node and it allows us to map things like",
    "start": "1364960",
    "end": "1370360"
  },
  {
    "text": "the Pod as you see here the status of the Pod uh to the demon set it's on as well as the cluster it's on so this sort",
    "start": "1370360",
    "end": "1377320"
  },
  {
    "text": "of decorates it with more contextual information uh before we send it off uh to our Central",
    "start": "1377320",
    "end": "1384679"
  },
  {
    "text": "injust uh next we have a lot of pro uh local Prometheus scrape Targets on our clusters so you know a lot of utility",
    "start": "1384679",
    "end": "1392320"
  },
  {
    "text": "deployments like sto and open policy agent uh have Prometheus endpoints also",
    "start": "1392320",
    "end": "1397559"
  },
  {
    "text": "our Legacy system supported Prometheus so many of our existing services are already instrumented in prom and have",
    "start": "1397559",
    "end": "1403360"
  },
  {
    "text": "the endpoint so for these we actually created another uh Edge uh stateful set",
    "start": "1403360",
    "end": "1410080"
  },
  {
    "text": "collector so this is another uh deployment of The Collector and we basically asked service owners to",
    "start": "1410080",
    "end": "1415600"
  },
  {
    "text": "annotate their services with standard Prometheus annotations like the ones you see in the operator and using the Prometheus",
    "start": "1415600",
    "end": "1422760"
  },
  {
    "text": "receiver we do service Discovery to find these scrape targets much like you would with normal",
    "start": "1422760",
    "end": "1428120"
  },
  {
    "text": "preus um we then use a Target allocator which actually comes with the open Telemetry operator uh this is a tertiary",
    "start": "1428120",
    "end": "1436440"
  },
  {
    "text": "deployment that distributes scrape targets among the collectors so once again this unlocks",
    "start": "1436440",
    "end": "1442080"
  },
  {
    "text": "horizontal scaling and the more promethus scrapes there are uh the more collectors we can spawn and distribute",
    "start": "1442080",
    "end": "1450120"
  },
  {
    "text": "that uh those scrape jobs uh just like the other collection scenarios we enrich these metrics and",
    "start": "1450120",
    "end": "1456080"
  },
  {
    "text": "then send them onto our Central inest finally we have use cases like",
    "start": "1456080",
    "end": "1461840"
  },
  {
    "text": "database or device uh or network device metrics and as you could see from the",
    "start": "1461840",
    "end": "1467279"
  },
  {
    "text": "previous part my talk these are somewhat orthogonal to our existing collections infrastructure which mainly sits in",
    "start": "1467279",
    "end": "1473240"
  },
  {
    "text": "kubernetes um maybe these need to run on other Hardware um they require Niche",
    "start": "1473240",
    "end": "1478360"
  },
  {
    "text": "collector components and uh we also have some other teams that own these and",
    "start": "1478360",
    "end": "1484520"
  },
  {
    "text": "would like to handle the collection of metrics themselves so we use the open Telemetry",
    "start": "1484520",
    "end": "1491120"
  },
  {
    "text": "operator for deployment and collection or management of collectors uh it's a really nice way of",
    "start": "1491120",
    "end": "1497600"
  },
  {
    "text": "uh simplifying deployment for us and we basically allow and even encourage other",
    "start": "1497600",
    "end": "1502679"
  },
  {
    "text": "teams with these Niche scenarios to implement their own instances of the C of their own",
    "start": "1502679",
    "end": "1508279"
  },
  {
    "text": "collectors um they still report to our Central inest collectors which still gives us full control of the inest and",
    "start": "1508279",
    "end": "1514840"
  },
  {
    "text": "the way it's coming so this covers most of the use cases for Telemetry on our",
    "start": "1514840",
    "end": "1522120"
  },
  {
    "text": "collectors one case study we've had with the collector where we really could not find an immediate solution of ailable",
    "start": "1522120",
    "end": "1528039"
  },
  {
    "text": "Upstream is metrics aggregation so we run simulations on hundreds of thousands of VMS and while",
    "start": "1528039",
    "end": "1534720"
  },
  {
    "text": "we want to get metrics on them uh we don't necessarily need the host level granularity for the cost um you know you",
    "start": "1534720",
    "end": "1541080"
  },
  {
    "text": "can think it's hundreds or even millions of unique time series so we came up with a way of",
    "start": "1541080",
    "end": "1547720"
  },
  {
    "text": "basically aggregating them um to still represent you know that population of uh",
    "start": "1547720",
    "end": "1555799"
  },
  {
    "text": "VMS without all the unique time series aggregate on the back end so initially we built this with some",
    "start": "1555799",
    "end": "1562840"
  },
  {
    "text": "collector contrib repo processors um which worked well uh so things like the",
    "start": "1562840",
    "end": "1568559"
  },
  {
    "text": "metric transforms the group by attributes the batch processors we basically kind of put them together and",
    "start": "1568559",
    "end": "1573960"
  },
  {
    "text": "had to alter them a little bit uh but eventually we made our own custom processor for this uh we used the open",
    "start": "1573960",
    "end": "1580080"
  },
  {
    "text": "Telemetry collector Builder which is just a really easy way of spinning your own open Telemetry collector image uh",
    "start": "1580080",
    "end": "1586960"
  },
  {
    "text": "based on just adding and removing components via go modules and basically this custom",
    "start": "1586960",
    "end": "1593200"
  },
  {
    "text": "processor that we made is part of that image and it Aggregates via accumulated windows in memory uh and then emits them",
    "start": "1593200",
    "end": "1601360"
  },
  {
    "text": "based on time uh the bottom graphs show the VM counts over time with sort of the out of thebox uh first uh version we",
    "start": "1601360",
    "end": "1609200"
  },
  {
    "text": "created and then with our custom processor that handles it a lot",
    "start": "1609200",
    "end": "1614320"
  },
  {
    "text": "smoother and some of the metrics we actually aggregate in histogram RS um which allow us to have uh heat maps on",
    "start": "1614320",
    "end": "1621320"
  },
  {
    "text": "really large VM distributions with only a like a few unique time series on the back end so like this uh heat map on the",
    "start": "1621320",
    "end": "1629840"
  },
  {
    "text": "top right it could only be maybe 60 70 time series you know representing",
    "start": "1629840",
    "end": "1634960"
  },
  {
    "text": "hundreds of thousands of points or hundreds of thousands of VMS all these collection systems sent to",
    "start": "1634960",
    "end": "1641720"
  },
  {
    "text": "our Central ingest uh here we normalize it uh if it hasn't been done already sample and then",
    "start": "1641720",
    "end": "1647600"
  },
  {
    "text": "out to our multiple backends due to the shared services model uh we own this cluster as the",
    "start": "1647600",
    "end": "1654480"
  },
  {
    "text": "observe body team so this scenario works best for us we're able to roll out quicker have more control over it",
    "start": "1654480",
    "end": "1660760"
  },
  {
    "text": "compared to the other multi- tended clusters where you know deployment is a little slower uh but it may differ by scenario",
    "start": "1660760",
    "end": "1667960"
  },
  {
    "text": "and your organ organizational structure one major benefit of this is it encapsulates observability as a",
    "start": "1667960",
    "end": "1674600"
  },
  {
    "text": "service so we basically front the vendor backends with our own OT LP endpoint and this allows for consumable",
    "start": "1674600",
    "end": "1681559"
  },
  {
    "text": "Solutions with other teams as I mentioned earlier it also gives us a lot of control around the Telemetry we send",
    "start": "1681559",
    "end": "1688799"
  },
  {
    "text": "basically everything that goes to our backends is coming through here um so we have the ability to also do composite",
    "start": "1688799",
    "end": "1696039"
  },
  {
    "text": "things across clusters like Trace sampling if we need to but it comes to the cost of",
    "start": "1696039",
    "end": "1701840"
  },
  {
    "text": "maintaining a really high availability as it is a single point of failure so that's it for me uh Jason's",
    "start": "1701840",
    "end": "1708120"
  },
  {
    "text": "going to talk about a few more considerations when doing a wholesale migration thanks yeah so with this section um",
    "start": "1708120",
    "end": "1717279"
  },
  {
    "text": "we're talking about doing the whole thing so we talked about replacing the agent on all the nodes and having that",
    "start": "1717279",
    "end": "1723440"
  },
  {
    "text": "be based on things like open t open Telemetry collector open source stuff",
    "start": "1723440",
    "end": "1728799"
  },
  {
    "text": "but now we're talking about replacing the entire observability system and all of the new complexities that you get with that um as I said before we used to",
    "start": "1728799",
    "end": "1736200"
  },
  {
    "text": "use data dog for this and now we're switching to um to chronosphere as our main backend for metrics and",
    "start": "1736200",
    "end": "1741559"
  },
  {
    "text": "tracing and with this uh the sort of the single biggest issue that happens is on",
    "start": "1741559",
    "end": "1748840"
  },
  {
    "text": "the read path so data dog has their own query language uh and then konis uses",
    "start": "1748840",
    "end": "1754320"
  },
  {
    "text": "the um they expose promql the sort of the sort of standard Prometheus format and these two things are not the same so",
    "start": "1754320",
    "end": "1761640"
  },
  {
    "text": "there's a huge amount of um effort that goes into translation and managing",
    "start": "1761640",
    "end": "1768000"
  },
  {
    "text": "um the translation process and trying to do that in a way that doesn't disrupt the teams very much our approach to that",
    "start": "1768000",
    "end": "1774559"
  },
  {
    "text": "is kind of um a combination of Leaning really heavily into automation as much as we can and designing a process that's",
    "start": "1774559",
    "end": "1782200"
  },
  {
    "text": "largely automation driven but at the end of the day you need a lot of eyes on um",
    "start": "1782200",
    "end": "1787799"
  },
  {
    "text": "the work that's going through and so um part of in our case we're getting some",
    "start": "1787799",
    "end": "1793039"
  },
  {
    "text": "assistance from chronosphere Team to help with translating like dashbo boards and monitors over um but even with that",
    "start": "1793039",
    "end": "1800600"
  },
  {
    "text": "with the amount of stuff we have to move um we need Automation and by automation",
    "start": "1800600",
    "end": "1805799"
  },
  {
    "text": "I'm talking like we have a process where teams will we'll ask teams to like hey",
    "start": "1805799",
    "end": "1811120"
  },
  {
    "text": "go look at all your assets that you have in data dog and tag them all up in some way so that we can find them uh in some",
    "start": "1811120",
    "end": "1818080"
  },
  {
    "text": "sort of you know uniform way that put some pressure on the team to basically figure out like what are you actually",
    "start": "1818080",
    "end": "1823880"
  },
  {
    "text": "using and provides a really good first pass at cutting away some of the R um and then when we have things kind of",
    "start": "1823880",
    "end": "1830679"
  },
  {
    "text": "tagged up we have automation that pulls all the um the dashboards and monitors",
    "start": "1830679",
    "end": "1835760"
  },
  {
    "text": "from in this case data dog and we have them in some sort of format and then we are working then we work to basically",
    "start": "1835760",
    "end": "1841760"
  },
  {
    "text": "translate that format into um in this case a grafana Json dashboard format",
    "start": "1841760",
    "end": "1846919"
  },
  {
    "text": "which chronosphere supports so um the other cool part about the uh the sort of",
    "start": "1846919",
    "end": "1853519"
  },
  {
    "text": "adherence to things like graan and Json it allows us to have more flexibility as",
    "start": "1853519",
    "end": "1858600"
  },
  {
    "text": "well so you know we actually chronosphere has a front end that has dashboards and uh a trace product but we",
    "start": "1858600",
    "end": "1865840"
  },
  {
    "text": "also have other use cases that involve and kind of require grafana like we have situations where we've got data in big",
    "start": "1865840",
    "end": "1872120"
  },
  {
    "text": "query or we want to maybe pull in metrics directly from gcp and that's just not really supported in a lot of uh",
    "start": "1872120",
    "end": "1878799"
  },
  {
    "text": "vendor products and um so we have an internal graphon as well now uh it's",
    "start": "1878799",
    "end": "1885639"
  },
  {
    "text": "kind of cool that the graphon uh Json format exists because um we could have",
    "start": "1885639",
    "end": "1891399"
  },
  {
    "text": "the same dashboard effectively live in both systems if we want to help further manage this down the road we've uh wrote",
    "start": "1891399",
    "end": "1899279"
  },
  {
    "text": "internally a kubernetes operator that's like the observability operator and what that does is like instead of um we have",
    "start": "1899279",
    "end": "1906720"
  },
  {
    "text": "had in the past like some some adherence to config as code and we're trying to lean more heavily into that and so the",
    "start": "1906720",
    "end": "1912880"
  },
  {
    "text": "cool part about this is you can Define like your monitors and your alerts as like kubernetes custom resources that",
    "start": "1912880",
    "end": "1920080"
  },
  {
    "text": "our operator understands and then the operator can reconcile them against whatever the back end is so it could be",
    "start": "1920080",
    "end": "1926039"
  },
  {
    "text": "that it creates a grafana dashboard CR which then the grafana operator is happy to you know create a dashboard for or we",
    "start": "1926039",
    "end": "1933519"
  },
  {
    "text": "um actually provision it in chronosphere and this opens up the ability to um do more interesting things with monitors",
    "start": "1933519",
    "end": "1939840"
  },
  {
    "text": "and and things later on like we could um have some like monitor redundancy within",
    "start": "1939840",
    "end": "1945120"
  },
  {
    "text": "our cluster if we don't want to have them all firing centrally or something like that so that's pretty cool um we",
    "start": "1945120",
    "end": "1952480"
  },
  {
    "text": "are using sloth for slos um because chronosphere is prom uh based and if you",
    "start": "1952480",
    "end": "1959519"
  },
  {
    "text": "haven't heard of sloth it is a way for you to Define SLO targets and then it will spit out a bunch of um sort of",
    "start": "1959519",
    "end": "1966840"
  },
  {
    "text": "recording rules and uh Prometheus alert manager rules that are are use those",
    "start": "1966840",
    "end": "1972320"
  },
  {
    "text": "recording rules and that help you sort of roll up and get the nice slos that you want uh this was kind of important",
    "start": "1972320",
    "end": "1977960"
  },
  {
    "text": "for us to tackle because um data dog has their own SLO product that we had to that we had a lot of investment",
    "start": "1977960",
    "end": "1984519"
  },
  {
    "text": "in um as far as monitoring goes the",
    "start": "1984519",
    "end": "1989639"
  },
  {
    "text": "approach that we've taken and in general for migration what worked for us was our",
    "start": "1989639",
    "end": "1994919"
  },
  {
    "text": "clusters we have like a few like gen pop clusters but we also have some that are more like just a little bit more of",
    "start": "1994919",
    "end": "2001399"
  },
  {
    "text": "special for certain teams and we're trying to migrate everything on like a cluster by cluster basis and that's like",
    "start": "2001399",
    "end": "2006799"
  },
  {
    "text": "what we're in the middle of right now um that works the best because it's easier to just turn a Damon set like off um if",
    "start": "2006799",
    "end": "2013399"
  },
  {
    "text": "you can make sure that every all the use cases are taken care of and especially in the case of dead dog they charge by",
    "start": "2013399",
    "end": "2018840"
  },
  {
    "text": "the host so you kind of have to turn everything off if you want to um stop double paint uh we have about like a one",
    "start": "2018840",
    "end": "2025720"
  },
  {
    "text": "month window that we're um using to basically move people over to a dual",
    "start": "2025720",
    "end": "2031360"
  },
  {
    "text": "shipping system all the stuff's going into both places we make sure that we didn't break anything in the old system",
    "start": "2031360",
    "end": "2036600"
  },
  {
    "text": "and then we we make sure that uh the new system has parody and once we have enough confidence in that we're then",
    "start": "2036600",
    "end": "2042840"
  },
  {
    "text": "able to um cut the cord and move them over so that's the way that we've been um approaching this but it really is",
    "start": "2042840",
    "end": "2049240"
  },
  {
    "text": "going to depend a lot on um on your organization these are just some ideas so uh just conclusion it's",
    "start": "2049240",
    "end": "2057599"
  },
  {
    "text": "actually a really good time to invest in Nel actually um there are always going to be little things you need to deal",
    "start": "2057599",
    "end": "2062679"
  },
  {
    "text": "with but uh in our experience it's been uh pretty nice to there's a lot of off",
    "start": "2062679",
    "end": "2067800"
  },
  {
    "text": "the-shelf stuff that just works and there's been a lot of bugs that have been fixed already by the time we got to them the open TL collector is an",
    "start": "2067800",
    "end": "2074800"
  },
  {
    "text": "absolute Workhorse we use it for basically everything on the right path and we're looking at more interesting",
    "start": "2074800",
    "end": "2081040"
  },
  {
    "text": "things to do with it in the future and uh lastly I'll say to read the code because um the docs could use",
    "start": "2081040",
    "end": "2087919"
  },
  {
    "text": "some work uh but the code is there and the code will not only help you understand uh sort of how everything is",
    "start": "2087919",
    "end": "2094358"
  },
  {
    "text": "working under the hood and help you with tuning things but it'll also maybe give you ideas of how you can um leverage",
    "start": "2094359",
    "end": "2100520"
  },
  {
    "text": "things in the future so with that um thanks very much I don't I think we kind of wanted to give a lot of attention to",
    "start": "2100520",
    "end": "2107200"
  },
  {
    "text": "the content so we didn't leave a lot of time for the uh microphone questions but Kevin and I are more than happy to sit",
    "start": "2107200",
    "end": "2114119"
  },
  {
    "text": "here and have a little huddle with anybody who wants to know more details because there's a lot of stuff I we couldn't really cover here just for the",
    "start": "2114119",
    "end": "2120160"
  },
  {
    "text": "for time but um thanks very much for [Applause]",
    "start": "2120160",
    "end": "2125800"
  },
  {
    "text": "coming",
    "start": "2125800",
    "end": "2128800"
  }
]
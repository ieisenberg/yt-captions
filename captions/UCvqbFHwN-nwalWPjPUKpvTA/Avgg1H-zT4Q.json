[
  {
    "text": "so welcome everyone good to see you here uh uh I'm Marcus Letterman from Intel",
    "start": "120",
    "end": "6120"
  },
  {
    "text": "working as a cloud orchestration software engineer there mostly working on the resource management area in",
    "start": "6120",
    "end": "13200"
  },
  {
    "text": "kubernetes and the runtimes hello everyone thanks for joining my name is Peter hunt I'm a senior software",
    "start": "13200",
    "end": "19140"
  },
  {
    "text": "engineer at Red Hat working primarily on cryo but sometimes cubelet signode things podman other container runtime",
    "start": "19140",
    "end": "26100"
  },
  {
    "text": "related Technologies and today we're going to be talking about class resources kubernetes is fastest way of",
    "start": "26100",
    "end": "32160"
  },
  {
    "text": "shushing noisy neighbors so I think we don't really need",
    "start": "32160",
    "end": "38219"
  },
  {
    "text": "um a button I don't think we really need to um argue about this too much but in",
    "start": "38219",
    "end": "43800"
  },
  {
    "text": "kubernetes we don't really expect all workloads to be treated equally um and there's been you know the native",
    "start": "43800",
    "end": "49739"
  },
  {
    "text": "construct in kubernetes that's you know represented this which is the qos quality of service",
    "start": "49739",
    "end": "55559"
  },
  {
    "text": "qos classes now represent uh specify CPU and memory limits and requests",
    "start": "55559",
    "end": "62359"
  },
  {
    "text": "another mechanism that's been in kubernetes since 119 that kind of does qoso it's not really called that is CPU",
    "start": "62359",
    "end": "70260"
  },
  {
    "text": "management which allow you to pin certain containers to certain CPUs and",
    "start": "70260",
    "end": "75780"
  },
  {
    "text": "that allows you to further customize the quality of service even though they're not really called qos classes there but",
    "start": "75780",
    "end": "81780"
  },
  {
    "text": "ultimately there's going to be more resources on a node to guarantee the quality of service of and that's kind of",
    "start": "81780",
    "end": "89520"
  },
  {
    "text": "the issue that we're looking at solving so the overall mission is we're looking to improve the quality of service of",
    "start": "89520",
    "end": "96000"
  },
  {
    "text": "applications to enable controls that don't fit into the current kubernetes resource model the three ones that were",
    "start": "96000",
    "end": "103259"
  },
  {
    "text": "originally targeting that we're going to be talking about today are cache memory bandwidth and disk IO and the ultimate",
    "start": "103259",
    "end": "109619"
  },
  {
    "text": "plan is to add a fundamental resource type to kubernetes that allows us to express those as well as future resource",
    "start": "109619",
    "end": "116579"
  },
  {
    "text": "types so properties of Qs class resource that we're going to describe today",
    "start": "116579",
    "end": "123320"
  },
  {
    "text": "that you know will eventually be trying to add to kubernetes is we have a recent",
    "start": "123320",
    "end": "129239"
  },
  {
    "text": "request class identifier instead of the amount of capacity So currently qos class resources specify the amount of",
    "start": "129239",
    "end": "136560"
  },
  {
    "text": "CPU and memory that pod wants but we want this of this to be opaque to",
    "start": "136560",
    "end": "142620"
  },
  {
    "text": "kubernetes and be instead of specified in a container runtime so you would",
    "start": "142620",
    "end": "148620"
  },
  {
    "text": "specify in a container you know I want my qos resource X to for this pod to be",
    "start": "148620",
    "end": "154560"
  },
  {
    "text": "Class A uh in addition the uh",
    "start": "154560",
    "end": "160500"
  },
  {
    "text": "we expect there to be multiple containers that are able to go into the same class in this case we have",
    "start": "160500",
    "end": "165900"
  },
  {
    "text": "container one two and three are all in class A the container four uh is you know we want some sort of different",
    "start": "165900",
    "end": "172019"
  },
  {
    "text": "topology for that so we're going to give it a separate class and finally we want a new end an",
    "start": "172019",
    "end": "178319"
  },
  {
    "text": "innumerable set of classes so you can have any number of classes representing",
    "start": "178319",
    "end": "183420"
  },
  {
    "text": "the specified resource that you're trying to represent so you know we I mentioned earlier we",
    "start": "183420",
    "end": "189780"
  },
  {
    "text": "were going to talk about a couple of examples and so we're going to go through three different uh",
    "start": "189780",
    "end": "194940"
  },
  {
    "text": "resources that we're looking to express with uh qos cost resources to start the",
    "start": "194940",
    "end": "201060"
  },
  {
    "text": "first one is Cash allocation so in Linux you can use the rest control FS interface which is in SFS to specify",
    "start": "201060",
    "end": "211200"
  },
  {
    "text": "cache allocation and this is already inherently class based there's a name for uh you know different caches that",
    "start": "211200",
    "end": "218400"
  },
  {
    "text": "you'd allocate to different processes and I'd ideally you know what we would",
    "start": "218400",
    "end": "223560"
  },
  {
    "text": "get out of this is being able to hide some Hardware details from the user the you know specific caches already",
    "start": "223560",
    "end": "231860"
  },
  {
    "text": "represent you know are a good example of what we're trying to represent with the classes because there are you know M",
    "start": "231860",
    "end": "239459"
  },
  {
    "text": "groups of class of uh you know groups of caches but we have an applications or",
    "start": "239459",
    "end": "245819"
  },
  {
    "text": "pods or containers that would actually fit into those caches",
    "start": "245819",
    "end": "250920"
  },
  {
    "text": "another example would be block IO So currently block i o is going to be",
    "start": "250920",
    "end": "257280"
  },
  {
    "text": "pretty Hardware dependent even though it's specified through the c groups you have different nodes you're going to",
    "start": "257280",
    "end": "262380"
  },
  {
    "text": "have totally different hardware and representing that in the cube API might be a little bit complex or challenging so that is an appealing aspect of the",
    "start": "262380",
    "end": "269460"
  },
  {
    "text": "opaque nature of these class resources where only the container runtime has to be aware of the differing Hardware",
    "start": "269460",
    "end": "275580"
  },
  {
    "text": "levels in since the container runtime you know this configuration of that could be node specific you can have for",
    "start": "275580",
    "end": "283199"
  },
  {
    "text": "different nodes the different Hardware could be accurately represented so block i o specifies throttling",
    "start": "283199",
    "end": "290419"
  },
  {
    "text": "parameters through device so here's the runtime spec that would describe the",
    "start": "290419",
    "end": "295560"
  },
  {
    "text": "block i o and to the left is the uh what actually is written in the C group hierarchy",
    "start": "295560",
    "end": "302220"
  },
  {
    "text": "so I'm going to go through a I'm going to walk through like an example of what we're kind of imagining uh the value of",
    "start": "302220",
    "end": "308820"
  },
  {
    "text": "this feature could be so imagine a very realistic scenario in which we have our emergency alarm system that will go off",
    "start": "308820",
    "end": "315479"
  },
  {
    "text": "if there's a natural disaster we want you know that to be very fast and be reactive to situations so that we can",
    "start": "315479",
    "end": "321780"
  },
  {
    "text": "get people safe quicker and then we have a rock band website that you know is going to handle the tour dates and all",
    "start": "321780",
    "end": "328979"
  },
  {
    "text": "of the tickets for a popular rock band nearby so as you know if you weren't to",
    "start": "328979",
    "end": "334199"
  },
  {
    "text": "try very hard to separate those two you would end up looking it would look like something like this where you know both",
    "start": "334199",
    "end": "340800"
  },
  {
    "text": "of them are sharing most of the resources you know the memory and CPU they're gonna have you know differing",
    "start": "340800",
    "end": "347220"
  },
  {
    "text": "amounts maybe but they're going to end up on you know the same CPUs and maybe if there's the rock band websites having",
    "start": "347220",
    "end": "353160"
  },
  {
    "text": "something happen um the emergency bar might get a little interrupted and that's not very good we want the emergency alarm to be able to",
    "start": "353160",
    "end": "360060"
  },
  {
    "text": "be isolated so you know now in kubernetes we can represent this with a static CPU policy",
    "start": "360060",
    "end": "367500"
  },
  {
    "text": "so have them separated on CPU cores that's a little bit better um and have you know the kuos classes be",
    "start": "367500",
    "end": "373139"
  },
  {
    "text": "represented in the limits of requests for the pods but that still doesn't really uh give us all that we want I",
    "start": "373139",
    "end": "380100"
  },
  {
    "text": "mean there's all these other resources that we've mentioned plus others that you know need to be broken up and still",
    "start": "380100",
    "end": "386220"
  },
  {
    "text": "thrashing on the rock band website could cause interruptions with the emergency alarm",
    "start": "386220",
    "end": "392220"
  },
  {
    "text": "so for example something that we could do is uh with your class resource",
    "start": "392220",
    "end": "397259"
  },
  {
    "text": "feature we could give the emergency alarm an exclusive cache with rdt and so",
    "start": "397259",
    "end": "403440"
  },
  {
    "text": "that would allow it to you know be a little bit more isolated from the rock band website",
    "start": "403440",
    "end": "410400"
  },
  {
    "text": "we could also throttle the memory bandwidth of the rock band website so even if there's a tour that's just been",
    "start": "410400",
    "end": "415979"
  },
  {
    "text": "announced you know spike in traffic won't cause the memory bandwidth to be taken up and be taken away from our",
    "start": "415979",
    "end": "421319"
  },
  {
    "text": "emergency alarm system we can also do uh we can give the",
    "start": "421319",
    "end": "426600"
  },
  {
    "text": "emergency alarm system block i o priority um you know give it a higher weight so it's able to get the blockile resources",
    "start": "426600",
    "end": "433440"
  },
  {
    "text": "it needs and we do the opposite for the rock band website and throttle it so",
    "start": "433440",
    "end": "438900"
  },
  {
    "text": "that uh you know it's not able to use too many resources so ultimately what we get with you know",
    "start": "438900",
    "end": "445319"
  },
  {
    "text": "this kind of configuration is a situation in which our emergency alarm system you know is finally able to get",
    "start": "445319",
    "end": "451259"
  },
  {
    "text": "some peace in its multi-tenant kubernetes cluster and able to get the resources that it needs so it can you",
    "start": "451259",
    "end": "456300"
  },
  {
    "text": "know help the people that need helping and not be interfered by those pesky rock bands",
    "start": "456300",
    "end": "461819"
  },
  {
    "text": "so I'm going to describe a little bit about what we currently have available for this uh in kubernetes and actually",
    "start": "461819",
    "end": "468360"
  },
  {
    "text": "in kubernetes it's not really there we have some support in the container runtime so it's cryo and containerdy",
    "start": "468360",
    "end": "474000"
  },
  {
    "text": "have support for using rest control FS to control the cache and memory bandwidth as well as the block i o I'm",
    "start": "474000",
    "end": "481560"
  },
  {
    "text": "using the Block iocq C group controller but it's only in the runtime so you",
    "start": "481560",
    "end": "487500"
  },
  {
    "text": "basically use a pod annotation to specify the um the control oh cool",
    "start": "487500",
    "end": "494460"
  },
  {
    "text": "know what's that I see um you use a use a config file in the",
    "start": "494460",
    "end": "499979"
  },
  {
    "text": "container runtime and that corresponds to a config file that specifies that",
    "start": "499979",
    "end": "505440"
  },
  {
    "text": "specific resource and then you use an annotation to specify that resource for",
    "start": "505440",
    "end": "511080"
  },
  {
    "text": "the Pod and that in the container runtime interprets that and then does something with it",
    "start": "511080",
    "end": "516839"
  },
  {
    "text": "this is you know this works this functions we can get this kind of isolation but we you know there's it's",
    "start": "516839",
    "end": "522959"
  },
  {
    "text": "not the best user experience for one it's not at all related to kubernetes you can so there's no documentation it's",
    "start": "522959",
    "end": "531540"
  },
  {
    "text": "only really for early adopters people who are intimately aware with the feature it's also a a pretty bad user",
    "start": "531540",
    "end": "538019"
  },
  {
    "text": "experience I mean we're using an annotation to specify something that's going to be specified like three or four",
    "start": "538019",
    "end": "543839"
  },
  {
    "text": "levels down depending of the stack depending how you look at it so there's no visibility as to what resources are",
    "start": "543839",
    "end": "550080"
  },
  {
    "text": "actually available on which nodes no support in the scheduler to actually be able to delegate which you know pod",
    "start": "550080",
    "end": "555839"
  },
  {
    "text": "should be going to which nodes depending on the classes that they want you just have to know what what there is",
    "start": "555839",
    "end": "562620"
  },
  {
    "text": "um and where to put it so it's not user friendly at all and I'm going to switch over to Marcus",
    "start": "562620",
    "end": "569459"
  },
  {
    "text": "to describe on the future that we would like to get to",
    "start": "569459",
    "end": "574680"
  },
  {
    "text": "so yes uh let's get get to the deeper technical design of our proposed",
    "start": "574680",
    "end": "582660"
  },
  {
    "text": "enhancement in kubernetes and first I'm describing the the kind of",
    "start": "582660",
    "end": "588420"
  },
  {
    "text": "control flow that we've envisioned for the cures class resources in the kind of",
    "start": "588420",
    "end": "594060"
  },
  {
    "text": "complete solution in kubernetes so here we have a simplified view of a",
    "start": "594060",
    "end": "600540"
  },
  {
    "text": "kubernetes cluster with the API server on a scheduler from the control plane then one node depicted in in this in",
    "start": "600540",
    "end": "607800"
  },
  {
    "text": "this figure and Hublot and the container runtime running there on the system then",
    "start": "607800",
    "end": "613399"
  },
  {
    "text": "representing the operating system and it and its services",
    "start": "613399",
    "end": "618959"
  },
  {
    "text": "so basically everything starts with the container runtime initializing or discovering",
    "start": "618959",
    "end": "625700"
  },
  {
    "text": "the Qs classical resources that are available in the system",
    "start": "625700",
    "end": "630720"
  },
  {
    "text": "so it might be something that the container runtime actually configures itself or it might be in some cases",
    "start": "630720",
    "end": "638040"
  },
  {
    "text": "something that is pre-configured by the node or cluster admin and then the",
    "start": "638040",
    "end": "643500"
  },
  {
    "text": "runtime only discovers what is what is available on the system anyway it gets the information about",
    "start": "643500",
    "end": "649680"
  },
  {
    "text": "available QR class resources from the system then it hands that information",
    "start": "649680",
    "end": "654959"
  },
  {
    "text": "over the cubelet which then in turn updates the node node status object on",
    "start": "654959",
    "end": "664079"
  },
  {
    "text": "the API server so we get the information there in the node capacity that okay these three resources cures classic",
    "start": "664079",
    "end": "671459"
  },
  {
    "text": "sources a b and c are available and then the specific classes of each each resource type",
    "start": "671459",
    "end": "680040"
  },
  {
    "text": "then uh pod pod spec or police created in the API server it",
    "start": "680040",
    "end": "687540"
  },
  {
    "text": "has some [Music] specific requests for the Curious class",
    "start": "687540",
    "end": "693060"
  },
  {
    "text": "resources in this in this case uh report request like class gold from resource a",
    "start": "693060",
    "end": "700620"
  },
  {
    "text": "and and class high priority from resource C scheduler fix that pod from the API",
    "start": "700620",
    "end": "708420"
  },
  {
    "text": "server and that's the normal node filtering and fitting trying to",
    "start": "708420",
    "end": "715019"
  },
  {
    "text": "find a suitable node that could satisfy the QRS class resource requests",
    "start": "715019",
    "end": "722940"
  },
  {
    "text": "put put there in the Pod spec then it finds that okay our node X actually can satisfy the requests so",
    "start": "722940",
    "end": "732980"
  },
  {
    "text": "resource a class roll down and this high priority for resource type c are",
    "start": "732980",
    "end": "738240"
  },
  {
    "text": "available on nodex it schedules schedules the pod to the node cubelet picks the top",
    "start": "738240",
    "end": "747200"
  },
  {
    "text": "and and raise the raise the Qs class results requests from the Pod spec",
    "start": "747200",
    "end": "754079"
  },
  {
    "text": "and hence that information over the CRA API to to the runtime",
    "start": "754079",
    "end": "760200"
  },
  {
    "text": "and then lastly and the runtime then uh",
    "start": "760200",
    "end": "766019"
  },
  {
    "text": "is a enforcing the curious class resource assignment of the",
    "start": "766019",
    "end": "772740"
  },
  {
    "text": "containers on the container processes on the system so that's that's how it's",
    "start": "772740",
    "end": "779160"
  },
  {
    "text": "we're envisioning it to work one key idea in our proposal",
    "start": "779160",
    "end": "786180"
  },
  {
    "text": "is to make the life of kubernetes as easy as possible uh",
    "start": "786180",
    "end": "791940"
  },
  {
    "text": "so making the Curious class resources as opaque to kubernetes as possible",
    "start": "791940",
    "end": "798120"
  },
  {
    "text": "so basically the configuration on management of curious class resources would be handled by the content around",
    "start": "798120",
    "end": "805320"
  },
  {
    "text": "time so kubernetes doesn't need to know actually about anything about the",
    "start": "805320",
    "end": "810600"
  },
  {
    "text": "Implement Implement implementation details of each of these curious class resources",
    "start": "810600",
    "end": "817019"
  },
  {
    "text": "so it basically knows what type of curious class sources are available and",
    "start": "817019",
    "end": "823620"
  },
  {
    "text": "what what classes in each type of resources are available on which nodes",
    "start": "823620",
    "end": "828720"
  },
  {
    "text": "but that's it it doesn't need to understand any any any more than that like what what",
    "start": "828720",
    "end": "835500"
  },
  {
    "text": "specific resource type or or class class name actually mean so it knows resource",
    "start": "835500",
    "end": "841560"
  },
  {
    "text": "types and names but class names but not much more and this would allow",
    "start": "841560",
    "end": "847019"
  },
  {
    "text": "like easy implementation of of new types of cure class resources",
    "start": "847019",
    "end": "852360"
  },
  {
    "text": "without any any changes in the in the kubernetes API or kubernetes components and one uh",
    "start": "852360",
    "end": "861779"
  },
  {
    "text": "use case we have in mind for example is uh for for a vendor to be able to",
    "start": "861779",
    "end": "868200"
  },
  {
    "text": "implement uh specific specific cures class resources for their needs",
    "start": "868200",
    "end": "875100"
  },
  {
    "text": "for example cloud service provider could write write a",
    "start": "875100",
    "end": "880800"
  },
  {
    "text": "uh controls for let's say disk or or a storage i o or network",
    "start": "880800",
    "end": "889079"
  },
  {
    "text": "network priority controls all in all we're trying to uh come up",
    "start": "889079",
    "end": "895620"
  },
  {
    "text": "with a generalized mechanism that would allow simple addition of of new QRS",
    "start": "895620",
    "end": "902279"
  },
  {
    "text": "controls and into kubernetes in the future in a future proof way",
    "start": "902279",
    "end": "909240"
  },
  {
    "text": "so the scope of the cap is uh currently kind of twofold",
    "start": "909240",
    "end": "914639"
  },
  {
    "text": "first first part is the CRI API between cubelet and the runtime so",
    "start": "914639",
    "end": "922199"
  },
  {
    "text": "we want cumulate to be able to communicate the runtime the Qs class",
    "start": "922199",
    "end": "930779"
  },
  {
    "text": "resource assignment assignments from the from the user and the other way around",
    "start": "930779",
    "end": "935820"
  },
  {
    "text": "so that the runtime is able to tell the cubelet what is actually available available on the Node we also want to",
    "start": "935820",
    "end": "944160"
  },
  {
    "text": "support in place updates of the Qs class resource",
    "start": "944160",
    "end": "949459"
  },
  {
    "text": "assignments of of running containers and currently",
    "start": "949459",
    "end": "956720"
  },
  {
    "text": "The Envision that the we would have an initial user interface",
    "start": "956720",
    "end": "962760"
  },
  {
    "text": "using pod annotations before before the kind of Port spec",
    "start": "962760",
    "end": "968820"
  },
  {
    "text": "changes and land in the kubernetes main line so similar annotation based",
    "start": "968820",
    "end": "976980"
  },
  {
    "text": "UI than what it what is currently available in the in the runtime only approach",
    "start": "976980",
    "end": "983399"
  },
  {
    "text": "and the second second uh part is then the kubernetes API so we want to extend",
    "start": "983399",
    "end": "988980"
  },
  {
    "text": "ports back to have a specific fields for for this us class resource requests",
    "start": "988980",
    "end": "995100"
  },
  {
    "text": "uh we want to update node status as well to see what is what is available on the nodes so this",
    "start": "995100",
    "end": "1002420"
  },
  {
    "text": "serves two purposes first visibility to users so they are able to see what is",
    "start": "1002420",
    "end": "1008720"
  },
  {
    "text": "available on which nodes and then also it's an enabler for enable enabler for",
    "start": "1008720",
    "end": "1015560"
  },
  {
    "text": "cube scheduler to be able to do the right thing so if I want to know that can satisfy the requests for the pod",
    "start": "1015560",
    "end": "1024020"
  },
  {
    "text": "and the third part of the kubernetes API we have in the cap at the moment is uh",
    "start": "1024020",
    "end": "1029360"
  },
  {
    "text": "is having uh permission control of of available QR",
    "start": "1029360",
    "end": "1035480"
  },
  {
    "text": "slash resources bye extending the resource quota mechanism",
    "start": "1035480",
    "end": "1041298"
  },
  {
    "text": "that is that is already available in kubernetes so uh",
    "start": "1041299",
    "end": "1048199"
  },
  {
    "text": "we think that it would be good to split the implementation in multiple phases",
    "start": "1048199",
    "end": "1055640"
  },
  {
    "text": "so first of all the first everything under the runtime",
    "start": "1055640",
    "end": "1061700"
  },
  {
    "text": "between runtime system is kind of uh implementation details and out of Auto",
    "start": "1061700",
    "end": "1066919"
  },
  {
    "text": "score of the cap but the first implementation phase would be just just a Sierra API between",
    "start": "1066919",
    "end": "1074240"
  },
  {
    "text": "cubelet and the runtime and then also Implement",
    "start": "1074240",
    "end": "1079480"
  },
  {
    "text": "interpretation of the specific special Port annotations in cubelet as the kind",
    "start": "1079480",
    "end": "1085100"
  },
  {
    "text": "of initial user interface and everything uh in in kubernetes API",
    "start": "1085100",
    "end": "1091460"
  },
  {
    "text": "and the under control plug components would be would be them uh implemented in in future phases",
    "start": "1091460",
    "end": "1099919"
  },
  {
    "text": "and with the with the cap fully implemented the user",
    "start": "1099919",
    "end": "1105860"
  },
  {
    "text": "inter user interface would look an experience would be a lot better than what what with the",
    "start": "1105860",
    "end": "1113179"
  },
  {
    "text": "runtime only approach that we currently have so everything starts similarly from the kind of runtime configuration in",
    "start": "1113179",
    "end": "1120080"
  },
  {
    "text": "this case an example of the cache cash management with with rest control",
    "start": "1120080",
    "end": "1127520"
  },
  {
    "text": "so similar thing three classes there but then uh with the runtime and cable at",
    "start": "1127520",
    "end": "1133520"
  },
  {
    "text": "support we we were able to update the no status say that okay this is available",
    "start": "1133520",
    "end": "1139280"
  },
  {
    "text": "there and that the Pod spec looks a lot cleaner as well and we can do like",
    "start": "1139280",
    "end": "1144380"
  },
  {
    "text": "proper uh input validation of the plc",
    "start": "1144380",
    "end": "1149380"
  },
  {
    "text": "for example so next we'll have a short demo",
    "start": "1149740",
    "end": "1158000"
  },
  {
    "text": "of a proof of oh [Music] sorry about that",
    "start": "1158000",
    "end": "1163779"
  },
  {
    "text": "of a of a proof of concept implementation that we currently have",
    "start": "1163820",
    "end": "1168860"
  },
  {
    "text": "so this demo will be kind of uh demonstrating the",
    "start": "1168860",
    "end": "1175160"
  },
  {
    "text": "full full complete solution with the scheduler support support uh resource",
    "start": "1175160",
    "end": "1180440"
  },
  {
    "text": "code and everything so this pre-recorded I I don't I don't trust the corporate",
    "start": "1180440",
    "end": "1186020"
  },
  {
    "text": "VPN and Wi-Fi and all all that so it's almost almost uh live it was recorded yesterday",
    "start": "1186020",
    "end": "1193460"
  },
  {
    "text": "so so in in this demo we have a",
    "start": "1193460",
    "end": "1198740"
  },
  {
    "text": "single Sim simple single node cluster uh with our",
    "start": "1198740",
    "end": "1203840"
  },
  {
    "text": "proof of concept code based on fairly recent versions of kubernetes and",
    "start": "1203840",
    "end": "1208940"
  },
  {
    "text": "acquire container runtime and uh quickly show the kind of container",
    "start": "1208940",
    "end": "1217100"
  },
  {
    "text": "runtime side configuration regarding cache allocation and and and uh and block guys away from the",
    "start": "1217100",
    "end": "1225440"
  },
  {
    "text": "previous examples already familiar so we configure three",
    "start": "1225440",
    "end": "1233000"
  },
  {
    "text": "three classes for rdt gold silver and bronze and then for Block Kyle similarly",
    "start": "1233000",
    "end": "1239179"
  },
  {
    "text": "three classes uh high priority normal and low priority",
    "start": "1239179",
    "end": "1244820"
  },
  {
    "text": "and first I'll I'll show The annotation based UI which",
    "start": "1244820",
    "end": "1251480"
  },
  {
    "text": "is not not much but anyway so in this this case we have a one one pod",
    "start": "1251480",
    "end": "1258020"
  },
  {
    "text": "with two containers and we use these special annotations for setting in this",
    "start": "1258020",
    "end": "1263179"
  },
  {
    "text": "case uh for container one like rdt class gold uh local class high priority and",
    "start": "1263179",
    "end": "1269480"
  },
  {
    "text": "then the second second container could be let's rock band side let's say with",
    "start": "1269480",
    "end": "1274760"
  },
  {
    "text": "already the class bronze and and block of low priority we create the Pod say that it's running",
    "start": "1274760",
    "end": "1282200"
  },
  {
    "text": "and then we can actually verify from the risk control",
    "start": "1282200",
    "end": "1287780"
  },
  {
    "text": "zero file system in under ccfs that actually some that pids",
    "start": "1287780",
    "end": "1294980"
  },
  {
    "text": "of of our containers were assigned to the classes that we",
    "start": "1294980",
    "end": "1300860"
  },
  {
    "text": "that really requested so silver class will be empty because nothing was was assigned there we could",
    "start": "1300860",
    "end": "1307880"
  },
  {
    "text": "do the same thing for Block IO but it's a bit hassle to find out the correct uh",
    "start": "1307880",
    "end": "1313340"
  },
  {
    "text": "C group file system passed there so we just trust that the local parameters were",
    "start": "1313340",
    "end": "1320260"
  },
  {
    "text": "also applied correctly so next",
    "start": "1320260",
    "end": "1325400"
  },
  {
    "text": "oh then we delete the Pod and say that okay nothing is anymore in the in the",
    "start": "1325400",
    "end": "1330559"
  },
  {
    "text": "dash as far so our container was was deleted there",
    "start": "1330559",
    "end": "1337100"
  },
  {
    "text": "uh next we'll see how it looks like in this complete solution so now looking at",
    "start": "1337100",
    "end": "1343580"
  },
  {
    "text": "the node status we can see that okay we have this uh this uh type of",
    "start": "1343580",
    "end": "1349940"
  },
  {
    "text": "uh cures class resources available on the Node so block i o class is high",
    "start": "1349940",
    "end": "1355280"
  },
  {
    "text": "priority low priority and normal as we configured same for rdt bronze gold and silver and we're in this demo we have",
    "start": "1355280",
    "end": "1362360"
  },
  {
    "text": "also one like stub stub curious classroom Source doing really",
    "start": "1362360",
    "end": "1368419"
  },
  {
    "text": "nothing just for demonstrating a third third",
    "start": "1368419",
    "end": "1373880"
  },
  {
    "text": "possible resource so then we can",
    "start": "1373880",
    "end": "1380659"
  },
  {
    "text": "take a look at the how the port spec would look like so here we have about dedicated Fields fields",
    "start": "1380659",
    "end": "1389059"
  },
  {
    "text": "for the Cure class resources so similar example or corresponding",
    "start": "1389059",
    "end": "1394940"
  },
  {
    "text": "example with their example with their annotations but now we use just use a dedicated fields in the Pod spec for",
    "start": "1394940",
    "end": "1401120"
  },
  {
    "text": "that that's yeah that's running and see that it's once and then again we",
    "start": "1401120",
    "end": "1409100"
  },
  {
    "text": "can take a quick look at the rest control file system okay yeah actually we got the got new P IDs in in the in",
    "start": "1409100",
    "end": "1417260"
  },
  {
    "text": "the dash as well so the cache allocation was applied as as we requested",
    "start": "1417260",
    "end": "1424299"
  },
  {
    "text": "so next one will be like demonstrating the scheduler support so here we have a pod back with with the",
    "start": "1424400",
    "end": "1433820"
  },
  {
    "text": "uh non-existing Oddity class bar and then also a resource that doesn't exist on the Node called dummy 3. and we apply",
    "start": "1433820",
    "end": "1443240"
  },
  {
    "text": "that and then if you take a look at the uh pod status we can say that okay yeah",
    "start": "1443240",
    "end": "1449960"
  },
  {
    "text": "dummy 3 doesn't exist and and also rdt class bar is unavailable on any note so",
    "start": "1449960",
    "end": "1457159"
  },
  {
    "text": "this this pod can cannot be run if a node with the with this",
    "start": "1457159",
    "end": "1462740"
  },
  {
    "text": "dummy dummy 3 resource and an early d-class bar would appear on the on the",
    "start": "1462740",
    "end": "1468380"
  },
  {
    "text": "cluster then and the port would get get schedules of course and lastly",
    "start": "1468380",
    "end": "1474679"
  },
  {
    "text": "we'll demonstrate the resource quota how that looks like or would look like so here we have a resource quarter spec",
    "start": "1474679",
    "end": "1481840"
  },
  {
    "text": "extended with the Curious class resources so for rdt we only allow class",
    "start": "1481840",
    "end": "1487760"
  },
  {
    "text": "brands for Block IO we allow classes normal and low priority and then for",
    "start": "1487760",
    "end": "1494120"
  },
  {
    "text": "this dummy class we dummy one curious classic Source we allow the usage of",
    "start": "1494120",
    "end": "1499940"
  },
  {
    "text": "classes b c and d and we upload the quota and then",
    "start": "1499940",
    "end": "1506960"
  },
  {
    "text": "take a look at the status of that quota object and from there we can we can see that uh",
    "start": "1506960",
    "end": "1516080"
  },
  {
    "text": "the limited limits that we put in place are",
    "start": "1516080",
    "end": "1521900"
  },
  {
    "text": "actually now enforced so for RDP only on the process bronzes allowed and local",
    "start": "1521900",
    "end": "1527000"
  },
  {
    "text": "normal and low priority as we as we want it so now if we try to create a pod with",
    "start": "1527000",
    "end": "1534380"
  },
  {
    "text": "uh this or analog curious class resources so in this in this case we have like RDP class gold",
    "start": "1534380",
    "end": "1541700"
  },
  {
    "text": "which which wasn't uh wasn't allowed in the resource code",
    "start": "1541700",
    "end": "1547220"
  },
  {
    "text": "aspect we tried to create that part and it it fails because",
    "start": "1547220",
    "end": "1553159"
  },
  {
    "text": "uh already class gold was not was not allowed then with the modifier",
    "start": "1553159",
    "end": "1561020"
  },
  {
    "text": "Parts back a bit so change the rdb class from gold to bronze and",
    "start": "1561020",
    "end": "1569179"
  },
  {
    "text": "then the port can be scheduled without without any problems so",
    "start": "1569179",
    "end": "1575840"
  },
  {
    "text": "everything works fine so that's",
    "start": "1575840",
    "end": "1581299"
  },
  {
    "text": "about the demo let's go ah let's continue with the slides",
    "start": "1581299",
    "end": "1587419"
  },
  {
    "text": "okay yeah hand it over to Peter thank you Marcus",
    "start": "1587419",
    "end": "1594799"
  },
  {
    "text": "so I'm going to talk a little bit about where we're at and where we're going so",
    "start": "1594799",
    "end": "1599960"
  },
  {
    "text": "the current status of the cap when we originally submitted this talk we had",
    "start": "1599960",
    "end": "1605120"
  },
  {
    "text": "hoped that the cap would have been made it in but it's still under review we're working through some details specifically trying to figure out which",
    "start": "1605120",
    "end": "1612020"
  },
  {
    "text": "parts of the phases uh we're figuring out so we're targeting 1.27 for this work you can try it out now with just",
    "start": "1612020",
    "end": "1618559"
  },
  {
    "text": "the container runtime annotation version now if you'd like some open concerns that we have are you know the usage of",
    "start": "1618559",
    "end": "1625400"
  },
  {
    "text": "annotations in Phase One whether the cube is going to become annotation aware and pass down the proper CRI object down",
    "start": "1625400",
    "end": "1631940"
  },
  {
    "text": "to the container runtime or if the cubelet is if we're going to go for full pod API support in phase one so then the",
    "start": "1631940",
    "end": "1639980"
  },
  {
    "text": "cube API server would pass down the resource to the cubelet directly and then the qubit down to the CRI",
    "start": "1639980",
    "end": "1646700"
  },
  {
    "text": "some you know small API details here and there and then a piece of future or some",
    "start": "1646700",
    "end": "1653299"
  },
  {
    "text": "pieces of future work past that future that we just talked about we can imagine a world in which maybe we'd want to make",
    "start": "1653299",
    "end": "1660500"
  },
  {
    "text": "explicit the Pod qos class that you know currently exists where it's currently",
    "start": "1660500",
    "end": "1666020"
  },
  {
    "text": "interpreted from the resources uh you know the the CPU and memory limits and",
    "start": "1666020",
    "end": "1671240"
  },
  {
    "text": "requests but uh you know maybe one day we'd want it to be explicit and actually say Qs class is burstable and give the",
    "start": "1671240",
    "end": "1678980"
  },
  {
    "text": "container runtime bad information also we want to you know possibly",
    "start": "1678980",
    "end": "1684260"
  },
  {
    "text": "Implement new types so that we've only talked about you know the three types that we have in scope now but eventually",
    "start": "1684260",
    "end": "1690200"
  },
  {
    "text": "you can imagine maybe we have some high bandwidth or like you know some swap or",
    "start": "1690200",
    "end": "1695360"
  },
  {
    "text": "maybe some there's some Hardware special fancy Hardware that has some special fancy resource that would want to be",
    "start": "1695360",
    "end": "1702860"
  },
  {
    "text": "broken up between containers and pods like that so we also have that in as well",
    "start": "1702860",
    "end": "1708980"
  },
  {
    "text": "if you are interested in getting involved through reviewing or testing or even contributing you can check out cap",
    "start": "1708980",
    "end": "1716080"
  },
  {
    "text": "3008 it's an and you can help out over there other than that I'd like to thank",
    "start": "1716080",
    "end": "1723559"
  },
  {
    "text": "everyone for joining us and ask if there are any questions [Applause]",
    "start": "1723559",
    "end": "1736549"
  },
  {
    "text": "yes um do we want to pass around Yeah question",
    "start": "1737419",
    "end": "1744820"
  },
  {
    "text": "yeah hey thanks for the talk um I'm curious if there's any",
    "start": "1744980",
    "end": "1750440"
  },
  {
    "text": "consideration about doing something out of the box that allows for basically Fair sharing of these resources among",
    "start": "1750440",
    "end": "1757039"
  },
  {
    "text": "pods running on the like a given node like rather than configuring quality of service classes or something like that",
    "start": "1757039",
    "end": "1762679"
  },
  {
    "text": "like like would these quality of service classes let's say that all the pods running on a node have the same quality of service",
    "start": "1762679",
    "end": "1768799"
  },
  {
    "text": "class is there something in place that would like throttle the pods or like I",
    "start": "1768799",
    "end": "1776539"
  },
  {
    "text": "guess I'll just could you elaborate on on that a little bit more or like setting like limits and how that",
    "start": "1776539",
    "end": "1782840"
  },
  {
    "text": "throttling would happen rather than just like prioritization so I think it depends on the resource",
    "start": "1782840",
    "end": "1789080"
  },
  {
    "text": "right like the like different resources handle having multiple processes within",
    "start": "1789080",
    "end": "1795740"
  },
  {
    "text": "them differently um so the focus of this is kind of designating priority but theoretically",
    "start": "1795740",
    "end": "1801919"
  },
  {
    "text": "if there were multiple processes within you know block i o uh weight for",
    "start": "1801919",
    "end": "1807620"
  },
  {
    "text": "instance and they would have equal block i o weight comparatively to each other but then you know anything that has a higher one outside of that would be",
    "start": "1807620",
    "end": "1814220"
  },
  {
    "text": "treated differently",
    "start": "1814220",
    "end": "1816940"
  },
  {
    "text": "I have a question so one thing I wasn't sure is who is responsible for a managed",
    "start": "1831020",
    "end": "1837380"
  },
  {
    "text": "allocation of the resource including recycling for example when when the",
    "start": "1837380",
    "end": "1842960"
  },
  {
    "text": "party is gone now the resources need to be counted back so traditionally I think",
    "start": "1842960",
    "end": "1849320"
  },
  {
    "text": "the current situation is the Copeland is the one allocating the resource on the",
    "start": "1849320",
    "end": "1854840"
  },
  {
    "text": "Node in your cap is that now the runtimes with responsibility",
    "start": "1854840",
    "end": "1861080"
  },
  {
    "text": "yeah basically the runtime runtime handles that so yeah so in that case uh",
    "start": "1861080",
    "end": "1867080"
  },
  {
    "text": "how so normally the runtime for example um containerd it doesn't really have",
    "start": "1867080",
    "end": "1873020"
  },
  {
    "text": "this view on the node right so do you have actually now it had need to have a",
    "start": "1873020",
    "end": "1878779"
  },
  {
    "text": "persistent View for the the resource on the Node so I think I think like the I don't know",
    "start": "1878779",
    "end": "1884840"
  },
  {
    "text": "I feel like it's actually it might be the admin who has the responsibility of balancing out the resources because",
    "start": "1884840",
    "end": "1890539"
  },
  {
    "text": "they're the one that passes down the yeah um yeah so I I because there's no automatic reconciliation that the",
    "start": "1890539",
    "end": "1897620"
  },
  {
    "text": "container runtime is able to do to like pull some other pod into a class when",
    "start": "1897620",
    "end": "1902659"
  },
  {
    "text": "another pod within that class disappears um so the balancing I think has to be",
    "start": "1902659",
    "end": "1908659"
  },
  {
    "text": "done by the Admin is that does that answer your question yeah what's the admin it's like you know the the person",
    "start": "1908659",
    "end": "1915260"
  },
  {
    "text": "writing the Pod spec or like you know um the person running the kubernetes cluster would have to make sure that",
    "start": "1915260",
    "end": "1921500"
  },
  {
    "text": "there are enough classes for the pods underneath them to be able to you know put into uh you know be designated but I",
    "start": "1921500",
    "end": "1928820"
  },
  {
    "text": "think it's up to the Pod author choosing the um the resource and",
    "start": "1928820",
    "end": "1935980"
  },
  {
    "text": "am I misinterpreting the question I might be I guess uh I'm a bit confused",
    "start": "1936159",
    "end": "1941600"
  },
  {
    "text": "of that for example the scheduling right in in that case the scheduler need to be aware",
    "start": "1941600",
    "end": "1947080"
  },
  {
    "text": "how many uh parts for example called qsa can fit into a node",
    "start": "1947080",
    "end": "1954080"
  },
  {
    "text": "so in that case I guess the copyright actually need to report the status relatively accurate",
    "start": "1954080",
    "end": "1962080"
  },
  {
    "text": "okay now now I've got the question so uh So currently it's actually out of this",
    "start": "1962200",
    "end": "1968240"
  },
  {
    "text": "out of scope of the cap to have this kind of accounting of these classes so maybe that's that's a possible future uh",
    "start": "1968240",
    "end": "1976039"
  },
  {
    "text": "Improvement I guess on this area but it's it's left out of the scope of the",
    "start": "1976039",
    "end": "1981620"
  },
  {
    "text": "cap currently to have any kind of accounting how many ports are actually assigned to certain class class for",
    "start": "1981620",
    "end": "1988220"
  },
  {
    "text": "example so and yeah and one reason is also to keep this kind of simple and not confuse",
    "start": "1988220",
    "end": "1993740"
  },
  {
    "text": "people to because we are kind of talking about or trying to talk about uh kind of unaccountable resources you know class",
    "start": "1993740",
    "end": "2001360"
  },
  {
    "text": "identifiers but yeah that yeah that's a good good question probably a future future Improvement on this area okay",
    "start": "2001360",
    "end": "2008500"
  },
  {
    "text": "thank you yeah I have a question really to the uh using Intel rdt to partition the cache",
    "start": "2008500",
    "end": "2016659"
  },
  {
    "text": "and bandwidth so uh so after like preparation the cache is it possible like for even the CPU is Idle the",
    "start": "2016659",
    "end": "2024039"
  },
  {
    "text": "process might use less resources so that it has some performance regression",
    "start": "2024039",
    "end": "2031360"
  },
  {
    "text": "uh so yeah yeah basically at the moment uh the risk control file system does and",
    "start": "2031360",
    "end": "2038080"
  },
  {
    "text": "does so that yeah if you if you uh limit the limit the",
    "start": "2038080",
    "end": "2044559"
  },
  {
    "text": "uh cash available for for some uh some Plus",
    "start": "2044559",
    "end": "2051520"
  },
  {
    "text": "so then even if the CPU is Idle it's only a ble to use the slice of cache that was",
    "start": "2051520",
    "end": "2059080"
  },
  {
    "text": "actually allocated so it's it's not giving the kind of idle cash okay so is there currently is there any solutions",
    "start": "2059080",
    "end": "2065679"
  },
  {
    "text": "from Intel that can like burst the um the usage from like say 30 to 100 if the",
    "start": "2065679",
    "end": "2073480"
  },
  {
    "text": "CPU is Idle um currently is there in technology to support that",
    "start": "2073480",
    "end": "2079839"
  },
  {
    "text": "so uh from the point of view of this this skip so it's kind of implementation detail of",
    "start": "2079839",
    "end": "2086378"
  },
  {
    "text": "the technology so I'm and I'm not kind of uh internally aware that what is what is",
    "start": "2086379",
    "end": "2092679"
  },
  {
    "text": "happening in that space kind of on that like that technology so what I mean yeah",
    "start": "2092679",
    "end": "2097839"
  },
  {
    "text": "basically this uh regarding the scope of this skip I",
    "start": "2097839",
    "end": "2103300"
  },
  {
    "text": "mean it it doesn't so it's kind of technical implementation detail of that technology so thanks yeah but good",
    "start": "2103300",
    "end": "2109839"
  },
  {
    "text": "question as well",
    "start": "2109839",
    "end": "2112560"
  },
  {
    "text": "so I think there's a similar problem that you faced today like the auto scaler may want to spin up a new node",
    "start": "2119800",
    "end": "2125800"
  },
  {
    "text": "and it may not know what your requirements are and you spin up the wrong note that doesn't have the class",
    "start": "2125800",
    "end": "2130839"
  },
  {
    "text": "you need then you cannot schedule the part and then it's like a deadlock so do you think of",
    "start": "2130839",
    "end": "2136540"
  },
  {
    "text": "there's a common solution coming out that can say the part needs this and the node that's been up should be of that",
    "start": "2136540",
    "end": "2143079"
  },
  {
    "text": "particular attack that will have the classes that you need yeah that's not stated in the cap at the",
    "start": "2143079",
    "end": "2149440"
  },
  {
    "text": "moment so I guess that's also part of part of the kind of future implementation phases to figure really",
    "start": "2149440",
    "end": "2154780"
  },
  {
    "text": "out how the how the kind of uh Auto scaler would work correctly and",
    "start": "2154780",
    "end": "2161320"
  },
  {
    "text": "then also the upcoming uh kind of in Place Port vertical Auto scaling is is",
    "start": "2161320",
    "end": "2166480"
  },
  {
    "text": "something that it's not like stated here or in the cap currently but it's also something that we want to want to be",
    "start": "2166480",
    "end": "2173079"
  },
  {
    "text": "able to support thank you all right I think we're totally out of",
    "start": "2173079",
    "end": "2178900"
  },
  {
    "text": "time but um yeah thank you both thank you everyone thank you",
    "start": "2178900",
    "end": "2184920"
  }
]
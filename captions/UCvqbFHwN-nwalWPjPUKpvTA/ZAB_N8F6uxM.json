[
  {
    "text": "cool I guess we get started so thank you",
    "start": "0",
    "end": "3629"
  },
  {
    "text": "guys so much for coming",
    "start": "3629",
    "end": "4589"
  },
  {
    "text": "that's aha hongou seem wait doll so hi",
    "start": "4589",
    "end": "8210"
  },
  {
    "text": "today so we're gonna talk a little bit",
    "start": "8210",
    "end": "10769"
  },
  {
    "text": "about modern data sciences they're",
    "start": "10769",
    "end": "12269"
  },
  {
    "text": "modded data science and I of science",
    "start": "12269",
    "end": "13860"
  },
  {
    "text": "pipelines and how we can take advantage",
    "start": "13860",
    "end": "15150"
  },
  {
    "text": "of coupon IDs and other cloud native",
    "start": "15150",
    "end": "16859"
  },
  {
    "text": "technologies to make this process a lot",
    "start": "16859",
    "end": "19230"
  },
  {
    "text": "more reliable and faster C cool before",
    "start": "19230",
    "end": "23550"
  },
  {
    "text": "we get started all the code examples",
    "start": "23550",
    "end": "25680"
  },
  {
    "text": "everything's gonna be on my github I'll",
    "start": "25680",
    "end": "27119"
  },
  {
    "text": "put out sway there I tweet about it too",
    "start": "27119",
    "end": "29160"
  },
  {
    "text": "and stuff so first thing is the process",
    "start": "29160",
    "end": "31740"
  },
  {
    "text": "we start with data science we have a",
    "start": "31740",
    "end": "33870"
  },
  {
    "text": "business need or problem discovery",
    "start": "33870",
    "end": "35610"
  },
  {
    "text": "customer issues then we go into the",
    "start": "35610",
    "end": "37739"
  },
  {
    "text": "development phase we do this is where we",
    "start": "37739",
    "end": "39390"
  },
  {
    "text": "get that raw data we understand what's",
    "start": "39390",
    "end": "41100"
  },
  {
    "text": "going on we iterate through and build",
    "start": "41100",
    "end": "42870"
  },
  {
    "text": "all models and try to make the most",
    "start": "42870",
    "end": "44040"
  },
  {
    "text": "accurate model as we can",
    "start": "44040",
    "end": "45149"
  },
  {
    "text": "and finally and most importantly in most",
    "start": "45149",
    "end": "47550"
  },
  {
    "text": "cases is we get to production we hit",
    "start": "47550",
    "end": "49860"
  },
  {
    "text": "that point where that model actually",
    "start": "49860",
    "end": "50879"
  },
  {
    "text": "impacts the user and it's the whole",
    "start": "50879",
    "end": "52770"
  },
  {
    "text": "process so we're looking at we want to",
    "start": "52770",
    "end": "53940"
  },
  {
    "text": "look at we've gotten pretty good at this",
    "start": "53940",
    "end": "55620"
  },
  {
    "text": "development phase there's a lot of tools",
    "start": "55620",
    "end": "57449"
  },
  {
    "text": "and technologies we have now to go",
    "start": "57449",
    "end": "59340"
  },
  {
    "text": "either if we're more advanced to go",
    "start": "59340",
    "end": "61140"
  },
  {
    "text": "deeper and deeper into our data to have",
    "start": "61140",
    "end": "62969"
  },
  {
    "text": "a full understanding or on lowering the",
    "start": "62969",
    "end": "66060"
  },
  {
    "text": "barrier entry - so anybody can take",
    "start": "66060",
    "end": "67770"
  },
  {
    "text": "advantage of machine learning and data",
    "start": "67770",
    "end": "69299"
  },
  {
    "text": "science so the only issue with that is",
    "start": "69299",
    "end": "72150"
  },
  {
    "text": "this is in the entire process if I have",
    "start": "72150",
    "end": "74850"
  },
  {
    "text": "the best model of all time the most",
    "start": "74850",
    "end": "75900"
  },
  {
    "text": "accurate model that doesn't do me any",
    "start": "75900",
    "end": "77640"
  },
  {
    "text": "good if it doesn't actually touch the",
    "start": "77640",
    "end": "79200"
  },
  {
    "text": "customer there's all the reasons for why",
    "start": "79200",
    "end": "81000"
  },
  {
    "text": "this process becomes complicated if you",
    "start": "81000",
    "end": "83040"
  },
  {
    "text": "look at modern data science workflows we",
    "start": "83040",
    "end": "85259"
  },
  {
    "text": "have to get all data extract it put in",
    "start": "85259",
    "end": "87689"
  },
  {
    "text": "places that we can actually use it in",
    "start": "87689",
    "end": "89670"
  },
  {
    "text": "databases the ETL in then we have to",
    "start": "89670",
    "end": "92610"
  },
  {
    "text": "actually train our models evaluate them",
    "start": "92610",
    "end": "94229"
  },
  {
    "text": "understand what's going on and finally",
    "start": "94229",
    "end": "96119"
  },
  {
    "text": "we have to be able to serve those models",
    "start": "96119",
    "end": "97409"
  },
  {
    "text": "and have those results ready and anybody",
    "start": "97409",
    "end": "99479"
  },
  {
    "text": "setting up these manual pipelines",
    "start": "99479",
    "end": "100829"
  },
  {
    "text": "realizes it's a it's a complicated",
    "start": "100829",
    "end": "102450"
  },
  {
    "text": "process there's a lot of things to",
    "start": "102450",
    "end": "104220"
  },
  {
    "text": "manage and things that can go wrong and",
    "start": "104220",
    "end": "105720"
  },
  {
    "text": "so moving forward and looking at what we",
    "start": "105720",
    "end": "108570"
  },
  {
    "text": "have today we have the the managed VMs",
    "start": "108570",
    "end": "111509"
  },
  {
    "text": "in the infrastructure and before this is",
    "start": "111509",
    "end": "113250"
  },
  {
    "text": "challenging with bare metal until cloud",
    "start": "113250",
    "end": "115020"
  },
  {
    "text": "providers came now we can get vm's",
    "start": "115020",
    "end": "116670"
  },
  {
    "text": "relatively cheap and easy but then we",
    "start": "116670",
    "end": "118710"
  },
  {
    "text": "have a problem of managing those",
    "start": "118710",
    "end": "120210"
  },
  {
    "text": "resources as we all know from this",
    "start": "120210",
    "end": "121860"
  },
  {
    "text": "confidence that's where kubernetes comes",
    "start": "121860",
    "end": "123060"
  },
  {
    "text": "in we now don't have to think about",
    "start": "123060",
    "end": "124619"
  },
  {
    "text": "virtual machines and understanding those",
    "start": "124619",
    "end": "126210"
  },
  {
    "text": "it can just manage those for us but the",
    "start": "126210",
    "end": "129330"
  },
  {
    "text": "problem is as we sell from that pipeline",
    "start": "129330",
    "end": "130770"
  },
  {
    "text": "before and data science there's a",
    "start": "130770",
    "end": "132930"
  },
  {
    "text": "a lot more involved in that and so now",
    "start": "132930",
    "end": "134790"
  },
  {
    "text": "we need a data infrastructure management",
    "start": "134790",
    "end": "136739"
  },
  {
    "text": "layer to help go through that pipeline",
    "start": "136739",
    "end": "138930"
  },
  {
    "text": "and understand the data going through it",
    "start": "138930",
    "end": "140780"
  },
  {
    "text": "so today we can talk about pachyderm and",
    "start": "140780",
    "end": "143819"
  },
  {
    "text": "pachyderm is one of the good example of",
    "start": "143819",
    "end": "145769"
  },
  {
    "text": "using native kubernetes",
    "start": "145769",
    "end": "146939"
  },
  {
    "text": "to tackle this problem of having data",
    "start": "146939",
    "end": "148980"
  },
  {
    "text": "data science pipelines and management",
    "start": "148980",
    "end": "150719"
  },
  {
    "text": "and so pakka dome has two main",
    "start": "150719",
    "end": "152400"
  },
  {
    "text": "components to it number one is a data",
    "start": "152400",
    "end": "154439"
  },
  {
    "text": "version so version control system for",
    "start": "154439",
    "end": "156480"
  },
  {
    "text": "data which is extremely powerful and",
    "start": "156480",
    "end": "158459"
  },
  {
    "text": "we'll talk about that in a little bit",
    "start": "158459",
    "end": "159540"
  },
  {
    "text": "until it has language agnostic pipelines",
    "start": "159540",
    "end": "161939"
  },
  {
    "text": "which means I can set up these",
    "start": "161939",
    "end": "163260"
  },
  {
    "text": "declarative pipelines just like a pod",
    "start": "163260",
    "end": "165239"
  },
  {
    "text": "spec or deployment spec of the state",
    "start": "165239",
    "end": "166769"
  },
  {
    "text": "that I want and then use containers to",
    "start": "166769",
    "end": "169530"
  },
  {
    "text": "transform our state and so let's take a",
    "start": "169530",
    "end": "171720"
  },
  {
    "text": "little look a common example of one of",
    "start": "171720",
    "end": "173909"
  },
  {
    "text": "those pipelines is something like this",
    "start": "173909",
    "end": "174810"
  },
  {
    "text": "all pipelines in pachyderm have a name",
    "start": "174810",
    "end": "178349"
  },
  {
    "text": "then you have the most important section",
    "start": "178349",
    "end": "180359"
  },
  {
    "text": "as the transformation so this",
    "start": "180359",
    "end": "181889"
  },
  {
    "text": "transformation section we give a",
    "start": "181889",
    "end": "183359"
  },
  {
    "text": "container we conversion this container",
    "start": "183359",
    "end": "185250"
  },
  {
    "text": "which is extremely important and we also",
    "start": "185250",
    "end": "187260"
  },
  {
    "text": "give it a command so anybody who knows",
    "start": "187260",
    "end": "189480"
  },
  {
    "text": "pod specs or deployment specs this",
    "start": "189480",
    "end": "191549"
  },
  {
    "text": "should look very familiar and then we",
    "start": "191549",
    "end": "194040"
  },
  {
    "text": "have an optional section which is",
    "start": "194040",
    "end": "195000"
  },
  {
    "text": "parallelization we're gonna go deeper",
    "start": "195000",
    "end": "196560"
  },
  {
    "text": "into this later but this allows you to",
    "start": "196560",
    "end": "198239"
  },
  {
    "text": "specify if I want multiple replicas of",
    "start": "198239",
    "end": "200849"
  },
  {
    "text": "my pods running so this gives a lot of",
    "start": "200849",
    "end": "203190"
  },
  {
    "text": "power and pipelines to be able to do",
    "start": "203190",
    "end": "204870"
  },
  {
    "text": "multi processing and finally we have an",
    "start": "204870",
    "end": "206909"
  },
  {
    "text": "input section and this allows us to",
    "start": "206909",
    "end": "209209"
  },
  {
    "text": "directly figure out how we want to",
    "start": "209209",
    "end": "211349"
  },
  {
    "text": "expose our data to our containers and",
    "start": "211349",
    "end": "213659"
  },
  {
    "text": "we'll see a lot of the power of that",
    "start": "213659",
    "end": "214620"
  },
  {
    "text": "later as well so now looking at a",
    "start": "214620",
    "end": "218069"
  },
  {
    "text": "pipeline like this it's not as",
    "start": "218069",
    "end": "219780"
  },
  {
    "text": "complicated anymore we have to have",
    "start": "219780",
    "end": "220919"
  },
  {
    "text": "these manual batch scripts to set up and",
    "start": "220919",
    "end": "222479"
  },
  {
    "text": "manage it manually we can have our JSON",
    "start": "222479",
    "end": "225389"
  },
  {
    "text": "files live in our codebase alongside",
    "start": "225389",
    "end": "226889"
  },
  {
    "text": "where our infrastructure is then",
    "start": "226889",
    "end": "228780"
  },
  {
    "text": "reviewed and understood by our team",
    "start": "228780",
    "end": "230579"
  },
  {
    "text": "going forward so something this pipeline",
    "start": "230579",
    "end": "233280"
  },
  {
    "text": "can be set up just like Cooper naze",
    "start": "233280",
    "end": "235530"
  },
  {
    "text": "deployments in seconds and so now before",
    "start": "235530",
    "end": "239519"
  },
  {
    "text": "we really dive deep into understanding",
    "start": "239519",
    "end": "240689"
  },
  {
    "text": "how to implement these pipelines in",
    "start": "240689",
    "end": "242819"
  },
  {
    "text": "pachyderms",
    "start": "242819",
    "end": "243329"
  },
  {
    "text": "we're looking at for data science",
    "start": "243329",
    "end": "245310"
  },
  {
    "text": "principles to help us along to make it a",
    "start": "245310",
    "end": "247709"
  },
  {
    "text": "little bit more reliable in our",
    "start": "247709",
    "end": "249479"
  },
  {
    "text": "processes so the first principle is just",
    "start": "249479",
    "end": "251430"
  },
  {
    "text": "autonomy as a data scientist I want to",
    "start": "251430",
    "end": "254220"
  },
  {
    "text": "be able to go into a project and use the",
    "start": "254220",
    "end": "256620"
  },
  {
    "text": "languages and tools that I want to so",
    "start": "256620",
    "end": "258419"
  },
  {
    "text": "whether it be Python for data",
    "start": "258419",
    "end": "259620"
  },
  {
    "text": "visualization or go for my processing",
    "start": "259620",
    "end": "261570"
  },
  {
    "text": "and not have to worry about making it",
    "start": "261570",
    "end": "263940"
  },
  {
    "text": "adapt to my infrastructure and so",
    "start": "263940",
    "end": "265919"
  },
  {
    "text": "there's a lot of",
    "start": "265919",
    "end": "266620"
  },
  {
    "text": "to do that but we also want to focus on",
    "start": "266620",
    "end": "271320"
  },
  {
    "text": "being able to manage so as a data",
    "start": "271320",
    "end": "275050"
  },
  {
    "text": "scientist to not have to have an extreme",
    "start": "275050",
    "end": "279639"
  },
  {
    "text": "experience in data science as well as",
    "start": "279639",
    "end": "281560"
  },
  {
    "text": "infrastructure so don't need 20 years of",
    "start": "281560",
    "end": "283660"
  },
  {
    "text": "experience in distributed systems to be",
    "start": "283660",
    "end": "285669"
  },
  {
    "text": "able to set up these good pipelines at",
    "start": "285669",
    "end": "287470"
  },
  {
    "text": "the end of the day we have specialized",
    "start": "287470",
    "end": "288910"
  },
  {
    "text": "skills we want to be able to focus on",
    "start": "288910",
    "end": "290650"
  },
  {
    "text": "those specialized skills and doing that",
    "start": "290650",
    "end": "294000"
  },
  {
    "text": "it should be pretty obvious now is we",
    "start": "294000",
    "end": "296440"
  },
  {
    "text": "use containers so containerization",
    "start": "296440",
    "end": "300100"
  },
  {
    "text": "there's tons of good talks yesterday",
    "start": "300100",
    "end": "301120"
  },
  {
    "text": "tons of good talks today about how we",
    "start": "301120",
    "end": "303039"
  },
  {
    "text": "can continue eyes it and in data science",
    "start": "303039",
    "end": "304780"
  },
  {
    "text": "there's really only two main sections",
    "start": "304780",
    "end": "306669"
  },
  {
    "text": "that we want to focus on and number one",
    "start": "306669",
    "end": "308710"
  },
  {
    "text": "a single operation for container this is",
    "start": "308710",
    "end": "310690"
  },
  {
    "text": "pretty obvious in other containers but",
    "start": "310690",
    "end": "312100"
  },
  {
    "text": "for us we wanted to talk about so if I",
    "start": "312100",
    "end": "313990"
  },
  {
    "text": "have a model I'm training that model",
    "start": "313990",
    "end": "315789"
  },
  {
    "text": "that should be a container if I have",
    "start": "315789",
    "end": "317530"
  },
  {
    "text": "evaluating that model and Ramez we want",
    "start": "317530",
    "end": "320560"
  },
  {
    "text": "that to be a separate container as we'll",
    "start": "320560",
    "end": "322240"
  },
  {
    "text": "see later setting up these pipelines",
    "start": "322240",
    "end": "324039"
  },
  {
    "text": "having these separate containers gives",
    "start": "324039",
    "end": "326320"
  },
  {
    "text": "us a lot of granularity and",
    "start": "326320",
    "end": "327789"
  },
  {
    "text": "understanding our process and how data",
    "start": "327789",
    "end": "329680"
  },
  {
    "text": "flows through that process and number",
    "start": "329680",
    "end": "331780"
  },
  {
    "text": "two number two we want to parameterize",
    "start": "331780",
    "end": "335260"
  },
  {
    "text": "our data inputs to that container so",
    "start": "335260",
    "end": "337360"
  },
  {
    "text": "what this means is we want to be able to",
    "start": "337360",
    "end": "339060"
  },
  {
    "text": "have exactly what data is going into our",
    "start": "339060",
    "end": "342250"
  },
  {
    "text": "container and where it's pulling from",
    "start": "342250",
    "end": "343720"
  },
  {
    "text": "and this is because pachyderm exposes",
    "start": "343720",
    "end": "345820"
  },
  {
    "text": "data to these containers and something",
    "start": "345820",
    "end": "347500"
  },
  {
    "text": "called the packet and file system the",
    "start": "347500",
    "end": "349120"
  },
  {
    "text": "PFS and this means this has two",
    "start": "349120",
    "end": "351849"
  },
  {
    "text": "advantages in packing number one is when",
    "start": "351849",
    "end": "354220"
  },
  {
    "text": "I'm testing my containers locally I'm",
    "start": "354220",
    "end": "356560"
  },
  {
    "text": "reading from a CSV or a local file it's",
    "start": "356560",
    "end": "358750"
  },
  {
    "text": "pretty common and now my production",
    "start": "358750",
    "end": "361270"
  },
  {
    "text": "environments my code is doing the exact",
    "start": "361270",
    "end": "362979"
  },
  {
    "text": "same thing is reading from these files",
    "start": "362979",
    "end": "364330"
  },
  {
    "text": "to understand what's going on in the",
    "start": "364330",
    "end": "366099"
  },
  {
    "text": "data so that means instead of having a",
    "start": "366099",
    "end": "368080"
  },
  {
    "text": "production database and then locally I'm",
    "start": "368080",
    "end": "370360"
  },
  {
    "text": "doing files and having to change these",
    "start": "370360",
    "end": "372160"
  },
  {
    "text": "interfaces there's a lot of problems",
    "start": "372160",
    "end": "373960"
  },
  {
    "text": "prone with that where this means my",
    "start": "373960",
    "end": "375460"
  },
  {
    "text": "local development environment is as",
    "start": "375460",
    "end": "377169"
  },
  {
    "text": "close as possible to my production",
    "start": "377169",
    "end": "378880"
  },
  {
    "text": "environment number two allows us to take",
    "start": "378880",
    "end": "381520"
  },
  {
    "text": "advantage of that parallelization that",
    "start": "381520",
    "end": "383320"
  },
  {
    "text": "we saw in our deployment specs so now",
    "start": "383320",
    "end": "385180"
  },
  {
    "text": "pachyderm if anybody's familiar with",
    "start": "385180",
    "end": "387280"
  },
  {
    "text": "Hadoop are these MapReduce problems this",
    "start": "387280",
    "end": "389949"
  },
  {
    "text": "is a way you can do a lot of these",
    "start": "389949",
    "end": "391389"
  },
  {
    "text": "applications in a coop and edie's native",
    "start": "391389",
    "end": "393130"
  },
  {
    "text": "way so now I can spin up multiple",
    "start": "393130",
    "end": "395349"
  },
  {
    "text": "instances of my container and then",
    "start": "395349",
    "end": "397360"
  },
  {
    "text": "packet and we'll manage our tician the",
    "start": "397360",
    "end": "399190"
  },
  {
    "text": "data between those",
    "start": "399190",
    "end": "400060"
  },
  {
    "text": "sharding the data another cool thing",
    "start": "400060",
    "end": "401889"
  },
  {
    "text": "about that is not only can I process",
    "start": "401889",
    "end": "403570"
  },
  {
    "text": "faster but if say one of my VMs goes",
    "start": "403570",
    "end": "405820"
  },
  {
    "text": "down and I lose a piece of that packet",
    "start": "405820",
    "end": "408160"
  },
  {
    "text": "I'm when kubernetes spins the pod backup",
    "start": "408160",
    "end": "409510"
  },
  {
    "text": "packet and will then process just that",
    "start": "409510",
    "end": "411760"
  },
  {
    "text": "data that hasn't been processed yet and",
    "start": "411760",
    "end": "413320"
  },
  {
    "text": "so this becomes very powerful in our",
    "start": "413320",
    "end": "414940"
  },
  {
    "text": "pipelines so now principle two is",
    "start": "414940",
    "end": "418889"
  },
  {
    "text": "reproducibility and this idea of having",
    "start": "418889",
    "end": "421270"
  },
  {
    "text": "data versioning and another one of those",
    "start": "421270",
    "end": "423460"
  },
  {
    "text": "really interesting concepts because you",
    "start": "423460",
    "end": "426220"
  },
  {
    "text": "can't if I asked anybody in this room",
    "start": "426220",
    "end": "427840"
  },
  {
    "text": "when the last time they started a coding",
    "start": "427840",
    "end": "429370"
  },
  {
    "text": "project without get and it's it's almost",
    "start": "429370",
    "end": "431440"
  },
  {
    "text": "crazy yet something like data that's",
    "start": "431440",
    "end": "433870"
  },
  {
    "text": "arguably more volatile than code nobody",
    "start": "433870",
    "end": "437350"
  },
  {
    "text": "thinks twice about it and so this allows",
    "start": "437350",
    "end": "439389"
  },
  {
    "text": "us to do a lot when it comes whether it",
    "start": "439389",
    "end": "441700"
  },
  {
    "text": "be for the developer where I can now go",
    "start": "441700",
    "end": "444790"
  },
  {
    "text": "through a process and understand exactly",
    "start": "444790",
    "end": "446500"
  },
  {
    "text": "the transformations I'm making to that",
    "start": "446500",
    "end": "448419"
  },
  {
    "text": "data or for my team so I can I don't",
    "start": "448419",
    "end": "452229"
  },
  {
    "text": "have to make these copies of databases I",
    "start": "452229",
    "end": "454060"
  },
  {
    "text": "can do i can now branch off data from my",
    "start": "454060",
    "end": "457150"
  },
  {
    "text": "coworker and have a full understanding",
    "start": "457150",
    "end": "458620"
  },
  {
    "text": "of exactly how this is going on or for",
    "start": "458620",
    "end": "462340"
  },
  {
    "text": "production as I can do different sanity",
    "start": "462340",
    "end": "465880"
  },
  {
    "text": "checks and debugging in production",
    "start": "465880",
    "end": "467350"
  },
  {
    "text": "understand exactly how my dad is flowing",
    "start": "467350",
    "end": "468760"
  },
  {
    "text": "I was talking to one group of data",
    "start": "468760",
    "end": "470560"
  },
  {
    "text": "scientists that they would they were",
    "start": "470560",
    "end": "472570"
  },
  {
    "text": "doing predictive models on a user",
    "start": "472570",
    "end": "474310"
  },
  {
    "text": "database and every single data scientist",
    "start": "474310",
    "end": "476620"
  },
  {
    "text": "there and every single different",
    "start": "476620",
    "end": "478120"
  },
  {
    "text": "operation they would make a copy of that",
    "start": "478120",
    "end": "479650"
  },
  {
    "text": "database and that seems if this is",
    "start": "479650",
    "end": "481840"
  },
  {
    "text": "something that's very familiar to you",
    "start": "481840",
    "end": "482890"
  },
  {
    "text": "this is something that's very very hard",
    "start": "482890",
    "end": "484660"
  },
  {
    "text": "to work with not only do you have stale",
    "start": "484660",
    "end": "486640"
  },
  {
    "text": "data we don't know how long ago this",
    "start": "486640",
    "end": "488620"
  },
  {
    "text": "data have been has been copied from the",
    "start": "488620",
    "end": "490630"
  },
  {
    "text": "main source but also as we make these",
    "start": "490630",
    "end": "492820"
  },
  {
    "text": "transformations what transformation has",
    "start": "492820",
    "end": "494650"
  },
  {
    "text": "been had to that so when you build these",
    "start": "494650",
    "end": "496240"
  },
  {
    "text": "models off of that data you don't know",
    "start": "496240",
    "end": "498100"
  },
  {
    "text": "how it's been affected or how it's going",
    "start": "498100",
    "end": "500169"
  },
  {
    "text": "to affect your in the production so now",
    "start": "500169",
    "end": "503410"
  },
  {
    "text": "this leads into probably one of most",
    "start": "503410",
    "end": "505300"
  },
  {
    "text": "impactful things that having these",
    "start": "505300",
    "end": "506889"
  },
  {
    "text": "pipelines and having version data is",
    "start": "506889",
    "end": "508780"
  },
  {
    "text": "it's something called data provenance",
    "start": "508780",
    "end": "510280"
  },
  {
    "text": "and this is essentially when you have a",
    "start": "510280",
    "end": "513310"
  },
  {
    "text": "version control data posit ori that",
    "start": "513310",
    "end": "516039"
  },
  {
    "text": "feeds into your pipeline and then feeds",
    "start": "516039",
    "end": "517539"
  },
  {
    "text": "out into another control i can now track",
    "start": "517539",
    "end": "520150"
  },
  {
    "text": "that data through that means when you",
    "start": "520150",
    "end": "522130"
  },
  {
    "text": "have a predictable result at the ends so",
    "start": "522130",
    "end": "523900"
  },
  {
    "text": "i have a prediction for my model i can",
    "start": "523900",
    "end": "525700"
  },
  {
    "text": "now track that through every single",
    "start": "525700",
    "end": "527110"
  },
  {
    "text": "iteration of my data all the way back",
    "start": "527110",
    "end": "528760"
  },
  {
    "text": "into the raw data that was put in there",
    "start": "528760",
    "end": "530440"
  },
  {
    "text": "and this has some amazing effects on",
    "start": "530440",
    "end": "533380"
  },
  {
    "text": "your",
    "start": "533380",
    "end": "533750"
  },
  {
    "text": "workflow and we want as I can retry",
    "start": "533750",
    "end": "535550"
  },
  {
    "text": "after failure so now there's pipelines",
    "start": "535550",
    "end": "537380"
  },
  {
    "text": "if I have a failure happen I know I",
    "start": "537380",
    "end": "540140"
  },
  {
    "text": "don't have to send it through the entire",
    "start": "540140",
    "end": "541460"
  },
  {
    "text": "pipeline again setting up these manual",
    "start": "541460",
    "end": "543350"
  },
  {
    "text": "processes where a lot of cases I have",
    "start": "543350",
    "end": "545990"
  },
  {
    "text": "timing between my data now I can just",
    "start": "545990",
    "end": "548930"
  },
  {
    "text": "pack it in automatically knows okay that",
    "start": "548930",
    "end": "550760"
  },
  {
    "text": "failed here we start just processing the",
    "start": "550760",
    "end": "553340"
  },
  {
    "text": "new data I can do roll backs say I have",
    "start": "553340",
    "end": "556850"
  },
  {
    "text": "some bad data that gets some biased data",
    "start": "556850",
    "end": "560360"
  },
  {
    "text": "that gets put into my process and goes",
    "start": "560360",
    "end": "561650"
  },
  {
    "text": "to my pipeline now all I have to do to",
    "start": "561650",
    "end": "564200"
  },
  {
    "text": "redo the entire pipeline is remove one",
    "start": "564200",
    "end": "566030"
  },
  {
    "text": "commit and then it can manage going",
    "start": "566030",
    "end": "567830"
  },
  {
    "text": "through the entire pipeline flow and",
    "start": "567830",
    "end": "569600"
  },
  {
    "text": "that's extremely powerful no more having",
    "start": "569600",
    "end": "571670"
  },
  {
    "text": "to go back and try to find old versions",
    "start": "571670",
    "end": "573740"
  },
  {
    "text": "that were saved you can now just do this",
    "start": "573740",
    "end": "576460"
  },
  {
    "text": "automatically into your CID CG pipelines",
    "start": "576460",
    "end": "579110"
  },
  {
    "text": "and finally but most importantly is it",
    "start": "579110",
    "end": "582290"
  },
  {
    "text": "gives clarity into your organization so",
    "start": "582290",
    "end": "583910"
  },
  {
    "text": "now you can see exactly how data is",
    "start": "583910",
    "end": "586490"
  },
  {
    "text": "affecting your organization exactly what",
    "start": "586490",
    "end": "588770"
  },
  {
    "text": "things are happening so that means if I",
    "start": "588770",
    "end": "590720"
  },
  {
    "text": "have bias I can track bias and my",
    "start": "590720",
    "end": "592790"
  },
  {
    "text": "algorithms and everything so the final",
    "start": "592790",
    "end": "597470"
  },
  {
    "text": "thing we're looking at is automation is",
    "start": "597470",
    "end": "598910"
  },
  {
    "text": "how do we really go through and employ",
    "start": "598910",
    "end": "601310"
  },
  {
    "text": "these data science pipelines into our",
    "start": "601310",
    "end": "602720"
  },
  {
    "text": "society CD workloads and cut native then",
    "start": "602720",
    "end": "606050"
  },
  {
    "text": "this cloud native role we're already",
    "start": "606050",
    "end": "607100"
  },
  {
    "text": "pretty familiar with doing this",
    "start": "607100",
    "end": "609080"
  },
  {
    "text": "automation and so now it's just as",
    "start": "609080",
    "end": "610730"
  },
  {
    "text": "important to have our pipeline",
    "start": "610730",
    "end": "612110"
  },
  {
    "text": "infrastructure alongside our code base",
    "start": "612110",
    "end": "613730"
  },
  {
    "text": "to go through the same review process",
    "start": "613730",
    "end": "615470"
  },
  {
    "text": "and things were used to in our normal",
    "start": "615470",
    "end": "617450"
  },
  {
    "text": "day-to-day operations and so today I'm",
    "start": "617450",
    "end": "620810"
  },
  {
    "text": "gonna use agile devops but any kind of",
    "start": "620810",
    "end": "622790"
  },
  {
    "text": "like Jenkins there's github actions is",
    "start": "622790",
    "end": "624589"
  },
  {
    "text": "gonna be I'm excited about going forward",
    "start": "624589",
    "end": "626210"
  },
  {
    "text": "and so to go through this review process",
    "start": "626210",
    "end": "629630"
  },
  {
    "text": "we have autonomy to really make it so we",
    "start": "629630",
    "end": "632360"
  },
  {
    "text": "have as much developer action as we can",
    "start": "632360",
    "end": "634310"
  },
  {
    "text": "as a data scientist shouldn't have to be",
    "start": "634310",
    "end": "636140"
  },
  {
    "text": "looking through all these workflows",
    "start": "636140",
    "end": "637360"
  },
  {
    "text": "number two is reproducibility that we",
    "start": "637360",
    "end": "639740"
  },
  {
    "text": "can now track exactly the changes made",
    "start": "639740",
    "end": "641660"
  },
  {
    "text": "to our data which is at the end a very",
    "start": "641660",
    "end": "643850"
  },
  {
    "text": "our most important thing as data",
    "start": "643850",
    "end": "646160"
  },
  {
    "text": "scientist and machine learning next we",
    "start": "646160",
    "end": "649250"
  },
  {
    "text": "have data provenance to be able have",
    "start": "649250",
    "end": "650240"
  },
  {
    "text": "clarity in our organization to have a",
    "start": "650240",
    "end": "652130"
  },
  {
    "text": "full understanding of how everything's",
    "start": "652130",
    "end": "653690"
  },
  {
    "text": "happening and finally to automate the",
    "start": "653690",
    "end": "655460"
  },
  {
    "text": "process to remove that manual work from",
    "start": "655460",
    "end": "657230"
  },
  {
    "text": "what we're doing so that let's look at",
    "start": "657230",
    "end": "659570"
  },
  {
    "text": "example so we're gonna lose a very",
    "start": "659570",
    "end": "661640"
  },
  {
    "text": "common data set the iris data set so",
    "start": "661640",
    "end": "663320"
  },
  {
    "text": "good for classification anybody who's",
    "start": "663320",
    "end": "665270"
  },
  {
    "text": "not familiar with it",
    "start": "665270",
    "end": "666350"
  },
  {
    "text": "there's four different petal lengths or",
    "start": "666350",
    "end": "670100"
  },
  {
    "text": "features and then classification can we",
    "start": "670100",
    "end": "672770"
  },
  {
    "text": "do hyper pyramidal tuning so we're gonna",
    "start": "672770",
    "end": "674810"
  },
  {
    "text": "have our all data we want to split that",
    "start": "674810",
    "end": "676850"
  },
  {
    "text": "data into training tests build a whole",
    "start": "676850",
    "end": "678770"
  },
  {
    "text": "bunch of different models with different",
    "start": "678770",
    "end": "679820"
  },
  {
    "text": "parameters and then we want to evaluate",
    "start": "679820",
    "end": "681980"
  },
  {
    "text": "each model and finally select that model",
    "start": "681980",
    "end": "684170"
  },
  {
    "text": "so in the pachyderm terms or whatever",
    "start": "684170",
    "end": "686180"
  },
  {
    "text": "pipeline is really gonna look like is we",
    "start": "686180",
    "end": "688070"
  },
  {
    "text": "have a data repository for all data that",
    "start": "688070",
    "end": "690050"
  },
  {
    "text": "can allow us to track the changes that",
    "start": "690050",
    "end": "691400"
  },
  {
    "text": "we make and how we add it that's gonna",
    "start": "691400",
    "end": "693440"
  },
  {
    "text": "go into a pipeline that splits us into",
    "start": "693440",
    "end": "695120"
  },
  {
    "text": "training and testing that's going to go",
    "start": "695120",
    "end": "698510"
  },
  {
    "text": "into another pipeline that's gonna use",
    "start": "698510",
    "end": "700790"
  },
  {
    "text": "the training data to train a whole bunch",
    "start": "700790",
    "end": "702020"
  },
  {
    "text": "of different models with different",
    "start": "702020",
    "end": "703280"
  },
  {
    "text": "parameters passed as well and those",
    "start": "703280",
    "end": "704630"
  },
  {
    "text": "parameters the same way or version",
    "start": "704630",
    "end": "707000"
  },
  {
    "text": "control finally we're going to evaluate",
    "start": "707000",
    "end": "711830"
  },
  {
    "text": "those models and then select the best",
    "start": "711830",
    "end": "713540"
  },
  {
    "text": "models based on the threshold and",
    "start": "713540",
    "end": "714800"
  },
  {
    "text": "anybody's used to setting up these kind",
    "start": "714800",
    "end": "716570"
  },
  {
    "text": "of data science pipelines it can be very",
    "start": "716570",
    "end": "718310"
  },
  {
    "text": "complex and there's a lot to go into it",
    "start": "718310",
    "end": "720710"
  },
  {
    "text": "let's take a look at what exactly we",
    "start": "720710",
    "end": "722720"
  },
  {
    "text": "need for pipeline or for packaging",
    "start": "722720",
    "end": "726069"
  },
  {
    "text": "so here I have my four different",
    "start": "727420",
    "end": "730160"
  },
  {
    "text": "pipeline specs we can see so here's my",
    "start": "730160",
    "end": "733100"
  },
  {
    "text": "model all I'm doing is I have a simple",
    "start": "733100",
    "end": "734570"
  },
  {
    "text": "Python script that's SVM for anybody's",
    "start": "734570",
    "end": "736370"
  },
  {
    "text": "curious we'll go deeper into that in a",
    "start": "736370",
    "end": "737600"
  },
  {
    "text": "minute but I loop through the input data",
    "start": "737600",
    "end": "740270"
  },
  {
    "text": "that I have in this case my raw data",
    "start": "740270",
    "end": "741800"
  },
  {
    "text": "file or the CSV that has my training",
    "start": "741800",
    "end": "743660"
  },
  {
    "text": "data and then my parameters that I want",
    "start": "743660",
    "end": "745490"
  },
  {
    "text": "to test it against and run the command",
    "start": "745490",
    "end": "748330"
  },
  {
    "text": "the most important thing here is this",
    "start": "748330",
    "end": "750650"
  },
  {
    "text": "parallelization spec so in Pike return",
    "start": "750650",
    "end": "752840"
  },
  {
    "text": "there's two ways to paralyze I can",
    "start": "752840",
    "end": "754130"
  },
  {
    "text": "either set a set number so maybe four",
    "start": "754130",
    "end": "756110"
  },
  {
    "text": "replicas or in this case I'm using some",
    "start": "756110",
    "end": "757880"
  },
  {
    "text": "quality coefficient so this is taking",
    "start": "757880",
    "end": "759590"
  },
  {
    "text": "advantage of the resources in my cluster",
    "start": "759590",
    "end": "760760"
  },
  {
    "text": "in this case since I have two it's gonna",
    "start": "760760",
    "end": "762980"
  },
  {
    "text": "run two instances of this for any node",
    "start": "762980",
    "end": "765110"
  },
  {
    "text": "in my cluster in this case I have three",
    "start": "765110",
    "end": "767060"
  },
  {
    "text": "nodes in a cluster and we'll see the",
    "start": "767060",
    "end": "768710"
  },
  {
    "text": "difference of that and then I expose my",
    "start": "768710",
    "end": "771140"
  },
  {
    "text": "raw data so in this case I want my",
    "start": "771140",
    "end": "772700"
  },
  {
    "text": "training data every single container and",
    "start": "772700",
    "end": "774260"
  },
  {
    "text": "then I want to partition or shard my",
    "start": "774260",
    "end": "777490"
  },
  {
    "text": "parameters of which parameters to go and",
    "start": "777490",
    "end": "780730"
  },
  {
    "text": "so they're very similar for the other",
    "start": "780730",
    "end": "783200"
  },
  {
    "text": "different pipelines now you go through",
    "start": "783200",
    "end": "784460"
  },
  {
    "text": "those but all this required to set this",
    "start": "784460",
    "end": "786740"
  },
  {
    "text": "up it is these simple commands now",
    "start": "786740",
    "end": "788690"
  },
  {
    "text": "pachyderm uses very similar to creeping",
    "start": "788690",
    "end": "791240"
  },
  {
    "text": "IDs has a PAC control here all we'd have",
    "start": "791240",
    "end": "793700"
  },
  {
    "text": "to do is create our repositories then we",
    "start": "793700",
    "end": "797150"
  },
  {
    "text": "add the data in in this case I'm",
    "start": "797150",
    "end": "799820"
  },
  {
    "text": "single file for my parameters that I",
    "start": "799820",
    "end": "801350"
  },
  {
    "text": "then split into multiple files this just",
    "start": "801350",
    "end": "803450"
  },
  {
    "text": "helps to when I do the distribution z'",
    "start": "803450",
    "end": "806030"
  },
  {
    "text": "and then finally I create the pipelines",
    "start": "806030",
    "end": "808220"
  },
  {
    "text": "so now instead of having each manual",
    "start": "808220",
    "end": "811430"
  },
  {
    "text": "step going through there that's all it",
    "start": "811430",
    "end": "812870"
  },
  {
    "text": "takes and so let's take a little look at",
    "start": "812870",
    "end": "814730"
  },
  {
    "text": "actually implementing that so there I'm",
    "start": "814730",
    "end": "819500"
  },
  {
    "text": "just running the script it's creating",
    "start": "819500",
    "end": "821540"
  },
  {
    "text": "the repository adding the data and then",
    "start": "821540",
    "end": "823970"
  },
  {
    "text": "finally it's going to create the",
    "start": "823970",
    "end": "825620"
  },
  {
    "text": "pipeline's so that's the coolest part",
    "start": "825620",
    "end": "828650"
  },
  {
    "text": "about all of this is this is just",
    "start": "828650",
    "end": "829880"
  },
  {
    "text": "kubernetes so all the tools that you're",
    "start": "829880",
    "end": "832100"
  },
  {
    "text": "used to with tracing and we're gonna see",
    "start": "832100",
    "end": "834380"
  },
  {
    "text": "in a minute Kubb control is it's just",
    "start": "834380",
    "end": "837080"
  },
  {
    "text": "spinning in pods in your cluster so if",
    "start": "837080",
    "end": "838880"
  },
  {
    "text": "you want to go deep into that you have",
    "start": "838880",
    "end": "840710"
  },
  {
    "text": "four control you can see everything in",
    "start": "840710",
    "end": "842300"
  },
  {
    "text": "your cluster so we see here that it",
    "start": "842300",
    "end": "844160"
  },
  {
    "text": "spins up a different pod for an entire",
    "start": "844160",
    "end": "845870"
  },
  {
    "text": "pipeline now here we have a few options",
    "start": "845870",
    "end": "848270"
  },
  {
    "text": "you can either have it these pods always",
    "start": "848270",
    "end": "850880"
  },
  {
    "text": "running so your pipeline is ready to go",
    "start": "850880",
    "end": "852500"
  },
  {
    "text": "if if you have some streaming data or",
    "start": "852500",
    "end": "854030"
  },
  {
    "text": "quick data that you need a constantly",
    "start": "854030",
    "end": "855320"
  },
  {
    "text": "process or you can have a setup to just",
    "start": "855320",
    "end": "857870"
  },
  {
    "text": "when you need it to just to send up",
    "start": "857870",
    "end": "860150"
  },
  {
    "text": "resources when it's needed and then spin",
    "start": "860150",
    "end": "861710"
  },
  {
    "text": "down those resources with a not so this",
    "start": "861710",
    "end": "863420"
  },
  {
    "text": "gives a lot of advantages to like the",
    "start": "863420",
    "end": "864920"
  },
  {
    "text": "virtual Kubla project so I can spin off",
    "start": "864920",
    "end": "866600"
  },
  {
    "text": "those resources into a service",
    "start": "866600",
    "end": "868340"
  },
  {
    "text": "architecture and so once we see those",
    "start": "868340",
    "end": "871820"
  },
  {
    "text": "pipelines started running we can use the",
    "start": "871820",
    "end": "873320"
  },
  {
    "text": "PAC control to start looking at these",
    "start": "873320",
    "end": "875240"
  },
  {
    "text": "jobs being executed so in this case we",
    "start": "875240",
    "end": "878810"
  },
  {
    "text": "see that our first job the splitting",
    "start": "878810",
    "end": "881570"
  },
  {
    "text": "training testing it saw that there was",
    "start": "881570",
    "end": "883670"
  },
  {
    "text": "data added to our raw data repository so",
    "start": "883670",
    "end": "886100"
  },
  {
    "text": "then it started executing the pipeline",
    "start": "886100",
    "end": "887450"
  },
  {
    "text": "in this case splitting into training",
    "start": "887450",
    "end": "889040"
  },
  {
    "text": "testing data next it started to train",
    "start": "889040",
    "end": "892160"
  },
  {
    "text": "our models I think there's there's 77",
    "start": "892160",
    "end": "894260"
  },
  {
    "text": "models that it shows and it's going",
    "start": "894260",
    "end": "896630"
  },
  {
    "text": "through and actually in training our",
    "start": "896630",
    "end": "898250"
  },
  {
    "text": "data through there and so it detected",
    "start": "898250",
    "end": "900170"
  },
  {
    "text": "that there was new training data and so",
    "start": "900170",
    "end": "902300"
  },
  {
    "text": "it executes that pipeline so no more",
    "start": "902300",
    "end": "904190"
  },
  {
    "text": "waiting we have seen a lot of data",
    "start": "904190",
    "end": "905930"
  },
  {
    "text": "science pipelines go where you wait",
    "start": "905930",
    "end": "907670"
  },
  {
    "text": "eight hours or try to make it you have",
    "start": "907670",
    "end": "909380"
  },
  {
    "text": "to make those timings because of the",
    "start": "909380",
    "end": "911270"
  },
  {
    "text": "version control it will automatically",
    "start": "911270",
    "end": "912920"
  },
  {
    "text": "track through there and so now that",
    "start": "912920",
    "end": "916280"
  },
  {
    "text": "finished so once the models were",
    "start": "916280",
    "end": "918560"
  },
  {
    "text": "finished and added to the model",
    "start": "918560",
    "end": "920270"
  },
  {
    "text": "repository it automatically kicked off",
    "start": "920270",
    "end": "922520"
  },
  {
    "text": "the evaluation pipeline and so now it",
    "start": "922520",
    "end": "925970"
  },
  {
    "text": "can evaluate all of those pipelines and",
    "start": "925970",
    "end": "927410"
  },
  {
    "text": "move forward and then once that's",
    "start": "927410",
    "end": "929120"
  },
  {
    "text": "finished it'll go into doing the",
    "start": "929120",
    "end": "931370"
  },
  {
    "text": "selecting",
    "start": "931370",
    "end": "932729"
  },
  {
    "text": "but so this is nice but that doesn't",
    "start": "932729",
    "end": "936189"
  },
  {
    "text": "take advantage of the automation this is",
    "start": "936189",
    "end": "937569"
  },
  {
    "text": "still very I don't want to have to",
    "start": "937569",
    "end": "938739"
  },
  {
    "text": "manually go out and update my pipelines",
    "start": "938739",
    "end": "940479"
  },
  {
    "text": "each time so now I'm gonna go through an",
    "start": "940479",
    "end": "942129"
  },
  {
    "text": "example of being a developer in this",
    "start": "942129",
    "end": "944259"
  },
  {
    "text": "case you don't you can be a data",
    "start": "944259",
    "end": "945729"
  },
  {
    "text": "scientist and not have to really focus",
    "start": "945729",
    "end": "947139"
  },
  {
    "text": "on crew Benes concepts or anything I can",
    "start": "947139",
    "end": "949689"
  },
  {
    "text": "push up to github run those different",
    "start": "949689",
    "end": "952329"
  },
  {
    "text": "run my CIA tests and do everything and",
    "start": "952329",
    "end": "955269"
  },
  {
    "text": "then have it being deployed onto my",
    "start": "955269",
    "end": "957309"
  },
  {
    "text": "cluster so we can see what that looks",
    "start": "957309",
    "end": "959259"
  },
  {
    "text": "like so here I have a PR with some small",
    "start": "959259",
    "end": "961239"
  },
  {
    "text": "model changes then I can push it it",
    "start": "961239",
    "end": "965409"
  },
  {
    "text": "automatically triggers a build and my CI",
    "start": "965409",
    "end": "967809"
  },
  {
    "text": "CD pipeline in this case it's going to",
    "start": "967809",
    "end": "971049"
  },
  {
    "text": "pull down the source code build my",
    "start": "971049",
    "end": "973569"
  },
  {
    "text": "containers then push that container to",
    "start": "973569",
    "end": "976689"
  },
  {
    "text": "my container repository and it versions",
    "start": "976689",
    "end": "980649"
  },
  {
    "text": "these through so I can now track the",
    "start": "980649",
    "end": "982269"
  },
  {
    "text": "builds in the source code exactly what",
    "start": "982269",
    "end": "984159"
  },
  {
    "text": "calls that container and then it's going",
    "start": "984159",
    "end": "988119"
  },
  {
    "text": "to do all their it's gonna replace in my",
    "start": "988119",
    "end": "989969"
  },
  {
    "text": "pachyderm files and do my deployments",
    "start": "989969",
    "end": "991989"
  },
  {
    "text": "out to my cluster and what's really cool",
    "start": "991989",
    "end": "994509"
  },
  {
    "text": "about this is pachyderm was already at",
    "start": "994509",
    "end": "996279"
  },
  {
    "text": "matok we're gonna know that the model",
    "start": "996279",
    "end": "999069"
  },
  {
    "text": "has changed and so it's gonna start",
    "start": "999069",
    "end": "1000599"
  },
  {
    "text": "processing base starting at that point",
    "start": "1000599",
    "end": "1002729"
  },
  {
    "text": "in my pipeline so it doesn't have to we",
    "start": "1002729",
    "end": "1005159"
  },
  {
    "text": "don't to reprocess all the data going",
    "start": "1005159",
    "end": "1006689"
  },
  {
    "text": "through there we can just focus on the",
    "start": "1006689",
    "end": "1008759"
  },
  {
    "text": "piece that's changed so in this case we",
    "start": "1008759",
    "end": "1011249"
  },
  {
    "text": "don't have to split our data into",
    "start": "1011249",
    "end": "1013079"
  },
  {
    "text": "training and testing it can just focus",
    "start": "1013079",
    "end": "1015449"
  },
  {
    "text": "on the new model being created so as",
    "start": "1015449",
    "end": "1019229"
  },
  {
    "text": "this video is going",
    "start": "1019229",
    "end": "1022039"
  },
  {
    "text": "to be a little faster and then once all",
    "start": "1023470",
    "end": "1029689"
  },
  {
    "text": "of that bill goes through we can do",
    "start": "1029690",
    "end": "1031939"
  },
  {
    "text": "those releases where we released",
    "start": "1031940",
    "end": "1033140"
  },
  {
    "text": "automatically to the development",
    "start": "1033140",
    "end": "1035300"
  },
  {
    "text": "environments and going through this it",
    "start": "1035300",
    "end": "1037670"
  },
  {
    "text": "gives us a much faster deployment",
    "start": "1037670",
    "end": "1039020"
  },
  {
    "text": "process with our models now we can",
    "start": "1039020",
    "end": "1040579"
  },
  {
    "text": "constantly test in production what we're",
    "start": "1040579",
    "end": "1042680"
  },
  {
    "text": "what our model is doing what it's like",
    "start": "1042680",
    "end": "1044420"
  },
  {
    "text": "well what confident we can release in a",
    "start": "1044420",
    "end": "1045920"
  },
  {
    "text": "staging or production and so here we see",
    "start": "1045920",
    "end": "1050600"
  },
  {
    "text": "that the this was our old pipeline that",
    "start": "1050600",
    "end": "1052880"
  },
  {
    "text": "was going through it succeeded and we",
    "start": "1052880",
    "end": "1055550"
  },
  {
    "text": "can it's automatically detecting the",
    "start": "1055550",
    "end": "1058130"
  },
  {
    "text": "changes in our pipeline and executing",
    "start": "1058130",
    "end": "1059750"
  },
  {
    "text": "those jobs and builds and so a really",
    "start": "1059750",
    "end": "1065060"
  },
  {
    "text": "nice thing about this is so here's the",
    "start": "1065060",
    "end": "1068260"
  },
  {
    "text": "Python script they're the model that I'm",
    "start": "1068260",
    "end": "1070250"
  },
  {
    "text": "actually using and so it's an SVM I take",
    "start": "1070250",
    "end": "1072920"
  },
  {
    "text": "in my parameters my inputs like we",
    "start": "1072920",
    "end": "1074330"
  },
  {
    "text": "talked about before we want to really",
    "start": "1074330",
    "end": "1075830"
  },
  {
    "text": "parameterize that input and output data",
    "start": "1075830",
    "end": "1077420"
  },
  {
    "text": "as files then I simply running the in",
    "start": "1077420",
    "end": "1082130"
  },
  {
    "text": "training the SVM and so as a data",
    "start": "1082130",
    "end": "1084110"
  },
  {
    "text": "scientist I don't really have to",
    "start": "1084110",
    "end": "1085700"
  },
  {
    "text": "understand even go through docker and",
    "start": "1085700",
    "end": "1087710"
  },
  {
    "text": "those things yet I can push it up it'll",
    "start": "1087710",
    "end": "1089600"
  },
  {
    "text": "train and it'll build my docker image",
    "start": "1089600",
    "end": "1091820"
  },
  {
    "text": "and then push it to the container",
    "start": "1091820",
    "end": "1093260"
  },
  {
    "text": "registry and so hopefully this gives you",
    "start": "1093260",
    "end": "1100100"
  },
  {
    "text": "a lot more ideas of some power you can",
    "start": "1100100",
    "end": "1101780"
  },
  {
    "text": "do with pachyderm and setting up these",
    "start": "1101780",
    "end": "1102920"
  },
  {
    "text": "pipelines obviously this is very",
    "start": "1102920",
    "end": "1104480"
  },
  {
    "text": "simplistic case with a pike pipeline but",
    "start": "1104480",
    "end": "1107360"
  },
  {
    "text": "having your entire all the",
    "start": "1107360",
    "end": "1109010"
  },
  {
    "text": "transformations be fully be attract",
    "start": "1109010",
    "end": "1110840"
  },
  {
    "text": "throughout the process and then you can",
    "start": "1110840",
    "end": "1113030"
  },
  {
    "text": "link in with maybe coop flow into",
    "start": "1113030",
    "end": "1114470"
  },
  {
    "text": "different curbs or trains or multiple",
    "start": "1114470",
    "end": "1116240"
  },
  {
    "text": "training when if you're talking more of",
    "start": "1116240",
    "end": "1117950"
  },
  {
    "text": "the Nimmo networks and so this process",
    "start": "1117950",
    "end": "1120740"
  },
  {
    "text": "having this automated process can really",
    "start": "1120740",
    "end": "1122510"
  },
  {
    "text": "help speed up and be more reliable to",
    "start": "1122510",
    "end": "1125510"
  },
  {
    "text": "get out and have impactful and be",
    "start": "1125510",
    "end": "1127700"
  },
  {
    "text": "impactful for your customers and so with",
    "start": "1127700",
    "end": "1131540"
  },
  {
    "text": "that if anybody has any questions or any",
    "start": "1131540",
    "end": "1133580"
  },
  {
    "text": "ideas on going forward with the",
    "start": "1133580",
    "end": "1135230"
  },
  {
    "text": "pipelines I'm the only one with Sam",
    "start": "1135230",
    "end": "1137300"
  },
  {
    "text": "crater so it's really easy to find me a",
    "start": "1137300",
    "end": "1138770"
  },
  {
    "text": "Twitter handle github medium anything so",
    "start": "1138770",
    "end": "1142210"
  },
  {
    "text": "also come down afterwards a talk I'd",
    "start": "1142210",
    "end": "1144680"
  },
  {
    "text": "love to hear your ideas and what you're",
    "start": "1144680",
    "end": "1146510"
  },
  {
    "text": "doing with that thank you so much and",
    "start": "1146510",
    "end": "1150040"
  },
  {
    "text": "have a great group time",
    "start": "1150040",
    "end": "1153640"
  },
  {
    "text": "[Applause]",
    "start": "1153700",
    "end": "1159049"
  }
]
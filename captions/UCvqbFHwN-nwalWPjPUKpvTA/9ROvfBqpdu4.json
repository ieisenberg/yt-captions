[
  {
    "text": "hi um I'm Josh and um uh I'm commonly known as God Josh yet",
    "start": "560",
    "end": "8480"
  },
  {
    "text": "is a reference to a 1993 advertisement of of God milk and when I'm not coding",
    "start": "8480",
    "end": "14000"
  },
  {
    "text": "I'm usually snowboarding as you can see over there in the picture um principal software engineer AG Graal Labs uh",
    "start": "14000",
    "end": "20640"
  },
  {
    "text": "promethus maintainer and I'm internally known as a metrics I say alerting guy which is a title that I've been trying",
    "start": "20640",
    "end": "26840"
  },
  {
    "text": "to shake off for a while now that I'm back on the metric team and I'm Richie uh also Prometheus",
    "start": "26840",
    "end": "32880"
  },
  {
    "text": "maintainer part of the office of the CTO at grafo um yeah so a little bit of a",
    "start": "32880",
    "end": "38160"
  },
  {
    "text": "show of hands if you use Prometheus please raise your hands keep them up if you think you are",
    "start": "38160",
    "end": "46920"
  },
  {
    "text": "like beginner level or or higher sorry like keep them up and only take them down if once it doesn't apply to you",
    "start": "46920",
    "end": "54079"
  },
  {
    "text": "take them uh keep them up if you think you are intermediate to Advanced and keep them up if you think",
    "start": "54079",
    "end": "60600"
  },
  {
    "text": "you're Advanced thank you this helps us roughly uh figure out how much intro versus",
    "start": "60600",
    "end": "67439"
  },
  {
    "text": "versus Deep dive we do during the thing because we have some L here so thank you",
    "start": "67439",
    "end": "75360"
  },
  {
    "text": "uh okay so what is Prometheus right Prometheus is a metric based monitoring system and a learning stack um we have a",
    "start": "75720",
    "end": "83479"
  },
  {
    "text": "very rich instrumentation ecosystem for all kinds of applications and um systems",
    "start": "83479",
    "end": "88560"
  },
  {
    "text": "in general um peritus in peritus itself is in charge of doing all the metric",
    "start": "88560",
    "end": "93680"
  },
  {
    "text": "collection and storage and once it's collected you can do all the things of the cool things that you hear about",
    "start": "93680",
    "end": "99759"
  },
  {
    "text": "right like you can do the quering of the metrics you can do alerting on them you can dashboard them in pretty graphs um",
    "start": "99759",
    "end": "106600"
  },
  {
    "text": "there's a bunch of exporters for all levels of the stack so this is not just about your application it's like there's",
    "start": "106600",
    "end": "112719"
  },
  {
    "text": "hundreds of different use cases for things you can monitor with Prometheus um and it's designed from the ground up",
    "start": "112719",
    "end": "118039"
  },
  {
    "text": "to uh cater for Cloud Dynamic environments right so we can handle churn really really well and hence we're",
    "start": "118039",
    "end": "123960"
  },
  {
    "text": "here at a cloud native event as a whole um a little bit about the architecture",
    "start": "123960",
    "end": "129679"
  },
  {
    "text": "as you can see so first we have the exporters right so this is the thing where Prometheus will be collecting",
    "start": "129679",
    "end": "135000"
  },
  {
    "text": "metrics from it can be your application it can be your database be an exporter",
    "start": "135000",
    "end": "141000"
  },
  {
    "text": "all sorts of things the next step in that process is the scraping so this is when perus actually grabs the metrics",
    "start": "141000",
    "end": "147000"
  },
  {
    "text": "from the given exporters and then inserts them into to what we call the tsdv time series databases for short um",
    "start": "147000",
    "end": "154720"
  },
  {
    "text": "and this is where your metrics are EV essentially stored right uh you can then query them with promql in order to do",
    "start": "154720",
    "end": "161159"
  },
  {
    "text": "PRD graphs and dashboards and things and you can see right at the top that this is the same thing you can do with rules",
    "start": "161159",
    "end": "167239"
  },
  {
    "text": "right so you can use promql in order to query the Prometheus database and um design and build your recording",
    "start": "167239",
    "end": "175200"
  },
  {
    "text": "rules or alerting rules um the biggest thing and the most most important one is",
    "start": "175200",
    "end": "180480"
  },
  {
    "text": "the service Discovery um you can just point this straight up to U kubernetes",
    "start": "180480",
    "end": "186319"
  },
  {
    "text": "and it will immediately know what it is that it needs to fetch what kind of metrics where your pots live um your",
    "start": "186319",
    "end": "192799"
  },
  {
    "text": "applications live and it will immediately store them into the TCB it's certainly like magic right like this is",
    "start": "192799",
    "end": "198519"
  },
  {
    "text": "why Prometheus is a the factor standard for kuties monitoring right and this is what part of the sauce that make C",
    "start": "198519",
    "end": "204920"
  },
  {
    "text": "eating such an awful piece of software at the end of the day did I miss anything no cool a little",
    "start": "204920",
    "end": "212599"
  },
  {
    "text": "bit about the history of Prometheus um originally developed in 2012 uh at SoundCloud um joined the cncf",
    "start": "212599",
    "end": "221120"
  },
  {
    "text": "has the second project ever in 2018 2016 the first project was kubernetes of",
    "start": "221120",
    "end": "227239"
  },
  {
    "text": "course right um released 2.0 in 2017 so that's almost seven years ago now and",
    "start": "227239",
    "end": "234879"
  },
  {
    "text": "graduated the cncf in 2018 it was the second project Ever After KU as well",
    "start": "234879",
    "end": "240239"
  },
  {
    "text": "right um the good people at Honey put a really cool documentary i l you with a",
    "start": "240239",
    "end": "245439"
  },
  {
    "text": "QR code on the video over there I think everyone should watch it it gives you a little bit of a you know wider lens in",
    "start": "245439",
    "end": "251519"
  },
  {
    "text": "the promethus history and I I just think it's really cool right I just think just watching the history of a piece of",
    "start": "251519",
    "end": "256840"
  },
  {
    "text": "software and trying to understand the rationale behind it it's something amazing um so if you have the chance",
    "start": "256840",
    "end": "262199"
  },
  {
    "text": "just you know go ahead and watch it a little bit up the top a little bit at the bottom we have the promethus",
    "start": "262199",
    "end": "267360"
  },
  {
    "text": "adoption these are some numbers that final Prov provides to us on a yearly",
    "start": "267360",
    "end": "272400"
  },
  {
    "text": "basis specifically at promcon which is the Prometheus conference um and you can see that even in 2024 right like",
    "start": "272400",
    "end": "279840"
  },
  {
    "text": "Prometheus has steady adoption throughout the years continues to grow at a very steady",
    "start": "279840",
    "end": "285800"
  },
  {
    "text": "Place Okay cool so now should talk about what's new specifically um first of all",
    "start": "285800",
    "end": "292800"
  },
  {
    "text": "the releases since last year so we have four main releases this is typically less than what we usually release within",
    "start": "292800",
    "end": "298520"
  },
  {
    "text": "the year but we have very busy trying to put 3.0 together um we have one LTS",
    "start": "298520",
    "end": "303840"
  },
  {
    "text": "release this guarantees it just speaks to theability of the long-term support stable release so if you care about you",
    "start": "303840",
    "end": "310280"
  },
  {
    "text": "know not having latest features and just having your promethus incense working as a whole we do have uh U an LTS version",
    "start": "310280",
    "end": "317880"
  },
  {
    "text": "basically promethus alert manager which is one of the pieces that I actually maintain I'm really proud that in",
    "start": "317880",
    "end": "323240"
  },
  {
    "text": "version uh c028 um we actually included four new",
    "start": "323240",
    "end": "328440"
  },
  {
    "text": "receivers right so we now have Integrations that you can actually send your alerts to uh on top of a bunch of",
    "start": "328440",
    "end": "333960"
  },
  {
    "text": "goodies such just like less research consumption you know and overall really really nice additions to the existing uh",
    "start": "333960",
    "end": "340080"
  },
  {
    "text": "Integrations that we have over there as well uh we have too many way too many uh exporter updates to even begin to list",
    "start": "340080",
    "end": "347039"
  },
  {
    "text": "right it's like the ones that you care about you should go and get up and check them out and a really cool thing that",
    "start": "347039",
    "end": "352800"
  },
  {
    "text": "happened this morning by by Richie is that we actually merge into pritus",
    "start": "352800",
    "end": "357919"
  },
  {
    "text": "community that get another cloudwatch exporter which is the most famous um",
    "start": "357919",
    "end": "362960"
  },
  {
    "text": "cloudwatch exporter out there and this just really speaks you know to the passion that the community has when it comes to uh donating building things and",
    "start": "362960",
    "end": "369800"
  },
  {
    "text": "then donating them back to to Prometheus cool um without further Ado I",
    "start": "369800",
    "end": "376520"
  },
  {
    "text": "really want to talk about Prometheus 3.0 and this is probably one of my favorite features that we have right here uh we",
    "start": "376520",
    "end": "382560"
  },
  {
    "text": "have a completely new develop UI onux um built from the ground up and in um in",
    "start": "382560",
    "end": "390880"
  },
  {
    "text": "react uh really beautiful right uh very different from what we had before uh you",
    "start": "390880",
    "end": "397160"
  },
  {
    "text": "have many different settings including the the graph of the resolutions uh but if you if you ask me what is the one",
    "start": "397160",
    "end": "403120"
  },
  {
    "text": "thing that I like the most about this new UI is the query explainer right it's like here you can see straight up what",
    "start": "403120",
    "end": "410720"
  },
  {
    "text": "your query is doing I struggle a lot with promql in the past right trying to figure out okay what the hell my query",
    "start": "410720",
    "end": "416400"
  },
  {
    "text": "is doing um now you can see it's straight up in UI what's actually",
    "start": "416400",
    "end": "421479"
  },
  {
    "text": "happened right like what is this function for and you know you know what the really cool thing about this is that this is actually interacting with your",
    "start": "421479",
    "end": "427840"
  },
  {
    "text": "own data in Prometheus right this is not just some sort of static analysis that tells you hey you know it's like your",
    "start": "427840",
    "end": "435080"
  },
  {
    "text": "quer is M form your syntax is wrong is no no this is actually in some cases as you can see here it's telling you that",
    "start": "435080",
    "end": "442520"
  },
  {
    "text": "the data that you have and the query that you're trying to build it's not compatible right I think this is just",
    "start": "442520",
    "end": "448319"
  },
  {
    "text": "you know amazing elence of the word",
    "start": "448319",
    "end": "453479"
  },
  {
    "text": "um I need to click it thank you so um let's talk native histograms",
    "start": "453479",
    "end": "460520"
  },
  {
    "text": "um for those who who have known uh Prometheus for some time um histograms",
    "start": "460520",
    "end": "466520"
  },
  {
    "text": "are incredibly powerful and they give you a really really good way to to determine how this and that API that HTP",
    "start": "466520",
    "end": "473479"
  },
  {
    "text": "endpoint that whatever is actually behaving and how your users are perceiving performance it's not like the",
    "start": "473479",
    "end": "478960"
  },
  {
    "text": "the usual average or something like actually put them into buckets and figure out okay who's like in the really",
    "start": "478960",
    "end": "484440"
  },
  {
    "text": "bad spot or what are the really slow queries even if 99.99% of my careers are",
    "start": "484440",
    "end": "490039"
  },
  {
    "text": "super quick um maybe a few of them aren't and those are the ones I actually need to care about at some point because I",
    "start": "490039",
    "end": "498039"
  },
  {
    "text": "else my users will be unhappy no matter if they're internal or external users doesn't matter so it used to be quite",
    "start": "498039",
    "end": "505080"
  },
  {
    "text": "involved to to uh to define those and the new style is is simpler in my",
    "start": "505080",
    "end": "511360"
  },
  {
    "text": "opinion but the main thing about the native histograms is if you look at",
    "start": "511360",
    "end": "516399"
  },
  {
    "text": "this this is a this is the heat map of a histogram so what you see here is basically just a distribution of um of",
    "start": "516399",
    "end": "523839"
  },
  {
    "text": "stuff and now you need to debug stuff and clearly from from what you can see",
    "start": "523839",
    "end": "531399"
  },
  {
    "text": "here in in your lower buckets of of of your of your level that's where you have",
    "start": "531399",
    "end": "536519"
  },
  {
    "text": "most of the hits but there's one kind of dirty secret if you implement native",
    "start": "536519",
    "end": "541800"
  },
  {
    "text": "histograms you need to already have good knowledge about what what boundaries for",
    "start": "541800",
    "end": "547240"
  },
  {
    "text": "your buckets you need to have because otherwise you can't really set good ones but if you set too many it's going to",
    "start": "547240",
    "end": "552560"
  },
  {
    "text": "become too expensive in particular at scale like okay you do this one thing on your laptop cool whatever you have 10 or",
    "start": "552560",
    "end": "557760"
  },
  {
    "text": "you have 20 doesn't matter but now you have a thousand pods really starts to add up so you need to be careful you need to have this balance and you used",
    "start": "557760",
    "end": "564560"
  },
  {
    "text": "to need to readjust it all the time so when you look at this obviously clearly",
    "start": "564560",
    "end": "570360"
  },
  {
    "text": "something is happening in the lowest ones this is the same data with Native",
    "start": "570360",
    "end": "575880"
  },
  {
    "text": "histograms and this shows you how it's not only more efficient and easier to do",
    "start": "575880",
    "end": "581279"
  },
  {
    "text": "and you have to do less mental overhead and less mental work to get started with Native histograms like all of those",
    "start": "581279",
    "end": "586440"
  },
  {
    "text": "things are true yes but you actually get higher resolution data and stuff which has previously been hidden is all of a",
    "start": "586440",
    "end": "593680"
  },
  {
    "text": "sudden being made available and obvious to you and it's really really nice to just like basic Bally reduce the amount",
    "start": "593680",
    "end": "601279"
  },
  {
    "text": "of thought and reduce the amount of Co coding which you have to do and get better results and also to be clear the",
    "start": "601279",
    "end": "608040"
  },
  {
    "text": "native histograms in promethus and in open Telemetry they were actually collaborative like initially there were",
    "start": "608040",
    "end": "613120"
  },
  {
    "text": "some some some hairy Parts but they are completely 100% the same so you don't have this thing where it's slightly",
    "start": "613120",
    "end": "618959"
  },
  {
    "text": "different it's 100% the same remote",
    "start": "618959",
    "end": "624640"
  },
  {
    "text": "right remote remote bride remain unchange for almost 7 years and and given the importance of the aspect of",
    "start": "624959",
    "end": "631279"
  },
  {
    "text": "Prometheus it's almost amazing that it got us this far I think it speak speaks wonders of you know how well-designed",
    "start": "631279",
    "end": "637320"
  },
  {
    "text": "the protocol was the first time around Prometheus is you know pull based for a reason and if you want to have the",
    "start": "637320",
    "end": "643519"
  },
  {
    "text": "performance and reality that deserves a monitoring system pulling data that we pulling data is what we consider",
    "start": "643519",
    "end": "649160"
  },
  {
    "text": "ultimately the right thing in Prometheus right however the message the message in",
    "start": "649160",
    "end": "654480"
  },
  {
    "text": "needs were loud and clear uh from the community getting your data out of",
    "start": "654480",
    "end": "659519"
  },
  {
    "text": "getting your data out of promethus reliably and efficiently into other system is crucial for the operation and scaling of your monitoring needs over",
    "start": "659519",
    "end": "666560"
  },
  {
    "text": "the year we have observed an influx of projects like cortex tanos mimir and",
    "start": "666560",
    "end": "672360"
  },
  {
    "text": "other pru compatible backends built around Prometheus and no we know and",
    "start": "672360",
    "end": "677720"
  },
  {
    "text": "understand that Prometheus for the ration is not the solution to the problem at the end of the day so with Prometheus 3.0 we have completely",
    "start": "677720",
    "end": "684480"
  },
  {
    "text": "overhauled or remote writer specification and we're now releasing as version 2.0 know but how exactly did we",
    "start": "684480",
    "end": "691760"
  },
  {
    "text": "actually make it better right let me walk you through an example first in here you can see that",
    "start": "691760",
    "end": "697639"
  },
  {
    "text": "we have one metric with different labels and different samples right and you can",
    "start": "697639",
    "end": "703320"
  },
  {
    "text": "see the verbosity of the actual uh payload on the on the right right like you can see that the labels all",
    "start": "703320",
    "end": "708959"
  },
  {
    "text": "duplicated U the number of values are there and the time sys as well right so like if you look if you look at the new",
    "start": "708959",
    "end": "715279"
  },
  {
    "text": "version you can see now that we use a technique called string inter turning it's pretty similar to what we already",
    "start": "715279",
    "end": "721040"
  },
  {
    "text": "use within the tsdv at the and the index and we call it a symbol table um",
    "start": "721040",
    "end": "726320"
  },
  {
    "text": "defining the values once and then referencing the original definition can save us a lot of space you know and",
    "start": "726320",
    "end": "732079"
  },
  {
    "text": "optimize compression at the end of the day um as such the results of this change are out of the waters right it's",
    "start": "732079",
    "end": "740040"
  },
  {
    "text": "like we have less messages over the wire at the end of the day almost 60% um we",
    "start": "740040",
    "end": "745399"
  },
  {
    "text": "have less location almost 90% And we have uh better CPUs utilization almost",
    "start": "745399",
    "end": "751040"
  },
  {
    "text": "70% down from what we had before but like the important part is not really the research consumption is the research",
    "start": "751040",
    "end": "756480"
  },
  {
    "text": "consumption of top of the added features that the new protocol has right so now you can use the new native histograms uh",
    "start": "756480",
    "end": "763600"
  },
  {
    "text": "format for your classic histograms as well um you have the exemplars you have metadata to always stand on these were",
    "start": "763600",
    "end": "770600"
  },
  {
    "text": "things that you need to you needed to control depending on how much resource usage you wanted to use and how much how",
    "start": "770600",
    "end": "776279"
  },
  {
    "text": "much message over the wire in version one and version two you get all this performance with all those features",
    "start": "776279",
    "end": "781920"
  },
  {
    "text": "enabled basically for free",
    "start": "781920",
    "end": "787959"
  },
  {
    "text": "so um from on a very personal level I've I've been working for or towards",
    "start": "787959",
    "end": "793720"
  },
  {
    "text": "compatibility between what is no open uh open Telemetry in Prometheus even before it had the name open Telemetry like",
    "start": "793720",
    "end": "800440"
  },
  {
    "text": "initially those discussions started somewhere in 2017 2018 with open sensus",
    "start": "800440",
    "end": "805560"
  },
  {
    "text": "it's been a really really long road and there are there are a lot of of things",
    "start": "805560",
    "end": "810839"
  },
  {
    "text": "which we had have which we had to do over the years um so initially it was more on the side of of trying to improve",
    "start": "810839",
    "end": "817880"
  },
  {
    "text": "on the open Telemetry side so This Promise of full promethus compatibility could actually become true and there",
    "start": "817880",
    "end": "824440"
  },
  {
    "text": "were a lot of of hairing problems which we had like bucket boundaries of the histograms and and all like a load of",
    "start": "824440",
    "end": "832040"
  },
  {
    "text": "stuff which just didn't align and a lot of those work has already been done and it's in the past people might not be",
    "start": "832040",
    "end": "837279"
  },
  {
    "text": "fully aware of this CU it didn't make big news for some reason I mean probably because there was always This Promise",
    "start": "837279",
    "end": "842800"
  },
  {
    "text": "already of this being competi so it was less of big news but short version if you're using open Telemetry for your",
    "start": "842800",
    "end": "849720"
  },
  {
    "text": "metric pipeline you can literally just uh enable the OTL endpoint and you can start pushing your stuff into into uh",
    "start": "849720",
    "end": "857240"
  },
  {
    "text": "Prometheus like there's a lot of reasons why we as Prometheus aors like with my Prometheus head on why I strongly prefer",
    "start": "857240",
    "end": "863240"
  },
  {
    "text": "the pole based model and we'll see a little bit of this later and like from a networking perspective it's just more resilient and robust but that doesn't",
    "start": "863240",
    "end": "870199"
  },
  {
    "text": "matter as long as users also want to be using push and you can both with Prometheus remote ride 2.0 and with",
    "start": "870199",
    "end": "878040"
  },
  {
    "text": "OTP this is how you would do the translation uh from OTP into into",
    "start": "878040",
    "end": "883880"
  },
  {
    "text": "Prometheus and for those who have seen this previously it's a little bit different now uh what you can see is we",
    "start": "883880",
    "end": "889920"
  },
  {
    "text": "don't escape utf8 anymore and what you also can see down below and this is relevant for any push based system we",
    "start": "889920",
    "end": "896639"
  },
  {
    "text": "have an outof order window here for 30 minutes you can can Define this as you choose because the thing is if you push",
    "start": "896639",
    "end": "902040"
  },
  {
    "text": "data you you lose a lot of guarantees which are just built in and and normal and just there with a pull-based model",
    "start": "902040",
    "end": "909199"
  },
  {
    "text": "one of them is that your data arrives in order that is out of the window with a push based model because you will have",
    "start": "909199",
    "end": "915720"
  },
  {
    "text": "delays somewhere it will happen someday and you need to account for it so you",
    "start": "915720",
    "end": "920800"
  },
  {
    "text": "can just Define how long is is too long for still allowing out of order stuff to",
    "start": "920800",
    "end": "926240"
  },
  {
    "text": "be put into premesis everything else would be rejected um what you can see here is how how it",
    "start": "926240",
    "end": "934560"
  },
  {
    "text": "looks for the um for the open Telemetry Side Up Above and for the prome side",
    "start": "934560",
    "end": "939600"
  },
  {
    "text": "down below what you can see is this is an up down counter so open Telemetry has two types of Gorges they're functionally",
    "start": "939600",
    "end": "946519"
  },
  {
    "text": "equivalent as far as I'm concerned and I have made this point within open Telemetry since 2020 at at the latest uh",
    "start": "946519",
    "end": "952519"
  },
  {
    "text": "but it doesn't matter like from Prometheus perspective you just have a garge and you as you can see you",
    "start": "952519",
    "end": "958160"
  },
  {
    "text": "actually have the exact same name you don't have to escape your dots or anything anymore speaking of dots and to",
    "start": "958160",
    "end": "965680"
  },
  {
    "text": "be clear when I say Dots here this also means anything within utf8 directionally",
    "start": "965680",
    "end": "970759"
  },
  {
    "text": "but dots were the most pressing thing so that's what we what we engage with first up above you see the exposition",
    "start": "970759",
    "end": "977839"
  },
  {
    "text": "format for those who have of you have ever seen a metrix endpoint like on your kubernetes or in your exporter or in",
    "start": "977839",
    "end": "983880"
  },
  {
    "text": "your workloads or you whatever this will look somewhat familiar like this is how the data is is prec presented by your",
    "start": "983880",
    "end": "989680"
  },
  {
    "text": "instrumented application in a promethus world and you can see that we now escape this and for those who who are familiar",
    "start": "989680",
    "end": "996240"
  },
  {
    "text": "with the format this is not the metric name is now part of uh of the stuff within the curlies and it's now in in",
    "start": "996240",
    "end": "1002600"
  },
  {
    "text": "double quotes we might be able to get rid of this for some cases like for example dots but for the time being we",
    "start": "1002600",
    "end": "1008560"
  },
  {
    "text": "just play it safe and we have this feedback highly appreciated because we don't know what people want we suspect",
    "start": "1008560",
    "end": "1015600"
  },
  {
    "text": "they want their stuff their monitoring stuff to be more stable than slly more convenient but you need to tell us um",
    "start": "1015600",
    "end": "1022120"
  },
  {
    "text": "and as you can see down below if I want to create the same like 10year old 12y",
    "start": "1022120",
    "end": "1028640"
  },
  {
    "text": "old promise of promethus remains true what you see and what you scrape the data you get in is also how you can get",
    "start": "1028640",
    "end": "1034678"
  },
  {
    "text": "it out so you don't have to like do a mental transformation or anything you can literally use the same format for",
    "start": "1034679",
    "end": "1040839"
  },
  {
    "text": "both exposing into promethus and for quering and obviously you can also do like more advanced use cases and that's",
    "start": "1040839",
    "end": "1046959"
  },
  {
    "text": "how the quoting would look there I can't overstate how much work this was",
    "start": "1046959",
    "end": "1052679"
  },
  {
    "text": "like it it sounds simple here but honestly it was a ton of work um",
    "start": "1052679",
    "end": "1058240"
  },
  {
    "text": "last promcon owned did a really good talk on some of the intricacies of this",
    "start": "1058240",
    "end": "1063760"
  },
  {
    "text": "if you want to scan the QR code it just gives you it just gets you to to the talk it goes a little bit into all the",
    "start": "1063760",
    "end": "1070000"
  },
  {
    "text": "detail and all the all the pain which had to be endured for this and again this is directionally the same for",
    "start": "1070000",
    "end": "1076640"
  },
  {
    "text": "anything utf8 dot is dots are just where we started because it's relatively well contained and relatively easy and also",
    "start": "1076640",
    "end": "1082960"
  },
  {
    "text": "had the highest impact for for the least amount of user visible change most of the backend has already been changed",
    "start": "1082960",
    "end": "1089120"
  },
  {
    "text": "because otherwise we couldn't have uh another thing which is coming",
    "start": "1089120",
    "end": "1094280"
  },
  {
    "text": "soon I'm mentally blocking oh yeah the create a time stamp so um with my open metrics head on",
    "start": "1094280",
    "end": "1102760"
  },
  {
    "text": "um this is something we we put into open metrics the exposition format stand for Prometheus in",
    "start": "1102760",
    "end": "1109360"
  },
  {
    "text": "I think it was 2018 maybe 2019 course Google in particular wanted to have this",
    "start": "1109360",
    "end": "1114640"
  },
  {
    "text": "there if you have a counter yes you can do your rate and you if you have resets and everything everything is fine and",
    "start": "1114640",
    "end": "1119840"
  },
  {
    "text": "everything just works but the one thing which he couldn't do previously is without at least some analysis tell how",
    "start": "1119840",
    "end": "1126039"
  },
  {
    "text": "old a counter was and if you have the age of the counter it gives you a really",
    "start": "1126039",
    "end": "1131760"
  },
  {
    "text": "good way to to make a determination how steep your angle of of climb for whatever counter is and again it sounds",
    "start": "1131760",
    "end": "1139760"
  },
  {
    "text": "trivial it sounds easy but it is really really hard to get this right with the level of performance which you're used",
    "start": "1139760",
    "end": "1146919"
  },
  {
    "text": "to from promethus because this basically doubles the cardinality of all your all your counters it's really painful if you",
    "start": "1146919",
    "end": "1154120"
  },
  {
    "text": "if you do this in the simple way we had to do this the hard",
    "start": "1154120",
    "end": "1159000"
  },
  {
    "text": "way now we're back into into pull versus push um so if you look at everything end",
    "start": "1162280",
    "end": "1169760"
  },
  {
    "text": "to end and I'm I'm more than happy to defend the statement like find me after or anything I I I can talk about this topic for hours um from a information",
    "start": "1169760",
    "end": "1178440"
  },
  {
    "text": "theoretical perspective end to end a pool model Gives You Better Properties period not open for debate it is a",
    "start": "1178440",
    "end": "1185120"
  },
  {
    "text": "scientific fact one of the things but it is more upfront work to be very clear",
    "start": "1185120",
    "end": "1191440"
  },
  {
    "text": "like it's easier to just ye something over the wall and it's someone else's problem it's in the pipeline and baby in the back end whatever I don't care about",
    "start": "1191440",
    "end": "1197880"
  },
  {
    "text": "it anymore really nice developer experience but end to end and taking the operators and into account maybe not",
    "start": "1197880",
    "end": "1203720"
  },
  {
    "text": "quite as nice Prometheus made the very deliberate decision that counters don't",
    "start": "1203720",
    "end": "1209360"
  },
  {
    "text": "go ever down they only go up which just monotonic increasing which hope I mean",
    "start": "1209360",
    "end": "1215280"
  },
  {
    "text": "in my opinion also it's the definition of a counter but whatever the point is",
    "start": "1215280",
    "end": "1220520"
  },
  {
    "text": "um you always expose everything and you always expose just the total amount you",
    "start": "1220520",
    "end": "1226200"
  },
  {
    "text": "just keep adding to it then was a very early fundamental decision within open",
    "start": "1226200",
    "end": "1231520"
  },
  {
    "text": "sensus which is now open Telemetry to support Deltas when you push counters or other data so you only send what was",
    "start": "1231520",
    "end": "1239240"
  },
  {
    "text": "changed and this gives you fewer robustness guarantees but that's not the point the point is promethus is",
    "start": "1239240",
    "end": "1245679"
  },
  {
    "text": "deliberately designed in a different way and it is really really painful to to change all the parts of promethus to",
    "start": "1245679",
    "end": "1252400"
  },
  {
    "text": "really properly and robustly support Delta temporality so when you see Delta",
    "start": "1252400",
    "end": "1257600"
  },
  {
    "text": "temporality that is what this is about that you don't have to send your complete counter every time and all the",
    "start": "1257600",
    "end": "1263559"
  },
  {
    "text": "counters you can actually only start sending bits and pieces of what actually changed again you have you have less",
    "start": "1263559",
    "end": "1270159"
  },
  {
    "text": "guarantees on it so if you ask me personally I would still prefer the other model but you can do it soon if you so",
    "start": "1270159",
    "end": "1276080"
  },
  {
    "text": "choose so thank you and if you have any oh no we forgot something we have one more thing oh we have one more",
    "start": "1276080",
    "end": "1282760"
  },
  {
    "text": "thing so we were talking about Prometheus 3 being in the future um you are going to see this",
    "start": "1282760",
    "end": "1289480"
  },
  {
    "text": "merged live right now so click the",
    "start": "1289480",
    "end": "1295360"
  },
  {
    "text": "button bring this in do it without showing any internal",
    "start": "1295360",
    "end": "1302640"
  },
  {
    "text": "work stuff hopefully do this",
    "start": "1302640",
    "end": "1308159"
  },
  {
    "text": "one I complete knows he knows I don't go into the fact that you're not completely",
    "start": "1308159",
    "end": "1315159"
  },
  {
    "text": "a static about this tells me you have no idea how much work this was this so we are talking people of",
    "start": "1315159",
    "end": "1322840"
  },
  {
    "text": "years like in all in all series I'm",
    "start": "1326840",
    "end": "1332760"
  },
  {
    "text": "ready yeah so as is tradition we are also getting all the other promethus maintainers on stage and anything you",
    "start": "1341840",
    "end": "1347720"
  },
  {
    "text": "want to ask just hit us come on up we don't",
    "start": "1347720",
    "end": "1353840"
  },
  {
    "text": "bite any questions someone has to have a",
    "start": "1353840",
    "end": "1361360"
  },
  {
    "text": "question we can run with a microphone as well so raise your hand as well if you want to ask a question maybe it's easier",
    "start": "1361360",
    "end": "1367600"
  },
  {
    "text": "yeah I can also run around with this one so I'm curious about the alert",
    "start": "1367600",
    "end": "1374120"
  },
  {
    "text": "manager and what's changing between diversion changes or can you tell me about",
    "start": "1374120",
    "end": "1381200"
  },
  {
    "text": "it in general sorry I'm here yeah uh in general we we have four new receivers",
    "start": "1381320",
    "end": "1386720"
  },
  {
    "text": "that's kind of like the main thing we have four new Integrations um we have a bunch of fixes around resource",
    "start": "1386720",
    "end": "1392320"
  },
  {
    "text": "consumption a couple memory leaks that we have identified with silences uh we entirely remov the API V1 now it's not",
    "start": "1392320",
    "end": "1399279"
  },
  {
    "text": "you know it's completely deprecated so it's only a strictly V2 you'll see that you see these as well in Prometheus 3.0",
    "start": "1399279",
    "end": "1405039"
  },
  {
    "text": "where you can no longer use B one of the alert manager uh in general is you know",
    "start": "1405039",
    "end": "1410120"
  },
  {
    "text": "uh the receivers I'll say the Integrations is uh the main thing um and yeah a couple of enhancements to the",
    "start": "1410120",
    "end": "1416720"
  },
  {
    "text": "other Integrations that we have I know this car got a lot of love from the community so you know we added a bunch",
    "start": "1416720",
    "end": "1422000"
  },
  {
    "text": "of fields that you can actually configure it over there uh a good friend of mine uh George actually did all the",
    "start": "1422000",
    "end": "1427320"
  },
  {
    "text": "work to support utfa uh in the alert manager so now you can send alerts with Emojis and dots and all that in order to",
    "start": "1427320",
    "end": "1434000"
  },
  {
    "text": "support um the the the open Telemetry initiative that you saw with imp prus it's what's all done in uh",
    "start": "1434000",
    "end": "1441279"
  },
  {
    "text": "do28 any other",
    "start": "1441279",
    "end": "1444799"
  },
  {
    "text": "question sorry follow up so um right now we do have Prometheus integrated and",
    "start": "1448240",
    "end": "1453600"
  },
  {
    "text": "I'll get um alerts through slack so just kind of a follow-up question with that",
    "start": "1453600",
    "end": "1459200"
  },
  {
    "text": "is there any type of Integrations going on with popular say PID your duty or OBS",
    "start": "1459200",
    "end": "1464480"
  },
  {
    "text": "or anything yeah so we do have an integration for uh PID your duty we do have an integration for obsi and what we",
    "start": "1464480",
    "end": "1471760"
  },
  {
    "text": "don't have is the V2 of slack but we do have the B1 so we don't have the Adaptive cards we're trying we're",
    "start": "1471760",
    "end": "1479000"
  },
  {
    "text": "actually looking for feedback right so like if you look around uh we do have a really big issue where we're trying to discuss how do we configure it because",
    "start": "1479000",
    "end": "1485679"
  },
  {
    "text": "that's generally the hard part right like how do you configure the actual slack Integrations when you're using adaptic cards I think it's called it um",
    "start": "1485679",
    "end": "1492919"
  },
  {
    "text": "and we're trying to decide how does the configuration look like at the end of the day in order to be able to support that that that's useful for right now I",
    "start": "1492919",
    "end": "1498840"
  },
  {
    "text": "use Prometheus very much to see what has happened I'm more interested in you know changing that up to see what is",
    "start": "1498840",
    "end": "1505120"
  },
  {
    "text": "happening or maybe even what could be happening so that's cool okay",
    "start": "1505120",
    "end": "1511398"
  },
  {
    "text": "cool quick question so uh now that we released the C uh when will we have",
    "start": "1512360",
    "end": "1518039"
  },
  {
    "text": "these features available in uh projects like mimir or",
    "start": "1518039",
    "end": "1523039"
  },
  {
    "text": "Thanos was can you repeat the question sorry when will we have the features in",
    "start": "1523600",
    "end": "1528679"
  },
  {
    "text": "Fr available for Thanos M so B do you want to take the Thanos one I mean it's",
    "start": "1528679",
    "end": "1535200"
  },
  {
    "text": "on on the road map uh when I was talking about Thanos updates uh project updates yeah um it's part of the part of the",
    "start": "1535200",
    "end": "1542320"
  },
  {
    "text": "work but for the timeline please help if you wanted sooner but I would expect in the next six",
    "start": "1542320",
    "end": "1548360"
  },
  {
    "text": "months uh I think for us it's going to be a similar timeline uh I know",
    "start": "1548360",
    "end": "1553520"
  },
  {
    "text": "we're halfway through the upgrade in",
    "start": "1553520",
    "end": "1558840"
  },
  {
    "text": "our Prometheus um so I think you know next 3 to six months of a timeline",
    "start": "1558840",
    "end": "1564360"
  },
  {
    "text": "before it actually reaches mimir uh and we actually release a new version right like because this is a tricky bit it's",
    "start": "1564360",
    "end": "1569440"
  },
  {
    "text": "like once you get all the changes in you need to make sure they work correctly there's no regressions and then we'll publish or release with all those",
    "start": "1569440",
    "end": "1575360"
  },
  {
    "text": "changes so 3 to six",
    "start": "1575360",
    "end": "1578398"
  },
  {
    "text": "months uh thank you for presentation I have a question to switch into the push model for perus So currently with pool",
    "start": "1583960",
    "end": "1591159"
  },
  {
    "text": "model there are cool features about atomicity of scrapes and you can control like the limit of samples per job uh",
    "start": "1591159",
    "end": "1597760"
  },
  {
    "text": "serious per job Etc and with push one request can contain data from multiple",
    "start": "1597760",
    "end": "1603919"
  },
  {
    "text": "jobs from multiple services do you have any plans to control uh to rate limit",
    "start": "1603919",
    "end": "1609399"
  },
  {
    "text": "this or control amount of data that you push to promes how to protect beend in",
    "start": "1609399",
    "end": "1615120"
  },
  {
    "text": "this I don't think there are any current plans and",
    "start": "1615120",
    "end": "1620240"
  },
  {
    "text": "um number two yeah just talking no number",
    "start": "1620760",
    "end": "1626960"
  },
  {
    "text": "two yeah you don't turn this off okay um so the short version is that you can",
    "start": "1626960",
    "end": "1633720"
  },
  {
    "text": "limit the like rate that remote right sends data at um but not the same way",
    "start": "1633720",
    "end": "1640399"
  },
  {
    "text": "that scrapes are limited right so um remote right just looks at all the data that Prometheus has ingested and sends",
    "start": "1640399",
    "end": "1647320"
  },
  {
    "text": "it in that same order uh but it has no notion of like whether or not certain data was part of scrape",
    "start": "1647320",
    "end": "1652760"
  },
  {
    "text": "one and other data was part of scrape 2 so you can in general rate limit remote right but not in the same way that",
    "start": "1652760",
    "end": "1658640"
  },
  {
    "text": "scrapes are limited yeah yeah and uh the same related",
    "start": "1658640",
    "end": "1664039"
  },
  {
    "text": "question to recording crues uh if I remember correctly Prometheus also has this atomicity of a scrape again so it",
    "start": "1664039",
    "end": "1671279"
  },
  {
    "text": "promises that recording Cru gets complete data during evaluation and now when we push data there are no such",
    "start": "1671279",
    "end": "1677600"
  },
  {
    "text": "promise right and are there any plans to yes I can take",
    "start": "1677600",
    "end": "1684279"
  },
  {
    "text": "this so we fa this problem very early on in Meir and the way that we solve it is",
    "start": "1684279",
    "end": "1689799"
  },
  {
    "text": "that we basically delayed rule evaluation right it's like you at least have a guarantee that you're going to wait I don't know a certain amount of",
    "start": "1689799",
    "end": "1695679"
  },
  {
    "text": "time before your data is there so for rule that you evaluate in t you can do evaluations to T minus one right the",
    "start": "1695679",
    "end": "1702640"
  },
  {
    "text": "cool thing about it is that I actually put that in prus as well right it's an experimental feature I put it about",
    "start": "1702640",
    "end": "1708200"
  },
  {
    "text": "three or four months ago you can actually use it you can actually experiment with it and try to you know delay your recording rule evaluation or",
    "start": "1708200",
    "end": "1715080"
  },
  {
    "text": "your alert evaluation by uh whatever time you think it's necessary to have the guarantees for your data to come in",
    "start": "1715080",
    "end": "1720320"
  },
  {
    "text": "and you know try to solve that problem that way I think that's worked Wonder wonderful for us right the delay is",
    "start": "1720320",
    "end": "1725600"
  },
  {
    "text": "almost negligence if you're R you're running your rules every five minutes which is typical right uh it's only",
    "start": "1725600",
    "end": "1731360"
  },
  {
    "text": "until you get the sub minute evaluations so you start running into a little bit more problems with that and even then",
    "start": "1731360",
    "end": "1736640"
  },
  {
    "text": "other things might break right",
    "start": "1736640",
    "end": "1740039"
  },
  {
    "text": "is there a plan to get that awesome explain ux um visible in other like",
    "start": "1743519",
    "end": "1749120"
  },
  {
    "text": "Prometheus UI like grafana for example can you repeat please repeat the",
    "start": "1749120",
    "end": "1755039"
  },
  {
    "text": "yeah that um that new explain ux that you showed um is there a plan to get",
    "start": "1755039",
    "end": "1760120"
  },
  {
    "text": "that visible in grafana or other Prometheus uis I mean you have three Gana people on",
    "start": "1760120",
    "end": "1766519"
  },
  {
    "text": "stage but we are here to talk about prome so yeah all right I",
    "start": "1766519",
    "end": "1772559"
  },
  {
    "text": "mean at least try it in Prometheus it's like it's really powerful and and even",
    "start": "1772559",
    "end": "1778440"
  },
  {
    "text": "like no matter who we we happen to work for um it is really powerful and is",
    "start": "1778440",
    "end": "1783600"
  },
  {
    "text": "really a a a huge refreshment to to all of Prometheus highly encourage you to to",
    "start": "1783600",
    "end": "1790519"
  },
  {
    "text": "just play with it and try it um you do have some like you have similar functionality in grafana but again",
    "start": "1790519",
    "end": "1796080"
  },
  {
    "text": "that's not the focus of of the talk thanks we have probably time for maybe",
    "start": "1796080",
    "end": "1802519"
  },
  {
    "text": "one or two questions at most we okay gotcha okay uh so I just wanted",
    "start": "1802519",
    "end": "1811200"
  },
  {
    "text": "to ask about uh you know the rise of open Telemetry and how it differs from",
    "start": "1811200",
    "end": "1817240"
  },
  {
    "text": "Prometheus how did you kind of balance the decision to keep some of your",
    "start": "1817240",
    "end": "1823279"
  },
  {
    "text": "opinions that you've talked about and also add the support for open telemetry",
    "start": "1823279",
    "end": "1828679"
  },
  {
    "text": "we are not changing our opinions um and to be very clear those opinions are",
    "start": "1828679",
    "end": "1834559"
  },
  {
    "text": "based on a lot of operational pain and a lot of a lot of learnings Across The",
    "start": "1834559",
    "end": "1840399"
  },
  {
    "text": "Wider industry um so if you're asking what the happy golden path is keep pulling um if",
    "start": "1840399",
    "end": "1848799"
  },
  {
    "text": "you if you look at what what kubernetes does with Cube State metrics it is pull only if you look what what like most",
    "start": "1848799",
    "end": "1855519"
  },
  {
    "text": "Cloud native stuff does it supports for me this is say pull from an end to endend perspective you're going to have",
    "start": "1855519",
    "end": "1861600"
  },
  {
    "text": "an easier time you and the nice thing is you get to offload a lot of the concerns of a pool based model onto US",
    "start": "1861600",
    "end": "1868960"
  },
  {
    "text": "basically um but all of this is irrelevant if a significant portion of the user base also wants to use push and",
    "start": "1868960",
    "end": "1876039"
  },
  {
    "text": "that's just the case so we we are not like closing our eyes and just being",
    "start": "1876039",
    "end": "1881600"
  },
  {
    "text": "like no this is not happening we are very much trying to support us and to be very clear from both the open Telemetry",
    "start": "1881600",
    "end": "1887240"
  },
  {
    "text": "and the promethus side and with my personal head on like I invested insane amounts of time on the open Telemetry",
    "start": "1887240",
    "end": "1892519"
  },
  {
    "text": "side into making all of this better but none of this also changes again yet again that we do have an opinion and",
    "start": "1892519",
    "end": "1898120"
  },
  {
    "text": "this is based on on a lot of experience so happy path remains but we will",
    "start": "1898120",
    "end": "1904000"
  },
  {
    "text": "support everything uh like either fixing it in open Telemetry like for example the bucket boundaries because it would",
    "start": "1904000",
    "end": "1910120"
  },
  {
    "text": "be mathematically impossible to do like to do it on the promethus side it we need it we must do it on Open Telemetry",
    "start": "1910120",
    "end": "1916840"
  },
  {
    "text": "side which is also why we did this first way before this work because it was just a more strategically important one um",
    "start": "1916840",
    "end": "1924120"
  },
  {
    "text": "yeah thank you no first of all thanks for all your hard",
    "start": "1924120",
    "end": "1930760"
  },
  {
    "text": "work we really appreciate it and looking forward to trying out 30 my question is",
    "start": "1930760",
    "end": "1935880"
  },
  {
    "text": "around custom exporters do you see a lot of work there to to reite customer",
    "start": "1935880",
    "end": "1942600"
  },
  {
    "text": "exporters or they pretty much work the same as they have before with 3 it you",
    "start": "1942600",
    "end": "1948360"
  },
  {
    "text": "don't like so if you keep using the old Exposition formul it's going to keep working uh if you use the exporter",
    "start": "1948360",
    "end": "1953919"
  },
  {
    "text": "toolkit which is the recommended way to do your custom exporters um you just get all of this for free as we update the",
    "start": "1953919",
    "end": "1960679"
  },
  {
    "text": "stuff so you don't have to care about anything um yeah",
    "start": "1960679",
    "end": "1966360"
  },
  {
    "text": "so but I mean I know people who just print F from their C and then they put it into a file and put it on a web",
    "start": "1966360",
    "end": "1972600"
  },
  {
    "text": "server like this will continue to work so you don't have to do anything but if you want to have a really nice EXP",
    "start": "1972600",
    "end": "1977880"
  },
  {
    "text": "experience use the exporter toolkit and everything just happens for you yeah okay thank",
    "start": "1977880",
    "end": "1983159"
  },
  {
    "text": "you me we don't have time for any more questions we have two more minutes so maybe one last question if anyone has it",
    "start": "1983159",
    "end": "1989440"
  },
  {
    "text": "or else we just stop here going once going",
    "start": "1989440",
    "end": "1995440"
  },
  {
    "text": "twice thank you very much [Music]",
    "start": "1995440",
    "end": "2003599"
  }
]
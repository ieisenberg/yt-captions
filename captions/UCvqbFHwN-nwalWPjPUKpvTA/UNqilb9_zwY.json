[
  {
    "start": "0",
    "end": "82000"
  },
  {
    "text": "hello and welcome to uh project introduction for jaeger my name is yurish crowe um this month is",
    "start": "160",
    "end": "7759"
  },
  {
    "text": "the fifth anniversary of jaeger starting october uh from the first commute it's in august",
    "start": "7759",
    "end": "13759"
  },
  {
    "text": "and so congrats to the project um as far as the agenda so i will start",
    "start": "13759",
    "end": "19840"
  },
  {
    "text": "with a brief introduction of uh why tracing is an important um part",
    "start": "19840",
    "end": "24960"
  },
  {
    "text": "of the observability for your systems i will do a short",
    "start": "24960",
    "end": "30000"
  },
  {
    "text": "live demo of jaeger features we'll talk about jaeger architecture we'll talk about sampling and i want to",
    "start": "30000",
    "end": "36079"
  },
  {
    "text": "finish with discussion about the relationship between jaeger and open telemetry and how these two projects are",
    "start": "36079",
    "end": "43680"
  },
  {
    "text": "um to say a few words about myself i'm a software engineer at uber",
    "start": "43680",
    "end": "48879"
  },
  {
    "text": "i started jaeger as an internal project and then we donated it to cloud native foundation",
    "start": "48879",
    "end": "56559"
  },
  {
    "text": "i'm also a co-founder of open tracing and open telemetry projects which are the instrumentation",
    "start": "56559",
    "end": "61840"
  },
  {
    "text": "uh projects for tracing and i also published a book last year about tracing and my experiences at uber",
    "start": "61840",
    "end": "68320"
  },
  {
    "text": "as well as experiences with jaeger and how to deploy it and configure and things like that you can find",
    "start": "68320",
    "end": "74400"
  },
  {
    "text": "uh my contact informations on on my website uh with a blog and another information",
    "start": "74400",
    "end": "82159"
  },
  {
    "start": "82000",
    "end": "377000"
  },
  {
    "text": "so to start with with the search question of observability um why tracing is important in",
    "start": "82159",
    "end": "90000"
  },
  {
    "text": "microservices especially in microservices architectures and why it becomes popular today so",
    "start": "90000",
    "end": "97280"
  },
  {
    "text": "modern systems have to deal with a very large scale and the traditional wisdom is that we",
    "start": "97280",
    "end": "103119"
  },
  {
    "text": "cannot scale up our servers because there's a limit to how much any given server can process and so",
    "start": "103119",
    "end": "109840"
  },
  {
    "text": "usually people say okay we need to scale out and build architecture in that way but what does scale out actually",
    "start": "109840",
    "end": "115840"
  },
  {
    "text": "mean the simplest uh approach to scaling out is that if you have a monolith service",
    "start": "115840",
    "end": "121920"
  },
  {
    "text": "you can just replicate it multiple times in many hosts and put a load balance in front of it and if",
    "start": "121920",
    "end": "127520"
  },
  {
    "text": "that's the whole of your architecture then you have a pretty uh clear picture of",
    "start": "127520",
    "end": "132640"
  },
  {
    "text": "uh how to debug these things and what type durability story is it because you could probably get away with just",
    "start": "132640",
    "end": "137840"
  },
  {
    "text": "metrics for every single instance tagged with the instance name and then you can investigate problems with that",
    "start": "137840",
    "end": "143520"
  },
  {
    "text": "architecture but in reality this is not how the systems are built today",
    "start": "143520",
    "end": "148879"
  },
  {
    "text": "and this is another type of scaling that we can talk about is it's scaling the systems in in depth uh",
    "start": "148879",
    "end": "155519"
  },
  {
    "text": "meaning that we don't have a single monarchs we actually break monoliths into many many different pieces and many different",
    "start": "155519",
    "end": "161680"
  },
  {
    "text": "layers and so any individual request that that hits the architecture has to go through all these many layers",
    "start": "161680",
    "end": "168080"
  },
  {
    "text": "so modern architectures are really deep systems uh if you look at any of them",
    "start": "168080",
    "end": "173440"
  },
  {
    "text": "and deep systems present unique challenges in terms of observability if we look at uh this picture which is",
    "start": "173440",
    "end": "180560"
  },
  {
    "text": "just a screenshot of uh microservices layout two birds few years ago so imagine that",
    "start": "180560",
    "end": "188239"
  },
  {
    "text": "there is a request coming from the mobile application that request might look like this when it hits this architecture right it",
    "start": "188239",
    "end": "194640"
  },
  {
    "text": "it goes through a large number of services all participating together and inserting one single request and",
    "start": "194640",
    "end": "202319"
  },
  {
    "text": "we can look at it in a different way this is the actual representation of the real production request from from uber",
    "start": "202319",
    "end": "207440"
  },
  {
    "text": "right might be an application start and we can see here there's like over 100 uh remote procedure calls within that",
    "start": "207440",
    "end": "214720"
  },
  {
    "text": "execution uh 14 levels of depth so why is that a problem for observability well the",
    "start": "214720",
    "end": "220159"
  },
  {
    "text": "problem is that now we have to answer questions uh about uh what's wrong with the system",
    "start": "220159",
    "end": "228319"
  },
  {
    "text": "uh given so many different nodes in the system that where the things can go wrong right and how do we start with that we we",
    "start": "228319",
    "end": "235120"
  },
  {
    "text": "approach it usually with oh we have some business metrics maybe the number of trips in a particular city",
    "start": "235120",
    "end": "240319"
  },
  {
    "text": "and suddenly that metrics dipped and so we have an alert and we try to investigate but then",
    "start": "240319",
    "end": "245840"
  },
  {
    "text": "then what where do you go from that business metric saying something is wrong to where in this massive architecture a",
    "start": "245840",
    "end": "252239"
  },
  {
    "text": "particular change happened that is causing this problem and this is where tracing really comes in because tracing",
    "start": "252239",
    "end": "258479"
  },
  {
    "text": "allows us to look at individual requests in full depth end to end and if there",
    "start": "258479",
    "end": "264160"
  },
  {
    "text": "are errors happening they will be captured in the trace um and so the the conclusion here is",
    "start": "264160",
    "end": "270240"
  },
  {
    "text": "that this is why tracing is important because uh in in the modern deep systems um sometimes it's much more difficult to",
    "start": "270240",
    "end": "277919"
  },
  {
    "text": "find where the problem is given the how distributed the system is rather than what is specifically wrong",
    "start": "277919",
    "end": "284080"
  },
  {
    "text": "because once you narrow down the problem there are a lot of variety of different tools that you can use to troubleshoot",
    "start": "284080",
    "end": "289759"
  },
  {
    "text": "it within let's say a single instance of a service but even to get there is very challenging especially if you're",
    "start": "289759",
    "end": "295840"
  },
  {
    "text": "starting from an alert on a business metric um i just want to give a brief kind of",
    "start": "295840",
    "end": "301919"
  },
  {
    "text": "crash course into tracing if you don't know how that works uh the the tracing is built on the",
    "start": "301919",
    "end": "307520"
  },
  {
    "text": "concept of a context propagation meaning that when the request comes to our architecture in this case let's say",
    "start": "307520",
    "end": "313440"
  },
  {
    "text": "service a at the top is the kind of gateway service maybe or api service and as soon as the",
    "start": "313440",
    "end": "320560"
  },
  {
    "text": "request comes in we assign a unique id to that request let's call it a trace id and we store it",
    "start": "320560",
    "end": "325600"
  },
  {
    "text": "in a thing which we call a context or a metadata and that metadata is attached to every single other rpc",
    "start": "325600",
    "end": "332000"
  },
  {
    "text": "call or request that the execution of this top level request involves right and so as",
    "start": "332000",
    "end": "337360"
  },
  {
    "text": "service or a call service b we will pass that metadata in and so on and so on uh and what that",
    "start": "337360",
    "end": "343039"
  },
  {
    "text": "does is basically that allows us to tag the a single execution across multiple services",
    "start": "343039",
    "end": "349039"
  },
  {
    "text": "and then assemble this data on the back end into coherent representation of the of the execution and",
    "start": "349039",
    "end": "354800"
  },
  {
    "text": "this is kind of a typical representation of a trace in the gantt chart where each service is",
    "start": "354800",
    "end": "360960"
  },
  {
    "text": "represented by a certain span of time uh where like from start to end of the operation within that service",
    "start": "360960",
    "end": "367360"
  },
  {
    "text": "and then there's a hierarchical relationship between uh between services um like a causality",
    "start": "367360",
    "end": "373199"
  },
  {
    "text": "which is being tracked by this metadata being propagated now let's look at the demo of jaeger",
    "start": "373199",
    "end": "379680"
  },
  {
    "start": "377000",
    "end": "448000"
  },
  {
    "text": "features so i have here um a clone of uh main jaeger repository",
    "start": "379680",
    "end": "385280"
  },
  {
    "text": "from github yaga tracing slash jager and there is a directory for examples",
    "start": "385280",
    "end": "390319"
  },
  {
    "text": "with a single sample application called hot rod so in that application we can see there",
    "start": "390319",
    "end": "395520"
  },
  {
    "text": "is a docker compose file which loads uh so-called jaeger",
    "start": "395520",
    "end": "402800"
  },
  {
    "text": "all-in-one this is a binary of single binary that combines",
    "start": "402800",
    "end": "408000"
  },
  {
    "text": "all of the jaeger components in just one executable so you can kind of easily run it and then there is another uh docker",
    "start": "408000",
    "end": "414479"
  },
  {
    "text": "image for the actual demo applications right so",
    "start": "414479",
    "end": "419199"
  },
  {
    "text": "let's start it uh we can see in the logs uh there are",
    "start": "421440",
    "end": "428479"
  },
  {
    "text": "two things so jaeger is the the main jaeger back end so it starts on on this uh port 16686 this is the query",
    "start": "428479",
    "end": "436000"
  },
  {
    "text": "series which also shows the front end the ui and then the the gem application started a whole",
    "start": "436000",
    "end": "441120"
  },
  {
    "text": "bunch of services uh the the one that's at 8080 is the one that we actually want to look at so",
    "start": "441120",
    "end": "447120"
  },
  {
    "text": "let's go there so we can see this is a kind of a mock rides on demand application where you",
    "start": "447120",
    "end": "453039"
  },
  {
    "text": "have customers and you can click a button and get a car right so let's order uh a few cars and we can see here",
    "start": "453039",
    "end": "459520"
  },
  {
    "text": "there's like license plate eta of arrival then some tracking",
    "start": "459520",
    "end": "464800"
  },
  {
    "text": "information for for debugging purposes uh and and the latency and you can see that the latency",
    "start": "464800",
    "end": "470639"
  },
  {
    "text": "kind of the more requests we put in the the higher the latency becomes right so like if i if i do another request it",
    "start": "470639",
    "end": "476960"
  },
  {
    "text": "will be short but if i send many of them then we'll see that the latency keeps climbing",
    "start": "476960",
    "end": "482560"
  },
  {
    "text": "right let's look at how these requests look in jager so we'll go to localhost at this point",
    "start": "482560",
    "end": "489919"
  },
  {
    "text": "that i mentioned previously and we can see here in the services drop down that",
    "start": "489919",
    "end": "496800"
  },
  {
    "start": "491000",
    "end": "541000"
  },
  {
    "text": "jaeger already detected all of our services in that mock application it also",
    "start": "496800",
    "end": "502319"
  },
  {
    "text": "detected itself because jaeger query itself is instrumented and so we can get traces from it",
    "start": "502319",
    "end": "508160"
  },
  {
    "text": "um so but we're interested in in in in the hot rods uh application but before we jump into traces",
    "start": "508160",
    "end": "514080"
  },
  {
    "text": "would it be nice if we knew what the architecture of that application is because all we've seen so far is the",
    "start": "514080",
    "end": "519680"
  },
  {
    "text": "front-end and so jaeger has the system architecture tab for this there's two views one is not like useful",
    "start": "519680",
    "end": "526240"
  },
  {
    "text": "for this case but the dag view is is is good uh because it gives us very clear picture of what all",
    "start": "526240",
    "end": "532240"
  },
  {
    "text": "the services that are included in this application how they're connected uh this is a number of requests",
    "start": "532240",
    "end": "537920"
  },
  {
    "text": "that were executed during my run of the demo let's go to see what what actual traces",
    "start": "537920",
    "end": "544560"
  },
  {
    "start": "541000",
    "end": "996000"
  },
  {
    "text": "look like right so there's a few ways that you can search for traces one is we can just go and do a blind",
    "start": "544560",
    "end": "550480"
  },
  {
    "text": "search once we selected the service we can just see and find all of them right",
    "start": "550480",
    "end": "556000"
  },
  {
    "text": "the other option we can do search by specific values if they are captured in an",
    "start": "556000",
    "end": "561760"
  },
  {
    "text": "instrumentation and in this case the instrumentation records these license plates",
    "start": "561760",
    "end": "567519"
  },
  {
    "text": "as the tag driver on the span of the of the service and so we can put it in a",
    "start": "567519",
    "end": "573040"
  },
  {
    "text": "search query we get just this one trace right and if",
    "start": "573040",
    "end": "579360"
  },
  {
    "text": "we go in that trace uh so let's let's just go through that view which is kind of the main view of most racing systems uh at least for",
    "start": "579360",
    "end": "586800"
  },
  {
    "text": "for a given trace right so here on we have a timeline so this is also known as a gantt chart view um and at the top we",
    "start": "586800",
    "end": "594160"
  },
  {
    "text": "have uh what we call a mini map it's kind of the small presentation of the trace it's useful when you need to navigate very",
    "start": "594160",
    "end": "600720"
  },
  {
    "text": "large traces because you can zoom in here and uh jump into various places",
    "start": "600720",
    "end": "606560"
  },
  {
    "text": "but in this case uh almost all of the trays well actually half of it still fits only on the screen so uh the mini map might be useful as",
    "start": "606560",
    "end": "613680"
  },
  {
    "text": "well then on the left we have um all these services uh laid out in the hierarchical manner",
    "start": "613680",
    "end": "620240"
  },
  {
    "text": "showing what uh how how which service called which are the service rights um so we can if we collapse everything",
    "start": "620240",
    "end": "628399"
  },
  {
    "text": "and then open only uh one level we will see that uh actually one more",
    "start": "628399",
    "end": "634320"
  },
  {
    "text": "level we can see here that the front-end service called the customer then it's called the root service multiple times",
    "start": "634320",
    "end": "640000"
  },
  {
    "text": "uh and also called the driver service here right so which is what what we've seen",
    "start": "640000",
    "end": "645920"
  },
  {
    "text": "in the in architecture diagram um and uh and basically every every bar here",
    "start": "645920",
    "end": "652320"
  },
  {
    "text": "represents a single span within the service uh you can see that let's say if we pick",
    "start": "652320",
    "end": "657680"
  },
  {
    "text": "a front end there is more than one span here even though logically there's only one operation because uh the way the tracing",
    "start": "657680",
    "end": "663839"
  },
  {
    "text": "instrumentation is done it creates a span not only for every incoming request but also for every",
    "start": "663839",
    "end": "669519"
  },
  {
    "text": "outgoing request so this http get dispatched that was the entry point into the",
    "start": "669519",
    "end": "676160"
  },
  {
    "text": "front-end service but then when it made a call another http call to the to the customer",
    "start": "676160",
    "end": "681360"
  },
  {
    "text": "service there was another child spend so-called client spam created there and if we click on any span we can get",
    "start": "681360",
    "end": "688000"
  },
  {
    "text": "uh additional details so let's look at the at the root span so the one thing that we have in spans are",
    "start": "688000",
    "end": "694480"
  },
  {
    "text": "things called tags tags are just some uh metadata that you can attach to the spans and it gets recorded and sent",
    "start": "694480",
    "end": "701120"
  },
  {
    "text": "in in the background to the yeah tracing back and so we can see there is useful things specifically like the the",
    "start": "701120",
    "end": "707760"
  },
  {
    "text": "exact url uh you don't want to put the url in the span name because that will make it very high cardinality and difficult to",
    "start": "707760",
    "end": "714000"
  },
  {
    "text": "aggregate but in the tags you can put any kind of cardinality and this is just i think nonsense for the ui",
    "start": "714000",
    "end": "721120"
  },
  {
    "text": "cache investing and then another interesting thing here is a span kind which says this is a",
    "start": "721120",
    "end": "728079"
  },
  {
    "text": "server span right so if we look at the next one as i said this is an outgoing outgoing call",
    "start": "728079",
    "end": "733519"
  },
  {
    "text": "uh or sorry this one doesn't have this this one it will have a span kind of",
    "start": "733519",
    "end": "740399"
  },
  {
    "text": "client so which says this is the uh the call i'm making out of the process to to the",
    "start": "740399",
    "end": "746000"
  },
  {
    "text": "next server and we can see that the url is it's hitting the customer service",
    "start": "746000",
    "end": "751279"
  },
  {
    "text": "going back to the top span um another thing that we can see here is that",
    "start": "751279",
    "end": "758160"
  },
  {
    "text": "the locks section right so uh in in the output here we can see that",
    "start": "758160",
    "end": "765760"
  },
  {
    "text": "there's like as i was executing this request there is a bunch of logs written to the standard out right and this is normal",
    "start": "765760",
    "end": "772480"
  },
  {
    "text": "you can pipe them into some central uh look aggregator aggregator",
    "start": "772480",
    "end": "777680"
  },
  {
    "text": "but they're kind of very difficult to use because again if if there are multiple concurrent requests you get a single jumble of",
    "start": "777680",
    "end": "784480"
  },
  {
    "text": "of these log lines mixed together whereas here these logs belong just to a single",
    "start": "784480",
    "end": "789519"
  },
  {
    "text": "request right and this the way they get into the trace is that if you look at the implementation of hot rod application it has a special",
    "start": "789519",
    "end": "796560"
  },
  {
    "text": "wrapper for the logger so that logger not only logs to send it out but also writes to the current span",
    "start": "796560",
    "end": "802320"
  },
  {
    "text": "uh and that allows you to kind of get the exact same information uh but uh like filtered out from the",
    "start": "802320",
    "end": "809360"
  },
  {
    "text": "from the rest of the noise that you can see in the logs so this is a very powerful feature of tracing that allows you to investigate problems um",
    "start": "809360",
    "end": "817120"
  },
  {
    "text": "within like very specific uh execution of your of your total trace",
    "start": "817120",
    "end": "822240"
  },
  {
    "text": "now let's uh expand everything again and look at uh what what the trace can also tell us uh",
    "start": "822240",
    "end": "828160"
  },
  {
    "text": "so one thing that's immediately obvious is that there is this mysql select which takes uh a majority like two",
    "start": "828160",
    "end": "835279"
  },
  {
    "text": "thirds of the total time of this request right so if we were investigating the latency problem then",
    "start": "835279",
    "end": "840959"
  },
  {
    "text": "this is clearly the path where we would look for for why this this particular places",
    "start": "840959",
    "end": "846639"
  },
  {
    "text": "is very slow it also has some interesting logs i'm not going to go into into this much too much but it says",
    "start": "846639",
    "end": "852000"
  },
  {
    "text": "waiting for log behind three transactions so it's probably not the actual query that was uh taking so long but the the operation",
    "start": "852000",
    "end": "859680"
  },
  {
    "text": "was simply stuck in india service right so there might be some resource pool contention here um the the other thing we can see",
    "start": "859680",
    "end": "866959"
  },
  {
    "text": "in the trace is that uh these multiple calls from the driver to radius service some of them failed as as can be",
    "start": "866959",
    "end": "873600"
  },
  {
    "text": "indicated by this red exclamation point and the way that that is detected is that if you look at",
    "start": "873600",
    "end": "879920"
  },
  {
    "text": "the tags you will see error equals true right so again this is uh instrumentation setting that up you can always do it for your own",
    "start": "879920",
    "end": "886000"
  },
  {
    "text": "spans or your own operations uh how you see fit uh jager simply just displays this",
    "start": "886000",
    "end": "892320"
  },
  {
    "text": "these errors have the ability to a bubble up the tree so if i start uh collapsing",
    "start": "892320",
    "end": "898720"
  },
  {
    "text": "uh things and we can see here that the driver is shown with an error even though there was no specific error in",
    "start": "898720",
    "end": "904000"
  },
  {
    "text": "the driver uh but then if you expand it then it's actually below right so sometimes it's useful when you're",
    "start": "904000",
    "end": "909600"
  },
  {
    "text": "looking at the very top of the trace to know if there are any errors and then you can drill down into where the exactly they happened and",
    "start": "909600",
    "end": "916560"
  },
  {
    "text": "finally uh another thing that we can easily tell from the trades in terms of like analyzing performance of the",
    "start": "916560",
    "end": "921920"
  },
  {
    "text": "applications that these calls to radius seem to be happening all in uh in a sort of a staircase pattern right",
    "start": "921920",
    "end": "928320"
  },
  {
    "text": "one after another so that would clearly be an indication of something that potentially can be improved uh because",
    "start": "928320",
    "end": "934399"
  },
  {
    "text": "if we know the the business logic of the application here uh it looks like it's getting like driver informations for different",
    "start": "934399",
    "end": "940560"
  },
  {
    "text": "drivers and so why couldn't the task radius for that in parallel or in a single bulk request right so that would have saved",
    "start": "940560",
    "end": "946639"
  },
  {
    "text": "uh this this much time basically by doing this all in one and finally the last segment where the",
    "start": "946639",
    "end": "952480"
  },
  {
    "text": "front application calls into the root service asking what is the closest route for the driver to get to us so that we",
    "start": "952480",
    "end": "958079"
  },
  {
    "text": "can compute the ata then we can see here that uh this execution is not as bad because there",
    "start": "958079",
    "end": "964480"
  },
  {
    "text": "are some concurrent requests going on but there is no more than three concurrent requests for some reason",
    "start": "964480",
    "end": "969519"
  },
  {
    "text": "right so this stop uh one two three and then once as soon as one star stops then the",
    "start": "969519",
    "end": "975680"
  },
  {
    "text": "other one starts so this is again an indication of some sort of resourceful contention this is like an executor pool uh",
    "start": "975680",
    "end": "982000"
  },
  {
    "text": "that's uh limited by three and you cannot execute more than that and so if you run multiple concurrent requests",
    "start": "982000",
    "end": "987279"
  },
  {
    "text": "then they're all gonna be blocking on this thing but in this case we don't see it because the contention the main contention is",
    "start": "987279",
    "end": "993199"
  },
  {
    "text": "really the mysql uh span if you if i go back to search screen the one thing i didn't talk about",
    "start": "993199",
    "end": "999279"
  },
  {
    "text": "it is uh is uh kind of what what you get on the search screen so um we you can also search for traces",
    "start": "999279",
    "end": "1005920"
  },
  {
    "text": "uh by other attributes specifically by duration right which could be very useful because if you are capturing a lot of",
    "start": "1005920",
    "end": "1012000"
  },
  {
    "text": "traces in the system some of them are maybe very short and quick and you are not really interested in investigating them",
    "start": "1012000",
    "end": "1018000"
  },
  {
    "text": "you really want to look at what your p99 latency traces and presumably you have some metric which says oh your p90 lite",
    "start": "1018000",
    "end": "1024319"
  },
  {
    "text": "entity is like two seconds right and you can put a query saying can you show me traces which are longer than",
    "start": "1024319",
    "end": "1029918"
  },
  {
    "text": "1.5 seconds right and so then boom we only have one trace here in this case if i make it maybe like",
    "start": "1029919",
    "end": "1036959"
  },
  {
    "text": "one second i get a few more right um so uh that allows you to narrow down the",
    "start": "1036959",
    "end": "1042959"
  },
  {
    "text": "search and then investigate uh the what the differences are uh in in this traces but",
    "start": "1042959",
    "end": "1048400"
  },
  {
    "text": "sometimes um looking at one single trace doesn't necessarily reveal all the problems that might be",
    "start": "1048400",
    "end": "1054559"
  },
  {
    "text": "happening in terms of performance and uh typically when you use normal uh performance profiling tools like",
    "start": "1054559",
    "end": "1061280"
  },
  {
    "text": "memory allocations you would take a snapshot before and after and then you compare those snapshots right and so jaeger also has this ability to",
    "start": "1061280",
    "end": "1067840"
  },
  {
    "text": "do the comparison uh you can select two traces uh and then click compare and what it",
    "start": "1067840",
    "end": "1073039"
  },
  {
    "text": "does is that combines them into into the graph representation and uses green and red color coding to indicate where",
    "start": "1073039",
    "end": "1078880"
  },
  {
    "text": "there are missing or extra nodes in this case because there's only one uh extra node so the the picture is not",
    "start": "1078880",
    "end": "1085760"
  },
  {
    "text": "that interesting but if we had a very large trace then that picture got a lot more interesting and i",
    "start": "1085760",
    "end": "1091120"
  },
  {
    "text": "can show you later in the slides example from real production traces and",
    "start": "1091120",
    "end": "1096640"
  },
  {
    "text": "finally the last piece i want to show here is we've looked at the system",
    "start": "1096640",
    "end": "1102640"
  },
  {
    "text": "architecture before this one right there is another view that jaeger has",
    "start": "1102640",
    "end": "1108880"
  },
  {
    "text": "which is called deep dependency graph it's built from the search results let me remove this uh duration so that i",
    "start": "1108880",
    "end": "1115120"
  },
  {
    "text": "can get more traces so 12 traces uh and then deep dependency graph builds uh uh an execution um like a",
    "start": "1115120",
    "end": "1123200"
  },
  {
    "text": "rigid representation of that of those traces however it looks very similar to the system architecture",
    "start": "1123200",
    "end": "1129200"
  },
  {
    "text": "but there is a significant difference in that this this graph is transitive so when you see an error going through the",
    "start": "1129200",
    "end": "1136160"
  },
  {
    "text": "like front-end service to driver and then to radius we know that",
    "start": "1136160",
    "end": "1141280"
  },
  {
    "text": "there is actually a path in some of the traces that goes through these two services whereas in the system architecture",
    "start": "1141280",
    "end": "1148799"
  },
  {
    "text": "that's not guaranteed so um just because there is a kind of an error from front end to customer doesn't",
    "start": "1148799",
    "end": "1155120"
  },
  {
    "text": "mean that there is any request from front end which will reach the mysql right because this graph is based on just the",
    "start": "1155120",
    "end": "1161120"
  },
  {
    "text": "pairwise connections between services and so why is that important is because uh sometimes sorry you need to search",
    "start": "1161120",
    "end": "1168480"
  },
  {
    "text": "again when you're investigating like dependencies of the services you",
    "start": "1168480",
    "end": "1174480"
  },
  {
    "text": "not only want to see what are my immediate dependencies under on the front-end service but you want to",
    "start": "1174480",
    "end": "1179600"
  },
  {
    "text": "like look for deeper dependencies but only those which actually matter because if there is a dependency of root service",
    "start": "1179600",
    "end": "1185360"
  },
  {
    "text": "let's say it's doing some background caching and hit some some storage here which never affects any of the front-end",
    "start": "1185360",
    "end": "1191280"
  },
  {
    "text": "requests then we don't show it here because it does not come up in the traces right and another feature of this graph",
    "start": "1191280",
    "end": "1196480"
  },
  {
    "text": "is that uh it's it is not going to show you the whole architecture but only pass going through the focal servers which is",
    "start": "1196480",
    "end": "1202400"
  },
  {
    "text": "why it's in pink here so we can refocus this view to another service and then it will",
    "start": "1202400",
    "end": "1207440"
  },
  {
    "text": "become even smaller uh for example in drive right because there's no paths that go through driver",
    "start": "1207440",
    "end": "1212880"
  },
  {
    "text": "and also through the customer service so they're not going to be shown here and finally this graph is also uh",
    "start": "1212880",
    "end": "1220000"
  },
  {
    "text": "can show you uh operation level view not just a service level view right",
    "start": "1220000",
    "end": "1225440"
  },
  {
    "text": "and so we can see here that there are actually two different operations from the regis that are being called uh and so they can",
    "start": "1225440",
    "end": "1231280"
  },
  {
    "text": "you can switch to this in the layout view you can you can change the graph to to show you different information",
    "start": "1231280",
    "end": "1237039"
  },
  {
    "text": "um so this graph we we built it as a sort of a platform to to do more stuff with it specifically",
    "start": "1237039",
    "end": "1243280"
  },
  {
    "text": "overlay and real-time information like what's your current latency or error rates on this graph right now it's",
    "start": "1243280",
    "end": "1249200"
  },
  {
    "text": "not hooked up in any way but this is kind of the future direction that we're going with",
    "start": "1249200",
    "end": "1254240"
  },
  {
    "text": "so i think this uh this is uh all i wanted to show you in the demo so",
    "start": "1254240",
    "end": "1260559"
  },
  {
    "text": "and then i will switch to my slide deck um and",
    "start": "1260559",
    "end": "1265840"
  },
  {
    "text": "i'll start with this sorry with this uh view that i mentioned over",
    "start": "1265840",
    "end": "1272559"
  },
  {
    "text": "production trace where you compare it to traces and we can see here that because um this this these two traces are much",
    "start": "1272559",
    "end": "1280240"
  },
  {
    "text": "larger uh there also they have a lot more interesting differences right and so at the red at the bottom shows that a",
    "start": "1280240",
    "end": "1286799"
  },
  {
    "text": "whole number of calls uh did not happen in the in the round right hand side trace uh and so for example if we look at the",
    "start": "1286799",
    "end": "1294000"
  },
  {
    "text": "duration the left one was 2.7 seconds the right one is 1.4 and so well because",
    "start": "1294000",
    "end": "1299200"
  },
  {
    "text": "this whole section is missing that kind of explains why it was faster but it also potentially there is an error there right and so",
    "start": "1299200",
    "end": "1306720"
  },
  {
    "text": "yeah i will skip this detail there's another way to to look at this uh comparison of the traces so this",
    "start": "1306720",
    "end": "1312720"
  },
  {
    "text": "comparison is currently structural so we're just comparing do the nodes exist in one versus another graph right",
    "start": "1312720",
    "end": "1319120"
  },
  {
    "text": "but uh we also may look sometimes at the uh the latency differences within each",
    "start": "1319120",
    "end": "1324240"
  },
  {
    "text": "individual span right um and so the latency difference is is kind of uh gives you a very different picture uh",
    "start": "1324240",
    "end": "1330799"
  },
  {
    "text": "but also drives your um sight immediately to the problems where you",
    "start": "1330799",
    "end": "1337360"
  },
  {
    "text": "want to investigate right so here we can see we're using like a heat map color coding for for like the darker red the darker",
    "start": "1337360",
    "end": "1344080"
  },
  {
    "text": "the red the the more latency differences in is within these notes uh and then the quiet notes means that",
    "start": "1344080",
    "end": "1350000"
  },
  {
    "text": "some of the notes were not even present in in the right hand side trace whereas gray means it's like there are no",
    "start": "1350000",
    "end": "1355520"
  },
  {
    "text": "difference and so we can see for example that kind of the the overall latency difference came into in this path right so it got",
    "start": "1355520",
    "end": "1362720"
  },
  {
    "text": "lighter light lighter but this is kind of one of the suspect spans that you might want to drill down and and look at what was",
    "start": "1362720",
    "end": "1369360"
  },
  {
    "text": "happening there uh and if you um mouse over uh these uh these nodes that actually shows",
    "start": "1369360",
    "end": "1376480"
  },
  {
    "text": "you how much extra time was spent in this specific span and how what the percentage of time over all of the trace",
    "start": "1376480",
    "end": "1382480"
  },
  {
    "text": "was wasted there um so i believe this this view is actually still not in the main branch it's like in the",
    "start": "1382480",
    "end": "1389360"
  },
  {
    "text": "pull request unfortunately so you can probably try it right away but um",
    "start": "1389360",
    "end": "1394799"
  },
  {
    "start": "1394000",
    "end": "1452000"
  },
  {
    "text": "so uh in conclusion you can use tracing tool to monitor transactions in your distributed",
    "start": "1394799",
    "end": "1400960"
  },
  {
    "text": "architecture and see where the requests are executing which services has been hit and what happens in every step of the way right uh we can also do",
    "start": "1400960",
    "end": "1408400"
  },
  {
    "text": "root cause analysis by looking at individual details like what tags exist in each span",
    "start": "1408400",
    "end": "1413440"
  },
  {
    "text": "uh like maybe sql query or a url uh or some errors where they happen and we can drill down into those uh we",
    "start": "1413440",
    "end": "1420159"
  },
  {
    "text": "can also look at various patterns of how the timeline time layout",
    "start": "1420159",
    "end": "1425200"
  },
  {
    "text": "of the trace look and so we can detect immediately patterns like what's the longest critical path what's the",
    "start": "1425200",
    "end": "1430880"
  },
  {
    "text": "staircase pattern why it's happening sequentially and things like that these visualizations make it very easy to",
    "start": "1430880",
    "end": "1436320"
  },
  {
    "text": "troubleshoot um and finally we can do um various service dependency analysis on the traces by using this system graph",
    "start": "1436320",
    "end": "1443279"
  },
  {
    "text": "and the transitive dependency graph and as i mentioned all of that is based on the distributed context propagation which is",
    "start": "1443279",
    "end": "1449760"
  },
  {
    "text": "provided by jager sdks and so now let's talk about jaeger",
    "start": "1449760",
    "end": "1455279"
  },
  {
    "start": "1452000",
    "end": "1525000"
  },
  {
    "text": "architecture and overall jaeger project so uh jaeger as a platform",
    "start": "1455279",
    "end": "1460480"
  },
  {
    "text": "uh consists of these four components uh it has a a number of client libraries also called",
    "start": "1460480",
    "end": "1467120"
  },
  {
    "text": "sdks or tracers in different languages you can see it on the left they all implement open tracing",
    "start": "1467120",
    "end": "1472159"
  },
  {
    "text": "api um and so those are the things that you put inside your application or inside",
    "start": "1472159",
    "end": "1477600"
  },
  {
    "text": "the framework that you're using within the application right and they collect data and they send it out uh to the jager backend and",
    "start": "1477600",
    "end": "1483440"
  },
  {
    "text": "that's the the middle piece here trace collection back-end uh which includes storage uh some pre-processing",
    "start": "1483440",
    "end": "1490080"
  },
  {
    "text": "some potential aggregations and things like that uh and back-end also feeds into the data mining",
    "start": "1490080",
    "end": "1495120"
  },
  {
    "text": "platform where you can run big job analysis big data analysis like flink jobs for real-time streaming or",
    "start": "1495120",
    "end": "1501279"
  },
  {
    "text": "spark and create aggregates or views of your traces for example the system graph",
    "start": "1501279",
    "end": "1508000"
  },
  {
    "text": "uh in the demo it was like all in memory but you can deploy it in such a way that it will actually compute uh from from a large",
    "start": "1508000",
    "end": "1515039"
  },
  {
    "text": "amount of traces and give you the visualizations and finally the the front end is embedded in the jaeger query as i",
    "start": "1515039",
    "end": "1521200"
  },
  {
    "text": "mentioned and provides the different views of the traces um one thing that is worth mentioning is",
    "start": "1521200",
    "end": "1528720"
  },
  {
    "start": "1525000",
    "end": "1562000"
  },
  {
    "text": "that jaeger project by itself does not provide instrumentation right so if you have no instrumentation in application",
    "start": "1528720",
    "end": "1534159"
  },
  {
    "text": "you're not going to get traces and we don't have auto instrumentation agents either uh and this was a country's decision uh",
    "start": "1534159",
    "end": "1542000"
  },
  {
    "text": "because those aspects of of distributed tracing are taken care of by projects like open",
    "start": "1542000",
    "end": "1548640"
  },
  {
    "text": "tracing and open telemetry and i'll later speak about what that means uh and so you need to get instrumentation",
    "start": "1548640",
    "end": "1554799"
  },
  {
    "text": "somehow so that you can start exporting data and yeah deals with collecting that data and presenting and",
    "start": "1554799",
    "end": "1560799"
  },
  {
    "text": "analyzing it so as far as history so by the way jager",
    "start": "1560799",
    "end": "1565840"
  },
  {
    "start": "1562000",
    "end": "1585000"
  },
  {
    "text": "means hunter and don't spell it please with jagger that's not the official name",
    "start": "1565840",
    "end": "1571679"
  },
  {
    "text": "it was inspired by dapper from google and and open zipkin as i mentioned we created the tuber and",
    "start": "1571679",
    "end": "1577679"
  },
  {
    "text": "then uh donated to cloud native foundation and now it's a top-level uh graduated project at cloud native",
    "start": "1577679",
    "end": "1583840"
  },
  {
    "text": "foundation um so how jaeger fits in",
    "start": "1583840",
    "end": "1588880"
  },
  {
    "start": "1585000",
    "end": "1921000"
  },
  {
    "text": "in your architecture is this is the slide tries to explain that so let's say you have two services a and b",
    "start": "1588880",
    "end": "1594799"
  },
  {
    "text": "right as i mentioned uh you need to have some form of instrumentation in those services and there are various",
    "start": "1594799",
    "end": "1601360"
  },
  {
    "text": "options you have you you can have open tracing instrumentation with lots of libraries are supported by open",
    "start": "1601360",
    "end": "1606640"
  },
  {
    "text": "tracing that you can just plug in and you don't have to do much in your code really just initialize some things and uh",
    "start": "1606640",
    "end": "1614880"
  },
  {
    "text": "and then we also include a jaeger sdk which simply implements that open",
    "start": "1614880",
    "end": "1619919"
  },
  {
    "text": "tracing binding so that when instrumentation captures the data it just gives it into the jager tracer and then tracer is",
    "start": "1619919",
    "end": "1626720"
  },
  {
    "text": "possible to send you into jaeger back end right however there are two data paths that you can see here on the screen",
    "start": "1626720",
    "end": "1632799"
  },
  {
    "text": "the the the top one in in a solid line is the so-called in-band",
    "start": "1632799",
    "end": "1637919"
  },
  {
    "text": "data which is when service a makes a request to service b it includes a certain metadata about the",
    "start": "1637919",
    "end": "1643919"
  },
  {
    "text": "trace in that request that's a very small piece of data like usually trace id span id and sampling flag",
    "start": "1643919",
    "end": "1650000"
  },
  {
    "text": "and there are different formats that are supported so jaeger has its own native format that was originally developed a tuber",
    "start": "1650000",
    "end": "1655840"
  },
  {
    "text": "but there is also now a w3c standard format called trace context that you can also configure",
    "start": "1655840",
    "end": "1661360"
  },
  {
    "text": "jager sdks to use to communicate between services and we also support zip code b3 format which",
    "start": "1661360",
    "end": "1666559"
  },
  {
    "text": "is another alternative of that and so that's how the trace information",
    "start": "1666559",
    "end": "1671840"
  },
  {
    "text": "gets into the service b which it reads that metadata and then creates uh again tracing data to send it out of band and so the trace",
    "start": "1671840",
    "end": "1678880"
  },
  {
    "text": "data that goes to jager back end is really is sent in the background uh by",
    "start": "1678880",
    "end": "1684240"
  },
  {
    "text": "background threads um and it does not like happen on the critical path of the application where",
    "start": "1684240",
    "end": "1689760"
  },
  {
    "text": "this part happens the top part on the critical path right it's part of your request execution flow",
    "start": "1689760",
    "end": "1695279"
  },
  {
    "text": "and as i mentioned you don't actually have to have necessarily jaeger tracers in your service because",
    "start": "1695279",
    "end": "1701039"
  },
  {
    "text": "there is other ways you can instrument you can instrument it with zipkin like a brave sur library or you can instrument with",
    "start": "1701039",
    "end": "1707679"
  },
  {
    "text": "various open telemetry sdks uh they all kind of support jaeger as as a data format except that if you zip",
    "start": "1707679",
    "end": "1715120"
  },
  {
    "text": "can down jager itself supports zip code format but jager backhand can combine all the data and present you",
    "start": "1715120",
    "end": "1720640"
  },
  {
    "text": "in for a form of traces so this is the architecture so um of jager itself right so on the left",
    "start": "1720640",
    "end": "1727840"
  },
  {
    "text": "again imagine that you have your application and you have jager client or jager sdk iranian inside the application and the",
    "start": "1727840",
    "end": "1734240"
  },
  {
    "text": "typical deployment that we recommend is that iran jaeger agent which is a small process",
    "start": "1734240",
    "end": "1739360"
  },
  {
    "text": "uh as a host agent so that you don't have to like run many of them on one host although if you",
    "start": "1739360",
    "end": "1745039"
  },
  {
    "text": "do want you can run it as a sidecar in the classic like pod uh kubernetes pod so that",
    "start": "1745039",
    "end": "1750640"
  },
  {
    "text": "every application will have its own eager agent is really it just is a proxy it knows how to find jaeger",
    "start": "1750640",
    "end": "1756320"
  },
  {
    "text": "back end and and send the data there um so you don't actually have to use it you can configure jager clients to go directly",
    "start": "1756320",
    "end": "1762880"
  },
  {
    "text": "to collector but then you have to deal with some discovery maybe like uns uh sir dns uh name uh so that uh like",
    "start": "1762880",
    "end": "1770640"
  },
  {
    "text": "collectors can be located whereas when the agent is local to the host you just send it to a local port and also uh with the agent you can use",
    "start": "1770640",
    "end": "1777919"
  },
  {
    "text": "udp so that it's sort of like it's a telemetry data it's not a big deal if you lose it",
    "start": "1777919",
    "end": "1783679"
  },
  {
    "text": "whereas when you send to jager collector you can't really use udp so you have to use uh some http uh protocol to send the",
    "start": "1783679",
    "end": "1790480"
  },
  {
    "text": "data and then jager collector receives all these traces from multiple applications",
    "start": "1790480",
    "end": "1795520"
  },
  {
    "text": "and saves them to the database you can also have spark of link jobs running off of that database uh and then the jager query visualizes",
    "start": "1795520",
    "end": "1802799"
  },
  {
    "text": "that thing and the last piece which is shown in the rats here is is a control flow this is",
    "start": "1802799",
    "end": "1808159"
  },
  {
    "text": "um something that we've built from the beginning into jager architecture uh which i'll speak to",
    "start": "1808159",
    "end": "1814000"
  },
  {
    "text": "uh when we talk about sampling it allows you to push configuration back into the jager sdks to affect how the sampling is",
    "start": "1814000",
    "end": "1820640"
  },
  {
    "text": "done in the application however this was the architecture that we initially uh run a tour and later on we switched to",
    "start": "1820640",
    "end": "1828720"
  },
  {
    "text": "to to slightly different architecture where after jager collector we introduced kafka",
    "start": "1828720",
    "end": "1834159"
  },
  {
    "text": "before a component which writes spends in into storage right so the jager collector got split",
    "start": "1834159",
    "end": "1840399"
  },
  {
    "text": "into collector and in in gesture and indexer and the reason we did that is because um when you sometimes have a traffic",
    "start": "1840399",
    "end": "1847120"
  },
  {
    "text": "spikes uh or some application uh is deployed with like a sampling of hundred percent",
    "start": "1847120",
    "end": "1852799"
  },
  {
    "text": "it's very easy to send too much data that jager collector is simply not able to say fast enough into this database",
    "start": "1852799",
    "end": "1858559"
  },
  {
    "text": "uh because database have like a throughput limit um and whereas kafka is usually a more",
    "start": "1858559",
    "end": "1864480"
  },
  {
    "text": "elastic uh storage you can think of it uh that that can accommodate uh huge",
    "start": "1864480",
    "end": "1871279"
  },
  {
    "text": "traffic spikes and so this is one reason we introduced it so like we don't lose data when there is a",
    "start": "1871279",
    "end": "1876960"
  },
  {
    "text": "traffic spike we just write more to kafka and then we experience a certain ingestion delay or lag as a result",
    "start": "1876960",
    "end": "1883519"
  },
  {
    "text": "because it takes a bit more time to save it to the database and so the traces are not immediately available in to the query",
    "start": "1883519",
    "end": "1889679"
  },
  {
    "text": "but another serious reason why we introduced kafka is because it allows us to to start building flink jobs",
    "start": "1889679",
    "end": "1895440"
  },
  {
    "text": "uh to do aggregations like the dependency graphs um in real time rather than iranian spark",
    "start": "1895440",
    "end": "1901200"
  },
  {
    "text": "job which has to read the whole database and and like this is uh doing it in real time is much more uh",
    "start": "1901200",
    "end": "1907120"
  },
  {
    "text": "interactive when you get uh data faster into into a system and it reacts faster so this is what we're currently running",
    "start": "1907120",
    "end": "1913279"
  },
  {
    "text": "at uber and uh again you don't have to use kafka you can go directly to the database it's really it depends on what",
    "start": "1913279",
    "end": "1918559"
  },
  {
    "text": "you want to get from this and the technology stack uh to mention for jaeger is it's uh",
    "start": "1918559",
    "end": "1926000"
  },
  {
    "start": "1921000",
    "end": "1989000"
  },
  {
    "text": "backhand is all written in go uh we support pluggable storage there are two ways there's a",
    "start": "1926000",
    "end": "1932080"
  },
  {
    "text": "several back-ends which are natively supported directly by the binaries that we uh distribute",
    "start": "1932080",
    "end": "1937600"
  },
  {
    "text": "specifically cassandra elasticsearch badger which is a sort of single node storage on disk and",
    "start": "1937600",
    "end": "1943679"
  },
  {
    "text": "also users like a toy in memory implementation that is used by all-in-one uh binary",
    "start": "1943679",
    "end": "1950000"
  },
  {
    "text": "uh however there is also another uh plugable solution called jrpc plugins where you can implement any kind of",
    "start": "1950000",
    "end": "1956559"
  },
  {
    "text": "storage backend uh communicating over jpc with the jager end with the jager collector and that",
    "start": "1956559",
    "end": "1963360"
  },
  {
    "text": "allows uh sort of us to to extend the capabilities to other storage engines",
    "start": "1963360",
    "end": "1969200"
  },
  {
    "text": "uh without kind of bringing all of that maintenance overhead into jager main jaeger repository",
    "start": "1969200",
    "end": "1974799"
  },
  {
    "text": "uh the frontend is built in javascript and react is pretty standard uh instrumentation libraries or like",
    "start": "1974799",
    "end": "1981919"
  },
  {
    "text": "sdks are all implemented in open tracing and we integrated with various like kafka and apache flink",
    "start": "1981919",
    "end": "1988840"
  },
  {
    "text": "frameworks and as i mentioned zip code compatibility involves two things we can uh jager clients",
    "start": "1988840",
    "end": "1996559"
  },
  {
    "start": "1989000",
    "end": "2012000"
  },
  {
    "text": "understand zipkin headers format on the wire and it also zip can collect sorry jager",
    "start": "1996559",
    "end": "2003200"
  },
  {
    "text": "collector can also receive data from zipkin in various formats that you can support um it can even read from kafka like in",
    "start": "2003200",
    "end": "2010640"
  },
  {
    "text": "in the zip code street format for example um now as i promised let's talk about",
    "start": "2010640",
    "end": "2015760"
  },
  {
    "start": "2012000",
    "end": "2084000"
  },
  {
    "text": "quickly about sampling so first of all why do we sample right why why it's even a topic",
    "start": "2015760",
    "end": "2020960"
  },
  {
    "text": "and the problem is that trace tracing information is very very rich uh you imagine like as i explained in",
    "start": "2020960",
    "end": "2028399"
  },
  {
    "text": "the demo for every rpc call you have two spans on the client and on the server so each each span can have all kinds of tags and",
    "start": "2028399",
    "end": "2035519"
  },
  {
    "text": "like attributes like with urls it can have logs so this is pretty bulky objects that we have to",
    "start": "2035519",
    "end": "2040960"
  },
  {
    "text": "ship and that happens for every single rpc request or actually hundreds of the rpc requests right so",
    "start": "2040960",
    "end": "2046480"
  },
  {
    "text": "the the volume of data accumulates pretty fast um and uh so if your service is doing like",
    "start": "2046480",
    "end": "2053200"
  },
  {
    "text": "i don't know ten ten thousand rpcs uh imagine how much data you're gonna accumulate per",
    "start": "2053200",
    "end": "2058480"
  },
  {
    "text": "second so storing all of that can incur pretty large storage costs that's one reason for sampling but",
    "start": "2058480",
    "end": "2065280"
  },
  {
    "text": "another reason is that uh just collecting all this data from the application also has an impact on the performance of your application so",
    "start": "2065280",
    "end": "2071760"
  },
  {
    "text": "you may introduce latency because you waste in cpu cycles on processing all this data and so",
    "start": "2071760",
    "end": "2077440"
  },
  {
    "text": "sampling is usually the technique to deal with that overhead and with the with a large storage cost to avoid them",
    "start": "2077440",
    "end": "2084560"
  },
  {
    "start": "2084000",
    "end": "2177000"
  },
  {
    "text": "so there are two types of sampling that typically used in the tracing system one",
    "start": "2084560",
    "end": "2090000"
  },
  {
    "text": "is head by sampling where the sampling decision is made at the very beginning when the trace is just starting so when you create a new random",
    "start": "2090000",
    "end": "2096720"
  },
  {
    "text": "trace id we flip a coin and say okay we're gonna sample it or not and once we make the decision that decision is fixed",
    "start": "2096720",
    "end": "2103040"
  },
  {
    "text": "for the life of the trace and it's propagated as part of the trace context so that every other service which",
    "start": "2103040",
    "end": "2108320"
  },
  {
    "text": "participates in the trace it will use the same decision so that you don't get like uh partial traces somewhere",
    "start": "2108320",
    "end": "2114320"
  },
  {
    "text": "here uh and uh because uh that is pretty cheap way of doing the",
    "start": "2114320",
    "end": "2119839"
  },
  {
    "text": "sampling it has very minimal performance overhead especially when the trace is not sampled all your uh instrumentation is really",
    "start": "2119839",
    "end": "2126640"
  },
  {
    "text": "effectively a no-op um you you get very little overhead um and this is the default mode that's",
    "start": "2126640",
    "end": "2133119"
  },
  {
    "text": "supported by jager sdk the downside of upfront sampling is that uh",
    "start": "2133119",
    "end": "2138160"
  },
  {
    "text": "your 99 of your requests in the system are gonna be normal and not particularly interesting",
    "start": "2138160",
    "end": "2143359"
  },
  {
    "text": "right you really want to look at outliers in terms of latency maybe errors uh",
    "start": "2143359",
    "end": "2148480"
  },
  {
    "text": "and those happen much more rarely and as a result if you also in like let's say they",
    "start": "2148480",
    "end": "2154160"
  },
  {
    "text": "happened 100 000 times and plus you also have a sampling rate and one thousand then really your chance to get an outlier or",
    "start": "2154160",
    "end": "2160960"
  },
  {
    "text": "anomaly is one in a million uh so that's kind of a bad thing about head based sampling and",
    "start": "2160960",
    "end": "2166480"
  },
  {
    "text": "unfortunately there's not much that can be improved about it because uh it simply doesn't know anything about",
    "start": "2166480",
    "end": "2172560"
  },
  {
    "text": "what will happen to the trace when it makes a sampling decision it's like done at the beginning and so um the way the",
    "start": "2172560",
    "end": "2180240"
  },
  {
    "start": "2177000",
    "end": "2279000"
  },
  {
    "text": "head-based sampling is done in jaeger is that each sdk can be configured with different samplers you can say use probabilistic",
    "start": "2180240",
    "end": "2186640"
  },
  {
    "text": "sample like a coin flip with a certain rates or you can use rate limit and say in like this many per second uh but uh the interesting part is that",
    "start": "2186640",
    "end": "2194079"
  },
  {
    "text": "is that all sdk supports so-called remote sampling where as i mentioned in the architecture",
    "start": "2194079",
    "end": "2199280"
  },
  {
    "text": "diagram the configuration actually comes from the back end and that's very powerful because when",
    "start": "2199280",
    "end": "2205200"
  },
  {
    "text": "you have very many services in your architecture and many different teams running those services those teams don't necessarily know what",
    "start": "2205200",
    "end": "2211040"
  },
  {
    "text": "kind of sampling is good for for that system uh they also don't know when the traffic patterns changes and",
    "start": "2211040",
    "end": "2217440"
  },
  {
    "text": "how do you need to reconfigure the sample or redeployed application uh whereas when the configuration comes from the",
    "start": "2217440",
    "end": "2223200"
  },
  {
    "text": "from the center location you could do all of that in a much more intelligent way at minimum you you give control to the",
    "start": "2223200",
    "end": "2229520"
  },
  {
    "text": "sampling to the team that runs the tracing infrastructure so that they have sort of like levers in terms of how much traffic they",
    "start": "2229520",
    "end": "2235599"
  },
  {
    "text": "want to ingest um and uh but you can also make something more intelligent like adaptive sampling",
    "start": "2235599",
    "end": "2241680"
  },
  {
    "text": "which calculates things on a sort of a control loop and reacts to traffic spikes this is",
    "start": "2241680",
    "end": "2247359"
  },
  {
    "text": "what we use at uber um and the one thing is is also interesting is the configuration can be done",
    "start": "2247359",
    "end": "2252880"
  },
  {
    "text": "per service and tournament points so it's very often the case that a given service may have",
    "start": "2252880",
    "end": "2257920"
  },
  {
    "text": "multiple endpoints with very different uh rates of of queries to them or requests",
    "start": "2257920",
    "end": "2263359"
  },
  {
    "text": "and so you don't want to sample everything at let's say one percent if the difference if you have multiple",
    "start": "2263359",
    "end": "2269040"
  },
  {
    "text": "like orders of magnitude in the qps of the end points so this configuration allows you to do at the",
    "start": "2269040",
    "end": "2274079"
  },
  {
    "text": "individual level and so you can read the documentation of how to configure it",
    "start": "2274079",
    "end": "2279200"
  },
  {
    "start": "2279000",
    "end": "2381000"
  },
  {
    "text": "now let's talk about tail based sounding so tail by sampling is is different uh completely different mode where the sampling",
    "start": "2279200",
    "end": "2285599"
  },
  {
    "text": "decision is made at the end of the trace and because of that it can be much more intelligent we can look at the latencies",
    "start": "2285599",
    "end": "2291040"
  },
  {
    "text": "we can look at the errors or some logs whatever anything that looks interesting in the trace we can we can",
    "start": "2291040",
    "end": "2296800"
  },
  {
    "text": "affect how we sample those traces uh um in in an interesting ways right however",
    "start": "2296800",
    "end": "2303040"
  },
  {
    "text": "that uh requires that all these traces still need to be stored somewhere because",
    "start": "2303040",
    "end": "2308320"
  },
  {
    "text": "um like traces are distributed you have all these spans cramming from all these different applications you kind of need",
    "start": "2308320",
    "end": "2314320"
  },
  {
    "text": "to assemble them all in one place first and you don't want to store them on disk during that assembly time because",
    "start": "2314320",
    "end": "2320240"
  },
  {
    "text": "uh then we defeat the purpose of sampling we we want not to hit the disk because it's",
    "start": "2320240",
    "end": "2325359"
  },
  {
    "text": "very expensive so it really means you have to allocate a lot of memory to store all these traces until they're done and you can make a",
    "start": "2325359",
    "end": "2331680"
  },
  {
    "text": "sampling decision fortunately they're all short usually traces like last no more than a second so most of them can be expired from memory",
    "start": "2331680",
    "end": "2337760"
  },
  {
    "text": "very quickly so it doesn't necessarily introduce a lot of memory overhead um uh",
    "start": "2337760",
    "end": "2343200"
  },
  {
    "text": "but there are some like architectural things you need to do to support that and another",
    "start": "2343200",
    "end": "2348480"
  },
  {
    "text": "another kind of downside of tail-based sampling is that because we need to collect all the data from from all this",
    "start": "2348480",
    "end": "2354320"
  },
  {
    "text": "every single request that means that it has the maximum performance overhead on your application",
    "start": "2354320",
    "end": "2359599"
  },
  {
    "text": "right and so it's a trade-off whether you want to afford that and maybe in increase in latency you can sometimes",
    "start": "2359599",
    "end": "2365920"
  },
  {
    "text": "combine the tail-based and head-based sampling so let's say instead of sampling one in a thousand you say well let's sample one and ten",
    "start": "2365920",
    "end": "2372560"
  },
  {
    "text": "but then do like for every tenth we kind of do the tail-based sampling so that that allows you to control the",
    "start": "2372560",
    "end": "2378560"
  },
  {
    "text": "costs and performance uh so how sampling tail based sampling",
    "start": "2378560",
    "end": "2384160"
  },
  {
    "start": "2381000",
    "end": "2444000"
  },
  {
    "text": "works in the aeger so there's nothing that needs to be done on the jaeger sdks because you simply configure them with",
    "start": "2384160",
    "end": "2389359"
  },
  {
    "text": "either 100 or like a fixed percentage uh where the the what the magic happens is",
    "start": "2389359",
    "end": "2396000"
  },
  {
    "text": "really in on the back end but jager components themselves don't support tail by sampling but we now release uh new components called",
    "start": "2396000",
    "end": "2403839"
  },
  {
    "text": "open telemetry collectors uh those are jaeger binaries specifically",
    "start": "2403839",
    "end": "2409040"
  },
  {
    "text": "built with from the open telemetry collector we just support tail by sampling and you can configure those collectors with",
    "start": "2409040",
    "end": "2415280"
  },
  {
    "text": "various sampling rules by like latency or certain tags like error tags um unfortunately at this point uh open",
    "start": "2415280",
    "end": "2421920"
  },
  {
    "text": "telemeter collector only supports a single node mode which means if you can fit all your traces uh in one",
    "start": "2421920",
    "end": "2428160"
  },
  {
    "text": "node memory then you're okay but if you need a kind of a scaled out solution uh then that's not currently available",
    "start": "2428160",
    "end": "2434960"
  },
  {
    "text": "but there is work already happening and there's a blog post by grafana how they did it so",
    "start": "2434960",
    "end": "2440480"
  },
  {
    "text": "it will it will be available in the near future uh and finally uh to close this i",
    "start": "2440480",
    "end": "2446800"
  },
  {
    "start": "2444000",
    "end": "2474000"
  },
  {
    "text": "mentioned that i want to talk about uh open telemetry so open telemetry is a new project in cncf which is a it",
    "start": "2446800",
    "end": "2454960"
  },
  {
    "text": "it's a descendant of open uh tracing and open sensors these two projects merge",
    "start": "2454960",
    "end": "2460160"
  },
  {
    "text": "and it deals with again establishing a unified instrumentation framework so that you can reuse the instrumentation",
    "start": "2460160",
    "end": "2465920"
  },
  {
    "text": "in multiple applications right it does not deal with the back end collection of traces except for the",
    "start": "2465920",
    "end": "2470960"
  },
  {
    "text": "collector which is kind of an intermediate piece so to to illustrate that let's say uh",
    "start": "2470960",
    "end": "2477200"
  },
  {
    "text": "we're we're dealing normally with jaeger and open tracing this is how jaeger historically evolved and so you have application your",
    "start": "2477200",
    "end": "2483920"
  },
  {
    "text": "application at the top there's like three types of applications that typically can be instrumented for tracing some of them are explicitly instrumented",
    "start": "2483920",
    "end": "2490880"
  },
  {
    "text": "directly in your code you can start spans and write where is metadata into it or more often",
    "start": "2490880",
    "end": "2496720"
  },
  {
    "text": "you're in the middle uh box here where you use some rpc framework which comes with the middleware for tracing",
    "start": "2496720",
    "end": "2502400"
  },
  {
    "text": "um or there's another option where you can sometimes there are in certain languages",
    "start": "2502400",
    "end": "2507680"
  },
  {
    "text": "there are auto instrumentation facilities where you can just attach a library to your binary and then you magically get traces like in open",
    "start": "2507680",
    "end": "2514400"
  },
  {
    "text": "tracing that's available for example in python and in java and then all these instrumentations they talk through open",
    "start": "2514400",
    "end": "2520560"
  },
  {
    "text": "tracing api which as i mentioned calls back into the jager sdk and then jaeger sdk sends the data",
    "start": "2520560",
    "end": "2525920"
  },
  {
    "text": "back to the jager back end right so it's very kind of all clear here so now what happens with open telemetry",
    "start": "2525920",
    "end": "2531920"
  },
  {
    "start": "2531000",
    "end": "2587000"
  },
  {
    "text": "uh so open telemetry presents a different slightly different api than open tracing it's conceptually still",
    "start": "2531920",
    "end": "2536960"
  },
  {
    "text": "very similar traces and spans and everything uh but the method names are slightly different so",
    "start": "2536960",
    "end": "2542480"
  },
  {
    "text": "but you can just use the different types of instrumentations for open telemetry and then you don't have to have uh or",
    "start": "2542480",
    "end": "2549200"
  },
  {
    "text": "run jaeger sdk you can just run standard open telemetry sdk which is included in the project in all languages",
    "start": "2549200",
    "end": "2555040"
  },
  {
    "text": "right and then that sdk has the ability to export data directly in the jager",
    "start": "2555040",
    "end": "2560800"
  },
  {
    "text": "format so you can still have jager agent or jaeger collector except in jaeger data spans uh but you can also",
    "start": "2560800",
    "end": "2567520"
  },
  {
    "text": "alternatively run open telemetry collector directly which and then export data in the open",
    "start": "2567520",
    "end": "2573119"
  },
  {
    "text": "telemetry format which is kind of a standardized way now to represent traces and jager is gradually",
    "start": "2573119",
    "end": "2579359"
  },
  {
    "text": "migrating to that uh and then open telemetry collector will still be able to forward data to",
    "start": "2579359",
    "end": "2585119"
  },
  {
    "text": "jager back and in the format and uh so as i mentioned jaeger uh components now exist that",
    "start": "2585119",
    "end": "2593359"
  },
  {
    "start": "2587000",
    "end": "2647000"
  },
  {
    "text": "extend open telemetry because collector in open telemetry is written on go we can just use it as a library",
    "start": "2593359",
    "end": "2598400"
  },
  {
    "text": "so we've built our own versions of those binaries which have the same capabilities as a",
    "start": "2598400",
    "end": "2604160"
  },
  {
    "text": "open telemetry drop stream collectors but with additional jaeger extensions which are kind of uh specific to jaeger for",
    "start": "2604160",
    "end": "2610319"
  },
  {
    "text": "example we can plug in directly our storage implementations into a collector so that you don't have to run",
    "start": "2610319",
    "end": "2615839"
  },
  {
    "text": "like multiple services to uh to push the data through um and we're also converting uh jaeger",
    "start": "2615839",
    "end": "2623040"
  },
  {
    "text": "uh implementations for storage now to work directly with the open telemeter data model",
    "start": "2623040",
    "end": "2628160"
  },
  {
    "text": "uh which is slightly richer than open tracing because it will kind of provide us better compatibility",
    "start": "2628160",
    "end": "2633440"
  },
  {
    "text": "and uh path forward uh and so we're trying to uh kind of reuse all the good thing that open",
    "start": "2633440",
    "end": "2638800"
  },
  {
    "text": "telemetry is building so that we can reduce the efforts we need to maintain for example all the jager sdks which was",
    "start": "2638800",
    "end": "2644560"
  },
  {
    "text": "pretty expensive um work in the past um so if you want to learn more about uh",
    "start": "2644560",
    "end": "2651839"
  },
  {
    "start": "2647000",
    "end": "2680000"
  },
  {
    "text": "uh jager uh you can you can attend a deep dive which will happen uh on the next day uh and so pavel will",
    "start": "2651839",
    "end": "2658960"
  },
  {
    "text": "be talking about more about jaeger architecture and other things and finally these are uh the ways that you",
    "start": "2658960",
    "end": "2664560"
  },
  {
    "text": "can get in touch with uh with the community of jaeger project there is a blog post there's a twitter",
    "start": "2664560",
    "end": "2670000"
  },
  {
    "text": "account that you can follow and there's online chat where you can go and ask questions things like that so that's the end of my",
    "start": "2670000",
    "end": "2677839"
  },
  {
    "text": "talk thank you very much",
    "start": "2677839",
    "end": "2682000"
  }
]
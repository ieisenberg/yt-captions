[
  {
    "text": "all right um thanks everyone for coming",
    "start": "80",
    "end": "2480"
  },
  {
    "text": "um today the so the title of this talk",
    "start": "2480",
    "end": "5120"
  },
  {
    "text": "is distribute impromptual expressions um",
    "start": "5120",
    "end": "7919"
  },
  {
    "text": "we'll focus in this session on some of",
    "start": "7919",
    "end": "10000"
  },
  {
    "text": "the work that we've done",
    "start": "10000",
    "end": "11679"
  },
  {
    "text": "uh with mod and with the thomas",
    "start": "11679",
    "end": "13120"
  },
  {
    "text": "community on",
    "start": "13120",
    "end": "14559"
  },
  {
    "text": "um implementing distributed query",
    "start": "14559",
    "end": "16640"
  },
  {
    "text": "execution in the thanos project",
    "start": "16640",
    "end": "19520"
  },
  {
    "text": "my name is philip i am a production",
    "start": "19520",
    "end": "21199"
  },
  {
    "text": "engineer at shopify",
    "start": "21199",
    "end": "22960"
  },
  {
    "text": "and with me today is moat who is a",
    "start": "22960",
    "end": "24480"
  },
  {
    "text": "senior software engineer at red hat",
    "start": "24480",
    "end": "27519"
  },
  {
    "text": "the agenda that we have today is the",
    "start": "27519",
    "end": "29840"
  },
  {
    "text": "following one we'll briefly cover why",
    "start": "29840",
    "end": "32480"
  },
  {
    "text": "prom ql and the primcal engine is kind",
    "start": "32480",
    "end": "34640"
  },
  {
    "text": "of hard to scale at the moment",
    "start": "34640",
    "end": "36079"
  },
  {
    "text": "specifically in prometheus",
    "start": "36079",
    "end": "37920"
  },
  {
    "text": "and then we'll cover two different",
    "start": "37920",
    "end": "39520"
  },
  {
    "text": "approaches that we are working on",
    "start": "39520",
    "end": "41680"
  },
  {
    "text": "in thanos",
    "start": "41680",
    "end": "43040"
  },
  {
    "text": "namely query push down what we call",
    "start": "43040",
    "end": "44879"
  },
  {
    "text": "query push down and query sharding",
    "start": "44879",
    "end": "47200"
  },
  {
    "text": "to speed up query execution and then",
    "start": "47200",
    "end": "49600"
  },
  {
    "text": "we'll take a look at sharding in",
    "start": "49600",
    "end": "50879"
  },
  {
    "text": "practice and at the end we'll cover",
    "start": "50879",
    "end": "53840"
  },
  {
    "text": "kind of we'll give a brief outlook of",
    "start": "53840",
    "end": "55440"
  },
  {
    "text": "where we hope thanos is going to develop",
    "start": "55440",
    "end": "57680"
  },
  {
    "text": "in the future",
    "start": "57680",
    "end": "60160"
  },
  {
    "text": "so if we take a look at the current",
    "start": "60160",
    "end": "62320"
  },
  {
    "text": "state of prometheus i mean we've heard",
    "start": "62320",
    "end": "64239"
  },
  {
    "text": "so many times here at kubecon that it's",
    "start": "64239",
    "end": "66080"
  },
  {
    "text": "become",
    "start": "66080",
    "end": "67280"
  },
  {
    "text": "very well adopted in the cloud native",
    "start": "67280",
    "end": "69040"
  },
  {
    "text": "monitoring space",
    "start": "69040",
    "end": "71200"
  },
  {
    "text": "basically anyone that's maybe used the",
    "start": "71200",
    "end": "73040"
  },
  {
    "text": "kubernetes cluster has seen a primitive",
    "start": "73040",
    "end": "74720"
  },
  {
    "text": "system lying around somewhere it's very",
    "start": "74720",
    "end": "76960"
  },
  {
    "text": "effective for real-time monitoring and",
    "start": "76960",
    "end": "78720"
  },
  {
    "text": "what's very good about prometheus is",
    "start": "78720",
    "end": "80640"
  },
  {
    "text": "this promptql query",
    "start": "80640",
    "end": "82720"
  },
  {
    "text": "query language that allows us to write",
    "start": "82720",
    "end": "84799"
  },
  {
    "text": "all kinds of expressive queries against",
    "start": "84799",
    "end": "87600"
  },
  {
    "text": "what we call time series data",
    "start": "87600",
    "end": "90640"
  },
  {
    "text": "and so the ideal use case for prometheus",
    "start": "90640",
    "end": "93600"
  },
  {
    "text": "is really the single cluster",
    "start": "93600",
    "end": "95920"
  },
  {
    "text": "monitoring whenever we want to go beyond",
    "start": "95920",
    "end": "98640"
  },
  {
    "text": "a single cluster there are different",
    "start": "98640",
    "end": "101119"
  },
  {
    "text": "challenges that are non-trivial to",
    "start": "101119",
    "end": "102640"
  },
  {
    "text": "overcome some of them being just the",
    "start": "102640",
    "end": "104320"
  },
  {
    "text": "fact that scraping across",
    "start": "104320",
    "end": "107119"
  },
  {
    "text": "boundary network boundaries can be",
    "start": "107119",
    "end": "109680"
  },
  {
    "text": "it comes with its own",
    "start": "109680",
    "end": "111600"
  },
  {
    "text": "challenges we have to rely on disks for",
    "start": "111600",
    "end": "114079"
  },
  {
    "text": "retention this can be hard to move",
    "start": "114079",
    "end": "116000"
  },
  {
    "text": "between acs regions clusters and so on",
    "start": "116000",
    "end": "119280"
  },
  {
    "text": "and overall the story about how to scale",
    "start": "119280",
    "end": "121920"
  },
  {
    "text": "prometheus horizontally is not there yet",
    "start": "121920",
    "end": "124960"
  },
  {
    "text": "and that's a conscious design decision",
    "start": "124960",
    "end": "126719"
  },
  {
    "text": "so there's nothing wrong with that",
    "start": "126719",
    "end": "129200"
  },
  {
    "text": "um",
    "start": "129200",
    "end": "130000"
  },
  {
    "text": "and as a result there are all these",
    "start": "130000",
    "end": "132080"
  },
  {
    "text": "different projects like cortex thanos",
    "start": "132080",
    "end": "134239"
  },
  {
    "text": "recently mimir that come in and uh try",
    "start": "134239",
    "end": "137200"
  },
  {
    "text": "to solve some of the scalability issues",
    "start": "137200",
    "end": "139360"
  },
  {
    "text": "that prometheus has",
    "start": "139360",
    "end": "142000"
  },
  {
    "text": "and if we look at thanos we can",
    "start": "142000",
    "end": "144000"
  },
  {
    "text": "essentially store data for",
    "start": "144000",
    "end": "146160"
  },
  {
    "text": "as long as we want in s3 buckets",
    "start": "146160",
    "end": "150239"
  },
  {
    "text": "in addition to that we get things like",
    "start": "150239",
    "end": "152640"
  },
  {
    "text": "write replication multi-tenancy all of",
    "start": "152640",
    "end": "154560"
  },
  {
    "text": "this kind of cloud native features",
    "start": "154560",
    "end": "156720"
  },
  {
    "text": "that we take for granted today",
    "start": "156720",
    "end": "159120"
  },
  {
    "text": "and",
    "start": "159120",
    "end": "160000"
  },
  {
    "text": "now that we have all of the data all of",
    "start": "160000",
    "end": "162400"
  },
  {
    "text": "this kind of long retention of data",
    "start": "162400",
    "end": "164480"
  },
  {
    "text": "massive data we can also execute prom ql",
    "start": "164480",
    "end": "167280"
  },
  {
    "text": "against that that data set",
    "start": "167280",
    "end": "170640"
  },
  {
    "text": "however",
    "start": "170640",
    "end": "171920"
  },
  {
    "text": "the prom ql engine that is in",
    "start": "171920",
    "end": "175120"
  },
  {
    "text": "um primitives thanos in all of these",
    "start": "175120",
    "end": "177360"
  },
  {
    "text": "projects is still kind of the same",
    "start": "177360",
    "end": "179599"
  },
  {
    "text": "engine that's used inside prometheus and",
    "start": "179599",
    "end": "181680"
  },
  {
    "text": "that engine is",
    "start": "181680",
    "end": "183120"
  },
  {
    "text": "single threaded single process and as a",
    "start": "183120",
    "end": "185920"
  },
  {
    "text": "result has to kind of fit all of the",
    "start": "185920",
    "end": "188640"
  },
  {
    "text": "time series for a query in memory has to",
    "start": "188640",
    "end": "191280"
  },
  {
    "text": "execute the memory uh the query in a",
    "start": "191280",
    "end": "193680"
  },
  {
    "text": "single thread",
    "start": "193680",
    "end": "195040"
  },
  {
    "text": "and the longer the query range and the",
    "start": "195040",
    "end": "197599"
  },
  {
    "text": "higher the cardinality the harder this",
    "start": "197599",
    "end": "200080"
  },
  {
    "text": "problem of executing the query becomes",
    "start": "200080",
    "end": "203440"
  },
  {
    "text": "and so we can visualize where this",
    "start": "203440",
    "end": "205680"
  },
  {
    "text": "bottleneck happens before we actually",
    "start": "205680",
    "end": "208080"
  },
  {
    "text": "try to solve the problem we can",
    "start": "208080",
    "end": "209680"
  },
  {
    "text": "visualize where the problem happens on a",
    "start": "209680",
    "end": "212000"
  },
  {
    "text": "very simple model let's say we have a",
    "start": "212000",
    "end": "214159"
  },
  {
    "text": "kubernetes cluster that has a prometheus",
    "start": "214159",
    "end": "216239"
  },
  {
    "text": "instance inside",
    "start": "216239",
    "end": "217840"
  },
  {
    "text": "that scraping just a set of targets and",
    "start": "217840",
    "end": "220400"
  },
  {
    "text": "when we outgrow that instance we can",
    "start": "220400",
    "end": "222159"
  },
  {
    "text": "deploy another instance that scrapes a",
    "start": "222159",
    "end": "224319"
  },
  {
    "text": "different set of targets and when we",
    "start": "224319",
    "end": "226560"
  },
  {
    "text": "want to get the global view of the",
    "start": "226560",
    "end": "228799"
  },
  {
    "text": "entire metric space we can deploy",
    "start": "228799",
    "end": "231440"
  },
  {
    "text": "something like a thanos querier that's",
    "start": "231440",
    "end": "233519"
  },
  {
    "text": "going to pull data from these prometheus",
    "start": "233519",
    "end": "235599"
  },
  {
    "text": "instances",
    "start": "235599",
    "end": "236959"
  },
  {
    "text": "and execute broadcasters",
    "start": "236959",
    "end": "239519"
  },
  {
    "text": "and if we kind of outgrow this cluster",
    "start": "239519",
    "end": "241920"
  },
  {
    "text": "we can deploy for example another",
    "start": "241920",
    "end": "243920"
  },
  {
    "text": "cluster let's say our production",
    "start": "243920",
    "end": "245360"
  },
  {
    "text": "environment is now bigger",
    "start": "245360",
    "end": "247280"
  },
  {
    "text": "and now when we want to get a global",
    "start": "247280",
    "end": "249519"
  },
  {
    "text": "view again of everything that's going on",
    "start": "249519",
    "end": "252480"
  },
  {
    "text": "we can layer a new thanos querier on top",
    "start": "252480",
    "end": "256320"
  },
  {
    "text": "now this tunnel square is going to kind",
    "start": "256320",
    "end": "258799"
  },
  {
    "text": "of communicate to the intermediary ones",
    "start": "258799",
    "end": "261040"
  },
  {
    "text": "and it can execute global queries across",
    "start": "261040",
    "end": "263440"
  },
  {
    "text": "the entire set of metrics",
    "start": "263440",
    "end": "266800"
  },
  {
    "text": "now the problem is whenever we want to",
    "start": "266800",
    "end": "269280"
  },
  {
    "text": "execute a global query",
    "start": "269280",
    "end": "271520"
  },
  {
    "text": "uh this specific tunnel square that's at",
    "start": "271520",
    "end": "274320"
  },
  {
    "text": "the root of the tree it has to reach out",
    "start": "274320",
    "end": "277199"
  },
  {
    "text": "to all of the underlying prometheus",
    "start": "277199",
    "end": "279440"
  },
  {
    "text": "instances",
    "start": "279440",
    "end": "280479"
  },
  {
    "text": "has to fetch time series data",
    "start": "280479",
    "end": "283040"
  },
  {
    "text": "um that's relevant for the query in",
    "start": "283040",
    "end": "285040"
  },
  {
    "text": "memory",
    "start": "285040",
    "end": "286080"
  },
  {
    "text": "in a single process and execute the",
    "start": "286080",
    "end": "288880"
  },
  {
    "text": "the query in that process",
    "start": "288880",
    "end": "290960"
  },
  {
    "text": "what's also interesting to note here is",
    "start": "290960",
    "end": "292639"
  },
  {
    "text": "that these intermediary queries in the",
    "start": "292639",
    "end": "294800"
  },
  {
    "text": "middle they're not actually doing any",
    "start": "294800",
    "end": "297520"
  },
  {
    "text": "they're not very active in the query",
    "start": "297520",
    "end": "298960"
  },
  {
    "text": "execution path so what they do is uh",
    "start": "298960",
    "end": "301680"
  },
  {
    "text": "mostly",
    "start": "301680",
    "end": "302800"
  },
  {
    "text": "they act they provide some basic service",
    "start": "302800",
    "end": "305039"
  },
  {
    "text": "discovery mechanisms so they allow the",
    "start": "305039",
    "end": "307440"
  },
  {
    "text": "root career to discover this instances",
    "start": "307440",
    "end": "310320"
  },
  {
    "text": "these leaves prometheus leaves at the",
    "start": "310320",
    "end": "312320"
  },
  {
    "text": "bottom",
    "start": "312320",
    "end": "313199"
  },
  {
    "text": "and they also kind of traffic data to",
    "start": "313199",
    "end": "315520"
  },
  {
    "text": "the top but other than that they're not",
    "start": "315520",
    "end": "318080"
  },
  {
    "text": "actually executing from ql even though",
    "start": "318080",
    "end": "320320"
  },
  {
    "text": "they have promptly engines inside them",
    "start": "320320",
    "end": "324000"
  },
  {
    "text": "and so",
    "start": "324000",
    "end": "325039"
  },
  {
    "text": "that's kind of the",
    "start": "325039",
    "end": "326639"
  },
  {
    "text": "um",
    "start": "326639",
    "end": "327600"
  },
  {
    "text": "the current state the the default mode",
    "start": "327600",
    "end": "330080"
  },
  {
    "text": "that we have in thanos",
    "start": "330080",
    "end": "331840"
  },
  {
    "text": "uh and this is why the the kind of the",
    "start": "331840",
    "end": "333759"
  },
  {
    "text": "queries query execution can get slow",
    "start": "333759",
    "end": "337199"
  },
  {
    "text": "with more data and now that we know this",
    "start": "337199",
    "end": "339600"
  },
  {
    "text": "we can look at",
    "start": "339600",
    "end": "340960"
  },
  {
    "text": "what we",
    "start": "340960",
    "end": "342080"
  },
  {
    "text": "we've been working on the kind of the",
    "start": "342080",
    "end": "344080"
  },
  {
    "text": "entire thousands community to",
    "start": "344080",
    "end": "345919"
  },
  {
    "text": "to alleviate some of the problems",
    "start": "345919",
    "end": "348639"
  },
  {
    "text": "and so the first thing that we will look",
    "start": "348639",
    "end": "350880"
  },
  {
    "text": "into is an approach",
    "start": "350880",
    "end": "352800"
  },
  {
    "text": "that is referred to as query push down",
    "start": "352800",
    "end": "355120"
  },
  {
    "text": "so with query push down",
    "start": "355120",
    "end": "357280"
  },
  {
    "text": "we can avo we can speed up queries by",
    "start": "357280",
    "end": "359360"
  },
  {
    "text": "simply avoiding streaming a large amount",
    "start": "359360",
    "end": "362639"
  },
  {
    "text": "of series in memory",
    "start": "362639",
    "end": "365199"
  },
  {
    "text": "if we look at if you want to look at how",
    "start": "365199",
    "end": "366560"
  },
  {
    "text": "that works",
    "start": "366560",
    "end": "367680"
  },
  {
    "text": "let's say we have again a simple model",
    "start": "367680",
    "end": "370240"
  },
  {
    "text": "a query with two instances",
    "start": "370240",
    "end": "373360"
  },
  {
    "text": "and let's say that we want to execute",
    "start": "373360",
    "end": "374800"
  },
  {
    "text": "the following query we want to calculate",
    "start": "374800",
    "end": "376880"
  },
  {
    "text": "the maximum or a particular metric um",
    "start": "376880",
    "end": "381520"
  },
  {
    "text": "yeah i'm the maximum or particular",
    "start": "381520",
    "end": "382960"
  },
  {
    "text": "metric",
    "start": "382960",
    "end": "383919"
  },
  {
    "text": "and so what we can do now is we can take",
    "start": "383919",
    "end": "386240"
  },
  {
    "text": "advantage of the computational",
    "start": "386240",
    "end": "388639"
  },
  {
    "text": "power the computational engine that's",
    "start": "388639",
    "end": "390639"
  },
  {
    "text": "built into these prometheus instances",
    "start": "390639",
    "end": "393039"
  },
  {
    "text": "we can um execute the query",
    "start": "393039",
    "end": "396160"
  },
  {
    "text": "locally first on the local data set",
    "start": "396160",
    "end": "399039"
  },
  {
    "text": "uh so these primiti are going to execute",
    "start": "399039",
    "end": "401440"
  },
  {
    "text": "this specific prim field query locally",
    "start": "401440",
    "end": "404160"
  },
  {
    "text": "and they're going to propagate just the",
    "start": "404160",
    "end": "406000"
  },
  {
    "text": "intermediary result upwards and then the",
    "start": "406000",
    "end": "409440"
  },
  {
    "text": "querier is going to recalculate the",
    "start": "409440",
    "end": "411280"
  },
  {
    "text": "query with this much smaller data set",
    "start": "411280",
    "end": "414560"
  },
  {
    "text": "and by that we kind of distribute the",
    "start": "414560",
    "end": "416319"
  },
  {
    "text": "query execution through the entire",
    "start": "416319",
    "end": "418639"
  },
  {
    "text": "system",
    "start": "418639",
    "end": "420639"
  },
  {
    "text": "so what you need to know kind of did was",
    "start": "420639",
    "end": "422639"
  },
  {
    "text": "the feel they are with queer push down",
    "start": "422639",
    "end": "424960"
  },
  {
    "text": "the important thing is that it's already",
    "start": "424960",
    "end": "426720"
  },
  {
    "text": "implemented in thanos and you can start",
    "start": "426720",
    "end": "428800"
  },
  {
    "text": "using it today",
    "start": "428800",
    "end": "430960"
  },
  {
    "text": "obviously the benefits are that it",
    "start": "430960",
    "end": "434160"
  },
  {
    "text": "speeds squares up it lowers from ql",
    "start": "434160",
    "end": "436639"
  },
  {
    "text": "execution latency by processing data at",
    "start": "436639",
    "end": "439440"
  },
  {
    "text": "rest so where it's at",
    "start": "439440",
    "end": "441280"
  },
  {
    "text": "uh and it doesn't ship",
    "start": "441280",
    "end": "443520"
  },
  {
    "text": "these megabytes or even gigabytes of",
    "start": "443520",
    "end": "445520"
  },
  {
    "text": "data over the network and if you want to",
    "start": "445520",
    "end": "447680"
  },
  {
    "text": "play with it you can enable it as a",
    "start": "447680",
    "end": "449280"
  },
  {
    "text": "feature flag",
    "start": "449280",
    "end": "450720"
  },
  {
    "text": "and start using it today",
    "start": "450720",
    "end": "453120"
  },
  {
    "text": "the current limitations that are there",
    "start": "453120",
    "end": "455840"
  },
  {
    "text": "which we hope",
    "start": "455840",
    "end": "457199"
  },
  {
    "text": "over time are going to get become less",
    "start": "457199",
    "end": "459199"
  },
  {
    "text": "and less is that",
    "start": "459199",
    "end": "460800"
  },
  {
    "text": "we can only apply it to a smaller set of",
    "start": "460800",
    "end": "463520"
  },
  {
    "text": "promptql functions so those are the mean",
    "start": "463520",
    "end": "465840"
  },
  {
    "text": "max top k bottom can group",
    "start": "465840",
    "end": "468479"
  },
  {
    "text": "they are kind of we can refer to them as",
    "start": "468479",
    "end": "470479"
  },
  {
    "text": "the item potent functions which we can",
    "start": "470479",
    "end": "472560"
  },
  {
    "text": "apply over and over again at various",
    "start": "472560",
    "end": "475039"
  },
  {
    "text": "levels in the query execution path",
    "start": "475039",
    "end": "477759"
  },
  {
    "text": "the flip side of that is that the more",
    "start": "477759",
    "end": "480160"
  },
  {
    "text": "common expressions such as sum rates uh",
    "start": "480160",
    "end": "482879"
  },
  {
    "text": "calculating uh quantiles for example",
    "start": "482879",
    "end": "486800"
  },
  {
    "text": "there's no good way to kind of defer",
    "start": "486800",
    "end": "489280"
  },
  {
    "text": "execution to the leaves yet",
    "start": "489280",
    "end": "491199"
  },
  {
    "text": "so we there's still more work to be done",
    "start": "491199",
    "end": "493599"
  },
  {
    "text": "there",
    "start": "493599",
    "end": "495759"
  },
  {
    "text": "then",
    "start": "495759",
    "end": "496879"
  },
  {
    "text": "there's there are kind of two other",
    "start": "496879",
    "end": "498879"
  },
  {
    "text": "things that we have to keep in mind if",
    "start": "498879",
    "end": "500639"
  },
  {
    "text": "we're going to execute queries then",
    "start": "500639",
    "end": "503360"
  },
  {
    "text": "we need components to have a query",
    "start": "503360",
    "end": "505039"
  },
  {
    "text": "execution engine and currently in thanos",
    "start": "505039",
    "end": "507759"
  },
  {
    "text": "it's only the tunnel sidecar that can",
    "start": "507759",
    "end": "509599"
  },
  {
    "text": "execute queries",
    "start": "509599",
    "end": "510879"
  },
  {
    "text": "um so",
    "start": "510879",
    "end": "512560"
  },
  {
    "text": "the other store components are simply",
    "start": "512560",
    "end": "514320"
  },
  {
    "text": "going",
    "start": "514320",
    "end": "515279"
  },
  {
    "text": "to ignore this instruction so you can",
    "start": "515279",
    "end": "517518"
  },
  {
    "text": "still enable push down",
    "start": "517519",
    "end": "520000"
  },
  {
    "text": "even if you have a mixed fleet of let's",
    "start": "520000",
    "end": "522159"
  },
  {
    "text": "say start side cars receivers store",
    "start": "522159",
    "end": "524399"
  },
  {
    "text": "gateways",
    "start": "524399",
    "end": "525760"
  },
  {
    "text": "it's just that it's",
    "start": "525760",
    "end": "527839"
  },
  {
    "text": "you can do that in a safe manner so to",
    "start": "527839",
    "end": "529680"
  },
  {
    "text": "say it's just that it's only the",
    "start": "529680",
    "end": "532800"
  },
  {
    "text": "prometheus instances can take advantage",
    "start": "532800",
    "end": "534959"
  },
  {
    "text": "of this",
    "start": "534959",
    "end": "535920"
  },
  {
    "text": "and finally if you decide to do this to",
    "start": "535920",
    "end": "538320"
  },
  {
    "text": "enable this feature uh during the",
    "start": "538320",
    "end": "540240"
  },
  {
    "text": "transition period just keep in mind that",
    "start": "540240",
    "end": "542640"
  },
  {
    "text": "query execution is not free and if these",
    "start": "542640",
    "end": "545040"
  },
  {
    "text": "promethea are going to start executing",
    "start": "545040",
    "end": "547120"
  },
  {
    "text": "queries",
    "start": "547120",
    "end": "548480"
  },
  {
    "text": "make sure you monitor for increased cpu",
    "start": "548480",
    "end": "550800"
  },
  {
    "text": "usage increase memory usage so that you",
    "start": "550800",
    "end": "553920"
  },
  {
    "text": "make sure they are adequately",
    "start": "553920",
    "end": "555040"
  },
  {
    "text": "provisioned",
    "start": "555040",
    "end": "556160"
  },
  {
    "text": "to",
    "start": "556160",
    "end": "557040"
  },
  {
    "text": "to handle this additional load",
    "start": "557040",
    "end": "560560"
  },
  {
    "text": "cool so as philip mentioned what we",
    "start": "561040",
    "end": "563680"
  },
  {
    "text": "found with query pushdown was that it",
    "start": "563680",
    "end": "565760"
  },
  {
    "text": "was super efficient for a very specific",
    "start": "565760",
    "end": "568640"
  },
  {
    "text": "use case what we wanted to do next was",
    "start": "568640",
    "end": "571279"
  },
  {
    "text": "to explore a technique that would allow",
    "start": "571279",
    "end": "573120"
  },
  {
    "text": "us to distribute queries more generally",
    "start": "573120",
    "end": "575200"
  },
  {
    "text": "across promql",
    "start": "575200",
    "end": "577440"
  },
  {
    "text": "we also wanted to make sure that",
    "start": "577440",
    "end": "579760"
  },
  {
    "text": "our evaluation of queries was limited to",
    "start": "579760",
    "end": "581920"
  },
  {
    "text": "query components the nuance that philip",
    "start": "581920",
    "end": "584640"
  },
  {
    "text": "mentioned around only",
    "start": "584640",
    "end": "586560"
  },
  {
    "text": "being able to push down queries if",
    "start": "586560",
    "end": "588320"
  },
  {
    "text": "there's a promql engine present",
    "start": "588320",
    "end": "590720"
  },
  {
    "text": "was a critical issue",
    "start": "590720",
    "end": "592959"
  },
  {
    "text": "we also wanted to",
    "start": "592959",
    "end": "595600"
  },
  {
    "text": "extend some of the",
    "start": "595600",
    "end": "597279"
  },
  {
    "text": "the existing query sharing in thanos so",
    "start": "597279",
    "end": "599279"
  },
  {
    "text": "that we could",
    "start": "599279",
    "end": "600480"
  },
  {
    "text": "distribute work even further",
    "start": "600480",
    "end": "603040"
  },
  {
    "text": "so those were our requirements going",
    "start": "603040",
    "end": "604320"
  },
  {
    "text": "into query sharding the tldr for career",
    "start": "604320",
    "end": "606320"
  },
  {
    "text": "shouting is that query sharding is just",
    "start": "606320",
    "end": "607680"
  },
  {
    "text": "splitting a query uh into distinct",
    "start": "607680",
    "end": "610720"
  },
  {
    "text": "parallelizable",
    "start": "610720",
    "end": "612480"
  },
  {
    "text": "sub queries",
    "start": "612480",
    "end": "615199"
  },
  {
    "text": "so before we talk about career shouting",
    "start": "616480",
    "end": "618000"
  },
  {
    "text": "it's probably worth looking at what a",
    "start": "618000",
    "end": "619279"
  },
  {
    "text": "time series actually is",
    "start": "619279",
    "end": "621120"
  },
  {
    "text": "um so you can see for this metric http",
    "start": "621120",
    "end": "623440"
  },
  {
    "text": "request duration seconds",
    "start": "623440",
    "end": "625440"
  },
  {
    "text": "we have this series axis and this time",
    "start": "625440",
    "end": "628320"
  },
  {
    "text": "axis",
    "start": "628320",
    "end": "629920"
  },
  {
    "text": "each metric is composed of unique",
    "start": "629920",
    "end": "632320"
  },
  {
    "text": "labeled dimensions so in this case we",
    "start": "632320",
    "end": "634000"
  },
  {
    "text": "have part and status with various values",
    "start": "634000",
    "end": "636800"
  },
  {
    "text": "and then each unique time series has",
    "start": "636800",
    "end": "638720"
  },
  {
    "text": "observations over time these are what",
    "start": "638720",
    "end": "641279"
  },
  {
    "text": "you would commonly refer to as samples",
    "start": "641279",
    "end": "643440"
  },
  {
    "text": "each sample has a value associated with",
    "start": "643440",
    "end": "645279"
  },
  {
    "text": "it and a timestamp",
    "start": "645279",
    "end": "648160"
  },
  {
    "text": "so when we're talking about sharding",
    "start": "649760",
    "end": "652399"
  },
  {
    "text": "i mentioned that thanos already has a",
    "start": "652399",
    "end": "653760"
  },
  {
    "text": "shouting implementation",
    "start": "653760",
    "end": "655360"
  },
  {
    "text": "there's this notion of horizontal",
    "start": "655360",
    "end": "656720"
  },
  {
    "text": "sharding or time splitting where",
    "start": "656720",
    "end": "659600"
  },
  {
    "text": "the",
    "start": "659600",
    "end": "660480"
  },
  {
    "text": "query can be split across time and then",
    "start": "660480",
    "end": "662800"
  },
  {
    "text": "run in parallel",
    "start": "662800",
    "end": "664240"
  },
  {
    "text": "this is because each",
    "start": "664240",
    "end": "666399"
  },
  {
    "text": "time slice will only have the time",
    "start": "666399",
    "end": "668320"
  },
  {
    "text": "series once",
    "start": "668320",
    "end": "670320"
  },
  {
    "text": "and",
    "start": "670320",
    "end": "671120"
  },
  {
    "text": "a query that spanning four days can be",
    "start": "671120",
    "end": "673440"
  },
  {
    "text": "split into four one day queries as an",
    "start": "673440",
    "end": "675360"
  },
  {
    "text": "example",
    "start": "675360",
    "end": "677040"
  },
  {
    "text": "the caveats with time splitting",
    "start": "677040",
    "end": "678560"
  },
  {
    "text": "currently is that it only works for",
    "start": "678560",
    "end": "680480"
  },
  {
    "text": "range queries so if you have rules or",
    "start": "680480",
    "end": "683040"
  },
  {
    "text": "alerts defined or if you're trying to",
    "start": "683040",
    "end": "684640"
  },
  {
    "text": "use it for instant queries",
    "start": "684640",
    "end": "686880"
  },
  {
    "text": "that's not as trivially parallelizable",
    "start": "686880",
    "end": "689600"
  },
  {
    "text": "as range queries are",
    "start": "689600",
    "end": "691279"
  },
  {
    "text": "and even for short intervals",
    "start": "691279",
    "end": "693279"
  },
  {
    "text": "um on the graph that we were looking at",
    "start": "693279",
    "end": "695120"
  },
  {
    "text": "before",
    "start": "695120",
    "end": "696240"
  },
  {
    "text": "a time slice can still have arbitrary",
    "start": "696240",
    "end": "699200"
  },
  {
    "text": "cardinality this is what the hub this is",
    "start": "699200",
    "end": "700880"
  },
  {
    "text": "the this is commonly known as the high",
    "start": "700880",
    "end": "702160"
  },
  {
    "text": "cardinality problem in prometheus which",
    "start": "702160",
    "end": "704160"
  },
  {
    "text": "is the more time series you have the",
    "start": "704160",
    "end": "706079"
  },
  {
    "text": "more expensive it is to execute a query",
    "start": "706079",
    "end": "710240"
  },
  {
    "text": "so this is what time based or horizontal",
    "start": "710240",
    "end": "712639"
  },
  {
    "text": "sharding looks like say you want to sum",
    "start": "712639",
    "end": "715200"
  },
  {
    "text": "buy a pod for a specific metric you want",
    "start": "715200",
    "end": "717600"
  },
  {
    "text": "to do a sum rate over a specific metric",
    "start": "717600",
    "end": "720000"
  },
  {
    "text": "um the way that time slicing works is if",
    "start": "720000",
    "end": "722240"
  },
  {
    "text": "your original range is in this example",
    "start": "722240",
    "end": "724880"
  },
  {
    "text": "t0 to t3 you would split that up into",
    "start": "724880",
    "end": "727519"
  },
  {
    "text": "three distinct ranges",
    "start": "727519",
    "end": "729360"
  },
  {
    "text": "and you would execute them in in",
    "start": "729360",
    "end": "730639"
  },
  {
    "text": "parallel or in series but that means",
    "start": "730639",
    "end": "733040"
  },
  {
    "text": "that you've limited",
    "start": "733040",
    "end": "734800"
  },
  {
    "text": "the number of samples that you might get",
    "start": "734800",
    "end": "736480"
  },
  {
    "text": "for each time series but you haven't",
    "start": "736480",
    "end": "738000"
  },
  {
    "text": "limited the number of time series you",
    "start": "738000",
    "end": "740000"
  },
  {
    "text": "might get",
    "start": "740000",
    "end": "741200"
  },
  {
    "text": "for each request",
    "start": "741200",
    "end": "743760"
  },
  {
    "text": "so how do we manage this vertical",
    "start": "743760",
    "end": "745360"
  },
  {
    "text": "cardinality this uh scary problem that a",
    "start": "745360",
    "end": "747920"
  },
  {
    "text": "lot of people in the prometheus",
    "start": "747920",
    "end": "749040"
  },
  {
    "text": "ecosystem talk about",
    "start": "749040",
    "end": "751839"
  },
  {
    "text": "um we wanted to work on extending and",
    "start": "751839",
    "end": "754000"
  },
  {
    "text": "supplementing the existing sharding that",
    "start": "754000",
    "end": "755519"
  },
  {
    "text": "we already have in thanos",
    "start": "755519",
    "end": "757200"
  },
  {
    "text": "with this notion of vertical sharding so",
    "start": "757200",
    "end": "758720"
  },
  {
    "text": "the same way that horizontal sharding",
    "start": "758720",
    "end": "760000"
  },
  {
    "text": "works across time vertical sharding",
    "start": "760000",
    "end": "761920"
  },
  {
    "text": "works across the unique label dimension",
    "start": "761920",
    "end": "764240"
  },
  {
    "text": "of each metric",
    "start": "764240",
    "end": "767040"
  },
  {
    "text": "each shot is disassociated because we're",
    "start": "767360",
    "end": "769440"
  },
  {
    "text": "guaranteeing that each unique time",
    "start": "769440",
    "end": "771360"
  },
  {
    "text": "series will always end up on the same",
    "start": "771360",
    "end": "772800"
  },
  {
    "text": "logical shard so you can process these",
    "start": "772800",
    "end": "774720"
  },
  {
    "text": "queries in parallel without worrying",
    "start": "774720",
    "end": "776480"
  },
  {
    "text": "about",
    "start": "776480",
    "end": "777440"
  },
  {
    "text": "duplication or correctness of your query",
    "start": "777440",
    "end": "780880"
  },
  {
    "text": "and we wanted critically for thanos to",
    "start": "780880",
    "end": "783440"
  },
  {
    "text": "do this without too much planning ahead",
    "start": "783440",
    "end": "785120"
  },
  {
    "text": "of time the reason why is because we",
    "start": "785120",
    "end": "787200"
  },
  {
    "text": "don't know where time series are ahead",
    "start": "787200",
    "end": "788800"
  },
  {
    "text": "of time with a query and we wanted to",
    "start": "788800",
    "end": "790639"
  },
  {
    "text": "avoid",
    "start": "790639",
    "end": "791920"
  },
  {
    "text": "additional",
    "start": "791920",
    "end": "793200"
  },
  {
    "text": "fetch request or just checking where",
    "start": "793200",
    "end": "795040"
  },
  {
    "text": "time series are before executing a",
    "start": "795040",
    "end": "797360"
  },
  {
    "text": "particular query",
    "start": "797360",
    "end": "799600"
  },
  {
    "text": "and in our implementation leaves are",
    "start": "799600",
    "end": "801279"
  },
  {
    "text": "responsible for deterministically",
    "start": "801279",
    "end": "802880"
  },
  {
    "text": "assigning time series to shards",
    "start": "802880",
    "end": "806959"
  },
  {
    "text": "we also didn't want to make any changes",
    "start": "806959",
    "end": "808399"
  },
  {
    "text": "to the thanos read path so",
    "start": "808399",
    "end": "810720"
  },
  {
    "text": "a commonly asked question is if you have",
    "start": "810720",
    "end": "812399"
  },
  {
    "text": "this issue of duplicate time series why",
    "start": "812399",
    "end": "814160"
  },
  {
    "text": "not just duplicate them when you write",
    "start": "814160",
    "end": "816399"
  },
  {
    "text": "um that's something that other projects",
    "start": "816399",
    "end": "818240"
  },
  {
    "text": "do so for example cortex they dedupe uh",
    "start": "818240",
    "end": "820880"
  },
  {
    "text": "on",
    "start": "820880",
    "end": "821600"
  },
  {
    "text": "on right we didn't want to change the",
    "start": "821600",
    "end": "823600"
  },
  {
    "text": "right path we wanted this improvement to",
    "start": "823600",
    "end": "825760"
  },
  {
    "text": "be",
    "start": "825760",
    "end": "827839"
  },
  {
    "text": "to be almost transparent to the user",
    "start": "827839",
    "end": "829519"
  },
  {
    "text": "where they don't actually need to change",
    "start": "829519",
    "end": "831440"
  },
  {
    "text": "how they've set up thanos",
    "start": "831440",
    "end": "834000"
  },
  {
    "text": "so the first uh expression that we",
    "start": "834000",
    "end": "836160"
  },
  {
    "text": "wanted to implement for this vertical",
    "start": "836160",
    "end": "838160"
  },
  {
    "text": "query sharding is this very common",
    "start": "838160",
    "end": "840320"
  },
  {
    "text": "grouped sum rate expression",
    "start": "840320",
    "end": "842639"
  },
  {
    "text": "so assume you have the same expression",
    "start": "842639",
    "end": "844480"
  },
  {
    "text": "where you're summing bipod and you want",
    "start": "844480",
    "end": "845839"
  },
  {
    "text": "to see the rate of increase of a counter",
    "start": "845839",
    "end": "848000"
  },
  {
    "text": "metric in this case http request",
    "start": "848000",
    "end": "849519"
  },
  {
    "text": "duration seconds",
    "start": "849519",
    "end": "851040"
  },
  {
    "text": "instead of sharing across the time axis",
    "start": "851040",
    "end": "853279"
  },
  {
    "text": "we actually want to shout across the",
    "start": "853279",
    "end": "854959"
  },
  {
    "text": "unique time series themselves so what",
    "start": "854959",
    "end": "857440"
  },
  {
    "text": "we're saying for each assign chart index",
    "start": "857440",
    "end": "860320"
  },
  {
    "text": "is that the same time series will always",
    "start": "860320",
    "end": "861839"
  },
  {
    "text": "appear there and then the query i can",
    "start": "861839",
    "end": "863519"
  },
  {
    "text": "process the query as it would normally",
    "start": "863519",
    "end": "866800"
  },
  {
    "text": "with an uncharted query",
    "start": "866800",
    "end": "868560"
  },
  {
    "text": "with a crucial final step which is that",
    "start": "868560",
    "end": "870399"
  },
  {
    "text": "we then concatenate the result uh of",
    "start": "870399",
    "end": "872560"
  },
  {
    "text": "everything that's been executed",
    "start": "872560",
    "end": "875440"
  },
  {
    "text": "now with that being said um you can",
    "start": "875440",
    "end": "877920"
  },
  {
    "text": "actually use both in conjunction so if",
    "start": "877920",
    "end": "879760"
  },
  {
    "text": "you do a",
    "start": "879760",
    "end": "880880"
  },
  {
    "text": "time range",
    "start": "880880",
    "end": "882639"
  },
  {
    "text": "or a horizontal shouting pass first and",
    "start": "882639",
    "end": "885040"
  },
  {
    "text": "then split each horizontal shard",
    "start": "885040",
    "end": "886800"
  },
  {
    "text": "vertically",
    "start": "886800",
    "end": "887920"
  },
  {
    "text": "uh across time series you've now taken",
    "start": "887920",
    "end": "890560"
  },
  {
    "text": "one one query that that can potentially",
    "start": "890560",
    "end": "892720"
  },
  {
    "text": "have arbitrary time range and arbitrary",
    "start": "892720",
    "end": "895120"
  },
  {
    "text": "cardinality and you've split it into",
    "start": "895120",
    "end": "897519"
  },
  {
    "text": "manageable parallelizable chunks that",
    "start": "897519",
    "end": "899680"
  },
  {
    "text": "can be computed in parallel",
    "start": "899680",
    "end": "902880"
  },
  {
    "text": "all right um",
    "start": "904399",
    "end": "906320"
  },
  {
    "text": "so as mod mentioned we kind of worked on",
    "start": "906320",
    "end": "909680"
  },
  {
    "text": "this approach for a while and we have a",
    "start": "909680",
    "end": "911920"
  },
  {
    "text": "reference implementation",
    "start": "911920",
    "end": "913240"
  },
  {
    "text": "[Music]",
    "start": "913240",
    "end": "914480"
  },
  {
    "text": "in a branch in thanos and we use that",
    "start": "914480",
    "end": "917519"
  },
  {
    "text": "reference implementation to see",
    "start": "917519",
    "end": "919519"
  },
  {
    "text": "whether the algorithm actually is going",
    "start": "919519",
    "end": "921600"
  },
  {
    "text": "to make any improvements",
    "start": "921600",
    "end": "923600"
  },
  {
    "text": "in order to do that we generated a very",
    "start": "923600",
    "end": "926240"
  },
  {
    "text": "simple benchmark we generated",
    "start": "926240",
    "end": "929279"
  },
  {
    "text": "a synthetic base data set essentially",
    "start": "929279",
    "end": "932079"
  },
  {
    "text": "we're hundred thousand series and by",
    "start": "932079",
    "end": "934320"
  },
  {
    "text": "that we hope to simulate a setup where",
    "start": "934320",
    "end": "936480"
  },
  {
    "text": "we have let's say 100 clusters with a",
    "start": "936480",
    "end": "938399"
  },
  {
    "text": "thousand calls each and each class in",
    "start": "938399",
    "end": "940160"
  },
  {
    "text": "each cluster",
    "start": "940160",
    "end": "941279"
  },
  {
    "text": "and then um for the we compared query",
    "start": "941279",
    "end": "944800"
  },
  {
    "text": "execution in um",
    "start": "944800",
    "end": "946720"
  },
  {
    "text": "uh started versus non-started setup so",
    "start": "946720",
    "end": "949120"
  },
  {
    "text": "for the sharded setup we use something",
    "start": "949120",
    "end": "951839"
  },
  {
    "text": "we call a starting factor of three that",
    "start": "951839",
    "end": "954160"
  },
  {
    "text": "just means one query one big query would",
    "start": "954160",
    "end": "956639"
  },
  {
    "text": "get split into three smaller queries and",
    "start": "956639",
    "end": "959279"
  },
  {
    "text": "would be executed a fan out in a",
    "start": "959279",
    "end": "961040"
  },
  {
    "text": "parallel manner and in the default mode",
    "start": "961040",
    "end": "964160"
  },
  {
    "text": "in the non-started implementation we",
    "start": "964160",
    "end": "966720"
  },
  {
    "text": "would just execute queries in a",
    "start": "966720",
    "end": "968079"
  },
  {
    "text": "round-robin manner across five different",
    "start": "968079",
    "end": "970160"
  },
  {
    "text": "queries",
    "start": "970160",
    "end": "971839"
  },
  {
    "text": "and to keep everything simple we we kind",
    "start": "971839",
    "end": "974000"
  },
  {
    "text": "of did the benchmark on a single node",
    "start": "974000",
    "end": "975839"
  },
  {
    "text": "essentially on a single machine",
    "start": "975839",
    "end": "978000"
  },
  {
    "text": "and what we wanted to see is first are",
    "start": "978000",
    "end": "980480"
  },
  {
    "text": "we going to improve user experience so",
    "start": "980480",
    "end": "982399"
  },
  {
    "text": "our query is going to get executed",
    "start": "982399",
    "end": "984399"
  },
  {
    "text": "faster",
    "start": "984399",
    "end": "985440"
  },
  {
    "text": "and second are we going to destabilize",
    "start": "985440",
    "end": "988480"
  },
  {
    "text": "or stabilize the system more by sharding",
    "start": "988480",
    "end": "990959"
  },
  {
    "text": "queries so",
    "start": "990959",
    "end": "992160"
  },
  {
    "text": "um what's the operator experience going",
    "start": "992160",
    "end": "994560"
  },
  {
    "text": "to be essentially and one way we thought",
    "start": "994560",
    "end": "997519"
  },
  {
    "text": "we could do that is by measuring peak",
    "start": "997519",
    "end": "999199"
  },
  {
    "text": "and average memory usage of queries over",
    "start": "999199",
    "end": "1002160"
  },
  {
    "text": "the course of this entire benchmark",
    "start": "1002160",
    "end": "1005199"
  },
  {
    "text": "so if we jump right into the results or",
    "start": "1005199",
    "end": "1007680"
  },
  {
    "text": "into the numbers",
    "start": "1007680",
    "end": "1009279"
  },
  {
    "text": "this particular graph shows the p90",
    "start": "1009279",
    "end": "1012240"
  },
  {
    "text": "latency of executing queries over",
    "start": "1012240",
    "end": "1014959"
  },
  {
    "text": "10 to 15 minutes",
    "start": "1014959",
    "end": "1016880"
  },
  {
    "text": "without charting so this is what you get",
    "start": "1016880",
    "end": "1018480"
  },
  {
    "text": "by default in thanos we see that at the",
    "start": "1018480",
    "end": "1020959"
  },
  {
    "text": "beginning the query latency is about",
    "start": "1020959",
    "end": "1023199"
  },
  {
    "text": "nine seconds at the end we end up",
    "start": "1023199",
    "end": "1025600"
  },
  {
    "text": "somewhere around 19 seconds",
    "start": "1025600",
    "end": "1028319"
  },
  {
    "text": "and in the middle there's also this kind",
    "start": "1028319",
    "end": "1030880"
  },
  {
    "text": "of big spike where we the the p90 jumps",
    "start": "1030880",
    "end": "1034079"
  },
  {
    "text": "to about 55 seconds to execute a query",
    "start": "1034079",
    "end": "1036720"
  },
  {
    "text": "so that just speaks to the fact that um",
    "start": "1036720",
    "end": "1039280"
  },
  {
    "text": "just doing a more work in a single",
    "start": "1039280",
    "end": "1042480"
  },
  {
    "text": "process over time can",
    "start": "1042480",
    "end": "1045360"
  },
  {
    "text": "kind of destabilize a lot of things in",
    "start": "1045360",
    "end": "1047760"
  },
  {
    "text": "the system",
    "start": "1047760",
    "end": "1049120"
  },
  {
    "text": "and if we compare that to the um sharded",
    "start": "1049120",
    "end": "1052240"
  },
  {
    "text": "setup so when we actually split queries",
    "start": "1052240",
    "end": "1054400"
  },
  {
    "text": "in smaller",
    "start": "1054400",
    "end": "1055840"
  },
  {
    "text": "shards",
    "start": "1055840",
    "end": "1057039"
  },
  {
    "text": "when we start the benchmarks of the the",
    "start": "1057039",
    "end": "1058960"
  },
  {
    "text": "p90 is about five seconds so already we",
    "start": "1058960",
    "end": "1061120"
  },
  {
    "text": "have about the 40",
    "start": "1061120",
    "end": "1062880"
  },
  {
    "text": "decrease in query execution and when we",
    "start": "1062880",
    "end": "1065360"
  },
  {
    "text": "end the benchmark the latency is about",
    "start": "1065360",
    "end": "1067679"
  },
  {
    "text": "5.5 5.7 seconds that so what we can see",
    "start": "1067679",
    "end": "1071520"
  },
  {
    "text": "from this graph which might not be again",
    "start": "1071520",
    "end": "1075360"
  },
  {
    "text": "easy to measure maybe in numbers is that",
    "start": "1075360",
    "end": "1077520"
  },
  {
    "text": "we get a much more predictable and much",
    "start": "1077520",
    "end": "1080480"
  },
  {
    "text": "smoother",
    "start": "1080480",
    "end": "1081600"
  },
  {
    "text": "query response time but simply",
    "start": "1081600",
    "end": "1083360"
  },
  {
    "text": "partitioning work",
    "start": "1083360",
    "end": "1085280"
  },
  {
    "text": "across multiple nodes",
    "start": "1085280",
    "end": "1087679"
  },
  {
    "text": "or multiple processes in this case the",
    "start": "1087679",
    "end": "1089840"
  },
  {
    "text": "single knowledge is multiple processes",
    "start": "1089840",
    "end": "1092480"
  },
  {
    "text": "looking at the memory usage again this",
    "start": "1092480",
    "end": "1094480"
  },
  {
    "text": "is the default mode no sharding what you",
    "start": "1094480",
    "end": "1096880"
  },
  {
    "text": "get out of the box right now",
    "start": "1096880",
    "end": "1099039"
  },
  {
    "text": "um if you install thanos uh the peak",
    "start": "1099039",
    "end": "1102000"
  },
  {
    "text": "memory for a query is about 1.5",
    "start": "1102000",
    "end": "1104880"
  },
  {
    "text": "gigabytes to execute a single query",
    "start": "1104880",
    "end": "1108320"
  },
  {
    "text": "whereas the average is about 1.2",
    "start": "1108320",
    "end": "1110320"
  },
  {
    "text": "gigabytes and comparing that with the",
    "start": "1110320",
    "end": "1112880"
  },
  {
    "text": "charted setup",
    "start": "1112880",
    "end": "1114320"
  },
  {
    "text": "we get again we see a decrease to about",
    "start": "1114320",
    "end": "1117039"
  },
  {
    "text": "800 megabytes so approximately 50",
    "start": "1117039",
    "end": "1120559"
  },
  {
    "text": "and the average is also about 700",
    "start": "1120559",
    "end": "1122720"
  },
  {
    "text": "megabytes and again what's visible here",
    "start": "1122720",
    "end": "1125200"
  },
  {
    "text": "is that",
    "start": "1125200",
    "end": "1126160"
  },
  {
    "text": "the memory usage is much more consistent",
    "start": "1126160",
    "end": "1128880"
  },
  {
    "text": "there aren't like big um jumps and drops",
    "start": "1128880",
    "end": "1132160"
  },
  {
    "text": "and the lines are much closer together",
    "start": "1132160",
    "end": "1134080"
  },
  {
    "text": "so there's much more predictability in",
    "start": "1134080",
    "end": "1136240"
  },
  {
    "text": "the system",
    "start": "1136240",
    "end": "1138160"
  },
  {
    "text": "so in summary vertical sharding benefits",
    "start": "1138160",
    "end": "1141760"
  },
  {
    "text": "very intuitive if we split work",
    "start": "1141760",
    "end": "1144880"
  },
  {
    "text": "across multiple processes we expect",
    "start": "1144880",
    "end": "1147520"
  },
  {
    "text": "lower",
    "start": "1147520",
    "end": "1148320"
  },
  {
    "text": "peak memory across those processes lower",
    "start": "1148320",
    "end": "1150720"
  },
  {
    "text": "latency that all makes sense",
    "start": "1150720",
    "end": "1153360"
  },
  {
    "text": "the crucial advantage which we",
    "start": "1153360",
    "end": "1156559"
  },
  {
    "text": "hope to achieve with virtual vertical",
    "start": "1156559",
    "end": "1158240"
  },
  {
    "text": "sharding over specifically striding by",
    "start": "1158240",
    "end": "1161200"
  },
  {
    "text": "kind of time range is that we can apply",
    "start": "1161200",
    "end": "1163679"
  },
  {
    "text": "this to instant queries so things like",
    "start": "1163679",
    "end": "1166240"
  },
  {
    "text": "alerting rules and recording rules can",
    "start": "1166240",
    "end": "1168160"
  },
  {
    "text": "also be executed in a sharded manner",
    "start": "1168160",
    "end": "1171039"
  },
  {
    "text": "and just we still have a few things to",
    "start": "1171039",
    "end": "1173679"
  },
  {
    "text": "hash out so we don't",
    "start": "1173679",
    "end": "1175760"
  },
  {
    "text": "support so we don't have an",
    "start": "1175760",
    "end": "1177200"
  },
  {
    "text": "implementation for the full",
    "start": "1177200",
    "end": "1178960"
  },
  {
    "text": "uh range of prompt qual expressions so",
    "start": "1178960",
    "end": "1180880"
  },
  {
    "text": "we need to have some sort of",
    "start": "1180880",
    "end": "1183200"
  },
  {
    "text": "aggregations in the",
    "start": "1183200",
    "end": "1185280"
  },
  {
    "text": "query expressions in order to shard on",
    "start": "1185280",
    "end": "1187039"
  },
  {
    "text": "those labels",
    "start": "1187039",
    "end": "1188320"
  },
  {
    "text": "uh but i'm i think that over time we'll",
    "start": "1188320",
    "end": "1190880"
  },
  {
    "text": "just we'll just a bit need a bit more",
    "start": "1190880",
    "end": "1192559"
  },
  {
    "text": "time to kind of hash out the details",
    "start": "1192559",
    "end": "1194799"
  },
  {
    "text": "there",
    "start": "1194799",
    "end": "1196240"
  },
  {
    "text": "and one more thing to keep in mind is",
    "start": "1196240",
    "end": "1198400"
  },
  {
    "text": "that as we start to split queries up",
    "start": "1198400",
    "end": "1202400"
  },
  {
    "text": "queries will be kind of smaller but",
    "start": "1202400",
    "end": "1204480"
  },
  {
    "text": "there's going to be more of them so",
    "start": "1204480",
    "end": "1206000"
  },
  {
    "text": "there's going to be more requests per",
    "start": "1206000",
    "end": "1208400"
  },
  {
    "text": "second let's say throughout the system",
    "start": "1208400",
    "end": "1210159"
  },
  {
    "text": "and we'll have to make sure that we keep",
    "start": "1210159",
    "end": "1211760"
  },
  {
    "text": "an eye on that and make sure that all",
    "start": "1211760",
    "end": "1214080"
  },
  {
    "text": "components are kind of",
    "start": "1214080",
    "end": "1216080"
  },
  {
    "text": "properly provisioned and capable of",
    "start": "1216080",
    "end": "1218000"
  },
  {
    "text": "handling that increased volume",
    "start": "1218000",
    "end": "1221840"
  },
  {
    "text": "cool so i guess we've heard uh about",
    "start": "1222880",
    "end": "1225120"
  },
  {
    "text": "practically how something like vertical",
    "start": "1225120",
    "end": "1226799"
  },
  {
    "text": "and horizontal query sharding works",
    "start": "1226799",
    "end": "1229440"
  },
  {
    "text": "we've seen the performance benefits and",
    "start": "1229440",
    "end": "1231600"
  },
  {
    "text": "the benchmark that we've presented",
    "start": "1231600",
    "end": "1234559"
  },
  {
    "text": "what i wanted to show is",
    "start": "1234559",
    "end": "1237039"
  },
  {
    "text": "philip and myself both work in kind of",
    "start": "1237039",
    "end": "1239520"
  },
  {
    "text": "fleet monitoring and observability teams",
    "start": "1239520",
    "end": "1241120"
  },
  {
    "text": "at our respective companies",
    "start": "1241120",
    "end": "1242880"
  },
  {
    "text": "and we wanted to give an impression of",
    "start": "1242880",
    "end": "1245200"
  },
  {
    "text": "vaguely the scale of problem that this",
    "start": "1245200",
    "end": "1247039"
  },
  {
    "text": "kind of solution or that this kind of",
    "start": "1247039",
    "end": "1249120"
  },
  {
    "text": "approach solves",
    "start": "1249120",
    "end": "1250720"
  },
  {
    "text": "so let's uh suppose you have um a",
    "start": "1250720",
    "end": "1253360"
  },
  {
    "text": "central observability cluster",
    "start": "1253360",
    "end": "1255760"
  },
  {
    "text": "that's running thanos",
    "start": "1255760",
    "end": "1257360"
  },
  {
    "text": "let's suppose that you have thousands of",
    "start": "1257360",
    "end": "1258799"
  },
  {
    "text": "clusters that you have to monitor either",
    "start": "1258799",
    "end": "1260720"
  },
  {
    "text": "platform monitoring or user workload",
    "start": "1260720",
    "end": "1262240"
  },
  {
    "text": "monitoring",
    "start": "1262240",
    "end": "1263919"
  },
  {
    "text": "and each of these clusters is producing",
    "start": "1263919",
    "end": "1266000"
  },
  {
    "text": "some amount of series per day and you",
    "start": "1266000",
    "end": "1267919"
  },
  {
    "text": "want",
    "start": "1267919",
    "end": "1268720"
  },
  {
    "text": "30-day retention with thanos you can",
    "start": "1268720",
    "end": "1270559"
  },
  {
    "text": "really have",
    "start": "1270559",
    "end": "1271600"
  },
  {
    "text": "arbitrary retention but let's just say",
    "start": "1271600",
    "end": "1273200"
  },
  {
    "text": "it's 30-day for the sake of example",
    "start": "1273200",
    "end": "1276400"
  },
  {
    "text": "i'm going to simplify the query path",
    "start": "1276400",
    "end": "1277760"
  },
  {
    "text": "just for the sake of demonstration um",
    "start": "1277760",
    "end": "1279919"
  },
  {
    "text": "but it stands to reason that if somebody",
    "start": "1279919",
    "end": "1281520"
  },
  {
    "text": "is writing metrics to a central place",
    "start": "1281520",
    "end": "1284320"
  },
  {
    "text": "that they probably want to query the",
    "start": "1284320",
    "end": "1285520"
  },
  {
    "text": "metrics as well",
    "start": "1285520",
    "end": "1288080"
  },
  {
    "text": "so let's say uh our users want to sum uh",
    "start": "1288080",
    "end": "1292000"
  },
  {
    "text": "some metric by cluster",
    "start": "1292000",
    "end": "1295280"
  },
  {
    "text": "we have uh our thanos queria but this",
    "start": "1295280",
    "end": "1297919"
  },
  {
    "text": "presents an interesting challenge with",
    "start": "1297919",
    "end": "1299600"
  },
  {
    "text": "the caveats we've mentioned already",
    "start": "1299600",
    "end": "1301200"
  },
  {
    "text": "which is that we need the node to be big",
    "start": "1301200",
    "end": "1303200"
  },
  {
    "text": "enough to be able to hold all of the",
    "start": "1303200",
    "end": "1305919"
  },
  {
    "text": "time series that a particular query is",
    "start": "1305919",
    "end": "1307919"
  },
  {
    "text": "fetching before it can evaluate prom qr",
    "start": "1307919",
    "end": "1310240"
  },
  {
    "text": "so we're holding 20 million active",
    "start": "1310240",
    "end": "1312320"
  },
  {
    "text": "series over 30 days",
    "start": "1312320",
    "end": "1314080"
  },
  {
    "text": "even if you uh time slice with",
    "start": "1314080",
    "end": "1317200"
  },
  {
    "text": "thanos as it currently stands",
    "start": "1317200",
    "end": "1319200"
  },
  {
    "text": "that's still a lot of metrics that you",
    "start": "1319200",
    "end": "1320880"
  },
  {
    "text": "might have to retrieve in a given query",
    "start": "1320880",
    "end": "1324000"
  },
  {
    "text": "so um",
    "start": "1324000",
    "end": "1325360"
  },
  {
    "text": "let's say you",
    "start": "1325360",
    "end": "1326559"
  },
  {
    "text": "create a 100 gigabyte thanos query so",
    "start": "1326559",
    "end": "1329039"
  },
  {
    "text": "you give it a 100 gig of memory and you",
    "start": "1329039",
    "end": "1330320"
  },
  {
    "text": "just hope that a query doesn't exceed",
    "start": "1330320",
    "end": "1332080"
  },
  {
    "text": "that amount",
    "start": "1332080",
    "end": "1333600"
  },
  {
    "text": "um you probably need a couple of",
    "start": "1333600",
    "end": "1335600"
  },
  {
    "text": "replicas because you might you you want",
    "start": "1335600",
    "end": "1337600"
  },
  {
    "text": "to serve concurrent traffic you're not",
    "start": "1337600",
    "end": "1338880"
  },
  {
    "text": "going to deal with one query at a given",
    "start": "1338880",
    "end": "1340720"
  },
  {
    "text": "time",
    "start": "1340720",
    "end": "1342960"
  },
  {
    "text": "and you just kind of hope that this",
    "start": "1342960",
    "end": "1344400"
  },
  {
    "text": "query executes and that you have enough",
    "start": "1344400",
    "end": "1346000"
  },
  {
    "text": "memory to facilitate it that's ignoring",
    "start": "1346000",
    "end": "1348159"
  },
  {
    "text": "even if you have concurrent queries that",
    "start": "1348159",
    "end": "1349760"
  },
  {
    "text": "are already going on in the process",
    "start": "1349760",
    "end": "1351919"
  },
  {
    "text": "and if you run out of memory",
    "start": "1351919",
    "end": "1353679"
  },
  {
    "text": "you run out of luck and your thanos",
    "start": "1353679",
    "end": "1355200"
  },
  {
    "text": "query falls over",
    "start": "1355200",
    "end": "1356960"
  },
  {
    "text": "so let's look at the same example but",
    "start": "1356960",
    "end": "1358640"
  },
  {
    "text": "let's assume that we have vertical",
    "start": "1358640",
    "end": "1360480"
  },
  {
    "text": "sharding so we've taken this",
    "start": "1360480",
    "end": "1363200"
  },
  {
    "text": "arbitrary length query we've split it by",
    "start": "1363200",
    "end": "1365760"
  },
  {
    "text": "time and then we've",
    "start": "1365760",
    "end": "1367120"
  },
  {
    "text": "sharded it by index",
    "start": "1367120",
    "end": "1370159"
  },
  {
    "text": "same expression we're summing by cluster",
    "start": "1370159",
    "end": "1372000"
  },
  {
    "text": "id",
    "start": "1372000",
    "end": "1373120"
  },
  {
    "text": "but now instead of having single nodes",
    "start": "1373120",
    "end": "1375440"
  },
  {
    "text": "having this this uh condition that a",
    "start": "1375440",
    "end": "1378240"
  },
  {
    "text": "single node has to be able to hold all",
    "start": "1378240",
    "end": "1379840"
  },
  {
    "text": "of the series in memory",
    "start": "1379840",
    "end": "1381440"
  },
  {
    "text": "we can shard uh the query across a fleet",
    "start": "1381440",
    "end": "1384159"
  },
  {
    "text": "of kind of fungible thanos queries query",
    "start": "1384159",
    "end": "1386159"
  },
  {
    "text": "has a stateless anyway",
    "start": "1386159",
    "end": "1389440"
  },
  {
    "text": "and this query load is going to be",
    "start": "1389440",
    "end": "1391280"
  },
  {
    "text": "attenuated across our fleet of thanos",
    "start": "1391280",
    "end": "1393840"
  },
  {
    "text": "queries instead of our",
    "start": "1393840",
    "end": "1395760"
  },
  {
    "text": "kind of special",
    "start": "1395760",
    "end": "1397200"
  },
  {
    "text": "large processes that we have to look",
    "start": "1397200",
    "end": "1398720"
  },
  {
    "text": "after",
    "start": "1398720",
    "end": "1400640"
  },
  {
    "text": "and this just means uh as a as a",
    "start": "1400640",
    "end": "1403280"
  },
  {
    "text": "platform engineer if you're maintaining",
    "start": "1403280",
    "end": "1404799"
  },
  {
    "text": "the system you can sleep better at night",
    "start": "1404799",
    "end": "1407280"
  },
  {
    "text": "and not worry about this",
    "start": "1407280",
    "end": "1408799"
  },
  {
    "text": "arbitrary problem",
    "start": "1408799",
    "end": "1410880"
  },
  {
    "text": "and or this arbitrary complexity problem",
    "start": "1410880",
    "end": "1413600"
  },
  {
    "text": "and",
    "start": "1413600",
    "end": "1414559"
  },
  {
    "text": "when it comes to scaling up and scaling",
    "start": "1414559",
    "end": "1416320"
  },
  {
    "text": "down thanos queries because you're",
    "start": "1416320",
    "end": "1417679"
  },
  {
    "text": "shouting queries it's simply the case of",
    "start": "1417679",
    "end": "1420240"
  },
  {
    "text": "having a horizontal part auto scaler",
    "start": "1420240",
    "end": "1422400"
  },
  {
    "text": "create more thanos queries or reduce",
    "start": "1422400",
    "end": "1424240"
  },
  {
    "text": "them when you don't have query load",
    "start": "1424240",
    "end": "1427520"
  },
  {
    "text": "so as philip mentioned we've there is an",
    "start": "1427600",
    "end": "1429760"
  },
  {
    "text": "implementation for this for for grouping",
    "start": "1429760",
    "end": "1432080"
  },
  {
    "text": "uh aggregation queries",
    "start": "1432080",
    "end": "1434720"
  },
  {
    "text": "there is also a proposal in upstream",
    "start": "1434720",
    "end": "1436080"
  },
  {
    "text": "thanos that discusses this",
    "start": "1436080",
    "end": "1438720"
  },
  {
    "text": "and we're working on expanding from qr",
    "start": "1438720",
    "end": "1440799"
  },
  {
    "text": "support so now that we've done some",
    "start": "1440799",
    "end": "1442559"
  },
  {
    "text": "rates uh by some",
    "start": "1442559",
    "end": "1444880"
  },
  {
    "text": "value we want to start exploring the",
    "start": "1444880",
    "end": "1446320"
  },
  {
    "text": "rest of the prom qr standard library",
    "start": "1446320",
    "end": "1448320"
  },
  {
    "text": "um this was philip and myself's first",
    "start": "1448320",
    "end": "1451360"
  },
  {
    "text": "foray into contributing to thanos so i",
    "start": "1451360",
    "end": "1454240"
  },
  {
    "text": "recommend that you all have a look at",
    "start": "1454240",
    "end": "1455679"
  },
  {
    "text": "these if this interests you and",
    "start": "1455679",
    "end": "1457600"
  },
  {
    "text": "contribute to thanos the community is",
    "start": "1457600",
    "end": "1459760"
  },
  {
    "text": "super friendly we had a great time",
    "start": "1459760",
    "end": "1461840"
  },
  {
    "text": "talking to people about these ideas and",
    "start": "1461840",
    "end": "1463200"
  },
  {
    "text": "there's plenty of",
    "start": "1463200",
    "end": "1464480"
  },
  {
    "text": "cool work to",
    "start": "1464480",
    "end": "1466240"
  },
  {
    "text": "to take a look at",
    "start": "1466240",
    "end": "1468240"
  },
  {
    "text": "for more context this was quite a",
    "start": "1468240",
    "end": "1471120"
  },
  {
    "text": "simplified view of the problem",
    "start": "1471120",
    "end": "1473679"
  },
  {
    "text": "but if you want to learn more about the",
    "start": "1473679",
    "end": "1474960"
  },
  {
    "text": "prometheus tsdb in the exposition format",
    "start": "1474960",
    "end": "1477360"
  },
  {
    "text": "or thanos itself and how to do fleet",
    "start": "1477360",
    "end": "1479440"
  },
  {
    "text": "monitoring in thanos there are these",
    "start": "1479440",
    "end": "1481039"
  },
  {
    "text": "great kubecon talks by",
    "start": "1481039",
    "end": "1482720"
  },
  {
    "text": "members of the computer of the community",
    "start": "1482720",
    "end": "1484400"
  },
  {
    "text": "of the prometheus and thanos community",
    "start": "1484400",
    "end": "1487360"
  },
  {
    "text": "that i recommend you watch",
    "start": "1487360",
    "end": "1490159"
  },
  {
    "text": "yeah and thanks thanks to thanks to the",
    "start": "1490159",
    "end": "1492320"
  },
  {
    "text": "community and maintainers",
    "start": "1492320",
    "end": "1494130"
  },
  {
    "text": "[Applause]",
    "start": "1494130",
    "end": "1502240"
  },
  {
    "text": "all right so i think we'll have some",
    "start": "1502240",
    "end": "1503679"
  },
  {
    "text": "time for questions and if anyone has any",
    "start": "1503679",
    "end": "1506080"
  },
  {
    "text": "questions i think you can just walk up",
    "start": "1506080",
    "end": "1508080"
  },
  {
    "text": "to that mic",
    "start": "1508080",
    "end": "1510480"
  },
  {
    "text": "and shoot",
    "start": "1510480",
    "end": "1513720"
  },
  {
    "text": "all right",
    "start": "1521200",
    "end": "1522480"
  },
  {
    "text": "hello hi thank you for the talk so it",
    "start": "1522480",
    "end": "1525200"
  },
  {
    "text": "seems like the vertical sharding might",
    "start": "1525200",
    "end": "1527279"
  },
  {
    "text": "be useful useful for prometheus",
    "start": "1527279",
    "end": "1530320"
  },
  {
    "text": "itself also like i think the majority of",
    "start": "1530320",
    "end": "1533039"
  },
  {
    "text": "the time is spent in getting the data",
    "start": "1533039",
    "end": "1534480"
  },
  {
    "text": "from the disk right so",
    "start": "1534480",
    "end": "1536000"
  },
  {
    "text": "it seems usable for a single prometheus",
    "start": "1536000",
    "end": "1538720"
  },
  {
    "text": "as well what are your thoughts on that",
    "start": "1538720",
    "end": "1542919"
  },
  {
    "text": "yeah that's true i guess the the thing",
    "start": "1544960",
    "end": "1547039"
  },
  {
    "text": "that prometheus tries to do and this is",
    "start": "1547039",
    "end": "1549760"
  },
  {
    "text": "i assume intentional by design",
    "start": "1549760",
    "end": "1552080"
  },
  {
    "text": "is is effectively restrict the problem",
    "start": "1552080",
    "end": "1554159"
  },
  {
    "text": "space prometheus is very good at doing a",
    "start": "1554159",
    "end": "1555760"
  },
  {
    "text": "very specific thing",
    "start": "1555760",
    "end": "1557440"
  },
  {
    "text": "and introducing complexities to promql",
    "start": "1557440",
    "end": "1560240"
  },
  {
    "text": "engine itself how it processes queries",
    "start": "1560240",
    "end": "1563039"
  },
  {
    "text": "are probably out of the scope of of",
    "start": "1563039",
    "end": "1564640"
  },
  {
    "text": "prometheus itself",
    "start": "1564640",
    "end": "1566480"
  },
  {
    "text": "but there is there's been talks in",
    "start": "1566480",
    "end": "1568799"
  },
  {
    "text": "various meetups this week",
    "start": "1568799",
    "end": "1570720"
  },
  {
    "text": "uh about what a a future promptgoal",
    "start": "1570720",
    "end": "1573120"
  },
  {
    "text": "engine would look like that's built for",
    "start": "1573120",
    "end": "1575039"
  },
  {
    "text": "this kind of cloud native use case",
    "start": "1575039",
    "end": "1576559"
  },
  {
    "text": "instead of the",
    "start": "1576559",
    "end": "1577840"
  },
  {
    "text": "single prometheus use case but it's not",
    "start": "1577840",
    "end": "1579520"
  },
  {
    "text": "an easy problem it's quite complex",
    "start": "1579520",
    "end": "1582400"
  },
  {
    "text": "i think there are also some um kind of",
    "start": "1582400",
    "end": "1584799"
  },
  {
    "text": "proposals informative itself to add",
    "start": "1584799",
    "end": "1586799"
  },
  {
    "text": "sharding at the tsdb level so that the",
    "start": "1586799",
    "end": "1589679"
  },
  {
    "text": "block can be you can retrieve um",
    "start": "1589679",
    "end": "1593120"
  },
  {
    "text": "shards of the block",
    "start": "1593120",
    "end": "1595039"
  },
  {
    "text": "um",
    "start": "1595039",
    "end": "1596080"
  },
  {
    "text": "we're again we're we're following that",
    "start": "1596080",
    "end": "1598080"
  },
  {
    "text": "work making sure that at least what",
    "start": "1598080",
    "end": "1599760"
  },
  {
    "text": "we're doing thanos is backwards",
    "start": "1599760",
    "end": "1601039"
  },
  {
    "text": "compatible or compatible with prometheus",
    "start": "1601039",
    "end": "1603279"
  },
  {
    "text": "um",
    "start": "1603279",
    "end": "1604320"
  },
  {
    "text": "but",
    "start": "1604320",
    "end": "1605279"
  },
  {
    "text": "changing such a stable project like a 10",
    "start": "1605279",
    "end": "1607520"
  },
  {
    "text": "year old cncf graduated project takes a",
    "start": "1607520",
    "end": "1611120"
  },
  {
    "text": "bit more time than",
    "start": "1611120",
    "end": "1612720"
  },
  {
    "text": "adding something kind of around it or",
    "start": "1612720",
    "end": "1614799"
  },
  {
    "text": "not",
    "start": "1614799",
    "end": "1616880"
  },
  {
    "text": "hey",
    "start": "1618320",
    "end": "1619039"
  },
  {
    "text": "thanks for the talk again",
    "start": "1619039",
    "end": "1621200"
  },
  {
    "text": "so you're proposing sharding on the",
    "start": "1621200",
    "end": "1623840"
  },
  {
    "text": "query level but if our data comes from",
    "start": "1623840",
    "end": "1627279"
  },
  {
    "text": "the store than our store can we also",
    "start": "1627279",
    "end": "1630000"
  },
  {
    "text": "shorten the store level",
    "start": "1630000",
    "end": "1632080"
  },
  {
    "text": "um so that's what we do we actually",
    "start": "1632080",
    "end": "1635520"
  },
  {
    "text": "um",
    "start": "1635520",
    "end": "1636559"
  },
  {
    "text": "so the query requests a chart from the",
    "start": "1636559",
    "end": "1639200"
  },
  {
    "text": "store",
    "start": "1639200",
    "end": "1640559"
  },
  {
    "text": "and the store only retrieves a subset of",
    "start": "1640559",
    "end": "1643200"
  },
  {
    "text": "data so sharding in in this particular",
    "start": "1643200",
    "end": "1645279"
  },
  {
    "text": "implementation",
    "start": "1645279",
    "end": "1646559"
  },
  {
    "text": "sharding is going to be implemented end",
    "start": "1646559",
    "end": "1648240"
  },
  {
    "text": "to end from",
    "start": "1648240",
    "end": "1649679"
  },
  {
    "text": "when you execute the query to the store",
    "start": "1649679",
    "end": "1652559"
  },
  {
    "text": "when the store actually retrieves data",
    "start": "1652559",
    "end": "1654960"
  },
  {
    "text": "sends it back to the credit",
    "start": "1654960",
    "end": "1656880"
  },
  {
    "text": "does that answer the question or",
    "start": "1656880",
    "end": "1660080"
  },
  {
    "text": "yeah more or less but",
    "start": "1660080",
    "end": "1662559"
  },
  {
    "text": "we have one story instance or multiple",
    "start": "1662559",
    "end": "1666720"
  },
  {
    "text": "you can still maintain your existing",
    "start": "1666720",
    "end": "1669120"
  },
  {
    "text": "setup",
    "start": "1669120",
    "end": "1670240"
  },
  {
    "text": "um",
    "start": "1670240",
    "end": "1671120"
  },
  {
    "text": "different uh so queries that handle",
    "start": "1671120",
    "end": "1674399"
  },
  {
    "text": "different charts will still talk to the",
    "start": "1674399",
    "end": "1676240"
  },
  {
    "text": "same",
    "start": "1676240",
    "end": "1677120"
  },
  {
    "text": "even if you have a single store instance",
    "start": "1677120",
    "end": "1678799"
  },
  {
    "text": "they will talk to this one store",
    "start": "1678799",
    "end": "1680399"
  },
  {
    "text": "instance they'll just request one shard",
    "start": "1680399",
    "end": "1682880"
  },
  {
    "text": "of the data so",
    "start": "1682880",
    "end": "1685200"
  },
  {
    "text": "the existing setup for you will not",
    "start": "1685200",
    "end": "1687360"
  },
  {
    "text": "change essentially yeah thanks",
    "start": "1687360",
    "end": "1691440"
  },
  {
    "text": "hi",
    "start": "1692320",
    "end": "1693200"
  },
  {
    "text": "um",
    "start": "1693200",
    "end": "1694080"
  },
  {
    "text": "did you by any chance have a look at the",
    "start": "1694080",
    "end": "1696960"
  },
  {
    "text": "s3 request weight when you do vertical",
    "start": "1696960",
    "end": "1699919"
  },
  {
    "text": "sharding",
    "start": "1699919",
    "end": "1701120"
  },
  {
    "text": "so does that increase or",
    "start": "1701120",
    "end": "1704000"
  },
  {
    "text": "because that's in our use case it's we",
    "start": "1704000",
    "end": "1706720"
  },
  {
    "text": "are limited by our s3 request rate we",
    "start": "1706720",
    "end": "1709760"
  },
  {
    "text": "basically have",
    "start": "1709760",
    "end": "1711120"
  },
  {
    "text": "unlimited compute and memory",
    "start": "1711120",
    "end": "1715200"
  },
  {
    "text": "uh i think that's a very good point um",
    "start": "1715440",
    "end": "1718720"
  },
  {
    "text": "so there there",
    "start": "1718720",
    "end": "1720480"
  },
  {
    "text": "we haven't looked um specifically at",
    "start": "1720480",
    "end": "1723440"
  },
  {
    "text": "this particular metric but",
    "start": "1723440",
    "end": "1726159"
  },
  {
    "text": "in thanos there are various way to cache",
    "start": "1726159",
    "end": "1729360"
  },
  {
    "text": "data from s3 so cache",
    "start": "1729360",
    "end": "1732399"
  },
  {
    "text": "both index data and chunk data",
    "start": "1732399",
    "end": "1735120"
  },
  {
    "text": "and so",
    "start": "1735120",
    "end": "1736399"
  },
  {
    "text": "we're hoping that even if there is an",
    "start": "1736399",
    "end": "1739200"
  },
  {
    "text": "increase we can reduce it by adding some",
    "start": "1739200",
    "end": "1740880"
  },
  {
    "text": "intermediary caching so that we don't",
    "start": "1740880",
    "end": "1742559"
  },
  {
    "text": "have to fetch data twice",
    "start": "1742559",
    "end": "1744960"
  },
  {
    "text": "um",
    "start": "1744960",
    "end": "1746480"
  },
  {
    "text": "so to answer your question the tl dr we",
    "start": "1746480",
    "end": "1748240"
  },
  {
    "text": "haven't specifically looked at it but we",
    "start": "1748240",
    "end": "1750000"
  },
  {
    "text": "hope that there's or we think that",
    "start": "1750000",
    "end": "1751279"
  },
  {
    "text": "there's a way to actually address this",
    "start": "1751279",
    "end": "1752720"
  },
  {
    "text": "problem so that we don't increase",
    "start": "1752720",
    "end": "1754399"
  },
  {
    "text": "requests towards s3",
    "start": "1754399",
    "end": "1757760"
  },
  {
    "text": "thanks",
    "start": "1758080",
    "end": "1760398"
  },
  {
    "text": "cool",
    "start": "1762799",
    "end": "1763840"
  },
  {
    "text": "we'll be outside after the talk if",
    "start": "1763840",
    "end": "1765279"
  },
  {
    "text": "anybody wants to",
    "start": "1765279",
    "end": "1766480"
  },
  {
    "text": "grab us and ask us a question but i'd",
    "start": "1766480",
    "end": "1768320"
  },
  {
    "text": "recommend you have a look at the",
    "start": "1768320",
    "end": "1769919"
  },
  {
    "text": "proposal in the upstream and engage with",
    "start": "1769919",
    "end": "1771600"
  },
  {
    "text": "the community if you have any concerns",
    "start": "1771600",
    "end": "1773360"
  },
  {
    "text": "or ideas",
    "start": "1773360",
    "end": "1775200"
  },
  {
    "text": "all right thank you",
    "start": "1775200",
    "end": "1778840"
  }
]
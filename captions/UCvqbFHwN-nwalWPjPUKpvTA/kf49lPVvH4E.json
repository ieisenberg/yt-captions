[
  {
    "text": "thank you all for joining us today my",
    "start": "719",
    "end": "3280"
  },
  {
    "text": "name is Ashley and this is AG up front",
    "start": "3280",
    "end": "6080"
  },
  {
    "text": "we're both software Engineers on the",
    "start": "6080",
    "end": "7439"
  },
  {
    "text": "grpc library maintainers team and we",
    "start": "7439",
    "end": "9760"
  },
  {
    "text": "also both work on the broader networking",
    "start": "9760",
    "end": "11280"
  },
  {
    "text": "stack for Google Cloud so thank you all",
    "start": "11280",
    "end": "13200"
  },
  {
    "text": "for joining us here for the last stretch",
    "start": "13200",
    "end": "14639"
  },
  {
    "text": "of the day so today we'll be giving an",
    "start": "14639",
    "end": "17520"
  },
  {
    "text": "iceberg style tour of how we think about",
    "start": "17520",
    "end": "19800"
  },
  {
    "text": "performance in grpc from the maintainers",
    "start": "19800",
    "end": "22119"
  },
  {
    "text": "perspective starting with some broad",
    "start": "22119",
    "end": "24119"
  },
  {
    "text": "principles of performance analysis and",
    "start": "24119",
    "end": "26080"
  },
  {
    "text": "then diving deeper into the tests and",
    "start": "26080",
    "end": "27960"
  },
  {
    "text": "tools that we use to analyze the",
    "start": "27960",
    "end": "29599"
  },
  {
    "text": "performance of the grpc libraries",
    "start": "29599",
    "end": "32078"
  },
  {
    "text": "finally we'll come back up to the",
    "start": "32079",
    "end": "33760"
  },
  {
    "text": "surface and give you all a sneak preview",
    "start": "33760",
    "end": "35600"
  },
  {
    "text": "of some of the cool features and",
    "start": "35600",
    "end": "37000"
  },
  {
    "text": "improvements coming soon so let's start",
    "start": "37000",
    "end": "39719"
  },
  {
    "text": "at the top why do we care about",
    "start": "39719",
    "end": "42160"
  },
  {
    "text": "performance quick show of hands how many",
    "start": "42160",
    "end": "44120"
  },
  {
    "text": "of you want your service to handle more",
    "start": "44120",
    "end": "45960"
  },
  {
    "text": "requests and faster and for the same",
    "start": "45960",
    "end": "47960"
  },
  {
    "text": "amount of compute yes cool how many of",
    "start": "47960",
    "end": "50920"
  },
  {
    "text": "you want your service to use less",
    "start": "50920",
    "end": "52399"
  },
  {
    "text": "resources so it doesn't rack up a huge",
    "start": "52399",
    "end": "54000"
  },
  {
    "text": "bill from your favorite cloud provider",
    "start": "54000",
    "end": "56160"
  },
  {
    "text": "yeah I think we all would like to save",
    "start": "56160",
    "end": "57879"
  },
  {
    "text": "money so the goal of performance",
    "start": "57879",
    "end": "60120"
  },
  {
    "text": "optimization is pretty simple we want to",
    "start": "60120",
    "end": "62239"
  },
  {
    "text": "do more useful stuff and for Less cost",
    "start": "62239",
    "end": "64920"
  },
  {
    "text": "and actually earlier today Gina and",
    "start": "64920",
    "end": "66640"
  },
  {
    "text": "arvine from the grpc maintainers team",
    "start": "66640",
    "end": "68920"
  },
  {
    "text": "talked about how you can do just that",
    "start": "68920",
    "end": "70360"
  },
  {
    "text": "with proxyless service mesh and",
    "start": "70360",
    "end": "72720"
  },
  {
    "text": "grpc but in general the problem of",
    "start": "72720",
    "end": "75640"
  },
  {
    "text": "actually measuring and improving the",
    "start": "75640",
    "end": "77280"
  },
  {
    "text": "performance of a service is very complex",
    "start": "77280",
    "end": "79600"
  },
  {
    "text": "because there are a lot of cral factors",
    "start": "79600",
    "end": "82159"
  },
  {
    "text": "that are unique to a particular service",
    "start": "82159",
    "end": "84280"
  },
  {
    "text": "so the way that one service owner thinks",
    "start": "84280",
    "end": "85920"
  },
  {
    "text": "about performance is going to be very",
    "start": "85920",
    "end": "87560"
  },
  {
    "text": "different from the way another service",
    "start": "87560",
    "end": "89079"
  },
  {
    "text": "owner would because their needs and",
    "start": "89079",
    "end": "91360"
  },
  {
    "text": "their resource constraints and their",
    "start": "91360",
    "end": "93040"
  },
  {
    "text": "ecosystems are going to be different",
    "start": "93040",
    "end": "94680"
  },
  {
    "text": "from each other in general though there",
    "start": "94680",
    "end": "97079"
  },
  {
    "text": "are a few common themes that we can use",
    "start": "97079",
    "end": "99360"
  },
  {
    "text": "When approaching the problem of how to",
    "start": "99360",
    "end": "101399"
  },
  {
    "text": "analyze performance for any given",
    "start": "101399",
    "end": "103640"
  },
  {
    "text": "service so first of all the why why do",
    "start": "103640",
    "end": "106719"
  },
  {
    "text": "we want to measure performance so this",
    "start": "106719",
    "end": "108960"
  },
  {
    "text": "goes beyond just improving how much",
    "start": "108960",
    "end": "110759"
  },
  {
    "text": "useful work it does or reducing its cost",
    "start": "110759",
    "end": "113640"
  },
  {
    "text": "the reason why continuous benchmarking",
    "start": "113640",
    "end": "115520"
  },
  {
    "text": "and profiling of our service is useful",
    "start": "115520",
    "end": "117920"
  },
  {
    "text": "is so that we can build a holistic view",
    "start": "117920",
    "end": "119680"
  },
  {
    "text": "of of how all the components and",
    "start": "119680",
    "end": "121560"
  },
  {
    "text": "dependencies in our service interact",
    "start": "121560",
    "end": "123119"
  },
  {
    "text": "with each other and how those",
    "start": "123119",
    "end": "124479"
  },
  {
    "text": "interactions evolve over time when we",
    "start": "124479",
    "end": "127200"
  },
  {
    "text": "look at many different points across the",
    "start": "127200",
    "end": "128679"
  },
  {
    "text": "service we can identify exactly where",
    "start": "128679",
    "end": "130800"
  },
  {
    "text": "the critical paths are and use that to",
    "start": "130800",
    "end": "132800"
  },
  {
    "text": "make informed decisions on what sorts of",
    "start": "132800",
    "end": "134840"
  },
  {
    "text": "optimizations are most helpful for us",
    "start": "134840",
    "end": "137560"
  },
  {
    "text": "and by gathering performance data over",
    "start": "137560",
    "end": "139239"
  },
  {
    "text": "time we can gain a better understanding",
    "start": "139239",
    "end": "141519"
  },
  {
    "text": "of not just the Baseline performance",
    "start": "141519",
    "end": "143000"
  },
  {
    "text": "trend of our service but also predict",
    "start": "143000",
    "end": "145280"
  },
  {
    "text": "how it Behavior might change in respond",
    "start": "145280",
    "end": "147560"
  },
  {
    "text": "to some new changes we introduced and",
    "start": "147560",
    "end": "149680"
  },
  {
    "text": "what the potential magnitude of the",
    "start": "149680",
    "end": "152080"
  },
  {
    "text": "impact could",
    "start": "152080",
    "end": "153640"
  },
  {
    "text": "be so now that we've convinced ourselves",
    "start": "153640",
    "end": "156280"
  },
  {
    "text": "that we should measure performance for a",
    "start": "156280",
    "end": "158319"
  },
  {
    "text": "service how should we actually do that",
    "start": "158319",
    "end": "161280"
  },
  {
    "text": "so whatever it is that we care about",
    "start": "161280",
    "end": "162640"
  },
  {
    "text": "measuring it's critical that the staging",
    "start": "162640",
    "end": "164760"
  },
  {
    "text": "environment where we're analizing our",
    "start": "164760",
    "end": "166480"
  },
  {
    "text": "services performance is as similar to",
    "start": "166480",
    "end": "168840"
  },
  {
    "text": "the production environment as possible",
    "start": "168840",
    "end": "170879"
  },
  {
    "text": "the more comprehensive our Benchmark",
    "start": "170879",
    "end": "173519"
  },
  {
    "text": "coverage the better signal it'll give us",
    "start": "173519",
    "end": "175959"
  },
  {
    "text": "on how our whole service is going to",
    "start": "175959",
    "end": "177760"
  },
  {
    "text": "behave in reality uh the the problem",
    "start": "177760",
    "end": "180120"
  },
  {
    "text": "here is that the more realistic The",
    "start": "180120",
    "end": "181519"
  },
  {
    "text": "Benchmark is the more expensive it'll be",
    "start": "181519",
    "end": "183640"
  },
  {
    "text": "to run and it might not always be",
    "start": "183640",
    "end": "185040"
  },
  {
    "text": "feasible to simulate a workload at the",
    "start": "185040",
    "end": "187440"
  },
  {
    "text": "same scale as what you actually see in",
    "start": "187440",
    "end": "189120"
  },
  {
    "text": "production um the catch here is that",
    "start": "189120",
    "end": "191080"
  },
  {
    "text": "your service might behave might behave",
    "start": "191080",
    "end": "193120"
  },
  {
    "text": "differently when you give it different",
    "start": "193120",
    "end": "194560"
  },
  {
    "text": "workloads for example under staging",
    "start": "194560",
    "end": "196760"
  },
  {
    "text": "workload your service might appear to be",
    "start": "196760",
    "end": "198879"
  },
  {
    "text": "input bound whereas in production it",
    "start": "198879",
    "end": "200599"
  },
  {
    "text": "might actually be compute bound and the",
    "start": "200599",
    "end": "202319"
  },
  {
    "text": "way to address those two problems are",
    "start": "202319",
    "end": "204000"
  },
  {
    "text": "going to be different from each other so",
    "start": "204000",
    "end": "205799"
  },
  {
    "text": "it's very important that we apply the",
    "start": "205799",
    "end": "208239"
  },
  {
    "text": "solution to our service that actually",
    "start": "208239",
    "end": "209959"
  },
  {
    "text": "improves things in",
    "start": "209959",
    "end": "212360"
  },
  {
    "text": "reality so so far we've touched a bit on",
    "start": "212360",
    "end": "215439"
  },
  {
    "text": "why and how we should measure",
    "start": "215439",
    "end": "216920"
  },
  {
    "text": "performance for any given service but",
    "start": "216920",
    "end": "219760"
  },
  {
    "text": "from the grpc maintainers point of view",
    "start": "219760",
    "end": "222000"
  },
  {
    "text": "we're in a slightly different position",
    "start": "222000",
    "end": "223680"
  },
  {
    "text": "from yall in that we don't build or run",
    "start": "223680",
    "end": "226560"
  },
  {
    "text": "Services ourselves rather grpc is used",
    "start": "226560",
    "end": "229560"
  },
  {
    "text": "by other developers such as yourselves",
    "start": "229560",
    "end": "231400"
  },
  {
    "text": "to build your microservices so this",
    "start": "231400",
    "end": "233920"
  },
  {
    "text": "means that there are basically an",
    "start": "233920",
    "end": "235480"
  },
  {
    "text": "endless number of different service",
    "start": "235480",
    "end": "237360"
  },
  {
    "text": "architectures out there that involve",
    "start": "237360",
    "end": "239079"
  },
  {
    "text": "grpc and each of them is going to have",
    "start": "239079",
    "end": "241599"
  },
  {
    "text": "their own unique needs and goals and",
    "start": "241599",
    "end": "244920"
  },
  {
    "text": "constraints and environments that they",
    "start": "244920",
    "end": "246560"
  },
  {
    "text": "need to work with which will impact",
    "start": "246560",
    "end": "248640"
  },
  {
    "text": "their performance Trends in unique ways",
    "start": "248640",
    "end": "251400"
  },
  {
    "text": "so because of that from the library",
    "start": "251400",
    "end": "253319"
  },
  {
    "text": "maintainers point of view we don't and",
    "start": "253319",
    "end": "255920"
  },
  {
    "text": "we can't really provide a definitive",
    "start": "255920",
    "end": "257919"
  },
  {
    "text": "answer on how you should optimize your",
    "start": "257919",
    "end": "260000"
  },
  {
    "text": "service because that depends a lot on",
    "start": "260000",
    "end": "261959"
  },
  {
    "text": "your particular situation instead what",
    "start": "261959",
    "end": "264880"
  },
  {
    "text": "we focus on its maintainers is we strive",
    "start": "264880",
    "end": "267199"
  },
  {
    "text": "to build an RPC Library that's both",
    "start": "267199",
    "end": "269360"
  },
  {
    "text": "featured rich and performant for as many",
    "start": "269360",
    "end": "271919"
  },
  {
    "text": "of those use cases out there as possible",
    "start": "271919",
    "end": "274400"
  },
  {
    "text": "we know that you rely on grpc to power",
    "start": "274400",
    "end": "276280"
  },
  {
    "text": "the critical Paths of your applications",
    "start": "276280",
    "end": "278360"
  },
  {
    "text": "so we invest considerably into testing",
    "start": "278360",
    "end": "280800"
  },
  {
    "text": "and improving the library's performance",
    "start": "280800",
    "end": "282840"
  },
  {
    "text": "so that you can rest assured that your",
    "start": "282840",
    "end": "284440"
  },
  {
    "text": "PC is delivering the performance you",
    "start": "284440",
    "end": "287400"
  },
  {
    "text": "expect so to achieve all that we",
    "start": "287400",
    "end": "289919"
  },
  {
    "text": "maintainers focus on a few driving",
    "start": "289919",
    "end": "291720"
  },
  {
    "text": "principles first of all we want to build",
    "start": "291720",
    "end": "294600"
  },
  {
    "text": "a featur rich Library while minimizing",
    "start": "294600",
    "end": "297080"
  },
  {
    "text": "the overall performance impact of those",
    "start": "297080",
    "end": "298840"
  },
  {
    "text": "features so as a general rule of thumb",
    "start": "298840",
    "end": "301320"
  },
  {
    "text": "as the feature set of a piece of",
    "start": "301320",
    "end": "302880"
  },
  {
    "text": "software increases the complexity is",
    "start": "302880",
    "end": "304840"
  },
  {
    "text": "also going to go up and that complexity",
    "start": "304840",
    "end": "306800"
  },
  {
    "text": "incurs extra overhead so when we're",
    "start": "306800",
    "end": "309400"
  },
  {
    "text": "designing new grpc features in addition",
    "start": "309400",
    "end": "312080"
  },
  {
    "text": "to minimizing the overhead of that",
    "start": "312080",
    "end": "314320"
  },
  {
    "text": "particular feature we also design it",
    "start": "314320",
    "end": "316479"
  },
  {
    "text": "such that users who don't use the",
    "start": "316479",
    "end": "318199"
  },
  {
    "text": "feature won't incur that extra overhead",
    "start": "318199",
    "end": "320800"
  },
  {
    "text": "at all in the first place secondly the",
    "start": "320800",
    "end": "323759"
  },
  {
    "text": "GPC library is long lived and evolving",
    "start": "323759",
    "end": "326680"
  },
  {
    "text": "over time so as maintainers we take a",
    "start": "326680",
    "end": "328400"
  },
  {
    "text": "more long-term View over the library as",
    "start": "328400",
    "end": "330560"
  },
  {
    "text": "a whole when we design features",
    "start": "330560",
    "end": "332639"
  },
  {
    "text": "especially for features that take a",
    "start": "332639",
    "end": "334680"
  },
  {
    "text": "longer timeline to implement or are more",
    "start": "334680",
    "end": "337039"
  },
  {
    "text": "complex to roll out safely to our wide",
    "start": "337039",
    "end": "339199"
  },
  {
    "text": "user base so to set up a foundation for",
    "start": "339199",
    "end": "342600"
  },
  {
    "text": "ourselves sometimes we make a short-term",
    "start": "342600",
    "end": "344639"
  },
  {
    "text": "performance tradeoff so that we can",
    "start": "344639",
    "end": "346400"
  },
  {
    "text": "invest into fully implementing and",
    "start": "346400",
    "end": "348240"
  },
  {
    "text": "rolling out a feature and so we can reap",
    "start": "348240",
    "end": "350520"
  },
  {
    "text": "its full benefits and a lot of the times",
    "start": "350520",
    "end": "352759"
  },
  {
    "text": "one of those benefits comes in the form",
    "start": "352759",
    "end": "354479"
  },
  {
    "text": "of net performance improvements and",
    "start": "354479",
    "end": "357120"
  },
  {
    "text": "we'll talk more about this later AJ is",
    "start": "357120",
    "end": "358919"
  },
  {
    "text": "going to share are some examples of some",
    "start": "358919",
    "end": "360639"
  },
  {
    "text": "of the performance work that we've been",
    "start": "360639",
    "end": "362120"
  },
  {
    "text": "doing and what yall can look forward to",
    "start": "362120",
    "end": "364199"
  },
  {
    "text": "in upcoming",
    "start": "364199",
    "end": "365880"
  },
  {
    "text": "releases and finally when we evaluate",
    "start": "365880",
    "end": "368840"
  },
  {
    "text": "performance we prefer to look at what's",
    "start": "368840",
    "end": "370840"
  },
  {
    "text": "happening to a real production workload",
    "start": "370840",
    "end": "373280"
  },
  {
    "text": "as opposed to trying to tune for a",
    "start": "373280",
    "end": "376080"
  },
  {
    "text": "particular Benchmark which could be",
    "start": "376080",
    "end": "378000"
  },
  {
    "text": "artificial and not really reflecting",
    "start": "378000",
    "end": "379800"
  },
  {
    "text": "what's happening in the real",
    "start": "379800",
    "end": "381880"
  },
  {
    "text": "world so that being said there's still",
    "start": "381880",
    "end": "384639"
  },
  {
    "text": "some amount of benefit to running some",
    "start": "384639",
    "end": "386479"
  },
  {
    "text": "form of Benchmark kind of like the",
    "start": "386479",
    "end": "388400"
  },
  {
    "text": "benefits of running a unit test which",
    "start": "388400",
    "end": "390560"
  },
  {
    "text": "while it's not going to be able to",
    "start": "390560",
    "end": "391560"
  },
  {
    "text": "exercise the complexities of your whole",
    "start": "391560",
    "end": "393680"
  },
  {
    "text": "system it will still give you a useful",
    "start": "393680",
    "end": "396080"
  },
  {
    "text": "signal as to whether its Behavior has",
    "start": "396080",
    "end": "398360"
  },
  {
    "text": "changed significantly in response to",
    "start": "398360",
    "end": "400479"
  },
  {
    "text": "like a new change so internally we run a",
    "start": "400479",
    "end": "403479"
  },
  {
    "text": "set of benchmarks continuously that test",
    "start": "403479",
    "end": "405639"
  },
  {
    "text": "various metrics of the grpc libraries",
    "start": "405639",
    "end": "408120"
  },
  {
    "text": "under a variety of scenarios so we",
    "start": "408120",
    "end": "410400"
  },
  {
    "text": "measure things like the latency and",
    "start": "410400",
    "end": "412120"
  },
  {
    "text": "throughput of different types of rpcs",
    "start": "412120",
    "end": "414800"
  },
  {
    "text": "and we also look at the CPU load on the",
    "start": "414800",
    "end": "417080"
  },
  {
    "text": "clients and servers as they process rpcs",
    "start": "417080",
    "end": "420360"
  },
  {
    "text": "and we test a wide variety of conditions",
    "start": "420360",
    "end": "423080"
  },
  {
    "text": "we vary things like the payload size in",
    "start": "423080",
    "end": "424879"
  },
  {
    "text": "our tests um we vary the number of cores",
    "start": "424879",
    "end": "427280"
  },
  {
    "text": "on the clients and servers and see what",
    "start": "427280",
    "end": "428919"
  },
  {
    "text": "happens and of course we do all this",
    "start": "428919",
    "end": "431080"
  },
  {
    "text": "testing in every language that we",
    "start": "431080",
    "end": "432960"
  },
  {
    "text": "support in",
    "start": "432960",
    "end": "433879"
  },
  {
    "text": "grpc so what you're looking at here is a",
    "start": "433879",
    "end": "436919"
  },
  {
    "text": "dashboard of our Benchmark results which",
    "start": "436919",
    "end": "439280"
  },
  {
    "text": "I'll talk more about in a later section",
    "start": "439280",
    "end": "441440"
  },
  {
    "text": "and also share a link so where is all of",
    "start": "441440",
    "end": "444080"
  },
  {
    "text": "this benchmarking data that you see come",
    "start": "444080",
    "end": "446240"
  },
  {
    "text": "from so we have built a dedicated",
    "start": "446240",
    "end": "448840"
  },
  {
    "text": "framework which which we use to",
    "start": "448840",
    "end": "450160"
  },
  {
    "text": "continuously Benchmark the grpc clients",
    "start": "450160",
    "end": "452240"
  },
  {
    "text": "and servers by sending RPC traffic",
    "start": "452240",
    "end": "454319"
  },
  {
    "text": "between them and taking measurements of",
    "start": "454319",
    "end": "456000"
  },
  {
    "text": "that so we built a lot of infrastructure",
    "start": "456000",
    "end": "458400"
  },
  {
    "text": "to help us in our goal to deliver lots",
    "start": "458400",
    "end": "460160"
  },
  {
    "text": "of powerful new features for grpc while",
    "start": "460160",
    "end": "462680"
  },
  {
    "text": "keeping the overall overhead low which",
    "start": "462680",
    "end": "465319"
  },
  {
    "text": "is just like the same goal that you have",
    "start": "465319",
    "end": "466759"
  },
  {
    "text": "for your services and your applications",
    "start": "466759",
    "end": "468759"
  },
  {
    "text": "you want to deliver lots of cool",
    "start": "468759",
    "end": "470039"
  },
  {
    "text": "features but without a corresponding",
    "start": "470039",
    "end": "472159"
  },
  {
    "text": "blowup in the overhead so let's dive",
    "start": "472159",
    "end": "474639"
  },
  {
    "text": "more into our infrastructure and how all",
    "start": "474639",
    "end": "476840"
  },
  {
    "text": "of that works",
    "start": "476840",
    "end": "479759"
  },
  {
    "text": "so our grpc Benchmark framework consists",
    "start": "479759",
    "end": "482720"
  },
  {
    "text": "of two main components we have multiple",
    "start": "482720",
    "end": "485440"
  },
  {
    "text": "QPS worker processes and we also have a",
    "start": "485440",
    "end": "488360"
  },
  {
    "text": "driver the QPS workers are what's",
    "start": "488360",
    "end": "490879"
  },
  {
    "text": "responsible for sending RPC traffic",
    "start": "490879",
    "end": "492840"
  },
  {
    "text": "among each other to form the main",
    "start": "492840",
    "end": "494319"
  },
  {
    "text": "workload that we are trying to measure",
    "start": "494319",
    "end": "496159"
  },
  {
    "text": "in our Benchmark and the driver is",
    "start": "496159",
    "end": "498280"
  },
  {
    "text": "responsible for orchestrating that",
    "start": "498280",
    "end": "499680"
  },
  {
    "text": "traffic according to the particular",
    "start": "499680",
    "end": "501520"
  },
  {
    "text": "benchmark test we're interested in",
    "start": "501520",
    "end": "503080"
  },
  {
    "text": "running so let's walk through an example",
    "start": "503080",
    "end": "505440"
  },
  {
    "text": "so if we want to run a grpc benchmark",
    "start": "505440",
    "end": "508120"
  },
  {
    "text": "the first thing we do is we set up all",
    "start": "508120",
    "end": "509680"
  },
  {
    "text": "of our workers and we set up our driver",
    "start": "509680",
    "end": "512240"
  },
  {
    "text": "so to tell our whole system uh what sort",
    "start": "512240",
    "end": "515039"
  },
  {
    "text": "of Benchmark we want to run we create a",
    "start": "515039",
    "end": "517479"
  },
  {
    "text": "Json configuration that contains the",
    "start": "517479",
    "end": "519640"
  },
  {
    "text": "Benchmark parameters so in this Json",
    "start": "519640",
    "end": "522080"
  },
  {
    "text": "configuration I would specify things",
    "start": "522080",
    "end": "523880"
  },
  {
    "text": "like what payload size I want to run any",
    "start": "523880",
    "end": "526440"
  },
  {
    "text": "sort of client or server specific",
    "start": "526440",
    "end": "528279"
  },
  {
    "text": "configuration and so on and it pass all",
    "start": "528279",
    "end": "530640"
  },
  {
    "text": "that into the driver and driver is going",
    "start": "530640",
    "end": "533120"
  },
  {
    "text": "to take that and set up the clients and",
    "start": "533120",
    "end": "535399"
  },
  {
    "text": "servers so it'll set up the server first",
    "start": "535399",
    "end": "537720"
  },
  {
    "text": "according to whatever arguments I speci",
    "start": "537720",
    "end": "539839"
  },
  {
    "text": "specified and then it'll set up the",
    "start": "539839",
    "end": "541760"
  },
  {
    "text": "client workers similarly and it will",
    "start": "541760",
    "end": "544120"
  },
  {
    "text": "take the host and Port of all the server",
    "start": "544120",
    "end": "545680"
  },
  {
    "text": "workers and pass them to the client so",
    "start": "545680",
    "end": "547640"
  },
  {
    "text": "it knows where to send the traffic to if",
    "start": "547640",
    "end": "549880"
  },
  {
    "text": "we want we can also override the server",
    "start": "549880",
    "end": "551920"
  },
  {
    "text": "Target so that the client sends traffic",
    "start": "551920",
    "end": "553680"
  },
  {
    "text": "to another back end if we so wish um but",
    "start": "553680",
    "end": "557560"
  },
  {
    "text": "in any case once the workers have been",
    "start": "557560",
    "end": "559079"
  },
  {
    "text": "set up uh the driver will send a signal",
    "start": "559079",
    "end": "561360"
  },
  {
    "text": "to the client to start sending rpcs to",
    "start": "561360",
    "end": "563200"
  },
  {
    "text": "the server and the client will do just",
    "start": "563200",
    "end": "564920"
  },
  {
    "text": "that so this traffic that's running",
    "start": "564920",
    "end": "566880"
  },
  {
    "text": "between the client and server is the",
    "start": "566880",
    "end": "568600"
  },
  {
    "text": "load that we trying to measure in their",
    "start": "568600",
    "end": "571720"
  },
  {
    "text": "Benchmark the number of rpcs that the",
    "start": "571720",
    "end": "574600"
  },
  {
    "text": "client sends to the server is configured",
    "start": "574600",
    "end": "577079"
  },
  {
    "text": "in terms of a duration of time so for",
    "start": "577079",
    "end": "579800"
  },
  {
    "text": "example I would tell the client in that",
    "start": "579800",
    "end": "581600"
  },
  {
    "text": "Json configuration to send traffic",
    "start": "581600",
    "end": "584399"
  },
  {
    "text": "continuously for say 10 seconds or for",
    "start": "584399",
    "end": "587040"
  },
  {
    "text": "one minute and I can also configure how",
    "start": "587040",
    "end": "589920"
  },
  {
    "text": "many rpcs to send simultaneously so I",
    "start": "589920",
    "end": "592880"
  },
  {
    "text": "can tell the client to send say 10 rpcs",
    "start": "592880",
    "end": "595560"
  },
  {
    "text": "concurrently at once and the client will",
    "start": "595560",
    "end": "597680"
  },
  {
    "text": "have multiple outstanding rpcs",
    "start": "597680",
    "end": "600320"
  },
  {
    "text": "with each RPC the client will record",
    "start": "600320",
    "end": "602240"
  },
  {
    "text": "data points like the latency of that",
    "start": "602240",
    "end": "603959"
  },
  {
    "text": "particular RPC what was the final status",
    "start": "603959",
    "end": "607160"
  },
  {
    "text": "um what was the CPU load it took to",
    "start": "607160",
    "end": "609000"
  },
  {
    "text": "process it and so on and the server is",
    "start": "609000",
    "end": "611480"
  },
  {
    "text": "also going to record similar data on its",
    "start": "611480",
    "end": "614680"
  },
  {
    "text": "end so once the duration of The",
    "start": "614680",
    "end": "617040"
  },
  {
    "text": "Benchmark has expired the driver will",
    "start": "617040",
    "end": "619399"
  },
  {
    "text": "send a signal to all the workers to stop",
    "start": "619399",
    "end": "621360"
  },
  {
    "text": "sending traffic and at this point the",
    "start": "621360",
    "end": "623279"
  },
  {
    "text": "workers will report back all those data",
    "start": "623279",
    "end": "625160"
  },
  {
    "text": "points that they've been collecting over",
    "start": "625160",
    "end": "626959"
  },
  {
    "text": "the lifetime of The Benchmark back to",
    "start": "626959",
    "end": "628440"
  },
  {
    "text": "the driver and the driver will collect",
    "start": "628440",
    "end": "630600"
  },
  {
    "text": "all that data and compute some useful",
    "start": "630600",
    "end": "632760"
  },
  {
    "text": "statistics for us like the what was the",
    "start": "632760",
    "end": "635040"
  },
  {
    "text": "QPS um it'll build out a histogram of",
    "start": "635040",
    "end": "637639"
  },
  {
    "text": "the latencies and and compute a bunch of",
    "start": "637639",
    "end": "640800"
  },
  {
    "text": "averages and so on and then it will",
    "start": "640800",
    "end": "642959"
  },
  {
    "text": "publish that data Downstream to anywhere",
    "start": "642959",
    "end": "645079"
  },
  {
    "text": "that we would like to go and inspect",
    "start": "645079",
    "end": "646720"
  },
  {
    "text": "those results later so it can write to a",
    "start": "646720",
    "end": "648800"
  },
  {
    "text": "database or to logs or wherever we",
    "start": "648800",
    "end": "652519"
  },
  {
    "text": "want so so far we've looked at an",
    "start": "652519",
    "end": "655040"
  },
  {
    "text": "example involving one client in one",
    "start": "655040",
    "end": "657120"
  },
  {
    "text": "server and we can do a lot more stuff",
    "start": "657120",
    "end": "659560"
  },
  {
    "text": "with this QPS framework we can spin up",
    "start": "659560",
    "end": "662200"
  },
  {
    "text": "multiple client and server workers and",
    "start": "662200",
    "end": "664120"
  },
  {
    "text": "have them all send traffic among each",
    "start": "664120",
    "end": "665880"
  },
  {
    "text": "other um we can make each worker",
    "start": "665880",
    "end": "668360"
  },
  {
    "text": "multi-threaded so this would cause each",
    "start": "668360",
    "end": "670560"
  },
  {
    "text": "worker to process rpcs in parallel and",
    "start": "670560",
    "end": "673000"
  },
  {
    "text": "so we can see what happens to our",
    "start": "673000",
    "end": "674360"
  },
  {
    "text": "performance there U we can have each",
    "start": "674360",
    "end": "676800"
  },
  {
    "text": "client open up multiple channels there",
    "start": "676800",
    "end": "679079"
  },
  {
    "text": "words multiple connections to each",
    "start": "679079",
    "end": "680240"
  },
  {
    "text": "server and have it send rpcs on all of",
    "start": "680240",
    "end": "682440"
  },
  {
    "text": "those channels at once and we can also",
    "start": "682440",
    "end": "684880"
  },
  {
    "text": "configure your standard grpc options and",
    "start": "684880",
    "end": "687360"
  },
  {
    "text": "all the workers like if we want to set",
    "start": "687360",
    "end": "689440"
  },
  {
    "text": "any channel arguments or particular",
    "start": "689440",
    "end": "691560"
  },
  {
    "text": "Channel credentials if we want the",
    "start": "691560",
    "end": "693560"
  },
  {
    "text": "workers to be synchronous or",
    "start": "693560",
    "end": "694839"
  },
  {
    "text": "asynchronous and so",
    "start": "694839",
    "end": "697079"
  },
  {
    "text": "on so as maintainers we want to make",
    "start": "697079",
    "end": "699839"
  },
  {
    "text": "sure that we cover all of those possible",
    "start": "699839",
    "end": "702440"
  },
  {
    "text": "different scenarios when we uh monitor",
    "start": "702440",
    "end": "704880"
  },
  {
    "text": "our GPC libraries so what we've done is",
    "start": "704880",
    "end": "708240"
  },
  {
    "text": "we've written a set of tools that will",
    "start": "708240",
    "end": "710880"
  },
  {
    "text": "generate all of those various Benchmark",
    "start": "710880",
    "end": "713120"
  },
  {
    "text": "scenarios for us and pass them over to a",
    "start": "713120",
    "end": "715200"
  },
  {
    "text": "test Runner which will run these",
    "start": "715200",
    "end": "717399"
  },
  {
    "text": "benchmarks continuously on a dedic",
    "start": "717399",
    "end": "719240"
  },
  {
    "text": "dedicated gke cluster and then we will",
    "start": "719240",
    "end": "721360"
  },
  {
    "text": "collect all that data and publish it to",
    "start": "721360",
    "end": "723000"
  },
  {
    "text": "the dashboard which I've linked on this",
    "start": "723000",
    "end": "724600"
  },
  {
    "text": "slide so if you're interested in running",
    "start": "724600",
    "end": "726720"
  },
  {
    "text": "a set of JPC benchmarks for yourself you",
    "start": "726720",
    "end": "729200"
  },
  {
    "text": "can check out the grpc test info repo",
    "start": "729200",
    "end": "731959"
  },
  {
    "text": "where we've open sourced all these tools",
    "start": "731959",
    "end": "734040"
  },
  {
    "text": "that we use for our continuous Benchmark",
    "start": "734040",
    "end": "736399"
  },
  {
    "text": "setup and you can set up your own",
    "start": "736399",
    "end": "738320"
  },
  {
    "text": "kubernetes cluster and run a set of grpc",
    "start": "738320",
    "end": "740600"
  },
  {
    "text": "benchmarks on your own and this is",
    "start": "740600",
    "end": "742560"
  },
  {
    "text": "helpful if you want to experiment with",
    "start": "742560",
    "end": "744480"
  },
  {
    "text": "say different versions of grpc or",
    "start": "744480",
    "end": "746560"
  },
  {
    "text": "different configurations and understand",
    "start": "746560",
    "end": "748839"
  },
  {
    "text": "how that might impact the performance of",
    "start": "748839",
    "end": "751000"
  },
  {
    "text": "your application or if you just want to",
    "start": "751000",
    "end": "753360"
  },
  {
    "text": "understand the role of grpc in the",
    "start": "753360",
    "end": "755760"
  },
  {
    "text": "overall performance profile of your",
    "start": "755760",
    "end": "757760"
  },
  {
    "text": "particular",
    "start": "757760",
    "end": "759680"
  },
  {
    "text": "service and so now I'll hand it over to",
    "start": "759680",
    "end": "761800"
  },
  {
    "text": "AJ who will talk more about some of the",
    "start": "761800",
    "end": "763440"
  },
  {
    "text": "other tests we have and also our",
    "start": "763440",
    "end": "764920"
  },
  {
    "text": "upcoming",
    "start": "764920",
    "end": "765880"
  },
  {
    "text": "features take",
    "start": "765880",
    "end": "768440"
  },
  {
    "text": "away all right thank you Ashley um so",
    "start": "768440",
    "end": "772160"
  },
  {
    "text": "that was a whirlwind tour of our endend",
    "start": "772160",
    "end": "773839"
  },
  {
    "text": "benchmarking system it's a very",
    "start": "773839",
    "end": "775839"
  },
  {
    "text": "important tool that helps us ensure grpc",
    "start": "775839",
    "end": "778320"
  },
  {
    "text": "remains perform perment under many",
    "start": "778320",
    "end": "780720"
  },
  {
    "text": "situations uh we also maintain a small",
    "start": "780720",
    "end": "782839"
  },
  {
    "text": "army of other approaches to Performance",
    "start": "782839",
    "end": "784639"
  },
  {
    "text": "measurement and testing in general in",
    "start": "784639",
    "end": "786639"
  },
  {
    "text": "this next section I've handpicked some",
    "start": "786639",
    "end": "788320"
  },
  {
    "text": "other significant pieces of code and",
    "start": "788320",
    "end": "789880"
  },
  {
    "text": "infrastructure in our core repository to",
    "start": "789880",
    "end": "792279"
  },
  {
    "text": "give you a feel for other ways we",
    "start": "792279",
    "end": "793760"
  },
  {
    "text": "examine and exercise grpc at Google we",
    "start": "793760",
    "end": "797199"
  },
  {
    "text": "use grpc pretty heavily just like you do",
    "start": "797199",
    "end": "799920"
  },
  {
    "text": "um and as Ashley said we understand that",
    "start": "799920",
    "end": "801440"
  },
  {
    "text": "grpc is critical infrastructure so we",
    "start": "801440",
    "end": "803800"
  },
  {
    "text": "aim to tackle performance and",
    "start": "803800",
    "end": "805199"
  },
  {
    "text": "correctness from uh as many perspectives",
    "start": "805199",
    "end": "808160"
  },
  {
    "text": "as we can um we're running a little",
    "start": "808160",
    "end": "810320"
  },
  {
    "text": "short on time I might have to fly",
    "start": "810320",
    "end": "811720"
  },
  {
    "text": "through some slides apologies feel free",
    "start": "811720",
    "end": "813800"
  },
  {
    "text": "to ask questions at the end um all right",
    "start": "813800",
    "end": "817440"
  },
  {
    "text": "to begin with measuring performance is",
    "start": "817440",
    "end": "819160"
  },
  {
    "text": "great but the numbers aren't very useful",
    "start": "819160",
    "end": "820959"
  },
  {
    "text": "if you are oblivious to them this is a",
    "start": "820959",
    "end": "823959"
  },
  {
    "text": "fantastic dashboard in my opinion but",
    "start": "823959",
    "end": "825800"
  },
  {
    "text": "grpc developers spend a good amount of",
    "start": "825800",
    "end": "827800"
  },
  {
    "text": "time working on things that shouldn't",
    "start": "827800",
    "end": "829480"
  },
  {
    "text": "affect performance and we all we don't",
    "start": "829480",
    "end": "832079"
  },
  {
    "text": "all check performance dashboards every",
    "start": "832079",
    "end": "833880"
  },
  {
    "text": "day so we need something to help us",
    "start": "833880",
    "end": "835600"
  },
  {
    "text": "monitor performance and alert us when",
    "start": "835600",
    "end": "837600"
  },
  {
    "text": "regressions occur",
    "start": "837600",
    "end": "839800"
  },
  {
    "text": "luckily we have a continuous profiling",
    "start": "839800",
    "end": "841600"
  },
  {
    "text": "system that runs across Google's Fleet",
    "start": "841600",
    "end": "843480"
  },
  {
    "text": "of machines and we get alerted for",
    "start": "843480",
    "end": "845320"
  },
  {
    "text": "abnormal resource utilization from",
    "start": "845320",
    "end": "847079"
  },
  {
    "text": "binaries that use",
    "start": "847079",
    "end": "848639"
  },
  {
    "text": "grpc sometimes a jump and resource",
    "start": "848639",
    "end": "850680"
  },
  {
    "text": "utilization may be a good thing",
    "start": "850680",
    "end": "852079"
  },
  {
    "text": "indicating some new grpc usage other",
    "start": "852079",
    "end": "854920"
  },
  {
    "text": "times it could be because I wrote some",
    "start": "854920",
    "end": "856600"
  },
  {
    "text": "code that added a few bytes of memory to",
    "start": "856600",
    "end": "858279"
  },
  {
    "text": "every call and a few bytes per call can",
    "start": "858279",
    "end": "860600"
  },
  {
    "text": "be a significant increase at scale when",
    "start": "860600",
    "end": "863440"
  },
  {
    "text": "regressions do occur we have a few tools",
    "start": "863440",
    "end": "865480"
  },
  {
    "text": "that can help us figure out what changed",
    "start": "865480",
    "end": "867480"
  },
  {
    "text": "one powerful combination you can use is",
    "start": "867480",
    "end": "869519"
  },
  {
    "text": "Linux perf and pprof Linux perf is a",
    "start": "869519",
    "end": "872199"
  },
  {
    "text": "standard open source tool available on",
    "start": "872199",
    "end": "873920"
  },
  {
    "text": "most dros that collects and analyzes",
    "start": "873920",
    "end": "876279"
  },
  {
    "text": "various run profile Telemetry like CPU",
    "start": "876279",
    "end": "878639"
  },
  {
    "text": "and memory usage PPR is another open",
    "start": "878639",
    "end": "881199"
  },
  {
    "text": "source tool that helps summarize and",
    "start": "881199",
    "end": "882800"
  },
  {
    "text": "display perer boards I particularly",
    "start": "882800",
    "end": "885320"
  },
  {
    "text": "appreciate the flame graphs of time",
    "start": "885320",
    "end": "886959"
  },
  {
    "text": "spent in each function and system call",
    "start": "886959",
    "end": "888959"
  },
  {
    "text": "you probably can't read it from there",
    "start": "888959",
    "end": "890480"
  },
  {
    "text": "but here we identified that for this",
    "start": "890480",
    "end": "892480"
  },
  {
    "text": "threadpool Benchmark for this one thread",
    "start": "892480",
    "end": "895000"
  },
  {
    "text": "nearly all of the execution time was",
    "start": "895000",
    "end": "896680"
  },
  {
    "text": "spent waiting on various lock",
    "start": "896680",
    "end": "898120"
  },
  {
    "text": "acquisitions finding ways to minimize",
    "start": "898120",
    "end": "900480"
  },
  {
    "text": "that lock contention could speed up our",
    "start": "900480",
    "end": "902399"
  },
  {
    "text": "threadpool execution if it ever becomes",
    "start": "902399",
    "end": "904399"
  },
  {
    "text": "a bottleneck uh this graph was generated",
    "start": "904399",
    "end": "907040"
  },
  {
    "text": "on demand using open source tools on my",
    "start": "907040",
    "end": "908920"
  },
  {
    "text": "development machine it's uh a great",
    "start": "908920",
    "end": "911759"
  },
  {
    "text": "snapshot of a benchmark but being able",
    "start": "911759",
    "end": "913880"
  },
  {
    "text": "to compare performance samples before",
    "start": "913880",
    "end": "915839"
  },
  {
    "text": "and after a regression is invaluable so",
    "start": "915839",
    "end": "918320"
  },
  {
    "text": "running this snapshot regularly is an",
    "start": "918320",
    "end": "920120"
  },
  {
    "text": "important part of our",
    "start": "920120",
    "end": "922000"
  },
  {
    "text": "process moving on micro benchmarks are",
    "start": "922000",
    "end": "924639"
  },
  {
    "text": "intended to exercise smaller pieces of",
    "start": "924639",
    "end": "926519"
  },
  {
    "text": "functionality a huge number of times by",
    "start": "926519",
    "end": "929079"
  },
  {
    "text": "focusing on something small and fast and",
    "start": "929079",
    "end": "930880"
  },
  {
    "text": "cranking up the iteration count we can",
    "start": "930880",
    "end": "933079"
  },
  {
    "text": "see more than whether or not something",
    "start": "933079",
    "end": "934720"
  },
  {
    "text": "is performant we can quickly see if it",
    "start": "934720",
    "end": "936639"
  },
  {
    "text": "is consistently performant for example",
    "start": "936639",
    "end": "939440"
  },
  {
    "text": "we can ask questions like do Benchmark",
    "start": "939440",
    "end": "941279"
  },
  {
    "text": "results vary wildly between iterations",
    "start": "941279",
    "end": "943560"
  },
  {
    "text": "or are they fairly stable does",
    "start": "943560",
    "end": "945680"
  },
  {
    "text": "performance change as The Benchmark",
    "start": "945680",
    "end": "947279"
  },
  {
    "text": "progresses maybe indicating some kind of",
    "start": "947279",
    "end": "949000"
  },
  {
    "text": "warm-up factor or all the results maybe",
    "start": "949000",
    "end": "951600"
  },
  {
    "text": "normally distributed or maybe something",
    "start": "951600",
    "end": "953120"
  },
  {
    "text": "with a heavy tail um looking at",
    "start": "953120",
    "end": "955319"
  },
  {
    "text": "performance at this smaller scale allows",
    "start": "955319",
    "end": "957120"
  },
  {
    "text": "us to home in on hotspots and we use",
    "start": "957120",
    "end": "959480"
  },
  {
    "text": "micro benchmarks across the stack what's",
    "start": "959480",
    "end": "961920"
  },
  {
    "text": "shown here is just a sampling of the",
    "start": "961920",
    "end": "963639"
  },
  {
    "text": "things we look at there are over 100",
    "start": "963639",
    "end": "965720"
  },
  {
    "text": "micro benchmarks in the C+ plus core",
    "start": "965720",
    "end": "967639"
  },
  {
    "text": "library and many more in other",
    "start": "967639",
    "end": "970160"
  },
  {
    "text": "implementations this is one of our",
    "start": "970160",
    "end": "971839"
  },
  {
    "text": "actual benchmarks written using uh",
    "start": "971839",
    "end": "973800"
  },
  {
    "text": "Google's open- Source Benchmark",
    "start": "973800",
    "end": "975480"
  },
  {
    "text": "framework aptly named Benchmark uh this",
    "start": "975480",
    "end": "978639"
  },
  {
    "text": "code measures how quickly C++ alarms can",
    "start": "978639",
    "end": "980959"
  },
  {
    "text": "fire let me walk you through this",
    "start": "980959",
    "end": "982560"
  },
  {
    "text": "example quickly the functionality we're",
    "start": "982560",
    "end": "985279"
  },
  {
    "text": "benchmarking is entirely inside this for",
    "start": "985279",
    "end": "987120"
  },
  {
    "text": "Loop which simply sets a z zero duration",
    "start": "987120",
    "end": "989519"
  },
  {
    "text": "time out on an alarm and pulls the",
    "start": "989519",
    "end": "991199"
  },
  {
    "text": "completion queue until that alarm has",
    "start": "991199",
    "end": "993240"
  },
  {
    "text": "fired and pushed its tag back onto the",
    "start": "993240",
    "end": "995160"
  },
  {
    "text": "queue the way it works is The Benchmark",
    "start": "995160",
    "end": "997560"
  },
  {
    "text": "system provides an iterable State object",
    "start": "997560",
    "end": "1000680"
  },
  {
    "text": "that controls the Benchmark allowing The",
    "start": "1000680",
    "end": "1002680"
  },
  {
    "text": "Benchmark system to determine the",
    "start": "1002680",
    "end": "1004360"
  },
  {
    "text": "iteration count and Benchmark timing uh",
    "start": "1004360",
    "end": "1007279"
  },
  {
    "text": "with command line Flags you can control",
    "start": "1007279",
    "end": "1008839"
  },
  {
    "text": "some of the iteration count Benchmark",
    "start": "1008839",
    "end": "1010720"
  },
  {
    "text": "timing and things of that nature now",
    "start": "1010720",
    "end": "1013079"
  },
  {
    "text": "this is a fairly thing uh trivial thing",
    "start": "1013079",
    "end": "1015079"
  },
  {
    "text": "to Benchmark but we Benchmark this",
    "start": "1015079",
    "end": "1017319"
  },
  {
    "text": "because historically this has been a",
    "start": "1017319",
    "end": "1018959"
  },
  {
    "text": "highly performant operation uh quick",
    "start": "1018959",
    "end": "1021360"
  },
  {
    "text": "show at hands who is familiar with",
    "start": "1021360",
    "end": "1022800"
  },
  {
    "text": "hyrum's",
    "start": "1022800",
    "end": "1024918"
  },
  {
    "text": "law okay we have four sweet you're going",
    "start": "1024919",
    "end": "1027760"
  },
  {
    "text": "to learn something so hyrum's law states",
    "start": "1027760",
    "end": "1030038"
  },
  {
    "text": "that given enough users regardless of",
    "start": "1030039",
    "end": "1032160"
  },
  {
    "text": "whether something is part of your API or",
    "start": "1032160",
    "end": "1033839"
  },
  {
    "text": "not all observable behaviors will be",
    "start": "1033839",
    "end": "1036280"
  },
  {
    "text": "depended on by somebody and the speed of",
    "start": "1036280",
    "end": "1039199"
  },
  {
    "text": "this API has become very important to a",
    "start": "1039199",
    "end": "1041438"
  },
  {
    "text": "few folks so while we don't make any",
    "start": "1041439",
    "end": "1043400"
  },
  {
    "text": "claims or guarantees that this special",
    "start": "1043400",
    "end": "1045319"
  },
  {
    "text": "case will remain performant we do",
    "start": "1045319",
    "end": "1047480"
  },
  {
    "text": "measure it and we do our best",
    "start": "1047480",
    "end": "1049960"
  },
  {
    "text": "uh here is that benchmark's current",
    "start": "1049960",
    "end": "1051240"
  },
  {
    "text": "performance using a simple configuration",
    "start": "1051240",
    "end": "1053039"
  },
  {
    "text": "on my development machine I'm going to",
    "start": "1053039",
    "end": "1055000"
  },
  {
    "text": "skip the rest of this slide um it's very",
    "start": "1055000",
    "end": "1057679"
  },
  {
    "text": "fast okay uh let's switch gears and talk",
    "start": "1057679",
    "end": "1060559"
  },
  {
    "text": "a bit about testing I will skip past the",
    "start": "1060559",
    "end": "1063280"
  },
  {
    "text": "obvious coverage we have for our tens of",
    "start": "1063280",
    "end": "1065120"
  },
  {
    "text": "thousands of unit tests and other end",
    "start": "1065120",
    "end": "1067440"
  },
  {
    "text": "to-end tests and things of that nature",
    "start": "1067440",
    "end": "1069799"
  },
  {
    "text": "uh instead let's skip to something more",
    "start": "1069799",
    "end": "1071240"
  },
  {
    "text": "interesting fuzzing uh for a brief",
    "start": "1071240",
    "end": "1073840"
  },
  {
    "text": "introduction for those who are",
    "start": "1073840",
    "end": "1075000"
  },
  {
    "text": "unfamiliar it's a technique that feeds",
    "start": "1075000",
    "end": "1077200"
  },
  {
    "text": "randomish handwavy randomish uh inputs",
    "start": "1077200",
    "end": "1080280"
  },
  {
    "text": "to your code and lets you assert that",
    "start": "1080280",
    "end": "1081960"
  },
  {
    "text": "the resulting state is as you'd expect",
    "start": "1081960",
    "end": "1083720"
  },
  {
    "text": "it to be uh and you may be surprised to",
    "start": "1083720",
    "end": "1086080"
  },
  {
    "text": "find out that fuzzing has actually",
    "start": "1086080",
    "end": "1087400"
  },
  {
    "text": "improved gpc's performance as well",
    "start": "1087400",
    "end": "1090480"
  },
  {
    "text": "generally to fuzz your code you write a",
    "start": "1090480",
    "end": "1092600"
  },
  {
    "text": "fairly small function that takes",
    "start": "1092600",
    "end": "1094120"
  },
  {
    "text": "interesting inputs for whatever inputs",
    "start": "1094120",
    "end": "1096320"
  },
  {
    "text": "may be interesting to your application",
    "start": "1096320",
    "end": "1098559"
  },
  {
    "text": "and that function then exercises your",
    "start": "1098559",
    "end": "1100200"
  },
  {
    "text": "code altogether this is the system under",
    "start": "1100200",
    "end": "1102159"
  },
  {
    "text": "test your fuzzing engine of choice will",
    "start": "1102159",
    "end": "1104159"
  },
  {
    "text": "then repeatedly create and feed new",
    "start": "1104159",
    "end": "1105799"
  },
  {
    "text": "input to your system under test coverage",
    "start": "1105799",
    "end": "1109080"
  },
  {
    "text": "guided fuzzing is a technique where the",
    "start": "1109080",
    "end": "1110679"
  },
  {
    "text": "engine looks at code coverage from the",
    "start": "1110679",
    "end": "1112559"
  },
  {
    "text": "runs of previous input to make informed",
    "start": "1112559",
    "end": "1115120"
  },
  {
    "text": "decisions on how to best mutate the",
    "start": "1115120",
    "end": "1116960"
  },
  {
    "text": "previous inputs so that the code gets",
    "start": "1116960",
    "end": "1119000"
  },
  {
    "text": "exercised in new ways the idea here is",
    "start": "1119000",
    "end": "1121400"
  },
  {
    "text": "that broadening that coverage is a good",
    "start": "1121400",
    "end": "1123000"
  },
  {
    "text": "way to find problems in your code",
    "start": "1123000",
    "end": "1125600"
  },
  {
    "text": "finally structure aware or grammar aware",
    "start": "1125600",
    "end": "1127919"
  },
  {
    "text": "fuzzing improves the fuzzer ability to",
    "start": "1127919",
    "end": "1129840"
  },
  {
    "text": "increase coverage by guiding the input",
    "start": "1129840",
    "end": "1132120"
  },
  {
    "text": "mut uh mutation process essentially",
    "start": "1132120",
    "end": "1134880"
  },
  {
    "text": "custom mutators are used to ensure that",
    "start": "1134880",
    "end": "1136640"
  },
  {
    "text": "the inputs generated by the fuzzing",
    "start": "1136640",
    "end": "1138240"
  },
  {
    "text": "engine are more meaningful to the",
    "start": "1138240",
    "end": "1141440"
  },
  {
    "text": "application uh with grpc we usually",
    "start": "1141440",
    "end": "1143760"
  },
  {
    "text": "create protos for each system under",
    "start": "1143760",
    "end": "1145559"
  },
  {
    "text": "tests that describe the inputs we want",
    "start": "1145559",
    "end": "1147320"
  },
  {
    "text": "our fuzzer instrumented code to receive",
    "start": "1147320",
    "end": "1150120"
  },
  {
    "text": "um this here is a tiny snippet of one",
    "start": "1150120",
    "end": "1152240"
  },
  {
    "text": "very large fuzzer input definition for",
    "start": "1152240",
    "end": "1154880"
  },
  {
    "text": "our API fuzzer uh for an example of how",
    "start": "1154880",
    "end": "1157559"
  },
  {
    "text": "this works the fuzzing engine can",
    "start": "1157559",
    "end": "1159120"
  },
  {
    "text": "provide any input that creates and",
    "start": "1159120",
    "end": "1161200"
  },
  {
    "text": "closes channels and servers repeatedly",
    "start": "1161200",
    "end": "1163400"
  },
  {
    "text": "in any order the system under test is",
    "start": "1163400",
    "end": "1166000"
  },
  {
    "text": "responsible for taking that input",
    "start": "1166000",
    "end": "1167880"
  },
  {
    "text": "performing the Rel relevant actions",
    "start": "1167880",
    "end": "1169400"
  },
  {
    "text": "wherever meaningful and asserting things",
    "start": "1169400",
    "end": "1171640"
  },
  {
    "text": "that should be true are indeed true",
    "start": "1171640",
    "end": "1173440"
  },
  {
    "text": "based on that input uh depending on what",
    "start": "1173440",
    "end": "1175679"
  },
  {
    "text": "sort of coverage was achieved our lib",
    "start": "1175679",
    "end": "1177360"
  },
  {
    "text": "protuff mutator then helps mutate the",
    "start": "1177360",
    "end": "1179720"
  },
  {
    "text": "input Proto values and feeds that input",
    "start": "1179720",
    "end": "1182120"
  },
  {
    "text": "back to the system for the next run we",
    "start": "1182120",
    "end": "1184919"
  },
  {
    "text": "currently have over 20 different fuzzers",
    "start": "1184919",
    "end": "1186559"
  },
  {
    "text": "running every single day for a large",
    "start": "1186559",
    "end": "1188720"
  },
  {
    "text": "slice of time on a bunch of machines um",
    "start": "1188720",
    "end": "1191440"
  },
  {
    "text": "because of them we have found in fixed",
    "start": "1191440",
    "end": "1193080"
  },
  {
    "text": "security vulnerabilities like the cve",
    "start": "1193080",
    "end": "1195080"
  },
  {
    "text": "listed here uh we found and fixed",
    "start": "1195080",
    "end": "1197520"
  },
  {
    "text": "interesting performance issues most",
    "start": "1197520",
    "end": "1199120"
  },
  {
    "text": "recently being how DNS resolvers behave",
    "start": "1199120",
    "end": "1201840"
  },
  {
    "text": "when you feed them 64,000 service",
    "start": "1201840",
    "end": "1204039"
  },
  {
    "text": "records uh the answer is not great um",
    "start": "1204039",
    "end": "1207520"
  },
  {
    "text": "but we also identified an essential",
    "start": "1207520",
    "end": "1209120"
  },
  {
    "text": "process that could be made lighter",
    "start": "1209120",
    "end": "1210520"
  },
  {
    "text": "weight um and we have many large corpor",
    "start": "1210520",
    "end": "1213080"
  },
  {
    "text": "of inputs that had all caused problems",
    "start": "1213080",
    "end": "1215159"
  },
  {
    "text": "in different ways all of which are now",
    "start": "1215159",
    "end": "1217600"
  },
  {
    "text": "fixed um these inputs are all now tested",
    "start": "1217600",
    "end": "1220240"
  },
  {
    "text": "regularly for regressions and they are",
    "start": "1220240",
    "end": "1222080"
  },
  {
    "text": "used to inform uh mutations for the",
    "start": "1222080",
    "end": "1225080"
  },
  {
    "text": "engine finally I'd like to wrap up with",
    "start": "1225080",
    "end": "1227280"
  },
  {
    "text": "a quick sneak preview of some of the",
    "start": "1227280",
    "end": "1229000"
  },
  {
    "text": "performance oriented projects that we've",
    "start": "1229000",
    "end": "1230840"
  },
  {
    "text": "been working on for the last couple",
    "start": "1230840",
    "end": "1232520"
  },
  {
    "text": "years first in grpc go the http2 uh",
    "start": "1232520",
    "end": "1236640"
  },
  {
    "text": "transport framer library is currently",
    "start": "1236640",
    "end": "1238640"
  },
  {
    "text": "being Rewritten uh the new framer API is",
    "start": "1238640",
    "end": "1241360"
  },
  {
    "text": "based on the idea that we can eliminate",
    "start": "1241360",
    "end": "1243280"
  },
  {
    "text": "most internal buffering and only",
    "start": "1243280",
    "end": "1245400"
  },
  {
    "text": "implement the subset of HTTP 2 that grpc",
    "start": "1245400",
    "end": "1248559"
  },
  {
    "text": "uses uh we're also taking an opportunity",
    "start": "1248559",
    "end": "1251039"
  },
  {
    "text": "to eliminate one or two allocations and",
    "start": "1251039",
    "end": "1252880"
  },
  {
    "text": "buffer copies for every RPC which could",
    "start": "1252880",
    "end": "1255720"
  },
  {
    "text": "result in a significant speed",
    "start": "1255720",
    "end": "1257600"
  },
  {
    "text": "up the grpc C++ library now has a way",
    "start": "1257600",
    "end": "1261280"
  },
  {
    "text": "for applications to take full control of",
    "start": "1261280",
    "end": "1263679"
  },
  {
    "text": "how grpc does a synchronous execution",
    "start": "1263679",
    "end": "1265960"
  },
  {
    "text": "under the hood uh and control how all",
    "start": "1265960",
    "end": "1268679"
  },
  {
    "text": "low-level IO is done this is called the",
    "start": "1268679",
    "end": "1270840"
  },
  {
    "text": "event engine it's a pluggable interface",
    "start": "1270840",
    "end": "1272919"
  },
  {
    "text": "that integrators can use to fully Define",
    "start": "1272919",
    "end": "1275159"
  },
  {
    "text": "those behaviors and adapt them to their",
    "start": "1275159",
    "end": "1277840"
  },
  {
    "text": "environments right uh with this new",
    "start": "1277840",
    "end": "1279600"
  },
  {
    "text": "callback native asynchronous execution",
    "start": "1279600",
    "end": "1281480"
  },
  {
    "text": "system uh we can move away from",
    "start": "1281480",
    "end": "1283360"
  },
  {
    "text": "completion cues internally and as a",
    "start": "1283360",
    "end": "1285279"
  },
  {
    "text": "result we have a necessary component for",
    "start": "1285279",
    "end": "1287520"
  },
  {
    "text": "a faster public callback",
    "start": "1287520",
    "end": "1290400"
  },
  {
    "text": "API uh finally grpc C++ is also",
    "start": "1290400",
    "end": "1293720"
  },
  {
    "text": "undergoing an internal refactoring to a",
    "start": "1293720",
    "end": "1295720"
  },
  {
    "text": "promise based filter stack it is heavily",
    "start": "1295720",
    "end": "1298039"
  },
  {
    "text": "inspired by rust Asing model um it's",
    "start": "1298039",
    "end": "1300600"
  },
  {
    "text": "also a template heavy refractor so it",
    "start": "1300600",
    "end": "1303039"
  },
  {
    "text": "lets us make fewer indirect calls",
    "start": "1303039",
    "end": "1304919"
  },
  {
    "text": "resulting in more efficient code",
    "start": "1304919",
    "end": "1306240"
  },
  {
    "text": "execution it brings significant decrease",
    "start": "1306240",
    "end": "1308520"
  },
  {
    "text": "in memory usage for every RPC um and it",
    "start": "1308520",
    "end": "1311679"
  },
  {
    "text": "eliminates the need for a handful of",
    "start": "1311679",
    "end": "1313240"
  },
  {
    "text": "mutex locks we have today um early",
    "start": "1313240",
    "end": "1316000"
  },
  {
    "text": "performance results are very promising",
    "start": "1316000",
    "end": "1317600"
  },
  {
    "text": "but the numbers are a bit too fresh to",
    "start": "1317600",
    "end": "1319760"
  },
  {
    "text": "share at the moment and we can expect to",
    "start": "1319760",
    "end": "1321720"
  },
  {
    "text": "reap the rewards later this year so to",
    "start": "1321720",
    "end": "1324720"
  },
  {
    "text": "sum it up um these are Big areas of",
    "start": "1324720",
    "end": "1326960"
  },
  {
    "text": "investment for us we hope this talk gave",
    "start": "1326960",
    "end": "1329000"
  },
  {
    "text": "you a bit of insight into what we do and",
    "start": "1329000",
    "end": "1331240"
  },
  {
    "text": "a bit more confidence in choosing grpc",
    "start": "1331240",
    "end": "1333480"
  },
  {
    "text": "for your stack um that's all for us",
    "start": "1333480",
    "end": "1336600"
  },
  {
    "text": "thank you for your time and uh please",
    "start": "1336600",
    "end": "1338600"
  },
  {
    "text": "let me know if there's any questions",
    "start": "1338600",
    "end": "1342520"
  },
  {
    "text": "oh one second microphone",
    "start": "1351360",
    "end": "1354799"
  },
  {
    "text": "coming are the data uh you showed on the",
    "start": "1354799",
    "end": "1357320"
  },
  {
    "text": "slide available for us to",
    "start": "1357320",
    "end": "1360480"
  },
  {
    "text": "review yeah we have a link to the the",
    "start": "1360480",
    "end": "1364159"
  },
  {
    "text": "dashboard sorry yeah go ahead um it's on",
    "start": "1364159",
    "end": "1368279"
  },
  {
    "text": "here let's see okay there uh up in the",
    "start": "1368279",
    "end": "1371200"
  },
  {
    "text": "top left I hope you can see that bit.",
    "start": "1371200",
    "end": "1374279"
  },
  {
    "text": "jpon 2024 Benchmark Das so this this is",
    "start": "1374279",
    "end": "1378720"
  },
  {
    "text": "this dashboard is available online",
    "start": "1378720",
    "end": "1380520"
  },
  {
    "text": "publicly for anyone um in or out of",
    "start": "1380520",
    "end": "1382840"
  },
  {
    "text": "Google to view uh and so this just",
    "start": "1382840",
    "end": "1385320"
  },
  {
    "text": "contains like data from all the",
    "start": "1385320",
    "end": "1386880"
  },
  {
    "text": "continuous runs of our uh The grpc",
    "start": "1386880",
    "end": "1389720"
  },
  {
    "text": "Benchmark framework that we' built",
    "start": "1389720",
    "end": "1391240"
  },
  {
    "text": "specifically for measuring like these",
    "start": "1391240",
    "end": "1393880"
  },
  {
    "text": "statistics of the JPC libraries so you",
    "start": "1393880",
    "end": "1396360"
  },
  {
    "text": "can take a look yeah I hope that uh",
    "start": "1396360",
    "end": "1399400"
  },
  {
    "text": "works if not there's another slide where",
    "start": "1399400",
    "end": "1401159"
  },
  {
    "text": "I've included like the direct Ur to that",
    "start": "1401159",
    "end": "1405159"
  },
  {
    "text": "dashboard if you search the um grpc doio",
    "start": "1405159",
    "end": "1408559"
  },
  {
    "text": "blog as well there are going to be links",
    "start": "1408559",
    "end": "1410360"
  },
  {
    "text": "there and a bit of documentation on how",
    "start": "1410360",
    "end": "1412320"
  },
  {
    "text": "this was",
    "start": "1412320",
    "end": "1414639"
  },
  {
    "text": "created all right suppose that's all uh",
    "start": "1415600",
    "end": "1419080"
  },
  {
    "text": "thank you all",
    "start": "1419080",
    "end": "1422360"
  }
]
[
  {
    "start": "0",
    "end": "58000"
  },
  {
    "text": "how you doing everybody can I hear a good come on all right yeah let's get some life in",
    "start": "719",
    "end": "8880"
  },
  {
    "text": "here so uh we're going to tell you a little bit about our journey into",
    "start": "8880",
    "end": "14000"
  },
  {
    "text": "kubernetes and how we went from learning it learning how to pronounce it to production in about 3 months time or so",
    "start": "14000",
    "end": "21320"
  },
  {
    "text": "uh we're from golf now which is a branch of Golf Channel which is also a branch",
    "start": "21320",
    "end": "27240"
  },
  {
    "text": "of NBC Sports and it keeps going from there and I'm you all those details um so who are we I am Sharie Muhammad",
    "start": "27240",
    "end": "35440"
  },
  {
    "text": "director of architecture on golf now been with company seven years actually today is my seven year",
    "start": "35440",
    "end": "42960"
  },
  {
    "text": "anniversary yeah there you go thank you Josh Chandler uh senior software",
    "start": "42960",
    "end": "50960"
  },
  {
    "text": "engineer on architecture team as well he's been two plus years about so yeah",
    "start": "50960",
    "end": "58559"
  },
  {
    "text": "so what do we do at golf now we are an Ecommerce platform uh for tea times we",
    "start": "58559",
    "end": "67720"
  },
  {
    "text": "do T we sell tea times for military things like that for nice discounts",
    "start": "67720",
    "end": "72799"
  },
  {
    "text": "obviously for them uh we have our counterparts in the EUR in Europe called te off times we also have a Groupon like",
    "start": "72799",
    "end": "81200"
  },
  {
    "text": "uh application called deal caddy to sell um golf clubs gloves things like that uh",
    "start": "81200",
    "end": "89439"
  },
  {
    "text": "we also have help with operations point of sale for the golf courses uh electronic t- sheets we help courses",
    "start": "89439",
    "end": "97200"
  },
  {
    "text": "that are Mom and Pop shops all the way up to Resorts um with uh their operations there we also offer services",
    "start": "97200",
    "end": "105719"
  },
  {
    "text": "like um phone answering Services 247365 um we also help them with bulk",
    "start": "105719",
    "end": "113079"
  },
  {
    "text": "purchasing of their products things like that we basically the focus of our",
    "start": "113079",
    "end": "118560"
  },
  {
    "text": "services is really to get the golf pros out in front of uh the customers that are actually there that are about to",
    "start": "118560",
    "end": "124520"
  },
  {
    "text": "golf and tea off um so we've been growing like crazy we've I think bought",
    "start": "124520",
    "end": "131280"
  },
  {
    "text": "about 10 companies or so in the past couple of years so it's been it's been",
    "start": "131280",
    "end": "136400"
  },
  {
    "text": "awesome so that takes us into growth is awesome right we're making tons of money",
    "start": "136400",
    "end": "141599"
  },
  {
    "text": "you've got people popping up from anywhere and everywhere even from places you don't even realize you would have um",
    "start": "141599",
    "end": "150319"
  },
  {
    "text": "and everybody's high-fiving each other sales team is like yeah we're killing it and everything and it's great however on",
    "start": "150319",
    "end": "157239"
  },
  {
    "text": "the technology side we're thinking wait a second growth is hard we got to deal",
    "start": "157239",
    "end": "163560"
  },
  {
    "text": "with um 20 plus second page load times making sure our website is up and",
    "start": "163560",
    "end": "170599"
  },
  {
    "text": "running um our infrastructure is getting hammered things like that um sleepless",
    "start": "170599",
    "end": "178120"
  },
  {
    "text": "nights of course um so with all that we actually went",
    "start": "178120",
    "end": "183599"
  },
  {
    "text": "through a lot of redesigning our code we had a lot of issues with our code um",
    "start": "183599",
    "end": "188799"
  },
  {
    "text": "store procedures not being very efficient so we fixed a lot of that stuff so a few months after that uh",
    "start": "188799",
    "end": "194799"
  },
  {
    "text": "Steve are uh sitting around in the corner over there um vpf technology comes to me he says I want you to make a",
    "start": "194799",
    "end": "202000"
  },
  {
    "text": "platform that is goo based and if a data center goes down user doesn't notice go",
    "start": "202000",
    "end": "208040"
  },
  {
    "text": "I'm like all right awesome yeah we can do that our problem and then a few seconds later it kind of sunk in I'm like wait a second what what do I got to",
    "start": "208040",
    "end": "216599"
  },
  {
    "text": "do and just kind of calm down from there realize all right well what were our pain points why did he ask to do this",
    "start": "216599",
    "end": "223799"
  },
  {
    "text": "why do we want to do this we just fixed a ton of code right but we were still growing there's still a lot coming down",
    "start": "223799",
    "end": "230360"
  },
  {
    "text": "the pipe for us and we needed to do something else we needed to learn how we",
    "start": "230360",
    "end": "236720"
  },
  {
    "text": "could scale in a much more efficient way so we could actually sleep cuz we went for about 2 to 3 years 4 years or so not",
    "start": "236720",
    "end": "243920"
  },
  {
    "text": "sleeping at night when our uh infrastructure was getting hit pretty hard",
    "start": "243920",
    "end": "250000"
  },
  {
    "start": "248000",
    "end": "296000"
  },
  {
    "text": "so the lay of the land of when we started um looked a little bit like this where we were West Coast Data Center",
    "start": "250000",
    "end": "257600"
  },
  {
    "text": "only then we had a Dr over on the east coast and then we had a one-way data",
    "start": "257600",
    "end": "263440"
  },
  {
    "text": "sync that would happen every 15 minutes or so and it was great but the problem",
    "start": "263440",
    "end": "269120"
  },
  {
    "text": "was is that we we'd have to build an identical data center so that means double the cost double the time of",
    "start": "269120",
    "end": "276639"
  },
  {
    "text": "deployment double the time of test then it's become a reactive thing not a proactive thing so if the data center on",
    "start": "276639",
    "end": "283639"
  },
  {
    "text": "the west goes down we have to scramble for a couple hours or whatever the case may be to make sure East is",
    "start": "283639",
    "end": "290199"
  },
  {
    "text": "okay um so that was at least delay of our",
    "start": "290199",
    "end": "296000"
  },
  {
    "start": "296000",
    "end": "415000"
  },
  {
    "text": "infrastructure then our application it was a monologue it was the textbook",
    "start": "296000",
    "end": "301440"
  },
  {
    "text": "example of reusability that you learn in computer science um so it shared",
    "start": "301440",
    "end": "309000"
  },
  {
    "text": "everything the problem with sharing everything is that when we made a change as you all know it would Ripple be a",
    "start": "309000",
    "end": "315320"
  },
  {
    "text": "huge ripple effect across everything in all our systems which means we'd have to test everything all the time all over",
    "start": "315320",
    "end": "322319"
  },
  {
    "text": "again free release which means our Cadence for releases were a lot slower",
    "start": "322319",
    "end": "327680"
  },
  {
    "text": "so from there we knew that we needed to break it apart so we wanted to go towards more",
    "start": "327680",
    "end": "333960"
  },
  {
    "text": "microservice architecture of course we wanted to be able to when something goes",
    "start": "333960",
    "end": "339360"
  },
  {
    "text": "down and yes I made it a database we wanted where something went down it would just heal",
    "start": "339360",
    "end": "345360"
  },
  {
    "text": "itself and if we had a lot a lot of hits coming against us we wanted to be able",
    "start": "345360",
    "end": "350960"
  },
  {
    "text": "to Auto scale on its own so we wanted it to kind of know our infrastructure and our traffic structure so that it um Auto",
    "start": "350960",
    "end": "358440"
  },
  {
    "text": "scale for us so at this point after kind of knowing at a high level what direction we wanted",
    "start": "358440",
    "end": "364919"
  },
  {
    "text": "to go we knew that we wanted to go containers um Docker and all these",
    "start": "364919",
    "end": "371599"
  },
  {
    "text": "things but the problem was containers and Docker were great at a local level",
    "start": "371599",
    "end": "376919"
  },
  {
    "text": "uh Dev machine Josh and I passing containers back and forth it was awesome made things a lot easier in that sense",
    "start": "376919",
    "end": "384080"
  },
  {
    "text": "however we had a lot of questions how is this going to go to production how will this scale how are we going to schedule",
    "start": "384080",
    "end": "391000"
  },
  {
    "text": "this how do we make this so that we don't have to deal with waking up to make sure a pot is always running so we",
    "start": "391000",
    "end": "399360"
  },
  {
    "text": "did a lot of research a lot of things we looked at were uh panamax Fleet",
    "start": "399360",
    "end": "406560"
  },
  {
    "text": "swarm um what's another one de deis yeah we looked at a couple different ones",
    "start": "406560",
    "end": "413199"
  },
  {
    "text": "mezos spere actually in dcos but then we stumbled on this thing called cber",
    "start": "413199",
    "end": "418280"
  },
  {
    "start": "415000",
    "end": "797000"
  },
  {
    "text": "something or other and we were like okay this seems kind of promising and at this point when we",
    "start": "418280",
    "end": "425120"
  },
  {
    "text": "discovered kubernetes this was about think September of last year it was a",
    "start": "425120",
    "end": "430160"
  },
  {
    "text": "1.04 five uh version and we realized that this is",
    "start": "430160",
    "end": "436479"
  },
  {
    "text": "probably the direction we want to go we were really heavy on mezos we were about to go in that direction however we",
    "start": "436479",
    "end": "444160"
  },
  {
    "text": "noticed that it wasn't as easy for us to be able to put it in different Cloud providers if we wanted to we were pretty",
    "start": "444160",
    "end": "450319"
  },
  {
    "text": "much stuck in AWS at least at that time we were pretty much stuck in AWS with dcos so we wanted to be able to make it",
    "start": "450319",
    "end": "457039"
  },
  {
    "text": "so that we could go in GCE AWS private wherever and kubernetes kind of gave us",
    "start": "457039",
    "end": "464520"
  },
  {
    "text": "that light it gave us uh that ability and we kind of shifted gears from there",
    "start": "464520",
    "end": "471039"
  },
  {
    "text": "and exactly around that time we um had this uh",
    "start": "471039",
    "end": "477159"
  },
  {
    "text": "battle between kubernetes and Cloud Foundry um we kind of were tasked with",
    "start": "477159",
    "end": "484360"
  },
  {
    "text": "okay go ahead and build out a kubernetes cluster and another team was building",
    "start": "484360",
    "end": "489759"
  },
  {
    "text": "out a cloud Foundry cluster to kind of see at the end of about 3 months or so",
    "start": "489759",
    "end": "496159"
  },
  {
    "text": "what is going to be more production ready how can we use it and things like that so as we were going through this",
    "start": "496159",
    "end": "504240"
  },
  {
    "text": "journey we realized towards I don't know two and a half months or so into it",
    "start": "504240",
    "end": "510479"
  },
  {
    "text": "Cloud fund rate wasn't going to work for us for our particular use cases and the way we wanted to use it we wanted it to",
    "start": "510479",
    "end": "515800"
  },
  {
    "text": "be able to run Docker because we had already containerized and dockerized a couple of our applications as it was at",
    "start": "515800",
    "end": "522159"
  },
  {
    "text": "that time and um we wanted to actually go a level deeper and containerize our data",
    "start": "522159",
    "end": "529519"
  },
  {
    "text": "tier um which was crazy at the time but we wanted everything to be the same",
    "start": "529519",
    "end": "536560"
  },
  {
    "text": "essentially um so at the end of the 3 months uh we had a production ready",
    "start": "536560",
    "end": "542640"
  },
  {
    "text": "pretty much kubernetes cluster and um that's when Steve came to us and was",
    "start": "542640",
    "end": "548839"
  },
  {
    "text": "like okay great PLC that's awesome but let's now put your money where your mouth is and let's start doing something",
    "start": "548839",
    "end": "554760"
  },
  {
    "text": "real now um so it took us to this point where we had bought a company called T leader",
    "start": "554760",
    "end": "561160"
  },
  {
    "text": "that was going towards this uh micr service architecture using node.js mongod DB um so it was kind of going in",
    "start": "561160",
    "end": "568600"
  },
  {
    "text": "the direction that we wanted to go to any anyway um but it was all running on",
    "start": "568600",
    "end": "575160"
  },
  {
    "text": "Heroku compos and a bunch of other thirdparty services for the data tier",
    "start": "575160",
    "end": "580320"
  },
  {
    "text": "and everything like that um so it was a perfect candidate for us to uh bring",
    "start": "580320",
    "end": "585640"
  },
  {
    "text": "over into our new platform that we were building so I'm very competitive and a little",
    "start": "585640",
    "end": "593839"
  },
  {
    "text": "crazy I guess and I wanted to prove that this new platform is definitely the way",
    "start": "593839",
    "end": "599480"
  },
  {
    "text": "want to go and it's the wave of the future for us so I wanted to prove that",
    "start": "599480",
    "end": "605839"
  },
  {
    "text": "we can do this in the middle of peak hours um when we're actually making",
    "start": "605839",
    "end": "611839"
  },
  {
    "text": "money on the on the system and start with the database first um so kind of got a little bit of",
    "start": "611839",
    "end": "619560"
  },
  {
    "text": "push back on that but Steve trusted us and and uh he went with us so we ended",
    "start": "619560",
    "end": "624680"
  },
  {
    "text": "up moving the databases one at a time over about a week span",
    "start": "624680",
    "end": "630160"
  },
  {
    "text": "um obviously when we CH when we moved one we make sure everything was running let it run for a couple days and then",
    "start": "630160",
    "end": "635680"
  },
  {
    "text": "moved the next and so on so it took us about a week or so and nobody noticed",
    "start": "635680",
    "end": "641639"
  },
  {
    "text": "which was awesome obviously the only person that really knew really the two of us and a couple other Engineers that",
    "start": "641639",
    "end": "646760"
  },
  {
    "text": "worked with us and uh Steve because we had to tell him obviously um so we kept",
    "start": "646760",
    "end": "651839"
  },
  {
    "text": "gaining confidence kept going from there started moving our rabbit mq queuing",
    "start": "651839",
    "end": "657040"
  },
  {
    "text": "service um our redis and just kept going from there and in about I think it was like a two to 3",
    "start": "657040",
    "end": "664120"
  },
  {
    "text": "week time frame we moved the entire infrastructure that was running third party SAS over into our uh new platform",
    "start": "664120",
    "end": "672480"
  },
  {
    "text": "that's actually running in uh GC and no not GK because I've had that question",
    "start": "672480",
    "end": "677839"
  },
  {
    "text": "many times um so life was good at that point",
    "start": "677839",
    "end": "685040"
  },
  {
    "text": "um but that didn't really solve the complete um requirement that was was given to us at the beginning so this was",
    "start": "685040",
    "end": "691480"
  },
  {
    "text": "just proving out that we could have these different clusters all all around the world so we had this in one data",
    "start": "691480",
    "end": "696839"
  },
  {
    "text": "center then now we had to get into designing how would we geographically",
    "start": "696839",
    "end": "702560"
  },
  {
    "text": "distribute all this data now obviously we could go to easy way and use uh",
    "start": "702560",
    "end": "708519"
  },
  {
    "text": "Mongo's replica sets across the globe and let it do it s from there and we'd",
    "start": "708519",
    "end": "713600"
  },
  {
    "text": "be done however we didn't want to marry ourselves to one particular data store",
    "start": "713600",
    "end": "718959"
  },
  {
    "text": "because because everything changes and it's constantly going and moving forward and we want to be able to move forward with it we don't want to be stuck",
    "start": "718959",
    "end": "725360"
  },
  {
    "text": "anywhere so we needed to devise a different way of moving all this data",
    "start": "725360",
    "end": "730399"
  },
  {
    "text": "around so what we came up with was let's put Kafka on top of all of this let's",
    "start": "730399",
    "end": "737920"
  },
  {
    "text": "have a service that can watch the oplog on whatever data store that we use and",
    "start": "737920",
    "end": "744199"
  },
  {
    "text": "basically take that oplog and push it up to Kafka",
    "start": "744199",
    "end": "749760"
  },
  {
    "text": "and then from there we could use uh mirror maker and move all the",
    "start": "749760",
    "end": "755440"
  },
  {
    "text": "operational logs basically all over the globe all over to the different data centers that need that data that who",
    "start": "755440",
    "end": "761800"
  },
  {
    "text": "does not have that data because the data originates from a particular Data Center and then has to move across to the",
    "start": "761800",
    "end": "768160"
  },
  {
    "text": "others so with this we're able to now keep everything eventually consistent",
    "start": "768160",
    "end": "775000"
  },
  {
    "text": "which is what a lot of the data stores do for us anyway and then the beauty of it is as well is that we can go and",
    "start": "775000",
    "end": "781720"
  },
  {
    "text": "change a database engine in anyone data uh data center if we wanted to although it's probably not recommended to do so",
    "start": "781720",
    "end": "788279"
  },
  {
    "text": "but if we wanted to we could as long as we change that service that's interacting with the database um we",
    "start": "788279",
    "end": "794959"
  },
  {
    "text": "should be fine from there and I'm going to pass it over to Josh now to talk to you guys a little",
    "start": "794959",
    "end": "801639"
  },
  {
    "start": "797000",
    "end": "919000"
  },
  {
    "text": "bit about our software development life cycle hi everybody I uh recently came down with the presenter flu so apologies",
    "start": "801639",
    "end": "809880"
  },
  {
    "text": "for that um so after you know day two of coupon I'm sure this is going to be kind",
    "start": "809880",
    "end": "816040"
  },
  {
    "text": "of a familiar workflow to most of you but uh we'll just walk through this very briefly so you know the life cycle",
    "start": "816040",
    "end": "821360"
  },
  {
    "text": "starts of course with any engineer and wants to make any kind of change to anything in fact you'll probably see some of these messages popping up uh as",
    "start": "821360",
    "end": "827600"
  },
  {
    "text": "we go through our demo which we're going to do in a second um as soon as somebody pushes to GitHub we have a set of web",
    "start": "827600",
    "end": "833720"
  },
  {
    "text": "hooks back there that uh allow that code to be pushed uh to our cicd pipeline in this",
    "start": "833720",
    "end": "841800"
  },
  {
    "text": "case we're using jenin in fact we use Jenkin as sort of a hive mine for our deployment infrastructure um as you'll",
    "start": "841800",
    "end": "847880"
  },
  {
    "text": "see in just a minute jenkin's first order operation is to build that code and do an automated",
    "start": "847880",
    "end": "854560"
  },
  {
    "text": "test whatever that may be uh npm build or I'm sorry npm install go build run",
    "start": "854560",
    "end": "861480"
  },
  {
    "text": "the automated test and make sure it succeeds if in fact it does then we'll have a Docker build and it will deploy",
    "start": "861480",
    "end": "868240"
  },
  {
    "text": "straight out to key. our uh container repository and then on the completion of",
    "start": "868240",
    "end": "875160"
  },
  {
    "text": "that operation we'll push that out to a staging kubernetes instance that we have",
    "start": "875160",
    "end": "880880"
  },
  {
    "text": "um after that's done we'll have Jenkins file a ticket on",
    "start": "880880",
    "end": "886160"
  },
  {
    "text": "our ticket tracking system jira which will inform a QA engineer hey go check this out we just made a",
    "start": "886160",
    "end": "893480"
  },
  {
    "text": "change so they'll be informed as such they'll interface with that code out there in the qaq kubernetes cluster",
    "start": "893480",
    "end": "899839"
  },
  {
    "text": "they'll sign off on the ticket that pushes back um two Jenkins that hey",
    "start": "899839",
    "end": "905399"
  },
  {
    "text": "mission complete and then we will roll that out to production kubernetes cluster currently we have it at a push",
    "start": "905399",
    "end": "911920"
  },
  {
    "text": "of a button we could make this automated if we wanted to it doesn't really matter we're just kind of trying to uh get things off the",
    "start": "911920",
    "end": "919160"
  },
  {
    "start": "919000",
    "end": "1280000"
  },
  {
    "text": "ground so with that I'm going to show a very brief CI",
    "start": "919160",
    "end": "925480"
  },
  {
    "text": "demo all right so just to kind of show you what we're working with here uh we wrote a little",
    "start": "927560",
    "end": "933880"
  },
  {
    "text": "toy application called Toy Box oh so sorry thank",
    "start": "933880",
    "end": "939759"
  },
  {
    "text": "you there we go this there really not much to toy box it's a toy it um really",
    "start": "944880",
    "end": "951880"
  },
  {
    "text": "just counts hits that's what you see here so every time you go to the page it'll count a hit and log it back um",
    "start": "951880",
    "end": "960000"
  },
  {
    "text": "and of course you can see we've got all that uh you know version history and stuff like that we have that this is QA",
    "start": "960000",
    "end": "965399"
  },
  {
    "text": "in fact we have two builds of this one is running in our staging instance the other one is running in our production infrastructure it's the exact same",
    "start": "965399",
    "end": "972480"
  },
  {
    "text": "code and it does the exact same thing before I get into the demo I just",
    "start": "972480",
    "end": "977720"
  },
  {
    "text": "kind of wanted to give you an overview of what this Jenkins stuff looks like so we kind of haven't gone the whole jenin",
    "start": "977720",
    "end": "983040"
  },
  {
    "text": "file route yet we did just recently up version to Jenkins 2 um and we are using Pipelines",
    "start": "983040",
    "end": "989120"
  },
  {
    "text": "but we kind of got things distilled down to a whole just tell me kind of what you",
    "start": "989120",
    "end": "994240"
  },
  {
    "text": "want want to interface with a cluster okay great here's your configuration for it um we have things about the tooling",
    "start": "994240",
    "end": "1000560"
  },
  {
    "text": "that you need to build out things uh environments that you want to use Source Control Management one day maybe we",
    "start": "1000560",
    "end": "1006800"
  },
  {
    "text": "won't be on git um we may want to change that over so we've done this and flattened this view out across most of",
    "start": "1006800",
    "end": "1013199"
  },
  {
    "text": "our build properties and it's worked out very very well for us we're really happy with it by and large",
    "start": "1013199",
    "end": "1020120"
  },
  {
    "text": "so with that let's start our demo which again is hiding off",
    "start": "1020240",
    "end": "1028038"
  },
  {
    "text": "screen so Toy Box isn't great because what if I were to",
    "start": "1031679",
    "end": "1039438"
  },
  {
    "text": "say hit it with some process that could generate thousands and thousands of requests a second and that wouldn't be",
    "start": "1039760",
    "end": "1046000"
  },
  {
    "text": "very good or very true so uh what I'm going to do to that end is first",
    "start": "1046000",
    "end": "1053640"
  },
  {
    "text": "switch to our QA cluster sorry I can't",
    "start": "1054240",
    "end": "1061360"
  },
  {
    "text": "type let's do 20 so if we flashback the application as",
    "start": "1061360",
    "end": "1068720"
  },
  {
    "text": "this pod start to spin up I just scaled up this requester module it's just making essentially curls against it over",
    "start": "1068720",
    "end": "1074000"
  },
  {
    "text": "and over again and you'll see that the traffic is kind of spiraling out of control and that's not very good just to",
    "start": "1074000",
    "end": "1080240"
  },
  {
    "text": "up the Annie on that too um I'm going to do the exact same thing in production because demo Gremlins you",
    "start": "1080240",
    "end": "1087520"
  },
  {
    "text": "know never happen and it would also kind of be nice to see um what transpires",
    "start": "1087520",
    "end": "1094200"
  },
  {
    "text": "when we uh do this roll",
    "start": "1094200",
    "end": "1098240"
  },
  {
    "text": "out okay so the thing I'm going to do here is put in some redice and that's",
    "start": "1101159",
    "end": "1106720"
  },
  {
    "text": "going to be it to do some rate limiting over the top it's one thing that we really really like about our microservice architecture and so far as",
    "start": "1106720",
    "end": "1111880"
  },
  {
    "text": "everything is so easy so smooth in fact when I wrote this out in the first place before I did all this syntactic sugar",
    "start": "1111880",
    "end": "1117520"
  },
  {
    "text": "over the top of this process um it really took five minutes to put it all together which is something I don't think we could say for our traditional",
    "start": "1117520",
    "end": "1124120"
  },
  {
    "text": "um monolithic builds so this is just a simple happy JS server I'm going to",
    "start": "1124120",
    "end": "1129320"
  },
  {
    "text": "change the version to two I'm going to add",
    "start": "1129320",
    "end": "1133799"
  },
  {
    "text": "it commit and I'm going to push it",
    "start": "1135039",
    "end": "1140159"
  },
  {
    "text": "so one thing I neglected to mention looking at that Jenkins config is we very meticulously log our CI uh",
    "start": "1140159",
    "end": "1145919"
  },
  {
    "text": "everything that happens in that process we're looking over it the entire time",
    "start": "1145919",
    "end": "1152280"
  },
  {
    "text": "um once that web hook actually picks up you're going to start seeing the messages coming through here that it's",
    "start": "1152280",
    "end": "1157960"
  },
  {
    "text": "actually doing its build and there it goes um we have kind of moved away from",
    "start": "1157960",
    "end": "1165919"
  },
  {
    "text": "actually talking to Jenkins directly uh So lately we've been kind of getting into the whole chat Ops thing and building out Bots um and in fact instead",
    "start": "1165919",
    "end": "1173480"
  },
  {
    "text": "of going into Jenkins to finish this all out I'm going to talk to our bot his name is Rick Jenkins and uh he is",
    "start": "1173480",
    "end": "1179919"
  },
  {
    "text": "essentially our interface into um Jenkins itself uh and I'll talk a little more",
    "start": "1179919",
    "end": "1185679"
  },
  {
    "text": "about where he came from here in just a minute but that build is completed I'm skipping over a couple of things hand",
    "start": "1185679",
    "end": "1191559"
  },
  {
    "text": "waving oh so sorry again my apologies",
    "start": "1191559",
    "end": "1200120"
  },
  {
    "text": "so all that stuff I just said repeat this is our logging process right now really very intense",
    "start": "1200120",
    "end": "1209320"
  },
  {
    "text": "um so here's our bot so I'm going to tell the bot to please deploy the build",
    "start": "1209600",
    "end": "1215919"
  },
  {
    "text": "for can iio Toy",
    "start": "1215919",
    "end": "1221480"
  },
  {
    "text": "Box oh he didn't understand although it's probably",
    "start": "1221480",
    "end": "1227640"
  },
  {
    "text": "because so far away there we",
    "start": "1227640",
    "end": "1232000"
  },
  {
    "text": "go and spelling is not my strong",
    "start": "1232760",
    "end": "1237039"
  },
  {
    "text": "suit so there he goes um you look over here at toy box you'll",
    "start": "1238559",
    "end": "1245520"
  },
  {
    "text": "notice the request traffic is really tailed off the deployment happened to the QA cluster just like that",
    "start": "1245520",
    "end": "1252559"
  },
  {
    "text": "and commensurately you're going to see the exact same thing over here on the production Edition we're taking a whole",
    "start": "1252559",
    "end": "1258600"
  },
  {
    "text": "whole lot of flack right now a lot of traffic as the the rolling update occurs but give it a little bit of time and",
    "start": "1258600",
    "end": "1264440"
  },
  {
    "text": "suddenly we get this super cool Edition instead the exact same here same thing here for",
    "start": "1264440",
    "end": "1270919"
  },
  {
    "start": "1280000",
    "end": "1473000"
  },
  {
    "text": "QA so before I let take back over okay um I",
    "start": "1281919",
    "end": "1287159"
  },
  {
    "text": "was going to talk about some of those supporting application infrastructure um when we came into this you know we as",
    "start": "1287159",
    "end": "1293080"
  },
  {
    "text": "Shar mentioned um we inherited that company T leader and they came from Heroku heroku's got all of its nice uh",
    "start": "1293080",
    "end": "1299279"
  },
  {
    "text": "features and things like that so we kind of wanted to get those things off the ground in kubernetes as well um one of",
    "start": "1299279",
    "end": "1304960"
  },
  {
    "text": "the first things we did was a higher fire equivalent called that we call quison um which is essentially",
    "start": "1304960",
    "end": "1310720"
  },
  {
    "text": "responsible for monitoring cues and modering rabbit mqq their sizes and then",
    "start": "1310720",
    "end": "1316279"
  },
  {
    "text": "uh scaling them up when time comes so we have settings that are quite a bit like higher fire and so far as that",
    "start": "1316279",
    "end": "1323760"
  },
  {
    "text": "goes we use pingdom a lot internally uh to monitor our applications we wanted a",
    "start": "1323760",
    "end": "1329320"
  },
  {
    "text": "way to look at things like mongodb and elastic search um semantically so",
    "start": "1329320",
    "end": "1334840"
  },
  {
    "text": "instead of just saying you know can I get to this thing can I do DNS lookup it's not enough we wanted to see",
    "start": "1334840",
    "end": "1340000"
  },
  {
    "text": "something that's more about um you know the semantics of how that application works I should be able to log into a",
    "start": "1340000",
    "end": "1345559"
  },
  {
    "text": " cluster run some query get a result back and everything should work out from top to bottom",
    "start": "1345559",
    "end": "1351080"
  },
  {
    "text": "there which um pingdom doesn't really give you that right out of the out of the box so we wrot an app called thief",
    "start": "1351080",
    "end": "1357679"
  },
  {
    "text": "and uh it does exactly that we have interfaces for uh mongod DB for elastic search uh for rabbit mq itself as a",
    "start": "1357679",
    "end": "1364720"
  },
  {
    "text": "matter of fact um as I said before we're getting into chat Ops and things like that so um",
    "start": "1364720",
    "end": "1372400"
  },
  {
    "text": "the Rick Jenkins bot that you saw a second ago is built on top of a framework that we are calling Amy",
    "start": "1372400",
    "end": "1379600"
  },
  {
    "text": "um that thing is really kind of meant to abstract away the concepts of you know your particular API we kind of wanted to",
    "start": "1379600",
    "end": "1386200"
  },
  {
    "text": "do like a hot thing but for the new age of slack so this am framework is something we're hoping to open source uh",
    "start": "1386200",
    "end": "1392320"
  },
  {
    "text": "in the near future so uh we have a Twitter handle for this at real Rick Jenkins if you want to follow us along",
    "start": "1392320",
    "end": "1398600"
  },
  {
    "text": "uh we think it's a really great project and you'll really get a whole lot out of it um what else we've been doing uh",
    "start": "1398600",
    "end": "1406159"
  },
  {
    "text": "backups of our entire cluster we've written a lot of things to be able to just kind of snapshot the state of things push it into buckets out there in",
    "start": "1406159",
    "end": "1412840"
  },
  {
    "text": "GC um that's been very good in fact we've saved ourselves numerous occasions by oh we just obliterated this object",
    "start": "1412840",
    "end": "1419360"
  },
  {
    "text": "what are we going to do let's go out to the bucket and just replicate it and then there you go or if we want to replay in a particular cluster we can do",
    "start": "1419360",
    "end": "1425720"
  },
  {
    "text": "that um one very big thing we did with our cluster was um we were trying to get U",
    "start": "1425720",
    "end": "1433559"
  },
  {
    "text": "some Geo service data um that we were paying for was very expensive very",
    "start": "1433559",
    "end": "1439200"
  },
  {
    "text": "prohibitively expensive uh we wanted to sub that out we were tasked with doing that um and in about a week with this",
    "start": "1439200",
    "end": "1448120"
  },
  {
    "text": "microservice architecture we were able to get one of these services off the ground with our own data store saved a",
    "start": "1448120",
    "end": "1454919"
  },
  {
    "text": "lot of money a lot of money um and we're able to survive July 3rd our worst day",
    "start": "1454919",
    "end": "1462480"
  },
  {
    "text": "like The Darkest Day of golf is July 3rd for people in our industry",
    "start": "1462480",
    "end": "1468679"
  },
  {
    "text": "so with that I'm going to hand this back over to sh thanks Josh so we're going to",
    "start": "1468679",
    "end": "1474679"
  },
  {
    "start": "1473000",
    "end": "1808000"
  },
  {
    "text": "talk about a little bit of our lessons learned what we've done what we wished",
    "start": "1474679",
    "end": "1479799"
  },
  {
    "text": "we hadn't done that kind of stuff um so one of the big things as Josh mentioned the the bot the chat bot that we created",
    "start": "1479799",
    "end": "1487679"
  },
  {
    "text": "we we were trying we were trying to create a UI um however because the",
    "start": "1487679",
    "end": "1493640"
  },
  {
    "text": "dashboard just wasn't there yet it was the early version of the UI it didn't have deployments and all that stuff so",
    "start": "1493640",
    "end": "1499399"
  },
  {
    "text": "we were going to start trying to create our own and um give it back however we got beat out at the time with dashboard",
    "start": "1499399",
    "end": "1506679"
  },
  {
    "text": "and we thought okay no problem so we started using that a little bit but then we wanted to even go a level deeper and",
    "start": "1506679",
    "end": "1512559"
  },
  {
    "text": "that's what kind of this chat uh chatbot came up and discussed it and Josh was",
    "start": "1512559",
    "end": "1518080"
  },
  {
    "text": "able to hack it out in a weekend which was great um and it's been working very nice for us now we just pull out our",
    "start": "1518080",
    "end": "1523600"
  },
  {
    "text": "phone builds and deploys from our slack apps and we have roles and everything in",
    "start": "1523600",
    "end": "1529159"
  },
  {
    "text": "it so that um somebody who shouldn't be deploying or building are not going to",
    "start": "1529159",
    "end": "1534399"
  },
  {
    "text": "be able to the bot will just tell them you can't do that um so that's that's been great so that's been a big lesson",
    "start": "1534399",
    "end": "1540679"
  },
  {
    "text": "learned for us another lesson learned for us is at the very beginning when we first started we wanted to have a",
    "start": "1540679",
    "end": "1546120"
  },
  {
    "text": "production cluster and a QA cluster we understood the point of name spaces and all that good stuff however since we had",
    "start": "1546120",
    "end": "1552440"
  },
  {
    "text": "to be PCI Compliant we weren't sure how that was going to go over with all the Auditors so we figured okay let's just",
    "start": "1552440",
    "end": "1558760"
  },
  {
    "text": "separate them completely even physically um so when we started out with that",
    "start": "1558760",
    "end": "1564919"
  },
  {
    "text": "unfortunately we we used the kuub script at the time and we didn't realize that",
    "start": "1564919",
    "end": "1571600"
  },
  {
    "text": "the kuub script is only going to create one subnet for you to run the cluster so",
    "start": "1571600",
    "end": "1577640"
  },
  {
    "text": "we went and spun up the second one it was on the same subnet so we were load",
    "start": "1577640",
    "end": "1583559"
  },
  {
    "text": "testing playing around with this thing and we were getting dropped packets 20",
    "start": "1583559",
    "end": "1589120"
  },
  {
    "text": "second load times like what the hell is wrong with this community why do they all like kubernetes man this thing is",
    "start": "1589120",
    "end": "1595080"
  },
  {
    "text": "not even working so one morning woke up in a cold sweat had this Epiphany was",
    "start": "1595080",
    "end": "1600760"
  },
  {
    "text": "like let's kill this other cluster cuz after digging deep into networks uh how",
    "start": "1600760",
    "end": "1606880"
  },
  {
    "text": "the networking worked I realized that it maybe this so we killed the cluster and",
    "start": "1606880",
    "end": "1612000"
  },
  {
    "text": "as soon as that happened the thing was Snappy it was quick it was just back to the point where like okay now we get it",
    "start": "1612000",
    "end": "1618480"
  },
  {
    "text": "we get why everybody loves kubernetes as much as they do um so we had to fix the",
    "start": "1618480",
    "end": "1625200"
  },
  {
    "text": "cuup script from our perspective to create a new subnet for us when we did deploy it into",
    "start": "1625200",
    "end": "1630360"
  },
  {
    "text": "GC um at the beginning as well we because we had started off with c.net",
    "start": "1630360",
    "end": "1636440"
  },
  {
    "text": "everything was in C and today there still is a lot in c.net there was no net core there was no container",
    "start": "1636440",
    "end": "1642840"
  },
  {
    "text": "containerization of that uh language so we're trying to work towards that so that's been kind of a long winded lesson",
    "start": "1642840",
    "end": "1649919"
  },
  {
    "text": "learned for us we're still working through it now um we actually have a few Engineers on the core team that's that",
    "start": "1649919",
    "end": "1655600"
  },
  {
    "text": "are actually starting to rewrite a lot of our services um to utilize that um",
    "start": "1655600",
    "end": "1661640"
  },
  {
    "text": "and then there was this one day we were trying to use ABAC uh the ABAC plugin so",
    "start": "1661640",
    "end": "1668919"
  },
  {
    "text": "we could have authorization and this person the want to name any names this",
    "start": "1668919",
    "end": "1674279"
  },
  {
    "text": "idiot wanted to try and do it on a production cluster",
    "start": "1674279",
    "end": "1679640"
  },
  {
    "text": "and the what man you threw that slide",
    "start": "1679640",
    "end": "1684720"
  },
  {
    "text": "in it's not cool what did What U anyway so yes it was me",
    "start": "1684720",
    "end": "1691840"
  },
  {
    "text": "the idiot I uh thought I was I knew what I was doing installed the ABAC uh plugin",
    "start": "1691840",
    "end": "1699159"
  },
  {
    "text": "tried to get it up and running and brought down our entire cluster and this was the production cluster mind you um",
    "start": "1699159",
    "end": "1706159"
  },
  {
    "text": "so this was part of my like crazy side where I just you know I was I was being",
    "start": "1706159",
    "end": "1711360"
  },
  {
    "text": "a little too ambitious so um with that the great thing was is that we had created a config backup mechanism that",
    "start": "1711360",
    "end": "1718480"
  },
  {
    "text": "will take our entire kubernetes infrastructure in uh Json files out",
    "start": "1718480",
    "end": "1724279"
  },
  {
    "text": "output and put them into a bucket for us somewhere that would run every 5 minutes so the nice thing was what all we had to",
    "start": "1724279",
    "end": "1730320"
  },
  {
    "text": "do was just go back to that bucket um pull it all down and Coupe",
    "start": "1730320",
    "end": "1735880"
  },
  {
    "text": "control everything and we were back up within 20 minutes and Steve had had sort",
    "start": "1735880",
    "end": "1741960"
  },
  {
    "text": "of noticed that something was up but then by the time he had come and checked in on us and we were already up and",
    "start": "1741960",
    "end": "1747200"
  },
  {
    "text": "running and then we had to tell them what happened obviously and tail between my legs and all that you know anyway so",
    "start": "1747200",
    "end": "1753039"
  },
  {
    "text": "I learned that at that point we needed a QA cluster um and try not to use Alpha",
    "start": "1753039",
    "end": "1758320"
  },
  {
    "text": "applications within um a production cluster so with all that I mean the",
    "start": "1758320",
    "end": "1763679"
  },
  {
    "text": "point was is that um a lot of the lessons that we learned were because we",
    "start": "1763679",
    "end": "1769519"
  },
  {
    "text": "created problems for ourselves and a lot of it was because of networking and things like that so if you haven't had",
    "start": "1769519",
    "end": "1776159"
  },
  {
    "text": "an issue with networking or kubernetes you're you have not used kubernetes you have not exercised it enough yet so so",
    "start": "1776159",
    "end": "1783919"
  },
  {
    "text": "anyway so that's our our big Lessons Learned I think from there so to wrap it up I wanted to share some stats with you",
    "start": "1783919",
    "end": "1789440"
  },
  {
    "text": "guys in this migration and how much we've actually done um in a such a short",
    "start": "1789440",
    "end": "1796399"
  },
  {
    "text": "period of time and really between between one and a half resources cuz I was about half the time Josh has been a",
    "start": "1796399",
    "end": "1802559"
  },
  {
    "text": "lot of the time uh fulltime on it and a couple anary de developers that were helping us out um we're running about",
    "start": "1802559",
    "end": "1810559"
  },
  {
    "start": "1808000",
    "end": "1925000"
  },
  {
    "text": "200 plus services within all our clusters um we're running four clusters",
    "start": "1810559",
    "end": "1817440"
  },
  {
    "text": "we have a Golf Channel cluster which golf channel is actually hosted through kubernetes we have a golf now cluster",
    "start": "1817440",
    "end": "1823799"
  },
  {
    "text": "that's running some of this uh tader uh that's actually running all of the",
    "start": "1823799",
    "end": "1828960"
  },
  {
    "text": "uh application on which is going to be kind of like a central uh microservice",
    "start": "1828960",
    "end": "1834279"
  },
  {
    "text": "everything's going to move towards uh that direction and then we have a QA cluster QA staging cluster and the last",
    "start": "1834279",
    "end": "1839840"
  },
  {
    "text": "cluster that we have is uh a cluster in the EU with our counterparts over there",
    "start": "1839840",
    "end": "1846840"
  },
  {
    "text": "um to also kind of get into all this we're running about 30 plus different um",
    "start": "1846840",
    "end": "1854279"
  },
  {
    "text": "replica sets mongod DB replica sets these are all different clusters for different uh microservices the idea that",
    "start": "1854279",
    "end": "1861000"
  },
  {
    "text": "we had was for a microservice to be truly a microservice you need to also make sure your database is essentially a",
    "start": "1861000",
    "end": "1867480"
  },
  {
    "text": "microservice in itself as well um we have about 10 plus elastic",
    "start": "1867480",
    "end": "1874039"
  },
  {
    "text": "search clusters 10 or so uh",
    "start": "1874039",
    "end": "1880120"
  },
  {
    "text": "redus we have about three terabytes of managed data um and this is again",
    "start": "1880120",
    "end": "1885840"
  },
  {
    "text": "running all our data tier within a containerized environment ephemeral containers all that good stuff we're",
    "start": "1885840",
    "end": "1892200"
  },
  {
    "text": "using obviously persistent discs um within uh Google and lastly our Lan Kafka cluster",
    "start": "1892200",
    "end": "1900399"
  },
  {
    "text": "which will grow um based on the slide I showed you guys earlier with the Geo data sync um but Kafka has been working",
    "start": "1900399",
    "end": "1907320"
  },
  {
    "text": "great for us actually another uh stat that I forgot to put in here was we have about three two or three two or three uh",
    "start": "1907320",
    "end": "1914720"
  },
  {
    "text": "rabbit mq clusters also to kind of itate a lot of our uh messages that are going",
    "start": "1914720",
    "end": "1920279"
  },
  {
    "text": "all over the place again so we don't have a single point of failure all that good stuff so with that um appreciate",
    "start": "1920279",
    "end": "1927240"
  },
  {
    "start": "1925000",
    "end": "2262000"
  },
  {
    "text": "you guys listening to us we have a few minutes uh wanted to open up the stage to some Q&A sure",
    "start": "1927240",
    "end": "1935600"
  },
  {
    "text": "yeah so the question was is that in the geodata sync design that we have does it assume that there's no overlap in the",
    "start": "1946279",
    "end": "1953080"
  },
  {
    "text": "data yes it does because every data center is going to generate their own tea times for that particular region so",
    "start": "1953080",
    "end": "1959240"
  },
  {
    "text": "we've got a a European region that's going to generate those tea times for the European region and then that data is going to go across to the US so if",
    "start": "1959240",
    "end": "1965679"
  },
  {
    "text": "there's a person in the US that's going to be planning a trip over into Europe their tea times don't necessarily need",
    "start": "1965679",
    "end": "1972120"
  },
  {
    "text": "to be minute by minute they don't need to be there right away they're going to probably be looking for two weeks three",
    "start": "1972120",
    "end": "1977919"
  },
  {
    "text": "weeks a month or couple months out so that data doesn't doesn't really churn as much as data that's going to expire",
    "start": "1977919",
    "end": "1983720"
  },
  {
    "text": "soon with the tea times that are coming up so yes it does assume that the data is unique that's being generated from",
    "start": "1983720",
    "end": "1989760"
  },
  {
    "text": "all over the place so through our tests originally we",
    "start": "1989760",
    "end": "1997360"
  },
  {
    "text": "wrote the um the service that pulled the data out of the oplog and pushed it over",
    "start": "1997360",
    "end": "2003320"
  },
  {
    "text": "uh we wrote that in node.js and that was taking quite a bit of time um if I remember it was",
    "start": "2003320",
    "end": "2009880"
  },
  {
    "text": "taking five to 10 seconds if I'm not mistaken about right yeah um and that to",
    "start": "2009880",
    "end": "2015399"
  },
  {
    "text": "us was not going to be scalable and it was running about I think actually now the stat let",
    "start": "2015399",
    "end": "2021480"
  },
  {
    "text": "me bring it back I think the stat stat was about 3,000 or so data points per second it was moving over and that to us",
    "start": "2021480",
    "end": "2028000"
  },
  {
    "text": "was not going to scale right it was not going to work for us it was going to start probably going lower actually so",
    "start": "2028000",
    "end": "2035760"
  },
  {
    "text": "based on what we were looking at what we were seeing as our traces we noticed that it was actually node that was",
    "start": "2035760",
    "end": "2041559"
  },
  {
    "text": "causing an issue node was not able to keep up with that constant barrage of",
    "start": "2041559",
    "end": "2047159"
  },
  {
    "text": "data because of his asynchronous nature and single threaded and all that good stuff so we realized at that point node",
    "start": "2047159",
    "end": "2054158"
  },
  {
    "text": "is awesome but node is awesome for web facing consumer facing type of deals but",
    "start": "2054159",
    "end": "2059800"
  },
  {
    "text": "if you're trying to do a lot of heavy lifting in the background we went with go we tried go it was our first time",
    "start": "2059800",
    "end": "2065638"
  },
  {
    "text": "ever using go and it was kind of like all right well let's let's play around with go we tried it when we went with go we the thing jumped up to like 10 to",
    "start": "2065639",
    "end": "2073280"
  },
  {
    "text": "15,000 a second and it was our literally our first application to go so there's",
    "start": "2073280",
    "end": "2078919"
  },
  {
    "text": "plenty of room for us to be able to make it better and faster and all that good stuff so at that point we realized all",
    "start": "2078919",
    "end": "2085720"
  },
  {
    "text": "right so all backend heavy lifting type of applications need to be a lower level type of language go",
    "start": "2085720",
    "end": "2091919"
  },
  {
    "text": "C++ something that nature and then some more of like the consumer facing apis",
    "start": "2091919",
    "end": "2097760"
  },
  {
    "text": "and uh um websites should probably be JavaScript and nodejs",
    "start": "2097760",
    "end": "2105040"
  },
  {
    "text": "so I'm sorry I didn't",
    "start": "2108560",
    "end": "2112359"
  },
  {
    "text": "understand oh so the question was how do we manage our database cluster our our clusters uh it's in GC right now our",
    "start": "2113920",
    "end": "2121200"
  },
  {
    "text": "goal is to eventually get it into a private Cloud so the point was is like I said was that we wanted it to be able to",
    "start": "2121200",
    "end": "2126640"
  },
  {
    "text": "be lifted up and moved into any data center that we wanted GCE AWS whatever",
    "start": "2126640",
    "end": "2133560"
  },
  {
    "text": "uh as well as private so uh at the moment right now we're only in GC um the",
    "start": "2133560",
    "end": "2138599"
  },
  {
    "text": "goal is to get it into private so that we can have the Federation control plane to you know go in and",
    "start": "2138599",
    "end": "2144760"
  },
  {
    "text": "out so we use cuup the cuup script um we just use what is uh in kubernetes right",
    "start": "2144760",
    "end": "2152040"
  },
  {
    "text": "now with the cuup script so yeah I know there's a cube ADM um that we're actually going to try to exercise in our",
    "start": "2152040",
    "end": "2158560"
  },
  {
    "text": "private cloud and then further uh utilize it into our CL our actual public",
    "start": "2158560",
    "end": "2166560"
  },
  {
    "text": "clouds why not GK the question um the reason why we didn't go GK was again so that we're Cloud agnostic cloud provider",
    "start": "2166880",
    "end": "2174160"
  },
  {
    "text": "agnostic gka is awesome uh we actually played around with it we used it and the beauty of it was we didn't have to deal",
    "start": "2174160",
    "end": "2179640"
  },
  {
    "text": "with the master right um however the point of us being agnostic to the cloud",
    "start": "2179640",
    "end": "2185680"
  },
  {
    "text": "it didn't it wasn't conducive to that and again it was just again to prove that we can actually go anywhere we want",
    "start": "2185680",
    "end": "2190960"
  },
  {
    "text": "it to in the future we may just say all right gka for GC and then uh use our own",
    "start": "2190960",
    "end": "2197319"
  },
  {
    "text": "homegrown into private and then just have the F the uh kubernetes Federation plane on top so and we're actually",
    "start": "2197319",
    "end": "2204240"
  },
  {
    "text": "running uh 1.4 today and we try to run we try to upgrade every half version so",
    "start": "2204240",
    "end": "2209839"
  },
  {
    "text": "next version is 1 1.4.5 uh which we're are going to plan after this and and so on",
    "start": "2209839",
    "end": "2218040"
  },
  {
    "text": "right so the question was uh what strategy we using to upgrade the cluster and have we looked into the Cube setion",
    "start": "2223240",
    "end": "2229800"
  },
  {
    "text": "stuff that uh Aon Levy was talking about earlier yeah self-hosting um we would",
    "start": "2229800",
    "end": "2235000"
  },
  {
    "text": "like to get to the self-hosting we we're not there yet by no means um we're literally utilizing the upgrade scripts",
    "start": "2235000",
    "end": "2241119"
  },
  {
    "text": "that are in in the repository um we just I think we adjusted a few things in it",
    "start": "2241119",
    "end": "2247040"
  },
  {
    "text": "we did to uh to utilize it the way we wanted so that it's a little safer made us give it gave us just the warm and",
    "start": "2247040",
    "end": "2253119"
  },
  {
    "text": "fuzzies a little bit I guess as we were doing it um but it's basically the upgrade script coup setion is definitely",
    "start": "2253119",
    "end": "2259440"
  },
  {
    "text": "coming for us particularly as we move into private clouds um you know with our environments and particular they're",
    "start": "2259440",
    "end": "2264520"
  },
  {
    "start": "2262000",
    "end": "2603000"
  },
  {
    "text": "extremely constrained there's lots of strict rules about it so bootstrapping is like the only way to go",
    "start": "2264520",
    "end": "2271480"
  },
  {
    "text": "painfully not you can tell you that for sure like a lot of the data here um actually elastics are just among the",
    "start": "2281640",
    "end": "2287760"
  },
  {
    "text": "easier of those um but we run them as containers oh I'm so sorry uh the",
    "start": "2287760",
    "end": "2294720"
  },
  {
    "text": "question was uh how do we run elastic search uh whether whether it's pet sets containers so we run them as Standalone",
    "start": "2294720",
    "end": "2301480"
  },
  {
    "text": "containers um we've done a lot of clever hacking to get all of our data tier instances up and running um search was",
    "start": "2301480",
    "end": "2308040"
  },
  {
    "text": "one of the easier ones to Federate um mongod was the hardest hands down absolutely",
    "start": "2308040",
    "end": "2314839"
  },
  {
    "text": "um I I mean like I'm I'm getting flashbacks right now just thinking about it as a matter of fact this was back cuz",
    "start": "2314839",
    "end": "2321119"
  },
  {
    "text": "we started this was back way before pet sets cuz we started at the 1.0.4 I said or five one of those two versions so we",
    "start": "2321119",
    "end": "2327640"
  },
  {
    "text": "had to make sure that it was always going to be able to come back and it didn't so yeah exactly um staple set's",
    "start": "2327640",
    "end": "2334720"
  },
  {
    "text": "definitely the way to go now it does seem like if we could go back and do it again again if we hadn't heaped on so much tooling as we have now it probably",
    "start": "2334720",
    "end": "2340880"
  },
  {
    "text": "would be one of those things but yeah we do we have taken a container approach to this point and we actually when we uh we",
    "start": "2340880",
    "end": "2347440"
  },
  {
    "text": "had been talking to at the time and and we had told them that we had done that and they kind of were really",
    "start": "2347440",
    "end": "2353880"
  },
  {
    "text": "scared they're like you can't do that like oh we did it and we've been running it for like a year and it's fine so I it",
    "start": "2353880",
    "end": "2360440"
  },
  {
    "text": "it seemed like we were one of the first to do that at least that they've heard of we haven't seen anybody running in",
    "start": "2360440",
    "end": "2366400"
  },
  {
    "text": "replica sets in that manner it took us quite a while to figure out how to do it but now it's I think it's a python",
    "start": "2366400",
    "end": "2371839"
  },
  {
    "text": "script at this point um and it's very easily we turn it up pretty easily",
    "start": "2371839",
    "end": "2377880"
  },
  {
    "text": "now sure do you want to take it or you want me to Sure uh actually you want to start so uh the question was PCI um",
    "start": "2387119",
    "end": "2394760"
  },
  {
    "text": "since we're PCI Compliant what kind of measures do we take to secure and everything so we didn't do anything",
    "start": "2394760",
    "end": "2400040"
  },
  {
    "text": "necessarily for the container to harden it or any in any way that shape or form actually to begin with because we had",
    "start": "2400040",
    "end": "2406440"
  },
  {
    "text": "PCI on the mind we were actually creating our own base images this was",
    "start": "2406440",
    "end": "2413440"
  },
  {
    "text": "basically unic kernel before unic kernel had a name um so we were trying to",
    "start": "2413440",
    "end": "2418560"
  },
  {
    "text": "create it and we were kind of building our almost our own drro of of what we",
    "start": "2418560",
    "end": "2424440"
  },
  {
    "text": "needed exactly so we went from the application and and built it down from there and took the things that we needed",
    "start": "2424440",
    "end": "2431240"
  },
  {
    "text": "if it was um whatever we needed for go or node.js or whatever the case maybe we build the base image from that again for",
    "start": "2431240",
    "end": "2438960"
  },
  {
    "text": "that security to harden it as much as possible so that we don't have SSH because we don't need it we don't have",
    "start": "2438960",
    "end": "2445319"
  },
  {
    "text": "USB drivers we don't have any of this other fluff in the OS that we don't necessarily need so we tried to harden",
    "start": "2445319",
    "end": "2451040"
  },
  {
    "text": "it in that way but that was becoming more of a pain for us and then the fact that we were using key and it giving us",
    "start": "2451040",
    "end": "2457400"
  },
  {
    "text": "the security scans we're like well maybe we're not doing it right and we went back to just using a Bas de Debian image",
    "start": "2457400",
    "end": "2465319"
  },
  {
    "text": "however now looking back at it maybe it was better for us to actually build our",
    "start": "2465319",
    "end": "2470560"
  },
  {
    "text": "base images from scratch the way we were to make it a little bit more secure yes we were losing the security scans",
    "start": "2470560",
    "end": "2477760"
  },
  {
    "text": "however we knew what was in there for sure and we could actually Version Control one Dr uh the the image based on",
    "start": "2477760",
    "end": "2485000"
  },
  {
    "text": "one version to another so in that sense we haven't done anything crazy break groundbreaking in that sense what we",
    "start": "2485000",
    "end": "2491359"
  },
  {
    "text": "actually did was just we made sure that our microservices that we created",
    "start": "2491359",
    "end": "2496680"
  },
  {
    "text": "were all um decoupled from the fact that the datas the the the pods that were",
    "start": "2496680",
    "end": "2503599"
  },
  {
    "text": "running within the data center did not process any data as far as credit cards go and everything was offloaded to our",
    "start": "2503599",
    "end": "2510920"
  },
  {
    "text": "PCI Zone which was on the west coast that it showed in the diagram so it's kind of like what we did we just",
    "start": "2510920",
    "end": "2516440"
  },
  {
    "text": "basically just made it so that there's a transparent redirect in the background that takes care of all of that for us so",
    "start": "2516440",
    "end": "2522160"
  },
  {
    "text": "that the security concern is kind of offloaded into our PCI Zone does that answer your question",
    "start": "2522160",
    "end": "2529838"
  },
  {
    "text": "can right we don't we don't have default Services service accounts that do that",
    "start": "2536359",
    "end": "2541520"
  },
  {
    "text": "have access to everything we create a new one for each service that and if it needs access to that particular service",
    "start": "2541520",
    "end": "2546800"
  },
  {
    "text": "it will get access um otherwise we don't share anything like that um yeah and",
    "start": "2546800",
    "end": "2552680"
  },
  {
    "text": "we're actually going to a different model right now where all our um passwords and everything on config Maps",
    "start": "2552680",
    "end": "2559079"
  },
  {
    "text": "however we wanted to be also be able to also put the config Maps within our uh repository so we can Version Control",
    "start": "2559079",
    "end": "2565599"
  },
  {
    "text": "them as well but then we have passwords in there so what we were going to do is actually create a config map that's",
    "start": "2565599",
    "end": "2570839"
  },
  {
    "text": "specific to passwords only that go in their own repo and then the application",
    "start": "2570839",
    "end": "2576400"
  },
  {
    "text": "specific config maps are pretty much wide open that don't have any security",
    "start": "2576400",
    "end": "2581800"
  },
  {
    "text": "type of issues that would be would be an issue if you had put them in a repository so I did you have anything",
    "start": "2581800",
    "end": "2587680"
  },
  {
    "text": "just briefly follow on I mean and I'm sure it's kind of a given we have not actually been audited yet so it's going",
    "start": "2587680",
    "end": "2593280"
  },
  {
    "text": "to be kind of an open question as to what happens yeah um you know it's right now kind of a question of following best",
    "start": "2593280",
    "end": "2599040"
  },
  {
    "text": "practice so yeah you know definitely segment uh all your account stuff of course we get the freebie of not having",
    "start": "2599040",
    "end": "2605599"
  },
  {
    "start": "2603000",
    "end": "2687000"
  },
  {
    "text": "to deal with credit card data that definitely does help but you know they're they're they're going to want to know so I think that'll be an open",
    "start": "2605599",
    "end": "2612280"
  },
  {
    "text": "question for next year well actually I think we're going to get audited this year I think we're gonna we're going to",
    "start": "2612280",
    "end": "2617319"
  },
  {
    "text": "actually go through that process so maybe next cucon I could give you a better answer I don't know anything else any other",
    "start": "2617319",
    "end": "2626319"
  },
  {
    "text": "questions yes so the question was all the Clusters that we have Mom",
    "start": "2631599",
    "end": "2637599"
  },
  {
    "text": "the Kafka all that stuff are they Al are they all containerized within kubernetes yes everything is containerized",
    "start": "2637599",
    "end": "2644880"
  },
  {
    "text": "everything is an ephemeral container everything is running in kubernetes everything is scheduled through",
    "start": "2644880",
    "end": "2651520"
  },
  {
    "text": "kubernetes yes we do have MySQL and then the question was do we have any relational databases yes everything is on yes",
    "start": "2651839",
    "end": "2660559"
  },
  {
    "text": "everything is on that was that was what we were trying to do we were trying to make it so that literally everything runs within uh",
    "start": "2660559",
    "end": "2667640"
  },
  {
    "text": "kubernetes so that we don't have to worry about anything really and that was",
    "start": "2667640",
    "end": "2672760"
  },
  {
    "text": "why Cloud Foundry actually didn't work out for us because they couldn't do that for us so think you wanted to add oh",
    "start": "2672760",
    "end": "2680040"
  },
  {
    "text": "sorry all right we're done thank you everybody thank you",
    "start": "2680040",
    "end": "2685960"
  }
]
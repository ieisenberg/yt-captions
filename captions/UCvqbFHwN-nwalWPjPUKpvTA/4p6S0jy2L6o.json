[
  {
    "text": "thanks for the introduction i want to",
    "start": "0",
    "end": "1199"
  },
  {
    "text": "i'll uh make this short and sweet um",
    "start": "1199",
    "end": "4080"
  },
  {
    "text": "yeah here to you to talk a little bit",
    "start": "4080",
    "end": "6480"
  },
  {
    "text": "about um one of the topics i'm fairly",
    "start": "6480",
    "end": "9120"
  },
  {
    "text": "passionate about and uh",
    "start": "9120",
    "end": "12559"
  },
  {
    "text": "we will be talking about it a little bit",
    "start": "12559",
    "end": "14240"
  },
  {
    "text": "later",
    "start": "14240",
    "end": "15679"
  },
  {
    "text": "in the day as well at a",
    "start": "15679",
    "end": "17920"
  },
  {
    "text": "a talk that our developer advocate gibbs",
    "start": "17920",
    "end": "21119"
  },
  {
    "text": "from chronosphere is giving",
    "start": "21119",
    "end": "23359"
  },
  {
    "text": "my name's rob i'm the",
    "start": "23359",
    "end": "25439"
  },
  {
    "text": "creator of the m3db open source project",
    "start": "25439",
    "end": "28720"
  },
  {
    "text": "and the the cto of chronosphere which is",
    "start": "28720",
    "end": "31119"
  },
  {
    "text": "a hosted sas uh observability um and",
    "start": "31119",
    "end": "35200"
  },
  {
    "text": "prometheus native um",
    "start": "35200",
    "end": "37120"
  },
  {
    "text": "monitoring platform",
    "start": "37120",
    "end": "39200"
  },
  {
    "text": "uh so",
    "start": "39200",
    "end": "41120"
  },
  {
    "text": "this is something that i assume uh lots",
    "start": "41120",
    "end": "43040"
  },
  {
    "text": "of us have faced",
    "start": "43040",
    "end": "45600"
  },
  {
    "text": "loading up a dashboard or trying to",
    "start": "45600",
    "end": "48399"
  },
  {
    "text": "essentially view some",
    "start": "48399",
    "end": "50559"
  },
  {
    "text": "high cardinality latency data over a",
    "start": "50559",
    "end": "54640"
  },
  {
    "text": "growing set of pods or uh distributed",
    "start": "54640",
    "end": "58800"
  },
  {
    "text": "system that you're monitoring and um you",
    "start": "58800",
    "end": "61359"
  },
  {
    "text": "know of course",
    "start": "61359",
    "end": "62480"
  },
  {
    "text": "uh over time this can become",
    "start": "62480",
    "end": "65280"
  },
  {
    "text": "something that can uh you know when you",
    "start": "65280",
    "end": "67360"
  },
  {
    "text": "add a whole bunch of cardinality really",
    "start": "67360",
    "end": "69280"
  },
  {
    "text": "quickly become",
    "start": "69280",
    "end": "70560"
  },
  {
    "text": "an immediate problem that impacts your",
    "start": "70560",
    "end": "72400"
  },
  {
    "text": "visibility so hands up who's ever run",
    "start": "72400",
    "end": "75040"
  },
  {
    "text": "into this kind of situation unexpectedly",
    "start": "75040",
    "end": "79439"
  },
  {
    "text": "wonderful not the only one",
    "start": "79439",
    "end": "82479"
  },
  {
    "text": "so",
    "start": "82720",
    "end": "84080"
  },
  {
    "text": "this talk the title of it uh definitely",
    "start": "84080",
    "end": "87439"
  },
  {
    "text": "seems um",
    "start": "87439",
    "end": "89680"
  },
  {
    "text": "i guess uh perhaps a little bit",
    "start": "89680",
    "end": "92880"
  },
  {
    "text": "uh",
    "start": "92880",
    "end": "94079"
  },
  {
    "text": "a little bit um",
    "start": "94079",
    "end": "95840"
  },
  {
    "text": "uh",
    "start": "95840",
    "end": "97119"
  },
  {
    "text": "extensive like millions of times serious",
    "start": "97119",
    "end": "99040"
  },
  {
    "text": "you know why are we talking about",
    "start": "99040",
    "end": "100079"
  },
  {
    "text": "millions of time series here",
    "start": "100079",
    "end": "101759"
  },
  {
    "text": "most of the pods that we're monitoring",
    "start": "101759",
    "end": "103280"
  },
  {
    "text": "are in the hundreds",
    "start": "103280",
    "end": "104960"
  },
  {
    "text": "um",
    "start": "104960",
    "end": "105840"
  },
  {
    "text": "but uh you know i just wanted to kind of",
    "start": "105840",
    "end": "107119"
  },
  {
    "text": "paint a picture of how you actually get",
    "start": "107119",
    "end": "109680"
  },
  {
    "text": "to millions of time series while",
    "start": "109680",
    "end": "111200"
  },
  {
    "text": "monitoring these pods",
    "start": "111200",
    "end": "113280"
  },
  {
    "text": "in a cloud-native world that",
    "start": "113280",
    "end": "116240"
  },
  {
    "text": "may be unexpected to the average um",
    "start": "116240",
    "end": "119520"
  },
  {
    "text": "to the average developer when they start",
    "start": "119520",
    "end": "121200"
  },
  {
    "text": "you know deploying um",
    "start": "121200",
    "end": "123759"
  },
  {
    "text": "applications and monitoring systems in",
    "start": "123759",
    "end": "126320"
  },
  {
    "text": "in a container world so",
    "start": "126320",
    "end": "129840"
  },
  {
    "text": "i'm just talking here about a single",
    "start": "129840",
    "end": "131840"
  },
  {
    "text": "metric and we'll find very quickly that",
    "start": "131840",
    "end": "134480"
  },
  {
    "text": "just measuring http or gpa",
    "start": "134480",
    "end": "136879"
  },
  {
    "text": "sorry or grpc traffic",
    "start": "136879",
    "end": "139599"
  },
  {
    "text": "can become",
    "start": "139599",
    "end": "142319"
  },
  {
    "text": "quite high cardinality very quickly so",
    "start": "142319",
    "end": "144319"
  },
  {
    "text": "we're talking about 50 micro services",
    "start": "144319",
    "end": "146239"
  },
  {
    "text": "200 say average pods per service now",
    "start": "146239",
    "end": "149440"
  },
  {
    "text": "that seems large but",
    "start": "149440",
    "end": "151360"
  },
  {
    "text": "imagine you know even",
    "start": "151360",
    "end": "153200"
  },
  {
    "text": "pegging one of these numbers down and",
    "start": "153200",
    "end": "154800"
  },
  {
    "text": "you can you're still in a very um high",
    "start": "154800",
    "end": "157120"
  },
  {
    "text": "cardinality world",
    "start": "157120",
    "end": "158560"
  },
  {
    "text": "and then say uh you know each one of",
    "start": "158560",
    "end": "160800"
  },
  {
    "text": "these services might have 20 average um",
    "start": "160800",
    "end": "163680"
  },
  {
    "text": "on average hp endpoints or grpc methods",
    "start": "163680",
    "end": "166160"
  },
  {
    "text": "five common status codes and 30",
    "start": "166160",
    "end": "168480"
  },
  {
    "text": "histogram buckets",
    "start": "168480",
    "end": "171120"
  },
  {
    "text": "so you quickly get to 30 million unique",
    "start": "171120",
    "end": "173599"
  },
  {
    "text": "time series which is um insane this is a",
    "start": "173599",
    "end": "176160"
  },
  {
    "text": "single metric we're talking about here",
    "start": "176160",
    "end": "178480"
  },
  {
    "text": "and you have lots of things you're",
    "start": "178480",
    "end": "179840"
  },
  {
    "text": "tracking and lots of unique metric names",
    "start": "179840",
    "end": "183120"
  },
  {
    "text": "in an organization",
    "start": "183120",
    "end": "184640"
  },
  {
    "text": "um so wouldn't it be nice as well to",
    "start": "184640",
    "end": "186400"
  },
  {
    "text": "slice and dice by the git server version",
    "start": "186400",
    "end": "188319"
  },
  {
    "text": "or the mobile client app version or web",
    "start": "188319",
    "end": "191120"
  },
  {
    "text": "front end version",
    "start": "191120",
    "end": "192480"
  },
  {
    "text": "these are all things that are just",
    "start": "192480",
    "end": "195120"
  },
  {
    "text": "really obtuse when you get to these kind",
    "start": "195120",
    "end": "197280"
  },
  {
    "text": "of numbers of unique time series so you",
    "start": "197280",
    "end": "199599"
  },
  {
    "text": "know if you multiply by two twice you",
    "start": "199599",
    "end": "201440"
  },
  {
    "text": "get to 120 million time series again for",
    "start": "201440",
    "end": "203760"
  },
  {
    "text": "a single metric um if we remove the pod",
    "start": "203760",
    "end": "206319"
  },
  {
    "text": "cardinality this becomes much more",
    "start": "206319",
    "end": "208239"
  },
  {
    "text": "manageable we get down to 150 000 unique",
    "start": "208239",
    "end": "211040"
  },
  {
    "text": "time series across all 50 micro services",
    "start": "211040",
    "end": "214239"
  },
  {
    "text": "um and then you know it becomes uh",
    "start": "214239",
    "end": "216879"
  },
  {
    "text": "manageable in terms of how you think",
    "start": "216879",
    "end": "218720"
  },
  {
    "text": "about keeping these around for a long",
    "start": "218720",
    "end": "220000"
  },
  {
    "text": "time so",
    "start": "220000",
    "end": "221120"
  },
  {
    "text": "um you know if you multiply by twice",
    "start": "221120",
    "end": "223200"
  },
  {
    "text": "again um each time to get the",
    "start": "223200",
    "end": "225599"
  },
  {
    "text": "active server versions and the mobile",
    "start": "225599",
    "end": "227040"
  },
  {
    "text": "client versions on there you're you're",
    "start": "227040",
    "end": "229040"
  },
  {
    "text": "with below one million unique time",
    "start": "229040",
    "end": "231040"
  },
  {
    "text": "series",
    "start": "231040",
    "end": "232000"
  },
  {
    "text": "um so how to get there uh a lot of folks",
    "start": "232000",
    "end": "235120"
  },
  {
    "text": "you know already",
    "start": "235120",
    "end": "236319"
  },
  {
    "text": "like recognize this problem and deploy",
    "start": "236319",
    "end": "238640"
  },
  {
    "text": "um",
    "start": "238640",
    "end": "240239"
  },
  {
    "text": "best practices to",
    "start": "240239",
    "end": "242239"
  },
  {
    "text": "make dashboards faster alerts more",
    "start": "242239",
    "end": "244159"
  },
  {
    "text": "manageable",
    "start": "244159",
    "end": "245599"
  },
  {
    "text": "and keeping the stay around for longer",
    "start": "245599",
    "end": "247360"
  },
  {
    "text": "periods of time more possible",
    "start": "247360",
    "end": "250799"
  },
  {
    "text": "using recording rules and recording",
    "start": "250799",
    "end": "252879"
  },
  {
    "text": "rules are uh one of you know the uh",
    "start": "252879",
    "end": "257120"
  },
  {
    "text": "unarguably very powerful tools in the",
    "start": "257120",
    "end": "260320"
  },
  {
    "text": "prometheus toolset",
    "start": "260320",
    "end": "262400"
  },
  {
    "text": "uh",
    "start": "262400",
    "end": "263520"
  },
  {
    "text": "however at these types of cardinality",
    "start": "263520",
    "end": "266320"
  },
  {
    "text": "they",
    "start": "266320",
    "end": "267280"
  },
  {
    "text": "you do run into frequent problems trying",
    "start": "267280",
    "end": "268960"
  },
  {
    "text": "to deploy them um in some of these you",
    "start": "268960",
    "end": "271600"
  },
  {
    "text": "know single individual metric uh",
    "start": "271600",
    "end": "275040"
  },
  {
    "text": "metrics that you're tracking that are",
    "start": "275040",
    "end": "277360"
  },
  {
    "text": "very high cardinality so we're talking",
    "start": "277360",
    "end": "279360"
  },
  {
    "text": "here about deploying a rule that",
    "start": "279360",
    "end": "280560"
  },
  {
    "text": "actually handles the latency across all",
    "start": "280560",
    "end": "282880"
  },
  {
    "text": "50 services just as an example up front",
    "start": "282880",
    "end": "286560"
  },
  {
    "text": "one thing you might run into when",
    "start": "286560",
    "end": "288160"
  },
  {
    "text": "deploying this rule is that you'll find",
    "start": "288160",
    "end": "290960"
  },
  {
    "text": "that the prometheus instance or",
    "start": "290960",
    "end": "293120"
  },
  {
    "text": "remote storage",
    "start": "293120",
    "end": "295280"
  },
  {
    "text": "solution that you're using such as",
    "start": "295280",
    "end": "296560"
  },
  {
    "text": "thanos cortex or m3",
    "start": "296560",
    "end": "299680"
  },
  {
    "text": "starts",
    "start": "299680",
    "end": "300639"
  },
  {
    "text": "basically unable to",
    "start": "300639",
    "end": "302320"
  },
  {
    "text": "even evaluate that result because it's",
    "start": "302320",
    "end": "304160"
  },
  {
    "text": "touching 30 million time series",
    "start": "304160",
    "end": "306400"
  },
  {
    "text": "and you'll see you know prometheus rule",
    "start": "306400",
    "end": "308880"
  },
  {
    "text": "evaluation errors uh in your metrics",
    "start": "308880",
    "end": "311759"
  },
  {
    "text": "that you're that you're monitoring for",
    "start": "311759",
    "end": "314479"
  },
  {
    "text": "um",
    "start": "314479",
    "end": "315360"
  },
  {
    "text": "your monitoring platform",
    "start": "315360",
    "end": "317120"
  },
  {
    "text": "and then you know you go look in the",
    "start": "317120",
    "end": "318479"
  },
  {
    "text": "logs you'll you might see something like",
    "start": "318479",
    "end": "319840"
  },
  {
    "text": "query processing with load too many",
    "start": "319840",
    "end": "321840"
  },
  {
    "text": "samples um in the memory so that's the",
    "start": "321840",
    "end": "324479"
  },
  {
    "text": "first",
    "start": "324479",
    "end": "325520"
  },
  {
    "text": "issue you might face another issue is if",
    "start": "325520",
    "end": "327600"
  },
  {
    "text": "you",
    "start": "327600",
    "end": "328320"
  },
  {
    "text": "reconfigure your prometheus or your",
    "start": "328320",
    "end": "330800"
  },
  {
    "text": "remote storage instance to actually",
    "start": "330800",
    "end": "333039"
  },
  {
    "text": "allow you to bypass those limits you'll",
    "start": "333039",
    "end": "335440"
  },
  {
    "text": "see that very frequently when we're",
    "start": "335440",
    "end": "337360"
  },
  {
    "text": "talking about 30 million time series",
    "start": "337360",
    "end": "338800"
  },
  {
    "text": "you're going to start missing that",
    "start": "338800",
    "end": "340160"
  },
  {
    "text": "evaluation cycle um it it takes far too",
    "start": "340160",
    "end": "343600"
  },
  {
    "text": "long to",
    "start": "343600",
    "end": "345520"
  },
  {
    "text": "load all that into memory process that",
    "start": "345520",
    "end": "347440"
  },
  {
    "text": "out and record all the",
    "start": "347440",
    "end": "349360"
  },
  {
    "text": "results uh when you've got that kind of",
    "start": "349360",
    "end": "352160"
  },
  {
    "text": "level of cardinality for a single rule",
    "start": "352160",
    "end": "354240"
  },
  {
    "text": "um and then if you know that there's um",
    "start": "354240",
    "end": "356960"
  },
  {
    "text": "of course",
    "start": "356960",
    "end": "357919"
  },
  {
    "text": "the workarounds that you might deploy so",
    "start": "357919",
    "end": "359919"
  },
  {
    "text": "you might deploy",
    "start": "359919",
    "end": "361680"
  },
  {
    "text": "so i already mentioned one which is",
    "start": "361680",
    "end": "363360"
  },
  {
    "text": "raising the maximum samples per query",
    "start": "363360",
    "end": "366560"
  },
  {
    "text": "allowed by prometheus or remote storage",
    "start": "366560",
    "end": "370560"
  },
  {
    "text": "the problem with that is that you'll",
    "start": "370560",
    "end": "373280"
  },
  {
    "text": "probably run out of memory uh",
    "start": "373280",
    "end": "375360"
  },
  {
    "text": "we're talking about 30 million time",
    "start": "375360",
    "end": "377120"
  },
  {
    "text": "series",
    "start": "377120",
    "end": "378479"
  },
  {
    "text": "and especially if you you know want to",
    "start": "378479",
    "end": "380160"
  },
  {
    "text": "do some kind of sla calculation that",
    "start": "380160",
    "end": "382240"
  },
  {
    "text": "actually is pulling back historical data",
    "start": "382240",
    "end": "384560"
  },
  {
    "text": "not in the the recent like 30 minutes 30",
    "start": "384560",
    "end": "387199"
  },
  {
    "text": "minute window um",
    "start": "387199",
    "end": "389120"
  },
  {
    "text": "that's just a lot of data to load and",
    "start": "389120",
    "end": "391840"
  },
  {
    "text": "process into the query engine um just by",
    "start": "391840",
    "end": "394080"
  },
  {
    "text": "itself",
    "start": "394080",
    "end": "395759"
  },
  {
    "text": "and then you know if you're able to",
    "start": "395759",
    "end": "397039"
  },
  {
    "text": "deploy enough resources and",
    "start": "397039",
    "end": "400960"
  },
  {
    "text": "bypass the the max samples limit um",
    "start": "400960",
    "end": "404639"
  },
  {
    "text": "you you buy a config you're still going",
    "start": "404639",
    "end": "406880"
  },
  {
    "text": "to see that you may miss the uh the",
    "start": "406880",
    "end": "409360"
  },
  {
    "text": "interval",
    "start": "409360",
    "end": "410560"
  },
  {
    "text": "so you know you might go and split out",
    "start": "410560",
    "end": "412479"
  },
  {
    "text": "the rules one per service um but this",
    "start": "412479",
    "end": "415440"
  },
  {
    "text": "again has similar problems uh so you",
    "start": "415440",
    "end": "417919"
  },
  {
    "text": "know divide 30 million by 50 get each",
    "start": "417919",
    "end": "420160"
  },
  {
    "text": "rule taking about 600 uh each rule needs",
    "start": "420160",
    "end": "423360"
  },
  {
    "text": "to process 600 000 unique time series",
    "start": "423360",
    "end": "425599"
  },
  {
    "text": "still um which is you know quite a quite",
    "start": "425599",
    "end": "428639"
  },
  {
    "text": "a huge number you're going to eventually",
    "start": "428639",
    "end": "430800"
  },
  {
    "text": "hit the the timeouts um",
    "start": "430800",
    "end": "433440"
  },
  {
    "text": "uh per uh rule group for for that kind",
    "start": "433440",
    "end": "436319"
  },
  {
    "text": "of deployment and also just at the end",
    "start": "436319",
    "end": "439120"
  },
  {
    "text": "of the day you're using a lot of",
    "start": "439120",
    "end": "440720"
  },
  {
    "text": "resources just to",
    "start": "440720",
    "end": "443199"
  },
  {
    "text": "basically aggregate",
    "start": "443199",
    "end": "444800"
  },
  {
    "text": "things in the same system that's storing",
    "start": "444800",
    "end": "447120"
  },
  {
    "text": "your data",
    "start": "447120",
    "end": "448560"
  },
  {
    "text": "so",
    "start": "448560",
    "end": "449759"
  },
  {
    "text": "architecturally you know these are the",
    "start": "449759",
    "end": "451039"
  },
  {
    "text": "steps that happen so you collect the",
    "start": "451039",
    "end": "452720"
  },
  {
    "text": "metrics um you write them to disk uh and",
    "start": "452720",
    "end": "455840"
  },
  {
    "text": "then",
    "start": "455840",
    "end": "456720"
  },
  {
    "text": "when you evaluate the recording rule it",
    "start": "456720",
    "end": "459039"
  },
  {
    "text": "doesn't uh a reverse index query and",
    "start": "459039",
    "end": "461520"
  },
  {
    "text": "then if it's touching millions of time",
    "start": "461520",
    "end": "462880"
  },
  {
    "text": "series or very high cardinality it that",
    "start": "462880",
    "end": "466240"
  },
  {
    "text": "can be expensive memory memory wise in",
    "start": "466240",
    "end": "469120"
  },
  {
    "text": "of itself",
    "start": "469120",
    "end": "470240"
  },
  {
    "text": "you read from that storage you evaluate",
    "start": "470240",
    "end": "472479"
  },
  {
    "text": "the results then you write it back to",
    "start": "472479",
    "end": "474240"
  },
  {
    "text": "storage um and so that's you know on a",
    "start": "474240",
    "end": "476800"
  },
  {
    "text": "single node that that um there you can",
    "start": "476800",
    "end": "479440"
  },
  {
    "text": "actually get quite far because there's",
    "start": "479440",
    "end": "480879"
  },
  {
    "text": "levels of efficiency with everything",
    "start": "480879",
    "end": "482720"
  },
  {
    "text": "happening in a single process here um",
    "start": "482720",
    "end": "484800"
  },
  {
    "text": "once you go to a distributed model uh",
    "start": "484800",
    "end": "487120"
  },
  {
    "text": "with you know thanos cortex m3 any",
    "start": "487120",
    "end": "489840"
  },
  {
    "text": "anything else um this picture looks even",
    "start": "489840",
    "end": "492960"
  },
  {
    "text": "more expensive because not only are you",
    "start": "492960",
    "end": "494879"
  },
  {
    "text": "doing that frequent expensive reverse",
    "start": "494879",
    "end": "496960"
  },
  {
    "text": "index query reading for storage",
    "start": "496960",
    "end": "498560"
  },
  {
    "text": "evaluating and writing back this is all",
    "start": "498560",
    "end": "500319"
  },
  {
    "text": "going across the network so",
    "start": "500319",
    "end": "502479"
  },
  {
    "text": "you know every 15 30 seconds 60 seconds",
    "start": "502479",
    "end": "505120"
  },
  {
    "text": "whatever your valuation interval is",
    "start": "505120",
    "end": "507280"
  },
  {
    "text": "you're pulling back huge amounts of data",
    "start": "507280",
    "end": "510160"
  },
  {
    "text": "over the network from many nodes",
    "start": "510160",
    "end": "512080"
  },
  {
    "text": "coordinating into one place where you",
    "start": "512080",
    "end": "513760"
  },
  {
    "text": "need to reserve a lot of resources and",
    "start": "513760",
    "end": "515919"
  },
  {
    "text": "then um all write it back and serialize",
    "start": "515919",
    "end": "519200"
  },
  {
    "text": "that as rpc or http calls",
    "start": "519200",
    "end": "522880"
  },
  {
    "text": "m3 aggregation is a little bit different",
    "start": "522880",
    "end": "524880"
  },
  {
    "text": "so it's not meant to be a replacement",
    "start": "524880",
    "end": "526800"
  },
  {
    "text": "for recording rules but it can turn a",
    "start": "526800",
    "end": "529839"
  },
  {
    "text": "lot of distinct counters into fewer",
    "start": "529839",
    "end": "531839"
  },
  {
    "text": "aggregate counters",
    "start": "531839",
    "end": "533680"
  },
  {
    "text": "and",
    "start": "533680",
    "end": "534560"
  },
  {
    "text": "it does that by basically taking you",
    "start": "534560",
    "end": "536480"
  },
  {
    "text": "know you can do things like take the",
    "start": "536480",
    "end": "537440"
  },
  {
    "text": "derivative as the first function of each",
    "start": "537440",
    "end": "539279"
  },
  {
    "text": "time series and then aggregate that",
    "start": "539279",
    "end": "541120"
  },
  {
    "text": "together",
    "start": "541120",
    "end": "542560"
  },
  {
    "text": "and then build another monotonic counter",
    "start": "542560",
    "end": "545279"
  },
  {
    "text": "from from input counters so what it's",
    "start": "545279",
    "end": "547360"
  },
  {
    "text": "doing is as data is written to either",
    "start": "547360",
    "end": "550320"
  },
  {
    "text": "the m3 coordinator which can be used as",
    "start": "550320",
    "end": "552480"
  },
  {
    "text": "a side card next to prometheus or using",
    "start": "552480",
    "end": "555040"
  },
  {
    "text": "a scaled m3 aggregator instance",
    "start": "555040",
    "end": "558399"
  },
  {
    "text": "it essentially does those",
    "start": "558399",
    "end": "561360"
  },
  {
    "text": "multi-step aggregations and it at each",
    "start": "561360",
    "end": "564080"
  },
  {
    "text": "step it basically can do a hop within um",
    "start": "564080",
    "end": "567519"
  },
  {
    "text": "the cluster itself so i can spread that",
    "start": "567519",
    "end": "569279"
  },
  {
    "text": "load for really high cardinality",
    "start": "569279",
    "end": "570640"
  },
  {
    "text": "workloads over multiple nodes and then",
    "start": "570640",
    "end": "572959"
  },
  {
    "text": "this is all happening in memory and then",
    "start": "572959",
    "end": "574480"
  },
  {
    "text": "eventually it rewrites the",
    "start": "574480",
    "end": "576880"
  },
  {
    "text": "results of storage uh and you we can do",
    "start": "576880",
    "end": "579360"
  },
  {
    "text": "this now uh with m3 as a v 1.3 with any",
    "start": "579360",
    "end": "583519"
  },
  {
    "text": "uh",
    "start": "583519",
    "end": "584560"
  },
  {
    "text": "prometheus remote right the receiver so",
    "start": "584560",
    "end": "586880"
  },
  {
    "text": "this is not just an m3db feature you can",
    "start": "586880",
    "end": "590000"
  },
  {
    "text": "combine this feature with any other",
    "start": "590000",
    "end": "591920"
  },
  {
    "text": "remote right back end",
    "start": "591920",
    "end": "594000"
  },
  {
    "text": "and so you know it's really meant to be",
    "start": "594000",
    "end": "595839"
  },
  {
    "text": "a supplement to recording rules uh it",
    "start": "595839",
    "end": "597680"
  },
  {
    "text": "saves the frequent expensive step",
    "start": "597680",
    "end": "600000"
  },
  {
    "text": "of the reverse index query the",
    "start": "600000",
    "end": "601360"
  },
  {
    "text": "restoration i need to write back",
    "start": "601360",
    "end": "604079"
  },
  {
    "text": "you can scale aggregation separate to",
    "start": "604079",
    "end": "605760"
  },
  {
    "text": "your tsdb so you allow your tftb to",
    "start": "605760",
    "end": "607920"
  },
  {
    "text": "focus on executing alerts and dashboards",
    "start": "607920",
    "end": "611200"
  },
  {
    "text": "and you you can aggregate millions of",
    "start": "611200",
    "end": "613120"
  },
  {
    "text": "series because you can spread it over a",
    "start": "613120",
    "end": "615680"
  },
  {
    "text": "large number of uh distinct resources",
    "start": "615680",
    "end": "618800"
  },
  {
    "text": "that",
    "start": "618800",
    "end": "620160"
  },
  {
    "text": "basically handle some parts of the",
    "start": "620160",
    "end": "622160"
  },
  {
    "text": "space",
    "start": "622160",
    "end": "623040"
  },
  {
    "text": "and so yeah and you can also use",
    "start": "623040",
    "end": "625279"
  },
  {
    "text": "template aggregation rules to basically",
    "start": "625279",
    "end": "627440"
  },
  {
    "text": "apply to many distinct metric names you",
    "start": "627440",
    "end": "629760"
  },
  {
    "text": "don't need to write a rule every single",
    "start": "629760",
    "end": "631279"
  },
  {
    "text": "time you want to do aggregation",
    "start": "631279",
    "end": "634000"
  },
  {
    "text": "and this was just a single metric you",
    "start": "634000",
    "end": "635519"
  },
  {
    "text": "know and if you remove and just look at",
    "start": "635519",
    "end": "636959"
  },
  {
    "text": "one service there's only 3 000 unique",
    "start": "636959",
    "end": "638880"
  },
  {
    "text": "time series here",
    "start": "638880",
    "end": "640720"
  },
  {
    "text": "very doable to scale up and look at",
    "start": "640720",
    "end": "642640"
  },
  {
    "text": "those metrics on the fly or as alerts",
    "start": "642640",
    "end": "645920"
  },
  {
    "text": "but if you want to learn more um our",
    "start": "645920",
    "end": "647440"
  },
  {
    "text": "session's at 3 25 pm today uh thank you",
    "start": "647440",
    "end": "649760"
  },
  {
    "text": "so much for having me here it's it's",
    "start": "649760",
    "end": "651200"
  },
  {
    "text": "been a it's been great to be back in",
    "start": "651200",
    "end": "652640"
  },
  {
    "text": "person thank you",
    "start": "652640",
    "end": "654240"
  },
  {
    "text": "wonderful thank you",
    "start": "654240",
    "end": "655760"
  },
  {
    "text": "and i know i have a couple questions but",
    "start": "655760",
    "end": "657920"
  },
  {
    "text": "that'll probably come for the session",
    "start": "657920",
    "end": "659200"
  },
  {
    "text": "later",
    "start": "659200",
    "end": "661600"
  }
]
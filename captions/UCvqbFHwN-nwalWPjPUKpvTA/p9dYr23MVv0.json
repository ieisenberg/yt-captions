[
  {
    "text": "thank you everyone my name is Matt Grossman and I'm here from Lyft to talk",
    "start": "1500",
    "end": "6540"
  },
  {
    "text": "about how we have used Envoy to rethink microservice development",
    "start": "6540",
    "end": "12679"
  },
  {
    "text": "so I actually I don't work with JP over on uh Envoy mobile I don't work with",
    "start": "12960",
    "end": "18840"
  },
  {
    "text": "Matt on other parts of envoy I'm actually part of the developer experience org at Lyft our goal we're",
    "start": "18840",
    "end": "24600"
  },
  {
    "text": "we're not networking we're not observability our goal is to make it so our teams our product developers are as",
    "start": "24600",
    "end": "31500"
  },
  {
    "text": "fast and safe as possible when they have a change that they have made and they want to feel confident in pushing it out",
    "start": "31500",
    "end": "36660"
  },
  {
    "text": "to production so I'm going to take us through the very systems that we've had at Lyft different",
    "start": "36660",
    "end": "43379"
  },
  {
    "text": "developer environments that we've had the problems we've run into them and how we've pivoted to using a system that uses Envoy to hopefully make that system",
    "start": "43379",
    "end": "49980"
  },
  {
    "text": "uh faster and better for Developers so if we Rewind by like two years",
    "start": "49980",
    "end": "55560"
  },
  {
    "text": "[Music] um this is what our change pipeline used to look like when a developer had some modification that they wanted to get out",
    "start": "55560",
    "end": "61680"
  },
  {
    "text": "to prod in development each user would have their own what we'd call a one box which was basically just a very large",
    "start": "61680",
    "end": "68820"
  },
  {
    "text": "ec2 instance and this would run the entirety of the lift system they would",
    "start": "68820",
    "end": "75240"
  },
  {
    "text": "change whatever amount that they want in their services is completely sandboxed in when they were done and they felt",
    "start": "75240",
    "end": "80700"
  },
  {
    "text": "confident in their change they would create a pull request get that plus one by a teammate and then take it out to our staging and production kubernetes",
    "start": "80700",
    "end": "87060"
  },
  {
    "text": "clusters so notably the development and staging and production run on very different Stacks here development our",
    "start": "87060",
    "end": "93960"
  },
  {
    "text": "one box is totally separate versus our kubernetes staging production were quite similar other than just like a couple",
    "start": "93960",
    "end": "99659"
  },
  {
    "text": "changes of course on with the data flowed like Etc so just to zoom in a little bit more",
    "start": "99659",
    "end": "105180"
  },
  {
    "text": "about what one box was like I said really large ec2s when a user want to",
    "start": "105180",
    "end": "111659"
  },
  {
    "text": "make change they would just make the modifications locally on their own machine then they would sync from their local to the remote and we'd kind of do",
    "start": "111659",
    "end": "119579"
  },
  {
    "text": "some hot reloading and the big thing was that because they were so large they could run every single service that left",
    "start": "119579",
    "end": "127200"
  },
  {
    "text": "um that worked for a really long time especially as we moved from a monolith to microservices at first we didn't have",
    "start": "127200",
    "end": "133020"
  },
  {
    "text": "that many but eventually we ran into problems um one of the problems with this type of development where each user got their",
    "start": "133020",
    "end": "139379"
  },
  {
    "text": "own ec2 was it would scale by End by services so of course this lift grew we",
    "start": "139379",
    "end": "144840"
  },
  {
    "text": "got a lot more Engineers which means we needed a lot more one boxes to give out to everyone also as Lyft grew the amount",
    "start": "144840",
    "end": "150959"
  },
  {
    "text": "of services that we needed and we're running and we're creating were much higher too so uh the one boxes that we",
    "start": "150959",
    "end": "156660"
  },
  {
    "text": "needed needed to be larger so it was just not a great uh scaling complexity",
    "start": "156660",
    "end": "162180"
  },
  {
    "text": "another large bomb that we ran into with one box was like I said it was very different than our kubernetes staging",
    "start": "162180",
    "end": "168540"
  },
  {
    "text": "and production environments so we have these issues with environment drift where something would work great in",
    "start": "168540",
    "end": "174120"
  },
  {
    "text": "development but then it would get deployed out to staging or production and we'd run into some sort of strange issues due to the system that was built",
    "start": "174120",
    "end": "180660"
  },
  {
    "text": "on top of sometimes the other problem would happen too where someone would put out a change not realized until later",
    "start": "180660",
    "end": "186540"
  },
  {
    "text": "that it was broken in development and then this caused issues with unclear ownership so our team the developer",
    "start": "186540",
    "end": "192959"
  },
  {
    "text": "experience team owned one box so when something would go wrong in development but it was working in other environments",
    "start": "192959",
    "end": "198420"
  },
  {
    "text": "they would kind of point fingers at us but we're not experts on every single person service so we would kind of have",
    "start": "198420",
    "end": "205140"
  },
  {
    "text": "to rely on the service owners and they of course wouldn't really feel responsibility themselves because they",
    "start": "205140",
    "end": "210300"
  },
  {
    "text": "weren't sure what they did wrong and it seemed working to them so a combination of these changes or",
    "start": "210300",
    "end": "215640"
  },
  {
    "text": "these problems is um what led to this unfortunately normal workflow that a lot of developers would end up doing",
    "start": "215640",
    "end": "221640"
  },
  {
    "text": "uh first they would provision one of these one boxes they would run a command by sshing into it that would spin up a",
    "start": "221640",
    "end": "227700"
  },
  {
    "text": "whole bunch of different containers and uh oftentimes that could take over an hour Sometimes some of those container",
    "start": "227700",
    "end": "233459"
  },
  {
    "text": "starts would fail so they would end up having to reprovision it and then eventually they would just give up and deploy and test and staging where",
    "start": "233459",
    "end": "239459"
  },
  {
    "text": "they're a lot more confident that things worked as expected this of course was a problem this is not a great developer",
    "start": "239459",
    "end": "245519"
  },
  {
    "text": "environment and because of that we you know decided we need to kind of",
    "start": "245519",
    "end": "251939"
  },
  {
    "text": "go back to the drawing board and figure out a better arrangement so that's what led us to the solution",
    "start": "251939",
    "end": "257280"
  },
  {
    "text": "where we are sharing a developer environment so in that last step that I said uh what's so wrong with deploying",
    "start": "257280",
    "end": "263580"
  },
  {
    "text": "to staging uh if we ended up doing that staging is not so bad it's a it's a real",
    "start": "263580",
    "end": "268979"
  },
  {
    "text": "environment it's very similar to production um staging has a bunch of great advantages actually it's like I said",
    "start": "268979",
    "end": "275040"
  },
  {
    "text": "very production-like at Lyft we had this whole system where we would have all these simulated rides that were sending",
    "start": "275040",
    "end": "280680"
  },
  {
    "text": "Ingress traffic so we kind of when you deploy out to staging you'd get some traffic that exercises your new code",
    "start": "280680",
    "end": "286860"
  },
  {
    "text": "paths so you kind of gain some confidence in it and then also teams really cared about maintaining the slos",
    "start": "286860",
    "end": "292199"
  },
  {
    "text": "and making sure that if their service was broken staging they went and actually fixed it they would get paged about it and uh you know if they would",
    "start": "292199",
    "end": "298800"
  },
  {
    "text": "peeve a bunch of people so of course they're going back and fixing it um so those are advantages but of course",
    "start": "298800",
    "end": "304560"
  },
  {
    "text": "staging also had some problems uh if you wanted to use it as a developer environment one of them was like I said",
    "start": "304560",
    "end": "311400"
  },
  {
    "text": "a broken service in staging might mean many uh transitive dependencies are also",
    "start": "311400",
    "end": "317639"
  },
  {
    "text": "broken they you deploy something bad you know your many calls Upstream from them but they are suddenly paging themselves",
    "start": "317639",
    "end": "324419"
  },
  {
    "text": "and like oh it's because someone on this other team in a far-flung org deployed and that's not great",
    "start": "324419",
    "end": "329940"
  },
  {
    "text": "um uh also because there was this one core version that was running on staging",
    "start": "329940",
    "end": "335039"
  },
  {
    "text": "for a given service [Music] um if teammates wanted to collaborate and",
    "start": "335039",
    "end": "340620"
  },
  {
    "text": "work on the same service but maybe they had their own branches that they wanted to test it wasn't super straightforward uh perhaps they would have to kind of",
    "start": "340620",
    "end": "347400"
  },
  {
    "text": "take turns and say hey I'm testing this in staging can you wait an hour I gotta wrap this up make sure it works as expected and so of course that slows",
    "start": "347400",
    "end": "354419"
  },
  {
    "text": "down Edge velocity and then lastly deploying something to staging was kind of more complicated than testing",
    "start": "354419",
    "end": "361139"
  },
  {
    "text": "something in development so Elise at Lyft deploying to staging was really just the final step before",
    "start": "361139",
    "end": "368039"
  },
  {
    "text": "you deployed a production so you'd have to create a pull request get a plus one from a teammate saying that the code works as expected uh run through all the",
    "start": "368039",
    "end": "374520"
  },
  {
    "text": "CI checks Etc and then start to deploy pipeline so all of those problems with staging",
    "start": "374520",
    "end": "381479"
  },
  {
    "text": "um kind of led us to realize that we can't just use as is we needed to make some modifications to our existing shared",
    "start": "381479",
    "end": "387360"
  },
  {
    "text": "environment and to do that we created the system called staging overrides that gives us a lot of the advantages of a shared environment for development but",
    "start": "387360",
    "end": "394259"
  },
  {
    "text": "it fixes a lot of the problems that we had with isolation so that was our overall goal and this is",
    "start": "394259",
    "end": "400380"
  },
  {
    "text": "kind of like a very high level picture of what staging overrides looks like um first uh users make requests to the",
    "start": "400380",
    "end": "407160"
  },
  {
    "text": "core staging environment but they have their own instance what we call an offloaded pod that contains just their",
    "start": "407160",
    "end": "413520"
  },
  {
    "text": "changes so when they are done with their changes they don't have to fully merge it they just need to get it up and make",
    "start": "413520",
    "end": "419160"
  },
  {
    "text": "a container image build from it they can deploy it to the staging mesh and from there it kind of lives in staging just",
    "start": "419160",
    "end": "425759"
  },
  {
    "text": "like anything else but notably it does not receive traffic from any other people who are testing and staging so",
    "start": "425759",
    "end": "431639"
  },
  {
    "text": "this fixes a lot of those problems of teammates stepping on each other's toes um the next part of staging overrides is",
    "start": "431639",
    "end": "438720"
  },
  {
    "text": "this override metadata now of course we don't want random strangers and staging",
    "start": "438720",
    "end": "444060"
  },
  {
    "text": "designers uh product who are testing to hit your potentially buggy code but we",
    "start": "444060",
    "end": "449280"
  },
  {
    "text": "do want you to hit it so you can make sure you're confident so to do that we had to embed metadata within the request",
    "start": "449280",
    "end": "454319"
  },
  {
    "text": "that kind of informs us how to do this type of routing and make you get offloaded to your or get sent to your",
    "start": "454319",
    "end": "461099"
  },
  {
    "text": "offloaded pod in this case the fraud service and that's kind of like the last part that brings us all together is what we",
    "start": "461099",
    "end": "467940"
  },
  {
    "text": "call routing override and sometimes called just overriding override based development where once we",
    "start": "467940",
    "end": "476220"
  },
  {
    "text": "know that this request has the metadata that says we want to do a test version we need to actually act on that and",
    "start": "476220",
    "end": "481680"
  },
  {
    "text": "Route kind of dynamically and appropriately to the Pod that you specified so those are kind of like the main",
    "start": "481680",
    "end": "488160"
  },
  {
    "text": "components that make up the system they call staging overrides um first is these unregistered offloaded pods the way we",
    "start": "488160",
    "end": "493919"
  },
  {
    "text": "do that is um we use an XDS control plane that we",
    "start": "493919",
    "end": "499379"
  },
  {
    "text": "have and we have some like very simple logic that does some endpoint Discovery service exclusion the next part is that",
    "start": "499379",
    "end": "506520"
  },
  {
    "text": "propagated override metadata for that we use envoys distributed",
    "start": "506520",
    "end": "511979"
  },
  {
    "text": "tracing technology they have built in as we just saw from University of Illinois they have a concept in there called baggage that'll dig into a little bit",
    "start": "511979",
    "end": "518099"
  },
  {
    "text": "further that lets us propagate this data and then lastly are the actual overrides",
    "start": "518099",
    "end": "523440"
  },
  {
    "text": "that act upon this data which are a custom filter that we wrote in Envoy as well as a cluster called the original",
    "start": "523440",
    "end": "529920"
  },
  {
    "text": "destination cluster or original DST so in the next couple minutes I'll just",
    "start": "529920",
    "end": "535140"
  },
  {
    "text": "kind of talk about all these different pieces and and how they work and how we kind of all combine them together to do this",
    "start": "535140",
    "end": "541500"
  },
  {
    "text": "so first is offloaded pods I would say this is probably the more straightforward part to do this we",
    "start": "541500",
    "end": "547380"
  },
  {
    "text": "created GitHub bot for um all of our users who are ended up putting up pull requests they could just",
    "start": "547380",
    "end": "553440"
  },
  {
    "text": "type slash offload and once their container image had finished building they would end up",
    "start": "553440",
    "end": "559640"
  },
  {
    "text": "it would start a new deploy a new deployment in our kubernetes staging cluster and this deployment uh that had",
    "start": "559640",
    "end": "566640"
  },
  {
    "text": "the Pod inside would be labeled specifically with this offloaded deploy equals true label so that's really all",
    "start": "566640",
    "end": "572459"
  },
  {
    "text": "we have to do on the deploy side to modify it and kind of wire that up with some amount of bots but then in our",
    "start": "572459",
    "end": "579720"
  },
  {
    "text": "control plane we're processing these Kate's events and sending out EDS to all",
    "start": "579720",
    "end": "584760"
  },
  {
    "text": "of our sidecar mash and telling them like hey here's a routable instance of the pay service we wanted to make sure",
    "start": "584760",
    "end": "589920"
  },
  {
    "text": "we didn't do that if we had just done an offloaded deploy so this in this very very simple pseudocode you can just",
    "start": "589920",
    "end": "595500"
  },
  {
    "text": "imagine that if we saw this pod as an event that popped up in our mesh we would just kind of skip over it so this",
    "start": "595500",
    "end": "601860"
  },
  {
    "text": "on its own simply deploying a pod into staging which is the same environment that others are comfortable testing in",
    "start": "601860",
    "end": "607920"
  },
  {
    "text": "actually provided some benefits and people just wanted to SSH into a pod run a script and kind of have confidence",
    "start": "607920",
    "end": "614640"
  },
  {
    "text": "that what they're doing was working they didn't need any Ingress traffic but of course the the power comes when you",
    "start": "614640",
    "end": "620760"
  },
  {
    "text": "actually can choose to route to that pod and to do that we needed to use some of this override metadata so here's kind of",
    "start": "620760",
    "end": "627480"
  },
  {
    "text": "just an example of what this metadata would look like you can imagine that in the metadata",
    "start": "627480",
    "end": "632760"
  },
  {
    "text": "that's within the request we say what the Upstream cluster which lifts is you",
    "start": "632760",
    "end": "637920"
  },
  {
    "text": "know roughly the service that we're trying to override as well as the IP address of that cluster so here it's pay",
    "start": "637920",
    "end": "644220"
  },
  {
    "text": "and the IP is 1.2.3.4 so let's dig a little bit more into that override metadata it doesn't have to be",
    "start": "644220",
    "end": "651480"
  },
  {
    "text": "very complicated um we technically we have some protobuf but you know really just a Json blob",
    "start": "651480",
    "end": "657240"
  },
  {
    "text": "that looks like this if you have some set of overrides that you want to apply throughout the duration of the request you just say hey this service in",
    "start": "657240",
    "end": "663480"
  },
  {
    "text": "particular rather than going to the Blessed version that's running on staging go to this IP colon port instead",
    "start": "663480",
    "end": "669740"
  },
  {
    "text": "so this is what we wanted the data to look like because we knew this was everything we needed to do our routing",
    "start": "669740",
    "end": "674760"
  },
  {
    "text": "the question was where did we actually put this data and make sure that it was always available",
    "start": "674760",
    "end": "679920"
  },
  {
    "text": "so to do that we leverage our existing setup at lift for distributed tracing",
    "start": "679920",
    "end": "685980"
  },
  {
    "text": "um distributed tracing as we just learned about in our chat makes it really easy to basically collect a whole",
    "start": "685980",
    "end": "692519"
  },
  {
    "text": "bunch of data about how our requests flowed end to end and uh at Lyft we have",
    "start": "692519",
    "end": "698220"
  },
  {
    "text": "a pretty good setup with header propagation it's not perfect but",
    "start": "698220",
    "end": "703760"
  },
  {
    "text": "collectively uh you know we use this Trace data for normal tracing requests you know our mesh kind of looks",
    "start": "703760",
    "end": "710040"
  },
  {
    "text": "something like that whiteboard and we use it for observability's sake which is traditionally what it's been",
    "start": "710040",
    "end": "715560"
  },
  {
    "text": "used for but we also use it like the fact that we got all of this header already",
    "start": "715560",
    "end": "721620"
  },
  {
    "text": "propagating was really useful for us because within this open tracing data and we're using open tracing open slam",
    "start": "721620",
    "end": "728339"
  },
  {
    "text": "and choose the new standard but for the most part they kind of work the same for what we're doing",
    "start": "728339",
    "end": "734040"
  },
  {
    "text": "um we were able to embed a special field within the header called baggage which a",
    "start": "734040",
    "end": "739140"
  },
  {
    "text": "lot of the time the metadata from your spans within a given Trace are kind of local only to that span and then they",
    "start": "739140",
    "end": "746820"
  },
  {
    "text": "don't also get propagated to any further upstreams in the call graph but baggage is special in that it is information you",
    "start": "746820",
    "end": "754019"
  },
  {
    "text": "embed once and it gets propagated across process lines so for us that's super useful because all we need to do is",
    "start": "754019",
    "end": "760380"
  },
  {
    "text": "really early in the request line take this metadata encapsulate it and Chuck it into our baggage field such that it",
    "start": "760380",
    "end": "767220"
  },
  {
    "text": "can be propagated throughout the whole request so now that we have the metadata that's",
    "start": "767220",
    "end": "774720"
  },
  {
    "text": "been propagated we have our offloaded pods we need to build the networking magic that'll actually act upon that",
    "start": "774720",
    "end": "780839"
  },
  {
    "text": "metadata and send us to the Pod we're interested in so uh very high level overview of envoy",
    "start": "780839",
    "end": "787079"
  },
  {
    "text": "lift pretty standard stuff each service is deployed alongside a sidecar Envoy it's a container within a pod for each",
    "start": "787079",
    "end": "794399"
  },
  {
    "text": "service and this container handles all Ingress to the service as well as egress which historically provides all the",
    "start": "794399",
    "end": "801120"
  },
  {
    "text": "benefits you would expect out of envoy you know the observability super simple for applications you don't need to think much about networking but for our",
    "start": "801120",
    "end": "808620"
  },
  {
    "text": "specific use case it's great that we knew every service was deployed alongside these sidecars because it really gave us a hook that we can",
    "start": "808620",
    "end": "815399"
  },
  {
    "text": "Implement and kind of intercept all of the routing that normally happens so to do that we used envoys HTTP filter",
    "start": "815399",
    "end": "823320"
  },
  {
    "text": "subsystem so we modified and created our own filter that",
    "start": "823320",
    "end": "830700"
  },
  {
    "text": "then we injected into every single one of the sidecars that is deployed at Lyft and basically what we need this HTTP",
    "start": "830700",
    "end": "837060"
  },
  {
    "text": "filter to do is mutate how we end up doing that routing and how we choose",
    "start": "837060",
    "end": "842399"
  },
  {
    "text": "what our Upstream endpoint is just before we were about to go to whatever was normally on staging",
    "start": "842399",
    "end": "850139"
  },
  {
    "text": "so at a really high level the filter logic is we extract the information",
    "start": "850139",
    "end": "855480"
  },
  {
    "text": "outside of the baggage which is generally just service IP pairs like I showed before",
    "start": "855480",
    "end": "860880"
  },
  {
    "text": "uh we see if any of the overrides within that baggage match where we are about to",
    "start": "860880",
    "end": "866700"
  },
  {
    "text": "route to by the time this HTTP filter is run we already know where Envoy intends ongoing it's already chosen that based",
    "start": "866700",
    "end": "873420"
  },
  {
    "text": "on host header based on uh paths Etc and if there's a match between what is in",
    "start": "873420",
    "end": "879660"
  },
  {
    "text": "the overrides and where we want to and where we plan on going we should",
    "start": "879660",
    "end": "884880"
  },
  {
    "text": "basically kind of like block that part of the routing and go to that IP address instead",
    "start": "884880",
    "end": "890579"
  },
  {
    "text": "so uh here is a very very high level C plus plus overview of what the filter",
    "start": "890579",
    "end": "896100"
  },
  {
    "text": "looks like I'm not going to walk you through it entirely today if you're interested you can go download the",
    "start": "896100",
    "end": "901380"
  },
  {
    "text": "slides later and check out all the code but I'm going to walk you just through the real key components that kind of make it tick the first part is what",
    "start": "901380",
    "end": "909120"
  },
  {
    "text": "we've been talking about which was because Envoy has first class support for tracing all we have to do is when we",
    "start": "909120",
    "end": "916019"
  },
  {
    "text": "Define our HTTP filter we say we get all these callbacks that gives us access to",
    "start": "916019",
    "end": "921720"
  },
  {
    "text": "things like the current Envoy span and then from there all we have to do is get baggage and pass it the key that you want so you can imagine having posted",
    "start": "921720",
    "end": "929160"
  },
  {
    "text": "our override metadata within the baggage overrides key we just call this get baggage bring it out and then parse it",
    "start": "929160",
    "end": "936120"
  },
  {
    "text": "into whatever data structure that you want to represent it in so we have a protobuf here that we parse it",
    "start": "936120",
    "end": "943440"
  },
  {
    "text": "um this next part's a little hairy but uh based on the way the HTTP filters work with routing within Envoy",
    "start": "943440",
    "end": "950760"
  },
  {
    "text": "um we can't just straight up mutate what Upstream cluster we send it to in this case",
    "start": "950760",
    "end": "956459"
  },
  {
    "text": "um you know you can imagine if we were sending it to the pay cluster originally we want to go to a different cluster",
    "start": "956459",
    "end": "961620"
  },
  {
    "text": "instead so what we end up having to do is take that existing cluster and wrap",
    "start": "961620",
    "end": "966899"
  },
  {
    "text": "around it in this thing called the delegating route that we kind of had to subclass and uh when we do that we can",
    "start": "966899",
    "end": "972779"
  },
  {
    "text": "provide the cluster that we want to go to instead so the question is okay we don't want to go to the normal pay",
    "start": "972779",
    "end": "978180"
  },
  {
    "text": "cluster because the normal pay cluster has all of the endpoints that weren't skipped over it has the true endpoints",
    "start": "978180",
    "end": "984180"
  },
  {
    "text": "that are really deployed in staging it's the ones that you know we want that are safe and blessed and work well so what",
    "start": "984180",
    "end": "990300"
  },
  {
    "text": "we want to do is send it to this other cluster called an original destination cluster so the original destination cluster",
    "start": "990300",
    "end": "996540"
  },
  {
    "text": "sometimes called the original DST has a special header a configuration called use HTTP header and when that is enabled",
    "start": "996540",
    "end": "1004339"
  },
  {
    "text": "if a request gets sent to this cluster with this header x dash Envoy Dash original DST host which you see at the",
    "start": "1004339",
    "end": "1010880"
  },
  {
    "text": "bottom with the IP address colon Port Envoy will take the IP address and Port",
    "start": "1010880",
    "end": "1016820"
  },
  {
    "text": "of that header and route to that instead of um you know wherever it's going",
    "start": "1016820",
    "end": "1023020"
  },
  {
    "text": "instead of that so coming back to the filter you can",
    "start": "1023020",
    "end": "1028339"
  },
  {
    "text": "imagine what we had to do was when we overwrote the cluster that we were doing our routing to in the filter we send it",
    "start": "1028339",
    "end": "1035480"
  },
  {
    "text": "to the original destination cluster instead and then we also add in a new HTTP header and that HTTP header is the",
    "start": "1035480",
    "end": "1042620"
  },
  {
    "text": "envoy original DST host and we also just add in that IP address that we kind of extracted out of the baggage earlier",
    "start": "1042620",
    "end": "1050000"
  },
  {
    "text": "and uh that's it not too hard of course a lot of error handling and other things",
    "start": "1050000",
    "end": "1055460"
  },
  {
    "text": "like that that we didn't end up doing as a real high level overview our steps there were take out the overrides from",
    "start": "1055460",
    "end": "1062780"
  },
  {
    "text": "the baggage from the tracing header take that route wrap it in this delegating route and make it so that for the most",
    "start": "1062780",
    "end": "1069320"
  },
  {
    "text": "part all attributes about this route are exactly the same as the one Envoy has already chosen but except the cluster",
    "start": "1069320",
    "end": "1075260"
  },
  {
    "text": "name for the cluster name we want to send it to the original destination cluster then we want to set the route to this",
    "start": "1075260",
    "end": "1081679"
  },
  {
    "text": "new route we just created and finally add in the IP address from the metadata we got from within the override baggage",
    "start": "1081679",
    "end": "1089559"
  },
  {
    "text": "and with that I would call that our staging overrides V1 that was a system",
    "start": "1089720",
    "end": "1095299"
  },
  {
    "text": "it took you know a year and a half or something to Pivot from this one box system and we did this a while ago and",
    "start": "1095299",
    "end": "1101419"
  },
  {
    "text": "we were really happy where where this got us you can see here you know",
    "start": "1101419",
    "end": "1106460"
  },
  {
    "text": "developers can keep sending requests to staging just like they normally would developers or product managers data",
    "start": "1106460",
    "end": "1112160"
  },
  {
    "text": "science anyone who's just trying to test something see how something looks all the while they are kind of blissfully unaware that there's all of this testing",
    "start": "1112160",
    "end": "1118640"
  },
  {
    "text": "happening around them because it's not affecting their requests it's just affecting the requests of people who are explicitly opting into these new routing",
    "start": "1118640",
    "end": "1125660"
  },
  {
    "text": "rules so now I'd like to talk a little bit more about some of the stuff that we have done on top of it as where we kind",
    "start": "1125660",
    "end": "1131900"
  },
  {
    "text": "of want to go next now that we've built this base system so one thing I kind of hand waved over",
    "start": "1131900",
    "end": "1137780"
  },
  {
    "text": "at the beginning is how do we actually get that baggage onto the request in the first place uh and the kind of we call",
    "start": "1137780",
    "end": "1144380"
  },
  {
    "text": "that baggage attachment tooling to do that we ideally don't want our",
    "start": "1144380",
    "end": "1149780"
  },
  {
    "text": "developers thinking about how do I manually craft this IP address",
    "start": "1149780",
    "end": "1155000"
  },
  {
    "text": "Json blob and tuck it onto every single request we kind of want that to be abstracted away from them",
    "start": "1155000",
    "end": "1160160"
  },
  {
    "text": "so there's a couple different ways that we thought about this but ideally the way we want our customers which are",
    "start": "1160160",
    "end": "1165500"
  },
  {
    "text": "other developers that lift to think about it is I have a pull request I've deployed this pull request into staging",
    "start": "1165500",
    "end": "1171320"
  },
  {
    "text": "uh given that this was the pull request of the changes give me the baggage and attach this baggage with the routes me",
    "start": "1171320",
    "end": "1177679"
  },
  {
    "text": "to it I don't really care about any other details besides that so we've actually worked on a couple different",
    "start": "1177679",
    "end": "1182900"
  },
  {
    "text": "ways to baggage attachment these first two are kind of examples of if we add another filter up front at the edge only",
    "start": "1182900",
    "end": "1190100"
  },
  {
    "text": "living on the edge not necessarily in the mesh um we could basically have it decode",
    "start": "1190100",
    "end": "1196039"
  },
  {
    "text": "some information either from a header or from the host name that kind of gives us all of the characteristics we need to",
    "start": "1196039",
    "end": "1202039"
  },
  {
    "text": "know about to determine what baggage we should attach but there's this one other option that we actually originally",
    "start": "1202039",
    "end": "1208039"
  },
  {
    "text": "started with and are still using today which is we send it through a proxy and this is great because if we intercept",
    "start": "1208039",
    "end": "1213559"
  },
  {
    "text": "the request that the user send we have all sorts of control to add in whatever data we want before it makes its way",
    "start": "1213559",
    "end": "1218660"
  },
  {
    "text": "Upstream so the proxy we have is our own in homegrown proxy we'd love to open",
    "start": "1218660",
    "end": "1223940"
  },
  {
    "text": "source it someday and maybe we'll get to that originally we created this progress this scriptable Ingress proxy for mobile",
    "start": "1223940",
    "end": "1231380"
  },
  {
    "text": "Engineers to mock out backends so rather than pointing their mobile apps at staging they would point it at this",
    "start": "1231380",
    "end": "1237919"
  },
  {
    "text": "proxy and then they could write all sorts of scripts against it that let them you know if the back end hadn't",
    "start": "1237919",
    "end": "1243860"
  },
  {
    "text": "completed it yet return back some dummy Json data or something like that and that kind of allowed the product Engineers who are both mobile and",
    "start": "1243860",
    "end": "1250220"
  },
  {
    "text": "back-end to work concurrently after they kind of agreed upon a contract of what the response body would look like",
    "start": "1250220",
    "end": "1256039"
  },
  {
    "text": "so this is what we ended up using is we just tell our developers to point their",
    "start": "1256039",
    "end": "1261559"
  },
  {
    "text": "browsers at their own proxy and um that is what they do today right now",
    "start": "1261559",
    "end": "1267860"
  },
  {
    "text": "they they say they Point their app to say let me talk to this scriptable proxy this proxy has all of the information it",
    "start": "1267860",
    "end": "1273620"
  },
  {
    "text": "needs to know once I've configured it and it will attach the baggage before it ends up sending it off to the rest of staging so we because we already have",
    "start": "1273620",
    "end": "1281840"
  },
  {
    "text": "this proxy which was very fortunate for us we kind of took what we already had and took the easiest path to getting",
    "start": "1281840",
    "end": "1287539"
  },
  {
    "text": "this working for our users so we just kind of defined like a helper type script snippet that says I want my all",
    "start": "1287539",
    "end": "1294500"
  },
  {
    "text": "of my requests that flow through the proxy to have these Envoy overrides here's my project here's my branch and",
    "start": "1294500",
    "end": "1301940"
  },
  {
    "text": "our proxy would be responsible for figuring out what was in the metadata and you can see here it's talking to the Kates API server and that gets back all",
    "start": "1301940",
    "end": "1308900"
  },
  {
    "text": "the information it needs to to fill in that metadata um so given that we've built all of that",
    "start": "1308900",
    "end": "1316520"
  },
  {
    "text": "so far we still think there's a lot more we could do with this General overrides driven development",
    "start": "1316520",
    "end": "1321860"
  },
  {
    "text": "um so like we already have this proxy that knows how to interact with baggage what if we uh Chuck that proxy",
    "start": "1321860",
    "end": "1330440"
  },
  {
    "text": "into the middle of the call graph as opposed to one of these offloaded pods now we have this wildly configurable and",
    "start": "1330440",
    "end": "1337640"
  },
  {
    "text": "scriptable solution that lets us kind of play with and Fiddle with requests before they actually go to their",
    "start": "1337640",
    "end": "1342919"
  },
  {
    "text": "upstreams it could work you know test what something would look like assuming an upstream was airing out you can do",
    "start": "1342919",
    "end": "1349400"
  },
  {
    "text": "all sorts of wild scripting like this and it really gives you mocking at any hop in the mesh as opposed to just at",
    "start": "1349400",
    "end": "1355100"
  },
  {
    "text": "the Ingress Edge another thing we've been exploring is what if we redirect the traffic to",
    "start": "1355100",
    "end": "1360799"
  },
  {
    "text": "laptops rather than just going to offloaded pods that have been deployed to staging uh if we embed something in",
    "start": "1360799",
    "end": "1367460"
  },
  {
    "text": "the metadata that lets you redirect to your own laptop you could do this much faster PR iteration cycle you don't have",
    "start": "1367460",
    "end": "1373640"
  },
  {
    "text": "to push up a pull request you don't have to wait for container image build and you don't have to wait for a deploy you can just hit it straight to your own",
    "start": "1373640",
    "end": "1378980"
  },
  {
    "text": "computer and another extension that we've been playing with and we have some of this",
    "start": "1378980",
    "end": "1384140"
  },
  {
    "text": "and we just keep adding more is what else could we include in this baggage for example what if we include something",
    "start": "1384140",
    "end": "1390260"
  },
  {
    "text": "that said like log level debug and that will very temporarily only for the duration of your request increase the",
    "start": "1390260",
    "end": "1397280"
  },
  {
    "text": "verbosity of all the logs so you know something that might not be showing up you just need to add a little bit more metadata and this is sufficient",
    "start": "1397280",
    "end": "1403159"
  },
  {
    "text": "optionally you could turn on feature flags that are only valid for your request so I think that these things about that",
    "start": "1403159",
    "end": "1410840"
  },
  {
    "text": "we what we could do with staging overrides I think kind of are the the full vision here we want to give complete control over request flow to",
    "start": "1410840",
    "end": "1417320"
  },
  {
    "text": "our developers uh this will make them feel like they have all the knobs and levers they have so they can reproduce",
    "start": "1417320",
    "end": "1422480"
  },
  {
    "text": "all their Arrangements make sure that they feel confident that they've tested everything comprehensively all the",
    "start": "1422480",
    "end": "1428780"
  },
  {
    "text": "different arrangements before they end up sending it to real staging and more importantly to production and of course",
    "start": "1428780",
    "end": "1434059"
  },
  {
    "text": "when we do this we want to make sure it's fully isolated we want to make sure that developers aren't stepping on each other's toes when this happens and our",
    "start": "1434059",
    "end": "1441200"
  },
  {
    "text": "team the developer experience is responsible for giving really good tooling that lets developers think about this seamlessly and just think about",
    "start": "1441200",
    "end": "1447200"
  },
  {
    "text": "these are the changes I want to test and here um here's all you need to do that",
    "start": "1447200",
    "end": "1454039"
  },
  {
    "text": "so just wrapping up in conclusion here um overall these are really good results",
    "start": "1454039",
    "end": "1459860"
  },
  {
    "text": "compared to our last iteration of our developer environment with one box provisioning a one box would take an hour or sometimes more or it just would",
    "start": "1459860",
    "end": "1466580"
  },
  {
    "text": "never work versus getting a pull request built and pushed up to staging takes 10 minutes if that",
    "start": "1466580",
    "end": "1472480"
  },
  {
    "text": "also there's a lot more parity now between our staging and production environments than our development was",
    "start": "1472480",
    "end": "1478280"
  },
  {
    "text": "with our other environments and this is great for us because the infra is more similar so changes we make in production",
    "start": "1478280",
    "end": "1483679"
  },
  {
    "text": "often end up benefiting staging as well so we just got a lot more for free and there's also a lot more functional",
    "start": "1483679",
    "end": "1489380"
  },
  {
    "text": "parity so that way developers who push something see it work in staging overrides and then push it to production",
    "start": "1489380",
    "end": "1494840"
  },
  {
    "text": "are a lot more confident that it will work as they expect it to and then lastly we think this is just a great new",
    "start": "1494840",
    "end": "1500900"
  },
  {
    "text": "framework that has kind of changed the way our team is working we're thinking about what else can we let our developers do to make sure that they",
    "start": "1500900",
    "end": "1507200"
  },
  {
    "text": "feel confident in their changes before it goes to production and we're kind of just getting started on all the different things where we can enable",
    "start": "1507200",
    "end": "1513980"
  },
  {
    "text": "uh as far as some challenges that we ran into when we were doing this um context propagation as we talked",
    "start": "1513980",
    "end": "1519320"
  },
  {
    "text": "about in the last chat uh is challenging we need to make sure that header now it contains the trace ID but also contains",
    "start": "1519320",
    "end": "1525140"
  },
  {
    "text": "these routing rules so if you have a service that you're trying to override real deep into a call graph and",
    "start": "1525140",
    "end": "1531799"
  },
  {
    "text": "somewhere along the way that header gets dropped then it won't end up being routed to the override because it'll not",
    "start": "1531799",
    "end": "1537440"
  },
  {
    "text": "have that metadata so thankfully at Lyft we have a whole bunch of libraries that we maintain for a common you know go python typescript that we can kind of",
    "start": "1537440",
    "end": "1544940"
  },
  {
    "text": "inject our own little code into there and make sure that it does the propagation there's another General problem with data isolation we are",
    "start": "1544940",
    "end": "1551779"
  },
  {
    "text": "sharing the same staging environment so you can imagine if something is really broken in staging and starts paging and",
    "start": "1551779",
    "end": "1557960"
  },
  {
    "text": "sending a lot of stats that might actually page to on-call so we've had to do work there to sort of Ensure it gets",
    "start": "1557960",
    "end": "1564799"
  },
  {
    "text": "sent to like a different stats namespace so it doesn't trigger all these alarms that have already been set up this has",
    "start": "1564799",
    "end": "1571340"
  },
  {
    "text": "been challenging because it's a generally new paradigm we kind of had to do a whole year-long flow of reteaching",
    "start": "1571340",
    "end": "1578419"
  },
  {
    "text": "people how this is supposed to work because it's very different from the the one box you know everyone gets their own sandbox type development and lastly if",
    "start": "1578419",
    "end": "1586220"
  },
  {
    "text": "we could redo this we think there's a lot better ways even within Envoy versus original DST that we could do but",
    "start": "1586220",
    "end": "1593960"
  },
  {
    "text": "there's also other really cool Tech now like telepresence is another cncf tool that does this very similarly and you",
    "start": "1593960",
    "end": "1601159"
  },
  {
    "text": "know we would probably reassess of course we had the envoy expertise for filters in-house and we're glad to work",
    "start": "1601159",
    "end": "1606440"
  },
  {
    "text": "on that but um you know if you're interested in exploring something similar I'd be sure to check out some of those options",
    "start": "1606440",
    "end": "1613000"
  },
  {
    "text": "and that's it thank you so much [Applause]",
    "start": "1613279",
    "end": "1621740"
  },
  {
    "text": "three to six",
    "start": "1633440",
    "end": "1637000"
  },
  {
    "text": "yeah yeah the question is do we feel like we're",
    "start": "1641059",
    "end": "1646940"
  },
  {
    "text": "abusing Telemetry data um to influence how our routing works so first of all we only do this in our",
    "start": "1646940",
    "end": "1653299"
  },
  {
    "text": "staging environment I'm just going to throw that out there though I know other people who have had success on doing this in production",
    "start": "1653299",
    "end": "1659120"
  },
  {
    "text": "um so I think that originally that is what our Trace header",
    "start": "1659120",
    "end": "1665179"
  },
  {
    "text": "was used for was Telemetry and in fact we when we saw that we're like oh can we",
    "start": "1665179",
    "end": "1670940"
  },
  {
    "text": "really trust it because our distributed tracing had some sort of flakiness to it but it actually forced us to reinvest it",
    "start": "1670940",
    "end": "1676039"
  },
  {
    "text": "and it doesn't really to the way we see it is",
    "start": "1676039",
    "end": "1681320"
  },
  {
    "text": "yes that metadata is used for Telemetry but we think it can be used for more and it's worth investing in because it can",
    "start": "1681320",
    "end": "1687740"
  },
  {
    "text": "be used for more so that was why it was there originally it was great for us because it was already partially implemented it was already mostly",
    "start": "1687740",
    "end": "1694220"
  },
  {
    "text": "propagating but finding another use case where it actually could like influence",
    "start": "1694220",
    "end": "1699980"
  },
  {
    "text": "product flows was enough for us to be like okay let's really go in here let's instrument where are the services that are dropping traces how do we go fix",
    "start": "1699980",
    "end": "1706039"
  },
  {
    "text": "them how do we page them how do we make sure that they don't introduce new changes that end up dropping this header so by adding this additional",
    "start": "1706039",
    "end": "1714340"
  },
  {
    "text": "use case for this Trace header it's kind of made us go all in on propagation such",
    "start": "1714340",
    "end": "1720320"
  },
  {
    "text": "that we trust it more it's still not perfect it sells issues",
    "start": "1720320",
    "end": "1726220"
  },
  {
    "text": "thank you",
    "start": "1731120",
    "end": "1733720"
  },
  {
    "text": "yeah the question is does anyone want one box back uh which is you know our big honking ec2 instance",
    "start": "1738679",
    "end": "1746299"
  },
  {
    "text": "um so separately alongside with this where we got rid of one box there's still this was kind of our solution for",
    "start": "1746299",
    "end": "1752240"
  },
  {
    "text": "end-to-end testing to make sure that you felt like something worked um you know involving multiple Services",
    "start": "1752240",
    "end": "1758120"
  },
  {
    "text": "kind of integration testing but one box also handled the use case of local development so real quick just my own",
    "start": "1758120",
    "end": "1765559"
  },
  {
    "text": "service let me run unit tests let me really quickly iterate on it so we do when we deprecated one box we also",
    "start": "1765559",
    "end": "1772039"
  },
  {
    "text": "invested heavily in getting a really good local development experience as well and by doing that we we use like a",
    "start": "1772039",
    "end": "1778340"
  },
  {
    "text": "bunch of some other tools like tilt is one of them for like basically running Docker compose locally on your own",
    "start": "1778340",
    "end": "1784760"
  },
  {
    "text": "machine you're only limited to really running your service and we've kind of cracked down on you know you can't have",
    "start": "1784760",
    "end": "1790100"
  },
  {
    "text": "this crazy Services spend dependency on your own laptop so I think a combination of those two which is the really good",
    "start": "1790100",
    "end": "1796640"
  },
  {
    "text": "fast local Arrangement and then like a much more comprehensive and trustworthy end-to-end experience in staging kind of",
    "start": "1796640",
    "end": "1803659"
  },
  {
    "text": "covers all the gaps there's still people who do want something like that um and you know there's ways you can",
    "start": "1803659",
    "end": "1810919"
  },
  {
    "text": "kind of do it but for the most part it seems we've gone to Oregon board",
    "start": "1810919",
    "end": "1815740"
  },
  {
    "text": "definitely a lot of like evangelism internally though that we had to do you know that was certainly one of the challenges here which is just this new",
    "start": "1816080",
    "end": "1822260"
  },
  {
    "text": "paradigm it's like we had to clot away from some people effectively because they were much more confident in it or",
    "start": "1822260",
    "end": "1828260"
  },
  {
    "text": "maybe they weren't set up super well in staging like most services are",
    "start": "1828260",
    "end": "1833080"
  },
  {
    "text": "do we have a way to test our infra in staging so by infrared do you mean like when we want to change our Envoy filter",
    "start": "1837559",
    "end": "1843200"
  },
  {
    "text": "or like like observability or what parts of infra do you mean",
    "start": "1843200",
    "end": "1848860"
  },
  {
    "text": "um yeah so uh I would say this is yeah like a first class support for",
    "start": "1850640",
    "end": "1858620"
  },
  {
    "text": "um product teams who are making changes to their services and I would say making changes to infra services or like for",
    "start": "1858620",
    "end": "1865760"
  },
  {
    "text": "example that service that responds back with the baggage after you give it a pull request that we don't have a great",
    "start": "1865760",
    "end": "1872960"
  },
  {
    "text": "way of testing right now and we kind of do our own bespoke things but you know we're like the infra team so we kind of",
    "start": "1872960",
    "end": "1878720"
  },
  {
    "text": "can figure out how to we hack it onto our own and kind of do our own bespoke thing it's not great but there are like",
    "start": "1878720",
    "end": "1885320"
  },
  {
    "text": "we've been chatting a lot with the networking team about how we can make it so they can like test a new Shaw of like",
    "start": "1885320",
    "end": "1893000"
  },
  {
    "text": "our Envoy binary on like just one pod or something so like we've like been looking into little Integrations with",
    "start": "1893000",
    "end": "1898760"
  },
  {
    "text": "infra teams here and there they're all just kind of you know way less the same in the way that all these product teams",
    "start": "1898760",
    "end": "1904340"
  },
  {
    "text": "are way more like similar like stateless services so it was way more easy to uniformly introduce this for them but",
    "start": "1904340",
    "end": "1909919"
  },
  {
    "text": "then our deploys team we kind of have like a one-off thing that sort of works with this system and requires a little",
    "start": "1909919",
    "end": "1915080"
  },
  {
    "text": "bit of cube cuddle port forward and a couple other hacks like that but it can",
    "start": "1915080",
    "end": "1920779"
  },
  {
    "text": "you know should we choose to invest it we have gone at working with some other info components",
    "start": "1920779",
    "end": "1926679"
  },
  {
    "text": "thank you thank you [Applause]",
    "start": "1929600",
    "end": "1934250"
  }
]
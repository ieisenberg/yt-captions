[
  {
    "text": "welcome or welcome to this session uh this session we're going to talk about",
    "start": "280",
    "end": "5759"
  },
  {
    "text": "breaking through cluster boundaries to autoscale workloads across them on a large scale and this is uh sh uh",
    "start": "5759",
    "end": "14440"
  },
  {
    "text": "software engineer at dark cloud and my name is in johnl software engineer at",
    "start": "14440",
    "end": "21359"
  },
  {
    "text": "zesk uh we're going to talk we're going to cover U the uh HPA part uh part out",
    "start": "21960",
    "end": "29480"
  },
  {
    "text": "scaling and the benefit of autoscaling across clusters multic clusters and uh",
    "start": "29480",
    "end": "35800"
  },
  {
    "text": "intro introduced to kamada in the kamada features about Federated HPA and Crown",
    "start": "35800",
    "end": "41640"
  },
  {
    "text": "Federated Federated HPA then we're going to do a live demo and then uh five to 3",
    "start": "41640",
    "end": "48640"
  },
  {
    "text": "to five minutes on the Q&A uh let's like uh I'm assuming that",
    "start": "48640",
    "end": "55199"
  },
  {
    "text": "everyone is familiar with HPA but let me refresh so HPA of the horizontal part",
    "start": "55199",
    "end": "61199"
  },
  {
    "text": "autoscaling is a mechanism for Auto uh automatically scaling the number of part",
    "start": "61199",
    "end": "66760"
  },
  {
    "text": "replicas in kontic cluster so that it's dynamically scale and application based",
    "start": "66760",
    "end": "72799"
  },
  {
    "text": "on the current metrix so there's no the speaker Nots okay so",
    "start": "72799",
    "end": "81720"
  },
  {
    "text": "during each time period the HPA controller manager querries resource utilization based on the metric specify",
    "start": "81720",
    "end": "88880"
  },
  {
    "text": "in h h PA definition the controller manager identify the target resources",
    "start": "88880",
    "end": "94560"
  },
  {
    "text": "defined by the uh uh defined by the scale Target reference and select the",
    "start": "94560",
    "end": "99840"
  },
  {
    "text": "paths based on spec selector labels from the target resource and retrieve the",
    "start": "99840",
    "end": "105079"
  },
  {
    "text": "metrix from either the resource uh metrix API or the cust Matrix API here",
    "start": "105079",
    "end": "111240"
  },
  {
    "text": "is an example okay example of uh HPA so you",
    "start": "111240",
    "end": "117880"
  },
  {
    "text": "can see that the the number of the replicas of this PHP Apache deployments um the number of replicas",
    "start": "117880",
    "end": "125439"
  },
  {
    "text": "will be increased or decreased um to maintain the average of uh five sorry",
    "start": "125439",
    "end": "132160"
  },
  {
    "text": "50% of CPU utilization which means the number of replicas will be scaled up or",
    "start": "132160",
    "end": "138800"
  },
  {
    "text": "scaled down if the uh Aver uh average CPU utilization is above or below",
    "start": "138800",
    "end": "147840"
  },
  {
    "text": "50% uh HPA works perfect in a single cluster",
    "start": "148360",
    "end": "154760"
  },
  {
    "text": "when we're thinking about like multi clusters of how can we handle Autos",
    "start": "154760",
    "end": "161519"
  },
  {
    "text": "scaling across clusters so um here list a bunch of benefits and uh uh we can so",
    "start": "161519",
    "end": "171280"
  },
  {
    "text": "uh we can have a unified management of Autos scaling operations AC cross clusters that can reduce the operation",
    "start": "171280",
    "end": "178640"
  },
  {
    "text": "uh redundant and also break through the uh the resource limitation of a single clusters for example there a massive",
    "start": "178640",
    "end": "186000"
  },
  {
    "text": "request coming through in a short period of time and we run out of like for example the",
    "start": "186000",
    "end": "193040"
  },
  {
    "text": "instance and also uh uh to meet like different scenarios we would like to",
    "start": "193040",
    "end": "198159"
  },
  {
    "text": "have a variety uh Vari strategies that can scale the workload uh across like",
    "start": "198159",
    "end": "205120"
  },
  {
    "text": "multiple clusters not only by like the cluster name and the scenarios can be um",
    "start": "205120",
    "end": "212640"
  },
  {
    "text": "like Disaster Recovery like the cluster level of a scaling full Disaster",
    "start": "212640",
    "end": "218159"
  },
  {
    "text": "Recovery also you can thinking about like other scenarios like cost efficiency something like that um but",
    "start": "218159",
    "end": "225760"
  },
  {
    "text": "how can we achieve that um kada can help you with that let",
    "start": "225760",
    "end": "231000"
  },
  {
    "text": "me take a moment to uh introduce kada so it is a crimin management system that",
    "start": "231000",
    "end": "237079"
  },
  {
    "text": "enables the cloud native application across multiple uh kubernetes clusters",
    "start": "237079",
    "end": "243200"
  },
  {
    "text": "and clouds it has bunch of capabilities listed here so um I'm going to start",
    "start": "243200",
    "end": "251040"
  },
  {
    "text": "from the first one it is uh uh kuiz Native API cap compatible so is speak directly",
    "start": "251040",
    "end": "260239"
  },
  {
    "text": "to the kubernetes native API so which means you don't have to make any change to your current uh applications and it's",
    "start": "260239",
    "end": "269080"
  },
  {
    "text": "open and natur uh open means is um open source tool and recently a couple of",
    "start": "269080",
    "end": "275080"
  },
  {
    "text": "months ago it it has been moved from um sbox project into",
    "start": "275080",
    "end": "280840"
  },
  {
    "text": "incubation it uh it voice the vendor Lo um so um it has integration with",
    "start": "280840",
    "end": "288280"
  },
  {
    "text": "majority of the cloud providers uh it also um provide the",
    "start": "288280",
    "end": "294560"
  },
  {
    "text": "building policies to stat for the scenarios like active active remote",
    "start": "294560",
    "end": "299800"
  },
  {
    "text": "disaster recovery and Geo redundant oh",
    "start": "299800",
    "end": "305160"
  },
  {
    "text": "sorry yeah sorry okay uh it has variety of fful",
    "start": "305160",
    "end": "316320"
  },
  {
    "text": "scheduling policies like a cluster Affinity multic cluster splitting",
    "start": "316320",
    "end": "321639"
  },
  {
    "text": "rebalancing a multi-dimension uh ha like uh multi-dimension High availability",
    "start": "321639",
    "end": "328319"
  },
  {
    "text": "across the regions KS closers and Cloud providers uh it also offers like",
    "start": "328319",
    "end": "336560"
  },
  {
    "text": "centralized management by saying that we're going to move to the next slide it shows like how kada looks like uh on",
    "start": "336560",
    "end": "344440"
  },
  {
    "text": "your right it shows that the kada control plan is more look like kubernetes native uh kubernetes uh",
    "start": "344440",
    "end": "351520"
  },
  {
    "text": "control plan so it has a kada APS server it has a commod controller a bunch of uh",
    "start": "351520",
    "end": "358360"
  },
  {
    "text": "uh a bunch of controllers is managed by the controller manager uh kada scheduler also has uh SD SE as a as a uh database",
    "start": "358360",
    "end": "367880"
  },
  {
    "text": "as a data store so it can um store all the objects and the members like each",
    "start": "367880",
    "end": "373880"
  },
  {
    "text": "individual koniz clusters can be joined to this control plan and at like either",
    "start": "373880",
    "end": "380199"
  },
  {
    "text": "via uh push mode or pull mode uh on the right it shows like the",
    "start": "380199",
    "end": "385560"
  },
  {
    "text": "carada workflow as I mentioned before um K is native um Native API cap",
    "start": "385560",
    "end": "393520"
  },
  {
    "text": "capabilities so it used the resource template exactly the same with um the",
    "start": "393520",
    "end": "400479"
  },
  {
    "text": "carbonet apis so and let's move down a bit uh the propagation policies the the",
    "start": "400479",
    "end": "407120"
  },
  {
    "text": "user designed for how the workload be prop propagate to the member",
    "start": "407120",
    "end": "413039"
  },
  {
    "text": "clusters with that the uh policy controller going to uh bind those",
    "start": "413039",
    "end": "420039"
  },
  {
    "text": "uh propagations with the resources accordingly and after those resource",
    "start": "420039",
    "end": "425639"
  },
  {
    "text": "bending generated the the bind controller going to take the override policy to do adjacent patch to the",
    "start": "425639",
    "end": "433360"
  },
  {
    "text": "resource bending and generate the work objects into the specific name space and",
    "start": "433360",
    "end": "439879"
  },
  {
    "text": "the um propagation controller will take the actual propagation to the member",
    "start": "439879",
    "end": "447599"
  },
  {
    "text": "cluster uh this is more like a before and after so before we using",
    "start": "448319",
    "end": "454800"
  },
  {
    "text": "kada uh it's more like um and a user or something that uh manually deploy each",
    "start": "454800",
    "end": "461919"
  },
  {
    "text": "deployment to each member cluster so a lot of like engineered toil or duplicate",
    "start": "461919",
    "end": "469639"
  },
  {
    "text": "operations but after we use kroma um it offers like a unified or centralized uh",
    "start": "469639",
    "end": "476840"
  },
  {
    "text": "control plane so uh all those those uh all those like workloads can be",
    "start": "476840",
    "end": "482639"
  },
  {
    "text": "propagate to the right member clusters based on the propagation policy you",
    "start": "482639",
    "end": "488919"
  },
  {
    "text": "set so it's more like a one step instead of the Redundant",
    "start": "488919",
    "end": "495120"
  },
  {
    "text": "operations but you may ask like every really have a perfect like cicd",
    "start": "497440",
    "end": "503080"
  },
  {
    "text": "pipelines to handle all those work for me like I'm not like manually deploy all",
    "start": "503080",
    "end": "508919"
  },
  {
    "text": "those stuff but kamada also offers the workload propagation policy so oh Advanced",
    "start": "508919",
    "end": "517719"
  },
  {
    "text": "policies so not only based on the cluster name it can like based on the",
    "start": "517719",
    "end": "523560"
  },
  {
    "text": "labels the field tent and tolerant and also topology and available resources so",
    "start": "523560",
    "end": "531440"
  },
  {
    "text": "let's take an example on the uh topology and available resources on the left it",
    "start": "531440",
    "end": "536680"
  },
  {
    "text": "shows like in uh most of the uh workload",
    "start": "536680",
    "end": "541920"
  },
  {
    "text": "are scheduled to like Zone X and maybe less workload schedule on a Zone Y and",
    "start": "541920",
    "end": "547880"
  },
  {
    "text": "you can Define all those in your propagation policy on the left it shows that the workload scheduled",
    "start": "547880",
    "end": "555399"
  },
  {
    "text": "on the cluster number two in the middle because it has more CPU so it kind of",
    "start": "555399",
    "end": "561800"
  },
  {
    "text": "makes sense right we have uh instance Reserve instance like in AWS uh we have",
    "start": "561800",
    "end": "568800"
  },
  {
    "text": "Reserve instance and we want to take fullly usage of those instance so we scheduled more workl there and for those",
    "start": "568800",
    "end": "577560"
  },
  {
    "text": "like last CPUs available in the cluster number one in cluster number three we",
    "start": "577560",
    "end": "582880"
  },
  {
    "text": "just schedule less workload more little cost",
    "start": "582880",
    "end": "587959"
  },
  {
    "text": "efficiency and I've been talking a lot about propagation policy how does it look like this is an example it shows",
    "start": "587959",
    "end": "596040"
  },
  {
    "text": "like how we propagate the engine X deploy M you can see there is a cluster",
    "start": "596040",
    "end": "601279"
  },
  {
    "text": "affinity and and it's defined like this deployment going to be propagated to",
    "start": "601279",
    "end": "607920"
  },
  {
    "text": "Cluster Member One and cluster member two with the propagation uh with the",
    "start": "607920",
    "end": "613839"
  },
  {
    "text": "replica uh division reference as weighted the last two lines over there",
    "start": "613839",
    "end": "620800"
  },
  {
    "text": "so uh it can be like static divided like we just have static uh members like one",
    "start": "620800",
    "end": "627640"
  },
  {
    "text": "or two it also uh offers like Dynamic weight head so you can Define it like based on the",
    "start": "627640",
    "end": "635120"
  },
  {
    "text": "available resources uh there is um under that the",
    "start": "635120",
    "end": "640160"
  },
  {
    "text": "last line is replica scheduling type uh there are currently two types available",
    "start": "640160",
    "end": "646200"
  },
  {
    "text": "one is duplicated uh the other one is divided uh we're going to in the demo we're going to use the divided uh but",
    "start": "646200",
    "end": "652920"
  },
  {
    "text": "duplicate you can thinking about when you're doing a blue green migration and",
    "start": "652920",
    "end": "658200"
  },
  {
    "text": "things like that during the during the migration you want to have the workflows existing on both clusters and uh I just",
    "start": "658200",
    "end": "668200"
  },
  {
    "text": "I I I don't think I covered all those policies uh there's a URL at the bottom",
    "start": "668200",
    "end": "673800"
  },
  {
    "text": "that you can uh visit to the kada website there's more detail information",
    "start": "673800",
    "end": "680600"
  },
  {
    "text": "there the other scenario I would like to mention is uh the cross cluster application",
    "start": "680600",
    "end": "686440"
  },
  {
    "text": "failover uh on the right so there are three member clusters uh register to the",
    "start": "686440",
    "end": "693320"
  },
  {
    "text": "control plan and one of them like is in trouble like maybe the API uh",
    "start": "693320",
    "end": "700440"
  },
  {
    "text": "connection maybe the API connection like uh cut off or like something you can",
    "start": "700440",
    "end": "707480"
  },
  {
    "text": "imagine like all of a sudden the member one is unavailable it's not ready and",
    "start": "707480",
    "end": "712760"
  },
  {
    "text": "it's uh it will be detected by the the cluster controller with Discovery",
    "start": "712760",
    "end": "720160"
  },
  {
    "text": "failure and the workload on the member one will be automatically scheduled to",
    "start": "720160",
    "end": "725399"
  },
  {
    "text": "the other available clusters so it's gracefully migrate ensure uninterrupted",
    "start": "725399",
    "end": "733399"
  },
  {
    "text": "service all right I've already covered the the first uh topics and then I'm",
    "start": "734240",
    "end": "740279"
  },
  {
    "text": "going to head over to S and he will walk you through uh the kamada features Federated HPA and the crown Federated",
    "start": "740279",
    "end": "747880"
  },
  {
    "text": "HPA okay thank you and let being and as we well know",
    "start": "747880",
    "end": "757959"
  },
  {
    "text": "when we want to use resource in kubernetes we should first look at the API definition of natural resource so",
    "start": "757959",
    "end": "765279"
  },
  {
    "text": "now I will introduce Federated HPA as you can see the Federated HPA is",
    "start": "765279",
    "end": "771959"
  },
  {
    "text": "consistent with the kubernetes native HPA and for example the spec field",
    "start": "771959",
    "end": "779600"
  },
  {
    "text": "is very similar to the uh ktic negative HPA um they both they both have Fields",
    "start": "779600",
    "end": "789079"
  },
  {
    "text": "such as uh mean rcast Max rcast Matrix behavior and so",
    "start": "789079",
    "end": "798000"
  },
  {
    "text": "on so you you can also see that the Matrix fi here inference the field of",
    "start": "798000",
    "end": "806279"
  },
  {
    "text": "negative HPA okay so how can we use f Federated HPA",
    "start": "806279",
    "end": "814720"
  },
  {
    "text": "and let's take a close look at how to meate and as I described earlier the Federate",
    "start": "814720",
    "end": "823399"
  },
  {
    "text": "HP is very similar to the negative HPA so if have any experience using a",
    "start": "823399",
    "end": "831920"
  },
  {
    "text": "negative HPA you can easily work with Federated HPA as well for example uh on on our left is",
    "start": "831920",
    "end": "840240"
  },
  {
    "text": "negative HPA on right is Federated HPA you can see not the two examples",
    "start": "840240",
    "end": "848040"
  },
  {
    "text": "only differ in a version and can't therefore you don't need to make",
    "start": "848040",
    "end": "855720"
  },
  {
    "text": "any change to your existing HPA aspect",
    "start": "855720",
    "end": "861000"
  },
  {
    "text": "field okay uh this is very important so how",
    "start": "861000",
    "end": "868480"
  },
  {
    "text": "can and so let's see how it works the K the F HP controller under",
    "start": "868480",
    "end": "878120"
  },
  {
    "text": "control plan obtain matrics of the deployment through the K",
    "start": "878120",
    "end": "886160"
  },
  {
    "text": "Matrix adapter and uh dynamically scales the number of replicas",
    "start": "886160",
    "end": "893160"
  },
  {
    "text": "of department and then K scer will schedule",
    "start": "893160",
    "end": "899480"
  },
  {
    "text": "this Le addit repast to different member clusters for example Member One and",
    "start": "899480",
    "end": "905600"
  },
  {
    "text": "member two and based on the scheding scheduling",
    "start": "905600",
    "end": "911079"
  },
  {
    "text": "policies uh specified by the user in their propagation policies in has early",
    "start": "911079",
    "end": "917839"
  },
  {
    "text": "introduced a propagation policy so uh this enables cost Caster Auto",
    "start": "917839",
    "end": "925680"
  },
  {
    "text": "scanning okay uh the f r HP controller is located in",
    "start": "925680",
    "end": "933600"
  },
  {
    "text": "the kand controller man management component it queres Matrix from kand API",
    "start": "933600",
    "end": "941160"
  },
  {
    "text": "server and uh uh and the scales repast of deployments",
    "start": "941160",
    "end": "950000"
  },
  {
    "text": "accordingly and then command IP server creates kand Matrix",
    "start": "950000",
    "end": "956079"
  },
  {
    "text": "adapter and then the kand Matrix adapter queres the me the member Matrix uh",
    "start": "956079",
    "end": "964959"
  },
  {
    "text": "queres Matrix server of member clusters to obtain Matrix or customer",
    "start": "964959",
    "end": "972000"
  },
  {
    "text": "matrix and then Aggregates them and finally returns them to kand APS server",
    "start": "972000",
    "end": "980759"
  },
  {
    "text": "so you can see that the Federated HPA emulates the mechanism of negative HPA",
    "start": "980759",
    "end": "990519"
  },
  {
    "text": "okay uh with the latest version of command releasing and there is a new API",
    "start": "991800",
    "end": "998639"
  },
  {
    "text": "Chown Federated HPA uh it is permanently used for scenario Nik if there is a",
    "start": "998639",
    "end": "1006040"
  },
  {
    "text": "traffic spec every day at 19 a.m. I would like to proactively scale up the",
    "start": "1006040",
    "end": "1013319"
  },
  {
    "text": "related servers or hand of time and for example 30 minutes before to handle your",
    "start": "1013319",
    "end": "1020600"
  },
  {
    "text": "P loads and uh ensure",
    "start": "1020600",
    "end": "1026520"
  },
  {
    "text": "availability okay and and other scenario like to schedule",
    "start": "1026520",
    "end": "1032438"
  },
  {
    "text": "database uh migration jobs on Recons okay in general uh Crown fated",
    "start": "1032439",
    "end": "1040000"
  },
  {
    "text": "HPA is used for regular or to scanning actions it can scale workloads not have",
    "start": "1040000",
    "end": "1045640"
  },
  {
    "text": "a uh scale sub Source or fated",
    "start": "1045640",
    "end": "1051200"
  },
  {
    "text": "HPA and let's take a look at the two examples of Chron feder Chron Federated",
    "start": "1053039",
    "end": "1061280"
  },
  {
    "text": "HPA on left we have an example of schedule scanning for Federated HPA it",
    "start": "1061280",
    "end": "1070640"
  },
  {
    "text": "uh it includes a schedule field for writing Crown table experss and uh or",
    "start": "1070640",
    "end": "1079280"
  },
  {
    "text": "Target mean wecast field on right we have an example of",
    "start": "1079280",
    "end": "1085520"
  },
  {
    "text": "schedule scanning for uh deployment uh it also includes a schedule",
    "start": "1085520",
    "end": "1091919"
  },
  {
    "text": "field uh for writing Crown table experss and our Target and our Target",
    "start": "1091919",
    "end": "1099400"
  },
  {
    "text": "rcast failed okay so when the specified time arrivers the crown ferity HPA controller",
    "start": "1099400",
    "end": "1107799"
  },
  {
    "text": "will trigger a scale up or a scale down actions allar your to proactivity scale",
    "start": "1107799",
    "end": "1115240"
  },
  {
    "text": "up or down your deployment okay uh K implements crown",
    "start": "1115240",
    "end": "1123360"
  },
  {
    "text": "for HPA as a c RP not periodically checks the Crown schedule time if your",
    "start": "1123360",
    "end": "1130440"
  },
  {
    "text": "schedule time is Reed uh it scales the workloads rcast or Federated HPA mean",
    "start": "1130440",
    "end": "1139960"
  },
  {
    "text": "rcast or Max Max rcast uh so you can see that uh the",
    "start": "1139960",
    "end": "1147039"
  },
  {
    "text": "crown fer related HPA working mechanism is very",
    "start": "1147039",
    "end": "1153200"
  },
  {
    "text": "simple okay and as I described earlier a crown Crown F reach HBA can scanning",
    "start": "1154080",
    "end": "1162440"
  },
  {
    "text": "workloads with a scale sub resource and scanning fated HPA",
    "start": "1162440",
    "end": "1168760"
  },
  {
    "text": "uh so let's take a look at the consideration for usage uh in",
    "start": "1168760",
    "end": "1174080"
  },
  {
    "text": "general it is important to uh ensure that the scanning",
    "start": "1174080",
    "end": "1180240"
  },
  {
    "text": "operations and performed by Chown ferity HPA and do not conflict with any other",
    "start": "1180240",
    "end": "1187360"
  },
  {
    "text": "ongoing scanning operations and so it is recommended to",
    "start": "1187360",
    "end": "1192559"
  },
  {
    "text": "first use Crown fer HP to scale FPA and",
    "start": "1192559",
    "end": "1198400"
  },
  {
    "text": "then Freer HP can scale work CLS based on their",
    "start": "1198400",
    "end": "1204480"
  },
  {
    "text": "matrics and and then let's take a look at the advantage and the notice of",
    "start": "1206799",
    "end": "1212440"
  },
  {
    "text": "crownit HPA F APA advantages the API and the",
    "start": "1212440",
    "end": "1219320"
  },
  {
    "text": "kubernetes native HPA are almost identical with the same user experience",
    "start": "1219320",
    "end": "1225600"
  },
  {
    "text": "and the low migration cost notice Federate APA is type of the",
    "start": "1225600",
    "end": "1232919"
  },
  {
    "text": "centor oh okay",
    "start": "1232919",
    "end": "1239600"
  },
  {
    "text": "okay and",
    "start": "1241799",
    "end": "1247520"
  },
  {
    "text": "oh oh okay okay f f Federated HPA is a type of the uh centralized multic",
    "start": "1247559",
    "end": "1254760"
  },
  {
    "text": "cluster HPA when are scanning concurr on a larger scale a larger bedways is",
    "start": "1254760",
    "end": "1261440"
  },
  {
    "text": "required and the storing and Computing cor responding data requires match CPU",
    "start": "1261440",
    "end": "1267520"
  },
  {
    "text": "and memory okay in a pH of some shortcomings of",
    "start": "1267520",
    "end": "1275520"
  },
  {
    "text": "Federated HPA the command Community is exploring a Le API distribute",
    "start": "1275520",
    "end": "1282720"
  },
  {
    "text": "HPA which introduce an agent in member clusters it will list and watch uh",
    "start": "1282720",
    "end": "1290880"
  },
  {
    "text": "distribute HPA and calculate calculate the intermediate States and then the",
    "start": "1290880",
    "end": "1298039"
  },
  {
    "text": "intermediate States will be updated to the status field of distribute",
    "start": "1298039",
    "end": "1304880"
  },
  {
    "text": "HPA and then kimada calculates the uh final result and adjust the number of",
    "start": "1304880",
    "end": "1312880"
  },
  {
    "text": "rcast uh based on intermediate data intermediate data reported by the agents",
    "start": "1312880",
    "end": "1321360"
  },
  {
    "text": "in the member cluster uh okay currently this design",
    "start": "1321360",
    "end": "1328720"
  },
  {
    "text": "under discussing so you are welcome to join",
    "start": "1328720",
    "end": "1333639"
  },
  {
    "text": "us all right let's uh let's take a quick demo before we move to the",
    "start": "1333880",
    "end": "1341159"
  },
  {
    "text": "takeaways so in the demo we're going to show you how we use kamada to um",
    "start": "1341159",
    "end": "1346360"
  },
  {
    "text": "propagate the workflow to member clusters we're going to have three uh kubernetes clusters uh uh in local one",
    "start": "1346360",
    "end": "1355159"
  },
  {
    "text": "going to be a host going to be the host where the kada control plane going to lives so this um on the on the ride",
    "start": "1355159",
    "end": "1362279"
  },
  {
    "text": "terminal oh sorry ride Terminals and those are two separate individual uh",
    "start": "1362279",
    "end": "1367679"
  },
  {
    "text": "kontis cluster will be joined as member cluster but",
    "start": "1367679",
    "end": "1373320"
  },
  {
    "text": "currently and uh in those member clusters uh they're they're not reg they're not",
    "start": "1376960",
    "end": "1383880"
  },
  {
    "text": "joined yet uh but super reest uh the metric server has been deployed to those",
    "start": "1383880",
    "end": "1390320"
  },
  {
    "text": "mem clusters and we have set up the kada on",
    "start": "1390320",
    "end": "1398000"
  },
  {
    "text": "the uh caronus cluster all right let's do the drawing",
    "start": "1398000",
    "end": "1406760"
  },
  {
    "text": "using kada CTL you can see both uh both member cluster has been Jo have been",
    "start": "1406760",
    "end": "1413880"
  },
  {
    "text": "joined to commod successfully and when are going to get the cluster it can",
    "start": "1413880",
    "end": "1419279"
  },
  {
    "text": "shows that the status of those clusters they are ready which means they're ready to be propagated and then we are going",
    "start": "1419279",
    "end": "1428279"
  },
  {
    "text": "to deploy a simple engine X application so you can see the replix set to two",
    "start": "1428279",
    "end": "1436880"
  },
  {
    "text": "and then we apply this deployment to",
    "start": "1436880",
    "end": "1444400"
  },
  {
    "text": "kamada create it but uh I would like to if you wanted",
    "start": "1444400",
    "end": "1452080"
  },
  {
    "text": "to get the",
    "start": "1452080",
    "end": "1455200"
  },
  {
    "text": "part yeah but but there's no like workload on the control plan or on",
    "start": "1458080",
    "end": "1464200"
  },
  {
    "text": "either of the member cluster because we don't have the propagation policy",
    "start": "1464200",
    "end": "1469360"
  },
  {
    "text": "setup and after we yeah let's take a look how the",
    "start": "1469360",
    "end": "1476080"
  },
  {
    "text": "publication policy looks like it",
    "start": "1476080",
    "end": "1480200"
  },
  {
    "text": "has uh it defined like the uh how we",
    "start": "1483440",
    "end": "1488480"
  },
  {
    "text": "schedule the replicas is weighted and one in each member clusters and it's",
    "start": "1488480",
    "end": "1494679"
  },
  {
    "text": "divided so we are expecting to see like one replica in each member",
    "start": "1494679",
    "end": "1500440"
  },
  {
    "text": "cluster let's apply this and you can see on the right there are",
    "start": "1500440",
    "end": "1507158"
  },
  {
    "text": "replicas cool and you may see",
    "start": "1511240",
    "end": "1516240"
  },
  {
    "text": "that and then we apply the Federated HBA and let's take a look what it look",
    "start": "1517799",
    "end": "1523960"
  },
  {
    "text": "like uh it defined the minimum replicas as one and Ma maximum replicat is 10 uh",
    "start": "1523960",
    "end": "1529799"
  },
  {
    "text": "with the scale down and scale up the time is 10 10 seconds with the CPU",
    "start": "1529799",
    "end": "1535760"
  },
  {
    "text": "utilization set us like 10% so we are",
    "start": "1535760",
    "end": "1540799"
  },
  {
    "text": "expecting to see maybe one of the oh it disappeared maybe one of the one of the replica disappear because there's no",
    "start": "1540799",
    "end": "1548120"
  },
  {
    "text": "like load actual load or traffic into this engine X",
    "start": "1548120",
    "end": "1554398"
  },
  {
    "text": "application all right we've we've log in to uh one of",
    "start": "1556679",
    "end": "1564360"
  },
  {
    "text": "the mem cluster and we do a lot generator using uh AB the Apache bench",
    "start": "1564360",
    "end": "1570720"
  },
  {
    "text": "so is the command it shows like in within 20 seconds we're going to make uh generate 10,000 of the",
    "start": "1570720",
    "end": "1578440"
  },
  {
    "text": "concurrence and we are expecting to see more replicas spin up in the member",
    "start": "1578440",
    "end": "1585919"
  },
  {
    "text": "clusters and L which means like maybe one one one or 2 two okay 3",
    "start": "1585919",
    "end": "1594320"
  },
  {
    "text": "three is it three two all right you can see the difference",
    "start": "1594320",
    "end": "1601399"
  },
  {
    "text": "is because it's uh automatically uh calculate based on the available resources maybe in the member one we",
    "start": "1601399",
    "end": "1608440"
  },
  {
    "text": "have more available resources but all those three clusters are generated by kind uh is",
    "start": "1608440",
    "end": "1615919"
  },
  {
    "text": "allcal and the load generator is completed and we may see that the",
    "start": "1615919",
    "end": "1622480"
  },
  {
    "text": "replicas will be scheduled down within a couple of",
    "start": "1622480",
    "end": "1628279"
  },
  {
    "text": "seconds well couple of seconds means like 10 20 seconds oh there",
    "start": "1628279",
    "end": "1633559"
  },
  {
    "text": "go all right uh that is the end of demo let let let's move back to our",
    "start": "1633559",
    "end": "1641200"
  },
  {
    "text": "slides so I want to take a quick moment to recap uh for the key takeaways here",
    "start": "1641200",
    "end": "1646960"
  },
  {
    "text": "is the Reg HPA cannot break through the cluster boundaries to outut of scale the workflows but the Federated HPA and",
    "start": "1646960",
    "end": "1654399"
  },
  {
    "text": "current feder HPA can help you with that and kada is a open source tool that",
    "start": "1654399",
    "end": "1660159"
  },
  {
    "text": "enable you to run your Cloud native application across multiple Caron clusters and",
    "start": "1660159",
    "end": "1668480"
  },
  {
    "text": "clouds so I would encourage everyone to uh give kada a try and see how it fits",
    "start": "1668480",
    "end": "1674720"
  },
  {
    "text": "in your use case or scenarios uh here are the links uh kada do the",
    "start": "1674720",
    "end": "1682399"
  },
  {
    "text": "GitHub Ripple and we have a a slack channel uh named kada and you are more",
    "start": "1682399",
    "end": "1688919"
  },
  {
    "text": "than welcome to join us thank you so [Applause]",
    "start": "1688919",
    "end": "1693970"
  },
  {
    "text": "[Music] much um thank you so much for listening",
    "start": "1693970",
    "end": "1699120"
  },
  {
    "text": "and I just want to give a a shout out to the Comm contributors and maintainers",
    "start": "1699120",
    "end": "1704679"
  },
  {
    "text": "you're awesome and we are appreciate your feedback uh please scan this QR code above to leave feedbacks for us and",
    "start": "1704679",
    "end": "1712360"
  },
  {
    "text": "yeah we we still have a couple of minutes uh I'm happy we're happy to answer any questions you may have",
    "start": "1712360",
    "end": "1722158"
  },
  {
    "text": "yes oh the question was uh uh so the Dow cloud is currently using kamada I'm",
    "start": "1725640",
    "end": "1732480"
  },
  {
    "text": "gonna let sh to answer this questions okay uh",
    "start": "1732480",
    "end": "1739399"
  },
  {
    "text": "we can discuss offline uh",
    "start": "1740919",
    "end": "1745480"
  },
  {
    "text": "yeah a short answer is yes yeah I got this correct answer yeah but we can discuss the more details like offline",
    "start": "1748600",
    "end": "1756240"
  },
  {
    "text": "yeah cool awesome the gentleman over there question yes so um we saw how you",
    "start": "1756240",
    "end": "1763000"
  },
  {
    "text": "were able to scale your workloads across multiple clusters",
    "start": "1763000",
    "end": "1768240"
  },
  {
    "text": "as traffic came in but my question is how are you handling Ingress because you",
    "start": "1768240",
    "end": "1773440"
  },
  {
    "text": "know once once workload scales out to another cluster your Ingress end point",
    "start": "1773440",
    "end": "1778559"
  },
  {
    "text": "is still on cluster a but now you've got you you've got a workload running on cluster B but no traffic's necessarily",
    "start": "1778559",
    "end": "1786080"
  },
  {
    "text": "going to that so how are you handling that problem with uh kada so if I understand it correctly",
    "start": "1786080",
    "end": "1793200"
  },
  {
    "text": "it's uh the question is when the the Ingress of a a single cluster is coming",
    "start": "1793200",
    "end": "1798320"
  },
  {
    "text": "in uh the traffic in but we've scheduled the workload on the other member cluster is that correct right right and without",
    "start": "1798320",
    "end": "1805080"
  },
  {
    "text": "something like gsob I mean I'm wondering how how that how that effectively scales",
    "start": "1805080",
    "end": "1811120"
  },
  {
    "text": "across multiple clusters can you answer those questions it's more like underlying like",
    "start": "1811120",
    "end": "1816200"
  },
  {
    "text": "networking setting up right right I mean there has to be like a networking part to it okay so uh as far as know the",
    "start": "1816200",
    "end": "1825320"
  },
  {
    "text": "underlying uh Network the best practice is to using Submariner",
    "start": "1825320",
    "end": "1830840"
  },
  {
    "text": "so all those cluster all the underlying uh all those member clusters are using submariners so they can be like talk to",
    "start": "1830840",
    "end": "1837960"
  },
  {
    "text": "each other and handling the traffic across the cluster that's more like Assumption of that but uh if you have",
    "start": "1837960",
    "end": "1844600"
  },
  {
    "text": "more concerns uh uh like we can discuss like offline okay and see your use Cas",
    "start": "1844600",
    "end": "1850960"
  },
  {
    "text": "are or you can open the issue for us in the r hole Yeah I I'll hit you all up in the chat uh slack Slack room thanks okay",
    "start": "1850960",
    "end": "1858399"
  },
  {
    "text": "thank you oh the next gentleman so in your in your examples",
    "start": "1858399",
    "end": "1863720"
  },
  {
    "text": "you're using the default name space yes if we have custom name spaces with custom resource quotas and limits and",
    "start": "1863720",
    "end": "1871000"
  },
  {
    "text": "policies do we have to create that name that name space with all of our resource cluster resource quotas and everything",
    "start": "1871000",
    "end": "1877279"
  },
  {
    "text": "across all the Clusters or do we that do that at your top level um kada and it",
    "start": "1877279",
    "end": "1882960"
  },
  {
    "text": "just creates that name space across all the Clusters oh I got you uh if I understand correctly your answer",
    "start": "1882960",
    "end": "1890159"
  },
  {
    "text": "your question is when we're using kada how it generate the name space in uh in",
    "start": "1890159",
    "end": "1896519"
  },
  {
    "text": "the control plan is that is the control plan yes when we uh deploy the the when",
    "start": "1896519",
    "end": "1903039"
  },
  {
    "text": "we to uh apply the deployment it will generate a default name space in the",
    "start": "1903039",
    "end": "1908120"
  },
  {
    "text": "kada control plan and after we apply the propagation policy it will generate the",
    "start": "1908120",
    "end": "1915480"
  },
  {
    "text": "uh specified name space in the the control plan like starting with kada d and instored all those uh work objects",
    "start": "1915480",
    "end": "1925000"
  },
  {
    "text": "and it is is the format is is uh e the",
    "start": "1925000",
    "end": "1930080"
  },
  {
    "text": "kada D s- cluster name Dash the name",
    "start": "1930080",
    "end": "1935360"
  },
  {
    "text": "space that you specify in youro file gotcha and it carries we we can show you",
    "start": "1935360",
    "end": "1941159"
  },
  {
    "text": "everything else or carried across all the the next cluster that it propagates to yes okay and it will create P of the",
    "start": "1941159",
    "end": "1947919"
  },
  {
    "text": "name space uh in all those member clusters I think you can see from there",
    "start": "1947919",
    "end": "1953519"
  },
  {
    "text": "gotcha gotcha that that CLE we should show that in our dam right yeah okay thank you okay cool I hope you I'll",
    "start": "1953519",
    "end": "1960960"
  },
  {
    "text": "answer your questions thank you thank you for your question yes I have one question related to the uh sorry I",
    "start": "1960960",
    "end": "1966919"
  },
  {
    "text": "cannot hear you hello I have one question related to Federated HPA does uh it supports",
    "start": "1966919",
    "end": "1973320"
  },
  {
    "text": "external metrics like data dog or any other pesis metric",
    "start": "1973320",
    "end": "1979039"
  },
  {
    "text": "sorry I still didn't hear yeah the Federate HPA does it support external",
    "start": "1979519",
    "end": "1985440"
  },
  {
    "text": "Matrix other than external Matrix yeah right uh uh I think we offer external",
    "start": "1985440",
    "end": "1991240"
  },
  {
    "text": "Matrix uh we have promus can you use with prome yeah yeah we can offer that",
    "start": "1991240",
    "end": "1997600"
  },
  {
    "text": "uh metric for monitoring yes I think there is a session in the website and",
    "start": "1997600",
    "end": "2003200"
  },
  {
    "text": "show that how we monitoring alerting based on those metric not only for the HPA or Federated HPA",
    "start": "2003200",
    "end": "2011279"
  },
  {
    "text": "but in general there are metrics available yeah thanks for a question yeah I had the same question but uh yeah",
    "start": "2011279",
    "end": "2019080"
  },
  {
    "text": "what happens in a network partition where your control cluster doesn't have access to the other clusters anymore so",
    "start": "2019080",
    "end": "2024519"
  },
  {
    "text": "the question was what happen if the network is like in trouble if there's a",
    "start": "2024519",
    "end": "2029799"
  },
  {
    "text": "if there's an outage in the between your control cluster that's managing the",
    "start": "2029799",
    "end": "2035039"
  },
  {
    "text": "Federated hpas and and the remote clusters what happens to the Federated the the HPA running in the Federated",
    "start": "2035039",
    "end": "2042360"
  },
  {
    "text": "clusters oh the question was what if like one of the memory cluster allows the connction what if the control",
    "start": "2042360",
    "end": "2048760"
  },
  {
    "text": "cluster to the remote clusters oh I got you so the question was sorry about that",
    "start": "2048760",
    "end": "2054358"
  },
  {
    "text": "the question was about how we handle if the kod control plan is unavailable so",
    "start": "2054359",
    "end": "2061000"
  },
  {
    "text": "if the if the control plane can't connect to the remote clusters they're happily doing their thing the remote",
    "start": "2061000",
    "end": "2067040"
  },
  {
    "text": "clusters are working but but the control plane can no longer talk to them",
    "start": "2067040",
    "end": "2074560"
  },
  {
    "text": "uh uh we cannot answer your question at the moment because we",
    "start": "2076200",
    "end": "2083960"
  },
  {
    "text": "uh so I'm assuming that all those workloads were like running happily on",
    "start": "2085280",
    "end": "2091079"
  },
  {
    "text": "each member CL but it would it would just stop scaling yes self scaling so it would no longer scale in or scale SC out",
    "start": "2091079",
    "end": "2097320"
  },
  {
    "text": "it would just run at a steady state yes I'm assuming that you have your HPA set up in the each memory clusters yes it",
    "start": "2097320",
    "end": "2103920"
  },
  {
    "text": "will the HP going to hand handling all those uh pod outo scaling in each member",
    "start": "2103920",
    "end": "2111920"
  },
  {
    "text": "clusters I'm hoping answer your question s if you if I didn't feel free to like",
    "start": "2112079",
    "end": "2117800"
  },
  {
    "text": "open I was specifically asking about the distributed ones distribut it where cuz",
    "start": "2117800",
    "end": "2123400"
  },
  {
    "text": "it look like the the example you just ran if cluster 2 if the control cluster",
    "start": "2123400",
    "end": "2128720"
  },
  {
    "text": "couldn't connect to Cluster 2 anymore would it just not schedule any more workloads on there oh oh uh uh to be clear so those",
    "start": "2128720",
    "end": "2137960"
  },
  {
    "text": "the the member cluster still register as a member cluster to the commod control plan right right be because if we unjoin",
    "start": "2137960",
    "end": "2145760"
  },
  {
    "text": "it's going to delete all the workload from Member two right but not an unjoin just like uh the network go Network",
    "start": "2145760",
    "end": "2151359"
  },
  {
    "text": "issue unde cable gets cut or something the workload are going to be still like",
    "start": "2151359",
    "end": "2156560"
  },
  {
    "text": "right in it inside a single uh member clusters but in the central the",
    "start": "2156560",
    "end": "2161839"
  },
  {
    "text": "Federated HPA cannot work canot scheduling those workload ACR the Clusters it lost the control right but",
    "start": "2161839",
    "end": "2168280"
  },
  {
    "text": "it does continue running but they would not scale in or out no yes without",
    "start": "2168280",
    "end": "2173560"
  },
  {
    "text": "scheduling across the cluster but they can be like running in a single cluster",
    "start": "2173560",
    "end": "2178880"
  },
  {
    "text": "yeah yes yes okay I um you you had a slide that showed um when you would uh",
    "start": "2178880",
    "end": "2185960"
  },
  {
    "text": "when when your control cluster lost connection to uh to one of the member clusters that would migrate the workload",
    "start": "2185960",
    "end": "2193119"
  },
  {
    "text": "to to one of the working clusters uh how were you how would you be able to migrate the workload if you've lost if",
    "start": "2193119",
    "end": "2200359"
  },
  {
    "text": "the control cluster has lost the connection to the member cluster okay",
    "start": "2200359",
    "end": "2205560"
  },
  {
    "text": "the question is uh there is a slide showing that we lost the the connectivity between",
    "start": "2205560",
    "end": "2211800"
  },
  {
    "text": "the uh but to be clear it's not a connection between uh uh the control",
    "start": "2211800",
    "end": "2218440"
  },
  {
    "text": "plane to the to each of the mem cluster just only one of the M CL one of them and it showed you would migrate that",
    "start": "2218440",
    "end": "2224000"
  },
  {
    "text": "workload to a new cluster um but uh I'm curious how would you do the migration",
    "start": "2224000",
    "end": "2230920"
  },
  {
    "text": "to uh because you don't have access to that cluster anymore so yes so how would you shut down that workload on the",
    "start": "2230920",
    "end": "2238880"
  },
  {
    "text": "cluster you can't reach to to create that on the new cluster or on the working cluster okay I got your question",
    "start": "2238880",
    "end": "2245520"
  },
  {
    "text": "so so the question is more like the the the whole cluster the workflow still running on the bad clusters and we just",
    "start": "2245520",
    "end": "2252760"
  },
  {
    "text": "Autos scale the workflows to the other member clusters how we're going to handle this situation uh but what we are",
    "start": "2252760",
    "end": "2258880"
  },
  {
    "text": "trying to explain is that cluster is in trouble so the workload disappeared and",
    "start": "2258880",
    "end": "2264000"
  },
  {
    "text": "it's based on the feature gate which is the enable failover so it's automatically uh scheduling to the other",
    "start": "2264000",
    "end": "2270640"
  },
  {
    "text": "member clusters um okay so it may schedule some some some new workloads",
    "start": "2270640",
    "end": "2277880"
  },
  {
    "text": "while the workloads on the cluster you can't reach anymore might still be yes we just assuming that cluster is down",
    "start": "2277880",
    "end": "2283800"
  },
  {
    "text": "and the workloads cannot handle any traffic I see okay thank you very much yeah thank you thank you for your",
    "start": "2283800",
    "end": "2289359"
  },
  {
    "text": "question",
    "start": "2289359",
    "end": "2292359"
  }
]
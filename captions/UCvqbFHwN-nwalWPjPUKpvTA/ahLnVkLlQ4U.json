[
  {
    "start": "0",
    "end": "57000"
  },
  {
    "text": "hello everyone my name is stefan pradhan i'm a software engineer at weworks",
    "start": "2000",
    "end": "7919"
  },
  {
    "text": "and i'm very happy today talk to you about flagger and progressive delivery we",
    "start": "7919",
    "end": "15040"
  },
  {
    "text": "started flagger two years ago as a way to decouple deployment",
    "start": "15040",
    "end": "21760"
  },
  {
    "text": "from the from release and enable automatic rollbacks",
    "start": "21760",
    "end": "29119"
  },
  {
    "text": "and make the release process safer to optimize let's see what",
    "start": "29119",
    "end": "36559"
  },
  {
    "text": "transformations you need to do to your cicd pipelines in order to move from a classical uh",
    "start": "36559",
    "end": "45039"
  },
  {
    "text": "way of deploying things to something that enables progressive delivery and how we",
    "start": "45039",
    "end": "50480"
  },
  {
    "text": "can apply these techniques",
    "start": "50480",
    "end": "54320"
  },
  {
    "start": "57000",
    "end": "162000"
  },
  {
    "text": "so i draw that diagram here how cicd looks like in general you have your",
    "start": "57680",
    "end": "64878"
  },
  {
    "text": "app repo where your source code is in there you also have a docker file",
    "start": "64879",
    "end": "70400"
  },
  {
    "text": "kubernetes manifests scripts that or channels that define how your ci cd",
    "start": "70400",
    "end": "77119"
  },
  {
    "text": "process goes so you push a change to your app repo that",
    "start": "77119",
    "end": "83200"
  },
  {
    "text": "creates a container image then your script will",
    "start": "83200",
    "end": "89600"
  },
  {
    "text": "place the new image tag inside the kubernetes manifest and apply those",
    "start": "89600",
    "end": "97040"
  },
  {
    "text": "manifests on the cluster this is how you release a new version of the app there are a couple of",
    "start": "97040",
    "end": "104240"
  },
  {
    "text": "challenges with this approach if you have multiple apps that share some infrastructure items let's say an",
    "start": "104240",
    "end": "111280"
  },
  {
    "text": "ingress controller or the same namespace and so on where do you place",
    "start": "111280",
    "end": "117040"
  },
  {
    "text": "those shared items if you place them in",
    "start": "117040",
    "end": "124240"
  },
  {
    "text": "all your app repos and you modify something in one ripple then when you run",
    "start": "124240",
    "end": "131200"
  },
  {
    "text": "these pipelines in parallel they'll be fighting each other right they'll be undoing each other's",
    "start": "131200",
    "end": "136400"
  },
  {
    "text": "changes there's another challenge is around rollback if you want to",
    "start": "136400",
    "end": "144239"
  },
  {
    "text": "restore your app to a previous version you have to rerun the whole pipeline that means creating a new container",
    "start": "144319",
    "end": "150640"
  },
  {
    "text": "registry deploying that on production that's not actually rollback because you create a",
    "start": "150640",
    "end": "156239"
  },
  {
    "text": "new artifact and whatever is in there could be different",
    "start": "156239",
    "end": "161840"
  },
  {
    "text": "and i listed here more things around cicd as a monolith",
    "start": "161840",
    "end": "169040"
  },
  {
    "start": "162000",
    "end": "219000"
  },
  {
    "text": "um one one aspect is around configuration drift if all these",
    "start": "169040",
    "end": "176160"
  },
  {
    "text": "manifests are all over the place in all your app repos how do you ensure that your production",
    "start": "176160",
    "end": "183680"
  },
  {
    "text": "system can be versioned how do you detect when your production system",
    "start": "183680",
    "end": "190319"
  },
  {
    "text": "changed somehow let's say someone edits something directly on the cluster",
    "start": "190319",
    "end": "195840"
  },
  {
    "text": "how do you make sure that those changes are being ported back to git",
    "start": "195840",
    "end": "201120"
  },
  {
    "text": "what happens to them when you run a new pipeline some of them could be overwritten and so",
    "start": "201120",
    "end": "206319"
  },
  {
    "text": "on so in order to to make the",
    "start": "206319",
    "end": "211360"
  },
  {
    "text": "production releases more stable more",
    "start": "211360",
    "end": "217200"
  },
  {
    "text": "traceable we can break ci from cd and how ci would look like",
    "start": "218080",
    "end": "225680"
  },
  {
    "start": "219000",
    "end": "330000"
  },
  {
    "text": "it's it's going to be the thing that runs your end-to-end tests um",
    "start": "225680",
    "end": "232640"
  },
  {
    "text": "maybe with a kubernetes kind cluster that you can run inside your ci system",
    "start": "232640",
    "end": "238400"
  },
  {
    "text": "if if everything goes okay you can also validate uh your kubernetes manifest with",
    "start": "238400",
    "end": "243439"
  },
  {
    "text": "something like opa conf test in the end you will be creating an immutable container image and you push",
    "start": "243439",
    "end": "250480"
  },
  {
    "text": "that the register and that's where your ci platform role ends it doesn't",
    "start": "250480",
    "end": "255840"
  },
  {
    "text": "know about your production clusters it doesn't connect to kubernetes that way",
    "start": "255840",
    "end": "263600"
  },
  {
    "text": "now for the continuous delivery part the proposal is you'll be using github",
    "start": "263600",
    "end": "270479"
  },
  {
    "text": "so what key tops means is you will have this repository where you define your whole",
    "start": "270479",
    "end": "276720"
  },
  {
    "text": "fleet state the continuous delivery controllers will",
    "start": "276720",
    "end": "282400"
  },
  {
    "text": "not be running outside the cluster will be running on each cluster and this is how the",
    "start": "282400",
    "end": "288880"
  },
  {
    "text": "clusters themselves will reconcile their own state they'll connect to your fleet repository they will take",
    "start": "288880",
    "end": "295759"
  },
  {
    "text": "let's say a customized overlay made for that particular cluster or that particular group of clusters let's say",
    "start": "295759",
    "end": "302160"
  },
  {
    "text": "have a staging group and a production group and so on and they will be continuously",
    "start": "302160",
    "end": "308080"
  },
  {
    "text": "reconciling their own state with what's defining it that means you can version your",
    "start": "308080",
    "end": "313840"
  },
  {
    "text": "infrastructure along with your app deployments and if you want to roll back to a",
    "start": "313840",
    "end": "320560"
  },
  {
    "text": "particular point in time you'll have matching definitions for for all these things",
    "start": "320560",
    "end": "329199"
  },
  {
    "start": "330000",
    "end": "401000"
  },
  {
    "text": "what challenges are with with this continuous delivery product with githubs",
    "start": "331039",
    "end": "337840"
  },
  {
    "text": "one of the issue is how what are you going to do if an app",
    "start": "337840",
    "end": "343199"
  },
  {
    "text": "misbehaves after you deploy it if if the app crashes let's say during",
    "start": "343199",
    "end": "348720"
  },
  {
    "text": "deployment the kubernetes rolling update will hold you can add health checks to your cd",
    "start": "348720",
    "end": "355919"
  },
  {
    "text": "system and you can know about it but what if your app",
    "start": "355919",
    "end": "361199"
  },
  {
    "text": "rolls out nicely then when um production traffic",
    "start": "361199",
    "end": "368240"
  },
  {
    "text": "ends up on the new version your version starts to error out with 500 errors or",
    "start": "368240",
    "end": "374319"
  },
  {
    "text": "maybe the code changes add a lot of latency so people get timeouts or the app will be very",
    "start": "374319",
    "end": "382800"
  },
  {
    "text": "hard to interact with also there are things like can you run",
    "start": "382800",
    "end": "389280"
  },
  {
    "text": "multiple versions at the same time and do tests between them and so on",
    "start": "389280",
    "end": "394720"
  },
  {
    "text": "so in order to to make such things easier to describe we can",
    "start": "394720",
    "end": "402560"
  },
  {
    "start": "401000",
    "end": "507000"
  },
  {
    "text": "break deployment from the release process we use the continuous delivery tool to",
    "start": "402560",
    "end": "411599"
  },
  {
    "text": "create deployments inside the cluster but instead of letting kubernetes roll out that deployment to everyone",
    "start": "411599",
    "end": "418080"
  },
  {
    "text": "we have a new thing that sits at the end of the pipeline and drives the release process",
    "start": "418080",
    "end": "424720"
  },
  {
    "text": "differently from what kubernetes is usually doing and here is where flagger comes into",
    "start": "424720",
    "end": "432160"
  },
  {
    "text": "place so you have your cluster repo you have your deployments there and you also have a",
    "start": "432160",
    "end": "437199"
  },
  {
    "text": "canary object custom resource definition that flagger understands where you define the policy",
    "start": "437199",
    "end": "442400"
  },
  {
    "text": "of how you want the release process to happen inside the cluster so",
    "start": "442400",
    "end": "450319"
  },
  {
    "text": "when you change something in your in your cluster state let's say you bump the version of a application",
    "start": "450319",
    "end": "457919"
  },
  {
    "text": "flux or another githubs operator there are many out there will apply that",
    "start": "457919",
    "end": "463840"
  },
  {
    "text": "change but instead of letting that change end up directly in your",
    "start": "463840",
    "end": "471680"
  },
  {
    "text": "node balancer so your users will end up on the new version flagger will take over from there and",
    "start": "471680",
    "end": "479680"
  },
  {
    "text": "will route traffic a small portion of your traffic towards",
    "start": "479680",
    "end": "485039"
  },
  {
    "text": "the new version will keep increasing that traffic weight it will measure metrics from prometheus",
    "start": "485039",
    "end": "492479"
  },
  {
    "text": "data dog cloudwatch and others and based on on those metrics it will take the decision is the",
    "start": "492479",
    "end": "500080"
  },
  {
    "text": "new version fit to serve production traffic or not",
    "start": "500080",
    "end": "507840"
  },
  {
    "start": "507000",
    "end": "537000"
  },
  {
    "text": "so as i said flagger is a kubernetes operator you deploy it on your cluster it has",
    "start": "508800",
    "end": "514719"
  },
  {
    "text": "this declarative model through a custom resource definition so it can create",
    "start": "514719",
    "end": "520399"
  },
  {
    "text": "uh policies uh inside your git repo how you want",
    "start": "520399",
    "end": "525440"
  },
  {
    "text": "the release to happen and flagger uses a traffic management solution to to",
    "start": "525440",
    "end": "532560"
  },
  {
    "text": "route traffic between between versions",
    "start": "532560",
    "end": "537839"
  },
  {
    "start": "537000",
    "end": "603000"
  },
  {
    "text": "and flagger works with a couple of service mesh implementations istio linkard upmesh and because flagger",
    "start": "538480",
    "end": "546480"
  },
  {
    "text": "works nicely with the service mesh interface things like open service mesh or",
    "start": "546480",
    "end": "554720"
  },
  {
    "text": "contour or [Music]",
    "start": "554720",
    "end": "560929"
  },
  {
    "text": "corp console connect could be uh could be working with",
    "start": "561200",
    "end": "567440"
  },
  {
    "text": "flagger in the future now maybe you don't you are not ready to use a service mesh or",
    "start": "567440",
    "end": "574959"
  },
  {
    "text": "you just want to do progressive delivery um with ingress controllers for that",
    "start": "574959",
    "end": "581120"
  },
  {
    "text": "flagger uh works with contour with glue with nginx and and skipper and you can combine for",
    "start": "581120",
    "end": "588320"
  },
  {
    "text": "example linkard doesn't come with an ingrow solution so you can combine one of those ingress controllers with",
    "start": "588320",
    "end": "594959"
  },
  {
    "text": "link rd and do both camera releases for your front-end apps",
    "start": "594959",
    "end": "600800"
  },
  {
    "text": "and back-end apps as well now in terms of deployment strategies",
    "start": "600800",
    "end": "607440"
  },
  {
    "start": "603000",
    "end": "724000"
  },
  {
    "text": "flagger implements a couple of different things the first one can",
    "start": "607440",
    "end": "612640"
  },
  {
    "text": "release with progressive traffic shifting works great for apps that expose http or grpc apis",
    "start": "612640",
    "end": "620160"
  },
  {
    "text": "stateful apps microservices etc now for front-end apps that have",
    "start": "620160",
    "end": "628000"
  },
  {
    "text": "let's say an api but also a static content like javascript css html and so on",
    "start": "628000",
    "end": "634880"
  },
  {
    "text": "when you are when you are doing the camera release you want to pin users to a particular",
    "start": "634880",
    "end": "642160"
  },
  {
    "text": "version and how can you do that with session affinity and flagger lets you",
    "start": "642160",
    "end": "648640"
  },
  {
    "text": "segment your users based on http headers or cookies so you can say all the users",
    "start": "648640",
    "end": "656079"
  },
  {
    "text": "that have this particular cookie only those will be used to test the new version",
    "start": "656079",
    "end": "664160"
  },
  {
    "text": "uh other strategies are blue green with traffic mirroring this works with uh",
    "start": "664160",
    "end": "669440"
  },
  {
    "text": "istio well this kind of strategy works great with item button apis so if your api is doing",
    "start": "669440",
    "end": "677680"
  },
  {
    "text": "any kind of change rights to a database or does uh uh changes some state",
    "start": "677680",
    "end": "684640"
  },
  {
    "text": "uh traffic mirroring is is not the way to do it because you will be duplicating all these sections but",
    "start": "684640",
    "end": "690720"
  },
  {
    "text": "if you have let's say machine learning workloads or caching",
    "start": "690720",
    "end": "697040"
  },
  {
    "text": "system or things that are you know building reports or any kind of get query uh traffic mirroring works",
    "start": "697040",
    "end": "705279"
  },
  {
    "text": "great for that and finally blue green the classical blue green where",
    "start": "705279",
    "end": "711600"
  },
  {
    "text": "flagger will run your end-to-end tests load tests looks at the metrics and based on that",
    "start": "711600",
    "end": "717440"
  },
  {
    "text": "result it does the switch from one version to another in a single go",
    "start": "717440",
    "end": "723360"
  },
  {
    "text": "and i have here um some graphical representation of how everything works the idea",
    "start": "723360",
    "end": "730560"
  },
  {
    "text": "is flagger monitors the the deployment that gets applied on the cluster",
    "start": "730560",
    "end": "737200"
  },
  {
    "text": "when it detects a new change it scales out the deployment starts to route traffic towards it with",
    "start": "737200",
    "end": "743600"
  },
  {
    "text": "metrics and at the end if everything goes okay it lets kubernetes",
    "start": "743600",
    "end": "748959"
  },
  {
    "text": "to the full rollout inside the cluster and for a b testing it uses instead of",
    "start": "748959",
    "end": "756720"
  },
  {
    "text": "gradually shifting traffic it uses a certain segment based on headers",
    "start": "756720",
    "end": "764560"
  },
  {
    "text": "and for blue green it runs tests then it does the final switch",
    "start": "764560",
    "end": "772240"
  },
  {
    "text": "okay demo time so i'm going to use flux version 2",
    "start": "772240",
    "end": "777760"
  },
  {
    "text": "to set up my cluster i'm going to use flagger for progressive delivery and i'm",
    "start": "777760",
    "end": "782880"
  },
  {
    "text": "going to use contour for doing a b testing for front-end apps and link rd for doing",
    "start": "782880",
    "end": "792160"
  },
  {
    "text": "canary releases inside the cluster for back-end apps",
    "start": "792160",
    "end": "800880"
  },
  {
    "text": "okay so i have an empty cluster here",
    "start": "800880",
    "end": "808079"
  },
  {
    "text": "okay i have a git repo",
    "start": "811040",
    "end": "816399"
  },
  {
    "text": "on github where i'm defining the state of my cluster",
    "start": "816399",
    "end": "821760"
  },
  {
    "text": "we have the infrastructure items like linker d flagger contour and i'm",
    "start": "821760",
    "end": "828480"
  },
  {
    "text": "i'm also defining two workloads front end and a back and up",
    "start": "828480",
    "end": "834720"
  },
  {
    "text": "so first i'm going to install flux",
    "start": "834720",
    "end": "842000"
  },
  {
    "text": "flux version 2 is composed of several uh controllers we have a controller that",
    "start": "842000",
    "end": "848880"
  },
  {
    "text": "deals with sources like git repositories or helm repositories or",
    "start": "848880",
    "end": "854000"
  },
  {
    "text": "s3 buckets and we also have specialized reconcilers like hand controller that knows how to",
    "start": "854000",
    "end": "862160"
  },
  {
    "text": "install a helm release run the tests upgrade roll back and so on and we have",
    "start": "862160",
    "end": "868079"
  },
  {
    "text": "customized controller which applies customize overlays on your cluster and so on",
    "start": "868079",
    "end": "874560"
  },
  {
    "text": "okay so i have flux installed now i want to",
    "start": "874560",
    "end": "879680"
  },
  {
    "text": "add this ripple to my cluster",
    "start": "880160",
    "end": "885839"
  },
  {
    "text": "so what i've told flux now is connect to the uh to my github repository",
    "start": "887839",
    "end": "894000"
  },
  {
    "text": "pull the pull all the manifest from there and make them available inside the cluster",
    "start": "894000",
    "end": "899680"
  },
  {
    "text": "now i'm going to tell flux how to reconcile the infrastructure items so first time",
    "start": "899680",
    "end": "906639"
  },
  {
    "text": "defining the the linker d customization inside uh the infrastructure link of the",
    "start": "906639",
    "end": "913040"
  },
  {
    "text": "directory there is a hand repository and a henry list helm repository points to the official",
    "start": "913040",
    "end": "919040"
  },
  {
    "text": "linker d uh repo where where their charts are and the hair release configures how i",
    "start": "919040",
    "end": "925279"
  },
  {
    "text": "want linker d to be installed on my cluster and here i'm also telling flux after",
    "start": "925279",
    "end": "934000"
  },
  {
    "text": "you apply all things make sure that the lingard proxy injector is up and",
    "start": "934000",
    "end": "939440"
  },
  {
    "text": "running and i'm going to use this information to define how how the cluster",
    "start": "939440",
    "end": "946480"
  },
  {
    "text": "reconciliation should work so link id as a service mesh needs to",
    "start": "946480",
    "end": "953920"
  },
  {
    "text": "inject um a proxy side car in each pod so i need to make sure that when i'm",
    "start": "953920",
    "end": "961279"
  },
  {
    "text": "reconciling anything else inside my cluster linker the injector is up and running so i get",
    "start": "961279",
    "end": "966800"
  },
  {
    "text": "a valid state of my workload okay i'm installing kodi now i'm going",
    "start": "966800",
    "end": "973120"
  },
  {
    "text": "to configure flagger and i'm telling flux hey flagger depends",
    "start": "973120",
    "end": "979759"
  },
  {
    "text": "on linkedin and finally i'm going to [Music]",
    "start": "979759",
    "end": "986399"
  },
  {
    "text": "tell flux to reconcile contour as well",
    "start": "986399",
    "end": "991920"
  },
  {
    "text": "so before this is okay let me run contour here and i'm going to",
    "start": "992480",
    "end": "999680"
  },
  {
    "text": "show you here in the infrastructure how i've configured contour so i want contour to be part of my",
    "start": "999680",
    "end": "1006560"
  },
  {
    "text": "service mesh and in order to do that i define a",
    "start": "1006560",
    "end": "1011839"
  },
  {
    "text": "customized patch for contour so i'm i'm pulling the contour manifest from the",
    "start": "1011839",
    "end": "1017279"
  },
  {
    "text": "contour repo but then i'm telling flux hey",
    "start": "1017279",
    "end": "1022399"
  },
  {
    "text": "take all this configuration and apply this customize batch to it contour comes with the demon set for for",
    "start": "1022399",
    "end": "1029199"
  },
  {
    "text": "the invoice reverse proxy and i'm adding here",
    "start": "1029199",
    "end": "1034400"
  },
  {
    "text": "an annotation to tell linker the inject from the project contour namespace inject your",
    "start": "1034400",
    "end": "1041120"
  },
  {
    "text": "sidecar only in the envoy pods",
    "start": "1041120",
    "end": "1046000"
  },
  {
    "text": "okay so i have everything running now if i'm i'm going",
    "start": "1046559",
    "end": "1052640"
  },
  {
    "text": "to look now at flagger logs seen that flagger has started it has",
    "start": "1052640",
    "end": "1059360"
  },
  {
    "text": "connected to the link rd prometheus and what i'm going to do now i'm going",
    "start": "1059360",
    "end": "1064559"
  },
  {
    "text": "to tell flux to deploy the workloads i have provisioned in my repo",
    "start": "1064559",
    "end": "1070720"
  },
  {
    "text": "i'm applying the workloads and flagger will",
    "start": "1070720",
    "end": "1078080"
  },
  {
    "text": "will start uh monitoring uh the the diplomas because in my workload",
    "start": "1078080",
    "end": "1084400"
  },
  {
    "text": "definition i also have uh canary custom resources and based on on that custom resource",
    "start": "1084400",
    "end": "1092000"
  },
  {
    "text": "flag will bootstrap both applications for us so if we look at what's happening in the",
    "start": "1092000",
    "end": "1098480"
  },
  {
    "text": "front-end main space",
    "start": "1098480",
    "end": "1101679"
  },
  {
    "text": "i see there are things happening so this is my deployment that i have i have",
    "start": "1107280",
    "end": "1112720"
  },
  {
    "text": "defined in my ditriple pod info in the front and namespace but i also have a canary definition for",
    "start": "1112720",
    "end": "1120320"
  },
  {
    "text": "for boarding called tells flagger how to configure the the whole thing what flagger does it",
    "start": "1120320",
    "end": "1126960"
  },
  {
    "text": "says okay i have this deployment running i'm going to take over the",
    "start": "1126960",
    "end": "1132720"
  },
  {
    "text": "uh reconciliation for it and i'm going to create a clone out of that deployment and the clone is",
    "start": "1132720",
    "end": "1138160"
  },
  {
    "text": "named minus primary after the clone is up and running",
    "start": "1138160",
    "end": "1143440"
  },
  {
    "text": "flagger will scale to zero the deployment that flux applied all",
    "start": "1143440",
    "end": "1148799"
  },
  {
    "text": "your uh production traffic from this moment on goes to pod info primary",
    "start": "1148799",
    "end": "1154080"
  },
  {
    "text": "so now if i'm looking again at the pods seeing that whatever was in it it's it's gone it's",
    "start": "1154080",
    "end": "1159760"
  },
  {
    "text": "scaled to zero and these primary pods are running flagger also creates",
    "start": "1159760",
    "end": "1165840"
  },
  {
    "text": "kubernetes services and contour ingress objects and",
    "start": "1165840",
    "end": "1172080"
  },
  {
    "text": "for for kubernetes services creates three services one is the apex service canary and the primary and these",
    "start": "1172080",
    "end": "1178320"
  },
  {
    "text": "services will be used for traffic switching so in your git repo you",
    "start": "1178320",
    "end": "1185600"
  },
  {
    "text": "are only defining uh your deployment and a horizontal port autoscaler and flagger will will create all the other",
    "start": "1185600",
    "end": "1192720"
  },
  {
    "text": "objects for you now i'm going to",
    "start": "1192720",
    "end": "1199120"
  },
  {
    "text": "pull forward to the envoy ingress controller and see if my app is",
    "start": "1199120",
    "end": "1205679"
  },
  {
    "text": "running yeah so i have version 500",
    "start": "1205679",
    "end": "1211520"
  },
  {
    "start": "1208000",
    "end": "1647000"
  },
  {
    "text": "bootstrap deployed in my cluster now let's say i want to do",
    "start": "1211520",
    "end": "1218400"
  },
  {
    "text": "release and how i'm going to do that i'm going into the ripple and i'm going to bump",
    "start": "1218400",
    "end": "1224880"
  },
  {
    "text": "the version number so workloads",
    "start": "1224880",
    "end": "1230400"
  },
  {
    "text": "front end and i have here um the definition of",
    "start": "1230400",
    "end": "1239120"
  },
  {
    "text": "where pod info deployments and horizontal auto scaler come from it comes from the app repo itself",
    "start": "1239120",
    "end": "1247280"
  },
  {
    "text": "for and and i've told flux to pick a particular uh tag now i can",
    "start": "1247280",
    "end": "1254720"
  },
  {
    "text": "tell flux to monitor the container registry and do the patching on its own and bump the the version every time i'm",
    "start": "1254720",
    "end": "1262240"
  },
  {
    "text": "i'm pushing something to the registry or i can do it manually so i'm going in here and saying hey i",
    "start": "1262240",
    "end": "1268400"
  },
  {
    "text": "want to deploy 501 i'm going to commit this change",
    "start": "1268400",
    "end": "1276559"
  },
  {
    "text": "and if i'm doing watch flux get customizations",
    "start": "1276559",
    "end": "1285279"
  },
  {
    "text": "what is going to happen is source controller part of flux will detect there is a new change in the",
    "start": "1286320",
    "end": "1292480"
  },
  {
    "text": "ripple we'll pull that change inside the cluster then the specialized controllers like customize control say hey i have a new",
    "start": "1292480",
    "end": "1299919"
  },
  {
    "text": "new revision i'm going to apply that uh inside",
    "start": "1299919",
    "end": "1306960"
  },
  {
    "text": "okay the new revision has been detected and now",
    "start": "1313919",
    "end": "1319840"
  },
  {
    "text": "flux applies that change in the order that i have specified so it takes into account dependencies first it applies",
    "start": "1319840",
    "end": "1326640"
  },
  {
    "text": "linker d uh then it applies uh my workloads and the workload has",
    "start": "1326640",
    "end": "1334400"
  },
  {
    "text": "has been applied it has moved to the new revision and if we look at what flagger is doing",
    "start": "1334400",
    "end": "1343360"
  },
  {
    "text": "flagger is saying hey i have detected a new version so i need to test it out according to the policy that i have in",
    "start": "1343360",
    "end": "1350880"
  },
  {
    "text": "my git report and if we look here we see that",
    "start": "1350880",
    "end": "1356320"
  },
  {
    "text": "we end up on five zero one and this is firefox let's see what happens if i'm",
    "start": "1356640",
    "end": "1364880"
  },
  {
    "text": "going to visit the same url using chrome on chrome i'm on five zero zero",
    "start": "1364880",
    "end": "1370159"
  },
  {
    "text": "why is that in my release definition",
    "start": "1370159",
    "end": "1376880"
  },
  {
    "text": "here i have so this is a canary definition for flagger and where i told",
    "start": "1378320",
    "end": "1383840"
  },
  {
    "text": "flagger hey test the new version only on users that have a header",
    "start": "1383840",
    "end": "1391360"
  },
  {
    "text": "that contains firefox in the user agent so i'm segmenting my user based on",
    "start": "1391360",
    "end": "1397440"
  },
  {
    "text": "something from the user agent header and i'm using those users to test my new",
    "start": "1397440",
    "end": "1403120"
  },
  {
    "text": "version so here i'm still on on zero zero and",
    "start": "1403120",
    "end": "1408559"
  },
  {
    "text": "this is where test is running right now",
    "start": "1408559",
    "end": "1412799"
  },
  {
    "text": "what flagger does every 10 seconds it reads metrics",
    "start": "1414320",
    "end": "1420640"
  },
  {
    "text": "checks that my slos my conditions are are fine i've made",
    "start": "1420640",
    "end": "1426880"
  },
  {
    "text": "conditions like 99 99 of all requests must succeed",
    "start": "1426880",
    "end": "1432400"
  },
  {
    "text": "the latency of my new app has to be under 500 milliseconds and so on so it checks all this",
    "start": "1432400",
    "end": "1437760"
  },
  {
    "text": "uh uh all these slos that i've defined and once the iterations are over",
    "start": "1437760",
    "end": "1444799"
  },
  {
    "text": "i've set up 10 iterations it should fully promote the new version",
    "start": "1444799",
    "end": "1450320"
  },
  {
    "text": "to all users and how it does that the moment the",
    "start": "1450320",
    "end": "1456720"
  },
  {
    "text": "the analysis is over it tells kubernetes hey now do the rolling upgrade",
    "start": "1456720",
    "end": "1461840"
  },
  {
    "text": "of the primary deployment with with what's declared in it",
    "start": "1461840",
    "end": "1468880"
  },
  {
    "text": "and it's doing that right now flagger also waits for horizontal auto",
    "start": "1468880",
    "end": "1474960"
  },
  {
    "text": "scaler to to scale up or down the workload so it pauses the",
    "start": "1474960",
    "end": "1480080"
  },
  {
    "text": "the analysis while hpa is running",
    "start": "1480080",
    "end": "1486720"
  },
  {
    "text": "it waits for uh for the all pods terminate and then it will uh finalize the the release so if i'm",
    "start": "1486720",
    "end": "1493520"
  },
  {
    "text": "going back here to my uh chrome",
    "start": "1493520",
    "end": "1498559"
  },
  {
    "text": "i see that now both uh both uh variant of",
    "start": "1498559",
    "end": "1504960"
  },
  {
    "text": "of users are on the same on the same version and this is how i've done an a b test",
    "start": "1504960",
    "end": "1513278"
  },
  {
    "text": "okay now let's see how how progressive a progressive trash",
    "start": "1513520",
    "end": "1518960"
  },
  {
    "text": "traffic shifting happens so i have here in workloads",
    "start": "1518960",
    "end": "1527120"
  },
  {
    "text": "the back-end definition it's still coding for the same app but in the",
    "start": "1527120",
    "end": "1535679"
  },
  {
    "text": "in the canary definition i've i've changed things a little there is no longer a header matching uh",
    "start": "1535679",
    "end": "1542799"
  },
  {
    "text": "condition now i'm configured i'm configuring flagger to shift traffic weight from",
    "start": "1542799",
    "end": "1551200"
  },
  {
    "text": "one version to another and i'm i'm telling flagger to start with five percent",
    "start": "1551200",
    "end": "1556400"
  },
  {
    "text": "go up to fifty percent while measuring metrics and so on and if everything goes uh according to",
    "start": "1556400",
    "end": "1562880"
  },
  {
    "text": "plan then do the final uh rollout",
    "start": "1562880",
    "end": "1571039"
  },
  {
    "text": "so what i'm going to do now i'm going to tell flux to update the backend",
    "start": "1571039",
    "end": "1578400"
  },
  {
    "text": "app and instead of specifying here a fixed version a fixed",
    "start": "1578400",
    "end": "1584720"
  },
  {
    "text": "git tag i'm going telflux to i'm going telflux to loop to take into",
    "start": "1584720",
    "end": "1591279"
  },
  {
    "text": "account a server expression find the latest release for that same word expression",
    "start": "1591279",
    "end": "1597360"
  },
  {
    "text": "and deploy that in my cluster so i'm doing here somewhere the expression is greater than",
    "start": "1597360",
    "end": "1604960"
  },
  {
    "text": "five zero commit this change",
    "start": "1604960",
    "end": "1613840"
  },
  {
    "text": "and",
    "start": "1614640",
    "end": "1617039"
  },
  {
    "text": "now if i'm looking at my back end",
    "start": "1621279",
    "end": "1627840"
  },
  {
    "text": "seeing that flagger has detected the new version and it will start to throw a lot traffic",
    "start": "1630559",
    "end": "1637760"
  },
  {
    "text": "towards it let's pour forward to the link of the",
    "start": "1637760",
    "end": "1643360"
  },
  {
    "text": "dashboard we don't need this anymore",
    "start": "1643360",
    "end": "1648960"
  },
  {
    "start": "1647000",
    "end": "1976000"
  },
  {
    "text": "okay let's look at linkardi so link rd can show how traffic",
    "start": "1648960",
    "end": "1655200"
  },
  {
    "text": "splitting is happening inside the cluster so if i look here",
    "start": "1655200",
    "end": "1660240"
  },
  {
    "text": "with info i see that liquid is reporting that the primary now is on 95",
    "start": "1660240",
    "end": "1666880"
  },
  {
    "text": "and the canary is on five percent now let's say there is something",
    "start": "1666880",
    "end": "1674159"
  },
  {
    "text": "going wrong with the canary how can i simulate errors i'm going to accept into a pod",
    "start": "1674159",
    "end": "1682240"
  },
  {
    "text": "i'm going to generate 500 errors for my canary workload",
    "start": "1682240",
    "end": "1690559"
  },
  {
    "text": "what flagger is doing it keeps increasing the weight and measures latency and error rate",
    "start": "1693360",
    "end": "1701600"
  },
  {
    "text": "now while i'm generating errors flagger has detected that okay the",
    "start": "1701600",
    "end": "1707840"
  },
  {
    "text": "success rate should be 99 percent and it now got to 97",
    "start": "1707840",
    "end": "1715200"
  },
  {
    "text": "and the success rate keeps dropping what is going to happen i've set a",
    "start": "1715440",
    "end": "1720799"
  },
  {
    "text": "threshold for flagger it fails more than three times roll it back and what flagger is doing right now it",
    "start": "1720799",
    "end": "1728080"
  },
  {
    "text": "has determined that the release conditions are not met",
    "start": "1728080",
    "end": "1734080"
  },
  {
    "text": "it it routes all the traffic back to the primary deployment",
    "start": "1734080",
    "end": "1739360"
  },
  {
    "text": "and scales down the experiment the canary so if we look back here",
    "start": "1739360",
    "end": "1748399"
  },
  {
    "text": "we see that the primary pods are still running the same as those one and my experiment",
    "start": "1749440",
    "end": "1756399"
  },
  {
    "text": "has failed and it's gone if i'm doing get pod",
    "start": "1756399",
    "end": "1764480"
  },
  {
    "text": "this one",
    "start": "1764480",
    "end": "1767840"
  },
  {
    "text": "looking at the image i stay i see that it's still on five zero zero so",
    "start": "1773520",
    "end": "1780640"
  },
  {
    "text": "this is how you can set service level objectives with with",
    "start": "1780640",
    "end": "1786399"
  },
  {
    "text": "flagger based on the metrics that the service measure and ingers controllers offers",
    "start": "1786399",
    "end": "1791520"
  },
  {
    "text": "now maybe you want to do more than that i mean it's it's okay to look at errors",
    "start": "1791520",
    "end": "1797919"
  },
  {
    "text": "and latency but in your release process you may want to include custom metrics like",
    "start": "1797919",
    "end": "1804399"
  },
  {
    "text": "whatever how many connections are open to a database how many people are clicking on a button",
    "start": "1804399",
    "end": "1809919"
  },
  {
    "text": "in an a b test and so on how you can do that you can instrument your apps with",
    "start": "1809919",
    "end": "1815440"
  },
  {
    "text": "let's say a prometus or you push the metrics to datadog",
    "start": "1815440",
    "end": "1821120"
  },
  {
    "text": "watch new relic and so on and flagger allows you to declare",
    "start": "1821120",
    "end": "1829200"
  },
  {
    "text": "service level objectives targeting these method providers so flagger will run a queries on datadog",
    "start": "1829200",
    "end": "1836399"
  },
  {
    "text": "let's say take those metrics from there and you can set a threshold for for each one",
    "start": "1836399",
    "end": "1842720"
  },
  {
    "text": "this was a demo going back to the",
    "start": "1843279",
    "end": "1847760"
  },
  {
    "text": "presentation",
    "start": "1848840",
    "end": "1851840"
  },
  {
    "text": "so if you are interested in how flagr works there is a docs website with details on how",
    "start": "1854960",
    "end": "1861519"
  },
  {
    "text": "you can configure it to work with any kind of service mesh on ingress controller how you can ingress controls how you can",
    "start": "1861519",
    "end": "1868000"
  },
  {
    "text": "define metric providers how you can configure flagger to issue kubernetes events for",
    "start": "1868000",
    "end": "1874880"
  },
  {
    "text": "everything that's happening or pause to slack microsoft teams rocket another",
    "start": "1874880",
    "end": "1880720"
  },
  {
    "text": "chat platform so you know when flagger did the rollback when it starts and so",
    "start": "1880720",
    "end": "1886000"
  },
  {
    "text": "on uh flagler also has capabilities like uh manual gating for example you can",
    "start": "1886000",
    "end": "1893600"
  },
  {
    "text": "configure flagger before it starts uh can release to ask permission so it will call on",
    "start": "1893600",
    "end": "1901519"
  },
  {
    "text": "webhook and say hey i want to start this can release am i allowed to do that and you can also have manual gates for",
    "start": "1901519",
    "end": "1908960"
  },
  {
    "text": "the final promotion so it does the release but uh it does the analysis but it doesn't do the final",
    "start": "1908960",
    "end": "1915200"
  },
  {
    "text": "release until someone tells it do it and so on um please check out the",
    "start": "1915200",
    "end": "1922559"
  },
  {
    "text": "um the repos here so it's a demo repo you linked the encounter what i demo",
    "start": "1922559",
    "end": "1928000"
  },
  {
    "text": "today and there is also one for uh for istio and uses both",
    "start": "1928000",
    "end": "1933519"
  },
  {
    "text": "flagger and flux to drive the whole thing from a guitar's perspective",
    "start": "1933519",
    "end": "1938559"
  },
  {
    "text": "now everything that i've shown is with guitars uh and it's using flag hd is in flux but",
    "start": "1938559",
    "end": "1944480"
  },
  {
    "text": "you can use flagger uh with any kind of continuous delivery tools even",
    "start": "1944480",
    "end": "1949760"
  },
  {
    "text": "if you do the whole thing from ci because flagger can be configured and controlled",
    "start": "1949760",
    "end": "1956080"
  },
  {
    "text": "through uh through a custom resource saying if you apply that from jenkins or whatever you are using",
    "start": "1956080",
    "end": "1962159"
  },
  {
    "text": "it will still do the same thing thank you very much and please try out flagger let me know",
    "start": "1962159",
    "end": "1970240"
  },
  {
    "text": "how it goes have a nice day",
    "start": "1970240",
    "end": "1976000"
  },
  {
    "text": "you",
    "start": "1976000",
    "end": "1978080"
  }
]
[
  {
    "start": "0",
    "end": "65000"
  },
  {
    "text": "hello everyone my name is Renault Qbert",
    "start": "30",
    "end": "3140"
  },
  {
    "text": "I'm an engineer at Nvidia I've been",
    "start": "3140",
    "end": "7639"
  },
  {
    "text": "contributing to the and working in the",
    "start": "7639",
    "end": "10519"
  },
  {
    "text": "communities community for the past year",
    "start": "10519",
    "end": "12750"
  },
  {
    "text": "with my team a container team and today",
    "start": "12750",
    "end": "16379"
  },
  {
    "text": "I'm going to talk mostly about GPU as a",
    "start": "16379",
    "end": "19980"
  },
  {
    "text": "service how do you actually deploy your",
    "start": "19980",
    "end": "23430"
  },
  {
    "text": "GPU cluster and where are the challenges",
    "start": "23430",
    "end": "25859"
  },
  {
    "text": "that you face when you operate a GPU",
    "start": "25859",
    "end": "29670"
  },
  {
    "text": "cluster or as a user the challenges that",
    "start": "29670",
    "end": "32610"
  },
  {
    "text": "you face when deploying your GP",
    "start": "32610",
    "end": "35700"
  },
  {
    "text": "applications will also look a bit into",
    "start": "35700",
    "end": "39469"
  },
  {
    "text": "how we actually built them the GPU and",
    "start": "39469",
    "end": "43350"
  },
  {
    "text": "device system in kubernetes",
    "start": "43350",
    "end": "46350"
  },
  {
    "text": "and less part will be about where the",
    "start": "46350",
    "end": "50039"
  },
  {
    "text": "challenges and the different solutions",
    "start": "50039",
    "end": "53399"
  },
  {
    "text": "that we want to see in kubernetes and in",
    "start": "53399",
    "end": "55020"
  },
  {
    "text": "general that we want to solve for GPUs",
    "start": "55020",
    "end": "56850"
  },
  {
    "text": "and so if we go ahead and look at why",
    "start": "56850",
    "end": "66630"
  },
  {
    "start": "65000",
    "end": "65000"
  },
  {
    "text": "GPUs and containers makes a lot of sense",
    "start": "66630",
    "end": "69150"
  },
  {
    "text": "you'll find out that actually containers",
    "start": "69150",
    "end": "72270"
  },
  {
    "text": "solve a lot of issues that mostly deep",
    "start": "72270",
    "end": "77040"
  },
  {
    "text": "learning scientists or HPC applications",
    "start": "77040",
    "end": "79830"
  },
  {
    "text": "or in general GPU applications have a",
    "start": "79830",
    "end": "83450"
  },
  {
    "text": "problem with and so if you're deploying",
    "start": "83450",
    "end": "86369"
  },
  {
    "text": "scientists for example you're going to",
    "start": "86369",
    "end": "88710"
  },
  {
    "text": "have a lot of issues well the first",
    "start": "88710",
    "end": "91530"
  },
  {
    "text": "thing that you're going to have an issue",
    "start": "91530",
    "end": "92939"
  },
  {
    "text": "is is actually installing tensorflow",
    "start": "92939",
    "end": "95990"
  },
  {
    "text": "it's it's not really easy and container",
    "start": "95990",
    "end": "98850"
  },
  {
    "text": "actually solve that because you actually",
    "start": "98850",
    "end": "100560"
  },
  {
    "text": "get really easily into dependency hell",
    "start": "100560",
    "end": "103110"
  },
  {
    "text": "and when you're deploying scientists you",
    "start": "103110",
    "end": "104970"
  },
  {
    "text": "don't want to spend a day at installing",
    "start": "104970",
    "end": "107130"
  },
  {
    "text": "and configuring your machine just to get",
    "start": "107130",
    "end": "111420"
  },
  {
    "text": "tensorflow",
    "start": "111420",
    "end": "111930"
  },
  {
    "text": "but doesn't stop there once you've",
    "start": "111930",
    "end": "113700"
  },
  {
    "text": "actually set up a GPU application or a",
    "start": "113700",
    "end": "116100"
  },
  {
    "text": "deep learning model and that you want to",
    "start": "116100",
    "end": "117479"
  },
  {
    "text": "distribute it to your co-workers well",
    "start": "117479",
    "end": "119969"
  },
  {
    "text": "you actually find out that there's a lot",
    "start": "119969",
    "end": "122399"
  },
  {
    "text": "of issues for example your GPU Mali area",
    "start": "122399",
    "end": "125280"
  },
  {
    "text": "sorry you're a deep learning model is",
    "start": "125280",
    "end": "126990"
  },
  {
    "text": "not going to converge or you won't have",
    "start": "126990",
    "end": "129209"
  },
  {
    "text": "the same speed because your co-workers",
    "start": "129209",
    "end": "132120"
  },
  {
    "text": "don't have the same tensional",
    "start": "132120",
    "end": "134220"
  },
  {
    "text": "so continuous actually solver that that",
    "start": "134220",
    "end": "138270"
  },
  {
    "text": "problem because you're actually just",
    "start": "138270",
    "end": "140040"
  },
  {
    "text": "distributing your code with its",
    "start": "140040",
    "end": "141960"
  },
  {
    "text": "dependencies and if you've ever tried to",
    "start": "141960",
    "end": "144540"
  },
  {
    "text": "actually install to version the",
    "start": "144540",
    "end": "146310"
  },
  {
    "text": "tensorflow on the same machine you'll",
    "start": "146310",
    "end": "148950"
  },
  {
    "text": "find out that installing tensorflow was",
    "start": "148950",
    "end": "151920"
  },
  {
    "text": "hell but answering to version of",
    "start": "151920",
    "end": "153900"
  },
  {
    "text": "tensorflow is is even harder and some of",
    "start": "153900",
    "end": "157770"
  },
  {
    "text": "the other issues that we're looking at",
    "start": "157770",
    "end": "159300"
  },
  {
    "text": "are how do i scale deep learning",
    "start": "159300",
    "end": "161610"
  },
  {
    "text": "application i've training my model on my",
    "start": "161610",
    "end": "164760"
  },
  {
    "text": "machine now I want more compute power I",
    "start": "164760",
    "end": "166620"
  },
  {
    "text": "want to scale more GPUs how do I solve",
    "start": "166620",
    "end": "170400"
  },
  {
    "text": "that how do I deploy a fault turrent",
    "start": "170400",
    "end": "173160"
  },
  {
    "text": "inference service in general how do i",
    "start": "173160",
    "end": "175170"
  },
  {
    "text": "tree bring the kubernetes the the",
    "start": "175170",
    "end": "180240"
  },
  {
    "text": "kubernetes way to GPU services so so if",
    "start": "180240",
    "end": "187500"
  },
  {
    "text": "you solve a lot of these challenges",
    "start": "187500",
    "end": "188760"
  },
  {
    "text": "we've we built our container tools from",
    "start": "188760",
    "end": "191190"
  },
  {
    "text": "the ground up to and will help us",
    "start": "191190",
    "end": "194600"
  },
  {
    "text": "support a lot of different use cases and",
    "start": "194600",
    "end": "197640"
  },
  {
    "text": "if you if you were familiar with Nvidia",
    "start": "197640",
    "end": "200370"
  },
  {
    "text": "dr. before what we were actually doing",
    "start": "200370",
    "end": "203190"
  },
  {
    "text": "is wrapping docker",
    "start": "203190",
    "end": "204480"
  },
  {
    "text": "specifically and you couldn't really use",
    "start": "204480",
    "end": "207239"
  },
  {
    "text": "a video docker for like any other",
    "start": "207239",
    "end": "210420"
  },
  {
    "text": "runtime and what we've what we did is",
    "start": "210420",
    "end": "213420"
  },
  {
    "text": "actually we integrate now at the runtime",
    "start": "213420",
    "end": "216030"
  },
  {
    "text": "level that means that we support a lot",
    "start": "216030",
    "end": "218610"
  },
  {
    "text": "more runtimes so for example Dockers",
    "start": "218610",
    "end": "220950"
  },
  {
    "text": "here are your singularity LXE and if",
    "start": "220950",
    "end": "224459"
  },
  {
    "text": "you're actually not familiar with this",
    "start": "224459",
    "end": "226019"
  },
  {
    "text": "the challenges that we're trying to face",
    "start": "226019",
    "end": "228440"
  },
  {
    "text": "with GPUs in containers there's a lot of",
    "start": "228440",
    "end": "232410"
  },
  {
    "text": "small things the biggest one being that",
    "start": "232410",
    "end": "235610"
  },
  {
    "text": "the cooler libraries that a lot of these",
    "start": "235610",
    "end": "238440"
  },
  {
    "text": "frameworks are deploying frameworks",
    "start": "238440",
    "end": "240810"
  },
  {
    "text": "depend on they have this very strict",
    "start": "240810",
    "end": "242880"
  },
  {
    "text": "requirement that you your your library",
    "start": "242880",
    "end": "246120"
  },
  {
    "text": "version must exactly match your kernel",
    "start": "246120",
    "end": "248610"
  },
  {
    "text": "your kernel module version that means",
    "start": "248610",
    "end": "251670"
  },
  {
    "text": "that you can't actually ship a container",
    "start": "251670",
    "end": "252870"
  },
  {
    "text": "with the cooler libraries or just in",
    "start": "252870",
    "end": "255720"
  },
  {
    "text": "general the user libraries that you",
    "start": "255720",
    "end": "257579"
  },
  {
    "text": "would like that like you would do for",
    "start": "257580",
    "end": "259590"
  },
  {
    "text": "any other general application we need to",
    "start": "259590",
    "end": "263010"
  },
  {
    "text": "actually inject these at at one time",
    "start": "263010",
    "end": "265380"
  },
  {
    "text": "level",
    "start": "265380",
    "end": "266639"
  },
  {
    "text": "and or at the run sorry step so that's",
    "start": "266639",
    "end": "272939"
  },
  {
    "text": "why we basically integrated at the",
    "start": "272939",
    "end": "274620"
  },
  {
    "text": "runtime level we have a really in",
    "start": "274620",
    "end": "277830"
  },
  {
    "text": "general the the way we are better",
    "start": "277830",
    "end": "279900"
  },
  {
    "text": "integrated for OCI runtimes because the",
    "start": "279900",
    "end": "282419"
  },
  {
    "text": "way we do it is that we get called at",
    "start": "282419",
    "end": "285210"
  },
  {
    "text": "the pre-start level and that means that",
    "start": "285210",
    "end": "288150"
  },
  {
    "text": "for a lot of these runtimes we don't",
    "start": "288150",
    "end": "291360"
  },
  {
    "text": "need to ship a specific a specific sorry",
    "start": "291360",
    "end": "295289"
  },
  {
    "text": "for a lot of these container runtimes we",
    "start": "295289",
    "end": "298199"
  },
  {
    "text": "don't need to ship a specific runtime",
    "start": "298199",
    "end": "300240"
  },
  {
    "text": "but for docker for example we actually",
    "start": "300240",
    "end": "302430"
  },
  {
    "text": "have to just wrapper NC and add a single",
    "start": "302430",
    "end": "304319"
  },
  {
    "text": "line of code that says well add restart",
    "start": "304319",
    "end": "307349"
  },
  {
    "text": "hook and so that allowed us actually to",
    "start": "307349",
    "end": "310319"
  },
  {
    "text": "support not a lot of new use cases and",
    "start": "310319",
    "end": "312599"
  },
  {
    "text": "you actually see that on the docker hub",
    "start": "312599",
    "end": "315270"
  },
  {
    "text": "is that we're slowly actually adding for",
    "start": "315270",
    "end": "320039"
  },
  {
    "text": "example support for graphics so that's",
    "start": "320039",
    "end": "322740"
  },
  {
    "text": "that's pretty interesting and now that",
    "start": "322740",
    "end": "326250"
  },
  {
    "text": "we actually have these support with",
    "start": "326250",
    "end": "328229"
  },
  {
    "text": "these tools to actually support more",
    "start": "328229",
    "end": "331050"
  },
  {
    "text": "runtimes we're really looking at",
    "start": "331050",
    "end": "332520"
  },
  {
    "text": "kubernetes and we've actually been",
    "start": "332520",
    "end": "335669"
  },
  {
    "text": "involved in the community for the past",
    "start": "335669",
    "end": "337110"
  },
  {
    "text": "year at the creation of the well during",
    "start": "337110",
    "end": "341879"
  },
  {
    "text": "the part where the resource management",
    "start": "341879",
    "end": "343620"
  },
  {
    "text": "workgroup was being created the resource",
    "start": "343620",
    "end": "348089"
  },
  {
    "text": "management work group had actually to",
    "start": "348089",
    "end": "349560"
  },
  {
    "text": "face-to-face we had one recently at",
    "start": "349560",
    "end": "351569"
  },
  {
    "text": "Nvidia and March and there was actually",
    "start": "351569",
    "end": "355379"
  },
  {
    "text": "there's a lot of engagement in that",
    "start": "355379",
    "end": "357389"
  },
  {
    "text": "workgroup and it's we are solving a lot",
    "start": "357389",
    "end": "359279"
  },
  {
    "text": "of different challenges and one of the",
    "start": "359279",
    "end": "362520"
  },
  {
    "text": "things we actually managed it to do is",
    "start": "362520",
    "end": "364759"
  },
  {
    "text": "we actually added this new device system",
    "start": "364759",
    "end": "368430"
  },
  {
    "text": "and in a year we graduated from alpha to",
    "start": "368430",
    "end": "371699"
  },
  {
    "text": "beer and if you look a bit at kubernetes",
    "start": "371699",
    "end": "375509"
  },
  {
    "text": "now you know that upstream GPU is now in",
    "start": "375509",
    "end": "378659"
  },
  {
    "text": "beta but it's still a bit challenging to",
    "start": "378659",
    "end": "382110"
  },
  {
    "text": "actually deployed provision of GPU",
    "start": "382110",
    "end": "384240"
  },
  {
    "text": "cluster on the other hand when you look",
    "start": "384240",
    "end": "386669"
  },
  {
    "text": "at what we went through last year were a",
    "start": "386669",
    "end": "391020"
  },
  {
    "text": "bit before in one six GPU support",
    "start": "391020",
    "end": "393870"
  },
  {
    "text": "actually stopped at one GPU per node and",
    "start": "393870",
    "end": "396899"
  },
  {
    "text": "and one seven",
    "start": "396899",
    "end": "399060"
  },
  {
    "text": "you actually you could actually support",
    "start": "399060",
    "end": "401190"
  },
  {
    "text": "more than one GPU per node but you still",
    "start": "401190",
    "end": "403290"
  },
  {
    "text": "had this issue that for example you had",
    "start": "403290",
    "end": "405810"
  },
  {
    "text": "to manually mount your volumes in your",
    "start": "405810",
    "end": "407400"
  },
  {
    "text": "pots back or you had no GPU monitoring",
    "start": "407400",
    "end": "409650"
  },
  {
    "text": "or or health check doing that your what",
    "start": "409650",
    "end": "414210"
  },
  {
    "text": "we did is we added this new plugin",
    "start": "414210",
    "end": "417810"
  },
  {
    "text": "system that allows not only to support",
    "start": "417810",
    "end": "419460"
  },
  {
    "text": "GPU but in a more generic way more",
    "start": "419460",
    "end": "422700"
  },
  {
    "text": "devices and we're engaging in the",
    "start": "422700",
    "end": "424560"
  },
  {
    "text": "community and especially in the resource",
    "start": "424560",
    "end": "426210"
  },
  {
    "text": "management workgroup with a lot of",
    "start": "426210",
    "end": "427950"
  },
  {
    "text": "different companies to handle things",
    "start": "427950",
    "end": "429810"
  },
  {
    "text": "like FPGAs like nicks and a lot of",
    "start": "429810",
    "end": "434220"
  },
  {
    "text": "different devices that allowed us in our",
    "start": "434220",
    "end": "437130"
  },
  {
    "text": "case to use our tools so the Nvidia",
    "start": "437130",
    "end": "439919"
  },
  {
    "text": "container runtime and in 110 since we",
    "start": "439919",
    "end": "443669"
  },
  {
    "text": "grabbed it to be done we actually have",
    "start": "443669",
    "end": "445770"
  },
  {
    "text": "now he'll stay well we had health check",
    "start": "445770",
    "end": "447810"
  },
  {
    "text": "before we are we have some monitoring",
    "start": "447810",
    "end": "450419"
  },
  {
    "text": "and we're looking at solving a lot of",
    "start": "450419",
    "end": "452490"
  },
  {
    "text": "different problems like heterogeneous",
    "start": "452490",
    "end": "454500"
  },
  {
    "text": "clusters support for GPU sharing support",
    "start": "454500",
    "end": "457229"
  },
  {
    "text": "for topology except a lot of features",
    "start": "457229",
    "end": "459510"
  },
  {
    "text": "that all go a bit later into in my talk",
    "start": "459510",
    "end": "463669"
  },
  {
    "text": "if you look at it from a user",
    "start": "463669",
    "end": "465780"
  },
  {
    "text": "perspective what that means to you is as",
    "start": "465780",
    "end": "468270"
  },
  {
    "text": "I was mentioning in one six one seven",
    "start": "468270",
    "end": "470310"
  },
  {
    "text": "you support one GPU per node you need to",
    "start": "470310",
    "end": "472289"
  },
  {
    "text": "manually mounted volumes so as I was",
    "start": "472289",
    "end": "475560"
  },
  {
    "text": "mentioning the different libraries you",
    "start": "475560",
    "end": "477479"
  },
  {
    "text": "actually have to make sure that they are",
    "start": "477479",
    "end": "479039"
  },
  {
    "text": "all in the same directory for all the",
    "start": "479039",
    "end": "481020"
  },
  {
    "text": "GPUs in your node if you are actually",
    "start": "481020",
    "end": "483390"
  },
  {
    "text": "upgrading the driver then you have to",
    "start": "483390",
    "end": "485370"
  },
  {
    "text": "make sure that you are placing the",
    "start": "485370",
    "end": "487289"
  },
  {
    "text": "libraries back in that same directory",
    "start": "487289",
    "end": "489240"
  },
  {
    "text": "and at the at that time you had very",
    "start": "489240",
    "end": "492240"
  },
  {
    "text": "fragmented ecosystem so everyone was",
    "start": "492240",
    "end": "494370"
  },
  {
    "text": "doing their own thing we were doing",
    "start": "494370",
    "end": "495570"
  },
  {
    "text": "Nvidia docker kubernetes was doing its",
    "start": "495570",
    "end": "497760"
  },
  {
    "text": "own implementation of Nvidia docker",
    "start": "497760",
    "end": "500510"
  },
  {
    "text": "singularity was doing its own thing too",
    "start": "500510",
    "end": "503130"
  },
  {
    "text": "and you had this issue where if your GP",
    "start": "503130",
    "end": "506700"
  },
  {
    "text": "would would be in a bad state it would",
    "start": "506700",
    "end": "509280"
  },
  {
    "text": "actually act as a blackhole take the",
    "start": "509280",
    "end": "512219"
  },
  {
    "text": "first GPU pod that pod that's requesting",
    "start": "512219",
    "end": "515099"
  },
  {
    "text": "a GPU your pod would get scheduled on",
    "start": "515099",
    "end": "517500"
  },
  {
    "text": "that node it then would crash",
    "start": "517500",
    "end": "519990"
  },
  {
    "text": "immediately kubernetes would try to",
    "start": "519990",
    "end": "522479"
  },
  {
    "text": "restart it after some point it would",
    "start": "522479",
    "end": "524790"
  },
  {
    "text": "pause it take the next pod crash it",
    "start": "524790",
    "end": "527280"
  },
  {
    "text": "again so that was a",
    "start": "527280",
    "end": "531030"
  },
  {
    "text": "that was a pretty brittle support what",
    "start": "531030",
    "end": "534090"
  },
  {
    "text": "we introduced in 1/8 is this device",
    "start": "534090",
    "end": "537030"
  },
  {
    "text": "login system what that means is as a",
    "start": "537030",
    "end": "539880"
  },
  {
    "text": "cluster and then you actually just",
    "start": "539880",
    "end": "541380"
  },
  {
    "text": "deploy your demon sets in a cluster and",
    "start": "541380",
    "end": "544890"
  },
  {
    "text": "your cluster then becomes GPU aware and",
    "start": "544890",
    "end": "547590"
  },
  {
    "text": "what that means is your nodes are going",
    "start": "547590",
    "end": "550410"
  },
  {
    "text": "to report to your cluster",
    "start": "550410",
    "end": "552240"
  },
  {
    "text": "how many GPUs they have they're gonna",
    "start": "552240",
    "end": "554280"
  },
  {
    "text": "set up the GPU so for example you might",
    "start": "554280",
    "end": "556260"
  },
  {
    "text": "want we are going to do some tests on",
    "start": "556260",
    "end": "559320"
  },
  {
    "text": "your GPU to make sure that it's healthy",
    "start": "559320",
    "end": "561120"
  },
  {
    "text": "and it'll also play an important role",
    "start": "561120",
    "end": "564060"
  },
  {
    "text": "exposing the device and general exposing",
    "start": "564060",
    "end": "566900"
  },
  {
    "text": "the Nvidia driver and fixing up a lot of",
    "start": "566900",
    "end": "570600"
  },
  {
    "text": "issues you might have in your container",
    "start": "570600",
    "end": "574819"
  },
  {
    "text": "so what that means is as a cluster and",
    "start": "575270",
    "end": "579300"
  },
  {
    "text": "then you have to if you want your GPU",
    "start": "579300",
    "end": "582000"
  },
  {
    "text": "cluster to be your cluster to be GPU",
    "start": "582000",
    "end": "584220"
  },
  {
    "text": "aware you only have to run one simple",
    "start": "584220",
    "end": "586290"
  },
  {
    "text": "command cube CT I'll create and then",
    "start": "586290",
    "end": "588890"
  },
  {
    "text": "this URL which are that bravery at the",
    "start": "588890",
    "end": "592020"
  },
  {
    "text": "two because it didn't fit on the side",
    "start": "592020",
    "end": "594150"
  },
  {
    "text": "and this allows you to just create a",
    "start": "594150",
    "end": "598140"
  },
  {
    "start": "597000",
    "end": "597000"
  },
  {
    "text": "basic pod that requests two GPUs and in",
    "start": "598140",
    "end": "601410"
  },
  {
    "text": "the end as a user that's all you care",
    "start": "601410",
    "end": "603900"
  },
  {
    "text": "about you just want to create a parts",
    "start": "603900",
    "end": "606900"
  },
  {
    "text": "back that requests that has a specific",
    "start": "606900",
    "end": "610680"
  },
  {
    "text": "docker image and just request a number",
    "start": "610680",
    "end": "613200"
  },
  {
    "text": "of GPUs so that's where we are right now",
    "start": "613200",
    "end": "618560"
  },
  {
    "text": "what that means is however operating",
    "start": "618560",
    "end": "623970"
  },
  {
    "text": "GPUs in a cluster has a lot of",
    "start": "623970",
    "end": "625680"
  },
  {
    "text": "challenges either from a cluster admin",
    "start": "625680",
    "end": "629190"
  },
  {
    "text": "perspective or from a user perspective",
    "start": "629190",
    "end": "630690"
  },
  {
    "text": "the first one you're actually going to",
    "start": "630690",
    "end": "632700"
  },
  {
    "text": "run in is well you're going to try to do",
    "start": "632700",
    "end": "636330"
  },
  {
    "start": "634000",
    "end": "634000"
  },
  {
    "text": "your blue-green updates and you have two",
    "start": "636330",
    "end": "638520"
  },
  {
    "text": "GPUs left in your cluster and what that",
    "start": "638520",
    "end": "642030"
  },
  {
    "text": "means for you is you're going to have to",
    "start": "642030",
    "end": "644820"
  },
  {
    "text": "deal with resource with the fact that",
    "start": "644820",
    "end": "647730"
  },
  {
    "text": "you resource contention you don't have",
    "start": "647730",
    "end": "649830"
  },
  {
    "text": "enough GPUs to actually get your version",
    "start": "649830",
    "end": "652680"
  },
  {
    "text": "two on your cluster and so your GP or",
    "start": "652680",
    "end": "655710"
  },
  {
    "text": "your version the version 2 of your",
    "start": "655710",
    "end": "658020"
  },
  {
    "text": "apology's actually just going to wait",
    "start": "658020",
    "end": "659610"
  },
  {
    "text": "indefinitely so a few solutions to fix",
    "start": "659610",
    "end": "662040"
  },
  {
    "text": "that is you could pre provision some",
    "start": "662040",
    "end": "663690"
  },
  {
    "text": "notes or you could try to",
    "start": "663690",
    "end": "664920"
  },
  {
    "text": "scale but if you try to scale you're",
    "start": "664920",
    "end": "667560"
  },
  {
    "text": "going to hit the second second issue is",
    "start": "667560",
    "end": "670380"
  },
  {
    "text": "that if you're using a double yes for",
    "start": "670380",
    "end": "672450"
  },
  {
    "text": "example you are limited you have a",
    "start": "672450",
    "end": "675720"
  },
  {
    "text": "limited number of instances especially",
    "start": "675720",
    "end": "677880"
  },
  {
    "text": "on GPUs so you're going to auto scale",
    "start": "677880",
    "end": "681389"
  },
  {
    "text": "and then at some points you're going to",
    "start": "681389",
    "end": "683699"
  },
  {
    "text": "you're going to be limited by the number",
    "start": "683699",
    "end": "685290"
  },
  {
    "text": "of instances that you can actually spawn",
    "start": "685290",
    "end": "688019"
  },
  {
    "text": "and in that case you're going to have to",
    "start": "688019",
    "end": "689880"
  },
  {
    "text": "open a ticket so it's usually pretty",
    "start": "689880",
    "end": "694470"
  },
  {
    "text": "easy to fix you just need to be aware",
    "start": "694470",
    "end": "696149"
  },
  {
    "text": "that doing a Bluegreen deployment is",
    "start": "696149",
    "end": "699870"
  },
  {
    "text": "something that might fail because you",
    "start": "699870",
    "end": "703139"
  },
  {
    "text": "don't have enough resource another",
    "start": "703139",
    "end": "705889"
  },
  {
    "text": "interesting thing that you might want to",
    "start": "705889",
    "end": "708240"
  },
  {
    "start": "707000",
    "end": "707000"
  },
  {
    "text": "look into is resiliency for GPU services",
    "start": "708240",
    "end": "710850"
  },
  {
    "text": "say for example you have an inference",
    "start": "710850",
    "end": "714930"
  },
  {
    "text": "service that's running and you want to",
    "start": "714930",
    "end": "717480"
  },
  {
    "text": "make sure that that inference service is",
    "start": "717480",
    "end": "719399"
  },
  {
    "text": "basically well a responds automatically",
    "start": "719399",
    "end": "723389"
  },
  {
    "text": "on another node if it fails or you want",
    "start": "723389",
    "end": "725699"
  },
  {
    "text": "to make sure that it's scales um the",
    "start": "725699",
    "end": "729120"
  },
  {
    "text": "issue is auto scaling is that it takes a",
    "start": "729120",
    "end": "732810"
  },
  {
    "text": "lot of time to actually provision a GPU",
    "start": "732810",
    "end": "734670"
  },
  {
    "text": "instance if you're on the AWS or GCP and",
    "start": "734670",
    "end": "737519"
  },
  {
    "text": "it might take between five and fifteen",
    "start": "737519",
    "end": "740070"
  },
  {
    "text": "minutes so if you're trying to actually",
    "start": "740070",
    "end": "743250"
  },
  {
    "text": "make sure that your service responds",
    "start": "743250",
    "end": "745829"
  },
  {
    "text": "pretty quickly and five to fifteen",
    "start": "745829",
    "end": "748199"
  },
  {
    "text": "minutes is not exactly what you want to",
    "start": "748199",
    "end": "750149"
  },
  {
    "text": "do so the good solution that you have",
    "start": "750149",
    "end": "753029"
  },
  {
    "text": "here is either you long as to pre",
    "start": "753029",
    "end": "755550"
  },
  {
    "text": "provision and instance unfortunately one",
    "start": "755550",
    "end": "759480"
  },
  {
    "text": "of the other thing that you might hit",
    "start": "759480",
    "end": "760829"
  },
  {
    "text": "and that's something that we that's a",
    "start": "760829",
    "end": "763980"
  },
  {
    "text": "parent that we've used for example in",
    "start": "763980",
    "end": "765890"
  },
  {
    "text": "one of the demos that we have is we have",
    "start": "765890",
    "end": "769380"
  },
  {
    "text": "a demo where we have an inference",
    "start": "769380",
    "end": "770910"
  },
  {
    "text": "service that's trying to and go through",
    "start": "770910",
    "end": "774269"
  },
  {
    "text": "a big amount of a flower image and try",
    "start": "774269",
    "end": "778440"
  },
  {
    "text": "to identify and classify what in what",
    "start": "778440",
    "end": "781170"
  },
  {
    "text": "image matches to what flower we found",
    "start": "781170",
    "end": "784589"
  },
  {
    "text": "out that actually loading the data takes",
    "start": "784589",
    "end": "786329"
  },
  {
    "text": "at ten to fifteen seconds and we found",
    "start": "786329",
    "end": "790380"
  },
  {
    "text": "out that this interesting pattern is",
    "start": "790380",
    "end": "791819"
  },
  {
    "text": "that you can actually just split the",
    "start": "791819",
    "end": "793949"
  },
  {
    "text": "data from the inference pod and have",
    "start": "793949",
    "end": "796949"
  },
  {
    "text": "your data just",
    "start": "796949",
    "end": "798600"
  },
  {
    "text": "we'll have your data pod just",
    "start": "798600",
    "end": "800520"
  },
  {
    "text": "pre-scheduled on other on other nodes",
    "start": "800520",
    "end": "803730"
  },
  {
    "text": "because it doesn't request it doesn't",
    "start": "803730",
    "end": "805590"
  },
  {
    "text": "require you to have a GPU driver sorry a",
    "start": "805590",
    "end": "810030"
  },
  {
    "text": "GPU and then you would have your data in",
    "start": "810030",
    "end": "813180"
  },
  {
    "text": "your inference container talk for",
    "start": "813180",
    "end": "814560"
  },
  {
    "text": "example through IPC so that would allow",
    "start": "814560",
    "end": "818190"
  },
  {
    "text": "you to basically if you for example want",
    "start": "818190",
    "end": "821220"
  },
  {
    "text": "to make sure that you have some",
    "start": "821220",
    "end": "822120"
  },
  {
    "text": "resiliency you have a liveness probe on",
    "start": "822120",
    "end": "824760"
  },
  {
    "text": "your container inference container and",
    "start": "824760",
    "end": "828090"
  },
  {
    "text": "once kubernetes the text that your",
    "start": "828090",
    "end": "830310"
  },
  {
    "text": "inference container is down it will",
    "start": "830310",
    "end": "831930"
  },
  {
    "text": "automatically spawn an inference",
    "start": "831930",
    "end": "833310"
  },
  {
    "text": "container on another node and that's how",
    "start": "833310",
    "end": "837810"
  },
  {
    "text": "you can actually get to something that's",
    "start": "837810",
    "end": "839570"
  },
  {
    "text": "at least from a user perspective a lot",
    "start": "839570",
    "end": "842460"
  },
  {
    "text": "more seamless than waiting 15 minutes or",
    "start": "842460",
    "end": "844560"
  },
  {
    "text": "15 seconds the other one is about",
    "start": "844560",
    "end": "848160"
  },
  {
    "start": "848000",
    "end": "848000"
  },
  {
    "text": "scaling GPU services that's one of the",
    "start": "848160",
    "end": "851640"
  },
  {
    "text": "requests that we actually get a lot is",
    "start": "851640",
    "end": "853460"
  },
  {
    "text": "or just in general people tend to get",
    "start": "853460",
    "end": "857070"
  },
  {
    "text": "this idea that it's probably better to",
    "start": "857070",
    "end": "859470"
  },
  {
    "text": "scale in GPU load now usually when you",
    "start": "859470",
    "end": "862080"
  },
  {
    "text": "try to scale services it's mostly",
    "start": "862080",
    "end": "864870"
  },
  {
    "text": "inference services and what that means",
    "start": "864870",
    "end": "867300"
  },
  {
    "text": "is that your bottleneck is probably not",
    "start": "867300",
    "end": "870150"
  },
  {
    "text": "going to be GPU load and you're better",
    "start": "870150",
    "end": "872910"
  },
  {
    "text": "our factory scaling based on QPS you can",
    "start": "872910",
    "end": "877770"
  },
  {
    "text": "actually use entrepot affinity to line",
    "start": "877770",
    "end": "879570"
  },
  {
    "text": "up nodes that have your data power so",
    "start": "879570",
    "end": "881510"
  },
  {
    "text": "you pre provision some notes make sure",
    "start": "881510",
    "end": "884610"
  },
  {
    "text": "your data pod runs on these nodes and",
    "start": "884610",
    "end": "886770"
  },
  {
    "text": "use this use the entrepot affinity",
    "start": "886770",
    "end": "889890"
  },
  {
    "text": "feature of kubernetes to make sure your",
    "start": "889890",
    "end": "893270"
  },
  {
    "text": "inference service scales correctly as",
    "start": "893270",
    "end": "896180"
  },
  {
    "text": "usual you're probably you probably want",
    "start": "896180",
    "end": "898380"
  },
  {
    "text": "to keep some spare nodes and so this is",
    "start": "898380",
    "end": "902010"
  },
  {
    "start": "901000",
    "end": "901000"
  },
  {
    "text": "also one of the interesting things is",
    "start": "902010",
    "end": "903750"
  },
  {
    "text": "that when you're actually building a GPU",
    "start": "903750",
    "end": "905820"
  },
  {
    "text": "cluster and you have a lot of for",
    "start": "905820",
    "end": "907830"
  },
  {
    "text": "example for your data scientists you're",
    "start": "907830",
    "end": "909900"
  },
  {
    "text": "actually going to face a lot of issues",
    "start": "909900",
    "end": "911730"
  },
  {
    "text": "in terms of how do I actually integrate",
    "start": "911730",
    "end": "914970"
  },
  {
    "text": "some of the business logic inside that's",
    "start": "914970",
    "end": "917880"
  },
  {
    "text": "one of the things you might want for",
    "start": "917880",
    "end": "919920"
  },
  {
    "text": "example is you might want one queue per",
    "start": "919920",
    "end": "923730"
  },
  {
    "text": "user and you might want to be able to",
    "start": "923730",
    "end": "925440"
  },
  {
    "text": "process the jobs one by one or",
    "start": "925440",
    "end": "928380"
  },
  {
    "text": "sequentially for the user and",
    "start": "928380",
    "end": "931400"
  },
  {
    "text": "the issue that you have right now is its",
    "start": "931400",
    "end": "934310"
  },
  {
    "text": "business logics so you should use an",
    "start": "934310",
    "end": "936590"
  },
  {
    "text": "operator but if you go down the operator",
    "start": "936590",
    "end": "939800"
  },
  {
    "text": "way you have all these issues where it",
    "start": "939800",
    "end": "942590"
  },
  {
    "text": "it makes some sense to be in an operator",
    "start": "942590",
    "end": "945650"
  },
  {
    "text": "but it would make more sense to be in a",
    "start": "945650",
    "end": "947150"
  },
  {
    "text": "custom schedule for example and in your",
    "start": "947150",
    "end": "950090"
  },
  {
    "text": "operator say you have you have these",
    "start": "950090",
    "end": "952430"
  },
  {
    "text": "three cues and all these spots and well",
    "start": "952430",
    "end": "956390"
  },
  {
    "text": "you want to schedule the first part and",
    "start": "956390",
    "end": "957860"
  },
  {
    "text": "so you would basically take that pod we",
    "start": "957860",
    "end": "961690"
  },
  {
    "text": "post it to the won't post it to the",
    "start": "961690",
    "end": "964580"
  },
  {
    "text": "kubernetes api is and well subscribe to",
    "start": "964580",
    "end": "968210"
  },
  {
    "text": "the events of that pod so you would look",
    "start": "968210",
    "end": "971390"
  },
  {
    "text": "around and make sure that if that part",
    "start": "971390",
    "end": "973190"
  },
  {
    "text": "has been scheduled then you can remove",
    "start": "973190",
    "end": "974630"
  },
  {
    "text": "it from the queue but if it hasn't",
    "start": "974630",
    "end": "976190"
  },
  {
    "text": "scheduled if it hasn't been scheduled",
    "start": "976190",
    "end": "978350"
  },
  {
    "text": "where it fell scheduling then you have",
    "start": "978350",
    "end": "980240"
  },
  {
    "text": "to delete that part and at that point",
    "start": "980240",
    "end": "983900"
  },
  {
    "text": "maybe between the moment that you got",
    "start": "983900",
    "end": "986510"
  },
  {
    "text": "the event that your part hasn't but has",
    "start": "986510",
    "end": "988520"
  },
  {
    "text": "failed scheduling and the moment that",
    "start": "988520",
    "end": "990200"
  },
  {
    "text": "you actually delete that part it could",
    "start": "990200",
    "end": "992450"
  },
  {
    "text": "have gone through the scheduler again",
    "start": "992450",
    "end": "993740"
  },
  {
    "text": "and being scheduled so there's a lot of",
    "start": "993740",
    "end": "998240"
  },
  {
    "text": "different there's actually a lot of",
    "start": "998240",
    "end": "1000790"
  },
  {
    "text": "business logic and that's more advanced",
    "start": "1000790",
    "end": "1003370"
  },
  {
    "text": "than that yeah you as a cluster admin",
    "start": "1003370",
    "end": "1005290"
  },
  {
    "text": "might want to actually get into and",
    "start": "1005290",
    "end": "1007780"
  },
  {
    "text": "there's no actually good solution for",
    "start": "1007780",
    "end": "1010660"
  },
  {
    "text": "that there are some things that are",
    "start": "1010660",
    "end": "1014020"
  },
  {
    "text": "being discussed in the community I think",
    "start": "1014020",
    "end": "1017590"
  },
  {
    "text": "it's called the scheduler framework that",
    "start": "1017590",
    "end": "1021060"
  },
  {
    "text": "six scheduling is working on but right",
    "start": "1021060",
    "end": "1024730"
  },
  {
    "text": "now it seems like it's custom scheduler",
    "start": "1024730",
    "end": "1027699"
  },
  {
    "text": "is the best way you can go through",
    "start": "1027700",
    "end": "1032370"
  },
  {
    "text": "though you still you can still see that",
    "start": "1032400",
    "end": "1035980"
  },
  {
    "text": "it's probably not the best solution so",
    "start": "1035980",
    "end": "1039100"
  },
  {
    "text": "if we look a bit more at the developer",
    "start": "1039100",
    "end": "1041500"
  },
  {
    "text": "perspective and that'll give you some",
    "start": "1041500",
    "end": "1043990"
  },
  {
    "text": "insights as to what are the features",
    "start": "1043990",
    "end": "1046209"
  },
  {
    "text": "that we want to actually solve for GPUs",
    "start": "1046209",
    "end": "1049570"
  },
  {
    "text": "and kubernetes and we're going to look a",
    "start": "1049570",
    "end": "1052690"
  },
  {
    "text": "bit at how it works and what that means",
    "start": "1052690",
    "end": "1055900"
  },
  {
    "start": "1054000",
    "end": "1054000"
  },
  {
    "text": "is we'll see a bit at the lot will look",
    "start": "1055900",
    "end": "1058540"
  },
  {
    "text": "a bit at the lifecycle of the device",
    "start": "1058540",
    "end": "1059980"
  },
  {
    "text": "plugin so as I was mentioning for me to",
    "start": "1059980",
    "end": "1062770"
  },
  {
    "text": "confirm you from your perspective as a",
    "start": "1062770",
    "end": "1064450"
  },
  {
    "text": "cluster",
    "start": "1064450",
    "end": "1065049"
  },
  {
    "text": "then you just deploy device login and",
    "start": "1065049",
    "end": "1067539"
  },
  {
    "text": "what happens is that since it's a demon",
    "start": "1067539",
    "end": "1070179"
  },
  {
    "text": "said it's going to be scheduled on the",
    "start": "1070179",
    "end": "1071409"
  },
  {
    "text": "nodes the nodes are going to create the",
    "start": "1071409",
    "end": "1073690"
  },
  {
    "text": "containers you probably have a driver",
    "start": "1073690",
    "end": "1076720"
  },
  {
    "text": "install if you're on GK for example they",
    "start": "1076720",
    "end": "1079929"
  },
  {
    "text": "have their own driver and so on this",
    "start": "1079929",
    "end": "1083980"
  },
  {
    "text": "works really well on gke because they're",
    "start": "1083980",
    "end": "1085809"
  },
  {
    "text": "using cost which is a very lockdown OS",
    "start": "1085809",
    "end": "1087999"
  },
  {
    "text": "we're looking at a more general ocean",
    "start": "1087999",
    "end": "1091090"
  },
  {
    "text": "that will work on other OSS for example",
    "start": "1091090",
    "end": "1094539"
  },
  {
    "text": "you've been lubuntu once your driver is",
    "start": "1094539",
    "end": "1098109"
  },
  {
    "text": "installed your device plugin registers",
    "start": "1098109",
    "end": "1100330"
  },
  {
    "text": "to the with the nodes and with the node",
    "start": "1100330",
    "end": "1102940"
  },
  {
    "text": "and cube it will then call the GRP C API",
    "start": "1102940",
    "end": "1105129"
  },
  {
    "text": "it's in there so your device plugin will",
    "start": "1105129",
    "end": "1109480"
  },
  {
    "text": "notify the cubit that it has for example",
    "start": "1109480",
    "end": "1112299"
  },
  {
    "text": "three GPUs and if one of the GPU crashes",
    "start": "1112299",
    "end": "1115809"
  },
  {
    "text": "it notifies cubelets cubelet bubbles",
    "start": "1115809",
    "end": "1118330"
  },
  {
    "text": "that up to the API server and the",
    "start": "1118330",
    "end": "1120519"
  },
  {
    "text": "schedule won't schedule more than two",
    "start": "1120519",
    "end": "1124710"
  },
  {
    "text": "parts that well more once get your more",
    "start": "1124710",
    "end": "1127629"
  },
  {
    "text": "than two GPUs on that node if you if the",
    "start": "1127629",
    "end": "1132489"
  },
  {
    "text": "if you've managed to fix the GPU crash",
    "start": "1132489",
    "end": "1134950"
  },
  {
    "text": "or the device will get manages to",
    "start": "1134950",
    "end": "1136929"
  },
  {
    "text": "recover some of it then it bubbles that",
    "start": "1136929",
    "end": "1140379"
  },
  {
    "text": "up to the node which bubbles that up to",
    "start": "1140379",
    "end": "1142179"
  },
  {
    "text": "the API server and goes to a schedule I",
    "start": "1142179",
    "end": "1144899"
  },
  {
    "text": "was also mentioning that we have a",
    "start": "1144899",
    "end": "1149669"
  },
  {
    "text": "continuing life cycle too so when your",
    "start": "1149669",
    "end": "1152470"
  },
  {
    "text": "power is created from a user's",
    "start": "1152470",
    "end": "1153999"
  },
  {
    "text": "perspective your Prada gets assigned its",
    "start": "1153999",
    "end": "1159129"
  },
  {
    "text": "node you know it selects the device and",
    "start": "1159129",
    "end": "1161889"
  },
  {
    "text": "then cause this G RPC call that's called",
    "start": "1161889",
    "end": "1164679"
  },
  {
    "text": "Palin mission and for each container it",
    "start": "1164679",
    "end": "1167799"
  },
  {
    "text": "will issue an initialize container call",
    "start": "1167799",
    "end": "1170470"
  },
  {
    "text": "when you delete it",
    "start": "1170470",
    "end": "1171940"
  },
  {
    "text": "we're looking at adding this spot",
    "start": "1171940",
    "end": "1173830"
  },
  {
    "text": "deleted call the last thing that I want",
    "start": "1173830",
    "end": "1179830"
  },
  {
    "start": "1178000",
    "end": "1178000"
  },
  {
    "text": "to talk about is zero downtime",
    "start": "1179830",
    "end": "1181989"
  },
  {
    "text": "registration and currently the way you",
    "start": "1181989",
    "end": "1185109"
  },
  {
    "text": "did register your device for again well",
    "start": "1185109",
    "end": "1187389"
  },
  {
    "text": "the way either device plug-in registers",
    "start": "1187389",
    "end": "1189220"
  },
  {
    "text": "itself with qubit is really do or your",
    "start": "1189220",
    "end": "1192879"
  },
  {
    "text": "pc protocol or mechanism we're looking",
    "start": "1192879",
    "end": "1197409"
  },
  {
    "text": "at making it very",
    "start": "1197409",
    "end": "1198760"
  },
  {
    "text": "your pc serve your device plugin just",
    "start": "1198760",
    "end": "1202419"
  },
  {
    "text": "puts its socket into an agreed-upon path",
    "start": "1202419",
    "end": "1205179"
  },
  {
    "text": "with qubit qubit watches that pass and",
    "start": "1205179",
    "end": "1208330"
  },
  {
    "text": "then calls the G RPC server that allows",
    "start": "1208330",
    "end": "1211660"
  },
  {
    "text": "you to actually do zero downtime",
    "start": "1211660",
    "end": "1213070"
  },
  {
    "text": "registration so if you want to for",
    "start": "1213070",
    "end": "1215320"
  },
  {
    "text": "example upgrade your device plug-in it",
    "start": "1215320",
    "end": "1218020"
  },
  {
    "text": "gets scheduled on the node places its",
    "start": "1218020",
    "end": "1221080"
  },
  {
    "text": "new socket inside that path qubit will",
    "start": "1221080",
    "end": "1224940"
  },
  {
    "text": "ping that G RPC server once it's sure",
    "start": "1224940",
    "end": "1227890"
  },
  {
    "text": "that the G RPC server is up and is ready",
    "start": "1227890",
    "end": "1230799"
  },
  {
    "text": "it will switch over to the 1.9 and that",
    "start": "1230799",
    "end": "1234460"
  },
  {
    "text": "allows a pre needs pattern and sorry",
    "start": "1234460",
    "end": "1237549"
  },
  {
    "text": "that we're looking into so for example",
    "start": "1237549",
    "end": "1241240"
  },
  {
    "text": "you might want to have in your cluster",
    "start": "1241240",
    "end": "1243309"
  },
  {
    "text": "some nodes that have ECC enabled and",
    "start": "1243309",
    "end": "1246900"
  },
  {
    "text": "what we're looking at is your device",
    "start": "1246900",
    "end": "1250179"
  },
  {
    "text": "plug-in watches the annotations on your",
    "start": "1250179",
    "end": "1252429"
  },
  {
    "text": "node you as a cluster admin add the",
    "start": "1252429",
    "end": "1254590"
  },
  {
    "text": "annotation and you know that says I want",
    "start": "1254590",
    "end": "1256630"
  },
  {
    "text": "ECC enabled so Nvidia comm slash device",
    "start": "1256630",
    "end": "1259179"
  },
  {
    "text": "plug-in for example and ECC enabled your",
    "start": "1259179",
    "end": "1263049"
  },
  {
    "text": "G on PC your Nvidia device plugin looks",
    "start": "1263049",
    "end": "1266490"
  },
  {
    "text": "well watches that gets that event",
    "start": "1266490",
    "end": "1268990"
  },
  {
    "text": "enables in CC on the GPUs and me",
    "start": "1268990",
    "end": "1272470"
  },
  {
    "text": "registers itself against qubits once",
    "start": "1272470",
    "end": "1274570"
  },
  {
    "text": "again zero downtime so that means that",
    "start": "1274570",
    "end": "1276940"
  },
  {
    "text": "you won't get any pods that won't get",
    "start": "1276940",
    "end": "1280809"
  },
  {
    "text": "rejected from your qubits and so all of",
    "start": "1280809",
    "end": "1286030"
  },
  {
    "text": "this is the reason I presented all of",
    "start": "1286030",
    "end": "1289419"
  },
  {
    "text": "this is so that you can see now that the",
    "start": "1289419",
    "end": "1293410"
  },
  {
    "text": "lifecycle of the device fuggin is pretty",
    "start": "1293410",
    "end": "1295600"
  },
  {
    "text": "much figured out and right now we're",
    "start": "1295600",
    "end": "1298299"
  },
  {
    "text": "really focusing on solving a lot of",
    "start": "1298299",
    "end": "1300640"
  },
  {
    "text": "challenges that you as a user will be",
    "start": "1300640",
    "end": "1303010"
  },
  {
    "text": "able to that you as a user will be able",
    "start": "1303010",
    "end": "1307270"
  },
  {
    "text": "to enable you so the first one we are",
    "start": "1307270",
    "end": "1310030"
  },
  {
    "start": "1310000",
    "end": "1310000"
  },
  {
    "text": "really want to push is GPU monitoring",
    "start": "1310030",
    "end": "1312910"
  },
  {
    "text": "currently you have some monitoring and",
    "start": "1312910",
    "end": "1314770"
  },
  {
    "text": "that you'll be able to see the GPU",
    "start": "1314770",
    "end": "1317169"
  },
  {
    "text": "memory the GP utilization but that's",
    "start": "1317169",
    "end": "1319299"
  },
  {
    "text": "basically it's what we want you as a",
    "start": "1319299",
    "end": "1323470"
  },
  {
    "text": "user to be able to see as a lot more",
    "start": "1323470",
    "end": "1325270"
  },
  {
    "text": "advanced metrics like at the GPU power",
    "start": "1325270",
    "end": "1327549"
  },
  {
    "text": "usage the envy link bandwidth or in",
    "start": "1327549",
    "end": "1329679"
  },
  {
    "text": "general like the number of sense that",
    "start": "1329679",
    "end": "1331540"
  },
  {
    "text": "you're using",
    "start": "1331540",
    "end": "1332290"
  },
  {
    "text": "the temperature etc we want to be able",
    "start": "1332290",
    "end": "1334840"
  },
  {
    "text": "to expose a lot of these different",
    "start": "1334840",
    "end": "1336760"
  },
  {
    "text": "metrics to you as the end user because",
    "start": "1336760",
    "end": "1338530"
  },
  {
    "text": "you you'll be able then to identify for",
    "start": "1338530",
    "end": "1342820"
  },
  {
    "text": "example GPU tests that are trying to",
    "start": "1342820",
    "end": "1346240"
  },
  {
    "text": "that that are just for example faulting",
    "start": "1346240",
    "end": "1349060"
  },
  {
    "text": "or detect power in efficiencies that's",
    "start": "1349060",
    "end": "1351610"
  },
  {
    "text": "something that might be interesting for",
    "start": "1351610",
    "end": "1353080"
  },
  {
    "text": "you or in general you might want to be",
    "start": "1353080",
    "end": "1356080"
  },
  {
    "text": "able to tell your deploying scientist",
    "start": "1356080",
    "end": "1357820"
  },
  {
    "text": "that you've seen some bottlenecks and",
    "start": "1357820",
    "end": "1360160"
  },
  {
    "text": "some throttling on the GPU other",
    "start": "1360160",
    "end": "1363940"
  },
  {
    "text": "challenges that we're looking at is",
    "start": "1363940",
    "end": "1365850"
  },
  {
    "start": "1364000",
    "end": "1364000"
  },
  {
    "text": "supporting heterogeneous clusters so",
    "start": "1365850",
    "end": "1368530"
  },
  {
    "text": "right now if you have multiple GPUs on",
    "start": "1368530",
    "end": "1370810"
  },
  {
    "text": "your cluster and you want to be able to",
    "start": "1370810",
    "end": "1372760"
  },
  {
    "text": "specify some requirements for example I",
    "start": "1372760",
    "end": "1375430"
  },
  {
    "text": "want to use this amount of memory I",
    "start": "1375430",
    "end": "1377650"
  },
  {
    "text": "might ask users at least eight gigs of",
    "start": "1377650",
    "end": "1379720"
  },
  {
    "text": "memory the only way you really have to",
    "start": "1379720",
    "end": "1383800"
  },
  {
    "text": "do it is you manually label your nodes",
    "start": "1383800",
    "end": "1386100"
  },
  {
    "text": "and use taints and combinations and you",
    "start": "1386100",
    "end": "1390340"
  },
  {
    "text": "might want to do for example envy link",
    "start": "1390340",
    "end": "1392620"
  },
  {
    "text": "ECC enabled and that's something we're",
    "start": "1392620",
    "end": "1395530"
  },
  {
    "text": "looking at in general with a something",
    "start": "1395530",
    "end": "1399400"
  },
  {
    "text": "that's called the resource class we also",
    "start": "1399400",
    "end": "1402550"
  },
  {
    "text": "have this this annoying bug that or just",
    "start": "1402550",
    "end": "1406840"
  },
  {
    "text": "in general implementation shortcoming",
    "start": "1406840",
    "end": "1408760"
  },
  {
    "text": "that with darker your only option is to",
    "start": "1408760",
    "end": "1412570"
  },
  {
    "text": "actually set the default runtime to",
    "start": "1412570",
    "end": "1414880"
  },
  {
    "text": "Nvidia and that means that all your in",
    "start": "1414880",
    "end": "1417520"
  },
  {
    "text": "all the docker images or all the",
    "start": "1417520",
    "end": "1420040"
  },
  {
    "text": "container images that are actually run",
    "start": "1420040",
    "end": "1421840"
  },
  {
    "text": "on your node will use the Nvidia runtime",
    "start": "1421840",
    "end": "1423840"
  },
  {
    "text": "that leads to this little unintended",
    "start": "1423840",
    "end": "1427570"
  },
  {
    "text": "consequence that if you have Nvidia",
    "start": "1427570",
    "end": "1430000"
  },
  {
    "text": "images that don't request GPUs they'll",
    "start": "1430000",
    "end": "1431740"
  },
  {
    "text": "see all the GPUs this is something we've",
    "start": "1431740",
    "end": "1434740"
  },
  {
    "text": "actually fixed in cRIO because you don't",
    "start": "1434740",
    "end": "1437080"
  },
  {
    "text": "have to set the default runtime to",
    "start": "1437080",
    "end": "1438730"
  },
  {
    "text": "Nvidia but we're looking at pushing that",
    "start": "1438730",
    "end": "1443020"
  },
  {
    "text": "in the community really what what are",
    "start": "1443020",
    "end": "1448090"
  },
  {
    "text": "the things that are really interesting",
    "start": "1448090",
    "end": "1449770"
  },
  {
    "text": "and we want to solve for the users our",
    "start": "1449770",
    "end": "1453030"
  },
  {
    "text": "GPU sharing and GPU topology and GPU",
    "start": "1453030",
    "end": "1457450"
  },
  {
    "text": "sharing is an interesting features that",
    "start": "1457450",
    "end": "1459520"
  },
  {
    "text": "is an interesting feature that you as a",
    "start": "1459520",
    "end": "1462070"
  },
  {
    "text": "user will be able to well you'll be able",
    "start": "1462070",
    "end": "1464950"
  },
  {
    "text": "to save some money",
    "start": "1464950",
    "end": "1466460"
  },
  {
    "text": "mostly we want you to be able to use our",
    "start": "1466460",
    "end": "1468799"
  },
  {
    "text": "GPUs at its full capacity because it's",
    "start": "1468799",
    "end": "1471950"
  },
  {
    "text": "really wasteful for you to actually have",
    "start": "1471950",
    "end": "1474350"
  },
  {
    "text": "a Volta and use an inference service but",
    "start": "1474350",
    "end": "1476750"
  },
  {
    "text": "it only uses 25% of that Volta and",
    "start": "1476750",
    "end": "1480080"
  },
  {
    "text": "that's that's most of the use cases that",
    "start": "1480080",
    "end": "1482510"
  },
  {
    "text": "we see for GPU sharing is mostly around",
    "start": "1482510",
    "end": "1485059"
  },
  {
    "text": "inference the question we're still",
    "start": "1485059",
    "end": "1489020"
  },
  {
    "text": "figuring out is how do we actually",
    "start": "1489020",
    "end": "1490490"
  },
  {
    "text": "expose that to the user because GPU",
    "start": "1490490",
    "end": "1494570"
  },
  {
    "text": "sharing is something that's mostly going",
    "start": "1494570",
    "end": "1496880"
  },
  {
    "text": "to be about scheduling in terms of how",
    "start": "1496880",
    "end": "1500720"
  },
  {
    "text": "its implemented in the runtime it's",
    "start": "1500720",
    "end": "1502820"
  },
  {
    "text": "still something that we need to figure",
    "start": "1502820",
    "end": "1504860"
  },
  {
    "text": "out because we don't have for example a",
    "start": "1504860",
    "end": "1506809"
  },
  {
    "text": "specific way to actually limit the",
    "start": "1506809",
    "end": "1508880"
  },
  {
    "text": "amount of memory a specific process or",
    "start": "1508880",
    "end": "1511460"
  },
  {
    "text": "container use and GPU topology is well",
    "start": "1511460",
    "end": "1515539"
  },
  {
    "text": "if you if you're if your container",
    "start": "1515539",
    "end": "1517700"
  },
  {
    "text": "actually request Q GPUs you can't give",
    "start": "1517700",
    "end": "1519890"
  },
  {
    "text": "it any Q GPUs on your node if you have a",
    "start": "1519890",
    "end": "1522409"
  },
  {
    "text": "numerous 10 for example you might want",
    "start": "1522409",
    "end": "1525260"
  },
  {
    "text": "to be you might want to be able to have",
    "start": "1525260",
    "end": "1526850"
  },
  {
    "text": "these two GPUs communicates as you env",
    "start": "1526850",
    "end": "1529640"
  },
  {
    "text": "link and not through QP I usually if you",
    "start": "1529640",
    "end": "1534559"
  },
  {
    "text": "actually just take any two GPUs the",
    "start": "1534559",
    "end": "1539270"
  },
  {
    "text": "issue you're facing is that it's",
    "start": "1539270",
    "end": "1540679"
  },
  {
    "text": "probably not as sometimes it's probably",
    "start": "1540679",
    "end": "1543260"
  },
  {
    "text": "not worth to even run the task we had",
    "start": "1543260",
    "end": "1548360"
  },
  {
    "text": "tree had the same problem is how do we",
    "start": "1548360",
    "end": "1550429"
  },
  {
    "text": "actually expose that to the user in",
    "start": "1550429",
    "end": "1553210"
  },
  {
    "text": "general these are the challenges ahead",
    "start": "1553210",
    "end": "1555860"
  },
  {
    "text": "in kubernetes but even in containers we",
    "start": "1555860",
    "end": "1558470"
  },
  {
    "text": "still have a lot of challenges for",
    "start": "1558470",
    "end": "1560000"
  },
  {
    "start": "1559000",
    "end": "1559000"
  },
  {
    "text": "example we want to be able to attach and",
    "start": "1560000",
    "end": "1562130"
  },
  {
    "text": "detach GPUs dynamically we want to be",
    "start": "1562130",
    "end": "1564260"
  },
  {
    "text": "able to support a lot of different",
    "start": "1564260",
    "end": "1565700"
  },
  {
    "text": "architectures so currently we we we have",
    "start": "1565700",
    "end": "1569539"
  },
  {
    "text": "a supporting in cost but there's a lot",
    "start": "1569539",
    "end": "1572240"
  },
  {
    "text": "of other container OS out there that we",
    "start": "1572240",
    "end": "1574370"
  },
  {
    "text": "want to be able to support or",
    "start": "1574370",
    "end": "1575860"
  },
  {
    "text": "virtualization so for example Quetta",
    "start": "1575860",
    "end": "1577970"
  },
  {
    "text": "containers as I was mentioning we're",
    "start": "1577970",
    "end": "1581120"
  },
  {
    "text": "enabling graphics and video encoding but",
    "start": "1581120",
    "end": "1583159"
  },
  {
    "text": "there's a lot of things that we still",
    "start": "1583159",
    "end": "1585200"
  },
  {
    "text": "need to actually expose with EPS so here",
    "start": "1585200",
    "end": "1590630"
  },
  {
    "text": "we go",
    "start": "1590630",
    "end": "1590960"
  },
  {
    "text": "that was my presentation and",
    "start": "1590960",
    "end": "1594309"
  },
  {
    "text": "thank you I think we still have some",
    "start": "1597320",
    "end": "1600659"
  },
  {
    "text": "time for questions and so um I think",
    "start": "1600659",
    "end": "1605759"
  },
  {
    "text": "there's a mic here Thanks",
    "start": "1605759",
    "end": "1613849"
  },
  {
    "text": "hi",
    "start": "1632930",
    "end": "1635190"
  },
  {
    "text": "you mentioned NWS a couple of times",
    "start": "1635190",
    "end": "1636720"
  },
  {
    "text": "there and I I recently found out that",
    "start": "1636720",
    "end": "1638880"
  },
  {
    "text": "there's actually two ways to get GP",
    "start": "1638880",
    "end": "1640320"
  },
  {
    "text": "using in the rest you can get GPU",
    "start": "1640320",
    "end": "1641880"
  },
  {
    "text": "instances but you can also attach",
    "start": "1641880",
    "end": "1644400"
  },
  {
    "text": "standalone GPUs to I guess any instance",
    "start": "1644400",
    "end": "1647190"
  },
  {
    "text": "type are both supported on whatever",
    "start": "1647190",
    "end": "1651450"
  },
  {
    "text": "setup we have today that setup that you",
    "start": "1651450",
    "end": "1652890"
  },
  {
    "text": "mentioned are both ways supported both a",
    "start": "1652890",
    "end": "1655860"
  },
  {
    "text": "proper GPU instance and just taking any",
    "start": "1655860",
    "end": "1658320"
  },
  {
    "text": "AWS instance and attaching a GPU to it",
    "start": "1658320",
    "end": "1661020"
  },
  {
    "text": "so um the way you're expected actually",
    "start": "1661020",
    "end": "1664260"
  },
  {
    "text": "to to use GPS and kubernetes is you",
    "start": "1664260",
    "end": "1668970"
  },
  {
    "text": "provision your note before you actually",
    "start": "1668970",
    "end": "1670670"
  },
  {
    "text": "register you know two against kubernetes",
    "start": "1670670",
    "end": "1672750"
  },
  {
    "text": "you provision it with GPUs if you're",
    "start": "1672750",
    "end": "1675210"
  },
  {
    "text": "dynamically attaching GPUs we don't",
    "start": "1675210",
    "end": "1678660"
  },
  {
    "text": "really support that thank you",
    "start": "1678660",
    "end": "1682490"
  },
  {
    "text": "hi can you briefly mention what is",
    "start": "1701240",
    "end": "1704070"
  },
  {
    "text": "supported or coming in terms of graphic",
    "start": "1704070",
    "end": "1706650"
  },
  {
    "text": "support can I run an OpenGL renderer and",
    "start": "1706650",
    "end": "1708690"
  },
  {
    "text": "get the frame buffer things like that",
    "start": "1708690",
    "end": "1710520"
  },
  {
    "text": "can you run sorry what OpenGL renderer",
    "start": "1710520",
    "end": "1713520"
  },
  {
    "text": "and get the frame buffer result is that",
    "start": "1713520",
    "end": "1715620"
  },
  {
    "text": "possible yet or coming or um so I",
    "start": "1715620",
    "end": "1718620"
  },
  {
    "text": "believe we have some images already",
    "start": "1718620",
    "end": "1724110"
  },
  {
    "text": "available in the docker hub I think we",
    "start": "1724110",
    "end": "1728460"
  },
  {
    "text": "support egl I believe you support GL and",
    "start": "1728460",
    "end": "1731130"
  },
  {
    "text": "we're looking at supporting a lot more",
    "start": "1731130",
    "end": "1733610"
  },
  {
    "text": "this effort is still ongoing so",
    "start": "1733610",
    "end": "1737690"
  },
  {
    "text": "depending on what you exactly need the",
    "start": "1737690",
    "end": "1740460"
  },
  {
    "text": "answer is probably yes but it could also",
    "start": "1740460",
    "end": "1742350"
  },
  {
    "text": "be no so it's very user specific sorry",
    "start": "1742350",
    "end": "1751880"
  },
  {
    "text": "okay well thank you very much and and I",
    "start": "1752540",
    "end": "1756900"
  },
  {
    "text": "guess since there are no other questions",
    "start": "1756900",
    "end": "1758700"
  },
  {
    "text": "and this is it",
    "start": "1758700",
    "end": "1761050"
  },
  {
    "text": "[Applause]",
    "start": "1761050",
    "end": "1765490"
  }
]
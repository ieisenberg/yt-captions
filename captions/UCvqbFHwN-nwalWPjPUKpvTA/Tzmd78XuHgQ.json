[
  {
    "text": "so I'm jel Ahmed I am flying all the way",
    "start": "40",
    "end": "2639"
  },
  {
    "text": "from India to deliver this uh my co-",
    "start": "2639",
    "end": "6080"
  },
  {
    "text": "speaker Rohit he couldn't travel because",
    "start": "6080",
    "end": "7759"
  },
  {
    "text": "of v um I am an AI architect and a cloud",
    "start": "7759",
    "end": "11679"
  },
  {
    "text": "architect at a health and safety company",
    "start": "11679",
    "end": "14000"
  },
  {
    "text": "called navat group and Rohit is a cncf",
    "start": "14000",
    "end": "16840"
  },
  {
    "text": "Ambassador and also uh think developer",
    "start": "16840",
    "end": "21080"
  },
  {
    "text": "relations manager at seos uh so today",
    "start": "21080",
    "end": "23680"
  },
  {
    "text": "we'll be talking around how do you uh",
    "start": "23680",
    "end": "25640"
  },
  {
    "text": "scale llms uh deploy them efficiently",
    "start": "25640",
    "end": "28240"
  },
  {
    "text": "and quickly right uh",
    "start": "28240",
    "end": "31160"
  },
  {
    "text": "uh okay I think we all agree to this",
    "start": "31160",
    "end": "34760"
  },
  {
    "text": "right you know alms today are everywhere",
    "start": "34760",
    "end": "36719"
  },
  {
    "text": "right every product that we see see",
    "start": "36719",
    "end": "38399"
  },
  {
    "text": "today everything that I've been using",
    "start": "38399",
    "end": "40600"
  },
  {
    "text": "for quite some time has an LM flavor to",
    "start": "40600",
    "end": "42680"
  },
  {
    "text": "it right some feature has been powered",
    "start": "42680",
    "end": "44280"
  },
  {
    "text": "by LM and this has been the rise of llms",
    "start": "44280",
    "end": "47879"
  },
  {
    "text": "right I think right from pre-2020 with",
    "start": "47879",
    "end": "50600"
  },
  {
    "text": "the rise of Transformers and but to",
    "start": "50600",
    "end": "52280"
  },
  {
    "text": "today where we have Fon 180b or even you",
    "start": "52280",
    "end": "55320"
  },
  {
    "text": "know exess Gro",
    "start": "55320",
    "end": "57440"
  },
  {
    "text": "340b uh models right which are",
    "start": "57440",
    "end": "61000"
  },
  {
    "text": "there and as the eyes of these models it",
    "start": "61000",
    "end": "63120"
  },
  {
    "text": "is difficult for us as an ml Engineers",
    "start": "63120",
    "end": "64760"
  },
  {
    "text": "to keep up with the systems deploy them",
    "start": "64760",
    "end": "67200"
  },
  {
    "text": "make sure that these go out out to our",
    "start": "67200",
    "end": "69000"
  },
  {
    "text": "hands of the users fast and they work",
    "start": "69000",
    "end": "71560"
  },
  {
    "text": "right uh the potential challenges I",
    "start": "71560",
    "end": "74119"
  },
  {
    "text": "think uh uh things around uh the",
    "start": "74119",
    "end": "77040"
  },
  {
    "text": "computational resources that is required",
    "start": "77040",
    "end": "78799"
  },
  {
    "text": "right both for training inference it",
    "start": "78799",
    "end": "81159"
  },
  {
    "text": "leads to a high inference cost High",
    "start": "81159",
    "end": "83000"
  },
  {
    "text": "infrastructure cost both for managing",
    "start": "83000",
    "end": "84799"
  },
  {
    "text": "right uh scaling up with gpus with hard",
    "start": "84799",
    "end": "87759"
  },
  {
    "text": "you know ml Engineers here know you know",
    "start": "87759",
    "end": "90159"
  },
  {
    "text": "while scaling up with CPUs is easier",
    "start": "90159",
    "end": "91960"
  },
  {
    "text": "it's because also because it's easy to",
    "start": "91960",
    "end": "94159"
  },
  {
    "text": "get like hold of those machines right",
    "start": "94159",
    "end": "96040"
  },
  {
    "text": "versus the GPU instances U all of these",
    "start": "96040",
    "end": "98880"
  },
  {
    "text": "models have a very high uh latency uh",
    "start": "98880",
    "end": "102439"
  },
  {
    "text": "because LMS are sequential nature right",
    "start": "102439",
    "end": "104759"
  },
  {
    "text": "to generate and let's say sentence of",
    "start": "104759",
    "end": "108719"
  },
  {
    "text": "52 u words you need to iterate 512 times",
    "start": "108719",
    "end": "112640"
  },
  {
    "text": "right so it's per token you're just",
    "start": "112640",
    "end": "114640"
  },
  {
    "text": "adding to the latency of it LMS are",
    "start": "114640",
    "end": "116759"
  },
  {
    "text": "large in size we have seen you know we",
    "start": "116759",
    "end": "118240"
  },
  {
    "text": "have models around 180b or 3 40 B",
    "start": "118240",
    "end": "123200"
  },
  {
    "text": "uh parameters and because of that it",
    "start": "123200",
    "end": "126079"
  },
  {
    "text": "impacts on the infrastructure impacts on",
    "start": "126079",
    "end": "127799"
  },
  {
    "text": "the latency in imp speed right and all",
    "start": "127799",
    "end": "130319"
  },
  {
    "text": "of these models have also High uh like",
    "start": "130319",
    "end": "132800"
  },
  {
    "text": "memory",
    "start": "132800",
    "end": "134160"
  },
  {
    "text": "requirements and I think I don't need to",
    "start": "134160",
    "end": "136080"
  },
  {
    "text": "reiterate this again uh but I think in",
    "start": "136080",
    "end": "138480"
  },
  {
    "text": "the in the previous talk around uh gp4 K",
    "start": "138480",
    "end": "142680"
  },
  {
    "text": "said right I think the speaker said in",
    "start": "142680",
    "end": "145000"
  },
  {
    "text": "ml kubernetes has become more like a",
    "start": "145000",
    "end": "147080"
  },
  {
    "text": "choice and it's not a Defector platform",
    "start": "147080",
    "end": "148760"
  },
  {
    "text": "R which is where we are moving I think",
    "start": "148760",
    "end": "150360"
  },
  {
    "text": "the ecosystem or the all ml Engineers",
    "start": "150360",
    "end": "151879"
  },
  {
    "text": "are moving to adopt Coes to deploy these",
    "start": "151879",
    "end": "155160"
  },
  {
    "text": "models uh I think the good thing that",
    "start": "155160",
    "end": "157160"
  },
  {
    "text": "Coes brings to us and as ml Engineers I",
    "start": "157160",
    "end": "159280"
  },
  {
    "text": "think we are not used to this right we",
    "start": "159280",
    "end": "160680"
  },
  {
    "text": "are used to writing on a jupyter",
    "start": "160680",
    "end": "162560"
  },
  {
    "text": "notebook building our models and be be",
    "start": "162560",
    "end": "164360"
  },
  {
    "text": "done with it right uh scalability of the",
    "start": "164360",
    "end": "167720"
  },
  {
    "text": "ml workloads optimized resource",
    "start": "167720",
    "end": "169640"
  },
  {
    "text": "allocation I think a good thing that",
    "start": "169640",
    "end": "170959"
  },
  {
    "text": "comes to us uh you know platform",
    "start": "170959",
    "end": "173040"
  },
  {
    "text": "agnostic often a time these models the",
    "start": "173040",
    "end": "175400"
  },
  {
    "text": "the ml engineers build them on their",
    "start": "175400",
    "end": "177159"
  },
  {
    "text": "machines or or on some other Cloud",
    "start": "177159",
    "end": "178800"
  },
  {
    "text": "platform but with with the scality of",
    "start": "178800",
    "end": "181239"
  },
  {
    "text": "gpus you need to move to various clouds",
    "start": "181239",
    "end": "184120"
  },
  {
    "text": "uh quickly wherever you get the GPU",
    "start": "184120",
    "end": "185760"
  },
  {
    "text": "right which is where the platform",
    "start": "185760",
    "end": "186680"
  },
  {
    "text": "agnostic part comes very handy and uh",
    "start": "186680",
    "end": "190120"
  },
  {
    "text": "with you know fall tolerance and",
    "start": "190120",
    "end": "192200"
  },
  {
    "text": "selfhealing capabilities the reliability",
    "start": "192200",
    "end": "194400"
  },
  {
    "text": "also comes onto the platform right but",
    "start": "194400",
    "end": "196560"
  },
  {
    "text": "all these are good things but when you",
    "start": "196560",
    "end": "198760"
  },
  {
    "text": "and okay before I go to that I think",
    "start": "198760",
    "end": "200159"
  },
  {
    "text": "this is a quote from Christopher burner",
    "start": "200159",
    "end": "203200"
  },
  {
    "text": "which and and this session was delivered",
    "start": "203200",
    "end": "205720"
  },
  {
    "text": "back in uh cucon EU OR7 or like 17 where",
    "start": "205720",
    "end": "210000"
  },
  {
    "text": "they mentioned I think all the infra is",
    "start": "210000",
    "end": "212360"
  },
  {
    "text": "on kubernetes and it scales up to 10 to",
    "start": "212360",
    "end": "214319"
  },
  {
    "text": "50x on the infrastructure right and",
    "start": "214319",
    "end": "216159"
  },
  {
    "text": "gives a lot of uh flexibility to the",
    "start": "216159",
    "end": "219040"
  },
  {
    "text": "developers to quickly experiment and",
    "start": "219040",
    "end": "220599"
  },
  {
    "text": "deploy their ml models uh and this might",
    "start": "220599",
    "end": "223640"
  },
  {
    "text": "be a typical architecture that you might",
    "start": "223640",
    "end": "225640"
  },
  {
    "text": "have seen or is are seeing across uh any",
    "start": "225640",
    "end": "229280"
  },
  {
    "text": "platform right so at the end you have",
    "start": "229280",
    "end": "230720"
  },
  {
    "text": "the user uh end users who talk to uh the",
    "start": "230720",
    "end": "234400"
  },
  {
    "text": "client AP let's say chat GPT or any any",
    "start": "234400",
    "end": "236879"
  },
  {
    "text": "LM power application that you build",
    "start": "236879",
    "end": "238519"
  },
  {
    "text": "right and on on our side we have let",
    "start": "238519",
    "end": "241400"
  },
  {
    "text": "secq",
    "start": "241400",
    "end": "242400"
  },
  {
    "text": "flow where you have these models",
    "start": "242400",
    "end": "244519"
  },
  {
    "text": "deployed and these models are deployed",
    "start": "244519",
    "end": "246760"
  },
  {
    "text": "on the using K or any other things right",
    "start": "246760",
    "end": "250120"
  },
  {
    "text": "but uh when you talk about this right it",
    "start": "250120",
    "end": "252360"
  },
  {
    "text": "is not as simple as how it looks right I",
    "start": "252360",
    "end": "255319"
  },
  {
    "text": "think the current experience if you talk",
    "start": "255319",
    "end": "256880"
  },
  {
    "text": "about from a developer perspective you",
    "start": "256880",
    "end": "258479"
  },
  {
    "text": "know downloading those models large",
    "start": "258479",
    "end": "260799"
  },
  {
    "text": "models say these are 200 to 400 GB size",
    "start": "260799",
    "end": "263759"
  },
  {
    "text": "of models we need to download with",
    "start": "263759",
    "end": "265880"
  },
  {
    "text": "expensive memory requirements long wait",
    "start": "265880",
    "end": "267960"
  },
  {
    "text": "times to load the models think about",
    "start": "267960",
    "end": "269759"
  },
  {
    "text": "about a uh you know upscaling scenario",
    "start": "269759",
    "end": "272280"
  },
  {
    "text": "where you need to U upscale within",
    "start": "272280",
    "end": "274440"
  },
  {
    "text": "milliseconds right but then you need to",
    "start": "274440",
    "end": "276440"
  },
  {
    "text": "download these large models and that",
    "start": "276440",
    "end": "278199"
  },
  {
    "text": "takes up a lot of latency just to load",
    "start": "278199",
    "end": "280000"
  },
  {
    "text": "the",
    "start": "280000",
    "end": "280639"
  },
  {
    "text": "model and and provision",
    "start": "280639",
    "end": "283560"
  },
  {
    "text": "it then uh The Next Step that comes to",
    "start": "283560",
    "end": "286280"
  },
  {
    "text": "you know in the life cycle and currently",
    "start": "286280",
    "end": "288280"
  },
  {
    "text": "uh even if you have to use C FL right",
    "start": "288280",
    "end": "290000"
  },
  {
    "text": "you need to create a container file you",
    "start": "290000",
    "end": "292039"
  },
  {
    "text": "need to optimize the models reduce those",
    "start": "292039",
    "end": "293880"
  },
  {
    "text": "model files convert them and create a",
    "start": "293880",
    "end": "296400"
  },
  {
    "text": "container and then push them to a",
    "start": "296400",
    "end": "298080"
  },
  {
    "text": "container rry right on top of that you",
    "start": "298080",
    "end": "300560"
  },
  {
    "text": "host the model provision necessary GPU",
    "start": "300560",
    "end": "303759"
  },
  {
    "text": "infrastructure may be a standalone",
    "start": "303759",
    "end": "306160"
  },
  {
    "text": "machine or let's say in a cluster and",
    "start": "306160",
    "end": "309800"
  },
  {
    "text": "then finally like set up the inference",
    "start": "309800",
    "end": "311840"
  },
  {
    "text": "server on top of that which serves the",
    "start": "311840",
    "end": "313680"
  },
  {
    "text": "API endpoint and then all your uh",
    "start": "313680",
    "end": "317400"
  },
  {
    "text": "applications talk to it right and then",
    "start": "317400",
    "end": "318960"
  },
  {
    "text": "troubleshoot any shared GPU like quota",
    "start": "318960",
    "end": "321600"
  },
  {
    "text": "limitations even if you how do you scale",
    "start": "321600",
    "end": "324199"
  },
  {
    "text": "and all those things right all these",
    "start": "324199",
    "end": "326600"
  },
  {
    "text": "things are disjoint right all these",
    "start": "326600",
    "end": "328280"
  },
  {
    "text": "things are one of the you two every time",
    "start": "328280",
    "end": "330440"
  },
  {
    "text": "repeatedly whenever you have to deploy",
    "start": "330440",
    "end": "331880"
  },
  {
    "text": "the model right and this takes several",
    "start": "331880",
    "end": "334000"
  },
  {
    "text": "weeks right if you see in the survey uh",
    "start": "334000",
    "end": "336360"
  },
  {
    "text": "you know a lot of surveys talk about 90%",
    "start": "336360",
    "end": "338199"
  },
  {
    "text": "of ml today projects don't go to",
    "start": "338199",
    "end": "341280"
  },
  {
    "text": "production just because of this right it",
    "start": "341280",
    "end": "343120"
  },
  {
    "text": "takes a lot of time for you to uh make",
    "start": "343120",
    "end": "345880"
  },
  {
    "text": "sure you have a model which works but",
    "start": "345880",
    "end": "347600"
  },
  {
    "text": "now pushing from then from let's say",
    "start": "347600",
    "end": "349240"
  },
  {
    "text": "staging to Pro takes a lot of time right",
    "start": "349240",
    "end": "352039"
  },
  {
    "text": "uh enters Kao right it's a kubernetes AI",
    "start": "352039",
    "end": "356800"
  },
  {
    "text": "uh tool chain operator it's I think 3",
    "start": "356800",
    "end": "359319"
  },
  {
    "text": "weeks",
    "start": "359319",
    "end": "360280"
  },
  {
    "text": "whole it's announced very recently uh",
    "start": "360280",
    "end": "363360"
  },
  {
    "text": "what it does is it automates that LM",
    "start": "363360",
    "end": "365440"
  },
  {
    "text": "inference on kubernetes right across",
    "start": "365440",
    "end": "367720"
  },
  {
    "text": "gpus and CPU so think about a scenario",
    "start": "367720",
    "end": "369800"
  },
  {
    "text": "where you have a model which doesn't",
    "start": "369800",
    "end": "372400"
  },
  {
    "text": "needs a lot of compute it can run on the",
    "start": "372400",
    "end": "374639"
  },
  {
    "text": "CPU at the same time it can also share",
    "start": "374639",
    "end": "377280"
  },
  {
    "text": "the same GPU across multiple models",
    "start": "377280",
    "end": "379160"
  },
  {
    "text": "which can uh you know let's say you have",
    "start": "379160",
    "end": "380919"
  },
  {
    "text": "one GPU one large GPU so that large GPU",
    "start": "380919",
    "end": "383160"
  },
  {
    "text": "can be shared across multiple smaller",
    "start": "383160",
    "end": "384639"
  },
  {
    "text": "models and those can run efficiently on",
    "start": "384639",
    "end": "386880"
  },
  {
    "text": "the same from right so it selects optim",
    "start": "386880",
    "end": "389639"
  },
  {
    "text": "M ly sized infrastructure for the model",
    "start": "389639",
    "end": "391440"
  },
  {
    "text": "so whenever you declare the model you",
    "start": "391440",
    "end": "393360"
  },
  {
    "text": "just give the requirements on what this",
    "start": "393360",
    "end": "395240"
  },
  {
    "text": "model needs and basis on that it selects",
    "start": "395240",
    "end": "397960"
  },
  {
    "text": "the right infra and then deploys it for",
    "start": "397960",
    "end": "399800"
  },
  {
    "text": "you right so it easily splits inference",
    "start": "399800",
    "end": "402560"
  },
  {
    "text": "across multiple lower GPU con let's say",
    "start": "402560",
    "end": "404599"
  },
  {
    "text": "you have a model model that needs a00",
    "start": "404599",
    "end": "407440"
  },
  {
    "text": "right but you don't get a00 from a cloud",
    "start": "407440",
    "end": "409759"
  },
  {
    "text": "provider we can still run the same model",
    "start": "409759",
    "end": "412479"
  },
  {
    "text": "on an on a cluster of L4 gpus where you",
    "start": "412479",
    "end": "415080"
  },
  {
    "text": "are you know running the model in a",
    "start": "415080",
    "end": "416840"
  },
  {
    "text": "distributed fashion so eliminates waight",
    "start": "416840",
    "end": "418639"
  },
  {
    "text": "time for higher GPU con",
    "start": "418639",
    "end": "421160"
  },
  {
    "text": "VMS uh it also provides you this presets",
    "start": "421160",
    "end": "423960"
  },
  {
    "text": "model servers or model images so all you",
    "start": "423960",
    "end": "426160"
  },
  {
    "text": "have to do is just uh choose the preset",
    "start": "426160",
    "end": "429960"
  },
  {
    "text": "uh preset image and uh deploy that which",
    "start": "429960",
    "end": "432720"
  },
  {
    "text": "will eventually deploy your model into",
    "start": "432720",
    "end": "434080"
  },
  {
    "text": "the cluster right so Kao has two major",
    "start": "434080",
    "end": "437080"
  },
  {
    "text": "components uh one is the GPU provisional",
    "start": "437080",
    "end": "440919"
  },
  {
    "text": "controller so it uses a machine uh in",
    "start": "440919",
    "end": "443680"
  },
  {
    "text": "the custom resource definition it's",
    "start": "443680",
    "end": "445919"
  },
  {
    "text": "originated from Carpenter interact with",
    "start": "445919",
    "end": "448680"
  },
  {
    "text": "the workspace control controller to add",
    "start": "448680",
    "end": "450199"
  },
  {
    "text": "new GPU nodes into the cluster whenever",
    "start": "450199",
    "end": "452080"
  },
  {
    "text": "required right so in an upscaling",
    "start": "452080",
    "end": "453759"
  },
  {
    "text": "scenario if you need to upscale it adds",
    "start": "453759",
    "end": "456160"
  },
  {
    "text": "that resource back into the Custer and",
    "start": "456160",
    "end": "458160"
  },
  {
    "text": "upskill and then you have a workspace",
    "start": "458160",
    "end": "460319"
  },
  {
    "text": "controller right so which reconciles all",
    "start": "460319",
    "end": "463120"
  },
  {
    "text": "these crds triggers auton node",
    "start": "463120",
    "end": "464960"
  },
  {
    "text": "provisioning and does all the management",
    "start": "464960",
    "end": "466639"
  },
  {
    "text": "work for you uh so the architecture",
    "start": "466639",
    "end": "469199"
  },
  {
    "text": "looks something like this so in in the",
    "start": "469199",
    "end": "471919"
  },
  {
    "text": "core you have that API server where API",
    "start": "471919",
    "end": "475120"
  },
  {
    "text": "workload is running and you have your",
    "start": "475120",
    "end": "476680"
  },
  {
    "text": "crds written for each model each precept",
    "start": "476680",
    "end": "479599"
  },
  {
    "text": "which is available to you so whenever",
    "start": "479599",
    "end": "481039"
  },
  {
    "text": "you apply that crd uh the work workspace",
    "start": "481039",
    "end": "485120"
  },
  {
    "text": "controller talks to the node provision",
    "start": "485120",
    "end": "488120"
  },
  {
    "text": "uh provisioner provisions and note uh",
    "start": "488120",
    "end": "491240"
  },
  {
    "text": "and then deploys a model into that uh",
    "start": "491240",
    "end": "494400"
  },
  {
    "text": "available",
    "start": "494400",
    "end": "496479"
  },
  {
    "text": "cluster uh yeah so right now I think off",
    "start": "496479",
    "end": "500280"
  },
  {
    "text": "the box it supports deployment of Open",
    "start": "500280",
    "end": "502360"
  },
  {
    "text": "Source LMS like FAL and Lama 2 I think",
    "start": "502360",
    "end": "504800"
  },
  {
    "text": "52 or which are currently available out",
    "start": "504800",
    "end": "507560"
  },
  {
    "text": "of the box uh",
    "start": "507560",
    "end": "510080"
  },
  {
    "text": "it you know you can create your own",
    "start": "510080",
    "end": "511680"
  },
  {
    "text": "containers it also comes with an HTTP",
    "start": "511680",
    "end": "513919"
  },
  {
    "text": "server you don't have to do",
    "start": "513919",
    "end": "515800"
  },
  {
    "text": "anything in terms of how do you now talk",
    "start": "515800",
    "end": "518518"
  },
  {
    "text": "to that model uh you avoid uh tuning of",
    "start": "518519",
    "end": "523479"
  },
  {
    "text": "deployment parameters anything every one",
    "start": "523479",
    "end": "525279"
  },
  {
    "text": "of you know when you need to deploy a",
    "start": "525279",
    "end": "526640"
  },
  {
    "text": "model you need to do a Guess Game of",
    "start": "526640",
    "end": "528720"
  },
  {
    "text": "okay is this the right infrastructure",
    "start": "528720",
    "end": "529959"
  },
  {
    "text": "for my model right is the right GPU is",
    "start": "529959",
    "end": "531720"
  },
  {
    "text": "this my right setup for the model and",
    "start": "531720",
    "end": "533920"
  },
  {
    "text": "can it uh fit or this can uh the infra",
    "start": "533920",
    "end": "537880"
  },
  {
    "text": "that I have uh fit the model that I have",
    "start": "537880",
    "end": "540160"
  },
  {
    "text": "right so all this guessing game is",
    "start": "540160",
    "end": "542240"
  },
  {
    "text": "rewarded U you know removed right uh",
    "start": "542240",
    "end": "544560"
  },
  {
    "text": "Auto provisioning of the GPU nodes U so",
    "start": "544560",
    "end": "547519"
  },
  {
    "text": "I I'll show you a yaml configuration",
    "start": "547519",
    "end": "549200"
  },
  {
    "text": "where you just have to Define okay this",
    "start": "549200",
    "end": "550480"
  },
  {
    "text": "is a requirement and it Provisions for",
    "start": "550480",
    "end": "553040"
  },
  {
    "text": "you deploys the model right and then you",
    "start": "553040",
    "end": "554680"
  },
  {
    "text": "host all the large models in a public",
    "start": "554680",
    "end": "556600"
  },
  {
    "text": "registry if a license",
    "start": "556600",
    "end": "558399"
  },
  {
    "text": "allowed",
    "start": "558399",
    "end": "560760"
  },
  {
    "text": "uh so the key benefits I think uh so",
    "start": "560760",
    "end": "563760"
  },
  {
    "text": "reduce cost because I think first is the",
    "start": "563760",
    "end": "565839"
  },
  {
    "text": "redu cost because now that you can split",
    "start": "565839",
    "end": "568240"
  },
  {
    "text": "the same infra across or or the same",
    "start": "568240",
    "end": "570480"
  },
  {
    "text": "model across multiple smaller instances",
    "start": "570480",
    "end": "572560"
  },
  {
    "text": "that available to you so hence you don't",
    "start": "572560",
    "end": "575560"
  },
  {
    "text": "pay those higher end GPU nodes but you",
    "start": "575560",
    "end": "577959"
  },
  {
    "text": "pay to a cluster of smaller nodes which",
    "start": "577959",
    "end": "579920"
  },
  {
    "text": "still uh is good enough to run your",
    "start": "579920",
    "end": "582480"
  },
  {
    "text": "models right so it supports a lot of",
    "start": "582480",
    "end": "584279"
  },
  {
    "text": "Open Source slms llms uh you get uh fine",
    "start": "584279",
    "end": "588600"
  },
  {
    "text": "grein control over the cluster over the",
    "start": "588600",
    "end": "590160"
  },
  {
    "text": "models that you are deploying uh and and",
    "start": "590160",
    "end": "592920"
  },
  {
    "text": "on top of that you have Network",
    "start": "592920",
    "end": "594800"
  },
  {
    "text": "and data security for you to ensure that",
    "start": "594800",
    "end": "598360"
  },
  {
    "text": "uh your data is leaves the on is",
    "start": "598360",
    "end": "600839"
  },
  {
    "text": "clustered and your data is always",
    "start": "600839",
    "end": "603480"
  },
  {
    "text": "secure uh yeah so this is a uh this is",
    "start": "603480",
    "end": "606360"
  },
  {
    "text": "the only yl that you need to write in",
    "start": "606360",
    "end": "607920"
  },
  {
    "text": "order to deploy right once you uh deploy",
    "start": "607920",
    "end": "611640"
  },
  {
    "text": "let's say Kao and and uh enable it on",
    "start": "611640",
    "end": "613839"
  },
  {
    "text": "your cluster all you have to do is WR",
    "start": "613839",
    "end": "615160"
  },
  {
    "text": "just write this yaml file so first is",
    "start": "615160",
    "end": "617279"
  },
  {
    "text": "you give a workspace name um",
    "start": "617279",
    "end": "620680"
  },
  {
    "text": "second the GPU type or let's say the",
    "start": "620680",
    "end": "623839"
  },
  {
    "text": "instance that you need to use and some",
    "start": "623839",
    "end": "626600"
  },
  {
    "text": "uh prets right which presets uh you want",
    "start": "626600",
    "end": "629040"
  },
  {
    "text": "to use use for this",
    "start": "629040",
    "end": "631000"
  },
  {
    "text": "model uh yeah so if I need to I just if",
    "start": "631000",
    "end": "634920"
  },
  {
    "text": "I summarize the entire",
    "start": "634920",
    "end": "637079"
  },
  {
    "text": "experience uh you the currently these",
    "start": "637079",
    "end": "639360"
  },
  {
    "text": "are steps you need to do right you do an",
    "start": "639360",
    "end": "640839"
  },
  {
    "text": "environment setup you do a model setup",
    "start": "640839",
    "end": "642959"
  },
  {
    "text": "containerize it and finally deploy all",
    "start": "642959",
    "end": "645600"
  },
  {
    "text": "gets boiled in just deploy a Kito on",
    "start": "645600",
    "end": "647240"
  },
  {
    "text": "your kubernetes apply the crd and it's",
    "start": "647240",
    "end": "649839"
  },
  {
    "text": "done for you right your entire model is",
    "start": "649839",
    "end": "651440"
  },
  {
    "text": "deployed for you it's available as an",
    "start": "651440",
    "end": "652800"
  },
  {
    "text": "HTTP and point for you to talk to and uh",
    "start": "652800",
    "end": "655480"
  },
  {
    "text": "generate your",
    "start": "655480",
    "end": "657240"
  },
  {
    "text": "responses uh yeah so at the core let's",
    "start": "657240",
    "end": "659920"
  },
  {
    "text": "say you have your model weights model",
    "start": "659920",
    "end": "662079"
  },
  {
    "text": "containers host image and provision infr",
    "start": "662079",
    "end": "664079"
  },
  {
    "text": "right on in in between your model uh Kyo",
    "start": "664079",
    "end": "668040"
  },
  {
    "text": "sits it's it allows you to deploy your",
    "start": "668040",
    "end": "670680"
  },
  {
    "text": "model inference uh train your model on",
    "start": "670680",
    "end": "673560"
  },
  {
    "text": "top of this inov it and I think um so",
    "start": "673560",
    "end": "676720"
  },
  {
    "text": "your whole infra workspace setup for",
    "start": "676720",
    "end": "679040"
  },
  {
    "text": "model inferencing is done in a matter of",
    "start": "679040",
    "end": "680959"
  },
  {
    "text": "minutes instead of uh weeks which it",
    "start": "680959",
    "end": "684000"
  },
  {
    "text": "used to take",
    "start": "684000",
    "end": "685760"
  },
  {
    "text": "earlier uh quickly we'll go to demo I",
    "start": "685760",
    "end": "688040"
  },
  {
    "text": "think uh while Rohit was supposed to do",
    "start": "688040",
    "end": "691320"
  },
  {
    "text": "this we have a recorded",
    "start": "691320",
    "end": "694399"
  },
  {
    "text": "session I'm working as a de manager at",
    "start": "698040",
    "end": "700920"
  },
  {
    "text": "saos and we are simplifying the",
    "start": "700920",
    "end": "703320"
  },
  {
    "text": "developers life uh for like",
    "start": "703320",
    "end": "705360"
  },
  {
    "text": "authorization service kind of thing but",
    "start": "705360",
    "end": "707800"
  },
  {
    "text": "today's topic is more around the Kao",
    "start": "707800",
    "end": "710160"
  },
  {
    "text": "which is I guess you already learned",
    "start": "710160",
    "end": "712000"
  },
  {
    "text": "from the channel like what I actually",
    "start": "712000",
    "end": "713760"
  },
  {
    "text": "does and stuff but I would like to show",
    "start": "713760",
    "end": "715560"
  },
  {
    "text": "you in the demo like what how you can",
    "start": "715560",
    "end": "717720"
  },
  {
    "text": "set it up so Kao is nothing but CU a d",
    "start": "717720",
    "end": "721120"
  },
  {
    "text": "operator so we today going to diing into",
    "start": "721120",
    "end": "724120"
  },
  {
    "text": "like how Kao simplifies the development",
    "start": "724120",
    "end": "726000"
  },
  {
    "text": "of large scale a machine leing models",
    "start": "726000",
    "end": "728120"
  },
  {
    "text": "like Fon which is one of the example in",
    "start": "728120",
    "end": "730440"
  },
  {
    "text": "a CU environment I will use the AKs for",
    "start": "730440",
    "end": "733399"
  },
  {
    "text": "that uh so without wasting time let's",
    "start": "733399",
    "end": "736240"
  },
  {
    "text": "understand uh what how we can do",
    "start": "736240",
    "end": "739440"
  },
  {
    "text": "this so if I go here you will see uh uh",
    "start": "739440",
    "end": "744600"
  },
  {
    "text": "it is talking about this uh this website",
    "start": "744600",
    "end": "747560"
  },
  {
    "text": "you can go and check it out like how to",
    "start": "747560",
    "end": "750480"
  },
  {
    "text": "do the",
    "start": "750480",
    "end": "752880"
  },
  {
    "text": "stuff so yeah here we can see like uh",
    "start": "755320",
    "end": "759360"
  },
  {
    "text": "how actually you can set up the K22",
    "start": "759360",
    "end": "761600"
  },
  {
    "text": "automat AML model and uh how you can",
    "start": "761600",
    "end": "765360"
  },
  {
    "text": "manage large model files and how you can",
    "start": "765360",
    "end": "767839"
  },
  {
    "text": "set the configurations Auto provision",
    "start": "767839",
    "end": "769880"
  },
  {
    "text": "gpus and do lot of stuff right but uh",
    "start": "769880",
    "end": "774199"
  },
  {
    "text": "there is some pris you should uh take in",
    "start": "774199",
    "end": "777240"
  },
  {
    "text": "care like uh you have",
    "start": "777240",
    "end": "779720"
  },
  {
    "text": "you should have a subscription you",
    "start": "779720",
    "end": "781440"
  },
  {
    "text": "should have a c install you can set up",
    "start": "781440",
    "end": "786320"
  },
  {
    "text": "uh like uh how",
    "start": "793160",
    "end": "797320"
  },
  {
    "text": "actually cryption you should have also",
    "start": "797320",
    "end": "799440"
  },
  {
    "text": "CI install you can set up uh the things",
    "start": "799440",
    "end": "802959"
  },
  {
    "text": "uh like key concept and all you know you",
    "start": "802959",
    "end": "805800"
  },
  {
    "text": "should know that then we will set up",
    "start": "805800",
    "end": "807959"
  },
  {
    "text": "those a cluster and you will understand",
    "start": "807959",
    "end": "810360"
  },
  {
    "text": "that so today we are going to set up the",
    "start": "810360",
    "end": "812600"
  },
  {
    "text": "G is uh uh this cluster and enable the",
    "start": "812600",
    "end": "815600"
  },
  {
    "text": "AI tool chain operator add-on inside",
    "start": "815600",
    "end": "818120"
  },
  {
    "text": "that so how we can do that that is yeah",
    "start": "818120",
    "end": "821000"
  },
  {
    "text": "we will talk about like aess cluster and",
    "start": "821000",
    "end": "823399"
  },
  {
    "text": "enabling the Kido add-on so uh let's go",
    "start": "823399",
    "end": "827480"
  },
  {
    "text": "into that you can see like we have to go",
    "start": "827480",
    "end": "830600"
  },
  {
    "text": "with this process but first I would like",
    "start": "830600",
    "end": "832519"
  },
  {
    "text": "to show you one of the example which is",
    "start": "832519",
    "end": "835040"
  },
  {
    "text": "Kido uh workspace F call yml which you",
    "start": "835040",
    "end": "838519"
  },
  {
    "text": "can go on directly check it out so it is",
    "start": "838519",
    "end": "841759"
  },
  {
    "text": "simple you don't have to do a lot of",
    "start": "841759",
    "end": "843600"
  },
  {
    "text": "things here so it is saying like API",
    "start": "843600",
    "end": "845880"
  },
  {
    "text": "virion which is V1 Alpha of skop and uh",
    "start": "845880",
    "end": "850560"
  },
  {
    "text": "here we will also talk about the",
    "start": "850560",
    "end": "851959"
  },
  {
    "text": "workspace which is Falcon 7B then",
    "start": "851959",
    "end": "854720"
  },
  {
    "text": "instance type is standard NCS which is",
    "start": "854720",
    "end": "856800"
  },
  {
    "text": "like provided by Microsoft for the uh ml",
    "start": "856800",
    "end": "860399"
  },
  {
    "text": "workloads where you can use the GPU",
    "start": "860399",
    "end": "863279"
  },
  {
    "text": "so uh like you can spend the money for",
    "start": "863279",
    "end": "868399"
  },
  {
    "text": "the GP us because today everything is on",
    "start": "868399",
    "end": "870600"
  },
  {
    "text": "AI and gpus is one of the least thing we",
    "start": "870600",
    "end": "874480"
  },
  {
    "text": "should care about and then there is uh",
    "start": "874480",
    "end": "878279"
  },
  {
    "text": "uh like match labels where you can label",
    "start": "878279",
    "end": "880680"
  },
  {
    "text": "the key value things and all and then uh",
    "start": "880680",
    "end": "883880"
  },
  {
    "text": "preset is where we will configure the",
    "start": "883880",
    "end": "885639"
  },
  {
    "text": "Falon 7B so let's dive into uh our",
    "start": "885639",
    "end": "889320"
  },
  {
    "text": "today's",
    "start": "889320",
    "end": "891680"
  },
  {
    "text": "tar so as you can see so we are running",
    "start": "895279",
    "end": "900240"
  },
  {
    "text": "the feature indry then then we can move",
    "start": "900240",
    "end": "905040"
  },
  {
    "text": "forward with today's installment of the",
    "start": "905040",
    "end": "909240"
  },
  {
    "text": "uh what we say register of like you just",
    "start": "909240",
    "end": "913279"
  },
  {
    "text": "doing the name space register here now",
    "start": "913279",
    "end": "915800"
  },
  {
    "text": "let's move to Next Step which is I will",
    "start": "915800",
    "end": "918199"
  },
  {
    "text": "use here uh it will take like a lot of",
    "start": "918199",
    "end": "922519"
  },
  {
    "text": "time yeah it just started running",
    "start": "922519",
    "end": "924920"
  },
  {
    "text": "forward slowly",
    "start": "924920",
    "end": "928839"
  },
  {
    "text": "yeah you see this creating the cluster",
    "start": "930079",
    "end": "932160"
  },
  {
    "text": "see it is done now you will see like uh",
    "start": "932160",
    "end": "936279"
  },
  {
    "text": "uh it's done that and now you guys set",
    "start": "936279",
    "end": "939880"
  },
  {
    "text": "new things here uh which was mentioned",
    "start": "939880",
    "end": "942399"
  },
  {
    "text": "that it's like cluster created with the",
    "start": "942399",
    "end": "944000"
  },
  {
    "text": "things but now I'm using the uh AKs",
    "start": "944000",
    "end": "947399"
  },
  {
    "text": "update for the get credentials and stuff",
    "start": "947399",
    "end": "951560"
  },
  {
    "text": "uh also like uh it will help me to uh do",
    "start": "951560",
    "end": "955519"
  },
  {
    "text": "the identity and things so that's it is",
    "start": "955519",
    "end": "958079"
  },
  {
    "text": "done is ready and now let's move forward",
    "start": "958079",
    "end": "961800"
  },
  {
    "text": "uh let's",
    "start": "961800",
    "end": "964279"
  },
  {
    "text": "check like uh principal ID uh identity",
    "start": "964880",
    "end": "968880"
  },
  {
    "text": "MC Resource Group",
    "start": "968880",
    "end": "972240"
  },
  {
    "text": "and so here you will see like I",
    "start": "976240",
    "end": "979880"
  },
  {
    "text": "have see issuer here and it is helping",
    "start": "979880",
    "end": "983480"
  },
  {
    "text": "me for the then principal ID Ro Resource",
    "start": "983480",
    "end": "987480"
  },
  {
    "text": "Group role definition ID ID is one the",
    "start": "987480",
    "end": "990360"
  },
  {
    "text": "important thing if you are working",
    "start": "990360",
    "end": "991759"
  },
  {
    "text": "towards identity and stuff yeah it is",
    "start": "991759",
    "end": "994279"
  },
  {
    "text": "earing and we can see uh it will connect",
    "start": "994279",
    "end": "997759"
  },
  {
    "text": "yeah it is created uh named as a card of",
    "start": "997759",
    "end": "1000600"
  },
  {
    "text": "idty verified by Runing your",
    "start": "1000600",
    "end": "1005120"
  },
  {
    "text": "deployment and cling filed just now to",
    "start": "1005880",
    "end": "1009440"
  },
  {
    "text": "create uh verify your deployment and",
    "start": "1009440",
    "end": "1011680"
  },
  {
    "text": "stuff uh it is it just have to run the",
    "start": "1011680",
    "end": "1016560"
  },
  {
    "text": "command get deployments",
    "start": "1016560",
    "end": "1020440"
  },
  {
    "text": "that we now host which is this Falcon 7B",
    "start": "1022759",
    "end": "1024760"
  },
  {
    "text": "model and so we're going to",
    "start": "1024760",
    "end": "1028120"
  },
  {
    "text": "use yeah so once you have uh let's say",
    "start": "1032240",
    "end": "1035038"
  },
  {
    "text": "the cluster deployed with Kao enable all",
    "start": "1035039",
    "end": "1037640"
  },
  {
    "text": "you have to do is just and there are",
    "start": "1037640",
    "end": "1039199"
  },
  {
    "text": "presets available for all the models",
    "start": "1039199",
    "end": "1040760"
  },
  {
    "text": "that supports you write this yaml you",
    "start": "1040760",
    "end": "1043798"
  },
  {
    "text": "you know do an KFC apply to the cluster",
    "start": "1043799",
    "end": "1046959"
  },
  {
    "text": "and once it applied it'll give you and",
    "start": "1046959",
    "end": "1049320"
  },
  {
    "text": "uh endpoint right which you can now talk",
    "start": "1049320",
    "end": "1051000"
  },
  {
    "text": "to the model so it's just a workspace",
    "start": "1051000",
    "end": "1052600"
  },
  {
    "text": "id/ chat uh you again write one more yl",
    "start": "1052600",
    "end": "1056480"
  },
  {
    "text": "for for your uh this AI service now to",
    "start": "1056480",
    "end": "1059160"
  },
  {
    "text": "talk to uh this cluster once you do that",
    "start": "1059160",
    "end": "1062160"
  },
  {
    "text": "uh you know once you create",
    "start": "1062160",
    "end": "1065440"
  },
  {
    "text": "this and do a KFC apply you'll see this",
    "start": "1065440",
    "end": "1068559"
  },
  {
    "text": "AI service on your on cluster will spin",
    "start": "1068559",
    "end": "1071080"
  },
  {
    "text": "up uh",
    "start": "1071080",
    "end": "1073600"
  },
  {
    "text": "and then finally you'll see your model",
    "start": "1073600",
    "end": "1077000"
  },
  {
    "text": "endpoint being generated right uh yeah",
    "start": "1077000",
    "end": "1081960"
  },
  {
    "text": "so uh yeah I think uh you can actually",
    "start": "1083320",
    "end": "1086840"
  },
  {
    "text": "go to this resources the GitHub repo and",
    "start": "1086840",
    "end": "1088720"
  },
  {
    "text": "there's a video tutorial of entire",
    "start": "1088720",
    "end": "1090600"
  },
  {
    "text": "deployment and inference the slides are",
    "start": "1090600",
    "end": "1092960"
  },
  {
    "text": "here the links are available for you to",
    "start": "1092960",
    "end": "1094520"
  },
  {
    "text": "quickly uh go through the documentation",
    "start": "1094520",
    "end": "1097440"
  },
  {
    "text": "the workshop and the video tutorial for",
    "start": "1097440",
    "end": "1099039"
  },
  {
    "text": "you to go through understand how kakito",
    "start": "1099039",
    "end": "1101440"
  },
  {
    "text": "Works how you can access or how you can",
    "start": "1101440",
    "end": "1103640"
  },
  {
    "text": "use it on with your infra to deploy this",
    "start": "1103640",
    "end": "1105480"
  },
  {
    "text": "model site just to summarize the entire",
    "start": "1105480",
    "end": "1108280"
  },
  {
    "text": "uh AG today so we had Kos which can",
    "start": "1108280",
    "end": "1111679"
  },
  {
    "text": "streamline your overall ml deployments",
    "start": "1111679",
    "end": "1114679"
  },
  {
    "text": "with custom crds uh it's an it provides",
    "start": "1114679",
    "end": "1117679"
  },
  {
    "text": "an efficient workflow to quickly deploy",
    "start": "1117679",
    "end": "1119360"
  },
  {
    "text": "and host your models and it does hold",
    "start": "1119360",
    "end": "1121919"
  },
  {
    "text": "your uh",
    "start": "1121919",
    "end": "1123120"
  },
  {
    "text": "GPU uh provisioning and and in uh",
    "start": "1123120",
    "end": "1126559"
  },
  {
    "text": "influencing like automated way I think",
    "start": "1126559",
    "end": "1128320"
  },
  {
    "text": "that's all U thank you uh thank you",
    "start": "1128320",
    "end": "1131600"
  },
  {
    "text": "everyone thank you again U and I think",
    "start": "1131600",
    "end": "1133760"
  },
  {
    "text": "any questions we can take yeah",
    "start": "1133760",
    "end": "1136480"
  },
  {
    "text": "[Applause]",
    "start": "1136480",
    "end": "1144099"
  },
  {
    "text": "hi I",
    "start": "1155039",
    "end": "1158240"
  },
  {
    "text": "can one to free yeah uh uh",
    "start": "1167280",
    "end": "1171440"
  },
  {
    "text": "so uh my question is uh let's consider I",
    "start": "1171440",
    "end": "1175240"
  },
  {
    "text": "have my fine-tuned llama with my own",
    "start": "1175240",
    "end": "1177600"
  },
  {
    "text": "like my own F Lama how can I deploy it",
    "start": "1177600",
    "end": "1180640"
  },
  {
    "text": "uh using uh K what steps should I do so",
    "start": "1180640",
    "end": "1184840"
  },
  {
    "text": "uh if you go to the GitHub right there",
    "start": "1184840",
    "end": "1187520"
  },
  {
    "text": "so all you have to do is in the sour in",
    "start": "1187520",
    "end": "1189840"
  },
  {
    "text": "the in the yamama configuration I'll",
    "start": "1189840",
    "end": "1191960"
  },
  {
    "text": "show you right uh",
    "start": "1191960",
    "end": "1196279"
  },
  {
    "text": "so all you do is uh I",
    "start": "1206480",
    "end": "1210200"
  },
  {
    "text": "think uh so you have to create that",
    "start": "1214960",
    "end": "1217080"
  },
  {
    "text": "Docker container uh which links to your",
    "start": "1217080",
    "end": "1219880"
  },
  {
    "text": "talks to so right now this talks to",
    "start": "1219880",
    "end": "1221919"
  },
  {
    "text": "that's hugging pH hostel models right",
    "start": "1221919",
    "end": "1223400"
  },
  {
    "text": "instead of you just point it to your",
    "start": "1223400",
    "end": "1225120"
  },
  {
    "text": "models and then once you deploy it it",
    "start": "1225120",
    "end": "1227320"
  },
  {
    "text": "pulls your model from there and Spins up",
    "start": "1227320",
    "end": "1228799"
  },
  {
    "text": "and gives to the end",
    "start": "1228799",
    "end": "1230679"
  },
  {
    "text": "point okay thank",
    "start": "1230679",
    "end": "1233240"
  },
  {
    "text": "you",
    "start": "1233240",
    "end": "1236240"
  },
  {
    "text": "yeah hi um yeah actually I have a",
    "start": "1238159",
    "end": "1241360"
  },
  {
    "text": "question does it support on Prem",
    "start": "1241360",
    "end": "1242880"
  },
  {
    "text": "clusters as well as on Prem cloud like",
    "start": "1242880",
    "end": "1245320"
  },
  {
    "text": "something like open stack instead of",
    "start": "1245320",
    "end": "1247320"
  },
  {
    "text": "right now it only supports AKs uh but I",
    "start": "1247320",
    "end": "1250360"
  },
  {
    "text": "think the road map is that uh it like to",
    "start": "1250360",
    "end": "1253159"
  },
  {
    "text": "make it sure that it it is cloud",
    "start": "1253159",
    "end": "1254760"
  },
  {
    "text": "agnostic and it it runs everywhere okay",
    "start": "1254760",
    "end": "1257600"
  },
  {
    "text": "and uh this is going to going to be soon",
    "start": "1257600",
    "end": "1259360"
  },
  {
    "text": "or I think I I spoke to some of the code",
    "start": "1259360",
    "end": "1262159"
  },
  {
    "text": "developers I think it is soon uh and an",
    "start": "1262159",
    "end": "1264400"
  },
  {
    "text": "on Prem should also work yeah because",
    "start": "1264400",
    "end": "1266919"
  },
  {
    "text": "right now what it does is the node",
    "start": "1266919",
    "end": "1268640"
  },
  {
    "text": "provisioner is only configured to talk",
    "start": "1268640",
    "end": "1270799"
  },
  {
    "text": "to AKs right you just or if you want you",
    "start": "1270799",
    "end": "1272480"
  },
  {
    "text": "can just extend it and make make sure",
    "start": "1272480",
    "end": "1274240"
  },
  {
    "text": "you know you create that adapter which",
    "start": "1274240",
    "end": "1276039"
  },
  {
    "text": "can talk to your own Prem or like other",
    "start": "1276039",
    "end": "1278640"
  },
  {
    "text": "cods okay thank you thank",
    "start": "1278640",
    "end": "1282440"
  },
  {
    "text": "you do we have time",
    "start": "1283080",
    "end": "1287519"
  },
  {
    "text": "uh for the model for pro model storage",
    "start": "1293120",
    "end": "1296120"
  },
  {
    "text": "or like a uh where do you store the",
    "start": "1296120",
    "end": "1297760"
  },
  {
    "text": "model sorry where do you store the model",
    "start": "1297760",
    "end": "1301120"
  },
  {
    "text": "the models uh storage as in uh there a",
    "start": "1301120",
    "end": "1304360"
  },
  {
    "text": "public models these are pulled from the",
    "start": "1304360",
    "end": "1305760"
  },
  {
    "text": "hugging page depository right so",
    "start": "1305760",
    "end": "1307960"
  },
  {
    "text": "downloading that model will take a long",
    "start": "1307960",
    "end": "1309559"
  },
  {
    "text": "time right how do you",
    "start": "1309559",
    "end": "1312520"
  },
  {
    "text": "um yeah how do you like uh are you like",
    "start": "1312520",
    "end": "1315720"
  },
  {
    "text": "downloading the hundreds of G let's for",
    "start": "1315720",
    "end": "1318960"
  },
  {
    "text": "are used right so you can create or",
    "start": "1318960",
    "end": "1320840"
  },
  {
    "text": "download those models make make those",
    "start": "1320840",
    "end": "1322559"
  },
  {
    "text": "available in the container itself yes",
    "start": "1322559",
    "end": "1324960"
  },
  {
    "text": "the container becomes a bit large but",
    "start": "1324960",
    "end": "1326840"
  },
  {
    "text": "since uh it is also let's say on your uh",
    "start": "1326840",
    "end": "1330279"
  },
  {
    "text": "like repository right so instead of",
    "start": "1330279",
    "end": "1331960"
  },
  {
    "text": "downloading the container uh model and",
    "start": "1331960",
    "end": "1333919"
  },
  {
    "text": "building the container you just quickly",
    "start": "1333919",
    "end": "1335400"
  },
  {
    "text": "you package everything all together into",
    "start": "1335400",
    "end": "1337360"
  },
  {
    "text": "a current container and ship that so you",
    "start": "1337360",
    "end": "1339400"
  },
  {
    "text": "put the model into the Container image",
    "start": "1339400",
    "end": "1341480"
  },
  {
    "text": "yeah so that will be like 100 Gig like",
    "start": "1341480",
    "end": "1345039"
  },
  {
    "text": "image",
    "start": "1345039",
    "end": "1346720"
  },
  {
    "text": "yes so pulling that image will take a",
    "start": "1346720",
    "end": "1349360"
  },
  {
    "text": "long time also right or like you catch",
    "start": "1349360",
    "end": "1351400"
  },
  {
    "text": "on the Note like you can catch that",
    "start": "1351400",
    "end": "1354960"
  },
  {
    "text": "okay thank",
    "start": "1354960",
    "end": "1358120"
  },
  {
    "text": "you",
    "start": "1358240",
    "end": "1359799"
  },
  {
    "text": "okay thank",
    "start": "1359799",
    "end": "1363559"
  }
]
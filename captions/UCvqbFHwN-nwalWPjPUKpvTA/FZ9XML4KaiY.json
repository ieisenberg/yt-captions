[
  {
    "text": "hi everyone my name is Richard I am a",
    "start": "399",
    "end": "3159"
  },
  {
    "text": "senior software engineer at Google cloud",
    "start": "3159",
    "end": "5680"
  },
  {
    "text": "and today I'm excited to talk to you",
    "start": "5680",
    "end": "7560"
  },
  {
    "text": "about how you can accelerate your gen",
    "start": "7560",
    "end": "9679"
  },
  {
    "text": "model inference with Ray and",
    "start": "9679",
    "end": "13240"
  },
  {
    "text": "kubernetes over the past year we're",
    "start": "13240",
    "end": "15679"
  },
  {
    "text": "seeing a lot of growth in large models",
    "start": "15679",
    "end": "18240"
  },
  {
    "text": "in the field of uh generative Ai and",
    "start": "18240",
    "end": "20760"
  },
  {
    "text": "this has enabled organizations to apply",
    "start": "20760",
    "end": "24920"
  },
  {
    "text": "Ai and solve problems that they weren't",
    "start": "24920",
    "end": "28000"
  },
  {
    "text": "able to solve before",
    "start": "28000",
    "end": "31400"
  },
  {
    "text": "and this in turn is uh driving larger",
    "start": "31400",
    "end": "34000"
  },
  {
    "text": "and lar larger models and over the past",
    "start": "34000",
    "end": "36640"
  },
  {
    "text": "few years we're seeing orders of",
    "start": "36640",
    "end": "38600"
  },
  {
    "text": "magnitude growth in the size of these",
    "start": "38600",
    "end": "41440"
  },
  {
    "text": "models uh so this uh basically means",
    "start": "41440",
    "end": "44600"
  },
  {
    "text": "that the organizations have to adopt",
    "start": "44600",
    "end": "47280"
  },
  {
    "text": "technologies that allows them to serve",
    "start": "47280",
    "end": "49640"
  },
  {
    "text": "models in a performant and um coste",
    "start": "49640",
    "end": "53480"
  },
  {
    "text": "effective",
    "start": "53480",
    "end": "54640"
  },
  {
    "text": "manner so uh Google has been an industry",
    "start": "54640",
    "end": "59320"
  },
  {
    "text": "leader in the field of AI and uh with",
    "start": "59320",
    "end": "62480"
  },
  {
    "text": "products like Maps search YouTube Etc",
    "start": "62480",
    "end": "66720"
  },
  {
    "text": "there are a lot of large models running",
    "start": "66720",
    "end": "68920"
  },
  {
    "text": "underneath these services so over the",
    "start": "68920",
    "end": "72240"
  },
  {
    "text": "past uh decades Google has uh built a",
    "start": "72240",
    "end": "76320"
  },
  {
    "text": "lot of uh specialized Hardware uh",
    "start": "76320",
    "end": "79360"
  },
  {
    "text": "specifically tatered for machine",
    "start": "79360",
    "end": "81680"
  },
  {
    "text": "learning",
    "start": "81680",
    "end": "82680"
  },
  {
    "text": "applications uh now one of these is uh",
    "start": "82680",
    "end": "86119"
  },
  {
    "text": "tensor processing units which is uh tpus",
    "start": "86119",
    "end": "90119"
  },
  {
    "text": "we recently introduced a V5 of tpus",
    "start": "90119",
    "end": "93720"
  },
  {
    "text": "which is the latest generations of tpus",
    "start": "93720",
    "end": "96960"
  },
  {
    "text": "and in doing so we want to um allow our",
    "start": "96960",
    "end": "99680"
  },
  {
    "text": "customers to have the same access to the",
    "start": "99680",
    "end": "103439"
  },
  {
    "text": "transformative technologies that has",
    "start": "103439",
    "end": "105920"
  },
  {
    "text": "enabled Google in its uh products and",
    "start": "105920",
    "end": "109479"
  },
  {
    "text": "services so the two main benefits of",
    "start": "109479",
    "end": "112960"
  },
  {
    "text": "tpus are efficiency and",
    "start": "112960",
    "end": "117159"
  },
  {
    "text": "scalability so let's like take a look at",
    "start": "117159",
    "end": "120159"
  },
  {
    "text": "the efficiency uh in this graph we're",
    "start": "120159",
    "end": "124079"
  },
  {
    "text": "comparing the V5 tpus with their",
    "start": "124079",
    "end": "127119"
  },
  {
    "text": "previous generation the V4 tpus and over",
    "start": "127119",
    "end": "130679"
  },
  {
    "text": "the horizontal axis we're seeing how the",
    "start": "130679",
    "end": "134360"
  },
  {
    "text": "V5 tpus perform on various uh generative",
    "start": "134360",
    "end": "139040"
  },
  {
    "text": "AI models and in the hor in the vertical",
    "start": "139040",
    "end": "142519"
  },
  {
    "text": "axis we're seeing the U relative",
    "start": "142519",
    "end": "145400"
  },
  {
    "text": "inference performance per dollar so as",
    "start": "145400",
    "end": "148000"
  },
  {
    "text": "you can see uh over the range of these",
    "start": "148000",
    "end": "150360"
  },
  {
    "text": "models the v5s tpus are demonstrating up",
    "start": "150360",
    "end": "154280"
  },
  {
    "text": "to 2.5 times more throughput per dollar",
    "start": "154280",
    "end": "157440"
  },
  {
    "text": "for generative AI",
    "start": "157440",
    "end": "160440"
  },
  {
    "text": "model next we're going to look at",
    "start": "161440",
    "end": "164080"
  },
  {
    "text": "scalability as a main benefit uh tpus",
    "start": "164080",
    "end": "167840"
  },
  {
    "text": "have a special",
    "start": "167840",
    "end": "169879"
  },
  {
    "text": "topology and as well as a high bandwidth",
    "start": "169879",
    "end": "173560"
  },
  {
    "text": "memory which allows them to work either",
    "start": "173560",
    "end": "176640"
  },
  {
    "text": "in unison or in combination with other",
    "start": "176640",
    "end": "179480"
  },
  {
    "text": "TP",
    "start": "179480",
    "end": "180480"
  },
  {
    "text": "sizes uh so in this table we're",
    "start": "180480",
    "end": "183080"
  },
  {
    "text": "demonstrating how this uh relates to uh",
    "start": "183080",
    "end": "186560"
  },
  {
    "text": "how it serves the different kinds of",
    "start": "186560",
    "end": "189599"
  },
  {
    "text": "models um you can see that U with a one",
    "start": "189599",
    "end": "192959"
  },
  {
    "text": "V5 dpu chip you can serve a 13 billion",
    "start": "192959",
    "end": "198799"
  },
  {
    "text": "llama 2 model uh however you can scale",
    "start": "198799",
    "end": "202280"
  },
  {
    "text": "that up you can scale up to 256 chips",
    "start": "202280",
    "end": "206560"
  },
  {
    "text": "which allows you to serve up to uh two",
    "start": "206560",
    "end": "210120"
  },
  {
    "text": "parameter",
    "start": "210120",
    "end": "212080"
  },
  {
    "text": "models um in addition uh multi slice",
    "start": "212080",
    "end": "215439"
  },
  {
    "text": "technology allows near linear scaling",
    "start": "215439",
    "end": "218799"
  },
  {
    "text": "with these models so you can uh really",
    "start": "218799",
    "end": "221959"
  },
  {
    "text": "utilize tpus to serve your your largest",
    "start": "221959",
    "end": "225879"
  },
  {
    "text": "generative AI",
    "start": "225879",
    "end": "228680"
  },
  {
    "text": "models so now let's shift giv us a",
    "start": "228879",
    "end": "231239"
  },
  {
    "text": "little bit um at the hardware ler we",
    "start": "231239",
    "end": "234159"
  },
  {
    "text": "have seen how tpus can optimize your",
    "start": "234159",
    "end": "236680"
  },
  {
    "text": "inference performance but what about the",
    "start": "236680",
    "end": "239760"
  },
  {
    "text": "application layer so uh distributed",
    "start": "239760",
    "end": "243799"
  },
  {
    "text": "computing is needed across various",
    "start": "243799",
    "end": "246280"
  },
  {
    "text": "stages of ML and add uh each stage of",
    "start": "246280",
    "end": "250079"
  },
  {
    "text": "your ml pipeline like for training model",
    "start": "250079",
    "end": "252959"
  },
  {
    "text": "serving and so",
    "start": "252959",
    "end": "254799"
  },
  {
    "text": "on and over the years each stage and",
    "start": "254799",
    "end": "257840"
  },
  {
    "text": "level is uh creating its own distributed",
    "start": "257840",
    "end": "260400"
  },
  {
    "text": "computing solution so you have a",
    "start": "260400",
    "end": "262600"
  },
  {
    "text": "different uh technical stack for for",
    "start": "262600",
    "end": "265080"
  },
  {
    "text": "training for serving Etc and this adds a",
    "start": "265080",
    "end": "268880"
  },
  {
    "text": "further complex cities into the",
    "start": "268880",
    "end": "271280"
  },
  {
    "text": "ecosystem now ENT Ray so Ray is an OSS",
    "start": "271280",
    "end": "276720"
  },
  {
    "text": "platform that's a universal distributed",
    "start": "276720",
    "end": "279800"
  },
  {
    "text": "computational framework across various",
    "start": "279800",
    "end": "282160"
  },
  {
    "text": "stages of",
    "start": "282160",
    "end": "283520"
  },
  {
    "text": "ML and R is really great at scaling it",
    "start": "283520",
    "end": "287000"
  },
  {
    "text": "allows you to scale from a single",
    "start": "287000",
    "end": "288520"
  },
  {
    "text": "machine to a multi node cluster with",
    "start": "288520",
    "end": "290919"
  },
  {
    "text": "minimal code changes and uh the ray AI",
    "start": "290919",
    "end": "294639"
  },
  {
    "text": "runtime library is specifically designed",
    "start": "294639",
    "end": "297720"
  },
  {
    "text": "for ML applications and supports uh uh",
    "start": "297720",
    "end": "302240"
  },
  {
    "text": "specialized libraries specifically for",
    "start": "302240",
    "end": "304720"
  },
  {
    "text": "training model serving uh reinfor",
    "start": "304720",
    "end": "307960"
  },
  {
    "text": "reinforcement learning hyperparameter",
    "start": "307960",
    "end": "310160"
  },
  {
    "text": "search and so",
    "start": "310160",
    "end": "312759"
  },
  {
    "text": "on so let's take a look inside a ray",
    "start": "312759",
    "end": "316479"
  },
  {
    "text": "cluster a ray cluster is an abstraction",
    "start": "316479",
    "end": "320280"
  },
  {
    "text": "it allows you to scale workflows to",
    "start": "320280",
    "end": "323039"
  },
  {
    "text": "multiple workers and",
    "start": "323039",
    "end": "325080"
  },
  {
    "text": "devices a cluster consists of a single",
    "start": "325080",
    "end": "328039"
  },
  {
    "text": "head node uh",
    "start": "328039",
    "end": "330000"
  },
  {
    "text": "as well as a number of worker notes Ray",
    "start": "330000",
    "end": "333440"
  },
  {
    "text": "supports Auto scaling so um if the head",
    "start": "333440",
    "end": "337800"
  },
  {
    "text": "node uh if if needed the head node will",
    "start": "337800",
    "end": "341600"
  },
  {
    "text": "launch more workers as required by the",
    "start": "341600",
    "end": "345440"
  },
  {
    "text": "workload uh you can create a rid cluster",
    "start": "345440",
    "end": "348080"
  },
  {
    "text": "either locally uh just on your laptop or",
    "start": "348080",
    "end": "351520"
  },
  {
    "text": "remotely on a distributed cluster so",
    "start": "351520",
    "end": "354960"
  },
  {
    "text": "this allows uh you to scale an",
    "start": "354960",
    "end": "358160"
  },
  {
    "text": "application um across various uh",
    "start": "358160",
    "end": "361479"
  },
  {
    "text": "Hardware",
    "start": "361479",
    "end": "363960"
  },
  {
    "text": "platforms uh let's take a look at how R",
    "start": "364120",
    "end": "367240"
  },
  {
    "text": "handles a ray uh handles a model",
    "start": "367240",
    "end": "370560"
  },
  {
    "text": "inference so here we have a snpp of a",
    "start": "370560",
    "end": "373039"
  },
  {
    "text": "code that's a very simple Ray serve",
    "start": "373039",
    "end": "376479"
  },
  {
    "text": "deployment uh Step One is uh you define",
    "start": "376479",
    "end": "379800"
  },
  {
    "text": "this uh inference class uh this is just",
    "start": "379800",
    "end": "383560"
  },
  {
    "text": "a a a python class that wraps around",
    "start": "383560",
    "end": "385919"
  },
  {
    "text": "your model um we can define an nit",
    "start": "385919",
    "end": "389720"
  },
  {
    "text": "method which uh initializes the model",
    "start": "389720",
    "end": "392560"
  },
  {
    "text": "State uh so obviously in real world",
    "start": "392560",
    "end": "396360"
  },
  {
    "text": "scenarios uh this could be a very large",
    "start": "396360",
    "end": "398639"
  },
  {
    "text": "neural",
    "start": "398639",
    "end": "399840"
  },
  {
    "text": "network and then um you define this uh",
    "start": "399840",
    "end": "403319"
  },
  {
    "text": "call method which uh returns an",
    "start": "403319",
    "end": "405720"
  },
  {
    "text": "inference result uh based on the",
    "start": "405720",
    "end": "409680"
  },
  {
    "text": "request so second step is that you uh",
    "start": "409680",
    "end": "413280"
  },
  {
    "text": "deploy this uh this model to your ray",
    "start": "413280",
    "end": "415440"
  },
  {
    "text": "cluster and this can be done in a single",
    "start": "415440",
    "end": "417919"
  },
  {
    "text": "line um",
    "start": "417919",
    "end": "419919"
  },
  {
    "text": "you bind your model and uh you send it",
    "start": "419919",
    "end": "421960"
  },
  {
    "text": "to to the ray serve library and uh under",
    "start": "421960",
    "end": "425080"
  },
  {
    "text": "the hood this schedules a rate actors",
    "start": "425080",
    "end": "427560"
  },
  {
    "text": "and task that's required to uh bring out",
    "start": "427560",
    "end": "430280"
  },
  {
    "text": "the model and allows it to serve HTTP",
    "start": "430280",
    "end": "433400"
  },
  {
    "text": "requests and opening up the",
    "start": "433400",
    "end": "436039"
  },
  {
    "text": "port uh the third step is actually",
    "start": "436039",
    "end": "438599"
  },
  {
    "text": "quering the deployment and uh fetching",
    "start": "438599",
    "end": "440720"
  },
  {
    "text": "back the",
    "start": "440720",
    "end": "443479"
  },
  {
    "text": "result so why is reserve good for",
    "start": "444039",
    "end": "448199"
  },
  {
    "text": "generative AI",
    "start": "448199",
    "end": "450080"
  },
  {
    "text": "uh first of all it is a framework",
    "start": "450080",
    "end": "452639"
  },
  {
    "text": "agnostic inference library in Python uh",
    "start": "452639",
    "end": "456120"
  },
  {
    "text": "it has a rich pythonic uh experience and",
    "start": "456120",
    "end": "460080"
  },
  {
    "text": "it supports any popular deep learning n",
    "start": "460080",
    "end": "463360"
  },
  {
    "text": "uh framework such as pytorch tensor flow",
    "start": "463360",
    "end": "466639"
  },
  {
    "text": "Psy learn huging phase",
    "start": "466639",
    "end": "469680"
  },
  {
    "text": "Etc and um a great advantage of using",
    "start": "469680",
    "end": "473000"
  },
  {
    "text": "race serve is um is good for model",
    "start": "473000",
    "end": "477360"
  },
  {
    "text": "composition so when we think of ml",
    "start": "477360",
    "end": "479879"
  },
  {
    "text": "models uh we don't really deploy models",
    "start": "479879",
    "end": "484120"
  },
  {
    "text": "in isolation so the models need to",
    "start": "484120",
    "end": "486919"
  },
  {
    "text": "interact with the greater um ecosystem",
    "start": "486919",
    "end": "490440"
  },
  {
    "text": "in order to be useful so this could be",
    "start": "490440",
    "end": "493479"
  },
  {
    "text": "um other models this could be business",
    "start": "493479",
    "end": "496039"
  },
  {
    "text": "logic this could be some database right",
    "start": "496039",
    "end": "499319"
  },
  {
    "text": "so you need um some way to integrate",
    "start": "499319",
    "end": "502639"
  },
  {
    "text": "your models with your uh business uh",
    "start": "502639",
    "end": "508319"
  },
  {
    "text": "ecosystem",
    "start": "508319",
    "end": "509840"
  },
  {
    "text": "and um race serve allows you to build",
    "start": "509840",
    "end": "512320"
  },
  {
    "text": "complex inference service with multiple",
    "start": "512320",
    "end": "514760"
  },
  {
    "text": "models with great e and allows U you to",
    "start": "514760",
    "end": "519240"
  },
  {
    "text": "uh compose models together um and",
    "start": "519240",
    "end": "522320"
  },
  {
    "text": "handles a complex scenario such as the",
    "start": "522320",
    "end": "525640"
  },
  {
    "text": "different model versioning and different",
    "start": "525640",
    "end": "529040"
  },
  {
    "text": "uh deployment",
    "start": "529040",
    "end": "530880"
  },
  {
    "text": "graphs um it is built on top of Ray so",
    "start": "530880",
    "end": "534160"
  },
  {
    "text": "it is very easily scalable so your serve",
    "start": "534160",
    "end": "538120"
  },
  {
    "text": "instance can",
    "start": "538120",
    "end": "540040"
  },
  {
    "text": "um you can scale up uh",
    "start": "540040",
    "end": "543120"
  },
  {
    "text": "replicas according to the request load",
    "start": "543120",
    "end": "546320"
  },
  {
    "text": "so all this makes uh race serve a great",
    "start": "546320",
    "end": "549720"
  },
  {
    "text": "choice for serving generative AI",
    "start": "549720",
    "end": "554399"
  },
  {
    "text": "models so let's take a minute to put it",
    "start": "557959",
    "end": "560680"
  },
  {
    "text": "all together uh at a hardware layer we",
    "start": "560680",
    "end": "563920"
  },
  {
    "text": "have seen how tpus can optimize uh the",
    "start": "563920",
    "end": "566880"
  },
  {
    "text": "performance of your models and add a",
    "start": "566880",
    "end": "568959"
  },
  {
    "text": "very efficient cost um in addition tpus",
    "start": "568959",
    "end": "572480"
  },
  {
    "text": "are also very",
    "start": "572480",
    "end": "574880"
  },
  {
    "text": "scalable um on the other end uh for the",
    "start": "574880",
    "end": "577880"
  },
  {
    "text": "application layer we look at how Ray can",
    "start": "577880",
    "end": "580720"
  },
  {
    "text": "simplify building and deploying AI",
    "start": "580720",
    "end": "583079"
  },
  {
    "text": "workloads so Ray has a really simple",
    "start": "583079",
    "end": "586240"
  },
  {
    "text": "pythonic uh interface uh that is well",
    "start": "586240",
    "end": "589279"
  },
  {
    "text": "integrated with u a rich ecosystem with",
    "start": "589279",
    "end": "593000"
  },
  {
    "text": "a Frameworks like tensorflow pytorch",
    "start": "593000",
    "end": "596000"
  },
  {
    "text": "hogging phase Etc and this allows you to",
    "start": "596000",
    "end": "598720"
  },
  {
    "text": "easily distribute your AI application to",
    "start": "598720",
    "end": "602440"
  },
  {
    "text": "a distributed cluster and uh because of",
    "start": "602440",
    "end": "605279"
  },
  {
    "text": "this simple interface you can deploy an",
    "start": "605279",
    "end": "608320"
  },
  {
    "text": "application from your laptop to a",
    "start": "608320",
    "end": "610880"
  },
  {
    "text": "cluster with a very little changes to",
    "start": "610880",
    "end": "612880"
  },
  {
    "text": "your",
    "start": "612880",
    "end": "614000"
  },
  {
    "text": "code uh Ray also supports Autos scaling",
    "start": "614000",
    "end": "617320"
  },
  {
    "text": "which uh abstracts away the underlying",
    "start": "617320",
    "end": "619600"
  },
  {
    "text": "resources and this really allows the ml",
    "start": "619600",
    "end": "622600"
  },
  {
    "text": "engineer to focus on developing the a AI",
    "start": "622600",
    "end": "626560"
  },
  {
    "text": "application um instead of worrying about",
    "start": "626560",
    "end": "629279"
  },
  {
    "text": "um how they orchestrate",
    "start": "629279",
    "end": "631040"
  },
  {
    "text": "resources and specifically Ray has AI",
    "start": "631040",
    "end": "635200"
  },
  {
    "text": "runtime which uh contains a number of uh",
    "start": "635200",
    "end": "638079"
  },
  {
    "text": "application and libraries including race",
    "start": "638079",
    "end": "640160"
  },
  {
    "text": "serve uh which uh supports uh features",
    "start": "640160",
    "end": "643240"
  },
  {
    "text": "such as automatically building uh",
    "start": "643240",
    "end": "645320"
  },
  {
    "text": "inference",
    "start": "645320",
    "end": "646519"
  },
  {
    "text": "graphs so all of this makes Ray an ideal",
    "start": "646519",
    "end": "650600"
  },
  {
    "text": "platform for uh ml Engineers to develop",
    "start": "650600",
    "end": "654279"
  },
  {
    "text": "their",
    "start": "654279",
    "end": "655639"
  },
  {
    "text": "applications but you need something to",
    "start": "655639",
    "end": "659040"
  },
  {
    "text": "tie the two together so what about",
    "start": "659040",
    "end": "662720"
  },
  {
    "text": "problems like uh managing uh resource",
    "start": "662720",
    "end": "666320"
  },
  {
    "text": "life cycles orchestrating resources or",
    "start": "666320",
    "end": "669760"
  },
  {
    "text": "what about the production uh level",
    "start": "669760",
    "end": "672160"
  },
  {
    "text": "problems like security monitoring",
    "start": "672160",
    "end": "676320"
  },
  {
    "text": "observability so this is where",
    "start": "676320",
    "end": "678760"
  },
  {
    "text": "kubernetes comes in so kubernetes is a",
    "start": "678760",
    "end": "682560"
  },
  {
    "text": "great OSS uh platform that has a a very",
    "start": "682560",
    "end": "687600"
  },
  {
    "text": "uh eco uh system friendly and uh it's uh",
    "start": "687600",
    "end": "691560"
  },
  {
    "text": "very uh flexible and offers uh great",
    "start": "691560",
    "end": "693959"
  },
  {
    "text": "performance and scale it really allows",
    "start": "693959",
    "end": "697040"
  },
  {
    "text": "you to uh tie together the um",
    "start": "697040",
    "end": "699519"
  },
  {
    "text": "application side improvements of Ray",
    "start": "699519",
    "end": "701959"
  },
  {
    "text": "with the uh uh Hardware side performance",
    "start": "701959",
    "end": "704880"
  },
  {
    "text": "offered by",
    "start": "704880",
    "end": "706680"
  },
  {
    "text": "tpus and we're going to take a look at",
    "start": "706680",
    "end": "709760"
  },
  {
    "text": "how kubernetes makes all this",
    "start": "709760",
    "end": "713480"
  },
  {
    "text": "happen so now let's see how all this",
    "start": "715800",
    "end": "718360"
  },
  {
    "text": "works on kubernetes so since tpus are",
    "start": "718360",
    "end": "721920"
  },
  {
    "text": "special uh designed for machine learning",
    "start": "721920",
    "end": "725040"
  },
  {
    "text": "workloads uh they work a little",
    "start": "725040",
    "end": "726760"
  },
  {
    "text": "differently from traditional",
    "start": "726760",
    "end": "729040"
  },
  {
    "text": "gpus uh so if you have deployed GPU",
    "start": "729040",
    "end": "732959"
  },
  {
    "text": "workloads on kubernetes before you know",
    "start": "732959",
    "end": "735519"
  },
  {
    "text": "you can create a uh VM with the gpus",
    "start": "735519",
    "end": "739199"
  },
  {
    "text": "attached to them and then a kubernetes",
    "start": "739199",
    "end": "742000"
  },
  {
    "text": "pot would reserve some number of gpus on",
    "start": "742000",
    "end": "745680"
  },
  {
    "text": "that pod",
    "start": "745680",
    "end": "747639"
  },
  {
    "text": "so uh tpus are topology aware which",
    "start": "747639",
    "end": "751959"
  },
  {
    "text": "means that uh they have to be deployed",
    "start": "751959",
    "end": "754560"
  },
  {
    "text": "on uh node pools that are also topology",
    "start": "754560",
    "end": "757480"
  },
  {
    "text": "aware um in addition the notes must be",
    "start": "757480",
    "end": "760320"
  },
  {
    "text": "connected with the high bandwidth memory",
    "start": "760320",
    "end": "763000"
  },
  {
    "text": "which is what gives them that uh High uh",
    "start": "763000",
    "end": "766720"
  },
  {
    "text": "performance",
    "start": "766720",
    "end": "768240"
  },
  {
    "text": "throughput um so from the workow",
    "start": "768240",
    "end": "771680"
  },
  {
    "text": "perspective uh we deploy each kubernetes",
    "start": "771680",
    "end": "775760"
  },
  {
    "text": "part on the TPU node and the TPU nodes",
    "start": "775760",
    "end": "780000"
  },
  {
    "text": "contains a number of TPU chips um in",
    "start": "780000",
    "end": "783839"
  },
  {
    "text": "addition a workload had to be co-",
    "start": "783839",
    "end": "786120"
  },
  {
    "text": "scheduled together on the topology so",
    "start": "786120",
    "end": "788920"
  },
  {
    "text": "the work so that the workload is also",
    "start": "788920",
    "end": "791160"
  },
  {
    "text": "topology",
    "start": "791160",
    "end": "793120"
  },
  {
    "text": "aware so um to help all of this um",
    "start": "793120",
    "end": "797920"
  },
  {
    "text": "here's a diagram of how we can deploy",
    "start": "797920",
    "end": "801120"
  },
  {
    "text": "Ray on the tpus uh here we're showing",
    "start": "801120",
    "end": "804560"
  },
  {
    "text": "that the The Raid head is running on a",
    "start": "804560",
    "end": "806600"
  },
  {
    "text": "CPU VM and uh each R worker is running",
    "start": "806600",
    "end": "810399"
  },
  {
    "text": "on a TPU host and because of this uh",
    "start": "810399",
    "end": "814560"
  },
  {
    "text": "this is all part of the same topology",
    "start": "814560",
    "end": "817240"
  },
  {
    "text": "each uh worker in this uh cluster has to",
    "start": "817240",
    "end": "821160"
  },
  {
    "text": "be aware of where the other workers are",
    "start": "821160",
    "end": "825120"
  },
  {
    "text": "uh they had to be initialized with an",
    "start": "825120",
    "end": "827680"
  },
  {
    "text": "environment which uh contains metadata",
    "start": "827680",
    "end": "831519"
  },
  {
    "text": "about that topology so in this case uh",
    "start": "831519",
    "end": "834720"
  },
  {
    "text": "this is a four node topology uh with a",
    "start": "834720",
    "end": "838519"
  },
  {
    "text": "four four chips each uh so each worker",
    "start": "838519",
    "end": "841320"
  },
  {
    "text": "is initialized with one unique index",
    "start": "841320",
    "end": "844600"
  },
  {
    "text": "which identifies them uh in at topology",
    "start": "844600",
    "end": "847839"
  },
  {
    "text": "and uh they're also initialized with the",
    "start": "847839",
    "end": "850440"
  },
  {
    "text": "host names of um all the other workers",
    "start": "850440",
    "end": "853959"
  },
  {
    "text": "in this in the same",
    "start": "853959",
    "end": "857199"
  },
  {
    "text": "typology so to help all this uh happen",
    "start": "857720",
    "end": "861399"
  },
  {
    "text": "uh in kubernetes we uh make use of cubra",
    "start": "861399",
    "end": "865199"
  },
  {
    "text": "which is a open- source operator for or",
    "start": "865199",
    "end": "868720"
  },
  {
    "text": "orchestrating rate workflows on",
    "start": "868720",
    "end": "871320"
  },
  {
    "text": "kubernetes uh it is currently uh",
    "start": "871320",
    "end": "874040"
  },
  {
    "text": "developed by uh the community and U here",
    "start": "874040",
    "end": "877800"
  },
  {
    "text": "we are showing this uh snippet from uh a",
    "start": "877800",
    "end": "882480"
  },
  {
    "text": "cubr spec uh so uh cubra defines a",
    "start": "882480",
    "end": "887079"
  },
  {
    "text": "custom resource for uh representing Ray",
    "start": "887079",
    "end": "890720"
  },
  {
    "text": "crusters so in uh this part which uh",
    "start": "890720",
    "end": "894440"
  },
  {
    "text": "we're showing",
    "start": "894440",
    "end": "896079"
  },
  {
    "text": "the part of the spec for deploying a",
    "start": "896079",
    "end": "898839"
  },
  {
    "text": "rate worker so you can see that the word",
    "start": "898839",
    "end": "900720"
  },
  {
    "text": "rate worker is reserving four TPU VMS uh",
    "start": "900720",
    "end": "905160"
  },
  {
    "text": "four four tpus and um it's a the node",
    "start": "905160",
    "end": "910320"
  },
  {
    "text": "selector specifies that it should be",
    "start": "910320",
    "end": "912079"
  },
  {
    "text": "running on a specific topology as well",
    "start": "912079",
    "end": "914720"
  },
  {
    "text": "as a accelerator",
    "start": "914720",
    "end": "917839"
  },
  {
    "text": "type so now let's uh see how you can run",
    "start": "918480",
    "end": "921800"
  },
  {
    "text": "a TPU workloads so uh here we're showing",
    "start": "921800",
    "end": "925199"
  },
  {
    "text": "some uh snippet of the code for running",
    "start": "925199",
    "end": "928279"
  },
  {
    "text": "uh very simple TPU workload uh we start",
    "start": "928279",
    "end": "931680"
  },
  {
    "text": "by initializing the ray cluster and uh",
    "start": "931680",
    "end": "934639"
  },
  {
    "text": "we Define this uh function which uh by",
    "start": "934639",
    "end": "937839"
  },
  {
    "text": "adding this one line we indicate that",
    "start": "937839",
    "end": "940480"
  },
  {
    "text": "this is a remote function uh so each um",
    "start": "940480",
    "end": "945560"
  },
  {
    "text": "uh worker is going to reserve for tpus",
    "start": "945560",
    "end": "949199"
  },
  {
    "text": "and inside this function we import a Jax",
    "start": "949199",
    "end": "951240"
  },
  {
    "text": "library and we exercise some work code",
    "start": "951240",
    "end": "954519"
  },
  {
    "text": "and outside of this we send non-blocking",
    "start": "954519",
    "end": "957319"
  },
  {
    "text": "calls uh which uh ensure that the same",
    "start": "957319",
    "end": "960560"
  },
  {
    "text": "work is uh being run on all the workers",
    "start": "960560",
    "end": "963600"
  },
  {
    "text": "and this is how you the this is how the",
    "start": "963600",
    "end": "966399"
  },
  {
    "text": "multi uh controller programming model",
    "start": "966399",
    "end": "971399"
  },
  {
    "text": "work so now let's talk about how we can",
    "start": "972240",
    "end": "975240"
  },
  {
    "text": "operationalize all this right so let's",
    "start": "975240",
    "end": "977680"
  },
  {
    "text": "see if uh you're deploying this in your",
    "start": "977680",
    "end": "980759"
  },
  {
    "text": "production environment what kind of",
    "start": "980759",
    "end": "982800"
  },
  {
    "text": "problems uh might you run into well",
    "start": "982800",
    "end": "986680"
  },
  {
    "text": "first of all how do you deploy the these",
    "start": "986680",
    "end": "988680"
  },
  {
    "text": "clusters at scale how do you provision",
    "start": "988680",
    "end": "991240"
  },
  {
    "text": "them in a way that is uh",
    "start": "991240",
    "end": "994639"
  },
  {
    "text": "reproducible and second um how do you",
    "start": "994639",
    "end": "998279"
  },
  {
    "text": "protect your services from um outside",
    "start": "998279",
    "end": "1001920"
  },
  {
    "text": "access un authorized access and U",
    "start": "1001920",
    "end": "1005399"
  },
  {
    "text": "additionally how do you grant uh fine",
    "start": "1005399",
    "end": "1007560"
  },
  {
    "text": "grain access to members of your team",
    "start": "1007560",
    "end": "1011600"
  },
  {
    "text": "right um You may want to use a logging",
    "start": "1011600",
    "end": "1015880"
  },
  {
    "text": "to see what's going on with your jobs",
    "start": "1015880",
    "end": "1018079"
  },
  {
    "text": "and your actors and your",
    "start": "1018079",
    "end": "1020720"
  },
  {
    "text": "nodes uh if you are the system",
    "start": "1020720",
    "end": "1023280"
  },
  {
    "text": "administrator maybe you're interested in",
    "start": "1023280",
    "end": "1025720"
  },
  {
    "text": "metrics about the system from a workload",
    "start": "1025720",
    "end": "1028160"
  },
  {
    "text": "agnostic point of view like being able",
    "start": "1028160",
    "end": "1030400"
  },
  {
    "text": "to view your resource utilization across",
    "start": "1030400",
    "end": "1033558"
  },
  {
    "text": "the system right so for all of this you",
    "start": "1033559",
    "end": "1036600"
  },
  {
    "text": "may need to uh have a uh ready to",
    "start": "1036600",
    "end": "1040640"
  },
  {
    "text": "deployed Autobox integration with other",
    "start": "1040640",
    "end": "1043520"
  },
  {
    "text": "managed cloud services uh so we provided",
    "start": "1043520",
    "end": "1047558"
  },
  {
    "text": "this uh GitHub link uh you can download",
    "start": "1047559",
    "end": "1050280"
  },
  {
    "text": "this and this is a a solution template",
    "start": "1050280",
    "end": "1054559"
  },
  {
    "text": "for deploying Ray on gke so we have",
    "start": "1054559",
    "end": "1058679"
  },
  {
    "text": "included um outter boox integration with",
    "start": "1058679",
    "end": "1062160"
  },
  {
    "text": "the GPU and TPU crossers we' have",
    "start": "1062160",
    "end": "1065039"
  },
  {
    "text": "included a cuay operator for you to",
    "start": "1065039",
    "end": "1067640"
  },
  {
    "text": "orchestrate your rate workloads and",
    "start": "1067640",
    "end": "1070320"
  },
  {
    "text": "we've uh enabled some integration with I",
    "start": "1070320",
    "end": "1073320"
  },
  {
    "text": "AP uh Cloud loging and Prometheus",
    "start": "1073320",
    "end": "1076000"
  },
  {
    "text": "monitoring and in addition we've also",
    "start": "1076000",
    "end": "1078440"
  },
  {
    "text": "included the Jupiter notebook server",
    "start": "1078440",
    "end": "1080760"
  },
  {
    "text": "which enables you to interact with the",
    "start": "1080760",
    "end": "1082880"
  },
  {
    "text": "cluster uh for easy",
    "start": "1082880",
    "end": "1086720"
  },
  {
    "text": "prototyping so this brings us to our",
    "start": "1087640",
    "end": "1090320"
  },
  {
    "text": "first demo uh which is uh serving stable",
    "start": "1090320",
    "end": "1093000"
  },
  {
    "text": "diffusion with Jupiter on tpus so this",
    "start": "1093000",
    "end": "1096400"
  },
  {
    "text": "is using the uh solution template that",
    "start": "1096400",
    "end": "1099200"
  },
  {
    "text": "I've just talked about uh stable",
    "start": "1099200",
    "end": "1101360"
  },
  {
    "text": "diffusion is a text to image generative",
    "start": "1101360",
    "end": "1103480"
  },
  {
    "text": "model uh for this demo we'll be using U",
    "start": "1103480",
    "end": "1106840"
  },
  {
    "text": "stable diffusion v14",
    "start": "1106840",
    "end": "1109320"
  },
  {
    "text": "and U you can uh see the source of the",
    "start": "1109320",
    "end": "1112360"
  },
  {
    "text": "the model at the at the link and this",
    "start": "1112360",
    "end": "1115159"
  },
  {
    "text": "will be uh deployed on a kubernetes",
    "start": "1115159",
    "end": "1118240"
  },
  {
    "text": "cluster with a single Ray cluster uh",
    "start": "1118240",
    "end": "1121600"
  },
  {
    "text": "where the worker is deployed on a single",
    "start": "1121600",
    "end": "1123600"
  },
  {
    "text": "host dpu and in the same kubernetes",
    "start": "1123600",
    "end": "1127280"
  },
  {
    "text": "cluster we will have a Jupiter notebook",
    "start": "1127280",
    "end": "1129960"
  },
  {
    "text": "which enables you to uh to interact with",
    "start": "1129960",
    "end": "1133960"
  },
  {
    "text": "the the r cluster",
    "start": "1133960",
    "end": "1136640"
  },
  {
    "text": "easily so now that's see the",
    "start": "1136640",
    "end": "1140559"
  },
  {
    "text": "demo okay so now let's use terraform to",
    "start": "1140559",
    "end": "1143880"
  },
  {
    "text": "deploy the solution I have just talked",
    "start": "1143880",
    "end": "1145559"
  },
  {
    "text": "about so this will deploy a ray cluster",
    "start": "1145559",
    "end": "1149120"
  },
  {
    "text": "in gke and it will include a uh TPU",
    "start": "1149120",
    "end": "1152640"
  },
  {
    "text": "worker on a single",
    "start": "1152640",
    "end": "1154200"
  },
  {
    "text": "host uh as well as a Jupiter notebook uh",
    "start": "1154200",
    "end": "1157520"
  },
  {
    "text": "for us to interact with the the red",
    "start": "1157520",
    "end": "1160200"
  },
  {
    "text": "cluster uh so let's see how we're",
    "start": "1160200",
    "end": "1162960"
  },
  {
    "text": "doing so let's check the status of the",
    "start": "1162960",
    "end": "1165880"
  },
  {
    "text": "parts okay so you can see that the uh",
    "start": "1165880",
    "end": "1168840"
  },
  {
    "text": "this spun up a red cluster with a head",
    "start": "1168840",
    "end": "1172080"
  },
  {
    "text": "and a worker and the worker is deployed",
    "start": "1172080",
    "end": "1175159"
  },
  {
    "text": "on a single host",
    "start": "1175159",
    "end": "1178520"
  },
  {
    "text": "TPU and now let's get the serviceing",
    "start": "1178960",
    "end": "1181440"
  },
  {
    "text": "point for uh the jiter server that we're",
    "start": "1181440",
    "end": "1185200"
  },
  {
    "text": "going to use uh that's this IP",
    "start": "1185200",
    "end": "1190679"
  },
  {
    "text": "address first of all we're going to",
    "start": "1191480",
    "end": "1193440"
  },
  {
    "text": "install Ray in the Jupiter",
    "start": "1193440",
    "end": "1196960"
  },
  {
    "text": "notebook uh since distributor notebook",
    "start": "1196960",
    "end": "1199600"
  },
  {
    "text": "is deployed in the same kubernetes",
    "start": "1199600",
    "end": "1201440"
  },
  {
    "text": "cluster as the ray cluster we can just",
    "start": "1201440",
    "end": "1204720"
  },
  {
    "text": "use the uh Ray clusters uh kubernetes",
    "start": "1204720",
    "end": "1209440"
  },
  {
    "text": "cluster IP end point to talk to it so",
    "start": "1209440",
    "end": "1212000"
  },
  {
    "text": "this uh this means that we don't have to",
    "start": "1212000",
    "end": "1215320"
  },
  {
    "text": "expose the ray cluster endpoint to the",
    "start": "1215320",
    "end": "1217720"
  },
  {
    "text": "internet uh we're going to initialize",
    "start": "1217720",
    "end": "1220360"
  },
  {
    "text": "the ray cluster as well as install some",
    "start": "1220360",
    "end": "1222640"
  },
  {
    "text": "dependencies like the Jack TPU",
    "start": "1222640",
    "end": "1225520"
  },
  {
    "text": "Library as well as the Transformers",
    "start": "1225520",
    "end": "1230159"
  },
  {
    "text": "uh this is the Ingress class basically",
    "start": "1231200",
    "end": "1232880"
  },
  {
    "text": "this just uh tells Ray how to route your",
    "start": "1232880",
    "end": "1237640"
  },
  {
    "text": "request this next part is the actual",
    "start": "1240799",
    "end": "1243720"
  },
  {
    "text": "stable diffusion model and you can see",
    "start": "1243720",
    "end": "1245799"
  },
  {
    "text": "that uh we're specifying the resource",
    "start": "1245799",
    "end": "1247559"
  },
  {
    "text": "requirements on each replica which is 4",
    "start": "1247559",
    "end": "1251640"
  },
  {
    "text": "tpus so this will uh bind the actual",
    "start": "1251720",
    "end": "1255440"
  },
  {
    "text": "model and start the Ser",
    "start": "1255440",
    "end": "1257120"
  },
  {
    "text": "instance",
    "start": "1257120",
    "end": "1259559"
  },
  {
    "text": "so while this is running let's take a",
    "start": "1259559",
    "end": "1261280"
  },
  {
    "text": "look at the ray dashboard uh this",
    "start": "1261280",
    "end": "1263720"
  },
  {
    "text": "dashboard helps a look at the status of",
    "start": "1263720",
    "end": "1266080"
  },
  {
    "text": "each job uh you can check out the uh the",
    "start": "1266080",
    "end": "1269919"
  },
  {
    "text": "surf uh instance which has been",
    "start": "1269919",
    "end": "1273279"
  },
  {
    "text": "started uh you can also look at the",
    "start": "1273279",
    "end": "1275640"
  },
  {
    "text": "cluster States and uh look at each",
    "start": "1275640",
    "end": "1279400"
  },
  {
    "text": "actor and uh view metrics and",
    "start": "1279400",
    "end": "1284360"
  },
  {
    "text": "logs so our serve instance should be",
    "start": "1286000",
    "end": "1289600"
  },
  {
    "text": "started now we're going to send the HTP",
    "start": "1289600",
    "end": "1292360"
  },
  {
    "text": "request to the serve endpoint the serve",
    "start": "1292360",
    "end": "1294840"
  },
  {
    "text": "endpoint in this case is also using the",
    "start": "1294840",
    "end": "1297200"
  },
  {
    "text": "same kubernetes endpoint as before and",
    "start": "1297200",
    "end": "1300960"
  },
  {
    "text": "you can see that we are sending a list",
    "start": "1300960",
    "end": "1303720"
  },
  {
    "text": "of uh text",
    "start": "1303720",
    "end": "1306960"
  },
  {
    "text": "prompts now for the images that we're",
    "start": "1306960",
    "end": "1309080"
  },
  {
    "text": "going to",
    "start": "1309080",
    "end": "1311440"
  },
  {
    "text": "generate okay let's send the request and",
    "start": "1315880",
    "end": "1318760"
  },
  {
    "text": "wait for it to",
    "start": "1318760",
    "end": "1319460"
  },
  {
    "text": "[Music]",
    "start": "1319460",
    "end": "1322479"
  },
  {
    "text": "finish all right let's see how well we",
    "start": "1323360",
    "end": "1327840"
  },
  {
    "text": "did so these are the images that are",
    "start": "1328400",
    "end": "1331960"
  },
  {
    "text": "prompt",
    "start": "1331960",
    "end": "1334360"
  },
  {
    "text": "generated okay that looks pretty good",
    "start": "1345080",
    "end": "1349960"
  },
  {
    "text": "so we just saw how we can use Jupiter",
    "start": "1350760",
    "end": "1352760"
  },
  {
    "text": "notebooks to interact with our Ray",
    "start": "1352760",
    "end": "1354600"
  },
  {
    "text": "cluster now let's do something a little",
    "start": "1354600",
    "end": "1356679"
  },
  {
    "text": "different now we're going to deploy a",
    "start": "1356679",
    "end": "1359320"
  },
  {
    "text": "server and client architecture using",
    "start": "1359320",
    "end": "1361360"
  },
  {
    "text": "grpc grpc is a uh uh open source RPC",
    "start": "1361360",
    "end": "1366919"
  },
  {
    "text": "Library uh originally created by Google",
    "start": "1366919",
    "end": "1370000"
  },
  {
    "text": "and this uh we're going to also deploy",
    "start": "1370000",
    "end": "1373440"
  },
  {
    "text": "stable diffusion uh with the single head",
    "start": "1373440",
    "end": "1376640"
  },
  {
    "text": "and the worker uh this time just for",
    "start": "1376640",
    "end": "1379159"
  },
  {
    "text": "front we're going to deploy the model on",
    "start": "1379159",
    "end": "1382520"
  },
  {
    "text": "gpus instead of",
    "start": "1382520",
    "end": "1384240"
  },
  {
    "text": "tpus and for the server side uh this",
    "start": "1384240",
    "end": "1387080"
  },
  {
    "text": "will also be run on the r Crosser but",
    "start": "1387080",
    "end": "1389159"
  },
  {
    "text": "this time we'll use the a grpc server",
    "start": "1389159",
    "end": "1392400"
  },
  {
    "text": "endpoint in the race Ser deployment and",
    "start": "1392400",
    "end": "1395159"
  },
  {
    "text": "on the client side we'll use a python uh",
    "start": "1395159",
    "end": "1398200"
  },
  {
    "text": "client library to send grpc requests and",
    "start": "1398200",
    "end": "1401320"
  },
  {
    "text": "stream the response back and uh",
    "start": "1401320",
    "end": "1403799"
  },
  {
    "text": "hopefully this will work out great let's",
    "start": "1403799",
    "end": "1406039"
  },
  {
    "text": "take a",
    "start": "1406039",
    "end": "1406880"
  },
  {
    "text": "look",
    "start": "1406880",
    "end": "1409880"
  },
  {
    "text": "okay so for this demo Let's uh start by",
    "start": "1410679",
    "end": "1413279"
  },
  {
    "text": "defining the",
    "start": "1413279",
    "end": "1415360"
  },
  {
    "text": "protos now let's take a look at the pro",
    "start": "1415360",
    "end": "1418080"
  },
  {
    "text": "class this is very straightforward uh",
    "start": "1418080",
    "end": "1421120"
  },
  {
    "text": "for the stable diffusion request we're",
    "start": "1421120",
    "end": "1423279"
  },
  {
    "text": "simply re including a string for the",
    "start": "1423279",
    "end": "1426679"
  },
  {
    "text": "prompt and for the response this is just",
    "start": "1426679",
    "end": "1429760"
  },
  {
    "text": "a uh stream byes for the picture that we",
    "start": "1429760",
    "end": "1432760"
  },
  {
    "text": "generated and the S diffusion service",
    "start": "1432760",
    "end": "1435360"
  },
  {
    "text": "just exposes a single RPC call which",
    "start": "1435360",
    "end": "1437919"
  },
  {
    "text": "generates a picture based on the",
    "start": "1437919",
    "end": "1442159"
  },
  {
    "text": "prompt okay so now using this uh Proto",
    "start": "1442159",
    "end": "1447200"
  },
  {
    "text": "file uh we're going to generate the uh",
    "start": "1447200",
    "end": "1450200"
  },
  {
    "text": "the pb2 files uh using the python grpc",
    "start": "1450200",
    "end": "1453240"
  },
  {
    "text": "tools so this is a single",
    "start": "1453240",
    "end": "1456559"
  },
  {
    "text": "command and this generated this couple",
    "start": "1456559",
    "end": "1459640"
  },
  {
    "text": "of",
    "start": "1459640",
    "end": "1461320"
  },
  {
    "text": "files so now we're going to use the uh",
    "start": "1461320",
    "end": "1465520"
  },
  {
    "text": "write the main body of the stable",
    "start": "1465520",
    "end": "1467840"
  },
  {
    "text": "diffusion model uh this is going to be",
    "start": "1467840",
    "end": "1470240"
  },
  {
    "text": "fairly similar to what we did before uh",
    "start": "1470240",
    "end": "1474720"
  },
  {
    "text": "but with a couple of differences first",
    "start": "1474720",
    "end": "1476720"
  },
  {
    "text": "we're importing the stable diffusion",
    "start": "1476720",
    "end": "1479799"
  },
  {
    "text": "protos that we have just generated uh",
    "start": "1479799",
    "end": "1482240"
  },
  {
    "text": "for grpc as well as just be a",
    "start": "1482240",
    "end": "1486200"
  },
  {
    "text": "p uh next uh this serve deployment is",
    "start": "1486200",
    "end": "1489880"
  },
  {
    "text": "going to use a single GPU as opposed to",
    "start": "1489880",
    "end": "1492640"
  },
  {
    "text": "a TPU the rest of the class is uh fairly",
    "start": "1492640",
    "end": "1496760"
  },
  {
    "text": "straightforward let's just expose the",
    "start": "1496760",
    "end": "1499039"
  },
  {
    "text": "generate",
    "start": "1499039",
    "end": "1500840"
  },
  {
    "text": "method and save the responses to the U",
    "start": "1500840",
    "end": "1504760"
  },
  {
    "text": "the file",
    "start": "1504760",
    "end": "1505760"
  },
  {
    "text": "stream and finally this is going to",
    "start": "1505760",
    "end": "1509399"
  },
  {
    "text": "start a race serve instance on the uh",
    "start": "1509399",
    "end": "1514240"
  },
  {
    "text": "grpc",
    "start": "1514240",
    "end": "1516919"
  },
  {
    "text": "port and let's uh submit this",
    "start": "1517760",
    "end": "1524240"
  },
  {
    "text": "job uh first I'm going to expose the ray",
    "start": "1524720",
    "end": "1529320"
  },
  {
    "text": "address uh by setting it as an",
    "start": "1529320",
    "end": "1531440"
  },
  {
    "text": "environment variable this is the IP of",
    "start": "1531440",
    "end": "1534080"
  },
  {
    "text": "the cluster that we just",
    "start": "1534080",
    "end": "1538120"
  },
  {
    "text": "deployed okay next I'm going to submit",
    "start": "1540159",
    "end": "1542919"
  },
  {
    "text": "the ray drop to this endpoint and this",
    "start": "1542919",
    "end": "1545480"
  },
  {
    "text": "is going to package up the local working",
    "start": "1545480",
    "end": "1548000"
  },
  {
    "text": "directory and use the stable diffusion",
    "start": "1548000",
    "end": "1550679"
  },
  {
    "text": "model as the entry",
    "start": "1550679",
    "end": "1552520"
  },
  {
    "text": "point now this is starting the grpc",
    "start": "1552520",
    "end": "1556679"
  },
  {
    "text": "server it's going to add a replica to",
    "start": "1556679",
    "end": "1559240"
  },
  {
    "text": "the",
    "start": "1559240",
    "end": "1561399"
  },
  {
    "text": "deployment okay this uh finish pretty",
    "start": "1562880",
    "end": "1566320"
  },
  {
    "text": "quickly so now let's take a look at the",
    "start": "1566320",
    "end": "1568919"
  },
  {
    "text": "test file we're using this to send a",
    "start": "1568919",
    "end": "1573159"
  },
  {
    "text": "grpc request to the endpoint that uh we",
    "start": "1573159",
    "end": "1576799"
  },
  {
    "text": "have just",
    "start": "1576799",
    "end": "1577880"
  },
  {
    "text": "deployed uh this is going to use the",
    "start": "1577880",
    "end": "1580039"
  },
  {
    "text": "same environment variable to get the ray",
    "start": "1580039",
    "end": "1582440"
  },
  {
    "text": "address uh it's going to send a single",
    "start": "1582440",
    "end": "1586240"
  },
  {
    "text": "prompt and uh the response will be",
    "start": "1586240",
    "end": "1589080"
  },
  {
    "text": "written to a local file so now let's uh",
    "start": "1589080",
    "end": "1592600"
  },
  {
    "text": "take a",
    "start": "1592600",
    "end": "1594919"
  },
  {
    "text": "look okay so this finished and let's",
    "start": "1606120",
    "end": "1609679"
  },
  {
    "text": "take a look at the",
    "start": "1609679",
    "end": "1612480"
  },
  {
    "text": "result okay okay that's pretty",
    "start": "1616360",
    "end": "1620200"
  },
  {
    "text": "good so we have just seen a couple demos",
    "start": "1620880",
    "end": "1624600"
  },
  {
    "text": "on how you can use a reserve to",
    "start": "1624600",
    "end": "1627000"
  },
  {
    "text": "accelerate your gen models on",
    "start": "1627000",
    "end": "1629480"
  },
  {
    "text": "kubernets so now I want to take a minute",
    "start": "1629480",
    "end": "1631760"
  },
  {
    "text": "and talk about what's coming",
    "start": "1631760",
    "end": "1633960"
  },
  {
    "text": "next so we have shown how you can serve",
    "start": "1633960",
    "end": "1637159"
  },
  {
    "text": "a single host model uh using tpus on",
    "start": "1637159",
    "end": "1640240"
  },
  {
    "text": "kubernetes uh but as I previously",
    "start": "1640240",
    "end": "1642679"
  },
  {
    "text": "mentioned you can actually combine",
    "start": "1642679",
    "end": "1644559"
  },
  {
    "text": "multiple tpus slices together and and uh",
    "start": "1644559",
    "end": "1648399"
  },
  {
    "text": "this will allow you to serve larger and",
    "start": "1648399",
    "end": "1650320"
  },
  {
    "text": "larger models so this requires us to",
    "start": "1650320",
    "end": "1654279"
  },
  {
    "text": "utilize the autoscaling capabilities of",
    "start": "1654279",
    "end": "1657039"
  },
  {
    "text": "kues as well as R so in the coming month",
    "start": "1657039",
    "end": "1660799"
  },
  {
    "text": "we will be supporting Autos scaling TPU",
    "start": "1660799",
    "end": "1663320"
  },
  {
    "text": "pods which allows you to scale models up",
    "start": "1663320",
    "end": "1666399"
  },
  {
    "text": "to trillions of",
    "start": "1666399",
    "end": "1668399"
  },
  {
    "text": "parameters um in addition we will be",
    "start": "1668399",
    "end": "1670799"
  },
  {
    "text": "adding more production support for uh",
    "start": "1670799",
    "end": "1673840"
  },
  {
    "text": "running Ray in kubernetes uh such as",
    "start": "1673840",
    "end": "1677000"
  },
  {
    "text": "better",
    "start": "1677000",
    "end": "1678039"
  },
  {
    "text": "observability uh enhancements to",
    "start": "1678039",
    "end": "1680640"
  },
  {
    "text": "security and F tolerance so I look",
    "start": "1680640",
    "end": "1684399"
  },
  {
    "text": "forward to seeing you again and thank",
    "start": "1684399",
    "end": "1686320"
  },
  {
    "text": "you very much for coming today",
    "start": "1686320",
    "end": "1690919"
  }
]
[
  {
    "start": "0",
    "end": "16000"
  },
  {
    "text": "hello everyone welcome to um our talk on building and managing a centralized machine learning platform",
    "start": "960",
    "end": "7120"
  },
  {
    "text": "with cook flow at cern uh we'll be talking about some work we've been doing the last few months",
    "start": "7120",
    "end": "12400"
  },
  {
    "text": "and a service that we open to our users",
    "start": "12400",
    "end": "17920"
  },
  {
    "start": "16000",
    "end": "47000"
  },
  {
    "text": "hello my name is dan gulovus i am a computing engineer in ceramcloud team my focus is on machine learning",
    "start": "18160",
    "end": "25039"
  },
  {
    "text": "infrastructure services with kubernetes and i will present this talk with my colleague ricardo",
    "start": "25039",
    "end": "30640"
  },
  {
    "text": "my name is ricardo i'm a computer engineer also in the cern cloud team i focus mostly on containers networking",
    "start": "30640",
    "end": "37840"
  },
  {
    "text": "and more recently gpu's accelerators and also machine learning and i'm also a member of the technical",
    "start": "37840",
    "end": "43040"
  },
  {
    "text": "oversight committee of the cncf as an end-user representative",
    "start": "43040",
    "end": "48399"
  },
  {
    "start": "47000",
    "end": "106000"
  },
  {
    "text": "so today we'll we'll give a talk about uh service at cern but just a very quick overview of what cern",
    "start": "48399",
    "end": "55120"
  },
  {
    "text": "is about so cern is the european laboratory for particle physics the largest particle physics laboratory in the world",
    "start": "55120",
    "end": "61680"
  },
  {
    "text": "and we build like large scientific machines that allow us to do fundamental research the largest we have is the large hadron",
    "start": "61680",
    "end": "68000"
  },
  {
    "text": "collider you probably heard of it it's a 27 kilometer perimeter particle accelerator that is 100 meters",
    "start": "68000",
    "end": "75439"
  },
  {
    "text": "in the ground and where we accelerate two beams of protons to very close to the speed of light and",
    "start": "75439",
    "end": "80560"
  },
  {
    "text": "we make them collide at very specific points where we build large experiments and you see here cms",
    "start": "80560",
    "end": "86400"
  },
  {
    "text": "lhcp atlas and alice to have an idea of the size you can see the geneva airport here",
    "start": "86400",
    "end": "92159"
  },
  {
    "text": "on the picture this is a an image of the accelerator itself in the tunnel and you can see all the",
    "start": "92159",
    "end": "99040"
  },
  {
    "text": "magnets that help us beam the uh bend the beam so that it circulates in the",
    "start": "99040",
    "end": "105119"
  },
  {
    "text": "in the accelerator and this is a picture of um of one of the detectors the cms",
    "start": "105119",
    "end": "111280"
  },
  {
    "text": "detector compact moon solenoid it's uh in a cavern 40 meters by 40 meters also 100",
    "start": "111280",
    "end": "117360"
  },
  {
    "text": "meters underground and this is where we make the proton beams collide",
    "start": "117360",
    "end": "122399"
  },
  {
    "text": "this detector and the others as well act like gigantic cameras where we take something like 40 million uh pictures a",
    "start": "122399",
    "end": "129280"
  },
  {
    "text": "second and the result of this is a large amount of data that we need to store and analyze um we we collect and",
    "start": "129280",
    "end": "136959"
  },
  {
    "text": "and store more than 70 petabytes of data every year and this is after a lot of filtering uh",
    "start": "136959",
    "end": "144160"
  },
  {
    "text": "one of one detector like this can generate something like one petabyte of data per second uh so that's why we",
    "start": "144160",
    "end": "151519"
  },
  {
    "text": "are constantly looking to new technologies that can help us handle this amount of data",
    "start": "151519",
    "end": "159360"
  },
  {
    "start": "158000",
    "end": "206000"
  },
  {
    "text": "so the main motivation for our service is the expanded usage of machine learning in high energy physics",
    "start": "160239",
    "end": "167200"
  },
  {
    "text": "different groups at cern work on various machine learning projects in order to achieve scientific goals of the large hadron",
    "start": "167200",
    "end": "173840"
  },
  {
    "text": "collider and we know that setting up and managing machine learning infrastructure is not an easy task and",
    "start": "173840",
    "end": "181519"
  },
  {
    "text": "currently most groups at cern manage their own machine learning infrastructure so we have four main experiments which all",
    "start": "181519",
    "end": "187840"
  },
  {
    "text": "branch to different groups and that means that a lot of people use their own",
    "start": "187840",
    "end": "193599"
  },
  {
    "text": "machine learning infrastructure we want to offer a centralized place",
    "start": "193599",
    "end": "198640"
  },
  {
    "text": "essentially service in order to reduce physicists efforts in infrastructure and to allow more time for scientific",
    "start": "198640",
    "end": "204959"
  },
  {
    "text": "research one of the main applications of machine",
    "start": "204959",
    "end": "211120"
  },
  {
    "start": "206000",
    "end": "263000"
  },
  {
    "text": "learning at cern is in particular reconstruction so during proton proton collisions short-lived particles are created in the",
    "start": "211120",
    "end": "217440"
  },
  {
    "text": "detectors for example higgs boson which leaves 10 to the minus 22 seconds",
    "start": "217440",
    "end": "224480"
  },
  {
    "text": "and to capture the events of the short-lived particles we measure energy depositions",
    "start": "224480",
    "end": "230239"
  },
  {
    "text": "in the detectors detectors can be considered as 3d cameras which leaves the opportunity to use",
    "start": "230239",
    "end": "237280"
  },
  {
    "text": "convolutional neural networks besides convolutional neural networks we can use",
    "start": "237280",
    "end": "242799"
  },
  {
    "text": "graph neural networks which are also very good at spatial representation so the example would be",
    "start": "242799",
    "end": "249680"
  },
  {
    "text": "to take the output of the detector and let that be an input to a network and",
    "start": "249680",
    "end": "255040"
  },
  {
    "text": "the output of the network would be the id of the particle whether it's a higgs boson or a muon or a pion",
    "start": "255040",
    "end": "261280"
  },
  {
    "text": "for example and now lots of research is going towards graph neural networks",
    "start": "261280",
    "end": "266720"
  },
  {
    "start": "263000",
    "end": "323000"
  },
  {
    "text": "uh another uh application is in detector simulations so large hadron collider is getting",
    "start": "266720",
    "end": "273199"
  },
  {
    "text": "upgraded there will be more even more data in the future and more sophisticated and faster",
    "start": "273199",
    "end": "279280"
  },
  {
    "text": "solutions are needed to support the upgrade from various perspectives one of them being simulations so uh",
    "start": "279280",
    "end": "286400"
  },
  {
    "text": "simulations are performed to so that we can accurately uh estimate uh what is going to happen",
    "start": "286400",
    "end": "293040"
  },
  {
    "text": "during the runs and the the traditional methods are monte carlo",
    "start": "293040",
    "end": "298639"
  },
  {
    "text": "simulations but recently 3d uh guns have started to be more commonly",
    "start": "298639",
    "end": "305120"
  },
  {
    "text": "used and they have proved to have a similar performance to state state-of-the-art monte carlo",
    "start": "305120",
    "end": "310479"
  },
  {
    "text": "and they offer 20 000 times faster simulation and also with 3d gun data can be",
    "start": "310479",
    "end": "316240"
  },
  {
    "text": "simulated on the fly which may reduce the need for storing the",
    "start": "316240",
    "end": "322840"
  },
  {
    "text": "data so our goal is to set up a platform to",
    "start": "322840",
    "end": "329280"
  },
  {
    "start": "323000",
    "end": "379000"
  },
  {
    "text": "support the end-to-end machine learning life cycles we want to be able to extract data from",
    "start": "329280",
    "end": "335520"
  },
  {
    "text": "the detectors through spark or hdfs and operate on that data then we want",
    "start": "335520",
    "end": "340800"
  },
  {
    "text": "fast iteration services such as notebooks because many users use notebooks daily",
    "start": "340800",
    "end": "346720"
  },
  {
    "text": "at least the notebooks are a good starting point for every machine learning user then for",
    "start": "346720",
    "end": "353039"
  },
  {
    "text": "more computationally extensive jobs we want to be able to perform distributed training with tensorflow or",
    "start": "353039",
    "end": "359600"
  },
  {
    "text": "by torch and even we want to branch out to public cloud",
    "start": "359600",
    "end": "364639"
  },
  {
    "text": "when resources are needed so then after the training we want to store our models and to be",
    "start": "364639",
    "end": "371039"
  },
  {
    "text": "able to perform scalable serving for for the trained models",
    "start": "371039",
    "end": "377919"
  },
  {
    "text": "cool so uh the platform that supports all of",
    "start": "378840",
    "end": "384000"
  },
  {
    "start": "379000",
    "end": "426000"
  },
  {
    "text": "our goals is cube flow uh basically with kubeflow we are utilizing power of kubernetes",
    "start": "384000",
    "end": "389680"
  },
  {
    "text": "to efficiently manage uh resources and we also offer users there all the desired",
    "start": "389680",
    "end": "396319"
  },
  {
    "text": "features uh the infrastructure part of cube flow is managed by our cloud team and our users are physicists and",
    "start": "396319",
    "end": "403680"
  },
  {
    "text": "scientists across the entire ser with kubeflow we can offer notebooks",
    "start": "403680",
    "end": "408720"
  },
  {
    "text": "pipelines distributed training model serving and we can also offer bursting to public",
    "start": "408720",
    "end": "413840"
  },
  {
    "text": "cloud when necessary and that means that basically all of our use cases are covered by kubeflow",
    "start": "413840",
    "end": "420400"
  },
  {
    "text": "and ricardo will now discuss our setup and challenges in terms of setting up our cube flow instance yeah",
    "start": "420400",
    "end": "427120"
  },
  {
    "start": "426000",
    "end": "536000"
  },
  {
    "text": "so i'll pick up on the nice description from there and before he does a cool demo i'll just uh talk about the layout of",
    "start": "427120",
    "end": "434720"
  },
  {
    "text": "the infrastructure we are using so this is a very simplified overview of the clusters the",
    "start": "434720",
    "end": "440080"
  },
  {
    "text": "layout of our clusters so we rely on as an entry point load balancer and this allows us to to simplify the",
    "start": "440080",
    "end": "447599"
  },
  {
    "text": "deployment and for example to do upgrades by just uh adding entry points to the balancer",
    "start": "447599",
    "end": "452720"
  },
  {
    "text": "new clusters on the back end and then there's a gateway that is our ingress gateway to",
    "start": "452720",
    "end": "458000"
  },
  {
    "text": "to the services uh the main important bit here is that we have three types of",
    "start": "458000",
    "end": "464560"
  },
  {
    "text": "nodes the first type is virtual gpus this is something that allows us to have",
    "start": "464560",
    "end": "470560"
  },
  {
    "text": "a large amount of gpu resources although they are not as performance as having a full gpu but it allows us to",
    "start": "470560",
    "end": "477919"
  },
  {
    "text": "have a much larger amount of resources for things like notebooks for example and we rely on t4s with time sharing in this case",
    "start": "477919",
    "end": "486000"
  },
  {
    "text": "and then we have the pc pci bathroom note group type and here we it's mostly",
    "start": "486000",
    "end": "492400"
  },
  {
    "text": "used for things like pipelines or or um distributed training hyperparameter optimization",
    "start": "492400",
    "end": "498160"
  },
  {
    "text": "and also multiple serving where you you want to guarantee a certain latency for for the model serving uh we do not do",
    "start": "498160",
    "end": "504960"
  },
  {
    "text": "today any kind of faster interconnect or anti-link or anything like this and the last bit we have here is cpu",
    "start": "504960",
    "end": "511039"
  },
  {
    "text": "and in this case we have a much larger amount of resources it's not as interesting if you're doing deep learning but actually this platform",
    "start": "511039",
    "end": "517120"
  },
  {
    "text": "ended up being used for other purposes as well where workflows and pipelines can be useful",
    "start": "517120",
    "end": "522719"
  },
  {
    "text": "so you can see that we have something on the order of hundreds of virtual gpus or the tens of full",
    "start": "522719",
    "end": "531279"
  },
  {
    "text": "gpus offered to the users a number of thousands of cpus just very quickly",
    "start": "531279",
    "end": "538240"
  },
  {
    "start": "536000",
    "end": "588000"
  },
  {
    "text": "our deployment is based on uh kubernetes 118 clusters today we use kubeflow 1 1 still and one",
    "start": "538240",
    "end": "545200"
  },
  {
    "text": "difference from the standard 1 1 deployment is that we upgraded this to one five and k native to zero fifteen",
    "start": "545200",
    "end": "551839"
  },
  {
    "text": "all the clusters and the deployments are managed using uh githubs and we have a one repository",
    "start": "551839",
    "end": "558240"
  },
  {
    "text": "where we define all the services and all the environments we support and it's all managed by argo cd",
    "start": "558240",
    "end": "564480"
  },
  {
    "text": "there is one very good feature here which is uh argo cd allows us to",
    "start": "564480",
    "end": "569600"
  },
  {
    "text": "use customize just for the flow deployment and then for the other components we rely on the operators for",
    "start": "569600",
    "end": "577040"
  },
  {
    "text": "both the sto and nvidia gpu operator deployments and then for prometheus gay native",
    "start": "577040",
    "end": "582800"
  },
  {
    "text": "cert manager we are relying on home charts upstream health charts",
    "start": "582800",
    "end": "588720"
  },
  {
    "start": "588000",
    "end": "695000"
  },
  {
    "text": "we one of the key aspects is the integrations we do with the internal cern services so",
    "start": "589120",
    "end": "594480"
  },
  {
    "text": "the first one is identity authorization and authentication and we link this to the cern sso we use uh which is based on",
    "start": "594480",
    "end": "602959"
  },
  {
    "text": "key cloak so this allows us to have not only the tokens that identify the user but also",
    "start": "602959",
    "end": "609600"
  },
  {
    "text": "the mapping of the users to the roles and the groups they belong to and what we do in our clusters is we we",
    "start": "609600",
    "end": "616079"
  },
  {
    "text": "have dedicated namespaces per user where people have a default quota that is",
    "start": "616079",
    "end": "621680"
  },
  {
    "text": "fixed and cannot be changed but also we have additional groups where people can belong to and this is defined",
    "start": "621680",
    "end": "628160"
  },
  {
    "text": "in the cern identity if they belong to these groups and in those groups they can request additional quota like more gpus for",
    "start": "628160",
    "end": "634320"
  },
  {
    "text": "example um and then the other very important part is the integration with our storage",
    "start": "634320",
    "end": "640800"
  },
  {
    "text": "systems as we we mentioned like data is a key aspect of everything we do uh so we integrate",
    "start": "640800",
    "end": "646880"
  },
  {
    "text": "with three the three main uh uh storage systems that are interesting in this case the first one is uh what we",
    "start": "646880",
    "end": "652640"
  },
  {
    "text": "call cvmfs certain vmfs fs which is a real really only distributed hierarchical",
    "start": "652640",
    "end": "658560"
  },
  {
    "text": "caching system for that is mostly used for software distribution the second one is an internal in-house",
    "start": "658560",
    "end": "665279"
  },
  {
    "text": "developed system called eos that is uh holding all the physics data in this case the important part is that",
    "start": "665279",
    "end": "671680"
  },
  {
    "text": "we need to we offer both kerberos and os2 based access os2 is very important",
    "start": "671680",
    "end": "677360"
  },
  {
    "text": "for things like notebooks and anything that is uh like browser oriented and then the last",
    "start": "677360",
    "end": "683279"
  },
  {
    "text": "one is hdfs they mentioned that in some cases people want to do the data preparation using",
    "start": "683279",
    "end": "689200"
  },
  {
    "text": "spark and in this case we are accessing hdfs using kerberos credentials",
    "start": "689200",
    "end": "695440"
  },
  {
    "start": "695000",
    "end": "780000"
  },
  {
    "text": "i will just summarize a couple of issues that we run well into while doing this the first",
    "start": "695440",
    "end": "701519"
  },
  {
    "text": "one is that the couple releases were not always very consistent in terms of what's",
    "start": "701519",
    "end": "707519"
  },
  {
    "text": "supporting what so one zero had for example multi-user support for for notebooks but not uh pipelines",
    "start": "707519",
    "end": "715360"
  },
  {
    "text": "and one-on-one brought multi-user pipelines but actually some of the components were not talking to to this",
    "start": "715360",
    "end": "721360"
  },
  {
    "text": "new api properly like kale from notebooks this meant that we spent quite a bit of time downstream",
    "start": "721360",
    "end": "727920"
  },
  {
    "text": "fixing these bits when we did the upgrade and this is one of the reasons why we are still in one one and we are",
    "start": "727920",
    "end": "733839"
  },
  {
    "text": "slowly uh updating to newer versions as well the second one is actually customized and",
    "start": "733839",
    "end": "739920"
  },
  {
    "text": "the way uh kubflow is using customize is quite complex so we decided to spend some time",
    "start": "739920",
    "end": "746160"
  },
  {
    "text": "simplifying things and removing some of the components out of it especially things like cert manager",
    "start": "746160",
    "end": "751839"
  },
  {
    "text": "istio and k-native which are quite critical and in the end we deploy them in another",
    "start": "751839",
    "end": "758160"
  },
  {
    "text": "way and we only deploy the workflow applications using customize and then the last one which is still an",
    "start": "758160",
    "end": "763839"
  },
  {
    "text": "ongoing issue is how to manage additional packages that people might require for both the",
    "start": "763839",
    "end": "768959"
  },
  {
    "text": "notebooks and then then for their pipelines as well and how can they install and add these",
    "start": "768959",
    "end": "775279"
  },
  {
    "text": "packages easily to their containers so this is something i will mention more later",
    "start": "775279",
    "end": "781839"
  },
  {
    "start": "780000",
    "end": "856000"
  },
  {
    "text": "the last bit i will mention before we jump to the demo is how we are doing uh bursting to the",
    "start": "781839",
    "end": "787279"
  },
  {
    "text": "public clouds um this is very important for us because we can get access to a much larger amount",
    "start": "787279",
    "end": "792320"
  },
  {
    "text": "of gpus and especially other types of accelerators like cpus or ipu's tpus are very interesting for our",
    "start": "792320",
    "end": "798800"
  },
  {
    "text": "use cases also because they are very cost effective we tried this using different",
    "start": "798800",
    "end": "805680"
  },
  {
    "text": "technologies over the last few years on the lower level we tried federation v1 and v2",
    "start": "805680",
    "end": "811440"
  },
  {
    "text": "we also have deployments using the virtual couplet we are not still very um experts in",
    "start": "811440",
    "end": "818399"
  },
  {
    "text": "istio but we are experimenting with it but actually for coop flow the most promising results and the way we",
    "start": "818399",
    "end": "824959"
  },
  {
    "text": "are offering this is actually to directly expose the other clusters to the to the users via their jupiter",
    "start": "824959",
    "end": "831760"
  },
  {
    "text": "environment so when you get your dripter environment your notebook environment you actually get the additional clusters configured",
    "start": "831760",
    "end": "838560"
  },
  {
    "text": "and these clusters are configured with the same cern sso so we can do uh something like using the",
    "start": "838560",
    "end": "844639"
  },
  {
    "text": "open policy agent to validate who is able to access which which clusters which groups can actually",
    "start": "844639",
    "end": "850240"
  },
  {
    "text": "access each cluster and then we do the quota management the same way in those clusters as well",
    "start": "850240",
    "end": "856000"
  },
  {
    "text": "this is working quite well this is a simple not so simple picture but it's",
    "start": "856000",
    "end": "861279"
  },
  {
    "text": "kind of simple given what is behind but the key aspect is that this jupiter environment",
    "start": "861279",
    "end": "867040"
  },
  {
    "text": "we have the cluster configuration and we are able to reuse the als",
    "start": "867040",
    "end": "872079"
  },
  {
    "text": "token that the user already have has by logging into this system at cern and then but",
    "start": "872079",
    "end": "879360"
  },
  {
    "text": "normally they would just submit to the same uh cluster where kubflow is running the the egyptian",
    "start": "879360",
    "end": "885279"
  },
  {
    "text": "environment and they would submit a tf job that would use gpus on premises and then when once this",
    "start": "885279",
    "end": "891120"
  },
  {
    "text": "training is done we we write to output artifacts to s3 where it can be served from the s3 instance at cern",
    "start": "891120",
    "end": "898800"
  },
  {
    "text": "by exposing additional clusters in the environment people can just source those clusters um",
    "start": "898800",
    "end": "904880"
  },
  {
    "text": "and then submit the tf jobs to external clusters and this in this case it would be good",
    "start": "904880",
    "end": "910800"
  },
  {
    "text": "the google cloud where we would have potentially thousands of gpus available",
    "start": "910800",
    "end": "915920"
  },
  {
    "text": "or gpus in the end again the output artifacts are written to s3 and served in the same",
    "start": "915920",
    "end": "922480"
  },
  {
    "text": "way as if they would have been trained internally so this is a quite promising",
    "start": "922480",
    "end": "927600"
  },
  {
    "text": "and this is what we are offering today okay now we'll go back to our demo",
    "start": "927600",
    "end": "935440"
  },
  {
    "text": "example so we remember 3d guns uh basically uh the the main issue with",
    "start": "935440",
    "end": "941440"
  },
  {
    "text": "3d guns is uh extensive training time so uh for our model uh it would take two",
    "start": "941440",
    "end": "949680"
  },
  {
    "text": "2.5 days to to properly train and if for example if we want to uh",
    "start": "949680",
    "end": "955680"
  },
  {
    "text": "search hyper parameters or change the model that iteration could last for weeks or",
    "start": "955680",
    "end": "961360"
  },
  {
    "text": "even months so this is uh with one gpu so to",
    "start": "961360",
    "end": "966720"
  },
  {
    "text": "create a more scalable solution um a distributed model is created basically uh it's uh",
    "start": "966720",
    "end": "973759"
  },
  {
    "text": "the model is trained using tensorflow strategies so uh for example we are using in our",
    "start": "973759",
    "end": "980720"
  },
  {
    "text": "example a multi-worker mirror strategy with which uses different nodes with multiple gpus",
    "start": "980720",
    "end": "987360"
  },
  {
    "text": "and also we have a script with uh accessing tpus for the distributed training",
    "start": "987360",
    "end": "994480"
  },
  {
    "start": "993000",
    "end": "1048000"
  },
  {
    "text": "uh so uh tf job and kubeflow helped us automate this distributed",
    "start": "994639",
    "end": "1002079"
  },
  {
    "text": "training process uh we are able to quickly iterate over different training configurations so basically we",
    "start": "1002079",
    "end": "1008800"
  },
  {
    "text": "are encapsulating tensorflow distribution and we mean it's it's managing it across kubernetes spots",
    "start": "1008800",
    "end": "1016160"
  },
  {
    "text": "uh so we are able with the job to run distributor training both locally",
    "start": "1016160",
    "end": "1022880"
  },
  {
    "text": "and on a public cloud as ricardo was describing and uh yeah we at gcp we are",
    "start": "1022880",
    "end": "1029038"
  },
  {
    "text": "using 128 preemptable uh machines for the distributed training",
    "start": "1029039",
    "end": "1035678"
  },
  {
    "text": "and now we can move to the demo",
    "start": "1035679",
    "end": "1040959"
  },
  {
    "text": "so let me share the screen [Music]",
    "start": "1041120",
    "end": "1046640"
  },
  {
    "start": "1048000",
    "end": "1085000"
  },
  {
    "text": "so now we are going to show our demo here we can see at ml.cern.ch our service dashboard basically this is",
    "start": "1049600",
    "end": "1056960"
  },
  {
    "text": "the cubesale dashboard and we can check all the",
    "start": "1056960",
    "end": "1063120"
  },
  {
    "text": "kubeflow features",
    "start": "1063120",
    "end": "1067840"
  },
  {
    "start": "1085000",
    "end": "1315000"
  },
  {
    "text": "so now we're going to show our demo uh we can see our dashboard here and we can see cubeflow features on the left we have",
    "start": "1086559",
    "end": "1092880"
  },
  {
    "text": "pipelines notebook servers cutib and the other features so",
    "start": "1092880",
    "end": "1098240"
  },
  {
    "text": "we'll go to our notebook which is basically where we have our demo prepared",
    "start": "1098240",
    "end": "1105120"
  },
  {
    "text": "so uh here we have a couple of demos we are going to show uh the first one",
    "start": "1107520",
    "end": "1113840"
  },
  {
    "text": "is um one from the from our examples repo basically we",
    "start": "1113840",
    "end": "1119679"
  },
  {
    "text": "created a repository for onboarding our users for various cube flow",
    "start": "1119679",
    "end": "1124880"
  },
  {
    "text": "features we are going to show kail this this example shows us how to",
    "start": "1124880",
    "end": "1131840"
  },
  {
    "text": "convert a notebook to a pipeline without writing any additional",
    "start": "1131840",
    "end": "1136880"
  },
  {
    "text": "python code so for that we're using kl deployment panel and basically the only thing we",
    "start": "1136880",
    "end": "1142400"
  },
  {
    "text": "need to do is to annotate every every cell so that it converts",
    "start": "1142400",
    "end": "1148160"
  },
  {
    "text": "properly to a pipeline component in addition to annotating we are",
    "start": "1148160",
    "end": "1155039"
  },
  {
    "text": "creating connections between pipeline components and we can also add the gpu to any",
    "start": "1155039",
    "end": "1160160"
  },
  {
    "text": "specific pipeline component so here we can in order to run",
    "start": "1160160",
    "end": "1166080"
  },
  {
    "text": "we only need to click this button compile and run and we can see our pipeline uh running",
    "start": "1166080",
    "end": "1172720"
  },
  {
    "text": "so while our pipeline is running we can check other uh features which we have in our service",
    "start": "1172720",
    "end": "1179919"
  },
  {
    "text": "uh one of them is eos so eos is where most users where all users",
    "start": "1179919",
    "end": "1187120"
  },
  {
    "text": "at cern have their personal directories and the mounting eos really allows",
    "start": "1187120",
    "end": "1194960"
  },
  {
    "text": "us to be able to access broad data from",
    "start": "1194960",
    "end": "1202400"
  },
  {
    "text": "multiple users basically every user can access their own personal folder here",
    "start": "1202400",
    "end": "1208240"
  },
  {
    "text": "and also we can show up the usage of a gpu with nvidia smi",
    "start": "1208240",
    "end": "1213360"
  },
  {
    "text": "so yeah we are starting with that the main example which we have",
    "start": "1213360",
    "end": "1220559"
  },
  {
    "text": "is the 3d gun so here uh we have our 3d gun training so we have a different scripts",
    "start": "1220559",
    "end": "1228559"
  },
  {
    "text": "here uh one of them is training a 3d gun with a cpu and then we train 3d gun with the gpu",
    "start": "1228559",
    "end": "1236559"
  },
  {
    "text": "here and it's all distributed training though when it comes to gpus so basically here what we want to check",
    "start": "1236559",
    "end": "1243200"
  },
  {
    "text": "is a strategy so we see that",
    "start": "1243200",
    "end": "1249760"
  },
  {
    "text": "we see that we are using multi-worker mirrored strategy for gpu training and",
    "start": "1249760",
    "end": "1256960"
  },
  {
    "text": "so as far as mentioning we are also uploading the train model to",
    "start": "1256960",
    "end": "1263120"
  },
  {
    "text": "a bucket and we see that code here that after the model is trained we are uploading it to our cern bucket",
    "start": "1263120",
    "end": "1269919"
  },
  {
    "text": "similarly for tpus only here we have a tpu strategy for distributed training",
    "start": "1269919",
    "end": "1277840"
  },
  {
    "text": "uh we also in this repository have a docker file to build our image to to run our",
    "start": "1278880",
    "end": "1285679"
  },
  {
    "text": "distributed training but we are not building it uh here we won't do that but we'll show our tf",
    "start": "1285679",
    "end": "1292080"
  },
  {
    "text": "job yaml file so to submit a tf job basically we can define our number of replicas here",
    "start": "1292080",
    "end": "1299200"
  },
  {
    "text": "number of gpus we are using here and then we also",
    "start": "1299200",
    "end": "1304320"
  },
  {
    "text": "we select the image and we also can select if we want uh full training and the number of",
    "start": "1304320",
    "end": "1310559"
  },
  {
    "text": "epochs and other customizable uh arguments",
    "start": "1310559",
    "end": "1315760"
  },
  {
    "start": "1315000",
    "end": "1715000"
  },
  {
    "text": "so now we are going to submit our our 3d 3d gun",
    "start": "1315919",
    "end": "1323600"
  },
  {
    "text": "tf job on a local cluster",
    "start": "1323600",
    "end": "1332000"
  },
  {
    "text": "you have to do is to do cubectl apply",
    "start": "1332000",
    "end": "1337840"
  },
  {
    "text": "3d gpu so yeah this one we are submitting to our local",
    "start": "1338559",
    "end": "1345440"
  },
  {
    "text": "cluster and we can check our",
    "start": "1345440",
    "end": "1352080"
  },
  {
    "text": "job and we see our team job running so now might be a good time to",
    "start": "1352320",
    "end": "1358720"
  },
  {
    "text": "check if our pipeline has completed it has so we can see our logs",
    "start": "1358720",
    "end": "1364159"
  },
  {
    "text": "and we can see that our pipeline has completely has completed training two models and we",
    "start": "1364159",
    "end": "1370960"
  },
  {
    "text": "see which model was better and now we're running the distributed training of a 3d gun on a",
    "start": "1370960",
    "end": "1377440"
  },
  {
    "text": "local cluster additionally we want to run a [Music]",
    "start": "1377440",
    "end": "1383039"
  },
  {
    "text": "3d gun training on a google cluster so basically uh",
    "start": "1383039",
    "end": "1389520"
  },
  {
    "text": "inside the cluster folder uh users would get uh um",
    "start": "1389520",
    "end": "1396000"
  },
  {
    "text": "information about all available clusters uh in our service so here we only have a cern and the gcp cluster",
    "start": "1396000",
    "end": "1403200"
  },
  {
    "text": "and all the users have to do to access the additional clusters is to",
    "start": "1403200",
    "end": "1409440"
  },
  {
    "text": "source these files so gcp",
    "start": "1409440",
    "end": "1414880"
  },
  {
    "text": "setup setup.sh and now they should be able to they",
    "start": "1414880",
    "end": "1421360"
  },
  {
    "text": "should they are in the google cloud cluster",
    "start": "1421360",
    "end": "1430240"
  },
  {
    "text": "so as we can see in the google cloud cluster there are no parts in my personal name space but in uh this local cluster we have our",
    "start": "1430240",
    "end": "1438799"
  },
  {
    "text": "i have a couple of pods here running and some of them completed so um",
    "start": "1438799",
    "end": "1444450"
  },
  {
    "text": "[Music] what we are going to submit here are",
    "start": "1444450",
    "end": "1449679"
  },
  {
    "text": "a 3d gun example so we can go to um to our",
    "start": "1449679",
    "end": "1456240"
  },
  {
    "text": "gcp uh our gcp aml file and we are going to",
    "start": "1456240",
    "end": "1464080"
  },
  {
    "text": "submit that",
    "start": "1464080",
    "end": "1473840"
  },
  {
    "text": "gcp so now we're submitting this tf job to our",
    "start": "1474880",
    "end": "1480880"
  },
  {
    "text": "google google cluster meanwhile we can check",
    "start": "1480880",
    "end": "1487840"
  },
  {
    "text": "if our training on our local cluster has completed",
    "start": "1487840",
    "end": "1495120"
  },
  {
    "text": "flow and yes we can see that it has completed",
    "start": "1498320",
    "end": "1504799"
  },
  {
    "text": "and to check the google cluster i'll be basically we want to have a",
    "start": "1504799",
    "end": "1510559"
  },
  {
    "text": "watch and yes we can see here that our workers are",
    "start": "1510559",
    "end": "1515679"
  },
  {
    "text": "uh deployed at nodes which have uh we v100s so in total we have",
    "start": "1515679",
    "end": "1522279"
  },
  {
    "text": "128 nodes running and we have a 16 workers where each worker",
    "start": "1522279",
    "end": "1529279"
  },
  {
    "text": "has 8 [Music] so now our training job is running",
    "start": "1529279",
    "end": "1536559"
  },
  {
    "text": "actually on a google uh cluster and this is what we see here",
    "start": "1536559",
    "end": "1542559"
  },
  {
    "text": "so we can close this now and here we see that our local job has",
    "start": "1542559",
    "end": "1548240"
  },
  {
    "text": "completed and now as ricardo was saying after the training we submit our model",
    "start": "1548240",
    "end": "1555520"
  },
  {
    "text": "to a bucket so here we can see uh the the trained model",
    "start": "1555520",
    "end": "1562799"
  },
  {
    "text": "stored on on our buckets so we have couple of files for each model and then this is all for for one model and for",
    "start": "1562799",
    "end": "1568799"
  },
  {
    "text": "one ebook so we have our discriminator and generator for 3d gun stored",
    "start": "1568799",
    "end": "1574240"
  },
  {
    "text": "in the bucket and we also have a saved model in the format so that it can be used for",
    "start": "1574240",
    "end": "1581360"
  },
  {
    "text": "inference for serving and also we want to maybe want to check this these metrics",
    "start": "1581360",
    "end": "1588960"
  },
  {
    "text": "basically this is how we can store a metrics how we store metrics about our",
    "start": "1588960",
    "end": "1594400"
  },
  {
    "text": "model after each epoch",
    "start": "1594400",
    "end": "1599840"
  },
  {
    "text": "so okay now we have covered the 3d gun the last thing i'd like to cover is the",
    "start": "1602000",
    "end": "1608559"
  },
  {
    "text": "inference is the inference rd inference services",
    "start": "1608559",
    "end": "1615278"
  },
  {
    "text": "services what we want to do here is to submit",
    "start": "1620320",
    "end": "1627360"
  },
  {
    "text": "an inference service and to basically serve a model",
    "start": "1627360",
    "end": "1634320"
  },
  {
    "text": "by only specifying where the model is located so you can see cube ctl",
    "start": "1634320",
    "end": "1640799"
  },
  {
    "text": "apply and now we have created our uh inference",
    "start": "1640799",
    "end": "1648799"
  },
  {
    "text": "service actually it was already it was already there but this is how we can",
    "start": "1648799",
    "end": "1654159"
  },
  {
    "text": "we create it when we when we want and then to test our inference",
    "start": "1654159",
    "end": "1662480"
  },
  {
    "text": "we can test it from here and we see that we are getting results and basically as we",
    "start": "1662480",
    "end": "1668320"
  },
  {
    "text": "were discussing we're getting a 3d output for",
    "start": "1668320",
    "end": "1673840"
  },
  {
    "text": "uh that represents the output of the detector so this is what happens when we do uh",
    "start": "1673840",
    "end": "1680799"
  },
  {
    "text": "one inference but uh we want to do 10 uh curl requests at the same time",
    "start": "1680799",
    "end": "1687919"
  },
  {
    "text": "so that we can see what happens to the number of predictor pods as we can see they are",
    "start": "1687919",
    "end": "1695360"
  },
  {
    "text": "the number of parts it is increasing it's auto scaling so that it can support",
    "start": "1695360",
    "end": "1700480"
  },
  {
    "text": "uh [Music] client requests",
    "start": "1700480",
    "end": "1706640"
  },
  {
    "text": "and basically uh yeah with this we have covered our demo",
    "start": "1706640",
    "end": "1712080"
  },
  {
    "start": "1715000",
    "end": "1742000"
  },
  {
    "text": "so basically during this training we were able to reduce the execution time from one hour",
    "start": "1716559",
    "end": "1723039"
  },
  {
    "text": "to 30 seconds for one e-book and for the full training we managed to get from",
    "start": "1723039",
    "end": "1729120"
  },
  {
    "text": "60 hours to around 30 minutes so tf job really helped us speed up the",
    "start": "1729200",
    "end": "1735679"
  },
  {
    "text": "development process and we see that we get almost linear improvement in our performance for our 3d gun model and our",
    "start": "1735679",
    "end": "1743520"
  },
  {
    "start": "1742000",
    "end": "1862000"
  },
  {
    "text": "card will offer the closing remarks yeah so basically i hope this was a",
    "start": "1743520",
    "end": "1750480"
  },
  {
    "text": "nice overview of the service we are offering and the potential that it has by offering uh like a consistent",
    "start": "1750480",
    "end": "1756480"
  },
  {
    "text": "environment where people can do their development but also interact with the services",
    "start": "1756480",
    "end": "1762559"
  },
  {
    "text": "we handle all the machine learning learning life cycle steps from preparation all the way to serving",
    "start": "1762559",
    "end": "1768159"
  },
  {
    "text": "um we managed to centralize the resources that are pre-scarce such as accelerators",
    "start": "1768159",
    "end": "1774880"
  },
  {
    "text": "in this case gpus and also we showed how we are doing currently the integration with external",
    "start": "1774880",
    "end": "1780720"
  },
  {
    "text": "resources for gpu's dpus using public clouds there are steps we are still working on",
    "start": "1780720",
    "end": "1786480"
  },
  {
    "text": "so one of the main ones is to onboard new use cases and from those there's a very interesting one for reinforcement",
    "start": "1786480",
    "end": "1793039"
  },
  {
    "text": "learning uh for from the people doing the beam calibration where they want to um like keep the model live and and",
    "start": "1793039",
    "end": "1800559"
  },
  {
    "text": "update it live while the beam is running and the second",
    "start": "1800559",
    "end": "1805679"
  },
  {
    "text": "second thing i would like to mention is this needs to be for users to be able to",
    "start": "1805679",
    "end": "1811279"
  },
  {
    "text": "curate their own environments and to add uh packages to to their own environments easily right",
    "start": "1811279",
    "end": "1817279"
  },
  {
    "text": "now the only option is to install the packages on the notebook but that doesn't work well when you're doing a transition to",
    "start": "1817279",
    "end": "1823279"
  },
  {
    "text": "pipelines for example or to distribute training so we have some experience using a tool",
    "start": "1823279",
    "end": "1828559"
  },
  {
    "text": "called binder for jupyter notebooks and we are looking at integrating this with the kuflow jr web app as well and the last",
    "start": "1828559",
    "end": "1836640"
  },
  {
    "text": "one is uh we are quite involved in the work ongoing work uh for flow improvements in metadata and artifact",
    "start": "1836640",
    "end": "1843200"
  },
  {
    "text": "management so it's something that we'll also keep pushing for in the community so we would like to",
    "start": "1843200",
    "end": "1849919"
  },
  {
    "text": "thank uh like everyone in the cupola community for for the great tooling that and of",
    "start": "1849919",
    "end": "1854960"
  },
  {
    "text": "course all the kubernetes and cloud native tools that we rely on as well and we are happy to answer any questions",
    "start": "1854960",
    "end": "1861200"
  },
  {
    "text": "thank you very much",
    "start": "1861200",
    "end": "1864720"
  }
]
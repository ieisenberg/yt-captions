[
  {
    "text": "thank you for joining the session uh and thank you for making it to the end of the day last session of the day right",
    "start": "120",
    "end": "5400"
  },
  {
    "text": "they're they're always rough they're always rough so uh it's been a it's been a great great event today so I've been",
    "start": "5400",
    "end": "11340"
  },
  {
    "text": "really enjoying it so uh but once again thank you for joining me uh my name is Josh Carlisle I am a principal engineer",
    "start": "11340",
    "end": "18420"
  },
  {
    "text": "at z-scaler and also on the community side I'm a Microsoft MVP and I am also",
    "start": "18420",
    "end": "23760"
  },
  {
    "text": "here with my colleague and I'm a stock software engineer at z-scaler",
    "start": "23760",
    "end": "29340"
  },
  {
    "text": "work with Josh yeah so we're colleagues and we work together and you're going to find out over the next 30 minutes what",
    "start": "29340",
    "end": "34559"
  },
  {
    "text": "we have been working on so to get started here a little bit a",
    "start": "34559",
    "end": "39960"
  },
  {
    "text": "little bit of our agenda here uh so we're going to give a little bit of a platform overview about what our world",
    "start": "39960",
    "end": "45300"
  },
  {
    "text": "looks like because we want to give this a little bit of a context right uh so that you understand a little bit more",
    "start": "45300",
    "end": "50399"
  },
  {
    "text": "about our solution and there we go and uh we're also going",
    "start": "50399",
    "end": "56879"
  },
  {
    "text": "to kind of cover some of our uh you know buy versus build some of our considerations we made and a little bit",
    "start": "56879",
    "end": "61920"
  },
  {
    "text": "of what our journey was like that led us to some of the decisions we made and where we landed on things uh and then",
    "start": "61920",
    "end": "67799"
  },
  {
    "text": "we're going to jump into a actual demo you're going to see a a abbreviated",
    "start": "67799",
    "end": "72900"
  },
  {
    "text": "version of kind of what our environment looks like a little bit of an easier to consume version that represents kind of",
    "start": "72900",
    "end": "78479"
  },
  {
    "text": "where we landed on things and and uh and then finally we're going to be covering some best practices and some lessons",
    "start": "78479",
    "end": "84180"
  },
  {
    "text": "learned right no nothing's perfect and there's always hiccups along the way so we're going to kind of be sharing a bit",
    "start": "84180",
    "end": "89939"
  },
  {
    "text": "about what we learned and what worked well for us so to give you a little bit of context",
    "start": "89939",
    "end": "96000"
  },
  {
    "text": "before we get started uh uh uh both Anita and I work on a product at z-scaler called Z scalar posture control",
    "start": "96000",
    "end": "102259"
  },
  {
    "text": "it is part of a category of applications commonly referred to as cnap uh and for",
    "start": "102259",
    "end": "109079"
  },
  {
    "text": "those folks who aren't aware of all the latest and greatest Gartner acronyms it stands for cloud native application",
    "start": "109079",
    "end": "116280"
  },
  {
    "text": "protection platform which is kind of a mouthful but in essence",
    "start": "116280",
    "end": "122159"
  },
  {
    "text": "we help our customers secure their Cloud native applications uh and we do that in a kind of in a very specific way so like",
    "start": "122159",
    "end": "129539"
  },
  {
    "text": "most SAS platforms out here we have customers and this is a little bit of a a difference when we talk about tenants",
    "start": "129539",
    "end": "136080"
  },
  {
    "text": "in our use case it's a little bit different than what other talks may have been talking about when we're talking",
    "start": "136080",
    "end": "141420"
  },
  {
    "text": "about tenants we have tenants in the traditional uh conversation uh uh",
    "start": "141420",
    "end": "146879"
  },
  {
    "text": "definition where where we have a platform that we offer out to our developer and feature and engineering",
    "start": "146879",
    "end": "152940"
  },
  {
    "text": "team something we call subsystems internally but we also have tenants as",
    "start": "152940",
    "end": "158160"
  },
  {
    "text": "in actual customers right so the the different spin on this is that in our",
    "start": "158160",
    "end": "164220"
  },
  {
    "text": "use case our multi-tenant use case it's actually multi-tenant of multi-tenants",
    "start": "164220",
    "end": "170099"
  },
  {
    "text": "uh and that adds a little bit of a different spin on some of the complexities and some of the challenges we had uh along our way in our journey",
    "start": "170099",
    "end": "177360"
  },
  {
    "text": "so we have our customers and and those customers like most customers are running Cloud native applications today",
    "start": "177360",
    "end": "182819"
  },
  {
    "text": "uh they're living in Azure and AWS and gcp right uh and they're also using sets",
    "start": "182819",
    "end": "187980"
  },
  {
    "text": "of tools uh to both build those applications deploy those applications Uh define those applications in the case",
    "start": "187980",
    "end": "194640"
  },
  {
    "text": "of IC uh and all of those uh platforms provide Telemetry to us right and what",
    "start": "194640",
    "end": "201780"
  },
  {
    "text": "our platform does is we essentially correlate and make sense out of all that Telemetry coming in to help customers",
    "start": "201780",
    "end": "207959"
  },
  {
    "text": "understand when they have misconfigurations that can lead to security problems when they have vulnerabilities maybe a a pack oops",
    "start": "207959",
    "end": "216599"
  },
  {
    "text": "did we lose okay sorry about that that was weird uh when we have a uh uh vulnerabilities for",
    "start": "216599",
    "end": "223980"
  },
  {
    "text": "example if there's a package that a particular service is using uh that has an exploit and we correlate it all",
    "start": "223980",
    "end": "229860"
  },
  {
    "text": "together and help customers make their applications more secure so that's kind of the context that we",
    "start": "229860",
    "end": "235500"
  },
  {
    "text": "live in we consume lots and lots and lots of data as part of that so what does this look like from a",
    "start": "235500",
    "end": "242879"
  },
  {
    "text": "deployment standpoint and where does this multi-tenant of multi-tenant start to kind of tie in well",
    "start": "242879",
    "end": "249540"
  },
  {
    "text": "this was a Greenfield project about 18 months ago uh and and that's both a blessing and a curse uh we had a lot of",
    "start": "249540",
    "end": "256380"
  },
  {
    "text": "freedom but we had a lot of decisions that we needed to make along the way and we secure Cloud native applications so",
    "start": "256380",
    "end": "263639"
  },
  {
    "text": "it makes sense that we should probably be a cloud native application ourselves right so we have a lot of the",
    "start": "263639",
    "end": "268919"
  },
  {
    "text": "traditional components that you expect from a cloud cloud native application we live in the cloud we are living in",
    "start": "268919",
    "end": "275100"
  },
  {
    "text": "kubernetes we have microservices and messaging infrastructure that we host and database infrastructure and a lot of",
    "start": "275100",
    "end": "282300"
  },
  {
    "text": "other platform components many of which are cncf projects we use open Telemetry",
    "start": "282300",
    "end": "287340"
  },
  {
    "text": "we use cada we use just a lot of other cncf projects to kind of help stitch together our platform and from a",
    "start": "287340",
    "end": "295560"
  },
  {
    "text": "traditional multi-tenant standpoint we have multiple environments right and those multiple environments are deployed",
    "start": "295560",
    "end": "301680"
  },
  {
    "text": "to what we call stamps or regions around the world what makes things a little bit more challenging is that we also have",
    "start": "301680",
    "end": "308520"
  },
  {
    "text": "customer specific microservices and customer specific components when you're in a multi-tenant environment from a",
    "start": "308520",
    "end": "315240"
  },
  {
    "text": "customer perspective you have some challenges things like noisy neighbors that you have to solve noise Noisy",
    "start": "315240",
    "end": "320940"
  },
  {
    "text": "Neighbor problems things like a customer data isolation customer isolation and",
    "start": "320940",
    "end": "325979"
  },
  {
    "text": "some of those some of those problems in the way which you solve them add a lot of complexity on how you",
    "start": "325979",
    "end": "331080"
  },
  {
    "text": "deploy applications so we have tenant specific microservices microservices are dedicated to tenants it's worth",
    "start": "331080",
    "end": "336960"
  },
  {
    "text": "mentioning we use another cncf project I mentioned a minute ago called cada that allows us to do that in a cost-effective",
    "start": "336960",
    "end": "342180"
  },
  {
    "text": "way so when nothing's running we don't pay for it a kind of like a scale to zero a little serverless kind of model",
    "start": "342180",
    "end": "347580"
  },
  {
    "text": "but we also have things like customer specific topics and customer specific databases and we have to be able to kind",
    "start": "347580",
    "end": "354600"
  },
  {
    "text": "of manage those kind of things so when we started kind of coming up with you know how do we handle what do we want to",
    "start": "354600",
    "end": "360120"
  },
  {
    "text": "do how do we want to approach this man we're Green Field here right we kind of started making some decisions we try to start thinking about you know do we want",
    "start": "360120",
    "end": "366419"
  },
  {
    "text": "to build our own you know are we that special right everybody thinks you're special everybody every product's unique but do we decide hey do we want to build",
    "start": "366419",
    "end": "372840"
  },
  {
    "text": "this ourselves do we want to use a traditional deployment platform uh uh you know things like GitHub actions or",
    "start": "372840",
    "end": "378720"
  },
  {
    "text": "you know Azure devops things that you that that are traditional out there or do we want to maybe Embrace a few good",
    "start": "378720",
    "end": "384120"
  },
  {
    "text": "Ops side right because git Ops Cloud native they kind of go hand in hand so that was definitely on there but we had had some strong considerations right we",
    "start": "384120",
    "end": "391319"
  },
  {
    "text": "needed to support some of the special multi-tenancy use cases we had tenants of tenants of tenants kind of scenario",
    "start": "391319",
    "end": "397160"
  },
  {
    "text": "we also were sensitive to not getting too early on new platforms because we",
    "start": "397160",
    "end": "403020"
  },
  {
    "text": "wanted something that had some maturity and some long some long life uh and we also it was very important that our",
    "start": "403020",
    "end": "409860"
  },
  {
    "text": "Engineers were comfortable with working with the platform uh because a key consideration across the board was",
    "start": "409860",
    "end": "415199"
  },
  {
    "text": "really around our our our velocity right and if we had to introduce something",
    "start": "415199",
    "end": "420240"
  },
  {
    "text": "really really new to our Engineers it's going to slow down our velocity and we wouldn't be able to meet some of our deployment goals and it obviously cost",
    "start": "420240",
    "end": "426900"
  },
  {
    "text": "is is a determining Factor so we had some painful first steps that we learned",
    "start": "426900",
    "end": "432720"
  },
  {
    "text": "from since velocity was really our number one goal we started to align",
    "start": "432720",
    "end": "439380"
  },
  {
    "text": "with basically do whatever you want as long as it's fast uh which obviously has",
    "start": "439380",
    "end": "445380"
  },
  {
    "text": "its its pluses and negatives and since we have subsystems which are basically teams we said you know do what",
    "start": "445380",
    "end": "452639"
  },
  {
    "text": "you need to do to deploy what you're responsible for deploying in the way that you feel confident doing uh and",
    "start": "452639",
    "end": "459720"
  },
  {
    "text": "that worked for a while that definitely got us through our hump we got a first release out really quickly a very large",
    "start": "459720",
    "end": "465240"
  },
  {
    "text": "product in about eight months but as we went GA we started to kind of identify this isn't really that great",
    "start": "465240",
    "end": "472139"
  },
  {
    "text": "right this is there's some pain points here it was fragile it was expensive when we started kind of thinking about",
    "start": "472139",
    "end": "477240"
  },
  {
    "text": "how do we how do we overcome these and we were still a little bit in the mindset of of do we build this ourselves",
    "start": "477240",
    "end": "484319"
  },
  {
    "text": "or do we uh uh lean into another solution and we started looking at",
    "start": "484319",
    "end": "489479"
  },
  {
    "text": "things like custom resource definitions and defining our own resources and that led us into looking a little bit closer",
    "start": "489479",
    "end": "495660"
  },
  {
    "text": "again at git Ops and a lot had changed in that year uh uh a lot of things had",
    "start": "495660",
    "end": "501120"
  },
  {
    "text": "matured in that year and so as we started to think about what's next we started to",
    "start": "501120",
    "end": "507720"
  },
  {
    "text": "very quickly align against get Ops it had the maturity that we were looking for our teams were comfortable with it",
    "start": "507720",
    "end": "513539"
  },
  {
    "text": "because the team's already using git today we're doing PR's today it was a metaphor that they were very comfortable",
    "start": "513539",
    "end": "518580"
  },
  {
    "text": "with key to us and you'll learn a little bit more as Anita jumps in and shows some more details about our multi-tenant",
    "start": "518580",
    "end": "524520"
  },
  {
    "text": "approach key to us was being able to eloquently handle that multi-tenant architecture that that tenant of tenants",
    "start": "524520",
    "end": "531720"
  },
  {
    "text": "scenario and what we found pretty quickly and we we were looking at various options we looked at Argo we",
    "start": "531720",
    "end": "537360"
  },
  {
    "text": "looked at flux we found fairly quickly that flux really shined in that",
    "start": "537360",
    "end": "542580"
  },
  {
    "text": "multi-tenant scenario for us and it did it in a way that was we felt was relatively a simple and simple to",
    "start": "542580",
    "end": "550380"
  },
  {
    "text": "understand uh and then of course the flux Community is fantastic when we had",
    "start": "550380",
    "end": "555480"
  },
  {
    "text": "some hesitations like oh we're getting into something really new right we started reaching out to the slack Channel a few other at a few other",
    "start": "555480",
    "end": "561779"
  },
  {
    "text": "locations we were getting really great vibes from the community a lot to support very responsive to the questions",
    "start": "561779",
    "end": "567540"
  },
  {
    "text": "and answers and we felt really comfortable about getting involved with something uh that is relatively new so",
    "start": "567540",
    "end": "574019"
  },
  {
    "text": "kind of content conscious in mind uh about what our journey kind of looked like some of our bumps along the lines",
    "start": "574019",
    "end": "579899"
  },
  {
    "text": "uh uh I'm gonna go ahead and pass off Danita and she's going to kind of talk a little bit about what our solution",
    "start": "579899",
    "end": "585720"
  },
  {
    "text": "actually looked like and some of the best practices around it yep thanks Josh and just to add to what Josh said it was",
    "start": "585720",
    "end": "592800"
  },
  {
    "text": "not just only the slack Channel but they had a really good examples available online from their GitHub repository that",
    "start": "592800",
    "end": "598380"
  },
  {
    "text": "we could just take in and then customize it uh pun intended customize it for for",
    "start": "598380",
    "end": "603839"
  },
  {
    "text": "our use case right so I'm just going to start with my first example uh which is like a multi uh excuse me a mono",
    "start": "603839",
    "end": "611279"
  },
  {
    "text": "repository example right so as our keynote speaker said this morning Christy that you copy paste and then you",
    "start": "611279",
    "end": "619920"
  },
  {
    "text": "evaluate and then you customize right so that is exactly what we did we did that we took up their example for mono",
    "start": "619920",
    "end": "625800"
  },
  {
    "text": "repository and then you know what we have here is apps these apps are",
    "start": "625800",
    "end": "631320"
  },
  {
    "text": "customer specific apps right so you see on the base we have identity subsystem which has bunch of Market service and so",
    "start": "631320",
    "end": "636600"
  },
  {
    "text": "does processor subsystem uh and then you know each customer has",
    "start": "636600",
    "end": "643200"
  },
  {
    "text": "their own Kafka topics and so on so forth right so that's all defined here in apps uh and then in infra infra is",
    "start": "643200",
    "end": "648959"
  },
  {
    "text": "something you know that's shared across all of the tenants you know on on any particular cluster so there you know we",
    "start": "648959",
    "end": "654000"
  },
  {
    "text": "would have like whatever slimsy operator or like you know cada operator and so on and so forth you know that's shared",
    "start": "654000",
    "end": "659220"
  },
  {
    "text": "across the across the tenants that's what we Define in infra and then obviously in clusters you know you",
    "start": "659220",
    "end": "664320"
  },
  {
    "text": "bootstrap your your flux and then you know you point it to whatever um uh communities cluster you're",
    "start": "664320",
    "end": "670740"
  },
  {
    "text": "pointing it to and in our for this demo we have it in on dev and proud that they're calling it but they both are our",
    "start": "670740",
    "end": "676079"
  },
  {
    "text": "Docker desktops running here locally on our Mac just for this demo uh and then obviously we have tenants right so this",
    "start": "676079",
    "end": "682740"
  },
  {
    "text": "is where we thought that flux came in like to rescue us like you know and then",
    "start": "682740",
    "end": "688380"
  },
  {
    "text": "just instantly worked for us so these are our actual tenants right the tenants that are using our product so when we",
    "start": "688380",
    "end": "693779"
  },
  {
    "text": "onboard them we do nothing but like you know create a PR or or an auto commit to",
    "start": "693779",
    "end": "699839"
  },
  {
    "text": "this repository and add a folder there and we will see a demo of that later but this is a repository structure",
    "start": "699839",
    "end": "706320"
  },
  {
    "text": "pretty standard practice that flux suggests like you know to have your repository structure like that so this is what I have here and here like you",
    "start": "706320",
    "end": "712920"
  },
  {
    "text": "know in in here if you see underneath that cluster what I have is an infra Dot",
    "start": "712920",
    "end": "718140"
  },
  {
    "text": "yaml and a tenants.yaml which is pointing to those folders in the repository right so my infra is pointing",
    "start": "718140",
    "end": "724079"
  },
  {
    "text": "to an infra Dev and then obviously you know my tenant is pointing to to tenants",
    "start": "724079",
    "end": "729120"
  },
  {
    "text": "Dev uh and and this is if you see it is under cluster Dev right and then similarly I have underneath prod I have",
    "start": "729120",
    "end": "735959"
  },
  {
    "text": "again the infra and prod which if you notice on line number 11 it's pointing to tenants prod uh Pat which is this pad",
    "start": "735959",
    "end": "743160"
  },
  {
    "text": "so each of those environments will get the tenants that are defined in in in in that directory all right so I'm going to",
    "start": "743160",
    "end": "749700"
  },
  {
    "text": "show you uh how this looks on the on the cluster and again as I mentioned this is my Docker desktop here uh if I see here",
    "start": "749700",
    "end": "757200"
  },
  {
    "text": "what are all the hand releases I have right and then you see look at look at look at the power here like you know I",
    "start": "757200",
    "end": "762839"
  },
  {
    "text": "can customize my hand releases so I have defined them in base but then I'm applying patches and my hand releases",
    "start": "762839",
    "end": "768000"
  },
  {
    "text": "are now customer specific I have an Acme identity service sound release and then",
    "start": "768000",
    "end": "773100"
  },
  {
    "text": "obviously I also have a contoso identity service number is diagonal so pretty much the same exact camera this is but",
    "start": "773100",
    "end": "779459"
  },
  {
    "text": "then for each of them each of the customers I also have here if I look at",
    "start": "779459",
    "end": "785100"
  },
  {
    "text": "the Kafka topics let's see if I've gotten my Kafka topics for each of those tenants right so I have an acne topic a",
    "start": "785100",
    "end": "791459"
  },
  {
    "text": "contoso topic and and so on and so forth right and if I go take a look at my pods here uh this is what is really important",
    "start": "791459",
    "end": "799200"
  },
  {
    "text": "for us because each of the tenants are running in their own namespaces right all of their resources are in their own",
    "start": "799200",
    "end": "804360"
  },
  {
    "text": "namespace and right here multi-tenancy writing they have their own service account they have their own access to secrets and so on and so forth",
    "start": "804360",
    "end": "810779"
  },
  {
    "text": "everything is locked down by their namespace and right here I have like those two pods for Acme and if I go in",
    "start": "810779",
    "end": "817019"
  },
  {
    "text": "conto so I have their pods in here and obviously I'm using a again from flux for this demo I'm using their pod info",
    "start": "817019",
    "end": "823459"
  },
  {
    "text": "pod so if I were to go take your own browser and go to one of those ports it",
    "start": "823459",
    "end": "829380"
  },
  {
    "text": "is the part info standard app running in there now what I would like to ask here to Josh like if you see here on my",
    "start": "829380",
    "end": "835980"
  },
  {
    "text": "repository in both of these clusters I have only two tenants right I have Acme and contoso and I would like uh Josh to",
    "start": "835980",
    "end": "845399"
  },
  {
    "text": "merge my PR so here I have a pre uh can like you know PR up here opened against",
    "start": "845399",
    "end": "852120"
  },
  {
    "text": "my repository which is onboarding aviati aviado for for demo and here what I'm",
    "start": "852120",
    "end": "858420"
  },
  {
    "text": "doing is just adding a commit to to the git repository and what the effect",
    "start": "858420",
    "end": "864060"
  },
  {
    "text": "should be is I should be seeing pods for this new customer I should see I haven't",
    "start": "864060",
    "end": "869100"
  },
  {
    "text": "released actually a Kafka topic for this for this customer or our tenant and Josh please go ahead March this PR",
    "start": "869100",
    "end": "877639"
  },
  {
    "text": "I'm using the handy GitHub app here so uh real time here we're going to merge this and see if this works uh",
    "start": "878519",
    "end": "886519"
  },
  {
    "text": "all right is it all right successfully merged and closed",
    "start": "890220",
    "end": "896820"
  },
  {
    "text": "right yep all right okay let's explore yeah let's let's go on on open lens and",
    "start": "896820",
    "end": "901860"
  },
  {
    "text": "see if I have gotten a new name space uh maybe not yet let's let's go ahead and take a look at the reconciliation uh so",
    "start": "901860",
    "end": "908820"
  },
  {
    "text": "if I go on the customization and um look at my tenant customization let's",
    "start": "908820",
    "end": "914279"
  },
  {
    "text": "see if it's if it's what's the state maybe it's reconciling um and eventually like you know I should",
    "start": "914279",
    "end": "920339"
  },
  {
    "text": "have um a new namespace and a new hand release uh all right here here it is so",
    "start": "920339",
    "end": "927120"
  },
  {
    "text": "I've got my I've got my new uh tenant my new",
    "start": "927120",
    "end": "933420"
  },
  {
    "text": "customer here running all of the pods that it's supposed to supposed to run obviously what is defined on the Basin",
    "start": "933420",
    "end": "939420"
  },
  {
    "text": "and and and and in the in the dev uh pads for that all right so this is pretty straightforward right you know uh",
    "start": "939420",
    "end": "946560"
  },
  {
    "text": "it's it's what flux promises to do and that is what it is here but in in reality we have a mono repository",
    "start": "946560",
    "end": "952740"
  },
  {
    "text": "structure right so we have for each of our um",
    "start": "952740",
    "end": "958019"
  },
  {
    "text": "for each of our um uh tenants or our customer apps or like",
    "start": "958019",
    "end": "963600"
  },
  {
    "text": "you know um their their Kafka or data requirements and so on and so forth like you know we have uh multiple repository",
    "start": "963600",
    "end": "970199"
  },
  {
    "text": "structure in reality and like you know these are some of the best practices that we follow on top of whatever I showed you here in the demo right so uh",
    "start": "970199",
    "end": "977459"
  },
  {
    "text": "if if I go and take a look at all my repositories here so the ones that are in green are the customer agnostic",
    "start": "977459",
    "end": "983399"
  },
  {
    "text": "deployments right and the ones that are in yellow are customer specific deployments so how do I make it all",
    "start": "983399",
    "end": "988920"
  },
  {
    "text": "available uh when flux is reconciling right so we have bunch of include there",
    "start": "988920",
    "end": "994019"
  },
  {
    "text": "right and uh everything is getting accumulated there on on the customization uh everything is is uh",
    "start": "994019",
    "end": "1001100"
  },
  {
    "text": "pulled in from different repositories and then pushed to the push to the cluster right so that is one of the uh",
    "start": "1001100",
    "end": "1006500"
  },
  {
    "text": "feature standard feature from flux that that we use another is is a flux diff it",
    "start": "1006500",
    "end": "1011839"
  },
  {
    "text": "is a very um powerful tool that flux gives us so even before I deploy or merge the pr to",
    "start": "1011839",
    "end": "1020540"
  },
  {
    "text": "see what the state would be on the cluster we have flux diff that we run our on our GitHub actions and then this",
    "start": "1020540",
    "end": "1026780"
  },
  {
    "text": "will tell me oh by the way if you were to merge this commit it's going to break on the cluster for this particular",
    "start": "1026780",
    "end": "1032058"
  },
  {
    "text": "reason right so then we go ahead and we fix our things because you know we are using plug stiff as part of our",
    "start": "1032059",
    "end": "1037339"
  },
  {
    "text": "continuous integration so that's really powerful that that we use and yet another thing is",
    "start": "1037339",
    "end": "1043339"
  },
  {
    "text": "um obviously like you know alerts and and notifications so we have both like a provider for slack and for grafana and",
    "start": "1043339",
    "end": "1050480"
  },
  {
    "text": "here you see like you know uh flux is constantly Recon filing and sending us notifications and we have like a slack",
    "start": "1050480",
    "end": "1057620"
  },
  {
    "text": "and grafana and we also have generic web hooks that we do certain things based on those so we are using all of that and",
    "start": "1057620",
    "end": "1064220"
  },
  {
    "text": "also something really important for us is post-built variable substitution like as you can see you know we have a bunch",
    "start": "1064220",
    "end": "1071240"
  },
  {
    "text": "of clusters like you know Dev clusters and staging and integration in us uh uh",
    "start": "1071240",
    "end": "1076580"
  },
  {
    "text": "best to region I can obviously we do on AWS but then we also have on in in EU",
    "start": "1076580",
    "end": "1081620"
  },
  {
    "text": "Central and so on and so forth right so here we rely heavily on this post-built",
    "start": "1081620",
    "end": "1086960"
  },
  {
    "text": "substitution because you know each of the environments have different uh values for for those things like you",
    "start": "1086960",
    "end": "1092960"
  },
  {
    "text": "know so we obviously uh use um Define them and then we use them depending on when we where we are",
    "start": "1092960",
    "end": "1098840"
  },
  {
    "text": "sending our um our workloads to so that's again really one of the best practices and really good tool that uh",
    "start": "1098840",
    "end": "1105860"
  },
  {
    "text": "customize along with flux providers that that that we use heavily so uh along",
    "start": "1105860",
    "end": "1111380"
  },
  {
    "text": "with along with like you know all of these things uh it is serving us really well because what happens now is I'm",
    "start": "1111380",
    "end": "1118100"
  },
  {
    "text": "onboarding a tenant by uh an automatic commit but then also I'm off-boarding",
    "start": "1118100",
    "end": "1123559"
  },
  {
    "text": "them when they are done using our product I'm off boarding them by just sending another commit and removing that",
    "start": "1123559",
    "end": "1129260"
  },
  {
    "text": "folder aviato from my repository which flux then reconcise because it has the",
    "start": "1129260",
    "end": "1135559"
  },
  {
    "text": "The Purge set to set to true so if you look at my tenants.com summer here you see line",
    "start": "1135559",
    "end": "1141860"
  },
  {
    "text": "number 12 excuse me not Purge prune true which means that if for resources and found on that path it will automatically",
    "start": "1141860",
    "end": "1148580"
  },
  {
    "text": "go ahead and clean up all the resources and then delete the namespace so you know I I don't have to keep notes and",
    "start": "1148580",
    "end": "1154940"
  },
  {
    "text": "reminders for myself oh by the way this tenant is offloaded go ahead something wasn't deleted or like you know so so",
    "start": "1154940",
    "end": "1160640"
  },
  {
    "text": "nothing in there everything happens just automatically with that yeah and and",
    "start": "1160640",
    "end": "1166039"
  },
  {
    "text": "I'll add to the off-boarding piece and this is a a something that was really meaningful for us internally and I think",
    "start": "1166039",
    "end": "1172220"
  },
  {
    "text": "different folks probably had some experience uh with traditional like more of a more of a push kind of model we",
    "start": "1172220",
    "end": "1180080"
  },
  {
    "text": "were onboarding particular tenants maybe we had had a trial or we were doing a POV POC with a customer and they were",
    "start": "1180080",
    "end": "1186919"
  },
  {
    "text": "ready to to buy for example and we wanted to have a formal environment for them or even in Dev and lower",
    "start": "1186919",
    "end": "1192559"
  },
  {
    "text": "environments we were always spinning up like you know practice environments and test environments uh uh and then we'd",
    "start": "1192559",
    "end": "1198140"
  },
  {
    "text": "off-board them and stuff will get left behind and they're like zombies on your",
    "start": "1198140",
    "end": "1203240"
  },
  {
    "text": "on your cluster and and and except they're very expensive zombies uh and",
    "start": "1203240",
    "end": "1209240"
  },
  {
    "text": "and that was a big problem for us and the desired State kind of model was really attractive especially for",
    "start": "1209240",
    "end": "1215240"
  },
  {
    "text": "off-boarding because we had a great deal of assurity that those resources would actually get cleaned up and we weren't",
    "start": "1215240",
    "end": "1221360"
  },
  {
    "text": "paying for all these zombies uh sitting around in all of our environments especially our lower environments uh",
    "start": "1221360",
    "end": "1226640"
  },
  {
    "text": "where developers would spin up a new tenant to test with and then spin it back down and do that 10 times a day and",
    "start": "1226640",
    "end": "1232460"
  },
  {
    "text": "each time something would go wrong and 20 of it would be left over right and that adds up day after day week after",
    "start": "1232460",
    "end": "1238039"
  },
  {
    "text": "week right and it also added a burden onto our devops team because there was always like some manual cleanup that",
    "start": "1238039",
    "end": "1244039"
  },
  {
    "text": "needed to happen right and so this model this multi-tenancy model uh uh the",
    "start": "1244039",
    "end": "1249559"
  },
  {
    "text": "multi-tenancy of multi-tenancy really really helped us not only save on the",
    "start": "1249559",
    "end": "1254780"
  },
  {
    "text": "complexity but on a lot of the costs as well so that's real go ahead sorry there we go so so let's in the last few",
    "start": "1254780",
    "end": "1262580"
  },
  {
    "text": "minutes we have here and and we'll leave some time for some questions as well uh there's a few learnings that we had from",
    "start": "1262580",
    "end": "1268940"
  },
  {
    "text": "this right uh uh uh and no products perfect uh uh there's always pain points right and and these are a few of the key",
    "start": "1268940",
    "end": "1276440"
  },
  {
    "text": "learnings that we had coming out of this uh our organization relied heavily on Helm charts right and one of the things",
    "start": "1276440",
    "end": "1283940"
  },
  {
    "text": "that's super valuable especially in production uh with flux is the ability to do drift detection right someone goes",
    "start": "1283940",
    "end": "1289760"
  },
  {
    "text": "in you know and goes in and says you know I'm just going to delete this x resource right I'm going to delete whatever it may be and and there's a",
    "start": "1289760",
    "end": "1297080"
  },
  {
    "text": "self-repair aspect of it right that'll repair itself uh pretty quickly and that works as expected for typical",
    "start": "1297080",
    "end": "1303380"
  },
  {
    "text": "deployments uh if you're deploying with the ammo you're the normal manifests uh uh or if you're even using uh customize",
    "start": "1303380",
    "end": "1310400"
  },
  {
    "text": "it works as expected one of the challenges we had is that",
    "start": "1310400",
    "end": "1315520"
  },
  {
    "text": "traditionally and this has changed but the helm charts didn't have the same level of drip detection that we expected",
    "start": "1315520",
    "end": "1322520"
  },
  {
    "text": "uh and and what that meant is is that someone went in and messed with a resource if they deleted the helm chart",
    "start": "1322520",
    "end": "1328400"
  },
  {
    "text": "things would reconcile it would come back but if they deleted a resource that the helm chart deployed then we didn't",
    "start": "1328400",
    "end": "1335240"
  },
  {
    "text": "get some of the expected Behavior now it's worth mentioning we were able to work around this issue with",
    "start": "1335240",
    "end": "1340880"
  },
  {
    "text": "notifications and some of the different tools that we had that that Nita showed you about understanding when things are",
    "start": "1340880",
    "end": "1346520"
  },
  {
    "text": "happening uh and we were able to get around that but it caused us a few hiccups but luckily there's actually a a",
    "start": "1346520",
    "end": "1353360"
  },
  {
    "text": "new and I believe it's in preview yeah no it's in preview to to manage uh when",
    "start": "1353360",
    "end": "1360200"
  },
  {
    "text": "you're using Helm charts to do the drift detection that you expect so even though it was a pain point for us if this is new for your environments it may not be",
    "start": "1360200",
    "end": "1367580"
  },
  {
    "text": "a pain point for you guys but it is we will be waiting until it goes GA so if we have a little bit of there the other",
    "start": "1367580",
    "end": "1373280"
  },
  {
    "text": "aspect that causes a few challenges there's no real super powerful admin",
    "start": "1373280",
    "end": "1378679"
  },
  {
    "text": "console right now once again we were able to kind of address this by spinning",
    "start": "1378679",
    "end": "1384200"
  },
  {
    "text": "up some really nice uh grafana charts we had lots of telemetry we had no shortage of data points coming in we had no",
    "start": "1384200",
    "end": "1390260"
  },
  {
    "text": "shortage of visibility but for folks who weren't familiar with flux and they were",
    "start": "1390260",
    "end": "1395720"
  },
  {
    "text": "like just give me a web page I can hit that shows me admin stuff right we didn't quite have that experience so we",
    "start": "1395720",
    "end": "1401480"
  },
  {
    "text": "had to do a little bit of work ahead of time to deliver on some full featured Helm chart I'm sorry full feature",
    "start": "1401480",
    "end": "1407000"
  },
  {
    "text": "grafana charts and some other dashboarding tools that allowed us to kind of get the visibility for the folks",
    "start": "1407000",
    "end": "1412100"
  },
  {
    "text": "that needed it the other thing we ran into is in we're in a very large environment hundreds of microservices",
    "start": "1412100",
    "end": "1417980"
  },
  {
    "text": "right and as you probably noticed uh even more so when we're doing tenant specific right and what we found over",
    "start": "1417980",
    "end": "1424640"
  },
  {
    "text": "time as well is that we had to kind of tweak a little bit of how often we want to reconcile certain types of resources",
    "start": "1424640",
    "end": "1430159"
  },
  {
    "text": "so we want to reconcile our tenant specific resources pretty quickly because they might be spinning up and spinning down",
    "start": "1430159",
    "end": "1436400"
  },
  {
    "text": "we deploy things like neo4j and and  and other aspects those we don't",
    "start": "1436400",
    "end": "1442940"
  },
  {
    "text": "need to reconcile too often if we're reconciling those too often we're probably doing something wrong right so uh all those reconciliations uh do cause",
    "start": "1442940",
    "end": "1450799"
  },
  {
    "text": "overhead in the cluster and and these days with you know hundreds of operators from various Solutions all landing on",
    "start": "1450799",
    "end": "1456020"
  },
  {
    "text": "your cluster right uh we found that we needed to tweak a little bit of uh uh that that reconciliation how often how",
    "start": "1456020",
    "end": "1462860"
  },
  {
    "text": "frequently we want to reconcile stuff because we were adding a lot of unneeded overhead uh onto our cluster with",
    "start": "1462860",
    "end": "1468919"
  },
  {
    "text": "frequent unneeded reconcile uh Cycles uh the last thing this is more of a more of",
    "start": "1468919",
    "end": "1474260"
  },
  {
    "text": "an interesting antidote is uh most people here are probably familiar with the garbage in garbage out uh uh kind of",
    "start": "1474260",
    "end": "1480500"
  },
  {
    "text": "a statement if you have badly defined deployments",
    "start": "1480500",
    "end": "1487340"
  },
  {
    "text": "they stand out exceedingly 10 times more when you're doing flux because every",
    "start": "1487340",
    "end": "1494059"
  },
  {
    "text": "time you reconcile it will let you know that you're doing something you shouldn't be doing as opposed to what",
    "start": "1494059",
    "end": "1499940"
  },
  {
    "text": "would normally take the place of manual so uh the quick story that that we were telling is that and luckily this was",
    "start": "1499940",
    "end": "1505460"
  },
  {
    "text": "just in Dev uh um most folks are are aware of different policies and",
    "start": "1505460",
    "end": "1510500"
  },
  {
    "text": "kubernetes around persistent storage and non-persistent storage and if you don't Define your storage",
    "start": "1510500",
    "end": "1516919"
  },
  {
    "text": "would the way that you want to Define your storage to be maybe more persistent uh and someone maybe happens to and Dev",
    "start": "1516919",
    "end": "1523820"
  },
  {
    "text": "goes and deletes something uh uh and flux will reconcile it you will lose that storage right so it's",
    "start": "1523820",
    "end": "1531740"
  },
  {
    "text": "not a flux thing but it made a a maybe some QA challenges in lower environments",
    "start": "1531740",
    "end": "1537799"
  },
  {
    "text": "before you know the the manifests were fully qaed a little bit more challenging because it became evident very very",
    "start": "1537799",
    "end": "1544580"
  },
  {
    "text": "quickly when you have a problem right yeah so garbage and garbage or we could put it in a day but flux made us fix our",
    "start": "1544580",
    "end": "1550220"
  },
  {
    "text": "deployments made us like you know aware of oh we should have a a volume policy",
    "start": "1550220",
    "end": "1555740"
  },
  {
    "text": "attached to to our volume like you know whether we want to retain it or whether we want to delete it so it brought some",
    "start": "1555740",
    "end": "1561380"
  },
  {
    "text": "of the inconsistencies or some of the things that we overlooked to write on our face that hey we gotta go fix this",
    "start": "1561380",
    "end": "1566960"
  },
  {
    "text": "so yeah which is both once again a blessing and a kind of a curse kind of thing right uh",
    "start": "1566960",
    "end": "1572779"
  },
  {
    "text": "one thing I want to mention as we kind of wrap and and and and open up uh for for any questions is uh um the demo that",
    "start": "1572779",
    "end": "1581659"
  },
  {
    "text": "Nita did that's all available up on a GitHub repo uh and yes it's up there the",
    "start": "1581659",
    "end": "1588020"
  },
  {
    "text": "demo code is on there you can clone that and run it there is we tried to make it so that you could",
    "start": "1588020",
    "end": "1593779"
  },
  {
    "text": "take and apply our learnings but didn't have all the crazy dependencies that we had right so you can actually pull this",
    "start": "1593779",
    "end": "1600020"
  },
  {
    "text": "down and and use it as is uh and explore how we were able to do multi-tenancy of",
    "start": "1600020",
    "end": "1606080"
  },
  {
    "text": "multi-tenancy uh with some uh uh pretty simple use cases we we had a little bit",
    "start": "1606080",
    "end": "1611179"
  },
  {
    "text": "of extras in there with a Kafka cluster and deploying topics so that you could kind of better understand some of the",
    "start": "1611179",
    "end": "1617059"
  },
  {
    "text": "common dependencies that you have when you're deploying these uh as well but uh a couple quick uh resources obviously",
    "start": "1617059",
    "end": "1623840"
  },
  {
    "text": "one of our best experience was working with the flux Community uh definitely check out uh that flux Community Link on",
    "start": "1623840",
    "end": "1631400"
  },
  {
    "text": "there and they'll be able to explore how to kind of reach out to the community Through slack channels and other mechanisms really really helped us on",
    "start": "1631400",
    "end": "1638059"
  },
  {
    "text": "our initial Journey reducing a lot of pain and obviously follow if you're interested in flux follow that getting",
    "start": "1638059",
    "end": "1643100"
  },
  {
    "text": "started guide uh and and and for both need and myself please reach out to us",
    "start": "1643100",
    "end": "1648140"
  },
  {
    "text": "on LinkedIn go ahead and feel free to connect with us we're happy to uh answer questions and uh and I think at this",
    "start": "1648140",
    "end": "1655279"
  },
  {
    "text": "point in time did you have anything else you wanted to add no this is this is great we love flux yeah yeah it solves our problems so",
    "start": "1655279",
    "end": "1661880"
  },
  {
    "text": "thank you and we've got just a few minutes left for questions if you'd like to uh",
    "start": "1661880",
    "end": "1666980"
  },
  {
    "text": "if there's any questions from the audience no questions okay great thank you thank",
    "start": "1666980",
    "end": "1674179"
  },
  {
    "text": "you so much for joining us [Applause]",
    "start": "1674179",
    "end": "1680900"
  },
  {
    "text": "yep okay that's awesome topic works too yeah fire away please",
    "start": "1680900",
    "end": "1685720"
  },
  {
    "text": "oh good question sorry uh so what tools or how did you",
    "start": "1691340",
    "end": "1698659"
  },
  {
    "text": "determine what intervals to use for your reconciliation right after the fact so so we didn't use any tool but",
    "start": "1698659",
    "end": "1705240"
  },
  {
    "text": "[Music] for example what are some of the things that are changing more frequently than",
    "start": "1705240",
    "end": "1710840"
  },
  {
    "text": "other right so let's say if I have a micro service for a for a for a tenant that is not changing as often that can",
    "start": "1710840",
    "end": "1717200"
  },
  {
    "text": "be reconciled at a at a higher frequency like you know maybe 30 minutes or 40 minutes like you know I could I could do",
    "start": "1717200",
    "end": "1722360"
  },
  {
    "text": "that for for that but if there is something that is changing often then that is like you know reconciliation uh",
    "start": "1722360",
    "end": "1728840"
  },
  {
    "text": "um uh faster so for example if I'm on boarding in Dev I get like you know",
    "start": "1728840",
    "end": "1734120"
  },
  {
    "text": "hundreds of tenants every day so I'm reconciling my tenant my my frequency on my tenant customization is",
    "start": "1734120",
    "end": "1741980"
  },
  {
    "text": "much shorter uh versus like you know uh my microservices and changing as often like you know is this just done and then",
    "start": "1741980",
    "end": "1748279"
  },
  {
    "text": "and I know that we are not working on it that stays longer but uh we did not use any tool it's just like a usage pattern",
    "start": "1748279",
    "end": "1754640"
  },
  {
    "text": "and uh some of the best practices from plugs uh if I have a lot many reconciliations happening I gotta tweak",
    "start": "1754640",
    "end": "1762080"
  },
  {
    "text": "my um uh controller uh Source controller or or customized controller so so I just",
    "start": "1762080",
    "end": "1770059"
  },
  {
    "text": "practice like you know the best practices for the documentation and then I just make sure I'm running the right number of threats for so for your",
    "start": "1770059",
    "end": "1776720"
  },
  {
    "text": "infrastruct stuff it's going to be like quite a long reconciliation versus your",
    "start": "1776720",
    "end": "1782179"
  },
  {
    "text": "correct correct correct right and and what we are thinking uh as as we are learning from it maybe instead of doing",
    "start": "1782179",
    "end": "1789500"
  },
  {
    "text": "all of the infra together in one customization maybe we can break it uh so so some of the things like you know",
    "start": "1789500",
    "end": "1795620"
  },
  {
    "text": "that we want to reconciliation uh often that can be as part of one customization",
    "start": "1795620",
    "end": "1801200"
  },
  {
    "text": "and and something that is like you know can I be there like you know happy go lucky stays there forever could be",
    "start": "1801200",
    "end": "1806240"
  },
  {
    "text": "another customer same is for tenants like you know I could have uh right now I just showed like one customization for",
    "start": "1806240",
    "end": "1811460"
  },
  {
    "text": "the entire tenant directory I could have it like you know do it by uh maybe",
    "start": "1811460",
    "end": "1816620"
  },
  {
    "text": "um what are the customers that are paying me money more money what are my my bigger customer they get",
    "start": "1816620",
    "end": "1822080"
  },
  {
    "text": "reconciliation uh faster than my other customers so things like that yeah and it's it's important to know that too",
    "start": "1822080",
    "end": "1828440"
  },
  {
    "text": "from the standpoint of like you're going to know that you need to do this because you're like why am I",
    "start": "1828440",
    "end": "1834080"
  },
  {
    "text": "keeping on having to increase my resources and sources over and over again right and to a certain extent you",
    "start": "1834080",
    "end": "1839299"
  },
  {
    "text": "run into you there's a potential running kind of like a deadlock scenario right because reconciliations you know that",
    "start": "1839299",
    "end": "1845419"
  },
  {
    "text": "that because the frequency of them so the trigger was is we were looking at resource utilization of all of our",
    "start": "1845419",
    "end": "1851480"
  },
  {
    "text": "operators on you know and there's so many operations these days right that that we were like okay we we probably",
    "start": "1851480",
    "end": "1857840"
  },
  {
    "text": "need to do something better about this and I think the key thing too is is keep it simple at first I think you've probably heard that in a lot of",
    "start": "1857840",
    "end": "1863179"
  },
  {
    "text": "conversations in a lot of presentations is is iteration is the key uh you can absolutely overthink this and you can",
    "start": "1863179",
    "end": "1870620"
  },
  {
    "text": "over architect this and and it's easy to do you can come up with some crazy directory structures and you can go the",
    "start": "1870620",
    "end": "1877399"
  },
  {
    "text": "other end of we had a monorepa for the demo and then for something very simple and straightforward you you know you",
    "start": "1877399",
    "end": "1883880"
  },
  {
    "text": "have 10 repos right uh breaking things out and so uh keep it simple uh uh and",
    "start": "1883880",
    "end": "1890240"
  },
  {
    "text": "watch the Telemetry and it will guide you on kind of what direction you need to grow watch you know uh how the the",
    "start": "1890240",
    "end": "1896720"
  },
  {
    "text": "patterns that the developers are doing PR's on right what are they triggering so on and so forth and and the nice",
    "start": "1896720",
    "end": "1902059"
  },
  {
    "text": "thing is and once again we had a really good experience with working with flux it was super flexible to allow us to evolve it wasn't a big deal to go okay",
    "start": "1902059",
    "end": "1909679"
  },
  {
    "text": "we need a little bit more structure here or here let's pull this out put it in a different repo it wasn't a big deal it",
    "start": "1909679",
    "end": "1915080"
  },
  {
    "text": "wasn't a scary thing uh to be able to do that yeah another thing is also what it",
    "start": "1915080",
    "end": "1920419"
  },
  {
    "text": "does good for us is the",
    "start": "1920419",
    "end": "1923380"
  },
  {
    "text": "needs B and C and D before it can reconcile that right so I can do that on",
    "start": "1925460",
    "end": "1931039"
  },
  {
    "text": "my hand release uh throw in the dependencies that it need and what it means that flux will only make sure that",
    "start": "1931039",
    "end": "1937159"
  },
  {
    "text": "the dependencies are available before it reconciles that chart again right so I'm defining those for my hand releases so",
    "start": "1937159",
    "end": "1944179"
  },
  {
    "text": "it is not constantly like you know so we don't have a we don't want a scenario",
    "start": "1944179",
    "end": "1949580"
  },
  {
    "text": "where we're spinning up a service that uses a topic that hasn't been created yet yeah we're referencing the database that hasn't been created yet things like",
    "start": "1949580",
    "end": "1955520"
  },
  {
    "text": "that so but good question good question any other questions",
    "start": "1955520",
    "end": "1961898"
  },
  {
    "text": "flux creators are we doing things right is there anything we can improve for flux",
    "start": "1963260",
    "end": "1969440"
  },
  {
    "text": "creators did we just scare you yeah so I guess right now you know we",
    "start": "1969440",
    "end": "1976700"
  },
  {
    "text": "have maybe like a bunch of customers right but we are we are definitely looking into seeing you",
    "start": "1976700",
    "end": "1983539"
  },
  {
    "text": "know once we have like customers in thousands how how are we going to scale our our flux controllers like and",
    "start": "1983539",
    "end": "1990140"
  },
  {
    "text": "obviously we're going to have some uh oh my gosh Kana moments and we will reach out to you and obviously we're going to",
    "start": "1990140",
    "end": "1996019"
  },
  {
    "text": "fine tune our our controllers to to see and we're going to iterate right we're going to work and hopefully we'll come back here and maybe maybe next year and",
    "start": "1996019",
    "end": "2003159"
  },
  {
    "text": "say this is what happened when we have 5 000 customers right and this is what we did it's a good place to have 5000",
    "start": "2003159",
    "end": "2009220"
  },
  {
    "text": "customers it's a good problem right it's a good problem to have but we're pretty confident where we landed in this and",
    "start": "2009220",
    "end": "2014380"
  },
  {
    "text": "we're having uh some really really good early and Midterm successes on this uh our developers are happy with it we feel",
    "start": "2014380",
    "end": "2020140"
  },
  {
    "text": "like we're getting the velocity that we want from it so uh we're we're pretty happy with where we landed but we know we're going to learn we're going to grow",
    "start": "2020140",
    "end": "2025960"
  },
  {
    "text": "we're going to probably make some mistakes and and uh and hopefully we'll we'll we'll share those and what we did for them so",
    "start": "2025960",
    "end": "2032860"
  },
  {
    "text": "yes",
    "start": "2032860",
    "end": "2035460"
  },
  {
    "text": "say that again sharding support no no no have you seen the new sharding something no no I have",
    "start": "2039059",
    "end": "2045340"
  },
  {
    "text": "not no you should check it out all right okay all right thank you for giving us a good homework yes we have some homework",
    "start": "2045340",
    "end": "2051220"
  },
  {
    "text": "now sorry support absolutely well that would be improved with that what would be improved uh what you can what you can",
    "start": "2051220",
    "end": "2056980"
  },
  {
    "text": "do is if your flux controllers are bottlenecking because you have too many I'm I'm assuming you're going to need",
    "start": "2056980",
    "end": "2062800"
  },
  {
    "text": "this before you hit five or ten thousand uh customers because we have a couple of people who said this is a blocker for us",
    "start": "2062800",
    "end": "2069158"
  },
  {
    "text": "okay so it was um sort of fast-tracked into the ga so it's in uh",
    "start": "2069159",
    "end": "2076060"
  },
  {
    "text": "I think we have 2.0.0 rc.2 now um",
    "start": "2076060",
    "end": "2081099"
  },
  {
    "text": "so you can you can check it out and see if it solves a problem for you and and",
    "start": "2081099",
    "end": "2086980"
  },
  {
    "text": "please mention your name oh I'm Kingdom I'm a flux maintainer there you go thank",
    "start": "2086980",
    "end": "2092020"
  },
  {
    "text": "you you're on record now so but thank you so much I hope everybody I know this is last show of",
    "start": "2092020",
    "end": "2098020"
  },
  {
    "text": "the day but uh I hope everybody is not there's more okay there's more sorry thanks",
    "start": "2098020",
    "end": "2103420"
  },
  {
    "text": "we're still we're still going okay well enjoy the rest of the day and enjoy the rest of the conference thank you very much",
    "start": "2103420",
    "end": "2110338"
  }
]
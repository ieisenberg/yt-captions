[
  {
    "text": "hi everyone thank you so much for coming I am David Oren check I lead open source",
    "start": "30",
    "end": "7170"
  },
  {
    "text": "machine learning and ni lofts at Azure and I'm one of the cofounders of cube flow and very pleased to be presenting",
    "start": "7170",
    "end": "13530"
  },
  {
    "text": "with one of the other co-founders of cube flow I've never presented with him before Jeremy lui and Google wasn't that crazy",
    "start": "13530",
    "end": "21210"
  },
  {
    "text": "we were scheduled for a talk I of course was very responsible didn't show up for",
    "start": "21210",
    "end": "27150"
  },
  {
    "text": "the talk so he gave it on his own he knows a bit about cube flow so that was ok so thank you so much for the",
    "start": "27150",
    "end": "34380"
  },
  {
    "text": "opportunity to talk this is about towards 1.0 it's like Zeno's paradox",
    "start": "34380",
    "end": "39660"
  },
  {
    "text": "we're almost there we'll keep getting there we're not there yet who knows what this is anyone want to",
    "start": "39660",
    "end": "47520"
  },
  {
    "text": "think yes no nothing this is the snack it is the first machine learning thing in the",
    "start": "47520",
    "end": "54989"
  },
  {
    "text": "world invented in 1951 machine learning has been around a while and the reality",
    "start": "54989",
    "end": "61170"
  },
  {
    "text": "is you know you look at something like this right in the year 2000 it was just pipe Python basically I mean obviously",
    "start": "61170",
    "end": "67979"
  },
  {
    "text": "there were other machine learning frameworks other machine learning tools but really things started to accelerate",
    "start": "67979",
    "end": "73380"
  },
  {
    "text": "about the year 2000 2006 it was numpy 2007 there was TN o pandas scikit-learn",
    "start": "73380",
    "end": "80610"
  },
  {
    "text": "in 2010 2013 cafe was introduced 2014 deep learning for Java 2015 was a",
    "start": "80610",
    "end": "88290"
  },
  {
    "text": "Cambrian explosion of frameworks a bunch of stuff coming out and now today you have even more than that and that's",
    "start": "88290",
    "end": "95700"
  },
  {
    "text": "fantastic you see more production-ready machine learning deep learning coming",
    "start": "95700",
    "end": "101130"
  },
  {
    "text": "out than ever before and so you may say we need one more ml solution because",
    "start": "101130",
    "end": "106530"
  },
  {
    "text": "that slide isn't full enough but the reality is is that everything you saw on",
    "start": "106530",
    "end": "113280"
  },
  {
    "text": "that slide it's really focused on solving a very specific problem and that is how you build a model but when you",
    "start": "113280",
    "end": "120060"
  },
  {
    "text": "talk about bringing things to production and actually having an impact on your business this is what you actually see",
    "start": "120060",
    "end": "126270"
  },
  {
    "text": "it you know it takes just a few weeks to build a model and you know just about a year later it's still not in production",
    "start": "126270",
    "end": "133140"
  },
  {
    "text": "and here's a real-world example there's an amazing repo out there for github",
    "start": "133140",
    "end": "138360"
  },
  {
    "text": "natural language search in just two weeks they were able to demo with a Jupiter notebook then three days they",
    "start": "138360",
    "end": "144870"
  },
  {
    "text": "built a mock-up and it's ready to go and then three months later still not in production because you know it's hard",
    "start": "144870",
    "end": "151320"
  },
  {
    "text": "and and like I said the problem is this everyone in our industry tends to focus",
    "start": "151320",
    "end": "157380"
  },
  {
    "text": "on this as being the key issue but the reality is it's just a small component",
    "start": "157380",
    "end": "162750"
  },
  {
    "text": "of an overall machine learning lifecycle and and you're like wait a second have I",
    "start": "162750",
    "end": "168300"
  },
  {
    "text": "heard this before you know isn't machine isn't the idea of building many",
    "start": "168300",
    "end": "173610"
  },
  {
    "text": "micro-services and tying them together a known thing and you're right it is that's why you're at a kubernetes",
    "start": "173610",
    "end": "179400"
  },
  {
    "text": "conference that's talking about nothing but micro services and all these kind of things and this is a slide literally from four years ago co-founder of",
    "start": "179400",
    "end": "185690"
  },
  {
    "text": "kubernetes Joe betta talking about how everything at Google runs inside a",
    "start": "185690",
    "end": "191190"
  },
  {
    "text": "container and the way that we were able to bring all these micro services in this design pattern to the world was",
    "start": "191190",
    "end": "197310"
  },
  {
    "text": "through something like kubernetes and cloud native applications and that the idea that you can deploy all these",
    "start": "197310",
    "end": "204000"
  },
  {
    "text": "applications all these many elements of a workflow or a pipeline loosely couple",
    "start": "204000",
    "end": "209910"
  },
  {
    "text": "them together and then give you something that is larger than the individual parts so the question is can",
    "start": "209910",
    "end": "216000"
  },
  {
    "text": "we use kubernetes to fix this can we use kubernetes to help provide a framework in which you can coordinate all these",
    "start": "216000",
    "end": "222510"
  },
  {
    "text": "many services together that bring your machine learning to production and you can except if you want to do that you",
    "start": "222510",
    "end": "229739"
  },
  {
    "text": "have to learn all this stuff right which is not so good I promise you I know a",
    "start": "229739",
    "end": "235260"
  },
  {
    "text": "lot of data scientists and trying to sit down with them and talk about gang scheduling or you know the right",
    "start": "235260",
    "end": "240450"
  },
  {
    "text": "parameters for kube control will not make anyone happy so the answer is could",
    "start": "240450",
    "end": "246060"
  },
  {
    "text": "we work towards something like cloud native ml and obviously we think we can",
    "start": "246060",
    "end": "252000"
  },
  {
    "text": "so what would cloud native ml look like well first you might select a set of applications that you would use for your",
    "start": "252000",
    "end": "259769"
  },
  {
    "text": "overall machine learning pipeline just a few examples up there then you would",
    "start": "259769",
    "end": "264840"
  },
  {
    "text": "describe some of the scenarios areas that you would be trying to achieve with those machine learning tools and then you would have a number",
    "start": "264840",
    "end": "273050"
  },
  {
    "text": "of different infrastructure components that combine together that you would use to provision and actually execute those",
    "start": "273050",
    "end": "280639"
  },
  {
    "text": "things but the unfortunate part today is you end up doing something like this in your test matrices and everything like",
    "start": "280639",
    "end": "287719"
  },
  {
    "text": "is loosely coupled together and it looks like a nightmare so that's why with Jeremy and fish who's standing on stage",
    "start": "287719",
    "end": "295039"
  },
  {
    "text": "they're in the picture in December of 2017 we introduced cube flow and the",
    "start": "295039",
    "end": "300139"
  },
  {
    "text": "idea was to make it easy for everyone everywhere to develop deploy and manage portable distributed ml on kubernetes",
    "start": "300139",
    "end": "308000"
  },
  {
    "text": "taking the advances and all the thoughts that we had up to you know kubernetes",
    "start": "308000",
    "end": "313909"
  },
  {
    "text": "and cube flow excuse me cube flow or kubernetes and cloud native apps and bring them to ml via cube flow",
    "start": "313909",
    "end": "321849"
  },
  {
    "text": "so what that looks like is this right the same stuff you have before same tools we're not asking you to learn",
    "start": "321849",
    "end": "327560"
  },
  {
    "text": "anything new we're not even asking you to learn any new procedures or change your compute what we want to do is give",
    "start": "327560",
    "end": "333110"
  },
  {
    "text": "you a common platform so that all those components can connect to cube flow inside of cube flow you can use the same",
    "start": "333110",
    "end": "339710"
  },
  {
    "text": "standard tooling and patterns and practices that you were using before but then you're able to roll it out into the",
    "start": "339710",
    "end": "346639"
  },
  {
    "text": "same compute environment you had before so the timeline looks like this we",
    "start": "346639",
    "end": "351949"
  },
  {
    "text": "introduced it in December of 2017 and every 4 months we've had a cadence are",
    "start": "351949",
    "end": "357770"
  },
  {
    "text": "accepting every three months every quarter we have a cadence over a new release you see they're cute flow 0.1 we",
    "start": "357770",
    "end": "363800"
  },
  {
    "text": "had our go and ambassador and Selden making it easy to get in make it easy to serve maybe easy to begin orchestrating",
    "start": "363800",
    "end": "370129"
  },
  {
    "text": "we started adding things like hyper parameter Tooting additional frameworks in chief of 0.2 0.3 we added our updated",
    "start": "370129",
    "end": "378860"
  },
  {
    "text": "our TF job and made it easier to deploy through KF control in Q plus 0.4 we had",
    "start": "378860",
    "end": "385190"
  },
  {
    "text": "a very significant release with the introduction of cube flow pipelines which we'll be demoing today and at Q",
    "start": "385190",
    "end": "390620"
  },
  {
    "text": "flow 50.5 we're going to announce some brand-new things around",
    "start": "390620",
    "end": "395800"
  },
  {
    "text": "Ferenc which is a way to execute from your notebook a very rich experience and",
    "start": "395800",
    "end": "401349"
  },
  {
    "text": "then also our brand new jupiter web app which makes it very easy to deploy so",
    "start": "401349",
    "end": "408250"
  },
  {
    "text": "with all that we think that cube flow is a cloud native platform for ml and our tenants are its composable its scalable",
    "start": "408250",
    "end": "415599"
  },
  {
    "text": "and it's portable and that means it is designed to run your applications in the",
    "start": "415599",
    "end": "420910"
  },
  {
    "text": "way that you want anywhere that kubernetes is can work the architecture as a whole looks something like this",
    "start": "420910",
    "end": "427360"
  },
  {
    "text": "you can see there you have an ingress endpoint that is native to kubernetes and it can connect you to either a rich",
    "start": "427360",
    "end": "433960"
  },
  {
    "text": "dashboard let you execute individual operators that are part of the queue flow platform or let you serve your",
    "start": "433960",
    "end": "441490"
  },
  {
    "text": "models but underlying all of that is a rich orchestration through queue flow",
    "start": "441490",
    "end": "446710"
  },
  {
    "text": "pipelines and then additionally rich metadata allowing you to coordinate",
    "start": "446710",
    "end": "452259"
  },
  {
    "text": "between all these various steps in the past year we've had an incredible amount of momentum you can see here just a few",
    "start": "452259",
    "end": "459789"
  },
  {
    "text": "of the many companies that are contributing and and you know when I started I could never have hoped for the",
    "start": "459789",
    "end": "466210"
  },
  {
    "text": "kind of velocity of real-world contributions in the past 28 days we",
    "start": "466210",
    "end": "471460"
  },
  {
    "text": "have over 500 pull requests and 80 unique authors and and by unique authors",
    "start": "471460",
    "end": "477729"
  },
  {
    "text": "I mean this write like a lot of people think about kubernetes and they think like oh that's just a Google thing but the reality is you don't fill a 10000",
    "start": "477729",
    "end": "484270"
  },
  {
    "text": "person organization with just Google right there's Google or not Google so what is cute flow look like cute flow a",
    "start": "484270",
    "end": "490150"
  },
  {
    "text": "year and a half old no funding no anything you know this is what it looks like you have Google and you have not",
    "start": "490150",
    "end": "496000"
  },
  {
    "text": "Google and that is tremendous that's what we mean when we say community driven like these are things that are",
    "start": "496000",
    "end": "502449"
  },
  {
    "text": "solving real people's problems today and there aren't just like little one offs of people contributing this is serious",
    "start": "502449",
    "end": "508180"
  },
  {
    "text": "stuff and to show you how much progress you've made it in this time the items on",
    "start": "508180",
    "end": "514959"
  },
  {
    "text": "the left are what we launched with and the items on the right are your you know standard critical user journey you're able to ingest transform train analyze",
    "start": "514959",
    "end": "523630"
  },
  {
    "text": "your data hyper parameter sweep you name it it's all built in and it's all orchestrated with cue flow pipe",
    "start": "523630",
    "end": "529630"
  },
  {
    "text": "and like I said we have an enormous amount of contributions and I cannot think enough all the folks up up here",
    "start": "529630",
    "end": "535750"
  },
  {
    "text": "who are really pushing the for platform forward and really making the business there on so like I said we're now at Q",
    "start": "535750",
    "end": "542860"
  },
  {
    "text": "fo 0.5 very proud to announce that we have a bunch of notebook improvements we",
    "start": "542860",
    "end": "548709"
  },
  {
    "text": "know that we want to give everyone a rich notebook experience without having to leave without having to you know our",
    "start": "548709",
    "end": "554410"
  },
  {
    "text": "joke is we don't not date a scientist to even have to use letter K if we can get there we're gonna be happy second around",
    "start": "554410",
    "end": "562089"
  },
  {
    "text": "deployment part of what we want to achieve with Q flow is being completely portable so whether or not that means",
    "start": "562089",
    "end": "568509"
  },
  {
    "text": "running on your laptop running in cloud one cloud to the CLI the deployment experience is the same and you're able",
    "start": "568509",
    "end": "576279"
  },
  {
    "text": "to use all the features of whatever environment you're deploying to and then finally pipelines again this is one of",
    "start": "576279",
    "end": "582009"
  },
  {
    "text": "the things that we feel very strongly is the differentiator is the thing that's going to help bring data science to",
    "start": "582009",
    "end": "587680"
  },
  {
    "text": "production faster is orchestration through pipelines and we're added GPU support we added a number of tf-x",
    "start": "587680",
    "end": "594310"
  },
  {
    "text": "integration that's tensorflow extended from google and then some upgrades are an external support so with that I've",
    "start": "594310",
    "end": "602230"
  },
  {
    "text": "done a lot of talking let me hand it off to Jeremy who's actually going to show you all a show off some of the features",
    "start": "602230",
    "end": "607600"
  },
  {
    "text": "in 0.5",
    "start": "607600",
    "end": "610199"
  },
  {
    "text": "thank you very much David so what we're going to be showing you today with a demo is we really want to show you how",
    "start": "616240",
    "end": "622990"
  },
  {
    "text": "you can go from developing a notebook developing a model inside a notebook all",
    "start": "622990",
    "end": "628029"
  },
  {
    "text": "the way to deploying that model into production and the key idea that we want to show is that we're gonna let our data",
    "start": "628029",
    "end": "633579"
  },
  {
    "text": "scientists be data scientists because they're gonna be able to develop their model inside the notebook using the",
    "start": "633579",
    "end": "638829"
  },
  {
    "text": "tools that are familiar with them and then we're going to be able to let them easily scale out by training as on",
    "start": "638829",
    "end": "644529"
  },
  {
    "text": "kubernetes and also deploying on kubernetes and then finally we're going to end up building a CI CD pipeline to",
    "start": "644529",
    "end": "650559"
  },
  {
    "text": "actually deliver that into production using coop flow pipelines and so we're gonna make our devops folks and SR ease",
    "start": "650559",
    "end": "657339"
  },
  {
    "text": "hoppy because we're gonna stick to the to the best practices for DevOps because",
    "start": "657339",
    "end": "663639"
  },
  {
    "text": "we're gonna follow you know get-ups workflow and be entirely declarative so",
    "start": "663639",
    "end": "669100"
  },
  {
    "text": "let's get started with the demo so this is the coop flow central dashboard so",
    "start": "669100",
    "end": "675759"
  },
  {
    "text": "this makes it really easy for our data scientists to navigate among all the different applications that are in coop",
    "start": "675759",
    "end": "681129"
  },
  {
    "text": "globe so we have really three today so we have notebooks sorry I clicked on the",
    "start": "681129",
    "end": "687249"
  },
  {
    "text": "docs so we have notebooks we have cat tip which is our hyper parameter tuning system and then of course we have",
    "start": "687249",
    "end": "693850"
  },
  {
    "text": "pipelines and so we're going to start off today by using notebooks so if we go",
    "start": "693850",
    "end": "700929"
  },
  {
    "text": "to the notebooks dashboard you can see that if we make it super easy for each user to have multiple notebooks so you",
    "start": "700929",
    "end": "706959"
  },
  {
    "text": "can have one running you know PI torch and one running tensor flow so they can you know let one run one job and then",
    "start": "706959",
    "end": "713589"
  },
  {
    "text": "start another one to do more work it's super easy to launch a new notebook so they can just click there to launch a",
    "start": "713589",
    "end": "719379"
  },
  {
    "text": "new server all they have to do is type the name for their notebook and then they specify the doctor image",
    "start": "719379",
    "end": "724420"
  },
  {
    "text": "they want to use and so we ship a bunch of stock runtime environments for tensorflow and other frameworks but you",
    "start": "724420",
    "end": "729939"
  },
  {
    "text": "can also build you know custom Jupiter docker images to have custom environments and then you can also",
    "start": "729939",
    "end": "735730"
  },
  {
    "text": "customize the amount the resources and even attach extra data volumes so it's",
    "start": "735730",
    "end": "741249"
  },
  {
    "text": "super easy to attach like an NFS share using PVCs so you can easily share data",
    "start": "741249",
    "end": "747009"
  },
  {
    "text": "I'm the different notebooks and other pods in your workflow so in this case I'm",
    "start": "747009",
    "end": "752720"
  },
  {
    "text": "going to go ahead and connect to an existing notebook that I have running so",
    "start": "752720",
    "end": "758390"
  },
  {
    "text": "here's my notebook and so in this notebook we're going to be building a model using extra boost to predict",
    "start": "758390",
    "end": "763910"
  },
  {
    "text": "housing prices and so I will be using the Eames data set which is one of the standard sort of data sets used in the",
    "start": "763910",
    "end": "770510"
  },
  {
    "text": "machine learning community for benchmarking and testing and so the idea here is to predict housing prices using",
    "start": "770510",
    "end": "776720"
  },
  {
    "text": "features like population area income etc and so in here we've defined a cell and",
    "start": "776720",
    "end": "784100"
  },
  {
    "text": "we just defined the code for training the model is that legible or should i",
    "start": "784100",
    "end": "789320"
  },
  {
    "text": "zoom in zoom in how's that good okay",
    "start": "789320",
    "end": "797030"
  },
  {
    "text": "so we've defined the functions for for training our model and so we're just",
    "start": "797030",
    "end": "802340"
  },
  {
    "text": "calling a extra boost here and I pushed that code four out of the way into a separate file just to make a little bit",
    "start": "802340",
    "end": "808070"
  },
  {
    "text": "more legible but you could put the code directly here as well and then also we have our predict function right so this",
    "start": "808070",
    "end": "813560"
  },
  {
    "text": "is normal Python code that people with data scientists would normally write in the cell or rubber they would like to",
    "start": "813560",
    "end": "818780"
  },
  {
    "text": "write it we've just asked them to put a little bit of structure around that code and define that as class methods so we",
    "start": "818780",
    "end": "824510"
  },
  {
    "text": "think that's very that should be very doable for data scientists because they're already pretty familiar and comfortable with Python so now what we",
    "start": "824510",
    "end": "831650"
  },
  {
    "text": "can do is we can go down here and we can instantiate this class and call training and so in this case training is just",
    "start": "831650",
    "end": "837560"
  },
  {
    "text": "running inside our notebook and similarly once we've done that we can go ahead and call project local predict so",
    "start": "837560",
    "end": "844010"
  },
  {
    "text": "we're just gonna load up some data and then call predict and so we're generating some predictions so this is all running inside the notebook so this",
    "start": "844010",
    "end": "849740"
  },
  {
    "text": "is the normal sort of workflow of a data scientist would be developing and iterating on another model inside a",
    "start": "849740",
    "end": "855080"
  },
  {
    "text": "notebook but you can imagine now that they want to scale out so maybe they've only been you know testing out their",
    "start": "855080",
    "end": "860570"
  },
  {
    "text": "model on a small sample of data because they wanted to train quickly and now they'd like to scale up and maybe run on",
    "start": "860570",
    "end": "866480"
  },
  {
    "text": "the full data set and so now they want to let it run you know maybe they want to let it run overnight or even longer or maybe they want to scale up and use",
    "start": "866480",
    "end": "874100"
  },
  {
    "text": "more resources more CPU and more GPUs and they want to maybe would like to run that as a batch job on kubernetes",
    "start": "874100",
    "end": "880380"
  },
  {
    "text": "or maybe they want to even you know run multiple jobs in parallel because they want to do some you know like a parameter sweet",
    "start": "880380",
    "end": "885900"
  },
  {
    "text": "so with coop flow and using fairing which is a high level library that we've built in coop flow for using and",
    "start": "885900",
    "end": "893790"
  },
  {
    "text": "consuming kubernetes we make it super easy to take this notebook and launch it as a job on kubernetes so all they have",
    "start": "893790",
    "end": "900870"
  },
  {
    "text": "to do is define really two variables the first is the docker registry where they",
    "start": "900870",
    "end": "905970"
  },
  {
    "text": "want to push the docker images that we're going to build and the second is the runtime docker image they want to",
    "start": "905970",
    "end": "912300"
  },
  {
    "text": "use as the runtime environment and so we're gonna use the same docker image that we're running our notebook in and this way we get the same exact",
    "start": "912300",
    "end": "918810"
  },
  {
    "text": "environment in our batch jobs that we're using in our notebook so here we can go ahead and with just you know about two lines of Python code",
    "start": "918810",
    "end": "926250"
  },
  {
    "text": "we can go ahead and build our doctorate image directly from our notebook and you'll notice that it's super fast and",
    "start": "926250",
    "end": "932850"
  },
  {
    "text": "we think that's super important because we don't want to get it in the way of the data scientist stab test cycle we",
    "start": "932850",
    "end": "938610"
  },
  {
    "text": "want that to be super quick so we've gone ahead and built the docker image and now using about two more lines of",
    "start": "938610",
    "end": "946200"
  },
  {
    "text": "Python code from the Ferenc library we can go ahead and deploy a job on kubernetes which is going to go ahead",
    "start": "946200",
    "end": "953070"
  },
  {
    "text": "and run that same training job code so it's gone ahead and launched the job and then introspect just logs so it's doing",
    "start": "953070",
    "end": "959910"
  },
  {
    "text": "the exact same training function except now it's actually running as a job on kubernetes and if you don't believe me",
    "start": "959910",
    "end": "965820"
  },
  {
    "text": "we can actually fetch by running coop cuddle the job spec and we can see that",
    "start": "965820",
    "end": "971040"
  },
  {
    "text": "we've actually gone ahead and spawned a kubernetes job so now we'd like to go ahead and deploy that using as a model",
    "start": "971040",
    "end": "979980"
  },
  {
    "text": "and create a rest endpoint that we can begin to hit and so we again we can do that really easily directly from the",
    "start": "979980",
    "end": "986070"
  },
  {
    "text": "notebook just by using a fairing and so again with like two lines of faring we can go ahead and deploy an endpoint and",
    "start": "986070",
    "end": "992130"
  },
  {
    "text": "that's going to give us an in custer IP address that we can hit and you can see",
    "start": "992130",
    "end": "998850"
  },
  {
    "text": "if we again check under the hood we can see that we've actually got a deployment a kubernetes deployment that we've",
    "start": "998850",
    "end": "1004760"
  },
  {
    "text": "created using the same docker image that we've built before and we've used Selden to wrap that predict code",
    "start": "1004760",
    "end": "1011710"
  },
  {
    "text": "Manan HTTP server so that h that predict function will now get invoked in",
    "start": "1011710",
    "end": "1017120"
  },
  {
    "text": "response to a HTTP request and so down here we can go ahead and read some data",
    "start": "1017120",
    "end": "1023030"
  },
  {
    "text": "and again do prediction only this time we're doing the prediction by sending an HTTP request to the to the server so",
    "start": "1023030",
    "end": "1031910"
  },
  {
    "text": "we've gone all the way from developing our model and prototype in our model inside a notebook to being able to",
    "start": "1031910",
    "end": "1036949"
  },
  {
    "text": "launch that as a job on kubernetes to scale up for training and also to deploying that as a deployment on",
    "start": "1036949",
    "end": "1043189"
  },
  {
    "text": "kubernetes so that we actually have a production ready server so now we're going to go ahead and build a CI CD",
    "start": "1043190",
    "end": "1049610"
  },
  {
    "text": "pipeline for deploying this into production using pipelines so the way",
    "start": "1049610",
    "end": "1055700"
  },
  {
    "text": "that we do that is you to define a pipeline you basically define a Python function which is very gonna define your",
    "start": "1055700",
    "end": "1062450"
  },
  {
    "text": "pipeline and you annotate that with the pipeline annotation so we just have this DSL dot pipeline and pipelines can be",
    "start": "1062450",
    "end": "1070130"
  },
  {
    "text": "parameterized so you can specify what parameters or arguments those pipelines will take and so in this case we're",
    "start": "1070130",
    "end": "1075620"
  },
  {
    "text": "going to take the path to the training data as well as the model file where we",
    "start": "1075620",
    "end": "1081410"
  },
  {
    "text": "wanna save the model and then in every step in your pipeline is defined by a",
    "start": "1081410",
    "end": "1087110"
  },
  {
    "text": "containerized operation so we just instantiate that using the DSL container option and we specify the docker image",
    "start": "1087110",
    "end": "1094910"
  },
  {
    "text": "that we want to run so in this case we're just going to specify the same docker image that we built before so",
    "start": "1094910",
    "end": "1100550"
  },
  {
    "text": "that we're getting getting a consistent environment across all of our steps training deploying and then running in",
    "start": "1100550",
    "end": "1105590"
  },
  {
    "text": "our pipeline and so the first function in our deployment pipeline is going to be the trainer model and so we're just",
    "start": "1105590",
    "end": "1111530"
  },
  {
    "text": "going to specify that we want to invoke the Train function that we defined before in our class and then we're going",
    "start": "1111530",
    "end": "1117080"
  },
  {
    "text": "to pass this specify the command-line arguments that we want to pass to that training function which in this case would be the training data as well as",
    "start": "1117080",
    "end": "1123710"
  },
  {
    "text": "the model file where we want to save the model and then to create a CI CD",
    "start": "1123710",
    "end": "1128810"
  },
  {
    "text": "pipeline what we're going to do is after we train the model we're going to deploy the model then we're going to validate",
    "start": "1128810",
    "end": "1134840"
  },
  {
    "text": "the model which in this case could just be sending a prediction to that model and then if that passes what we're gonna",
    "start": "1134840",
    "end": "1141050"
  },
  {
    "text": "actually do is create a PR which is going to go ahead and update that deployment back to point to the new model and so",
    "start": "1141050",
    "end": "1148190"
  },
  {
    "text": "after we do that what we do is we use the pipeline's SDK to compile that",
    "start": "1148190",
    "end": "1153620"
  },
  {
    "text": "pipeline that's just generating the Argos back to run this and then we can just submit that pipeline by calling the",
    "start": "1153620",
    "end": "1160370"
  },
  {
    "text": "run function in the Python SDK and so if we do that that's going to go ahead and launch that pipeline and so if you click",
    "start": "1160370",
    "end": "1167720"
  },
  {
    "text": "on the link down here we can see the pipeline running it's going to take a",
    "start": "1167720",
    "end": "1172730"
  },
  {
    "text": "little bit of time so we can click over and we can see a pre pre finished pipeline and so you can see we have the",
    "start": "1172730",
    "end": "1178370"
  },
  {
    "text": "four steps that we defined before so we have trained deployed validate and then create PR and then if we click here we",
    "start": "1178370",
    "end": "1185900"
  },
  {
    "text": "can see all the runs of the this pipeline so in cupola pipelines we",
    "start": "1185900",
    "end": "1191299"
  },
  {
    "text": "organize all the different runs of a pipeline into an experiment and so we can see all of the runs and we can see the currently running pipeline and yeah",
    "start": "1191299",
    "end": "1200390"
  },
  {
    "text": "we can see that it's made it through the first three steps and it's doing the final request to create the PR and if we",
    "start": "1200390",
    "end": "1207710"
  },
  {
    "text": "go over here to get hub we can see that we actually created a PR and what we what this PR was doing is we've",
    "start": "1207710",
    "end": "1213169"
  },
  {
    "text": "basically updated the model specification which in this case is specified by an environment variable to",
    "start": "1213169",
    "end": "1219160"
  },
  {
    "text": "the latest model which we've saved in GCS so going back to the die",
    "start": "1219160",
    "end": "1227980"
  },
  {
    "text": "so just to recap we went all the way",
    "start": "1231980",
    "end": "1237930"
  },
  {
    "text": "from development to production and while we did that we made our data scientists happy because we allowed them to stay in",
    "start": "1237930",
    "end": "1243720"
  },
  {
    "text": "their data their environment that's very friendly to them so we allowed them to continue to develop and iterate inside a",
    "start": "1243720",
    "end": "1249690"
  },
  {
    "text": "notebook but we nonetheless allowed them to leverage kubernetes for scalability",
    "start": "1249690",
    "end": "1255030"
  },
  {
    "text": "you know they were able to do both batch jobs and scaling out for for training",
    "start": "1255030",
    "end": "1262110"
  },
  {
    "text": "and then deploy the actual model but we also made our saris happy because we ended up with a declarative get-ups",
    "start": "1262110",
    "end": "1267750"
  },
  {
    "text": "based workflow for pushing this model into production and then importantly at",
    "start": "1267750",
    "end": "1273270"
  },
  {
    "text": "no point that we have to rewrite the notebook code in order to deploy it and",
    "start": "1273270",
    "end": "1278700"
  },
  {
    "text": "so with that I'm gonna hand it back to David thanks Jeremy so I hope you can",
    "start": "1278700",
    "end": "1287790"
  },
  {
    "text": "see that you know we really are thinking about this how do we bring together both the data scientists and the asari the",
    "start": "1287790",
    "end": "1294390"
  },
  {
    "text": "the quickest way to hurt your data science / - you know productivity is to",
    "start": "1294390",
    "end": "1301140"
  },
  {
    "text": "ask them to learn an entirely new set of tools and ask them to pick up a bunch of things especially if that's hurts their ability to iterate using the tools they",
    "start": "1301140",
    "end": "1307920"
  },
  {
    "text": "know and love like notebooks and visualization and things like that on the other hand unless you build a system",
    "start": "1307920",
    "end": "1314790"
  },
  {
    "text": "like this which is get ops based which is ml ops base that understands how to",
    "start": "1314790",
    "end": "1319860"
  },
  {
    "text": "transform those artifacts produced by data scientists in a production ready to a production ready artifact you're gonna",
    "start": "1319860",
    "end": "1327720"
  },
  {
    "text": "have nothing but trouble so 40.6 we know",
    "start": "1327720",
    "end": "1333600"
  },
  {
    "text": "that you know there's still a lot of stuff to do one of the top requests we get by a mile is multi user support we",
    "start": "1333600",
    "end": "1340350"
  },
  {
    "text": "want to make it very easy for multiple people to join together in a single cube flow deployment yet still use isolation",
    "start": "1340350",
    "end": "1346800"
  },
  {
    "text": "between them and we're gonna be doing that we're also have sto and bringing a",
    "start": "1346800",
    "end": "1352170"
  },
  {
    "text": "number of our api's to 1.0 a second we want to really make double down our",
    "start": "1352170",
    "end": "1358200"
  },
  {
    "text": "investments in metadata we think that tying all these experiments together through rich metadata",
    "start": "1358200",
    "end": "1365330"
  },
  {
    "text": "you know using known schemas and and making it available for everyone excuse me to use will be really really",
    "start": "1365330",
    "end": "1372530"
  },
  {
    "text": "powerful if you can describe all the steps you just saw Jeremy walked through there with rich metadata and with rich",
    "start": "1372530",
    "end": "1377900"
  },
  {
    "text": "tracking that makes a huge difference a second thing that we're investing in in",
    "start": "1377900",
    "end": "1383510"
  },
  {
    "text": "that same capacity around tooling is we will be swapping out case Annette for customized case net was the decision we",
    "start": "1383510",
    "end": "1390710"
  },
  {
    "text": "made when we first launched the project it is deprecated and we're moving towards customized which is a upstream",
    "start": "1390710",
    "end": "1397730"
  },
  {
    "text": "templating system in kubernetes and we're much more confident that it will be maintained long term and then finally",
    "start": "1397730",
    "end": "1404450"
  },
  {
    "text": "around pipelines we are going to continue to do our pipeline work we consider that to be critical to building",
    "start": "1404450",
    "end": "1411740"
  },
  {
    "text": "that production ready end-to-end machine learning system so what does this must",
    "start": "1411740",
    "end": "1417350"
  },
  {
    "text": "be to talk about one email so I have good news all these bits are already production ready I don't know what",
    "start": "1417350",
    "end": "1422870"
  },
  {
    "text": "you're complaining about but but that's the truth right these things kubernetes and tensorflow and pi",
    "start": "1422870",
    "end": "1429800"
  },
  {
    "text": "torch and tf-x ISTE Oh Selden these are all core components in cube flow they",
    "start": "1429800",
    "end": "1436760"
  },
  {
    "text": "already run in a containerized way they already run in a way that that your SR ease and your data scientists can trust",
    "start": "1436760",
    "end": "1444010"
  },
  {
    "text": "massive massive deployments inside Google in the real world you know are already using them today and and that's",
    "start": "1444010",
    "end": "1451520"
  },
  {
    "text": "really part of the good news about get flow we're not going out there and introducing a brand new machine learning system and we're not just arbitrarily",
    "start": "1451520",
    "end": "1458600"
  },
  {
    "text": "declaring something as 1.0 because you know somebody needs it we know what",
    "start": "1458600",
    "end": "1463790"
  },
  {
    "text": "needs to be production ready and that is when you start your tensorflow job it better finish or it better give you a",
    "start": "1463790",
    "end": "1468860"
  },
  {
    "text": "good reason why and and that's what kubernetes and cube flow is designed to provide already however you're right",
    "start": "1468860",
    "end": "1476690"
  },
  {
    "text": "cube flow as a whole is not 1.0 and by that we mean we really want to be thoughtful about when we declare that",
    "start": "1476690",
    "end": "1483350"
  },
  {
    "text": "1.0 because that means we're going to snap to AP is that we plan on supporting for a long time and in order to do that",
    "start": "1483350",
    "end": "1491390"
  },
  {
    "text": "in order to really feel comfortable we want to make sure these critical user journeys are absolutely nailed and that",
    "start": "1491390",
    "end": "1497690"
  },
  {
    "text": "is you know exactly like you saw there building and training from your notebook making sure that multiple people can",
    "start": "1497690",
    "end": "1503210"
  },
  {
    "text": "share a single a single cube flow deployment having a uniform experience",
    "start": "1503210",
    "end": "1510860"
  },
  {
    "text": "for installation unfortunately today right now we don't have enough people testing we don't get enough bugs from",
    "start": "1510860",
    "end": "1517820"
  },
  {
    "text": "from different cloud environments and so on and we need to start detecting those so that we can make sure that we really",
    "start": "1517820",
    "end": "1523730"
  },
  {
    "text": "do support every cloud that is out there we want to make sure that the pipeline's",
    "start": "1523730",
    "end": "1528980"
  },
  {
    "text": "get richer and and use the best practices of get ops and we're gonna be doing a bunch of work around that and",
    "start": "1528980",
    "end": "1534800"
  },
  {
    "text": "then finally I you know one of the biggest areas of machine learning is tracking and and reproducibility and",
    "start": "1534800",
    "end": "1542870"
  },
  {
    "text": "we're gonna be doing a number of investments around that as well and and we don't think we need to be perfect about all of these things by the time we",
    "start": "1542870",
    "end": "1549290"
  },
  {
    "text": "get to 1.0 but we want to make sure that we have an experience that makes it more powerful for a data scientist we don't",
    "start": "1549290",
    "end": "1555800"
  },
  {
    "text": "want to have to have them take a step back in order to adopt this platform that is production-ready",
    "start": "1555800",
    "end": "1562070"
  },
  {
    "text": "one additional thing that we want to talk about is governance this is an extremely important issue if a project",
    "start": "1562070",
    "end": "1569750"
  },
  {
    "text": "doesn't have people who are not from a different company on the governance board it is not an open project I cannot",
    "start": "1569750",
    "end": "1575810"
  },
  {
    "text": "stress that enough and that is something a big step we're taking we we have a",
    "start": "1575810",
    "end": "1580820"
  },
  {
    "text": "proposal for governance right now we would love for you to come join give us feedback join the governance join our",
    "start": "1580820",
    "end": "1587480"
  },
  {
    "text": "SIG's this is an extremely open project if it is a single company driving the",
    "start": "1587480",
    "end": "1593870"
  },
  {
    "text": "boat we have done not done our job I have not done my job so please come talk to me talk to any of the people and we",
    "start": "1593870",
    "end": "1599179"
  },
  {
    "text": "will figure out how to make this work together you know I was there for the original governance of kubernetes and we",
    "start": "1599179",
    "end": "1604910"
  },
  {
    "text": "very much are following off their lead and I always like to end with this slide because I'm full of a room of very smart",
    "start": "1604910",
    "end": "1612710"
  },
  {
    "text": "people who are thinking about machine learning and in the reality as as data science will touch every industry and",
    "start": "1612710",
    "end": "1619610"
  },
  {
    "text": "it's up to us the people in this room the people on the feed to think about",
    "start": "1619610",
    "end": "1624919"
  },
  {
    "text": "the people outside this room the people who are not watching the feed how can we make their lives better",
    "start": "1624919",
    "end": "1630510"
  },
  {
    "text": "how can we help them be smarter about their jobs how can we help them change the world through tooling and techniques",
    "start": "1630510",
    "end": "1637140"
  },
  {
    "text": "and making it simple for them to bring their knowledge to the to the fore like I said cube flow is open open design",
    "start": "1637140",
    "end": "1643890"
  },
  {
    "text": "open community open chat and lots of links please come to any or all of these",
    "start": "1643890",
    "end": "1650730"
  },
  {
    "text": "you can we have couplet all right we have a slack we have a weekly community meeting we have you know hundreds of",
    "start": "1650730",
    "end": "1657690"
  },
  {
    "text": "people here who are engaged in to flow today and we're happy to help you you have me you can email me at any time and",
    "start": "1657690",
    "end": "1664200"
  },
  {
    "text": "I will have happy to answer your cue flow questions and with that thank you very much",
    "start": "1664200",
    "end": "1669400"
  },
  {
    "text": "[Applause]",
    "start": "1669400",
    "end": "1672969"
  },
  {
    "text": "[Music] so we have about we have about four minutes left any questions yes tail",
    "start": "1675960",
    "end": "1685250"
  },
  {
    "text": "you got it so uh tans point was that we have an hour and a half long showcase at right now after this talk at the Google",
    "start": "1693310",
    "end": "1700960"
  },
  {
    "text": "booth for could flow birds of other please come by I will be there Jeremy will be there we're ready to answer your",
    "start": "1700960",
    "end": "1706270"
  },
  {
    "text": "questions oh sorry it is at the Google cloud booth please come yes",
    "start": "1706270",
    "end": "1716669"
  },
  {
    "text": "yeah",
    "start": "1719880",
    "end": "1722880"
  },
  {
    "text": "yeah so the question was one platform is extensibility do we plan to support a",
    "start": "1730440",
    "end": "1736419"
  },
  {
    "text": "standard API for extensibility for a number of different toolings the answer",
    "start": "1736419",
    "end": "1742450"
  },
  {
    "text": "is yes and no right now the idea is that the packages the way you deploy a",
    "start": "1742450",
    "end": "1747519"
  },
  {
    "text": "package is fairly standard right you can do basically whatever you want but you can easily go you can grab a package and",
    "start": "1747519",
    "end": "1753579"
  },
  {
    "text": "it will deploy in a fairly well-known way part of what we're doing around metadata is giving you standards for",
    "start": "1753579",
    "end": "1759609"
  },
  {
    "text": "writing out what your package is doing and things like that but the reason I say yes on the other hand is when we see",
    "start": "1759609",
    "end": "1767109"
  },
  {
    "text": "enough people doing an implementation the community has started to form standards around those particular",
    "start": "1767109",
    "end": "1773139"
  },
  {
    "text": "implementations so you look at something like serving we have a brand-new effort called KF serving queue flow serving",
    "start": "1773139",
    "end": "1778389"
  },
  {
    "text": "which is an effort to standardize on that API and that's an API that's not just gonna be standard for packages that",
    "start": "1778389",
    "end": "1783969"
  },
  {
    "text": "the plain cute flow but Google and Microsoft and other folks Blumberg are all contributing to that as well so",
    "start": "1783969",
    "end": "1789669"
  },
  {
    "text": "that's how we standardize the API for serving similarly some of the folks from",
    "start": "1789669",
    "end": "1795459"
  },
  {
    "text": "ant financial and others are standardizing on the operator framework for jobs for example right now that we",
    "start": "1795459",
    "end": "1801969"
  },
  {
    "text": "have a PI torch job an MX net job a tensorflow job excuse jobs so on and so",
    "start": "1801969",
    "end": "1807820"
  },
  {
    "text": "forth we're like oh wow we've done this a bunch of times let's come up with a standard for that so it is not we're not",
    "start": "1807820",
    "end": "1813549"
  },
  {
    "text": "going to be standards driven but we are gonna say when there's enough of them out there hey really we should get",
    "start": "1813549",
    "end": "1819279"
  },
  {
    "text": "together and let's move forward did Jeremy anything",
    "start": "1819279",
    "end": "1825299"
  },
  {
    "text": "so how much effort do we put on open to making it run on open shift we do have a",
    "start": "1832100",
    "end": "1838010"
  },
  {
    "text": "number of Red Hat contributors right now and our p0 is if you have a kubernetes",
    "start": "1838010",
    "end": "1845390"
  },
  {
    "text": "conformant cluster it should run so if it does not run well you're on us and we",
    "start": "1845390",
    "end": "1851630"
  },
  {
    "text": "are gonna take that bug and make it sure it works that said I would love more particularly usability testing set up",
    "start": "1851630",
    "end": "1859159"
  },
  {
    "text": "testing debugging we don't have as many OpenShift contributors as I would like",
    "start": "1859159",
    "end": "1866900"
  },
  {
    "text": "that's not bad-mouthing anyone it's just what people showed up with and if you",
    "start": "1866900",
    "end": "1872330"
  },
  {
    "text": "have openshift and you want to run it and file 100 bugs we would love it we just don't have that automated test",
    "start": "1872330",
    "end": "1877580"
  },
  {
    "text": "matrices as much as I would like",
    "start": "1877580",
    "end": "1880779"
  },
  {
    "text": "so the question was do we have any approximate date for queue flow 1.0 the",
    "start": "1888220",
    "end": "1893720"
  },
  {
    "text": "answer is when it's ready no the answer is many components will go 1.0 fairly",
    "start": "1893720",
    "end": "1900290"
  },
  {
    "text": "soon right so TF job is just about 1.0 pi torch job is about 1.0 and we'll make",
    "start": "1900290",
    "end": "1906320"
  },
  {
    "text": "you know we're trying to make good decisions around that I don't I would feel uncomfortable giving you an",
    "start": "1906320",
    "end": "1911330"
  },
  {
    "text": "absolute date I would say if you need it to be 1.0 come talk to me and let's",
    "start": "1911330",
    "end": "1916790"
  },
  {
    "text": "figure out what you're concerned about because I can tell you many of the api's",
    "start": "1916790",
    "end": "1921860"
  },
  {
    "text": "are feeling pretty good right now but there are a lot of brand-new things like metadata and things like that that just",
    "start": "1921860",
    "end": "1927140"
  },
  {
    "text": "need miles on the road so the best you could do is help us by just taking it",
    "start": "1927140",
    "end": "1932240"
  },
  {
    "text": "and running it and if it doesn't feel right then that's come time to come talk to us but the more feedback we get about",
    "start": "1932240",
    "end": "1937730"
  },
  {
    "text": "it running the better we are but like I said it really is the component to production-ready it is being used in",
    "start": "1937730",
    "end": "1944030"
  },
  {
    "text": "thousands of places today and and even if it's just that individual component",
    "start": "1944030",
    "end": "1949310"
  },
  {
    "text": "it runs great yeah",
    "start": "1949310",
    "end": "1953530"
  },
  {
    "text": "yeah yeah so the question is do you have",
    "start": "1960600",
    "end": "1969130"
  },
  {
    "text": "to use notebooks to do all your cute flow stuff absolutely not thank you very",
    "start": "1969130",
    "end": "1974290"
  },
  {
    "text": "much for the segue in an hour and 55 minutes to 255 what time is it 2 hours",
    "start": "1974290",
    "end": "1982000"
  },
  {
    "text": "and 55 minutes I will be presenting an ml ops presentation about using cue flow",
    "start": "1982000",
    "end": "1987370"
  },
  {
    "text": "and ml ops in that I won't note no books I will do it only with Python scripts the reality is is that pipelines is very",
    "start": "1987370",
    "end": "1996190"
  },
  {
    "text": "very rich as long as you can containerize your code and in fact under under the hood what Jeremy showed today",
    "start": "1996190",
    "end": "2003030"
  },
  {
    "text": "even though he was driven from a notebook that was all Python as well so there's absolutely nothing tying it to that you're able to containerize your",
    "start": "2003030",
    "end": "2009570"
  },
  {
    "text": "Python script give it standard end points and then put it in a pipeline and it'll run I think for example to develop",
    "start": "2009570",
    "end": "2017820"
  },
  {
    "text": "locally in your favorite IDE and then deploy things and scale things out on to your cluster so that's another common",
    "start": "2017820",
    "end": "2023460"
  },
  {
    "text": "use case for it what's that oh and we",
    "start": "2023460",
    "end": "2030990"
  },
  {
    "text": "added functions as well any other questions yep",
    "start": "2030990",
    "end": "2040010"
  },
  {
    "text": "yeah so that's a really interesting question the question was how do we deal with versioning of the data and",
    "start": "2053710",
    "end": "2059658"
  },
  {
    "text": "obviously you know artifact tracking and things like that that is something we've heard a lot of right the realities is",
    "start": "2059659",
    "end": "2067339"
  },
  {
    "text": "that the the Data Platform you provide is ultimately probably going to have to",
    "start": "2067339",
    "end": "2072769"
  },
  {
    "text": "do some form of checkpointing or artifact production because of the",
    "start": "2072769",
    "end": "2078200"
  },
  {
    "text": "nature of you know how you version data over time cube flow will pick up that",
    "start": "2078200",
    "end": "2084230"
  },
  {
    "text": "information and allow you to store it in things like you know your overall metadata store and things like that but",
    "start": "2084230",
    "end": "2089720"
  },
  {
    "text": "I don't think is a first class thing cube flow is gonna solve that that's it for example pachyderm has a rich data",
    "start": "2089720",
    "end": "2097299"
  },
  {
    "text": "solution and they are integrated into cube flow today and so that that's an example where you would use pachyderm",
    "start": "2097299",
    "end": "2103490"
  },
  {
    "text": "pachyderm would provide you a checkpoint and a version data you would store that metadata and then you would consume that in the next stage of your pipeline but",
    "start": "2103490",
    "end": "2110510"
  },
  {
    "text": "but we wouldn't expect Hublot to solve that natively it would expect versioning from the underlying data provider yeah",
    "start": "2110510",
    "end": "2116779"
  },
  {
    "text": "and then the integration point would be like the metadata store so like you could with snapshot your volume for example a rip dough has a solution for",
    "start": "2116779",
    "end": "2122809"
  },
  {
    "text": "snaps rubbing your your PVC volumes and then you can record that in your metadata so you can deco I ran training",
    "start": "2122809",
    "end": "2128990"
  },
  {
    "text": "and here's the the snapshot that I ran on so now you have a completely reproducible pipeline for yourself",
    "start": "2128990",
    "end": "2137828"
  },
  {
    "text": "sorry Mineo or Divya",
    "start": "2147280",
    "end": "2151540"
  },
  {
    "text": "hmm yeah so you should talk to the",
    "start": "2156359",
    "end": "2163410"
  },
  {
    "text": "gentleman right right ahead of you who from Eric doe because they are doing a",
    "start": "2163410",
    "end": "2168450"
  },
  {
    "text": "lot of that multi cloud multi deployment storage issues again that's an area",
    "start": "2168450",
    "end": "2175950"
  },
  {
    "text": "where we would hope that below the layer that would be provided we we're trying",
    "start": "2175950",
    "end": "2182220"
  },
  {
    "text": "to have fairly clean abstraction layers between the infrastructure components the kubernetes components and then the",
    "start": "2182220",
    "end": "2188309"
  },
  {
    "text": "cube flow components we want you know we're not going to try and stall storage we're not going to try and stall",
    "start": "2188309",
    "end": "2193529"
  },
  {
    "text": "networking these are very hard problems we're gonna rely on the platform that we're running on in specifically kubernetes to solve some of these other",
    "start": "2193529",
    "end": "2200400"
  },
  {
    "text": "issues any other questions we'll be at",
    "start": "2200400",
    "end": "2205470"
  },
  {
    "text": "the like I said Google Cloud booth doing a birds of a feather right now and then we have oh yeah thank you we have a",
    "start": "2205470",
    "end": "2212160"
  },
  {
    "text": "number of other key flow talks and you know people walking around cue flow shirts on come talk to us thank you over",
    "start": "2212160",
    "end": "2220750"
  },
  {
    "text": "[Applause]",
    "start": "2220750",
    "end": "2223059"
  }
]
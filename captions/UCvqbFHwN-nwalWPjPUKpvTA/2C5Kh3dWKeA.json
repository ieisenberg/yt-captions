[
  {
    "start": "0",
    "end": "54000"
  },
  {
    "text": "hello everyone thanks for coming and thanks for taking the road - to the",
    "start": "79",
    "end": "5220"
  },
  {
    "text": "hotel we got some power outage in the in the main building so thanks for coming my name is Eduardo Silva and from our",
    "start": "5220",
    "end": "12840"
  },
  {
    "text": "from the team treasurer data and Massoud colony from arm so we are both from arm",
    "start": "12840",
    "end": "19350"
  },
  {
    "text": "and we're both main 10 years of this project which is called fluent bed and as a deep type session and this year we",
    "start": "19350",
    "end": "26939"
  },
  {
    "text": "decided to start talking about a different approach and different and",
    "start": "26939",
    "end": "32640"
  },
  {
    "text": "enhancement that we are working together in the data of stream processing and data processing login used to be",
    "start": "32640",
    "end": "40260"
  },
  {
    "text": "something that to take lots from one place to the other but we think that we",
    "start": "40260",
    "end": "45719"
  },
  {
    "text": "can take that to the next level where we can do stream processing and data modification and things that no other",
    "start": "45719",
    "end": "51660"
  },
  {
    "text": "tools are doing at the moment so the whole point of logging is to deal with",
    "start": "51660",
    "end": "57960"
  },
  {
    "start": "54000",
    "end": "98000"
  },
  {
    "text": "data but if you have too much data it's useless if you're not able to",
    "start": "57960",
    "end": "63120"
  },
  {
    "text": "gather the value and the problem is that data is everywhere so if you don't stop",
    "start": "63120",
    "end": "68159"
  },
  {
    "text": "value data as I said is useless and if you have all a bunch of data that data",
    "start": "68159",
    "end": "74070"
  },
  {
    "text": "is everywhere and you want to gather these insights you need to have the your data centralize it in some place like a",
    "start": "74070",
    "end": "81270"
  },
  {
    "text": "database or a cloud service so then you can extract the value and I would say",
    "start": "81270",
    "end": "87030"
  },
  {
    "text": "that that is like the main reason behind login and all this kind of to Linux flew",
    "start": "87030",
    "end": "92070"
  },
  {
    "text": "in DM flew in baby be able to concentrate your data so you can take advantage of that and extract the",
    "start": "92070",
    "end": "98340"
  },
  {
    "start": "98000",
    "end": "157000"
  },
  {
    "text": "problem value but there are many kind of challenges here log in in general is not",
    "start": "98340",
    "end": "104100"
  },
  {
    "text": "fun but also it's not easy because data comes from different places TCP UDP the",
    "start": "104100",
    "end": "111390"
  },
  {
    "text": "file system nowaday we have system D with Journal D we have data coming from sensors or",
    "start": "111390",
    "end": "116549"
  },
  {
    "text": "remote Hardware like firewalls so how do we be able to collect all this",
    "start": "116549",
    "end": "122430"
  },
  {
    "text": "information and centralize all this information that is not just that comes from different places also different",
    "start": "122430",
    "end": "129179"
  },
  {
    "text": "formats in general we say that we take this hardware or software data or as events we",
    "start": "129179",
    "end": "136040"
  },
  {
    "text": "centralize them in a database and then we can do analysis but we have multiple",
    "start": "136040",
    "end": "141140"
  },
  {
    "text": "of them and saying you know that every year things are scaling up if you have a couple nearest cluster or any kind of",
    "start": "141140",
    "end": "148189"
  },
  {
    "text": "environment it's a scaling up in some way and of course if it's Caleb you are getting more data involved and your data",
    "start": "148189",
    "end": "154849"
  },
  {
    "text": "analysis get some troubles so as I said we got this kind of challenges and if",
    "start": "154849",
    "end": "162439"
  },
  {
    "text": "you are familiar with a unique services like Apache my sequel you will realize that every data has a different format",
    "start": "162439",
    "end": "169510"
  },
  {
    "text": "okay I'm in for a computer this is just text right it's just an array of light",
    "start": "169510",
    "end": "176690"
  },
  {
    "text": "there's no difference so it really when we consume this data in addition to deal",
    "start": "176690",
    "end": "182810"
  },
  {
    "text": "with different source of data with the format we need to have a way to convert this data from an instructor way to a",
    "start": "182810",
    "end": "190069"
  },
  {
    "text": "struktur way you can see that JSON is kind of a structure because we have a map we have keys values arrays and",
    "start": "190069",
    "end": "197540"
  },
  {
    "text": "different data types but that is not it's not true for all the kind of locks",
    "start": "197540",
    "end": "204290"
  },
  {
    "text": "that we have available and this is where flu embed comes in if you embed is a",
    "start": "204290",
    "end": "209569"
  },
  {
    "text": "project that borns as a child break of flu Andy in order to solve different",
    "start": "209569",
    "end": "214909"
  },
  {
    "text": "challenges four years ago forecasting that we are going to need something more lightweight and something that needs to",
    "start": "214909",
    "end": "221449"
  },
  {
    "text": "play well either in containers but also with embedded Linux it is started in",
    "start": "221449",
    "end": "226729"
  },
  {
    "text": "2015 and quick evolved it for the cloud space and with the cloud space I mean",
    "start": "226729",
    "end": "232400"
  },
  {
    "text": "that people who was running containers or any kind of cloud services say hey",
    "start": "232400",
    "end": "237680"
  },
  {
    "text": "we're recent flu Indy is really good but also we need something lightweight for some special scenarios like flu embed so",
    "start": "237680",
    "end": "245209"
  },
  {
    "text": "sorry like H note or something like that so we started this project with that in",
    "start": "245209",
    "end": "251150"
  },
  {
    "text": "mind and we said okay let's develop both projects and of course both projects are open source under the CN CF and under",
    "start": "251150",
    "end": "258560"
  },
  {
    "text": "the Apache License fluent bed today talking to people we realize that there",
    "start": "258560",
    "end": "264380"
  },
  {
    "text": "was quite a fun that they were surprised that is reading see language yeah it's not goal is not",
    "start": "264380",
    "end": "269630"
  },
  {
    "text": "rust it's not Java it's C language people get that question but when they",
    "start": "269630",
    "end": "275330"
  },
  {
    "text": "see the final results in performance in low CPU and low memory you say okay this",
    "start": "275330",
    "end": "282050"
  },
  {
    "text": "project is really good and it's a good fit for different markets not just a cloud where you have big servers but",
    "start": "282050",
    "end": "289370"
  },
  {
    "text": "also for embedded Linux for any kind of data processing or H computing side it",
    "start": "289370",
    "end": "295070"
  },
  {
    "text": "will work we have a pluggable architecture we support different kind of plugins plugins to collect data from",
    "start": "295070",
    "end": "301220"
  },
  {
    "text": "to modify the data and also ship the data out to any kind of database or",
    "start": "301220",
    "end": "306440"
  },
  {
    "text": "cloud service and of course we provide built-in security on it",
    "start": "306440",
    "end": "311500"
  },
  {
    "text": "when flu indeed was decided it was a sign in a way that it was considered",
    "start": "311500",
    "end": "317300"
  },
  {
    "text": "like a data pipeline so say we have an input from where we collect data we have",
    "start": "317300",
    "end": "322760"
  },
  {
    "text": "a parser section or compute component where we take some data and we convert",
    "start": "322760",
    "end": "327770"
  },
  {
    "text": "from one structure to structure then we have a filter baby because you learn to filter out information or maybe you want",
    "start": "327770",
    "end": "335300"
  },
  {
    "text": "to obtain some metadata to your records we are going to see that right now then you buffer your data because you",
    "start": "335300",
    "end": "341390"
  },
  {
    "text": "don't want to lose it and then you're able to roll your data to your favorite in database and from a fluent bed",
    "start": "341390",
    "end": "347900"
  },
  {
    "text": "perspective we took the same design the same principles if you are familiar with",
    "start": "347900",
    "end": "354260"
  },
  {
    "text": "kubernetes a or containers in logging just a simple message that stacks hey",
    "start": "354260",
    "end": "360410"
  },
  {
    "text": "Keep Calm it's not just that message because also it has a timestamp and also",
    "start": "360410",
    "end": "366170"
  },
  {
    "text": "an origin from where this message was generated so a simple message get more",
    "start": "366170",
    "end": "372050"
  },
  {
    "text": "context and in cover knit is that this is not enough because if you are",
    "start": "372050",
    "end": "377600"
  },
  {
    "start": "373000",
    "end": "441000"
  },
  {
    "text": "familiar with kubernetes how do you deploy applications you can say I take this pot which it will be my application",
    "start": "377600",
    "end": "384440"
  },
  {
    "text": "and make 10 replicas ok if you do 10 replicas likely the replicas will be",
    "start": "384440",
    "end": "390190"
  },
  {
    "text": "spawned on different nodes so at some point how do you identify when you get",
    "start": "390190",
    "end": "395810"
  },
  {
    "text": "some issue on which node the problem is happening right on which of the replicas already getting problems",
    "start": "395810",
    "end": "402770"
  },
  {
    "text": "and this is where we append some context so for a simple look message what we get",
    "start": "402770",
    "end": "409279"
  },
  {
    "text": "is not only the message also the stream that is coming from the pot name the host name container name namespace name",
    "start": "409279",
    "end": "416449"
  },
  {
    "text": "and so on because as I said at the beginning our aim is to perform data analysis so if you think that you",
    "start": "416449",
    "end": "423979"
  },
  {
    "text": "concentrate all your data in one central place you want to identify where the data is coming from and this is why",
    "start": "423979",
    "end": "430819"
  },
  {
    "text": "specialize it to test flu in D and flu embed allows you to add context to every record to every event that is being",
    "start": "430819",
    "end": "437930"
  },
  {
    "text": "generated by applications or hard work so for us an application generates",
    "start": "437930",
    "end": "445370"
  },
  {
    "start": "441000",
    "end": "488000"
  },
  {
    "text": "something that is we call a record a record is select technical term and that",
    "start": "445370",
    "end": "450379"
  },
  {
    "text": "record as I said has a timestamp and a message but internally we don't handle",
    "start": "450379",
    "end": "457129"
  },
  {
    "text": "that Asakura an array of bytes at normal text we use like a binary representation",
    "start": "457129",
    "end": "462349"
  },
  {
    "text": "of that message in a format which is called message back so message back",
    "start": "462349",
    "end": "467659"
  },
  {
    "text": "considers lab binary JSON so you can serialize data a message apart and is",
    "start": "467659",
    "end": "472669"
  },
  {
    "text": "quite performin because if you want to do data analysis and you have a map of a hundred of keys",
    "start": "472669",
    "end": "478219"
  },
  {
    "text": "you're not parsing by per byte you can skip between each key and of course we",
    "start": "478219",
    "end": "485000"
  },
  {
    "text": "are going to optimize a memory and CPU so and this is how flu embed and fluency",
    "start": "485000",
    "end": "491779"
  },
  {
    "start": "488000",
    "end": "538000"
  },
  {
    "text": "in general operate so they take data and compare any kind of information in a",
    "start": "491779",
    "end": "497089"
  },
  {
    "text": "binary representation for internal purposes when the data a comes in this",
    "start": "497089",
    "end": "505009"
  },
  {
    "text": "is a quite of learn global architecture for example in the left we group by all the records by their origin so we can",
    "start": "505009",
    "end": "512570"
  },
  {
    "text": "apply a tag because we say all this data that is coming from one place will have a tag and that tag is going to be rolled",
    "start": "512570",
    "end": "519800"
  },
  {
    "text": "back to any kind of destinations so we support like tagging with will curve",
    "start": "519800",
    "end": "524930"
  },
  {
    "text": "matching and we can send one record to multiple places which is pretty common people said hey I want to have some kind",
    "start": "524930",
    "end": "531470"
  },
  {
    "text": "of Records on elasticsearch but also I want to put some of the into Amazon for persistence",
    "start": "531470",
    "end": "539080"
  },
  {
    "start": "538000",
    "end": "620000"
  },
  {
    "text": "in communities we deploy how do we solve this login he said we deploy flume D and",
    "start": "539080",
    "end": "545810"
  },
  {
    "text": "flu embed as a daemon said a demon said is support that runs on every node and",
    "start": "545810",
    "end": "550940"
  },
  {
    "text": "this was a common question so how it operates so we deploy flu in bed like a sidecar",
    "start": "550940",
    "end": "556670"
  },
  {
    "text": "for every application and that's what is known as a daemon set you can see that in the node you just deploy 1 lakh",
    "start": "556670",
    "end": "563300"
  },
  {
    "text": "processor but this lot processor has access to the whole container locks and",
    "start": "563300",
    "end": "568720"
  },
  {
    "text": "once it get access to the container locks then is able to talk to the API",
    "start": "568720",
    "end": "574430"
  },
  {
    "text": "server because as I said before we want to get all the context for the locks like labels and notations and any kind",
    "start": "574430",
    "end": "582230"
  },
  {
    "text": "of information that is not local in the node but the API server is a word so if",
    "start": "582230",
    "end": "589160"
  },
  {
    "text": "you look at this you say ok you cannot handle this manually right you need the right trolling for this and that's why I",
    "start": "589160",
    "end": "594740"
  },
  {
    "text": "flew in DM flowing bed has the kubernetes filter that handle all of these details behind the scenes so when",
    "start": "594740",
    "end": "602000"
  },
  {
    "text": "trying to say you just need to deploy one bit I'm doing this a demon set and they will do the work for you and after",
    "start": "602000",
    "end": "609560"
  },
  {
    "text": "that they are able to push all the logs or information to your decided database",
    "start": "609560",
    "end": "614840"
  },
  {
    "text": "or cloud service can be Kafka influx in a place data dog or so on so now a",
    "start": "614840",
    "end": "623270"
  },
  {
    "start": "620000",
    "end": "667000"
  },
  {
    "text": "couple of project updates and the project has been running for about 40",
    "start": "623270",
    "end": "628820"
  },
  {
    "text": "years and they are really happy that we have more than 100 contributors if you",
    "start": "628820",
    "end": "636080"
  },
  {
    "text": "consider this that we're a small company start a project and then you see many",
    "start": "636080",
    "end": "641330"
  },
  {
    "text": "companies contributing back because of his adoption because this is working I think that we feel really happy about",
    "start": "641330",
    "end": "647690"
  },
  {
    "text": "this because also there's a one moment that the project is bigger than us right",
    "start": "647690",
    "end": "652900"
  },
  {
    "text": "it's a community dream project where different companies are also invest in their own time their own money to make",
    "start": "652900",
    "end": "660020"
  },
  {
    "text": "the Priya better and the player will not be in the status that is today is not",
    "start": "660020",
    "end": "665630"
  },
  {
    "text": "where for these people and one of the happy stats for this year",
    "start": "665630",
    "end": "672370"
  },
  {
    "start": "667000",
    "end": "717000"
  },
  {
    "text": "is that as of today we had more that 50 million deployments just on this day just today so every day we are getting",
    "start": "672370",
    "end": "680589"
  },
  {
    "text": "like 300,000 deployments in kubernetes that means and some cluster is spinning",
    "start": "680589",
    "end": "686620"
  },
  {
    "text": "Amazon beams or bare metal machine and is deploying full embed on it and if you",
    "start": "686620",
    "end": "693490"
  },
  {
    "text": "compare that with the last years so we're doubling and I think that we respect like maybe 200 millions for the",
    "start": "693490",
    "end": "701709"
  },
  {
    "text": "next year so this is kind of statistics per month for this year of course",
    "start": "701709",
    "end": "707589"
  },
  {
    "text": "November is a still growing this is from the last weekend but October we close with eight million eight point five",
    "start": "707589",
    "end": "714579"
  },
  {
    "text": "million eight point seven million in",
    "start": "714579",
    "end": "719620"
  },
  {
    "start": "717000",
    "end": "835000"
  },
  {
    "text": "terms of who's contributing back to the project and I think that we got a good investment from AWS AWS said we are",
    "start": "719620",
    "end": "727120"
  },
  {
    "text": "going to use full and bit and going to normalize a fluent bid for all most of",
    "start": "727120",
    "end": "732160"
  },
  {
    "text": "our login solutions and we are going to start implemented their own plugins for",
    "start": "732160",
    "end": "737649"
  },
  {
    "text": "full embed so AWS is contributing plugins to connect through embed with their own services file ends Amazon s3",
    "start": "737649",
    "end": "744209"
  },
  {
    "text": "redshift and so on Google cloud platform is using flue embed internally to and",
    "start": "744209",
    "end": "750149"
  },
  {
    "text": "data to contribute impacted on the adopt plugin so now we are in a position where",
    "start": "750149",
    "end": "755410"
  },
  {
    "text": "companies are creating dead connectors because they wanted a community of flu embed of users be able to use their own",
    "start": "755410",
    "end": "762069"
  },
  {
    "text": "services for data in Asian one of the",
    "start": "762069",
    "end": "767319"
  },
  {
    "text": "ordinance that we have is that a used to be the sole maintainer of this project",
    "start": "767319",
    "end": "772389"
  },
  {
    "text": "but this break is growing so I would like to say that we have two new maintainer one of them is Massoud who's",
    "start": "772389",
    "end": "779050"
  },
  {
    "text": "here Moscow has contributed a lot on the stream processor core part anything as has played a key role on division on the",
    "start": "779050",
    "end": "787000"
  },
  {
    "text": "how this operates or to get applause for Massoud",
    "start": "787000",
    "end": "791939"
  },
  {
    "text": "he has to be very patience with me and we have a new also meant a contributor",
    "start": "792710",
    "end": "798810"
  },
  {
    "text": "who's not here something he could not float from Japan but Fujimoto is managing all the windows platform port",
    "start": "798810",
    "end": "805680"
  },
  {
    "text": "which as you know windows is really painful environment for developers",
    "start": "805680",
    "end": "812030"
  },
  {
    "text": "personally I want to stay away from it so hopefully we have somebody with the",
    "start": "812030",
    "end": "817200"
  },
  {
    "text": "right expertise we have fluent big packages for windows and we have many people this week working in to have a",
    "start": "817200",
    "end": "823890"
  },
  {
    "text": "fluent bit windows containers for kubernetes it's a still working process",
    "start": "823890",
    "end": "829140"
  },
  {
    "text": "but we also we got people a this is not a working wolf we need more time for it",
    "start": "829140",
    "end": "835550"
  },
  {
    "start": "835000",
    "end": "957000"
  },
  {
    "text": "today we just release fluent bait 13.3 and just explain a little bit we have",
    "start": "835550",
    "end": "843240"
  },
  {
    "text": "the major version which is one they sorry the stable version one major",
    "start": "843240",
    "end": "848970"
  },
  {
    "text": "version three and the last number becomes some inner fixes so every time that we release a new version of will",
    "start": "848970",
    "end": "855420"
  },
  {
    "text": "embed we are aware that if we mess up the things we are going to mess up thousand of nodes so you can always rely",
    "start": "855420",
    "end": "864180"
  },
  {
    "text": "on the stable version like this and every time that the last number change you want you can make sure that it's",
    "start": "864180",
    "end": "870990"
  },
  {
    "text": "just a bug fix something that is not working now it's working and we tested heavily now a bit of the road map a",
    "start": "870990",
    "end": "880710"
  },
  {
    "text": "where we're going for the next year on at the end of January thing we are planted in major release 1.4 a one of",
    "start": "880710",
    "end": "887940"
  },
  {
    "text": "the futures is that config Maps this is not about kubernetes config maps but confirm acts is about a way to avoid",
    "start": "887940",
    "end": "895200"
  },
  {
    "text": "that you make typos in your configuration or you mess up things and we don't tell you why so if you have a",
    "start": "895200",
    "end": "903210"
  },
  {
    "text": "configuration property called parcel and you type a parser a it will tell you a this is wrong this is not going to work",
    "start": "903210",
    "end": "909720"
  },
  {
    "text": "these are the right options and so on is we never imagined that when people use",
    "start": "909720",
    "end": "914820"
  },
  {
    "text": "services like this they make so many mistakes so many so we need to provide a",
    "start": "914820",
    "end": "920490"
  },
  {
    "text": "way to avoid that also we have a bunch of users who are not used",
    "start": "920490",
    "end": "925779"
  },
  {
    "text": "just utf-8 as a text encoding they have latin characters and all kind of",
    "start": "925779",
    "end": "931060"
  },
  {
    "text": "encodings where our old and we are providing support for them - and a we're",
    "start": "931060",
    "end": "937120"
  },
  {
    "text": "continuing invest in stream processor as in Massoud Co explained in that part birth better implement machine learning",
    "start": "937120",
    "end": "943629"
  },
  {
    "text": "algorithms because now fluid is not just for the cloud it can run on the edge and the edge can be anything an old an",
    "start": "943629",
    "end": "950230"
  },
  {
    "text": "embedded device or an embedded gateway and of course continue improving on performance and connectors a little",
    "start": "950230",
    "end": "958899"
  },
  {
    "start": "957000",
    "end": "1007000"
  },
  {
    "text": "introduction about the stream processing before to give the award to Massoud if",
    "start": "958899",
    "end": "963970"
  },
  {
    "text": "we concede that when we do a stream processing we say that its ability to work with data modification or perform",
    "start": "963970",
    "end": "970689"
  },
  {
    "text": "data calculation we have two scenarios we have the edge and we have the cloud and this is fine that is currently",
    "start": "970689",
    "end": "978639"
  },
  {
    "text": "working but most of the stream processor now needs to have a JVM running a couple",
    "start": "978639",
    "end": "984399"
  },
  {
    "text": "of clusters in the cloud and when you want to do data analysis and get faster",
    "start": "984399",
    "end": "990339"
  },
  {
    "text": "response from your queries it takes time or minutes it depends of the month your data you",
    "start": "990339",
    "end": "996910"
  },
  {
    "text": "have so if you send all your data to the cloud you have to wait for indexing or stream processor just complete these",
    "start": "996910",
    "end": "1002910"
  },
  {
    "text": "jobs to run your own queries so how can we make it better so we said eh let's",
    "start": "1002910",
    "end": "1008639"
  },
  {
    "text": "build log in on asteroids right let's put a stream processor on the log in layer and why well the wisest plane and",
    "start": "1008639",
    "end": "1016769"
  },
  {
    "text": "how is this so instead the same login layer we are providing a stream",
    "start": "1016769",
    "end": "1022680"
  },
  {
    "text": "processing capabilities so for certain egg queries or analytics functions that",
    "start": "1022680",
    "end": "1028409"
  },
  {
    "text": "you want to run you don't need to go to the database you just run it on the edge like H computing and then you just ship",
    "start": "1028409",
    "end": "1036000"
  },
  {
    "text": "the results out to the cloud and I'm going to be the N word to my suit so it",
    "start": "1036000",
    "end": "1041058"
  },
  {
    "text": "will do some yes Thank You Eduardo so Edward explained that pretty well and",
    "start": "1041059",
    "end": "1046589"
  },
  {
    "text": "in general so streams of data where we have a streams of data when we collect",
    "start": "1046589",
    "end": "1052770"
  },
  {
    "start": "1048000",
    "end": "1134000"
  },
  {
    "text": "all the data or logs with with fluent bit like we can have logs and metrics if",
    "start": "1052770",
    "end": "1058380"
  },
  {
    "text": "you're deploying that on the edge can have sensor data that we can read by fluent by specific fluent the front bit",
    "start": "1058380",
    "end": "1064590"
  },
  {
    "text": "plugins and this is three pressing on the edge allows us to offload",
    "start": "1064590",
    "end": "1070080"
  },
  {
    "text": "computations from the server side to edge nodes to the collector like in",
    "start": "1070080",
    "end": "1076019"
  },
  {
    "text": "fluent bit so assume that you have thousands of thousands of node and you're just spreading the collect",
    "start": "1076019",
    "end": "1081179"
  },
  {
    "text": "computations on this one thousand nodes is instead of waiting for the node so send the data to the server do the",
    "start": "1081179",
    "end": "1086340"
  },
  {
    "text": "computations and possibly get back to the node the other thing is that you only send required data to the cloud so",
    "start": "1086340",
    "end": "1093779"
  },
  {
    "text": "you don't need to send everything so we'll get back to the to that later in general if you want to write a",
    "start": "1093779",
    "end": "1099539"
  },
  {
    "text": "computation on fluent bit or and everything so you prefer not to write a",
    "start": "1099539",
    "end": "1104789"
  },
  {
    "text": "complicated code yourself you need some sort of simple declarative language that you can describe your computation in so",
    "start": "1104789",
    "end": "1111960"
  },
  {
    "text": "in fluid stream processing we are providing a declarative SQL like language that you can define most of the",
    "start": "1111960",
    "end": "1119159"
  },
  {
    "text": "common computations in that we have provided lots of functions and we are also adding more function to that and",
    "start": "1119159",
    "end": "1126419"
  },
  {
    "text": "one of the main important thing is that it's integrated in fluid co-regency it's pretty fast and it's very resource",
    "start": "1126419",
    "end": "1132480"
  },
  {
    "text": "efficient ok so many of you may be familiar with fluid configuration so we",
    "start": "1132480",
    "end": "1141269"
  },
  {
    "start": "1134000",
    "end": "1302000"
  },
  {
    "text": "can write we can have a syntax for the streams like we can create a stream",
    "start": "1141269",
    "end": "1146370"
  },
  {
    "text": "using the syntax that they will describe later and I will show that to you later that you can just simply add your stream",
    "start": "1146370",
    "end": "1154289"
  },
  {
    "text": "tasks to a file and just think sort of include that file in your fluid country file and that's it it is very simple so",
    "start": "1154289",
    "end": "1161789"
  },
  {
    "text": "this is a kind of a simple form of how you define a stream task in fluent bit",
    "start": "1161789",
    "end": "1168450"
  },
  {
    "text": "and you can go to documentation and see how exactly can you do that I will show",
    "start": "1168450",
    "end": "1174299"
  },
  {
    "text": "that in your to you later in the demo but you definitely say create a stream with a specific stream name as and like",
    "start": "1174299",
    "end": "1182909"
  },
  {
    "text": "a school language you will have a selector statement you can say select this field this world is filled from",
    "start": "1182909",
    "end": "1190110"
  },
  {
    "text": "this stream which is a stream and the stream name can be your input plugins assume that you are reading from memory",
    "start": "1190110",
    "end": "1196980"
  },
  {
    "text": "plug-in and you want to do some sort of averaging of the other the memory usage you can say select mem that used from",
    "start": "1196980",
    "end": "1205200"
  },
  {
    "text": "Stream memory and then in general for stream processors we have to do the",
    "start": "1205200",
    "end": "1210320"
  },
  {
    "text": "computations over a window a window of some specific size so we're defining",
    "start": "1210320",
    "end": "1216380"
  },
  {
    "text": "window of we have two types of windows here that we collect all the data in the",
    "start": "1216380",
    "end": "1221580"
  },
  {
    "text": "window and then we do the calculations like average mean mics time service functional it is and this windows are we",
    "start": "1221580",
    "end": "1229440"
  },
  {
    "text": "have tumbling window which for example is a window of size five seconds which",
    "start": "1229440",
    "end": "1234570"
  },
  {
    "text": "collects on the data insight use does a computation sense the computation throughout to the output plug in throws",
    "start": "1234570",
    "end": "1241980"
  },
  {
    "text": "away everything waits for the window to be filled or we have a hopping window which many of you may know that as a",
    "start": "1241980",
    "end": "1248490"
  },
  {
    "text": "sliding window which we can have a window of size five seconds we wait for the window to be filled we move the",
    "start": "1248490",
    "end": "1254820"
  },
  {
    "text": "window one second by one second and do the calculations over that and I can say that it is very popular more than",
    "start": "1254820",
    "end": "1261240"
  },
  {
    "text": "tumbling window now we can do the filtering over the records that we get",
    "start": "1261240",
    "end": "1266760"
  },
  {
    "text": "by the word condition like SQL so we can just do this calculations and filter a",
    "start": "1266760",
    "end": "1272429"
  },
  {
    "text": "filter already caused by the word condition and we can also do the group by over the fields that you want for",
    "start": "1272429",
    "end": "1281340"
  },
  {
    "text": "example you can have temperature from different temperature sensors in different rooms and you want to get the",
    "start": "1281340",
    "end": "1288240"
  },
  {
    "text": "average based on the room so we can use the group by for example you say group by room number then in the output",
    "start": "1288240",
    "end": "1295350"
  },
  {
    "text": "records then you will you will have one record per room for the average temperature okay but where does this",
    "start": "1295350",
    "end": "1305100"
  },
  {
    "text": "stream processor resides in in the work flow that we had for fluent bit so the film bit has input plugins parser filter",
    "start": "1305100",
    "end": "1311970"
  },
  {
    "text": "buffer and in general what we do is that so we can we sort of pipe the output of",
    "start": "1311970",
    "end": "1318299"
  },
  {
    "text": "the buffer to the stream processor based on the name for example if the input is memory and then we define a signal that",
    "start": "1318299",
    "end": "1325500"
  },
  {
    "text": "says cell like these things from stream memory then we are sort of passing the output",
    "start": "1325500",
    "end": "1333000"
  },
  {
    "text": "of this buffer toward a stream processor and then it is designed in a way that it exactly looks like another input plugin",
    "start": "1333000",
    "end": "1339510"
  },
  {
    "text": "so we can again pass it to filter buffer or you can have a sequence of a stream",
    "start": "1339510",
    "end": "1345810"
  },
  {
    "text": "processor tasks one after each other that makes this very strong and you can",
    "start": "1345810",
    "end": "1351060"
  },
  {
    "text": "do many different kind of scenarios with that this is a subset of the functions",
    "start": "1351060",
    "end": "1358530"
  },
  {
    "start": "1354000",
    "end": "1436000"
  },
  {
    "text": "that we provides so we have more than that and we are going to add more than this as well so we can have average over",
    "start": "1358530",
    "end": "1364290"
  },
  {
    "text": "cheese count minimum maximum and some you can have time functions that you can",
    "start": "1364290",
    "end": "1370140"
  },
  {
    "text": "be added to your output record like and now UNIX times Sam one of the important",
    "start": "1370140",
    "end": "1375450"
  },
  {
    "text": "things that we are working on and we have added currently is that we are started adding time series functions for",
    "start": "1375450",
    "end": "1381450"
  },
  {
    "text": "example we have a forecast function here you have a stream of memory or CPU as",
    "start": "1381450",
    "end": "1387270"
  },
  {
    "text": "soon as you have an a stream of memory and you want to forecast when so what",
    "start": "1387270",
    "end": "1393060"
  },
  {
    "text": "will it be what will be the memory usage in the next 100 seconds and then based on this forecast you may some send some",
    "start": "1393060",
    "end": "1400320"
  },
  {
    "text": "alerts to some services on the cloud this is actually a simple linear",
    "start": "1400320",
    "end": "1405810"
  },
  {
    "text": "regression here but it's just possible if someone is interested can add more time service function to that and we are",
    "start": "1405810",
    "end": "1411930"
  },
  {
    "text": "working on adding more what about important things so I don't have that in the demo but assume that you have a",
    "start": "1411930",
    "end": "1418140"
  },
  {
    "text": "nested Jason so can we do anything on the nested Jason so yes so we are also providing sub keys so you can do all",
    "start": "1418140",
    "end": "1425760"
  },
  {
    "text": "these kind of operations on key sub key one sub key too so if you have an acyl",
    "start": "1425760",
    "end": "1431790"
  },
  {
    "text": "Jason you're still able to use a string processor example so I will I will demo",
    "start": "1431790",
    "end": "1439320"
  },
  {
    "start": "1436000",
    "end": "1514000"
  },
  {
    "text": "this now so like out of memory forecast so as soon as we have an input memory in",
    "start": "1439320",
    "end": "1445530"
  },
  {
    "text": "an input plug in memory that we are reading the memory usage on a specific note and then we want to forecast the",
    "start": "1445530",
    "end": "1455100"
  },
  {
    "text": "memory usage in the next 100 seconds so this is this is a simple simple example of that you can say select",
    "start": "1455100",
    "end": "1461159"
  },
  {
    "text": "transfers forecast the first parameter is your records time the second parameter is a mem that used which is",
    "start": "1461159",
    "end": "1467970"
  },
  {
    "text": "which you read from them input plug in memory and the third parameter is 100",
    "start": "1467970",
    "end": "1475049"
  },
  {
    "text": "and if it's the first if the first parameter is time it means 100 seconds after the record",
    "start": "1475049",
    "end": "1480570"
  },
  {
    "text": "time so we want to see what will be the childhood what will be the forecast for memory usage on this note in the next",
    "start": "1480570",
    "end": "1485940"
  },
  {
    "text": "100 seconds from a stream memory input memory plug in and we have a hopping",
    "start": "1485940",
    "end": "1492000"
  },
  {
    "text": "window or sliding window of size 30 seconds that does this forecasting over",
    "start": "1492000",
    "end": "1497070"
  },
  {
    "text": "the 30 seconds and in general we read one one sample per second so it's like over the 30 samples and move it one",
    "start": "1497070",
    "end": "1504240"
  },
  {
    "text": "second by one second in general so if you have a line your windows you have a better forecasting by the way so you",
    "start": "1504240",
    "end": "1511169"
  },
  {
    "text": "will have less noise in your forecasting so we'll see that in the demo ok so I",
    "start": "1511169",
    "end": "1519600"
  },
  {
    "start": "1514000",
    "end": "1871000"
  },
  {
    "text": "show you a configuration for that so we will have learnt paid forecast",
    "start": "1519600",
    "end": "1528360"
  },
  {
    "text": "configuration so if you are familiar with the configuration you will",
    "start": "1528360",
    "end": "1533399"
  },
  {
    "text": "understand it better otherwise don't worry about that I wouldn't go through the details but I wanted to say is that in the section service you just define a",
    "start": "1533399",
    "end": "1540120"
  },
  {
    "text": "file as the stream file and the name of the file that you define your stream",
    "start": "1540120",
    "end": "1545640"
  },
  {
    "text": "tasks and you will have input memory",
    "start": "1545640",
    "end": "1551100"
  },
  {
    "text": "that is titusz memory so we'll use that in our query and I'm sending that to",
    "start": "1551100",
    "end": "1556710"
  },
  {
    "text": "influx DB in order to visualize that and there is another output so it's like output that is just that I'd rather just",
    "start": "1556710",
    "end": "1564419"
  },
  {
    "text": "you know emerge that into master is a pretty nice plugin that you can send your alerts here for example I'm sending",
    "start": "1564419",
    "end": "1569909"
  },
  {
    "text": "everything that matches the tag alert to slack and I'm also showing everything",
    "start": "1569909",
    "end": "1575039"
  },
  {
    "text": "I'm sending everything to CDR to make sure everything is working with fine and having a quick look at the the memory",
    "start": "1575039",
    "end": "1583350"
  },
  {
    "text": "forecast a streaming tasks so it is a bit different from what I showed you that was a simple thing you will define",
    "start": "1583350",
    "end": "1589260"
  },
  {
    "text": "your tasks like this you will define your stream tasks here and then exact and define here as Krita stream I just go",
    "start": "1589260",
    "end": "1596520"
  },
  {
    "text": "through the end now to say that we do from a stream memory and a hopping",
    "start": "1596520",
    "end": "1601620"
  },
  {
    "text": "window 15 seconds a small hopping window for the sake of the demo it's better to have a longer one to have better and",
    "start": "1601620",
    "end": "1606870"
  },
  {
    "text": "less noise and better accuracy and I'm applying an average effort the memory usage memory I'd used and I'm trying to",
    "start": "1606870",
    "end": "1614700"
  },
  {
    "text": "also forecast the memory usage in the next 100 seconds and send it to the",
    "start": "1614700",
    "end": "1620010"
  },
  {
    "text": "output record with the name of forecast oh yeah sure",
    "start": "1620010",
    "end": "1627140"
  },
  {
    "text": "it's good ok so in the second test offer",
    "start": "1627140",
    "end": "1633960"
  },
  {
    "text": "for the sake of having less noise I just read from the above a stream forecast",
    "start": "1633960",
    "end": "1639030"
  },
  {
    "text": "and apply an average over the forecast have a list less noisy forecast for the sake of them are by the way and now I",
    "start": "1639030",
    "end": "1645840"
  },
  {
    "text": "have another stream here called alert so I read from this forecast average the",
    "start": "1645840",
    "end": "1651690"
  },
  {
    "text": "average over the forecast which is smoother than the forecast by the way and create a stream called alert to",
    "start": "1651690",
    "end": "1657570"
  },
  {
    "text": "whenever our forecasts it's over 1.5 gigahertz of memory that's it now we try",
    "start": "1657570",
    "end": "1666210"
  },
  {
    "text": "to run it ok so build from be it and the",
    "start": "1666210",
    "end": "1675690"
  },
  {
    "text": "configuration file is demo one bit for chess okay so if user it's a CD out so",
    "start": "1675690",
    "end": "1685620"
  },
  {
    "text": "this shows the output of the memory plug memory plug in so this is what memory",
    "start": "1685620",
    "end": "1690660"
  },
  {
    "text": "plug in sends to our forecast stream after 30 seconds here we are starting to",
    "start": "1690660",
    "end": "1697020"
  },
  {
    "text": "get forecasts as well so this is the output of the forecast so I stop here sort of so this is a forecast that has",
    "start": "1697020",
    "end": "1704370"
  },
  {
    "text": "average of memory used and the forecast in the next 100 seconds and this is an average over the forecast and this is",
    "start": "1704370",
    "end": "1712320"
  },
  {
    "text": "again under you know earlier output from the memory field so if I go here I can",
    "start": "1712320",
    "end": "1717630"
  },
  {
    "text": "see yes this these are the green line is the forecast and the the green line is",
    "start": "1717630",
    "end": "1723090"
  },
  {
    "text": "the average of memory usage and one is the forecast which is almost the",
    "start": "1723090",
    "end": "1728480"
  },
  {
    "text": "same because we are not changing the memory usage on there on the machine but now if I start running some service that",
    "start": "1728480",
    "end": "1737840"
  },
  {
    "text": "starts consuming memory then you can see",
    "start": "1737840",
    "end": "1742909"
  },
  {
    "text": "that the forecasts start to increase that means that the yellow line says",
    "start": "1742909",
    "end": "1747980"
  },
  {
    "text": "shows the forecast in the next 100 seconds that says all in the National 100 seconds we have this amount of",
    "start": "1747980",
    "end": "1753110"
  },
  {
    "text": "memory used again because the window is not that long so you can see some sort",
    "start": "1753110",
    "end": "1758869"
  },
  {
    "text": "of not very smooth changes but at the end of the day you can see that it's",
    "start": "1758869",
    "end": "1764389"
  },
  {
    "text": "going up and up and we are hoping that when it gets to 1.5 gigabytes of memory usage we will get some alert on a",
    "start": "1764389",
    "end": "1771289"
  },
  {
    "text": "selectional that we created for that ok it's it a week we can wait while it's",
    "start": "1771289",
    "end": "1778909"
  },
  {
    "text": "showing that maybe I can move to the other one and just wait for therefore this lag alert because we don't have",
    "start": "1778909",
    "end": "1784129"
  },
  {
    "text": "that much time so or we can get to that possibly soon",
    "start": "1784129",
    "end": "1790269"
  },
  {
    "text": "yeah close",
    "start": "1804490",
    "end": "1808710"
  },
  {
    "text": "yes possible is coming oh here I think",
    "start": "1838250",
    "end": "1843420"
  },
  {
    "text": "it notification but we are I was waiting for the notification but we are getting alerts on the slack channel here so that",
    "start": "1843420",
    "end": "1850920"
  },
  {
    "text": "means that so it takes you know it takes a memory usage and sending others for us on this next channel so I was hoping",
    "start": "1850920",
    "end": "1857040"
  },
  {
    "text": "that I get notification on here under notification bar but I didn't so okay",
    "start": "1857040",
    "end": "1864270"
  },
  {
    "text": "this is one thing that you can use so like time series forecast but one other",
    "start": "1864270",
    "end": "1872700"
  },
  {
    "start": "1871000",
    "end": "1911000"
  },
  {
    "text": "important thing that we are going to have in the next releases snapshot once",
    "start": "1872700",
    "end": "1879870"
  },
  {
    "text": "one a some some team that was working on the edge computation told us look so we don't want to send everything like 100",
    "start": "1879870",
    "end": "1887010"
  },
  {
    "text": "lakhs per second to the server's so we want to send data to the server so the cloud only when it is required so this a",
    "start": "1887010",
    "end": "1896010"
  },
  {
    "text": "snapshot is a new feature that is pretty well working with that like we create a",
    "start": "1896010",
    "end": "1902400"
  },
  {
    "text": "snapshot over as well our record a snapshot over on a stream and we just",
    "start": "1902400",
    "end": "1908430"
  },
  {
    "text": "flush flush the snapshot when something happens for example an Apache server so",
    "start": "1908430",
    "end": "1915300"
  },
  {
    "start": "1911000",
    "end": "1971000"
  },
  {
    "text": "they don't want to send all the info info likes to the server but whenever in the 500-hour happens they want to send",
    "start": "1915300",
    "end": "1921270"
  },
  {
    "text": "love to the server but the prop the point is when a 500 error happens you need to see a history of logs in order",
    "start": "1921270",
    "end": "1927720"
  },
  {
    "text": "to debug things because of that we clear the snapshot of some size like here five seconds from the stream Apache here and",
    "start": "1927720",
    "end": "1936570"
  },
  {
    "text": "it has second it has the property of five seconds or a limit of ten so we can",
    "start": "1936570",
    "end": "1942030"
  },
  {
    "text": "have the snapshot of size or the number of records or both of them or one of them here I added both of them and here",
    "start": "1942030",
    "end": "1947730"
  },
  {
    "text": "in the seconds now in the second rule we can say flush a snapshot from this stream Apache",
    "start": "1947730",
    "end": "1953880"
  },
  {
    "text": "when code is 500 then whenever a 500 error happens so it flushes the snapshot",
    "start": "1953880",
    "end": "1959429"
  },
  {
    "text": "to the output plug in this this - doesn't need to be the same so we can create a snapshot on one stream and you",
    "start": "1959429",
    "end": "1966690"
  },
  {
    "text": "can apply a condition on another stream that that makes it pretty flexible demo",
    "start": "1966690",
    "end": "1972030"
  },
  {
    "start": "1971000",
    "end": "2114000"
  },
  {
    "text": "for that okay so for a demo I just show",
    "start": "1972030",
    "end": "1978450"
  },
  {
    "text": "I think you have seen that but I again I think this is very similar so the live",
    "start": "1978450",
    "end": "1988350"
  },
  {
    "text": "snapshot we exactly have these two things that you saw on the previous slide so we are reading a from an Apache",
    "start": "1988350",
    "end": "1994320"
  },
  {
    "text": "a lot from up from without reading opportu likes and whenever an error 500 happens be flushed and and I've used",
    "start": "1994320",
    "end": "2002780"
  },
  {
    "text": "some sort of lagging like these artificial eyes that I'm using as a kind of parse as Jason in a file that I'm",
    "start": "2002780",
    "end": "2009919"
  },
  {
    "text": "just passing those likes to fluent bit to see how it how it works these are all 200 codes 200 HTTP status codes and here",
    "start": "2009919",
    "end": "2018230"
  },
  {
    "text": "I have a 500 and I'm assuming that I'm pumping this soon blog the one per second to fluent bit and I'm expecting",
    "start": "2018230",
    "end": "2025130"
  },
  {
    "text": "that I can see at least five previous logs on my slack channel so if I run",
    "start": "2025130",
    "end": "2032360"
  },
  {
    "text": "this",
    "start": "2032360",
    "end": "2034600"
  },
  {
    "text": "and what I would do is that I'm reading this what she likes and sending this to",
    "start": "2041460",
    "end": "2049658"
  },
  {
    "text": "another liked fight that I'm tailing simulating reading the likes from Apache",
    "start": "2049659",
    "end": "2056220"
  },
  {
    "text": "then it sends like one per second here and I'm expecting that when I get to 500",
    "start": "2056220",
    "end": "2064388"
  },
  {
    "text": "error I get a snapshot of size five to our aqua channel yes you can see that in",
    "start": "2064389",
    "end": "2070690"
  },
  {
    "text": "the acedia out and possible if I go here you can see that the snapshot is sent to",
    "start": "2070690",
    "end": "2076628"
  },
  {
    "text": "our slack channel which you can think of that as the snapshot is sent your like server for example so that means that we",
    "start": "2076629",
    "end": "2083230"
  },
  {
    "text": "are not sending under law all the logs to the server we are just sending a snapshot of the lock to the server",
    "start": "2083230",
    "end": "2089850"
  },
  {
    "text": "whenever an event happens or air or happens which is very important for edge",
    "start": "2089850",
    "end": "2095950"
  },
  {
    "text": "nodes especially because they have problems with the resource limits their problem with bandwidth and everything so",
    "start": "2095950",
    "end": "2102280"
  },
  {
    "text": "we don't want to send everything we don't want to consume bandwidth so that is also a feature that we are going to",
    "start": "2102280",
    "end": "2108040"
  },
  {
    "text": "release in in the next in 1.4 I think",
    "start": "2108040",
    "end": "2113160"
  },
  {
    "start": "2114000",
    "end": "2613000"
  },
  {
    "text": "and if you have any questions please ask your questions",
    "start": "2114390",
    "end": "2120630"
  },
  {
    "text": "so we define the size of the snapshots in two ways so we can define it in",
    "start": "2130770",
    "end": "2136740"
  },
  {
    "text": "seconds like the size of the window of the snapshot or we can have another",
    "start": "2136740",
    "end": "2143920"
  },
  {
    "text": "another measurement for that which is limit so we can have the snapshots that",
    "start": "2143920",
    "end": "2149140"
  },
  {
    "text": "is of size 10 records or 5 seconds which were comes first or it's not mandatory",
    "start": "2149140",
    "end": "2155080"
  },
  {
    "text": "to use both of them so you can use just limiting so we can we keep 10 records or",
    "start": "2155080",
    "end": "2160900"
  },
  {
    "text": "just size we give a snapshot of size 5 seconds exactly",
    "start": "2160900",
    "end": "2169360"
  },
  {
    "text": "yeah yeah we do like better safety like for the last 5 seconds",
    "start": "2169360",
    "end": "2174700"
  },
  {
    "text": "you have many different snapshots one overwrite the other some when it happens it takes the last snapshot that we don't",
    "start": "2174700",
    "end": "2181750"
  },
  {
    "text": "last 5 seconds with records",
    "start": "2181750",
    "end": "2185400"
  },
  {
    "text": "well in that question is forcing us to release our secret to take over the",
    "start": "2223530",
    "end": "2229840"
  },
  {
    "text": "world but a yes dynamic configuration is something that we have been asking many",
    "start": "2229840",
    "end": "2237160"
  },
  {
    "text": "times but of course we got other priorities and I think that what you see with",
    "start": "2237160",
    "end": "2242410"
  },
  {
    "text": "conflict maps which is a way to help the users with configuration it's also a way",
    "start": "2242410",
    "end": "2248680"
  },
  {
    "text": "for plugins to say eh this is a Manman configuration and this is that data types with that in place we can",
    "start": "2248680",
    "end": "2256660"
  },
  {
    "text": "implement dynamic configuration because I don't want to restart a plug-in if they configure a new configuration is",
    "start": "2256660",
    "end": "2263050"
  },
  {
    "text": "wrong and I need a way to validate that before hint so config Maps is for that",
    "start": "2263050",
    "end": "2268480"
  },
  {
    "text": "also second question hey this is really cool",
    "start": "2268480",
    "end": "2273630"
  },
  {
    "text": "really and I'm very excited via NASA too but also what we're most excited is that",
    "start": "2273630",
    "end": "2280590"
  },
  {
    "text": "UB will be able to run sequel queries remotely so from your own application",
    "start": "2280590",
    "end": "2288190"
  },
  {
    "text": "you're going to connect to the bigger pipeline of flow embed you're going to say run some sequel queries and the",
    "start": "2288190",
    "end": "2294010"
  },
  {
    "text": "results will go to your client application and we are going to add",
    "start": "2294010",
    "end": "2300490"
  },
  {
    "text": "persistency to",
    "start": "2300490",
    "end": "2303300"
  },
  {
    "text": "okay that's the push backs off today Multi line looks when a java application",
    "start": "2324630",
    "end": "2329920"
  },
  {
    "text": "or you get a stack trace and your application generate like twenty lines",
    "start": "2329920",
    "end": "2335530"
  },
  {
    "text": "but the containers handled that like twenty different records okay in fluent",
    "start": "2335530",
    "end": "2340870"
  },
  {
    "text": "bit we support multi line out of a Dockers we you can configure a",
    "start": "2340870",
    "end": "2346750"
  },
  {
    "text": "multi-line mode and you said the first line of a multi-line stack trace looks like this so everything after that is a",
    "start": "2346750",
    "end": "2353740"
  },
  {
    "text": "continuation so we have a way to correlate that but the problem with containers is that the message is not in",
    "start": "2353740",
    "end": "2360610"
  },
  {
    "text": "the main the main line is inside a record of a JSON so we are going to add",
    "start": "2360610",
    "end": "2366940"
  },
  {
    "text": "support for that because people is asking and yeah we have to deal with Java yeah that's why it's configurable",
    "start": "2366940",
    "end": "2379960"
  },
  {
    "text": "so you can say how your pattern will look like so yeah well let's start with",
    "start": "2379960",
    "end": "2389170"
  },
  {
    "text": "one so you can say this is my first pattern and maybe you will need to specify an order but that is something",
    "start": "2389170",
    "end": "2395920"
  },
  {
    "text": "that we need to iterate with community community yeah sure",
    "start": "2395920",
    "end": "2404490"
  },
  {
    "text": "good use case okay okay oh yeah we have",
    "start": "2409140",
    "end": "2415119"
  },
  {
    "text": "to implement that",
    "start": "2415119",
    "end": "2417748"
  },
  {
    "text": "yes so you define a tag here and your output plug-in will actually says that",
    "start": "2432600",
    "end": "2439530"
  },
  {
    "text": "if you see the tag then I will send that to the output sever rudder so based on",
    "start": "2439530",
    "end": "2445860"
  },
  {
    "text": "this tag you define for example here so the way that the configuration is",
    "start": "2445860",
    "end": "2451020"
  },
  {
    "text": "written is like so the other plugin says",
    "start": "2451020",
    "end": "2460610"
  },
  {
    "text": "whenever a string comes that matches like underlined external app shot on",
    "start": "2460610",
    "end": "2466590"
  },
  {
    "text": "neural Flashdance and his Twitter slack so you match based on this yeah so you",
    "start": "2466590",
    "end": "2472320"
  },
  {
    "text": "don't want to use the slack for production battosai yeah for for alerts is pretty good as many people use this",
    "start": "2472320",
    "end": "2478860"
  },
  {
    "text": "like for alerts so you may define your alerts whatever they have to tell your maintainer or whatever that something is",
    "start": "2478860",
    "end": "2485520"
  },
  {
    "text": "wrong",
    "start": "2485520",
    "end": "2487730"
  },
  {
    "text": "so if you sit under discussion by the way so we are trying to see if we can sums we can add some sort of tensorflow",
    "start": "2509270",
    "end": "2516520"
  },
  {
    "text": "capabilities to that but it it is not an easy thing to to work on because it",
    "start": "2516520",
    "end": "2522080"
  },
  {
    "text": "might be heavy for edge devices so that is under discussion so so at the moment",
    "start": "2522080",
    "end": "2528619"
  },
  {
    "text": "I am Not sure that if we can release any kind of tensor tensor flow based inference or something for version 1.4",
    "start": "2528619",
    "end": "2536270"
  },
  {
    "text": "for at least so we can add more time series functionalities",
    "start": "2536270",
    "end": "2541450"
  },
  {
    "text": "so you have a mic so yeah sorry yes it's",
    "start": "2552859",
    "end": "2566760"
  },
  {
    "text": "coming so we support multi line but not multi line in containers that is coming for containers no no they flew in this",
    "start": "2566760",
    "end": "2584760"
  },
  {
    "text": "reading in Ruby and C but the API of who and babe is totally different so so we",
    "start": "2584760",
    "end": "2591630"
  },
  {
    "text": "build we build plugins and based on community needs get what that is",
    "start": "2591630",
    "end": "2601970"
  },
  {
    "text": "what thanks so much for coming and we are free to talk if you want",
    "start": "2601970",
    "end": "2607210"
  },
  {
    "text": "[Applause]",
    "start": "2607210",
    "end": "2613030"
  }
]
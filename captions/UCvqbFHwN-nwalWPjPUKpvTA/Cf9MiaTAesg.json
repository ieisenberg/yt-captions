[
  {
    "text": "uh",
    "start": "2520",
    "end": "4080"
  },
  {
    "text": "uh yep uh hi everyone uh I'm nit and uh",
    "start": "4080",
    "end": "9519"
  },
  {
    "text": "uh I was an early engineer at atlin and",
    "start": "9519",
    "end": "11799"
  },
  {
    "text": "now I'm in the platform engineering team",
    "start": "11799",
    "end": "13839"
  },
  {
    "text": "uh I live in San California I'm here",
    "start": "13839",
    "end": "15599"
  },
  {
    "text": "with my colleague SATA Paul uh to",
    "start": "15599",
    "end": "18199"
  },
  {
    "text": "present uh some of the case studies that",
    "start": "18199",
    "end": "20320"
  },
  {
    "text": "we had done with AO workflows uh at uh",
    "start": "20320",
    "end": "23240"
  },
  {
    "text": "at a company uh and we built uh scalable",
    "start": "23240",
    "end": "26199"
  },
  {
    "text": "and effective workflows and we going to",
    "start": "26199",
    "end": "27800"
  },
  {
    "text": "talk about some of the capabilities that",
    "start": "27800",
    "end": "28880"
  },
  {
    "text": "we unlocked with Argo workflows uh in a",
    "start": "28880",
    "end": "31800"
  },
  {
    "text": "company and uh yeah let's go sorry yeah",
    "start": "31800",
    "end": "37520"
  },
  {
    "text": "I just going to step step back a bit and",
    "start": "37520",
    "end": "39399"
  },
  {
    "text": "talk about atlin and how it's relevant",
    "start": "39399",
    "end": "41120"
  },
  {
    "text": "to why we use Argo workflows uh atlin",
    "start": "41120",
    "end": "43840"
  },
  {
    "text": "think of it as uh a place uh uh a",
    "start": "43840",
    "end": "47039"
  },
  {
    "text": "collaborative workspace for data teams",
    "start": "47039",
    "end": "49039"
  },
  {
    "text": "uh just like GitHub is for engineering",
    "start": "49039",
    "end": "50520"
  },
  {
    "text": "teams and figma is for design teams",
    "start": "50520",
    "end": "52960"
  },
  {
    "text": "atlan is for data teams to collaborate",
    "start": "52960",
    "end": "55199"
  },
  {
    "text": "uh we provided a single pain for uh data",
    "start": "55199",
    "end": "58120"
  },
  {
    "text": "Engineers or any personas uh to uh trust",
    "start": "58120",
    "end": "62039"
  },
  {
    "text": "govern and collaborate on data assets uh",
    "start": "62039",
    "end": "65720"
  },
  {
    "text": "we go next okay oop",
    "start": "65720",
    "end": "69320"
  },
  {
    "text": "sorry oh it doesn't show up okay uh I",
    "start": "69320",
    "end": "72759"
  },
  {
    "text": "think we are facing some issues with the",
    "start": "72759",
    "end": "73960"
  },
  {
    "text": "internet",
    "start": "73960",
    "end": "76840"
  },
  {
    "text": "uh give me one yeah",
    "start": "77880",
    "end": "82200"
  },
  {
    "text": "connect uh it's it's fine I guess if",
    "start": "84600",
    "end": "88000"
  },
  {
    "text": "it's uh can can we go back a bit can you",
    "start": "88000",
    "end": "92520"
  },
  {
    "text": "drive once no go back no it's not okay",
    "start": "92520",
    "end": "98479"
  },
  {
    "text": "try going back it oh yeah uh so I",
    "start": "98479",
    "end": "102680"
  },
  {
    "text": "talking about atlin uh we are uh we are",
    "start": "102680",
    "end": "105560"
  },
  {
    "text": "created top across the all the journals",
    "start": "105560",
    "end": "107719"
  },
  {
    "text": "that you could see uh we have top right",
    "start": "107719",
    "end": "109560"
  },
  {
    "text": "corner in the Gardner uh the Forester",
    "start": "109560",
    "end": "111520"
  },
  {
    "text": "wave and also top right in the Gardner",
    "start": "111520",
    "end": "113920"
  },
  {
    "text": "Gartner reviews and we are uh powering",
    "start": "113920",
    "end": "115759"
  },
  {
    "text": "data teams across the world uh to uh",
    "start": "115759",
    "end": "119520"
  },
  {
    "text": "just to quickly prace how how many of",
    "start": "119520",
    "end": "122159"
  },
  {
    "text": "you uh use Argo workflows for ETL",
    "start": "122159",
    "end": "124799"
  },
  {
    "text": "workflows in a company oh that's a nice",
    "start": "124799",
    "end": "127000"
  },
  {
    "text": "show of hands here thanks uh and uh how",
    "start": "127000",
    "end": "130080"
  },
  {
    "text": "many of you all have used it for more",
    "start": "130080",
    "end": "131959"
  },
  {
    "text": "than 10 million records uh show fans uh",
    "start": "131959",
    "end": "134400"
  },
  {
    "text": "because we're talk talking about scale",
    "start": "134400",
    "end": "135760"
  },
  {
    "text": "here oh thank you we have some folks",
    "start": "135760",
    "end": "138080"
  },
  {
    "text": "from pip kit also here as fun uh at",
    "start": "138080",
    "end": "140519"
  },
  {
    "text": "atlin we we took a bold step couple of",
    "start": "140519",
    "end": "142440"
  },
  {
    "text": "years back uh to use Argo workflows for",
    "start": "142440",
    "end": "144720"
  },
  {
    "text": "data processing uh for all of us who",
    "start": "144720",
    "end": "147239"
  },
  {
    "text": "know Argo workflows was initially built",
    "start": "147239",
    "end": "149040"
  },
  {
    "text": "for uh uh highly for highly paralyzed",
    "start": "149040",
    "end": "152239"
  },
  {
    "text": "orchestrating highly paralyzed uh",
    "start": "152239",
    "end": "154239"
  },
  {
    "text": "kubernetes jobs uh but we to the B set",
    "start": "154239",
    "end": "157720"
  },
  {
    "text": "to use it as a data processing uh for",
    "start": "157720",
    "end": "160200"
  },
  {
    "text": "data processing workflows and at",
    "start": "160200",
    "end": "161560"
  },
  {
    "text": "workflows uh and uh yeah if we if you go",
    "start": "161560",
    "end": "164879"
  },
  {
    "text": "next previously we also presented uh",
    "start": "164879",
    "end": "167159"
  },
  {
    "text": "some of our internal Touring that we uh",
    "start": "167159",
    "end": "168920"
  },
  {
    "text": "that we used at uh at a company which is",
    "start": "168920",
    "end": "170920"
  },
  {
    "text": "called Argo pm to manage uh Argo",
    "start": "170920",
    "end": "173120"
  },
  {
    "text": "workflows which is built on top of ku's",
    "start": "173120",
    "end": "175239"
  },
  {
    "text": "uh apis uh we did this did that at",
    "start": "175239",
    "end": "178280"
  },
  {
    "text": "Amsterdam last year and also at Chago",
    "start": "178280",
    "end": "180360"
  },
  {
    "text": "Argo argoon Chicago for using the Argo",
    "start": "180360",
    "end": "183640"
  },
  {
    "text": "CD here you go uh yeah so Argo workflows",
    "start": "183640",
    "end": "188159"
  },
  {
    "text": "we use we we heavily leverage Argo",
    "start": "188159",
    "end": "190400"
  },
  {
    "text": "workflows uh for our Marketplace if you",
    "start": "190400",
    "end": "192560"
  },
  {
    "text": "see we have a bunch of connectors we",
    "start": "192560",
    "end": "194440"
  },
  {
    "text": "have more than 50 connectors all of",
    "start": "194440",
    "end": "196480"
  },
  {
    "text": "which is built using Argo workflows",
    "start": "196480",
    "end": "198040"
  },
  {
    "text": "heavily uh and we go next yeah U what is",
    "start": "198040",
    "end": "202959"
  },
  {
    "text": "ETL workflow right just for some of us",
    "start": "202959",
    "end": "205319"
  },
  {
    "text": "uh ETL is just extract transform load",
    "start": "205319",
    "end": "208040"
  },
  {
    "text": "extract you connect to a source extract",
    "start": "208040",
    "end": "210319"
  },
  {
    "text": "some metadata in our case transform",
    "start": "210319",
    "end": "212400"
  },
  {
    "text": "means you process you do some",
    "start": "212400",
    "end": "213840"
  },
  {
    "text": "Transformations on top of it uh in order",
    "start": "213840",
    "end": "216000"
  },
  {
    "text": "to comply with the schema that you have",
    "start": "216000",
    "end": "218680"
  },
  {
    "text": "in the load step uh in load is basically",
    "start": "218680",
    "end": "221439"
  },
  {
    "text": "where you load the transform metadata",
    "start": "221439",
    "end": "223640"
  },
  {
    "text": "into a warehouse or data catalog right",
    "start": "223640",
    "end": "226280"
  },
  {
    "text": "this is how it just go back yeah this is",
    "start": "226280",
    "end": "228519"
  },
  {
    "text": "how it uh basically looks like an Argo",
    "start": "228519",
    "end": "230319"
  },
  {
    "text": "it's a dag you can see there's some",
    "start": "230319",
    "end": "231959"
  },
  {
    "text": "steps for extraction there's some step",
    "start": "231959",
    "end": "233799"
  },
  {
    "text": "for transformation and stuff and then we",
    "start": "233799",
    "end": "235799"
  },
  {
    "text": "just heavily paralyze to load it in the",
    "start": "235799",
    "end": "237680"
  },
  {
    "text": "data catalog or or a data Warehouse",
    "start": "237680",
    "end": "240319"
  },
  {
    "text": "right uh if we go next yeah while using",
    "start": "240319",
    "end": "244120"
  },
  {
    "text": "Argo workflows initially it was going",
    "start": "244120",
    "end": "246040"
  },
  {
    "text": "really great but then we hit some",
    "start": "246040",
    "end": "247799"
  },
  {
    "text": "challenges with scale our source volume",
    "start": "247799",
    "end": "249959"
  },
  {
    "text": "was really grow uh really clobbering up",
    "start": "249959",
    "end": "252480"
  },
  {
    "text": "it's basically it went from couple of,",
    "start": "252480",
    "end": "254439"
  },
  {
    "text": "100K or 500k to Millions 10 millions and",
    "start": "254439",
    "end": "258320"
  },
  {
    "text": "and we recently saw a request for 100",
    "start": "258320",
    "end": "259880"
  },
  {
    "text": "million assets as well which is bringing",
    "start": "259880",
    "end": "261600"
  },
  {
    "text": "in 100 million assets from Source",
    "start": "261600",
    "end": "263479"
  },
  {
    "text": "transforming it and also loading it that",
    "start": "263479",
    "end": "265639"
  },
  {
    "text": "was a huge scale for us so what we're",
    "start": "265639",
    "end": "267680"
  },
  {
    "text": "going to talk about today is two two",
    "start": "267680",
    "end": "269720"
  },
  {
    "text": "pillars one is performance and the other",
    "start": "269720",
    "end": "271840"
  },
  {
    "text": "is system reliability performance when I",
    "start": "271840",
    "end": "273840"
  },
  {
    "text": "talk about it how do we perform well",
    "start": "273840",
    "end": "276400"
  },
  {
    "text": "when there's so much estate at source",
    "start": "276400",
    "end": "278880"
  },
  {
    "text": "right how do we massively improve it how",
    "start": "278880",
    "end": "281639"
  },
  {
    "text": "do you provide good run times for our",
    "start": "281639",
    "end": "282960"
  },
  {
    "text": "customers and manage the slas as well",
    "start": "282960",
    "end": "284919"
  },
  {
    "text": "right uh go next so I'm going to cover",
    "start": "284919",
    "end": "287880"
  },
  {
    "text": "performance pillar and my colleague will",
    "start": "287880",
    "end": "289440"
  },
  {
    "text": "cover uh the reliability pillar in",
    "start": "289440",
    "end": "291680"
  },
  {
    "text": "performance there are uh when you run a",
    "start": "291680",
    "end": "293840"
  },
  {
    "text": "workflow there's always two categories",
    "start": "293840",
    "end": "296720"
  },
  {
    "text": "or of runs right one is when you run it",
    "start": "296720",
    "end": "299720"
  },
  {
    "text": "for the first time uh in especially",
    "start": "299720",
    "end": "301840"
  },
  {
    "text": "especially in the ETL workflow one is",
    "start": "301840",
    "end": "303479"
  },
  {
    "text": "when you run it for the first time and",
    "start": "303479",
    "end": "305320"
  },
  {
    "text": "then when you once you have the",
    "start": "305320",
    "end": "306759"
  },
  {
    "text": "subsequent run what does first run mean",
    "start": "306759",
    "end": "309320"
  },
  {
    "text": "it this is the first very first run of",
    "start": "309320",
    "end": "311440"
  },
  {
    "text": "the workflow and uh there's no State",
    "start": "311440",
    "end": "314160"
  },
  {
    "text": "there's no context nothing there's no",
    "start": "314160",
    "end": "315680"
  },
  {
    "text": "States stored right subsequent is",
    "start": "315680",
    "end": "317320"
  },
  {
    "text": "basically when you have some states",
    "start": "317320",
    "end": "318800"
  },
  {
    "text": "store and you can leverage it to make",
    "start": "318800",
    "end": "320680"
  },
  {
    "text": "the run times faster for the subsequent",
    "start": "320680",
    "end": "322280"
  },
  {
    "text": "runs right",
    "start": "322280",
    "end": "324280"
  },
  {
    "text": "uh okay let's go back yeah that's about",
    "start": "324280",
    "end": "327039"
  },
  {
    "text": "first R uh the transformation steps so",
    "start": "327039",
    "end": "329360"
  },
  {
    "text": "we realiz that there was a single part",
    "start": "329360",
    "end": "331600"
  },
  {
    "text": "that we were using a single process",
    "start": "331600",
    "end": "333840"
  },
  {
    "text": "which was doing all the transformation",
    "start": "333840",
    "end": "335880"
  },
  {
    "text": "uh if you see this is an example of a a",
    "start": "335880",
    "end": "339240"
  },
  {
    "text": "SQL Universe where we extracting",
    "start": "339240",
    "end": "340800"
  },
  {
    "text": "databases schema tables and columns and",
    "start": "340800",
    "end": "343600"
  },
  {
    "text": "we just had a single transformation part",
    "start": "343600",
    "end": "345160"
  },
  {
    "text": "which is essentially a single process to",
    "start": "345160",
    "end": "346680"
  },
  {
    "text": "extract to transform all the data and we",
    "start": "346680",
    "end": "349199"
  },
  {
    "text": "realized this was taking about 95% of",
    "start": "349199",
    "end": "350960"
  },
  {
    "text": "the time there's one more insight here",
    "start": "350960",
    "end": "354280"
  },
  {
    "text": "that it for if we just did a",
    "start": "354280",
    "end": "356240"
  },
  {
    "text": "benchmarking we observed that for 100",
    "start": "356240",
    "end": "358199"
  },
  {
    "text": "million records it was taking the",
    "start": "358199",
    "end": "359240"
  },
  {
    "text": "transformation step itself was taking 22",
    "start": "359240",
    "end": "361600"
  },
  {
    "text": "hours which is almost a day right and",
    "start": "361600",
    "end": "364160"
  },
  {
    "text": "extraction was another base of its own",
    "start": "364160",
    "end": "366360"
  },
  {
    "text": "right so just to give a breakdown of SQL",
    "start": "366360",
    "end": "369199"
  },
  {
    "text": "universe in our customer environment it",
    "start": "369199",
    "end": "371759"
  },
  {
    "text": "was about 95% of columns if you say if",
    "start": "371759",
    "end": "374240"
  },
  {
    "text": "you have a 100 set of 100 set of Estates",
    "start": "374240",
    "end": "377880"
  },
  {
    "text": "95 was columns three was about tables",
    "start": "377880",
    "end": "380479"
  },
  {
    "text": "and rest of it was state by and schemas",
    "start": "380479",
    "end": "382400"
  },
  {
    "text": "right so if you see a pattern here if",
    "start": "382400",
    "end": "384560"
  },
  {
    "text": "you're using a single pod it's a it's a",
    "start": "384560",
    "end": "386360"
  },
  {
    "text": "good idea to just uh paralyze the reason",
    "start": "386360",
    "end": "388680"
  },
  {
    "text": "was transformation was reading from",
    "start": "388680",
    "end": "390360"
  },
  {
    "text": "recuit files transforming it and writing",
    "start": "390360",
    "end": "393080"
  },
  {
    "text": "to a writing to another file which is",
    "start": "393080",
    "end": "396080"
  },
  {
    "text": "more of iio bound we realized that if we",
    "start": "396080",
    "end": "398599"
  },
  {
    "text": "could just cut it down to cut down the",
    "start": "398599",
    "end": "401080"
  },
  {
    "text": "scaled assets which is 95% of columns we",
    "start": "401080",
    "end": "403520"
  },
  {
    "text": "paralyze it we chunk it and paralyze it",
    "start": "403520",
    "end": "406240"
  },
  {
    "text": "and rest of it is handled by default",
    "start": "406240",
    "end": "408080"
  },
  {
    "text": "which is an existing flow we could do",
    "start": "408080",
    "end": "409840"
  },
  {
    "text": "some uh some massive improvements here",
    "start": "409840",
    "end": "411960"
  },
  {
    "text": "right so we did two things here right we",
    "start": "411960",
    "end": "414000"
  },
  {
    "text": "chunked the column output records uh and",
    "start": "414000",
    "end": "418080"
  },
  {
    "text": "into reasonable size chunks in our case",
    "start": "418080",
    "end": "420440"
  },
  {
    "text": "we chose 10 million in your case you",
    "start": "420440",
    "end": "422160"
  },
  {
    "text": "could choose any reasonable number after",
    "start": "422160",
    "end": "423560"
  },
  {
    "text": "experiments right we did that and after",
    "start": "423560",
    "end": "426240"
  },
  {
    "text": "that we used we leverage Argo looping",
    "start": "426240",
    "end": "429039"
  },
  {
    "text": "capabilities if you have heard about",
    "start": "429039",
    "end": "430520"
  },
  {
    "text": "with items or with sequence which allows",
    "start": "430520",
    "end": "432840"
  },
  {
    "text": "you to Loop over and spawn pods for",
    "start": "432840",
    "end": "435560"
  },
  {
    "text": "processing uh for processing purposes",
    "start": "435560",
    "end": "437960"
  },
  {
    "text": "right that's looping and we also did one",
    "start": "437960",
    "end": "440080"
  },
  {
    "text": "more thing synchronization the reason we",
    "start": "440080",
    "end": "442240"
  },
  {
    "text": "use synchronization is because you can't",
    "start": "442240",
    "end": "443960"
  },
  {
    "text": "have the loop take over and just spawn",
    "start": "443960",
    "end": "446800"
  },
  {
    "text": "massive number of workloads right you",
    "start": "446800",
    "end": "448680"
  },
  {
    "text": "could have if if you choose a wrong size",
    "start": "448680",
    "end": "451319"
  },
  {
    "text": "chunk that could go up to hundreds and",
    "start": "451319",
    "end": "454240"
  },
  {
    "text": "more of like workloads that you open",
    "start": "454240",
    "end": "456360"
  },
  {
    "text": "right you consume lot of resources so we",
    "start": "456360",
    "end": "458639"
  },
  {
    "text": "use synchronization we start to 10 and",
    "start": "458639",
    "end": "461680"
  },
  {
    "text": "uh here's a snippet I'm sure it might",
    "start": "461680",
    "end": "463599"
  },
  {
    "text": "not be visible because it represents a",
    "start": "463599",
    "end": "465319"
  },
  {
    "text": "highly sophisticated workflow in a very",
    "start": "465319",
    "end": "466680"
  },
  {
    "text": "simple compressed way uh but if you see",
    "start": "466680",
    "end": "468879"
  },
  {
    "text": "we are passing on a chunk size and uh",
    "start": "468879",
    "end": "471319"
  },
  {
    "text": "what we do is uh we also uh make sure we",
    "start": "471319",
    "end": "474479"
  },
  {
    "text": "paralyze the uh column extraction step",
    "start": "474479",
    "end": "477560"
  },
  {
    "text": "uh so that it extracts in chunks and",
    "start": "477560",
    "end": "479840"
  },
  {
    "text": "keep gives us multiple files rather than",
    "start": "479840",
    "end": "481560"
  },
  {
    "text": "single file to a process later in the",
    "start": "481560",
    "end": "483360"
  },
  {
    "text": "transformation and then we do a with",
    "start": "483360",
    "end": "485479"
  },
  {
    "text": "sequence we know how many number of",
    "start": "485479",
    "end": "487280"
  },
  {
    "text": "files are there so we we'll do a with",
    "start": "487280",
    "end": "488919"
  },
  {
    "text": "sequence and we paralyze the column",
    "start": "488919",
    "end": "490879"
  },
  {
    "text": "transformation basically the impact as",
    "start": "490879",
    "end": "494520"
  },
  {
    "text": "you see before it would take us about uh",
    "start": "494520",
    "end": "497400"
  },
  {
    "text": "1 hour 38 minutes to for transforming 10",
    "start": "497400",
    "end": "499720"
  },
  {
    "text": "million records it would take us 22",
    "start": "499720",
    "end": "501639"
  },
  {
    "text": "hours for like 100 million records it it",
    "start": "501639",
    "end": "504000"
  },
  {
    "text": "just massively came down with this Pary",
    "start": "504000",
    "end": "505879"
  },
  {
    "text": "this is very simple Noble idea but we",
    "start": "505879",
    "end": "508639"
  },
  {
    "text": "implied it with data data workflows year",
    "start": "508639",
    "end": "511560"
  },
  {
    "text": "data ETL workflows year there's a small",
    "start": "511560",
    "end": "513680"
  },
  {
    "text": "Nuance to it the file size that we",
    "start": "513680",
    "end": "515399"
  },
  {
    "text": "choose and the how we mount it also",
    "start": "515399",
    "end": "518399"
  },
  {
    "text": "matters because you're going to incur",
    "start": "518399",
    "end": "520479"
  },
  {
    "text": "incur S3 or like the object store cost",
    "start": "520479",
    "end": "522479"
  },
  {
    "text": "where you're loading it from also the",
    "start": "522479",
    "end": "524159"
  },
  {
    "text": "size of the file will uh take up a lot",
    "start": "524159",
    "end": "525880"
  },
  {
    "text": "of the cost and the time to transfer",
    "start": "525880",
    "end": "527360"
  },
  {
    "text": "data transfer basically so that's about",
    "start": "527360",
    "end": "530360"
  },
  {
    "text": "that's about first run but there's",
    "start": "530360",
    "end": "532399"
  },
  {
    "text": "another chance that we come when you",
    "start": "532399",
    "end": "533959"
  },
  {
    "text": "solve the first run you have subsequent",
    "start": "533959",
    "end": "535600"
  },
  {
    "text": "run right ideally how would you do it is",
    "start": "535600",
    "end": "538480"
  },
  {
    "text": "like how would in the existing flow how",
    "start": "538480",
    "end": "541120"
  },
  {
    "text": "would it exist is basically you would",
    "start": "541120",
    "end": "543120"
  },
  {
    "text": "extract the whole estate again uh you",
    "start": "543120",
    "end": "546720"
  },
  {
    "text": "know that some of it exists already in",
    "start": "546720",
    "end": "548720"
  },
  {
    "text": "your catalog you want to compare you",
    "start": "548720",
    "end": "550240"
  },
  {
    "text": "want to do some diff on it and then just",
    "start": "550240",
    "end": "552600"
  },
  {
    "text": "update the catalog or the warehouse with",
    "start": "552600",
    "end": "554760"
  },
  {
    "text": "some new modified assets right that's",
    "start": "554760",
    "end": "557279"
  },
  {
    "text": "how it would work by default but we",
    "start": "557279",
    "end": "559200"
  },
  {
    "text": "noticed that there was a huge issue",
    "start": "559200",
    "end": "561240"
  },
  {
    "text": "there as well the extraction would take",
    "start": "561240",
    "end": "562600"
  },
  {
    "text": "about 4 hours for 4 million assets in",
    "start": "562600",
    "end": "564839"
  },
  {
    "text": "our case and it would go the processing",
    "start": "564839",
    "end": "567240"
  },
  {
    "text": "would go up to like 1 and a half hours",
    "start": "567240",
    "end": "568839"
  },
  {
    "text": "which is still a lot for us for",
    "start": "568839",
    "end": "570040"
  },
  {
    "text": "subsequent run we already taken much",
    "start": "570040",
    "end": "571839"
  },
  {
    "text": "efforts to run the first run right so",
    "start": "571839",
    "end": "575440"
  },
  {
    "text": "what we noticed was uh uh yeah exactly",
    "start": "575440",
    "end": "579120"
  },
  {
    "text": "we had to extract all the metadata we",
    "start": "579120",
    "end": "580800"
  },
  {
    "text": "had to do compare we had to calculate",
    "start": "580800",
    "end": "582480"
  },
  {
    "text": "diff and we also had to load the diff",
    "start": "582480",
    "end": "584880"
  },
  {
    "text": "metadata into the catalog to take a lot",
    "start": "584880",
    "end": "586800"
  },
  {
    "text": "of time a lot of runtime right so we",
    "start": "586800",
    "end": "589320"
  },
  {
    "text": "realize some of the sources actually",
    "start": "589320",
    "end": "591240"
  },
  {
    "text": "support or allow us to extract the",
    "start": "591240",
    "end": "593959"
  },
  {
    "text": "update mati using system cataloges they",
    "start": "593959",
    "end": "595839"
  },
  {
    "text": "have system catalogs and tables which",
    "start": "595839",
    "end": "598880"
  },
  {
    "text": "provide updated updated metadata or",
    "start": "598880",
    "end": "601440"
  },
  {
    "text": "updated time stamp where you could just",
    "start": "601440",
    "end": "603720"
  },
  {
    "text": "use that time and use a marker and just",
    "start": "603720",
    "end": "606959"
  },
  {
    "text": "extract the update met you don't have to",
    "start": "606959",
    "end": "608680"
  },
  {
    "text": "extract all of those things so that's",
    "start": "608680",
    "end": "610519"
  },
  {
    "text": "what we started doing here we just in",
    "start": "610519",
    "end": "613560"
  },
  {
    "text": "the first step we just extract the uh",
    "start": "613560",
    "end": "615720"
  },
  {
    "text": "the time stamp if it's not if if it",
    "start": "615720",
    "end": "617800"
  },
  {
    "text": "doesn't exist we just start from all",
    "start": "617800",
    "end": "619320"
  },
  {
    "text": "over again extract it do the same",
    "start": "619320",
    "end": "621800"
  },
  {
    "text": "processing lower it but at the final",
    "start": "621800",
    "end": "624040"
  },
  {
    "text": "step we just store the final time stamp",
    "start": "624040",
    "end": "626880"
  },
  {
    "text": "which is after it succeeded basically",
    "start": "626880",
    "end": "630000"
  },
  {
    "text": "uh so yeah that's that's what we call as",
    "start": "630000",
    "end": "631760"
  },
  {
    "text": "marker based incremental extraction what",
    "start": "631760",
    "end": "633320"
  },
  {
    "text": "we do is just fetch the time stamp uh",
    "start": "633320",
    "end": "635839"
  },
  {
    "text": "change the ddl uh to use the modified",
    "start": "635839",
    "end": "639079"
  },
  {
    "text": "for to to use the existing time stamp",
    "start": "639079",
    "end": "642120"
  },
  {
    "text": "process it o sorry what",
    "start": "642120",
    "end": "645560"
  },
  {
    "text": "happened uh yeah back we have a lot of",
    "start": "645560",
    "end": "649040"
  },
  {
    "text": "technical challenges today I guess I",
    "start": "649040",
    "end": "650240"
  },
  {
    "text": "don't know uh but this is a simplified",
    "start": "650240",
    "end": "652079"
  },
  {
    "text": "version of the uh uh the workflow that",
    "start": "652079",
    "end": "654279"
  },
  {
    "text": "we built is basically uh extraction we",
    "start": "654279",
    "end": "657040"
  },
  {
    "text": "just have the time stamp to extract it",
    "start": "657040",
    "end": "659079"
  },
  {
    "text": "and and we update the ddl that we sent",
    "start": "659079",
    "end": "660760"
  },
  {
    "text": "you to the source so that we just get",
    "start": "660760",
    "end": "662639"
  },
  {
    "text": "the update metadata and also we use the",
    "start": "662639",
    "end": "665720"
  },
  {
    "text": "uh just save the last time stamp so that",
    "start": "665720",
    "end": "668519"
  },
  {
    "text": "we use the marker to for the further",
    "start": "668519",
    "end": "669959"
  },
  {
    "text": "extraction this is how we solved the",
    "start": "669959",
    "end": "671480"
  },
  {
    "text": "subsequent run and it came down",
    "start": "671480",
    "end": "673120"
  },
  {
    "text": "massively again like this is again a",
    "start": "673120",
    "end": "674720"
  },
  {
    "text": "simple idea to be implemented and uh the",
    "start": "674720",
    "end": "677040"
  },
  {
    "text": "extraction time would just come down to",
    "start": "677040",
    "end": "678519"
  },
  {
    "text": "15 minutes and the processing would be",
    "start": "678519",
    "end": "679839"
  },
  {
    "text": "10 minutes we also had to not store any",
    "start": "679839",
    "end": "682240"
  },
  {
    "text": "metata again in our state to compare it",
    "start": "682240",
    "end": "684600"
  },
  {
    "text": "or calculate diff or anything uh also it",
    "start": "684600",
    "end": "687760"
  },
  {
    "text": "had used the uh Source being a single",
    "start": "687760",
    "end": "689800"
  },
  {
    "text": "point of uh Truth for us uh we didn't",
    "start": "689800",
    "end": "692240"
  },
  {
    "text": "have to maintain any state as as we said",
    "start": "692240",
    "end": "695079"
  },
  {
    "text": "uh the limitations only few sources",
    "start": "695079",
    "end": "697600"
  },
  {
    "text": "support this uh type of extraction",
    "start": "697600",
    "end": "699920"
  },
  {
    "text": "because not all of the sources have",
    "start": "699920",
    "end": "702200"
  },
  {
    "text": "system catalogs that have the update",
    "start": "702200",
    "end": "704040"
  },
  {
    "text": "metad time stamp that is one the second",
    "start": "704040",
    "end": "706480"
  },
  {
    "text": "is uh the sync which uh updates the",
    "start": "706480",
    "end": "709320"
  },
  {
    "text": "system catalogs in the source is also",
    "start": "709320",
    "end": "711040"
  },
  {
    "text": "delayed snowflake has it 3 hours datab",
    "start": "711040",
    "end": "713360"
  },
  {
    "text": "has it like couple of hours uh which",
    "start": "713360",
    "end": "714959"
  },
  {
    "text": "might be a limitation here in the",
    "start": "714959",
    "end": "716920"
  },
  {
    "text": "approach uh that's about the performance",
    "start": "716920",
    "end": "719440"
  },
  {
    "text": "pillar of our of a talk my colleague sat",
    "start": "719440",
    "end": "723519"
  },
  {
    "text": "will talk about the reliability pillar",
    "start": "723519",
    "end": "724839"
  },
  {
    "text": "how we Sol some of the resource",
    "start": "724839",
    "end": "726000"
  },
  {
    "text": "constraints that we are facing uh with",
    "start": "726000",
    "end": "728279"
  },
  {
    "text": "the runs",
    "start": "728279",
    "end": "730959"
  },
  {
    "text": "uh hi everyone uh myself satabata uh I'm",
    "start": "731040",
    "end": "734560"
  },
  {
    "text": "an engineer in atlan and I belong to the",
    "start": "734560",
    "end": "736399"
  },
  {
    "text": "atlan Marketplace team and some of the",
    "start": "736399",
    "end": "738560"
  },
  {
    "text": "connectors I've built here so today I'm",
    "start": "738560",
    "end": "741320"
  },
  {
    "text": "going to cover the reliability pillar",
    "start": "741320",
    "end": "742920"
  },
  {
    "text": "out here so when we talk about system",
    "start": "742920",
    "end": "744680"
  },
  {
    "text": "reliability the thing which comes in the",
    "start": "744680",
    "end": "746360"
  },
  {
    "text": "mind is that okay we should be able to",
    "start": "746360",
    "end": "748199"
  },
  {
    "text": "run our workflows in such a way that you",
    "start": "748199",
    "end": "749959"
  },
  {
    "text": "trigger them and forget about it",
    "start": "749959",
    "end": "752079"
  },
  {
    "text": "basically because and also uh it",
    "start": "752079",
    "end": "754760"
  },
  {
    "text": "symbolizes a kind of a trust in the",
    "start": "754760",
    "end": "756839"
  },
  {
    "text": "system that you do not incur failures",
    "start": "756839",
    "end": "759120"
  },
  {
    "text": "right based upon whatever the state of",
    "start": "759120",
    "end": "761279"
  },
  {
    "text": "your Source may be it may scale up in",
    "start": "761279",
    "end": "763680"
  },
  {
    "text": "volume of assets it may even you know",
    "start": "763680",
    "end": "765760"
  },
  {
    "text": "change its own state but the failur",
    "start": "765760",
    "end": "768079"
  },
  {
    "text": "should not occur in that sense so",
    "start": "768079",
    "end": "770399"
  },
  {
    "text": "keeping in context uh we have these two",
    "start": "770399",
    "end": "772519"
  },
  {
    "text": "sets where we dynamically kind of",
    "start": "772519",
    "end": "774440"
  },
  {
    "text": "allocated resources right uh in the in",
    "start": "774440",
    "end": "777320"
  },
  {
    "text": "the pods or mostly the overflow pods and",
    "start": "777320",
    "end": "780440"
  },
  {
    "text": "also we effectively paralyzed query",
    "start": "780440",
    "end": "783079"
  },
  {
    "text": "processing uh so when we talk about",
    "start": "783079",
    "end": "785639"
  },
  {
    "text": "query processing there comes you know",
    "start": "785639",
    "end": "787680"
  },
  {
    "text": "how we you know want to uh in you know",
    "start": "787680",
    "end": "790839"
  },
  {
    "text": "process a query to you know gain some",
    "start": "790839",
    "end": "792399"
  },
  {
    "text": "insights I I'll cover each one of them",
    "start": "792399",
    "end": "794120"
  },
  {
    "text": "in detail so yeah let's uh Jump Right In",
    "start": "794120",
    "end": "797399"
  },
  {
    "text": "so for the dynamic resource allocation",
    "start": "797399",
    "end": "799399"
  },
  {
    "text": "the challenge earlier was that we kind",
    "start": "799399",
    "end": "802040"
  },
  {
    "text": "of statically defined or predefined uh",
    "start": "802040",
    "end": "805360"
  },
  {
    "text": "kind of a you know memory and PVC claims",
    "start": "805360",
    "end": "807399"
  },
  {
    "text": "in that sense right so",
    "start": "807399",
    "end": "809920"
  },
  {
    "text": "let's say if your estate volume has",
    "start": "809920",
    "end": "811440"
  },
  {
    "text": "scaled right this particular challenge",
    "start": "811440",
    "end": "813399"
  },
  {
    "text": "was faced okay U my pod is unable to",
    "start": "813399",
    "end": "816800"
  },
  {
    "text": "handle the load for let's say you know",
    "start": "816800",
    "end": "819160"
  },
  {
    "text": "extraction of metadata or even it can go",
    "start": "819160",
    "end": "821360"
  },
  {
    "text": "down to processes transforms and then",
    "start": "821360",
    "end": "823440"
  },
  {
    "text": "the publish or the load part right so if",
    "start": "823440",
    "end": "826320"
  },
  {
    "text": "you see about the challenges of",
    "start": "826320",
    "end": "828120"
  },
  {
    "text": "tightrope management which we had here",
    "start": "828120",
    "end": "830800"
  },
  {
    "text": "overall is you know static resource",
    "start": "830800",
    "end": "832519"
  },
  {
    "text": "allocation as a mention other thing",
    "start": "832519",
    "end": "834600"
  },
  {
    "text": "which was a bit of a concern for us is",
    "start": "834600",
    "end": "836480"
  },
  {
    "text": "the cost saving measure because we you",
    "start": "836480",
    "end": "838320"
  },
  {
    "text": "know if we more kind of resources it",
    "start": "838320",
    "end": "841399"
  },
  {
    "text": "basically costed us much more right and",
    "start": "841399",
    "end": "844160"
  },
  {
    "text": "you use spot notes for spinning up pods",
    "start": "844160",
    "end": "846440"
  },
  {
    "text": "the reason being for us to save a kind",
    "start": "846440",
    "end": "848839"
  },
  {
    "text": "of a cost out here and uh the way we",
    "start": "848839",
    "end": "852240"
  },
  {
    "text": "kind of solved it is we kind of",
    "start": "852240",
    "end": "855160"
  },
  {
    "text": "pre-estimated the amount of resources",
    "start": "855160",
    "end": "857800"
  },
  {
    "text": "based on Source volume statistics what",
    "start": "857800",
    "end": "860160"
  },
  {
    "text": "do mean by that is that we uh kind of",
    "start": "860160",
    "end": "862759"
  },
  {
    "text": "send a query to the source we kind of",
    "start": "862759",
    "end": "864720"
  },
  {
    "text": "justify okay what are the counts",
    "start": "864720",
    "end": "866120"
  },
  {
    "text": "possible and then we kind of allocate",
    "start": "866120",
    "end": "868600"
  },
  {
    "text": "the X why if you see in the diagram",
    "start": "868600",
    "end": "870880"
  },
  {
    "text": "there uh the memory and PVC claims",
    "start": "870880",
    "end": "873360"
  },
  {
    "text": "accordingly right so yeah we quer the",
    "start": "873360",
    "end": "876040"
  },
  {
    "text": "source to an estimate count we kind of",
    "start": "876040",
    "end": "878120"
  },
  {
    "text": "optically you know optimal allocation",
    "start": "878120",
    "end": "880040"
  },
  {
    "text": "based on some gra graph or line equation",
    "start": "880040",
    "end": "882519"
  },
  {
    "text": "which we have and then we kind of",
    "start": "882519",
    "end": "883839"
  },
  {
    "text": "dynamically allocate this during P",
    "start": "883839",
    "end": "886399"
  },
  {
    "text": "scheduling right and here's a sample if",
    "start": "886399",
    "end": "889040"
  },
  {
    "text": "you take a look uh at the highlighted",
    "start": "889040",
    "end": "890959"
  },
  {
    "text": "part we kind of send a select query",
    "start": "890959",
    "end": "893240"
  },
  {
    "text": "which kind of gives us the count of",
    "start": "893240",
    "end": "895600"
  },
  {
    "text": "Estates and then we interally the code",
    "start": "895600",
    "end": "898800"
  },
  {
    "text": "uh which is their kind of you know",
    "start": "898800",
    "end": "900880"
  },
  {
    "text": "estimates it based on some equations and",
    "start": "900880",
    "end": "903480"
  },
  {
    "text": "then if you see we kind of use that uh",
    "start": "903480",
    "end": "906560"
  },
  {
    "text": "down here in the resources requests and",
    "start": "906560",
    "end": "909199"
  },
  {
    "text": "the storage part where we kind of okay",
    "start": "909199",
    "end": "911160"
  },
  {
    "text": "this is the amount of PVC estimated can",
    "start": "911160",
    "end": "913199"
  },
  {
    "text": "you allocate this at time of runtime",
    "start": "913199",
    "end": "916440"
  },
  {
    "text": "right uh so that's one second what we",
    "start": "916440",
    "end": "920079"
  },
  {
    "text": "also observed is that okay there is",
    "start": "920079",
    "end": "921920"
  },
  {
    "text": "something known as incremental retries",
    "start": "921920",
    "end": "924160"
  },
  {
    "text": "right so you can even add a retry uh in",
    "start": "924160",
    "end": "927160"
  },
  {
    "text": "case of Aro workflows out here and how",
    "start": "927160",
    "end": "929040"
  },
  {
    "text": "that would work here is that okay I know",
    "start": "929040",
    "end": "931240"
  },
  {
    "text": "that there is some predefined allocation",
    "start": "931240",
    "end": "933279"
  },
  {
    "text": "which you have mentioned earlier right",
    "start": "933279",
    "end": "935519"
  },
  {
    "text": "and your P fails but instead of feeling",
    "start": "935519",
    "end": "937959"
  },
  {
    "text": "the entire ETL workflow what we can do",
    "start": "937959",
    "end": "939959"
  },
  {
    "text": "is that okay can we do a retry and we",
    "start": "939959",
    "end": "942160"
  },
  {
    "text": "kind of optimize or maybe you know",
    "start": "942160",
    "end": "945199"
  },
  {
    "text": "vertically increase the resources based",
    "start": "945199",
    "end": "947240"
  },
  {
    "text": "on you know let's say in this case it's",
    "start": "947240",
    "end": "948880"
  },
  {
    "text": "2x right so such that the as I told",
    "start": "948880",
    "end": "952279"
  },
  {
    "text": "system reliability is something where",
    "start": "952279",
    "end": "954199"
  },
  {
    "text": "you gain trust right so you should not",
    "start": "954199",
    "end": "956040"
  },
  {
    "text": "want your entire ETL workflow pipeline",
    "start": "956040",
    "end": "958800"
  },
  {
    "text": "to fail off and you're unable to catalog",
    "start": "958800",
    "end": "960720"
  },
  {
    "text": "assets so this kind of helped us there",
    "start": "960720",
    "end": "963120"
  },
  {
    "text": "so we defined a retry strategy for the",
    "start": "963120",
    "end": "965040"
  },
  {
    "text": "Pod and we and based upon the you know",
    "start": "965040",
    "end": "967839"
  },
  {
    "text": "rry count which is defined at the time",
    "start": "967839",
    "end": "969880"
  },
  {
    "text": "of retry strategy we kind of",
    "start": "969880",
    "end": "971639"
  },
  {
    "text": "incrementally allocated the resources",
    "start": "971639",
    "end": "974040"
  },
  {
    "text": "right if you see the samples here you",
    "start": "974040",
    "end": "975839"
  },
  {
    "text": "should be able to see the retest",
    "start": "975839",
    "end": "977480"
  },
  {
    "text": "strategies we have defined the limit is",
    "start": "977480",
    "end": "979560"
  },
  {
    "text": "two uh you can you know Define the limit",
    "start": "979560",
    "end": "982480"
  },
  {
    "text": "as you want to and if you go down in the",
    "start": "982480",
    "end": "985000"
  },
  {
    "text": "container section where we have request",
    "start": "985000",
    "end": "986639"
  },
  {
    "text": "memory and the limits of memory we kind",
    "start": "986639",
    "end": "988720"
  },
  {
    "text": "of used that retry count over there to",
    "start": "988720",
    "end": "990880"
  },
  {
    "text": "kind of you know scale the resources uh",
    "start": "990880",
    "end": "994000"
  },
  {
    "text": "on the retry which we have so yeah the",
    "start": "994000",
    "end": "997319"
  },
  {
    "text": "impact as I mentioned this is a very",
    "start": "997319",
    "end": "999079"
  },
  {
    "text": "good impact we reduced pipeline failures",
    "start": "999079",
    "end": "1001399"
  },
  {
    "text": "mostly and increased system uh",
    "start": "1001399",
    "end": "1003560"
  },
  {
    "text": "resiliency in this overall aspect right",
    "start": "1003560",
    "end": "1007519"
  },
  {
    "text": "we have one more thing to cover that's",
    "start": "1007519",
    "end": "1009240"
  },
  {
    "text": "effectively paralyze query processing",
    "start": "1009240",
    "end": "1011279"
  },
  {
    "text": "and I think this going to be a bit",
    "start": "1011279",
    "end": "1013279"
  },
  {
    "text": "interesting out here uh so we kind of",
    "start": "1013279",
    "end": "1017240"
  },
  {
    "text": "process query for insight right so here",
    "start": "1017240",
    "end": "1019680"
  },
  {
    "text": "I would like to set up some context we",
    "start": "1019680",
    "end": "1021639"
  },
  {
    "text": "do some query history extraction right",
    "start": "1021639",
    "end": "1023639"
  },
  {
    "text": "so think about you have a SQL Source",
    "start": "1023639",
    "end": "1025480"
  },
  {
    "text": "there are lots of data Engineers",
    "start": "1025480",
    "end": "1027079"
  },
  {
    "text": "scientists running your SQL queries",
    "start": "1027079",
    "end": "1029079"
  },
  {
    "text": "right these queries are basically some",
    "start": "1029079",
    "end": "1032199"
  },
  {
    "text": "of the sources for example snowflake uh",
    "start": "1032199",
    "end": "1034558"
  },
  {
    "text": "stores this in a timestamp audit Trail",
    "start": "1034559",
    "end": "1037880"
  },
  {
    "text": "fashion right so it's I think like I",
    "start": "1037880",
    "end": "1041000"
  },
  {
    "text": "mean I look at query history to be a",
    "start": "1041000",
    "end": "1043720"
  },
  {
    "text": "timestamp based audit Trail right of",
    "start": "1043720",
    "end": "1046240"
  },
  {
    "text": "your SQL queries and this can be a gold",
    "start": "1046240",
    "end": "1048280"
  },
  {
    "text": "mine of patterns right for example if",
    "start": "1048280",
    "end": "1050440"
  },
  {
    "text": "you talk about user engagement in like",
    "start": "1050440",
    "end": "1052440"
  },
  {
    "text": "patterns okay uh which kind of you know",
    "start": "1052440",
    "end": "1055160"
  },
  {
    "text": "data teams is using my queries here",
    "start": "1055160",
    "end": "1057280"
  },
  {
    "text": "right performance analysis okay what is",
    "start": "1057280",
    "end": "1059200"
  },
  {
    "text": "the most resource intensive query or",
    "start": "1059200",
    "end": "1061919"
  },
  {
    "text": "where can I optimize that right usage",
    "start": "1061919",
    "end": "1063919"
  },
  {
    "text": "intelligence okay uh maybe there are",
    "start": "1063919",
    "end": "1066280"
  },
  {
    "text": "some queries",
    "start": "1066280",
    "end": "1069480"
  },
  {
    "text": "sorry oh okay maybe there are some",
    "start": "1069480",
    "end": "1072080"
  },
  {
    "text": "queries uh which U is not being used",
    "start": "1072080",
    "end": "1075080"
  },
  {
    "text": "right maybe there are very less amount",
    "start": "1075080",
    "end": "1076720"
  },
  {
    "text": "of usage can I use that for archival",
    "start": "1076720",
    "end": "1079760"
  },
  {
    "text": "right I may not need it in my source so",
    "start": "1079760",
    "end": "1081880"
  },
  {
    "text": "all of these behavioral patterns kinds",
    "start": "1081880",
    "end": "1083320"
  },
  {
    "text": "of comes out when you try to query",
    "start": "1083320",
    "end": "1085039"
  },
  {
    "text": "process for insights in our initial",
    "start": "1085039",
    "end": "1087799"
  },
  {
    "text": "scale we actually had the estate volume",
    "start": "1087799",
    "end": "1090919"
  },
  {
    "text": "of assets to be 1 to 4 million right and",
    "start": "1090919",
    "end": "1094240"
  },
  {
    "text": "the query history volume here was kind",
    "start": "1094240",
    "end": "1096640"
  },
  {
    "text": "of 600k right which means the number of",
    "start": "1096640",
    "end": "1098840"
  },
  {
    "text": "queries at the source and there's also a",
    "start": "1098840",
    "end": "1101799"
  },
  {
    "text": "part known as window analysis so okay if",
    "start": "1101799",
    "end": "1104280"
  },
  {
    "text": "I want to understand my engagement",
    "start": "1104280",
    "end": "1106200"
  },
  {
    "text": "patterns based on some window okay let's",
    "start": "1106200",
    "end": "1108240"
  },
  {
    "text": "say the last 30 days right even that",
    "start": "1108240",
    "end": "1110320"
  },
  {
    "text": "kind of played a role because the more",
    "start": "1110320",
    "end": "1112240"
  },
  {
    "text": "number of days or the way you adjust the",
    "start": "1112240",
    "end": "1114320"
  },
  {
    "text": "window May differ in the amount of query",
    "start": "1114320",
    "end": "1116919"
  },
  {
    "text": "history of the queries which you are",
    "start": "1116919",
    "end": "1118280"
  },
  {
    "text": "processing right and we chose Delta leak",
    "start": "1118280",
    "end": "1121720"
  },
  {
    "text": "and spice park at that point of time uh",
    "start": "1121720",
    "end": "1124320"
  },
  {
    "text": "there were lots of reasons for us uh it",
    "start": "1124320",
    "end": "1126520"
  },
  {
    "text": "was a kind of fit for us Delta Lake was",
    "start": "1126520",
    "end": "1128640"
  },
  {
    "text": "helpful in versioning it helped us to",
    "start": "1128640",
    "end": "1131679"
  },
  {
    "text": "maintain roll backs right and also spark",
    "start": "1131679",
    "end": "1134280"
  },
  {
    "text": "was the only available writer at that",
    "start": "1134280",
    "end": "1135720"
  },
  {
    "text": "point of time for Delta Lake right so uh",
    "start": "1135720",
    "end": "1138240"
  },
  {
    "text": "this I'm talking about P spark it's an",
    "start": "1138240",
    "end": "1139960"
  },
  {
    "text": "inmemory based implementation of spark",
    "start": "1139960",
    "end": "1142440"
  },
  {
    "text": "right so the challenges here where we",
    "start": "1142440",
    "end": "1145520"
  },
  {
    "text": "faced is when it kind of went from the",
    "start": "1145520",
    "end": "1149200"
  },
  {
    "text": "growing scale of Estates right so it",
    "start": "1149200",
    "end": "1151080"
  },
  {
    "text": "when the estate went up to 10 million",
    "start": "1151080",
    "end": "1153600"
  },
  {
    "text": "almost and the query history which You",
    "start": "1153600",
    "end": "1155320"
  },
  {
    "text": "observe from some of the customers which",
    "start": "1155320",
    "end": "1157280"
  },
  {
    "text": "we have went about 12 million so it's",
    "start": "1157280",
    "end": "1159840"
  },
  {
    "text": "like 12 million query processing how can",
    "start": "1159840",
    "end": "1161480"
  },
  {
    "text": "you do it effectively spark deployment",
    "start": "1161480",
    "end": "1163799"
  },
  {
    "text": "was a concern for us because it was only",
    "start": "1163799",
    "end": "1165799"
  },
  {
    "text": "a master only spark deployment which",
    "start": "1165799",
    "end": "1167960"
  },
  {
    "text": "means it's a single class cluster spark",
    "start": "1167960",
    "end": "1169240"
  },
  {
    "text": "deployment the reason for that is",
    "start": "1169240",
    "end": "1171640"
  },
  {
    "text": "related to costs because each of our",
    "start": "1171640",
    "end": "1174200"
  },
  {
    "text": "customers do have one cluster dedicated",
    "start": "1174200",
    "end": "1177080"
  },
  {
    "text": "to each one of them right so in that",
    "start": "1177080",
    "end": "1179240"
  },
  {
    "text": "particular sense if we trying to spin up",
    "start": "1179240",
    "end": "1181039"
  },
  {
    "text": "multicluster spark deployment it would",
    "start": "1181039",
    "end": "1183400"
  },
  {
    "text": "again cost us much more so this kind of",
    "start": "1183400",
    "end": "1186960"
  },
  {
    "text": "uh played",
    "start": "1186960",
    "end": "1188679"
  },
  {
    "text": "together sorry man I think okay so these",
    "start": "1188679",
    "end": "1192840"
  },
  {
    "text": "are the challenges which we faced in",
    "start": "1192840",
    "end": "1194520"
  },
  {
    "text": "this scenario and the way we leveraged",
    "start": "1194520",
    "end": "1197679"
  },
  {
    "text": "here is something as dug DB um May I",
    "start": "1197679",
    "end": "1202000"
  },
  {
    "text": "know how how many of you are familiar",
    "start": "1202000",
    "end": "1203360"
  },
  {
    "text": "with Doug DB and kind of use it okay so",
    "start": "1203360",
    "end": "1207480"
  },
  {
    "text": "we kind of chunked the passing of the",
    "start": "1207480",
    "end": "1211000"
  },
  {
    "text": "queries right that's where we chunked",
    "start": "1211000",
    "end": "1212919"
  },
  {
    "text": "the F the first chunk right and each one",
    "start": "1212919",
    "end": "1215679"
  },
  {
    "text": "of those passing when when I mean by",
    "start": "1215679",
    "end": "1217440"
  },
  {
    "text": "passing is that okay let's get some Json",
    "start": "1217440",
    "end": "1219440"
  },
  {
    "text": "metadata out of it right some kind of",
    "start": "1219440",
    "end": "1220919"
  },
  {
    "text": "relevant metadata then we pass it on to",
    "start": "1220919",
    "end": "1223120"
  },
  {
    "text": "duck DB for processing right here and",
    "start": "1223120",
    "end": "1225679"
  },
  {
    "text": "Argo acted as a orchestrator in this",
    "start": "1225679",
    "end": "1227840"
  },
  {
    "text": "sense right so duck B was the",
    "start": "1227840",
    "end": "1229640"
  },
  {
    "text": "implementation for us to process the",
    "start": "1229640",
    "end": "1232120"
  },
  {
    "text": "queries for insight and uh you know Aro",
    "start": "1232120",
    "end": "1235640"
  },
  {
    "text": "kind of ared us with the parallel",
    "start": "1235640",
    "end": "1237240"
  },
  {
    "text": "execution maintaining synchronization",
    "start": "1237240",
    "end": "1239720"
  },
  {
    "text": "over here right and at the end we",
    "start": "1239720",
    "end": "1241559"
  },
  {
    "text": "basically aggregate so think about if",
    "start": "1241559",
    "end": "1243600"
  },
  {
    "text": "you have you know let's say n number of",
    "start": "1243600",
    "end": "1245280"
  },
  {
    "text": "days to calculate it can all run parall",
    "start": "1245280",
    "end": "1247840"
  },
  {
    "text": "and then you would just need one part",
    "start": "1247840",
    "end": "1249640"
  },
  {
    "text": "for aggregation instead of One Singular",
    "start": "1249640",
    "end": "1252000"
  },
  {
    "text": "part which was there earlier right which",
    "start": "1252000",
    "end": "1254159"
  },
  {
    "text": "would which did all of this processing",
    "start": "1254159",
    "end": "1256159"
  },
  {
    "text": "across 30 days right so that's where",
    "start": "1256159",
    "end": "1258720"
  },
  {
    "text": "Argo workl came in as I mentioned it was",
    "start": "1258720",
    "end": "1262200"
  },
  {
    "text": "kind of fast compared to P spark because",
    "start": "1262200",
    "end": "1264440"
  },
  {
    "text": "there was you know initialization was",
    "start": "1264440",
    "end": "1266600"
  },
  {
    "text": "pretty much okay you use the python SDK",
    "start": "1266600",
    "end": "1268720"
  },
  {
    "text": "for duck DB and it kind of handled 3.3",
    "start": "1268720",
    "end": "1271559"
  },
  {
    "text": "GB pocket files per Port right so duck",
    "start": "1271559",
    "end": "1273760"
  },
  {
    "text": "DB kind of made sure your Json has been",
    "start": "1273760",
    "end": "1277919"
  },
  {
    "text": "uh implemented in a paret fashion the",
    "start": "1277919",
    "end": "1280120"
  },
  {
    "text": "beautiful part about this is that you",
    "start": "1280120",
    "end": "1281919"
  },
  {
    "text": "can run sequels over pocket files right",
    "start": "1281919",
    "end": "1284080"
  },
  {
    "text": "so it's if you have a SQL background you",
    "start": "1284080",
    "end": "1287080"
  },
  {
    "text": "can let's say okay I can do a SQL query",
    "start": "1287080",
    "end": "1289360"
  },
  {
    "text": "to calculate the rank which essentially",
    "start": "1289360",
    "end": "1291600"
  },
  {
    "text": "means let's say okay let me get the top",
    "start": "1291600",
    "end": "1293080"
  },
  {
    "text": "five users of a particular query right",
    "start": "1293080",
    "end": "1295120"
  },
  {
    "text": "so that's where we leverage a Dean as I",
    "start": "1295120",
    "end": "1296919"
  },
  {
    "text": "mentioned ago came as an orchestrator we",
    "start": "1296919",
    "end": "1299320"
  },
  {
    "text": "use Chun based Loops right to prevent",
    "start": "1299320",
    "end": "1301720"
  },
  {
    "text": "and we also prevented memory overload as",
    "start": "1301720",
    "end": "1303679"
  },
  {
    "text": "I mentioned what was there with ppar",
    "start": "1303679",
    "end": "1305520"
  },
  {
    "text": "sema4 control synchronization and",
    "start": "1305520",
    "end": "1307240"
  },
  {
    "text": "cluster overload",
    "start": "1307240",
    "end": "1309760"
  },
  {
    "text": "uh",
    "start": "1309760",
    "end": "1311960"
  },
  {
    "text": "sorry",
    "start": "1311960",
    "end": "1314960"
  },
  {
    "text": "folks Okay so yeah the cluster overload",
    "start": "1316520",
    "end": "1320039"
  },
  {
    "text": "because think about if you scheduling",
    "start": "1320039",
    "end": "1322520"
  },
  {
    "text": "pause on of a cluster right so semaphor",
    "start": "1322520",
    "end": "1325000"
  },
  {
    "text": "of ago kind of helped us okay we do not",
    "start": "1325000",
    "end": "1327440"
  },
  {
    "text": "want to flood the cluster with number of",
    "start": "1327440",
    "end": "1329159"
  },
  {
    "text": "multiple pods can we do in a more",
    "start": "1329159",
    "end": "1331200"
  },
  {
    "text": "synchronized manner such that you know",
    "start": "1331200",
    "end": "1333039"
  },
  {
    "text": "all kinds of pods are scheduled properly",
    "start": "1333039",
    "end": "1335960"
  },
  {
    "text": "so the impact it was pretty much",
    "start": "1335960",
    "end": "1338200"
  },
  {
    "text": "impressive if you see the experimental",
    "start": "1338200",
    "end": "1340320"
  },
  {
    "text": "observability that's the single node uh",
    "start": "1340320",
    "end": "1342720"
  },
  {
    "text": "e cluster uh which we used and it was",
    "start": "1342720",
    "end": "1345919"
  },
  {
    "text": "kind of 2.3 times faster than ppar from",
    "start": "1345919",
    "end": "1348360"
  },
  {
    "text": "a production observability perspective",
    "start": "1348360",
    "end": "1350600"
  },
  {
    "text": "the pipeline success rate kind of",
    "start": "1350600",
    "end": "1352159"
  },
  {
    "text": "increased from the failure from 78 to",
    "start": "1352159",
    "end": "1356240"
  },
  {
    "text": "96.5 we had one of our customers who",
    "start": "1356240",
    "end": "1358919"
  },
  {
    "text": "where we observed this 2 million assets",
    "start": "1358919",
    "end": "1361240"
  },
  {
    "text": "runtime cut the runtime with the",
    "start": "1361240",
    "end": "1364720"
  },
  {
    "text": "processing that we did with dug DB from",
    "start": "1364720",
    "end": "1366799"
  },
  {
    "text": "71 minutes it came down to 8.67 minutes",
    "start": "1366799",
    "end": "1369679"
  },
  {
    "text": "and the pipeline failures right so out",
    "start": "1369679",
    "end": "1371440"
  },
  {
    "text": "of every let's say 150 daily runs of",
    "start": "1371440",
    "end": "1374240"
  },
  {
    "text": "workf flows across customers it was only",
    "start": "1374240",
    "end": "1376559"
  },
  {
    "text": "reduced to mostly about four uh you know",
    "start": "1376559",
    "end": "1378880"
  },
  {
    "text": "failures per day and so the you can see",
    "start": "1378880",
    "end": "1381039"
  },
  {
    "text": "the drip down of the count of you know",
    "start": "1381039",
    "end": "1383400"
  },
  {
    "text": "the percentage that we you know drived",
    "start": "1383400",
    "end": "1385080"
  },
  {
    "text": "here so this is mostly how we establish",
    "start": "1385080",
    "end": "1388960"
  },
  {
    "text": "trust about how we can handle uh ago",
    "start": "1388960",
    "end": "1392559"
  },
  {
    "text": "workflows and use very you know simple",
    "start": "1392559",
    "end": "1395799"
  },
  {
    "text": "and uh techniques of ago which is there",
    "start": "1395799",
    "end": "1399360"
  },
  {
    "text": "right to increase the system resiliency",
    "start": "1399360",
    "end": "1401600"
  },
  {
    "text": "and Trust for us so yeah uh so that's",
    "start": "1401600",
    "end": "1405600"
  },
  {
    "text": "all for today I know we Face some",
    "start": "1405600",
    "end": "1406960"
  },
  {
    "text": "technical difficulties here but uh happy",
    "start": "1406960",
    "end": "1408720"
  },
  {
    "text": "to take any questions right now uh if",
    "start": "1408720",
    "end": "1410440"
  },
  {
    "text": "anybody would have uh or happy to",
    "start": "1410440",
    "end": "1413400"
  },
  {
    "text": "connect later in case there's anything",
    "start": "1413400",
    "end": "1415720"
  },
  {
    "text": "yeah thank you saata and Nish let's give",
    "start": "1415720",
    "end": "1418520"
  },
  {
    "text": "it up thank you",
    "start": "1418520",
    "end": "1423159"
  },
  {
    "text": "much I think we'll have time for one",
    "start": "1423440",
    "end": "1425880"
  },
  {
    "text": "question if yeah just one thing you can",
    "start": "1425880",
    "end": "1427880"
  },
  {
    "text": "just uh scan this feed uh QR if you want",
    "start": "1427880",
    "end": "1429919"
  },
  {
    "text": "to give some feedback or let's say you",
    "start": "1429919",
    "end": "1431200"
  },
  {
    "text": "have any questions you can just leave it",
    "start": "1431200",
    "end": "1432480"
  },
  {
    "text": "out there we'll be down here in the",
    "start": "1432480",
    "end": "1434600"
  },
  {
    "text": "corner if you want to connect we are",
    "start": "1434600",
    "end": "1436600"
  },
  {
    "text": "good to connect here so yeah thank you",
    "start": "1436600",
    "end": "1438200"
  },
  {
    "text": "so much much appreciate the time was",
    "start": "1438200",
    "end": "1439720"
  },
  {
    "text": "there any questions any questions one",
    "start": "1439720",
    "end": "1442880"
  },
  {
    "text": "question all right thanks okay thank you",
    "start": "1442880",
    "end": "1448200"
  }
]
[
  {
    "text": "uh this is all your gpus are belong to us I'm Ryan hesy and this is p",
    "start": "280",
    "end": "8360"
  },
  {
    "text": "procop we work at Nvidia and we're going to be talking",
    "start": "8360",
    "end": "13719"
  },
  {
    "text": "about how we maintain GeForce now the GeForce now",
    "start": "13719",
    "end": "19480"
  },
  {
    "text": "infrastructure okay so if you don't know about uh GeForce now if you're not familiar with it um little intro to it",
    "start": "19480",
    "end": "25920"
  },
  {
    "text": "um but we do uh at Nvidia with gForce now we have a a service where we offer",
    "start": "25920",
    "end": "31960"
  },
  {
    "text": "you to play games in the cloud and we can stream it to your device and so what",
    "start": "31960",
    "end": "37360"
  },
  {
    "text": "what uh how does this look with infrastructure so we take gpus we put them in our data centers and you as an",
    "start": "37360",
    "end": "44920"
  },
  {
    "text": "end user can open up your device you can go to the GeForce now client and open up",
    "start": "44920",
    "end": "50120"
  },
  {
    "text": "your steam Library start playing your game and the graphics for that game will",
    "start": "50120",
    "end": "55520"
  },
  {
    "text": "be will be rendered on a GPU in the cloud and",
    "start": "55520",
    "end": "60800"
  },
  {
    "text": "those Graphics get streamed back over the network to your device so that's a little bit how it works um these these",
    "start": "60800",
    "end": "68280"
  },
  {
    "text": "data centers these these clusters we um our Fleet is is a bunch of it's all it's all kubernetes or mostly kubernetes the",
    "start": "68280",
    "end": "75000"
  },
  {
    "text": "one we're going to be talking about is uh we have about 40 plus kubernetes clusters that we run which about 30,000",
    "start": "75000",
    "end": "80439"
  },
  {
    "text": "plus nodes might even be more than that now um and we run a lot of these",
    "start": "80439",
    "end": "86360"
  },
  {
    "text": "workloads uh in VMS so we use CT a lot lot uh these These workloads are uh",
    "start": "86360",
    "end": "94040"
  },
  {
    "text": "Windows guests and we um so makes so we run Windows guest we attach gpus to them",
    "start": "94040",
    "end": "101520"
  },
  {
    "text": "and you know we we render graphics and and stream them to and users and we're about 60,000 plus gpus across our data",
    "start": "101520",
    "end": "107719"
  },
  {
    "text": "centers uh geolocated all over the world okay um so what's our philosophy",
    "start": "107719",
    "end": "115680"
  },
  {
    "text": "when when I say maintaining the fleet like doing maintenance what's our philosophy um at Nvidia so I'm going to give you an",
    "start": "115680",
    "end": "123399"
  },
  {
    "text": "analogy if if you need two requirements if you wanted to build a race car first",
    "start": "123399",
    "end": "129679"
  },
  {
    "text": "requirement is you really want to build a fast car right the second requirement",
    "start": "129679",
    "end": "135319"
  },
  {
    "text": "is you need to be able to do and repair your car on the racetrack",
    "start": "135319",
    "end": "141440"
  },
  {
    "text": "the second requirement is equally as important as the first and so with kubernetes in",
    "start": "141440",
    "end": "149080"
  },
  {
    "text": "production it's really important that we keep that in mind that we run a really good service we run a service that's",
    "start": "149080",
    "end": "155319"
  },
  {
    "text": "always available for us and one that we can repair while it's run while it's in",
    "start": "155319",
    "end": "161360"
  },
  {
    "text": "production okay so what does that mean like maintaining the fleet like what are all the steps the things that we do when",
    "start": "163159",
    "end": "169440"
  },
  {
    "text": "we want to maintain this infrastructure well we do a ton of things um we always want to make sure our gpus are up to",
    "start": "169440",
    "end": "175080"
  },
  {
    "text": "date right there's new gpus that are coming out all the time and we have we want to get them in our data centers we",
    "start": "175080",
    "end": "180879"
  },
  {
    "text": "want to make them the best hardware available for our users and so we're constantly taking gpus and we're we're",
    "start": "180879",
    "end": "188080"
  },
  {
    "text": "we're making them available in different ways and and so we want to get these these gpus and make them uh get them",
    "start": "188080",
    "end": "193239"
  },
  {
    "text": "into our infrastructure uh we're doing kubernetes upgrade right there's lots of reasons to do kuet upgrade right we CVS is is",
    "start": "193239",
    "end": "201120"
  },
  {
    "text": "obviously one that's really important but I mean features right we participate in the community we build you know we we",
    "start": "201120",
    "end": "206959"
  },
  {
    "text": "build uh on top of kubernetes and we we can contribute to it and there's so many features coming out that are so",
    "start": "206959",
    "end": "212920"
  },
  {
    "text": "important even nowadays we talk about Dr so important with how we allocate devices and really influential with how",
    "start": "212920",
    "end": "220439"
  },
  {
    "text": "we want to use kubernetes and then also uh really important new features like um list",
    "start": "220439",
    "end": "226720"
  },
  {
    "text": "streams um consistent cach reads all this stuff like so important for scalability that we really care about",
    "start": "226720",
    "end": "234000"
  },
  {
    "text": "and and so we need to get these new versions of kubernetes we need to get them into our data centers we need to",
    "start": "234000",
    "end": "239840"
  },
  {
    "text": "get them as soon as we can so what else we do driver upgrades um such a critical",
    "start": "239840",
    "end": "245159"
  },
  {
    "text": "thing like anyone who's got gpus here you're probably upgrading your drivers and a regular Cadence we do as well we",
    "start": "245159",
    "end": "251400"
  },
  {
    "text": "pay close attention to that we want to make sure we put a lot of effort into make sure we have the latest drivers in our data centers um we run on bare metal",
    "start": "251400",
    "end": "258880"
  },
  {
    "text": "so we're running VMS on bare metal so we do o upgrade right we do every which",
    "start": "258880",
    "end": "264759"
  },
  {
    "text": "includes so many things I mean the package management to everything from the host config um all of those steps",
    "start": "264759",
    "end": "270800"
  },
  {
    "text": "all kind of rolled up together um and takes a lot of work um if you bios upgrade right a lot of things a lot of",
    "start": "270800",
    "end": "277240"
  },
  {
    "text": "things that people do right we do we do that as well and then remediation right so important um you know we keep our our",
    "start": "277240",
    "end": "283800"
  },
  {
    "text": "clusters healthy and the list kind of goes on and actually there's probably many more but can't talk too long about",
    "start": "283800",
    "end": "290759"
  },
  {
    "text": "it okay so we have this problem right we we want to maintain our Fleet um so we put our",
    "start": "290759",
    "end": "297320"
  },
  {
    "text": "heads together and we thought to ourselves well how do we do this how how can we how can we do this uh with our",
    "start": "297320",
    "end": "305080"
  },
  {
    "text": "existing requirements um well so I wrote down a few goals like when we",
    "start": "305080",
    "end": "310320"
  },
  {
    "text": "were thinking about this solution uh first is you know we want um we want to",
    "start": "310320",
    "end": "315440"
  },
  {
    "text": "uh want to upgrade our infrastructure without impacting users right it almost goes without being said but it really does need to be emphasized like we don't",
    "start": "315440",
    "end": "321960"
  },
  {
    "text": "want to impact our users like someone's playing a game it's not cool that we you know we interfere with that so we we we",
    "start": "321960",
    "end": "328400"
  },
  {
    "text": "really emphasize that um we want a scalable solution right we have so many data centers so many nodes",
    "start": "328400",
    "end": "333440"
  },
  {
    "text": "so many gpus it's really important that um we're achieving the right amount of scale we're doing",
    "start": "333440",
    "end": "339680"
  },
  {
    "text": "maintenance uh and then we want to support any current and future infrastructure upgrades right this is like a casting a really wide net because",
    "start": "339680",
    "end": "346560"
  },
  {
    "text": "we have no idea of all the different infrastructure upgrades and stuff that we want to do in the future but the",
    "start": "346560",
    "end": "352680"
  },
  {
    "text": "point is like we want to be agnostic we want to be ready for anything that we might want to do uh and lastly we really",
    "start": "352680",
    "end": "358680"
  },
  {
    "text": "want to enable automation it's so critical at our scale and and all our operations that we have to do we really",
    "start": "358680",
    "end": "364600"
  },
  {
    "text": "want to scale by automating more uh and so when looking at trying to solve this problem um we also have a few",
    "start": "364600",
    "end": "371800"
  },
  {
    "text": "non goals and I think um these are also really important we we don't want to",
    "start": "371800",
    "end": "377560"
  },
  {
    "text": "reimplement or replace CU CTL drain um I think it's like does a good job for what",
    "start": "377560",
    "end": "383880"
  },
  {
    "text": "it what it does and people like it right and and the second one is that um we don't want to create an Nvidia only",
    "start": "383880",
    "end": "390479"
  },
  {
    "text": "solution and so kind of the way I would summarize those two non goals is like we want to use what the community does and",
    "start": "390479",
    "end": "397400"
  },
  {
    "text": "does well and we want to leverage that and so if you're using a solution in the community the whole point is like you",
    "start": "397400",
    "end": "403680"
  },
  {
    "text": "would be able to keep using it too because that's how we'd feel like we like you know C cail drain we want to",
    "start": "403680",
    "end": "409919"
  },
  {
    "text": "keep using it too so the whole idea is we can leverage those things and whatever solution we come up with would",
    "start": "409919",
    "end": "415560"
  },
  {
    "text": "be a anyone would be able to leverage that too",
    "start": "415560",
    "end": "419918"
  },
  {
    "text": "okay so we we kind of put our heads together we we took our requirements and",
    "start": "421120",
    "end": "427120"
  },
  {
    "text": "um we figured is that we needed some sort of U maintenance API we figured that um that the missing",
    "start": "427120",
    "end": "436639"
  },
  {
    "text": "piece was that we needed a way to track maintenance and and essentially this",
    "start": "436639",
    "end": "442440"
  },
  {
    "text": "maintenance API would be we need a bunch of states and those States would describe a",
    "start": "442440",
    "end": "448879"
  },
  {
    "text": "maintenance right and and so we could put that behind an API right a crd in kuat we can",
    "start": "448879",
    "end": "454960"
  },
  {
    "text": "extend the API and um our thesis is that if we can accurately Define all of the",
    "start": "454960",
    "end": "460800"
  },
  {
    "text": "different states that a maintenance would go through um then we should be able to create a bunch of powerful",
    "start": "460800",
    "end": "466759"
  },
  {
    "text": "tooling around it so we needed to test this thesis so these were the requirements that came up these are the",
    "start": "466759",
    "end": "472960"
  },
  {
    "text": "different states that we that came to mind that we believe that every maintenance will go through in in some",
    "start": "472960",
    "end": "479000"
  },
  {
    "text": "form okay so the first one scheduling a drain right we're all familiar with this this",
    "start": "479000",
    "end": "484400"
  },
  {
    "text": "is like me saying okay I'm going to a node and like okay it's time to evacuate",
    "start": "484400",
    "end": "489560"
  },
  {
    "text": "like you know please leave the node right we do this in lots of different ways um uh but you know we that's always",
    "start": "489560",
    "end": "495720"
  },
  {
    "text": "our first step when we want to get to that node and do maintenance on it the second step start the drain and this is",
    "start": "495720",
    "end": "502120"
  },
  {
    "text": "this can mean a lot of things like I said goop gopy Shel drain is like that sounds good A lot of people use it but",
    "start": "502120",
    "end": "508599"
  },
  {
    "text": "if you use it a lot I'm sure there's some people who out there who know the corner cases of it especially if you",
    "start": "508599",
    "end": "514839"
  },
  {
    "text": "have one replica and you have uh and you can't scale down and you you'll get",
    "start": "514839",
    "end": "520240"
  },
  {
    "text": "blocked when you try to do qctl drain right there's like all these Concepts that um come in that Define a drain and",
    "start": "520240",
    "end": "527839"
  },
  {
    "text": "um so you might need a different solution and you know so however you define drain the whole point is is that",
    "start": "527839",
    "end": "533640"
  },
  {
    "text": "what we want to do with this this state requirement is that you need to actually execute on on the The Strain you start",
    "start": "533640",
    "end": "540079"
  },
  {
    "text": "it and and you actually go and complete the strain so essentially what that means is you can you can Define",
    "start": "540079",
    "end": "545720"
  },
  {
    "text": "essentially all the different tools and methods as you can do to get there but you do need to get there to a point where the node is drained right we can't",
    "start": "545720",
    "end": "552839"
  },
  {
    "text": "really do maintenance on something that has um active workloads that defeats our our",
    "start": "552839",
    "end": "558839"
  },
  {
    "text": "purpose okay so the fourth requirement um is actually starting the mainten right this is where the you know the fun",
    "start": "558839",
    "end": "565680"
  },
  {
    "text": "starts so we get to a point now where we can actually take this node or take this",
    "start": "565680",
    "end": "572320"
  },
  {
    "text": "you know this Hardware whatever is we want to do um and and upgrade it or or mediate it or fix it Whatever It Is",
    "start": "572320",
    "end": "578800"
  },
  {
    "text": "without actually worrying about impacting and users um and so you know this state you",
    "start": "578800",
    "end": "584040"
  },
  {
    "text": "can imagine is very much up to the end User it's going to be like there's so many different maintenances and",
    "start": "584040",
    "end": "589720"
  },
  {
    "text": "different techniques you can use um in our clusters we use Cube spray like if we want to upgrade",
    "start": "589720",
    "end": "595240"
  },
  {
    "text": "kubernetes but I mean everyone uses different tools for upgrading and then",
    "start": "595240",
    "end": "600399"
  },
  {
    "text": "we also have very unique sets of hardware and topologies and and upgrades and maintenances that we do so again",
    "start": "600399",
    "end": "607040"
  },
  {
    "text": "it's like very much up to the end user to Define exactly what that means but you're always going to have to do that",
    "start": "607040",
    "end": "612480"
  },
  {
    "text": "step and then next we have to complete a maintenance or um have a fork in the",
    "start": "612480",
    "end": "617720"
  },
  {
    "text": "road here and fail a maintenance right we need to exit ramps when in these situations where um things don't quite",
    "start": "617720",
    "end": "624279"
  },
  {
    "text": "go the way we expect um uh and then you know next we do validating the",
    "start": "624279",
    "end": "629440"
  },
  {
    "text": "maintenance this kind of thing like think of you know we run tests we want to make sure that um some assumptions",
    "start": "629440",
    "end": "635079"
  },
  {
    "text": "are met uh before um we move on and I think what's really important about that",
    "start": "635079",
    "end": "640320"
  },
  {
    "text": "is you know with validating um you can it's really powerful to Define what are your assumptions are when you complete",
    "start": "640320",
    "end": "647000"
  },
  {
    "text": "your maintenance right um we do a lot of um we make with our testing we test like",
    "start": "647000",
    "end": "652760"
  },
  {
    "text": "the node is healthy before we return it to the cluster but you could really do anything you could say okay was this",
    "start": "652760",
    "end": "657959"
  },
  {
    "text": "maintenance successful right like in kubernetes that would be like looking at the node and seeing the you know the the",
    "start": "657959",
    "end": "663480"
  },
  {
    "text": "version that the the cubet is reporting on the API um but there's like so many ways you can do that so um there's a lot",
    "start": "663480",
    "end": "671079"
  },
  {
    "text": "of ways you can you can approach that and and it's really valuable with uh to make those assumptions and so um",
    "start": "671079",
    "end": "678519"
  },
  {
    "text": "completing or failing validation what what's really interesting is that that fork that other path where we fail",
    "start": "678519",
    "end": "684839"
  },
  {
    "text": "validation like we could do a whole cucon talk on failing validation or are are getting a node that we can't bring",
    "start": "684839",
    "end": "691920"
  },
  {
    "text": "back in production like I'm sure we've probably all seen this like where we've we've got to a point where this node",
    "start": "691920",
    "end": "697760"
  },
  {
    "text": "just fails and we don't know what to do and you know we've done all different things to try and bring it back and",
    "start": "697760",
    "end": "703720"
  },
  {
    "text": "we've retried our maintenance operations we retry validation and we have no idea like what's wrong and and someone like",
    "start": "703720",
    "end": "709560"
  },
  {
    "text": "in the data center pulled out the ethernet cable or something you know like we have no idea like it's hard to detect these things sometimes and um and",
    "start": "709560",
    "end": "717440"
  },
  {
    "text": "so what do we do like what's really valuable is that these off-ramps can bring you to a place where you it's",
    "start": "717440",
    "end": "724279"
  },
  {
    "text": "almost like detection like we've we've determined that this node can't work right we've we've probably gone through",
    "start": "724279",
    "end": "730160"
  },
  {
    "text": "this process like four times fifth pass through or 10th pass through validation it still fails we should probably have a",
    "start": "730160",
    "end": "736800"
  },
  {
    "text": "person look at it so anyway that's a whole talk that we could talk about we have like so many cases where we come across these things like these edge",
    "start": "736800",
    "end": "743240"
  },
  {
    "text": "cases where we we we basically bring in people to go look at and figure out what's going on with the node or the GPU",
    "start": "743240",
    "end": "750199"
  },
  {
    "text": "other sort of accelerators okay and then finally returning to production um finally like",
    "start": "750199",
    "end": "756560"
  },
  {
    "text": "we're done like this would be the last step like we've completed our maintenance we've validated the noes healthy the the maintenance was complete",
    "start": "756560",
    "end": "763360"
  },
  {
    "text": "so you can kind of get a sense just to summarize like with these eight is the these steps are going to be the steps",
    "start": "763360",
    "end": "769000"
  },
  {
    "text": "you're always going to go through when you want to do maintenance uh in some form so uh what did we do we we like I",
    "start": "769000",
    "end": "774839"
  },
  {
    "text": "said we wanted to build an API so what what we did um well we we did did that we built an API and uh we called it we",
    "start": "774839",
    "end": "782000"
  },
  {
    "text": "called it notify maintenance API uh the the the name notify um combined with",
    "start": "782000",
    "end": "788600"
  },
  {
    "text": "maintenance kind of has a meaning in that we we want to send out a lot of notifications with maintenance",
    "start": "788600",
    "end": "793800"
  },
  {
    "text": "maintenance is kind of interesting and that like everyone wants to know about it right it's really important and so",
    "start": "793800",
    "end": "799800"
  },
  {
    "text": "that's one of the other focuses that we have um and I'll get to that in just a minute U but just to give you an example",
    "start": "799800",
    "end": "805079"
  },
  {
    "text": "like looking at the requirements that we had for doing maintenance um you can you can see like some of the states that you",
    "start": "805079",
    "end": "810839"
  },
  {
    "text": "always will go through like scheduling a drain right we just created a state for that we call it maintenance schedule",
    "start": "810839",
    "end": "816600"
  },
  {
    "text": "starting a drain right we created a state for that um we call it maintenance started um then last one like returning",
    "start": "816600",
    "end": "822440"
  },
  {
    "text": "to production right that's maintenance complete so you get a sense like we created this finite State machine goes",
    "start": "822440",
    "end": "827760"
  },
  {
    "text": "through a bunch of steps and we have this these canonical apis these canonical States for representing",
    "start": "827760",
    "end": "833800"
  },
  {
    "text": "maintenance we can do lots of powerful things with that so that's what we're going to we're talk about just a second",
    "start": "833800",
    "end": "840360"
  },
  {
    "text": "so this is just an example um of what this looks like it's actually um pretty",
    "start": "840360",
    "end": "845399"
  },
  {
    "text": "simple API we um not too much to it um we have a few fields in the spec um the",
    "start": "845399",
    "end": "851360"
  },
  {
    "text": "additional message Channel this is kind of the notified part of notifi Maintenance where um we want to get the",
    "start": "851360",
    "end": "857360"
  },
  {
    "text": "word out that that U maintenance is going on and so um we actually send our messages um so like for example like",
    "start": "857360",
    "end": "865320"
  },
  {
    "text": "this is a crd this is uh a CR and and you have um in it uh or with with with",
    "start": "865320",
    "end": "873320"
  },
  {
    "text": "it the kubernetes events right if we change the state we'll get all these different events sent to all the Watchers so we have all this event",
    "start": "873320",
    "end": "879959"
  },
  {
    "text": "system built into kuties um with uh our focus with with actually notifying lots",
    "start": "879959",
    "end": "885079"
  },
  {
    "text": "of people we also want to send the events um outside of that structure right because like human beings we don't",
    "start": "885079",
    "end": "890680"
  },
  {
    "text": "really watch kubernetes objects and like monitor their states it's not really a great system I mean I know everyone",
    "start": "890680",
    "end": "896320"
  },
  {
    "text": "loves you know cute cuddle watch but um I don't like sitting in my laptop and 3 in the morning doing that so I would",
    "start": "896320",
    "end": "901720"
  },
  {
    "text": "much rather get some sort of notification in another way and so that's what we do is like these",
    "start": "901720",
    "end": "907279"
  },
  {
    "text": "additional message channels we send them out we send them to people we'll send them to slack um they get all over the",
    "start": "907279",
    "end": "912720"
  },
  {
    "text": "place we actually use Pub sub systems like SNS and um but you can really use anything like RAB mq and eventually fan",
    "start": "912720",
    "end": "919320"
  },
  {
    "text": "out these messages all over different all over different places outside um of",
    "start": "919320",
    "end": "925320"
  },
  {
    "text": "kubernetes okay in the second field um maintenance ID essentially like you can see here V bios 0 42b like what does",
    "start": "925320",
    "end": "932240"
  },
  {
    "text": "that mean um well kind of like what we want to do is we want to like version our upgrades we want to describe our",
    "start": "932240",
    "end": "938759"
  },
  {
    "text": "upgrades and and what we're doing and particularly um these should be like",
    "start": "938759",
    "end": "944160"
  },
  {
    "text": "uids so all the CRS associated with v bios 04 2B should all have the same",
    "start": "944160",
    "end": "950240"
  },
  {
    "text": "maintenance ID and they all have um different CRS and different representations uh of or description of",
    "start": "950240",
    "end": "956920"
  },
  {
    "text": "Maintenance and so this one one is vbio 0 42b and it's on node 003b right we",
    "start": "956920",
    "end": "963680"
  },
  {
    "text": "could have another one that's on node 04b um so these these kinds of things are we we should see a lot of them and",
    "start": "963680",
    "end": "969720"
  },
  {
    "text": "then in the aggregate it describes exactly what we're doing with maintenance inside of a inide of a",
    "start": "969720",
    "end": "976240"
  },
  {
    "text": "cluster um and then another one the maintenance type this one's kind of cool because um two types of maintenances um",
    "start": "976240",
    "end": "982959"
  },
  {
    "text": "planned and unplanned um I'll have a diagram with that in just a second but really important Fields um planned is",
    "start": "982959",
    "end": "989040"
  },
  {
    "text": "like premeditated maintenance operations that you want to do um unplanned is",
    "start": "989040",
    "end": "994079"
  },
  {
    "text": "things that suddenly go wrong that need to be fixed and um that has a big deal",
    "start": "994079",
    "end": "1000800"
  },
  {
    "text": "for for understanding whether actually a maintenance should be scheduled or treated differently right like unplanned",
    "start": "1000800",
    "end": "1007680"
  },
  {
    "text": "maintenance if something's wrong we kind of want to fix the node versus planned like maybe it's not a good time to",
    "start": "1007680",
    "end": "1013120"
  },
  {
    "text": "accept this kubernetes upgrade when the node's broken so you kind of get a sense like how that um how that can uh we can",
    "start": "1013120",
    "end": "1019800"
  },
  {
    "text": "use that um and then the last two in status um you know we have the main in status this is just our our diff this is",
    "start": "1019800",
    "end": "1026079"
  },
  {
    "text": "representation of our state machine uh and then the last one um SLA expires um one thing that's really important with",
    "start": "1026079",
    "end": "1033120"
  },
  {
    "text": "um doing maintenances is that uh you really have to have this agreement with the end user that if you want to remove",
    "start": "1033120",
    "end": "1040240"
  },
  {
    "text": "a workload it can't just run indefinitely so we we have to have some sort of agreement here and understanding",
    "start": "1040240",
    "end": "1046280"
  },
  {
    "text": "that these workloads should at some point expire and so that's kind of a way to signal that we can have a time stamp",
    "start": "1046280",
    "end": "1051960"
  },
  {
    "text": "to that we agree upon you know some later date that these workloads should be",
    "start": "1051960",
    "end": "1057679"
  },
  {
    "text": "moved okay so let's talk more about the notify part of this so really what we're doing with this notify maintenance API",
    "start": "1058160",
    "end": "1064600"
  },
  {
    "text": "is we're we're trying to coordinate maintenance um between operators right we write controllers we write operators",
    "start": "1064600",
    "end": "1070679"
  },
  {
    "text": "we have a bunch of states and we want to use those um as a conduit to communicate",
    "start": "1070679",
    "end": "1075760"
  },
  {
    "text": "right we have um we can write a bunch of automation we can uh to to do maintenance for us but it's really",
    "start": "1075760",
    "end": "1081679"
  },
  {
    "text": "important to include humans like I was saying we want to get people involved they really care about maintenances and",
    "start": "1081679",
    "end": "1087880"
  },
  {
    "text": "if there's like any devops people out there like you know that when failures occur like they end up as incidents and",
    "start": "1087880",
    "end": "1093760"
  },
  {
    "text": "those incidents get reported to your phone over pag your duty or something and and you probably want to figure out",
    "start": "1093760",
    "end": "1099159"
  },
  {
    "text": "what's going on and and so a lot of times we want to actually before you get that page we probably would like to know",
    "start": "1099159",
    "end": "1106240"
  },
  {
    "text": "that okay someone was actually doing maintenance in that zone not really an incident so it's really important to you",
    "start": "1106240",
    "end": "1111720"
  },
  {
    "text": "know to get the word around about this stuff and like I said we we basically what we do is we we send these over to",
    "start": "1111720",
    "end": "1117320"
  },
  {
    "text": "uh SNS whenever we do these State transitions um um but you can you can use really any system any message bus",
    "start": "1117320",
    "end": "1123720"
  },
  {
    "text": "for this and we fan out to all different sources and then we we actually format our messages for different end users",
    "start": "1123720",
    "end": "1130559"
  },
  {
    "text": "like humans um we probably don't want like yaml when we get a message we probably would just like a string",
    "start": "1130559",
    "end": "1136600"
  },
  {
    "text": "summarizing what's happening um so we do stuff like that okay so",
    "start": "1136600",
    "end": "1141640"
  },
  {
    "text": "here's a look at what it actually um when this comes together so this picture",
    "start": "1141640",
    "end": "1147120"
  },
  {
    "text": "um is a look at just inside a single cluster um when you have the notifi maintenance API uh what you get so with",
    "start": "1147120",
    "end": "1154120"
  },
  {
    "text": "notifi maintenance API you have a bunch of States we have this understanding of of the meaning of a maintenance that",
    "start": "1154120",
    "end": "1160120"
  },
  {
    "text": "represented in state and what we get is this um these orange boxes surrounding",
    "start": "1160120",
    "end": "1165640"
  },
  {
    "text": "it and these are the ecosystem that that is really important for doing maintenance and these kinds of things",
    "start": "1165640",
    "end": "1171880"
  },
  {
    "text": "are really specific to end users so um we have our own implementations of these",
    "start": "1171880",
    "end": "1176960"
  },
  {
    "text": "of these things and probably anyone that's doing maintenance would have their own implementation of this as well",
    "start": "1176960",
    "end": "1182039"
  },
  {
    "text": "so just give you um a brief overview what they are like a maintenance schedule scheduler is a um a component",
    "start": "1182039",
    "end": "1188520"
  },
  {
    "text": "that would move us between different states and notify maintenance right from like if we schedule the maintenance or",
    "start": "1188520",
    "end": "1195559"
  },
  {
    "text": "if we're in drain State you know if the node's drained we would move between these kinds of things um and then we",
    "start": "1195559",
    "end": "1201000"
  },
  {
    "text": "have another controller like a drain controller a drain operator that understands the right way to drain right",
    "start": "1201000",
    "end": "1206840"
  },
  {
    "text": "that could just be a QB CTL drain or um I mean there's other kinds of complex",
    "start": "1206840",
    "end": "1211960"
  },
  {
    "text": "things like with cubert you may want to live migrate right it's all these complex things that you could do so",
    "start": "1211960",
    "end": "1217400"
  },
  {
    "text": "that's where you'd want to implement that and then um the last one last Orange Box is on the right side is the",
    "start": "1217400",
    "end": "1222760"
  },
  {
    "text": "maintenance controller that's essentially saying that um we want a controller that actually actively does the maintenance that would be something",
    "start": "1222760",
    "end": "1229559"
  },
  {
    "text": "like like ku's upgrade or upgrading the V bios whatever it is like it upgrade",
    "start": "1229559",
    "end": "1234799"
  },
  {
    "text": "the OS anything like we can write um we can get to the state representation where we say okay it's time to do",
    "start": "1234799",
    "end": "1240679"
  },
  {
    "text": "maintenance the controller can spring into action and actually do the maintenance um and then and then the the",
    "start": "1240679",
    "end": "1246919"
  },
  {
    "text": "bottom picture is like how we kind of spray these events around okay so that's that's how it looks like today that's",
    "start": "1246919",
    "end": "1252720"
  },
  {
    "text": "something we implemented now in Nvidia clusters so this is kind of what we want to move to tomorrow um and this is like",
    "start": "1252720",
    "end": "1259480"
  },
  {
    "text": "the large kind of like the end game for us in coordinating Fleet Maintenance um is what I call it and we're really what",
    "start": "1259480",
    "end": "1265360"
  },
  {
    "text": "we're doing here is we're push we're Shifting the user left where instead of just creating CRS inside of data center",
    "start": "1265360",
    "end": "1270960"
  },
  {
    "text": "inide of cman cluster we actually want to um look outside of the kuber endus",
    "start": "1270960",
    "end": "1276120"
  },
  {
    "text": "cluster we want to at the fleet level we want to um say Okay I want to do a",
    "start": "1276120",
    "end": "1282080"
  },
  {
    "text": "maintenance on a data center in New York City and a data center in Florida and a data center in Los Angeles and and then",
    "start": "1282080",
    "end": "1290120"
  },
  {
    "text": "this Fleet scheduler component this Fleet Maintenance component says okay it's a great time to do maintenance",
    "start": "1290120",
    "end": "1295679"
  },
  {
    "text": "right now in Florida so all we do is go into the zone and say create a bunch of CRS and and and and and then inside the",
    "start": "1295679",
    "end": "1302760"
  },
  {
    "text": "Zone we have the schedular component that's going to see these and say okay it's a good time to do maintenance on node one node 7even and node 10 right",
    "start": "1302760",
    "end": "1310039"
  },
  {
    "text": "and it would work through the zone so we can you kind of see how the hierarchy of this um you can build this this this",
    "start": "1310039",
    "end": "1315880"
  },
  {
    "text": "hocr system um and that's what we're actually looking to do uh to do now okay um so for I'm G to hand over to",
    "start": "1315880",
    "end": "1324480"
  },
  {
    "text": "P here in just a second the um PO is going to talk about unplanned maintenance and this is going to be the",
    "start": "1324480",
    "end": "1331400"
  },
  {
    "text": "like the real world use of like of this or one of the big gains we actually have quite a few but unplanned maintenance is",
    "start": "1331400",
    "end": "1336559"
  },
  {
    "text": "a really cool one um unplanned maintenance is like I said it's operations that go wrong in in the data",
    "start": "1336559",
    "end": "1342200"
  },
  {
    "text": "center and um we need to we need to fix them we need to fix these nodes and um",
    "start": "1342200",
    "end": "1347279"
  },
  {
    "text": "this is a big win for us that we were able to automate that process and work with notifi maintenance to schedule",
    "start": "1347279",
    "end": "1352600"
  },
  {
    "text": "these things safely so that we can remediate and fix notes hello uh so at the beginning I",
    "start": "1352600",
    "end": "1360760"
  },
  {
    "text": "would like to uh tell what I understand about unplan maintenance so in our case",
    "start": "1360760",
    "end": "1366120"
  },
  {
    "text": "can be anything like Hardware failure for example GPU fail of the bus or software crashes which sometimes also a",
    "start": "1366120",
    "end": "1373440"
  },
  {
    "text": "symptom of bad hardware and the more gpus you have in your data center the more failures you have and instead of",
    "start": "1373440",
    "end": "1380960"
  },
  {
    "text": "fighting with it we just accept that failures and we incorporate the ongoing",
    "start": "1380960",
    "end": "1386120"
  },
  {
    "text": "maintenance like as a part of our daily operations so uh yeah I want to uh show",
    "start": "1386120",
    "end": "1392679"
  },
  {
    "text": "you first how it looked in the past so we have perfectly fine healthy curent cluster with GPU nodes and something",
    "start": "1392679",
    "end": "1400360"
  },
  {
    "text": "goes wrong we can see that the capacity goes down and in the past we just had to",
    "start": "1400360",
    "end": "1405799"
  },
  {
    "text": "had some on call engineer going to the no diagnose it go through our run books",
    "start": "1405799",
    "end": "1411320"
  },
  {
    "text": "the signature errors everything and when they uh successfully hopefully",
    "start": "1411320",
    "end": "1416840"
  },
  {
    "text": "successfully diagnose the issue then he can remediate it like run some comments on the Node also through run books Etc",
    "start": "1416840",
    "end": "1424279"
  },
  {
    "text": "and then when everything went fine uh he could return the node to the cluster so",
    "start": "1424279",
    "end": "1431600"
  },
  {
    "text": "it take uh it took a lot of engineering hours for us to sustain this model and",
    "start": "1431600",
    "end": "1438440"
  },
  {
    "text": "some of the failures we didn't even notice them and it was like permanently affecting our capacity so we wanted to",
    "start": "1438440",
    "end": "1445960"
  },
  {
    "text": "solve it somehow and this is how we integrate with notify maintenance we",
    "start": "1445960",
    "end": "1451080"
  },
  {
    "text": "just took Ryan picture and removed the human on the left from it and run some automation basically we have a I would",
    "start": "1451080",
    "end": "1458880"
  },
  {
    "text": "say three layers in that first one very important one is detection layer so uh",
    "start": "1458880",
    "end": "1465799"
  },
  {
    "text": "yeah so currently we use node condition as an API to show that the node failed",
    "start": "1465799",
    "end": "1471080"
  },
  {
    "text": "uh we use node condition because there is one cool open source project which is called node problem detector and also",
    "start": "1471080",
    "end": "1476679"
  },
  {
    "text": "uses this API so we just uh started with it and you can see that it's kind of",
    "start": "1476679",
    "end": "1484000"
  },
  {
    "text": "expressive API you can see what's wrong with the cluster uh what's wrong with the node but the longer we use it we see",
    "start": "1484000",
    "end": "1490919"
  },
  {
    "text": "some shortcomings but it's like with every new kubernetes project you start building from the apis that are present",
    "start": "1490919",
    "end": "1497640"
  },
  {
    "text": "that are there and then when you start to add new features you see that maybe it can be extended or maybe it can be",
    "start": "1497640",
    "end": "1503600"
  },
  {
    "text": "replaced so let's take an example of a hardware failure yeah we have like for example two gpus on the note and one",
    "start": "1503600",
    "end": "1510880"
  },
  {
    "text": "failed so how will we express that which GPU failed in our case we just put it in",
    "start": "1510880",
    "end": "1515919"
  },
  {
    "text": "the message field and then we have like some regexs or other things in the other",
    "start": "1515919",
    "end": "1521039"
  },
  {
    "text": "layers of our stack but we could probably make it a bit better for uh our",
    "start": "1521039",
    "end": "1527520"
  },
  {
    "text": "operators so so maybe Dr can fix it in the future I know you will hear a lot of",
    "start": "1527520",
    "end": "1532640"
  },
  {
    "text": "Dr during this Co Cube con yeah but maybe maybe you can use it so uh we have",
    "start": "1532640",
    "end": "1539520"
  },
  {
    "text": "we we know we are not only using no problem detector as our detection demons we also have our custom GPU problem",
    "start": "1539520",
    "end": "1545320"
  },
  {
    "text": "detector which is the part of our device plug-in so it's like uh for us it's the",
    "start": "1545320",
    "end": "1552320"
  },
  {
    "text": "perfect place to put this detection as it has all the power uh for the GPU it",
    "start": "1552320",
    "end": "1558880"
  },
  {
    "text": "has all the knowledge about it so it can uh very quickly and precisely says what's going on and what's wrong with",
    "start": "1558880",
    "end": "1565399"
  },
  {
    "text": "the GPU on the note so yeah uh when we have the detection and we say that node",
    "start": "1565399",
    "end": "1571159"
  },
  {
    "text": "failed then we use another cool open source project which is called node heal check operator and basically it has its",
    "start": "1571159",
    "end": "1577640"
  },
  {
    "text": "own config and it like compares the uh node condition on the host with its",
    "start": "1577640",
    "end": "1583880"
  },
  {
    "text": "config and when it sees that okay I know this note condition and it means that the note is broken it triggers a",
    "start": "1583880",
    "end": "1590600"
  },
  {
    "text": "specified remediation and triggering Remediation is just creating another kubernetes custom resource so another",
    "start": "1590600",
    "end": "1597559"
  },
  {
    "text": "operator can take it and fix it so as you will see in like two slides uh our",
    "start": "1597559",
    "end": "1603640"
  },
  {
    "text": "remediation engine is also like escalating uh remediation so is if the first one failed then go to the second",
    "start": "1603640",
    "end": "1610159"
  },
  {
    "text": "one if the second one fail go to the third one so on so on so on until we say okay it's unfixable someone has to",
    "start": "1610159",
    "end": "1616440"
  },
  {
    "text": "manually do it because the machine is yeah cannot do it so uh this is the",
    "start": "1616440",
    "end": "1623240"
  },
  {
    "text": "custom resource that we use uh it's it's called note health check and you can see that for for the selector match",
    "start": "1623240",
    "end": "1630080"
  },
  {
    "text": "expression uh we tell node health check operator take a look at all the GPU nodes uh make sure that they are not",
    "start": "1630080",
    "end": "1636679"
  },
  {
    "text": "currently being uh uh the the other maintenance control is not acting upon it like for example someone is upgrading",
    "start": "1636679",
    "end": "1643640"
  },
  {
    "text": "cuber on it Etc and when you see that the GPU DVP device failure node",
    "start": "1643640",
    "end": "1649720"
  },
  {
    "text": "condition on the Node for 2 minutes create node remediation template object and the node remediation template object",
    "start": "1649720",
    "end": "1657440"
  },
  {
    "text": "uh will'll just uh instruct our operator to run those remediation on the host and",
    "start": "1657440",
    "end": "1664200"
  },
  {
    "text": "as you can see uh this is like an escalating one our remediation engine so",
    "start": "1664200",
    "end": "1669399"
  },
  {
    "text": "for examp let's take an example GPU fell off the boo follow the bus so in in the",
    "start": "1669399",
    "end": "1674720"
  },
  {
    "text": "peak times we only care about the capacity so the simplest solution is just to reboot the note maybe it will",
    "start": "1674720",
    "end": "1680480"
  },
  {
    "text": "help maybe not uh but definitely we'll have more nodes in the cluster for our customers and then sometimes it happens",
    "start": "1680480",
    "end": "1687159"
  },
  {
    "text": "that reboot is stuck so maybe we should like escalate it then for example ipmi",
    "start": "1687159",
    "end": "1692799"
  },
  {
    "text": "power cycle can help or not and if it didn't help we just say Okay this note",
    "start": "1692799",
    "end": "1698159"
  },
  {
    "text": "is like definitely broken someone has to take a look at it uh so this is how we do it and yeah I wanted to mention",
    "start": "1698159",
    "end": "1705399"
  },
  {
    "text": "validation because we always say all right you need test Etc but we never say you have to also run them so yeah you",
    "start": "1705399",
    "end": "1712039"
  },
  {
    "text": "should also run them definitely because sometimes uh our code was remediating in the node and it says remediation was",
    "start": "1712039",
    "end": "1717960"
  },
  {
    "text": "successful but the validation says otherwise so even simple sanity check is something you should do check if there",
    "start": "1717960",
    "end": "1724440"
  },
  {
    "text": "are all the gpus that we expect on the host before returning into the production and yeah some goas so we",
    "start": "1724440",
    "end": "1732600"
  },
  {
    "text": "implemented all of this it was pretty nice for some time and then we've seen like okay but one given note is being",
    "start": "1732600",
    "end": "1739600"
  },
  {
    "text": "remediated every 30 minutes like for a week and maybe it's not a perfect solution because it's still not able to",
    "start": "1739600",
    "end": "1747919"
  },
  {
    "text": "operate any uh our operating customer workload yeah so we did some quick fix",
    "start": "1747919",
    "end": "1754960"
  },
  {
    "text": "we created an alert uh as you can see we use a note health check operator pruse",
    "start": "1754960",
    "end": "1760760"
  },
  {
    "text": "metrics and we just say Okay this note was being remediated more than uh two",
    "start": "1760760",
    "end": "1765840"
  },
  {
    "text": "times where in 90 minutes interval yeah we should alert or like for example just",
    "start": "1765840",
    "end": "1772440"
  },
  {
    "text": "stop remating this note of course we have more than just this one alert specified in different interval but I",
    "start": "1772440",
    "end": "1778640"
  },
  {
    "text": "just wanted to show you the example of it and yeah the summary so yeah we just",
    "start": "1778640",
    "end": "1784480"
  },
  {
    "text": "did some summary with Ryan uh this week and it seems like we are doing a like on",
    "start": "1784480",
    "end": "1790799"
  },
  {
    "text": "average about 19 remediation per day per 1,000 notes so in our scale it's a a lot",
    "start": "1790799",
    "end": "1798320"
  },
  {
    "text": "it's like almost 1,000 remediation per day and what's the best about that is",
    "start": "1798320",
    "end": "1803360"
  },
  {
    "text": "that our developers are not being paged anymore about that and we are just fixing those noes or remediating the",
    "start": "1803360",
    "end": "1809559"
  },
  {
    "text": "noes automatically and our developers can do anything like anything is better than just fixing the Noe going for round",
    "start": "1809559",
    "end": "1816640"
  },
  {
    "text": "books Etc uh yeah right now I will hand over to",
    "start": "1816640",
    "end": "1822360"
  },
  {
    "text": "Ryan okay so um the the work we talked about here the the notify maintenance API we've actually open sourced it",
    "start": "1822360",
    "end": "1828679"
  },
  {
    "text": "um it's under the project on the left with that QR code it's called Pika um you can check it out um if you're",
    "start": "1828679",
    "end": "1834799"
  },
  {
    "text": "curious you want to try it um uh like I said it's it's it's a state machine it's",
    "start": "1834799",
    "end": "1840840"
  },
  {
    "text": "a it's a it's a way to it has a bunch of canonical States for defining maintenance so you can use it to build a",
    "start": "1840840",
    "end": "1847640"
  },
  {
    "text": "bunch of controllers like we described around it so that you can do maintenance in a similar way um so but you know what's next like",
    "start": "1847640",
    "end": "1855159"
  },
  {
    "text": "we open source this um you know we really want to collaborate more with um you know that was kind of one of our requirements with this and um kind of I",
    "start": "1855159",
    "end": "1862559"
  },
  {
    "text": "left this as a question but you know start a working group I mean I think like if there's a lot of interest in about this in the community um I would",
    "start": "1862559",
    "end": "1869799"
  },
  {
    "text": "love to start a work in group and start discussing this topic and I think it would be interesting and really cross cutting AC uh across a bunch of sigs and",
    "start": "1869799",
    "end": "1877639"
  },
  {
    "text": "working groups and me you look at like the number of accelerators we're putting in our data centers today and we're really just increasing the entropy of",
    "start": "1877639",
    "end": "1883960"
  },
  {
    "text": "our data centers and this is just leading to more challenges and and challenges with doing maintenance and",
    "start": "1883960",
    "end": "1889880"
  },
  {
    "text": "even like figuring out like what's going on with some of the problems um and so that's that kind of thing um really",
    "start": "1889880",
    "end": "1897159"
  },
  {
    "text": "leads us to like look at um different solutions where we need to we have our devices and we need to you know we need",
    "start": "1897159",
    "end": "1902720"
  },
  {
    "text": "to report them up to kubernetes like all that kind of stuff is is really important um detecting issues so that we",
    "start": "1902720",
    "end": "1909200"
  },
  {
    "text": "can even do something with them um so all that stuff is um is really interesting to us like we we want to",
    "start": "1909200",
    "end": "1915679"
  },
  {
    "text": "keep our capacity online right it's so expensive all these different accelerators we want to make sure they're in use all the time as much as",
    "start": "1915679",
    "end": "1922240"
  },
  {
    "text": "possible um and so one of resource um there is a cap for this um that is in",
    "start": "1922240",
    "end": "1927360"
  },
  {
    "text": "the community for node maintenance um and something that we're interested in and uh will be participating in so it's",
    "start": "1927360",
    "end": "1935039"
  },
  {
    "text": "I think um there is some interest out there but if you are really interested in talking about do maintenance and know come find us we definitely are",
    "start": "1935039",
    "end": "1941480"
  },
  {
    "text": "interested and and continue to talk about this more okay and and that's it thank you",
    "start": "1941480",
    "end": "1949510"
  },
  {
    "text": "[Applause]",
    "start": "1949510",
    "end": "1954880"
  },
  {
    "text": "yeah oh oh do you if you have if you have any questions just step up to the mic and ask away we've got two",
    "start": "1954880",
    "end": "1963240"
  },
  {
    "text": "minutes hey how's it going can you hear me yep okay uh does your maintenance",
    "start": "1969320",
    "end": "1974880"
  },
  {
    "text": "controller take into account multiple node drains do do you have logic or are you thinking about putting logic in",
    "start": "1974880",
    "end": "1980720"
  },
  {
    "text": "seems like the number the quantity of nodes you have you probably need to do more than one at a time yeah so that's a great question so that's really",
    "start": "1980720",
    "end": "1986600"
  },
  {
    "text": "important because we have to take that into account because we want to keep capacity online one of our requirements is we don't want to interrupt end users",
    "start": "1986600",
    "end": "1993080"
  },
  {
    "text": "so that also means that we're going to be getting new workloads constantly so that's our assumption so we can't just",
    "start": "1993080",
    "end": "1998320"
  },
  {
    "text": "take capacity down forever so we need to be careful to look at what is going on",
    "start": "1998320",
    "end": "2004039"
  },
  {
    "text": "in the cluster how many nodes are unschedulable how many are under maintenance how many under unplanned maintenance right or broken or",
    "start": "2004039",
    "end": "2010120"
  },
  {
    "text": "remediated right so we that's something that we built into uh our controller to to figure out the right thing to do",
    "start": "2010120",
    "end": "2016480"
  },
  {
    "text": "whether it's the right time to do maintenance cool thank you you're welcome uh yeah quick question uh for",
    "start": "2016480",
    "end": "2023080"
  },
  {
    "text": "plant for plant uh maintenance we can hear you yeah can you hear me now yeah",
    "start": "2023080",
    "end": "2028440"
  },
  {
    "text": "that's for plant maintenance uh how do you guys uh communicate that with the customers and if if there is a workload",
    "start": "2028440",
    "end": "2036679"
  },
  {
    "text": "running uh do you just uh replace it restart it from beginning or is there",
    "start": "2036679",
    "end": "2042519"
  },
  {
    "text": "any uh protocol to checkpoint and restart from the uh",
    "start": "2042519",
    "end": "2048638"
  },
  {
    "text": "same point on the new machine um okay so your question is um if we were interrupt",
    "start": "2048639",
    "end": "2054440"
  },
  {
    "text": "a workload did do we have like a checkpoint so that we could return to where it was if we were to bring it back",
    "start": "2054440",
    "end": "2060760"
  },
  {
    "text": "online um so right now with um with the GeForce now workloads we we don't um we",
    "start": "2060760",
    "end": "2067398"
  },
  {
    "text": "don't really checkpoint them um doesn't mean like we can't do that we actually",
    "start": "2067399",
    "end": "2072760"
  },
  {
    "text": "we could um I I don't know if we had we've had too much of a use case for it um but the the thing that I would say",
    "start": "2072760",
    "end": "2079760"
  },
  {
    "text": "that's important um about your question is like if we were to take on like AI workloads for example that'd be like a",
    "start": "2079760",
    "end": "2085599"
  },
  {
    "text": "really important thing to do like we really when we're going to load large language models into onto a node like",
    "start": "2085599",
    "end": "2091280"
  },
  {
    "text": "it's really important that we just you know we can checkpoint them and you know return to where they were so it's",
    "start": "2091280",
    "end": "2096679"
  },
  {
    "text": "something that um we could do it's something we just have to incorporate into you know how we handle maintenance",
    "start": "2096679",
    "end": "2102440"
  },
  {
    "text": "yeah I think that notify maintenance object can be also used by tenants to actively watch for ongoing maintenances",
    "start": "2102440",
    "end": "2108800"
  },
  {
    "text": "on the Node we can also like fun out those to the tenant it's up up to how",
    "start": "2108800",
    "end": "2114040"
  },
  {
    "text": "you define your API with our tenants yeah and Which object can they watch and",
    "start": "2114040",
    "end": "2119839"
  },
  {
    "text": "if they even have like kubernetes access to note yeah like the API one",
    "start": "2119839",
    "end": "2125920"
  },
  {
    "text": "thanks hi um sorry what is the primary uh motivation to use crds as part of the",
    "start": "2125920",
    "end": "2135359"
  },
  {
    "text": "uh state to basically that's how you operate and for the state transitions",
    "start": "2135359",
    "end": "2140400"
  },
  {
    "text": "right so um have you ever explored other options like uh using a centralized or",
    "start": "2140400",
    "end": "2147240"
  },
  {
    "text": "distributed database or maybe annotations on the note so um kind of",
    "start": "2147240",
    "end": "2152800"
  },
  {
    "text": "curious the the decision behind the behind that",
    "start": "2152800",
    "end": "2158920"
  },
  {
    "text": "uh so I I missed some of the question was it that what was the decision to use crds is that what you said right yeah",
    "start": "2158920",
    "end": "2164800"
  },
  {
    "text": "okay um so the the reason was because we wanted to we really wanted a kuber",
    "start": "2164800",
    "end": "2170160"
  },
  {
    "text": "native solution I that was really important to us and we also wanted to I this is a common pattern in kubernets",
    "start": "2170160",
    "end": "2175520"
  },
  {
    "text": "like we can define a state machine and expose it behind um a custom resource definition um so we wanted to we really",
    "start": "2175520",
    "end": "2182920"
  },
  {
    "text": "just wanted to follow the same pattern and and besides the you know there's such a re Rich ecosystem in C for controllers and and and listat and and",
    "start": "2182920",
    "end": "2190560"
  },
  {
    "text": "so we really wanted to leverage all of that in our ecosystem for um implementing this so like all like I",
    "start": "2190560",
    "end": "2196319"
  },
  {
    "text": "showed those orange boxes on the screen those are all controllers those are all Native operators in kuity so we get all",
    "start": "2196319",
    "end": "2202040"
  },
  {
    "text": "that logic of of essentially list watch and and events for free um we get that",
    "start": "2202040",
    "end": "2208960"
  },
  {
    "text": "through the API server and ND so it really solved a bunch of problems for us we didn't have to worry about a lot of",
    "start": "2208960",
    "end": "2215079"
  },
  {
    "text": "those things so it made it easier for us to to get started and make it effective",
    "start": "2215079",
    "end": "2220839"
  },
  {
    "text": "thank you can you hear me hello yep so can you",
    "start": "2220839",
    "end": "2226119"
  },
  {
    "text": "guys speak a bit to how you guys are actually making workload aware decisions",
    "start": "2226119",
    "end": "2231200"
  },
  {
    "text": "on when you should approve maintenance right you're like approving maintenance on I'm assuming on behalf of workloads",
    "start": "2231200",
    "end": "2236760"
  },
  {
    "text": "um can you speak a bit to like what kind of intelligence you guys are using is it just pdb are you doing some like actual",
    "start": "2236760",
    "end": "2243520"
  },
  {
    "text": "checks with the workloads like I know you're actually informing you said you'd actually inform the workloads or fan out the the message can you speak a bit more",
    "start": "2243520",
    "end": "2250200"
  },
  {
    "text": "to this yeah um so we this is something",
    "start": "2250200",
    "end": "2255680"
  },
  {
    "text": "that's like kind of ongoing we've um because it's it's like a really large topic um we we're actually kind of",
    "start": "2255680",
    "end": "2262960"
  },
  {
    "text": "learning along the way as we're doing this um we've now that we've got a point where we can do maintenances in data",
    "start": "2262960",
    "end": "2268119"
  },
  {
    "text": "centers so um a lot of what we're looking at doing now is like when I give the example scheduling maintenance at",
    "start": "2268119",
    "end": "2274000"
  },
  {
    "text": "the fleet level is we have all these Regional data centers right and you can imagine that um that and maybe this is",
    "start": "2274000",
    "end": "2281280"
  },
  {
    "text": "for many out here like there's certain seasonality patterns to your usage and so there's this is just one example",
    "start": "2281280",
    "end": "2287640"
  },
  {
    "text": "where we could look at the seasonality data and we could say okay well data center in Florida right now is under low",
    "start": "2287640",
    "end": "2294400"
  },
  {
    "text": "usage so it's like really good time to do maintenance there whereas in LAX that it's under high usage so we really",
    "start": "2294400",
    "end": "2301160"
  },
  {
    "text": "shouldn't take the opportunity to do maintenance we could but you know it might be a little slower so there's",
    "start": "2301160",
    "end": "2306640"
  },
  {
    "text": "these all these things we can do we can choose pick and choose on all these different factors we can go by incidents",
    "start": "2306640",
    "end": "2312160"
  },
  {
    "text": "active incidents Regional incidents um you know those are all the kind of things that we've we found and we're",
    "start": "2312160",
    "end": "2317440"
  },
  {
    "text": "learning that we um we're going to be incorporating so you're not necessarily looking into like what the workloads are",
    "start": "2317440",
    "end": "2324480"
  },
  {
    "text": "doing like it's workload agnostic at this point so we also do like some of our tenants has its own controllers it's",
    "start": "2324480",
    "end": "2331680"
  },
  {
    "text": "not like using uh I know replic C set or something like this that's why we also has SLA and our tenant controllers are",
    "start": "2331680",
    "end": "2339040"
  },
  {
    "text": "watching the notify maintenance objects and they know that they have to evacuate their workload in this amount of time I",
    "start": "2339040",
    "end": "2346359"
  },
  {
    "text": "see thank you okay I think we're at time thank you",
    "start": "2346359",
    "end": "2353960"
  },
  {
    "text": "very much [Applause]",
    "start": "2353960",
    "end": "2358440"
  }
]
[
  {
    "text": "hello everyone super happy to be here in the CubeCon stage uh welcome i'm super",
    "start": "0",
    "end": "5520"
  },
  {
    "text": "excited to be here in London in my home city i hope all of you enjoying the warm weather in April in London so my name is",
    "start": "5520",
    "end": "12639"
  },
  {
    "text": "Andre i work at Apple um I've been this committee for the last 8 years right now I'm the cubeflow steering committee so",
    "start": "12639",
    "end": "18480"
  },
  {
    "text": "today we're going to share you the updates from the ecosystem at what's actually next for cloud native ML and",
    "start": "18480",
    "end": "24080"
  },
  {
    "text": "first of all I think we'll spend um few minutes to introduce our panelists so you can start",
    "start": "24080",
    "end": "30000"
  },
  {
    "text": "thank you uh I'm Yuki a software engineer working for cyber agent and",
    "start": "30000",
    "end": "35760"
  },
  {
    "text": "maintaining cubernetes cube cube for Q batch related CNC cell ecosystem tools",
    "start": "35760",
    "end": "44399"
  },
  {
    "text": "hi everyone uh thank you for being here my name is Yan i'm a senior principal software engineer at Red Hat AI and I'm",
    "start": "44399",
    "end": "51680"
  },
  {
    "text": "one of the steering committee members in Coupeflow and also a project lead for",
    "start": "51680",
    "end": "56879"
  },
  {
    "text": "AGO and uh also co-chair in the Kubernetes working group serving",
    "start": "56879",
    "end": "63280"
  },
  {
    "text": "hi everyone I'm a technical director at Newanx AI um in open source i uh I'm",
    "start": "63280",
    "end": "69840"
  },
  {
    "text": "part of the cubeflow steering committee and lead couple of AI initiatives um training and autoML and also in ML",
    "start": "69840",
    "end": "76000"
  },
  {
    "text": "common storage hello and welcome i'm Valentina",
    "start": "76000",
    "end": "81439"
  },
  {
    "text": "Rodriguez i'm a principal architect at Red Hat and also I contribute to QFlow on diverse projects i'm also part of the",
    "start": "81439",
    "end": "88400"
  },
  {
    "text": "release team and also work with the platform working groups and a case and I am a KCD organizer in New York so thank",
    "start": "88400",
    "end": "95680"
  },
  {
    "text": "you thanks you please welcome these amazing speakers to the",
    "start": "95680",
    "end": "102400"
  },
  {
    "text": "panel all right so let's talk about Cubeflow so first of all let me ask you how many of you actually know about",
    "start": "103159",
    "end": "109079"
  },
  {
    "text": "Cubeflow all right how many of you actually successfully run this in production all right I see a few hands",
    "start": "109079",
    "end": "115600"
  },
  {
    "text": "here so just to remind everyone uh Qflow is an ecosystem of open source projects uh so the goal of our community is to",
    "start": "115600",
    "end": "122159"
  },
  {
    "text": "make it simple uh to make AI and ML compares simple portable and scalable you can run these components in any",
    "start": "122159",
    "end": "128319"
  },
  {
    "text": "kubernetes cluster whether it's on-prem third party cloud or local machines uh",
    "start": "128319",
    "end": "133760"
  },
  {
    "text": "the beauty of the Qflow is composable platform so you can use individual components as a standalone application or as a complete end to- end platform so",
    "start": "133760",
    "end": "140319"
  },
  {
    "text": "this session will be focusing on GNI and LLM ops and our community in the quite recent years work really hard to",
    "start": "140319",
    "end": "147360"
  },
  {
    "text": "actually enable Qflow components for geni and I think we can say that similar to AI and ML right now we all live in",
    "start": "147360",
    "end": "154080"
  },
  {
    "text": "this new world and all these components actually you know you can easily do geni and lmops with them and we will share",
    "start": "154080",
    "end": "160720"
  },
  {
    "text": "throughout the session how actually it's possible so by the flow you can think about like a bridge between ML and cloud",
    "start": "160720",
    "end": "167200"
  },
  {
    "text": "ecosystem so we provide a simple interfaces is for data science ML engineers to leverage those advanced",
    "start": "167200",
    "end": "173239"
  },
  {
    "text": "tools so we will structure our session in a way that we're going to show you the life cycle so this is a geni life",
    "start": "173239",
    "end": "178879"
  },
  {
    "text": "cycle that uh our community maintains and as you can see Qflow has several components which actually address every",
    "start": "178879",
    "end": "184959"
  },
  {
    "text": "stage of geni life cycle starting from spark operator for data processing the notebooks for model development and",
    "start": "184959",
    "end": "191440"
  },
  {
    "text": "trainer for fine-tuning and distributed training kip for model optimization architecture search for large large",
    "start": "191440",
    "end": "198720"
  },
  {
    "text": "scale inference and the Qflow pipelines which is stitch all these pieces together also we have a model registry",
    "start": "198720",
    "end": "204080"
  },
  {
    "text": "which allows us to store metadata and artifacts and have a sort pluggable system in it so as you can see this",
    "start": "204080",
    "end": "209920"
  },
  {
    "text": "extremely powerful because this is an extensible and a portable ecosystem because organizations can take",
    "start": "209920",
    "end": "215200"
  },
  {
    "text": "components they need and integrated with their uh internal platforms so let me first talk about",
    "start": "215200",
    "end": "221200"
  },
  {
    "text": "notebooks and what kind of exciting data we had there uh so notebooks team worked super hard to enable actually notebooks",
    "start": "221200",
    "end": "227040"
  },
  {
    "text": "to the toe this is a new thing called cubeflow workspaces uh this is like the snapshot of the new UI that's going to",
    "start": "227040",
    "end": "233040"
  },
  {
    "text": "come up very soon so the idea is to provide you simple interfaces how you can create um interactive ID for data",
    "start": "233040",
    "end": "239200"
  },
  {
    "text": "scientists using R studio VS code Jupyter lab in a way that this is very plable for data scientists and at the",
    "start": "239200",
    "end": "245760"
  },
  {
    "text": "same time for platform engineers so if you want to learn about it please join their community calls there a lot of exciting updates coming in so looking",
    "start": "245760",
    "end": "252480"
  },
  {
    "text": "forward to the release uh moving forward to the spark operator so the goal of spark operator is to enable spark",
    "start": "252480",
    "end": "258400"
  },
  {
    "text": "applications on top of kubernetes we have a lot of uh organizations who using this in production uh that recently this",
    "start": "258400",
    "end": "265120"
  },
  {
    "text": "project could donated from Google to Qflow ecosystem so right now it's part of our broader scope and in quite",
    "start": "265120",
    "end": "271840"
  },
  {
    "text": "recently they released a new version of spark operator which is 2.1.0 uh they integrated new portlates there to",
    "start": "271840",
    "end": "278560"
  },
  {
    "text": "support spark 3.x also they've done a significant amount of work for unicorn with gang scheduling uh they refactoring",
    "start": "278560",
    "end": "285680"
  },
  {
    "text": "the entire codebase with control runtime also like very exciting things about interactive sessions um so folks in the",
    "start": "285680",
    "end": "292720"
  },
  {
    "text": "spark operator community work really hard to actually enabling uh Jupyter notebooks uh works well with spark on",
    "start": "292720",
    "end": "299280"
  },
  {
    "text": "kubernetes so this is like very exciting things coming in uh so if you want to join them please uh join the community",
    "start": "299280",
    "end": "304560"
  },
  {
    "text": "calls it's like calls every I believe Friday every second Friday so community",
    "start": "304560",
    "end": "309919"
  },
  {
    "text": "is great and let us know if you're using spark operator we're looking forward to more organizations being involved uh one of the very exciting things about Spark",
    "start": "309919",
    "end": "316400"
  },
  {
    "text": "is actually uh benchmarks that uh AWS friends from AWS uh have done here so",
    "start": "316400",
    "end": "322080"
  },
  {
    "text": "they actually uh try to run qflow spark operator on 60,000 spark applications",
    "start": "322080",
    "end": "327840"
  },
  {
    "text": "across 36,000 pots which was great like this blog post has a lot of great information of how actually spark can be",
    "start": "327840",
    "end": "335360"
  },
  {
    "text": "used at large scale so it's amazing please take a look um so J next uh so",
    "start": "335360",
    "end": "342080"
  },
  {
    "text": "next I'm going to speak about Qflow KT project uh so as I mentioned this project for hyperparameter optimization",
    "start": "342080",
    "end": "348000"
  },
  {
    "text": "and architecture search so I have few exciting updates for GNI this year so this is one of the examples how we",
    "start": "348000",
    "end": "355120"
  },
  {
    "text": "actually simplify hyperparameter optimization for LM fine-tuning which actually allows you seamlessly create uh",
    "start": "355120",
    "end": "362160"
  },
  {
    "text": "experiments with KATIP using just one simple API uh so this is actually one of uh good thing where this is the was",
    "start": "362160",
    "end": "368800"
  },
  {
    "text": "contributed by GSOC students with our community so this is fully um uh fully",
    "start": "368800",
    "end": "374240"
  },
  {
    "text": "in upstream so if you want to check this in the blog post I'm strongly suggest you to check how we can make it easy for",
    "start": "374240",
    "end": "379840"
  },
  {
    "text": "folks to do parameter optimization for LLMs also one of the exciting updates about rack so actually katip is kind of",
    "start": "379840",
    "end": "387120"
  },
  {
    "text": "the project which allows you to to optimize almost anything and one of uh our contributors um show how you can use",
    "start": "387120",
    "end": "394800"
  },
  {
    "text": "this with rateral generation so basically they creating the entire rack pipeline and um uh plugin is within kip",
    "start": "394800",
    "end": "402080"
  },
  {
    "text": "experiment so they can see how this could be optimized within um within their life cycle so also please feel",
    "start": "402080",
    "end": "408720"
  },
  {
    "text": "free to check the blog post it's really exciting things uh then I'm going to pass it to Yuki so he will speak more",
    "start": "408720",
    "end": "414240"
  },
  {
    "text": "about the Qflow trainer project we have a lot of things there thank you Andre",
    "start": "414240",
    "end": "419280"
  },
  {
    "text": "okay uh in my section uh I will introduce about QR trainer uh as",
    "start": "419280",
    "end": "426479"
  },
  {
    "text": "described by Andre so in today ML workforce cycle uh uh we we typically uh",
    "start": "426479",
    "end": "435759"
  },
  {
    "text": "perform the training model training and finetuning um after the model",
    "start": "435759",
    "end": "441880"
  },
  {
    "text": "development um trainer is responsible responsible for the um fine tuning and",
    "start": "441880",
    "end": "448560"
  },
  {
    "text": "model training",
    "start": "448560",
    "end": "451880"
  },
  {
    "text": "uh Q for trainer is uh actually uh designed for not only for large rangage",
    "start": "453919",
    "end": "460319"
  },
  {
    "text": "model so gener generic fine turing and machine learning training model um",
    "start": "460319",
    "end": "467039"
  },
  {
    "text": "across various frameworks uh something like uh pytor jacks uh tensorfl or",
    "start": "467039",
    "end": "474199"
  },
  {
    "text": "others uh Q for trainer uh today uh we",
    "start": "474199",
    "end": "479440"
  },
  {
    "text": "have Q for trainer B2 and Q for trainer B2 is um ro oriented resource model uh",
    "start": "479440",
    "end": "487120"
  },
  {
    "text": "which means trainer has two types resources uh which is train job and training",
    "start": "487120",
    "end": "493639"
  },
  {
    "text": "runtime uh training runtime is predefined by DevOps engineers and",
    "start": "493639",
    "end": "501120"
  },
  {
    "text": "uh ML engineers define the train job and they specify",
    "start": "501120",
    "end": "507840"
  },
  {
    "text": "uh arbitrary training runtime in their train job this model uh allows us to",
    "start": "507840",
    "end": "514159"
  },
  {
    "text": "decouple responsibility between infrastructure side and training code",
    "start": "514159",
    "end": "519959"
  },
  {
    "text": "side by this resource model uh oh sorry",
    "start": "519959",
    "end": "525000"
  },
  {
    "text": "uh okay uh by this resource model uh data scientist can focus on their uh",
    "start": "525000",
    "end": "532160"
  },
  {
    "text": "training code and related parameters like number of nodes or number of",
    "start": "532160",
    "end": "538399"
  },
  {
    "text": "processes inside of single nodes or some",
    "start": "538399",
    "end": "543680"
  },
  {
    "text": "else and uh this table is um current uh machine learning frame",
    "start": "544519",
    "end": "552320"
  },
  {
    "text": "supporting tables as you know uh we are planning to",
    "start": "552320",
    "end": "559519"
  },
  {
    "text": "uh support various type of ML framework uh for britzu the same as B run trainer",
    "start": "559519",
    "end": "565440"
  },
  {
    "text": "uh currently uh we support PyTorch deep speed",
    "start": "565440",
    "end": "571320"
  },
  {
    "text": "MLX and the TensorFlow and hugging face is under development eventually uh we",
    "start": "571320",
    "end": "579279"
  },
  {
    "text": "supports Jax ple and exib",
    "start": "579279",
    "end": "584640"
  },
  {
    "text": "boost in this slide uh let me quickly iterate uh our cube for trainer internal",
    "start": "587560",
    "end": "594200"
  },
  {
    "text": "mechanism uh in the training B run uh we have ML framework dedicated CL something",
    "start": "594200",
    "end": "600880"
  },
  {
    "text": "like Python job or TF job however in the trainer B2 uh we consolidate all kind of",
    "start": "600880",
    "end": "608720"
  },
  {
    "text": "job CLD into training runtime and train job",
    "start": "608720",
    "end": "613959"
  },
  {
    "text": "um so instead of uh dedicated job CLD job CLDs uh we construct cube for",
    "start": "613959",
    "end": "622320"
  },
  {
    "text": "trainer pipeline framework only for internally this allows to reduce",
    "start": "622320",
    "end": "628000"
  },
  {
    "text": "maintaining CLS and rapidly increase additional ML frameworks in cube for",
    "start": "628000",
    "end": "634079"
  },
  {
    "text": "trainer additionally this allows platform developers to support arbitrary",
    "start": "634079",
    "end": "640480"
  },
  {
    "text": "ML framework by themselves internally next Andre is introducing",
    "start": "640480",
    "end": "648320"
  },
  {
    "text": "about uh user experience thank you Yuki uh so Qflow trainer is a next generation",
    "start": "648320",
    "end": "654079"
  },
  {
    "text": "of training operator for those who have been using there so it's has a lot of great features for geni so one of the",
    "start": "654079",
    "end": "660079"
  },
  {
    "text": "examples this was a talk yesterday about distributed arocache for distributed ML",
    "start": "660079",
    "end": "665519"
  },
  {
    "text": "training so what it is is very exciting project so what we basically have done within the community we connected those",
    "start": "665519",
    "end": "673120"
  },
  {
    "text": "data libraries data fusion Apache arrow and iceberg and we bring them to kubernetes so the thing is like this is",
    "start": "673120",
    "end": "680399"
  },
  {
    "text": "exciting work we're going to give another demo today in the Qflow booth at 1 p.m about it but the goal is for us to",
    "start": "680399",
    "end": "686480"
  },
  {
    "text": "actually create a distributed cache on Kubernetes which allows us to distribute streaming for the PyTorch so basically",
    "start": "686480",
    "end": "692720"
  },
  {
    "text": "we kind of converting the arrow format from uh from iceberg all the way to the PyTorch tensors which basically allows",
    "start": "692720",
    "end": "699680"
  },
  {
    "text": "to do zero copy translation we see a lot of improvements we're constantly doing benchmarks we're going to propose it to",
    "start": "699680",
    "end": "705040"
  },
  {
    "text": "the Qul community relatively soon so please join us in the booth if you want to see the demo it's like one of the most exciting work going on right now",
    "start": "705040",
    "end": "712240"
  },
  {
    "text": "going next so Jennai so as I mentioned before in the panel and many of us actually know right now we try to see",
    "start": "712240",
    "end": "718800"
  },
  {
    "text": "how we can simplify cubeflow for ML users specifically data scientists and ML engineers so this is like one of the",
    "start": "718800",
    "end": "726320"
  },
  {
    "text": "really exciting work coming in so we try to provide unifi SDK which can allow data scientists to quickly process their",
    "start": "726320",
    "end": "732880"
  },
  {
    "text": "data train them and optimize and everything in a single Python interface so they don't even need to know anything",
    "start": "732880",
    "end": "739279"
  },
  {
    "text": "about Kubernetes so what we learn from our users they want to still leverage Kubernetes to scale but they don't want",
    "start": "739279",
    "end": "744639"
  },
  {
    "text": "to learn Kubernetes so Kubernetes kind of abstracted the way they don't even need to understand coupube cuttle or",
    "start": "744639",
    "end": "750320"
  },
  {
    "text": "docker or yaml kubernetes they just focus on pytorch which they run it and then scale it exciting work coming in",
    "start": "750320",
    "end": "756240"
  },
  {
    "text": "new working group ML experience we are happy to announce it it will be in the cubeflow community if you want to join",
    "start": "756240",
    "end": "761839"
  },
  {
    "text": "please check this um proposal in the community one of the also exciting",
    "start": "761839",
    "end": "767600"
  },
  {
    "text": "things about Qflow SDK we collaborate with llama community because I think as as you can see during the session Qflow",
    "start": "767600",
    "end": "774000"
  },
  {
    "text": "kind of provide the end toend ecosystem for uh genera at scale and we right now",
    "start": "774000",
    "end": "780240"
  },
  {
    "text": "try to stitch llama pieces and Qflow together so folks who actually using llama in production they can leverage",
    "start": "780240",
    "end": "786560"
  },
  {
    "text": "the Qflow tools so quickly build agents do post training do evaluations using the existing tools so all of us not",
    "start": "786560",
    "end": "793200"
  },
  {
    "text": "going to reinvent the wheel um all of also exciting things about this torch",
    "start": "793200",
    "end": "798320"
  },
  {
    "text": "tune thing so with SDK initiative we collaborate with torch tune community to create this uh fine-tuning experience",
    "start": "798320",
    "end": "805120"
  },
  {
    "text": "experience when basically the designers can simply use one train API with pre-built trainers which we kind of",
    "start": "805120",
    "end": "812079"
  },
  {
    "text": "pre-create and all the thing they need to do just need to as you can mentioned trainer has a concept of runtime so we",
    "start": "812079",
    "end": "817600"
  },
  {
    "text": "create a runtime where they can just pass it in their Python script and this runtime has entire utilization for uh",
    "start": "817600",
    "end": "823760"
  },
  {
    "text": "data sets modelization and it has distributed training so extremely powerful we're leveraging Kubernetes for",
    "start": "823760",
    "end": "829639"
  },
  {
    "text": "orchestration leveraging torch tune for uh PyTorch fine-tuning so we don't need to again uh redo the same things all",
    "start": "829639",
    "end": "836880"
  },
  {
    "text": "over and over over again and all of this and Jon will give a demo about end to engine experience so all this allows us",
    "start": "836880",
    "end": "843360"
  },
  {
    "text": "to construct the entire pipeline using the pure Python interfaces so we have process data with spark we have training",
    "start": "843360",
    "end": "850320"
  },
  {
    "text": "with uh Qflow trainer we have a serving with Korf and all this constructing end to end GNI pipeline which again uh Jon",
    "start": "850320",
    "end": "857440"
  },
  {
    "text": "will mention about in this session and it's super exciting and it's great experience for data scientists so they",
    "start": "857440",
    "end": "862639"
  },
  {
    "text": "can quickly do iteration at scale uh with leveraging all those advanced tools community working with uh so I will pass",
    "start": "862639",
    "end": "870079"
  },
  {
    "text": "it to you so you can speak at model registry thank you Anjie so um machine learning life cycle",
    "start": "870079",
    "end": "877920"
  },
  {
    "text": "and AI life cycles are very complicated so you can train the model tune your",
    "start": "877920",
    "end": "883120"
  },
  {
    "text": "model experiment with notebooks and everything right how do we track everything right so the Kufra model",
    "start": "883120",
    "end": "889760"
  },
  {
    "text": "registry was a project donated from Red Hat to help users manage and version",
    "start": "889760",
    "end": "895440"
  },
  {
    "text": "models and their metadata throughout the machine learning life cycle it fills a gap between model",
    "start": "895440",
    "end": "902560"
  },
  {
    "text": "experimentation and production activities and provides an central interface for all stakeholders in the",
    "start": "902560",
    "end": "910160"
  },
  {
    "text": "machine machine learning life cycle to collaborate on machine learning models",
    "start": "910160",
    "end": "916240"
  },
  {
    "text": "so some updates from the model registry projects so we introduced the model registry UI uh so that's pretty neat and",
    "start": "916240",
    "end": "924320"
  },
  {
    "text": "it's uh much easier to use now besides uh the backend APIs uh and CIS right so",
    "start": "924320",
    "end": "930800"
  },
  {
    "text": "with UI you can easily just click around and upload your models and uh do all",
    "start": "930800",
    "end": "936240"
  },
  {
    "text": "sorts of things so it you can register models easily and yeah we also have",
    "start": "936240",
    "end": "941600"
  },
  {
    "text": "updates to integrate with custom storage initializers as well so that it can work",
    "start": "941600",
    "end": "946800"
  },
  {
    "text": "well with Kserve and other projects so there are other minor features and bug fixes along the",
    "start": "946800",
    "end": "953240"
  },
  {
    "text": "way and once you have the model right how do you serve it so case of comes",
    "start": "953240",
    "end": "958639"
  },
  {
    "text": "into play in this machine learning life cycle uh to serve your models so what is",
    "start": "958639",
    "end": "964160"
  },
  {
    "text": "Kserve kserve is a highly scalable standard and cloud agnostic model serving an inference platform on",
    "start": "964160",
    "end": "971079"
  },
  {
    "text": "Kubernetes note that it's is not only for predictive AI but also for generative AI as",
    "start": "971079",
    "end": "979199"
  },
  {
    "text": "well some updates from the queso perspective uh so we added the integration with envoy AI gateway that",
    "start": "979320",
    "end": "986720"
  },
  {
    "text": "provides support for multiple RM providers and tokenbased read limiting",
    "start": "986720",
    "end": "992800"
  },
  {
    "text": "and routing with traffic shaping uh fallback and load balancing and so on so",
    "start": "992800",
    "end": "998320"
  },
  {
    "text": "we've also improved the autoscaling capabilities for large model use cases",
    "start": "998320",
    "end": "1003920"
  },
  {
    "text": "so that you can use um uh you can do like autoscaling based on custom metrics",
    "start": "1003920",
    "end": "1009600"
  },
  {
    "text": "uh this is through the ka integration with queso and we've also added the model caching capability uh through PV",
    "start": "1009600",
    "end": "1017040"
  },
  {
    "text": "and PVC so that you don't have to download the model uh um uh again for",
    "start": "1017040",
    "end": "1023440"
  },
  {
    "text": "dur especially if the model is large uh and it takes time for uh to spin up the",
    "start": "1023440",
    "end": "1029280"
  },
  {
    "text": "model during autoscaling and we've also improved the RM serving runtimes so we've added the",
    "start": "1029280",
    "end": "1036558"
  },
  {
    "text": "multiode inference support through VRM server Uh so we'll continue working with the",
    "start": "1036559",
    "end": "1041600"
  },
  {
    "text": "VRM community to improve uh the uh the VRM serving runtime so we and we also",
    "start": "1041600",
    "end": "1048240"
  },
  {
    "text": "added support for uh gateway API integration so uh to especially",
    "start": "1048240",
    "end": "1054799"
  },
  {
    "text": "specifically for the raw deployment mode so that you can uh use it to uh use both",
    "start": "1054799",
    "end": "1060720"
  },
  {
    "text": "ETL and envoy gateway as your uh gateway implementation",
    "start": "1060720",
    "end": "1066880"
  },
  {
    "text": "next I'll pass it to Jonno",
    "start": "1066880",
    "end": "1071400"
  },
  {
    "text": "yeah you would have heard about all the components here so Qflow pipelines is the last one which is stitching all",
    "start": "1072640",
    "end": "1078240"
  },
  {
    "text": "these components together so if you want to orchestrate the entire workflow in a DAG or a graph uh pipelines can stitch",
    "start": "1078240",
    "end": "1085039"
  },
  {
    "text": "together i'll show in the coming demo so I'll just go with the demo i",
    "start": "1085039",
    "end": "1090160"
  },
  {
    "text": "think this will make things clear um so we'll take a a minimal uh example here",
    "start": "1090160",
    "end": "1097200"
  },
  {
    "text": "uh in the interest of time so we'll take a hugging face gemma 3 1 billion model",
    "start": "1097200",
    "end": "1102240"
  },
  {
    "text": "which is a very lightweight a small model which got released uh a week ago",
    "start": "1102240",
    "end": "1107559"
  },
  {
    "text": "um and the idea is to create a fine-tuned model for reasoning so you",
    "start": "1107559",
    "end": "1112720"
  },
  {
    "text": "would have heard about reasoning the idea is to in understand how your the",
    "start": "1112720",
    "end": "1117840"
  },
  {
    "text": "inference output is obtained right using gRPO um using the unsloth library um so",
    "start": "1117840",
    "end": "1124320"
  },
  {
    "text": "that uh the idea is to use the Qflow trainer for doing the finetuning and once we have the finetune model use case",
    "start": "1124320",
    "end": "1131919"
  },
  {
    "text": "for the final inference and the whole thing is stitched uh within the Qflow",
    "start": "1131919",
    "end": "1138720"
  },
  {
    "text": "pipelines so here is the uh default uh",
    "start": "1141720",
    "end": "1146880"
  },
  {
    "text": "Qflow dashboard so we have uh default user which is the Qflow user um you",
    "start": "1146880",
    "end": "1152880"
  },
  {
    "text": "could and this is based on the profiles so you can switch between profiles if you have um uh permissions to do that so",
    "start": "1152880",
    "end": "1160480"
  },
  {
    "text": "this is a multi-tenent system where you log in as a user and you can being an admin you can always switch to other",
    "start": "1160480",
    "end": "1165919"
  },
  {
    "text": "profiles so on the left whatever you are seeing are keyflow components um and uh",
    "start": "1165919",
    "end": "1172640"
  },
  {
    "text": "the notebooks a cat pipelines you would have heard about all of that and in u if you go to notebooks u",
    "start": "1172640",
    "end": "1181679"
  },
  {
    "text": "you could create jupyter notebooks or uh r studio whatever runtime that you need",
    "start": "1181679",
    "end": "1187360"
  },
  {
    "text": "and specify resources for example right and add storage and do do your",
    "start": "1187360",
    "end": "1192799"
  },
  {
    "text": "experimentation in the very first",
    "start": "1192799",
    "end": "1196480"
  },
  {
    "text": "For Katib you could add hyperparameter tuner optimization um with various",
    "start": "1199120",
    "end": "1204160"
  },
  {
    "text": "algorithms with your target and the objectives that you actually want to have for your pipelines you can create",
    "start": "1204160",
    "end": "1211120"
  },
  {
    "text": "an experiment and associate runs so run is a single workflow execution you can imagine this to be like multiple runs",
    "start": "1211120",
    "end": "1217039"
  },
  {
    "text": "within your organization running graphs multiple times based on your requirement so let's go to the LLM ops part using Q",
    "start": "1217039",
    "end": "1225280"
  },
  {
    "text": "for pipelines i have a notebook here um which which is already",
    "start": "1225280",
    "end": "1231080"
  },
  {
    "text": "created going into the notebook which where I have a few fine-tuning uh Jupyter",
    "start": "1231080",
    "end": "1236840"
  },
  {
    "text": "notebook installed KFP which is the Kfl pipelines",
    "start": "1236840",
    "end": "1242159"
  },
  {
    "text": "SDK used uh hugging face token for downloading um the gated model from",
    "start": "1245240",
    "end": "1250960"
  },
  {
    "text": "hugging face which is a jamaat 3 model so the idea is to wrap your training",
    "start": "1250960",
    "end": "1256960"
  },
  {
    "text": "code if you have in in the current experiment we are using a custom trainer",
    "start": "1256960",
    "end": "1262240"
  },
  {
    "text": "so it is up to you if you if you want to have a default experiment you could use a torch tune which we talked about it",
    "start": "1262240",
    "end": "1267760"
  },
  {
    "text": "sometime later um so use torch tune if you want your library to take it",
    "start": "1267760",
    "end": "1273200"
  },
  {
    "text": "entirely from uh start the start to end or you could use if you have a custom code wrap it within your uh DSL",
    "start": "1273200",
    "end": "1281200"
  },
  {
    "text": "component of KFP pipeline and it will take care of that so here I'm using an slot library here um where I specify the",
    "start": "1281200",
    "end": "1289440"
  },
  {
    "text": "model name and if you know GRPO the idea is to create reward functions so um the",
    "start": "1289440",
    "end": "1296320"
  },
  {
    "text": "better the better the output you reward more it will get the output will get aligned to the direction that we are",
    "start": "1296320",
    "end": "1302159"
  },
  {
    "text": "seeing if your output is bad you give negative rewards which is saying that like you have to tune more right that's",
    "start": "1302159",
    "end": "1308960"
  },
  {
    "text": "the GRPO so idea is to give more rewards when you are formatting and the answers",
    "start": "1308960",
    "end": "1314240"
  },
  {
    "text": "are right and give penalty when they are wrong right and that's a very simple one",
    "start": "1314240",
    "end": "1319679"
  },
  {
    "text": "um we'll share that so that like if you want to see what happens in the back",
    "start": "1319679",
    "end": "1325320"
  },
  {
    "text": "end so um all the reward functions are defined and we have the gRPO trainer",
    "start": "1325320",
    "end": "1332080"
  },
  {
    "text": "from unsloth um where we put all the hyperparameter tuning uh tuning options",
    "start": "1332080",
    "end": "1337200"
  },
  {
    "text": "so if you want kip to tune this that's also possible it's not shown in this demo but all the hyperparameters can be",
    "start": "1337200",
    "end": "1343600"
  },
  {
    "text": "tuned using kip and um and this is the main part",
    "start": "1343600",
    "end": "1349120"
  },
  {
    "text": "right uh I'm using the train function of the trainer so I've defined the the train function used the cubeflow trainer",
    "start": "1349120",
    "end": "1356640"
  },
  {
    "text": "to start training in a distributed manner so here if you see that this is a",
    "start": "1356640",
    "end": "1362159"
  },
  {
    "text": "core part right I'm saying I'm going to train this function on one node",
    "start": "1362159",
    "end": "1367600"
  },
  {
    "text": "with four CPUs 64 gig memory and one GPU right so just change number of nodes or",
    "start": "1367600",
    "end": "1374720"
  },
  {
    "text": "number of GPUs that you have in your cluster and it will automatically scale",
    "start": "1374720",
    "end": "1380039"
  },
  {
    "text": "up and I'm waiting for uh the job to get completed and once done um I delete the",
    "start": "1380039",
    "end": "1387520"
  },
  {
    "text": "job the second pipeline task here is the inference once I have a fine-tuned job I",
    "start": "1387520",
    "end": "1394880"
  },
  {
    "text": "will create a deployment from uh the finetuned job uh fine-tuned model that",
    "start": "1394880",
    "end": "1400080"
  },
  {
    "text": "is created from the previous task using case right and the whole pipeline um is",
    "start": "1400080",
    "end": "1406679"
  },
  {
    "text": "orchestrated using the Qflow pipelines where I create the DAG here i'm saying",
    "start": "1406679",
    "end": "1412320"
  },
  {
    "text": "that the training has to happen after the storage is provisioned and the serving has to happen after uh the",
    "start": "1412320",
    "end": "1418480"
  },
  {
    "text": "finetuning is complete and I'm triggering the fine-tuning",
    "start": "1418480",
    "end": "1427039"
  },
  {
    "text": "here so once the fine-tuning pipeline is created uh you could go to the pipeline",
    "start": "1430600",
    "end": "1436720"
  },
  {
    "text": "section the UI to see the progress so you would see a new run here which is",
    "start": "1436720",
    "end": "1442400"
  },
  {
    "text": "triggered here and see the DAG which got created right i created storage i have a",
    "start": "1442400",
    "end": "1447520"
  },
  {
    "text": "fine-tuning step which is happening right now and once that is completed it",
    "start": "1447520",
    "end": "1452559"
  },
  {
    "text": "goes to the serving step and there is a separate uh path which I have created for the",
    "start": "1452559",
    "end": "1458799"
  },
  {
    "text": "original model to just to uh do a comparison serving of the original",
    "start": "1458799",
    "end": "1464559"
  },
  {
    "text": "model so you could see logs and all the other the details within the UI itself",
    "start": "1467000",
    "end": "1472400"
  },
  {
    "text": "without looking anything from the Kubernetes side of things so the gpo finetuning happens right now so if you",
    "start": "1472400",
    "end": "1479760"
  },
  {
    "text": "see the pod you would see that there's a training pod which is created because we are using a single pod right now but you",
    "start": "1479760",
    "end": "1486880"
  },
  {
    "text": "can scale as per your requirements and uh you could see that the train job",
    "start": "1486880",
    "end": "1492559"
  },
  {
    "text": "which is a CD4 running the training right and it is in created uh",
    "start": "1492559",
    "end": "1498679"
  },
  {
    "text": "state and there's a base model which which got created and that's the reason I'm seeing uh inference service from the",
    "start": "1498679",
    "end": "1506120"
  },
  {
    "text": "base so once it is complete you could see that the training",
    "start": "1506120",
    "end": "1511760"
  },
  {
    "text": "part gets into the completed state and the bottommost part was the part for",
    "start": "1511760",
    "end": "1517520"
  },
  {
    "text": "serving so the finetuned model was job was created completed and then it went",
    "start": "1517520",
    "end": "1522720"
  },
  {
    "text": "to the serving state so you could see that in the UI",
    "start": "1522720",
    "end": "1529200"
  },
  {
    "text": "itself all the steps are complete and I'm ready for inferencing",
    "start": "1529200",
    "end": "1535400"
  },
  {
    "text": "and you you could also see the same thing uh all the case of related uh",
    "start": "1537039",
    "end": "1542320"
  },
  {
    "text": "endpoint details from the case of tab there to see uh what endpoints are and",
    "start": "1542320",
    "end": "1547679"
  },
  {
    "text": "how to send requests to",
    "start": "1547679",
    "end": "1550880"
  },
  {
    "text": "that just to highlight here so we used GRPO trainer so you could also see that",
    "start": "1557960",
    "end": "1563840"
  },
  {
    "text": "the rewards are getting better so which actually means the finetuning is happening so we did that for limited",
    "start": "1563840",
    "end": "1569200"
  },
  {
    "text": "steps in the interest of time but your rewards are getting better so if you do",
    "start": "1569200",
    "end": "1574400"
  },
  {
    "text": "it for longer time you would get much aligned results based on your requirements",
    "start": "1574400",
    "end": "1582279"
  },
  {
    "text": "so you could get the uh infraside metrics as well and we are ready for the final inference so I I'm asking a",
    "start": "1589120",
    "end": "1596320"
  },
  {
    "text": "question what is the area of triangle for length 344 right and I'm sending",
    "start": "1596320",
    "end": "1602000"
  },
  {
    "text": "request to the hosted endpoint by ker and you could see that the model is",
    "start": "1602000",
    "end": "1608320"
  },
  {
    "text": "trying to reason right like from the site length that we have it is trying to",
    "start": "1608320",
    "end": "1614559"
  },
  {
    "text": "figure out what's the solution possible solution that I have so the in a in a",
    "start": "1614559",
    "end": "1620240"
  },
  {
    "text": "normal sense you would see the final answer the area of triangle is 3 uh",
    "start": "1620240",
    "end": "1626360"
  },
  {
    "text": "55x4 and between the start working out sessions you would see how this is",
    "start": "1626360",
    "end": "1632200"
  },
  {
    "text": "obtained that's the whole demo",
    "start": "1632200",
    "end": "1637080"
  },
  {
    "text": "all right so I have two minutes to summarize everything but doing my best but uh well thank you so much for",
    "start": "1640559",
    "end": "1646799"
  },
  {
    "text": "staying with us on this uh we have great news great news so we have released Qflow 1 uh here at QC con a couple of",
    "start": "1646799",
    "end": "1656000"
  },
  {
    "text": "days ago so kudos to the team and everyone who contribute thank you so much uh but yeah we have many great",
    "start": "1656000",
    "end": "1662960"
  },
  {
    "text": "things uh so we talk about the UI already we are also bringing efficiency",
    "start": "1662960",
    "end": "1668559"
  },
  {
    "text": "and optimization and user experience with training operator distributed track support also uh we talked already about",
    "start": "1668559",
    "end": "1675679"
  },
  {
    "text": "Katy so we'll skip it but also for uh Qflow pipelines we are doing many improvements to allow you from user",
    "start": "1675679",
    "end": "1682480"
  },
  {
    "text": "experience but also efficiency to control like resource uh limits management in the pipeline but also for",
    "start": "1682480",
    "end": "1690320"
  },
  {
    "text": "um controlling the limits in into the loop parallelism so you can control the whole uh pipeline uh the whole loop",
    "start": "1690320",
    "end": "1698919"
  },
  {
    "text": "execution so the other thing we have is also a spark operator is now part of",
    "start": "1698919",
    "end": "1705120"
  },
  {
    "text": "Qflow and we are working hard on security so we have done CVS reductions",
    "start": "1705120",
    "end": "1710640"
  },
  {
    "text": "but also we are looking into all components and looking into improving uh security best practices uh this is the",
    "start": "1710640",
    "end": "1717919"
  },
  {
    "text": "road map so just really quick again we are looking into uh many things from uh",
    "start": "1717919",
    "end": "1723279"
  },
  {
    "text": "gen AI inference support from KER we talk about trainer user experience",
    "start": "1723279",
    "end": "1729279"
  },
  {
    "text": "pipeline security upgrades and ex continue in increasing the experience",
    "start": "1729279",
    "end": "1734960"
  },
  {
    "text": "and also a storage integration for model registry but what is exciting is really",
    "start": "1734960",
    "end": "1742000"
  },
  {
    "text": "about what this community is about and it's about we are working towards",
    "start": "1742000",
    "end": "1747600"
  },
  {
    "text": "graduation right now so it's a really exciting time if in our community and",
    "start": "1747600",
    "end": "1753039"
  },
  {
    "text": "everything around AI so what we are doing is also all the working groups are coming together to build new work new",
    "start": "1753039",
    "end": "1760399"
  },
  {
    "text": "working groups that we can work across the different components by bringing like data uh focuses on data and and",
    "start": "1760399",
    "end": "1768240"
  },
  {
    "text": "also use better user experience across all those components so the great thing about the all of these is that we are a",
    "start": "1768240",
    "end": "1775760"
  },
  {
    "text": "community that evolves that brings new idea and you can be part of it so if you have ideas about any proposal so feel",
    "start": "1775760",
    "end": "1782799"
  },
  {
    "text": "free to submit it on any of these links the other thing that we are working on is in our outreach committee so we do",
    "start": "1782799",
    "end": "1789919"
  },
  {
    "text": "need help on this so please help us join us uh we are working also on Helmchart",
    "start": "1789919",
    "end": "1795760"
  },
  {
    "text": "so the idea is how we can make our uh deployment process for Qflow more easy",
    "start": "1795760",
    "end": "1801679"
  },
  {
    "text": "for you by bringing the homes into the picture for Qflow the manifest projects",
    "start": "1801679",
    "end": "1806960"
  },
  {
    "text": "and all the components but also fees for example who's been an add-on the F",
    "start": "1806960",
    "end": "1812159"
  },
  {
    "text": "community uh proposed to donate the uh as a feature store to the Qflow",
    "start": "1812159",
    "end": "1818919"
  },
  {
    "text": "ecosystem so the last things I want to invite you to join our community this QR",
    "start": "1818919",
    "end": "1825039"
  },
  {
    "text": "code you can join uh this is our Slack",
    "start": "1825039",
    "end": "1830600"
  },
  {
    "text": "yeah we also have meetings our meetings are amazing so each working group uh",
    "start": "1831200",
    "end": "1837360"
  },
  {
    "text": "meets and talks and discuss discuss things uh so you can be part of that we",
    "start": "1837360",
    "end": "1842559"
  },
  {
    "text": "are really looking forward to you know decide the future of of QFlow and AI so",
    "start": "1842559",
    "end": "1847600"
  },
  {
    "text": "let's do it together join our meetings uh this QR code will give you more",
    "start": "1847600",
    "end": "1853000"
  },
  {
    "text": "information uh the other thing is the Qflow community call is the best way and",
    "start": "1853000",
    "end": "1858320"
  },
  {
    "text": "the best path uh sorry the best way where you can start joining our",
    "start": "1858320",
    "end": "1863960"
  },
  {
    "text": "community get involved uh we have many social channels as well where you can",
    "start": "1863960",
    "end": "1869039"
  },
  {
    "text": "follow us and also we had many adopters i don't know if you saw the keynote yesterday was amazing so please join us",
    "start": "1869039",
    "end": "1877919"
  },
  {
    "text": "and we also have a survey so we want to hear from you about your experience with Qflow maybe you are a new adopter maybe",
    "start": "1877919",
    "end": "1886240"
  },
  {
    "text": "you are evaluating we want to hear from you because we will help it will help us to really start shaping shaping the",
    "start": "1886240",
    "end": "1892799"
  },
  {
    "text": "future looking in how what are the things that we can improve and we want to do it with you you are our community",
    "start": "1892799",
    "end": "1898720"
  },
  {
    "text": "so we really want to hear from you and with that this is my last slide uh just a quick question how many of you are",
    "start": "1898720",
    "end": "1905360"
  },
  {
    "text": "data scientists here today",
    "start": "1905360",
    "end": "1909559"
  },
  {
    "text": "okay how many of you are AI engineers how many of you are platform",
    "start": "1910799",
    "end": "1917399"
  },
  {
    "text": "engineers okay great thank you so much please connect with us thank you",
    "start": "1917399",
    "end": "1924799"
  },
  {
    "text": "thank you feel free to ask any questions after the session looking forward to speak with all of you and please join us",
    "start": "1924799",
    "end": "1929840"
  },
  {
    "text": "let's not reinvent the wheel let's build things together so thank you everyone",
    "start": "1929840",
    "end": "1935360"
  }
]
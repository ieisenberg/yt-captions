[
  {
    "start": "0",
    "end": "72000"
  },
  {
    "text": "all right well i would like to begin this session um and the goal here is to do a deep",
    "start": "320",
    "end": "6000"
  },
  {
    "text": "dive into the open telemetry metrics system um i was asked to give this talk uh by",
    "start": "6000",
    "end": "11200"
  },
  {
    "text": "the organizers and they suggested that it would be a good idea to have a conversation a year ago we did this",
    "start": "11200",
    "end": "17119"
  },
  {
    "text": "um earlier on in our open telemetry project and had a similar presentation here",
    "start": "17119",
    "end": "23600"
  },
  {
    "text": "where liz from honeycomb spoke with me for an hour about the metrics api and it was",
    "start": "23600",
    "end": "28720"
  },
  {
    "text": "really helpful to have outsiders and insiders talking with me about it as we went",
    "start": "28720",
    "end": "34160"
  },
  {
    "text": "so we're going to do that again and i have with me shelby and justin shelby is at honeycomb and has agreed to",
    "start": "34160",
    "end": "41600"
  },
  {
    "text": "be an eager participant in this session and then justin is at new relic and has been one of the",
    "start": "41600",
    "end": "47039"
  },
  {
    "text": "contributors especially working on our semantic conventions for the open telemetry system okay",
    "start": "47039",
    "end": "54879"
  },
  {
    "text": "i probably should introduce myself i'm an engineer at lightstep i've been working in observability for i",
    "start": "54879",
    "end": "60399"
  },
  {
    "text": "think about 15 years before lightstep i was at google and",
    "start": "60399",
    "end": "66159"
  },
  {
    "text": "have been involved in like tracing metrics and logging for a long time okay so the outline is there are three",
    "start": "66159",
    "end": "72799"
  },
  {
    "start": "72000",
    "end": "72000"
  },
  {
    "text": "parts here um going to start with what we were trying to achieve and what we're after in this project because we're not done",
    "start": "72799",
    "end": "78799"
  },
  {
    "text": "it's it's underway um and we'll talk about the sort of timeline we that we think we have",
    "start": "78799",
    "end": "84000"
  },
  {
    "text": "um the bulk of this sort of slide deck is talking about data model and the things we discovered when we",
    "start": "84000",
    "end": "89759"
  },
  {
    "text": "tried to combine a prometheus system with a statistic system",
    "start": "89759",
    "end": "95280"
  },
  {
    "text": "with a tracing system what happened and then lastly we're going to talk about some of the ways you can configure this",
    "start": "95280",
    "end": "101280"
  },
  {
    "text": "thing that we've built the open telemetry metrics which includes both sdks and the collector",
    "start": "101280",
    "end": "106560"
  },
  {
    "text": "and all the various protocols that we have at our disposal okay apologize for anybody visually",
    "start": "106560",
    "end": "114880"
  },
  {
    "start": "113000",
    "end": "113000"
  },
  {
    "text": "impaired i'm better at drawing slides than i am at making them on the computer so i've scanned a bunch of um",
    "start": "114880",
    "end": "120399"
  },
  {
    "text": "hand drawings for this uh deck and um hopefully uh you can follow along and",
    "start": "120399",
    "end": "126799"
  },
  {
    "text": "read my writing um i'm trying to sort of start by saying who this is for i want to attract",
    "start": "126799",
    "end": "132480"
  },
  {
    "text": "like an audience to talk about metrics now so i think we can basically agree that there are many different participants in the in the",
    "start": "132480",
    "end": "138959"
  },
  {
    "text": "in this type of community we have people who are trying to configure telemetry in diagnostics for their platforms for",
    "start": "138959",
    "end": "145440"
  },
  {
    "text": "their for their for their companies or their where they work there are engineers who are actually writing instrumentation and",
    "start": "145440",
    "end": "150879"
  },
  {
    "text": "software at those companies trying to make more observability and better diagnostics for themselves and then there are actually users who",
    "start": "150879",
    "end": "157040"
  },
  {
    "text": "are trying to understand why is my system broken why can't i you know log into my my machine or whatever",
    "start": "157040",
    "end": "162720"
  },
  {
    "text": "so these three different groups have kind of different perspectives on the problem space and um we end up",
    "start": "162720",
    "end": "168720"
  },
  {
    "text": "thinking about what each of them wants as we um talk through this problem space",
    "start": "168720",
    "end": "174080"
  },
  {
    "text": "okay ultimately the goal is to get some dashboards or some other form of alerting or monitoring on your data and",
    "start": "174080",
    "end": "180560"
  },
  {
    "text": "that looks something like this drawing that i made here on the right um this next diagram comes straight out of",
    "start": "180560",
    "end": "186720"
  },
  {
    "start": "184000",
    "end": "184000"
  },
  {
    "text": "the open telemetry library guidelines this was put together in the very early days of the project basically seeing",
    "start": "186720",
    "end": "191760"
  },
  {
    "text": "what we're after as far as the project as a whole one of the things that we wanted to do is build",
    "start": "191760",
    "end": "196800"
  },
  {
    "text": "a neutral system so that you could as a as a developer decide to use open telemetry without locking yourself",
    "start": "196800",
    "end": "203040"
  },
  {
    "text": "into somebody's sdk or some some vendors system so what that means is that we've created",
    "start": "203040",
    "end": "208799"
  },
  {
    "text": "an api separation from the sdk it means our interfaces are decoupled",
    "start": "208799",
    "end": "214159"
  },
  {
    "text": "from our implementations and this means that you can swap in another sdk or some alternate implementation later",
    "start": "214159",
    "end": "221920"
  },
  {
    "text": "um so the the diagram has here your your application code running",
    "start": "221920",
    "end": "227120"
  },
  {
    "text": "sorry um and then it goes into this sort of green box which combines both the api",
    "start": "227120",
    "end": "232720"
  },
  {
    "text": "that's the spec that we've put together for how you interact with metrics as well as the sdk which is the default",
    "start": "232720",
    "end": "238879"
  },
  {
    "text": "implementation that all the open telemetry libraries are going to include and together this should provide you a high",
    "start": "238879",
    "end": "245439"
  },
  {
    "text": "performance pipeline and you will then configure an exporter for the protocol that you want",
    "start": "245439",
    "end": "250720"
  },
  {
    "text": "so that you can expose your data in to the system that you want to",
    "start": "250720",
    "end": "256959"
  },
  {
    "text": "so josh is how much how much more effort is it to use something um to use the open telemetry setup",
    "start": "256959",
    "end": "263600"
  },
  {
    "text": "versus some of the vendor neutral um integration or the vendor-specific integrations that",
    "start": "263600",
    "end": "269199"
  },
  {
    "text": "people may be used to um i'm not exactly sure which vendor",
    "start": "269199",
    "end": "275360"
  },
  {
    "text": "integrations you might be thinking of um so some",
    "start": "275360",
    "end": "280720"
  },
  {
    "text": "say sdks come in with a bunch of built-in metrics for say your platform so you start using this library and you",
    "start": "280720",
    "end": "286240"
  },
  {
    "text": "get host metrics by out of the box you get kubernetes metrics out of the box um this is something that the open geometry",
    "start": "286240",
    "end": "292880"
  },
  {
    "text": "system will include um so automatic metrics as much as possible are going to be included for you",
    "start": "292880",
    "end": "298000"
  },
  {
    "text": "and um i've really structured this talk cut to leave sort of the details that you as a programmer might want to know to write",
    "start": "298000",
    "end": "304479"
  },
  {
    "text": "your own metrics it's really not the most important part of this topic this talk because what we're really trying to do is help you",
    "start": "304479",
    "end": "309919"
  },
  {
    "text": "set up an ecosystem help you set up a collector and an export pipeline very few engineers actually write custom metrics",
    "start": "309919",
    "end": "316240"
  },
  {
    "text": "and so that's sort of the least important part of the top talk here gotcha thank you all right",
    "start": "316240",
    "end": "323280"
  },
  {
    "text": "so what's next here um uh one of the major requirements here is",
    "start": "323280",
    "end": "328400"
  },
  {
    "text": "that we are an open source project and and this at least at least from my perspective was one of the biggest",
    "start": "328400",
    "end": "333680"
  },
  {
    "text": "challenges of joining an open source project is now you don't work for a company anymore you kind of have your own um we have the",
    "start": "333680",
    "end": "340880"
  },
  {
    "text": "community to think about first and so this has been um a project that",
    "start": "340880",
    "end": "346560"
  },
  {
    "text": "that moves at the pace of the community because we're getting what the community wants so i've drawn a picture here of a kind of a",
    "start": "346560",
    "end": "352720"
  },
  {
    "text": "system that basically is a collection pipeline for both tracing and metrics data and we're trying to show that",
    "start": "352720",
    "end": "358560"
  },
  {
    "text": "this collection infrastructure is going to work with all the open source systems that you're already using because that",
    "start": "358560",
    "end": "364160"
  },
  {
    "text": "was one of our priorities",
    "start": "364160",
    "end": "367840"
  },
  {
    "text": "okay um one of the sources of our sort of most sophisticated requirements came from open census the open census system",
    "start": "370400",
    "end": "377360"
  },
  {
    "start": "371000",
    "end": "371000"
  },
  {
    "text": "is really what gave us the open telemetry project combined with open tracing so",
    "start": "377360",
    "end": "383360"
  },
  {
    "text": "the the open tracing side of that combination gave us that requirement about sdk separation from the api",
    "start": "383360",
    "end": "389919"
  },
  {
    "text": "what opencensus gave us was the requirement for a very high performance sdk",
    "start": "389919",
    "end": "395039"
  },
  {
    "text": "and the requirement to have that sdk be configurable and in metrics what that meant was the",
    "start": "395039",
    "end": "400319"
  },
  {
    "text": "ability to choose which metrics are going to be exported to choose which dimensions are going to be exported and they call that the views",
    "start": "400319",
    "end": "406639"
  },
  {
    "text": "api so all those requirements were given to us sort of at the starting point we need to have a better way to",
    "start": "406639",
    "end": "412639"
  },
  {
    "text": "configure which what happens when you use a metrics api",
    "start": "412639",
    "end": "418800"
  },
  {
    "text": "next it's not just about how do you record numbers um we need to make sure that the entire",
    "start": "420479",
    "end": "425840"
  },
  {
    "text": "problem is being solved so in addition to you creating your own application metrics you have plugins for",
    "start": "425840",
    "end": "432560"
  },
  {
    "text": "your host metrics you have plugins for your kubernetes metrics you have instrumentation for tracing",
    "start": "432560",
    "end": "438240"
  },
  {
    "text": "that is shared has shared resource attributes for your metrics and so we want to have specifications that tell",
    "start": "438240",
    "end": "445360"
  },
  {
    "text": "us exactly how you should label data in a standard way so that users will be able to find it and understand what",
    "start": "445360",
    "end": "451199"
  },
  {
    "text": "they're looking at and so this is really a task that bridges technical stuff",
    "start": "451199",
    "end": "456319"
  },
  {
    "text": "with kind of language stuff and understanding and questions about how we talk and what names we use",
    "start": "456319",
    "end": "462080"
  },
  {
    "text": "so this is an interesting sort of uh corner of the specification which is really about",
    "start": "462080",
    "end": "467280"
  },
  {
    "text": "language and terminology and understanding",
    "start": "467280",
    "end": "471918"
  },
  {
    "text": "um before i talk about data model and what you can do with this i want to be honest with you about the current",
    "start": "472960",
    "end": "479440"
  },
  {
    "text": "timeline we are um right now the open telemetry project is trying to finish",
    "start": "479440",
    "end": "485039"
  },
  {
    "text": "the tracing spec as and and and freeze that and make sure that we have a stable tracing environment",
    "start": "485039",
    "end": "490160"
  },
  {
    "text": "soon because of that attention being given to trace the metrics project has been slowed down a little bit",
    "start": "490160",
    "end": "495599"
  },
  {
    "text": "so we're kind of like putting our attention to tracing while we uh and waiting to finish metrics um but",
    "start": "495599",
    "end": "501199"
  },
  {
    "text": "there is also just a large number of moving parts in this problem space we have specifications which um we've",
    "start": "501199",
    "end": "507199"
  },
  {
    "text": "we've definitely finished the the for the most part we finished our api spec but the sdk specification is",
    "start": "507199",
    "end": "512399"
  },
  {
    "text": "probably going to be the last thing to finish because we have to actually implement this sdk in a bunch of different languages",
    "start": "512399",
    "end": "518000"
  },
  {
    "text": "and figure out what else needs to be answered but as far as um sort of the collector support that's",
    "start": "518000",
    "end": "524000"
  },
  {
    "text": "been sort of ahead of schedule because we have the open census collector already and a number of the integrations and the",
    "start": "524000",
    "end": "529519"
  },
  {
    "text": "receivers and exporters that you've heard about today were already in place for metrics so that's that's a little bit ahead and",
    "start": "529519",
    "end": "536320"
  },
  {
    "text": "then there's a few kind of lingering questions about data model and the protocol that",
    "start": "536320",
    "end": "541440"
  },
  {
    "text": "um are things that we may want to solve in the distant future we may not need to at all those are sort",
    "start": "541440",
    "end": "546720"
  },
  {
    "text": "of open questions um things uh questions about sort of the obscure corners of the world where you",
    "start": "546720",
    "end": "551839"
  },
  {
    "text": "might want to use the protocol for something different but for the most part we're getting close and we think that by the second",
    "start": "551839",
    "end": "557440"
  },
  {
    "text": "first half of next year you'll be able to use this for real awesome",
    "start": "557440",
    "end": "563200"
  },
  {
    "text": "okay i'm gonna start talking about data model now um before you do we have a couple",
    "start": "563200",
    "end": "568640"
  },
  {
    "start": "566000",
    "end": "566000"
  },
  {
    "text": "questions in the chat that i wanted to share so um raj has a question does the",
    "start": "568640",
    "end": "573680"
  },
  {
    "text": "sdk capture raw data at a time stamp or is there data aggregation processing in the sdk",
    "start": "573680",
    "end": "581120"
  },
  {
    "text": "right so i i do plan to talk a little bit about that later there is definitely that's one of those performance",
    "start": "581120",
    "end": "586480"
  },
  {
    "text": "requirements that we got from open census we need to have a high performance metrics library and we know that",
    "start": "586480",
    "end": "591839"
  },
  {
    "text": "the sort of gold standard at the the point when we started was prometheus libraries so prometheus libraries are organized in",
    "start": "591839",
    "end": "598160"
  },
  {
    "text": "such a way that your updates are very fast mainly because you're actually pinning memory to keep",
    "start": "598160",
    "end": "604160"
  },
  {
    "text": "you know a variable in place that you can update quickly so we're going to talk later on this",
    "start": "604160",
    "end": "609839"
  },
  {
    "text": "talk about something called aggregation temporality which lets us move that memory in our system but we're still going to",
    "start": "609839",
    "end": "615920"
  },
  {
    "text": "be able to aggregate in the process over short windows of time and output data that's been aggregated",
    "start": "615920",
    "end": "622160"
  },
  {
    "text": "before it leaves the process cool and yeah we'll go into that later",
    "start": "622160",
    "end": "628399"
  },
  {
    "text": "in your presentation and then the other question um that's been coming up a lot today",
    "start": "628399",
    "end": "633760"
  },
  {
    "text": "um i'm not sure if you're planning to talk about this a little bit more but um the relationship between openmetrics",
    "start": "633760",
    "end": "640640"
  },
  {
    "text": "and hotel or otlp yes that is absolutely going to be part of this presentation it's one of",
    "start": "640640",
    "end": "646959"
  },
  {
    "text": "the bigger questions that i have to answer and i hope that i will be able to answer that by the end of this presentation",
    "start": "646959",
    "end": "652720"
  },
  {
    "text": "great then i will get out of your way cool all right so i just want to start with",
    "start": "652720",
    "end": "658320"
  },
  {
    "text": "data model like this is a like what are we doing this is about metrics so i kind of want to bring us",
    "start": "658320",
    "end": "663920"
  },
  {
    "text": "all back to the top level which is we're trying to look at some numbers probably in a visual way",
    "start": "663920",
    "end": "669760"
  },
  {
    "text": "we may also be alerting and monitoring on them but the classic application for metrics is to create some charts",
    "start": "669760",
    "end": "675680"
  },
  {
    "text": "and put them on a dashboard so i want to talk through the different kinds of charts and dashboarding facilities that are",
    "start": "675680",
    "end": "682160"
  },
  {
    "text": "commonly available through metrics because there are different data types here so",
    "start": "682160",
    "end": "687519"
  },
  {
    "text": "um the next few slides are going to talk about your sort of typical charts that you might get out of",
    "start": "687519",
    "end": "692720"
  },
  {
    "text": "a metric system that's what we're after so first here is a count time series",
    "start": "692720",
    "end": "698160"
  },
  {
    "text": "what i'm calling a count time series is just that there's some counter and it's it's cumulative in the sense",
    "start": "698160",
    "end": "703839"
  },
  {
    "text": "that i've begin this counter at the start of my process and i may add to it i may subtract to it we haven't talked about monotonicity yet",
    "start": "703839",
    "end": "710639"
  },
  {
    "text": "but over time that total is kept as a sum and whatever value i'm looking at as a",
    "start": "710639",
    "end": "716959"
  },
  {
    "text": "function of time is the total cumulative count for that metric",
    "start": "716959",
    "end": "723040"
  },
  {
    "text": "this is going to come up a lot throughout this talk i use the we use the terms cumulative and delta",
    "start": "723040",
    "end": "728800"
  },
  {
    "text": "i'm going to use the greek letter sigma to refer to cumulative since it's a mathematical association we all have",
    "start": "728800",
    "end": "734880"
  },
  {
    "text": "and then you can imagine looking at the same data as a rate now this is one of the big",
    "start": "734880",
    "end": "741839"
  },
  {
    "text": "deals here in metrics is that you can often represent count or some data as either a rate or a total",
    "start": "741839",
    "end": "747519"
  },
  {
    "text": "and that's this comes this is one of the complications that we're going to have to deal with um because they have different",
    "start": "747519",
    "end": "753120"
  },
  {
    "text": "properties um but they're roughly speaking equivalent so when we talk about showing a rate it",
    "start": "753120",
    "end": "758800"
  },
  {
    "text": "is um going to be associated with what we call deltas you're reporting the change in",
    "start": "758800",
    "end": "764079"
  },
  {
    "text": "some quantity and then you're going to plot the change so this change could be um can is a number that can rise and",
    "start": "764079",
    "end": "770480"
  },
  {
    "text": "fall and if the number uh the count is not monotonic this change could actually be negative",
    "start": "770480",
    "end": "776399"
  },
  {
    "text": "so this is another way to talk about reporting some data um we also have this notion of a gauge",
    "start": "776399",
    "end": "783519"
  },
  {
    "text": "in the kind of traditional metrics interfaces and the data model here is a little different from um",
    "start": "783519",
    "end": "790720"
  },
  {
    "text": "sort of well what i'm trying to show with this visualization diagram here is that you may set a gauge many times",
    "start": "790720",
    "end": "797600"
  },
  {
    "text": "during an interval but what we commonly report when we're talking about gauges is the last value that was set",
    "start": "797600",
    "end": "803200"
  },
  {
    "text": "so although you have many points visualized in this in this graph only",
    "start": "803200",
    "end": "808480"
  },
  {
    "text": "the blue colored dots are the ones that are going to be actually reported so this is called last value",
    "start": "808480",
    "end": "814079"
  },
  {
    "text": "reporting we call this a gauge and it's interesting because we don't actually value or",
    "start": "814079",
    "end": "820399"
  },
  {
    "text": "keep information about every point in some sense the number of points is irrelevant here all we want to know is that there's a",
    "start": "820399",
    "end": "826959"
  },
  {
    "text": "signal we can evaluate it at a point in time and we often record just one value this",
    "start": "826959",
    "end": "832160"
  },
  {
    "text": "is a relatively inexpensive type of aggregation now we also have this thing we call",
    "start": "832160",
    "end": "837680"
  },
  {
    "text": "histograms or sometimes we call them distributions the idea is that here you have these individual measurements",
    "start": "837680",
    "end": "843519"
  },
  {
    "text": "and instead of just recording say the last value of one of those measurements we're going to somehow capture more",
    "start": "843519",
    "end": "848720"
  },
  {
    "text": "we're going to capture both account and the value so that we can speak independently about the count",
    "start": "848720",
    "end": "854639"
  },
  {
    "text": "and about the values so what i've drawn here now is a distribution on the top i've got red purple and blue",
    "start": "854639",
    "end": "861199"
  },
  {
    "text": "showing you quantiles so this might be p99 p50 p10 telling you where the",
    "start": "861199",
    "end": "866399"
  },
  {
    "text": "distribution of latency or some other value in your system is and then on the bottom i have",
    "start": "866399",
    "end": "871519"
  },
  {
    "text": "a rate plot which is showing for the same data set how many points were there",
    "start": "871519",
    "end": "876639"
  },
  {
    "text": "per unit of time so a histogram is sort of the most expensive type of metric data that we report because it includes",
    "start": "876639",
    "end": "883600"
  },
  {
    "text": "two independent pieces of information and we often use it to summarize a whole distribution",
    "start": "883600",
    "end": "889920"
  },
  {
    "text": "so these tend to be a little bit more expensive that the goal of those last four pages",
    "start": "889920",
    "end": "895440"
  },
  {
    "start": "894000",
    "end": "894000"
  },
  {
    "text": "there was to show you that there's something familiar and common that we are after even though this data model may feel confusing after",
    "start": "895440",
    "end": "901760"
  },
  {
    "text": "we start talking about it for a bit now as far as what's different in open",
    "start": "901760",
    "end": "908240"
  },
  {
    "text": "metrics and open telemetry this is the this is where it starts there's two pieces of the data model that are not",
    "start": "908240",
    "end": "913519"
  },
  {
    "text": "present in an open telemetry um system and i just want to say it's not because",
    "start": "913519",
    "end": "919760"
  },
  {
    "text": "they're missing it's because when you're pulling data in a metric system you don't need these features so the",
    "start": "919760",
    "end": "926000"
  },
  {
    "text": "first thing is resources resources are a concept for these key value attributes that we attach to our",
    "start": "926000",
    "end": "932320"
  },
  {
    "text": "diagnostics or our instrument or our observability data it's not just metrics this is also for spans and logs",
    "start": "932320",
    "end": "939199"
  },
  {
    "text": "so i use the term attributes for this key value association and the difference between what we've",
    "start": "939199",
    "end": "945440"
  },
  {
    "text": "got in openometry and what you have and say openmetrics is that this concept or resource is in",
    "start": "945440",
    "end": "950880"
  },
  {
    "text": "the protocol so that when you report a batch of metrics data you're going to have one section for resources",
    "start": "950880",
    "end": "956720"
  },
  {
    "text": "and then you're going to have a lot of metrics data inside that encapsulation and so this allows us to begin creating",
    "start": "956720",
    "end": "964079"
  },
  {
    "text": "common uh coordinates and telemetry between traces and and metrics because we have",
    "start": "964079",
    "end": "969199"
  },
  {
    "text": "standard resources and we can configure these export pipelines to attach standard resources to both our",
    "start": "969199",
    "end": "975920"
  },
  {
    "text": "traces and our metrics as they pass through the export pipeline so having resources is a first class concept",
    "start": "975920",
    "end": "982639"
  },
  {
    "text": "and then of course we have resource conventions for how you should name your resources i've shown one example here which is for",
    "start": "982639",
    "end": "988399"
  },
  {
    "text": "the service attribute namespace you've got service name service namespace service instance id and",
    "start": "988399",
    "end": "994079"
  },
  {
    "text": "service version we are suggesting that these sorts of attributes may be included with metric",
    "start": "994079",
    "end": "999199"
  },
  {
    "text": "data and then some point later you may have to export them into a system that doesn't have this concept of resources",
    "start": "999199",
    "end": "1005199"
  },
  {
    "text": "and we're going to have to talk about whether those resources are or are not attached as metric attributes",
    "start": "1005199",
    "end": "1011199"
  },
  {
    "text": "or sometimes these are called labels and tags we have a terminology problem there and try to avoid it for this talk",
    "start": "1011199",
    "end": "1016880"
  },
  {
    "text": "so so the first thing we're adding that's different from openmetrics is the concept of resources and they say that you don't need these",
    "start": "1016880",
    "end": "1023279"
  },
  {
    "text": "in a pull-based system because if you think about how prometheus works you scrape the target the target gives",
    "start": "1023279",
    "end": "1029038"
  },
  {
    "text": "you all of its own metric data including its own metric labels but it doesn't know its own resources",
    "start": "1029039",
    "end": "1035199"
  },
  {
    "text": "the whole point of scraping and a pull-based system is that you discover the targets you",
    "start": "1035199",
    "end": "1040720"
  },
  {
    "text": "scrape them and you know what their resources are so it's the person that pulls that data",
    "start": "1040720",
    "end": "1045918"
  },
  {
    "text": "who's responsible for attaching resources and that's why you didn't need it in open metrics",
    "start": "1045919",
    "end": "1051600"
  },
  {
    "text": "the other thing that's different in open telemetry compared with openmetrics is this notion that we have support for",
    "start": "1051600",
    "end": "1057840"
  },
  {
    "start": "1052000",
    "end": "1052000"
  },
  {
    "text": "temporality the word temporality is one that we um sort of made up it is a real word but",
    "start": "1057840",
    "end": "1063679"
  },
  {
    "text": "we're using it to refer to this distinction between delta and cumulative reporting",
    "start": "1063679",
    "end": "1069440"
  },
  {
    "text": "so um and i want to make a distinction between because we use this word in two senses here it's pretty important to the",
    "start": "1069440",
    "end": "1075280"
  },
  {
    "text": "design of the whole system so bear with me the idea that there's something called temporality",
    "start": "1075280",
    "end": "1080720"
  },
  {
    "text": "is trying to describe a relationship with time and when we report um metrics data they",
    "start": "1080720",
    "end": "1087200"
  },
  {
    "text": "may be cumulative or they may be delta generally speaking deltas mean that you're reporting differences since the last report and",
    "start": "1087200",
    "end": "1094320"
  },
  {
    "text": "every report is independent and does not build on the previous report we need to um so we're reporting changes",
    "start": "1094320",
    "end": "1101679"
  },
  {
    "text": "one after the other in cumulative reporting we're going to repeat report some total since the beginning of time",
    "start": "1101679",
    "end": "1107360"
  },
  {
    "text": "and we're going to keep re-reporting that total since the beginning of time okay why are we talking about this well",
    "start": "1107360",
    "end": "1116000"
  },
  {
    "text": "there's something here called instrument temporality which is what type of numbers does this instrument deal with and that's an api",
    "start": "1116480",
    "end": "1123440"
  },
  {
    "text": "question and there's something called aggregation temporality which is what is in the protocol that i'm putting through my",
    "start": "1123440",
    "end": "1129200"
  },
  {
    "text": "pipeline okay this is confusing i have another slide on it so why do we care",
    "start": "1129200",
    "end": "1134799"
  },
  {
    "start": "1131000",
    "end": "1131000"
  },
  {
    "text": "well the this choice is entirely about keeping state and stateful interactions betw out of",
    "start": "1134799",
    "end": "1140720"
  },
  {
    "text": "the sdk and the api for open telemetry so if you think about reporting say a total uh",
    "start": "1140720",
    "end": "1146960"
  },
  {
    "text": "your current memory usage you don't want to report your current memory usage as a delta because that",
    "start": "1146960",
    "end": "1152160"
  },
  {
    "text": "would require you to remember the last value that you reported for your current memory usage so therefore we find it's better",
    "start": "1152160",
    "end": "1158640"
  },
  {
    "text": "if you're reporting something like a current memory usage to report a current total and in the",
    "start": "1158640",
    "end": "1164000"
  },
  {
    "text": "system that we're going to have if you're reporting information from a callback you're generally going to report",
    "start": "1164000",
    "end": "1169120"
  },
  {
    "text": "totals if you're reporting something in a mean line code as part of a transaction or a request",
    "start": "1169120",
    "end": "1174960"
  },
  {
    "text": "you're going to report deltas so from the start we have this built into our instruments",
    "start": "1174960",
    "end": "1180240"
  },
  {
    "text": "and it's because we think it is more convenient to talk about deltas in some contexts and more convenient to",
    "start": "1180240",
    "end": "1185760"
  },
  {
    "text": "talk about totals in other contexts it keeps state out now the point of creating",
    "start": "1185760",
    "end": "1192240"
  },
  {
    "text": "this concept in aggregation this instrument sorry the point of creating instrument temporality is that we can adjust",
    "start": "1192240",
    "end": "1198799"
  },
  {
    "text": "aggregation temporality so what goes in is not necessarily what comes out and it turns out that if we have deltas",
    "start": "1198799",
    "end": "1204880"
  },
  {
    "text": "coming in and we want cumulatives coming out we're going to put memory so this is why",
    "start": "1204880",
    "end": "1209919"
  },
  {
    "text": "we have these questions there's a trade-off trade-off is between reliability",
    "start": "1209919",
    "end": "1215200"
  },
  {
    "text": "and memory costs uh there's going to be more on this",
    "start": "1215200",
    "end": "1220480"
  },
  {
    "text": "topic we will keep talking about this so um i need to so we're sort of",
    "start": "1220480",
    "end": "1227520"
  },
  {
    "start": "1223000",
    "end": "1223000"
  },
  {
    "text": "we're still talking about data model but we're trying now to integrate the concepts from prometheus and the",
    "start": "1227520",
    "end": "1232720"
  },
  {
    "text": "concepts from statsd because one of those systems uses cumulatives and one of those systems uses deltas",
    "start": "1232720",
    "end": "1239120"
  },
  {
    "text": "so however in the api for both of those systems counters use deltas",
    "start": "1239120",
    "end": "1245360"
  },
  {
    "text": "so both prometheus and stats you expect when you're using a counter that you will tell it a delta however",
    "start": "1245360",
    "end": "1251760"
  },
  {
    "text": "when prometheus writes data to its spread ahead log or exports data through its remote right",
    "start": "1251760",
    "end": "1256799"
  },
  {
    "text": "it's sending you cumulatives and so this is why prometheus has trouble with",
    "start": "1256799",
    "end": "1263280"
  },
  {
    "text": "cardinality it requires you to keep memory inside the client library for every",
    "start": "1263280",
    "end": "1268640"
  },
  {
    "text": "counter you've ever used because it has to track the cumulative value",
    "start": "1268640",
    "end": "1274159"
  },
  {
    "text": "in open telemetry we are giving you these instruments that have delta",
    "start": "1274159",
    "end": "1280159"
  },
  {
    "text": "instrument temporality counters and this this instrument that we call up down counter are for for inputting changes or deltas",
    "start": "1280159",
    "end": "1288240"
  },
  {
    "text": "to a sum so these are just like the prometheus concepts these are just like the statsd concept",
    "start": "1288240",
    "end": "1293440"
  },
  {
    "text": "except that we've given you two ones for monotonic counters and one's for non-monotonic counters",
    "start": "1293440",
    "end": "1300559"
  },
  {
    "text": "this is actually the simple case these are deltas now when we talk about gauges",
    "start": "1300559",
    "end": "1309520"
  },
  {
    "text": "i mentioned earlier in some of this breakout sessions that there's a little bit of a terminology problem and the i don't want to go too close to",
    "start": "1309520",
    "end": "1316640"
  },
  {
    "text": "the details here because i will lose you and you'll get bored but basically prometheus and statsy use the term gage",
    "start": "1316640",
    "end": "1322159"
  },
  {
    "text": "in slightly different ways and i've copied a definition out of wikipedia for the word gage itself",
    "start": "1322159",
    "end": "1327360"
  },
  {
    "text": "turns out that the actual word has two meanings in our actual engineering practice this is a confusing term to",
    "start": "1327360",
    "end": "1333200"
  },
  {
    "text": "begin with and it turns out because there's it's used differently in prometheus and statsd it's even more confusing we're trying",
    "start": "1333200",
    "end": "1339679"
  },
  {
    "text": "not to use it so the thing that you're using a gauge for however is a real application",
    "start": "1339679",
    "end": "1346080"
  },
  {
    "start": "1341000",
    "end": "1341000"
  },
  {
    "text": "in prometheus and statsd gauge got used whenever we wanted an individual",
    "start": "1346080",
    "end": "1351520"
  },
  {
    "text": "measurement but not the cost of a histogram so open telemetry um created a new",
    "start": "1351520",
    "end": "1357600"
  },
  {
    "text": "distinction to cover this gauge use case and it's when you're recording an individual measurement so",
    "start": "1357600",
    "end": "1365440"
  },
  {
    "text": "i'm going to talk more about what an individual measurement means but the point is that if you take a",
    "start": "1365440",
    "end": "1370799"
  },
  {
    "text": "measurement and there's something um so you say suppose you measure a latency you",
    "start": "1370799",
    "end": "1377440"
  },
  {
    "text": "would never add that measurement of latency to another measurement of latency just for the sake of adding those two",
    "start": "1377440",
    "end": "1384080"
  },
  {
    "text": "numbers together that is an individual measurement and you're interested in knowing individual latencies",
    "start": "1384080",
    "end": "1390000"
  },
  {
    "text": "so there's some so um when you when you use this value recorder instrument you're going to be computing a",
    "start": "1390000",
    "end": "1395840"
  },
  {
    "text": "distribution as opposed to computing a sum which is a much simpler operation and much cheaper operation",
    "start": "1395840",
    "end": "1402400"
  },
  {
    "text": "um i'm trying to explain why gauge doesn't exist and i think i'm getting a little confused or i'm not sure that people are following",
    "start": "1402400",
    "end": "1408799"
  },
  {
    "text": "you at me at this time because gage is a very confusing concept but what i'm trying to say here is that",
    "start": "1408799",
    "end": "1414720"
  },
  {
    "text": "we've replaced the concept of a gauge instrument with two new instruments one is",
    "start": "1414720",
    "end": "1420000"
  },
  {
    "text": "going to be called value recorder and one is called value observer we use value recorder to record",
    "start": "1420000",
    "end": "1425360"
  },
  {
    "text": "individual measurements we use value observer to witness an individual measurement such as a",
    "start": "1425360",
    "end": "1432400"
  },
  {
    "text": "callback observing a total",
    "start": "1432400",
    "end": "1435919"
  },
  {
    "text": "i'm afraid this slide is not going off but i'm going to keep going",
    "start": "1437520",
    "end": "1442399"
  },
  {
    "text": "the problem i'm trying to explain with gage is that sometimes they got used to record sums that were cumulative",
    "start": "1442880",
    "end": "1448320"
  },
  {
    "text": "or sums that were not monotonic and sometimes they were used to record sort of um other measurements such as a",
    "start": "1448320",
    "end": "1454880"
  },
  {
    "text": "temperature or a latency which is not something you ordinarily add together so the point is gauges got used",
    "start": "1454880",
    "end": "1461679"
  },
  {
    "text": "for several different things in each of these systems and we are trying to provide you",
    "start": "1461679",
    "end": "1466880"
  },
  {
    "text": "instruments that get used for exactly one thing if you're observing a sum or you're",
    "start": "1466880",
    "end": "1472080"
  },
  {
    "text": "observing a non-monotonic sum instead of using a gauge you're going to use one of these",
    "start": "1472080",
    "end": "1477919"
  },
  {
    "text": "new instruments called some observer or up down some observer and these are instruments that have",
    "start": "1477919",
    "end": "1482960"
  },
  {
    "text": "so-called cumulative instrument temporality we're going to keep talking about this",
    "start": "1482960",
    "end": "1488720"
  },
  {
    "text": "because you yes please shall we go back one slide um so when you say",
    "start": "1488720",
    "end": "1494480"
  },
  {
    "start": "1494000",
    "end": "1494000"
  },
  {
    "text": "monotonic just because i'm i might have missed that meaning at one point that's like a",
    "start": "1494480",
    "end": "1500320"
  },
  {
    "text": "something that's unrelated to the previous value right it's i may have confused you and i would",
    "start": "1500320",
    "end": "1506960"
  },
  {
    "text": "love to just completely reiterate this so i've used term deltas and cumulatives",
    "start": "1506960",
    "end": "1512640"
  },
  {
    "text": "like you just described this is about the relationship between a prior interval and the current",
    "start": "1512640",
    "end": "1518240"
  },
  {
    "text": "interval um as far as reporting count some values",
    "start": "1518240",
    "end": "1523520"
  },
  {
    "text": "the the the question about monotonicity is really about whether the function is always rising or always",
    "start": "1523520",
    "end": "1528880"
  },
  {
    "text": "following for example um i don't so the distinction is between sums that rise and fall versus",
    "start": "1528880",
    "end": "1534720"
  },
  {
    "text": "sums that only rise and when when we have a sum that only rises more often we're interested in showing",
    "start": "1534720",
    "end": "1541039"
  },
  {
    "text": "that as a rate but when we have a sum that rises and falls more often we are interested in showing that as a count",
    "start": "1541039",
    "end": "1546880"
  },
  {
    "text": "and so you're probably familiar with metrics interfaces having the ability to choose whether you're talking about a rate or a",
    "start": "1546880",
    "end": "1552240"
  },
  {
    "text": "count this is this is something that we're actually encoding in these instruments for open telemetry",
    "start": "1552240",
    "end": "1559120"
  },
  {
    "text": "so i can imagine like for um in a very lay example right age is always in",
    "start": "1559120",
    "end": "1565600"
  },
  {
    "text": "relation to the previous year you can always just say like age plus one right and that's my birthday it's",
    "start": "1565600",
    "end": "1571120"
  },
  {
    "text": "related to the previous year but for like temperature it's completely unrelated to the past yesterday's temperature",
    "start": "1571120",
    "end": "1577120"
  },
  {
    "text": "um you might you might say like you might your google alert says like oh it's going to be seven degrees colder",
    "start": "1577120",
    "end": "1582640"
  },
  {
    "text": "today but usually you just want the individual like today's temperature um yeah that's like that's a good",
    "start": "1582640",
    "end": "1588480"
  },
  {
    "text": "observation you don't ordinarily monitor changes in temperature you monitor absolute temperatures",
    "start": "1588480",
    "end": "1593679"
  },
  {
    "text": "but you might monitor something like that that is um being counted as a rate",
    "start": "1593679",
    "end": "1600720"
  },
  {
    "text": "and then you might monitor that as a change so um",
    "start": "1600720",
    "end": "1606799"
  },
  {
    "text": "yeah okay i i like using the very human examples but um it's it's",
    "start": "1607120",
    "end": "1612880"
  },
  {
    "text": "also helpful to have them i let your other examples of things like um",
    "start": "1612880",
    "end": "1618159"
  },
  {
    "text": "um cp usage right where you always want that at the particular moment you don't care how",
    "start": "1618159",
    "end": "1624320"
  },
  {
    "text": "you don't usually care how much that relates to like five minutes ago yeah i i like your example of using age",
    "start": "1624320",
    "end": "1630559"
  },
  {
    "text": "though it's a great one so you could imagine two ways of of monitoring you an age of a person",
    "start": "1630559",
    "end": "1635600"
  },
  {
    "text": "if you're if you use a counter then every year you increment it by one if you're using a sum observer then",
    "start": "1635600",
    "end": "1641360"
  },
  {
    "text": "every year you output your current age and that's always one more than the last year so and",
    "start": "1641360",
    "end": "1646720"
  },
  {
    "text": "we could talk more about the differences um we will talk more about the differences as one of the key aspects of",
    "start": "1646720",
    "end": "1652320"
  },
  {
    "text": "this design gotcha josh that's super helpful",
    "start": "1652320",
    "end": "1657840"
  },
  {
    "text": "justin please would you explain a little bit about why an instrumentation author shouldn't just",
    "start": "1657840",
    "end": "1664960"
  },
  {
    "text": "always use the up down sum observer when you could use it to record age as well right is there a good reason to",
    "start": "1664960",
    "end": "1670720"
  },
  {
    "text": "only use the sum observer in that case yes and i i'm i promise i tried to put a",
    "start": "1670720",
    "end": "1677520"
  },
  {
    "text": "aside about this actually it's the next one um so there has been this debate and i promise",
    "start": "1677520",
    "end": "1684399"
  },
  {
    "text": "you we are going to spend more time updating our specs to try and clarify this issue um so uh i i'm now regretting that i",
    "start": "1684399",
    "end": "1693200"
  },
  {
    "text": "that i didn't include more detail already on the instruments that we've designed we've got six instruments and and some of this is",
    "start": "1693200",
    "end": "1700240"
  },
  {
    "text": "what we're talking about right now um but but but when we talk about semantic kind there really are",
    "start": "1700240",
    "end": "1706000"
  },
  {
    "text": "two to my knowledge and in the technical committee we are in the sig we've been talking about the words adding versus grouping",
    "start": "1706000",
    "end": "1712240"
  },
  {
    "text": "what we're trying to distinguish is between things that you add or things that you average um and things",
    "start": "1712240",
    "end": "1718640"
  },
  {
    "text": "that you add are are interesting let's suppose you're sampling so if i have a bunch of observations of",
    "start": "1718640",
    "end": "1725440"
  },
  {
    "text": "things that i add well the larger numbers are more interesting because they contribute more to a sum",
    "start": "1725440",
    "end": "1730960"
  },
  {
    "text": "so if i'm say sampling numbers and i know that there are things i care about the sum well then i put weight on those",
    "start": "1730960",
    "end": "1737520"
  },
  {
    "text": "the higher numbers get more weight when i'm sampling or down or any kind of aggregation that i'm",
    "start": "1737520",
    "end": "1743039"
  },
  {
    "text": "doing where where sum is the the property i'm after then i want to know that it's a sum",
    "start": "1743039",
    "end": "1748640"
  },
  {
    "text": "whereas if i'm doing something like down sampling or reducing dimensionality of one of these other types like where",
    "start": "1748640",
    "end": "1755840"
  },
  {
    "text": "traditionally we have used a gauge or where you use now a value recorder or a value observer",
    "start": "1755840",
    "end": "1761200"
  },
  {
    "text": "then there's there's no just there's no in difference in importance between a small number and a big number you have a zero latency",
    "start": "1761200",
    "end": "1768240"
  },
  {
    "text": "that's a significant measurement it's no more or less significant than 100 second latency so when you're talking about these",
    "start": "1768240",
    "end": "1774880"
  },
  {
    "text": "individual values or individual measurements you want to think of that as a different semantic type than it is than say a",
    "start": "1774880",
    "end": "1781279"
  },
  {
    "text": "an increment where you're just going to contribute to a sum because bigger increments matter more",
    "start": "1781279",
    "end": "1787760"
  },
  {
    "text": "this is um a little we're sort of straining into the theory of measurement and and i should have put i could have put some slides in here about that but",
    "start": "1788720",
    "end": "1795679"
  },
  {
    "text": "we do in sort of in statistics or in in math we talk about scale for the numbers",
    "start": "1795679",
    "end": "1801600"
  },
  {
    "text": "so you can talk about ratio scale and interval scale and logarithm scale um",
    "start": "1801600",
    "end": "1807520"
  },
  {
    "text": "you can answer the question in those terms as well but i'd rather do it with the way i just did",
    "start": "1807520",
    "end": "1814559"
  },
  {
    "text": "so um i just discussed roughly what was on this slide is to say that we are interested",
    "start": "1819520",
    "end": "1825600"
  },
  {
    "text": "in keeping the semantic type when we have when we have that information and this choice justin's question the",
    "start": "1825600",
    "end": "1831120"
  },
  {
    "text": "choice between value recorder and or sorry value observer and and up down some observer",
    "start": "1831120",
    "end": "1837679"
  },
  {
    "text": "though those they're very close but conceptually we want them to be different and i promise you we'll keep writing to",
    "start": "1837679",
    "end": "1843600"
  },
  {
    "text": "try and clarify this point okay um well i finished my section on",
    "start": "1843600",
    "end": "1851279"
  },
  {
    "start": "1850000",
    "end": "1850000"
  },
  {
    "text": "data model um so that's good we made it through and you asked the same question right as i was reaching my last slide um",
    "start": "1851279",
    "end": "1859120"
  },
  {
    "text": "okay so for the rest of this talk we are going to go through some of the ways that you can configure export for your metrics data especially",
    "start": "1859120",
    "end": "1866240"
  },
  {
    "text": "talking about how we control costs okay so um in not particularly great order here we",
    "start": "1866240",
    "end": "1874159"
  },
  {
    "text": "have a few features that are sort of new and interesting for open telemetry one of the things that's been i think",
    "start": "1874159",
    "end": "1879279"
  },
  {
    "text": "holding back the industry uh generally speaking is that we need variable balanced histograms or we need",
    "start": "1879279",
    "end": "1885279"
  },
  {
    "text": "histograms that can support high resolution and be relatively compressed various",
    "start": "1885279",
    "end": "1890399"
  },
  {
    "text": "ways of saying the same thing sometimes we call these sketches histograms by however you formulate them are approximate",
    "start": "1890399",
    "end": "1896880"
  },
  {
    "text": "representations of a distribution and we want to get better at this so um i've named some",
    "start": "1896880",
    "end": "1902240"
  },
  {
    "text": "algorithms that are that you that are used for this we are currently negotiating and working out some of the protocol",
    "start": "1902240",
    "end": "1908240"
  },
  {
    "text": "decisions that we want here and we are looking to standardize on one of these",
    "start": "1908240",
    "end": "1913679"
  },
  {
    "text": "algorithms as a sort of recommended approach so open geometry is going to",
    "start": "1913679",
    "end": "1919919"
  },
  {
    "text": "offer you essentially better histograms than than you've been getting out of the box for some of the",
    "start": "1919919",
    "end": "1925039"
  },
  {
    "text": "metric systems that you're interested that you've been using dd sketch is the leading contender",
    "start": "1925039",
    "end": "1934559"
  },
  {
    "start": "1934000",
    "end": "1934000"
  },
  {
    "text": "um a lot of the discussion that we've had about temporality in the past 15 minutes ultimately comes down to cost",
    "start": "1934559",
    "end": "1941679"
  },
  {
    "text": "and cardinality so what we have a situation where we expect that users or developers are going to be writing",
    "start": "1941679",
    "end": "1948399"
  },
  {
    "text": "instrumentation and putting metric labels together that are sort of that they may not actually know",
    "start": "1948399",
    "end": "1953919"
  },
  {
    "text": "what are the useful labels or what the cost tolerances of the people running that code are going to be so that you may end up as a situation",
    "start": "1953919",
    "end": "1960080"
  },
  {
    "text": "where you're generating more labels than you actually need so what do you do with that situation",
    "start": "1960080",
    "end": "1966000"
  },
  {
    "text": "two things that we know how to do that we're including in part as as as part of the open telemetry metric system",
    "start": "1966000",
    "end": "1972080"
  },
  {
    "text": "one is that we have the ability to do in-process aggregation so these these sdks are relatively",
    "start": "1972080",
    "end": "1978000"
  },
  {
    "text": "sophisticated they include the ability to coalesce events that happen over a short interval of time",
    "start": "1978000",
    "end": "1984080"
  },
  {
    "text": "and then if we want to do label label reduction we can actually erase those labels and just aggregate those values",
    "start": "1984080",
    "end": "1989760"
  },
  {
    "text": "together so that we get fewer time series with more aggregation happening so this is a facility that the sdks",
    "start": "1989760",
    "end": "1996320"
  },
  {
    "text": "include and it's something that we have to configure so later on we'll talk about how to configure that but for now the sdks",
    "start": "1996320",
    "end": "2001840"
  },
  {
    "text": "include this mechanism the other thing that we can do to control cost is the reason why i've been talking about",
    "start": "2001840",
    "end": "2007200"
  },
  {
    "text": "temporality so much so in a statsd system you may have been used to cardinality being okay because every at every flush",
    "start": "2007200",
    "end": "2014480"
  },
  {
    "text": "interval you can completely forget what you've been reporting and just begin accumulating new state",
    "start": "2014480",
    "end": "2019600"
  },
  {
    "text": "whereas in a prometheus system if you use high cardinality those labels are stuck in memory for a very long time",
    "start": "2019600",
    "end": "2026320"
  },
  {
    "text": "so a stateless export pipeline is one where you force the use of delta export of delta aggregation",
    "start": "2026320",
    "end": "2032480"
  },
  {
    "text": "temporality in order to allow yourself to flesh out memory",
    "start": "2032480",
    "end": "2037840"
  },
  {
    "text": "so let's look at some diagrams this here is a diagram of a standalone",
    "start": "2040320",
    "end": "2045440"
  },
  {
    "text": "sdk running open telemetry metrics so you've got your application code running you have a runtime metrics",
    "start": "2045440",
    "end": "2052560"
  },
  {
    "text": "instrumentation package running that's telling you garbage question statistics maybe you have a host metrics",
    "start": "2052560",
    "end": "2058158"
  },
  {
    "text": "instrumentation package that's running that may be telling you cpu usage and memory usage and so on",
    "start": "2058159",
    "end": "2063679"
  },
  {
    "text": "you have the open telemetry api beneath that you have the sdk the sdk has a frontline component we",
    "start": "2063679",
    "end": "2070158"
  },
  {
    "text": "call the accumulator which builds up short-term state so over one interval whether that's a second or a minute or",
    "start": "2070159",
    "end": "2077040"
  },
  {
    "text": "ten minutes could be anything you build up a record of everything that's happened during that period of time",
    "start": "2077040",
    "end": "2082638"
  },
  {
    "text": "and then every once in a while the sdk flushes its state i have this orange box here with a",
    "start": "2082639",
    "end": "2089919"
  },
  {
    "text": "diagram saying here is where we do delta to cumulative conversion so this orange box represents a",
    "start": "2089919",
    "end": "2096638"
  },
  {
    "text": "long-term memory commitment in order to implement cumulative export for your metrics",
    "start": "2096639",
    "end": "2102000"
  },
  {
    "text": "you have to put memory somewhere and in this configuration this standalone configuration you just put that directly in your sdk",
    "start": "2102000",
    "end": "2109040"
  },
  {
    "text": "so this is a configuration where you don't want to use a lot of cardinality because it's going to sit in memory for a long",
    "start": "2109040",
    "end": "2114720"
  },
  {
    "text": "time but this is a this is a configuration that's very compatible with downstream systems",
    "start": "2114720",
    "end": "2120400"
  },
  {
    "text": "you can blindly send this to an endpoint say a collector and it can export to prometheus because you put the data",
    "start": "2120400",
    "end": "2126880"
  },
  {
    "text": "into cumulative form before you send it now the problem is you have to put a lot of",
    "start": "2126880",
    "end": "2132880"
  },
  {
    "text": "memory in your application for this and you have to hold on to that memory for a long time and it prevents you from using high",
    "start": "2132880",
    "end": "2138000"
  },
  {
    "text": "cardinality metrics so we have this other option to configure an export pipeline that is",
    "start": "2138000",
    "end": "2144400"
  },
  {
    "text": "stateless and the way we do this is by making sure that the aggregation temporality matches",
    "start": "2144400",
    "end": "2150320"
  },
  {
    "text": "instrument temporality if you're putting deltas in you give deltas out if you're putting cumulatives in you put",
    "start": "2150320",
    "end": "2155680"
  },
  {
    "text": "cumulatives out and this way you have no memory requirements so in this diagram it's the same as the diagram before but now there's no",
    "start": "2155680",
    "end": "2162320"
  },
  {
    "text": "long-term memory commitment and there's no orange box there's nothing happening in that box it's just passing straight through",
    "start": "2162320",
    "end": "2168400"
  },
  {
    "text": "so this is going to cost you less and if you have an otlp endpoint that supports deltas natively",
    "start": "2168400",
    "end": "2174720"
  },
  {
    "text": "this is actually a good configuration and um i want to say if anyone's listening here if you're the author of an open source",
    "start": "2174720",
    "end": "2181760"
  },
  {
    "text": "backend for metrics data this is an opportunity a big opportunity to accept native otlp data",
    "start": "2181760",
    "end": "2187680"
  },
  {
    "text": "because it will allow the clients to begin configuring themselves statelessly and this is going to be open the door to",
    "start": "2187680",
    "end": "2195040"
  },
  {
    "text": "high cardinality metrics so that was a sort of complicated uh",
    "start": "2195040",
    "end": "2201200"
  },
  {
    "start": "2199000",
    "end": "2199000"
  },
  {
    "text": "configuration here because it is standalone you've got several things running inside your process and all those things running inside your process",
    "start": "2201200",
    "end": "2206960"
  },
  {
    "text": "add up to risk and cost so there's another way you can configure this and this is using the collector as an agent so i",
    "start": "2206960",
    "end": "2214720"
  },
  {
    "text": "might want to export cumulative metrics because that makes the downstream system happy so i can for example write to prometheus",
    "start": "2214720",
    "end": "2221760"
  },
  {
    "text": "but somewhere in my pipeline i have to configure this point where i convert deltas to cumulatives which leads to a",
    "start": "2221760",
    "end": "2227280"
  },
  {
    "text": "long-term memory requirement so in this configuration i have an application running inside of a host but",
    "start": "2227280",
    "end": "2234000"
  },
  {
    "text": "it's it is a stateless exporter so it is it is outputting otlp with aggregation temporality",
    "start": "2234000",
    "end": "2240079"
  },
  {
    "text": "to require no memory the hotel collector is running on the same host it is able",
    "start": "2240079",
    "end": "2246000"
  },
  {
    "text": "to implement that delta to cumulative conversion and then you can output otlp converted",
    "start": "2246000",
    "end": "2251760"
  },
  {
    "text": "to cumulative from your host but your application is still running statelessly so this is a way that we can reduce risk",
    "start": "2251760",
    "end": "2259200"
  },
  {
    "text": "on the application itself if you were accidentally to put high cardinality metrics in this configuration it'll crash the",
    "start": "2259200",
    "end": "2266400"
  },
  {
    "text": "collector not your application actually the collector is probably written to handle",
    "start": "2266400",
    "end": "2271520"
  },
  {
    "text": "that better than your application is so so that's one configuration of course",
    "start": "2271520",
    "end": "2276880"
  },
  {
    "text": "there is still a long term state requirement here we've just moved it from the application to the collector",
    "start": "2276880",
    "end": "2283440"
  },
  {
    "text": "so there's another configuration this is where we talk about just a standalone prometheus exporter suppose you have an",
    "start": "2283440",
    "end": "2289599"
  },
  {
    "text": "existing prometheus setup you just want to add one new new target so in this situation it's roughly the same as that configuration",
    "start": "2289599",
    "end": "2296320"
  },
  {
    "text": "that i showed you before i'm running my runtime metrics plugin tells me gc stats i'm running my host",
    "start": "2296320",
    "end": "2302160"
  },
  {
    "text": "metrics which means i don't need to run some other prometheus tool to export node statistics um i've got my api sdk",
    "start": "2302160",
    "end": "2310079"
  },
  {
    "text": "i'm still doing that delta cumulative conversion because i must for prometheus and then i can either pull that data",
    "start": "2310079",
    "end": "2315839"
  },
  {
    "text": "using openmetrics or i can push that data using a prometheus remote write exporter in both of these cases",
    "start": "2315839",
    "end": "2322000"
  },
  {
    "text": "i'm writing to prometheus in both these cases i have to do a delta to cumulative conversion because again prometheus requires it",
    "start": "2322000",
    "end": "2329680"
  },
  {
    "text": "but i could also do that statelessly again same almost the same diagram as before i've got a stateless application i'm",
    "start": "2329680",
    "end": "2336320"
  },
  {
    "start": "2330000",
    "end": "2330000"
  },
  {
    "text": "sending through a stateless export pipeline i'm receiving that at the collector agent i then can do delta to cumulative",
    "start": "2336320",
    "end": "2342720"
  },
  {
    "text": "conversion but now i'm going to use the prometheus remote right because there's some impedance mismatch",
    "start": "2342720",
    "end": "2349839"
  },
  {
    "text": "using open telemetry using openmetrics to pull from a collector we're not going to do that right away",
    "start": "2349839",
    "end": "2355920"
  },
  {
    "text": "um so this is a way you can export to prometheus through a stateless in-process exporter and a",
    "start": "2355920",
    "end": "2361680"
  },
  {
    "text": "local agent that's not the only way you can configure export for open telemetry metrics i want",
    "start": "2361680",
    "end": "2367839"
  },
  {
    "start": "2364000",
    "end": "2364000"
  },
  {
    "text": "to do a little review on some of the stuff that we just talked about there's sort of two",
    "start": "2367839",
    "end": "2373040"
  },
  {
    "text": "uh ways that you might to two ends of the spectrum that you might configure your metrics export",
    "start": "2373040",
    "end": "2378560"
  },
  {
    "text": "you can do either push and pull or you can do stateless or cumulative but we generally pair the pull model",
    "start": "2378560",
    "end": "2384720"
  },
  {
    "text": "with cumulative which is the prometheus model and that's the default for open telemetry and we all um and and that has",
    "start": "2384720",
    "end": "2391440"
  },
  {
    "text": "properties are good for prometheus you're automatically going to work with prometheus even if you have a collector in the loop you get easier reliability",
    "start": "2391440",
    "end": "2399280"
  },
  {
    "text": "because when you drop a record or a data point in prometheus when you drop a cumulative data point it",
    "start": "2399280",
    "end": "2405920"
  },
  {
    "text": "gets smoothed out by the next data point that arrives so loss loss of data is pretty okay in a",
    "start": "2405920",
    "end": "2411359"
  },
  {
    "text": "prometheus system um but high cardinality is pretty much not allowed and it will blow you up if",
    "start": "2411359",
    "end": "2416880"
  },
  {
    "text": "you do it by accident so in this other side here we've got",
    "start": "2416880",
    "end": "2422079"
  },
  {
    "text": "this premie this this push model and this stateless export model so the one thing that's",
    "start": "2422079",
    "end": "2427440"
  },
  {
    "text": "going for it is it's exactly the same as we're doing already for traces if you're going to set up an export pipeline for your span",
    "start": "2427440",
    "end": "2432960"
  },
  {
    "text": "data you might want to set up the same exact topology for your metrics data so the idea that you're going to attach",
    "start": "2432960",
    "end": "2439520"
  },
  {
    "text": "resources as you collect data through your infrastructure it fits very well it matches trace collection however",
    "start": "2439520",
    "end": "2447119"
  },
  {
    "text": "it means you're using delta delta aggregation temporality it means that you have to be a little bit you have to work a lot harder for",
    "start": "2447119",
    "end": "2453520"
  },
  {
    "text": "reliability so you have to avoid drop packets means loss of data and replayed packets means",
    "start": "2453520",
    "end": "2459599"
  },
  {
    "text": "double counted data so we have to be careful to avoid dropping data but we also have to avoid replay",
    "start": "2459599",
    "end": "2466400"
  },
  {
    "text": "but the upside of this configuration is that that high cardinality is no longer a",
    "start": "2466400",
    "end": "2472480"
  },
  {
    "text": "cost inside the process and high cardinality if the downstream system supports it is going to be okay and actually could",
    "start": "2472480",
    "end": "2478800"
  },
  {
    "text": "be good for the user i didn't cover this com this sort of worst and best of both cases which would",
    "start": "2478800",
    "end": "2484319"
  },
  {
    "text": "be a push cumulative model that is definitely a valid configuration it's exactly what you want if you're",
    "start": "2484319",
    "end": "2489680"
  },
  {
    "text": "going to send prometheus data through a collector so um these are choices um currently",
    "start": "2489680",
    "end": "2497599"
  },
  {
    "text": "we're we're the default for open telemetry is cumulative because it's the most compatible but it does mean that",
    "start": "2497599",
    "end": "2503440"
  },
  {
    "text": "basically we're giving you prometheus status quo you're gonna be keeping memory for your cardinality",
    "start": "2503440",
    "end": "2509440"
  },
  {
    "text": "until we reconfigure your system to use this push stateless export strategy hey josh",
    "start": "2509440",
    "end": "2516800"
  },
  {
    "text": "yeah question came in in our chat about what things exactly do we need to configure to get to that stateless",
    "start": "2516800",
    "end": "2522000"
  },
  {
    "text": "model you're describing um good question um so we need some more",
    "start": "2522000",
    "end": "2527280"
  },
  {
    "text": "collector development there is not an actual accumulated cumulative",
    "start": "2527280",
    "end": "2532960"
  },
  {
    "text": "processing stage today it's imaginary um the reference implementation for the",
    "start": "2532960",
    "end": "2540319"
  },
  {
    "text": "otel metrics sdk which is the one that i've been developing in go does have this ability to select the",
    "start": "2540319",
    "end": "2545839"
  },
  {
    "text": "stateless versus cumulative mode today so the the sdk support has been specced out",
    "start": "2545839",
    "end": "2551040"
  },
  {
    "text": "the reference implementation does exist it works but as far as um a collector support",
    "start": "2551040",
    "end": "2557520"
  },
  {
    "text": "it's not there yet if you had a vendor that was supporting both forms of otlp today you could get that from at least",
    "start": "2557520",
    "end": "2564560"
  },
  {
    "text": "from the reference implementation",
    "start": "2564560",
    "end": "2567760"
  },
  {
    "text": "hope that answers the question um i'm very excited about this because as a user from a statistic background i",
    "start": "2570000",
    "end": "2575760"
  },
  {
    "text": "was used to having a little bit more cardinality than i'm able to get from a prometheus configuration so i would like to push",
    "start": "2575760",
    "end": "2582560"
  },
  {
    "text": "more hype more cardinality on the metrics world until it's a real problem and i'm hoping i think there's a good opportunity for",
    "start": "2582560",
    "end": "2588880"
  },
  {
    "text": "data scientists to come help us with actual cardinality control mechanisms like we can down sample to control",
    "start": "2588880",
    "end": "2594640"
  },
  {
    "text": "cardinality for example i think that's actually a",
    "start": "2594640",
    "end": "2600079"
  },
  {
    "text": "really exciting topic but i won't say no more um i think we're almost at the end here",
    "start": "2600079",
    "end": "2607119"
  },
  {
    "start": "2605000",
    "end": "2605000"
  },
  {
    "text": "of my slide deck um i have a few more diagrams just to kind of give you a greater picture of all the ways you might configure open",
    "start": "2607119",
    "end": "2612720"
  },
  {
    "text": "telemetry metrics um this is an example of a sort of kubernetes deployment where you've got a node",
    "start": "2612720",
    "end": "2618160"
  },
  {
    "text": "you've got a daemon set collector running on every node you've configured your receivers for",
    "start": "2618160",
    "end": "2624240"
  },
  {
    "text": "openmetrics for statsd for otlp you've got the kubernetes receiver built in so you're",
    "start": "2624240",
    "end": "2629760"
  },
  {
    "text": "getting the kubernetes state metrics you've got a host metrics running on the collector so you don't have to run those",
    "start": "2629760",
    "end": "2635680"
  },
  {
    "text": "host metrics on every machine running on the pod or on the node for example so these are just a number of",
    "start": "2635680",
    "end": "2641680"
  },
  {
    "text": "sort of this is the scale of these installations is now good we're going to be able to to talk about one collector per node and",
    "start": "2641680",
    "end": "2648560"
  },
  {
    "text": "a bunch of different targets per node and so on and this is just part of this the plan for open telemetry collector",
    "start": "2648560",
    "end": "2656560"
  },
  {
    "text": "um definitely part of that resource model is that we're going to implement hierarchical",
    "start": "2656720",
    "end": "2662480"
  },
  {
    "text": "collections so that you have a node collector that's collecting all the resources all the metrics locally and it's going to pass that to a regional collector",
    "start": "2662480",
    "end": "2669040"
  },
  {
    "text": "that's going to attach all of your regional resource attributes and it might pass to a global or other levels of hierarchy",
    "start": "2669040",
    "end": "2675520"
  },
  {
    "text": "that you can use to organize your metrics data this is something that you might be able",
    "start": "2675520",
    "end": "2681200"
  },
  {
    "text": "to to bypass certain prometheus features with if you're using prometheus you might be using recording rules to get some more",
    "start": "2681200",
    "end": "2686960"
  },
  {
    "text": "functionality but we can just talk about an expert pipeline that aggregates everything together into one place",
    "start": "2686960",
    "end": "2692720"
  },
  {
    "text": "without that type of recording rule functionality which is like a right time aggregation",
    "start": "2692720",
    "end": "2699200"
  },
  {
    "text": "all right there's one more i saved it for last i've discovered that there are a lot of prometheus users out there who have",
    "start": "2699200",
    "end": "2705440"
  },
  {
    "text": "invested a tremendous amount in their configuration so prometheus does a lot of things and it's going to",
    "start": "2705440",
    "end": "2710640"
  },
  {
    "text": "be difficult to replace all of that functionality so we were looking for ways to help",
    "start": "2710640",
    "end": "2716319"
  },
  {
    "text": "prometheus users get on board with open telemetry and begin using otlp",
    "start": "2716319",
    "end": "2722240"
  },
  {
    "text": "so i found this thing um that the stackdriver group had done a couple years ago it is",
    "start": "2722240",
    "end": "2727920"
  },
  {
    "text": "a stackdriver prometheus sidecar i haven't talked about this much but",
    "start": "2727920",
    "end": "2733200"
  },
  {
    "text": "today uh it's open source now um we opened up the public the repository publicly this is a sidecar for prometheus",
    "start": "2733200",
    "end": "2739760"
  },
  {
    "text": "basically lets you read prometheus data and send otlp um this i see as a short-term solution",
    "start": "2739760",
    "end": "2746079"
  },
  {
    "text": "because ultimately the prometheus project will add metadata to its remote right protocol and then it will be able to",
    "start": "2746079",
    "end": "2752880"
  },
  {
    "text": "um replace this sidecar so today you cannot send prometheus data directly out",
    "start": "2752880",
    "end": "2758000"
  },
  {
    "text": "of prometheus into otlp without a tool like this but hopefully in the future that restriction will go away",
    "start": "2758000",
    "end": "2765119"
  },
  {
    "text": "i put a few links to this this code base as well as a couple of the prometheus issues that are currently trying to",
    "start": "2765119",
    "end": "2771440"
  },
  {
    "text": "address this shortcoming so that hopefully we can retire this code in the future but meanwhile prometheus users should be",
    "start": "2771440",
    "end": "2778079"
  },
  {
    "text": "able to try their open telemetry metrics system and this should also help us migrate",
    "start": "2778079",
    "end": "2783280"
  },
  {
    "text": "from prometheus onto open telemetry in a gradual way now i think i've actually reached the",
    "start": "2783280",
    "end": "2789599"
  },
  {
    "text": "end of the talk and i'd love to have questions and discussion from the group",
    "start": "2789599",
    "end": "2802480"
  },
  {
    "text": "josh are you expecting questions on this on the zoom chat or we can ask them just like uh since i've been presenting i",
    "start": "2802480",
    "end": "2809760"
  },
  {
    "text": "wasn't reading zoom chat but i'm gonna unpresent um and and then we can all talk",
    "start": "2809760",
    "end": "2816720"
  },
  {
    "text": "and i'll read the chat have a quick one please so this morning we were talking about traces and context and context",
    "start": "2816720",
    "end": "2822640"
  },
  {
    "text": "propagation and this this afternoon we are talking about metrics and labels and tags so do we",
    "start": "2822640",
    "end": "2830160"
  },
  {
    "text": "lose the context of traces when we handle open telemetry matrix or is this",
    "start": "2830160",
    "end": "2836000"
  },
  {
    "text": "is there a way when we can link or correlate the traces context",
    "start": "2836000",
    "end": "2841359"
  },
  {
    "text": "with the metrics labels right um first i always want to point",
    "start": "2841359",
    "end": "2846800"
  },
  {
    "text": "out there's been a bit of terminology um debate and we we haven't actually settled it so the term",
    "start": "2846800",
    "end": "2852240"
  },
  {
    "text": "attribute the term label and term tag are almost synonymous and used interchangeably here i hope",
    "start": "2852240",
    "end": "2858160"
  },
  {
    "text": "that's not the question you're actually asking i believe you're asking about how we talk about distributed context",
    "start": "2858160",
    "end": "2864400"
  },
  {
    "text": "and getting those attributes that come from say",
    "start": "2864400",
    "end": "2870559"
  },
  {
    "text": "distributed actors in your system onto your metrics this is something that i mentioned in",
    "start": "2870559",
    "end": "2875760"
  },
  {
    "text": "one of the breakout sessions earlier today was the sort of driving i think a driving",
    "start": "2875760",
    "end": "2881040"
  },
  {
    "text": "motivator for the census design and part of the sort of the the heritage of open telemetry at",
    "start": "2881040",
    "end": "2887440"
  },
  {
    "text": "this point is that that we were a bit based off of open census metrics so openstack just metrics did include a",
    "start": "2887440",
    "end": "2895119"
  },
  {
    "text": "way to um",
    "start": "2895119",
    "end": "2900960"
  },
  {
    "text": "open senses did include a way to um get your distributed context",
    "start": "2900960",
    "end": "2908160"
  },
  {
    "text": "attributes into your metrics it's something that you have to configure we're talking about the terminology for this we've we've got something called an",
    "start": "2908160",
    "end": "2915119"
  },
  {
    "text": "an enhancer at this point which is a a hook that you can use to pull attributes out of your context",
    "start": "2915119",
    "end": "2921440"
  },
  {
    "text": "and put them into your metric system i hope that answers the question we're still talking terminology okay i think maybe",
    "start": "2921440",
    "end": "2927599"
  },
  {
    "text": "there are a few pieces there one of them is that we can pull uh key values from",
    "start": "2927599",
    "end": "2933119"
  },
  {
    "text": "your baggage from that correlation context and put them onto metrics another one i think is just built into",
    "start": "2933119",
    "end": "2938400"
  },
  {
    "text": "the semantic conventions of our metrics we are trying to design the semantic conventions so that you can make correlations",
    "start": "2938400",
    "end": "2944720"
  },
  {
    "text": "between those metrics and the traces that might be representing the same timed operations and then the final",
    "start": "2944720",
    "end": "2951119"
  },
  {
    "text": "thing that is maybe the most exciting in my opinion is the concept of exemplars that go on metrics and what",
    "start": "2951119",
    "end": "2956800"
  },
  {
    "text": "this is is like each metric will include just like a list of",
    "start": "2956800",
    "end": "2962160"
  },
  {
    "text": "a few data points a few spans that are examples of that metric",
    "start": "2962160",
    "end": "2969200"
  },
  {
    "text": "which then there's like a very strong correlation between those fans and then those that specific metric",
    "start": "2969200",
    "end": "2975359"
  },
  {
    "text": "yeah so to make that clear we have ways at least planned out or specked out in",
    "start": "2976079",
    "end": "2981200"
  },
  {
    "text": "protocol to get data from your contacts including both those attributes as well as your spam id and your trace",
    "start": "2981200",
    "end": "2987440"
  },
  {
    "text": "id and to get that associated with metrics",
    "start": "2987440",
    "end": "2992079"
  },
  {
    "text": "fantastic cool thank you very much um so we were planning to take a",
    "start": "2992480",
    "end": "2999520"
  },
  {
    "text": "five-minute break before the next session um but if there are any other",
    "start": "2999520",
    "end": "3004720"
  },
  {
    "text": "um questions you can take them into the hotel community slack channel",
    "start": "3004720",
    "end": "3011280"
  },
  {
    "text": "um thank you so much josh justin for for presenting and sharing your expertise um",
    "start": "3011280",
    "end": "3017359"
  },
  {
    "text": "i i shared my notes in the chat i'll share them in in the slack channel as well um i got a lot out of this",
    "start": "3017359",
    "end": "3025359"
  },
  {
    "text": "thank you shelby um i'd be happy to stay on for a little bit i do see the questions now when i was presenting i couldn't see it i'm not sure how i could",
    "start": "3025359",
    "end": "3031839"
  },
  {
    "text": "have fixed that but there's one here for example i can see about um motel policy on discovery",
    "start": "3031839",
    "end": "3037520"
  },
  {
    "text": "when using open metrics approach that is really one of the greatest questions and it's not one that we're really answering",
    "start": "3037520",
    "end": "3043440"
  },
  {
    "text": "here openmetrics or sorry the prometheus system has a great big piece of code that does service discovery",
    "start": "3043440",
    "end": "3050079"
  },
  {
    "text": "and right now there's an ongoing discussion about how to either emulate or simplify or replace",
    "start": "3050079",
    "end": "3057440"
  },
  {
    "text": "such functionality in the hotel collector world and the current state of affairs is actually not so good we've linked in a",
    "start": "3057440",
    "end": "3063599"
  },
  {
    "text": "huge dependency on the prometheus system and are actually using that service discovery configuration",
    "start": "3063599",
    "end": "3069520"
  },
  {
    "text": "which has caused some friction and some dependency bloat um we are working on that bowden would",
    "start": "3069520",
    "end": "3076559"
  },
  {
    "text": "you like to speak anybody want to speak on that",
    "start": "3076559",
    "end": "3082640"
  },
  {
    "text": "something that needs to happen yeah",
    "start": "3082640",
    "end": "3087119"
  },
  {
    "text": "um i i actually have uh a dream here that somebody will take the",
    "start": "3088800",
    "end": "3094079"
  },
  {
    "text": "prometheus service discovery code factor it out of prometheus and create a first class service called service",
    "start": "3094079",
    "end": "3099680"
  },
  {
    "text": "discovery service and then we can have an hotel collector plugin which will reach out to the service discovery service",
    "start": "3099680",
    "end": "3105760"
  },
  {
    "text": "with some sort of sharding information and get a list of sharded targets for it to scrape so that we can then rather than linking in",
    "start": "3105760",
    "end": "3112960"
  },
  {
    "text": "a huge dependency on prometheus just actually call out to a service that does the same stuff",
    "start": "3112960",
    "end": "3118559"
  },
  {
    "text": "and then the prometheus service discovery will become its own thing awesome answer thank you",
    "start": "3118559",
    "end": "3126240"
  },
  {
    "text": "also uh it was mentioned on the slack that this is a break of five minutes before",
    "start": "3126240",
    "end": "3132079"
  },
  {
    "text": "the next session so everyone who is willing to chat more feel free to",
    "start": "3132079",
    "end": "3137200"
  },
  {
    "text": "but otherwise it's considered a break",
    "start": "3137200",
    "end": "3141599"
  },
  {
    "text": "service discovery service discovery service oh geez all right everyone thank you i'll be in",
    "start": "3142480",
    "end": "3148400"
  },
  {
    "text": "the next session i look forward to it",
    "start": "3148400",
    "end": "3153200"
  }
]
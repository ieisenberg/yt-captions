[
  {
    "start": "0",
    "end": "28000"
  },
  {
    "text": "hi everyone my name is Suman Cara Marie my pronouns are he/him and his today I'm",
    "start": "60",
    "end": "6120"
  },
  {
    "text": "going to talk about slack trace a new tracing tool we have built at slack so just something about the name is that",
    "start": "6120",
    "end": "13380"
  },
  {
    "text": "there's a talk deadline the project doesn't have an internal name so we just picked that because that was the top of",
    "start": "13380",
    "end": "19980"
  },
  {
    "text": "my hair mind at that time so it has it's it's not how we trace flag but it's the",
    "start": "19980",
    "end": "26400"
  },
  {
    "text": "name is there just for the sake of the talk so just a little bit about me so",
    "start": "26400",
    "end": "31410"
  },
  {
    "start": "28000",
    "end": "106000"
  },
  {
    "text": "I'm a senior staff engineer it slack and I work on the monitoring team there I",
    "start": "31410",
    "end": "37500"
  },
  {
    "text": "lead the team I love building and running petabyte scale observability",
    "start": "37500",
    "end": "42570"
  },
  {
    "text": "systems and at twitter thing precise to work at Twitter Pinterest Facebook like",
    "start": "42570",
    "end": "48270"
  },
  {
    "text": "that strip there and I ran ELQ at a lot of these companies and we also replaced",
    "start": "48270",
    "end": "55770"
  },
  {
    "text": "al khair Twitter with a system called log lines which is a log search platform which manages about two petabytes of",
    "start": "55770",
    "end": "60840"
  },
  {
    "text": "data today I was a tech lead for Zipkin project at Twitter and I was also on the",
    "start": "60840",
    "end": "65970"
  },
  {
    "text": "open tracing Advisory Committee customer advisory committee something and I also",
    "start": "65970",
    "end": "72990"
  },
  {
    "text": "built end-to-end tracing at Pinterest it's the system is called pin trace on the matrix",
    "start": "72990",
    "end": "79080"
  },
  {
    "text": "front I I was part of like Twitter's matrix stack we're an open DSD be at",
    "start": "79080",
    "end": "86090"
  },
  {
    "text": "Pinterest I we run at slack we run like one of the largest Prometheus clusters",
    "start": "86090",
    "end": "91799"
  },
  {
    "text": "in the world I also wrote an in-memory matrix storage engine called UV that for",
    "start": "91799",
    "end": "98310"
  },
  {
    "text": "open DHCP in general I'm actually very interested in distributed systems cloud",
    "start": "98310",
    "end": "103619"
  },
  {
    "text": "infrastructure infrastructure and general systems so I'd like to start",
    "start": "103619",
    "end": "109170"
  },
  {
    "text": "with a really really quick overview of tracing so going back it is slow is the",
    "start": "109170",
    "end": "115290"
  },
  {
    "text": "hardest problem to debug in a distributed system so tracing was built to identify where the bottlenecks are in",
    "start": "115290",
    "end": "123030"
  },
  {
    "text": "the system right everybody builds their own version of tracing so I mean that",
    "start": "123030",
    "end": "130679"
  },
  {
    "text": "gave rise to Rodrigo's tenth rule of distributed system on it any sufficiently complicated distributed",
    "start": "130679",
    "end": "136260"
  },
  {
    "text": "system contains an ad hoc informally specified siloed implementation of casa tracing right so then we have these",
    "start": "136260",
    "end": "144600"
  },
  {
    "start": "143000",
    "end": "202000"
  },
  {
    "text": "tracing systems today where it's a bit more formalized view of capturing this",
    "start": "144600",
    "end": "151290"
  },
  {
    "text": "information in a trace and then analyzing it using cold visualizations and analytics tools so what we did to",
    "start": "151290",
    "end": "158550"
  },
  {
    "text": "trace this data is we took a request centric view where we follow a request along its execution paths of all its",
    "start": "158550",
    "end": "165720"
  },
  {
    "text": "micro-services and then along its request execution path we capture the spans which is the trace data we collect",
    "start": "165720",
    "end": "173700"
  },
  {
    "text": "this data store it and some data store somewhere and then generally these",
    "start": "173700",
    "end": "179520"
  },
  {
    "text": "systems have a find traces view where you search for the representative traces",
    "start": "179520",
    "end": "184620"
  },
  {
    "text": "and then you look at one of those traces in a trace view and sometimes you also look at this data in a service graph",
    "start": "184620",
    "end": "191250"
  },
  {
    "text": "right this is generally a very high level view of tracing systems right some",
    "start": "191250",
    "end": "198000"
  },
  {
    "text": "tools and vendors do provide analytics on top of this trace data right so",
    "start": "198000",
    "end": "204020"
  },
  {
    "start": "202000",
    "end": "355000"
  },
  {
    "text": "having built these systems right like at Twitter Pinterest and like slack one of",
    "start": "204020",
    "end": "210030"
  },
  {
    "text": "the things that there's an emerging theme is like these systems are very complex like all those like Deathstar",
    "start": "210030",
    "end": "215400"
  },
  {
    "text": "diagrams you see like in slides are real and honestly those diagrams actually are",
    "start": "215400",
    "end": "220530"
  },
  {
    "text": "not very useful in practice at all it's like just a cool visualization of how complex everything is so what we found",
    "start": "220530",
    "end": "229290"
  },
  {
    "text": "from these traces like using these traces at scale is there are like a lot of problems you need a lot of intuition",
    "start": "229290",
    "end": "236670"
  },
  {
    "text": "and expertise to understand defined representative traces so once you are",
    "start": "236670",
    "end": "243840"
  },
  {
    "text": "tracing these systems unless you know more or less what you're looking for and search for the right thing it's really",
    "start": "243840",
    "end": "250260"
  },
  {
    "text": "hard like it would the data you collect won't be useful unless you do have to",
    "start": "250260",
    "end": "256260"
  },
  {
    "text": "have some sense of what you are knowing and even if you find the representative trace and like you you are looking at it",
    "start": "256260",
    "end": "261630"
  },
  {
    "text": "in a trace view the tools stop there they don't tell you what slow like it's left as an exercise to the reader",
    "start": "261630",
    "end": "267750"
  },
  {
    "text": "slower why it is slow right so as a result tracing tools have a very steep",
    "start": "267750",
    "end": "273030"
  },
  {
    "text": "learning curve the normal pattern is like some a handful of people at a company get really good at it and then",
    "start": "273030",
    "end": "280020"
  },
  {
    "text": "they use it to derive most of the insights forward for a wide swath of",
    "start": "280020",
    "end": "286950"
  },
  {
    "text": "employees tracing is not a general generally is not the tool they reach out to ask and answer questions about their",
    "start": "286950",
    "end": "293700"
  },
  {
    "text": "systems performance so service graphs are cool but outside of like demos in like real production scenarios they are",
    "start": "293700",
    "end": "300600"
  },
  {
    "text": "not very useful at least like you know in my experience and traces cannot be",
    "start": "300600",
    "end": "306900"
  },
  {
    "text": "used for triage so if you have a pair ongoing production issue generally traces are not used for triage they are",
    "start": "306900",
    "end": "313080"
  },
  {
    "text": "generally used to identify bottlenecks and like fake identify bottlenecks and",
    "start": "313080",
    "end": "318090"
  },
  {
    "text": "fix point issues performance issues but when you have an ongoing incident traces are generally not the tool you reach out",
    "start": "318090",
    "end": "324570"
  },
  {
    "text": "for they can help if you know that hey like trace would answer this question but generally they may not be right and",
    "start": "324570",
    "end": "332360"
  },
  {
    "text": "there are other problems with traces like you sample at scale you have to have you have instrumentation overhead",
    "start": "332360",
    "end": "338820"
  },
  {
    "text": "and as a result what happens is when you have your you're capturing less data as",
    "start": "338820",
    "end": "347040"
  },
  {
    "text": "a result the number of questions you can ask of your traces generally diminishes",
    "start": "347040",
    "end": "352700"
  },
  {
    "text": "at scale so what happens is once",
    "start": "352700",
    "end": "358640"
  },
  {
    "start": "355000",
    "end": "437000"
  },
  {
    "text": "generally tracing systems are built they are deployed you get some quick wins",
    "start": "358640",
    "end": "363780"
  },
  {
    "text": "which are very interesting and then tracing usually falls on the wayside it becomes a nice-to-have tool as opposed",
    "start": "363780",
    "end": "370650"
  },
  {
    "text": "to a must-have tool right like if it goes away like if your prom goes away",
    "start": "370650",
    "end": "375780"
  },
  {
    "text": "all hell breaks loose if racing goes away yeah right so true but the thing is",
    "start": "375780",
    "end": "383150"
  },
  {
    "text": "traces have very rich and complex data in them the problem we have found by",
    "start": "383150",
    "end": "389669"
  },
  {
    "text": "building these systems is these the data in the traces is exposed as literally",
    "start": "389669",
    "end": "395310"
  },
  {
    "text": "two views like a trace view and a service graph view it's basically like",
    "start": "395310",
    "end": "400440"
  },
  {
    "text": "taking all your fans Prometheus metrics or logs and everything and just providing a single dashboard to your data right that's a",
    "start": "400440",
    "end": "407430"
  },
  {
    "text": "single view into your data and it's pretty constraining because you can't ask any more questions of the data it's",
    "start": "407430",
    "end": "412860"
  },
  {
    "text": "like you have these views and then that's pretty much it right it's a waste of the data we collect so that's why we",
    "start": "412860",
    "end": "420180"
  },
  {
    "text": "want to make trace Reiter more useful and to make it more useful we want to make it more accessible right that's our",
    "start": "420180",
    "end": "426419"
  },
  {
    "text": "goal so the image there basically shows like initially there's a lot of hype and",
    "start": "426419",
    "end": "432389"
  },
  {
    "text": "then they're deflated exceptions and generally that's where it's stuck right so what we want to do we want to access",
    "start": "432389",
    "end": "439590"
  },
  {
    "start": "437000",
    "end": "503000"
  },
  {
    "text": "this traces as raw data right so why do we care right so as I said the we only",
    "start": "439590",
    "end": "446909"
  },
  {
    "text": "get fixed views into the data but what if we can access raw data if you access raw data you can slice and dice these",
    "start": "446909",
    "end": "453029"
  },
  {
    "text": "spans across various dimensions to get unique insights right for example we can",
    "start": "453029",
    "end": "458759"
  },
  {
    "text": "mix and match the data from different spans to ask and answer different sets",
    "start": "458759",
    "end": "463860"
  },
  {
    "text": "of questions that we couldn't ask before right we can build custom dashboards and analytics all the things we do on logs",
    "start": "463860",
    "end": "469860"
  },
  {
    "text": "and metrics today on traces as well right to get the value out of them right so we",
    "start": "469860",
    "end": "476789"
  },
  {
    "text": "were thinking about this and it it was I came across a strange like revelation",
    "start": "476789",
    "end": "482219"
  },
  {
    "text": "right for me it was hey we access metrics and logs as raw data right",
    "start": "482219",
    "end": "487229"
  },
  {
    "text": "why not traces traces you don't have you don't even know what the data format is you just go to Zipkin UI or jäger UI or",
    "start": "487229",
    "end": "494520"
  },
  {
    "text": "your tool and then you just put in some information and then it spits out of view that's pretty much it you don't",
    "start": "494520",
    "end": "499680"
  },
  {
    "text": "access raw data in traces why is that so having thought through this and we have",
    "start": "499680",
    "end": "506099"
  },
  {
    "start": "503000",
    "end": "566000"
  },
  {
    "text": "identified a few issues and like we got a few insights right so if you look at",
    "start": "506099",
    "end": "512159"
  },
  {
    "text": "like tracing today you have this open tracing api's where the trace that's how",
    "start": "512159",
    "end": "518430"
  },
  {
    "text": "you instrument your applications right open tracing is a complex but clean API right to instrument you're the your",
    "start": "518430",
    "end": "526260"
  },
  {
    "text": "crazy your application for tracing right and on the other end you have cool clean intuitive UI s-- which is you have you",
    "start": "526260",
    "end": "534960"
  },
  {
    "text": "or traceview and your service craft right to look at this data but what's in between is pretty much undefined its",
    "start": "534960",
    "end": "541860"
  },
  {
    "text": "implementation defined it's very complex right the span formats are very complex and they are designed to fit the needs",
    "start": "541860",
    "end": "549780"
  },
  {
    "text": "of the tools the questions they answer the diverged storage systems they use the diverse query languages they use all",
    "start": "549780",
    "end": "556170"
  },
  {
    "text": "the internal formats are designed for to fit into this like to fit into this diverse model of off spans right so what",
    "start": "556170",
    "end": "568320"
  },
  {
    "text": "is complex about this file format right so we looked at all the span formats or",
    "start": "568320",
    "end": "574650"
  },
  {
    "text": "at least like the publicly available ones and here is what we found right most the reason span formats are complex",
    "start": "574650",
    "end": "580560"
  },
  {
    "text": "is they are very network centric like tracing distributed tracing started from",
    "start": "580560",
    "end": "586530"
  },
  {
    "text": "a very network centric perspective so the span formats are very network",
    "start": "586530",
    "end": "592080"
  },
  {
    "text": "centric and as time went on people added UI things that are needed for the UI's",
    "start": "592080",
    "end": "598140"
  },
  {
    "text": "for all the tools into the sponsors right so the the span formats",
    "start": "598140",
    "end": "603360"
  },
  {
    "text": "organically grow and there are like interesting side effects of this right so if you look at a span format for",
    "start": "603360",
    "end": "610020"
  },
  {
    "text": "Zipkin yoga or any of these projects one of the things you would see is for example if you look at a span which",
    "start": "610020",
    "end": "616110"
  },
  {
    "text": "represents how much time something happened and then you have two ways in",
    "start": "616110",
    "end": "621150"
  },
  {
    "text": "to represent the sub time right one way",
    "start": "621150",
    "end": "626220"
  },
  {
    "text": "is you can use that you can use your child's pants to represent sub parts of",
    "start": "626220",
    "end": "632400"
  },
  {
    "text": "that span and you can also technically use annotations and people do do that right so there are two ways and then",
    "start": "632400",
    "end": "639060"
  },
  {
    "text": "there are some UI driven aspects to these pants for example Zipkin has annotations and binary annotations",
    "start": "639060",
    "end": "644580"
  },
  {
    "text": "what's the difference annotations are sub events in a span that you would look",
    "start": "644580",
    "end": "650100"
  },
  {
    "text": "at that are shown in the UI whereas binary annotations are the same things but they're not shown in the UI",
    "start": "650100",
    "end": "656430"
  },
  {
    "text": "because they're supposed to have binary data right and there are like logs and",
    "start": "656430",
    "end": "662190"
  },
  {
    "text": "tags in these pants what are logs like it this is like something from a storage concern right",
    "start": "662190",
    "end": "668200"
  },
  {
    "text": "if you have application logs you don't want like generally these systems are stored in like Cassandra or something",
    "start": "668200",
    "end": "673780"
  },
  {
    "text": "and you don't want to index this data in a specific way so you have log you put that data in logs and then you put",
    "start": "673780",
    "end": "679450"
  },
  {
    "text": "different data in tags which is like a more columnar friendly analytics friendly thing right and then there are",
    "start": "679450",
    "end": "686740"
  },
  {
    "text": "Network centric concerns right so Zipkin has single host like multi host spans whereas span events can belong to",
    "start": "686740",
    "end": "693040"
  },
  {
    "text": "multiple hosts Zipkin Jaeger has single host span where every span can only be",
    "start": "693040",
    "end": "699700"
  },
  {
    "text": "produced contains the data produced from a single host right their wives and why receive annotations and then there are",
    "start": "699700",
    "end": "705840"
  },
  {
    "text": "complexities or long span relationships and they're just basically too many span formats out there right we each with its",
    "start": "705840",
    "end": "712960"
  },
  {
    "text": "own like take on what a span should contain and most of these are driven by",
    "start": "712960",
    "end": "718150"
  },
  {
    "text": "what the tools need right so and then",
    "start": "718150",
    "end": "723970"
  },
  {
    "text": "there are other influences like we talked about like the data model of these spans is influenced by the storage",
    "start": "723970",
    "end": "730120"
  },
  {
    "text": "systems we use the query model the query model exposed by those systems and the",
    "start": "730120",
    "end": "736930"
  },
  {
    "text": "latency of those queries all of these impact the span format today right so",
    "start": "736930",
    "end": "743200"
  },
  {
    "text": "and this also has impact on how much the cost of the tracing in front which query",
    "start": "743200",
    "end": "748570"
  },
  {
    "text": "languages we use so what we do is we built to address these complexities we",
    "start": "748570",
    "end": "755050"
  },
  {
    "start": "749000",
    "end": "808000"
  },
  {
    "text": "built a very simple span format which is pretty minimalistic called a span event",
    "start": "755050",
    "end": "761380"
  },
  {
    "text": "right what is the span event a span event is a very simple format for",
    "start": "761380",
    "end": "767490"
  },
  {
    "text": "representing a span right so a span event here are the goals of this new the",
    "start": "767490",
    "end": "773800"
  },
  {
    "text": "span event we designed span event we wanted to support querying raw data",
    "start": "773800",
    "end": "779020"
  },
  {
    "text": "using sequel we want these fans to be easy to produce right we want this like",
    "start": "779020",
    "end": "786820"
  },
  {
    "text": "a span event format we don't want we don't care if these fans are part of a trace or not right and a span event",
    "start": "786820",
    "end": "794740"
  },
  {
    "text": "should be but we want to capture the full fidelity of the spans if you take a Zipkin span jäger span or an open",
    "start": "794740",
    "end": "801130"
  },
  {
    "text": "expand or open sensor span we want to capture all that data in our span so we want to capture that full fidelity we",
    "start": "801130",
    "end": "806920"
  },
  {
    "text": "just don't want to lose that data right so a new event has the following fields",
    "start": "806920",
    "end": "812380"
  },
  {
    "start": "808000",
    "end": "875000"
  },
  {
    "text": "like we have an ID which is the unique ID for an event we also have a timestamp",
    "start": "812380",
    "end": "817480"
  },
  {
    "text": "which is the time at which they even started the duration which is the time it took to run this event we have",
    "start": "817480",
    "end": "825250"
  },
  {
    "text": "something called a parent ID but which establishes a relationship between two",
    "start": "825250",
    "end": "830920"
  },
  {
    "text": "spans we call it parent ID but it establishes a relationship it does not have to be a",
    "start": "830920",
    "end": "836320"
  },
  {
    "text": "parent-child relationship we also have a trace ID which is an ID that we use for",
    "start": "836320",
    "end": "841420"
  },
  {
    "text": "deeply nested spans every event has a name every event has a type which could be a service name we also have tags",
    "start": "841420",
    "end": "848410"
  },
  {
    "text": "which are arbitrary set of key value pairs for all these events right and we",
    "start": "848410",
    "end": "853870"
  },
  {
    "text": "additionally have a new field called a span type which is similar to a kind and then it shows the type of Hispanic but",
    "start": "853870",
    "end": "860230"
  },
  {
    "text": "it's an annotation whether it's a client span server span anything like that so the reason we did this is it actually",
    "start": "860230",
    "end": "868510"
  },
  {
    "text": "looks very similar to the existing span formats out there but it is very",
    "start": "868510",
    "end": "873790"
  },
  {
    "text": "minimalistic right so we have these variants on this spans like the reason",
    "start": "873790",
    "end": "879100"
  },
  {
    "start": "875000",
    "end": "922000"
  },
  {
    "text": "span formats are very complex is they have these additional ideas that are tagged on to them over time right so",
    "start": "879100",
    "end": "884380"
  },
  {
    "text": "like annotations and annotations are these point events that are part of a",
    "start": "884380",
    "end": "889750"
  },
  {
    "text": "span so we just make it a spand type and then it's it is also a span event but we",
    "start": "889750",
    "end": "895510"
  },
  {
    "text": "just declare that as a additional child span that the UI wants to do something",
    "start": "895510",
    "end": "902620"
  },
  {
    "text": "about as opposed to like some nested structure in a current span right we",
    "start": "902620",
    "end": "907930"
  },
  {
    "text": "have point spans which are spans that happen for an instant so these are spans with duration of one we also have one",
    "start": "907930",
    "end": "914020"
  },
  {
    "text": "off spans which are spans that are not related to a request at all it's just something that happened in the system",
    "start": "914020",
    "end": "920230"
  },
  {
    "text": "right so we picked Seco as the query",
    "start": "920230",
    "end": "926110"
  },
  {
    "text": "layer for these data because sequel is widely used and popular it is simple to",
    "start": "926110",
    "end": "932170"
  },
  {
    "text": "get started with this and the other advantage is sequel ease",
    "start": "932170",
    "end": "938160"
  },
  {
    "text": "verbose but yet very expressive and we can do all sorts of complex joints on",
    "start": "938160",
    "end": "943230"
  },
  {
    "text": "this data right and the more important reason we chose sequel is it's supported",
    "start": "943230",
    "end": "948990"
  },
  {
    "text": "by a wide variety of storage packets that are available out there right so we",
    "start": "948990",
    "end": "954959"
  },
  {
    "start": "953000",
    "end": "967000"
  },
  {
    "text": "took all of these ideas put them in a project that is internally called feet tracing and then the goal of this",
    "start": "954959",
    "end": "960420"
  },
  {
    "text": "project was we want to represent our traces as causal spanned events that can be queried over sequel right so so this",
    "start": "960420",
    "end": "970139"
  },
  {
    "start": "967000",
    "end": "1057000"
  },
  {
    "text": "is the part where like I'll talk about like our pipeline and infrastructure but this is this bits are not very exciting",
    "start": "970139",
    "end": "977220"
  },
  {
    "text": "but it's like pretty standard so we have our apps which generate spans right we",
    "start": "977220",
    "end": "986370"
  },
  {
    "text": "generate span events some internal apps and then we also and we all the span",
    "start": "986370",
    "end": "992130"
  },
  {
    "text": "humans that are generated by apps are written to neuron which is slack's internal reliability event pipeline and",
    "start": "992130",
    "end": "999569"
  },
  {
    "text": "it's in an open source technology of that would be scribe ish and then we",
    "start": "999569",
    "end": "1006860"
  },
  {
    "text": "also have a history TP endpoint for ingesting these span events called Wallace the Wallace service takes this",
    "start": "1006860",
    "end": "1012829"
  },
  {
    "text": "pan events right simply mehron and then we also have trace adapters so the thing",
    "start": "1012829",
    "end": "1017990"
  },
  {
    "text": "is because we invented in your span format we don't want to invent new instrumentation into the applications we",
    "start": "1017990",
    "end": "1023360"
  },
  {
    "text": "just want to use this open source instrumentation that is already applicable and we already have",
    "start": "1023360",
    "end": "1029199"
  },
  {
    "text": "frameworks and applications that have instrumented them so we wrote adapters for Jager spans and Zipkin spans so",
    "start": "1029199",
    "end": "1036350"
  },
  {
    "text": "applications just can just point to point their endpoints to these plans and",
    "start": "1036350",
    "end": "1041418"
  },
  {
    "text": "then we can get these things and then neuron takes these plans writes them to Kafka and then we have several neuron",
    "start": "1041419",
    "end": "1047360"
  },
  {
    "text": "consumers that send the data to Honeycomb our internal data warehouse which is a presto cluster and we have an",
    "start": "1047360",
    "end": "1052760"
  },
  {
    "text": "internal Fork of Zipkin to handle this data and we send it to that too so these",
    "start": "1052760",
    "end": "1058940"
  },
  {
    "start": "1057000",
    "end": "1079000"
  },
  {
    "text": "are just like some use this is a view when you this is a view of a request when you send a a message in slack so the API is called",
    "start": "1058940",
    "end": "1066810"
  },
  {
    "text": "chat or post message we send the request and this is a trace view of that we trace memcache calls database calls G",
    "start": "1066810",
    "end": "1072720"
  },
  {
    "text": "RPC HTTP and all those calls so this is like just part of that request we can",
    "start": "1072720",
    "end": "1080720"
  },
  {
    "start": "1079000",
    "end": "1089000"
  },
  {
    "text": "build heat maps and dashboards on this data both within honeycomb and also",
    "start": "1080720",
    "end": "1086760"
  },
  {
    "text": "within our internal data warehouse and we can also access this data in our data",
    "start": "1086760",
    "end": "1092340"
  },
  {
    "start": "1089000",
    "end": "1107000"
  },
  {
    "text": "warehouse using complex sequel queries here is an example of a UI with a sample query that shows show me all the traces",
    "start": "1092340",
    "end": "1099000"
  },
  {
    "text": "today that have an API method and that came from a specific host so it's like a",
    "start": "1099000",
    "end": "1104310"
  },
  {
    "text": "cross span join query right so that's like the heart that's basically to prove",
    "start": "1104310",
    "end": "1112500"
  },
  {
    "text": "that hey we have the system it works right so today we run the system in production we trace 100% of our requests",
    "start": "1112500",
    "end": "1121260"
  },
  {
    "text": "in dev and about 1 to 2 percent of our all API requests in prod right so as",
    "start": "1121260",
    "end": "1128400"
  },
  {
    "text": "expected this tool has provided visibility into what is happening that was the most important question for us",
    "start": "1128400",
    "end": "1134280"
  },
  {
    "text": "in addition tracing has helped us as expected to identify the performance",
    "start": "1134280",
    "end": "1139350"
  },
  {
    "text": "bottlenecks on our system but more importantly it helped us prioritize which bottlenecks to fix because",
    "start": "1139350",
    "end": "1148190"
  },
  {
    "text": "previously if you use a tracing system it will tell you something is slow but because you can't access the trace data",
    "start": "1148190",
    "end": "1153810"
  },
  {
    "text": "you don't know how prevalent it is or whether it's affecting your largest customers or your smallest customers right like so with the trace data we",
    "start": "1153810",
    "end": "1161760"
  },
  {
    "text": "were able to do that and the most surprising bit for me by is by allowing",
    "start": "1161760",
    "end": "1168150"
  },
  {
    "text": "our users to open up the trace data and access it in any way the most",
    "start": "1168150",
    "end": "1173370"
  },
  {
    "text": "interesting thing for me is we were asking questions of this data without",
    "start": "1173370",
    "end": "1178470"
  },
  {
    "text": "adding additional instrumentation generally whenever you have some question about how something works you have to go in and add some additional",
    "start": "1178470",
    "end": "1185970"
  },
  {
    "text": "instrumentation at a counter metric whatever to get the insight but with trace data we do have to do that most of",
    "start": "1185970",
    "end": "1192270"
  },
  {
    "text": "the time almost every single time there is a production issue or any saying we could go into the system and",
    "start": "1192270",
    "end": "1197660"
  },
  {
    "text": "just formulate a new query on this data and get an answer without adding additional data that was very powerful",
    "start": "1197660",
    "end": "1203299"
  },
  {
    "text": "and some teams today do use traces at slack as a result for trying production",
    "start": "1203299",
    "end": "1210320"
  },
  {
    "text": "issues so we had like a major incident where like github was done and well",
    "start": "1210320",
    "end": "1216860"
  },
  {
    "text": "internal instance of github was down and we weren't sure why because we made a massive change to some of the components",
    "start": "1216860",
    "end": "1224059"
  },
  {
    "text": "that the pipeline depends on and we actually trace used traces heavily to",
    "start": "1224059",
    "end": "1229790"
  },
  {
    "text": "triage that issue and identify like bad hosts and like take them down very quickly and the most interesting bit for",
    "start": "1229790",
    "end": "1238820"
  },
  {
    "text": "us is how we use the trace data I'll give you three examples well I only have",
    "start": "1238820",
    "end": "1244730"
  },
  {
    "text": "two on the slides but I'll give you three so the first one is as I said",
    "start": "1244730",
    "end": "1250190"
  },
  {
    "text": "before we have we use memcache we use caching heavily in an architecture one of the things is caching does not have",
    "start": "1250190",
    "end": "1257000"
  },
  {
    "text": "the same effect for all the customers right so we have memcache for example",
    "start": "1257000",
    "end": "1263660"
  },
  {
    "text": "for large customers there can be hundreds of memcache calls in a single request right for small customers",
    "start": "1263660",
    "end": "1268850"
  },
  {
    "text": "they'll be tense so the perception of latency from memcache for a given customer is dependent on a specific",
    "start": "1268850",
    "end": "1275750"
  },
  {
    "text": "endpoint in their use case so what we were able to do is we were able to ask",
    "start": "1275750",
    "end": "1280970"
  },
  {
    "text": "very pointed questions that you couldn't ask off of your data before which is hey does memcache contribute to p99",
    "start": "1280970",
    "end": "1288799"
  },
  {
    "text": "latencies for this large customer right so for example if we want to make our performance better for our largest",
    "start": "1288799",
    "end": "1294080"
  },
  {
    "text": "customers how much should I invest in memcache right is memcache the right",
    "start": "1294080",
    "end": "1299330"
  },
  {
    "text": "place to invest a trace data told us that yes it is because what we found is",
    "start": "1299330",
    "end": "1305120"
  },
  {
    "text": "from the trace data is hey our largest customers always hit p99 latency so we",
    "start": "1305120",
    "end": "1310370"
  },
  {
    "text": "cannot just look at 99 we need to probably look at three nines and optimize that and that's one inside we",
    "start": "1310370",
    "end": "1315440"
  },
  {
    "text": "got out of it right and then the other thing we found interesting answers to is",
    "start": "1315440",
    "end": "1322040"
  },
  {
    "text": "we have these API calls for IDR so slack provides this feature called",
    "start": "1322040",
    "end": "1328190"
  },
  {
    "text": "international data residency we data is actually spread across for legal",
    "start": "1328190",
    "end": "1334830"
  },
  {
    "text": "reasons some customers want the data in a specific geographic region so when we",
    "start": "1334830",
    "end": "1339990"
  },
  {
    "text": "launched this feature generally when you launch features like this where you keep the data in a different DG or graphic",
    "start": "1339990",
    "end": "1346500"
  },
  {
    "text": "region and it's in a different AWS data center any slowness is generally attributed to this like cross region",
    "start": "1346500",
    "end": "1352980"
  },
  {
    "text": "cause right we really don't have data from matrix and logs to really prove one way or the other whether it is the case",
    "start": "1352980",
    "end": "1358950"
  },
  {
    "text": "or not but with traces we could prove whether how slow the idea calls were",
    "start": "1358950",
    "end": "1365070"
  },
  {
    "text": "making the actual endpoint calls for example if the idea calls adds 100 milliseconds of latency right a cross",
    "start": "1365070",
    "end": "1371490"
  },
  {
    "text": "region call if the overall call takes 4 seconds that hundred milliseconds is not",
    "start": "1371490",
    "end": "1377520"
  },
  {
    "text": "optimizing that 100 milliseconds or blaming it is not going to help right so",
    "start": "1377520",
    "end": "1382559"
  },
  {
    "text": "it has helped us I didn't compare in region queries with cross region queries",
    "start": "1382559",
    "end": "1388140"
  },
  {
    "text": "to know whether the additional latency we are seeing for idea customers is because we are making that network hop",
    "start": "1388140",
    "end": "1394799"
  },
  {
    "text": "across the region or not similarly for our ekm customers which is like basically encrypted slack messages",
    "start": "1394799",
    "end": "1402500"
  },
  {
    "text": "we can also say whether there's latency for API requests is coming from our slow",
    "start": "1402500",
    "end": "1408030"
  },
  {
    "text": "customers the third bit where we use traces very heavily is I mean one of the",
    "start": "1408030",
    "end": "1415620"
  },
  {
    "text": "biggest problems with tracing is you have to like trace your requests across the stack right but a slack desktop",
    "start": "1415620",
    "end": "1422429"
  },
  {
    "text": "client uses WebSockets if you do a network console you would see it so we",
    "start": "1422429",
    "end": "1427679"
  },
  {
    "text": "use WebSockets so we did we maintain a persistent connection with some edge network and one of the interesting",
    "start": "1427679",
    "end": "1433740"
  },
  {
    "text": "things is we look traces are not very well suited for tracking a request through those through WebSockets and so",
    "start": "1433740",
    "end": "1442230"
  },
  {
    "text": "what we did was we model the WebSocket state as a trace in itself and we have a",
    "start": "1442230",
    "end": "1449429"
  },
  {
    "text": "client trace and a server trace right and what we did with this is now because",
    "start": "1449429",
    "end": "1455159"
  },
  {
    "text": "it's sequel we could ask hey this request is this customer is experiencing slowness easy because he is in degraded",
    "start": "1455159",
    "end": "1461460"
  },
  {
    "text": "mode right because is a state of the websocket and if the",
    "start": "1461460",
    "end": "1467310"
  },
  {
    "text": "websocket network is down we go to the back end but because we have a client state and we have this degraded mode we",
    "start": "1467310",
    "end": "1473910"
  },
  {
    "text": "can mix and match independent requests right like the state of WebSocket is not",
    "start": "1473910",
    "end": "1480330"
  },
  {
    "text": "even a trace it's not part of any request but yet we could take this data makes it with our trace data in a sequel",
    "start": "1480330",
    "end": "1486330"
  },
  {
    "text": "query and ask is this low because uh because the customer is running integrated mode or not right so we were",
    "start": "1486330",
    "end": "1492570"
  },
  {
    "text": "able to get some unique insights which were not possible if we couldn't access this trace data as raw data before and",
    "start": "1492570",
    "end": "1501890"
  },
  {
    "start": "1500000",
    "end": "1589000"
  },
  {
    "text": "in future we want to build a canonical instrumentation based on trace data as I",
    "start": "1501890",
    "end": "1507540"
  },
  {
    "text": "said like we were able to ask a lot of questions about the trace data that we couldn't ask before so what we want to",
    "start": "1507540",
    "end": "1514110"
  },
  {
    "text": "do going forward at slack is we want to make the the trace data as the default",
    "start": "1514110",
    "end": "1521610"
  },
  {
    "text": "canonical instrumentation so when we launched a new feature without adding any additional instrumentation we want",
    "start": "1521610",
    "end": "1527340"
  },
  {
    "text": "the trace data to answer basic questions about the health and performance of our application and we are also going",
    "start": "1527340",
    "end": "1533970"
  },
  {
    "text": "towards end-to-end tracing where we want to start where we are starting to trace the fly we start the trace on your",
    "start": "1533970",
    "end": "1539850"
  },
  {
    "text": "client so when you send a message we trace it all the way to the database call I had a demo plan but because of",
    "start": "1539850",
    "end": "1546720"
  },
  {
    "text": "this party network I didn't like show it and we also add an auto analytics tag on",
    "start": "1546720",
    "end": "1553020"
  },
  {
    "text": "our span we're in the data warehouse if a span has that we automatically",
    "start": "1553020",
    "end": "1558240"
  },
  {
    "text": "generate the automatically generate custom analytics for users without users",
    "start": "1558240",
    "end": "1564330"
  },
  {
    "text": "having to do anything other than just say that this pan has this tag right in future we want to open-source the",
    "start": "1564330",
    "end": "1569580"
  },
  {
    "text": "system and using this system we want to bridge the gap between events logs and",
    "start": "1569580",
    "end": "1575220"
  },
  {
    "text": "traces we also want to at some point investigate like a more concise query",
    "start": "1575220",
    "end": "1581610"
  },
  {
    "text": "language for querying this data because right now sequel is honestly verbose if you have a lot of nested calls and to",
    "start": "1581610",
    "end": "1591180"
  },
  {
    "start": "1589000",
    "end": "1634000"
  },
  {
    "text": "summarize we I believe that querying trace data as raw data is extremely",
    "start": "1591180",
    "end": "1596700"
  },
  {
    "text": "powerful it'll unlock a lot more use cases from your trace data and it'll be extremely",
    "start": "1596700",
    "end": "1602639"
  },
  {
    "text": "valuable I think and the span event is actually a simplified span format that",
    "start": "1602639",
    "end": "1608940"
  },
  {
    "text": "we designed to allow querying traces as raw data sequel is a powerful tool to",
    "start": "1608940",
    "end": "1614279"
  },
  {
    "text": "query these pans and we have put all of these ideas together in feed tracing or",
    "start": "1614279",
    "end": "1620070"
  },
  {
    "text": "slack trace and it works well previously if I built a tracing system I had to knock on every team's door and say hey",
    "start": "1620070",
    "end": "1626519"
  },
  {
    "text": "like please use tracing it'll be very useful now people knock on my door so I consider that a success and ask so this",
    "start": "1626519",
    "end": "1636359"
  },
  {
    "start": "1634000",
    "end": "2014000"
  },
  {
    "text": "is the team that helped me support hand build our team so and thank you for",
    "start": "1636359",
    "end": "1641820"
  },
  {
    "text": "giving me this opportunity and yeah we are hiring so if anybody wants to join",
    "start": "1641820",
    "end": "1647039"
  },
  {
    "text": "thank you we've got time for a couple",
    "start": "1647039",
    "end": "1654359"
  },
  {
    "text": "questions but first is Minea Abdi here",
    "start": "1654359",
    "end": "1659450"
  },
  {
    "text": "right there okay great we're gonna get you set up in the back with a with a",
    "start": "1659450",
    "end": "1667739"
  },
  {
    "text": "audio you see him waving his hand over there okay thanks okay questions",
    "start": "1667739",
    "end": "1674389"
  },
  {
    "text": "questions right there",
    "start": "1674389",
    "end": "1677749"
  },
  {
    "text": "hi one of my question is what kind of data were restoring and data warehouse",
    "start": "1682679",
    "end": "1688809"
  },
  {
    "text": "as if it was pans or do you have your own if the so I showed you a span event",
    "start": "1688809",
    "end": "1693879"
  },
  {
    "text": "format right yeah the data in honeycomb and the data and data warehouse is exactly the same okay yeah there is no",
    "start": "1693879",
    "end": "1699730"
  },
  {
    "text": "difference so my other question is you're trying to replicate the data in honeycomb as well as your data warehouse",
    "start": "1699730",
    "end": "1706230"
  },
  {
    "text": "don't you see it as an additional cost it is but data for data warehouse is",
    "start": "1706230",
    "end": "1711669"
  },
  {
    "text": "presto so it's mostly the data stored on s3 and we only query it on demand so the",
    "start": "1711669",
    "end": "1718000"
  },
  {
    "text": "storage costs are low we get infinite retention because of our data warehouse whereas the data in honeycomb is only",
    "start": "1718000",
    "end": "1724659"
  },
  {
    "text": "for like a couple of weeks at this point and it's only it's used for like so the",
    "start": "1724659",
    "end": "1731409"
  },
  {
    "text": "way we think about honeycomb versus data warehouse is data way honeycomb for recent data short interactive queries",
    "start": "1731409",
    "end": "1737549"
  },
  {
    "text": "data warehouse for complex analytics over long time ranges of data okay and I",
    "start": "1737549",
    "end": "1743019"
  },
  {
    "text": "also see that you have used a pin yeah so what is it back-end that you have used yes elastic search elastic search I",
    "start": "1743019",
    "end": "1759929"
  },
  {
    "text": "guess one questions because you're doing a lot of analysis on the data right and I noticed you're doing one to two",
    "start": "1759929",
    "end": "1766960"
  },
  {
    "text": "percent sampling of your trace data right I guess the question is how you",
    "start": "1766960",
    "end": "1772809"
  },
  {
    "text": "know can you tell the data statistically robust rate since you're only yeah so",
    "start": "1772809",
    "end": "1778379"
  },
  {
    "text": "yeah great question so what we actually do is okay the way we do sampling is",
    "start": "1778379",
    "end": "1785080"
  },
  {
    "text": "different so we have a one percent based sampling rate which is the sampling rate that always happens right the additional",
    "start": "1785080",
    "end": "1793269"
  },
  {
    "text": "one percent is actually our C II person or some team turns on tracing for a",
    "start": "1793269",
    "end": "1799659"
  },
  {
    "text": "specific team or for a specific customer or specific request so as a result from",
    "start": "1799659",
    "end": "1804879"
  },
  {
    "text": "the one person sampling we get like a general idea of how things are going or what kind of things our systems are do",
    "start": "1804879",
    "end": "1812650"
  },
  {
    "text": "and from the additional 1% we get the specific data so the beauty of ours is like this tired sampling is generally",
    "start": "1812650",
    "end": "1819670"
  },
  {
    "text": "tracing is like sampled and then you don't get a specific request so with our sampling scenario we handle both",
    "start": "1819670",
    "end": "1826900"
  },
  {
    "text": "specifics as well as generic requests so",
    "start": "1826900",
    "end": "1832530"
  },
  {
    "text": "so to answer your question the specifics help if it's a specific problem and the",
    "start": "1832530",
    "end": "1837850"
  },
  {
    "text": "base sampling helps with general things like hey how does the chart message get",
    "start": "1837850",
    "end": "1844270"
  },
  {
    "text": "processed for a large customer yeah one request from like a day is good enough",
    "start": "1844270",
    "end": "1851040"
  },
  {
    "text": "right one more question over here and actually while we take that question if",
    "start": "1851580",
    "end": "1857200"
  },
  {
    "text": "we could maybe get you set up so you can keep that mic on big round of applause",
    "start": "1857200",
    "end": "1875830"
  },
  {
    "text": "that was a great talk really appreciate it but don't go too far because we got a",
    "start": "1875830",
    "end": "1880990"
  },
  {
    "text": "question here okay",
    "start": "1880990",
    "end": "1888250"
  },
  {
    "text": "yeah really interesting talk I just have a question so you talked about 1% sampling but now you have these",
    "start": "1888250",
    "end": "1894250"
  },
  {
    "text": "interesting sequel queries that you can use have you thought or are you thinking",
    "start": "1894250",
    "end": "1900130"
  },
  {
    "text": "about perhaps making some of these queries that become interesting like standing queries on on more than one",
    "start": "1900130",
    "end": "1906910"
  },
  {
    "text": "percent such that the traces that are filtered by the queries yeah yeah dori",
    "start": "1906910",
    "end": "1913300"
  },
  {
    "text": "somewhere yeah we can actually filter our traces by to say that hey like tell me all the sequel queries that are",
    "start": "1913300",
    "end": "1920260"
  },
  {
    "text": "actually this query and then we can actually filter our traces by that but",
    "start": "1920260",
    "end": "1926170"
  },
  {
    "text": "this is currently on the 1% that you already stored right yeah general query",
    "start": "1926170",
    "end": "1931510"
  },
  {
    "text": "we can do that but if it's a specific query we trace those specific requests",
    "start": "1931510",
    "end": "1937660"
  },
  {
    "text": "so generally we turn on tracing when we launched a new feature along new paths or something so that's a use case for",
    "start": "1937660",
    "end": "1943840"
  },
  {
    "text": "those specific queries generally right yeah thanks yeah you got a quick",
    "start": "1943840",
    "end": "1955790"
  },
  {
    "text": "one where's this coming from yeah why not wanna assume on so if",
    "start": "1955790",
    "end": "1964970"
  },
  {
    "text": "you're just taking 1% yeah if you have a long tailed distribution you're not gonna really get a sense of what the",
    "start": "1964970",
    "end": "1970250"
  },
  {
    "text": "application latency distribution is so yes we don't but we have metrics and log",
    "start": "1970250",
    "end": "1976280"
  },
  {
    "text": "we have matrix for that so if you need precision we go to matrix and that is actually more efficient from a",
    "start": "1976280",
    "end": "1983110"
  },
  {
    "text": "instrumentation perspective from a storage perspective and a cost perspective but would you build to get",
    "start": "1983110",
    "end": "1989150"
  },
  {
    "text": "the correlation that you did if you only taking 1% the one you just mentioned it so generally one person works out very",
    "start": "1989150",
    "end": "1994700"
  },
  {
    "text": "well yeah I mean X scale of course over a period of time okay yeah this sounds",
    "start": "1994700",
    "end": "2001420"
  },
  {
    "text": "like a birds of a feather session in the making sampling went in how to do it and why",
    "start": "2001420",
    "end": "2009150"
  },
  {
    "text": "okay oh good okay another round of applause that was excellent",
    "start": "2009150",
    "end": "2015450"
  }
]
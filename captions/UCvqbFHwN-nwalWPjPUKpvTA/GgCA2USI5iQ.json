[
  {
    "text": "okay let's get started thank you everyone for joining us today welcome to today's",
    "start": "1360",
    "end": "6960"
  },
  {
    "text": "cncf webinar kubernetes network modules why is this so dang hard i'm jerry",
    "start": "6960",
    "end": "13679"
  },
  {
    "text": "fallon and i'll be moderating today's webinar i'd like to welcome our presenter today tim hawkin principal software engineer",
    "start": "13679",
    "end": "20160"
  },
  {
    "text": "at google just a few housekeeping items before we get started during the webinar you are not able to talk as an attendee",
    "start": "20160",
    "end": "26640"
  },
  {
    "text": "there is a q a box at the bottom of your screen please feel free to drop in your your questions in there and we'll get to",
    "start": "26640",
    "end": "32960"
  },
  {
    "text": "as many as we can at the end this is an official webinar of the cncf and as such is subject to the cncf code",
    "start": "32960",
    "end": "38719"
  },
  {
    "text": "of conduct please do not add anything to the chat or questions that would be in violation of the code of conduct",
    "start": "38719",
    "end": "44160"
  },
  {
    "text": "in short please be respectful of your fellow participants and presenters please also note that the recording and",
    "start": "44160",
    "end": "49280"
  },
  {
    "text": "slides will be posted later today to the cncf webinar page at cncf dot io webinars",
    "start": "49280",
    "end": "55520"
  },
  {
    "text": "and with that i'll hand it over to tim to kick off today's presentation take it away",
    "start": "55520",
    "end": "60960"
  },
  {
    "text": "thanks so much for the introduction uh i am excited to be here today i am talking",
    "start": "61520",
    "end": "67600"
  },
  {
    "text": "about one of my favorite topics which is networking and kubernetes uh this is this is a problem that has",
    "start": "67600",
    "end": "74320"
  },
  {
    "text": "plagued a lot of people for a long time uh and people still five years after the interaction",
    "start": "74320",
    "end": "80400"
  },
  {
    "text": "kubernetes are still wrestling with the model of how it works and how to integrate it so",
    "start": "80400",
    "end": "86320"
  },
  {
    "text": "i a few weeks ago i prepared some slides just for a reading uh and they got tens of thousands of",
    "start": "86320",
    "end": "93360"
  },
  {
    "text": "views and i thought it was really interesting so i would present them here today",
    "start": "93360",
    "end": "101520"
  },
  {
    "text": "so before i jump into that let me introduce myself my name is tim",
    "start": "101520",
    "end": "108000"
  },
  {
    "text": "i work at google on kubernetes and gke and related projects i was part of the",
    "start": "108000",
    "end": "113119"
  },
  {
    "text": "original kubernetes team uh i've been working on it since before it was open sourced uh as tends to happen with projects like",
    "start": "113119",
    "end": "119680"
  },
  {
    "text": "that somebody had to to do the networking and i drew the short straw so i mostly pay attention to things like",
    "start": "119680",
    "end": "126799"
  },
  {
    "text": "networking storage nodes multi-cluster lower level topics within the system",
    "start": "126799",
    "end": "131840"
  },
  {
    "text": "um but today we're going to be focusing on the network model so what do i",
    "start": "131840",
    "end": "138160"
  },
  {
    "text": "what do i mean by the network model so let's go back to basics a little bit",
    "start": "138160",
    "end": "144400"
  },
  {
    "text": "when you have a kubernetes cluster it is a bunch of machines and we",
    "start": "144400",
    "end": "150560"
  },
  {
    "text": "tend to think of it in terms of virtual machines but the truth is it doesn't really matter i don't care if they're virtual or physical",
    "start": "150560",
    "end": "156000"
  },
  {
    "text": "uh those machines are plugged into some some network right this makes sense this shouldn't be surprising to anybody",
    "start": "156000",
    "end": "163200"
  },
  {
    "text": "this is standard machine stuff the those machines we call nodes and we run our workloads",
    "start": "163200",
    "end": "170160"
  },
  {
    "text": "pods on those nodes kubernetes is interesting because pods get ip addresses",
    "start": "170160",
    "end": "176000"
  },
  {
    "text": "so pods 10 the question that we have here is how do pods get those ip addresses and",
    "start": "176000",
    "end": "181200"
  },
  {
    "text": "how do they integrate with the rest of the network",
    "start": "181200",
    "end": "186640"
  },
  {
    "text": "i suspect i've already lost some folks and which is why we're going to dive deep on this stuff today",
    "start": "187120",
    "end": "194959"
  },
  {
    "text": "so let's go even further back to the core principles of the kubernetes networking",
    "start": "194959",
    "end": "200879"
  },
  {
    "text": "fundamentals there are basically two rules for kubernetes integrations one",
    "start": "200879",
    "end": "206879"
  },
  {
    "text": "all pods on a given node can communicate with all other pods on all nodes without nat don't worry if",
    "start": "206879",
    "end": "213760"
  },
  {
    "text": "that doesn't resonate for you yet we'll walk through it uh and rule two agents on a node",
    "start": "213760",
    "end": "219599"
  },
  {
    "text": "for example system demons can communicate with all the pods on that node and that's",
    "start": "219599",
    "end": "224879"
  },
  {
    "text": "so that we can do things like health checks and and uh system management agents i'm going to focus less on that today",
    "start": "224879",
    "end": "232959"
  },
  {
    "text": "so let's walk through what it means for all pods to be able to talk to all other pods without nat so let's start with what we think of as",
    "start": "233040",
    "end": "240560"
  },
  {
    "text": "a quote normal cluster so",
    "start": "240560",
    "end": "245599"
  },
  {
    "text": "we start with a network in this case we're looking at the 10.8 network which",
    "start": "245599",
    "end": "251599"
  },
  {
    "text": "is rfc 1918 private space and almost everybody uses for their private networks because it's",
    "start": "251599",
    "end": "258000"
  },
  {
    "text": "pretty large within that network i'm going to carve",
    "start": "258000",
    "end": "263600"
  },
  {
    "text": "off a chunk of ip space for the cluster now in this case i'm",
    "start": "263600",
    "end": "268960"
  },
  {
    "text": "carving off a slash 16 which is 64 thousand i p 164 k ip addresses",
    "start": "268960",
    "end": "274960"
  },
  {
    "text": "uh it's important to note it is not required that a cluster be a single ip range and",
    "start": "274960",
    "end": "281120"
  },
  {
    "text": "in fact we're seeing more and more users today who are not doing it this way",
    "start": "281120",
    "end": "286320"
  },
  {
    "text": "but it's very common and historically that is how people have done it and it makes my pictures a whole lot easier",
    "start": "286320",
    "end": "292880"
  },
  {
    "text": "so let's go back to this picture so we've got a cluster space carved out in this case i'm carving out 10 0 0 0",
    "start": "292880",
    "end": "300000"
  },
  {
    "text": "for our cluster now within that cluster i've got two nodes and those",
    "start": "300000",
    "end": "306000"
  },
  {
    "text": "nodes get their own ip addresses and those ip addresses come from that come from the larger network i want",
    "start": "306000",
    "end": "313120"
  },
  {
    "text": "to pause on that how the nodes get the ip addresses we'll come back to that in a little bit but for now each node gets an ip address",
    "start": "313120",
    "end": "320080"
  },
  {
    "text": "which again shouldn't be very surprising to anybody here's the fun part each node also gets",
    "start": "320080",
    "end": "326960"
  },
  {
    "text": "a carve out from the cluster's space for the pods that will run on each node in this example i've shown",
    "start": "326960",
    "end": "335680"
  },
  {
    "text": "that two nodes are each taking a slash 24 which is 256 ip addresses which is a lot",
    "start": "335680",
    "end": "343120"
  },
  {
    "text": "and again you don't have to give every node 24 but it's easy for the pictures and",
    "start": "343120",
    "end": "350080"
  },
  {
    "text": "for people to think about in whole whole octets so we're going to run with this for this example",
    "start": "350080",
    "end": "356240"
  },
  {
    "text": "uh as before it's not required that nodes have predefined ip ranges",
    "start": "356240",
    "end": "361600"
  },
  {
    "text": "but it is typically how it is done and it's it's going to make my drawings a lot easier",
    "start": "361600",
    "end": "366800"
  },
  {
    "text": "so we're going to assume that every node has a pre-allocated space this does put a bound on the number of",
    "start": "366800",
    "end": "373840"
  },
  {
    "text": "pods that you can run concurrently on a given node if every pod gets an ip address it's going to be able to only",
    "start": "373840",
    "end": "379600"
  },
  {
    "text": "run 256 the good news is that's a lot so when those pods run each of them",
    "start": "379600",
    "end": "388160"
  },
  {
    "text": "gets an ip address and again i mentioned it's they get it",
    "start": "388160",
    "end": "393840"
  },
  {
    "text": "from the node's ip range not always there are some implementations that get ip addresses via more dynamic mechanisms but this is",
    "start": "393840",
    "end": "400880"
  },
  {
    "text": "how it's usually done and how we usually represent it so again each pod gets an ip address you can see in this case the ip address for",
    "start": "400880",
    "end": "408080"
  },
  {
    "text": "each for each pod comes from the range allocated to each node i hope that's not too confusing so rule",
    "start": "408080",
    "end": "415520"
  },
  {
    "text": "one of kubernetes networking demands that all pods can reach all other pods",
    "start": "415520",
    "end": "420960"
  },
  {
    "text": "this is the fundamental rule this is what enables the kubernetes model to work here's the",
    "start": "420960",
    "end": "428080"
  },
  {
    "text": "rub kubernetes does not guarantee anything about stuff that is outside of the",
    "start": "428080",
    "end": "434000"
  },
  {
    "text": "cluster in short we put up a wall around the cluster and we pretend that things outside the cluster don't",
    "start": "434000",
    "end": "439919"
  },
  {
    "text": "really exist or rather they're not part of the fundamental networking model so if i have a client outside of my",
    "start": "439919",
    "end": "446960"
  },
  {
    "text": "cluster and i want to talk to a pod or a service inside my cluster can i do it how do i do it if i have a",
    "start": "446960",
    "end": "453599"
  },
  {
    "text": "pod in my cluster and i want to reach some other service outside my cluster say an auth server or a database can i do it",
    "start": "453599",
    "end": "461280"
  },
  {
    "text": "again how what happens when i do it this is the stuff that has become very challenging for",
    "start": "461280",
    "end": "468560"
  },
  {
    "text": "people to reason about and it's getting worse because multi-cluster networking",
    "start": "468560",
    "end": "474400"
  },
  {
    "text": "makes this even more confusing if i have two clusters can pods in one cluster reach pods in",
    "start": "474400",
    "end": "480639"
  },
  {
    "text": "the other cluster that seems like might be a useful thing so today what i want to explore",
    "start": "480639",
    "end": "487520"
  },
  {
    "text": "non-exhaustively because there's a million creative things that people have done is how you might think about the sort of",
    "start": "487520",
    "end": "494879"
  },
  {
    "text": "taxonomy of models that people are using for integrating clusters into their network",
    "start": "494879",
    "end": "501520"
  },
  {
    "text": "so let's start with what i call fully integrated mode or flat mode i'm",
    "start": "502160",
    "end": "508400"
  },
  {
    "text": "terrible at naming things so i apologize in advance uh they're just going to get worse from here",
    "start": "508400",
    "end": "514719"
  },
  {
    "text": "so in a flat mode you can see that each node like i showed before has its own ip",
    "start": "514959",
    "end": "520080"
  },
  {
    "text": "address but it gets an ip range from the network uh everyone who's on that broader",
    "start": "520080",
    "end": "526720"
  },
  {
    "text": "network so those clients and those servers the things that i've labeled other here they know how to deal with the fact",
    "start": "526720",
    "end": "533920"
  },
  {
    "text": "that each node has more than one ip address and they they understand that that might be that the routing is",
    "start": "533920",
    "end": "540880"
  },
  {
    "text": "configured statically in the network devices they're top of rack switches or even on each node",
    "start": "540880",
    "end": "546160"
  },
  {
    "text": "or you might use bgp for advertisement uh or it might be configured deep in the fabric",
    "start": "546160",
    "end": "551360"
  },
  {
    "text": "like uh in a cloud environment uh the point is people don't have to think about where",
    "start": "551360",
    "end": "557519"
  },
  {
    "text": "those like addresses are they can just talk to those ip addresses now i called it flat mode and anybody",
    "start": "557519",
    "end": "563760"
  },
  {
    "text": "who's a networking expert is immediately raising their hand um this might be l2 flat it might be l3",
    "start": "563760",
    "end": "569760"
  },
  {
    "text": "flat that is a different discussion and i don't really want to get into that today",
    "start": "569760",
    "end": "574800"
  },
  {
    "text": "there's trade-offs uh i don't want to talk about cni drivers today either really it's it's uh somewhat orthogonal",
    "start": "574800",
    "end": "581519"
  },
  {
    "text": "to the discussion um the main point here is that pods and everything else share an ip space",
    "start": "581519",
    "end": "588560"
  },
  {
    "text": "this makes communications really easy to reason about everything's on the same network",
    "start": "588560",
    "end": "593839"
  },
  {
    "text": "there's no overlapping ip addresses there's no overlay networks there's no magic going on there's no",
    "start": "593839",
    "end": "600160"
  },
  {
    "text": "translation uh this is what kubernetes really wants this is what we designed for and it is achievable in lots of",
    "start": "600160",
    "end": "608480"
  },
  {
    "text": "places in lots of ways for example clouds like google or amazon can implement this directly this",
    "start": "608480",
    "end": "616240"
  },
  {
    "text": "gives you full integration so this is really great when you have a lot of ip space",
    "start": "616240",
    "end": "623600"
  },
  {
    "text": "kubernetes loves ips and we've shown here that we've carved off a slash 16 right that is a lot of ip",
    "start": "623600",
    "end": "629760"
  },
  {
    "text": "space uh it's good when the network is very programmable or dynamic when you have",
    "start": "629760",
    "end": "634959"
  },
  {
    "text": "control over the routing it's great when you need high integration and performance there's no",
    "start": "634959",
    "end": "640480"
  },
  {
    "text": "translations there's no proxies in between the clients and the servers regardless",
    "start": "640480",
    "end": "645519"
  },
  {
    "text": "of where they are um and it's also really good when kubernetes makes up a large part of your footprint right",
    "start": "645519",
    "end": "651200"
  },
  {
    "text": "when you can afford vip space and you can justify it because you're spending a lot of your your budget on kubernetes",
    "start": "651200",
    "end": "659360"
  },
  {
    "text": "not so good when you have ip fragmentation or scarcity of ip",
    "start": "659360",
    "end": "664480"
  },
  {
    "text": "addresses uh you can read that as brown fields uh lots of established companies have already taken",
    "start": "664480",
    "end": "671120"
  },
  {
    "text": "the 10 8 space and carved it up and routed it around their infrastructure generally i don't",
    "start": "671120",
    "end": "677920"
  },
  {
    "text": "mean this in a negative way but somewhat casually with respect to fragmentation and when kubernetes comes in and says",
    "start": "677920",
    "end": "684880"
  },
  {
    "text": "hey i need a slash 16 i need 64 000 ip addresses some network administrators heads",
    "start": "684880",
    "end": "692079"
  },
  {
    "text": "explode it's also not really good when your network infrastructure is very difficult to configure or not very dynamic",
    "start": "692079",
    "end": "699760"
  },
  {
    "text": "or if kubernetes is just a tiny piece of your overall footprint then this may not be the best model for",
    "start": "699760",
    "end": "706399"
  },
  {
    "text": "you at the complete other end of the spectrum we have a model",
    "start": "706399",
    "end": "712800"
  },
  {
    "text": "fully isolated or air gapped mode in this model their networks are",
    "start": "712800",
    "end": "718560"
  },
  {
    "text": "completely disconnected there is no connectivity from inside or outside uh the clients there's no such thing as",
    "start": "718560",
    "end": "724880"
  },
  {
    "text": "a client outside of your cluster reaching into your cluster it just doesn't happen and within your cluster you can still",
    "start": "724880",
    "end": "731200"
  },
  {
    "text": "maintain the kubernetes requirements but between clusters or two other things it doesn't exist",
    "start": "731200",
    "end": "738399"
  },
  {
    "text": "in fact this is an interesting model because you can reuse all of the ip",
    "start": "738560",
    "end": "743839"
  },
  {
    "text": "because everything is completely disconnected there's no reason that you can't allocate the same ip addresses in every",
    "start": "743839",
    "end": "750079"
  },
  {
    "text": "cluster in fact they're basically on different networks",
    "start": "750079",
    "end": "754959"
  },
  {
    "text": "so you can see sort of in this model there is no connectivity they are uh as the expression goes they are air",
    "start": "755279",
    "end": "761600"
  },
  {
    "text": "gap there is nothing connecting them this is really good when you don't need any integration when you have a workload",
    "start": "761600",
    "end": "768240"
  },
  {
    "text": "that needs to run in isolation um it's you know it applies when uh",
    "start": "768240",
    "end": "773279"
  },
  {
    "text": "ipspace is scarce uh we network is not programmable one of the reasons people look at this",
    "start": "773279",
    "end": "778639"
  },
  {
    "text": "model is because they care a lot about security and this makes it much easier to reason about security",
    "start": "778639",
    "end": "784839"
  },
  {
    "text": "boundaries however it doesn't work at all if you need communications across",
    "start": "784839",
    "end": "790639"
  },
  {
    "text": "a cluster edge right so i describe this as one end of the spectrum so let's look at",
    "start": "790639",
    "end": "796639"
  },
  {
    "text": "a point a little closer to the middle where we're going to spend mo",
    "start": "796639",
    "end": "801839"
  },
  {
    "text": "pods within the the cluster get ip addresses from that private network and then there are bridges gateways into",
    "start": "813120",
    "end": "820160"
  },
  {
    "text": "the cluster and out of the cluster uh that are set up by your environment this is a very common model especially",
    "start": "820160",
    "end": "826800"
  },
  {
    "text": "in enterprise world some people have claimed that this is the only way or this is the default way",
    "start": "826800",
    "end": "832639"
  },
  {
    "text": "for kubernetes that i've heard people say quote you have to choose which overlay you're going to use",
    "start": "832639",
    "end": "838000"
  },
  {
    "text": "uh those sorts of statements are false obviously we've looked at two different models already",
    "start": "838000",
    "end": "843279"
  },
  {
    "text": "um that said this is a very very common model in this case ingress and egress traffic",
    "start": "843279",
    "end": "850399"
  },
  {
    "text": "will go through one or more uh quoty fingers gateways we'll talk about gateways in a little in a little bit",
    "start": "850399",
    "end": "858480"
  },
  {
    "text": "this can be implemented via overlays it's very common to use things like vxlan there's a lot of products out",
    "start": "858480",
    "end": "864160"
  },
  {
    "text": "there that will help you set up vxlan overlays but it doesn't have to be it can also be",
    "start": "864160",
    "end": "870240"
  },
  {
    "text": "set up via private uh routing rules right so another common model is to use uh not to use an",
    "start": "870240",
    "end": "877199"
  },
  {
    "text": "overlay encapsulation but to use straight ip addressing um but to use private vgp advertisement so",
    "start": "877199",
    "end": "884000"
  },
  {
    "text": "they're limited and only those nodes in the cluster know about each other",
    "start": "884000",
    "end": "889360"
  },
  {
    "text": "another way to think of this is that your nodes exist with two interfaces with one leg in the",
    "start": "890720",
    "end": "896560"
  },
  {
    "text": "main network and one leg on a private network and they know how to route which traffic",
    "start": "896560",
    "end": "902480"
  },
  {
    "text": "which side this is in fact if you squint how clouds generally treat the internet you have a",
    "start": "902480",
    "end": "909040"
  },
  {
    "text": "private network of vpc which you carefully control traffic into and out of",
    "start": "909040",
    "end": "914800"
  },
  {
    "text": "right so you're applying the same sort of pattern to your kubernetes clusters",
    "start": "914800",
    "end": "920639"
  },
  {
    "text": "in fact in this model you can reuse pod ips in each cluster which is a major",
    "start": "920959",
    "end": "926880"
  },
  {
    "text": "motivation for this model so uh depending on what gateway means for you",
    "start": "926880",
    "end": "932240"
  },
  {
    "text": "you may or may not be able to reuse node ip addresses but node ips are very low count compared to pot ips",
    "start": "932240",
    "end": "939600"
  },
  {
    "text": "right in this example we're looking at 256 times more ip addresses for pods",
    "start": "939600",
    "end": "944959"
  },
  {
    "text": "so here you can see i can use the same pod range for every cluster because pods never directly talk to",
    "start": "944959",
    "end": "951759"
  },
  {
    "text": "other pods they always go through some sort of gateway gateways are going to be translators or",
    "start": "951759",
    "end": "957120"
  },
  {
    "text": "access mechanisms this model is really good when you need",
    "start": "957120",
    "end": "964560"
  },
  {
    "text": "some amount of integration it's not air but it's not complete",
    "start": "964560",
    "end": "969600"
  },
  {
    "text": "it's good when ipspace is scarce or fragmented you can afford node-ip addresses but you can't really",
    "start": "969600",
    "end": "976480"
  },
  {
    "text": "afford the pod ip addresses at least not in giant contiguous chunks one of the things that's happening in",
    "start": "976480",
    "end": "982399"
  },
  {
    "text": "upstream kubernetes right now is making it more uh possible to run your clusters with",
    "start": "982399",
    "end": "988160"
  },
  {
    "text": "less monolithic chunks which will take away some of the value of this model which i think is a good",
    "start": "988160",
    "end": "994160"
  },
  {
    "text": "thing this is also good when your network is not very programmable or dynamic right and so you can plug it in and to",
    "start": "994160",
    "end": "1001839"
  },
  {
    "text": "the rest of the network you seem to have some number of vms or machines",
    "start": "1001839",
    "end": "1007120"
  },
  {
    "text": "nodes and that's it it's not so good when you have to debug",
    "start": "1007120",
    "end": "1013600"
  },
  {
    "text": "connectivity when you're bringing traffic in through a gateway uh traffic gets necessarily more complicated",
    "start": "1013600",
    "end": "1018880"
  },
  {
    "text": "there's gonna be some form of translation and you need to figure out what is happening there it becomes much harder to reason about",
    "start": "1018880",
    "end": "1025120"
  },
  {
    "text": "uh what exactly is happening it's also not very good if you need direct to endpoint",
    "start": "1025120",
    "end": "1030319"
  },
  {
    "text": "communications there are some systems out there that assume that clients can talk directly to their",
    "start": "1030319",
    "end": "1036000"
  },
  {
    "text": "endpoints they don't use things like load balancers and if you need those direct",
    "start": "1036000",
    "end": "1041038"
  },
  {
    "text": "communications then this gateway model starts to break down it's also problematic if you need a lot",
    "start": "1041039",
    "end": "1048160"
  },
  {
    "text": "of services exposed the gateways can be complicated or sometimes expensive",
    "start": "1048160",
    "end": "1053360"
  },
  {
    "text": "especially if you're not using http where you can reuse ip addresses if you're using layer 4",
    "start": "1053360",
    "end": "1060160"
  },
  {
    "text": "services like tcp or udp but not http you can end up requiring a lot of infrastructure to bring traffic in and",
    "start": "1060160",
    "end": "1066799"
  },
  {
    "text": "out it's also not so good when you are relying on client ip addresses for",
    "start": "1066799",
    "end": "1073120"
  },
  {
    "text": "firewalls which is a fairly common thing to do especially in larger companies where you",
    "start": "1073120",
    "end": "1078799"
  },
  {
    "text": "say look only these ip addresses are allowed to access my database well those gateways uh become more",
    "start": "1078799",
    "end": "1085039"
  },
  {
    "text": "complicated now because you have a limited number of them and it can also",
    "start": "1085039",
    "end": "1090080"
  },
  {
    "text": "be problematic if you have a large number of nodes because things like overlays",
    "start": "1090080",
    "end": "1095280"
  },
  {
    "text": "and uh route advertisement tend to scale poorly and you need to get more and more",
    "start": "1095280",
    "end": "1100880"
  },
  {
    "text": "infrastructure as you get larger so i seem to have painted that model in",
    "start": "1100880",
    "end": "1106880"
  },
  {
    "text": "a bad light but it is a very common model so i want to dig in more into what gateway really means",
    "start": "1106880",
    "end": "1115039"
  },
  {
    "text": "so here's the simplest form of gateway you use your nodes as the gateways in this model all the",
    "start": "1115200",
    "end": "1122240"
  },
  {
    "text": "traffic into or out of the cluster is done explicitly by the nodes in the cluster there's no uh",
    "start": "1122240",
    "end": "1127679"
  },
  {
    "text": "extra load balancers or or routers or anything else here um the traffic comes through",
    "start": "1127679",
    "end": "1135200"
  },
  {
    "text": "the node so this is like i said the nodes have uh one leg in the main network which would",
    "start": "1135200",
    "end": "1140320"
  },
  {
    "text": "be their uh node ip address here the the 10 to 40 network uh and",
    "start": "1140320",
    "end": "1145679"
  },
  {
    "text": "they have another interface in the pod network which is the 10 0 network",
    "start": "1145679",
    "end": "1151840"
  },
  {
    "text": "so in in this case i'm going to take this apart even further and talk about how exactly ingressing",
    "start": "1152960",
    "end": "1158480"
  },
  {
    "text": "risk works here so let's talk about ingress first so",
    "start": "1158480",
    "end": "1163760"
  },
  {
    "text": "service node ports is something anybody who's played with kubernetes is probably run up against and try to figure out if",
    "start": "1163760",
    "end": "1169840"
  },
  {
    "text": "they can make do what they want um and it's a confusing mechanism so i'm gonna",
    "start": "1169840",
    "end": "1175120"
  },
  {
    "text": "dig into it even a little bit further in the case of a service node port you",
    "start": "1175120",
    "end": "1180240"
  },
  {
    "text": "have a client here 128.1.1 it's sending a packet that packet",
    "start": "1180240",
    "end": "1186880"
  },
  {
    "text": "as it transits is targeted at a node ip address remember the",
    "start": "1186880",
    "end": "1193760"
  },
  {
    "text": "uh the client only knows node ip addresses and not pod id addresses so hopefully you have a",
    "start": "1193760",
    "end": "1200080"
  },
  {
    "text": "service that is load balanced or or is only a single instance because i'm sending it to a port on the node",
    "start": "1200080",
    "end": "1206960"
  },
  {
    "text": "it doesn't really matter which node because node ports exist on all of the nodes so you need some mechanism",
    "start": "1206960",
    "end": "1212720"
  },
  {
    "text": "to figure out where you're going to send it into those nodes which is a slightly different conversation but let's assume you have",
    "start": "1212720",
    "end": "1220000"
  },
  {
    "text": "a dns or something and it's going to tell you that the service you're looking for is",
    "start": "1220000",
    "end": "1225120"
  },
  {
    "text": "available on these nodes at this port and the port in a service",
    "start": "1225120",
    "end": "1230400"
  },
  {
    "text": "node port isn't arbitrary you don't get to choose port 80. kubernetes generally manages those",
    "start": "1230400",
    "end": "1235600"
  },
  {
    "text": "ports for you and it uses them uses a high port range to",
    "start": "1235600",
    "end": "1241280"
  },
  {
    "text": "generally avoid conflict so you'll see ports in the 30 000 range so here my client is talking to port",
    "start": "1241280",
    "end": "1247520"
  },
  {
    "text": "something you know 30 000 something on one of the nodes",
    "start": "1247520",
    "end": "1253039"
  },
  {
    "text": "when it arrives at the node the node is going to use the destination port of the ip packet to figure out",
    "start": "1253280",
    "end": "1260559"
  },
  {
    "text": "which service you're talking to so if you're talking to port 3001 you might be going to service foo",
    "start": "1260559",
    "end": "1266400"
  },
  {
    "text": "and if you're talking to port 3002 you're going to service bar and it's going to do a destination",
    "start": "1266400",
    "end": "1273360"
  },
  {
    "text": "network address translation or dnat and it's going to pick one of the back",
    "start": "1273360",
    "end": "1278880"
  },
  {
    "text": "ends that it understands as being part of service foo or service bar depending on which court it came in",
    "start": "1278880",
    "end": "1284799"
  },
  {
    "text": "and it's going to rewrite that ip packet the most common implementation is iptables but we also have",
    "start": "1284799",
    "end": "1290000"
  },
  {
    "text": "implementations now in ipvs and nf tables and evpf",
    "start": "1290000",
    "end": "1295039"
  },
  {
    "text": "uh who are all able to perform the same basic logic we're going to forward that packet and linux is actually quite good at this",
    "start": "1295039",
    "end": "1302000"
  },
  {
    "text": "so it'll forward the packet uh onto the destination pod that we wanted to it to arrive at note",
    "start": "1302000",
    "end": "1308880"
  },
  {
    "text": "here the client didn't choose which pod it's talking to it just talked to the port",
    "start": "1308880",
    "end": "1316158"
  },
  {
    "text": "and i'm sorry i'm seeing a chat in there an audio problem uh i don't know how to",
    "start": "1316840",
    "end": "1324559"
  },
  {
    "text": "fix it um so i'm gonna press on i'll try to get",
    "start": "1324559",
    "end": "1332400"
  },
  {
    "text": "a little closer to the mic the packet arrives at the destination pod now",
    "start": "1332400",
    "end": "1338640"
  },
  {
    "text": "so one of the common things that people do is they will ingress traffic into an l7",
    "start": "1338640",
    "end": "1345600"
  },
  {
    "text": "proxy what what does that mean uh they'll run something like envoy or nginx or aj proxy",
    "start": "1345600",
    "end": "1353200"
  },
  {
    "text": "inside their cluster they will route all the traffic through a node port into that and use",
    "start": "1353200",
    "end": "1359600"
  },
  {
    "text": "that to do further forwarding things like http are wonderful because they have",
    "start": "1359600",
    "end": "1365280"
  },
  {
    "text": "headers that you can use to tell what did you actually mean what host were you actually looking for",
    "start": "1365280",
    "end": "1370799"
  },
  {
    "text": "this is for example the in cluster ingress controllers that many people run",
    "start": "1370799",
    "end": "1376960"
  },
  {
    "text": "so again going back to this diagram you can see once it's arrived at that pod i can do",
    "start": "1376960",
    "end": "1382720"
  },
  {
    "text": "anything i want with it on the reverse path the host is going to do the opposite of that dnat translation",
    "start": "1382720",
    "end": "1390080"
  },
  {
    "text": "and it's going to convert the packet back so when your original client",
    "start": "1390080",
    "end": "1395280"
  },
  {
    "text": "gets the the response uh when the packet gets through when the",
    "start": "1395280",
    "end": "1400960"
  },
  {
    "text": "client gets the response it seems to come from the nodes node port that it was",
    "start": "1400960",
    "end": "1406080"
  },
  {
    "text": "talking to originally so the client is happy and the pods are happy and everybody's happy",
    "start": "1406080",
    "end": "1412159"
  },
  {
    "text": "except if you cared about some of the finer details which we'll get into in a",
    "start": "1412159",
    "end": "1417200"
  },
  {
    "text": "bit so looking at the egress side right if i want to send",
    "start": "1417200",
    "end": "1423120"
  },
  {
    "text": "traffic from my cluster to something else uh we often call this snap source nat um the typical model",
    "start": "1423120",
    "end": "1430720"
  },
  {
    "text": "here is to use what linux calls ip masquerade what ip masquerade does is it says that",
    "start": "1430720",
    "end": "1437520"
  },
  {
    "text": "uh traffic leaving this node this machine is going to look like it came from this",
    "start": "1437520",
    "end": "1443520"
  },
  {
    "text": "machine so when i've got my client inside the cluster and i want to send traffic out of my cluster",
    "start": "1443520",
    "end": "1449200"
  },
  {
    "text": "we send the packet out when it reaches the edge of the node it's going to translate",
    "start": "1449200",
    "end": "1457600"
  },
  {
    "text": "into the node's ip address so all the traffic from that node appears to come",
    "start": "1457600",
    "end": "1463520"
  },
  {
    "text": "from that nodes ip if you were tcp dumping it you would see the source address as the",
    "start": "1463520",
    "end": "1470400"
  },
  {
    "text": "the node 2 in the first cluster now because we're doing ingress and",
    "start": "1470400",
    "end": "1476960"
  },
  {
    "text": "egress through nodes when it arrives at the destination cluster what we saw happening with node",
    "start": "1476960",
    "end": "1482720"
  },
  {
    "text": "port is also going to happen and so now you have a packet whose source address and destination",
    "start": "1482720",
    "end": "1488559"
  },
  {
    "text": "address have both been modified it's got two translations along the way this is the cost of of these gateways",
    "start": "1488559",
    "end": "1495520"
  },
  {
    "text": "and it eventually is delivered to the node and as before when it responds it's going to",
    "start": "1495520",
    "end": "1502080"
  },
  {
    "text": "go back through those translations in reverse and the pods themselves aren't really",
    "start": "1502080",
    "end": "1507600"
  },
  {
    "text": "aware of what happened with the packets the network fabric happened",
    "start": "1507600",
    "end": "1512720"
  },
  {
    "text": "handled it all for you there's a different model though which",
    "start": "1512720",
    "end": "1518000"
  },
  {
    "text": "uses a virtual ip address and this is used in uh in some cloud providers",
    "start": "1518000",
    "end": "1524080"
  },
  {
    "text": "to provide a slightly different model instead of having to know about",
    "start": "1524080",
    "end": "1529120"
  },
  {
    "text": "a node which node and which node port to use which is kind of a clunky",
    "start": "1529120",
    "end": "1534240"
  },
  {
    "text": "human interface we give you a virtual ip address and that virtual ip address represents a",
    "start": "1534240",
    "end": "1540640"
  },
  {
    "text": "service in your kubernetes cluster it's very similar to node port",
    "start": "1540640",
    "end": "1545760"
  },
  {
    "text": "but instead of using the destination port we're going to use the destination ip to make those same routing decisions",
    "start": "1545760",
    "end": "1552720"
  },
  {
    "text": "so i'm not going to re-animate the same drawing but the packet will flow through basically the same path",
    "start": "1552720",
    "end": "1558159"
  },
  {
    "text": "it will go through the same sorts of translations but instead of a human having addressed a 30 000",
    "start": "1558159",
    "end": "1565600"
  },
  {
    "text": "port it can address a virtual ip address this is more compatible with things like typical dns and open source",
    "start": "1565600",
    "end": "1572240"
  },
  {
    "text": "software which isn't always easily configured for random arbitrary ports",
    "start": "1572240",
    "end": "1579360"
  },
  {
    "text": "with the egress path you still need something like ip masquerade as snat to uh to egress",
    "start": "1580559",
    "end": "1588240"
  },
  {
    "text": "and there's a slight change just like variant of this model which is a more proxiful way of doing",
    "start": "1588640",
    "end": "1595039"
  },
  {
    "text": "things instead of having a virtual ip address you have an actual proxy the difference here being that",
    "start": "1595039",
    "end": "1601840"
  },
  {
    "text": "the virtual ip typically does not terminate a tcp session it will forward packets",
    "start": "1601840",
    "end": "1607120"
  },
  {
    "text": "and the proxy will terminate a tcp session and open a new session otherwise it's sort of",
    "start": "1607120",
    "end": "1613120"
  },
  {
    "text": "behaviorally very similar again the packet will arrive at the proxy the proxy will choose",
    "start": "1613120",
    "end": "1618320"
  },
  {
    "text": "which back end it's going to go to and will forward the packet one of the interesting things about",
    "start": "1618320",
    "end": "1625200"
  },
  {
    "text": "proxy model is you can either route to a node port which is how kubernetes started with support for",
    "start": "1625200",
    "end": "1631760"
  },
  {
    "text": "example uh amazon uh elbs or it can route directly to pod ip addresses",
    "start": "1631760",
    "end": "1637840"
  },
  {
    "text": "if that proxy is smart enough to know how to get onto the island this is a more modern approach which is",
    "start": "1637840",
    "end": "1645039"
  },
  {
    "text": "very nice the problem here and in many of these models is",
    "start": "1645039",
    "end": "1651360"
  },
  {
    "text": "the mechanism here will obscure the client ip so in this case the proxy because it",
    "start": "1651360",
    "end": "1657360"
  },
  {
    "text": "terminated the original session and opened a new session traffic looks like it's coming from that",
    "start": "1657360",
    "end": "1662480"
  },
  {
    "text": "proxy's ip address so if you have a client assuming if you have a server that needs to understand",
    "start": "1662480",
    "end": "1667840"
  },
  {
    "text": "the client ip address you have to pass it through in some other mechanism again",
    "start": "1667840",
    "end": "1672880"
  },
  {
    "text": "some proxies like elb support things like the proxy protocol which will include a header on a tcp",
    "start": "1672880",
    "end": "1679279"
  },
  {
    "text": "stream if you're using http proxies then you've got ways of encoding it in http headers",
    "start": "1679279",
    "end": "1686960"
  },
  {
    "text": "um if you don't have those things you have a much more difficult time getting the true client ip address",
    "start": "1686960",
    "end": "1695120"
  },
  {
    "text": "and like the vip model you still need something like s nat in order to be able to leave",
    "start": "1695120",
    "end": "1700399"
  },
  {
    "text": "the cluster now i could probably talk for another hour just about ingress in fact i have",
    "start": "1700399",
    "end": "1706880"
  },
  {
    "text": "another slide deck which i tried to merge in here and then realized i was way over time uh that goes into more detail about how",
    "start": "1706880",
    "end": "1714000"
  },
  {
    "text": "these models work and the various trade-offs uh of them and and the uh the actual details of how kubernetes implements",
    "start": "1714000",
    "end": "1720080"
  },
  {
    "text": "them um but i'll have to do that at another webinar",
    "start": "1720080",
    "end": "1725840"
  },
  {
    "text": "the options for egress gateways honestly are very poorly explored so far",
    "start": "1725919",
    "end": "1731120"
  },
  {
    "text": "we've had a lot of discussions but we've not yet seen a lot of interesting",
    "start": "1731120",
    "end": "1736840"
  },
  {
    "text": "implementations so we looked at island mode and",
    "start": "1736840",
    "end": "1743360"
  },
  {
    "text": "uh one of the variants of island mode that we're seeing uh in more usage now is what i call",
    "start": "1743360",
    "end": "1749120"
  },
  {
    "text": "archipelago mode which is uh roughly bigger islands or groups of islands",
    "start": "1749120",
    "end": "1756720"
  },
  {
    "text": "within the archipelago the uh the model is effectively the flat",
    "start": "1757679",
    "end": "1763279"
  },
  {
    "text": "model which means that your multiple clusters can talk to each other without translation uh it",
    "start": "1763279",
    "end": "1770000"
  },
  {
    "text": "means you have a flat space and you carve off a lot of ip within that archipelago but when you",
    "start": "1770000",
    "end": "1776880"
  },
  {
    "text": "integrate it with the rest of network it becomes island mode again like island mode this can be implemented",
    "start": "1776880",
    "end": "1783840"
  },
  {
    "text": "as an overlay or not as an overlay and it still needs gateways to come in and out",
    "start": "1783840",
    "end": "1791840"
  },
  {
    "text": "of this again this could be gateways using the nodes this could be gateways",
    "start": "1791840",
    "end": "1797200"
  },
  {
    "text": "using virtual ip addresses or this could be gateways using proxies or other variants this is",
    "start": "1797200",
    "end": "1803200"
  },
  {
    "text": "not an exhaustive exploration of this but these are the most common patterns that we've seen",
    "start": "1803200",
    "end": "1808799"
  },
  {
    "text": "this is a really attractive model um well sorry backing up you can't reuse ip",
    "start": "1808799",
    "end": "1814399"
  },
  {
    "text": "addresses between clusters but you can between archipelagos so we've seen for example",
    "start": "1814399",
    "end": "1820000"
  },
  {
    "text": "customers who set up an archipelago per cloud region or per data center",
    "start": "1820000",
    "end": "1826159"
  },
  {
    "text": "and they can economize on ip space between those but still have high levels of",
    "start": "1826159",
    "end": "1832399"
  },
  {
    "text": "connectivity within a particular region this is good when you need that high",
    "start": "1832399",
    "end": "1838000"
  },
  {
    "text": "level of integration if you have services like kafka that want",
    "start": "1838000",
    "end": "1843120"
  },
  {
    "text": "direct connections to endpoints it's good when you need some amount of integration with your",
    "start": "1843120",
    "end": "1848480"
  },
  {
    "text": "non-kubernetes environment but that's not maybe the primary driver it's",
    "start": "1848480",
    "end": "1854000"
  },
  {
    "text": "good when ipspace is scarce though it uses more space than plane island mode",
    "start": "1854000",
    "end": "1861519"
  },
  {
    "text": "and it's good when you're less programmable and dynamic",
    "start": "1861519",
    "end": "1866720"
  },
  {
    "text": "like island mode itself uh if you need to debug connectivity between clusters",
    "start": "1867279",
    "end": "1874559"
  },
  {
    "text": "this can get complicated uh if you need those direct-to-end point communications from outside of the archipelago it can",
    "start": "1874559",
    "end": "1882000"
  },
  {
    "text": "be complicated if you need to expose a lot of services to their non-kubernetes environment it",
    "start": "1882000",
    "end": "1889279"
  },
  {
    "text": "can be hard for example node ports by default are limited to about 2000 node ports and we have",
    "start": "1889279",
    "end": "1897440"
  },
  {
    "text": "had actual users of kubernetes who need more it is a configurable flag but it's not",
    "start": "1897440",
    "end": "1902559"
  },
  {
    "text": "something most people configure so if you have large numbers of services it can be a problem",
    "start": "1902559",
    "end": "1908240"
  },
  {
    "text": "um like plane island mode if you're relying on client ips for firewalls it can be problematic",
    "start": "1908240",
    "end": "1913600"
  },
  {
    "text": "um or if you have large numbers of nodes across all of your clusters now your scale limit is",
    "start": "1913600",
    "end": "1918640"
  },
  {
    "text": "the number of nodes in the archipelago instead of the number of nodes in each cluster so",
    "start": "1918640",
    "end": "1924000"
  },
  {
    "text": "you can see there's a real trade-off uh to be made in this model",
    "start": "1924000",
    "end": "1930399"
  },
  {
    "text": "the gateway options are very similar to plane island mode um and so i won't go back into them",
    "start": "1930880",
    "end": "1937039"
  },
  {
    "text": "again but i will look for an opportunity to present more on on ingress and the ingress modes",
    "start": "1937039",
    "end": "1945360"
  },
  {
    "text": "later and i'm hoping that we will soon have the ability to talk more about egress gateways and more egress modes",
    "start": "1945360",
    "end": "1953840"
  },
  {
    "text": "so of course uh you want to know which which one should i use uh and the sad truth is there is no",
    "start": "1953840",
    "end": "1960720"
  },
  {
    "text": "right answer unfortunately uh i don't know your environment uh in the abstract um there's there's no",
    "start": "1960720",
    "end": "1968159"
  },
  {
    "text": "way that i can tell you which one is best they have real trade-offs and i've tried to uh elucidate some of those trade-offs",
    "start": "1968159",
    "end": "1975519"
  },
  {
    "text": "here um but you have to make some value decisions yourself if i could i would wave my",
    "start": "1975519",
    "end": "1983120"
  },
  {
    "text": "magic wand and give everybody ipv6 and then flat mode would not be such a big deal um",
    "start": "1983120",
    "end": "1989120"
  },
  {
    "text": "but that isn't possible yet um and there are other considerations beyond just ip efficiency",
    "start": "1989120",
    "end": "1995360"
  },
  {
    "text": "so uh i'm happy to talk with people about which modes they think make sense for them but there isn't a",
    "start": "1995360",
    "end": "2002000"
  },
  {
    "text": "magical answer so i'd like now uh we're",
    "start": "2002000",
    "end": "2009039"
  },
  {
    "text": "we've got plenty of time for questions i'd like to switch to questions because i think this is uh such a nuanced topic",
    "start": "2009039",
    "end": "2015760"
  },
  {
    "text": "that the details will be fun to talk about okay tim thank you very much for the",
    "start": "2015760",
    "end": "2022159"
  },
  {
    "text": "presentation um we have plenty of time for questions as tim said so if anyone has anything they'd",
    "start": "2022159",
    "end": "2028320"
  },
  {
    "text": "like to ask please drop it into the q a box and we'll get to as many as we can before the end of the hour",
    "start": "2028320",
    "end": "2046000"
  },
  {
    "text": "i see that my audio was really bad i'm so sorry",
    "start": "2046000",
    "end": "2050240"
  },
  {
    "text": "uh i believe they're recording yes the question is will ever record be sure there will be a shared uh recording of",
    "start": "2057359",
    "end": "2062638"
  },
  {
    "text": "this uh i apologize for the audio i will i see in the chat a question uh ways to",
    "start": "2062639",
    "end": "2067760"
  },
  {
    "text": "look over the slides yes i have posted the slides already on",
    "start": "2067760",
    "end": "2072839"
  },
  {
    "text": "my speaker deck so if you go to speakerdeck.com t-h-o-c-k-i-n uh then you can find the",
    "start": "2072839",
    "end": "2080320"
  },
  {
    "text": "slides there uh and i imagine that the cncf um we'll be also posting the slides since",
    "start": "2080320",
    "end": "2086960"
  },
  {
    "text": "we shared them um question can you explain island mode sure so let's let's flip",
    "start": "2086960",
    "end": "2094560"
  },
  {
    "text": "back in there to island mode since this is the uh the most common model that i see",
    "start": "2094560",
    "end": "2099920"
  },
  {
    "text": "for larger enterprises",
    "start": "2099920",
    "end": "2103838"
  },
  {
    "text": "all right so plain old island mode um in this model for example let me just",
    "start": "2114800",
    "end": "2120720"
  },
  {
    "text": "pick on one particular model if you look at the two different clusters",
    "start": "2120720",
    "end": "2126160"
  },
  {
    "text": "you can set up a vxlan overlay for example again this is not the only way to do it",
    "start": "2126160",
    "end": "2131440"
  },
  {
    "text": "just one example instead of a vxlan overlay each of the nodes in that cluster",
    "start": "2131440",
    "end": "2137200"
  },
  {
    "text": "have an agent running that understands how to route vxlan packets",
    "start": "2137200",
    "end": "2143839"
  },
  {
    "text": "and they might get that information by um uh gossip by talking to each other or",
    "start": "2143839",
    "end": "2149839"
  },
  {
    "text": "they might get it through the kubernetes api or through some other configuration mechanism but they all know how to uh route to each other so node",
    "start": "2149839",
    "end": "2157200"
  },
  {
    "text": "one in the top cluster knows that if it needs to talk to the pod c",
    "start": "2157200",
    "end": "2163040"
  },
  {
    "text": "then it's going to encapsulate the packet and forward it on to node two right but it's only between the nodes",
    "start": "2163040",
    "end": "2170079"
  },
  {
    "text": "within that cluster that that information is shared so if uh pod a in the top cluster wants to",
    "start": "2170079",
    "end": "2176720"
  },
  {
    "text": "talk to pod a in the bottom cluster it doesn't know how to get there and that's why it's called an island",
    "start": "2176720",
    "end": "2182800"
  },
  {
    "text": "because there isn't there isn't a bridge between these two things they're not connected to each other um and that's why i drew the edge of the",
    "start": "2182800",
    "end": "2189760"
  },
  {
    "text": "cluster in a darker shade um to emphasize that it's kind of a barrier within the cluster",
    "start": "2189760",
    "end": "2195760"
  },
  {
    "text": "they all know how to reach each other but outside the cluster it doesn't work now i picked on the xlan but there are",
    "start": "2195760",
    "end": "2202240"
  },
  {
    "text": "other models you can use for example bgp to share routing information between those nodes if your",
    "start": "2202240",
    "end": "2208800"
  },
  {
    "text": "network understands how to do bgp or you can even just use static routing configuration you can run",
    "start": "2208800",
    "end": "2214400"
  },
  {
    "text": "an agent on each node that literally just uses the linux route tools to configure static routes to forward ip",
    "start": "2214400",
    "end": "2220560"
  },
  {
    "text": "packets so there are different ways that you can implement the island but the the name comes from the idea",
    "start": "2220560",
    "end": "2226720"
  },
  {
    "text": "that it is isolated and that it is not as easily accessible as things on the",
    "start": "2226720",
    "end": "2232960"
  },
  {
    "text": "you know quote mainland might be i saw there was a follow-up question to this",
    "start": "2232960",
    "end": "2239440"
  },
  {
    "text": "uh all right let's go through the i can't find the follow-up um so uh nat",
    "start": "2240839",
    "end": "2247280"
  },
  {
    "text": "scalability issues so yeah nat scalability is a fun question",
    "start": "2247280",
    "end": "2252480"
  },
  {
    "text": "um when you're doing all these translations the kernel has to keep track of which translations",
    "start": "2252480",
    "end": "2258800"
  },
  {
    "text": "it's doing so there's a tool called contract connection tracking which the linux",
    "start": "2258800",
    "end": "2263920"
  },
  {
    "text": "kernel offers and which we use heavily in the default implementations now there are many implementations services",
    "start": "2263920",
    "end": "2270640"
  },
  {
    "text": "are an abstraction um connection tracking we set up by default when you run",
    "start": "2270640",
    "end": "2276480"
  },
  {
    "text": "cube proxy we set up a large number of connection tracking records so we make a lot of space for the kernel to be able to track",
    "start": "2276480",
    "end": "2282839"
  },
  {
    "text": "connections um this is generally fine for most users it's fine",
    "start": "2282839",
    "end": "2288240"
  },
  {
    "text": "and for tcp in particular it tends to not be a huge problem because tcp is connection oriented and when the",
    "start": "2288240",
    "end": "2295119"
  },
  {
    "text": "connection closes we can immediately clean up the connection tracking if you use a lot",
    "start": "2295119",
    "end": "2300160"
  },
  {
    "text": "of udp services it can be problematic udp doesn't have a connection so we have",
    "start": "2300160",
    "end": "2306880"
  },
  {
    "text": "to time out udp contract records so uh what we have seen occasionally is",
    "start": "2306880",
    "end": "2313200"
  },
  {
    "text": "customers who have a high number of udp based services and with connection tracking records",
    "start": "2313200",
    "end": "2319680"
  },
  {
    "text": "that are just sitting on waiting to be tied out um and so for some of those customers we've given them",
    "start": "2319680",
    "end": "2325040"
  },
  {
    "text": "some flags you can set that key proxy to change the scaling for comedy connection tracking records that you create",
    "start": "2325040",
    "end": "2332400"
  },
  {
    "text": "um some other models like psyllium as a replacement for proxy doesn't use i believe to not use",
    "start": "2332400",
    "end": "2337920"
  },
  {
    "text": "the kernel's connection tracking mechanism uses its own connection tracking mechanism",
    "start": "2337920",
    "end": "2344319"
  },
  {
    "text": "we would be able to elaborate on the arrival on node and next steps to determine which node and pod",
    "start": "2345119",
    "end": "2351839"
  },
  {
    "text": "uh yes let's flip back to that sorry two windows",
    "start": "2351839",
    "end": "2358240"
  },
  {
    "text": "uh let's look at",
    "start": "2358640",
    "end": "2362078"
  },
  {
    "text": "so i'm",
    "start": "2365359",
    "end": "2369039"
  },
  {
    "text": "is going to look at the destination that's the first decision which service did you need to talk to and given that",
    "start": "2377599",
    "end": "2384880"
  },
  {
    "text": "it's going to use um i'll talk about the model i'm most familiar with which is like tables it's going to enter any",
    "start": "2384880",
    "end": "2391760"
  },
  {
    "text": "logic that says okay i've determined that you are heading for service",
    "start": "2391760",
    "end": "2397839"
  },
  {
    "text": "come on slides",
    "start": "2399280",
    "end": "2402000"
  },
  {
    "text": "like that there we go um so determine that you're you're aiming for",
    "start": "2404560",
    "end": "2409680"
  },
  {
    "text": "service food um it will then figure out okay service foo",
    "start": "2409680",
    "end": "2415040"
  },
  {
    "text": "has some number of pods behind it and it's going to try to choose a pod",
    "start": "2415040",
    "end": "2421200"
  },
  {
    "text": "for you to route to now i don't get into it very deep um in some cases it's going to",
    "start": "2421200",
    "end": "2429119"
  },
  {
    "text": "choose a pod for you that's on the same node like in this example but in other cases it's going to choose a pod that's on a",
    "start": "2429119",
    "end": "2434960"
  },
  {
    "text": "different node so there may not be a pod for service foo on the node that you",
    "start": "2434960",
    "end": "2440880"
  },
  {
    "text": "happened to get routed to it it's going to actually route it to another node",
    "start": "2440880",
    "end": "2447119"
  },
  {
    "text": "which adds some complexity to the logic and makes it that much more difficult for humans",
    "start": "2447119",
    "end": "2452240"
  },
  {
    "text": "to reason about because their con other tcp dump for example will show multiple",
    "start": "2452240",
    "end": "2459040"
  },
  {
    "text": "connections with multiple address translations happening across multiple nodes",
    "start": "2459040",
    "end": "2464160"
  },
  {
    "text": "this is the part that's really unfortunate about that model kubernetes has introduced some",
    "start": "2464160",
    "end": "2470319"
  },
  {
    "text": "parameters like uh external traffic policy which allow you to control that a little bit",
    "start": "2470319",
    "end": "2475440"
  },
  {
    "text": "more and limit it to only sending traffic to pods on the same node which is great",
    "start": "2475440",
    "end": "2483040"
  },
  {
    "text": "except if you happen to have routed to a node that doesn't have any back ends in which case it will end",
    "start": "2483040",
    "end": "2489599"
  },
  {
    "text": "up being a black hole so this is a trade-off that we allow users to make on a service by service",
    "start": "2489599",
    "end": "2494800"
  },
  {
    "text": "basis because there isn't an easy and easy answer to that",
    "start": "2494800",
    "end": "2501040"
  },
  {
    "text": "for things like cloud load balancers i'll talk to the vip model let me pass through here",
    "start": "2501040",
    "end": "2509680"
  },
  {
    "text": "um something we do in the cloud load balancers is when we implement the vip we have a",
    "start": "2509680",
    "end": "2516240"
  },
  {
    "text": "health check on each node which tells us whether or not each service",
    "start": "2516240",
    "end": "2521359"
  },
  {
    "text": "has a back end for that service on that node that was a long sentence given node one",
    "start": "2521359",
    "end": "2529119"
  },
  {
    "text": "does it have back ends for foo if the answer is yes the vip will potentially route to node one if the",
    "start": "2529119",
    "end": "2535440"
  },
  {
    "text": "answer is no the zip will not route to node one it will only route to node two or whichever nodes",
    "start": "2535440",
    "end": "2540560"
  },
  {
    "text": "actually have back ends that way you avoid the black holding problem",
    "start": "2540560",
    "end": "2546560"
  },
  {
    "text": "how do you increase the default number of pods from 100 to 254 like you mentioned uh i know the ips needs to be there um",
    "start": "2547520",
    "end": "2553839"
  },
  {
    "text": "so the number of pods you run on a node are governed by two different flags one is the number of ip addresses you",
    "start": "2553839",
    "end": "2560319"
  },
  {
    "text": "allocate to that node and the other is how many pods cubelet is willing to run cubelet generally sets",
    "start": "2560319",
    "end": "2567680"
  },
  {
    "text": "a limit of i think the default is 110 for the number of pods on a node there",
    "start": "2567680",
    "end": "2573440"
  },
  {
    "text": "are some people some use cases where you want to raise that what we",
    "start": "2573440",
    "end": "2579040"
  },
  {
    "text": "don't want to do what we discourage people from doing is making the number of pods and the number of ip addresses very",
    "start": "2579040",
    "end": "2586000"
  },
  {
    "text": "close to each other what happens in that case is you can potentially reuse ip addresses",
    "start": "2586000",
    "end": "2591839"
  },
  {
    "text": "very quickly and kubernetes being a distributed system there's generally something out",
    "start": "2591839",
    "end": "2597839"
  },
  {
    "text": "there that has cached an ip address whether it's dns which has you know time time to live",
    "start": "2597839",
    "end": "2603760"
  },
  {
    "text": "measured in seconds but still not instantaneous so we we generally say however many pods",
    "start": "2603760",
    "end": "2611440"
  },
  {
    "text": "you want to run on a node your ip addresses should be about twice that big in fact what we do by default",
    "start": "2611440",
    "end": "2617040"
  },
  {
    "text": "in gke is when you tell us how many pods you want to run on a node we round up to a",
    "start": "2617040",
    "end": "2622640"
  },
  {
    "text": "power of two and then double it uh so if you want to run 110 pods that's going to round up to 128 which double",
    "start": "2622640",
    "end": "2629280"
  },
  {
    "text": "this 256. um many users most users in fact don't need to run 100 pods per node and",
    "start": "2629280",
    "end": "2636480"
  },
  {
    "text": "they can actually dial that in the other direction and set it lower so if they say i only need to run",
    "start": "2636480",
    "end": "2641520"
  },
  {
    "text": "32 pods per node then we round that up to 32 and we double it to 64 and they",
    "start": "2641520",
    "end": "2646720"
  },
  {
    "text": "get four times as many nodes in the same ip space",
    "start": "2646720",
    "end": "2652319"
  },
  {
    "text": "any chance you can talk about the ingress options that you left out due to time i have another deck which is also",
    "start": "2652800",
    "end": "2658880"
  },
  {
    "text": "presented on my on my speaker deck which you can walk through where i dig into the vip model and the proxy model",
    "start": "2658880",
    "end": "2665359"
  },
  {
    "text": "in a lot more detail um also if you uh google for",
    "start": "2665359",
    "end": "2670400"
  },
  {
    "text": "uh for me we've done some talks that go into excruciating detail about how the traffic routing works",
    "start": "2670400",
    "end": "2676319"
  },
  {
    "text": "with respect to different load balancing models would overlapping service network",
    "start": "2676319",
    "end": "2682480"
  },
  {
    "text": "ipspace i just lost the question",
    "start": "2682480",
    "end": "2687200"
  },
  {
    "text": "i can take that up for you good overlapping service network ip space with external empty space be an issue if a",
    "start": "2687680",
    "end": "2693520"
  },
  {
    "text": "pod needs to communicate with both in cluster services and services external to the cluster if i'm understanding the question",
    "start": "2693520",
    "end": "2699599"
  },
  {
    "text": "correctly yes any time you overlap ip addresses you now have to",
    "start": "2699599",
    "end": "2704880"
  },
  {
    "text": "disambiguate if you have a client that wants to talk to both of them this is one of the fundamental",
    "start": "2704880",
    "end": "2710960"
  },
  {
    "text": "problems of ipv4 is just not enough ip addresses to go around",
    "start": "2710960",
    "end": "2716720"
  },
  {
    "text": "so if you look at a model like uh island mode where you might potentially reuse those",
    "start": "2716720",
    "end": "2723599"
  },
  {
    "text": "ip addresses there is simply no way that you can have a pod directly speak to another pod because it",
    "start": "2723599",
    "end": "2730319"
  },
  {
    "text": "can't tell whether it's talking to its own private version of that ip address or to",
    "start": "2730319",
    "end": "2735440"
  },
  {
    "text": "the other clusters version of that ip address this is akin to if you set up your",
    "start": "2735440",
    "end": "2742560"
  },
  {
    "text": "internal network to use the 8.8.8.8 ip",
    "start": "2742560",
    "end": "2747839"
  },
  {
    "text": "address i would not know how to tell whether you meant to talk to google dns or to your own service",
    "start": "2747839",
    "end": "2754000"
  },
  {
    "text": "so overlapping ip addresses should be done carefully and thoughtfully",
    "start": "2754000",
    "end": "2759359"
  },
  {
    "text": "uh questions i saw something that i meant to answer would ipip overlays work um any overlay",
    "start": "2759359",
    "end": "2766640"
  },
  {
    "text": "should work if you can route the traffic into the other cluster uh deterministically vxlan is the one",
    "start": "2766640",
    "end": "2773599"
  },
  {
    "text": "that has sort of risen as very popular right now because it's a fairly simple overlay but people are certainly doing it with",
    "start": "2773599",
    "end": "2780160"
  },
  {
    "text": "gre or other encapsulation mechanisms",
    "start": "2780160",
    "end": "2784640"
  },
  {
    "text": "could you give some idea on node pool what is the use case for more than one node pool sure node pools is not an official",
    "start": "2785440",
    "end": "2793440"
  },
  {
    "text": "kubernetes concept but it's implemented by many of the kubernetes providers",
    "start": "2793440",
    "end": "2798480"
  },
  {
    "text": "it's just a group of machines that have something in common so i can speak to the way gke implements",
    "start": "2798480",
    "end": "2804640"
  },
  {
    "text": "it it's a a template for a vm shape so all the vms all the nodes in a vm",
    "start": "2804640",
    "end": "2812160"
  },
  {
    "text": "excuse me all the nodes in a node pool have the same shape and configuration so we offer you",
    "start": "2812160",
    "end": "2819119"
  },
  {
    "text": "the ability to configure the pods per node that is configurable at the node pool",
    "start": "2819119",
    "end": "2825119"
  },
  {
    "text": "level for example but it's not an official kubernetes concept each node has its own configuration so",
    "start": "2825119",
    "end": "2832000"
  },
  {
    "text": "when when we go to schedule we're going to look at each individual node and ask the node how many how many pods do you",
    "start": "2832000",
    "end": "2837920"
  },
  {
    "text": "allow that's part of the node status",
    "start": "2837920",
    "end": "2842078"
  },
  {
    "text": "questions how do you increase the default number of plot oh that we did that one um what are some of the challenges trade-offs you've observed when you",
    "start": "2842960",
    "end": "2848960"
  },
  {
    "text": "correlate these models with low latency packet processing uh the short answer for low latency",
    "start": "2848960",
    "end": "2855119"
  },
  {
    "text": "packet processing is the more things that have to touch the packet the worse off you're going to be",
    "start": "2855119",
    "end": "2860240"
  },
  {
    "text": "right that seems pretty self-evident if you're bouncing through proxies you're going to have generally higher",
    "start": "2860240",
    "end": "2866800"
  },
  {
    "text": "latency than if you're not and so for customers who need who really focus",
    "start": "2866800",
    "end": "2872000"
  },
  {
    "text": "and care about low latency packet processing we encourage them to go have uh fully integrated flat mode as",
    "start": "2872000",
    "end": "2879760"
  },
  {
    "text": "much as they can and sometimes that means having different mixed models they have one",
    "start": "2879760",
    "end": "2885040"
  },
  {
    "text": "cluster that runs their super low latency applications and is in flat mode and",
    "start": "2885040",
    "end": "2890720"
  },
  {
    "text": "they have another cluster in island mode which handles less latency sensitive applications",
    "start": "2890720",
    "end": "2897520"
  },
  {
    "text": "question are gateways managed by kubernetes only no absolutely you can do whatever you want to make those gateways work",
    "start": "2898240",
    "end": "2904960"
  },
  {
    "text": "kubernetes happens to have some abstractions that make it relatively easy to set up load balancers",
    "start": "2904960",
    "end": "2911359"
  },
  {
    "text": "in various cloud environments but you uh kubernetes is wonderful in this way there's an api and there's",
    "start": "2911359",
    "end": "2917200"
  },
  {
    "text": "the implementation and they are distinct and you can implement your own uh again quote cloud provider via",
    "start": "2917200",
    "end": "2924160"
  },
  {
    "text": "whatever mechanism you want if you have some load balancing infrastructure that you like or some creative traffic routing that or network",
    "start": "2924160",
    "end": "2931200"
  },
  {
    "text": "fabric that you can leverage you are welcome to do your own thing kubernetes gives you lots of interesting",
    "start": "2931200",
    "end": "2938240"
  },
  {
    "text": "api mechanics so you can watch for updates and implement your own controllers and in fact all of our controllers are open",
    "start": "2938240",
    "end": "2944240"
  },
  {
    "text": "source so you can uh embrace and extend the controllers that we've already written to work in your own environments",
    "start": "2944240",
    "end": "2952480"
  },
  {
    "text": "how would flannel versus calico work which pattern are they flannel and calico are island modes generally um",
    "start": "2953359",
    "end": "2960559"
  },
  {
    "text": "calico being a bgp model uh well actually a mixed model now but",
    "start": "2960559",
    "end": "2966000"
  },
  {
    "text": "primarily was focused on bgp it can integrate with the larger network but it also can",
    "start": "2966000",
    "end": "2971680"
  },
  {
    "text": "not depending on where you're going to uh route those advertisements um flannel or canal",
    "start": "2971680",
    "end": "2978559"
  },
  {
    "text": "uh are vxlan implementations so those are generally uh island mode implementations",
    "start": "2978559",
    "end": "2984720"
  },
  {
    "text": "do you know any way to simplify this model and remove the dependency on that do you see service mesh solutions adding",
    "start": "2984720",
    "end": "2990480"
  },
  {
    "text": "value to the network layer indicates or the opposite so",
    "start": "2990480",
    "end": "2995920"
  },
  {
    "text": "nat is one of the implementations that we use for uh cube proxy right um",
    "start": "2995920",
    "end": "3003599"
  },
  {
    "text": "if you wanted to use something like a service mesh instead of a cube proxy that is a completely valid",
    "start": "3003599",
    "end": "3009520"
  },
  {
    "text": "implementation and it wouldn't need nat in the same way like it doesn't rely on the kernel's nat",
    "start": "3009520",
    "end": "3016319"
  },
  {
    "text": "but it's going to be doing uh effectively translation in the proxy so you still have some amount of state",
    "start": "3016319",
    "end": "3022400"
  },
  {
    "text": "that is stored as your routing pockets from around i'm a big believer in funny i was just",
    "start": "3022400",
    "end": "3028240"
  },
  {
    "text": "talking about this this morning on twitter i'm a big believer in service mesh and the idea that eventually most users will",
    "start": "3028240",
    "end": "3034720"
  },
  {
    "text": "want some of what service mesh offers uh probably most users will not want all of it but most users will want some",
    "start": "3034720",
    "end": "3041359"
  },
  {
    "text": "subset of it and so as service meshes become more powerful and more easy to use",
    "start": "3041359",
    "end": "3047920"
  },
  {
    "text": "i think it's great that they can implement these same abstractions and you should be able to use them uh",
    "start": "3047920",
    "end": "3054000"
  },
  {
    "text": "just like any other implementation right so if if you wanted to use for example seo",
    "start": "3054000",
    "end": "3059200"
  },
  {
    "text": "it's going to handle service routing instead of q proxy and that's great",
    "start": "3059200",
    "end": "3064240"
  },
  {
    "text": "so many questions this is awesome um where are we apologizing for the question but i want",
    "start": "3066640",
    "end": "3071920"
  },
  {
    "text": "to ask this is an entry point for learning understanding kubernetes difficult for an admin who has a good understanding and skills with",
    "start": "3071920",
    "end": "3079680"
  },
  {
    "text": "virtualization sorry that wasn't the question as a follow-up i think okay um",
    "start": "3080839",
    "end": "3087200"
  },
  {
    "text": "do you have references for setting up these different modes technical configs and tools yes uh the references",
    "start": "3087200",
    "end": "3094400"
  },
  {
    "text": "are generally in the implementation so there is there's documentation on setting up flannel and canal",
    "start": "3094400",
    "end": "3101599"
  },
  {
    "text": "for um island mode uh and calico has lots of great docks for",
    "start": "3101599",
    "end": "3106880"
  },
  {
    "text": "setting up calico the default kubernetes implementation kind of assumes flat mode",
    "start": "3106880",
    "end": "3113599"
  },
  {
    "text": "but it doesn't assume it very hard it just doesn't assume anything about networking other than the kubernetes networking model which",
    "start": "3113599",
    "end": "3121520"
  },
  {
    "text": "means pods can talk to other pods yeah the kubernetes the hard way uh",
    "start": "3121520",
    "end": "3128400"
  },
  {
    "text": "is a great doc it's very difficult to write abstract docs around the networking",
    "start": "3128400",
    "end": "3134960"
  },
  {
    "text": "model because there's so many dependencies on which environment you're in what they support",
    "start": "3134960",
    "end": "3140800"
  },
  {
    "text": "how native it can get not every cloud provider can support full flat mode for example",
    "start": "3140800",
    "end": "3147839"
  },
  {
    "text": "suggestions on local platforms to explore experiment with case networking options i am a big fan of kind myself",
    "start": "3148720",
    "end": "3156559"
  },
  {
    "text": "but kind builds unknocker and there's only so much you can do with it",
    "start": "3156559",
    "end": "3163040"
  },
  {
    "text": "before you end up running into things that the kernel lets you do which you might not be able to do uh in",
    "start": "3163040",
    "end": "3169920"
  },
  {
    "text": "a real network model um so uh i would i personally use kind for testing stuff out when i would play",
    "start": "3169920",
    "end": "3176400"
  },
  {
    "text": "with like l2 space um i use google cloud when i want to play with a non-l2 space",
    "start": "3176400",
    "end": "3184640"
  },
  {
    "text": "is cube proxy based on iptables qproxy has several modes built into it one of them is iptables that was the",
    "start": "3184720",
    "end": "3191920"
  },
  {
    "text": "default and maybe still is the default and most common model increasingly",
    "start": "3191920",
    "end": "3197440"
  },
  {
    "text": "people are using ipvs as the implementation which is a somewhat optimized path",
    "start": "3197440",
    "end": "3202720"
  },
  {
    "text": "through the kernel but very similar in internal mechanisms very different in",
    "start": "3202720",
    "end": "3208240"
  },
  {
    "text": "configuration there's also a user space mode which hardly anybody uses anymore",
    "start": "3208240",
    "end": "3215440"
  },
  {
    "text": "and there are now there's been proposals to add nf tables directly although i think we're going to see a",
    "start": "3215440",
    "end": "3221280"
  },
  {
    "text": "standalone replacement for cube proxy that uses nf tables and psyllium for example uses evpf",
    "start": "3221280",
    "end": "3229200"
  },
  {
    "text": "and rather than folding all that into one giant q proxy binary i've been encouraging people to build",
    "start": "3229200",
    "end": "3235599"
  },
  {
    "text": "their own cube proxy replacements q proxy is just one implementation of the service abstraction",
    "start": "3235599",
    "end": "3243440"
  },
  {
    "text": "when using where to go when using a node port service would clients within the",
    "start": "3244000",
    "end": "3249440"
  },
  {
    "text": "same node be able to use that node's ipv and service or do they have to use the pod ip directly",
    "start": "3249440",
    "end": "3256319"
  },
  {
    "text": "in most implementations you can use the nodes ip and node port but i'm not sure why you would",
    "start": "3256319",
    "end": "3262559"
  },
  {
    "text": "want to unless you have some weird consistency requirement",
    "start": "3262559",
    "end": "3268640"
  },
  {
    "text": "node ports very frankly were designed to build higher level load balancers so",
    "start": "3268640",
    "end": "3275520"
  },
  {
    "text": "when people are using node ports directly it's for me it's a smell like i feel like you're missing a piece",
    "start": "3275520",
    "end": "3282079"
  },
  {
    "text": "the goal is to implement load balancers and proxies and vips through node ports not to have people",
    "start": "3282079",
    "end": "3288079"
  },
  {
    "text": "use them directly there are services of type cluster ip with cluster ip none that can be routed",
    "start": "3288079",
    "end": "3293920"
  },
  {
    "text": "via a service name yes how does the communication happen for those without an ip associated with the service",
    "start": "3293920",
    "end": "3299280"
  },
  {
    "text": "so we call those headless services uh they don't have an ip address ahead they",
    "start": "3299280",
    "end": "3306079"
  },
  {
    "text": "do not work very well in island mode because you if you have five replicas you need five ip addresses",
    "start": "3306079",
    "end": "3312240"
  },
  {
    "text": "to address them or five ports to address them and the problem is the number of replicas can change dynamically",
    "start": "3312240",
    "end": "3318240"
  },
  {
    "text": "and it's much slower to program load balancing infrastructure uh than it is to program within the",
    "start": "3318240",
    "end": "3324240"
  },
  {
    "text": "cluster and so in general if you have headless services this is what i said about direct connectivity",
    "start": "3324240",
    "end": "3330240"
  },
  {
    "text": "direct to end point connectivity it does not map very well into uh highland modes",
    "start": "3330240",
    "end": "3337920"
  },
  {
    "text": "and i'm told i have no minutes left i'm happy to do more questions via",
    "start": "3337920",
    "end": "3343599"
  },
  {
    "text": "whatever mechanism people can find me i'm available on twitter on uh",
    "start": "3343599",
    "end": "3350160"
  },
  {
    "text": "slack on github on whatever medium i want to also throw a",
    "start": "3350160",
    "end": "3355760"
  },
  {
    "text": "quick shout out we have another ambassador webinar coming september 25th caitlyn is doing and bowie we'll be",
    "start": "3355760",
    "end": "3363119"
  },
  {
    "text": "talking about the evolution of the ingress api which we just touched on barely today",
    "start": "3363119",
    "end": "3369119"
  },
  {
    "text": "and it's new hopefully replacement called gateway you can click on the link in there go to the cncf upcoming webinars and get more",
    "start": "3369119",
    "end": "3376319"
  },
  {
    "text": "details okay well thank you very much tim for a wonderful presentation",
    "start": "3376319",
    "end": "3381839"
  },
  {
    "text": "and thank you all so much for your participation as well as i said before today's presentation",
    "start": "3381839",
    "end": "3387760"
  },
  {
    "text": "and slides will be available on the cncf website later today that is all the time we have for today",
    "start": "3387760",
    "end": "3393839"
  },
  {
    "text": "thank you very much for joining us today everyone and stay safe",
    "start": "3393839",
    "end": "3403359"
  }
]
[
  {
    "text": "yeah hello everyone yeah today's topic is LCD",
    "start": "160",
    "end": "7960"
  },
  {
    "text": "3.6.0 and LCD operator 0.1 you know uh",
    "start": "7960",
    "end": "13679"
  },
  {
    "text": "we will walk you through what's new and some key improvements you know RCD 2.6",
    "start": "13679",
    "end": "18880"
  },
  {
    "text": "is really a big milestone because it has almost four years since",
    "start": "18880",
    "end": "25800"
  },
  {
    "text": "3.5.0 so but so far we only released RC3 release candidate 3 due to an upgrade",
    "start": "25800",
    "end": "33360"
  },
  {
    "text": "issue we will dive into later but anyway is a major step forward we are going to",
    "start": "33360",
    "end": "38719"
  },
  {
    "text": "share the detail today yeah this is our today's speaker",
    "start": "38719",
    "end": "46559"
  },
  {
    "text": "hi everyone I'm Orush Shaha from uh VMware by Broadcom a software engineer",
    "start": "46559",
    "end": "51840"
  },
  {
    "text": "who is working on contributing to city as well as making downstream releases of",
    "start": "51840",
    "end": "56879"
  },
  {
    "text": "city and Kubernetes hi uh my name is Cyprian i'm a",
    "start": "56879",
    "end": "63280"
  },
  {
    "text": "Kubernetes maintainer Kaops uh no problem detector cloud provider and many",
    "start": "63280",
    "end": "70159"
  },
  {
    "text": "other tools uh I'm happy to do a lot of open source in my spare time",
    "start": "70159",
    "end": "77439"
  },
  {
    "text": "hi um hi uh I'm Ivan uh I'm VP of uh engineering at Inar Technologies uh I",
    "start": "77439",
    "end": "84799"
  },
  {
    "text": "contribute to CD um I'm mostly in charge of CI/CD um tooling and stuff like that",
    "start": "84799",
    "end": "93680"
  },
  {
    "text": "hello uh I'm Pami i'm the city maintainer and also SD code tag lead",
    "start": "93680",
    "end": "100079"
  },
  {
    "text": "suan didn't come this time suan is coming from Google he is reviewer",
    "start": "100079",
    "end": "107040"
  },
  {
    "text": "yeah yeah before we dive in we have some exciting updates for the community first",
    "start": "107240",
    "end": "113680"
  },
  {
    "text": "we have a new maintainer on board Fuway from Microsoft yeah welcome",
    "start": "113680",
    "end": "120119"
  },
  {
    "text": "Fu yeah we also have a new SIG LCD chair Ivan",
    "start": "120119",
    "end": "127010"
  },
  {
    "text": "[Applause] yeah yeah we also formed a new uh",
    "start": "127010",
    "end": "133200"
  },
  {
    "text": "release team the the team is led by Ivan and James ivan is also here",
    "start": "133200",
    "end": "140959"
  },
  {
    "text": "yes yeah yeah this is the agenda first we",
    "start": "140959",
    "end": "148800"
  },
  {
    "text": "will go through the new feature for 3.6.0 yeah apart from the new feature we",
    "start": "148800",
    "end": "154720"
  },
  {
    "text": "will highlight uh an upgrade issue it's the exact reason why we didn't release",
    "start": "154720",
    "end": "160519"
  },
  {
    "text": "326.0 before coupon events and after that we will dive into",
    "start": "160519",
    "end": "166400"
  },
  {
    "text": "the performance improvement in 306.0 zero and also the major enhancement for",
    "start": "166400",
    "end": "172480"
  },
  {
    "text": "the performance testing tool and also IB we are walk through the release",
    "start": "172480",
    "end": "177640"
  },
  {
    "text": "process and we and separate we are introduced new working group LCD",
    "start": "177640",
    "end": "182800"
  },
  {
    "text": "operator and also the detail for the LCD operator 0.1 and AR will talk about the",
    "start": "182800",
    "end": "189200"
  },
  {
    "text": "future work and road map for LCD operator finally if time permit we will have Q&A",
    "start": "189200",
    "end": "196080"
  },
  {
    "text": "session Yeah the first of the feature is migration to W3 store you know",
    "start": "197080",
    "end": "203120"
  },
  {
    "text": "previously we are using the W2 store w2 store is is a Lexi uh data format with the",
    "start": "203120",
    "end": "212560"
  },
  {
    "text": "suffix SNAP you can see the example it had already deprecated since release 3.4",
    "start": "212560",
    "end": "220080"
  },
  {
    "text": "but user can still enable it using the flag enable way too up to uh 3.5 it is",
    "start": "220080",
    "end": "226560"
  },
  {
    "text": "still the source of truth for me data in 3.5 w3 store is the bot database file is",
    "start": "226560",
    "end": "234000"
  },
  {
    "text": "the source of truth for the membership data in 3.6 but the flag enable 2 had",
    "start": "234000",
    "end": "240560"
  },
  {
    "text": "already been removed in 3.6 so there's no way to enable way to store in",
    "start": "240560",
    "end": "247879"
  },
  {
    "text": "3.6 the efforts of migration is still ongoing currently we are still bootstrap",
    "start": "247879",
    "end": "254560"
  },
  {
    "text": "LD on W2 store and replay the war record on the latest W2 snapshot in 37 we are",
    "start": "254560",
    "end": "262479"
  },
  {
    "text": "going to bootstrap LD on W3 store and replay the world record on the starting",
    "start": "262479",
    "end": "269040"
  },
  {
    "text": "from the consistent index yeah the second feature is D grid",
    "start": "269040",
    "end": "277720"
  },
  {
    "text": "L3.6.0 Zero is the first version to fully support downgrades at a high level",
    "start": "277720",
    "end": "283600"
  },
  {
    "text": "the downgrade process involved two stage the first stage is to migrate the data",
    "start": "283600",
    "end": "289040"
  },
  {
    "text": "schema to the target version for example if you downgrade from 3.6 to 3.5 then",
    "start": "289040",
    "end": "295440"
  },
  {
    "text": "the target downgrade version is 3.5 the second stage is rolling down grid each member just place the binary or image",
    "start": "295440",
    "end": "303040"
  },
  {
    "text": "from user perspective there are three steps the fourth step is validated the downgrades currently we only support one",
    "start": "303040",
    "end": "310400"
  },
  {
    "text": "manual at a time for example you cannot downgrade from 3.6 to 3.4 it's not allowed you can only downgrade from 3.6",
    "start": "310400",
    "end": "317680"
  },
  {
    "text": "to 3.5 you can use the LCD cer downgrade validate command or you can use call the",
    "start": "317680",
    "end": "324639"
  },
  {
    "text": "client SDK API once the validation is successful you can go to the second the step two to",
    "start": "324639",
    "end": "331919"
  },
  {
    "text": "enable the downgrade you can run the LCD control down grid enable or call the client",
    "start": "331919",
    "end": "338840"
  },
  {
    "text": "SDK you know we need to you know we once the downgrade is enabled LCD will",
    "start": "338840",
    "end": "345280"
  },
  {
    "text": "automatically migrate the schema so we need to wait for the storage version",
    "start": "345280",
    "end": "351199"
  },
  {
    "text": "being changed to the target version in this example the down target version is",
    "start": "351199",
    "end": "356240"
  },
  {
    "text": "3.5 and the story version is still is also 3.5 so it's save to do the next",
    "start": "356240",
    "end": "362320"
  },
  {
    "text": "step the step three is just to place the binary or image one by one for all the",
    "start": "362320",
    "end": "370240"
  },
  {
    "text": "member yeah this is the fishial gates so I didn't come this time just",
    "start": "370840",
    "end": "376639"
  },
  {
    "text": "play video hello everyone i'm excited to introduce the new feature gates in SD",
    "start": "376639",
    "end": "382400"
  },
  {
    "text": "3.6 release before the 3.6 six uh any new",
    "start": "382400",
    "end": "388080"
  },
  {
    "text": "feature is added to SD through a feature gate experimental uh",
    "start": "388080",
    "end": "394199"
  },
  {
    "text": "flag and then when it's ready to graduate we have to remove the",
    "start": "394199",
    "end": "400000"
  },
  {
    "text": "experimental prefix in the flag so that's a breaking change and also it's pretty hard to",
    "start": "400000",
    "end": "407280"
  },
  {
    "text": "track what stage the feature is in so it is not uncommon for some features to get",
    "start": "407280",
    "end": "414639"
  },
  {
    "text": "abandoned uh over the years so due to these reasons we are switching to use",
    "start": "414639",
    "end": "421759"
  },
  {
    "text": "the kubernetes style feature gates uh so for a feature gate it can go",
    "start": "421759",
    "end": "429680"
  },
  {
    "text": "through alpha beta and GA uh stages and the users can enable or disable a",
    "start": "429680",
    "end": "436720"
  },
  {
    "text": "feature through the feature gates uh flag and in 3.6 Six we have migrated all",
    "start": "436720",
    "end": "443520"
  },
  {
    "text": "the existing experimental feature flags into the new feature gates with this uh new feature gates in",
    "start": "443520",
    "end": "451440"
  },
  {
    "text": "place uh sedd is also adopting the kubernetes cap process for any new",
    "start": "451440",
    "end": "458000"
  },
  {
    "text": "feature development so with these changes",
    "start": "458000",
    "end": "464160"
  },
  {
    "text": "uh we can get the benefits of no more of flag breaking changes for graduating a",
    "start": "464160",
    "end": "471599"
  },
  {
    "text": "feature from the experimental stage and generally the feature gate is",
    "start": "471599",
    "end": "478560"
  },
  {
    "text": "less uh error and there will be less risk of new feature breaking SD so",
    "start": "478560",
    "end": "486879"
  },
  {
    "text": "hopefully uh developers can be feel more comfortable to introduce new features into",
    "start": "486879",
    "end": "492520"
  },
  {
    "text": "SD in addition uh the feature stage will be more",
    "start": "492520",
    "end": "498960"
  },
  {
    "text": "tractable and then there will be clear criteria for future graduation so with",
    "start": "498960",
    "end": "506080"
  },
  {
    "text": "these changes we hope that uh they we can bring more faster uh development",
    "start": "506080",
    "end": "513279"
  },
  {
    "text": "cycle into SD for future releases",
    "start": "513279",
    "end": "518919"
  },
  {
    "text": "hello everyone uh I'm excited yeah that's so inity 3.6 we're also",
    "start": "520479",
    "end": "528080"
  },
  {
    "text": "introducing two more house check endpoints that's live Z and ready Z",
    "start": "528080",
    "end": "534160"
  },
  {
    "text": "uh so the live Z endpoint reflects whether the process is still alive or",
    "start": "534160",
    "end": "539760"
  },
  {
    "text": "whether it needs a restart the ready Z endpoint reflects whether the process is ready to serve",
    "start": "539760",
    "end": "546120"
  },
  {
    "text": "traffic before this change in 3.4 and 3.5 there's only a single health",
    "start": "546120",
    "end": "552640"
  },
  {
    "text": "endpoint so it doesn't reflect the difference between whether you want to restart or you need to stop uh serving",
    "start": "552640",
    "end": "559680"
  },
  {
    "text": "the traffic and here I've listed an example of how",
    "start": "559680",
    "end": "565200"
  },
  {
    "text": "to call the endpoint and what it returns um with a verbose uh parameter you can",
    "start": "565200",
    "end": "571360"
  },
  {
    "text": "see uh what checks are being performed and whether the health uh the server is",
    "start": "571360",
    "end": "578080"
  },
  {
    "text": "healthy or not so now the SED house check is fully",
    "start": "578080",
    "end": "584160"
  },
  {
    "text": "compliant with Kubernetes uh API expectations and hopefully this can",
    "start": "584160",
    "end": "591120"
  },
  {
    "text": "bring some nice change to your health probe",
    "start": "591120",
    "end": "596839"
  },
  {
    "text": "so in okay the next feature is we discovery",
    "start": "597519",
    "end": "602640"
  },
  {
    "text": "you know we can bootstrap LCD cluster with the help of the discovery service",
    "start": "602640",
    "end": "608399"
  },
  {
    "text": "you know when we bootstrap a new LC cluster each member know nothing about",
    "start": "608399",
    "end": "613839"
  },
  {
    "text": "it peer it when each member start up it just regist itself with the discovery",
    "start": "613839",
    "end": "619760"
  },
  {
    "text": "service and then watch the discovery service until all the peer have finished",
    "start": "619760",
    "end": "625680"
  },
  {
    "text": "the registration and finally the discovery service return the full peer list so is the discovery service is",
    "start": "625680",
    "end": "634160"
  },
  {
    "text": "discovery protocol is only used in the very first cluster bootstrap the W3 discovery is using the LCD client SDK 3",
    "start": "634160",
    "end": "641920"
  },
  {
    "text": "to talk to the discovery service the lack discovery is based on the LCD",
    "start": "641920",
    "end": "648959"
  },
  {
    "text": "client V2 is already deprecated the public discovery service",
    "start": "648959",
    "end": "655000"
  },
  {
    "text": "discovery.io is not maintained anymore",
    "start": "655000",
    "end": "659800"
  },
  {
    "text": "yeah I would like highlight an upgrade issue it exactly reason why we delayed the release of",
    "start": "660880",
    "end": "667000"
  },
  {
    "text": "3.6.0 the symptom is when upgrade from 3.5 to 3.6 may fail the reason is too",
    "start": "667000",
    "end": "673839"
  },
  {
    "text": "many lender in the cluster you know when we upgrade from 3.6 uh 3.5 to 3.6 some",
    "start": "673839",
    "end": "680800"
  },
  {
    "text": "member may reward to lender the root cause is there's a bug in the 35 when",
    "start": "680800",
    "end": "687200"
  },
  {
    "text": "we're promoting a lender the promoting is only possessed in the W2 store not the W3 store as we mentioned earlier W2",
    "start": "687200",
    "end": "694399"
  },
  {
    "text": "store is the social truth in 3.5 but W3 store is the social truth in 3.6 so is",
    "start": "694399",
    "end": "701360"
  },
  {
    "text": "the reason why we only see this issue when upgrade from 3.5 to 36 the issue",
    "start": "701360",
    "end": "707920"
  },
  {
    "text": "was introduced in 3.5.1 so all the patch between 3.5.1 and 3.5.19 are",
    "start": "707920",
    "end": "716360"
  },
  {
    "text": "affected we fixed the issue in 35.20 so the most important thing is user must",
    "start": "716360",
    "end": "723440"
  },
  {
    "text": "upgrade to 3.5.20 or high patch before upgrading to 3.6 yeah we have a blog to",
    "start": "723440",
    "end": "730959"
  },
  {
    "text": "summarize the details please check it out yeah I",
    "start": "730959",
    "end": "736720"
  },
  {
    "text": "uh All right so I'm going to dig a little bit deeper into how we measure performance in net cityd uh and also I'm",
    "start": "736720",
    "end": "744560"
  },
  {
    "text": "going to compare a little bit uh the results of the performance of 3.5 uh 21",
    "start": "744560",
    "end": "750800"
  },
  {
    "text": "or 20 uh versus 3.6 release candidate 3 uh we initially we had all of this",
    "start": "750800",
    "end": "758160"
  },
  {
    "text": "tooling and uh the plotting was greed in Python we decided that because our main",
    "start": "758160",
    "end": "764240"
  },
  {
    "text": "code base is created in Go we decided to rewrite it and now all of these charts are generated uh in Go uh this is a read",
    "start": "764240",
    "end": "773839"
  },
  {
    "text": "write heat map uh for a different read write ratios uh so we have different",
    "start": "773839",
    "end": "780639"
  },
  {
    "text": "read write ratios and we are measuring the different value",
    "start": "780639",
    "end": "785880"
  },
  {
    "text": "sizes versus different number of connections so basically this is the",
    "start": "785880",
    "end": "790959"
  },
  {
    "text": "comparison of 36 and 35 uh if you see blue here it will mean that 35 is has",
    "start": "790959",
    "end": "799120"
  },
  {
    "text": "better performance but as we can see it's uh so the performance is consistently better in 3.6 um there's",
    "start": "799120",
    "end": "806639"
  },
  {
    "text": "not going to be a lot of time to discuss these charts so I if if you want to discuss a little bit more about the",
    "start": "806639",
    "end": "812959"
  },
  {
    "text": "performance I invite you to join the uh to come to our booth tomorrow uh this",
    "start": "812959",
    "end": "818160"
  },
  {
    "text": "the previous charts where the read performance this is the right performance uh and again it's very",
    "start": "818160",
    "end": "824480"
  },
  {
    "text": "similar story uh 3.6 is is has better performance uh there's just uh the first",
    "start": "824480",
    "end": "831279"
  },
  {
    "text": "uh ratio that it's a little bit uh 35 performs a little bit better uh so we're",
    "start": "831279",
    "end": "837199"
  },
  {
    "text": "also exploring new ways on how to represent this data uh because sometimes",
    "start": "837199",
    "end": "842720"
  },
  {
    "text": "uh the heat map is not very representative so we are experimenting with these power line charts and it's",
    "start": "842720",
    "end": "849519"
  },
  {
    "text": "basically the same story uh blue is uh 3.6 red is uh 3.5 um and it's basically",
    "start": "849519",
    "end": "858480"
  },
  {
    "text": "just the the same data just visualizing a different representation and I think",
    "start": "858480",
    "end": "864000"
  },
  {
    "text": "it's a little bit clear uh also it's clear uh to see how 3.6 is behaving uh",
    "start": "864000",
    "end": "870800"
  },
  {
    "text": "even better in the same chart we are now having read and write um and so this is",
    "start": "870800",
    "end": "877680"
  },
  {
    "text": "also like this is more uh read write ratios um we're also trying to see how",
    "start": "877680",
    "end": "887040"
  },
  {
    "text": "we can measure the resources that HCD is using so we added some measurement to",
    "start": "887040",
    "end": "892480"
  },
  {
    "text": "the RAM and to the CPU and uh so here we can see again same colors blue is HCD",
    "start": "892480",
    "end": "899120"
  },
  {
    "text": "3.6 six and we can see that there is less memory consumption uh you see that",
    "start": "899120",
    "end": "905120"
  },
  {
    "text": "there's like a lot of uh like uh lines that like uh vertical lines and it's",
    "start": "905120",
    "end": "911279"
  },
  {
    "text": "because we are running uh several iterations of the same tests but the",
    "start": "911279",
    "end": "917360"
  },
  {
    "text": "result is very constant uh consistent uh the RAM usage is better there is a",
    "start": "917360",
    "end": "923440"
  },
  {
    "text": "slightly almost uh it's not there's not a lot of CPU",
    "start": "923440",
    "end": "930600"
  },
  {
    "text": "improvement uh it's very similar it's marginal if there's some CPU improvement",
    "start": "930600",
    "end": "936560"
  },
  {
    "text": "uh and so some something that you can also see in these charts is that uh it's",
    "start": "936560",
    "end": "942320"
  },
  {
    "text": "and it's consistent with the read write uh heat maps is that 3.6 ends before uh",
    "start": "942320",
    "end": "949040"
  },
  {
    "text": "the process from 3.5 so it 3.6 has way",
    "start": "949040",
    "end": "954720"
  },
  {
    "text": "better performance um so why is 3.6 uh",
    "start": "954720",
    "end": "960000"
  },
  {
    "text": "why does it have a way better performance there's a default in 3.5 the snapshot count it's in 3.5 it defaults",
    "start": "960000",
    "end": "967920"
  },
  {
    "text": "to 100,000 um and in 3.6 we just change it to 10,000 and that has a significant",
    "start": "967920",
    "end": "975519"
  },
  {
    "text": "improvement in RAM and also Marik in pull request",
    "start": "975519",
    "end": "981160"
  },
  {
    "text": "18825 he did uh reduce the number of rap snapshots in memory making the compact",
    "start": "981160",
    "end": "987680"
  },
  {
    "text": "history more frequent uh we're still working in several ideas to improve",
    "start": "987680",
    "end": "993199"
  },
  {
    "text": "memory usage and resources um and now I'm going to jump topics into",
    "start": "993199",
    "end": "999759"
  },
  {
    "text": "the release process very quickly uh so we have we initially we had a very",
    "start": "999759",
    "end": "1005600"
  },
  {
    "text": "manual way of doing the releases uh I think the first the first 3.5 released",
    "start": "1005600",
    "end": "1013120"
  },
  {
    "text": "uh took like more than a day because uh the new the new maintainers were still",
    "start": "1013120",
    "end": "1018399"
  },
  {
    "text": "trying to understand how the releases worked uh so basically James and I took over the process and what we are trying",
    "start": "1018399",
    "end": "1025678"
  },
  {
    "text": "to make it uh more to bring more automation in James words the release is",
    "start": "1025679",
    "end": "1030880"
  },
  {
    "text": "becoming more and more boring and for automation that's great um so we're also",
    "start": "1030880",
    "end": "1037038"
  },
  {
    "text": "what we're also want to do is improve the security because we know that a lot of so if we have a a CVE uh because of a",
    "start": "1037039",
    "end": "1046400"
  },
  {
    "text": "library that we're using I know that you are all affected so we are trying to see how we can uh add some out like have",
    "start": "1046400",
    "end": "1054080"
  },
  {
    "text": "some periodic jobs to scan for those vulnerabilities so we can do a release faster and uh so you don't have issues",
    "start": "1054080",
    "end": "1060880"
  },
  {
    "text": "with uh image scans like 3y and uh yeah that's",
    "start": "1060880",
    "end": "1067480"
  },
  {
    "text": "me okay",
    "start": "1067480",
    "end": "1071480"
  },
  {
    "text": "u I will talk about the operator now and",
    "start": "1075000",
    "end": "1080160"
  },
  {
    "text": "the CD operator work group uh we started that about a year ago uh with the goal",
    "start": "1080160",
    "end": "1085919"
  },
  {
    "text": "of providing an operator that could manage at CD uh for the community and to",
    "start": "1085919",
    "end": "1092080"
  },
  {
    "text": "standardize on something that would be adopted by much more than a single company there",
    "start": "1092080",
    "end": "1098640"
  },
  {
    "text": "are lots of CD operators in the wild some better some worse some more",
    "start": "1098640",
    "end": "1105120"
  },
  {
    "text": "maintained than others so um we had a scope uh we started to",
    "start": "1105120",
    "end": "1112799"
  },
  {
    "text": "collect requirements use cases for that uh prioritize uh the work uh in terms of",
    "start": "1112799",
    "end": "1121360"
  },
  {
    "text": "what would be needed to have such an operator and reviewed existing uh",
    "start": "1121360",
    "end": "1127799"
  },
  {
    "text": "implementations from other companies we had numerous uh meetings about that",
    "start": "1127799",
    "end": "1134960"
  },
  {
    "text": "uh we decided to start from scratch and accept uh contributions from uh",
    "start": "1134960",
    "end": "1140880"
  },
  {
    "text": "interested parties uh so that we build something that is",
    "start": "1140880",
    "end": "1146960"
  },
  {
    "text": "modern and compliant with uh Kubernetes requirements so right now we have a new",
    "start": "1146960",
    "end": "1156440"
  },
  {
    "text": "repository bootstrapped uh everything uh that uh a project needs updates",
    "start": "1156440",
    "end": "1163960"
  },
  {
    "text": "uh and um we also started uh working on a P",
    "start": "1163960",
    "end": "1174520"
  },
  {
    "text": "um and uh a road map this uh operator was uh meant to be only",
    "start": "1174600",
    "end": "1184160"
  },
  {
    "text": "for running inside Kubernetes obviously because it's an operator so it's not for",
    "start": "1184160",
    "end": "1190080"
  },
  {
    "text": "bare metal clusters so if you want to start a cluster from scratch this is not",
    "start": "1190080",
    "end": "1195320"
  },
  {
    "text": "you um and we have a bi-weekly meeting in",
    "start": "1195320",
    "end": "1201679"
  },
  {
    "text": "case anyone wants to join the effort or provide feedback",
    "start": "1201679",
    "end": "1208039"
  },
  {
    "text": "cool uh for this CubeCon we have a milestone that's CD operator",
    "start": "1209160",
    "end": "1217320"
  },
  {
    "text": "0.1.0 that's the first uh release um it is a first step so don't",
    "start": "1217320",
    "end": "1224799"
  },
  {
    "text": "get too excited you cannot use it in production yet um we're just uh",
    "start": "1224799",
    "end": "1230320"
  },
  {
    "text": "bootstrapping the repo automated updates basic tests",
    "start": "1230320",
    "end": "1236159"
  },
  {
    "text": "uh release scripts and we're able to create a new cluster customize it with",
    "start": "1236159",
    "end": "1242080"
  },
  {
    "text": "whatever options you want uh and uh use",
    "start": "1242080",
    "end": "1247360"
  },
  {
    "text": "various CSI drivers for storage um we're grateful to all our contributors and uh",
    "start": "1247360",
    "end": "1254880"
  },
  {
    "text": "with special mentions to Ivan um Abdul Raman uh Ara and",
    "start": "1254880",
    "end": "1264120"
  },
  {
    "text": "uh G D",
    "start": "1264120",
    "end": "1268440"
  },
  {
    "text": "uh say good job to them uh they really",
    "start": "1271400",
    "end": "1276960"
  },
  {
    "text": "helped us get us to this point and uh Ara please uh present the future of",
    "start": "1276960",
    "end": "1284720"
  },
  {
    "text": "uh the operator uh thank you Sepron so let's look at how",
    "start": "1284720",
    "end": "1290480"
  },
  {
    "text": "the future work looks like for uh the city operator so in version 0.2 we'll be",
    "start": "1290480",
    "end": "1297840"
  },
  {
    "text": "enabling TLS communication through certificate management and uh starting",
    "start": "1297840",
    "end": "1303200"
  },
  {
    "text": "with the providers like search manager and auto auto providers so what auto",
    "start": "1303200",
    "end": "1308240"
  },
  {
    "text": "provider basically means that if you don't uh by default provide any uh",
    "start": "1308240",
    "end": "1314240"
  },
  {
    "text": "certificate provider it will automatically uh provide a certificate for you so the TLS configuration looks",
    "start": "1314240",
    "end": "1321039"
  },
  {
    "text": "something like this uh where there will be a provider say we are saying manager",
    "start": "1321039",
    "end": "1326720"
  },
  {
    "text": "and it will have a provider config followed uh which will have the respective uh provider configuration for",
    "start": "1326720",
    "end": "1334559"
  },
  {
    "text": "this instance is the search manager config and that will have its own necessary uh fields like common name",
    "start": "1334559",
    "end": "1341760"
  },
  {
    "text": "issuer kind which is relevant to that uh provider and we will be adding more",
    "start": "1341760",
    "end": "1347919"
  },
  {
    "text": "providers going ahead uh next is the upgrades uh upgrade is still supported",
    "start": "1347919",
    "end": "1352960"
  },
  {
    "text": "in 0.1 but in 0.2 we will be adding more tests and E2 uh workflows to fortify it",
    "start": "1352960",
    "end": "1361360"
  },
  {
    "text": "and that includes patch upgrades as well as minor upgrades uh for 0.3 and beyond we will be",
    "start": "1361360",
    "end": "1368720"
  },
  {
    "text": "implementing uh disaster recovery for each of the cluster members backup for",
    "start": "1368720",
    "end": "1375200"
  },
  {
    "text": "periodic and u on demand uh backup of the clusters as well as uh creation and",
    "start": "1375200",
    "end": "1383039"
  },
  {
    "text": "new uh uh restoration of new clusters uh from available backups and that brings us to the end of",
    "start": "1383039",
    "end": "1390960"
  },
  {
    "text": "our uh session uh thank you and we are open to questions",
    "start": "1390960",
    "end": "1397640"
  },
  {
    "text": "[Applause]",
    "start": "1397710",
    "end": "1404630"
  },
  {
    "text": "hi um yeah thanks for the updates uh was very insightful uh looking for this 36",
    "start": "1415760",
    "end": "1422960"
  },
  {
    "text": "release actually um so I'm I'm kind of have a well related question like not we",
    "start": "1422960",
    "end": "1430080"
  },
  {
    "text": "didn't mention it like but I'm I'm I'm thinking I'm considering about like having you know like multiple ETCD",
    "start": "1430080",
    "end": "1436840"
  },
  {
    "text": "clusters and syncing them all together for some use case and I know that uh",
    "start": "1436840",
    "end": "1443679"
  },
  {
    "text": "there is a tool to sync the clusters called like mirror maker I guess right",
    "start": "1443679",
    "end": "1449280"
  },
  {
    "text": "it's like a synchronous way of like syncing one cluster to another right uh but I",
    "start": "1449280",
    "end": "1454679"
  },
  {
    "text": "Wonder if this stuff kind of supports a birectional thing and if it is how can",
    "start": "1454679",
    "end": "1462320"
  },
  {
    "text": "it kind of makes the conflict resolution in that case or it's like just not a problem that ETCD ever will solve um",
    "start": "1462320",
    "end": "1469679"
  },
  {
    "text": "just trying again trying to understand um how to say um the possibilities right",
    "start": "1469679",
    "end": "1476240"
  },
  {
    "text": "of etc when it comes to several clusters that each has its own",
    "start": "1476240",
    "end": "1482960"
  },
  {
    "text": "quorums",
    "start": "1482960",
    "end": "1485440"
  },
  {
    "text": "Basically direction in both",
    "start": "1494039",
    "end": "1499120"
  },
  {
    "text": "directions still don't get question sorry could you could you could you",
    "start": "1511320",
    "end": "1516559"
  },
  {
    "text": "repeat sorry sorry what could you repeat sorry didn't get your question sorry yeah yeah um so",
    "start": "1516559",
    "end": "1524720"
  },
  {
    "text": "it's it's like um so hypothetical since I I I don't know i just like started looking into it um that I know that um",
    "start": "1524720",
    "end": "1532400"
  },
  {
    "text": "if you have multiple different cluster CTCD clusters each with its own quorum like each has let's say three nodes raft",
    "start": "1532400",
    "end": "1540080"
  },
  {
    "text": "right um and you need to sync the data from one cluster to another right so",
    "start": "1540080",
    "end": "1546559"
  },
  {
    "text": "there is a utility that you provide called the mirror maker oh right um but",
    "start": "1546559",
    "end": "1552480"
  },
  {
    "text": "and I know that it's kind of a synchronously replicates from one to another uh but um I'm I'm kind of like",
    "start": "1552480",
    "end": "1558480"
  },
  {
    "text": "wonder maybe you can also like from your side explain like the use case for it and and does it support maybe this like",
    "start": "1558480",
    "end": "1565840"
  },
  {
    "text": "birectional things and if it does how does it work with this um kind of",
    "start": "1565840",
    "end": "1573200"
  },
  {
    "text": "conflicts problem because each cluster can be consistent right but when it",
    "start": "1573200",
    "end": "1578480"
  },
  {
    "text": "comes to trying to make consistent clusters across geo distributional stuff it's kind of like hard problem right",
    "start": "1578480",
    "end": "1584960"
  },
  {
    "text": "okay got Um yeah yeah yeah you know the the mirror command I don't think the",
    "start": "1584960",
    "end": "1591120"
  },
  {
    "text": "community has verified the in production environment it is just a command for user to use I don't think is verified by",
    "start": "1591120",
    "end": "1599279"
  },
  {
    "text": "in production if you want to migrate from one cluster to another cluster I think the backup and restore is the",
    "start": "1599279",
    "end": "1606159"
  },
  {
    "text": "simple is most simple is most robust way to do that if you want to do migrate",
    "start": "1606159",
    "end": "1612640"
  },
  {
    "text": "data online I think The probably the best way I can think of is for example",
    "start": "1612640",
    "end": "1618799"
  },
  {
    "text": "if you want to migrate from one data uh data center to another data center you could you can add a member in another",
    "start": "1618799",
    "end": "1625679"
  },
  {
    "text": "data center join to the existing cluster and then remove one member from",
    "start": "1625679",
    "end": "1632159"
  },
  {
    "text": "the old data center and then add a new the second one in the new data center",
    "start": "1632159",
    "end": "1637520"
  },
  {
    "text": "just rolling migrate member one by one this is probably the you can do this online you want to",
    "start": "1637520",
    "end": "1644480"
  },
  {
    "text": "offline just back up restore yeah okay yeah I see yeah thanks a lot",
    "start": "1644480",
    "end": "1652679"
  },
  {
    "text": "thank you uh thank you i just first thing I wanted to say was thank you for forming the working group and picking",
    "start": "1666080",
    "end": "1671679"
  },
  {
    "text": "this project up and putting your time into it i think it was silently terrifying for a lot of people that CD",
    "start": "1671679",
    "end": "1678480"
  },
  {
    "text": "was kind of getting into a state that it was in so really really appreciate it thank you um kind of curious to hear if",
    "start": "1678480",
    "end": "1685520"
  },
  {
    "text": "you have any thoughts that you don't have to well I'm not going to hold you to anything that you say but kind of",
    "start": "1685520",
    "end": "1691360"
  },
  {
    "text": "like beyond the initial road map like what are you thinking like if you think like a couple of years out are there any",
    "start": "1691360",
    "end": "1697200"
  },
  {
    "text": "things that you kind of want to do that it doesn't do or things that it could be used for that it's not used for today or",
    "start": "1697200",
    "end": "1702640"
  },
  {
    "text": "like spaces that you would like to see it grow into",
    "start": "1702640",
    "end": "1707720"
  },
  {
    "text": "again yeah yeah please yeah sorry oh it's okay it's just an an open-ended question about kind of longer term plans",
    "start": "1714480",
    "end": "1722159"
  },
  {
    "text": "or ideas that you have even if you haven't fully fleshed them out or like areas where you would like to see more",
    "start": "1722159",
    "end": "1728480"
  },
  {
    "text": "work go into where maybe people can help help you or or stuff like that",
    "start": "1728480",
    "end": "1734760"
  },
  {
    "text": "oh yeah uh for the for the future work you know",
    "start": "1735640",
    "end": "1741159"
  },
  {
    "text": "uh you know just mentioned you know currently we are still bootstrap LCD from V2 store and replay the world",
    "start": "1741159",
    "end": "1748720"
  },
  {
    "text": "record based on the latest V2 snapshots you know the V2 store is already",
    "start": "1748720",
    "end": "1754360"
  },
  {
    "text": "deprecated in F7 we are going to bootstrap LD from W3 store and replay",
    "start": "1754360",
    "end": "1760799"
  },
  {
    "text": "the world record starting from the consistent index this is a major change",
    "start": "1760799",
    "end": "1767360"
  },
  {
    "text": "so we need probably need carbon maintainer to collaborate for this this is the main change for the F7 server the",
    "start": "1767360",
    "end": "1774399"
  },
  {
    "text": "second change is to second thing priority i think we need to spend more effort on",
    "start": "1774399",
    "end": "1780360"
  },
  {
    "text": "performance in the in the previous we received several issue of complaint about memory usage on LCD probably we",
    "start": "1780360",
    "end": "1787520"
  },
  {
    "text": "are spend more effort to improve memory usage in the 37 yeah these are two thing I can think of yeah",
    "start": "1787520",
    "end": "1797039"
  },
  {
    "text": "hey guys uh thanks for the insightful session uh my question is related to HCD",
    "start": "1797039",
    "end": "1802880"
  },
  {
    "text": "uh database size where like uh with the current limits of 8GB but we do have a",
    "start": "1802880",
    "end": "1808039"
  },
  {
    "text": "requirement we're hitting those thresholds because of hundreds of controllers which we're running",
    "start": "1808039",
    "end": "1814799"
  },
  {
    "text": "uh due to performance issues you guys limit that size to 8GB right so in the",
    "start": "1814799",
    "end": "1820480"
  },
  {
    "text": "advanced editions like versions is there any consideration to increase that size",
    "start": "1820480",
    "end": "1828200"
  },
  {
    "text": "sorry so can can we repeat again sorry the HCD uh database size from 8GB hard",
    "start": "1828799",
    "end": "1837080"
  },
  {
    "text": "limit to increase up to next size sorry",
    "start": "1837080",
    "end": "1845480"
  },
  {
    "text": "oh yeah uh yeah currently the the default is 2",
    "start": "1846679",
    "end": "1853640"
  },
  {
    "text": "GB the default quarter is 2 GB and the user can but is configurable us can",
    "start": "1853640",
    "end": "1860640"
  },
  {
    "text": "change the quarter can do eight or 16 GB whatever but the problem is when uh when",
    "start": "1860640",
    "end": "1868000"
  },
  {
    "text": "a new member join the cluster we need to send a snapshot to the new member so",
    "start": "1868000",
    "end": "1873679"
  },
  {
    "text": "when you send uh send a huge snapshot this is one thing but probably the",
    "start": "1873679",
    "end": "1881120"
  },
  {
    "text": "network network bandwidth is not big problem because they have high throughput in the current the second",
    "start": "1881120",
    "end": "1888080"
  },
  {
    "text": "thing is you know we add the memory the DB file into memory directly so the",
    "start": "1888080",
    "end": "1895520"
  },
  {
    "text": "bigger the DB size the more memory usage and we also have some internal",
    "start": "1895520",
    "end": "1900880"
  },
  {
    "text": "cache which means when you have more data then you have more catch so the",
    "start": "1900880",
    "end": "1906799"
  },
  {
    "text": "memory is is big pressure for the LCD that's the reason the LCD is designed",
    "start": "1906799",
    "end": "1912399"
  },
  {
    "text": "for metadata is not for large scale data",
    "start": "1912399",
    "end": "1919279"
  },
  {
    "text": "Yeah yeah yeah thank you",
    "start": "1924760",
    "end": "1929720"
  }
]
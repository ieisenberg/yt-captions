[
  {
    "text": "welcome everyone to the wit maintainer talk my name is deepti sigi and I'm uh",
    "start": "640",
    "end": "8519"
  },
  {
    "text": "the tech lead for vus and I'm a software engineer at Planet",
    "start": "8519",
    "end": "14400"
  },
  {
    "text": "scale uh hello I'm kazimir Salis software relability engineer in Vitz",
    "start": "14400",
    "end": "20080"
  },
  {
    "text": "databases team and we'll be presenting uh user story of VES invented and uh I'm",
    "start": "20080",
    "end": "27359"
  },
  {
    "text": "Floren poar I'm a maintainer of the Vitz project and I'm also a software engineer at plan",
    "start": "27359",
    "end": "32439"
  },
  {
    "text": "scal so today we're going to start by presenting to you what is vest we're going to give a brief overview of the",
    "start": "32440",
    "end": "38800"
  },
  {
    "text": "project and then kazimieras will talk to you about the Vinted user story their adoption and how they're using Vitz and",
    "start": "38800",
    "end": "46480"
  },
  {
    "text": "finally Dy we talk to you about the new and up and upcoming exciting features of vites and at the end we'll have some",
    "start": "46480",
    "end": "53039"
  },
  {
    "text": "time for question and answers all right let's get started what is vitess so Vitz is a cloud name scat",
    "start": "53039",
    "end": "60719"
  },
  {
    "text": "and distributed database it is built around my SQL in fact it started in 2010",
    "start": "60719",
    "end": "67240"
  },
  {
    "text": "at uh YouTube as a skating solution for my SQL later it was donated by YouTube",
    "start": "67240",
    "end": "72640"
  },
  {
    "text": "to cncf in 2018 and then it became a graduate Project A year later in",
    "start": "72640",
    "end": "80079"
  },
  {
    "text": "2019 uh it is massively scalable because we have sharding in vest which allows",
    "start": "80079",
    "end": "86079"
  },
  {
    "text": "you to partition your data across multiple primaries and then then it is highly available because we Whenever",
    "start": "86079",
    "end": "93240"
  },
  {
    "text": "there is a failure on the primary we're going to we're going to detect it and repair",
    "start": "93240",
    "end": "98720"
  },
  {
    "text": "it uh so vas is widely used in production by many many companies from small to extremely large and we have a",
    "start": "98720",
    "end": "106719"
  },
  {
    "text": "few key adopters like slack who's running 100% on vest so every time you send a slack message it's going through",
    "start": "106719",
    "end": "113640"
  },
  {
    "text": "vest we also have GitHub um they're running all of their issues and pro",
    "start": "113640",
    "end": "118880"
  },
  {
    "text": "request on vitess and I think they have a little bit less than a million QPS on average we also have Vinted which",
    "start": "118880",
    "end": "125880"
  },
  {
    "text": "kasimas will talk about soon but they do about 2.2 Millions QPS and finally we have Planet scale",
    "start": "125880",
    "end": "132920"
  },
  {
    "text": "database Sav where they have approximately 10,000 different uh vs",
    "start": "132920",
    "end": "138800"
  },
  {
    "text": "cluster running in production so of course we're uh an open",
    "start": "138800",
    "end": "144640"
  },
  {
    "text": "source project we have about 15 maintainers working on the project and",
    "start": "144640",
    "end": "149959"
  },
  {
    "text": "over the last year we had a little bit more than 250 contributors from which",
    "start": "149959",
    "end": "155280"
  },
  {
    "text": "115 were Cod contributors all of those came from 47 companies and the Cod",
    "start": "155280",
    "end": "161239"
  },
  {
    "text": "contributors came from a little bit more than 20 companies so before I move into the move",
    "start": "161239",
    "end": "167640"
  },
  {
    "text": "on to the more technical part of the talk we should introduce four key word",
    "start": "167640",
    "end": "173480"
  },
  {
    "text": "for about vest so first one is a keyspace so a keyspace is basically the",
    "start": "173480",
    "end": "178560"
  },
  {
    "text": "same as a myql logical database so you can have",
    "start": "178560",
    "end": "184239"
  },
  {
    "text": "the user keyspace and inside of that keyspace you're going to have a bunch of tables related to the user data like",
    "start": "184239",
    "end": "189560"
  },
  {
    "text": "users users meta metadata Etc and then we have a Shard A Shard is basically a",
    "start": "189560",
    "end": "195360"
  },
  {
    "text": "subset of that keyspace and you can have one or more Shard per keyspace and every Shard is composed of one primary and at",
    "start": "195360",
    "end": "203080"
  },
  {
    "text": "least and one or more replica um we have V schema so V schema",
    "start": "203080",
    "end": "209120"
  },
  {
    "text": "is a specification on how you want to Shard a specific table and it is user defined it's",
    "start": "209120",
    "end": "216959"
  },
  {
    "text": "flexible and uh and that's it and then we have a vindex which is used inside of the V schema that vindex is basically",
    "start": "216959",
    "end": "223879"
  },
  {
    "text": "going to be the same as the myal index uh here's a diagram of the",
    "start": "223879",
    "end": "231360"
  },
  {
    "text": "architecture of vest on the right hand side we have Shard 1 2 3 n and like I",
    "start": "231360",
    "end": "236439"
  },
  {
    "text": "said before those are composed of one primary and then one or more replicas and then we can see if we look at the",
    "start": "236439",
    "end": "241799"
  },
  {
    "text": "primary for example we have my and VT tablet so the my is basically the myd",
    "start": "241799",
    "end": "248400"
  },
  {
    "text": "instance process uh that's where we're going to store the tables Etc and then attached to it as a side car we're going",
    "start": "248400",
    "end": "254560"
  },
  {
    "text": "to have V tablet so v Tablet is going to send and manage um all the queries sorry",
    "start": "254560",
    "end": "261519"
  },
  {
    "text": "it's going to send all the queries down to my schol D and it's going to help manage my scho d as",
    "start": "261519",
    "end": "267000"
  },
  {
    "text": "well v Tablet is connected to vate which is the central component here and it",
    "start": "267000",
    "end": "275080"
  },
  {
    "text": "communicates through grpc and the SQL protocol so yeah vtk so that's like the",
    "start": "275080",
    "end": "282320"
  },
  {
    "text": "most user facing component it's um it connects to your application using also",
    "start": "282320",
    "end": "288039"
  },
  {
    "text": "grpc or the SQL protocol and it's going to receive a query it's going to unpar the query and",
    "start": "288039",
    "end": "295360"
  },
  {
    "text": "interpret the query and then it's going to send it down to the proper Shard and key space",
    "start": "295360",
    "end": "301639"
  },
  {
    "text": "uh in yellow we have the control plane so vld is the CLI tool to administrate",
    "start": "301840",
    "end": "308000"
  },
  {
    "text": "vest vork is the orchestration tool this is what allows us to detect the failure and repair the failure in the cluster",
    "start": "308000",
    "end": "315120"
  },
  {
    "text": "and finally we have V admin which is the UI of the of VES the administration UI",
    "start": "315120",
    "end": "322759"
  },
  {
    "text": "of VES and in red finally we have the topology servers so those can be usually",
    "start": "322759",
    "end": "329720"
  },
  {
    "text": "etcd zooke keeper or I think that's all I will support maybe we support more but",
    "start": "329720",
    "end": "334880"
  },
  {
    "text": "usually it's etcd uh so why would you want to use vess compared to Van MySQL so we're",
    "start": "334880",
    "end": "342440"
  },
  {
    "text": "trying to be as compatible as possible with mySQL so we're adding query support",
    "start": "342440",
    "end": "348600"
  },
  {
    "text": "um over each release to be as compatible as we can uh we have restarting which",
    "start": "348600",
    "end": "354759"
  },
  {
    "text": "allows you to restart your data in as many shards as you want we have",
    "start": "354759",
    "end": "359800"
  },
  {
    "text": "materialization which is almost the same as the my schol materialization but we update the view in real time we have",
    "start": "359800",
    "end": "367720"
  },
  {
    "text": "cluster management so we have different tools to allow you to manage your cluster we have non-blocking online",
    "start": "367720",
    "end": "374400"
  },
  {
    "text": "schema changes simulus backup recovery operations we also have query consolidation so let's say you have a",
    "start": "374400",
    "end": "382599"
  },
  {
    "text": "student spike in in your queries using the same query we're going to send that",
    "start": "382599",
    "end": "388639"
  },
  {
    "text": "query only once to my SQL get the result and respond to all the queries at the",
    "start": "388639",
    "end": "394120"
  },
  {
    "text": "same time from vate to not overload the myql and then we have automatic fader",
    "start": "394120",
    "end": "402240"
  },
  {
    "text": "detection and repair so that's thanks to vtor now I'm going to pass it to kazas",
    "start": "402240",
    "end": "408639"
  },
  {
    "text": "to talk about the Vintage user story uh hello again I will present how and why",
    "start": "408639",
    "end": "413720"
  },
  {
    "text": "we use advented with us clusters uh let's start what we do at",
    "start": "413720",
    "end": "419199"
  },
  {
    "text": "first uh Ved applications allow to sell secondhand fashion easily and safely and",
    "start": "419199",
    "end": "426639"
  },
  {
    "text": "with over 80 million users in 19 markets in Europe and North America we are on",
    "start": "426639",
    "end": "432720"
  },
  {
    "text": "the um aim to make secondhand fashion preferred world uh Preferred Choice",
    "start": "432720",
    "end": "440199"
  },
  {
    "text": "worldwide sorry uh I'm very excited to present here in Paris because uh in even",
    "start": "440199",
    "end": "448560"
  },
  {
    "text": "all the France our user Community is biggest and that's why a few years back we",
    "start": "448560",
    "end": "456360"
  },
  {
    "text": "decided to start here our second brand Vinted go that uh helped",
    "start": "456360",
    "end": "462479"
  },
  {
    "text": "to uh make uh better control of of shipping of packages and take uh impact",
    "start": "462479",
    "end": "471479"
  },
  {
    "text": "on climate of shipping and currently wied go Works in over 90 ciens in France",
    "start": "471479",
    "end": "477400"
  },
  {
    "text": "with over 1,500 pickup and drop off points and whenever a user adds some",
    "start": "477400",
    "end": "484599"
  },
  {
    "text": "item to sell on minted Marketplace sends any message or ships any package all",
    "start": "484599",
    "end": "490879"
  },
  {
    "text": "this information is store in one of our vtest clusters uh we are running currently",
    "start": "490879",
    "end": "498159"
  },
  {
    "text": "vest version 11 with some back ports mostly uh some Buck fixes or",
    "start": "498159",
    "end": "503280"
  },
  {
    "text": "improvements for operations uh all the Clusters runs on beer metal uh managed by all the host",
    "start": "503280",
    "end": "510919"
  },
  {
    "text": "are managed by chef and for any cluster level operations like monitoring backups",
    "start": "510919",
    "end": "516959"
  },
  {
    "text": "provisioning we write a workflows using a temporal system um as the VZ is cloud native we",
    "start": "516959",
    "end": "523760"
  },
  {
    "text": "would like to move this way and First Steps we're taking we moving B gates to",
    "start": "523760",
    "end": "530000"
  },
  {
    "text": "kubernetes and currently we have uh over an 80 uh",
    "start": "530000",
    "end": "536279"
  },
  {
    "text": "clusters and these clusters run uh over 200 shards it's all these shards",
    "start": "536279",
    "end": "542959"
  },
  {
    "text": "consisting from eight VT tablets paired with aqal instance and they're spread",
    "start": "542959",
    "end": "549480"
  },
  {
    "text": "through two regions like in every sh four VT tablets run in one region and",
    "start": "549480",
    "end": "554640"
  },
  {
    "text": "four in another uh and all this allows us to serve over 1.2 million queries from",
    "start": "554640",
    "end": "561120"
  },
  {
    "text": "primaries and about 1 million queries from replicas we have about 30 terabyt",
    "start": "561120",
    "end": "566800"
  },
  {
    "text": "of data and we run 5,000 V streams to",
    "start": "566800",
    "end": "572120"
  },
  {
    "text": "export data changes from vtas to other systems like data warehouse or search",
    "start": "572120",
    "end": "579440"
  },
  {
    "text": "clusters uh and why vs um one of the features that I like in vs is throttling",
    "start": "579440",
    "end": "586240"
  },
  {
    "text": "API that allows developers when they need to backfill some data or change a",
    "start": "586240",
    "end": "593600"
  },
  {
    "text": "lot of data in the database they can write a job which asks first the database uh is it healthy enough and",
    "start": "593600",
    "end": "601560"
  },
  {
    "text": "then write a small badge and ask again in this way uh allowing to throttle if",
    "start": "601560",
    "end": "606760"
  },
  {
    "text": "the database comes up to its limit and allows to uh for us to avoid some",
    "start": "606760",
    "end": "613480"
  },
  {
    "text": "outages if we accidentally try to write a lot too much data than the cluster can",
    "start": "613480",
    "end": "619720"
  },
  {
    "text": "sustain uh when we first moved to vest we initially had multiple myql clusters",
    "start": "619720",
    "end": "627240"
  },
  {
    "text": "that were Shed from application side uh but we saw that we uh need a better",
    "start": "627240",
    "end": "634640"
  },
  {
    "text": "solution we started testing with us uh brought a benchmarking tool that allowed",
    "start": "634640",
    "end": "640600"
  },
  {
    "text": "to capture our workload from application like all we had a feature switch that",
    "start": "640600",
    "end": "646560"
  },
  {
    "text": "when we send some query to VES we would send the same query to Kafka then we",
    "start": "646560",
    "end": "652320"
  },
  {
    "text": "would uh query and some metadata and from that metadata we would uh",
    "start": "652320",
    "end": "657680"
  },
  {
    "text": "collect uh queries from the same request into separate Badges and could replay on a test",
    "start": "657680",
    "end": "663839"
  },
  {
    "text": "environment um then let's say migrate that environment to vest and compare how",
    "start": "663839",
    "end": "669800"
  },
  {
    "text": "it goes uh another uh test show that it",
    "start": "669800",
    "end": "675880"
  },
  {
    "text": "has added just 2 milliseconds per query latency which is very nice with all the",
    "start": "675880",
    "end": "681079"
  },
  {
    "text": "additional features that we get uh so we switched to the test initially we switched to version 8 and later upgraded",
    "start": "681079",
    "end": "688200"
  },
  {
    "text": "to version 11 uh use the same uh benchmarking tool to",
    "start": "688200",
    "end": "693920"
  },
  {
    "text": "see how the upgrade would go uh uh another very nice feature of",
    "start": "693920",
    "end": "700040"
  },
  {
    "text": "vest uh is moving data inside the cluster and even importing from my SQL clusters it's called V application and",
    "start": "700040",
    "end": "707760"
  },
  {
    "text": "we diff for verifying this data move and it allows not only to easily move the",
    "start": "707760",
    "end": "713440"
  },
  {
    "text": "data but after cut off it allows to replicate data back in case something goes wrong like you",
    "start": "713440",
    "end": "719959"
  },
  {
    "text": "provision two small cluster on the other side whatever we can switch back to",
    "start": "719959",
    "end": "726480"
  },
  {
    "text": "previous configuration without losing any data uh but the primary reason why we",
    "start": "726480",
    "end": "733839"
  },
  {
    "text": "chose vest is a that it allows horizontal sharding on top of my SQL",
    "start": "733839",
    "end": "739440"
  },
  {
    "text": "when you have one cluster of my SQL having only one table that you do not have like what to move out and it's",
    "start": "739440",
    "end": "746480"
  },
  {
    "text": "already too big like migrations takes multiple weeks um backup sticks very",
    "start": "746480",
    "end": "752199"
  },
  {
    "text": "long and uh the query latency starts to rise because of the load this where it",
    "start": "752199",
    "end": "758639"
  },
  {
    "text": "comes to help uh we initially moved our clusters",
    "start": "758639",
    "end": "764839"
  },
  {
    "text": "as they are into vest like every cluster moved to one key space with one Shard",
    "start": "764839",
    "end": "770120"
  },
  {
    "text": "and later on we started sharding the most loaded ones",
    "start": "770120",
    "end": "775959"
  },
  {
    "text": "horizontally uh this required some more tooling uh first thing that we did we",
    "start": "775959",
    "end": "781360"
  },
  {
    "text": "enabled testing in our cicd pipeline uh on a horizontal sh sharded with test",
    "start": "781360",
    "end": "788880"
  },
  {
    "text": "that developers could just see in the code oh these tables are horizontally sharded and the test would run on",
    "start": "788880",
    "end": "795240"
  },
  {
    "text": "actually sharded with us and tell them if anything fails because the query compatibility on sharded is a bit",
    "start": "795240",
    "end": "801920"
  },
  {
    "text": "different and there is other things to watch out like cross Shard",
    "start": "801920",
    "end": "807880"
  },
  {
    "text": "transactions uh or cross joints that are more complicated and the other thing that",
    "start": "807880",
    "end": "815880"
  },
  {
    "text": "test do not catch all the queries so we build a uh in our query logging solution",
    "start": "815880",
    "end": "822519"
  },
  {
    "text": "that collects all the unique queries and we can run VT explain Tool uh similar to",
    "start": "822519",
    "end": "827959"
  },
  {
    "text": "myql explain VT explain allows to see how we test with",
    "start": "827959",
    "end": "834279"
  },
  {
    "text": "uh execute the query uh if it fails if it succeeds and running on this unique",
    "start": "834279",
    "end": "840759"
  },
  {
    "text": "where is pretty much is enough to understand if your code would work when",
    "start": "840759",
    "end": "845839"
  },
  {
    "text": "switch to horizontal sharding and what benefit we got uh",
    "start": "845839",
    "end": "852040"
  },
  {
    "text": "there is uh historical screenshot from our grafana when we switched uh one of",
    "start": "852040",
    "end": "858600"
  },
  {
    "text": "the most loaded key spaces into horizontal sharding uh how Laten is dropped on",
    "start": "858600",
    "end": "865720"
  },
  {
    "text": "primary on queries going to primaries and all the magic behind this was like",
    "start": "865720",
    "end": "871399"
  },
  {
    "text": "vest horizontal sharding with four time more Hardware serving this",
    "start": "871399",
    "end": "876720"
  },
  {
    "text": "keyspace so here is a very short overview what we do with the but you can",
    "start": "876720",
    "end": "882000"
  },
  {
    "text": "read in our blog win. engineering uh the stor is in much more details we have",
    "start": "882000",
    "end": "888040"
  },
  {
    "text": "multiple uh blog post v v v voage how we",
    "start": "888040",
    "end": "893440"
  },
  {
    "text": "migrated from AQL to vest uh how our cicd pipeline works and we hope to have",
    "start": "893440",
    "end": "899480"
  },
  {
    "text": "more blog post about with this in the future thank",
    "start": "899480",
    "end": "905079"
  },
  {
    "text": "[Applause] you we'll move on to the new and",
    "start": "907020",
    "end": "913320"
  },
  {
    "text": "upcoming features uh we did wits version 18 in",
    "start": "913320",
    "end": "918639"
  },
  {
    "text": "November of last year and witus version 19 earlier this month uh in the first",
    "start": "918639",
    "end": "924079"
  },
  {
    "text": "week of March so I'll cover um what is new in these two latest releases and",
    "start": "924079",
    "end": "930800"
  },
  {
    "text": "then talk a little bit about what we plan to do in future",
    "start": "930800",
    "end": "936000"
  },
  {
    "text": "releases uh let's do query serving first this is always a Hot Topic because my",
    "start": "936120",
    "end": "941680"
  },
  {
    "text": "SQL is a moving Target they keep adding uh syntax new syntax new features and we",
    "start": "941680",
    "end": "947160"
  },
  {
    "text": "have to keep up with those uh some of the things that have been added in one",
    "start": "947160",
    "end": "952560"
  },
  {
    "text": "of the last two releases uh basic support for selects using Comon table",
    "start": "952560",
    "end": "957920"
  },
  {
    "text": "expressions we've added experimental foreign key support uh most vtus users",
    "start": "957920",
    "end": "965240"
  },
  {
    "text": "don't actually use foreign keys because at the scale at which people run vas it's simply not practical to use foreign",
    "start": "965240",
    "end": "972399"
  },
  {
    "text": "key constraints uh there is a perceptible performance hit but there are uh smaller",
    "start": "972399",
    "end": "978519"
  },
  {
    "text": "users of Wis who would like to keep the foreign key functionality while still adopting with us so this is still",
    "start": "978519",
    "end": "985079"
  },
  {
    "text": "experimental but it looks good and and uh people can try it",
    "start": "985079",
    "end": "991600"
  },
  {
    "text": "out the other thing that we added was support for views across shards this is",
    "start": "991600",
    "end": "997199"
  },
  {
    "text": "something that you just can't do in MySQL views are local to um a given",
    "start": "997199",
    "end": "1002480"
  },
  {
    "text": "MySQL server but with wit you can actually create views that are cross Shard that are managed by vus and um",
    "start": "1002480",
    "end": "1010680"
  },
  {
    "text": "queries against those views work even when the underlying data has to go across shards we've added better support",
    "start": "1010680",
    "end": "1017959"
  },
  {
    "text": "for unions derived tables and subqueries and we also revamped our",
    "start": "1017959",
    "end": "1023440"
  },
  {
    "text": "benchmarking website so this is the uh vest sub project that we call are we",
    "start": "1023440",
    "end": "1029000"
  },
  {
    "text": "fast yet benchmark.us doio and we run uh",
    "start": "1029000",
    "end": "1034120"
  },
  {
    "text": "a certain number of benchmarks every day and we also measure every new release",
    "start": "1034120",
    "end": "1039280"
  },
  {
    "text": "against the previous release to make sure that there are no regressions in terms of query performance and these",
    "start": "1039280",
    "end": "1046240"
  },
  {
    "text": "include oltp olap uh which are CIS bench and also tpcc",
    "start": "1046240",
    "end": "1052760"
  },
  {
    "text": "workloads uh we have a new UI for uh the website and um it's much more usable",
    "start": "1052760",
    "end": "1060480"
  },
  {
    "text": "than the previous version uh We've added V schema validations as Flora mentioned",
    "start": "1060480",
    "end": "1065960"
  },
  {
    "text": "V schema is how you specify to wit us how you want to do the horizontal sharding and uh it's done per table",
    "start": "1065960",
    "end": "1074400"
  },
  {
    "text": "previously it was possible to have errors in your V schema and you would not find out until you actually started",
    "start": "1074400",
    "end": "1081240"
  },
  {
    "text": "running the queries whereas now uh we actually do some validations up",
    "start": "1081240",
    "end": "1086720"
  },
  {
    "text": "front we've added some uh my SQL syntax extensions we do this periodically just",
    "start": "1086720",
    "end": "1093120"
  },
  {
    "text": "to provide usability for people who are using Vitus that through VT gate you can",
    "start": "1093120",
    "end": "1099039"
  },
  {
    "text": "uh execute some MySQL like commands which are not actually my SQL commands",
    "start": "1099039",
    "end": "1104679"
  },
  {
    "text": "and one of them the new one is V explain so the VT explain tool that winted used",
    "start": "1104679",
    "end": "1111120"
  },
  {
    "text": "to uh check the query compatibility before they actually did their horizontal sharding you can actually",
    "start": "1111120",
    "end": "1117799"
  },
  {
    "text": "also use on a running witht cluster using BT gate and we explain we'll tell",
    "start": "1117799",
    "end": "1123120"
  },
  {
    "text": "you how that query is going to be executed which shards it will go to",
    "start": "1123120",
    "end": "1128240"
  },
  {
    "text": "whether it is cross Shard which uh Vex will be used and so on we've also added",
    "start": "1128240",
    "end": "1135000"
  },
  {
    "text": "support for deletes and updates with joints",
    "start": "1135000",
    "end": "1140720"
  },
  {
    "text": "uh moving on to other parts of vtus the CLI migrations and so on uh We've",
    "start": "1141039",
    "end": "1147640"
  },
  {
    "text": "completely Rewritten the wit CLI to use Cobra and uh we reimplemented all of the",
    "start": "1147640",
    "end": "1154080"
  },
  {
    "text": "flags using wiper previously we were using the built-in goang flag Library",
    "start": "1154080",
    "end": "1159520"
  },
  {
    "text": "which led to flag pollution so if different witas binaries shared the same",
    "start": "1159520",
    "end": "1164640"
  },
  {
    "text": "golang package they would all get all the flags whether or not they were relevant so uh with wiper we've actually",
    "start": "1164640",
    "end": "1172480"
  },
  {
    "text": "been able to clean up all of that and we also have the nice benefit of",
    "start": "1172480",
    "end": "1177600"
  },
  {
    "text": "autogenerating the reference documentation for the CLI and the flags",
    "start": "1177600",
    "end": "1183240"
  },
  {
    "text": "and the flag reference dos actually makes sense because whatever you see in the docs are all valid flags for those",
    "start": "1183240",
    "end": "1191280"
  },
  {
    "text": "binaries uh the other thing wiper lets us do is dynamic reload of the",
    "start": "1191280",
    "end": "1196640"
  },
  {
    "text": "configuration uh right now very small subset of the flags can be reloaded dynamically but this allows us to add",
    "start": "1196640",
    "end": "1204080"
  },
  {
    "text": "more Flags to that set of uh Dynamic reloading of flags which means that you",
    "start": "1204080",
    "end": "1210400"
  },
  {
    "text": "don't need to restart the process you don't need to send it a Sig up uh when",
    "start": "1210400",
    "end": "1215480"
  },
  {
    "text": "the config file changes it will automatically be reloaded Vitus comes with a kubernetes",
    "start": "1215480",
    "end": "1222360"
  },
  {
    "text": "operator and uh in the most recent release we actually uh started letting",
    "start": "1222360",
    "end": "1229440"
  },
  {
    "text": "the operator manage my SQL minor version upgrades it is still considered too",
    "start": "1229440",
    "end": "1234960"
  },
  {
    "text": "risky to do a major MySQL version upgrade purely through the operator so this is minor uh releases only so for",
    "start": "1234960",
    "end": "1242520"
  },
  {
    "text": "example MySQL 57 to 8.0 is probably not a great idea to do an in place upgrade",
    "start": "1242520",
    "end": "1248159"
  },
  {
    "text": "on a running vus cluster but if it's an 0 minor version it's generally safe and",
    "start": "1248159",
    "end": "1254640"
  },
  {
    "text": "uh you just change the image tag and the operator will manage uh r roll out of all of the components with the new MySQL",
    "start": "1254640",
    "end": "1263440"
  },
  {
    "text": "version uh we did a security audit of vest last year and the results were",
    "start": "1263440",
    "end": "1269000"
  },
  {
    "text": "published uh by cncf as a Blog and there were some recommendations that came out",
    "start": "1269000",
    "end": "1274720"
  },
  {
    "text": "of that the high priority things were fixed right away but there were some medium priority issues that we fixed in",
    "start": "1274720",
    "end": "1280120"
  },
  {
    "text": "the last couple of releases uh We've also added support for",
    "start": "1280120",
    "end": "1285240"
  },
  {
    "text": "incremental backups and point in time recovery point time recovery is a vtest feature that has actually been around",
    "start": "1285240",
    "end": "1292080"
  },
  {
    "text": "for four or 5 years now but it depended on being able to uh read the bin logs",
    "start": "1292080",
    "end": "1299720"
  },
  {
    "text": "from a bin log server which had to be yet another component that you needed to deploy make it highly available and all",
    "start": "1299720",
    "end": "1306720"
  },
  {
    "text": "those things and that was complicated enough that most people would actually not use the feature we have",
    "start": "1306720",
    "end": "1313400"
  },
  {
    "text": "reimplemented the feature to not require a separate bin log server we can just use use the binary log files from my SQL",
    "start": "1313400",
    "end": "1321159"
  },
  {
    "text": "to do point in time recovery uh the other thing I want to talk about is near zero downtime",
    "start": "1321159",
    "end": "1327480"
  },
  {
    "text": "migration cutovers so there are various operations you do in Vitus where it is",
    "start": "1327480",
    "end": "1333480"
  },
  {
    "text": "possible to have downtime your primary goes down you have to fail over to a replica you have a certain amount of",
    "start": "1333480",
    "end": "1340760"
  },
  {
    "text": "down downtime it might be seconds it might be a minute but you also have",
    "start": "1340760",
    "end": "1346520"
  },
  {
    "text": "planned operations when you're doing Main maintenance on your cluster you want to be able to fail over from a",
    "start": "1346520",
    "end": "1352120"
  },
  {
    "text": "primary to a replica MySQL so that you can do upgrades and other types of maintenance on your primary and those",
    "start": "1352120",
    "end": "1359279"
  },
  {
    "text": "planned failovers we want to be zero downtime and Vitus has functionality for",
    "start": "1359279",
    "end": "1365080"
  },
  {
    "text": "buffering right qu right traffic to the primary and after the failover once you",
    "start": "1365080",
    "end": "1371120"
  },
  {
    "text": "have a new primary that traffic will be sent to the new primary reads will still work you can still do replica queries uh",
    "start": "1371120",
    "end": "1378640"
  },
  {
    "text": "while this operation is happening there will be no interruption but for wrs there will be a pause and then the",
    "start": "1378640",
    "end": "1384880"
  },
  {
    "text": "queries will be reprocessed so that you don't return errors to the client to the",
    "start": "1384880",
    "end": "1390559"
  },
  {
    "text": "application but we've also implemented this buffering functionality for data",
    "start": "1390559",
    "end": "1395880"
  },
  {
    "text": "migrations so if you're doing if you're using vus move tables to move data from",
    "start": "1395880",
    "end": "1400960"
  },
  {
    "text": "your existing MySQL into a wit managed cluster there is a point in time where",
    "start": "1400960",
    "end": "1406240"
  },
  {
    "text": "you've finished all the copying and you want to cut over traffic to the new cluster previously there would be",
    "start": "1406240",
    "end": "1413159"
  },
  {
    "text": "between 10 and 30 seconds of downtime during that cutover but now that we've implemented buffering you don't have",
    "start": "1413159",
    "end": "1420240"
  },
  {
    "text": "that even during those cutovers and the same thing applies to resharding when you do resharding as",
    "start": "1420240",
    "end": "1426360"
  },
  {
    "text": "kazimir has mentioned when you do resharding it's possible to switch back and forth and keep the uh old cluster",
    "start": "1426360",
    "end": "1435520"
  },
  {
    "text": "and new cluster in sync the same thing works for importing data or doing",
    "start": "1435520",
    "end": "1440840"
  },
  {
    "text": "vertical sharding where you're migrating tables from one keyspace to another you can go back and forth but each time",
    "start": "1440840",
    "end": "1447799"
  },
  {
    "text": "there would be a short amount of downtime so what we have done is with buffering that is as low as",
    "start": "1447799",
    "end": "1455480"
  },
  {
    "text": "possible uh Next Up Performance and reliability we've implemented more",
    "start": "1455480",
    "end": "1462080"
  },
  {
    "text": "efficient connection pooling previously we would end up basically doing a first",
    "start": "1462080",
    "end": "1468000"
  },
  {
    "text": "and first out type of connection pooling where all of the connections would get used which meant that when you initially",
    "start": "1468000",
    "end": "1474799"
  },
  {
    "text": "started it would take some time for things to warm up because you had to establish those connections to my SQL",
    "start": "1474799",
    "end": "1481679"
  },
  {
    "text": "and fill the pool we now have a much more efficient connection pooling where",
    "start": "1481679",
    "end": "1487120"
  },
  {
    "text": "existing connections which are free can be reused uh much faster instead of",
    "start": "1487120",
    "end": "1492600"
  },
  {
    "text": "having to fill the pool so may so you may not even fill the pool if you don't need to so that just improves the",
    "start": "1492600",
    "end": "1499200"
  },
  {
    "text": "startup times for clients and it's more efficient in terms of memory as well um we've implemented",
    "start": "1499200",
    "end": "1507159"
  },
  {
    "text": "faster hashing for sharding hash is the most popular function that people use as",
    "start": "1507159",
    "end": "1513240"
  },
  {
    "text": "their sharding key and um what this means is that whenever you are trying to",
    "start": "1513240",
    "end": "1519799"
  },
  {
    "text": "access data first we have to compute the hash and that that tells us where that",
    "start": "1519799",
    "end": "1525279"
  },
  {
    "text": "particular roow lives so this is in the common path and faster hashing means",
    "start": "1525279",
    "end": "1531279"
  },
  {
    "text": "that all the queries get faster um we have faster inmemory",
    "start": "1531279",
    "end": "1536320"
  },
  {
    "text": "aggregations when you have cross Shard queries what we end up doing sometimes is fetching data from multiple shards",
    "start": "1536320",
    "end": "1543679"
  },
  {
    "text": "and then in vgate in memory we may be doing a sum or a count or an average or",
    "start": "1543679",
    "end": "1549360"
  },
  {
    "text": "some other type of function and all of those have been made faster and the end result of all this is that when we ran",
    "start": "1549360",
    "end": "1556320"
  },
  {
    "text": "the benchmarks on version 19 the most recent release it ended up being faster on all the benchmarks compared compared",
    "start": "1556320",
    "end": "1563200"
  },
  {
    "text": "to the previous release uh We've also implemented backoffs for online ddl",
    "start": "1563200",
    "end": "1568720"
  },
  {
    "text": "cutovers so online schema changes is one of the areas where vtis really shines",
    "start": "1568720",
    "end": "1574320"
  },
  {
    "text": "because this is a problem that the MySQL Community has grappled with for many years and many people have built tools",
    "start": "1574320",
    "end": "1581200"
  },
  {
    "text": "to make those things easier and in Vitus we have a Vitus native way of doing",
    "start": "1581200",
    "end": "1586600"
  },
  {
    "text": "online schema changes and we've just been making performance improvements to those uh to make sure that we don't",
    "start": "1586600",
    "end": "1594360"
  },
  {
    "text": "overload the database when we are attempting to do a cut over for an online schema change and we've also",
    "start": "1594360",
    "end": "1600760"
  },
  {
    "text": "implemented faster cleanup of the artifacts that online uh ddl",
    "start": "1600760",
    "end": "1606200"
  },
  {
    "text": "creates uh the other thing we did which uh I think is a major win is that the",
    "start": "1606200",
    "end": "1612080"
  },
  {
    "text": "topology server whether it's at CD or zookeeper where VT stores its metadata",
    "start": "1612080",
    "end": "1617320"
  },
  {
    "text": "tends to be a Hot Spot sometimes because all of the vus components read data from",
    "start": "1617320",
    "end": "1622799"
  },
  {
    "text": "it and they set watches on keys in uh the topology server they pull it",
    "start": "1622799",
    "end": "1629679"
  },
  {
    "text": "periodically to reload the topology data so what we have done is that for",
    "start": "1629679",
    "end": "1635640"
  },
  {
    "text": "instance there are many parts in there are many places in vas where we will be",
    "start": "1635640",
    "end": "1640799"
  },
  {
    "text": "saying fetch all the shards from the toppo and previously we used to get them",
    "start": "1640799",
    "end": "1646399"
  },
  {
    "text": "one at a time what we are able to do now is to say here is the prefix key fetch",
    "start": "1646399",
    "end": "1652799"
  },
  {
    "text": "all the shards in one call so this actually leads to an order of magnitude reduction in the number of network calls",
    "start": "1652799",
    "end": "1660039"
  },
  {
    "text": "we are making to the toppo and the load that we are putting on the toppo we've also made uh functional and",
    "start": "1660039",
    "end": "1668039"
  },
  {
    "text": "reliability improvements to the incremental backup feature okay so that was the previous",
    "start": "1668039",
    "end": "1673960"
  },
  {
    "text": "releases what's coming up um we we have",
    "start": "1673960",
    "end": "1679720"
  },
  {
    "text": "started working on multiable deletes and updates we will be publishing fewer and",
    "start": "1679720",
    "end": "1685760"
  },
  {
    "text": "smaller Docker images over time the docker images have grown and we want to slim them down and the way we are going",
    "start": "1685760",
    "end": "1691720"
  },
  {
    "text": "to do it is that we are going to stop shipping MySQL binaries in the witus docker images instead you can run with",
    "start": "1691720",
    "end": "1698960"
  },
  {
    "text": "any published MySQL Docker image uh and just run it with wits uh We've",
    "start": "1698960",
    "end": "1705600"
  },
  {
    "text": "implemented we are in the process of implementing Windex hints so uh a Windex",
    "start": "1705600",
    "end": "1712279"
  },
  {
    "text": "hint is where you tell vgate which Windex to use for the query because",
    "start": "1712279",
    "end": "1718279"
  },
  {
    "text": "sometimes if there are multiple vexes on the same table it may pick a less efficient",
    "start": "1718279",
    "end": "1723760"
  },
  {
    "text": "Vex we are adding support for more functions in Cross Shard queries we are",
    "start": "1723760",
    "end": "1729080"
  },
  {
    "text": "also adding uh new metrics in various parts of uh vus for example we have a",
    "start": "1729080",
    "end": "1735240"
  },
  {
    "text": "whole bunch of new metrics for throttling uh we will be adding more uh support for CTE so uh deletes and",
    "start": "1735240",
    "end": "1743039"
  },
  {
    "text": "updates using Common Table Expressions recursive uh CTS those are all planned and we also plan to spend more time",
    "start": "1743039",
    "end": "1749840"
  },
  {
    "text": "doing performance optimizations we have a bunch of resources there's the website uh where",
    "start": "1749840",
    "end": "1757120"
  },
  {
    "text": "we have documentation getting started tutorials so um the website covers the",
    "start": "1757120",
    "end": "1762919"
  },
  {
    "text": "gamut from people who are just getting started to people who have been running with us for many years but there are",
    "start": "1762919",
    "end": "1769279"
  },
  {
    "text": "some new things and uh there is new documentation around that source code is",
    "start": "1769279",
    "end": "1774399"
  },
  {
    "text": "on GitHub and we have a slack workspace there is a link from our website to join",
    "start": "1774399",
    "end": "1779880"
  },
  {
    "text": "uh the slack workspace and there are a couple of blogs that are worth reading one of them was done by slack how they",
    "start": "1779880",
    "end": "1787519"
  },
  {
    "text": "actually migrated everything all of their data to wit us and another one",
    "start": "1787519",
    "end": "1793360"
  },
  {
    "text": "from Square now block where uh they migrated",
    "start": "1793360",
    "end": "1799120"
  },
  {
    "text": "their Square cach app to vus and also did multiple rounds of",
    "start": "1799120",
    "end": "1805158"
  },
  {
    "text": "resharding that's everything we had so it's time for",
    "start": "1805480",
    "end": "1810900"
  },
  {
    "text": "[Applause]",
    "start": "1810900",
    "end": "1817679"
  },
  {
    "text": "questions",
    "start": "1817679",
    "end": "1820679"
  },
  {
    "text": "yes thank you uh in the Vinted presentation you mentioned in your architect show something about eight I'm",
    "start": "1822720",
    "end": "1829960"
  },
  {
    "text": "not sure it was eight node per Shard and can you explain why eight I'm a new does",
    "start": "1829960",
    "end": "1838080"
  },
  {
    "text": "it mean that one primary seven replica so you have a lot of",
    "start": "1838080",
    "end": "1844840"
  },
  {
    "text": "read uh yes uh we run one primary and seven replica but like two replicas are",
    "start": "1845399",
    "end": "1853519"
  },
  {
    "text": "reserved for uh exporting data to Data Warehouse saw some um on the flag where is from",
    "start": "1853519",
    "end": "1861240"
  },
  {
    "text": "developers if they need to um investigate something so effectively like six serve",
    "start": "1861240",
    "end": "1868000"
  },
  {
    "text": "production and two extra for longer",
    "start": "1868000",
    "end": "1874440"
  },
  {
    "text": "workloads he has a um you talked about a fail over time",
    "start": "1877639",
    "end": "1885840"
  },
  {
    "text": "of up to one minute so uh how do you detect uh failure of the primary and and",
    "start": "1885840",
    "end": "1892919"
  },
  {
    "text": "what needs to be done during failover so can understand this uh one minute uh",
    "start": "1892919",
    "end": "1898760"
  },
  {
    "text": "delay yeah uh so we have a component called VTR which monitors all of the VT",
    "start": "1898760",
    "end": "1905720"
  },
  {
    "text": "tablets VT tablet is the sidecar instance that is um managing the MySQL",
    "start": "1905720",
    "end": "1911600"
  },
  {
    "text": "so VTR can it's basically pulling all of",
    "start": "1911600",
    "end": "1917159"
  },
  {
    "text": "the MySQL every second essentially and uh",
    "start": "1917159",
    "end": "1923960"
  },
  {
    "text": "if three three consecutive uh PS fail what VOR will do is that it will",
    "start": "1923960",
    "end": "1931880"
  },
  {
    "text": "check whether the replicas are able to talk to the primary because it is possible that the vtor itself is Network",
    "start": "1931880",
    "end": "1938000"
  },
  {
    "text": "partitioned from the primary the primary may be fine but vtor is not able to reach it so VOR does the failure",
    "start": "1938000",
    "end": "1944480"
  },
  {
    "text": "detection which takes up to 5 seconds after your my actually goes down and",
    "start": "1944480",
    "end": "1949639"
  },
  {
    "text": "then it'll do a failover to one of the replicas and typically it doesn't take 1",
    "start": "1949639",
    "end": "1956720"
  },
  {
    "text": "minute but it is possible for um it to take say 15 or 20 seconds so typically",
    "start": "1956720",
    "end": "1965039"
  },
  {
    "text": "we see failover times of around 15 seconds but sometimes it may just take",
    "start": "1965039",
    "end": "1970639"
  },
  {
    "text": "time for some replicas may not be eligible for promotion the way you have",
    "start": "1970639",
    "end": "1976279"
  },
  {
    "text": "configured the cluster right because maybe you have uh distributed it",
    "start": "1976279",
    "end": "1981880"
  },
  {
    "text": "across regions and you want to keep your primary in a certain region and it's possible that the replica you've that is",
    "start": "1981880",
    "end": "1988399"
  },
  {
    "text": "eligible for promotion is not fully up to date then you have to find something else which is up to date and replicate",
    "start": "1988399",
    "end": "1995240"
  },
  {
    "text": "all the pending or the missing transactions from there which is why I said it could take up to a minute mostly",
    "start": "1995240",
    "end": "2001519"
  },
  {
    "text": "we don't see it taking up to a minute as long as the replicas are pretty up to",
    "start": "2001519",
    "end": "2006760"
  },
  {
    "text": "date yes okay hi um you were talking about um",
    "start": "2006760",
    "end": "2013559"
  },
  {
    "text": "point in time recovery utilizing the my SQL bin locks um inside vest so to speak",
    "start": "2013559",
    "end": "2020120"
  },
  {
    "text": "without using a bin lock server so the question I have is um where um are those spin locks kept",
    "start": "2020120",
    "end": "2026960"
  },
  {
    "text": "and um to what to which size can they reasonably grow before you have to cut",
    "start": "2026960",
    "end": "2032240"
  },
  {
    "text": "them allowing for which window of time without breaking down major function of",
    "start": "2032240",
    "end": "2038360"
  },
  {
    "text": "the vest service itself right so um typically when witus is managing the",
    "start": "2038360",
    "end": "2045320"
  },
  {
    "text": "myql there will be a directory specified where everything is stored all the MySQL",
    "start": "2045320",
    "end": "2050520"
  },
  {
    "text": "files are stored there and uh at the my SQL level you are specifying a bin log",
    "start": "2050520",
    "end": "2056000"
  },
  {
    "text": "retention period so that could be 3 days that could be 7 Days depending on the amount of dis you are able to provision",
    "start": "2056000",
    "end": "2062878"
  },
  {
    "text": "for the VT tablet you would specify that and that will be as far as you can go you will not not be able to go anywhere",
    "start": "2062879",
    "end": "2069679"
  },
  {
    "text": "beyond that so if you can afford to provision a huge dis then you can have a 30-day retention and you can go back up",
    "start": "2069679",
    "end": "2077000"
  },
  {
    "text": "to 30 days what we have seen is that people typically run with 7 Days of Bin logs",
    "start": "2077000",
    "end": "2084398"
  },
  {
    "text": "and sometimes even shorter depending on the volume of their updates because",
    "start": "2084399",
    "end": "2090158"
  },
  {
    "text": "there are some people who just do frequent updates they have like a modified at date or last access then",
    "start": "2090159",
    "end": "2098200"
  },
  {
    "text": "you just produce billions of uh Bin logs and you simply can't afford to keep them",
    "start": "2098200",
    "end": "2103680"
  },
  {
    "text": "for 30 days so all that is",
    "start": "2103680",
    "end": "2107359"
  },
  {
    "text": "configurable hey thanks for the talk uh you mention that Vinted is running at clusters did you do you do you if if the",
    "start": "2110280",
    "end": "2118599"
  },
  {
    "text": "technology um scales horizontally do you do it for maintenance purposes what's the reason for so many clusters uh like",
    "start": "2118599",
    "end": "2125079"
  },
  {
    "text": "we effectively run one cluster per seate service that we have so we do not allow separate",
    "start": "2125079",
    "end": "2133359"
  },
  {
    "text": "services to connect to the same with us with t cluster like separating",
    "start": "2133359",
    "end": "2139640"
  },
  {
    "text": "database hello uh thank you very much for the talk uh question um do you vest",
    "start": "2148440",
    "end": "2155280"
  },
  {
    "text": "supports uh myql 8 and my SQL 7 databases where we are trying different",
    "start": "2155280",
    "end": "2161880"
  },
  {
    "text": "features witus does support well we have just uh end of life MySQL 5.7 support",
    "start": "2161880",
    "end": "2170480"
  },
  {
    "text": "because um MySQL 57 itself is EOL so technically we really only support my",
    "start": "2170480",
    "end": "2177319"
  },
  {
    "text": "SQL 8 at this point but we are keeping a certain amount of my SQL 57 support so",
    "start": "2177319",
    "end": "2183440"
  },
  {
    "text": "that people can migrate so it is still possible to put wit us in front of an existing MySQL 57 database and migrate",
    "start": "2183440",
    "end": "2190599"
  },
  {
    "text": "all of the data into a MySQL 8 database and one last question um is there any",
    "start": "2190599",
    "end": "2196520"
  },
  {
    "text": "plan to make it work with aora database in AWS",
    "start": "2196520",
    "end": "2201560"
  },
  {
    "text": "uh we don't currently have any plans to make it work with Aurora so The Stance",
    "start": "2201560",
    "end": "2207880"
  },
  {
    "text": "when it comes to something like RDS or Aurora or Marb all of which people have",
    "start": "2207880",
    "end": "2213440"
  },
  {
    "text": "actually run wit us with in the past is that it is very difficult for us maintainers to maintain that many",
    "start": "2213440",
    "end": "2220359"
  },
  {
    "text": "versions so if there is interest from the community and someone really wants to run it then they will need to try it",
    "start": "2220359",
    "end": "2226040"
  },
  {
    "text": "out and we can help them but it's just too much for the maintainer team to",
    "start": "2226040",
    "end": "2231800"
  },
  {
    "text": "maintain so many different flavors so there are people who ran it with RDS for a long time and that",
    "start": "2231800",
    "end": "2238880"
  },
  {
    "text": "worked so I noticed um in your architecture diagram there was a little bit about big data and how that uh",
    "start": "2242880",
    "end": "2249319"
  },
  {
    "text": "queries does that query differently can you explain more about how that works so uh in Vitus you typically",
    "start": "2249319",
    "end": "2257200"
  },
  {
    "text": "configure timeouts for the queries and those timeouts don't apply if you are um",
    "start": "2257200",
    "end": "2264000"
  },
  {
    "text": "running in a specific mode so when you're doing big data or analytics you can specify that you want to run in olap",
    "start": "2264000",
    "end": "2270400"
  },
  {
    "text": "mode and then you we don't time out the queries they can run for a long time so it's possible to provision a different",
    "start": "2270400",
    "end": "2277200"
  },
  {
    "text": "type of replica and you can provision it with more resources if necessary and",
    "start": "2277200",
    "end": "2282680"
  },
  {
    "text": "execute olap type queries I think we are out of time so we",
    "start": "2282680",
    "end": "2288920"
  },
  {
    "text": "are happy to chat off stage but thank you everyone for attending this was",
    "start": "2288920",
    "end": "2294319"
  },
  {
    "text": "really great and I loved all the questions as well thank [Applause]",
    "start": "2294319",
    "end": "2304499"
  },
  {
    "text": "you",
    "start": "2306440",
    "end": "2309440"
  }
]
[
  {
    "text": "uh welcome to the session yeah such a",
    "start": "120",
    "end": "2200"
  },
  {
    "text": "big stage that's my 12 Cube con talk I",
    "start": "2200",
    "end": "6000"
  },
  {
    "text": "still feel excited or nervous too by the",
    "start": "6000",
    "end": "10120"
  },
  {
    "text": "way there are no fancy animation photos",
    "start": "10120",
    "end": "13000"
  },
  {
    "text": "as previous talks I still hope you won't",
    "start": "13000",
    "end": "15440"
  },
  {
    "text": "find it too boring so I'm y turn from",
    "start": "15440",
    "end": "18439"
  },
  {
    "text": "Nvidia a quick disclaimer all the",
    "start": "18439",
    "end": "21680"
  },
  {
    "text": "contents and opinions on personal not",
    "start": "21680",
    "end": "25160"
  },
  {
    "text": "representative of my former and current",
    "start": "25160",
    "end": "27640"
  },
  {
    "text": "employee and the analysis",
    "start": "27640",
    "end": "30519"
  },
  {
    "text": "made some simplified assumptions may",
    "start": "30519",
    "end": "33719"
  },
  {
    "text": "contain the",
    "start": "33719",
    "end": "35239"
  },
  {
    "text": "mistakes okay so as we all know and the",
    "start": "35239",
    "end": "38160"
  },
  {
    "text": "tning large language models is expensive",
    "start": "38160",
    "end": "42079"
  },
  {
    "text": "but the model inferencing and model",
    "start": "42079",
    "end": "44079"
  },
  {
    "text": "serving expensive too to some extent it",
    "start": "44079",
    "end": "47160"
  },
  {
    "text": "could dominate the overall cost for the",
    "start": "47160",
    "end": "49559"
  },
  {
    "text": "following reason one is not everyone",
    "start": "49559",
    "end": "51879"
  },
  {
    "text": "needs TR their model from scratch they",
    "start": "51879",
    "end": "54079"
  },
  {
    "text": "can find two existing model secondly and",
    "start": "54079",
    "end": "57960"
  },
  {
    "text": "the model serving right also need to",
    "start": "57960",
    "end": "60280"
  },
  {
    "text": "access a large number of the model",
    "start": "60280",
    "end": "62239"
  },
  {
    "text": "parameters and also demand and very high",
    "start": "62239",
    "end": "65320"
  },
  {
    "text": "performance low latency finally a not",
    "start": "65320",
    "end": "67799"
  },
  {
    "text": "applications and model serving like CH",
    "start": "67799",
    "end": "70080"
  },
  {
    "text": "GPT right and they have to handle a very",
    "start": "70080",
    "end": "73600"
  },
  {
    "text": "lar and the volume of the user",
    "start": "73600",
    "end": "77280"
  },
  {
    "text": "request so here is a backup envelope",
    "start": "77280",
    "end": "81720"
  },
  {
    "text": "estimate and I did based on public",
    "start": "81720",
    "end": "84320"
  },
  {
    "text": "available data so firstly and from the",
    "start": "84320",
    "end": "87680"
  },
  {
    "text": "number of users right like Chad GP",
    "start": "87680",
    "end": "90520"
  },
  {
    "text": "we have like the 100 millions of the",
    "start": "90520",
    "end": "93439"
  },
  {
    "text": "active users per week if we assume every",
    "start": "93439",
    "end": "96040"
  },
  {
    "text": "us make five request total is 71 and the",
    "start": "96040",
    "end": "99479"
  },
  {
    "text": "media of the request what assume the",
    "start": "99479",
    "end": "102680"
  },
  {
    "text": "each request cost 1 cent the total cost",
    "start": "102680",
    "end": "105320"
  },
  {
    "text": "of Da operation cost is about the",
    "start": "105320",
    "end": "109399"
  },
  {
    "text": "$700,000 and another perspective we can",
    "start": "109399",
    "end": "112200"
  },
  {
    "text": "look at the cost is from the server",
    "start": "112200",
    "end": "114799"
  },
  {
    "text": "performance perspective for example a100",
    "start": "114799",
    "end": "117560"
  },
  {
    "text": "and how many requests that they can",
    "start": "117560",
    "end": "119079"
  },
  {
    "text": "handle then we assume right how many the",
    "start": "119079",
    "end": "122719"
  },
  {
    "text": "the a100 GPU we need finally based on",
    "start": "122719",
    "end": "126280"
  },
  {
    "text": "some the public the cloud uh GPU Cloud",
    "start": "126280",
    "end": "130399"
  },
  {
    "text": "cost right like every hour is $2 then",
    "start": "130399",
    "end": "133840"
  },
  {
    "text": "the cost is about the $1 million again",
    "start": "133840",
    "end": "136800"
  },
  {
    "text": "those numbers have never been verified",
    "start": "136800",
    "end": "139440"
  },
  {
    "text": "and uh I hope they are not far from the",
    "start": "139440",
    "end": "143280"
  },
  {
    "text": "truth at least in the same ball park but",
    "start": "143280",
    "end": "145920"
  },
  {
    "text": "uh the key takeaway is model serving and",
    "start": "145920",
    "end": "148920"
  },
  {
    "text": "model inferencing is",
    "start": "148920",
    "end": "151800"
  },
  {
    "text": "expensive so another thing I want to see",
    "start": "151800",
    "end": "154280"
  },
  {
    "text": "is also the performance is critical",
    "start": "154280",
    "end": "156519"
  },
  {
    "text": "right compared to internet service like",
    "start": "156519",
    "end": "158879"
  },
  {
    "text": "search Google search we are talking",
    "start": "158879",
    "end": "160920"
  },
  {
    "text": "about the latency in the range of the",
    "start": "160920",
    "end": "163599"
  },
  {
    "text": "hundreds of milliseconds but today all",
    "start": "163599",
    "end": "166319"
  },
  {
    "text": "this and the not AGR model GPT",
    "start": "166319",
    "end": "169480"
  },
  {
    "text": "generative AI is still me seconds tens",
    "start": "169480",
    "end": "172800"
  },
  {
    "text": "of seconds even minutes there are not of",
    "start": "172800",
    "end": "175200"
  },
  {
    "text": "room or space we need to",
    "start": "175200",
    "end": "177640"
  },
  {
    "text": "improve so if we look at the",
    "start": "177640",
    "end": "180360"
  },
  {
    "text": "large and or big picture right we drawn",
    "start": "180360",
    "end": "183480"
  },
  {
    "text": "the AI work the GPU and the Clusters is",
    "start": "183480",
    "end": "186200"
  },
  {
    "text": "basically is a different diverse",
    "start": "186200",
    "end": "188799"
  },
  {
    "text": "workloads right from motor training to",
    "start": "188799",
    "end": "191080"
  },
  {
    "text": "serving to the cicd to visualization",
    "start": "191080",
    "end": "194200"
  },
  {
    "text": "interactive on hyrogen network but one",
    "start": "194200",
    "end": "197280"
  },
  {
    "text": "thing I want to highlight here is how",
    "start": "197280",
    "end": "199599"
  },
  {
    "text": "can we improve the efficiencies Nvidia",
    "start": "199599",
    "end": "201799"
  },
  {
    "text": "already and offer and the different the",
    "start": "201799",
    "end": "204360"
  },
  {
    "text": "GPU and the sharing technology from the",
    "start": "204360",
    "end": "206519"
  },
  {
    "text": "multi-process sharing to time slicing to",
    "start": "206519",
    "end": "209319"
  },
  {
    "text": "multiple instance of uh the GPU also the",
    "start": "209319",
    "end": "212799"
  },
  {
    "text": "virtualized the GPU that's something we",
    "start": "212799",
    "end": "214920"
  },
  {
    "text": "should take advantage and to improve the",
    "start": "214920",
    "end": "219000"
  },
  {
    "text": "efficiency okay so in terms of the how",
    "start": "219640",
    "end": "222400"
  },
  {
    "text": "can we improve that model serving and I",
    "start": "222400",
    "end": "224959"
  },
  {
    "text": "think the forign aspects right we need",
    "start": "224959",
    "end": "227040"
  },
  {
    "text": "more and efficient the workload and",
    "start": "227040",
    "end": "229319"
  },
  {
    "text": "scheduling algorithm from Advanced",
    "start": "229319",
    "end": "231360"
  },
  {
    "text": "scheduling and resource sharing and J",
    "start": "231360",
    "end": "233879"
  },
  {
    "text": "over management of course the machine",
    "start": "233879",
    "end": "235840"
  },
  {
    "text": "learning and the AI Community also",
    "start": "235840",
    "end": "237560"
  },
  {
    "text": "working on Improvement and optimization",
    "start": "237560",
    "end": "240959"
  },
  {
    "text": "technical like smaller models and model",
    "start": "240959",
    "end": "243720"
  },
  {
    "text": "compression technicals like the",
    "start": "243720",
    "end": "245680"
  },
  {
    "text": "continuous batching of course finally we",
    "start": "245680",
    "end": "248560"
  },
  {
    "text": "should continue to improve the hardware",
    "start": "248560",
    "end": "250360"
  },
  {
    "text": "performance so to summarize and conclude",
    "start": "250360",
    "end": "253040"
  },
  {
    "text": "my talks the model serving uh",
    "start": "253040",
    "end": "255439"
  },
  {
    "text": "inferencing is critically important uh I",
    "start": "255439",
    "end": "259000"
  },
  {
    "text": "want to see and just like Google and",
    "start": "259000",
    "end": "261199"
  },
  {
    "text": "other internet company right the Pioneer",
    "start": "261199",
    "end": "263960"
  },
  {
    "text": "the distributor n skill system for the",
    "start": "263960",
    "end": "266720"
  },
  {
    "text": "internet service and the search today we",
    "start": "266720",
    "end": "269280"
  },
  {
    "text": "need uh scalable efficient and for",
    "start": "269280",
    "end": "273520"
  },
  {
    "text": "tolerant and the cloud native solution",
    "start": "273520",
    "end": "276600"
  },
  {
    "text": "for the emerging AI workload",
    "start": "276600",
    "end": "278919"
  },
  {
    "text": "specifically I think there are major",
    "start": "278919",
    "end": "280800"
  },
  {
    "text": "opportunities in the cloud native",
    "start": "280800",
    "end": "282840"
  },
  {
    "text": "Resource Management Solutions there are",
    "start": "282840",
    "end": "285520"
  },
  {
    "text": "n talks from Nvidia about how to improve",
    "start": "285520",
    "end": "288400"
  },
  {
    "text": "the AI workload on GPU clusters all this",
    "start": "288400",
    "end": "291199"
  },
  {
    "text": "new device driver technology GPU sharing",
    "start": "291199",
    "end": "294560"
  },
  {
    "text": "tomoro the first we start with my",
    "start": "294560",
    "end": "296560"
  },
  {
    "text": "colleague Kevin and uh San about the GPU",
    "start": "296560",
    "end": "300960"
  },
  {
    "text": "acceleration GPU sharing please come to",
    "start": "300960",
    "end": "303320"
  },
  {
    "text": "our sessions and uh learn more about",
    "start": "303320",
    "end": "306639"
  },
  {
    "text": "accelerating AI workload using the",
    "start": "306639",
    "end": "308800"
  },
  {
    "text": "Nvidia and the hardware Technologies",
    "start": "308800",
    "end": "310759"
  },
  {
    "text": "thank you very much",
    "start": "310759",
    "end": "313039"
  },
  {
    "text": "bye",
    "start": "313039",
    "end": "316039"
  }
]
[
  {
    "text": "okay now it's time so we are going to be presenting one story",
    "start": "320",
    "end": "6879"
  },
  {
    "text": "essentially how we use several cloud native foundation projects",
    "start": "6879",
    "end": "11920"
  },
  {
    "text": "to build a telemetry pipeline mostly with a network automation use case in mind",
    "start": "11920",
    "end": "18880"
  },
  {
    "text": "and the key elements are kubernetes and some operators including the stream c1",
    "start": "18880",
    "end": "26080"
  },
  {
    "text": "and yes the idea is we will be introducing ourselves the context",
    "start": "26080",
    "end": "31760"
  },
  {
    "text": "then we will describe a bit the project and the platform supporting that project",
    "start": "31760",
    "end": "38239"
  },
  {
    "text": "to then cover some details about the solution as well as some associated problems and issues we had",
    "start": "38239",
    "end": "46000"
  },
  {
    "text": "we will be using a slightly different format for this and before closing we will be also sharing some highlights",
    "start": "46000",
    "end": "52160"
  },
  {
    "text": "about the impact in our organization but before that fernando",
    "start": "52160",
    "end": "58480"
  },
  {
    "text": "hi everyone i hope you are all having a great conference so far so i'm fernando i'm working at fastly",
    "start": "58480",
    "end": "64158"
  },
  {
    "text": "i'm basically enabling coordinates for fastly control playing applications kubernetes is not a new space to me i",
    "start": "64159",
    "end": "70960"
  },
  {
    "text": "think i started on the early stages think thanks to companies like 20 niagara and vietnamese i had a great",
    "start": "70960",
    "end": "76479"
  },
  {
    "text": "experience there and i also had the pleasure to contribute to the kubernetes open source community with bug fixes features and",
    "start": "76479",
    "end": "84400"
  },
  {
    "text": "and even custom controllers like 20 secrets manager um so this is me then hand over to danny",
    "start": "84400",
    "end": "91280"
  },
  {
    "text": "again and yes this is daniel just an engineer at fastly",
    "start": "91280",
    "end": "96960"
  },
  {
    "text": "i been in the like doing lots of data devops stuff mostly in the barcelona",
    "start": "96960",
    "end": "102159"
  },
  {
    "text": "area so also from spain and yes i also love open source and i try to contribute as much as i can",
    "start": "102159",
    "end": "109520"
  },
  {
    "text": "and also let's introduce a bit our company fastly maybe you already know about us",
    "start": "109520",
    "end": "115680"
  },
  {
    "text": "our mission in the end is to make internet users happy and how do we try to do this it's mostly",
    "start": "115680",
    "end": "123119"
  },
  {
    "text": "by having a distributed architecture where our customers can can you hear me",
    "start": "123119",
    "end": "129360"
  },
  {
    "text": "okay where our customers can execute code as close as possible to the end users and deliver contents",
    "start": "129360",
    "end": "136959"
  },
  {
    "text": "beating in mind performance and reliability so yes we have like a relatively large",
    "start": "136959",
    "end": "144160"
  },
  {
    "text": "network defined by software we let our customers to run applications",
    "start": "144160",
    "end": "150239"
  },
  {
    "text": "in our edge and uh yeah the idea is to make our customers as autonomous as possible to",
    "start": "150239",
    "end": "156879"
  },
  {
    "text": "let them just to create whatever they need in our platform and benefit from our infrastructure",
    "start": "156879",
    "end": "164640"
  },
  {
    "text": "some numbers if you are more used to requests per second 8 billion requests per day means an",
    "start": "164640",
    "end": "170800"
  },
  {
    "text": "average of 10 10 million requests per second",
    "start": "170800",
    "end": "176640"
  },
  {
    "text": "so yeah the size is relatively high and",
    "start": "176640",
    "end": "181840"
  },
  {
    "text": "that was quite clear probably almost one year ago with that we had an out as a one-hour autism we were on the news",
    "start": "181840",
    "end": "189040"
  },
  {
    "text": "so that's scary but also interesting at the same time and yes this is more or less how our",
    "start": "189040",
    "end": "194879"
  },
  {
    "text": "network looks like today so we have many points of presence across the globe",
    "start": "194879",
    "end": "200239"
  },
  {
    "text": "we try to put them close to our end users and the main",
    "start": "200239",
    "end": "206480"
  },
  {
    "text": "concept here is that the scale of the network is quite high and as a consequence",
    "start": "206480",
    "end": "212480"
  },
  {
    "text": "we need more stuff so things that are not in that data plane in our fleet we need the",
    "start": "212480",
    "end": "218640"
  },
  {
    "text": "control plane as well to orchestrate and to manage all this large network",
    "start": "218640",
    "end": "224640"
  },
  {
    "text": "actually in the control plane is where most of the automation magic lives and this story is about one of these",
    "start": "224640",
    "end": "232959"
  },
  {
    "text": "automation services which is autopilot the pilot is probably not a very",
    "start": "232959",
    "end": "239840"
  },
  {
    "text": "original name i think i have heard about like autopilot three times already in this conference but this is our",
    "start": "239840",
    "end": "246080"
  },
  {
    "text": "autopilot and in order to introduce the problem that it solves let's take a look to",
    "start": "246080",
    "end": "252640"
  },
  {
    "text": "our how our pop networking looks like at high level",
    "start": "252640",
    "end": "257680"
  },
  {
    "text": "the idea is that yeah we have devices network devices compute devices and they are connected to several",
    "start": "257680",
    "end": "265120"
  },
  {
    "text": "asn's other esn's so some of them act as transit providers for us so essentially when we send",
    "start": "265120",
    "end": "272479"
  },
  {
    "text": "traffic they can route the traffic anywhere on internet we have other",
    "start": "272479",
    "end": "277680"
  },
  {
    "text": "relationships with other asn's so we may have direct links building relationships with them",
    "start": "277680",
    "end": "284080"
  },
  {
    "text": "but here the key message is that in order to deliver traffic from our platform there are multiple links",
    "start": "284080",
    "end": "291040"
  },
  {
    "text": "available so many routes for a given destination and in the end we need to make decisions about what what is the",
    "start": "291040",
    "end": "297759"
  },
  {
    "text": "best way to for war traffic to our end users and also to the origin servers",
    "start": "297759",
    "end": "303919"
  },
  {
    "text": "and that is what autopilot is trying to solve it's about building in mind performance",
    "start": "303919",
    "end": "309520"
  },
  {
    "text": "bearing in mind capacity how hot our links are we need to route traffic accordingly",
    "start": "309520",
    "end": "316400"
  },
  {
    "text": "and automation here is not a new thing if you browse our engineering blog post",
    "start": "316400",
    "end": "321600"
  },
  {
    "text": "you will find previous iterations of this if you are also working in a large scale network in a big tech company",
    "start": "321600",
    "end": "328400"
  },
  {
    "text": "maybe you have your own solution for this and who is behind this last iteration of",
    "start": "328400",
    "end": "334720"
  },
  {
    "text": "autopilot is essentially what it's the nco team that it's in nexus in network systems fastly",
    "start": "334720",
    "end": "342400"
  },
  {
    "text": "and initially we had like six engineers focused in that initiative",
    "start": "342400",
    "end": "347919"
  },
  {
    "text": "and these engineers were we had like mixed skills so there were software engineers",
    "start": "347919",
    "end": "353919"
  },
  {
    "text": "network engineers uh also sres like me and",
    "start": "353919",
    "end": "359520"
  },
  {
    "text": "here each one also of the key messages in the end there are many implementation",
    "start": "359520",
    "end": "364960"
  },
  {
    "text": "possibilities for something like this but we need to be in mind the team supporting extending this solution and",
    "start": "364960",
    "end": "370960"
  },
  {
    "text": "that was also a key item in our design so autopilot at very high level",
    "start": "370960",
    "end": "379120"
  },
  {
    "text": "we are not regulating the wheel we follow the typical pattern of measuring things then computing if we need to push",
    "start": "379120",
    "end": "385759"
  },
  {
    "text": "a network change and finally also uh the routing manager like a wrapper of our",
    "start": "385759",
    "end": "392400"
  },
  {
    "text": "of our routing infrastructure which in the end also applies the changes to our fleet",
    "start": "392400",
    "end": "398960"
  },
  {
    "text": "let's actually focus in the yellow box the telemetry pipeline",
    "start": "398960",
    "end": "404400"
  },
  {
    "text": "and what is that telemetry pipeline doing is essentially consolidating many inputs",
    "start": "404400",
    "end": "412080"
  },
  {
    "text": "telemetry data from many sources we have systems information so metrics mostly from our",
    "start": "412080",
    "end": "418720"
  },
  {
    "text": "prometheus infrastructure that describe the status of the links what is the capacity of the links we",
    "start": "418720",
    "end": "424639"
  },
  {
    "text": "have then we have flow data and that is super key for this problem",
    "start": "424639",
    "end": "431199"
  },
  {
    "text": "in we are something like the network data we are moving in our fleet in order to know",
    "start": "431199",
    "end": "437360"
  },
  {
    "text": "what this what are the destination of every packet we are sending",
    "start": "437360",
    "end": "443039"
  },
  {
    "text": "to across our network we are sampling of course and then we also consider performance data",
    "start": "443039",
    "end": "450080"
  },
  {
    "text": "even at application level and even we are also proving the different links we have in order to",
    "start": "450080",
    "end": "457919"
  },
  {
    "text": "know what's the the performance and the status of these links in our network",
    "start": "457919",
    "end": "463440"
  },
  {
    "text": "so how the pipeline actually looks like this is the portion that cares about the",
    "start": "463440",
    "end": "469840"
  },
  {
    "text": "the the net flow the s-flow data consumption so essentially we have",
    "start": "469840",
    "end": "474960"
  },
  {
    "text": "network devices switches in our case which are emitting as flow information with an exflo agent we encapsulate that",
    "start": "474960",
    "end": "482639"
  },
  {
    "text": "data using a dtls tunnel so everything is udp and that will be relevant later",
    "start": "482639",
    "end": "488800"
  },
  {
    "text": "then in the actual pipeline we process we have a first stage that it's kind of",
    "start": "488800",
    "end": "494160"
  },
  {
    "text": "enriching and aggregating some data using pmrt that it's another open source project to finally push all the data to",
    "start": "494160",
    "end": "502479"
  },
  {
    "text": "a kafka topic that is acting like a buffer so and finally we have an api in top of",
    "start": "502479",
    "end": "507919"
  },
  {
    "text": "this that is maintaining like an in-memory view of the network state",
    "start": "507919",
    "end": "513279"
  },
  {
    "text": "so a offers and grpc api other components are consuming including the controller that is the one that",
    "start": "513279",
    "end": "519279"
  },
  {
    "text": "implements the magic in order to enrich that telemetry data",
    "start": "519279",
    "end": "524320"
  },
  {
    "text": "we also need to know the routing state and we do this via that route manager",
    "start": "524320",
    "end": "529760"
  },
  {
    "text": "service and finally as i mentioned we are also collecting consolidating",
    "start": "529760",
    "end": "534959"
  },
  {
    "text": "metrics from our promises infrastructure essentially some counters and other data directly",
    "start": "534959",
    "end": "541600"
  },
  {
    "text": "coming from our switches so in order to run these services that",
    "start": "541600",
    "end": "548399"
  },
  {
    "text": "architecture i described we need to process data at certain scale",
    "start": "548399",
    "end": "555040"
  },
  {
    "text": "just to give you an idea it's more or less given the sampling we are doing it's about processing",
    "start": "555040",
    "end": "560880"
  },
  {
    "text": "hundreds of thousands of packets per second the we need a runtime to manage these",
    "start": "560880",
    "end": "567360"
  },
  {
    "text": "components these services to deploy new versions and so on and",
    "start": "567360",
    "end": "572399"
  },
  {
    "text": "of course as everyone wants probably we want to run this in many different locations",
    "start": "572399",
    "end": "578240"
  },
  {
    "text": "as close as possible to our points of presence so we need to put this in several places and we also want to be a",
    "start": "578240",
    "end": "585839"
  },
  {
    "text": "dissolution they wanted to be also cloud agnostic so we didn't wanted to couple this to another cloud provider",
    "start": "585839",
    "end": "592080"
  },
  {
    "text": "given our control plane is very diverse we wanted to be able to run this also in",
    "start": "592080",
    "end": "597360"
  },
  {
    "text": "some dedicated data centers we have four control plane workloads and",
    "start": "597360",
    "end": "603120"
  },
  {
    "text": "yes surprise in order to run a control plane uh workloads when we",
    "start": "603120",
    "end": "609200"
  },
  {
    "text": "started this project we didn't have like a proper standard so for the data plane yes everything is",
    "start": "609200",
    "end": "614399"
  },
  {
    "text": "super standardized so every component we put in our fleet is following is is",
    "start": "614399",
    "end": "619760"
  },
  {
    "text": "using some frameworks and well-known patterns but for the control plane it's a different story",
    "start": "619760",
    "end": "625519"
  },
  {
    "text": "we had a mixture of different infrastructures different cloud providers and",
    "start": "625519",
    "end": "631200"
  },
  {
    "text": "yeah even in the network control and optimization team we were already using kubernetes but many kubernetes clusters",
    "start": "631200",
    "end": "638480"
  },
  {
    "text": "in google cloud mostly dedicated for individual workloads",
    "start": "638480",
    "end": "644240"
  },
  {
    "text": "and actually regarding kafka fasting was already using kafka for other use cases but we didn't have like",
    "start": "644240",
    "end": "650240"
  },
  {
    "text": "a proper production really set up so there was actually even opposition",
    "start": "650240",
    "end": "656160"
  },
  {
    "text": "from the team to incorporate kafka in the project scope even that was the perception that that was complicated was",
    "start": "656160",
    "end": "662640"
  },
  {
    "text": "complex we were on a small team so managing something like this could be a challenge",
    "start": "662640",
    "end": "668560"
  },
  {
    "text": "and now i'm handing over to fernando we'll we who will describe a bit more the kubernetes posture and what's",
    "start": "668560",
    "end": "675360"
  },
  {
    "text": "the platform point of view and how the kubernetes offering and internal offering evolve",
    "start": "675360",
    "end": "680560"
  },
  {
    "text": "to match these requirements so thank you danny kubernetes at fastly",
    "start": "680560",
    "end": "686320"
  },
  {
    "text": "circa 2020 it pretty much looks like this you want a cluster you get a cluster you",
    "start": "686320",
    "end": "692240"
  },
  {
    "text": "want a cluster you get a cluster everyone get a cluster teams were pretty autonomous here like",
    "start": "692240",
    "end": "697279"
  },
  {
    "text": "teams we learn like cloud projects or cloud accounts and create the infrastructure the problem is that led to a very",
    "start": "697279",
    "end": "704079"
  },
  {
    "text": "fragmented underutilized and expensive infrastructure like danny mentioned we we have several",
    "start": "704079",
    "end": "710079"
  },
  {
    "text": "clusters over there hosting only one service maybe and since it also came from mostly",
    "start": "710079",
    "end": "716480"
  },
  {
    "text": "individual initiative there was no standard way of creating the clusters configuring them or even deploying to",
    "start": "716480",
    "end": "721760"
  },
  {
    "text": "them some folks will use terraform some other folks will use the cloud console directly others pull me some people will",
    "start": "721760",
    "end": "727200"
  },
  {
    "text": "use hem to deploy others royal and other customize and and there was also a maintenance part of them because most mostly the",
    "start": "727200",
    "end": "733920"
  },
  {
    "text": "engineers deploying on kubernetes they didn't have the experience to administrate kubernetes clusters",
    "start": "733920",
    "end": "741360"
  },
  {
    "text": "so fastly decided to create a kubernetes team initially we were for two folks in new",
    "start": "741440",
    "end": "746560"
  },
  {
    "text": "zealand one in canada and myself in spain and the goals were to build a kubernetes shared platform for the control plane",
    "start": "746560",
    "end": "753360"
  },
  {
    "text": "standardizing infrastructure deployment and application deployment and the scale",
    "start": "753360",
    "end": "758560"
  },
  {
    "text": "eventually cross reon cross clouds and eventually elevate also developers",
    "start": "758560",
    "end": "763600"
  },
  {
    "text": "capability to deploy faster and scale and the latter brought the project name which is also not very original",
    "start": "763600",
    "end": "770079"
  },
  {
    "text": "elevation so let's talk about elevation of it elevation first version was indeed",
    "start": "770079",
    "end": "776079"
  },
  {
    "text": "pretty simple we started with uh one cluster per stage and only one region but we designed",
    "start": "776079",
    "end": "782240"
  },
  {
    "text": "everything to escape across region so if we need more region we will create another cluster",
    "start": "782240",
    "end": "787279"
  },
  {
    "text": "we standardize it on helm via flag cd using agitos pattern because github was not new to fastly even when they were",
    "start": "787279",
    "end": "793760"
  },
  {
    "text": "not using kubernetes at the beginning and we deployed to one single cloud provider but the stack the whole stack",
    "start": "793760",
    "end": "799920"
  },
  {
    "text": "was designed to be cloud has no agnostic because we were envisioning that some people will request other cloud provider",
    "start": "799920",
    "end": "805360"
  },
  {
    "text": "or even parameter clusters so to accomplish that we did things like implement authentication with our",
    "start": "805360",
    "end": "811360"
  },
  {
    "text": "identity provider not time to the cloud am we were using hardware we're using hardware as a container register you",
    "start": "811360",
    "end": "816959"
  },
  {
    "text": "know gcr not tcr or anything like that we're using bolt for secrets management",
    "start": "816959",
    "end": "822240"
  },
  {
    "text": "because you know kubernetes secrets um you know and also we're using ingress engine x",
    "start": "822240",
    "end": "828399"
  },
  {
    "text": "and are using the cloud ingress and also share manager is not the cloud google cluster manager aws rmi or",
    "start": "828399",
    "end": "834880"
  },
  {
    "text": "anything like that we're using jet stack share manager to issue thirds from less and create and also from our",
    "start": "834880",
    "end": "840560"
  },
  {
    "text": "recently released root ca our servability stack is pretty common",
    "start": "840560",
    "end": "846000"
  },
  {
    "text": "obser prometheus grafana splunk fluenty so it's also open source not tying into",
    "start": "846000",
    "end": "851279"
  },
  {
    "text": "anything not tying into any cloud provider so as soon as we released the first",
    "start": "851279",
    "end": "857680"
  },
  {
    "text": "version we started having the first customers and we tried to gather feedback um",
    "start": "857680",
    "end": "863040"
  },
  {
    "text": "the most important feedback we got is hey we we need more regions we we need more cloud providers we would like to have",
    "start": "863040",
    "end": "869120"
  },
  {
    "text": "parameter clusters because we are hosting latency sensitive applications so we we want to be closer to this pop or closer",
    "start": "869120",
    "end": "876480"
  },
  {
    "text": "to that pop or this fastly deployment or this cloud service right um so we got it",
    "start": "876480",
    "end": "883519"
  },
  {
    "text": "the the other thing was reducing the onboarding overhead because the onboarding at the beginning was a bit convoluted so",
    "start": "883519",
    "end": "888800"
  },
  {
    "text": "false will register the namespace and we'll register a predefined service account so then we will have to",
    "start": "888800",
    "end": "893920"
  },
  {
    "text": "configure bolt so the service account can read in a specific path involved and",
    "start": "893920",
    "end": "898959"
  },
  {
    "text": "that was a bit you know convoluted like i said also the pilot team they wanted a proper",
    "start": "898959",
    "end": "904399"
  },
  {
    "text": "um kafka kafka support in the company without needing to go and create more vms peering with vpc or something like",
    "start": "904399",
    "end": "911680"
  },
  {
    "text": "that so they wanted something in cluster and they asked it for for help um also",
    "start": "911680",
    "end": "918160"
  },
  {
    "text": "there were other teams that they were not comp they were completely new to kubernetes helm and other stuff and and",
    "start": "918160",
    "end": "923440"
  },
  {
    "text": "when they tried to to get into into our platform they were like oh geez this is overwhelming uh can we can you",
    "start": "923440",
    "end": "931040"
  },
  {
    "text": "folks build more abstractions to to engineers like us more used to networking than than the kubernetes",
    "start": "931040",
    "end": "938880"
  },
  {
    "text": "so um also we provide the service mesh in the first version and we were not providing",
    "start": "938880",
    "end": "945120"
  },
  {
    "text": "like a lot of visibility into a service mesh so that was a reasonable ask so with it and with that come the second",
    "start": "945120",
    "end": "952079"
  },
  {
    "text": "version of elevation which is more or less how kubernetes looks at fastly today",
    "start": "952079",
    "end": "958320"
  },
  {
    "text": "it it became pretty clearly pretty oh sorry it became clear pretty quickly that with four team members we won't be",
    "start": "958320",
    "end": "964880"
  },
  {
    "text": "able to scale properly and create cluster cross read young and cross clouds and whatnot so so we got two new",
    "start": "964880",
    "end": "971440"
  },
  {
    "text": "members that have been very helpful uh we're in the us and when in the uk",
    "start": "971440",
    "end": "977839"
  },
  {
    "text": "so this is what we did clusters in google cloud in aws bari metal is spanning across three different",
    "start": "977839",
    "end": "985120"
  },
  {
    "text": "continents and regions and so on so forth and we have today i think like 20-ish clusters",
    "start": "985120",
    "end": "991440"
  },
  {
    "text": "and i'm probably we're creating three or four more in the coming weeks so",
    "start": "991440",
    "end": "996800"
  },
  {
    "text": "that was that's what we did one of the key messages that i want to share is that we started relying a lot",
    "start": "996800",
    "end": "1002560"
  },
  {
    "text": "in operators the existing operators and operators that we built in the team and that was a that was a huge win for",
    "start": "1002560",
    "end": "1009360"
  },
  {
    "text": "cell service making teams more autonomous and automation and stuff like that this is one of the examples who so we",
    "start": "1009360",
    "end": "1016079"
  },
  {
    "text": "built a custom controller to configure hashicor bolt so we we have also a tool called kiverno",
    "start": "1016079",
    "end": "1023360"
  },
  {
    "text": "maybe you're familiar with it which is a policy management tool so now when when people are registering a",
    "start": "1023360",
    "end": "1029438"
  },
  {
    "text": "namespace in elevation uh under the hood kiverno will create a secret engine kv2 secret engine that",
    "start": "1029439",
    "end": "1036480"
  },
  {
    "text": "will get mounted automatically in its last namespace also when a service account gets created",
    "start": "1036480",
    "end": "1042640"
  },
  {
    "text": "no need for registering a service account or like that kiverno will create a ball roll and a",
    "start": "1042640",
    "end": "1048558"
  },
  {
    "text": "ball policy using our ball controller so that's all with the whole the whole on boarding issues and we rely them more",
    "start": "1048559",
    "end": "1056400"
  },
  {
    "text": "in more controllers also we provided some abstractions",
    "start": "1056400",
    "end": "1061520"
  },
  {
    "text": "we created a library chart and also a default chart that will encompass like you know all the best practices like uh",
    "start": "1061520",
    "end": "1068000"
  },
  {
    "text": "making sure that you have a both description budgets that you have put on the affinities and you don't have to",
    "start": "1068000",
    "end": "1073840"
  },
  {
    "text": "care about should i put this annotation for this or that annotation for that what ingress class what server manager",
    "start": "1073840",
    "end": "1079280"
  },
  {
    "text": "issuer and stuff like that so with this simple yaml file people would will be able to",
    "start": "1079280",
    "end": "1084880"
  },
  {
    "text": "deploy an http application with tls and ingress routing",
    "start": "1084880",
    "end": "1090960"
  },
  {
    "text": "we made some observability improvements so in elevation uh i think this is pretty common pattern whenever you",
    "start": "1091039",
    "end": "1096720"
  },
  {
    "text": "deploy your containers into elevation you you we provide with a default dashboard which is called the world load",
    "start": "1096720",
    "end": "1102960"
  },
  {
    "text": "overview right so you will get cpu uh memory and stuff like that but we were",
    "start": "1102960",
    "end": "1108080"
  },
  {
    "text": "missing like a lot of servicemen's visibility so we built in a bunch of linker the dashboard into our",
    "start": "1108080",
    "end": "1114640"
  },
  {
    "text": "default dashboard but of course we enable the linker the ui and we enable teams to execute on their namespace",
    "start": "1114640",
    "end": "1121760"
  },
  {
    "text": "linkedin tab link in the top and all that stuff to travel should because it's freaking important for teams like",
    "start": "1121760",
    "end": "1127039"
  },
  {
    "text": "autopilot uh which are indeed it's a network service right other than that um git ops is cool but",
    "start": "1127039",
    "end": "1134400"
  },
  {
    "text": "people were like okay so this thing got merged so now what is it deployed or not so we created a bunch of grafana tables",
    "start": "1134400",
    "end": "1141760"
  },
  {
    "text": "and dashboard this is just an example so to make sure that they understand like the thing got deployed correctly",
    "start": "1141760",
    "end": "1149520"
  },
  {
    "text": "and of course we we talked about um using an operator in the cluster and um",
    "start": "1149600",
    "end": "1154799"
  },
  {
    "text": "we agreed like the string c seemed like a a strong a strong operator well maintained to provide a cell service",
    "start": "1154799",
    "end": "1162000"
  },
  {
    "text": "around creating kafka clusters and teams could be very autonomous on that",
    "start": "1162000",
    "end": "1167840"
  },
  {
    "text": "so i'm going to talk about a little bit how it is the user experience in elevation today and what teams like",
    "start": "1168240",
    "end": "1174799"
  },
  {
    "text": "autopilot are actually experiencing so",
    "start": "1174799",
    "end": "1179840"
  },
  {
    "text": "we have an initial exploratory phase where we have like our back roof relays relaxed uh policies relaxed",
    "start": "1179840",
    "end": "1186799"
  },
  {
    "text": "and these are basically development clusters we also we also have a playground project in our container registry in",
    "start": "1186799",
    "end": "1193520"
  },
  {
    "text": "harvard so people don't need ci to push an image to it they",
    "start": "1193520",
    "end": "1198559"
  },
  {
    "text": "they they just go ahead develop their thing iterate push their images and then we will allow hardware a playground",
    "start": "1198559",
    "end": "1205360"
  },
  {
    "text": "project in our development cluster there's no enforcement either on using flags githubs or anything like that they",
    "start": "1205360",
    "end": "1211120"
  },
  {
    "text": "can use the default chart that we provide their own health chart royal ml customize whatever they need to iterate",
    "start": "1211120",
    "end": "1216799"
  },
  {
    "text": "and get their application running and then being able to move on to the next phase obviously we have a ball cluster per",
    "start": "1216799",
    "end": "1223440"
  },
  {
    "text": "cluster so they go and put their secrets there if they need to and once they feel comfortable",
    "start": "1223440",
    "end": "1230640"
  },
  {
    "text": "they go on uh to the next phase which is build and then deploy so they just push their docker file under hem chart if",
    "start": "1230640",
    "end": "1237360"
  },
  {
    "text": "they have a hamstring and not using the default chart then a jenkins job will kick off and then jenkins will contact um",
    "start": "1237360",
    "end": "1244480"
  },
  {
    "text": "hashgraph with the hardware plugin that we built in-house to issue ephemeral",
    "start": "1244480",
    "end": "1249679"
  },
  {
    "text": "hardware robot account tokens so then jenkins will sign the images we'll package the hem chart if any and",
    "start": "1249679",
    "end": "1257200"
  },
  {
    "text": "sign it as well and then push it to hardware's fast list project which is the only one allowed in production and",
    "start": "1257200",
    "end": "1262559"
  },
  {
    "text": "staging clusters after that they can just go ahead and deploy using flux so they just need to",
    "start": "1262559",
    "end": "1268960"
  },
  {
    "text": "create a pull request against our hem releases repository and some teams even go very",
    "start": "1268960",
    "end": "1274480"
  },
  {
    "text": "innovative and created their own jenkins pipelines to automatically generate a hand release from a docker image stack",
    "start": "1274480",
    "end": "1281440"
  },
  {
    "text": "updating only the key values that they need then flux will go and synchronize and",
    "start": "1281440",
    "end": "1286799"
  },
  {
    "text": "deploy the hand release to the kubernetes cluster",
    "start": "1286799",
    "end": "1293280"
  },
  {
    "text": "so now i hand over to danny to explain the good about and the ugly things about all this all of this",
    "start": "1293280",
    "end": "1298720"
  },
  {
    "text": "correct so yes we are going to now present some details about the solution in three different buckets and that",
    "start": "1298720",
    "end": "1305039"
  },
  {
    "text": "reminded us this film film by the way that i didn't know but it was recorded here in several",
    "start": "1305039",
    "end": "1311360"
  },
  {
    "text": "locations in spain including almeria that is in the south of let's",
    "start": "1311360",
    "end": "1316480"
  },
  {
    "text": "say valencia so uh yes let's first see the the first",
    "start": "1316480",
    "end": "1322159"
  },
  {
    "text": "buckets good things and one is like configuration management for this solution",
    "start": "1322159",
    "end": "1329039"
  },
  {
    "text": "so this this piece of jammel hope the guys in",
    "start": "1329039",
    "end": "1334799"
  },
  {
    "text": "the back of the room can read something but this is just an example that comes in the stream documentation",
    "start": "1334799",
    "end": "1342080"
  },
  {
    "text": "it's just how to create an example kafka cluster you define several properties",
    "start": "1342080",
    "end": "1348799"
  },
  {
    "text": "including the sizing uh how which some defaults and",
    "start": "1348799",
    "end": "1355520"
  },
  {
    "text": "even some properties of the zookeeper cluster that it's backing the the",
    "start": "1355520",
    "end": "1360799"
  },
  {
    "text": "at its back in kafka and even other operators that we can you can plug to this",
    "start": "1360799",
    "end": "1367840"
  },
  {
    "text": "to this setup but we didn't stop there as fernando mentioned we are using helm",
    "start": "1367840",
    "end": "1373919"
  },
  {
    "text": "charts to push workloads to the elevation to the kubernetes clusters so we also created one for the telemetry",
    "start": "1373919",
    "end": "1380559"
  },
  {
    "text": "kafka and that chart is actually exposing some values some of them are sizing matters",
    "start": "1380559",
    "end": "1387600"
  },
  {
    "text": "which are not abstracting the cluster too much but some others and i think the important piece is the autopilot cites a",
    "start": "1387600",
    "end": "1395360"
  },
  {
    "text": "value that it's in the bottom it's the list of pops that are given deployment a given autopilot deployment",
    "start": "1395360",
    "end": "1401200"
  },
  {
    "text": "is expected to support we have equivalent properties in other autopilot",
    "start": "1401200",
    "end": "1406480"
  },
  {
    "text": "services and the idea in the case of kafka is that if you define a specific",
    "start": "1406480",
    "end": "1411679"
  },
  {
    "text": "pop you want to support in a cluster automatically you are going to get the",
    "start": "1411679",
    "end": "1417360"
  },
  {
    "text": "topics you need for the telemetry data for that top you are going to get a right user with",
    "start": "1417360",
    "end": "1424080"
  },
  {
    "text": "the right grants a read user and also the operator is going to store some credentials directly",
    "start": "1424080",
    "end": "1430080"
  },
  {
    "text": "as kubernetes secrets then some processes that are emitting",
    "start": "1430080",
    "end": "1435200"
  },
  {
    "text": "the data like sftd from pmrt can pick the secrets and directly start",
    "start": "1435200",
    "end": "1441279"
  },
  {
    "text": "pushing the data to the topics and the same for the reader in a predictable location they can pick",
    "start": "1441279",
    "end": "1447279"
  },
  {
    "text": "the credentials and that's it so everything is plugged and",
    "start": "1447279",
    "end": "1452640"
  },
  {
    "text": "here so the first key point in this section is like we don't have a separate",
    "start": "1452640",
    "end": "1458080"
  },
  {
    "text": "tool on or configuration management system for the kafka cluster it's just",
    "start": "1458080",
    "end": "1463440"
  },
  {
    "text": "another hand release in as we have for the other applications and in fact in the past i have been",
    "start": "1463440",
    "end": "1469679"
  },
  {
    "text": "promoting for instance polumi a lot also externally but not having",
    "start": "1469679",
    "end": "1474880"
  },
  {
    "text": "to require a different tool to manage your kafka cluster is even better than the best of",
    "start": "1474880",
    "end": "1480159"
  },
  {
    "text": "the tools so more things about the helm chart we have in the middle that is also as i",
    "start": "1480159",
    "end": "1486559"
  },
  {
    "text": "mentioned a good abstraction opportunity and the sizing knobs",
    "start": "1486559",
    "end": "1491600"
  },
  {
    "text": "which are very coupled to the kafka setup could be even removed",
    "start": "1491600",
    "end": "1497440"
  },
  {
    "text": "now that we are supporting the solution in many pops we can't predict how much let's say how big the kafka cluster",
    "start": "1497440",
    "end": "1503760"
  },
  {
    "text": "needs to be given the number of pops we are supporting so we could even drop these values and in the end just have",
    "start": "1503760",
    "end": "1510320"
  },
  {
    "text": "the list of pops we are going to support regarding portability",
    "start": "1510320",
    "end": "1516400"
  },
  {
    "text": "these are just a few commands this is the helm releases repo fernando was",
    "start": "1516400",
    "end": "1521760"
  },
  {
    "text": "mentioning so we have several hand releases as xml files in a given folder",
    "start": "1521760",
    "end": "1527840"
  },
  {
    "text": "one folder a per a cluster and in the end in order to deploy autopilot in a",
    "start": "1527840",
    "end": "1533679"
  },
  {
    "text": "different cluster with the same configuration it's as simple as copying the helm releases",
    "start": "1533679",
    "end": "1539679"
  },
  {
    "text": "and in fact that is already outdated it's where autopilot was already running a",
    "start": "1539679",
    "end": "1545520"
  },
  {
    "text": "few weeks ago and was we had many different clusters some in aws on",
    "start": "1545520",
    "end": "1551120"
  },
  {
    "text": "gcp and everything looks more or less the same from a configuration perspective",
    "start": "1551120",
    "end": "1556880"
  },
  {
    "text": "regarding plugability and mostly focused in operational tooling i think the also the streams operator",
    "start": "1556880",
    "end": "1563520"
  },
  {
    "text": "does a great job exposing some operational flows directly as",
    "start": "1563520",
    "end": "1568559"
  },
  {
    "text": "kubernetes primitives so in this case if you want to browse which kafka topics do we have you can you can just use qfctl",
    "start": "1568559",
    "end": "1576559"
  },
  {
    "text": "and list these objects or even other",
    "start": "1576559",
    "end": "1581760"
  },
  {
    "text": "maintenance operations like i want to trigger a rolling upgrade in my cluster you just",
    "start": "1581760",
    "end": "1588400"
  },
  {
    "text": "the streams operator maps this to an annotation in the stateful set for the cluster so in order to trigger it you",
    "start": "1588400",
    "end": "1595120"
  },
  {
    "text": "just put that annotation and the magic happens then plugability also with the auxiliary",
    "start": "1595120",
    "end": "1601120"
  },
  {
    "text": "systems the streams community is maintaining like some great grafana dashboards but",
    "start": "1601120",
    "end": "1606880"
  },
  {
    "text": "it's not just the fact that we have grafana to display all the prometheus metrics is the fact that all telemetry",
    "start": "1606880",
    "end": "1613440"
  },
  {
    "text": "services can share a common dashboard where you can easily correlate information from the",
    "start": "1613440",
    "end": "1620480"
  },
  {
    "text": "meter of the of kafka with the kafka metrics themselves and that is super",
    "start": "1620480",
    "end": "1625760"
  },
  {
    "text": "powerful to in the end identify and correlate problems you may have in your setup",
    "start": "1625760",
    "end": "1631760"
  },
  {
    "text": "and the same applies to the logs we are using splunk we are forwarding everything to splunk and in a single",
    "start": "1631760",
    "end": "1637440"
  },
  {
    "text": "query we can check okay what are the logs in this case of the telemetry",
    "start": "1637440",
    "end": "1644080"
  },
  {
    "text": "component so the one that is consuming the data but also the logs from the kafka cluster and you can easily",
    "start": "1644080",
    "end": "1650799"
  },
  {
    "text": "correlate events so a summary of this section",
    "start": "1650799",
    "end": "1656240"
  },
  {
    "text": "kafka in our setup is not a special thing it's just another workload in the cluster and",
    "start": "1656240",
    "end": "1662080"
  },
  {
    "text": "we use the same tooling and the same processes to manage a kafka",
    "start": "1662080",
    "end": "1667360"
  },
  {
    "text": "as well as the other workloads we have in the telemetry pipeline then things that are not so great in",
    "start": "1667360",
    "end": "1675360"
  },
  {
    "text": "this setup is the fact that yeah we have an operator an operator is an extra component you need to install and",
    "start": "1675360",
    "end": "1681760"
  },
  {
    "text": "maintaining your cluster a compare to some software as a service solutions",
    "start": "1681760",
    "end": "1688080"
  },
  {
    "text": "and actually that brings an interesting topic that is ownership of the operator",
    "start": "1688080",
    "end": "1693520"
  },
  {
    "text": "right now the operators in the elevation clusters are maintained by our platform team so fernando's team",
    "start": "1693520",
    "end": "1700320"
  },
  {
    "text": "and teams like network systems they are just consuming the operators",
    "start": "1700320",
    "end": "1705679"
  },
  {
    "text": "however however we feel like this something like this may not scale well so in the moment we have other teams",
    "start": "1705679",
    "end": "1712080"
  },
  {
    "text": "consuming or creating their kafka clusters just coordinating the teams to",
    "start": "1712080",
    "end": "1718000"
  },
  {
    "text": "to perform a kafka upgrade normally in hand with an operator upgrade can easily become a full-time job so yeah we bet",
    "start": "1718000",
    "end": "1725520"
  },
  {
    "text": "that at some point if this solution is kind of consumed by other teams",
    "start": "1725520",
    "end": "1730799"
  },
  {
    "text": "we may need to involve other teams to support the solution",
    "start": "1730799",
    "end": "1736880"
  },
  {
    "text": "and fernando the ugly like like me",
    "start": "1736960",
    "end": "1741600"
  },
  {
    "text": "so you know what happens when you have a kubernetes in multiple clouds barry metal you have a service mesh you have",
    "start": "1742399",
    "end": "1747840"
  },
  {
    "text": "udp you have bgp that it it's bound to happen that you're gonna find",
    "start": "1747840",
    "end": "1753520"
  },
  {
    "text": "these dudes just eating popcorn uh laughing at your face",
    "start": "1753520",
    "end": "1758880"
  },
  {
    "text": "so the the first very interesting challenge that we found is that you know autopilot telemetry api receives like a constant",
    "start": "1758880",
    "end": "1765840"
  },
  {
    "text": "udp flow non-stop it's non-stop from the switches so we noticed that pod that got",
    "start": "1765840",
    "end": "1771440"
  },
  {
    "text": "restarted and rescheduled to the same node somehow the udp packets started to be blackholed",
    "start": "1771440",
    "end": "1776559"
  },
  {
    "text": "my teammate and friend danny kuczynski thankfully discovered the",
    "start": "1776559",
    "end": "1781600"
  },
  {
    "text": "backing cube proxy which basically you know when you're going from one end point to zero endpoint",
    "start": "1781600",
    "end": "1787120"
  },
  {
    "text": "q proxy will flash the contract entry corresponding to the load balancer uh external ip and the pod ip right",
    "start": "1787120",
    "end": "1794640"
  },
  {
    "text": "but contract sorry the flow will still hit the node if it's rescheduling the same node so a",
    "start": "1794640",
    "end": "1800080"
  },
  {
    "text": "new contract entry was created before the ipta was not got apply so the",
    "start": "1800080",
    "end": "1805200"
  },
  {
    "text": "contract entry had the load balancer external ip and not the pod ip that was very interesting we found that",
    "start": "1805200",
    "end": "1811520"
  },
  {
    "text": "back they fixed it pretty quickly so that's dumb",
    "start": "1811520",
    "end": "1816640"
  },
  {
    "text": "this one is also a good one very interesting because it was a whole team f4",
    "start": "1816640",
    "end": "1821679"
  },
  {
    "text": "and i appreciate that so they the we hit the hard limit in in aws security group rule limit and then",
    "start": "1821679",
    "end": "1829120"
  },
  {
    "text": "we can we reach out to the time to our time there was nothing they could do and and basically the problem is that",
    "start": "1829120",
    "end": "1835520"
  },
  {
    "text": "the aws load balancer controller will create an excessive amount of security group rules",
    "start": "1835520",
    "end": "1841279"
  },
  {
    "text": "um [Music] per per load balancer so it's one inbound rule for the node security group",
    "start": "1841279",
    "end": "1847840"
  },
  {
    "text": "per client traffic allowed source ip which is something that autopilot for instance uses a lot",
    "start": "1847840",
    "end": "1854480"
  },
  {
    "text": "and then one rule for the health check on each subnet in the vpc",
    "start": "1854480",
    "end": "1859519"
  },
  {
    "text": "so one of the recommendations where i'll switch to alv and this is not http so not not very helpful",
    "start": "1859519",
    "end": "1865840"
  },
  {
    "text": "or switched to elv it's deprecated right so not an option either and uh we could",
    "start": "1865840",
    "end": "1871120"
  },
  {
    "text": "we we needed also to preserve the source ip because otherwise we couldn't perform authentication based on ip and stuff",
    "start": "1871120",
    "end": "1877200"
  },
  {
    "text": "like that so so uh we we didn't wanted to implement something like proxy protocol or anything like that",
    "start": "1877200",
    "end": "1883279"
  },
  {
    "text": "so we came up with a creative software solution which basically was let's disable the security group creation at",
    "start": "1883279",
    "end": "1889600"
  },
  {
    "text": "all and let let's just use kiberno to create a calico global network policy that will",
    "start": "1889600",
    "end": "1895519"
  },
  {
    "text": "allow or block traffic so we did that but you know like in kubernetes there is an orphan dependent",
    "start": "1895519",
    "end": "1901039"
  },
  {
    "text": "rule right so a load balancer service cannot own a global network policy because the global",
    "start": "1901039",
    "end": "1908080"
  },
  {
    "text": "network policies cluster scope and the load balancer is named space scope so ki verno couldn't delete the",
    "start": "1908080",
    "end": "1914399"
  },
  {
    "text": "couldn't garbage collect the global network policy if the service if the load balancer service got deleted so we implemented our own",
    "start": "1914399",
    "end": "1921279"
  },
  {
    "text": "custom controller custom service controller based on annotation only to to garbage collect the calico global",
    "start": "1921279",
    "end": "1927120"
  },
  {
    "text": "network policy it's been rolled out in production like three four weeks ago and it's working",
    "start": "1927120",
    "end": "1932880"
  },
  {
    "text": "fine and we we're not expecting more issues in that regard",
    "start": "1932880",
    "end": "1938960"
  },
  {
    "text": "so handing over to then again yes let's quickly review the impact of",
    "start": "1938960",
    "end": "1944159"
  },
  {
    "text": "this setup in our teams the first box actually represents the",
    "start": "1944159",
    "end": "1949279"
  },
  {
    "text": "first pr we had in the telemetry uh repo so and it's actually the the bootstrap",
    "start": "1949279",
    "end": "1955120"
  },
  {
    "text": "so just the gopher app is an internal tool to bootstrap a golang project so it's just creating the structure",
    "start": "1955120",
    "end": "1961200"
  },
  {
    "text": "and the second is it represents actually the moment where we enable the telemetry pipeline in a non-production cluster",
    "start": "1961200",
    "end": "1968720"
  },
  {
    "text": "and it only took like four weeks to get the full solution working in that non-production pop",
    "start": "1968720",
    "end": "1975120"
  },
  {
    "text": "and considering that the team was quite small with also maintaining other services and doing other projects that",
    "start": "1975120",
    "end": "1980399"
  },
  {
    "text": "was pretty nice also reviewing the history of the of the",
    "start": "1980399",
    "end": "1986000"
  },
  {
    "text": "repo with the helm chart for the kafka setup there are there were some changes in the",
    "start": "1986000",
    "end": "1991120"
  },
  {
    "text": "last months but they are mostly connected to kafka upgrades and operator upgrades and not to scale the solution",
    "start": "1991120",
    "end": "1997360"
  },
  {
    "text": "we essentially we were able to just adding additional values to scale the solution to all the pops and in fact if",
    "start": "1997360",
    "end": "2003760"
  },
  {
    "text": "you take a look to the helm releases repo where we have the actual worlds we are running in production you can see",
    "start": "2003760",
    "end": "2010399"
  },
  {
    "text": "that there has been already like 10 engineers contributing to the kafka configuration that silently means these",
    "start": "2010399",
    "end": "2018559"
  },
  {
    "text": "engineers have been creating kafka topics kafka users even without knowing",
    "start": "2018559",
    "end": "2024080"
  },
  {
    "text": "so yes we have like this impression that okay autopilot actually manage itself",
    "start": "2024080",
    "end": "2030000"
  },
  {
    "text": "and given this right now we are working to consolidate other telemetry uh processing in the",
    "start": "2030000",
    "end": "2037039"
  },
  {
    "text": "same architecture and also the net network teams of network operations they use this type of",
    "start": "2037039",
    "end": "2045039"
  },
  {
    "text": "network data to operate the network every day but there are even other use cases like",
    "start": "2045039",
    "end": "2050240"
  },
  {
    "text": "capacity planning and implementing other solutions on top of this information",
    "start": "2050240",
    "end": "2056158"
  },
  {
    "text": "and yes and not only the kafka like the telemetry pipelines consolidation we are",
    "start": "2056159",
    "end": "2061200"
  },
  {
    "text": "also now migrating other workloads we had in these dedicated gt clusters to elevation",
    "start": "2061200",
    "end": "2067118"
  },
  {
    "text": "so we can just focus in other challenges we have so let's now start closing",
    "start": "2067119",
    "end": "2074560"
  },
  {
    "text": "the session main points we need like a scalable platform to run",
    "start": "2074560",
    "end": "2081520"
  },
  {
    "text": "a network automation at fastly and kubernetes is a great fit for this",
    "start": "2081520",
    "end": "2087040"
  },
  {
    "text": "and in addition our very specific setup with some operators like the stream c1 and also some other configurations is",
    "start": "2087040",
    "end": "2094480"
  },
  {
    "text": "helping us in projects like like autopilot and its telemetry",
    "start": "2094480",
    "end": "2099599"
  },
  {
    "text": "pipeline thanks for being here i think we have",
    "start": "2099599",
    "end": "2104800"
  },
  {
    "text": "maybe well not so much time for questions but maybe we can accept one",
    "start": "2104800",
    "end": "2111119"
  },
  {
    "text": "i don't know if there is a microphone for this or if you want to ask and i will try to",
    "start": "2112240",
    "end": "2117280"
  },
  {
    "text": "repeat",
    "start": "2117280",
    "end": "2119680"
  },
  {
    "text": "we use mutual tls4",
    "start": "2126320",
    "end": "2130119"
  },
  {
    "text": "er not exactly well yes it's a dtls and yes uh",
    "start": "2132160",
    "end": "2139880"
  },
  {
    "text": "correct perfect so the question is how the the kafka consumers and the producers how",
    "start": "2146640",
    "end": "2153920"
  },
  {
    "text": "they do authenticate against the the kafka cluster",
    "start": "2153920",
    "end": "2159240"
  },
  {
    "text": "okay so how we distribute the the certificates across the diff the different different",
    "start": "2167920",
    "end": "2174960"
  },
  {
    "text": "workloads in the cluster so here i stream is our friend it's when you declare a kafka user that is a specific",
    "start": "2174960",
    "end": "2181920"
  },
  {
    "text": "object stream c it's a custom resource stream she gives to the",
    "start": "2181920",
    "end": "2187200"
  },
  {
    "text": "cluster since he actually there are different like user authentication types yes we",
    "start": "2187200",
    "end": "2192400"
  },
  {
    "text": "are using a tls based authentication and that means that the stream c creates the credentials and stores the",
    "start": "2192400",
    "end": "2198640"
  },
  {
    "text": "credentials as kubernetes secrets so then given the workloads using kafka",
    "start": "2198640",
    "end": "2204560"
  },
  {
    "text": "live in the same cluster we can directly pull these credentials from the other workloads",
    "start": "2204560",
    "end": "2212240"
  },
  {
    "text": "correct yes we are using that a shared kubernetes offering from platform so we have a dedicated namespace for autopilot",
    "start": "2213520",
    "end": "2220400"
  },
  {
    "text": "services so yes all these services live in a single name space",
    "start": "2220400",
    "end": "2225520"
  },
  {
    "text": "thank you so thanks",
    "start": "2225520",
    "end": "2231160"
  }
]
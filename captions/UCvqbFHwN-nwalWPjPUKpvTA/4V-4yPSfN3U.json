[
  {
    "start": "0",
    "end": "0"
  },
  {
    "text": "okay thanks everybody for patients like",
    "start": "230",
    "end": "5450"
  },
  {
    "text": "benchmarking the AV for the talk is fixed as long as it's fixed before the",
    "start": "5450",
    "end": "10620"
  },
  {
    "text": "talk is supposed to start right just like it doesn't matter how slow the responses as long as it's within your",
    "start": "10620",
    "end": "16350"
  },
  {
    "text": "required time parameters so we're gonna talk a little bit about benchmarking and about storage on kubernetes",
    "start": "16350",
    "end": "23820"
  },
  {
    "text": "now I've been doing this kubernetes thing for a little while since I don't know 0-8 something like",
    "start": "23820",
    "end": "31500"
  },
  {
    "text": "that and the reason why I got into kubernetes is because I wanted to put",
    "start": "31500",
    "end": "40110"
  },
  {
    "text": "databases on kubernetes I've been a database geek for quite a while I've been doing database automation as a",
    "start": "40110",
    "end": "47940"
  },
  {
    "text": "consultant and that sort of thing and I saw a real opportunity with kubernetes to provide a platform for database",
    "start": "47940",
    "end": "54210"
  },
  {
    "text": "automation however not everyone is as",
    "start": "54210",
    "end": "59910"
  },
  {
    "text": "optimistic as I am about putting",
    "start": "59910",
    "end": "65040"
  },
  {
    "text": "databases in stateful applications on kubernetes the a lot of people have seen",
    "start": "65040",
    "end": "72780"
  },
  {
    "text": "this tweet by Kelsey which was the start of an argument between the two of us about stateful applications and",
    "start": "72780",
    "end": "79259"
  },
  {
    "text": "kubernetes but the and admittedly he has",
    "start": "79259",
    "end": "85439"
  },
  {
    "text": "a point because there are a lot of issues with running stateful application",
    "start": "85439",
    "end": "90869"
  },
  {
    "text": "of kubernetes and most of them relate to storage that is storage is still hard we",
    "start": "90869",
    "end": "101460"
  },
  {
    "text": "haven't done a lot to make storage less hard on kubernetes than it was before kubernetes was around so we're working",
    "start": "101460",
    "end": "108899"
  },
  {
    "text": "on it now one of the things if you're talking about storage for a cloud for a large",
    "start": "108899",
    "end": "115079"
  },
  {
    "text": "infrastructure for that sort of thing you actually have sort of three major",
    "start": "115079",
    "end": "120570"
  },
  {
    "text": "problems in this environment one is management as in you have admins and",
    "start": "120570",
    "end": "127710"
  },
  {
    "text": "that sort of thing who are used to the storage environment from bare metal etc I'm used to an older set of tools",
    "start": "127710",
    "end": "134270"
  },
  {
    "text": "they're not used to the new tools the new tools aren't necessarily as complete or as mature as some of the old tools",
    "start": "134270",
    "end": "139700"
  },
  {
    "text": "were although that's arguable and so that presents a challenge to doing",
    "start": "139700",
    "end": "145370"
  },
  {
    "text": "storage and stateful apps and on you know cloud native environment the second thing is setup complexity just the",
    "start": "145370",
    "end": "152660"
  },
  {
    "text": "difficulty because you have all of the stuff that you used to have to do to make storage physically work and now you",
    "start": "152660",
    "end": "158959"
  },
  {
    "text": "also have to configure this abstraction layer on top in order to let your cloud",
    "start": "158959",
    "end": "164180"
  },
  {
    "text": "native platform access the storage and then a third question or a third problem",
    "start": "164180",
    "end": "169670"
  },
  {
    "text": "that always comes up is performance right as people do not want to give up performance for that cloud now in terms",
    "start": "169670",
    "end": "179239"
  },
  {
    "text": "of setup complexity were already trying to address its but one of my favorite projects which is rook right so Brooke is an operator that configures your",
    "start": "179239",
    "end": "186049"
  },
  {
    "text": "storage in a kubernetes environment and the goal of this is to simplify storage",
    "start": "186049",
    "end": "191299"
  },
  {
    "text": "complexity for people doing work on bare metal or more hand-built clouds etc and",
    "start": "191299",
    "end": "198980"
  },
  {
    "text": "made a lot of progress in rock there's still a lot of work to do but it really is a very nice tool so that's being",
    "start": "198980",
    "end": "205670"
  },
  {
    "text": "addressed I don't really have an answer for the management problems for anybody",
    "start": "205670",
    "end": "211100"
  },
  {
    "text": "here who is already an admin who is maybe moving their internal cloud native",
    "start": "211100",
    "end": "216140"
  },
  {
    "text": "world my answer is honestly get used to the new tools once you are used to them they are really better than the old",
    "start": "216140",
    "end": "221989"
  },
  {
    "text": "tools but I can't get you over that step of needing to get used to the new tools",
    "start": "221989",
    "end": "227079"
  },
  {
    "text": "and then the third issue is the one that we're going to be talking about today",
    "start": "227079",
    "end": "233209"
  },
  {
    "text": "performance the cell now there's a few",
    "start": "233209",
    "end": "241489"
  },
  {
    "text": "reasons why I want to talk about performance number one is I mean how many people here are a system administrator yeah and",
    "start": "241489",
    "end": "248840"
  },
  {
    "text": "how many people here are a database administrator yeah I got a few right and you guys don't care at all about",
    "start": "248840",
    "end": "254750"
  },
  {
    "text": "performance right it's not nobody asks you any questions of a performance do they right everything is always as fast",
    "start": "254750",
    "end": "263150"
  },
  {
    "text": "as it needs to be no no so Syd admins really care about performance it's something they spend a",
    "start": "263150",
    "end": "269270"
  },
  {
    "text": "lot of time thinking about and thus for the new cloud native platforms a lot of",
    "start": "269270",
    "end": "276530"
  },
  {
    "text": "trade-off is presented in the form of ease of use ease of manageability versus speed and that can be a hard trade-off",
    "start": "276530",
    "end": "284360"
  },
  {
    "text": "to make if speed is really important to you and if you're forced to make that",
    "start": "284360",
    "end": "290479"
  },
  {
    "text": "trade-off then that can be a major migration roadblock you can say hey well",
    "start": "290479",
    "end": "296030"
  },
  {
    "text": "we have everything that we need to move our platform to this new cloud native infrastructure that we built up but",
    "start": "296030",
    "end": "302300"
  },
  {
    "text": "we're worried that it's not gonna hold up under peak customer demand and we don't have a good way to figure that out",
    "start": "302300",
    "end": "308479"
  },
  {
    "text": "ahead of time now the other reason why I care about performance is that I've just",
    "start": "308479",
    "end": "314210"
  },
  {
    "text": "been doing that forever I've been a performance and benchmarking geek since",
    "start": "314210",
    "end": "319340"
  },
  {
    "text": "my hair was actually all blonde and I continue to do that because honestly",
    "start": "319340",
    "end": "324650"
  },
  {
    "text": "from my perspective because I'm a crazy person performance in benchmarking it's fun and so I've started doing a lot of",
    "start": "324650",
    "end": "332090"
  },
  {
    "text": "it on new cloud native stuff so let's talk a little bit about benchmarking because part of my goal here is I'm",
    "start": "332090",
    "end": "337970"
  },
  {
    "text": "gonna present some numbers and some of my own findings about benchmarking but what I really want you to learn here is",
    "start": "337970",
    "end": "343909"
  },
  {
    "text": "some of the tools that are out there and some of the methodologies that are out there for you to do your own benchmarking because my hardware is not",
    "start": "343909",
    "end": "351590"
  },
  {
    "text": "your hardware and the numbers that I show you aren't necessarily going to apply to your use case which means you",
    "start": "351590",
    "end": "356870"
  },
  {
    "text": "need to do your own testing and the tools are not actually as hard as you",
    "start": "356870",
    "end": "362300"
  },
  {
    "text": "might think they are so when we're talking about benchmarking what we're really talking about doing is",
    "start": "362300",
    "end": "367610"
  },
  {
    "text": "comparing so in English the word benchmark is both a thing that you do in",
    "start": "367610",
    "end": "374270"
  },
  {
    "text": "terms of like a benchmarking test etc and so think of you've said you know this is your mark of how fast or how",
    "start": "374270",
    "end": "381229"
  },
  {
    "text": "high or whatever you're supposed to be so when we're talking about benchmarking we're really talking about comparing right we're comparing cloud native",
    "start": "381229",
    "end": "387860"
  },
  {
    "text": "storage to say bare-metal storage or comparing new release of kubernetes or",
    "start": "387860",
    "end": "393380"
  },
  {
    "text": "rook or whatever to previous releases or we're comparing one configuration to another configure or most importantly we're comparing the",
    "start": "393380",
    "end": "401380"
  },
  {
    "text": "spec requirements of for example how fast a website request needs to be with",
    "start": "401380",
    "end": "407740"
  },
  {
    "text": "what we're actually getting and so we",
    "start": "407740",
    "end": "413020"
  },
  {
    "text": "need to benchmark a variety of different kinds of storage there are a variety of",
    "start": "413020",
    "end": "419290"
  },
  {
    "text": "storage options that we have out there and they're gonna benchmark so your",
    "start": "419290",
    "end": "425169"
  },
  {
    "text": "basic storage right what everybody's you know all familiar with is what we call bare metal storage right now this might",
    "start": "425169",
    "end": "430660"
  },
  {
    "text": "be bare VM storage which is more complicated I'm gonna get into that but you know in terms of you were using the",
    "start": "430660",
    "end": "437620"
  },
  {
    "text": "underlying platform and file system directly and running stuff on that and",
    "start": "437620",
    "end": "443160"
  },
  {
    "text": "then there's a sort of intermediate step on kubernetes where you can use local storage particularly recent releases of",
    "start": "443160",
    "end": "449169"
  },
  {
    "text": "kubernetes we have both host path and local persistent volumes options which",
    "start": "449169",
    "end": "455320"
  },
  {
    "text": "are very similar but work differently in subtly different ways that allow you to basically sort of directly attached",
    "start": "455320",
    "end": "460810"
  },
  {
    "text": "storage from the host which is actually a good option for a bunch of workloads like if you have a database that manages",
    "start": "460810",
    "end": "467650"
  },
  {
    "text": "all of its own redundancy then you don't necessarily need the storage layer to be redundant and local storage might be a",
    "start": "467650",
    "end": "474160"
  },
  {
    "text": "better option and then a third one which is actually the most common one and I think people shouldn't be quite so fast",
    "start": "474160",
    "end": "480010"
  },
  {
    "text": "to jump to this as their first option but everybody's running a public cloud right which means network storage right",
    "start": "480010",
    "end": "485620"
  },
  {
    "text": "and this could be a C on this could be EBS this could be something else but",
    "start": "485620",
    "end": "490720"
  },
  {
    "start": "487000",
    "end": "487000"
  },
  {
    "text": "network storage provided by the platform and network storage has its own you know sort of set of caveats and then the",
    "start": "490720",
    "end": "497289"
  },
  {
    "text": "final one are we talking about here is we call cloud native distributed storage right well you have a distributed storage platform you host that on",
    "start": "497289",
    "end": "504220"
  },
  {
    "text": "kubernetes and other tools and then at the same time it supplies storage to your cloud native environment and",
    "start": "504220",
    "end": "509710"
  },
  {
    "text": "there's a lot of fun because it is it is a sort of self-contained thing right you you were using cloud native tools to",
    "start": "509710",
    "end": "516280"
  },
  {
    "text": "deploy a complete stack instead of a partial stack we're accessing other things now I'm not going to be talking",
    "start": "516280",
    "end": "522729"
  },
  {
    "text": "about network storage for this if you look at my lightning talk from coop con Seattle that one was mostly about",
    "start": "522729",
    "end": "529750"
  },
  {
    "text": "network storage because I did all my test AWS so you can compare the numbers there",
    "start": "529750",
    "end": "534930"
  },
  {
    "text": "you look at look at my comparisons there one of the things that I will say is that in a lot of ways as a benchmark are",
    "start": "534930",
    "end": "542200"
  },
  {
    "text": "it's uninteresting because the performance characteristics of EBS",
    "start": "542200",
    "end": "547269"
  },
  {
    "text": "itself if you're testing an AWS dominate the benchmarks compared to any other platform choices now let's talk a little",
    "start": "547269",
    "end": "555970"
  },
  {
    "text": "bit about measuring IO right because this is what we're talking about in terms of benchmarking storage right as",
    "start": "555970",
    "end": "562600"
  },
  {
    "text": "we care about IO and there's four different kinds of IO activity random",
    "start": "562600",
    "end": "568149"
  },
  {
    "text": "leads we are looking up random blocks and pulling them up random writes where you're writing random blocks per",
    "start": "568149",
    "end": "574779"
  },
  {
    "text": "location to disk sequential reads where you're reading a whole bunch of stuff in a row that is at least logically bundled",
    "start": "574779",
    "end": "582459"
  },
  {
    "text": "together whether or not it's physically stored that way and then sequential writes where you're writing out very",
    "start": "582459",
    "end": "587890"
  },
  {
    "text": "large blocks and these are all different activities that different kinds of applications do and so we want to know",
    "start": "587890",
    "end": "593440"
  },
  {
    "text": "how they all perform now it happens to be the case that we can generally bundle random leads and random writes together",
    "start": "593440",
    "end": "599230"
  },
  {
    "text": "into one workload because most workloads that do random reads also do random writes and vice-versa and it's fairly easy to measure them",
    "start": "599230",
    "end": "606220"
  },
  {
    "text": "together what is sequential reads and sequential writes are often done at different times and so this is our sort",
    "start": "606220",
    "end": "611890"
  },
  {
    "text": "of standard bench marking setup and there's two main characteristics that we",
    "start": "611890",
    "end": "617440"
  },
  {
    "text": "actually want to measure one of them is latency and latency is honestly what we",
    "start": "617440",
    "end": "622779"
  },
  {
    "text": "care about the most which is how long does it take a single request to complete because that's usually what",
    "start": "622779",
    "end": "628000"
  },
  {
    "text": "your actual spec is right you know a user shaves their profile it has to come",
    "start": "628000",
    "end": "633339"
  },
  {
    "text": "back to them including the entire stack including the storage it has to come back to them in two seconds or less",
    "start": "633339",
    "end": "638380"
  },
  {
    "text": "right there might be your spec right and so you need to add up all the layers and make sure they don't add up to more than two seconds on a 95th percentile say and",
    "start": "638380",
    "end": "647260"
  },
  {
    "text": "so latency is what you generally care about and then the secondary thing that you care about is throughput right how many requests at once in parallel can we",
    "start": "647260",
    "end": "654970"
  },
  {
    "text": "handle and sometimes these two can be a trade off the but we need to know how we",
    "start": "654970",
    "end": "661270"
  },
  {
    "text": "hold up for both so we basically have sort of three different storage options and three",
    "start": "661270",
    "end": "666630"
  },
  {
    "text": "different kinds of i/o that we want to measure and at least two different metrics we want to measure across those",
    "start": "666630",
    "end": "671700"
  },
  {
    "text": "it's actually more metrics so I'm gonna do all this it's a lot of stuff what",
    "start": "671700",
    "end": "676800"
  },
  {
    "text": "just happens that US folks who in the database industry have spent something",
    "start": "676800",
    "end": "683400"
  },
  {
    "text": "on the order of five decades worrying about this so we have a lot of tools to",
    "start": "683400",
    "end": "688410"
  },
  {
    "text": "measure all of these things that are already there that are already reasonably featured complete that are",
    "start": "688410",
    "end": "693600"
  },
  {
    "text": "already actually reasonably easy to use for lightweight benchmark things so I",
    "start": "693600",
    "end": "700280"
  },
  {
    "text": "actually decided to start with three local micro benchmarks because it's a",
    "start": "700280",
    "end": "705390"
  },
  {
    "text": "full benchmark that's like TBC or spec or whatever that has a lot of complexity",
    "start": "705390",
    "end": "710760"
  },
  {
    "text": "and measures a lot of different kinds of state and a bunch of other things but if you just want to measure your storage",
    "start": "710760",
    "end": "716190"
  },
  {
    "text": "performance what you really want is what US folks in the performance industry call a micro benchmark which is a test",
    "start": "716190",
    "end": "721590"
  },
  {
    "text": "that does one or two relatively simple things in order to see how they perform",
    "start": "721590",
    "end": "728150"
  },
  {
    "text": "and so the three that I used for the series of tests were sis bench",
    "start": "728150",
    "end": "733670"
  },
  {
    "text": "PostgreSQL PG bench and the cockroach TB workloads now sis bench was created by the my",
    "start": "733670",
    "end": "741060"
  },
  {
    "text": "sequel team in order for them to benchmark stuff it's now its own separate open-source project has been",
    "start": "741060",
    "end": "746430"
  },
  {
    "text": "for years and it's actually nice because it's measuring more low-level stuff um",
    "start": "746430",
    "end": "751490"
  },
  {
    "text": "it does a bunch of system level tests of CPU performance memory performance TV performance and of course IO performance",
    "start": "751490",
    "end": "758280"
  },
  {
    "text": "and you can tell to do specific kinds of i/o I want to do just random reads I want to do just sequential writes that",
    "start": "758280",
    "end": "763830"
  },
  {
    "text": "sort of thing and it is a much more accessible and easy to use tool than a sort of deeper kernel level tool like",
    "start": "763830",
    "end": "771090"
  },
  {
    "text": "fil which are out there but they're hard to learn how to use properly and so I'd",
    "start": "771090",
    "end": "778530"
  },
  {
    "text": "recommend if you're just doing this for yourself use sis bench it's a lot easier to understand the second thing is I'm",
    "start": "778530",
    "end": "785370"
  },
  {
    "text": "using Postgres PG bench this is a tool that ships with Postgres which is a database micro benchmark based on the",
    "start": "785370",
    "end": "791970"
  },
  {
    "text": "TCP benchmark retired archival benchmark",
    "start": "791970",
    "end": "797210"
  },
  {
    "text": "from the transaction processing council and it basically has a very simple",
    "start": "797210",
    "end": "803210"
  },
  {
    "text": "workload of financial transactions that pretty much measures reads and writes so",
    "start": "803210",
    "end": "808880"
  },
  {
    "text": "random transactional reads and writes and plus I can use the database build",
    "start": "808880",
    "end": "815900"
  },
  {
    "text": "process for that which is pretty predictable as a simulation of how you would do on a general extract transform",
    "start": "815900",
    "end": "822680"
  },
  {
    "text": "load in other words loading bulk data into the database and the final thing is",
    "start": "822680",
    "end": "828530"
  },
  {
    "text": "the folks at cockroach TV have produced this workloads package that is a ton of great micro benchmarks that that are",
    "start": "828530",
    "end": "836900"
  },
  {
    "text": "really awesome and very well documented like like I am really thankful to the",
    "start": "836900",
    "end": "843320"
  },
  {
    "text": "the cockroach TV team for putting this together because it's honestly nicer to use than almost anything in the",
    "start": "843320",
    "end": "848510"
  },
  {
    "text": "benchmark and performance space one of them is Bank that's a lot like PG bench and consuming a simple financial transaction benchmark and another one is",
    "start": "848510",
    "end": "855860"
  },
  {
    "text": "a lightweight version of the TPCC transaction processing benchmark that you hear people publishing official",
    "start": "855860",
    "end": "862100"
  },
  {
    "text": "numbers for and this is a more complex workload that often tends to be locked",
    "start": "862100",
    "end": "867770"
  },
  {
    "text": "pound now both of these are right heavy because we're measuring i/o so now there",
    "start": "867770",
    "end": "873680"
  },
  {
    "text": "are some things that you want to do when you are going to do micro benchmarking on your own so one of them is you need",
    "start": "873680",
    "end": "883310"
  },
  {
    "text": "to do more than one run you can't just do one run often random factors the alertness is really aware of will affect",
    "start": "883310",
    "end": "889220"
  },
  {
    "text": "the performance for a single run so you want to do a bunch of different runs you know three runs five runs seven runs so",
    "start": "889220",
    "end": "895010"
  },
  {
    "text": "you don't have to kill yourself but more than one and like average them or throw it outliers or something like that",
    "start": "895010",
    "end": "901360"
  },
  {
    "text": "second is you want to do long runs there's a lot of caching and flushing",
    "start": "901360",
    "end": "907340"
  },
  {
    "text": "the cache behavior and file systems there's caching and flushing they have behavior in databases that takes place",
    "start": "907340",
    "end": "913130"
  },
  {
    "text": "on like a five minute or 10 minute cycle so if you're not running that benchmark for at least twenty thirty minutes an",
    "start": "913130",
    "end": "919490"
  },
  {
    "text": "hour you're not seeing that behavior which would affect your real life or clubs ideal you want to run it with",
    "start": "919490",
    "end": "927020"
  },
  {
    "text": "multiple file and database sizes although I'll explain why I didn't actually do this in the numbers I'm about to present to you you want to have",
    "start": "927020",
    "end": "933410"
  },
  {
    "text": "multiple connections or multiple threads for just straight i/o because in any",
    "start": "933410",
    "end": "939380"
  },
  {
    "text": "cloud you're going to have multiple competing resources and then the last thing is if you can use bare metal to do",
    "start": "939380",
    "end": "947600"
  },
  {
    "text": "your testing and the reason why is if",
    "start": "947600",
    "end": "952640"
  },
  {
    "text": "you are doing testing because a lot of people like well why don't just spin this up on a public cloud right because",
    "start": "952640",
    "end": "957710"
  },
  {
    "text": "I can deploy instances easily I can automate the whole thing right well there's some problems with that one is you get this problem with public cloud",
    "start": "957710",
    "end": "963500"
  },
  {
    "text": "called noisy neighbors right which is one of the most dramatic things that affects the performance is not anything you're doing but what somebody else who",
    "start": "963500",
    "end": "969800"
  },
  {
    "text": "is sharing an instance with you is doing and as a result if you are benchmarking",
    "start": "969800",
    "end": "976460"
  },
  {
    "text": "on public cloud you need to run dozens of benchmark runs and be prepared to throw it outliers in average the rest",
    "start": "976460",
    "end": "982850"
  },
  {
    "text": "and that sort of thing and tear down and spin up new instances in order to get any kind of a reliable result that",
    "start": "982850",
    "end": "989660"
  },
  {
    "text": "actually tells you how your platform is performing the other thing is that on",
    "start": "989660",
    "end": "996050"
  },
  {
    "text": "public cloud you can't actually necessarily do really large size workloads because that starts to get",
    "start": "996050",
    "end": "1001180"
  },
  {
    "text": "really expensive so if you can test on bare metal particularly if you're",
    "start": "1001180",
    "end": "1006370"
  },
  {
    "text": "planning on eventually running on bare metal you need to test on bare map that's why I tested bare matter so let's",
    "start": "1006370",
    "end": "1014890"
  },
  {
    "text": "go ahead and talk about some numbers here so now let me give you some caveats",
    "start": "1014890",
    "end": "1019960"
  },
  {
    "text": "here this involves different tests and different databases and different",
    "start": "1019960",
    "end": "1025689"
  },
  {
    "text": "workloads and these numbers are only comparable for the same test in the same database between different",
    "start": "1025690",
    "end": "1033780"
  },
  {
    "text": "configurations they're not comparable to each other because like for example you're gonna see the bank and the TBC be",
    "start": "1033780",
    "end": "1039579"
  },
  {
    "text": "the the PG bench numbers and these are not comparable between cockroach TV and",
    "start": "1039580",
    "end": "1044589"
  },
  {
    "text": "post quiz because the workloads are actually not the same the databases here",
    "start": "1044589",
    "end": "1050020"
  },
  {
    "text": "are minimally tuned I put in some basic sort of pro forma stuff invites the",
    "start": "1050020",
    "end": "1055900"
  },
  {
    "text": "PostgreSQL project and advise the copper excuse me project they're just some basic things that you",
    "start": "1055900",
    "end": "1060970"
  },
  {
    "text": "for performance but not beyond that the and of course my hardware and my",
    "start": "1060970",
    "end": "1069790"
  },
  {
    "text": "software and the platform I set up in the number of nodes that I have in the configuration are learning different from what you're actually using so these",
    "start": "1069790",
    "end": "1075580"
  },
  {
    "text": "are not your numbers these are examples of numbers that you could derive if you run these if you run tests yourself now",
    "start": "1075580",
    "end": "1083950"
  },
  {
    "start": "1083000",
    "end": "1083000"
  },
  {
    "text": "this is the hardware platform that had available to me this is in Red Hat's open source practice office test lab so",
    "start": "1083950",
    "end": "1091210"
  },
  {
    "text": "got a six blade cluster each of these blades is 20 course 120 gigabytes of RAM",
    "start": "1091210",
    "end": "1096430"
  },
  {
    "text": "to SSDs with 200 gigabytes of space each",
    "start": "1096430",
    "end": "1102150"
  },
  {
    "text": "and a shared network now there's a couple of interesting cabbage that this",
    "start": "1102150",
    "end": "1107800"
  },
  {
    "text": "does to my performance first of all one of the problems that I have is doing",
    "start": "1107800",
    "end": "1114010"
  },
  {
    "text": "tests for databases that are larger than memory which is something you usually want to do in order to force a lot more",
    "start": "1114010",
    "end": "1119710"
  },
  {
    "text": "i/o activity and see how workloads that are larger than memory are going to actually perform in reality the problem",
    "start": "1119710",
    "end": "1125770"
  },
  {
    "text": "is if I only have tuned to gigabytes of storage you have 128 gigabytes of memory it's very hard to arrange that kind of a",
    "start": "1125770",
    "end": "1131740"
  },
  {
    "text": "test so the numbers that I'm going to show you don't include that later on I'm actually get some bigger SSDs and on my",
    "start": "1131740",
    "end": "1137950"
  },
  {
    "text": "blog actually publish a larger than memory test but you won't see that in the numbers coming up for that reason",
    "start": "1137950",
    "end": "1142960"
  },
  {
    "text": "the oh sorry the other thing cheer'd network was supposed to light up here the other thing is there's also a",
    "start": "1142960",
    "end": "1150550"
  },
  {
    "text": "problem with having a shared network which is I'm on the same routers as the rest of the test lab and so we have some",
    "start": "1150550",
    "end": "1155920"
  },
  {
    "text": "of the same noisy neighbor problems and we have you'll see in performance later on some network bottlenecking",
    "start": "1155920",
    "end": "1161380"
  },
  {
    "text": "um that then makes it hard to determine the actual i/o performance because i'm",
    "start": "1161380",
    "end": "1167530"
  },
  {
    "text": "overwhelming the router that's supporting I think 64 blades so so some",
    "start": "1167530",
    "end": "1176110"
  },
  {
    "text": "caveats you always run into this but what happens is because we're smaller than memory we are mostly measuring the",
    "start": "1176110",
    "end": "1184360"
  },
  {
    "text": "eyewear measuring is mostly our ability to sync stuff to disk when we need to that's the i/o we're measuring mostly",
    "start": "1184360",
    "end": "1190600"
  },
  {
    "text": "rather than raw pushing large numbers of blocks to disk because most things are gonna be in",
    "start": "1190600",
    "end": "1196070"
  },
  {
    "text": "cached in memory and we have the shared network problem so now the first one",
    "start": "1196070",
    "end": "1202279"
  },
  {
    "start": "1199000",
    "end": "1199000"
  },
  {
    "text": "here is we're going to do our bare metal test or our hosts file system test really there's a better name for it",
    "start": "1202279",
    "end": "1207769"
  },
  {
    "text": "right which is we're hosts install kubernetes is actually running but we're not using it this gives us a reference",
    "start": "1207769",
    "end": "1214880"
  },
  {
    "text": "numbers to be right this is bare metal and this gives us our reference numbers for what are we comparing to if you care",
    "start": "1214880",
    "end": "1222559"
  },
  {
    "text": "this is in XFS LVM setup for the different volumes and we're just running",
    "start": "1222559",
    "end": "1227659"
  },
  {
    "text": "it that way so first thing we do is cyst bench because that's more sort of your straight IO performance right I'm gonna",
    "start": "1227659",
    "end": "1233450"
  },
  {
    "text": "see what our random reads a random writes are like sequential reads sequential writes so on this hardware",
    "start": "1233450",
    "end": "1240820"
  },
  {
    "text": "random leads per second about ten thousand seven hundred or whatever",
    "start": "1240820",
    "end": "1245830"
  },
  {
    "text": "random writes per second about seven thousand these are reasonably fast SSDs so getting a lot of little random writes",
    "start": "1245830",
    "end": "1254080"
  },
  {
    "text": "because we're pulling mostly from memory because I have this limitation on database size the sequential writes are",
    "start": "1254080",
    "end": "1260600"
  },
  {
    "text": "really fast if you man if you have or code that's much larger than memory you'll see that number drop by an order",
    "start": "1260600",
    "end": "1266690"
  },
  {
    "text": "of magnitude but since we're pulling mostly out of cache we get 22 gigabytes",
    "start": "1266690",
    "end": "1271940"
  },
  {
    "text": "per second and then we've got this 88 megabytes per second write on block writes and that is actually the downside",
    "start": "1271940",
    "end": "1278929"
  },
  {
    "text": "of SSDs which is that effectively all rights are random writes on an SSD and so you don't necessarily get a big bonus",
    "start": "1278929",
    "end": "1286549"
  },
  {
    "text": "for doing sequential writes now more complicated grid now we're going to look",
    "start": "1286549",
    "end": "1292100"
  },
  {
    "text": "at the different database benchmarks here right so we've got PG bench and PG bench has three Mets three main metrics",
    "start": "1292100",
    "end": "1298429"
  },
  {
    "text": "that I'm gonna look at it actually outputs a lot more database load time again simulating doing a load of data",
    "start": "1298429",
    "end": "1304450"
  },
  {
    "text": "transactions per second average latency because again throughput and latency",
    "start": "1304450",
    "end": "1309889"
  },
  {
    "text": "right these are the things we care about throughput and latency and then for the other two workloads we've got throughput",
    "start": "1309889",
    "end": "1315649"
  },
  {
    "text": "in latency right transactions per second what are 95% latency so quartiles are",
    "start": "1315649",
    "end": "1321370"
  },
  {
    "text": "new orders per second which is what you usually measure for TPCC classically in the benchmark so for the",
    "start": "1321370",
    "end": "1329630"
  },
  {
    "text": "hardware so first of all for PG bands who run their load time 404 seconds to",
    "start": "1329630",
    "end": "1335059"
  },
  {
    "text": "load build the indexes everything else we got that as our as our sort of start 11 over 11,000 transactions per second",
    "start": "1335059",
    "end": "1342880"
  },
  {
    "text": "and an average 2.8 millisecond latency so this is our initial sort of benchmark",
    "start": "1342880",
    "end": "1351080"
  },
  {
    "text": "of what we're getting off of the underlying file system with the general idea that we don't really have way as",
    "start": "1351080",
    "end": "1356420"
  },
  {
    "text": "further the cloud native platform to do better than that we're trying to get as close to that as possible now the reason",
    "start": "1356420",
    "end": "1364309"
  },
  {
    "text": "why I don't have any of the cockroach TV stuff is I'm actually never installed cockroach TB off of kubernetes before",
    "start": "1364309",
    "end": "1371950"
  },
  {
    "text": "I've always used I didn't start using it until it was available in kubernetes and the installation process for installing",
    "start": "1371950",
    "end": "1379040"
  },
  {
    "text": "it on top of kubernetes is much better documented than the bare metal installation process and I was getting",
    "start": "1379040",
    "end": "1386090"
  },
  {
    "text": "truly terrible numbers on bare metal which means I was doing something wrong so I might have that later but I'm not",
    "start": "1386090",
    "end": "1394429"
  },
  {
    "text": "gonna have bare metal numbers for cockroach TV for this but is this the in a moment that actually ends up not",
    "start": "1394429",
    "end": "1399620"
  },
  {
    "text": "mattering that much because the next one we're going to do is the local volumes test right and this is where you use",
    "start": "1399620",
    "end": "1405470"
  },
  {
    "text": "host path or local persistent volumes for volumes so I have a directory that",
    "start": "1405470",
    "end": "1410929"
  },
  {
    "text": "exists on every worker node and that directory has been assigned to be a host",
    "start": "1410929",
    "end": "1417320"
  },
  {
    "text": "path volume for kubernetes for this containers that I'm running and basically it's just local storage we're",
    "start": "1417320",
    "end": "1423260"
  },
  {
    "text": "attaching in the actual database or suspend containers a little snippet of",
    "start": "1423260",
    "end": "1429050"
  },
  {
    "text": "my kubernetes setup they're sending a post path is really easy and let me say again this is an option for real world more",
    "start": "1429050",
    "end": "1435350"
  },
  {
    "text": "clothes right but you should definitely look at this depending on what your requirements are for things like",
    "start": "1435350",
    "end": "1442550"
  },
  {
    "text": "databases etc particularly if you can rely on the database platform itself for redundancy so what we see here is that",
    "start": "1442550",
    "end": "1450260"
  },
  {
    "text": "as we would expect local storage performance is almost identical",
    "start": "1450260",
    "end": "1457350"
  },
  {
    "text": "- just doing a nun bear mother the the overhead or negligible number is less",
    "start": "1457350",
    "end": "1463769"
  },
  {
    "text": "than 1% in terms of overhead for the platform and that sort of thing because really we're just going through a couple",
    "start": "1463769",
    "end": "1470009"
  },
  {
    "text": "of layers of namespaces in order to access the same storage we are accessing in the first place and as a result that's almost identical",
    "start": "1470009",
    "end": "1477000"
  },
  {
    "text": "and that means that I can actually get my benchmark numbers for cockroach DB as",
    "start": "1477000",
    "end": "1482759"
  },
  {
    "text": "well as the ones for PG bench right so we've got our basic numbers for cockroach DB here which includes I",
    "start": "1482759",
    "end": "1489980"
  },
  {
    "text": "forty-seven hundred operations per second again the new orders so new orders per minute 1290 and then our",
    "start": "1489980",
    "end": "1497789"
  },
  {
    "text": "latency target numbers the however",
    "start": "1497789",
    "end": "1503870"
  },
  {
    "text": "something going on here so Postgres",
    "start": "1503870",
    "end": "1509039"
  },
  {
    "text": "throughput dropped a bunch and latency jumped in these two are related right higher latency means less throughput",
    "start": "1509039",
    "end": "1515669"
  },
  {
    "text": "because we run out of database client connections and have to wait and that's",
    "start": "1515669",
    "end": "1521370"
  },
  {
    "text": "actually pretty substantial considering that were just once again going through C groups to access our storage so what",
    "start": "1521370",
    "end": "1528149"
  },
  {
    "text": "is going on here and so I did a little bit of this so the thing was I needed to",
    "start": "1528149",
    "end": "1534179"
  },
  {
    "start": "1531000",
    "end": "1531000"
  },
  {
    "text": "run the PG bench client on bare metal because that was how I ran the bare metal benchmark test but earlier when",
    "start": "1534179",
    "end": "1540059"
  },
  {
    "text": "the PG bench client on bare metal that meant that I went through node port to access postcodes itself that as I",
    "start": "1540059",
    "end": "1545909"
  },
  {
    "text": "created a node port service for Postgres in order to access it for PG bench well",
    "start": "1545909",
    "end": "1553799"
  },
  {
    "text": "the thing is this means I have some extra network hops and some extra lookup time and on a workload like PG bench",
    "start": "1553799",
    "end": "1561059"
  },
  {
    "text": "that has a lot of little tiny short database commands that write a single 8k block those network hops and that woke",
    "start": "1561059",
    "end": "1567210"
  },
  {
    "text": "up time actually matter a lot and so we can see that here in terms of that",
    "start": "1567210",
    "end": "1572610"
  },
  {
    "text": "overhead now our next set up that we're",
    "start": "1572610",
    "end": "1579120"
  },
  {
    "start": "1575000",
    "end": "1575000"
  },
  {
    "text": "going to do here is rook storage right this will really care about is our cloud native storage right because the cloud native storage is awesome and so we want",
    "start": "1579120",
    "end": "1585210"
  },
  {
    "text": "to know can we use this as performance on it going to be primitive or is it going to be okay so I set up this far",
    "start": "1585210",
    "end": "1591320"
  },
  {
    "text": "no drug since F cholesterol my worker nodes now because it is a relatively small cluster as far as what SEF can do",
    "start": "1591320",
    "end": "1598010"
  },
  {
    "text": "I only set up one level redundancy so so two copies of every object right did",
    "start": "1598010",
    "end": "1605000"
  },
  {
    "text": "some default tweaks from the documentation for performance and then importantly for people are looking at",
    "start": "1605000",
    "end": "1610670"
  },
  {
    "text": "the cockroach TV setup this is cockroach TV manual install on top of rook storage",
    "start": "1610670",
    "end": "1615890"
  },
  {
    "text": "not the cockroach TV operator which works differently so first let's look at",
    "start": "1615890",
    "end": "1622760"
  },
  {
    "text": "sis bench right here so doing sis penchant for the storage here and this",
    "start": "1622760",
    "end": "1627800"
  },
  {
    "text": "looks pretty darn good so random reads random writes we're getting about",
    "start": "1627800",
    "end": "1634450"
  },
  {
    "text": "one-sixth less than doing it with local volumes attached which actually for my",
    "start": "1634450",
    "end": "1641720"
  },
  {
    "text": "perspective is amazing in terms of relative considering what's F gives you",
    "start": "1641720",
    "end": "1646760"
  },
  {
    "text": "in terms of manageability the and for",
    "start": "1646760",
    "end": "1651890"
  },
  {
    "text": "that matter we're doing you know I",
    "start": "1651890",
    "end": "1657100"
  },
  {
    "text": "random reads are putting much the same pulling it out of sequential reads Aprilia no cache and sequential writes",
    "start": "1657100",
    "end": "1662510"
  },
  {
    "text": "get faster like a lot faster and I'm like what's going on with that and I",
    "start": "1662510",
    "end": "1667850"
  },
  {
    "text": "actually tore it down and I rebuilt it and I reran the tests and I got the same numbers and what was going on well what",
    "start": "1667850",
    "end": "1673160"
  },
  {
    "text": "sis bench does for sequential writes is it does a sequential right thing of a group of random files 48 in the case of",
    "start": "1673160",
    "end": "1680510"
  },
  {
    "text": "my particular choice of workload so 48 files which are all being sequentially written to in parallel on multiple",
    "start": "1680510",
    "end": "1686720"
  },
  {
    "text": "threads well that is a perfect workload for Seth Seth loves that because it can",
    "start": "1686720",
    "end": "1694130"
  },
  {
    "text": "actually farm out the actual i/o to its multiple nodes so I actually got a boost in performance on that so that's what",
    "start": "1694130",
    "end": "1700790"
  },
  {
    "text": "your real-world workload looks like you could actually get better performance off the set then you do off with bare",
    "start": "1700790",
    "end": "1706130"
  },
  {
    "text": "metal however database workloads a little bit different",
    "start": "1706130",
    "end": "1711640"
  },
  {
    "text": "Danny's workloads we get a little bit slower I mean it's actually a lot slower right so we've got an extra third of our",
    "start": "1711640",
    "end": "1719450"
  },
  {
    "text": "time in terms of the bulk load characteristic and then",
    "start": "1719450",
    "end": "1724460"
  },
  {
    "text": "about half of the same throughput on PG bench and the reason why we're getting",
    "start": "1724460",
    "end": "1729960"
  },
  {
    "text": "about half the same throughput is we've about doubled our latency now that extra latency has to do with the network",
    "start": "1729960",
    "end": "1736200"
  },
  {
    "text": "hopping that we're doing for all of these small writes now people have never",
    "start": "1736200",
    "end": "1742140"
  },
  {
    "text": "dealt with distributed storage before might think that this looks bad from my perspective this looks really good I",
    "start": "1742140",
    "end": "1747990"
  },
  {
    "text": "mean because if I set up a safe cloud then I have storage on all of my nodes that I can use with stateful sets and I",
    "start": "1747990",
    "end": "1755280"
  },
  {
    "text": "don't really have to worry about configuring storage in each individual node so the manageability gain is",
    "start": "1755280",
    "end": "1761130"
  },
  {
    "text": "tremendous and this performance compared to earlier generations of distributed",
    "start": "1761130",
    "end": "1766500"
  },
  {
    "text": "storage is actually terrific I'm getting half so the question then becomes in a real-world workload is is it acceptable",
    "start": "1766500",
    "end": "1773220"
  },
  {
    "text": "given your spec right can you afford to double your latency in some cases the",
    "start": "1773220",
    "end": "1778980"
  },
  {
    "text": "answer is yes in some cases the answer is no and we get about the same thing off of the cockroach TB workloads right",
    "start": "1778980",
    "end": "1785669"
  },
  {
    "text": "so the Bank workload about half the throughput about double the latency TB CC about double the latency but the same",
    "start": "1785669",
    "end": "1791910"
  },
  {
    "text": "throughput well what's going on with that well the TB CCD benchmark is like I said can tend to be locked bound and in",
    "start": "1791910",
    "end": "1799620"
  },
  {
    "text": "this case the locking for conflicting transactions completely overshadows any i/o wait time for new orders and as a",
    "start": "1799620",
    "end": "1808380"
  },
  {
    "text": "result the actual number of orders we can process are not different just the latency of those individual",
    "start": "1808380",
    "end": "1813510"
  },
  {
    "text": "orders so continue working on this because I care about performance does it",
    "start": "1813510",
    "end": "1819540"
  },
  {
    "text": "care about hosting databases on cloud native platforms I'm going to be looking at getting access to some bare metal",
    "start": "1819540",
    "end": "1826770"
  },
  {
    "text": "platform with a non shared network so that I can get rid of having Network overhead and network latency obscuring",
    "start": "1826770",
    "end": "1833990"
  },
  {
    "text": "storage performance maybe try experimenting on with different overlay",
    "start": "1833990",
    "end": "1839340"
  },
  {
    "text": "networks this cluster was installed using flannel I might want to see if we've or of calico or if something else",
    "start": "1839340",
    "end": "1845669"
  },
  {
    "text": "actually gives me better performance out of the box like I said adding more disks",
    "start": "1845669",
    "end": "1851390"
  },
  {
    "text": "in order to be able to run other workloads figuring out ways to just",
    "start": "1851390",
    "end": "1856800"
  },
  {
    "text": "the benchmark workload over a cockroach TV better which is the one thing the workload toolkit doesn't really do out",
    "start": "1856800",
    "end": "1863130"
  },
  {
    "text": "of the box and of course Sefton but some conclusions I get working away you'd walk away with here is benchmark",
    "start": "1863130",
    "end": "1870030"
  },
  {
    "start": "1865000",
    "end": "1865000"
  },
  {
    "text": "your own hardware with simple database benchmarks as a way of testing your performance before you for example",
    "start": "1870030",
    "end": "1875820"
  },
  {
    "text": "migrate platforms so that you know what to expect local Viper formance should be equivalent to bare metal rook and Seth",
    "start": "1875820",
    "end": "1883230"
  },
  {
    "text": "has good throughput but about double the latency for random writes and importantly but where secondary issues",
    "start": "1883230",
    "end": "1889920"
  },
  {
    "start": "1887000",
    "end": "1887000"
  },
  {
    "text": "that look like i/o performance differences but aren't finally if you go",
    "start": "1889920",
    "end": "1895440"
  },
  {
    "text": "back and you look at my numbers from the Lightning talk which is on video from CN",
    "start": "1895440",
    "end": "1900570"
  },
  {
    "text": "CF you'll notice comparing the differences here the differences there are much smaller and that is because",
    "start": "1900570",
    "end": "1906030"
  },
  {
    "text": "cloud latency affects mask a lot of performance differences and as a result",
    "start": "1906030",
    "end": "1911040"
  },
  {
    "text": "you don't actually see them on public cloud so I think we have time for one or two questions before everybody runs off",
    "start": "1911040",
    "end": "1917130"
  },
  {
    "text": "for lunch so questions go for it do we have a mic for questions she's got",
    "start": "1917130",
    "end": "1925110"
  },
  {
    "text": "a mic yeah oh I have a mic",
    "start": "1925110",
    "end": "1930470"
  },
  {
    "text": "go ahead and ask your question I'll just repeat it oh I'm gonna need a mic I",
    "start": "1935930",
    "end": "1943280"
  },
  {
    "text": "can't hear you oh here it is got it",
    "start": "1943280",
    "end": "1949720"
  },
  {
    "text": "Hey I was wondering if that was Raiders block device if they did any tuning and",
    "start": "1963879",
    "end": "1969200"
  },
  {
    "text": "if he given safe FS thought or - and what you expect of safe FS I did a",
    "start": "1969200",
    "end": "1975500"
  },
  {
    "text": "minimal amount right I did a minimal amount of tuning I mean part of it was I was depending on rook as an operator and",
    "start": "1975500",
    "end": "1982399"
  },
  {
    "text": "rook doesn't necessarily allow you to change that many settings and so I just",
    "start": "1982399",
    "end": "1987799"
  },
  {
    "text": "did some there were some basic settings on setting cache that are recommended out of the instructions and I did that",
    "start": "1987799",
    "end": "1993740"
  },
  {
    "text": "and that was it so there's probably a lot of opportunities to tune this further",
    "start": "1993740",
    "end": "2000059"
  },
  {
    "text": "two questions one is do you have something published we can copy the",
    "start": "2011960",
    "end": "2018960"
  },
  {
    "text": "actual calls you made so that when we replicate your tests we can little bit",
    "start": "2018960",
    "end": "2025320"
  },
  {
    "text": "see okay this is at least going in the same direction not not yet but I will",
    "start": "2025320",
    "end": "2031460"
  },
  {
    "text": "like within the next couple of weeks after to come I actually ran into a bug",
    "start": "2031460",
    "end": "2038760"
  },
  {
    "text": "on kubernetes in the course of doing these benchmarks which caused me to fall",
    "start": "2038760",
    "end": "2045179"
  },
  {
    "text": "behind in putting all this together in github repo format so watch my Twitter",
    "start": "2045179",
    "end": "2050760"
  },
  {
    "text": "feed I or follow me on github which is",
    "start": "2050760",
    "end": "2056429"
  },
  {
    "text": "also Jay burkas and there will be stuff going up in a couple of weeks that will have recommendations on how to do this",
    "start": "2056429",
    "end": "2061530"
  },
  {
    "text": "on your own with sample commands and can you say something about storage OS o why",
    "start": "2061530",
    "end": "2068730"
  },
  {
    "text": "do you focus on self if storage is is being pushed by Red Hat now I actually",
    "start": "2068730",
    "end": "2074608"
  },
  {
    "text": "have not used storage OS so happy to test that as an option sometime in the",
    "start": "2074609",
    "end": "2081599"
  },
  {
    "text": "future along with some of the other things I'm sure the port works people would like me to test their thing or",
    "start": "2081599",
    "end": "2087898"
  },
  {
    "text": "maybe they wouldn't the but I was starting out with the things I work for Red Hat so I'm gonna start out with Saif",
    "start": "2087899",
    "end": "2095128"
  },
  {
    "text": "and rook because that's what we're invested in but I'm happy to actually",
    "start": "2095129",
    "end": "2100800"
  },
  {
    "text": "look at testing other platforms depending on how hard they are to install high when you're running the the",
    "start": "2100800",
    "end": "2111540"
  },
  {
    "text": "C's bench stuff or or PG bench running it in a potent inside the kubernetes",
    "start": "2111540",
    "end": "2117210"
  },
  {
    "text": "cluster or you're running it from outside of the cluster system what this",
    "start": "2117210",
    "end": "2122730"
  },
  {
    "text": "bench is actually easy because I get it actually so here's here's by the way",
    "start": "2122730",
    "end": "2128400"
  },
  {
    "text": "here's the server cluster the and then I say what's this bench is I can actually",
    "start": "2128400",
    "end": "2135000"
  },
  {
    "text": "run that in the container which means I don't have to worry about Network hops and that's one of the reasons why there",
    "start": "2135000",
    "end": "2141930"
  },
  {
    "text": "was such a minor difference on suspension a much or substantial difference in Postgres is because there were no network hops",
    "start": "2141930",
    "end": "2147300"
  },
  {
    "text": "because I was the container had the storage attached and Ira insisted directly against the storage",
    "start": "2147300",
    "end": "2153270"
  },
  {
    "text": "so did you let's see if I actually still have this bench open no I apparently",
    "start": "2153270",
    "end": "2159780"
  },
  {
    "text": "don't still have a network connection so I can't actually show you that sorry the",
    "start": "2159780",
    "end": "2165200"
  },
  {
    "text": "but yeah but I was running it in the container hey probably confused about",
    "start": "2165200",
    "end": "2170700"
  },
  {
    "text": "one part of your presentation so forgive me for the Cystic and fuchsia so you said you compared to cockroach TB",
    "start": "2170700",
    "end": "2176940"
  },
  {
    "text": "to post grass and cockroach TB he actually has built-in replication and all that and he said at some point they",
    "start": "2176940",
    "end": "2183030"
  },
  {
    "text": "just do two replicas using SAP but cockroach GB can do its own replication",
    "start": "2183030",
    "end": "2188550"
  },
  {
    "text": "so wouldn't it be just much more easier to benchmark cockroach TB just running on local volumes and not against",
    "start": "2188550",
    "end": "2196050"
  },
  {
    "text": "f-number what I did I did pence for a cockroach GB running a local well oh so the self was not involved when you did",
    "start": "2196050",
    "end": "2202140"
  },
  {
    "text": "cockroach TB at all I did both I did cockroach TB in local volumes and then I did cockroach to be running on topple self oh so I did both of them isn't that",
    "start": "2202140",
    "end": "2209160"
  },
  {
    "text": "case when you showed a performance number off like a hundred and fifty percent drop it might be that it is",
    "start": "2209160",
    "end": "2214920"
  },
  {
    "text": "actually doing four replicas instead of three or two oh yeah before we we have double redundancy there right you have",
    "start": "2214920",
    "end": "2220380"
  },
  {
    "text": "cockroach t be replicating everything in you have okay self-replicating everything in like I said my goal here",
    "start": "2220380",
    "end": "2226020"
  },
  {
    "text": "was to test safe okay not to test cockroach TB oh okay make sense suppose grass wasn't only making normal replicas",
    "start": "2226020",
    "end": "2232680"
  },
  {
    "text": "I would write to a local thing and then set for do the replica yeah everything is there I was doing Postgres with",
    "start": "2232680",
    "end": "2237780"
  },
  {
    "text": "replication it would be a synchronous replication okay which would have a negligible effect on performance so I didn't bother setting it up okay that",
    "start": "2237780",
    "end": "2244380"
  },
  {
    "text": "makes sense thank you yep so coming back to running",
    "start": "2244380",
    "end": "2251700"
  },
  {
    "text": "the test inside or outside shouldn't it be possible to run PG bins inside the cluster as well yes here's the problem",
    "start": "2251700",
    "end": "2259260"
  },
  {
    "text": "with that though it actually did be that the problem is you then have limitations on the amount of CPU and memory that PG",
    "start": "2259260",
    "end": "2266220"
  },
  {
    "text": "bench itself can use on the client side which affect your results so I could",
    "start": "2266220",
    "end": "2272490"
  },
  {
    "text": "have done it the other way around where I actually ran PG bench inside kubernetes against bare metal story",
    "start": "2272490",
    "end": "2277859"
  },
  {
    "text": "in order to get a comparable thing but I'm saying whether or not the PG client is inside a kubernetes pod makes",
    "start": "2277859",
    "end": "2285599"
  },
  {
    "text": "a difference in terms of the amount of throughput that client can deliver because you have you know you have to",
    "start": "2285599",
    "end": "2293369"
  },
  {
    "text": "actually put memory and CPU limits on it they're gonna be slightly lower than what's available at a bare-metal machine",
    "start": "2293369",
    "end": "2298770"
  },
  {
    "text": "even if it's like 80 percent of what's available in a bare-metal machine so",
    "start": "2298770",
    "end": "2308780"
  },
  {
    "text": "should there be any performance difference between a host portfolium and a local persistent volume or so they",
    "start": "2308780",
    "end": "2314880"
  },
  {
    "text": "expect it to be the same host volumes and local precision volumes are the same thing where they're different is the",
    "start": "2314880",
    "end": "2322050"
  },
  {
    "text": "management of them in terms of creating and destroying them thanks but but the actual storage attachment mechanism is",
    "start": "2322050",
    "end": "2327570"
  },
  {
    "text": "the same code okay well thank you very much",
    "start": "2327570",
    "end": "2334300"
  },
  {
    "text": "[Applause]",
    "start": "2334300",
    "end": "2338309"
  }
]
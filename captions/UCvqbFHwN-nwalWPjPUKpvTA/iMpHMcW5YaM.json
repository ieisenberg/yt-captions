[
  {
    "text": "all right so hi everybody and my name is",
    "start": "900",
    "end": "6680"
  },
  {
    "text": "[Music] please raise your hand if you use chicken wings",
    "start": "13090",
    "end": "19140"
  },
  {
    "text": "that's great okay now keep your attitude please",
    "start": "19140",
    "end": "25160"
  },
  {
    "text": "wait so I see these two hands came down and you are still alive so",
    "start": "27140",
    "end": "33000"
  },
  {
    "text": "trust me once I always have a feeling that we had enough to do it sooner or",
    "start": "33000",
    "end": "38700"
  },
  {
    "text": "later okay",
    "start": "38700",
    "end": "44899"
  },
  {
    "text": "so just so we're on the same page here gpus are highly optimized for deep",
    "start": "44899",
    "end": "50879"
  },
  {
    "text": "learning processors they can dramatically speed up the computer processes so that's why a lot of people",
    "start": "50879",
    "end": "57180"
  },
  {
    "text": "choose to do their deep learning and AI models on GPS so we want to learn more gpus because we",
    "start": "57180",
    "end": "64320"
  },
  {
    "text": "want to do more AI but gpus are so expensive we can't just keep buying more",
    "start": "64320",
    "end": "71159"
  },
  {
    "text": "and more so that's why we need to try to bring the most out of our existing reviews and",
    "start": "71159",
    "end": "79080"
  },
  {
    "text": "that's a big challenge so in this talk we're going to talk about GP utilization",
    "start": "79080",
    "end": "84540"
  },
  {
    "text": "and how it's often known how we can detect it and we're about to show you",
    "start": "84540",
    "end": "89700"
  },
  {
    "text": "some tools that are built that can help in the situation",
    "start": "89700",
    "end": "95900"
  },
  {
    "text": "thank you so it's true that when you use",
    "start": "97380",
    "end": "104659"
  },
  {
    "text": "only one aspect and the problem is how do efficiently",
    "start": "109100",
    "end": "115020"
  },
  {
    "text": "manage and provision to your business now I know GPU provisioning is not a",
    "start": "115020",
    "end": "121140"
  },
  {
    "text": "term that we use on a daily basis but the truth is",
    "start": "121140",
    "end": "126180"
  },
  {
    "text": "she does that for you and we will see what kubernetes does and also what it",
    "start": "126180",
    "end": "131640"
  },
  {
    "text": "does but first let's try to understand why GP provision is not an easy task then we'll",
    "start": "131640",
    "end": "137700"
  },
  {
    "text": "do this by an example let's say that you are a manager of the",
    "start": "137700",
    "end": "143160"
  },
  {
    "text": "team you'll speak English now this is through both the small things of our",
    "start": "143160",
    "end": "148739"
  },
  {
    "text": "team members and there are large organizations with hundreds of thousands of different communities",
    "start": "148739",
    "end": "154560"
  },
  {
    "text": "important to use so each one of the members has",
    "start": "154560",
    "end": "163260"
  },
  {
    "text": "its own GP all right sorry can I hand you a mic your um attached one doesn't",
    "start": "163260",
    "end": "168660"
  },
  {
    "text": "seem to be working so people can't hit you online thank you so should I go back or just can you hear me now",
    "start": "168660",
    "end": "175080"
  },
  {
    "text": "right all right so let's say we have four team members and we have four gpus",
    "start": "175080",
    "end": "180660"
  },
  {
    "text": "now each of the members has his own GPU and then comes a new member",
    "start": "180660",
    "end": "187080"
  },
  {
    "text": "now you as the manager probably think that you need more gpus",
    "start": "187080",
    "end": "192900"
  },
  {
    "text": "and let's go through all the things that are happening while you're out there on the Journey of getting these more gpus",
    "start": "192900",
    "end": "199260"
  },
  {
    "text": "that you need so first of all you are sure that you're",
    "start": "199260",
    "end": "204300"
  },
  {
    "text": "letting the new member down because you remember the only last minute that you need these gpus",
    "start": "204300",
    "end": "209400"
  },
  {
    "text": "you start fighting the I.T department to get these more gpus even though you already have a few",
    "start": "209400",
    "end": "215340"
  },
  {
    "text": "you have to explain your boss why the new project is being delayed and all",
    "start": "215340",
    "end": "220739"
  },
  {
    "text": "this time the new member is waiting for her GPU resources now trust me this this",
    "start": "220739",
    "end": "226200"
  },
  {
    "text": "is how I look when I wait for my resources and the truth is that you don't always",
    "start": "226200",
    "end": "231959"
  },
  {
    "text": "need more gpus when the new team member comes",
    "start": "231959",
    "end": "237599"
  },
  {
    "text": "instead of getting more gpus you just you um",
    "start": "237599",
    "end": "243480"
  },
  {
    "text": "I'm sorry so the truth is that you don't always need more gpus and we will see",
    "start": "243480",
    "end": "249360"
  },
  {
    "text": "why so first of all not all the tasks",
    "start": "249360",
    "end": "254640"
  },
  {
    "text": "require all the resources that a user gets some tasks are just smaller",
    "start": "254640",
    "end": "262380"
  },
  {
    "text": "now secondly some of the work is being done out of the GPU leaving the GPU unused for",
    "start": "262380",
    "end": "270360"
  },
  {
    "text": "example writing code or building the model also some GPU workloads have heavy CPU",
    "start": "270360",
    "end": "278160"
  },
  {
    "text": "and I O tasks in addition to that people take breaks",
    "start": "278160",
    "end": "284160"
  },
  {
    "text": "now this could be a short 10 minute coffee break lunch or even entire days",
    "start": "284160",
    "end": "289860"
  },
  {
    "text": "off during this time the resources could be unused almost entirely",
    "start": "289860",
    "end": "296220"
  },
  {
    "text": "and generally speaking not all the resources are being properly used",
    "start": "296220",
    "end": "302580"
  },
  {
    "text": "so instead when the new team member comes instead of getting more gpus what you",
    "start": "302580",
    "end": "310500"
  },
  {
    "text": "want is just to use this idle GPU resources now until now I I was talking about a",
    "start": "310500",
    "end": "318120"
  },
  {
    "text": "team of people sharing gpus but this is exactly the same case for a kubernetes",
    "start": "318120",
    "end": "323940"
  },
  {
    "text": "cluster running different AI workloads because very similarly to people",
    "start": "323940",
    "end": "329300"
  },
  {
    "text": "different AI workloads are not identical they have different loads and different",
    "start": "329300",
    "end": "335699"
  },
  {
    "text": "resource consumption now it took us quite some time to fully",
    "start": "335699",
    "end": "342780"
  },
  {
    "text": "understand why it's so hard to to fully utilize a GPU but I think that now we",
    "start": "342780",
    "end": "349080"
  },
  {
    "text": "can say that there are two fundamental reasons for it the first one is that many GPU usage",
    "start": "349080",
    "end": "355740"
  },
  {
    "text": "patterns are under utilized by definition for example when you do",
    "start": "355740",
    "end": "360780"
  },
  {
    "text": "remote debugging with vs code or pycharm when you write code interactively with a",
    "start": "360780",
    "end": "367199"
  },
  {
    "text": "jupyter notebook or just a python shell when you have idle AI workloads just",
    "start": "367199",
    "end": "372600"
  },
  {
    "text": "waiting for new requests and when you have just not so heavy tasks like small",
    "start": "372600",
    "end": "378060"
  },
  {
    "text": "models or small batch sizes the second fundamental reason is that",
    "start": "378060",
    "end": "385199"
  },
  {
    "text": "gpus are being provisioned statically and coarse grained this means that most",
    "start": "385199",
    "end": "390840"
  },
  {
    "text": "of the time you will see a GPU being provisioned for either a user or",
    "start": "390840",
    "end": "397500"
  },
  {
    "text": "an AI workload in order to overcome these challenges",
    "start": "397500",
    "end": "404880"
  },
  {
    "text": "gpus must be provisioned in a smarter way they have to be provisioned dynamically",
    "start": "404880",
    "end": "412080"
  },
  {
    "text": "and this means not a GPU per user or a per single AI workload",
    "start": "412080",
    "end": "418680"
  },
  {
    "text": "additionally they should be provisioned in a finer grain for example fractions of gpus",
    "start": "418680",
    "end": "424979"
  },
  {
    "text": "and they also be over provisioned this means that you should run more workloads",
    "start": "424979",
    "end": "430319"
  },
  {
    "text": "than the available gpus very similarly to other resources like CPU memory and",
    "start": "430319",
    "end": "436199"
  },
  {
    "text": "storage devices now unfortunately for us kubernetes does",
    "start": "436199",
    "end": "441960"
  },
  {
    "text": "not support over provisioning of gpus it also does not support fractional provisioning in gpus but luckily for us",
    "start": "441960",
    "end": "449580"
  },
  {
    "text": "it does provision our gpus in a dynamic way now if you're not using kubernetes just",
    "start": "449580",
    "end": "457440"
  },
  {
    "text": "yet for example if you're running on the host machine directly or over SSH we",
    "start": "457440",
    "end": "463620"
  },
  {
    "text": "created the right tool for you we call it GN and it stands for GPU environment",
    "start": "463620",
    "end": "469440"
  },
  {
    "text": "management it's 100 free and open source",
    "start": "469440",
    "end": "474599"
  },
  {
    "text": "it is highly inspired by existing environment management software like piant conda and others and it works in a",
    "start": "474599",
    "end": "482819"
  },
  {
    "text": "very similar way and it helps people to provision their gpus in a smarter way",
    "start": "482819",
    "end": "489539"
  },
  {
    "text": "now GPU gnf sorry is a terminal based tool just like payan and conda but we",
    "start": "489539",
    "end": "495539"
  },
  {
    "text": "did create integration to Common Ides we have an extension for vs code we have an",
    "start": "495539",
    "end": "501900"
  },
  {
    "text": "extension for Jupiter lab and we are working on creating a plugin for python as well so that every GPU user can use",
    "start": "501900",
    "end": "508919"
  },
  {
    "text": "their gpus in a smarter way natively in his or her working environment",
    "start": "508919",
    "end": "514680"
  },
  {
    "text": "gnf and all these extensions are open source and available on our GitHub page and I recommend you to go check them out",
    "start": "514680",
    "end": "521700"
  },
  {
    "text": "and see if it can be useful for your team now going back to kubernetes",
    "start": "521700",
    "end": "528660"
  },
  {
    "text": "we said that kubernetes does provision gpus in a dynamic way but the problem is",
    "start": "528660",
    "end": "534600"
  },
  {
    "text": "that it does it in a pod granularity this means that most of the time you will see one GPU provisioned for one pod",
    "start": "534600",
    "end": "544680"
  },
  {
    "text": "and when this spot gets scheduled a GPU is assigned to it and as long as the Pod",
    "start": "544680",
    "end": "551399"
  },
  {
    "text": "is alive this GPU cannot be reassigned to other pods even if the GPU is idle",
    "start": "551399",
    "end": "557880"
  },
  {
    "text": "and not used because any of the reasons that we saw earlier",
    "start": "557880",
    "end": "563060"
  },
  {
    "text": "now this must be changed if we want to fully utilize gpus",
    "start": "563100",
    "end": "569880"
  },
  {
    "text": "furthermore even with the smartest provisioning mechanism",
    "start": "569880",
    "end": "574980"
  },
  {
    "text": "the provisioning smart provisioning is not enough because GPU resources should not be an",
    "start": "574980",
    "end": "581640"
  },
  {
    "text": "afterthought the point in time in which we deploy an AI workload to production cannot be the",
    "start": "581640",
    "end": "588480"
  },
  {
    "text": "first time that we ask ourselves how much how many GPU resources do we need",
    "start": "588480",
    "end": "594360"
  },
  {
    "text": "the GPU resource requirements should be properly defined in the development",
    "start": "594360",
    "end": "599580"
  },
  {
    "text": "phase of the project just like any other project dependency for example python",
    "start": "599580",
    "end": "604620"
  },
  {
    "text": "packages or a docker-based image and I truly believe that they should be",
    "start": "604620",
    "end": "610080"
  },
  {
    "text": "specified in as infrastructure as code now if you use GN for your project it",
    "start": "610080",
    "end": "616980"
  },
  {
    "text": "allows you to save the research requirements as code as part of your git Repository",
    "start": "616980",
    "end": "624379"
  },
  {
    "text": "okay so the truth is that there is no magic button for these problems we have",
    "start": "625140",
    "end": "632040"
  },
  {
    "text": "to change our mindset and now after we have a better understanding of it I'm",
    "start": "632040",
    "end": "637140"
  },
  {
    "text": "going to pass it to Natasha and she will continue with the second part",
    "start": "637140",
    "end": "641899"
  },
  {
    "text": "thank you okay so now that we understand the problem our responsibilities and the",
    "start": "643220",
    "end": "651180"
  },
  {
    "text": "power we have in our hands but where does it take us what can we actually do about it",
    "start": "651180",
    "end": "657899"
  },
  {
    "text": "well you cannot improve what you don't do so the first thing we need to do is to get a better View and to better",
    "start": "657899",
    "end": "664620"
  },
  {
    "text": "understand that your utilization in our classroom so we want to know if we have",
    "start": "664620",
    "end": "669720"
  },
  {
    "text": "some item gpus see if they have pending workers so let's drill down and see are you",
    "start": "669720",
    "end": "676440"
  },
  {
    "text": "really confused now going back to the case of AI",
    "start": "676440",
    "end": "682200"
  },
  {
    "text": "workloads in a kubernetes club station we know that different workloads have different lows and different resource",
    "start": "682200",
    "end": "688440"
  },
  {
    "text": "consumption but how can we actually measure it in reality you guessed right it's GP utilization so",
    "start": "688440",
    "end": "696420"
  },
  {
    "text": "this is the official definition of GPU transactions but the factor just means how much the GPA will be used",
    "start": "696420",
    "end": "703980"
  },
  {
    "text": "so the utilization is low or even zero it means the GPU is not being fully used",
    "start": "703980",
    "end": "711959"
  },
  {
    "text": "so um in order to detect low utilization in a",
    "start": "711959",
    "end": "717660"
  },
  {
    "text": "cluster we want to detect the organizations let's see how we can do this so I'll",
    "start": "717660",
    "end": "723959"
  },
  {
    "text": "just say this if you have a cluster we could use but you have not installed",
    "start": "723959",
    "end": "729420"
  },
  {
    "text": "for brunettes yet and you're considering it you can use iron drop with surrounding eyes open source top like",
    "start": "729420",
    "end": "735240"
  },
  {
    "text": "toe or monitoring details and cluster over SSH we don't have time to look at",
    "start": "735240",
    "end": "740760"
  },
  {
    "text": "it today but it's really cool so you can take over but for our test is now we do have the",
    "start": "740760",
    "end": "747300"
  },
  {
    "text": "brilliant question so let's say we have two loans for gpus each eight children now let's get a better look of what's",
    "start": "747300",
    "end": "754920"
  },
  {
    "text": "going on on those tubules so this is the dashboard we built",
    "start": "754920",
    "end": "760019"
  },
  {
    "text": "uh we're going to go over everything here in just a few minutes but what is",
    "start": "760019",
    "end": "765720"
  },
  {
    "text": "the first thing that I want you to notice so we have eight allocated gpus out of eight total right now",
    "start": "765720",
    "end": "772380"
  },
  {
    "text": "and what do we see on the right the problem we said before we have a",
    "start": "772380",
    "end": "779100"
  },
  {
    "text": "problem now we can actually see it we have two pending pods that request the GPU and are not allocated due to lack of",
    "start": "779100",
    "end": "786600"
  },
  {
    "text": "resources but at the same time we have two gpus that are allocated by costs that are not using them",
    "start": "786600",
    "end": "793320"
  },
  {
    "text": "and they're either so this is a big problem now I want us to go a little bit",
    "start": "793320",
    "end": "798720"
  },
  {
    "text": "to that and I'm going to I'm going to explain how I built the such position and then we'll go back",
    "start": "798720",
    "end": "805620"
  },
  {
    "text": "so to identify an objectives we need to know the GP utilization of each review",
    "start": "805620",
    "end": "811160"
  },
  {
    "text": "at a certain moment so if the GP utilization is zero and there is a",
    "start": "811160",
    "end": "816600"
  },
  {
    "text": "running part on the GPU it will be identity and probably one of the most expensive",
    "start": "816600",
    "end": "823139"
  },
  {
    "text": "gpus you have in the cluster you're paying for it and you can't even use it so we need some sort of component to",
    "start": "823139",
    "end": "830160"
  },
  {
    "text": "export this database luckily for us we have open source schools that can help us with this so we",
    "start": "830160",
    "end": "836820"
  },
  {
    "text": "have in the videos this is James Porter it's a demon set that exports metrics about gpus on the loop if you are",
    "start": "836820",
    "end": "844019"
  },
  {
    "text": "working with gpus and kubernetes you probably already have it installed as part of nvidia's GPU operators",
    "start": "844019",
    "end": "850200"
  },
  {
    "text": "we also have videos which ensure you've all heard that and it's a monitoring system that collects and stories of",
    "start": "850200",
    "end": "855959"
  },
  {
    "text": "metrics we also have grafana that comes both in with Prometheus and it allows to",
    "start": "855959",
    "end": "862139"
  },
  {
    "text": "build the dashboards like the one we said earlier so they're all easy to install and easy to use they're a pretty",
    "start": "862139",
    "end": "869040"
  },
  {
    "text": "UI and everything I installed them on my kubernetes cluster and I opened the produced now take a",
    "start": "869040",
    "end": "877079"
  },
  {
    "text": "deep breath we're going to Deep dive into some technology for a few minutes so this is a screenshot from Prometheus",
    "start": "877079",
    "end": "883019"
  },
  {
    "text": "C1 just raw metrics without the font this is the metric we are interested in",
    "start": "883019",
    "end": "888720"
  },
  {
    "text": "dcgmfid comes from the dcgm exporter each record",
    "start": "888720",
    "end": "894600"
  },
  {
    "text": "here stands for a different GPU and the value of digitization is a percentage so",
    "start": "894600",
    "end": "900180"
  },
  {
    "text": "the value will be between 0 and 100. and the labels of the Matrix give us",
    "start": "900180",
    "end": "906180"
  },
  {
    "text": "more information about each debut so we're able to identify them so for example we have the kubernetes node of",
    "start": "906180",
    "end": "912420"
  },
  {
    "text": "the GPU we also have its uuad and GPU index on",
    "start": "912420",
    "end": "917820"
  },
  {
    "text": "the on the Node and there's a spot running on the GPU we'll have the code name and namespace",
    "start": "917820",
    "end": "925199"
  },
  {
    "text": "and if there's no hard running overview those needles will just be equal now out of all the records here we are",
    "start": "925199",
    "end": "933660"
  },
  {
    "text": "interested in the ones that actually had a problem so we can use chrome2l which is",
    "start": "933660",
    "end": "938880"
  },
  {
    "text": "Prometheus query language to perform some queries only the metrics so this is",
    "start": "938880",
    "end": "944040"
  },
  {
    "text": "how to filter on the inside results see if we use a non-empty called label and those records here stand for the gpus",
    "start": "944040",
    "end": "951720"
  },
  {
    "text": "with a pod run instrument and also we would like to filter on the",
    "start": "951720",
    "end": "957420"
  },
  {
    "text": "ideal allocated so we want the utilization to be zero which means the Matrix value equals zero",
    "start": "957420",
    "end": "963779"
  },
  {
    "text": "so this is also from ql and there you have it those are the",
    "start": "963779",
    "end": "969899"
  },
  {
    "text": "either allocated gpus they have pod running on them and visualization is zero",
    "start": "969899",
    "end": "975000"
  },
  {
    "text": "so I used some more Chrome ql to aggregate all this data on this metric",
    "start": "975000",
    "end": "981420"
  },
  {
    "text": "and other metrics as well and then I put it in this grafana dashboard it's also",
    "start": "981420",
    "end": "987959"
  },
  {
    "text": "open source of course you can take a look at it later you see if the previous queries layers and how I put it in",
    "start": "987959",
    "end": "993480"
  },
  {
    "text": "rafana so now that we understand where this data is coming from",
    "start": "993480",
    "end": "999600"
  },
  {
    "text": "we can analyze what we see so here we have the amount of item",
    "start": "999600",
    "end": "1005660"
  },
  {
    "text": "allocated to use and below deposites that are running on those GPS",
    "start": "1005660",
    "end": "1011420"
  },
  {
    "text": "and here we have the pending defending positive requested GPU so we can also know how many gpus each photo is",
    "start": "1011420",
    "end": "1018680"
  },
  {
    "text": "requesting for his item now if each user or team believes a",
    "start": "1018680",
    "end": "1024678"
  },
  {
    "text": "different name space which is a good next practice uh yeah um then we would know the owner of those",
    "start": "1024679",
    "end": "1031459"
  },
  {
    "text": "Idol GPU bugs and we can kindly contact them and ask them to delete the reports",
    "start": "1031459",
    "end": "1037520"
  },
  {
    "text": "or maybe delete them by ourselves if we have the permissions for it and we can also know the owners the the users",
    "start": "1037520",
    "end": "1045918"
  },
  {
    "text": "submitted attending costs so we may know who's going to be angry with us but",
    "start": "1045919",
    "end": "1050960"
  },
  {
    "text": "they're not running on reports that we want to be executed",
    "start": "1050960",
    "end": "1055780"
  },
  {
    "text": "now I wanted to look at a slightly different case here the cluster is not full we have six gpus out here and a",
    "start": "1056000",
    "end": "1062780"
  },
  {
    "text": "store now some organizations might not even know this information that they have",
    "start": "1062780",
    "end": "1068600"
  },
  {
    "text": "available gpus they're not idle allocated because there's no quad running on them they're just available",
    "start": "1068600",
    "end": "1074799"
  },
  {
    "text": "so it's an easier problem and I know it sounds funny but you should just execute",
    "start": "1074799",
    "end": "1080660"
  },
  {
    "text": "more workloads use your availability gpus to pay good money for a number",
    "start": "1080660",
    "end": "1086500"
  },
  {
    "text": "these graphs give us a good visualization of the GPU utilization so here we have the GP utilization over",
    "start": "1087320",
    "end": "1094039"
  },
  {
    "text": "time each line stands for different GPU and you can adjust that time spent on",
    "start": "1094039",
    "end": "1100280"
  },
  {
    "text": "top of the good hand page and so it could be like the last five minutes or the last 24 hours whatever",
    "start": "1100280",
    "end": "1106160"
  },
  {
    "text": "you want also we have the average review utilization out of all gpus in the",
    "start": "1106160",
    "end": "1112220"
  },
  {
    "text": "cluster and we have their running deposit allocate the GPU for this digitalization",
    "start": "1112220",
    "end": "1119799"
  },
  {
    "text": "so now that we have all this data we understand the GP utilization you can see it and visualize it",
    "start": "1120200",
    "end": "1126799"
  },
  {
    "text": "what can we actually do about this well the first thing is the thing and we",
    "start": "1126799",
    "end": "1133700"
  },
  {
    "text": "said that already we can delete the audio GPU box so either the user or the admin can do that if it both have access",
    "start": "1133700",
    "end": "1139760"
  },
  {
    "text": "to the dashboard another thing we can try to do is to avoid the ideologicals in the first",
    "start": "1139760",
    "end": "1146059"
  },
  {
    "text": "place so for example when you run acrosses inside a Jupiter Road and you press that Little Rock button",
    "start": "1146059",
    "end": "1152780"
  },
  {
    "text": "and then the process finishes and the notebook stays open and allocates an energy View",
    "start": "1152780",
    "end": "1158600"
  },
  {
    "text": "so instead you can finish working on your model inside when you want to execute it long term",
    "start": "1158600",
    "end": "1165500"
  },
  {
    "text": "you can run it as a previous job in that way when the process inside finishes the",
    "start": "1165500",
    "end": "1170900"
  },
  {
    "text": "Pod and the job will terminate and the GPU will be available for other ones in that way depending problems so",
    "start": "1170900",
    "end": "1178400"
  },
  {
    "text": "earlier for example can start running and this is our goal",
    "start": "1178400",
    "end": "1183279"
  },
  {
    "text": "so let's summarize we understood the problem and presented some easy steps we",
    "start": "1183799",
    "end": "1189320"
  },
  {
    "text": "can do to improve the situation but it takes more you need to look",
    "start": "1189320",
    "end": "1194419"
  },
  {
    "text": "behind the scenes maybe think of a better work process one that suits you in your organization we have all this",
    "start": "1194419",
    "end": "1201200"
  },
  {
    "text": "data presented in the dashboard um that can help you get a better understanding of the degree utilization",
    "start": "1201200",
    "end": "1207799"
  },
  {
    "text": "so you can use the dashboard deployment change it add more information to it adapt it to your needs maybe use grafana",
    "start": "1207799",
    "end": "1215120"
  },
  {
    "text": "alerts the power is in your hands only after we do all that you can",
    "start": "1215120",
    "end": "1221120"
  },
  {
    "text": "continue to do the next steps which is for example smart provisioning smart scheduling",
    "start": "1221120",
    "end": "1226700"
  },
  {
    "text": "increasing digitalization of existing models but we don't have time to talk about it today",
    "start": "1226700",
    "end": "1233740"
  },
  {
    "text": "yeah so thank you everybody for joining us today as we said during the",
    "start": "1237380",
    "end": "1242960"
  },
  {
    "text": "presentation everything we mentioned every tool is open source and available on our GitHub page",
    "start": "1242960",
    "end": "1248660"
  },
  {
    "text": "and we'd love to hear more from you about the way that you use gpus and the",
    "start": "1248660",
    "end": "1253940"
  },
  {
    "text": "problems that you encounter so here are our email addresses feel free to contact us we will also be at the Run AI Booth",
    "start": "1253940",
    "end": "1262880"
  },
  {
    "text": "booth number S63 so just walk by in the next couple of days and we'd like to",
    "start": "1262880",
    "end": "1270080"
  },
  {
    "text": "hear from you thank you [Applause]",
    "start": "1270080",
    "end": "1277760"
  },
  {
    "text": "brilliant um thank you Raz and Natasha excellent talk um yeah I'll open up to questions",
    "start": "1277760",
    "end": "1284120"
  },
  {
    "text": "um okay oh there are loads oh that's this I was actually going to ask one but I better better let the audience do them first when you go first",
    "start": "1284120",
    "end": "1291860"
  },
  {
    "text": "um I just had a question about it strikes me that if you're going to do it dynamically you may you may need to",
    "start": "1291860",
    "end": "1298940"
  },
  {
    "text": "know the length of time somebody's going to use the Pod um in order to so that you're not",
    "start": "1298940",
    "end": "1305840"
  },
  {
    "text": "switching them right or if if it's idle and then the person who owns it the way you've described it is very like you",
    "start": "1305840",
    "end": "1311179"
  },
  {
    "text": "take it back so now that first person no longer has access to a GPU just wondering if you could elaborate on that",
    "start": "1311179",
    "end": "1317840"
  },
  {
    "text": "yeah so that's a great question yeah",
    "start": "1317840",
    "end": "1321940"
  },
  {
    "text": "models have some idle time then they go back to being not idle but if you see like um a pod being idle for a day for a",
    "start": "1328659",
    "end": "1336080"
  },
  {
    "text": "long time and you maybe you don't have to know that this person went on vacation you just see its Idol on the dashboard then",
    "start": "1336080",
    "end": "1343580"
  },
  {
    "text": "you can delete it and yeah the person will lose access to the GPU but well they shouldn't in the first place",
    "start": "1343580",
    "end": "1350120"
  },
  {
    "text": "execute workloads that have idle gpus for 24 hours so it's like our our",
    "start": "1350120",
    "end": "1355520"
  },
  {
    "text": "approach is like their problem if I if I may add so",
    "start": "1355520",
    "end": "1361580"
  },
  {
    "text": "um what you suggested is a is a great idea it's a bit too simple and naive I",
    "start": "1361580",
    "end": "1366799"
  },
  {
    "text": "mean it would be beneficial you can specify the amount of time that you think that a pod is going to run so that",
    "start": "1366799",
    "end": "1372620"
  },
  {
    "text": "the orchestration system as a hint to the orchestration system but this is too",
    "start": "1372620",
    "end": "1378740"
  },
  {
    "text": "simple when you talk about big big clusters with many different AI workloads so what you would want to have",
    "start": "1378740",
    "end": "1385220"
  },
  {
    "text": "is a system that would automatically detect idle resources and idle pods and",
    "start": "1385220",
    "end": "1392659"
  },
  {
    "text": "we'll take these resources and bring them automatically to other pods so this",
    "start": "1392659",
    "end": "1398360"
  },
  {
    "text": "would be a great idea but it's too naive I'm sorry it might be too naive and",
    "start": "1398360",
    "end": "1403640"
  },
  {
    "text": "we're looking for more advanced ways to even improve it without specifying",
    "start": "1403640",
    "end": "1409400"
  },
  {
    "text": "hints priorly",
    "start": "1409400",
    "end": "1412780"
  },
  {
    "text": "One Challenge we've had with using the dcgm metrics is that utilization is",
    "start": "1416360",
    "end": "1422059"
  },
  {
    "text": "actually defined as if you've done one Cuda operation in the last one second so you could do a Cuda mem copy and you get",
    "start": "1422059",
    "end": "1429320"
  },
  {
    "text": "utilization I'm kind of curious if you've been able to develop anything else deeper to",
    "start": "1429320",
    "end": "1435080"
  },
  {
    "text": "actually understand how many Cuda cores are really left and like how much you",
    "start": "1435080",
    "end": "1440179"
  },
  {
    "text": "can push the GPU more yeah so that's a great question because",
    "start": "1440179",
    "end": "1446000"
  },
  {
    "text": "the GPU utilization might be misleading because as you said it might",
    "start": "1446000",
    "end": "1451820"
  },
  {
    "text": "be also too naive because if you do something very small on the GPU every",
    "start": "1451820",
    "end": "1457400"
  },
  {
    "text": "sampling window then it might seem that you have high GPU utilization now this is an inherited problem with looking at",
    "start": "1457400",
    "end": "1465200"
  },
  {
    "text": "GP utilization uh there might be other metrics that could be",
    "start": "1465200",
    "end": "1471340"
  },
  {
    "text": "created for example to understand the size of the Cuda calls that are running",
    "start": "1471340",
    "end": "1476919"
  },
  {
    "text": "and there are Technologies of Nvidia for example MPS that allows you to have a",
    "start": "1476919",
    "end": "1483080"
  },
  {
    "text": "bit more understanding about them and you have also profiling tools from Nvidia that will help you to further",
    "start": "1483080",
    "end": "1491480"
  },
  {
    "text": "understand how much you actually do use your GPU now GPU utilization is just a",
    "start": "1491480",
    "end": "1497179"
  },
  {
    "text": "very basic metric but it gives you at least 80 percent into the direction that",
    "start": "1497179",
    "end": "1502280"
  },
  {
    "text": "you're heading cool so I'm curious what you see as the uh",
    "start": "1502280",
    "end": "1512240"
  },
  {
    "text": "the future of the road map of time slicing or context switching of gpus",
    "start": "1512240",
    "end": "1518240"
  },
  {
    "text": "that does seem like the Holy Grail I'm a system operator not an a data",
    "start": "1518240",
    "end": "1523520"
  },
  {
    "text": "engineer so you know what I see as a system operator is well why aren't we",
    "start": "1523520",
    "end": "1528980"
  },
  {
    "text": "treating our gpus like CPUs with multi-threading and time slicing and stuff and what do you guys see as the",
    "start": "1528980",
    "end": "1535100"
  },
  {
    "text": "the future of this this like around the corner is it decades away like where is the technology going",
    "start": "1535100",
    "end": "1540500"
  },
  {
    "text": "okay so this is another great question so yeah I think the way we see it is that we believe that we can have a",
    "start": "1540500",
    "end": "1547820"
  },
  {
    "text": "system that automatically detects the idleness and the resource consumption in real time and then just",
    "start": "1547820",
    "end": "1555679"
  },
  {
    "text": "like any other more mature resources for example CPU cores or CPU memory that",
    "start": "1555679",
    "end": "1561740"
  },
  {
    "text": "they've been here for decades just like that we can develop technology that",
    "start": "1561740",
    "end": "1567200"
  },
  {
    "text": "would treat GPU resources in a very similar way in which you just submit",
    "start": "1567200",
    "end": "1573200"
  },
  {
    "text": "your workloads and the system underneath realize understands in real time how",
    "start": "1573200",
    "end": "1579559"
  },
  {
    "text": "much resources every workload needs and if a workload can give it up temporarily",
    "start": "1579559",
    "end": "1585440"
  },
  {
    "text": "if it gives up gives it up intentionally so for this temporary period of time we",
    "start": "1585440",
    "end": "1593120"
  },
  {
    "text": "can give these resources to another workload so yeah this is the Holy Grail",
    "start": "1593120",
    "end": "1598940"
  },
  {
    "text": "and the Holy Grail is to make gpus very similar to CPUs because nowadays when",
    "start": "1598940",
    "end": "1605059"
  },
  {
    "text": "you submit CPU workloads you don't really care about what core what CPU",
    "start": "1605059",
    "end": "1610220"
  },
  {
    "text": "core is going to run on the operating system does it for you so we believe that you can achieve the exact same",
    "start": "1610220",
    "end": "1616220"
  },
  {
    "text": "thing for gpus and no it's not decades away it's it's here and it's going it's going to",
    "start": "1616220",
    "end": "1622100"
  },
  {
    "text": "happen real soon I believe it",
    "start": "1622100",
    "end": "1625960"
  },
  {
    "text": "um so earlier you had described a little bit about looking at like batch workloads and jobs in order to be able",
    "start": "1627740",
    "end": "1633140"
  },
  {
    "text": "to kind of relieve the pressure on the gpus is the primary spot that you're looking for to try and relieve this GPU",
    "start": "1633140",
    "end": "1638900"
  },
  {
    "text": "pressure like looking at being able how do we move some of what we would know what that we might do interactively to",
    "start": "1638900",
    "end": "1645260"
  },
  {
    "text": "job-based things or like what does that Continuum look like I'm sorry I'm not sure I understand the",
    "start": "1645260",
    "end": "1651620"
  },
  {
    "text": "question um",
    "start": "1651620",
    "end": "1655120"
  },
  {
    "text": "[Music] if you're debugging or building a model and then you you finished it and you",
    "start": "1660240",
    "end": "1666559"
  },
  {
    "text": "want to train it for a long um a long time that's where it's better",
    "start": "1666559",
    "end": "1671720"
  },
  {
    "text": "that you switch to a job and not a notebook because when I describe it does",
    "start": "1671720",
    "end": "1677720"
  },
  {
    "text": "that answer your question I think that's part of it because like so so like even during that debugging cycle like so I",
    "start": "1677720",
    "end": "1683539"
  },
  {
    "text": "have a data scientist working for eight hours a day they take that break but they're still interactively looking at",
    "start": "1683539",
    "end": "1688760"
  },
  {
    "text": "that that is a to me like even as you described in the presentation that's a period of time that like they went for",
    "start": "1688760",
    "end": "1694820"
  },
  {
    "text": "lunch for an hour and a half I could use that GPU somewhere else but because it's nominally interactive job that's still",
    "start": "1694820",
    "end": "1701360"
  },
  {
    "text": "holding that GPU yeah can relate to that so this is this is a really great question so yeah here",
    "start": "1701360",
    "end": "1708559"
  },
  {
    "text": "we presented some basic stuff that people can do nowadays but if we're talking into more advanced stuff then",
    "start": "1708559",
    "end": "1715039"
  },
  {
    "text": "your your point is is really correct because we believe that we that you can",
    "start": "1715039",
    "end": "1722240"
  },
  {
    "text": "have a system that detects this GPU idleness and when you decouple this CPU",
    "start": "1722240",
    "end": "1727940"
  },
  {
    "text": "resources from GPU resources then you can leave the jupyter notebook running the user can still use the GPU notebook",
    "start": "1727940",
    "end": "1735679"
  },
  {
    "text": "for visualizing the data for writing code interactively but as long as nothing is running on the GPU our system",
    "start": "1735679",
    "end": "1742700"
  },
  {
    "text": "underneath can take the GPU resources to another pod that is that is sharing in a",
    "start": "1742700",
    "end": "1749720"
  },
  {
    "text": "controlled Way by this system and it's sharing the GPU resources so you do I",
    "start": "1749720",
    "end": "1755240"
  },
  {
    "text": "mean like the Holy Grail is that you will not have to stop your job entirely you just you'll just have a system that",
    "start": "1755240",
    "end": "1762559"
  },
  {
    "text": "manages it underneath does that answer all right",
    "start": "1762559",
    "end": "1769299"
  },
  {
    "text": "uh did you get a chance to compare schedulers like misos versus kubernetes",
    "start": "1769299",
    "end": "1775279"
  },
  {
    "text": "so uh some misos has a good scheduler called dominant resource",
    "start": "1775279",
    "end": "1781700"
  },
  {
    "text": "fairness and it has a it has a pretty good uh very decent creating algorithm and you get a chance to compare and so",
    "start": "1781700",
    "end": "1788779"
  },
  {
    "text": "that we can you can see how which is a better scheduler for resources like GPU",
    "start": "1788779",
    "end": "1797200"
  },
  {
    "text": "all right so uh yeah we believe that we understand AI",
    "start": "1797200",
    "end": "1803840"
  },
  {
    "text": "workloads in a in a very intimate way because we go through all the stack we",
    "start": "1803840",
    "end": "1809539"
  },
  {
    "text": "go through the kubernetes layer and the Linux layer and the GPU the Cuda layers themselves as well as the applications",
    "start": "1809539",
    "end": "1816980"
  },
  {
    "text": "and Frameworks like tensorflow and pytorch so we believe that we can create a kubernetes scheduler that is fully",
    "start": "1816980",
    "end": "1824360"
  },
  {
    "text": "dedicated to Ai workloads and we believe we believe that we can build the",
    "start": "1824360",
    "end": "1830659"
  },
  {
    "text": "software that is needed in all these layers instead of relying on others to",
    "start": "1830659",
    "end": "1835820"
  },
  {
    "text": "implement them for us so I'm not familiar specifically with the scheduler that you mentioned but",
    "start": "1835820",
    "end": "1842659"
  },
  {
    "text": "internally we do have a lot of thoughts around existing schedulers and we do we",
    "start": "1842659",
    "end": "1848659"
  },
  {
    "text": "do have our distinguishment between them and I'm sure you can we can talk about it later cool",
    "start": "1848659",
    "end": "1854480"
  },
  {
    "text": "um time for one more question if anyone has one I haven't already oh sorry yeah yeah there we go",
    "start": "1854480",
    "end": "1863020"
  },
  {
    "text": "have you found that the provisioning and metrics differ by workload type you know",
    "start": "1865100",
    "end": "1870260"
  },
  {
    "text": "a lot of what you've explained is really good for like batch processing but you might have inference workloads on the",
    "start": "1870260",
    "end": "1875899"
  },
  {
    "text": "same cluster that want to hold on to a GPU longer and that might be you know appropriate for for that type of",
    "start": "1875899",
    "end": "1882860"
  },
  {
    "text": "workload yeah exactly I mean there are many types of workloads for example interactively",
    "start": "1882860",
    "end": "1890419"
  },
  {
    "text": "building a model training the model in inference servers as well and inference servers can be idle as well because they",
    "start": "1890419",
    "end": "1897440"
  },
  {
    "text": "are waiting for new requests to arrive so we can detect it and while until",
    "start": "1897440",
    "end": "1903260"
  },
  {
    "text": "these requests arrive you can take these GPU resources to another workload so",
    "start": "1903260",
    "end": "1908360"
  },
  {
    "text": "this is this is true also for inference clusters as well",
    "start": "1908360",
    "end": "1913659"
  },
  {
    "text": "great um well yeah thank you again let's have another round of applause for us and",
    "start": "1914899",
    "end": "1920419"
  },
  {
    "text": "Natasha [Applause]",
    "start": "1920419",
    "end": "1926529"
  }
]
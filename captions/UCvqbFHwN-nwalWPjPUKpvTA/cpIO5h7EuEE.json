[
  {
    "start": "0",
    "end": "37000"
  },
  {
    "text": "good morning I am Jason de Tavares and I am the track host for the performance",
    "start": "60",
    "end": "5069"
  },
  {
    "text": "track this morning please make sure that you go back to sketch calm and rate this",
    "start": "5069",
    "end": "14160"
  },
  {
    "text": "talk at the end of it our speaker today is the lead of the",
    "start": "14160",
    "end": "21180"
  },
  {
    "text": "platform as a service team at box and he's going to tell us about how they implemented an SLA for the platform",
    "start": "21180",
    "end": "28130"
  },
  {
    "text": "please welcome Shrek didya hey guys so when I'm in Sonic I've",
    "start": "28130",
    "end": "39690"
  },
  {
    "text": "been in a box for about two years and a couple of months now and before box I used to be at Apple I like to I like to",
    "start": "39690",
    "end": "45210"
  },
  {
    "text": "talk to you guys about why we thought of and how we implemented an SLA for our",
    "start": "45210",
    "end": "50760"
  },
  {
    "text": "platform o things that are things I'd",
    "start": "50760",
    "end": "56250"
  },
  {
    "start": "52000",
    "end": "72000"
  },
  {
    "text": "like to go over today our waters of kubernetes look like a box what's the",
    "start": "56250",
    "end": "61350"
  },
  {
    "text": "problem that we had water solutions we looked at what principles we use to kind of navigate our way and and finally what",
    "start": "61350",
    "end": "69299"
  },
  {
    "text": "kind of kind of solution we picked this slide will give you a quick brief",
    "start": "69299",
    "end": "74430"
  },
  {
    "start": "72000",
    "end": "159000"
  },
  {
    "text": "history of time off of kubernetes at box as you guys know kubernetes of key aid I",
    "start": "74430",
    "end": "81390"
  },
  {
    "text": "think originally like mid kind of 2015 we we picked it up right away and we and",
    "start": "81390",
    "end": "89369"
  },
  {
    "text": "we implement our platform on top of it and we actually g8 our platform internally and are made of 2016 we call",
    "start": "89369",
    "end": "97500"
  },
  {
    "text": "our platform sky net which is a reference to terminator we wanted a platform to become self-aware at some",
    "start": "97500",
    "end": "103290"
  },
  {
    "text": "point and through the years we've kind of scaled ourselves to kind of where we",
    "start": "103290",
    "end": "110250"
  },
  {
    "text": "are today we run about 150 plus services in in production today which is roughly",
    "start": "110250",
    "end": "117149"
  },
  {
    "text": "75 percent of boxes kind of the stateless footprint we we run about",
    "start": "117149",
    "end": "124460"
  },
  {
    "text": "fluid a half thousand pods of hosts with",
    "start": "124460",
    "end": "129539"
  },
  {
    "text": "1,000 in the indeed largest of cluster mounts to roughly 25% of boxes compute",
    "start": "129539",
    "end": "136560"
  },
  {
    "text": "kind of the the datacenter footprint we",
    "start": "136560",
    "end": "142440"
  },
  {
    "text": "have about nine production grader clusters across of three regions they're all in in inactive bare metals we have",
    "start": "142440",
    "end": "150510"
  },
  {
    "text": "about 25,000 pods across all of these or clusters with of 9,000 pods in our largest cluster we built a platform of",
    "start": "150510",
    "end": "160530"
  },
  {
    "start": "159000",
    "end": "234000"
  },
  {
    "text": "the service on top of our our kubernetes infrastructure with the mission that we",
    "start": "160530",
    "end": "165989"
  },
  {
    "text": "wanted to allow other box teams to to run and manage their applications in a",
    "start": "165989",
    "end": "172950"
  },
  {
    "text": "secure efficient reliable manner in any region of the world our platform has",
    "start": "172950",
    "end": "181560"
  },
  {
    "text": "minimal abstractions on top of a kubernetes so as box teams you know kind of on board on top of our platform they",
    "start": "181560",
    "end": "189930"
  },
  {
    "text": "have a bit of a learning curve to learn about kind of a kubernetes api and stuff",
    "start": "189930",
    "end": "196500"
  },
  {
    "text": "from when they on board we use drops we have a declarative config",
    "start": "196500",
    "end": "203700"
  },
  {
    "text": "it we use of JSON it to to express that",
    "start": "203700",
    "end": "210150"
  },
  {
    "text": "of configuration and to also compile that into into cube manifests that",
    "start": "210150",
    "end": "215340"
  },
  {
    "text": "ultimately get applied to our our our clusters with with with the cube applier",
    "start": "215340",
    "end": "222200"
  },
  {
    "text": "cuba fire was a project that we built at box and we've actually donated to the to",
    "start": "222200",
    "end": "228030"
  },
  {
    "text": "the open source yep other things we have",
    "start": "228030",
    "end": "235950"
  },
  {
    "start": "234000",
    "end": "284000"
  },
  {
    "text": "in our platform are cross-cutting concerns for example we have a we have a",
    "start": "235950",
    "end": "241079"
  },
  {
    "text": "we have a we have an internal CA that that of delivers PKI to the pods we use",
    "start": "241079",
    "end": "248489"
  },
  {
    "text": "hashey core vault to deliver secrets we use of calico for network management and",
    "start": "248489",
    "end": "255480"
  },
  {
    "text": "for IPM we use smart stack for service discovery we're actually at a point",
    "start": "255480",
    "end": "260910"
  },
  {
    "text": "where we're pushing the scale of limits for smart stack and we're looking into replacing it we",
    "start": "260910",
    "end": "267250"
  },
  {
    "text": "artifactory for image management of our docker images Jenkins for pipelines and finally we use of namespaces and and and",
    "start": "267250",
    "end": "275200"
  },
  {
    "text": "are back policies to give granular access and control on a per service",
    "start": "275200",
    "end": "281350"
  },
  {
    "text": "basis back in 2017 or 2018 timeframe we",
    "start": "281350",
    "end": "287500"
  },
  {
    "start": "284000",
    "end": "417000"
  },
  {
    "text": "actually went through a bunch of problems and and scalability challenges in our platform and as we were",
    "start": "287500",
    "end": "294370"
  },
  {
    "text": "implementing fixes for our platform for those of stability problems we had we",
    "start": "294370",
    "end": "300490"
  },
  {
    "text": "had two kind of thoughts we didn't know how much the improvements were being",
    "start": "300490",
    "end": "305680"
  },
  {
    "text": "made by those fixes and we didn't know how how to prioritize those fixes because we didn't know what the the the",
    "start": "305680",
    "end": "312400"
  },
  {
    "text": "the bar built run here at and so we were kind of in this mode of hey how do we",
    "start": "312400",
    "end": "317590"
  },
  {
    "text": "measure our platform health and we were kind of there was a conundrum of",
    "start": "317590",
    "end": "324030"
  },
  {
    "text": "questions that we came across what is our service level agreement what is our",
    "start": "324030",
    "end": "330190"
  },
  {
    "text": "key performance indicator do we even support things like saturation with",
    "start": "330190",
    "end": "336190"
  },
  {
    "text": "Rupert traffic etc what is the service level objective is there three nines two",
    "start": "336190",
    "end": "341950"
  },
  {
    "text": "and a half I mean two and a half nines four nines how do we measure these",
    "start": "341950",
    "end": "347410"
  },
  {
    "text": "service level indicators further on was",
    "start": "347410",
    "end": "352960"
  },
  {
    "text": "the breadth of the off of this problem do we measure our control plane do we",
    "start": "352960",
    "end": "358300"
  },
  {
    "text": "measure our data plane both or something else do we go what's the what's the kind",
    "start": "358300",
    "end": "365110"
  },
  {
    "text": "of depth we act measure and do we measure at our cluster level at the zone level or a region level or across the",
    "start": "365110",
    "end": "371050"
  },
  {
    "text": "board we also looked at what the or the industry kind of thinks about this",
    "start": "371050",
    "end": "376540"
  },
  {
    "text": "problem here's two instances of what we found from dear statements from the",
    "start": "376540",
    "end": "382750"
  },
  {
    "text": "SFA's of of some cloud providers and the thing that I want to point out here as",
    "start": "382750",
    "end": "388690"
  },
  {
    "text": "these are liberal kind of assumptions what this really boils down to is that if you if if your service has at least",
    "start": "388690",
    "end": "395349"
  },
  {
    "text": "one instance that is alive and actually taking traffic then your service will not be considered on over",
    "start": "395349",
    "end": "401770"
  },
  {
    "text": "and that that's pretty liberal like if people were to implement the same principles in our platform we would be",
    "start": "401770",
    "end": "409440"
  },
  {
    "text": "set up ourselves or like like failure so",
    "start": "409440",
    "end": "417520"
  },
  {
    "start": "417000",
    "end": "559000"
  },
  {
    "text": "we started simple and we began exploring some solutions the the first solution we",
    "start": "417520",
    "end": "423040"
  },
  {
    "text": "kind of thought of was hey let's just go ahead and count the number of minutes that we've regretted our voxcom side",
    "start": "423040",
    "end": "429880"
  },
  {
    "text": "that this was very course and it it did",
    "start": "429880",
    "end": "435910"
  },
  {
    "text": "not account for a large number of other problems that were happening within our platform basically not all paths not all",
    "start": "435910",
    "end": "445330"
  },
  {
    "text": "paths lag relations what would cause a good cause of box.com who tied relations",
    "start": "445330",
    "end": "451200"
  },
  {
    "text": "so we've we've been one step ahead we began measuring the percentage of 500",
    "start": "451200",
    "end": "458530"
  },
  {
    "text": "from the API server and we call this our control plane control plane availability and uptime there were some problems with",
    "start": "458530",
    "end": "468850"
  },
  {
    "text": "this as well it did not account for other for other types of errors that",
    "start": "468850",
    "end": "475420"
  },
  {
    "text": "happen while she showed up in in the API server logs like for hundreds it it did",
    "start": "475420",
    "end": "481090"
  },
  {
    "text": "not account for for like scheduler issues it did not account for controller manager issues in effect it did not",
    "start": "481090",
    "end": "487330"
  },
  {
    "text": "account for the data plane and so we went ahead and implemented a synthetic test to represent our data plane",
    "start": "487330",
    "end": "494920"
  },
  {
    "text": "availability the this synthetic tests were to run every 10 15 seconds and it",
    "start": "494920",
    "end": "500650"
  },
  {
    "text": "would run on a subset of hosts and it would test a subset of the of the features for the lifecycle of the part",
    "start": "500650",
    "end": "508270"
  },
  {
    "text": "to kind of see when a you know kind of POD we created is a part of receiving",
    "start": "508270",
    "end": "513940"
  },
  {
    "text": "the assets that it needs for example of PKI and secrets et cetera then again",
    "start": "513940",
    "end": "522130"
  },
  {
    "text": "this wasn't real it wasn't representative of of our customers it",
    "start": "522130",
    "end": "527530"
  },
  {
    "text": "was it was it was it was a synthetic and so at this point we kind of step back",
    "start": "527530",
    "end": "532600"
  },
  {
    "text": "and kind of ask what are what are the questions we want to believe focus on from oral the",
    "start": "532600",
    "end": "538690"
  },
  {
    "text": "conundrum and and two questions really stood out one was what were customers",
    "start": "538690",
    "end": "544000"
  },
  {
    "text": "really care about right and the second question was how do we leverage",
    "start": "544000",
    "end": "550330"
  },
  {
    "text": "kubernetes itself to build build an SLA",
    "start": "550330",
    "end": "555339"
  },
  {
    "text": "for a platform customers normally care",
    "start": "555339",
    "end": "561490"
  },
  {
    "text": "about more about about the ease of use of the of the platform itself they care",
    "start": "561490",
    "end": "568210"
  },
  {
    "text": "about keeping their own service up and along and running at at all times and",
    "start": "568210",
    "end": "573839"
  },
  {
    "text": "they care about how to serve a hundred percent of the peak traffic at all times",
    "start": "573839",
    "end": "579720"
  },
  {
    "text": "they don't necessarily care about the control plane availability if our control plane dies they don't care they",
    "start": "579720",
    "end": "586810"
  },
  {
    "text": "shouldn't even come to know a lot of our customers have begun telling us that",
    "start": "586810",
    "end": "593800"
  },
  {
    "text": "they actually don't care about the kubernetes api itself remember I told you that our platform is has very few",
    "start": "593800",
    "end": "600250"
  },
  {
    "text": "abstractions and their customers have a learning curve to understand with kubernetes people started telling us",
    "start": "600250",
    "end": "607240"
  },
  {
    "text": "that I should don't want to learn about kubernetes like up a whole lot that's a separate problem but I just want to kind",
    "start": "607240",
    "end": "613240"
  },
  {
    "text": "of highlight it here and and and finally customers care much less how the",
    "start": "613240",
    "end": "619900"
  },
  {
    "text": "platform implements the protections for it from things like hardware failures",
    "start": "619900",
    "end": "625560"
  },
  {
    "text": "software failures ensuring there's enough capacity available for like bin",
    "start": "625560",
    "end": "631420"
  },
  {
    "text": "packing your reports in or maintenance etc we also looked at a bunch of",
    "start": "631420",
    "end": "641620"
  },
  {
    "start": "638000",
    "end": "784000"
  },
  {
    "text": "protections there are kubernetes offers liveness various probes which all of you",
    "start": "641620",
    "end": "647890"
  },
  {
    "text": "guys know about hopefully rolling updates is a mechanism that that helps",
    "start": "647890",
    "end": "654760"
  },
  {
    "text": "block the propagation of bad changes pdb",
    "start": "654760",
    "end": "664600"
  },
  {
    "text": "is more more recent concept it protects service from from administrative",
    "start": "664600",
    "end": "670810"
  },
  {
    "text": "disruptions and when there's another kind of it isn't it isn't a feature but",
    "start": "670810",
    "end": "677680"
  },
  {
    "text": "it's a method of how you configure quality the the the the quality of service for your part by by specifying",
    "start": "677680",
    "end": "686680"
  },
  {
    "text": "the resource from requests and limits author containers and it's you know you",
    "start": "686680",
    "end": "692440"
  },
  {
    "text": "can you can set your pots to guaranteed vegetable or best effort we choose",
    "start": "692440",
    "end": "699850"
  },
  {
    "text": "guaranteed the principle behind that and",
    "start": "699850",
    "end": "705310"
  },
  {
    "text": "actual guarantee means to set your part of requests at these at the same level",
    "start": "705310",
    "end": "710500"
  },
  {
    "text": "as your part of limits on a container request and and limits so you don't give",
    "start": "710500",
    "end": "716590"
  },
  {
    "text": "more CPU to your limits than your requests the the principle behind this",
    "start": "716590",
    "end": "722230"
  },
  {
    "text": "is when we looked at our traffic or peak traffic we notice that all of our",
    "start": "722230",
    "end": "727900"
  },
  {
    "text": "services were actually peak during peak traffic and if if all services would",
    "start": "727900",
    "end": "734410"
  },
  {
    "text": "attempt to burst and use more CPU we would cause a lot of noisy neighbor problem so our recommendation to our",
    "start": "734410",
    "end": "742780"
  },
  {
    "text": "service owners wars use of guaranteed mode and if you if you if you want to scale for peak traffic then they're like",
    "start": "742780",
    "end": "748900"
  },
  {
    "text": "scale horizontally you know create more replicas and and not increase of CPU",
    "start": "748900",
    "end": "754690"
  },
  {
    "text": "life memory on each of your each of each each of your containers and there might have been other kind of jobs which we",
    "start": "754690",
    "end": "762970"
  },
  {
    "text": "didn't explore at the time realize this was all most of you are here and a half ago that we kind of export this and",
    "start": "762970",
    "end": "770340"
  },
  {
    "text": "we're actually running a version of kubernetes that's bad that's far behind",
    "start": "770340",
    "end": "777900"
  },
  {
    "text": "the upstream so we kind of limited in the the features that we can use so the",
    "start": "777900",
    "end": "785710"
  },
  {
    "start": "784000",
    "end": "899000"
  },
  {
    "text": "solution that we landed upon was was a CRI critical replica availability",
    "start": "785710",
    "end": "793800"
  },
  {
    "text": "principally we wanted to build a platform that provided high availability services",
    "start": "793800",
    "end": "800550"
  },
  {
    "text": "we kept in mind two things kind of high-level if the platform doesn't meet",
    "start": "801550",
    "end": "806920"
  },
  {
    "text": "on the VHA needs of a service then somehow that should show up in the",
    "start": "806920",
    "end": "812470"
  },
  {
    "text": "platform's health metric conversely if a handful of services cannot get can get a",
    "start": "812470",
    "end": "820779"
  },
  {
    "text": "che then something is probably wrong with those handful of services with themselves then this isn't the problem",
    "start": "820779",
    "end": "827170"
  },
  {
    "text": "at mass and so we were in the heart of",
    "start": "827170",
    "end": "832630"
  },
  {
    "text": "implementing something that that provided accountability to all of our service owners and and and enables us to",
    "start": "832630",
    "end": "840930"
  },
  {
    "text": "prioritize the fixes that we were making against our kind of stability problems",
    "start": "840930",
    "end": "848519"
  },
  {
    "text": "conceptually our customers are our tenants our service owners would define",
    "start": "849420",
    "end": "856149"
  },
  {
    "text": "a minimum healthy number of critical replicas that would be needed to for the",
    "start": "856149",
    "end": "863290"
  },
  {
    "text": "service to be able to serve a hundred percent off of traffic at peak I've left",
    "start": "863290",
    "end": "868600"
  },
  {
    "text": "out details about how this is actually configured on a per cluster or a per data center or a poorer zone of region",
    "start": "868600",
    "end": "875680"
  },
  {
    "text": "level this is keeping it simple for now once we once we got that from our",
    "start": "875680",
    "end": "882790"
  },
  {
    "text": "service owners we would go ahead and our platform would both calculate and and",
    "start": "882790",
    "end": "889930"
  },
  {
    "text": "and automatically configure kubernetes or protections for those services taking",
    "start": "889930",
    "end": "899560"
  },
  {
    "start": "899000",
    "end": "1051000"
  },
  {
    "text": "an example of that realized that the values that I'm going to go through here",
    "start": "899560",
    "end": "905110"
  },
  {
    "text": "are very suggestive the method is also very suggestive from this might not be",
    "start": "905110",
    "end": "910540"
  },
  {
    "text": "exactly what we do because we're constantly changing and evolving but I wanted to show this to actually serve as",
    "start": "910540",
    "end": "917890"
  },
  {
    "text": "a basis for how you would think about building your own SLA so a customer",
    "start": "917890",
    "end": "926470"
  },
  {
    "text": "which is our service owner we have to define their critical replica threshold let's say hundred replicas it would go",
    "start": "926470",
    "end": "932980"
  },
  {
    "text": "ahead and configure their there liveness and readiness probes to ensure",
    "start": "932980",
    "end": "938170"
  },
  {
    "text": "that they you know they account for their own dependencies and also they",
    "start": "938170",
    "end": "943870"
  },
  {
    "text": "would use the guaranteed quality of service they would ensure that the request for limits match their request",
    "start": "943870",
    "end": "951070"
  },
  {
    "text": "my term limits on on the only other resources and then the platform would",
    "start": "951070",
    "end": "956110"
  },
  {
    "text": "come in and and and and begin adding protections on top of that in a layered",
    "start": "956110",
    "end": "961870"
  },
  {
    "text": "fashion bottom most layer would be hardware protection you know a service",
    "start": "961870",
    "end": "967210"
  },
  {
    "text": "should be able to lose X number of parts if there is a hardware failure assuming 5% hardware failure 5% of the",
    "start": "967210",
    "end": "974020"
  },
  {
    "text": "of the cause of the service can go down and added at any point of time so we need to run 105 pods on top of that we",
    "start": "974020",
    "end": "982450"
  },
  {
    "text": "added the this option budget buffer which was to allow administrative",
    "start": "982450",
    "end": "988000"
  },
  {
    "text": "disruptions hey I want to go ahead and drain a couple of hosts because there's",
    "start": "988000",
    "end": "993940"
  },
  {
    "text": "a problem and I need to bounce them on top of that we added a I added some sort",
    "start": "993940",
    "end": "1000450"
  },
  {
    "text": "of rolling update buffer hey at added anytime there's a hardware failure and there's a disruption going on and and",
    "start": "1000450",
    "end": "1007470"
  },
  {
    "text": "there's an administrative disruption going on I still should be able to do rolling updates so added that buffer",
    "start": "1007470",
    "end": "1013170"
  },
  {
    "text": "here and then finally another buffer for maintenance for example a you know I",
    "start": "1013170",
    "end": "1021270"
  },
  {
    "text": "want to be able to lose a whole rack or for like maintenance and when there",
    "start": "1021270",
    "end": "1027870"
  },
  {
    "text": "could be many more levels you know we haven't completed our full story yet but",
    "start": "1027870",
    "end": "1033569"
  },
  {
    "text": "what I want to tell you here is that even though the service actually needs hundred replicas to be available we",
    "start": "1033570",
    "end": "1039240"
  },
  {
    "text": "actually gave the service 117 pods and we actually gave the service 123 pause",
    "start": "1039240",
    "end": "1045329"
  },
  {
    "text": "both of capacity right how do we measure",
    "start": "1045329",
    "end": "1052710"
  },
  {
    "start": "1051000",
    "end": "1121000"
  },
  {
    "text": "the SLI how do we really measure this so we take the minimum of replicas we",
    "start": "1052710",
    "end": "1058950"
  },
  {
    "text": "required for H a for every service and then we calculate the available replicas",
    "start": "1058950",
    "end": "1064440"
  },
  {
    "text": "for every service over comparing the total available with the",
    "start": "1064440",
    "end": "1070340"
  },
  {
    "text": "with the CRT in our example the total available was Kernan was was 101 117 and",
    "start": "1070340",
    "end": "1078380"
  },
  {
    "text": "his CRT was 100 and then we calculated these replicas availability which is a",
    "start": "1078380",
    "end": "1083510"
  },
  {
    "text": "percentage of of the CRT so as long as as that service had more than 100 parts",
    "start": "1083510",
    "end": "1090440"
  },
  {
    "text": "alive at any given time between 100 and an hundred seventeen we would consider that or service to be hundred percent",
    "start": "1090440",
    "end": "1096320"
  },
  {
    "text": "available and the moment that that service would actually start losing parts below hundred we would start",
    "start": "1096320",
    "end": "1102890"
  },
  {
    "text": "accounting for that in our in our CSA and finally we would take an aggregate",
    "start": "1102890",
    "end": "1108170"
  },
  {
    "text": "could take a simple average across all the across the availability for all the other all services across a AVO who give",
    "start": "1108170",
    "end": "1117230"
  },
  {
    "text": "like given arbitrary period of time here's an example of what the metric",
    "start": "1117230",
    "end": "1125240"
  },
  {
    "text": "looks like for us today that's for the month of October and as you can see we",
    "start": "1125240",
    "end": "1131870"
  },
  {
    "text": "are well above our SLO why we chose why",
    "start": "1131870",
    "end": "1138380"
  },
  {
    "text": "we chose of three nines of SLO and the story around that is probably a topic",
    "start": "1138380",
    "end": "1144770"
  },
  {
    "text": "for some other time but I can stick around after the talk if people want to know",
    "start": "1144770",
    "end": "1151570"
  },
  {
    "start": "1153000",
    "end": "1493000"
  },
  {
    "text": "so even though we built this the project isn't complete we are aware of a few",
    "start": "1160820",
    "end": "1167880"
  },
  {
    "text": "gaps that I want to talk about and there's a bunch of future work that we want to do to improve this we we",
    "start": "1167880",
    "end": "1174600"
  },
  {
    "text": "realized that massive system failures are things we cannot do anything about",
    "start": "1174600",
    "end": "1180139"
  },
  {
    "text": "they will impact our SLI of regardless of what we would have actually chosen to",
    "start": "1180139",
    "end": "1186830"
  },
  {
    "text": "measure next the an interesting thing",
    "start": "1186830",
    "end": "1193049"
  },
  {
    "text": "about our the way we calculate our CRA is that we treat all services equally",
    "start": "1193049",
    "end": "1200389"
  },
  {
    "text": "some people might think this is a feature we should treat everybody equal this is a platform and other people",
    "start": "1200389",
    "end": "1206940"
  },
  {
    "text": "might think this is a bug we should have some monitoring we think it's a bug because we do feel that we have a class",
    "start": "1206940",
    "end": "1214019"
  },
  {
    "text": "of services that are more or less in the critical path of customer traffic and so",
    "start": "1214019",
    "end": "1219840"
  },
  {
    "text": "like there is an actual reason to create tiers of services so that's something we",
    "start": "1219840",
    "end": "1227580"
  },
  {
    "text": "would want to fix in the future maybe we do that using grade averages I don't",
    "start": "1227580",
    "end": "1234120"
  },
  {
    "text": "know we haven't explored that yet we also realized that we were subject to",
    "start": "1234120",
    "end": "1239850"
  },
  {
    "text": "service owner induced errors for example if a if a service introduces a bad",
    "start": "1239850",
    "end": "1245730"
  },
  {
    "text": "change which has a which has a latent bug that shows up after a couple of days and of crash loops a bunch of their pods",
    "start": "1245730",
    "end": "1252710"
  },
  {
    "text": "there's no way we could have protected against that and that would ultimately show us show the the CRN I going down or",
    "start": "1252710",
    "end": "1264419"
  },
  {
    "text": "for example a service which hasn't really configured as of liveness probes correctly first to get into a state",
    "start": "1264419",
    "end": "1272970"
  },
  {
    "text": "where our CRS shows good but the platform actually has the problems",
    "start": "1272970",
    "end": "1278429"
  },
  {
    "text": "underneath some of the for some future work that we want to do we would like to",
    "start": "1278429",
    "end": "1286820"
  },
  {
    "text": "leverage new features of kubernetes for",
    "start": "1286820",
    "end": "1291929"
  },
  {
    "text": "example odd priority and preemption realize we",
    "start": "1291929",
    "end": "1299890"
  },
  {
    "text": "like we are our central point of CRA",
    "start": "1299890",
    "end": "1306010"
  },
  {
    "text": "is that we want to we want the platform to at least maintain the the critical",
    "start": "1306010",
    "end": "1312190"
  },
  {
    "text": "number of replicas at all times so let's say we have situation where we lose 25%",
    "start": "1312190",
    "end": "1317530"
  },
  {
    "text": "of our of our of our capacity and we have a hundred services from which 99 services are healthy they have all of",
    "start": "1317530",
    "end": "1324460"
  },
  {
    "text": "their critical replicas up and alive but there's one service which which which which which has lost half of its parts",
    "start": "1324460",
    "end": "1331470"
  },
  {
    "text": "we don't have a mechanism that will go and kill the healthy parts from all the",
    "start": "1331470",
    "end": "1336940"
  },
  {
    "text": "99 services so that we can make room for the critical replicas of this one service which which is unhealthy and so",
    "start": "1336940",
    "end": "1345490"
  },
  {
    "text": "we need a feature from from kubernetes where we can we can express the fact",
    "start": "1345490",
    "end": "1351460"
  },
  {
    "text": "that we want to keep the critical replicas of these of services alive at all times even if it means going and",
    "start": "1351460",
    "end": "1358600"
  },
  {
    "text": "killing healthy pods from other services we want to improve our tooling around",
    "start": "1358600",
    "end": "1366390"
  },
  {
    "text": "RHA for example we want to improve the way we do canadian we want to introduce",
    "start": "1366390",
    "end": "1374200"
  },
  {
    "text": "more more chaos in in our system when we built our platform a large number of",
    "start": "1374200",
    "end": "1383670"
  },
  {
    "text": "tenants actually moved over from the from the bare metal world over into the",
    "start": "1383670",
    "end": "1388780"
  },
  {
    "text": "kubernetes from platform and they kind of brought along with them some anti-patterns and some like bad",
    "start": "1388780",
    "end": "1395170"
  },
  {
    "text": "architectures when you're in a barrel you're not necessarily thinking about if",
    "start": "1395170",
    "end": "1400300"
  },
  {
    "text": "my if my machine dies at at it at any point of time how do i recover how do I",
    "start": "1400300",
    "end": "1405340"
  },
  {
    "text": "convert across my kind of healthy healthy instances and and and and and so forth well deployments are really",
    "start": "1405340",
    "end": "1411610"
  },
  {
    "text": "controlled and and and tightly orchestrated so a lot of the services",
    "start": "1411610",
    "end": "1417850"
  },
  {
    "text": "that we are running today aren't actually fully like completely built for",
    "start": "1417850",
    "end": "1423490"
  },
  {
    "text": "hard shutdowns and so we want to and and really if if if hard shutdowns",
    "start": "1423490",
    "end": "1430059"
  },
  {
    "text": "happen those services take a long time to kind of recover and and and and and",
    "start": "1430059",
    "end": "1438519"
  },
  {
    "text": "become healthy again and so we want to like introduce more more chaos so that we can help those services improve that",
    "start": "1438519",
    "end": "1447210"
  },
  {
    "text": "improve their architecture in order to ultimately improve our RCRA and lastly",
    "start": "1447210",
    "end": "1456070"
  },
  {
    "text": "we want to have kind of a stronger service on our accountability we want to",
    "start": "1456070",
    "end": "1462549"
  },
  {
    "text": "implement some system where all services on a platform get out of out of box",
    "start": "1462549",
    "end": "1468909"
  },
  {
    "text": "alerts so that if their pods start dying they get paged and like they need to",
    "start": "1468909",
    "end": "1474970"
  },
  {
    "text": "come back and fix those or like implementing some sort of a policy where",
    "start": "1474970",
    "end": "1479980"
  },
  {
    "text": "you know if we find that a service is misbehaving or they haven't responded to their page in like in a while we exclude",
    "start": "1479980",
    "end": "1486789"
  },
  {
    "text": "them from our SLI and and they they they actually don't get our protections anymore that's it that's all I had for",
    "start": "1486789",
    "end": "1495119"
  },
  {
    "start": "1493000",
    "end": "1508000"
  },
  {
    "text": "tonight I'm happy to take any questions if anybody has",
    "start": "1495119",
    "end": "1500279"
  },
  {
    "text": "[Applause]",
    "start": "1500300",
    "end": "1507900"
  },
  {
    "start": "1508000",
    "end": "1593000"
  },
  {
    "text": "how do you deal with like sock compliance sock to compliance where developers can access prod or do you",
    "start": "1508400",
    "end": "1515730"
  },
  {
    "text": "have that issue developers can't access a prod yeah we use I mean our developers",
    "start": "1515730",
    "end": "1524160"
  },
  {
    "text": "actually can access prod but they can access prod through through through",
    "start": "1524160",
    "end": "1529500"
  },
  {
    "text": "specific controls we have a we have it we have jump machines bastions which",
    "start": "1529500",
    "end": "1536850"
  },
  {
    "text": "have you know appropriate ackles kind of applied to them that enable them to access access prod and they're all like",
    "start": "1536850",
    "end": "1543540"
  },
  {
    "text": "that's all like that's all in that's the infrastructure level access and on top",
    "start": "1543540",
    "end": "1550950"
  },
  {
    "text": "of that we have kubernetes our back and and we use a bandwidth who's LDAP for",
    "start": "1550950",
    "end": "1556440"
  },
  {
    "text": "authentication as well so a developer can only access their own services in in",
    "start": "1556440",
    "end": "1563400"
  },
  {
    "text": "in in the production does that answer your question I see you know I see I",
    "start": "1563400",
    "end": "1579630"
  },
  {
    "text": "have some other members from my team heard you know here in the room maybe we can hang out outside because they have",
    "start": "1579630",
    "end": "1585150"
  },
  {
    "text": "more information about some of the things you're talking about can you tell",
    "start": "1585150",
    "end": "1594870"
  },
  {
    "text": "us more about your tooling that you use to add additional pods above the",
    "start": "1594870",
    "end": "1600960"
  },
  {
    "text": "customer to find CRA sure one of the slides mentioned we have a declarative",
    "start": "1600960",
    "end": "1607050"
  },
  {
    "text": "configuration system that we operate and gate and we use JSON ER to express their",
    "start": "1607050",
    "end": "1613050"
  },
  {
    "text": "configuration we use we've built a",
    "start": "1613050",
    "end": "1618210"
  },
  {
    "text": "closure in like a like our we use JSON to actually compile their configuration",
    "start": "1618210",
    "end": "1625530"
  },
  {
    "text": "and produce community use of manifests we've included a we've built a closure",
    "start": "1625530",
    "end": "1630660"
  },
  {
    "text": "in there which actually manipulates kubernetes of manifests",
    "start": "1630660",
    "end": "1637309"
  },
  {
    "text": "before they are written back into into who get and that's how we kind of we we",
    "start": "1637309",
    "end": "1643280"
  },
  {
    "text": "expect the users to order service owners to express their critical replicas we",
    "start": "1643280",
    "end": "1648409"
  },
  {
    "text": "read that in our in our in our closure and we omit new kind of protections for",
    "start": "1648409",
    "end": "1655429"
  },
  {
    "text": "example of PDP's or rolling updates and we bump up the replicas to what we think is actually best for them and then we",
    "start": "1655429",
    "end": "1662330"
  },
  {
    "text": "actually writer to get yes back to the",
    "start": "1662330",
    "end": "1667580"
  },
  {
    "text": "same report exactly so the sort of the both the the plain tent and the and the",
    "start": "1667580",
    "end": "1673610"
  },
  {
    "text": "full manifest actually goes in those in the same repository so if service order makes a change with composite locally",
    "start": "1673610",
    "end": "1681380"
  },
  {
    "text": "there are producers of set of like changes in the in the in the release folder and that gets commuted as one",
    "start": "1681380",
    "end": "1688669"
  },
  {
    "text": "block",
    "start": "1688669",
    "end": "1690880"
  },
  {
    "start": "1696000",
    "end": "1795000"
  },
  {
    "text": "yeah if there are other elements to the platform that a team provides say efk",
    "start": "1696970",
    "end": "1703780"
  },
  {
    "text": "logging support or service match that's also considered part of the platform any suggestions on extending this to those",
    "start": "1703780",
    "end": "1711370"
  },
  {
    "text": "other services that's a great point so",
    "start": "1711370",
    "end": "1720760"
  },
  {
    "text": "two answers kind of there one is not all",
    "start": "1720760",
    "end": "1727270"
  },
  {
    "text": "of our systems that we have today are built for for cube native one of the",
    "start": "1727270",
    "end": "1734050"
  },
  {
    "text": "things one of the fundamental reasons we can do this is because we are heavily using the kubernetes of controls so if",
    "start": "1734050",
    "end": "1743320"
  },
  {
    "text": "you have a system which which which has all of these integrations which are on the cob which are also key kind of like",
    "start": "1743320",
    "end": "1750160"
  },
  {
    "text": "a native maybe then it'll be much easier to kind of faint lab like find out if",
    "start": "1750160",
    "end": "1758530"
  },
  {
    "text": "there are controls which we can use to automatically protect services from doing the right thing the other way to",
    "start": "1758530",
    "end": "1765730"
  },
  {
    "text": "look at this is that because we have a deathly rate of system we can actually",
    "start": "1765730",
    "end": "1772750"
  },
  {
    "text": "go ahead and build those things out even for those integrations even though even",
    "start": "1772750",
    "end": "1778420"
  },
  {
    "text": "if they aren't work a native we haven't really thought about this problem but we",
    "start": "1778420",
    "end": "1784210"
  },
  {
    "text": "think we have the right set of tools to be able to address at least a small portion of this great talk so on one of",
    "start": "1784210",
    "end": "1798460"
  },
  {
    "start": "1795000",
    "end": "1913000"
  },
  {
    "text": "the slides you said customers care about ease of use the availability of their service and serving a hundred percent of",
    "start": "1798460",
    "end": "1805870"
  },
  {
    "text": "the traffic but looks like with CRA only tackling about the second part which is",
    "start": "1805870",
    "end": "1811720"
  },
  {
    "text": "availability which is last - actually - Lars - but how about other parts of platform like what if your ingress is",
    "start": "1811720",
    "end": "1818770"
  },
  {
    "text": "down then that's a great point I want to answer that in two ways one is we",
    "start": "1818770",
    "end": "1825520"
  },
  {
    "text": "encourage services to build as much",
    "start": "1825520",
    "end": "1831340"
  },
  {
    "text": "health as possible into its of lightness and and readiness probes and and and",
    "start": "1831340",
    "end": "1842760"
  },
  {
    "text": "part of solving that is if if if if the egress is down for the service then",
    "start": "1842760",
    "end": "1850470"
  },
  {
    "text": "build it in a way that that actually trips the aliveness probe or the",
    "start": "1850470",
    "end": "1857110"
  },
  {
    "text": "readiness probe so that that actually shows up in the in the health of the service the second answer to your",
    "start": "1857110",
    "end": "1864010"
  },
  {
    "text": "problem is that this is not a silver bullet use rightly pointed out this is not the only metric that we want to like",
    "start": "1864010",
    "end": "1870460"
  },
  {
    "text": "of track and and and and think about there are lots of other metrics that we",
    "start": "1870460",
    "end": "1876220"
  },
  {
    "text": "use for example how fast can how fast can a change is really make it into",
    "start": "1876220",
    "end": "1881500"
  },
  {
    "text": "production how many changes can be made in parallel how much time does it does a",
    "start": "1881500",
    "end": "1887470"
  },
  {
    "text": "developer spend or actually babysitting their pipeline but when we thought about",
    "start": "1887470",
    "end": "1892570"
  },
  {
    "text": "this we wanted to think about one single metric that we can project both upwards",
    "start": "1892570",
    "end": "1897970"
  },
  {
    "text": "to our like business and project downwards to our customers that that can",
    "start": "1897970",
    "end": "1903880"
  },
  {
    "text": "you know like bring us all all on the same page but this is certainly not the only thing we track yeah great talk",
    "start": "1903880",
    "end": "1916200"
  },
  {
    "start": "1913000",
    "end": "2208000"
  },
  {
    "text": "so is it tricky at all for teams to define their critical pod level or pod",
    "start": "1916200",
    "end": "1922900"
  },
  {
    "text": "count like do you find some teams don't know or I have to iterate for a while yes the fine if I kind of want to be",
    "start": "1922900",
    "end": "1934390"
  },
  {
    "text": "correctly what kind of guidance do we provide them on setting that I intro critical replica we address that in a",
    "start": "1934390",
    "end": "1943180"
  },
  {
    "text": "couple of ways one we kind of admit that we don't have the right tools in place",
    "start": "1943180",
    "end": "1948460"
  },
  {
    "text": "for a service or not to go and actually do performance testing of their",
    "start": "1948460",
    "end": "1955090"
  },
  {
    "text": "application to actually see how many parts they need to be able to serve with peak traffic on the other hand we do",
    "start": "1955090",
    "end": "1961660"
  },
  {
    "text": "have a separate capacity engineering team which actually monitors the both the",
    "start": "1961660",
    "end": "1967930"
  },
  {
    "text": "capacity and the energy utilization of the service to get a sense of where the",
    "start": "1967930",
    "end": "1973960"
  },
  {
    "text": "service is at in terms of its its its its head room and that's that's one way",
    "start": "1973960",
    "end": "1981070"
  },
  {
    "text": "we kind of use to kind of kind of assess what's the right range therefore the",
    "start": "1981070",
    "end": "1986230"
  },
  {
    "text": "folio replicas part to offer answer is that we provided a we actually ran this",
    "start": "1986230",
    "end": "1994990"
  },
  {
    "text": "program as an opt-in program we didn't force everyone to implement this right away we implemented the controls for",
    "start": "1994990",
    "end": "2003990"
  },
  {
    "text": "that for this and we we expressed a",
    "start": "2003990",
    "end": "2009900"
  },
  {
    "text": "label that one could apply to their deployment if we if we found the label",
    "start": "2009900",
    "end": "2018000"
  },
  {
    "text": "it would be treated as an opt-in and we would actually start admitting those like those those protections and if if",
    "start": "2018000",
    "end": "2025080"
  },
  {
    "text": "if a service who didn't have the label you actually would emit of warnings alluding our build that hey you should",
    "start": "2025080",
    "end": "2032160"
  },
  {
    "text": "start opting in into this program and figured out the replicas you need yeah",
    "start": "2032160",
    "end": "2037950"
  },
  {
    "text": "kind of answer your question yeah just a follow-up to that what kind of guidance",
    "start": "2037950",
    "end": "2043830"
  },
  {
    "text": "do you provide to your customers about what their health checks should be doing",
    "start": "2043830",
    "end": "2049679"
  },
  {
    "text": "to define readiness and did you have you gotten what's your feedback you've",
    "start": "2049680",
    "end": "2055649"
  },
  {
    "text": "gotten from your team's about this particular metric yeah",
    "start": "2055650",
    "end": "2062300"
  },
  {
    "text": "most of our so I think I think there were two questions there ask your first",
    "start": "2062570",
    "end": "2068490"
  },
  {
    "text": "question how do we provide guidance to what the right thing to do is there now we actually have an internal wiki where",
    "start": "2068490",
    "end": "2076440"
  },
  {
    "text": "we will be produced all of our guidelines and and guidances and all that you actually have a full page about",
    "start": "2076440",
    "end": "2083399"
  },
  {
    "text": "you know how should you configure your liveness and local readiness probes with examples of situations that you should",
    "start": "2083400",
    "end": "2089040"
  },
  {
    "text": "treat and you any kind of certain treat I don't remember a lot of things from",
    "start": "2089040",
    "end": "2094230"
  },
  {
    "text": "the top of my head but we do have things for example like like I think in the readiness probe",
    "start": "2094230",
    "end": "2101990"
  },
  {
    "text": "don't actually check or don't make outbound connections or network connections in your in your readiness",
    "start": "2101990",
    "end": "2108600"
  },
  {
    "text": "probe do something with in-memory checks that you can quickly respond back we",
    "start": "2108600",
    "end": "2115620"
  },
  {
    "text": "have a full set and we and and we point all of our service orders to that page and we constantly kind of improve it we",
    "start": "2115620",
    "end": "2122070"
  },
  {
    "text": "also have a lot of links in there that point to upstream best practice and and",
    "start": "2122070",
    "end": "2127140"
  },
  {
    "text": "the kind of sources that's the way we kind of actually mitigate that we don't",
    "start": "2127140",
    "end": "2133230"
  },
  {
    "text": "have a formal way of actually going into all all of her services and actually verifying whether they are actually",
    "start": "2133230",
    "end": "2138750"
  },
  {
    "text": "using it the right way what do our customers actually think about this",
    "start": "2138750",
    "end": "2143840"
  },
  {
    "text": "that's an it's an interesting question I think it partly answers someone someone",
    "start": "2143840",
    "end": "2149370"
  },
  {
    "text": "else's questions we haven't fully completed this program yet we think",
    "start": "2149370",
    "end": "2154470"
  },
  {
    "text": "about I don't know maybe 10 to 20 percent of our customers have actually opted into this so we haven't raised",
    "start": "2154470",
    "end": "2160710"
  },
  {
    "text": "that that that that that critical mass where we are you know where we had that",
    "start": "2160710",
    "end": "2167070"
  },
  {
    "text": "that kind of feedback from them yet we hope to finish this program by the end",
    "start": "2167070",
    "end": "2174960"
  },
  {
    "text": "of next year we're an enterprise company everybody has lots of priorities and so",
    "start": "2174960",
    "end": "2182090"
  },
  {
    "text": "we can't every we can't have everyone to fix this and opt in like within a short",
    "start": "2182090",
    "end": "2187290"
  },
  {
    "text": "period of time but hopefully yet at some point of next year we will have I have my trousers all right I know some of you",
    "start": "2187290",
    "end": "2193800"
  },
  {
    "text": "still have questions but we have reached time so if you could try to take those conversations out into the hallway and",
    "start": "2193800",
    "end": "2201060"
  },
  {
    "text": "please do remember to rate the session on sketch comedy",
    "start": "2201060",
    "end": "2206420"
  },
  {
    "text": "[Applause]",
    "start": "2206910",
    "end": "2210089"
  }
]
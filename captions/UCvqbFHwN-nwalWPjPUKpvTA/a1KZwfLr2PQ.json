[
  {
    "text": "hello everyone for those who are still getting seated there are still plenty of seats up front there's five amusing ones",
    "start": "80",
    "end": "6120"
  },
  {
    "text": "here but there's actually legitimately like more seats here so if you Shuffle forward you can actually find a place to sit so please do uh while you do that",
    "start": "6120",
    "end": "12759"
  },
  {
    "text": "we'll introduce ourselves my name is Morgan mlan I'm a director of product management on Splunk I'm one of the co-founders of open cemetry I still",
    "start": "12759",
    "end": "19000"
  },
  {
    "text": "spend a huge amount of my time on the project every single day I'm Dan jaglowski I'm a principal software",
    "start": "19000",
    "end": "24320"
  },
  {
    "text": "developer at observe IQ and a maintainer of the open Telemetry collector I've been developing observability softare",
    "start": "24320",
    "end": "30000"
  },
  {
    "text": "for for over a decade and contributing to open chemetry for the last 3 years or so and we're talking about logs today so",
    "start": "30000",
    "end": "37160"
  },
  {
    "text": "open cemetry started 2019 we added traces then we added metrics uh today we made an announcement earlier today that",
    "start": "37160",
    "end": "42719"
  },
  {
    "text": "we've added logs logs have actually been present in open Telemetry in some form for the last two two years roughly uh",
    "start": "42719",
    "end": "49719"
  },
  {
    "text": "but a couple months ago things started actually reaching maturity and so we declared 1.0 for various components of",
    "start": "49719",
    "end": "54879"
  },
  {
    "text": "logging in open cemetry so we had a big celebration this morning a big announcement about that but today at",
    "start": "54879",
    "end": "60079"
  },
  {
    "text": "this session we actually get to dive into the details about what that means if you're not familiar with open slimmetry open slimmetry is a collection",
    "start": "60079",
    "end": "66880"
  },
  {
    "text": "of tools apis and software development kits that are used to instrument generate and Export Telemetry data that",
    "start": "66880",
    "end": "72040"
  },
  {
    "text": "help you analyze your software's performance and behavior and in Practical terms that actually means it",
    "start": "72040",
    "end": "77080"
  },
  {
    "text": "captures traces and metrics and logs and other types of data from your applications and your infrastructure and it sends them to backends for storage",
    "start": "77080",
    "end": "83680"
  },
  {
    "text": "and Analysis part of the Beauty from open cemetry is you can send that data to effectively anywhere you want which",
    "start": "83680",
    "end": "89040"
  },
  {
    "text": "is very very nice gives you a lot of flexibility gives you ownership over your own data the most used component of",
    "start": "89040",
    "end": "95759"
  },
  {
    "text": "open Telemetry there are many but probably the most popular is the open Telemetry collector this is typically deployed as an agent on each host so",
    "start": "95759",
    "end": "102720"
  },
  {
    "text": "deployed on Windows or on Linux or deployed onto kubernetes clusters and The Collector does a couple things it",
    "start": "102720",
    "end": "108640"
  },
  {
    "text": "captures logs which is what we're talking about today it also captures system metrics so host metrics CPU",
    "start": "108640",
    "end": "113920"
  },
  {
    "text": "memory consumption things like that uh it also captures metrics from thirdparty applications you might be running",
    "start": "113920",
    "end": "119920"
  },
  {
    "text": "databases message cues things where you didn't write the code but you deployed it and there's there sort of you know common things that we know how to",
    "start": "119920",
    "end": "125960"
  },
  {
    "text": "capture metrics for uh importantly The Collector can also receive data from other things other than that uh the most",
    "start": "125960",
    "end": "132800"
  },
  {
    "text": "common of these would be open slet trees language instrumentation so these would be sdks open symmetry has one for every",
    "start": "132800",
    "end": "138720"
  },
  {
    "text": "common programming language and automatic instrumentation agents those send data to The Collector The Collector",
    "start": "138720",
    "end": "143879"
  },
  {
    "text": "then sends that data up or out to wherever you want that data to go you can also pre-process this data in The",
    "start": "143879",
    "end": "149120"
  },
  {
    "text": "Collector not going to talk a whole lot I guess we are going to talk about that today uh we're not going to details for for non- logging use cases today but you",
    "start": "149120",
    "end": "155440"
  },
  {
    "text": "can use the collector to reshape to change the data to change the metadata and it has a ton of power and flexibility",
    "start": "155440",
    "end": "161959"
  },
  {
    "text": "there and it's important to go a bit back in time to talk about why we're even discussing logs here open slimmetry",
    "start": "161959",
    "end": "168239"
  },
  {
    "text": "was announced in 2019 which I mentioned earlier uh originally the vision for open slimmetry was to add support for",
    "start": "168239",
    "end": "173680"
  },
  {
    "text": "distributed traces and for metrics tracing was particularly important the the only sort of tracing solutions back",
    "start": "173680",
    "end": "179640"
  },
  {
    "text": "then then uh for capturing data were always tied to a particular backend they were either vendor specific you'd go",
    "start": "179640",
    "end": "185159"
  },
  {
    "text": "sign up for some vendor APM software they would give you an agent it would capture traces but it would only work with theirs and even open source",
    "start": "185159",
    "end": "191120"
  },
  {
    "text": "Solutions at the time joerger and Zipkin they would have agents or or components that would send traces back to those",
    "start": "191120",
    "end": "197280"
  },
  {
    "text": "specific components open cemetry really democratized this it's it had an independent way to capture distributed",
    "start": "197280",
    "end": "202480"
  },
  {
    "text": "traces that you could send to any back end last year that Vision was extended to metrics as well uh and for logs",
    "start": "202480",
    "end": "209080"
  },
  {
    "text": "though we hit a bit of a question because there are actually many really good solutions for capturing logs that are independent of backends today fluent",
    "start": "209080",
    "end": "216000"
  },
  {
    "text": "comes to mind fluent def fluent bit but there are plenty of others as well and so logging is an area where there were",
    "start": "216000",
    "end": "221360"
  },
  {
    "text": "already uh solutions that were relatively good and relatively well adopted uh and so we wanted to add open",
    "start": "221360",
    "end": "228280"
  },
  {
    "text": "uh logs to open cemetry so that people would have a single place to process and capture their logs they' have one agent",
    "start": "228280",
    "end": "233599"
  },
  {
    "text": "one configuration the benefits of that I think are fairly self-evident uh but we also wanted to go beyond that right if",
    "start": "233599",
    "end": "239400"
  },
  {
    "text": "we were going to tackle logs we'd have to do more than just what is otherwise done in the industry but in open Telemetry and so we went around and we",
    "start": "239400",
    "end": "246319"
  },
  {
    "text": "asked various you know large end users sort of hyperscale cloud companies all the way to just large uh companies",
    "start": "246319",
    "end": "251760"
  },
  {
    "text": "running software at scale uh and also discuss uh met with vendors of logging uh products and also talked with them",
    "start": "251760",
    "end": "258680"
  },
  {
    "text": "and there were a few problems that they pointed out that even with the best logging solutions that existed then this",
    "start": "258680",
    "end": "264639"
  },
  {
    "text": "is in about 2020 uh that they still didn't solve and the first and probably the most prominent was enforcing",
    "start": "264639",
    "end": "270880"
  },
  {
    "text": "consistent semantics and metadata so logs in contrast to metrics and traces are almost always written by a human at",
    "start": "270880",
    "end": "277320"
  },
  {
    "text": "some point right a software developer writes a logging statement that logging statement gets picked up it gets parsed",
    "start": "277320",
    "end": "282360"
  },
  {
    "text": "by a logging agent sent to a back end we all work in Fairly large organizations we have different people writing logging",
    "start": "282360",
    "end": "288039"
  },
  {
    "text": "statements there are many different standards and patterns that get applied to the logs that get authored this is problematic when you actually want to",
    "start": "288039",
    "end": "294440"
  },
  {
    "text": "analyze these logs uh in order to do great aggregate analysis you want metadata from the most basic basic",
    "start": "294440",
    "end": "299840"
  },
  {
    "text": "things like time stamps to more advanced metadata like HTTP semantics for request to be recorded in a way that you can",
    "start": "299840",
    "end": "306240"
  },
  {
    "text": "compare them across logs from different sources this is often very very challenging and it leads to companies",
    "start": "306240",
    "end": "312160"
  },
  {
    "text": "where these are authored differently to either doing one of three things where they either don't update this so they",
    "start": "312160",
    "end": "318080"
  },
  {
    "text": "just simply lose out on logs in their queries when they just don't match uh they try to pre-process their logs and",
    "start": "318080",
    "end": "324240"
  },
  {
    "text": "spend a ton of engineering time and a ton of CPU and memory where they're reshaping logs after they're captured to",
    "start": "324240",
    "end": "330080"
  },
  {
    "text": "put them into the right format or they're writing like the world's most disgusting nasty logging queries that take every single case of metadata into",
    "start": "330080",
    "end": "336639"
  },
  {
    "text": "account these are solutions but none of them are sort of enviable none of these are a good place a good healthy place to",
    "start": "336639",
    "end": "341720"
  },
  {
    "text": "be the other challenges that they pointed out is that logs are log capture is often not super performant so I'm not",
    "start": "341720",
    "end": "348560"
  },
  {
    "text": "talking here about like log processing on the back end of the cost of that but literally the CPU and memory impact of most logging agents is higher than most",
    "start": "348560",
    "end": "355479"
  },
  {
    "text": "people think it should be this isn't to begrudged those logging agents they're very well written generally but the challenge is you have agents that are",
    "start": "355479",
    "end": "361639"
  },
  {
    "text": "parsing human readable text they're doing a fair amount of work because logs are free form and that just simply just",
    "start": "361639",
    "end": "367520"
  },
  {
    "text": "costs a lot of CPU and memory there are other challenges that people pointed out logs aren't typically correlated with",
    "start": "367520",
    "end": "372599"
  },
  {
    "text": "traces and spans at least they weren't when we were having these conversations I think that Gap has actually generally been bridged since then but it's another",
    "start": "372599",
    "end": "378479"
  },
  {
    "text": "thing that open Petry does nicely out of box awesome thanks Morgan um so I'm",
    "start": "378479",
    "end": "384680"
  },
  {
    "text": "going to start with a quick overview of what the rest of this talk will cover so first I'm going to talk very brief about",
    "start": "384680",
    "end": "389800"
  },
  {
    "text": "the evolution of logging uh starting from its very simple Origins all the way to how in open Telemetry integrates with",
    "start": "389800",
    "end": "396280"
  },
  {
    "text": "modern logging Frameworks uh Morgan will tell you about our representation of logs including the data model and",
    "start": "396280",
    "end": "402440"
  },
  {
    "text": "semantic inventions and I'll talk about the open Telemetry collector specifically how it can ingest and parse",
    "start": "402440",
    "end": "408560"
  },
  {
    "text": "logs from many different sources and then finally we'll do a quick demo and wrap up with",
    "start": "408560",
    "end": "414800"
  },
  {
    "text": "Q&A so logs have been around for a very very long time if you sit down to learn",
    "start": "414800",
    "end": "419919"
  },
  {
    "text": "any programming language you immediately write a logging program you might not",
    "start": "419919",
    "end": "425080"
  },
  {
    "text": "think about hello world as a logging program or a Telemetry program but it emits a signal that communicates what is",
    "start": "425080",
    "end": "431319"
  },
  {
    "text": "happening within the application and that's pretty much what Telemetry is all about and from there most aspiring",
    "start": "431319",
    "end": "438280"
  },
  {
    "text": "developers quickly learn the value of dropping these kinds of print statements throughout their code you can see which parts of your code are executing where",
    "start": "438280",
    "end": "444560"
  },
  {
    "text": "your errors are happening what the what values your variables are taking and so on but this approach has many",
    "start": "444560",
    "end": "450479"
  },
  {
    "text": "limitations and so to address those uh dedicated logging libraries were",
    "start": "450479",
    "end": "457000"
  },
  {
    "text": "developed uh so most languages these days have a small number of well established and widely used uh logging",
    "start": "457599",
    "end": "464159"
  },
  {
    "text": "libraries and some are more sophisticated than others on the simpler side of the spectrum you have ones that",
    "start": "464159",
    "end": "469479"
  },
  {
    "text": "pretty much just add a time stamp and maybe a new line to each line to each log but uh at this level you're very",
    "start": "469479",
    "end": "475440"
  },
  {
    "text": "much still just emitting uh information with very minimal stress structure on the other end of the",
    "start": "475440",
    "end": "481759"
  },
  {
    "text": "spectrum you have modern logging Frameworks and these provide a number of other benefits you get your time stamp",
    "start": "481759",
    "end": "487080"
  },
  {
    "text": "but you also they typically impose a some notion of a severity scale uh and",
    "start": "487080",
    "end": "492120"
  },
  {
    "text": "they encourage you to structure the data they'll encourage you to use uh key value pairs so that you can index and",
    "start": "492120",
    "end": "497440"
  },
  {
    "text": "query on the keys uh and they may even include some textual information either automatically or or that you can",
    "start": "497440",
    "end": "504120"
  },
  {
    "text": "optionally provide a simple example is like a logger name which gives you some context of about where the log came from",
    "start": "504120",
    "end": "509879"
  },
  {
    "text": "within your code base so um the other important thing that uh these modern logging libraries",
    "start": "509879",
    "end": "516839"
  },
  {
    "text": "allow you to do is to conf to independently configure where the logs will go from your application uh",
    "start": "516839",
    "end": "523039"
  },
  {
    "text": "separately from you know the actual logging statements in your code that describe what information you think is",
    "start": "523039",
    "end": "528160"
  },
  {
    "text": "relevant to capture so 's a concrete example uh log for J is popular in the Java world and",
    "start": "528160",
    "end": "535160"
  },
  {
    "text": "they have a concept called appenders which allow you to uh to do this to um say where you'd like your logs to go uh",
    "start": "535160",
    "end": "541440"
  },
  {
    "text": "this example is very simple we're just formatting a log into a line of text and then uh printing it to standard out so",
    "start": "541440",
    "end": "547519"
  },
  {
    "text": "it's just a fancy Hello World um but because we're using this logging framework we can very easily reconfigure",
    "start": "547519",
    "end": "554000"
  },
  {
    "text": "where the logs would go just by changing the appender or adding another appender so uh we have an open Telemetry appender",
    "start": "554000",
    "end": "561240"
  },
  {
    "text": "here so this will convert the uh logs into open telemetry's representation and",
    "start": "561240",
    "end": "567519"
  },
  {
    "text": "allow you to transmit them directly to an open Telemetry collector or to a backend using",
    "start": "567519",
    "end": "573240"
  },
  {
    "text": "OTP so ideally uh to make this switch you don't really need to write any new code aside from a little bit of",
    "start": "573240",
    "end": "579279"
  },
  {
    "text": "configuration um and um you know these appenders are written using what we call",
    "start": "579279",
    "end": "584680"
  },
  {
    "text": "a logbridge API and SDK we have these available in several languages today and",
    "start": "584680",
    "end": "589920"
  },
  {
    "text": "the rest of the languages supported by open Telemetry should follow fairly quickly um these make the process of",
    "start": "589920",
    "end": "596720"
  },
  {
    "text": "developing these appenders easier U and they help to ensure that the uh the appender adheres to the open Telemetry",
    "start": "596720",
    "end": "603839"
  },
  {
    "text": "specification we have appenders available today in a for several popular logging Frameworks uh but the general",
    "start": "603839",
    "end": "610560"
  },
  {
    "text": "goal here is that most popular Frameworks and most popular languages will eventually have an open simetry",
    "start": "610560",
    "end": "616480"
  },
  {
    "text": "appender and by the way if you're the kind of person who's inclined to write an appender for a framework that you are",
    "start": "616480",
    "end": "621720"
  },
  {
    "text": "using uh please consider contributing that back to the open slum project we'd like we'd love to have",
    "start": "621720",
    "end": "628040"
  },
  {
    "text": "it so taking a step back this approach we've taken with logs is different than",
    "start": "628040",
    "end": "634320"
  },
  {
    "text": "what we did with metrics and tracing instrumentation uh and the reason is basically just because of these logging",
    "start": "634320",
    "end": "639720"
  },
  {
    "text": "Frameworks they are ubiquitous and mature and the appender pattern gives us everything that we need we",
    "start": "639720",
    "end": "646720"
  },
  {
    "text": "can apply a set of semantics across all Telemetry types and we can consistently",
    "start": "646720",
    "end": "652760"
  },
  {
    "text": "correlate Logs with the other data types by annotating the same contextual information so the resource that emitted",
    "start": "652760",
    "end": "658680"
  },
  {
    "text": "the signal or in many cases the transaction that triggered the",
    "start": "658680",
    "end": "664399"
  },
  {
    "text": "Telemetry and we're also achieving substantial performance benefits this way versus the use of traditional",
    "start": "664399",
    "end": "669560"
  },
  {
    "text": "appenders and again primarily this is because we don't have to rein just and parse the logs we can just trans they",
    "start": "669560",
    "end": "675600"
  },
  {
    "text": "they originate in open telemetries format and then they stay in it uh so I'll talk more about the",
    "start": "675600",
    "end": "681880"
  },
  {
    "text": "collector in a minute but Morgan's going to take you through the data model yeah so there's two actual things to talk",
    "start": "681880",
    "end": "687639"
  },
  {
    "text": "about here so open SL has its core data model this is the data model that is present on every single signal that open",
    "start": "687639",
    "end": "694200"
  },
  {
    "text": "Telemetry captures most of the fields are required it is a nice strongly type thing that is always there and it",
    "start": "694200",
    "end": "699839"
  },
  {
    "text": "includes the fields you would expect for a metric a trace a log and future profile anything like that so time",
    "start": "699839",
    "end": "705440"
  },
  {
    "text": "stamps uh trace and spans if some if a log is going to be correlated with a with a trace or span uh as well as",
    "start": "705440",
    "end": "711959"
  },
  {
    "text": "information like the resource information resource information is probably the most critical part of this that defines the host or the the cluster",
    "start": "711959",
    "end": "718639"
  },
  {
    "text": "or sort of basic host information where a log or other signal was captured from it also describes the surface",
    "start": "718639",
    "end": "724040"
  },
  {
    "text": "information that's really important when you actually want to correlate a log with a trace with a metric or something else this is all the standard open",
    "start": "724040",
    "end": "731000"
  },
  {
    "text": "cemetry data model that you've seen before there's no major changes here what's being added or or what's being",
    "start": "731000",
    "end": "736320"
  },
  {
    "text": "extended really is semantics so these are fields that are very particular to",
    "start": "736320",
    "end": "741440"
  },
  {
    "text": "the situation in which a signal is captur these are not specific to logs but they're probably most relevant for logs so if you think of an HTTP that",
    "start": "741440",
    "end": "748920"
  },
  {
    "text": "Quest that gets captured using open symmetries now 1.0 HTTP uh semantics you would capture things like the error code",
    "start": "748920",
    "end": "756160"
  },
  {
    "text": "or the latency or other sort of core information about that HTTP request that would get encoded into the log this is",
    "start": "756160",
    "end": "761560"
  },
  {
    "text": "also strongly typed uh it is also uh typically binary formatted when the log is being transmitted and so it's",
    "start": "761560",
    "end": "767639"
  },
  {
    "text": "something that can be read very performant and critically this guarantees the metadata will be the same because it forces you to enter it in the",
    "start": "767639",
    "end": "774279"
  },
  {
    "text": "same way it is checked and tested throughout the pipeline all right let's talk about the",
    "start": "774279",
    "end": "780160"
  },
  {
    "text": "collector so this is if you're not familiar it's a standalone process that can ingest metrics traces logs from many",
    "start": "780160",
    "end": "786240"
  },
  {
    "text": "different sources and then it can process those signals in many different ways and ultimately forward them to the",
    "start": "786240",
    "end": "792560"
  },
  {
    "text": "back end of your choice uh most users of open Telemetry will find the collector useful in one way or",
    "start": "792560",
    "end": "798440"
  },
  {
    "text": "another so like the rest of the project The Collector first supported traces and then metrics but the intention from",
    "start": "798440",
    "end": "804199"
  },
  {
    "text": "early on was to natively support the ingestion and parsing of logs basic basically we want to have a single",
    "start": "804199",
    "end": "810480"
  },
  {
    "text": "process that handles all types of telemetry so this was largely bootstrapped by a donation from observe",
    "start": "810480",
    "end": "816000"
  },
  {
    "text": "IQ we had developed a standalone log agent with a broad set of ingestion and parsing capabilities and in 2021 we",
    "start": "816000",
    "end": "824040"
  },
  {
    "text": "agreed to donate that agent to open Telemetry integrate it directly into the collector and continue development from",
    "start": "824040",
    "end": "830360"
  },
  {
    "text": "there so over the last three years with a lot of great contributions from the community and a lot of good feedback um",
    "start": "830360",
    "end": "837000"
  },
  {
    "text": "that codebase has been integrated into the colle collector uh refined hardened and at this point many organizations",
    "start": "837000",
    "end": "843120"
  },
  {
    "text": "actually will take their first steps into the open Telemetry ecosystem by deploying The Collector as a traditional",
    "start": "843120",
    "end": "848240"
  },
  {
    "text": "log agent first and then layering on additional capabilities from",
    "start": "848240",
    "end": "854160"
  },
  {
    "text": "there uh let's go one one layer deeper here on what the collector can actually do uh so we've talked about",
    "start": "854199",
    "end": "860079"
  },
  {
    "text": "instrumentation so just to reiterate uh if you're using any kind of open Telemetry instrumentation including open",
    "start": "860079",
    "end": "866399"
  },
  {
    "text": "Telemetry log appenders you can forward very easily forward your data to The Collector using otpr native",
    "start": "866399",
    "end": "872880"
  },
  {
    "text": "protocol if you are using another log agent such as fluent bit you can very",
    "start": "872880",
    "end": "877959"
  },
  {
    "text": "easily bring that data into the open Telemetry ecosystem you can just send that to The Collector it will translate",
    "start": "877959",
    "end": "883079"
  },
  {
    "text": "it into open telemetry's representation and then you can work with it natively from there and as I mentioned we have now",
    "start": "883079",
    "end": "891240"
  },
  {
    "text": "many capabilities in The Collector for reading from other data sources we can read application logs from files we can",
    "start": "891240",
    "end": "897360"
  },
  {
    "text": "read system logs from Journal or Windows Event log we support CIS log and some other options as well and again this is",
    "start": "897360",
    "end": "904360"
  },
  {
    "text": "all built directly into the collector so it runs within a single process and there are no external",
    "start": "904360",
    "end": "910399"
  },
  {
    "text": "dependencies so one of the challenges uh with ingesting logs from traditional sources is the the representation varies",
    "start": "911000",
    "end": "917680"
  },
  {
    "text": "so widely um some logs are well- defined Json structures others are pretty much just free form text and we see",
    "start": "917680",
    "end": "924279"
  },
  {
    "text": "everything in between so in order to support these uh in the collector in",
    "start": "924279",
    "end": "929480"
  },
  {
    "text": "order to make it possible to interpret this into the open Telemetry data model no matter which format you're starting",
    "start": "929480",
    "end": "936160"
  },
  {
    "text": "from we need a very flexible solution so to solve this we have a very broad set",
    "start": "936160",
    "end": "942160"
  },
  {
    "text": "of granular capabilities which you can compose as necessary to extract",
    "start": "942160",
    "end": "947560"
  },
  {
    "text": "individual values from free form text uh to manipulate and interpret and",
    "start": "947560",
    "end": "953040"
  },
  {
    "text": "ultimately parse these values into the right data types and then assign them into the correct Fields within the open",
    "start": "953040",
    "end": "958759"
  },
  {
    "text": "Telemetry data model and then on top of this shared set of capabilities we built",
    "start": "958759",
    "end": "964120"
  },
  {
    "text": "a series of log receivers so each of these corresponds to a traditional mechanism for transmitting logs so",
    "start": "964120",
    "end": "970079"
  },
  {
    "text": "wherever your logs are already going you can point the appropriate log receiver to that log source and then you can",
    "start": "970079",
    "end": "975920"
  },
  {
    "text": "apply any necessary operations to interpret them into the data model um this isn't a tutorial on log",
    "start": "975920",
    "end": "983759"
  },
  {
    "text": "parsing so I'm going to I'll keep this example brief but just to give you a sense of these capabilities and what",
    "start": "983759",
    "end": "989079"
  },
  {
    "text": "this kind of looks like in practice uh let's say we want to uh parse this log file so first of all we'll use the file",
    "start": "989079",
    "end": "995440"
  },
  {
    "text": "log receiver which can find track and read files it handles file rotation and",
    "start": "995440",
    "end": "1001240"
  },
  {
    "text": "other common uh log file patterns um so the basic idea is that we will reading",
    "start": "1001240",
    "end": "1006279"
  },
  {
    "text": "the contents and tokenize it into individual log records very commonly that just means One log per line but",
    "start": "1006279",
    "end": "1012120"
  },
  {
    "text": "that's not always a case and we can handle a variety of situations there um",
    "start": "1012120",
    "end": "1017560"
  },
  {
    "text": "so in this case we just just let's say we get our uh we get the first log we've isolated it what we'll do is we create a",
    "start": "1017560",
    "end": "1023360"
  },
  {
    "text": "log record object and assign that value into the body of that and then we'll process it from there so as you would",
    "start": "1023360",
    "end": "1030319"
  },
  {
    "text": "expect we have a Rex parsing utility and this just allows us to isolate pieces of information from that log and give them",
    "start": "1030319",
    "end": "1036400"
  },
  {
    "text": "names so that we can work with them further time stamps pretty naturally you",
    "start": "1036400",
    "end": "1041600"
  },
  {
    "text": "can define a a time stamp layout and then parse that into a Unix Tim stamp assign that into the time field in our",
    "start": "1041600",
    "end": "1048000"
  },
  {
    "text": "data model for severity we have a very flexible system as well um there's uh many",
    "start": "1048000",
    "end": "1054679"
  },
  {
    "text": "different severity scales out there in open Telemetry is just one of them so we no matter which scale you're coming from",
    "start": "1054679",
    "end": "1060120"
  },
  {
    "text": "you need to be able to basically just Define the mapping from that scale to open Telemetry so any string set of",
    "start": "1060120",
    "end": "1066799"
  },
  {
    "text": "strings number range of numbers can be corresponded to directly to an open Telemetry severity level and then it",
    "start": "1066799",
    "end": "1073120"
  },
  {
    "text": "will just automatically interpret those this uh structured piece is obviously Json but it's technically a",
    "start": "1073120",
    "end": "1080400"
  },
  {
    "text": "string so we can parse this into a Json object and that gives us access to the fields within",
    "start": "1080400",
    "end": "1085520"
  },
  {
    "text": "it and then this value has apparently some structure so uh we can extract some",
    "start": "1085520",
    "end": "1091159"
  },
  {
    "text": "more information and then let's just say that type fu is a piece of information we maybe it matches a semantic",
    "start": "1091159",
    "end": "1097159"
  },
  {
    "text": "convention or uh it's just something we want to be able to index and query on we can move it into the log record",
    "start": "1097159",
    "end": "1102840"
  },
  {
    "text": "attributes and then optionally now that we've parsed out a bunch of uh all the rest of the information we can put the",
    "start": "1102840",
    "end": "1109360"
  },
  {
    "text": "remaining free form text back in the body or optionally if you like you can just leave the body as is it has the",
    "start": "1109360",
    "end": "1114559"
  },
  {
    "text": "original log record that way so it's this kind of um composition",
    "start": "1114559",
    "end": "1119919"
  },
  {
    "text": "of discrete operations that gives us uh the ability to interpret pretty much any",
    "start": "1119919",
    "end": "1125360"
  },
  {
    "text": "logs uh into the open Telemetry data model uh now as much as I think these uh",
    "start": "1125360",
    "end": "1133080"
  },
  {
    "text": "ingestion and parsing capabilities in The Collector are both robust and I think competitively per perform it with",
    "start": "1133080",
    "end": "1138840"
  },
  {
    "text": "other logging agents I do want to reiterate that all things being equal uh you can save a lot of uh cost and and",
    "start": "1138840",
    "end": "1145760"
  },
  {
    "text": "avoid some risk if you're able to instrum to capture and transmit logs using instrumentation because you don't",
    "start": "1145760",
    "end": "1151159"
  },
  {
    "text": "have to do all of this tracking of files reading files injesting from files parsing and so on and I think probably a",
    "start": "1151159",
    "end": "1158600"
  },
  {
    "text": "pattern that many people would follow off this was for existing applications where you don't want to touch them you don't want to rewrite them you can start",
    "start": "1158600",
    "end": "1164280"
  },
  {
    "text": "capturing logs of open Telemetry from those files using the collector right now but if you're writing a new application we strongly tell you to",
    "start": "1164280",
    "end": "1170720"
  },
  {
    "text": "consider um uh using instrumentation to capture those logs the performance will be better you're guaranteed to get that",
    "start": "1170720",
    "end": "1176320"
  },
  {
    "text": "metadata coming through consistently exactly the it's the instrumentation can automatically apply",
    "start": "1176320",
    "end": "1182120"
  },
  {
    "text": "the the semantics and the the context to logs just as well as the other signals and uh that's going to be something I'll",
    "start": "1182120",
    "end": "1188039"
  },
  {
    "text": "show you here in this demo how that how that comes to uh or how that becomes an advantage so the the scenario here is",
    "start": "1188039",
    "end": "1194280"
  },
  {
    "text": "I'm running the open Telemetry demo application this is a microservices application where where each service is written in a different language but",
    "start": "1194280",
    "end": "1200720"
  },
  {
    "text": "they're all using open Telemetry instrumentation and then I'm sending um logs logs in spans from all of these",
    "start": "1200720",
    "end": "1208159"
  },
  {
    "text": "services to a collector which I'll run locally and then within that collector I",
    "start": "1208159",
    "end": "1213360"
  },
  {
    "text": "will make sampling decisions that apply across the data types so this is something fundamental to the open",
    "start": "1213360",
    "end": "1218720"
  },
  {
    "text": "Telemetry data model that we have these cross cutting contexts we have Trace context resource context uh",
    "start": "1218720",
    "end": "1225120"
  },
  {
    "text": "instrumentation scope corresponds to the part of the code that the the signal came",
    "start": "1225120",
    "end": "1230520"
  },
  {
    "text": "from um so we're able to make these kinds of decisions um and then I'm just emitting this to two different files so",
    "start": "1230520",
    "end": "1237080"
  },
  {
    "text": "we can see which spans and which logs were sampled I'm just using these as an approximation of a backend this is a",
    "start": "1237080",
    "end": "1242440"
  },
  {
    "text": "demo I want to keep it simple okay so let me try to get this",
    "start": "1242440",
    "end": "1250080"
  },
  {
    "text": "started of",
    "start": "1250480",
    "end": "1253720"
  },
  {
    "text": "course y all right so first I'm running a",
    "start": "1257120",
    "end": "1264679"
  },
  {
    "text": "collector locally and I'm starting the demo",
    "start": "1264679",
    "end": "1270799"
  },
  {
    "text": "application and then I'm just going to immediately begin tailing files from the",
    "start": "1270799",
    "end": "1276919"
  },
  {
    "text": "basically tailing out the logs that we've sampled now just to while this uh while this starts up and runs we may not",
    "start": "1276919",
    "end": "1283559"
  },
  {
    "text": "see a log for a minute here but uh you know why is this important um um you",
    "start": "1283559",
    "end": "1289320"
  },
  {
    "text": "know if you've ever worked with spans or logs at scale like you pretty much have to do some sampling right and uh the",
    "start": "1289320",
    "end": "1295919"
  },
  {
    "text": "problem traditionally is that you make sampling decisions about spans independently from logs or metrics but",
    "start": "1295919",
    "end": "1302520"
  },
  {
    "text": "with these crosscutting contexts that we have built into our data model we can make these decisions once and then apply",
    "start": "1302520",
    "end": "1308200"
  },
  {
    "text": "them across the board so if you if we were to for example make a",
    "start": "1308200",
    "end": "1313720"
  },
  {
    "text": "uh sample just randomly one Trace out of a thousand uh uh and then keep the spans",
    "start": "1313720",
    "end": "1319760"
  },
  {
    "text": "from that trace and then made a similar kind of determination for logs we' have a very little chance that there's any",
    "start": "1319760",
    "end": "1325679"
  },
  {
    "text": "overlap in the data that we've sampled one out of a million basically yeah yeah",
    "start": "1325679",
    "end": "1331039"
  },
  {
    "text": "so um but that's the uh sampling ratio I'm using here um but I think in a",
    "start": "1331039",
    "end": "1336159"
  },
  {
    "text": "minute here we will see uh that we've sampled some logs and then I can show you that we've also sampled corresponding spans yeah just to",
    "start": "1336159",
    "end": "1343279"
  },
  {
    "text": "reiterate the beauty here is that your tracing sampling decisions here are driving the logging samp decisions so",
    "start": "1343279",
    "end": "1348880"
  },
  {
    "text": "every Trace will have the full set of logs that is super super super super important assuming we generate I'm I'll",
    "start": "1348880",
    "end": "1357360"
  },
  {
    "text": "show you the configuration in the meantime so this is um there we go this is the configuration I'm using just",
    "start": "1357360",
    "end": "1364320"
  },
  {
    "text": "receiving with an OTL receiver uh and then ultimately writing uh with an exporter and then this is a just a proof",
    "start": "1364320",
    "end": "1370520"
  },
  {
    "text": "of concept connector but the principle is designed into our data model but again I'm just using a one in a th000",
    "start": "1370520",
    "end": "1376159"
  },
  {
    "text": "sampling rate to make a decision about about a trace ID it doesn't matter if the trace ID is first observed from a",
    "start": "1376159",
    "end": "1381760"
  },
  {
    "text": "log or a span I'll make that decision the first time I see it and then apply it to any additional spans or logs that",
    "start": "1381760",
    "end": "1387440"
  },
  {
    "text": "come through and as long as the if the sampling decision is embedded into those logs that means that you can achieve",
    "start": "1387440",
    "end": "1393600"
  },
  {
    "text": "this even if you're just picking up those logs from a file on disk I think in this case we're doing this directly through instrumentation correct correct",
    "start": "1393600",
    "end": "1400200"
  },
  {
    "text": "yeah so in this case the the sampling decision can actually be made within the application in process and the instrumentation very simple but if that",
    "start": "1400200",
    "end": "1405960"
  },
  {
    "text": "sampling decision is in from the trace embedded in logs you can still make that decision in The Collector using the processing that Dan was showing earlier",
    "start": "1405960",
    "end": "1413760"
  },
  {
    "text": "so we did sample eventually a log I copied its Trace ID here and then",
    "start": "1413760",
    "end": "1419320"
  },
  {
    "text": "searched the uh file with all the spans in it to just show that we also have spans from that that same",
    "start": "1419320",
    "end": "1425320"
  },
  {
    "text": "Trace so this this is a scenario that you typically I guess it would be it",
    "start": "1425320",
    "end": "1431000"
  },
  {
    "text": "would be very very difficult to pull off using existing existing techniques so this is very very important all right so we're going to",
    "start": "1431000",
    "end": "1437279"
  },
  {
    "text": "recap a few things things before we jump into questions I think open Telemetry logging is very very important right like we announced like I said metrics",
    "start": "1437279",
    "end": "1443880"
  },
  {
    "text": "last year tracing a few years before that but logging is important for a few reasons first is you can now use open",
    "start": "1443880",
    "end": "1449000"
  },
  {
    "text": "cemetry as your primary data collection agent you don't have to use open symetry for traces and maybe metrics and",
    "start": "1449000",
    "end": "1454400"
  },
  {
    "text": "something else for logs that alone is a very big deal we expect that to drive a ton of adoption of this and we're very",
    "start": "1454400",
    "end": "1460279"
  },
  {
    "text": "very excited for that it also means you're using a single configuration a single set of uh uh rules for",
    "start": "1460279",
    "end": "1465640"
  },
  {
    "text": "pre-processing if you want to do pre-processing like some of the things that Dan was showing earlier it makes it just a lot easier to manage uh your",
    "start": "1465640",
    "end": "1472799"
  },
  {
    "text": "traces metrics and log collection at scale because you have that one agent and one semantics and one sort of schema",
    "start": "1472799",
    "end": "1478640"
  },
  {
    "text": "for configuring it and managing it it also means you can uh choose where to send that data for all of your different data",
    "start": "1478640",
    "end": "1484120"
  },
  {
    "text": "types uh it also guarantees you have consistent metadata across not just your logs that alone is is a big achievement",
    "start": "1484120",
    "end": "1490600"
  },
  {
    "text": "but also across your metrics and traces which makes the insights that you can glean from all of those different types",
    "start": "1490600",
    "end": "1495880"
  },
  {
    "text": "of data all the more powerful because that data is guaranteed that that metadata is guaranteed to be the same it",
    "start": "1495880",
    "end": "1501679"
  },
  {
    "text": "means you can do things like quickly isolate all of your Telemetry all of your signals from a given host or a given service at times that can be",
    "start": "1501679",
    "end": "1507960"
  },
  {
    "text": "challenging across traces metrics and logs even today it also means you can show all of the logs for a given Trace",
    "start": "1507960",
    "end": "1513640"
  },
  {
    "text": "as we were showing or even sample your logs so that they're sampled consistently with your traces again",
    "start": "1513640",
    "end": "1519039"
  },
  {
    "text": "that's very very uh difficult if not impossible to achieve today it also means that you you in most situations",
    "start": "1519039",
    "end": "1524919"
  },
  {
    "text": "will not need massive clusters of servers for log shaping and field extraction of course if you want to do custom things with your logs then yes",
    "start": "1524919",
    "end": "1530679"
  },
  {
    "text": "you'll still need to do that but if you just want to ensure that your logs have a consistent shape and consistent sematics that is guaranteed at the",
    "start": "1530679",
    "end": "1537679"
  },
  {
    "text": "source you the developer and operator are not responsible for reshaping them or writing those nasty log queries that",
    "start": "1537679",
    "end": "1543600"
  },
  {
    "text": "I'm sure we're all pretty familiar with at this point this is very good finally if you're capturing those logs directly",
    "start": "1543600",
    "end": "1549679"
  },
  {
    "text": "from instrumentation you're dramatically reducing your compute in memory overhead of capturing those logs because they're just staying in that that open symetry",
    "start": "1549679",
    "end": "1556480"
  },
  {
    "text": "type the entire way you aren't burning a bunch of CPU in memory on each host or within yeah on each host uh to go and",
    "start": "1556480",
    "end": "1563480"
  },
  {
    "text": "extract fields from those logs uh so that you can get them into the correct shape or just better understand them so",
    "start": "1563480",
    "end": "1568720"
  },
  {
    "text": "this is very exciting again like this is a big deal for the logging space it's also a big deal for open cemetry we're",
    "start": "1568720",
    "end": "1573880"
  },
  {
    "text": "excited to see where this goes certainly our experience of metrics last year is that the uptake was very very quick and",
    "start": "1573880",
    "end": "1579399"
  },
  {
    "text": "very rapidly as maintainers an open ceter we started getting uh great feature requests and other things submitted into the project and we're",
    "start": "1579399",
    "end": "1584799"
  },
  {
    "text": "expecting to see the same with logs uh with that we'd be happy to take any of your questions so there's a microphone",
    "start": "1584799",
    "end": "1590039"
  },
  {
    "text": "there or if people want to raise their hand we can call them out and uh shout but we'd prefer the microphone if you're",
    "start": "1590039",
    "end": "1595360"
  },
  {
    "text": "willing to go up yes hey so one thing that some developers do is they have logs that",
    "start": "1595360",
    "end": "1602080"
  },
  {
    "text": "actually are metrics right the log is you know just one thing um are there plans to have like a connector or",
    "start": "1602080",
    "end": "1608440"
  },
  {
    "text": "something to convert data that's inest as a log into a metric like is that like log metrization yeah um I think you can",
    "start": "1608440",
    "end": "1614760"
  },
  {
    "text": "do that today in The Collector um there there are some there's like a counting connector but there's uh and what you're",
    "start": "1614760",
    "end": "1621039"
  },
  {
    "text": "talking about I think is more like extracting it uh contextually from there yeah that um I think Observer Q has a",
    "start": "1621039",
    "end": "1626919"
  },
  {
    "text": "component like this and we'd like to Upstream that at some point here so I I think others in the community have asked for this too it's just a matter of uh",
    "start": "1626919",
    "end": "1633080"
  },
  {
    "text": "getting the contribution made so cool exciting yeah and you can already do the counts I think of logs today in The Collector yeah please um when thinking",
    "start": "1633080",
    "end": "1641640"
  },
  {
    "text": "about receiving logs directly through OTP um do you see a risk with data loss",
    "start": "1641640",
    "end": "1647039"
  },
  {
    "text": "and if if so like what what would be the recommendation to to deal with that I",
    "start": "1647039",
    "end": "1652279"
  },
  {
    "text": "ask you this this morning so you canile right where the guarantee that and it's a good question because like I've run",
    "start": "1652279",
    "end": "1658880"
  },
  {
    "text": "into examples today with customers of ours where where um uh even with traditional logs right if if you can't",
    "start": "1658880",
    "end": "1665519"
  },
  {
    "text": "pick them up from dis fast enough they get right and then they fill the buffer and then some are lost and so you're really asking like with instrumentation",
    "start": "1665519",
    "end": "1671679"
  },
  {
    "text": "what happens there I will defer to Dan for that well I'll say that I know this is OB some obvious consideration that's",
    "start": "1671679",
    "end": "1679480"
  },
  {
    "text": "taken into account and we have to design uh well the instrumentation is designed with this kind of thing in mind with",
    "start": "1679480",
    "end": "1685880"
  },
  {
    "text": "like queuing and whatnot um but I don't spend much time in the instrumentation myself actually so I don't actually have",
    "start": "1685880",
    "end": "1691600"
  },
  {
    "text": "a great answer for you U that that is the one question we were hoping not to get because neither of us know the actual answer to it uh for for pulling",
    "start": "1691600",
    "end": "1698360"
  },
  {
    "text": "up for parsing logs from dis there's a bunch of considerations that have been made but for direct ones I think that",
    "start": "1698360",
    "end": "1703399"
  },
  {
    "text": "things have done I'm looking at Demitri over there to see no he's giv me a face okay um we'll have to answer that later",
    "start": "1703399",
    "end": "1710399"
  },
  {
    "text": "hi uh quick question about sample rate uh adjustments in real time so like if",
    "start": "1710399",
    "end": "1716760"
  },
  {
    "text": "suddenly you see a flood of Errors will the sample rate dynamically increase to get more traces and spans and more",
    "start": "1716760",
    "end": "1722880"
  },
  {
    "text": "information from that so the the the demo that I did just there was just a",
    "start": "1722880",
    "end": "1728480"
  },
  {
    "text": "very simple proof of concept that's just using probabilistic sampling which is like the simplest you can get um but in",
    "start": "1728480",
    "end": "1734720"
  },
  {
    "text": "principle any criteria or strategy stry that you could apply you know on the",
    "start": "1734720",
    "end": "1739919"
  },
  {
    "text": "tracing context you're basically just making a decision about a given Trace ID given whatever the criteria is to sample",
    "start": "1739919",
    "end": "1746960"
  },
  {
    "text": "it or not and um the the ability to sample it across data types um could be",
    "start": "1746960",
    "end": "1755320"
  },
  {
    "text": "applied regardless so I think you can have Dynamic sampling like you're describing there and and do the same",
    "start": "1755320",
    "end": "1760720"
  },
  {
    "text": "thing in principle the short answer is yes right like again in that demo the log sampling is just following the trace",
    "start": "1760720",
    "end": "1766559"
  },
  {
    "text": "sampling you could do Dynamic sampling of traces today in hotel and whatever you have for logs would follow that in",
    "start": "1766559",
    "end": "1771600"
  },
  {
    "text": "this example please thank you so configuring",
    "start": "1771600",
    "end": "1777240"
  },
  {
    "text": "complex logging agent has a problem that if you have you know like the transformation routing multiple outputs",
    "start": "1777240",
    "end": "1784200"
  },
  {
    "text": "so the the main problem usually is debugging you know what happens with my log and you know sometimes you got",
    "start": "1784200",
    "end": "1789279"
  },
  {
    "text": "exceptions so you need you know the error cast as well so I'm just curious about you know if there is any future",
    "start": "1789279",
    "end": "1795960"
  },
  {
    "text": "plan about you know how to bu those configuration how to you know handle erroring errors and things like this so",
    "start": "1795960",
    "end": "1802760"
  },
  {
    "text": "we actually have a lot in there today uh for this um so one thing you can do is",
    "start": "1802760",
    "end": "1808640"
  },
  {
    "text": "you can basically among these uh many operators that as we call them in there uh we have a router so you can identify",
    "start": "1808640",
    "end": "1815320"
  },
  {
    "text": "specific formats that you know how to parse and then everything else you can send somewhere else to uh later look at",
    "start": "1815320",
    "end": "1821760"
  },
  {
    "text": "and say okay I didn't expect this format how do I handle this um there is also Al",
    "start": "1821760",
    "end": "1828000"
  },
  {
    "text": "um there are some some ways to sort of bail out early and just print to another",
    "start": "1828000",
    "end": "1833640"
  },
  {
    "text": "file or standard out uh if you're actively debugging it the other thing is",
    "start": "1833640",
    "end": "1838720"
  },
  {
    "text": "can I have a follow up on that so for example destination debug is interesting because I can when I'm dumping something",
    "start": "1838720",
    "end": "1844559"
  },
  {
    "text": "into file it has a format you know like Json format but if I'm using you know like a service that has specific HTTP",
    "start": "1844559",
    "end": "1851559"
  },
  {
    "text": "request I need the HTTP request dumped because that's where you know like the formatic happens at the destination",
    "start": "1851559",
    "end": "1858000"
  },
  {
    "text": "level so things like this I I thinking about this that uh is it will be it",
    "start": "1858000",
    "end": "1864000"
  },
  {
    "text": "possible you know for example D the request because maybe there is you know like SSL everything in place so I can't",
    "start": "1864000",
    "end": "1870440"
  },
  {
    "text": "you know easily uh TCP down the the the Stu but I really need you know the the",
    "start": "1870440",
    "end": "1875880"
  },
  {
    "text": "payload that uh it sends or the a uh the UR or or this kind of stuff yeah I I",
    "start": "1875880",
    "end": "1882880"
  },
  {
    "text": "don't think that's a log specific problem um so I think whatever we whatever Solutions we have um or will",
    "start": "1882880",
    "end": "1889240"
  },
  {
    "text": "have uh prob address broadly so yeah yeah this is probably an a question but",
    "start": "1889240",
    "end": "1895600"
  },
  {
    "text": "uh can you talk a little bit about how scalability Works in The Collector because if you get just a lot of a huge",
    "start": "1895600",
    "end": "1902279"
  },
  {
    "text": "amount of logs obviously you're going to overload something and then if you're doing correlation kind of the like span",
    "start": "1902279",
    "end": "1907799"
  },
  {
    "text": "ID the trace ID request across all these different streams you have to have some clustering or some interprocess",
    "start": "1907799",
    "end": "1913519"
  },
  {
    "text": "communication between the charts and the cluster so how does that all work yeah so there's you have the ability to there's a load balancing exporter in The",
    "start": "1913519",
    "end": "1920279"
  },
  {
    "text": "Collector which you can use to uh you know basically provide Affinity based on",
    "start": "1920279",
    "end": "1926360"
  },
  {
    "text": "Trace ID to one collector or another and so you can sort of like load balance and distribute your load and then make your",
    "start": "1926360",
    "end": "1932320"
  },
  {
    "text": "sampling",
    "start": "1932320",
    "end": "1934720"
  },
  {
    "text": "decisions if you need to be doing that level of processing yeah I would say for the for the examples like this yeah",
    "start": "1938559",
    "end": "1945080"
  },
  {
    "text": "straightforward examples you're not going to need that yeah yeah",
    "start": "1945080",
    "end": "1950559"
  },
  {
    "text": "yeah yeah uh so the idea to sample both logs and traces is is really interesting",
    "start": "1950559",
    "end": "1955840"
  },
  {
    "text": "and I noticed the examples we have here are more about head based sampling y I'm wondering like has anybody explored it",
    "start": "1955840",
    "end": "1961840"
  },
  {
    "text": "seems like it would be possible to do tail based sampling with this model as well if I'm just wondering there sort of",
    "start": "1961840",
    "end": "1967080"
  },
  {
    "text": "scalability implications of that because usually you've got more logs than you've got so you can do tailbase sampling on",
    "start": "1967080",
    "end": "1972279"
  },
  {
    "text": "The Collector today I will say like I think there was a lot of enthusiasm about this probably like two or three",
    "start": "1972279",
    "end": "1977919"
  },
  {
    "text": "years ago for for tracing ignoring logs for a moment um I will say in my experience the compute and storage and",
    "start": "1977919",
    "end": "1983840"
  },
  {
    "text": "memory overhead of doing tailbase sampling The Collector is substantial uh and it's not even like a collector needs",
    "start": "1983840",
    "end": "1989600"
  },
  {
    "text": "to be optimized thing it's just the you're basically processing traces and then sending the spans on to be processed again um but that being said",
    "start": "1989600",
    "end": "1997279"
  },
  {
    "text": "yeah you like in theory and in practice you can actually do that today right now for the traces and the logs would of course just follow the decisions you",
    "start": "1997279",
    "end": "2003399"
  },
  {
    "text": "make for the traces assuming you set it up the way we did hey another scalability question um it",
    "start": "2003399",
    "end": "2009760"
  },
  {
    "text": "sounds like to clarify um application logs if you're instrumented um sounds like very reliable process reading from",
    "start": "2009760",
    "end": "2016639"
  },
  {
    "text": "disk um there needs to be some considerations can you speak on speak to that for reading the dog logs from dis and how that works yeah so that's that's",
    "start": "2016639",
    "end": "2023240"
  },
  {
    "text": "the stuff that we weren't showing in the demo that we talked about earlier where yeah that's built in now to The Collector first class you can point it",
    "start": "2023240",
    "end": "2029120"
  },
  {
    "text": "at log files uh so again it wasn't live demo but it was the slides we were showing where you can you know Define",
    "start": "2029120",
    "end": "2034559"
  },
  {
    "text": "rules in The Collector to extract certain fields and treat them different way ways it's pretty robust like speaking for myself we've had customers",
    "start": "2034559",
    "end": "2041120"
  },
  {
    "text": "who've been using this uh majority of our customers from kubernetes sources for over a year even before it went GA",
    "start": "2041120",
    "end": "2046559"
  },
  {
    "text": "and that's using traditional locking paths not the inprocess path so it it works quite well one more question yeah um you",
    "start": "2046559",
    "end": "2054560"
  },
  {
    "text": "mentioned uh the exporters that are baked into that collector yeah like u i I use another product that has like a",
    "start": "2054560",
    "end": "2061520"
  },
  {
    "text": "node exporter B elastic search what implementations do you guys have for those are",
    "start": "2061520",
    "end": "2067638"
  },
  {
    "text": "different I imagine over time it'll grow but for right now for logging I don't know the exact list of exporters I don't",
    "start": "2067639",
    "end": "2074398"
  },
  {
    "text": "know the exact list but there are a lot um it's pretty new there's already quite a few though yeah I think there's over a dozen for metric side of things metrics",
    "start": "2074399",
    "end": "2080919"
  },
  {
    "text": "has a ton so like traces and metrics are pretty mature like I don't really know of any sources you can't export to either via their own export or or just",
    "start": "2080919",
    "end": "2087358"
  },
  {
    "text": "because they support OTL okay I think you said elastic I'm pretty sure that's",
    "start": "2087359",
    "end": "2092800"
  },
  {
    "text": "in there if I'm running an elastic search service on a node and I have theot collector installed there it'll",
    "start": "2092800",
    "end": "2098680"
  },
  {
    "text": "gather metrics from elastic and Export those it can yeah yes you want",
    "start": "2098680",
    "end": "2103760"
  },
  {
    "text": "performance metrics of elastic itself in this case yeah that should work like yeah because I think you can download",
    "start": "2103760",
    "end": "2109160"
  },
  {
    "text": "let's say node exporter install it on a machine and have that present metrics and so the O will have the Noe exporter",
    "start": "2109160",
    "end": "2115440"
  },
  {
    "text": "baked into it and it'll scrape its own metrics and pull those or there is a metric scraper for elastic surge okay",
    "start": "2115440",
    "end": "2121359"
  },
  {
    "text": "yep I think probably last question just because oh they told us to stop once you come up at the end we'll we'll check one",
    "start": "2121359",
    "end": "2126440"
  },
  {
    "text": "one back pressure ready the new collector is in terms of pushing logs for example in our current environment we don't sample anything in terms of",
    "start": "2126440",
    "end": "2133160"
  },
  {
    "text": "logs uh for various reasons uh yeah compliance or other reasons scale the",
    "start": "2133160",
    "end": "2138599"
  },
  {
    "text": "scale is like always a problem so we decentralized everything and we moved everything to the source rather than writing a central pipeline sure so is it",
    "start": "2138599",
    "end": "2145640"
  },
  {
    "text": "back pressure tested we're being told we're out of time so you want to just come up and we can back yeah thanks",
    "start": "2145640",
    "end": "2151440"
  },
  {
    "text": "thanks everyone thank you for coming thanks everyone",
    "start": "2151440",
    "end": "2157319"
  }
]
[
  {
    "start": "0",
    "end": "88000"
  },
  {
    "text": "okay good afternoon thanks for coming to",
    "start": "30",
    "end": "2760"
  },
  {
    "text": "this talk my name is Jung Hyung I'm an",
    "start": "2760",
    "end": "6540"
  },
  {
    "text": "Seagal lead and the maintainer of",
    "start": "6540",
    "end": "8429"
  },
  {
    "text": "tensorflow project I work for more",
    "start": "8429",
    "end": "11730"
  },
  {
    "text": "behind which is a company in saline",
    "start": "11730",
    "end": "13620"
  },
  {
    "text": "valley he sees again tongue he is member",
    "start": "13620",
    "end": "17520"
  },
  {
    "text": "of cookie flow and the involving several",
    "start": "17520",
    "end": "20330"
  },
  {
    "text": "several kubernetes operators intensive",
    "start": "20330",
    "end": "23070"
  },
  {
    "text": "in cookie flow arc is also maintainer of",
    "start": "23070",
    "end": "26400"
  },
  {
    "text": "several machine learning frameworks such",
    "start": "26400",
    "end": "28920"
  },
  {
    "text": "as tensorflow",
    "start": "28920",
    "end": "29939"
  },
  {
    "text": "MX net and XE boost he worked for and",
    "start": "29939",
    "end": "34200"
  },
  {
    "text": "financial at the moment in today's talk",
    "start": "34200",
    "end": "38219"
  },
  {
    "text": "our focus is to discuss about",
    "start": "38219",
    "end": "40730"
  },
  {
    "text": "large-scale distributive learning with",
    "start": "40730",
    "end": "43620"
  },
  {
    "text": "kubernetes operators we will briefly",
    "start": "43620",
    "end": "46079"
  },
  {
    "text": "cover about cancer intensive law have",
    "start": "46079",
    "end": "49440"
  },
  {
    "text": "some concept incriminates operators and",
    "start": "49440",
    "end": "51840"
  },
  {
    "text": "also come some concept in cookie flow so",
    "start": "51840",
    "end": "57960"
  },
  {
    "text": "before we get started I would like to",
    "start": "57960",
    "end": "60329"
  },
  {
    "text": "briefly discuss about motivation to have",
    "start": "60329",
    "end": "63539"
  },
  {
    "text": "a tradition for deep learning many",
    "start": "63539",
    "end": "65939"
  },
  {
    "text": "people may ask the question of why the",
    "start": "65939",
    "end": "68520"
  },
  {
    "text": "planning is so special in our tradition",
    "start": "68520",
    "end": "71549"
  },
  {
    "text": "there are several reasons for that in",
    "start": "71549",
    "end": "75420"
  },
  {
    "text": "traditional continual tradition your",
    "start": "75420",
    "end": "78780"
  },
  {
    "text": "typical ad always state least continuous",
    "start": "78780",
    "end": "81479"
  },
  {
    "text": "those dailies continuous are typically",
    "start": "81479",
    "end": "84330"
  },
  {
    "text": "web applications for web applications",
    "start": "84330",
    "end": "86820"
  },
  {
    "text": "you can easily scale up and down",
    "start": "86820",
    "end": "88979"
  },
  {
    "start": "88000",
    "end": "88000"
  },
  {
    "text": "container without any restrictions for",
    "start": "88979",
    "end": "94350"
  },
  {
    "text": "deep learning however there is one big",
    "start": "94350",
    "end": "96900"
  },
  {
    "text": "factor the big factor is the tripi of",
    "start": "96900",
    "end": "99450"
  },
  {
    "text": "involvement as we all know machine",
    "start": "99450",
    "end": "101939"
  },
  {
    "text": "learning relies on cheaply or nowadays",
    "start": "101939",
    "end": "103979"
  },
  {
    "text": "without gvo your machine learning will",
    "start": "103979",
    "end": "106560"
  },
  {
    "text": "will not be running efficiently but gpo",
    "start": "106560",
    "end": "109710"
  },
  {
    "text": "is expensive that means you have to",
    "start": "109710",
    "end": "113430"
  },
  {
    "text": "worry about the ratio of your GPU CPU",
    "start": "113430",
    "end": "115799"
  },
  {
    "text": "and i/o if you look at this graph you",
    "start": "115799",
    "end": "118740"
  },
  {
    "text": "can see if you if your GPU is not a",
    "start": "118740",
    "end": "122939"
  },
  {
    "text": "properly pipeline you can waste a lot of",
    "start": "122939",
    "end": "125490"
  },
  {
    "text": "time waiting for the data to be",
    "start": "125490",
    "end": "127829"
  },
  {
    "text": "transferred from aisle to cpiotto GPO",
    "start": "127829",
    "end": "131069"
  },
  {
    "text": "and that's great waste of resources",
    "start": "131069",
    "end": "133610"
  },
  {
    "text": "and the problem is the GPO is expensive",
    "start": "133610",
    "end": "137540"
  },
  {
    "text": "so you want to make sure your investment",
    "start": "137540",
    "end": "139940"
  },
  {
    "text": "has been fully recovered when you do the",
    "start": "139940",
    "end": "142700"
  },
  {
    "text": "deep learning if you see the tag at the",
    "start": "142700",
    "end": "145550"
  },
  {
    "text": "bottom of diagram as you can see with a",
    "start": "145550",
    "end": "148610"
  },
  {
    "text": "proper pipeline you could efficiently",
    "start": "148610",
    "end": "151460"
  },
  {
    "text": "utilize your resources specially for",
    "start": "151460",
    "end": "153860"
  },
  {
    "text": "expensive G feels so that's why the deep",
    "start": "153860",
    "end": "157100"
  },
  {
    "text": "learning has a special needs of our",
    "start": "157100",
    "end": "159080"
  },
  {
    "text": "tradition and it's very different from",
    "start": "159080",
    "end": "161780"
  },
  {
    "text": "the dailies continuous like web",
    "start": "161780",
    "end": "163790"
  },
  {
    "text": "applications",
    "start": "163790",
    "end": "166629"
  },
  {
    "text": "another reason for deep learning to have",
    "start": "166720",
    "end": "170120"
  },
  {
    "text": "a proper uh tradition is so called",
    "start": "170120",
    "end": "173150"
  },
  {
    "text": "distribution strategy for were the years",
    "start": "173150",
    "end": "177890"
  },
  {
    "text": "people had been proposing different ways",
    "start": "177890",
    "end": "179990"
  },
  {
    "text": "of doing distributive learning and the",
    "start": "179990",
    "end": "182450"
  },
  {
    "text": "most successful one in sofa is a",
    "start": "182450",
    "end": "185540"
  },
  {
    "text": "parameter server model in parameter",
    "start": "185540",
    "end": "188330"
  },
  {
    "text": "server model in a cluster you typically",
    "start": "188330",
    "end": "191480"
  },
  {
    "text": "have two types of nodes the parameter",
    "start": "191480",
    "end": "194660"
  },
  {
    "text": "server knows and the worker node you",
    "start": "194660",
    "end": "197810"
  },
  {
    "text": "typically have one with several",
    "start": "197810",
    "end": "199370"
  },
  {
    "text": "parameters server you also have a fleet",
    "start": "199370",
    "end": "202070"
  },
  {
    "text": "of worker node to the other gpo",
    "start": "202070",
    "end": "204910"
  },
  {
    "text": "intensive work for parameter server it's",
    "start": "204910",
    "end": "208820"
  },
  {
    "text": "a central place for you to update the",
    "start": "208820",
    "end": "210890"
  },
  {
    "text": "parameters like in the diagram if you",
    "start": "210890",
    "end": "214100"
  },
  {
    "text": "could look at diagram the workflow for",
    "start": "214100",
    "end": "217060"
  },
  {
    "text": "distributive learning with parameter",
    "start": "217060",
    "end": "219170"
  },
  {
    "text": "server model is done in this way worker",
    "start": "219170",
    "end": "222500"
  },
  {
    "text": "node will first do the calculation based",
    "start": "222500",
    "end": "226940"
  },
  {
    "text": "on a subset of the data the partial",
    "start": "226940",
    "end": "231530"
  },
  {
    "text": "gradient you calculated will be pushed",
    "start": "231530",
    "end": "234019"
  },
  {
    "text": "to parameter server and the parameter",
    "start": "234019",
    "end": "236510"
  },
  {
    "text": "server will grab all the gradient from",
    "start": "236510",
    "end": "239180"
  },
  {
    "text": "different worker node do the calculation",
    "start": "239180",
    "end": "242000"
  },
  {
    "text": "to get a new weight the new weight will",
    "start": "242000",
    "end": "245090"
  },
  {
    "text": "be fully distributed to working out",
    "start": "245090",
    "end": "247100"
  },
  {
    "text": "again to wait for the next round of",
    "start": "247100",
    "end": "249230"
  },
  {
    "text": "update so that's a whole lifecycle of a",
    "start": "249230",
    "end": "252890"
  },
  {
    "text": "permanent server model as we mentioned a",
    "start": "252890",
    "end": "256400"
  },
  {
    "start": "254000",
    "end": "254000"
  },
  {
    "text": "parameter server has been a successful",
    "start": "256400",
    "end": "258320"
  },
  {
    "text": "model in the past but recently people",
    "start": "258320",
    "end": "261470"
  },
  {
    "text": "proposed and the discuss about if there",
    "start": "261470",
    "end": "264440"
  },
  {
    "text": "are any other ways of doing distributive",
    "start": "264440",
    "end": "266870"
  },
  {
    "text": "learning",
    "start": "266870",
    "end": "268300"
  },
  {
    "text": "the most promising one is so-called our",
    "start": "268300",
    "end": "271900"
  },
  {
    "text": "reduce tragedy done in the past by MPI",
    "start": "271900",
    "end": "276130"
  },
  {
    "text": "community the our reduce treachery",
    "start": "276130",
    "end": "280289"
  },
  {
    "text": "essentially is not a new concept but",
    "start": "280289",
    "end": "283000"
  },
  {
    "text": "it's actually only have only been used",
    "start": "283000",
    "end": "285970"
  },
  {
    "text": "in deep learning community recently",
    "start": "285970",
    "end": "288360"
  },
  {
    "text": "before we discuss about our retail",
    "start": "288360",
    "end": "291520"
  },
  {
    "start": "290000",
    "end": "290000"
  },
  {
    "text": "strategy I want to discuss about reduce",
    "start": "291520",
    "end": "295660"
  },
  {
    "text": "strategy for the council reduce is very",
    "start": "295660",
    "end": "299860"
  },
  {
    "text": "forward you'll have a several note you",
    "start": "299860",
    "end": "303430"
  },
  {
    "text": "let's say you want to do a summation of",
    "start": "303430",
    "end": "305530"
  },
  {
    "text": "different numbers stored on each node so",
    "start": "305530",
    "end": "308500"
  },
  {
    "text": "how do you how do you do that",
    "start": "308500",
    "end": "310150"
  },
  {
    "text": "so essentially you can just aggregate",
    "start": "310150",
    "end": "313690"
  },
  {
    "text": "data on different node and the",
    "start": "313690",
    "end": "316240"
  },
  {
    "text": "researchers tab you'll do a partial",
    "start": "316240",
    "end": "318580"
  },
  {
    "text": "submission until you reach the root node",
    "start": "318580",
    "end": "321820"
  },
  {
    "text": "which will give you the final answer so",
    "start": "321820",
    "end": "324370"
  },
  {
    "text": "that's the so-called reduce strategy for",
    "start": "324370",
    "end": "331539"
  },
  {
    "text": "MPI the concept of our reduced strategy",
    "start": "331539",
    "end": "334360"
  },
  {
    "text": "it's actually similar the only",
    "start": "334360",
    "end": "336400"
  },
  {
    "text": "difference is that when you after you",
    "start": "336400",
    "end": "339699"
  },
  {
    "text": "get the summation from from the root",
    "start": "339699",
    "end": "343570"
  },
  {
    "text": "node you don't stop here you do",
    "start": "343570",
    "end": "345820"
  },
  {
    "text": "additional broadcast to to make sure the",
    "start": "345820",
    "end": "348759"
  },
  {
    "start": "346000",
    "end": "346000"
  },
  {
    "text": "number is available on all nodes so it's",
    "start": "348759",
    "end": "351909"
  },
  {
    "text": "like this way it was a summation each",
    "start": "351909",
    "end": "354820"
  },
  {
    "text": "node you reach the root node to catch a",
    "start": "354820",
    "end": "357610"
  },
  {
    "text": "number and the finally you do the",
    "start": "357610",
    "end": "359860"
  },
  {
    "text": "broadcast to reach to different nodes so",
    "start": "359860",
    "end": "363370"
  },
  {
    "text": "that every node will get a number",
    "start": "363370",
    "end": "367530"
  },
  {
    "text": "so to summarize our reduce is a reduce",
    "start": "367770",
    "end": "371080"
  },
  {
    "text": "plus broadcast model so one question",
    "start": "371080",
    "end": "376570"
  },
  {
    "text": "people costing us is if a permit seller",
    "start": "376570",
    "end": "379449"
  },
  {
    "text": "has been using in the past of why do we",
    "start": "379449",
    "end": "381460"
  },
  {
    "text": "need another distribution strategy there",
    "start": "381460",
    "end": "384370"
  },
  {
    "text": "are several reasons for that so first of",
    "start": "384370",
    "end": "386710"
  },
  {
    "text": "all parameter server require a",
    "start": "386710",
    "end": "389729"
  },
  {
    "text": "centralized location to save the data",
    "start": "389729",
    "end": "392409"
  },
  {
    "text": "and this data has to be CPU intensive",
    "start": "392409",
    "end": "395219"
  },
  {
    "text": "a lot of people read the question say",
    "start": "395219",
    "end": "399500"
  },
  {
    "text": "her paralyzed our machine might be",
    "start": "399500",
    "end": "402440"
  },
  {
    "text": "different from paralyzing a cluster and",
    "start": "402440",
    "end": "404690"
  },
  {
    "text": "the parameter server model might be best",
    "start": "404690",
    "end": "406850"
  },
  {
    "text": "fitted to have a module process that",
    "start": "406850",
    "end": "409850"
  },
  {
    "text": "running on the same machine but not",
    "start": "409850",
    "end": "411740"
  },
  {
    "text": "necessarily to to perm to the",
    "start": "411740",
    "end": "415190"
  },
  {
    "text": "distributor job in a cluster so it's",
    "start": "415190",
    "end": "418610"
  },
  {
    "text": "kind of controversy to say if parameter",
    "start": "418610",
    "end": "421250"
  },
  {
    "text": "server is a best approach but for over",
    "start": "421250",
    "end": "427370"
  },
  {
    "text": "the years especially for the past",
    "start": "427370",
    "end": "429650"
  },
  {
    "text": "several years people has invested lots",
    "start": "429650",
    "end": "432620"
  },
  {
    "text": "of effort there are lots of investment",
    "start": "432620",
    "end": "435680"
  },
  {
    "text": "over parameter server there are",
    "start": "435680",
    "end": "437600"
  },
  {
    "text": "different South Wales different packages",
    "start": "437600",
    "end": "439790"
  },
  {
    "text": "and frameworks supporting this model so",
    "start": "439790",
    "end": "441980"
  },
  {
    "text": "it's really hard to throw away so that's",
    "start": "441980",
    "end": "446630"
  },
  {
    "text": "why we come here to discuss about the",
    "start": "446630",
    "end": "448790"
  },
  {
    "text": "difference distribution strategy for",
    "start": "448790",
    "end": "451220"
  },
  {
    "text": "distributive planning if we look back we",
    "start": "451220",
    "end": "455870"
  },
  {
    "text": "discuss about our tradition for deep",
    "start": "455870",
    "end": "458030"
  },
  {
    "text": "learning we notice there are several",
    "start": "458030",
    "end": "460540"
  },
  {
    "text": "characteristics first it has data for",
    "start": "460540",
    "end": "463910"
  },
  {
    "text": "metadata the state of omert√† data need",
    "start": "463910",
    "end": "467030"
  },
  {
    "text": "to be properly managed in your whole",
    "start": "467030",
    "end": "470419"
  },
  {
    "text": "life cycle we also noticed that we need",
    "start": "470419",
    "end": "474350"
  },
  {
    "text": "a traditional framework of course we are",
    "start": "474350",
    "end": "476930"
  },
  {
    "text": "here in kuvakin so we also discuss about",
    "start": "476930",
    "end": "479510"
  },
  {
    "text": "ways to do it with kubernetes",
    "start": "479510",
    "end": "482140"
  },
  {
    "text": "if we combine album together the best",
    "start": "482140",
    "end": "485570"
  },
  {
    "text": "approach as well we could see is a",
    "start": "485570",
    "end": "488210"
  },
  {
    "text": "kubernetes operators so in this talk",
    "start": "488210",
    "end": "492200"
  },
  {
    "text": "we're going to introduce several",
    "start": "492200",
    "end": "493520"
  },
  {
    "text": "community operators for managing deep",
    "start": "493520",
    "end": "497030"
  },
  {
    "text": "learning or tradition the the operators",
    "start": "497030",
    "end": "501110"
  },
  {
    "start": "499000",
    "end": "499000"
  },
  {
    "text": "we are going to discuss are under the",
    "start": "501110",
    "end": "503750"
  },
  {
    "text": "cookie flow project we will discuss",
    "start": "503750",
    "end": "506210"
  },
  {
    "text": "several operators the TF operator which",
    "start": "506210",
    "end": "509120"
  },
  {
    "text": "is operator for managing tension flows a",
    "start": "509120",
    "end": "512000"
  },
  {
    "text": "parameter server model the pipe water",
    "start": "512000",
    "end": "515000"
  },
  {
    "text": "operator which is used for manage",
    "start": "515000",
    "end": "517550"
  },
  {
    "text": "another popular pretty popular machine",
    "start": "517550",
    "end": "519890"
  },
  {
    "text": "learning framework of pipe watch and",
    "start": "519890",
    "end": "521560"
  },
  {
    "text": "finally we are going to discuss about",
    "start": "521560",
    "end": "524120"
  },
  {
    "text": "ampere operator the ampere operator here",
    "start": "524120",
    "end": "527360"
  },
  {
    "text": "might be misleading because we mentioned",
    "start": "527360",
    "end": "529700"
  },
  {
    "text": "by the MPI but really it's just",
    "start": "529700",
    "end": "533269"
  },
  {
    "text": "it's actually just mapi our radius",
    "start": "533269",
    "end": "536990"
  },
  {
    "text": "tragedy operator so it's actually could",
    "start": "536990",
    "end": "539600"
  },
  {
    "text": "be applied to different machine learning",
    "start": "539600",
    "end": "541369"
  },
  {
    "text": "frameworks",
    "start": "541369",
    "end": "542329"
  },
  {
    "text": "now just for MPI next I'm going to hand",
    "start": "542329",
    "end": "547189"
  },
  {
    "text": "over my microphone to my caller to you",
    "start": "547189",
    "end": "549949"
  },
  {
    "text": "and he is going to discuss about",
    "start": "549949",
    "end": "551389"
  },
  {
    "text": "different operators and how to do that",
    "start": "551389",
    "end": "554179"
  },
  {
    "text": "with kubernetes and the cookie flow so",
    "start": "554179",
    "end": "562579"
  },
  {
    "text": "today we will focus on these three",
    "start": "562579",
    "end": "564860"
  },
  {
    "text": "operators under could be flow so Kiev",
    "start": "564860",
    "end": "568610"
  },
  {
    "text": "operator",
    "start": "568610",
    "end": "569389"
  },
  {
    "text": "obviously it works with tencel flow but",
    "start": "569389",
    "end": "574279"
  },
  {
    "text": "not other frameworks",
    "start": "574279",
    "end": "575600"
  },
  {
    "text": "it supports distribution strategies or",
    "start": "575600",
    "end": "578839"
  },
  {
    "text": "different backends",
    "start": "578839",
    "end": "580279"
  },
  {
    "text": "whether its TF ductus tribute module for",
    "start": "580279",
    "end": "584720"
  },
  {
    "text": "example MPI which is the all we do",
    "start": "584720",
    "end": "587869"
  },
  {
    "text": "strategy that we that John talked about",
    "start": "587869",
    "end": "589910"
  },
  {
    "text": "and NCR which is a collective",
    "start": "589910",
    "end": "595540"
  },
  {
    "text": "communications library open source file",
    "start": "595540",
    "end": "598189"
  },
  {
    "text": "Nvidia and then parameter server",
    "start": "598189",
    "end": "600259"
  },
  {
    "text": "strategy that you also talked about and",
    "start": "600259",
    "end": "602629"
  },
  {
    "text": "then the TPU strategy which will make",
    "start": "602629",
    "end": "608119"
  },
  {
    "text": "tensorflow work we are with more",
    "start": "608119",
    "end": "610790"
  },
  {
    "text": "efficiently with Google stencil",
    "start": "610790",
    "end": "613309"
  },
  {
    "text": "processing units and then Pat Hodge",
    "start": "613309",
    "end": "615709"
  },
  {
    "text": "operator it works with high touch users",
    "start": "615709",
    "end": "620509"
  },
  {
    "text": "can access different distribution",
    "start": "620509",
    "end": "622600"
  },
  {
    "text": "strategies via touch that distributed",
    "start": "622600",
    "end": "626029"
  },
  {
    "text": "module which includes backends such as",
    "start": "626029",
    "end": "629449"
  },
  {
    "text": "glue which is also another collective",
    "start": "629449",
    "end": "633170"
  },
  {
    "text": "communications library by Facebook and",
    "start": "633170",
    "end": "636139"
  },
  {
    "text": "then NPR and NCC our last but not least",
    "start": "636139",
    "end": "640670"
  },
  {
    "text": "MPI operator supports all types of MPI",
    "start": "640670",
    "end": "645079"
  },
  {
    "text": "based jobs so for example you can run",
    "start": "645079",
    "end": "650749"
  },
  {
    "text": "all kinds of jobs that can be executed",
    "start": "650749",
    "end": "654259"
  },
  {
    "text": "on openmpi so for example ha road is a",
    "start": "654259",
    "end": "658999"
  },
  {
    "text": "framework by",
    "start": "658999",
    "end": "661180"
  },
  {
    "text": "it supports different machine and",
    "start": "661180",
    "end": "664060"
  },
  {
    "text": "frameworks such as tensorflow high Taj",
    "start": "664060",
    "end": "666670"
  },
  {
    "text": "IMAX net and Kira's which can be either",
    "start": "666670",
    "end": "672030"
  },
  {
    "text": "the original Kira's or TF that Kira's it",
    "start": "672030",
    "end": "677170"
  },
  {
    "text": "you tonight users can utilize the",
    "start": "677170",
    "end": "679480"
  },
  {
    "text": "Harwood distributed optimizer to run MPI",
    "start": "679480",
    "end": "684370"
  },
  {
    "text": "based distribution strategy",
    "start": "684370",
    "end": "687070"
  },
  {
    "text": "note that it's only MPI let's take a",
    "start": "687070",
    "end": "691390"
  },
  {
    "text": "quick look at the different operators",
    "start": "691390",
    "end": "695460"
  },
  {
    "text": "here we have TF job which is on the left",
    "start": "695460",
    "end": "701110"
  },
  {
    "text": "hand side TF job is accustomed resource",
    "start": "701110",
    "end": "704200"
  },
  {
    "text": "definition provided by TF operator so",
    "start": "704200",
    "end": "708730"
  },
  {
    "text": "all you need to do is to define your",
    "start": "708730",
    "end": "712170"
  },
  {
    "text": "tensile replicas back here we are",
    "start": "712170",
    "end": "715150"
  },
  {
    "text": "defining the worker spec which includes",
    "start": "715150",
    "end": "719020"
  },
  {
    "text": "how many replicas are we running for the",
    "start": "719020",
    "end": "721780"
  },
  {
    "text": "worker nodes and we define the resources",
    "start": "721780",
    "end": "725440"
  },
  {
    "text": "that's required for the replicas",
    "start": "725440",
    "end": "728470"
  },
  {
    "text": "replicated containers here and for",
    "start": "728470",
    "end": "732070"
  },
  {
    "text": "example here we are using our four GPUs",
    "start": "732070",
    "end": "734650"
  },
  {
    "text": "and we execute this tensorflow script",
    "start": "734650",
    "end": "738310"
  },
  {
    "text": "here on the right hand side this is MPI",
    "start": "738310",
    "end": "743230"
  },
  {
    "text": "job custom with the custom resource",
    "start": "743230",
    "end": "747340"
  },
  {
    "text": "definition provided by MPI operator it's",
    "start": "747340",
    "end": "750700"
  },
  {
    "text": "very similar to the TF job definition we",
    "start": "750700",
    "end": "755350"
  },
  {
    "text": "will just defined MPI or replicate",
    "start": "755350",
    "end": "758940"
  },
  {
    "text": "replicas back here for the worker",
    "start": "758940",
    "end": "762660"
  },
  {
    "text": "replicas the rest of them are similar",
    "start": "762660",
    "end": "766030"
  },
  {
    "text": "except for this last command to ask to",
    "start": "766030",
    "end": "770230"
  },
  {
    "text": "execute inside the container we run the",
    "start": "770230",
    "end": "773470"
  },
  {
    "text": "MPI run command here and then these",
    "start": "773470",
    "end": "777520"
  },
  {
    "text": "Python scripts include is a mixed tensor",
    "start": "777520",
    "end": "781180"
  },
  {
    "text": "flow class horror would program which",
    "start": "781180",
    "end": "784060"
  },
  {
    "text": "we'll talk about later",
    "start": "784060",
    "end": "786870"
  },
  {
    "text": "first of all let's take a look at a",
    "start": "787310",
    "end": "789860"
  },
  {
    "text": "quick simple example using tensorflow",
    "start": "789860",
    "end": "793390"
  },
  {
    "text": "to run a basic training locally so we",
    "start": "793390",
    "end": "798140"
  },
  {
    "text": "import tensorflow",
    "start": "798140",
    "end": "799700"
  },
  {
    "text": "here and then import tensorflow",
    "start": "799700",
    "end": "803360"
  },
  {
    "text": "io which is the easiest way to import",
    "start": "803360",
    "end": "806089"
  },
  {
    "text": "different data sets extensions and file",
    "start": "806089",
    "end": "809540"
  },
  {
    "text": "system extensions for tensorflow",
    "start": "809540",
    "end": "812150"
  },
  {
    "start": "812000",
    "end": "812000"
  },
  {
    "text": "so here we are importing Emily's dataset",
    "start": "812150",
    "end": "815920"
  },
  {
    "text": "using the tensor for IO module and then",
    "start": "815920",
    "end": "819350"
  },
  {
    "text": "we map each image to image these",
    "start": "819350",
    "end": "823960"
  },
  {
    "text": "features and labels to this particular",
    "start": "823960",
    "end": "827210"
  },
  {
    "text": "float32 type and then we can take",
    "start": "827210",
    "end": "831520"
  },
  {
    "text": "batches of the data set of saba of batch",
    "start": "831520",
    "end": "835370"
  },
  {
    "text": "size 1000 next we can define the tensile",
    "start": "835370",
    "end": "840710"
  },
  {
    "text": "flow model model using T of the Cure's",
    "start": "840710",
    "end": "843580"
  },
  {
    "text": "module and here we are defining a",
    "start": "843580",
    "end": "846890"
  },
  {
    "text": "sequential model which is linear a stack",
    "start": "846890",
    "end": "851660"
  },
  {
    "text": "of linear a linear stack of different",
    "start": "851660",
    "end": "855080"
  },
  {
    "text": "layers deep learning measures first we",
    "start": "855080",
    "end": "858950"
  },
  {
    "text": "flatten the input into this particular",
    "start": "858950",
    "end": "862160"
  },
  {
    "text": "shape and then we apply a fully",
    "start": "862160",
    "end": "865490"
  },
  {
    "text": "connected dense layer of width 512",
    "start": "865490",
    "end": "869750"
  },
  {
    "text": "neurons with riilu as a activation",
    "start": "869750",
    "end": "872930"
  },
  {
    "text": "function and the next we apply a drop",
    "start": "872930",
    "end": "877070"
  },
  {
    "text": "out here which means we drop 20% of the",
    "start": "877070",
    "end": "881230"
  },
  {
    "text": "input or we randomly drop 20% of the",
    "start": "881230",
    "end": "884720"
  },
  {
    "text": "input to avoid or reduce overfitting",
    "start": "884720",
    "end": "888560"
  },
  {
    "text": "problem and then we apply another fully",
    "start": "888560",
    "end": "892070"
  },
  {
    "text": "connected layer with own interneurons",
    "start": "892070",
    "end": "894589"
  },
  {
    "text": "just to get the different classes so",
    "start": "894589",
    "end": "899240"
  },
  {
    "text": "once we finish defining the model we",
    "start": "899240",
    "end": "902060"
  },
  {
    "text": "configure the model for training here",
    "start": "902060",
    "end": "905230"
  },
  {
    "text": "using SPICE specifying specifying this",
    "start": "905230",
    "end": "908330"
  },
  {
    "text": "particular function and this quick",
    "start": "908330",
    "end": "911360"
  },
  {
    "text": "stochastic gradient descent",
    "start": "911360",
    "end": "913560"
  },
  {
    "text": "optimizer and then we fit the model we",
    "start": "913560",
    "end": "916980"
  },
  {
    "text": "train the model using the data set that",
    "start": "916980",
    "end": "919470"
  },
  {
    "text": "we imported earlier and with this many",
    "start": "919470",
    "end": "922769"
  },
  {
    "text": "appropriate approaches and then we last",
    "start": "922769",
    "end": "926490"
  },
  {
    "text": "we evaluate that it has the model using",
    "start": "926490",
    "end": "929879"
  },
  {
    "text": "here is just a very simple example which",
    "start": "929879",
    "end": "932430"
  },
  {
    "text": "you use the data set that we imported",
    "start": "932430",
    "end": "935220"
  },
  {
    "text": "earlier to evaluate how well is the",
    "start": "935220",
    "end": "937920"
  },
  {
    "text": "model performing on this particular data",
    "start": "937920",
    "end": "940740"
  },
  {
    "text": "set this is a rod tensile flow that can",
    "start": "940740",
    "end": "945059"
  },
  {
    "text": "be executed locally but next let's take",
    "start": "945059",
    "end": "948779"
  },
  {
    "start": "947000",
    "end": "947000"
  },
  {
    "text": "a look at how do we turn this tensor",
    "start": "948779",
    "end": "951149"
  },
  {
    "text": "flow program into into a distributed",
    "start": "951149",
    "end": "954540"
  },
  {
    "text": "training in distributists settings so",
    "start": "954540",
    "end": "958019"
  },
  {
    "text": "same as you as before we import the data",
    "start": "958019",
    "end": "961559"
  },
  {
    "text": "set and the model and then we initialize",
    "start": "961559",
    "end": "965279"
  },
  {
    "text": "a mirrored strategy using TF that",
    "start": "965279",
    "end": "968790"
  },
  {
    "text": "distribute module what this does is it",
    "start": "968790",
    "end": "972930"
  },
  {
    "text": "nourished variables to distribute across",
    "start": "972930",
    "end": "976170"
  },
  {
    "text": "multiple devices and machines we then",
    "start": "976170",
    "end": "979500"
  },
  {
    "text": "use all reduce to combine the gradients",
    "start": "979500",
    "end": "982579"
  },
  {
    "text": "compiled convent ingredients across the",
    "start": "982579",
    "end": "985920"
  },
  {
    "text": "devices before applying them to the",
    "start": "985920",
    "end": "989670"
  },
  {
    "text": "variables to keep them in sync so simple",
    "start": "989670",
    "end": "996360"
  },
  {
    "text": "as that we just define that we we just",
    "start": "996360",
    "end": "1000250"
  },
  {
    "text": "configure that model with the last",
    "start": "1000250",
    "end": "1003559"
  },
  {
    "text": "function and optimizer as user but",
    "start": "1003559",
    "end": "1005720"
  },
  {
    "text": "within this mirrored strategy scope next",
    "start": "1005720",
    "end": "1011509"
  },
  {
    "start": "1010000",
    "end": "1010000"
  },
  {
    "text": "let's take a look at how do we use",
    "start": "1011509",
    "end": "1014360"
  },
  {
    "text": "harwood to run tensor Florine we all",
    "start": "1014360",
    "end": "1017689"
  },
  {
    "text": "reduce fashion so we here we import one",
    "start": "1017689",
    "end": "1024438"
  },
  {
    "text": "additional library here which is under a",
    "start": "1024439",
    "end": "1028699"
  },
  {
    "text": "rule that Kira's robbery so this harwood",
    "start": "1028699",
    "end": "1031760"
  },
  {
    "text": "program would work with TF Dockers or",
    "start": "1031760",
    "end": "1035329"
  },
  {
    "text": "kill the",
    "start": "1035329",
    "end": "1036750"
  },
  {
    "text": "Akira's so same as usual we define the",
    "start": "1036750",
    "end": "1040740"
  },
  {
    "text": "model data set and then we define the",
    "start": "1040740",
    "end": "1044188"
  },
  {
    "text": "optimizer using Rodentia for API but",
    "start": "1044189",
    "end": "1049230"
  },
  {
    "text": "what's special here is that we then",
    "start": "1049230",
    "end": "1051750"
  },
  {
    "text": "apply a Hollywood distributed optimizer",
    "start": "1051750",
    "end": "1055070"
  },
  {
    "text": "we'll wrap this previous tensorflow",
    "start": "1055070",
    "end": "1058440"
  },
  {
    "text": "optimizer that we need initialized and",
    "start": "1058440",
    "end": "1061260"
  },
  {
    "text": "then this will configure the distributed",
    "start": "1061260",
    "end": "1063660"
  },
  {
    "text": "training for us using how rules define",
    "start": "1063660",
    "end": "1067700"
  },
  {
    "text": "distributed strategy we apply the with",
    "start": "1067700",
    "end": "1073500"
  },
  {
    "text": "an compiled model to configure the",
    "start": "1073500",
    "end": "1075660"
  },
  {
    "text": "training and then we define this",
    "start": "1075660",
    "end": "1077910"
  },
  {
    "text": "additional callback for this pious model",
    "start": "1077910",
    "end": "1081840"
  },
  {
    "text": "which is the broadcast global variable",
    "start": "1081840",
    "end": "1084660"
  },
  {
    "text": "callback this callback basically",
    "start": "1084660",
    "end": "1087890"
  },
  {
    "text": "broadcasts in the initial variable",
    "start": "1087890",
    "end": "1090990"
  },
  {
    "text": "States from length 0 to or other",
    "start": "1090990",
    "end": "1093600"
  },
  {
    "text": "processes so this will ensure the",
    "start": "1093600",
    "end": "1097380"
  },
  {
    "text": "initialization of variables the Atkins",
    "start": "1097380",
    "end": "1103560"
  },
  {
    "text": "is consistent across all workers for",
    "start": "1103560",
    "end": "1107370"
  },
  {
    "text": "example if the training is studied with",
    "start": "1107370",
    "end": "1109650"
  },
  {
    "text": "random weights or the training is",
    "start": "1109650",
    "end": "1111720"
  },
  {
    "text": "restored from a check of previous saved",
    "start": "1111720",
    "end": "1115320"
  },
  {
    "text": "check point this will ensure the",
    "start": "1115320",
    "end": "1117710"
  },
  {
    "text": "initialization is consistent so let's",
    "start": "1117710",
    "end": "1123950"
  },
  {
    "text": "compare these two options we have on the",
    "start": "1123950",
    "end": "1127440"
  },
  {
    "text": "left hand side is the raw tensorflow",
    "start": "1127440",
    "end": "1129800"
  },
  {
    "text": "program using TF that distribute module",
    "start": "1129800",
    "end": "1133260"
  },
  {
    "text": "and on the right hand side is the",
    "start": "1133260",
    "end": "1135480"
  },
  {
    "text": "harwood plans tensorflow program that we",
    "start": "1135480",
    "end": "1138180"
  },
  {
    "text": "just saw so this this these boxes",
    "start": "1138180",
    "end": "1144330"
  },
  {
    "text": "highlights the differences basically so",
    "start": "1144330",
    "end": "1148010"
  },
  {
    "text": "if we add those additional eyes if we",
    "start": "1148010",
    "end": "1151760"
  },
  {
    "text": "switch this mute strategy scope to this",
    "start": "1151760",
    "end": "1157170"
  },
  {
    "text": "Hollywood distributed optimizer wrapper",
    "start": "1157170",
    "end": "1159510"
  },
  {
    "text": "and then add our callback then we",
    "start": "1159510",
    "end": "1162430"
  },
  {
    "text": "to switch to use highroad and then we",
    "start": "1162430",
    "end": "1165790"
  },
  {
    "text": "can so on the left hand side we can use",
    "start": "1165790",
    "end": "1169180"
  },
  {
    "text": "TF job to run that particular program",
    "start": "1169180",
    "end": "1172330"
  },
  {
    "text": "and on the right hand side the Harwood",
    "start": "1172330",
    "end": "1175120"
  },
  {
    "text": "program can be executed using MPI",
    "start": "1175120",
    "end": "1177670"
  },
  {
    "text": "operator so record and next let's",
    "start": "1177670",
    "end": "1191740"
  },
  {
    "text": "briefly talk about how do we use Harwood",
    "start": "1191740",
    "end": "1194650"
  },
  {
    "text": "with Python so so we just do a user",
    "start": "1194650",
    "end": "1201390"
  },
  {
    "text": "normal height watch program we import",
    "start": "1201390",
    "end": "1205290"
  },
  {
    "text": "patrasche module and we use Pathology's",
    "start": "1205290",
    "end": "1208330"
  },
  {
    "text": "own data loader too late to load the",
    "start": "1208330",
    "end": "1212770"
  },
  {
    "text": "data set just as very similar to",
    "start": "1212770",
    "end": "1215490"
  },
  {
    "text": "previously we use tensorflow alloy to",
    "start": "1215490",
    "end": "1218440"
  },
  {
    "text": "import the data set and we apply we",
    "start": "1218440",
    "end": "1222640"
  },
  {
    "text": "initialize an optimizer using paid watch",
    "start": "1222640",
    "end": "1225630"
  },
  {
    "text": "optimizer and then similarly we apply a",
    "start": "1225630",
    "end": "1229480"
  },
  {
    "text": "Hollywood distributed optimizer on top",
    "start": "1229480",
    "end": "1232750"
  },
  {
    "text": "of the head post optimizer so that we",
    "start": "1232750",
    "end": "1238270"
  },
  {
    "text": "can use the disability strategy defined",
    "start": "1238270",
    "end": "1241510"
  },
  {
    "text": "in Harwood and then similarly with the",
    "start": "1241510",
    "end": "1244330"
  },
  {
    "text": "we broadcast all the variables using",
    "start": "1244330",
    "end": "1248580"
  },
  {
    "text": "this horrid that broadcast parameters",
    "start": "1248580",
    "end": "1252190"
  },
  {
    "text": "note that this function is a valuable",
    "start": "1252190",
    "end": "1255220"
  },
  {
    "text": "under hallowed that touch but that's the",
    "start": "1255220",
    "end": "1258760"
  },
  {
    "text": "only change you need to make in order to",
    "start": "1258760",
    "end": "1262060"
  },
  {
    "text": "run hide watch using Hollywood and here",
    "start": "1262060",
    "end": "1265540"
  },
  {
    "text": "we are very similar to the pencil flow",
    "start": "1265540",
    "end": "1268450"
  },
  {
    "text": "class hold program we use the rank 0",
    "start": "1268450",
    "end": "1273880"
  },
  {
    "text": "process as a route process so we can so",
    "start": "1273880",
    "end": "1278740"
  },
  {
    "text": "so we initialize the rest of the",
    "start": "1278740",
    "end": "1281530"
  },
  {
    "text": "processes using the same variable States",
    "start": "1281530",
    "end": "1284830"
  },
  {
    "text": "and then here we do under this nested",
    "start": "1284830",
    "end": "1290410"
  },
  {
    "text": "for-loops we iterate data and run the",
    "start": "1290410",
    "end": "1295880"
  },
  {
    "text": "hydraulics training here step by step",
    "start": "1295880",
    "end": "1302260"
  },
  {
    "text": "okay",
    "start": "1302530",
    "end": "1303710"
  },
  {
    "start": "1303000",
    "end": "1303000"
  },
  {
    "text": "let's recall GF job versus MPI job these",
    "start": "1303710",
    "end": "1308360"
  },
  {
    "text": "are the only differences we need to",
    "start": "1308360",
    "end": "1310580"
  },
  {
    "text": "check but we need to make in order to",
    "start": "1310580",
    "end": "1313430"
  },
  {
    "text": "run test flow program under T repeater",
    "start": "1313430",
    "end": "1319070"
  },
  {
    "text": "or MPI operator but note that here the",
    "start": "1319070",
    "end": "1324890"
  },
  {
    "text": "API version we want offer to you for MPI",
    "start": "1324890",
    "end": "1328040"
  },
  {
    "text": "job is still a work in progress this is",
    "start": "1328040",
    "end": "1330830"
  },
  {
    "text": "something we work with the community to",
    "start": "1330830",
    "end": "1333520"
  },
  {
    "text": "to ensure that two different two",
    "start": "1333520",
    "end": "1337220"
  },
  {
    "text": "different operators or even more",
    "start": "1337220",
    "end": "1339920"
  },
  {
    "text": "operators such as Patridge can be the",
    "start": "1339920",
    "end": "1343910"
  },
  {
    "text": "API can be standardized and similar to",
    "start": "1343910",
    "end": "1347750"
  },
  {
    "text": "each other so all these are the only",
    "start": "1347750",
    "end": "1350200"
  },
  {
    "text": "changes we need to make in order to",
    "start": "1350200",
    "end": "1352640"
  },
  {
    "text": "switch one Operator",
    "start": "1352640",
    "end": "1354350"
  },
  {
    "text": "to another something we are working on",
    "start": "1354350",
    "end": "1357860"
  },
  {
    "start": "1357000",
    "end": "1357000"
  },
  {
    "text": "so these all these commonly all these",
    "start": "1357860",
    "end": "1361970"
  },
  {
    "text": "code all these reusable components from",
    "start": "1361970",
    "end": "1366500"
  },
  {
    "text": "different operators for is a material",
    "start": "1366500",
    "end": "1368450"
  },
  {
    "text": "operator",
    "start": "1368450",
    "end": "1369110"
  },
  {
    "text": "high-touch operator MPI operators are",
    "start": "1369110",
    "end": "1373630"
  },
  {
    "text": "happy to over refactored in this copy",
    "start": "1373630",
    "end": "1378080"
  },
  {
    "text": "flow common repo this also includes",
    "start": "1378080",
    "end": "1383590"
  },
  {
    "text": "common and standardized API spec and",
    "start": "1383590",
    "end": "1386420"
  },
  {
    "text": "there's also a base job controller in",
    "start": "1386420",
    "end": "1390110"
  },
  {
    "text": "interface so that new operators can",
    "start": "1390110",
    "end": "1394250"
  },
  {
    "text": "inherit and implement using the",
    "start": "1394250",
    "end": "1397730"
  },
  {
    "text": "utilities we have industry code and",
    "start": "1397730",
    "end": "1400340"
  },
  {
    "text": "there's also testing utilities in could",
    "start": "1400340",
    "end": "1403370"
  },
  {
    "text": "be follow common so this is something we",
    "start": "1403370",
    "end": "1406070"
  },
  {
    "text": "are working hard on to make sure the",
    "start": "1406070",
    "end": "1407810"
  },
  {
    "text": "api's are standardized",
    "start": "1407810",
    "end": "1409809"
  },
  {
    "text": "and the components are reusable so for",
    "start": "1409809",
    "end": "1413019"
  },
  {
    "text": "example we are working on a Tantra",
    "start": "1413019",
    "end": "1415869"
  },
  {
    "text": "financial we are working on an ex to",
    "start": "1415869",
    "end": "1417429"
  },
  {
    "text": "boost operator which we are inherit are",
    "start": "1417429",
    "end": "1420820"
  },
  {
    "text": "you actively from this common operator",
    "start": "1420820",
    "end": "1425340"
  },
  {
    "text": "sink that's it for today I'm just",
    "start": "1426599",
    "end": "1429070"
  },
  {
    "text": "wondering anyone has any questions",
    "start": "1429070",
    "end": "1432330"
  },
  {
    "text": "not sure it is supportive use already in",
    "start": "1443600",
    "end": "1446760"
  },
  {
    "text": "parameter service or TPO so two",
    "start": "1446760",
    "end": "1449010"
  },
  {
    "text": "questions",
    "start": "1449010",
    "end": "1450560"
  },
  {
    "text": "these are poverty peers if you support",
    "start": "1450560",
    "end": "1455490"
  },
  {
    "text": "abuse already tense of GPUs are already",
    "start": "1455490",
    "end": "1459660"
  },
  {
    "text": "supported",
    "start": "1459660",
    "end": "1462230"
  },
  {
    "text": "I think the question is about TP oh",
    "start": "1467780",
    "end": "1472060"
  },
  {
    "text": "that's so first of all TP oh it's only",
    "start": "1472060",
    "end": "1476530"
  },
  {
    "text": "we talk about ten shuffle of you talk",
    "start": "1476530",
    "end": "1478820"
  },
  {
    "text": "about TP oh and you probably who could",
    "start": "1478820",
    "end": "1481310"
  },
  {
    "text": "hear TP o aloud from Google guys TP o is",
    "start": "1481310",
    "end": "1486040"
  },
  {
    "text": "essentially designed and released by",
    "start": "1486040",
    "end": "1488540"
  },
  {
    "text": "Google and that's only available no go",
    "start": "1488540",
    "end": "1492020"
  },
  {
    "text": "crowd so it's it's very much a vendor",
    "start": "1492020",
    "end": "1496430"
  },
  {
    "text": "specific so if you use I would say if",
    "start": "1496430",
    "end": "1500420"
  },
  {
    "text": "you use tensorflow Uncle cloud you'll",
    "start": "1500420",
    "end": "1502550"
  },
  {
    "text": "probably can experiment and use TP o",
    "start": "1502550",
    "end": "1505010"
  },
  {
    "text": "because that's as far as I know there is",
    "start": "1505010",
    "end": "1508670"
  },
  {
    "text": "a very good support from tensorflow team",
    "start": "1508670",
    "end": "1510860"
  },
  {
    "text": "for to make sure our algorithm available",
    "start": "1510860",
    "end": "1513530"
  },
  {
    "text": "for TP o but if you'll try to for",
    "start": "1513530",
    "end": "1517220"
  },
  {
    "text": "different reasons cause the reason or",
    "start": "1517220",
    "end": "1519770"
  },
  {
    "text": "for your company policy reason you",
    "start": "1519770",
    "end": "1522410"
  },
  {
    "text": "decided to use a different cloud vendor",
    "start": "1522410",
    "end": "1525650"
  },
  {
    "text": "like AWS or if you decide to deploy your",
    "start": "1525650",
    "end": "1529070"
  },
  {
    "text": "own GPS fleet then TP o is now going to",
    "start": "1529070",
    "end": "1533780"
  },
  {
    "text": "be a no not going to be the best choice",
    "start": "1533780",
    "end": "1535880"
  },
  {
    "text": "and also I would like to point out is",
    "start": "1535880",
    "end": "1538130"
  },
  {
    "text": "that at least for tensorflow",
    "start": "1538130",
    "end": "1541180"
  },
  {
    "text": "now the other algorithm we always run on",
    "start": "1541180",
    "end": "1544280"
  },
  {
    "text": "TP o but tensorflow team has spent a lot",
    "start": "1544280",
    "end": "1547100"
  },
  {
    "text": "of effort to try to make sure TP o is",
    "start": "1547100",
    "end": "1550540"
  },
  {
    "text": "vertical also a first-class citizen and",
    "start": "1550540",
    "end": "1552860"
  },
  {
    "text": "support and the other questions",
    "start": "1552860",
    "end": "1559450"
  },
  {
    "text": "I thank you very much for a talk very",
    "start": "1567200",
    "end": "1568910"
  },
  {
    "text": "technical really really liked I was",
    "start": "1568910",
    "end": "1571550"
  },
  {
    "text": "wondering I among the net the frameworks",
    "start": "1571550",
    "end": "1574460"
  },
  {
    "text": "you mentioned IMAX net and as far as",
    "start": "1574460",
    "end": "1577310"
  },
  {
    "text": "understood you would support MX not",
    "start": "1577310",
    "end": "1579470"
  },
  {
    "text": "using gaurav odd for sure",
    "start": "1579470",
    "end": "1581660"
  },
  {
    "text": "but as far as I can remember and mcsnack",
    "start": "1581660",
    "end": "1584840"
  },
  {
    "text": "has a built in MPI support for",
    "start": "1584840",
    "end": "1587300"
  },
  {
    "text": "distributed computation I was wondering",
    "start": "1587300",
    "end": "1589580"
  },
  {
    "text": "if you could integrate natively imax net",
    "start": "1589580",
    "end": "1592520"
  },
  {
    "text": "into cue flow with any specific MX net",
    "start": "1592520",
    "end": "1596090"
  },
  {
    "text": "operator maybe so I think the question",
    "start": "1596090",
    "end": "1599960"
  },
  {
    "text": "is we discuss about different",
    "start": "1599960",
    "end": "1602200"
  },
  {
    "text": "distribution strategy and discussed",
    "start": "1602200",
    "end": "1604220"
  },
  {
    "text": "about different frameworks but we",
    "start": "1604220",
    "end": "1606530"
  },
  {
    "text": "probably didn't talk a lot about XML MX",
    "start": "1606530",
    "end": "1608960"
  },
  {
    "text": "net and your question was MX net",
    "start": "1608960",
    "end": "1612440"
  },
  {
    "text": "actually have a support our distribution",
    "start": "1612440",
    "end": "1615260"
  },
  {
    "text": "strategy building",
    "start": "1615260",
    "end": "1617600"
  },
  {
    "text": "so you're just wondering if this one is",
    "start": "1617600",
    "end": "1619940"
  },
  {
    "text": "something we can see that it's very",
    "start": "1619940",
    "end": "1624740"
  },
  {
    "text": "similar to 10 suppor and potage which",
    "start": "1624740",
    "end": "1627950"
  },
  {
    "text": "have their own built-in support for",
    "start": "1627950",
    "end": "1630650"
  },
  {
    "text": "different distribute strategies but so",
    "start": "1630650",
    "end": "1635180"
  },
  {
    "text": "the answer is totally up to you to",
    "start": "1635180",
    "end": "1637220"
  },
  {
    "text": "whether to use the beauty in this UV",
    "start": "1637220",
    "end": "1639260"
  },
  {
    "text": "support or not there's also a horror",
    "start": "1639260",
    "end": "1641840"
  },
  {
    "text": "would support horror would integration",
    "start": "1641840",
    "end": "1645230"
  },
  {
    "text": "with a match net so that you can run",
    "start": "1645230",
    "end": "1647390"
  },
  {
    "text": "Amex not using her own as well under the",
    "start": "1647390",
    "end": "1650810"
  },
  {
    "text": "standardized hallowed MPI stories very",
    "start": "1650810",
    "end": "1655490"
  },
  {
    "text": "easy to change to switch one fluid for",
    "start": "1655490",
    "end": "1658220"
  },
  {
    "text": "food if we move to another so it's easy",
    "start": "1658220",
    "end": "1661580"
  },
  {
    "text": "so sometimes if you wanna do different",
    "start": "1661580",
    "end": "1665180"
  },
  {
    "text": "pieces on different frameworks that",
    "start": "1665180",
    "end": "1666800"
  },
  {
    "text": "might be helpful maybe I can add a",
    "start": "1666800",
    "end": "1669800"
  },
  {
    "text": "little bit more comment you feel having",
    "start": "1669800",
    "end": "1672830"
  },
  {
    "text": "me involved in different machine",
    "start": "1672830",
    "end": "1674810"
  },
  {
    "text": "learning framework you probably notice",
    "start": "1674810",
    "end": "1676370"
  },
  {
    "text": "that a lot of ways to do the same thing",
    "start": "1676370",
    "end": "1679580"
  },
  {
    "text": "in tensorflow one dot X if you want to",
    "start": "1679580",
    "end": "1682940"
  },
  {
    "text": "build a model you can use TF Harris TF",
    "start": "1682940",
    "end": "1685940"
  },
  {
    "text": "assuming that you have layers and that",
    "start": "1685940",
    "end": "1687800"
  },
  {
    "text": "you have asleep eventually I would like",
    "start": "1687800",
    "end": "1691190"
  },
  {
    "text": "to say is",
    "start": "1691190",
    "end": "1692570"
  },
  {
    "text": "something you have the freedom to see",
    "start": "1692570",
    "end": "1694940"
  },
  {
    "text": "like any framework or any way to build",
    "start": "1694940",
    "end": "1697640"
  },
  {
    "text": "your model or beauty or distributed deep",
    "start": "1697640",
    "end": "1700820"
  },
  {
    "text": "learning framework available that",
    "start": "1700820",
    "end": "1703810"
  },
  {
    "text": "basically you want to stick with the",
    "start": "1703810",
    "end": "1706310"
  },
  {
    "text": "majority of the users because that's as",
    "start": "1706310",
    "end": "1709160"
  },
  {
    "text": "far as I know many frame workers are not",
    "start": "1709160",
    "end": "1711910"
  },
  {
    "text": "truly in production years or now truly",
    "start": "1711910",
    "end": "1715420"
  },
  {
    "text": "widely use which actually you may",
    "start": "1715420",
    "end": "1717950"
  },
  {
    "text": "encounter some issues you feel use them",
    "start": "1717950",
    "end": "1720860"
  },
  {
    "text": "less know less known frameworks or less",
    "start": "1720860",
    "end": "1724180"
  },
  {
    "text": "less yield frameworks so that's my",
    "start": "1724180",
    "end": "1727160"
  },
  {
    "text": "suggestion any any other questions I",
    "start": "1727160",
    "end": "1733090"
  },
  {
    "text": "guess I guess that's it for today thanks",
    "start": "1733090",
    "end": "1736370"
  },
  {
    "text": "everyone for coming to this talk have a",
    "start": "1736370",
    "end": "1738320"
  },
  {
    "text": "great day and enjoy your stay in",
    "start": "1738320",
    "end": "1740240"
  },
  {
    "text": "Barcelona beautiful Barcelona",
    "start": "1740240",
    "end": "1743800"
  },
  {
    "text": "[Applause]",
    "start": "1743800",
    "end": "1746849"
  }
]
[
  {
    "text": "hello everyone uh and thank you all for coming my name is Leila i work at",
    "start": "160",
    "end": "5680"
  },
  {
    "text": "Shopify as a site reliability engineer uh I'm part of the resiliency",
    "start": "5680",
    "end": "11120"
  },
  {
    "text": "organization at Shopify whose uh responsibility is to ensure Shopify is",
    "start": "11120",
    "end": "16960"
  },
  {
    "text": "always uh up and running ready and reliable for merchants uh and our buyers",
    "start": "16960",
    "end": "22080"
  },
  {
    "text": "across the globe my talk today will be about a project uh where we improved",
    "start": "22080",
    "end": "28960"
  },
  {
    "text": "elastic search indexing performance as well as the reliability of our infrastructure uh by using dedicated",
    "start": "28960",
    "end": "36640"
  },
  {
    "text": "node pools that are automatically scaled by kada",
    "start": "36640",
    "end": "42040"
  },
  {
    "text": "scalers in the next 30 minutes we will learn how at Shopify we uh host the",
    "start": "42040",
    "end": "48800"
  },
  {
    "text": "search infrastructure on top of Kubernetes we'll talk about the entire data pipeline that writes data from uh",
    "start": "48800",
    "end": "56559"
  },
  {
    "text": "SQL to elastic search through CFKA and the resilience of its architecture uh I",
    "start": "56559",
    "end": "62239"
  },
  {
    "text": "will follow by presenting the problem we needed to solve and we'll share our",
    "start": "62239",
    "end": "68000"
  },
  {
    "text": "solution for it followed by um some technical details on how to use SCADA uh",
    "start": "68000",
    "end": "73840"
  },
  {
    "text": "scalers for scaling uh Kubernetes workloads and I will conclude the presentation with a Q&A",
    "start": "73840",
    "end": "81520"
  },
  {
    "text": "shopify is the all-in-one um commerce platform uh to start run and get and",
    "start": "81520",
    "end": "87840"
  },
  {
    "text": "grow a business uh it is the leading global commerce company that provides essential internet infrastructure for",
    "start": "87840",
    "end": "95040"
  },
  {
    "text": "commerce uh as well as uh trusted tools to start scale uh and run a retail",
    "start": "95040",
    "end": "100880"
  },
  {
    "text": "business of any size currently we have over uh 3 million",
    "start": "100880",
    "end": "106720"
  },
  {
    "text": "businesses using our platform uh we have merchants like Gym Shark and Fashion",
    "start": "106720",
    "end": "112240"
  },
  {
    "text": "Nova selling their products with us uh we represent over 175 countries and have about 10% of the",
    "start": "112240",
    "end": "121119"
  },
  {
    "text": "total US commerce um in the summer of 2024 we reached a trill uh trillion",
    "start": "121119",
    "end": "127840"
  },
  {
    "text": "dollars in gross merchandise volume one of the largest events in commerce is",
    "start": "127840",
    "end": "135440"
  },
  {
    "text": "the Black Friday Cyber Monday week uh which we call it BFCM uh to share more",
    "start": "135440",
    "end": "140959"
  },
  {
    "text": "stats about the scale of Shopify uh during the BFCM of 2024 Shopify",
    "start": "140959",
    "end": "147120"
  },
  {
    "text": "processed around 58 pabytes of data served more than a trillion edge",
    "start": "147120",
    "end": "153440"
  },
  {
    "text": "requests as well as more than 10 trillion database queries uh which led to around 12 billion dollars of global",
    "start": "153440",
    "end": "160959"
  },
  {
    "text": "sales search is a fundamental part of any",
    "start": "160959",
    "end": "166959"
  },
  {
    "text": "commerce platform that allows buyers to search and filter for products or for merchants",
    "start": "166959",
    "end": "174080"
  },
  {
    "text": "to fulfill their orders manage their customers and inventory and when you go to any online store and search for a",
    "start": "174080",
    "end": "181519"
  },
  {
    "text": "product your request goes to a search engine that is backed by a secondary",
    "start": "181519",
    "end": "186879"
  },
  {
    "text": "data store which is different from traditional databases uh and the search",
    "start": "186879",
    "end": "192400"
  },
  {
    "text": "engine that we use at Shopify is Elastic Search a quick refresher on Elastic",
    "start": "192400",
    "end": "199680"
  },
  {
    "text": "Search it is a distributed text search and analytics engine uh it is built on",
    "start": "199680",
    "end": "205840"
  },
  {
    "text": "top of Lucine that has full text search capabilities that are well suited to the",
    "start": "205840",
    "end": "211440"
  },
  {
    "text": "e-commerce domain it's also a scalable and fault tolerant system and it handles a lot of the hard",
    "start": "211440",
    "end": "219040"
  },
  {
    "text": "parts of running a distributed uh system very well for us elastic search stores",
    "start": "219040",
    "end": "224799"
  },
  {
    "text": "data uh that share similar characteristics in a logical name space",
    "start": "224799",
    "end": "230400"
  },
  {
    "text": "called an index these indices are split into multiple charts which can be either",
    "start": "230400",
    "end": "236720"
  },
  {
    "text": "primary shards or replica charts [Music] we run our fleet of elastic search",
    "start": "236720",
    "end": "243120"
  },
  {
    "text": "clusters on managed Kubernetes clusters GK on top of uh GCP and we deploy and",
    "start": "243120",
    "end": "248720"
  },
  {
    "text": "maintain them using uh a custom Kubernetes um controller that we have",
    "start": "248720",
    "end": "255840"
  },
  {
    "text": "built shopify is a large um complex technical ecosystem that is made up of a",
    "start": "257000",
    "end": "263440"
  },
  {
    "text": "variety of apps and services and the biggest service at Shopify is called the Shopify core which is a big rails",
    "start": "263440",
    "end": "270320"
  },
  {
    "text": "monolith that powers all of our merchant shops and storefronts we run Shopify in",
    "start": "270320",
    "end": "277199"
  },
  {
    "text": "GCP regions for resiliency uh what you're looking at here is a um high",
    "start": "277199",
    "end": "283360"
  },
  {
    "text": "level structure of Shopify core in a single region the entire Shopify core in a region is broken down into above a 100",
    "start": "283360",
    "end": "291520"
  },
  {
    "text": "logical groups of SQL databases and instances of other services which are simplified in this slide um all of these",
    "start": "291520",
    "end": "299919"
  },
  {
    "text": "services power all of our online store functionality for the shops running in",
    "start": "299919",
    "end": "305759"
  },
  {
    "text": "that region uh in every region we run one instance of elastic search for",
    "start": "305759",
    "end": "312720"
  },
  {
    "text": "Shopify core that provides search functionality for the shops in that",
    "start": "312720",
    "end": "318960"
  },
  {
    "text": "region to give more context elastic search is used as a secondary data store",
    "start": "319639",
    "end": "325440"
  },
  {
    "text": "it is util uh utilized to provide additional functionalities such as fast",
    "start": "325440",
    "end": "330880"
  },
  {
    "text": "search capabilities aggregations or full text search on top of the existing data",
    "start": "330880",
    "end": "336639"
  },
  {
    "text": "in the primary data store which is SQL in our",
    "start": "336639",
    "end": "341198"
  },
  {
    "text": "case we have an ingest pipeline in each region that consists of CFKA topics and",
    "start": "342039",
    "end": "348160"
  },
  {
    "text": "CFKA consumers we produce updates made to records for all related SQL instances",
    "start": "348160",
    "end": "354960"
  },
  {
    "text": "in the region to our CFKA topics and our consumers pick up those messages from the topics and write them to the correct",
    "start": "354960",
    "end": "362240"
  },
  {
    "text": "u elastic search index in real time indexing is a term we will use a",
    "start": "362240",
    "end": "369600"
  },
  {
    "text": "lot in this um talk uh it is uh the act of uh writing documents from the primary",
    "start": "369600",
    "end": "376720"
  },
  {
    "text": "data store to elastic",
    "start": "376720",
    "end": "381280"
  },
  {
    "text": "search we store elastic search documents in uh elastic search indices for example",
    "start": "382120",
    "end": "389199"
  },
  {
    "text": "we have an index that allows merchants to search and filter through the orders they receive or another index that",
    "start": "389199",
    "end": "396639"
  },
  {
    "text": "allows them to search uh through their products or their customers",
    "start": "396639",
    "end": "402440"
  },
  {
    "text": "uh merchants are able merchants or buyers are able to search uh these",
    "start": "404800",
    "end": "410080"
  },
  {
    "text": "indices um um and uh their their queries are sent",
    "start": "410080",
    "end": "416720"
  },
  {
    "text": "to the correct elastic search index through a uh routing layer",
    "start": "416720",
    "end": "423639"
  },
  {
    "text": "our focus in this talk will be on the indexing path uh shown here which we",
    "start": "424160",
    "end": "429759"
  },
  {
    "text": "call the indexing pipeline in the previous slide uh we saw",
    "start": "429759",
    "end": "435199"
  },
  {
    "text": "the indexing pipeline that brought data from SQL as the primary data store to elastic search through CFKA but that was",
    "start": "435199",
    "end": "442639"
  },
  {
    "text": "really simplified and we have actually built two different uh indexing pipelines for two different write",
    "start": "442639",
    "end": "448960"
  },
  {
    "text": "profiles one of them is called the real time pipeline",
    "start": "448960",
    "end": "454919"
  },
  {
    "text": "um which for example indexes a product to elastic search and makes it available",
    "start": "454919",
    "end": "460319"
  },
  {
    "text": "for search for buyers when a merchant for example adds a new product to their online store the other one is called the",
    "start": "460319",
    "end": "466720"
  },
  {
    "text": "reindex uh pipeline we have a lot of developers at Shopify um they create",
    "start": "466720",
    "end": "473199"
  },
  {
    "text": "indices modify index analyzers and add or remove versions of the index",
    "start": "473199",
    "end": "479440"
  },
  {
    "text": "uh they add or remove fields from the the indices and basically they change the shape of the indices a lot and when",
    "start": "479440",
    "end": "487759"
  },
  {
    "text": "that happens we need to uh migrate all that data to a new version of the index",
    "start": "487759",
    "end": "494000"
  },
  {
    "text": "and promote that index to make the new feature available to the merchants uh as well as the buyers we call this",
    "start": "494000",
    "end": "500759"
  },
  {
    "text": "reindexing which basically means rebuilding an entire elastic search uh",
    "start": "500759",
    "end": "506000"
  },
  {
    "text": "index from SQL records and as I just mentioned we have two",
    "start": "506000",
    "end": "513039"
  },
  {
    "text": "separate indexing pipelines for real time and reindex rights uh which we see on this slide as a bit of a background",
    "start": "513039",
    "end": "521120"
  },
  {
    "text": "CFKA is a distributed publish subscribe messaging uh messaging system data is",
    "start": "521120",
    "end": "527519"
  },
  {
    "text": "written to CFKA topics by producers and consumed from those topics by consumers",
    "start": "527519",
    "end": "533839"
  },
  {
    "text": "we have separate CFKA topics for each pipeline the real time CFKA consumers",
    "start": "533839",
    "end": "539600"
  },
  {
    "text": "consume from the real-time CFKA topics and the uh and write to the production",
    "start": "539600",
    "end": "546320"
  },
  {
    "text": "indices these indices provide search results for buyers and",
    "start": "546320",
    "end": "551480"
  },
  {
    "text": "merchants the reindex consumers on the other hand um do not write to production",
    "start": "551480",
    "end": "557040"
  },
  {
    "text": "indices they only write to indices uh whose aliases end with a",
    "start": "557040",
    "end": "564160"
  },
  {
    "text": "new the new indices get created when we",
    "start": "564920",
    "end": "570000"
  },
  {
    "text": "start a reindex uh for a specific index for example for the orders index uh the",
    "start": "570000",
    "end": "576160"
  },
  {
    "text": "orders new index will eventually be a copy of the production index uh for",
    "start": "576160",
    "end": "581519"
  },
  {
    "text": "orders but with different fields and different features a new index does not receive production",
    "start": "581519",
    "end": "589279"
  },
  {
    "text": "queries because its data is in uh is incomplete until all the necessary",
    "start": "589279",
    "end": "594480"
  },
  {
    "text": "records from SQL have been written to it after the dot new index is created",
    "start": "594480",
    "end": "602480"
  },
  {
    "text": "some jobs get spawned and uh read the necessary records from SQL produce them",
    "start": "602480",
    "end": "608240"
  },
  {
    "text": "to the reindex cafka topic which will be consumed by the reindex consumers and",
    "start": "608240",
    "end": "613680"
  },
  {
    "text": "will eventually be written to the new index and to make sure that the new",
    "start": "613680",
    "end": "619760"
  },
  {
    "text": "index also receives the real time updates uh the reindex topic also receives",
    "start": "619760",
    "end": "625839"
  },
  {
    "text": "real-time updates made to SQL after a while all records in SQL will",
    "start": "625839",
    "end": "633680"
  },
  {
    "text": "get processed and no more reindex writes will be produced to the reindex cafka topic at this time the reindex is",
    "start": "633680",
    "end": "641279"
  },
  {
    "text": "finished and we can flip the new index live flipping it live basically means",
    "start": "641279",
    "end": "646640"
  },
  {
    "text": "changing the alias for the production and the new index and after this",
    "start": "646640",
    "end": "651800"
  },
  {
    "text": "the new will become our new production index and will have the updated fields",
    "start": "651800",
    "end": "658399"
  },
  {
    "text": "and features and will be queried by the clients as mentioned before our elastic",
    "start": "658399",
    "end": "665600"
  },
  {
    "text": "search clusters run on Kubernetes on top of GCP across different uh regions and",
    "start": "665600",
    "end": "671200"
  },
  {
    "text": "availability zones it's good to know that today the entire Shopify ecosystem including the Shopify core uh its uh",
    "start": "671200",
    "end": "679959"
  },
  {
    "text": "storefronts and other services run across the globe uh from North America to Europe and to Singapore we have",
    "start": "679959",
    "end": "687680"
  },
  {
    "text": "elastic search clusters spread across these regions giving us resilience and",
    "start": "687680",
    "end": "693680"
  },
  {
    "text": "availability through redundancy so let's talk more about resilience",
    "start": "693680",
    "end": "700640"
  },
  {
    "text": "taking a closer look at uh an example GCP region where Shopify core and its uh",
    "start": "700640",
    "end": "706800"
  },
  {
    "text": "elastic search cluster runs we have the indexing pipeline updating uh elastic",
    "start": "706800",
    "end": "713040"
  },
  {
    "text": "search when changes are made to SQL records and we can see here that search queries are sent to the elastic search",
    "start": "713040",
    "end": "720480"
  },
  {
    "text": "through a routing layer meaning that queries made to shops in a certain region are routed to the elastic search",
    "start": "720480",
    "end": "727680"
  },
  {
    "text": "in the same region we know that the first step towards high availability is redundancy",
    "start": "727680",
    "end": "735120"
  },
  {
    "text": "and to mitigate regional failures we should replicate our systems to another",
    "start": "735120",
    "end": "740920"
  },
  {
    "text": "region the the active SQL instances and um CFKA topics in different regions they",
    "start": "740920",
    "end": "748480"
  },
  {
    "text": "hold different data sets and we need to replicate their data between regions so",
    "start": "748480",
    "end": "754079"
  },
  {
    "text": "both elastic search clusters uh have the uh the same data set and with this inter",
    "start": "754079",
    "end": "759839"
  },
  {
    "text": "region uh data replication if one of the elastic search clusters goes down uh we",
    "start": "759839",
    "end": "766240"
  },
  {
    "text": "can fail over the query traffic to the elastic search cluster that is",
    "start": "766240",
    "end": "771600"
  },
  {
    "text": "functional until the other one has recovered at the application layer",
    "start": "771600",
    "end": "778959"
  },
  {
    "text": "elastic search also provides fall tolerance by being zone aware meaning that if we deploy our Kubernetes cluster",
    "start": "778959",
    "end": "786000"
  },
  {
    "text": "across three uh different availability zones when elastic search distributes",
    "start": "786000",
    "end": "791920"
  },
  {
    "text": "primary and replica shards uh it distributes them across these zones in a way that the primary and replica for one",
    "start": "791920",
    "end": "799360"
  },
  {
    "text": "shard do not end up uh in the same availability zone",
    "start": "799360",
    "end": "805760"
  },
  {
    "text": "we use node affinity rules to ensure that two pods from the same uh elastic",
    "start": "805760",
    "end": "811760"
  },
  {
    "text": "search cluster do not get uh scheduled on the same node and we also taint the",
    "start": "811760",
    "end": "817440"
  },
  {
    "text": "GKE node so only the elastic search pods are deployed on them the elastic search pods are given",
    "start": "817440",
    "end": "825360"
  },
  {
    "text": "the right toleration so they can be scheduled on the right GKE",
    "start": "825360",
    "end": "830920"
  },
  {
    "text": "nodes with this zone aware setting uh we can also do maintenance more quickly um",
    "start": "830920",
    "end": "836800"
  },
  {
    "text": "as we can bring down an entire availability zone for maintenance without being worried about data",
    "start": "836800",
    "end": "843800"
  },
  {
    "text": "loss to give a sense of uh the scale of search at Shopify as of today the search",
    "start": "843800",
    "end": "850160"
  },
  {
    "text": "platform team manages above 800 distinct elastic search clusters some of which are as large as 260 node clusters and",
    "start": "850160",
    "end": "858399"
  },
  {
    "text": "many are as small as just three node clusters and together they store more",
    "start": "858399",
    "end": "864320"
  },
  {
    "text": "than three pabytes of data for Shopify core elastic search the",
    "start": "864320",
    "end": "870320"
  },
  {
    "text": "real-time indexing rate can peak at 90,000 documents per second uh while our",
    "start": "870320",
    "end": "875760"
  },
  {
    "text": "reindex indexing rate peaks at 500,000 documents per second and as you can see",
    "start": "875760",
    "end": "881920"
  },
  {
    "text": "the reindex pipeline uh the reindex pipeline throughput is a lot higher than",
    "start": "881920",
    "end": "887519"
  },
  {
    "text": "that of the real time pipeline and to recall reindexes are done occasionally",
    "start": "887519",
    "end": "893760"
  },
  {
    "text": "to change the shape of an index in other words they are an occasional burst of",
    "start": "893760",
    "end": "898959"
  },
  {
    "text": "rights to elastic search this is actually a nice segue to the problem",
    "start": "898959",
    "end": "905440"
  },
  {
    "text": "statement uh which will be followed by the solution what you see in this slide is",
    "start": "905440",
    "end": "912720"
  },
  {
    "text": "the distribution of elastic search pods across many VMs running on GCP as",
    "start": "912720",
    "end": "919279"
  },
  {
    "text": "mentioned before an elastic search index is split into many shards and each shard",
    "start": "919279",
    "end": "924320"
  },
  {
    "text": "has a replica for example the production index for orders is split into a,024",
    "start": "924320",
    "end": "930880"
  },
  {
    "text": "uh primary shards each of them having a replica chart which is um shown by a different color in here this index uh",
    "start": "930880",
    "end": "939040"
  },
  {
    "text": "receives realtime writes as well as production queries when a reindex starts for maintenance",
    "start": "939040",
    "end": "945760"
  },
  {
    "text": "another index called the orders new with the same number of uh charts is created",
    "start": "945760",
    "end": "952079"
  },
  {
    "text": "on the same VMs which will receive the heavy reindex rights and since the",
    "start": "952079",
    "end": "957600"
  },
  {
    "text": "production and the new index share the same compute and storage resources the",
    "start": "957600",
    "end": "963199"
  },
  {
    "text": "heavy reindex rights um will impact the real time rights and slow them",
    "start": "963199",
    "end": "968440"
  },
  {
    "text": "down and delayed real-time indexing uh results in",
    "start": "968440",
    "end": "974800"
  },
  {
    "text": "uh stale or inaccurate search results which could result in lost revenue for",
    "start": "974800",
    "end": "980399"
  },
  {
    "text": "our merchants which is a big deal so the fact that real time and reindex",
    "start": "980399",
    "end": "987920"
  },
  {
    "text": "rights share the same compute and storage resources uh leads to reindexes impact uh impacting production rights",
    "start": "987920",
    "end": "995120"
  },
  {
    "text": "and queries which leads to uh pager fatigue uh because the on call would get",
    "start": "995120",
    "end": "1001440"
  },
  {
    "text": "paged for real-time indexing delay which can only be mitigated by",
    "start": "1001440",
    "end": "1007920"
  },
  {
    "text": "stopping the reindex starting it all over again uh which also uh slows down",
    "start": "1007920",
    "end": "1013920"
  },
  {
    "text": "feature rollouts for our developers our initial approach to solve",
    "start": "1013920",
    "end": "1019360"
  },
  {
    "text": "this problem was to overprovision the cluster to always be ready uh to handle",
    "start": "1019360",
    "end": "1025199"
  },
  {
    "text": "the load of the reindexes and this became too expensive as Shopify kept",
    "start": "1025199",
    "end": "1030720"
  },
  {
    "text": "growing and the cost was no longer acceptable",
    "start": "1030720",
    "end": "1036120"
  },
  {
    "text": "therefore we decided to separate the infrastructure for real time and reindex",
    "start": "1036880",
    "end": "1042720"
  },
  {
    "text": "rights this was a huge undertaking because it required us to make some fundamental changes to our existing",
    "start": "1042720",
    "end": "1049440"
  },
  {
    "text": "reindex pipeline the first step to do this was to create a separate GKE node",
    "start": "1049440",
    "end": "1055120"
  },
  {
    "text": "poolool just for running reindexes we leveraged Kubernetes taints and",
    "start": "1055120",
    "end": "1061720"
  },
  {
    "text": "tolerations to ensure that elastic search pods for reindexes only get",
    "start": "1061720",
    "end": "1067200"
  },
  {
    "text": "scheduled on the reindex GKE nodes uh same as for the elastic search pods for",
    "start": "1067200",
    "end": "1073760"
  },
  {
    "text": "realtime rights",
    "start": "1073760",
    "end": "1077320"
  },
  {
    "text": "just as a quick refresher a Kubernetes taint is",
    "start": "1081120",
    "end": "1086880"
  },
  {
    "text": "a mechanism that allows a node to repel a set of pots taints are applied to nodes and",
    "start": "1086880",
    "end": "1095200"
  },
  {
    "text": "they work together with tolerations which are applied to pods the primary purpose of using taints is to ensure",
    "start": "1095200",
    "end": "1102320"
  },
  {
    "text": "that certain pods uh are not scheduled on the wrong nodes",
    "start": "1102320",
    "end": "1108320"
  },
  {
    "text": "so giving the reindex and real-time toleration to pods uh will ensure they get scheduled on different note pools",
    "start": "1108320",
    "end": "1115120"
  },
  {
    "text": "which will provide the first step towards uh isolation of reindex and real time",
    "start": "1115120",
    "end": "1121240"
  },
  {
    "text": "rights we use the elastic search uh builtin chart allocation settings to",
    "start": "1121240",
    "end": "1127679"
  },
  {
    "text": "force all indices uh to be hosted on the elastic search pods that run on the real",
    "start": "1127679",
    "end": "1133120"
  },
  {
    "text": "time note poolool except for the ones whose aliases and uh with a new which",
    "start": "1133120",
    "end": "1138559"
  },
  {
    "text": "should be hosted on the elastic search pods uh that run on the reindex note",
    "start": "1138559",
    "end": "1144520"
  },
  {
    "text": "poolool once the reindex is done we switch the alias for the new index which",
    "start": "1144520",
    "end": "1150160"
  },
  {
    "text": "will force its charts to be relocated to the real-time note pool and uh become",
    "start": "1150160",
    "end": "1156240"
  },
  {
    "text": "searchable by clients and this way reindexes no longer impact production",
    "start": "1156240",
    "end": "1162160"
  },
  {
    "text": "reads and rights also since the real-time node",
    "start": "1162160",
    "end": "1167520"
  },
  {
    "text": "poolool no longer has to provide for the heavy reindex rights there is no need to",
    "start": "1167520",
    "end": "1172640"
  },
  {
    "text": "overprovision uh that no pool and it gives us a great opportunity to save infrastructure",
    "start": "1172640",
    "end": "1179400"
  },
  {
    "text": "costs but as you see now it's the reindex notepool that is burning",
    "start": "1179400",
    "end": "1185720"
  },
  {
    "text": "money and this is where node autoscaling uh will come in handy ideally we would",
    "start": "1185720",
    "end": "1191679"
  },
  {
    "text": "need a very small GKE node pool that gets scaled scales up when the reindex",
    "start": "1191679",
    "end": "1197160"
  },
  {
    "text": "starts and we expect that the node pool uh scales up depending on the size the",
    "start": "1197160",
    "end": "1204000"
  },
  {
    "text": "number of shards uh of the index that we want to backfill we picked Kada which stands for",
    "start": "1204000",
    "end": "1212080"
  },
  {
    "text": "Kubernetes event-driven uh autoscaling which is an open source project that",
    "start": "1212080",
    "end": "1217520"
  },
  {
    "text": "provides autoscaling for Kubernetes workloads uh it's designed to extend the capabilities of the Kubernetes",
    "start": "1217520",
    "end": "1224880"
  },
  {
    "text": "horizontal pod autoscaler by allowing workloads to scale uh based on metrics",
    "start": "1224880",
    "end": "1231120"
  },
  {
    "text": "from various event sources rather than just uh CPU or memory utilization",
    "start": "1231120",
    "end": "1237360"
  },
  {
    "text": "this makes KADA particularly useful uh for applications that need to scale in",
    "start": "1237360",
    "end": "1242960"
  },
  {
    "text": "response to events like Q length uh number of incoming messages or in our",
    "start": "1242960",
    "end": "1248280"
  },
  {
    "text": "case to automatically scale up the Kubernetes workload when a reindex",
    "start": "1248280",
    "end": "1253679"
  },
  {
    "text": "starts scaling up the Kubernetes workload uh will force the GKE node",
    "start": "1253679",
    "end": "1259760"
  },
  {
    "text": "poolool hosting the reindex pods to be expanded as well kada is implemented as",
    "start": "1259760",
    "end": "1266240"
  },
  {
    "text": "a Kubernetes operator which uses custom resources",
    "start": "1266240",
    "end": "1271480"
  },
  {
    "text": "um to define how scaling should behave and uh it consists of two main",
    "start": "1271480",
    "end": "1276840"
  },
  {
    "text": "components one is the KADA controller that watches for a KADA custom resource",
    "start": "1276840",
    "end": "1282720"
  },
  {
    "text": "called the uh scaled object and manages the life cycle of the uh corresponding",
    "start": "1282720",
    "end": "1288640"
  },
  {
    "text": "HPA resources the other one is the metrics adapter that collects and",
    "start": "1288640",
    "end": "1294400"
  },
  {
    "text": "provides uh metrics to the Kubernetes HPA which then makes decisions about",
    "start": "1294400",
    "end": "1300799"
  },
  {
    "text": "scaling the application pods uh up or down based on those",
    "start": "1300799",
    "end": "1307320"
  },
  {
    "text": "metrics kada supports a variety of event sources um called the scalers and",
    "start": "1307320",
    "end": "1313600"
  },
  {
    "text": "Prometheus is one of them uh each event source is represented as a trigger in the Kada",
    "start": "1313600",
    "end": "1321120"
  },
  {
    "text": "configuration scaled objects are custom resources uh used for scaling",
    "start": "1321880",
    "end": "1327000"
  },
  {
    "text": "deployments uh stateful sets or any other scalable um Kubernetes workload we",
    "start": "1327000",
    "end": "1333440"
  },
  {
    "text": "define the triggers and scaling behaviors used by Kada to scale workloads uh you see an example of a",
    "start": "1333440",
    "end": "1341120"
  },
  {
    "text": "scaled object uh on the slide uh for our specific use case we set the scale",
    "start": "1341120",
    "end": "1346320"
  },
  {
    "text": "target to our reindex stateful set that uh runs the elastic search pods that are",
    "start": "1346320",
    "end": "1352080"
  },
  {
    "text": "used for reindexes and we also have settings for min and max replica counts",
    "start": "1352080",
    "end": "1357679"
  },
  {
    "text": "uh these settings determine the minimum and maximum number of replicas that the stateful set can scale to based on the",
    "start": "1357679",
    "end": "1364720"
  },
  {
    "text": "events that are triggering the uh scaling action for us we set the minimum",
    "start": "1364720",
    "end": "1370080"
  },
  {
    "text": "as low as three and the maximum to around 200",
    "start": "1370080",
    "end": "1375480"
  },
  {
    "text": "replicas the Prometheus trigger in Kada enables autoscaling uh based on the",
    "start": "1375480",
    "end": "1381440"
  },
  {
    "text": "results of the Prometheus query uh when you configure a scale object with a",
    "start": "1381440",
    "end": "1387280"
  },
  {
    "text": "Prometheus trigger Kada will periodically send queries uh to a specified Prometheus uh server and uh",
    "start": "1387280",
    "end": "1395919"
  },
  {
    "text": "the responses to these queries are then used to make decisions about uh scaling",
    "start": "1395919",
    "end": "1401200"
  },
  {
    "text": "the Kubernetes workloads up or down and for our use case we wrote a",
    "start": "1401200",
    "end": "1407280"
  },
  {
    "text": "Prometheus query that calculates the number of shards uh divided by the",
    "start": "1407280",
    "end": "1413360"
  },
  {
    "text": "number of nodes and we set the threshold to one uh which means that ideally for",
    "start": "1413360",
    "end": "1419120"
  },
  {
    "text": "peak performance uh we want to have one shard on a single node however if the",
    "start": "1419120",
    "end": "1426000"
  },
  {
    "text": "index has like 2,000 shards and the max replica count is set to 200 we will end",
    "start": "1426000",
    "end": "1432000"
  },
  {
    "text": "up with um only 200 nodes which means that each node will have 10",
    "start": "1432000",
    "end": "1438720"
  },
  {
    "text": "charts the following slides show an example for node autoscaling uh we have",
    "start": "1439080",
    "end": "1444559"
  },
  {
    "text": "a real-time node poolool hosting charts for production indices we also have a reindex node poolool with a minimum of",
    "start": "1444559",
    "end": "1451840"
  },
  {
    "text": "three nodes that initially host no indices so the prometheus query for kada",
    "start": "1451840",
    "end": "1458240"
  },
  {
    "text": "that calculates the number of shards uh divided by the number of nodes will return zero kada convers uh compares the",
    "start": "1458240",
    "end": "1466480"
  },
  {
    "text": "query results to the threshold we have set uh which is one and decides to do nothing because the reindex workload",
    "start": "1466480",
    "end": "1474480"
  },
  {
    "text": "already has three replicas which is the minimum allowed",
    "start": "1474480",
    "end": "1479520"
  },
  {
    "text": "next the reindex starts for an index that has for example four primary shards and four replica shards so eight shards",
    "start": "1479520",
    "end": "1486640"
  },
  {
    "text": "in total because of the routing allocations that we have set for elastic search the shards of the new index will",
    "start": "1486640",
    "end": "1493520"
  },
  {
    "text": "be created on the pods running on the reindex node pool",
    "start": "1493520",
    "end": "1498640"
  },
  {
    "text": "uh and what once this happens the primeus query would return a value",
    "start": "1498640",
    "end": "1503679"
  },
  {
    "text": "higher than our threshold of one which signals to kada to scale the reindex",
    "start": "1503679",
    "end": "1509039"
  },
  {
    "text": "workload up until the result for the query uh becomes equal to the threshold",
    "start": "1509039",
    "end": "1514559"
  },
  {
    "text": "scaling up the reindex workload expands the underlying uh GKE note",
    "start": "1514559",
    "end": "1521000"
  },
  {
    "text": "pool once the node pool gets scaled up uh elastic search automatically balances",
    "start": "1521000",
    "end": "1526880"
  },
  {
    "text": "shards across the nodes so each node of the node pool will have one shard now",
    "start": "1526880",
    "end": "1532720"
  },
  {
    "text": "the primeus query returns one which is equal to the threshold and kada will",
    "start": "1532720",
    "end": "1538159"
  },
  {
    "text": "take no scaling actions after the reindex is done uh and we switch the new",
    "start": "1538159",
    "end": "1544000"
  },
  {
    "text": "index live all charts from the reindex node pools get evacuated by elastic search",
    "start": "1544000",
    "end": "1550960"
  },
  {
    "text": "and will get scheduled on the real time node poolool at this point the prometheus query returns zero which is",
    "start": "1550960",
    "end": "1557679"
  },
  {
    "text": "below the threshold and consequently kada decides to scale down the reindex",
    "start": "1557679",
    "end": "1563679"
  },
  {
    "text": "uh workload the reindex workload gets scaled down by Kada which consequently",
    "start": "1563679",
    "end": "1569760"
  },
  {
    "text": "scales down the underlying uh GKE node pool to the minimum number of nodes",
    "start": "1569760",
    "end": "1575520"
  },
  {
    "text": "which in our case was three and Kada will take no further actions until a new",
    "start": "1575520",
    "end": "1581600"
  },
  {
    "text": "reindex is started with dedicated reindex nodes uh",
    "start": "1581600",
    "end": "1587679"
  },
  {
    "text": "we were able to reindex our orders index which has around 100 terabytes of data",
    "start": "1587679",
    "end": "1593440"
  },
  {
    "text": "40% faster the cute bite threads on the real-time nodes was also dropped by 98%",
    "start": "1593440",
    "end": "1600080"
  },
  {
    "text": "during reindexes which helped improve real-time writes performance and as a result the pager fatigue due to this",
    "start": "1600080",
    "end": "1607679"
  },
  {
    "text": "problem was no longer an issue and developers were able to ship features uh faster leveraging node autoscaling uh we",
    "start": "1607679",
    "end": "1615760"
  },
  {
    "text": "were able to reduce the total number of uh CPU cores and memory used by our",
    "start": "1615760",
    "end": "1621679"
  },
  {
    "text": "real-time node pool by 58% and 15% respectively",
    "start": "1621679",
    "end": "1626880"
  },
  {
    "text": "uh which led to a total saving of 43% in infrastructure",
    "start": "1626880",
    "end": "1632520"
  },
  {
    "text": "costs this was only an example of the interesting problems we solve at Shopify",
    "start": "1632520",
    "end": "1638320"
  },
  {
    "text": "uh we're always looking for people who are interested in solving problems at scale uh scan this QR code uh to get",
    "start": "1638320",
    "end": "1646480"
  },
  {
    "text": "more uh information and if you have any questions uh I'd be happy to answer them",
    "start": "1646480",
    "end": "1652000"
  },
  {
    "text": "thank you [Applause]",
    "start": "1652000",
    "end": "1662249"
  },
  {
    "text": "thank you",
    "start": "1662400",
    "end": "1665559"
  },
  {
    "text": "oh we have one question yeah it's going to be a quick one um when you scaling down scaling down your reindexing note",
    "start": "1667440",
    "end": "1676000"
  },
  {
    "text": "pool how do you make sure that you accidentally don't shut down the node",
    "start": "1676000",
    "end": "1681279"
  },
  {
    "text": "that still has a shard that didn't get moved to the other uh that's a really",
    "start": "1681279",
    "end": "1688399"
  },
  {
    "text": "good question um well we are saved by the the the results of the Prometheus",
    "start": "1688399",
    "end": "1694880"
  },
  {
    "text": "query if we have data on the nodes that we want to scale down the query will not",
    "start": "1694880",
    "end": "1700960"
  },
  {
    "text": "return zero it it will show that there are some shards uh on those nodes so",
    "start": "1700960",
    "end": "1706480"
  },
  {
    "text": "that query that divides the number of shards by the nodes will not return uh",
    "start": "1706480",
    "end": "1711679"
  },
  {
    "text": "zero but at some point some shards will move and some the the note pool gets",
    "start": "1711679",
    "end": "1718960"
  },
  {
    "text": "scaled down when all shards have moved when only when there are zero shards on",
    "start": "1718960",
    "end": "1725520"
  },
  {
    "text": "the reindex notes okay thank you thank you",
    "start": "1725520",
    "end": "1731720"
  },
  {
    "text": "hi one more question how fast do you scale up the worker nodes because when",
    "start": "1740000",
    "end": "1745600"
  },
  {
    "text": "you create the index with thousand shares it means that uh do you do you",
    "start": "1745600",
    "end": "1750960"
  },
  {
    "text": "scale up all the worker nodes at once it's uh you are able to define the",
    "start": "1750960",
    "end": "1757679"
  },
  {
    "text": "scaling behavior in the scaled object config uh you can like say scale up for me like five",
    "start": "1757679",
    "end": "1767440"
  },
  {
    "text": "pod at or which means five nodes at a time or like by a percentage if I'm not",
    "start": "1767440",
    "end": "1773760"
  },
  {
    "text": "wrong in our case for the the one that you mentioned like a very large index I",
    "start": "1773760",
    "end": "1779760"
  },
  {
    "text": "believe it took I think 30 minutes to scale up",
    "start": "1779760",
    "end": "1785600"
  },
  {
    "text": "which we really we are okay with because this is a maintenance uh kind of thing",
    "start": "1785600",
    "end": "1791760"
  },
  {
    "text": "so like 30 minutes is basically nothing it's just system warming up thank you",
    "start": "1791760",
    "end": "1798080"
  },
  {
    "text": "thank you hi i didn't really get how you manage",
    "start": "1798080",
    "end": "1804480"
  },
  {
    "text": "the affinity between the shards and the nodes they are hosted on is that an",
    "start": "1804480",
    "end": "1810000"
  },
  {
    "text": "elastic search feature or your custom controller great question yes it is it",
    "start": "1810000",
    "end": "1815440"
  },
  {
    "text": "is the elastic search feature you are able to define some custom node attributes and you are able to you set",
    "start": "1815440",
    "end": "1824799"
  },
  {
    "text": "you are able to say that if this index has this kind of alias always like",
    "start": "1824799",
    "end": "1829919"
  },
  {
    "text": "allocated to a note that has this naming pattern so this is a feature that",
    "start": "1829919",
    "end": "1835919"
  },
  {
    "text": "elastic search provides and the shards of that index uh follow that the rule",
    "start": "1835919",
    "end": "1842320"
  },
  {
    "text": "and will end up getting hosted or like scheduled uh on the uh in our case on",
    "start": "1842320",
    "end": "1848880"
  },
  {
    "text": "the reindex note pool thank you very much thank you",
    "start": "1848880",
    "end": "1855399"
  },
  {
    "text": "hi there thanks for the brilliant talk thank you um what kind of ballpark figures do you have for when data has to",
    "start": "1856880",
    "end": "1864399"
  },
  {
    "text": "move around um after you've completed a reindex uh I didn't catch the beginning",
    "start": "1864399",
    "end": "1869840"
  },
  {
    "text": "of your question what kind of ballpark figures in terms of time does it take for the data to move around you know",
    "start": "1869840",
    "end": "1876240"
  },
  {
    "text": "when you've done a reindex when we are done with the reindex yeah and you're scaling down things uh yes uh great",
    "start": "1876240",
    "end": "1884720"
  },
  {
    "text": "question it is it obviously it depends on the index that we're running but for our largest um I think it took about two",
    "start": "1884720",
    "end": "1894320"
  },
  {
    "text": "hours like to be fully all for all the shards to fully move from the reindex",
    "start": "1894320",
    "end": "1901440"
  },
  {
    "text": "nodes to the real time notes okay cool and as as orders of terabytes like hundreds of terabytes you said yeah yes",
    "start": "1901440",
    "end": "1909600"
  },
  {
    "text": "thank you yeah thank you thank you everyone",
    "start": "1909600",
    "end": "1915640"
  },
  {
    "text": "[Applause]",
    "start": "1915640",
    "end": "1918939"
  }
]
[
  {
    "text": "girl hello everybody my name is Evelyn I'm a tech lead on the data science",
    "start": "30",
    "end": "5220"
  },
  {
    "text": "platform team at kojic I'm joined here today with Jeremy levy who is the co-creator of Q flow today we're going",
    "start": "5220",
    "end": "12420"
  },
  {
    "text": "to be talking a bit about building ml platforms on top of kubernetes the two",
    "start": "12420",
    "end": "19949"
  },
  {
    "text": "messages I want you guys to take away from the talk is firstly cube and cube flow or great platforms to bold email",
    "start": "19949",
    "end": "27779"
  },
  {
    "text": "platforms on and to run ml workloads on and then secondly feast one of the open",
    "start": "27779",
    "end": "33300"
  },
  {
    "text": "source projects that we developed at kojic along with cube flow allows you to rapidly iterate on models so the gender",
    "start": "33300",
    "end": "42030"
  },
  {
    "text": "just in brief we're going to talk a little bit about the go-jek story from where we started with kubernetes and how",
    "start": "42030",
    "end": "49050"
  },
  {
    "text": "we built our platform on top of it and why that make made sense we're gonna have a quick demo on feast as well as",
    "start": "49050",
    "end": "55320"
  },
  {
    "text": "with cube flow and faring specifically on building and deploying a model and",
    "start": "55320",
    "end": "60449"
  },
  {
    "text": "then we were gonna like Jeremy's gonna catch you guys up on some of the latest happenings in cube flow and talk a bit",
    "start": "60449",
    "end": "65850"
  },
  {
    "text": "about Keith's flow so whose go check code Rick's an Indonesian technology",
    "start": "65850",
    "end": "71909"
  },
  {
    "text": "startup we're most famous for right heading on motorcycles but since",
    "start": "71909",
    "end": "76920"
  },
  {
    "text": "launching that product a few years ago we've branched out into many different other products right heading in cars",
    "start": "76920",
    "end": "83000"
  },
  {
    "text": "taxis food delivery with curved food there's digital payments with copay logistics",
    "start": "83000",
    "end": "90390"
  },
  {
    "text": "with code box and guess and in total we have about 18 different products in 15 different verticals and all together",
    "start": "90390",
    "end": "96570"
  },
  {
    "text": "they form one super app and the goal of this app is to have a solution for every",
    "start": "96570",
    "end": "101850"
  },
  {
    "text": "working birthday need that you have just to give you an indication of the kind of",
    "start": "101850",
    "end": "107790"
  },
  {
    "text": "scale so we originally started in Indonesia but since then we've branched out into many different markets",
    "start": "107790",
    "end": "113310"
  },
  {
    "text": "Singapore Vietnam Thailand in one of our products the right heading product we",
    "start": "113310",
    "end": "119670"
  },
  {
    "text": "have about 2 million drivers on the platform and we process about a hundred million bookings every month for more",
    "start": "119670",
    "end": "126149"
  },
  {
    "text": "than a hundred million bookings every month in go food were one of the largest food delivery services in Southeast Asia",
    "start": "126149",
    "end": "132650"
  },
  {
    "text": "excluding China one of the largest in Asia with over 400,000 merchants on our",
    "start": "132650",
    "end": "137750"
  },
  {
    "text": "platform and then third the curb paid the product we have is also one of the",
    "start": "137750",
    "end": "144379"
  },
  {
    "text": "fastest growing digital wallets so the scale is quite large and the ability for us to influence the business through",
    "start": "144379",
    "end": "152299"
  },
  {
    "text": "machine learning and data science systems is quite immense and at the heart of that is data and I hope this",
    "start": "152299",
    "end": "158629"
  },
  {
    "text": "renders correctly but this is an animation of one of our services go right in throughout one day in Jakarta",
    "start": "158629",
    "end": "166400"
  },
  {
    "text": "and each pixel is a person being picked up or dropped off on a motorcycle so you",
    "start": "166400",
    "end": "173450"
  },
  {
    "text": "can imagine the amount of data we have in the amount of transactions and the amount of ml of the scope for machine",
    "start": "173450",
    "end": "179720"
  },
  {
    "text": "learning and data science to make an impact here but when we started we didn't really have a platform or",
    "start": "179720",
    "end": "185239"
  },
  {
    "text": "anything to build on top of so as a data science back firmly we were tossed worth or at a sense platform team we were",
    "start": "185239",
    "end": "191299"
  },
  {
    "text": "tossed with but deciding of what what to build our platform on right do you use a managed service do you both from scratch",
    "start": "191299",
    "end": "198049"
  },
  {
    "text": "to use something that abstract that away like you burn a DS so we looked at the problem space and opportunities in the",
    "start": "198049",
    "end": "203840"
  },
  {
    "text": "company and what we saw was train like this where there was two types of",
    "start": "203840",
    "end": "211190"
  },
  {
    "text": "problems basically the first was you had opportunities to put the platform to",
    "start": "211190",
    "end": "217519"
  },
  {
    "text": "effect model creation for data scientists that work ephemeral wolf line maybe they were just going to be used",
    "start": "217519",
    "end": "224359"
  },
  {
    "text": "for analysis or a small project that never gets into production so that's on",
    "start": "224359",
    "end": "230120"
  },
  {
    "text": "the left hand side over here but there are also these high-impact projects that we recorded sessions systems essentially",
    "start": "230120",
    "end": "237199"
  },
  {
    "text": "so a pricing engine or driver allocation or the food recommendations on the homepage or any kind of search engine",
    "start": "237199",
    "end": "244400"
  },
  {
    "text": "within the application so from the perspective of a platform that we had to",
    "start": "244400",
    "end": "249650"
  },
  {
    "text": "both we had to satisfy both of these orthogonal objectives one is provide an",
    "start": "249650",
    "end": "254930"
  },
  {
    "text": "abstraction for the users that makes it easy for them to quickly iterate in bulk models and the other one is that the",
    "start": "254930",
    "end": "261200"
  },
  {
    "text": "platform should be able to integrate with our production engineering systems and it should cater for all the requirements of those",
    "start": "261200",
    "end": "268290"
  },
  {
    "text": "systems and handle the scale and and be extensible and flexible so given these",
    "start": "268290",
    "end": "275940"
  },
  {
    "text": "two orthogonal constraints we decided to focus on the most impactful use cases at the start we build our platform based on",
    "start": "275940",
    "end": "282840"
  },
  {
    "text": "one specific project and and then take it from there and add incrementally add",
    "start": "282840",
    "end": "287940"
  },
  {
    "text": "more systems and projects to it and so the one we decided to start with was the",
    "start": "287940",
    "end": "293040"
  },
  {
    "text": "driver allocation in each case so this is a system that takes a list of drivers and the customer and then decides which",
    "start": "293040",
    "end": "299370"
  },
  {
    "text": "driver to same to that customer and the volume of transactions that previous",
    "start": "299370",
    "end": "304620"
  },
  {
    "text": "processed by one of these smooth of this system itself is very high so hundreds of more than a hundred million bookings",
    "start": "304620",
    "end": "309870"
  },
  {
    "text": "every month so it has a very high ability to affect the bottom line of the business and based on the requirements",
    "start": "309870",
    "end": "318600"
  },
  {
    "text": "and our knowledge of the complexity of the system and the importance of the system we need to be engineering heavy so we just we opted based on our",
    "start": "318600",
    "end": "326190"
  },
  {
    "text": "understanding of the m/l landscape to build our platform on kubernetes and originally it was mostly because of the",
    "start": "326190",
    "end": "332370"
  },
  {
    "text": "dependence dependency management aspects of it because our data science were already using docker for their containers and packaging up the",
    "start": "332370",
    "end": "339840"
  },
  {
    "text": "dependencies but we also got benefits like container orchestration and process isolation so basically what the system",
    "start": "339840",
    "end": "345840"
  },
  {
    "text": "did was we'd use a very basic airflow pipeline to trainer model and deploy that model in a web service to container",
    "start": "345840",
    "end": "353280"
  },
  {
    "text": "running innkeeper Nettie's it would get in the request which is a list of drivers in the customer maybe we didn't",
    "start": "353280",
    "end": "358320"
  },
  {
    "text": "reach that with some data and then it would give a response on which drivers who same to the customer and this had an",
    "start": "358320",
    "end": "365010"
  },
  {
    "text": "incremental game and it did to improve our bottom line but it wasn't that spectacular and one of the concerns was",
    "start": "365010",
    "end": "372120"
  },
  {
    "text": "the learning curve of cube and so we were always questioning at the start was going for cube the right decision but",
    "start": "372120",
    "end": "378840"
  },
  {
    "text": "over time it proved to be indeed the right decision so immediately it started",
    "start": "378840",
    "end": "384870"
  },
  {
    "text": "paying dividends when we needed to add experimentation so when we started deploying multiple models into our kubernetes cluster we needed a way to",
    "start": "384870",
    "end": "391169"
  },
  {
    "text": "manage traffic to these models so we built a very rudimentary you experimentation user interface for our",
    "start": "391169",
    "end": "398190"
  },
  {
    "text": "data scientist so that they can configure traffic splits to these models and one of the benefits of kubernetes",
    "start": "398190",
    "end": "403530"
  },
  {
    "text": "was that it provided a extended eyes control plane for us to bowl on top off so we could loosely couple our ingress",
    "start": "403530",
    "end": "410040"
  },
  {
    "text": "and our traffic manager which is in the cluster to configuration user interface that's updating that config map and then",
    "start": "410040",
    "end": "417150"
  },
  {
    "text": "we could just template eyes the engine X configuration and then layer that we had",
    "start": "417150",
    "end": "422640"
  },
  {
    "text": "traffic splitting and experimentation so so really this is one of the key value",
    "start": "422640",
    "end": "428640"
  },
  {
    "text": "adds that kubernetes brings when you're building a platform on top of cuber natives the second value add was on",
    "start": "428640",
    "end": "436080"
  },
  {
    "text": "orchestration so already here we're seeing that the system is getting a little bit more complex so what we found",
    "start": "436080",
    "end": "442380"
  },
  {
    "text": "was that it's very rare to actually have just a model in a web service serving these responses and actually doing a",
    "start": "442380",
    "end": "448290"
  },
  {
    "text": "good job what we found is that you actually need many different models ensemble together to have a valuable output and so we bought an Orchestrator",
    "start": "448290",
    "end": "455130"
  },
  {
    "text": "called lasso and if you want to look for an alternative and open-source well there sell them that you can also look",
    "start": "455130",
    "end": "460170"
  },
  {
    "text": "at but basically you define a workflow or a graph and this graph can do things like call multiple models and take the",
    "start": "460170",
    "end": "467100"
  },
  {
    "text": "most confident response or pull two models and maybe one is fast and accurate but one is not it's maybe sorry",
    "start": "467100",
    "end": "475320"
  },
  {
    "text": "one is slow and I it's known accurate but other ones fast and not accurate so if the one is taking too long to respond",
    "start": "475320",
    "end": "480870"
  },
  {
    "text": "then take the other one now so you can do all of these complex logic and that",
    "start": "480870",
    "end": "486300"
  },
  {
    "text": "was really a big value add and that dramatically improve the impact of the system and then it at the end of the day",
    "start": "486300",
    "end": "493350"
  },
  {
    "text": "are also experimenting on multiple versions of these so Cubans helped us here because you have an orca sex acute",
    "start": "493350",
    "end": "499860"
  },
  {
    "text": "environment that shared between all of these services so running these graphs are really efficient and at the end of",
    "start": "499860",
    "end": "505380"
  },
  {
    "text": "the day your version controlling this inference croc with your manifest for kubernetes and you can see and get your",
    "start": "505380",
    "end": "512250"
  },
  {
    "text": "whole system and how it's going to operate in clear-text then there were",
    "start": "512250",
    "end": "518159"
  },
  {
    "text": "some other benefits to running on Cube and at just economies of scale so we also started to standardize across the",
    "start": "518160",
    "end": "524460"
  },
  {
    "text": "company on kubernetes it wasn't just the data science of the ml teams and a lot of the benefits were being",
    "start": "524460",
    "end": "531130"
  },
  {
    "text": "felt by our team by what the other teams were building so in one case we wanted to log the incoming requests to our",
    "start": "531130",
    "end": "537250"
  },
  {
    "text": "services but because of the performance constraints there is actually too hard to do this ourselves",
    "start": "537250",
    "end": "542920"
  },
  {
    "text": "you can just log to the console so one of the teams both their logging sidecar and basically you deploy this as a",
    "start": "542920",
    "end": "548589"
  },
  {
    "text": "daemon set and all your services can just log to a port on their local host and the logs and the matrix organ",
    "start": "548589",
    "end": "555160"
  },
  {
    "text": "streamed off to some stream like pops up or Kafka but of course we benefited from",
    "start": "555160",
    "end": "560560"
  },
  {
    "text": "many other systems and components that we bought by other teams and within Gajic one of the things I wasn't showing",
    "start": "560560",
    "end": "569620"
  },
  {
    "text": "earlier was that there are these databases actually with deployed with",
    "start": "569620",
    "end": "574660"
  },
  {
    "text": "the models and these databases or for example radius paws that have data loaded into them through the jobs that",
    "start": "574660",
    "end": "583120"
  },
  {
    "text": "are executed within the cuber Nettie's environment so they'll take for example a data set called GCS and load it into a",
    "start": "583120",
    "end": "590110"
  },
  {
    "text": "raid ISM and just finish their execution and then this Redis contains all the features for that specific model to",
    "start": "590110",
    "end": "596649"
  },
  {
    "text": "actually do it inference because the request needs to be enriched for those feast features so we really benefited in",
    "start": "596649",
    "end": "602709"
  },
  {
    "text": "terms of running workloads and cuber Nettie's because of the fact that you had the jobs API and intelligent",
    "start": "602709",
    "end": "608649"
  },
  {
    "text": "resource scheduling and you could easily deploy a future consumer that just Auto scales and pulls in real-time features",
    "start": "608649",
    "end": "614440"
  },
  {
    "text": "into these rails pods and what we're moving towards now is using cupola pipelines to orchestrate a lot of these",
    "start": "614440",
    "end": "621070"
  },
  {
    "text": "jobs so the tracks where a lot of the panes that we had there it can",
    "start": "621070",
    "end": "626200"
  },
  {
    "text": "intelligently schedule for example a workload that means a GPU and it finds the right node with the right amount of",
    "start": "626200",
    "end": "631690"
  },
  {
    "text": "memory to run your compute so among cube really benefits from its capabilities in",
    "start": "631690",
    "end": "637630"
  },
  {
    "text": "terms of workloads but one of the inefficient parts here was the duplication of features within these",
    "start": "637630",
    "end": "643800"
  },
  {
    "text": "latest pods so we were having a lot of issues and a lot of pain around feature engineering data scientists would",
    "start": "643800",
    "end": "649690"
  },
  {
    "text": "reinvent the same features across projects across teams there was an inconsistency between the future",
    "start": "649690",
    "end": "655240"
  },
  {
    "text": "transformations for streams and for batch wonders in Python one is in Java and this is a very common problem and",
    "start": "655240",
    "end": "660459"
  },
  {
    "text": "that is or in email systems so we knew there's a hot spot that we wanted to fix and so we",
    "start": "660459",
    "end": "666270"
  },
  {
    "text": "looked at building a feature store for this so there are two to basically roles",
    "start": "666270",
    "end": "672090"
  },
  {
    "text": "or personas that use a feature store but one one side you have the data creators",
    "start": "672090",
    "end": "677340"
  },
  {
    "text": "they're creating datasets from a raw data electronic transformations and batch and they're creating extreme",
    "start": "677340",
    "end": "683580"
  },
  {
    "text": "transformations when I publishing it in some stream and then you have a user of that data that wants to train a model",
    "start": "683580",
    "end": "688680"
  },
  {
    "text": "and somehow serve that model so what we ended up building was a store that",
    "start": "688680",
    "end": "695610"
  },
  {
    "text": "allows you to ingest these features either real-time or batch and they get",
    "start": "695610",
    "end": "701400"
  },
  {
    "text": "stored in from these streams into two stores one is a feature warehouse in our",
    "start": "701400",
    "end": "707100"
  },
  {
    "text": "case that's bigquery the other is a serving store which can be either",
    "start": "707100",
    "end": "712200"
  },
  {
    "text": "BigTable or register pending on your requirements and what this provides to the end user they Mel engineer is a",
    "start": "712200",
    "end": "718500"
  },
  {
    "text": "consistent API to both of these stores so they define a feature set and then they can query from the future warehouse",
    "start": "718500",
    "end": "724710"
  },
  {
    "text": "over a time range historical feature data train their model take their model into production and then use the same",
    "start": "724710",
    "end": "730770"
  },
  {
    "text": "feature say to query real time features in serving and so this eliminates the serving training skew that means you can",
    "start": "730770",
    "end": "738180"
  },
  {
    "text": "manage your features centrally so you don't have duplication between teams and they can discover features that are in use and it also means you don't need to",
    "start": "738180",
    "end": "744510"
  },
  {
    "text": "roll out new databases for each model that gets deployed so one of the so this",
    "start": "744510",
    "end": "752220"
  },
  {
    "text": "is all the architecture changes when you have a feast serving deployment so you'll just deploy that piece serving within the same cluster with which is",
    "start": "752220",
    "end": "759000"
  },
  {
    "text": "managing your production workload and of course you could have deployed that anywhere that could be in a managed service or it could be on a VM but",
    "start": "759000",
    "end": "764700"
  },
  {
    "text": "ultimately one of the benefits to Kuban alias and running in all systems is that you can deploy everything basically in",
    "start": "764700",
    "end": "770100"
  },
  {
    "text": "one cluster so if you have a page of going over to a.m. you can just look at your one cluster to get a complete",
    "start": "770100",
    "end": "775440"
  },
  {
    "text": "overview of all the issues that have there and debug that so from an operational standpoint is a big benefit",
    "start": "775440",
    "end": "781740"
  },
  {
    "text": "to standardizing on kubernetes for for these email systems and then we",
    "start": "781740",
    "end": "788160"
  },
  {
    "text": "had a rapid expansion so we were deploying more and more models and systems to these model variants within a",
    "start": "788160",
    "end": "795210"
  },
  {
    "text": "specific service type so go ride is our ride-hailing service type but we had many different service types that we",
    "start": "795210",
    "end": "800400"
  },
  {
    "text": "were expanding to so we had free delivery which also needs allocation we have logistics we have ride-hailing on",
    "start": "800400",
    "end": "806970"
  },
  {
    "text": "cars and they will have their own different models because it's trained on different data so we were expanding",
    "start": "806970",
    "end": "812550"
  },
  {
    "text": "rapidly into all these service types and then we're also expanding into new markets so we're expanding into Singapore and Thailand and Vietnam as",
    "start": "812550",
    "end": "818640"
  },
  {
    "text": "well so quickly the amount of models and systems grew exponentially and you can't",
    "start": "818640",
    "end": "825630"
  },
  {
    "text": "just duplicate these models and just serve from a single endpoint for example in Thailand there are very strict",
    "start": "825630",
    "end": "831000"
  },
  {
    "text": "regulations on what taxi motorcycle taxis are allowed to do so a lot of",
    "start": "831000",
    "end": "836610"
  },
  {
    "text": "logic goes into these systems it's not just an extra boost or a PI torch there's actual business logic like is",
    "start": "836610",
    "end": "841800"
  },
  {
    "text": "written into these deployments so the way we managed to scale out our systems",
    "start": "841800",
    "end": "847620"
  },
  {
    "text": "was through the approach of essentially get ops and infrastructures code so we",
    "start": "847620",
    "end": "853620"
  },
  {
    "text": "roll out all our infrastructure across all of our V pcs and regions through terraform and we even just install a lot",
    "start": "853620",
    "end": "861839"
  },
  {
    "text": "of our Cuban Ares manifests and components through terraform using the home provider and that that maintains",
    "start": "861839",
    "end": "868200"
  },
  {
    "text": "that state for us and so it's a lot easier to reason about and to scale out and then we deploy our",
    "start": "868200",
    "end": "875250"
  },
  {
    "text": "applications to a CD system through go CD and ultimately everything is version controlled and we always have a good",
    "start": "875250",
    "end": "882150"
  },
  {
    "text": "context of our of our systems and this is also highly portable right we can",
    "start": "882150",
    "end": "887250"
  },
  {
    "text": "easily spin up and destroy a region if we wanted to there's also a good link here but one of our and tech leads on",
    "start": "887250",
    "end": "893760"
  },
  {
    "text": "the data engineering team if you guys wanted to check that out so once you have this once you version control",
    "start": "893760",
    "end": "899400"
  },
  {
    "text": "everything in your scale to all these markets then you get some other great benefits as well so imagine you're training a model or even using keep up",
    "start": "899400",
    "end": "906540"
  },
  {
    "text": "pipelines what you can do is you can you can track the inputs to that that pipeline you can track the version of",
    "start": "906540",
    "end": "912790"
  },
  {
    "text": "the pipeline and you're gonna you're gonna have a bunch of artifacts are being produced so your training let's say one model but all of your processes",
    "start": "912790",
    "end": "919390"
  },
  {
    "text": "are creating artifacts you create from source code you're creating docker images and get you've got your",
    "start": "919390",
    "end": "924400"
  },
  {
    "text": "configuration stored and all of these artifacts together can can be monitored through their stores and you can produce",
    "start": "924400",
    "end": "932830"
  },
  {
    "text": "a unique version of all the other combination of these artifacts and you can create a deployment and this is what",
    "start": "932830",
    "end": "938410"
  },
  {
    "text": "we're doing now so whenever one of these artifacts changes we are obtaining the deployed system and this is a very",
    "start": "938410",
    "end": "944230"
  },
  {
    "text": "scalable approach across all of our markets and the biggest benefit of this is that ultimately you can tie your",
    "start": "944230",
    "end": "952980"
  },
  {
    "text": "experimental outcome to the unique combination of artifacts that went into that specific deployment so it allows",
    "start": "952980",
    "end": "959050"
  },
  {
    "text": "you to reason about why a deployment worked or didn't work and then to add to",
    "start": "959050",
    "end": "964060"
  },
  {
    "text": "this what we're focusing on now and what the cupula team is looking at now is metadata management how can you go",
    "start": "964060",
    "end": "969400"
  },
  {
    "text": "hockey track all the metadata across this lifecycle and then go up stream",
    "start": "969400",
    "end": "974740"
  },
  {
    "text": "when you discover something went well or didn't go well and then it gives you more context about that",
    "start": "974740",
    "end": "981150"
  },
  {
    "text": "so just to cover the good parts that we discussed earlier the the ecosystem",
    "start": "981150",
    "end": "987220"
  },
  {
    "text": "currently for ml and kubernetes is vibrant and that's one of the biggest draws for us especially with cube flow bringing together all these these",
    "start": "987220",
    "end": "993550"
  },
  {
    "text": "packages and components and frameworks the consistent API and the q4q Bernese provides is a great way to extend and",
    "start": "993550",
    "end": "1000720"
  },
  {
    "text": "both the platform's so in our case our ml platform the workloads it there's",
    "start": "1000720",
    "end": "1006390"
  },
  {
    "text": "also a great benefit of running workloads and Cuban Andes because of its intelligent resource scheduling and utilization having everything centrally",
    "start": "1006390",
    "end": "1014070"
  },
  {
    "text": "deployed on the keeper Nettie's cluster is also one of the great benefits and then once you follow a gear ops based",
    "start": "1014070",
    "end": "1019260"
  },
  {
    "text": "approach and you're versioning and tracking all of the artifacts that you're into a deployment you can easily",
    "start": "1019260",
    "end": "1025910"
  },
  {
    "text": "introduce tracing and an ability to reason about and explain your experiments",
    "start": "1025910",
    "end": "1031699"
  },
  {
    "text": "so what still sucks multi-tenancy is still pretty bad we don't have a good",
    "start": "1031699",
    "end": "1037199"
  },
  {
    "text": "way to expose kubernetes clusters to our data scientists and some of them are very full stack there very strong engineers so finding the",
    "start": "1037199",
    "end": "1045370"
  },
  {
    "text": "balance between introducing or breaking that abstraction or not it's quite tough staple systems are still kind of a",
    "start": "1045370",
    "end": "1051850"
  },
  {
    "text": "challenge running DBS and in cube we tend to opt for the managed services for",
    "start": "1051850",
    "end": "1057909"
  },
  {
    "text": "databases right now using google cloud and there's not some leaky abstractions in terms of when you're asking the other",
    "start": "1057909",
    "end": "1064270"
  },
  {
    "text": "scientists to write annotations for example and coming up next we are",
    "start": "1064270",
    "end": "1070059"
  },
  {
    "text": "focusing on the in user experience so we focused on building the platform for capabilities in terms of running prod",
    "start": "1070059",
    "end": "1075640"
  },
  {
    "text": "systems that are complex and scale out and drive big impact but we want to address the long tail of customers that",
    "start": "1075640",
    "end": "1081940"
  },
  {
    "text": "are throughout our organization because we have thousands of employees and we're",
    "start": "1081940",
    "end": "1087460"
  },
  {
    "text": "also focusing on metadata tracking like I said earlier and also integrating sto tracing into our stack and I'll leave",
    "start": "1087460",
    "end": "1094539"
  },
  {
    "text": "you on this quote from Kelsey and ITAR which i think is very cool at least in our experience building a name of that for holding an email platform on top of",
    "start": "1094539",
    "end": "1100690"
  },
  {
    "text": "cube really made sense think thank you",
    "start": "1100690",
    "end": "1106899"
  },
  {
    "text": "very much well that's a really great introduction and motivation for coop flow because what we realize talking to",
    "start": "1106899",
    "end": "1113289"
  },
  {
    "text": "a lot of companies and customers is that gojek wasn't alone in building a platform for machine learning and using",
    "start": "1113289",
    "end": "1120190"
  },
  {
    "text": "kubernetes lots of people were doing that same thing you know and they as william mentioned you know they built a",
    "start": "1120190",
    "end": "1125890"
  },
  {
    "text": "custom resource lasso internally for doing graphs of inference of models when",
    "start": "1125890",
    "end": "1131950"
  },
  {
    "text": "there were companies outside that like Seldon doing the exact same things and many of those companies have presented here at coop kong and so what we decided",
    "start": "1131950",
    "end": "1139090"
  },
  {
    "text": "to to do is we said why not create an open platform for machine learning on",
    "start": "1139090",
    "end": "1144340"
  },
  {
    "text": "kubernetes that everyone can contribute to and everyone could use and that's what coop flow is it's an open",
    "start": "1144340",
    "end": "1149470"
  },
  {
    "text": "kubernetes native platform for our mouths our mission is basically to make it easy for everyone to develop deploy",
    "start": "1149470",
    "end": "1155710"
  },
  {
    "text": "and manage portable distributed ml on kubernetes so we'd like to give you a",
    "start": "1155710",
    "end": "1161140"
  },
  {
    "text": "demo of what that looks like and what we would like to show you is that using coupon Cooper you can build the same types of",
    "start": "1161140",
    "end": "1168100"
  },
  {
    "text": "workflows that companies like gojek are using in production right so workflows like their driver allocation workflow",
    "start": "1168100",
    "end": "1175510"
  },
  {
    "text": "and so what we're going to show you is we're going to show you how you can use feast which to keep track of your",
    "start": "1175510",
    "end": "1181750"
  },
  {
    "text": "features and load them load your features there and that's going to allow your data scientists to rapidly develop",
    "start": "1181750",
    "end": "1187660"
  },
  {
    "text": "and iterate on models and we're going to show you how they can do that using notebooks running on coop flow use on",
    "start": "1187660",
    "end": "1193810"
  },
  {
    "text": "top of kubernetes and so after we've developed our model we're gonna take advantage of fairing which is a library",
    "start": "1193810",
    "end": "1200200"
  },
  {
    "text": "in kubernetes it's going to make it really easy for your data scientists to deploy their models on kubernetes",
    "start": "1200200",
    "end": "1205450"
  },
  {
    "text": "without sort of having to learn all those kubernetes concepts like pods",
    "start": "1205450",
    "end": "1210990"
  },
  {
    "text": "services and deployments and then finally as you as we saw from Willems",
    "start": "1210990",
    "end": "1216220"
  },
  {
    "text": "talk you often want to build these pipelines that can define these multi-step worth clothes and we're going",
    "start": "1216220",
    "end": "1221710"
  },
  {
    "text": "to show you how you can do that in coop flow pipelines so with that I'm going to",
    "start": "1221710",
    "end": "1226870"
  },
  {
    "text": "switch over to the demo so this is the central dashboard for our coop flow and",
    "start": "1226870",
    "end": "1232510"
  },
  {
    "text": "so the idea is that we're going to deploy and manage a bunch of applications for machine learning on kubernetes right and so after you've",
    "start": "1232510",
    "end": "1238870"
  },
  {
    "text": "logged into coop flow you can use this dashboard to navigate between all the different applications and right now we",
    "start": "1238870",
    "end": "1244900"
  },
  {
    "text": "basically have three applications we have notebooks sorry that's the docs",
    "start": "1244900",
    "end": "1250200"
  },
  {
    "text": "this is notebooks we have Captain which is our hyper parameter tuning system and",
    "start": "1250200",
    "end": "1258540"
  },
  {
    "text": "then we have pipelines we also have a bunch of components like custom resources for training and deploying",
    "start": "1258540",
    "end": "1264250"
  },
  {
    "text": "models but those don't necessarily have you eyes so I'm not showing them right now so let's go to notebooks right so",
    "start": "1264250",
    "end": "1271150"
  },
  {
    "text": "from here we can see all of our notebooks that we have running and so we make it really easy for data scientists",
    "start": "1271150",
    "end": "1276280"
  },
  {
    "text": "to launch and run manage multiple notebooks simultaneously so they could have different environments maybe one",
    "start": "1276280",
    "end": "1281710"
  },
  {
    "text": "for pi torch maybe one for tensor flow and maybe ones running some long-running job and they can work",
    "start": "1281710",
    "end": "1286820"
  },
  {
    "text": "another one and so to launch a notebook they just click here on new server and they have a simple web UI where they can",
    "start": "1286820",
    "end": "1292549"
  },
  {
    "text": "fill out a form in order to launch a notebook so they just give it a name and then they can specify the docker image",
    "start": "1292549",
    "end": "1298880"
  },
  {
    "text": "they want to use we ship a bunch of stock runtime environments for ML but you can also build custom docker images",
    "start": "1298880",
    "end": "1306440"
  },
  {
    "text": "that have you know the libraries that you need installed and then you can fill out the resources that you need and you",
    "start": "1306440",
    "end": "1312919"
  },
  {
    "text": "can even attach volumes if you have to attach extra data data system storage systems like an NFS share so after",
    "start": "1312919",
    "end": "1321620"
  },
  {
    "text": "you've done that you can go ahead and connect to your notebook so I'm going to",
    "start": "1321620",
    "end": "1327259"
  },
  {
    "text": "switch over to the notebook I've already started up and so this is a notebook that we're going to use for our demo and so in this demo what we're going to be",
    "start": "1327259",
    "end": "1333950"
  },
  {
    "text": "doing is we're going to be using the Chicago taxicab data set which is a data set that's used in a lot of ml research",
    "start": "1333950",
    "end": "1340090"
  },
  {
    "text": "and examples and it's basically a data set of Chicago taxi rides it's got",
    "start": "1340090",
    "end": "1346700"
  },
  {
    "text": "various features about those taxi rides such as duration pickup time delivery destination and then fare cost how much",
    "start": "1346700",
    "end": "1355159"
  },
  {
    "text": "the taxi ride cost and so what we're going to try to do is we're going to try to use these features to predict how much a taxi ride is going to cost let me",
    "start": "1355159",
    "end": "1363169"
  },
  {
    "text": "zoom in how's that font size can people see that okay we're good",
    "start": "1363169",
    "end": "1369710"
  },
  {
    "text": "alright so I'm going to scroll down here or is it so so here what we're doing is",
    "start": "1369710",
    "end": "1380179"
  },
  {
    "text": "we're going to load some data set load some data from a CSV file that contains",
    "start": "1380179",
    "end": "1385429"
  },
  {
    "text": "the Chicago taxicab data set and so in this case we're just loading it into a panda's data frame so we're going to",
    "start": "1385429",
    "end": "1392779"
  },
  {
    "text": "load this data into a feast that's mostly to illustrate how you can actually go about loading data into",
    "start": "1392779",
    "end": "1398360"
  },
  {
    "text": "feast in practice you'd be continually streaming or ingesting your data from like your logs into your data store or",
    "start": "1398360",
    "end": "1406190"
  },
  {
    "text": "fees but we wanted to sort of illustrate this aspect of feast for you so after",
    "start": "1406190",
    "end": "1412399"
  },
  {
    "text": "we've loaded that data what we're doing here is we're basically computing some derived features where we're basically using pandas and",
    "start": "1412399",
    "end": "1418370"
  },
  {
    "text": "and data frames to combine several features and compute some other features but and that we're going to load into",
    "start": "1418370",
    "end": "1424640"
  },
  {
    "text": "the data store and so down here this is where we start to define an importer to",
    "start": "1424640",
    "end": "1431150"
  },
  {
    "text": "actually import the data into feast and I'm going to turn it back over to warm to basically describe what's happening here so what the importer is doing is",
    "start": "1431150",
    "end": "1437990"
  },
  {
    "text": "it's taking a data frame as an input and then it allows you to define some information about the entity which in",
    "start": "1437990",
    "end": "1443510"
  },
  {
    "text": "this case is the right and it allows you to define the mapping of the columns",
    "start": "1443510",
    "end": "1449539"
  },
  {
    "text": "within that data frame two features that exist within the feature store and if I don't exist then you can specify you can",
    "start": "1449539",
    "end": "1456169"
  },
  {
    "text": "see it says apply features it'll actually create those features the first time you run this import so when your",
    "start": "1456169",
    "end": "1461960"
  },
  {
    "text": "run list it's going to start a job in the background and it's going to load in all of those features and like Jeremy said in production this would probably",
    "start": "1461960",
    "end": "1467539"
  },
  {
    "text": "be at the end of an ETL or you'd run a similar job that's long-running to streaming data constantly from a stream",
    "start": "1467539",
    "end": "1474409"
  },
  {
    "text": "and so your feature stores always being updated with new data and if you go down",
    "start": "1474409",
    "end": "1479899"
  },
  {
    "text": "a little bit you'll see ok it's creating all of these features within within the",
    "start": "1479899",
    "end": "1485149"
  },
  {
    "text": "future store I'll just want to scroll down a little bit right and then you get to the most",
    "start": "1485149",
    "end": "1491600"
  },
  {
    "text": "important part which is defining your feature set and this is what is going to allow us to create you could provide us",
    "start": "1491600",
    "end": "1497690"
  },
  {
    "text": "with a way to and get consistency between our training and serving so in this case we're defining a feature set",
    "start": "1497690",
    "end": "1502970"
  },
  {
    "text": "which is a list of features by their ID and then we're going to create an object",
    "start": "1502970",
    "end": "1508010"
  },
  {
    "text": "out of that that's part of the tasty Kay and then we're going to materialize a dataset so we're going to retrieve the",
    "start": "1508010",
    "end": "1513320"
  },
  {
    "text": "features from the training store and if you you'll see that we did ahead there and it's the same data that we just",
    "start": "1513320",
    "end": "1519620"
  },
  {
    "text": "ingested and and this is this is what the feature store provides for you it",
    "start": "1519620",
    "end": "1525799"
  },
  {
    "text": "allows you to query over a time range and pull out and materialize that data for training and importantly it unit",
    "start": "1525799",
    "end": "1531679"
  },
  {
    "text": "you're going to use that feature set again that lists the features for on the serving side",
    "start": "1531679",
    "end": "1538480"
  },
  {
    "text": "so this is typically where a data scientist would start off with building a model so if you've tasked your data",
    "start": "1540730",
    "end": "1547480"
  },
  {
    "text": "scientists with you know building a model to solve some problem you know such as predicting fares the first thing",
    "start": "1547480",
    "end": "1553510"
  },
  {
    "text": "they would do is they would go ahead and load that date you know a bunch of features from you know their data store like feast and then they would try to",
    "start": "1553510",
    "end": "1559900"
  },
  {
    "text": "visualize that data in order to see you know is there a signal there that I can use to solve this problem and so to do",
    "start": "1559900",
    "end": "1566710"
  },
  {
    "text": "that we're going to use tensorflow data validation so this is one of the many applications that's in tf-x which is a",
    "start": "1566710",
    "end": "1574030"
  },
  {
    "text": "set of applications that Google is open sourcing and releasing to enable you to build complex ml systems and so what TF",
    "start": "1574030",
    "end": "1581710"
  },
  {
    "text": "DB does is it will go through your data set and compute various statistics and then it provides a nice handy widget I",
    "start": "1581710",
    "end": "1588910"
  },
  {
    "text": "think it's based on facets that allows you to visualize those statistics right so here we're looking at you know",
    "start": "1588910",
    "end": "1595030"
  },
  {
    "text": "various columns like passenger count and it's printing out some various statistics and then we can visualize",
    "start": "1595030",
    "end": "1601750"
  },
  {
    "text": "things like the distribution and it's interactive so you can you know change those settings to view them differently",
    "start": "1601750",
    "end": "1607150"
  },
  {
    "text": "and so one of the reasons I wanted to show that is one of the questions we get most in coop flow is how is tf-x in coop",
    "start": "1607150",
    "end": "1614080"
  },
  {
    "text": "flow related to one another and the answer is that you know they work really well together with coop flow we're trying to make it really easy to run",
    "start": "1614080",
    "end": "1621010"
  },
  {
    "text": "Tenzer flow tf-x on kubernetes so you can leverage those applications as part of your workflows",
    "start": "1621010",
    "end": "1628320"
  },
  {
    "text": "so after we've done that then we can go down here and we can start to define the code to train our model and so here's",
    "start": "1628320",
    "end": "1635110"
  },
  {
    "text": "the training code and so you can see down here we actually there we go we",
    "start": "1635110",
    "end": "1643030"
  },
  {
    "text": "load the data from feast and here what we're doing is we're specifying the time range that we want to download so we can",
    "start": "1643030",
    "end": "1650590"
  },
  {
    "text": "specify like the last 28 days and then we're going to download the features that were defined by our feature set",
    "start": "1650590",
    "end": "1656440"
  },
  {
    "text": "that willem just showed and then over here we're actually defining our training code and in this case we're",
    "start": "1656440",
    "end": "1662140"
  },
  {
    "text": "just building a simple linear model to predict the fares from the features we defined and then down here we have the",
    "start": "1662140",
    "end": "1668530"
  },
  {
    "text": "predict code and what the predict code is doing is it's taking in the eye that's identifying that the taxi ride",
    "start": "1668530",
    "end": "1674820"
  },
  {
    "text": "and then from feast we're gonna load that features so you can see we're just calling get serving data and here we're",
    "start": "1674820",
    "end": "1681030"
  },
  {
    "text": "gonna load in the same features that we were using and training and then we're gonna feed that data into our linear",
    "start": "1681030",
    "end": "1686340"
  },
  {
    "text": "model so the most important thing is that what you don't see here so what you don't see here is a lot of complicated",
    "start": "1686340",
    "end": "1692400"
  },
  {
    "text": "code to go and fetch these features these different features from multiple different databases and compute the",
    "start": "1692400",
    "end": "1699450"
  },
  {
    "text": "features from the raw data and so as well I mentioned before that allows us to avoid the training serving askew",
    "start": "1699450",
    "end": "1707220"
  },
  {
    "text": "because we're getting using the same features in training as in serving and that's because of we're using fees to",
    "start": "1707220",
    "end": "1714090"
  },
  {
    "text": "take care of that so after we've done that we can go ahead and train our model",
    "start": "1714090",
    "end": "1720030"
  },
  {
    "text": "inside our notebook so here we're just in invoking train it seems like my",
    "start": "1720030",
    "end": "1729660"
  },
  {
    "text": "notebooks having problems anyways and then we can go on and call prediction and we can invoke it inside the notebook",
    "start": "1729660",
    "end": "1737720"
  },
  {
    "text": "and then one thing that would happen is after you've built your model and you've iterated on your model inside the",
    "start": "1737720",
    "end": "1743460"
  },
  {
    "text": "notebook you'd like to go ahead and maybe scale out on kubernetes so you can",
    "start": "1743460",
    "end": "1748980"
  },
  {
    "text": "imagine if you're training on a very small data set so that you can train quickly and iterate once you've got a",
    "start": "1748980",
    "end": "1754020"
  },
  {
    "text": "model that you're happy with you might want to go ahead and launch that as a long-running job on kubernetes maybe and",
    "start": "1754020",
    "end": "1759900"
  },
  {
    "text": "maybe you know process the full data set so maybe you've been training only in the last 28 days and now you want to go",
    "start": "1759900",
    "end": "1765299"
  },
  {
    "text": "and train on all of your data maybe for the last year so in this case we can use fairing to easily launch a training job",
    "start": "1765299",
    "end": "1771330"
  },
  {
    "text": "on kubernetes so to do that all we have to do is specify to two values one is",
    "start": "1771330",
    "end": "1778140"
  },
  {
    "text": "the docker image that we want to use and so in this case we're going to use the same runtime environment as we're using",
    "start": "1778140",
    "end": "1784500"
  },
  {
    "text": "our notebook for our notebook so we can get the same environment as we're using in our notebook and then the other thing",
    "start": "1784500",
    "end": "1790440"
  },
  {
    "text": "we have to specify is the docker image where we want to push the dock push the image and then with Baron we just have",
    "start": "1790440",
    "end": "1796830"
  },
  {
    "text": "to call one simple line which is a couple lines of Python code to build the and what fairing is going to do is it's",
    "start": "1796830",
    "end": "1803550"
  },
  {
    "text": "going to take our notebook convert it to Python code and then build and push a docker image we can then just invoke a",
    "start": "1803550",
    "end": "1811020"
  },
  {
    "text": "couple lines of Python code to actually launch a kubernetes job and then baring",
    "start": "1811020",
    "end": "1816450"
  },
  {
    "text": "will actually go and fetch the logs from that kubernetes job and print them out for convenience and we can actually call",
    "start": "1816450",
    "end": "1822840"
  },
  {
    "text": "out to kubernetes to print out the actual kubernetes job that we actually submitted and ran so we can see we just",
    "start": "1822840",
    "end": "1828300"
  },
  {
    "text": "have the expected spec for Cooper net equipment his job once we've trained our",
    "start": "1828300",
    "end": "1835470"
  },
  {
    "text": "model me what me might want to actually go ahead and deploy that in kubernetes to get a restful endpoint that we can",
    "start": "1835470",
    "end": "1840630"
  },
  {
    "text": "call so in this case we can again use fairing to automatically launch a build and launch deployment on kubernetes",
    "start": "1840630",
    "end": "1847350"
  },
  {
    "text": "and that's just another couple lines of Python code to deploy that and then you can see we printed out the endpoint that",
    "start": "1847350",
    "end": "1853320"
  },
  {
    "text": "we're getting inside our cluster to actually do predictions and then finally",
    "start": "1853320",
    "end": "1859590"
  },
  {
    "text": "as as William showed we might want to develop a complex pipeline to run multiple steps and to make it easy to",
    "start": "1859590",
    "end": "1866580"
  },
  {
    "text": "repeat all these steps so for that we can use coop flow pipelines and so to define a pipeline you know we just",
    "start": "1866580",
    "end": "1873570"
  },
  {
    "text": "define a function which we're going to use to define the steps in our pipeline and we add this simple annotation to let",
    "start": "1873570",
    "end": "1879540"
  },
  {
    "text": "coop flow pipelines know this is actually a pipeline then inside the pipeline we just define the steps of our",
    "start": "1879540",
    "end": "1885210"
  },
  {
    "text": "pipeline each step in a pipeline is going to run a containerized operation so basically it's going to spin up a pod",
    "start": "1885210",
    "end": "1891060"
  },
  {
    "text": "and so all we have to do is specify the image we want to use and so in this case we're going to use the same images we",
    "start": "1891060",
    "end": "1896940"
  },
  {
    "text": "used for training and deploying and that were created by fairing and then we just specify the the command that we want to",
    "start": "1896940",
    "end": "1904770"
  },
  {
    "text": "invoke and so in this case we can just tell it that we wanted run training and then we can tell what time range of data",
    "start": "1904770",
    "end": "1911190"
  },
  {
    "text": "that we actually want to train on and we can pass that as command-line arguments sorry and then to actually submit it the",
    "start": "1911190",
    "end": "1918960"
  },
  {
    "text": "pipeline we can just call out to the pipe of the coop flow pipelines SDK and that will go ahead and submit the",
    "start": "1918960",
    "end": "1925620"
  },
  {
    "text": "pipeline and print out a link and we can open that link to see that pipeline running in coop flow pipelines and so in",
    "start": "1925620",
    "end": "1932429"
  },
  {
    "text": "this case we have a very simple pipeline where we're just pre-processing and training and then validating the",
    "start": "1932429",
    "end": "1937839"
  },
  {
    "text": "data so the key takeaway is that you know using coop flow you can begin to build these complex workflows just like",
    "start": "1937839",
    "end": "1944289"
  },
  {
    "text": "go-jek is doing and this is gonna land using feast as your feature store you",
    "start": "1944289",
    "end": "1950080"
  },
  {
    "text": "can rapidly iterate and deploy models into production so just a couple quick",
    "start": "1950080",
    "end": "1963070"
  },
  {
    "text": "words about coop flow so this is kind of the motivation for coop flow so if",
    "start": "1963070",
    "end": "1969249"
  },
  {
    "text": "you're building coop flop ml pipelines it's a complex workflow that you have",
    "start": "1969249",
    "end": "1974979"
  },
  {
    "text": "multiple steps that you go through to build and deploy ml into production so you have data ingestion you have",
    "start": "1974979",
    "end": "1980799"
  },
  {
    "text": "training you have deploying for each of these steps in your process you have multiple applications that you could",
    "start": "1980799",
    "end": "1986409"
  },
  {
    "text": "choose from so for example for serving you could be using tensorflow serving you could be using invidious inference",
    "start": "1986409",
    "end": "1992589"
  },
  {
    "text": "server so with coop coop flow we're trying to make it very easy to run these applications on kubernetes and then",
    "start": "1992589",
    "end": "1998519"
  },
  {
    "text": "combine them into complex workflows we have three core tenants you know one is",
    "start": "1998519",
    "end": "2004739"
  },
  {
    "text": "composability so as you saw from our our demo we want to make it super easy to take different applications like feast",
    "start": "2004739",
    "end": "2011009"
  },
  {
    "text": "and tf-x and combine them into complex workflows we're also very interested in scalability so we want to make it super",
    "start": "2011009",
    "end": "2017190"
  },
  {
    "text": "easy for users to scale out you know either by running multiple jobs or running jobs with you know large amounts",
    "start": "2017190",
    "end": "2023339"
  },
  {
    "text": "of resources and then finally portability we want to make it super easy to run anywhere that kubernetes",
    "start": "2023339",
    "end": "2030450"
  },
  {
    "text": "runs and that's one of the and that's one of the advantages of using kubernetes is that it runs in the cloud",
    "start": "2030450",
    "end": "2035729"
  },
  {
    "text": "and on-premise is a quick diagram of what coop flow looks like the",
    "start": "2035729",
    "end": "2041399"
  },
  {
    "text": "architecture we basically have a bunch of shared applications and custom",
    "start": "2041399",
    "end": "2048299"
  },
  {
    "text": "controllers that run in a shared namespace but then all users can deploy and consume coop flow in their own",
    "start": "2048299",
    "end": "2054270"
  },
  {
    "text": "namespace so they can run pipelines and notebooks in their own namespace and then we expose all these services behind",
    "start": "2054270",
    "end": "2061919"
  },
  {
    "text": "an ingress so that you can access them from out the cluster as I mentioned before we are",
    "start": "2061919",
    "end": "2067950"
  },
  {
    "text": "an open-source project and we have a weird we have a lot of momentum and a lot of great contributions from outside",
    "start": "2067950",
    "end": "2074249"
  },
  {
    "text": "the community and from within the community so we have over 30 companies participating and we're growing rapidly",
    "start": "2074249",
    "end": "2079919"
  },
  {
    "text": "as these graphs show so in the last 28 days we've had almost 500 PRS and our",
    "start": "2079919",
    "end": "2085499"
  },
  {
    "text": "number of contributors keeps growing we have about 80 unique contributors in the last 80 days 20 28 days and finally you",
    "start": "2085499",
    "end": "2093929"
  },
  {
    "text": "know our motto so to speak is we want to have a low bar so make it super easy for people to get started with machine",
    "start": "2093929",
    "end": "2099779"
  },
  {
    "text": "learning on kubernetes but then we want to have a very high ceiling so we don't want to limit what people can do with",
    "start": "2099779",
    "end": "2105509"
  },
  {
    "text": "machine learning on kubernetes and so finally I think it would be great if you went to the coop flow docs page and",
    "start": "2105509",
    "end": "2112769"
  },
  {
    "text": "found our getting started guide to try out coop flow you can also go to the",
    "start": "2112769",
    "end": "2117869"
  },
  {
    "text": "feast website and follow the instructions to installing feast and if you go to this github page you can",
    "start": "2117869",
    "end": "2124739"
  },
  {
    "text": "actually download the demo that we showed you today and go through it yourself there's a lot of great talks to",
    "start": "2124739",
    "end": "2132150"
  },
  {
    "text": "here at coop con about coop flow you might want to consider checking out some of the videos or materials online thank",
    "start": "2132150",
    "end": "2139199"
  },
  {
    "text": "you very much I don't think we have any time left for questions but maybe we can try for one if anybody has a quick one",
    "start": "2139199",
    "end": "2148069"
  },
  {
    "text": "the question was what is the store used for inference for the features in production the serving store in our case",
    "start": "2155940",
    "end": "2163080"
  },
  {
    "text": "we have a choice between greatest or big table in this case of straightest yes",
    "start": "2163080",
    "end": "2170270"
  },
  {
    "text": "one more quick question all right",
    "start": "2170270",
    "end": "2176270"
  },
  {
    "text": "I think that's definitely on the cards but it's not a priority for us right now it's a little early stages for this",
    "start": "2183990",
    "end": "2191190"
  },
  {
    "text": "software project so we're open to PRS here once you contribute thank you very",
    "start": "2191190",
    "end": "2198780"
  },
  {
    "text": "much we'll be outside if anybody has any other questions [Applause]",
    "start": "2198780",
    "end": "2206290"
  }
]
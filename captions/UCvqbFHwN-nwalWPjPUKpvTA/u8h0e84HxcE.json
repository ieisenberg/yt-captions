[
  {
    "start": "0",
    "end": "0"
  },
  {
    "text": "hi everyone i'm joseph esquivel i'm working reddit in the containers team during this talk i will go through the",
    "start": "80",
    "end": "6000"
  },
  {
    "text": "secret linux kernel feature give some basic introduction with a particular focus on how it's used by",
    "start": "6000",
    "end": "11519"
  },
  {
    "text": "kubernetes i'll go through about c group version and what it took to get support for c group of v2",
    "start": "11519",
    "end": "17680"
  },
  {
    "text": "so what are c groups c group is a kernel feature that allows to set research constraints",
    "start": "17680",
    "end": "23199"
  },
  {
    "start": "18000",
    "end": "18000"
  },
  {
    "text": "to a group of processes it also allows to monitor how much of these resources are really used its structure has a set of",
    "start": "23199",
    "end": "30640"
  },
  {
    "text": "different controllers each of them specialized for a kind of resource so we have controllers",
    "start": "30640",
    "end": "37280"
  },
  {
    "text": "like cpu to limit the monitor cpu usage or the memory controller that is",
    "start": "37280",
    "end": "42719"
  },
  {
    "text": "specialized with memory usage c groups are structured in a hierarchical way each c group has a",
    "start": "42719",
    "end": "48399"
  },
  {
    "text": "parent except for the root c group they are managed from user space to a",
    "start": "48399",
    "end": "54559"
  },
  {
    "text": "file system so how do we use them whenever you have a problem like limiting",
    "start": "54559",
    "end": "59680"
  },
  {
    "start": "56000",
    "end": "56000"
  },
  {
    "text": "resource usage for a pod or a container c groups can help us we can solve problems like having",
    "start": "59680",
    "end": "65760"
  },
  {
    "text": "constraints on how much memory can be used how much cpu and what cpu cores are allowed for some",
    "start": "65760",
    "end": "72000"
  },
  {
    "text": "containers we can set also weights on each c group saying how much time in",
    "start": "72000",
    "end": "78000"
  },
  {
    "text": "proportion to the other c groups it should get when there is cpu contention",
    "start": "78000",
    "end": "83520"
  },
  {
    "text": "we can also limit assets to the os devices also pits are a finite resource",
    "start": "83520",
    "end": "90320"
  },
  {
    "text": "so through c groups we can also limit how many of them are allowed to each container",
    "start": "90320",
    "end": "99439"
  },
  {
    "start": "99000",
    "end": "99000"
  },
  {
    "text": "uh to give some background sigrpu v1 the one currently used by kubernetes was",
    "start": "99439",
    "end": "106960"
  },
  {
    "text": "first developed at google in 2006 and uh force finally merged in the upstream",
    "start": "106960",
    "end": "112479"
  },
  {
    "text": "linux kernel in 2008 secret v2 followed up",
    "start": "112479",
    "end": "118479"
  },
  {
    "text": "a decade later and was released in 2016. so it's uh it's not really such a novel",
    "start": "118479",
    "end": "125360"
  },
  {
    "text": "technology it has been around already for some years the proposal for adding uh secret v2",
    "start": "125360",
    "end": "131520"
  },
  {
    "text": "supports was accepted just a few months ago last february and the secret pv2 support",
    "start": "131520",
    "end": "140000"
  },
  {
    "text": "was added for the release 119. c groups are not a monolithic feature",
    "start": "140319",
    "end": "146480"
  },
  {
    "text": "controllers were that the later after the initial support for example",
    "start": "146480",
    "end": "152160"
  },
  {
    "text": "ldma was added to c group week 1 even after zero pv2 was already released",
    "start": "152160",
    "end": "160480"
  },
  {
    "text": "so let's start with segreg one as i have already stressed it it's a",
    "start": "160480",
    "end": "166000"
  },
  {
    "text": "group of different controllers each of them specialized for a single resource configuration separately for each of",
    "start": "166000",
    "end": "174080"
  },
  {
    "text": "controller they have a hierarchical structure in",
    "start": "174080",
    "end": "181040"
  },
  {
    "text": "the picture we see a few c groups created for the memory controller a and b are at the same level while c is a child",
    "start": "181040",
    "end": "187760"
  },
  {
    "text": "of a so it inherits all the limitations we we set for a",
    "start": "187760",
    "end": "192879"
  },
  {
    "text": "and the likewise d inherits all the limitations from from c child c groups can restrict",
    "start": "192879",
    "end": "201200"
  },
  {
    "text": "further the limits that were set for the parent",
    "start": "201200",
    "end": "207200"
  },
  {
    "text": "other controllers might or may not have the same urge since they are configured separately",
    "start": "207599",
    "end": "212799"
  },
  {
    "text": "they could have a completely different uh tree in practic in practice this freedom is never used and and the same",
    "start": "212799",
    "end": "220879"
  },
  {
    "text": "hierarchy with the same naming is mirrored across all the",
    "start": "220879",
    "end": "226319"
  },
  {
    "text": "controllers later we will see how this experience led some decisions",
    "start": "226319",
    "end": "232400"
  },
  {
    "text": "in the c group of v2 design since the freedom of having controllers",
    "start": "232400",
    "end": "238959"
  },
  {
    "text": "configured separately bring some difficulties in managing them while a container is being configured",
    "start": "238959",
    "end": "246480"
  },
  {
    "text": "it's part of some c groups but not of the others so setting c groups for a process is not",
    "start": "246480",
    "end": "252959"
  },
  {
    "text": "an atomic operation so cdc group",
    "start": "252959",
    "end": "260160"
  },
  {
    "text": "there are there are no syscalls or io ctrls to configure c groups everything is managed through the file system",
    "start": "260160",
    "end": "268880"
  },
  {
    "text": "the c group file system is the api for managing c groups each controller in secret v1 is a",
    "start": "268880",
    "end": "275120"
  },
  {
    "text": "different file system it must be mounted separately well this is not something users must do manually",
    "start": "275120",
    "end": "281120"
  },
  {
    "text": "usually the operating system takes care of setting up all the all these mounts and",
    "start": "281120",
    "end": "287520"
  },
  {
    "text": "we we see how how many mounts there are typically for a on a c group of one host like each",
    "start": "287520",
    "end": "294320"
  },
  {
    "text": "controller has a different mount",
    "start": "294320",
    "end": "299599"
  },
  {
    "start": "301000",
    "end": "301000"
  },
  {
    "text": "some useful information is also exposed to the procfs file system if we want to know",
    "start": "302160",
    "end": "308960"
  },
  {
    "text": "what uh c group process belongs we can look that through the uh proc b2c group file",
    "start": "308960",
    "end": "317039"
  },
  {
    "text": "there is also another file that gives more general stats about c groups usage",
    "start": "317039",
    "end": "325440"
  },
  {
    "start": "323000",
    "end": "323000"
  },
  {
    "text": "so how to interact with c groups regular file system operations like mkdir rename write rmd are used to",
    "start": "325440",
    "end": "333360"
  },
  {
    "text": "manage them to give an id in this table we can see what operations are",
    "start": "333360",
    "end": "338400"
  },
  {
    "text": "allowed to use let's say we are running a process and we would like to",
    "start": "338400",
    "end": "343680"
  },
  {
    "text": "limit its memory usage and we want to do this manually using directly the c group api",
    "start": "343680",
    "end": "352000"
  },
  {
    "text": "so the first thing we we have to do is to make sure the memory controller is mounted",
    "start": "352000",
    "end": "357600"
  },
  {
    "text": "so under the memory controller we create a new c group uh for simplicity we'll just",
    "start": "357600",
    "end": "363360"
  },
  {
    "text": "create it under the the root",
    "start": "363360",
    "end": "367840"
  },
  {
    "text": "then we will move the process we want to limit under the secret we just created and we",
    "start": "369919",
    "end": "376240"
  },
  {
    "text": "do that by writing the process speed to the cgroup.prox file",
    "start": "376240",
    "end": "381919"
  },
  {
    "text": "and finally we can set the limits on the new c group by writing to the memory.limitingbytes",
    "start": "381919",
    "end": "389600"
  },
  {
    "text": "file once the is terminated",
    "start": "389600",
    "end": "394880"
  },
  {
    "text": "the signal from must be cleaned manually through rmd so no one is going to do this",
    "start": "394880",
    "end": "402080"
  },
  {
    "text": "manually but these are exactly the steps the container runtime",
    "start": "402080",
    "end": "407520"
  },
  {
    "text": "takes for managing c groups i need to quickly introduce quality of service classes in kubernetes as it is",
    "start": "407520",
    "end": "414479"
  },
  {
    "start": "410000",
    "end": "410000"
  },
  {
    "text": "important to understand the next slides the cubelet assigns a qs class to each bot depending on how",
    "start": "414479",
    "end": "420479"
  },
  {
    "text": "its limits and requests are set if each container in the pod has bought limits and requests",
    "start": "420479",
    "end": "426000"
  },
  {
    "text": "set and they are equal then it gets what it asks for so it gets assigned the guaranteed qs",
    "start": "426000",
    "end": "431520"
  },
  {
    "text": "class if it's not guaranteed but there is at least one limit set deposits assigned the boostable qs class",
    "start": "431520",
    "end": "439280"
  },
  {
    "text": "everything else that is neither guaranteed nor boostable it's a best effort",
    "start": "439280",
    "end": "447360"
  },
  {
    "text": "so the human killer strictly speaking it's not a c group feature but it's used by kubernetes to",
    "start": "448880",
    "end": "454880"
  },
  {
    "text": "complement how it's used c groups actually each linux process has a home score",
    "start": "454880",
    "end": "461840"
  },
  {
    "text": "in out of memory situations the kernel will take it into account and will prefer terminating processes",
    "start": "461840",
    "end": "467759"
  },
  {
    "text": "with a higher room score it's possible to modify its volume part to a configurable adjustment",
    "start": "467759",
    "end": "476479"
  },
  {
    "start": "477000",
    "end": "477000"
  },
  {
    "text": "uh so uh um scoring kubernetes each",
    "start": "477199",
    "end": "482240"
  },
  {
    "text": "qs class is assigned a different home score as we saw earlier the higher the score",
    "start": "482240",
    "end": "489199"
  },
  {
    "text": "is the most likely the processors are going to be terminated by the kernel if there is not enough memory",
    "start": "489199",
    "end": "495840"
  },
  {
    "text": "best effort pods are the first ones to be terminated",
    "start": "495840",
    "end": "501360"
  },
  {
    "text": "guaranteed pods instead have almost the same home score as cubelet",
    "start": "501440",
    "end": "506479"
  },
  {
    "text": "the boostable pods instead gets assigned a dynamic value that it's calculated",
    "start": "506479",
    "end": "515279"
  },
  {
    "text": "considering how much memories are located to them in proportion to the entire",
    "start": "515279",
    "end": "521599"
  },
  {
    "text": "available memory so c groups are used by the cubelet",
    "start": "521599",
    "end": "528640"
  },
  {
    "start": "525000",
    "end": "525000"
  },
  {
    "text": "together with home score to manage and organize the pods the hierarchy created by kubernetes",
    "start": "528640",
    "end": "533920"
  },
  {
    "text": "is quite complex there is a cubot c group the dot",
    "start": "533920",
    "end": "539519"
  },
  {
    "text": "slice suffix is used when using the systemd driver",
    "start": "539519",
    "end": "546160"
  },
  {
    "text": "all pods are under this three group it's possible to settle limits for all the pods at this level",
    "start": "546160",
    "end": "554080"
  },
  {
    "text": "there is a mechanism in the cubelet called the system reservation where some resources are allocated for",
    "start": "554480",
    "end": "559920"
  },
  {
    "text": "the rest of the system when such reservation is in place limits for all the pods are configured",
    "start": "559920",
    "end": "567120"
  },
  {
    "text": "at this level at the cubot c-group so that it will affect every every bot",
    "start": "567120",
    "end": "574480"
  },
  {
    "text": "the guaranteed pods are a children of the cubs c group",
    "start": "574480",
    "end": "582399"
  },
  {
    "text": "at the same level like uh as each guaranteed pod there are two sibling c groups cubs",
    "start": "582399",
    "end": "589440"
  },
  {
    "text": "best effort and keyboards burstable each of them contain all the pods for the for the qos",
    "start": "589440",
    "end": "596640"
  },
  {
    "text": "class they refer to",
    "start": "596640",
    "end": "600399"
  },
  {
    "text": "the the the difference at the c group level between uh burstable and best effort is that best",
    "start": "601920",
    "end": "607440"
  },
  {
    "text": "effort gets the lowest cpu weight so that on cpu contention",
    "start": "607440",
    "end": "612800"
  },
  {
    "text": "the best effort pods gets the lowest",
    "start": "612800",
    "end": "619360"
  },
  {
    "text": "amount of cpu when we specify a limit in the yam spec",
    "start": "619360",
    "end": "626079"
  },
  {
    "start": "622000",
    "end": "622000"
  },
  {
    "text": "file they will be ultimately written to the c group file system as we saw",
    "start": "626079",
    "end": "631600"
  },
  {
    "text": "earlier until it gets there though there are quite a few steps involved",
    "start": "631600",
    "end": "638240"
  },
  {
    "text": "once the pod is scheduled to unload the cube blood handles the request of creating the pods",
    "start": "638240",
    "end": "645360"
  },
  {
    "text": "the limits that are configured for the pod are passed down to the cri runtime using",
    "start": "645360",
    "end": "652240"
  },
  {
    "text": "grpc and together with a home score value that the cubelet calculated",
    "start": "652240",
    "end": "661839"
  },
  {
    "text": "the container runtime after it sets up the storage and the network for the container it passed down the configuration to the",
    "start": "663920",
    "end": "671839"
  },
  {
    "text": "oc i run time that it responsible for",
    "start": "671839",
    "end": "677519"
  },
  {
    "text": "for running and configuring the container c group so we have",
    "start": "677519",
    "end": "685120"
  },
  {
    "text": "we have the communication between cubelet and cri runtime using gerpis",
    "start": "686240",
    "end": "692399"
  },
  {
    "text": "then we have the container runtime passing the configuration to the ocran time",
    "start": "692399",
    "end": "698320"
  },
  {
    "text": "through a json file",
    "start": "698320",
    "end": "703360"
  },
  {
    "text": "the ocean run time in the in the steps to create the container will uh will write this",
    "start": "703360",
    "end": "710480"
  },
  {
    "text": "values to the to the c group file system and set also the room score adjustment",
    "start": "710480",
    "end": "717360"
  },
  {
    "text": "to the proc file system the cubelet uses c groups also for",
    "start": "717360",
    "end": "723120"
  },
  {
    "start": "721000",
    "end": "721000"
  },
  {
    "text": "monitoring resource usages and that's done through the advisor the advisor is a package embedded",
    "start": "723120",
    "end": "728880"
  },
  {
    "text": "directly into the cubelet so while the container runtime is responsible for creating the c groups for the",
    "start": "728880",
    "end": "734720"
  },
  {
    "text": "various containers c advisor uses the same c groups to read statistics on what",
    "start": "734720",
    "end": "740880"
  },
  {
    "text": "resources are used by each of them i won't go into the details but obviously c advisor also needs to",
    "start": "740880",
    "end": "747360"
  },
  {
    "text": "understand the c groups version used by the host shortly",
    "start": "747360",
    "end": "752639"
  },
  {
    "text": "it's just another component to take care of for the c group v to support",
    "start": "752639",
    "end": "759120"
  },
  {
    "start": "759000",
    "end": "759000"
  },
  {
    "text": "so why do we care about c group we do if we can do everything already with a single moving one",
    "start": "759120",
    "end": "765279"
  },
  {
    "text": "well there are some issues with the sigrupui one that ultimately led to having a new version",
    "start": "765279",
    "end": "772880"
  },
  {
    "text": "of for the for c groups as we saw each controller must be",
    "start": "772880",
    "end": "779120"
  },
  {
    "text": "handled separately even if this freedom is never used in practice",
    "start": "779120",
    "end": "784160"
  },
  {
    "text": "it is just another uh additional complexity for uh no real gain also",
    "start": "784160",
    "end": "792480"
  },
  {
    "text": "integration with some subsystems is not ideal and fixing uh some of the ps is not",
    "start": "792480",
    "end": "800079"
  },
  {
    "text": "possible as it will be a breaking change",
    "start": "800079",
    "end": "804560"
  },
  {
    "text": "one big issue that doesn't affect directly our kubernetes groups today",
    "start": "805120",
    "end": "810399"
  },
  {
    "text": "is that delegation is not safe it's not possible with c group v1 to delegate a",
    "start": "810399",
    "end": "815920"
  },
  {
    "text": "subtree to a less privileged process in a safe way it's also not",
    "start": "815920",
    "end": "821600"
  },
  {
    "text": "possible to pre-allocate resources if we want to pre-allocate for a c group",
    "start": "821600",
    "end": "827519"
  },
  {
    "text": "a certain amount of resources like we like if we want to allocate uh",
    "start": "827519",
    "end": "833760"
  },
  {
    "text": "some memory that's not possible today with zero v1",
    "start": "833760",
    "end": "839600"
  },
  {
    "text": "as we saw the setup is not an atomic operation since a process must be",
    "start": "840959",
    "end": "847920"
  },
  {
    "text": "configured for each controller separately uh another big issue that it's",
    "start": "847920",
    "end": "855760"
  },
  {
    "text": "affecting kubernetes is that the um killer is not c group aware",
    "start": "855760",
    "end": "861600"
  },
  {
    "text": "if there is a out of memory situation the and given different process with the",
    "start": "862160",
    "end": "870000"
  },
  {
    "text": "same um score the kernel will terminate these processes without taking into account",
    "start": "870000",
    "end": "877519"
  },
  {
    "text": "to what c group they belong so what happens is that uh",
    "start": "877519",
    "end": "884480"
  },
  {
    "text": "processes from different containers can be terminated so leaving the these containers in a",
    "start": "884480",
    "end": "891120"
  },
  {
    "text": "broken state since some process are terminated but some others are left running",
    "start": "891120",
    "end": "898560"
  },
  {
    "text": "ideally what we would uh want is that a container so that it's under a",
    "start": "898560",
    "end": "906320"
  },
  {
    "text": "single c group is terminated like a an atomic unit so that all the processes",
    "start": "906320",
    "end": "913040"
  },
  {
    "text": "in the c group are terminated and and also we would like to first try",
    "start": "913040",
    "end": "920079"
  },
  {
    "text": "terminating a single container before uh affecting uh more of them",
    "start": "920079",
    "end": "927839"
  },
  {
    "text": "so let's get to singapore v2 now",
    "start": "928639",
    "end": "933199"
  },
  {
    "start": "934000",
    "end": "934000"
  },
  {
    "text": "so how we got here uh so fedora 31 was the first distro to enable secret",
    "start": "934000",
    "end": "939759"
  },
  {
    "text": "v2 by default we took a bet with it but it turned out to be a good decision",
    "start": "939759",
    "end": "946480"
  },
  {
    "text": "this was the turning point since once we switched to the default for fedora the rest of the",
    "start": "946480",
    "end": "953040"
  },
  {
    "text": "ecosystem followed the cost was uh was high since uh",
    "start": "953040",
    "end": "960000"
  },
  {
    "text": "since programs missing support for secret we do wouldn't work on a default fedora 31 installation",
    "start": "962560",
    "end": "971040"
  },
  {
    "text": "cyrano initially was my side project i started working on it as a replacement for run c while playing",
    "start": "971360",
    "end": "978240"
  },
  {
    "text": "with it i added support for c group of v2 and and it gained features",
    "start": "978240",
    "end": "986399"
  },
  {
    "text": "until we decided to use it by default on fedora with podman",
    "start": "986399",
    "end": "991759"
  },
  {
    "text": "we got a good feed the feedbacks with that and it's still used as the default",
    "start": "991759",
    "end": "997120"
  },
  {
    "text": "oci runtime at the time of the fedora 31 switch",
    "start": "997120",
    "end": "1003040"
  },
  {
    "text": "kubernetes also gained support for huge tlb",
    "start": "1003040",
    "end": "1008079"
  },
  {
    "text": "that controller will still missing in the in the kernel for c group v2 so by the time i got to work on the",
    "start": "1008079",
    "end": "1017279"
  },
  {
    "text": "enhancement proposal for the kubernetes i also needed to make sure that huge dlp",
    "start": "1017279",
    "end": "1023040"
  },
  {
    "text": "was supported in secret v2 soi to to add support for uh tlb in the kernel",
    "start": "1023040",
    "end": "1030880"
  },
  {
    "start": "1032000",
    "end": "1032000"
  },
  {
    "text": "so why do we need secret v2 well there are various reasons as we saw",
    "start": "1032160",
    "end": "1038000"
  },
  {
    "text": "before with the issues related to singapore v1 the most important uh one",
    "start": "1038000",
    "end": "1046079"
  },
  {
    "text": "for uh having the the switch to secret v2 is that secret one is considered legacy and",
    "start": "1046079",
    "end": "1054080"
  },
  {
    "text": "as such is named in the kernel also no new features will be added in the",
    "start": "1054080",
    "end": "1059840"
  },
  {
    "text": "future so this uh this migration had to happen at some point",
    "start": "1059840",
    "end": "1067840"
  },
  {
    "text": "uh also all the issues we saw before with the c group v1 are somehow fixed with the group of",
    "start": "1068559",
    "end": "1075679"
  },
  {
    "text": "v2 we have a c group aware whom killer",
    "start": "1075679",
    "end": "1081679"
  },
  {
    "text": "so that containers can be terminated as [Music]",
    "start": "1081679",
    "end": "1087200"
  },
  {
    "text": "atomically and my favorite feature that we gained with",
    "start": "1087200",
    "end": "1093679"
  },
  {
    "text": "c group of v2 is that delegation to less privileged process it's safe what does what does it mean it",
    "start": "1093679",
    "end": "1101360"
  },
  {
    "text": "means that uh we can create a sub c group",
    "start": "1101360",
    "end": "1106400"
  },
  {
    "text": "and well literally shown it to a different user",
    "start": "1106400",
    "end": "1112000"
  },
  {
    "text": "and let the user fully manage it",
    "start": "1112000",
    "end": "1116080"
  },
  {
    "text": "so that an user that it's not root on the system can fully manage",
    "start": "1117440",
    "end": "1124080"
  },
  {
    "text": "a c group and that's and that's safe a different return c",
    "start": "1124080",
    "end": "1130160"
  },
  {
    "text": "group we want another difference uh moving to c group v2 is that on",
    "start": "1130160",
    "end": "1137440"
  },
  {
    "text": "companies by default we also enable the c group namespace i will talk more about it later",
    "start": "1137440",
    "end": "1145360"
  },
  {
    "text": "so c group v2 there is a single hierarchy different than v1 and there is also a single mount",
    "start": "1145360",
    "end": "1153039"
  },
  {
    "text": "point and the process is part of a single c group",
    "start": "1153039",
    "end": "1159200"
  },
  {
    "text": "some controllers are not entered by c group itself anymore like the devices controller",
    "start": "1160559",
    "end": "1167760"
  },
  {
    "text": "now that it's and it's entered through eppf",
    "start": "1167760",
    "end": "1173200"
  },
  {
    "start": "1173000",
    "end": "1173000"
  },
  {
    "text": "the controllers are appropriate property of the c group itself so now we don't create a c group",
    "start": "1173840",
    "end": "1181919"
  },
  {
    "text": "under a controller but we enable a controller for the c group a controller can be used in a",
    "start": "1181919",
    "end": "1188880"
  },
  {
    "text": "c group only fits already enabled in the parent c group this is done through a new file",
    "start": "1188880",
    "end": "1197840"
  },
  {
    "text": "cgroup subtree control",
    "start": "1197840",
    "end": "1201440"
  },
  {
    "text": "not everything that was exposed by sigrpup v1 is available with c group v2 for instance there are some stat",
    "start": "1203039",
    "end": "1209840"
  },
  {
    "text": "files like usage per cpu but it's not present in c group v2 there are also some",
    "start": "1209840",
    "end": "1216799"
  },
  {
    "text": "new features that are not available in c group v1 some configuration changed semantics in",
    "start": "1216799",
    "end": "1224320"
  },
  {
    "text": "v2 for example the memory swap limit is configured in a different way",
    "start": "1224320",
    "end": "1230320"
  },
  {
    "text": "some other configuration kept the same semantics as in v1 but are using either different names",
    "start": "1230320",
    "end": "1237039"
  },
  {
    "text": "or different ranges an example is cpu shares that changed",
    "start": "1237039",
    "end": "1242159"
  },
  {
    "text": "both the name and the range in c group v2",
    "start": "1242159",
    "end": "1249440"
  },
  {
    "start": "1247000",
    "end": "1247000"
  },
  {
    "text": "um so other uh difference with single proof v2 the first one it's a",
    "start": "1249440",
    "end": "1256880"
  },
  {
    "text": "huge difference to always keep in mind with c group v2 processor can be added only to leaf",
    "start": "1256880",
    "end": "1262720"
  },
  {
    "text": "nodes in the hierarchy each node in the c group",
    "start": "1262720",
    "end": "1270320"
  },
  {
    "text": "hierarchy can either have children c groups or f processes with c group v1 instead",
    "start": "1270320",
    "end": "1277200"
  },
  {
    "text": "process could be moved at any level in the tree so we we had a c group that was",
    "start": "1277200",
    "end": "1285840"
  },
  {
    "text": "having a process to manage but also having sub c groups",
    "start": "1286240",
    "end": "1292320"
  },
  {
    "text": "as i already said before a controller must be enabled in all the parent c groups before it can be used in a in a c group",
    "start": "1293679",
    "end": "1302880"
  },
  {
    "text": "originally all the trades had to be in the same c group the this limitation was relaxed at the",
    "start": "1302880",
    "end": "1310080"
  },
  {
    "text": "newer kernels and now it's possible to migrate single threats to different",
    "start": "1310080",
    "end": "1315679"
  },
  {
    "text": "c groups there is also an another cool feature",
    "start": "1315679",
    "end": "1322320"
  },
  {
    "text": "ns delegate that was added later and that makes the allegation to",
    "start": "1322320",
    "end": "1327440"
  },
  {
    "text": "privileged process even safer as it enables additional restrictions",
    "start": "1327440",
    "end": "1334159"
  },
  {
    "start": "1333000",
    "end": "1333000"
  },
  {
    "text": "pressure style information is a new c group v2 feature for each c group it says how much time",
    "start": "1335280",
    "end": "1342320"
  },
  {
    "text": "was wasted waiting for resources to be available it gives a good indication when the",
    "start": "1342320",
    "end": "1347919"
  },
  {
    "text": "system is not doing enough useful work and if a pot must be terminated",
    "start": "1347919",
    "end": "1355200"
  },
  {
    "text": "this new feature enables umd then killer in user space that it's developed by",
    "start": "1355919",
    "end": "1361679"
  },
  {
    "text": "facebook and being added to systemd so that",
    "start": "1361679",
    "end": "1367280"
  },
  {
    "text": "the hume killer management is moved to user space from the from the kernel",
    "start": "1367280",
    "end": "1375840"
  },
  {
    "start": "1377000",
    "end": "1377000"
  },
  {
    "text": "in secret v2 memory limits are configured through four different files that gives",
    "start": "1378960",
    "end": "1384480"
  },
  {
    "text": "a lot of control on on memory",
    "start": "1384480",
    "end": "1389840"
  },
  {
    "text": "still this configuration is not exposed to kubernetes as we",
    "start": "1390320",
    "end": "1397840"
  },
  {
    "text": "as we are exposing at the moment just the features that were also available in c group v1 but",
    "start": "1397840",
    "end": "1405360"
  },
  {
    "text": "this this is something to well to improve in in the future",
    "start": "1405360",
    "end": "1410880"
  },
  {
    "text": "now with c group v2 it's possible to specify a portion of memory that's never going",
    "start": "1410880",
    "end": "1417440"
  },
  {
    "text": "to be reclaimed that's configured to the memory.min file",
    "start": "1417440",
    "end": "1424080"
  },
  {
    "text": "and there are also other levels configurable memory low it's a",
    "start": "1424480",
    "end": "1432240"
  },
  {
    "text": "it's a memory that it's reclaimed only if there is nothing uh reclaimable in other c groups",
    "start": "1432240",
    "end": "1438480"
  },
  {
    "text": "then there is memory high and the kernel on the wrong run tries to",
    "start": "1438480",
    "end": "1445279"
  },
  {
    "text": "keep a memory usage for the c group below this limit and then there is uh well there is still a heart limit and",
    "start": "1445279",
    "end": "1453440"
  },
  {
    "text": "once that is reached the process is it's terminated immediately",
    "start": "1453440",
    "end": "1458960"
  },
  {
    "text": "by the kernel this is not a secret feature added",
    "start": "1458960",
    "end": "1466559"
  },
  {
    "start": "1461000",
    "end": "1461000"
  },
  {
    "text": "by secret v2 but this was not used the before with cgroup v1 as only",
    "start": "1466559",
    "end": "1475840"
  },
  {
    "text": "well only newer kernels had support for it with c group v2 instead we are sure that",
    "start": "1475840",
    "end": "1482559"
  },
  {
    "text": "the kernel it's new enough to have also the c group namespace so it makes sense to enable it by",
    "start": "1482559",
    "end": "1488400"
  },
  {
    "text": "default also this is the right timing for such breaking changes because anyway we are changing all the",
    "start": "1488400",
    "end": "1498480"
  },
  {
    "text": "c group api is exposed to the user space and to the containers",
    "start": "1498480",
    "end": "1506720"
  },
  {
    "text": "when the container runs in a new c group namespace it won't be able to read its full c group from the host perspective",
    "start": "1510320",
    "end": "1517600"
  },
  {
    "text": "anymore it will be limited to the namespace that we are just creating",
    "start": "1517600",
    "end": "1523360"
  },
  {
    "text": "when a space is created the current c group becomes the the root",
    "start": "1523360",
    "end": "1530158"
  },
  {
    "start": "1533000",
    "end": "1533000"
  },
  {
    "text": "the ocean time is the component responsible for ultimately setting up the container",
    "start": "1533440",
    "end": "1538640"
  },
  {
    "text": "it's the lowest level in the stack and as we saw earlier it gets the configuration directly from a",
    "start": "1538640",
    "end": "1544320"
  },
  {
    "text": "container's runtime engine such as cryo container d as a json file",
    "start": "1544320",
    "end": "1550400"
  },
  {
    "text": "as part of the configuration that it gets there is a resources block that specifies the c",
    "start": "1551279",
    "end": "1557440"
  },
  {
    "text": "group limits to use on a c group v1 system as we can see on",
    "start": "1557440",
    "end": "1563840"
  },
  {
    "text": "the slide this configuration maps exactly to the c group file system",
    "start": "1563840",
    "end": "1569520"
  },
  {
    "text": "there isn't any creative step in the oc iron time it just moves the configuration from the json file to the file system",
    "start": "1569520",
    "end": "1577679"
  },
  {
    "text": "there are time specs are designed for c group v1 they don't map nicely to c group v2",
    "start": "1577919",
    "end": "1584720"
  },
  {
    "text": "different file names in different ranges and some times the different semantics are not",
    "start": "1584720",
    "end": "1591039"
  },
  {
    "text": "managed through this configuration the only mechanism for extending the",
    "start": "1591039",
    "end": "1598720"
  },
  {
    "text": "ucrm time configuration is true annotations but that's not really nice for structured data and it's not a",
    "start": "1598720",
    "end": "1605520"
  },
  {
    "text": "standard it's not it's meant only for custom extensions not for",
    "start": "1605520",
    "end": "1610960"
  },
  {
    "text": "something like sigrupue to support the first two problems",
    "start": "1610960",
    "end": "1617200"
  },
  {
    "text": "are somehow solved today and i'll show you how in the next slide for the tiered one",
    "start": "1617200",
    "end": "1622640"
  },
  {
    "text": "i opened a proposal for extending the runtime specifications and adding native support for c group",
    "start": "1622640",
    "end": "1629840"
  },
  {
    "text": "v2 so the problems i introduced before",
    "start": "1629840",
    "end": "1638799"
  },
  {
    "start": "1633000",
    "end": "1633000"
  },
  {
    "text": "are solved today with a mechanism of conversion between the two versions firstly i had implemented",
    "start": "1638799",
    "end": "1645600"
  },
  {
    "text": "it for siran and they thought it was a hack but well it was good enough to get",
    "start": "1645600",
    "end": "1650799"
  },
  {
    "text": "started without worrying about changing specifications and the",
    "start": "1650799",
    "end": "1655840"
  },
  {
    "text": "rest of the stack an example is the cpu shares file that",
    "start": "1655840",
    "end": "1663120"
  },
  {
    "text": "if we get the configuration from c group week one that so the range",
    "start": "1663120",
    "end": "1670480"
  },
  {
    "text": "as the c group v1 valid range is converted to cgroup v2",
    "start": "1670480",
    "end": "1677360"
  },
  {
    "text": "so it's written to a different file and using a different range",
    "start": "1677360",
    "end": "1683840"
  },
  {
    "text": "advantages of such mechanism well is that a container engine requires minimal changes as it can",
    "start": "1687200",
    "end": "1693919"
  },
  {
    "text": "generate exactly the same configuration for the oci runtime",
    "start": "1693919",
    "end": "1699440"
  },
  {
    "text": "same thing for the cubelet that can pass down the the same limits as before as they will be converted",
    "start": "1699440",
    "end": "1706960"
  },
  {
    "text": "later anyway uh run c now performs the",
    "start": "1706960",
    "end": "1713600"
  },
  {
    "text": "the same conversions so there are there are two oc iron times uh using the",
    "start": "1713600",
    "end": "1720799"
  },
  {
    "text": "this mechanism now",
    "start": "1720799",
    "end": "1725840"
  },
  {
    "text": "so what's next well we reached the features parrot with cgroup v1 now",
    "start": "1726080",
    "end": "1733440"
  },
  {
    "start": "1727000",
    "end": "1727000"
  },
  {
    "text": "uh probably the first next step is to get the runtime specs changes",
    "start": "1733440",
    "end": "1740720"
  },
  {
    "text": "and once we have that we can add native support through the stack",
    "start": "1740720",
    "end": "1747120"
  },
  {
    "text": "starting from the starting from the oca runtime and and extending",
    "start": "1747120",
    "end": "1754799"
  },
  {
    "text": "containers runtime and kubernetes to take advantage of the new features we have with c group",
    "start": "1754799",
    "end": "1761600"
  },
  {
    "text": "v2 c group v2 enables some useful",
    "start": "1761600",
    "end": "1768880"
  },
  {
    "text": "new use cases for kubernetes as i was saying before delegation to",
    "start": "1768880",
    "end": "1777919"
  },
  {
    "text": "less privileged processes it's it's safe now",
    "start": "1777919",
    "end": "1784159"
  },
  {
    "text": "so what is possible for kubernetes that it it will be possible to have nested the kubernetes with a full c",
    "start": "1784159",
    "end": "1790720"
  },
  {
    "text": "group support and that's and that can be done in a safe way since",
    "start": "1790720",
    "end": "1797760"
  },
  {
    "text": "the nested environment cannot affect the outside limits",
    "start": "1797760",
    "end": "1808320"
  },
  {
    "text": "that's all thanks",
    "start": "1808320",
    "end": "1812960"
  }
]
[
  {
    "text": "hello everyone I'm Tommy thank you for joining these sessions I'm the senior software developer at IBM working in the",
    "start": "719",
    "end": "6919"
  },
  {
    "text": "open technology teams and today we're going uh to go over the complexity on scaling Mii pipelines on C using",
    "start": "6919",
    "end": "15160"
  },
  {
    "text": "tons so to begin with let's talk about what is ton pipelines so ton pipelines",
    "start": "15160",
    "end": "20199"
  },
  {
    "text": "is a project that provides CID style resource for declaring cicd style pipelines and it's mainly you know",
    "start": "20199",
    "end": "26640"
  },
  {
    "text": "construct with you know few main crds namely task pipeline task run pipeline",
    "start": "26640",
    "end": "31800"
  },
  {
    "text": "run and custom runs um these are three you know major CD that we use within P ton pipelines um for example the",
    "start": "31800",
    "end": "39559"
  },
  {
    "text": "pipeline run it defines the execution of the pipeline itself that compos multiple tasks a task run that defines the",
    "start": "39559",
    "end": "46000"
  },
  {
    "text": "execution of a task which is a a set of build steps and also we also have a",
    "start": "46000",
    "end": "51239"
  },
  {
    "text": "custom runs that allows you to instantiate and execute Uh custom task which is able to implement with you know",
    "start": "51239",
    "end": "57960"
  },
  {
    "text": "uh any custom Cass controller which you could Define your own um task Logics and why want to use ton pipeline",
    "start": "57960",
    "end": "65640"
  },
  {
    "text": "to build our ml infrastructure well the main reason is that like we are need to build our ml infrastructure on top of",
    "start": "65640",
    "end": "71560"
  },
  {
    "text": "open shift and open shift container platform is the industry leaders uh is the industry leading Enterprise ku8",
    "start": "71560",
    "end": "78000"
  },
  {
    "text": "platform which it brings out the box of many featur for developer including CICS",
    "start": "78000",
    "end": "83439"
  },
  {
    "text": "uh and the cicd for open ship um platform is open ship pipelines and open",
    "start": "83439",
    "end": "88600"
  },
  {
    "text": "ship pipeline is based onch te ton project which offers native Integrations",
    "start": "88600",
    "end": "93920"
  },
  {
    "text": "with the open share platforms and provides smooth experience for the developers and out of the box uh open",
    "start": "93920",
    "end": "100320"
  },
  {
    "text": "shift peline also certified by red hat for open shift and also have Enterprise version a available on open shift as",
    "start": "100320",
    "end": "106759"
  },
  {
    "text": "well and that's why we have this is the main reason want to run you know secure pipelines for ML and AI on open shift",
    "start": "106759",
    "end": "113520"
  },
  {
    "text": "and this is the option we have chosen and when we actually look into",
    "start": "113520",
    "end": "118680"
  },
  {
    "text": "what techn have out the box we see a lot of the good things so techon will able to help us run anable floats a to",
    "start": "118680",
    "end": "125399"
  },
  {
    "text": "construct and create new parts for each of the task that us have defined able to have like condition that um uh able to",
    "start": "125399",
    "end": "132680"
  },
  {
    "text": "skip task when the condition you know is not match and able to pass PR very easily so any of the inputs and output",
    "start": "132680",
    "end": "139080"
  },
  {
    "text": "can be passed in between multiple parts and it has like um API to connect you",
    "start": "139080",
    "end": "144360"
  },
  {
    "text": "know custom controller so you want to have your custom Logic for your task you could also do that and were able to",
    "start": "144360",
    "end": "150480"
  },
  {
    "text": "optimize you know workflow workflow very easily on the controller levels and able to provide abstract the template which",
    "start": "150480",
    "end": "156440"
  },
  {
    "text": "it help us when we deploy the pipeline on different environments it's easy to have a different configuration settings",
    "start": "156440",
    "end": "163440"
  },
  {
    "text": "that defined on the pipeline levels and as we kind of build you know um ml pip on top tectons we see like",
    "start": "163440",
    "end": "171040"
  },
  {
    "text": "this F feature we want to have it in tecton and our IBM team actually work with the T Community to accomplish these",
    "start": "171040",
    "end": "177680"
  },
  {
    "text": "kind of features so uh first of all like we have the T finally it would help us",
    "start": "177680",
    "end": "183040"
  },
  {
    "text": "you know like Define any like arror handling cleanups if the pipeline is finished or failed and we also have like",
    "start": "183040",
    "end": "189760"
  },
  {
    "text": "very standard API um definitions and have a lot of way you could abstract the spec so you could actually Define a",
    "start": "189760",
    "end": "196480"
  },
  {
    "text": "global or clusterwise specs that able to share across model pipelines or share",
    "start": "196480",
    "end": "201519"
  },
  {
    "text": "across all your test inside the same pipelines and we also have ton workspace which it help you to define the common",
    "start": "201519",
    "end": "207879"
  },
  {
    "text": "you know volume across all your pipelines and you could also Define volume within the same pipeline so all",
    "start": "207879",
    "end": "213519"
  },
  {
    "text": "the task share the same you know workspace definitions and of course we",
    "start": "213519",
    "end": "218720"
  },
  {
    "text": "have the uh ton custom task which allow you to have any custom logic that is not provided by the um ton pipeline out the",
    "start": "218720",
    "end": "226360"
  },
  {
    "text": "box and we also have different termination Logics where if you want to cancel pipeline in machine learning",
    "start": "226360",
    "end": "232120"
  },
  {
    "text": "sometimes you want to just get rid of all the resource that you're running to just free up all the resource we have that Logics but you can also do the",
    "start": "232120",
    "end": "238560"
  },
  {
    "text": "traditional cicd way where you want you know the current running task to complete first then you exe uh exit the",
    "start": "238560",
    "end": "245560"
  },
  {
    "text": "pipeline you can also do that so there's multiple way you could terminate you know ton depending on your need and of",
    "start": "245560",
    "end": "252439"
  },
  {
    "text": "course um with machine learning we have a lot of parameters so having different like Matrix and able to Loop over those",
    "start": "252439",
    "end": "258600"
  },
  {
    "text": "Matrix is very helpful and with the new um ton release it actually introduce a",
    "start": "258600",
    "end": "264320"
  },
  {
    "text": "new common expression language um conditions so now not you not only able",
    "start": "264320",
    "end": "269840"
  },
  {
    "text": "to you know have condition just do like string matching you go like um have simple common expression language to do",
    "start": "269840",
    "end": "276199"
  },
  {
    "text": "the conditions on the fly so that's very helpful with all these fantastic",
    "start": "276199",
    "end": "281360"
  },
  {
    "text": "features on tons um we're able to build you know um very good workflows right",
    "start": "281360",
    "end": "287360"
  },
  {
    "text": "using tons basically just create a pipeline object you know to the G control plan it creates the um pipeline",
    "start": "287360",
    "end": "294440"
  },
  {
    "text": "CD and then with in the pipeline CD we create you know Tas crd that basically just construct with parts and all those",
    "start": "294440",
    "end": "300960"
  },
  {
    "text": "part will run you know each of those step which is a uh container by itself and this is the Fantastic you know cicd",
    "start": "300960",
    "end": "307520"
  },
  {
    "text": "platform and we're able to use them to you know build like simple you know uh ml pipelines in this case but we see the",
    "start": "307520",
    "end": "314320"
  },
  {
    "text": "limitation when we try to scale and give more complex ml pipelines um so some of the limitation",
    "start": "314320",
    "end": "319960"
  },
  {
    "text": "we found at the very beginning is that like ton we have no caching out the box",
    "start": "319960",
    "end": "325039"
  },
  {
    "text": "it makes sense because it's actually just a controller handle workflow there's no stor for uh store and cash",
    "start": "325039",
    "end": "331800"
  },
  {
    "text": "and there's no good you know uh python SDK capability let's say for data scientists it's very difficult for them",
    "start": "331800",
    "end": "337319"
  },
  {
    "text": "to you know compose a pipeline just using yo so it's good to have a python SDK to help them compose pipelines and",
    "start": "337319",
    "end": "344960"
  },
  {
    "text": "with this know like all the Box garbage collection so as you run more experiments uh those problem actually",
    "start": "344960",
    "end": "350639"
  },
  {
    "text": "you know leave on kubernetes which kind of was a lot you know this resource in our case and there's no lock archival so",
    "start": "350639",
    "end": "357240"
  },
  {
    "text": "when you actually try to clean up there's no way you could you know retain all those locks and of course um when",
    "start": "357240",
    "end": "363080"
  },
  {
    "text": "you have more complex pipeline you might want to share you know pipeline parameter across model pipelines um",
    "start": "363080",
    "end": "368720"
  },
  {
    "text": "currently there's no good out the box way to do on tectons so we see that as a limitation where we have to have all the",
    "start": "368720",
    "end": "375319"
  },
  {
    "text": "pipeline that compos in single taton pipelines which limit our scale abilities um and that comes to the next",
    "start": "375319",
    "end": "383199"
  },
  {
    "text": "um line where you compost everything in one single pipelines with the kuet unit",
    "start": "383199",
    "end": "388560"
  },
  {
    "text": "XD store you kind of limit on let's say 1.5 megabyte on your pipeline definition spec which limit the scale of the uh",
    "start": "388560",
    "end": "396479"
  },
  {
    "text": "pipeline size itself and lastly because um ml pipelines right you need to",
    "start": "396479",
    "end": "402599"
  },
  {
    "text": "understand what kind of inputs and output what kind of artif produce um so we need some tot of metadata to track",
    "start": "402599",
    "end": "409000"
  },
  {
    "text": "all those information so data scientist could easily go back and understand what they actually you know run and produce",
    "start": "409000",
    "end": "415520"
  },
  {
    "text": "within that pipelines and because of that we actually load into like all the",
    "start": "415520",
    "end": "421080"
  },
  {
    "text": "different you know open source projects and we found like ke for pipelines and ke for pipeline is actually aimed for um",
    "start": "421080",
    "end": "427360"
  },
  {
    "text": "data scientist to run any runtime any framework any data types so for example you want to just you know trade a models",
    "start": "427360",
    "end": "433960"
  },
  {
    "text": "using pytorch or using python to do like promt turning you could easily do on K for pel as well there's no limitation on",
    "start": "433960",
    "end": "440840"
  },
  {
    "text": "uh any library that blocking you um and it also provides you know very easy interface for data scientists um so for",
    "start": "440840",
    "end": "448560"
  },
  {
    "text": "examples right it has the python DSL so the scientist could Define their container spec or their Workforce spec",
    "start": "448560",
    "end": "454960"
  },
  {
    "text": "um using python itself and because with a native python it's easy to just pass input and outputs between you know",
    "start": "454960",
    "end": "461400"
  },
  {
    "text": "different python function and it will just translate into um this input output",
    "start": "461400",
    "end": "467120"
  },
  {
    "text": "and condition to ton directly and then um in addition why because we also have",
    "start": "467120",
    "end": "472360"
  },
  {
    "text": "looping capabilities um uh user could able to Define programmatic Concepts and",
    "start": "472360",
    "end": "478360"
  },
  {
    "text": "those concept easy translate into like C native pipelines um such as parallel",
    "start": "478360",
    "end": "483680"
  },
  {
    "text": "loops and in addition to that P pipeline provides you know uh multiple layers of",
    "start": "483680",
    "end": "488720"
  },
  {
    "text": "optimizations so first of all um the runtime of P actually leverage any cicd",
    "start": "488720",
    "end": "494639"
  },
  {
    "text": "cicd runtime you have provides so at the very beginning uh GI for power was built on AOS before ton was introduced and our",
    "start": "494639",
    "end": "501599"
  },
  {
    "text": "team see that ton is very useful for building M pipelines we actually introduce a new runtime to K for",
    "start": "501599",
    "end": "506639"
  },
  {
    "text": "pipelines for tectons and with um k for",
    "start": "506639",
    "end": "511720"
  },
  {
    "text": "pipelines right you're able to like provide us a common storage for storing experiment and data metadata tracking so",
    "start": "511720",
    "end": "518800"
  },
  {
    "text": "uh user could able to track all the experiment um and any kind of like",
    "start": "518800",
    "end": "524399"
  },
  {
    "text": "inputs and output also being stored in this case and once the pipeline is finished right we also have like garbage",
    "start": "524399",
    "end": "530480"
  },
  {
    "text": "cleanup and garbage collections where we able to archive all the um pipeline",
    "start": "530480",
    "end": "535680"
  },
  {
    "text": "history into a myle database so we able to create clean up all the uh space from kubernetes but you could still have all",
    "start": "535680",
    "end": "542720"
  },
  {
    "text": "the information that store in the database for analysis and F future reference as well and on top of that we",
    "start": "542720",
    "end": "549320"
  },
  {
    "text": "also add like um caching capabilities so uh anything you have ran before and um",
    "start": "549320",
    "end": "555279"
  },
  {
    "text": "you have no like um you want to like just cash the steps and not waste resource um once let's say your p is fa",
    "start": "555279",
    "end": "562560"
  },
  {
    "text": "you just re want it and you want to cash out the previous step you can also do that with k for",
    "start": "562560",
    "end": "568120"
  },
  {
    "text": "Pipelines and with this you can see like G pipeline provide a good way to clean up",
    "start": "568120",
    "end": "573399"
  },
  {
    "text": "all your um old pipelines in the um kuber control plane and provide a good",
    "start": "573399",
    "end": "578959"
  },
  {
    "text": "way to you know cache um your workloads uh inside the existing tecton",
    "start": "578959",
    "end": "585839"
  },
  {
    "text": "pipelines and what we have implements you know kful Pipeline on ton V1 is more like an extension of the existing ton",
    "start": "585839",
    "end": "592959"
  },
  {
    "text": "features so uh we are not we are really not modifying the ton pel itself too",
    "start": "592959",
    "end": "598440"
  },
  {
    "text": "much if we are mostly just do mapping you know the U user pipeline definition pretty much one",
    "start": "598440",
    "end": "604360"
  },
  {
    "text": "to one to ton pipelines but adding you know additional optimization features um so we have see that like um T garbage",
    "start": "604360",
    "end": "612560"
  },
  {
    "text": "collection so it that helps just reduce given any um HD dis size you know provide a python dsls and API server so",
    "start": "612560",
    "end": "620560"
  },
  {
    "text": "any user request could go to like the um Q for p API server and reduce the number",
    "start": "620560",
    "end": "626240"
  },
  {
    "text": "of qu uh user need to do uh to the kuber API directly and uh because we actually",
    "start": "626240",
    "end": "632839"
  },
  {
    "text": "want to do like cashing without modifying the ton pipeline itself in the first version we actually using part",
    "start": "632839",
    "end": "638959"
  },
  {
    "text": "mutation for caching which uh even uh with Al for p you could leverage this feature with Native ton just by adding",
    "start": "638959",
    "end": "645680"
  },
  {
    "text": "two annotations um so there's no impact to the ton controller Logics and um at",
    "start": "645680",
    "end": "651760"
  },
  {
    "text": "the very first uh version when we uh Implement ton backends um to K4 pipelines there's no um you know common",
    "start": "651760",
    "end": "659320"
  },
  {
    "text": "expression language and P Loops but we can easily extend those feature using custom test controller that's how we",
    "start": "659320",
    "end": "665519"
  },
  {
    "text": "actually leverage custom Tas controll at the beginning and um f f also provide",
    "start": "665519",
    "end": "670680"
  },
  {
    "text": "ways uh common storage for you to store the common artifacts and we also take",
    "start": "670680",
    "end": "676040"
  },
  {
    "text": "that advantage and store all our logs Al our logs in that com storage as well and",
    "start": "676040",
    "end": "681920"
  },
  {
    "text": "with the Pyon dsls it's easy for G scientist to produce any helper function and let other data scientists will use",
    "start": "681920",
    "end": "688600"
  },
  {
    "text": "so it's easy to produce common helper function and able to compose you know multiple common function into one simple",
    "start": "688600",
    "end": "695600"
  },
  {
    "text": "Q for pent task um for example we have like user that um produce logic that",
    "start": "695600",
    "end": "701320"
  },
  {
    "text": "wait for all the other file to be ready then execute that could be a simple python function that defines in Q for",
    "start": "701320",
    "end": "708320"
  },
  {
    "text": "Pipeline and then in the compiler code because it's commonly used we could just take the same Logics and apply to other",
    "start": "708320",
    "end": "714839"
  },
  {
    "text": "pipeline that uh other user have been using and finally it also produce um",
    "start": "714839",
    "end": "720480"
  },
  {
    "text": "provides a very simple preliminary metadata tracking so it actually gives you an idea what kind of data is",
    "start": "720480",
    "end": "726240"
  },
  {
    "text": "actually thrown in and what C data is been consumed for each",
    "start": "726240",
    "end": "731200"
  },
  {
    "text": "steps with all this awesome features uh we still see this limitation on the",
    "start": "732160",
    "end": "737760"
  },
  {
    "text": "scalabilities namely um when we do the caching um because we don't want to interfere the",
    "start": "737760",
    "end": "743680"
  },
  {
    "text": "tecton controller logic but from the beginning um the caching only can be done for part mutation which we still",
    "start": "743680",
    "end": "751399"
  },
  {
    "text": "have to like um schedule the part we still have to create the part construct the part that is the big bottle next and",
    "start": "751399",
    "end": "757120"
  },
  {
    "text": "because our power user actually have like tens of thousands of tasks in each pipelines um with tens of thousands of",
    "start": "757120",
    "end": "763360"
  },
  {
    "text": "tasks even though you try to like cash them you still have tens of thousands apart so that actually bottom next our",
    "start": "763360",
    "end": "769639"
  },
  {
    "text": "uh schedule as well for allocating resources and because of the um um big",
    "start": "769639",
    "end": "776880"
  },
  {
    "text": "size of pipelines um we are not able to store you know anything that's more than let's say 2,000 TS inside a single",
    "start": "776880",
    "end": "783720"
  },
  {
    "text": "pipeline because of the size of XDS and as we actually put all these Tas",
    "start": "783720",
    "end": "789079"
  },
  {
    "text": "togethers um by by the nature of tectons you want to break tecton into multiple",
    "start": "789079",
    "end": "795079"
  },
  {
    "text": "pipelines and just have them all connected together and passing problem between those pipelines it gets very",
    "start": "795079",
    "end": "801600"
  },
  {
    "text": "complex and when you try to compose that complex pipelines traversing that graph and you know validating that graph and",
    "start": "801600",
    "end": "807920"
  },
  {
    "text": "passing PR around that graph is very difficult um so this is why we kind of see um even",
    "start": "807920",
    "end": "815160"
  },
  {
    "text": "just to Traverse like a very good big graph in ton we see bottle next doing the scheduling",
    "start": "815160",
    "end": "822000"
  },
  {
    "text": "aspects so this is why we kind of move into a new design of kful pipeline called K4 pipeline V2s so instead of you",
    "start": "822000",
    "end": "829600"
  },
  {
    "text": "know having kful pipeline to be a small compilers that Maps you know um user um",
    "start": "829600",
    "end": "835279"
  },
  {
    "text": "Define the Python's uh definition one to one to tectons we actually just have a smart runtime where um the KP DSL KP SDK",
    "start": "835279",
    "end": "844639"
  },
  {
    "text": "or whatever your local no code uh interface that you compose the pipeline or compile into a intermediate",
    "start": "844639",
    "end": "851720"
  },
  {
    "text": "representations and behind the scenes this intermediate representation have all the uh lot all the uh graph",
    "start": "851720",
    "end": "858519"
  },
  {
    "text": "definitions all the uh requirements for composing the pipelines and let the",
    "start": "858519",
    "end": "863720"
  },
  {
    "text": "backend itself to optimally just uh map their own subset of the pipelines to",
    "start": "863720",
    "end": "870399"
  },
  {
    "text": "this uh complex pipeline itself so U from a tecton perspective you could have multiple tecton pipelines to compos one",
    "start": "870399",
    "end": "877519"
  },
  {
    "text": "you know uh complex user intermediate repr representations so from a user",
    "start": "877519",
    "end": "882759"
  },
  {
    "text": "perspective you could still see the pipeline be represent very complex but behind the scene it would break into",
    "start": "882759",
    "end": "888639"
  },
  {
    "text": "multiple pieces so tecton will not have the bottle neck of like sculpturing a big you know graph and Traverse a big",
    "start": "888639",
    "end": "896440"
  },
  {
    "text": "graph and to achieve this uh we actually introduced you know uh New Concepts called driver executed Publishers so",
    "start": "896440",
    "end": "904680"
  },
  {
    "text": "basically um in the drivers right so we actually uh storing you know uh PR Dex",
    "start": "904680",
    "end": "911320"
  },
  {
    "text": "and contacts in a driver so it knows uh okay which note is this execution supposed to do um and then once the",
    "start": "911320",
    "end": "918639"
  },
  {
    "text": "execution finished uh there will be a publisher that uploads the outputs artifacts and Status um to our common",
    "start": "918639",
    "end": "925880"
  },
  {
    "text": "you know um metad service called mlmd so so all the pipelines no matter which",
    "start": "925880",
    "end": "930959"
  },
  {
    "text": "pipeline you use could all you know share the same um parameter metadata artifacts Statics using just this mlmd",
    "start": "930959",
    "end": "939440"
  },
  {
    "text": "metadata servers um and this is very powerful because this means we actually",
    "start": "939440",
    "end": "944639"
  },
  {
    "text": "could break down ton into multiple smaller pipelines and reduce you know the complexity of the graph itself um",
    "start": "944639",
    "end": "950600"
  },
  {
    "text": "from the runtime representations and uh with the Q4 P V2",
    "start": "950600",
    "end": "958800"
  },
  {
    "text": "another um enhancement we have done is uh because we have uh Brun time for Aros",
    "start": "958800",
    "end": "964360"
  },
  {
    "text": "and ton as well we also create a abstract interface for future runtime so let's say you want to bring in airflow",
    "start": "964360",
    "end": "970920"
  },
  {
    "text": "it would be very easy for you to just uh add these three different components one is a compiler convert you know the Q for",
    "start": "970920",
    "end": "977000"
  },
  {
    "text": "peline intermediate representation into um the representation you want run time to run and then you have those you know",
    "start": "977000",
    "end": "984839"
  },
  {
    "text": "uh files right like you could convert uh your P into model pipelines and when you run it you have to just create a",
    "start": "984839",
    "end": "991000"
  },
  {
    "text": "execution clients to run those you know resources you have produce and then you also have execution specs that's where",
    "start": "991000",
    "end": "997600"
  },
  {
    "text": "it helps you to um modify it um your underlaying runtime specs when you actually need to say update parameters",
    "start": "997600",
    "end": "1004120"
  },
  {
    "text": "or update um a small subset of the",
    "start": "1004120",
    "end": "1009959"
  },
  {
    "text": "specs and um when we kind of dive in into what k for power V2 actually provides um we could see the driver",
    "start": "1010800",
    "end": "1018000"
  },
  {
    "text": "publisher model actually um separate into like kind of two categories so when",
    "start": "1018000",
    "end": "1024000"
  },
  {
    "text": "we actually say driver and publisher on the you know uh graph level the direct",
    "start": "1024000",
    "end": "1030000"
  },
  {
    "text": "exec graph levels you could see the driver actually just produce the parameter artifacts for the parent",
    "start": "1030000",
    "end": "1035480"
  },
  {
    "text": "contents and then see whether or not um our sub pipeline then because user could",
    "start": "1035480",
    "end": "1040798"
  },
  {
    "text": "also uh produce multiple sub pipelines we could see whether or not this supply line has been execut and we can we cach",
    "start": "1040799",
    "end": "1046839"
  },
  {
    "text": "it if so we could actually SK the whole subd and just reduce the complexity of the graph itself and then once the graph",
    "start": "1046839",
    "end": "1054480"
  },
  {
    "text": "is finished right the publisher could just takes the information um from the sub line have produced and just publish",
    "start": "1054480",
    "end": "1061200"
  },
  {
    "text": "it back to the um metad service and then on the task level when you actually won't need to run a contain 't run a",
    "start": "1061200",
    "end": "1067720"
  },
  {
    "text": "part for that particular task um the same driver and execution logic exist so",
    "start": "1067720",
    "end": "1073000"
  },
  {
    "text": "the driver I check whether or not this Tas has been executed before uh fet all the parameters um compu the conditions",
    "start": "1073000",
    "end": "1080320"
  },
  {
    "text": "and then if the cach is exist then actually we just skip the execution part if not then you uh it will just create",
    "start": "1080320",
    "end": "1087880"
  },
  {
    "text": "execution with the publisher embedded so in this case the publisher is actually a binary inside the user um part itself so",
    "start": "1087880",
    "end": "1096559"
  },
  {
    "text": "we are not adding you know any extra step we're not adding like um extra containers that um uh reduce you know",
    "start": "1096559",
    "end": "1104039"
  },
  {
    "text": "the user run times and once the user you know execution is finished we could see like from the publisher",
    "start": "1104039",
    "end": "1110520"
  },
  {
    "text": "aspects um um before the um user action is uh created uh the publisher main job",
    "start": "1110520",
    "end": "1119080"
  },
  {
    "text": "is actually to put all the artifact in needs for the user task to run and then",
    "start": "1119080",
    "end": "1124159"
  },
  {
    "text": "we place all those parameter with the necessary um parameter from the MMD then",
    "start": "1124159",
    "end": "1129400"
  },
  {
    "text": "run the user execution commands and once the execution command is finished then we grab any other effect that needed to",
    "start": "1129400",
    "end": "1135200"
  },
  {
    "text": "be upload upload to the uh um uh object storage that's designated and then",
    "start": "1135200",
    "end": "1140480"
  },
  {
    "text": "publish you know all the metadata that's related where the artifact is stored and what the parameter is being produced",
    "start": "1140480",
    "end": "1146559"
  },
  {
    "text": "back to you know the MMD medata servers so this way we don't have to rely on kuber API at all to you know s",
    "start": "1146559",
    "end": "1154039"
  },
  {
    "text": "all those status um you know know where the parameter is been um located uh all",
    "start": "1154039",
    "end": "1160440"
  },
  {
    "text": "this information actually store in MMD Med server so uh we actually could reduce the bottom net from the city",
    "start": "1160440",
    "end": "1167360"
  },
  {
    "text": "control plan itself and from a very high levels um when ke4",
    "start": "1167360",
    "end": "1174360"
  },
  {
    "text": "pipelines um on ton first designed it uh we have all these kind of driver publisher task um actually is a task in",
    "start": "1174360",
    "end": "1182600"
  },
  {
    "text": "tons and as we can see like this all bottom next when we create a lot of task inside a single yo and when ton schedule",
    "start": "1182600",
    "end": "1190320"
  },
  {
    "text": "like a lot of task it actually create a lot of bottle next on the schedule on the ton schedule itself and this is why",
    "start": "1190320",
    "end": "1196320"
  },
  {
    "text": "we as we kind of improve over time we try to merge all those driver Logics inside our um task controller and P",
    "start": "1196320",
    "end": "1205120"
  },
  {
    "text": "controller itself so our our current design is actually able to merge um the",
    "start": "1205120",
    "end": "1210440"
  },
  {
    "text": "driver and publisher logic into our task controller itself so the C task controller could just go ahead and",
    "start": "1210440",
    "end": "1217159"
  },
  {
    "text": "evaluate whether or not uh this cast this task is been cached and also evaluate all the conditions and if if",
    "start": "1217159",
    "end": "1224360"
  },
  {
    "text": "there's a need you uh you need to run a part you could actually run a part to to accomplish a task but we're also aware",
    "start": "1224360",
    "end": "1231080"
  },
  {
    "text": "that for M workflow sometime you might need like distributed trainings or let's say you want to run a ray workflows we",
    "start": "1231080",
    "end": "1237640"
  },
  {
    "text": "we could just simply just create a ray crd so you don't have to have a part that's dedicated to Runner clients uh we",
    "start": "1237640",
    "end": "1244640"
  },
  {
    "text": "could just create a c for you and um the r the r controller will just be aware the C and run your R drops so it's very",
    "start": "1244640",
    "end": "1251840"
  },
  {
    "text": "easy to integrate and reduce the number of part in integrate in these",
    "start": "1251840",
    "end": "1257080"
  },
  {
    "text": "scenarios um so to summarize um you know K4 p on ton V2 it brings the way how you run you",
    "start": "1257120",
    "end": "1264440"
  },
  {
    "text": "know uh custom task to handle caching skipping conditions and handling parameters all in one place and we also",
    "start": "1264440",
    "end": "1271840"
  },
  {
    "text": "have the publisher binary you know run along with the user codes so able to upload all the user task parameter into",
    "start": "1271840",
    "end": "1277760"
  },
  {
    "text": "the ml metadata service so actually able to you know reduce the uh limitation",
    "start": "1277760",
    "end": "1283080"
  },
  {
    "text": "from tons as you know ton parameter actually pass via the um C the yo itself",
    "start": "1283080",
    "end": "1289440"
  },
  {
    "text": "so as you put a lot of you know parameter inside ton you will have a limit on you know how big your",
    "start": "1289440",
    "end": "1295760"
  },
  {
    "text": "parameters but with this new approach um the uh the publish P just push the",
    "start": "1295760",
    "end": "1301640"
  },
  {
    "text": "parameter to the MF metadata servers which is backed by um current in the",
    "start": "1301640",
    "end": "1306799"
  },
  {
    "text": "open source MySQL or postare SQL database so your limit is much higher uh",
    "start": "1306799",
    "end": "1312360"
  },
  {
    "text": "in this scenarios and lastly we also you know publish a uh also upload all the problem status and graph structures all",
    "start": "1312360",
    "end": "1320080"
  },
  {
    "text": "in M metadata service so we actually don't have to retain you know the the graph structure in the uh pipeline uh",
    "start": "1320080",
    "end": "1327000"
  },
  {
    "text": "the tecton definition and on C itself so as we actually executing the pipelines",
    "start": "1327000",
    "end": "1332159"
  },
  {
    "text": "we can actually clean up the pipelines um because all the information will be uploaded as you know the subset of the",
    "start": "1332159",
    "end": "1338679"
  },
  {
    "text": "pipeline is being complete and with this uh enhancement we",
    "start": "1338679",
    "end": "1345440"
  },
  {
    "text": "could see that uh we able address the po you know creation issues um when we do the caching so all the cach right now",
    "start": "1345440",
    "end": "1352440"
  },
  {
    "text": "you don't need to you know create a new part so it would be very efficient from a cach pers perspective because of the",
    "start": "1352440",
    "end": "1358799"
  },
  {
    "text": "pipeline could be you know decouples into uh very small sub pipelines graph traversal is very simple with in ton",
    "start": "1358799",
    "end": "1365440"
  },
  {
    "text": "because you only see like subset of the pipeline it doesn't have to understand the whole complexity of the gigantic ml",
    "start": "1365440",
    "end": "1372080"
  },
  {
    "text": "pip floats um and all those information are stored in MMD so MMD you can see it",
    "start": "1372080",
    "end": "1377200"
  },
  {
    "text": "stores all the par and P status and it also um dramatically reduce the",
    "start": "1377200",
    "end": "1383520"
  },
  {
    "text": "limitation from XDS so you can actually break into a lot of um smaller Pipeline and store into xcds right um only small",
    "start": "1383520",
    "end": "1392120"
  },
  {
    "text": "limitation we still see is that um as our power users still have tens of thousands of tasks um each of those",
    "start": "1392120",
    "end": "1398480"
  },
  {
    "text": "tasks still represents by custom resource on kubernetes so as the number of P grow we could still see some",
    "start": "1398480",
    "end": "1404640"
  },
  {
    "text": "limitation on XDS but this is kind of similar to the concept of checkpoints from machine learning where um all each",
    "start": "1404640",
    "end": "1412679"
  },
  {
    "text": "our test is actually we quot those status um in the persistent volumes um",
    "start": "1412679",
    "end": "1417720"
  },
  {
    "text": "so we we could just actually um have the machine learning pipeline to be more",
    "start": "1417720",
    "end": "1422799"
  },
  {
    "text": "condensed and for any parameters any status doesn't need to be store in um",
    "start": "1422799",
    "end": "1428640"
  },
  {
    "text": "persistent um volumes we could um maybe just have a more advanced compilers to",
    "start": "1428640",
    "end": "1434440"
  },
  {
    "text": "combine those Logics and only pass those parameter in memory in instead of you know swing all those information in MMD",
    "start": "1434440",
    "end": "1440960"
  },
  {
    "text": "which you know reduce our um run times um so this is kind of a future",
    "start": "1440960",
    "end": "1447240"
  },
  {
    "text": "enhancement we're planning to do um and with that we're going to show you a",
    "start": "1447240",
    "end": "1452600"
  },
  {
    "text": "quick demos on how K ton 2.0 is been accomplished you could see we're using",
    "start": "1452600",
    "end": "1458559"
  },
  {
    "text": "you know the same SDK UI no matter you're using AO um tecton back end and",
    "start": "1458559",
    "end": "1465279"
  },
  {
    "text": "currently with the G pipeline 2.0 the implementation have't optimized the backend to run driver tasks um using",
    "start": "1465279",
    "end": "1473440"
  },
  {
    "text": "HTTP templat so all the driver Tas on Argo currently still running on part but the committee is working on uh",
    "start": "1473440",
    "end": "1479720"
  },
  {
    "text": "converting the aggo back and also to use um more like um long running server approach which it will significantly",
    "start": "1479720",
    "end": "1486760"
  },
  {
    "text": "able to reduce the caching time as you can see without that um ago has to take",
    "start": "1486760",
    "end": "1491799"
  },
  {
    "text": "you know like at least create three or four additional part which dramatically uh increase the duration where in in t",
    "start": "1491799",
    "end": "1498039"
  },
  {
    "text": "time we could simply just run a cach pipeline within two seconds so with this I'm going to show",
    "start": "1498039",
    "end": "1505000"
  },
  {
    "text": "the demot so uh when you go into the Q4",
    "start": "1505000",
    "end": "1511799"
  },
  {
    "text": "pipeline interface you could see this a pipeline you have created um once you click on this uh you could actually see",
    "start": "1511799",
    "end": "1519159"
  },
  {
    "text": "you know uh we also have versioning for the pipelines you could um pick different versions in this case I would",
    "start": "1519159",
    "end": "1524440"
  },
  {
    "text": "just um first run a version where uh we have all the um tasks um being",
    "start": "1524440",
    "end": "1532360"
  },
  {
    "text": "cached so let's just create a simple run um so when the p is being cached you",
    "start": "1532360",
    "end": "1538559"
  },
  {
    "text": "can see it could uh execute it uh fairly simply um over here and complet it very",
    "start": "1538559",
    "end": "1546159"
  },
  {
    "text": "fast so should be running in seconds yes so once the",
    "start": "1546159",
    "end": "1552559"
  },
  {
    "text": "you know pipeline is being scheduled everything is just pop out instantly um then and as we kind of go back um we can",
    "start": "1552559",
    "end": "1560480"
  },
  {
    "text": "see I think the startup times for the controller itself takes a bit a little bit so it it's been a second but it's",
    "start": "1560480",
    "end": "1567000"
  },
  {
    "text": "still like very fast um in the scenarios um and the fastest usually uh",
    "start": "1567000",
    "end": "1573159"
  },
  {
    "text": "in ideal environment you could see it could gets down to like two seconds when you run this",
    "start": "1573159",
    "end": "1578320"
  },
  {
    "text": "pipelines um and when we actually get the pment Run itself you could see Department actually completes",
    "start": "1578320",
    "end": "1585480"
  },
  {
    "text": "you know within a second even in the uh ton um U resource",
    "start": "1585480",
    "end": "1591600"
  },
  {
    "text": "perspective and you can see we actually run stuff in this pipeline so we actually run at least four tasks to",
    "start": "1591600",
    "end": "1598279"
  },
  {
    "text": "evaluate um the context of the graph and then also evaluate whether or not we",
    "start": "1598279",
    "end": "1604039"
  },
  {
    "text": "have the cach hit and all these four Tas is complete you know within like",
    "start": "1604039",
    "end": "1610440"
  },
  {
    "text": "seconds and with q for p is very easy for you to just pick uh which task um",
    "start": "1611480",
    "end": "1618120"
  },
  {
    "text": "been cached so let's do a scenario let's say we are not caching the training step",
    "start": "1618120",
    "end": "1623440"
  },
  {
    "text": "because um you know sometime training you have like Randomness uh in this case so we might not want to uh cat this so",
    "start": "1623440",
    "end": "1631240"
  },
  {
    "text": "you could just like run the same step multiple times but um because the preprocessing is always the same because",
    "start": "1631240",
    "end": "1637720"
  },
  {
    "text": "you have same data coming in and you do the same transformation so your output is always going to be the same um so in",
    "start": "1637720",
    "end": "1644480"
  },
  {
    "text": "this scenario you could see you know we could just cach the pre-processing part and then just take the same environment",
    "start": "1644480",
    "end": "1650640"
  },
  {
    "text": "um that produced um by by the cast outputs and do the trainings so it",
    "start": "1650640",
    "end": "1656679"
  },
  {
    "text": "should see yeah it will able to grab the artifacts right from the cach um output",
    "start": "1656679",
    "end": "1662440"
  },
  {
    "text": "and then do the training it actually running the part do trainings um and you could see from the output",
    "start": "1662440",
    "end": "1669399"
  },
  {
    "text": "itself could show you um the artifact produce in this case just simple message um artifa it",
    "start": "1669399",
    "end": "1676159"
  },
  {
    "text": "produce and then and once it produced you can see this is the new model in being uploaded to um the Min",
    "start": "1676159",
    "end": "1683440"
  },
  {
    "text": "storage so it's very easy to you know navigate in this case and you could simply just decide which test you want",
    "start": "1683440",
    "end": "1690159"
  },
  {
    "text": "to cach and which test uh you want to always",
    "start": "1690159",
    "end": "1694919"
  },
  {
    "text": "run so with this uh I complete my demo so we want to talk about some of the future optimization we're going to do um",
    "start": "1700279",
    "end": "1707919"
  },
  {
    "text": "with our current designs um because our current designs kind of rely on these driver and publisher models and our",
    "start": "1707919",
    "end": "1715279"
  },
  {
    "text": "initial implementation actually just um connecting all the roof node um behind",
    "start": "1715279",
    "end": "1721200"
  },
  {
    "text": "the driver uh test and uh connect all the leaf noes uh um connect the",
    "start": "1721200",
    "end": "1728279"
  },
  {
    "text": "publisher after all the leaf notes it actually creates a extra layer of complexity when we construct the pipeline s so the next pH we actually",
    "start": "1728279",
    "end": "1735159"
  },
  {
    "text": "try to have our controller to handles all the you know like driver and publisher logic itself as well and only",
    "start": "1735159",
    "end": "1741679"
  },
  {
    "text": "let ton handles the core um pipeline execution so um this way we actually",
    "start": "1741679",
    "end": "1747440"
  },
  {
    "text": "retain the complex U retain the same you know p uh tecton structures but able to",
    "start": "1747440",
    "end": "1752840"
  },
  {
    "text": "you know add those uh extra capability to do caching upload status right to the",
    "start": "1752840",
    "end": "1757960"
  },
  {
    "text": "med service in the controller itself um and as from the community size",
    "start": "1757960",
    "end": "1764840"
  },
  {
    "text": "um we're actually working on a more mature St IR so we were able to you know upload um the graph level status more",
    "start": "1764840",
    "end": "1772240"
  },
  {
    "text": "mature as well so this is why kind of uh we have some delays on you know migrating this uh approach to the new",
    "start": "1772240",
    "end": "1779760"
  },
  {
    "text": "you know controller uh all Handle by controller approach and then I think lastly we want to Auto optimize the",
    "start": "1779760",
    "end": "1786760"
  },
  {
    "text": "looping crd where we see looping is basically repeatingly execute the same um task multiple times so we actually",
    "start": "1786760",
    "end": "1793880"
  },
  {
    "text": "want to enhance the uh Lum capability to have a uh all the looping task to run in",
    "start": "1793880",
    "end": "1799200"
  },
  {
    "text": "a long running server and just input different prameters different sets uh of inputs um so we actually able to reduce",
    "start": "1799200",
    "end": "1806039"
  },
  {
    "text": "the number of Tas number of resource um that is redundant in the P itself um so",
    "start": "1806039",
    "end": "1811720"
  },
  {
    "text": "with that um it completes um our talk today so here are the links to uh the",
    "start": "1811720",
    "end": "1817360"
  },
  {
    "text": "ton pipeline project Cy ton project for all the optimizations open shift pipeline for all of you want to run you",
    "start": "1817360",
    "end": "1824240"
  },
  {
    "text": "know this project on open shift and feel free to just um come to our slack Channel have you have any questions and",
    "start": "1824240",
    "end": "1831640"
  },
  {
    "text": "you wondering how this open source project is Implement in our product also check out Wason X which is also compos",
    "start": "1831640",
    "end": "1838519"
  },
  {
    "text": "all the open source Technologies in our product itself thank you very",
    "start": "1838519",
    "end": "1844320"
  },
  {
    "text": "much any",
    "start": "1846519",
    "end": "1849799"
  },
  {
    "text": "questions any question in the",
    "start": "1856240",
    "end": "1862840"
  },
  {
    "text": "audience if not I could take it offline as well thank you very",
    "start": "1862840",
    "end": "1868200"
  },
  {
    "text": "much",
    "start": "1870240",
    "end": "1873240"
  }
]
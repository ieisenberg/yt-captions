[
  {
    "text": "good to be here I'm excited to be here",
    "start": "160",
    "end": "3280"
  },
  {
    "text": "I'm Ron andar I'm the CTO and co-founder",
    "start": "3280",
    "end": "7120"
  },
  {
    "text": "of Ron",
    "start": "7120",
    "end": "9040"
  },
  {
    "text": "Ai and I'll be speaking about training",
    "start": "9040",
    "end": "12519"
  },
  {
    "text": "large language models on",
    "start": "12519",
    "end": "15400"
  },
  {
    "text": "kubernetes um and I think one of my",
    "start": "15400",
    "end": "18199"
  },
  {
    "text": "goals in this talk will be to convince",
    "start": "18199",
    "end": "21720"
  },
  {
    "text": "you that",
    "start": "21720",
    "end": "23880"
  },
  {
    "text": "scheduling is a an a critical component",
    "start": "23880",
    "end": "28080"
  },
  {
    "text": "when it comes to operating AI clusters",
    "start": "28080",
    "end": "31599"
  },
  {
    "text": "and we saw quite a few talks on",
    "start": "31599",
    "end": "34440"
  },
  {
    "text": "scheduling today and actually also in",
    "start": "34440",
    "end": "37160"
  },
  {
    "text": "previous Cube con's previous AI days so",
    "start": "37160",
    "end": "40719"
  },
  {
    "text": "I think there are a lot of people who",
    "start": "40719",
    "end": "42440"
  },
  {
    "text": "are already convinced in that um but",
    "start": "42440",
    "end": "46039"
  },
  {
    "text": "I'll I'll try to convince those that are",
    "start": "46039",
    "end": "48399"
  },
  {
    "text": "not convinced um but let's start so um",
    "start": "48399",
    "end": "53440"
  },
  {
    "text": "open AI right a year ago they did this",
    "start": "53440",
    "end": "57760"
  },
  {
    "text": "amazing thing and launched CH GPT to the",
    "start": "57760",
    "end": "63120"
  },
  {
    "text": "entire",
    "start": "63120",
    "end": "64239"
  },
  {
    "text": "world and the amazing powerful",
    "start": "64239",
    "end": "68240"
  },
  {
    "text": "capabilities of language models suddenly",
    "start": "68240",
    "end": "71560"
  },
  {
    "text": "became available to everyone",
    "start": "71560",
    "end": "75119"
  },
  {
    "text": "essentially and that that was amazing",
    "start": "75119",
    "end": "78320"
  },
  {
    "text": "and that created a lot of excitement",
    "start": "78320",
    "end": "80400"
  },
  {
    "text": "today around llms around generative AI",
    "start": "80400",
    "end": "83560"
  },
  {
    "text": "we all feel it right it's a amazing days",
    "start": "83560",
    "end": "86280"
  },
  {
    "text": "to be in the AI space right now so",
    "start": "86280",
    "end": "90759"
  },
  {
    "text": "amazing times and right open AI they",
    "start": "90759",
    "end": "94479"
  },
  {
    "text": "they launched CH GPT and shortly after",
    "start": "94479",
    "end": "97799"
  },
  {
    "text": "they raised $10 billion from Microsoft",
    "start": "97799",
    "end": "102360"
  },
  {
    "text": "$10 billion that's a huge number and in",
    "start": "102360",
    "end": "106079"
  },
  {
    "text": "Microsoft's announcement they spoke",
    "start": "106079",
    "end": "108600"
  },
  {
    "text": "about the goals of the",
    "start": "108600",
    "end": "110840"
  },
  {
    "text": "Investments so three main goals the",
    "start": "110840",
    "end": "114799"
  },
  {
    "text": "first is to build a superc computer for",
    "start": "114799",
    "end": "117159"
  },
  {
    "text": "open AI the second is to use use open AI",
    "start": "117159",
    "end": "121039"
  },
  {
    "text": "models in Microsoft products and then",
    "start": "121039",
    "end": "124719"
  },
  {
    "text": "the third is to be the exclusive cloud",
    "start": "124719",
    "end": "127119"
  },
  {
    "text": "provider for for open",
    "start": "127119",
    "end": "129599"
  },
  {
    "text": "AI right so 10 billion mostly almost",
    "start": "129599",
    "end": "133920"
  },
  {
    "text": "entirely goes to compute just to compute",
    "start": "133920",
    "end": "137800"
  },
  {
    "text": "power that open AI needs to operate to",
    "start": "137800",
    "end": "141120"
  },
  {
    "text": "train models to to deploy models to to",
    "start": "141120",
    "end": "143920"
  },
  {
    "text": "run their operations and since then",
    "start": "143920",
    "end": "146360"
  },
  {
    "text": "right a lot of startups raised billions",
    "start": "146360",
    "end": "148519"
  },
  {
    "text": "of dollars inflection AI um raised $1.3",
    "start": "148519",
    "end": "153599"
  },
  {
    "text": "billion entropic just recently $4",
    "start": "153599",
    "end": "156480"
  },
  {
    "text": "billion from Amazon and2 billion dollar",
    "start": "156480",
    "end": "159560"
  },
  {
    "text": "from Google crazy numbers it all goes",
    "start": "159560",
    "end": "163920"
  },
  {
    "text": "mostly goes to compute",
    "start": "163920",
    "end": "167720"
  },
  {
    "text": "power",
    "start": "167720",
    "end": "170440"
  },
  {
    "text": "and and right we're seeing this trend in",
    "start": "170440",
    "end": "173239"
  },
  {
    "text": "the last 10 years that there there is",
    "start": "173239",
    "end": "175920"
  },
  {
    "text": "explosive demand for compute power in AI",
    "start": "175920",
    "end": "179000"
  },
  {
    "text": "this graphs shows the computing power",
    "start": "179000",
    "end": "183280"
  },
  {
    "text": "that is required to train",
    "start": "183280",
    "end": "184599"
  },
  {
    "text": "state-of-the-art",
    "start": "184599",
    "end": "185920"
  },
  {
    "text": "models versus the time in which the",
    "start": "185920",
    "end": "189480"
  },
  {
    "text": "those models were published so you can",
    "start": "189480",
    "end": "191799"
  },
  {
    "text": "see the blue region right the blue part",
    "start": "191799",
    "end": "196680"
  },
  {
    "text": "and the red part are those the the parts",
    "start": "196680",
    "end": "199680"
  },
  {
    "text": "were in the Deep learning era and the",
    "start": "199680",
    "end": "201519"
  },
  {
    "text": "large language era so you see that since",
    "start": "201519",
    "end": "204440"
  },
  {
    "text": "2012",
    "start": "204440",
    "end": "205920"
  },
  {
    "text": "2013 huge increase in the computational",
    "start": "205920",
    "end": "209480"
  },
  {
    "text": "part our requirements to train",
    "start": "209480",
    "end": "211239"
  },
  {
    "text": "state-ofthe-art models in the last",
    "start": "211239",
    "end": "213680"
  },
  {
    "text": "decade we saw eight orders of magnitude",
    "start": "213680",
    "end": "218159"
  },
  {
    "text": "increase in the computing power eight",
    "start": "218159",
    "end": "221159"
  },
  {
    "text": "orders of magnitude that's 100 million",
    "start": "221159",
    "end": "224720"
  },
  {
    "text": "times increase in computing power to",
    "start": "224720",
    "end": "226959"
  },
  {
    "text": "train state-of-the-art models and with",
    "start": "226959",
    "end": "230040"
  },
  {
    "text": "loud language now right now we seeing",
    "start": "230040",
    "end": "232239"
  },
  {
    "text": "again this big jump the large language",
    "start": "232239",
    "end": "235079"
  },
  {
    "text": "models are those red dots so two orders",
    "start": "235079",
    "end": "238959"
  },
  {
    "text": "of magnitude more computing power to",
    "start": "238959",
    "end": "242159"
  },
  {
    "text": "train llms with respect to training",
    "start": "242159",
    "end": "245200"
  },
  {
    "text": "traditional de planning models right so",
    "start": "245200",
    "end": "247959"
  },
  {
    "text": "a lot of computing power so there is a",
    "start": "247959",
    "end": "250319"
  },
  {
    "text": "big promise for AI and llms but also a",
    "start": "250319",
    "end": "254360"
  },
  {
    "text": "huge problem when it comes to computing",
    "start": "254360",
    "end": "257680"
  },
  {
    "text": "power and what we see right now is",
    "start": "257680",
    "end": "260000"
  },
  {
    "text": "companies struggling with compute for AI",
    "start": "260000",
    "end": "264040"
  },
  {
    "text": "Sam Alman tweeted about that that's like",
    "start": "264040",
    "end": "266040"
  },
  {
    "text": "a famous tweet about the compute cost um",
    "start": "266040",
    "end": "270280"
  },
  {
    "text": "that are they are ey watering compute",
    "start": "270280",
    "end": "273440"
  },
  {
    "text": "cost right Microsoft in W warned",
    "start": "273440",
    "end": "276639"
  },
  {
    "text": "investors in their previous um um",
    "start": "276639",
    "end": "281280"
  },
  {
    "text": "Financial reports that they might not",
    "start": "281280",
    "end": "283400"
  },
  {
    "text": "reach their goals because they won't",
    "start": "283400",
    "end": "286000"
  },
  {
    "text": "have enough chips",
    "start": "286000",
    "end": "288199"
  },
  {
    "text": "enough gpus essentially to get to their",
    "start": "288199",
    "end": "291639"
  },
  {
    "text": "goals so the big companies are",
    "start": "291639",
    "end": "293600"
  },
  {
    "text": "struggling also also smaller companies",
    "start": "293600",
    "end": "295800"
  },
  {
    "text": "right the GPU shortage we saw that in",
    "start": "295800",
    "end": "297600"
  },
  {
    "text": "the last year so companies are",
    "start": "297600",
    "end": "299120"
  },
  {
    "text": "struggling just getting access to",
    "start": "299120",
    "end": "300720"
  },
  {
    "text": "compute sometimes you you'll get into",
    "start": "300720",
    "end": "302880"
  },
  {
    "text": "the your cloud provider and you won't",
    "start": "302880",
    "end": "305280"
  },
  {
    "text": "find a GPU to spin up for days when it",
    "start": "305280",
    "end": "308320"
  },
  {
    "text": "comes to a highend gpus h100 you can",
    "start": "308320",
    "end": "312120"
  },
  {
    "text": "wait for days until it's just getting",
    "start": "312120",
    "end": "314199"
  },
  {
    "text": "access to one one GPU that's crazy so",
    "start": "314199",
    "end": "318199"
  },
  {
    "text": "compute access to compute is is is is is",
    "start": "318199",
    "end": "323160"
  },
  {
    "text": "is a big problem and what we're seeing",
    "start": "323160",
    "end": "325759"
  },
  {
    "text": "right now is a shift in how companies",
    "start": "325759",
    "end": "329080"
  },
  {
    "text": "are consuming Cloud resources so",
    "start": "329080",
    "end": "331880"
  },
  {
    "text": "companies are just securing from",
    "start": "331880",
    "end": "333800"
  },
  {
    "text": "themselves access to gpus to AI",
    "start": "333800",
    "end": "337720"
  },
  {
    "text": "compute and",
    "start": "337720",
    "end": "340440"
  },
  {
    "text": "and there is a shift from on demand",
    "start": "340440",
    "end": "343560"
  },
  {
    "text": "spinning up resources whenever you need",
    "start": "343560",
    "end": "345680"
  },
  {
    "text": "them to just reserving more and more",
    "start": "345680",
    "end": "349120"
  },
  {
    "text": "instances more and more gpus reserving",
    "start": "349120",
    "end": "351400"
  },
  {
    "text": "blocks of gpus and having like a",
    "start": "351400",
    "end": "354000"
  },
  {
    "text": "capacity for your own",
    "start": "354000",
    "end": "357720"
  },
  {
    "text": "use and and when it comes to managing",
    "start": "358319",
    "end": "362479"
  },
  {
    "text": "compute capacity for your AI workloads",
    "start": "362479",
    "end": "365199"
  },
  {
    "text": "and just managing it operating it",
    "start": "365199",
    "end": "367599"
  },
  {
    "text": "providing access to your compute",
    "start": "367599",
    "end": "369120"
  },
  {
    "text": "capacity is key is key to your AI",
    "start": "369120",
    "end": "372160"
  },
  {
    "text": "development to your AI initiatives",
    "start": "372160",
    "end": "373880"
  },
  {
    "text": "because when it's done wrongly what we",
    "start": "373880",
    "end": "375840"
  },
  {
    "text": "see time after time when we're working",
    "start": "375840",
    "end": "377360"
  },
  {
    "text": "with customers is that few things can",
    "start": "377360",
    "end": "380520"
  },
  {
    "text": "happen when it's not being managed",
    "start": "380520",
    "end": "381960"
  },
  {
    "text": "correctly so first of all GPU",
    "start": "381960",
    "end": "383560"
  },
  {
    "text": "utilization I think we heard we all",
    "start": "383560",
    "end": "385919"
  },
  {
    "text": "hearing about it GP utilization can",
    "start": "385919",
    "end": "388759"
  },
  {
    "text": "typically be",
    "start": "388759",
    "end": "390000"
  },
  {
    "text": "much lower than 20% so you have like",
    "start": "390000",
    "end": "393319"
  },
  {
    "text": "very expensive gpus and less than fifth",
    "start": "393319",
    "end": "395720"
  },
  {
    "text": "of it is actually being utilized but",
    "start": "395720",
    "end": "398199"
  },
  {
    "text": "more",
    "start": "398199",
    "end": "399520"
  },
  {
    "text": "importantly even when companies are",
    "start": "399520",
    "end": "401440"
  },
  {
    "text": "securing for the GPU access Time After",
    "start": "401440",
    "end": "404599"
  },
  {
    "text": "Time people are still feeling G the GPU",
    "start": "404599",
    "end": "407440"
  },
  {
    "text": "is a button neck that just getting",
    "start": "407440",
    "end": "409160"
  },
  {
    "text": "access to GPU is still a button neck and",
    "start": "409160",
    "end": "410840"
  },
  {
    "text": "there are long waiting times to get",
    "start": "410840",
    "end": "412520"
  },
  {
    "text": "access to compute and that means that",
    "start": "412520",
    "end": "415400"
  },
  {
    "text": "productivity of teams is is degradates",
    "start": "415400",
    "end": "418039"
  },
  {
    "text": "pool productivity that that means also",
    "start": "418039",
    "end": "420080"
  },
  {
    "text": "that the quality of AI degradates right",
    "start": "420080",
    "end": "422560"
  },
  {
    "text": "so managing and operating compute",
    "start": "422560",
    "end": "424680"
  },
  {
    "text": "capacity and access to compute capacity",
    "start": "424680",
    "end": "426560"
  },
  {
    "text": "is",
    "start": "426560",
    "end": "428759"
  },
  {
    "text": "key",
    "start": "430280",
    "end": "432199"
  },
  {
    "text": "and and what are the solutions that we",
    "start": "432199",
    "end": "434520"
  },
  {
    "text": "see right now on how people our",
    "start": "434520",
    "end": "436479"
  },
  {
    "text": "companies are are managing access to",
    "start": "436479",
    "end": "439280"
  },
  {
    "text": "compute so we see a few Solutions I want",
    "start": "439280",
    "end": "441240"
  },
  {
    "text": "to go over",
    "start": "441240",
    "end": "442639"
  },
  {
    "text": "them quickly because one thing is and",
    "start": "442639",
    "end": "446080"
  },
  {
    "text": "that's like straightforward approach is",
    "start": "446080",
    "end": "448639"
  },
  {
    "text": "just give giving um static allocations",
    "start": "448639",
    "end": "452280"
  },
  {
    "text": "of compute resources to users for",
    "start": "452280",
    "end": "455080"
  },
  {
    "text": "example each user is getting a whole GPU",
    "start": "455080",
    "end": "458680"
  },
  {
    "text": "machine in the cloud right it's all it's",
    "start": "458680",
    "end": "461759"
  },
  {
    "text": "for them use for their use only it's",
    "start": "461759",
    "end": "464639"
  },
  {
    "text": "always available for them right that's",
    "start": "464639",
    "end": "466599"
  },
  {
    "text": "that's the good thing but then what we",
    "start": "466599",
    "end": "468560"
  },
  {
    "text": "see is that static allocations are are",
    "start": "468560",
    "end": "471639"
  },
  {
    "text": "somewhat of a problem because when it",
    "start": "471639",
    "end": "474240"
  },
  {
    "text": "comes to ai ai requires this Dynamic",
    "start": "474240",
    "end": "477440"
  },
  {
    "text": "access to compute",
    "start": "477440",
    "end": "480159"
  },
  {
    "text": "most of the time people need just like",
    "start": "480159",
    "end": "482599"
  },
  {
    "text": "fractions of gpus to run their notebook",
    "start": "482599",
    "end": "485720"
  },
  {
    "text": "to build and debug their code and just",
    "start": "485720",
    "end": "488599"
  },
  {
    "text": "occasionally they need a lot of",
    "start": "488599",
    "end": "489919"
  },
  {
    "text": "computing power to um f tune llms to",
    "start": "489919",
    "end": "494520"
  },
  {
    "text": "just run multiple experiments so we see",
    "start": "494520",
    "end": "496680"
  },
  {
    "text": "this this is like profile usage of our",
    "start": "496680",
    "end": "499080"
  },
  {
    "text": "own users and the the way they access",
    "start": "499080",
    "end": "503039"
  },
  {
    "text": "gpus the round the workloads cost time",
    "start": "503039",
    "end": "506319"
  },
  {
    "text": "and we see for example user",
    "start": "506319",
    "end": "508240"
  },
  {
    "text": "two user to for a few days running a big",
    "start": "508240",
    "end": "513200"
  },
  {
    "text": "workload on 16 gpus right just",
    "start": "513200",
    "end": "515680"
  },
  {
    "text": "fine-tuning a model um on two nodes of",
    "start": "515680",
    "end": "519000"
  },
  {
    "text": "gpus and then idle like almost idle for",
    "start": "519000",
    "end": "523080"
  },
  {
    "text": "weeks and then us a four idle for weeks",
    "start": "523080",
    "end": "526880"
  },
  {
    "text": "and then launching a lot of jobs in",
    "start": "526880",
    "end": "528800"
  },
  {
    "text": "parallel using more than 20 gpus right",
    "start": "528800",
    "end": "531519"
  },
  {
    "text": "for a few days for like 10",
    "start": "531519",
    "end": "534160"
  },
  {
    "text": "days so the the the access to computer",
    "start": "534160",
    "end": "539000"
  },
  {
    "text": "is very is is dynamic and it's B",
    "start": "539000",
    "end": "541279"
  },
  {
    "text": "burstable so when giving static",
    "start": "541279",
    "end": "543560"
  },
  {
    "text": "allocations that's not that's not that",
    "start": "543560",
    "end": "546000"
  },
  {
    "text": "efficient right because either the the",
    "start": "546000",
    "end": "548279"
  },
  {
    "text": "allocation is too high and then you're",
    "start": "548279",
    "end": "551480"
  },
  {
    "text": "getting a lot of gpus idle most of the",
    "start": "551480",
    "end": "553760"
  },
  {
    "text": "time or the or the allocation is too low",
    "start": "553760",
    "end": "557399"
  },
  {
    "text": "and just user are users are being",
    "start": "557399",
    "end": "559360"
  },
  {
    "text": "limited by the quot that is that is was",
    "start": "559360",
    "end": "562279"
  },
  {
    "text": "given to them for example if user two",
    "start": "562279",
    "end": "564399"
  },
  {
    "text": "had gotten just eight gpus right those",
    "start": "564399",
    "end": "567279"
  },
  {
    "text": "workloads could not run",
    "start": "567279",
    "end": "569800"
  },
  {
    "text": "and if us four will get like an",
    "start": "569800",
    "end": "573040"
  },
  {
    "text": "allocation of AG gpus most of those H",
    "start": "573040",
    "end": "575120"
  },
  {
    "text": "gpus will be idle for a long time but",
    "start": "575120",
    "end": "578200"
  },
  {
    "text": "then those workloads wouldn't wouldn't",
    "start": "578200",
    "end": "580600"
  },
  {
    "text": "be able to run or they would run for",
    "start": "580600",
    "end": "582839"
  },
  {
    "text": "longer time right so time to get results",
    "start": "582839",
    "end": "586000"
  },
  {
    "text": "becomes longer with the when when",
    "start": "586000",
    "end": "588240"
  },
  {
    "text": "allocations are are too low so static",
    "start": "588240",
    "end": "591320"
  },
  {
    "text": "allocations is that a problem right fix",
    "start": "591320",
    "end": "593240"
  },
  {
    "text": "quotas and you're getting this idle gpus",
    "start": "593240",
    "end": "596200"
  },
  {
    "text": "people are not getting access to as much",
    "start": "596200",
    "end": "598440"
  },
  {
    "text": "compute they need need whenever they",
    "start": "598440",
    "end": "599920"
  },
  {
    "text": "need it and so there's a need of this",
    "start": "599920",
    "end": "602360"
  },
  {
    "text": "like Dynamic quas right Dynamic quas",
    "start": "602360",
    "end": "606040"
  },
  {
    "text": "that adjust to um to the needs at of",
    "start": "606040",
    "end": "610440"
  },
  {
    "text": "users at every point of time so users",
    "start": "610440",
    "end": "612959"
  },
  {
    "text": "could share their gpus could share their",
    "start": "612959",
    "end": "614839"
  },
  {
    "text": "ID",
    "start": "614839",
    "end": "616720"
  },
  {
    "text": "gpus",
    "start": "616720",
    "end": "619200"
  },
  {
    "text": "and the second Solutions",
    "start": "619200",
    "end": "623000"
  },
  {
    "text": "the that we see is teams trying to share",
    "start": "623000",
    "end": "627040"
  },
  {
    "text": "GPU machines between themselves right in",
    "start": "627040",
    "end": "629200"
  },
  {
    "text": "a manual way with Excel sheets or",
    "start": "629200",
    "end": "632399"
  },
  {
    "text": "through slack Channel just you know",
    "start": "632399",
    "end": "634279"
  },
  {
    "text": "coordinating between themselves and",
    "start": "634279",
    "end": "637200"
  },
  {
    "text": "right doing that is is not fun first of",
    "start": "637200",
    "end": "639399"
  },
  {
    "text": "all doing like manual allocation but",
    "start": "639399",
    "end": "642240"
  },
  {
    "text": "then we also see this problem of that we",
    "start": "642240",
    "end": "645360"
  },
  {
    "text": "we call it GPU hugging so people don't",
    "start": "645360",
    "end": "648399"
  },
  {
    "text": "want to let go their gpus because if",
    "start": "648399",
    "end": "650720"
  },
  {
    "text": "they would then they would need to fight",
    "start": "650720",
    "end": "653760"
  },
  {
    "text": "to get back their gpus because someone",
    "start": "653760",
    "end": "655399"
  },
  {
    "text": "else would take it so we see this absur",
    "start": "655399",
    "end": "659160"
  },
  {
    "text": "situation where people are hugging their",
    "start": "659160",
    "end": "661000"
  },
  {
    "text": "gpus they're not actually using it and",
    "start": "661000",
    "end": "663720"
  },
  {
    "text": "while other people in in the team are",
    "start": "663720",
    "end": "667000"
  },
  {
    "text": "just waiting for their gpus they waiting",
    "start": "667000",
    "end": "668800"
  },
  {
    "text": "to get access to gpus so that's like",
    "start": "668800",
    "end": "670600"
  },
  {
    "text": "that's also not the way to go right",
    "start": "670600",
    "end": "672079"
  },
  {
    "text": "there is a but there is a sense of like",
    "start": "672079",
    "end": "674399"
  },
  {
    "text": "giving a guaranteed quot to users just",
    "start": "674399",
    "end": "677880"
  },
  {
    "text": "giving them guaranteed access to compute",
    "start": "677880",
    "end": "680639"
  },
  {
    "text": "whenever they need",
    "start": "680639",
    "end": "682560"
  },
  {
    "text": "it and last thing that we see is is",
    "start": "682560",
    "end": "685200"
  },
  {
    "text": "trying to share a GPU cluster right a",
    "start": "685200",
    "end": "687959"
  },
  {
    "text": "cluster of GPU used with an orchestrator",
    "start": "687959",
    "end": "690320"
  },
  {
    "text": "with a",
    "start": "690320",
    "end": "691519"
  },
  {
    "text": "Schuler",
    "start": "691519",
    "end": "693720"
  },
  {
    "text": "and and then right we have HPC",
    "start": "693720",
    "end": "696320"
  },
  {
    "text": "schedulers high performance schedule",
    "start": "696320",
    "end": "699000"
  },
  {
    "text": "from the high performance Computing",
    "start": "699000",
    "end": "700720"
  },
  {
    "text": "world that were developed more than 10",
    "start": "700720",
    "end": "703120"
  },
  {
    "text": "years ago like SL right so as we see it",
    "start": "703120",
    "end": "706639"
  },
  {
    "text": "they are really they provide some ofat a",
    "start": "706639",
    "end": "708959"
  },
  {
    "text": "good solution when it comes to running",
    "start": "708959",
    "end": "711480"
  },
  {
    "text": "batch workloads and running training",
    "start": "711480",
    "end": "714600"
  },
  {
    "text": "batch workloads but AI also requires",
    "start": "714600",
    "end": "718360"
  },
  {
    "text": "this inter interactive sessions for",
    "start": "718360",
    "end": "720160"
  },
  {
    "text": "users to use their Jupiter notebooks or",
    "start": "720160",
    "end": "722839"
  },
  {
    "text": "any other IDE tool and and there was",
    "start": "722839",
    "end": "725720"
  },
  {
    "text": "also right a need to deploy models as",
    "start": "725720",
    "end": "727880"
  },
  {
    "text": "Services as",
    "start": "727880",
    "end": "729880"
  },
  {
    "text": "applications and and HPC schedules were",
    "start": "729880",
    "end": "733600"
  },
  {
    "text": "not built to that so when it comes to",
    "start": "733600",
    "end": "735600"
  },
  {
    "text": "interactive and inference they provide",
    "start": "735600",
    "end": "737320"
  },
  {
    "text": "somewhat a limited solution so and HPC",
    "start": "737320",
    "end": "740680"
  },
  {
    "text": "schedules are great for solving part of",
    "start": "740680",
    "end": "743399"
  },
  {
    "text": "the problem as we see",
    "start": "743399",
    "end": "746440"
  },
  {
    "text": "it on the other hand",
    "start": "746880",
    "end": "749519"
  },
  {
    "text": "kubernetes provides a somewhat like a",
    "start": "749519",
    "end": "751800"
  },
  {
    "text": "male",
    "start": "751800",
    "end": "753600"
  },
  {
    "text": "image to that right so kubernetes was",
    "start": "753600",
    "end": "756279"
  },
  {
    "text": "built to run for running micro Services",
    "start": "756279",
    "end": "759560"
  },
  {
    "text": "running applications right so it's a",
    "start": "759560",
    "end": "762160"
  },
  {
    "text": "perfect fit you're getting a lot of",
    "start": "762160",
    "end": "763560"
  },
  {
    "text": "tools like load balancing Auto scaling a",
    "start": "763560",
    "end": "765839"
  },
  {
    "text": "lot of tools that you need when you're",
    "start": "765839",
    "end": "767720"
  },
  {
    "text": "deploying",
    "start": "767720",
    "end": "769399"
  },
  {
    "text": "services and it's also good right for",
    "start": "769399",
    "end": "772040"
  },
  {
    "text": "for running interactive sessions but",
    "start": "772040",
    "end": "774240"
  },
  {
    "text": "when it comes to bed scheduling we all",
    "start": "774240",
    "end": "775880"
  },
  {
    "text": "know it right like we S talks about it",
    "start": "775880",
    "end": "778040"
  },
  {
    "text": "so there are limit ation there are some",
    "start": "778040",
    "end": "780079"
  },
  {
    "text": "gaps when it comes to the default",
    "start": "780079",
    "end": "781560"
  },
  {
    "text": "kubernetes but the good good news is",
    "start": "781560",
    "end": "784120"
  },
  {
    "text": "that Solutions exist Solutions exist",
    "start": "784120",
    "end": "786880"
  },
  {
    "text": "today so people can build um can use and",
    "start": "786880",
    "end": "791000"
  },
  {
    "text": "build a management uh clusters",
    "start": "791000",
    "end": "794440"
  },
  {
    "text": "management AI clusters to with",
    "start": "794440",
    "end": "796760"
  },
  {
    "text": "kubernetes and just solve the whole",
    "start": "796760",
    "end": "798279"
  },
  {
    "text": "problem so solution exists so let's Rec",
    "start": "798279",
    "end": "800480"
  },
  {
    "text": "up for example so what's what's needed",
    "start": "800480",
    "end": "802279"
  },
  {
    "text": "when it comes to AI uh and for with",
    "start": "802279",
    "end": "806600"
  },
  {
    "text": "scheduling uh in specifics so there's a",
    "start": "806600",
    "end": "809440"
  },
  {
    "text": "need to run to schedule interactive",
    "start": "809440",
    "end": "811920"
  },
  {
    "text": "sessions the bch jobs",
    "start": "811920",
    "end": "814160"
  },
  {
    "text": "inference kubernetes can do all of that",
    "start": "814160",
    "end": "816680"
  },
  {
    "text": "right but there are gaps when it comes",
    "start": "816680",
    "end": "818560"
  },
  {
    "text": "to Dynamic quas so with the default",
    "start": "818560",
    "end": "820560"
  },
  {
    "text": "schedu there's static allocations um",
    "start": "820560",
    "end": "824000"
  },
  {
    "text": "there's a need to get like guaranteed",
    "start": "824000",
    "end": "826199"
  },
  {
    "text": "quotas sharing resources in a fair way",
    "start": "826199",
    "end": "830519"
  },
  {
    "text": "with fair share algorithms hierarchial",
    "start": "830519",
    "end": "833759"
  },
  {
    "text": "cues Advanced queuing gang SCH gang",
    "start": "833759",
    "end": "837600"
  },
  {
    "text": "scheduling for distributed",
    "start": "837600",
    "end": "839399"
  },
  {
    "text": "where workloads so all of those there",
    "start": "839399",
    "end": "842360"
  },
  {
    "text": "are gaps in in kubernetes and when it",
    "start": "842360",
    "end": "845480"
  },
  {
    "text": "comes to GPU provisioning same thing",
    "start": "845480",
    "end": "847759"
  },
  {
    "text": "there are",
    "start": "847759",
    "end": "849240"
  },
  {
    "text": "gaps and gpus can be provisioned in in a",
    "start": "849240",
    "end": "853320"
  },
  {
    "text": "dynamic",
    "start": "853320",
    "end": "854440"
  },
  {
    "text": "way in kubernetes but it's the solution",
    "start": "854440",
    "end": "858480"
  },
  {
    "text": "for like for just provisioning fractions",
    "start": "858480",
    "end": "861199"
  },
  {
    "text": "of gpus in kubernetes that's somewhat",
    "start": "861199",
    "end": "863959"
  },
  {
    "text": "limited right and over provisioning gpus",
    "start": "863959",
    "end": "868839"
  },
  {
    "text": "that's also very limited right why not",
    "start": "868839",
    "end": "871720"
  },
  {
    "text": "over provisioning gpus as you over",
    "start": "871720",
    "end": "874199"
  },
  {
    "text": "provision CPUs right but as I say the",
    "start": "874199",
    "end": "878399"
  },
  {
    "text": "good news is that there are solutions",
    "start": "878399",
    "end": "880000"
  },
  {
    "text": "today and the community did this amazing",
    "start": "880000",
    "end": "882399"
  },
  {
    "text": "amazing work and when it comes to",
    "start": "882399",
    "end": "885160"
  },
  {
    "text": "scheduling right those tools volcano",
    "start": "885160",
    "end": "887120"
  },
  {
    "text": "unicorn schedulers that that cover those",
    "start": "887120",
    "end": "890160"
  },
  {
    "text": "gaps h q we heard about that que",
    "start": "890160",
    "end": "893800"
  },
  {
    "text": "together with the schedu framework so",
    "start": "893800",
    "end": "895600"
  },
  {
    "text": "they're providing them um um a way to um",
    "start": "895600",
    "end": "900240"
  },
  {
    "text": "to overcome those",
    "start": "900240",
    "end": "901920"
  },
  {
    "text": "gaps when it comes to GPU provisioning",
    "start": "901920",
    "end": "904600"
  },
  {
    "text": "Advanced GPU provisioning we heard about",
    "start": "904600",
    "end": "907160"
  },
  {
    "text": "the dynamic resource allocation today so",
    "start": "907160",
    "end": "910120"
  },
  {
    "text": "another framework by the community that",
    "start": "910120",
    "end": "912759"
  },
  {
    "text": "can solve those gaps and we troni we're",
    "start": "912759",
    "end": "916040"
  },
  {
    "text": "we're doing that right so we've built",
    "start": "916040",
    "end": "918320"
  },
  {
    "text": "our own scheduler and we're providing",
    "start": "918320",
    "end": "921320"
  },
  {
    "text": "this layer of U of advanced GPU",
    "start": "921320",
    "end": "925120"
  },
  {
    "text": "provisioning with fractional gpus with a",
    "start": "925120",
    "end": "927000"
  },
  {
    "text": "way to over provision GP use inside of",
    "start": "927000",
    "end": "929440"
  },
  {
    "text": "kubernetes so we worked on that in the",
    "start": "929440",
    "end": "931480"
  },
  {
    "text": "last five years we did a lot of work",
    "start": "931480",
    "end": "934079"
  },
  {
    "text": "there and and we essentially we have a",
    "start": "934079",
    "end": "936680"
  },
  {
    "text": "an an Enterprise product right an",
    "start": "936680",
    "end": "938880"
  },
  {
    "text": "Enterprise product built on kubernetes",
    "start": "938880",
    "end": "941519"
  },
  {
    "text": "with providing the GPU schuer um the the",
    "start": "941519",
    "end": "945160"
  },
  {
    "text": "layer for GPU provisioning and all the",
    "start": "945160",
    "end": "948600"
  },
  {
    "text": "tools um that cluster admins and",
    "start": "948600",
    "end": "952480"
  },
  {
    "text": "researchers and data scientists need to",
    "start": "952480",
    "end": "955639"
  },
  {
    "text": "easily train and deploy models on top of",
    "start": "955639",
    "end": "958639"
  },
  {
    "text": "kubernetes with all you know all the",
    "start": "958639",
    "end": "961000"
  },
  {
    "text": "good stuff under the hood the schedule",
    "start": "961000",
    "end": "963079"
  },
  {
    "text": "and everything that is needed um so",
    "start": "963079",
    "end": "965480"
  },
  {
    "text": "that's run AI right an Enterprise",
    "start": "965480",
    "end": "967759"
  },
  {
    "text": "product I won't speak a lot about us but",
    "start": "967759",
    "end": "970720"
  },
  {
    "text": "I will invite you to visit our booth",
    "start": "970720",
    "end": "975199"
  },
  {
    "text": "that's our booth our people are there",
    "start": "975199",
    "end": "978000"
  },
  {
    "text": "and we love Cube con we every Cube con",
    "start": "978000",
    "end": "980800"
  },
  {
    "text": "we're here so uh so please come and",
    "start": "980800",
    "end": "985959"
  },
  {
    "text": "visit",
    "start": "985959",
    "end": "987519"
  },
  {
    "text": "us and in the second in the second part",
    "start": "987519",
    "end": "990880"
  },
  {
    "text": "of this presentation I want to talk",
    "start": "990880",
    "end": "992360"
  },
  {
    "text": "about the community work that we're",
    "start": "992360",
    "end": "994160"
  },
  {
    "text": "doing we're doing we have a few projects",
    "start": "994160",
    "end": "996680"
  },
  {
    "text": "going on I want to speak about one of",
    "start": "996680",
    "end": "998880"
  },
  {
    "text": "them and this project is about just",
    "start": "998880",
    "end": "1003120"
  },
  {
    "text": "making it very easy for the community to",
    "start": "1003120",
    "end": "1006519"
  },
  {
    "text": "train llms train Transformers on",
    "start": "1006519",
    "end": "1010839"
  },
  {
    "text": "kubernetes with all data preparation",
    "start": "1010839",
    "end": "1013319"
  },
  {
    "text": "data preprocessing that is needed so",
    "start": "1013319",
    "end": "1016160"
  },
  {
    "text": "it's a joint work with Nvidia with the",
    "start": "1016160",
    "end": "1019199"
  },
  {
    "text": "the Nemo framework by Nvidia we're",
    "start": "1019199",
    "end": "1021680"
  },
  {
    "text": "working on it together and we're",
    "start": "1021680",
    "end": "1023240"
  },
  {
    "text": "providing in our",
    "start": "1023240",
    "end": "1025480"
  },
  {
    "text": "repository optimized scripts with",
    "start": "1025480",
    "end": "1028839"
  },
  {
    "text": "optimized",
    "start": "1028839",
    "end": "1029880"
  },
  {
    "text": "configurations that people can use to",
    "start": "1029880",
    "end": "1033000"
  },
  {
    "text": "launch training jobs llms on big",
    "start": "1033000",
    "end": "1037280"
  },
  {
    "text": "workloads on M multi node very easily so",
    "start": "1037280",
    "end": "1040558"
  },
  {
    "text": "everything is optimized you just need to",
    "start": "1040559",
    "end": "1042038"
  },
  {
    "text": "run it so that's the goal with the how",
    "start": "1042039",
    "end": "1044319"
  },
  {
    "text": "to gu and everything so we have the our",
    "start": "1044319",
    "end": "1046880"
  },
  {
    "text": "repository all of it is also so under",
    "start": "1046880",
    "end": "1049360"
  },
  {
    "text": "the Nemo framework and their dogs as",
    "start": "1049360",
    "end": "1051640"
  },
  {
    "text": "well so this is a work by our engineer",
    "start": "1051640",
    "end": "1054840"
  },
  {
    "text": "om he's our lead engineer he's amazing",
    "start": "1054840",
    "end": "1057240"
  },
  {
    "text": "he did this all all of this work he was",
    "start": "1057240",
    "end": "1059039"
  },
  {
    "text": "supposed to be here but he he got stuck",
    "start": "1059039",
    "end": "1061360"
  },
  {
    "text": "in in Israel so he couldn't join me but",
    "start": "1061360",
    "end": "1063679"
  },
  {
    "text": "I wanted to give him the the",
    "start": "1063679",
    "end": "1065640"
  },
  {
    "text": "recognition and he did a a good amazing",
    "start": "1065640",
    "end": "1069919"
  },
  {
    "text": "work so we also did this benchmarking",
    "start": "1069919",
    "end": "1072240"
  },
  {
    "text": "walk on training performance on",
    "start": "1072240",
    "end": "1077159"
  },
  {
    "text": "kubernetes and",
    "start": "1077159",
    "end": "1079760"
  },
  {
    "text": "we had a setup with djx GPU machines for",
    "start": "1079760",
    "end": "1084039"
  },
  {
    "text": "GPU machines with a100 with 80 gab of",
    "start": "1084039",
    "end": "1088240"
  },
  {
    "text": "GPU",
    "start": "1088240",
    "end": "1089400"
  },
  {
    "text": "memory overall 32 gpus with infin",
    "start": "1089400",
    "end": "1094039"
  },
  {
    "text": "band and we use this software stack",
    "start": "1094039",
    "end": "1097000"
  },
  {
    "text": "right on top of kubernetes the Nvidia",
    "start": "1097000",
    "end": "1098720"
  },
  {
    "text": "GPU operator the network operator which",
    "start": "1098720",
    "end": "1101720"
  },
  {
    "text": "is the network operator simplifies a lot",
    "start": "1101720",
    "end": "1104159"
  },
  {
    "text": "of the installation and setup that is",
    "start": "1104159",
    "end": "1106919"
  },
  {
    "text": "required to run",
    "start": "1106919",
    "end": "1108919"
  },
  {
    "text": "H distributed training in an optimized",
    "start": "1108919",
    "end": "1111480"
  },
  {
    "text": "way and the cube flow training operator",
    "start": "1111480",
    "end": "1114200"
  },
  {
    "text": "which we use our customers using a great",
    "start": "1114200",
    "end": "1117760"
  },
  {
    "text": "a great tool that we highly",
    "start": "1117760",
    "end": "1121320"
  },
  {
    "text": "recommend and so we did this work and we",
    "start": "1122200",
    "end": "1125679"
  },
  {
    "text": "trained gpt3 with five billions of par",
    "start": "1125679",
    "end": "1129000"
  },
  {
    "text": "five billions",
    "start": "1129000",
    "end": "1130400"
  },
  {
    "text": "parameters and with kubernetes and",
    "start": "1130400",
    "end": "1133679"
  },
  {
    "text": "without kubernetes on bare metal and we",
    "start": "1133679",
    "end": "1137400"
  },
  {
    "text": "measured the f",
    "start": "1137400",
    "end": "1139320"
  },
  {
    "text": "in terms of number of tokens being",
    "start": "1139320",
    "end": "1142760"
  },
  {
    "text": "processed per",
    "start": "1142760",
    "end": "1145360"
  },
  {
    "text": "second on one node two nodes and four",
    "start": "1145360",
    "end": "1148000"
  },
  {
    "text": "nodes and this is the results that we",
    "start": "1148000",
    "end": "1150200"
  },
  {
    "text": "get we got you can see here the",
    "start": "1150200",
    "end": "1152200"
  },
  {
    "text": "difference between the throughput with",
    "start": "1152200",
    "end": "1154919"
  },
  {
    "text": "and without kubernetes right with know",
    "start": "1154919",
    "end": "1157679"
  },
  {
    "text": "the software layers that comes with",
    "start": "1157679",
    "end": "1159240"
  },
  {
    "text": "kubernetes and you see that the overhead",
    "start": "1159240",
    "end": "1162039"
  },
  {
    "text": "has really small less than 2% in this",
    "start": "1162039",
    "end": "1167000"
  },
  {
    "text": "case",
    "start": "1167240",
    "end": "1169200"
  },
  {
    "text": "and you can see here also the",
    "start": "1169200",
    "end": "1171120"
  },
  {
    "text": "scaling um flut versus the number of",
    "start": "1171120",
    "end": "1174240"
  },
  {
    "text": "gpus so with then with kuet is very",
    "start": "1174240",
    "end": "1177320"
  },
  {
    "text": "close to each other and the results are",
    "start": "1177320",
    "end": "1179159"
  },
  {
    "text": "very close to perfect linear scale with",
    "start": "1179159",
    "end": "1182159"
  },
  {
    "text": "the number of",
    "start": "1182159",
    "end": "1184039"
  },
  {
    "text": "gpus we also changed the smaller model",
    "start": "1184039",
    "end": "1187320"
  },
  {
    "text": "and gpt3 with 126 million parameters and",
    "start": "1187320",
    "end": "1192600"
  },
  {
    "text": "again with and without kubernetes with",
    "start": "1192600",
    "end": "1195679"
  },
  {
    "text": "MPI and the results again are the",
    "start": "1195679",
    "end": "1198280"
  },
  {
    "text": "difference is is is very",
    "start": "1198280",
    "end": "1200679"
  },
  {
    "text": "small and in terms of scaling also",
    "start": "1200679",
    "end": "1204159"
  },
  {
    "text": "scaling it's harder to scale smaller",
    "start": "1204159",
    "end": "1207159"
  },
  {
    "text": "models with the number of gpus right so",
    "start": "1207159",
    "end": "1209640"
  },
  {
    "text": "we see here somewhat of a degradation in",
    "start": "1209640",
    "end": "1212039"
  },
  {
    "text": "terms of how close the results are to",
    "start": "1212039",
    "end": "1214360"
  },
  {
    "text": "perfect linear",
    "start": "1214360",
    "end": "1216960"
  },
  {
    "text": "scale um and that's it those are the the",
    "start": "1216960",
    "end": "1221960"
  },
  {
    "text": "you can you can get access to those",
    "start": "1221960",
    "end": "1224600"
  },
  {
    "text": "scripts to those uh to those Frameworks",
    "start": "1224600",
    "end": "1227159"
  },
  {
    "text": "that we did in our repository on end in",
    "start": "1227159",
    "end": "1230559"
  },
  {
    "text": "Nvidia Nemo dos and that's our booth and",
    "start": "1230559",
    "end": "1235159"
  },
  {
    "text": "that's it thank you very",
    "start": "1235159",
    "end": "1237730"
  },
  {
    "text": "[Applause]",
    "start": "1237730",
    "end": "1241600"
  },
  {
    "text": "much thank you so we actually have quite",
    "start": "1241600",
    "end": "1244480"
  },
  {
    "text": "a lot of time for questions so the",
    "start": "1244480",
    "end": "1247120"
  },
  {
    "text": "microphone is in the",
    "start": "1247120",
    "end": "1248840"
  },
  {
    "text": "middle uh get",
    "start": "1248840",
    "end": "1252080"
  },
  {
    "text": "open Bring it",
    "start": "1252080",
    "end": "1255480"
  },
  {
    "text": "on I I can kick things out you had a",
    "start": "1256039",
    "end": "1259080"
  },
  {
    "text": "reference in the on premises and Cloud",
    "start": "1259080",
    "end": "1262200"
  },
  {
    "text": "resources uh in one of your slides I",
    "start": "1262200",
    "end": "1264679"
  },
  {
    "text": "think on a previous one so I have two",
    "start": "1264679",
    "end": "1268400"
  },
  {
    "text": "questions on hey here yeah that one",
    "start": "1268400",
    "end": "1270880"
  },
  {
    "text": "after yeah so I had a couple questions",
    "start": "1270880",
    "end": "1273799"
  },
  {
    "text": "two two questions here one is uh uh how",
    "start": "1273799",
    "end": "1277279"
  },
  {
    "text": "do you solve the challenge of like",
    "start": "1277279",
    "end": "1280240"
  },
  {
    "text": "merging on premises Resources with Cloud",
    "start": "1280240",
    "end": "1282720"
  },
  {
    "text": "resources and do you see a challenge",
    "start": "1282720",
    "end": "1284559"
  },
  {
    "text": "there not only for multicluster on",
    "start": "1284559",
    "end": "1286440"
  },
  {
    "text": "premises but when you start Crossing",
    "start": "1286440",
    "end": "1289080"
  },
  {
    "text": "boundaries like this the second one is",
    "start": "1289080",
    "end": "1291159"
  },
  {
    "text": "you mention ax and um can you talk about",
    "start": "1291159",
    "end": "1295960"
  },
  {
    "text": "uh a little a little bit more about how",
    "start": "1295960",
    "end": "1298200"
  },
  {
    "text": "do you integrate those with kubernetes",
    "start": "1298200",
    "end": "1300000"
  },
  {
    "text": "and any challenges that might be there",
    "start": "1300000",
    "end": "1302159"
  },
  {
    "text": "yeah okay so that's a that's a great",
    "start": "1302159",
    "end": "1304080"
  },
  {
    "text": "question so two great question actually",
    "start": "1304080",
    "end": "1306679"
  },
  {
    "text": "so one is about multicluster right",
    "start": "1306679",
    "end": "1308600"
  },
  {
    "text": "multicluster scheduling essentially so",
    "start": "1308600",
    "end": "1310679"
  },
  {
    "text": "you can have one cluster on premises and",
    "start": "1310679",
    "end": "1313600"
  },
  {
    "text": "another cluster in the cloud",
    "start": "1313600",
    "end": "1317039"
  },
  {
    "text": "and and scheduling a course clusters",
    "start": "1317039",
    "end": "1320120"
  },
  {
    "text": "that could be beneficial right and when",
    "start": "1320120",
    "end": "1323240"
  },
  {
    "text": "resources are are finished in one",
    "start": "1323240",
    "end": "1325440"
  },
  {
    "text": "cluster you want to maybe migrate them",
    "start": "1325440",
    "end": "1327279"
  },
  {
    "text": "to another cluster so doing all of that",
    "start": "1327279",
    "end": "1329120"
  },
  {
    "text": "so we're actually um we're we're",
    "start": "1329120",
    "end": "1332159"
  },
  {
    "text": "providing a control plane on top",
    "start": "1332159",
    "end": "1334720"
  },
  {
    "text": "multicluster control plane right so you",
    "start": "1334720",
    "end": "1336840"
  },
  {
    "text": "can um um orchestrate and View and",
    "start": "1336840",
    "end": "1340159"
  },
  {
    "text": "monitor all your your resources",
    "start": "1340159",
    "end": "1342240"
  },
  {
    "text": "workloads across cluster for a single",
    "start": "1342240",
    "end": "1344240"
  },
  {
    "text": "location and you can set policies and",
    "start": "1344240",
    "end": "1346480"
  },
  {
    "text": "quarters for each cluster",
    "start": "1346480",
    "end": "1348760"
  },
  {
    "text": "um from a single plane in terms of",
    "start": "1348760",
    "end": "1351760"
  },
  {
    "text": "multic claster scheduling that's",
    "start": "1351760",
    "end": "1353360"
  },
  {
    "text": "interesting that's a hard thing to do",
    "start": "1353360",
    "end": "1356080"
  },
  {
    "text": "there are projects like that so Armada",
    "start": "1356080",
    "end": "1359559"
  },
  {
    "text": "by research is an amazing project",
    "start": "1359559",
    "end": "1361520"
  },
  {
    "text": "they're working hard on that that's a",
    "start": "1361520",
    "end": "1363480"
  },
  {
    "text": "great work there",
    "start": "1363480",
    "end": "1365480"
  },
  {
    "text": "and yeah I would love to see like how",
    "start": "1365480",
    "end": "1367760"
  },
  {
    "text": "this this topic is is being moving",
    "start": "1367760",
    "end": "1369919"
  },
  {
    "text": "forward by the community for sure um and",
    "start": "1369919",
    "end": "1373440"
  },
  {
    "text": "you spoke also about what what was the",
    "start": "1373440",
    "end": "1375320"
  },
  {
    "text": "question second",
    "start": "1375320",
    "end": "1376720"
  },
  {
    "text": "question the",
    "start": "1376720",
    "end": "1378760"
  },
  {
    "text": "I guess especially for for yeah yeah for",
    "start": "1378760",
    "end": "1381080"
  },
  {
    "text": "especially for inference and how you",
    "start": "1381080",
    "end": "1382600"
  },
  {
    "text": "manage that yeah so that's that's a",
    "start": "1382600",
    "end": "1384360"
  },
  {
    "text": "great question right so in",
    "start": "1384360",
    "end": "1387720"
  },
  {
    "text": "um of course most of our customers are",
    "start": "1387720",
    "end": "1390279"
  },
  {
    "text": "using Nvidia gpus right like most of the",
    "start": "1390279",
    "end": "1393240"
  },
  {
    "text": "world is using inidia gpus",
    "start": "1393240",
    "end": "1397600"
  },
  {
    "text": "and and in terms of as6 and integrating",
    "start": "1397919",
    "end": "1403279"
  },
  {
    "text": "A6 into kubernetes and scheduling",
    "start": "1403279",
    "end": "1405279"
  },
  {
    "text": "workloads on top of A6 so that's an an",
    "start": "1405279",
    "end": "1407600"
  },
  {
    "text": "interesting topic we we're working on",
    "start": "1407600",
    "end": "1409880"
  },
  {
    "text": "those things so we we're working and of",
    "start": "1409880",
    "end": "1412120"
  },
  {
    "text": "course AMD are there tpus are there and",
    "start": "1412120",
    "end": "1415000"
  },
  {
    "text": "more right and more A6 are there I think",
    "start": "1415000",
    "end": "1418440"
  },
  {
    "text": "we'll see more and more from them in the",
    "start": "1418440",
    "end": "1421039"
  },
  {
    "text": "future",
    "start": "1421039",
    "end": "1422799"
  },
  {
    "text": "and I think that today it's it's",
    "start": "1422799",
    "end": "1427120"
  },
  {
    "text": "relatively easy to integrate ASC into a",
    "start": "1427120",
    "end": "1431919"
  },
  {
    "text": "kubernetes um cluster and schedule",
    "start": "1431919",
    "end": "1434760"
  },
  {
    "text": "workloads on that on those as6 maybe it",
    "start": "1434760",
    "end": "1438039"
  },
  {
    "text": "we you know there are challenges around",
    "start": "1438039",
    "end": "1439919"
  },
  {
    "text": "monitoring you know providing like",
    "start": "1439919",
    "end": "1441840"
  },
  {
    "text": "metrics in a simple way but also those",
    "start": "1441840",
    "end": "1444600"
  },
  {
    "text": "those are like not big issues so from",
    "start": "1444600",
    "end": "1447919"
  },
  {
    "text": "what we see is is something that is",
    "start": "1447919",
    "end": "1449760"
  },
  {
    "text": "doable in in a relatively short time I",
    "start": "1449760",
    "end": "1452520"
  },
  {
    "text": "think things like fractionalizing as6",
    "start": "1452520",
    "end": "1455200"
  },
  {
    "text": "like you can fractionalize gpus that's",
    "start": "1455200",
    "end": "1456919"
  },
  {
    "text": "harder that's more difficult but in",
    "start": "1456919",
    "end": "1459720"
  },
  {
    "text": "terms of scheduling workloads on on as6",
    "start": "1459720",
    "end": "1462200"
  },
  {
    "text": "I think it's in kubernetes right now",
    "start": "1462200",
    "end": "1464640"
  },
  {
    "text": "it's in a good",
    "start": "1464640",
    "end": "1466799"
  },
  {
    "text": "state",
    "start": "1466799",
    "end": "1469399"
  },
  {
    "text": "right I I don't see",
    "start": "1469399",
    "end": "1471480"
  },
  {
    "text": "any okay I don't see any additional",
    "start": "1471480",
    "end": "1473919"
  },
  {
    "text": "question so thanks again for a great",
    "start": "1473919",
    "end": "1476480"
  },
  {
    "text": "talkk ah there's one yeah",
    "start": "1476480",
    "end": "1480279"
  },
  {
    "text": "save I'm sorry if I came in a little bit",
    "start": "1480279",
    "end": "1482440"
  },
  {
    "text": "late but you mentioned fractionalizing",
    "start": "1482440",
    "end": "1484360"
  },
  {
    "text": "gpus MH do you do anything beyond MPS or",
    "start": "1484360",
    "end": "1487760"
  },
  {
    "text": "Mig or those things that come with the",
    "start": "1487760",
    "end": "1489919"
  },
  {
    "text": "operators that Nvidia",
    "start": "1489919",
    "end": "1493080"
  },
  {
    "text": "provides so do I think with migs or can",
    "start": "1493080",
    "end": "1496279"
  },
  {
    "text": "you repeat that question I didn't yeah",
    "start": "1496279",
    "end": "1497840"
  },
  {
    "text": "yeah so I'm assuming fractionalizing a",
    "start": "1497840",
    "end": "1499720"
  },
  {
    "text": "GPU means that you carve it into little",
    "start": "1499720",
    "end": "1501960"
  },
  {
    "text": "pieces right which Nvidia does right",
    "start": "1501960",
    "end": "1504320"
  },
  {
    "text": "with Mig right or MPS right are you",
    "start": "1504320",
    "end": "1508000"
  },
  {
    "text": "doing anything else or you're kind of",
    "start": "1508000",
    "end": "1509799"
  },
  {
    "text": "orchestrating those things so okay so",
    "start": "1509799",
    "end": "1512960"
  },
  {
    "text": "that's okay so we're doing a few things",
    "start": "1512960",
    "end": "1514559"
  },
  {
    "text": "so as he said there are a few ways to",
    "start": "1514559",
    "end": "1516960"
  },
  {
    "text": "fractionalize gpus and one way is with",
    "start": "1516960",
    "end": "1520399"
  },
  {
    "text": "Mig and that's a more um that will",
    "start": "1520399",
    "end": "1523919"
  },
  {
    "text": "provide you a hardware isolation right",
    "start": "1523919",
    "end": "1526440"
  },
  {
    "text": "you'll get um Hardware isolated slices",
    "start": "1526440",
    "end": "1529840"
  },
  {
    "text": "of the GPU with Mig and that's",
    "start": "1529840",
    "end": "1534240"
  },
  {
    "text": "great and that might be less flexible",
    "start": "1534240",
    "end": "1538720"
  },
  {
    "text": "right with Hardware when you do things",
    "start": "1538720",
    "end": "1540360"
  },
  {
    "text": "with Hardware it's less flexible when",
    "start": "1540360",
    "end": "1541880"
  },
  {
    "text": "you're doing things with software and",
    "start": "1541880",
    "end": "1545440"
  },
  {
    "text": "there are also approaches of slicing",
    "start": "1545440",
    "end": "1547960"
  },
  {
    "text": "gpus with just software only right so",
    "start": "1547960",
    "end": "1550320"
  },
  {
    "text": "MPS is one of them",
    "start": "1550320",
    "end": "1553159"
  },
  {
    "text": "and what we're doing we're doing some",
    "start": "1553159",
    "end": "1556320"
  },
  {
    "text": "we're doing we're with doing a few",
    "start": "1556320",
    "end": "1558200"
  },
  {
    "text": "things so first of all the",
    "start": "1558200",
    "end": "1560240"
  },
  {
    "text": "fractionalizing gpus is a problem that",
    "start": "1560240",
    "end": "1562600"
  },
  {
    "text": "needs to be solved at the kubernetes",
    "start": "1562600",
    "end": "1564360"
  },
  {
    "text": "cluster scheduling layer right so just",
    "start": "1564360",
    "end": "1566840"
  },
  {
    "text": "scheduling workloads on fractions of",
    "start": "1566840",
    "end": "1569159"
  },
  {
    "text": "gpus that's something that that the",
    "start": "1569159",
    "end": "1571279"
  },
  {
    "text": "default kubernetes doesn't support out",
    "start": "1571279",
    "end": "1573159"
  },
  {
    "text": "of the box so that's something that",
    "start": "1573159",
    "end": "1574760"
  },
  {
    "text": "needs to be solved that's one thing and",
    "start": "1574760",
    "end": "1576840"
  },
  {
    "text": "then the second thing that we do and I",
    "start": "1576840",
    "end": "1578960"
  },
  {
    "text": "think is unique for us we're sitting at",
    "start": "1578960",
    "end": "1580360"
  },
  {
    "text": "the Cuda layer and and we're",
    "start": "1580360",
    "end": "1582880"
  },
  {
    "text": "intercepting Cuda calls and we manage",
    "start": "1582880",
    "end": "1585679"
  },
  {
    "text": "the access to the GPU",
    "start": "1585679",
    "end": "1588120"
  },
  {
    "text": "and we allow multiple workloads to share",
    "start": "1588120",
    "end": "1590919"
  },
  {
    "text": "that GPU in a controlled way right so",
    "start": "1590919",
    "end": "1594200"
  },
  {
    "text": "with software you can be much more",
    "start": "1594200",
    "end": "1596240"
  },
  {
    "text": "flexible in terms of how those workloads",
    "start": "1596240",
    "end": "1598840"
  },
  {
    "text": "are accessing the GPU because for",
    "start": "1598840",
    "end": "1601159"
  },
  {
    "text": "example if you're running two workloads",
    "start": "1601159",
    "end": "1602679"
  },
  {
    "text": "on a GPU with when it runs with Mig then",
    "start": "1602679",
    "end": "1606440"
  },
  {
    "text": "you those two workloads at every point",
    "start": "1606440",
    "end": "1608480"
  },
  {
    "text": "of time they're getting just the Mig",
    "start": "1608480",
    "end": "1610520"
  },
  {
    "text": "slices that were provision to them but",
    "start": "1610520",
    "end": "1614279"
  },
  {
    "text": "when you're running with software so you",
    "start": "1614279",
    "end": "1616760"
  },
  {
    "text": "can essentially give the entire GPU to",
    "start": "1616760",
    "end": "1619799"
  },
  {
    "text": "one of the one of the workloads if the",
    "start": "1619799",
    "end": "1622919"
  },
  {
    "text": "other workload is is Idle right so that",
    "start": "1622919",
    "end": "1625760"
  },
  {
    "text": "flexibility you can give just with",
    "start": "1625760",
    "end": "1627399"
  },
  {
    "text": "software so that's one of the advantages",
    "start": "1627399",
    "end": "1629200"
  },
  {
    "text": "of using software to",
    "start": "1629200",
    "end": "1632120"
  },
  {
    "text": "fractionalize fractionalizing gpus then",
    "start": "1632120",
    "end": "1634480"
  },
  {
    "text": "of course it's you know they're coming",
    "start": "1634480",
    "end": "1636120"
  },
  {
    "text": "there are questions of what happens when",
    "start": "1636120",
    "end": "1637960"
  },
  {
    "text": "the workloads are colliding right so how",
    "start": "1637960",
    "end": "1639880"
  },
  {
    "text": "do you control that so we're sitting at",
    "start": "1639880",
    "end": "1641960"
  },
  {
    "text": "the Cuda level to control what happens",
    "start": "1641960",
    "end": "1644320"
  },
  {
    "text": "when workloads are are colliding so how",
    "start": "1644320",
    "end": "1646760"
  },
  {
    "text": "you know",
    "start": "1646760",
    "end": "1648840"
  },
  {
    "text": "aling in a in a in a in a controlled",
    "start": "1648840",
    "end": "1653720"
  },
  {
    "text": "way awesome then let's thank Ronan again",
    "start": "1653960",
    "end": "1657520"
  },
  {
    "text": "and switch to the next talk thanks thank",
    "start": "1657520",
    "end": "1660000"
  },
  {
    "text": "you",
    "start": "1660000",
    "end": "1661480"
  },
  {
    "text": "again",
    "start": "1661480",
    "end": "1664480"
  }
]
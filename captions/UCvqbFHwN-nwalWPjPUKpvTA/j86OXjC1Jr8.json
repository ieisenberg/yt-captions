[
  {
    "start": "0",
    "end": "40000"
  },
  {
    "text": "hello and welcome to the rook intro",
    "start": "80",
    "end": "3120"
  },
  {
    "text": "and ceph deep dive today i'll be",
    "start": "3120",
    "end": "7279"
  },
  {
    "text": "joined by my colleague satoru also",
    "start": "7279",
    "end": "10000"
  },
  {
    "text": "travis and sebastian who will help out",
    "start": "10000",
    "end": "11840"
  },
  {
    "text": "with the q a section",
    "start": "11840",
    "end": "13920"
  },
  {
    "text": "before we get started i do also want to",
    "start": "13920",
    "end": "16080"
  },
  {
    "text": "mention travis gave",
    "start": "16080",
    "end": "17840"
  },
  {
    "text": "a lightning talk a little earlier in",
    "start": "17840",
    "end": "20560"
  },
  {
    "text": "this cubecon",
    "start": "20560",
    "end": "21760"
  },
  {
    "text": "please take a look and watch that if you",
    "start": "21760",
    "end": "24880"
  },
  {
    "text": "want just a",
    "start": "24880",
    "end": "26320"
  },
  {
    "text": "quick broad introduction to rook",
    "start": "26320",
    "end": "29359"
  },
  {
    "text": "but for now let's uh let's start with",
    "start": "29359",
    "end": "32960"
  },
  {
    "text": "some of kubernetes storage challenges",
    "start": "32960",
    "end": "35360"
  },
  {
    "text": "this is where i like to start when",
    "start": "35360",
    "end": "37440"
  },
  {
    "text": "talking about uh when talking about rook",
    "start": "37440",
    "end": "42239"
  },
  {
    "start": "40000",
    "end": "40000"
  },
  {
    "text": "kubernetes is a platform used to manage",
    "start": "42559",
    "end": "45280"
  },
  {
    "text": "distributed applications",
    "start": "45280",
    "end": "47360"
  },
  {
    "text": "and in the ideal these applications are",
    "start": "47360",
    "end": "50239"
  },
  {
    "text": "stateless",
    "start": "50239",
    "end": "51440"
  },
  {
    "text": "but this isn't always the case this",
    "start": "51440",
    "end": "53920"
  },
  {
    "text": "isn't something that can be always",
    "start": "53920",
    "end": "55520"
  },
  {
    "text": "achieved",
    "start": "55520",
    "end": "56640"
  },
  {
    "text": "there is very often some reliance on",
    "start": "56640",
    "end": "60000"
  },
  {
    "text": "external storage this external storage",
    "start": "60000",
    "end": "64000"
  },
  {
    "text": "is non-portable it can be",
    "start": "64000",
    "end": "67040"
  },
  {
    "text": "a deployment burden and",
    "start": "67040",
    "end": "71040"
  },
  {
    "text": "it also needs someone to manage the",
    "start": "71040",
    "end": "72799"
  },
  {
    "text": "storage especially for",
    "start": "72799",
    "end": "74240"
  },
  {
    "text": "day two operations which composes 99.9",
    "start": "74240",
    "end": "78400"
  },
  {
    "text": "percent of",
    "start": "78400",
    "end": "79520"
  },
  {
    "text": "uh the the bulk of what storage is",
    "start": "79520",
    "end": "83520"
  },
  {
    "text": "there also may be a cases where",
    "start": "83520",
    "end": "87040"
  },
  {
    "text": "you have storage available but you are",
    "start": "87040",
    "end": "89200"
  },
  {
    "text": "sort of vendor locked into your cloud",
    "start": "89200",
    "end": "91600"
  },
  {
    "text": "provider or",
    "start": "91600",
    "end": "93600"
  },
  {
    "text": "to something else you have set up in",
    "start": "93600",
    "end": "95680"
  },
  {
    "text": "your organization",
    "start": "95680",
    "end": "98320"
  },
  {
    "text": "and rook aims to overcome these",
    "start": "98320",
    "end": "101680"
  },
  {
    "text": "challenges",
    "start": "101680",
    "end": "102960"
  },
  {
    "text": "so what is rook in a little more of a",
    "start": "102960",
    "end": "105600"
  },
  {
    "start": "105000",
    "end": "105000"
  },
  {
    "text": "deep level",
    "start": "105600",
    "end": "106960"
  },
  {
    "text": "rook makes storage available inside your",
    "start": "106960",
    "end": "109280"
  },
  {
    "text": "kubernetes cluster",
    "start": "109280",
    "end": "110960"
  },
  {
    "text": "and rook supports multiple different",
    "start": "110960",
    "end": "114079"
  },
  {
    "text": "backends each is a different kubernetes",
    "start": "114079",
    "end": "116479"
  },
  {
    "text": "operator",
    "start": "116479",
    "end": "117200"
  },
  {
    "text": "and has its own custom resource",
    "start": "117200",
    "end": "119200"
  },
  {
    "text": "definitions for users to create storage",
    "start": "119200",
    "end": "121600"
  },
  {
    "text": "from it",
    "start": "121600",
    "end": "124000"
  },
  {
    "text": "rook provides automated management for",
    "start": "124000",
    "end": "127439"
  },
  {
    "text": "any of these storage operators this",
    "start": "127439",
    "end": "130479"
  },
  {
    "text": "includes deployment configuration as",
    "start": "130479",
    "end": "132560"
  },
  {
    "text": "well as updates",
    "start": "132560",
    "end": "134720"
  },
  {
    "text": "and once the storage has been set up it",
    "start": "134720",
    "end": "137440"
  },
  {
    "text": "can be consumed like any other",
    "start": "137440",
    "end": "139040"
  },
  {
    "text": "kubernetes storage",
    "start": "139040",
    "end": "141040"
  },
  {
    "text": "with storage classes and persistent",
    "start": "141040",
    "end": "143280"
  },
  {
    "text": "volume claims for applications",
    "start": "143280",
    "end": "145760"
  },
  {
    "text": "rook is also fully open source using the",
    "start": "145760",
    "end": "148480"
  },
  {
    "text": "apache 2.0 license",
    "start": "148480",
    "end": "152239"
  },
  {
    "start": "151000",
    "end": "151000"
  },
  {
    "text": "the storage providers i mentioned before",
    "start": "153040",
    "end": "155360"
  },
  {
    "text": "ceph is",
    "start": "155360",
    "end": "156080"
  },
  {
    "text": "the most stable but we also have",
    "start": "156080",
    "end": "158560"
  },
  {
    "text": "cassandra",
    "start": "158560",
    "end": "159760"
  },
  {
    "text": "network file system and yucabyte db",
    "start": "159760",
    "end": "162959"
  },
  {
    "text": "available also",
    "start": "162959",
    "end": "166080"
  },
  {
    "text": "some quick stats that we like to",
    "start": "166319",
    "end": "169519"
  },
  {
    "text": "highlight",
    "start": "169519",
    "end": "170000"
  },
  {
    "text": "for rook uh we're a cncf graduated",
    "start": "170000",
    "end": "173280"
  },
  {
    "text": "project",
    "start": "173280",
    "end": "174000"
  },
  {
    "text": "we have just released our version 1.6 of",
    "start": "174000",
    "end": "176959"
  },
  {
    "text": "rook which we're very excited about",
    "start": "176959",
    "end": "179040"
  },
  {
    "text": "and we've recently hit 215 million",
    "start": "179040",
    "end": "182319"
  },
  {
    "text": "downloads",
    "start": "182319",
    "end": "183440"
  },
  {
    "text": "of the rook application",
    "start": "183440",
    "end": "186720"
  },
  {
    "text": "and as promised i i'm getting into a cef",
    "start": "188000",
    "end": "191519"
  },
  {
    "text": "deep dive here with rook",
    "start": "191519",
    "end": "193920"
  },
  {
    "text": "so let's hop into that starting with",
    "start": "193920",
    "end": "196800"
  },
  {
    "start": "195000",
    "end": "195000"
  },
  {
    "text": "what is",
    "start": "196800",
    "end": "197599"
  },
  {
    "text": "what is seth um stuff is also open",
    "start": "197599",
    "end": "200640"
  },
  {
    "text": "source",
    "start": "200640",
    "end": "201440"
  },
  {
    "text": "and it is a tried and true distributed",
    "start": "201440",
    "end": "205280"
  },
  {
    "text": "software defined storage solution",
    "start": "205280",
    "end": "208720"
  },
  {
    "text": "ceph is pushing 10 years old at this",
    "start": "208720",
    "end": "212480"
  },
  {
    "text": "point",
    "start": "212480",
    "end": "212879"
  },
  {
    "text": "and provides block shared file system as",
    "start": "212879",
    "end": "216239"
  },
  {
    "text": "well as",
    "start": "216239",
    "end": "216959"
  },
  {
    "text": "s3 compliant object storage all in one",
    "start": "216959",
    "end": "220319"
  },
  {
    "text": "package",
    "start": "220319",
    "end": "220879"
  },
  {
    "text": "it's been enterprise tested and it has a",
    "start": "220879",
    "end": "223920"
  },
  {
    "text": "lot of",
    "start": "223920",
    "end": "224879"
  },
  {
    "text": "performance features as well if you'd",
    "start": "224879",
    "end": "227360"
  },
  {
    "text": "like more information on ceph",
    "start": "227360",
    "end": "229280"
  },
  {
    "text": "you can look at the link below",
    "start": "229280",
    "end": "232879"
  },
  {
    "start": "232000",
    "end": "232000"
  },
  {
    "text": "let's talk about the architectural",
    "start": "233599",
    "end": "235120"
  },
  {
    "text": "layers of rook with seth",
    "start": "235120",
    "end": "238000"
  },
  {
    "text": "starting with the rook operator itself",
    "start": "238000",
    "end": "240640"
  },
  {
    "text": "which",
    "start": "240640",
    "end": "241040"
  },
  {
    "text": "owns the management of ceph there's also",
    "start": "241040",
    "end": "244400"
  },
  {
    "text": "ceph csi",
    "start": "244400",
    "end": "245519"
  },
  {
    "text": "which is the csi driver that dynamically",
    "start": "245519",
    "end": "248239"
  },
  {
    "text": "provisions",
    "start": "248239",
    "end": "248959"
  },
  {
    "text": "and then mounts storage to use user",
    "start": "248959",
    "end": "251360"
  },
  {
    "text": "applications",
    "start": "251360",
    "end": "253120"
  },
  {
    "text": "ceph itself is the data layer which rook",
    "start": "253120",
    "end": "256239"
  },
  {
    "text": "encapsulates and manages",
    "start": "256239",
    "end": "259600"
  },
  {
    "start": "259000",
    "end": "259000"
  },
  {
    "text": "this first layer rook management is",
    "start": "260079",
    "end": "263280"
  },
  {
    "text": "shown by the blue boxes it is primarily",
    "start": "263280",
    "end": "266320"
  },
  {
    "text": "the rook",
    "start": "266320",
    "end": "266880"
  },
  {
    "text": "operator in the middle top and also",
    "start": "266880",
    "end": "270080"
  },
  {
    "text": "consists of",
    "start": "270080",
    "end": "271440"
  },
  {
    "text": "some additional daemons depending on the",
    "start": "271440",
    "end": "273199"
  },
  {
    "text": "configuration",
    "start": "273199",
    "end": "275759"
  },
  {
    "text": "something i can also note here about",
    "start": "275759",
    "end": "278080"
  },
  {
    "text": "ceph is that these ceph osds that you",
    "start": "278080",
    "end": "280400"
  },
  {
    "text": "see several of",
    "start": "280400",
    "end": "282400"
  },
  {
    "text": "those are object storage daemons",
    "start": "282400",
    "end": "285440"
  },
  {
    "text": "and they connect to underlying storage",
    "start": "285440",
    "end": "288560"
  },
  {
    "text": "and then with ceph they aggregate that",
    "start": "288560",
    "end": "293040"
  },
  {
    "text": "pool it together in a software defined",
    "start": "293040",
    "end": "295600"
  },
  {
    "text": "cluster",
    "start": "295600",
    "end": "296320"
  },
  {
    "text": "and then expose that to the user",
    "start": "296320",
    "end": "300080"
  },
  {
    "start": "300000",
    "end": "300000"
  },
  {
    "text": "at layer 2 we have the csi provisioning",
    "start": "300720",
    "end": "303440"
  },
  {
    "text": "of rook",
    "start": "303440",
    "end": "304080"
  },
  {
    "text": "this is where user application requests",
    "start": "304080",
    "end": "306720"
  },
  {
    "text": "block",
    "start": "306720",
    "end": "307199"
  },
  {
    "text": "or file and",
    "start": "307199",
    "end": "310960"
  },
  {
    "text": "then those are provisioned based on a",
    "start": "310960",
    "end": "312880"
  },
  {
    "text": "storage class",
    "start": "312880",
    "end": "314320"
  },
  {
    "text": "and presented to the user generally",
    "start": "314320",
    "end": "316800"
  },
  {
    "text": "block is",
    "start": "316800",
    "end": "317600"
  },
  {
    "text": "a read write once volume for only a",
    "start": "317600",
    "end": "320720"
  },
  {
    "text": "single application",
    "start": "320720",
    "end": "322320"
  },
  {
    "text": "and file system can be read write once",
    "start": "322320",
    "end": "324479"
  },
  {
    "text": "or read write many",
    "start": "324479",
    "end": "326720"
  },
  {
    "text": "there's also a similar system in rook",
    "start": "326720",
    "end": "329280"
  },
  {
    "text": "setup for object storage",
    "start": "329280",
    "end": "330960"
  },
  {
    "text": "where a storage class exists and the",
    "start": "330960",
    "end": "333680"
  },
  {
    "text": "user can make a bucket claim",
    "start": "333680",
    "end": "335440"
  },
  {
    "text": "for that object storage and rook then",
    "start": "335440",
    "end": "338800"
  },
  {
    "text": "implements a bucket provisioner",
    "start": "338800",
    "end": "341039"
  },
  {
    "text": "to create the bucket for the user while",
    "start": "341039",
    "end": "344160"
  },
  {
    "start": "343000",
    "end": "343000"
  },
  {
    "text": "i'm already talking about buckets",
    "start": "344160",
    "end": "347360"
  },
  {
    "text": "in purple if the user requests object",
    "start": "347360",
    "end": "350320"
  },
  {
    "text": "storage",
    "start": "350320",
    "end": "351440"
  },
  {
    "text": "they can then get information about the",
    "start": "351440",
    "end": "354000"
  },
  {
    "text": "storage rook has created",
    "start": "354000",
    "end": "355520"
  },
  {
    "text": "via a kubernetes secret and then connect",
    "start": "355520",
    "end": "359680"
  },
  {
    "text": "via s3 protocol using those connection",
    "start": "359680",
    "end": "362560"
  },
  {
    "text": "details they're provided in the secret",
    "start": "362560",
    "end": "365360"
  },
  {
    "text": "and you can see that in purple for",
    "start": "365360",
    "end": "369120"
  },
  {
    "text": "block and file storage the",
    "start": "369120",
    "end": "372479"
  },
  {
    "text": "user application is directly given",
    "start": "372479",
    "end": "374960"
  },
  {
    "text": "access",
    "start": "374960",
    "end": "375680"
  },
  {
    "text": "to via a kernel driver to the cef",
    "start": "375680",
    "end": "379120"
  },
  {
    "text": "cluster underneath",
    "start": "379120",
    "end": "380160"
  },
  {
    "text": "so rook does not sit anywhere in the",
    "start": "380160",
    "end": "382400"
  },
  {
    "text": "data path",
    "start": "382400",
    "end": "383360"
  },
  {
    "text": "it is straight from the application to",
    "start": "383360",
    "end": "386240"
  },
  {
    "text": "ceph",
    "start": "386240",
    "end": "388560"
  },
  {
    "text": "i'd like to highlight some of the key",
    "start": "389520",
    "end": "391680"
  },
  {
    "text": "features of rook now that i've talked",
    "start": "391680",
    "end": "393600"
  },
  {
    "text": "about the architecture",
    "start": "393600",
    "end": "396400"
  },
  {
    "start": "395000",
    "end": "395000"
  },
  {
    "text": "first of all simplicity rook is really",
    "start": "396400",
    "end": "399440"
  },
  {
    "text": "focused on simplicity",
    "start": "399440",
    "end": "401759"
  },
  {
    "text": "starting with installation which really",
    "start": "401759",
    "end": "404720"
  },
  {
    "text": "is",
    "start": "404720",
    "end": "405120"
  },
  {
    "text": "installing some common components",
    "start": "405120",
    "end": "406960"
  },
  {
    "text": "including our custom resource",
    "start": "406960",
    "end": "408560"
  },
  {
    "text": "definitions",
    "start": "408560",
    "end": "410080"
  },
  {
    "text": "followed by the permissions",
    "start": "410080",
    "end": "413199"
  },
  {
    "text": "that rook needs to operate following",
    "start": "413199",
    "end": "416080"
  },
  {
    "text": "that",
    "start": "416080",
    "end": "416560"
  },
  {
    "text": "the user can generally just directly",
    "start": "416560",
    "end": "419599"
  },
  {
    "text": "install the",
    "start": "419599",
    "end": "420479"
  },
  {
    "text": "ceph operator though there is",
    "start": "420479",
    "end": "422560"
  },
  {
    "text": "configuration if they want",
    "start": "422560",
    "end": "424479"
  },
  {
    "text": "and following that just configure the",
    "start": "424479",
    "end": "428000"
  },
  {
    "text": "ceph cluster resource as desired and",
    "start": "428000",
    "end": "430400"
  },
  {
    "text": "then deploy that",
    "start": "430400",
    "end": "432240"
  },
  {
    "text": "there is an example of a very minimal",
    "start": "432240",
    "end": "435520"
  },
  {
    "text": "self-cluster resource off to the right",
    "start": "435520",
    "end": "437360"
  },
  {
    "text": "so it really can be",
    "start": "437360",
    "end": "439599"
  },
  {
    "text": "quite simply expressed",
    "start": "439599",
    "end": "442639"
  },
  {
    "text": "we also want to focus on as many",
    "start": "442639",
    "end": "445120"
  },
  {
    "start": "443000",
    "end": "443000"
  },
  {
    "text": "environments as possible in rook",
    "start": "445120",
    "end": "447599"
  },
  {
    "text": "it's pretty natural to think of bare",
    "start": "447599",
    "end": "450080"
  },
  {
    "text": "metal where you can bring your own",
    "start": "450080",
    "end": "451360"
  },
  {
    "text": "hardware or use",
    "start": "451360",
    "end": "452400"
  },
  {
    "text": "shared hardware and provide storage to",
    "start": "452400",
    "end": "456080"
  },
  {
    "text": "your ceph cluster",
    "start": "456080",
    "end": "458080"
  },
  {
    "text": "rook also operates and is focused on",
    "start": "458080",
    "end": "460560"
  },
  {
    "text": "cloud providers",
    "start": "460560",
    "end": "462000"
  },
  {
    "text": "and this is largely to expand upon cloud",
    "start": "462000",
    "end": "465599"
  },
  {
    "text": "provider storage with rook's",
    "start": "465599",
    "end": "466960"
  },
  {
    "text": "capabilities",
    "start": "466960",
    "end": "469520"
  },
  {
    "start": "468000",
    "end": "468000"
  },
  {
    "text": "digging a little deeper into that last",
    "start": "469520",
    "end": "471759"
  },
  {
    "text": "bit",
    "start": "471759",
    "end": "472879"
  },
  {
    "text": "in a cloud environment ceph will use",
    "start": "472879",
    "end": "474800"
  },
  {
    "text": "persistent volume claims",
    "start": "474800",
    "end": "476319"
  },
  {
    "text": "as the underlying storage there's no",
    "start": "476319",
    "end": "479440"
  },
  {
    "text": "need for direct access to local devices",
    "start": "479440",
    "end": "482240"
  },
  {
    "text": "and",
    "start": "482240",
    "end": "483120"
  },
  {
    "text": "this can give a consistent storage",
    "start": "483120",
    "end": "484879"
  },
  {
    "text": "platform wherever kubernetes is deployed",
    "start": "484879",
    "end": "487199"
  },
  {
    "text": "regardless of where kubernetes is",
    "start": "487199",
    "end": "488960"
  },
  {
    "text": "deployed this is great for",
    "start": "488960",
    "end": "491599"
  },
  {
    "text": "multi-cloud installations",
    "start": "491599",
    "end": "494879"
  },
  {
    "text": "this also can help overcome some of the",
    "start": "494879",
    "end": "496720"
  },
  {
    "text": "shortcomings of cloud providers storage",
    "start": "496720",
    "end": "500400"
  },
  {
    "text": "whether this is allowing storage across",
    "start": "500400",
    "end": "502960"
  },
  {
    "text": "availability zones",
    "start": "502960",
    "end": "504960"
  },
  {
    "text": "or a lot of providers actually take many",
    "start": "504960",
    "end": "507680"
  },
  {
    "text": "minutes to fail over",
    "start": "507680",
    "end": "508960"
  },
  {
    "text": "storage that ceph and",
    "start": "508960",
    "end": "512000"
  },
  {
    "text": "by extension rook can fail over in",
    "start": "512000",
    "end": "514560"
  },
  {
    "text": "seconds",
    "start": "514560",
    "end": "516959"
  },
  {
    "text": "rook also allows for a greater number of",
    "start": "516959",
    "end": "518959"
  },
  {
    "text": "pvs per node",
    "start": "518959",
    "end": "520479"
  },
  {
    "text": "effectively limited only by whatever",
    "start": "520479",
    "end": "523360"
  },
  {
    "text": "performance",
    "start": "523360",
    "end": "524320"
  },
  {
    "text": "is there than strictly saying only 30",
    "start": "524320",
    "end": "527440"
  },
  {
    "text": "like some cloud providers",
    "start": "527440",
    "end": "530160"
  },
  {
    "text": "and some users also really",
    "start": "530160",
    "end": "533440"
  },
  {
    "text": "want to get better performance to cost",
    "start": "533440",
    "end": "535760"
  },
  {
    "text": "ratio by picking",
    "start": "535760",
    "end": "537600"
  },
  {
    "text": "the storage from their cloud provider",
    "start": "537600",
    "end": "539839"
  },
  {
    "text": "that gives them what they want",
    "start": "539839",
    "end": "541440"
  },
  {
    "text": "for the best cost and then using that",
    "start": "541440",
    "end": "544640"
  },
  {
    "text": "storage",
    "start": "544640",
    "end": "546160"
  },
  {
    "text": "uh within rook",
    "start": "546160",
    "end": "549519"
  },
  {
    "start": "549000",
    "end": "549000"
  },
  {
    "text": "rook is customizable for",
    "start": "549519",
    "end": "553120"
  },
  {
    "text": "basically any cluster topology it is",
    "start": "553120",
    "end": "556560"
  },
  {
    "text": "customizable across and within",
    "start": "556560",
    "end": "559200"
  },
  {
    "text": "topologies",
    "start": "559200",
    "end": "560959"
  },
  {
    "text": "and in order to provide high",
    "start": "560959",
    "end": "562720"
  },
  {
    "text": "availability and durability",
    "start": "562720",
    "end": "565440"
  },
  {
    "text": "we can spread ceph daemons across",
    "start": "565440",
    "end": "568080"
  },
  {
    "text": "failure domains",
    "start": "568080",
    "end": "570320"
  },
  {
    "text": "we can also deploy on specific nodes if",
    "start": "570320",
    "end": "572399"
  },
  {
    "text": "you desire to",
    "start": "572399",
    "end": "573760"
  },
  {
    "text": "totally separate storage nodes from",
    "start": "573760",
    "end": "576240"
  },
  {
    "text": "application nodes",
    "start": "576240",
    "end": "577760"
  },
  {
    "text": "and have some more support that way",
    "start": "577760",
    "end": "581360"
  },
  {
    "text": "or even just have a single storage",
    "start": "581360",
    "end": "584800"
  },
  {
    "text": "node if you have a very small",
    "start": "584800",
    "end": "586800"
  },
  {
    "text": "environment",
    "start": "586800",
    "end": "588880"
  },
  {
    "text": "similar to ease of installation",
    "start": "588880",
    "end": "592320"
  },
  {
    "start": "589000",
    "end": "589000"
  },
  {
    "text": "rook updates are mostly fully automated",
    "start": "592320",
    "end": "595440"
  },
  {
    "text": "ceph updates and evensef major upgrades",
    "start": "595440",
    "end": "598800"
  },
  {
    "text": "are handled totally by rook",
    "start": "598800",
    "end": "602560"
  },
  {
    "text": "similarly rook patch updates uh for",
    "start": "602560",
    "end": "605279"
  },
  {
    "text": "example",
    "start": "605279",
    "end": "606240"
  },
  {
    "text": "going from version 1.6.0",
    "start": "606240",
    "end": "609440"
  },
  {
    "text": "to version 1.6.2 that update is fully",
    "start": "609440",
    "end": "612800"
  },
  {
    "text": "automated",
    "start": "612800",
    "end": "614160"
  },
  {
    "text": "you just need to tell kubernetes that",
    "start": "614160",
    "end": "616480"
  },
  {
    "text": "you want to update rook",
    "start": "616480",
    "end": "618720"
  },
  {
    "text": "rook minor upgrades do sometimes require",
    "start": "618720",
    "end": "620959"
  },
  {
    "text": "some manual work",
    "start": "620959",
    "end": "622800"
  },
  {
    "text": "this allows for taking advantage of the",
    "start": "622800",
    "end": "625360"
  },
  {
    "text": "latest features",
    "start": "625360",
    "end": "626800"
  },
  {
    "text": "and occasionally a kubernetes cef csi or",
    "start": "626800",
    "end": "630480"
  },
  {
    "text": "rook feature",
    "start": "630480",
    "end": "631360"
  },
  {
    "text": "is deprecated and users may need to take",
    "start": "631360",
    "end": "634079"
  },
  {
    "text": "some manual steps to",
    "start": "634079",
    "end": "635680"
  },
  {
    "text": "migrate but this is pretty pretty rare",
    "start": "635680",
    "end": "639279"
  },
  {
    "text": "in",
    "start": "639279",
    "end": "639680"
  },
  {
    "text": "more recent releases everything will be",
    "start": "639680",
    "end": "642640"
  },
  {
    "text": "documented in rook's upgrade guide for",
    "start": "642640",
    "end": "644480"
  },
  {
    "text": "upgrades we do still",
    "start": "644480",
    "end": "646320"
  },
  {
    "text": "try to make everything as automated as",
    "start": "646320",
    "end": "648000"
  },
  {
    "text": "possible and as",
    "start": "648000",
    "end": "649519"
  },
  {
    "text": "simple and streamlined as possible",
    "start": "649519",
    "end": "652560"
  },
  {
    "text": "the csi driver which i've talked about a",
    "start": "652560",
    "end": "654959"
  },
  {
    "start": "653000",
    "end": "653000"
  },
  {
    "text": "lot provides a lot of the functionality",
    "start": "654959",
    "end": "656959"
  },
  {
    "text": "that rick provides it allows dynamic",
    "start": "656959",
    "end": "659760"
  },
  {
    "text": "provisioning",
    "start": "659760",
    "end": "660480"
  },
  {
    "text": "of read write once or rewrite many",
    "start": "660480",
    "end": "663440"
  },
  {
    "text": "volumes",
    "start": "663440",
    "end": "664240"
  },
  {
    "text": "for both block and file system",
    "start": "664240",
    "end": "667760"
  },
  {
    "text": "it also allows volume expansion and",
    "start": "667760",
    "end": "671360"
  },
  {
    "text": "it allows snapshots and clones though",
    "start": "671360",
    "end": "674800"
  },
  {
    "text": "that's still in beta there is an older",
    "start": "674800",
    "end": "677920"
  },
  {
    "text": "flex volume driver that's still",
    "start": "677920",
    "end": "679519"
  },
  {
    "text": "available",
    "start": "679519",
    "end": "680720"
  },
  {
    "text": "but support is limited and we really we",
    "start": "680720",
    "end": "683680"
  },
  {
    "text": "really recommend using the csi driver",
    "start": "683680",
    "end": "686079"
  },
  {
    "text": "whenever possible",
    "start": "686079",
    "end": "689839"
  },
  {
    "start": "689000",
    "end": "689000"
  },
  {
    "text": "another feature that rook provides is",
    "start": "690560",
    "end": "693600"
  },
  {
    "text": "the ability to connect to a ceph cluster",
    "start": "693600",
    "end": "695680"
  },
  {
    "text": "that's outside of the current kubernetes",
    "start": "695680",
    "end": "697760"
  },
  {
    "text": "cluster",
    "start": "697760",
    "end": "699600"
  },
  {
    "text": "for example if your organization already",
    "start": "699600",
    "end": "702560"
  },
  {
    "text": "runs",
    "start": "702560",
    "end": "703040"
  },
  {
    "text": "a ceph cluster you don't need to create",
    "start": "703040",
    "end": "705440"
  },
  {
    "text": "a new one",
    "start": "705440",
    "end": "706399"
  },
  {
    "text": "inside of kubernetes with rook you can",
    "start": "706399",
    "end": "708399"
  },
  {
    "text": "connect",
    "start": "708399",
    "end": "709519"
  },
  {
    "text": "your kubernetes cluster with rook to the",
    "start": "709519",
    "end": "711360"
  },
  {
    "text": "existing external ceph cluster as we",
    "start": "711360",
    "end": "713600"
  },
  {
    "text": "call it",
    "start": "713600",
    "end": "714320"
  },
  {
    "text": "and then you can still dynamically",
    "start": "714320",
    "end": "716320"
  },
  {
    "text": "create your block file or object storage",
    "start": "716320",
    "end": "719279"
  },
  {
    "text": "for your kubernetes applications the",
    "start": "719279",
    "end": "721920"
  },
  {
    "text": "ceph cluster is just",
    "start": "721920",
    "end": "723600"
  },
  {
    "text": "managed outside i also talked a little",
    "start": "723600",
    "end": "727519"
  },
  {
    "start": "727000",
    "end": "727000"
  },
  {
    "text": "bit about the object storage",
    "start": "727519",
    "end": "729680"
  },
  {
    "text": "provisioning this is something that is",
    "start": "729680",
    "end": "732079"
  },
  {
    "text": "pretty unique to rook",
    "start": "732079",
    "end": "734160"
  },
  {
    "text": "this allows administrators to define a",
    "start": "734160",
    "end": "736320"
  },
  {
    "text": "custom storage class",
    "start": "736320",
    "end": "737920"
  },
  {
    "text": "for object storage and then a user",
    "start": "737920",
    "end": "741279"
  },
  {
    "text": "can create what is called an object",
    "start": "741279",
    "end": "743120"
  },
  {
    "text": "bucket claim or",
    "start": "743120",
    "end": "744320"
  },
  {
    "text": "obc and following a pattern that's",
    "start": "744320",
    "end": "748160"
  },
  {
    "text": "similar to persistent volume claims",
    "start": "748160",
    "end": "751440"
  },
  {
    "text": "the rook operator will create an object",
    "start": "751440",
    "end": "754720"
  },
  {
    "text": "bucket",
    "start": "754720",
    "end": "755360"
  },
  {
    "text": "when requested and then access to that",
    "start": "755360",
    "end": "758880"
  },
  {
    "text": "bucket is given",
    "start": "758880",
    "end": "759839"
  },
  {
    "text": "via kubernetes secret there's currently",
    "start": "759839",
    "end": "763040"
  },
  {
    "text": "a kubernetes enhancement proposal",
    "start": "763040",
    "end": "765519"
  },
  {
    "text": "called cozy which is short for container",
    "start": "765519",
    "end": "768160"
  },
  {
    "text": "object storage interface",
    "start": "768160",
    "end": "770320"
  },
  {
    "text": "which aims to supersede this",
    "start": "770320",
    "end": "772800"
  },
  {
    "text": "functionality",
    "start": "772800",
    "end": "773680"
  },
  {
    "text": "rook has a what i've often called a",
    "start": "773680",
    "end": "777839"
  },
  {
    "text": "proof of concept of the themes of cozy",
    "start": "777839",
    "end": "780959"
  },
  {
    "text": "and",
    "start": "780959",
    "end": "781600"
  },
  {
    "text": "you can look forward to hearing more",
    "start": "781600",
    "end": "783440"
  },
  {
    "text": "about cozy and rook",
    "start": "783440",
    "end": "784959"
  },
  {
    "text": "in the next i would say year or so",
    "start": "784959",
    "end": "789360"
  },
  {
    "text": "i'd also like to specifically talk about",
    "start": "789839",
    "end": "792399"
  },
  {
    "text": "the new features we've added in",
    "start": "792399",
    "end": "794240"
  },
  {
    "text": "rook version 1.6 really quickly firstly",
    "start": "794240",
    "end": "797760"
  },
  {
    "start": "796000",
    "end": "796000"
  },
  {
    "text": "starting with support for a new ceph",
    "start": "797760",
    "end": "799920"
  },
  {
    "text": "version",
    "start": "799920",
    "end": "801040"
  },
  {
    "text": "that's ceph pacific in rook version 1.6",
    "start": "801040",
    "end": "804000"
  },
  {
    "text": "support three step",
    "start": "804000",
    "end": "805120"
  },
  {
    "text": "versions we generally aim to support two",
    "start": "805120",
    "end": "809279"
  },
  {
    "text": "ceph versions",
    "start": "809279",
    "end": "810880"
  },
  {
    "text": "so support will be dropped for version",
    "start": "810880",
    "end": "813200"
  },
  {
    "text": "14 in",
    "start": "813200",
    "end": "814959"
  },
  {
    "text": "version 1.7 but we do want to give this",
    "start": "814959",
    "end": "817040"
  },
  {
    "text": "time for users to",
    "start": "817040",
    "end": "818560"
  },
  {
    "text": "migrate as they desire",
    "start": "818560",
    "end": "821680"
  },
  {
    "start": "821000",
    "end": "821000"
  },
  {
    "text": "broadly ceph file system has a couple",
    "start": "821680",
    "end": "824399"
  },
  {
    "text": "new features which are exciting",
    "start": "824399",
    "end": "826560"
  },
  {
    "text": "we have support for multiple file",
    "start": "826560",
    "end": "829040"
  },
  {
    "text": "systems perseph cluster",
    "start": "829040",
    "end": "830480"
  },
  {
    "text": "which is in uh general availability it's",
    "start": "830480",
    "end": "833600"
  },
  {
    "text": "no longer in a preview state",
    "start": "833600",
    "end": "835519"
  },
  {
    "text": "we also support mirroring a file system",
    "start": "835519",
    "end": "837760"
  },
  {
    "text": "from oneself cluster",
    "start": "837760",
    "end": "838880"
  },
  {
    "text": "to another we also support high",
    "start": "838880",
    "end": "842079"
  },
  {
    "text": "availability for ceph manager daemons",
    "start": "842079",
    "end": "845360"
  },
  {
    "text": "and pod disruption budgets are enabled",
    "start": "845360",
    "end": "847360"
  },
  {
    "text": "by default",
    "start": "847360",
    "end": "848720"
  },
  {
    "text": "which helps us maintain a",
    "start": "848720",
    "end": "851760"
  },
  {
    "text": "stable ceph cluster during maintenance",
    "start": "851760",
    "end": "854800"
  },
  {
    "text": "and updates",
    "start": "854800",
    "end": "857680"
  },
  {
    "start": "857000",
    "end": "857000"
  },
  {
    "text": "osds have a couple enhancements that we",
    "start": "857680",
    "end": "859839"
  },
  {
    "text": "can call out specifically",
    "start": "859839",
    "end": "862480"
  },
  {
    "text": "osds can be bulk updated in parallel",
    "start": "862480",
    "end": "865760"
  },
  {
    "text": "rook will do this automatically and it",
    "start": "865760",
    "end": "867600"
  },
  {
    "text": "respects failure domains to retain that",
    "start": "867600",
    "end": "869680"
  },
  {
    "text": "high availability",
    "start": "869680",
    "end": "871519"
  },
  {
    "text": "and also we are continuing to try to use",
    "start": "871519",
    "end": "874639"
  },
  {
    "text": "lvm the logical volume management",
    "start": "874639",
    "end": "877760"
  },
  {
    "text": "less and less for new osds",
    "start": "877760",
    "end": "880959"
  },
  {
    "text": "this has allowed us to restore support",
    "start": "880959",
    "end": "883360"
  },
  {
    "text": "for creating osds on partitions",
    "start": "883360",
    "end": "886160"
  },
  {
    "text": "and just puts less stuff",
    "start": "886160",
    "end": "889360"
  },
  {
    "text": "in the way of what we're trying to",
    "start": "889360",
    "end": "890800"
  },
  {
    "text": "create for the user",
    "start": "890800",
    "end": "893199"
  },
  {
    "text": "i'd like to pass it off now to my",
    "start": "893199",
    "end": "894880"
  },
  {
    "text": "colleague satoru who's going to give",
    "start": "894880",
    "end": "896720"
  },
  {
    "text": "a demo next",
    "start": "896720",
    "end": "899920"
  },
  {
    "text": "i'll demonstrate how to create a log",
    "start": "899920",
    "end": "902560"
  },
  {
    "text": "safe cluster",
    "start": "902560",
    "end": "905440"
  },
  {
    "start": "906000",
    "end": "906000"
  },
  {
    "text": "there are two types of clusters",
    "start": "906240",
    "end": "909519"
  },
  {
    "text": "host based cluster and bbc base cluster",
    "start": "909519",
    "end": "914000"
  },
  {
    "text": "in host based cluster you specify",
    "start": "914000",
    "end": "916880"
  },
  {
    "text": "hardware configurations",
    "start": "916880",
    "end": "918399"
  },
  {
    "text": "directly in safe cluster cluster",
    "start": "918399",
    "end": "921040"
  },
  {
    "text": "resource",
    "start": "921040",
    "end": "922720"
  },
  {
    "text": "then push standard data is on hostpaths",
    "start": "922720",
    "end": "927440"
  },
  {
    "text": "in ppg-based cluster you specify volume",
    "start": "927440",
    "end": "930560"
  },
  {
    "text": "claim templates for",
    "start": "930560",
    "end": "931920"
  },
  {
    "text": "ost then push center data is on ppc",
    "start": "931920",
    "end": "938160"
  },
  {
    "start": "938000",
    "end": "938000"
  },
  {
    "text": "host-based cluster is suitable for",
    "start": "939680",
    "end": "942800"
  },
  {
    "text": "a simple cluster especially if",
    "start": "942800",
    "end": "946560"
  },
  {
    "text": "you use all nodes and all devices",
    "start": "946560",
    "end": "951440"
  },
  {
    "text": "but cluster resources get complicated",
    "start": "951440",
    "end": "955360"
  },
  {
    "text": "in host-based cluster if not all nodes",
    "start": "955360",
    "end": "959120"
  },
  {
    "text": "are used or there are various hardware",
    "start": "959120",
    "end": "962560"
  },
  {
    "text": "configurations for each node",
    "start": "962560",
    "end": "965440"
  },
  {
    "text": "in such cases you might have to",
    "start": "965440",
    "end": "969199"
  },
  {
    "text": "list all nodes and",
    "start": "969199",
    "end": "972560"
  },
  {
    "text": "all devices like this",
    "start": "972560",
    "end": "976320"
  },
  {
    "text": "in ppg based cluster you are free from",
    "start": "978000",
    "end": "980959"
  },
  {
    "text": "describing hardware configurations",
    "start": "980959",
    "end": "983680"
  },
  {
    "text": "instead you should specify volume claim",
    "start": "983680",
    "end": "986240"
  },
  {
    "text": "templates inside",
    "start": "986240",
    "end": "987600"
  },
  {
    "text": "a glossary source and you should specify",
    "start": "987600",
    "end": "992000"
  },
  {
    "text": "the number of ost and",
    "start": "992000",
    "end": "995680"
  },
  {
    "text": "the storage class names and",
    "start": "995680",
    "end": "999199"
  },
  {
    "text": "the oysters size",
    "start": "999199",
    "end": "1002399"
  },
  {
    "text": "since pbc based cluster is not so",
    "start": "1002399",
    "end": "1005440"
  },
  {
    "text": "intuitive i'll explain",
    "start": "1005440",
    "end": "1008480"
  },
  {
    "text": "its detail by creating a simple ppg",
    "start": "1008480",
    "end": "1012560"
  },
  {
    "text": "based cluster step by step",
    "start": "1012560",
    "end": "1016480"
  },
  {
    "start": "1017000",
    "end": "1017000"
  },
  {
    "text": "i'll use this environment to",
    "start": "1017920",
    "end": "1021360"
  },
  {
    "text": "in this demo there is a kubernetes",
    "start": "1021360",
    "end": "1024240"
  },
  {
    "text": "cluster",
    "start": "1024240",
    "end": "1025360"
  },
  {
    "text": "consists of one node this node has",
    "start": "1025360",
    "end": "1029520"
  },
  {
    "text": "two local purchases and volumes local 0",
    "start": "1029520",
    "end": "1032959"
  },
  {
    "text": "and local 1 and this kubernetes cluster",
    "start": "1032959",
    "end": "1036400"
  },
  {
    "text": "has",
    "start": "1036400",
    "end": "1037038"
  },
  {
    "text": "rook operator",
    "start": "1037039",
    "end": "1039839"
  },
  {
    "text": "so this demo contains two steps",
    "start": "1040400",
    "end": "1043839"
  },
  {
    "text": "first one is create a simple cluster",
    "start": "1043839",
    "end": "1046959"
  },
  {
    "text": "the second one is expand this cluster",
    "start": "1046959",
    "end": "1051280"
  },
  {
    "text": "so let's set the first step",
    "start": "1051280",
    "end": "1054799"
  },
  {
    "text": "create a simple cluster to create a",
    "start": "1054799",
    "end": "1058160"
  },
  {
    "text": "simple cluster",
    "start": "1058160",
    "end": "1059600"
  },
  {
    "text": "let's apply support sample cluster.yaml",
    "start": "1059600",
    "end": "1062799"
  },
  {
    "text": "on the toolbox yaml",
    "start": "1062799",
    "end": "1065960"
  },
  {
    "text": "progress.yaml contains a",
    "start": "1065960",
    "end": "1068799"
  },
  {
    "text": "simple uh safe cluster cluster resource",
    "start": "1068799",
    "end": "1072559"
  },
  {
    "text": "and the toolbox yaml contains a toolbox",
    "start": "1072559",
    "end": "1075840"
  },
  {
    "text": "port",
    "start": "1075840",
    "end": "1076240"
  },
  {
    "text": "the definition of toolbox port toolbox",
    "start": "1076240",
    "end": "1079679"
  },
  {
    "text": "spot",
    "start": "1079679",
    "end": "1080160"
  },
  {
    "text": "is to use executing",
    "start": "1080160",
    "end": "1083280"
  },
  {
    "text": "to execute a safe command from",
    "start": "1083280",
    "end": "1085840"
  },
  {
    "text": "kubernetes",
    "start": "1085840",
    "end": "1088080"
  },
  {
    "text": "so let's see the sample cluster.dml",
    "start": "1088080",
    "end": "1095640"
  },
  {
    "text": "sample cluster okay",
    "start": "1095640",
    "end": "1098799"
  },
  {
    "text": "so it's safe cluster cluster results",
    "start": "1098799",
    "end": "1102400"
  },
  {
    "text": "and the most important part is the",
    "start": "1102400",
    "end": "1105760"
  },
  {
    "text": "number of counts and volume gram",
    "start": "1105760",
    "end": "1108480"
  },
  {
    "text": "templates",
    "start": "1108480",
    "end": "1109200"
  },
  {
    "text": "inside storage class device sets",
    "start": "1109200",
    "end": "1112240"
  },
  {
    "text": "number of ost is",
    "start": "1112240",
    "end": "1115840"
  },
  {
    "text": "one and this the osd",
    "start": "1115840",
    "end": "1119840"
  },
  {
    "text": "are consumed from local volumes",
    "start": "1119840",
    "end": "1123440"
  },
  {
    "text": "and its size is uh",
    "start": "1123440",
    "end": "1127120"
  },
  {
    "text": "at least five gigabytes",
    "start": "1127280",
    "end": "1130799"
  },
  {
    "text": "okay so let's apply",
    "start": "1130960",
    "end": "1134320"
  },
  {
    "text": "this yamu",
    "start": "1134320",
    "end": "1137440"
  },
  {
    "text": "oops sorry",
    "start": "1140720",
    "end": "1143440"
  },
  {
    "text": "okay let's up also apply toolbox port",
    "start": "1144240",
    "end": "1151840"
  },
  {
    "text": "on the right watch the list of",
    "start": "1152080",
    "end": "1155280"
  },
  {
    "text": "all save look save ports",
    "start": "1155280",
    "end": "1159840"
  },
  {
    "text": "and these are",
    "start": "1159840",
    "end": "1161130"
  },
  {
    "text": "[Music]",
    "start": "1161130",
    "end": "1162880"
  },
  {
    "text": "csi drivers and next",
    "start": "1162880",
    "end": "1166080"
  },
  {
    "text": "this is a monitor ports",
    "start": "1166080",
    "end": "1169600"
  },
  {
    "text": "okay so",
    "start": "1169600",
    "end": "1172640"
  },
  {
    "text": "now monitor port initializing and",
    "start": "1172640",
    "end": "1175679"
  },
  {
    "text": "now running next",
    "start": "1175679",
    "end": "1178960"
  },
  {
    "text": "uh manager port and ost prepare ports",
    "start": "1178960",
    "end": "1183039"
  },
  {
    "text": "are",
    "start": "1183039",
    "end": "1184240"
  },
  {
    "text": "created so please wait for a while",
    "start": "1184240",
    "end": "1188240"
  },
  {
    "text": "okay manager port is creating and oc",
    "start": "1188240",
    "end": "1191520"
  },
  {
    "text": "prepare",
    "start": "1191520",
    "end": "1192080"
  },
  {
    "text": "port is now creating ocd prepare port",
    "start": "1192080",
    "end": "1195600"
  },
  {
    "text": "is to initialize the new",
    "start": "1195600",
    "end": "1198880"
  },
  {
    "text": "osd so now it's running so",
    "start": "1198880",
    "end": "1202159"
  },
  {
    "text": "it means configuring the new osd",
    "start": "1202159",
    "end": "1207039"
  },
  {
    "text": "so it takes a bit long time so please",
    "start": "1207039",
    "end": "1210400"
  },
  {
    "text": "wait",
    "start": "1210400",
    "end": "1210799"
  },
  {
    "text": "for a while but probably",
    "start": "1210799",
    "end": "1214640"
  },
  {
    "text": "okay yes it's completed",
    "start": "1214640",
    "end": "1217760"
  },
  {
    "text": "so rock safe cluster is launching",
    "start": "1217760",
    "end": "1221760"
  },
  {
    "text": "and now initializing okay it's running",
    "start": "1221760",
    "end": "1225600"
  },
  {
    "text": "so the",
    "start": "1225600",
    "end": "1228480"
  },
  {
    "text": "get bot okay",
    "start": "1228720",
    "end": "1232480"
  },
  {
    "text": "all ports are created",
    "start": "1232480",
    "end": "1236080"
  },
  {
    "text": "these are csi",
    "start": "1236080",
    "end": "1239120"
  },
  {
    "text": "cc drivers and it's a manager",
    "start": "1239120",
    "end": "1242400"
  },
  {
    "text": "ports monitor ports operator ports and",
    "start": "1242400",
    "end": "1245520"
  },
  {
    "text": "usb ports and we also created i also",
    "start": "1245520",
    "end": "1250080"
  },
  {
    "text": "created toolbox port",
    "start": "1250080",
    "end": "1252400"
  },
  {
    "text": "okay",
    "start": "1252400",
    "end": "1254720"
  },
  {
    "text": "so kubercontrol get",
    "start": "1256559",
    "end": "1260000"
  },
  {
    "text": "baby okay local zero is bound to",
    "start": "1260000",
    "end": "1264559"
  },
  {
    "text": "ppc that is created by",
    "start": "1264559",
    "end": "1267679"
  },
  {
    "text": "rook and its size is",
    "start": "1267679",
    "end": "1272720"
  },
  {
    "text": "the pvc is bound used",
    "start": "1272720",
    "end": "1275919"
  },
  {
    "text": "by this looksafe",
    "start": "1275919",
    "end": "1279280"
  },
  {
    "text": "ost00 port okay",
    "start": "1279280",
    "end": "1283200"
  },
  {
    "text": "so we also we can confirm the status of",
    "start": "1283200",
    "end": "1288320"
  },
  {
    "text": "the safe cluster by executing",
    "start": "1288320",
    "end": "1293039"
  },
  {
    "text": "save commands from toolbox port",
    "start": "1293039",
    "end": "1297440"
  },
  {
    "text": "take i save",
    "start": "1299679",
    "end": "1303200"
  },
  {
    "text": "choose save",
    "start": "1303200",
    "end": "1306720"
  },
  {
    "text": "okay the safe cluster is successfully",
    "start": "1306720",
    "end": "1310559"
  },
  {
    "text": "created",
    "start": "1310559",
    "end": "1311440"
  },
  {
    "text": "and its row",
    "start": "1311440",
    "end": "1315200"
  },
  {
    "text": "capacity is six gigabytes",
    "start": "1315200",
    "end": "1318559"
  },
  {
    "text": "and it's the same as the capacity of",
    "start": "1318559",
    "end": "1320880"
  },
  {
    "text": "local",
    "start": "1320880",
    "end": "1322000"
  },
  {
    "text": "local zero percent volume okay",
    "start": "1322000",
    "end": "1326640"
  },
  {
    "start": "1327000",
    "end": "1327000"
  },
  {
    "text": "so all ports uh created toolbox monitor",
    "start": "1327679",
    "end": "1331039"
  },
  {
    "text": "manager and ost",
    "start": "1331039",
    "end": "1333039"
  },
  {
    "text": "and local 0 percent volume",
    "start": "1333039",
    "end": "1336240"
  },
  {
    "text": "consumed by ost with t0",
    "start": "1336240",
    "end": "1341200"
  },
  {
    "text": "so the next step is expand this cluster",
    "start": "1341200",
    "end": "1345120"
  },
  {
    "text": "it's very easy you just need to increase",
    "start": "1345120",
    "end": "1348480"
  },
  {
    "text": "count field in cluster resource",
    "start": "1348480",
    "end": "1353120"
  },
  {
    "text": "control rule save",
    "start": "1354400",
    "end": "1357440"
  },
  {
    "text": "edit save cluster",
    "start": "1357440",
    "end": "1362879"
  },
  {
    "text": "okay look safe",
    "start": "1363360",
    "end": "1366960"
  },
  {
    "text": "storage grass device",
    "start": "1367520",
    "end": "1371520"
  },
  {
    "text": "set okay so",
    "start": "1371520",
    "end": "1374960"
  },
  {
    "text": "currently of course the number of ost",
    "start": "1374960",
    "end": "1378000"
  },
  {
    "text": "is one so let's increase it",
    "start": "1378000",
    "end": "1381600"
  },
  {
    "text": "to so and save",
    "start": "1381600",
    "end": "1385360"
  },
  {
    "text": "so let's see let's watch the",
    "start": "1385360",
    "end": "1390320"
  },
  {
    "text": "port and look save namespace",
    "start": "1391440",
    "end": "1396559"
  },
  {
    "text": "now look the operator port is",
    "start": "1396559",
    "end": "1400559"
  },
  {
    "text": "under reconsideration",
    "start": "1400559",
    "end": "1404080"
  },
  {
    "text": "okay the new oc prepare port",
    "start": "1405919",
    "end": "1409600"
  },
  {
    "text": "to initializing the new",
    "start": "1409600",
    "end": "1412720"
  },
  {
    "text": "osd is running",
    "start": "1412720",
    "end": "1415760"
  },
  {
    "text": "it's initializing the new sd",
    "start": "1415760",
    "end": "1419840"
  },
  {
    "text": "so it takes some times",
    "start": "1420960",
    "end": "1424640"
  },
  {
    "text": "okay it's completed and the new oc1 port",
    "start": "1425200",
    "end": "1430000"
  },
  {
    "text": "created so it's",
    "start": "1430000",
    "end": "1434240"
  },
  {
    "text": "running okay so the osd one",
    "start": "1434240",
    "end": "1437520"
  },
  {
    "text": "usd one is added to my",
    "start": "1437520",
    "end": "1442240"
  },
  {
    "text": "safe look safe cluster control",
    "start": "1442240",
    "end": "1445600"
  },
  {
    "text": "get b okay both",
    "start": "1445600",
    "end": "1448720"
  },
  {
    "text": "local volumes are bound to",
    "start": "1448720",
    "end": "1453120"
  },
  {
    "text": "oyster ports and let's see",
    "start": "1453120",
    "end": "1457840"
  },
  {
    "text": "k status",
    "start": "1457840",
    "end": "1462640"
  },
  {
    "text": "so now the row capacity",
    "start": "1463360",
    "end": "1466559"
  },
  {
    "text": "increase is increased from 6 gigabytes",
    "start": "1466559",
    "end": "1469919"
  },
  {
    "text": "to",
    "start": "1469919",
    "end": "1471200"
  },
  {
    "text": "12 gigabytes the it succeeded to",
    "start": "1471200",
    "end": "1474960"
  },
  {
    "text": "expand my kubernetes by safe cluster",
    "start": "1474960",
    "end": "1479919"
  },
  {
    "text": "okay so",
    "start": "1479919",
    "end": "1483200"
  },
  {
    "start": "1480000",
    "end": "1480000"
  },
  {
    "text": "if you need to increase",
    "start": "1483200",
    "end": "1486880"
  },
  {
    "text": "increase the number of oysters more and",
    "start": "1486880",
    "end": "1488880"
  },
  {
    "text": "more you just",
    "start": "1488880",
    "end": "1490559"
  },
  {
    "text": "prepare you just need to prepare",
    "start": "1490559",
    "end": "1495120"
  },
  {
    "text": "people persistent volumes and increase",
    "start": "1495120",
    "end": "1498480"
  },
  {
    "text": "the",
    "start": "1498480",
    "end": "1499679"
  },
  {
    "text": "account period it's very easy",
    "start": "1499679",
    "end": "1503760"
  },
  {
    "start": "1504000",
    "end": "1504000"
  },
  {
    "text": "and there are some advanced",
    "start": "1504720",
    "end": "1506400"
  },
  {
    "text": "configurations of pbg-based cluster",
    "start": "1506400",
    "end": "1509760"
  },
  {
    "text": "the first one is",
    "start": "1509760",
    "end": "1512960"
  },
  {
    "text": "if uh you use csi drivers with dynamic",
    "start": "1512960",
    "end": "1517200"
  },
  {
    "text": "volume provisioning",
    "start": "1517200",
    "end": "1519120"
  },
  {
    "text": "you can create purchase and volumes for",
    "start": "1519120",
    "end": "1521679"
  },
  {
    "text": "ost on demand",
    "start": "1521679",
    "end": "1523760"
  },
  {
    "text": "in other words if",
    "start": "1523760",
    "end": "1528240"
  },
  {
    "text": "you don't need to prepare passes and",
    "start": "1528240",
    "end": "1531840"
  },
  {
    "text": "volumes",
    "start": "1531840",
    "end": "1532480"
  },
  {
    "text": "before increase count",
    "start": "1532480",
    "end": "1536480"
  },
  {
    "text": "you increase account",
    "start": "1536480",
    "end": "1539600"
  },
  {
    "text": "then purchase the volume are created",
    "start": "1539600",
    "end": "1543279"
  },
  {
    "text": "on demand and the second one",
    "start": "1543279",
    "end": "1546799"
  },
  {
    "text": "is if you need a spread ost evenly",
    "start": "1546799",
    "end": "1550799"
  },
  {
    "text": "among all storage nodes uh i guess",
    "start": "1550799",
    "end": "1554720"
  },
  {
    "text": "it can be applied to in most cases",
    "start": "1554720",
    "end": "1558880"
  },
  {
    "text": "you can use topology spread constraints",
    "start": "1558880",
    "end": "1561200"
  },
  {
    "text": "feature",
    "start": "1561200",
    "end": "1561919"
  },
  {
    "text": "in kubernetes so for more information",
    "start": "1561919",
    "end": "1566159"
  },
  {
    "text": "about these topics",
    "start": "1566159",
    "end": "1567840"
  },
  {
    "text": "please read this blog post",
    "start": "1567840",
    "end": "1572080"
  },
  {
    "text": "thanks satoru and thank you all for",
    "start": "1572640",
    "end": "1575440"
  },
  {
    "text": "tuning in",
    "start": "1575440",
    "end": "1576960"
  },
  {
    "text": "i'd like to leave you all with some",
    "start": "1576960",
    "end": "1578320"
  },
  {
    "text": "information about how you can get",
    "start": "1578320",
    "end": "1580720"
  },
  {
    "text": "involved",
    "start": "1580720",
    "end": "1582159"
  },
  {
    "text": "or just get more information about rook",
    "start": "1582159",
    "end": "1586240"
  },
  {
    "text": "i'll leave this up while we now start",
    "start": "1586240",
    "end": "1588640"
  },
  {
    "text": "our",
    "start": "1588640",
    "end": "1589360"
  },
  {
    "text": "q a session thank you again",
    "start": "1589360",
    "end": "1594720"
  }
]
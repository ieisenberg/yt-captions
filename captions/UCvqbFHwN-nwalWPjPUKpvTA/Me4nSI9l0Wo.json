[
  {
    "text": "yeah hello everyone how was your day",
    "start": "440",
    "end": "4160"
  },
  {
    "text": "Zero so far I hope everything was well I",
    "start": "4160",
    "end": "8360"
  },
  {
    "text": "am Mario I am a customer delivery",
    "start": "8360",
    "end": "12719"
  },
  {
    "text": "architect at catic and I don't know",
    "start": "12719",
    "end": "15599"
  },
  {
    "text": "nothing about AI um the reason why I",
    "start": "15599",
    "end": "18760"
  },
  {
    "text": "don't know nothing about AI because I",
    "start": "18760",
    "end": "20400"
  },
  {
    "text": "don't have to but we want to basically",
    "start": "20400",
    "end": "24680"
  },
  {
    "text": "yeah run AI workloads somewhere and",
    "start": "24680",
    "end": "28800"
  },
  {
    "text": "utilize them so uh I work for kuber",
    "start": "28800",
    "end": "31720"
  },
  {
    "text": "Matic we build a multicluster",
    "start": "31720",
    "end": "34559"
  },
  {
    "text": "multicloud um kubernetes management",
    "start": "34559",
    "end": "37640"
  },
  {
    "text": "platform I also am part of uh sik Contra",
    "start": "37640",
    "end": "41719"
  },
  {
    "text": "comps for the kubernetes project and sik",
    "start": "41719",
    "end": "43879"
  },
  {
    "text": "kades infra for the kubernetes project",
    "start": "43879",
    "end": "46600"
  },
  {
    "text": "and I'm also acting as an ambassador for",
    "start": "46600",
    "end": "49879"
  },
  {
    "text": "arm and I work as a gde for Google and",
    "start": "49879",
    "end": "55920"
  },
  {
    "text": "I'm from Bavaria and Germany usually I",
    "start": "55920",
    "end": "58120"
  },
  {
    "text": "have my later hos but on ly it was to",
    "start": "58120",
    "end": "60559"
  },
  {
    "text": "cold in Paris so no later H in this",
    "start": "60559",
    "end": "63519"
  },
  {
    "text": "time",
    "start": "63519",
    "end": "65158"
  },
  {
    "text": "um when we talk about Ai and AI",
    "start": "65159",
    "end": "69240"
  },
  {
    "text": "workloads it's always hard to where do I",
    "start": "69240",
    "end": "73479"
  },
  {
    "text": "run this right so where do I actually",
    "start": "73479",
    "end": "76520"
  },
  {
    "text": "run my models where do I train my models",
    "start": "76520",
    "end": "78880"
  },
  {
    "text": "where do I use",
    "start": "78880",
    "end": "80680"
  },
  {
    "text": "my uh my requirements where where do I",
    "start": "80680",
    "end": "85280"
  },
  {
    "text": "have a platform to run this so",
    "start": "85280",
    "end": "86759"
  },
  {
    "text": "kubernetes is an option to run Ai and to",
    "start": "86759",
    "end": "90200"
  },
  {
    "text": "train AI models but it's not a",
    "start": "90200",
    "end": "92680"
  },
  {
    "text": "requirement",
    "start": "92680",
    "end": "94439"
  },
  {
    "text": "however it's a pretty well fit why is",
    "start": "94439",
    "end": "97320"
  },
  {
    "text": "kubernetes a pretty well fit we have who",
    "start": "97320",
    "end": "100360"
  },
  {
    "text": "of you is using kubernetes in",
    "start": "100360",
    "end": "103759"
  },
  {
    "text": "production that's good so what are the",
    "start": "103759",
    "end": "106759"
  },
  {
    "text": "benefits of kubernetes it's has",
    "start": "106759",
    "end": "108920"
  },
  {
    "text": "self-healing aspects it's scalable you",
    "start": "108920",
    "end": "111680"
  },
  {
    "text": "can run it everywhere you can literally",
    "start": "111680",
    "end": "114320"
  },
  {
    "text": "I run it everywhere I can run it",
    "start": "114320",
    "end": "116399"
  },
  {
    "text": "potentially on my phone now which is",
    "start": "116399",
    "end": "118560"
  },
  {
    "text": "quite nice but probably most of the",
    "start": "118560",
    "end": "121200"
  },
  {
    "text": "people won't do this so we have a",
    "start": "121200",
    "end": "124439"
  },
  {
    "text": "multitude of options and I bet all of",
    "start": "124439",
    "end": "127560"
  },
  {
    "text": "you have problems running kubernetes",
    "start": "127560",
    "end": "129800"
  },
  {
    "text": "clusters or is everyone running",
    "start": "129800",
    "end": "132360"
  },
  {
    "text": "kubernetes smoothly without any issues",
    "start": "132360",
    "end": "134760"
  },
  {
    "text": "and everything is fine all the time if",
    "start": "134760",
    "end": "137160"
  },
  {
    "text": "yes please show your",
    "start": "137160",
    "end": "139360"
  },
  {
    "text": "hand oh one that's nice one person has",
    "start": "139360",
    "end": "144080"
  },
  {
    "text": "uh no problems so running Ai workloads",
    "start": "144080",
    "end": "147640"
  },
  {
    "text": "and kubernetes has the benefit that we",
    "start": "147640",
    "end": "150200"
  },
  {
    "text": "have the scalability we can stretch it",
    "start": "150200",
    "end": "152560"
  },
  {
    "text": "out we can basically distribute",
    "start": "152560",
    "end": "154959"
  },
  {
    "text": "everything but we can also utilize AI to",
    "start": "154959",
    "end": "159440"
  },
  {
    "text": "yeah slim our our process and or to to",
    "start": "159440",
    "end": "163360"
  },
  {
    "text": "fix clusters and for this there's an",
    "start": "163360",
    "end": "166080"
  },
  {
    "text": "open source tool and it's a cloud native",
    "start": "166080",
    "end": "168400"
  },
  {
    "text": "sandbox project since last year which is",
    "start": "168400",
    "end": "171000"
  },
  {
    "text": "called KS GPT who has used KS",
    "start": "171000",
    "end": "174800"
  },
  {
    "text": "GPT that's not so many people so KS GPT",
    "start": "174800",
    "end": "179680"
  },
  {
    "text": "is is as I said an open source project",
    "start": "179680",
    "end": "182440"
  },
  {
    "text": "and uh it's help you triaging kubernetes",
    "start": "182440",
    "end": "185959"
  },
  {
    "text": "issues with the help of AI you can",
    "start": "185959",
    "end": "189560"
  },
  {
    "text": "implement it with 10 different",
    "start": "189560",
    "end": "191159"
  },
  {
    "text": "interfaces it's you can use cat GPT you",
    "start": "191159",
    "end": "194040"
  },
  {
    "text": "can use uh Gemini you can use vtex ey",
    "start": "194040",
    "end": "197560"
  },
  {
    "text": "you can use uh AWS you can use all of",
    "start": "197560",
    "end": "200920"
  },
  {
    "text": "the different Windows um it also has a",
    "start": "200920",
    "end": "203440"
  },
  {
    "text": "in cluster operator for consistent",
    "start": "203440",
    "end": "205400"
  },
  {
    "text": "monitoring so you can basically run it",
    "start": "205400",
    "end": "207959"
  },
  {
    "text": "in your shell or you just run it in",
    "start": "207959",
    "end": "210200"
  },
  {
    "text": "every cluster and get locks of it sent",
    "start": "210200",
    "end": "214000"
  },
  {
    "text": "to all of the all of the different",
    "start": "214000",
    "end": "217640"
  },
  {
    "text": "environments the problem is I'm from",
    "start": "217640",
    "end": "220439"
  },
  {
    "text": "Germany we don't trust providers we",
    "start": "220439",
    "end": "223239"
  },
  {
    "text": "don't trust anyone we don't trust our",
    "start": "223239",
    "end": "226120"
  },
  {
    "text": "own mother prob so the problem is we",
    "start": "226120",
    "end": "230400"
  },
  {
    "text": "don't want our things that run in our",
    "start": "230400",
    "end": "233760"
  },
  {
    "text": "cluster being sent to a public cloud",
    "start": "233760",
    "end": "236000"
  },
  {
    "text": "provider or being sent to open uh open I",
    "start": "236000",
    "end": "240200"
  },
  {
    "text": "or we we we just don't want our data to",
    "start": "240200",
    "end": "243680"
  },
  {
    "text": "go out",
    "start": "243680",
    "end": "246439"
  },
  {
    "text": "so we create a magic triangle inside of",
    "start": "246439",
    "end": "250599"
  },
  {
    "text": "our environment which means that we",
    "start": "250599",
    "end": "253159"
  },
  {
    "text": "basically take what we want and run it",
    "start": "253159",
    "end": "257400"
  },
  {
    "text": "inside of our own clusters this means we",
    "start": "257400",
    "end": "261919"
  },
  {
    "text": "utilize three different things there we",
    "start": "261919",
    "end": "264360"
  },
  {
    "text": "utilize our own knowledge that we have",
    "start": "264360",
    "end": "266479"
  },
  {
    "text": "about kubernetes because everyone has",
    "start": "266479",
    "end": "269560"
  },
  {
    "text": "has a slack chat with hey how do I debug",
    "start": "269560",
    "end": "272080"
  },
  {
    "text": "this how do I debug this issue um and",
    "start": "272080",
    "end": "274960"
  },
  {
    "text": "there's also the the potential that we",
    "start": "274960",
    "end": "277520"
  },
  {
    "text": "can use like hey let's scrape kubernetes",
    "start": "277520",
    "end": "281280"
  },
  {
    "text": "questions from St overflow and see what",
    "start": "281280",
    "end": "284639"
  },
  {
    "text": "are the yeah what are what are the",
    "start": "284639",
    "end": "287320"
  },
  {
    "text": "common the common questions that we have",
    "start": "287320",
    "end": "289840"
  },
  {
    "text": "and then we use local AI which is also",
    "start": "289840",
    "end": "292919"
  },
  {
    "text": "an open source project and I I think",
    "start": "292919",
    "end": "295120"
  },
  {
    "text": "you're now following me where I want to",
    "start": "295120",
    "end": "297000"
  },
  {
    "text": "go with there so you don't have we don't",
    "start": "297000",
    "end": "299479"
  },
  {
    "text": "have have to pay for the yeah for paid",
    "start": "299479",
    "end": "303800"
  },
  {
    "text": "services for AI because we can basically",
    "start": "303800",
    "end": "306120"
  },
  {
    "text": "do this on our own in our own",
    "start": "306120",
    "end": "308039"
  },
  {
    "text": "environment and own it and that's the",
    "start": "308039",
    "end": "310240"
  },
  {
    "text": "the most important part and we can",
    "start": "310240",
    "end": "312479"
  },
  {
    "text": "utilize a tool called C Cube flow who",
    "start": "312479",
    "end": "314960"
  },
  {
    "text": "has used Cube flow before one person two",
    "start": "314960",
    "end": "318080"
  },
  {
    "text": "uh quite some persons so we can utilize",
    "start": "318080",
    "end": "321280"
  },
  {
    "text": "Cube flow as an environment where we",
    "start": "321280",
    "end": "324240"
  },
  {
    "text": "want to run this so Cube flow is an MLA",
    "start": "324240",
    "end": "328639"
  },
  {
    "text": "ml toolkit it is there for data",
    "start": "328639",
    "end": "332479"
  },
  {
    "text": "preparation you can do train your models",
    "start": "332479",
    "end": "335000"
  },
  {
    "text": "you can f tune your models you can uh",
    "start": "335000",
    "end": "338000"
  },
  {
    "text": "have a serving where you can run your",
    "start": "338000",
    "end": "340199"
  },
  {
    "text": "model and you can also have a service uh",
    "start": "340199",
    "end": "344039"
  },
  {
    "text": "you have also the service management",
    "start": "344039",
    "end": "345680"
  },
  {
    "text": "option um to run this stuff the problem",
    "start": "345680",
    "end": "348360"
  },
  {
    "text": "with this is we will only use a really",
    "start": "348360",
    "end": "351400"
  },
  {
    "text": "really small part of it because we will",
    "start": "351400",
    "end": "354000"
  },
  {
    "text": "mostly only use for this setup Cube flow",
    "start": "354000",
    "end": "356240"
  },
  {
    "text": "pipelines why you would ask k sgpt",
    "start": "356240",
    "end": "359800"
  },
  {
    "text": "doesn't support K surf momentarily to",
    "start": "359800",
    "end": "363440"
  },
  {
    "text": "basically serf this the good thing is",
    "start": "363440",
    "end": "365479"
  },
  {
    "text": "Cube flow can basically run everywhere",
    "start": "365479",
    "end": "368560"
  },
  {
    "text": "so you can run it on your laptop you can",
    "start": "368560",
    "end": "370919"
  },
  {
    "text": "run it in your home lab you can run it",
    "start": "370919",
    "end": "374080"
  },
  {
    "text": "in a public Cloud you can there are um",
    "start": "374080",
    "end": "376840"
  },
  {
    "text": "providers to run it in the uh on the big",
    "start": "376840",
    "end": "379479"
  },
  {
    "text": "public Cloud providers and uh it's a",
    "start": "379479",
    "end": "382120"
  },
  {
    "text": "tool set that you can just install out",
    "start": "382120",
    "end": "383800"
  },
  {
    "text": "of the",
    "start": "383800",
    "end": "384680"
  },
  {
    "text": "box what is local AI local AI is also an",
    "start": "384680",
    "end": "388840"
  },
  {
    "text": "open source project",
    "start": "388840",
    "end": "390240"
  },
  {
    "text": "that basically",
    "start": "390240",
    "end": "391960"
  },
  {
    "text": "do provide you with a rest API for that",
    "start": "391960",
    "end": "396919"
  },
  {
    "text": "is compatible with open API",
    "start": "396919",
    "end": "399440"
  },
  {
    "text": "specifications so we can use local AI to",
    "start": "399440",
    "end": "404919"
  },
  {
    "text": "run our llm models inside of our",
    "start": "404919",
    "end": "408479"
  },
  {
    "text": "clusters because local AI also has a h",
    "start": "408479",
    "end": "411479"
  },
  {
    "text": "shot so we can use it in our clusters we",
    "start": "411479",
    "end": "413560"
  },
  {
    "text": "can deploy it via a handshot then we",
    "start": "413560",
    "end": "416199"
  },
  {
    "text": "have the benefits of running it inside",
    "start": "416199",
    "end": "418160"
  },
  {
    "text": "of kubernetes so load distribution run",
    "start": "418160",
    "end": "421039"
  },
  {
    "text": "multiple models at once uh we can use it",
    "start": "421039",
    "end": "424360"
  },
  {
    "text": "to generate to generate images we can",
    "start": "424360",
    "end": "426840"
  },
  {
    "text": "use it to generate audio and the best",
    "start": "426840",
    "end": "430120"
  },
  {
    "text": "thing is it doesn't require GPU so we",
    "start": "430120",
    "end": "433599"
  },
  {
    "text": "don't have to have a GPU to run our",
    "start": "433599",
    "end": "437160"
  },
  {
    "text": "models inside of our clusters so we can",
    "start": "437160",
    "end": "439759"
  },
  {
    "text": "utilize our normal clusters",
    "start": "439759",
    "end": "443840"
  },
  {
    "text": "there how does this looks in the end um",
    "start": "443840",
    "end": "448120"
  },
  {
    "text": "when I said we are taking our own fine",
    "start": "448120",
    "end": "451720"
  },
  {
    "text": "chud model and put it into our own",
    "start": "451720",
    "end": "454120"
  },
  {
    "text": "clusters to basically feed into K sgpd",
    "start": "454120",
    "end": "457759"
  },
  {
    "text": "when we so what we still need to do and",
    "start": "457759",
    "end": "461400"
  },
  {
    "text": "this is the hard part and because this",
    "start": "461400",
    "end": "463560"
  },
  {
    "text": "is only a lightning talk we can't get",
    "start": "463560",
    "end": "465720"
  },
  {
    "text": "into too much detail there we first need",
    "start": "465720",
    "end": "468360"
  },
  {
    "text": "to prepare a data set so you still go",
    "start": "468360",
    "end": "471560"
  },
  {
    "text": "the the normal workflow of what would",
    "start": "471560",
    "end": "474199"
  },
  {
    "text": "you do to F tune your own model and",
    "start": "474199",
    "end": "477240"
  },
  {
    "text": "alone this part is hilarious hard so",
    "start": "477240",
    "end": "480800"
  },
  {
    "text": "this takes time and this is something",
    "start": "480800",
    "end": "482520"
  },
  {
    "text": "that you always need to remember when",
    "start": "482520",
    "end": "484319"
  },
  {
    "text": "you look at this whole setup that every",
    "start": "484319",
    "end": "487360"
  },
  {
    "text": "step of this although it's running in",
    "start": "487360",
    "end": "489759"
  },
  {
    "text": "your own infrastructure this takes time",
    "start": "489759",
    "end": "493479"
  },
  {
    "text": "this takes working time this takes",
    "start": "493479",
    "end": "495599"
  },
  {
    "text": "compute time this takes money from your",
    "start": "495599",
    "end": "498400"
  },
  {
    "text": "company to run this so even though it is",
    "start": "498400",
    "end": "502199"
  },
  {
    "text": "yours think twice if you want to have",
    "start": "502199",
    "end": "505199"
  },
  {
    "text": "the whole stack in your own or if you",
    "start": "505199",
    "end": "507680"
  },
  {
    "text": "just want to use other service this is",
    "start": "507680",
    "end": "509759"
  },
  {
    "text": "for this but if you want to be secure",
    "start": "509759",
    "end": "512399"
  },
  {
    "text": "and if you have requirements and there",
    "start": "512399",
    "end": "514640"
  },
  {
    "text": "are certain fields in the industry that",
    "start": "514640",
    "end": "517000"
  },
  {
    "text": "have requirements like we cannot have",
    "start": "517000",
    "end": "520440"
  },
  {
    "text": "any of our data get outside of our",
    "start": "520440",
    "end": "523200"
  },
  {
    "text": "environment then you need to go to the",
    "start": "523200",
    "end": "525480"
  },
  {
    "text": "painful process and basically do",
    "start": "525480",
    "end": "527160"
  },
  {
    "text": "everything yourself then what we do is",
    "start": "527160",
    "end": "529839"
  },
  {
    "text": "we use pytorch um and let write with",
    "start": "529839",
    "end": "533480"
  },
  {
    "text": "pytorch a fine tuning script so we take",
    "start": "533480",
    "end": "536640"
  },
  {
    "text": "an existing llm and I mean there plenty",
    "start": "536640",
    "end": "540200"
  },
  {
    "text": "uh plenty of LMS out there um the good",
    "start": "540200",
    "end": "543680"
  },
  {
    "text": "thing is uh it local AI supports a",
    "start": "543680",
    "end": "547880"
  },
  {
    "text": "multitude of L of llms that you can use",
    "start": "547880",
    "end": "551320"
  },
  {
    "text": "and utilize and there's also Gemma that",
    "start": "551320",
    "end": "556040"
  },
  {
    "text": "basically so you can use Gemma from",
    "start": "556040",
    "end": "557920"
  },
  {
    "text": "Google you can use open Llama from from",
    "start": "557920",
    "end": "561120"
  },
  {
    "text": "meta and so on and so on and then we",
    "start": "561120",
    "end": "563279"
  },
  {
    "text": "have basically our py toch job that",
    "start": "563279",
    "end": "567399"
  },
  {
    "text": "takes the fine-tuning",
    "start": "567399",
    "end": "569920"
  },
  {
    "text": "process uh so you put everything into a",
    "start": "569920",
    "end": "572640"
  },
  {
    "text": "Docker container load the data set with",
    "start": "572640",
    "end": "575000"
  },
  {
    "text": "the script and then you basically run it",
    "start": "575000",
    "end": "577760"
  },
  {
    "text": "inside of a pipeline of cube flow and",
    "start": "577760",
    "end": "580560"
  },
  {
    "text": "then put it out as a GT UF file and then",
    "start": "580560",
    "end": "585800"
  },
  {
    "text": "you give it to local Ai and then the the",
    "start": "585800",
    "end": "589320"
  },
  {
    "text": "easiest thing is this is just the",
    "start": "589320",
    "end": "591040"
  },
  {
    "text": "connector so this is just a connector",
    "start": "591040",
    "end": "592959"
  },
  {
    "text": "that asks like hey k sgpt please take as",
    "start": "592959",
    "end": "596560"
  },
  {
    "text": "an endpoint for the questions that you",
    "start": "596560",
    "end": "599480"
  },
  {
    "text": "run inside of your cluster please just",
    "start": "599480",
    "end": "601760"
  },
  {
    "text": "take uh local Ai and all of the",
    "start": "601760",
    "end": "605519"
  },
  {
    "text": "questions go there and then you can say",
    "start": "605519",
    "end": "607399"
  },
  {
    "text": "like uh cads GPT analyze explain and it",
    "start": "607399",
    "end": "611360"
  },
  {
    "text": "will analyze your whole cluster with",
    "start": "611360",
    "end": "613720"
  },
  {
    "text": "your own local",
    "start": "613720",
    "end": "615680"
  },
  {
    "text": "running um",
    "start": "615680",
    "end": "618399"
  },
  {
    "text": "model but as I said this is the",
    "start": "618399",
    "end": "622120"
  },
  {
    "text": "beginning this means this is not the end",
    "start": "622120",
    "end": "625760"
  },
  {
    "text": "where we are there is a lot of hassle",
    "start": "625760",
    "end": "628399"
  },
  {
    "text": "the main problem that we currently have",
    "start": "628399",
    "end": "630279"
  },
  {
    "text": "is Cube flow is horrible to set up and I",
    "start": "630279",
    "end": "634519"
  },
  {
    "text": "mean really horrible we are waiting for",
    "start": "634519",
    "end": "637360"
  },
  {
    "text": "a solution that is like hey I want to",
    "start": "637360",
    "end": "640160"
  },
  {
    "text": "have like a Helm shot and it runs in my",
    "start": "640160",
    "end": "641959"
  },
  {
    "text": "cluster and everything is fine this is",
    "start": "641959",
    "end": "643800"
  },
  {
    "text": "not the case there are some Wenders that",
    "start": "643800",
    "end": "646440"
  },
  {
    "text": "basically package Cube flow U I know",
    "start": "646440",
    "end": "649000"
  },
  {
    "text": "that canonical have like a easy outof",
    "start": "649000",
    "end": "651240"
  },
  {
    "text": "thee boox solution the big cloud",
    "start": "651240",
    "end": "652880"
  },
  {
    "text": "providers have outof thee box solution",
    "start": "652880",
    "end": "654600"
  },
  {
    "text": "but if you run it on Prem on your own",
    "start": "654600",
    "end": "656480"
  },
  {
    "text": "data set H it's",
    "start": "656480",
    "end": "660000"
  },
  {
    "text": "not fun um you need still need to write",
    "start": "660000",
    "end": "663079"
  },
  {
    "text": "the pyge fine tuning scripts there has",
    "start": "663079",
    "end": "665040"
  },
  {
    "text": "no plug and play um and also data",
    "start": "665040",
    "end": "668279"
  },
  {
    "text": "preparation takes time um so this is all",
    "start": "668279",
    "end": "672120"
  },
  {
    "text": "the things that still hold us back you",
    "start": "672120",
    "end": "674880"
  },
  {
    "text": "need to constantly fine tune the good",
    "start": "674880",
    "end": "677560"
  },
  {
    "text": "thing is everything is so fast so",
    "start": "677560",
    "end": "679720"
  },
  {
    "text": "basically what I showed you",
    "start": "679720",
    "end": "681440"
  },
  {
    "text": "today won't",
    "start": "681440",
    "end": "683680"
  },
  {
    "text": "be I don't know it's it's the same last",
    "start": "683680",
    "end": "687000"
  },
  {
    "text": "slide um so everything that I showed you",
    "start": "687000",
    "end": "689440"
  },
  {
    "text": "today is probably completely obsolete in",
    "start": "689440",
    "end": "691880"
  },
  {
    "text": "half a year so when we meet in Salt Lake",
    "start": "691880",
    "end": "693680"
  },
  {
    "text": "City you say like why did you talk about",
    "start": "693680",
    "end": "696839"
  },
  {
    "text": "this it's way easier now um but I think",
    "start": "696839",
    "end": "700519"
  },
  {
    "text": "tuning no matter where you run it tuning",
    "start": "700519",
    "end": "703639"
  },
  {
    "text": "your set with your own data is the next",
    "start": "703639",
    "end": "707200"
  },
  {
    "text": "logical step to utilize AI because",
    "start": "707200",
    "end": "710320"
  },
  {
    "text": "models are fine but what we want is we",
    "start": "710320",
    "end": "713000"
  },
  {
    "text": "want our own fine-tuned models with our",
    "start": "713000",
    "end": "716519"
  },
  {
    "text": "data because there we have the knowledge",
    "start": "716519",
    "end": "718720"
  },
  {
    "text": "that we can",
    "start": "718720",
    "end": "719760"
  },
  {
    "text": "multiply thank you very",
    "start": "719760",
    "end": "723320"
  },
  {
    "text": "much",
    "start": "727000",
    "end": "730000"
  }
]
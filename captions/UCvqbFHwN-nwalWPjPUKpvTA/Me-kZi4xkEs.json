[
  {
    "start": "0",
    "end": "145000"
  },
  {
    "text": "so welcome to the Prometheus deep dive a kook on my name is Ben I'm a site",
    "start": "210",
    "end": "8880"
  },
  {
    "text": "reliability engineer at KITT lab and I'm also been a contributor to the Prometheus team for quite a number of",
    "start": "8880",
    "end": "15450"
  },
  {
    "text": "years now most of my work is not on prometheus itself but all the exporters and integrations that people use and",
    "start": "15450",
    "end": "22890"
  },
  {
    "text": "yeah feel free if you have questions one of our other Prometheus developers",
    "start": "22890",
    "end": "28769"
  },
  {
    "text": "will be handing out mics during if you have a question in the middle of talk feel free to interrupt me I don't mind",
    "start": "28769",
    "end": "34730"
  },
  {
    "text": "so quick 101 since this is the deep dive but you know Prometheus started in late",
    "start": "34730",
    "end": "41520"
  },
  {
    "text": "2012 it was created as a realtor it was",
    "start": "41520",
    "end": "46980"
  },
  {
    "text": "created to solve real world problems we had quite a lot of metrics but we also",
    "start": "46980",
    "end": "54719"
  },
  {
    "text": "had problems with having monitoring at",
    "start": "54719",
    "end": "60180"
  },
  {
    "text": "the time Nagios keep up with the rate of change in our infrastructure and so we built this system to be an active",
    "start": "60180",
    "end": "67470"
  },
  {
    "text": "monitoring system and not just a passive data collector so who into the intro yesterday yeah and",
    "start": "67470",
    "end": "76740"
  },
  {
    "text": "maybe an other random audience question now who's who's already using Prometheus",
    "start": "76740",
    "end": "83180"
  },
  {
    "text": "[Music] who's not using Prometheus and is just getting started",
    "start": "83180",
    "end": "88350"
  },
  {
    "text": "yeah cool so now that you've got Prometheus",
    "start": "88350",
    "end": "93540"
  },
  {
    "text": "installed what do we go what do we do here well there's a lot of good reading",
    "start": "93540",
    "end": "99000"
  },
  {
    "text": "material on on monitoring itself and and why it's good to use monitoring to let",
    "start": "99000",
    "end": "105360"
  },
  {
    "text": "you know when your systems are working properly I'm a big fan of the",
    "start": "105360",
    "end": "110880"
  },
  {
    "text": "of this tecnique of the red method and used method where kind of two sides of",
    "start": "110880",
    "end": "116340"
  },
  {
    "text": "the same coin and it's it's all about looking at your metrics from the perspective of your users because your",
    "start": "116340",
    "end": "123360"
  },
  {
    "text": "users don't care if your out of memory or your CPUs are overloaded they care if they're there there their requests are",
    "start": "123360",
    "end": "130709"
  },
  {
    "text": "going through and they're going through quickly and there's a lot of great material on that and then on for",
    "start": "130709",
    "end": "136950"
  },
  {
    "text": "Prometheus itself there's a couple of really great books that you can read they they go through all the detail of",
    "start": "136950",
    "end": "142620"
  },
  {
    "text": "getting you into prometheus but yeah so Prometheus itself is a is",
    "start": "142620",
    "end": "149150"
  },
  {
    "start": "145000",
    "end": "280000"
  },
  {
    "text": "what I call a intentionally uncoordinated distributed system is the",
    "start": "149150",
    "end": "154830"
  },
  {
    "text": "Prometheus design was came from a need where the monitoring system needed to be",
    "start": "154830",
    "end": "161430"
  },
  {
    "text": "the most reliable thing on the network and which meant that the Prometheus itself needed to have the least number",
    "start": "161430",
    "end": "167099"
  },
  {
    "text": "of dependencies on anything else on your network so as long as it it's up and running it's got a little local disk and",
    "start": "167099",
    "end": "173519"
  },
  {
    "text": "it can reach to the network it can monitor it versus other other monitoring",
    "start": "173519",
    "end": "179400"
  },
  {
    "text": "platforms where like if you've got it if you're linked to the internet goes down",
    "start": "179400",
    "end": "185190"
  },
  {
    "text": "you lose all visibility because you can't send any data to your SAS platform anymore or if you if if Prometheus",
    "start": "185190",
    "end": "193920"
  },
  {
    "text": "included monitoring that included a distributed storage cluster well how can you monitor if if when you're cassandra",
    "start": "193920",
    "end": "201569"
  },
  {
    "text": "is down you know you want Prometheus to be able to tell you that your Cassandra is down or whatever you happen to be",
    "start": "201569",
    "end": "208230"
  },
  {
    "text": "using for for a for storage you want to run Prometheus close to your targets",
    "start": "208230",
    "end": "215030"
  },
  {
    "text": "because you don't want to monitor your when links or or other network as a side",
    "start": "215030",
    "end": "221430"
  },
  {
    "text": "effect of of your of your of your target monitoring and we always recommend that",
    "start": "221430",
    "end": "227639"
  },
  {
    "text": "you think about vertical charting before you start thinking about horizontal charting so if you've got a thousand",
    "start": "227639",
    "end": "233880"
  },
  {
    "text": "pods and 500 of them are for one service and 500 500 or for another service split",
    "start": "233880",
    "end": "240329"
  },
  {
    "text": "your Prometheus to have 500 one service and 500 on the and yes so it's a it's a minimal",
    "start": "240329",
    "end": "247290"
  },
  {
    "text": "dependency super robust piece of software the prometheus includes its own",
    "start": "247290",
    "end": "253140"
  },
  {
    "text": "built-in time series database it uses right ahead log for reliability during",
    "start": "253140",
    "end": "259950"
  },
  {
    "text": "operation and restarts but in the the time series database itself is is",
    "start": "259950",
    "end": "265230"
  },
  {
    "text": "written out and it is immutable so it's it's hard to corrupt and it works works",
    "start": "265230",
    "end": "270510"
  },
  {
    "text": "pretty well it has it goes through simple compaction cycles to make the",
    "start": "270510",
    "end": "275850"
  },
  {
    "text": "indexing more efficient and it's just designed to be reasonably simple and robust so yeah there's a lot of common",
    "start": "275850",
    "end": "284040"
  },
  {
    "start": "280000",
    "end": "610000"
  },
  {
    "text": "questions that I get for Prometheus so Prometheus is collecting float64 data",
    "start": "284040",
    "end": "294570"
  },
  {
    "text": "all the time and the the best practice is you want to expose your your you want",
    "start": "294570",
    "end": "301889"
  },
  {
    "text": "to count your events and expose those as counters because if me because Prometheus is a polling based system if",
    "start": "301889",
    "end": "308250"
  },
  {
    "text": "you lose a data point you don't want to lose the information that was contained in that data point completely so you",
    "start": "308250",
    "end": "314729"
  },
  {
    "text": "have a count of say one and then a scrape happens and now the count is two and another scrape happens now the count",
    "start": "314729",
    "end": "320850"
  },
  {
    "text": "is three and Boop's you missed a scrape and you come up in the next count is",
    "start": "320850",
    "end": "326760"
  },
  {
    "text": "five so you don't know whether it went from the next scrape would have been",
    "start": "326760",
    "end": "333419"
  },
  {
    "text": "three or four but at least you know that the total is still there so you don't actually lose the you lose fidelity but",
    "start": "333419",
    "end": "340320"
  },
  {
    "text": "you don't lose accuracy and so because of this you the first thing that you",
    "start": "340320",
    "end": "345539"
  },
  {
    "text": "tend to run on a previous counter is you run a rate or an increase to find out what the rate of change of that counter",
    "start": "345539",
    "end": "352110"
  },
  {
    "text": "is because most of the time if you're counting CPU seconds to find out how",
    "start": "352110",
    "end": "357360"
  },
  {
    "text": "much CPU usage is going on in a process or a server you need to take a rate to",
    "start": "357360",
    "end": "362460"
  },
  {
    "text": "find out how many CPU seconds per second is is being used and that gives you you know the percentage of CPU utilization",
    "start": "362460",
    "end": "368520"
  },
  {
    "text": "or how many cores a process is using if you've got a multi-threaded app and so",
    "start": "368520",
    "end": "373550"
  },
  {
    "text": "here's some real-world example of data points and so this is sixty seconds of data for",
    "start": "373550",
    "end": "379800"
  },
  {
    "text": "a counter that's going up and somewhere around you know fifteen hundred two or",
    "start": "379800",
    "end": "386010"
  },
  {
    "text": "so every every fifteen seconds and you can see that the scrape intervals is",
    "start": "386010",
    "end": "393060"
  },
  {
    "text": "fifteen seconds so we get four data points within 16 seconds and there's like one at four seconds a nice note",
    "start": "393060",
    "end": "399720"
  },
  {
    "text": "next one at 19 seconds etc etc and then that's just one instance of this server",
    "start": "399720",
    "end": "406470"
  },
  {
    "text": "so we've got a this is from a H a proxy web server or web reverse proxy and you",
    "start": "406470",
    "end": "414539"
  },
  {
    "text": "know we of course have more than one H a proxy the load balance all of our systems so here's the data points from a",
    "start": "414539",
    "end": "419789"
  },
  {
    "text": "different H a proxy and so it's it's not going up as fast but also notice that",
    "start": "419789",
    "end": "425639"
  },
  {
    "text": "the the the samples are offset differently so Prometheus you tell it to",
    "start": "425639",
    "end": "431370"
  },
  {
    "text": "scrape all of your targets every 15 seconds and it's not doing that on a clock basis it's actually taking all of",
    "start": "431370",
    "end": "437910"
  },
  {
    "text": "your targets and spreading them out over the scrape interval so that you get this nice even and flow of ingestion into",
    "start": "437910",
    "end": "444060"
  },
  {
    "text": "Prometheus it also gives you some nice like mathematical effects to to get more",
    "start": "444060",
    "end": "449550"
  },
  {
    "text": "accurate information and so when you get a bunch of different data points you can",
    "start": "449550",
    "end": "455070"
  },
  {
    "text": "see that they're spread out all over time within that window and now now we",
    "start": "455070",
    "end": "460410"
  },
  {
    "text": "want to query this and we want to get a rate so we're gonna say say I hit the query button and I time-aligned my query",
    "start": "460410",
    "end": "467099"
  },
  {
    "text": "so that it my query time is at the top of the minute and I'm asking for an",
    "start": "467099",
    "end": "473729"
  },
  {
    "text": "increase over 30 seconds and so now I've got two data points that fall within",
    "start": "473729",
    "end": "478860"
  },
  {
    "text": "that 30-second window and what Prometheus does is instead of giving you",
    "start": "478860",
    "end": "484349"
  },
  {
    "text": "the difference between the first data point and the second data point it actually extrapolates",
    "start": "484349",
    "end": "489750"
  },
  {
    "text": "the the two data points to find out what the total increase would be if there were more samples within that section or",
    "start": "489750",
    "end": "495539"
  },
  {
    "text": "within that within that range and this is really a little bit confusing for some people because they they see a",
    "start": "495539",
    "end": "501389"
  },
  {
    "text": "counter and it goes up by one and they're like but I got a number that was was I got two point five",
    "start": "501389",
    "end": "509160"
  },
  {
    "text": "because and they're like that that's confusing and well it's all because it's interpolation because it you're asking",
    "start": "509160",
    "end": "517500"
  },
  {
    "text": "you ask Cory theists for 30 seconds worth of increase but it's only gotten data points that are 15 seconds apart",
    "start": "517500",
    "end": "524010"
  },
  {
    "text": "within that time window so it has to extrapolate to give you the correct answer because if you know that that",
    "start": "524010",
    "end": "530520"
  },
  {
    "text": "counter is kind of going up at the same rate and once once we start adding more data",
    "start": "530520",
    "end": "537300"
  },
  {
    "text": "points back into this and we do more extrapolation you can see that it is now",
    "start": "537300",
    "end": "542700"
  },
  {
    "text": "gonna work out because now if I want to take all four of my H a proxy servers and sum up that that increase I can now",
    "start": "542700",
    "end": "550050"
  },
  {
    "text": "not have to worry about the the milliseconds of difference in time between the different scrapes that are",
    "start": "550050",
    "end": "555960"
  },
  {
    "text": "in that time window another interesting thing is what if I asked for a minute of",
    "start": "555960",
    "end": "562320"
  },
  {
    "text": "increase I don't have any more pretty pictures thank you good gnuplot what if",
    "start": "562320",
    "end": "567930"
  },
  {
    "text": "I asked for an increase and what if over the whole minute what if that say that",
    "start": "567930",
    "end": "574860"
  },
  {
    "text": "the the blue circles on the top of the graph the first two data points were",
    "start": "574860",
    "end": "580860"
  },
  {
    "text": "missing so if I didn't do extrapolation and I had was missing those two data",
    "start": "580860",
    "end": "587340"
  },
  {
    "text": "points I would only get say about 2000",
    "start": "587340",
    "end": "592350"
  },
  {
    "text": "on the increase versus the total of 6,000 which is what it's really going on here so it's one of those cases where we",
    "start": "592350",
    "end": "599010"
  },
  {
    "text": "we do the interpolation we do the extrapolation of the data in order to try and produce a more accurate overall",
    "start": "599010",
    "end": "605250"
  },
  {
    "text": "picture of the of the data that you've got in your metrics so next big question",
    "start": "605250",
    "end": "612540"
  },
  {
    "start": "610000",
    "end": "793000"
  },
  {
    "text": "a lot of people ask is okay so now I've got a Prometheus and it's overloaded or I started a nice I now have two",
    "start": "612540",
    "end": "619800"
  },
  {
    "text": "Prometheus servers and I've got high availability and and we're gonna start",
    "start": "619800",
    "end": "626280"
  },
  {
    "text": "talking about scaling and the first the first question people ask is well how do i capacity plan well it depends mostly",
    "start": "626280",
    "end": "633900"
  },
  {
    "text": "on the rate of ingestion of your data because as Prometheus collects data it's got a store it somewhere and it needs",
    "start": "633900",
    "end": "640500"
  },
  {
    "text": "currently about 1.5 it's per per sample and so it's pretty easy to just do a little bit of capacity",
    "start": "640500",
    "end": "646770"
  },
  {
    "text": "planning math or and and it also depends a little bit on the data that you've got so usually the recommendation is is you",
    "start": "646770",
    "end": "653970"
  },
  {
    "text": "start out you look at the to you you you scrape some of your data and then you can now start to build a capacity",
    "start": "653970",
    "end": "659940"
  },
  {
    "text": "planning story for your for your Prometheus and you and so like for",
    "start": "659940",
    "end": "667020"
  },
  {
    "text": "example we have a server in our production environment that's doing about a hundred thousand samples per",
    "start": "667020",
    "end": "672270"
  },
  {
    "text": "second by about one and a half bytes for 60 seconds for 60 minutes and it's about",
    "start": "672270",
    "end": "677640"
  },
  {
    "text": "half a gigabyte an hour and that's a bit of data but it's not too bad when a hundred thousand samples per second is",
    "start": "677640",
    "end": "683100"
  },
  {
    "text": "quite big we have we have a lot of metrics and a lot of data and that's just you know one of our our Prometheus",
    "start": "683100",
    "end": "688950"
  },
  {
    "text": "servers now the question is is now I've",
    "start": "688950",
    "end": "694200"
  },
  {
    "text": "got all these multiple instances and how do i scale it well the there's a bunch",
    "start": "694200",
    "end": "700050"
  },
  {
    "text": "of different ways Prometheus has a technique called Federation where you",
    "start": "700050",
    "end": "706590"
  },
  {
    "text": "can take a single Prometheus that is collecting data from a lot of targets and you don't maybe not even care",
    "start": "706590",
    "end": "713370"
  },
  {
    "text": "because it's a you know say a bunch of individual auto scaled pods and the individual pods don't matter so what you",
    "start": "713370",
    "end": "719910"
  },
  {
    "text": "really care about is the cluster level data so you have what promethease is called recording rules it takes a",
    "start": "719910",
    "end": "725940"
  },
  {
    "text": "Prometheus query and stores that into a new metric and then you have a",
    "start": "725940",
    "end": "731610"
  },
  {
    "text": "Federation server on top of that that pulls in just the recording rules and ignores the individual pod data and",
    "start": "731610",
    "end": "738810"
  },
  {
    "text": "that's a simple like hierarchical system the promise of course if you tried to",
    "start": "738810",
    "end": "743820"
  },
  {
    "text": "pull everything into that federated server it would blow up because if you try it's it's not a method of like",
    "start": "743820",
    "end": "749880"
  },
  {
    "text": "replicating it's a myth it's a method of tearing but if you really want to get",
    "start": "749880",
    "end": "755520"
  },
  {
    "text": "all of the data into a database well you're gonna need some kind of horizontally scalable database and in",
    "start": "755520",
    "end": "762360"
  },
  {
    "text": "the Prometheus design we have the individual previous servers that are small and robust and good for alerting",
    "start": "762360",
    "end": "768060"
  },
  {
    "text": "and then you've got these large scale databases that might fall over if there's a network partition but at least",
    "start": "768060",
    "end": "774120"
  },
  {
    "text": "the is still gonna work and so things like cortex and m3 DB and Thanos are",
    "start": "774120",
    "end": "779310"
  },
  {
    "text": "different methods of doing horizontal scaling of the data from multiple clusters and multiple instances of",
    "start": "779310",
    "end": "786540"
  },
  {
    "text": "Prometheus and dealing with the the high availability deduplication and things like that and for a long time we've had",
    "start": "786540",
    "end": "796500"
  },
  {
    "start": "793000",
    "end": "828000"
  },
  {
    "text": "this service discovery moratorium and we're finally out we we're now taking",
    "start": "796500",
    "end": "801840"
  },
  {
    "text": "new service discovery methods so who here is using docker swarm and would love to have parithi support for docker",
    "start": "801840",
    "end": "809160"
  },
  {
    "text": "swarm directly well we can do it now some somebody open a pull request and",
    "start": "809160",
    "end": "817050"
  },
  {
    "text": "yeah I want to save time because lots of people have questions so let's do Q&A",
    "start": "817050",
    "end": "825650"
  },
  {
    "text": "yarn do you have a question what's what's what's what's your biggest problem for me theist okay we have one",
    "start": "827720",
    "end": "839760"
  },
  {
    "start": "828000",
    "end": "867000"
  },
  {
    "text": "here go first what is the impact in the",
    "start": "839760",
    "end": "845490"
  },
  {
    "text": "storage of using many levels for per metric sorry say that again",
    "start": "845490",
    "end": "851010"
  },
  {
    "text": "what is the impact in terms of the storage when you use many many labels for parametric I'm not I'm not sure with",
    "start": "851010",
    "end": "862050"
  },
  {
    "text": "what's the impact on the storage so yeah",
    "start": "862050",
    "end": "870390"
  },
  {
    "start": "867000",
    "end": "990000"
  },
  {
    "text": "the Prometheus uses an inverted index so when you add a new new label it doesn't",
    "start": "870390",
    "end": "877650"
  },
  {
    "text": "really take up that much more space because the index itself only really",
    "start": "877650",
    "end": "883110"
  },
  {
    "text": "needs to store the the the key from that label into the the metric and it's it's",
    "start": "883110",
    "end": "889050"
  },
  {
    "text": "relatively efficient so it's it's totally okay to have a bunch of different labels especially if it you",
    "start": "889050",
    "end": "896550"
  },
  {
    "text": "know they're important that you want them to you want to be able to have your infrastructure like if you're talking",
    "start": "896550",
    "end": "903750"
  },
  {
    "text": "about like service discovery labels and you've got you know maybe a data center label or a cluster label and like those are",
    "start": "903750",
    "end": "911009"
  },
  {
    "text": "those are not that expensive perps mention the Colleen allegation the",
    "start": "911009",
    "end": "917790"
  },
  {
    "text": "infamous yeah you wanna you you want to make sure that you don't have tons of values for those labels because the the",
    "start": "917790",
    "end": "927079"
  },
  {
    "text": "the more values the bigger the index is and the longer it takes to scan those",
    "start": "927500",
    "end": "932910"
  },
  {
    "text": "indexes when you're when you're walking a metric but if you've got you know tens of data centers or or hundreds of",
    "start": "932910",
    "end": "942149"
  },
  {
    "text": "clusters those though that's a reasonable amount of of cardinality it's",
    "start": "942149",
    "end": "947339"
  },
  {
    "text": "also hope how things are correlated so if you have a an instance level naturally and then you have faster label",
    "start": "947339",
    "end": "954540"
  },
  {
    "text": "but in one cluster you always have the same instances it's actually not increasing cardinality that's",
    "start": "954540",
    "end": "961470"
  },
  {
    "text": "essentially a free label but if you add something only two orthogonal you get those like square growth of cardinality",
    "start": "961470",
    "end": "969170"
  },
  {
    "text": "okay so regarding pre aggregates let's",
    "start": "969170",
    "end": "975990"
  },
  {
    "text": "say I captured a metric for a month and this parameter supports creating a new Priya after a month and then creating on",
    "start": "975990",
    "end": "981959"
  },
  {
    "text": "existing data or does the pre aggregate has to exist at the tended metrics getting captured should I take it sure",
    "start": "981959",
    "end": "991319"
  },
  {
    "start": "990000",
    "end": "1056000"
  },
  {
    "text": "why now that sounds like retro actively evaluating recording rules is that it",
    "start": "991319",
    "end": "997399"
  },
  {
    "text": "okay that's not yet a feature but the plumbing is all in place so it's on the",
    "start": "997399",
    "end": "1003199"
  },
  {
    "text": "roadmap and it will I don't know whoever works on it it's actually she's pretty",
    "start": "1003199",
    "end": "1008480"
  },
  {
    "text": "straightforward technically no to do there there's actually an open pull request to to start building into prom",
    "start": "1008480",
    "end": "1014540"
  },
  {
    "text": "tool the some of that ability so the DTS DB is structured in a way that inserting",
    "start": "1014540",
    "end": "1021170"
  },
  {
    "text": "individual time series later is a really expensive operation but there is like it's implemented as an operation and now",
    "start": "1021170",
    "end": "1028069"
  },
  {
    "text": "you just need the tooling that Ravel gets a rule or that backfills data you got from another source and this will",
    "start": "1028069",
    "end": "1035000"
  },
  {
    "text": "all happen fairly soon okay you go that one first I'm curious",
    "start": "1035000",
    "end": "1045829"
  },
  {
    "text": "what experience you have with the the aggregation layer you know there's your",
    "start": "1045829",
    "end": "1051080"
  },
  {
    "text": "Thanos your your your Thanos cortex you don't what kind of experience do you guys yeah so so I get lab worries in",
    "start": "1051080",
    "end": "1058550"
  },
  {
    "start": "1056000",
    "end": "1263000"
  },
  {
    "text": "Thanos because it was really really nice to deploy is we we were before we were",
    "start": "1058550",
    "end": "1065240"
  },
  {
    "text": "using Thanos you know we were smaller than we were growing and we were adding more Prometheus servers and we were having more you know as tedious to setup",
    "start": "1065240",
    "end": "1072140"
  },
  {
    "text": "dashboards that pulled from multiple you know so we're using Groupon up for our dashboards and it was tedious to have",
    "start": "1072140",
    "end": "1077990"
  },
  {
    "text": "like one data source for this cluster in this data source for this cluster and mixing data sources was really annoying",
    "start": "1077990",
    "end": "1083720"
  },
  {
    "text": "so we added Thanos as an overlay proxy to make it easier to query but we",
    "start": "1083720",
    "end": "1090890"
  },
  {
    "text": "weren't actually using the any storage so we actually had six months of data in our Prometheus servers and that was",
    "start": "1090890",
    "end": "1096590"
  },
  {
    "text": "working quite well and it was just fan of as an add-on to start doing the",
    "start": "1096590",
    "end": "1101960"
  },
  {
    "text": "overlay layer and deduplication because you know we we we had four are between",
    "start": "1101960",
    "end": "1108770"
  },
  {
    "text": "our ger fauna and our Prometheus servers we had a little uh nginx failover so",
    "start": "1108770",
    "end": "1114200"
  },
  {
    "text": "it's just a whichever whichever one was it would pick the first one and if that one was down I would grab the second I",
    "start": "1114200",
    "end": "1120050"
  },
  {
    "text": "forget what the nginx configures for that but it was just a simple failover and then um but that that would produce",
    "start": "1120050",
    "end": "1128930"
  },
  {
    "text": "weirdness sometimes because of course they've got different gaps and so adding Thanos to do the gap fill was really",
    "start": "1128930",
    "end": "1135830"
  },
  {
    "text": "really nice and then after we after we",
    "start": "1135830",
    "end": "1140870"
  },
  {
    "text": "rolled that out then we started to experiment with pushing our T's to be data into a object storage and using the",
    "start": "1140870",
    "end": "1147020"
  },
  {
    "text": "storage for that can you hear me yeah got a quick follow-up then did you guys",
    "start": "1147020",
    "end": "1153590"
  },
  {
    "text": "use any sort of caching layers because the the finals queries can get kind of slow yeah so we're we're using we're not",
    "start": "1153590",
    "end": "1162170"
  },
  {
    "text": "we're using it for our public dashboards so we're using trickster and it works",
    "start": "1162170",
    "end": "1167690"
  },
  {
    "text": "okay but yeah there's there's a bunch of I've been we're talking with the I've",
    "start": "1167690",
    "end": "1175070"
  },
  {
    "text": "been talking with the tano's developers and we're talking about adding a caching layer and actually specifically there's",
    "start": "1175070",
    "end": "1181160"
  },
  {
    "text": "talk about bringing the cortex query caching layer into Santos and like",
    "start": "1181160",
    "end": "1187340"
  },
  {
    "text": "there's some some code share between all these projects like that's the nice thing is we we've got a good team where",
    "start": "1187340",
    "end": "1193820"
  },
  {
    "text": "the cortex developers and the thanos developers and the Prometheus developers are all kind of the same team it's just",
    "start": "1193820",
    "end": "1198950"
  },
  {
    "text": "slightly different techniques for the same stuff that's I think that's already merged like you can use this context",
    "start": "1198950",
    "end": "1205760"
  },
  {
    "text": "cache for normal communities for Taro's it works in all directions cool so",
    "start": "1205760",
    "end": "1213740"
  },
  {
    "text": "prometheus alert manager is like a nice tool for monitoring alerts and such and",
    "start": "1213740",
    "end": "1219020"
  },
  {
    "text": "I like its simplicity um but do you have any other integrations that might like empower",
    "start": "1219020",
    "end": "1224540"
  },
  {
    "text": "like the the ops personnel that collecting Prometheus data to like tune their alerts without necessarily having",
    "start": "1224540",
    "end": "1230510"
  },
  {
    "text": "to go into like like crate configurations at the code level like",
    "start": "1230510",
    "end": "1236660"
  },
  {
    "text": "ROM qol and such like GUI tools for the",
    "start": "1236660",
    "end": "1242810"
  },
  {
    "text": "alerting rules we keep trying to convince the gravano people to build that for us but no I don't most of us on",
    "start": "1242810",
    "end": "1252980"
  },
  {
    "text": "the prometheus team or we're back-end developers we we don't like doing UI",
    "start": "1252980",
    "end": "1259720"
  },
  {
    "text": "yeah um giving recommendations or resources on how to like go about comparing contrasting the various",
    "start": "1262600",
    "end": "1268130"
  },
  {
    "start": "1263000",
    "end": "1338000"
  },
  {
    "text": "storage solutions between cortex m3 DB or Thanos and how to choose one to use for your environment not specific I",
    "start": "1268130",
    "end": "1276830"
  },
  {
    "text": "don't have any Darren do you have any recommendations for picking a storage",
    "start": "1276830",
    "end": "1283280"
  },
  {
    "text": "layer it's a kind of it depends on what your what your like network layout is",
    "start": "1283280",
    "end": "1288800"
  },
  {
    "text": "and you know what your what kind of storage systems do you have you know dependent",
    "start": "1288800",
    "end": "1294409"
  },
  {
    "text": "you know how much complication do you want like no the Thanos is really interesting because it only requires",
    "start": "1294409",
    "end": "1299659"
  },
  {
    "text": "object storage and it works by sin it works really well if you have like",
    "start": "1299659",
    "end": "1305869"
  },
  {
    "text": "integrated network where you can actually sit have Thanos query talk",
    "start": "1305869",
    "end": "1311539"
  },
  {
    "text": "directly to the Prometheus servers but if you're very highly distributed and",
    "start": "1311539",
    "end": "1316730"
  },
  {
    "text": "you don't have a global VPN and you've got remote sites something like cortex",
    "start": "1316730",
    "end": "1321889"
  },
  {
    "text": "might be better where you've got the remote Prometheus servers behind some kind of NAT and it streams the data out",
    "start": "1321889",
    "end": "1327470"
  },
  {
    "text": "to the internet over the public internet and sends it up it into a core text",
    "start": "1327470",
    "end": "1333220"
  },
  {
    "text": "service mmm",
    "start": "1333220",
    "end": "1338659"
  },
  {
    "start": "1338000",
    "end": "1404000"
  },
  {
    "text": "so you asked us what's our greatest problem with Prometheus right now for us",
    "start": "1338659",
    "end": "1344149"
  },
  {
    "text": "it's that the Jenkins plugin doesn't work we installed it and it crashed",
    "start": "1344149",
    "end": "1349820"
  },
  {
    "text": "immediately now before I go fix that and submit a PR for myself to fix it what is",
    "start": "1349820",
    "end": "1358759"
  },
  {
    "text": "the plan for things like Jenkins or other integrations that are popular but",
    "start": "1358759",
    "end": "1366200"
  },
  {
    "text": "might not be in the core of what you guys are working on yeah no we actually",
    "start": "1366200",
    "end": "1371779"
  },
  {
    "text": "have a separate we have a separate github organization called prometheus community and we're slowly trying to",
    "start": "1371779",
    "end": "1379309"
  },
  {
    "text": "find that we're slowly trying to build that up as like the place where popular things can go and have additional",
    "start": "1379309",
    "end": "1386570"
  },
  {
    "text": "maintenance and be more more official than than just some random other github",
    "start": "1386570",
    "end": "1392840"
  },
  {
    "text": "org and we're you know we're slowly trying to get that on board and help them so check out the Prometheus",
    "start": "1392840",
    "end": "1398539"
  },
  {
    "text": "community github org I'll do that maybe",
    "start": "1398539",
    "end": "1405049"
  },
  {
    "start": "1404000",
    "end": "1440000"
  },
  {
    "text": "this is a little more starter question we've been using Prometheus prom operators and getting our all the",
    "start": "1405049",
    "end": "1413539"
  },
  {
    "text": "metrics for our cluster and that's working really well we've got Gravano running all sorts of interesting dashboards and as soon as we do that now",
    "start": "1413539",
    "end": "1419629"
  },
  {
    "text": "the application developers are saying hey I want to use that for some application specific metrics that we want to put in and I'm",
    "start": "1419629",
    "end": "1425600"
  },
  {
    "text": "wondering if you could talk a little bit about what we have to do to do that I know there's SDKs for a Java go know",
    "start": "1425600",
    "end": "1432560"
  },
  {
    "text": "whatever but now are we running an additional web server that's gonna be on each one of our pods that are now you",
    "start": "1432560",
    "end": "1439340"
  },
  {
    "text": "know hosting all the metrics are we sending them somewhere are we registering with that I mean the pom",
    "start": "1439340",
    "end": "1445070"
  },
  {
    "start": "1440000",
    "end": "1550000"
  },
  {
    "text": "operators were great for the cluster but now they build this in how complicated is that going to be yeah so all of the",
    "start": "1445070",
    "end": "1451390"
  },
  {
    "text": "the Prometheus metrics protocol is simple HTTP GET and all the Prometheus",
    "start": "1451390",
    "end": "1458150"
  },
  {
    "text": "client libraries include hooks into whatever language web servers are available so if you've got the Java you",
    "start": "1458150",
    "end": "1464630"
  },
  {
    "text": "know it uses the Java Web HTTP server you have a go lying at uses go HTTP and",
    "start": "1464630",
    "end": "1470240"
  },
  {
    "text": "then yeah so you you just use these Prometheus client libraries in your code and either on an exhibit you can you can",
    "start": "1470240",
    "end": "1478220"
  },
  {
    "text": "register it if you've got like a request router you can register you can put the Prometheus metrics registry which is the",
    "start": "1478220",
    "end": "1485320"
  },
  {
    "text": "usual name for the the internal metric counter trackers and you put you can",
    "start": "1485320",
    "end": "1491780"
  },
  {
    "text": "just send a route to slash metrics and Prometheus can then scrape that data and and collect and put it into the database",
    "start": "1491780",
    "end": "1499180"
  },
  {
    "text": "and but you know there are cases where you might want it you might want to put it on a different port and set the",
    "start": "1499180",
    "end": "1505430"
  },
  {
    "text": "service discovery so you've got your main API port and you get your metrics port but it's it's up it's kind of up to",
    "start": "1505430",
    "end": "1511940"
  },
  {
    "text": "it depends on the language and things like we actually recently moved we have",
    "start": "1511940",
    "end": "1517790"
  },
  {
    "text": "a large rails app and we moved the we're moving the Prometheus metrics from an",
    "start": "1517790",
    "end": "1523670"
  },
  {
    "text": "inline controller to its own dedicated port on the the unicorn controller",
    "start": "1523670",
    "end": "1529610"
  },
  {
    "text": "process so because it turns out that whenever we get slammed with traffic unicorn queues and then we lose",
    "start": "1529610",
    "end": "1535670"
  },
  {
    "text": "monitoring and so we've moved it to a separate port because though because of the limitations of Ruby but ongoing it's",
    "start": "1535670",
    "end": "1542630"
  },
  {
    "text": "all guru teens and it's no big deal got",
    "start": "1542630",
    "end": "1548330"
  },
  {
    "text": "one on the right can you give us an update on the state of vertical compaction in prometheus",
    "start": "1548330",
    "end": "1556340"
  },
  {
    "start": "1550000",
    "end": "1630000"
  },
  {
    "text": "like what do you what what what specific question about compaction so if you're",
    "start": "1557360",
    "end": "1562679"
  },
  {
    "text": "back filling data from a different Prometheus server if you're like doing a",
    "start": "1562679",
    "end": "1567929"
  },
  {
    "text": "remote right or if you have focus and you have a che pairs that are both",
    "start": "1567929",
    "end": "1573049"
  },
  {
    "text": "providing data for the same the same time period kind of compacting that down so that you're not keeping the",
    "start": "1573049",
    "end": "1579510"
  },
  {
    "text": "duplicated data in the object store that's more of a question for things like cortex and and Thanos I believe",
    "start": "1579510",
    "end": "1586530"
  },
  {
    "text": "cortex takes the H a and throws away one of the them automatically",
    "start": "1586530",
    "end": "1592429"
  },
  {
    "text": "whereas Thanos keeps both and and keeps both around and so that's that's kind of",
    "start": "1592429",
    "end": "1599370"
  },
  {
    "text": "like prometheus Prometheus itself is not a remote right receiver so you can't stream one Prometheus to another that's",
    "start": "1599370",
    "end": "1606240"
  },
  {
    "text": "more of a question for things like panels and cortex so the I mean both of",
    "start": "1606240",
    "end": "1612120"
  },
  {
    "text": "them have deduplication logic and if you backfill into a Prometheus server if this tooling we mentioned which is kind",
    "start": "1612120",
    "end": "1619500"
  },
  {
    "text": "of there we're not really ready to vailable then it will not to do deduplication it will just put it all",
    "start": "1619500",
    "end": "1625409"
  },
  {
    "text": "together into one time series block so I",
    "start": "1625409",
    "end": "1630630"
  },
  {
    "start": "1630000",
    "end": "1711000"
  },
  {
    "text": "understand that most people are using grow fauna [Music]",
    "start": "1630630",
    "end": "1636360"
  },
  {
    "text": "has there been discussion about a way to quickly visualize all the metric graphs",
    "start": "1636360",
    "end": "1642600"
  },
  {
    "text": "of a target in Prometheus itself so yeah we the Prometheus web interfaces is",
    "start": "1642600",
    "end": "1650510"
  },
  {
    "text": "intentionally simple and it's mostly",
    "start": "1650510",
    "end": "1655650"
  },
  {
    "text": "there to like provide a basic debugging interface and and getting started and testing queries and then you know my",
    "start": "1655650",
    "end": "1662070"
  },
  {
    "text": "usual workflow is all all beyond Prometheus or Thanos using interface and I'll do a bunch of test queries and I'll",
    "start": "1662070",
    "end": "1667650"
  },
  {
    "text": "figure out what I want and then I'll copy and paste those in the core fauna but we actually just started a rewrite",
    "start": "1667650",
    "end": "1675059"
  },
  {
    "text": "of the web interface the original webinar face on Prometheus was handwritten javis ripped and it was really annoying to",
    "start": "1675059",
    "end": "1682870"
  },
  {
    "text": "work on and we've got a new a new UI we're rebuilding and react so we're",
    "start": "1682870",
    "end": "1688600"
  },
  {
    "text": "looking for more contributors to contribute features to the built in prometheus UI there's also work on an",
    "start": "1688600",
    "end": "1697090"
  },
  {
    "text": "LSP implementation for prom ql that this react your I could perhaps use or you",
    "start": "1697090",
    "end": "1704230"
  },
  {
    "text": "can use in vs code so it's quite exciting what's happening there this",
    "start": "1704230",
    "end": "1711790"
  },
  {
    "start": "1711000",
    "end": "1753000"
  },
  {
    "text": "might be a github issue but I'm gonna ask it anyways is there gonna be any",
    "start": "1711790",
    "end": "1717670"
  },
  {
    "text": "continued support for sizing on TS DB being specified on the CLI it's an",
    "start": "1717670",
    "end": "1723340"
  },
  {
    "text": "experimental feature right now and it does not work properly for me the mean",
    "start": "1723340",
    "end": "1728650"
  },
  {
    "text": "there were two teams size based retention yes correct I haven't heard anything that that it",
    "start": "1728650",
    "end": "1735100"
  },
  {
    "text": "doesn't work I've tested it it works for normally okay so the issue yeah sounds",
    "start": "1735100",
    "end": "1743200"
  },
  {
    "text": "like you might have hit a bug anybody",
    "start": "1743200",
    "end": "1748420"
  },
  {
    "text": "else got one right here the I wonder if you have any tips or",
    "start": "1748420",
    "end": "1755650"
  },
  {
    "start": "1753000",
    "end": "1855000"
  },
  {
    "text": "anything for config management cuz config management of Prometheus can get heavy it has a lot of configs alert",
    "start": "1755650",
    "end": "1762100"
  },
  {
    "text": "configs and you also have to often update configs all the time you want to add an alert or double remove an alert",
    "start": "1762100",
    "end": "1767230"
  },
  {
    "text": "so yeah it depends on what your your configuration management system is like",
    "start": "1767230",
    "end": "1773890"
  },
  {
    "text": "you know we have a lot of our configuration and chef other people are",
    "start": "1773890",
    "end": "1781179"
  },
  {
    "text": "you know there's there's the operator stuff and you can use JSON it yeah",
    "start": "1781179",
    "end": "1787420"
  },
  {
    "text": "there's there's a lot of JSON O's is super interesting we're actually moving all of our dashboards into Griffin at",
    "start": "1787420",
    "end": "1794980"
  },
  {
    "text": "JSON it so our instead of hand clicking and making all of our dashboards we we",
    "start": "1794980",
    "end": "1801100"
  },
  {
    "text": "auto generate them so they're all consistent with all the services so prometheus is super opinionated in many",
    "start": "1801100",
    "end": "1807550"
  },
  {
    "text": "aspects but this is intentionally up to you to pick your poison having said that",
    "start": "1807550",
    "end": "1813639"
  },
  {
    "text": "bunch of projects get mix in sub-directories just as examples how you",
    "start": "1813639",
    "end": "1819099"
  },
  {
    "text": "could with JSON or create rules create dashboards but that's not as in like",
    "start": "1819099",
    "end": "1825219"
  },
  {
    "text": "this is another one canonical way it's just a way for us to document possible",
    "start": "1825219",
    "end": "1830649"
  },
  {
    "text": "rules possible dashboards three for a few more minutes so as like an",
    "start": "1830649",
    "end": "1836979"
  },
  {
    "text": "infrastructure or operations person I think Prometheus makes a lot of sense and the scalability aspect of it it's very",
    "start": "1836979",
    "end": "1843789"
  },
  {
    "text": "logical there's a bit of an overhead I think when you ask sort of regular",
    "start": "1843789",
    "end": "1850149"
  },
  {
    "text": "day-to-day application engineers to start using it because there are some sort of non intuitive concepts in there",
    "start": "1850149",
    "end": "1855999"
  },
  {
    "text": "they're like different than uh yeah metrics is a service kind of company do",
    "start": "1855999",
    "end": "1861159"
  },
  {
    "text": "you've any recommendations on sort of like how to onboard people mentally and yes the the the previous books and and",
    "start": "1861159",
    "end": "1870789"
  },
  {
    "text": "we have you know we have a bunch of how-to guides and tutorials stuff on our website you know we're always looking to",
    "start": "1870789",
    "end": "1877389"
  },
  {
    "text": "improve those and yeah there's we also have a YouTube channel",
    "start": "1877389",
    "end": "1883589"
  },
  {
    "text": "so we're every year we have Prometheus",
    "start": "1883589",
    "end": "1888729"
  },
  {
    "text": "conference and we have lots of great talks and I'm actually going to be putting together after we get the 2019",
    "start": "1888729",
    "end": "1895979"
  },
  {
    "text": "talks posted online well I'm gonna make like a Prometheus 101 playlist on",
    "start": "1895979",
    "end": "1902499"
  },
  {
    "text": "YouTube it's cool and I think that's all we have time for",
    "start": "1902499",
    "end": "1909029"
  },
  {
    "text": "you",
    "start": "1913200",
    "end": "1915260"
  }
]
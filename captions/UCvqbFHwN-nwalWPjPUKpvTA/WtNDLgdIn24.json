[
  {
    "text": "hello everyone and welcome to this talk U this talk is about low overhead zero instrumentation profiling in the context",
    "start": "799",
    "end": "6040"
  },
  {
    "text": "of Home Telemetry and more specifically about the ebpf profiling agents that",
    "start": "6040",
    "end": "11759"
  },
  {
    "text": "elastic has recently donated to open Telemetry my name is Chris calanis I'm",
    "start": "11759",
    "end": "16800"
  },
  {
    "text": "currently working as a principal engineer at elastic I'm also a maintainer of the open Telemetry",
    "start": "16800",
    "end": "22359"
  },
  {
    "text": "profiling Sig and a co-author and maintainer of the open cemetry ebpf profiler that is the subject of this",
    "start": "22359",
    "end": "29279"
  },
  {
    "text": "talk",
    "start": "29279",
    "end": "31960"
  },
  {
    "text": "I took this slide from one of my favorite lnk presentations it's called making progress and I highly recommend",
    "start": "35160",
    "end": "41000"
  },
  {
    "text": "you watch it it's a photograph of the NASA Mission Control Center and the last line at the bottom reads software",
    "start": "41000",
    "end": "47760"
  },
  {
    "text": "organizations who don't have a situation room don't understand where they are now in this and another",
    "start": "47760",
    "end": "53840"
  },
  {
    "text": "presentations Alan argues for biologically inspired approaches to modeling complex systems with continuous",
    "start": "53840",
    "end": "60320"
  },
  {
    "text": "feedback play playing a pro a prominent role I think that this is highly relevant to today's complicated",
    "start": "60320",
    "end": "66680"
  },
  {
    "text": "observability landscape as information proliferation and the move to highly distributed microservice heavy",
    "start": "66680",
    "end": "72759"
  },
  {
    "text": "architectures is making it a lot harder to distinguish signal from noise so this is something that continuous profiling",
    "start": "72759",
    "end": "79520"
  },
  {
    "text": "can definitely help with Thomas Dulan has talked about the cloud becoming the",
    "start": "79520",
    "end": "84680"
  },
  {
    "text": "new operating system and from this point of view continuous profilers can be seen",
    "start": "84680",
    "end": "89920"
  },
  {
    "text": "seen as tools that are native to and designed for this new",
    "start": "89920",
    "end": "96640"
  },
  {
    "text": "substrate as an example uh many companies have difficulty mapping CPU",
    "start": "97439",
    "end": "102479"
  },
  {
    "text": "consumption down to specific lines of code and tracking performance regressions over time some hyperscalers",
    "start": "102479",
    "end": "108399"
  },
  {
    "text": "have had data center-wide continuous profiling for some time for example Google they call it Google wide profiling they've even published a few",
    "start": "108399",
    "end": "114759"
  },
  {
    "text": "papers about it so and those papers have been very influential but generally speaking",
    "start": "114759",
    "end": "120840"
  },
  {
    "text": "continuous profiling hasn't been widely available contemporary profilers do not",
    "start": "120840",
    "end": "125880"
  },
  {
    "text": "work well with production binaries that are usually compiled without frame pointers and without symbols and they don't typically support high level",
    "start": "125880",
    "end": "132440"
  },
  {
    "text": "languages without application instrumentation it will be great uh if we could make a lightweight data center",
    "start": "132440",
    "end": "138920"
  },
  {
    "text": "wide uh continuous profiler that could be easily deployed and supports all widely used programming languages",
    "start": "138920",
    "end": "145239"
  },
  {
    "text": "available to everyone and uh this is exactly what we",
    "start": "145239",
    "end": "150959"
  },
  {
    "text": "try to accomplish in a startup called optimize Cloud where in 2021 we launched",
    "start": "150959",
    "end": "156200"
  },
  {
    "text": "the low overhead multi runtime uh zero instrumentation profiler shortly after that we were",
    "start": "156200",
    "end": "162959"
  },
  {
    "text": "acquired by elastic and in 2024 elastic decided to donate the profiling agent to open Telemetry whilst continuing to",
    "start": "162959",
    "end": "170000"
  },
  {
    "text": "support and evolve its functionality we see this profiler as something that complements but does not replace",
    "start": "170000",
    "end": "176599"
  },
  {
    "text": "traditional observability Solutions and this includes profilers that are are based on application instrumentation as",
    "start": "176599",
    "end": "182480"
  },
  {
    "text": "the sets of tradeoffs and capabilities are typically different across the two approaches our profiler is based on ebpf",
    "start": "182480",
    "end": "190560"
  },
  {
    "text": "which is technology that gives us a way to insert and execute new code inside the Linux kernel in a safe manner",
    "start": "190560",
    "end": "196799"
  },
  {
    "text": "without having to implement a kernel module it was originally designed for packet filtering but people eventually realized",
    "start": "196799",
    "end": "203640"
  },
  {
    "text": "that it could be used for all sorts of other things and drastically extended the set of problems that ebpf could be",
    "start": "203640",
    "end": "208959"
  },
  {
    "text": "applied to the profiler does not require application instrumentation or restarts of any kind and supports both native",
    "start": "208959",
    "end": "215599"
  },
  {
    "text": "code and code executing in higher level language run times it offers us whole",
    "start": "215599",
    "end": "220640"
  },
  {
    "text": "system visibility all the way down into the kernel now on the performance front",
    "start": "220640",
    "end": "226280"
  },
  {
    "text": "we aim for low CPU and memory overheads in order to make running the profiler continuously in production possible at",
    "start": "226280",
    "end": "231640"
  },
  {
    "text": "all times our current targets are less than 1% system CPU and less than 250",
    "start": "231640",
    "end": "237280"
  },
  {
    "text": "megabytes of memory and that's for for the typical",
    "start": "237280",
    "end": "241720"
  },
  {
    "text": "case now here you can see very high level architectural diagram of of how the agent is split into components uh",
    "start": "242319",
    "end": "249920"
  },
  {
    "text": "essentially we have two components here the kenel space component and the user space component the kenel space component is implemented in ebfc and the",
    "start": "249920",
    "end": "257759"
  },
  {
    "text": "user space component in go uh during initialization of the agent we set up",
    "start": "257759",
    "end": "262960"
  },
  {
    "text": "all the ebpf maps load the unwinder programs into the kernel and configure the various event pumps data Exchange",
    "start": "262960",
    "end": "269880"
  },
  {
    "text": "between the two components G user space generally takes place over ebpf Maps although we also use perf events for",
    "start": "269880",
    "end": "276400"
  },
  {
    "text": "messaging now we can see here that both the ebpf programs running in the kernel but also the user space agent process",
    "start": "276400",
    "end": "283000"
  },
  {
    "text": "can read a Target process memory the ebpf programs will do that during unwinding and the user space agent",
    "start": "283000",
    "end": "289880"
  },
  {
    "text": "process will do that during high level language symbolization and there's another part",
    "start": "289880",
    "end": "295160"
  },
  {
    "text": "here on the part of the user space go agent that I'm not going to show to you we call it the process manager is responsible for tracking processes that",
    "start": "295160",
    "end": "301720"
  },
  {
    "text": "are executing on the target system executable mappings in those processes and then extracting information from",
    "start": "301720",
    "end": "307280"
  },
  {
    "text": "those processes and placing it in ebpf",
    "start": "307280",
    "end": "311919"
  },
  {
    "text": "maps this is another very high level overview of how we do CPU profiling using sampling via ebpf generally uh",
    "start": "312320",
    "end": "319199"
  },
  {
    "text": "ebpf lets us attach programs to various parts of the kernel now in this specific",
    "start": "319199",
    "end": "324240"
  },
  {
    "text": "case we attach to the kernel timer interrupt and run our code at 20 HZ this",
    "start": "324240",
    "end": "329400"
  },
  {
    "text": "means means that 20 times a second the kernel will interrupt every non-idle CPU core on the system and run our ebpf",
    "start": "329400",
    "end": "336720"
  },
  {
    "text": "program which will immediately begin unwinding the stack at the point of interruption until the thread entry",
    "start": "336720",
    "end": "341759"
  },
  {
    "text": "point is reached uh now during stock unwinding I have an arrow there you can see it Loops",
    "start": "341759",
    "end": "347600"
  },
  {
    "text": "back from uh step three to step two uh because we can automatically switch between native and high level language",
    "start": "347600",
    "end": "354360"
  },
  {
    "text": "unwinding depending on where in memory the program counter points and for example this allows us to see seamlessly",
    "start": "354360",
    "end": "360039"
  },
  {
    "text": "captur stack traces that contain python or Java frames calling into a C library uh finally once the thread entry",
    "start": "360039",
    "end": "367599"
  },
  {
    "text": "point is reached uh the stack frames produced by unwinding are reported to user space for additional processing and",
    "start": "367599",
    "end": "374039"
  },
  {
    "text": "there are some more processing operations that we going to show here for in the inter of time such as casing and aring traces with container ketes",
    "start": "374039",
    "end": "380319"
  },
  {
    "text": "metadata and so on now I'm going to go a little bit more",
    "start": "380319",
    "end": "385520"
  },
  {
    "text": "uh deep into unwinding just make sure that everybody understands what's happening uh this is is a visual representation of a thread stack as it's",
    "start": "385520",
    "end": "392080"
  },
  {
    "text": "stored in memory so we can see that this stack is comprised of three stack frames so when unwinding we begin at the lowest",
    "start": "392080",
    "end": "400000"
  },
  {
    "text": "frame uh and try to recover all the return addresses that have been placed",
    "start": "400000",
    "end": "405080"
  },
  {
    "text": "on the stack now return addresses are essentially program counter values that point to executable code in memory if a",
    "start": "405080",
    "end": "412360"
  },
  {
    "text": "program is compiled with frame pointers enabled then we can simply walk the linked list starting from the current",
    "start": "412360",
    "end": "418919"
  },
  {
    "text": "value of the frame pointer register which is going to point to the frame pointer from the previous frame which",
    "start": "418919",
    "end": "424240"
  },
  {
    "text": "points to the frame pointer of the previous frame and so on uh this process is called stack walking or unwinding and",
    "start": "424240",
    "end": "431520"
  },
  {
    "text": "the end result is a stack Trace that contains stack frames that encapsulate a snapshot of all function calls in the",
    "start": "431520",
    "end": "438520"
  },
  {
    "text": "thread that is being Unwound uh at that point in",
    "start": "438520",
    "end": "443680"
  },
  {
    "text": "time now unfortunately native code does doesn't usually come with frame pointers",
    "start": "446280",
    "end": "451319"
  },
  {
    "text": "this decision is a remnant of the Register Star 32-bit xa6 Intel architecture which led compilers to",
    "start": "451319",
    "end": "458160"
  },
  {
    "text": "using the frameo register as a general purpose register now today with the amd64 and RM 64 architectures they offer",
    "start": "458160",
    "end": "464879"
  },
  {
    "text": "us a lot more general purpose registers so that's less of a problem and so there's recently being a shift towards",
    "start": "464879",
    "end": "471520"
  },
  {
    "text": "compiling code with frame pointers in production realistically however coverage will remain poor for quite some",
    "start": "471520",
    "end": "477440"
  },
  {
    "text": "time as a lot of Linux distributions don't yet support this so as you can see here in this stack if if we try to",
    "start": "477440",
    "end": "484039"
  },
  {
    "text": "unwind this again we're going to start at the lowest frame we don't have anything to follow in order to get to",
    "start": "484039",
    "end": "490199"
  },
  {
    "text": "the next frame so for a solution that's going to work everywhere including with code that doesn't have frame pointers we",
    "start": "490199",
    "end": "496759"
  },
  {
    "text": "need some mechanism to give us the next frame for unwinding and uh this mechanism in this",
    "start": "496759",
    "end": "504319"
  },
  {
    "text": "case is the eh frame section in an elf executable the eh frame was originally intended for C++ unwinding for example",
    "start": "504319",
    "end": "511879"
  },
  {
    "text": "when an exception is thrown in in C++ code the stock needs to be unwind until a Handler is found and then execution",
    "start": "511879",
    "end": "518719"
  },
  {
    "text": "will resume at the Handler with all the intermediate stack frames being thrown away now it turns out that one can reuse",
    "start": "518719",
    "end": "524920"
  },
  {
    "text": "this information uh in order to unwind stacks for profiling this is also possible because the eh frame section is",
    "start": "524920",
    "end": "531600"
  },
  {
    "text": "present in almost every native executable uh to enable interoperability where for example A C library can call",
    "start": "531600",
    "end": "537279"
  },
  {
    "text": "into a C++ library that could throw an exception then we want that exception to propagate upwards and unwind through the",
    "start": "537279",
    "end": "544320"
  },
  {
    "text": "the C library to colors of the C library so what happens is that a compiler will",
    "start": "544320",
    "end": "549839"
  },
  {
    "text": "typically emit this information even for non C++ binaries now the data in the E",
    "start": "549839",
    "end": "555680"
  },
  {
    "text": "frame section is stored in a format that is called dwarf and that's essentially virtual machine that data due to its",
    "start": "555680",
    "end": "562680"
  },
  {
    "text": "flexibility is not easy to pass especially from ebpf so for that reason the profiling agent pre-processes that",
    "start": "562680",
    "end": "569519"
  },
  {
    "text": "data uh we basically shape it into something a lot simpler that ebpf can",
    "start": "569519",
    "end": "574720"
  },
  {
    "text": "easily consume and then we populate the ebpf maps that the unwinding programs running into the kernel can can access",
    "start": "574720",
    "end": "581360"
  },
  {
    "text": "for go for go binaries the eh frame section may not be present so we use the",
    "start": "581360",
    "end": "587120"
  },
  {
    "text": "go PCL and tab section Instead This is essentially is an internal tog go data structure that also contains the",
    "start": "587120",
    "end": "593519"
  },
  {
    "text": "information we need to unwind stacks and which go itself uses in order to create its own stack traces",
    "start": "593519",
    "end": "599920"
  },
  {
    "text": "and finally for high level language uh Stacks uh we use random specific logic",
    "start": "599920",
    "end": "605079"
  },
  {
    "text": "to to unwind them I I'll come back to this in a little bit the native unwinder is an abpf",
    "start": "605079",
    "end": "612040"
  },
  {
    "text": "program that's running inside the kernel U we can also see this as a very simple virtual machine and this is a rough",
    "start": "612040",
    "end": "617519"
  },
  {
    "text": "translation to pseudo code we start by uh we start unwinding by reading the register state from the process that",
    "start": "617519",
    "end": "623120"
  },
  {
    "text": "we've interrupted and then we extract the current frame and append it to the current stack trace and then we Lo Lo",
    "start": "623120",
    "end": "629480"
  },
  {
    "text": "and execute an unwinding instruction based on the current value of the program counter and the current P ID the",
    "start": "629480",
    "end": "635680"
  },
  {
    "text": "instruction tells us how to proceed and how to unwind the next frame the output of the Native unwinder is essentially a",
    "start": "635680",
    "end": "641720"
  },
  {
    "text": "stack race and that's composed of a list of frames where each frame is composed of a module ID and an offset within that",
    "start": "641720",
    "end": "648800"
  },
  {
    "text": "module and I'll I'll explain a little bit later you know how that uh is actually",
    "start": "648800",
    "end": "654040"
  },
  {
    "text": "used for high level language unwinders we also Implement those in BPF but they",
    "start": "654040",
    "end": "659320"
  },
  {
    "text": "work differently uh so every language with sub routines needs some way to keep track of function calls in memory",
    "start": "659320",
    "end": "665600"
  },
  {
    "text": "otherwise you wouldn't know where to return to after a call so what we did here is we reverse engineered every",
    "start": "665600",
    "end": "671560"
  },
  {
    "text": "language runtime that we support in order to figure out how it keeps track of Stack frames and how it constructs",
    "start": "671560",
    "end": "676800"
  },
  {
    "text": "its own stack traces then we essentially reimplemented the same logic in ebpf by the way sometimes language run",
    "start": "676800",
    "end": "683560"
  },
  {
    "text": "time will come with GDB scripts that can produce stack traces for that runtime for that's very useful for debugging but",
    "start": "683560",
    "end": "689360"
  },
  {
    "text": "by examining those scripts and rewriting the logic that they Implement into ebpf you now have an unwinder for that",
    "start": "689360",
    "end": "696040"
  },
  {
    "text": "runtime uh so the information that the agent makes available to ebpf programs in order to enable unwinding for high",
    "start": "696040",
    "end": "701680"
  },
  {
    "text": "level languages can be very simple for example in Python it's just a few stract offsets that that we can statically",
    "start": "701680",
    "end": "707440"
  },
  {
    "text": "extract or more elaborate for example in hotspot uh we need to include locations",
    "start": "707440",
    "end": "713160"
  },
  {
    "text": "of hips and zit regions and so on but the general idea is that we do a lot of the work up front in user space in order",
    "start": "713160",
    "end": "719839"
  },
  {
    "text": "to make the kernel unwinding logic in ebpf as simple and as performant as we possibly can creating an unwinder for a",
    "start": "719839",
    "end": "727920"
  },
  {
    "text": "very complicated runtime like a hotspot is a lot of work but uh once we've done",
    "start": "727920",
    "end": "733199"
  },
  {
    "text": "all the work and now we have the unwinder run times usually don't change that much from version to version for",
    "start": "733199",
    "end": "738839"
  },
  {
    "text": "example for for minor version updates it's very often the case that we don't have to update anything our unwinders",
    "start": "738839",
    "end": "745240"
  },
  {
    "text": "keep working so for major version updates and a lot of cases we can use",
    "start": "745240",
    "end": "750800"
  },
  {
    "text": "GDB scripting to automatically extract offsets that have changed now someone may ask why go through all this effort",
    "start": "750800",
    "end": "757800"
  },
  {
    "text": "especially since a lot of high level languages now support J damp and per dump those are relatively simple formats",
    "start": "757800",
    "end": "763959"
  },
  {
    "text": "that can map program counter values to function names and they're also supported by the Linux perf tooling the",
    "start": "763959",
    "end": "771000"
  },
  {
    "text": "answer here is that they're not enabled by default so they require is starting the target process rebuilding a",
    "start": "771000",
    "end": "776920"
  },
  {
    "text": "container but I you know the only give us function names so we cannot get uh file names no line numbers and they",
    "start": "776920",
    "end": "783560"
  },
  {
    "text": "don't support inline functions but more importantly for us by working with these formats can be very time very CPU",
    "start": "783560",
    "end": "790639"
  },
  {
    "text": "intensive uh and that makes them unsuitable for low overhead continuous profiling like as an example I have here",
    "start": "790639",
    "end": "797040"
  },
  {
    "text": "a snippet taken from the net C documentation and as you can see if you enable per Maps or J times you can incur",
    "start": "797040",
    "end": "804399"
  },
  {
    "text": "a 10 to 20% CPU hit now for a lot of production deployments this is completely",
    "start": "804399",
    "end": "811120"
  },
  {
    "text": "unacceptable these are all the languages that we currently support I'm only showing a few native languages that",
    "start": "812839",
    "end": "818399"
  },
  {
    "text": "compile to native code but essentially we support every language that produces native executables with a functional eh",
    "start": "818399",
    "end": "824240"
  },
  {
    "text": "frame section which is most of them uh regarding not having r64 support for net",
    "start": "824240",
    "end": "829959"
  },
  {
    "text": "and no JS there's no technical limitation there it's just we just haven't gotten around to doing that yet but contributions are very welcome",
    "start": "829959",
    "end": "839399"
  },
  {
    "text": "and these are all the minimum kernel versions that we support generally we try to support the oldest kernel that we",
    "start": "841199",
    "end": "846959"
  },
  {
    "text": "can reasonably get away with without compromising too much on performance and for us generally this means LTS kernels",
    "start": "846959",
    "end": "853480"
  },
  {
    "text": "now 419 as you see here is it's pretty old at this point but we're still supporting it now for arm the minimum",
    "start": "853480",
    "end": "859120"
  },
  {
    "text": "version is a bit higher because there exists a breaking bag where it's impossible to read user memory in any",
    "start": "859120",
    "end": "864600"
  },
  {
    "text": "version prior to 5.4 now there might be Linux distribution uh that have back the fix but we decided not to deal with that",
    "start": "864600",
    "end": "871880"
  },
  {
    "text": "at all as the number of F that use older kernels on arm is should be fairly low",
    "start": "871880",
    "end": "877920"
  },
  {
    "text": "and on the low left you can see a r metric which is lines of code uh you can",
    "start": "877920",
    "end": "883399"
  },
  {
    "text": "yeah see this as a complexity metric of our various high level language unwinders as expected the hotspot",
    "start": "883399",
    "end": "888959"
  },
  {
    "text": "unwinder is our most complicated one but if you look at the bottom PHP and Ruby",
    "start": "888959",
    "end": "894240"
  },
  {
    "text": "they're relatively simple at less than 300 lines of code and that includes comments",
    "start": "894240",
    "end": "901040"
  },
  {
    "text": "now the the minimum Kel versions that we support also introduce the constraints that we have to work with in terms of",
    "start": "902519",
    "end": "908320"
  },
  {
    "text": "what we can do with BPF ebpf is not a stable thing it changes with every Kel version so new ebpf helpers become",
    "start": "908320",
    "end": "914720"
  },
  {
    "text": "available new functionality and so on so the first limitation is we cannot loop as the verifier cannot prove whether a",
    "start": "914720",
    "end": "921519"
  },
  {
    "text": "loop will terminate what we need to do instead is to tell the compiler to unroll all our Loops which also means",
    "start": "921519",
    "end": "927199"
  },
  {
    "text": "that we can dynamically set the number of loop iterations now every Loop iteration that we unroll will increase",
    "start": "927199",
    "end": "932680"
  },
  {
    "text": "the total program size and this is important because we only have 496 instructions per program to to work with",
    "start": "932680",
    "end": "939720"
  },
  {
    "text": "we can partly work around this by using tail calls which are BPF to BPF program calls that essentially replace the",
    "start": "939720",
    "end": "945839"
  },
  {
    "text": "calling program with the program that's been called there is no going back to the caller and we can do 32 of these",
    "start": "945839",
    "end": "952160"
  },
  {
    "text": "tail calls which means that in total we have 32 * 496 so that's around 120 th000",
    "start": "952160",
    "end": "959279"
  },
  {
    "text": "instructions to work with and it turns out that these are more than enough for for",
    "start": "959279",
    "end": "964519"
  },
  {
    "text": "unwinding now there are some other annoyances in goes like everyone here who's work with the BPF will surely",
    "start": "964519",
    "end": "970079"
  },
  {
    "text": "recognize later Kel versions give us more flexibility they have better and more General looping constructs but it",
    "start": "970079",
    "end": "976759"
  },
  {
    "text": "will take a while before these kernels propagate widely to production so for now we're sticking with the lowest",
    "start": "976759",
    "end": "982639"
  },
  {
    "text": "common denominator uh yeah so since our high",
    "start": "982639",
    "end": "989160"
  },
  {
    "text": "level language unwinders depend on runtime internals new versions of run times could change some of their internals and this means that they could",
    "start": "989160",
    "end": "995120"
  },
  {
    "text": "break our unwinders so we need a way to reliably detect regressions over time to",
    "start": "995120",
    "end": "1000360"
  },
  {
    "text": "enable these regression tests we compile our own winders against we have a user space seam implementation of the E BPF",
    "start": "1000360",
    "end": "1006759"
  },
  {
    "text": "helper functions and this allows us to run the unwinders as regular executables and even run them inside the debuger",
    "start": "1006759",
    "end": "1013319"
  },
  {
    "text": "such as GDB and we can single step through the execution we decided to use cord dumps which are snapshots of a",
    "start": "1013319",
    "end": "1019759"
  },
  {
    "text": "processing execution that include memory mappings and thread States the unwinders perform all the memory reads using the",
    "start": "1019759",
    "end": "1026240"
  },
  {
    "text": "same ebpf helper functions that they typically use in the kernel except now in this in the test Suite those raids",
    "start": "1026240",
    "end": "1033079"
  },
  {
    "text": "are transparently targeting the cord dams which essentially act as simulated processes now on the right you can see",
    "start": "1033079",
    "end": "1039720"
  },
  {
    "text": "how a test case looks like in Jon I have a parallel test case here and we can see",
    "start": "1039720",
    "end": "1045400"
  },
  {
    "text": "that it has both high level Pearl and native code stack frames now in this example there's only one thread but of",
    "start": "1045400",
    "end": "1051400"
  },
  {
    "text": "course a test case can also contain multiple threads with every thread we include the exact unwinding and also",
    "start": "1051400",
    "end": "1058080"
  },
  {
    "text": "symbolization information uh when it's available now in order to make the cord dams available to everyone that clones",
    "start": "1058080",
    "end": "1063960"
  },
  {
    "text": "the repository and wants to run the test R we store them in Oracle cloud in an S3",
    "start": "1063960",
    "end": "1069000"
  },
  {
    "text": "compatible sync that's all managed by open Telemetry we consider G lfs but given the very low per repository quotas",
    "start": "1069000",
    "end": "1076440"
  },
  {
    "text": "it's a bad fit for an open source project that we have no control over who clones it and who wants to run the the test",
    "start": "1076440",
    "end": "1083440"
  },
  {
    "text": "stre now besides unwinding the other major operation",
    "start": "1084000",
    "end": "1089360"
  },
  {
    "text": "uh which produces uh which the agent performs is symbolization uh symbolization",
    "start": "1089360",
    "end": "1096159"
  },
  {
    "text": "essentially takes a stack frame uh stack Trace as produced by unwinding and annotates the frames with symbolic information such as function name uh",
    "start": "1096159",
    "end": "1102799"
  },
  {
    "text": "file name line number and so on now as an example here on the left you can see stack Trace that was produced by",
    "start": "1102799",
    "end": "1107880"
  },
  {
    "text": "unwinding and on the the same stack Trace that's now symbolized uh now this is a native stack trace and the top two",
    "start": "1107880",
    "end": "1114880"
  },
  {
    "text": "stack frames are Kel frames and the bottom two are user space frames belonging to a go",
    "start": "1114880",
    "end": "1122039"
  },
  {
    "text": "application for Native executables uh symbols are not typically present in production as they can be hundreds of",
    "start": "1122360",
    "end": "1128640"
  },
  {
    "text": "megabytes or even gigabytes in size so this means that we need another way to perform symbolization after the agent",
    "start": "1128640",
    "end": "1135039"
  },
  {
    "text": "has picked up the profiling data possibly on the back end we can do that by relying on module IDs which are",
    "start": "1135039",
    "end": "1141640"
  },
  {
    "text": "unique identifiers for executable or shared Library files now on the right we can see some examples of different build",
    "start": "1141640",
    "end": "1146960"
  },
  {
    "text": "IDs that the compiler generates and inserts into binaries that he creates some of these build IDs can be used as",
    "start": "1146960",
    "end": "1152360"
  },
  {
    "text": "module IDs but they they come with issues for example the the go uh build ID specific to go only and the new build",
    "start": "1152360",
    "end": "1159240"
  },
  {
    "text": "ID may not always be present like for example in Alpine Linux it doesn't exist and Alpine is very widely used in Docker",
    "start": "1159240",
    "end": "1167520"
  },
  {
    "text": "containers but even if it's present the G build ID could be low cardinality or",
    "start": "1167520",
    "end": "1172600"
  },
  {
    "text": "it could be completely nuled out with garbage so that essentially invalidates it as a unique identifier for an",
    "start": "1172600",
    "end": "1178080"
  },
  {
    "text": "executable so what we did here we introduced our own custom housing scheme uh which is pretty simple",
    "start": "1178080",
    "end": "1185280"
  },
  {
    "text": "essentially we concate the first and last pages of an exq file together with its",
    "start": "1185280",
    "end": "1190880"
  },
  {
    "text": "length uh it's a very simple scheme very fast to execute but we found out that it",
    "start": "1190880",
    "end": "1196039"
  },
  {
    "text": "works Al very well in practice now besides using this custom husting scheme the agent can also record and Report the",
    "start": "1196039",
    "end": "1202120"
  },
  {
    "text": "other build ID types if they're present uh but and this is useful for interoperability for example like one",
    "start": "1202120",
    "end": "1207480"
  },
  {
    "text": "can use the G build ID to cery symbol servers or interface with other tooling that supports G build IDs and one last",
    "start": "1207480",
    "end": "1214240"
  },
  {
    "text": "thing to note here is that while the agent could symbolize native stack traces on the targets meaning on the",
    "start": "1214240",
    "end": "1219440"
  },
  {
    "text": "machine that it's executing on if the symbols are present there this is not currently done and the expectation is",
    "start": "1219440",
    "end": "1225240"
  },
  {
    "text": "that symbolization would take place after the fact on the back end for example now we are working towards supporting the scenario and we're going",
    "start": "1225240",
    "end": "1231320"
  },
  {
    "text": "to start with go executables which in the vast majority of cases come with",
    "start": "1231320",
    "end": "1237200"
  },
  {
    "text": "symbols uh since symbols for high level languages are always present on the target inside the memory space of the",
    "start": "1238039",
    "end": "1243440"
  },
  {
    "text": "process that is being profiled the agent can extract them directly from the target however for some Ram times uh",
    "start": "1243440",
    "end": "1249280"
  },
  {
    "text": "extracting these symbols may not be straightforward as we have to walk very complicated data structures so to keep",
    "start": "1249280",
    "end": "1255480"
  },
  {
    "text": "the complexity of the ebpf code low and also to operate within the constraints I mentioned before uh that are imposed on",
    "start": "1255480",
    "end": "1260960"
  },
  {
    "text": "us by the minimum Kel versions that we support we decided to perform symbolization uh for code from high",
    "start": "1260960",
    "end": "1266400"
  },
  {
    "text": "level languages in user space this means that the unwinding programs for high level languages do minimal work they",
    "start": "1266400",
    "end": "1272640"
  },
  {
    "text": "typically extract some offset or pointer values send them to user space and then user space code can actually Chase those",
    "start": "1272640",
    "end": "1278279"
  },
  {
    "text": "values in order to extract symbols from the target process memory space and the last line here you can see that this",
    "start": "1278279",
    "end": "1284120"
  },
  {
    "text": "leaves us open to some race conditions because there is a time that passes from the point where the stack Trace is",
    "start": "1284120",
    "end": "1289480"
  },
  {
    "text": "generated in the kernel in BPF and you know it's sent to user space and then symbolization takes place for example slift processes if they go away then you",
    "start": "1289480",
    "end": "1296720"
  },
  {
    "text": "cannot really reach inside them and and extract the symbols but they those sort",
    "start": "1296720",
    "end": "1301880"
  },
  {
    "text": "of races are infrequent and the agent operates on uh an eventual consistency model anyway so it's perfectly",
    "start": "1301880",
    "end": "1309600"
  },
  {
    "text": "okay now the profiling uh agent reports all the collected data using the old t",
    "start": "1309600",
    "end": "1314799"
  },
  {
    "text": "uh profiling signal this is a new signal type that we've also introduced uh this year in April we started out with Google",
    "start": "1314799",
    "end": "1321000"
  },
  {
    "text": "ppro as the base but in the interest of Rapid Evolution we've since decided to break wire compatibility with POF and",
    "start": "1321000",
    "end": "1326960"
  },
  {
    "text": "instead we strive for convertibility uh this new profiling signal is stateless unidirectional and",
    "start": "1326960",
    "end": "1332679"
  },
  {
    "text": "works on top of grpc we want to have first class support for continuous profiling but also instrumentation and",
    "start": "1332679",
    "end": "1338880"
  },
  {
    "text": "sdks and of course interoperability with other open Telemetry signals is very high priority uh the new signal type is",
    "start": "1338880",
    "end": "1345400"
  },
  {
    "text": "still experimental it's undergoing a lot of breaking changes on one hand this can be annoying",
    "start": "1345400",
    "end": "1351080"
  },
  {
    "text": "especially to Consumers and implementors but on the other hand this is the only way for us to experiment with different use cases and better explore the",
    "start": "1351080",
    "end": "1356880"
  },
  {
    "text": "solution space so feedback on that front is greatly appreciated and please get involved with the discussions taking",
    "start": "1356880",
    "end": "1362880"
  },
  {
    "text": "place in the profiling Sig if you have a particular use case that you'd like to see covered we hope that we can",
    "start": "1362880",
    "end": "1368039"
  },
  {
    "text": "stabilize the new signal type sometime in the new year now regarding the backends the",
    "start": "1368039",
    "end": "1374320"
  },
  {
    "text": "profiling agent can talk to any back end that supports the OTL profiling signal currently this is the elastic Universal",
    "start": "1374320",
    "end": "1380640"
  },
  {
    "text": "profiling back end polar signal pyroscope and data dog was coming soon I last talk to Felix couple of weeks ago",
    "start": "1380640",
    "end": "1387520"
  },
  {
    "text": "at the time of this talk there may be additional vendors who have added support for the OTL profiling signal for",
    "start": "1387520",
    "end": "1393880"
  },
  {
    "text": "experimentation and debugging elastic also makes available a standalone back end um in the form of a desktop",
    "start": "1393880",
    "end": "1399880"
  },
  {
    "text": "application that you can run on your Linux or Mac workstation we call it Dev filer this is not currently open source",
    "start": "1399880",
    "end": "1406440"
  },
  {
    "text": "but we're working on open sourcing it my my guess this is going to happen very soon our top priority at the moment is",
    "start": "1406440",
    "end": "1412720"
  },
  {
    "text": "to integrate the profiling agent with the open Telemetry collector and have it run as an open Telemetry collector",
    "start": "1412720",
    "end": "1417880"
  },
  {
    "text": "receiver this will allow us to run the collector as an agent and have it record profiles and forward them using OTP now",
    "start": "1417880",
    "end": "1424840"
  },
  {
    "text": "towards that end we've recently introduced OTP profiling support to The Collector it can now receive process and",
    "start": "1424840",
    "end": "1430840"
  },
  {
    "text": "Export OTP profiling data if you want more information about this and a way to actually try this out for yourself you",
    "start": "1430840",
    "end": "1436120"
  },
  {
    "text": "can see the linked blog post that I have at the bottom over now this is a very rough road map",
    "start": "1436120",
    "end": "1443480"
  },
  {
    "text": "with the indicators at the bottom you can take them to be Milestones or months with the caveat that you know none of",
    "start": "1443480",
    "end": "1448960"
  },
  {
    "text": "this is fixed support for luajit is expected to landar very soon uh we're currently reviewing it we're also",
    "start": "1448960",
    "end": "1454520"
  },
  {
    "text": "working on of CPU profiling uh this is also in review now regarding symbolization we are working towards uh",
    "start": "1454520",
    "end": "1461919"
  },
  {
    "text": "as I said having the agent do Native executable symbolization on the target but also working on a separate symbol",
    "start": "1461919",
    "end": "1467799"
  },
  {
    "text": "upload protocol which would' like to specify as part of telemetry and that can be used for bulk",
    "start": "1467799",
    "end": "1473320"
  },
  {
    "text": "symbol uploads uh regarding the profiling signal as I said our top priority is stabilization we're cleaning",
    "start": "1473320",
    "end": "1479200"
  },
  {
    "text": "up various POF related bits and pieces also working on semantic conventions for profiling and a specification for",
    "start": "1479200",
    "end": "1485679"
  },
  {
    "text": "profiling and also on a proposal for better supporting discrete events for",
    "start": "1485679",
    "end": "1491240"
  },
  {
    "text": "the open Telemetry collector we're working on the receiver and we're also updating various processors we could use",
    "start": "1491240",
    "end": "1496399"
  },
  {
    "text": "a lot more help here if you're currently relying on a receiver or a processor and you'd like it to support profiling you",
    "start": "1496399",
    "end": "1502279"
  },
  {
    "text": "know please do get involved in the future we'd like to support more run times for example I have Aang here we",
    "start": "1502279",
    "end": "1509559"
  },
  {
    "text": "we've had some preliminary discussions it can definitely happen uh and I've also listed some other ideas that we've",
    "start": "1509559",
    "end": "1515279"
  },
  {
    "text": "discussed in the past but uh finally and most importantly it's still early days",
    "start": "1515279",
    "end": "1520880"
  },
  {
    "text": "for profiling in otel and there's a lot of unexplored potential so all of us can realize it uh if we all get involved",
    "start": "1520880",
    "end": "1529520"
  },
  {
    "text": "now I'm going to attempt a live demo uh but be before I do that so I have here",
    "start": "1529520",
    "end": "1535399"
  },
  {
    "text": "two links those links are to the artifacts that you can use if you want to do the demo for yourself uh",
    "start": "1535399",
    "end": "1542320"
  },
  {
    "text": "unfortunately we're not making releases of the binary releases of the agent so you're going to have to go to the repository clone it and compile the",
    "start": "1542320",
    "end": "1548720"
  },
  {
    "text": "agent yourself you can use this commit sha over there to ensure that you're going to get something that at least works as I said there are a lot of",
    "start": "1548720",
    "end": "1555159"
  },
  {
    "text": "breaking changes so there's no guarantee that if you just clone and compile the current main that this is going to work",
    "start": "1555159",
    "end": "1561159"
  },
  {
    "text": "but if if you use this commit then this will work because I've tried it myself and that filer you can download also",
    "start": "1561159",
    "end": "1567880"
  },
  {
    "text": "from that link if you use that authorization token now let me",
    "start": "1567880",
    "end": "1575520"
  },
  {
    "text": "Okay cool so this is the the filer application usually I run this all the",
    "start": "1603600",
    "end": "1610760"
  },
  {
    "text": "time um you know because the and I have the agent running on my uh Linux VM",
    "start": "1610760",
    "end": "1615919"
  },
  {
    "text": "which is my main development VM so right here you you can see some tag frames it's previously",
    "start": "1615919",
    "end": "1621120"
  },
  {
    "text": "collected uh this is the flame graph view on the top there's also a timeline with uh samples you can pan and also",
    "start": "1621120",
    "end": "1630200"
  },
  {
    "text": "zoom in focus on specific time span we also",
    "start": "1630200",
    "end": "1636200"
  },
  {
    "text": "have a top end functions view so you can see how much specific how much CPU relative CPU a specific function is is",
    "start": "1636200",
    "end": "1642480"
  },
  {
    "text": "consuming on the executable tabs if you dag and drop a binary here then uh the de filer application will extract all",
    "start": "1642480",
    "end": "1648760"
  },
  {
    "text": "the symbols and symbolize stack traces that it has previously recorded so you can do symbolization after the fact in a",
    "start": "1648760",
    "end": "1655919"
  },
  {
    "text": "very similar manner as what you will be doing if you were doing it on the back",
    "start": "1655919",
    "end": "1660960"
  },
  {
    "text": "end so with that said now let me actually run some work",
    "start": "1660960",
    "end": "1668000"
  },
  {
    "text": "cloes so I'm going to start with uh the Java Benchmark here",
    "start": "1671039",
    "end": "1677640"
  },
  {
    "text": "I hope you can all read the the frame",
    "start": "1691919",
    "end": "1697158"
  },
  {
    "text": "information so this is a Java stack tree so the first thing you note here besides the like once you get past the Terrible",
    "start": "1700799",
    "end": "1707679"
  },
  {
    "text": "verbos of java stack traces is that we have different colors for for stack",
    "start": "1707679",
    "end": "1713240"
  },
  {
    "text": "frames for example the stack frames in blue are native stack frames the stack frames in green belong to Java code",
    "start": "1713240",
    "end": "1720600"
  },
  {
    "text": "that's executing on the jvm the stack frames in purple are Kel frames so every",
    "start": "1720600",
    "end": "1728799"
  },
  {
    "text": "uh different language that we support has its own color so you can quickly focus on something now this",
    "start": "1728799",
    "end": "1736039"
  },
  {
    "text": "Benchmark that I executed here is doing HTTP uh requests using NTI and uh a high",
    "start": "1736039",
    "end": "1743559"
  },
  {
    "text": "performance Java Library so we would expect to start from uh lib C so the",
    "start": "1743559",
    "end": "1749840"
  },
  {
    "text": "frames at the top are the the the origin frames and the the frames at the bottom",
    "start": "1749840",
    "end": "1755640"
  },
  {
    "text": "are the leaf frames the the the bottom as frame is where we interrupted the CPU",
    "start": "1755640",
    "end": "1761720"
  },
  {
    "text": "core so in this case we can see that we're going from libc into the jvm",
    "start": "1761720",
    "end": "1766880"
  },
  {
    "text": "internals and then into higher level code in Java we scroll further down we see",
    "start": "1766880",
    "end": "1775399"
  },
  {
    "text": "that we're doing a system call in the kernel in this case WR send message so",
    "start": "1775399",
    "end": "1781640"
  },
  {
    "text": "we're actually sending packets uh through the TCP path in the",
    "start": "1781640",
    "end": "1787000"
  },
  {
    "text": "kernel and this essentially shows us that uh we have a similar stack trays",
    "start": "1787000",
    "end": "1792360"
  },
  {
    "text": "here that can span everything like from the kernel all the layers of abstraction into native code into Java",
    "start": "1792360",
    "end": "1799440"
  },
  {
    "text": "now I'm going to execute a different uh Java",
    "start": "1799440",
    "end": "1805200"
  },
  {
    "text": "workload so this is a different Benchmark here and again it's Java U you can see Java St but what I want to focus",
    "start": "1813720",
    "end": "1819799"
  },
  {
    "text": "on here is this I'm going to zoom in hopefully see this if you look at the",
    "start": "1819799",
    "end": "1826559"
  },
  {
    "text": "file names here they end up in Scala so Scala is a language that trans jvm and",
    "start": "1826559",
    "end": "1831760"
  },
  {
    "text": "the profiling agent has no specific support for Scala the hour and winders just U Know and expect hotspot but what",
    "start": "1831760",
    "end": "1840039"
  },
  {
    "text": "this shows is that we can essentially symbolize like every language that r on top of the jvm uh and that's",
    "start": "1840039",
    "end": "1850080"
  },
  {
    "text": "nice now let me run a python workload I'm going to",
    "start": "1851960",
    "end": "1857600"
  },
  {
    "text": "show you what I'm going to essentially be executing here so this let me",
    "start": "1857600",
    "end": "1864880"
  },
  {
    "text": "hopefully so this is a minimal python application uh it's using the P copy",
    "start": "1866799",
    "end": "1872120"
  },
  {
    "text": "which is a wrapper for the C piap packet capture library and it opens a a file",
    "start": "1872120",
    "end": "1878000"
  },
  {
    "text": "this file has thousands of packets in there and essentially reads every packets and does some simulation of",
    "start": "1878000",
    "end": "1884480"
  },
  {
    "text": "processing so let me execute it",
    "start": "1884480",
    "end": "1889440"
  },
  {
    "text": "so here we have the the python stack and what I want to show you with this example is that again we start in libc",
    "start": "1896519",
    "end": "1902760"
  },
  {
    "text": "then we enter the python interpreter internals these are written in C and then we enter the high level python code",
    "start": "1902760",
    "end": "1909880"
  },
  {
    "text": "you can see here the the the code that I I wrote but what happens here is that",
    "start": "1909880",
    "end": "1916919"
  },
  {
    "text": "when when we do uh the loop call here we're",
    "start": "1916919",
    "end": "1923919"
  },
  {
    "text": "providing a call back so we're calling into C we're calling into the liap library from",
    "start": "1923919",
    "end": "1930000"
  },
  {
    "text": "Python and that's what we see here from python into C into Le pickup and we're",
    "start": "1930000",
    "end": "1936600"
  },
  {
    "text": "passing a python call back so Le pickup is going to call back into",
    "start": "1936600",
    "end": "1941960"
  },
  {
    "text": "Python and this is exactly what's happening here to call our python call back so this demonstrates again that",
    "start": "1941960",
    "end": "1950360"
  },
  {
    "text": "like the the way we capture the stack happens in a simless way and we have the complete this giv us the complete fix",
    "start": "1950360",
    "end": "1956000"
  },
  {
    "text": "picture of of what's Happening uh in this case and now I'm going to run another",
    "start": "1956000",
    "end": "1961480"
  },
  {
    "text": "python",
    "start": "1961480",
    "end": "1963760"
  },
  {
    "text": "workload so this is essentially a benchmark that does a lot of Jon dis",
    "start": "1975639",
    "end": "1981799"
  },
  {
    "text": "realization and hassing of strings so your typical uh microservice you could",
    "start": "1981799",
    "end": "1987080"
  },
  {
    "text": "say and you can see that if I zoom in here we see the you know the Json decode",
    "start": "1987080",
    "end": "1993360"
  },
  {
    "text": "calls and so on and then if I if I look at some stack frames",
    "start": "1993360",
    "end": "1998679"
  },
  {
    "text": "here then you're going to see a lot of my operations taking place here because this is a memory intensive benchwork but",
    "start": "1998679",
    "end": "2004000"
  },
  {
    "text": "looking at the flame graph is not the best way to actually understand what's happening here because uh the the Malo calls are going to be",
    "start": "2004000",
    "end": "2011159"
  },
  {
    "text": "distributed across many different stack traces but if we reach to the top functions view we can get a better idea",
    "start": "2011159",
    "end": "2016720"
  },
  {
    "text": "of where the CPU is being spent and we can see here that uh we're essentially",
    "start": "2016720",
    "end": "2023000"
  },
  {
    "text": "spending like a lot of time in gipc Malo uh like if we add up all those numbers",
    "start": "2023000",
    "end": "2030679"
  },
  {
    "text": "here including free and M we're spending more than 20% here of the CPU time just",
    "start": "2030679",
    "end": "2036000"
  },
  {
    "text": "doing memory allocation and this is a strong hint that maybe we could easily optimize this and I'm going",
    "start": "2036000",
    "end": "2043559"
  },
  {
    "text": "to now run the same Benchmark but what I'm doing now is",
    "start": "2043559",
    "end": "2050560"
  },
  {
    "text": "um I've switched the memory allocator out to G Malo instead of",
    "start": "2050560",
    "end": "2056839"
  },
  {
    "text": "GPC so now as you can see most of the time is actually being spent on the the operations that The",
    "start": "2060040",
    "end": "2066760"
  },
  {
    "text": "Benchmark is doing this ization passing of strings and Hing and you don't see the 20% uh time I mean it's not zero but",
    "start": "2066760",
    "end": "2075800"
  },
  {
    "text": "there is some memory location overhead in the Malo here as well but it's it's a lot uh it's a lot better than what we",
    "start": "2075800",
    "end": "2081200"
  },
  {
    "text": "had",
    "start": "2081200",
    "end": "2083358"
  },
  {
    "text": "before so with that uh I conclude the demo and uh I want to thank everyone",
    "start": "2087560",
    "end": "2093480"
  },
  {
    "text": "especially I want to thank everybody who has contributed to open Telemetry profiling and all of you for for coming",
    "start": "2093480",
    "end": "2099320"
  },
  {
    "text": "and uh experiencing this talk and now feel free to to ask",
    "start": "2099320",
    "end": "2104890"
  },
  {
    "text": "[Applause]",
    "start": "2104890",
    "end": "2113939"
  },
  {
    "text": "questions what language is the desktop app in sorry could you repeat that yeah what",
    "start": "2116680",
    "end": "2123040"
  },
  {
    "text": "language is the desktop app written in what languages we do not have no the",
    "start": "2123040",
    "end": "2128440"
  },
  {
    "text": "desktop app the um Dev filer Dev filer what what",
    "start": "2128440",
    "end": "2134280"
  },
  {
    "text": "language is is it implemented in yes yeah it's it's written in Rust and it's using it's essentially written like a a",
    "start": "2134280",
    "end": "2140960"
  },
  {
    "text": "game because it's refreshing 60 frames a second it's using what we call an immediate mode uh UI",
    "start": "2140960",
    "end": "2147680"
  },
  {
    "text": "Library um yeah thank you so what about multi-threaded",
    "start": "2147680",
    "end": "2154400"
  },
  {
    "text": "programs so you showed single threaded program in your examples",
    "start": "2154400",
    "end": "2159640"
  },
  {
    "text": "sorry I couldn't hear you so what about multi-threaded programs like you showed a single threaded examples like how does",
    "start": "2160079",
    "end": "2166920"
  },
  {
    "text": "it show up in yeah there there's no there is absolutely no difference it doesn't make any difference because as I said the once the kernel uh the K timer",
    "start": "2166920",
    "end": "2175640"
  },
  {
    "text": "interrupts every non-idol CPU core on the system if you have 20 CES executing code then you're going to get 20",
    "start": "2175640",
    "end": "2182480"
  },
  {
    "text": "different stack traces one stack Trace per core so threads just work there is nothing that we have to do separately",
    "start": "2182480",
    "end": "2188800"
  },
  {
    "text": "for that hey thank you um would it be",
    "start": "2188800",
    "end": "2196160"
  },
  {
    "text": "possible to profile evf programs as well as user space programs uh yeah currently we don't do",
    "start": "2196160",
    "end": "2203119"
  },
  {
    "text": "that uh maybe that's something that uh we could",
    "start": "2203119",
    "end": "2209000"
  },
  {
    "text": "consider okay thank you thank you Christos uh my question is",
    "start": "2209000",
    "end": "2216240"
  },
  {
    "text": "about uh correlation with uh the SDK context um are there any",
    "start": "2216240",
    "end": "2222400"
  },
  {
    "text": "plans or what are the plans for the correlation between a specific trace and",
    "start": "2222400",
    "end": "2228040"
  },
  {
    "text": "uh some of these profiles yeah so we had a talk the other day Jonas uh from elastic and myself",
    "start": "2228040",
    "end": "2235079"
  },
  {
    "text": "it's recorded and that talk goes into detail of how we actually do that so we do have support for correlation like you",
    "start": "2235079",
    "end": "2241240"
  },
  {
    "text": "can have trace and span IDs be essentially added to a stack Trace we",
    "start": "2241240",
    "end": "2246440"
  },
  {
    "text": "use thread local storage for that we're currently supporting Java but you know essentially we can support any language",
    "start": "2246440",
    "end": "2252599"
  },
  {
    "text": "even languages that have virtual threads and they mount uh lightweight threads on",
    "start": "2252599",
    "end": "2258160"
  },
  {
    "text": "top of opening system threads as long as we have a way to actually uh detect when that takes place and uh yeah we we can",
    "start": "2258160",
    "end": "2266760"
  },
  {
    "text": "expect that I would say to land in open Telemetry sooner rather than later it's",
    "start": "2266760",
    "end": "2271880"
  },
  {
    "text": "definitely something that we want to to add okay thank you",
    "start": "2271880",
    "end": "2277480"
  }
]